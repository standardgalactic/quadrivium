Martin Kreuzer and Lorenzo Robbiano
Computational
Commutative
Algebra
1
July 3, 2000
Springer-Verlag
Berlin Heidelberg NewYork
London Paris Tokyo
Hong Kong Barcelona
Budapest

Foreword
Hofstadter’s Law: It always takes longer than you think it will take,
even if you take into account Hofstadter’s Law.
(Douglas R. Hofstadter)
Dear Reader,
what you are holding in your hands now is for you a book. But for us, for our
families and friends, it has been known as the book over the last three years.
Three years of intense work just to ﬁll three centimeters of your bookshelf!
This amounts to about one centimeter per year, or roughly two-ﬁfths of an
inch per year if you are non-metric. Clearly we had ample opportunity to
experience the full force of Hofstadter’s Law.
Writing a book about Computational Commutative Algebra is not un-
like computing a Gr¨obner basis: you need unshakeable faith to believe that
the project will ever end; likewise, you must trust in the Noetherianity of
polynomial rings to believe that Buchberger’s Algorithm will ever terminate.
Naturally, we hope that the ﬁnal result proves our eﬀorts worthwhile. This
is a book for learning, teaching, reading, and, most of all, enjoying the topic
at hand.
Since neither of us is a native English speaker, the literary quality of
this work is necessarily a little limited. Worries about our lack of linguis-
tic sophistication grew considerably upon reading the following part of the
introduction of “The Random House College Dictionary”
An educated speaker will transfer from informal haven’t to formal have
not. The uneducated speaker who informally uses I seen or I done gone
may adjust to the formal mode with I have saw and I have went.
Quite apart from being unable to distinguish between the informal and
formal modes, we were frequently puzzled by such elementary questions as:
is there another word for synonym? Luckily, we were able to extricate our-
selves from the worst mires thanks to the generous aid of John Abbott and
Tony Geramita. They provided us with much insight into British English and
American English, respectively. However, notwithstanding their illuminating
help, we were sometimes unable to discover the ultimate truth: should I be
an ideal in a ring R or an ideal of a ring R? Finally, we decided to be
non-partisan and use both.

VI
Having revealed the names of two of our main aides, we now abandon all
pretence and admit that the book is really a joint eﬀort of many people. We
especially thank Alessio Del Padrone who carefully checked every detail of
the main text and test-solved all of the exercises. The tasks of proof-reading
and checking tutorials were variously carried out by John Abbott, Anna Bi-
gatti, Massimo Caboara, Robert Forkel, Tony Geramita, Bettina Kreuzer,
and Marie Vitulli. Anna Bigatti wrote or improved many of the CoCoA pro-
grams we present, and also suggested the tutorials about Toric Ideals and
Diophantine Systems and Integer Programming. The tutorial about Strange
Polynomials comes from research by John Abbott. The tutorial about Elim-
ination of Module Components comes from research in the doctoral thesis of
Massimo Caboara. The tutorial about Splines was conceived by Jens Schmid-
bauer. Most tutorials were tested, and in many cases corrected, by the stu-
dents who attended our lecture courses. Our colleagues Bruno Buchberger,
Dave Perkinson, and Moss Sweedler helped us with material for jokes and
quotes.
Moral help came from our families. Our wives Bettina and Gabriella, and
our children Chiara, Francesco, Katharina, and Veronika patiently helped us
to shoulder the problems and burdens which writing a book entails. And from
the practical point of view, this project could never have come to a successful
conclusion without the untiring support of Dr. Martin Peters, his assistant
Ruth Allewelt, and the other members of the staﬀat Springer Verlag.
Finally, we would like to mention our favourite soccer teams, Bayern
M¨unchen and Juventus Turin, as well as the stock market mania of the late
1990s: they provided us with never-ending material for discussions when our
work on the book became too overwhelming.
Martin Kreuzer and Lorenzo Robbiano,
Regensburg and Genova, June 2000

Contents
Foreword . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
V
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
0.1
What Is This Book About? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
0.2
What Is a Gr¨obner Basis? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
0.3
Who Invented This Theory? . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
0.4
Now, What Is This Book Really About? . . . . . . . . . . . . . . . . . . .
4
0.5
What Is This Book Not About? . . . . . . . . . . . . . . . . . . . . . . . . . .
7
0.6
Are There any Applications of This Theory? . . . . . . . . . . . . . . .
8
0.7
How Was This Book Written? . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10
0.8
What Is a Tutorial?. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
0.9
What Is CoCoA? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
0.10 And What Is This Book Good for? . . . . . . . . . . . . . . . . . . . . . . .
12
0.11 Some Final Words of Wisdom . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13
1.
Foundations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
1.1
Polynomial Rings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
Tutorial 1. Polynomial Representation I . . . . . . . . . . . . . . . . . . . .
24
Tutorial 2. The Extended Euclidean Algorithm . . . . . . . . . . . . . .
26
Tutorial 3. Finite Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
1.2
Unique Factorization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
Tutorial 4. Euclidean Domains . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
Tutorial 5. Squarefree Parts of Polynomials . . . . . . . . . . . . . . . . .
37
Tutorial 6. Berlekamp’s Algorithm . . . . . . . . . . . . . . . . . . . . . . . .
38
1.3
Monomial Ideals and Monomial Modules . . . . . . . . . . . . . . . . . .
41
Tutorial 7. Cogenerators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
Tutorial 8. Basic Operations with Monomial Ideals and Modules
48
1.4
Term Orderings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
Tutorial 9. Monoid Orderings Represented by Matrices. . . . . . . .
57
Tutorial 10. Classiﬁcation of Term Orderings . . . . . . . . . . . . . . . .
58
1.5
Leading Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
59
Tutorial 11. Polynomial Representation II . . . . . . . . . . . . . . . . . .
65
Tutorial 12. Symmetric Polynomials . . . . . . . . . . . . . . . . . . . . . . .
66
Tutorial 13. Newton Polytopes . . . . . . . . . . . . . . . . . . . . . . . . . . .
67

VIII
Contents
1.6
The Division Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
69
Tutorial 14. Implementation of the Division Algorithm . . . . . . . .
73
Tutorial 15. Normal Remainders . . . . . . . . . . . . . . . . . . . . . . . . . .
75
1.7
Gradings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
76
Tutorial 16. Homogeneous Polynomials . . . . . . . . . . . . . . . . . . . .
83
2.
Gr¨obner Bases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
85
2.1
Special Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
87
Tutorial 17. Minimal Polynomials of Algebraic Numbers . . . . . .
89
2.2
Rewrite Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
Tutorial 18. Algebraic Numbers . . . . . . . . . . . . . . . . . . . . . . . . . .
97
2.3
Syzygies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
99
Tutorial 19. Syzygies of Elements of Monomial Modules . . . . . . . 108
Tutorial 20. Lifting of Syzygies . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
2.4
Gr¨obner Bases of Ideals and Modules . . . . . . . . . . . . . . . . . . . . . 110
2.4.A
Existence of Gr¨obner Bases . . . . . . . . . . . . . . . . . . . . . . . 111
2.4.B
Normal Forms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
2.4.C
Reduced Gr¨obner Bases. . . . . . . . . . . . . . . . . . . . . . . . . . . 115
Tutorial 21. Linear Algebra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
Tutorial 22. Reduced Gr¨obner Bases. . . . . . . . . . . . . . . . . . . . . . . 119
2.5
Buchberger’s Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
Tutorial 23. Buchberger’s Criterion. . . . . . . . . . . . . . . . . . . . . . . . 127
Tutorial 24. Computing Some Gr¨obner Bases . . . . . . . . . . . . . . . 129
Tutorial 25. Some Optimizations of Buchberger’s Algorithm . . . 130
2.6
Hilbert’s Nullstellensatz . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
2.6.A
The Field-Theoretic Version . . . . . . . . . . . . . . . . . . . . . . . 134
2.6.B
The Geometric Version . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
Tutorial 26. Graph Colourings . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
Tutorial 27. Aﬃne Varieties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
3.
First Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
3.1
Computation of Syzygy Modules . . . . . . . . . . . . . . . . . . . . . . . . . 148
Tutorial 28. Splines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
Tutorial 29. Hilbert’s Syzygy Theorem . . . . . . . . . . . . . . . . . . . . . 159
3.2
Elementary Operations on Modules . . . . . . . . . . . . . . . . . . . . . . . 160
3.2.A
Intersections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
3.2.B
Colon Ideals and Annihilators . . . . . . . . . . . . . . . . . . . . . 166
3.2.C
Colon Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
Tutorial 30. Computation of Intersections . . . . . . . . . . . . . . . . . . 174
Tutorial 31. Computation of Colon Ideals and Colon Modules . . 175
3.3
Homomorphisms of Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177
3.3.A
Kernels, Images, and Liftings of Linear Maps . . . . . . . . 178
3.3.B
Hom-Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
Tutorial 32. Computing Kernels and Pullbacks . . . . . . . . . . . . . . 191
Tutorial 33. The Depth of a Module . . . . . . . . . . . . . . . . . . . . . . . 192

Contents
IX
3.4
Elimination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
Tutorial 34. Elimination of Module Components . . . . . . . . . . . . . 202
Tutorial 35. Projective Spaces and Graßmannians . . . . . . . . . . . . 204
Tutorial 36. Diophantine Systems and Integer Programming . . . 207
3.5
Localization and Saturation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
3.5.A
Localization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212
3.5.B
Saturation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215
Tutorial 37. Computation of Saturations . . . . . . . . . . . . . . . . . . . 220
Tutorial 38. Toric Ideals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221
3.6
Homomorphisms of Algebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
Tutorial 39. Projections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234
Tutorial 40. Gr¨obner Bases and Invariant Theory . . . . . . . . . . . . 236
Tutorial 41. Subalgebras of Function Fields . . . . . . . . . . . . . . . . . 239
3.7
Systems of Polynomial Equations . . . . . . . . . . . . . . . . . . . . . . . . . 241
3.7.A
A Bound for the Number of Solutions . . . . . . . . . . . . . . 243
3.7.B
Radicals of Zero-Dimensional Ideals . . . . . . . . . . . . . . . . 246
3.7.C
Solving Systems Eﬀectively. . . . . . . . . . . . . . . . . . . . . . . . 254
Tutorial 42. Strange Polynomials . . . . . . . . . . . . . . . . . . . . . . . . . 261
Tutorial 43. Primary Decompositions . . . . . . . . . . . . . . . . . . . . . . 263
Tutorial 44. Modern Portfolio Theory. . . . . . . . . . . . . . . . . . . . . . 267
A.
How to Get Started with CoCoA . . . . . . . . . . . . . . . . . . . . . . . . . . 275
B.
How to Program CoCoA. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
C.
A Potpourri of CoCoA Programs . . . . . . . . . . . . . . . . . . . . . . . . . . 293
D. Hints for Selected Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
Notation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315

Introduction
It seems to be a common practice of book readers to
glance through the introduction and skip the rest.
To discourage this kind of behaviour, we tried
to make this introduction suﬃciently
humorous to get you hooked,
and suﬃciently vague
to tempt you
to read
on.
0.1 What Is This Book About?
The title of this book is “Computational Commutative Algebra 1”. In other
words, it treats that part of commutative algebra which is suitable for explicit
computer calculations. Or, if you prefer, the topic is that part of computer
algebra which deals with commutative objects like rings and modules. Or, as
one colleague put it jokingly, the topic could be called “computative algebra”.
This description immediately leads us to another question. What is com-
mutative algebra? It is the study of that area of algebra in which the impor-
tant operations are commutative, particularly commutative rings and mod-
ules over them. We shall assume throughout the book that the reader has
some elementary knowledge of algebra: the kinds of objects one studies should
be familiar (groups, rings, ﬁelds, etc.), as should some of the basic construc-
tions (homomorphisms, residue class rings, etc.). The commutative algebra
part of this book is the treatment of polynomials in one or more indetermi-
nates. To put this in a more fancy way, we could say that the generality we
shall be able to deal with is the theory of ﬁnitely generated modules over
ﬁnitely generated algebras over a ﬁeld.
This leaves us with one last unexplained part of the title. What does the
“1” refer to? You guessed it! There will be a second volume called “Com-
putational Commutative Algebra 2”. In the course of writing this book, we
found that it was impossible to concentrate all the material we had planned
in one volume. Thus, in the (hopefully) not so distant future we will be back
with more. Meanwhile, we suggest you get acquainted with the next 300 or
so pages, and we are conﬁdent that this will keep you busy for a while.

2
Introduction
Although the fundamental ideas of Computational Commutative Algebra
are deeply rooted in the development of mathematics in the 20th century,
their full power only emerged in the last twenty years. One central notion
which embodies both the old and the new features of this subject is the
notion of a Gr¨obner basis.
0.2 What Is a Gr¨obner Basis?
The theory of Gr¨obner bases is a wonderful example of how an idea used to
solve one problem can become the key for solving a great variety of other
problems in diﬀerent areas of mathematics and even outside mathematics.
The introduction of Gr¨obner bases is analogous to the introduction of i as
a solution of the equation x2 + 1 = 0. After i has been added to the reals,
the ﬁeld of complex numbers arises. The astonishing fact is that in this way
not only x2 + 1 = 0 has a solution, but also every other polynomial equation
over the reals has a solution.
Suppose now that we want to address the following problem. Let
f1(x1, . . . , xn) = 0, . . . , fs(x1, . . . , xn) = 0
be a system of polynomial equations deﬁned over an arbitrary ﬁeld, and let
f(x1, . . . , xn) = 0 be an additional polynomial equation. How can we decide
if f(x1, . . . , xn) = 0 holds for all solutions of the initial system of equations?
Naturally, this depends on where we look for such solutions. In any event,
part of the problem is certainly to decide whether f belongs to the ideal I
generated by f1, . . . , fs, i.e. whether there are polynomials g1, . . . , gs such
that f = g1f1 + · · · + gsfs. If f ∈I , then every solution of f1 = · · · = fs = 0
is also a solution of f = 0.
The problem of deciding whether or not f ∈I is called the Ideal Mem-
bership Problem. It can be viewed as the search for a solution of x2 + 1 = 0
in our analogy. As in the case of the introduction of i, once the key tool,
namely a Gr¨obner basis of I , has been found, we can solve not only the Ideal
Membership Problem, but also a vast array of other problems.
Now, what is a Gr¨obner basis? It is a special system of generators of the
ideal I with the property that the decision as to whether or not f ∈I can
be answered by a simple division with remainder process. Its importance for
practical computer calculations comes from the fact that there is an explicit
algorithm, called Buchberger’s Algorithm, which allows us to ﬁnd a Gr¨obner
basis starting from any system of generators {f1, . . . , fs} of I .

0.3 Who Invented This Theory?
3
0.3 Who Invented This Theory?
As often happens, there are many people who may lay claim to inventing
some aspects of this theory. In our view, the major step was taken by B.
Buchberger in the mid-sixties. He formulated the concept of Gr¨obner bases
and, extending a suggestion of his advisor W. Gr¨obner, found an algorithm to
compute them, and proved the fundamental theorem on which the correctness
and termination of the algorithm hinges.
For many years the importance of Buchberger’s work was not fully ap-
preciated. Only in the eighties did researchers in mathematics and computer
science start a deep investigation of the new theory. Many generalizations
and a wide variety of applications were developed. It has now become clear
that the theory of Gr¨obner bases can be widely used in many areas of science.
The simplicity of its fundamental ideas stands in stark contrast to its power
and the breadth of its applications. Simplicity and power: two ingredients
which combine perfectly to ensure the continued success of this theory.
For instance, researchers in commutative algebra and algebraic geometry
beneﬁtted immediately from the appearance of specialized computer algebra
systems such as CoCoA, Macaulay, and Singular. Based on advanced imple-
mentations of Buchberger’s Algorithm for the computation of Gr¨obner bases,
they allow the user to study examples, calculate invariants, and explore ob-
jects one could only dream of dealing with before. The most fascinating fea-
ture of these systems is that their capabilities come from tying together deep
ideas in both mathematics and computer science.
It was only in the nineties that the process of establishing computer al-
gebra as an independent discipline started to take place. This contributed a
great deal to the increased demand to learn about Gr¨obner bases and inspired
many authors to write books about the subject. For instance, among others,
the following books have already appeared.
1) W. Adams and P. Loustaunau, An Introduction to Gr¨obner Bases
2) T. Becker and V. Weispfenning, Gr¨obner Bases
3) B. Buchberger and F. Winkler (eds.), Gr¨obner Bases and Applications
4) D. Cox, J. Little and D. O’Shea, Ideals, Varieties and Algorithms
5) D. Eisenbud, Commutative Algebra with a View toward Algebraic Geom-
etry, Chapter 15
6) B. Mishra, Algorithmic algebra
7) W. Vasconcelos, Computational Methods in Commutative Algebra and
Algebraic Geometry
8) F. Winkler, Polynomial Algorithms in Computer Algebra
9) R. Fr¨oberg, An Introduction to Gr¨obner Bases
Is there any need for another book on the subject? Clearly we think so.
For the remainder of this introduction, we shall try to explain why. First we
should explain how the contents of this book relate to the books listed above.

4
Introduction
0.4 Now, What Is This Book Really About?
Instead of dwelling on generalities and the virtues of the theory of Gr¨obner
bases, let us get down to some nitty-gritty details of real mathematics. Let
us examine some concrete problems whose solutions we shall try to explain
in this book. For instance, let us start with the Ideal Membership Problem
mentioned above.
Suppose we are given a polynomial ring P = K[x1, . . . , xn] over some
ﬁeld K , a polynomial f ∈P , and some other polynomials f1, . . . , fs ∈P
which generate an ideal I = (f1, . . . , fs) ⊆P .
Question 1 How can we decide whether f ∈I ?
In other words, we are asking whether it is possible to ﬁnd polynomials
g1, . . . , gs ∈P such that f = g1f1+· · ·+gsfs. In such a relation, many terms
can cancel on the right-hand side. Thus there is no obvious a priori bound
on the degrees of g1, . . . , gs , and we cannot simply convert this question to
a system of linear equations by comparing coeﬃcients.
Next we suppose we are given a ﬁnitely generated K -algebra R speciﬁed
by generators and relations. This means that we have a representation R =
P/I with P and I as above.
Question 2 How can we perform addition and multiplication in R?
Of course, if f1, f2 ∈P are representatives of residue classes r1, r2 ∈R,
then f1 + f2 (resp. f1f2 ) represents the residue class r1 + r2 (resp. r1r2 ).
But this depends on the choice of representatives, and if we want to check
whether two diﬀerent results represent the same residue class, we are led back
to Question 1. A much better solution would be to have a “canonical” repre-
sentative for each residue class, and to compute the canonical representative
of r1 + r2 (resp. r1r2 ).
More generally, we can ask the same question for modules. If M is a
ﬁnitely generated R-module, then M is also a ﬁnitely generated P -module
via the surjective homomorphism P −↠R, and, using generators and rela-
tions, the module M has a presentation of the form M ∼= P r/N for some
P -submodule N ⊆P r .
Question 3 How can we perform addition and scalar multiplication in M ?
Let us now turn to a diﬀerent problem. For polynomials in one indetermi-
nate, there is a well-known and elementary algorithm for doing division with
remainder. If we try to generalize this to polynomials in n indeterminates,
we encounter a number of diﬃculties.
Question 4 How can we perform polynomial division for polynomials in n
indeterminates? In other words, is there a “canonical” representation f =
q1f1 + · · · + qsfs + p such that q1, . . . , qs ∈P and the remainder p ∈P is
“small”?

0.4 Now, What Is This Book Really About?
5
Again we ﬁnd a connection with Question 2. If we can deﬁne the polyno-
mial division in a canonical way, we can try to use the remainder p as the
canonical representative of the residue class of f in R. Even if we are able to
perform the basic operations in R or M , the next step has to be the possi-
bility of computing with ideals (resp. submodules). Suppose we have further
polynomials g1, . . . , gt ∈P which generate an ideal J = (g1, . . . , gt).
Question 5 How can we perform elementary operations on ideals or sub-
modules? More precisely, how can we compute systems of generators of the
following ideals?
a) I ∩J
b) I :P J = {f ∈P | f · J ⊆I}
c) I :P J∞= {f ∈P | f · Ji ⊆I for some i ∈N}
The cases of computing I + J and I · J are obviously easy. It turns out
that the keys to the solution of this last question are the answers to our
next two problems, namely the problems of computing syzygy modules and
elimination modules.
Question 6 How can we compute the module of all syzygies of (f1, . . . , fs),
i.e. the P -module
SyzP (f1, . . . , fs) = {(g1, . . . , gs) ∈P s | g1f1 + · · · + gsfs = 0} ?
Question 7 How can we solve the Elimination Problem, i.e. for 1 ≤m < n,
how can we ﬁnd the ideal I ∩K[x1, . . . , xm]?
As we shall see, the answers to those questions have numerous applica-
tions. For instance, after we have studied the arithmetic of ﬁnitely generated
K -algebras R = P/I and of ﬁnitely generated R-modules M , the next
natural problem is to do computations with homomorphisms between such
objects.
Suppose M1 = P r1/N1 and M2 = P r2/N2 are two ﬁnitely generated
R-modules, and ϕ : M1 −→M2 is an R-linear map which is given explicitly
by an r2 × r1 -matrix of polynomials.
Question 8 How can we compute presentations of the kernel and the image
of ϕ?
And the following question gives a ﬁrst indication that we may also try
to use Computational Commutative Algebra to compute objects which are
usually studied in homological algebra.
Question 9 Is it possible to compute a presentation of the ﬁnitely generated
P -module HomP (M1, M2)?

6
Introduction
Now suppose R = P/I and S = Q/J are two ﬁnitely generated K -alge-
bras, where Q = K[y1, . . . , ym] is another polynomial ring and J ⊆Q is an
ideal. Furthermore, suppose that ψ : R −→S is a K -algebra homomorphism
which is explicitly given by a list of polynomials in Q representing the images
ψ(x1 + I), . . . , ψ(xn + I).
Question 10 How can we compute presentations of the kernel and the image
of ψ? And how can we decide for a given element of S whether it is in the
image of ψ?
Finally, one of the most famous applications of Computational Commu-
tative Algebra is the possibility to solve polynomial systems of equations.
Question 11 How can we check whether the system of polynomial equations
f1(x1, . . . , xn) = · · · = fs(x1, . . . , xn) = 0
has solutions in K
n , where K is the algebraic closure of K , and whether
the number of those solutions is ﬁnite or inﬁnite?
Question 12 If the system of polynomial equations
f1(x1, . . . , xn) = · · · = fs(x1, . . . , xn) = 0
has only ﬁnitely many solutions (a1, . . . , an) ∈K
n , how can we describe
them? For instance, can we compute the minimal polynomials of the elements
a1, . . . , an over K ? And how can we tell which of the combinations of the
zeros of those polynomials solve the system of equations?
These and many related questions will be answered in this book. For a
similar description of the contents of Volume 2 we refer the reader to its
introduction. Here we only mention that it will contain three more chapters
called
Chapter IV
The Homogeneous Case
Chapter V
Hilbert Functions
Chapter VI
Further Applications of Gr¨obner Bases
Let us end this discussion by pointing out one important choice we made.
From the very beginning we have developed the theory for submodules of
free modules over polynomial rings, and not just for their ideals. This diﬀers
markedly from the common practice of introducing everything only in the
case of ideals and then leaving the appropriate generalizations to the reader.
Naturally, there is a trade-oﬀinvolved here. We have to pay for our
generality with slight complications lingering around almost every corner.
This suggests that the usual exercises “left to the reader” by other authors
could harbour a few nasty mines. But much more importantly, in our view
Gr¨obner basis theory is intrinsically about modules. Buchberger’s Algorithm,
his Gr¨obner basis criterion, and other central notions and results deal with

0.5 What Is This Book Not About?
7
syzygies. In any case, the set of all syzygies is a module, not an ideal. There-
fore a proper introduction to Gr¨obner basis theory cannot avoid submodules
of free modules. In fact, we believe this book shows that there is no reason
to avoid them.
Finally, we would like to point out that even if you are only interested in
the theory of polynomial ideals, often you still have to be able to compute
with modules, for instance if you want to compute some invariants which
are derived from the free resolution of the ideal. Without modules, a number
of important applications of this theory would have to remain conspicuously
absent!
0.5 What Is This Book Not About?
The list of topics which we do not talk about is too long to be included here,
but for instance it contains soccer, chess, gardening, and our other favourite
pastimes.
Computational Commutative Algebra is part of a larger ﬁeld of inves-
tigation called symbolic computation which some people also call computer
algebra. Covering this huge topic is beyond the scope of our book. So, what
is symbolic computation about? Abstractly speaking, it deals with those al-
gorithms which allow modern computers to perform computations involving
symbols, and not only numbers.
Unlike your math teacher, computers do not object to symbolic simpliﬁ-
cation and rewriting of formulas such as
6\4
16\ = 4
and
9\5
19\ = 5
and
1
6 +
¡ 1
3 × 1
2
¢
=
¡ 1
6 + 1
3
¢
×
¡ 1
6 + 1
2
¢
More seriously, symbolic computation includes topics such as computational
group theory, symbolic integration, symbolic summation, quantiﬁer elimina-
tion, etc., which we shall not touch here.
Another circle of questions which we avoid is concerned with computabil-
ity, recursive functions, decidability, and so on. Almost all of our algorithms
will be formulated for polynomials and vectors of polynomials with coeﬃ-
cients in an arbitrary ﬁeld. Clearly, if you want to implement those algo-
rithms on a computer, you will have to assume that the ﬁeld is computable.
This means (approximately) that you have to be able to store an element of
your ﬁeld in ﬁnitely many memory cells of the computer, that you can check
in ﬁnitely many steps whether two such representations correspond to the
same ﬁeld element, and you have to provide algorithms for performing the
four basic operations +, −, ×, ÷, i.e. sequences of instructions which perform
these operations in ﬁnitely many steps.
For us, this assumption does not present any problem at all, since for
concrete implementations we shall always assume that the base ﬁeld is one
of the ﬁelds implemented in CoCoA, and those ﬁelds are computable.

8
Introduction
Moreover, we are not going to give a detailed account of the history of the
topics we discuss. Likewise, although at the end of the book you will ﬁnd some
references, we decided not to cite everything everywhere. More correctly, we
did not cite anything anywhere. If you want additional information about
the historical development, you can look into the books mentioned above.
For speciﬁc references to recent research papers, we recommend that you use
electronic preprint and review services. The number of papers in Computa-
tional Commutative Algebra is growing exponentially, and unlike Gr¨obner
basis computations, it does not seem likely that it will end eventually. If all
else fails, you can also drop an e-mail to us, and we will try to help you.
Finally, we do not talk about complexity issues. We shall mainly be con-
tent with proving that our algorithms terminate after ﬁnitely many steps.
Unfortunately, this ﬁnite number of steps could be so large that the actual
termination of the calculation occurs well beyond our lifetimes! In fact, it
is known that the computation of a Gr¨obner basis has doubly-exponential
worst-case time complexity. In layman’s terms this means that we should
worry that no computation of any Gr¨obner basis ever terminates in our life-
times. Fortunately, the practical experiences of mathematicians are not that
dramatic. The computation of the Gr¨obner basis of a reasonable ideal or
module usually terminates in a reasonable amount of time.
Nevertheless, it is an important topic to study how long a computer cal-
culation will actually take. For instance, in Appendix C we give some hints
which can help you speed up your CoCoA programs. The main reason that we
have not delved more into complexity considerations is that we are not spe-
cialists in this subject and we feel that we cannot contribute many meaningful
remarks in this direction.
If you are interested in practical applications of Computational Com-
mutative Algebra, the complexity issues you are going to encounter are of a
diﬀerent nature anyway. Usually, they cannot be solved by theoretical consid-
erations. Instead, they require a good grasp of the underlying mathematical
problem and a concerted eﬀort to improve your program code.
0.6 Are There any Applications of This Theory?
Deﬁnitely, yes! Computational Commutative Algebra has many applications,
some of them in other areas of mathematics, and some of them in other
sciences. Amongst others, we shall see some easy cases of the following ap-
plications.
Applications in Algebraic Geometry
• Hilbert’s Nullstellensatz (see Section 2.6)
• Aﬃne varieties (see Tutorial 27)

0.6 Are There any Applications of This Theory?
9
• Projective spaces and Graßmannians (see Tutorial 35)
• Saturation (for computing the homogeneous vanishing ideal of a projec-
tive variety, see Section 3.5 and Volume 2)
• Systems of polynomial equations (see Section 3.7)
• Primary decompositions (for computing irreducible components of vari-
eties, see Tutorial 43)
• Projective Varieties (see Volume 2)
• Homogenization (for computing projective closures, see Volume 2)
• Set-theoretic complete intersections (see Volume 2)
• Dimensions of aﬃne and projective varieties (see Volume 2)
• Ideals of points (see Volume 2)
Applications in Number Theory
• Modular arithmetic, factoring polynomials over ﬁnite ﬁelds (see Tutori-
als 3 and 6)
• Computations in the ﬁeld of algebraic numbers (see Tutorials 17 and 18)
• Magic squares (see Volume 2)
Applications in Homological Algebra
• Computation of syzygy modules (see Section 3.1)
• Kernels, images and liftings of module homomorphisms (see Section 3.3)
• Computation of Hom-modules (see Section 3.3)
• Ext-modules and the depth of a module (see Tutorial 33)
• Graded free resolutions (see Volume 2)
Applications in Combinatorics
• Monomial ideals and modules (see Section 1.3)
• Graph colourings (see Tutorial 26)
• Toric ideals (see Tutorial 38)
Practical and Other Applications
• Splines (see Tutorial 28)
• Diophantine Systems and Integer Programming (see Tutorial 36 and 38)
• Strange Polynomials (see Tutorial 42)
• Mathematical Finance: Modern Portfolio Theory (see Tutorial 44)
• Photogrammetry (see Volume 2)
• Chess Puzzles (see Volume 2)
• Statistics: Design of Experiments (see Volume 2)
• Automatic Theorem Proving (see Volume 2)

10
Introduction
0.7 How Was This Book Written?
In our opinion, any plan for writing a book should include a set of rules which
the authors intend to follow consistently. This metarule is more diﬃcult to
comply with than one thinks, and indeed many books appear to have been
written in a more liberal manner. Strictly following a set of rules seems to
be in contrast with the freedom of choosing diﬀerent approaches to diﬀerent
problems. On the other hand, too much freedom sometimes leads to situations
which, in our opinion, cheat the reader.
For instance, one of our most important rules is that statements called
Lemma, Proposition, Theorem, etc. have to be followed by a complete proof,
and the development of the theory should be as self-contained as possible.
In particular, we avoid relegating proofs to exercises, giving a proof which
consists of a reference which is not speciﬁc, giving a proof which consists
of a reference hard to verify, because it uses diﬀerent assumptions and/or
notation, and giving a proof which consists of a reference to a later part of
the book.
Another fundamental rule is that the notation used in this book is con-
sistent throughout the book and always as close as possible to the notation
of the computer algebra system CoCoA. It is clear that, in an emerging ﬁeld
like computer algebra, the notation is still in ﬂux and few conventions hold
uniformly. We think that the situation in computer algebra is even worse
than elsewhere. Just look at the following table which presents the diﬀerent
terminologies and the notation used for some fundamental objects in our ref-
erences listed in Subsection 0.3. Its second row contains our choices which
agree with CoCoA.
Given a non-zero polynomial f in a polynomial ring K[x1, . . . , xn] and
an ordering σ on the set of products of powers of indeterminates, we let
xα1
1 · · · xαn
n
be the largest element (with respect to σ) in the support of f
and c ∈K its coeﬃcient in f .
xα1
1 · · · xαn
n
Notation
c · xα1
1 . . . xαn
n
Notation
leading term
LTσ(f)
(none)
LMσ(f)
1)
leading power product
lp(f)
leading term
lt(f)
2)
head term
HT(f)
head monomial
HM(f)
3)
leading power product
LPP≺(f)
leading monomial
LM≺(f)
4)
leading monomial
LM(f)
leading term
LT(f)
5)
initial monomial
(none)
initial term
in>(f)
6)
head term
Hterm(f)
head monomial
Hmono(f)
7)
initial monomial
in(f), M(f)
leading term
lt(f), L(f)
8)
leading power product
lpp(f)
initial
in(f)
9)
leading monomial
lm(f)
leading term
lt(f)
A further constraint is that we have tried to structure each section ac-
cording to the following scheme: introduction, body, exercises, tutorials.

0.8 What Is a Tutorial?
11
The introduction describes the content in a lively style, where Italian
imagination overtakes German rigour. Metaphors, sketches of examples, and
psychological motivations of the themes of the section are included here. The
body is the technical part of the section. It includes deﬁnitions, theorems,
proofs, etc. Very few compromises with imagination are accepted here. How-
ever, we always try to liven up the text by including examples.
Nothing special needs to be said about the exercises, except maybe that
they are supposed to be easy. A careful reader of the book should succeed in
solving them, and to make life even easier, we include some hints for selected
exercises in the text, and some more in Appendix D. Then there is one of the
main features of this book which we believe to be non-standard. At the end
of every section there are tutorials.
0.8 What Is a Tutorial?
Almost all books about computer algebra include some exercises which re-
quire that actual computations be performed with the help of a computer
algebra system. But in our opinion, the gap between the theory and actual
computations is much too wide.
First of all, the algorithms in the text are usually presented in pseudocode
which, in general, is completely diﬀerent from the way you write a function
in a computer algebra system. In fact, we have a hard time understanding
precisely what pseudocode is, because it is not rigorously deﬁned. Instead, we
have tried to present all algorithms in the same way mathematicians formu-
late other theorems and to provide explicit and complete proofs of their ﬁnite-
ness and correctness. If the reader is asked to implement a certain algorithm
as a part of some tutorial or exercise, these natural language descriptions
should translate easily into computer code on a step-by-step basis.
Secondly, to narrow the gap between theory and computation even more,
we decided to link the tutorials and some exercises with a speciﬁc computer
algebra system, namely CoCoA. This does not mean that you cannot use
another computer algebra system. It only means that there deﬁnitely is a
solution using CoCoA.
Every tutorial develops a theme. Sometimes we anticipate later parts of
the theory, or we step out a little from the main stream and provide some
pointers to applications or other areas of interest. A tutorial is like a small
section by itself which is not used in the main text of the book. Some eﬀort
on the part of the reader may be required to develop a small piece of theory
or to implement certain algorithms. However, many suggestions and hints in
the CoCoA style are there to guide you through the main diﬃculties.

12
Introduction
0.9 What Is CoCoA?
CoCoA is a computer algebra system. It is freely available and may be found
on the internet at the URL
http://cocoa.dima.unige.it
CoCoA means “Computations in Commutative Algebra”. As we men-
tioned above, we suggest that you use CoCoA to solve the programming parts
of the tutorials. The version of CoCoA we refer to in this book is CoCoA 4.
In Appendix A, we give some instructions on how you can download and
install CoCoA on your computer. Then we show how you can start the program
and how you can use it interactively. Before trying to solve the ﬁrst tutorial,
we think you should read through this appendix and those following it. The
basic features of CoCoA, its syntax, and its data types are explained there.
If you have never used a computer algebra system before, you should
deﬁnitely go through some of the examples on your computer. Play a little
and get yourself acquainted with the system! Soon you will also learn how to
use the on-line manual in order to get additional information.
Since the tutorials and some exercises require that you do some actual
programming, we added Appendix B which gives a brief introduction to this
topic. There you can ﬁnd the basic commands for creating your own CoCoA
functions, as well as some ideas on how you can organize your program devel-
opment. In Appendix C we provide you with a number of examples of CoCoA
programs which should help to get you started and which contain clues for
certain tutorials.
0.10 And What Is This Book Good for?
Too often, mathematical results are terribly abused by teachers
who take a cheap shortcut and simply refer to a result
from the past, from another place, another context,
totally underestimating the diﬃculty (and the importance)
of transporting these ideas from one place to another.
When that happens, the mathematics loses, the application loses,
and most of all, the student loses.
(Peter Taylor)
From the very ﬁrst glimpse, it should be clear to you that this book
is not a typical undergraduate text. But it is primarily intended to serve
as a textbook for courses in Computational Commutative Algebra at the
undergraduate or graduate level. As we explained above, we tried to avoid
the traps Peter Taylor mentions. The material developed here has already
been used for teaching undergraduate and graduate students with little or no
experience in computer algebra.
Secondly, you can use this book for a self-guided tour of Computational
Commutative Algebra. We did our best to ﬁll it with many examples, detailed

0.11 Some Final Words of Wisdom
13
proofs, and generous hints for exercises and tutorials which should help to
pave your road. This does not necessarily mean that when you work your
way through the book, there will be no unexpected diﬃculties.
Probably you already know some of the topics we discuss. Or, maybe, you
think you know them. For instance, you may have previously encountered
the polynomial ring in a single indeterminate over a ﬁeld such as Q, R,
or C, and you may feel comfortable using such polynomials. But did you
know that there are polynomials whose square has fewer terms than the
polynomial itself? At ﬁrst glance this seems unlikely, at second glance it may
look possible, and at third glance you will still not be able to decide, because
you ﬁnd no example. By looking at the polynomial
f = x12 + 2
5 x11 −2
25 x10 +
4
125 x9 −
2
125 x8 +
2
125 x7
−
3
2750 x6 −
1
275 x5 +
1
1375 x4 −
2
6875 x3 +
1
6875 x2 −
1
6875 x −
1
13750
whose square is
f 2 = x24 + 4
5 x23 +
44
3125 x19 +
2441
171875 x18 −
2016
171875 x17 −
16719
37812500 x12
+
141
9453125 x11 −
3
859375 x7 +
13
8593750 x6 +
1
4296875 x5 +
1
47265625 x +
1
189062500
you can convince yourself that such a phenomenon actually occurs. But what
is really surprising is that this is the simplest example possible, as we shall
see in Tutorial 42.
Thus we advise you to go through the book with an open and critical
mind. We have tried to ﬁll it with a lot of hidden treasures, and we think that
even if you have some previous knowledge of Computational Commutative
Algebra, you will ﬁnd something new or something that could change your
view of one topic or another.
Last, but not least, the book can also be used as a repository of explicit
algorithms, programming exercises, and CoCoA tricks. So, even if computers
and programming entice you more than algebraic theorems, you will ﬁnd
plenty of things to learn and to do.
0.11 Some Final Words of Wisdom
Naturally, this introduction has to leave many important questions unan-
swered. What is the deeper meaning of Computational Commutative Al-
gebra? What is the relationship between doing computations and proving
algebraic theorems? Will this theory ﬁnd widespread applications? What is
the future of Computational Commutative Algebra? Instead of elaborating
on these profound philosophical problems, let us end this introduction and
send you oﬀinto Chapter 1 with a few words of wisdom by Mark Green.

14
Introduction
There is one change which has overtaken commutative algebra that is in
my view revolutionary in character – the advent of symbolic computation.
This is as yet an unﬁnished revolution. At present, many researchers rou-
tinely use Macaulay, Maple, Mathematica, and CoCoA to perform computer
experiments, and as more people become adept at doing this, the list of the-
orems that have grown out of such experiments will enlarge. The next phase
of this development, in which the questions that are considered interesting
are inﬂuenced by computation and where these questions make contact with
the real world, is just beginning to unfold. I suspect that ultimately there
will be a sizable applied wing to commutative algebra, which now exists in
embryonic form.

1. Foundations
Der Ball ist rund.
(Sepp Herberger)
In the introduction we have already discussed our battle plan and the main
themes to be encountered, and now we are at the very start of the game. No
book can be completely self-contained, and this one is no exception. In par-
ticular, we assume that the reader has some knowledge of basic algebra, but
we think that she/he might feel more comfortable if we recall some funda-
mental deﬁnitions. Section 1.1 is speciﬁcally designed with this purpose in
mind and also to present many examples. They serve as reminders of known
facts for more experienced readers, and as training for beginners. The main
notion recalled there is that of a polynomial, which plays a fundamental role
throughout the book.
At the end of Section 1.1 we present, for the ﬁrst time, a special feature
of this book, namely the tutorials. Among other tasks, most tutorials require
doing some programming using the computer algebra system CoCoA. As we
said in the introduction, this book is not about computability, but rather
about actual computations of objects related to polynomials. Therefore we
are not going to discuss computability and related questions, but instead we
shall develop the necessary background in Commutative Algebra and then
show how you can work with it: go to your desk, turn on the computer, and
work.
What are the most fundamental properties of polynomial rings over ﬁelds?
One of them is certainly the unique factorization property. Section 1.2 is en-
tirely devoted to this concept. In some sense this section can be considered
as another link between very elementary notions in algebra and the themes
of the book. However, the task of describing algorithms for factorizing poly-
nomials is not taken up here. Only in a tutorial at the end of Section 1.2 do
we give a guide to implementing Berlekamp’s Algorithm which computes the
factorization of univariate polynomials over ﬁnite ﬁelds.
After the ﬁrst two sections, the reader should be suﬃciently warmed up
to enter the game for real, and Section 1.3 is intended to serve this purpose.
In particular, Dickson’s Lemma provides a fundamental ﬁniteness result and
gives us a ﬁrst hint about how to compute with polynomial ideals and mod-
ules. Section 1.4 brings the reader into the realm of orderings. Term orderings

16
1. Foundations
are an important tool for actually computing, since they enable us to write
polynomials in a well-deﬁned way which can then be implemented on a com-
puter.
After ordering the terms in polynomials or tuples of polynomials com-
pletely, their leading terms can be singled out. Section 1.5 shows how to use
those leading terms to build leading term ideals and modules. Conceptually,
these are simpler objects to handle than the original ideals or modules. For
instance, the main result of Section 1.5 is Macaulay’s Basis Theorem which
describes a basis of a quotient module in terms of a certain leading term
module.
A drawback of Macaulay’s Basis Theorem is that it neither says how to
compute such a basis nor how to represent the residue classes. A ﬁrst at-
tempt to overcome these diﬃculties is made in Section 1.6 where the reader
is instructed on how to perform a division with remainder for tuples of poly-
nomials. This procedure is called the Division Algorithm and generalizes the
well-known algorithm for univariate polynomials.
However, we shall see that the Division Algorithm fails to completely
solve the problem of computing in residue class modules. New forces have
to be brought into play. Section 1.7, the closing section of the ﬁrst chapter,
serves as a preparation for further advances. It is devoted to accumulating
new knowledge and to enlarging the reader’s background. More precisely,
very general notions of gradings are described there. They can be used to
overcome some of the diﬃculties encountered in Chapter 1. This goal will be
the topic of subsequent chapters.

1.1 Polynomial Rings
17
1.1 Polynomial Rings
Even the longest journey
begins with the ﬁrst step.
(Chinese Proverb)
As mentioned above, we think that the reader might feel more comfortable
if we recall some fundamental deﬁnitions. Therefore the style of this section is
slightly diﬀerent from the rest of the book simply because we want to squeeze
in several notions. Thus there will be more emphasis on examples than on
theorems.
The main purpose of this section is to recall the notions of polynomials and
polynomial rings. They are the most fundamental objects of Computational
Commutative Algebra and play a central role throughout this book. It is
important to clarify what we mean by a ring. Technically speaking, we mean
an “associative, commutative ring with identity”.
To be a little less blunt, we should say that rings are abundant in “na-
ture” and the reader should have already met some, for instance the rings of
integers Z, rational numbers Q, real numbers R, and complex numbers C.
One should remember that the rational numbers, the real numbers, and the
complex numbers have the extra property that every non-zero element is in-
vertible, and that they are called ﬁelds. Also all square matrices of a given
size with entries in a ring form a ring with respect to the usual operations
of componentwise sum and row-by-column product, but, in contrast to the
previously mentioned rings, the property A · B = B · A fails, i.e. they form
a non-commutative ring.
Although we shall use matrices intensively, our basic objects are poly-
nomial rings in a ﬁnite number of indeterminates over ﬁelds. Since they are
commutative rings, let us ﬁrst deﬁne these objects.
Recall that a monoid is a set S , together with an operation S ×S −→S
which is associative and for which there exists an identity element, i.e. an
element 1S ∈S such that 1S · s = s · 1S = s for all s ∈S . When it is clear
which monoid is considered, we simple write 1 instead of 1S . Furthermore,
a group is a monoid in which every element is invertible, i.e. such that for
all s ∈S there exists an element s′ ∈S which satisﬁes s · s′ = s′ · s = 1S .
A monoid is called commutative if s · s′ = s′ · s for all s, s′ ∈S .
Deﬁnition 1.1.1. By a ring (R, +, ·) (or simply R if no ambiguity can
arise) we shall always mean a commutative ring with identity element,
i.e. a set R together with two associative operations +, · : R × R →R
such that (R, +) is a commutative group with identity element 0, such that
(R\{0}, ·) is a commutative monoid with identity element 1R , and such that
the distributive laws are satisﬁed. If no ambiguity arises, we use 1 instead
of 1R . A ﬁeld K is a ring such that (K \ {0}, ·) is a group.
For the rest of this section, we let R be a ring. Some elements of a ring
have special properties. For instance, if r ∈R satisﬁes ri = 0 for some i ≥0,

18
1. Foundations
then r is called a nilpotent element, and if rr′ = 0 implies r′ = 0 for all
r′ ∈R, then r is called a non-zerodivisor. A ring whose non-zero elements
are non-zerodivisors is called an integral domain. For example, every ﬁeld
is an integral domain.
The following example is not central to the themes of this book, but it
contributes to show the abundance of rings.
Example 1.1.2. Let C(R) be the set of continuous functions over the reals.
If we deﬁne f + g and f · g by the rules (f + g)(a) = f(a) + g(a) and
(f ·g)(a) = f(a)·g(a) for every a ∈R, then it is easy to see that (C(R), +, ·)
is a commutative ring.
Normally, when we deﬁne a new class of algebraic objects, we also want to
know which maps between them respect their structure. Thus we now recall
the concept of a ring homomorphism.
Deﬁnition 1.1.3. Let R, S , and T be rings.
a) A map ϕ : R →S is called a ring homomorphism if ϕ(1R) = 1S
and for all elements r, r′ ∈R we have ϕ(r + r′) = ϕ(r) + ϕ(r′) and
ϕ(r ·r′) = ϕ(r)·ϕ(r′), i.e. if ϕ preserves the ring operations. In this case
we also call S an R-algebra with structural homomorphism ϕ.
b) Given two R-algebras S and T whose structural homomorphisms are
ϕ : R −→S and ψ : R −→T , a ring homomorphism ϱ : S −→T is
called an R-algebra homomorphism if we have ϱ(ϕ(r)·s) = ψ(r)·ϱ(s)
for all r ∈R and all s ∈S .
For instance, going back to Example 1.1.2, we see that the inclusion of the
constant functions into C(R) makes C(R) an R-algebra, and that the map
ϕ : C(R) −→R deﬁned by
ϕ(f) = f(0)
is a ring homomorphism and also
an R-algebra homomorphism. For every ring R, there exists a ring homo-
morphism ϕ : Z −→R which maps 1Z to 1R . It is called the characteristic
homomorphism of R.
Sometimes a ﬁeld and a group are tied together by an operation of the
ﬁeld on the group to produce the very well known algebraic structure of
a vector space. In this case the elements of the ﬁeld are called scalars, the
elements of the group are called vectors, and the operation is called scalar
multiplication. Those concepts generalize in the following way.
Deﬁnition 1.1.4. An R-module M is a commutative group (M, +) with
an operation · : R × M →M (called scalar multiplication) such that
1·m = m for all m ∈M , and such that the associative and distributive laws
are satisﬁed. A commutative subgroup N ⊆M is called an R-submodule
if we have R · N ⊆N . If N ⊂M then it is called a proper submodule. An
R-submodule of the R-module R is called an ideal of R.
Given two R-modules M and N , a map ϕ : M −→N is called an R-
module homomorphism or an R-linear map if ϕ(m + m′) = ϕ(m) +
ϕ(m′) and ϕ(r · m) = r · ϕ(m) for all r ∈R and all m, m′ ∈M .

1.1 Polynomial Rings
19
Using this terminology, we can say that an R-algebra is a ring with an
extra structure of an R-module such that the two structures are compatible
and the usual commutative and distributive laws are satisﬁed.
The deﬁnition of an ideal I ⊆R could also be rephrased by saying that
a subset I of R is an ideal if it is an additive subgroup of R and R · I ⊆I .
In a ﬁeld K , the only two ideals are K itself and {0}. Given any ideal I in
a ring R, we can form the residue class ring R/I . It is an R-module in the
obvious way. It is even an R-algebra, since the canonical map R −→R/I is
a ring homomorphism.
Some ideals of R have special properties. For instance, an ideal I ⊂R is
called a prime ideal if rr′ ∈I implies r ∈I or r′ ∈I for all r, r′ ∈R, and
it is called a maximal ideal of R if the only ideal properly containing I
is R itself. It is easy to see that I is a prime ideal if and only if R/I is an
integral domain, that I is a maximal ideal if and only if R/I is a ﬁeld, and
hence that maximal ideals are prime ideals.
Deﬁnition 1.1.5. Let M be an R-module.
a) A set {mλ | λ ∈Λ} of elements of M is called a system of generators
of M if every m ∈M has a representation m = r1mλ1 + · · · + rnmλn
such that n ∈N, r1, . . . , rn ∈R and λ1, . . . , λn ∈Λ. In this case we
write M = ⟨mλ | λ ∈Λ⟩. The empty set is a system of generators of the
zero module {0}.
b) The module M is called ﬁnitely generated if it has a ﬁnite system of
generators. If M is generated by a single element, it is called cyclic. A
cyclic ideal is called a principal ideal.
c) A system of generators {mλ | λ ∈Λ} is called an R-basis of M if
every element of M has a unique representation as above. If M has an
R-basis, it is called a free R-module.
d) If M is a ﬁnitely generated free R-module and {m1, . . . , mr} is an R-
basis of M , then r is called the rank of M and denoted by rk(M). We
remind the reader that it is known that all bases of a ﬁnitely generated
free module have the same length. Hence the rank of M is well-deﬁned.
Example 1.1.6. Finitely generated and free modules arise in a number of
situations.
a) The rings Z and K[x] where K is a ﬁeld have the property that all their
ideals are principal. An integral domain with this property is called a
principal ideal domain. For example, the ideal in K[x] generated by
{x −x2, x2} is also generated by {x}.
b) The ideal (2) ⊆Z is a free Z-module of rank one, whereas the Z-module
Z/(2) is not free.
c) If K is a ﬁeld and V is a K -vector space, then every K -submodule of
V is free. This follows from the existence theorem for bases in vector
spaces.
d) The ring R is a free R-module with basis {1}.

20
1. Foundations
The following notion generalizes the vector space of n-tuples of elements
in a ﬁeld.
Deﬁnition 1.1.7. For n ∈N, the set Rn = {(r1, . . . , rn) | r1, . . . , rn ∈R}
of all n-tuples is a free R-module with respect to componentwise addition
and scalar multiplication. For i = 1, . . . , n, let the tuple ei be given by
ei = (0, . . . , 0, 1, 0, . . . , 0), with 1 occurring in the ith position. Then the set
{e1, . . . , en} is an R-basis of Rn. We call it the canonical basis of Rn .
Now we recall the notion of a univariate polynomial ring. Since we shall
use it to deﬁne multivariate polynomial rings recursively, we start with an
arbitrary ring R. We consider the set R(N) of all sequences (r0, r1, . . .)
of elements r0, r1, . . . ∈R such that we have ri ̸= 0 for only ﬁnitely
many indices i ≥0. Using componentwise addition and scalar multiplica-
tion, this set becomes a free R-module with R-basis {ei | i ∈N}, where
ei = (0, . . . , 0, 1, 0, 0, . . .) with 1 occurring in position i + 1. Every element
of this set has a unique representation (r0, r1, . . .) = P
i∈N riei . Given two
elements P
i∈N riei and P
i∈N siei , we deﬁne
(
X
i∈N
riei) · (
X
i∈N
siei) =
X
i∈N


i
X
j=0
rjsi−j

ei
Can you imagine where this strange rule comes from? (The answer to this
question is given after the next deﬁnition.)
It is easy to check that the set R(N), together with componentwise addi-
tion and the product deﬁned above, is a commutative ring with identity e0 ,
and that ei = ei
1 for all i ∈N. Furthermore, the map R →R(N) given by
r 7→r · e0 is an injective ring homomorphism.
Deﬁnition 1.1.8. We let R be a ring and equip R(N) with the ring structure
deﬁned above.
a) If we let x = e1 , the ring R(N) is called the polynomial ring in the
indeterminate x over R and is denoted by R[x]. It is a commutative
ring and every element of R[x] has a unique representation P
i∈N rixi
with ri ∈R and ri ̸= 0 for only ﬁnitely many indices i ∈N.
b) For n ≥1, we recursively deﬁne R[x1, . . . , xn] = (R[x1, . . . , xn−1])[xn]
and call it the polynomial ring in n indeterminates over R.
c) The elements of a polynomial ring are called polynomials. Polynomials
in one indeterminate are often called univariate polynomials, while
polynomials in several indeterminates are called multivariate polyno-
mials.
Notice that, given this deﬁnition, the multiplication of two univariate
polynomials P
i∈N rixi and P
i∈N sixi comes out to be P
i∈N(Pi
j=0 rjsi−j) xi,
and this corresponds exactly to what we learn in high school. Many proper-
ties of a ring are inherited by polynomial rings over it. Some instances of this
general phenomenon are given by the following proposition.

1.1 Polynomial Rings
21
Proposition 1.1.9. Let R be an integral domain.
a) The units in R[x1, . . . , xn] are the units in R.
b) The polynomial ring R[x1, . . . , xn] is an integral domain.
Proof.
Since R[x1, . . . , xn] was deﬁned recursively, it suﬃces to prove the
claims for n = 1. Given two elements f = P
i∈N rixi and g = P
j∈N r′
jxj in
R[x] \ {0}, we let d = max{i ∈N | ri ̸= 0} and e = max{j ∈N | r′
j ̸= 0}.
Then the deﬁnition of the multiplication in R[x] implies that one of the
summands in the representation of the element fg is rdr′
exd+e ̸= 0. From
this remark both claims follow immediately.
□
Both statements of this proposition fail if R is not an integral domain.
For instance, if R = Z/(4), then (1 + 2x)(1 −2x) = 1 and 2x · (2x2 + 2) = 0
in R[x]. Following the recursive deﬁnition, an example of a polynomial in
three indeterminates over Q is
f(x1, x2, x3) =
¡
( 2
3 −x3
1) + (x4
1)x2
¢
+
¡
(1 −x5
1)x4
2 −( 3
7x1 + 7x3
1)x5
2
+(x11
1 )x7
2
¢
x3 +
¡
( 1
12x1 −13x2
1 + 7
67x3
1) + (x1 −3
22x3
1)x2 + (4 −x1)x2
2
¢
x2
3
+
¡
x2
2 + (4 −8
13x9
1)x3
2
¢
x3
3
Many parentheses have to be used to represent multivariate polynomials
in this way. It sure looks ugly, doesn’t it? But we can do much better. The
associative and distributive laws provide us with a more compact representa-
tion. In fact, every polynomial f ∈R[x1, . . . , xn] has a unique representation
of the form
f =
X
α∈Nn
cαtα
where α = (α1, . . . , αn) and tα = xα1
1 · · · xαn
n , and where only ﬁnitely many
elements cα ∈R are diﬀerent from zero. For instance, the polynomial above
can be written as
f(x1, x2, x3) = x11
1 x7
2x3 −8
13x9
1x3
2x3
3 −x5
1x4
2x3 −7x3
1x5
2x3 −3
7x1x5
2x3
−3
22x3
1x2x2
3 + x4
1x2 + 7
67x3
1x2
3 −x1x2
2x2
3 + x4
2x3 + 5x2
2x3
3
−13x2
1x2
3 + x1x2x2
3 + 4x2
2x2
3 −x3
1 + 1
12x1x2
3 + 2
3
It is immediately clear that there are many diﬀerent ways of writing down
this polynomial depending on the ordering of the elements x11
1 x7
2x3 , x9
1x2
2x3
3 ,
x5
1x4
2x3 , etc.
More generally, let r ≥1, and let M = (R[x1, . . . , xn])r be the ﬁnitely
generated free R[x1, . . . , xn]-module with canonical basis {e1, . . . , er} such
that ei = (0, . . . , 0, 1, 0, . . . , 0) as in Deﬁnition 1.1.7. Then every element
m ∈M has a unique representation of the form
m = (f1, . . . , fr) =
r
X
i=1
X
α∈Nn
cα,itαei

22
1. Foundations
where f1, . . . , fr ∈R[x1, . . . , xn], and where only ﬁnitely many elements
cα,i ∈R are diﬀerent from zero.
In these representations, we used polynomials of the form xα1
1 · · · xαn
n ,
where α1, . . . , αn ∈N. Since such elements will occur frequently, we give
them a name.
Deﬁnition 1.1.10. Let n ≥1.
a) A polynomial f ∈R[x1, . . . , xn] of the form f = xα1
1 · · · xαn
n
such that
(α1, . . . , αn) ∈Nn is called a term or power product. The set of all
terms of R[x1, . . . , xn] is denoted by Tn or T(x1, . . . , xn).
b) For a term t = xα1
1 · · · xαn
n
∈Tn , the number deg(t) = α1 + · · · + αn is
called the degree of t.
c) The map log : Tn →Nn deﬁned by xα1
1 · · · xαn
n
7→(α1, . . . , αn) is called
the logarithm.
d) If r ≥1 and M
= (R[x1, . . . , xn])r is the ﬁnitely generated free
R[x1, . . . , xn]-module with canonical basis {e1, . . . , er}, then a term
of M is an element of the form tei such that t ∈Tn and 1 ≤i ≤r.
The set of all terms of M will be denoted by Tn⟨e1, . . . , er⟩or by
T(x1, . . . , xn)⟨e1, . . . , er⟩.
The set Tn is a commutative monoid. Its identity element is 1 = x0
1 · · · x0
n .
The monoid Tn does not depend on the ring of coeﬃcients R. The set
Tn⟨e1, . . . , er⟩can be considered as the disjoint union of r copies of Tn where
the symbols e1, . . . , er simply indicate which copy of Tn we are considering.
Deﬁnition 1.1.11. Let n ≥1, let f = P
α∈Nn cαtα ∈R[x1, . . . , xn] be a
polynomial, and let m = Pr
i=1
P
α∈Nn cα,itαei ∈M = (R[x1, . . . , xn])r .
a) For every α ∈Nn ,i ∈{1, . . . , r}, the element cα,i ∈R is called the
coeﬃcient of the term tαei in m.
b) The set {tαei ∈Tn⟨e1, . . . , er⟩| cα,i ̸= 0} is called the support of m
and denoted by Supp(m).
c) If f ̸= 0, the number max{deg(tα) | tα ∈Supp(f)} is called the degree
of f and denoted by deg(f).
For example, the support of the polynomial f ∈Q[x1, x2, x3] above con-
sists of 17 terms, and the sequence of their degrees is 19, 15, 10, 9, 7, 6, 5, 5, 5,
5, 5, 4, 4, 4, 3, 3, 0. We have ordered the terms in Supp(f) by decreasing de-
gree. However, this is not enough to order them completely since there are sev-
eral terms with the same degree. Complete orderings on Tn and Tn⟨e1, . . . , er⟩
will be examined in Section 1.4.
The polynomial ring can be used to deﬁne interesting ring homomor-
phisms. One of its fundamental properties, called the Universal Property,
says that ring homomorphisms starting from a polynomial ring are uniquely
deﬁned by the images of the indeterminates, and those images may be chosen
freely.

1.1 Polynomial Rings
23
Proposition 1.1.12. (Universal Property of the Polynomial Ring)
Let S be an R-algebra with structural homomorphism ϕ : R →S , let n ≥1,
and let s1, . . . , sn be elements in S . Then there exists a unique ring homo-
morphism ψ : R[x1, . . . , xn] →S such that ψ|R = ϕ and ψ(xi) = si for
i = 1, . . . , n.
Proof.
By induction, it suﬃces to prove the claim for n = 1. For d ≥0 and
c0, . . . , cd ∈R, we let ψ(Pd
i=0 cixi
1) = Pd
i=0 ϕ(ci)si
1 . It is easy to check that
this deﬁnes a ring homomorphism having the required properties. On the
other hand, since ψ has to be compatible with addition and multiplication,
this deﬁnition is forced upon us and ψ is uniquely determined.
□
A ring homomorphism ψ deﬁned in this way is also called an evaluation
homomorphism, and the image of a polynomial f is called the evalua-
tion f(s1, . . . , sn) of f at (s1, . . . , sn). In the special case when S = R, an
evaluation homomorphism ψ : R[x1, . . . , xn] −→R is also called a substi-
tution homomorphism. Using evaluations, we can speak about generators
of R-algebras in the following manner.
Deﬁnition 1.1.13. Let S be an R-algebra.
a) A set {sλ | λ ∈Λ} of elements of S is called a system of gen-
erators of S if for every element s ∈S there is a ﬁnite subset
{λ1, . . . , λt} of Λ and a polynomial f(x1, . . . , xt) ∈R[x1, . . . , xt] such
that s = f(sλ1, . . . , sλt).
b) The R-algebra S is called ﬁnitely generated if it has a ﬁnite system
of generators.
Corollary 1.1.14. An R-algebra S is ﬁnitely generated if and only if
there exists a number n ∈N and a surjective R-algebra homomorphism
ϕ : R[x1, . . . , xn] −→S .
In other words, every ﬁnitely generated R-algebra S is of the form
S ∼= R[x1, . . . , xn]/I where I is an ideal in R[x1, . . . , xn].
Proof.
This follows from the fact that a set {s1, . . . , sn} of elements of S
is a system of generators of S if and only if the R-algebra homomorphism
ϕ : R[x1, . . . , xn] −→S deﬁned by xi 7−→si for i = 1, . . . , n is surjective.
□
For an R-algebra S which has a ﬁnite system of generators {s1, . . . , sn},
the corresponding isomorphism S ∼= R[x1, . . . , xn]/I is called a presenta-
tion of S by generators and relations, and the ideal I is called the ideal of
algebraic relations among {s1, . . . , sn} with coeﬃcients in R.

24
1. Foundations
Exercise 1.
Let d ∈Z be a non-square number, and let K = Q[
√
d],
where we use
√
d = i·
√
−d if d < 0. Prove that K is a ﬁeld, and that every
element r ∈K has a unique representation r = a + b
√
d with a, b ∈Q.
The ﬁeld K is called the quadratic number ﬁeld generated by
√
d.
After representing r, s ∈K by pairs of rationals, give formulae for r + s,
−r, r · s, and
1
r for r ̸= 0.
Exercise 2.
Show that, up to a unique isomorphism, the polynomial
ring R[x1, . . . , xn] is the only R-algebra satisfying the universal property
stated in Proposition 1.1.12. In other words, suppose that T is another
R-algebra together with elements t1, . . . , tn ∈T , such that whenever you
have an R-algebra S together with elements s1, . . . , sn ∈S , then there
exists a unique R-algebra homomorphism ψ : T →S satisfying ψ(ti) = si
for i = 1, . . . , n. Then show that there is a unique R-algebra isomorphism
R[x1, . . . , xn] →T such that xi 7→ti for i = 1, . . . , n.
Exercise 3. Show that the map log : Tn −→Nn is an isomorphism of
monoids.
Exercise 4.
Let v1 = (a11, a21, . . . , an1), . . . , vn = (a1n, a2n, . . . , ann)
be elements of Zn , and let A = (aij) ∈Matn(Z) be the matrix whose
columns are the coordinates of v1, . . . , vn . Show that the set {v1, . . . , vn}
is a Z-basis of Zn if and only if det(A) ∈{1, −1}.
Exercise 5. Let S be the set of functions from Z to Z.
a) Show that S with the usual sum and product of functions is a Z-
algebra.
b) Use considerations about the cardinality of S to show that S is not
a ﬁnitely generated Z-algebra.
Exercise 6. Let R be a ring and I a non-zero ideal of R. Prove that I
is a free R-module if and only if it is a principal ideal generated by a
non-zerodivisor.
Exercise 7.
Let R be a ring. Show that the following conditions are
equivalent.
a) The ring R is a ﬁeld.
b) Every ﬁnitely generated R-module is free.
c) Every cyclic R-module is free.
Exercise 8. Let K be a ﬁeld, P = K[x1, x2], and I be the ideal in P
generated by {x1, x2}. Show that I is not a free P -module.
Tutorial 1: Polynomial Representation I
In what follows we work over the ring K[x, y], where K is one of the ﬁelds
deﬁned in CoCoA. Using Deﬁnition 1.1.8, we see that we can represent every
polynomial f ∈K[x, y] as a list of lists, where a univariate polynomial a0 +
a1x + · · · + adxd such that a0, . . . , ad ∈K and ad ̸= 0 is represented by the
list [a0, . . . , ad].

1.1 Polynomial Rings
25
The purpose of this tutorial is to program the transition from polynomials
to lists (and back), and to see how addition and multiplication of polynomials
can be carried out using their list representations. Thus this tutorial is mainly
intended as an introduction to the kind of CoCoA programming we ask you
to do in other tutorials.
There are solutions of parts of this tutorial in Appendix C.1. Since
most programs require the use of lists, we suggest you read Appendices A.6
and B.5 before you start. A (long) list of CoCoA commands for dealing with
lists can be generated by invoking the on-line manual with the command
H.Commands(’list’);
a) Write a CoCoA program ReprUniv(. . .) which takes two arguments: the
ﬁrst argument should be a univariate polynomial over K , and the second
one should be the indeterminate occurring in it. If the polynomial is
f = a0 +a1x+· · ·+adxd, the program should return the list [a0, . . . , ad]
representing this polynomial.
Hint: There is a pedestrian solution involving a For-loop and the CoCoA
function CoeffOfTerm(. . .) and an elegant one using the command
Coefficients(. . .).
b) Implement also a CoCoA function ListToPoly(. . .) which takes a list of
numbers and constructs the corresponding univariate polynomial in the
indeterminate x. Use this function and ReprPoly(. . .) to convert the
polynomials f1 = x4 + 3x2 −x + 1 and f2 = y2 + 2y + 3 to lists and
back.
Hint: A simple For-loop or the sum over an appropriately constructed
list will do the trick.
c) Write CoCoA functions AddUniv(. . .) and MultUniv(. . .) which take two
lists representing univariate polynomials and compute the lists represent-
ing their sum and product, respectively. Use the program ListToPoly(. . .)
to check the correctness of both functions.
Hint: When implementing the sum, you should switch the summands
such that the ﬁrst one has larger degree (i.e. a longer list). Then you can
add the elements of the second list onto the ﬁrst one.
For the implementation of the product, you may want to consider the
formula (a0 + · · · + adxd) · (b0 + · · · + bexe) = Pd+e
i=0 (Pi
j=0 ajbi−j) · xi . It
may be useful to bring both lists to the same length ﬁrst (by appending
zeros). The inner sum could be realized by a construction like Sum(L),
where L is the list of all ajbi−j .
d) Write a CoCoA program ReprPoly(. . .) which represents a polynomial
f ∈K[x, y] as a list of lists of elements of K . The elements of the big
list are lists representing univariate polynomials in K[x], namely the co-
eﬃcients of the diﬀerent powers of y in the polynomial, considered as an
element of (K[x])[y] as in Deﬁnition 1.1.8.b. For instance, the polynomial
f1 = x2 + 2xy + 3y2 is represented by the list of lists [[0, 0, 1], [0, 2], [3]].

26
1. Foundations
Hint: The CoCoA command Deg(F,x) returns the degree of a polynomial
F with respect to the indeterminate x. The function Shorten(. . .) in
Appendix C.1 removes trailing zeros from a list. These facts and a double
For-loop are good enough for a ﬁrst solution. More elegantly, you can also
use Reversed(Coefficients(. . .)) and a clever list construction.
e) Write a CoCoA program ListListToPoly(. . .) which converts lists of lists
back to polynomials in K[x, y].
f) Apply the programs ReprPoly(. . .) and ListListToPoly(. . .) to the
polynomials f1 = x2 + 2xy + 3y2 , f2 = y2 −x4 , and f3 = 1 + x +
y + x2 + y2 + x4 + y4 + x8 + y8 .
g) Write CoCoA-programs AddPoly(. . .) and MultPoly(. . .) which take two
lists L1, L2 representing polynomials in K[x, y] and compute the lists
representing their sum and product, respectively.
h) Check the correctness of your programs by converting f1 + f2 , f1 · f2
and f2f3 + f 3
1 into lists in two ways.
i) (For more advanced programmers) Using recursive programming, redo
parts d), e), and g) for polynomials in K[x1, . . . , xn]. Try these functions
in some concrete examples and show that they are correct.
Tutorial 2: The Extended Euclidean Algorithm
There is a well-known algorithm for computing the greatest common divisor
of two positive integers called the Euclidean Algorithm. In this tutorial
we shall extend it and use the extended version to show how to implement
the basic operations of a ﬁeld of type Fp = Z/(p).
a) Let a, b ∈Z. Consider the following sequence of instructions.
1) If a = b = 0, return 0. If a = 0 and b ̸= 0, return |b|. If a ̸= 0
and b = 0, return |a|. Otherwise replace a and b by their absolute
values and form the pair (a, b) ∈N2 .
2) If a > b, interchange a and b.
3) Compute a representation b = qa + r with q ∈N and a remainder
0 ≤r < a. If r = 0, return a. If r ̸= 0, replace (a, b) by (r, a) and
repeat step 3).
Show that this is an algorithm which stops after ﬁnitely many steps and
returns gcd(a, b), i.e. the greatest common divisor of a and b. (We use
gcd(0, 0) = 0.) It is called the Euclidean Algorithm.
b) Write a CoCoA function Euclid(. . .) which implements the algorithm
of a).
c) Prove that, for a, b ∈Z, there exist c, d ∈Z such that ac+bd = gcd(a, b).
d) Let a, b ∈Z. Consider the following sequence of instructions.
1) If a = b = 0, return the triple (0, 0, 0). If a = 0 and b ̸= 0, return the
triple (0, |b|
b , |b|). If a ̸= 0 and b = 0, return the triple ( |a|
a , 0, |a|).

1.1 Polynomial Rings
27
2) Form the triples (c0, d0, e0) = ( |a|
a , 0, |a|) and (c1, d1, e1) = (0, |b|
b , |b|).
3) Check whether e1 ≤e0 . If this is not the case, interchange (c0, d0, e0)
and (c1, d1, e1).
4) Write e0 in the form e0 = qe1 + r, where q ∈N and 0 ≤r < e1 .
Then form (c2, d2, e2) = (c0 −qc1, d0 −qd1, r).
5) Replace (c0, d0, e0) by (c1, d1, e1) and (c1, d1, e1) by (c2, d2, e2).
6) Repeat steps 4) and 5) until e1 = 0. Then return the triple (c0, d0, e0)
and stop.
Show that this is an algorithm, called the Extended Euclidean Algo-
rithm, i.e. that it stops after ﬁnitely many steps, and that it computes
a triple (c, d, e) ∈Z3 such that e = gcd(a, b) and ac + bd = e.
e) Write a CoCoA function ExtEuclid(. . .) which implements the algorithm
in d).
f) Explain how one can modify the Extended Euclidean Algorithm so that it
applies to univariate polynomials over a ﬁeld K . Write a CoCoA function
PolyExtEuclid(. . .) which performs this computation.
Hint: Use the built-in CoCoA function DivAlg(. . .) to do the division with
remainder.
g) Every element of Z/(p) can be uniquely represented by one of the inte-
gers in {0, 1, . . . , p−1}. Write CoCoA functions ZpAdd(. . .), ZpMult(. . .),
ZpNeg(. . .), and ZpInv(. . .) which compute addition, multiplication, neg-
atives, and inverses in Z/(p) using this representation. Do not use the
built-in modular arithmetic of CoCoA, but ﬁnd direct methods.
Tutorial 3: Finite Fields
In Tutorial 2 we showed how to perform actual computations in the ﬁnite
ﬁelds of type Z/(p). The purpose of this tutorial is to build upon that knowl-
edge and show how it is possible to compute in more general ﬁnite ﬁelds. Let
p > 1 be a prime number.
(Note: Several parts require some basic knowledge of ﬁeld theory.)
a) Let K be a ﬁnite ﬁeld of characteristic p. Show that the number q of
elements of K is a power of p, i.e. there is a number e > 0 such that
q = pe. (Hint: Note that K is a Z/(p)-vector space.)
b) Let L be an algebraically closed ﬁeld of characteristic p. Prove that there
exists a unique subﬁeld Fq of L which has q elements, and that it is the
set of roots of the equation xq −x = 0.
c) Show that every ﬁeld K with q elements is isomorphic to Fq , that there
is an irreducible polynomial f of degree e in Z/(p)[x], and that there is
an isomorphism K ∼= Z/(p)[x]/(f).
Hint: For the second part, use the fact that the multiplicative group
K \ {0} is cyclic.

28
1. Foundations
d) Implement a CoCoA function IrredPoly(. . .) which computes the list of
all monic irreducible polynomials f of degree d = deg f ≤e in Z/(p)[x],
i.e. whose coeﬃcient of xd is 1. Proceed degree by degree, starting with
[x, x −1, . . . , x −p + 1] and appending the list of all monic polynomials
of degree d which are not divisible by one of the irreducible polynomials
of degree ≤d/2.
e) Using f = Last(IrredPoly(. . .)), we can represent every element r ∈K
as a list r = [r1, . . . , re] of elements r1, . . . , re ∈Z/(p) such that
r+(f) = r1+r2x+· · ·+rexe−1+(f). Write CoCoA functions FFAdd(. . .),
FFNeg(. . .), FFMult(. . .), and FFInv(. . .) which compute the lists repre-
senting the sums, negatives, products, and inverses of elements of K ,
respectively. (Hint: Use the base ring S::=Z/(P)[x].)
f) Compute a representation of the ﬁeld F16 and its multiplication table.

1.2 Unique Factorization
29
1.2 Unique Factorization
Everything should be made
as simple as possible,
but not simpler.
(Albert Einstein)
In this section we discuss a fundamental property of polynomial rings over
ﬁelds, namely the unique factorization property. One learns in school that for
every integer n we may write n = pα1
1 pα2
2 · · · pαs
s , where p1, . . . , ps are prime
numbers. For instance, 504 = 23 · 32 · 7. Moreover, such a factorization is
unique up to sign changes and order, for instance 504 = (−2)3 ·(−7)·32 . The
main topic in this section is to prove that polynomial rings have the same
property.
The spirit of the section is to give an account of the theory underlying
this notion which is as simple as possible, but not simpler. Once it is known
that polynomial rings over ﬁelds have the unique factorization property, the
next question is how to compute factorizations of polynomials eﬀectively. The
treatment of that question goes beyond the scope of this book. However, in
Tutorial 6 we give some hints on how to do it for univariate polynomials over
Z/(p).
Other notions which everyone learns in school are the least common mul-
tiple and greatest common divisor of natural numbers. We show that factorial
rings provide a suitable environment for deﬁning such concepts (see Deﬁni-
tion 1.2.6) and we prove some of their basic properties (see Proposition 1.2.8).
Other subjects related to the unique factorization property will be considered
in the exercises and tutorials.
Now, let us do ﬁrst things ﬁrst and introduce the notions of irreducible and
prime elements in such a way that it is possible to speak about factorizations.
Deﬁnition 1.2.1. Let R be an integral domain and r ∈R \ {0} be a non-
unit.
a) The element r is said to be reducible,
if it can be expressed as the
product of two elements neither of which is a unit. Otherwise it is called
irreducible.
b) If r = u·r1·r2 · · · rs with a unit u ∈R and irreducible elements r1, . . . , rs,
then such an expression is called a factorization of r.
c) If r has the property that r | r1 · r2 implies r | r1 or r | r2 for all
r1, r2 ∈R, then r is called a prime (or a prime element) of R.
For a unit r ∈R, we shall call r = r a factorization of r. We observe
that the only divisors of an irreducible element are the units and the element
itself.
Proposition 1.2.2. In the polynomial ring K[x] in one indeterminate over
a ﬁeld K , a non-zero non-unit element is a prime if and only if it is irre-
ducible.

30
1. Foundations
Proof.
The only non-trivial implication is to show that if f is irreducible,
then it is a prime. We have already mentioned (see Example 1.1.6) that if
K is a ﬁeld, then every ideal in K[x] is principal. Suppose f is irreducible,
f | ab, and f ∤a. Then ab = gf for some g ∈K[x]. Since the ideal (a, f) is
generated by a divisor of f , we have (a, f) = (1), and therefore 1 = ra + sf
for some r, s ∈K[x]. Thus we get b = rab + sbf = rgf + sbf and f | b.
□
In Exercise 9 we will see an element of an integral domain which is ir-
reducible but not prime. The following example shows that the notion of
irreducibility in a polynomial ring depends strongly on the ﬁeld of coeﬃ-
cients.
Example 1.2.3. In the ring R[x] the element x2 + 1 is irreducible. On the
other hand, in the ring C[x], we have x2 + 1 = (x + i)(x −i), hence it
is reducible. It is clear that other factorizations of x2 + 1 are for instance
(i −x)(−i −x) and (2x + 2i)(1/2x −1/2i), but it is also clear that these
factorizations are basically the same, i.e. they diﬀer only by changing the
factors by units.
This leads to the following deﬁnition.
Deﬁnition 1.2.4. Let R be an integral domain. Then R is said to be fac-
torial, or a factorial domain, or a unique factorization domain if every
non-unit in R \ {0} has a unique factorization up to order and units.
For example, every ﬁeld is trivially a factorial domain. In order to ﬁnd
less trivial examples, we want to study how this uniqueness of factorizations
relates to the notions of irreducible and prime elements.
Proposition 1.2.5. Let R be an integral domain with the property that ev-
ery non-zero non-unit has a factorization. Then the following conditions are
equivalent.
a) The ring R is factorial.
b) Every irreducible element of R is a prime.
Proof.
Let R be factorial, and let r ∈R be an irreducible element. Suppose
r | ab. Hence we have an equation ab = cr with non-units a, b, c ∈R \ {0}.
Then the irreducible factor r must show up either in the factorization of a
or in that of b. Therefore we have either r | a or r | b which shows that r is
a prime.
Conversely, let a1a2 · · · as = b1b2 · · · bt be factorizations of the same ele-
ment. We see that b1b2 · · · bt ∈(a1), hence the assumption implies that one
of the factors has to be in (a1). Up to a permutation of the factors we may
assume that b1 ∈(a1). Since both a1 and b1 are irreducible, they are equal
up to a unit and can be cancelled in the equation a1a2 · · · as = b1b2 · · · bt.
Continuing in this way, we can see that the two factorizations are essentially
the same.
□

1.2 Unique Factorization
31
As with integers, it is possible to deﬁne greatest common divisors and
least common multiples in a factorial domain.
Deﬁnition 1.2.6. Let R be a factorial domain. We say that two irreducible
elements of R are associated if they diﬀer only by multiplication with a
unit of R. Let the set P ⊆R be obtained by picking one element in each
class of associated irreducible elements of R. Furthermore, let m ≥2 and
f1, . . . , fm ∈R \ {0}.
a) Let f1 = c1
Q
p∈P pαp and f2 = c2
Q
p∈P pβp be factorizations of f1 and
f2 with units c1, c2 ∈R, with αp, βp ∈N, and with αp = βp = 0 for all
but ﬁnitely many p ∈P . Then the element
gcd(f1, f2) = Q
p∈P
pmin{αp,βp}
is called a greatest common divisor of f1 and f2 , and the element
lcm(f1, f2) = Q
p∈P
pmax{αp,βp}
is called a least common multiple of f1 and f2 .
b) If gcd(f1, f2) = 1, we say that f1, f2 are coprime or relatively prime.
c) For m > 2, we deﬁne a greatest common divisor and a least com-
mon multiple of f1, . . . , fm recursively by
gcd(f1, . . . , fm) = gcd(gcd(f1, . . . , fm−1), fm)
lcm(f1, . . . , fm) = lcm(lcm(f1, . . . , fm−1), fm)
d) Let f = c Q
p∈P pαp with a unit c ∈R, with αp ∈N, and with αp = 0
for all but ﬁnitely many p ∈P be the decomposition of an element
f ∈R \ {0} into irreducible factors. Then the element
sqfree(f) = Q
p∈P
pmin{1,αp}
is called a squarefree part of f .
It is clear that the deﬁnition of greatest common divisors and least com-
mon multiples does not depend on the order of the elements. It is also clear
that greatest common divisors, least common multiples, and squarefree parts
of elements f1, . . . , fm ∈R\{0} change only by a unit if we choose a diﬀerent
set of representatives P for the equivalence classes of irreducible elements. We
shall therefore speak of the greatest common divisor and the least common
multiple of f1, . . . , fm ∈R\{0}, as well as the squarefree part of f ∈R\{0},
while always keeping in mind that they are unique only up to a unit.
In the following, we describe some connections between greatest com-
mon divisors, least common multiples, and ideal theory. First we characterize
greatest common divisors and least common multiples by divisibility proper-
ties.

32
1. Foundations
Proposition 1.2.7. (Characterization of gcd and lcm)
Let R be a factorial domain, and let f1, . . . , fm ∈R \ {0}
a) An element f ∈R is the greatest common divisor of f1, . . . , fm if and
only if f | fi for i = 1, . . . , m and every element g ∈R such that g | fi
for i = 1, . . . , m satisﬁes g | f .
b) An element f ∈R is the least common multiple of f1, . . . , fm if and only
if fi | f for i = 1, . . . , m and every element g ∈R such that fi | g for
i = 1, . . . , m satisﬁes f | g.
Proof.
First we prove a). For i = 1, . . . , m, let fi = ci
Q
p∈P pαpi be the
factorization of fi . Using the deﬁnition and induction on m, we see that
gcd(f1, . . . , fm) = Q
p∈P pmin{αp1,...,αpm} . Thus it follows immediately that
gcd(f1, . . . , fm) divides fi for i = 1, . . . , m.
Now let g ∈R be a common divisor of f1, . . . , fm, and let g = c Q
p∈P pβp
be the factorization of g. For every i ∈{1, . . . , m}, the condition g | fi
implies that βp ≤αpi for all p ∈P . Hence we get βp ≤max{αp1, . . . , αpm}
for all p ∈P , and therefore g | gcd(f1, . . . , fm).
The proof of claim b) follows in exactly the same way.
□
Proposition 1.2.8. Let R be a factorial domain and f1, . . . , fm ∈R \ {0}.
a) The element lcm(f1, . . . , fm) generates the ideal (f1) ∩· · · ∩(fm).
b) We have gcd(f1, f2) = f1f2/ lcm(f1, f2).
c) Suppose R is a principal ideal domain. Then gcd(f1, . . . , fm) generates
the ideal (f1, . . . , fm). In particular, we have gcd(f1, . . . , fm) = 1 if and
only if there are elements g1, . . . , gm ∈R such that g1f1+· · ·+gmfm = 1.
Proof.
Since least common multiples were deﬁned recursively, it suﬃces to
prove claim a) for m = 2. Let f1 = c1pα1
1 · · · pαs
s
and f2 = c2pβ1
1 · · · pβs
s
be
factorizations of f1 and f2 , where c1, c2 ∈R are units, where αi, βj ≥0,
and where p1, . . . , ps ∈R are irreducible elements representing s diﬀerent
equivalence classes. Note that lcm(f1, f2) = pmax{α1,β1}
1
· · · pmax{αs,βs}
s
is di-
visible by both f1 and f2 , i.e. it is in (f1) ∩(f2). Conversely, every element
in (f1) ∩(f2) is divisible by pαi
i
and pβi
i
for i = 1, . . . , s, and therefore by
pmax{αi,βi}
i
. Thus every element in (f1) ∩(f2) is a multiple of lcm(f1, f2).
The proof of b) follows from the fact that αi + βi = min{αi, βi} +
max{αi, βi} for i = 1, . . . , s. Finally, to show c), we note that any ele-
ment of (f1, . . . , fm) is a multiple of gcd(f1, . . . , fm). Conversely, let h ∈R
be a generator of (f1, . . . , fm). Since h | fi for i = 1, . . . , m, we have
h | gcd(f1, . . . , fm). Thus we get gcd(f1, . . . , fm) ∈(h) = (f1, . . . , fm), as
claimed.
□
Now it is time to move directly to the heart of this section. We want to
prove that polynomial rings over ﬁelds are factorial. The next lemma is the
key to this proof.

1.2 Unique Factorization
33
Deﬁnition 1.2.9. Let R be a factorial domain and f ∈R[x]\{0}. A great-
est common divisor of the coeﬃcients of f is called a content of f .
As
before, we usually speak of the content of f and denote it by cont(f). If
cont(f) = 1, we say that f is primitive.
Lemma 1.2.10. (Gauß’s Lemma)
Let R be a factorial domain, and let f, g ∈R[x] be non-zero polynomials.
a) We have cont(fg) = cont(f) · cont(g).
b) If f, g are primitive, so is fg.
Proof.
It is clear that a) follows from b), since every polynomial f is of
the form f = cont(f) · ˜f for some primitive polynomial ˜f . So, let us prove
b). We write f = P
i∈N rixi and g = P
i∈N sixi with ri, si ∈R. Let p
be an irreducible element of R. The hypothesis implies that the numbers
j = min{i ∈N | p ∤ri} and k = min{i ∈N | p ∤si} exist. Now R is factorial
and p is irreducible, hence prime. As it does not divide rj and sk , it does
not divide rj · sk either. The choice of j and k yields that p does not divide
the coeﬃcient of xj+k in fg. Therefore it does not divide cont(fg), and we
are done.
□
Lemma 1.2.11. Let R be a factorial domain. Then every non-zero element
of R[x] has a factorization.
Proof.
Let f ∈R[x]\{0} be a non-unit. Since f is of the form f = cont(f)·g
with a primitive polynomial g, and since cont(f) has a factorization by
assumption, we may assume that f is primitive.
We proceed by induction on d = deg(f). If d = 0 then f = cont(f) = 1
has a trivial factorization. If d > 0 and f is irreducible, there is nothing to
prove. Otherwise, let f = gh with non-units g, h ∈R[x] \ {0}. If one of the
two, say g, has degree zero, i.e. if g ∈R, then 1 = cont(f) = g · cont(h),
contradicting the fact that g is not a unit. Thus the degrees of g and h
are both strictly less than d, and an application of the inductive hypothesis
ﬁnishes the proof.
□
Proposition 1.2.12. Let R be a factorial domain. Then R[x] is also a fac-
torial domain.
Proof.
According to Proposition 1.2.5 and Lemma 1.2.11, we have to prove
that every irreducible polynomial in R[x] is prime. Let Q(R) be the ﬁeld of
fractions of R. In order to prove the claim, we shall argue as follows: if f
is an irreducible element of R[x], we show that it is irreducible in Q(R)[x],
hence prime in Q(R)[x]. Finally, we infer from this that f is prime in R[x].
Let f be an irreducible element in R[x]. Then it is clear that f is prim-
itive. Suppose we have in Q(R)[x] an equation f = g1h1 with non-zero and
non-invertible polynomials g1, h1 ∈Q(R)[x]. Then g1 and h1 are of positive
degree. By possibly clearing the denominators, we see that there exists an

34
1. Foundations
element r ∈R such that rf = g2h2 with g2, h2 ∈R[x]. From Lemma 1.2.10
we know that r = cont(g2) · cont(h2). Thus we can simplify and get a new
equation f = g3h3 with primitive polynomials g3, h3 ∈R[x]. Since the de-
grees of g3 and h3 are positive and R is an integral domain, neither is a
unit, contradicting the irreducibility of f . Thus we have shown that f is
irreducible in Q(R)[x].
The ring Q(R)[x] is a univariate polynomial ring over a ﬁeld, hence in
Q(R)[x] every irreducible element is prime (see Proposition 1.2.2). Conse-
quently, the polynomial f is prime in Q(R)[x]. It remains to show that f
is prime as an element of R[x]. We start with an equation ef = gh, where
e, g, h ∈R[x]. If we read it in Q(R)[x], we deduce that g or h must be a mul-
tiple of f in Q(R)[x]. Assume for instance that g = qf with q ∈Q(R)[x].
By clearing the denominators, we get rg = pf for some r ∈R and p ∈R[x].
Therefore we have r · cont(g) = cont(p), and after cancelling r we obtain
g ∈(f), as was to be shown.
□
By repeatedly applying the previous proposition, we see that polynomial
rings over ﬁelds are factorial domains. This is one of their fundamental prop-
erties and deserves to be the ﬁnal theorem of the present section.
Theorem 1.2.13. Let K be a ﬁeld and n ≥1. Then the polynomial ring
K[x1, . . . , xn] is a factorial domain.
Exercise 1. Prove that prime elements are irreducible.
Exercise 2. Let p = 101. Write a CoCoA program which checks whether
a given polynomial f ∈Z/(p)[x] of degree deg(f) ≤3 is irreducible. Prove
the correctness of your method.
Exercise 3.
Let p be a prime number and π : Z[x] →Z/(p)[x] the
canonical homomorphism.
a) Show that if f ∈Z[x] is a monic polynomial and π(f) is irreducible
then f is irreducible.
b) Prove that statement a) is, in general, false if f is not monic.
c) Give a counterexample to the converse of a).
Exercise 4.
Find a factorial domain R ̸= Z which does not contain a
ﬁeld.
Exercise 5.
Show that if R is a factorial domain and p is minimal
among the prime ideals diﬀerent from (0), then p is principal.
Exercise 6. Let R be an integral domain with the property that every
non-zero non-unit has a factorization. Assume that, for all a, b ∈R \ {0},
the ideal (a) ∩(b) is principal.
a) Prove that, given non-associated irreducible elements a, b ∈R \ {0},
we have (a) ∩(b) = (ab).
Hint: Let (a) ∩(b) = (c), let ab = rc, and let c = sa. Show that s
cannot be a unit. Then deduce that r has to be a unit.

1.2 Unique Factorization
35
b) Use a) to prove that two factorizations of any element are the same
up to order and units.
c) Conclude that R is a factorial domain.
Exercise 7.
Consider the ring R = Z[√−5]. Prove that the elements
f1 = 2 + 2√−5 and f2 = 6 do not have a greatest common divisor in the
sense of Proposition 1.2.7.a.
Hint: Show that both 2 and 1 + √−5 are common divisors.
Exercise 8.
Let R be a factorial domain and a, b ∈R \ {0} two co-
prime elements. Prove that the polynomial ax+b is an irreducible element
of R[x].
Exercise 9. Let K be a ﬁeld, P = K[x1, x2, x3, x4], and p be the
principal ideal generated by f = x1x4 −x2x3 .
a) Show that the polynomial f is irreducible in P . Deduce that P/p is
an integral domain.
b) Prove that the residue class of x1 modulo p is irreducible in P/p, but
not prime. Use this to infer that P/p is not factorial.
Exercise 10. Let K be a ﬁeld and K(x) the ﬁeld of fractions of K[x].
We consider the ring R = K[x1, x2]/(x1x2 −1).
a) Show that R is isomorphic to a K -subalgebra of K(x) which contains
K[x]. (Hint: Try to map x1 to x and x2 to
1
x . To show that only
multiples of x1x2−1 are in the kernel of this map, write polynomials in
K[x1, x2] as P
i>0 xi
1 ·fi(x1x2)+P
i>0 xi
2 ·gi(x1x2)+c where c ∈K .)
b) Using a), we may assume K[x] ⊂R ⊂K(x). In this situation, show
that x is a unit in R and every element g ∈R can be written as
g = xr · f where r ∈Z and f ∈K[x].
c) Prove that R is a factorial domain. (Hint: Use the representation given
in b) to show that every irreducible element is prime.)
Exercise 11. For a univariate polynomial f , we denote its derivative
by f ′ . Let K be a ﬁeld such that char(K) ̸= 2, 3.
a) Let f(x) = x(x −a)(x −b) and assume that 2 and a2 + b2 + (a −b)2
are squares in K . Then prove that f ′(x) splits as the product of two
linear factors.
b) If 3 is a square in K , observe that f = x3 −3ax2 −3b2x + 9ab2 is a
product of three linear factors.
c) Use a) and b) to prove that the following conditions are equivalent.
1) For all a, b ∈K , there is an element c ∈K such that a2+b2 = c2 .
2) For every monic polynomial f ∈K[x] of degree 3 which is a
product of three linear factors, f ′ is a product of two linear fac-
tors.

36
1. Foundations
Tutorial 4: Euclidean Domains
In general, it is diﬃcult to decide whether a given ring is factorial, and con-
sequently there exists only a rather limited supply of examples of factorial
domains. The purpose of this tutorial is to provide the reader with a tool for
constructing or detecting a special kind of non-trivial factorial domains.
We say that (R, ϕ) (or simply R) is a Euclidean domain if R is a
domain and ϕ is a function ϕ : R \ {0} →N such that for all a, b ∈R \ {0}
the following properties hold.
1) If a | b then ϕ(a) ≤ϕ(b).
2) There exist elements q, r ∈R such that a = qb + r and either r = 0 or
ϕ(r) < ϕ(b).
First of all, prove that in a Euclidean domain R the following additional
rule holds.
3) Let a, b ∈R \ {0}. If b = ac for some non-unit c ∈R, then ϕ(a) < ϕ(b).
Hint: Use 2) and write a = qb + r. Show that r ̸= 0, hence ϕ(r) < ϕ(b).
Deduce (1 −qc)a = r, hence ϕ(a) ≤ϕ(r).
Some rings, which should be familiar to the reader, are in fact Euclidean
domains.
a) Show that the ring of integers Z, together with the absolute value func-
tion, is a Euclidean domain.
b) Check that every univariate polynomial ring K[x] over a ﬁeld K , to-
gether with the degree function, is a Euclidean domain.
In the following, we let R be a Euclidean domain.
c) Show that if m = min{ϕ(a) | a ∈R\{0}}, then {a ∈R\{0} | ϕ(a) = m}
is the set of units of R.
d) Use 1), and an argument similar to that given in Lemma 1.2.11, to prove
that every non-unit in R \ {0} has a factorization.
e) Use 2) to show that in R there is a notion of gcd(a, b) for a, b ∈R \ {0}
in the sense of Proposition 1.2.7.a, and that gcd(a, b) can be expressed
as ra + sb with r, s ∈R.
f) Use e) to prove that in R every irreducible element is prime. Conclude
that R is factorial.
Hint: Let p be irreducible and ab = cp. If p does not divide a, then
gcd(a, p) = 1. Hence 1 = ra + sp, and therefore b = · · ·.
g) Consider the subring Z[i] = {a + bi | a, b ∈Z} of C. It is called the ring
of Gaußian numbers.
1) Let ϕ : Z[i]\{0} −→N be deﬁned by ϕ(a+bi) = a2 +b2 . Show that
ϕ makes Z[i] into a Euclidean domain.
Hint: Let z1 = a + bi, z2 = c + di and z = z1
z2 = (a+bi)(c−di)
c2+d2
∈Q[i].
Choose for q ∈Z[i] a “good” approximation of z and write z1 =
qz2 + r.
2) Find the set of units of Z[i].

1.2 Unique Factorization
37
3) Let p ∈N be a prime number. Show that p is reducible in Z[i] if
and only if there exist a, b ∈N such that p = a2 + b2 .
Hint: Prove that the map ϕ is compatible with multiplication.
4) Show that if z ∈Z[i] is such that ϕ(z) is a prime number in Z, then
z is prime in Z[i].
5) Representing elements of Z[i] as pairs of integers, implement two
CoCoA functions GaussGCD(. . .) and GaussLCM(. . .) which compute
the greatest common divisor and least common multiple of two
Gaußian integers, respectively.
6) Using CoCoA, program a factorization algorithm GaussFactor(. . .)
for elements z ∈Z[i].
Hint: Proceed as for integers, searching for divisors in the set of all
elements a + bi such that a2 + b2 divides ϕ(z).
Tutorial 5: Squarefree Parts of Polynomials
In this tutorial we shall explore how one can eﬀectively compute the square-
free part of a univariate polynomial over certain ﬁelds. It will turn out that
this seemingly innocent problem is in fact intrinsically related to the structure
of the base ﬁeld K .
a) Let K be a ﬁeld of characteristic p > 0, and let ϕ : K →K be the map
deﬁned by ϕ(a) = ap . The map ϕ is called the Frobenius map.
1) Show that the map ϕ is a ring homomorphism.
2) Show that ϕ is bijective if K is ﬁnite.
3) Deduce that if K is ﬁnite then every element has a unique pth root.
If a ﬁeld K has characteristic 0 or has characteristic p > 0 and, in
addition, has the property that every element has a pth root, then K is called
a perfect ﬁeld. In the sequel, we let K be a perfect ﬁeld and f ∈K[x] a
non-zero polynomial. We use the convention gcd(f, 0) = f and denote the
derivative of f by f ′ .
b) Let char(K) = p > 0. Show that f ′ = 0 holds if and only if f is of the
form f = gp for some g ∈K[x].
c) Suppose that K = Fq , where q = pe and e > 0, is a ﬁnite ﬁeld of
characteristic p > 0 (see Tutorial 3), and let f ∈K[x] be a polynomial
such that f ′ = 0. Explain how one can compute a polynomial g ∈K[x]
such that gp = f .
Hint: Show that every term in the support of f is of the form xαp and
prove (cpe−1)p = c for all c ∈K .
d) Write a CoCoA function PRoot(. . .) which takes a polynomial f ∈Fp[x]
such that f ′ = 0 and computes a polynomial g ∈Fp[x] such that f = gp .
e) Show that if f is irreducible, then we have gcd(f, f ′) = 1.
Hint: Distinguish the cases char(K) = 0 and char(K) = p > 0.

38
1. Foundations
f) Let g ∈K[x] be a polynomial such that gcd(f, g) = 1. Prove the formula
gcd(fg, (fg)′) = gcd(f, f ′) gcd(g, g′).
g) Let char(K) = 0 and f = c Qs
i=1 pαi
i
be the factorization of f into
distinct irreducible factors, where c ∈K \ {0}. Show that gcd(f, f ′) =
Qs
i=1 pαi−1
i
and deduce that sqfree(f) can be computed by using the
formula
sqfree(f) = f/ gcd(f, f ′)
h) Find an example which shows that g) is false if char(K) = p > 0.
i) Now let K be a ﬁnite ﬁeld of characteristic p > 0. In Proposition 3.7.12
we shall prove that sqfree(f) can be computed using the following algo-
rithm.
1) Compute s1 = gcd(f, f ′). If s1 = 1, then return f .
2) Check whether we have s′
1 = 0. In this case, use b) to conclude that
s1 = gp for some polynomial g ∈K[x]. Compute g using PRoot(. . .).
Then replace f by fg
s1 =
f
gp−1 , and continue with step 1).
3) Compute si+1 = gcd(si, s′
i) for i = 1, 2, . . . until s′
i+1 = 0, i.e. until
si+1 is a pth power si+1 = gp for some g ∈K[x]. Then calculate g
again, replace f by fg
s1 , and continue with step 1).
Write a CoCoA function SqFree(. . .) which checks whether the base ﬁeld
is Q or Fp and computes the squarefree part of a given univariate poly-
nomial.
Tutorial 6: Berlekamp’s Algorithm
In the case of a ﬁnite ﬁeld K , we shall explore a concrete algorithm which
factors polynomials in K[x]. So, let p be a prime number, let e be a positive
integer, let q = pe, and let K be the ﬁeld with q elements (see Tutorial 3).
(If you are unfamiliar with ﬁnite ﬁelds, it is enough to concentrate on the
case q = p, K = Z/(p).)
Our goal is to compute the factorization of a non-constant monic polyno-
mial f ∈K[x] of degree d = deg(f).
a) Prove that the ring R = K[x]/(f) is a d-dimensional K -vector space
with basis {1, ¯x, ¯x2, . . . , ¯xd−1}, where ¯x is the residue class of x in R.
In what follows, let Q = (qij) be the d × d-matrix over K whose ith
row consists of the coordinates of ¯xq(i−1) in the basis {1, ¯x, . . . , ¯xd−1} of R.
Furthermore, we let ¯g = γ0 + · · · + γd−1¯xd−1 with γ0, . . . , γd−1 ∈K be the
representation of the residue class of a polynomial g ∈K[x] in this basis.
b) Show that ¯gq = (γ0, . . . , γd−1)·Q·(1, ¯x, . . . , ¯xd−1)tr . Conclude that there
is a 1-1 correspondence between elements ¯g ∈R such that ¯gq −¯g = 0
and vectors (γ0, . . . , γd−1) ∈Kd such that (γ0, . . . , γd−1) · (Q −Id) = 0,
where Id denotes the d × d identity matrix.

1.2 Unique Factorization
39
c) For any polynomial g ∈K[x] satisfying ¯gq −¯g = 0 in R, prove that we
have f = Q
κ∈K gcd(f, g −κ). (Hint: Find the factorization of xq −x
and substitute g for x.)
d) Let f = Qr
i=1 pαi
i
be the factorization of f , where αi > 0 for i = 1, . . . , r
and p1, . . . , pr are the diﬀerent irreducible monic factors of f . Prove
the following special case of the Chinese Remainder Theorem. The
canonical map
ε : R −→K[x]/(pα1
1 ) × · · · × K[x]/(pαr
r )
is an isomorphism of K[x]-algebras. (Hint: To show surjectivity, let
g1, . . . , gr ∈K[x], use hi = Q
j̸=i pαj
j , get an equation Pr
i=1 aihi = 1,
and consider ε(Pr
i=1 giaihi).)
Deduce that ε induces an isomorphism of K -vector spaces
ϕ : {¯g ∈R | ¯gq −¯g = 0} −→Kr
e) Conclude from d) that the number of distinct irreducible factors of f is
given by r = dimK(ker(Q −Id)). Write a CoCoA function IsIrred(. . .)
which checks whether a given polynomial f ∈K[x] is irreducible.
Hint: You may use the CoCoA function Syz(. . .) to compute the kernel
of a linear map.
f) Consider the following sequence of instructions.
1) Compute the matrix Q and the number r deﬁned above.
Let {(vi1, . . . , vid) | 1 ≤i ≤r} be a K -basis of ker(Q −Id) and
gi = vi1 + vi2x + · · · + vidxd−1 ∈K[x] for 1 ≤i ≤r. W.l.o.g. we can
assume that gr = 1 and deg(gi) > 0 for 1 ≤i < r.
2) For all κ ∈K , compute gcd(f, g1 −κ) and obtain a representation
f = Q
κ∈K gcd(f, g1 −κ). If this representation contains r diﬀerent
non-constant factors, return it as the result.
3) For i = 1, 2, . . ., let f = fi 1 · · · fi µi be the representation of f com-
puted so far. For every κ ∈K and every j ∈{1, . . . , µi}, compute
gcd(fi j, gi+1 −κ). Then check, if the representation
f =
µi
Q
j=1
Q
κ∈K
gcd(fi j, gi+1 −κ)
consists of r diﬀerent non-constant factors. If not, increase i by one
and repeat step 3), until it does. Then return this representation as
the result.
Show that this is an algorithm which stops for some i ≤r −1 and that
it returns a representation of f as the product of powers of distinct irre-
ducible monic polynomials. It is called Berlekamp’s Algorithm. If we
combine it with the algorithm for computing squarefree parts of polyno-
mials in K[x] described in Tutorial 5, we have a complete factorization
algorithm for univariate polynomials over ﬁnite ﬁelds.

40
1. Foundations
Hint: To show ﬁniteness, use that the determinant of the matrix Φ of the
map ϕ above is non-zero, and that the number of non-constant diﬀerent
factors in fi1 · · · fiµi is equal to the number of diﬀerent entries in the ith
column of Φ.
g) Implement Berlekamp’s Algorithm for K = Z/(p). Then apply your
function Berlekamp(. . .) and check it against the built-in routines of
CoCoA in the following cases.
1) f1 = x100 −x200 ∈Z/(5)[x]
2) f2 = 1 + x + x2 + x6 + x7 + x8 + x12 ∈Z/(2)[x]
3) f3 = 1 −x100 ∈Z/(7)[x]
4) f4 = 8 + 2x + 8x2 + 10x3 + 10x4 + x6 + x8 ∈Z/(13)[x]
5) f5 = 2 + x + x2 + x3 + x4 + x5 ∈Z/(31991)[x]

1.3 Monomial Ideals and Monomial Modules
41
1.3 Monomial Ideals and Monomial Modules
Mathematics is a game
played according to certain simple rules
with meaningless marks on paper.
(David Hilbert)
Let us start with a little game. Consider the monoid T1 = {1, x, x2, x3, . . .}.
Pick one element in T1 , call it s1 , and delete it from T1 . Then pick another
element in T1\{s1}, call it s2 , and delete it from T1\{s1}. If s2 is not di-
visible by s1 you say that s2 is a winner. Keep going on and construct a
sequence {sn} of distinct elements of T1 and declare that sn is a winner if it
is not divisible by any of the preceding ones. It is immediately clear that, after
the ﬁrst choice has been made, only a ﬁnite number of potential winners are
left. Therefore in your sequence from a certain point on all the elements are
losers, i.e. multiples of some preceding element. In this case the explanation
is easy, but a more important question arises: is a similar conclusion valid if
you start with Tn instead?
One of the main purposes of this section is to answer that question, and
the answer is Dickson’s Lemma. Put in another way, we show that monomial
ideals are ﬁnitely generated. The importance of this result will become more
evident later, but of course it is already clear that statements about “ﬁnite-
ness” are crucial for actual computations. Towards the end of this section we
also prove a powerful structure theorem for monomial modules.
Now we begin with the deﬁnition of two algebraic structures which help us
translate our game into a solid mathematical result. We recall that a monoid
is a set together with an associative operation on it such that there exists
an identity. Since in all the cases considered in this book the operation will
be commutative, we shall from now on use the term “monoid” to denote a
commutative monoid.
Deﬁnition 1.3.1. Let (Γ, ◦) be a monoid.
a) A non-empty subset ∆⊆Γ is called a monoideal (pronounced “mono-
ideal”) in Γ (or a monoid ideal in Γ ) if we have ∆◦Γ ⊆∆.
b) A subset B of a monoideal ∆in Γ is called a system of generators of
∆(or ∆is said to be generated by B) if ∆is the smallest monoideal
in Γ containing B. In this case we have ∆= {β ◦γ | β ∈B, γ ∈Γ}. If
B = {β1, β2, . . .}, we will also use the notation ∆= (β1, β2, . . .).
c) A set Σ together with an operation ∗: Γ ×Σ →Σ given by (γ, s) 7→γ∗s
is called a Γ -monomodule (or a monoid module over Γ ) if for all
s ∈Σ and all γ1, γ2 ∈Γ we have
1) 1Γ ∗s = s,
2) (γ1 ◦γ2) ∗s = γ1 ∗(γ2 ∗s).
d) A non-empty subset Σ′ ⊆Σ is called a Γ -submonomodule of Σ if
Γ ∗Σ′ ⊆Σ′ .

42
1. Foundations
e) A subset B of a Γ -monomodule Σ is called a system of generators
of Σ if Σ = {γ ∗s | γ ∈Γ, s ∈B}.
Later the symbols ◦and ∗will sometimes be omitted. Obviously, a
monoideal in Γ is also a Γ -monomodule. In fact, it is a Γ -submonomodule
of the Γ -monomodule Γ , just like for regular ideals and modules. The most
important example of a monomodule for our purposes is the set of terms
Tn⟨e1, . . . , er⟩of a free module R[x1, . . . , xn]r over some polynomial ring. It
is a Tn-monomodule generated by {e1, . . . , er}. Some monomodules require
inﬁnite systems of generators, as our next example shows.
Example 1.3.2. The set Q≥0 of non-negative rational numbers with the
usual sum is a monoid. Then Q>0 , the set of positive rational numbers, is a
monoideal in Q≥0 which is generated by { 1
n | n ≥1}. It is easy to see that
this monoideal is not ﬁnitely generated.
Now let I = R\Q be the set of irrational numbers. Adding an element of
Q≥0 to an element of I yields an element of I. Since conditions 1) and 2)
of Deﬁnition 1.3.1.c are satisﬁed, we have here an example of a Q≥0 -mono-
module. Again one can show that this monomodule is not ﬁnitely generated.
Deﬁnition 1.3.3. Let (Γ, ◦) be a monoid and (Σ, ∗) a Γ -monomodule.
a) We say that the cancellation law holds in Γ , if γ1 ◦γ3 = γ2 ◦γ3 implies
γ1 = γ2 for all γ1, γ2, γ3 ∈Γ .
b) We say that the left-cancellation law holds in Σ , if γ ∗s1 = γ ∗s2
implies s1 = s2 for all γ ∈Γ , s1, s2 ∈Σ .
c) We say that the right-cancellation law holds in Σ , if γ1 ∗s = γ2 ∗s
implies γ1 = γ2 for all γ1, γ2 ∈Γ , s ∈Σ .
If we consider a monoid Γ as a Γ -monomodule in the obvious way, con-
ditions b) and c) both agree with a) so that there is only one cancellation law
in Γ . In Example 1.3.2, the cancellation law holds in Q≥0 , and both the left-
cancellation law and the right-cancellation law hold in the monomodule I.
Furthermore, for every n ≥1, the cancellation law holds in the monoid of
terms Tn introduced in Deﬁnition 1.1.10, and, for every r ≥1, both the left-
cancellation law and the right-cancellation law hold in the Tn -monomodule
Tn⟨e1, . . . , er⟩. The following concept provides an important ﬁniteness con-
dition for monoids.
Proposition 1.3.4. For a monoid (Γ, ◦) the following conditions are equiv-
alent.
a) Every monoideal in Γ is ﬁnitely generated.
b) Every ascending chain ∆1 ⊆∆2 ⊆· · · of monoideals in Γ is eventually
stationary.
c) Every non-empty set of monoideals in Γ has a maximal element with
respect to inclusion.
If these conditions are satisﬁed, the monoid Γ is called Noetherian.

1.3 Monomial Ideals and Monomial Modules
43
Proof.
First we show a) ⇒b). Suppose we have a chain ∆1 ⊆∆2 ⊆· · · of
monoideals in Γ and a sequence n1 < n2 < · · · such that there exist elements
γi ∈∆ni+1\∆ni for all i ≥1. Then we claim that the monoideal generated by
{γ1, γ2, . . .} is not ﬁnitely generated. It is contained in the union ∪i≥1∆i , but
not in one of the monoideals ∆i . Now assume that it is generated by a ﬁnite
set. Then such a ﬁnite set has to be contained in some ∆i , a contradiction.
Now we prove b) ⇒c). Let S be a non-empty set of monoideals in Γ ,
and let ∆1 ∈S . If ∆1 is not maximal, there exists a monoideal ∆2 ∈S such
that ∆1 ⊂∆2 . Continuing in this way, we obtain a chain ∆1 ⊂∆2 ⊂· · ·
which has to be ﬁnite by b). Then the last element of the chain is a maximal
element of S .
To show the remaining implication c) ⇒a), we let ∆⊆Γ be a monoideal.
The set of all monoideals in Γ which are generated by ﬁnite subsets of ∆
contains a maximal element. By construction, this element has to be ∆itself.
□
Proposition 1.3.5. For n ≥1, the monoid (Nn, +) is Noetherian.
Proof.
We use induction on n. When n = 1, every monoideal is obviously
of the form (a) with a ﬁxed a ∈N. For n > 1, we let ∆1 ⊆∆2 ⊆· · · be an
ascending chain of monoideals in Nn . Suppose there are indices n1 < n2 < · · ·
and elements wi ∈∆ni+1 \ ∆ni for i ≥1. Let v1 = wm1 ∈{w1, w2, . . .}
be a vector whose ﬁrst component is minimal. Then we let v2 = wm2 ∈
{wm1+1, wm1+2, . . .} be a vector whose ﬁrst component is minimal again,
etc. In this way we construct a sequence v1, v2, . . . of vectors of Nn whose
ﬁrst components form a non-decreasing sequence.
For all i ≥1, we let v′
i now be the vector in Nn−1 which consists of
the last n −1 components of vi . By the induction hypothesis, the chain of
monoideals (v′
1) ⊆(v′
1, v′
2) ⊆· · · in Nn−1 becomes eventually stationary.
Then also the chain (v1) ⊆(v1, v2) ⊆· · · of monoideals in Nn becomes even-
tually stationary, since the ﬁrst components of v1, v2, . . . form an increasing
sequence. We arrive at a contradiction to the construction of w1, w2, . . ., since
we had vi = wmi /∈(w1, . . . , wmi−1) ⊇(v1, . . . , vi−1) for all i ≥2.
□
In the remaining part of this section we shall apply the above theory to
the monoid of terms in a polynomial ring. The translation of the previous
proposition provides us with an important ﬁniteness condition for ideals in
polynomial rings.
Corollary 1.3.6. (Dickson’s Lemma)
Let n ≥1, and let t1, t2, . . . be a sequence of terms in Tn . Then there exists
a number N > 0 such that for every i > N the term ti is a multiple of one
of the terms t1, . . . , tN , i.e. the monoideal (t1, t2, . . .) ⊆Tn is generated by
{t1, . . . , tN}.
In particular, for every ring R, the ideal (t1, t2, . . .) ⊆R[x1, . . . , xn] is
ﬁnitely generated.

44
1. Foundations
Proof.
The map log : Tn →Nn given by xα1
1 · · · xαn
n
7→(α1, . . . , αn) is
clearly an isomorphism of monoids. The monoideal (log(t1), log(t2), . . .) ⊆Nn
is ﬁnitely generated by the previous proposition. Thus there exists a number
N > 0 such that this monoideal is generated by {log(t1), . . . , log(tN)}. Con-
sequently, the monoideal (t1, t2, . . .) ⊆Tn is generated by {t1, . . . , tN}.
□
As we shall see, ideals and modules generated by terms have many special
properties. We begin our studies by giving them a special name. Let R be a
ring, let n ≥1, let P = R[x1, . . . , xn] be a polynomial ring, and let r ≥1.
Deﬁnition 1.3.7. A P -submodule M ⊆P r is called a monomial module,
if it has a system of generators consisting of elements of Tn⟨e1, . . . , er⟩. A
monomial submodule of P is also called a monomial ideal of P .
Monomial ideals can be readily visualized, especially when there are just
two or three indeterminates.
Remark 1.3.8. For monomial ideals I ⊆R[x1, x2], we can illustrate the
set of terms in I as follows. A term xi
1xj
2 ∈T2 is represented by the point
(i, j) ∈N2 . Then, for each term xi
1xj
2 ∈I , the quadrant {xk
1xl
2 | k ≥i, l ≥j}
is contained in I . For instance, when I = (x5
1, x3
1x2, x1x2
2, x4
2) we obtain the
following picture.
....................................................... ................
.............................................
................
x1
x2
•
•
•
•
1
x4
2
x1x2
2
x3
1x2
x5
1
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
Dickson’s Lemma can be generalized to monomial modules as follows.
Theorem 1.3.9. (Structure Theorem for Monomial Modules)
Let M ⊆P r be a monomial module.
a) The module M is ﬁnitely generated, i.e. there are ﬁnitely many terms
t1, . . . , ts ∈Tn and numbers γ1, . . . , γs ∈{1, . . . , r} such that we have
M = ⟨t1eγ1, . . . , tseγs⟩.
b) There are monomial ideals I1, . . . , Ir ⊆P such that M is of the form
M ∼= ⊕r
i=1Iiei .

1.3 Monomial Ideals and Monomial Modules
45
Proof.
Let B ⊆Tn⟨e1, . . . , er⟩be a system of generators of M . For every
number i ∈{1, . . . , r} we deﬁne the set Bi = {t ∈Tn | tei ∈B} ⊆Tn .
By Dickson’s Lemma, the monomial ideals Ii = (Bi) have ﬁnite systems
of generators Gi ⊆Bi . Obviously the P -module M is then generated by
G1e1 ∪· · · ∪Grer ⊆Tn⟨e1, . . . , er⟩. This proves a) and the claim M =
Pr
i=1 Iiei in b). The fact that this sum is direct follows from M ⊆⊕r
i=1Pei .
□
The ﬁrst part of this theorem says in particular that the analogue of
Proposition 1.3.4.a holds for monomial modules. Let us note that this implies
that also the analogue of Proposition 1.3.4.b is true.
Corollary 1.3.10. Every ascending chain of monomial submodules of P r is
eventually stationary.
Proof.
Suppose there exists a strictly ascending chain M1 ⊂M2 ⊂· · · of
monomial submodules of P r . Since each module is generated by terms, we
can then ﬁnd a term ti ∈Mi \ Mi−1 for every i ≥2. For all i ≥1 we
have ⟨t1, . . . , ti⟩⊆Mi , and therefore ti+1 /∈⟨t1, . . . , ti⟩. Thus the monomial
submodule ⟨t1, t2, . . .⟩of P r is not ﬁnitely generated, in contradiction to the
theorem.
□
Finally, we address the question of uniqueness for systems of generators
of monomial modules.
Proposition 1.3.11. Let M ⊆P r be a monomial submodule.
a) For every system of generators G = {t1, . . . , ts} of M consisting of
terms, and for every term t ∈M , there exists a term ti ∈G such
that t is a multiple of ti .
b) In the set of all systems of generators of M which consist entirely of
terms there is a unique minimal element with respect to inclusion. We
call it the minimal monomial system of generators of M .
Proof.
The ﬁrst claim follows from the fact that if we write t = Ps
i=1 fiti
with polynomials f1, . . . , fs ∈P , then the term t must show up in the
support of one of the elements f1t1, . . . , fsts.
To show b), we prove existence ﬁrst. By Theorem 1.3.9.a, there exists a
ﬁnite system of generators of M consisting of terms. If we delete in this set
all terms which are proper multiples of another element of that set, and if we
also remove all repetitions of an element, we obtain a system of generators
of M which cannot be shortened anymore.
To prove uniqueness, we suppose that there are two diﬀerent minimal
monomial systems of generators G1 and G2 of M . By symmetry, we may
assume that there is a term t ∈G1 \ G2 . From a) we conclude that t is a
multiple of an element t′ ∈G2 . Using a) again, we see that t′ , and therefore t,
is a multiple of one of the elements of G1 . Since G1 is minimal, that element is
necessarily t itself, i.e. t and t′ are multiples of each other. Thus t = t′ ∈G2 ,
a contradiction.
□

46
1. Foundations
Exercise 1.
Let Γ be a commutative group. Show that in it there is
only one monoideal, namely Γ itself.
Exercise 2. Equip the set Γ = {0, ∞} with the “natural” addition and
show that (Γ, +) is a commutative monoid in which the cancellation law
does not hold.
Exercise 3. We consider the additive monoid Q≥0 (see Example 1.3.2).
We let a be a non-negative real number and Q≥a = {b ∈Q≥0 | b ≥a}.
a) Prove that if a ∈Q, then Q≥a is a principal monoideal, i.e. a
monoideal generated by a single element.
b) Prove that if a /∈Q, then Q≥a is a monoideal which is not ﬁnitely
generated.
c) If a /∈Q, ﬁnd an inﬁnite increasing sequence of monoideals in Q>0
whose union is Q≥a .
d) Prove that the monomodule I = R \ Q is not ﬁnitely generated.
Exercise 4. Let us use the notation of Example 1.3.2 again.
a) Show that Q>0 with the usual multiplication is a monoid.
b) Show that this monoid has no non-trivial monoideal.
c) Show that I = R \ Q is a Q>0 -monomodule.
Exercise 5. Let (Γ, ◦) be a Noetherian monoid in which the cancellation
law holds. Assuming that the only unit is 1Γ , prove that every monoideal
∆has a unique minimal (i.e. shortest) set of generators.
Exercise 6. Let (Γ, ◦) be a monoid, ∆a ﬁnitely generated monoideal
in Γ , and let B be a system of generators of ∆. Prove that ∆can be
generated by a ﬁnite subset of B.
Exercise 7.
Let n ≥1 and r ≥1. Show that the set of terms
Tn⟨e1, . . . , er⟩is a monomodule over Tn .
Exercise 8. Let B ⊂Tn be such that no element in B is divisible by
another element in B . Prove that B is ﬁnite.
Exercise 9.
Let (Γ, ◦) be a monoid, and let Σ be a Γ -monomodule.
We say that Σ is a Noetherian Γ -monomodule if every ascending chain
of Γ -submonomodules Σ1 ⊆Σ2 ⊆· · · of Σ is eventually stationary.
a) For submonomodules of Σ , formulate and prove an analogue of Propo-
sition 1.3.4.
b) Let Γ be a Noetherian monoid, and let Σ be a ﬁnitely generated
Γ -monomodule. Then show that Σ is Noetherian.
c) Conclude that the Tn -monomodule Tn⟨e1, . . . , er⟩is Noetherian.

1.3 Monomial Ideals and Monomial Modules
47
Tutorial 7: Cogenerators
Let (Γ, ◦) be a monoid, let ∆be a monoideal in Γ , let Λ = Γ\∆be the
complement of ∆in Γ , and let C ⊆Λ. We say that C cogenerates ∆if
Λ = {γ ∈Γ | γ ◦γ′ ∈C for some γ′ ∈Γ}.
............................... ................
..............................
................
x1
x2
•
•
•
1
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
a) Show that the complement Λ of a monoideal in a monoid is characterized
by the following property: if γ ∈Λ and γ′ | γ , then γ′ ∈Λ.
b) Let ∆(I) be the monoideal in T2 consisting of the terms in the ideal
I = (x5
1, x3
1x2, x1x2
2, x4
2) introduced in Remark 1.3.8. Show that ∆(I) is
ﬁnitely cogenerated and ﬁnd a minimal set of cogenerators.
c) Now let J = (x5
1, x3
1x2, x1x2
2), and let ∆(J) be the associated monoideal
in T2 . Find a set of cogenerators and show that J is not ﬁnitely cogen-
erated.
d) Characterize the ﬁnitely cogenerated monoideals in T2 . Show that they
have a unique minimal set of cogenerators.
e) Let m(∆) be the cardinality of a minimal set of generators and c(∆)
the cardinality of a minimal set of cogenerators of a ﬁnitely cogenerated
monoideal ∆⊆T2 . Prove that c(∆) = m(∆) −1.
f) Characterize monoideals in T2 cogenerated by a single element. Given
such a monoideal ∆⊆T2 and its cogenerator λ ∈Λ, prove that we have
∆= {t ∈T2 | x1 · t ∈∆, x2 · t ∈∆} \ {λ}.
g) Write a CoCoA function MinCogens(. . .) which, given a ﬁnite list of terms,
checks if the monoideal generated by them is ﬁnitely cogenerated and in
that case computes the minimal set of cogenerators.

48
1. Foundations
Tutorial 8: Basic Operations with Monomial Ideals and Modules
Let K be a ﬁeld, let n ≥1, let P = K[x1, . . . , xn], and let r ≥1.
a) Show that a P -submodule M ⊆P r is a monomial module if and only if
for every m ∈M and every t ∈Supp(m) we have t ∈M .
b) Write a CoCoA function Is Monomial(. . .) which, for a list of vectors
generating a P -submodule M ⊆P r , checks if M is monomial and which
returns TRUE or FALSE. (Hint: You may use the CoCoA operator IsIn.)
c) Implement a CoCoA function MonComps(. . .) which, for a list of terms
generating a monomial P -submodule M ⊆P r , computes the list of
monomial ideals I1, . . . , Ir such that M = I1e1 ⊕· · · ⊕Irer as in Propo-
sition 1.3.9.b.
d) Write a CoCoA program MinMonomials(. . .) which takes a list of terms
generating a monomial P -submodule of P r and computes the minimal
monomial system of generators of that module. (Hint: Do the case of a
monomial ideal ﬁrst. Then apply the preceding program.)
In the sequel, we let I ⊆P be a monomial ideal and M ⊆P r as well
as N ⊆P r monomial submodules, all given by lists of terms which generate
them.
e) Prove that M + N and I · M are monomial submodules of P r . Write
CoCoA functions MonSum(. . .) and MonProd(. . .) which compute those
modules.
f) Show that M ∩N is a monomial submodule of P r by giving an ex-
plicit monomial system of generators. Then implement a CoCoA function
MonIntersection(. . .) which computes this intersection. (Hint: Do the
case r = 1 ﬁrst. Then try to generalize your result.)
g) Prove that M : N = {f ∈P | f · N ⊆M} is a monomial ideal by
giving an explicit monomial system of generators. Write a CoCoA function
MonColon(. . .) which computes this colon ideal.
h) Let 1 ≤m < n. Show that M ∩K[x1, . . . , xm]r is a monomial
K[x1, . . . , xm]-submodule of K[x1, . . . , xm]r by exhibiting an explicit
monomial system of generators. Write a CoCoA function MonElim(. . .)
which computes this elimination module.
i) Show that
√
I = {f ∈P | f i ∈I for some i ∈N} is the monomial ideal
generated by the squarefree parts of the generators of I . Write a CoCoA
function MonRadical(. . .) which computes this radical ideal.
Hint: The hint given here anticipates some themes explained later, start-
ing with the next section. Given two terms t1, t2 , we let t1 > t2 if the
ﬁrst non-zero component of log(t1) −log(t2) is positive. Show that, for
f ∈P \ {0} and i ∈N, the largest term in Supp(f i) is the ith power
of the largest term in Supp(f). Now use a) and induction on the size of
Supp(f) to prove that f i ∈I implies sqfree(t) ∈
√
I for all t ∈Supp(f).

1.4 Term Orderings
49
1.4 Term Orderings
Dura Lex, sed Lex.
(Ancient Latin Proverb)
Let us for a moment go back to Section 1.1 where we discussed the notion
of polynomial rings in one and several indeterminates. A univariate polyno-
mial with coeﬃcients in a ring R is an expression of the type f(x) = P rixi .
One question is: in how many diﬀerent ways can we write f(x)? We might
agree that the coeﬃcients should be written before the corresponding power
product and also decide to be “nice” and avoid the + sign before the ﬁrst co-
eﬃcient, but still we have to face the commutative property of the sum, which
implies that for instance 1 + 2x −3x2 can also be written as 1 −3x2 + 2x.
This may not be a relevant question for “pure” mathematicians, but it is fun-
damental if you wish to implement polynomials and use them in a computer
program.
Clearly, what really matters is the order in which the terms 1, x, x2 ,
i.e. the elements in Supp(f), are written. Using the recursive deﬁnition of
multivariate polynomials, we see that the way of writing them depends on how
we write the univariate ones. And to do it, we see the necessity of knowing
how to order T1 . Look again at f(x) = 1 + 2x −3x2 , whose support is
{1, x, x2}. There are six ways of ordering three elements, which then yield
six representations of f , namely 1 + 2x −3x2 , 1 −3x2 + 2x, 2x + 1 −3x2 ,
2x −3x2 + 1, −3x2 + 1 + 2x, and −3x2 + 2x + 1. However, we believe that
you are going to “keep” only 1 + 2x −3x2 and −3x2 + 2x + 1.
Apart from aesthetic reasons, there is a technical one which validates
this choice. Namely, suppose that you choose the rule “order by increasing
degree”, which yields the representation 1+2x−3x2 , and suppose you want to
multiply f(x) by x3 , say. After termwise multiplication, the rule continues to
hold and you do not have to reorder the result. This leads to an extra property
that your ordering of terms should have, the property of being compatible
with multiplication. Put in a more technical setting, you should require that
the total ordering on T1 makes it into an ordered monoid. Then you see that
the speciﬁcation 1 < x implies x < x2 < x3 and so on, and ﬁnally you
see that only two possible orderings are left, the one described by 1 < x
and the one described by x < 1. This is the end of the story for univariate
polynomials and also for multivariate ones, if a recursive representation is
used.
But we have already seen that other properties of polynomials allow us
to get rid of the parentheses and express them as sums of coeﬃcients times
elements in Tn . So the question now is how to order Tn . For the same reasons
as before we need compatibility with its monoid structure. Let f(x1, x2, x3) =
x1x3 + x2
2 ; should we write it as x1x3 + x2
2 or rather as x2
2 + x1x3 ? There is
no obvious answer to this question, and the purpose of this section is to shed
some light on it.

50
1. Foundations
In particular, we shall study total orderings on Tn and on Tn⟨e1, . . . , er⟩.
If they have a certain additional property, they are called term orderings.
This “fundamental property of module term orderings” is the key to showing
ﬁniteness for most algorithms we shall encounter later.
An attempt to classify all possible term orderings on Tn, at least in
some easy cases, is made in Tutorial 10. Although we avoid treating the
general classiﬁcation of term orderings, we do show that some orderings can
be deﬁned by matrices via scalar products (see Proposition 1.4.12), and that
all the most important monoid orderings are of that type.
In the following, let (Γ, ◦) be a monoid. Recall that for us this always
means that Γ is commutative.
Deﬁnition 1.4.1. A relation σ on Γ is a subset of Γ ×Γ . If a pair (γ1, γ2)
is in that subset, we shall write γ1 ≥σ γ2 . A relation σ on Γ is called
complete if any two elements γ1, γ2 ∈Γ are comparable, i.e. if we have
γ1 ≥σ γ2 or γ2 ≥σ γ1 .
A complete relation σ on Γ is called a monoid ordering if the following
conditions are satisﬁed for all γ1, γ2, γ3 ∈Γ .
a) γ1 ≥σ γ1
(reﬂexivity)
b) γ1 ≥σ γ2 and γ2 ≥σ γ1 imply γ1 = γ2
(antisymmetry)
c) γ1 ≥σ γ2 and γ2 ≥σ γ3 imply γ1 ≥σ γ3
(transitivity)
d) γ1 ≥σ γ2 implies γ1 ◦γ3 ≥σ γ2 ◦γ3
If, in addition, we have
e) γ ≥σ 1Γ for all γ ∈Γ
then σ is called a term ordering on Γ .
If σ is a relation on Γ , and if γ1, γ2 ∈Γ are such that γ1 ≥σ γ2 , we also
write γ2 ≤σ γ1 . Furthermore, if additionally γ1 ̸= γ2 , we write γ1 >σ γ2
or γ2 <σ γ1 . If the cancellation law holds in Γ , condition 1.4.1.d can be
reversed as follows.
Remark 1.4.2. Let σ be a monoid ordering on Γ .
a) Suppose that the cancellation law holds in Γ , and let γ1, γ2, γ3 ∈Γ . Then
an inequality γ1 ◦γ3 ≥σ γ2 ◦γ3 implies γ1 ≥σ γ2 . This follows from the
observation that γ2 >σ γ1 implies γ2◦γ3 ≥σ γ1◦γ3 by Deﬁnition 1.4.1.d,
and equality is excluded by the cancellation law.
b) If Γ ̸= {1Γ } and the cancellation law holds in Γ , then Γ is inﬁnite.
Namely, let γ ̸= 1Γ be an element of Γ . Now let us consider the set
S = {γi | i ∈N}. We have either 1Γ >σ γ or γ >σ 1Γ . In the ﬁrst case
1Γ >σ γ >σ γ2 >σ · · · shows that S is inﬁnite. In the second case we
argue analogously.
c) By induction we can show that, for any γ ∈Γ and any n > 0, the
condition γ ≥σ 1Γ is equivalent to γn ≥σ 1Γ .

1.4 Term Orderings
51
Under the isomorphism of monoids log : Tn →Nn , monoid orderings
(resp. term orderings) on Tn correspond 1-1 to monoid orderings (resp. term
orderings) on Nn . Now we introduce some of the most important term or-
derings on Tn.
Deﬁnition 1.4.3. For t1, t2 ∈Tn we say t1 ≥Lex t2 if and only if the ﬁrst
non-zero component of log(t1) −log(t2) is positive or t1 = t2 . It is easy
to check that this deﬁnes a term ordering on Tn — it is called the lexico-
graphic term ordering and is denoted by Lex.
Example 1.4.4. Using Lex, the indeterminates are ordered decreasingly,
i.e. by x1 >Lex x2 >Lex · · · >Lex xn . For instance, when n = 3, we have
x1x2
2 >Lex x3
2x4
3 , since (1, 2, 0) −(0, 3, 4) = (1, −1, −4) has a positive ﬁrst
component. Similarly, we have x3
1x2
2x4
3 >Lex x3
1x2
2x3 , since the ﬁrst non-zero
component of (3, 2, 4)−(3, 2, 1) = (0, 0, 3) is positive. Also x1x3 >Lex x2
2 , and
we see how to use Lex to order the polynomial mentioned at the beginning
of the section.
For n = 26, if one replaces x26 by A, x25 by B, etc., and one decides to
write “smallest ﬁrst”, then the lexicographic ordering on the terms becomes
similar to the usual ordering on words in a dictionary. We say similar and not
equal because there is a fundamental diﬀerence between our words and the
words in a dictionary. Our words (or terms) are commutative, so in our lexicon
the two words ape and pea are the same. Although this book is entirely about
commutative things, we must admit that non-commutative dictionaries have
certain advantages.
Deﬁnition 1.4.5. For two terms t1, t2 ∈Tn we say t1 ≥DegLex t2 if we have
deg(t1) > deg(t2), or if we have deg(t1) = deg(t2) and t1 ≥Lex t2 . It is easy
to check that this, too, deﬁnes a term ordering on Tn — it is called the
degree-lexicographic term ordering and is denoted by DegLex.
Example 1.4.6. Using DegLex, we see that x1 >DegLex · · · >DegLex xn holds
again. For instance, when n = 3, we have x1x2
2x3
3 >DegLex x2
1x2
2 , since
deg(x1x2
2x3
3) = 6 > 4 = deg(x2
1x2
2), and we have x2
1x2
2x2
3 >DegLex x1x2
2x3
3 ,
since deg(x2
1x2
2x2
3) = 6 = deg(x1x2
2x3
3) and (2, 2, 2)−(1, 2, 3) = (1, 0, −1) has
a positive ﬁrst component.
Deﬁnition 1.4.7. For t1, t2 ∈Tn we say t1 ≥DegRevLex t2 if we have
deg(t1) > deg(t2), or if we have deg(t1) = deg(t2) and the last non-zero
component of log(t1) −log(t2) is negative, or if t1 = t2 . It is easy to check
that this deﬁnes a term ordering on Tn — it is called the degree-reverse-
lexicographic term ordering and is denoted by DegRevLex.
Example 1.4.8. Again, using DegRevLex, the indeterminates are ordered
by x1 >DegRevLex · · · >DegRevLex xn. For instance, when n = 3, we have
x4
1x7
2x3 >DegRevLex x4
1x2
2x3
3 , since deg(x4
1x7
2x3) = 12 > 9 = deg(x4
1x2
2x3
3),
and we have x1x5
2x2
3 >DegRevLex x4
1x2x3
3 , since both terms have degree 8 and

52
1. Foundations
(1, 5, 2) −(4, 1, 3) = (−3, 4, −1) has a negative last component. Similarly, we
have x3
1x3
2x2
3 <DegRevLex x4
1x2
2x2
3 , since both terms have degree 8 and the last
non-zero component of (3, 3, 2) −(4, 2, 2) = (−1, 1, 0) is positive.
If we drop the ﬁrst condition in the deﬁnition of DegRevLex, i.e. if we let
t1 ≥RevLex t2 if the last non-zero component of log(t1) −log(t2) is negative
or if t1 = t2 , we obtain a monoid ordering on Tn, called the reverse-
lexicographic ordering, which is not a term ordering (see Exercise 3).
Deﬁnition 1.4.9. A monoid ordering σ on Tn is called degree compati-
ble if t1 ≥σ t2 for t1, t2 ∈Tn implies deg(t1) ≥deg(t2).
For instance, DegLex and DegRevLex are degree compatible term order-
ings.
Deﬁnition 1.4.10. Let 1 ≤j < n, let L = {x1, . . . , xj}, and let t1 =
xα1
1 · · · xαn
n , t2 = xβ1
1 · · · xβn
n
be two terms in Tn . We say t1 ≥Elim(L) t2 if we
have α1 + · · · + αj > β1 + · · · + βj , or if α1 + · · · + αj = β1 + · · · + βj and
t1 ≥DegRevLex t2 . It is easy to check that this deﬁnes a term ordering on Tn
— it is called an elimination ordering for L and is denoted by Elim(L).
The orderings Elim(L) are members of a larger class of elimination or-
derings described in Section 3.4. Again the indeterminates are ordered by
x1 >Elim(L) · · · >Elim(L) xn .
Looking at these examples, we notice that they share a common prop-
erty: the comparison of two terms is achieved by comparing their logarithms.
Indeed, since the map log : Tn →Nn is an isomorphism of monoids, one can
use terms and their logarithms interchangeably. Thus in the above examples
the comparison of terms is based on the comparison of the values of some
linear functions on their logarithms.
For instance, if t1 = xα1
1 · · · xαn
n , t2 = xβ1
1 · · · xβn
n
and (γ1, . . . , γn) =
(α1 −β1, . . . , αn −βn), then Deﬁnition 1.4.7 implies that t1 >DegRevLex t2 if
and only if the ﬁrst non-zero component of (γ1 + . . . + γn, −γn, . . . , −γ2) is
positive. We see that the components of this vector are linear functions in
the coordinates of log(t1) −log(t2). This leads us to introduce the following
construction.
Deﬁnition 1.4.11. Let v1, . . . , vn ∈Zn be linearly independent vectors,
and let V be the non-singular matrix whose ith row is vi for i = 1, . . . , n. For
t1, t2 ∈Tn, we say t1 ≥Ord(V ) t2 if t1 = t2 or if the ﬁrst non-zero coordinate
of the vector V · (log(t1) −log(t2)) is positive, where · denotes the usual
matrix-by-vector product and (log(t1) −log(t2)) has to be considered as a
column vector. It is easy to check that this deﬁnes a monoid ordering Ord(V )
on Tn. We call it the ordering represented by V .

1.4 Term Orderings
53
Proposition 1.4.12. Let V be the matrix whose rows are linearly indepen-
dent vectors v1, . . . , vn ∈Zn . Then Ord(V ) is a term ordering if and only if
the ﬁrst non-zero element in each column of V is positive.
Proof.
It is clear that a monoid ordering σ on Tn is a term ordering if and
only if xi >σ 1 for i = 1, . . . , n. Let ai be the ﬁrst non-zero element of the
ith column of V . Then V · (log(xi) −log(1)) = (0, . . . , 0, ai, . . .)tr shows that
xi >Ord(V ) 1 is equivalent to ai > 0.
□
For example, it is easy to see that Lex is the ordering represented by the
identity matrix, and from the above description of DegRevLex it follows that
it is represented by the matrix
V =





1
1
. . .
1
1
0
0
. . .
0
−1
0
0
. . .
−1
0
. . .
. . .
. . .
. . .
. . .
0
−1
0
. . .
0





Also for the other monoid orderings introduced above it is possible to see
that they are represented by some matrix (see Exercise 6). There is a complete
classiﬁcation of monoid orderings on Tn . It says that they essentially are all
of type Ord(V ), where V is a matrix with entries in R (see Exercise 7). For
computational purposes, monoid orderings represented by integral matrices
as above are good enough.
Our next two propositions deal with the question how term orderings
behave under restrictions and extensions of the monoids on which they are
deﬁned.
Proposition 1.4.13. Let σ be a monoid ordering on Tn, and let Tn−1
i
be
the monoid of terms in the indeterminates x1, . . . , xi−1, xi+1, . . . , xn.
a) The restriction σi of σ to Tn−1
i
is a monoid ordering.
b) If σ is a term ordering then also σi is a term ordering.
c) Suppose that σ is represented by a matrix V . Then σi is represented by
the matrix Vi which is obtained from V by ﬁrst deleting the ith column
and then the ﬁrst row which is linearly dependent on those above it.
Proof.
The ﬁrst assertion is clear since Tn−1
i
can be viewed as a submonoid
of Tn . The second one follows immediately from the deﬁnition of a term
ordering. To prove c), we observe that if we disregard the ith indeterminate,
we must delete the ith column from V . Then we are left with a matrix of
shape n × (n −1) and rank n −1. We delete the ﬁrst row which depends on
those above it, because if for a vector all the previous scalar products vanish,
then also the scalar product with the dependent row vanishes. Thus we get
a matrix Vi of shape (n −1) × (n −1) and rank n −1. It represents σi ,
because for all t1, t2 ∈Tn−1
i
the vector Vi · (log(t1) −log(t2)) agrees with
V · (log(t1) −log(t2)), except that we have to regard t1 and t2 as elements
of Tn and to remove the entry corresponding to the deleted row.
□

54
1. Foundations
Proposition 1.4.14. Every monoid ordering σ on Nn has a unique exten-
sion to a monoid ordering σ′ on Zn .
Proof.
For v ∈Zn , there exist vectors v1, v2 ∈Nn such that v = v1 −v2 .
We say v ≤σ′ 0 if and only if v1 ≤σ v2 . To see that this is well-deﬁned, we
take two representations v = v1 −v2 = v′
1 −v′
2 with v1, v2, v′
1, v′
2 ∈Nn and
note that v1 ≤σ v2 is equivalent to v1 + v′
2 ≤σ v2 + v′
2 by Remark 1.4.2.a.
This in turn is equivalent to v′
1 + v2 ≤σ v2 + v′
2 , and therefore to v′
1 ≤σ v′
2 .
If we now deﬁne v ≤σ′ w ⇐⇒v −w ≤σ′ 0 for v, w ∈Zn , it is easy to check
that Axioms a) – d) of Deﬁnition 1.4.1 are satisﬁed.
The uniqueness of σ′ follows from the observation that, for v, v′ ∈Zn
such that v = v1 −v2 and v′ = v′
1 −v′
2 with v1, v2, v′
1, v′
2 ∈Nn , the condition
v ≤σ′ v′ is equivalent to v1 + v′
2 ≤σ v′
1 + v2 .
□
In view of this proposition, and by extending Lex to Zn , we can rephrase
Deﬁnition 1.4.11 as follows: t1 ≥Ord(V ) t2 ⇐⇒V · (log(t1) −log(t2)) ≥Lex 0
for t1, t2 ∈Tn.
The proposition also implies that studying monoid orderings on Tn is
equivalent to studying monoid orderings on Zn . In particular, we shall use
the same symbol for a monoid ordering on Tn, its translation to Nn, and its
unique extension to Zn . In particular, we may apply this notational conven-
tion and say that for a monoid ordering σ on Tn and t1, t1 ∈Tn we have
t1 ≥σ t2 ⇐⇒log(t1) −log(t2) ≥σ 0.
The ﬁnal part of this section treats the extension of the theory of monoid
orderings to orderings on monomial modules. More precisely, for n, r ≥1, we
want to deﬁne suitable orderings on the set of terms Tn⟨e1, . . . , er⟩introduced
in Deﬁnition 1.1.10.
Deﬁnition 1.4.15. Let (Γ, ◦) be a monoid and (Σ, ∗) a Γ -monomodule. A
complete relation σ on Σ is called a module ordering if for all s1, s2, s3 ∈Σ
and all γ ∈Γ we have
a) s1 ≥σ s1
(reﬂexivity)
b) s1 ≥σ s2 and s2 ≥σ s1 imply s1 = s2
(antisymmetry)
c) s1 ≥σ s2 and s2 ≥σ s3 imply s1 ≥σ s3
(transitivity)
d) s1 ≥σ s2 implies γ ∗s1 ≥σ γ ∗s2
If, in addition, we have
e) γ ∗s ≥σ s for all s ∈Σ and all γ ∈Γ
then σ is called a module term ordering on Σ .
For us, the most important case will be the case Γ = Tn and Σ =
Tn⟨e1, . . . , er⟩. If r = 1, then module orderings are monoid orderings on
Tn = Tn⟨e1⟩as introduced in Deﬁnition 1.4.1, and module term orderings
are nothing but term orderings. We also note that it is easy to see that in this
case condition e) is equivalent to tei ≥σ ei for all t ∈Tn and all i = 1, . . . , r.

1.4 Term Orderings
55
The most important module orderings for our purposes are constructed as
follows.
Example 1.4.16. Let To be a term ordering on Tn.
a) For t1ei, t2ej ∈Tn⟨e1, . . . , er⟩such that t1, t2 ∈Tn and i, j ∈{1, . . . , r},
we let
t1ei ≥ToPos t2ej
⇐⇒
t1 >To t2
or
(t1 = t2 and i ≤j)
In this way we obtain a module term ordering ToPos on Tn⟨e1, . . . , er⟩.
The intuitive meaning of ToPos is that one ﬁrst compares the two power
products using To and then breaks ties by looking at their positions in
the vector.
b) For t1ei, t2ej ∈Tn⟨e1, . . . , er⟩such that t1, t2 ∈Tn and i, j ∈{1, . . . , r},
we let
t1ei ≥PosTo t2ej
⇐⇒
i < j
or
(i = j and t1 ≥To t2)
Again we obtain a module term ordering PosTo on Tn⟨e1, . . . , er⟩.
Deﬁnition 1.4.17. Let (Γ, ◦) be a monoid, let τ be a monoid ordering on
Γ , and let (Σ, ∗) be a Γ -monomodule. We say that a module ordering σ on
Σ is compatible with τ if γ1 ≥τ γ2 implies γ1∗s ≥σ γ2∗s for all γ1, γ2 ∈Γ
and all s ∈Σ .
For instance, if To is a monoid ordering on Tn , then both module or-
derings ToPos and PosTo on Tn⟨e1, . . . , er⟩are compatible with To. We end
this section by describing a fundamental property of term orderings.
Proposition 1.4.18. (Well-Orderings)
Let (Γ, ◦) be a monoid, (Σ, ∗) a Γ -monomodule, and σ a module ordering
on Σ . Then the following conditions are equivalent.
a) Every non-empty subset of Σ has a minimal element with respect to σ.
b) Every descending chain s1 ≥σ s2 ≥σ · · · in Σ is eventually stationary.
If these conditions are satisﬁed, the ordering σ is called a well-ordering.
If the left-cancellation law holds in Σ , then every well-ordering is a module
term ordering.
Proof.
The implication a) ⇒b) follows from the fact that the set of ele-
ments of a descending chain has a minimal element if and only if the chain
is eventually stationary. Conversely, if there is a non-empty subset Σ′ ⊂Σ
having no minimal element with respect to σ, we can obviously construct an
inﬁnite, strictly descending chain of elements of Σ′ .
To prove the additional claim, we observe that if s >σ γ ∗s for some
γ ∈Γ and s ∈Σ , then s >σ γ ∗s >σ γ2 ∗s >σ · · · is an inﬁnite chain which
is not eventually stationary.
□

56
1. Foundations
Theorem 1.4.19. (Fundamental Property of Term Orderings)
For a module ordering σ on Tn⟨e1, . . . , er⟩, the following conditions are
equivalent.
a) The relation σ is a module term ordering.
b) The relation σ is a well-ordering.
Proof.
In view of the previous proposition and the fact that the left-
cancellation law holds in Tn⟨e1, . . . , er⟩, it suﬃces to prove a) ⇒b). We
suppose there is a chain t1eγ1 ≥σ t2eγ2 ≥σ · · · in Tn⟨e1, . . . , er⟩which is
not eventually stationary, where t1, t2, . . . ∈Tn and γ1, γ2, . . . ∈{1, . . . , r}.
For some i ∈{1, . . . , r}, we then have a subchain tδ1ei ≥σ tδ2ei ≥σ · · ·
such that 1 ≤δ1 < δ2 < · · · which is not eventually stationary. By Dick-
son’s Lemma 1.3.6, the monoideal (tδ1, tδ2, . . .) is generated by ﬁnitely many
terms tδ1, . . . , tδN for some N > 0. Since σ is a module term ordering, it
follows that for each j > N there exists a number k ∈{1, . . . , N} such that
tδjei ≥σ tδkei , a contradiction.
□
Exercise 1.
Prove that the relations Lex, DegLex, DegRevLex, and
Elim(L) on Tn are term orderings.
Exercise 2. For each of the term orderings Lex, DegLex, and DegRevLex,
write down the 20 smallest terms of T3 in increasing order.
Exercise 3. Deﬁne a relation RevLex on Tn by t1 ≥RevLex t2 if the last
non-zero component of log(t1) −log(t2) is negative, or if t1 = t2 . Show
that RevLex is a monoid ordering on Tn which is not a term ordering.
How are the indeterminates ordered by RevLex?
Exercise 4. Go back to Example 1.4.4, replace x1 by A, x2 by B , etc.,
and decide to write “biggest ﬁrst”. What is the monoid ordering on Tn
similar to the usual ordering on words in a dictionary?
Exercise 5. Let V be a matrix whose rows are linearly independent vec-
tors v1, . . . , vn ∈Zn . Prove that the relation Ord(V ) is a monoid ordering
on Tn .
Exercise 6. For each of the term orderings Lex, DegLex, DegRevLex,
and Elim(L), give a non-singular matrix V such that they are represented
by V .
Exercise 7. Let u = (1,
√
2) and let σ be the relation on T2 deﬁned by
t1 ≥σ t2 if and only if u · (log(t1) −log(t2)) ≥0 for t1, t2 ∈T2 .
a) Show that σ is a term ordering on T2 .
b) Show that σ cannot be represented by any matrix of integers.
Hint: Prove that, for any term ordering τ represented by a matrix of
integers, there exist terms t, t′ ∈T2 such that t >σ t′ and t <τ t′ .

1.4 Term Orderings
57
Exercise 8.
Prove that every monoid ordering σ on Zn has a unique
extension to a monoid ordering σ′ on Qn .
Hint: A vector v ∈Qn can be represented in the form v = 1
q ·p with q > 0
and p ∈Zn . Then deﬁne v ≥σ′ 0 if and only if p ≥σ 0. To see that this
is well-deﬁned, take two representations v = 1
q · p =
1
q′ · p′ with q, q′ > 0
and p, p′ ∈Zn and prove p ≥σ 0 ⇐⇒q′p ≥σ 0.
Exercise 9. Show that the relations ToPos and PosTo deﬁned in Exam-
ple 1.4.16 are module term orderings.
Exercise 10. Let K be a ﬁeld, let P = K[x1, . . . , xn], and let e1, . . . , er
be new indeterminates. Consider the P -linear map ϕ : P r −→P[e1, . . . , er]
deﬁned by ϕ((f1, . . . , fr)) = f1e1 + · · · + frer .
a) Show that ϕ is an injective homomorphism of P -modules.
Using ϕ, we identify P r with the corresponding submodule of P[e1, . . . , er].
Let ϑ be a monoid ordering on Tn+r = T(x1, . . . , xn, e1, . . . , er), let τ be
the monoid ordering on Tn obtained by restriction of ϑ (see Proposi-
tion 1.4.13), and let σ be the ordering induced by ϑ on Tn⟨e1, . . . , er⟩
via ϕ.
b) Prove that σ is module ordering on Tn⟨e1, . . . , er⟩.
c) Prove that σ is compatible with τ .
Exercise 11.
Let σ be a module ordering on Tn⟨e1, . . . , er⟩. View
Tn⟨e1, . . . , er⟩as a disjoint union of r components, each of which is a
copy of Tn , and denote the restriction of σ to the ith component by σi .
a) Prove that σi is a monoid ordering for every i = 1, . . . , r.
b) Let τ be a monoid ordering on Tn such that σ is compatible with τ .
Prove that σi = τ for every i = 1, . . . , r.
Tutorial 9: Monoid Orderings Represented by Matrices
Let (v1, . . . , vn), (v′
1, . . . , v′
n) be two n-tuples of linearly independent vectors
in Qn , and let V, V ′ ∈Matn(Q) be the matrices having those vectors as
rows.
a) Extend Deﬁnition 1.4.11 to orderings represented by rational matrices
like V ∈Matn(Q).
b) Suppose there exists a lower triangular matrix W ∈Matn(Q) whose
entries in the diagonal are positive such that V ′ = WV . Prove that
Ord(V ) = Ord(V ′).
c) Prove that Ord(V ) can be represented by a matrix in Matn(Z).
d) Prove that if σ is a term ordering represented by a rational matrix V ,
then it can also be represented by a rational matrix V ′ whose entries are
non-negative.
e) Find such a representation for DegRevLex.
f) Prove the following partial converse of b). If Ord(V ) = Ord(V ′), then
there exists a rational number λ > 0 such that v′
1 = λv1 .

58
1. Foundations
g) Now we assume that v′
1 ̸= λv1 for all λ > 0. Write a CoCoA program
TODifference(. . .) which computes two terms t1, t2 ∈Tn such that
t1 >Ord(V ) t2 and t1 <Ord(V ′) t2 .
h) Write a CoCoA program CheckEquality(. . .) which checks for a given
number d > 0 if the term orderings represented by V and V ′ agree for
all terms of degree ≤d in Tn.
i) (This part is a much more elaborate project.) Find criteria which charac-
terize when V and V ′ represent the same monoid ordering.
Tutorial 10: Classiﬁcation of Term Orderings
In this tutorial we want to get a good understanding of all possible term
orderings on Tn for n ≤3.
a) Prove that on T1 there is only one term ordering, namely Deg.
b) Show that on T2 there are precisely two degree compatible term orderings
σ, τ which are characterized by x1 >σ x2 and x2 >τ x1 .
c) Classify all possible term orderings on T2 which satisfy x1 >σ x2 . To do
that use the following scheme.
1) Prove that there exists exactly one term ordering σ on T2 such that
x1 >σ xi
2 for all i ≥2.
2) Suppose that a term ordering σ on T2 satisﬁes x1 <σ xN
2
for some
N ≥2, and let q = inf{ j
i ∈Q+ | xi
1 <σ xj
2}. Prove that 1 ≤q ≤N .
3) Following 2), suppose that q ∈R \ Q. Show that there exists ex-
actly one term ordering σ with those properties and that it satisﬁes
xi1
1 xi2
2 ≥σ xj1
1 xj2
2
if and only if i1q + i2 ≥j1q + j2 .
4) Following 2), suppose that q ∈Q \ {1}. Show that there exist ex-
actly two term orderings with those properties. Prove that they are
represented by matrices by exhibiting the matrices.
5) Finally, if q = 1 in 2), show that there exists exactly one term or-
dering with those properties and that it is represented by a matrix.
d) For all terms of degree ≤2 in T3 , ﬁnd all orderings induced by degree
compatible term orderings. You may assume that the indeterminates are
numbered in such a way that x1 >σ x2 >σ x3 .
e) Repeat the previous part for all terms of degree ≤3 in T3 .
f) Prove that there are inﬁnitely many diﬀerent degree compatible term
orderings on T3 .
g) Write a CoCoA program TermOrderList(. . .) which takes two numbers
i, d > 0, deﬁnes a degree compatible term ordering TOi on T3 which is
diﬀerent for each i, and returns the list of all terms of degree ≤d ordered
according to TOi .

1.5 Leading Terms
59
1.5 Leading Terms
The real leader has no need to lead.
He is content to point the way.
(Henry Miller)
In the last section we saw how to order terms. A ﬁrst consequence is that,
once a monoid ordering on Tn is chosen, we can sort the terms in the support
of a polynomial, and therefore represent the polynomial in a unique way as
a sum. This provides us with a new way of looking at polynomials.
In some sense, as soon as the ordering is given and the polynomial
f(x1, x2, x3) = x1x3 −x2
2 + x1 is written just as you see it (for instance
if you are using DegLex), we can say that −x2
2 + x1x3 + x1 is not allowed
anymore. If in the process of some computation −x2
2 + x1x3 + x1 shows up
somewhere, it is automatically converted to x1x3 −x2
2 + x1 . This does not
violate the commutativity law, rather it conveys the idea that the equality
x1x3 −x2
2 + x1 = −x2
2 + x1x3 + x1 should be interpreted in the following
way. The polynomial f(x1, x2, x3), written correctly with the sequence of
symbols x1x3 −x2
2 +x1 , is equal to the polynomial −x2
2 +x1x3 +x1 , because
−x2
2 + x1x3 + x1 is automatically converted to x1x3 −x2
2 + x1 , and this is
the same sequence of symbols as before.
The hierarchy created among the terms in Supp(f) by the monoid or-
dering implies that x1x3 becomes “bigger” and “more important” than the
other terms. Should it be called the “leader”, the “initial”, or the “head”?
We call it the leading term of f(x1, x2, x3). Of course all of this can and will
be extended to module orderings.
The ﬁrst part of this section is devoted to explaining these concepts and
to getting a better insight into their mathematical meaning. Then we address
a very important problem. One of the main ideas in Computational Commu-
tative Algebra is to study or detect properties of ideals and modules using the
information coming from their associated leading term ideals and modules.
The reason is that the latter objects, whose nature is purely combinatorial,
are easier to deal with, and the ﬁrst step in this direction is Macaulay’s Basis
Theorem.
Suppose we have an ideal I in a polynomial ring P = K[x1, . . . , xn] over
a ﬁeld K . It is clear that the residue class ring P/I can be viewed as a
K -vector space. Some natural questions arise. Is it possible to exhibit an
explicit basis? Can we compute it? The second question will take much more
eﬀort, but with the aid of leading terms, Macaulay’s Basis Theorem yields a
beautiful answer to the ﬁrst one. This theorem requires the assumption that
the module ordering is a term ordering. Thus we see, for the ﬁrst time, the
theoretical importance of term orderings.
In the ﬁnal part of this section we show how two fundamental term or-
derings, Lex and DegRevLex, can be characterized using the kind of leading
terms they produce.

60
1. Foundations
In what follows, we let R be a ring, n ≥1, P = R[x1, . . . , xn] a polyno-
mial ring, r ≥1, and σ a module ordering on the set of terms Tn⟨e1, . . . , er⟩
of P r . The standard basis of P r will be denoted by {e1, . . . , er} as usual.
Remark 1.5.1. Every element m ∈P r \{0} has a unique representation as
a linear combination of terms
m =
s
X
i=1
citieγi
where c1, . . . , cs ∈R\{0}, t1, . . . , ts ∈Tn , γ1, . . . , γs ∈{1, . . . , r}, and where
t1eγ1 >σ t2eγ2 >σ · · · >σ tseγs .
If we write m = f1e1 + · · · + frer , where f1, . . . , fr ∈P , then we have
Supp(fi) = {tj | γj = i} for each i ∈{1, . . . , r}.
Deﬁnition 1.5.2. For a non-zero element m ∈P r , let m = Ps
i=1 citieγi be
the representation according to Remark 1.5.1.
a) The term LTσ(m) = t1eγ1 ∈Tn⟨e1, . . . , er⟩is called the leading term
of m with respect to σ.
b) The element LCσ(m) = c1 ∈R \ {0} is called the leading coeﬃcient
of m with respect to σ. If LCσ(m) = 1, we say that m is σ-monic, or
simply monic if σ is clear from the context.
c) We let LMσ(m) = LCσ(m) · LTσ(m) = c1t1eγ1 .
For the zero vector m = (0, . . . , 0), we recall from Deﬁnition 1.1.11 that
Supp(m) = ∅. The leading term LTσ(m) and the leading coeﬃcient LCσ(m)
are not deﬁned.
Note that the leading term of a vector m ∈P r \ {0} really consists of
two data: the term t1 ∈Tn which is sometimes also called the leading
power product of m, and the position γ1 ∈{1, . . . , r} of this term which
is sometimes called the leading position of m. In CoCoA, the leading power
product of a vector can be obtained using the function LPP(. . .), and the
leading position is accessible via LPos(. . .).
With respect to the usual operations such as addition and multiplication
of polynomials, leading terms behave pretty much as one would expect: the
leading term of a sum is the biggest leading term of one of the summands,
except if some “cancellation” occurs, and the leading term of the product is
the product of the leading terms, except for some pathological cases. Let us
collect the precise rules.
Proposition 1.5.3. (Rules for Computing with Leading Terms)
As above, we let P = R[x1, . . . , xn] be a polynomial ring over a ring R and σ
a module ordering on Tn⟨e1, . . . , er⟩. Moreover, let f, f1, f2 ∈P be non-zero
polynomials, and let m, m1, m2 ∈P r be non-zero vectors of polynomials.

1.5 Leading Terms
61
a) We have Supp(m1 + m2) ⊆Supp(m1) ∪Supp(m2), and if moreover
m1 + m2 ̸= 0, then LTσ(m1 + m2) ≤σ maxσ{LTσ(m1), LTσ(m2)}.
b) Suppose that m1 + m2 ̸= 0, and suppose that LTσ(m1) ̸= LTσ(m2) or
LCσ(m1) + LCσ(m2) ̸= 0. Then we have
LTσ(m1 + m2) = maxσ{LTσ(m1), LTσ(m2)}
c) For t ∈Tn , we have LTσ(tm) = t · LTσ(m).
d) If R is an integral domain, and if t is the term in Supp(f) for which
t · LTσ(m) is maximal with respect to σ, then LTσ(fm) = t · LTσ(m).
e) If R is an integral domain, and if τ is a monoid ordering on Tn such
that σ is compatible with τ , then we have
LTσ(fm) = LTτ(f) · LTσ(m)
In particular, if R is an integral domain, then LTτ(f1f2) = LTτ(f1) ·
LTτ(f2).
Proof.
To prove a), write m1 = Ps
i=1 citieγi and m2 = Ps′
j=1 c′
jt′
jeγ′
j ac-
cording to Remark 1.5.1. From the representation
m1 + m2 =
r
X
i=1
X
t∈Tn
³
X
{j|tj=t,γj=i}
cj +
X
{j|t′
j=t,γ′
j=i}
c′
j
´
tei
we conclude that Supp(m1 + m2) ⊆Supp(m1) ∪Supp(m2) and also that
tei ≤σ maxσ{t1eγ1, t′
1eγ′
1} for all tei ∈Supp(m1 + m2).
For the proof of b), we represent m1 , m2 and m1 + m2 as above. If
we have LTσ(m1) = t1eγ1 = t′
1eγ′
1 = LTσ(m2), then c1 + c′
1 ̸= 0 implies
that LTσ(m1 + m2) = t1eγ1 = maxσ{t1eγ1, t′
1eγ′
1}. When t1eγ1 <σ t′
1eγ′
1 or
t1eγ1 >σ t′
1eγ′
1 , the claim follows immediately from the above representation
of m1 + m2 .
In order to show claim c), we write m = Ps
i=1 citieγi as in Remark 1.5.1.
Then tm = Ps
i=1 ci(tti)eγi is the representation of tm, since tieγi >σ tjeγj
for 1 ≤i < j ≤s implies (tti)eγi >σ (ttj)eγj . Thus we obtain LTσ(tm) =
tt1eγ1 = t · LTσ(m).
For the proof of d), we represent f = Ps
i=1 citi and m = Ps′
j=1 c′
jt′
jeγj
according to Remark 1.5.1. Then we have tit′
jeγj ≤σ ti LTσ(m) ≤σ t LTσ(m)
for i = 1, . . . , s and for j = 1, . . . , s′ . Let ck be the coeﬃcient of t in f .
Now the claim follows from fm = Ps
i=1
Ps′
j=1(cic′
j)(tit′
j)eγj and ckc′
1 ̸= 0.
To prove e), we observe that if σ is compatible with τ , then the term
t = LTτ(f) is the unique element of Supp(f) for which t·LTσ(m) is maximal
with respect to σ.
□
Deﬁnition 1.5.4. Let M ⊆P r be a P -submodule.
a) The module LTσ(M) = ⟨LTσ(m) | m ∈M \ {0}⟩is called the leading
term module of M with respect to σ.

62
1. Foundations
b) If r = 1, i.e. if M ⊆P , then the ideal LTσ(M) ⊆P is also called the
leading term ideal of M with respect to σ.
c) The monomodule {LTσ(m) | m ∈M \ {0}} ⊆Tn⟨e1, . . . , er⟩will be
denoted by LTσ{M}.
Notice that, for M = ⟨0⟩, we get LTσ(M) = ⟨0⟩and LTσ{M} = ∅
using this deﬁnition. If m1, . . . , ms ∈P r are non-zero vectors, and if
M = ⟨m1, . . . , ms⟩⊆P r is the submodule generated by them, we have
⟨LTσ(m1), . . . , LTσ(ms)⟩⊆LTσ(M). The following example shows that this
can be a proper inclusion.
Example 1.5.5. Let I be the ideal in K[x, y] generated by {x2−1, xy−1},
and let σ = DegLex. Then f = y(x2 −1) −x(xy −1) = x −y ∈I implies
LTσ(f) = x ∈LTσ(I), but x is not in the ideal generated by LTσ(x2−1) = x2
and LTσ(xy −1) = xy.
Nevertheless, there are systems of elements of M whose leading terms
generate LTσ(M) as our next proposition shows.
Proposition 1.5.6. Let M ⊆P r be a non-zero P-submodule.
a) Every term tei ∈LTσ(M) with t ∈Tn and 1 ≤i ≤r is of the form
tei = LTσ(m) for some m ∈M .
b) There exist non-zero elements m1, . . . , ms ∈M such that we have
LTσ(M) = ⟨LTσ(m1), . . . , LTσ(ms)⟩.
Proof.
The elements of the set LTσ{M} generate the R-module LTσ(M).
By Proposition 1.3.11.a, every term in LTσ(M) is then of the form t·LTσ(m)
with t ∈Tn and m ∈M , and is therefore equal to LTσ(tm). This proves a).
Theorem 1.3.9.a implies that LTσ{M} is generated by ﬁnitely many
terms as a monomodule over Tn . Thus those terms generate the R-module
LTσ(M), and using a) we get claim b).
□
Now we are ready to prove the main result of this section. As we said
before, Macaulay’s Basis Theorem requires the assumption that the module
ordering is a term ordering. Furthermore, we need to assume that our base
ring is a ﬁeld.
Theorem 1.5.7. (Macaulay’s Basis Theorem)
Let K be a ﬁeld, let P = K[x1, . . . , xn] be a polynomial ring over K ,
let M ⊆P r be a P-submodule, and let σ be a module term ordering on
Tn⟨e1, . . . , er⟩. We denote the set of all terms in Tn⟨e1, . . . , er⟩\ LTσ{M}
by B. Then the residue classes of the elements of B form a basis of the
K -vector space P r/M .
Proof.
First we prove that the elements ¯b ∈P r/M such that b ∈B form
a system of generators of P r/M . In other words, we need to prove that the
vector subspace N = P
b∈B K ·b+M equals P r . For a contradiction suppose

1.5 Leading Terms
63
that N ⊂P r . Then the set P r \ N contains some non-zero elements. Hence
Theorem 1.4.19 implies that there exists an element m of P r \ N having
a minimal leading term with respect to σ. If now LTσ(m) ∈B, then the
element m −LCσ(m) LTσ(m) is still in P r \ N and has a smaller leading
term than m: a contradiction. Thus we need to have LTσ(m) ∈LTσ{M}.
So there exists an element m′ ∈M such that LTσ(m′) = LTσ(m). Again
the element m −LCσ(m)
LCσ(m′)m′ lies in P r \ N and has a smaller leading term
than m: a contradiction again.
Now we prove linear independence. Suppose there is a relation m =
Ps
i=1 cimi ∈M such that c1, . . . , cs ∈K\{0} and m1, . . . , ms ∈B. Then we
have LTσ(m) ∈LTσ{M}, since m ∈M . We also have LTσ(m) ∈Supp(m) ⊆
{m1, . . . , ms} ⊆B, because m1, . . . , ms are terms, and because of Proposi-
tion 1.5.3.a. Altogether we ﬁnd LTσ(m) ∈LTσ{M} ∩B = ∅which is impos-
sible.
□
To see how essential the assumption is that σ is a term ordering, consider
the following example.
Example 1.5.8. Let P = K[x], let σ = Ord(−1), and let I be the principal
ideal generated by x−x2 . Then LTσ(x−x2) = x, so that T1\LTσ{I} = {1}.
However, the residue class of x cannot be a constant.
Remark 1.5.9. Macaulay’s Basis Theorem gives us a ﬁrst idea of how to
compute eﬀectively in P r/M . First we would need to know LTσ(M) for
some module term ordering σ, and then we could represent every element
uniquely as a ﬁnite linear combination of the residue classes of the elements
of B = Tn⟨e1, . . . , er⟩\ LTσ{M}. Unfortunately, we do not yet know how to
calculate LTσ(M), and we cannot store the basis {¯b | b ∈B} in a computer,
since it is in general inﬁnite. In the next chapter we shall see how to overcome
these problems.
To conclude this section, we show how to characterize two of the most
important term orderings on Tn , namely Lex and DegRevLex in terms of
their behaviour when they are used to order polynomials. So, for the rest of
the section, let R be a ring, and let P = R[x1, . . . , xn].
Proposition 1.5.10. Let σ be a monoid ordering on Tn . Then the following
conditions are equivalent.
a) σ = Lex
b) For f ∈P and i ∈{1, . . . , n} such that LTσ(f) ∈R[xi, . . . , xn], we have
f ∈R[xi, . . . , xn].
Proof.
To prove a) ⇒b), let f ∈P be such that LTLex(f) ∈R[xi, . . . , xn].
If t ∈Supp(f)\{LTLex(f)}, then by Deﬁnition 1.4.3 the ﬁrst non-zero compo-
nent of log(LTLex(f))−log(t) is positive. But since the ﬁrst i−1 components
of LTLex(f) are zero, also the ﬁrst i −1 components of log(t) have to be
zero. Thus we get t ∈R[xi, . . . , xn] for all t ∈Supp(f).

64
1. Foundations
Now we prove b) ⇒a). Let us consider two terms t1, t2 ∈Tn such
that log(t1) −log(t2) = (0, . . . , 0, ci−1, . . . , cn), with ci−1 > 0. The ﬁrst
i −2 coordinates of log(t1) and log(t2) are equal, so we can use property
d) of Deﬁnition 1.4.1 and assume that they are zero. For the same reason
we can also assume that the (i −1)st coordinate of log(t2) is zero, while
the (i −1)st coordinate of log(t1) is diﬀerent from zero. Next we consider
the polynomial f = t1 + t2 . Suppose for contradiction that LTσ(f) = t2 .
Then LTσ(f) ∈R[xi, . . . , xn], and b) implies that also f ∈R[xi, . . . , xn].
Consequently, we see that t1 = f −t2 ∈R[xi, . . . , xn], in contradiction with
the fact that the (i−1)st coordinate of log(t1) is diﬀerent from zero. Therefore
we have LTσ(f) = t1 , i.e. t1 >σ t2 .
Altogether, we have shown that t1 >Lex t2 implies t1 >σ t2 . By inter-
changing t1 and t2 , we ﬁnd that t1 >Lex t2 if and only if t1 >σ t2 . Therefore
we have σ = Lex.
□
Proposition 1.5.11. Let σ be a monoid ordering on Tn . Then the following
conditions are equivalent.
a) σ = RevLex
b) For f ∈P and i ∈{1, . . . , n} such that LTσ(f) ∈(xi, ..., xn), we have
f ∈(xi, ..., xn).
Proof.
To prove a) ⇒b), let f ∈P be such that LTσ(f) is in the ideal
(xi, . . . , xn). If t ∈Supp(f)\{LTσ(f)}, then by the deﬁnition of RevLex, the
last non-zero component of log(LTσ(f)) −log(t) is negative. But since the
last non-zero component of log(LTσ(f)) is in a position between i and n,
also the last non-zero component of log(t) has to be in a position between
i and n. This means that all the terms in Supp(f) have to be in the ideal
(xi, . . . , xn).
Now we prove b) ⇒a). Let t1, t2 be two terms in Tn such that log(t1) −
log(t2) = (c1, . . . , ci, 0, . . . , 0), with ci < 0. The last n −i coordinates of
log(t1) and log(t2) are equal, so we can use property d) of Deﬁnition 1.4.1
and assume that they are zero. For the same reason we can also assume that
the ith coordinate of log(t1) is zero while the ith coordinate of log(t2) is
diﬀerent from zero. Let us consider the polynomial f = t1 + t2 . Suppose for
contradiction that LTσ(f) = t2 . Then LTσ(f) ∈(xi, ..., xn), and b) implies
that also f ∈(xi, ..., xn). Consequently, we have t1 = f −t2 ∈(xi, ..., xn),
in contradiction with the fact that the last n −i coordinates of log(t1) are
zero. Therefore LTσ(f) = t1 , i.e. we have t1 >σ t2 , and we may conclude
that σ = RevLex.
□
Later on in this Chapter (see Section 1.7) and in the second volume we
will study the concepts of gradings and homogeneity in great detail. However,
for the moment it is enough to recall that a polynomial of degree d is said
to be homogeneous if all the terms in its support have degree d. Also, we
refer to Deﬁnition 1.4.9 for the notion of degree-compatible term orderings.

1.5 Leading Terms
65
Then an easy modiﬁcation of the proof of the preceding proposition yields the
following characterization of the degree-reverse-lexicographic term ordering.
Corollary 1.5.12. Let σ be a degree-compatible term ordering on Tn . Then
the following conditions are equivalent.
a) σ = DegRevLex
b) For every homogeneous polynomial f ∈P and every i ∈{1, . . . , n} such
that LTσ(f) ∈(xi, . . . , xn), we have f ∈(xi, . . . , xn).
Exercise 1. Let f = x2
1 + x1x2 + x2
2 ∈P = K[x1, x2]. Show that there
is no monoid ordering σ on T2 such that LTσ(f) = x1x2 .
Exercise 2. For each of the following polynomials in Q[x1, x2, x3], ﬁnd
a term ordering such that the given representation agrees with the one
provided by Remark 1.5.1.
a) f1 = x1x3
2x3 + 2x1x2
2x2
3 −x2
1x3
3
b) f2 = 4x4
1x5
2x3 + 2x3
1x2
2x3 + x1x2
2x4
3
c) f3 = −x2
1x4
2x3 + 3x1x6
2 −2x2
1x2
2
Exercise 3. Do the leading terms of the polynomials f1 = x4
1x2 −x5
3 ,
f2 = x3
1x3
2 −1, and f3 = x2
1x4
2 −2x3 generate the leading term ideal with
respect to DegRevLex of the ideal (f1, f2, f3) in Q[x1, x2, x3]?
Exercise 4. Let K be a ﬁeld. Try to use Macaulay’s Basis Theorem to
determine an explicit K -basis of the ring K[x1, x2, x3]/(x1 −x3
3, x2 −x4
3).
Hint: Use the lexicographic term ordering.
Exercise 5.
Let K be a ﬁeld, let P = K[x1, . . . , xn], let 1 ≤m < n,
and let V ∈Matn(Z) be a matrix with det(V ) ̸= 0 and of the following
type
V =
“ v
W
”
where v = (0, . . . , 0, 1, . . . , 1), the last 0 occurring in the mth position,
and where W ∈Matn−1,n(Z) is such that the ﬁrst non-zero element in
each of the ﬁrst m columns is positive.
a) Show that the ordering Ord(V ) on Tn is a term ordering.
b) Show that if f ∈P and LTOrd(V )(f) ∈K[x1, . . . , xm], then we have
f ∈K[x1, . . . , xm].
Exercise 6. Let K be a ﬁeld, and let V ∈Matn(Z) be a matrix with
det(V ) ̸= 0 which is of the following type
V =
“ v
W
”
where v = (0, . . . , 0, −1) and W ∈Matn−1,n(Z).
a) Show that the ordering Ord(V ) on Tn is not a term ordering.
b) Show that if f ∈K[x1, . . . , xn] and xn | LTOrd(V )(f), then xn | f .
c) Can you modify V
in such a way that b) holds for homogeneous
polynomials, but not in general?

66
1. Foundations
Tutorial 11: Polynomial Representation II
Using Remark 1.5.1, we have another possible way of representing polynomi-
als from the polynomial ring P = K[x1, . . . , xn] over a ﬁeld K in a computer
program. We choose a term ordering σ on Tn. For each f ∈P \ {0}, we let
f =
s
X
i=1
citi
with c1, . . . , cs ∈K \ {0} and with t1, . . . , ts ∈Tn such that t1 >σ · · · >σ ts
be the representation according to Remark 1.5.1. Then we represent f in the
computer program by the list of pairs
[[c1, log(t1)], . . . , [cs, log(ts)]]
where log(t1), . . . , log(ts) are considered as vectors in Zn .
a) Write a CoCoA program ReprPoly2(. . .) which takes a polynomial in
Q[x1, . . . , xn] and computes this representation.
b) Implement CoCoA functions AddPoly2(. . .) and MultPoly2(. . .) which
calculate the lists corresponding to the sums and products of two poly-
nomials represented in this way.
c) Check the correctness of your programs by applying them to the poly-
nomials of Tutorial 1.f. Compute the lists representing f1 + f2 , f1 · f2 ,
and f2 · f3 + f 3
1 again in two ways.
Tutorial 12: Symmetric Polynomials
Let K be a ﬁeld and f ∈P = K[x1, . . . , xn] a polynomial. We call f
symmetric if f is invariant under all permutations of the indeterminates
x1, . . . , xn . For i = 1, . . . , n, the polynomials
si =
X
j1<···<ji
xj1 · · · xji
are called the elementary symmetric polynomials. In this tutorial we
intend to give an eﬀective proof for the well-known theorem that every sym-
metric polynomial can be written as a polynomial in s1, . . . , sn . To this end,
we equip the polynomial ring P with the lexicographic term ordering Lex.
a) Show that the symmetric group Sn (i.e. the group of all permuta-
tions of the variables x1, . . . , xn ) is generated by the transpositions
⟨x1, x2⟩, . . . , ⟨x1, xn⟩.
b) Write a CoCoA program Is Symmetric(. . .) which checks if a given poly-
nomial is symmetric and returns the corresponding Boolean value. (Hint:
Show that it suﬃces to check invariance under a system of generators of
Sn and use the CoCoA command Subst(...).)

1.5 Leading Terms
67
c) Prove the recursive formula si = ˜si +xn˜si−1 for n > 1 and i ∈Z, where
˜s1, . . . , ˜sn−1 are the elementary symmetric polynomials in the indeter-
minates x1, . . . , xn−1 , where we set si = ˜si = 0 if i < 0 or i > n, and
where s0 = ˜s0 = 1.
d) Use c) to write a CoCoA program ElSym(. . .) which computes the ith
elementary symmetric polynomial in n indeterminates.
e) Prove that the leading term LTLex(f) = xα1
1 · · · xαn
n
of a symmetric poly-
nomial f ∈P \ {0} satisﬁes α1 ≥· · · ≥αn .
f) Show that one can subtract from f a suitable multiple of the polynomial
sα1−α2
1
· · · sαn−1−αn
n−1
· sαn
n
such that the result is a symmetric polynomial
with a smaller leading term with respect to Lex. Consequently, develop
an algorithm for representing f as a polynomial in s1, . . . , sn.
g) Implement the algorithm from f) in a CoCoA function ReprSym(. . .) which
takes a polynomial f ∈P and returns a polynomial g ∈P such that
f = g(s1, . . . , sn).
h) Apply Is Symmetric(. . .) and ReprSym(. . .) to the following polynomi-
als.
1) F1 = x3
1x2 + x3
2x3 + x1x3
2 + x1x3
3 + x3
1x3 + x2x3
3 ∈Q[x1, x2, x3]
2) F2 = P
i̸=j x2
i xj ∈Q[x1, . . . , x5]
3) F3 = x5
1 + · · · + x5
5 ∈Q[x1, . . . , x5]
Tutorial 13: Newton Polytopes
Given a non-zero polynomial f in a polynomial ring P = K[x1, . . . , xn] over
a ﬁeld K , we may wonder which terms in its support can be the leading term
with respect to some term ordering. A partial answer to this question can be
given using the Newton polytope of f which is the subject of this tutorial.
For v1, v2 ∈Rn , the set {λ1v1 + λ2v2 | λ1, λ2 ∈R≥0, λ1 + λ2 = 1} is
called the line segment deﬁned by v1 and v2 and is denoted by [v1v2]. A
subset S ⊆Rn is called convex if for all v1, v2 ∈S the line segment [v1v2]
is contained in S .
a) Let S ⊆Rn be a non-empty subset. Show that there exists a unique
convex subset of Rn containing S which is contained in every other
convex set containing S . It is called the convex hull of S and denoted
by conv(S).
Hint: Consider the intersection of all convex sets containing S .
b) Let S ⊆Rn be a convex set, and let v ∈Rn \ S . Prove the equality
conv(S ∪{v}) = {[vw] | w ∈S}, but also give an example of a set
S′ ⊆Rn such that {[vw] | v, w ∈S′} is not the convex hull of S′ .
For a ﬁnite subset S = {v1, . . . , vr} of Rn , its convex hull P = conv(S)
is also called a polytope. A vertex of P is an element v ∈P such that
v /∈conv(P \ {v}). The set of all vertices of P is denoted by Vert(P).

68
1. Foundations
c) Show that P = {Pr
i=1 λivi | λ1, . . . , λr ∈R≥0, λ1 + · · · + λr = 1}.
Hint: Use induction on r, the fact that if we let α = Pr−1
i=1 λi , then
Pr
i=1 λivi = α(Pr−1
i=1
λi
α vi) + λrvr , and apply b).
d) Show that Vert(P) ⊆S .
e) Prove that the convex hull of Vert(P) is P and that, among all sets
whose convex hull is P , it is the unique minimal set with that property.
Now let us return to our non-zero polynomial f ∈P = K[x1, . . . , xn]. We
let S = {log(t) | t ∈Supp(f)} and call Newton(f) = conv(S) the Newton
polytope of f . Further, we let Vert(f) be the subset of Supp(f) which
corresponds to the set of vertices of Newton(f).
f) Prove that if t ∈Supp(f) \ Vert(f), then there is no monoid ordering σ
such that LTσ(f) = t.
Hint: Use the fact that if S = {v1, . . . , vr} ⊆Qn , then every element v
of P ∩Qn has a representation v = Pr
i=1 λivi with λ1, . . . , λr ∈Q≥0
and λ1+· · ·+λr = 1. (You do not have to prove this.) Now let Vert(f) =
{t1, . . . , ts}. Find a relation log(t) = Ps
i=1 λi log(ti) with λi ∈Q≥0 , and
thus a relation ta0 = Qs
i=1 tai
i
with a0, . . . , as ∈N and a0 = a1+· · ·+as.
g) Let f = 3x6y2 + 2x3y3 −xy + 5x3y5 ∈K[x, y].
1) Find a term ordering σ such that LTσ(f) = x6y2 .
2) Find a term ordering σ such that LTσ(f) = x3y5 .
3) Show that LTσ(f) ̸= xy for every term ordering σ.
4) Show that LTσ(f) ̸= x3y3 for every monoid ordering σ.

1.6 The Division Algorithm
69
1.6 The Division Algorithm
Divide et impera.
(Philip of Macedonia)
As we mentioned in Remark 1.5.9, Macaulay’s Basis Theorem is certainly
the ﬁrst step towards being able to compute in residue class modules P r/M ,
where P = K[x1, . . . , xn] is a polynomial ring over a ﬁeld. One gap still to
be ﬁlled in is the lack of an algorithm which allows us to write a residue
class as a linear combination of the residue classes of the terms contained in
Tn⟨e1, . . . , er⟩\ LTσ{M}.
Let us have a closer look at what happens for residue class rings of K[x].
In that case any given ideal is principal. Let I ⊆K[x] be a non-zero ideal
and f = adxd + ad−1xd−1 + · · · + a0 a generator of I such that ad ̸= 0,
i.e. such that deg(f) = d. In Section 1.2 we have already mentioned division
with remainder for univariate polynomials. By using this device, for any given
polynomial g we get a representation g = qf + p, where p is either zero or a
polynomial of degree less than d. This implies that every element in the ring
K[x]/(f) can be uniquely represented as a linear combination of the residue
classes 1, ¯x, . . . , ¯xd−1 .
Of course this is a special instance of Macaulay’s Basis Theorem. But in
the univariate case we have more than that. Namely, the Division Algorithm
for univariate polynomials allows us to eﬀectively obtain the desired repre-
sentation. The topic of the present section is to answer the question as to
whether this technique can be extended to the multivariate case. As we shall
see, there is no unique way to perform polynomial division in several indeter-
minates. Instead, the Division Algorithm tells us how much uniqueness we
can expect and gives us an explicit way how to go about the computation.
The result of dividing a vector m ∈P r by a tuple of vectors (g1, . . . , gs)
is a representation of the form m = q1g1 + · · · + qsgs + p with q1, . . . , qs ∈P
and p ∈P r having certain extra properties. The vector p is called the normal
remainder of m with respect to (g1, . . . , gs). It has the drawback of depending
both on the chosen module term ordering σ and the order of the elements in
the tuple (g1, . . . , gs). Nevertheless, it will play a major role in Buchberger’s
Algorithm for computing Gr¨obner bases in Section 2.5.
In this section, we let K be a ﬁeld, n ≥1, P = K[x1, . . . , xn], r ≥1,
and σ a module term ordering on Tn⟨e1, . . . , er⟩.
Example 1.6.1. In the case K = Q, n = r = 1, and P = K[x1] = K[x],
let us consider the polynomials f = x3 + 2x2 + x + 1 and g = 2x + 1. Then
we can compute f
g in the following way:
x3 + 2x2 + x + 1 = g · ( 1
2x2 + 3
4x + 1
8) remainder
7
8
x3 +
1
2x2
3
2x2 + x + 1

70
1. Foundations
3
2x2 +
3
4x
1
4x + 1
1
4x +
1
8
7
8
In other words, we have f = qg + p with q = 1
2x2 + 3
4x + 1
8 and p = 7
8 . The
characteristic property of p is deg(p) < deg(g).
When we are dealing with polynomials in two indeterminates, we can try
to imitate this procedure and proceed as follows.
Example 1.6.2. Let f = x2
1x2 + x1x2
2 + x2
2 , g1 = x1x2 −1, and g2 = x2
2 −1
be three polynomials in Q[x1, x2]. We are looking for polynomials q1 , q2 ,
and p such that f = q1g1 + q2g2 + p and deg(p) < 2. With that goal, we
eliminate LTLex(f) step by step as follows:
x2
1x2 + x1x2
2 + x2
2 =
½
g1 · (x1 + x2)
g2 · (1)
remainder
x1 + x2 + 1
x2
1x2 −x1
x1x2
2 + x1 + x2
2
x1x2
2 −x2
x1 + x2
2 + x2
x2
2 −1
x1 + x2 + 1
Note that LTLex(x1+x2
2+x2) = x1 is not divisible by LTLex(g1) or LTLex(g2),
so that it has to be added to the remainder. We obtain a representation
f = q1g1 + q2g2 + p such that q1 = x1 + x2 , q2 = 1, and p = x1 + x2 + 1.
Again we have deg(p) = 1 < 2 = deg(g1) = deg(g2).
Remark 1.6.3. The result of the procedure described in the previous ex-
ample depends very much on the order of the elements g1, g2 . For instance,
if we let g′
1 = g2 and g′
2 = g1 , we get a diﬀerent result:
x2
1x2 + x1x2
2 + x2
2 =
½
g′
1 · (x1 + 1)
g′
2 · (x1)
remainder
2x1 + 1
x2
1x2 −x1
x1x2
2 + x1 + x2
2
x1x2
2 −x1
2x1 + x2
2
x2
2 −1
2x1 + 1

1.6 The Division Algorithm
71
In other words, we ﬁnd a representation f = q′
1g′
1+q′
2g′
2+p′ = q′
2g1+q′
1g2+p′
such that q′
1 = x1 + 1, q′
2 = x1 , and p′ = 2x1 + 1.
The procedure described above can be extended to a very general sit-
uation. It provides us with the following algorithm. Note that whenever
t, t′, t′′ ∈Tn satisfy t = t′t′′ , and for all i ∈{1, . . . , r}, we shall commit
a slight abuse of notation and write t′′ = tei
t′ei .
Theorem 1.6.4. (The Division Algorithm)
Let s ≥1, and let m, g1, . . . , gs ∈P r \ {0}. Consider the following sequence
of instructions.
1) Let q1 = · · · = qs = 0, p = 0, and v = m.
2) Find the smallest i ∈{1, . . . , s} such that LTσ(v) is a multiple of
LTσ(gi). If such an i exists, replace qi by qi +
LMσ(v)
LMσ(gi) and v by
v −LMσ(v)
LMσ(gi) · gi .
3) Repeat step 2) until there is no more i ∈{1, . . . , s} such that LTσ(v) is a
multiple of LTσ(gi). Then replace p by p+LMσ(v) and v by v−LMσ(v).
4) If now v ̸= 0, start again with step 2). If v = 0, return the tuple
(q1, . . . , qs) ∈P s and the vector p ∈P r .
This is an algorithm which returns vectors (q1, . . . , qs) ∈P s and p ∈P r
such that
m = q1g1 + · · · + qsgs + p
and such that the following conditions are satisﬁed.
a) No element of Supp(p) is contained in ⟨LTσ(g1), . . . , LTσ(gs)⟩.
b) If qi ̸= 0 for some i ∈{1, . . . , s}, then we have LTσ(qigi) ≤σ LTσ(m).
c) For all indices i = 1, . . . , s and all terms t in the support of qi , we have
t · LTσ(gi) /∈⟨LTσ(g1), . . . , LTσ(gi−1)⟩.
Moreover, the vectors (q1, . . . , qs) ∈P s and p ∈P r satisfying the above
conditions are uniquely determined by the tuple (m, g1, . . . , gs) ∈(P r)s+1 .
Proof.
First we observe that at each point in the Division Algorithm the
equation
m = q1g1 + · · · + qsgs + p + v
holds, since in step 2) we have qigi + v = (qi + LMσ(v)
LMσ(gi))gi + (v −LMσ(v)
LMσ(gi)gi),
and in step 3) we have p + v = (p + LMσ(v)) + (v −LMσ(v)).
The algorithm stops after ﬁnitely many steps, because both in step 2)
and in step 3) the leading term LTσ(v) becomes strictly smaller with respect
to σ. By Theorem 1.4.19, this can happen only ﬁnitely many times.
When the algorithm stops, we have m = q1g1+· · ·+qsgs+p. The vector p
satisﬁes property a), since in step 3) a scalar multiple of a term is added to p
only if that term is not a multiple of one of the terms LTσ(g1), . . . , LTσ(gs).
Now we prove by induction on the number of steps processed that we
always have LTσ(v) ≤σ LTσ(m) and LTσ(qigi) ≤σ LTσ(m) when qi ̸= 0.

72
1. Foundations
This is obviously satisﬁed at the start of the algorithm. Every time step 2)
is executed and the old and new values of qi are not zero, we have the
inequalities
LTσ
¡
(qi + LMσ(v)
LMσ(gi)) · gi
¢
≤σ maxσ{LTσ(qigi), LTσ(v)} ≤σ LTσ(m).
The same conclusion holds trivially if the old value of qi was zero. Thus
condition b) continues to hold throughout the algorithm.
Furthermore, condition c) is always satisﬁed, since in step 2) only scalar
multiples of terms t ∈Tn⟨e1, . . . , er⟩are added to qi for which t · LTσ(gi)
was not eliminated from v during an earlier execution of step 2), i.e. which
are not a multiple of one of the terms LTσ(g1), . . . , LTσ(gi−1).
Finally, we show uniqueness. Suppose there are two representations m =
q1g1 + · · · + qsgs + p = q′
1g1 + · · · + q′
sgs + p′ which satisfy conditions a), b),
and c). Then we have
0 = (q1 −q′
1)g1 + · · · + (qs −q′
s)gs + (p −p′)
(∗)
Condition a) implies that LTσ(p −p′) /∈⟨LTσ(g1), . . . , LTσ(gs)⟩, and
condition c) implies that LTσ((qi −q′
i)gi) /∈⟨LTσ(g1), . . . , LTσ(gi−1)⟩for
all i ∈{1, . . . , s} with qi ̸= q′
i . Thus the leading terms of the summands
in (∗) are pairwise diﬀerent. In view of Rule 1.5.3.b, this is impossible unless
q1 −q′
1 = · · · = qs −q′
s = p −p′ = 0.
□
Remark 1.6.5. Using the Division Algorithm, it is not always possible
to decide whether the element m ∈P r is contained in the submod-
ule ⟨g1, . . . , gs⟩⊆P r . For instance, if n = 2, r = 1, P = Q[x1, x2],
m = x1x2
2 −x1 , g1 = x1x2 + 1, and g2 = x2
2 −1, then we calculate with
respect to Lex the following representation:
x1x2
2 −x1 =
½
g1 · (x2)
g2 · (0)
remainder
−x1 −x2
x1x2
2 + x2
−x1 −x2
Thus we ﬁnd m = q1g1+q2g2+p with q1 = x2 , q2 = 0, and p = −x1−x2 ̸= 0.
But, in fact, the element m = x1 · g2 is in the ideal (g1, g2) ⊆P .
The Division Algorithm allows us to express the residue class of an
element m modulo the submodule generated by {g1, . . . , gs} as a lin-
ear combination of those terms which are not multiples of any term in
{LTσ(g1), . . . , LTσ(gs)}. But the set of those terms is in general not the
desired basis of P r/M , as the following example shows.

1.6 The Division Algorithm
73
Example 1.6.6. In the situation of Example 1.6.2, the Division Algorithm
yields f = (x1 + x2)g1 + g2 + (x1 + x2 + 1). If we use g′
1 = g2 and g′
2 = g1 as
in Remark 1.6.3, we get f = x1g1 + (x1 + 1)g2 + (2x1 + 1). Therefore we see
that x1 −x2 = (2x1 + 1) −(x1 + x2 + 1) is an element of the ideal (g1, g2),
i.e. that x1 and x2 have the same residue class in P/(g1, g2).
But neither x1 nor x2 are multiples of any term in {LTσ(g1), LTσ(g2)}.
Thus we cannot use T2 \ (LTσ(g1), LTσ(g2)) as a set of representatives of a
K -basis of P/(g1, g2).
We conclude this section with a deﬁnition which will be of fundamental
importance when we discuss Buchberger’s Algorithm (see Section 2.5).
Deﬁnition 1.6.7. Let s ≥1, let m, g1, . . . , gs ∈P r \ {0}, and let G be the
tuple (g1, . . . , gs). We apply the Division Algorithm and obtain a represen-
tation m = q1g1 + · · · + qsgs + p with q1, . . . , qs ∈P and p ∈P r . Then the
vector p is called the normal remainder of m with respect to G and is
denoted by NRσ,G(m), or simply by NRG(m) if no confusion can arise. For
m = 0, we let NRG(m) = 0.
In other publications, the normal remainder of a vector is sometimes also
called its normal form with respect to G . However, we shall reserve the
latter notion for a more special situation (see Section 2.4).
Exercise 1. Let n = 2, let P = K[x, y], and let σ = DegRevLex. Apply
the Division Algorithm to divide f by (g1, g2) in the following cases.
a) f = x2 + y2 , g1 = xy −1, g2 = x2 −xy
b) f = x7 −1, g1 = x2 −y, g2 = y2 −x
c) f = x3y3 −x3 −y3 , g1 = xy2 −x2 , g2 = x2y −y2
Exercise 2. Let P = K[x1, . . . , xn], let σ be a term ordering on Tn , let
g ∈P r \ {0}, and let M = ⟨g⟩be the cyclic submodule of P r generated
by g.
a) Prove that LTσ(M) = ⟨LTσ(g)⟩.
b) Show that the residue classes of the terms contained in the set
Tn⟨e1, . . . , er⟩\ {t · LTσ(g) | t ∈Tn} form a K -basis of P r/M .
c) Conclude that dimK(P r/M) = ∞if r > 1.
d) Show that, for every m ∈P r , the Division Algorithm yields the unique
representation of the residue class of m modulo M in terms of the
basis in b).
Exercise 3.
Let f, g1, g2 ∈P = K[x1, x2] be polynomials such that
g1 ∈K[x1] and g2 ∈K[x2]. Then show that NR(g1,g2)(f) = NR(g2,g1)(f).
Exercise 4. Give an example of four polynomials f, g1, g2, g3 ∈Q[x, y, z]
and a term ordering σ such that the normal remainder of f with respect
to G = (g1, g2, g3) never has a degree < deg(f), no matter how G is
ordered.
Exercise 5. Let f = y2z2 −x3 −x, g1 = y3 −x2 −1, and g2 = xy −z2
be polynomials in Q[x, y, z], and let G = (g1, g2). Give an example of a
term ordering σ on T3 such that NRσ,G(f) = 0 and an example of a term
ordering τ on T3 such that NRτ,G(f) ̸= 0.

74
1. Foundations
Tutorial 14: Implementation of the Division Algorithm
In this tutorial we consider several possibilities to implement versions of
the Division Algorithm. As above, let K be a ﬁeld, let n ≥1, let P =
K[x1, . . . , xn], let r ≥1, let σ be a module term ordering on Tn⟨e1, . . . , er⟩,
let s ≥1, and let g1, . . . , gs ∈P r \ {0}.
a) Program a CoCoA function Division(. . .) which takes a non-zero vector
m ∈P r and a list of non-zero vectors G = [g1, . . . , gs], performs the
Division Algorithm, and computes a list [[q1, . . . , qs], p] corresponding to
the representation m = q1g1 + · · · + qsgs + p and having properties a),
b), and c) of Theorem 1.6.4.
Hint: For implementing step 2), you may want to use the CoCoA functions
LPP(...) and LPos(...).
b) In the following cases, use Division(. . .) to compute representations
as above. In all cases, use both PosLex and DegRevLexPos. Check your
answers by applying the built-in CoCoA function DivAlg(. . .).
1) n = 3, r = 2, m = (x2
1 + x2
2 + x2
3, x1x2x3), g1 = (x1, x2), g2 =
(x2, x3), g3 = (x3, x1)
2) n = r = 4, m = (x4
1, x4
2, x4
3, x4
4), g1 = (x1 + 1, 0, 0, 0), g2 = (0, x2 +
1, 0, 0), g3 = (0, 0, x3 + 1, 0), g4 = (0, 0, 0, x4 + 1)
3) n = 2, r = 5, m = (x4
1, x3
1x2, x2
1x2
2, x1x3
2, x4
2), g1 = (x4
1, x3
1, x2
1, x1, 1),
g2 = (1, x2, x2
2, x3
2, x4
2)
c) Given m, g1, . . . , gs ∈P r \ {0}, consider the following sequence of in-
structions.
1) Let i = 1 and q1 = · · · = qs = 0.
2) Find the largest term t ∈Supp(m) which is of the form t = t′ LTσ(gi)
for some t′ ∈Tn . If there exists such a term, let c ∈K \ {0} be its
coeﬃcient in m, replace m by m −
c
LCσ(gi) t′ gi , and add
c
LCσ(gi) t′
to qi .
3) Repeat step 2) as often as possible. When ﬁnally the intersection
Supp(m) ∩(LTσ(gi)) is empty, increase i by one.
4) If i ≤s, continue with step 2). Otherwise set p = m and return the
list [q1, . . . , qs, p].
Show that this is an algorithm, i.e. that it stops after ﬁnitely many steps,
and that it returns a list [[q1, . . . , qs], p] such that q1, . . . , qs ∈P , p ∈P r ,
and m = q1g1 + · · · + qsgs + p.
d) Give an example in which the representation calculated in c) does not
have the properties required in Theorem 1.6.4.
e) Show that, if one repeats the algorithm of c) often enough (i.e. if one
applies it to the element p instead of m, etc.), the representations of m
one gets become eventually stable. Give an example in which this stable
representation still does not agree with the representation calculated by
the Division Algorithm.

1.6 The Division Algorithm
75
f) Implement the algorithm of c) and the procedure described in e) in a
CoCoA function Division2(. . .) and compare its eﬃciency with the func-
tion Division(. . .) by applying it to the test cases of b).
Tutorial 15: Normal Remainders
If we are only interested in the normal remainder of an element m ∈P r with
respect to a tuple of vectors G , we can use a simpliﬁed version of the Division
Algorithm which we want to examine in this tutorial.
Let K be a ﬁeld, P = K[x1, . . . , xn] a polynomial ring over K , σ a
module term ordering on Tn⟨e1, . . . , er⟩, and G = (g1, . . . , gs) ∈(P r)s. To
each vector m ∈P r , we can apply the Normal Remainder Algorithm.
1) Choose the largest term t ∈Supp(m) with respect to σ which is divisible
by one of the leading terms LTσ(g1), . . . , LTσ(gs). If no such term exists,
return m and stop.
2) Find the minimal i ∈{1, . . . , s} such that LTσ(gi) divides t and write
t = t′ LTσ(gi) with t′ ∈Tn.
3) Let c ∈K \{0} be the coeﬃcient of t in m. Replace m by m−
ct′
LCσ(gi)gi
and continue with step 1).
As we shall see, for the purposes of Section 2.5, it will suﬃce to implement
and use this algorithm.
a) Prove that the Normal Remainder Algorithm is an algorithm, i.e. that
it stops after ﬁnitely many steps. Then compare it to the Division Algo-
rithm and show that it returns NRG(m).
b) Write a CoCoA program NormalRemainder(. . .) which computes the nor-
mal remainder of an element m ∈P r with respect to the list of vectors
G using the above algorithm. Do not use the built-in function NR(. . .) of
CoCoA.
c) Apply the program NormalRemainder(. . .) in the following cases, where
K = Q and σ = PosLex.
1) m = x4
1x2 + x4
2x3 + x4
3x1 ∈Q[x1, x2, x3], g1 = x2
1x2 , g2 = x2
2x3 ,
g3 = x2
3x1
2) m = (x3
1 + 1, x3
2 + 1, x3
3 + 1) ∈Q[x1, x2, x3]3 , g1 = (x1, x2, x3),
g2 = (0, x2, x1)
3) m = (x1x2 + x3x4, x1x2x3x4) ∈Q[x1, x2, x3, x4]2 , g1 = (x1, 0), g2 =
(x2, 0), g3 = (0, x3), g4 = (0, x4)
d) Give an example which shows that the normal remainder of an element
m ∈P r depends on the ordering of the elements in G = (g1, . . . , gs).
e) Give an example of an element m ∈⟨g1, . . . , gs⟩⊆P r such that
NRG(m) ̸= 0. Show that if an element m ∈P r does satisfy NRG(m) = 0,
then it is contained in the submodule ⟨g1, . . . , gs⟩⊆P r .

76
1. Foundations
1.7 Gradings
The writer saw that some mathematicians
call this lemma “Nakayama’s lemma”
and therefore the writer asked Nakayama, [...]
what would be the best name for this lemma?
Then, Nakayama kindly answered the writer
that the name of Krull-Azumaya [...]
would be the best name for the lemma.
(Masayoshi Nagata)
This section serves as a link between the ﬁrst chapter and the subsequent
ones. The point is that, in view of Macaulay’s Basis Theorem, we would
like to eﬀectively compute both a basis of a quotient module P r/M and
the representation of every residue class in terms of such a basis. The ﬁrst
attempt to do that was made in the previous section where we studied the
Division Algorithm. We found that in the multivariate case it is a ﬁrst step,
but it does not solve the problem completely. How can we go on?
As happens many times in mathematics, new tools are needed. In partic-
ular, it will turn out to be important to have general notions of graded rings
and modules available. So, in this section we introduce and study quite gen-
eral kinds of gradings, namely rings graded over monoids and modules graded
over monomodules. Two main results are that we characterize homogeneous
ideals and graded submodules by the property that they have homogeneous
sets of generators (see Proposition 1.7.10) and that it is possible to repre-
sent homogeneous elements in terms of those generators using homogeneous
coeﬃcients of complementary degree (see Corollary 1.7.11).
In the last part of the section, we prove two useful results about rings
graded over monoids carrying a monoid ordering. We characterize homoge-
neous prime ideals (see Proposition 1.7.12), and we prove a graded version of
Nakayama’s Lemma (see Proposition 1.7.15). Not all results in this section
are given in their greatest generality, but they will be general enough for our
later applications.
Recall that in this book all monoids and rings are assumed to be commu-
tative. Throughout this section, let R be a ring and M an R-module.
Deﬁnition 1.7.1. Let (Γ, +) be a monoid.
a) The ring R is called a Γ -graded ring (or a (R, Γ)-graded ring, or
graded over Γ ) if there exists a family of additive subgroups {Rγ}γ∈Γ
such that
1) R = ⊕γ∈Γ Rγ ,
2) Rγ · Rγ′ ⊆Rγ+γ′ for all γ, γ′ ∈Γ .
b) The elements of Rγ are called homogeneous of degree γ . For r ∈Rγ
we write deg(r) = γ .

1.7 Gradings
77
c) If r ∈R and r = P
γ∈Γ rγ is the decomposition of r according to a.1),
where rγ ∈Rγ , then rγ is called the homogeneous component of
degree γ of r.
If R is a Γ -graded ring, then 0 is a homogeneous element of R of every
degree. Moreover, the decomposition of every element into its homogeneous
components is unique, since in Deﬁnition 1.7.1.a we have a direct sum. If the
cancellation law holds in Γ , then the set R0 is a subring of R, and for every
γ ∈Γ the set Rγ is an R0 -module.
The following two examples constitute the most important situations in
which we shall meet Γ -graded rings.
Example 1.7.2. Let S be a ring, let n ≥1, and let P = S[x1, . . . , xn] be
a polynomial ring over S . If we let
Pd = {f ∈P | deg(t) = d for all t ∈Supp(f)}
for d ≥0, we make P into an N-graded ring. This grading is called the
standard grading of P . It satisﬁes deg(x1) = · · · = deg(xn) = 1. For
d ≥0, the elements of Pd are called homogeneous polynomials (or forms)
of degree d.
Example 1.7.3. Let S be a ring, let n ≥1, and let P = S[x1, . . . , xn] be
a polynomial ring over S . For each (α1, . . . , αn) ∈Nn , we let P(α1,...,αn) =
S · xα1
1 · · · xαn
n . It is clear that in this way P = ⊕(α1,...,αn)∈NnP(α1,...,αn)
becomes an Nn-graded ring. We can also view P as a Zn-graded ring if we
deﬁne P(α1,...,αn) = 0 for every (α1, . . . , αn) ∈Zn such that αi < 0 for some
i ∈{1, . . . , n}.
A natural way to extend Deﬁnition 1.7.1 to cover R-modules would be
to use the monoid Γ again as the set of possible degrees. As we shall see in
Section 2.3, this is not suﬃciently general, so that we have to resort to the
following notion.
Deﬁnition 1.7.4. Let (Γ, +) be a monoid, let R be a Γ -graded ring, let
(Σ, ∗) be a Γ -monomodule, and let M be an R-module. We say that M
is a Σ -graded R-module (or a Σ -graded (R, Γ)-module, or simply a
graded R-module if Σ = Γ ) if there exists a family of subgroups {Ms}s∈Σ
such that
1) M = ⊕s∈ΣMs ,
2) Rγ · Ms ⊆Mγ∗s for all γ ∈Γ and all s ∈Σ .
For the remainder of this section, we let (Γ, +) be a monoid in which the
cancellation law holds, R a Γ -graded ring, (Σ, ∗) a Γ -monomodule, and M
a Σ -graded R-module. Then the set Ms is an R0 -module for every s ∈Σ .
Let us have a look at the quintessential example of a Σ -graded R-module.

78
1. Foundations
Example 1.7.5. Let S be a ring, let n ≥1, and let P = S[x1, . . . , xn]
be a polynomial ring over S equipped with the Nn -grading deﬁned in Ex-
ample 1.7.3. Via the isomorphism log : Tn −→Nn , we shall view this as a
Tn-grading. For r ≥1, the set of terms Tn⟨e1, . . . , er⟩of the P -module P r
is a Tn -monomodule. Now we let (P r)tei = Stei for t ∈Tn and 1 ≤i ≤r,
i.e. for tei ∈Tn⟨e1, . . . , er⟩. It is easy to check that this makes P r into a
Tn⟨e1, . . . , er⟩-graded P -module.
Given a Σ -graded R-module, there exists a cheap way of making more
Σ -graded R-modules called shifting degrees. Modules obtained by shifting
degrees in R itself are the basic building blocks in the construction of graded
free resolutions in Volume 2.
Deﬁnition 1.7.6. Let γ ∈Γ be a ﬁxed element such that the multiplication
map µγ : Σ −→Σ deﬁned by s 7→γ ∗s is injective. For instance, if the left-
cancellation law holds in Σ , this assumption is satisﬁed for all γ ∈Γ .
a) For every s ∈Σ , we deﬁne M(γ)s = Mγ∗s. Then we let M(γ) =
⊕s∈ΣM(γ)s. It is easy to check that in this way we get a Σ -graded
R-module M(γ). We call it the module obtained by shifting degrees
by γ . If the map µγ : Σ −→Σ is bijective, the set underlying M(γ)
agrees with M .
b) Modules of the form ⊕i∈IR(γi), where I is a set and γi ∈Γ for all i ∈I ,
will be called Γ -graded free R-modules. Here we let (⊕i∈IR(γi))γ =
⊕i∈IR(γi)γ for all γ ∈Γ .
Having deﬁned Γ -graded rings and Σ -graded R-modules, we also need
the appropriate sets of homomorphisms between those objects.
Deﬁnition 1.7.7. Let S be another ring which is graded over a monoid
(Γ ′, +), and let N be another Σ -graded R-module.
a) For a ring homomorphism ϕ : R →S and a homomorphism of monoids
ψ : Γ →Γ ′ , we call (ϕ, ψ) (or simply ϕ) a homomorphism of graded
rings if ϕ(Rγ) ⊆Sψ(γ) for every γ ∈Γ .
b) An R-linear map λ : M →N is called a homomorphism of Σ -graded
R-modules or a homogeneous R-linear map if λ(Ms) ⊆Ns for all
s ∈Σ .
For instance, let γ ∈Γ be an invertible element, and let r ∈Rγ . Then
the R-linear map µr : R(−γ) →R deﬁned by r′ 7→rr′ is a homomorphism
of graded R-modules.
Next we want to introduce the “correct” kind of subobjects of graded rings
and modules. Note that if we equip P = K[x] with the standard grading and
let I = (x −1) ⊆P , then it is clear that I ∩Pd = (0) for every d ∈N.
Somehow this suggests that I does not “inherit” the grading of P . In other
words, what we really need is that the canonical injective map I ,−→P is
a homomorphism of graded R-modules. Spelling this out in concrete terms,
we arrive at the following deﬁnition.

1.7 Gradings
79
Deﬁnition 1.7.8. An R-submodule N of the Σ -graded R-module M is
called a Σ -graded R-submodule of M if we have N = ⊕s∈Σ(N ∩Ms).
A Γ -graded submodule of R is also called a Γ -homogeneous ideal
of R, or simply a homogeneous ideal of R if Γ is clear from the context.
Remark 1.7.9. Let N ⊆M be a Σ -graded R-submodule. We can equip
the residue class module M/N with the structure of a Σ -graded R-module
by deﬁning (M/N)s = Ms/Ns for every s ∈Σ . Thus the canonical homo-
morphism M −→M/N becomes a homomorphism of Σ -graded R-modules.
In particular, the residue class ring R/I of R by a homogeneous ideal is
again a Γ -graded ring.
For practical purposes, the following proposition and its corollary are most
useful. They allow us to quickly prove that some submodule is Σ -graded by
exhibiting a homogeneous system of generators, and to use this fact to get
“nice” representations of arbitrary homogeneous elements in terms of those
homogeneous generators.
Proposition 1.7.10. Let N ⊆M be an R-submodule, and let Ns = N ∩Ms
for all s ∈Σ . Then the following conditions are equivalent.
a) N = ⊕s∈ΣNs
b) If n ∈N and n = P
s∈Σ ns is the decomposition of n into its homoge-
neous components, then ns ∈N for all s ∈Σ .
c) There is a system of generators of N which consists of homogeneous
elements.
Proof.
First we show a) ⇒b). Choose an element n ∈N and let n =
P
s∈Σ ns be its decomposition according to a), where ns ∈Ns for all s ∈Σ .
Since ns ∈Ns ⊆Ms and M = ⊕s∈ΣMs , this is also the decomposition of n
into its homogeneous components in M . Thus the homogeneous components
of n lie in N .
Implication b) ⇒c) follows by taking all homogeneous components of
a system of generators of N . Now we show c) ⇒a). Let {nβ | β ∈B}
be a homogeneous system of generators of N and let n ∈N . We write
n = P
β∈B rβnβ with elements rβ ∈R. For each β ∈B we decompose
rβ = P
γ∈Γ rβ,γ into its homogeneous components. Then
n =
X
β∈B
X
γ∈Γ
rβ,γnβ =
X
s∈Σ
³
X
{(β,γ) | γ∗deg(nβ)=s}
rβ,γnβ
´
∈
X
s∈Σ
Ns
shows N = P
s∈Σ Ns , and from M = ⊕s∈ΣMs we get that this sum is
direct.
□
Corollary 1.7.11. Suppose that the right-cancellation law holds in Σ . Let
N ⊆M be a Σ -graded R-submodule, let {nβ | β ∈B} be a set of ho-
mogeneous generators of N , and let s ∈Σ . Every element n ∈Ns has a
representation n = P
β∈B rβnβ with homogeneous elements rβ ∈R such
that deg(rβ) ∗deg(nβ) = s for every β ∈B.

80
1. Foundations
Proof.
Let n = P
β∈B aβnβ with aβ ∈R for β ∈B. We decompose aβ as
the sum of its homogeneous components and group them by writing aβ =
a′
β + a′′
β , where a′
β is the unique homogeneous component of aβ such that
deg(a′
β) ∗deg(nβ) = s. We get n = P
β∈B a′
βnβ + P
β∈B a′′
βnβ . Equivalently,
we have 0 = (P
β∈B a′
βnβ −n) + P
β∈B a′′
βnβ . By construction, the element
P
β∈B a′
βnβ −n is a homogeneous component of this sum, i.e. it has to be
zero.
□
In the preceding proof we used the assumption that the right-cancellation
law holds in Σ in order to have a′
β uniquely singled out by the relation
deg(a′
β) ∗deg(nβ) = s. We leave the generalization to the reader (see Exer-
cise 9).
For the remainder of this section, we shall assume that we are also given a
monoid ordering τ on Γ . By Remark 1.4.2.b, this implies that the monoid Γ
is inﬁnite. We can characterize homogeneous prime ideals by the usual prop-
erty applied to homogeneous elements only.
Proposition 1.7.12. Let p be a homogeneous proper ideal in R. Then the
following conditions are equivalent.
a) The ideal p is a prime ideal.
b) If fg ∈p for homogeneous elements f, g ∈R, then f ∈p or g ∈p.
Proof.
It suﬃces to show that b) implies a). Let f, g ∈R be two elements
such that fg ∈p. We decompose them into their homogeneous components.
If we allow some components to be zero, we may assume that the two sets
of degrees are identical, i.e. that we have f = fγ1 + · · · + fγs and g =
gγ1 + · · · + gγs , where γ1 <τ · · · <τ γs . For a contradiction, we assume that
the numbers i = min{k ∈N | fγk /∈p} and j = min{k ∈N | gγk /∈p} exist.
Now we look at the homogeneous component of degree γi + γj of fg. It is
given by the formula
fγigγj +
X
{(k,l)|γk+γl=γi+γj}
fγkgγl
Since γk <τ γi or γl <τ γj for every summand above, we have k < i or
l < j , and therefore fγkgγl ∈p. Hence also fγigγj belongs to p, and the
hypothesis implies fγi ∈p or gγj ∈p, a contradiction.
□
Although neither of the two equivalent conditions in the previous propo-
sition contains any reference to τ , the existence of such a monoid ordering is
instrumental for the claim to hold, as our next example shows.
Example 1.7.13. Let R = Z[i] be the ring of Gaußian numbers (see Tu-
torial 4), i.e. the Z-subalgebra of C generated by {i}. If we use the group
Γ = Z/(2), we see that R is a Γ -graded ring with R0 = Z and R1 = Zi.
Let us consider the ideal I = (2) in R. It is not a prime ideal, since

1.7 Gradings
81
(1−i)(1+i) = 2 and neither 1−i nor 1+i is in I . However, if f, g ∈R are
homogeneous elements such that fg ∈I , then f ∈I or g ∈I . This follows,
because either f, g ∈R0 or f, g ∈R1 , and in both cases the fact that 2 is a
prime number shows the claim.
Our last goal in this section is to prove a version of Nakayama’s famous
lemma adapted to graded modules. First, we need the following result.
Lemma 1.7.14. If τ is a term ordering on Γ , then R+ = ⊕γ>τ 0Rγ is a
homogeneous ideal of R.
Proof.
It suﬃces to show R · R+ ⊆R+ . This follows from the fact that
every element is a ﬁnite sum of homogeneous elements, and for homogeneous
elements f ∈Rγ , g ∈Rγ′ with γ, γ′ ∈Γ and γ′ >τ 0 we have fg ∈Rγ+γ′
with γ + γ′ >τ γ ≥τ 0 by Deﬁnition 1.4.1.
□
Proposition 1.7.15. (Graded Version of Nakayama’s Lemma)
Let τ be a term ordering on Γ and σ a well-ordering on Σ which is compat-
ible with τ . Suppose that the right-cancellation law holds in Σ . Let M1, M2
be two Σ -graded R-submodules of M such that M1 ⊆M2 ⊆M1 + R+ · M2 .
Then M1 = M2 .
Proof.
It suﬃces to show M2 ⊆M1 . Suppose that this is not the case.
By Proposition 1.4.18, there exists a homogeneous element m ∈M2 \ M1
of minimum degree with respect to σ. Using the hypothesis and Corol-
lary 1.7.11, we see that there exist homogeneous elements m′ ∈M1 ,
g1, . . . , gs ∈M2 , and f1, . . . , fs ∈R+ such that m = m′ + Ps
i=1 figi and
such that deg(fi) ∗deg(gi) = deg(m) for i = 1, . . . , s. Since deg(fi) >τ 0 for
i = 1, . . . , s, the degrees of the elements g1, . . . , gs are less than the degree
of m. The choice of m then implies g1, . . . , gs ∈M1 . Consequently, we get
m ∈M1 , a contradiction.
□
Corollary 1.7.16. Let τ be a term ordering on Γ and σ a well-ordering
on Σ which is compatible with τ . Suppose that the right-cancellation law
holds in Σ .
a) A set of homogeneous elements m1, . . . , ms ∈M generates the R-mod-
ule M if and only if their residue classes m1, . . . , ms in M/(R+ · M)
generate this residue class module.
b) If R0 is a ﬁeld, every homogeneous system of generators of M contains
a minimal one.
Proof.
To prove a), it suﬃces to show the implication “⇐”. Let N be the
graded submodule of M generated by {m1, . . . , ms}. By assumption we have
M ⊆N + R+ · M . Therefore Nakayama’s Lemma yields M = N .
The proof of b) follows from a), from R/R+ ∼= R0 , and from the fact
that every system of generators of the R0 -module M/(R+ · M) contains a
basis.
□

82
1. Foundations
Exercise 1. Let Γ be a monoid in which the cancellation law holds, and
let R be a Γ -graded ring. Prove that 1 ∈R0 .
Hint: Write 1 = P
γ∈Γ rγ and show that r0 = 1.
Exercise 2.
Let Γ = {0, ∞} be the monoid deﬁned in Exercise 2 of
Section 1.3, and let R be a ring.
a) Deﬁne deg(r) = ∞for all r ∈R. Show that this makes R into a Γ -
graded ring in which the element 1 is homogeneous of some non-zero
degree.
b) Equip S = R ⊕R with componentwise addition and multiplication,
and let S0 = R⊕0 as well as S∞= 0⊕R. Show that this makes S into
a Γ -graded ring in which the element 1 = (1, 1) is not homogeneous.
Exercise 3.
Let R be a ring, let P = R[x1, . . . , xn], and let r ≥1.
Check that the deﬁnition Pt = R·t for t ∈Tn makes P into a Tn -graded
ring, and that P r together with the grading deﬁned in Example 1.7.5 is a
Tn⟨e1, . . . , er⟩-graded P -module.
Exercise 4.
Let K be a ﬁeld, let R = K[x], let Γ = N, and let
Rγ = {c(x −1)γ | c ∈K} for all γ ∈Γ .
a) Show that R is a Γ -graded ring.
b) Prove that I = (x) is not a homogeneous ideal of R.
c) Give an example of a homogeneous ideal of R.
Exercise 5.
Check that the set M(γ) = ⊕s∈ΣM(γ)s , as introduced
in Deﬁnition 1.7.6, is indeed a Σ -graded R-module. Then consider an
element r ∈Rγ and the map M −→M(γ) deﬁned by m 7→rm, and
show that it is a homomorphism of Σ -graded R-modules.
Exercise 6. Let K be a ﬁeld, let R = K[x1, x2], let Γ = N2 , and let
R(α1,α2) = {cxα1
1 xα2
2
| c ∈K} for (α1, α2) ∈N2 as in Example 1.7.3.
Furthermore, let Γ ′ = N and let Rγ′ be the K-vector space generated by
{xα1
1 xα2
2
| α1 + α2 = γ′} for γ′ ∈Γ ′ . In this way, R becomes both a Γ -
and a Γ ′ -graded ring. Finally, let ϕ : R →R be the identity map and
ψ : Γ →Γ ′ the map deﬁned by ψ((α1, α2)) = α1 + α2 . Show that (ϕ, ψ)
is a homomorphism of graded rings.
Exercise 7. Let R be a Γ -graded ring and S ⊆R a subring. Discuss
whether and how one can equip S with a Γ -grading in such a way that
the inclusion S ,→R becomes a homomorphism of graded rings.
Exercise 8. Let Γ be a monoid in which the cancellation law holds. A
Γ -graded ring R = ⊕γ∈Γ Rγ is called a Γ -graded ﬁeld if every homoge-
neous element of R \ {0} is a unit. Let R be a Γ -graded ﬁeld.
a) Prove that R0 is a ﬁeld, and that for every γ ∈Γ the R0 -vector
space Rγ has dimension ≤1. (Hint: Use Exercise 1.)
b) Give an example of a Γ -graded ﬁeld which is not a ﬁeld. (Hint: Con-
sider the ring K[x, x−1].)
c) Show that {γ ∈Γ | Rγ ̸= 0} is a group.
d) Let M be a ﬁnitely generated Γ -graded R-module. Prove that M
has an R-basis consisting of homogeneous elements. (Hint: Start with
a minimal homogeneous system of generators and show that it is a
basis.)

1.7 Gradings
83
Exercise 9. Modify the statement of Corollary 1.7.11 to generalize it to
the case of a monomodule Σ in which the right-cancellation law does not
necessarily hold.
Exercise 10. Give an example of a ring R graded over a monoid (Γ, +)
such that there exists a monoid order σ on Γ , but R+ = ⊕γ>σ0Rγ is not
an ideal of R.
Tutorial 16: Homogeneous Polynomials
Recall that the standard grading on the polynomial ring P = K[x1, . . . , xn]
over a ﬁeld K was deﬁned by Pd = {f ∈P | deg(t) = d for all t ∈Supp(f)}
for d ∈N in Example 1.7.2, and that the elements of Pd are called homoge-
neous polynomials of degree d.
In this tutorial we want to get a better understanding of the space Pd of
homogeneous polynomials of degree d. We want to know its dimension and
to characterize its elements.
a) Show that Pd is a K -vector space of dimension
¡n+d−1
d
¢
for all d ∈N.
b) Find and prove a formula which computes the dimension of the quotient
vector space of Pd/V , where V is the subspace of polynomials which are
divisible by x1 .
c) Let K be an inﬁnite ﬁeld. Suppose that f ∈P satisﬁes f(a1, . . . , an) = 0
for every (a1, . . . , an) ∈Kn. Then show that f = 0.
d) Produce an example which shows that the above statement is false if K
is ﬁnite.
e) Prove that if f ∈P is a non-zero homogeneous polynomial of degree d,
then f(λa1, . . . , λan) = λd · f(a1, . . . , an) holds for all λ ∈K and all
(a1, . . . , an) ∈Kn.
f) Prove that the converse of e) holds if K has at least max{deg(f), d} + 1
elements.
Now consider the following non-standard grading on P = K[x1, x2]. We
declare x1 to be homogeneous of degree 2 and x2 to be homogeneous of
degree 1. Then we let Pd = {f ∈P | 2α1 + α2 = d for all xα1
1 xα2
2
∈
Supp(f)} ∪{0} for all d ∈N.
g) Prove this deﬁnition makes P into a N-graded ring.
h) Explicitly describe the function from N to N which maps d to dimK(Pd),
i.e. ﬁnd a formula for dimK(Pd).
i) Modify e) above to ﬁt this case.


2. Gr¨obner Bases
A threat is stronger than its execution.
(Aaron Nimzowitch)
Towards the end of Chapter 1 we encountered Macaulay’s Basis Theorem.
It says that, given a polynomial ring P = K[x1, . . . , xn] over a ﬁeld K and a
P -submodule M of P r , one can attack the problem of computing a K -basis
of the quotient module P r/M if one knows LTσ(M) for some term ordering
σ. But we saw that the leading terms of a set of generators of M do not
necessarily generate LTσ(M).
Thus the opening sections of this chapter are variations on the theme that
not all systems of generators of a module are equal. Some are more special
than others. In Section 2.1 we ﬁnd that the leading terms of a system of non-
zero generators {g1, . . . , gs} of M generate LTσ(M) if and only if it is special
in the following sense: for every m ∈M \ {0} there exists a representation
m = Ps
i=1 figi with f1, . . . , fs ∈P such that LTσ(m) ≥σ LTσ(figi) for all
i = 1, . . . , s such that fi ̸= 0.
Then we change our strategy and attack systems of generators from
another side. Given a term ordering σ on Tn⟨e1, . . . , er⟩, every element
g ∈P r \ {0} can be split as g = LMσ(g) −g′ . By looking at this equa-
tion modulo ⟨g⟩, we can view g as a rewrite rule, namely the rule which
substitutes LMσ(g) with the element g′ which represents the same residue
class. If we have a bunch of non-zero vectors {g1, . . . , gs}, we get a bunch of
rewrite rules. What kind of game can we play with those rules?
Suppose a vector m ∈P r contains a term in its support which is a mul-
tiple of LTσ(gi) for some i ∈{1, . . . , s}. Then we can use the rule associated
to gi and rewrite m. The element obtained in this way is congruent to m
modulo M . The procedure of moving from one representative of this residue
class to another resembles the division algorithm. However, at each point we
may have several moves available, and a diﬀerent order of those moves could
lead to a diﬀerent result. A generating set {g1, . . . , gs} of M is special if,
no matter which order you choose, you always arrive at the same result. In
Section 2.2, we treat rewrite rules and prove the surprising fact that this new
kind of specialty is equivalent to the ones described before.
However, the most fundamental motive for looking at special systems of
generators is still missing. The notion of a syzygy of a tuple (g1, . . . , gs) is

86
2. Gr¨obner Bases
one of the decisive ideas for successful applications of Computational Com-
mutative Algebra. Using the theory of gradings developed in Section 1.7, we
show that every syzygy of (LTσ(g1), . . . , LTσ(gs)) can be lifted to a syzygy
of (g1, . . . , gs) if and only if {g1, . . . , gs} has the special properties discussed
earlier.
After threatening to do it for a long time, we ﬁnally combine all those
ideas and introduce Gr¨obner bases. A Gr¨obner basis of a submodule M of P r
is a set of generators which is special in one (and therefore all) of the above
ways. In Section 2.4 we launch an investigation into their properties and uses
by showing that their existence can be viewed as a consequence of Dickson’s
Lemma. Most applications of Gr¨obner bases will be treated in Chapter 3 and
Volume 2, but some rewards for our careful preparations can be reaped imme-
diately, for instance a proof of Hilbert’s Basis Theorem, the notion of normal
forms, the submodule membership test, and a new version of Macaulay’s
Basis Theorem.
Next we put a great emphasis on the derived notion of a reduced Gr¨obner
basis. It has the astonishing property that, given a submodule M of P r
and a term ordering σ, it is a unique system of generators of M satisfying
certain natural conditions. We believe that this is one of the most ubiquitous
theoretical tools in Computational Commutative Algebra. Just to give the
ﬂavour of its importance, we show how one can use it to deduce a seemingly
unrelated result about the existence and uniqueness of the ﬁeld of deﬁnition
of submodules of P r .
After all this theory, it is time to explain how one can actually step into
action and compute a Gr¨obner basis of M from a given ﬁnite set of gener-
ators. The power of our study of syzygies enables us to capture the spirit of
Buchberger’s Algorithm in Section 2.5. Not only shall we prove and improve
its basic procedure, but we shall also ﬁnally achieve our goal of eﬀectively
computing in residue class modules via Macaulay’s Basis Theorem and nor-
mal forms.
As sometimes happens in real life, including science, the discovery of a
tool which enables us to solve one problem opens the door to many other
discoveries. Gr¨obner bases are certainly one of those tools, but before delving
into the realm of their applications, we close the chapter with another one,
namely Hilbert’s Nullstellensatz. This theorem is one of the milestones in
the process of translating algebra into geometry and geometry into algebra
and forms the background for many applications in algebraic geometry. Sec-
tion 2.6 is entirely devoted to its proof, which also uses some pieces of Gr¨obner
basis theory. It highlights the importance of switching from one ground ﬁeld
to a ﬁeld extension, so that the geometric notion of an aﬃne variety gets its
proper perspective.
Once more the chapter closes with an opening theme. Besides being a
metaphor of life, this end of one struggle already lays the groundwork for
successful applications in subsequent chapters.

2.1 Special Generation
87
2.1 Special Generation
All animals are equal.
But some animals are more equal than others.
(George Orwell)
Let f be a non-zero polynomial and g a non-zero polynomial in the
principal ideal generated by f , i.e. let g = hf for a suitable polynomial h. If
σ is a monoid ordering on Tn , then LTσ(g) = LTσ(hf) = LTσ(h) LTσ(f). In
other words, the leading term of every element in the principal ideal generated
by f is in the ideal generated by LTσ(f).
On the other hand, let us go back for a moment to Example 1.5.5. We
saw that for f = y(x2 −1) −x(xy −1) = x −y and σ = DegLex the
leading monomials of the two summands cancel out, so that x, the leading
term of the result, is smaller than the leading terms of the summands. This
shows that some generators have a special behaviour with respect to the
leading terms of the elements they generate. More precisely, we see that
x = LTσ(f) /∈(LTσ(x2 −1), LTσ(xy −1)) = (x2, xy). However, if we add in
this example the elements guaranteed by Proposition 1.5.6.b, we get another
set of generators of the ideal (x2 −1, xy −1) whose leading terms generate
the leading term ideal.
This is the prototypical case of the phenomenon that not all systems of
generators of an ideal or module are equal alluded to in the introduction of
this chapter. Some systems of generators have special properties which we
want to describe in this and the following sections. Later it will become clear
that all of those properties are incarnations of the same concept, namely the
concept of Gr¨obner bases.
As usual, we let K be a ﬁeld, n ≥1, P = K[x1, . . . , xn] a polynomial
ring, r ≥1, and σ a module term ordering on Tn⟨e1, . . . , er⟩.
Proposition 2.1.1. (Special Generation of Submodules)
Let M ⊆P r be a P -submodule, and let g1, . . . , gs ∈P r \ {0}. Then the
following conditions are equivalent.
A1) For every element m ∈M \ {0}, there are f1, . . . , fs ∈P such that
m = Ps
i=1 figi and LTσ(m) ≥σ LTσ(figi) for all i = 1, . . . , s such that
figi ̸= 0.
A2) For every element m ∈M \{0}, there are f1, . . . , fs ∈P such that m =
Ps
i=1 figi and LTσ(m) = maxσ{LTσ(figi) | i ∈{1, . . . , s}, figi ̸= 0}.
Proof.
Since Condition A2) obviously implies A1), it suﬃces to prove the
reverse direction. The inequality “≥σ ” in A2) follows immediately from A1).
The inequality “≤σ ” in A2) follows from Proposition 1.5.3.a.
□
If M ⊆P r is a P -submodule and g1, . . . , gs ∈M \ {0}, then Condi-
tions A1) and A2) say that {g1, . . . , gs} is a special system of generators
of M . Using the example mentioned above, we see that it is not true that

88
2. Gr¨obner Bases
Conditions A1) and A2) hold for every system of generators of M , because
LTσ(f) <σ maxσ{x2, xy} ≤σ maxσ{LTσ(f1(x2 −1)), LTσ(f2(xy −1))}, in-
dependent of which elements f1, f2 ∈P \ {0} we choose.
It is also interesting to observe that if τ is a term ordering on Tn and σ is
a module term ordering on Tn⟨e1, . . . , er⟩which is compatible with τ , then
we can expand LTσ(figi) = LTτ(fi) LTσ(gi) in the above statements.
The intuitive meaning of Conditions A1) and A2) is that every element
m ∈M \ {0} should have a representation m = Ps
i=1 figi such that the
highest term which occurs in the computation of the right-hand side does
not cancel. Consequently, the leading term of m is a multiple of one of the
terms LTσ(g1), . . . , LTσ(gs). Now we examine this last property more closely.
Proposition 2.1.2. (Generation of Leading Term Modules)
Let M ⊆P r be a P -submodule and g1, . . . , gs ∈M \{0}. Then the following
conditions are equivalent.
B1) The set {LTσ(g1), . . . , LTσ(gs)} generates the Tn-monomodule LTσ{M}.
B2) The set {LTσ(g1), . . . , LTσ(gs)} generates the P -submodule LTσ(M)
of Pr .
Proof.
Since B1) implies B2) by deﬁnition, it suﬃces to show the reverse
direction. Let m ∈M \ {0}, and let LTσ(m) = f1 LTσ(g1) + · · · + fs LTσ(gs)
for some polynomials f1, . . . , fs ∈P . By Proposition 1.5.3.a, the term
LTσ(m) is in the support of one of the vectors f1 LTσ(g1), . . . , fs LTσ(gs).
Thus there is an index i ∈{1, . . . , s} and a term t ∈Supp(fi) such that
LTσ(m) = t · LTσ(gi).
□
Finally, we show the ﬁrst important link between the two properties of
special systems of generators which we have described so far.
Proposition 2.1.3. Let M ⊆P r be a P -submodule, and let g1, . . . , gs be
non-zero elements of M . Then Conditions A1), A2) of Proposition 2.1.1
and Conditions B1), B2) of Proposition 2.1.2 are equivalent.
Proof.
Condition A2) implies B1) by Proposition 1.5.3.d. Thus we show
B1) ⇒A1). Suppose there exists an element m ∈M \ {0} which cannot
be represented in the desired way. By Theorem 1.4.19, there exists such an
element m with minimal leading term with respect to σ. By B1), we have
LTσ(m) = t · LTσ(gi) for some i ∈{1, . . . , s} and some t ∈Tn . Clearly, we
have m −LCσ(m)
LCσ(gi)tgi ̸= 0, since m = LCσ(m)
LCσ(gi)tgi would be a representation
satisfying A1). Therefore we ﬁnd LTσ(m −LCσ(m)
LCσ(gi)tgi) <σ LTσ(m), and the
element m−LCσ(m)
LCσ(gi)tgi ∈M \{0} can be represented as required in A1). But
then also m can be represented as required in A1), in contradiction with our
assumption.
□

2.1 Special Generation
89
Exercise 1. Give an example of a term ordering σ, a module M ⊆P r,
and a set of elements {g1, . . . , gs} ⊆P r \M which satisﬁes Conditions A1)
and A2).
Exercise 2. Let K be a ﬁeld, let P = K[x1, . . . , xn], let σ be a term
ordering on Tn , let g1, g2 ∈P be two K -linearly independent linear
polynomials, and let i1, i2 ∈{1, . . . , n} be such that xi1 = LTσ(g1) and
xi2 = LTσ(g2). Prove that the following conditions are equivalent.
a) Conditions A1) and A2) hold for g1 , g2 .
b) xi1 ̸= xi2
Exercise 3.
Prove that for r = 1 and σ = RevLex, Conditions B1)
and B2) are strictly weaker than A1) and A2).
Exercise 4.
Let r = 1 and σ = DegLex. Show that the polynomials
g1 = x1x2 −x2 and g2 = x2
1 −x2 do not have properties B1) and B2).
Find LTDegLex((g1, g2)) and a third polynomial g3 ∈(g1, g2) such that
{g1, g2, g3} satisﬁes B1) and B2).
Exercise 5.
Let σ be a term ordering on T2 , and let g1 = x3 −1
and g2 = y3 −y. Prove that {g1, g2} satisﬁes B1) and B2). Represent
f = x3y + xy3 −x3 −xy −y + 1 as a combination of g1 and g2 according
to Condition A1).
Tutorial 17: Minimal Polynomials of Algebraic Numbers
In this tutorial we let K be a ﬁeld and L = K[x]/(f) a ﬁnite extension ﬁeld
of K , where f ∈K[x] is an irreducible polynomial of degree d. We represent
an element ℓ∈L as the residue class of a polynomial g ∈K[x] and ask the
following question.
How can one compute the minimal polynomial of ℓover K ?
Below we shall develop two elementary approaches to this question. In
Section 3.6, we shall see a more general method for determining the minimal
polynomial of an element in an arbitrary ﬁnitely generated K -algebra.
a) Let ¯x be the residue class of x in L. Show that {1, ¯x, . . . , ¯xd−1} is a
K -basis of L and conclude that the minimal polynomial of ℓover K
has degree ≤d.
b) For i = 0, . . . , d, let ai ∈K be the coeﬃcient of xi in the minimal
polynomial of ℓover K and hi ∈K[x] the remainder of the division
of gi by f . Prove a0 + a1h1 + · · · + adhd = 0 and show that this yields a
system of d linear equations for a0, . . . , ad. Explain how we can use its
solution space to answer our question.
c) Implement the method developed in b) in a CoCoA function LinAlgMP(. . .)
which takes f and g and computes the minimal polynomial of ℓover K .
Hint: You may use the CoCoA function Syz(. . .) to ﬁnd the solution space
of a system of linear equations.

90
2. Gr¨obner Bases
d) Apply your function LinAlgMP(. . .) to compute the minimal polynomials
over Q of the following algebraic numbers.
1)
1
2 + i
2
√
3
2)
4√
2 +
√
2 + 2
3) (¯x3+¯x−1)/¯x, where f = x5−x−2. (Hint: Notice that 1
¯x = 1
2 ¯x4−1
2 .)
e) Now we consider the ideal I = (x2−g(x1), f(x1)) ⊆K[x1, x2]. Prove that
a polynomial h ∈K[x2] satisﬁes h(ℓ) = 0 if and only if h ∈I . Conclude
that the minimal polynomial of ℓover K is an element of minimal degree
in the principal ideal I ∩K[x2]. (Hint: Show that K[x1, x2]/I ∼= L.)
f) Prove that LTLex(I) contains a power of x2 . Conclude that, in order to
ﬁnd the minimal polynomial of ℓover K , it suﬃces to compute a system
of generators of I which satisﬁes Conditions B1) and B2) with respect
to Lex.
g) Write a CoCoA function LexMP(. . .) which takes f and g and computes
the minimal polynomial of ℓover K using the method developed in f).
(Hint: You may assume that the base ring is Q[x[1], x[2]], Lex and apply
the CoCoA function LT(I).) Use your function LexMP(. . .) to check your
results in d).
h) Compute the minimal polynomial of (¯x3 + ¯x −1)/¯x5 over Q in the case
f = x7 −x −1 using both LinAlgMP(. . .) and LexMP(. . .). Write down
the two polynomials whose leading terms generate LTLex(I) = (x1, x7
2).
Which of the two methods is in general more eﬃcient? Why?
i) Develop diﬀerent methods for computing the representation of ℓ−1 in
the K -basis {1, ¯x, . . . , ¯xd−1} of L using the following ideas.
1) Linear Algebra
2) The Extended Euclidean Algorithm
Prove the correctness of your methods. Then write two CoCoA functions
LinAlgInv(. . .) and ExtEucInv(. . .), and compare the results in the cases
of d).

2.2 Rewrite Rules
91
2.2 Rewrite Rules
All roads lead to Rome.
(Roman Proverb)
All roads do not lead to Rome.
(Slovenian Proverb)
Let us go back to the Division Algorithm discussed in Section 1.6 and try
to understand its working more deeply. What is its essence? If we look at
Theorem 1.6.4, we see that the event which triggers steps 2) and 3) is the
detection of a term in the support of m which is a multiple of one of the
leading terms LTσ(g1), . . . , LTσ(gs). Once such a term is found, the basic
operation is to replace it by smaller terms.
A closer look at what happens is provided by the following example. Let
f = x2y, g1 = x2 −x + 1, g2 = xy −x −y + 3, and let σ = DegLex.
Since x2y is a multiple of LTσ(g1), the ﬁrst step of the Division Algorithm
applied to f and (g1, g2) yields f = y · g1 + 0 · g2 + (f −yg1), and we ﬁnd
f −yg1 = y(x −1). In this ﬁrst step we have replaced f by f −yg1 . The
core of this operation is to take g1 , write it as x2 −(x −1), and replace x2
by x −1. Thus we use g1 as a rule for replacing its head, namely x2 , by its
tail, namely x −1. Clearly, if a polynomial g1 is written as a −b, we have
a = b mod (g1), but here we emphasize the fact that a = b mod (g1) can be
viewed as a rule for replacing a by b. In other words, we orient the equality
by destroying its symmetry in order to use a polynomial as a rewrite rule.
Now we continue with the Division Algorithm. First we observe that
LTσ(xy −y) = xy is a multiple of LTσ(g2). So the second step yields
f = y · g1 + 1 · g2 + (f −yg1 −g2) and f −yg1 −g2 = x −3. Again we
stress the point that the core of this operation is to use g2 as a rewrite rule
in the sense that its leading term xy is replaced by its tail x + y −3. Here
the Division Algorithm stops.
Suppose instead that we perform the Division Algorithm with respect
to f and (g2, g1). Then we get f = (x + 1) · g2 + 1 · g1 + (f −(x + 1)g2 −g1),
and we see that f −(x + 1)g2 −g1 = −x + y −4. The algorithm stops and
returns an output which is not the same as before.
Summarizing, we can say that the core of the Division Algorithm is to use
the elements g1, . . . , gs as rewrite rules. To use gi as a rewrite rule means to
replace the leading term of gi by the remaining part of it, with the obvious
adjustment if gi is not monic. Of course we should be allowed to use the
rewrite rules repeatedly. But in the Division Algorithm the rewrite rules
have a well deﬁned hierarchy, i.e. the application of the ﬁrst rewrite rule is
preferred to the second one, and so on. If we have the possibility of using
several rewrite rules at a certain point, the Division Algorithm forces us to
use the ﬁrst one in the hierarchy.
What happens if we destroy this hierarchy? Then we are allowed to use at
each step any applicable rewrite rule, but the drawback is immediately clear.
A look at the previous example convinces us that diﬀerent possible paths

92
2. Gr¨obner Bases
may lead to diﬀerent results. So the natural question is whether there are
sets of rewrite rules such that all possible paths can be continued until they
reach the same result. “Conﬂuence” is the name of this game and the essence
of this section, a modern version of the motto “all roads lead to Rome”.
And there is a ﬁnal surprising result. We will discover that for a set of
polynomials or vectors of polynomials, being special in the sense of conﬂuence
is equivalent to being special in the sense of Conditions A) and B) described
in Section 2.1. Thus rewrite rules provide a diﬀerent aspect of the same
phenomenon. Although it is beyond the scope of this book, it turns out that
this view is most suitable for generalizations in a number of directions, e.g.
to the non-commutative case.
Now it is time to study these ideas in a more technical manner. Let K be
a ﬁeld, n ̸= 1, P = K[x1, . . . , xn] a polynomial ring, r ≥1, and σ a module
term ordering on Tn⟨e1, . . . , er⟩.
Deﬁnition 2.2.1. Let g1, . . . , gs ∈P r \ {0} and G = {g1, . . . , gs}.
a) Let m1, m2 ∈P r, and suppose there exist a constant c ∈K , a term
t ∈Tn , and an index i ∈{1, . . . , s} such that m2 = m1 −c tgi and
t · LTσ(gi) /∈Supp(m2). Then we say that m1 reduces to m2 in one
step using the rewrite rule deﬁned by gi (or simply that m1 reduces
to m2 in one step using gi ), and we write m1
gi
−→m2 . The passage
from m1 to m2 is also called a reduction step.
b) The transitive closure of the relations
g1
−→, . . . ,
gs
−→is called the rewrite
relation deﬁned by G and is denoted by
G
−→. In other words, for
m1, m2 ∈P r, we let m1
G
−→m2 if and only if there exist indices
i1, . . . , it ∈{1, . . . , s} and elements m′
0, . . . , m′
t ∈P r such that
m1 = m′
0
gi1
−→m′
1
gi2
−→· · ·
git
−→m′
t = m2
c) An element m1 ∈P r with the property that there is no i ∈{1, . . . , s}
and no m2 ∈P r \ {m1} such that m1
gi
−→m2 is called irreducible with
respect to
G
−→.
d) The equivalence relation deﬁned by
G
−→will be denoted by
G
←→.
In part a) of this deﬁnition, we can choose c = 0 and t ∈Tn such that
t·LTσ(gi) /∈Supp(m1). This is called a trivial reduction. By using it we see
that m1
gi
−→m1 . In the example mentioned in the introduction, we have for
instance f
g1
−→xy −y and xy −y
g2
−→x−3. Thus f
G
−→x−3 and x−3
G
←→f
hold, while x −3
G
−→f is not true, because the leading term of f is larger
than x.

2.2 Rewrite Rules
93
Proposition 2.2.2. (Properties of Rewrite Relations)
Let g1, . . . , gs ∈P r \ {0}, and let G = {g1, . . . , gs}.
a) If m1, m2 ∈P r satisfy m1
G
−→m2 and m2
G
−→m1 , then m1 = m2 .
b) If m1, m2 ∈P r satisfy m1
G
−→m2 , and if t ∈Tn, then we have
tm1
G
−→tm2 .
c) Every chain m1
G
−→m2
G
−→· · · such that m1, m2, . . . ∈P r becomes even-
tually stationary.
d) If m1, m2 ∈P r satisfy m1
gi
−→m2 for i ∈{1, . . . , s}, and if m3 ∈P r,
then there exists an element m4 ∈P r such that m1 + m3
G
−→m4 and
m2 + m3
G
−→m4 .
e) If m1, m2, m3, m4 ∈P r satisfy m1
G
←→m2 and m3
G
←→m4 , then we
have m1 + m3
G
←→m2 + m4 .
f) If m1, m2 ∈P r satisfy m1
G
←→m2 , and if f ∈P , then we have
fm1
G
←→fm2 .
g) For m ∈P r, we have m
G
←→0 if and only if m ∈⟨g1, . . . , gs⟩.
h) For m1, m2 ∈P r, we have m1
G
←→m2 if and only if m1 −m2 ∈
⟨g1, . . . , gs⟩.
Proof.
To show claim a), we consider a chain of reduction steps which repre-
sents m1
G
−→m2
G
−→m1 , i.e. a chain m1 = m′
0
gi1
−→· · ·
git
−→m′
t = m1 such that
i1, . . . , it ∈{1, . . . , s} and m′
j = m2 for some j ∈{1, . . . , t −1}. The eﬀect
of a reduction step is that a term is replaced by other terms, all of which
are smaller with respect to σ. So let tek with t ∈Tn and k ∈{1, . . . , s} be
the largest term with respect to σ which is reduced in this chain. This term
is not contained in the support of the result anymore, unless each reduction
step is trivial, i.e. unless m1 = m2 .
Claim b) holds, since it holds at each reduction step. Thus we prove c)
now. Suppose there exist i1, i2, . . . ∈{1, . . . , s} and m1, m2, . . . ∈P r such
that we have a chain of reduction steps m1
gi1
−→m2
gi2
−→· · · which does not
become stationary. The ﬁrst claim is that each mi must have a term in
its support which reduces eventually. Indeed we observe that if this does not
happen, it means that starting from mi the sequence of reductions is actually
a sequence of equalities. Therefore there exists a term ti in Supp(mi) which is
the largest term with respect to σ which is reduced later in the chain. Then we
have t1 ≥σ t2 ≥σ · · ·, and since every term ti is reduced eventually, this chain
does not become stationary either, in contradiction with Theorem 1.4.19.
For the proof of d), we let c ∈K , t ∈Tn, and i ∈{1, . . . , s} be such
that m2 = m1 −c tgi and t LTσ(gi) /∈Supp(m2). Clearly we may assume
c ̸= 0. We let c′ be the coeﬃcient of t LTσ(gi) in m3 and distinguish two
cases. When c′ = −c, we have m1 + m3 = m2 + m3 + c tgi = m2 + m3 −
c′tgi . Since the coeﬃcient of t LTσ(gi) in m2 + m3 −c′tgi vanishes, we get

94
2. Gr¨obner Bases
m2 + m3
gi
−→m1 + m3 , and we can choose m4 = m1 + m3 . When c′ ̸= −c
we deﬁne m4 by
m4 = m1 + m3 −(c + c′)tgi = m2 + m3 −c′tgi
and obtain the claim, because the coeﬃcient of t LTσ(gi) vanishes in m4 .
Next, claim e) follows from d), and f) follows from b) and e) by repre-
senting f as a sum of monomials. Since h) is an immediate consequence of e)
and g), it remains to show g). If m
G
←→0, we collect the terms used in the
various reduction steps and get a representation m = f1g1 + · · · + fsgs with
f1, . . . , fs ∈P . Conversely, given an element m ∈P r with such a represen-
tation, it suﬃces by e) to prove figi
G
←→0 for i = 1, . . . , s. This follows from
gi
G
←→0 and f).
□
Unfortunately, it is not clear how we could use part g) of the above
proposition to check whether a given element m ∈P r is contained in the
submodule ⟨g1, . . . , gs⟩, because we do not know the direction of the reduc-
tion steps used in m
G
←→0. In other words, if we use only reduction steps
m = m0
gi1
−→m1
gi2
−→· · ·, we might get stuck at some point with an irreducible
element with respect to
G
−→. The next example shows that this can really
happen.
Example 2.2.3. Let n = 3, r = 1, G = {g1, g2} with g1 = x2
1−x2 and g2 =
x1x2 −x3 , and let σ be the term ordering DegRevLex. Then the polynomial
f = x2
1x2 −x1x3 is contained in the ideal (g1, g2), since f = x1g2 . But if we
use the reduction step f
g1
−→x2
2 −x1x3 , we arrive at an irreducible element
with respect to
G
−→.
It is also important to notice that if σ is not a term ordering, then claim c)
of Proposition 2.2.2 may fail to hold, as the following example shows.
Example 2.2.4. Let n = 2, let r = 1, let G = {g} with g = x −xy, and
let σ = RevLex. Then the chain x
g
−→xy
g
−→xy2
g
−→· · · does not become
stationary.
After seeing the main properties of rewrite relations, we want to investi-
gate the property of conﬂuence which, as we said before, is crucial for later
applications.
Proposition 2.2.5. Let g1, . . . , gs ∈P r \ {0}, let G = {g1, . . . , gs}, and let
M = ⟨g1, . . . , gs⟩⊆P r . Then the following conditions are equivalent.
C1) For an element m ∈P r, we have m
G
−→0 if and only if m ∈M .
C2) If m ∈M is irreducible with respect to
G
−→, then we have m = 0.
C3) For every element m1 ∈P r, there is a unique element m2 ∈P r such
that m1
G
−→m2 and m2 is irreducible with respect to
G
−→.

2.2 Rewrite Rules
95
C4) If m1, m2, m3 ∈P r satisfy m1
G
−→m2 and m1
G
−→m3 , then there exists
an element m4 ∈P r such that m2
G
−→m4 and m3
G
−→m4 . (A relation
G
−→with this property is called conﬂuent.)
m1
m3
m2
m4


3
QQQQ
Q
s





3
Q
Q
Q
Q
QQ
s
G
G
G
G
Proof.
For the proof of C1) ⇒C2), we note that if m ∈M , then C1)
implies m
G
−→0. Thus if m is irreducible with respect to
G
−→, we get m = 0.
Next we show that C2) implies C3). By Proposition 2.2.2.c, there is an
element m2 ∈P r which is irreducible with respect to
G
−→and which satisﬁes
m1
G
−→m2 . Suppose m′
2 ∈P r is another element with those properties. Then
we have m2 −m′
2 ∈M , since m1
G
−→m2 and m1
G
−→m′
2 . Furthermore,
the element m2 −m′
2 is irreducible with respect to
G
−→, since no term in
Supp(m2)∪Supp(m′
2) is a multiple of one of the terms LTσ(g1), . . . , LTσ(gs).
By C2), we conclude m2 = m′
2 .
Now we prove C3) ⇒C4). By Proposition 2.2.2.c, there are elements
m′
2, m′
3 ∈P r which are irreducible with respect to
G
−→and which satisfy
m2
G
−→m′
2 as well as m3
G
−→m′
3 . From m1
G
−→m′
2 , m1
G
−→m′
3 , and C3), we
conclude m′
2 = m′
3 . Then the claim follows for m4 = m′
2 = m′
3 .
Finally, to show C4) ⇒C1), it suﬃces, by Proposition 2.2.2.g, to prove
m
G
−→0 for m ∈M , where we already know m
G
←→0. Let m1, . . . , mt ∈P r
be such that m1 = m, mt = 0, and for all i = 1, . . . , t −1 we either have
mi
G
−→mi+1 or mi+1
G
−→mi . Let ℓ∈{1, . . . , t −2} be the largest index
such that mℓ+1
G
−→mℓ. Then we have mℓ+1
G
−→0 and mℓ+1
G
−→mℓ, and
C4) yields mℓ
G
−→0. If we replace the sequence m = m1, . . . , mt = 0 by
the shorter sequence m = m1, . . . , mℓ, 0, we see that the claim follows by
induction.
□
The remainder of this section deals with connections between conﬂuent
rewrite relations and the previous section. First we prove a useful technical
result.
Lemma 2.2.6. Let g1, . . . , gs ∈P r \ {0}, let G = {g1, . . . , gs}, and let
M = ⟨g1, . . . , gs⟩. Assume that an element m ∈M \ {0} satisﬁes m
G
−→0.
a) There exist an index α ∈{1, . . . , s} and a term t ∈Tn such that
LTσ(m) = t · LTσ(gα).

96
2. Gr¨obner Bases
b) By collecting all reduction steps in m
G
−→0, we get f ′
1, . . . , f ′
s ∈P such
that m −LCσ(m)
LCσ(gα) t gα = Ps
i=1 f ′
igi and such that LTσ(m) >σ LTσ(f ′
igi)
for i = 1, . . . , s with f ′
igi ̸= 0.
c) If we put fi = f ′
i for i ∈{1, . . . , s} \ {α} and fα = f ′
α + LCσ(m)
LCσ(gα) t,
then we obtain an element m = Ps
i=1 figi whose leading term satisﬁes
LTσ(m) = maxσ{LTσ(figi) | i ∈{1, . . . , s}, figi ̸= 0}.
Proof.
Claim a) follows immediately from the fact that LTσ(m) has to be
eliminated at one of the reduction steps.
Now we prove b). Let m1, . . . , mt ∈P r be such that m1 = m, mt = 0,
and for all i = 1, . . . , t −1 we have mi
G
−→mi+1 using one reduction step.
By a), there exists a reduction step where the leading term of m is reduced.
This step is unique, since it substitutes LTσ(m) with smaller terms. So, let
ℓ∈{1, . . . , t −1} be such that mℓ+1 = mℓ−LCσ(m)
LCσ(gα) t gα. Then
m −LCσ(m)
LCσ(gα) t gα = m −(mℓ−mℓ+1) =
ℓ−1
X
i=1
(mi −mi+1) +
t−1
X
i=ℓ+1
(mi −mi+1)
is of the form Ps
i=1 f ′
igi . Here the polynomials f ′
i are obtained by collecting
the elements of type c t appearing in the two sums, where each diﬀerence
mi −mi+1 is of the form mi −mi+1 = c t gβ for some c ∈K , t ∈Tn, and
β ∈{1, . . . , s}. To conclude the proof it suﬃces to observe that when we
write mi −mi+1 = c t gβ , we get t LTσ(gβ) ≤σ LTσ(mi) by the deﬁnition of
a reduction step.
Finally, we see that c) is an immediate consequence of b).
□
Let us examine the claims of this lemma in a concrete case.
Example 2.2.7. Let g1 = x2 −xy, g2 = xy −x −z, and g3 = xy + xz be
polynomials in Q[x, y, z], let G = {g1, g2, g3}, and let σ = DegLex. Suppose
we want to reduce the polynomial x3 with respect to the rewrite relation
G
−→.
One possibility is to apply the following chain of reduction steps.
x3
g1
−→x2y
g2
−→x2 + xz
g1
−→xy + xz
g3
−→0
As predicted by part a) of the lemma, we ﬁnd x3 = LTσ(x3) = x LTσ(g1).
Furthermore, by collecting the reduction steps, we get x3−xg1 = xg2+g1+g3 ,
where x3 = LTσ(x3) is strictly bigger than x2y = LTσ(xg2), x2 = LTσ(g1),
and xy = LTσ(g3) with respect to σ.
Finally, to check part c) of the lemma, we also bring xg1 to the other side
and write
x3 = (x + 1)g1 + xg2 + g3
Here we have x3 = maxσ{LTσ((x + 1)g1), LTσ(xg2), LTσ(g3)}, as claimed.

2.2 Rewrite Rules
97
Unfortunately, the lemma requires that the element reduces to zero. In
our case, we could have followed a diﬀerent sequence of reduction steps, for
instance
x3
g1
−→x2y
g1
−→xy2
g2
−→xy + yz
g2
−→yz + x + z
Here we end up with an element which cannot be reduced further and which
is non-zero. By looking at this sequence of instruction steps, we cannot decide
whether x3 satisﬁes the hypothesis of the lemma.
Both in the introduction to this section and in the previous example we
have seen that the property of being conﬂuent is not shared by all rewrite
relations. Is there a better way of understanding it? The following proposition
gives a somehow unexpected answer.
Proposition 2.2.8. Let g1, . . . , gs ∈P r \ {0}, let G = {g1, . . . , gs}, and
let M = ⟨g1, . . . , gs⟩. Then Conditions A1), A2) of Proposition 2.1.1 are
equivalent with Conditions C1), C2), C3), and C4) of Proposition 2.2.5.
Proof.
To prove A2) ⇒C2) by contradiction, we suppose that there is an
element m ∈M \ {0} which is irreducible with respect to
G
−→. By Con-
dition A2), the element m has a representation m = Ps
i=1 figi such that
f1, . . . , fs ∈P and LTσ(m) = maxσ{LTσ(figi) | i ∈{1, . . . , s}, figi ̸= 0}.
Let t LTσ(gi) be the term which achieves this maximum. Then the element
m′ = m −LCσ(m)
LCσ(gi)tgi satisﬁes m
G
−→m′ and m′ ̸= m, a contradiction.
Conversely, C1) ⇒A2) follows directly from Lemma 2.2.6.
□
Exercise 1. Let σ be a module term ordering, let g ∈P r \ {0}, and let
G = {g}. Show that the rewrite relation
G
−→is conﬂuent.
Exercise 2. Let σ be a module term ordering, and let G be a ﬁnite set
of terms in P r . Show that Conditions C) of Proposition 2.2.5 hold for the
rewrite relation
G
−→.
Exercise 3.
Give an example of a rewrite relation
G
−→which is not
conﬂuent.
Exercise 4.
Let σ be a monoid ordering on Tn , let t1, t2 ∈Tn be
terms with t1 >σ t2 , and let g = t1 −t2 . Consider the rewrite relation
deﬁned by G = {g}. (Observe that here we do not assume that σ is a
term ordering.) Prove that the following conditions are equivalent.
a) t1 ∤t2
b) Every chain f1
G
−→f2
G
−→· · · such that f1, f2, . . . ∈P becomes even-
tually stationary.

98
2. Gr¨obner Bases
Tutorial 18: Algebraic Numbers
In this tutorial, we want to use CoCoA to give some hints about how one
can eﬀectively compute in the ﬁeld Q of algebraic numbers, i.e. the algebraic
closure of Q. We shall compute only up to conjugates, i.e. we shall represent
an algebraic number by its minimal polynomial over Q. To distinguish be-
tween conjugate algebraic numbers, we would also have to provide reasonably
good approximations in Q[i]. Furthermore, we shall be content to ﬁnd some
polynomial which has a certain algebraic number as one of its zeros. After
factoring this polynomial using the CoCoA function Factor(. . .) one could
then try to use methods of numerical analysis to ﬁnd the factor which is the
minimal polynomial of the desired algebraic number.
Let a1, a2 ∈Q be two algebraic numbers represented by irreducible poly-
nomials g1, g2 ∈Q[x] of degrees d1, d2 , respectively.
a) Use Macaulay’s Basis Theorem 1.5.7 to show that the residue classes of
{xi
1xj
2 | 0 ≤i < d1, 0 ≤j < d2} form a Q-basis of the Q-algebra
Q[x1, x2]/(g1(x1), g2(x2)).
b) Show that one can ﬁnd a polynomial having a1 + a2 as one of its zeros
in the following way.
1) Represent the residue classes of the powers 1, x1 + x2, (x1 + x2)2, . . .
in the basis given in a). Use the rewrite relation
G
−→corresponding
to G = {g1(x1), g2(x2)} to ﬁnd such representations.
2) Continue with step 1) until there is a linear relation between the
representations of 1, x1 + x2, . . . , (x1 + x2)d for some d ≥0. Then
there is a polynomial of degree d which vanishes at a1 + a2 .
c) Write a CoCoA program AlgSum(. . .) which takes the pair (g1, g2) and
computes a polynomial which vanishes at a1 + a2 using the algorithm
developed in b).
d) Repeat parts b) and c) for the product a1a2 . In particular, write a CoCoA
program AlgMult(. . .) which ﬁnds a polynomial which vanishes at a1a2 .
e) Given an algebraic number a ∈Q represented by an irreducible polyno-
mial g ∈Q[x], what is the minimal polynomial of −a? Write a CoCoA
program AlgNeg(. . .) which takes g and computes the minimal polyno-
mial of −a.
f) Given a non-zero algebraic number a ∈Q represented by an irreducible
polynomial g ∈Q[x], what is the minimal polynomial of
1
a ? Write a
CoCoA program AlgInv(. . .) which takes g and computes the minimal
polynomial of
1
a .
g) Apply your CoCoA programs AlgSum(. . .), AlgMult(. . .), AlgNeg(. . .),
and AlgInv(. . .) in the following cases. (You’ll have to ﬁnd g1, g2 ﬁrst!)
1) a1 =
√
2, a2 =
√
3
2) a1 =
3√
3, a2 = 1
2 + i
2
√
3
3) a1 =
√
2 +
√
3, a2 = −i

2.3 Syzygies
99
2.3 Syzygies
Not in the beauty of the words
lies the persuasion of an explanation,
but in their combination (συζυγι´α, syzyg´ıa).
(Dionysius Halicarnassensis)
In the previous two sections we saw a number of conditions satisﬁed by
certain special systems of generators of an ideal or module, but not by all of
them. Although Proposition 1.5.6 says that such special systems of generators
exist always, we do not yet know how to replace a given system of generators
with another one having those additional properties.
In this section we change our point of view once more and look at these
phenomena from the perspective of syzygies. Despite the exotic name, a
syzygy is a very simple object to deﬁne. Namely, given a ring R and a tuple
of elements (g1, . . . , gs) of an R-module, every tuple (f1, . . . , fs) of elements
of R such that f1g1 + · · · + fsgs = 0 is called a syzygy of (g1, . . . , gs). The
introduction of syzygies will eventually achieve several goals. First of all, we
see in this section that the failure of Conditions A), B), C) can be better
understood in terms of syzygies. Even more important is the fact that in sub-
sequent sections we shall use syzygies to ﬁnd an algorithmic way to replace
a given set of generators, which does not satisfy the conditions, with another
one, which does.
What we have said so far suggests the importance of syzygies, and in
fact they turn out to be one of the most fundamental algebraic objects.
Consequently, the computation of a system of generators for the module of
syzygies of a given tuple is one of the central problems in Computational
Commutative Algebra. It is also the key to many applications studied in
Chapter 3.
But for the moment, let us get down to earth and start digging for the
hidden treasures in the land of syzygies. To ﬁnd the set of all syzygies of a
given tuple G = (g1, . . . , gs) of non-zero polynomial vectors g1, . . . , gs ∈P r,
where P = K[x1, . . . , xn] is a polynomial ring over a ﬁeld K , we use the
same strategy which brought us rich rewards before: reduce questions about
polynomials or vectors of polynomials to questions about their leading terms.
Thus we start out by connecting the deﬁning exact sequence of the module
of syzygies Syz(G) of G and the deﬁning exact sequence of Syz(LMσ(G)),
the syzygy module of LMσ(G) = (LMσ(g1), . . . , LMσ(gs)), via a fundamental
diagram.
Then we compute an explicit system of generators for Syz(LMσ(G)), and
ﬁnally we try to lift those syzygies to syzygies of G . This means that we try
to ﬁnd syzygies of G whose highest homogeneous components (in some sense)
are the syzygies generating Syz(LMσ(G)). When we try to lift the treasures
of syzygies in this way, we encounter another unexpected gem: A system of
generators of a module has the property that the syzygies of their leading

100
2. Gr¨obner Bases
terms can be lifted if and only if the set of generators satisﬁes Conditions
A), B), and C)!
Deﬁnition 2.3.1. Let R be a ring, M an R-module, and G = (g1, . . . , gs)
a tuple of elements of M .
a) A syzygy of G is a tuple (f1, . . . , fs) ∈Rs such that f1g1+· · ·+fsgs = 0.
b) The set of all syzygies of G forms an R-module which we call the
(ﬁrst) syzygy module of G and which we denote by SyzR(G) or by
SyzR(g1, . . . , gs). If no confusion can arise, we shall also write Syz(G) or
Syz(g1, . . . , gs).
As in the previous sections, we let K be a ﬁeld, n ≥1, P = K[x1, . . . , xn]
a polynomial ring, r ≥1, and σ a module term ordering on Tn⟨e1, . . . , er⟩.
Furthermore, we let g1, . . . , gs ∈P r \ {0}, we let M = ⟨g1, . . . , gs⟩⊆P r, and
we denote the s-tuple (g1, . . . , gs) by G . Then we consider the P -module
P s with canonical basis {ε1, . . . , εs} and the homomorphism λ : P s −→M
given by εj 7→gj for j = 1, . . . , s. In this situation we can also describe the
syzygy module of G by SyzP (G) = ker(λ).
The nature of many facts explained in this section is not elementary, so
the inexperienced reader might have some diﬃculties. For instance, it is clear
that even if we start with an ideal, given by a set of polynomial generators, the
set of their syzygies is a module. So the theory is described in the framework
of modules. Moreover, we shall need to introduce a ﬁne grading on the module
of syzygies in order to detect the correct “highest homogeneous component”
when we follow the above approach.
Since we do not want any reader running away from this book at this
point, we decided to use a didactic tool: a running example. This is an ex-
ample which we will revisit several times during the section, and which we
will use to make all deﬁnitions and constructions as lucid as possible. Let us
start our running example by introducing its basic objects.
Example 2.3.2. Let n = 3, let r = 1, and let us equip P = Q[x, y, z]
with the degree-lexicographic term ordering σ. Then we consider the ideal
M = ⟨g1, g2⟩generated by g1 = x2 −y2 −x and g2 = xy2 −z3 , and the pair
G = (g1, g2). Of course the reason why we call this ideal M (and not I ) is
to have a better way of comparing the example with the general theory.
The syzygy module of G is the submodule Syz(G) = {(f1, f2) ∈P 2 |
f1g1 +f2g2 = 0} = {(f1, f2) ∈P 2 | f1(x2 −y2 −x)+f2(xy2 −z3) = 0} of P 2 .
Some syzygies of G are obviously given by (g2, −g1) and its multiples, but
are there others?
When we combine the exact sequence 0 −→M −→P r −→P r/M −→0
with the description of Syz(G) as the kernel of λ, we obtain a long exact
sequence
0 −→Syz(G) −→P s
λ
−→P r −→P r/M −→0

2.3 Syzygies
101
Now let N ⊆P r be the P -submodule of P r generated by the vectors
{LMσ(g1), . . . , LMσ(gs)}, let LMσ(G) be the tuple (LMσ(g1), . . . , LMσ(gs)),
and let Λ : P s −→N denote the homomorphism given by εj 7→LMσ(gj) for
j = 1, . . . , s. Then Ker(Λ) is the syzygy module of LMσ(G). Consequently,
it will be denoted by Syz(LMσ(G)). We obtain another long exact sequence
0 −→Syz(LMσ(G)) −→P s
Λ
−→P r −→P r/N −→0
Recall from Example 1.7.5 that P r carries a natural structure of a
Tn⟨e1, . . . , er⟩-graded module over the Tn -graded ring P . More precisely,
we have (P r)tei = K · tei and Pt = K · t for t ∈Tn and i = 1, . . . , r. If we
look at the deﬁnition of Λ, we see that Λ(Ps
j=1 fjεj) = Ps
j=1 fj LMσ(gj).
This fact suggests that we should try to equip the P -module P s with a
Tn⟨e1, . . . , er⟩-grading which is somehow compatible with Λ. By using this
approach we ﬁnd, in the next proposition, that the second sequence carries
more structure than the ﬁrst one.
Proposition 2.3.3. In the above situation we deﬁne
(P s)tei = {
sP
j=1
cjtjεj ∈P s | cj = 0 or
tj LTσ(gj) = tei for j = 1, . . . , s}
for all tei ∈Tn⟨e1, . . . , er⟩.
a) We have P s = ⊕tei∈Tn⟨e1,...,er⟩(P s)tei . In this way, P s becomes a
Tn⟨e1, . . . , er⟩-graded module over the Tn-graded ring P .
b) The map Λ is a homomorphism of Tn⟨e1, . . . , er⟩-graded P -modules. In
fact, the sequence 0 −→Syz(LMσ(G)) −→P s
Λ
−→P r −→P r/N −→0
consists of homomorphisms of Tn⟨e1, . . . , er⟩-graded modules.
Proof.
In order to show a), we ﬁrst observe that (P s)tei is a group for every
t ∈Tn and every i ∈{1, . . . , r}. Then we verify P s = ⊕tei∈Tn⟨e1,...,er⟩(P s)tei .
Every element Ps
j=1 fjεj ∈P s is a sum of elements of the form c t′εj with
c ∈K \ {0} and t′ ∈Tn . By deﬁnition, we have c t′εj ∈(P s)t′ LTσ(gj) , so
that it remains to show that the sum is a direct sum.
To this end we notice that, for each j ∈{1, . . . , s}, there exists at most one
term t′ in the support of fj such that t′ LTσ(gj) = tei . Therefore every term
in the support of Ps
j=1 fjεj is contained precisely in one summand (P s)tei .
Finally, we observe that t · (P s)t′ei ⊆(P s)tt′ei shows that our deﬁnition
actually yields a Tn⟨e1, . . . , er⟩-graded module over the Tn-graded ring P .
Now we prove b). For every tei ∈Tn⟨e1, . . . , er⟩and every element
Ps
j=1 cjtjεj ∈(P s)tei we have Λ(Ps
j=1 cjtjεj) = Ps
j=1 cjtj LMσ(gj) =
(Ps
j=1 cj)tei ∈(P r)tei . Therefore Λ is a homomorphism of Tn⟨e1, . . . , er⟩-
graded modules, and Syz(LMσ(G)) = ker(Λ) inherits the structure of a
Tn⟨e1, . . . , er⟩-graded module. Since N is a monomial submodule of P r , it is
a Tn⟨e1, . . . , er⟩-graded submodule by Proposition 1.7.10, and the canonical

102
2. Gr¨obner Bases
homomorphism P r −→P r/N is a homomorphism of Tn⟨e1, . . . , er⟩-graded
P -modules by Remark 1.7.9. Thus the whole sequence consists of homomor-
phisms of Tn⟨e1, . . . , er⟩-graded modules.
□
Example 2.3.2 (continued) In our example we have LMσ(G) = (x2, xy2).
Then for instance (P 2)x2y2 = {(c1t1, c2t2) ∈P 2 | c1t1x2, c2t2xy2 ∈Q·x2y2}.
Examples of elements which belong to (P 2)x2y2 are (y2, 0), (−y2, x), and
( 1
2y2, −4x).
The intrinsic meaning of the new concepts which we are now going to
introduce will be discussed more thoroughly in Volume 2. For the time
being, they are only deﬁned with the purpose of better dealing with the
Tn⟨e1, . . . , er⟩-gradings described above.
Deﬁnition 2.3.4. Let m be a non-zero element of a Tn⟨e1, . . . , er⟩-graded
module, and let m = P
µ∈Tn⟨e1,...,er⟩mµ be the decomposition of m into its
homogeneous components. The term maxσ{µ ∈Tn⟨e1, . . . , er⟩| mµ ̸= 0} is
called the σ-degree of m, and the homogeneous component of m of this
degree is called the σ-leading form of m.
In the case of the Tn⟨e1, . . . , er⟩-grading on P s deﬁned in Proposi-
tion 2.3.3, we denote the σ-degree of an element m ∈P s \{0} by degσ,G(m),
and its σ-leading form by LFσ,G(m). In the next proposition we show how
to determine degσ,G(m) and LFσ,G(m) for a non-zero element m ∈P s.
Proposition 2.3.5. Let the module P s be equipped with the Tn⟨e1, . . . , er⟩-
grading deﬁned above, let f1, . . . , fs ∈P , and let m = Ps
j=1 fjεj ∈P s \{0}.
a) We have degσ,G(m) = maxσ{LTσ(fjgj) | j ∈{1, . . . , s}, fjgj ̸= 0}.
b) We have LFσ,G(m) = Ps
j=1 ¯fjεj , where
¯fj =





0
if fj = 0 or LTσ(fjgj) <σ degσ,G(m)
cjtj
if LTσ(fjgj) = degσ,G(m) and cj ∈K, tj ∈Supp(fj)
are such that LMσ(fjgj) = cjtj LMσ(gj)
Proof.
Claim a) follows from Proposition 1.5.3 and Deﬁnition 2.3.4. To
show b), we use that degσ,G(m) = maxσ{t LTσ(gj) | 1 ≤j ≤s, t ∈Supp(fj)}
by a), and this maximum is achieved precisely for the terms described in the
formula.
□
Sometimes we are dealing with the case r = 1, or we can pick a monoid
ordering τ on Tn such that σ is compatible with τ . In this case, we have
¯fj = cjtj = LMτ(fj) in part b) of this proposition.
Example 2.3.2 (continued) Let us compute both the σ-degree and the
σ-leading form of some elements of P s in our running example. For instance,
if we consider the pair ( 1
2y2z, −4xz), we have degσ,G( 1
2y2z, −4xz) = x2y2z
and LFσ,G( 1
2y2z, −4xz) = ( 1
2y2z, −4xz). Alternatively, if we start with the
pair (y2z−x, −4x2−y−3) ∈P 2, we get degσ,G(y2z−x, −4x2−y−3) = x3y2
and LFσ,G(y2z −x, −4x2 −y −3) = (0, −4x2).

2.3 Syzygies
103
Our next goal is to connect the two long exact sequences constructed
above. We deﬁne a map LM : P r −→P r , which sends 0 to 0 and m to
LMσ(m) if m ̸= 0. Analogously we deﬁne a map LF : P s −→P s which
sends 0 to 0 and m to LFσ,G(m) if m ̸= 0. In this way we get the following
fundamental diagram.
0
−→
Syz(G)
−→
P s
λ
−→
P r
−→
P r/M
−→
0
yLF
yLM
0
−→
Syz(LMσ(G))
−→
P s
Λ
−→
P r
−→
P r/N
−→
0
This diagram suggests natural questions, for instance whether the verti-
cal maps are homomorphisms (clearly they aren’t), and whether the diagram
commutes (it doesn’t). A more precise answer to the second question is pro-
vided by our next proposition.
Proposition 2.3.6. In the situation described above, let m ∈P s \ Syz(G).
a) We have LTσ(λ(m)) ≤σ degσ,G(m).
b) We have LF(m) ∈Syz(LMσ(G)) if and only if LTσ(λ(m)) <σ degσ,G(m).
c) We have Λ(LF(m)) = LM(λ(m)) if and only if LTσ(λ(m)) = degσ,G(m).
Now, let m ∈Syz(G) instead.
d) We have LF(m) ∈Syz(LMσ(G)). Therefore the map LF induces a map
LF |Syz(G) : Syz(G) −→Syz(LMσ(G))
which we denote by LF again.
Proof.
Claim a) follows from the rules for computing with leading terms
(see Proposition 1.5.3) and from Proposition 2.3.5.a. Namely, for the element
m = Ps
j=1 fjεj ∈P s \ {0} we calculate
LTσ(λ(m)) = LTσ(
sP
j=1
fjgj) ≤σ maxσ{LTσ(fjgj) | j ∈{1, . . . , s}, fjgj ̸= 0}
= degσ,G(m)
To prove b), we write m = Ps
j=1 fjεj ∈P s \ {0} and LFσ,G(m) =
Ps
j=1 ¯fjεj as in Proposition 2.3.5. Then Λ(LF(m)) = Ps
j=1 ¯fj LMσ(gj) = 0
is equivalent to the vanishing of the coeﬃcient of degσ,G(m) in Ps
j=1 fjgj ,
i.e. it is equivalent to LTσ(λ(m)) <σ degσ,G(m).
To prove c), we note that LTσ(λ(m)) ̸= degσ,G(m) implies by a) and b)
that we have Λ(LF(m)) = 0. Since λ(m) ̸= 0, we then get LM(λ(m)) =
LMσ(λ(m)) ̸= 0 = Λ(LF(m)). Conversely, if LTσ(λ(m)) = degσ,G(m), then
LM(λ(m)) = LMσ(Ps
j=1 fjgj) = P
{j| ¯
fj̸=0} LMσ(fjgj) = Ps
j=1 ¯fj LMσ(gj) =
Λ(LF(m)).

104
2. Gr¨obner Bases
Finally we show claim d). Let m = Ps
j=1 fjεj ∈Syz(G) \ {0}. Starting
with λ(m) = 0, we get that the coeﬃcient of degσ,G(m) in Ps
j=1 fjgj van-
ishes, and hence P
{j| ¯
fj̸=0} LMσ(fjgj) = Ps
j=1 ¯fj LMσ(gj) = Λ(LF(m)) = 0.
□
Let us check the claims of this proposition in our running example.
Example 2.3.2 (continued) Recall that M = ⟨g1, g2⟩is the ideal generated
by g1 = x2 −y2 −x and g2 = xy2 −z3 , and that σ = DegLex.
a) The element m = (y2, −x) of P 2 satisﬁes λ(m) = y2g1 −xg2 =
−y4 −xy2 + xz3 , and thus degσ,G(m) = x2y2 is not a scalar multi-
ple of LM(λ(m)) = LMσ(λ(m)) = xz3 . Going the other way in the
fundamental diagram, we calculate LF(m) = (y2, −x) and Λ(LF(m)) =
y2 LMσ(g1)−x LMσ(g2) = 0. In particular LF(m) ∈Syz(LMσ(G)). Here
we have a case where LTσ(λ(m)) <σ degσ,G(m) and where LM(λ(m)) ̸=
Λ(LF(m)).
b) The element m = (x, y) of P 2 satisﬁes λ(m) = xg1 + yg2 = x3 −xy2 −
x2 + xy3 −yz3 , and thus degσ,G(m) = xy3 as well as LM(λ(m)) =
xy3 . On the other hand, we calculate LF(m) = (0, y) and Λ(LF(m)) =
y LMσ(g2) = xy3 . Here we have a case where LTσ(λ(m)) = degσ,G(m)
and LM(λ(m)) = Λ(LF(m)).
In this example the element m = (y2, −x) satisﬁes m /∈Syz(G), whereas
LF(m) ∈Syz(LMσ(G)). The fact that LF(m) is a syzygy of LMσ(G) may be
considered as a sort of ﬁrst step in the construction of a syzygy of G . Thus
a possible approach to our problem of computing a system of generators
for Syz(G) could be to ﬁnd elements which generate Syz(LMσ(G)) and to
“lift” them to elements of Syz(G) in some way. The remainder of this section
is devoted to studying the feasibility of such an approach. As a ﬁrst step we
see how to obtain an explicit ﬁnite set of generators of Syz(LMσ(G)).
Theorem 2.3.7. (Syzygies of Elements of Monomial Modules)
For j = 1, . . . , s, we write LMσ(gj) in the form LMσ(gj) = cjtjeγj with
cj ∈K , tj ∈Tn , and γj ∈{1, . . . , r}. For all i, j ∈{1, . . . , s}, we deﬁne
tij = lcm(ti,tj)
ti
.
a) For all i, j ∈{1, . . . , s} such that i < j and γi = γj , the element
σij = 1
ci tijεi −1
cj tjiεj ∈P s is a syzygy of LMσ(G) and is homogeneous
of σ-degree degσ,G(σij) = lcm(ti, tj)eγi .
b) We have
Syz(LMσ(G)) = ⟨σij | 1 ≤i < j ≤s, γi = γj⟩
In particular, Syz(LMσ(G)) is a ﬁnitely generated Tn⟨e1, . . . , er⟩-graded
submodule of P s.
Proof.
To prove a), we note that Λ(σij) = 0 and that
degσ,G(tijεi)= lcm(ti,tj)
ti
LTσ(gi) = lcm(ti, tj)eγi

2.3 Syzygies
105
=lcm(ti, tj)eγj =
lcm(ti,tj)
tj
LTσ(gj) = degσ,G(tjiεj)
Now we prove b). In view of a), it is clear that Syz(LMσ(G)) ̸= 0 if
and only if there exist i, j ∈{1, . . . , s} such that i < j and γi = γj . Since
Λ is a homomorphism of Tn⟨e1, . . . , er⟩-graded P -modules, its kernel is a
Tn⟨e1, . . . , er⟩-graded submodule of P s and has a homogeneous system of
generators. Let us consider one of those homogeneous generators and write
it as m = Ps
j=1 aj¯tjεj ∈P s \ {0} with aj ∈K and ¯tj ∈Tn . There are
an index µ ∈{1, . . . , s} and a term t ∈Tn such that ¯tj LTσ(gj) = teµ
whenever aj ̸= 0, which is another way of saying that m is homogeneous
and degσ,G(m) = teµ. Next, let size(m) denote the cardinality of the set
{i ∈{1, . . . , s} | ai ̸= 0}. Since Λ(m) = 0, we have Ps
j=1 ajcj = 0, and since
m ̸= 0, it follows that size(m) ≥2. Hence there are at least two indices α, β
such that aα ̸= 0 and aβ ̸= 0. From t = ¯tαtα = ¯tβtβ we see that t is a
multiple of lcm(tα, tβ), hence
¯tα =
t
tα =
t
lcm(tα,tβ)tαβ
and
¯tβ =
t
tβ =
t
lcm(tα,tβ)tβα
We deduce that the syzygy
t
lcm(tα,tβ)σαβ has the same σ-degree as m. More-
over we see that if m′ = m−aαcα
t
lcm(tα,tβ)σαβ , then size(m′) < size(m). An
obvious inductive argument concludes the proof.
□
As an immediate consequence of the above theorem, it follows that there
are no non-zero syzygies if γi ̸= γj for all 1 ≤i < j ≤s. This observation is
ampliﬁed in Exercise 7. Clearly, the proof of the theorem can be used as an
algorithm for computing the representation of an element of Syz(LM(G)) in
terms of the generators σij .
Example 2.3.8. Let n = 3, let r = 1, and let us equip P = Q[x, y, z] with
the term ordering σ = DegRevLex. We consider the vector G = (g1, g2, g3),
where g1 = 4x2y −x, g2 = 3xy3 , and g3 = yz −x −1. Then we have
LMσ(G) = (4x2y, 3xy3, yz).
The module element m = (y2z, −2xz, 2x2y2) = y2zε1 −2xzε2 + 2x2y2ε3
is contained in Syz(LMσ(G)), since y2z · 4x2y −2xz · 3xy3 + 2x2y2 · yz = 0.
Moreover, the element m is homogeneous of σ-degree degσ,G(m) = x2y3z,
and we have size(m) = 3.
According to Theorem 2.3.7, we should be able to express m as a combi-
nation of σ12 , σ13 , and σ23 . Using the notation of the proof of the the-
orem, we see that a1, a2, a3 are diﬀerent from zero. So, let α = 1 and
β = 2. We get lcm(t1, t2) = x2y3 , and therefore
x2y3z
lcm(t1,t2) =
x2y3z
x2y3
= z.
Thus we form the element m′ = m −a1c1
x2y3z
lcm(t1,t2)σ12 = m −4zσ12 .
Now we compute σ12 =
1
4y2ε1 −1
3xε2 = ( 1
4y2, −1
3x, 0) and get m′ =
(y2z, −2xz, 2x2y2) −4z( 1
4y2, −1
3x, 0) = (0, −2
3xz, 2x2y2). Finally, we deter-
mine σ23 = 1
3zε2 −xy2ε3 = (0, 1
3z, −xy2). It is clear that (0, −2
3xz, 2x2y2) =
−2xσ23 . In conclusion, we ﬁnd the desired representation m = 4zσ12−2xσ23 .

106
2. Gr¨obner Bases
The next steps in our program are to give a meaning to the process of
“lifting” a syzygy of LMσ(G) to a syzygy of G , and then to study whether
such liftings can always be found.
Deﬁnition 2.3.9. An element m ∈P s is called a lifting of an element
m ∈P s if we have LF(m) = m.
Proposition 2.3.10. The following conditions are equivalent.
D1) Every homogeneous element of Syz(LMσ(G)) has a lifting in Syz(G).
D2) There exists a homogeneous system of generators of Syz(LMσ(G)) con-
sisting entirely of elements which have a lifting in Syz(G).
D3) There exists a ﬁnite homogeneous system of generators of Syz(LMσ(G))
consisting entirely of elements which have a lifting in Syz(G).
Proof.
Since D1) ⇒D3) as an immediate consequence of Theorem 2.3.7,
and since D3) ⇒D2) holds trivially, it suﬃces to prove that D1) follows
from D2). Let I be a set, let {mi}i∈I be a homogeneous system of generators
of Syz(LMσ(G)) indexed over I , and let mi ∈Syz(G) be a lifting of mi
for every i ∈I . Given a homogeneous element m ∈Syz(LTσ(G)) \ {0},
there exists a natural number h such that we have m = Ph
j=1 cjtjmij with
cj ∈K \ {0}, with tj ∈Tn , and with ij ∈I for j = 1, . . . , h. Clearly, we
may assume degσ,G(tjmij) = degσ,G(m) for j = 1, . . . , h. From the fact that
LF(tjmij) = tjmij we conclude degσ,G(tjmij) = degσ,G(m). This, in turn,
implies LF(Ph
j=1 cjtjmij) = Ph
j=1 cjtjmij = m, which concludes the proof.
□
If we want to ﬁnd all elements of Syz(G) using this process of lifting,
we need to ascertain that there exists a system of generators of Syz(G) con-
sisting of liftings. This is achieved by the following proposition whose proof
demonstrates once more the power of term orderings.
Proposition 2.3.11. Let {m1, . . . , mt} be a homogeneous system of gener-
ators of the module Syz(LMσ(G)), and let m1, . . . , mt ∈Syz(G) be elements
such that LF(mi) = mi for i = 1, . . . , t. Then {m1, . . . , mt} is a system of
generators of Syz(G).
Proof.
For contradiction we assume that the subset S of Syz(G) of syzygies
which are not generated by {m1, . . . , mt} is not empty. By the fundamen-
tal property of term orderings (see Theorem 1.4.19), there exists m ∈S
with minimal degσ,G . Then there exists a natural number h such that we
have LF(m) = Ph
j=1 cjtjmij with cj ∈K \ {0}, with tj ∈Tn , and with
ij ∈{1, . . . , t} for j = 1, . . . , h. The element m′ = m−Ph
i=1 citimij satisﬁes
either m′ = 0 or degσ,G(m′) <σ degσ,G(m). In both cases we get a contra-
diction, and the proof is complete.
□
The ﬁnal proposition in this section is the gem we promised in the intro-
duction.

2.3 Syzygies
107
Proposition 2.3.12. Let g1, . . . , gs ∈P r \ {0} and M = ⟨g1, . . . , gs⟩. Then
Conditions A1), A2) of Proposition 2.1.1 and Conditions D1), D2), D3) of
Proposition 2.3.10 are equivalent.
Proof.
First we show that Condition A2) implies D1). Let m = Ps
j=1 fjεj
be a non-zero homogeneous element of Syz(LMσ(G)). We may suppose that
λ(m) ̸= 0, since in case λ(m) = 0 we have m ∈Syz(G) and LF(m) = m,
i.e. the element m is a lifting of itself. By Condition A2), the element λ(m)
has a representation λ(m) = Ps
i=1 higi with polynomials h1, . . . , hs ∈P
such that LTσ(λ(m)) = maxσ{LTσ(higi) | i ∈{1, . . . , s}, higi ̸= 0}. Now we
consider the element h = Ps
j=1 hjεj ∈P s. We have m −h ∈Syz(G) and
LTσ(λ(m)) = LTσ(λ(h)) = degσ,G(h). On the other hand, since LF(m) = m
and Λ(LF(m)) = 0, Proposition 2.3.6.b yields LTσ(λ(m)) <σ degσ,G(m).
Altogether, we get degσ,G(m) >σ degσ,G(h) and LF(m −h) = LF(m) = m.
Thus the element m −h is a lifting of m.
Now let us show the reverse implication. We assume for contradiction that
there exists an element v ∈M \{0} which cannot be represented as requested
by Condition A2). We observe that if v = Ps
i=1 figi for some polynomials
f1, . . . , fs ∈P and if m = Ps
j=1 fjεj , then we have v = λ(m). In other
words, the element m is a preimage of v under λ. By the fundamental prop-
erty of term orderings (see Theorem 1.4.19), we know that among all preim-
ages of v under λ, there exists one preimage m with minimal degσ,G(m).
We cannot have degσ,G(m) = LTσ(v), because otherwise the representation
v = Ps
i=1 figi is already of the form required by Condition A2). Therefore
Proposition 2.3.6.a shows that we must have LTσ(v) <σ degσ,G(m). Next,
Proposition 2.3.6.b yields LF(m) ∈Syz(LMσ(G)). Thus Condition D1) gives
us an element m′ = Ps
j=1 f ′
jεj ∈Syz(G) such that LF(m′) = LF(m). In
particular, this means that degσ,G(m −m′) <σ degσ,G(m) and λ(m −m′) =
λ(m) = v, which contradicts the minimality of the σ-degree of m.
□
Exercise 1. Find a term ordering σ and elements g1, . . . , gs ∈P r \ {0}
which generate a submodule M = ⟨g1, . . . , gs⟩⊆P r such that Conditions
D1), D2), and D3) are not satisﬁed.
Exercise 2. Find a 2 × 3-matrix over P = K[x, y, z] whose associated
ideal of 2 × 2-minors is generated by {x2 −y, xy −z, y2 −xz}. By adding
suitable rows to this matrix, show how one can produce non-trivial syzygies
of the triple G = (x2 −y, xy −z, y2 −xz).
Exercise 3. In the case n = 2, P = Q[x, y], r = 2, compute a system
of generators of the syzygy module of the tuple G = ((xy +y, x), (x−y, y),
(x, x + y), (−x, y)) by hand.
Exercise 4.
Let P = K[x, y, z] be a polynomial ring over a ﬁeld K ,
let r = 1, and let G = (x, y, z). Compute the syzygy module of a set of
generators of SyzP (G).

108
2. Gr¨obner Bases
Exercise 5.
Give a direct proof for the fact that Condition D1) of
Proposition 2.3.10 implies Condition B2) of Proposition 2.1.2.
Hint: If m ∈M \ {0} has a leading term outside N , pick a preimage of m
under λ of smallest σ-degree and look at the fundamental diagram.
Exercise 6. Let g1, . . . , gs ∈P r \ {0}, let M = ⟨g1, . . . , gs⟩, and let G
be the tuple (g1, . . . , gs).
a) Prove that Syz(G) = 0 if and only if M is a free P -module with basis
{g1, . . . , gs}.
b) Let s = 3, let n = 3, let r = 2, let g1 = (x2, x −y), let g2 = (0, y),
and let g3 = (xy, z). Then show that Syz(G) ̸= 0.
Exercise 7. Let g1, . . . , gs ∈P r \{0}, let M = ⟨g1, . . . , gs⟩, let G be the
s-tuple (g1, . . . , gs), let σ be a module term ordering on Tn⟨e1, . . . , er⟩,
and let LTσ(gi) = tieγi with ti ∈Tn and γi ∈{1, . . . , r} for i = 1, . . . , s.
a) Prove that M is a free P -module if γi ̸= γj for all i ̸= j .
b) Deduce that the submodule of P 3 generated by the set of vectors
{(x, y −z, x), (z, y2 −x, x), (z2 −y + 1, y2 −x, x −3)} is free.
Tutorial 19: Syzygies of Elements of Monomial Modules
Let K be a ﬁeld, n ≥1, P = K[x1, . . . , xn], r ≥1, and M ⊆P r a
monomial submodule generated by {t1eγ1, . . . , tseγs}, where t1, . . . , ts ∈Tn
and γ1, . . . , γs ∈{1, . . . , r}.
a) Use Theorem 2.3.7 to give an explicit system of generators of the syzygy
module of (t1eγ1, . . . , tseγs). Write a CoCoA function MonomialSyz(. . .)
which takes a system of generators of a monomial module M as above
and computes its ﬁrst syzygy module.
b) Show by example that the system of generators of the syzygy module
given in a) is in general not minimal, even if {t1eγ1, . . . , tseγs} is minimal.
c) Apply your function MonomialSyz(. . .) to compute the syzygy modules
of the following tuples.
1) (x34y7, x23y19) ⊆Q[x, y]2
2) (x, y, z) ⊆Q[x, y, z]3
3) (xy, yz, xz) ⊆Q[x, y, z]3
4) (xe1, ye1, ye2, ze2, xe3, ze3) ⊆(Q[x, y, z]3)6
d) Show that if r = 1, 1 ≤i < j < k ≤s, and tk divides lcm(ti, tj), then
the syzygy σij (as deﬁned in Theorem 2.3.7) is in the module generated
by σik and σjk .
e) Write an improved version MonomialIdealSyz(. . .) of your program
from a) which works for systems of generators of monomial ideals and
takes the optimization of part d) into account.
f) Apply the function MonomialIdealSyz(. . .) in the appropriate cases
of c). Each time, try to determine whether the computed system of gen-
erators of the syzygy module is minimal.

2.3 Syzygies
109
Tutorial 20: Lifting of Syzygies
In this tutorial we shall try to program the lifting of syzygies discussed in
the last part of the current section. As usual, let K be a ﬁeld, let n ≥1, let
P = K[x1, . . . , xn] be a polynomial ring, let r ≥1, let σ be a module term
ordering on Tn⟨e1, . . . , er⟩, let G = (g1, . . . , gs) ∈(P r)s be a tuple of non-zero
vectors, and let M = ⟨g1, . . . , gs⟩⊆P r . We assume that Conditions D1),
D2), and D3) are satisﬁed. For i = 1, . . . , s, we write LTσ(gi) = tieγi with
ti ∈Tn and 1 ≤γi ≤r, and, for i, j ∈{1, . . . , s} such that γi = γj , we let
tij = lcm(ti, tj)/ti = tj/ gcd(ti, tj).
a) Show that, for 1 ≤i < j ≤s such that γi = γj , there are representations
LCσ(gi)−1tijgi −LCσ(gj)−1tjigj =
s
X
k=1
fijkgk
where fij1, . . . , fijs ∈P , and where LTσ(fijkgk) <σ LTσ(tijgi) for all
k ∈{1, . . . , s} such that fijk ̸= 0.
b) Let {σij | 1 ≤i < j ≤s, γi = γj} be the system of generators of
the kernel of the map Λ : P s −→P r , ei 7−→LMσ(gi) introduced in
Theorem 2.3.7. Prove that the elements sij = σij −Ps
k=1 fijkεj are
liftings of σij for all i, j as above.
c) Conclude that the set {sij | 1 ≤i < j ≤s, γi = γj} is a system of
generators of the syzygy module Syz(G).
d) Using the program Division(. . .) from Tutorial 14 as a subfunction,
write a CoCoA program StdRepr(. . .) which takes the tuple G and in-
dices i, j as above and computes a list of polynomials [fij1, . . . , fijs]
corresponding to the representation in a).
e) Using the program MonomialSyz(. . .) from Tutorial 19 and StdRepr(. . .)
as subfunctions, write a CoCoA program LiftSyz(. . .) which takes the
tuple G and computes the list of all syzygies sij as in b).
f) Using the module term ordering DegRevLexPos, compute the lists of all
syzygies σij and all sij in the following cases.
1) G = (x2
1 −x2, x2
2 −x3, x2
3 −x1) ∈Q[x1, x2, x3]3
2) G = (x1e1, x2e1, x3e2, x1e3) ∈(Q[x1, x2, x3]3)4
3) G = (x1x4−x2x3, x1x2
3−x2
2x4, x2
1x3−x3
2, x2x2
4−x3
3) ∈Q[x1, x2, x3, x4]4

110
2. Gr¨obner Bases
2.4 Gr¨obner Bases of Ideals and Modules
The motifs of a combination, in themselves simple,
are often interwoven with each other. [...]
The idea which links the motifs is artistic,
it creates something that had never before been there.
(Emanuel Lasker)
In the previous three sections we saw many conditions arising from a num-
ber of diﬀerent motifs, and all of them turned out to be equivalent. Whenever
such a phenomenon shows up, it is clear that something very important is
going on: there must be some fundamental idea behind the scene which needs
to be brought to center stage. In our case it is the notion of a Gr¨obner basis.
It is one of those rare notions in the history of modern mathematics which
was able to deviate the main stream of events. It became a fundamental tool,
both for its theoretical and practical consequences.
The section opens by linking the diﬀerent motifs studied before through
the idea of a Gr¨obner basis. The natural search for the existence of such
objects leads to a fairly easy positive answer (see Proposition 2.4.3). Part of
this existence result is Hilbert’s Basis Theorem 2.4.6 for ﬁnitely generated
modules over ﬁnitely generated K -algebras. Of course it is not necessary to
develop the theory of Gr¨obner bases to achieve that result, but we decided to
include it here as an application in order to highlight the theoretical power
of Gr¨obner bases.
Then we become more ambitious and try to solve the problem of com-
puting in residue class modules. Using a Gr¨obner basis, we deﬁne the normal
form of an element with respect to a submodule and show that it is indepen-
dent of the Gr¨obner basis chosen. It agrees with the normal remainder given
by the Division Algorithm 1.6.4. Thus it is a unique representative of the
residue class of the given element which can be computed by performing the
Division Algorithm with respect to any Gr¨obner basis of the submodule. Con-
sequently, we get a submodule membership test, also called ideal membership
test when r = 1, and a new formulation of Macaulay’s Basis Theorem.
But what is really striking is another form of uniqueness. In our opinion,
it is one of the most important theoretical results of this theory. Given a
Gr¨obner basis of a submodule M of P r , we can modify its elements in such
a way that we get another Gr¨obner basis with the extra properties of being
monic, minimal, and interreduced. Surprisingly, this reduced Gr¨obner basis
of M depends only on the module and the chosen term ordering. As we
shall see, the possibility of representing a submodule by a unique system of
generators has numerous theoretical and practical applications. To give a ﬁrst
support to this claim, we devote the last part of this section to the proof of the
existence and uniqueness of the ﬁeld of deﬁnition of a given submodule M ,
i.e. a minimal subﬁeld of K which contains the coeﬃcients of some system
of generators of M .

2.4 Gr¨obner Bases of Ideals and Modules
111
Now we start the main part of this section by recalling that, as usual,
we let K be a ﬁeld, n ≥1, P = K[x1, . . . , xn] a polynomial ring, r ≥1,
and σ a module term ordering on Tn⟨e1, . . . , er⟩. In the following theorem
we collect all the conditions studied in the previous sections.
Theorem 2.4.1. (Characterization of Gr¨obner Bases)
For a set of elements G = {g1, . . . , gs} ⊆P r \ {0} which generates a sub-
module M = ⟨g1, . . . , gs⟩⊆P r , let
G
−→be the rewrite rule deﬁned by G,
let G be the tuple (g1, . . . , gs), let λ be the map λ : P s −→P r deﬁned by
εi 7→gi , and let Λ : P s −→P r be the map deﬁned by εi 7→LMσ(gi). Then
the following conditions are equivalent.
A1) For every element m ∈M \ {0}, there are f1, . . . , fs ∈P such that
m = Ps
i=1 figi and LTσ(m) ≥σ LTσ(figi) for all i = 1, . . . , s such that
figi ̸= 0, i.e. such that LTσ(m) ≥σ degσ,G(Ps
i=1 fiεi).
A2) For every element m ∈M \{0}, there are f1, . . . , fs ∈P such that m =
Ps
i=1 figi and LTσ(m) = maxσ{LTσ(figi) | i ∈{1, . . . , s}, figi ̸= 0},
i.e. such that LTσ(m) = degσ,G(Ps
i=1 fiεi).
B1) The set {LTσ(g1), . . . , LTσ(gs)} generates the Tn-monomodule LTσ{M}.
B2) The set {LTσ(g1), . . . , LTσ(gs)} generates the P -submodule LTσ(M)
of P r .
C1) For an element m ∈P r, we have m
G
−→0 if and only if m ∈M .
C2) If m ∈M is irreducible with respect to
G
−→, then we have m = 0.
C3) For every element m1 ∈P r, there is a unique element m2 ∈P r such
that m1
G
−→m2 and m2 is irreducible with respect to
G
−→.
C4) If m1, m2, m3 ∈P r satisfy m1
G
−→m2 and m1
G
−→m3 , then there exists
an element m4 ∈P r such that m2
G
−→m4 and m3
G
−→m4 .
D1) Every homogeneous element of Syz(LMσ(G)) has a lifting in Syz(G).
D2) There exists a homogeneous system of generators of Syz(LMσ(G)) con-
sisting entirely of elements which have a lifting in Syz(G).
D3) There exists a ﬁnite homogeneous system of generators of Syz(LMσ(G))
consisting entirely of elements which have a lifting in Syz(G).
Proof.
This follows from Propositions 2.1.3, 2.2.8, and 2.3.12.
□
Deﬁnition 2.4.2. Let G = {g1, . . . , gs} ⊆P r \ {0} be a set of elements
which generates a submodule M = ⟨g1, . . . , gs⟩⊆P r . If the conditions of
Theorem 2.4.1 are satisﬁed, then G is called a Gr¨obner basis of M with
respect to σ or a σ-Gr¨obner basis of M . In the case M = ⟨0⟩, we shall
say that G = ∅is a σ-Gr¨obner basis of M .

112
2. Gr¨obner Bases
2.4.A
Existence of Gr¨obner Bases
Our ﬁrst task is to show the existence of Gr¨obner bases. If we recall Propo-
sition 1.5.6.b, it is clear that there are elements g1, . . . , gs ∈M satisfying
Condition B2). But do they generate M ? Our next proposition answers this
question aﬃrmatively.
Proposition 2.4.3. (Existence of a σ-Gr¨obner Basis)
Let M be a non-zero P -submodule of P r .
a) Given g1, . . . , gs ∈M \{0} such that LTσ(M) = ⟨LTσ(g1), . . . , LTσ(gs)⟩,
we have M = ⟨g1, . . . , gs⟩, and the set G = {g1, . . . , gs} is a σ-Gr¨obner
basis of M .
b) The module M has a σ-Gr¨obner basis G = {g1, . . . , gs} ⊆M \ {0}.
Proof.
First we show claim a) by contradiction. Suppose ⟨g1, . . . , gs⟩⊂M .
By Theorem 1.4.19, there exists an element m ∈M \ ⟨g1, . . . , gs⟩whose
leading term LTσ(m) is minimal with respect to σ among all elements of
that set. Since we have LTσ(m) ∈LTσ(M) = ⟨LTσ(g1), . . . , LTσ(gs)⟩, there
are c ∈K\{0}, t ∈Tn , and i ∈{1, . . . , s} such that LMσ(m) = c t LMσ(gi).
Thus we get LTσ(m −c t gi) <σ LTσ(m), and hence m −c t gi ∈⟨g1, . . . , gs⟩,
contradicting m /∈⟨g1, . . . , gs⟩.
Claim b) follows from a) using Proposition 1.5.6.b.
□
The existence of Gr¨obner bases implies one of the most important proper-
ties of polynomial rings over ﬁelds. In Section 1.3 we described the property
of being Noetherian in the case of monoideals. Using a similar formulation,
we extend it to ideals and modules.
Deﬁnition 2.4.4. A ring (resp. module) is called Noetherian if every as-
cending chain of ideals (resp. submodules) becomes eventually stationary.
The following characterizations of Noetherian modules are in complete
analogy with the case of Noetherian monoids and can be shown exactly as
Proposition 1.3.4.
Proposition 2.4.5. Let R be a ring and M an R-module. The following
conditions are equivalent.
a) Every submodule of M is ﬁnitely generated.
b) Every ascending chain N1 ⊆N2 ⊆· · · of submodules of M is eventually
stationary.
c) Every non-empty set of submodules of M has a maximal element (with
respect to inclusion).
As a consequence of Proposition 2.4.3, we obtain a version of Hilbert’s
Basis Theorem for ﬁnitely generated modules over ﬁnitely generated K -
algebras.

2.4 Gr¨obner Bases of Ideals and Modules
113
Theorem 2.4.6. (Hilbert’s Basis Theorem)
Every ﬁnitely generated module over a ﬁnitely generated K -algebra is
Noetherian. In particular, P = K[x1, . . . , xn] is a Noetherian ring.
Proof.
If we represent the K -algebra in the form P/I with a polynomial
ring P = K[x1, . . . , xn] and an ideal I ⊆P , we can view the module M as
a ﬁnitely generated P -module via the canonical map P −↠P/I . Obviously
it suﬃces to show that every P -submodule of M is ﬁnitely generated. Since
M is ﬁnitely generated, we can represent M in the form M = P r/U with
r ≥1 and a submodule U ⊆P r . Since every submodule of M is of the
form N/U with a submodule N ⊆P r , it suﬃces to show that every P -sub-
module of P r is ﬁnitely generated, and this is an immediate consequence of
Proposition 2.4.3.
□
2.4.B
Normal Forms
Our next application of Gr¨obner bases is to show how they help us to perform
eﬀective calculations in a residue class module P r/M . Several attempts to
solve this question have failed so far, because we were not able to ﬁnd a
unique representative in P r for a residue class in P r/M . Using a Gr¨obner
basis, we now ﬁnd that all those attempts lead to the same unique answer.
Let G = {g1, . . . , gs} ⊆P r \ {0} be a σ-Gr¨obner basis of M
=
⟨g1, . . . , gs⟩⊆P r, and let m ∈P r . By Condition C3), there exists a unique
element mG ∈P r such that m
G
−→mG and such that mG is irreducible with
respect to
G
−→. A priori this element seems to depend on the Gr¨obner basis
chosen, but indeed it does not, as the following proposition shows.
Proposition 2.4.7. In the above situation, mG is the unique element of P r
with the properties that m −mG ∈M and Supp(mG) ∩LTσ{M} = ∅. In
particular, it does not depend on the particular σ-Gr¨obner basis chosen.
Proof.
We know that m −mG ∈M and that the support of mG does not
intersect LTσ{M}. Uniqueness follows from the observation that, for two
such elements mG and mH , the support of mG−mH ∈M does not intersect
LTσ{M}, and this is, by Condition C2), only possible if mG −mH = 0.
□
Deﬁnition 2.4.8. Let M ⊆P r be a non-zero module, and let m ∈P r . The
element mG ∈P r described above is called the normal form of m with
respect to σ. It is denoted by NFσ,M(m), or simply by NFσ(m) if it is clear
which submodule is considered.
Below we collect some properties of normal forms. In particular, we see
that the Division Algorithm with respect to a Gr¨obner basis provides an
eﬀective method for computing normal forms.

114
2. Gr¨obner Bases
Corollary 2.4.9. In the above situation, let G = (g1, . . . , gs).
a) If m ∈P r, then NRσ,G(m) agrees with NFσ(m). In particular, the nor-
mal remainder does not depend on the order of the elements g1, . . . , gs.
b) For m1, m2 ∈P r, we have NFσ(m1 −m2) = NFσ(m1) −NFσ(m2).
c) For m ∈P r, we have NFσ(NFσ(m)) = NFσ(m).
Proof.
Claim a) follows from m−NRσ,G(m) ∈M and from the fact that the
support of NRσ,G(m) does not meet LTσ{M}. Next we show b). We have
m1−m2−(NFσ(m1)−NFσ(m2)) = (m1−NFσ(m1))−(m2−NFσ(m2)) ∈M
and NFσ(m1)−NFσ(m2) is irreducible with respect to
G
−→. The uniqueness
of such an element yields the conclusion. Claim c) follows similarly, because
NFσ(m)−NFσ(m) = 0 ∈M and NFσ(m) is irreducible with respect to
G
−→.
□
For the purposes of actual computations, one of the most useful appli-
cations of normal forms is the possibility to check whether an element is
contained in a submodule or whether one submodule is contained in another.
Proposition 2.4.10. (Submodule Membership Test)
Let {g1, . . . , gs} ⊆P r generate a P -submodule M = ⟨g1, . . . , gs⟩of P r, and
let {h1, . . . , ht} ⊆P r generate a P -submodule N = ⟨h1, . . . , ht⟩⊆P r .
a) For m1, m2 ∈P r, we have m1 −m2 ∈M if and only if NFσ,M(m1) =
NFσ,M(m2). In particular, an element m ∈P r satisﬁes m ∈M if and
only if NFσ,M(m) = 0.
b) We have N ⊆M if and only if NFσ,M(hi) = 0 for i = 1, . . . , t.
c) The condition M = N is equivalent to NFσ,N(gi) = NFσ,M(hj) = 0 for
i = 1, . . . , s and j = 1, . . . , t.
d) If N ⊆M and LTσ{M} ⊆LTσ{N}, then M = N .
Proof.
To show the ﬁrst claim, let m1, m2 ∈P r such that m1 −m2 ∈M .
Then 0 = NFσ,M(m1−m2) = NFσ,M(m1)−NFσ,M(m2) by Corollary 2.4.9.b.
Conversely, let NFσ,M(m1) = NFσ,M(m2). In this case, the claim follows
from m1 −m2 = (m1 −NFσ,M(m1)) −(m2 −NFσ,M(m2)) ∈M .
Clearly, claim b) is a consequence of a), and claim c) follows from b).
Thus it remains to prove claim d). Since we have N ⊆M , it is clear that
LTσ{N} ⊆LTσ{M}. Thus the hypothesis that we have the other inclusion
LTσ{M} ⊆LTσ{N} implies equality LTσ{N} = LTσ{M}. Now take an
element m ∈M . We have Supp(NFσ,N(m)) ∩LTσ{N} = ∅, and therefore
Supp(NFσ,N(m)) ∩LTσ{M} = ∅. The uniqueness in Proposition 2.4.7 shows
that NFσ,N(m) = 0, i.e. we get m ∈N .
□
As an important application of the notion of Gr¨obner basis, we get a new
version of Macaulay’s Basis Theorem 1.5.7.

2.4 Gr¨obner Bases of Ideals and Modules
115
Corollary 2.4.11. (New Version of Macaulay’s Basis Theorem)
Let M ⊆P r be a P -submodule, let G = {g1, . . . , gs} ⊆P r \ {0} be a
σ-Gr¨obner basis of M , and let B be the set of all terms in Tn⟨e1, . . . , er⟩
which are not a multiple of any term in the set {LTσ(g1), . . . , LTσ(gs)}. Then
the residue classes of the elements of B form a K -basis of P r/M .
Proof.
The fact that G is a σ-Gr¨obner basis of M implies that LTσ{M}
is generated by {LTσ(g1), . . . , LTσ(gs)} by Condition B1) of Theorem 2.4.1.
So the statement follows immediately from Theorem 1.5.7.
□
2.4.C
Reduced Gr¨obner Bases
In the last part of this section we address the question of uniqueness of
Gr¨obner bases and provide an application of it. Given a module term or-
dering σ, a submodule M ⊆P r has many σ-Gr¨obner bases. For instance,
we can add arbitrary elements of M to a σ-Gr¨obner basis and it remains
a σ-Gr¨obner basis of M . However, there is a unique one which satisﬁes the
following additional conditions.
Deﬁnition 2.4.12. Let G = {g1, . . . , gs} ⊆P r \ {0} and M = ⟨g1, . . . , gs⟩.
We say that G is a reduced σ-Gr¨obner basis of M if the following con-
ditions are satisﬁed.
a) For i = 1, . . . , s, we have LCσ(gi) = 1.
b) The set {LTσ(g1), . . . , LTσ(gs)} is a minimal system of generators of
LTσ(M).
c) For i = 1, . . . , s, we have Supp(gi −LTσ(gi)) ∩LTσ{M} = ∅.
Theorem 2.4.13. (Existence and Uniqueness of Reduced Gr¨obner
Bases)
For every P -submodule M ⊆P r, there exists a unique reduced σ-Gr¨obner
basis.
Proof.
We start by proving existence. Let G = {g1, . . . , gs} be any σ-
Gr¨obner basis of M . If we replace gi by LCσ(gi)−1gi for i = 1, . . . , s, we
obtain a Gr¨obner basis with property a). By Condition B2) of Theorem 2.4.1,
the monomial module LTσ(M) is generated by {LTσ(g1), . . . , LTσ(gs)}.
Then we use Proposition 1.3.11.b to get from this set the unique minimal sys-
tem of generators of LTσ(M). After possibly renumbering the vectors we may
assume that this minimal system of generators is {LTσ(g1), . . . , LTσ(gt)},
where t ≤s. And using again Condition B2) and Proposition 2.4.3.a, we
see that the set G′ = {g1, . . . , gt} is a σ-Gr¨obner basis of M which satisﬁes
conditions a) and b) of the deﬁnition.
Now we write gi = LTσ(gi) + hi , and if we let g′
i = LTσ(gi) + NFσ(hi)
for i = 1, . . . , t, we can form the set G′′ = {g′
1, . . . , g′
t}. We claim that G′′
is a reduced σ-Gr¨obner basis of M . Since g′
i = gi −(hi −NFσ(hi)), we use

116
2. Gr¨obner Bases
Proposition 2.4.7 and get g′
i ∈M for i = 1, . . . , t. By Condition B2), the
set G′′ is a σ-Gr¨obner basis of M . Since it clearly satisﬁes conditions a)
and b) of the deﬁnition, it remains to prove that it also satisﬁes condition c).
Indeed, for every i ∈{1, . . . , t}, no term in Supp(NFσ(hi)) lies in LTσ{M},
because NFσ(hi) is irreducible with respect to
G′
−→.
Finally, to show uniqueness, we assume that G = {g1, . . . , gs} and
H = {h1, . . . , ht} are two reduced σ-Gr¨obner bases of M . From the fact that
the minimal monomial system of generators of a monomial module is unique
(see Proposition 1.3.11.b), we conclude s = t and that we can renumber the
elements of H such that LTσ(gi) = LTσ(hi) for i = 1, . . . , s. Moreover, for
i = 1, . . . , s, we have gi −hi ∈M , and gi −hi is, by condition c) of the deﬁ-
nition, irreducible with respect to
G
−→. Thus property C2) of Theorem 2.4.1
proves gi = hi for i = 1, . . . , s.
□
As an application of the existence and uniqueness of reduced σ-Gr¨obner
bases we can show the existence and uniqueness of a ﬁeld of deﬁnition for
submodules of P r .
Deﬁnition 2.4.14. Let K be a ﬁeld, P = K[x1, . . . , xn] a polynomial ring,
and M ⊆P r a P -submodule.
a) Let k ⊆K be a subﬁeld. We say that M is deﬁned over k if there
exist elements in k[x1, . . . , xn]r which generate M as a P -module.
b) A subﬁeld k ⊆K is called a ﬁeld of deﬁnition of M if M is deﬁned
over k and there exists no proper subﬁeld k′ ⊂k such that M is deﬁned
over k′ .
It is clear that if a ﬁeld of deﬁnition of a P -submodule M ⊆P r exists,
it has to contain the prime ﬁeld of K . Let us look at a concrete example.
Example 2.4.15. Let I ⊆C[x1, x2, x3] be the ideal generated by the set
{x2
1 −
√
5x1x2 + 3x1x3 + 2
√
5x2
3, x1x2 −
√
2x2
3, 2x1x2 +
√
3x2
3}. Obviously,
the ideal I is deﬁned over Q[
√
2,
√
3,
√
5].
But it is also easy to check that I = (x2
1 + 3x1x3, x1x2, x2
3). Therefore,
the ideal I is deﬁned over the prime ﬁeld Q of C, and the unique ﬁeld of
deﬁnition of I is Q.
The following lemma captures one important aspect of the proof of the
existence and uniqueness of the ﬁeld of deﬁnition.
Lemma 2.4.16. Let K′ ⊆K be a ﬁeld extension, let P ′ = K′[x1, . . . , xn],
let M ′ ⊆(P ′)r be a P ′ -submodule of (P ′)r , and let M be the P -submodule
of P r generated by the elements of M ′ .
a) A σ-Gr¨obner basis of M ′ is also a σ-Gr¨obner basis of M . In particular,
we have LTσ{M ′} = LTσ{M}.
b) The reduced σ-Gr¨obner basis of M ′ is also the reduced σ-Gr¨obner basis
of M .

2.4 Gr¨obner Bases of Ideals and Modules
117
Proof.
Let G = {g1, . . . , gs} ⊆(P ′)r \ {0} be a σ-Gr¨obner basis of M ′ .
Since the set G generates the P ′ -module M ′ and the set M ′ generates the
P -module M , the set G generates the P -module M .
Let G be the tuple (g1, . . . , gs). Using Theorem 2.3.7, we see that
Syz(LTσ(G)) = ⟨σij | 1 ≤i < j ≤s, γi = γj⟩, where σij ∈(P ′)s is given
by σij =
1
ci tijεi −
1
cj tjiεj . By Condition D1) of Theorem 2.4.1, the ele-
ments σij have liftings in (P ′)s . These liftings are also liftings in P s of the
elements σij if we consider those as elements of P s . Using Condition D3) of
Theorem 2.4.1, we deduce that G is in fact a σ-Gr¨obner basis of M . This
proves a).
To prove b), we observe that the extra conditions required in Deﬁni-
tion 2.4.12 are independent of the base ﬁeld.
□
Theorem 2.4.17. (Existence and Uniqueness of the Field of Deﬁni-
tion)
Let M be a non-zero P -submodule of P r .
a) There exists a unique ﬁeld of deﬁnition of M .
b) Given any module term ordering σ, let G be the corresponding reduced
σ-Gr¨obner basis of M . Then the ﬁeld of deﬁnition of M is the ﬁeld
generated over the prime ﬁeld of K by the coeﬃcients of the terms in the
support of the vectors in G.
Proof.
Let σ be a module term ordering, and let G be the reduced σ-
Gr¨obner basis of M . Moreover, let k be the ﬁeld generated over the prime
ﬁeld of K by the coeﬃcients of the elements of G. Since the set G gener-
ates M , the module M is deﬁned over k.
Suppose now that K′ ⊆K is a subﬁeld over which M is deﬁned, i.e. sup-
pose there exists a system of generators {m1, . . . , mt} of the P -module M
which is contained in K′[x1, . . . , xn]r \ {0}. Let G′
= {g′
1, . . . , g′
s} ⊆
K′[x1, . . . , xn]r be the reduced σ-Gr¨obner basis of the K′[x1, . . . , xn]-module
⟨m1, . . . , mt⟩⊆K′[x1, . . . , xn]r . Since the reduced σ-Gr¨obner basis of a mod-
ule is unique, Lemma 2.4.16.b implies G = G′ . From this we infer that
k ⊆K′ .
The facts that M is deﬁned over k, and that every other ﬁeld over
which M is deﬁned contains k, together imply both claims of the theo-
rem.
□
Exercise 1.
Let I = (g) with g ∈P \ {0} be a principal ideal in P .
Show that G = {g} is a Gr¨obner basis of I with respect to every term
ordering.
Exercise 2. Let m1, . . . , ms ∈P r be terms, and let M = ⟨m1, . . . , ms⟩.
Show that {m1, . . . , ms} is a Gr¨obner basis of M with respect to every
term ordering.

118
2. Gr¨obner Bases
Exercise 3. Let G = {g1, . . . , gs} ⊆P r \ {0} be a σ-Gr¨obner basis of
the P -module M = ⟨g1, . . . , gs⟩, and let m ∈M . Show that G ∪{m} is
a σ-Gr¨obner basis of M .
Exercise 4.
Let g1 = x2 −x2
1 and g2 = x3 −x3
1 be polynomials in
K[x1, x2, x3]. Find a term ordering σ on T3 such that G = {g1, g2} is a
σ-Gr¨obner basis of the ideal I = (g1, g2), and a term ordering τ such that
it is not.
Exercise 5. Let P = K[x1, . . . , xn], let m ≤n, let G = {f1, f2, . . . , fm},
where fi ∈K[xi] for i = 1, . . . , m, and let I ⊆P be the ideal generated
by G.
a) Use Condition C3) of Theorem 2.4.1 to show that G is a σ-Gr¨obner
basis of I with respect to every term ordering σ.
b) If, moreover, the polynomials fi are monic, show that G is the reduced
σ-Gr¨obner basis of I with respect to every term ordering σ.
Exercise 6. Let R be a Noetherian integral domain. Show that the
following conditions are equivalent.
a) For all a, b ∈R \ {0}, the ideal (a) ∩(b) is principal.
b) The ring R is factorial.
Hint: Use Exercise 6 in Section 1.2.
Exercise 7. Using Corollary 2.4.11 and CoCoA, ﬁnd a set of terms whose
residue classes form a basis of Z/(5)[x, y, z]/(x2−yz, y3+z3, z5−x2y2) as a
Z/(5)-vector space. (Hint: You may use the CoCoA function GBasis(...).)
Exercise 8.
A system of generators G = {g1, . . . , gs} ⊆P r \ {0} of
a P -module M = ⟨g1, . . . , gs⟩⊆P r is called a minimal σ-Gr¨obner
basis of M if {LTσ(g1), . . . , LTσ(gs)} is a minimal system of generators
of LTσ(M).
a) Prove that any two minimal σ-Gr¨obner bases of M have the same
number of elements.
b) Give an example of a module M which has two diﬀerent minimal
σ-Gr¨obner bases, all of whose elements gi have leading coeﬃcients
LCσ(gi) = 1.
Exercise 9.
Let σ be a term ordering on Tn⟨e1, . . . , er⟩. We set
LTσ(0) = ∞. In particular, we are assuming LTσ(g) <σ LTσ(0) for every
g ∈P r . Given a tuple (g1, . . . , gs) ∈(P r)s , we identify it with the tuple
(g1, . . . , gs, 0) ∈(P r)s+1 , hence with (g1, . . . , gs, 0, 0) ∈(P r)s+2 , and so
on.
For two tuples G = (g1, . . . , gs) ∈(P r)s and G′ = (g′
1, . . . , g′
s′) ∈(P r)s′ ,
we deﬁne G ⪯G′ if and only if LTσ(G) ≤Lex LTσ(G′). This means that
either there exists an index i ≥1 such that LTσ(gi) <σ LTσ(g′
i) and
LTσ(gj) = LTσ(g′
j) for 1 ≤j < i, or we have G = G′ .
A tuple G = (g1, . . . , gs) of elements in P r is said to be increasingly
ordered with respect to σ if LTσ(g1) ≤σ · · · ≤σ LTσ(gs). It is said to be
interreduced if gi ̸= 0 for i = 1, . . . , s and LTσ(gi) does not divide any
term in Supp(gj) for i, j ∈{1, . . . , s} such that i ̸= j . Finally, the tuple
G it is called monic if all its components are monic.
a) For g1, . . . , gs, gs+1, . . . , gt ∈P r, show (g1, . . . , gs, gs+1, . . . , gt) ⪯
(g1, . . . , gs).

2.4 Gr¨obner Bases of Ideals and Modules
119
b) Prove that the relation ⪯is reﬂexive and transitive, but not a to-
tal ordering on the set of the increasingly ordered tuples of elements
of P r .
c) Let M be a non-zero submodule of P r , and let G be an increasingly
ordered, interreduced tuple of elements of M . Show that the following
conditions are equivalent.
1) With respect to ⪯, the tuple G is minimal among all increasingly
ordered, interreduced, monic tuples of elements of M .
2) The tuple G is obtained by increasingly ordering the reduced σ-
Gr¨obner basis of M .
Exercise 10. Let I be an ideal of P = K[x1, . . . , xn], let σ be a term
ordering on Tn , and let Γ be a group of K -algebra automorphisms of P .
Show by example that if I is Γ -stable (i.e. if γ(I) ⊆I for all γ ∈Γ ),
then the reduced σ-Gr¨obner basis of I need not be Γ -stable.
Tutorial 21: Linear Algebra
The purpose of this tutorial is to show how Gaußian Elimination in Linear
Algebra relates to the theory of Gr¨obner bases. Let K be a ﬁeld, let m, n > 0,
and let A = (aij) be an m × n-matrix with coeﬃcients in K . We equip the
ring P = K[x1, . . . , xn] with the lexicographic term ordering Lex.
a) Write a CoCoA program RowReduce(. . .) which uses row operations to
bring the matrix A into row echelon form and then returns the matrix
B = (bij) obtained in this way.
b) For i = 1, . . . , m, let fi = ai1x1+· · ·+ainxn and gi = bi1x1+· · ·+binxn .
Show that G = {gi | 1 ≤i ≤m, gi ̸= 0} is a Lex-Gr¨obner basis of the
ideal I = (f1, . . . , fm).
c) Find and prove an algorithm which computes the Lex-Gr¨obner basis of
an ideal I of P which is generated by polynomials of degree ≤1.
d) Implement your algorithm in a CoCoA function LinearGB(. . .) which
takes a list of polynomials of degree ≤1 generating I and returns the
Lex-Gr¨obner basis of I .
e) Use LinearGB(. . .) to compute the Lex-Gr¨obner bases of the following
ideals.
1) I1 = (3x1 −6x2 −2x3, 2x1 −4x2 + 4x4, x1 −2x2 −x3 −x4) ⊆
Q[x1, x2, x3, x4]
2) I2 = (x1 + x2 + x3, x1 −x2, x1 −x3) ⊆Q[x1, x2, x3]
3) I3 = (x1 + 1, x2 + x3 + 1, x4 + x5 + 1, x1 + x4 −1) ⊆Q[x1, . . . , x5]

120
2. Gr¨obner Bases
Tutorial 22: Reduced Gr¨obner Bases
In this tutorial we shall implement an algorithm to ﬁnd the reduced Gr¨obner
basis from an arbitrary one, and we shall study various particular cases of
reduced Gr¨obner bases. So let K be a ﬁeld, n ≥1, P = K[x1, . . . , xn], r ≥1,
σ a module term ordering on Tn⟨e1, . . . , er⟩, and G = {g1, . . . , gs} ⊆P r\{0}
a σ-Gr¨obner basis of theP -submodule M = ⟨g1, . . . , gs⟩⊆P r .
a) Implement the method described in the proof of Theorem 2.4.13. Write
a CoCoA function ReduceGB(. . .) which takes any σ-Gr¨obner basis of M
and computes the reduced σ-Gr¨obner basis from it.
b) Apply your function ReduceGB(. . .) in the following cases, assuming each
time that the given sets are Lex-Gr¨obner bases of the ideals they generate.
1) G1 = {x2 + y2 + 1, x2y + 2xy + x, −2xy −x + y3 + y, −y5 −2y4 +
y2 + y −2} ⊆Z/(5)[x, y].
2) G2 = {xz3 −x−3y6 −18y4 −12y3 −18y2 −12y−3, 15x−y6 −12y5 −
79y3−24y2−67y+z3−26, y6+6y4+4y3+6y2+4y−z3+2, z3−1} ⊆
Q[x, y, z].
3) G3 = {x2 + y −1, xy −2y2 + 2y, 4y3 −7y2 + 3y, 1/2x2 + 1/2xy −
y2 + 3/2y −1/2} ⊆Q[x, y].
c) Now we equip the polynomial ring P with its standard grading (see
Example 1.7.2). Prove that an ideal I ⊆P is homogeneous if and only
if its reduced σ-Gr¨obner basis consists of homogeneous polynomials.
Hint: First show that any homogeneous ideal has a σ-Gr¨obner basis
consisting of homogeneous polynomials.
d) Let m ≥1, let A = (aij) be an m × n-matrix with coeﬃcients in K ,
and let fi = ai1x1 + · · · + ainxn for i = 1, . . . , m. Using row operations
only, we bring A to reduced row echelon form B = (bij), i.e. in the row
echelon form we clear out everything starting from the bottom. For the
non-zero rows numbered i = 1, . . . , t of B, we form the linear polynomials
gi = bi1x1 + · · · + binxn. Prove that {g1/ LCLex(g1), . . . , gt/ LCLex(gt)} is
the reduced Lex-Gr¨obner basis of the ideal I = (f1, . . . , fm) of P .
e) Write a CoCoA program LinRedGB(. . .) which computes the reduced Lex-
Gr¨obner basis of an ideal I = (f1, . . . , fm) as in d) using the method
described there.
f) Apply your function LinRedGB(. . .) to the ideals I1 and I2 of Tu-
torial 21.e. Check your results by comparing them to the results of
LinearGB(. . .) and ReduceGB(. . .).
g) Suppose that {m1, . . . , mt} ⊆P r \ {0} is any system of generators of
the P -module M , and that G = {g1, . . . , gs} ⊆P r \ {0} is the reduced
σ-Gr¨obner basis of M . Then there are matrices A = (aij) and B = (bij)
with coeﬃcients in P such that mi = ai1g1 + · · · + aisgs for i = 1, . . . , t
and gj = bj1m1 + · · · + bjtmt for j = 1, . . . , s. Give an example in which
AB is not the identity matrix.

2.5 Buchberger’s Algorithm
121
2.5 Buchberger’s Algorithm
Knowing + and × is good enough,
understanding their interaction is ideal.
(Bruno Buchberger)
In the last section we saw some theoretical applications of Gr¨obner bases,
especially of reduced Gr¨obner bases. But Gr¨obner bases would be hardly
more than a small side subject in commutative algebra if we did not have
the possibility of computing them. The key to almost all applications of
Gr¨obner bases in Computational Commutative Algebra, and therefore to the
remainder of these volumes, is the algorithm developed by Bruno Buchberger
in his doctoral thesis [Bu65].
As we mentioned in the introduction of Section 2.3, the algorithmic way
to replace a given set of generators of a module with a Gr¨obner basis is based
on the characterization of Gr¨obner bases via lifting of syzygies. The idea is
that we need to check whether the set of generators satisﬁes Condition D3).
If a syzygy of the leading terms is found which does not lift to a syzygy of the
generators, we can ﬁnd an element of the module which has a new leading
term. By adding it to the set of generators, we can achieve the desired lifting.
Then the termination of the algorithm is guaranteed by Dickson’s Lemma
(more precisely, by Corollary 1.3.10), and its correctness follows from the
fact that lifting of syzygies characterizes Gr¨obner bases (see Theorem 2.4.1).
Since Buchberger’s Algorithm is the basic tool underlying most calcula-
tions in Computational Commutative Algebra, it is very important to study
possibilities for optimizing it. First indications on how to avoid some unnec-
essary steps in the execution of the algorithm are given in Remark 2.5.6 and
Proposition 2.5.8. Some additional possibilities are contained in Tutorial 25.
For the case of systems of generators consisting of homogeneous polynomials
or vectors of polynomials, an eﬃcient version of Buchberger’s Algorithm will
be explained in Volume 2.
At the end of this section we discuss the Extended Buchberger Algorithm.
Besides a Gr¨obner basis, it also yields the change of basis matrix from the
given system of generators to the Gr¨obner basis (see Proposition 2.5.11).
As usual, let K be a ﬁeld, let n ≥1, let P = K[x1, . . . , xn] be a polyno-
mial ring, let r ≥1, and let σ be a module term ordering on Tn⟨e1, . . . , er⟩.
Our goal is to compute a σ-Gr¨obner basis of a P -submodule M ⊆P r which
is explicitly given by a system of generators G = {g1, . . . , gs} ⊆P r \ {0}.
Let G be the tuple (g1, . . . , gs). We start by writing LMσ(gi) = citieγi with
ci ∈K \ {0}, ti ∈Tn , and γi ∈{1, . . . , r} for i = 1, . . . , s, and by recalling
the fundamental diagram
0
−→
Syz(G)
−→
P s
λ
−→
P r
−→
P r/M
−→
0
yLF
yLM
0
−→
Syz(LMσ(G))
−→
P s
Λ
−→
P r
−→
P r/N
−→
0

122
2. Gr¨obner Bases
studied in Section 2.3. Then we introduce or recall the following abbrevia-
tions.
Deﬁnition 2.5.1. Let B be the set B = {(i, j) | 1 ≤i < j ≤s, γi = γj}.
Moreover, let tij = lcm(ti,tj)
ti
=
tj
gcd(ti,tj) ∈Tn and σij = 1
ci tijεi−1
cj tjiεj ∈P s
for all i, j ∈{1, . . . , s}. For every pair (i, j) ∈B, we call
Sij = λ(σij) = 1
ci tij gi −1
cj tji gj ∈M
the S-vector of gi and gj . If r = 1, we call Sij ∈P also the S-polynomial
of gi and gj .
We can rephrase Theorem 2.3.7 by saying that if (i, j) ∈B, then σij is a
homogeneous element of P s with degσ,G(σij) = lcm(ti, tj)eγi and that the
set Σ = {σij | (i, j) ∈B} is a homogeneous system of generators of the
P -module Syz(LMσ(G)). Furthermore, we know by Theorem 2.4.1 that G
is a σ-Gr¨obner basis of M if and only if all those elements σij have liftings
in Syz(G). For some of them, this is always the case.
Proposition 2.5.2. Let (i, j) ∈B be such that Sij
G
−→0. Then σij has a
lifting in Syz(G).
Proof.
If Sij = 0, there is nothing to show, since σij is a lifting of it-
self. Thus we may assume Sij ̸= 0. In view of Lemma 2.2.6, we can use
Sij
G
−→0 to obtain a representation Sij = Ps
k=1 fkgk with f1, . . . , fs ∈P
such that LTσ(Sij) = maxσ{LTσ(fkgk) | 1 ≤k ≤s, fkgk ̸= 0}. Since
σij is homogeneous, we have Λ(LF(σij)) = Λ(σij) = 0, and Proposi-
tion 2.3.6.b yields degσ,G(σij) >σ LTσ(Sij). Now we consider the element
τij = σij −Ps
k=1 fkεk ∈P s. From degσ,G(Ps
k=1 fkεk) = LTσ(Sij) <σ
degσ,G(σij) we deduce that LFσ,G(τij) = σij . From λ(τij) = λ(σij)−Sij = 0
and LF(τij) = σij we conclude that τij is a lifting of σij in Syz(G).
□
Corollary 2.5.3. (Buchberger’s Criterion)
Let M ⊆P r be a P -submodule generated by G = {g1, . . . , gs} ⊆P r \ {0},
and let G = (g1, . . . , gs). Then the following conditions are equivalent.
a) The set G is a σ-Gr¨obner basis of M .
b) For all pairs (i, j) ∈B, we have NRσ,G(Sij) = 0.
Proof.
If G is a σ-Gr¨obner basis of M, then Sij ∈M yields NRσ,G(Sij) = 0
by Corollary 2.4.9.a and Proposition 2.4.10.a. Conversely, if condition b)
holds, then Sij
G
−→0. Using Proposition 2.5.2 we see that, for every pair
(i, j) ∈B, the element σij has a lifting in Syz(G). Thus Condition D3) of
Theorem 2.4.1 holds.
□
Let us see how this criterion applies in practice. The following example
also shows that the leading term ideal of the square of an ideal is, in general,
not the square of the leading term ideal.

2.5 Buchberger’s Algorithm
123
Example 2.5.4. Let P = Q[x, y, z], let σ = DegRevLex, and let I be the
ideal of P generated by g1 = x2 −y2 , g2 = xy2 −z3 , and g3 = y4 −xz3 =
−y2g1 + xg2 . Successively, we compute
S12 = −y2g1 + xg2 = y4 −xz3
g3
−→0
S13 = y4g1 −x2g3 = −y6 + x3z3
g3
−→x3z3 −xy2z3
g2
−→0
S23 = y2g2 −xg3 = −y2z3 + x2z3
g1
−→0
Thus Buchberger’s Criterion applies and says that {g1, g2, g3} is a σ-Gr¨obner
basis of I . In particular, the leading term ideal of I is LTσ(I) = (x2, xy2, y4).
By the way, in this example the obvious inclusion LTσ(I)2 ⊆LTσ(I2) is a
strict one, disproving a claim in [CLS92], p. 443. More precisely, the element
f = g2
2 −g1g3 = y6 +x3z3 −3xy2z3 +z6 ∈I2 has a leading term LTσ(f) = y6
which is not in LTσ(I)2 .
The idea of Buchberger’s Algorithm is to enlarge G in such a way that
eventually all elements σij with (i, j) ∈B have a lifting in Syz(G). By
Theorem 2.4.1, this ensures that the enlarged set is a σ-Gr¨obner basis of M .
Theorem 2.5.5. (Buchberger’s Algorithm)
Let G = (g1, . . . , gs) ∈(P r)s be a tuple of non-zero elements which generate
a submodule M = ⟨g1, . . . , gs⟩⊆P r. For i = 1, . . . , s, let LMσ(gi) = citieγi
with ci ∈K \ {0}, ti ∈Tn, and γi ∈{1, . . . , r}. Consider the following
sequence of instructions.
1) Let s′ = s and B = B = {(i, j) | 1 ≤i < j ≤s′, γi = γj}.
2) If B = ∅, return the result G . Otherwise, choose a pair (i, j) ∈B and
delete it from B.
3) Compute Sij =
tj
ci gcd(ti,tj) gi−
ti
cj gcd(ti,tj) gj and NRσ,G(Sij). If the result
is NRσ,G(Sij) = 0, continue with step 2).
4) Increase s′ by one. Append gs′ = NRσ,G(Sij) to G and the set of pairs
{(i, s′) | 1 ≤i < s′, γi = γs′} to B. Then continue with step 2).
This is an algorithm, i.e. it stops after ﬁnitely many steps. It returns a tuple
G of vectors which form a σ-Gr¨obner basis of M .
Proof.
Every time step 2) is executed, one pair is cancelled from B. The
set B is enlarged only in step 4). When this happens, an element is ap-
pended to G which has a leading term with respect to σ which is not in the
monomodule generated by the leading terms of the previous elements of G .
Corollary 1.3.10 shows that P r cannot contain an inﬁnite chain
⟨LTσ(g1), . . . , LTσ(gs)⟩⊂⟨LTσ(g1), . . . , LTσ(gs+1)⟩⊂· · ·
Therefore step 4) can be executed only a ﬁnite number of times, i.e. the
procedure stops after ﬁnitely many steps.

124
2. Gr¨obner Bases
It remains to show that when the algorithm stops, the vectors in the
resulting tuple G form a σ-Gr¨obner basis of M . During the execution of the
procedure all pairs (i, j) ∈B are considered, since whenever s′ is increased
in step 4), all necessary new pairs (i, s′) are added to B. By Corollary 2.5.3,
it suﬃces to show that, for every (i, j) ∈B, we have NRσ,G(Sij) = 0. If at
a certain step Sij = 0 or NRσ,G(Sij) = 0, there is nothing to prove. If at
a certain step NRσ,G(Sij) ̸= 0, then NRσ,G(Sij) is added to the tuple G .
Hence NRσ,G(Sij) reduces to 0 via the rewrite rule deﬁned by the vectors in
the new tuple.
□
A closer look at this proof shows that a number of variants and optimiza-
tions of Buchberger’s Algorithm are possible. Some of the most eﬀective ones
will be discussed in Tutorial 25 and in Volume 2. Here we limit ourselves to
pointing out some obvious opportunities for improvement.
Remark 2.5.6. (First Optimizations of Buchberger’s Algorithm)
a) In Buchberger’s Algorithm, one can substitute the computation of the
normal remainder NRσ,G(Sij) by any procedure producing an element
m ∈P r which satisﬁes Sij
G
−→m, and LTσ(m) /∈⟨LTσ(g1), . . . , LTσ(gs′)⟩
if m ̸= 0.
b) If B′ ⊆B is a subset with the property that also the set {σij | (i, j) ∈B′}
generates Syz(LMσ(G)), it suﬃces to start with B = B′ in step 1) of
Buchberger’s Algorithm. This follows from Proposition 2.3.11.
c) In step 2) of the theorem we did not specify which pair (i, j) ∈B
we should choose. One possibility is to take the pair (i, j) for which
lcm(ti, tj) is minimal with respect to σ. This is called the normal se-
lection strategy. It works well in practice if the term ordering σ is
degree-compatible. Another possibility which avoids sorting the terms
lcm(ti, tj) with respect to σ is to take any pair (i, j) for which the de-
gree of lcm(ti, tj) is minimal.
To help the reader understand Theorem 2.5.5 better, we now apply Buch-
berger’s Algorithm in a concrete case.
Example 2.5.7. Let n = 2, let r = 1, let M ⊆P = K[x, y] be the ideal
generated by g1 = x2 and g2 = xy + y2 , and let G = (g1, g2). We want to
compute a Gr¨obner basis of M with respect to σ = Lex and follow the steps
of Buchberger’s Algorithm.
1) Let s′ = 2 and B = {(1, 2)}.
2) Choose (1, 2) ∈B and set B = ∅.
3) We compute S12 = yg1 −xg2 = −xy2
g2
−→y3 = NRσ,G(S12) ̸= 0.
4) Let s′ = 3, let G = (g1, g2, g3) with g3 = y3 , and let B = {(1, 3), (2, 3)}.
Then return to step 2).
2) Choose (1, 3) ∈B and set B = {(2, 3)}.
3) We compute S13 = y3g1 −x2g3 = 0 and return to step 2).

2.5 Buchberger’s Algorithm
125
2) Choose (2, 3) ∈B and set B = ∅.
3) We compute S23 = y2g2 −xg3 = y4 . Then we calculate S23
g3
−→0 =
NRσ,G(S23) and return to step 2).
2) Since B = ∅, we return the result G = (g1, g2, g3).
If r = 1, i.e. if M is an ideal in P , there is another optimization of
Buchberger’s Algorithm which turns out to be useful in practise.
Proposition 2.5.8. Let G = (g1, . . . , gs) be a tuple of non-zero polynomials,
let I = (g1, . . . , gs) ⊆P , and let ti = LTσ(gi) for i = 1, . . . , s. Suppose that
gcd(ti, tj) = 1 for some pair (i, j) ∈B. Then σij has a lifting in Syz(G).
Proof.
This follows from the observations that σij =
1
ci tjεi −
1
cj tiεj and
that τij =
1
cicj gjεi −
1
cicj giεj is a lifting of σij in Syz(G).
□
Remark 2.5.9. For f, g ∈P , the pair (−g, f) is called the trivial syzygy
of (f, g). Therefore Proposition 2.5.8 can be rephrased by saying that if
gcd(ti, tj) = 1, then the trivial syzygy of (LMσ(gi), LMσ(gj)) can be lifted
to the trivial syzygy of (gi, gj).
The above result can be used to detect some special Gr¨obner bases.
Corollary 2.5.10. Let G = {g1, . . . , gs} ⊆P \{0}, and let I = (g1, . . . , gs).
Assume that the leading terms of the elements g1, . . . , gs are pairwise co-
prime. Then G is a σ-Gr¨obner basis of I .
Proof.
Let G = (g1, . . . , gs). By Proposition 2.5.8, every element σij has a
lifting in Syz(G). Thus G satisﬁes Condition D3) of Theorem 2.4.1.
□
Finally, we can extend Buchberger’s Algorithm in such a way that it not
only computes a Gr¨obner basis of a submodule M ⊆P r , but also a matrix
of polynomials which describes how the Gr¨obner basis can be expressed in
terms of the original system of generators of M .
Proposition 2.5.11. (The Extended Buchberger Algorithm)
Let G = (g1, . . . , gs) ∈(P r)s be a tuple of non-zero vectors in P r which
generate a submodule M = ⟨g1, . . . , gs⟩⊆P r . We write LMσ(gi) = citieγi
with ci ∈K \ {0}, ti ∈Tn , and γi ∈{1, . . . , r} for i = 1, . . . , s. Consider
the following sequence of instructions.
1) Let s′ = s, let A be the s × s identity matrix, and let B = B.
2) If B = ∅, return the result (G, A). Otherwise, choose a pair (i, j) ∈B
and delete it from B.
3) Use the Division Algorithm 1.6.4 to compute a representation Sij =
q1g1 + · · · + qs′gs′ + p, where q1, . . . , qs′ ∈P and p ∈P r , such that
the conditions of Theorem 1.6.4 hold.
If p = 0, continue with step 2).

126
2. Gr¨obner Bases
4) If p ̸= 0 in step 3), then increase s′ by one, append gs′ = p to G ,
add {(i, s′) | 1 ≤i < s′, γi = γs′} to B, and append the column vec-
tor
tj
ci gcd(ti,tj)ai −
ti
cj gcd(ti,tj)aj −q1a1 −· · · −qs′−1as′−1 to A, where
a1, . . . , as′−1 denote the previous columns of A. Then continue with
step 2).
This is an algorithm, i.e. it stops after ﬁnitely many steps. It returns a tuple
G = (g1, . . . , gs′) of vectors which form a σ-Gr¨obner basis of M , where
s′ ≥s, together with an s × s′ -matrix A = (aij) of polynomials such that
gj = a1jg1 + · · · + asjgs for j = 1, . . . , s′ .
Proof.
In view of Theorem 2.5.5, it suﬃces to prove the last claim. Each time
a new column is appended to A in step 4), we have gj = a1jg1+· · ·+asjgs for
j < s′ , where s′ is the current number of columns of A. Now the calculation
gs′ = p = Sij −q1g1 −· · · −qs′−1gs′−1
= tij
ci (a1ig1 + · · · + asigs) −tji
cj (a1jg1 + · · · + asjgs)
−Ps′−1
k=1 qk(a1kg1 + · · · + askgs)
= (g1, . . . , gs) · (
tj
ci gcd(ti,tj)ai −
ti
cj gcd(ti,tj)aj −q1a1 −· · · −qs′−1as′−1)
= (g1, . . . , gs) · (a1s′, . . . , ass′)tr = a1s′g1 + · · · + ass′gs
ﬁnishes the proof.
□
To show how this extended algorithm works in practice, let us apply it in
the situation of Example 2.5.7.
Example 2.5.12. Let n = 2, let r = 1, let M ⊆P = K[x, y] be the
ideal generated by g1 = x2 and g2 = xy + y2 , and let G = (g1, g2). As in
Example 2.5.7, we follow the steps of the Buchberger Algorithm, except that
we now use the extended version above.
1) Let s′ = 2, let A =
¡1 0
0 1
¢
, and let B = {(1, 2)}.
2) Choose (1, 2) ∈B and set B = ∅.
3) We compute S12 = −xy2 = 0·g1+(−y)·g2+y3 and let q1 = 0, q2 = −y,
and p = y3 .
4) Let s′ = 3, let G = (g1, g2, g3) with g3 = y3 , and let B = {(1, 3), (2, 3)}.
We append the column vector ya1 −xa2 −0 · a1 + ya2 to the matrix A
and get A =
¡1 0
y
0 1 −x+y
¢
. Then we return to step 2).
2) Choose (1, 3) ∈B and set B = {(2, 3)}.
3) We compute S13 = y3g1 −x2g3 = 0 and return to step 2).
2) Choose (2, 3) ∈B and set B = ∅.
3) We compute S23 = y4 = 0 · g1 + 0 · g2 + yg3 . Then we return to step 2).
2) Since B = ∅, we return the result (G, A), where G = (g1, g2, g3) and
A =
¡1 0
y
0 1 −x+y
¢
.

2.5 Buchberger’s Algorithm
127
Exercise 1.
Let P = K[x, y, z], let G = (x2 −y, xy −z) ∈P 2 , and
let σ = DegRevLex. Perform all steps of Buchberger’s Algorithm applied
to G . Then ﬁnd a term ordering σ such that G is a σ-Gr¨obner basis of
the ideal (x2 −y, xy −z).
Exercise 2. Apply Buchberger’s Algorithm as in Example 2.5.7 to com-
pute a DegLexPos-Gr¨obner basis of the submodule M = ⟨g1, g2, g3, g4⟩
of Q[x, y]3 in the following cases.
a) g1 = (x2, xy, y2), g2 = (y, 0, x), g3 = (0, x, y), g4 = (y, 1, 0)
b) g1 = (y −x, y, y), g2 = (xy, x, x), g3 = (x, y, y), g4 = (x, y, 0)
c) g1 = (0, y, x), g2 = (0, x, xy −x), g3 = (y, x, 0), g4 = (y2, y, 0)
Exercise 3. In the cases of Exercise 2, determine representatives for a
K -basis of Q[x, y]3/M .
Exercise 4. Find out which module M ⊆Q[x, y]3 in Exercise 2 contains
the vector
m = (x2y −y2 + xy2, xy2 −y2 + x2 + 2xy −x −y, x2y + xy2 −3xy + x)
Exercise 5. A polynomial f ∈P = K[x1, . . . , xn] is called a binomial
if it is of the form f = at + a′t′ with a, a′ ∈K \ {0} and t, t′ ∈Tn . Let σ
be a term ordering on Tn and I a binomial ideal, i.e. an ideal generated
by binomials.
a) Prove that the reduced σ-Gr¨obner basis of I consists of binomials.
b) Given a term t ∈Tn , show that NFσ,I(t) is a scalar multiple of a
term.
Exercise 6.
Consider the polynomial ring P = Q[x, y], the P -sub-
module M = ⟨g1, g2, g3, g4⟩⊆P 3 such that g1 = (xy, x, y), g2 = (y2 + y,
x + y2, x), g3 = (−x, y, x), g4 = (y2, y, x), and the module term ordering
σ = LexPos.
a) Using the algorithm given in Proposition 2.5.11, compute a σ-Gr¨obner
basis {g1, . . . , gs′} of M , where s′ ≥4, and a matrix A such that
(g1, . . . , gs′) = (g1, . . . , g4) · A.
b) Now use the method described in the proof of Proposition 2.4.13 to
compute the reduced σ-Gr¨obner basis {g′
1, . . . , g′
6} of M . Then ﬁnd
a matrix A′ such that (g′
1, . . . , g′
6) = (g1, . . . , g4) · A′ .
c) For the following elements of P 3 , check whether they lie in M , and if
they do, ﬁnd their representations in terms of both {g′
1, . . . , g′
6} and
{g1, . . . , g4}.
1) m1 = (−2y, y −1, xy + y)
2) m2 = (xy5 −xy + y, xy4 + x + 2y2 −y, y5 + xy)
d) For the following pairs of elements of P r , check whether m1 + M
agrees with m2 + M in the residue class module P r/M .
1) m1 = (2y, x2y + x2 + xy + 2x −3y, −x + y), m2 = (−x2 + y −x,
x3 + 2x2, x2 −y)
2) m1 = (x3+x2+y−x, x2+x, x+y), m2 = (y, x3+2x2−xy−y, 0)

128
2. Gr¨obner Bases
Tutorial 23: Buchberger’s Criterion
In this tutorial we shall implement Buchberger’s Criterion 2.5.3 and use it
to decide whether certain sets of polynomials are Gr¨obner bases of the ideals
they generate. As in the whole section, we let K be a ﬁeld, we let P =
K[x1, . . . , xn] be a polynomial ring over K , we let σ be a module term
ordering on Tn⟨e1, . . . , er⟩, where r ≥1, we let G = (g1, . . . , gs) be a tuple
of non-zero vectors, and we let M ⊆P r be the P -submodule generated by
the vectors in G .
a) Write a CoCoA function CheckGB(. . .) which takes G and uses Buch-
berger’s Criterion 2.5.3 to check whether it forms a σ-Gr¨obner basis
of M . (Hint: You may want to use the function NormalRemainder(. . .)
from Tutorial 15 or the built-in CoCoA function NR(. . .).)
b) Let G = {x2−x2
1, x3−x3
1} ⊆Q[x1, x2, x3}. Use the function CheckGB(. . .)
to check whether G is a σ-Gr¨obner basis of the ideal it generates, where
σ is one of the following term orderings: Lex, DegLex, Ord(V ) where
V =
³ 0
0
1
0
1
0
1
0
0
´
or V =
³ 0
0
1
1
0
0
0
1
0
´
.
c) Use the function CheckGB(. . .) to determine which of the following sys-
tems of generators are Gr¨obner bases with respect to the stated term or-
derings of the ideals and modules they generate. In the ﬁrst three cases,
try to ﬁnd a term ordering and a system of generators containing G such
that Corollary 2.5.10 can be applied.
1) G = {x1x2
2 −x1x3 + x2, x1x2 −x2
3, x1 −x2x4
3} ⊆Q[x1, x2, x3] with
respect to Lex
2) G = {x4
1x2
2 −x5
3, x3
1x3
2 −1, x2
1x4
2 −2x3} ⊆Q[x1, x2, x3] with respect
to DegLex
3) G = {x1x3 −x2
2, x1x4 −x2x3, x2x4 −x2
3} ⊆Q[x1, x2, x3, x4] with
respect to DegRevLex
4) G = {(x2
1 −x2x3)(e1 + e2), (x1x3 −x2x4)(e1 −e2), (x2
3 −x1x4)e1,
(x2
3 −x1x4)e2} ⊆Q[x1, x2, x3, x4]2 with respect to PosDegRevLex
and DegRevLexPos
5) G = {(x1 −x2
2)e1, (x1 −x3
3)e1, (x2 −x2
1)e2, (x2 −x3
3)e2, (x3 −x2
1)e3,
(x3 −x3
2)e3} ⊆Q[x1, x2, x3]3 with respect to PosDegRevLex and
DegRevLexPos
d) Let n > 1, and let σ be the lexicographic term ordering on K[x1, . . . , xn,
y1, . . . , yn] such that x1 >σ · · · >σ xn >σ y1 >σ · · · >σ yn. Moreover,
for i = 1, . . . , n, let si = P
1≤j1<···<ji≤n xj1 · · · xji be the ith elementary
symmetric polynomial in x1, . . . , xn (see also Tutorial 12), and let hi,j =
P
αj+···+αn=i xαj
j · · · xαn
n
for i, j = 1, . . . , n. Use Buchberger’s Criterion
to prove that the polynomials
gi = (−1)i(yi −si) +
i−1
X
j=1
(−1)jhi−j,i (yj −sj)

2.5 Buchberger’s Algorithm
129
such that i = 1, . . . , n form a σ-Gr¨obner basis of the polynomial ideal
I = (y1 −s1, . . . , yn −sn).
e) Verify the result of d) for n = 1, . . . , 5 by applying your function
CheckGB(. . .). Can you compute this for larger n? How far can you go?
Tutorial 24: Computing Some Gr¨obner Bases
The purpose of this tutorial is to implement a ﬁrst version of Buchberger’s
Algorithm in the case of polynomial ideals, and to use it to study some
particular examples. For instance, we will see that the elements of the reduced
Gr¨obner basis of an ideal can have very high degree, even if the generators
of the ideals have low degrees.
Then, for the speciﬁc ideal I = (yz −z2, xz −z2, xy −z2), you will be
guided to ﬁnd all possible reduced Gr¨obner bases of I , and to give a meaning
to the picture on the cover of this book. As usual, we let P = K[x1, . . . , xn]
be a polynomial ring over a ﬁeld K .
a) Write a CoCoA function SPoly(. . .) which takes a tuple of non-zero poly-
nomials (g1, . . . , gs) and indices i, j ∈{1, . . . , s} with i ̸= j as arguments
and returns the S-polynomial Sij of gi and gj with respect to the current
term ordering.
b) Implement Buchberger’s Algorithm 2.5.5 in the case of polynomial ideals.
To this end, write a CoCoA program FirstGB(. . .) which takes a tuple
of non-zero polynomials generating the ideal and computes a Gr¨obner
basis with respect to the current term ordering. (Hint: For step 3), use
the built-in function NR(. . .) or NormalRemainder(. . .) of Tutorial 15.)
c) Using FirstGB(. . .), calculate the Gr¨obner bases of the following ideals
with respect to the stated term orderings.
1) I = (x2
2, x1x2x3 + x3
3) ⊆Q[x1, x2, x3] with respect to DegRevLex
2) I = (x2
1x2 −1, x1x2
2 −x1) ⊆Q[x1, x2] with respect to Lex and
DegLex
3) I = (x1 −x4
3, x2 −x5
3) ⊆Q[x1, x2, x3] with respect to Lex and
DegRevLex
d) Prove that for every number m ≥1, the reduced Gr¨obner basis of
Im = (xm+1
1
−x2xm−1
3
x4, x1xm−1
2
−xm
3 , xm
1 x3−xm
2 x4) ⊆K[x1, x2, x3, x4]
with respect to DegRevLex contains fm = xm2+1
3
−xm2
2 x4 . Note that the
degree m2 + 1 of this polynomial is much higher than the degrees of the
generators of Im. Can you write down the whole reduced Gr¨obner basis
of Im with respect to DegRevLex? (Guess it or prove it!)
e) If you couldn’t do the second part of d), calculate the reduced Gr¨obner
basis of the ideal Im with respect to DegRevLex using FirstGB(. . .) for
m = 1, . . . , 100 and determine its length.

130
2. Gr¨obner Bases
f) Prove that the ideal I3 of part d) has the same reduced Gr¨obner bases
with respect to Lex and DegRevLex. Does this hold for all m ≥1?
In the remainder of this tutorial, we want to study the polynomial ideal
I = (xy −z2, xz −z2, yz −z2) in P = K[x, y, z]. Although we are not going
to use it, we mention that I is the ideal of all polynomials which vanish at
three lines in A3
K passing through the origin, or, equivalently, at three points
in P2
K (see Tutorials 27 and 35).
g) Let σ be any term ordering such that x >σ z and y >σ z. Show that
the reduced σ-Gr¨obner basis of I is {xz −z2, yz −z2, xy −z2}.
h) Let σ be any term ordering such that x >σ z and z >σ y. Show that
the reduced σ-Gr¨obner basis of I is {xy −yz, xz −yz, z2 −yz}.
i) Let σ be any term ordering such that y >σ z and z >σ x. Show that
the reduced σ-Gr¨obner basis of I is {z2 −xz, yz −xz, xy −xz}.
j) Consider the situation where σ is a term ordering such that z >σ x and
z >σ y. Show that there are only two possible reduced Gr¨obner bases
of I , according as x >σ y or y >σ x. Observe that in both cases the
number of elements in the reduced Gr¨obner basis is four.
k) Prove there are exactly ﬁve reduced Gr¨obner bases of I .
l) Group the term orderings in ﬁve classes, depending on the inequalities
considered before. Then ﬁnd ﬁve term orderings which give rise to the
ﬁve reduced Gr¨obner bases you found above.
m) Prove that for each of the ﬁve reduced Gr¨obner bases, there is an inﬁnite
set of term orderings σ such that it is the reduced σ-Gr¨obner basis of I .
n) Consider the description of term orderings by matrices explained in Sec-
tion 1.4. Try to use it to interpret the following picture.
........................................................................ ................
....................................................................
................
.........................................................................
................
.............
...................................
...................................
.............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
....................................................................................................................................................................................................................................................................................................
.....................................................................................................................................................................................................................
x
y
z
(1, 0, 0)
(0, 1, 0)
(0, 0, 1)

2.5 Buchberger’s Algorithm
131
Tutorial 25: Some Optimizations of Buchberger’s Algorithm
The purpose of this tutorial is to ﬁnd and to implement optimized versions
of Buchberger’s Algorithm in the case of polynomial ideals. The amount
of time consumed by a certain Gr¨obner basis computation depends largely
on the number of pairs which have to be dealt with, and on the number
of reduction steps which have to be performed in order to treat each pair.
Therefore we will ask you to implement counters in your programs which
measure these quantities, and we will judge our progress towards our goal of
optimizing Buchberger’s Algorithm by looking at the numbers returned by
those counters.
Let P = K[x1, . . . , xn] be a polynomial ring over a ﬁeld K , let I ⊆P be
an ideal, and let G = (g1, . . . , gs) be a tuple of non-zero polynomials which
generate I . Furthermore, let σ be a term ordering, and let the elements
ti, tij ∈Tn , σij ∈P s, and Sij ∈P be deﬁned as at the beginning of this
section.
a) Update your CoCoA function FirstGB(. . .) from Tutorial 24 such that it
returns not only a σ-Gr¨obner basis of I , but also the number of pairs
(i, j) such that Sij ̸= 0, i.e. such that the normal remainder had to be
computed, and the total number of reduction steps which were necessary
to compute all those normal remainders.
Hint: You will have to modify the function NormalRemainder(. . .) from
Tutorial 15 suitably.
b) Apply your new function FirstGB(. . .) in the following ﬁve cases. Each
time, compute a Gr¨obner basis with respect to DegRevLex and one with
respect to Lex.
1) I = (x2
1 −2x2
2 + 3x1, x3
1 −2x1x2) in Q[x1, x2]
2) I = (x1 −2x4
3, x2 −3x5
3) in Q[x1, x2, x3]
3) I = (x2
1 −2x2
2, x3
1 −3x3
3, x4
1 −x4
4) in Q[x1, x2, x3, x4]
4) I = (x3
1 −4x3
2, x5
1 −7x5
3, x7
1 −11x7
4) in Q[x1, x2, x3, x4]
5) I = (x2
1 + x3
2 + x3
3 −1, x3
1 + x4
2 + x5
3 −1) in Q[x1, x2, x3]
c) Implement a CoCoA function SecondGB(. . .) which takes the list G and
computes a σ-Gr¨obner basis of I via Buchberger’s Algorithm 2.5.5,
where the pair (i, j) ∈B is chosen in step 2) according to the nor-
mal selection strategy (see Remark 2.5.6.c), and where the optimization
which follows from Proposition 2.5.8 is used.
d) Apply your function SecondGB(. . .) in the cases of b) and compare the re-
sults of your counters with those returned by the function FirstGB(. . .).
e) Given 1 ≤i < j < k ≤s, ﬁnd three terms t, t′, t′′ ∈Tn such that
tσij + t′σjk + t′′σik = 0. Prove that one can choose t′′ = 1 if and only
if tk divides lcm(ti, tj). Give similar criteria for t = 1 and t′ = 1. The
triple (i, j, k) is called a Buchberger triple if one can choose t = 1 or
t′ = 1 or t′′ = 1.

132
2. Gr¨obner Bases
f) Prove that one can drop a pair (i, j) in the execution of Buchberger’s
Algorithm if it is contained in a Buchberger triple and if the other two
pairs have been treated already. Write a CoCoA function ThirdGB(. . .)
which is based on SecondGB(. . .) and adds this new optimization. To
make sure that you do not drop more than one pair from a Buchberger
triple, implement a list T which keeps track of the pairs which have been
treated already.
g) Apply your function ThirdGB(. . .) in the cases of b) and determine the
improvement which has been achieved.
h) Start again with your implementation SecondGB(. . .) of Buchberger’s
Algorithm, and replace step 4) by the following sequence of instructions.
4a) Increase s′ by one. Append gi = NRσ,G(Sij) to G , and form the set
C = {(i, s′) | 1 ≤i < s′, γi = γs′}.
4b) Delete in C all pairs (j, s′) such that there exists an index i
in {1, . . . , s′ −1} with the properties that i < j and ts′i divides ts′j .
4c) Delete in C all pairs (i, s′) such that there exists an index j
in {1, . . . , s′ −1} with the properties that i < j and ts′j properly
divides ts′i .
4d) Delete in B all pairs (i, j) such that no divisibility occurs between
ts′i and ts′j (hence both (i, s′) and (j, s′) survived the preceding
two steps) and we have gcd(tis′, tjs′) = 1.
4e) Replace B by B ∪C and continue with step 2).
The fact that this modiﬁed algorithm still computes a σ-Gr¨obner basis
of M in ﬁnitely many steps will be studied in Volume 2. Implement it in
a CoCoA function GoodGB(. . .), apply this function in the cases of b), and
compare the values returned by your counters with the earlier results.

2.6 Hilbert’s Nullstellensatz
133
2.6 Hilbert’s Nullstellensatz
The art of doing mathematics
consists in ﬁnding that special case
which contains all the germs of generality.
(David Hilbert)
As in the ﬁrst chapter, this closing section deviates from the main line
of development. It is both a bridge to many applications of Computational
Commutative Algebra and a foundation for numerous theoretical advances
in later chapters. In the introduction of this book we mentioned that one
of the most common areas where Computational Commutative Algebra is
applied is algebraic geometry. The fundamental tool to translate statements
from algebraic geometry into the language of commutative algebra and back
is Hilbert’s Nullstellensatz.
So, what is the relation between geometry and polynomials? Polynomial
rings were introduced right at the beginning of this book. Since then, we
kept trying to extract information from their intrinsic algebraic structure. But
there is another way of looking at polynomials: they can be seen as functions.
More precisely, given a polynomial f in the polynomial ring K[x1, . . . , xn]
over a ﬁeld K and an extension ﬁeld L ⊇K , we can evaluate f at each
point of Ln and obtain a function from Ln to L.
Of special importance is then the set of zeros of f , i.e. the set of points
(a1, . . . , an) ∈Ln such that f(a1, . . . , an) = 0. More generally, we can ex-
tend the setting to many polynomial equations and look for their common ze-
ros. These are the geometric counterparts of polynomial ideals, and Hilbert’s
Nullstellensatz, in its diﬀerent versions, provides the connection between both
kinds of objects.
Since we are trying to be as self-contained as possible, we present a proof
of Hilbert’s Nullstellensatz in the current section. At several key points the
theory of Gr¨obner bases will prove very useful. On the way, we shall also
obtain a clearer picture of how the set of solutions of a system of polynomial
equations depends on the ﬁeld over which those equations are deﬁned, and
on the ﬁeld where we look for the coordinates of the solution points. For
instance, the polynomial x4 + 2x2 + 1 ∈R[x] has no zeros in R, but the
two zeros i and −i in C. As we shall see, this simple special case already
contains the germ of many more general phenomena.
The section begins with the proofs of some algebraic facts which lead to
the ﬁeld theoretic version of Hilbert’s Nullstellensatz (see Theorem 2.6.6).
This theorem can also be viewed as a structure theorem for maximal ideals
in polynomial rings over algebraically closed ﬁelds (see Corollary 2.6.9). As a
consequence, we are able to interpret the zeros of an ideal I in such a polyno-
mial ring as the set of maximal ideals containing I (see Proposition 2.6.11).
For instance, the zeros of x4 + 2x2 + 1 ∈C[x] correspond to the maximal
ideals (x + i) and (x −i) containing this polynomial.

134
2. Gr¨obner Bases
Given a ﬁeld extension K ⊂L, an important result is proved about
the behaviour of ideals under extension from K[x1, . . . , xn] to L[x1, . . . , xn].
This result is the key to the weak form of Hilbert’s Nullstellensatz (see Theo-
rem 2.6.13) which provides us with an eﬀective way to check whether a given
polynomial ideal has zeros in K
n, where K is the algebraic closure of K .
For our ideal (x4 + 2x2 + 1) ⊆R[x], the easy observation 1 /∈(x4 + 2x2 + 1)
suﬃces to conclude that it has zeros in the algebraic closure C of R.
Finally, we prove the Nullstellensatz in its full generality (see Theo-
rem 2.6.16). It says that the operation of forming the vanishing ideal of a
subset of K
n is an inverse to the operation of taking the set of zeros of a
polynomial ideal if one considers radical ideals only. This highlights the im-
portance of the ideal theoretic operation of forming the radical of an ideal.
In the case of the principal ideal (x4 + 2x2 + 1) in C[x], it says that the
vanishing ideal of its set of zeros {i, −i} is its radical ideal (x2 + 1).
2.6.A
The Field-Theoretic Version
Let K be an arbitrary ﬁeld. Many algebraic geometers use the following
terminology.
Deﬁnition 2.6.1. A ﬁnitely generated K -algebra is also called an aﬃne
K -algebra.
According to Corollary 1.1.14, such algebras are of the form P/I for some
polynomial ring P = K[x1, . . . , xn] and some ideal I ⊆P . Now we present
three lemmas leading up to the ﬁrst theorem of this section which is also
called the ﬁeld-theoretic version of Hilbert’s Nullstellensatz. Recall that the
ﬁeld of fractions of a polynomial ring P = K[x1, . . . , xn] is usually denoted
by Q(P) = K(x1, . . . , xn).
Lemma 2.6.2. Let x be an indeterminate over our ﬁeld K . Then K(x) is
not an aﬃne K -algebra.
Proof.
Suppose K(x) = K[ f1
g1 , . . . , fs
gs ] for some f1, . . . , fs, g1, . . . , gs ∈K[x]
such that g1 ·g2 · · · gs ̸= 0. Since 1
x /∈K[x], we may assume g1 ·g2 · · · gs /∈K .
Then the fraction
1
1+g1·g2···gs can be written as a polynomial expression in
f1
g1 , . . . , fs
gs . Clearing denominators, we get (g1·g2 · · · gs)i = (1+g1·g2 · · · gs)·h
for suitable i > 0 and h ∈K[x]. Now K[x] is a factorial domain (see Theo-
rem 1.2.13), but clearly no irreducible factor of the non-constant polynomial
1 + g1 · g2 · · · gs can divide one of the polynomials g1, . . . , gs. This contradic-
tion ﬁnishes the proof.
□
Lemma 2.6.3. Let A ⊆B ⊆C be three rings.
a) If B is a ﬁnitely generated A-module, then it is also a ﬁnitely generated
A-algebra.

2.6 Hilbert’s Nullstellensatz
135
b) If B is a ﬁnitely generated A-algebra and if C is a ﬁnitely generated
B-algebra, then C is a ﬁnitely generated A-algebra.
Proof.
Let {b1, . . . , bs} be a set of generators of B as an A-module. Then
B = Ab1 + · · · + Abs ⊆A[b1, . . . , bs] ⊆B implies claim a). For the proof
of b), we use Corollary 1.1.14 to write B = A[x1, . . . , xn]/I with an ideal
I ⊆A[x1, . . . , xn] and C = B[y1, . . . , ym]/J with an ideal J ⊆B[y1, . . . , ym].
Then the claim follows from
C ∼= A[x1, . . . , xn, y1, . . . , ym]/
¡
I · A[x1, . . . , xn, y1, . . . , ym] + π−1(J)
¢
where π : A[x1, . . . , xn, y1, . . . , ym] −→B[y1, . . . , ym] is the canonical homo-
morphism.
□
The next result is deeper. We want to show that under certain circum-
stances a K -subalgebra of an aﬃne K -algebra is an aﬃne K -algebra. The
following example shows that this is not always the case.
Example 2.6.4. The K -subalgebra K[x, xy, xy2, xy3, . . .] of K[x, y] is not
ﬁnitely generated. Namely, for every ﬁnite set of elements of this subalgebra,
the ﬁnitely many terms in the support of those polynomials can be writ-
ten as polynomials in ﬁnitely many terms x, xy, . . . , xyi . But since we have
xyi /∈K[x, xy, . . . , xyi−1] for i ≥2, those polynomials do not generate the
subalgebra.
Lemma 2.6.5. Let A and B be two K -algebras such that A ⊆B. Assume
that B is an aﬃne K -algebra and a ﬁnitely generated A-module. Then A is
an aﬃne K -algebra.
Proof.
Let {b1, . . . , bs} be a set of generators of B as a K -algebra and
{β1, . . . , βt} a set of generators of B as an A-module. Then there are ele-
ments aij, a′
ijk ∈A such that we have expressions
bi =
tP
j=1
aijβj for i = 1, . . . , s
and
βiβj =
tP
k=1
a′
ijkβk for i, j = 1, . . . , t.
Let A0 be the K -subalgebra of A generated by all elements aij and a′
ijk .
It is an aﬃne K -algebra, hence Noetherian by Theorem 2.4.6. Assume for a
moment that we know that B is a ﬁnitely generated A0 -module. Then B is a
Noetherian A0 -module by Theorem 2.4.6 again. Thus A, an A0 -submodule
of B, is a ﬁnitely generated A0 -module. Therefore A is a ﬁnitely generated
A0 -algebra by Lemma 2.6.3.a. Since A0 is an aﬃne K -algebra, also A is an
aﬃne K -algebra by Lemma 2.6.3.b.
Consequently, to ﬁnish the proof it suﬃces to show that B is a ﬁnitely
generated A0 -module. To this end we observe that every element of B is a
polynomial expression in β1, . . . , βt with coeﬃcients in A0 because of the ﬁrst
set of expressions above. Using the second set of expressions, we can replace

136
2. Gr¨obner Bases
every product βiβj by an element of A0β1 + · · · + A0βt. If we iterate those
substitutions, we see that every element of B is in A0β1 + · · · + A0βt + A0 ,
i.e. the A0 -module B is generated by {1, β1, . . . , βt}.
□
Theorem 2.6.6. (Field-Theoretic Version of Hilbert’s Nullstellen-
satz)
Let P = K[x1, . . . , xn] and m a maximal ideal of P .
a) For every i ∈{1, . . . , n}, the intersection m ∩K[xi] is a non-zero ideal.
b) The aﬃne K -algebra P/m is a ﬁnitely generated K -vector space.
Proof.
First we show that a) implies b). By assumption, for i = 1, . . . , n,
the intersection m ∩K[xi] is a non-zero principal ideal generated by some
non-constant polynomial fi ∈K[xi]. Then the ideal n = (f1, . . . , fn) ⊆P
is contained in m and we have a surjective homomorphism P/n −↠P/m.
Therefore it suﬃces to show that P/n is a ﬁnitely generated K -vector space.
Now {f1, . . . , fn} is a Gr¨obner basis of n with respect to every term ordering
σ by Corollary 2.5.10. If we write LTσ(fi) = xdi
i
with di ≥1 for i = 1, . . . , n,
we may deduce from Corollary 2.4.11 that a K -vector space basis of P/n is
given by the ﬁnite set of residue classes of the terms xα1
1 · · · xαn
n
such that
0 ≤αi < di for i = 1, . . . , n.
Now we prove a) by induction on n. If n = 1, the ideal m is a principal
ideal generated by an irreducible polynomial, and the claim holds. If n > 1,
we denote the aﬃne K -algebra P/m by B. Let i ∈{1, . . . , n}, let xi be the
residue class of xi in B, and let A be the ﬁeld of fractions of the integral
domain K[xi] contained in the ﬁeld B. Clearly, considered as an A-alge-
bra, B is generated by {x1, . . . , xi−1, xi+1, . . . , xn}. By induction and the
implication shown above, B is a ﬁnitely generated A-vector space. Therefore,
by Lemma 2.6.5, the ﬁeld A is a ﬁnitely generated K -algebra. Then xi is not
an indeterminate over K by Lemma 2.6.2, and hence m ∩K[xi] is diﬀerent
from (0).
□
Condition a) of the above theorem does not hold for more general rings, as
the following example shows. (In this example we shall use some facts about
power series and Laurent series rings which will be discussed more thoroughly
in Chapter V. The inexperienced reader may safely skip it.)
Example 2.6.7. Let R = K[[x]][y] be the polynomial ring in the indeter-
minate y over the univariate power series ring K[[x]] over a ﬁeld K . Then
the principal ideal m = (xy −1) is maximal, because R/(xy −1) ∼= K[[x]]x
is a ﬁeld. But we have m ∩K[y] = (0).
Deﬁnition 2.6.8. A ﬁeld K is called algebraically closed if every irre-
ducible polynomial in K[x] is linear. This implies that every polynomial
f ∈K[x] of degree d can be written as
f(x) = c (x −a1)α1(x −a2)α2 · · · (x −as)αs

2.6 Hilbert’s Nullstellensatz
137
where c, a1, . . . , as ∈K and α1, . . . , αs ∈N are such that a1, . . . , as are
pairwise distinct and α1 + · · · + αs = d.
For instance, the Fundamental Theorem of Algebra says that the
ﬁeld of complex numbers C is algebraically closed. The ﬁelds R and Q are
not algebraically closed, since the quadratic polynomial x2 + 1 is irreducible
over them.
An important result which you should know is that, for every ﬁeld K ,
there exists an algebraic extension ﬁeld K which is an algebraically closed
ﬁeld. (And if you do not know it, you can look for instance at [La70], Ch. 7.)
The ﬁeld K is unique up to a K -algebra isomorphism and is called the alge-
braic closure of K . For example, the ﬁeld C is the algebraic closure of R,
since it is algebraically closed and an algebraic extension of R. The algebraic
closure of Q is the ﬁeld of algebraic numbers Q discussed in Tutorial 18.
The ﬁeld-theoretic version of Hilbert’s Nullstellensatz can also be inter-
preted as a structure theorem for maximal ideals in polynomial rings over
algebraically closed ﬁelds.
Corollary 2.6.9. Let K be an algebraically closed ﬁeld, and let m be a max-
imal ideal in K[x1, . . . , xn]. Then there exist elements a1, . . . , an in K such
that
m = (x1 −a1, . . . , xn −an)
Proof.
Theorem 2.6.6 yields non-zero polynomials f1, . . . , fn ∈m such that
fi ∈K[xi] for i = 1, . . . , n. Every polynomial fi factorizes completely into
linear factors, since K is algebraically closed. Moreover, the ideal m is maxi-
mal, hence prime. This implies that it contains one of the linear factors of each
polynomial fi , say xi −ai . Then m contains the ideal (x1 −a1, . . . , xn −an)
which, on the other hand, is a maximal ideal. Thus they must be equal and
the proof is complete.
□
2.6.B
The Geometric Version
In the remainder of this section we want to explain the geometric versions of
Hilbert’s Nullstellensatz. The German word “Nullstellensatz” literally means
“zero-places-proposition”. Let us deﬁne what this refers to.
Deﬁnition 2.6.10. Let K ⊆L be a ﬁeld extension, let K be the algebraic
closure of K , and let P = K[x1, . . . , xn].
a) An element (a1, . . . , an) ∈Ln (which we shall also call a point of Ln ) is
said to be a zero of a polynomial f ∈P in Ln if f(a1, . . . , an) = 0, i.e.
if the evaluation of f at the point (a1, . . . , an) is zero. The set of all zeros
of f in Ln will be denoted by ZL(f). If we simply say that (a1, . . . , an)
is a zero of f , we mean (a1, . . . , an) ∈K
n and f(a1, . . . , an) = 0.

138
2. Gr¨obner Bases
b) For an ideal I ⊆P , the set of zeros of I
in Ln is deﬁned as
ZL(I) = {(a1, . . . , an) ∈Ln | f(a1, . . . , an) = 0 for all f ∈I}
Again we call the set of zeros of I in K
n simply the set of zeros of I
and denote it by Z(I). Later we shall also call Z(I) the aﬃne variety
deﬁned by I .
It is easy to see that the set of zeros ZL(f) of a polynomial f ∈P
in Ln agrees with the set of zeros ZL((f)) of the principal ideal it generates.
Moreover, if an ideal I ⊆P is generated by a set of polynomials {f1, . . . , fs},
then we have ZL(I) = ∩s
i=1ZL(fi).
Algebraically, the set of zeros of an ideal corresponds to a set of maximal
ideals in the polynomial ring, as our next proposition shows.
Proposition 2.6.11. Let K be an algebraically closed ﬁeld, let I be a proper
ideal in P = K[x1, . . . , xn], and let Σ be the set of maximal ideals in P which
contain I . Then the map
ϕ : Z(I) −→Σ
deﬁned by ϕ(a1, . . . , an) = (x1 −a1, . . . , xn −an) is bijective.
Proof.
For p = (a1, . . . , an) ∈Kn , we denote by mp = (x1 −a1, . . . , xn −an)
the corresponding maximal ideal in P . Then the map ϕ can be described by
ϕ(p) = mp . First we prove that ϕ is well-deﬁned. For a point p ∈Z(I), all
polynomials in I vanish at p. Using the Division Algorithm 1.6.4, we then
see that those polynomials belong to mp .
The map ϕ is clearly injective. Hence it suﬃces to show that it is surjec-
tive. We choose a maximal ideal m ∈Σ . By Corollary 2.6.9, there exists a
point p = (a1, . . . , an) ∈Kn such that m = mp . By the deﬁnition of Σ , we
have mp ⊇I . It follows that p ∈Z(I), and the proof is complete.
□
Our next result is useful for comparing the set of zeros of I in Ln for
diﬀerent extension ﬁelds L of K . Remember that if K ⊆L is a ﬁeld extension
and I is an ideal of P = K[x1, . . . , xn], we use the notation IL[x1, . . . xn] to
denote the ideal of L[x1, . . . xn] generated by the set I .
Proposition 2.6.12. Let K ⊆L be a ﬁeld extension and I an ideal of
K[x1, . . . , xn]. Then
IL[x1, . . . , xn] ∩K[x1, . . . , xn] = I
In particular, we have IL[x1, . . . , xn] = L[x1, . . . , xn] if and only if we have
I = K[x1, . . . , xn].
Proof.
Obviously we only need to prove that the left-hand side is contained
in I . We choose a term ordering σ on Tn and let G = {g1, . . . , gs} be
a σ-Gr¨obner basis of I . From Lemma 2.4.16 it follows that the set G is

2.6 Hilbert’s Nullstellensatz
139
also a σ-Gr¨obner basis of the ideal IL[x1, . . . , xn]. Now let f be a poly-
nomial in IL[x1, . . . , xn] ∩K[x1, . . . , xn]. If we compute the normal form
NFσ(f) using the Division Algorithm 1.6.4, we only perform operations
inside K[x1, . . . , xn], and therefore f −NFσ(f) is in the ideal generated
in K[x1, . . . , xn] by the set of polynomials {g1, . . . , gs}, which is I . But
f ∈IL[x1, . . . , xn] implies NFσ(f) = 0, hence we have f ∈I .
□
The questions which ideals have zeros and how one can check that are
now answered by the following theorem and its corollary.
Theorem 2.6.13. (Weak Nullstellensatz)
Let K be a ﬁeld, and let I be a proper ideal of P = K[x1, . . . , xn], i.e. let
I ⊂P . Then Z(I) ̸= ∅.
Proof.
Let K be the algebraic closure of K, and let P = K[x1, . . . , xn].
Then IP is a proper ideal of P by Proposition 2.6.12. Since we know that P
is Noetherian, the ideal IP is contained in a maximal ideal m of P by Propo-
sition 2.4.5.c. Now Corollary 2.6.9 says that there is a point (a1, . . . , an) ∈K
n
such that m = (x1 −a1, . . . , xn −an). Hence (a1, . . . , an) is a zero of m, and
therefore also of I ⊆IP ⊆m.
□
Of course, one cannot hope to get ZK(I) ̸= ∅if K is not algebraically
closed, since for instance ZQ(x2 + 1) = ∅. Moreover, although the question
of whether ZL(I) = ∅or not does not depend on which algebraically closed
ﬁeld L ⊇K we choose, the set ZL(I) itself clearly does. For instance, if
I = (y −x2) ⊆Q[x, y], then (π, π2) ∈ZC(I), but (π, π2) /∈ZQ(I).
Corollary 2.6.14. Let L be a ﬁeld which contains the algebraic closure
of K , and let I be an ideal of K[x1, . . . , xn]. Then the following conditions
are equivalent.
a) ZL(I) = ∅
b) 1 ∈I
In particular, this result holds if K is the ﬁeld of deﬁnition of I .
Proof.
Clearly b) implies a). For the converse, we observe that ZL(I) = ∅
implies Z(I) = ∅, and then 1 ∈I by the Weak Nullstellensatz.
□
Recall that, for a ring R and an ideal I in R, the set {r ∈R | ri ∈I
for some i ≥0} is again an ideal of R which is called the radical of I
and denoted by
√
I . An ideal I such that I =
√
I is called a radical ideal.
Equivalently, an ideal I is a radical ideal in R if the residue class ring R/I has
no non-zero nilpotent elements. Thus, for instance, prime ideals are radical
ideals.
In the case of an ideal I of K[x1, . . . , xn], it is easy to see that I and
√
I
have the same set of zeros. Thus the operation of assigning the set of zeros to
an ideal I ⊆K[x1, . . . , xn] is not one-to-one. In order to study this operation
more closely, let us deﬁne an operation going in the other direction.

140
2. Gr¨obner Bases
Deﬁnition 2.6.15. Let K ⊆L be a ﬁeld extension, and let S ⊆Ln . Then
the set of all polynomials f ∈K[x1, . . . , xn] such that f(a1, . . . , an) = 0
for all points (a1, . . . , an) ∈S forms an ideal of the polynomial ring
K[x1, . . . , xn]. This ideal is called the vanishing ideal of S in K[x1, . . . , xn]
and denoted by I(S).
Using this notation, the strong version of Hilbert’s Nullstellensatz says
that the operation I(. . .) is an inverse to Z(. . .) if one considers only radical
ideals in polynomial rings over algebraically closed ﬁelds.
Theorem 2.6.16. (Hilbert’s Nullstellensatz)
Let K be an algebraically closed ﬁeld, and let I be a proper ideal of
K[x1, . . . , xn]. Then
I(Z(I)) =
√
I
Proof.
To show the inclusion I(Z(I)) ⊇
√
I , suppose that a polynomial
f ∈P = K[x1, . . . , xn] satisﬁes f i ∈I for some i ≥0. Then we have
f i(a1, . . . , an) = 0 for every point (a1, . . . , an) ∈Z(I). Thus we also have
f(a1, . . . , an) = 0 for every point (a1, . . . , an) ∈Z(I), i.e. f ∈I(Z(I)).
To prove the other inclusion, we may assume that I ̸= (0). We choose
f ∈I(Z(I)) \ {0} and a system of generators {g1, . . . , gs} of I . Let xn+1
be a new indeterminate, and consider the ideal I′ = IP[xn+1] + (xn+1f −1)
in the polynomial ring P[xn+1]. For every point (a1, . . . , an+1) ∈Z(I′) we
have an+1f(a1, . . . , an) = 1 and gi(a1, . . . , an) = 0 for i = 1, . . . , s. But
then (a1, . . . , an) ∈Z(I) and f(a1, . . . , an) ̸= 0 contradict the choice of f .
Consequently, such a point does not exist, i.e. Z(I′) = ∅, and the Weak
Nullstellensatz 2.6.13 yields 1 ∈I′ .
Therefore there are polynomials h, h1, . . . , hs ∈P[xn+1] such that 1 =
Ps
i=1 hi·gi+h·(xn+1f−1). In the ﬁeld K(x1, . . . , xn, xn+1) we may substitute
1
f for xn+1 . We get the equality
1 =
sP
i=1
hi(x1, . . . , xn, 1
f ) · gi
By clearing the denominators, we ﬁnd f m = Ps
i=1 ˜hi · gi for some m ≥0
and suitable polynomials ˜h1, . . . , ˜hs ∈P , which means that f ∈
√
I .
□
Our ﬁnal result in this section provides a reformulation of Hilbert’s Null-
stellensatz which will prove useful in the ﬁnal section of this book.
Corollary 2.6.17. Let K be a ﬁeld, let I be a proper ideal in the poly-
nomial ring P = K[x1, . . . , xn], let K be the algebraic closure of K , let
P = K[x1, . . . , xn], and let f be a polynomial in P . If f belongs to all
maximal ideals containing IP , then f ∈
√
I .

2.6 Hilbert’s Nullstellensatz
141
Proof.
First we observe that Proposition 2.6.11 implies f ∈I(Z(IP)). This
ideal equals
√
IP by Hilbert’s Nullstellensatz 2.6.16. Therefore there exists
a number i ∈N such that f i ∈IP . The claim now follows from Proposi-
tion 2.6.12.
□
Exercise 1. Give a direct proof for the fact that condition b) of Theo-
rem 2.6.6 implies condition a) of that theorem.
Exercise 2.
Let K be a ﬁeld and f(x) ∈K[x] an irreducible poly-
nomial. Find a maximal ideal m in K[x, y] which contains the ideal
I = (f(x), f(y)), and compute the intersection of m with K[x] and K[y].
Exercise 3. (Structure of Maximal Ideals in R[x1, . . . , xn])
Let m be a maximal ideal in R[x1, . . . , xn].
a) Let n = 1. Show that m is either generated by a polynomial of type
x1 −a with a ∈R, or a polynomial of type x2
1 +ax1 +b with a, b ∈R
and a2 −4b < 0.
Hint: Use the fact that if a + ib is a complex zero of a polynomial in
R[x], then also a−ib is a zero, to characterize irreducible polynomials
in R[x].
b) Let n = 2 and f1 = x2
1 + a1x1 + b1 , f2 = x2
2 + a2x2 + b2 with
a1, b1, a2, b2 ∈R and a2
1 −4b1 < 0, a2
2 −4b2 < 0. Show that the ideal
I = (f1, f2) is not maximal in R[x1, x2].
Hint: Use the fact that R[x1, x2]/(f1) is isomorphic to C[x2].
c) Let n = 2 and assume that x2
1 + a1x1 + b1 ∈m with a1, b1 ∈R and
a2
1 −4b1 < 0. Show that there exist a2, b2 ∈R such that we have
m = (x2
1 + a1x1 + b1, x2 −a2x1 −b2).
d) In the general case prove the following fact: either there exist numbers
a1, . . . , an ∈R such that m = (x1 −a1, . . . , xn −an) or, up to a per-
mutation of the indeterminates, there exist a1, b1, a2, b2 . . . , an, bn ∈R
such that a2
1−4b1 < 0 and m = (x2
1+a1x1+b1, x2−a2x1−b2, . . . , xn−
anx1 −bn).
Exercise 4. Let f ∈Q[x, y] be a non-constant polynomial. Prove that
ZQ(f) ⊂Z(f).
Exercise 5. Let K ⊆L be a ﬁeld extension, let P = K[x1, . . . , xn], let
f, f1, . . . , fs ∈P , and let I = (f1, . . . , fs).
a) Show that ZL(f) = ZL((f)).
b) Show that ZL(I) = ∩s
i=1ZL(fi).
c) Show that ZL(I) = ZL(
√
I).
Exercise 6.
Let K ⊆L be a ﬁeld extension, let I be an ideal in
K[x1, . . . , xn], and let S be a subset of Ln .
a) Show that I(ZL(I)) ⊇I .
b) Show that ZL(I(S)) ⊇S .

142
2. Gr¨obner Bases
Exercise 7.
Let R be a ring, and let I and J be ideals in R. Prove
the following rules.
a)
p√
I =
√
I
b)
√
I ∩J =
√
IJ =
√
I ∩
√
J
c)
√
Ii =
√
I for all i ≥1.
d) If I is an intersection of prime ideals, then
√
I = I .
e)
p√
I +
√
J =
√
I + J
Exercise 8. Let K be an algebraically closed ﬁeld and I a proper ideal
of P = K[x1, . . . , xn]. In this exercise we use the Zariski topology on Kn
deﬁned in Tutorial 27.
The ideal I is said to be reducible if it is the intersection of two strictly
bigger ideals. A closed set of a topological space is said to be reducible
if it is the union of two properly contained closed subsets.
a) Show that if I is reducible, then Z(I) is reducible.
b) Give an example which shows that the converse is not true.
c) Show that the converse of a) is true if I is a radical ideal.
d) Let I be a radical ideal. Prove that the following conditions are equiv-
alent.
1) There exist two ideals I1, I2 ⊂P such that I = I1 ∩I2 and
I1 + I2 = P .
2) Z(I) is disconnected, i.e. it is the union of two disjoint closed
sets.
Exercise 9. Let K be an algebraically closed ﬁeld, and let I be a proper
radical ideal of P = K[x1, . . . , xn].
a) Prove that Z(I) is ﬁnite if and only if I is of the form
I = Ts
i=1 (x1 −ai1, . . . , xn −ain)
with pairwise diﬀerent points (a11, . . . , a1n), . . . , (as1, . . . , asn) ∈Kn .
b) Show that if a) holds, then ZL(I) = Z(I) for every extension ﬁeld
L ⊇K .

2.6 Hilbert’s Nullstellensatz
143
Tutorial 26: Graph Colourings
Suppose we are given 3 diﬀerent colours and a graph Γ having n nodes and
at most one arch between any two nodes, e.g.
•
•
•
•
•
•
•
1
2
3
4
5
6
7
...............................................................................................................................................
..................................................................................................................
...............................................................................................................................................................................................................................................................................................................................................................
...............................................................................................................................................
......................................................................................
...............................................................................................................................................................................................
.............................................................................................................................................................................................................................................................................................
.......................................................................................................
.............................................................................................................................................................................................................................................................................................
....................................................................................................................................................................................................................................................
....................................................................................................................................................................................................................................................
...............................................................................................................................................................................................
Our goal is to ﬁnd out if the nodes can be coloured in such a way that
no arch connects two nodes of the same colour. In order to use the theory of
Gr¨obner bases to solve this problem, we introduce the following notation.
The colours will be called −1, 0, and 1. They will be identiﬁed with the
elements of the ﬁeld F3 = Z/(3). For i = 1, . . . , n, we choose an indetermi-
nate xi and form the polynomial ring P = F3[x1, . . . , xn]. We shall identify
a colouring of the graph with a point of Fn
3 such that the ith coordinate of
the point corresponds to the colour of the ith node.
a) Show that the set of zeros of the ideal (x3
1 −x1, . . . , x3
n −xn) is precisely
the set of all colourings.
b) Prove that the ith and jth node of the graph have diﬀerent colours if
and only if the colouring is a zero of the polynomial x2
i + xixj + x2
j −1.
c) In addition, we may assume that the ﬁrst and second nodes are connected,
that the ﬁrst node has colour “0”, and that the second node has colour
“1”. What polynomial equations does this imply for the colourings under
consideration?
d) Write a CoCoA program Colouring(. . .) which takes a list of pairs from
{1, . . . , n}2 representing the arches and computes an ideal I ⊆P whose
zeros are precisely the colourings of the graph represented by those pairs
which satisfy our additional conditions.
e) Apply your function Colouring(. . .) to the graph above. Then use CoCoA
to compute the reduced Lex-Gr¨obner basis of this ideal. Does the graph
have a colouring of the desired kind? If yes, how many diﬀerent ones?
(Hint: Use Hilbert’s Nullstellensatz to interpret the answer of your cal-
culation.)
f) Consider the graph formed by connecting the center of a regular 7-gon
to its vertices. (It has 8 nodes and 14 arches.) Use CoCoA and the Weak
Nullstellensatz to show that this graph cannot be coloured as required
above.

144
2. Gr¨obner Bases
Tutorial 27: Aﬃne Varieties
Let K ⊆L be a ﬁeld extension. For every ideal I in K[x1, . . . , xn] we
consider the set ZL(I) ⊆Ln as given in Deﬁnition 2.6.10. For the moment,
let us call a subset of Ln a zero-set if it is of the form ZL(I) ⊆Ln for some
ideal I ⊆K[x1, . . . , xn].
a) Prove the following claims.
1) ∅is a zero-set.
2) Ln is a zero-set.
3) If E1, . . . , Es are zero-sets, then ∪s
i=1Ei is a zero-set.
4) If J is a set of indices and {Ej}j∈J a set of zero-sets indexed by J ,
then ∩j∈JEj is a zero-set.
Deduce that the zero-sets of Ln can be taken as the closed sets of a
topology, which we denote by TopK,L . If K = L, then TopK,K is called
the Zariski topology on Kn . Moreover, Kn with the Zariski topology
is called the n-dimensional aﬃne space over K and denoted by An
K .
Zero-sets in K
n are called aﬃne varieties (or aﬃne sets).
b) Let p1 and p2 be two distinct points in Kn . Then the set of points
p1p2 = {p1 + λ(p2 −p1) | λ ∈K} is called the line passing through p1
and p2 . Show that p1p2 is a closed set in the Zariski topology.
c) Let K ⊂K′ ⊆L be ﬁeld extensions and TopK,L , TopK′,L the corre-
sponding topologies on Ln . Show that TopK′,L is ﬁner than TopK,L , i.e.
that every closed set with respect to TopK,L is also closed with respect
to TopK′,L .
d) Let K be algebraically closed and consider the Zariski topology on
Kn . Show that there is a bijection between the set of radical ideals in
K[x1, . . . , xn] and the closed sets in An
K . Then show that the statement
is false if K is not algebraically closed.
e) Let K be algebraically closed, let I be an ideal in P = K[x1, . . . , xn],
and assume that the dimension of P/I as a vector space over K is ﬁnite.
Then show that Z(I) is a ﬁnite set of points.
Hint: For i = 1, . . . , n, show that I ∩K[xi] = (fi) ̸= (0) and conclude
that Z(I) ⊆Z((f1, . . . , fn)).
f) Let P = Q[x1, . . . , xn], and let I be an ideal in P . Write two CoCoA
programs which perform the following tasks.
1) Given I and a point p ∈Qn , check if p ∈ZQ(I) and return the
corresponding Boolean value.
2) If I ̸= (0), ﬁnd a point p which is not in ZQ(I) and return it.
g) Let S be a subset of An
K . Show that the set of all Zariski-closed sub-
sets of An
K containing S has a unique minimal element (with respect to
inclusion). This zero-set is called the Zariski closure of S .
h) Let K be an algebraically closed ﬁeld, and let S ⊆An
K . Prove that the
Zariski closure of S is given by Z(I(S)).

3. First Applications
Ripeness is all. [...]
Also the story of the moon and the bonﬁres, I knew it.
However, I began to realize that I did not know anymore that I knew it.
(Cesare Pavese)
It has already been a long journey. From the snowy hills down to the
valleys and up again, we have encountered many milestones and discovered
impressive tools. Meanwhile time has passed, the colours of the landscape
have changed, and now it is time to go back to the hills and do the harvesting.
Do you realize that you have accumulated the knowledge of many facts
which you might be able to use now? Possibly you have already forgotten
that you knew them. Let us remind you of the factoriality of polynomial
rings over ﬁelds, and of the games played in Chapter 1 with terms and term
orderings. Then, in Chapter 2, we planned a strategy, made our moves, and
discovered Gr¨obner bases, Buchberger’s Algorithm, Hilbert’s Nullstellensatz,
and numerous other devices. In particular, by now you should be able to see
clearly how fundamental the notion of a syzygy is, for instance because it
plays an essential role in the construction of Buchberger’s Algorithm.
However, the importance of syzygies in Algebra goes far beyond what we
have seen up to now. Therefore it is highly relevant to be able to compute
them. In fact, our ﬁrst achievement in this chapter is the solution of the
problem of computing SyzP (g1, . . . , gs) for arbitrary vectors g1, . . . , gs ∈P r,
where P = K[x1, . . . , xn] is a polynomial ring over a ﬁeld K (see Theo-
rem 3.1.8). Exploiting this new ability, we will then discover ways to explic-
itly perform basic operations among ideals and modules such as intersections,
colon ideals, and colon modules (see Section 3.2).
Next, we enjoy a trip into the realms of Computational Linear Algebra
and Computational Homological Algebra. Using syzygy computations, we
can ﬁnd presentations for the kernel and the image of a linear map between
ﬁnitely generated P -modules, and we can lift a linear map along another
one. Even more challenging, but within our grasp, is the task of computing
presentations of Hom-modules. Using the ingredients gathered earlier, we
shall concoct an algorithm in Subsection 3.3.B.
Having safely put in store many fruits of syzygy calculations, we move to
the next orchard. Elimination theory provides us with a particularly fertile
soil for further applications. This is a fascinating subject whose roots lie in

146
3. First Applications
classical geometry, where it is related to projections. From the point of view
of Computational Commutative Algebra, we have to perform an important
switch. From here on we are no longer allowed to use an arbitrary module
term ordering. Instead, we have to limit ourselves to the more restrictive class
of elimination orderings.
After we explain the main theorem for computing elimination modules in
Section 3.4, many other ripening fruits will become ready for picking. Using
the method of tag variables, we obtain new ways to perform the basic opera-
tions on modules. Then, in Section 3.5, we learn how to compute saturations
and how to check radical membership.
Other important applications are collected in Section 3.6, where we dis-
cuss ring homomorphisms. Among other things, we show how to ﬁnd presen-
tations for the kernel and the image of a homomorphism of ﬁnitely generated
algebras, how to solve the implicitization problem, how to compute mini-
mal polynomials of elements in aﬃne algebras, how to check membership in
ﬁnitely generated subalgebras, and how to analyze surjective and bijective
homomorphisms between polynomial rings.
The ﬁnal Section 3.7 of this chapter, and hence of this volume, represents
the ultimate act of harvesting. It is devoted to the problem of solving systems
of polynomial equations eﬀectively. At that stage of your reading, you will
be challenged to recall almost all the knowledge that you gathered during
the journey, to become aware of the skills and the tools which you have
learned, and to use them to dig out the roots of systems of equations. Our
last ﬁeld of investigation also contains algorithms for checking whether the
set of solutions of a system of equations is ﬁnite, for computing squarefree
parts of polynomials, and for ﬁnding radicals of zero-dimensional ideals.
And what then? There are countless other applications of Gr¨obner bases,
and new ones are discovered almost daily. But since we wanted to ﬁnish this
book before the new millennium, we decided to stop here. Other applications
and interesting topics will be contained in Volume 2. So, see you later!
Some Words About Notation
Such is the advantage of a well-constructed language
that its simpliﬁed notation often becomes
the source of profound theories.
(Pierre-Simon de Laplace)
Before moving into medias res, let us mention a problem which could
come to haunt us, namely the choice of a convenient notation. As usual, let
P = K[x1, . . . , xn] be a polynomial ring over a ﬁeld K , let r ≥1, and let
G = (g1, . . . , gs) be a tuple of vectors in P r.
In this situation, the question arises how we should interpret G . It is clear
that tuples of vectors and matrices representing them are diﬀerent objects.
But to ease the notation and to keep the usage of symbols under control,

3. First Applications
147
it would be convenient to identify them in a natural way. The key point is
that when we look at G = (g1, . . . , gs), we see that it is already written as a
row. Thus we are naturally lead to think of the vectors g1, . . . , gs as column
vectors, and to identify G with the matrix having those columns.
Indeed, from now on we shall make this identiﬁcation. It allows us to
interpret an expression Ps
i=1 figi as the result of a matrix multiplication in
the following way.
s
X
i=1
figi = (g1, . . . , gs)



f1
...
fs



Here the row (g1, . . . , gs) is written as a tuple, with the appropriate commas,
and interpreted as a matrix. Now recall that a syzygy of G has been deﬁned
as a tuple of polynomials (f1, . . . , fs) ∈P s such that Ps
i=1 figi = 0. So,
given a tuple of syzygies S of G , we can read the formula G S = 0 as the
corresponding matrix expression.
On the other hand, given a matrix M of size r×t, we can speak about the
P -submodule of P r generated by the t vectors represented by the columns
of M. Consequently, when we write Syz(M), we mean the module of syzygies
of the vectors represented by the columns of M. For a tuple of syzygies S
of M, the corresponding matrix expression is again M S = 0.
Finally, a map λ : P s −→P r deﬁned by sending ei to the vector gi for
i = 1, . . . , s can be represented by the s-tuple G = (g1, . . . , gs) as well as by
the matrix whose columns represent the vectors in G . And now it should be
clear that this matrix can safely be called G again.
The upshot of this discussion is that we represent a linear map between
free modules by the matrix whose columns are the images of the canonical
basis vectors, that the generators of the syzygy module of a tuple of vectors
are the columns of the syzygy matrix, and that the syzygy matrix is on the
right-hand side of the corresponding matrix product.

148
3. First Applications
3.1 Computation of Syzygy Modules
The greatest of these [things common to all living beings]
happen to be four pairs (συζυγι´αι, syzyg´ıai) in number:
wakefulness and sleep, youth and old age,
inhalation and exhalation, and life and death.
(Aristoteles)
As you undoubtedly remember, the main step in the theory of Gr¨obner
bases was taken in Section 2.3 where we discussed syzygies. There we saw
that ﬁnding the Gr¨obner basis of a submodule of P r is equivalent to being
able to lift syzygies. The module of syzygies of a polynomial ideal or module
is one of the fundamental algebraic objects. Therefore its computation is one
of the central problems in Computational Commutative Algebra.
Syzygies also played a central role in Buchberger’s Algorithm in Sec-
tion 2.5. A key ingredient in the development of this algorithm was the lift-
ing of syzygies of leading terms. Thus the following questions arise naturally.
Given a tuple G = (g1, . . . , gs) of elements in P r, how can one lift the syzy-
gies of their leading terms explicitly? And how can one get a set of generators
for the module Syz(G) from those liftings?
Our strategy for answering those questions is to proceed as follows. Let
G = (g1, . . . , gs) be a tuple of non-zero vectors in P r which generate a mod-
ule M , and let σ be a module term ordering on Tn⟨e1, . . . , er⟩. First we deﬁne
a suitable module term ordering on the monomodule of terms Tn⟨ε1, . . . , εs⟩
of P s, namely the ordering τ induced by (σ, G), and show that the ele-
ments σij deﬁned in Theorem 2.3.7 form a τ -Gr¨obner basis of the syzygy
module of (LMσ(g1), . . . , LMσ(gs)). Next we assume that G is a Gr¨obner ba-
sis of M with respect to σ and prove that the liftings sij of those elements
constitute a τ -Gr¨obner basis of Syz(G).
The ﬁnal step is to compute the syzygy module Syz(H) for any tuple
H = (h1, . . . , ht) of vectors which generate M . This goal is achieved in
Theorem 3.1.8 by using a clever combination of the Division Algorithm 1.6.4
and the Extended Buchberger Algorithm 2.5.11. As a consequence, we see
how to obtain all explicit representations of an element of a module as a
combination of a given set of generators (see Corollary 3.1.9). And as a ﬁnal
byproduct we show how one can extract an irredundant system of generators
of a module from a given one (see Corollary 3.1.12).
As in the previous chapter, we let K be a ﬁeld, P = K[x1, . . . , xn] a
polynomial ring, M ⊆P r a non-zero P -submodule, and G = (g1, . . . , gs)
a tuple of non-zero vectors which generate M . Furthermore, we let σ be a
module term ordering on Tn⟨e1, . . . , er⟩, and we write LMσ(gi) = ci tieγi
with ci ∈K , ti ∈Tn , and γi ∈{1, . . . , r} for i = 1, . . . , s. If we denote the
canonical basis of the P -module P s by {ε1, . . . , εs}, the s-tuple G corre-
sponds to the surjective P -linear map λ : P s −→M given by λ(εi) = gi for
i = 1, . . . , s. Recall that the syzygy module Syz(G) is nothing but the kernel
of λ.

3.1 Computation of Syzygy Modules
149
Our ﬁrst goal is to introduce a certain module term ordering on the set of
terms of P s such that the map λ is somehow “compatible” with the module
term orderings on P s and P r .
Deﬁnition 3.1.1. On Tn⟨ε1, . . . , εs⟩, we deﬁne a complete relation τ in the
following way. Let tεi and t′εj be two elements of Tn⟨ε1, . . . , εs⟩, where
t, t′ ∈Tn and i, j ∈{1, . . . , s}.
Then we let tεi ≥τ t′εj if we have LTσ(tgi) >σ LTσ(t′gj), or if we have
LTσ(tgi) = LTσ(t′gj) and i ≤j . The relation τ is called the ordering
induced by (σ, G) on Tn⟨ε1, . . . , εs⟩.
Using Deﬁnition 2.3.4 and Proposition 2.3.5, we can rephrase the deﬁ-
nition of τ by saying that tεi ≥τ t′εj if degσ,G(tεi) >σ degσ,G(t′εj), or if
degσ,G(tεi) = degσ,G(t′εj) and i ≤j . Now we check that this relation is
indeed a module term ordering.
Lemma 3.1.2. The relation τ deﬁned above is a module term ordering on
Tn⟨ε1, . . . , εs⟩.
Proof.
According to Deﬁnition 1.4.15 we have to check that τ is reﬂex-
ive, antisymmetric, transitive, compatible with the monomodule structure,
and that it deﬁnes a term ordering. All the proofs are straightforward;
here we prove the transitivity. Let t, t′, t′′ ∈Tn and i, j, k ∈{1, . . . , s}
such that we have tεi ≥τ
t′εj ≥τ
t′′εk . From the deﬁnition of τ we
get LTσ(tgi) ≥σ LTσ(t′gj) ≥σ LTσ(t′′gk). Furthermore, we either have
LTσ(tgi) >σ LTσ(t′′gk), or we have LTσ(tgi) = LTσ(t′gj) = LTσ(t′′gk) and
i ≤j ≤k. Both times we end up with tεi ≥τ t′′εk .
□
What is τ good for? If the vectors in G form a σ-Gr¨obner basis of M ,
we can try to compute Syz(G) via the following steps: from Theorem 2.3.7
we know an explicit system of generators of Syz(LMσ(G)), by Condition D1)
those syzygies lift to syzygies of G , and by Proposition 2.3.11 those liftings
generate the desired syzygy module. So the main task is to make the process
of lifting more explicit.
Let us recall some notation from Chapter 2. For i, j ∈{1, . . . , s}, we
deﬁned tij = lcm(ti,tj)
ti
and σij =
1
ci tijεi −1
cj tjiεj . Furthermore, we deﬁne
B = {(i, j) | 1 ≤i < j ≤s, γi = γj}. Theorem 2.3.7 says that the set
Σ = {σij | (i, j) ∈B} generates Syz(LMσ(G)). The importance of τ de-
rives from the remarkable property that Σ is actually a τ -Gr¨obner basis of
Syz(LMσ(G)), as our next proposition shows.
Proposition 3.1.3. Let G = (g1, . . . , gs) be a tuple of non-zero vectors
which generate M . Then the set Σ = {σij | (i, j) ∈B} is a τ -Gr¨obner
basis of Syz(LMσ(G)).
Proof.
If Syz(LMσ(G)) = 0, then Σ = ∅is a σ-Gr¨obner basis of this module.
Now let z ∈Syz(LMσ(G)) \ {0}, and let z′ = LFσ,G(z). We want to show

150
3. First Applications
that LTτ(z) ∈⟨LTτ(σij) | (i, j) ∈B⟩. The deﬁnition of τ implies that
LTτ(z) = LTτ(z′). Thus we may assume that z is homogeneous with respect
to the Tn⟨e1, . . . , er⟩-grading on P s deﬁned in Proposition 2.3.3. This means
that if we write z = Ps
i=1 c′
it′
iεi with c′
i ∈K and t′
i ∈Tn, then we have
t′
i LTσ(gi) = t′
j LTσ(gj) for all 1 ≤i < j ≤s such that c′
ic′
j ̸= 0.
Next, let µ = min{i | c′
i ̸= 0}. Then z is in fact a syzygy in the module
Syz(LMσ(gµ), . . . , LMσ(gs)), and the deﬁnition of τ implies LTτ(z) = t′
µεµ.
Using Theorem 2.3.7, we ﬁnd that the set Σµ = {σij ∈Σ | µ ≤i < j ≤s}
is a system of generators of the syzygy module Syz(LMσ(gµ), . . . , LMσ(gs)).
Therefore we have a representation z = P
µ≤i<j≤s aijσij , where aij ∈P .
By looking at the coeﬃcient of εµ in this representation, we see that t′
µ is
in the ideal generated by the set {tµj | µ < j ≤s}. Thus t′
µ is a multiple
of one of those terms, say of tµk . Since LTτ(σµk) = tµkεµ , it follows that
LTτ(z) ∈⟨LTτ(σµj) | µ < j ≤s⟩.
□
Based on this result, we can now make the process of lifting the syzy-
gies σij explicit and obtain at the same time that the set of liftings is in fact
a τ -Gr¨obner basis of Syz(G).
Proposition 3.1.4. Let G = (g1, . . . , gs) be a tuple of non-zero vectors
in P r which form a σ-Gr¨obner basis of M .
a) For all (i, j) ∈B, we have either σij ∈Syz(G), i.e. λ(σij) = 0, or
a representation λ(σij) = Ps
k=1 fijkgk with fijk ∈P and such that
degσ,G(σij) = maxσ{LTσ(fijkgk) | k ∈{1, . . . , s}} >σ LTσ(λ(σij)).
Now we deﬁne sij = σij if λ(σij) = 0 and sij = σij−Ps
k=1 fijkεk otherwise.
b) The set {sij | (i, j) ∈B} is a τ -Gr¨obner basis of Syz(G). In particular,
it is a system of generators of Syz(G).
c) Let B′ ⊆B be such that {σij | (i, j) ∈B′} generates Syz(LMσ(G)). Then
the set {sij | (i, j) ∈B′} is a system of generators of Syz(G).
Proof.
To prove a), we recall that σij is a homogeneous element of P s
of σ-degree degσ,G(σij) = lcm(ti, tj)eγi by Theorem 2.3.7.a. Therefore we
get LF(σij) = σij ∈Syz(LMσ(G)). Consequently, if λ(σij) ̸= 0, then
LTσ(λ(σij)) <σ degσ,G(σij) by Proposition 2.3.6.b, and the desired repre-
sentation follows from Condition A2) in Theorem 2.4.1.
Next we prove b). If Syz(G) = 0, then also Syz(LMσ(G)) = 0 by Condi-
tion D1) of Theorem 2.4.1, and we have B = ∅. Thus we can assume that
Syz(G) ̸= 0. From a) and the deﬁnition of τ we deduce that LTτ(sij) = tijεi .
Now we take any non-zero element z of Syz(G). We have to show that LTτ(z)
is a multiple of one of the terms in {LTτ(sij) | (i, j) ∈B}. The deﬁni-
tion of τ yields LTτ(z) = LTτ(LFσ,G(z)). By Proposition 2.3.6.d, we have
LFσ,G(z) ∈Syz(LMσ(G)). Hence Proposition 3.1.3 implies the claim.
The proof of c) follows from Proposition 2.3.11.
□
As a straightforward consequence of the preceding proposition, we have
the following algorithm for computing syzygy modules of Gr¨obner bases.

3.1 Computation of Syzygy Modules
151
Corollary 3.1.5. (Computing Syzygy Modules of Gr¨obner Bases)
Let G = (g1, . . . , gs) be a tuple of non-zero vectors in P r which form a
σ-Gr¨obner basis of M . Consider the following sequence of instructions.
1) Create a matrix M over P with s rows and initially zero columns. Then
compute the set B = {(i, j) | 1 ≤i < j ≤s, γi = γj}.
2) If B = ∅, return the matrix M. Otherwise, choose a pair (i, j) ∈B and
delete it from B.
3) Form the vectors σij =
1
ci tijεi −
1
cj tjiεj and calculate Sij = λ(σij).
If Sij ̸= 0, use the Division Algorithm 1.6.4 to compute a representation
Sij = Ps
k=1 fijkgk such that LTσ(fijkgk) ≤σ LTσ(Sij) for k = 1, . . . , s.
4) If Sij = 0, append σij , expanded into a column vector, to the matrix M,
and if Sij ̸= 0, append the column sij = σij −Ps
k=1 fijkεk to the ma-
trix M. Then continue with step 2).
This is an algorithm which returns a matrix M over P whose columns rep-
resent a τ -Gr¨obner basis of Syz(G), and in particular a system of generators
of Syz(G).
Remark 3.1.6. Using Proposition 3.1.4.c, we can modify the above algo-
rithm in the following way. Suppose that for some reason we know a subset
B′ ⊂B such that Σ′ = {σij ∈Σ | (i, j) ∈B′} is a set of generators of
Syz(LMσ(G)). Then we may start with B = B′ in step 1), and we still get a
system of generators of Syz(G).
Let us illustrate the course of this algorithm with an example.
Example 3.1.7. In the ring P = K[x1, x2, x3, x4], consider the polynomials
g1 = x1x4−x2x3 , g2 = x1x2
3−x2
2x4 , g3 = x2
1x3−x3
2 , and g4 = x2x2
4−x3
3 . Let
G = (g1, g2, g3, g4) ∈P 4 , and let I = (g1, g2, g3, g4) ⊆P . In order to compute
the syzygy module of G , we observe that {g1, g2, g3, g4} is a Gr¨obner basis
of I with respect to σ = DegLex. According to the corollary, we calculate
S12 = x2
3g1 −x4g2 = x2
2x2
4 −x2x3
3 = x2g4
S13 = x1x3g1 −x4g3 = −x1x2x2
3 + x3
2x4 = −x2g2
S14 = x2x4g1 −x1g4 = x1x3
3 −x2
2x3x4 = x3g2
S23 = x1g2 −x3g3 = −x1x2
2x4 + x3
2x3 = −x2
2g1
S24 = x2x2
4g2 −x1x2
3g4 = x1x5
3 −x3
2x3
4 = x3
3g2 −x2
2x4g4
S34 = x2x2
4g3 −x2
1x3g4 = x2
1x4
3 −x4
2x2
4 = x3
3g3 −x3
2g4
Therefore the P -module Syz(G) is generated by the columns of the matrix
M =



x2
3
x1x3
x2x4
x2
2
0
0
−x4
x2
−x3
x1
x2x2
4 −x3
3
0
0
−x4
0
−x3
0
x2x2
4 −x3
3
−x2
0
−x1
0
−x1x2
3 + x2
2x4
−x2
1x3 + x3
2



In fact, the columns of M are a Gr¨obner basis of Syz(G) with respect to the
ordering induced by (σ, G).

152
3. First Applications
At this point we know how to compute a system of generators of the
syzygy module of a Gr¨obner basis. Now we become more ambitious and want
to be able to calculate the syzygy module of an arbitrary system of generators
{h1, . . . , ht} of M , where we even allow zero vectors.
The key ingredients will be the following. Using the Extended Buch-
berger Algorithm 2.5.11, we can calculate a Gr¨obner basis {g1, . . . , gs} of M
together with representations gj = a1jh1 + · · · + atjht for j = 1, . . . , s.
Furthermore, after we have calculated this Gr¨obner basis, we can use the
Division Algorithm 1.6.4 to ﬁnd representations hj = b1jg1 + · · · + bsjgs
for j = 1, . . . , t. Thus we can explicitly calculate the matrices A = (aij)
and B = (bij) required by the following theorem.
But before, we remind the reader that a tuple of vectors can also be viewed
as a matrix, namely the matrix whose columns consist of the coordinates of
the vectors.
Theorem 3.1.8. (Computation of Syzygy Modules)
Let {h1, . . . , ht} be a system of generators of a P-submodule M of P r, let
H = (h1, . . . , ht), let {g1, . . . , gs} be a σ-Gr¨obner basis of M , and let G
be the tuple (g1, . . . , gs). Furthermore, suppose we are given a t × s-matrix
A = (aij) and an s × t-matrix B = (bij) over P such that G = H A
and H = G B. Finally, let M be a matrix whose columns generate Syz(G),
and let It be the t × t identity matrix. Then the columns of the matrix
N = (A M | It −A B) generate the module Syz(H).
Proof.
From G = H A and H = G B we get
H N = (H A M | H −H A B) = (G M | H −G B) = (0 | H −H) = 0
Hence the columns of N are syzygies of H. Conversely, if a column vector v
is a syzygy of H, we have G B · v = H · v = 0. Hence we have B · v ∈Syz(G),
and therefore this vector lies in the column space of M. From the identity
v = A (B · v)+(It −A B) ·v we may then conclude that v lies in the column
space of N .
□
Corollary 3.1.9. (Explicit Membership)
With the same assumptions as in Theorem 3.1.8, let m = Ps
i=1 figi ∈M ,
where fi ∈P for i = 1, . . . , s, and let F be the matrix consisting of one
column whose entries are f1, . . . , fs.
a) The equality m = H (A F) provides an explicit expression of m as a
combination of the given generators h1, . . . , ht of M .
b) Let N = (A M | It −A B). Then every explicit expression of m as
a combination of the given generators h1, . . . , ht of M is of the form
m = H (A F + N P) for a suitable matrix P consisting of one column
of polynomials.

3.1 Computation of Syzygy Modules
153
Proof.
To prove a), it suﬃces to combine the two equalities m = G F and
G = H A. Now we prove b). If m = H Q with a t×1-matrix Q of polynomi-
als, we deduce from a) that H Q−H (A F) = 0. Hence Q−A F is a syzygy
of H. From Theorem 3.1.8 we deduce that Q −A F = N P for a suitable
column matrix P . Now we combine m = H Q with Q = A F + N P and
obtain the claim.
□
Our next example shows how one can apply the previous theorem in prac-
tice. It also demonstrates that the system of generators of Syz(H) provided
by the theorem is in general not minimal.
Example 3.1.10. In Example 2.5.7 we saw that {g1, g2, g3} with g1 = x2 ,
g2 = xy + y2 , and g3 = y3 is a Gr¨obner basis of the ideal I = (g1, g2) in
P = K[x, y] with respect to σ = Lex. We let G = (g1, g2, g3), h1 = g1 , and
h2 = g2 , and we want to compute the syzygy module of H = (h1, h2).
Using the Extended Buchberger Algorithm 2.5.11, we calculate the ma-
trix A, and using the Division Algorithm 1.6.4, we calculate the matrix B.
We ﬁnd
A =
µ
1
0
y
0
1
−x + y
¶
and
B =


1
0
0
1
0
0


An application of Corollary 3.1.5 now yields the system of generators
s12 = yε1 + (−x + y)ε2 −ε3 , s13 = y3ε1 −x2ε3 , and s23 = y2ε2 + (−x −y)ε3
of the P -module Syz(G). Therefore we get
M =


y
y3
0
−x + y
0
y2
−1
−x2
−x −y


and
N =
µ
0
−y(x2 −y2)
−y(x + y)
0
0
0
x2(x −y)
x2
0
0
¶
Even if we delete the zero columns in N , we still have no minimal system
of generators of Syz(H), since the second column is a multiple of the third.
Altogether, we ﬁnd
Syz(H) = ⟨−y(x + y)ε1 + x2ε2⟩⊆P 2
It is apparent that in the preceding example we actually could have done
without using the Extended Buchberger Algorithm or the Division Algo-
rithm, since the Gr¨obner basis {g1, g2, g3} contained the system of generators
{h1, h2} whose syzygy module we wanted to compute. This happens quite
often if we start with an arbitrary system of generators of M and determine
a Gr¨obner basis from it by using Buchberger’s Algorithm. So, let us study
this case.

154
3. First Applications
Corollary 3.1.11. Suppose that, in the situation of Theorem 3.1.8, the ma-
trix A is of the form A = (It | C) with a t × (s −t)-matrix C over P . Let
M be a matrix whose columns generate Syz(G). If we decompose it in the
form M = ( M′
M′′ ) with a matrix M′ having t rows and a matrix M′′ hav-
ing s −t rows, then the syzygy module Syz(H) is generated by the columns
of the matrix M′ + C · M′′.
Proof.
By assumption, the matrix B is of the form B = ( It
0 ). Therefore we
obtain It −A B = It −It = 0, and the right-hand part of the matrix N
in the theorem contributes nothing to Syz(H). The left-hand part of N is
given by A M = (It | C) · ( M′
M′′ ) = M′ + C · M′′.
□
As an application of Theorem 3.1.8, we have the following method to
determine an irredundant system of generators of a P -submodule M ⊆P r ,
i.e. a system of generators such that no proper subset of it generates M .
Notice that the second condition in the following corollary can be checked
eﬀectively using the Submodule Membership Test 2.4.10.a.
Corollary 3.1.12. Let {h1, . . . , ht} be a system of generators of a P -sub-
module M ⊆P r , let H = (h1, . . . , ht), and let N be a matrix over P
whose columns generate the P -module Syz(H). For every i ∈{1, . . . , t}, the
following conditions are equivalent.
a) We have hi ∈⟨h1, . . . , hi−1, hi+1, . . . , ht⟩.
b) The ideal generated by the ith row of N is the unit ideal of P .
In particular, a repeated application of this equivalence allows us to ﬁnd
an irredundant system of generators of M which is contained in {h1, . . . , ht}.
Proof.
Both conditions are equivalent to the condition that there exists a
column in the column space of N whose ith entry is 1.
□
Example 3.1.13. Let h1 = x2y2 −1, h2 = x4y4 −2x2y2 + xyz2 −1
2z4 + 1
2 ,
h3 = xyz2 −1
2z4 −1
2 , and h4 = xy −z2 be polynomials in Q[x, y, z],
and let I be the ideal generated by {h1, h2, h3, h4}. Using the method de-
scribed in the corollary, we try to shorten this system of generators. Since
Syz(h1, h2, h3, h4) = ⟨(1, 0, −2, −xy + z2), (0, 0, −2xy + 2z2, 2xyz2 −z4 −1),
(x2y2 −1, −1, 1, 0)⟩, we can delete h1 from the system of generators of I .
Since Syz(h2, h3, h4) = ⟨(0, −2xy + 2z2, 2xyz2 −z4 −1), (1, −x2y2 −1
2xyz2 −
1
2z4 + 1, −x3y3 + 1
4z6 + 3
2xy −3
4z2)⟩, we can then delete h2 . The remaining
system of generators {h3, h4} of I is irredundant, because we can check that
Syz(h3, h4) = ⟨(−2xy + 2z2, 2xyz2 −z4 −1)⟩.
This example also shows that we can shorten some systems of generators
in diﬀerent ways. For instance, we could have deleted h2 and then h3 in
order to get the irredundant system of generators {h1, h4} of I .

3.1 Computation of Syzygy Modules
155
Exercise 1. Let f1, f2 ∈P be two non-zero polynomials. Suppose that
the module Syz(f1, f2) ⊆P 2 is generated by a single vector (g1, g2) ∈P 2.
Then show that f2 is a multiple of g1 , and that gcd(f1, f2) = f2/g1 .
Exercise 2. Compute a set of generators of Syz(H) in Example 3.1.10,
using the method described in Corollary 3.1.11.
Exercise 3.
Let P = K[x, y, z], let σ be a term ordering on T3 , let
g1 = yz , g2 = xz , g3 = xy, and let G = (g1, g2, g3). Find a subset B′ ⊆B
such that the corresponding set Σ′ = {σij ∈Σ | (i, j) ∈B′} is a set of
generators of Syz(LMσ(G)), but {sij | (i, j) ∈B′} is not a τ -Gr¨obner
basis of Syz(G), where τ is the ordering induced by (σ, G).
Exercise 4. Let G = (g1, . . . , gs), where gi ∈P for i = 1, . . . , s. Prove
that Syz(G) = (0) if and only if s = 1.
Exercise 5.
Let G = (g1, . . . , gs), where gi ∈P for i = 1, . . . , s and
g1 = 1. Describe an explicit set of generators of Syz(G) consisting of s−1
elements.
Exercise 6. Let I be an ideal in P = K[x1, . . . , xn].
a) Assume that I is a principal ideal generated by a non-zero element f .
Then show that every element of I has a unique representation as a
multiple of f .
b) Assume that I = (f1, . . . , fr), where fi ∈P for i = 1, . . . , r and
r > 1, and let f ∈I . Then show that f can be represented in more
than one way as a combination of f1, . . . , fr .
Exercise 7. Let {h1, . . . , ht} be a set of vectors in P r which generates
a module M ⊆P r , let m ∈M , and let σ be a term ordering of type
PosTo on Tn⟨ε1, . . . , εt+1⟩. Explain how one can use the knowledge of
a σ-Gr¨obner basis of the syzygy module Syz(m, h1, . . . , ht) to give an
alternative method for computing explicit membership.
Tutorial 28: Splines
Suppose we have a closed interval [a, b] ⊆R, where a, b ∈R and a < b. For
k ≥1, a tuple C = (c0, . . . , ck) ∈Rk such that a = c0 < c1 < · · · < ck = b
deﬁnes a decomposition of the interval [a, b] into subintervals. Furthermore,
suppose that we are given numbers d0, . . . dk ∈R. A tuple of polynomials
(s1, . . . , sk) ∈R[x]k is called a C -spline with values (d0, . . . , dk) if we have
si(ci−1) = di−1 and si(ci) = di for i = 1, . . . , k. The set of all C -splines will
be denoted by S(C). Notice that we did not ﬁx the tuple (d0, . . . , dk) here,
i.e. that S(C) contains the C -splines for all tuples (d0, . . . , dk). Our goal in
this tutorial is to study the set of C -splines and to compute it eﬀectively.
To each spline (s1, . . . , sk) ∈S(C) we can associate the spline function
s : [a, b] −→R given by s(t) = si(t) for t ∈[ci−1, ci] and i = 1, . . . , k. A
natural situation in which spline functions are useful occurs when we have a

156
3. First Applications
bounded function f : [a, b] −→R (which may be very complicated) for which
we know ﬁnitely many values di = f(ci) for i = 0, . . . , k. In this case we are
looking for a spline function s : [a, b] −→R which approximates f well, i.e.
for which the number ∥f −s ∥∞= sup
t∈[a,b]
{|f(t) −s(t)|} is small.
a) The simplest cases of splines are single polynomials passing through the
points (c0, d0), . . . , (ck, dk). For i = 0, . . . , k, we deﬁne ℓi = Q
j̸=i
x−cj
ci−cj .
Show that the Lagrange interpolation polynomial ℓ= Pk
i=0 diℓi has
degree ≤k and passes through the points (c0, d0), . . . , (ck, dk). Write a
CoCoA function Lagrange(. . .) which takes the list of pairs (ci, di) and
computes the Lagrange interpolation polynomial.
b) Take the functions f : [0, 2π] −→R given by f(t) = sin(t) and
g : [−2, 2] −→R given by g(t) =
1
1+25t2 . In each case, divide the inter-
val into k = 4 equal parts and compute the corresponding Lagrangean
interpolation polynomial.
Hint: First write a CoCoA function Sin(. . .) which uses the Taylor expan-
sion to compute the value of sin(t) up to a certain number of decimal
digits. Then write a CoCoA function Values(. . .) which takes the tuple
(c0, . . . , ck) and the name of the function and computes the list of pairs
[(c0, d0), . . . , (ck, dk)]. Finally, this list can be used in Lagrange(. . .).
............................... ................
.......................................................
................
..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.................................... ................
......................................................
................
................................................................................................................................................................................................................................................................................................................................................................................................................................................
........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
c) Repeat part b) with k = 8. Use CoCoA to compute approximations for
∥f −s ∥∞and ∥g −s ∥∞in all cases. Conclude that the approximation
of f by its interpolation polynomial got better when we increased k,
whereas the approximation of g got worse.
Hint: Compute |f(t)−s(t)| resp. |g(t)−s(t)| for all t increasing in steps
of 0.01 from a to b.

3.1 Computation of Syzygy Modules
157
................................. ................
......................................................
................
.........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
................................. ................
.......................................................
................
.........................................................................................................................................................................................................................................................................................................................................................................................................................
.....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
d) Let r ≥0, and let Ar be the matrix





1
−1
0
· · ·
0
(x −c1)r+1
0
· · ·
0
0
...
...
...
...
0
...
...
...
...
...
...
...
0
...
...
...
0
0
· · ·
0
1
−1
0
· · ·
0
(x −ck−1)r+1





of size (k −1) × (2k −1). Prove that, for a spline (s1, . . . , sk) ∈S(C),
the following conditions are equivalent.
1) The associated spline function s : [a, b] −→R is r times diﬀerentiable
and its rth derivative is continuous.
2) For i = 1, . . . , k−1, the diﬀerence si−si+1 is divisible by (x−ci)r+1.
3) There are polynomials sk+1, . . . , s2k−1 ∈R[x] such that the tuple
(s1, . . . , s2k−1) is contained in Syz(Ar).
The set of all C -splines (s1, . . . , sk) satisfying these conditions will be
denoted by Sr(C).
e) Using d), conclude that Sr(C) is an R[x]-submodule of R[x]k . Write a
CoCoA function Splines(. . .) which takes r and a tuple C ∈Qk+1 and
computes a system of generators for the R[x]-module Sr(C).
Hint: Use Lemma 2.4.16 to show that it suﬃces to compute a system of
generators of the corresponding Q[x]-module.
f) Let d ≥0. We say that a C -spline (s1, . . . , sk) ∈Sr(C) has degree ≤d
if deg(si) ≤d for i = 1, . . . , k. Prove that the subset Sr
d(C) ⊆Sr(C) of all
C -splines of degree ≤d is an R-vector subspace of R[x]k of dimension
dimR(Sr
d(C)) =
½ d + 1
if d < r + 1
(k −1)(d −r) + d + 1
if d ≥r + 1
Hint: Consider the vectors (xi, . . . , xi), where i = 0, . . . , d, and the vec-
tors (0, . . . , 0, xi(x−cj)r+1, . . . , xi(x−cj)r+1), where i = 0, . . . , d−r −1
and j = 1, . . . , k −1. (There are j zeros.)

158
3. First Applications
g) A C -spline (s1, . . . , sk) ∈S2
3(C) is called a natural C -spline if it satisﬁes
the additional conditions s′′
1(a) = 0 and s′′
k(b) = 0. Let (s1, . . . , sk) be a
natural C -spline with values (d0, . . . , dk).
1) Prove that the tuple (0, s′′
1(c1), . . . , s′′
k−1(ck−1), 0) is the unique so-
lution of the system of equations
(ci−ci−1)xi−1+2 (ci+1−ci−1)xi+(ci+1−ci)xi+1 = 6( di+1−di
ci+1−ci −di−di−1
ci−ci−1 )
where i = 1, . . . , k −1.
2) Show that the spline (s1, . . . , sk) can be computed from this tuple
via the formulas si = αi(x−ci−1)3+βi(x−ci−1)2+γi(c−ci−1)+di−1 ,
where αi =
1
6(ci−ci−1) ·(s′′
i (ci)−s′′
i−1(ci−1)), where βi = 1
2 s′′
i−1(ci−1),
and where γi = ci−1−ci
6
· (s′′
i (ci) + 2s′′
i−1(ci−1)) + di−di−1
ci−ci−1 for every
i ∈{1, . . . , k}.
3) Write a CoCoA function NatSpline(. . .) which takes the tuple of
pairs ((c0, d0), . . . , (ck, dk)) and computes the corresponding natural
C -spline.
h) Apply your function NatSpline(. . .) to compute the natural C -spline
approximating the function h : [0, 3] −→R given by h(t) = sin(et),
where C is the equidistant decomposition of [0, 3] into 12 parts.
i) Redo part h) using the decomposition C′ = (0, 0.45, 1.15, 1.55, 1.85, 2.05,
2.25, 2.4, 2.55, 2.65, 2.75, 2.85, 3). Show that the corresponding spline func-
tion becomes a much better approximation of h.
.................................................. ................
.......................................................
................
•
•
•
•
•
•
•
•
•
•
•
•
•
..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.................................................. ................
.......................................................
................
•
•
•
•
•
•
•
•
•
•
•
•
•
..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................

3.1 Computation of Syzygy Modules
159
Tutorial 29: Hilbert’s Syzygy Theorem
Let K be a ﬁeld, let P = K[x1, . . . , xn], let σ be a module term ordering
on Tn⟨e1, . . . , er⟩, let M ⊆P r be a P -submodule, and let G = (g1, . . . , gs)
be a tuple of non-zero vectors which form a σ-Gr¨obner basis of M .
a) Suppose, in addition, that for every i = 1, . . . , s there exists an index
γi ∈{1, . . . , r} such that LTσ(gi) = eγi . Show that the P -module M is
free. (Hint: Reduce the proof to the case where γi ̸= γj for i ̸= j . Then
argue as in Exercise 7 of Section 2.3.)
Now assume instead that LTσ(g1) >PosLex · · · >PosLex LTσ(gs) and that
there exists a number m ∈{1, . . . , n} such that LTσ(gi) ∈K[xm, . . . , xn]r
for i = 1, . . . , s.
b) Prove that LTτ(σij) ∈K[xm+1, . . . , xn]s for all syzygies σij of G con-
structed in Corollary 3.1.5, where τ is the ordering induced by (σ, G)
on Tn⟨ε1, . . . , εs⟩.
c) Conclude that, in the situation of b), there exists an exact sequence
0 −→Fn−m −→· · · −→F1 −→F0 −→M −→0
with ﬁnitely generated free P -modules F0, . . . , Fn−m.
d) Let N be a non-zero, ﬁnitely generated P -module. Represent the mod-
ule N as N ∼= P r/M for a suitable r ≥1 and a P -submodule M of P r .
Then use c) to show that there exists an exact sequence
0 −→Fn −→· · · −→F1 −→F0 −→N −→0
with ﬁnitely generated free P -modules F0, . . . , Fn , some of which may
be zero. This is an eﬀective proof of Hilbert’s Syzygy Theorem due
to F. Schreyer.
e) Let n = 3. Write a CoCoA program HilbRes(. . .) which takes a tuple
of non-zero vectors G which form a Gr¨obner basis of a module M and
computes a resolution of the residue class module P r/M in the way
described above. (Do not use the built-in CoCoA function Res(. . .).)

160
3. First Applications
3.2 Elementary Operations on Modules
‘And you do Addition?’ the White Queen asked.
‘What’s one and one and one and one and one
and one and one and one and one and one?’
‘I don’t know,’ said Alice. ‘I lost count.’
‘She can’t do Addition,’ the Red Queen interrupted.
‘Can you do Subtraction? Take nine from eight.’
‘Nine from eight I can’t, you know,’ Alice replied very readily: ‘but – ’
‘She can’t do Subtraction,’ said the White Queen. ‘Can you do Division?
Divide a loaf by a knife – what’s the answer to that?’
‘I suppose –’ Alice was beginning, but the Red Queen answered for her.
‘Bread-and-butter, of course’.
(Charles L. Dodgson)
This is rather a long section, much longer than the average. Even the
quotation is longer than usual! Why? As the title suggests, we want to de-
scribe techniques for computing elementary operations on modules such as
sums, products, intersections, colon ideals, annihilators, etc. The key ingre-
dient will be the computation of syzygy modules explained in the previous
section. Then, in later sections and in Volume 2, our elementary operations
on modules will themselves become the key ingredients for a host of other
applications of Computational Commutative Algebra.
It is a fact that there are many diﬀerent ways to perform these operations,
and our goal is to describe the most important ones in suﬃcient detail so
that the propositions we present can be easily translated into algorithms.
We are aware that the general appearance of the entire section is rather
technical, with many matrices and indices ﬂoating around. However, if you
are interested both in the theoretical background and in how to implement
the operations described here, then we hope that you are ready to pay this
price.
Now let us have a closer look at the contents of the current section. We
decided to split it into three subsections which deal with intersections, colon
ideals and annihilators, and colon modules, respectively.
Do we do Addition? Not really, because we consider it trivial. Can we do
Subtraction? Nor that. We don’t know what the diﬀerence of two ideals or
modules could mean. The ﬁrst non-obvious operation is the computation of
the intersection of two ideals or submodules. First, consider the following sim-
ple case. For two non-zero principal ideals I = (f) and J = (g) in P = K[x]
we saw in Proposition 1.2.8.a that their intersection is I ∩J = (lcm(f, g)).
What happens if we consider ideals I and J in P = K[x1, . . . , xn]? How
can we compute a set of generators of I ∩J from given sets of generators of I
and J ? There is no obvious answer, but in Section 3.1 we expended a lot of
eﬀort to compute syzygies, and now it is time to reap the rewards. With the
tools developed there we will be able to solve the problem even in the more
general case of modules (see Propositions 3.2.3 and 3.2.7).

3.2 Elementary Operations on Modules
161
A nice consequence is the possibility of presenting a module of the
form M/(M ∩N) via generators and relations (see Corollary 3.2.6). An-
other nice extra bonus is the discovery that syzygies provide a method for
computing greatest common divisors and least common multiples of multi-
variate polynomials, without having to resort to factorizing algorithms (see
Corollary 3.2.9).
Can we do Division? Suppose we are given two non-zero polynomials
g, h ∈P such that g = fh for some polynomial f ∈P . This equation implies
that f is a generator of the ideal {a ∈P | a·h ∈(g)}. For two ideals I, J ⊆P ,
a natural generalization is to consider the ideal I :P J = {a ∈P | a · J ⊆I}.
We call it the colon ideal of I by J . This construction is particularly useful
in the computation of the so-called primary decompositions (see Tutorial 43)
and in algebraic geometry, where it is related to the process of removing
irreducible components from an algebraic variety.
The deﬁnition of colon ideals can be extended in two ways into the realm of
modules. One method describes an operation on two modules which produces
an ideal, called the colon ideal. It can also be viewed as the annihilator of a
certain quotient module (see Deﬁnition 3.2.10). The other method yields an
operation on two modules and an ideal which produces a module called the
colon module (see Deﬁnition 3.2.17).
In the subsection “Colon Ideals and Annihilators” we show two diﬀerent
approaches to the computation of colon ideals, one based on intersections
and the other based on syzygies of a suitable matrix (see Proposition 3.2.15).
And in the subsection “Colon Modules” we show two diﬀerent approaches
to the computation of colon modules. Again, one is based on intersections
and the other on syzygies of a suitable matrix (see Proposition 3.2.22). A
ﬁnal application of the techniques developed above is a method for checking
whether a given sequence of polynomials is a regular sequence, a property
which we shall reexamine in Tutorial 33 and in Volume 2.
Let K be a ﬁeld, n ≥1, P = K[x1, . . . , xn] a polynomial ring, r ≥1,
σ a module term ordering on Tn⟨e1, . . . , er⟩, and G = (g1, . . . , gs) ∈(P r)s a
tuple of vectors which generate a P -submodule M of P r . Furthermore, we
let H = (h1, . . . , ht) ∈(P r)t be a tuple of vectors which generate another
P -submodule N of P r .
For an r′ ×s′ matrix M with entries in P , we let Syz(M) be the syzygy
module of the tuple of the columns of M, each viewed as a vector in P r′, as
already explained in the introduction of the chapter. The following remark
collects some operations on modules which can be computed in a completely
trivial way.
Remark 3.2.1. Let M = ⟨g1, . . . , gs⟩and N = ⟨h1, . . . , ht⟩be two P -sub-
modules of P r as above, and let I ⊆P be an ideal which is generated by a
set of polynomials {f1, . . . , fu} ⊆P .
a) The sum M + N is the P -submodule of P r generated by the set of
vectors {g1, . . . , gs, h1, . . . , ht} ⊆P r .

162
3. First Applications
b) The product I · M is the P -submodule of P r generated by the set of
vectors {figj | 1 ≤i ≤u, 1 ≤j ≤s} ⊆P r .
c) For every d ≥1, the power Id is the ideal of P generated by the set of
polynomials {fj1 · · · fjd | j1, . . . , jd ∈{1, . . . , u}} ⊆P .
3.2.A
Intersections
The ﬁrst non-trivial operation we consider is the computation of the intersec-
tion of two submodules of P r . One method for performing this computation
is based on the following result about the preimage of a submodule of P r
under a P -linear map λ : P s −→P r . Recall that the canonical basis of P s
is denoted by {ε1, . . . , εs}.
Lemma 3.2.2. Let N = ⟨h1, . . . , ht⟩be a P -submodule of P r, and let the
P -linear map λ : P s −→P r be given by ϕ(εi) = gi for i = 1, . . . , s. We let
{v1, . . . , vu} ⊆P s+t be a system of generators of Syz(g1, . . . , gs, h1, . . . , ht),
and we write vj = (f1j, . . . , fs+t j) with f1j, . . . , fs+t j ∈P for j = 1, . . . , u.
Then we have
λ−1(N) = ⟨(f1j, . . . , fsj) | 1 ≤j ≤u⟩
Proof.
Since we have λ(f1j, . . . , fsj) = Ps
i=1 fijgi = −Pt
i=1 fs+i jhi ∈N
for j = 1, . . . , u, it suﬃces to prove the reverse inclusion. Given a vector
v = (a1, . . . , as) ∈λ−1(N), we can ﬁnd polynomials as+1, . . . , as+t ∈P
such that λ(v) = Ps
i=1 aigi = −Pt
i=1 as+ihi . Then (a1, . . . , as+t) is in
Syz(g1, . . . , gs, h1, . . . , ht), and we can ﬁnd polynomials p1, . . . , pu ∈P such
that (a1, . . . , as+t) = Pu
j=1 pjvj . In particular, we get v = (a1, . . . , as) =
Pu
j=1 pj(f1j, . . . , fsj) which proves the claim.
□
Proposition 3.2.3. (Intersection of Two Submodules)
Let M = ⟨g1, . . . , gs⟩and N = ⟨h1, . . . , ht⟩be two P -submodules of P r, and
let λ : P s −→P r be the P -linear map given by ϕ(εi) = gi for i = 1, . . . , s.
a) Let {v1, . . . , vu} ⊆P s+t be a system of generators of the P -module
Syz(g1, . . . , gs, h1, . . . , ht), and let vj = (f1j, . . . , fs+t j) with polynomials
f1j, . . . , fs+t j ∈P for j = 1, . . . , u. Then we have
M ∩N = λ(λ−1(N)) = ⟨
sP
i=1
fijgi | 1 ≤j ≤u⟩
b) Consider the following block matrix of size 2r × (r + s + t)
M =
µ
Ir
G
0
Ir
0
H
¶
where Ir is the r × r identity matrix. Let {v1, . . . , vu} ⊆P r+s+t be a
system of generators of Syz(M), and let vj = (f1j, . . . , fr+s+t j) with
f1j, . . . , fr+s+t j ∈P for j = 1, . . . , u. Then
M ∩N = ⟨(f1j, . . . , frj) | 1 ≤j ≤u⟩

3.2 Elementary Operations on Modules
163
Proof.
Since claim a) follows immediately from the lemma, it suﬃces to
show claim b). Let w1, . . . , wr+s+t be the column vectors of M. If we look
at the ﬁrst and the last r components of f1jw1 + · · · + fr+s+t j wr+s+t = 0,
we obtain



f1j
...
frj


= −fr+1 j g1 −· · · −fr+s j gs = −fr+s+1 j h1 −· · · −fr+s+t j ht
for j = 1, . . . , u, and therefore (f1j, . . . , frj) ∈M ∩N . Conversely, if we start
with an element v ∈M∩N , and if we write v = (a1, . . . , ar) with polynomials
a1, . . . , ar ∈P , then there are polynomials ar+1, . . . , ar+s+t ∈P such that
v = −ar+1g1 −· · · −ar+sgs = −ar+s+1h1 −· · · −ar+s+tht
By combining those representations of v, we get the vector equation
a1w1 + · · · + ar+s+twr+s+t = 0
Thus there are polynomials p1, . . . , pu ∈P such that
(a1, . . . , ar+s+t) =
u
X
j=1
pj(f1j, . . . , fr+s+t j)
The ﬁrst r components of this equality now prove the claim.
□
Example 3.2.4. Let us compute the intersection of the ideals I1 = (x1, x2)
and I2 = (x2
1 −x2
2, x1x2x3, x2
3 −x1) in the ring K[x1, x2, x3] using the two
methods provided by this proposition.
Following the ﬁrst method, we compute a system of generators of the
syzygy module Syz(x1, x2, x2
1−x2
2, x1x2x3, x2
3−x1) and get {v1, v2, v3, v4, v5},
where v1 = (x2, −x1, 0, 0, 0), v2 = (x1, −x2, −1, 0, 0), v3 = (−x2, x2
3, 0, 0, −y),
v4 = (x2
3 −x1, 0, 0, 0, −x1), and v5 = (x2x3, 0, 0, −1, 0). Therefore we con-
clude that I1 ∩I2 = (x2
1 −x2
2, x2x2
3 −x1x2, x1x2
3 −x2
2, x1x2x3).
Following the second method, we compute a system of generators of the
syzygy module of the columns of
M =
µ
1
x1
x2
0
0
0
1
0
0
x2
1 −x2
2
x1x2x3
x2
3 −x1
¶
The computation yields the set {⟨0, x2, −x1, 0, 0, 0⟩, ⟨−x2
1+x2
2, x1, −x2, 1, 0, 0⟩,
⟨−x2x2
3+x1x2, 0, x2
3−x1, 0, 0, x2⟩, ⟨−x1x2
3+x2
2, x2
3, −x2, 1, 0, x1⟩, ⟨−x1x2x3,
0, x1x3, 0, 1, 0⟩}. We pick the ﬁrst non-zero coordinates of these vectors and
get I1 ∩I2 = (−x2
1 +x2
2, −x2x2
3 +x1x2, −x1x2
3 +x2
2, −x1x2x3), in agreement
with the above result.
Next we use the preceding proposition to solve an important problem.
Before, let us introduce a little bit of terminology.

164
3. First Applications
Deﬁnition 3.2.5. Let R be a ring, and let M = ⟨m1, . . . , ms⟩be a ﬁnitely
generated R-module. Suppose that the syzygy module Syz(m1, . . . , ms) has
a ﬁnite system of generators {v1, . . . , vu} ⊆Rs. Moreover, let {e1, . . . , es}
be the canonical basis of Rs and {ε1, . . . , εu} the canonical basis of Ru .
We deﬁne an R-linear map ϕ : Rs −→M by ϕ(ei) = mi for i = 1, . . . , s
and an R-linear map ψ : Ru −→Rs by ψ(εj) = vj for j = 1, . . . , u. Then
the sequence
Ru
ψ
−→Rs
ϕ
−→M −→0
is clearly exact. It is called a presentation of M via generators and
relations, or simply a presentation of M . Equivalently, we shall also call
the induced isomorphism M ∼= Rs/⟨v1, . . . , vu⟩a presentation of M . Here
the residue classes of the canonical basis vectors of Rs correspond to the
generators of M , and the vectors v1, . . . , vu generate the module of relations
among those generators.
Given two submodules M, N of P r, it is natural to ask for a presentation
of M/(M ∩N) via generators and relations. More generally, we have the
following result.
Corollary 3.2.6. Given the situation of Proposition 3.2.3, we deﬁne vectors
wj = (f1j, . . . , fsj) for j = 1, . . . , u. The map λ induces a P -linear map
λ : P s −→M/(M ∩N). Moreover, let ψ : P u −→P s be the P -linear map
which sends εj to wj for j = 1, . . . , u. Then the sequence
P u
ψ
−→P s
λ
−→M/(M ∩N) −→0
is a presentation of M/(M ∩N). In other words, there is an isomorphism of
P -modules M/(M ∩N) ∼= P s/⟨w1, . . . , wu⟩.
Proof.
Since the image of λ is M , it is clear that λ is surjective. The
kernel of λ is λ−1(M ∩N) = λ−1(N). By Lemma 3.2.2, this preimage equals
⟨w1, . . . , wu⟩= Im(ψ).
□
If we need to compute the intersection of a ﬁnite number of submodules
M1, . . . , Mℓof P r, we may either proceed recursively or try to intersect all
submodules simultaneously.
Proposition 3.2.7. (Computation of Multiple Intersections)
Let ℓ≥2, and let M1, . . . , Mℓ⊆P r be P -submodules. For every index
i ∈{1, . . . , ℓ}, let Mi be a matrix whose column vectors generate Mi .
a) We have M1 ∩· · · ∩Mℓ= (· · · ((M1 ∩M2) ∩M3) ∩· · ·) ∩Mℓ. Therefore
we can compute M1 ∩· · · ∩Mℓby iteratively applying Proposition 3.2.3.
b) Consider the block matrix

3.2 Elementary Operations on Modules
165
M =





Ir
M1
0
· · ·
0
Ir
0
M2
...
...
...
...
...
...
0
Ir
0
· · ·
0
Mℓ





Let {v1, . . . , vu} be a system of generators of the syzygy module Syz(M),
and write vj = (f1j, f2j, . . .) with f1j, f2j, . . . ∈P for j = 1, . . . , u. Then
we have
M1 ∩· · · ∩Mℓ= ⟨(f1j, . . . , frj) | 1 ≤j ≤u⟩
Proof.
The proof of the second method follows in the same way as the proof
of Proposition 3.2.3.b.
□
Example 3.2.8. Let us compute the intersection of the three prime ideals
p1 = (x, y), p2 = (x2 −y3, y2 −z), and p3 = (x −y3, y2 −z) in K[x, y, z]
using the two methods explained in this proposition.
First, we compute I = p1 ∩p2 and get I = (y3 −yz, xy2 −xz, x2 −yz).
Then we calculate I ∩p3 and get p1 ∩p2 ∩p3 = (y3 −yz, xy2 −xz, x2yz −
y2z2 −x3 + xyz).
Following the second method, we compute a system of generators of the
syzygy module of the columns of
M =


1
x
y
0
0
0
0
1
0
0
x2 −y3
y2 −z
0
0
1
0
0
0
0
x −y3
y2 −z


The computation yields a complicated set of generators, from which we ex-
tract the ﬁrst coordinates and get p1∩p2∩p3 = (−y3+yz, −xy2+xz, −x2yz+
y2z2+x3−xyz, −x2y2+y3z+x2z−yz2, −x3y+xy2z+x2z2−yz3). An irredun-
dant subset of generators is {−y3 +yz, −xy2 +xz, −x2yz +y2z2 +x3 −xyz}.
Thus we see that we get the same ideal as above.
As an application of the preceding two propositions, we can show how to
compute greatest common divisors and least common multiples of polynomi-
als in n indeterminates. We point out that the following corollary provides
an algorithm which works over any base ﬁeld K over which we can compute
Gr¨obner bases. In particular, it does not require factorization of multivariate
polynomials.
As in Section 1.2, the expressions gcd(f1, . . . , fm) resp. lcm(f1, . . . , fm)
shall represent any greatest common divisor resp. least common multiple of
a set of polynomials {f1, . . . , fm} ⊆P .
Corollary 3.2.9. (Computation of gcd and lcm)
Let m ≥2, let f1, . . . , fm ∈P , and let σ be a term ordering on Tn .
a) The reduced σ-Gr¨obner basis of the intersection ideal (f1) ∩· · · ∩(fm)
consists of precisely one element, namely the element lcm(f1, . . . , fm).
Thus least common multiples can be computed using Proposition 3.2.7.

166
3. First Applications
b) A greatest common divisor of two polynomials can be computed via a) and
the formula gcd(f1, f2) = f1f2/ lcm(f1, f2). A greatest common divisor of
more than two polynomials can be computed recursively using the formula
gcd(f1, . . . , fm) = gcd(gcd(f1, . . . , fm−1), fm).
Proof.
By Proposition 1.2.8.a, the ideal I = (f1) ∩· · · ∩(fm) is generated
by the polynomial f = lcm(f1, . . . , fm). Since I is a principal ideal, we have
LTσ(I) = (LTσ(f)), and therefore the reduced σ-Gr¨obner basis of I consists
of precisely one polynomial, namely f . This proves a), and b) is an immediate
consequence of a) and Proposition 1.2.8.b.
□
3.2.B
Colon Ideals and Annihilators
Now we start to consider the problem of computing colon ideals and annihi-
lators. They are deﬁned as follows.
Deﬁnition 3.2.10. Let R be a ring, and let U be an R-module.
a) Given two R-submodules M and N of U , the set
N :R M = {r ∈R | r · M ⊆N}
is an ideal of R. It is called the colon ideal (or the ideal quotient if
U = R) of N by M .
b) Let M be an R-module. The set AnnR(M) = {r ∈R | r · M = 0} is an
ideal of R. It is called the annihilator of M .
Colon ideals and annihilators are essentially the same thing, as our next
proposition shows.
Proposition 3.2.11. Let R be a ring, let U be an R-module, and let M
and N be two R-submodules of U . Then
N :R M = AnnR(M/(N ∩M))
Proof.
The deﬁnition yields AnnR(M/(N ∩M)) = {r ∈R | r·M ⊆N ∩M}.
Since r ·M is contained in M for every r ∈R, we get AnnR(M/(N ∩M)) =
{r ∈R | r · M ⊆N}, and this proves the claim.
□
Our goal is to compute the above objects eﬀectively when we deal with
ﬁnitely generated modules over aﬃne algebras. We just saw that computing
colon ideals is the same thing as computing annihilators. The next remark
says that for our purposes it suﬃces to compute annihilators of ﬁnitely gen-
erated P -modules, where P = K[x1, . . . , xn] is the polynomial ring over a
ﬁeld K as usual.

3.2 Elementary Operations on Modules
167
Remark 3.2.12. Let J be an ideal in P , let M be a ﬁnitely generated
module over the aﬃne K -algebra P/J , and let π : P −↠P/J be the
canonical homomorphism. We can view M as a ﬁnitely generated P -module
via π, i.e. via f · m = π(f)m for f ∈P and m ∈M .
Then the annihilator AnnP/J(M) is the image of the ideal AnnP (M)
under π, because π(f) ∈AnnP/J(M) for some f ∈P means π(f) · M =
f · M = 0, i.e. it means f ∈AnnP (M).
The following lemma solves our problem in the case of a cyclic module M .
Lemma 3.2.13. Let M = ⟨g⟩and N = ⟨h1, . . . , ht⟩be two P -submodules
of P r, where M is cyclic. Let {v1, . . . , vu} ⊆P t+1 be a system of generators
of Syz(g, h1, . . . , ht). We write vj = (f1j, . . . , ft+1 j) with f1j, . . . , ft+1 j ∈P
for j = 1, . . . , u. Then
N :P ⟨g⟩= AnnP (M/(N ∩M)) = (f11, . . . , f1u)
Proof.
It suﬃces to apply Lemma 3.2.2 to the map λ : P −→P r given by
1 7→g, because we have N :P ⟨g⟩= λ−1(N).
□
Example 3.2.14. Consider the intersection I = p1 ∩p2 of the two prime
ideals p1 = (y, z) and p2 = (x −y2, y3 −z) in the ring P = K[x, y, z]. Using
Proposition 3.2.3, we ﬁnd I = (xy−z, y3−z). In fact, Corollary 3.1.12 allows
us to check that {xy −z, y3 −z} is an irredundant system of generators of I .
Now we want to compute the colon ideal I :P (f), where f is the
polynomial f = x −y2 . The lemma tell us that we have to calculate
Syz(x−y2, xy−z, y3−z). The result is the module generated by the two vec-
tors (−y, 1, 1) and (z−xy, x−y2, 0). Thus we obtain I :P (f) = (−y, z−xy) =
(y, z) = p1 .
The explanation of this result is simple, and we can prove it directly. For
g ∈p1 , we have fg ∈p1 , and also fg ∈p2 , since f ∈p2 . Therefore we have
fg ∈I , and this means that g ∈I :P (f). Conversely, let fg ∈I . Then
fg ∈p1 and f /∈p1 implies g ∈p1 , because p1 is a prime ideal.
Proposition 3.2.15. (Computation of Colon Ideals)
Let M = ⟨g1, . . . , gs⟩and N = ⟨h1, . . . , ht⟩be two P -submodules of P r, and
let H = (h1, . . . , ht).
a) The colon ideal N :P M and the annihilator of M/(N ∩M) can be
computed using Lemma 3.2.13 and the formula
N :P M = AnnP (M/(N ∩M)) =
s\
i=1
(N :P ⟨gi⟩)
b) Consider the following block matrix of size rs × (st + 1)

168
3. First Applications
M =





g1
H
0
· · ·
0
g2
0
H
...
...
...
...
...
...
0
gs
0
· · ·
0
H





Let {v1, . . . , vu} ⊆P st+1 be a system of generators of the syzygy mod-
ule Syz(M). We write vj = (f0j, f (1)
1j , . . . f (1)
tj , . . . . . . , f (s)
1j , . . . , f (s)
tj ) with
f0j, f (1)
1j , . . . , f (s)
tj
∈P for j = 1, . . . , u. Then we have
N :P M = AnnP (M/(N ∩M)) = (f01, . . . , f0u)
Proof.
Part a) follows directly from the deﬁnitions. Therefore we prove claim
b). Let w0, w(1)
1 , . . . , w(1)
t , . . . . . . , w(s)
1 , . . . , w(s)
t
∈P rs be the column vectors
of M. For j = 1, . . . , u we have f0jw0 = −Ps
k=1(Pt
i=1 f (k)
ij w(k)
i
). For a
ﬁxed ℓ∈{1, . . . , s}, we get f0jgℓ= −Pt
i=1 f (ℓ)
ij hi for j = 1, . . . , u. Since
this holds for every ℓbetween 1 and s, we get f0j ∈N :P M for j = 1, . . . , u.
Conversely, let a0 ∈N :P M be given. Then there are polynomials
a11, . . . , ast ∈P such that a0gj = Pt
i=1 aijhi for j = 1, . . . , s. By com-
bining these equations into a vector equation, we get
a0w0 −(a11w(1)
1
+ · · · + at1w(1)
t
+ · · · · · · + a1sw(s)
1
+ · · · + atsw(s)
t ) = 0
Therefore there exist polynomials p1, . . . , pu ∈P such that the column vector
given by (a0, −a11, . . . , −at1, . . . . . . , −a1s, . . . , −ats)tr is equal to Pu
j=1 pjvj .
By considering the ﬁrst component of this equation, we get a0 = Pu
j=1 pjf0j ,
and this completes the proof.
□
Example 3.2.16. Let I ⊆Q[x1, x2, x3] be the ideal which is given by the
intersection of the three prime ideals p1 = (x1, x2), p2 = (x2
1 −x3
2, x2 −x3),
and p3 = (x1 −x2
2, x2
1 −x3), and let J = (x2 −x3, x2
1 −x3).
If we want to compute I :P J using part a) of the proposition, we have
to calculate I1 = I :P (x2 −x3) via Lemma 3.2.13. The result is the ideal
I1 = (x2
2 −x1, x2
1x2 −x2x3, x3
1 −x1x3). Similarly, we compute the ideal
I2 = I :P (x2
1 −x3) = (x2
2 −x2x3, x2
1 −x2x3, x1x2 −x1x3). Finally, we
intersect I1 and I2 and get I :P J = I1 ∩I2 = I .
Again the result can be explained in the following way. We can prove as in
Example 3.2.14 that I :P (x2−x3) = p1∩p3 , and that I :P (x2
1−x3) = p1∩p2 .
Now the conclusion follows from part a) of the proposition again.

3.2 Elementary Operations on Modules
169
3.2.C
Colon Modules
Given two ideals I and J in a ring R, we have seen how to compute the colon
ideal I :R J . The colon ideal of one R-module by another was a generalization
of this colon ideal operation between ideals. But there is another way to
generalize it from ideals to modules, namely the colon module operation.
Deﬁnition 3.2.17. Let R be a ring, let I be an ideal in R, let U be an
R-module, and let M and N be two R-submodules of U . Then the set
N :M I = {m ∈M | I · m ⊆N} is an R-submodule of M (and of U ). It is
called the colon module of N by I in M .
The purpose of this subsection is to explain several methods for computing
colon modules of ﬁnitely generated modules over aﬃne K -algebras. We ﬁrst
reduce the problem to the case of submodules of a ﬁnitely generated free
P -module, where P = K[x1, . . . , xn] is a polynomial ring as above.
Proposition 3.2.18. Let J be an ideal in P, let U be a ﬁnitely generated
module over the K -algebra P/J , and let M and N be two P/J -submodules
of U . Furthermore, let I be an ideal in P containing J . Our goal is to
compute N :M (I/J).
Suppose we are given a presentation U ∼= P r/V with a P -submodule V
of P r . We can write M ∼= M ′/V and N ∼= N ′/V with P -submodules M ′
and N ′ of P r containing V . Then N :M (I/J) is the residue class module
of N ′ :M′ I in U .
Proof.
The module N :M (I/J) is given by {¯v ∈M ′/V | (I/J)·¯v ⊆N ′/V }.
This set is {¯v ∈M ′/V | I·v ⊆N ′ for every v ∈M ′ with residue class ¯v ∈U}.
Therefore it is the image of {v ∈M ′ | I·v ⊆N ′} in U . The last set is nothing
but N ′ :M′ I which proves the claim.
□
Example 3.2.19. Let R be the K -algebra with K -basis {1, ε}, where we
have ε2 = 0, let N = ⟨(1, ε)⟩⊆R2 , and let I be the ideal I = (ε) in R.
Suppose we want to compute N :R2 I .
To this end, we ﬁrst write R in the form R = P/(x2) with P = K[x].
Here ε is the image of x in R, and I is the image of the ideal I = (x). Then
we notice that R2 = P 2/V for V = ⟨(x2, 0), (0, x2)⟩, and that N = N ′/V
for N ′ = ⟨(1, x), (x2, 0), (0, x2)⟩. Thus the desired colon module is the image
of N ′ :P 2 I in R2 .
As a consequence of this proposition, we shall now restrict our attention
to the case where M and N are P -submodules of P r and I is an ideal
in P . In a manner similar to the last subsection, we begin by explaining
the computation of the colon module of a submodule by a principal ideal.
We present two methods for doing this calculation, one based on a syzygy
module computation, and one based on performing a certain intersection of
two submodules.

170
3. First Applications
Lemma 3.2.20. Let M = ⟨g1, . . . , gs⟩and N = ⟨h1, . . . , ht⟩be two P -sub-
modules of P r, and let f ∈P \ {0}. Furthermore, let {v1, . . . , vu} ⊆P r be
a system of generators of the P -module fM ∩N . For i = 1, . . . , u, we may
write vi = fwi for some wi ∈M . Then we have
N :M (f) = ⟨w1, . . . , wu⟩
In particular, we compute N :M (f) as follows. Let {˜v1, . . . , ˜vℓ} ⊆P s+t
be a system of generators of the module Syz(fg1, . . . , fgs, h1, . . . , ht). If we
write ˜vj = (f1j, . . . , fs+t j) with f1j, . . . , fs+t j ∈P for j = 1, . . . , ℓ, then
N :M (f) = ⟨
sP
i=1
fijgi | 1 ≤j ≤ℓ⟩
Proof.
First we observe that f · wi = vi ∈fM ∩N ⊆N implies that
wi ∈N :M (f) for i = 1, . . . , u. Conversely, if we start with an element
m ∈N :M (f), we have fm ∈fM ∩N . Thus we can represent fm in the
form fm = Pu
i=1 aivi = Pu
i=1 aifwi with a1, . . . , au ∈P . We cancel f and
obtain m = Pu
i=1 aiwi ∈⟨w1, . . . , wu⟩, as we wanted to show.
To prove the additional claim, it suﬃces to apply Proposition 3.2.3.a to
compute the intersection fM ∩N .
□
Example 3.2.21. When we apply part a) of this lemma in the situation
of the previous example, we see that we have to compute xP 2 ∩N ′ =
⟨(x, 0), (0, x)⟩∩⟨(1, x), (x2, 0), (0, x2)⟩. The result is ⟨(x, 0), (0, x2)⟩. There-
fore we have N ′ :P 2 I = ⟨(1, 0), (0, x)⟩, and the colon module N :R2 I we
were originally interested in equals ⟨(1, 0), (0, ε)⟩.
For the computation of colon modules in the general case, we have again
the choice between reductions to the case of principal ideals and a direct
method. As we saw before, it is enough to treat submodules of P r .
Proposition 3.2.22. (Computation of Colon Modules)
Let M = ⟨g1, . . . , gs⟩and N = ⟨h1, . . . , ht⟩be two P -submodules of P r, let
G = (g1, . . . , gs), let H = (h1, . . . , ht), and let I ⊆P be an ideal generated
by a set of polynomials {f1, . . . , fℓ}.
a) We may compute N :M I by using Lemma 3.2.20 and the formula
N :M I =
ℓ\
i=1
N :M (fi)
b) Consider the following block matrix of size rℓ× (s + ℓt)
M =





f1G
H
0
· · ·
0
f2G
0
H
...
...
...
...
...
...
0
fℓG
0
· · ·
0
H






3.2 Elementary Operations on Modules
171
Let {v1, . . . , vu} ⊆P s+ℓt be a system of generators of the syzygy module
Syz(M). We write vj = (f1j, . . . , fsj, f (1)
1j , . . . f (1)
tj , . . . . . . , f (ℓ)
1j , . . . , f (ℓ)
tj )
with f1j, . . . , f (ℓ)
tj ∈P for j = 1, . . . , u. Then we have
N :M I = ⟨
sP
i=1
fijgi | j = 1, . . . , u⟩
Proof.
Part a) follows directly from the deﬁnitions. Therefore we prove
claim b). Let w1, . . . , ws, w(1)
1 , . . . , w(1)
t , . . . . . . , w(ℓ)
1 , . . . , w(ℓ)
t
be the column
vectors of M. We have Ps
i=1 fijwi = −Pℓ
m=1(Pt
i=1 f (m)
ij
w(m)
i
) for every
j = 1, . . . , u. If we consider the kth batch of t components of this equation,
we see that fk(Ps
i=1 fijgi) = Pt
i=1 f (k)
ij hi for j = 1, . . . , u and k = 1, . . . , ℓ.
Hence we get Ps
i=1 fijgi ∈N :M I for j = 1, . . . , u.
Conversely, let v = Ps
i=1 aigi ∈N :M I with a1, . . . , as ∈P . Then
there exist polynomials a11, . . . , atℓ∈P such that fkv = Pt
i=1 aikhi for
k = 1, . . . , ℓ. By combining these equations into a vector equation, we get
a1w1+· · ·+asws−(a11w(1)
1 +· · ·+at1w(1)
t
+· · · · · ·+a1ℓw(ℓ)
1 +· · ·+atℓw(ℓ)
t ) = 0
Therefore there exist polynomials p1, . . . , pu ∈P such that the column vec-
tor given by (a1, . . . , as, −a11, . . . , −at1, . . . . . . , −a1ℓ, . . . , −atℓ)tr is equal to
Pu
j=1 pjvj . The ﬁrst s components of this equality yield the claim.
□
The previous propositions provide us with a way to check whether a given
sequence of polynomials is a regular sequence for a given ﬁnitely generated
P -module. Regular sequences are deﬁned as follows.
Deﬁnition 3.2.23. Let R be a ring and U an R-module.
a) An element f ∈R is called a non-zerodivisor for U if f ·m = 0 implies
m = 0 for all m ∈U .
b) A sequence of elements f1, . . . , fℓ∈R is called a regular sequence
for U or an U -regular sequence if we have (f1, . . . , fℓ)U ̸= U and
if fi is a non-zerodivisor for U/(f1, . . . , fi−1)U for i = 1, . . . , ℓ.
The deﬁnition of a non-zerodivisor for U obviously generalizes the one
given for U = R in Section 1.1. If the ring R in this deﬁnition is our poly-
nomial ring P , two polynomials f, g ∈P \ {0} form a P -regular sequence
if and only if they are coprime. For three polynomials in P , the question
whether they form a P -regular sequence may depend on their order (see
Tutorial 33.b).
Now let U be a ﬁnitely generated P -module. In order to check whether
a given sequence of polynomials is a regular sequence for U , we can choose
a presentation U ∼= P r/N and apply the following corollary.

172
3. First Applications
Corollary 3.2.24. (Regular Sequence Test)
Let M = ⟨g1, . . . , gs⟩be a P -submodule of P r, let N be a P -submodule of M,
and let f1, . . . , fℓ∈P . For j = 0, . . . , ℓ, we deﬁne Nj = (f1, . . . , fj)M + N .
Then the following conditions are equivalent.
a) The sequence f1, . . . , fℓis a regular sequence for M/N .
b) There exists an index i ∈{1, . . . , s} such that gi /∈Nℓ, and we have
Nj−1 :M (fj) ⊆Nj−1 for j = 1, . . . , ℓ.
c) Let σ be a module term ordering on Tn⟨e1, . . . , er⟩. For j = 1, . . . , ℓ,
we let {hj1, . . . , hjuj} be a system of generators of Nj−1 :M (fj). Then
there exists an index i ∈{1, . . . , s} such that NFσ,Nℓ(gi) ̸= 0, and we
have NFσ,Nj−1(hj1) = · · · = NFσ,Nj−1(hjuj) = 0 for j = 1, . . . , ℓ.
Proof.
The equivalence of a) and b) is an immediate consequence of the
deﬁnition if we use U = M/N and observe that (f1, . . . , fj)U = Nj/N and
U/(f1, . . . , fj)U = M/Nj . The equivalence of b) and c) follows from the
Submodule Membership Test 2.4.10.
□
The following example gives a non-trivial case of three polynomials
f1, f2, f3 ∈P which do not form a regular sequence.
Example 3.2.25. In the ring P = K[x1, x2, x3, x4], consider f1 = x2x4−x2
3 ,
f2 = x1x4 −x2x3 , and f3 = x1x3 −x2
2 . We want to use the corollary to check
whether f1, f2, f3 is a regular sequence for P .
The ideal (f1, f2, f3) is proper, so only the conditions on the colon ideals
have to be checked. Clearly, any two of the three polynomials are coprime,
and thus form a regular sequence. The computation of (f1, f2) :P (f3) yields
(x3, x4). Neither of the two elements x3, x4 is contained in (f1, f2). Therefore
f1, f2, f3 is not a regular sequence for P .
Exercise 1. In this exercise we anticipate a theme which will be discussed
more thoroughly in Chapter IV. Let K be a ﬁeld, let P = K[x1], and let
f, g ∈P \ {0}. In P = K[x0, x1], we consider the homogenizations
F = xdeg(f)
0
· f( x1
x0 ) and G = xdeg(g)
0
· g( x1
x0 ). Show that
gcd(f, g) = gcd(F, G)|x0=1
Deduce an algorithm which ﬁnds gcd(f, g) by computing the elements of
degree ≤deg(f) + deg(g) of a Gr¨obner basis of the ideal (F, G).
Hint: First show that x0 does not divide the homogenization of any poly-
nomial and that the homogenization of a product is the product of the
homogenizations.
Exercise 2. Let P = K[x1, . . . , xn] be a polynomial ring over a ﬁeld K ,
let σ be a term ordering on Tn , and let f, g ∈P be such that LTσ(f)
and LTσ(g) are coprime. Show that f and g are coprime.

3.2 Elementary Operations on Modules
173
Exercise 3. Let P = K[x1, . . . , xn] be a polynomial ring over a ﬁeld K ,
and let r ≥3. Find r non-zero submodules M1, . . . , Mr of P r such that
Mi ∩Mj ̸= 0 for 1 ≤i < j ≤s and ∩r
i=1Mi = 0.
Exercise 4.
Let R be a ring, and let M , N , as well as U be three
P -submodules of a given R-module. Assume that M ⊇N or M ⊇U .
Then prove the modular law
M ∩(N + U) = M ∩N + M ∩U
Exercise 5. Let R be a ring, let a, I , and J be ideals of R, and let S
be the residue class ring S = R/a. Denote by I and J the ideals of S
generated by the images of I and J , respectively. Prove that
I ∩J = ((I + a) ∩(J + a))/a
Exercise 6. Let P = K[x1, . . . , xn] be a polynomial ring over a ﬁeld K ,
and let M = ⟨g1, . . . , gs⟩and N = ⟨h1, . . . , ht⟩be two P -submodules
of P r . Prove that the following conditions are equivalent.
a) N ⊆M
b) There exists a matrix A =
` B
It
´
over P , where B is of size s × t and
It is the identity matrix of size t × t, such that the columns of A
generate the module Syz(g1, . . . , gs, h1, . . . , ht).
Exercise 7. Let R be a ring, and let I, J, I1, I2, . . . , In be ideals in R.
Prove the following rules for colon ideals.
a) (I :R J) · J ⊆I
b) (I1 :R I2) :R I3 = (I1 :R I3) :R I2
c) (I1 :R I2) :R I3 = I1 :R (I2I3)
d) (I1 ∩· · · ∩In) :R J = (I1 :R J) ∩· · · ∩(In :R J)
e) I :R (I1 + · · · + In) = (I :R I1) ∩· · · ∩(I :R In)
Exercise 8. Let p and q be prime ideals in a ring R such that q is not
contained in p. Show that (p ∩q) :R q = p.
Exercise 9. Let P = K[x1, . . . , xn] be a polynomial ring over a ﬁeld K ,
and let a, b, c, d ∈P \ {0}. Prove that the following conditions are equiv-
alent.
a) ⟨(a, b)⟩:P ⟨(c, d)⟩̸= 0
b) ad = bc
Exercise 10. Let K be a ﬁeld, let P = K[x1, . . . , xn], let r ≥1, and
let M be a P -submodule of P r with a system of generators of the form
{fg1, . . . , fgs}, where f ∈P and g1, . . . , gs ∈P r \ {0}.
a) Show that M :P r (f) = ⟨g1, . . . , gs⟩.
b) Now let r = 1 and g′
i = gi/ gcd(g1, . . . , gs) for i = 1, . . . , s. Prove
that (g1, . . . , gs) :P (gcd(g1, . . . , gs)) = (g′
1, . . . , g′
s).
Exercise 11. Triples of integers (a, b, c) ∈Z3 \ {(0, 0, 0)} satisfying the
equation a2 + b2 = c2 are called Pythagorean triples. A Pythagorean
triple (a, b, c) is called fundamental if gcd(a, b, c) = 1. A Pythagorean
triple (a, b, c) is called positive if (a, b, c) ∈N3 \ {(0, 0, 0)}.

174
3. First Applications
a) Prove that fundamental Pythagorean triples are in 1–1 correspondence
with rational points on the circle C = Z(x2 + y2 −1) ⊆Q 2 , i.e. with
points (a, b) ∈Q2 such that a2 + b2 −1 = 0.
b) Find a point on C which does not correspond to a Pythagorean triple.
Let ℓ∈Q[x, y] be a linear polynomial deﬁning a line L = Z(ℓ) ⊆Q 2
through the point P = (0, 1).
c) Prove that L intersects C in precisely one other point P ′ , unless ℓ
is a multiple of y −1.
d) Show that P ′ is a rational point of C and that its vanishing ideal is the
colon ideal (x2+y2−1, ℓ) :Q [x,y] (x, y−1) = (x2+y2−1, ℓ) :Q [x,y] (y−1).
e) Write a CoCoA function Pythagoras(. . .) which computes a speciﬁed
number of fundamental positive Pythagorean triples in the following
way.
1) Choose random numbers a, b ∈Q \ {0} and let ℓ= ax + b(y −1).
2) Compute the vanishing ideal I(P ′).
3) Determine the monic generators x −p and y −q of I(P ′).
4) Find the corresponding fundamental positive Pythagorean triple.
Tutorial 30: Computation of Intersections
The purpose of this tutorial is to implement and study the algorithms for
computing intersections of submodules of P r introduced in the ﬁrst subsec-
tion. Let K be a ﬁeld, let P = K[x1, . . . , xn], let r ≥1, let ℓ≥2, and let
M1, . . . , Mℓ⊆P r be P -submodules given by sets of vectors which generate
them.
a) Write CoCoA functions Intersect1(. . .) and Intersect2(. . .) which
compute the intersection module M1 ∩M2 using the methods of Propo-
sition 3.2.3.a and 3.2.3.b, respectively.
b) Apply your functions Intersect1(. . .) and Intersect2(. . .) to compute
the intersections of the following ideals and modules.
1) M1 = (x2y2 −x2) and M2 = (x2y + xy2) in Q[x, y]
2) M1 = (x3 + y2 −1, xy −x + 3) and M2 = (xy2 −1) in Q[x, y]
3) M1 = ⟨(x, y−z), (z, y)⟩and M2 = ⟨(z, y+1), (x, y−1)⟩in Q[x, y, z]2
4) M1 = ⟨(xy, y, x), (y2, y, x), (x, −y, −y)⟩and M2 = ⟨(0, x −y, x −y),
(x, x, x), (0, 0, x2 + x + y2 −y −2xy), (0, x2 + x, x2 + x)⟩in Q[x, y]3
c) Write CoCoA functions MultiIntersect1(. . .) and MultiIntersect2(. . .)
which compute the intersection module M1 ∩· · ·∩Mℓusing the methods
of Proposition 3.2.7.a and 3.2.7.b, respectively.
d) Apply your functions MultiIntersect1(. . .) and MultiIntersect2(. . .)
to compute the intersections of the ideals and modules given in b) and
the following additional ideals and modules.
1) M3 = (x2y −xy2)
2) M3 = (x, y) and M4 = (x −y2 + 2)

3.2 Elementary Operations on Modules
175
3) M3 = ⟨(x, y), (0, y2 −1)⟩and M4 = ⟨(xyz, 0)⟩
4) M3 = ⟨(xy, 0, 0), (x2, 0, 0), (y2, 0, 0)⟩
e) Let r = 1. Prove that if we compute a Gr¨obner basis of Syz(M) with
respect to a module term ordering of type PosTo in Proposition 3.2.3.b,
then the resulting system of generators {f11, . . . , f1u} of the intersection
ideal M1 ∩M2 is a Gr¨obner basis with respect to the term ordering To.
f) Find an example which shows that the claim of e) is not true if we use a
module term ordering of type ToPos.
g) Let R = P/I be an aﬃne K -algebra, where I is an ideal in P , and
let N1, . . . , Nℓbe R-submodules of Rr/U , where U is an R-submodule
of Rr . Suppose we are given lists of vectors in P r representing systems of
generators of N1, . . . , Nℓ. Explain how one can compute a list of vectors
in P r whose residue classes generate N1 ∩· · · ∩Nℓ.
Tutorial 31: Computation of Colon Ideals and Colon Modules
In the second and third subsection we saw a number of diﬀerent ways to com-
pute colon ideals and colon modules. In this tutorial we want to implement
those methods and compare their eﬃciency. We shall also see some useful
properties of colon ideals and study the associated primes of a module.
Let K be a ﬁeld, let P = K[x1, . . . , xn], let f ∈P , let r ≥1, and let
M = ⟨g1, . . . , gs⟩and N = ⟨h1, . . . , ht⟩be two P -submodules of P r .
a) Show that N :P M = P if and only if M ⊆N .
b) For r = 1, show that N :P M ⊇N . Find ideals N ⊂M ⊂P such that
N :P M = N .
c) Using the two methods of Proposition 3.2.15, write two CoCoA functions
ColonI1(. . .) and ColonI2(. . .) which take the tuples G = (g1, . . . , gs)
and H = (h1, . . . , ht) and compute the colon ideal N :P M .
d) Apply your functions ColonI1(. . .) and ColonI2(. . .) in the following
cases.
1) M = (x4, x3z, x2z2, xz3, z4) and N = (x4z4, x3yz3, x2y2z2, xy3z, y4)
in P = Q[x, y, z]
2) M = (x−1, y −1, z −1)5 and N = (x+y +z −3)3 in P = Q[x, y, z]
3) M = (x−1, y−1, z−1)2∩(x, y, z) and N = (x, y, z) in P = Q[x, y, z]
4) M = ⟨(x, y), (y, x)⟩and N = ⟨(x2, y2)⟩in P 2 = Q[x, y]2
Which function tends to be faster?
In what follows, we let R be a Noetherian ring and U a non-zero ﬁnitely
generated R-module. A prime ideal of R is called an associated prime
of U if it is the annihilator of a cyclic R-submodule of U .
e) Show that there always exists an associated prime of U .
Hint: Prove that the set of ideals {AnnR(u) | u ∈U \{0}} has a maximal
element with respect to inclusion and that this maximal element is a
prime ideal.

176
3. First Applications
f) Prove that the union of the associated primes of U is precisely the set of
zerodivisors for this module.
g) Prove that there are only ﬁnitely many associated primes of U .
Hint: First show that there exists a chain of R-submodules 0 = U0 ⊆
U1 ⊆· · · ⊆Uℓ= U such that Ui/Ui−1 ∼= R/pi with a prime ideal
pi ⊆R for i = 1, . . . , ℓ. Then prove that the associated primes of U are
contained in {p1, . . . , pℓ}.
h) In the following cases, try to use your function ColonI1(. . .) to ﬁnd an
associated prime p of the P -module P r/M and an element v ∈P r/M
such that p = AnnP (v). Can you ﬁnd all associated primes in each case?
1) M = (x3 + 3x2y + y2 + y, y2 + 2x + y) in P = Q[x, y]
2) M = ⟨(y2 −2y + 1, z2), (xz, yz −z)⟩in P 2 = Q[x, y, z]2
i) Implement the diﬀerent methods for computing N :M (I), where I
is an ideal in P , which derive from Proposition 3.2.22 and Proposi-
tion 3.2.7.a in three CoCoA functions ColonM1(. . .) and ColonM2(. . .)
and ColonM3(. . .). Apply your functions in the following cases. Which
function tends to be faster?
1) P = Q[x, y, z], N = ⟨(x, y), (y, xy)⟩, M = ⟨(xy, yz)⟩, I = (x2, y2).
Hint: The result is ⟨(x3y −xy3, x2yz −y3z)⟩.
2) P
= Q[x, y, z], N = ⟨(x2, xy, y2), (y2, yz, z2)⟩, M = ⟨(x, 0, 0),
(y, 0, 0)⟩, I = (x, y, z).
3) P = Q[x, y, z], N = ⟨(x2, xy, y2), (y2, yz, z2), (x2, xz, z2)⟩, M =
⟨(x, 0, 0), (0, y, 0), (0, 0, z)⟩, I = (x, y, z).

3.3 Homomorphisms of Modules
177
3.3 Homomorphisms of Modules
The four seasons are salt, pepper, mustard, and vinegar.
(from “Kids Say the Darndest Things”)
In this section we dish up two courses: our ﬁrst subsection gives a brief
outline of computational linear algebra, and the second makes an initial step
into the realm of computational homological algebra. As in the previous sec-
tion, our recipe will be to reduce all computational tasks to calculations of
syzygy modules.
For starters, we treat the standard fare of linear algebra. We consider
the problem of computing presentations for the kernels and images of linear
maps between modules (see Proposition 3.3.1). Then we add a little spice
by discussing liftings along linear maps (see Proposition 3.3.6). This topic
gives us a foretaste of more advanced applications such as pullbacks (see also
Tutorial 32), inductive and projective limits, and maps between complexes.
In the second part of this section we try to cook up a recipe for calculat-
ing Hom-modules. More precisely, we observe that the set of homomorphisms
between two ﬁnitely generated modules carries a natural module structure
itself, and we aim to ﬁnd a presentation of this module. We need a number of
reﬁned ingredients, each of which merits careful sampling: ﬂattening isomor-
phisms (see Proposition 3.3.9), explicit descriptions of the functoriality of the
covariant and the contravariant Hom-functors (see Proposition 3.3.13), and
some exactness properties of those Hom-functors (see Proposition 3.3.14).
Finally, we can serve up the resulting algorithm for computing a presen-
tation of a Hom-module (see Theorem 3.3.15) which reduces this task to the
calculation of the kernel of a linear map. This second part of the section is
more diﬃcult to digest, not so much because the matter is deeper, but rather
because the complexity of the objects makes the reading more challenging.
Although it is peppered by healthy tidbits of knowledge for your further
mathematical life, there is no great harm in skipping it at ﬁrst reading, since
in the rest of this volume we do not make further use of it.
As usual, in order to perform eﬀective computations we have to assume
certain ﬁniteness conditions. As in preceding sections, it turns out that the
appropriate generality we can deal with is the theory of ﬁnitely generated
modules over aﬃne K -algebras over a ﬁeld K . However, we still have a choice
as to how to represent such modules. We could consider only submodules of
ﬁnitely generated free modules over a polynomial ring P = K[x1, . . . , xn].
Or we could consider modules given by subquotients, i.e. by residue class
modules of submodules of ﬁnitely generated free modules over P , and so on.
The best choice, in our opinion, is to present the theory for quotients of
ﬁnitely generated free modules over P , i.e. for modules of the form P r/M ,
where M is a P -submodule of P r . The reason goes back to Corollary 3.2.6
where we saw how to ﬁnd such a presentation for an arbitrary subquotient.
In Remark 3.3.3 we give hints on how to deal with some other situations.

178
3. First Applications
For the remainder of this section, we let K be a ﬁeld, P = K[x1, . . . , xn]
a polynomial ring over K , and R = P/I an aﬃne K -algebra. Given two
ﬁnitely generated R-modules, we write them as P r/M and P s/N , where
r, s > 0 and M ⊆P r as well as N ⊆P s are P -submodules. In this section,
to avoid overburdening the notation, we denote the canonical basis of P a by
{e1, . . . , ea}.
3.3.A
Kernels, Images, and Liftings of Linear Maps
Our ﬁrst goal is to show how one can compute presentations of the kernel
and the image of a P -linear map ϕ : P r/M −→P s/N . To this end, we write
ϕ(ej + M) = wj + N
where wj = (f1j, . . . , fsj) and fij ∈P for i = 1, . . . , s and j = 1, . . . , r.
Furthermore, let {g1, . . . , gα} be a system of generators of M , and let
{h1, . . . , hβ} be a system of generators of N .
Proposition 3.3.1. (Kernels and Images of Linear Maps)
Let ϕ : P r/M −→P s/N be a P -linear map as above, and let {v1, . . . , vu}
be a system of generators of the syzygy module Syz(w1, . . . , wr, h1, . . . , hβ).
For j = 1, . . . , u, we write those syzygies as vj = (k1j, . . . , kr+β j) with
k1j, . . . , kr+β j ∈P .
a) The kernel of ϕ is given by Ker(ϕ) = ⟨(k1j, . . . , krj)+M | j = 1, . . . , u⟩.
b) A presentation of the image of ϕ is given by the exact sequence
P u
ψ
−→P r
ϕ◦π
−→Im(ϕ) −→0
where ψ is deﬁned by ψ(ej) = (k1j, . . . , krj) for j = 1, . . . , u, and where
π : P r −↠P r/M is the canonical homomorphism.
c) Let {(ℓ1j, . . . , ℓu+α j) | j = 1, . . . , u′} be a system of generators of the
module Syz(ψ(e1), . . . , ψ(eu), g1, . . . , gα), where ℓ1j, . . . , ℓu+α j ∈P for
j = 1, . . . , u′ . Then a presentation of the kernel of ϕ is given by the exact
sequence
P u′
ψ′
−→P u
π◦ψ
−→Ker(ϕ) −→0
where ψ′ is deﬁned by ψ′(ej) = (ℓ1j, . . . , ℓuj) for j = 1, . . . , u′ .
Proof.
To prove a), we note that ϕ is induced by the map λ : P r −→P s
which is given by λ(ej) = wj for j = 1, . . . , r. Thus Ker(ϕ) is the image
of λ−1(N) in P r/M , and the claim follows from Lemma 3.2.2.
The same result yields claim b), because Ker(ϕ◦π) = λ−1(N), as we can
see from the commutative diagram
P r
λ
−→
P s
yπ
y
P r/M
ϕ
−→
P s/N

3.3 Homomorphisms of Modules
179
Finally, we note that claim a) says that Ker(ϕ) is the image of the map
π ◦ψ : P u −→P r/M . Then claim c) follows by applying b) to this map.
□
Let us illustrate the results of this proposition with a concrete example.
Example 3.3.2. Consider the ring P = Q[x, y] and the two P -submodules
M = ⟨(x, −y −1, 0)⟩of P 3 and N = ⟨(x2, 0), (0, x3), (y, 0), (0, y)⟩of P 2 .
The P -linear map ϕ′ : P 3 −→P 2/N deﬁned by ϕ′(e1) = (xy, y + 1) + N ,
ϕ′(e2) = (x2, x) + N , and ϕ′(e3) = (y, 1) + N vanishes on M , because
ϕ′(x, −y −1, 0) = x(xy, y + 1) −(y + 1)(x2, x) + N = (−x2, 0) + N = 0 + N .
Hence ϕ′ induces a P -linear map ϕ : P 3/M −→P 2/N .
In order to ﬁnd the kernel of ϕ, we have to compute the syzygy mod-
ule Syz((xy, y + 1),
(x2, x),
(y, 1),
(x2, 0),
(0, x3),
(y, 0),
(0, y)). We
get the system of generators {(0, 0, −y, 0, 0, y, 1), (1, 0, −1, 0, 0, −x + 1, −1),
(0, 1, −x, −1, 0, x, 0), (x, −y, −x, 0, 0, x, 0), (0, 0, −x3, 0, 1, x3, 0)}. Therefore
Ker(ϕ) is generated by {(0, 0, −y) + M , (1, 0, −1) + M , (0, 1, −x) + M ,
(x, −y, −x) + M , (0, 0, −x3) + M}, and Im(ϕ) has a presentation of the
form P 5 −→P 3 −→Im(ϕ) −→0.
To get a presentation of Ker(ϕ), we have to compute the syzygy module
Syz((0, 0, −y), (1, 0, −1), (0, 1, −x), (x, −y, −x), (0, 0, −x3), (x, −y −1, 0)).
We get the system of generators {(0, 0, −1, 1, 0, −1), (−x, −x, y, 1, 0, 0),
(0, x3, −x2y, −x2, y, 0)}. Notice that the second generator means that our
system of generators of Ker(ϕ) can be shortened. By part c) of the propo-
sition, Ker(ϕ) has a presentation of the form P 3
ψ′
−→P 5 −→Ker(ϕ) −→0,
where ψ′(e1) = (0, 0, −1, 1, 0), ψ′(e2) = (−x, −x, y, 1, 0), and ψ′(e3) =
(0, x3, −x2y, −x2, y).
The proposition above is often applied in slightly modiﬁed ways to com-
pute various operations involving homomorphisms of modules. Here we men-
tion just two of them and leave it to the imagination of the reader to ﬁnd
more.
Remark 3.3.3. Let ϕ : P r/M −→P s/N be a P -linear map as above, and
let U ⊆P s be a further P -submodule which contains N and is generated
by vectors {u1, . . . , uγ} ⊆P s .
a) A presentation of the preimage ϕ−1(U/N) of U/N under the homomor-
phism ϕ can be computed by applying Proposition 3.3.1.c to ﬁnd a pre-
sentation of the kernel of the composite map P r/M
ϕ
−→P s/N −↠P s/U ,
where the second homomorphism is the canonical homomorphism.
b) Suppose we want to ﬁnd the kernel of a P -linear map ϕ : U −→P s/N ,
where U = ⟨u1, . . . , ur⟩is an explicitly given P -submodule of a ﬁnitely
generated free P -module. We can compute the kernel of the P -linear
map ψ : P r −→P s/N deﬁned by ψ(ei) = ϕ(ui) for i = 1, . . . , r. Then
Ker(ϕ) is the image of Ker(ψ) under the canonical map P r −↠U .

180
3. First Applications
Besides being able to compute presentations of the kernel and the image
of a linear map, we need one more ingredient which enables us to treat most
linear algebra questions about ﬁnitely generated modules: we need to be able
to lift a map from a free P -module to an arbitrary ﬁnitely generated module
along a homomorphism to that module. More generally, liftings along linear
maps are deﬁned as follows.
Deﬁnition 3.3.4. Let R be a ring, let U , V , and W be R-modules, let
µ : V −→W be an R-linear map, and let ψ : U −→W be another R-linear
map which satisﬁes Im(ψ) ⊆Im(µ). Then a lifting of ψ along µ is an
R-linear map λ : U −→V such that ψ = µ ◦λ.
In other words, the map λ is a lifting of ψ along µ if it makes the following
diagram commutative.
V
W
U
-
?
¡
¡
¡
¡
ª µ
ψ
λ
Proposition 3.3.5. (Existence of a Lifting Along a Linear Map)
Let R be a ring, let t ≥1, let V and W be R-modules, let µ : V −→W
be an R-linear map, and let ψ : Rt −→W be another R-linear map which
satisﬁes Im(ψ) ⊆Im(µ). Then there exists a lifting of ψ along µ.
Proof.
Let {e1, . . . , et} be the canonical basis of Rt, and let wi = ψ(ei) for
i = 1, . . . , t. The assumption that Im(ψ) ⊆Im(µ) implies that there exist
v1, . . . , vt ∈V such that µ(vi) = wi for i = 1, . . . , t. Then it suﬃces to deﬁne
the R-linear map λ : Rt −→V by λ(ei) = vi for i = 1, . . . , t.
□
In the case of a linear map ϕ : P r/M −→P s/N as above, we can compute
a lifting along ϕ explicitly. The main ingredient to solve this task is our
method to deal with explicit membership, as explained in Corollary 3.1.9.a.
Proposition 3.3.6. (Computation of a Lifting Along a Linear Map)
Let ϕ : P r/M −→P s/N be a P -linear map as above and ψ : P t −→P s/N
another P -linear map which satisﬁes Im(ψ) ⊆Im(ϕ). Let ψ be given by
ψ(ei) = pi + N for i = 1, . . . , t, where p1, . . . , pt ∈P s.
Using Explicit Membership 3.1.9.a, we can compute a matrix B = (bij)
of polynomials such that (p1, . . . , pt) = (w1, . . . , wr, h1, . . . , hβ) · B. Then the
P -linear map λ : P t −→P r/M deﬁned by ej 7−→b1je1 + · · · + brjer + M
for j = 1, . . . , t is a lifting of ψ along ϕ.
Proof.
First of all, the assumption Im(ψ) ⊆Im(ϕ) implies pi ∈⟨w1, . . . , wr,
h1, . . . , hβ⟩. Therefore we can use Corollary 3.1.9.a and get a matrix B with

3.3 Homomorphisms of Modules
181
the required property. Since we know that ψ(ej) = pj + N for j = 1, . . . , t,
we can check that
(ϕ ◦λ)(ej) = ϕ(b1je1 + · · · + brjer + M) = b1jw1 + · · · + brjwr + N = pj + N
for j = 1, . . . , t. Thus we see that ψ = ϕ ◦λ, as was claimed.
□
Let us do an explicit computation of a lifting using the map introduced
in Example 3.3.2.
Example 3.3.7. Consider the map ϕ : P 3/M −→P 2/N deﬁned in Ex-
ample 3.3.2, and let ψ : P −→P 2/N be the P -linear map deﬁned by
ψ(1) = (x3 + y2, 2x2) + N . This map satisﬁes Im(ψ) ⊆Im(ϕ), because we
can use Explicit Membership 3.1.9.a to ﬁnd a representation (x3 +y2, 2x2) =
x(x2, x) + (x2 + y)(y, 1) −x2(y, 0) −(0, y).
In particular, we see that ψ(1) + N = xϕ(e2) + (x2 + y)ϕ(e3) + N . Hence
the map λ : P −→P 3/M deﬁned by λ(1) = (0, x, x2 + y) + M is a lifting
of ψ along ϕ.
3.3.B
Hom-Modules
Pesto a-a zeneise.
(Genueser Delikatesse)
After having computed the most important objects associated to one
module homomorphism, we now want to describe HomP (P r/M, P s/N), the
module of all P -linear maps ϕ : P r/M −→P s/N . Recall that for two
such homomorphisms ϕ and ψ, and for f ∈P , the module structure of
HomP (P r/M, P s/N) is given by
(ϕ+ψ)(v +M) = ϕ(v +M)+ψ(v +M)
and
(f ·ϕ)(v +M) = f ·ϕ(v +M)
for all v ∈P r . Our goal is to describe HomP (P r/M, P s/N) by generators
and relations, i.e. to compute an explicit presentation.
As a ﬁrst step, we treat the easiest case M = ⟨0⟩and N = ⟨0⟩. In this
situation, there is clearly an isomorphism HomP (P r, P s) −→P rs , and our
only task is to make it explicit. Given r, s > 0, we denote by Mats,r(P)
the set of matrices with s rows, r columns, and entries in P . Using compo-
nentwise sum and multiplication by a polynomial, Mats,r(P) has a natural
P -module structure. The next deﬁnition recalls the well-known way to asso-
ciate a matrix to a linear map and provides the other ingredient for solving
the ﬁrst step.

182
3. First Applications
Deﬁnition 3.3.8. Let r and s be positive integers.
a) Given a P -module homomorphism ϕ ∈HomP (P r, P s), let ϕ(ej) =
(a1j, . . . , asj) for j = 1, . . . , r, and let Aϕ = (aij) ∈Mats,r(P). This
construction yields a map
Λr,s : HomP (P r, P s) −→Mats,r(P)
We say that Aϕ = Λr,s(ϕ) = (ϕ(e1), . . . , ϕ(er)) is the matrix associ-
ated to ϕ.
b) The map Fls,r : Mats,r(P) −→P rs which sends a matrix A = (aij)
to the vector (a11, a21, . . . , as1, a12, a22, . . . , as2, . . . . . . , a1r, a2r, . . . , asr)
is clearly an isomorphism of P -modules. It is called a ﬂattening iso-
morphism.
Recall that, given two P -linear maps ϕ : P r −→P s and ψ : P s −→P t,
the matrix associated to their composition is the product of their associated
matrices, i.e. we have Λr,t(ψ ◦ϕ) = Λs,t(ψ) · Λr,s(ϕ). By combining the two
maps Λr,s and Fls,r , we obtain the desired explicit representation of the
Hom-module HomP (P r, P s).
Proposition 3.3.9. Let r and s be positive integers.
a) The P -linear map map Λr,s : HomP (P r, P s) −→Mats,r(P) is an iso-
morphism.
b) The P -linear map Φr,s = Fls,r ◦Λr,s : HomP (P r, P s) −→P rs is an
isomorphism.
Proof.
Since we have already noticed that Fls,r is an isomorphism, it suﬃces
to prove a). The fact that the map Λr,s is a P -module homomorphism comes
from the very deﬁnitions. If Λr,s(ϕ) is the zero matrix, then ϕ(ej) = 0 for
j = 1, . . . , r, and thus ϕ is the zero map. Given a matrix A ∈Mats,r(P), we
deﬁne a map ϕ ∈HomP (P r, P s) by ϕ(ej) = (a1j, . . . , asj) for j = 1, . . . , r.
Clearly, we have A = Λr,s(ϕ) which concludes the proof.
□
Our next goal is to understand better how the isomorphisms Φr,s behave
when we compose them with maps which are deﬁned using the functoriality
of the Hom-module. The Hom-module is functorial in its two arguments in
the following sense.
Deﬁnition 3.3.10. Let R be a ring, and let U , V , and W be R-modules.
a) For every R-linear map ϕ : U −→V , we introduce a corresponding
R-linear map ϕ∗: HomR(V, W) −→HomR(U, W) by ϕ∗(λ) = λ ◦ϕ for
all λ ∈HomR(V, W). We denote it by ϕ∗= HomR(ϕ, W) and say that
HomR(—, W) is the contravariant Hom-functor.
b) For every R-linear map ψ : V −→W , we introduce a corresponding
R-linear map ψ∗: HomR(U, V ) −→HomR(U, W) by ψ∗(λ) = ψ ◦λ for
all λ ∈HomR(U, V ). We denote it by ψ∗= HomR(U, ψ) and say that
HomR(U, —) is the covariant Hom-functor.

3.3 Homomorphisms of Modules
183
Given P -linear maps ϕ : P r −→P r′ and ψ : P s −→P s′ , we can apply
the above isomorphisms Φi,j to both ends of the homomorphisms ϕ∗=
HomP (ϕ, P s) and ψ∗= HomP (P r, ψ). Then there are P -linear maps eϕ and
eψ such that the diagrams
HomP (P r′, P s)
ϕ∗
−→
HomP (P r, P s)
yΦr′,s
yΦr,s
P r′s
eϕ
−→
P rs
and
HomP (P r, P s)
ψ∗
−→
HomP (P r, P s′)
yΦr,s
yΦr,s′
P rs
e
ψ
−→
P rs′
are commutative. In other words, we let eϕ = Φr,s ◦ϕ∗◦(Φr′,s)−1 and eψ =
Φr,s′ ◦ψ∗◦(Φr,s)−1 . In order to ﬁnd the matrices associated to eϕ and eψ, we
proceed in two steps.
Remark 3.3.11. Given P -linear maps ϕ : P r −→P r′ and ψ : P s −→P s′ ,
let ϕ∗= HomP (ϕ, P s) and ψ∗= HomP (P r, ψ). In this situation, we deﬁne
a P -linear map ϕ : Mats,r′(P) −→Mats,r(P) by right multiplication
by Aϕ , i.e. by ϕ(B) = B · Aϕ for every B ∈Mats,r′(P).
Furthermore, we deﬁne a P -linear map ψ : Mats,r(P) −→Mats′,r(P) by
left multiplication by Aψ , i.e. by ψ(B) = Aψ · B for every B ∈Mats,r(P).
Then we have two diagrams
HomP (P r′, P s)
ϕ∗
−→
HomP (P r, P s)
yΛr′,s
yΛr,s
Mats,r′(P)
ϕ
−→
Mats,r(P)
and
HomP (P r, P s)
ψ∗
−→
HomP (P r, P s′)
yΛr,s
yΛr,s′
Mats,r(P)
ψ
−→
Mats′,r(P)
Both of these diagrams are commutative, because the matrix associated to a
composition of two linear maps is the product of the two matrices associated
to the individual maps.
Now we are going to make the second step, namely the explicit construc-
tion of the commutative diagrams involving ϕ and eϕ resp. ψ and eψ. The
necessary matrices are deﬁned as follows.

184
3. First Applications
Deﬁnition 3.3.12. Let A = (aij) ∈Matr,r′(P) and B = (bij) ∈Mats,s′(P)
be two matrices over P . Then the block matrix


a11B
· · ·
a1r′B
...
...
ar1B
· · ·
arr′B


of size rs × r′s′ is called the tensor product or the outer product or the
Kronecker product of A and B, and is denoted by A ⊗B.
In linear algebra, there is the notion of the tensor product of linear maps
between vector spaces. The preceding deﬁnition is related to that notion, but
it would lead us too far away to discuss this connection. If the matrix A is
the identity matrix of size r × r, the tensor product A ⊗B is simply the
block matrix





B
0
· · ·
0
0
B
...
...
...
...
...
0
0
· · ·
0
B





Proposition 3.3.13. Let ϕ : P r −→P r′ and ψ : P s −→P s′ be P -linear
maps, let ϕ∗= HomP (ϕ, P s), and let ψ∗= HomP (P r, ψ).
a) Let ϕ be the map deﬁned by right multiplication by Aϕ , and let eϕ be the
map whose associated matrix is Atr
ϕ ⊗Is. Then we have a commutative
diagram of P -linear maps
Mats,r′(P)
ϕ
−→
Mats,r(P)
yFls,r′
yFls,r
P r′s
eϕ
−→
P rs
b) Let ψ be the map deﬁned by left multiplication by Aψ , and let eψ be the
map whose associated matrix is Ir ⊗Aψ . Then we have a commutative
diagram of P -linear maps
Mats,r(P)
ψ
−→
Mats′,r(P)
yFls,r
yFls′,r
P rs
e
ψ
−→
P rs′
Proof.
First we show claim a). Let Aϕ = (aij) ∈Matr′,r(P) be the matrix
associated to ϕ. We start with a tuple (f11, f21, . . . , fs1, . . . , f1r′, f2r′ . . . , fsr′)
in P r′s. This tuple is the image of the matrix F = (fij) under the map Fls,r′ .
By Remark 3.3.11, we have ϕ(F) = F · Aϕ , and for i = 1, . . . , s and

3.3 Homomorphisms of Modules
185
j = 1, . . . , r, the (i, j)-entry of this matrix is Pr′
k=1 fikakj . By apply-
ing the isomorphism Fls,r , we see that the image of our original tuple
(f11, f21, . . . , fsr′) under the map eϕ is
Ã
r′
P
k=1
f1kak1,
r′
P
k=1
f2kak1, . . . ,
r′
P
k=1
fskak1, . . . ,
r′
P
k=1
f1kakr,
r′
P
k=1
f2kakr, . . . ,
r′
P
k=1
fskakr
!
Using this description of eϕ, it is easy to check that its associated matrix is
indeed Atr
ϕ ⊗Is .
Now we prove claim b) in a similar fashion. Let Aψ = (aij) ∈Mats′,s(P)
be the matrix associated to ψ. Starting again with a tuple (f11, f21, . . . , fs1,
. . . , f1r, f2r, . . . , fsr) in P rs whose preimage under Fls,r is F = (fij), we
see that the (i, j)-entry of ψ(F) = Aψ · F is given by Ps
k=1 aikfkj for
i = 1, . . . , s′ and j = 1, . . . , r. Thus the image under eψ of the original tuple
is given by
³ sP
k=1
a1kfk1,
sP
k=1
a2kfk1, . . . ,
sP
k=1
as′kfk1, . . . ,
sP
k=1
a1kfkr,
sP
k=1
a2kfkr, . . . ,
sP
k=1
as′kfkr
´
Again it is easy to use this description to check that Ir ⊗Aψ is the associated
matrix of eψ.
□
To perform our computation of Hom-modules in the general case, i.e.
when M and N are not necessarily zero, we still need one more ingredient,
namely the following exactness properties of the covariant and the contravari-
ant Hom-functors.
Proposition 3.3.14. Let R be a ring, let U1
ϕ
−→U2
ψ
−→U3 −→0 be an
exact sequence of R-modules, let t ≥1, and let V be a further R-module.
a) If we let ϕ∗= HomR(Rt, ϕ) and ψ∗= HomR(Rt, ψ), then
HomR(Rt, U1)
ϕ∗
−→HomR(Rt, U2)
ψ∗
−→HomR(Rt, U3) −→0
is an exact sequence of R-modules.
b) If we let ϕ∗= HomR(ϕ, V ) and ψ∗= HomR(ψ, V ), then
0 −→HomR(U3, V )
ψ∗
−→HomR(U2, V )
ϕ∗
−→HomR(U1, V )
is an exact sequence of R-modules.
Proof.
To prove a), we ﬁrst show Im(ϕ∗) = Ker(ψ∗). For every map
λ ∈HomR(Rr, U1), we have Im(ϕ ◦λ) ⊆Im(ϕ) = Ker(ψ), and there-
fore ψ∗(ϕ∗(λ)) = ψ ◦ϕ ◦λ = 0. Conversely, if we are given an element
λ ∈Ker(ψ∗), then ψ ◦λ = 0 implies Im(λ) ⊆Ker(ψ) = Im(ϕ). By Propo-
sition 3.3.5, it follows that there exists a map λ′ ∈HomR(Rt, U1) such that
λ = ϕ ◦λ′ = ϕ∗(λ′). Thus we get λ ∈Im(ϕ∗), as we wanted to show.

186
3. First Applications
Next we prove the surjectivity of the map ψ∗. Let {ε1, . . . , εt} denote the
canonical basis of Rt. Given a map λ ∈HomR(Rt, U3), we have λ(εi) ∈U3 =
Im(ψ) for i = 1, . . . , t. Therefore we can choose elements u1, . . . , ut ∈U2
such that λ(εi) = ψ(ui) for i = 1, . . . , t. Then we deﬁne an R-linear map
λ′ : Rt −→U2 by λ′(εi) = ui for i = 1, . . . , t. Clearly, this map λ′ satisﬁes
ψ∗(λ′) = ψ ◦λ′ = λ, and we get λ ∈Im(ψ∗), as desired.
To prove claim b), we start again by showing Im(ψ∗) = Ker(ϕ∗). For
a map λ ∈HomR(U3, V ), we have ϕ∗(ψ∗(λ)) = λ ◦ψ ◦ϕ = 0, because
ψ ◦ϕ = 0. This shows Im(ψ∗) ⊆Ker(ϕ∗). Conversely, let λ ∈Ker(ϕ∗) be
given, i.e. let λ : U2 −→V be an R-linear map such that λ ◦ϕ = 0. Then
Ker(ψ) = Im(ϕ) ⊆Ker(λ) shows that λ induces λ : U2/ Ker(ψ) −→V .
Similarly, the surjection ψ induces an isomorphism ψ : U2/ Ker(ψ) −→U3 .
Thus we obtain a map λ′ = λ ◦(ψ)−1 : U3 −→V . Now we denote the
canonical homomorphism U2 −→U2/ Ker(ψ) by ε and get from λ = λ′ ◦ψ
the desired conclusion λ = λ ◦ε = λ′ ◦ψ ◦ε = λ′ ◦ψ = ψ∗(λ′) ∈Im(ψ∗).
Finally, we show that the map ψ∗is injective. Suppose that we have
ψ∗(λ) = λ ◦ψ = 0 for some map λ ∈HomR(U3, V ). Then we obtain the
relations U3 = Im(ψ) ⊆Ker(λ) ⊆U3 which imply Ker(λ) = U3 , i.e. λ = 0,
and we are done.
□
At this point we have all the necessary ingredients for cooking up our
algorithm. After all the trouble we had to go through in this subsection in
order to arrive here, the following theorem yields an algorithm for computing
Hom-modules which is of surprising simplicity. The ﬁnal meal does not always
show the eﬀorts which went into preparing it!
Theorem 3.3.15. (Computation of Hom-Modules)
Let M = ⟨g1, . . . , gα⟩⊆P r and N = ⟨h1, . . . , hβ⟩⊆P s be two P -sub-
modules. Let G be the matrix of size r × α whose columns are g1, . . . , gα,
let H be the matrix of size s × β whose columns are h1, . . . , hβ , let U be
the P -submodule of P rs which is generated by the column vectors of the
matrix Ir ⊗H of size rs × rβ , and let V be the P -submodule of P αs which
is generated by the column vectors of the matrix Iα ⊗H of size αs × αβ .
Finally, let λ : P rs −→P αs be the P -linear map whose associated matrix
is Gtr ⊗Is.
a) The map λ satisﬁes the inclusion λ(U) ⊆V and induces a P -linear
map λ : P rs/U −→P αs/V .
b) The P -module HomP (P r/M, P s/N) is isomorphic to Ker(λ). In partic-
ular, a presentation of HomP (P r/M, P s/N) can be computed by using
Proposition 3.3.1.c to ﬁnd a presentation of the kernel of λ.
c) Let ϑ ∈HomP (P r/M, P s/N) be represented, as an element of Ker(λ),
by the residue class (a11, a21, . . . , as1, . . . . . . , ar1, ar2, . . . , ars) + U . Then
the map ϑ is induced by the P -linear map Θ : P r −→P s whose associ-
ated matrix is AΘ = (aij).

3.3 Homomorphisms of Modules
187
Proof.
First we apply Proposition 3.3.14 to the presentations
P α
ϕ
−→P r −→P r/M −→0
and
P β
ψ
−→P s −→P s/N −→0
where ϕ(ei) = gi for i = 1, . . . , α and ψ(ej) = hj for j = 1, . . . , β . We
get the following fundamental diagram (1). Its maps are deﬁned by applying
the covariant and contravariant Hom-functors to the various maps in the two
presentations. It is easy to check that this diagram is in fact commutative.
HomP (P r, P β)
−→
HomP (P α, P β)
(1)
↓
↓
HomP (P r, P s)
−→
HomP (P α, P s)
↓
↓
0 −→HomP (P r/M, P s/N) −→HomP (P r, P s/N) −→HomP (P α, P s/N)
↓
↓
0
0
In order to prove a), we need to construct four further commutative dia-
grams. By the deﬁnition of the P -linear map ϕ∗
s = HomP (ϕ, P s), we have a
commutative diagram
(2)
HomP (P r, P s)
ϕ∗
s
−→
HomP (P α, P s)
yΦr,s
yΦα,s
P rs
eϕs
−→
P αs
By Proposition 3.3.13.a, the map λ is precisely eϕs.
Similarly, by the deﬁnition of the P -linear maps (ψα)∗= HomP (P α, ψ)
and (ψr)∗= HomP (P r, ψ), we have two commutative diagrams
(3)
HomP (P α, P β)
(ψα)∗
−→HomP (P α, P s)
yΦα,β
yΦα,s
P αβ
e
ψα
−→
P αs
and (4)
HomP (P r, P β)
(ψr)∗
−→HomP (P r, P s)
yΦr,β
yΦr,s
P rβ
e
ψr
−→
P rs
Using Remark 3.3.11 and Proposition 3.3.13.b, we see that the matrices as-
sociated to the maps eψα and eψr are Iα ⊗H and Ir ⊗H, and their images
are V and U , respectively.
Finally, we let ϕ∗
β = HomP (ϕ, P β) and observe that the diagram
(5)
HomP (P r, P β)
(ψr)∗
−→
HomP (P r, P s)
yϕ∗
β
yϕ∗
s
HomP (P α, P β)
(ψα)∗
−→
HomP (P α, P s)

188
3. First Applications
is commutative, because ϕ∗
s((ψr)∗(γ)) = ψ ◦γ ◦ϕ = (ψα)∗(ϕ∗
β(γ)) for all
γ ∈HomP (P r, P β).
Now we are ready to prove claim a). Using the above diagrams, we cal-
culate
λ(U) = Im(λ ◦eψr) = Im(eϕs ◦eψr ◦Φr,β) =
(4) Im(eϕs ◦Φr,s ◦(ψr)∗)
=
(2) Im(Φα,s ◦ϕ∗
s ◦(ψr)∗) =
(5) Im(Φα,s ◦(ψα)∗◦ϕ∗
β)
=
(3) Im( eψα ◦Φα,β ◦ϕ∗
β) ⊆Im( eψα) = V
To prove b), we note that in diagram (4) both Φr,β and Φr,s are isomor-
phisms. Therefore also the induced map Φr,s between the cokernels of (ψr)∗
and eψr is an isomorphism. Similarly, we can use diagram (3) and get an
induced isomorphism Φα,s between the cokernels of (ψα)∗and eψα . Thus we
have two more commutative diagrams
(6)
HomP (P r, P s) −↠HomP (P r, P s/N)
yΦr,s
yΦr,s
P rs
−↠
P rs/U
and (7)
HomP (P α, P s) −↠HomP (P α, P s/N)
yΦα,s
yΦα,s
P αs
−↠
P αs/V
By combining diagrams (2), (6), (7), and the lower right part of the fun-
damental diagram (1), we ﬁnd that also the diagram
HomP (P r, P s/N)
Λ
−→
HomP (P α, P s/N)
yΦr,s
yΦα,s
P rs/U
λ
−→
P αs/V
is commutative, where Λ = HomP (ϕ, P s/N). Since HomP (P r/M, P s/N) is
isomorphic to the kernel of Λ by the fundamental diagram (1), and since
the two vertical maps are isomorphisms, the claim HomP (P r/M, P s/N) ∼=
Ker(λ) follows.
To prove c), we let Θ : P r −→P s be the P -linear map whose associated
matrix is AΘ = (aij). Using Deﬁnition 3.3.8.b, we see that the image of Θ
in P rs is the tuple (a11, . . . , ars). In view of diagrams (2) and (7), this implies
that the map ϑ : P r/M −→P s/N induced by Θ corresponds to the residue
class (a11, . . . , ars) + U ∈P rs/U .
□

3.3 Homomorphisms of Modules
189
To conclude this section, we compute an explicit example.
Example 3.3.16. Once more we let P = Q[x, y], and we use the P -sub-
modules M = ⟨(x, −y −1, 0)⟩of P 3 and N = ⟨(x2, 0), (0, x3), (y, 0), (0, y)⟩
of P 2 introduced in Example 3.3.2. Our goal is to compute a presentation
of HomP (P 3/M, P 2/N) using Theorem 3.3.15. In our case α = 1, r = 3,
β = 4, s = 2, G =
³
x
−y−1
0
´
, H =
³
x2
0
0
x3
y
0
0
y
´
, U is the P -submodule of P 6
generated by the columns of the matrix I3⊗H, and V is the submodule of P 2
generated by the columns of the matrix I1 ⊗H = H. Moreover, the matrix
Gtr ⊗I2 =
³
x
0
0
x
−y−1
0
0
−y−1
0
0
0
0
´
deﬁnes a P -linear map λ : P 6 −→P 2,
and it is easy to check that λ(U) ⊆V . Thus we obtain a P -linear map
λ : P 6/U −→P 2/V .
Our goal is to ﬁnd a presentation of the P -module HomP (P 3/M, P 2/N).
In view of the theorem, we can apply Proposition 3.3.1.a to compute a system
of generators of Ker(λ). We get HomP (P 3/M, P 2/N) = ⟨ϕ1, ϕ2, . . . , ϕ8⟩,
where ϕ1 corresponds to (x, 0, 0, 0, 0, 0) + U, ϕ2 to (0, x2, 0, 0, 0, 0) + U, ϕ3
to (0, 0, 0, 0, 1, 0)+U, ϕ4 to (0, 0, 0, 0, 0, 1)+U, ϕ5 to (0, 0, y, 0, 0, 0)+U, ϕ6
to (0, 0, 0, y, 0, 0)+U, ϕ7 to (1, 0, x, 0, 0, 0)+U, and ϕ8 to (0, 1, 0, x, 0, 0)+U.
Next we use Proposition 3.3.1.c and compute the presentation
P 12
µ
−→P 8
ν
−→HomP (P 3/M, P 2/N) −→0
where ν is given by ν(ei) = ϕi for i = 1, . . . , 8 and µ is associated to
Aµ =











0
0
0
0
y
x
−1
0
0
0
0
0
0
0
0
0
0
0
0
0
y
x
−1
0
y
0
0
0
0
0
0
x2
0
0
0
0
0
y
0
0
0
0
0
0
0
0
0
x3
0
0
x
0
0
0
0
0
0
0
0
0
0
0
0
x
0
0
0
0
0
0
0
0
0
0
−y
0
0
0
x
0
0
0
0
0
0
0
0
−y
0
0
0
0
0
0
x2
0











Finally, let us consider the P -linear map ϕ : P 3/M −→P 2/N deﬁned
in Example 3.3.2. It is induced by the P -linear map Φ : P 3 −→P 2
whose associated matrix is AΦ =
³
xy
y+1
x2
x
y
1
´
. By part c) of the theo-
rem, the map ϕ is represented by (xy, y + 1, x2, x, y, 1) + U as an element
of Ker(λ). Using Explicit Membership 3.1.9.a, we can ﬁnd the representa-
tion ϕ = (y −1)ϕ1 + yϕ3 + ϕ4 −xϕ6 + xϕ7 + (y + 1)ϕ8 of ϕ in terms of the
generators of HomP (P 3/M, P 2/N).

190
3. First Applications
Exercise 1. Let P = K[x1, . . . , xn] be a polynomial ring over a ﬁeld K ,
and let ϕ : P r/M −→P s/N be a P -linear map as in Subsection 3.3.A. Ex-
plain how one can compute a presentation of Coker(ϕ) = (P s/N)/ Im(ϕ).
Exercise 2. Let K be a ﬁeld, let P = K[x, y], let f = x + y −1, and
let I = (y(y −1), f) ⊆P . Compute the kernel of the multiplication map
µf : P/I2 −→P/I2 deﬁned by g + I2 7→fg + I2 .
Exercise 3. Let P = K[x, y, z] be a polynomial ring over a ﬁeld K , and
let a, b ∈N such that b ≥a. Prove that multiplication by xb−ayb−azb−a
yields a well-deﬁned P -linear map ϕ : P/(xa, ya, za) −→P/(xb, yb, zb)
and that ϕ is injective.
Exercise 4. Let P = K[x, y] be a polynomial ring in two indeterminates
over a ﬁeld K , let G = (x, y), and let I be the ideal generated by {x, y}.
a) Show that there is no P -linear map ϕ : I −→P such that we have
ϕ(fx + gy) = f for all f, g ∈P .
b) Use a presentation of I to prove that HomP (I, P) ∼= ⟨(x, y)⟩⊆P 2 .
c) Find a non-trivial P -linear map ϕ : I −→P .
Exercise 5. Let R be a ring, let I be an ideal in R, and let M be an
R-module. Prove that HomR(R/I, M) ∼= 0 :M I .
Exercise 6.
Let R be a ring, let M and N be R-modules, and let
ϕ : M −→N be an R-linear map. The map
ϕˇ = HomR(ϕ, R) : HomR(N, R) −→HomR(M, R)
is called the dual map of ϕ.
a) Given an exact sequence 0 −→M ′
ϕ
−→M
ψ
−→M ′′ −→0 of R-mod-
ules, show that the dual sequence
0 −→HomR(M ′′, R)
ψˇ
−→HomR(M, R)
ϕˇ
−→HomR(M ′, R)
is exact. Give an example in which the map ϕˇ is not surjective.
b) Prove that the map ϕˇ in a) is surjective if there exists an R-linear
map ϱ : M ′′ −→M such that ψ ◦ϱ = idM′′ .
c) Let K be a ﬁeld, let P = K[x1, . . . , xn], and let ϕ : P r −→P s .
What is the matrix associated to the composition of P -linear maps
P s Φ−1
s,1
−→HomP (P s, P)
ϕˇ
−→HomP (P r, P)
Φr,1
−→P r ?
Exercise 7. Let R be a ring, and let M be an R-module. Show that
the following conditions are equivalent.
a) Given R-modules U and V and R-linear maps ϕ : U −→V and
ψ : M −→V such that Im(ψ) ⊆Im(ϕ), there always exists a lifting
of ψ along ϕ.
b) Given R-modules U and V and an R-linear map ϕ : U −→V which
is surjective, the map HomR(M, ϕ) : HomR(M, U) −→HomR(M, V )
is also surjective.
c) For every surjective R-linear map π : V −→M , there is an R-linear
map ψ : M −→V such that π ◦ψ = idM .
d) There exists a free R-module U and an R-submodule V ⊆U such
that U ∼= V ⊕M .

3.3 Homomorphisms of Modules
191
A module M satisfying these conditions is called a projective module.
Clearly, free R-modules are projective modules. (Hint: To prove that c)
implies d), use the surjective map ⊕m∈MR · em −→M given by em 7→m
for all m ∈M .)
Exercise 8.
Let R be a ring, let 0 −→U1
ϕ
−→U2
ψ
−→U3 be an exact
sequence of R-modules, and let V be a further R-module. For the maps
ϕ∗= HomR(V, ϕ) and ψ∗= HomR(V, ψ), show that
0 −→HomR(V, U1)
ϕ∗
−→HomR(V, U2)
ψ∗
−→HomR(V, U3)
is an exact sequence of R-modules.
Tutorial 32: Computing Kernels and Pullbacks
Most of the computations presented in the previous sections can be considered
as special cases of computations of kernels of certain module homomorphisms.
The purpose of this tutorial is to study some concrete instances of this general
phenomenon.
We start with the situation introduced at the beginning of this section.
In particular, we let M = ⟨g1, . . . , gα⟩⊆P r and N = ⟨h1, . . . , hβ⟩⊆P s be
two P -submodules and ϕ : P r/M −→P s/N a P -module homomorphism.
a) Implement the algorithms of Proposition 3.3.1 for the computation of
generators of Ker(ϕ) and presentations of Im(ϕ) and Ker(ϕ) in CoCoA
functions KernelGens(. . .), ImagePres(. . .), and KernelPres(. . .), re-
spectively.
b) Apply your functions from a) to compute the kernels and images of the
following homomorphisms ϕ : P r/M −→P s/N , where P = Q[x, y, z],
r = 3, M = ⟨(−x, −y, 1)⟩, s = 2, and N = ⟨(x, y), (y, z), (z, x)⟩. (Notice
that ϕ(e3 + M) is determined uniquely by ϕ(e1 + M) and ϕ(e2 + M).)
1) ϕ(e1 + M) = (1, x2 + xy + y2) + N , ϕ(e2 + M) = (xyz −1, 0) + N
2) ϕ(e1 + M) = (x3 −z −1, y3 −z −1) + N , ϕ(e2 + M) = (1, 1) + N
3) ϕ(e1 + M) = (x −1, y −1) + N , ϕ(e2 + M) = (y −1, z −1) + N
c) Let R be a ring, let M1 , M2 , and M3 be three R-modules, and let
ϕ1 : M1 −→M3 and ϕ2 : M2 −→M3 be two R-linear maps. Show that
there exists an R-module N with the following properties.
1) There are R-linear maps ψ1 : N −→M1 and ψ2 : N −→M2 such
that ϕ1 ◦ψ1 = ϕ2 ◦ψ2 .
2) If N ′ is a further R-module such that there are two R-linear maps
ψ′
1 : N ′ −→M1 and ψ′
2 : N ′ −→M2 satisfying ϕ1 ◦ψ′
1 = ϕ2 ◦ψ′
2 ,
then there exists an R-linear map λ : N ′ −→N such that ψ′
1 = ψ1◦λ
and ψ′
2 = ψ2 ◦λ.

192
3. First Applications
Furthermore, this module N is unique up to a unique isomorphism of
R-modules. Together with the two maps ψ1 and ψ2 , the module N is
called the pullback of ϕ1 and ϕ2 . Property 2) is called the universal
property of the pullback.
Hint: Look at d) to get a clue how to construct the pullback.
...................................................................................................................................... ................
.....................................................................................................................................
................
......................................................................................................................................
................
...................................................................................................................................... ................
......................................................................................................................................................................................................................................................................................
................
...................................................................................................................................................................................................................................................................................... ................
............................ ................
............. ............. ............. ............. .............
M2
M3
N
M1
N ′
ϕ1
ψ2
ψ1
ϕ2
ψ′
2
ψ′
1
λ
d) Prove that, given two P -linear maps ϕ1 : P k −→P r and ϕ2 : P l −→P r
between ﬁnitely generated free P -modules, the pullback of ϕ1 and ϕ2
can be computed as the kernel of the P -linear map ψ : P k+l −→P r
deﬁned by ψ((f1, . . . , fk+l)) = ϕ1((f1, . . . , fk)) −ϕ2((fk+1, . . . , fk+l)).
e) Write a CoCoA function Pullback(. . .) which takes two matrices over P
having the same number of rows and computes the pullback of the two
P -linear maps deﬁned by those matrices.
f) Show that the intersection M ∩N can be computed using the pullback
of the maps λ : P α −→P r given by λ(ei) = gi for i = 1, . . . , α and
µ : P β −→P r given by µ(ei) = hi for i = 1, . . . , β . Use your function
Pullback(. . .) to compute the intersections of the submodules deﬁned in
Tutorial 30.b and compare your results with those of that tutorial.
g) Show that the annihilator of an element m + M of P r/M can be com-
puted using the pullback of the map λ and the map ν : P −→P r given
by 1 7→m.
Can you ﬁnd the annihilator AnnP (P r/M) using a single pullback com-
putation? (Hint: Look at Proposition 3.2.15.b.)
h) Show that, for a polynomial f ∈P , the colon module M :P r (f) can be
computed using the pullback of the map λ and the map δ : P r −→P r
given by ei 7→fei for i = 1, . . . , r.
Can you ﬁnd the colon module M :P r I for an ideal I ⊆P using a single
pullback computation? (Hint: Look at Proposition 3.2.22.b.)

3.3 Homomorphisms of Modules
193
Tutorial 33: The Depth of a Module
Let R be a Noetherian ring, let M be a ﬁnitely generated R-module, and
let I be an ideal in R such that IM ̸= M . Generalizing Deﬁnition 3.2.23
slightly, we shall say that a tuple of elements (f1, . . . , fℓ) ∈Rℓis called an
M -regular sequence in I if f1, . . . , fℓis a regular sequence for M and if
fi ∈I for i = 1, . . . , ℓ.
An M -regular sequence (f1, . . . , fℓ) in I is called maximal if there
is no M -regular sequence in I of the form (f1, . . . , fℓ, fℓ+1). It can be
shown that all maximal M -regular sequences in I have the same length
(cf. [Ku80], VI.3.1). This length is called the I -depth of M and is denoted
by depthI(M). In this tutorial we want to study some properties of the
I -depth of a module and ﬁnd a way to compute it.
a) Let f, g ∈R such that (f, g) is an M -regular sequence in I , and assume
that g is a non-zerodivisor for M . Then show that also (g, f) is an
M -regular sequence in I .
b) Let R = K[x, y, z] be the polynomial ring in three indeterminates over
a ﬁeld K . Prove that the tuple (x2 −x, xy −1, xz) is an R-regular
sequence in the ideal it generates, but (x2 −x, xz, xy −1) is not an
R-regular sequence in that ideal.
c) Prove that if the ideal I is contained in the union of ﬁnitely many prime
ideals of R, it is already contained in one of them.
d) Show that the following conditions are equivalent.
1) depthI(M) = 0
2) ⟨0⟩:M I ̸= ⟨0⟩
3) HomR(R/I, M) ̸= 0
Hint: Use Tutorial 31 and part c).
e) Let R = K[x1, . . . , xn] be a polynomial ring over a ﬁeld K and let M
be a ﬁnitely generated R-module given by an explicit presentation
M = Rr/⟨g1, . . . , gs⟩, where g1, . . . , gs ∈Rr . Write a CoCoA program
IsDepth0(. . .) which takes a tuple of vectors (g1, . . . , gs) and a tuple of
polynomials (f1, . . . , ft), checks whether the R-module M has I -depth
zero with respect to I = (f1, . . . , ft), and returns the corresponding
Boolean value.
Hint: Use part d) and Theorem 3.3.15.
f) Let r ≥1, and let 0 −→N −→Rr −→M −→0 be an exact sequence
of R-modules. Prove that
1) depthI(N) = depthI(M)
if depthI(R) = depthI(M), and
2) depthI(N) = depthI(M) + 1
if depthI(R) > depthI(M).
Hint: If depthI(M) > 0, then choose x ∈I which is a non-zerodivisor
for both R and M . Construct the commutative diagram

194
3. First Applications
0
−→
N
−→
Rr
−→
M
−→
0
yµx
yµx
yµx
0
−→
N
−→
Rr
−→
M
−→
0
y
y
y
N/xN
Rr/xRr
M/xM
y
y
y
0
0
0
notice that depthI(M/xM) = depthI(M) −1, and continue.
g) Let · · · F2
ϕ2
−→F1
ϕ1
−→F0
ϕ0
−→R/I −→0 be a ﬁnite free resolution of R/I ,
i.e. an exact sequence of R-modules such that F0, F1, F2, . . . are ﬁnitely
generated free R-modules, and let ϕ∗
i = HomR(ϕi, M) for i ≥0. Show
that the sequence
0 −→HomR(R/I, M)
ϕ∗
0
−→HomR(F0, M)
ϕ∗
1
−→HomR(F1, M)
ϕ∗
2
−→· · ·
is a complex, i.e. that Im(ϕ∗
i ) ⊆Ker(ϕ∗
i+1) for i ≥0.
h) In the situation of g), let Ni = Ker(ϕi) for i ≥0. For i ≥0, the
cokernel of the map HomR(Fi, M) −→HomR(Ni, M) is called the
(i + 1)st Ext-module of R/I with values in M , and is denoted by
Exti+1
R (R/I, M). Prove that Exti+1
R (R/I, M) ̸= 0 if and only if we have
Im(ϕ∗
i ) ̸= Ker(ϕ∗
i+1) in g).
i) (This part requires some knowledge of homological algebra.) For d ≥1,
prove that depthI(M) = d if and only if Exti
R(R/I, M) = 0 for 0 ≤i < d
and Extd
R(R/I, M) ̸= 0. (Here we let Ext0
R(R/I, M) = HomR(R/I, M).)
Hint: Use induction on d. Choose a non-zerodivisor x for M and apply
HomR(—, M) to the exact sequence 0 −→M
µx
−→M −→M/xM −→0.
j) Now let R = K[x1, . . . , xn] and M = Rr/⟨g1, . . . , gs⟩again. Using i),
develop an algorithm for the computation of depthI(M). Implement your
algorithm in a CoCoA function Depth(. . .).
Hint: Using Proposition 3.3.13.a, show that the map ϕ∗
i is induced by
the map whose associated matrix is Aϕi ⊗Ir under the representation
of HomR(Fi, M) given by Theorem 3.3.15.b. Then show how one can
ﬁnd a presentation of Ker(ϕ∗
i+1)/ Im(ϕ∗
i ) with the aid of Corollary 3.2.6.
k) Apply your CoCoA function Depth(. . .) in the following cases.
1) I = (x, y, z) and M = (xy −z, yz −x, xz −y) in Q[x, y, z]
2) I = (x1, x2, x3, x4) and M = (x2x3 −x1x4, x3
2 −x2
1x3, x1x2
3 −x2
2x4,
x3
3 −x2x2
4) in Q[x1, x2, x3, x4]
3) I = (x, 5y −3, 5z −4) and M = ⟨(x, y, z)⟩in Q[x, y, z]3

3.4 Elimination
195
3.4 Elimination
Eliminate, eliminate, eliminate.
Eliminate the eliminators of elimination theory.
(Shreeram S. Abhyankar)
So far in this chapter we have solved all problems by computing syzygies.
Another common feature of our approach has been that it didn’t matter
which module term ordering we chose to compute the Gr¨obner bases we
needed. Starting from now, we have to eliminate this freedom in order to
gather the additional power we need for tackling other kinds of applications
of Computational Commutative Algebra.
For instance, given an ideal I in a polynomial ring P = K[x1, . . . , xn]
over a ﬁeld K and a number j ∈{1, . . . , n −1}, we can consider the set
of all polynomials in I which involve only the indeterminates x1, . . . , xj .
This set I ∩K[x1, . . . , xj] is clearly an ideal in K[x1, . . . , xj]. It is called
the elimination ideal of I with respect to the indeterminates {xj+1, . . . , xn},
because passing from I to this ideal means eliminating all polynomials in
which one of these latter indeterminates occurs. Now the key observation is
that, for solving the problem of computing elimination ideals, we need to
compute the Gr¨obner basis of I with respect to special term orderings called
elimination orderings.
But why couldn’t we eliminate the elimination problem instead? Let us
show you a couple of examples where elimination appears naturally. Suppose
we have a hunch that there could exist a formula which expresses the area
s of a triangle in terms of the three side lengths a, b, and c. We choose a
system of coordinates in the plane such that the situation looks as follows.
................................... ................
...................................
................
x
y
(a, 0)
(x, y)
a
b
c
.............................................................................................................................................................................................................................................................................................................................................................................................................................
By Pythagoras’s Theorem, we have b2 = (a −x)2 + y2 and c2 = x2 + y2 .
Furthermore, we observe that 2s = ay. Then we construct the polynomial
ideal I = (b2−(a−x)2−y2, c2−x2−y2, 2s−ay) in the ring K[x, y, a, b, c, s].
The desired formula should be a polynomial relation among the indetermi-
nates a, b, c, s. It should arise as a consequence of the algebraic relations
coded in the ideal I . Thus it should be contained in I ∩K[a, b, c, s]. In-
deed, when we compute the elimination ideal I ∩K[a, b, c, s], we ﬁnd just
one generator which corresponds to Heron’s Formula
s2 =
1
16(a + b + c)(a + b −c)(a −b + c)(−a + b + c)

196
3. First Applications
In the second example we consider the set of all points (x, y, z) ∈A3
Q such
that
x = t3, y = t4, z = t5
for some t ∈Q
This set of points is an aﬃne variety. In the language of algebraic geometry,
it is called a parametrically deﬁned space curve. If we want an ideal I in
Q[x, y, z] such that this space curve equals ZQ(I), we have to form the larger
ideal J = (x−t3, y−t4, z−t5) in Q[x, y, z, t] and to eliminate t. The resulting
ideal I = J ∩Q[x, y, z] = (x3 −yz, y2 −xz, x2y −z2) has the space curve as
its zero set.
The remainder of this chapter will consist almost entirely of applications of
elimination. This goes a long way to show how important it is. The current
section provides the basis for those applications. Namely, we show how to
compute generators of an elimination module of a P -submodule M ⊆P r ,
i.e. of a P -module of the form M ∩K[xi | xi /∈L]r , where L is a subset of
the set of indeterminates {x1, . . . , xn} (see Theorem 3.4.5).
Then we provide the reader with an additional technique for eﬀectively
performing the elementary operations on ideals and modules discussed earlier
(see Proposition 3.4.6 and Proposition 3.4.9). This technique, sometimes also
known as the method of tag variables, will later help us solve a variety of
other problems. The geometric interpretation of elimination is that we want
to project objects which are in big spaces into smaller spaces. A discussion of
this geometric point of view will be suggested in Tutorial 39.
In the following we let K be a ﬁeld, P = K[x1, . . . , xn] a polynomial
ring , r ≥1, and M ⊆P r a P -submodule. Moreover, let L ⊆{x1, . . . , xn}
be a subset of the set of indeterminates, and let bP = K[xi | xi /∈L] be the
polynomial ring in the remaining indeterminates.
Deﬁnition 3.4.1. Let L ⊆{x1, . . . , xn} be a subset of the set of indetermi-
nates as above.
a) A module term ordering σ on Tn⟨e1, . . . , er⟩is called an elimination
ordering for L if every element m ∈P r \ {0} such that LTσ(m) ∈bP r
is contained in bP r .
b) Given a P -submodule M of P r , the bP -submodule M ∩bP r of bP r is
called the elimination module of M with respect to L.
In other words, an elimination ordering for L has the property that if the
indeterminates in L do not occur in the leading term of an element, they do
not occur in the element at all. In Section 1.4, we have already deﬁned some
kind of elimination orderings. In fact, they are a special case of elimination
orderings in the sense of the above deﬁnition.
Example 3.4.2. Let r = 1 and L = {x1, . . . , xj} for j ∈{1, . . . , n −1}.
Then the elimination ordering Elim(L) deﬁned in Example 1.4.10 is an elimi-
nation ordering for L in the sense of Deﬁnition 3.4.1.a. Namely, let f ∈P \{0}

3.4 Elimination
197
be a polynomial whose leading term satisﬁes LTElim(L)(f) ∈K[xj+1, . . . , xn].
If we write LTElim(L)(f) = xα1
1 · · · xαn
n , and if t = xβ1
1 · · · xβn
n
is any term
in Supp(f), then the deﬁnition of Elim(L) implies 0 = α1 + · · · + αj ≥
β1 + · · · + βj . Thus we obtain β1 = · · · = βj = 0, i.e. t ∈K[xj+1, . . . , xn].
Since t ∈Supp(f) was arbitrary, we ﬁnd f ∈K[xj+1, . . . , xn] as desired.
For module term orderings on Tn⟨e1, . . . , er⟩with r ≥2, examples of
elimination orderings can be obtained as follows.
Example 3.4.3. Let 1 ≤j ≤n −1, and let L = {x1, . . . , xj}. Then the
module term ordering LexPos on Tn⟨e1, . . . , er⟩is an elimination ordering
for L. To check this, we suppose a vector m ∈P r \ {0} has a leading term
such that LTLexPos(m) ∈K[xj+1, . . . , xn]r . We write LTLexPos(m) = teγ ,
where t ∈Tn and 1 ≤γ ≤r. Let t′eγ′ be an element of Supp(m), where
t′ ∈Tn and 1 ≤γ′ ≤r. By deﬁnition of LexPos, we have t ≥Lex t′ . Since
the term t does not involve x1, . . . , xj , we get t′ ∈K[xj+1, . . . , xn]. Thus we
have m ∈K[xj+1, . . . , xn]r , as we needed to show.
In particular, given j ∈{1, . . . , n −1}, this example shows that the lex-
icographic term ordering on Tn is an elimination ordering for the ﬁrst j
indeterminates (see also Proposition 1.5.10). Other kinds of elimination or-
derings on Tn⟨e1, . . . , er⟩will be studied in Tutorial 34.
Our ﬁrst goal in this section is to learn how to compute elimination mod-
ules. The following preparatory result generalizes Proposition 1.4.13.
Proposition 3.4.4. Let σ be a module ordering on Tn⟨e1, . . . , er⟩. More-
over, we let bT⟨e1, . . . , er⟩be the set of terms involving only the indeterminates
{xi | xi /∈L}.
a) The restriction ˆσ of σ to bT⟨e1, ..., er⟩is a module ordering.
b) If σ is a module term ordering, then also ˆσ is a module term ordering.
Proof.
The case L = {xi} is a straightforward generalization of Proposi-
tion 1.4.13 to Tn⟨e1, . . . , er⟩. The general case follows by repeated applica-
tion of this result.
□
After we have computed the Gr¨obner basis of M with respect to an
elimination ordering σ on Tn⟨e1, . . . , er⟩, it is easy to read oﬀa system of
generators for the corresponding elimination module. This is the essence of
the following theorem which is the main result of the current section and lies
at the heart of many applications of Computational Commutative Algebra.
Theorem 3.4.5. (Computation of Elimination Modules)
Let M be a P -submodule of P r, let L ⊆{x1, . . . , xn} be a subset of the set
of indeterminates, and let σ be an elimination ordering for L. Furthermore,
consider the polynomial subring bP = K[xi | xi /∈L] of P as well as the
restriction ˆσ of σ to the set of terms bT⟨e1, . . . , er⟩in bP r.

198
3. First Applications
a) We have LTˆσ(M ∩bP r) = LTσ(M) ∩bP r.
b) Let G be a σ-Gr¨obner basis of M , and let bG be the set of all elements
of G which are contained in bP r. Then the set bG is a ˆσ-Gr¨obner basis
of M ∩bP r.
c) Let G be the reduced σ-Gr¨obner basis of M . Then bG = G ∩bP r is the
reduced ˆσ-Gr¨obner basis of M ∩bP r.
Proof.
In a), only the inclusion “⊇” needs to be shown. Let G = {g1, . . . , gs}
be a σ-Gr¨obner basis of M . If we have tei ∈LTσ(M) for some term t ∈bP
and some i ∈{1, . . . , r}, then there exists a term t′ ∈Tn and a number
j ∈{1, . . . , s} such that tei = t′ LTσ(gj). Since t ∈bP , we also have t′ ∈bP
and LTσ(gj) ∈bP r . From the fact that σ is an elimination ordering for L,
we can then conclude gj ∈bP r , and hence t′gj ∈bP r . Thus the claim follows
from tei = t′ LTˆσ(gj) = LTˆσ(t′gj) ∈LTˆσ(M ∩bP r). Claim b) is an immediate
consequence of a), and c) follows from b).
□
Notice that we allow M = ⟨0⟩in this theorem. In this case we have
LTσ(M) = ⟨0⟩by deﬁnition, G = ∅is a σ-Gr¨obner basis of M , and bG = ∅
is a σ-Gr¨obner basis of M ∩bP r = ⟨0⟩.
As we indicated above, the preceding theorem has a number of important
applications which will be explored in the remainder of this chapter. We
begin by describing alternative ways to perform the elementary operations on
modules discussed in the previous sections. The next proposition shows how
one can compute the intersection of two submodules of P r using elimination.
Proposition 3.4.6. Let M and N be two submodules of P r, let {g1, . . . , gs}
be a system of generators of M , and let {h1, . . . , ht} be a system of generators
of N . We choose a new indeterminate y and consider the P[y]-submodule
U = ⟨yg1, . . . , ygs, (1 −y)h1, . . . , (1 −y)ht⟩
of P[y]r . Then we have M ∩N = U ∩P r .
Proof.
For v ∈M ∩N , there are polynomials p1, . . . , ps, q1, . . . , qt ∈P such
that we have v = Ps
i=1 pigi = Pt
j=1 qjhj . From this we get
v = yv+(1−y)v = p1yg1+· · ·+psygs+q1(1−y)h1+· · ·+qt(1−y)ht ∈U ∩P r
Conversely, suppose we are given a vector v ∈U ∩P r . By deﬁnition
of U , there exist polynomials p1, . . . , ps, q1, . . . , qt ∈P[y] such that we have
v = Ps
i=1 piygi + Pt
j=1 qj(1 −y)hj . Since v ∈P r, the element v is invariant
under the substitution y 7→0, i.e. we have v = Pt
i=1 q(x1, . . . , xn, 0)hi ∈N .
Similarly, the element v is invariant under the substitution y 7→1, i.e. we
have v = Ps
i=1 pi(x1, . . . , xn, 1)gi ∈M . Altogether, we get v ∈M ∩N .
□

3.4 Elimination
199
Example 3.4.7. Let us redo the computation of the intersection of (x1, x2)
and (x2
1 −x2
2, x1x2x3, x2
3 −x1) in P = K[x1, x2, x3] mentioned in Exam-
ple 3.2.4. In the polynomial ring P[y] = K[x1, x2, x3, y], we consider the
ideal U = ((1 −y)x1, (1 −y)x2, y(x2
1 −x2
2), y(x1x2x3), y(x2
3 −x1)). The
reduced Gr¨obner basis of this ideal with respect to Elim(y) is given by
{x2
1 −x2
2, x2x2
3 −x1x2, x1x2
3 −x2
2, x1x2x3, x3
2, x2y −x2, x1y −x1, x2
3y −x1}.
Since x3
2 = x3(x1x2x3)−x2(x1x2
3−x2
2), we can disregard the generator x3
2 ,
and the ideal U ∩P equals (x2
1 −x2
2, x2x2
3 −x1x2, x1x2
3 −x2
2, x1x2x3), in
agreement with the result obtained in Example 3.2.4.
A similar method can be used to compute the intersection of ℓsubmodules
M1, . . . , Mℓof P r simultaneously. In the case ℓ= 2, it yields an alternative
to the method explained in Proposition 3.4.6.
Proposition 3.4.8. Let ℓ≥2, and for every i ∈{1, . . . , ℓ} let Mi be a
P -submodule of P r which is generated by a set of vectors {gi1, . . . , gisi}.
We choose new indeterminates y1, . . . , yℓand consider the P[y1, . . . , yℓ]-sub-
module U of P[y1, . . . , yℓ]r generated by
{yigij | 1 ≤i ≤ℓ, 1 ≤j ≤si} ∪{(1 −y1 −· · · −yℓ)ei | 1 ≤i ≤r}
Then we have M1 ∩· · · ∩Mℓ= U ∩P r .
Proof.
Let v ∈M1 ∩· · · ∩Mℓ. For i = 1, . . . , ℓ, we choose fi1, . . . , fisi ∈P
such that v = fi1gi1 + · · · + fisigisi . Then we have
v = y1v + · · · + yℓv + (1 −y1 −· · · −yℓ)v
=
ℓP
i=1
si
P
j=1
fijyigij + (1 −y1 −· · · −yℓ)v
∈U ∩P r
Conversely, given a vector v ∈U ∩P r, we can write it in the form
v = Pℓ
i=1
Psi
j=1 fijyigij + Pr
k=1 hk(1 −y1 −· · · −yℓ)ek with polynomials
fij, hk ∈P[y1, . . . , yℓ]. Let i ∈{1, . . . , ℓ}. Since v ∈P r , this vector is invari-
ant under the substitution yj 7→δij for j = 1, . . . , ℓ, where δij = 0 for j ̸= i
and δii = 1. Therefore we get v = Psi
j=1 fij(x1, . . . , xn, δi1, . . . , δiℓ)gij ∈Mi
for i = 1, . . . , ℓ.
□
Finally, we indicate how one can use elimination to compute colon mod-
ules. A similar method can be used to ﬁnd the annihilator of a module (see
Exercise 11). Given a P -submodule M ⊆P r and a new indeterminate y,
we denote the P[y]-submodule of P[y]r generated by the elements of M
by MP[y].
Proposition 3.4.9. Let M and N be submodules of P r, let {g1, . . . , gs} be
a system of generators of M , and let {h1, . . . , ht} be a system of generators
of N .

200
3. First Applications
a) Given a polynomial f ∈P , we choose a new indeterminate y and
let U be the P[y]-submodule of P[y]r generated by the set of poly-
nomials {fyg1, . . . , fygs, (1 −y)h1, . . . , (1 −y)ht}. Furthermore, we let
{v1, . . . , vu} be a system of generators of the elimination module U ∩P r.
For i = 1, . . . , u, we may write vi = fwi for some wi ∈M . Then we
have
N :M (f) = ⟨w1, . . . , wu⟩
b) Given an ideal I = (f1, . . . , fℓ) in P , we choose a new indeterminate y
and consider the polynomial f(y) = f1 +f2y+· · ·+fℓyℓ−1 in P[y]. Then
we have
N :M I = (NP[y] :MP [y] (f(y))) ∩P r
Proof.
The ﬁrst claim follows by combining Lemma 3.2.20 and Proposi-
tion 3.4.6. Now we prove claim b). For a vector v ∈M satisfying fiv ∈N
for i = 1, . . . , ℓ, we obviously have f(y) v = (f1 + · · · + fℓyℓ−1)v ∈NP[y].
Conversely, let v ∈MP[y] ∩P r be such that f(y) v ∈NP[y]. Since,
clearly, MP[y] ∩P r = M , we actually have v ∈M . We consider P[y] as a
polynomial ring in one indeterminate y over the ring P and equip it with the
standard grading deg(y) = 1. Then NP[y] is a graded submodule of P[y]r ,
because it is generated by homogeneous elements of degree zero (see Proposi-
tion 1.7.10). Thus (f1 + · · · + fℓyℓ−1)v ∈NP[y] implies fiyi−1v ∈NP[y] for
i = 1, . . . , ℓ. Next we write fiyi−1v as an explicit P[y]-linear combination of
the generators {h1, . . . , ht} of NP[y] and perform the substitution y 7→1.
We obtain fiv ∈N for i = 1, . . . , ℓ. Therefore we have v ∈N :M I .
□
Example 3.4.10. In Example 3.2.16 we computed the colon ideal I :P J in
the ring Q[x1, x2, x3], where I = (x3
2−x2
2x3−x1x2+x1x3, x1x2
2x3+x2
2x2
3−x3
1+
x1x2
2 −x2
1x3 + x2
2x3 −x1x2
3 −x2
1, x2
2x3
3 −x2
1x2x3 −x1x3
3 + x3
1 −x2
2x3 + x2x2
3)
and J = (x2 −x3, x2
1 −x3). Let us redo this computation with our new
technique. We consider the ring P[y] = K[x1, x2, x3, y] and form the ideal
IP[y] and the polynomial f(y) = (x2 −x3) + (x2
1 −x3)y. Then we compute
IP[y] :P [y] (f(y)) using CoCoA and get a number of polynomials which are
already contained in P and generate I .
In the following example we show a subtle feature of Proposition 3.4.9.b.
Namely, we show that the inclusion (N :M I)P[y] ⊆NP[y] :MP [y] (f(y)) can
be strict even in the case where M = P r . This contradicts a claim in [Ei95],
Exercise 15.41.b.
Example 3.4.11. Over the polynomial ring P = Z/(101)[x1, x2, x3, x4], we
consider the ideals J = (x1x3, x2x4, x1x4+x2x3) and I = (x3, x4). We claim
that (J :P I)P[y] ⊂JP[y] :P [y] (x3 + x4y). If we compute J :P I with one of
the above methods, we get J :P I = (x1x2, x2
1, x1x3, x1x4, x2
2, x2x3, x2x4).
On the other hand, JP[y] :P [y] (x3 + x4y) = (x1x2, x2
1, x1x3, x1x4, x2
2, x2x3,
x2x4, x2y + x1). Clearly, the polynomial x2y + x1 is not contained in the
ideal (J :P I)P[y].

3.4 Elimination
201
Exercise 1. Consider the polynomial ring P = K[x, y] over a ﬁeld K .
Prove that the only elimination ordering for L = {x} is Lex.
Exercise 2. Consider the polynomial ring P = K[x, y, z] over a ﬁeld K .
Describe at least two diﬀerent elimination orderings for L = {z}.
Exercise 3.
Let {x1, . . . , xn} be a set of indeterminates, and let
L ⊆{x1, . . . , xn}. Find a matrix V ∈Matn(Z) such that Ord(V ) is an
elimination ordering for L on Tn .
Exercise 4. Let P = K[x1, . . . , xn] be a polynomial ring over a ﬁeld K
and I = (f) a principal ideal in P generated by a polynomial f ∈P \{0}.
Moreover, let L ⊆{x1, . . . , xn}, and let bP = K[xi | xi /∈L]. Show that
we have I ∩bP = (0) if and only if f /∈bP .
Exercise 5. Let K be a ﬁeld, let P = K[x1, . . . , xn], let t1, . . . , ts ∈Tn
be terms such that t1 >Lex t2 >Lex · · · >Lex ts , and let I be the ideal in P
generated by {t1, . . . , ts}. Prove that we have I ∩K[xn] = (0) if and only
if ts /∈K[xn].
Exercise 6.
Let P
= K[x1, . . . , xn] be a polynomial ring over a
ﬁeld K , and let M be the P -submodule of P n generated by {g1, . . . , gn},
where g1 = (x1, x2, . . . , xn), where g2 = (xn, x1, . . . , xn−1), . . ., and where
gn = (x2, x3, . . . , xn, x1). Show that M ∩K[x2, . . . , xn]n = (0).
Exercise 7. Let P = K[x1, . . . , xn] be a polynomial ring over a ﬁeld K ,
let L ⊆{x1, . . . , xn}, and let
bP = K[xi | xi /∈L]. Furthermore, let
I = (f1, . . . , fr) be an ideal in P , and let A be the aﬃne K -algebra P/I .
Finally, let B be a residue class ring of bP such that the inclusion bP ⊆P
induces an injective K -algebra homomorphism ϕ : B −→A.
bP
,−→
P
???y
???y
B
,−→
A = P/I
Explain how one can compute a set of generators of an ideal J in bP such
that B is isomorphic to bP/J .
Exercise 8. Let I be an ideal in a polynomial ring P = K[x, y1, . . . , yn]
over a ﬁeld K , and assume that I ∩K[x] ̸= (0). Let σ be an elimination
ordering for {y1, . . . , yn}, and let G be the reduced σ-Gr¨obner basis of I .
a) Show that G ∩K[x] consists of a single polynomial, say f .
b) Prove that if I is a prime ideal, then f is irreducible.
Exercise 9. Use CoCoA to prove Heron’s Formula.
Exercise 10. Use CoCoA to ﬁnd the equations vanishing at the following
parametrically deﬁned curves.
a) {(t3, t4, t5) | t ∈Q}
b) {(t, t2, t3) | t ∈Q} (This is called the twisted cubic curve.)
c) {(
3t
t3+1,
3t2
t3+1) | t ∈Q} (This is called the folium of Descartes.)

202
3. First Applications
Exercise 11. Let P = K[x1, . . . , xn] be a polynomial ring over a ﬁeld K ,
let r ≥1, let M be a P -submodule of P r , let {g1, . . . , gs} ⊆P r be a
system of generators of M , and let v ∈P r . We choose a new indeter-
minate y and consider the P[y]-submodule U = ⟨yg1, . . . , ygs, (1 −y)v⟩
of P[y]r . Show that every element of a system of generators {h1, . . . , ht}
of the elimination module U ∩P r is of the form hi = fiv with fi ∈P
for i = 1, . . . , t, and that the annihilator of the cyclic submodule ⟨v + M⟩
of P r/M is the ideal (f1, . . . , ft).
Tutorial 34: Elimination of Module Components
In this section we studied module term orderings which had the property that
if the leading term of an element did not involve certain indeterminates, then
the whole element did not contain those indeterminates. Suppose we could
consider also the canonical basis vectors e1, . . . , er as “indeterminates”. Then
we could deﬁne a diﬀerent kind of elimination ordering, namely one having
the property that if the leading term of an element does not involve certain ei ,
then the whole element does not contain a multiple of one of those ei in its
support.
More precisely, we introduce the following notion. Let P = K[x1, . . . , xn]
be a polynomial ring over a ﬁeld K , let r ≥1, and let M ⊆P r be a
P -submodule which is generated by a tuple G = (g1, . . . , gs) of vectors
in P r . Moreover, let σ be a module term ordering on Tn⟨e1, . . . , er⟩, and let
L ⊆{1, . . . , r}. The module term ordering σ is called a component
elimination ordering for L if every element m ∈P r \ {0} such that
LTσ(m) ∈L
i∈{1,...,r}\L Pei is contained in L
i∈{1,...,r}\L Pei . The mod-
ule M ∩L
i∈{1,...,r}\L Pei is called the component elimination module
of M with respect to L.
In this tutorial we want to study component elimination orderings and
show some of their applications. In particular, we shall see that they allow
us to compute various operations in yet another way. For practical purposes,
the methods explained here tend to be among the most eﬃcient ones.
a) Let To be a term ordering on Tn , let i ∈{1, . . . , r}, and let L be the set
{1, . . . , i}. Show that the module term ordering PosTo on Tn⟨e1, . . . , er⟩
(see Example 1.4.16.b) is a component elimination ordering for L.
b) State and prove a result for the restriction of σ to Tn⟨ei | i /∈L⟩which
is analogous to Proposition 3.4.4.
c) Prove the following version of Theorem 3.4.5 for component elimination
orderings.
Let c
P r = L
i∈{1,...,r}\L Pei , and let ˆσ be the restriction of σ to the
monomodule of terms in c
P r .
a) We have LTˆσ(M ∩c
P r) = LTσ(M) ∩c
P r .

3.4 Elimination
203
b) For a σ-Gr¨obner basis G of M , the set bG = G∩c
P r is a ˆσ-Gr¨obner
basis of the component elimination module M ∩c
P r .
Hint: Use the canonical basis vectors e1, . . . , er as indeterminates (see
Exercise 10 in Section 1.4).
c) Consider the following block matrix of size (r + s) × s.
U =
µ
G
Is
¶
Let U be the P -submodule of P r+s generated by the columns of
U , let L = {1, . . . , r}, and let σ be a module term ordering on
Tn⟨e1, . . . , er, er+1, . . . , er+s⟩which is a component elimination ordering
for L. Show that
U ∩(
r+s
L
i=r+1
Pei) ∼= SyzP (G)
Hint: Consider a σ-Gr¨obner basis of U . Show that one can read oﬀa
σ-Gr¨obner basis of M and a σ-Gr¨obner basis of SyzP (G).
d) Write a CoCoA function CompElimSyz(. . .) which takes the tuple G and
uses the preceding method to compute a system of generators of the
module SyzP (G). Apply your function to compute Gr¨obner bases of the
syzygy modules of the following tuples with respect to PosDegRevLex
and PosLex.
1) G = (x2, xy + y2) in Q[x, y]2
2) G = ((x2, x −y), (0, y), (xy, z)) in (Q[x, y, z]2)3
3) G = ((xy + y, x), (x −y, y), (x, x + y), (−x, y)) in (Q[x, y]2)4
e) Let N be another P -submodule of P r , and let H = (h1, . . . , ht) be a
tuple of vectors which generate N . Consider the following block matrix
of size 2r × (s + t).
V =
µ
G
H
0
H
¶
Let V be the P -submodule of P 2r generated by the columns of V , let
L = {1, . . . , r}, and let σ be a module term ordering on Tn⟨e1, . . . , e2r⟩
which is a component elimination ordering for L. Show that
V ∩(
2r
L
i=r+1
Pei) ∼= M ∩N
Hint: Consider a σ-Gr¨obner basis of V . Show that one can read oﬀa
σ-Gr¨obner basis of M + N and a σ-Gr¨obner basis of M ∩N .
f) Implement a CoCoA function CompElimIntersection(. . .) which takes
tuples G and H generating P -submodules M and N of P r and uses the
preceding method to compute a system of generators of the intersection
module M ∩N . Apply your function to compute the Gr¨obner bases
of the intersection modules asked for in Tutorial 30.b with respect to
PosDegRevLex and PosLex.

204
3. First Applications
g) Given a vector v ∈P r, consider the following block matrix W of size
(r + 1) × (s + 1).
W =
µ
G
v
0
1
¶
Let W be the P -submodule of P r+1 generated by the columns of W ,
let L be the set {1, . . . , r}, and let σ be a module term ordering on
Tn⟨e1, . . . , er, er+1⟩which is a component elimination ordering for L.
Show that
W ∩Per+1 ∼= M :P ⟨v⟩
Hint: Consider a σ-Gr¨obner basis of W . Show that one can read oﬀa
σ-Gr¨obner basis of M + ⟨v⟩and a σ-Gr¨obner basis of M :P ⟨v⟩.
h) Write a CoCoA function CompElimColon(. . .) which takes the tuple G and
a vector v ∈P r and uses the preceding method to compute a system of
generators of the colon ideal M :P ⟨v⟩. Apply your function to compute
Gr¨obner bases with respect to PosDegRevLex and PosLex of the colon
ideals corresponding to the following cases (see Tutorial 31.d).
1) G is a system of generators of the ideal (x −1, y −1, z −1)5 and
v = (x + y + z −3)3 in Q[x, y, z]
2) G is a system of generators of the ideal (x−1, y −1, z −1)2 ∩(x, y, z)
and v = x in Q[x, y, z]
3) G = ((x, y), (y, x)) and v = (x2, y2) in Q[x, y]2
Tutorial 35: Projective Spaces and Graßmannians
In algebraic geometry, frequently a certain set of objects corresponds one-
to-one to the set of points of another object. Some of the most important
examples for this phenomenon will be introduced in this tutorial.
Let K be a ﬁeld and V be a non-zero ﬁnite-dimensional K -vector space.
For v, v′ ∈V \ {0}, we let v ∼v′ if and only if there exists an element
λ ∈K \ {0} such that v = λv′ . It is easy to check that the relation ∼is an
equivalence relation. The set (V \ {0})/ ∼of its equivalence classes will be
called the projective space associated to V and will be denoted by P(V ).
In the special case V = Kn+1 , we shall also say that P(V ) is called the
n-dimensional projective space over K , and we shall denote it by P n
K .
The equivalence class of an element in V
is called a point in P(V ). If
(p0, . . . , pn+1) ∈Kn+1 \ {0}, then the point of P n
K deﬁned by its equiva-
lence class will be denoted by (p0 : . . . : pn).
The set of equivalence classes of the non-zero elements of a 2-dimensional
vector subspace of V will be called a line in P(V ), and the set of equivalence
classes of non-zero elements of an (dim(V ) −1)-dimensional vector subspace
of V will be called a hyperplane in P(V ).

3.4 Elimination
205
a) Show that there is a bijection between P(V ) and the set of 1-dimensional
K -vector subspaces of V .
b) For every hyperplane H ⊆P n
K , ﬁnd a tuple (a0, . . . , an) ∈Kn+1 \ {0}
such that H is the set of all points (p0 : . . . : pn) ∈P n
K which satisfy
a0p0 + · · · + anpn = 0. (First note that this condition is well-deﬁned.)
Moreover, prove that two tuples (a0, . . . , an) and (b0, . . . , bn) give rise
to the same hyperplane H ⊆P n
K in this way if and only if there exists
an element λ ∈K \ {0} such that (a0, . . . , an) = λ · (b0, . . . , bn).
c) Prove that any two distinct lines in P2
K meet at a unique point.
d) Let Hyp(P n
K) be the set of all hyperplanes of P n
K . Show that one can
deﬁne a map η : Hyp(P n
K) −→P n
K by using b) to map H to the point
(a0 : . . . : an). Prove that the map η is bijective. Thus we can view the
set Hyp(P n
K) as an n-dimensional projective space over K . It is called
the dual projective space and sometimes denoted by (P n
K)ˇ.
e) Show that the set of all elements of (P n
K)ˇ which correspond to hyper-
planes passing through the point (0 : . . . : 0 : 1) is a hyperplane in (P n
K)ˇ.
f) Let p be a prime number and K = Fp . Write a CoCoA function
Hyperplanes(. . .) which takes a point (p0 : . . . : pn) ∈P n
K and com-
putes the list of all tuples (a0, . . . , an) ∈Kn+1 which correspond to the
hyperplanes passing through the point.
g) Use your CoCoA function Hyperplanes(. . .) to compute the lines passing
through each of the following points P ∈P2
K , where K = F3 .
1) P = (0 : 0 : 1)
2) P = (0 : 1 : 1)
3) P = (1 : 1 : 1)
After having seen that the set of 1-dimensional K -vector subspaces
of Kn+1 can be identiﬁed with the set of points of the n-dimensional projec-
tive space over K , we now turn our attention to the set of (m+1)-dimensional
K -vector subspaces of Kn+1 , where 1 ≤m < n. We start with the ﬁrst non-
trivial case m = 1 and n = 3.
h) Explain how one can identify the set of all 2-dimensional K -vector sub-
spaces of K4 with the set Lin(P3
K) of lines in P3
K .
i) Now we deﬁne a map
ϕ : Lin(P3
K) −→P5
K
as follows. Let {e1, . . . , e4} be the canonical basis of K4 . Every line
L ∈Lin(P3
K) corresponds to a 2-dimensional vector subspace V of K4 .
We choose a K -basis of V and represent it as a 4 × 2-matrix
V =



a11
a12
a21
a22
a31
a32
a41
a42




206
3. First Applications
with entries in K . Then we form the 6-tuple (d12, d13, d14, d23, d24, d34) of
the 2 × 2-minors of V . Each minor is speciﬁed by choosing two rows, i.e.
by a pair of indices (i, j) such that 1 ≤i < j ≤4. We order the minors by
ordering the pairs of indices decreasingly with respect to the lexicographic
ordering on N2 . Finally, we let ϕ(L) = (d12 : d13 : d14 : d23 : d24 : d34).
Prove that the map ϕ is well-deﬁned and injective. The image of the
map ϕ is called the Graßmannian of lines in P3
K and is denoted
by Grass1(P3
K).
Hint: Show that we can assume d12 ̸= 0 without loss of generality. Then
prove that there exists a basis of V such that the corresponding matrix
has the shape
V′ =



1
0
0
1
a31
a32
a41
a42



j) Show how one can extend the preceding results in order to deﬁne the
Graßmannian Grassm(P n
K) of m-dimensional subspaces of P n
K for ev-
ery m ∈{1, . . . , n −1}.
Hint: For every (m+1)-dimensional K -vector subspace of Kn+1 , there
exists a basis such that its associated matrix has the shape
V =












1
0
· · ·
0
0
1
...
...
...
...
...
0
0
· · ·
0
1
am+2 1
am+2 2
· · ·
am+2 m+1
...
...
...
an+1 1
an+1 2
· · ·
an+1 m+1












The (m+1) × (m+1)-minors of such a matrix are speciﬁed by the tuples
(i1, . . . , im+1) of indices of chosen rows, where we assume that these
indices are ordered by 1 ≤i1 < · · · < im+1 ≤n + 1. Again we order
those tuples decreasingly with respect to Lex and get an injective map
of the set of (m+1)-dimensional K -vector subspaces of Kn+1 to PN
K ,
where N =
¡ n+1
m+1
¢
−1.
The ﬁnal part of this tutorial is devoted to describing the Graßmannian
Grassm(P n
K) in more detail. In Volume 2 we shall introduce the notion of a
projective variety as the set of zeros of a homogeneous ideal. In fact, Graß-
mannians are projective varieties. For the time being, we shall be content
with ﬁnding some equations which vanish on the points of Grassm(P n
K). This
amounts to ﬁnding algebraic relations among the (m+1) × (m+1)-minors of
an (n+1) × (m+1)-matrix.
k) Let us consider again the case m = 1 and n = 3. Show that the minors
of size 2 × 2 of the matrix V′ above are algebraically related by the

3.4 Elimination
207
polynomial equation
d12d34 −d13d24 + d14d23 = 0
l) Still in the case m = 1 and n = 3, consider the 2×2-minors d12, . . . , d34
of the original matrix V . In order to ﬁnd the algebraic relations among
these minors, we form the polynomial ring
P = K[d12, d13, d14, d23, d24, d34, a11, a21, a31, a41, a12, a22, a32, a42]
in 14 indeterminates over K . Deﬁne a suitable ideal I ⊆P such that
the elimination ideal I ∩K[d12, d13, d14, d23, d24, d34] is the desired ideal
of algebraic relations. Write a CoCoA function which computes this elim-
ination ideal, and show that it is principal.
m) More generally, for any m ∈{1, . . . , n}, the ideal of algebraic relations
among the minors of size (m+1) × (m+1) of a matrix V = (aij) of
size (n+1)×(m+1) is called the ideal of Pl¨ucker relations. Implement
a CoCoA function Pluecker(. . .) which takes m and n as input and
computes a set of generators for the ideal of Pl¨ucker relations.
Hint: Assume that the base ring has
¡ n+1
m+1
¢
indeterminates. Then form
a larger polynomial ring having
¡ n+1
m+1
¢
+ (m+1)(n+1) indeterminates,
apply the CoCoA command Minors(. . .) appropriately, and transport the
result of your computation back to the original ring using a suitable ring
map.
Tutorial 36: Diophantine Systems and Integer Programming
Let A = (aij) ∈Matm,n(Z) be a matrix having m rows, n columns, and
integer entries. Furthermore, let (b1, . . . , bm) ∈Zm be a vector having m
integer entries, and let z1, . . . , zn be indeterminates. Our ﬁrst goal in this
tutorial is to study the set of non-negative integer solutions of the following
system of Diophantine inequalities.







a11z1 + a12z2 + · · · + a1nzn
≤
b1
a21z1 + a22z2 + · · · + a2nzn
≤
b2
...
...
...
am1z1 + am2z2 + · · · + amnzn
≤
bm
a) As a ﬁrst step, we convert the above system of inequalities into a sys-
tem of equations in the following way. We introduce new indeterminates
zn+1, . . . , zn+m and consider the associated system of Diophantine
equations







a11z1 + a12z2 + · · · + a1nzn + zn+1
=
b1
a21z1 + a22z2 + · · · + a2nzn + zn+2
=
b2
...
...
...
am1z1 + am2z2 + · · · + amnzn + zn+m
=
bm

208
3. First Applications
Prove that there is a one-to-one correspondence between the set of all so-
lutions (α1, . . . , αn) ∈Nn of the above system of Diophantine inequalities
and the set of non-negative integer solutions (α1, . . . , αn, αn+1, . . . , αn+m)
in Nn+m of the associated system of Diophantine equations.
In view of this result, we shall from now on assume that our original
system is in fact a system of Diophantine equations, i.e. that we want to ﬁnd
the non-negative integer solutions (α1, . . . , αn) ∈Nn of the system







a11z1 + a12z2 + · · · + a1nzn
=
b1
a21z1 + a22z2 + · · · + a2nzn
=
b2
...
...
...
am1z1 + am2z2 + · · · + amnzn
=
bm
which we shall denote by S .
For our next step in the solution process, we need some additional def-
initions. Let y1, . . . , ym be further indeterminates. A product of the form
yi1
1 · · · yim
m , where we have (i1, . . . , im) ∈Zm , is called an extended term in
the indeterminates y1, . . . , ym. The set of all extended terms will be denoted
by Em. It is clearly a monoid with respect to multiplication.
Now let K be a ﬁeld. An expression of the form
f =
P
(i1,...,im)∈Zm c(i1,...,im) yi1
1 · · · yim
m
where only ﬁnitely many elements c(i1,...,im) ∈K are diﬀerent from zero,
is called a Laurent polynomial in the indeterminates y1, . . . , ym. The set
of all Laurent polynomials is clearly a K -algebra and will be denoted by
L = K[y1, . . . , ym, y−1
1 , . . . , y−1
m ].
b) Prove that the map log : Em −→Zm deﬁned by yi1
1 · · · yim
m 7→(i1, . . . , im)
is an isomorphism of groups.
c) Prove that a tuple (α1, . . . , αn) ∈Nn is a solution of S if and only if the
following equations hold in L.









ya11α1+a12α2+···+a1nαn
1
=
yb1
1
ya21α1+a22α2+···+a2nαn
2
=
yb2
2
...
...
...
yam1α1+am2α2+···+amnαn
m
=
ybm
m
d) Prove that a tuple (α1, . . . , αn) ∈Nn is a solution of S if and only if the
following equation holds in L.
ya11α1+a12α2+···+a1nαn
1
· · · yam1α1+am2α2+···+amnαn
m
= yb1
1 · · · ybm
m
e) For i = 1, . . . , n, we deﬁne the extended term ti = ya1i
1 ya2i
2
· · · yami
m
.
(Notice that its exponents correspond to the ith column of the matrix A.)

3.4 Elimination
209
Prove that a tuple (α1, . . . , αn) ∈Nn is a solution of S if and only if the
following equation holds in L.
tα1
1 · · · tαn
n
= yb1
1 · · · ybm
m
Conclude that there exists a solution of S in Nn if and only if the
extended term yb1
1 · · · ybm
m is an element of the K -subalgebra K[t1, . . . , tn]
of L.
In the second part of this tutorial, we try to apply the knowledge acquired
above for solving the integer programming problem in a special case. For
this, we shall from now on assume that the entries of the matrix A and the
vector b = (b1, . . . , bm) are non-negative integers. Moreover, we suppose that
we are given a non-zero tuple (c1, . . . , cn) ∈Nn of natural numbers.
The map C : Nn −→N deﬁned by (α1, . . . , αn) 7→c1α1 + · · · + cnαn
is called the linear cost function associated to (c1, . . . , cn). The integer
programming problem IP(A, b, C) asks for those solutions of the system S
for which the cost function C is minimal.
In the sequel, let {x1, . . . , xn} be new indeterminates, let Q be the ring
Q = K[x1, . . . , xn, y1, . . . , ym], let J = (x1 −t1, . . . , xn −tn) ⊆Q, and let σ
be an elimination ordering for {y1, . . . , ym} on T(x1, . . . , xn, y1, . . . , ym).
f) Show that NFσ,J(yb1
1 · · · ybm
m ) is a term (see Exercise 5 of Section 2.5).
g) Prove that (α1, . . . , αn) ∈Nn is a solution of S if and only if the poly-
nomial yb1
1 · · · ybm
m −xα1
1 · · · xαn
n
is contained in J .
Hint: Show that tα1
1 · · · tαn
n
≡xα1
1 tα2
2 · · · tαn
n
≡· · · ≡xα1
1 · · · xαn
n
mod-
ulo J .
h) Prove that the system S has solutions if and only if NFσ,J(yb1
1 · · · ybm
m )
is contained in the subring K[x1, . . . , xn] of Q.
i) Write a CoCoA function IsSolvable(. . .) which takes A and (b1, . . . , bm)
and decides whether the corresponding system S is solvable.
j) Use your function IsSolvable(. . .) to check whether the following sys-
tems of Diophantine equations are solvable.
1)


3
1
11
2
3
4
5
0
1
7
5
6
1
9
2




x1
...
x5

=


20
17
23


2)


3
1
11
2
3
4
5
0
1
7
5
6
1
9
2




x1
...
x5

=


20
17
21


3)


3
1
11
2
3
5
3
4
5
0
1
7
4
6
5
6
1
9
2
3
3




x1
...
x7

=


31
27
38



210
3. First Applications
k) Implement a CoCoA function DioSysSolve(. . .) which takes a matrix A
and a tuple (b1, . . . , bm) such that the corresponding system S is solvable
and uses the above results to ﬁnd a solution of S .
l) Use your function DioSysSolve(. . .) to ﬁnd explicit solutions for those
systems of Diophantine equations above which are solvable.
m) Find an elimination ordering σ for the set of indeterminates {y1, . . . , ym}
on T(x1, . . . , xn, y1, . . . , ym) such that the restriction ˆσ of σ to the
monoid of terms T(x1, . . . , xn) is cost compatible. By this we mean
that ˆσ has the property that whenever C(α1, . . . , αn) ≥C(β1, . . . , βn)
for two tuples (α1, . . . , αn), (β1, . . . , βn) ∈Nn , then we have the inequal-
ity xα1
1 · · · xαn
n
≥ˆσ xβ1
1 · · · xβn
n .
n) Write a CoCoA function CcOrd(. . .) which takes (c1, . . . , cn) ∈Nn \ {0}
and computes a matrix V ∈Matm+n(Z) such that the associated term
ordering Ord(V ) is an elimination ordering for {y1, . . . , ym} whose re-
striction to T(x1, . . . , xn) is cost-compatible.
o) Let σ be an elimination ordering for {y1, . . . , ym} whose restriction to
T(x1, . . . , xn) is cost-compatible. Assume that the system S has solu-
tions, i.e. that there exist numbers α1, . . . , αn ∈N such that we have
xα1
1 · · · xαn
n
= NFσ,J(yb1
1 · · · ybm
m ). Then show that
C(α1, . . . , αn) = min{C(β1, . . . , βn)|(β1, . . . , βn) ∈Nn is a solution of S}
In other words, the tuple (α1, . . . , αn) is a solution of the integer pro-
gramming problem IP(A, b, C).
p) Write a CoCoA function IPSolve(. . .) which takes A, (b1, . . . , bm), and
(c1, . . . , cn), checks whether the corresponding system S is solvable, and
computes a solution of the integer programming problem IP(A, b, C) in
that case.
q) Use your function IPSolve(. . .) to solve the following integer program-
ming problems.
1) A and b as in k1), (c1, . . . , c5) = (23, 15, 6, 7, 1)
2) A and b as in k3), (c1, . . . , c7) = (23, 15, 67, 1, 53, 4)

3.5 Localization and Saturation
211
3.5 Localization and Saturation
All generalizations are dangerous,
even this one.
(Alexandre Dumas jr.)
In the previous sections, we saw several ways to compute colon ideals and
colon modules. Let us apply our knowledge in an easy case. Suppose we are
given the ideal I = (x2, xy2, y3z4) in the polynomial ring P = K[x, y, z] over
a ﬁeld K . When we compute the colon ideal I : (y), we get (x2, xy, y2z4).
When we compute I : (y2) instead, we get I : (y2) = (x, yz4). Continuing
this way, we ﬁnd I : (y3) = (x, z4), and it is easy to see that I : (yd) = (x, z4)
for every d ≥3.
What conclusions can we draw from this example? First of all, we observe
the phenomenon that the process of forming I : (yd) for d = 1, 2, 3, . . .
stabilizes after a while. This leads to a new ideal which is called the saturation
of I with respect to (y) and is denoted by I : (y)∞. In the case we just looked
at, the ideal I : (y)∞is generated by {x, z4}.
But there is more to see. Suppose we could consider y as an invertible
element. Then, clearly, the ideal I would be equal to the ideal generated
by {x, z4}. Two completely diﬀerent approaches lead to the same result. A
chain of colon ideals stabilizes exactly at the ideal which could be obtained
by considering one element as invertible. Although it may appear to be dan-
gerous to draw such general conclusions from such an easy example, this is
not a coincidence. Rather, it is a special case of an algebraic process which
we study in the ﬁrst part of this section.
To do that, we need to make a brief detour in order to introduce localiza-
tion. Localization allows us to consider some elements of a ring as invertible.
Everybody is familiar with the operation of inverting all non-zero integers
in order to get the ﬁeld of rational numbers. Localization is a far-reaching
generalization of this process to arbitrary rings, to arbitrary multiplicatively
closed sets of elements which are to be inverted, and to arbitrary modules
over those rings. We can even divide by zero! (If this looks like localization
could turn into a nightmare, take solace in the fact that localizing in zero
makes a module vanish.)
Since you know our style by now, it is clear that we are not going to treat
the subject of localization in the style of Bourbaki. Instead, we content our-
selves with pointing out one aspect which is relevant from the computational
point of view. The localization of a ring R at one element can be represented
as a residue class ring of R[y] (see Proposition 3.5.6).
In the second subsection, we generalize the above example and deﬁne the
saturation of a module N by an ideal I in another module M . As for colon
modules, we immediately reduce the computation of saturations to the case
of submodules of P r, where P is a polynomial ring over a ﬁeld. Generalizing
the above example again, it turns out that the saturation of a module is the

212
3. First Applications
limit of a suitable family of colon modules (see Proposition 3.5.9). This gives
us a ﬁrst na¨ıve method for computing saturations.
More sophisticated methods can be derived from the link between satura-
tions and localizations provided by Proposition 3.5.11. It says that the satu-
ration with respect to a principal ideal can also be obtained by extending the
module to the localization at the generating element and then contracting it
back. Our main Theorem 3.5.13 oﬀers several approaches to the computation
of saturations based on this idea.
The most important uses of saturation calculations are for more advanced
tasks such as computing primary decompositions (see Tutorial 43), local co-
homology modules, and the deﬁning ideals of projective algebraic varieties or
schemes. At the end of the current section, we solve a more modest problem
and show how to solve the radical membership problem (see Corollary 3.5.15).
After saturating you with promises, let us get going and do some real
mathematics!
3.5.A
Localization
In this subsection we let R be a commutative ring and M an R-module.
Deﬁnition 3.5.1. A subset S ⊆R is called multiplicatively closed if
1R ∈S and the product of any two elements of S is again contained in S .
For instance, a multiplicatively closed set is obtained by taking an element
f ∈R and considering the set of its powers S = {f i | i ∈N}. Another
common example occurs when R is an integral domain. Then S = R \ {0}
is a multiplicatively closed subset of R. In this case, we have already made
use of the ﬁeld of fractions of R, i.e. the ﬁeld consisting of the fractions
r
s ,
where r ∈R and s ∈S .
Given a multiplicatively closed subset S of an arbitrary commutative
ring R, the process of forming the ﬁeld of fractions of a domain can be
generalized as follows.
Proposition 3.5.2. Let R be a commutative ring, let M be an R-module,
and let S be a multiplicatively closed subset of R. We consider the set of
pairs {(m, s) | m ∈M, s ∈S}. For two such pairs (m, s), (m′, s′), we let
(m, s) ∼(m′, s′) if and only if there exists an element s′′ ∈S such that
s′′(sm′ −s′m) = 0.
a) The relation ∼is an equivalence relation.
b) Let us denote the set of all equivalence classes by MS and the equivalence
class of a pair (m, s) by
m
s . Then the rules
m
s + m′
s′ = s′m + sm′
ss′
and
r · m
s = rm
s
for all r ∈R, for all m, m′ ∈M , and for all s, s′ ∈S make MS into
an R-module.

3.5 Localization and Saturation
213
c) The map M −→MS deﬁned by m 7−→m
1 is R-linear.
d) For r, r′ ∈R, for m ∈M , and for s, s′ ∈S , the rules
r
s · r′
s′ = rr′
ss′
and
r
s · m
s′ = rm
ss′
make RS into a ring and MS into an RS -module.
Proof.
Since the relation ∼is clearly reﬂexive and symmetric, it suﬃces
to show that it is transitive. Suppose that (m, s) ∼(m′, s′) ∼(m′′, s′′), i.e.
that there exist elements t, u ∈S such that we have t(sm′ −s′m) = 0 and
u(s′m′′ −s′′m′) = 0. Then tuss′′m′ = tus′s′′m and tuss′′m′ = tuss′m′′.
This implies tus′(sm′′ −s′′m) = 0, and therefore (m, s) ∼(m′′, s′′). Thus
claim a) is proved. The remaining claims follow from the observation that
the stated rules and maps are independent of the choice of representatives of
the involved equivalence classes.
□
In particular, part c) of this proposition says that the map R −→RS de-
ﬁned by r 7→r
1 is an R-algebra homomorphism. Clearly, the RS -module MS
is generated by the elements in the image of the canonical map M −→MS .
Deﬁnition 3.5.3. In the situation of the proposition, the RS -module MS
is called the localization of M at S or the module of fractions of M
with respect to S .
Some authors use the notation S−1M or M[S−1] for the module of frac-
tions MS . If the multiplicatively closed set S is of the form S = {f i | i ∈N}
with an element f ∈R, we shall write Mf instead of MS and speak of the
localization of M at the element f .
Using the deﬁnition of ∼, it follows immediately that an element m ∈M
maps to
m
1 = 0 in MS if and only if sm = 0 for some s ∈S . For a ﬁnitely
generated R-module M , we can then see that MS = 0 is equivalent to
AnnR(M) ∩S ̸= ∅. In particular, we have MS = 0 if 0 ∈S .
Example 3.5.4. Let P = K[x1, . . . , xn] be a polynomial ring over a ﬁeld K ,
and let S be the set of polynomials with non-zero constant term. Then S
is a multiplicatively closed subset of P , and the ring PS consists of those
rational functions which are deﬁned at the point (0, . . . , 0).
More generally, let p be a prime ideal in R. Then the set S = R \ p is a
multiplicatively closed subset of R, and we can form the ring RS . In commu-
tative algebra, this ring is usually denoted by Rp . In algebraic geometry, it
is related to the ring of germs of functions at a point of a certain topological
space. This is the reason why it is called the localization of R at p.
Our next objective is to understand the concept of localization at an
element in a diﬀerent way. The following auxiliary result will prove useful for
this purpose. For a more general version, look at Exercise 5.

214
3. First Applications
Proposition 3.5.5. (Extended Division)
Let R be a ring, let f ∈R, let y be a new indeterminate, and let g(y) be a
non-zero polynomial in R[y]. Then there exist a polynomial q(y) ∈R[y] and
an element r ∈R such that
f deg(g)g(y) = q(y) · (fy −1) + r
Proof.
Writing g(y) = Pγ
i=0 ciyi with γ = deg(g) ∈N and c0, . . . , cγ ∈R,
we see that the polynomial f γg(y) = Pγ
i=0 f γ−ici(fy)i ∈R[y] is of the form
˜g(fy) with a polynomial ˜g(y) ∈R[y]. Next, we substitute y + 1 for y and
decompose ˜g(y+1) in the form ˜g(y+1) = ˜q(y)·y+r, where ˜q(y) ∈R[y] and
r ∈R. After we perform the substitution y 7→fy −1, this equation becomes
f γg(y) = ˜g(fy) = ˜q(fy −1) · (fy −1) + r = q(y) · (fy −1) + r
with q(y) = ˜q(fy −1) ∈R[y], as desired.
□
Proposition 3.5.6. Let R be a ring, let f ∈R \ {0}, and let y be a new
indeterminate. Then there exists an isomorphism of R-algebras
Rf ∼= R[y]/(fy −1)
Proof.
The R-algebra homomorphism ϕ : R[y] −→Rf deﬁned by y 7→1
f is
clearly surjective and satisﬁes fy−1 ∈Ker(ϕ). Suppose g(y) ∈Ker(ϕ)\{0}.
Using Extended Division 3.5.5, we ﬁnd a representation f γg(y) = q(y) ·
(fy −1) + r, where γ = deg(g), where q(y) ∈R[y], and where r ∈R. By
applying the map ϕ, we get the equation r = f γg( 1
f ) = 0 in Rf , because we
started with g(y) ∈Ker(ϕ). Thus there exists an i > 0 such that f ir = 0.
Consequently, f γ+ig(y) = f iq(y)(fy −1) implies
g(y) = f γ+iyγ+ig(y) −(f γ+iyγ+i −1)g(y)
= f iyγ+iq(y) · (fy −1) −(f γ+i−1yγ+i−1 + f γ+i−2yγ+i−2 + · · · + 1)
·(fy −1) · g(y)
∈(fy −1)
and therefore Ker(ϕ) = (fy −1).
□
Of course this is only a very small portion of what can be said about
the concept of localization. But for the time being, it is enough for us to
understand the connection to saturation which follows now.

3.5 Localization and Saturation
215
3.5.B
Saturation
The following deﬁnition of the saturation of a module by an ideal resembles
the deﬁnition of the colon module. But there is one important diﬀerence: for
each element m ∈M , we may have to choose a diﬀerent exponent i such
that Iim ⊆N , and there is no a priori bound on those exponents.
Deﬁnition 3.5.7. Let R be a commutative ring, let I be an ideal in R, let
U be an R-module, and let M and N be two R-submodules of U . Then
the set
N :M I∞= S
i∈N
N :M Ii = {m ∈M | Ii · m ⊆N for some i ∈N}
is an R-submodule of M . It is called the saturation of N by I in M .
In this subsection we want to provide the reader with some explicit meth-
ods for computing saturations of ﬁnitely generated modules over aﬃne al-
gebras. As usual, we let K be a ﬁeld and P = K[x1, . . . , xn] a polynomial
ring over K . With the following result we reduce the general problem of
computing saturations to the case of submodules of a ﬁnitely generated free
P -module. The procedure is completely analogous to the one we followed in
Proposition 3.2.18, and the proof is also the same.
Proposition 3.5.8. Let J be an ideal in P , let U be a ﬁnitely generated
module over the aﬃne K -algebra P/J , and let M and N be P/J -sub-
modules of U . Furthermore, let I be an ideal in P containing J . Our goal
is to compute N :M (I/J)∞.
Suppose we are given a presentation U ∼= P r/V with a P -submodule V
of P r . We can write M = M ′/V and N = N ′/V with P -submodules M ′
and N ′ of P r containing V . Then N :M (I/J)∞is the residue class module
of N ′ :M′ I∞in U .
Again, as a consequence of this proposition, we shall from now on consider
only the case of submodules M and N of P r for some r ≥0, and of an
ideal I ⊆P . The following na¨ıve method for computing N :M I∞frequently
works well in practice, although it requires the computation of an a priori
unknown number of Gr¨obner bases.
Proposition 3.5.9. For some number i ∈N we have N :M Ii = N :M Ii+1.
If we let µ = min{i ∈N | N :M Ii = N :M Ii+1}, then
N :M I∞= N :M Iµ = N :M Iµ+1 = · · ·
Proof.
For m ∈M such that Iim ⊆N for some i ≥0, we obviously have
Ii+1m ⊆N . Thus there is a chain N :M I ⊆N :M I2 ⊆· · · ⊆M which
becomes stationary after a while, because M is a Noetherian P -module by
Hilbert’s Basis Theorem 2.4.6. This prove the ﬁrst claim.

216
3. First Applications
Now we assume that N :M Ii = N :M Ii+1 for some i ≥0, and we let
m ∈N :M Ii+2 . Since Ii+2m ⊆N , we get Ii+1fm ⊆N for all f ∈I , and
therefore Iifm ⊆N . Thus we have shown N :M Ii+2 ⊆N :M Ii+1 , and
since the other inclusion holds trivially, we ﬁnd N :M Ii+2 = N :M Ii+1 .
Inductively, we obtain N :M Ii = N :M Ij for all j ≥i. In view of the above
chain of submodules, this ﬁnishes the argument.
□
Notice that we have N :M Ii+1 = (N :M Ii) :M I , so that we can compute
the colon modules required by this proposition also by repeatedly taking the
colon module by I .
Example 3.5.10. Let I be the ideal (x2
1x2 −2x1x2
2 + x3
2, x3
1 −3x1x2
2 + 2x3
2,
x1x2
2x2
3 −x3
2x2
3 −x1x3
2 + x4
2, x3
2x4
3 −2x4
2x2
3 + x5
2) in the polynomial ring P =
Q[x1, x2, x3]. Suppose we want to determine I :P (x1)∞.
When we compute I1 = I :P (x1), we get I1 = (x2
1−2x1x2+x2
2, x1x2x2
3−
x2
2x2
3−x1x2
2+x3
2, x2
2x4
3−2x3
2x2
3+x4
2). Then we can check that I ⊂I1 . Thus we
have to compute I2 = I1 :P (x1) next. We get I2 = (x2
1 −2x1x2 + x2
2, x1x2
3 −
x2x2
3 −x1x2 + x2
2, x2x4
3 −2x2
2x2
3 + x3
2). Again we can check that I1 ⊂I2 .
Continuing this way, we calculate I3 = I2 :P (x1) = (x2
1 −2x1x2 +x2
2, x1x2
3 −
x2x2
3 −x1x2 + x2
2, x4
3 −2x2x2
3 + x2
2) and check that I2 ⊂I3 . Finally, the ideal
I4 = I3 :P (x1) = (x2
1 −2x1x2 +x2
2, x1x2
3 −x2x2
3 −x1x2 +x2
2, x4
3 −2x2x2
3 +x2
2)
satisﬁes I3 = I4 .
Using the proposition, we conclude that I :P (x1)∞= I3 = (x2
1 −2x1x2 +
x2
2, x1x2
3 −x2x2
3 −x1x2 + x2
2, x4
3 −2x2x2
3 + x2
2).
Of course, it would be nice if we could predict the number µ in the
proposition beforehand. Some attempts in this direction are contained in
Tutorial 37.
The reason for the importance of localizations with respect to the prob-
lem of computing saturations is that the saturation of a submodule of P r
with respect to a principal ideal can be viewed as the combination of extend-
ing the submodule to the localization and contracting it back. In the next
proposition, the module P r will be considered as a subset of (P r)f via the
canonical map.
Proposition 3.5.11. (Saturation and Localization)
Let M and N be two P -submodules of P r , and let I = (f) be a principal
ideal in P generated by a non-zero polynomial f ∈P .
a) The Pf -module Nf can be identiﬁed with the Pf -submodule of (P r)f
generated by the images of the elements of N under the canonical map
P r −→(P r)f .
b) We have N :M I∞= Nf ∩M .
Proof.
To prove a), we denote the canonical map N ,−→P r by ι, and we
let ϕ be the map ϕ : Nf −→(P r)f given by ϕ( v
f i ) = ι(v)
f i . It is easy to check
that ϕ is well-deﬁned and injective, and this implies the claim.

3.5 Localization and Saturation
217
Now we show claim b). To prove “⊆”, let v ∈M and i ∈N such that
Ii · v ⊆N . By a), the fact that f iv ∈N implies
v
1 =
1
f i · f iv ∈Nf . Next
we show “⊇”. Given a vector v ∈M such that
v
1 =
w
f i for some w ∈N
and some i ∈N, we have f i+jv = f jw in P r for some j ∈N, and thus
f iv = w ∈N . Hence we get v ∈N :M Ii ⊆N :M I∞.
□
How can we use this connection between localizations and saturations?
The key for turning it into an algorithm is the presentation we found in Propo-
sition 3.5.6 for the localization at an element. Using this presentation, we can
explicitly perform the process of extending the submodule and contracting it
back. Thus we arrive at several new methods for computing saturations.
Lemma 3.5.12. Let M and N be two P submodules of P r, and let I and J
be two ideals in P . Then we have
(N :M I∞) ∩(N :M J∞) = N :M (I + J)∞
Proof.
Only the inclusion “⊆” needs to be shown. Let v ∈M such that
Iiv ⊆N and Jjv ⊆N for some i, j ∈N. Then we have (f + g)i+jv ∈N
for all f ∈I and all g ∈J , because in the expansion of (f + g)i+j every
summand is divisible by f i or gj . Thus the claim is proved.
□
Theorem 3.5.13. (Computation of Saturations)
Let M and N be two non-zero P -submodules of P r , let I be a non-zero ideal
in P , and let y be a new indeterminate. In the following, we identify P r with
its image in P[y]r .
a) Suppose that I = (f) is a principal ideal generated by a non-zero poly-
nomial f ∈P . Then we have
N :M (f)∞=
³
NP[y] + (fy −1) · P[y]r´
∩M
b) Let {f1, . . . , fs} be a system of generators of I . Then we have
N :M I∞=
sT
i=1
N :M (fi)∞
c) Let {f1, . . . , fs} be a system of generators of I . In P[y], we form the
polynomial f(y) = f1 + f2y + · · · + fsys−1 . Then we have
N :M I∞=
¡
NP[y] :P [y]r (f(y))∞¢
∩M
Proof.
To prove the ﬁrst claim, we take an element v ∈M which satisﬁes
Ii · v ⊆N for some i ≥1. Then v = f iyiv −(1 + fy + · · · + f i−1yi−1)(fy −
1)v is contained in the right-hand side. Conversely, let v be an element of
(NP[y] + (fy −1)P[y]r) ∩M , and let {w1, . . . , wu} ⊆N \ {0} be a system
of generators of N . Then there are polynomials g1, . . . , gu, h1, . . . , hr ∈P[y]
such that v = g1w1 + · · · + guwu + h1(fy −1)e1 + · · · + hr(fy −1)er , where

218
3. First Applications
{e1, . . . , er} denotes the canonical basis of P[y]r . After considering this as
an equation in (Pf[y])r , we perform the substitution y 7→1
f . Since v ∈P r
is invariant under this substitution, we obtain
v = g1(x1, . . . , xn, 1
f )w1 + · · · + gu(x1, . . . , xn, 1
f )wu
Let f j be a common denominator of g1(x1, . . . , xn, 1
f ), . . . , gu(x1, . . . , xn, 1
f ).
Now it suﬃces to multiply everything with f j in order to see that f jv ∈N .
Thus we have v ∈N :M I∞.
Claim b) follows by induction from the lemma. Finally, to prove c), we
note that Ii · v ⊆N for some vector v ∈M and some i ∈N implies
fα1 · · · fαi v ∈N for all α1, . . . , αi ∈{1, . . . , s}. On the other hand, we have
f(y)iv =
s
X
α1,...,αi=1
c(α1,...,αi)fα1 · · · fαi yα1+···+αi−i v
for suitable coeﬃcients c(α1,...,αi) ∈N. Hence we obtain f(y)iv ∈NP[y].
To show the other inclusion, we proceed by induction on s and note
that the case s = 1 is trivially true. For s > 1, we start with an element
v ∈M satisfying f(y)iv ∈NP[y] for some i ∈N and expand f(y)iv as
above. We consider P[y] as a polynomial ring in one indeterminate y over
the ring P and equip it with the standard grading deg(y) = 1. Then the
P[y]-submodule NP[y] of P[y]r is a graded submodule, of P[y]r , since it is
generated by homogeneous elements of degree zero (see Proposition 1.7.10).
Therefore we have P
α1+···+αi−i=j c(α1,...,αi)fα1 · · · fαiv ∈N for all j ∈N.
In particular, the case j = i(s −1) implies f i
sv ∈N .
Since we know v ∈NP[y] :P [y]r (f(y))∞and v ∈NP[y] :P [y]r (fsys−1)∞,
we can use the lemma to get v ∈MP[y] :P [y]r (f1 + f2y + · · · + fs−1ys−2)∞.
Now we apply the induction hypothesis and obtain v ∈N :M (f1, . . . , fs−1)∞.
Together with v ∈N :M (fs)∞and the lemma, this implies the claim.
□
Example 3.5.14. Consider again the ideal I ⊆P = Q[x1, x2, x3] given
in Example 3.5.10. If we want to compute I :P (x1)∞using the method
suggested by part a) of the theorem, we have to form the polynomial ideal
J = I + (1 −x1y) in P[y]. Then we eliminate y and get again the correct
answer J ∩P = (x2
1 −2x1x2 +x2
2, x1x2
3 −x2x2
3 −x1x2 +x2
2, x4
3 −2x2x2
3 +x2
2) =
I :P (x1)∞.
As an application of the previous theorem, we ﬁnd an eﬀective criterion
for checking whether a given polynomial is in the radical of some ideal. Notice
that this problem is much easier than the problem of actually computing the
radical of an ideal which will be studied in Section 3.7.

3.5 Localization and Saturation
219
Corollary 3.5.15. (Radical Membership Test)
Let I be an ideal in P , let f ∈P \ {0}, and let y be a new indeterminate.
Then the following conditions are equivalent.
a) We have f ∈
√
I .
b) We have IPf = Pf .
c) We have 1 ∈I :P (f)∞.
d) In the ring P[y] we have 1 ∈IP[y] + (fy −1).
e) Every Gr¨obner basis of the ideal IP[y] + (fy −1) in P[y] contains an
element of K \ {0}.
f) The reduced Gr¨obner basis of the ideal IP[y] + (fy −1) in P[y] with
respect to every term ordering is {1}.
Proof.
First we show the equivalence of a) and b). Let f i ∈I for some
i ∈N. Then 1 = f i ·
1
f i ∈IPf . Conversely, if 1 ∈IPf , then there exist
a polynomial g ∈I and a number i ∈N such that 1 =
g
f i . Using the
deﬁnition of Pf , we get f i = g ∈I . The equivalence of b) and c) follows from
Proposition 3.5.11.b, and the equivalence of c) and d) from Theorem 3.5.13.a.
Finally, it is clear that the last two conditions are nothing but reformulations
of d).
□
Example 3.5.16. Once again, let I be the ideal of P = Q[x1, x2, x3] given
in Example 3.5.10. Suppose we want to check whether f = x1x2 −x1x2
3
is contained in
√
I . In the ring P[y], we compute a reduced Gr¨obner basis
of the ideal IP[y] + (fy −1) and get {1}. Hence we conclude that f ∈
√
I .
Exercise 1. Let R be a ring, let M be a ﬁnitely generated R-module,
and let S ⊆R be a multiplicatively closed subset. Prove that the following
conditions are equivalent.
a) MS = 0
b) AnnR(M) ∩S ̸= 0
Exercise 2. Let R be a ring and p a prime ideal in R.
a) Show that S = R \ p is a multiplicative set.
b) Prove that the ring RS has a unique maximal ideal. Describe the
elements of that ideal.
Exercise 3. Let R be a ring, let M be an R-module, and let S ⊆R
be a multiplicatively closed set. Prove that the localization MS has the
following universal property.
If N is any R-module such that the multiplication map µs : N −→N
is bijective for every element s ∈S , and if ϕ : M −→N is an R-linear
map, then there exists precisely one R-linear map ψ : MS −→N such
that ϕ = ψ ◦ι, where ι : M −→MS is the canonical map.
Exercise 4. Let P be a polynomial ring over a ﬁeld K , let f1, . . . , fs ∈P
be non-zero polynomials, and let S be the multiplicative monoid generated
by {f1, . . . , fs}. Show that there is an isomorphism PS ∼= P[y]/(fy −1),
where f = Qs
i=1 fi .

220
3. First Applications
Exercise 5. Let R be a ring, let y be an indeterminate, and let
g(y), h(y) ∈R[y]\{0}. Moreover, we let γ = max{deg(g)−deg(h)+1, 0},
and we let a ∈R be the leading coeﬃcient of h(y).
a) Prove that there exist polynomials q(y), r(y) ∈R[y] such that we have
r(y) = 0 or deg(r) < deg(h), and such that
aγg(y) = q(y)h(y) + r(y)
Hint: Proceed by induction on deg(g). If deg(g) ≥deg(h), consider
the polynomial a g(y) −b ydeg(g)−deg(h)h(y), where b is the leading
coeﬃcient of g(y).
b) In the situation of a), show that q(y) and r(y) are uniquely deter-
mined if a is a non-zerodivisor of R.
Exercise 6.
Let R be a ring, let I be an ideal in R, and let p be a
prime ideal in R. Prove that if r ∈(R \ p) ∩
√
I , then (p ∩I) : r∞= p.
Exercise 7.
Let R be a ring, let 0 −→M ′ −→M −→M ′′ −→0 be
an exact sequence of R-modules, and let I be an ideal in R. Prove that
there is an induced exact sequence of R-modules
0 −→0 :M′ I∞−→0 :M I∞−→0 :M′′ I∞
and give an example in which the induced map 0 :M I∞−→0 :M′′ I∞is
not surjective.
Exercise 8. Let P = K[x1, . . . , xn] be a polynomial ring over a ﬁeld K ,
let I = (f1, . . . , fs) be an ideal in P , and let g ∈P \ {0}. Write a CoCoA
function which implements the algorithm for checking whether g ∈
√
I
holds provided by Corollary 3.5.15.
Exercise 9. Let K be a ﬁeld and P = K[x1, . . . , x5]. Consider the two
matrices
A =
„
x1
x2
x3
x2
x4
x5
«
and
B =
 x1
x2
x3
x2
x4
x5
x3
x5
0
!
Let d1 = x2x5 −x3x4 , d2 = x2x3 −x1x5 , and d3 = x1x4 −x2
2 be the
2×2-minors of A, and let d be the determinant of B. For I = (d1, d2, d3)
and J = (d3, d), show that
√
I =
√
J .
Tutorial 37: Computation of Saturations
In this tutorial we ask you to implement the algorithms for computing sat-
urations which we explained above. Furthermore, we want to study possible
improvements of these algorithms.
Let P = K[x1, . . . , xn] be a polynomial ring over a ﬁeld K , let I ⊆P be
an ideal which is generated by a set of polynomials {f1, . . . , fs}, and let M
and N be two P -submodules of P r .

3.5 Localization and Saturation
221
a) Write a CoCoA function Sat1(. . .) which implements the method of
Proposition 3.5.9 for computing N :M I∞. In order to ﬁnd the colon
modules N :M Ii , implement the method of Proposition 3.4.9.b in a
CoCoA function ElimColon(. . .).
b) Apply your function Sat1(. . .) to compute the saturation N :M I∞in
the following cases.
1) I = (x, y, z), N = (x + y −3z, y2 −3yz + 2z2) ∩(x, y, z)4 , M = (1)
in Q[x, y, z]
2) I = (x −y), N = ⟨xye1, x2e1, y2e2⟩, M = ⟨xye1, xye2⟩in Q[x, y]2
3) I = (x, y + z), N = ⟨(yz −2z2)e1, (y2 −4z2)e2, (xz −z2)e2,
(x2 −z2)e3⟩, M = ⟨xe1, ye2, ze3⟩in Q[x, y, z]3
c) Implement the method of Theorem 3.5.13.a,b for computing N :M I∞
in a CoCoA function Sat2(. . .) and apply it to the cases given in b).
d) Implement the method of Theorem 3.5.13.c for computing N :M I∞in
a CoCoA function Sat3(. . .) and apply it to the cases given in b).
e) Let I = (f) be a non-zero principal ideal, and let v ∈N :M I∞. Describe
two diﬀerent ways how one can ﬁnd an integer i ≥0 such that f iv ∈N .
Hint: One method uses Proposition 3.5.9, and the other one follows from
the proof of Theorem 3.5.13.a.
f) Let I be again an arbitrary ideal in P . Use your answers of e) to write
two CoCoA functions RadPower1(. . .) and RadPower2(. . .) which ﬁnd for
every polynomial f ∈
√
I an integer i ≥0 such that f i ∈I . Apply your
functions in the following cases.
1) I = (x3, y3, z3), f = x + y + z in Q[x, y, z]
2) I = (x1x4−x2
2, x2x5−x3x4, x1x5−x2x3), f = x1x2
5−2x2x3x5+x2
3x4
in Q[x1, . . . , x5]
g) Prove the formula
N :M (f1 · · · fs)∞= (· · · ((N :M (f1)∞) :M (f2)∞) · · ·) :M (fs)∞
h) Use g) to write a CoCoA function SatIndets(. . .) which takes an ideal I
in P and computes I :P (x1 · · · xn)∞. Apply this function in the following
cases.
1) I = (x7
1 −x2
2x3, x4
1x4 −x3
2) in Q[x1, . . . , x4]
2) I = (x1x2x3 −x4x5x6, x5x7 −x1x2x6) in Q[x1, . . . , x7]
3) I = (x2x4−x6x8, x2x2
8−x3
4, x1x3−x5x7, x2
1x7−x2
3x5) in Q[x1, . . . , x8]
i) Let g1, . . . , gt be further polynomials in P . Suppose that J is an ideal
in P which contains the polynomial f1 · · · fs −g1 · · · gt. Then prove the
formula
J :P (f1 · · · fs · g1 · · · gt)∞= J :P (f1 · · · fs)∞

222
3. First Applications
Tutorial 38: Toric Ideals
In Tutorial 36, we found a solution of the integer programming problem
IP(A, b, C), where A = (aij) ∈Matm,n(N), b = (b1, . . . , bm) ∈Nm , and
C : Nn −→N is a non-zero linear function. Since the integer programming
problem has many practical applications, it is important to solve it as eﬃ-
ciently as possible. Let us discuss our earlier solution in this respect.
The main step was to consider the terms ti = ya1i
1
· · · yami
m
for all
i = 1, . . . , n, and to form the binomial ideal J = (x1 −t1, . . . , xn −tn)
in K[x1, . . . , xn, y1, . . . , ym], where K is a ﬁeld. Then we had to compute
the Gr¨obner basis of the ideal J with respect to an elimination ordering
for {y1, . . . , ym}. Unfortunately, this computation is, in general, rather inef-
ﬁcient.
Let P = K[x1, . . . , xn]. The ideal I = J ∩P is called the toric ideal
associated to the matrix A. In this tutorial, we want to search for another
way to compute I and to study possibilities for applying this method to
optimize the solution of the integer programming problem. By S , we denote
again the system of Diophantine equations







a11z1 + a12z2 + · · · + a1nzn
=
b1
a21z1 + a22z2 + · · · + a2nzn
=
b2
...
...
...
am1z1 + am2z2 + · · · + amnzn
=
bm
a) Let (α1, . . . , αn) ∈Nn be a solution of S , let σ be a cost-compatible
term ordering on T(x1, . . . , xn), and let (β1, . . . , βn) ∈Nn be such that
xβ1
1 · · · xβn
n = NFσ,I(xα1
1 · · · xαn
n ). Prove that (β1, . . . , βn) is a solution of
the integer programming problem IP(A, b, C).
Thus we can try to solve IP(A, b, C) as follows. First we ﬁnd a solution
(α1, . . . , αn) of the system S , for instance by an exhaustive search or as in
Tutorial 36.k. Then we ﬁnd a system of generators of I . Next, we choose
a cost-compatible term ordering σ on T(x1, . . . , xn). Finally, we calculate a
σ-Gr¨obner basis of I and NFσ,I(xα1
1 · · · xαn
n ).
Computationally, the most expensive step in this procedure is the second
one, i.e. the determination of a system of generators of I . Let us implement
a reference function against which we can judge possible optimizations.
b) Write a CoCoA function Toric1(. . .) which takes the matrix A and com-
putes the toric ideal I = J ∩P associated to A via the built-in command
Elim(. . .).
c) Apply your function Toric1(. . .) in the following cases. Each time, mea-
sure the execution time using Time.
1) A1 =


3
1
11
2
3
5
3
5
4
5
0
1
7
4
6
2
5
6
1
9
2
3
3
1



3.5 Localization and Saturation
223
2) A2 =





1
4
9
5
8
7
3
3
6
7
1
6
2
4
4
1
2
4
0
4
4
3
4
4
3
6
6
5
2
9
3
1
9
6
9
7
1
9
2
9
9
7
0
6
3
9
2
0
8
4





3) A3 =



4 3 3 3 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0
0 1 0 0 2 1 1 0 0 0 3 2 2 1 1 1 0 0 0 0 4 3
0 0 1 0 0 1 0 2 1 0 0 1 0 2 1 0 3 2 1 0 0 1
0 0 0 1 0 0 1 0 1 2 0 0 1 0 1 2 0 1 2 3 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0
3 2 2 2 1 1 1 1 0 0 0 0 0
0 2 0 1 3 2 1 0 4 3 2 1 0
1 0 1 2 0 1 2 3 0 1 2 3 4



Now we consider the homogeneous system of Diophantine equations as-
sociated to S and denote it by S0 .







a11z1 + a12z2 + · · · + a1nzn
=
0
a21z1 + a22z2 + · · · + a2nzn
=
0
...
...
...
am1z1 + am2z2 + · · · + amnzn
=
0
Let L ⊆Zn be the set of integer solutions of S0 . A subset of Zn is called a
lattice in Zn if it is a free Z-submodule.
d) Show that L is a lattice of rank n −rk(A) in Zn.
e) Prove that the following construction yields a map ϕ : L −→I which
is well-deﬁned. A tuple (α1, . . . , αn) ∈L can be uniquely written as
(max(α1, 0), . . . , max(αn, 0))−(max(−α1, 0), . . . , max(−αn, 0)). Then we
deﬁne
ϕ(α1, . . . , αn) = xmax(α1,0)
1
· · · xmax(αn,0)
n
−xmax(−α1,0)
1
· · · xmax(−αn,0)
n
Hint: Use I = J ∩P and a technique similar to Tutorial 36.g.
f) Conversely, let xα1
1 · · · xαn
n −xβ1
1 · · · xβn
n ∈I for some tuples (α1, . . . , αn),
(β1, . . . , βn) ∈Nn. Prove that (α1 −β1, . . . , αn −βn) ∈L.
g) Let L = K[x1, . . . , xn, x−1
1 , . . . , x−1
n ] be the ring of Laurent polynomials
introduced in Tutorial 36. Describe an explicit isomorphism of K -alge-
bras Px1···xn ∼= L.
h) Let r = rk(L) = n −rk(A) > 0, and let {v1, . . . , vr} ⊆L be a Z-
basis of L. The ideal IL = (ϕ(v1), . . . , ϕ(vr)) is called the lattice ideal
associated to L. Show that IL · Px1···xn = I · Px1···xn and conclude that
I = IL :P (x1 · · · xn)∞
Hint: First show that IL ⊆I by using e) and that I is a prime ideal. If
α = (α1, . . . , αn) is of the form α = Pr
i=1 civi , write ϕ(α) = xα+ −xα−
and expand xα+/xα−−1 into a product.

224
3. First Applications
i) Use h) to write a CoCoA function Toric2(. . .) which takes the matrix A
and computes its associated toric ideal I . For the computation of the
saturation, apply the function SatIndets(. . .) of Tutorial 37.h.
Hint: Use the CoCoA function LinKer(. . .) at least eight times to get
diﬀerent Z-bases of L. (The function LinKer(. . .) is not deterministic.)
In this way, produce many generators of IL.
j) Calculate the toric ideals associated to the matrices in part c) using
Toric2(. . .) and Time how long it takes.
k) Explain how one can use Tutorial 37.i to avoid some saturations with
respect to certain indeterminates in the function Toric2(. . .). Write a
CoCoA function Toric3(. . .) which implements this optimization.
l) Apply your function Toric3(. . .) in the cases of c), measure its execution
times again, and compare the result with your previous timings.

3.6 Homomorphisms of Algebras
225
3.6 Homomorphisms of Algebras
He who asks questions
cannot avoid the answers.
(Cameroon Proverb)
In Subsection 3.3.A we examined homomorphisms between ﬁnitely gen-
erated modules over an aﬃne algebra P/I , where P = K[x1, . . . , xn] is a
polynomial ring over a ﬁeld K and I ⊆P is an ideal. We answered the
question of how to compute presentations for the kernel and the image of
such a homomorphism. Now we ask the same questions for K -algebra homo-
morphisms.
So, let P ′ = K[y1, . . . , ym] be another polynomial ring, and let I′ ⊆P ′
be an ideal. How can we compute the kernel of a K -algebra homomorphism
ϕ : P/I −→P ′/I′ ? Our earlier results are not applicable, because P ′/I′ is in
general not a ﬁnitely generated P/I -module. Therefore we need a diﬀerent
approach. Fortunately, the elimination techniques introduced in Section 3.4
come to our rescue. We embed both P and P ′ into the larger polynomial
ring Q = K[x1, . . . , xn, y1, . . . , ym] and form J = I′Q+(x1−f1, . . . , xn−fn),
where fi ∈P ′ are chosen such that fi +I′ = ϕ(xi +I) for i = 1, . . . , n. Then
Ker(ϕ) is simply the residue class ideal of the elimination ideal J ∩P .
A number of other questions can be reformulated as questions about the
kernels of suitable K -algebra homomorphisms. For example, we can solve the
implicitization problem which asks for the ideal of algebraic relations among
a given set of polynomials.
Another application is the possibility to perform the following task. Let
us consider the aﬃne Q-algebra Q[x, y]/(x2 + 2xy + y2 + 1), and let us
denote by x and y the residue classes of x and y. Clearly, the element
x + y satisﬁes an algebraic equation, namely (x + y)2 + 1 = 0. Such an
element is called algebraic over Q. On the other hand, the element x does
not satisfy an algebraic equation. It is called transcendental over Q. Given
an aﬃne K -algebra and an element in it, it is possible to decide whether
the element is transcendental or algebraic, and in the latter case to ﬁnd its
minimal polynomial over K (see Corollary 3.6.4).
Then we turn our attention to the study of the image of a K -algebra
homomorphism ϕ : P/I −→P ′/I′ . Proposition 3.6.6 allows us to check
whether or not a given element of P ′/I′ is contained in the image of ϕ. In
the ﬁrst case, we show how one can represent it explicitly using the generators
of Im(ϕ). The set Im(ϕ) is an aﬃne K -algebra itself and will be presented
using generators and relations. Another beautiful application of our elimina-
tion techniques is the possibility to decide whether ϕ is surjective just by
looking at the shape of a particular Gr¨obner basis.
In the last part, this result is extended and sharpened for homomorphisms
ϕ : P −→P ′ of polynomial rings over K . Once more the full power of
reduced Gr¨obner bases shows up. In particular, we explain how the shape
of a suitable reduced Gr¨obner basis allows us to compute an explicit right

226
3. First Applications
inverse homomorphism if ϕ is surjective (see Proposition 3.6.9). Finally, we
get a very explicit characterization of K -algebra automorphisms of P (see
Proposition 3.6.12).
Several times in this section an interesting phenomenon occurs. We start
with a fairly simple, innocent looking example and ask a straightforward
question: what happens if we apply the theoretical results in this concrete
case? Sometimes the answer can be much more complicated than we would
ever have imagined. And we would not be surprised if, when you try your
own examples using CoCoA, the answer ﬁlls screen after screen. Such is life!
In Section 1.1 we introduced evaluation homomorphisms on polynomial
rings. Evaluation homomorphisms of the type ψ : R[x1, . . . , xn] −→R were
also called substitution homomorphisms. Since we want to study algebra
homomorphisms in this section, the following facts about substitution homo-
morphisms will come in handy.
Proposition 3.6.1. Let R be a ring, let R[x1, . . . , xn] be a polynomial ring
over R, let f1, . . . , fn ∈R, and let ψ : R[x1, . . . , xn] −→R be the substitu-
tion homomorphism deﬁned by ψ(xi) = fi for i = 1, . . . , n.
a) The kernel of ψ is the ideal (x1 −f1, . . . , xn −fn) in R[x1, . . . , xn].
b) For every g ∈R[x1, . . . , xn], there exist h1, . . . , hn ∈R[x1, . . . , xn] such
that
g =
nP
i=1
hi (xi −fi) + g(f1, . . . , fn)
Proof.
Obviously, claim b) implies a). Given g ∈R[x1, . . . , xn], we apply
the R-algebra homomorphism ϑ : R[x1, . . . , xn] −→R[x1, . . . , xn] deﬁned
by ϑ(xi) = xi + fi for i = 1, . . . , n. Then we write ϑ(g) in the form
ϑ(g) = g(x1 + f1, . . . , xn + fn) =
nP
i=1
ehi xi + r
where eh1, . . . ,ehn ∈R[x1, . . . , xn] and r ∈R. By applying the substitution
homomorphism xi 7→0 for i = 1, . . . , n to both sides of this equation, we
see that r = g(f1, . . . , fn).
Clearly, the R-algebra homomorphism ϑ′ : R[x1, . . . , xn] −→R[x1, . . . , xn]
deﬁned by ϑ′(xi) = xi −fi for i = 1, . . . , n is inverse to ϑ. When we ap-
ply it to the above equation, we get g = ϑ′(ϑ(g)) = Pn
i=1 ϑ′(ehi)(xi −fi) +
g(f1, . . . , fn). By setting hi = ϑ′(ehi) for i = 1, . . . , n, we obtain the desired
result.
□
For the remainder of this section, we let K be a ﬁeld, and we suppose
that P = K[x1, . . . , xn] and P ′ = K[y1, . . . , ym] are two polynomial rings
containing proper ideals I ⊂P and I′ ⊂P ′ . Then a K -algebra homomor-
phism
ϕ : P/I −→P ′/I′

3.6 Homomorphisms of Algebras
227
is determined by polynomials f1, . . . , fn ∈P ′ such that ϕ(xi + I) = fi + I′
for i = 1, . . . , n. We can view P ′/I′ as a P/I -algebra via ϕ by letting
(f + I) · (g + I′) = ϕ(f + I) · (g + I′) for f ∈P and g ∈P ′ . But as one can
easily see, the P/I -module P ′/I′ is in general not ﬁnitely generated, so that
the previous results on modules cannot be used for computing presentations
of the P -modules Ker(ϕ) and Im(ϕ). Instead, we are now going to provide
other eﬀective methods for this purpose.
Proposition 3.6.2. (Kernels of K-Algebra Homomorphisms)
Let ϕ : P/I −→P ′/I′ be a K -algebra homomorphism which is given by
ϕ(xi + I) = fi + I′ for i = 1, . . . , n. We form the polynomial ring Q =
K[x1, . . . , xn, y1, . . . , ym] and the ideal J = I′Q + (x1 −f1, . . . , xn −fn).
Then Ker(ϕ) is the image of the ideal J ∩P in P/I .
Proof.
Let g ∈P be a polynomial such that g + I ∈Ker(ϕ). Then the
equality ϕ(g + I) = g(f1, . . . , fn) + I′ = 0 implies g(f1, . . . , fn) ∈I′ . If we
consider h = g −g(f1, . . . , fn) ∈Q as a polynomial with coeﬃcients in P ′
and indeterminates x1, . . . , xn , we have h(f1, . . . , fn) = 0. Therefore Propo-
sition 3.6.1.a implies that h is in the ideal generated by {x1−f1, . . . , xn−fn}
in Q. In particular, we get g = g(f1, . . . , fn) + h ∈J ∩P .
Conversely, let g ∈J ∩P , and let {h1, . . . , hs} ⊆P ′ be a system of
generators of I′ . Since we have g ∈J , we can represent g in the form
g = Ps
i=1 gihi + Pn
j=1 kj(xj −fj) with polynomials gi, kj ∈Q. Now we
substitute xi 7−→fi for i = 1, . . . , n in this representation, and we get
g(f1, . . . , fn) = Ps
i=1 gi(f1, . . . , fn, y1, . . . , ym)hi ∈I′ . Therefore we obtain
ϕ(g + I) = g(f1, . . . , fn) + I′ = 0, as claimed.
□
In the introduction of the previous section we mentioned the impliciti-
zation problem. Given polynomials f1, . . . , fn ∈P ′ , it asks how one can
ﬁnd the ideal of algebraic relations among them. This problem can be solved
by applying the preceding proposition in the case I = (0) and I′ = (0).
Corollary 3.6.3. (Implicitization)
Given polynomials f1, . . . , fn ∈P ′ , we deﬁne a K -algebra homomorphism
ϕ : P −→P ′ by ϕ(xi) = fi for i = 1, . . . , n. In K[x1, . . . , xn, y1, . . . , ym],
we consider the ideal J = (x1 −f1, . . . , xn −fn). Then the ideal of algebraic
relations among f1, . . . , fn is given by
Ker(ϕ) = J ∩P
Another application of the previous proposition is the possibility to check
whether an element of an aﬃne K -algebra is algebraic or transcendental
over K, and to compute its minimal polynomial in the ﬁrst case.
Corollary 3.6.4. (Minimal Polynomials)
Let I be an ideal in P , let R be the aﬃne K -algebra R = P/I , and let
f ∈R \ {0} be the residue class of a polynomial f ∈P . We consider a new

228
3. First Applications
indeterminate y and form the ideal J = I · P[y] + (y −f) in the polynomial
ring P[y].
a) The element f ∈R is transcendental over K if and only if we have
J ∩K[y] = (0).
b) If the element f ∈R is algebraic over K , then any generating polynomial
of the elimination ideal J ∩K[y] is a minimal polynomial of f over K .
Proof.
Both claims follow from the proposition. We observe that f is tran-
scendental over K if and only if the kernel of the K -algebra homomorphism
K[y] −→R deﬁned by y 7→f is trivial. If this kernel is non-trivial, the
minimal polynomial of f over K generates it.
□
Example 3.6.5. Consider the aﬃne Q-algebra R = Q[x]/(x7 −x −1). The
polynomial x7 −x −1 is irreducible over Q. Therefore R is a ﬁeld. The
residue class of the polynomial f = x6 −9x5 + x + 11 in R has the minimal
polynomial
y7−83 y6+2999 y5−61029 y4+726440 y3−4538196 y2−9285526 y+22670839
over Q. To check this, we have to form the ideal J = (x7 −x −1, y −f)
in Q[x, y] and to compute J ∩Q[y]. In spite of the apparent simplicity of
the question, the answer shows that you should not try to calculate this by
hand. Of course, CoCoA does it in a split-second!
Next we want to study the image of ϕ : P/I −→P ′/I′ . Clearly, Im(ϕ) is
the K -subalgebra of P ′/I′ generated by f1 + I′, . . . , fn + I′. In particular, it
is an aﬃne K -algebra. (In Example 2.6.4 we saw that, in general, subalgebras
of aﬃne K -algebras need not be aﬃne algebras.) Moreover, we recall from
above that P ′/I′ is, in general, not a ﬁnitely generated module over its
subalgebra Im(ϕ).
This leads us to a number of questions. How can we decide eﬀectively
whether a given residue class of P ′/I′ lies in Im(ϕ)? And if it does, how can
we represent it using the generators of that K -algebra? How can we check
whether ϕ is surjective? How can we ﬁnd an explicit presentation of Im(ϕ)
as a K -algebra? These questions are answered by the following proposition.
Proposition 3.6.6. (Images of K-Algebra Homomorphisms)
Let ϕ : P/I −→P ′/I′ be a K -algebra homomorphism which is given by
ϕ(xi + I) = fi + I′ for i = 1, . . . , n. We form the polynomial ring Q =
K[x1, . . . , xn, y1, . . . , ym] and the ideal J = I′Q + (x1 −f1, . . . , xn −fn),
and we let σ be an elimination ordering for {y1, . . . , ym}. Furthermore, we
let G = {g1, . . . , gs} be the reduced σ-Gr¨obner basis of J , and we assume
that G ∩P = {g1, . . . , gt} for some t ≤s.
a) For a polynomial g ∈P ′, we have g + I′ ∈Im(ϕ) if and only if we have
NFσ,J(g) ∈P . (For the computation of this normal form, we view g as
an element of Q.)

3.6 Homomorphisms of Algebras
229
b) If a polynomial g ∈P ′ satisﬁes h = NFσ,J(g) ∈P , then the equation
g+I′ = h(f1, . . . , fn)+I′ provides an explicit representation of its residue
class as an element of Im(ϕ).
c) The aﬃne K -algebra Im(ϕ) has the presentation
Im(ϕ) ∼= K[x1, . . . , xn]/(g1, . . . , gt)
d) The K -algebra homomorphism ϕ : P/I −→P ′/I′ is surjective if and
only if G contains elements of the form yi −hi , where hi ∈P for
i = 1, . . . , m.
Proof.
By applying the Division Algorithm 1.6.4 and Corollary 2.4.9.a, we
obtain a representation
g = q1g1 + · · · + qsgs + NFσ,J(g)
with q1, . . . , qs ∈Q. If we have NFσ,J(g) ∈P here, we substitute xi 7→fi for
i = 1, . . . , n. Since g1, . . . , gs are contained in J , they yield elements of I′
under this substitution. Hence we get g −(NFσ,J(g))(f1, . . . , fn) ∈I′ . This
proves b) and the implication “⇐” of a).
Now we assume that g ∈P ′ satisﬁes g + I′ ∈Im(ϕ). We want to show
NFσ,J(g) ∈P . By assumption, there exists a polynomial h ∈P such that we
have g+I′ = ϕ(h+I) = h(f1, . . . , fn)+I′ . Since g−h(f1, . . . , fn) ∈I′Q ⊆J
and h −h(f1, . . . , fn) ∈(x1 −f1, . . . , xn −fn) ⊆J by Proposition 3.6.1.b,
the polynomials g, h, and h(f1, . . . , fn) have the same normal form by
Proposition 2.4.10.a. Using the fact that σ is an elimination ordering for
{y1, . . . , ym}, we see that h ∈P implies NFσ,J(g) = NFσ,J(h(f1, . . . , fn)) =
NFσ,J(h) ∈P . Thus also the implication “⇒” of a) holds.
Next we prove c). By Theorem 3.4.5, the ideal (g1, . . . , gt) is precisely
the elimination ideal J ∩P , which in turn maps to Ker(ϕ) in P/I by
Proposition 3.6.2. Thus we have Im(ϕ) ∼= (P/I)/ Ker(ϕ) ∼= P/(J ∩P) =
P/(g1, . . . , gt).
Finally, we prove d). Suppose that ϕ is surjective. Let i ∈{1, . . . , m}.
As yi + I′ ∈Im(ϕ), part a) yields hi = NFσ,J(yi) ∈P . Thus we have
yi −hi = yi −NFσ,J(yi) ∈J . Since LMσ(yi −hi) = yi , the polynomial
yi −hi is monic. Moreover, Q/J ∼= P ′/I′ shows that J is a proper ideal
of Q. Thus yi is a minimal generator of LTσ(J). The reduced σ-Gr¨obner
basis of J has to contain an element of the form yi −ki , where ki ∈P . Since
both hi and ki are irreducible and (yi −hi) −(yi −ki) = ki −hi , it follows
that hi = ki , i.e. that the polynomial yi −hi is contained in the reduced
σ-Gr¨obner basis of J .
Conversely, let G be the reduced σ-Gr¨obner basis of J . If yi −hi ∈G for
some i ∈{1, . . . , m}, then we have hi = NFσ,J(yi), and therefore a) shows
yi + I′ ∈Im(ϕ).
□
In Tutorial 41.c you can see a discussion of the generalization of part c)
of this proposition to the case of subalgebras generated by rational functions.

230
3. First Applications
As in Corollary 3.6.3, we now restrict our attention to the case I = I′ = 0,
i.e. the case of homomorphisms of polynomial rings over K . In this case,
parts a) and b) of the proposition specialize to the following result.
Corollary 3.6.7. (Subalgebra Membership Test)
Let f1, . . . , fn ∈P ′, let S = K[f1, . . . , fn] be the K-subalgebra of P ′ genera-
ted by {f1, . . . , fn}, let J = (x1−f1, . . . , xn−fn) ⊆K[x1, . . . , xn, y1, . . . , ym],
and let σ be an elimination ordering for {y1, . . . , ym}.
Then a polynomial g ∈P ′ is contained in the subalgebra S if and only if
NFσ,J(g) ∈P . In this case, if we let h = NFσ,J(g), then g = h(f1, . . . , fn)
is an explicit representation of g as an element of S .
As an application of this corollary, we can compute the representation
of a symmetric polynomial in terms of elementary symmetric polynomials
discussed in Tutorial 12 in a diﬀerent way.
Example 3.6.8. In Tutorial 12 we proved that the elementary symmetric
polynomials s1, . . . , sn generate the K -subalgebra of all symmetric poly-
nomials in P ′ = K[y1, . . . , yn]. We deﬁne a K -algebra homomorphism
ϕ : K[x1, . . . , xn] −→P ′ by mapping xi to si for i = 1, . . . , n. Then
we form the ideal J = (x1 −s1, . . . , xn −sn) in the polynomial ring
Q = K[x1, . . . , xn, y1, . . . , yn]. By the corollary, we can compute the rep-
resentation of a symmetric polynomial f ∈P ′ in terms of the elementary
symmetric polynomials by calculating the normal form NFσ,J(f) and sub-
stituting xi 7→si for i = 1, . . . , n.
For surjective homomorphisms ϕ : P −→P ′ , we can strengthen Proposi-
tion 3.6.6.d as follows.
Proposition 3.6.9. (Surjective K-Algebra Homomorphisms Between
Polynomial Rings)
Let ϕ : P −→P ′ be a surjective K -algebra homomorphism which is given
by ϕ(xi) = fi for i = 1, . . . , n. In the ring Q = K[x1, . . . , xn, y1, . . . , ym],
we consider the ideal J = (x1 −f1, . . . , xn −fn). Let σ be an elimination
ordering for {y1, . . . , ym}.
a) There exist polynomials h1, . . . , hm, g1, . . . , gs ∈P such that the reduced
σ-Gr¨obner basis of J is {y1 −h1, . . . , ym −hm, g1, . . . , gs}.
b) The set {g1, . . . , gs} is the reduced Gr¨obner basis of Ker(ϕ) with respect
to the term ordering obtained by restricting σ to T(x1, . . . , xn).
c) The homomorphism ψ : P ′ →P deﬁned by ψ(yi) = hi for i = 1, . . . , m
is a right inverse of ϕ, i.e. we have ϕ ◦ψ = id P ′ .
Proof.
First we prove a). Since ϕ is surjective, Proposition 3.6.6.d shows
that the reduced σ-Gr¨obner basis G of J contains elements of the form
yi −hi , where hi ∈P for i = 1, . . . , m. Let g be another element in G.
Since the Gr¨obner basis is reduced, the term LTσ(g) is not divisible by any

3.6 Homomorphisms of Algebras
231
indeterminate in {y1, . . . , ym}. Therefore we have LTσ(g) ∈P . We know
that σ is an elimination ordering for {y1, . . . , ym}. Hence LTσ(g) ∈P implies
g ∈P , and a) is proved.
Claim b) follows from Proposition 3.6.2 and Theorem 3.4.5.c. To prove c),
it suﬃces to show that yi = hi(f1, . . . , fn) for i = 1, . . . , m. Let ui = yi −hi
for i = 1, . . . , m. Consider ui as a polynomial in P ′[x1, . . . , xn]. Since we
have ui ∈J = (x1 −f1, . . . , xn −fn), it is clear that ui(f1, . . . , fn) = 0. This
means yi −hi(f1, . . . , fn) = 0 for i = 1, . . . , m, as we wanted to show.
□
The following example shows how one can apply this proposition in prac-
tice.
Example 3.6.10. Using the rings P = Q[x1, x2, x3] and P ′ = Q[y1, y2],
we let ϕ : P →P ′ be the Q-algebra homomorphism which is deﬁned by
ϕ(x1) = 1
5y1 + y4
2 , ϕ(x2) = 2y2
1 + y2 , and ϕ(x3) = 1
3y2 . We compute the
reduced Gr¨obner basis of the ideal J = (x1−1
5y1−y4
2, x2−2y2
1 −y2, x3−1
3y2)
with respect to an elimination ordering for {y1, y2}. Using CoCoA, we get
{y1 −5x1 + 405x4
3, y2 −3x3, x8
3 −2
81x1x4
3 +
1
6561x2
1 −
1
328050x2 +
1
109350x3}.
Thus Proposition 3.6.6.d shows that ϕ is surjective, Proposition 3.6.9.b
shows Ker(ϕ) = (x8
3 −2
81x1x4
3 +
1
6561x2
1 −
1
328050x2 +
1
109350x3), and Proposi-
tion 3.6.9.c shows that a right inverse of ϕ is given by the Q-algebra homo-
morphism ψ : P ′ →P deﬁned by ψ(y1) = −405x4
3 + 5x1 and ψ(y2) = 3x3 .
Our last topic in this section is the computational treatment and charac-
terization of bijective K -algebra homomorphisms. In Volume 2, we shall see
that a surjective K -algebra homomorphism ϕ : P −→P ′ can only exist if
n ≥m. If ϕ is bijective, then it is easy to check that also the inverse map
ϕ−1 : P ′ −→P is a K -algebra homomorphism. Thus, if ϕ is bijective, we
must have n = m. Hence the map ϕ is a K -algebra automorphism of P
in this case, i.e. a K -algebra homomorphism ϕ : P −→P such that there
exists a K -algebra homomorphism ψ : P −→P which satisﬁes ψ ◦ϕ = idP
and ϕ ◦ψ = idP .
The following lemma shows that surjective K -algebra homomorphisms
ϕ : P −→P are already K -algebra automorphisms.
Lemma 3.6.11. Let R be a Noetherian ring, and let ϕ : R −→R be a ring
homomorphism. Then the following conditions are equivalent.
a) The map ϕ is surjective.
b) The map ϕ is bijective.
Proof.
It suﬃces to show “a)⇒b)”. For every i ≥1, we obviously have
Ker(ϕi) ⊆Ker(ϕi+1). Since R is a Noetherian ring, there exists a number
j ∈N such that Ker(ϕi) = Ker(ϕj) for all i ≥j . Now let r ∈Ker(ϕ).
The surjectivity of ϕ implies the surjectivity of ϕj . Hence there exists an
element r′ ∈R such that r = ϕj(r′). Then 0 = ϕ(r) = ϕj+1(r′) implies
r′ ∈Ker(ϕj+1) = Ker(ϕj), and therefore r = ϕj(r′) = 0. Consequently, the
map ϕ is injective.
□

232
3. First Applications
By combining the preceding results, we can characterize K -algebra auto-
morphisms of P as follows.
Proposition 3.6.12. (Automomorphisms of Polynomial Rings)
Let P = K[x1, . . . , xn], and let ϕ : P −→P be a K -algebra homo-
morphism given by ϕ(xi) = fi for i = 1, . . . , n. Furthermore, let Q =
K[x1, . . . , xn, y1, . . . , yn], let J = (x1−f1(y1, . . . , yn), . . . , xn−fn(y1, . . . , yn)),
and let σ be an elimination ordering for {y1, . . . , yn}. Then the following
conditions are equivalent.
a) The map ϕ is a K -algebra automorphism of P .
b) The homomorphism ϕ is surjective.
c) There exist polynomials h1, . . . , hn ∈P such that the reduced σ-Gr¨obner
basis of J is {y1 −h1, . . . , yn −hn}.
If these conditions hold, the K -algebra homomorphism ψ : P →P deﬁned
by ψ(xi) = hi for i = 1, . . . , n is the inverse of ϕ, i.e. we have ψ = ϕ−1 .
Proof.
The equivalence of a) and b) is a special case of Lemma 3.6.11. By
Proposition 3.6.9, condition a) implies c). Given c), we can apply Proposi-
tion 3.6.6.d to conclude that ϕ is surjective. By Lemma 3.6.11, it is then an
isomorphism of K -algebras. Since Proposition 3.6.9.c shows that ψ is a right
inverse of ϕ, it is the inverse of ϕ.
□
Once again, we can take a concrete K -algebra automorphism of P and
ask for a computation of its inverse. But even if we start with a fairly simple
map, the size and the intricacy of the answer may surprise us.
Example 3.6.13. Using the polynomial ring P = Q[x1, x2, x3], let us con-
sider the two Q-algebra homomorphisms
ψ1 :
P
−→
P
x1
7−→
x1
x2
7−→
x2 + x2
1
x3
7−→
x3 + x1x2
and
ψ2 :
P
−→
P
x1
7−→
x1 + x2x3
x2
7−→
x2 −x3 + x2
3
x3
7−→
x3
It is easy to apply the preceding proposition in order to see that those
two maps are Q-algebra automorphisms of P . Thus also ϕ = ψ2 ◦ψ1 is
a Q-algebra automorphism of P . Let fi = ϕ(xi) for i = 1, 2, 3, i.e. let
f1 = x1 + x2x3 , let f2 = x2 −x3 + x2
1 + x2
3 + 2x1x2x3 + x2
2x2
3 , and let
f3 = x3 + x1x2 −x1x3 + x1x2
3 + x2
2x3 −x2x2
3 + x2x3
3 . It follows that x1 , x2 ,
and x3 can be expressed as polynomials in f1 , f2 , and f3 by the method
explained at the end of the last proposition. In the case at hand, the results
are the impressive expressions
x1
=
f 9
1 −3f 7
1 f2 + 3f 5
1 f 2
2 + 3f 6
1 f3 −f 6
1 −f 3
1 f 3
2 −6f 4
1 f2f3 + f 5
1 + 2f 4
1 f2
+3f 2
1 f 2
2 f3 + 3f 3
1 f 2
3 −2f 3
1 f2 −f 2
1 f 2
2 −2f 3
1 f3 −3f1f2f 2
3 + f1f 2
2
+2f1f2f3 + f 3
3 −f2f3 −f 2
2 + f1
x2
=
−f 6
1 + 2f 4
1 f2 −f 2
1 f 2
2 −2f 3
1 f3 + f 3
1 + 2f1f2f3 −f 2
1 −f1f2 −f 2
3
+f2 + f3
x3
=
f 3
1 −f1f2 + f3

3.6 Homomorphisms of Algebras
233
Exercise 1. Find a K -algebra homomorphism ϕ : P/I −→P ′/I′ such
that P ′/I′ is not a ﬁnitely generated P/I -module via ϕ.
Exercise 2. Solve the implicitization problems for the following tuples
of polynomials.
a) (t3, t4 −t, t5 + t −1) ∈Q[t]3
b) (t31 + t6 + t, t8, t10) ∈Q[t]3
c) ( 1
2 t3, t4 −1
3 s, t5 + t −s2) ∈Q[s, t]3
d) (s + t, s(s + 2t), s2(s + 3t)) ∈Q[s, t]3 (The set of zeros of the solution
is called the tangent surface to the twisted cubic.)
e) (s3 −3st2 −3s, t3 −3s2t −3t, 3s2 −3t2) ∈Q[s, t]3 (The set of zeros of
the solution is called the Enneper surface.)
Exercise 3.
Let P/I be an aﬃne K -algebra such that dimK(P/I) is
ﬁnite. Prove that every element in P/I is algebraic over K .
Exercise 4. Given polynomials f1, . . . , fs ∈P = K[x1, . . . , xn] and an
ideal I ⊆P , how can one decide eﬀectively whether the residue classes
f1 + I, . . . , fs + I of f1, . . . , fs in the aﬃne K -algebra R = P/I are
algebraically independent over K ?
Exercise 5. Let P = K[x, y] be a polynomial ring over a ﬁeld K , and
let I be a non-zero principal ideal in P . Prove that at least one element
of the set {x + I, y + I} ⊆P/I is transcendental over K .
Exercise 6.
Implement the method of Example 3.6.8 to compute the
representation of a symmetric polynomial in terms of the elementary sym-
metric polynomials by writing a CoCoA function ReprSym2(. . .).
Hint: Use the Gr¨obner basis of J = (x1 −s1, . . . , xn −sn) provided by
Tutorial 23.d.
Exercise 7. Let ϕ : K[x] →K[y] be a K -algebra homomorphism, and
let f = ϕ(x).
a) Prove that ϕ is injective if and only if f /∈K .
b) Prove that ϕ is surjective if and only if deg(f) = 1.
Exercise 8. Let ϕ : R →S be a ring homomorphism.
a) Prove that ϕ is a ring isomorphism (i.e. that there exists a ring ho-
momorphism ψ : S −→R such that ψ ◦ϕ = idR and ϕ ◦ψ = idS ) if
and only if ϕ is bijective.
b) Give an example of an injective ring homomorphism ϕ : R −→S
such that there is no ring homomorphism ψ : S −→R which satisﬁes
ψ ◦ϕ = idR .
c) Give an example of a surjective ring homomorphism ϕ : R −→S
such that there exists no ring homomorphism ψ : S −→R satisfying
ϕ ◦ψ = idS .
Exercise 9. Let P = K[x1, . . . , xn] be a polynomial ring over a ﬁeld K ,
and let ϕ : P −→P be a K -algebra homomorphism. Prove that if ϕ is a
K -algebra automorphism of P and ϕ(xi) = fi for i = 1, . . . , n, then the
Jacobian determinant det( ∂fi
∂xj ) is an element of K \ {0}.
The question whether over ﬁelds K of characteristic zero the converse
of this statement holds is the famous (and as yet unsolved) Jacobian
Conjecture.

234
3. First Applications
Exercise 10. Let P = K[x1, . . . , xn] be a polynomial ring over a ﬁeld
K , let R = K[f1, . . . , fm] ⊆P be a ﬁnitely generated subalgebra with
f1, . . . , fm ∈P , and let I ⊆P be an ideal.
a) Show that we can get a presentation of the aﬃne K -algebra R/(I ∩R)
as follows. Let Q = K[x1, . . . , xn, y1, . . . , ym], and let J be the ideal
J = IQ + (y1 −f1, . . . , ym −fm) in Q. Then there is an isomorphism
of K -algebras
R/(I ∩R) ∼= K[y1, . . . , ym]/(J ∩K[y1, . . . , ym])
b) How can one compute a system of generators of the ideal I ∩R in R?
Write a CoCoA function which computes this system of generators.
c) Generalize parts a) and b) to P -submodules of P r for some r ≥1
and their intersection with Rr .
Tutorial 39: Projections
In Section 3.4, we promised to provide you with a geometric interpretation
of elimination. This interpretation is based on projections. It is the topic
of the present tutorial. Since we shall need to use the language of algebraic
geometry, we assume that you have read Section 2.6 and Tutorial 27.
Let K be a ﬁeld. The aﬃne space An
K was deﬁned as the set Kn together
with the Zariski topology. As usual in mathematics, we do not only consider
objects, but we also introduce the appropriate kind of maps between them.
A polynomial map (or a morphism of aﬃne spaces) is deﬁned as a map
ψ : Am
K →An
K for which there exist polynomials f1, . . . , fn ∈K[y1, . . . , ym]
such that ψ(a1, . . . , am) = (f1(a1, . . . , am), . . . , fn(a1, . . . , am)) for all points
(a1, . . . , am) ∈Am
K .
In the ﬁrst part of this tutorial, we examine some general properties of
polynomial maps. In particular, we want to study their ﬁbers and images. Let
P = K[x1, . . . , xn] and P ′ = K[y1, . . . , ym] be two polynomial rings over K ,
let f1, . . . , fn ∈P ′ , let ϕ : P −→P ′ be the K -algebra homomorphism
deﬁned by ϕ(xi) = fi for i = 1, . . . , n, and let ψ : Am
K −→An
K be the poly-
nomial map satisfying ψ(a1, . . . , am) = (f1(a1, . . . , am), . . . , fn(a1, . . . , am))
for all (a1, . . . , am) ∈Am
K .
a) Let I be an ideal in P , and let V = Z(I) be the zero-set in An
K deﬁned
by I . Show that ψ−1(V ) is the zero-set in Am
K deﬁned by the ideal
J = (ϕ(f) | f ∈I) ⊆P ′ .
b) Let P = (a1, . . . , an) ∈An
K . Use a) to describe the ﬁber ψ−1(P) of the
polynomial map ψ over the point P . Write a CoCoA program Fiber(. . .)
which computes the ideal deﬁning this ﬁber.
c) Let g ∈P be an element of the vanishing ideal of Im(ψ). Show that the
polynomial g(f1, . . . , fn) ∈P ′ vanishes on all points of Am
K . Recall that
we proved in Tutorial 16.c that this implies g(f1, . . . , fn) = 0 if K is
inﬁnite.

3.6 Homomorphisms of Algebras
235
d) Let p be a prime number, let q = pe for some e > 0, and let K be
the ﬁnite ﬁeld K = Fq (see Tutorial 3). Prove that the ideal of all
polynomials h ∈P ′ with the property that h(a1, . . . , am) = 0 for all
(a1, . . . , am) ∈Am
K is generated by {yq
1 −y1, . . . , yq
m −ym}.
Hint: It suﬃces to show that h = 0 if degyi(h) < q for i = 1, . . . , m.
Consider h(a1, . . . , am−1, ym) and argue by induction on m.
To avoid the problems encountered in d), we assume from now on that K
is an inﬁnite ﬁeld. Then we know that g(f1, . . . , fn) = 0 for all g ∈I(Im(ψ)).
We introduce the same notation as in the section and let Q be the polynomial
ring Q = K[x1, . . . , xn, y1, . . . , ym], and J the ideal J = (x1−f1, . . . , xn−fn)
in Q.
e) Prove that J is a prime ideal in Q, and conclude that I = J ∩P is a
prime ideal in P .
f) Show that the elimination ideal I = J ∩P agrees with the vanishing
ideal of Im(ψ).
Hint: Apply Proposition 3.6.1.b.
g) Write a CoCoA function Image(. . .) which takes the tuple (f1, . . . , fn)
and computes the vanishing ideal of the image of the associated polyno-
mial map ψ. Apply your function Image(. . .) and calculate the vanishing
ideals of the images of the following maps.
1) ψ : A2
Q −→A3
Q deﬁned by (a1, a2) 7→(a1a2, a1a2
2, a3
2)
2) ψ : A2
Q −→A3
Q deﬁned by (a1, a2) 7→(a1, a1a2, a2
2)
(The image of this map is called Whitney’s umbrella.)
3) ψ : A2
Q −→A5
Q deﬁned by (a1, a2) 7→(a1, a2, a2
1, a1a2, a2
2)
(The image of this map is called the Veronese surface in A5
Q.)
h) Let I = J ∩P . Prove that Z(I) is the Zariski closure of Im(ψ).
Hint: Tutorial 27.h implies this claim if K is algebraically closed. In
the general case, embed K in its algebraic closure and argue that any
zero-set in An
K containing Im(ψ) has to contain Z(I).
i) Show that Im(ψ) ⊂Z(I) in the ﬁrst example of part g) above. Moreover,
prove that the same thing happens even if replace the ﬁeld Q by C.
Hint: Consider the line Z(x2, x3).
The last part of this tutorial is devoted to explaining its title. Given
positive integers m ≥n and n distinct numbers i1, . . . , in ∈{1, . . . , m},
the map πi1,...,in : Am
K −→An
K deﬁned by (a1, . . . , am) 7→(ai1, . . . , ain) is
called the projection of Am
K onto its components (i1, . . . , in). It is clearly
a polynomial map. Using projections, we can give the following geometric
interpretation of the ideal J and its elimination ideal I = J ∩P .
j) The set of all points (a1, . . . , am, b1, . . . , bn) ∈Am+n
K
such that we have
bi = fi(a1, . . . , am) for i = 1, . . . , n is called the graph of the map ψ.
Let us denote it by G. Prove that G = Z(J) and J = I(G).

236
3. First Applications
k) Prove that the two projections π(1) = π1,...,m : Am+n
K
−→Am
K and
π(2) = πm+1,...,m+n : Am+n
K
−→An
K induce surjections π(1)
G
: G −→Am
K
and π(2)
G : G −→Z(I), and that we have a commutative diagram
Am
K
Z(I) ⊆An
K
G
-
@
@
@
@
R
¡
¡
¡
¡
ª
ψ
π(2)
G
π(1)
G
Thus the formation of the elimination ideal I = J ∩P is the exact
algebraic analogue of the formation of the projection π(2)
G : G −→Z(I).
Tutorial 40: Gr¨obner Bases and Invariant Theory
In Tutorial 12 and Example 3.6.8 we saw that the K -subalgebra of all sym-
metric polynomials in the polynomial ring P = K[x1, . . . , xn] over a ﬁeld K
is generated by the elementary symmetric polynomials, and we saw how one
can represent an arbitrary symmetric polynomial as a polynomial expression
in those elementary symmetric polynomials. In this tutorial we want to gen-
eralize these results to K -subalgebras of P consisting of polynomials which
are invariant under the action of a ﬁnite matrix group.
Let GLn(K) ⊆Matn(K) be the group of all invertible n × n-matrices
over K . It is called the general linear group over K and operates on the
polynomial ring P by
GLn(K) × P
−→
P
(A , f)
7−→
f(A · x)
where we use x to denote the column vector x = (x1, . . . , xn)tr , and where
we let A · x = (a11x1 + · · · + a1nxn, . . . , an1x1 + · · · + annxn) for A = (aij).
In the sequel, we let G ⊆GLn(K) be a ﬁnite subgroup. We shall say that G
is a ﬁnite matrix group.
a) Write a CoCoA function IsGroup(. . .) which takes a list of matrices in
Matn(K) and checks whether they form a ﬁnite matrix group. Apply
your function to verify that the following sets of matrices do indeed form
ﬁnite matrix groups.
1) C2 =
n¡ 1
0
0
1
¢
,
³
−1
0
0
−1
´o
(cyclic group of order 2)
2) C3 =
n¡ 1
0
0
1
¢
,
³
0
1
−1
−1
´
,
³
−1
−1
1
0
´o
(cyclic group of order 3)
3) C4 =
n¡ 1
0
0
1
¢
,
¡ 0
1
−1
0
¢
,
³
−1
0
0
−1
´
,
³
0
−1
1
0
´o
(cyclic group of order 4)
4) V4 =
n¡ 1
0
0
1
¢
,
³
−1
0
0
−1
´
,
¡ 0
1
1
0
¢
,
³
0
−1
−1
0
´o
(Klein four group)

3.6 Homomorphisms of Algebras
237
5) C6 =
n¡ 1
0
0
1
¢
,
¡ 0
−1
1
1
¢
,
¡ −1
−1
1
0
¢
,
¡ −1
0
0
−1
¢
,
¡ 0
1
−1
−1
¢
,
¡ 1
1
−1
0
¢o
(cyclic group
of order 6)
6) S3 =
n³ 1
0
0
0
1
0
0
0
1
´
,
³ 0
1
0
1
0
0
0
0
1
´
,
³ 0
0
1
0
1
0
1
0
0
´
,
³ 1
0
0
0
0
1
0
1
0
´
,
³ 0
0
1
1
0
0
0
1
0
´
,
³ 0
1
0
0
0
1
1
0
0
´o
(permutation group on three elements)
7) D4 =
n¡ 1
0
0
1
¢
,
¡ −1
0
0
1
¢
,
¡ 0
1
−1
0
¢
,
¡ −1
0
0
−1
¢
,
¡ 0
1
1
0
¢
,
¡ 0
−1
−1
0
¢
,
¡ 1
0
0
−1
¢
,
¡ 0
−1
1
0
¢o
(dihedral group of order 8)
8) R8 =
½³ 1
0
0
0
1
0
0
0
1
´
,
µ
−1
0
0
0
1
0
0
0
1
¶
,
µ
1
0
0
0
−1
0
0
0
1
¶
,
³ 1
0
0
0
1
0
0
0
−1
´
,
µ
−1
0
0
0
−1
0
0
0
1
¶
,
µ
−1
0
0
0
1
0
0
0
−1
¶
,
µ
1
0
0
0
−1
0
0
0
−1
¶
,
µ
−1
0
0
0
−1
0
0
0
−1
¶¾
(reﬂection group of the
coordinate planes)
9) A4 =
n³ 1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
1
´
,
³ 0
1
0
0
1
0
0
0
0
0
0
1
0
0
1
0
´
,
³ 0
0
1
0
0
0
0
1
1
0
0
0
0
1
0
0
´
,
³ 0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
´
,
³ 0
1
0
0
0
0
1
0
1
0
0
0
0
0
0
1
´
,
³ 0
0
1
0
1
0
0
0
0
1
0
0
0
0
0
1
´
,
³ 0
1
0
0
0
0
0
1
0
0
1
0
1
0
0
0
´
,
³ 0
0
0
1
1
0
0
0
0
0
1
0
0
1
0
0
´
,
³ 0
0
1
0
0
1
0
0
0
0
0
1
1
0
0
0
´
,
³ 0
0
0
1
0
1
0
0
1
0
0
0
0
0
1
0
´
,
³ 1
0
0
0
0
0
1
0
0
0
0
1
0
1
0
0
´
,
³ 1
0
0
0
0
0
0
1
0
1
0
0
0
0
1
0
´o
(alternating group on four elements)
10) W24 =
½³ 1
0
0
0
1
0
0
0
1
´
,
µ
−1
0
0
0
−1
0
0
0
1
¶
,
µ
−1
0
0
0
1
0
0
0
−1
¶
,
µ
1
0
0
0
−1
0
0
0
−1
¶
,
µ
0
1
0
−1
0
0
0
0
1
¶
,
µ
0
−1
0
1
0
0
0
0
1
¶
,
³ 0
1
0
1
0
0
0
0
−1
´
,
µ
0
−1
0
−1
0
0
0
0
−1
¶
,
µ
0
0
1
0
1
0
−1
0
0
¶
,
µ
0
0
1
0
−1
0
1
0
0
¶
,
³ 0
0
−1
0
1
0
1
0
0
´
,
µ
0
0
−1
0
−1
0
−1
0
0
¶
,
³ 1
0
0
0
0
−1
0
1
0
´
,
µ
1
0
0
0
0
1
0
−1
0
¶
,
µ
−1
0
0
0
0
1
0
1
0
¶
,
µ
−1
0
0
0
0
−1
0
−1
0
¶
,
³ 0
0
1
1
0
0
0
1
0
´
,
µ
0
0
1
−1
0
0
0
−1
0
¶
,
µ
0
0
−1
1
0
0
0
−1
0
¶
,
µ
0
0
−1
−1
0
0
0
1
0
¶
,
³ 0
1
0
0
0
1
1
0
0
´
,
µ
0
−1
0
0
0
−1
1
0
0
¶
,
µ
0
1
0
0
0
−1
−1
0
0
¶
,
µ
0
−1
0
0
0
1
−1
0
0
¶¾
(rotation group of the cube)
b) A polynomial f ∈P is said to be invariant under G if it satisﬁes
f(A · x) = f(x1, . . . , xn) for all matrices A ∈G. Write a CoCoA func-
tion IsInvariant(. . .) which takes a list of matrices representing a ﬁnite
matrix group and a polynomial f ∈P , checks whether f is invariant un-
der this group, and returns the corresponding Boolean value. Apply your
function in the following cases.
1) G = C2 , f = x2 −xy + y2
2) G = C4 , f = x3y + 2x2y2 −xy3
3) G = W24 , f = (x2 −y2)(x2 −z2)(y2 −z2)
4) G = W24 , f = xyz(x2 −y2)(x2 −z2)(y2 −z2)
c) Show that the set of all polynomials in P which are invariant under G
is a graded K -subalgebra of P . We denote this subalgebra by P G and

238
3. First Applications
call it the ring of invariants of G. (Here we equip P with the standard
grading.)
Recall that not every K -subalgebra of P is ﬁnitely generated (see Exam-
ple 2.6.4). Our next goal is to show that P G is a ﬁnitely generated subalgebra
if char(K) = 0. Thus we assume from here on that K is a ﬁeld of character-
istic zero. The map ϱG : P −→P deﬁned by ϱG(f) =
1
#G
P
A∈G f(A · x)
is called the Reynolds operator of G.
d) Show that ϱG : P −→P is a homogeneous K -linear map which has the
following properties.
1) For all f ∈P Gand g ∈P , we have ϱG(fg) = f ϱG(g).
2) We have Im(ϱG) = P G and ϱG ◦ϱG = ϱG.
e) Write a CoCoA function Reynolds(. . .) which takes a list of matrices
representing the elements of G and a polynomial f and computes ϱG(f).
Apply this function in the following cases.
1) G = V4 , f = x + y
2) G = D4 , f = x3 −xy + y3
3) G = A4 , f = x1 −x2 + x3 −x4
f) Prove that there are ﬁnitely many homogeneous polynomials f1, . . . , fs
in P such that P G = K[f1, . . . , fs].
Hint: Let I be the ideal in P which is generated by all homogeneous
polynomials f ∈P G such that deg(f) > 0, and let {f1, . . . , fs} be
a homogeneous system of generators of I . Assume that P G ⊂I and
choose a homogeneous polynomial g ∈I\P G of minimal degree. Then use
Corollary 1.7.11 to write g = Ps
i=1 hifi with homogeneous polynomials
h1, . . . , hs ∈P of positive degree. Now apply ϱG and use d).
Unfortunately, the proof of f) does not tell us how we can ﬁnd ﬁnitely
many homogeneous polynomials f1, . . . , fs ∈P such that P G = K[f1, . . . , fs].
Below we formulate an algorithm which does this job, although it is rather in-
eﬃcient. If you are adventurous, you can try to reconstruct Emmy Noether’s
proof for the correctness of this algorithm later in part j). A more powerful
computational approach to the problem of ﬁnding the ring of invariants is
based on Molien’s Theorem and will be discussed in Volume 2.
g) Consider the following sequence of instructions.
1) Let L = ∅. Choose a degree-compatible term ordering σ on Tn and
compute the tuple (t1, . . . , tN) of all terms of degree ≤#G in P ,
ordered increasingly with respect to σ. (Here N is the number of
such terms.)
2) For i = 1, . . . , N , compute ϱG(ti). Use the Subalgebra Membership
Test 3.6.7 to check whether ϱG(ti) ∈K[f | f ∈L]. If this is not the
case, append ϱG(ti) to the set L.
3) Return L.

3.6 Homomorphisms of Algebras
239
Later we shall prove that this is an algorithm which returns a set L of
homogeneous polynomials such that P G = K[f | f ∈L]. Implement this
algorithm in a CoCoA function Invariants(. . .) whose input is a list of
matrices representing the elements of G.
h) Apply your function Invariants(. . .) to compute the ring of invariants
for as many of the groups listed in part a) as possible. How far can you
get? Can you think of possible optimizations of your function?
i) After you have found a system of algebra generators for P G, you can
use Corollary 3.6.7 to represent any invariant polynomial as a poly-
nomial expression in those algebra generators. Write a CoCoA function
ReprInvariants(. . .) which performs this task and apply it in the fol-
lowing cases.
1) G = C2 , f = x10 + 2x9y + 3x8y2 + · · · + 11y10
2) G = C4 , f = 3x6y2 −2x5y3 + 6x4y4 + 2x3y5 + 3x2y6
3) G = C6 , f = x4y2 −2x3y3 + x2y4
j) (This part is a more challenging project.) Prove the correctness of the
algorithm in g) using the following steps.
1) For d ≥0, let pd = xd
1 + · · · + xd
n. Using induction on n, prove
Newton’s identities
pd −s1pd−1 + · · · + (−1)d−1sd−1p1 + (−1)ddsd = 0
where s1, . . . , sn are the elementary symmetric polynomials, and
where si = 0 for i > n (see Tutorial 12.c).
2) Using induction on d ≥0, prove that sd is a polynomial in
p1, . . . , pn . Conclude that every symmetric polynomial is a polyno-
mial in p1, . . . , pn . (You need to use char(K) = 0 here.)
3) Show that it suﬃces to prove ϱG(xα1
1 · · · xαn
n ) ∈K[f | f ∈L] for
all tuples (α1, . . . , αn) ∈Nn in order to show the correctness of the
algorithm.
4) Let d ≥1 and γ = #G. Introduce new indeterminates y1, . . . , yn .
For every matrix A ∈G, we let a1, . . . , an be the rows of A
and qA the polynomial qA = (a1 · x) y1 + · · · + (an · x) yn in
K[x1, . . . , xn, y1, . . . , yn]. Prove the formula
P
A∈G
(qA)d = γ ·
P
α1+···+αn=d
d!
α1!···αn! ϱG(xα1
1 · · · xαn
n ) yα1
1 · · · yαn
n
Hint: Substitute (ai · x) yi in the expansion of (x1 + · · · + xn)d and
sum over all A ∈G.
5) Using step 2), write
P
A∈G
(qA)d as a polynomial in the expressions
P
A∈G
(qA), . . . , P
A∈G
(qA)γ .
6) Then substitute the formulas of step 4) in this polynomial and com-
pare the coeﬃcients of yα1
1 · · · yαn
n
for all (α1, . . . , αn) ∈Nn .

240
3. First Applications
Tutorial 41: Subalgebras of Function Fields
The purpose of this tutorial is to study ﬁnitely generated subalgebras of
algebraic function ﬁelds. More precisely, we let R be an integral domain and
Q(R) its ﬁeld of fractions.
a) Show that Q(R) is a ﬁnitely generated R-algebra if and only if it is
generated by a single element.
b) Given a1, . . . , ar, b1, . . . , br ∈R and a polynomial f ∈R[y1, . . . , yr],
prove that there exist i1, . . . , ir > 0 such that
bi1
1 · · · bir
r f = g(a1, . . . , ar) + h
where g ∈R[y1, . . . , yr] and h ∈(b1y1−a1, . . . , bryr−ar) ⊆R[y1, . . . , yr].
c) Let a1, . . . , ar ∈R and b1, . . . , br ∈R \ {0}. Show that the ﬁnitely
generated R-subalgebra R[ a1
b1 , . . . , ar
br ] of Q(R) has a presentation
R[ a1
b1 , . . . , ar
br ] ∼= R[y1, . . . , yr]/I ∩R[y1, . . . , yr]
where y1, . . . , yr, z1, . . . , zr are independent indeterminates over R and
where I is the ideal I = (b1y1−a1, . . . , bryr −ar, b1z1−1, . . . , brzr −1) in
the ring R[y1, . . . , yr, z1, . . . , zr]. (Hint: Deﬁne an R-algebra homomor-
phism ϕ : R[y1, . . . , yr] −→R[ a1
b1 , . . . , ar
br ] by yi 7−→ai
bi for i = 1, . . . , r
and show that its kernel is I ∩R[y1, . . . , yr].)
d) Now let K be a ﬁeld and R = K[x1, . . . , xn]/p an aﬃne K -algebra,
where p ⊆K[x1, . . . , xn] is a prime ideal. Prove that for polynomials
f1, . . . , fr ∈K[x1, . . . , xn] and g1, . . . , gr ∈K[x1, . . . , xn] \ {0} we have
a presentation
R[ f1
g1 , . . . , fr
gr ] ∼= K[x1, . . . , xn, y1, . . . , yr]/(I+p)∩K[x1, . . . , xn, y1, . . . , yr]
where I is deﬁned in an analogous way as above and p is the extension
ideal of p in K[x1, . . . , xn, y1, . . . , yr, z1, . . . , zr].
e) Write a CoCoA function FFSubAlg(. . .) which ﬁnds a presentation of
R[ f1
g1 , . . . , fr
gr ] for R = K[x1, . . . , xn]/J from the lists [f1, . . . , fr] and
[g1, . . . , gr], and from a system of generators of J .
f) Apply the function FFSubAlg(. . .) to compute a presentation of R[ ¯x2
¯x1 ]
for R = Q[x1, x2, x3, x4]/(x1x3−x2x4). Show also that R[y1]/(x1y1−x2)
is not an integral domain.
g) Prove R[ a
b ] ∼= R[y]/(by −a) if R is a factorial domain and a, b ∈R \ {0}
are coprime. Note that R[ 1
b] ∼= R[y]/(by −1) is true without the assump-
tion that R is a factorial domain (see Proposition 3.5.6).

3.7 Systems of Polynomial Equations
241
3.7 Systems of Polynomial Equations
ella va amica da cima a valle
[from hilltop to valley lightly she drifts]
(Lorenzo Robbiano, palindromic verse.
It is painted on a sundial in Castelletto d’Orba)
This is the last section, but in some sense it could also be considered
as a chapter by itself, or perhaps as the starting point of Volume 2, or as
a motivation for the subjects dealt with in this book. We are not trying to
suggest a palindromic reading of the topics treated so far. Rather, we would
like to convince you that the ideas developed here should not be considered
as steps of a linear evolution with a clear direction.
Mathematics moves as other human activities do. Sometimes it seems to
climb up a steep mountain, sometimes it slowly drifts down into fertile valleys.
What is the ultimate goal? It could be the solution of a famous problem, the
development of a new theory, a better understanding of an old theory, or the
pursuit of concrete applications in the real world. Mathematicians go back
and forth between those goals, following old paths or creating new ones.
During this perennial wandering, almost certainly they are going to en-
counter systems of polynomial equations. They appear in many mathematical
models of physical systems, in the study of algebraic structures, and in the
algebraic description of geometric objects. We should keep in mind that the
main goal is to solve them. Thus they lie at the heart of Computational
Commutative Algebra.
Our choice, to devote this ﬁnal section to systems of polynomial equations,
was made because we wanted to show how many of the computational skills
acquired so far have to be used in order to get a better grip on the problem.
No more wandering about. Digging the ground and ﬁnding the roots is the
main task now. Let us have a closer look at the diﬃculties which lie ahead.
Given polynomials f1, . . . , fs in the polynomial ring P = K[x1, . . . , xn]
over a ﬁeld K , we can study the following system of polynomial equations:





f1(x1, . . . , xn) = 0
...
fs(x1, . . . , xn) = 0
Three fundamental questions suggest themselves.
1. What does it mean to solve this system of equations?
If the polynomials f1, . . . , fs have degrees ≤1, the answer is a well-
known result in Linear Algebra: there are ﬁnitely many vectors in Kn such
that their linear combinations are precisely the set of solutions of the system
of equations. As soon as one of the polynomials f1, . . . , fs has degree ≥2,
the situation becomes much more complicated.

242
3. First Applications
It turns out that it is more promising to look for the set of solutions of
the above system of equations in K
n, where K is the algebraic closure of K .
Thus, to solve the above system of equations means to determine the set of
zeros of the ideal I = (f1, . . . , fs) in the sense of Section 2.6.
2. How can we describe this set of solutions?
For a single solution (a1, . . . , an) ∈K
n, we can try to determine the mini-
mal polynomials of a1, . . . , an over K . This speciﬁes those algebraic numbers
up to conjugates. And if K = Q, we could then use methods of numerical
analysis to single out the precise solution from that set of conjugates by ﬁnd-
ing a suﬃciently good approximation in Q[i]. Already if K is a ﬁnite ﬁeld,
those methods do not apply.
Thus, in most cases, we shall have to content ourselves with solving the
system of equations in a symbolic way. This leaves us with the following
problem. Suppose that a solution (a1, . . . , an) ∈K
n is described by the
minimal polynomials of a1, . . . , an over K .
3. How many and which tuples of conjugates form the set of solutions?
Towards the end of this section we shall give what we view as a good
answer to this question. We shall show how to compute a single polynomial
in one indeterminate such that if you assign symbols to its roots, then you
can write down the exact solutions of the system as polynomial expressions
in those symbols.
To organize the material, we decided to split this section into three sub-
sections. They deal with a bound for the number of solutions, radicals of
zero-dimensional ideals, and with solving systems eﬀectively. Let us look at
their contents one-by-one.
First, it is important to be able to recognize which systems have only a
ﬁnite number of solutions. This is achieved by the Finiteness Criterion 3.7.1.
If the set of solutions is inﬁnite, we cannot list them anyway, so let us assume
it is ﬁnite. Then we shall provide estimates for the number of solutions. It
turns out that dimK(P/I) provides such a bound (see Proposition 3.7.5).
However this bound is not sharp (see Example 3.7.6), because it is unable to
distinguish between simple and multiple roots.
In the second subsection we turn our attention to radical ideals. Starting
from this point we shall assume that either char(K) = 0 or K is a perfect
ﬁeld of characteristic char(K) = p > 0 which has eﬀective pth roots (see
Deﬁnition 3.7.10). In order to ﬁnd an algorithm which computes the radical
of the given ideal I = (f1, . . . , fs), we ﬁrst have to explain how one can com-
pute the squarefree part of a polynomial in K[x] (see Proposition 3.7.12).
Then we prove Seidenberg’s Lemma 3.7.15 which provides a criterion for a
zero-dimensional ideal I to be radical and permits us to develop an algo-
rithm which computes the radical of I (see Corollary 3.7.16). If the ideal is
radical, we ﬁnally get the optimal bound for the number of solutions (see
Theorem 3.7.19).

3.7 Systems of Polynomial Equations
243
After all this preparatory work, we are ready to handle the problem of
solving systems eﬀectively in the third subsection. Given a zero-dimensional
radical ideal, we show how to change coordinates in order to put the zeros in
normal xn -position (see Proposition 3.7.22), i.e. to transform the given sys-
tem into a new one which is better suited for revealing its solutions. Then the
Shape Lemma 3.7.25 says that, after we compute the reduced Lex-Gr¨obner
basis of the resulting ideal, we can write down the solution set of the system
in a very explicit way. The last step is made in Corollary 3.7.26 where we
present an algorithm which combines all the pieces of information acquired
before and computes the solutions in a suitable format.
A ﬁnal remark is necessary here. We do not claim that the algorithms
contained in this section are particularly eﬃcient. They are mainly intended
to show that an algorithmic solution of the problem is possible, and to indicate
the twists and turns one encounters when the computation has to be carried
out in a symbolic environment.
In the sequel, let K be a ﬁeld, let P = K[x1, . . . , xn], let f1, . . . , fs ∈P ,
and let I = (f1, . . . , fs). Moreover, let K be the algebraic closure of K ,
and let P = K[x1, . . . , xn]. By S we shall denote the system of polynomial
equations





f1(x1, . . . , xn) = 0
...
fs(x1, . . . , xn) = 0
3.7.A
A Bound for the Number of Solutions
Given a system of polynomial equations S as above, there can be ﬁnitely or
inﬁnitely many solutions (a1, . . . , an) ∈K
n. Our ﬁrst proposition provides
an algorithmic criterion for ﬁniteness, since Buchberger’s Algorithm allows
us to check condition e) eﬀectively.
Proposition 3.7.1. (Finiteness Criterion)
Let σ be a term ordering on Tn . The following conditions are equivalent.
a) The system of equations S has only ﬁnitely many solutions.
b) The ideal IP is contained in only ﬁnitely maximal ideals of P .
c) For i = 1, . . . , n, we have I ∩K[xi] ̸= (0).
d) The K -vector space K[x1, . . . , xn]/I is ﬁnite-dimensional.
e) The set Tn \ LTσ{I} is ﬁnite.
f) For every i ∈{1, . . . , n}, there exists a number αi ≥0 such that we have
xαi
i
∈LTσ(I).
Proof.
First we show a) ⇒b). By Corollary 2.6.9, every maximal ideal m
of P is of the form m = (x1 −a1, . . . , xn −an) with a1, . . . , an ∈K . If m
contains IP , then the polynomials f1, . . . , fs lie in the kernel of the sub-
stitution homomorphism ϕ : P −→K which is deﬁned by x1 7→ai for

244
3. First Applications
i = 1, . . . , n. Therefore (a1, . . . , an) is a solution of S . Since there are only
ﬁnitely many such solutions, there can be only ﬁnitely many maximal ideals
m containing IP .
Now we prove b) ⇒f). Let m1, . . . , mt be the maximal ideals of P
containing IP . By Corollary 2.6.9, there are tuples (ai1, . . . , ain) such that
mi = (x1 −ai1, . . . , xn −ain) for i = 1, . . . , t. For j = 1, . . . , n, we form the
polynomials gj = Qt
i=1(xj −aij) ∈K[xj]. From what we have shown in the
proof of a) ⇒b) it follows that gj vanishes on every solution of S . Thus
Hilbert’s Nullstellensatz 2.6.16 yields a number αj ≥0 such that gαj
j
∈IP .
Hence we have xtαj
j
∈LTσ(IP). Now Lemma 2.4.16 shows xtαj
j
∈LTσ(I).
The implication f) ⇒e) is clear, because every term of a suﬃciently
high degree is divisible by one of the terms xtα1
1
, . . . , xtαn
n
, and e) ⇒d) is
a consequence of Macaulay’s Basis Theorem 1.5.7. Thus we prove d) ⇒c)
next. Since P/I is a ﬁnite-dimensional K -vector space, the residue classes
1 + I, xi + I, x2
i + I, . . . are K -linearly dependent. Hence there are non-zero
polynomials gi ∈I ∩K[xi] for every i ∈{1, . . . , n}. Finally, given non-zero
polynomials gi ∈I ∩K[xi] for i = 1, . . . , n, the i-th coordinate of any
solution of S is a zero of gi . Therefore there are at most deg(g1) · · · deg(gn)
such solutions, proving c) ⇒a).
□
The proof of the preceding proposition yields an easy bound for the num-
ber of solutions of S if this number is ﬁnite. We saw that, for i = 1, . . . , n,
the elimination ideal I ∩K[xi] is non-zero, and therefore generated by a non-
zero polynomial gi ∈K[xi]. Then the number of solutions of S was shown
to be at most deg(g1) · · · deg(gn). In fact, a much sharper bound is available.
Before we proceed to derive it, let us introduce the following terminology.
Deﬁnition 3.7.2. An ideal I = (f1, . . . , fs) in P = K[x1, . . . , xn] is called
zero-dimensional if it satisﬁes the equivalent conditions of the Finiteness
Criterion 3.7.1.
Corollary 3.7.3. With the same assumptions and notation as in the Finite-
ness Criterion 3.7.1, let I and J be ideals in P .
a) If I is maximal, then I is zero-dimensional.
b) If I is zero-dimensional and I ⊆J , then J is zero-dimensional.
c) If I is zero-dimensional, then IP is also zero-dimensional and
dimK(P/I) = dimK(P/IP)
Proof.
First we observe that a) is a consequence of Theorem 2.6.6.b and
the Finiteness Criterion 3.7.1.d. The proof of b) follows from the fact that
dimK(P/J) ≤dimK(P/I). Since K ⊆K , a combination of Lemma 2.4.16.a
and Macaulay’s Basis Theorem 1.5.7 yields dimK(P/I) = dimK(P/IP). This
proves both claims of c).
□

3.7 Systems of Polynomial Equations
245
Since we are interested in describing the solutions of the system of poly-
nomial equations S explicitly, we shall assume from now on that there are
only ﬁnitely many such solutions, i.e. that the ideal I = (f1, . . . , fs) is zero-
dimensional. To prove the desired bound for the number of solutions of S
we need one more ingredient, namely a ring-theoretic version of the Chinese
Remainder Theorem.
Lemma 3.7.4. (Chinese Remainder Theorem)
Let R be a ring, and let I1, . . . , It be ideals in R.
a) The canonical R-linear map ϕ : R/(I1 ∩· · · ∩It) −→Qt
i=1 R/Ii is
injective.
b) If the ideals I1, . . . , It are pairwise comaximal, i.e. if Ii + Ij = R for
i ̸= j , then the map ϕ is an isomorphism of R-modules.
Proof.
Since the map ϕ is clearly injective, it suﬃces to show claim b). Fix
a number i ∈{1, . . . , t}, and let Ji = ∩j̸=iIj . Since Ii and Ij are comaximal
for all j ̸= i, we ﬁnd aj ∈Ii and bj ∈Ij such that aj + bj = 1. Then
1 = Q
j̸=i(aj +bj) ∈Ii+Q
j̸=i Ij ⊆Ii+Ji shows that the ideals Ii and Ji are
comaximal. Thus there are elements pi ∈Ii and qi ∈Ji such that pi+qi = 1.
Now it is easy to check that an element (r1 + I1, . . . , rt + It) of Qt
i=1 R/Ii is
the image of the residue class of q1r1 +· · ·+qtrt = (1−p1)r1 +. . .+(1−pt)rt
under ϕ.
□
Proposition 3.7.5. (Bound for the Number of Solutions)
Let f1, . . . , fs ∈P be polynomials which generate a zero-dimensional ideal
I = (f1, . . . , fs). Then the system of equations
f1(x1, . . . , xn) = · · · = fs(x1, . . . , xn) = 0
has at most dimK(P/I) solutions in K
n.
Proof.
Let P
= K[x1, . . . , xn]. By Proposition 2.6.11, the solutions of
S correspond one-to-one to the maximal ideals in P containing IP . Let
m1, . . . , mt be those maximal ideals. From IP ⊆m1 ∩· · · ∩mt we get
dimK(P/IP) ≥dimK(P/(m1 ∩· · · ∩mt)). Now the Chinese Remainder The-
orem yields P/(m1 ∩· · · ∩mt) ∼= Qt
i=1 P/mi , and Corollary 2.6.9 shows
P/mi ∼= K for i = 1, . . . , t. Finally, using Corollary 3.7.3.c, we obtain
dimK(P/IP) = dimK(P/I). Altogether, we get
t=dimK(
tQ
i=1
P/mi) = dimK(P/(m1 ∩· · · ∩mt))
≤dimK(P/IP) = dimK(P/I)
which is the desired inequality.
□

246
3. First Applications
Of course, knowing that there are only ﬁnitely many solutions and having
a bound for their number is only a small step towards actually solving a sys-
tem of polynomial equations. Let us try to study solutions (a1, . . . , an) ∈K
n
of S more closely. Starting from a zero-dimensional ideal I = (f1, . . . , fs)
in P , we may compute a generator gi ∈K[xi] of the elimination ideal
I ∩K[xi] for every i ∈{1, . . . , n}. Then every coordinate ai of a solution
(a1, . . . , an) of S is a zero of gi .
Suppose we are able to factor polynomials in K[xi] eﬀectively (see for
instance Tutorial 6). The irreducible factors of gi are precisely the minimal
polynomials over K of the ith coordinates of the solutions of S . In sim-
ple cases, this easy observation may suﬃce to solve the system of equations
completely, as the following example shows.
Example 3.7.6. Let us consider the three polynomials f1 = x2 + y + z −1,
f2 = x + y2 + z −1, and f3 = x + y + z2 −1 in P = Q[x, y, z]. They
deﬁne a system of polynomial equations f1 = f2 = f3 = 0 and generate
an ideal I = (f1, f2, f3) in P . We observe that {f1, f2, f3} is a DegRevLex-
Gr¨obner Basis of I and deduce that LTDegRevlex(I) = (x2, y2, z2), so that
dimQ(P/I) = 8. Therefore 8 is an upper bound for the number of solutions
of S .
How sharp is this a bound? When we compute generators gi of the elim-
ination ideals I ∩Q[xi] for i = 1, 2, 3 and factor them, we get
g1 = x6 −4x4 + 4x3 −x2 = x2(x −1)2(x + 1 +
√
2)(x + 1 −
√
2)
g2 = y6 −4y4 + 4y3 −y2 = y2(y −1)2(y + 1 +
√
2)(y + 1 −
√
2)
g3 = z6 −4z4 + 4z3 −z2 = z2(z −1)2(z + 1 +
√
2)(z + 1 −
√
2)
Each of those polynomials has four diﬀerent zeros. By substituting them into
the original system of equations, we see that of the 64 possible combinations
only the ﬁve tuples {(1, 0, 0), (0, 1, 0), (0, 0, 1), (−1 +
√
2, −1 +
√
2, −1 +
√
2),
(−1 −
√
2, −1 −
√
2, −1 −
√
2)} are actual solutions.
In this example, we see other phenomena emerging. For instance, it is
clear that the last step of the procedure applied in this example breaks down
if the zeros of the polynomials g1, . . . , gn cannot be represented by radicals.
Another important fact is that, while the bound given by Proposition 3.7.5
is 8, the actual number of solutions is 5.
Let us try to explain this phenomenon. If a polynomial f vanishes at the
set of solutions of S , then also sqfree(f) vanishes at that set. Consequently,
the system S has the same set of solutions as the system S′ , where S′ is
obtained from S by adding the squarefree parts of some polynomials in S .
Looking at the example above, we can now understand why the upper bound
given by Proposition 3.7.5 is not sharp. In the next subsection, we investigate
this aspect of the theory more closely.

3.7 Systems of Polynomial Equations
247
3.7.B
Radicals of Zero-Dimensional Ideals
In the last example we encountered a case in which the system S had multiple
solutions. What does this mean exactly? Arguing as above, we note that the
system of equations deﬁned by I = (f1, . . . , fs) has the same solutions as the
system of equations deﬁned by a set of generators of its radical
√
I = {f ∈P | f i ∈I for some i ≥0}
So, the next goal is to reduce the solution of systems of polynomial equations
to the case where the polynomials generate a radical ideal. To this end, we
need to introduce the notion of a perfect ﬁeld.
Deﬁnition 3.7.7. A ﬁeld K is called a perfect ﬁeld if either its charac-
teristic is 0 or its characteristic is p > 0 and we have K = Kp , i.e. every
element in K has a pth-root in K .
Let us immediately point out that, for a perfect ﬁeld K of characteris-
tic p > 0, the pth root of an element a ∈K is uniquely determined, because
if b, c ∈K satisfy bp = cp = a, then bp −cp = (b −c)p = 0 implies b = c.
For instance, given a prime number p ∈N, the ﬁeld K = Fp is perfect,
since every element is its own pth root. More generally, if K = Fq is any
ﬁnite ﬁeld, where q = pe and e > 0, then the map x 7→xpe−1 provides pth
roots, because we have (xpe−1)p = xq = x for all x ∈K . At this point we
know that ﬁelds of characteristic 0 and ﬁnite ﬁelds are perfect. Are there
non-perfect ﬁelds? The answer is yes, as the following example shows.
Example 3.7.8. Let p ∈N be a prime number, let K = Fp , let x be an
indeterminate, and let L = K(x) be the ﬁeld of fractions of K[x]. Then,
using the factoriality of K[x], we can easily see that x has no pth root in L.
Therefore the ﬁeld L is not perfect.
Is there an eﬀective method for computing the radical of a zero-dimensional
ideal? The radical of a zero-dimensional ideal I = (f) in K[x] is easy to de-
scribe. It is the principal ideal generated by sqfree(f). Thus we shall ﬁrst show
how one can compute the squarefree part of a univariate polynomial. The al-
gorithm is based on the following collection of useful facts about sqfree(f).
Proposition 3.7.9. Let K be a ﬁeld and f ∈K[x] a non-constant polyno-
mial.
a) If gcd(f, f ′) = 1, then f is squarefree.
b) Assume that one of the following conditions holds.
1) We have char(K) = 0.
2) We have char(K) = p > 0 and f = cf α1
1
· · · f αt
t
, where c ∈K \ {0},
where α1, . . . , αt > 0 satisfy p ∤αi for i = 1, . . . , t, and where
f1, . . . , ft are pairwise distinct irreducible monic polynomials.

248
3. First Applications
Then the squarefree part of f is given by sqfree(f) = f/ gcd(f, f ′).
c) Let K be a perfect ﬁeld of characteristic p > 0. Then we have f ′ = 0 if
and only if f is of the form f = gp for some polynomial g ∈K[x].
d) Let K be a perfect ﬁeld. Then the converse of a) holds, i.e. if f is square-
free, then we have gcd(f, f ′) = 1.
Proof.
First we prove a). Suppose that f is not squarefree. Then we can
write f in the form f = f 2
1 f2 with polynomials f1, f2 ∈K[x] such that f1 is
not constant. We compute the derivative of f and get f ′ = 2f1f ′
1f2 + f 2
1 f ′
2 .
Thus we have f1 | gcd(f, f ′), a contradiction.
In order to see that claim b) holds, we write down a factorization
f = cf α1
1
· · · f αt
t
as in 2). Then we note that gcd(f, f ′) = f α1−1
1
· · · f αt−1
t
in both cases. Thus we get f/ gcd(f, f ′) = cf1 · · · ft = sqfree(f).
To prove c), we observe that if f = gp , then f ′ = pg′gp−1 = 0. Conversely,
suppose that f ′ = 0. We write f = P
i≥0 aixi with ai ∈K , and we see that
f ′ = P
i≥1 iaixi−1 = 0 implies ai = 0 for all i ≥0 such that p ∤i. Hence the
polynomial f is of the form f = P
i≥0 apixpi . Since the ﬁeld K is perfect,
there exist elements bi ∈K such that api = bp
i for all i ≥0. Altogether, we
ﬁnd f = P
i≥0(bixi)p = gp for g = P
i≥0 bixi .
Finally we prove d). We decompose f into irreducible factors f = f1 · · · ft
and note that f ′ = Pt
i=1 f1 · · · fi−1f ′
ifi+1 · · · ft. Now we claim that every
irreducible polynomial fi ∈K[x] satisﬁes f ′
i ̸= 0. If char(K) = 0, this is
clear, and if char(K) = p > 0, it follows from c). Thus we get gcd(fi, f ′
i) = 1.
This implies gcd(fi, f ′) = gcd(fi, f ′
i) = 1, and therefore gcd(f, f ′) = 1.
□
For the promised algorithm, we need one further ingredient. When we
work over a perfect base ﬁeld K of characteristic p > 0, Deﬁnition 3.7.7
requires that every element in K has a pth root. But of course we need
to be able to compute that root. This observation motivates the following
deﬁnition.
Deﬁnition 3.7.10. Let K be a perfect ﬁeld of characteristic p > 0. We
shall say that K has eﬀective pth roots if there exists an algorithm which
computes the pth root of any element of K .
For instance, ﬁnite ﬁelds are perfect ﬁelds with eﬀective pth roots. Over
perfect ﬁelds having eﬀective pth roots, we can extract the pth root of uni-
variate polynomials with vanishing derivative as follows.
Remark 3.7.11. Let K be a perfect ﬁeld of characteristic char(K) = p > 0
which has eﬀective pth roots. Suppose that f ∈K[x] is a non-constant
polynomial such that f ′ = 0. Then we can eﬀectively compute the unique
polynomial g ∈K[x] such that f = gp . Namely, we saw in the proof of
Proposition 3.7.9.c that f is of the form f = P
i≥0 apixpi . By assumption,
for every i ≥0 such that api ̸= 0, we can compute the element bi ∈K such
that bp
i = api. Then g = P
i≥0 bixi is the desired polynomial.

3.7 Systems of Polynomial Equations
249
Finally, all the tools we need to compute squarefree parts of univariate
polynomials in characteristic p are in place. Ready, steady, go! (American
English: Ready, set, go!)
Proposition 3.7.12. (Squarefree Parts in Characteristic p)
Let K be a perfect ﬁeld of characteristic p > 0 having eﬀective pth roots.
Given a polynomial f ∈K[x]\K , consider the following sequence of instruc-
tions.
1) Calculate s1 = gcd(f, f ′). If s1 = 1, then return f .
2) Check whether we have s′
1 = 0. In this case, s1 = gp for some uniquely
determined polynomial g ∈K[x]. Calculate g, replace f by
fg
s1 =
f
gp−1 ,
and continue with step 1).
3) Compute si+1 = gcd(si, s′
i) for i = 1, 2, . . . until s′
i+1 = 0, i.e. until si+1
is a pth power si+1 = gp for some g ∈K[x]. Then calculate g, replace f
by
fg
s1 , and continue with step 1).
This is an algorithm which computes the squarefree part sqfree(f) of f .
Proof.
If gcd(f, f ′) = 1, the algorithm stops in step 1) and returns the
correct result by Proposition 3.7.9.a. If gcd(f, f ′) ̸= 1, we write f = cf p
1 f2
with c ∈K\{0} and monic polynomials f1, f2 ∈K[x] such that no pth power
of an irreducible polynomial divides f2 . Then we calculate f ′ = cf p
1 f ′
2 and
s1 = gcd(f, f ′) = f p
1 gcd(f2, f ′
2). We let f3 = gcd(f2, f ′
2) and ﬁnd s′
1 = f p
1 f ′
3 .
If now s′
1 = 0, the algorithm executes the second part of step 2). In
this case, f ′
3 = 0 implies f3 = 1, because no pth power of an irreducible
polynomial divides f2 and f3 = gcd(f2, f ′
2) divides f2 . Hence it follows that
s1 = f p
1 , and the polynomial g which is computed in step 2) equals f1 .
Therefore we have
f
gp−1 = f1f2 . Since s1 = f p
1 ̸= 1, we have deg(f1) > 0,
and the algorithm is applied again to a polynomial of smaller degree.
If s′
1 ̸= 0, we calculate s2 = gcd(s1, s′
1) = f p
1 gcd(f3, f ′
3), and so on,
until s′
i+1 = 0 for some i ≥1. This case will eventually happen, since
each iteration lowers the degree of the corresponding polynomial si . When
s′
i+1 = 0, we see as above that si+1 = f p
1 . Thus the polynomial g calculated
in step 3) equals f1 again, and the algorithm is applied to the polynomial
ff1
s1 = f1f2/ gcd(f2, f ′
2) which has clearly a smaller degree than f .
Finally, the correctness of the algorithm in the case s1 ̸= 1 follows from
sqfree(f) = sqfree(f p
1 f2) = sqfree(f1 sqfree(f2))
= sqfree(f1f2/ gcd(f2, f ′
2)) = sqfree(ff1/f p
1 gcd(f2, f ′
2))
= sqfree(ff1/s1)
□
To improve our understanding of this algorithm, we shall now apply it in
two non-trivial concrete cases.

250
3. First Applications
Example 3.7.13. Let K = Z/(5), and let f = x31−2x30−x6+2x5 ∈K[x].
We apply the algorithm of Proposition 3.7.12 to compute the squarefree part
of f .
1) Since f ′ = x30 −x5 , we get s1 = gcd(f, f ′) = x30 −x5 ̸= 1.
2) Since s′
1 = 0, we see that s1 = g5 , where g = x6 −x. So we replace f
by f = fg/s1 = x7 −2x6 −x2 + 2x and start again.
1) Since f ′ = 2x6 −2x5 −2x + 2, we get s1 = gcd(f, f ′) = x5 −1 ̸= 1.
2) Since s′
1 = 0, we see that s1 = g5 , where g = x −1. So we replace f by
f = fg/s1 = x3 + 2x2 + 2x and start again.
1) Since f ′ = −2x2 −x + 2, we get s1 = gcd(f, f ′) = 1. At this point the
algorithm stops and returns sqfree(f) = x3 + 2x2 + 2x.
Using a factorization algorithm, we can check f = x31 −2x30 −x6 +2x5 =
x5(x −1)25(x −2) and sqfree(f) = x3 + 2x2 + 2x = x(x −1)(x −2).
Example 3.7.14. Let K = Z/(3) and f = x6 +x5 −x4 +x2 −x−1 ∈K[x].
When we apply the algorithm of Proposition 3.7.12, we have to perform the
following steps.
1) Since f ′ = −x4 −x3 −x−1, we get s1 = gcd(f, f ′) = x4 +x3 +x+1 ̸= 1.
2) We calculate s′
1 = x3 + 1 ̸= 0.
3) We calculate s2 = gcd(s1, s′
1) = x3 + 1. Since s′
2 = 0, we ﬁnd s2 = g3,
where g = x + 1. Thus we replace f by fg
s1 = x3 + x2 −x −1.
1) Since f ′ = −x −1, we have s1 = gcd(f, f ′) = x + 1 ̸= 1.
2) We calculate s′
1 = 1 ̸= 0.
3) We calculate s2 = 1 and s′
2 = 0. Hence s2 = g3, where g = 1. We
replace f by fg
s1 = x2 −1.
1) Since f ′ = −x, we get s1 = 1. At this point the algorithm stops and
returns sqfree(f) = x2 −1.
Notice that in this case it is important that we divide fg by s1 in the
second execution of step 3), because fg
s2 = f .
Altogether, we may combine Proposition 3.7.9.b and Proposition 3.7.12
by saying that over ﬁelds of characteristic zero and over perfect ﬁelds of
characteristic p > 0 having eﬀective pth roots, we can compute the squarefree
part of a univariate polynomial eﬀectively.
Our next proposition provides the key for reducing the computation of
radicals of zero-dimensional ideals to the univariate case.
Proposition 3.7.15. (Seidenberg’s Lemma)
Let K be a ﬁeld, let P = K[x1, . . . , xn], and let I ⊆P be a zero-dimensional
ideal. Suppose that, for every i ∈{1, . . . , n}, there exists a non-zero polyno-
mial gi ∈I ∩K[xi] such that gcd(gi, g′
i) = 1. Then I is a radical ideal.
Proof.
By Proposition 3.7.9.a, the polynomials g1, . . . , gn are squarefree. We
proceed by induction on n. For n = 1, the principal ideal I ⊆K[x1] contains

3.7 Systems of Polynomial Equations
251
a squarefree polynomial. Therefore it is generated by a squarefree polynomial,
i.e. it is a radical ideal.
Now let n > 1. We write g1 = h1 · · · ht with irreducible polynomials
h1, . . . , ht ∈K[x1]. We claim that I = ∩t
i=1(I + (hi)). For every polynomial
f ∈∩t
i=1(I + (hi)) there are ri ∈I and qi ∈P such that f = ri + qihi
for i = 1, . . . , t. Obviously, we have f · Q
j̸=i hj ∈I for i = 1, . . . , t, and
because of gcd(Q
j̸=1 hj, . . . , Q
j̸=t hj) = 1 we ﬁnd ℓ1, . . . , ℓt ∈K[x1] such
that ℓ1
Q
j̸=1 hj + · · · + ℓt
Q
j̸=t hj = 1 (see Proposition 1.2.8.c). Altogether,
f = Pt
i=1 ℓif Q
j̸=i hj ∈I proves the claim.
Because of this claim and the fact that a ﬁnite intersection of radical ide-
als is again radical, it suﬃces to show that I +(hi) is radical for i = 1, . . . , t.
So we may assume that g1 is irreducible. Hence the ﬁeld L = K[x1]/(g1)
is a ﬁnite K -vector space, and the canonical surjective homomorphism
ϕ : K[x1, . . . , xn] −→L[x2, . . . , xn] satisﬁes ker(ϕ) = (g1) ⊆I . The
ideal J = ϕ(I) is again zero-dimensional, because L[x2, . . . , xn]/J ∼= P/I .
For all i = 2, . . . , n, the polynomials ϕ(gi) = gi ∈L[x2, . . . , xn] satisfy
gcd(gi, g′
i) = 1 again. Therefore J is a radical ideal by the inductive hy-
pothesis, i.e. we have no non-zero nilpotents in L[x2, . . . , xn]/J . The above
isomorphism shows that also P/I has no non-zero nilpotents, hence I is a
radical ideal.
□
As a consequence of Seidenberg’s Lemma, we can now prove the following
straightforward algorithm for computing the radical of a zero-dimensional
polynomial ideal.
Corollary 3.7.16. (Computation of Radicals of Zero-Dimensional
Ideals)
Let K be a ﬁeld of characteristic zero or a perfect ﬁeld of characteristic p > 0
having eﬀective pth roots. Then the following algorithm computes the radical
of a zero-dimensional ideal I in K[x1, . . . , xn].
1) For i = 1, . . . , n compute a generator gi ∈K[xi] of the elimination ideal
I ∩K[xi].
2) Using Proposition 3.7.9.b or Proposition 3.7.12, compute sqfree(g1), . . . ,
sqfree(gn) and return the ideal I + (sqfree(g1), . . . , sqfree(gn)).
Proof.
By Proposition 3.7.1.c, the polynomials g1, . . . , gn are non-zero. Since
the ideal J = I + (sqfree(g1), . . . , sqfree(gn)) satisﬁes I ⊆J ⊆
√
I , we have
√
I =
√
J . For i = 1, . . . , n, let hi = sqfree(gi). By Proposition 3.7.9.d, the
polynomials hi satisfy gcd(hi, h′
i) = 1. Thus Seidenberg’s Lemma yields the
claim.
□
Notice that the ideal J = I +(sqfree(g1), . . . , sqfree(gn)) returned by this
algorithm satisﬁes J ∩K[xi] = (sqfree(gi)) for i = 1, . . . , n. Next, we want to
see the above algorithm working in practice. It allows us to replace a system
of polynomial equations by another one which has the same set of solutions,
but corresponds to an ideal which is usually larger.

252
3. First Applications
Example 3.7.17. Let us consider the following system S over the polyno-
mial ring P = Q[x, y, z].



















y2 −
2
375xz + 22
75yz +
29
1500z2 + 2
75x −7
15y −
7
150z = 0
xy + 31
150xz −1
5yz −1
50z2 −8
15x + y + 1
10z = 0
x2 −7
15xz + 4yz + 2
5z2 + 7
3x −20y −2z = 0
z3 + 6
5xz + 24yz −38
5 z2 −6x −120y + 13z = 0
yz2 −3
25xz −47
5 yz + 3
50z2 + 3
5x + 22y −3
10z = 0
xz2 −7xz + 10x = 0
The associated ideal I ⊆P , i.e. the ideal generated by the left-hand sides of
the equations in S , satisﬁes dimQ(P/I) = 7, as we can compute for instance
using Buchberger’s Algorithm 2.5.5 and Macaulay’s Basis Theorem 2.4.11.
The upper bound for the number of solutions of S given by Proposition 3.7.5
is therefore 7.
Now we compute the three generators g1 , g2 , and g3 of the elimination
ideals I ∩Q[x], I ∩Q[y], and I ∩Q[z]. We obtain g1 = x4 + 2x3 −3x2 ,
g2 = y4 + 4
5y3 +
1
20y2 −
1
20y, and g3 = z4 −12z3 + 45z2 −50z. Then we
use Proposition 3.7.9.b to calculate sqfree(g1) = x3 + 2x2 −3x, sqfree(g2) =
y3 + 3
10y2 −1
10y, and sqfree(g3) = z3 −7z2 + 10z.
By adding these three equations to the system, we obtain a larger system
of polynomial equations with the same set of solutions. Let us try to use
Proposition 3.7.5 again to bound the number of solutions. By computing a
Gr¨obner basis of the associated ideal, we see that the new system of equations
can be replaced by



















z2 + 6
5x + 24y −13
5 z = 0
x2 + 7
5x −12y −6
5z = 0
xy −3
25x + 3
5y + 3
50z = 0
y2 +
7
250x + 9
25y −
7
500z = 0
xz −2x = 0
yz −3
25x −22
5 y + 3
50z = 0
This time Macaulay’s Basis Theorem yields dimQ(P/J) = 4, i.e. we get a
better bound for the number of solutions. Is this a good bound? Our next
goal is to show that it is in fact optimal, i.e. that 4 is exactly the number of
solutions of S .
For a system of equations f1 = · · · = fs = 0 corresponding to a zero-
dimensional radical ideal I = (f1, . . . , fs), and for a perfect base ﬁeld K ,
the solutions of the system are simple zeros of I in the sense of the following
proposition. We note that a ﬁnite intersection of maximal ideals in P is
clearly a radical ideal.

3.7 Systems of Polynomial Equations
253
Proposition 3.7.18. Let I be a zero-dimensional radical ideal in P , let K
be the algebraic closure of K , and let P = K[x1, . . . , xn].
a) There are only ﬁnitely many maximal ideals m1, . . . , mt of P contain-
ing I , and the ideal I is their intersection I = m1 ∩· · · ∩mt.
b) If K is a perfect ﬁeld, then also the ideal IP is a radical ideal. In par-
ticular, the ideal IP is again the intersection of the ﬁnite set of maximal
ideals containing it.
Proof.
First we show claim a). Every maximal ideal m containing I is zero-
dimensional by Corollary 3.7.3.a. Therefore also mP is zero-dimensional by
Corollary 3.7.3.c. By the Finiteness Criterion 3.7.1.a, this implies that Z(mP)
is ﬁnite. So, there are ﬁnitely many maximal ideals m1, . . . , mu of P contain-
ing m P , and for each of those we have mi∩P = m. Using the same reasoning,
we also see that IP is contained in only ﬁnitely many maximal ideals of P ,
and then it follows that I is contained in only ﬁnitely many maximal ideals
m1, . . . , mt of P . Every element f of m1 ∩· · · ∩mt lies in all maximal ideals
of P containing IP . By Corollary 2.6.17, we therefore have f ∈
√
I = I .
Altogether, we get I = m1 ∩· · · ∩mt.
Now we prove b). We note that, for i = 1, . . . , n, the Finiteness Crite-
rion 3.7.1.c says that the ideal I ∩K[xi] is a principal ideal generated by a
non-zero polynomial gi ∈K[xi]. Because of the assumption that I is radical,
the generator gi of I ∩K[xi] has to be squarefree. Then we use the assump-
tion that K is perfect and Proposition 3.7.9.d to see that gcd(gi, g′
i) = 1.
Hence, by Proposition 1.2.8.c, there exist polynomials hi, ˜hi ∈K[xi] such
that 1 = higi + ˜hig′
i . This equation continues to hold in K[xi]. Thus we also
have gcd(gi, g′
i) = 1 if we view gi and g′
i as elements of P . Now we may
apply Seidenberg’s Lemma 3.7.15 to IP , and the proof is complete.
□
If the system of polynomial equations S corresponds to a zero-dimensional
radical ideal, and if the base ﬁeld is perfect, the bound for the number of
solutions given in Proposition 3.7.5 is sharp, i.e. we have the following formula
for the exact number of solutions.
Theorem 3.7.19. (Exact Number of Solutions)
Let I be a zero-dimensional radical ideal in P , let K be the algebraic closure
of K , and let P = K[x1, . . . , xn]. If K is a perfect ﬁeld, the number of
solutions of the system of equations S is equal to the number of maximal
ideals of P containing IP , and this number is precisely dimK(P/I).
Proof.
Using Proposition 3.7.18.a, we write I = m1 ∩· · · ∩mt with maximal
ideals m1, . . . , mt of P , and we write mi P = mi1 ∩· · · ∩miµi with maximal
ideals mi1, . . . , miµi of P for i = 1, . . . , t. Then the Chinese Remainder
Theorem 3.7.4.b and Corollary 3.7.3.c allow us to calculate
dimK(P/I)=
tP
i=1
dimK(P/mi) =
tP
i=1
dimK(P/m P)

254
3. First Applications
=
tP
i=1
µi
P
j=1
dimK(P/mij) =
tP
i=1
µi
The last equality follows from Corollary 2.6.9. The number Pt
i=1 µi is ex-
actly the number of maximal ideals of P containing IP , i.e. the number of
solutions of S .
□
Now we know that the number of solutions of the system S in Exam-
ple 3.7.17 is precisely 4. Can we ﬁnd them?
Example 3.7.20. Consider the second system of polynomial equations con-
tained in Example 3.7.17. Notice that the equation xz −2x = 0 can be
factored into x(z −2) = 0. As in high school, we can split the system into
two systems S1 and S2 . After interreducing the generators, these systems
are given by



z −2 = 0
x + 20y −1 = 0
y2 −1
5y = 0
and



x = 0
y + 1
10z = 0
z2 −5z, = 0
Now it is easy to get the four solutions (1, 0, 2), (−3, 1
5, 2), (0, 0, 0), (0, −1
2, 5).
Of course, most of the time we cannot use tricks like this one. Therefore
we need a general strategy for ﬁnding the solutions. Such a strategy will be
developed in the next subsection.
3.7.C
Solving Systems Eﬀectively
As a consequence of the above discussions, we shall from now on assume that
we want to solve a system of polynomial equations f1 = . . . = fs = 0 such
that I = (f1, . . . , fs) is a zero-dimensional radical ideal in P = K[x1, . . . , xn].
Our next goal is to perform a linear change of coordinates in such a way that
the resulting system of equations has the additional property that its solutions
in K
n have pairwise distinct last coordinates. Let us introduce the following
name for this property.
Deﬁnition 3.7.21. Suppose that I is a zero-dimensional ideal in P , and
let i ∈{1, . . . , n}. We say that I is in normal xi-position if any two zeros
(a1, . . . , an), (b1, . . . , bn) ∈K
n of I satisfy ai ̸= bi .
To bring a given zero-dimensional ideal into normal xn-position, we may
have to extend the base ﬁeld (if it is ﬁnite) and to perform a linear change
of coordinates. Our next proposition gives a precise condition when this is
possible.

3.7 Systems of Polynomial Equations
255
Proposition 3.7.22. Suppose that I is a zero-dimensional ideal in P , let
t = dimK(P/I), and assume that the ﬁeld K contains more than
¡t
2
¢
ele-
ments. Then there exists a tuple (c1, . . . , cn−1) ∈Kn−1 such that
c1a1 + · · · + cn−1an−1 + an ̸= c1b1 + · · · + cn−1bn−1 + bn
for all pairs of zeros (a1, . . . , an), (b1, . . . , bn) ∈K
n of I . Consequently the
linear change of coordinates given by x1 7→x1, . . . , xn−1 7→xn−1 , and by
xn 7→xn −c1x1 −· · · −cn−1xn−1 transforms I into an ideal in normal
xn -position.
Proof.
Let (a1, . . . , an) and (b1, . . . , bn) be two distinct zeros of I in K
n.
In choosing the tuple (c1, . . . , cn−1) ∈Kn−1, we have to avoid the solutions
in Kn−1 of the linear equation
(a1 −b1)x1 + · · · + (an−1 −bn−1)xn−1 = an −bn
These solutions are obtained by adding all solutions of the corresponding
homogeneous equation to one of them. Thus there are at most (#K)n−2 of
them. Altogether, we have to avoid at most
¡t
2
¢
· (#K)n−2 tuples in Kn−1,
which is clearly possible if #K >
¡t
2
¢
.
□
At this point it may be useful to remind the reader that the linear change
of coordinates mentioned in this proposition transforms the ideal I into
the ideal J = (f(x1, . . . , xn−1, xn −c1x1 −· · · −cn−1xn−1) | f ∈I), and
that a point (a1, . . . , an) ∈K
n is a zero of I if and only if the point
(a1, . . . , an−1, an + c1a1 + · · · + cn−1an−1) is a zero of J (see also Exer-
cise 6). To ﬁnish the discussion of how to bring a zero-dimensional ideal into
normal xn -position, it now suﬃces to explain how one can check whether it
already is in normal xn -position. For that, we shall have to pass to its radical
ideal ﬁrst. Then we use the following theorem.
Theorem 3.7.23. Let K be a perfect ﬁeld, let P = K[x1, . . . , xn], let I ⊆P
be a zero-dimensional radical ideal, and let gn be the monic generator of the
ideal I ∩K[xn]. Then the following conditions are equivalent.
a) The ideal I is in normal xn-position.
b) The degree of gn is equal to dimK(P/I).
c) The injection K[xn] ,−→P
induces an isomorphism of K -algebras
K[xn]/(gn) ∼= P/I .
Proof.
By construction, the injection K[xn] ,−→P induces an injective
K -algebra homomorphism K[xn]/(gn) ,−→P/I . In particular, we have
deg(gn) = dimK(K[xn]/(gn)) ≤dimK(P/I). Now claim a) implies b), be-
cause the last component of every zero of I is a zero of gn and gn is square-
free. Hence we have deg(gn) ≥dimK(P/I) by Theorem 3.7.19.
It is clear that b) implies c), because we have an injective K -algebra
homomorphism K[xn]/(gn) ,−→P/I , and both algebras have the same

256
3. First Applications
vector space dimension over K . Thus it remains to prove that c) im-
plies a). We consider the reduced Gr¨obner basis G of I with respect to
an elimination ordering σ for {x1, . . . , xn−1}. By Theorem 3.4.5.c, we have
G ∩K[xn] = {gn}. By Lemma 2.4.16.b, the set G is also the reduced
σ-Gr¨obner basis of IP ∩K[xn], where K is the algebraic closure of K .
Thus the canonical map K[xn]/(gn) −→P/IP is injective. Using the hy-
pothesis, we see that deg(gn) = dimK(P/I), and Corollary 3.7.3.c shows
dimK(P/I) = dimK(P/IP). Hence the map K[xn]/(gn) −→P/IP is bijec-
tive.
By Theorem 3.7.19, the degree of gn equals the number of zeros of I .
Let d = deg(gn), and let a1, . . . , ad ∈K be the zeros of gn . The maxi-
mal ideals of the quotient ring K[xn]/(gn) are the principal ideals gener-
ated by the residue classes of xn −ai for i = 1, . . . , d. Under the above
isomorphism, they correspond to maximal ideals mi of P/IP . By Corol-
lary 2.6.9, each ideal mi is the residue class ideal of an ideal of the form
(x1 −αi1, . . . , xn −αin) in P , where αi1, . . . , αin ∈K . Since we have
(x1 −αi1, . . . , xn −αin) ∩K[xn] = (xn −an) by construction, it follows
that αin = ai for i = 1, . . . , d. By Proposition 3.7.18.b, the squarefree poly-
nomial gn has pairwise distinct roots a1, . . . , ad. Therefore we see that the
last coordinates of the zeros {(αi1, . . . , αin) | i = 1, . . . , d} of I are pairwise
distinct.
□
This theorem can be viewed as a generalization of a well-known result in
ﬁeld theory.
Remark 3.7.24. Let L/K be a ﬁnite ﬁeld extension, i.e. let L ⊇K be
an extension ﬁeld which is a ﬁnite dimensional K -vector space. Since every
K -basis of L is also a system of generators of the K -algebra L, there exists
a presentation L ∼= P/I , where P = K[x1, . . . , xn] is a polynomial ring
over K , and where I ⊆P is a maximal ideal.
Let t = dimK(L). If the ﬁeld K is perfect and has more than
¡t
2
¢
ele-
ments, we can use Proposition 3.7.22 to ﬁnd a linear change of coordinates
such that the transform of I is in normal xn -position. Then condition c) of
the theorem shows that L is of the form L ∼= K[x]/(g) with an irreducible
polynomial g ∈K[x]. In other words, viewed as a K -algebra, the ﬁeld L is
generated by a single element.
In ﬁeld theory, this result is called the Primitive Element Theorem.
Although we are not going to treat this subject in greater detail, let us men-
tion that the assumption that K is a perfect ﬁeld is essential for the Primitive
Element Theorem to hold, whereas the assumption that K has more than
¡t
2
¢
elements can easily be dispensed with (see also Exercise 8).
The reason why we wanted to reduce our problem of solving a system of
polynomial equations f1 = · · · = fs = 0 to the case when I = (f1, . . . , fs) is a
zero-dimensional radical ideal in normal xn -position is the following theorem.
It says that, in this situation, the reduced Lex-Gr¨obner basis of I has a

3.7 Systems of Polynomial Equations
257
very special shape. That is why it is sometimes called the Shape Lemma.
Moreover, the special shape of this Gr¨obner basis enables us to write down
formulas for all solutions of S in terms of the roots of a generator gn of
I ∩K[xn].
Theorem 3.7.25. (The Shape Lemma)
Let K be a perfect ﬁeld, let I ⊆P be a zero-dimensional radical ideal in
normal xn -position, let gn ∈K[xn] be the monic generator of the elimination
ideal I ∩K[xn], and let d = deg(gn).
a) The reduced Gr¨obner basis of the ideal I with respect to Lex is of the
form {x1 −g1, . . . , xn−1 −gn−1, gn}, where g1, . . . , gn−1 ∈K[xn].
b) The polynomial gn has d distinct zeros a1, . . . , ad ∈K , and the set of
zeros of I is
Z(I) = {(g1(ai), . . . , gn−1(ai), ai) | i = 1, . . . , d}
Proof.
Since b) follows from a) by applying Theorem 3.7.19 to the zero-
dimensional radical ideal (gn) ⊆K[xn], it suﬃces to prove claim a). From
Theorem 3.7.23.c we deduce that, for each i ∈{1, . . . , n}, the residue class
xi + I is a K -linear combination of 1 + I, . . . , xd−1
n
+ I . Hence there exist
g1, . . . , gn−1 ∈K[xn] such that xi −gi ∈I for i = 1, . . . , n−1. Now we show
that {x1 −g1, . . . , xn−1 −gn−1, gn} is the reduced Lex-Gr¨obner basis of I .
Since those polynomials are in I , we have (x1, . . . , xn−1, xd
n) ⊆LTLex(I), and
Macaulay’s Basis Theorem 1.5.7 implies that this is an equality. Therefore
{LTLex(g1), . . . , LTLex(gn)} is a minimal system of generators of LTLex(I).
Furthermore, since deg(gi) < d for i = 1, . . . , n −1, the elements of this
Gr¨obner basis are fully reduced.
□
The last result of this section, its highlight, and in some sense also its
true beginning, is the following corollary. It combines everything we learned
before and gives a detailed recipe for solving systems of polynomial equations
eﬀectively, albeit not necessarily eﬃciently.
Corollary 3.7.26. (Solving Systems Eﬀectively)
Let K be a ﬁeld of characteristic zero or a perfect ﬁeld of characteristic p > 0
having eﬀective pth roots. Furthermore, let f1, . . . , fs ∈P = K[x1, . . . , xn],
and let I = (f1, . . . , fs). Consider the following sequence of instructions.
1) For i = 1, . . . , n, compute a generator gi of the elimination ideal
I ∩K[xi]. If gi = 0 for some i ∈{1, . . . , n}, then return "Infinite
Solution Set" and stop.
2) Depending on the characteristic of K , use Proposition 3.7.9.b or Propo-
sition 3.7.12 to compute hi = sqfree(gi) for i = 1, . . . , n. Then replace I
by I + (h1, . . . , hn).
3) Compute d = #(Tn \ LTσ{I}).
4) Check if deg(hn) = d. In this case, let (c1, . . . , cn−1) = (0, . . . , 0) and
continue with step 8).

258
3. First Applications
5) If K is ﬁnite, enlarge it so that it has more than
¡d
2
¢
elements.
6) Choose (c1, . . . , cn−1) ∈Kn−1 . Apply the coordinate transformation
x1 7→x1, . . ., xn−1 7→xn−1 , xn 7→xn −c1x1 −· · · −cn−1xn−1 to I
and get an ideal J .
7) Compute a generator of J ∩K[xn] and check if it has degree d. If not,
repeat steps 6) and 7) until this is the case. Then rename J and call it I .
8) Compute the reduced Gr¨obner basis of I with respect to Lex. It has the
shape {x1 −g1, . . . , xn−1 −gn−1, gn} with polynomials g1, . . . , gn ∈K[xn]
and with deg(gn) = d. Return the tuples (c1, . . . , cn−1) and (g1, . . . , gn)
and stop.
This is an algorithm which decides whether the system of polynomial equa-
tions S given by f1 = · · · = fs = 0 has ﬁnitely many solutions. In that case,
it returns tuples (c1, . . . , cn−1) ∈Kn−1 and (g1, . . . , gn) ∈K[xn]n such that,
after we perform the linear change of coordinates x1 7→x1, . . . , xn−1 7→xn−1 ,
xn 7→xn −c1x1 −· · · −cn−1xn−1 , the transformed system of equations
has the set of solutions {(g1(ai), . . . , gn−1(ai), ai) | i = 1, . . . , d}, where
a1, . . . , ad ∈K are the zeros of gn .
In other words, the original system of equations has the set of solutions
{(g1(ai), . . . , gn−1(ai), ai −c1g1(ai) −· · · −cn−1gn−1(ai)) | i = 1, . . . , d}.
Proof.
The fact that step 1) checks correctly whether Z(I) is ﬁnite follows
from Proposition 3.7.1. By Corollary 3.7.16, the ideal I is replaced by its
radical
√
I in step 2). As we noticed after the proof of Corollary 3.7.16, we
have
√
I∩K[xi] = (hi) for i = 1, . . . , n. Now Theorem 3.7.19 and Macaulay’s
Basis Theorem 1.5.7 imply that the number d computed in step 3) is exactly
the number of solutions of our system of equations.
The ideal I is in normal xn -position if and only if the degree of a gen-
erator of I ∩K[xn] is d (see Theorem 3.7.23). This is checked in step 4). If
it does not hold, we have to ﬁnd a suitable linear change of coordinates. In
step 5) we enlarge the ﬁeld K if necessary so that the hypothesis of Propo-
sition 3.7.22 is satisﬁed. Then this proposition says that we eventually ﬁnd
a tuple (c1, . . . , cn−1) ∈Kn−1 in step 6) such that the corresponding linear
change of coordinates puts I into normal xn -position. In step 7) we check
whether this has happened, and if not, we repeat step 6). Finally we are in
the situation of the Shape Lemma. It yields the correctness of step 8) and
the claim of the corollary.
□
For more advanced readers we note that when we work over a ﬁnite ﬁeld K
and we arrive at step 6) of this algorithm, we can perform an exhaustive
search of all tuples (c1, . . . , cn−1) ∈Kn−1, and Proposition 3.7.22 guarantees
that we will eventually ﬁnd a suitable coordinate transformation. In the case
of an inﬁnite base ﬁeld K , choosing random tuples (c1, . . . , cn−1) ∈Kn−1
seems to yield only a probabilistic algorithm, but using more reﬁned tools
one could show that it is actually deterministic.

3.7 Systems of Polynomial Equations
259
Of course, if K = Q and if the zeros of the polynomial gn can be repre-
sented using radicals, then this corollary provides us with actual formulas for
the solutions of our system of equations S . More generally, if we accept the
zeros a1, . . . , ad ∈K of gn as symbols denoting certain algebraic numbers
over K , we still get formulas for the solutions of S in terms of those sym-
bols. If we want the minimal polynomials over K of the coordinates of those
solutions, we can compute them using the methods described in Tutorial 17.
We end this section with an example which shows how one can apply the
preceding algorithm in a concrete case.
Example 3.7.27. Let us consider the following system of equations over
K = Q. Let f1 = x2
1+x2
2+x2
3−9, f2 = 3x2
1−x2
2x3 , and f3 = x2
1x3−2x2
2+2 be
three polynomials in P = Q[x1, x2, x3] which deﬁne a system of polynomial
equations f1 = f2 = f3 = 0. We let I = (f1, f2, f3) and follow the steps of
the algorithm in Corollary 3.7.26.
1) We compute I ∩Q[xi] = (gi) for i = 1, 2, 3 and get the polynomials
g1 = x6
1 +12x4
1 −12x2
1 −32 ̸= 0, g2 = x8
2 −16x6
2 −9x4
2 +108x2
2 +108 ̸= 0,
and g3 = x4
3 −15x2
3 −2x3 + 48 ̸= 0.
2) Since gcd(gi, g′
i) = 1 for i = 1, 2, 3, those polynomials are squarefree
and I is a radical ideal.
3) We compute d = #(T3 \ LTLex(I)) = 16. Thus the number of solutions
is 16.
4) Since deg(g3) = 4 < 16, the ideal I is not yet in normal x3 -position.
5) Nothing has to be done, because K = Q is inﬁnite.
6) We choose (c1, c2) = (−1, −1) and apply the corresponding coordinate
transformation x1 7→x1 , x2 7→x2 , x3 7→x1 + x2 + x3 to compute J .
7) We compute a generator h3 of J ∩Q[x3] and get the polynomial h3 =
x16
3 −72x14
3 +16x13
3 +· · ·−338 079 047. Therefore the ideal J is in normal
x3 -position. We rename J and call it I .
8) We compute the reduced Gr¨obner basis of I with respect to Lex and
get {x1 −c15x15
3 −· · · −c0, x2 −d15x15
3 −· · · −d0, h3} with numbers
c0, . . . , c15, d0, . . . , d15 ∈Q which have approximately 30-digit numer-
ators and denominators. Then we let h1 = c0 + · · · + c15x15 and
h2 = d0+· · ·+d15x15 , and we return the tuples (−1, −1) and (h1, h2, h3).
Hint: If this calculation takes very long on your computer, you may want
to ﬁrst enlarge the system of generators of I by adding to it elements of
other Gr¨obner bases, e.g. with respect to the various elimination order-
ings.
The meaning of this result is that we can write the 16 solutions of S
as triples whose coordinates are polynomials in the zeros a1, . . . , a16 ∈Q
of h3 . In this particular example, there exists a way how we can simplify the
computation. If we factor g3 , we get g3 = (x3 −2)(x3
3 + 2x2
3 −11x3 −24).
Therefore, instead of S , we can also solve the following two systems of poly-
nomial equations.

260
3. First Applications
1) If x3 = 2, we have the new system of equations



x2
1 + x2
2 −5 = 0
3x2
1 −2x2
2 = 0
x2
1 −x2
2 + 1 = 0
which easily yields the solutions (±
√
2, ±
√
3, 2) of the original system S .
2) In the system of equations f1 = f2 = f3 = 0 and x3
3+2x2
3−11x3−24 = 0,
the indeterminates x1 and x2 appear only quadratically. Thus we may
substitute y1 = x2
1 , y2 = x2
2 , and y3 = x3 , and solve the system of
equations





h1 = y1 + y2 + y2
3 −9 = 0
h2 = 3y1 −y2y3 = 0
h3 = y1y3 −2y2 + 2 = 0
h4 = y3
3 + 3y2
3 −11y3 −24 = 0
That system of equations simpliﬁes in a straightforward way, and we get
y1 = 4y2
3 −2y3 −40 and y2 = −5y2
3 +2y3 +49, so that the three solutions
of h4 = 0 each give rise to four solutions of our original system S .
Exercise 1. Prove that a ﬁeld K is perfect if and only if the following
two conditions are equivalent for every polynomial f ∈K[x] \ K .
a) The polynomial f is squarefree.
b) We have gcd(f, f ′) = 1.
Exercise 2. Let p be a prime number, let K = Fp be the ﬁeld with p
elements, and let f ∈K[x].
a) Write a CoCoA function IsPPower(. . .) which checks whether f is
of the form f = gp with a polynomial g ∈K[x] and returns the
corresponding Boolean value.
b) Write a CoCoA function PRoot(. . .) which takes a polynomial f of the
form f = gp such that g ∈K[x] and computes g.
Exercise 3. Prove that a zero-dimensional prime ideal of P is maximal.
Hint: Use Proposition 3.7.18.a.
Exercise 4. Find an example of a ﬁeld K and a radical ideal I ⊆K[x]
such that I · K[x] is not radical, where K is the algebraic closure of K .
Hint: Look at the polynomial xp −y ∈Z/(p)(y)[x].
Exercise 5. Let f = x5 −4x4 + 10x2 −x −3 ∈Q[x]. Using for instance
the CoCoA function Factor(. . .), check that its factorization in Q[x] is
f = f1 · f2 , where f1 = x3 −3x2 + 1 and f2 = x2 −x −3.
a) Let g = x3 + ax2 + bx + c and h = x2 + dx + e be polynomials
in Q[x, a, b, c, d, e]. We set f = g · h and compare the coeﬃcients
for the diﬀerent powers of x. Solve the corresponding system S of
polynomial equations and recover the above factorization.

3.7 Systems of Polynomial Equations
261
b) Let K = Q[e]/(e3 −3e −1), and let ε be the image of e in K . By
computing the reduced Lex-Gr¨obner basis of the ideal associated with
the system S , show that g = x3 + (ε2 −4)x2 −ε2x −3(ε2 −3) and
h = x2 −ε2x + ε in K[x] satisfy f = g · h.
c) Do a) and b) contradict the unique factorization property of K[x]?
Hint: Show that h | f1 in K[x].
d) Find the complete factorization of f in K[x], and then in Q[x].
Exercise 6. Let K be a ﬁeld, let I be an ideal in P = K[x1, . . . , xn],
let (c1, . . . , cn−1) ∈Kn−1 , and let ϕ : P −→P be the linear change
of coordinates which is deﬁned by x1 7→x1, . . . , xn−1 7→xn−1 , and by
xn 7→xn −c1x1 −· · · −cn−1xn−1 .
a) Show that ϕ is a K -algebra isomorphism and describe J = ϕ(I).
b) Prove that a tuple (a1, . . . , an) ∈K
n is a zero of I if and only if the
tuple (a1, . . . , an−1, an + c1a1 + · · · + cn−1an−1) is a zero of J .
Exercise 7. Let P = Q[x1, . . . , xn], and let I ⊆P be a zero-dimensional
radical ideal.
a) Write a CoCoA function IsNormalPos(. . .) which checks whether I is
in normal xn -position and returns the corresponding Boolean value.
b) Write a CoCoA function NormalPosTrafo(. . .) which computes a tuple
of rational numbers (c1, . . . , cn−1) ∈Qn−1 such that the linear change
of coordinates which is deﬁned by x1 7→x1 , . . ., xn−1 7→xn−1 , and
by xn 7→xn −c1x1 −· · · −cn−1xn−1 transforms I into an ideal in
normal xn -position. (Of course, if I is already in normal xn -position,
your function should return the zero vector.)
Exercise 8. Let K be a perfect ﬁeld, and let L/K be a ﬁnite ﬁeld
extension. Prove that there exists an irreducible polynomial g ∈K[x] and
an isomorphism L ∼= K[x]/(g). (Hint: If K is ﬁnite, look at Tutorial 3.)
Tutorial 42: Strange Polynomials
Let us remind you of Section 0.10 in the introduction of this book. There we
claimed that even polynomials in a single indeterminate over a ﬁeld are not as
simple as one would think. Of course, you are familiar with the phenomenon
where one multiplies two polynomials, and a lot of cancellation occurs so
the result is simpler than either of the factors. But what about the following
claim? Given any ε > 0, there exists a polynomial f ∈Q[x] such that
the number of terms of Supp(f 2) is less than ε times the number of terms
of Supp(f). Would you believe this? For instance, with ε = 0.001 we are
talking about a polynomial which has a thousand times more terms than its
square. If you doubt that such a polynomial could ever exist, do not worry.
Below you will prove it.
In this tutorial, we shall show you how to construct some strange polyno-
mials, i.e. some polynomials having unexpected properties. For a polynomial

262
3. First Applications
f ∈Q[x], we let ℓ(f) = # Supp(f). We shall say that f is a dense poly-
nomial if ℓ(f) = deg(f) + 1. To get started, we treat the following question.
Is it possible that f is dense, but f 2 is not?
In the remainder of this tutorial, we let f ∈Q[x] be a dense univariate
polynomial of degree d = deg(f) > 0. We let f = adxd +ad−1xd−1 +· · ·+a0 ,
where a0, . . . , ad ∈Q.
a) Show that if deg(f) = 1, then f 2 is dense.
b) Show that if deg(f) ≥2, then ℓ(f 2) ≥4.
c) Let a ∈Q\{0}. Show that the following maps Ti : Q[x] −→Q[x] induce
bijective maps on the set of dense polynomials which preserve both ℓ(f)
and ℓ(f 2).
1) T1(f) = af
2) T2(f) = f(ax)
3) T3(f) = xdf( 1
x)
d) Using T1 , show that, for answering our question, we may assume that f
is monic.
e) Assume that f is monic, i.e. that we have f = xd + ad−1xd−1 + · · · + a0 .
Consider a0, . . . , ad−1 as indeterminates over Q. Next, write f 2 in the
form f 2 = x2d+b2d−1x2d−1+· · ·+b0 with b0, . . . , b2d−1 ∈Q[a0, . . . , ad−1].
Prove that deg(bi) ≤2 for i = 0, . . . , 2d −1.
f) Prove that there exists a non-empty Zariski-open subset U ⊆Ad
Q such
that, for every (a0, . . . , ad−1) ∈U , the corresponding monic polynomial f
satisﬁes ℓ(f 2) = 2 deg(f)+1, i.e. it has a dense square. (For the deﬁnition
of the Zariski topology on Ad
Q , see Tutorial 27.)
g) For f = x2 + a1x + a0 , describe the set U explicitly. Find an example
such that ℓ(f) < 5 = 2 deg(f) + 1.
h) Show that if deg(f) = 2 and f is dense, then 4 ≤ℓ(f 2) ≤5. Hence
quadratic polynomials satisfy ℓ(f) < ℓ(f 2).
i) Show that 4 is the ﬁrst degree for which there exists a dense polynomial
f ∈Q[x] with ℓ(f) = ℓ(f 2). Exhibit such an example.
Altogether, we have shown that there exists a maximum value for ℓ(f 2),
namely 2 deg(f) + 1, which is achieved by most polynomials, but there are
examples where this maximum is not achieved. In fact, we have seen that
ℓ(f 2) = ℓ(f) = deg(f) + 1 is possible. Now we become even more ambitious
and ask the following question.
Is it possible that f is dense and ℓ(f 2) < ℓ(f)?
Our next goal is to show that this question has a positive answer, too.
But in order to ﬁnd an example of such a polynomial, one has to go at least
to degree 12. More precisely, we shall explain how you can prove that there
are no examples of degree ≤11.

3.7 Systems of Polynomial Equations
263
As before, we let f = xd + ad−1xd−1 + · · · + a0 ∈Q[x] be a dense polyno-
mial. The ﬁrst possibility for ℓ(f 2) < ℓ(f) = d + 1 occurs when ℓ(f 2) = d.
It turns out to be easiest to look for f such that ℓ(f 2) ≤d.
j) Consider the polynomial
f = (x6 + 2
5x5 −2
25x4 +
4
125x3 −
2
125x2 +
2
125x +
1
125)(x6 + α)
where α is one of the six values α1 = −1
110 , α2 = −1
253 , α3 = −2
55 ,
α4 =
1
15625·α1 = −110
15625 , α5 =
1
15625·α2 = −253
15625 , or α6 =
1
15625·α3 =
−11
6250 . Use CoCoA to check that ℓ(f) = 13, while ℓ(f 2) = 12.
For instance, in the case α1 = −1
110 , we obtain the example printed in
Section 0.10.
k) Apply T2 and T1 to the above polynomial f to produce another dense
polynomial g of degree 12 such that g = x12 + x11 + · · · and ℓ(g2) = 12.
l) Show that there exist ﬁnitely many systems of d+2 polynomial equations
over the ring Q[a0, . . . , ad−2, x] such that at least one of them has a
solution if and only if there exists a dense polynomial f which satisﬁes
ℓ(f 2) ≤d.
Hint: In view of part i), it suﬃces to consider the case d ≥4. Using T1
and T2 , we may assume that ad = ad−1 = 1 and that the coeﬃcients
b2d, b2d−1, b1, b0 of f 2 are diﬀerent from zero. Therefore at least d + 1
coeﬃcients of f 2 among the remaining 2d−3 have to vanish. Finally, we
need to add one equation which expresses the fact that the coeﬃcients
of f are non-zero (see Proposition 3.5.6).
m) Let d = 5. Write a CoCoA program StrangeSystems(. . .) which ﬁnds
the ideals associated to the systems described in part l). Then use Corol-
lary 2.6.14 and suitable Gr¨obner basis computations with CoCoA to show
that there is no dense polynomial f ∈Q[x] of degree ﬁve such that
ℓ(f 2) ≤5.
n) Try to do the computation for d = 6 and higher. Be careful that, as
the degree of f increases, the number of systems to be checked grows
tremendously. Give an estimate of this number depending on deg(f).
In the last part of this tutorial, we shall show that even the following
daring question has a positive answer.
For every ε > 0, is there a dense f ∈Q[x] with ℓ(f 2) < ε · ℓ(f)?
o) Let f ∈Q[x] be a dense polynomial. Show that g(x) = f(x) · f(x2d+1)
satisﬁes ℓ(g) = ℓ(f)2 . (Hint: Think of g as consisting of d + 1 copies
of f , multiplied by various terms and scalars.)
p) In the situation of o), show that ℓ(g2) = ℓ(f 2)2 . (Hint: Let h = f 2 and
note that g(x)2 = h(x) · h(x2d+1).)
q) Now let f be one of the polynomials in j), and let g(x) = f(x) · f(x25).
Show that
ℓ(g2)
ℓ(g) =
³
ℓ(f 2)
ℓ(f)
´2
= ( 12
13)2 . By repeating this process, prove
that the above question has a positive answer.

264
3. First Applications
Tutorial 43: Primary Decompositions
Although the computation of the primary decomposition of a polynomial
ideal is one of the most advanced operations in Computational Commutative
Algebra, we shall now try to perform the ﬁrst few steps in this direction.
Naturally, this tutorial requires somewhat higher algebraic skills than the
ones before.
Given a ring R, an ideal q ⊂R is called a primary ideal if every
zerodivisor in R/q is a nilpotent element. Equivalently, we are asking that,
for all a, b ∈R such that ab ∈q and a /∈q, there exists a number i ≥1 such
that bi ∈q.
In the sequel we assume that R is a Noetherian ring.
a) Prove that the radical of a primary ideal q is a prime ideal p. We shall
say that the ideal q is p-primary.
b) Prove that an ideal q in R is p-primary if and only if there exists exactly
one associated prime of R/q, namely the prime p. (For the deﬁnition of
an associated prime, see Tutorial 31.e.)
c) An ideal q in R is called irreducible if it cannot be written as the
intersection of two ideals, both of which properly contain it. Show that
every irreducible ideal q in R is a primary ideal.
Hint: Assume that there are two diﬀerent associated primes of R/q and
deduce a contradiction.
d) Using c) and the fact that R is Noetherian, prove that every ideal in R
can be written as a ﬁnite intersection of primary ideals. Such a represen-
tation is called a primary decomposition of the ideal.
Hint: Consider the largest ideal in R which is not an intersection of
ﬁnitely many irreducible ideals.
In the remaining part of this tutorial, we want to compute primary de-
compositions for zero-dimensional ideals in the ring P = K[x1, . . . , xn] over
a perfect ﬁeld K . If char(K) = p > 0, we also assume that K has eﬀective
pth roots. We have seen that one can compute
√
I in this case, and that
√
I
is the intersection of ﬁnitely many maximal ideals in P .
e) Write a CoCoA function ZeroDimRad(. . .) which takes a zero-dimensional
ideal I ⊆P and computes
√
I using the method of Corollary 3.7.16.
Hint: The base ﬁeld K is Q or Fp . You may want to use the function
SqFree(. . .) from Tutorial 5.
f) Apply your function ZeroDimRad(. . .) to compute the radicals of the
following zero-dimensional ideals.
1) I1 = (x3, x2y + x, y2) in Q[x, y]
2) I2 = (x27 + y27 + 1, x18 −x9y9 −x9) in Z/(3)[x, y]
3) I3 = (z2, y2z + yz, xz + yz, y4 + 2y3 + y2, xy2 + y3 + xy + y2,
x2 + 2xy + y2) in Q[x, y, z]
4) I4 = (z7, y98 + y49, x49 + y49) in Z/(7)[x, y, z]

3.7 Systems of Polynomial Equations
265
g) Suppose that
√
I = m1 ∩· · · ∩mt with maximal ideals m1, . . . , mt in P .
For i = 1, . . . , t, let qi = I :P (I :P m∞
i ). Show that qi is a mi -primary
ideal for i = 1, . . . , t, and that I = q1∩· · ·∩qt is a primary decomposition
of I .
Hint: Start with a primary decomposition I = q′
1 ∩· · · ∩q′
u . Show that
u = t and that we can assume mi =
p
q′
i for i = 1, . . . , t. Then apply
the Chinese Remainder Theorem 3.7.4 to P/I and prove q′
i = qi for
i = 1, . . . , t.
Thus we can reduce the computation of a primary decomposition of a
zero-dimensional ideal to the case of a zero-dimensional radical ideal. From
now on, let I be a zero-dimensional radical ideal in P .
h) Write a CoCoA function IsNormalPos(. . .) which checks whether I is in
normal xi -position for some i ∈{1, . . . , n} and returns FALSE or the
corresponding i.
i) Apply your function IsNormalPos(. . .) to check whether the following
zero-dimensional ideals are in normal xi -position for some i ∈{1, . . . , n}.
1) I5 = (x2 + y2 −1, 4xy −2x −2y + 1) in Q[x, y]
2) I6 = (x2 −y, x2 −3x + 2) in Q[x, y]
3) I7 = (yz + z, y2 + y, x + y + z, z2 −z) in Q[x, y, z]
j) Suppose that I is not in normal xi -position for any i ∈{1, . . . , n}.
Write a CoCoA function NormalPosTrafo(. . .) which computes an index
i ∈{1, . . . , n} and a tuple (c1, . . . , cn−1) ∈Kn−1 such that the linear
change of coordinates which is deﬁned by xj 7→xj for j ̸= i and by
xi 7→xi −c1x1 −· · ·−ci−1xi−1 −cixi+1 −· · ·−cn−1xn transforms I into
an ideal in normal xi -position.
Hint: If char(K) = 0 and if you did Exercise 7, you may use your results.
If char(K) = p > 0, try all possible coordinate changes. In case none of
them works, exit the program with an error message.
k) Use your function NormalPosTrafo(. . .) to ﬁnd transformations which
bring the following ideals into normal xi -position for some i ∈{1, . . . , n}.
1) I8 = (x2 + y2 + 3, x2 −y2 + 1) in Q[x, y]
2) I9 = (xy, x2 + x, y3 + y2 + y) in Z/(2)[x, y]
3) I10 = (x3 −x, y2 + y, z2 −z) in Z/(3)[x, y, z]
In view of the preceding results, we shall from now on assume that there
exists an i ∈{1, . . . , n} such that the ideal I is in normal xi -position.
l) Using Theorem 2.6.6, prove that I ∩K[xj] ̸= (0) for j = 1, . . . , n.
m) Let pi ∈K[xi] be the monic generator of I∩K[xi], and let pi = fi1 · · · fit
be the decomposition of pi into monic irreducible factors. Show that the
polynomials fi1, . . . , fit are pairwise distinct, and that I + (fij) is a
maximal ideal for j = 1, . . . , t.
Hint: Let m and m′ be two maximal ideal containing I + (fij). Show
that m ∩K[xi] = m′ ∩K[xi] = (fij), and that m and m′ are in normal
xi -position. Conclude that m and m′ have the same zeros in K
n .

266
3. First Applications
n) In this situation, let mj = I + (fij) for j = 1, . . . , t. Prove that we have
I = m1 ∩· · · ∩mt.
Hint: Proceed as in the proof of Seidenberg’s Lemma 3.7.15.
o) Find an example of a zero-dimensional radical ideal I ⊆P such that
I ∩K[xi] is a maximal ideal for i = 1, . . . , n, but I is not a maximal
ideal. Thus the assumption about the normal position is essential in the
argument above.
p) Now combine the results achieved so far and develop an algorithm
which computes the primary decomposition of a zero-dimensional radical
ideal I . Implement this algorithm in a CoCoA function RadicalDec(. . .).
Hint: Use the built-in CoCoA function Factor(. . .) to compute the fac-
torization of the element pi .
q) Apply your function RadicalDec(. . .) to compute the primary decompo-
sition of the following zero-dimensional radical ideals.
1) I11 = (y3−2y2−2y−3, xy2+xy−2y2+x−2y−2, 13x2−5y2−5y+8)
in Q[x, y]
2) I12 = (2y2 −y, x −y, 2yz + z2 −y −z, 2z3 −z2 + y −z) in Q[x, y, z]
3) I13 = (x2 −x, y2 −y, z2 −z, xy, xz, yz) in Z/(3)[x, y, z]
r) Finally, write a CoCoA function PrimaryDec(. . .) which checks whether a
given ideal I is zero-dimensional and computes a primary decomposition
of I in that case.
Hint: Use the Finiteness Criterion 3.7.1 and the functions you wrote be-
fore. For the computation of the saturation and the colon ideal in part g),
you can use the built-in CoCoA functions or the results of Tutorials 31
and 37.
s) Apply your function PrimaryDec(. . .) to compute the primary decompo-
sitions of the ideals I1, . . . , I13 and of the following ideals.
1) I14 = (4xy3 −6xy2 −2y3 −x2 + 3y2 + 2x −1, 2x2y + 2xy2 −x2 −
4xy −y2 + 2x + 2y −1) in Q[x, y]
2) I15 = (x2 + y2 + z2 + 1, y2z + yz2 + yz, xy2 + y3 + yz2 + xy + y,
y4 + y2, z4 + z2, yz3 + yz2, xz2 + yz2 + z3 + xz + yz + z, xyz) in
Z/(2)[x, y, z]
3) I16 = (x3 + y3 −z3 + xy −x −y, xz −yz, xy2 −xy −y2 + y,
x2y −x2 −xy + x, y4 −y3) in Z/(3)[x, y, z]

3.7 Systems of Polynomial Equations
267
Tutorial 44: Modern Portfolio Theory
Bull Markets
are born on pessimism,
grow on skepticism,
mature on optimism,
and die on euphoria.
(John Templeton)
With this, the ﬁnal, tutorial we venture where few algebraists have gone
before. Indeed, we want to apply Computational Commutative Algebra to
some problems of mathematical ﬁnance. Modern portfolio theory originated
with the doctoral dissertation of H. Markowitz, has been studied extensively
in economic circles, is widely believed and applied on Wall Street, and even
earned its author a Nobel Prize. But no applications of Computational Com-
mutative Algebra to this area were known to us. Thus is was time to invent
something!
What is modern portfolio theory about?
Let us begin this journey by explaining the main problem of portfolio the-
ory. Suppose we have a certain number of investments available, for instance
stocks, bonds, real estate, cash, gold, etc. Moreover, suppose we know the
prices of those investments at certain dates in the past, for instance at the
end of each of the last 20 years. Now the problem of portfolio theory consists
in distributing the available money in those investments in such a way that
the expected future value of the portfolio is as high as possible, while at the
same time the risk that this expectation is badly disappointed is held to a
minimum.
How can one describe this problem mathematically?
To solve this problem, modern portfolio theory proposes to use the follow-
ing mathematical model. Suppose that there exist n investments from which
we can choose. Let {t0, . . . , tN} be the points in time at which we know the
prices of these investments. For simplicity, we assume that ti is, for every
i ∈{1, . . . , N}, of the form ti = t0 + i · ∆t with a ﬁxed time period ∆t. For
i = 1, . . . , n, let Ai : {t0, . . . , tN} −→Q>0 be the function whose values are
the prices of the ith investment.
Next, we set Ω= {t1, . . . , tN}, and, for i = 1, . . . , n, we consider the
maps
Xi : Ω−→Q>0
deﬁned by
tj 7−→
Ai(tj)+Bi(tj)
Ai(tj−1)
where Bi(tj) is the income derived from the ith investment during the pe-
riod [ti−1, ti], for instance a stock dividend or an interest payment. The
function Xi is called the total return of the ith investment.
Now a portfolio is a tuple (a1, . . . , an) ∈Rn
>0 such that a1+· · ·+an = 1.
Here ai represents the portion of the initial capital which is allocated to the

268
3. First Applications
ith investment. Consequently, the function X = a1X1+· · ·+anXn represents
the total return of the portfolio.
And how does one recognize a “good” portfolio?
In order to deﬁne what we mean by a “high expected return” and a “low
risk” of the portfolio, we now have to make Ωinto a discrete probability
space. Don’t worry! We do not expect that you know what this is. For our
purposes, the following deﬁnitions will be suﬃcient. (For experts we remark
that the map p which assigns to each subset S ⊆Ωthe number p(S) = #S
N
is used to deﬁne the uniform distribution on Ω.)
For i = 1, . . . , n, the number E(Xi) =
1
N
PN
k=1 Xi(tk) is called the ex-
pected return of the ith investment. (In probability theory, one would say
that E(Xi) is the expected value of the random variable Xi .) Similarly, the
number
E(X) = 1
N
N
P
j=1
(a1X1(tj) + · · · + anXn(tj)) = a1E(X1) + · · · + anE(Xn)
is called the expected return of the portfolio (a1, . . . , an).
Furthermore, for i = 1, . . . , n, the number Var(Xi) =
1
N
PN
k=1(Xi(tk) −
E(Xi))2 is called the variance of Xi , and the number σ(Xi) =
p
Var(Xi)
is called the standard deviation of Xi . For i, j ∈{1, . . . , n}, the num-
ber Cov(Xi, Xj) =
1
N
PN
k=1(Xi(tk) −E(Xi))(Xj(tk) −E(Xj)) is called
the covariance of Xi and Xj , and if σ(Xi)σ(Xj) ̸= 0, the number
ϱ(Xi, Xj) = Cov(Xi, Xj)/(σ(Xi)σ(Xj)) is called the correlation coeﬃ-
cient of Xi and Xj .
At this point, it is time for you to start working. But let us insert a few
cautionary remarks here. The tasks we assign in this tutorial are generally
less well-deﬁned than in the tutorials before. Moreover, the level of diﬃculty
is somewhat higher than usual. However, we think that the rewards you can
reap by solving all parts make the eﬀort worthwhile.
a) Suppose that the investments are given by the lists of values of their total
return functions Xi : Ω−→Q>0 . Write CoCoA functions ExpRet(. . .),
VarRet(. . .), and CovRet(. . .) which take these lists and a number d ≥1
and compute E(Xi), Var(Xi), and Cov(Xi, Xj) up to d decimal places.
b) Apply these functions to the following lists Li = [Xi(t1), . . . , Xi(tN)].
1) L1 = [0.935, 0.989, 1.132, 0.687, 0.648, 1.408, 1.083, 0.816, 0.902, 1.035,
1.429, 1.034, 1.229, 1.333, 1.144, 1.022, 0.907, 0.839, 1.208, 1.271]
2) L2 = [0.713, 1.067, 1.133, 0.739, 1.014, 1.402, 0.904, 1.079, 1.047, 0.865,
0.966, 1.02, 1.127, 1.4, 1.061, 1.664, 1.048, 0.698, 1.328, 1.348]
3) L3 = [1.078, 1.118, 1.609, 1.167, 0.702, 1.09, 1.046, 1.177, 1.181, 0.831,
1.461, 1.207, 1.032, 1.434, 1.331, 1.104, 1.43, 1.222, 1.53, 1.069]
4) L4 = [0.981, 1.058, 1.063, 0.99, 0.992, 1.094, 1.056, 1.154, 1.083, 0.998,
0.999, 0.947, 1.137, 1.094, 1.079, 1.081, 1.071, 1.08, 1.04, 1.001]

3.7 Systems of Polynomial Equations
269
5) L5 = [0.992, 1.042, 1.456, 1.437, 1.532, 0.805, 0.872, 1.056, 1.161, 2.056,
1.445, 0.79, 1.164, 0.988, 0.933, 0.815, 0.953, 1.029, 0.954, 0.957]
c) For i, j = 1, . . . , n, show that the following claims hold.
1) Cov(Xi, Xi) = Var(Xi)
2) −1 ≤ϱ(Xi, Xj) ≤1
Hint: Without giving a proof, use the Cauchy-Schwarz inequality
| PN
k=1 xkyk|2 ≤(PN
k=1 x2
k)(PN
k=1 y2
k) for xk, yk ∈R.
d) For the variance Var(X) = 1
N
PN
k=1(X(tk) −E(X))2 , prove
Var(X) =
N
P
i,j=1
aiaj Cov(Xi, Xj)
=
nP
i=1
a2
i Var(Xi) + 2
P
1≤i<j≤n
aiaj Cov(Xi, Xj)
Using these numbers, modern portfolio theory considers the expected
return E(X) of a portfolio as a measure of its “expected future value”
and the standard deviation σ(X) or the variance Var(X) as a measure
for the “risk” associated with this portfolio. Thus a portfolio (a1, . . . , an)
is called eﬃcient if every other portfolio (b1, . . . , bn) with the same vari-
ance satisﬁes E(b1X1 + · · · + bnXn) ≤E(a1X1 + · · · + anXn), and if
every other portfolio (c1, . . . , cn) with the same expected return satisﬁes
Var(c1X1 + · · · + cnXn) ≥Var(a1X1 + · · · + anXn). The set of all eﬃcient
portfolios is called the eﬃcient frontier.
Thus, altogether, we see that the main problem of portfolio theory be-
comes the computation of the eﬃcient frontier when the available investments
are given via their total return functions X1, . . . , Xn : Ω−→Q>0 .
How can one compute the eﬃcient frontier?
To simplify our notation, let ei = E(Xi), let vi = Var(Xi), and let
cij = Cov(Xi, Xj) for i, j = 1, . . . , n. We shall suppose that the numbers ei ,
vi , and cij are given rational numbers. Given a portfolio (a1, . . . , an), we let
e = E(X) and v = Var(X) be the expected return and the variance of the
corresponding function X = a1X1 + · · · anXn . Our discussion so far shows
that the following equations hold.
(1)
0 = a1 + · · · + an −1
(2)
0 = a1e1 + · · · + anen −e
(3)
0 =
nP
i=1
a2
i vi + 2
P
1≤i<j≤n
aiajcij −v
In order to compute one eﬃcient portfolio, we may consider v as a given
number (“risk level”) and try to optimize e in (2) under the side conditions
(1), (3). The method of Lagrange multipliers says that the maximum of e

270
3. First Applications
occurs when the partial derivatives of (2) with respect to the indeterminates
a1, . . . , an are linear combinations of the partial derivatives of (1) and (3).
e) Using the method of Lagrange multipliers, show that the following addi-
tional equations have to be satisﬁed for certain ℓ, m ∈Q.
(4)
0 = ei −ℓ−m (2aivi +
X
j̸=i
ajcij)
for i = 1, . . . , n
f) Write a CoCoA function PFEqn(. . .) which computes an ideal I in the
ring Q[a1, . . . , an, e, v, ℓ, m] which is generated by n + 3 polynomials
corresponding to equations (1), (2), (3), and (4).
g) Prove that, in general, the ideal J = I ∩Q[e, v] is a non-zero principal
ideal generated by a quadratic polynomial of the form v −q(e).
Hint: Divide equation (4) by m and assume that all denominators and
determinants are non-zero.
Every point on the parabola deﬁned by v = q(e) in the (v, e)-plane
corresponds to a portfolio if the associated tuple (a1, . . . , an) consists of
non-negative numbers. By construction, such a portfolio satisﬁes the ﬁrst
property of an eﬃcient portfolio. In fact, one can show that it is an eﬃcient
portfolio. Notice that, for every non-empty subset S ⊆{1, . . . , n}, we can
repeat this construction for the corresponding subset of investments and get
a parabola deﬁned by an equation v = qS(e).
h) Write a CoCoA program AllParab(. . .) which computes the list of all
2n −1 quadratic polynomials v −qS(e).
Hint: First, you may want to write a CoCoA function which computes all
non-empty subsets S of {1, . . . , n}.
i) Implement a CoCoA function IntPoints(. . .) which calculates a matrix
containing approximations of all points of intersection of the “upper
halves” of the parabolas Z(v −qS(e)).
Hint: To ﬁnd approximations for the solutions of a quadratic equation in
one indeterminate, you may use the functions Round(. . .) and Sqrt(. . .)
explained in Appendix C.5.
j) Apply your functions AllParab(. . .) and IntPoints(. . .) in the case of
the ﬁve investments of part b).
k) The points of intersection computed by IntPoints(. . .) subdivide the
upper half of each parabola Z(v −qS(e)) into a number of segments.
Show that on each parabola there exists at most one segment whose
points correspond to portfolios.
Thus the parts of the eﬃcient frontier are made up of segments of parabo-
las corresponding to portfolios where ai = 0 for some indices i ∈{1, . . . , n},
i.e. to portfolios which involve only a proper subset of the set of available in-
vestments. Clearly, there exists one portfolio for which v attains the minimal
possible value vmin . We call it the minimal risk portfolio. The situation
can be illustrated as follows.

3.7 Systems of Polynomial Equations
271
..................................... ................
......................................
................
v
e
•
•
•
eﬃcient fontier
possible porfolios
...........................................................................................................................................................................................................................................................................................................................................................................................................................................................
................................................ . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
. . . . . . . . . .
. . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . .
. . .
l) Write a CoCoA function MinPF(. . .) which computes the minimal risk
portfolio (a1, . . . , an).
m) Apply your function MinPF(. . .) to compute the minimal risk portfolio
for the ﬁve investments of part b).
n) Implement a CoCoA function Frontier(. . .) which computes the diﬀerent
pieces of parabolas which constitute the eﬃcient frontier and their points
of intersection.
Hint: Notice that you can easily decide which parabola is the “higher”
one from their point of intersection onwards by comparing their leading
coeﬃcients.
o) Compute the eﬃcient frontier for the ﬁve investments of part b).
What is the “best” eﬃcient portfolio?
Naturally, the answer to this question depends partially on the type of
investor for whom the portfolio is constructed. But, astonishingly, there is
a nice rule which identiﬁes one point on the eﬃcient frontier which has the
property that the corresponding portfolio has the highest return if one con-
tinues the investment process over many time periods.
To motivate this rule, we use some deeper results from probability theory.
It is not necessary that you know them in order to solve this part of the
tutorial, but the overall level of diﬃculty is somewhat higher than before.
Let W0 be the initial capital. The value of a portfolio (a1, . . . , an) after i
time periods is Wi = W0 · Qi
j=1 X(tj), where X = a1X1 + · · · + anXn . Thus
we have ln( Wi
W0 ) = Pi
j=1 ln(X(tj)). The strong law of large numbers now
says that
lim
i→∞
1
i
iP
j=1
(ln(X(tj) −E(ln X)) = 0
holds almost certainly, i.e. that it holds with probability one.

272
3. First Applications
q) Let (b1, . . . , bn) be another portfolio, and let Y = b1X1 + · · · + bnXn .
Furthermore, let W ′
i be the value of the portfolio (b1, . . . , bn) after i time
periods. Show that Wi > W ′
i holds almost certainly for large numbers i
if and only if we have E(ln X) > E(ln Y ).
Hint: Assume that the limit limi→∞1
i
Pi
j=1 ln(X(tj)) exists.
The MEL-rule (“maximum expected logarithm”) says that a portfolio
(a1, . . . , an) is better than a portfolio (b1, . . . , bn) in the very long run if
E(ln X) > E(ln Y ) for X = a1X1 + · · · + anXn and Y = b1X1 + · · · + bnXn .
Thus we should choose that point on the eﬃcient frontier for which E(ln X)
attains its maximal value.
Above we computed segments of parabolas which constitute the eﬃcient
frontier. Since we can calculate E(ln X) for the portfolios corresponding to
the points of intersection of those parabolas, it suﬃces to consider the case
that the MEL-rule speciﬁes a portfolio which corresponds to an interior point
of one of those segments of parabolas.
r) Using the Taylor expansion of ln(x) at the point x = e, prove the
approximation formula E(ln X) ≈ln(E(X)) −1
2
Var(X)
E(X)2 .
s) Write v = q(e) and form the derivative with respect to e of the above
approximation formula. Conclude that the MEL-rule yields the following
additional quadratic equation for the optimal portfolio on the eﬃcient
frontier.
(5)
e2 −1
2 e q′(e) + q(e) = 0
t) Develop an algorithm for computing the portfolio which is speciﬁed by
the MEL-rule. Implement this algorithm in a CoCoA function MELPF(. . .)
and apply this function to the ﬁve investments of part b).
Hint: To compute ln(e), you can write e = 1 + r and use the formula
ln(1 + r) = r −1
2r2 + 1
3r3 −+ · · ·.
How does this theory hold up in practice?
Men, it has been well said, think in herds;
it will be seen that they go mad in herds,
while they only recover their senses slowly,
and one by one.
(Charles MacKay)
Nowadays, modern portfolio theory is widely believed and followed by
professional money managers. As we have seen, it is possible to write pro-
grams which compute a suggested asset allocation in an automatic way. The
economic justiﬁcation for it is based on the assumption that ﬁnancial markets
are eﬃcient. This means that if there was a theory which could produce reli-
able above-average gains in the ﬁnancial world without taking above-average
risks, everybody would immediately start to apply it, and it would necessarily
stop functioning.

3.7 Systems of Polynomial Equations
273
However, it has long been known that markets are not very eﬃcient. As
the world-wide stock market mania of the late 1990s showed once again,
both private and institutional investors are inﬂuenced by crowd psychology.
Moreover, many corporations and even governments do not hesitate to ma-
nipulate the stock and bond markets. And when a serious ﬁnancial crisis
develops, the market liquidity required by modern portfolio theory dries up
completely, because there is no one willing or able to step in on the buy-side.
Another serious objection to modern portfolio theory is that the standard
deviation or the variance of the total return of a portfolio is inadequate to
measure the risk associated with this portfolio. Price volatility does not detect
whether stocks or other investments are signiﬁcantly over- or undervalued
with respect to the assets they represent. If you invested money in the late
1920s or the late 1960s according to this theory, you would have had to put a
signiﬁcant portion into the US stock market, because it had a high expected
return and a low volatility, and you would have lost it.
What should we do instead? Since CoCoA cannot really help us in this
case, it may be useful to apply our common sense. When you invest money
and buy something, it is important to pay a low price relative to the value
of whatever you purchase. When your government dramatically increases the
supply of money, it may be useful to convert some of your paper wealth to
something of more lasting value such as real estate or gold. And when the
people around you get carried away by their herd instincts, relax, recover
your senses, get out of the markets while the going is good, and enjoy your
life! We hope that in this way you will ﬁnd the time to do some more of the
tutorials in this book.


A. How to Get Started with CoCoA
No keyboard present.
Hit F1 to continue.
(DOS Error Message)
A.1
Getting CoCoA
The computer algebra system CoCoA is available free of charge via the inter-
net. You may download it from the WWW page
ftp://cocoa.dima.unige.it/cocoa/index.html
Choose the ﬁle corresponding to your machine and operating system, and
do not forget to get a copy of the manual from the directory /doc. Then
decompress the ﬁle ending in .zip, or .tgz, or .hqx. Depending on your
system, you will have to use a command like unzip or tar -zxvf, or the
graphical interface of a decompression tool like Winzip.
As a result you should have an appropriately named directory or folder,
for instance /usr/local/cocoa/, which contains the executable ﬁle of the
program (called cocoa or cocoa.exe), a ﬁle named userinit.coc, and a
subdirectory called lib. If, instead, you ﬁnd hundreds of ﬁles in your folder,
you forgot to uncompress in such a way that all paths are restored!
A.2
Starting CoCoA
Now let us try the program. You can start it by simply typing
cocoa
while you are in the folder containing the executable ﬁle. Or, if you have a
graphical operating system, you can also click on its icon. And if there is no
icon, create a link or shortcut to the executable ﬁle ﬁrst. Then the current
version of CoCoA starts up and displays a screen like

276
A. How to Get Started with CoCoA
-------------------------------------------------------
---
___/
___/
\
---
--
/
_ \
/
_ \
, \
--
--
\
|
| \
|
|
___ \
--
---
____, __/
____, __/ _/
_\
---
-------------------------------------------------------
--
Version
: 4.0
--
--
Online Help
: type
Man();
--
--
Web site
: http://cocoa.dima.unige.it
--
-------------------------------------------------------
-- The current ring is R ::= Q[x,y,z];
-------------------------------
Below we shall explain how you can enter commands by going with you
through a sample session. But ﬁrst, let us show you how you can exit the
program. Simply type
Quit;
hit <Enter>, and that’s it! Or maybe not. If you are using the graphical
interface of CoCoA under Unix or Windows, you can either send a line to
CoCoA by typing <Ctrl + Enter> at the end of the line, or you can select
a line or a group of lines and send it to CoCoA using <Ctrl + Enter>. And
if you are using CoCoA on Macintosh, you should make sure you hit the
<Enter> key, not the one marked <Return>. And if, by any chance, you are
in a mediterranean mood, you can also leave CoCoA with a cordial
Ciao;
A.3
Using CoCoA Interactively
In fact, when you typed Quit; above, you entered your ﬁrst CoCoA command.
A CoCoA command has two notable features: it starts with a capital letter,
and it ends with a semicolon. If you want to deﬁne a new object, you have to
give it a name starting with a capital letter. Then you can assign it a value
by using := as in the following example.
F:=x^2+y^2-1;
This command deﬁnes a new polynomial F in the current ring which has the
value x2+y2−1. (We will be talking about rings later, but for the moment we
assume that you just started CoCoA and that the current ring is the default
ring R = Q[x,y,z].) The value of the new polynomial F is x^2+y^2-1. As
you can see, the indeterminates of a polynomial ring in CoCoA have lower-case
letters as names and are raised to powers using the ^ key. Sometimes they

A. How to Get Started with CoCoA
277
carry indices like x[1],x[2],x[3]. All other names of objects and functions
in CoCoA start with a capital letter.
Now let us print out the value of our polynomial F. For this we could type
Print(F); or simply
F;
Then CoCoA answers
x^2 + y^2 - 1
-------------------------------
We could also perform some calculation before typing its result, e.g.
F^2-F+1;
yields the output
x^4 + 2x^2y^2 + y^4 - 3x^2 - 3y^2 + 3
-------------------------------
Next we apply one of the built-in CoCoA functions.
Factor(F-2xy+1);
CoCoA replies
[[x - y, 2]]
-------------------------------
which means F −2xy + 1 = (x −y)2.
A.4
Getting Help
A moment ago we saw an example of the use of the CoCoA function Factor().
If you want to know more about this function, type
Man(’Factor’);
and CoCoA will display the page of its on-line manual describing the function
Factor(). In this case, you may even type
Man(’fac’);
Since fac is not the name of a CoCoA command, CoCoA looks for all topics
in its on-line manual containing that string. For more extensive information
about how to use the manual, type
Man();

278
A. How to Get Started with CoCoA
After that, you get a list of possible commands for getting help. For instance,
H.Toc(); will give you the table of contents of the online manual, H.Tips();
will give you tips for using the online manual, and H.Commands(’Topic’);
summarizes all commands associated with ’Topic’ (the quotes are needed
to mark a string).
There are several other ways to access the CoCoA manual. In the directory
doc on the ftp-server mentioned in Section A.1 you will ﬁnd an html-version
for reading with an internet browser, and a postscript-version for printing.
Finally, if you use the graphical interface of CoCoA under Windows, you can
also access the manual through the Windows help system.
Since this introduction to CoCoA has to be limited in space and scope,
we strongly urge you to look up all the topics we discuss in the manual.
There you will ﬁnd more extensive and more detailed information. Moreover,
there is a section of the manual called “Tutorial” which complements these
appendices and should be studied as well.
A.5
Data Types
Let us get back to our example session. Suppose we now want to deﬁne a
polynomial ideal. Using the manual, we ﬁnd that the correct command is
Ideal() and we can type
I:=Ideal(F,x-y);
J:=Ideal(x,y,z)^2;
Intersection(I,J);
CoCoA will not reply to the ﬁrst two lines, since they are assignments. But it
reacts to the last line by printing
Ideal(xz - yz, xy - y^2, y^2z^2 - 1/2z^2, y^3z - 1/2yz,
y^4 - 1/2y^2, x^2 - y^2)
-------------------------------
which means that the intersection of the ideals I and J has been computed.
Sometimes it may be advisable to use the command Set Indentation; be-
fore typing out a list or an ideal. In our case, we’d get
Ideal(
xz - yz,
xy - y^2,
y^2z^2 - 1/2z^2,
y^3z - 1/2yz,
y^4 - 1/2y^2,
x^2 - y^2)
-------------------------------

A. How to Get Started with CoCoA
279
Naturally, this behaviour can be reversed by entering Unset Indentation;
Many CoCoA objects like polynomials, ideals, and modules are deﬁned
over a base ring. The command CurrentRing(); tells you the value of the
current ring. E.g. in our example session we would get the answer Q[x,y,z].
A new ring can be deﬁned by a command like
Use S::=Z/(5)[x,y,z];
Here ::= is the instruction to create a new ring, S is its name, Z/(5) is its
ﬁeld of coeﬃcients, and x,y,z are its indeterminates. After you have deﬁned
the new ring S, you are also making it the current base ring by invoking the
command Use <Ringname>; You can switch back to your initial ring with
the command Use R; and if you type RingEnvs(); you get a list of all the
base rings deﬁned so far.
Whenever you create a new polynomial, ideal, or module, it is deﬁned
over the current ring. To see a list of all objects in the working memory,
you can type Memory(); and to see also the values of those objects you can
use Describe Memory(); At this point you may get a list of descriptions of
objects of diﬀerent types. Some of the most common data types in CoCoA are
INT, RAT
arbitrarily large integers resp. rational numbers
ZMOD
elements of a ﬁnite ﬁeld Z/(p) where p is a prime number
POLY
polynomials
IDEAL
polynomial ideals
RING
polynomial rings
VECTOR
vectors whose entries are polynomials
MODULE
submodules of ﬁnite free modules over polynomial rings
LIST
Lists of objects of the form [Object1, Object2, Object3]
MAT
matrices of polynomials
STRING
strings (sequences of characters)
BOOL
Boolean variables (i.e. their value is either TRUE or FALSE)
In CoCoA, you usually do not have to specify the data types of the objects
you create. Most sensible data type conversions are done automatically. The
command Type(Object) displays the data type of an Object. If necessary,
you can also force type conversions using Cast() e.g.
L:=[x,y,z];
Type(L);
shows that L is of type LIST, whereas
Cast(L,IDEAL);
leads to the answer
Ideal(x, y, z)
-------------------------------

280
A. How to Get Started with CoCoA
For special type conversions, there are frequently individual commands, e.g.
the above conversion could have been done by typing I:=Ideal(L); Then
the ideal I can be converted back to a list by using Gens(I); which brings
us to our next topic: What is a list?
A.6
Lists
In CoCoA, a list is a sequence of objects, separated by commas and enclosed in
square brackets. Lists are very common and useful objects in CoCoA. Exam-
ples of lists are for instance [1,2,3] and [x,y,z]. The diﬀerent components
of a list do not necessarily have to have the same data type, e.g. as in the list
[1,TRUE,x]. Given a list L:=[x,y,z]; you can access its second component
by typing
L[2];
which yields the result y. Another way to achieve the same result is to type
Comp(L,2); This is especially convenient if the list L is not directly given by
its name but the result of some other evaluation, e.g. as in Comp(Gens(I),1);
where I is an ideal.
Besides listing all the elements, there are other ways to create a list. Two
simple ones are the range operator and the Cartesian product. The range
operator N..M creates the list of all integers between N and M. For instance,
1..5;
creates the list
[1, 2, 3, 4, 5]
-------------------------------
The range operator can also create a list of indeterminates of the current
ring (in the current term ordering), e.g. if the current ring is Q[x,y,z], then
x..z creates the list [x,y,z], and if the current ring is Q[x[1..8]], then
x[1]..x[4] creates the list [x[1],x[2],x[3],x[4]]. The Cartesian product
of two lists is the list of all pairs, e.g. the product [1,2,3] >< [x,y] yields
the list [[1, x], [1, y], [2, x], [2, y], [3, x], [3, y]].
There are many built-in CoCoA function for dealing with lists. We in-
vite you to print a list of them using Man(’Functions for Lists’); In our
opinion, some of the most useful ones are
a) Append(L,O) to append an object O to a list L,
b) Concat(L,M) to combine two lists L and M into one,
c) First(L,N) and Last(L,N) to retrieve the list of the ﬁrst and last N
elements of a list L, respectively,
d) Diff(L,M) to create the list of all elements of the list L which are not in
the list M, and
e) Len(L) to determine the number of elements of a list L.

A. How to Get Started with CoCoA
281
If you want to build a new list by computing (or entering) its elements
one by one, you can either apply commands such as Append(L,x); repeat-
edly, or you can ﬁrst deﬁne a new “empty” list of a speciﬁed length N
via L:=NewList(N); and then assign its entries using commands such as
L[1]:=x;
Notice that, unlike other functions for lists, the command Append(L,x)
does not return a value, but modiﬁes the argument list L. CoCoA tries to
be clever about operations with lists. For instance, if L:=[x,y,z]; then 2L;
yields the list [2x, 2y, 2z]. But of course, it has to leave some thinking to
you, and a construction like [x,y,z]^3; makes no unique sense.
Finally, we note that more advanced ways to construct lists will be dis-
cussed in Appendix B.5.
A.7
It
Finally, we would like to mention a special CoCoA variable called It. At each
point in time it contains the last output. In particular, if you print the result
of a computation and then discover that you still need it, you can assign it
to a variable using It, e.g.
Factor(x^9-1);
[[x - 1, 1], [x^2 + x + 1, 1], [x^6 + x^3 + 1, 1]]
-------------------------------
L:=It;
L;
[[x - 1, 1], [x^2 + x + 1, 1], [x^6 + x^3 + 1, 1]]
-------------------------------
Of course, we encourage you to develop a habit of always assigning the result
of a computation to a variable, e.g. using L:=Factor(x^9-1); and then to
print it. As one CoCoA programmer put it:
Never use It!


B. How to Program CoCoA
The code was willing.
It considered your request,
but the chips were weak.
(Anonymous)
B.1
Deﬁning New CoCoA Functions
Apart from using CoCoA interactively as explained in Appendix A, the sys-
tem also gives you the possibility to extend it by writing your own CoCoA
functions. It has a fully-ﬂedged programming language, called CoCoAL, and
provides means for packaging, storing and reusing the functions you create.
A new CoCoA function is created using a command of the form
Define FunctionName(Arguments)
<Commands>
EndDefine;
Here FunctionName is the name by which you later want to call your function,
Arguments is the (possibly empty) list of arguments it takes, and <Commands>
denotes a group of CoCoA commands.
Let us look at an example. We want to write a function which computes
the ideal generated by the pth powers of the generators a given ideal, where
the prime number p is the characteristic of the base ﬁeld.
Define Frobenius(I)
P:=Characteristic();
L:=Gens(I);
For N:=1 To Len(L) Do
L[N]:=L[N]^P;
EndFor;
Return Ideal(L);
EndDefine;
Note that in order to enter this function deﬁnition on a version of CoCoA
having a graphical interface, you should highlight all lines using the mouse

284
B. How to Program CoCoA
and then evaluate this selection. Afterwards we can use our new function like
any built-in CoCoA function. For instance, we can type
Use S::=Z/(5)[x,y,z];
I:=Ideal(xy,yz,x-y);
Frobenius(I);
and we get the answer
Ideal(x^5y^5, y^5z^5, x^5-y^5)
-------------------------------
After the execution of this function, your original ideal I is unchanged, al-
though it has been tampered with inside the function! The reason for this
is that the ideal I inside the function Frobenius(I) is just a “local” ob-
ject to which CoCoA passed the value of your original ideal I. Instead, if you
want the function to operate directly on the original ideal, you should type
Define Frobenius(Var I) in the ﬁrst line of the function deﬁnition.
B.2
Program Development
As soon as you start to write CoCoA functions more frequently, you will
feel the need to develop some techniques for doing this. Since the available
methods vary considerably from one operating system to another, and since
almost every CoCoA programmer has his own favourite procedures, we shall
restrict ourselves to pointing out the most common ways.
Many CoCoA users work with a text-based CoCoA interface inside a graph-
ical operating system environment, e.g. inside X-Windows or Windows. In
this case we recommend the “Copy and Paste” technique for creating CoCoA
functions:
• Open two windows, one for CoCoA and one for a text editor. The editor
should be able to save pure ASCII ﬁles.
• Create the CoCoA function inside the editor.
• Use “Copy” and “Paste” to transfer the deﬁnition to CoCoA, so that
CoCoA can check it for syntax errors.
• Repeat the previous steps until the program is correct. Then you can
save it using the editor in a ﬁle whose ﬁle name extension is customarily
taken to be .coc.
Another possibility for Unix users is to run CoCoA in a shell of a suitable
editor program like Emacs. (Some useful ﬁles for doing this are on the CoCoA
website.) If you run a text-based version of CoCoA under a text-based oper-
ating system like DOS, you will have to revert to a more primitive technique:

B. How to Program CoCoA
285
• Create the function using a text editor and save it in a ﬁle, e.g. in
myfile.coc.
• Modify the ﬁle userinit.coc to include a source command which reads
your ﬁle at startup, i.e. include the line
<< ’myfile.coc’;
• Now start CoCoA. It reads and checks your program. If there is still an
error, you have to quit CoCoA and return to the editor.
A much more advanced way of using CoCoA is possible if you are able to
use one of the CoCoA versions with a graphical user interface, e.g. the new
graphical interface for X-Windows and Windows, or CoCoA on a Macintosh.
In this case you can edit your function inside the lower window, select it and
send it to CoCoA until it is correct. Probably you may not want to do this
in the interactive window, but rather in a ﬁle window which you can create
using <File> + <New>. When you are content with your function, you can
then save it to a ﬁle. And don’t forget to write some documentation for your
functions, or else you will soon be unable to reuse them!
B.3
Input and Output
In Section B.1 we saw an example of how a CoCoA function can pass the
result of its computations back to the system. The command
Return <Object>;
exits the function and returns the value of <Object> to the place from where
the function was called.
Passing objects to a CoCoA function is obviously achieved through its
argument or list of arguments. Notice that the name which you give to a
function argument in the function deﬁnition does not have to agree with the
name of the object on which you call the function. Moreover, the argument
name in the function deﬁnition denotes a variable for which you do not have
to specify a data type and which is local to the function, i.e. it may agree
with the name of an object elsewhere and it will be deleted after the function
has been executed. Finally, it is important to remember that objects outside
the CoCoA function which are not passed to it through the list of arguments
are not known inside the function. For instance, if we have
I:=Ideal(x^2,y^2);
Define IdealSquare(J)
I:=J^2;
Return I;
EndDefine;

286
B. How to Program CoCoA
then the ideal I:=Ideal(x^2,y^2); is not destroyed or changed during the
execution of IdealSquare(Ideal(z)); and we can call IdealSquare(I);
without getting into trouble.
Another way of obtaining feedback from a CoCoA function, for instance
during its execution, is to have it write output on the screen. This can be
achieved by using the commands
Print <Object>,...,<Object>;
PrintLn <Object>,...,<Object>;
The ﬁrst command is used to print a sequence of objects to the screen, and
the second one does the same thing but adds a line break afterwards. For
example, to print out the value of F:=x^2+y^2-1, we could write
Print ’The value of F is F = ’,F;
The value of F is F = x^2 + y^2 - 1
-------------------------------
Finally, using CoCoA you can also write data to ﬁles and read them again.
We have already mentioned the source command << which allows you to read
a ﬁle containing function deﬁnitions, e.g. << ’myfile.coc’; For reading and
writing other data, you need to open an input or an output ﬁle and to write
to such a “device”. Since this is a very advanced use of CoCoA, we refer you
to Man(’Print On’); for details about printing on a ﬁle.
B.4
Program Flow Control
Our next topic is to discuss methods for controlling the way in which a
sequence of commands is executed within a CoCoA function. In order to repeat
a certain sequence of commands a prescribed number of times, you can use
a construction like
N:=10;
For I:=1 To N Do
<Commands>
EndFor;
Here I is the name of an integer variable which is initially one, is increased by
one each time the <Commands> have been executed, and is N (or an expression
having an integer value) when the loop ends. For instance, the following
function creates a random vector over the base ﬁeld whose length is the
number of indeterminates of the base ring.
Define RandomVector()
N:=NumIndets();
L:=NewList(N);
For I:=1 To N Do

B. How to Program CoCoA
287
L[I]:=Rand();
EndFor;
Return Vector(L);
EndDefine;
Another way to create a loop is provided by the command
ForEach M In L Do
<Commands>
EndForEach;
where M is an object name which you can choose and L is a list. Here the
<Commands> are executed for each element of the list (whose elements are
examined in the obvious order), and during that execution the element is the
value of the “read-only” object M. This loop construction is particularly useful
if you do not know beforehand how many elements L is going to have, i.e.
how often the <Commands> have to be performed. For example, the function
Define TermProduct(D)
L:=Support(DensePoly(D));
Result:=1;
ForEach M In L Do
Result:=Result*M;
EndForEach;
Return Result;
EndDefine;
computes the product of all terms of degree D in the current ring. Even more
common is the situation that a loop has to be repeated until a certain logical
condition is satisﬁed. This can be achieved by using
While <logical condition> Do
<Commands>
EndWhile;
Here the <logical condition> is some expression which evaluates to a
Boolean value. If this Boolean value is TRUE, then the <Commands> are exe-
cuted, otherwise the loop ends. For instance, the following example computes
the largest power of two dividing a given natural number.
Define MaxPower(N)
I:=1;
While Mod(N,2)=0 Do
I:=I*2;
N:=N/2;
EndWhile;
Return I;
EndDefine;

288
B. How to Program CoCoA
Finally, CoCoA also provides methods for executing one sequence of com-
mands or another, depending on the value of some logical condition. The two
most frequently used methods are
If <logical condition> Then <Commands> EndIf;
If <logical condition> Then <Cmds1> Else <Cmds2> EndIf;
In the ﬁrst case, the <Commands> are executed only if <logical condition>
evaluates to TRUE. Otherwise they are skipped and program execution contin-
ues after the EndIf; In the second case, the commands <Cmds1> are executed
if the <logical condition> is TRUE, and the commands <Cmds2> are exe-
cuted if it is FALSE. For instance, the function
Define MaxOdd(N)
If Mod(N,2)=1 Then
Return N;
Else
M:=MaxPower(N)
EndIf;
Return N/M;
EndDefine;
computes the largest odd divisor of a natural number N. Notice that the
command Return N; leads to an immediate termination of this function if it
is encountered.
Should these hints be not suﬃcient to solve your speciﬁc program ﬂow
control problem, or should you intend to get the “CoCoA bug”, we invite you
to study the CoCoA manual which contains several more possibilities and a
host of examples.
B.5
List Constructions
The creators of CoCoA spent a lot of eﬀort to make the system as user-friendly
as possible. In particular, CoCoA allows you deﬁne lists of objects in ways
which are very similar to the usual mathematical deﬁnition of sets in books
or on the blackboard. This list construction can take a number of diﬀerent
forms, the most important of which are
[ <Object> | X In <List> ]
[ <Object> | X In <LIST> And <logical condition> ]
[X In <List> | <logical condition>]
In the ﬁrst form, <Object> is a CoCoA expression which usually depends on
the variable X and evaluates to a CoCoA object. Thus this form constructs the
list of all such objects such that X is an element of the <List>. The second
form does essentially the same thing, except that only those elements X of
<List> are used to construct objects for which the <logical condition>

B. How to Program CoCoA
289
evaluates to TRUE. The third form creates the sublist of <List> consisting of
all of its elements X for which the <logical condition> is TRUE.
Let us see some examples of list constructions. The ﬁrst function returns
a list of N random linear forms in the current ring, where N is a speciﬁed
natural number.
Define RandomLinear(N)
L:=[Randomized(DensePoly(1)) | I In 1..N];
Return L;
EndDefine;
Notice that in this case I is not used in the deﬁnition of the created list
elements, and observe the use of the range operator 1..N which generates
the list [1,2,3,...,N]. An example for the second form of list constructions
is
Define EvenIntegers(N)
L:=[I | I In 1..N And Mod(I,2)=0];
Return L;
EndDefine;
a function which returns the list of even integers between 1 and N. Finally,
the function
Define IrrePolys(L)
Irre:=[F In L | Len(Factor(F))=1];
Irre:=[F In Irre | Comp(Factor(F),1,2)=1];
Return Irre
EndDefine;
computes the sublist of a given list of monic polynomials consisting of the
irreducible ones.
Maybe you have also noticed that in this example program we have a
command which does not end in a semicolon, apparently contradicting what
we said in Appendix A. Without falling into the abyss of computer jargon,
let us just say that you can drop the semicolon if it immediately precedes
the End;
of some command.
B.6
Recursive Programming
Next we show you the perfect way for creating CoCoA programs which run
into an inﬁnite loop. More seriously, CoCoA allows a function to call itself. Of
course, if you use this feature you have to make sure that the process termi-
nates eventually. For example, a compact implementation of the computation
of the factorial of a natural number is

290
B. How to Program CoCoA
Define Factorial(N)
If N=0 Then
Return 1;
Else
Return N*Factorial(N-1);
EndIf;
EndDefine;
In this example ﬁniteness is achieved by checking whether N=0 before the
recursive function call which applies to a smaller integer N-1. Clearly, recur-
sive function calls are both powerful and dangerous. Let us give one more
example. The following function recursively computes the nondecreasing list
of prime factors of a natural number.
Define FactorList(N)
If N=1 Then
Return [];
EndIf;
I:=2;
While Mod(N,I)<>0 Do
I:=I+1;
EndWhile;
L:=FactorList(N/I);
Return Concat([I],L);
EndDefine;
And now oﬀto your own experiments!
B.7
Improving Your Programs
To end our whirlwind tour of CoCoA, let us show you some ways to improve
and manage your CoCoA programs. The command
Set Timer;
turns on an automatic timing mechanism. Every time you enter a command,
CoCoA displays the CPU time that was consumed for its execution, e.g.
Set Timer;
Factor(x^233-3x^223+x^222-7x^12+x^11+21x^2-10x+1);
[[x^11 - 3x + 1, 1], [x^222 - 7x + 1, 1]]
-------------------------------
Cpu time = 1.81, User time = 1
-------------------------------
You can use this feature to test various versions of your programs and opti-
mize them for fastest performance. If you get sick of those timing messages,

B. How to Program CoCoA
291
you can turn them oﬀagain by typing (guess what?) Unset Timer; To time
a single command, you can also use Time <Command>; For instance, above
we could have written
Time L:=Factor(x^233-3x^223+x^222-7x^12+x^11+21x^2-10x+1);
After a while, you will have a number of CoCoA functions, and if you do
not use them regularly, you will forget their exact names, syntax, etc. To ﬁnd
their names again after you loaded the ﬁle containing them, you can use the
CoCoA command
Starting( <String> );
It displays a list of the names of all CoCoA functions starting with <String>,
including you own creations. Do not forget to enclose the string in quotes,
though! And if you have a hard time remembering the syntax of the functions
you wrote, we suggest that you write a help function for each of them. If the
function is called MyFunction(), you should create a new function like
Define Help_MyFunction()
<Commands>
EndDefine;
Then this function is executed every time you type Help(’MyFunction’); Of
course, the <Commands> it contains will usually be commands to print some
help text.
After another long while, you will have so many CoCoA functions that it
becomes diﬃcult to keep track of all their names, etc. If you come this far,
you can get out of trouble by collecting your functions in packages. A CoCoA
package is a ﬁle containing a lot of CoCoA functions. Usually it has a name
ending with .pkg. Its content is of the shape
Package <Packagename>
<Function Definitions>
EndPackage;
Later you can share your package with others, e.g. people in the CoCoA User
Group or other students in your class sweating over the same homework. As
this is again a very advanced way of using CoCoA, we suggest that you look
at Man(’Package’); for details.
In the next appendix you can see some examples in which the previous
hints are applied. If you need more precise information, we suggest that you
look carefully at the CoCoA manual mentioned in Appendix A. And if all else
fails, you may write an e-mail to
cocoa@dima.unige.it
But for the time being, we wish you good luck and say
Ciao;
-- Bye


C. A Potpourri of CoCoA Programs
Bugs come in through open Windows.
(Anonymous)
C.1
Some Hints for Tutorial 1
In this appendix we shall frequently see that the same algorithm can be
turned into CoCoA functions in many ways. Part a) of Tutorial 1 is a case in
point. For a beginning programmer, the following solution should not be too
diﬃcult to ﬁnd.
Define ReprUniv(F,X)
L:=NewList(Deg(F)+1);
For I:=0 To Deg(F) Do
L[I+1]:=CoeffOfTerm(X^I,F);
EndFor;
Return L;
EndDefine;
In the second line, we deﬁne a new list L of the appropriate length. Then a
For-loop is used to ﬁll that list with the coeﬃcients of the given polynomial.
The identiﬁer X holds the name of the indeterminate with respect to which
the polynomial F is univariate. Notice how we had to change the indices, since
in CoCoA the elements of a list are numbered starting with “1”.
An elegant solution is based on the CoCoA function Coefficients(. . .).
Define ReprUniv(F,X)
Return Reversed(Coefficients(F,X));
EndDefine;
As for the function ListToPoly(. . .), we only give you the solution in-
volving the list construction, in order to make you feel more comfortable with
this style of programming. (We trust you can do the For-loop by now, can’t
you?)
Define ListToPoly(L)
Return Sum([L[I] x^(I-1) | I In 1..Len(L)]);
EndDefine;

294
C. A Potpourri of CoCoA Programs
For part c), we leave the implementation of AddUniv(. . .) to you. A very
explicit and down-to-earth solution for the multiplication could look as fol-
lows.
Define MultUniv(L,M)
D:=Len(L)+Len(M)-2;
For I:=Len(L)+1 To D+1 Do
Append(L,0);
EndFor;
For I:=Len(M)+1 To D+1 Do
Append(M,0);
EndFor;
N:=NewList(D+1,0);
For I:=0 To D Do
N[I+1]:=Sum([L[J+1]*M[I+1-J] | J In 0..I]);
EndFor;
Return N;
EndDefine;
In the second line, we determine the degree D of the product. Then we
append zeros to the lists L and M until both of them have length D+1. Finally,
we construct another list N which will contain the ﬁnal result. Its entries are
computed using the formula for the coeﬃcients of the product given in the
hint. The list construction creates the list of all ajbi−j .
The following CoCoA program removes the trailing zeros of a list. It may
be useful for solving part d) of the tutorial. Notice how we were able to exploit
the While-loop.
Define Shorten(L)
N:=Len(L);
While L[N]=0 Do
N:=N-1;
EndWhile;
Return First(L,N);
EndDefine;
There is also an elegant solution to part d) based on Coefficients(...)
and the list construction. Although we do not expect you to be able to write
such programs (yet!), it is well worth studying.
Define ReprPoly(F)
Return [Reversed(Coefficients(G,x))|G In
Reversed(Coefficients(F,y))];
EndDefine;
By now, you should begin to see the picture of how the other parts of the
tutorial can be solved. For instance, for the function AddPoly(. . .) you should

C. A Potpourri of CoCoA Programs
295
again switch the summands such that the one with the higher y-degree comes
ﬁrst, and then add the second one onto the ﬁrst one using AddUniv(. . .). And
by the time you are doing MultPoly(. . .), you will ﬁnd that the hardest part
of programming is usually to get your mathematics right. We end these hints
with a master solution of the PolyToList conversion in the general case.
Define PolyToList(F)
Return RecPolyToList(F,1);
EndDefine;
Define RecPolyToList(F,N)
If N=NumIndets() Then
Return Reversed(Coefficients(F,Indet(N)));
EndIf;
Return [RecPolyToList(G,N+1)|G In
Reversed(Coefficients(F,Indet(N)))];
EndDefine;
C.2
Diﬀerent Styles of CoCoA Programming
Computers are not intelligent.
They only think they are.
(Anonymous)
Let us show you some diﬀerent programming styles using a very elemen-
tary example. We want to create an n × n-matrix whose entries are random
integers between 0 and 100. A quick look at the on-line manual, and you
should be able to locate the function Rand(0, 100) which generates such a
random integer.
A very explicit ﬁrst way to solve our task is to create a new matrix of the
desired size and then to ﬁll it using a double For-loop.
Define RandomMatrix(N)
M:=NewMat(N,N);
For I:=1 To N Do
For J:=1 To N Do
M[I,J]:=Rand(0,100);
EndFor;
EndFor;
Return M;
EndDefine;
Another possibility which is sometimes preferred by beginners is to create
the necessary lists by starting with an empty list and using the Append(. . .)
command, for instance

296
C. A Potpourri of CoCoA Programs
Define RandomMatrix(N)
M:=[];
For I:=1 To N Do
L:=[];
For J:=1 To N Do
Append(L,Rand(0,100));
EndFor;
Append(M,L);
EndFor;
Return Mat(M);
EndDefine;
Both of these double loops tend to be rather slow in practice. Try
RandomMatrix(100)! A more eﬃcient way is to use the list constructions
advertised in Appendix B.6. In our example, we could write
Define RandomMatrix(N)
M:=[[Rand(0,100) | I In 1..N] | J In 1..N];
Return Mat(M);
EndDefine;
This would produce the same result. Even more compressed code can be
generated using the short form for deﬁning one-line functions.
RandomMatrix(N):=Mat[[Rand(0,100)|I In 1..N]|J In 1..N];
But don’t overdo it! We would consider this bad programming style. If you
squeeze too much into those list constructions, your program code becomes
diﬃcult to read. And the one who has to suﬀer most because of this is usually
yourself, when you want to reuse your code (or parts of it) at a later stage.
C.3.
Hints for Other Tutorials in Chapter 1
When all else fails,
read the instructions.
(Anonymous)
In order to make the tutorials accessible to inexperienced CoCoA pro-
grammers, we now provide some additional hints for selected tutorials in
Chapter 1. We strongly urge you to ﬁrst try those tutorials on your own. If
all else fails, you may look for some inspiration here. But keep in mind that
CoCoA programming is only 10% inspiration and 90% perspiration.
In Tutorial 2 you should not have severe problems to convert the given
steps into workable CoCoA programs. But for PolyExtEuclid(. . .), let us
show you how to implement the crucial step 4). We suppose that the tuple
(c0, d0, e0) is stored in T0 and (c1, d1, e1) in T1.

C. A Potpourri of CoCoA Programs
297
While T1[3] <> 0 Do
Q:=DivAlg(T0[3],[T1[3]]);
Q1:=Comp(Q.Quotients,1);
T:=T0-Q1*T1; T0:=T1; T1:=T;
EndWhile;
The following program computes all monic univariate polynomials of a
speciﬁed degree over a ﬁnite ﬁeld.
Define MonicPoly(D)
If D=0 Then
Return [1];
EndIf;
If D=1 Then
Return [x+N | N In 0..(Characteristic()-1)];
EndIf;
Pre:=MonicPoly(D-1);
Return ConcatLists([[x*F+N | N In
0..(Characteristic()-1)] | F In Pre]);
EndDefine;
You can use it in Tutorial 3 for writing the function IrredPoly(. . .). Loop
through all monic polynomials of some degree and check whether they are
divisible by any irreducible polynomial of smaller degree. The remainder of
the division of F by G can be found by calling NR(F,[G]).
Clearly, the function GaussFactor(. . .) in Tutorial 4 is a tough nut to
crack. So, let us help you. Suppose a Gaußian number z = a + ib ∈Z[i]
is represented in CoCoA by the list [a, b]. Using the function Sqrt(. . .) from
Appendix C.5, we can create a list of possible divisors of z = a+ib as follows.
Define PossibleDivisors(Z)
Norm:=Z[1]^2+Z[2]^2;
N:=Sqrt(Norm,0);
L:=Diff((-N..N) >< (-N..N), [[0,0]]);
Return [X In L | Mod(Norm,X[1]^2+X[2]^2)=0];
EndDefine;
While nothing special needs to be said about Tutorial 5, the following
function does part of the work in Tutorial 6. In fact, it provides a quick way
to compute the matrix Q.
Define MatQ(F)
P:=Characteristic();
Q:=NewMat(Deg(F),Deg(F),0%P);
Q[1,1]:=1%P;
XP:=NR(x^P,[F]);
XI:=1;

298
C. A Potpourri of CoCoA Programs
For I:=1 To Deg(F)-1 Do
XI:=NR(XI*XP,[F]);
Q[I+1]:=[CoeffOfTerm(x^J,XI) | J In 0..(Deg(F)-1)];
EndFor;
Return Q;
EndDefine;
Notice that the expression 1%P gives you the residue class of 1 in the ﬁeld
Z/(P), independent of what the current ring is.
Tutorials 7 and 8 are again easy, but since there are so many small func-
tions you have to write in Tutorial 8, let us do two of them for you. (The
very desperate among you can even use those programs to reverse-engineer
a hint for the proof!)
Define MonIntersection(I,J)
L:=[LCM(G[1],G[2]) | G In Gens(I) >< Gens(J)];
Return Ideal(Interreduced(L));
EndDefine;
Define MonColon(I,J)
K:=Ideal(1);
ForEach G In Gens(J) Do
L:=[LCM(F,G)/G | F In Gens(I)];
K:=MonIntersection(K,Ideal(L));
EndForEach;
Return K;
EndDefine;
For Tutorials 9 and 10, it is important that you know about CoCoA’s
sorting facilities. For instance, suppose we have a list of pairs of integers,
and we want to sort them into lexicographically increasing order. The ﬁrst
step consists of deﬁning a Boolean-valued function of two arguments which
returns TRUE if the ﬁrst argument is smaller than the second one.
Define MyLex(A,B)
Return A[1]<B[1] Or (A[1]=B[1] And A[2]<=B[2]);
EndDefine;
Now we can sort any list L of pairs of integers with respect to our comparison
function MyLex(A,B) by typing
NewL:=SortedBy(L,Function(’MyLex’));
In view of the extensive help we oﬀered for Tutorial 1, we hope that you
can manage to do Tutorial 11 essentially on your own. In order to check the
correctness of your results, you can also use the inverse transformation
Define ListToPoly(L)
Return Sum([X[1]*LogToTerm(X[2]) | X In L]);
EndDefine;

C. A Potpourri of CoCoA Programs
299
If you somehow got stuck writing the function ElSym(. . .) in Tutorial 12,
but you would like to try your luck with the last parts of the tutorial, you
can use the following alternative solution. It is based on the formula
(y −x1)(y −x2) · · · (y −xn) =
nP
i=0
(−1)n−isn−i yi
Furthermore, you can learn from this function how to use a diﬀerent base
ring inside a CoCoA function and how to move polynomials from one ring to
another.
Define AltElSym(N,I)
P:=Characteristic();
If P=0 Then
NewR::=Q[x[1..N],y];
Else
NewR::=Z/(P)[x[1..N],y];
EndIf;
Using NewR Do
F:=Product([y-x[I] | I In 1..N]);
S:=Coefficients(F,y);
SI:=(-1)^I * S[I+1];
EndUsing;
Phi:=RMap(Concat(First(Indets(),N),[0]));
Return Image(SI,Phi);
EndDefine;
In Tutorial 13 there is nothing to program, and in Tutorials 14 and 15
the stated algorithms should easily convert into CoCoA programs on a step-
by-step basis. Nevertheless, let us oﬀer you the following subprograms which
may aid you in implementing step 2) of the Division Algorithm 1.6.4.
Define Reducer(M,G)
For I:=1 To Len(G) Do
If LPos(G[I])=LPos(M) And Type(LPP(M)/LPP(G[I]))=POLY
Then
Return I;
EndIf;
EndFor;
Return 0;
EndDefine;
Define DivisionLT(M,G)
Q:=NewList(Len(G),0);
I:=Reducer(M,G);
While I<>0 Do
Q[I]:=Q[I]+LPP(M)/LPP(G[I]);

300
C. A Potpourri of CoCoA Programs
M:=M-LPP(M)/LPP(G[I])*G[I];
I:=Reducer(M,G);
EndWhile;
Return [Q,M];
EndDefine;
Finally, in Tutorial 16 no programming is required. What a pity, we were just
getting the knack of it!
C.4
Optimizing CoCoA Functions
How do you make Windows faster?
Throw it harder.
(Anonymous)
When you start to write more complicated CoCoA programs, you will soon
discover cases where the execution of the program seems to be unduly slow.
There is a simple rule-of-thumb which says that most computer programs
spend more than 90% of the execution time in less then 10% of the program
code. Hence, if you want to improve the performance of your CoCoA programs,
you have to ﬁnd the lines corresponding to those 10% of the code, and to
optimize them carefully.
Let us explain this process using a very easy example. In Appendix B.6 we
showed you the program FactorList(N) which uses recursive programming
and computes the list of prime numbers dividing a given integer N. First we
measure the time it needs to factorize a few numbers.
Time FactorList(123456789);
[3, 3, 3607, 3803]
Cpu time = 7.31, User time = 7
-------------------------------
Time FactorList(1111111);
[239, 4649]
Cpu time = 4.51, User time = 5
-------------------------------
These answers mean that, on a modest computer, it took 7.3 and 4.5 seconds
to factor the two numbers. If we look at the source code of our program, it
is clear that the most time consuming part is the While-loop. If we didn’t
know that, we could put a Time command in front of every suspicious line of
the program. For the moment, let us just put a Time command in front of
the While-loop. (We also added a PrintLn; command before Return []; in
order to improve the appearance of the output.)

C. A Potpourri of CoCoA Programs
301
FactorList(123456789);
Cpu time = 0.00, User time = 0
Cpu time = 0.00, User time = 0
Cpu time = 3.35, User time = 3
Cpu time = 3.57, User time = 4
[3, 3, 3607, 3803]
-------------------------------
FactorList(1111111);
Cpu time = 0.22, User time = 0
Cpu time = 4.34, User time = 4
[239, 4649]
-------------------------------
The data conﬁrm that almost all of the time is spent searching for the large
prime divisors. For this task, several obvious improvements are at hand. For
instance, we can start the search for a new divisor with the last one, and
after we have reduced N to an odd number we can look for odd divisors only.
The following function incorporates these optimizations.
Define FactorList2(N)
If N=1 Then
Return [];
EndIf;
If Mod(N,2)=0 Then
Return Concat([2],FactorList2(N/2));
EndIf;
L:=[];
I:=1;
While I<=N Do
I:=I+2;
If Mod(N,I)=0 Then
Append(L,I);
N:=Div(N,I);
I:=I-2;
EndIf;
EndWhile;
Return L;
EndDefine;
The result is a noticeable speeding up of our factorizations.
Time FactorList2(123456789);
[3, 3, 3607, 3803]
Cpu time = 2.14, User time = 2
-------------------------------

302
C. A Potpourri of CoCoA Programs
Time FactorList2(1111111);
[239, 4649]
Cpu time = 2.59, User time = 2
-------------------------------
But more diﬃcult examples still take too long.
Time FactorList2(111111111);
[3, 3, 37, 333667]
Cpu time = 184.50, User time = 185
-------------------------------
Sometimes alternative ways of implementing the same function can inﬂu-
ence the execution time. For instance, in Appendix C.2 the versions of the
program RandomMatrix(N) which are based on list constructions are signiﬁ-
cantly faster than the ones based on For-loops. But usually we can achieve
the best program improvements by working on the underlying mathematics.
Our third and ﬁnal version of FactorList(N) is a case in point. It applies the
function Sqrt(XRat,N) introduced in the next section to restrict the search
for prime divisors of N to numbers less than or equal to the square root of N.
Define FactorList3(N)
If N=1 Then
Return [];
EndIf;
If Mod(N,2)=0 Then
Return Concat([2],FactorList3(N/2));
EndIf;
L:=[];
S:=Sqrt(N,0);
I:=3;
Repeat
If Mod(N,I)=0 Then
Append(L,I);
N:=Div(N,I);
S:=Sqrt(N,0);
I:=I-2;
EndIf;
I:=I+2;
Until I>S;
Append(L,N);
Return L;
EndDefine;
This time the factorization of the more diﬃcult example above is found
in a split second!

C. A Potpourri of CoCoA Programs
303
Time FactorList3(111111111);
[3, 3, 37, 333667]
Cpu time = 0.17, User time = 0
-------------------------------
C.5
How To Do Calculus Using CoCoA
Ask not what your country can do for you.
Ask what you can do for your country.
(John F. Kennedy)
Most computer algebra systems have been designed and developed by
people who had certain applications or functionalities in mind. Thus each of
them has its strengths and its weaknesses. As a user, you will sooner or later
discover that your favourite computer algebra system was not designed to do
precisely what you want it to do. Should you then switch to another one?
Maybe. But frequently it is just as useful and instructive to teach your old
dog a new trick.
For instance, CoCoA was clearly not designed for applications in calculus.
In the current version, there are no ﬂoating point numbers available, and not a
single transcendental function (sin, log, exp,...) is implemented. Nevertheless,
in several situations above we needed an approximation for the square root
of a rational number. Let us show you how you can extend the scope of
CoCoA to include such a function. First we need the possibility to round a
rational number to a given number of digits after the decimal point. (Our
function always rounds the number downwards. We leave it to you to ﬁnd
the appropriate change in order to get the usual rule.)
Define Round(XRat,N)
XR:=Cast(XRat*10^N,RAT);
Return Div(XR.Num,XR.Den)/10^N;
EndDefine;
Next, we scour some calculus books and come up with an algorithm for
computing square roots. It is based on the method used by the ancient Baby-
lonians. Namely, given a real number r > 0, the sequence x0 = r and
xi = 1
2 (xi−1 +
r
xi−1 ) for i ≥1 converges to √r.
Define Babylon(XRat,N)
Last:=XRat;
New:=(XRat+1)/2;
While Abs(New-Last)>(0.1)^(N+1) Do
Last:=New;
New:=(Last+XRat/Last)/2;
EndWhile;
Return Round(New,N);
EndDefine;

304
C. A Potpourri of CoCoA Programs
Unfortunately, this method converges too slowly if we start with a large num-
ber. Hence our ﬁnal function ﬁrst reduces the problem to a number r/10i < 1
and then applies the Babylonian algorithm.
Define Sqrt(XRat,N)
I:=0;
While 10^I<Abs(XRat) Do
I:=I+1;
EndWhile;
If Mod(I,2)=1 Then
I:=I+1;
EndIf;
Return Babylon(XRat/10^I,N+I/2)*10^(I/2);
EndDefine;
It is clear that endless further possibilities exist for extending the function-
ality of CoCoA. So, do not ask what CoCoA can do for you, but what you can
do for CoCoA!

D. Hints for Selected Exercises
Rough grinding is a caveman’s job:
eat well, sleep well, and work like hell!
(John L. Dobson)
D.1
Hints for Exercises in Chapter 1
Exercise 1.1.1. Show that x2 −d generates a maximal ideal in Q[x]. Then prove
that K ∼= Q[x]/(x2 −d).
Exercise 1.1.4.
Let {v1, ..., vn} be a Z-basis of Zn . Show that the Z-module
homomorphism ϕ : Zn −→Zn is an isomorphism, where ϕ is deﬁned by ϕ(ei) = vi
for i = 1, . . . , n. Therefore there exists a matrix B ∈Matn(Z) such that AB = I .
Conversely, let x = (x1, . . . , xn)tr . Then det(A) ∈{1, −1} implies that A is
invertible in Matn(Z), and that the system of linear equations A · x = v has the
unique solution A−1 · v.
Exercise 1.1.6. Let B = {rλ | λ ∈Λ} be an R-basis of the non-zero ideal I . If it
contains two elements rλ1 , rλ2 , then rλ2rλ1 −rλ1rλ2 = 0 rλ1 −0 rλ2 . If it contains
one element r which is a zero-divisor, then there exists a non-zero element s ∈R
such that sr = 0r = 0.
Conversely, if I = (r) and r is a non-zero divisor, then the multiplication by r
yields an isomorphism of R-modules between R and I .
Exercise 1.1.7. We give a hint on c) ⇔a). Every non-zero element r generates a
principal ideal. Since this is a cyclic R-module, the element r is a non-zero divisor.
Conversely, assume that there exists a non-zero non-invertible element r. Then the
cyclic R-module R/(r) is not free.
Exercise 1.2.3.
To prove a), use the fact that the canonical images of monic
polynomials have the same degree.
Exercise 1.2.5. By assumption, there exists an element a ∈p \ {0}. Obviously,
the element a is not a unit. Then at least one of its irreducible factors, say p, is
in p. The factoriality of R implies that (p) is prime. Hence we have (p) = p.
Exercise 1.2.7.
We extend the hint on the proof of c) given at the end of the
exercise. We see that f1 = 2 + 2√−5 = 2(1 + √−5) and that f2 = 6 = 2 · 3 =
(1 −√−5)(1 + √−5). Let g = gcd(f1, f2). Then there exist a1, a2, b1, b2 ∈Z such
that g = 2(a1 +b1
√−5) = (1+√−5)(a2 +b2
√−5). Deﬁne ϕ(a+b√−5) = a2 +5b2 .
Show that ϕ is compatible with the product and evaluate ϕ(g). In this way, you
get 2(a2
1 + 5b2
1) = 3(a2
2 + 5b2
2) in N. Hence 6 | ϕ(g). On the other hand, we
have ϕ(g) | ϕ(2 −2√−5) and ϕ(g) | ϕ(6), so that ϕ(g) | 12. Now we combine

306
D. Hints for Selected Exercises
g = (1+ √−5)(a2 +b2
√−5) and 6 | ϕ(g) | 12 and get g = 1+ √−5. Together with
g = 2(a1 + b1
√−5), this yields a contradiction.
Exercise 1.2.9. To prove a), use Exercise 1.2.8. We give a hint on how to prove
that x1 + (f) is irreducible in P/(f). Suppose that there exist g, h ∈P such that
x1+(f) = (g+(f))(h+(f)). Then there exists a polynomial r such that x1 = gh+rf
holds in P . Now use considerations about the degrees of the polynomials involved
in this equation.
Exercise 1.2.11. We give a hint on c). To prove 1) ⇒2), you may assume that
f = x(x −a)(x −b) and then use a). For the converse implication, you may use
f = x(x−1)(x+1) to show that 3 is a square, and then use b) to get the conclusion.
Exercise 1.3.3. To prove d), look at the cardinality of the sets under consideration.
Exercise 1.3.5. Imitate the proof of Proposition 1.3.11.b.
Exercise 1.3.6.
Let {δ1, ..., δs} be a ﬁnite system of generators of ∆, and let
B = {bi | i ∈I} be a system of generators of ∆. Then, for every k ∈{1, ..., s},
there exist γk ∈Γ and bik ∈B such that δk = γk ◦bik . Therefore {bi1, ..., bin}
generates ∆.
Exercise 1.3.8. Use Dickson’s Lemma 1.3.6.
Exercise 1.3.9. Use the fact that Tn⟨e1, . . . , er⟩= ∪n
i=1Tnei .
Exercise 1.4.5. Use the observation made after Proposition 1.4.14 that
t1 ≥Ord(V ) t2
⇐⇒
V · (log(t1) −log(t2)) ≥Lex 0
Exercise 1.4.6. We have DegLex = Ord(V), where
V =
0
B
B
B
B
B
@
1
1
. . .
1
1
1
0
. . .
0
0
0
1
...
...
...
...
...
...
0
...
0
. . .
0
1
0
1
C
C
C
C
C
A
Exercise 1.5.3. Observe that LTσ(x2f2 −x1f3) = x1x3 ̸∈(x4
1x2, x3
1x3
2, x2
1x4
2).
Exercise 1.5.4.
Let σ = Lex, let a, b ∈K[x1, x2, x3], let f1 = a(x1 −x3
3), let
f2 = b(x2 −x4
3), and let f = f1 + f2 . First, examine the cases where a or b are
zero. Then assume that both are non-zero polynomials, and examine the case where
LMσ(ax1)+LMσ(bx2) ̸= 0. Finally, assume that LMσ(ax1)+LMσ(bx2) = 0. Show
that in every case LTσ(f) is a multiple of x1 or x2 .
Exercise 1.6.3.
The process of replacing a power product in x1 with smaller
power products in x1 , and the process of replacing a power product in x2 with
smaller power products in x2 are independent.
Exercise 1.7.8.
To prove a), use the fact that, for r, r′ ∈Rγ \ {0}, we have
r′ = (r−1r′)r. To prove d), use Corollary 1.7.11.

D. Hints for Selected Exercises
307
D.2
Hints for Exercises in Chapter 2
Exercise 2.1.2. To prove a) ⇒b), argue by contradiction. Assume that xi1 = xi2
and consider the polynomial
1
LCσ(g1) g1 −
1
LCσ(g2) g2 . To prove b) ⇒a), we suggest
an anticipation of a method which will be used later in Section 2.3. For a pair
(a1, a2) ∈P 2 \ {(0, 0)}, we deﬁne deg(a1, 0) = LTσ(a1), deg(0, a2) = LTσ(a2),
and deg(a1, a2) = max{LTσ(a1), LTσ(a2)} if both a1 and a2 are non-zero. Given
g = a1g1+a2g2 , we say that g has a representation via (a1, a2), and that deg(a1, a2)
is the degree of the representation. Show that every element in the ideal (g1, g2) has
a representation of minimal degree. Then prove that such a representation satisﬁes
Condition A2).
Exercise 2.1.3. Use K[x, y], g1 = x + 1, and g2 = y + 1.
Exercise 2.1.4. Use g3 = (x1 + 1)g1 −x2g2 = x2
2 −x2 .
Exercise 2.1.5.
Use the suggestion given for Exercise 2.1.2 above, and the fact
that x3 and y3 are coprime.
Exercise 2.2.4. To prove a) ⇒b), show that there exists a term ordering τ such
that t1 >τ t2 .
Exercise 2.3.7. To show a), use Theorem 2.3.7.b.
Exercise 2.4.8. Use Proposition 1.3.11.
Exercise 2.5.5.
Show that every reduction step transforms a binomial into a
binomial.
Exercise 2.6.1. Suppose there exists i ∈{1, . . . , n} such that m ∩K[xi] = (0).
Then show that there exists a K -algebra homomorphism K[xi] ,−→P/m which is
injective.
D.3
Hints for Exercises in Chapter 3
Exercise 3.1.1. Use the fact that P is a factorial domain.
Exercise 3.1.3.
We have Σ = {σ12, σ13, σ23}, where σ12 = xε1 −yε2 , where
σ13 = xε1 −zε3 , and where σ23 = yε2 −zε3 = σ13 −σ12 . Then consider the set
B′ = {(1, 2), (1, 3)}.
Exercise 3.2.9. To prove b) ⇒a), use the fact that ab(c, d) = bc(a, b).
Exercise 3.3.4. To show a), use the fact that fx + gy = (f −y)x + (g + x)y.
Exercise 3.4.6.
Show that {g1, . . . , gn} is a Gr¨obner basis with respect to a
suitable module term ordering.
Exercise 3.4.7. Prove that B ∼= bP/(I ∩bP).
Exercise 3.4.11. Use Proposition 3.4.6.
Exercise 3.5.2. Consider the ideal pRS .
Exercise 3.5.4. Prove that there is an isomorphism between PS and Pf .

308
D. Hints for Selected Exercises
Exercise 3.5.7. To ﬁnd an example with the required property, you may consider
the polynomial ring K[x] and the following exact sequence of P -modules.
0 −→P
x
−→P −→P/(x)P −→0
Exercise 3.5.9. If you do not ﬁnd a proof, use CoCoA to show that d2
1, d2
2 ∈J in
the case K = Q. Then verify that the representations of d2
1 and d2
2 obtained with
CoCoA are valid for every ﬁeld K .
Exercise 3.6.4. Consider the K -algebra homomorphism ϕ : K[x1, . . . , xs] −→R
which is deﬁned by ϕ(xi) = fi + I for i = 1, . . . , n.
Exercise 3.6.9. Prove that the Jacobian determinant of the composition of two
K -algebra homomorphisms from P to P is the product of the two Jacobian de-
terminants.
Exercise 3.7.1.
One important step in the proof is to show that if K is not a
perfect ﬁeld, then there exists a squarefree polynomial f such that gcd(f, f ′) = 1.
Let a ∈K be such that it has no pth root in K . Then show that f = xp −a is
irreducible. To do this, you may consider f as an element of K[x].
Ich habe fertig.
(Giovanni Trapattoni)

Notation
1. Special Sets
N
set of natural numbers, N = {0, 1, 2, . . .}
Z
set of integers
Q
set of rational numbers
Q>0
set of positive rational numbers
Q
set of algebraic numbers
R
set of real numbers
C
set of complex numbers
Fq
ﬁnite ﬁeld with q elements
Z[i]
ring of Gaußian numbers
I
set of irrational numbers, I = R \ Q
Sn
symmetric group on n elements
An
K
n-dimensional aﬃne space over a ﬁeld K
B
set of pairs B = {(i, j) | 1 ≤i < j ≤s, γi = γj}
Tn or T(x1, . . . , xn) set of terms in the indeterminates x1, . . . , xn
Tn⟨e1, . . . , er⟩set of terms in K[x1, . . . , xn]r , i.e. the set of all tei such
that t ∈Tn and 1 ≤i ≤r
S(C)
set of all C -splines
P(V )
projective space associated to a vector space V
P n
K
projective space associated to Kn
En
set of extended terms xα1
1 · · · xαn
n , where α1, . . . , αn ∈Z
2. Sets and Maps
A ⊆B
set A is a (not necessarily proper) subset of set B
A ⊂B
set A is a proper subset of set B
A \ B
set diﬀerence of A and B, i.e. the set of all elements of A
which are not contained in B
#A
number of elements of a ﬁnite set A
ψ ◦ϕ
composition of two maps ϕ : A −→B and ψ : B −→C
Im(ϕ)
image of a map ϕ : A −→B
Ker(ϕ)
kernel of a homomorphism ϕ : A −→B

310
Notation
Coker(ϕ)
cokernel of a homomorphism ϕ : A −→B, i.e. Coker(ϕ) =
B/ Im(ϕ)
idA
identity map on a set A
A −↠B
a surjective map A −→B
A ,−→B
an injective map A −→B
ϕˇ
dual of a linear map
0 −→A
ϕ
−→B
ψ
−→C −→0 exact sequence of homomorphisms, i.e. a se-
quence such that ϕ is injective, ψ is surjective, and Im(ϕ) =
Ker(ψ)
LM : P r −→P r map deﬁned by LM(m) = LMσ(m) for m ̸= 0 and
LM(0) = 0
LF : P s −→P s map deﬁned by LF(m) = LFσ,G(m) for m ̸= 0 and
LF(0) = 0
ZL(f)
set of zeros of a polynomial
ZL(I)
set of zeros of an ideal
p1p2
line through two points p1 and p2
(p0 : . . . : pn) point in an n-dimensional projective space
Hyp(P n
K)
set of hyperplanes in P n
K
Lin(P n
K)
set of lines in P n
K
(P n
K)ˇ
dual projective space
Grassm(P n
K) Graßmannian of m-dimensional subspaces of P n
K
3. Orderings
≥σ
monoid ordering or module ordering
Lex
lexicographic term ordering
DegLex
degree-lexicographic term ordering
DegRevLex
degree-reverse-lexicographic term ordering
RevLex
reverse-lexicographic ordering
Elim(L)
elimination ordering for L
Ord(V )
ordering associated to the matrix V
4. Polynomials and Vectors
deg(f)
degree of a polynomial
Supp(v)
support of a vector of polynomials
gcd(f1, . . . , fm) greatest common divisor of f1, . . . , fm
lcm(f1, . . . , fm) least common multiple of f1, . . . , fm
sqfree(f)
squarefree part of f
cont(f)
content of a univariate polynomial f
f ′
derivative of a univariate polynomial f
Newton(f)
Newton polytope of a polynomial
[v1v2]
line segment from v1 to v2

Notation
311
LTσ(v)
leading term of a vector of polynomials
LCσ(v)
leading coeﬃcient of a vector of polynomials
LMσ(v)
equals LCσ(v) · LTσ(v)
NRσ,G(v)
normal remainder of a vector
LMσ(G)
deﬁned by LMσ(G) = (LMσ(g1), . . . , LMσ(gs)) for a tuple
G = (g1, . . . , gs)
degσ,G(v)
σ-degree of a vector
LFσ,G(v)
σ-leading form of a vector
tij
deﬁned by tij = lcm(ti,tj)
ti
for terms ti, tj
σij
fundamental syzygy, σij = LCσ(gi)−1tijεi −LCσ(gj)−1tjiεj
Sij
S-vector of gi and gj , deﬁned by Sij = LCσ(gi)−1tijgi −
LCσ(gj)−1tjigj
NFσ,M(v)
normal form of a vector w.r.t. a submodule
det( fi
xj )
Jacobian determinant of a system of polynomials
5. Rings and Fields
char(K)
characteristic of the ﬁeld K
Q(R)
ﬁeld of fractions of an integral domain R
K[x1, . . . , xn] polynomial ring in the indeterminates x1, . . . , xn over K
K(x1, . . . , xn) ﬁeld of rational functions in the indeterminates x1, . . . , xn
over K
K[[x]]
power series ring in one indeterminate
K[x1, . . . , xn, x−1
1 , . . . , x−1
n ] Laurent polynomial ring
K[x1, . . . , xn]G ring of invariants of G
Qn
i=1 Ri
direct product of the rings R1, . . . , Rn
6. Ideals and Modules
rk(M)
rank of a free module
{e1, . . . , er}
canonical basis of a ﬁnitely generated free module
M1 ⊕M2
direct sum of two groups or modules
I · M
submodule of M generated by products fm, where f ∈I
and m ∈M
v + M
residue class of a vector v modulo M
⟨mλ | λ ∈Λ⟩module generated by the set {mλ | λ ∈Λ}
(fλ | λ ∈Λ)
ideal (or monoideal) generated by the set {fλ | λ ∈Λ}
LTσ(M)
leading term module of M
LTσ{M}
monomodule of terms in M
SyzR(G)
syzygy module of a tuple G
√
I
radical of an ideal
I(S)
vanishing ideal of a set of points
AnnR(M)
annihilator of a module

312
Notation
N :R M
colon ideal of N by M
N :M I
colon module of N by I in M
HomR(M, N) Hom-module of linear maps ϕ : M −→N
Exti
R(R/I, M) ith Ext-module of R/I with values in M
MS
localization of a module M at a multiplicatively closed set S
Mf
localization of a module at an element f
N :M I∞
saturation of a module N by an ideal I in M
IL
lattice ideal associated to L
7. Matrices
Matn(R)
set of n × n-matrices over R
Matm,n(R)
set of m × n-matrices over R
GLn(R)
set of invertible n × n-matrices over R
A tr
transposed matrix of A
Is
identity matrix of size s × s
Aϕ
matrix associated to a linear map ϕ
Λr,s
homomorphism mapping a linear map to its associated matrix
Fls,r
ﬂattening isomorphism
Φr,s
isomorphism deﬁned by Φr,s = Fls,r ◦Λr,s
A ⊗B
tensor product of A and B
8. Mathematical Operators
dimK(V )
dimension of a K -vector space V
log(t)
logarithm of a term, log(xα1
1 · · · xαn
n ) = (α1, . . . , αn)
conv(S)
convex hull of a set
Vert(P)
set of vertices of a polytope
maxσ(A)
maximum of the set A w.r.t. the relation σ
inf(A)
inﬁmum of a set A of real numbers
sup(A)
supremum of a set A of real numbers
g
−→
reduction step using an element g
G
−→
rewrite relation deﬁned by a set of vectors
G
←→
equivalence relation deﬁned by
G
−→
TopK,L
relative Zariski topology
depthI(M)
I -depth of a module
IP(A, b, C)
integer programming problem
ϱG
Reynolds operator of G
ℓ(f)
number of terms in the support of a polynomial f
E(X)
expected value of a random variable X
Var(X)
variance of a random variable X
σ(X)
standard deviation of a random variable X
Cov(X, Y )
covariance of two random variables X, Y
ϱ(X, Y )
correlation coeﬃcient of two random variables X, Y

Bibliography
[AL94] W. Adams and P. Loustaunau, An introduction to Gr¨obner bases, Graduate
Studies in Math. 3, Amer. Math. Soc., Providence 1994
[BW93] T. Becker and V. Weispfenning, Gr¨obner bases, Springer, New York 1993
[Bu65] B. Buchberger, On ﬁnding a vector space basis of the residue class ring mod-
ulo a zero dimensional polynomial ideal (in German), PhD Thesis, Universit¨at
Innsbruck, Innsbruck 1965
[BW98] B. Buchberger and F. Winkler, Gr¨obner bases and applications, London
Math. Soc. Lect. Note Ser. 251, Cambridge University Press, Cambridge 1998
[CLS92] D. Cox, J. Little, and D. O’Shea, Ideals, varieties, and algorithms,
Springer, New York 1992
[Ei95] D. Eisenbud, Commutative algebra with a view toward algebraic geometry,
Springer, New York 1995
[Fr97] R. Fr¨oberg, An introduction to Gr¨obner bases, John Wiley & Sons, Chich-
ester 1997
[Ku80] E. Kunz, Introduction to commutative algebra and algebraic geometry,
Birkh¨auser, Boston 1985
[La70] S. Lang, Algebra, Addison-Wesley, Reading 1970
[Mi93] B. Mishra, Algorithmic algebra, Springer, New York 1993
[Va98] W. Vasconcelos, Computational methods in commutative algebra and al-
gebraic geometry, Algorithms and Computation in Math. 2, Springer, Berlin
1998
[Wi96] F. Winkler, Polynomial algorithms in computer algebra, Springer, Wien
1996


Index
aﬃne
– algebra, 134
– set, 144
– space, 144
– variety, 138, 144
algebra, 18
– aﬃne, 134
– automorphism, 231
– ﬁnitely generated, 23
– fundamental theorem of, 137
– presentation, 23
algebraic closure of a ﬁeld, 137
algebraic element, 227
algebraic relation, 23, 227
algebraically closed ﬁeld, 137
algorithm
– Berlekamp, 38
– Buchberger, 123
– division, 71
– Euclidean, 26
– extended Buchberger, 125
– extended Euclidean, 27
– for solving systems eﬀectively, 257
– normal remainder, 75
alternating group, 237
annihilator, 166
– computation, 167
– of a cyclic module, 167
– of a module, 166
antisymmetry, 50, 54
associated
– elements, 31
– matrix, 182
– prime, 175
– projective space, 204
– toric ideal, 222
automorphism
– of a polynomial ring, 232
– of an algebra, 231
basis
– canonical, 20
– of a module, 19
Berlekamp algorithm, 38
binomial, 127
– ideal, 127
Buchberger triple, 131
Buchberger’s algorithm, 123
– extended version, 125
– optimization, 124, 131
Buchberger’s criterion, 122, 128
CoCoA, 11
– introduction, 275
– programming, 283
cancellation law, 42
– left, 42
– right, 42
canonical basis, 20
Cauchy-Schwarz inequality, 269
characterization
– of Gr¨obner bases, 111, 122
– of homogeneous prime ideals, 80
– of Noetherian modules, 112
– of Noetherian monoids, 42
– of DegRevLex, 65
– of Lex, 63
– of RevLex, 64
Chinese remainder theorem, 39, 245
coeﬃcient, 22
– leading, 60
cogenerator, 47
colon ideal, 48, 166
– computation, 167, 175, 204
colon module, 169
– computation, 170, 175
– using elimination, 199
comaximal ideals, 245
commutative monoid, 17
complete relation, 50
complex of linear maps, 194
component elimination
– module, 202
– ordering, 202

316
Index
conﬂuent rewrite relation, 95
content, 33
contravariant Hom-functor, 182
convex
– hull, 67
– set, 67
coprime elements, 31
correlation coeﬃcient, 268
cost compatible term ordering, 210
cost function, 209
covariance, 268
covariant Hom-functor, 182
cyclic
– group, 236
– module, 19
decomposition
– into homogeneous components, 77
degree
– compatible term ordering, 52
– in Tn⟨e1, . . . , er⟩-graded modules,
102
– of a polynomial, 22
– of a spline, 157
– of a term, 22
– shifting, 78
degree-lexicographic term ordering, 51
degree-reverse-lexicographic term
ordering, 51
dense polynomial, 262
depth of a module, 193
dihedral group, 237
Diophantine system, 207
disconnected set, 142
division algorithm, 71
– implementation, 74
domain
– Euclidean, 36
– factorial, 30
– integral, 18
– principal ideal, 19
dual
– map, 190
– projective space, 205
– sequence, 190
eﬀective pth roots, 248
eﬃcient
– frontier, 269
– portfolio, 269
element
– algebraic, 227
– associated, 31
– coprime, 31
– deﬁnes a rewrite rule, 92
– homogeneous, 76
– irreducible, 29
– prime, 29
– reduces to another element, 92
– reducible, 29
– squarefree part, 31
– transcendental, 227
elementary symmetric polynomial, 66
elimination
– computation, 197, 202
– ideal, 196
– module, 48, 196, 202
– of module components, 202
– ordering, 52, 196, 202
Enneper surface, 233
Euclidean algorithm, 26
– extended, 27
Euclidean domain, 36
evaluation, 23
– homomorphism, 23
exact sequence
– deﬁning syzygies, 100
– of Hom-modules, 185
expected return, 268
explicit membership, 152
Ext-module, 194
extended division, 214, 220
extended term, 208
factorial domain, 30
factorization, 29
ﬁber, 234
ﬁeld, 17
– algebraic closure, 137
– algebraically closed, 137
– ﬁnite, 27
– graded, 82
– having eﬀective pth roots, 248
– of algebraic numbers, 98
– of deﬁnition, 116
– of fractions, 212
– perfect, 37, 247
ﬁniteness criterion, 243
ﬂattening isomorphism, 182
folium of Descartes, 201
form, 77
Frobenius map, 37
functoriality of the Hom-module, 182
fundamental diagram
– of Hom-modules, 187
– of syzygy modules, 103, 121
fundamental property

Index
317
– of term orderings, 56
fundamental theorem
– of algebra, 137
Gaußian
– elimination, 119
– numbers, 36, 80
general linear group, 236
generation of leading term modules, 88
Gr¨obner basis, 111
– characterization, 111
– computation, 129
– existence, 112
– homogeneous, 120
– invariance under ﬁeld extension, 116
– minimal, 118
– reduced, 115, 120
Graßmannian, 206
graded
– ﬁeld, 82
– free module, 78
– module, 77
– residue class module, 79
– residue class ring, 79
– ring, 76
– submodule, 79
grading
– by Tn , 77
– by Tn⟨e1, . . . , er⟩, 78
– on syzygy module, 101
– standard, 77
graph, 235
– colouring, 143
greatest common divisor, 31
– computation, 165
group, 17
– alternating, 237
– cyclic, 236
– dihedral, 237
– general linear, 236
– of matrices, 236
– of permutations, 237
– of reﬂections, 237
– of rotations, 237
Heron’s formula, 196
Hilbert’s basis theorem, 113
Hilbert’s Nullstellensatz, 140
– ﬁeld-theoretic version, 136
– strong version, 140
– weak version, 139
Hilbert’s syzygy theorem, 159
Hom-functor
– contravariant, 182
– covariant, 182
– exactness properties, 185
Hom-module, 181
– computation, 186
homogeneous
– component, 77
– element, 76
– form, 77
– Gr¨obner basis, 120
– ideal, 79
– linear map, 78
– polynomial, 77, 83
– prime ideal, 80
– system of generators, 79
homogenization, 172
homomorphism
– algebra, 18
– characteristic, 18
– evaluation, 23
– Frobenius, 37
– module, 18
– of graded modules, 78
– of graded rings, 78
– ring, 18
– structural, 18
– substitution, 23, 226
hyperplane, 204
ideal, 18
– binomial, 127
– colon, 48
– comaximal, 245
– elimination, 196
– homogeneous, 79
– irreducible, 264
– lattice, 223
– maximal, 19
– membership test, 114
– monomial, 44
– of algebraic relations, 23, 227
– primary, 264
– prime, 19
– principal, 19
– radical, 48, 139
– stable, 119
– toric, 222
– vanishing, 140
– zero-dimensional, 244
ideal quotient, 166
image
– of a linear map, 178
– of a morphism, 235
– of an algebra homomorphism, 228

318
Index
implicitization, 227
increasingly ordered tuple, 118
integer programming, 207, 222
integral domain, 18
interreduced tuple, 118
intersection
– computation, 174, 203
– of several submodules, 164
– of two submodules, 162
– using elimination, 199
invariant polynomial, 237
invariant theory, 236
irrational numbers, 42
irreducible
– element, 29
– ideal, 264
– w.r.t. a rewrite relation, 92
irredundant system of generators, 154
Jacobian
– conjecture, 233
– determinant, 233
kernel
– computation, 191, 227
– of a linear map, 178
– of an algebra homomorphism, 227
Klein four group, 236
Kronecker product, 184
Krull-Azumaya lemma, 76
Lagrange interpolation, 156
Lagrange multipliers, 270
lattice, 223
– ideal, 223
Laurent polynomial, 208
leading
– coeﬃcient, 60
– form, 102
– position, 60
– power product, 60
– term, 60
– term ideal, 62
– – of a square, 123
– term module, 61
least common multiple, 31
– computation, 165
left-cancellation law, 42
lemma
– of Dickson, 43
– of Gauß, 33
– of Krull-Azumaya, 76
– of Nakayama, 81
– of Seidenberg, 250
lexicographic term ordering, 51
lifting
– computation, 109, 180
– existence, 106, 180
– of a linear map, 180
– of syzygies, 106, 109
line, 144
– in projective space, 204
– segment, 67
linear algebra, 119, 178
linear map, 18
– homogeneous, 78
localization, 213
logarithm, 22
Macaulay’s basis theorem, 62, 115
matrix
– associated to a linear map, 182
– group, 236
– notation, 147
maximal ideal, 19
– structure theorem, 137, 141
MEL-rule, 272
method of tag variables, 196
minimal Gr¨obner basis, 118
minimal polynomial, 227
– of an algebraic number, 89, 98
minimal risk portfolio, 270
modern portfolio theory, 267
modular law, 173
module, 18
– annihilator, 166
– basis, 19
– colon, 169
– cyclic, 19
– deﬁned over a ﬁeld, 116
– depth, 193
– elimination, 48, 196
– ﬁnitely generated, 19
– free, 19
– graded, 77
– graded free, 78
– monomial, 44
– Noetherian, 112
– of fractions, 213
– of homomorphisms, 181
– of syzygies, 100
– ordering, 54
– projective, 191
– rank, 19
– term ordering, 54
Molien’s theorem, 238
monic

Index
319
– polynomial, 60
– tuple, 118
monoid, 17, 41
– commutative, 17
– ideal, 41
– module, 41
– Noetherian, 42
– ordering, 50
– with cancellation law, 42
monoideal, 41
monomial ideal, 44
monomial module, 44
– structure theorem, 44
monomodule, 41
– Noetherian, 46
morphism of aﬃne spaces, 234
multiplicatively closed set, 212
Nakayama’s lemma, 81
natural spline, 158
Newton polytope, 67
Newton’s identities, 239
nilpotent element, 18
Noetherian
– module, 112
– monoid, 42
– monomodule, 46
non-zerodivisor, 18
– for a module, 171, 176
normal
– xi -position, 254
– form, 73, 113
– remainder, 73, 75
– remainder algorithm, 75
– selection strategy, 124
Nullstellensatz
– ﬁeld-theoretic version, 136
– strong version, 140
– weak version, 139
number ﬁeld
– algebraic closure, 98
– Gaußian, 36
– quadratic, 24
ordering
– RevLex, 52
– compatible, 55
– induced by a tuple, 149
– of a monoid, 50
– of a monomodule, 54
– of terms, 50
– represented by a matrix, 52, 57
– reverse-lexicographic, 52
outer product, 184
palindromic verse, 241
parametrically deﬁned space curve, 196
perfect ﬁeld, 37, 247
permutation group, 237
Pl¨ucker relations, 207
point, 137
– in projective space, 204
polynomial, 20
– binomial, 127
– content, 33
– dense, 262
– derivative, 35
– elementary symmetric, 66
– homogeneous, 77, 83
– invariant, 237
– Lagrange interpolation, 156
– Laurent, 208
– map, 234
– minimal, 89, 227
– monic, 28, 60
– multivariate, 20
– primitive, 33
– representation, 24, 60, 66
– squarefree part, 37
– strange, 261
– symmetric, 66, 129, 230
– univariate, 20
– zero, 137
polynomial ring, 20
– factoriality, 33
– surjective homomorphism, 230
– univariate, 20
polytope, 67
– Newton, 67
– vertex, 67
portfolio, 268
power product, 22
preimage computation, 162
presentation
– of a module, 164
– of a subquotient, 164
– of an algebra, 23
– of the image, 178, 228
– of the kernel, 178
– via generators and relations, 164
primary
– decomposition, 264
– ideal, 264
prime
– associated, 175
– element, 29
– ideal, 19

320
Index
primitive element theorem, 256
primitive polynomial, 33
principal ideal domain, 19
projection, 235
projective
– hyperplane, 204
– line, 204
– module, 191
– point, 204
– space, 204
pullback, 191
– universal property, 192
Pythagorean triple, 173
– fundamental, 173
– positive, 173
radical, 139
– ideal, 48, 139
– membership test, 219
– of a zero-dimensional ideal, 247
– – computation, 251
rank, 19
reduced Gr¨obner basis, 115, 120
reduces in one step, 92
reducible
– element, 29
– ideal, 142
– topological space, 142
reduction step, 92
reﬂection group, 237
reﬂexivity, 50, 54
regular sequence, 171
– in an ideal, 193
– test, 172
relation, 50
– algebraic, 23
– complete, 50
– rewrite, 92
relatively prime elements, 31
reverse-lexicographic ordering, 52
rewrite relation, 92
– conﬂuent, 95
rewrite rule, 92
Reynolds operator, 238
right-cancellation law, 42
ring, 17
– graded, 76
– homomorphism, 18
– of invariants, 238
– polynomial, 20
– unique factorization, 30
rotation group, 237
running example, 100
S-polynomial, 122
S-vector, 122
saturation, 215
– and localization, 216
– computation, 215, 217, 220
– exactness properties, 220
scalar multiplication, 18
Seidenberg’s lemma, 250
set
– aﬃne, 144
– convex, 67
– disconnected, 142
– multiplicatively closed, 212
– of zeros, 138
shape lemma, 257
shifting degrees, 78
special generation of submodules, 87
spline, 155
– degree, 157
– function, 156
– natural, 158
squarefree part, 31
– computation, 249
stable ideal, 119
standard deviation, 268
standard grading, 77
strong law of large numbers, 271
subalgebra
– membership test, 230
– of a function ﬁeld, 240
submodule, 18
– membership test, 114
submonomodule, 41
substitution homomorphism, 23, 226
support, 22
symmetric
– group, 66
– polynomial, 66, 129, 230
system
– of Diophantine equations, 207
– of Diophantine inequalities, 207
– of polynomial equations, 241
system of generators
– homogeneous, 79
– irredundant, 154
– minimal homogeneous, 81
– minimal monomial, 45
– of a module, 19
– of a monoideal, 41
– of a monomodule, 42
– of an algebra, 23
– of leading term module, 88
– special, 87

Index
321
syzygy, 100
– of terms, 104
– trivial, 125
syzygy module, 100
– computation, 152, 203
– of a Gr¨obner basis, 151
– of elements of a monomial module,
104, 108
syzygy theorem of Hilbert, 159
Taylor expansion, 272
tensor product, 184
term, 22
– extended, 208
– leading, 60
– of a module, 22
term ordering, 50
– DegLex, 51
– DegRevLex, 51
– Elim(L), 52
– Lex, 51
– Ord(V), 52
– PosTo, 55
– ToPos, 55
– classiﬁcation, 58
– compatible, 55
– cost compatible, 210
– degree compatible, 52
– degree-lexicographic, 51
– degree-reverse-lexicographic, 51
– elimination, 52, 196
– induced by a tuple, 149
– lexicographic, 51
– module, 54
– represented by a matrix, 52
theorem
– Chinese remainder, 39, 245
– of Hilbert, 113, 159
– of Macaulay, 62, 115
– of Molien, 238
– primitive element, 256
toric ideal, 222
total return, 267
transcendental element, 227
transitive closure, 92
transitivity, 50, 54
trivial reduction, 92
trivial syzygy, 125
twisted cubic curve, 201
– tangent surface, 233
unique factorization domain, 30
universal property
– of localization, 219
– of polynomial rings, 23
– of the pullback, 192
vanishing ideal, 140
variance, 268
Veronese surface, 235
vertex, 67
well-ordering, 55
Whitney’s umbrella, 235
Zariski closure, 144
Zariski topology, 144
zero, 137
– set, 138, 144
zero-dimensional ideal, 244

