THE FRANK J. FABOZZI SERIES
DESSISLAVA A. PACHAMANOVA • FRANK J. FABOZZI
SIMULATION AND
OPTIMIZATION
IN FINANCE + Web Site
Modeling with MATLAB,
@RISK, or VBA


Simulation and
Optimization in
Finance

The Frank J. Fabozzi Series
Fixed Income Securities, Second Edition by Frank J. Fabozzi
Focus on Value: A Corporate and Investor Guide to Wealth Creation by James L. Grant and James A. Abate
Handbook of Global Fixed Income Calculations by Dragomir Krgin
Managing a Corporate Bond Portfolio by Leland E. Crabbe and Frank J. Fabozzi
Real Options and Option-Embedded Securities by William T. Moore
Capital Budgeting: Theory and Practice by Pamela P. Peterson and Frank J. Fabozzi
The Exchange-Traded Funds Manual by Gary L. Gastineau
Professional Perspectives on Fixed Income Portfolio Management, Volume 3 edited by Frank J. Fabozzi
Investing in Emerging Fixed Income Markets edited by Frank J. Fabozzi and Efstathia Pilarinu
Handbook of Alternative Assets by Mark J. P. Anson
The Global Money Markets by Frank J. Fabozzi, Steven V. Mann, and Moorad Choudhry
The Handbook of Financial Instruments edited by Frank J. Fabozzi
Interest Rate, Term Structure, and Valuation Modeling edited by Frank J. Fabozzi
Investment Performance Measurement by Bruce J. Feibel
The Handbook of Equity Style Management edited by T. Daniel Coggin and Frank J. Fabozzi
The Theory and Practice of Investment Management edited by Frank J. Fabozzi and Harry M. Markowitz
Foundations of Economic Value Added, Second Edition by James L. Grant
Financial Management and Analysis, Second Edition by Frank J. Fabozzi and Pamela P. Peterson
Measuring and Controlling Interest Rate and Credit Risk, Second Edition by Frank J. Fabozzi, Steven V. Mann, and
Moorad Choudhry
Professional Perspectives on Fixed Income Portfolio Management, Volume 4 edited by Frank J. Fabozzi
The Handbook of European Fixed Income Securities edited by Frank J. Fabozzi and Moorad Choudhry
The Handbook of European Structured Financial Products edited by Frank J. Fabozzi and Moorad Choudhry
The Mathematics of Financial Modeling and Investment Management by Sergio M. Focardi and Frank J. Fabozzi
Short Selling: Strategies, Risks, and Rewards edited by Frank J. Fabozzi
The Real Estate Investment Handbook by G. Timothy Haight and Daniel Singer
Market Neutral Strategies edited by Bruce I. Jacobs and Kenneth N. Levy
Securities Finance: Securities Lending and Repurchase Agreements edited by Frank J. Fabozzi and Steven V. Mann
Fat-Tailed and Skewed Asset Return Distributions by Svetlozar T. Rachev, Christian Menn, and Frank J. Fabozzi
Financial Modeling of the Equity Market: From CAPM to Cointegration by Frank J. Fabozzi, Sergio M. Focardi, and
Petter N. Kolm
Advanced Bond Portfolio Management: Best Practices in Modeling and Strategies edited by Frank J. Fabozzi, Lionel
Martellini, and Philippe Priaulet
Analysis of Financial Statements, Second Edition by Pamela P. Peterson and Frank J. Fabozzi
Collateralized Debt Obligations: Structures and Analysis, Second Edition by Douglas J. Lucas, Laurie S. Goodman, and
Frank J. Fabozzi
Handbook of Alternative Assets, Second Edition by Mark J. P. Anson
Introduction to Structured Finance by Frank J. Fabozzi, Henry A. Davis, and Moorad Choudhry
Financial Econometrics by Svetlozar T. Rachev, Stefan Mittnik, Frank J. Fabozzi, Sergio M. Focardi, and Teo Jasic
Developments in Collateralized Debt Obligations: New Products and Insights by Douglas J. Lucas, Laurie S. Goodman,
Frank J. Fabozzi, and Rebecca J. Manning
Robust Portfolio Optimization and Management by Frank J. Fabozzi, Peter N. Kolm, Dessislava A. Pachamanova, and
Sergio M. Focardi
Advanced Stochastic Models, Risk Assessment, and Portfolio Optimizations by Svetlozar T. Rachev, Stogan V. Stoyanov,
and Frank J. Fabozzi
How to Select Investment Managers and Evaluate Performance by G. Timothy Haight, Stephen O. Morrell, and
Glenn E. Ross
Bayesian Methods in Finance by Svetlozar T. Rachev, John S. J. Hsu, Biliana S. Bagasheva, and Frank J. Fabozzi
The Handbook of Commodity Investing by Frank J. Fabozzi, Roland F¨uss, and Dieter G. Kaiser
The Handbook of Municipal Bonds edited by Sylvan G. Feldstein and Frank J. Fabozzi
Subprime Mortgage Credit Derivatives by Laurie S. Goodman, Shumin Li, Douglas J. Lucas, Thomas A Zimmerman,
and Frank J. Fabozzi
Introduction to Securitization by Frank J. Fabozzi and Vinod Kothari
Structured Products and Related Credit Derivatives edited by Brian P. Lancaster, Glenn M. Schultz, and Frank J. Fabozzi
Handbook of Finance: Volume I: Financial Markets and Instruments edited by Frank J. Fabozzi
Handbook of Finance: Volume II: Financial Management and Asset Management edited by Frank J. Fabozzi
Handbook of Finance: Volume III: Valuation, Financial Modeling, and Quantitative Tools edited by Frank J. Fabozzi
Finance: Capital Markets, Financial Management, and Investment Management by Frank J. Fabozzi and Pamela
Peterson-Drake
Active Private Equity Real Estate Strategy edited by David J. Lynn
Foundations and Applications of the Time Value of Money by Pamela Peterson-Drake and Frank J. Fabozzi
Leveraged Finance: Concepts, Methods, and Trading of High-Yield Bonds, Loans, and Derivatives by Stephen Antczak,
Douglas Lucas, and Frank J. Fabozzi
Modern Financial Systems: Theory and Applications by Edwin Neave
Institutional Investment Management: Equity and Bond Portfolio Strategies and Applications by Frank J. Fabozzi
Quantitative Equity Investing: Techniques and Strategies by Frank J. Fabozzi, Sergio M. Focardi, Petter N. Kolm
Simulation and Optimization in Finance: Modeling with MATLAB, @RISK, or VBA by Dessislava A. Pachamanova and
Frank J. Fabozzi

Simulation and
Optimization in
Finance
Modeling with MATLAB,
@RISK, or VBA
DESSISLAVA A. PACHAMANOVA
FRANK J. FABOZZI
John Wiley & Sons, Inc.

Copyright C⃝2010 by John Wiley & Sons, Inc. All rights reserved.
Published by John Wiley & Sons, Inc., Hoboken, New Jersey.
Published simultaneously in Canada.
No part of this publication may be reproduced, stored in a retrieval system, or transmitted in
any form or by any means, electronic, mechanical, photocopying, recording, scanning, or
otherwise, except as permitted under Section 107 or 108 of the 1976 United States Copyright
Act, without either the prior written permission of the Publisher, or authorization through
payment of the appropriate per-copy fee to the Copyright Clearance Center, Inc., 222
Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax (978) 646-8600, or on the Web
at www.copyright.com. Requests to the Publisher for permission should be addressed to the
Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030,
(201) 748-6011, fax (201) 748-6008, or online at http://www.wiley.com/go/permissions.
Limit of Liability/Disclaimer of Warranty: While the publisher and author have used their
best efforts in preparing this book, they make no representations or warranties with respect to
the accuracy or completeness of the contents of this book and speciﬁcally disclaim any implied
warranties of merchantability or ﬁtness for a particular purpose. No warranty may be created
or extended by sales representatives or written sales materials. The advice and strategies
contained herein may not be suitable for your situation. You should consult with a
professional where appropriate. Neither the publisher nor author shall be liable for any loss of
proﬁt or any other commercial damages, including but not limited to special, incidental,
consequential, or other damages.
For general information on our other products and services or for technical support, please
contact our Customer Care Department within the United States at (800) 762-2974, outside
the United States at (317) 572-3993 or fax (317) 572-4002.
Wiley also publishes its books in a variety of electronic formats. Some content that appears in
print may not be available in electronic formats. For more information about Wiley products,
visit our Web site at www.wiley.com.
Library of Congress Cataloging-in-Publication Data:
Pachamanova, Dessislava A.
Simulation and optimization in ﬁnance : modeling with MATLAB, @RISK, or VBA /
Dessislava A. Pachamanova, Frank J. Fabozzi.
p. cm. – (Frank J. Fabozzi series ; 173)
Includes index.
ISBN 978-0-470-37189-3 (cloth); 978-0-470-88211-5 (ebk);
978-0-470-88212-2 (ebk)
1. Finance–Mathematical models–Computer programs.
I. Fabozzi, Frank J.
II. Title.
HG106.P33 2010
332.0285′53–dc22
2010027038
Printed in the United States of America
10
9
8
7
6
5
4
3
2
1

Dessislava A. Pachamanova
To my husband, Christian, and my children,
Anna and Coleman
Frank J. Fabozzi
To my wife, Donna, and my children, Patricia,
Karly, and Francesco


Contents
Preface
xi
About the Authors
xvi
Acknowledgments
xvii
CHAPTER 1
Introduction
1
Optimization; Simulation; Outline of Topics
PART ONE
Fundamental Concepts
CHAPTER 2
Important Finance Concepts
11
Basic Theory of Interest; Asset Classes; Basic Trading
Terminology; Calculating Rate of Return; Valuation;
Important Concepts in Fixed Income; Summary; Notes
CHAPTER 3
Random Variables, Probability Distributions, and
Important Statistical Concepts
51
What is a Probability Distribution?; Bernoulli
Probability Distribution and Probability Mass
Functions; Binomial Probability Distribution and
Discrete Distributions; Normal Distribution and
Probability Density Functions; Concept of Cumulative
Probability; Describing Distributions; Brief Overview
of Some Important Probability Distributions;
Dependence Between Two Random Variables:
Covariance and Correlation; Sums of Random
Variables; Joint Probability Distributions and
Conditional Probability; From Probability Theory to
Statistical Measurement: Probability Distributions and
Sampling; Summary; Software Hints; Notes
vii

viii
CONTENTS
CHAPTER 4
Simulation Modeling
101
Monte Carlo Simulation: A Simple Example; Why Use
Simulation?; Important Questions in Simulation
Modeling; Random Number Generation; Summary;
Software Hints; Notes
CHAPTER 5
Optimization Modeling
143
Optimization Formulations; Important Types of
Optimization Problems; Optimization Problem
Formulation Examples; Optimization Algorithms;
Optimization Duality; Multistage Optimization;
Optimization Software; Summary; Software Hints; Notes
CHAPTER 6
Optimization under Uncertainty
211
Dynamic Programming; Stochastic Programming;
Robust Optimization; Summary; Notes
PART TWO
Portfolio Optimization and Risk Measures
CHAPTER 7
Asset Diversiﬁcation and Efﬁcient Frontiers
245
The Case for Diversiﬁcation; The Classical
Mean-Variance Optimization Framework; Efﬁcient
Frontiers; Alternative Formulations of the Classical
Mean-Variance Optimization Problem; The Capital
Market Line; Expected Utility Theory; Summary;
Software Hints; Notes
CHAPTER 8
Advances in the Theory of Portfolio Risk Measures
277
Classes of Risk Measures; Value-At-Risk; Conditional
Value-At-Risk and the Concept of Coherent Risk
Measures; Summary; Software Hints; Notes
CHAPTER 9
Equity Portfolio Selection in Practice
321
The Investment Process; Portfolio Constraints
Commonly Used in Practice; Benchmark Exposure and
Tracking Error Minimization; Incorporating

Contents
ix
Transaction Costs; Incorporating Taxes; Multiaccount
Optimization; Robust Parameter Estimation; Portfolio
Resampling; Robust Portfolio Optimization; Summary;
Software Hints; Notes
CHAPTER 10
Fixed Income Portfolio Management in Practice
373
Measuring Bond Portfolio Risk; The Spectrum of Bond
Portfolio Management Strategies; Liability-Driven
Strategies; Summary; Notes
PART THREE
Asset Pricing Models
CHAPTER 11
Factor Models
401
The Capital Asset Pricing Model; The Arbitrage Pricing
Theory; Building Multifactor Models in Practice;
Applications of Factor Models in Portfolio
Management; Summary; Software Hints; Notes
CHAPTER 12
Modeling Asset Price Dynamics
421
Binomial Trees; Arithmetic Random Walks; Geometric
Random Walks; Mean Reversion; Advanced Random
Walk Models; Stochastic Processes; Summary;
Software Hints; Notes
PART FOUR
Derivative Pricing and Use
CHAPTER 13
Introduction to Derivatives
477
Basic Types of Derivatives; Important Concepts for
Derivative Pricing and Use; Pricing Forwards and
Futures; Pricing Options; Pricing Swaps; Summary;
Software Hints; Notes
CHAPTER 14
Pricing Derivatives by Simulation
531
Computing Option Prices with Crude Monte Carlo
Simulation; Variance Reduction Techniques;

x
CONTENTS
Quasirandom Number Sequences; More Simulation
Application Examples; Summary; Software Hints; Notes
CHAPTER 15
Structuring and Pricing Residential Mortgage-Backed Securities
587
Types of Asset-Backed Securities; Mortgage-Backed
Securities: Important Terminology; Types of RMBS
Structures; Pricing RMBS by Simulation; Using
Simulation to Estimate Sensitivity of RMBS Prices to
Different Factors; Structuring RMBS Deals Using
Dynamic Programming; Summary; Notes
CHAPTER 16
Using Derivatives in Portfolio Management
627
Using Derivatives in Equity Portfolio Management;
Using Derivatives in Bond Portfolio Management;
Using Futures to Implement an Asset Allocation
Decision; Measuring Portfolio Risk When the Portfolio
Contains Derivatives; Summary; Notes
PART FIVE
Capital Budgeting Decisions
CHAPTER 17
Capital Budgeting under Uncertainty
653
Classifying Investment Projects; Investment Decisions
and Wealth Maximization; Evaluating Project Risk;
Case Study; Managing Portfolios of Projects; Summary;
Software Hints; Notes
CHAPTER 18
Real Options
707
Types of Real Options; Real Options and Financial
Options; New View of NPV; Option to Expand;
Option to Abandon; More Real Options Examples;
Estimation of Inputs for Real Option Valuation
Models; Summary; Software Hints; Notes
References
733
Index
743

Preface
S
imulation and Optimization in Finance: Modeling with MATLAB,
@RISK, or VBA is an introduction to two quantitative modeling tools—
simulation and optimization—and their applications in ﬁnancial risk man-
agement. In addition to laying a solid theoretical foundation and discussing
the practical implications of applying simulation and optimization tech-
niques, the book uses simulation and optimization as a means to clarify
difﬁcult concepts in traditional risk models in ﬁnance, and explains how to
build ﬁnancial models with software. The book covers a wide range of ap-
plications and is written in a theoretically rigorous way, which will make it
of interest to both practitioners and academics. It can be used as a self-study
aid by ﬁnance practitioners and students who have some fundamental back-
ground in calculus and statistics, or as a textbook in ﬁnance and quantitative
methods courses. In addition, this book is accompanied by a web site where
readers can go to download an array of supplementary materials. Please
see the “Companion Web Site” section toward the end of this Preface for
more details.
CENTRAL THEMES
Simulation and Optimization in Finance contains 18 chapters in ﬁve parts.
Part One, Fundamental Concepts, provides background on the most impor-
tant ﬁnance, simulation, optimization, and optimization under uncertainty
concepts that are necessary to understand the ﬁnancial applications in later
parts of the book. Part Two, Portfolio Optimization and Risk Measures,
reviews the theory and practice of equity and ﬁxed income portfolio man-
agement, from classical frameworks, such as mean-variance optimization,
to recent advances in the theory of risk measurement, such as value-at-risk
and conditional value-at-risk estimation. Part Three, Asset Pricing Models,
discusses classical static and dynamic models for asset pricing, such as factor
models and different types of random walks. Part Four, Derivative Pricing
and Use, introduces important types of ﬁnancial derivatives, shows how
their value can be determined by simulation, reviews advanced simulation
xi

xii
PREFACE
methods for efﬁcient implementation of pricing algorithms, and discusses
how derivatives can be employed for portfolio risk management and return
enhancement purposes. Part Five, Capital Budgeting Decisions, reviews cap-
ital budgeting decision models, including real options, and discusses applica-
tions of simulation and optimization in capital budgeting under uncertainty.
It is important to note that there often are multiple numerical methods
that can be used to handle a particular problem in ﬁnance. Many of the
topics listed here, especially asset and derivative pricing models, however,
have traditionally been out of reach for readers without advanced degrees in
mathematics because understanding the theory behind the models and the
advanced methods for modeling requires years of training. Simulation and
optimization formulations provide a framework within which very challeng-
ing concepts can be explained through simple visualization and hands-on
implementation, which makes the material accessible to readers with little
background in advanced mathematics.
SOFTWARE
In our experience, teaching and learning cannot be effective without exam-
ples and hands-on implementation. Most of the chapters in this book have
“Software Hints” sections that explain how to use the applications under
discussion. The examples themselves are posted on the companion web site
discussed later in the Preface.
In Simulation and Optimization in Finance, we assume basic familiar-
ity with spreadsheets and Microsoft Excel, and use two different platforms
to implement concepts and algorithms: the Palisade Decision Tools Suite
and other Excel-based software (@RISK1, Solver2, VBA3), and MATLAB4.
Readers do not need to learn both; they can choose one or the other, depend-
ing on their level of familiarity and comfort with spreadsheet programs and
their add-ins versus programming environments such as MATLAB. Speciﬁ-
cally, users with ﬁnance and social science backgrounds typically prefer an
Excel-based implementation, whereas users with engineering and quanti-
tative backgrounds prefer MATLAB. Some tasks and implementations are
easier in one environment than in the other, and students who have used this
book in the form of lecture notes in the past have felt they beneﬁtted from
learning about both platforms. Basic introductions to the software used in
the book are provided in Appendices B through D, which can be accessed at
the companion web site.
Although Excel and other programs are used extensively in this book,
we were wary of turning it into a software tutorial. Our goal was to com-
bine concepts and tools for implementing them in an effective manner

Preface
xiii
without necessarily covering every aspect of working in a speciﬁc software
environment.
We have, of course, attempted to implement all examples correctly.
That said, the code is provided “as is” and is intended only to illustrate
the concepts in this book. Readers who use the code for ﬁnancial decision
making are doing so at their own risk. For full information on the terms
of use of the code, please see the licensing information in each ﬁle on the
companion web site.
The following web sites provide useful information about Palisade De-
cision Tools Suite and MATLAB. Readers can download trial versions or
purchase the software.
■Palisade Decision Tools Suite, http://www.palisade.com
■MATLAB, http://www.mathworks.com
TEACHING
Simulation and Optimization in Finance: Modeling with MATLAB, @RISK,
or VBA covers ﬁnance and applied quantitative methods theory, as well as
a wide range of applications. It can be used as a textbook for upper-level
undergraduate or lower-level graduate (such as MBA or Master’s) courses
in applied quantitative methods, operations research, decision sciences, or
ﬁnancial engineering, ﬁnance courses in derivatives, investments or corpo-
rate ﬁnance with an emphasis on modeling, or as a supplement in a special
topics course in quantitative methods or ﬁnance. In addition, the book can
be used as a self-study aid by students, or serve as a reference for student
projects.
The book assumes that the reader has no background in ﬁnance or ad-
vanced quantitative methods except for basic calculus and statistics. Most
quantitative concepts necessary for understanding the notation or applica-
tions are introduced and explained in endnotes, software hints, and online
appendices. This makes the book suitable for readers with a wide range of
backgrounds and particularly so as a textbook for classes with mixed audi-
ences (such as engineering and business students). In fact, the idea for this
book project matured after years of searching for an appropriate text for a
course with a mixed audience that needed a good reference for both ﬁnance
and quantitative methods topics.
Every chapter follows the same basic outline. The concepts are intro-
duced in the main body of the chapter, and illustrations are provided. At
the end of each chapter, there is a summary that contains the most impor-
tant discussion points. A Software Hints section provides instructions and

xiv
PREFACE
code for implementing the examples in the chapter with both Excel-based
software and MATLAB.
On the companion web site, there are practice sections for selected
chapters. These sections feature examples that complement those found
in their respective chapters. Some practice sections contain cases as well.
The cases are more in-depth exercises that focus on a particular practical
application not necessarily covered in the chapter, but possible to address
with the tools introduced in that chapter.
We recommend that before proceeding with the main body of this book,
readers consult the four appendices on the companion web site, namely
Appendix A, Basic Linear Algebra Concepts; Appendix B, Introduction to
@RISK; Appendix C, Introduction to MATLAB; and Appendix D, Intro-
duction to Visual Basic for Applications. They provide background on basic
mathematical and programming concepts that enable readers to understand
the implementation and the code provided in the Software Hints sections.
The chapters that introduce fundamental concepts all contain code that
can be found on the companion web site. Some more advanced chapters do
not; the idea is that at that point students are sufﬁciently familiar with the
applications and models to put together examples on their own based on the
code provided in previous chapters. The material in the advanced chapters
can be used also as templates for student course projects.
A typical course may start with the material in Chapters 2 through 6.
It can then cover the material in Chapters 7 through 9, which focus on
applications of optimization for single-period optimal portfolio allocation
and risk management. The course then proceeds with Chapters 11 through
14, which introduce static and dynamic asset pricing models through sim-
ulation as well as derivative pricing by simulation, and ends with Chapters
17 and 18, which discuss applications of simulation and optimization in
capital budgeting. Chapters 10, 15, and 16 represent good assignments for
ﬁnal projects because they use concepts similar to other chapters, but in a
different context and without as much implementation detail.
Depending on the nature of the course, only some of Chapters 2 through
6 will need to be covered explicitly; but the information in these chapters is
useful in case the instructor would like to assign the chapters as reading for
students who lack some of the necessary background for the course.
COMPANION WEB SITE
Additional material for Simulation and Optimization in Finance can be
downloaded by visiting www.wiley.com/go/pachamanova. Please log in to
the web site using this password: ﬁnance123. The ﬁles on this companion

Preface
xv
web site are organized in the following folders: Appendices, Code, and
Practice. The Appendices directory contains Appendix A through D. The
Practice directory contains practice problems and cases indexed by chapter.
(Practice problems are present for Chapters 4–16, 18, and Appendix D, as a
bonus to the content in the book. Please note, however, that only problems
are offered without solutions.) The Code directory has Excel and MATLAB
subdirectories that contain ﬁles for use with the corresponding software.
The latter ﬁles are referenced in the main body of the book and the Software
Hints sections for selected chapters.
The companion web site is a great resource for readers interested in
actually implementing the concepts in the book. Such readers should begin
by reading the applicable appendix on the companion web site with infor-
mation about the software they intend to use, then read the main body of a
chapter, the chapter’s Software Hints, and, ﬁnally, the Excel model ﬁles or
MATLAB code in the code directory on the companion web site.
NOTES
1. An Excel add-in for simulation.
2. An Excel add-in for optimization that comes standard with Excel.
3. Visual Basic for Applications—a programming language that can be
used to automate tasks in Excel.
4. A programming environment for mathematical and engineering appli-
cations that provides users with tools for number array manipulation,
statistical estimation, simulation, optimization, and others.

About the Authors
Dessislava A. Pachamanova is an Associate Professor of Operations Re-
search at Babson College where she holds the Zwerling Term Chair. Her
research interests lie in the areas of portfolio risk management, simulation,
high-performance optimization, and ﬁnancial engineering. She has published
a number of articles in operations research, ﬁnance, and engineering jour-
nals, and coauthored the Wiley title Robust Portfolio Optimization and
Management (2007). Dessislava’s academic research is supplemented by
consulting and previous work in the ﬁnancial industry, including projects
with quantitative strategy groups at WestLB and Goldman Sachs. She holds
an AB in mathematics from Princeton University and a PhD in operations
research from the Sloan School of Management at MIT.
Frank J. Fabozzi is Professor in the Practice of Finance in the School of
Management at Yale University. Prior to joining the Yale faculty, he was
a Visiting Professor of Finance in the Sloan School at MIT. Frank is a Fel-
low of the International Center for Finance at Yale University and on the
Advisory Council for the Department of Operations Research and Financial
Engineering at Princeton University. He is the editor of the Journal of Port-
folio Management and an associate editor of the Journal of Fixed Income.
He earned a doctorate in economics from the City University of New York
in 1972. In 2002 was inducted into the Fixed Income Analysts Society’s Hall
of Fame and is the 2007 recipient of the C. Stewart Sheppard Award given
by the CFA Institute. He earned the designation of Chartered Financial Ana-
lyst and Certiﬁed Public Accountant. He has authored and edited numerous
books in ﬁnance.
xvi

Acknowledgments
I
n writing a book that covers such a wide range of topics in simulation,
optimization, and ﬁnance, we were fortunate to have received valuable
help from a number of individuals. The following people have commented
on chapters or sections of chapters or provided helpful references and intro-
ductions:
■Anthony Corr, Brett McElwee, and Max Capetta of Continuum Capital
Management
■Nalan Gulpinar of the University of Warwick Business School
■Craig Stephenson of Babson College
■Hugh Crowther of Crowther Investment, LLC
■Bruce Collins of Western Connecticut State University
■Pamela Drake of James Madison University
Zack Coburn implemented the VBA code for the Software Hints sec-
tions in Chapters 7 and 14. Christian Hicks helped with writing and testing
some of the VBA code in the book, such as the VBA implementation of the
American option pricing model with least squares in Chapter 14. Professor
Mark Potter of Babson College allowed us to modify his case, “Reebok
International: Strategic Asset Allocation,” for use as an example in Chapter
17, and some of the ideas are based on case spreadsheet models further de-
veloped by Kathy Hevert and Richard Bliss of Babson College. Some of the
cases and examples in the book are based on ideas and research by Thomas
Malloy, Michael Allietta, Adam Bergenﬁeld, Nick Kyprianou, Jason Aron-
son, and Rohan Duggal. The real estate valuation project example in section
18.6.3 in Chapter 18 is based on ideas by Matt Bujnicki, Matt Enright, and
Alec Kyprianou.
We would also like to thank Wendy Gudgeon and Stan Brown from
Palisade Software and Steve Wilcockson, Naomi Fernandes, Meg Vulliez,
Chris Watson, and Srikanth Krishnamurthy of Mathworks for their help
with obtaining most recent versions of the software used in the book and
for additional materials useful for implementing some of the examples.
DESSISLAVA A. PACHAMANOVA
FRANK J. FABOZZI
xvii


CHAPTER1
Introduction
F
inance is the application of economic principles to decision making, and
involves the allocation of money under conditions of uncertainty. In-
vestors allocate their funds among ﬁnancial assets in order to accomplish
their objectives. Business entities and government at all levels raise funds by
issuing claims in the form of debt (e.g., loans and bonds) or equity (e.g.,
common stock) and, in turn, invest those funds. Finance provides the frame-
work for making decisions as to how those funds should be obtained and
then invested.
The ﬁeld of ﬁnance has three specialty areas: (1) capital markets and
capital market theory, (2) ﬁnancial management, and (3) portfolio man-
agement. The specialty ﬁeld of capital markets and capital market theory
focuses on the study of the ﬁnancial system, the structure of interest rates,
and the pricing of risky assets. Financial management, sometimes called
business ﬁnance, is the specialty area of ﬁnance concerned with ﬁnancial de-
cision making within a business entity. Although we often refer to ﬁnancial
management as corporate ﬁnance, the principles of ﬁnancial management
also apply to other forms of business and to government entities. Moreover,
not all nongovernment business enterprises are corporations. Financial man-
agers are primarily concerned with investment decisions and ﬁnancing deci-
sions within business. Making investment decisions that involve long-term
capital expenditures is called capital budgeting. Portfolio management deals
with the management of individual or institutional funds. This specialty
area of ﬁnance—also commonly referred to as investment management, as-
set management, and money management—involves selecting an investment
strategy and then selecting the speciﬁc assets to be included in a portfolio.
A critical element common to all three specialty areas in ﬁnance is the
concept of risk. Measuring and quantifying risk is critical for the fair val-
uation of an asset, the selection of capital budgeting projects in ﬁnancial
management, the selection of individual asset holdings, and portfolio con-
struction in portfolio management. The ﬁeld of risk management includes
1

2
INTRODUCTION
the identiﬁcation, measurement, and control of risk in a business entity or
a portfolio.
Sophisticated mathematical tools have been employed in order to deal
with the risks associated with individual assets, capital budgeting projects,
and selecting assets in portfolio construction. The use of such tools is now
commonplace in the ﬁnancial industry. For example, in portfolio man-
agement, practitioners run statistical routines to identify risk factors that
drive asset returns, scenario analyses to evaluate the risk of their posi-
tions, and algorithms to ﬁnd the optimal way to allocate assets or execute
a trade.
This book focuses on two quantitative tools—optimization and simula-
tion—and discusses their applications in ﬁnance. In this chapter, we brieﬂy
introduce these two techniques, and provide an overview of the structure of
the book.
OPTIMIZATION
Optimization is an area in applied mathematics that, most generally, deals
with efﬁcient algorithms for ﬁnding an optimal solution among a set of
solutions that satisfy given constraints. The ﬁrst application of optimization
in ﬁnance was suggested by Harry Markowitz in 1952, in a seminal paper
that outlined his mean-variance optimization framework for optimal asset
allocation. Some other classical problems in ﬁnance that can be solved by
optimization algorithms include:
■Is there a possibility to make riskless proﬁt given market prices of related
securities? (This opportunity is called an arbitrage opportunity and is
discussed in Chapter 13.)
■How should trades be executed so as to reach a target allocation with
minimum transaction costs?
■Given a limited capital budget, which capital budgeting projects should
be selected?
■Given estimates for the costs and beneﬁts of a multistage capital budget-
ing project, at what stage should the project be expanded/abandoned?
Traditional optimization modeling assumes that the inputs to the algo-
rithms are certain, but there is also a branch of optimization that studies the
optimal decision under uncertainty about the parameters of the problem.
Fast and reliable algorithms exist for many classes of optimization prob-
lems, and advances in computing power have made optimization techniques
a viable and useful part of the standard toolset of the ﬁnancial modeler.

Introduction
3
SIMULATION
Simulation is a technique for replicating uncertain processes, and evaluating
decisions under uncertain conditions. Perhaps the earliest application of
simulation in ﬁnance was in ﬁnancial management. Hertz (1964) argued that
traditional valuation methods for investments omitted from consideration an
important component: the fact that many of the inputs were inaccurate. He
suggested modeling the uncertainty through probability-weighted scenarios,
which would allow for obtaining a range of outcomes for the value of the
investments and associated probabilities for each outcome. These ideas were
forgotten for a while, but have experienced tremendous growth in the last
two decades. Simulation is now used not only in ﬁnancial management,
but also in risk management and pricing of different ﬁnancial instruments.
In portfolio management, for example, the correlated behavior of different
factors over time is simulated in order to estimate measures of portfolio
risk. In pricing ﬁnancial options or complex securities, such as mortgage-
backed securities, paths for the underlying risk factors are simulated; and
the fair price of the securities is estimated as the average of the discounted
payoffs over those paths. We will see numerous examples of such simulation
applications in this book.
Simulation bears some resemblance to an intuitive tool for modifying
original assumptions in ﬁnancial models—what-if analysis—which has been
used for a long time in ﬁnancial applications. In what-if analysis, each un-
certain input in a model is assigned a range of possible values—typically,
best, worst, and most likely value—and the modeler analyzes what happens
to the decision under these scenarios. The important additional component
in simulation modeling, however, is that there are probabilities associated
with the different outcomes. This allows for obtaining an additional piece of
information compared to what-if analysis: the probabilities that speciﬁc ﬁnal
outcomes will happen. Probability theory is so fundamental to understand-
ing the nature of simulation analysis, that we include a chapter (Chapter 3)
on the most important aspects of probability theory that are relevant for
simulation modeling.
OUTLINE OF TOPICS
The book is organized as follows. Part One (Chapters 2 through 6) pro-
vides a background on the fundamental concepts used in the rest of the
book. Part Two (Chapters 7 through 10) introduces the classical under-
pinnings of modern portfolio theory, and discusses the role of simulation
and optimization in recent developments. Part Three (Chapters 11 and 12)

4
INTRODUCTION
summarizes important models for asset pricing and asset price dynamics.
Understanding how to implement these models is a prerequisite for the ma-
terial in Part Four (Chapters 13 through 16), which deals with the pricing of
ﬁnancial derivatives, mortgage-backed securities, advanced portfolio man-
agement, and advanced simulation methods. Part Five (Chapters 17 and 18)
discusses applications of simulation and optimization in capital budgeting
and real option valuation. The four appendices (on the companion web site)
feature introductions to linear algebra concepts, @RISK, MATLAB, and
Visual Basic for Applications in Microsoft Excel.
We begin by listing important ﬁnance terminology in Chapter 2. This
includes basic theory of interest; terminology associated with equities, ﬁxed
income securities, and trading; calculation of rate of return; and useful
concepts in ﬁxed income, such as spot rates, forward rates, yield, duration,
and convexity.
Chapter 3 is an introduction to probability theory, distributions, and
basic statistics. We review important probability distributions, such as the
normal distribution and the binomial distribution, measures of central ten-
dency and variability, and measures of strength of codependence between
random variables. Understanding these concepts is paramount to under-
standing the simulation models discussed in the book.
Chapter 4 introduces simulation as a methodology. We discuss deter-
mining inputs for and interpreting output from simulation models, and
explain the methodology behind generating random numbers from differ-
ent probability distributions. We also touch upon recent developments in
efﬁcient random number generation, which provides the foundation for the
advanced simulation methods for ﬁnancial derivative pricing discussed in
Part Four of the book.
In Chapter 5 we provide a practical introduction to optimization. We
discuss the most commonly encountered types of optimization problems in
ﬁnance, and elaborate on the concept of “difﬁcult” versus “easy” optimiza-
tion problems. We introduce optimization duality and describe intuitively
how optimization algorithms work. Illustrations of simple ﬁnance problems
that can be handled with optimization techniques are provided, including
examples of optimal portfolio allocation and cash ﬂow matching from the
ﬁeld of portfolio management, and capital budgeting from the ﬁeld of ﬁ-
nancial management. We also discuss dynamic programming—a technique
for solving optimization problems over multiple stages. Multistage opti-
mization is used in Chapters 13 and 18. Finally, we review available soft-
ware for different types of optimization problems and portfolio optimization
in particular.
Classical optimization methods treat the parameters in optimization
problems as deterministic and accurate. In reality, however, these param-
eters are typically estimated through error-prone statistical procedures or

Introduction
5
based on subjective evaluation, resulting in estimates with signiﬁcant estima-
tion errors. The output of optimization routines based on poorly estimated
inputs can be at best useless and at worst seriously misleading. It is impor-
tant to know how to treat uncertainty in the estimates of input parameters
in optimization problems. Chapter 6 provides a taxonomy of methods for
optimization under uncertainty. We review the main ideas behind dynamic
programming under uncertainty, stochastic programming, and robust opti-
mization, and illustrate the methods with examples. We will encounter these
methods in applications in Chapters 9, 13, 14, and 18.
Chapter 7 uses the concept of optimization to introduce the mean-
variance framework that is the foundation of modern portfolio theory.
We also present an alternative framework for optimal decision making in
investments—expected utility maximization—and explain its relationship to
mean-variance optimization.
Chapter 8 extends the classical mean-variance portfolio optimization
theory to a more general mean-risk setting. We cover the most commonly
used alternative risk measures that are generally better suited than vari-
ance for describing investor preferences when asset return distributions are
skewed or fat-tailed. We focus on two popular portfolio risk measures—
value-at-risk and conditional value-at-risk—and show how to estimate them
using simulation. We also formulate the problems of optimal asset allocation
under these risk measures using optimization.
Chapter 9 provides an overview of practical considerations in imple-
menting portfolio optimization. We review constraints that are most com-
monly faced by portfolio managers, and show how to formulate them as part
of optimization problems. We also show how the classical framework for
portfolio allocation can be extended to include transaction costs, and discuss
index tracking, optimization of trades across multiple client accounts, and
robust portfolio optimization techniques to minimize estimation error.
While Chapter 9 focuses mostly on equity portfolio management,
Chapter 10 discusses the speciﬁcities of ﬁxed income (bond) portfolio man-
agement. Many of the same concepts are used in equity and ﬁxed income
portfolio management (which are deﬁned in Chapter 2); however, ﬁxed in-
come securities have some fundamental differences from equities, so the
concepts cannot always be applied in the same way in which they would be
applied for stock portfolios. We review classical measures of bond portfolio
risk, such as duration, key rate duration, and spread duration. We discuss
bond portfolio optimization relative to a benchmark index. We also give
examples of how optimization can be used in liability-driven bond portfolio
strategies such as immunization and cash ﬂow matching.
Chapter 11 transitions from the topic of portfolio management to the
topic of asset pricing, and introduces standard ﬁnancial models for explain-
ing asset returns—the Capital Asset Pricing Model (CAPM), which is based

6
INTRODUCTION
on the mean-variance framework described in Chapter 7, the Arbitrage
Pricing Theory (APT), and factor models. Such models are widely used in
portfolio management—they not only help to model the processes that drive
asset prices, but also substantially reduce the computational burden for sta-
tistical estimation and asset allocation optimization algorithms.
Chapter 12 focuses on dynamic asset pricing models, which are based
on random processes. We examine the most commonly used types of ran-
dom walks, and illustrate their behavior through simulation. The models
discussed include arithmetic, geometric, different types of mean-reverting
random walks, and more advanced hybrid models. In our presentation in
the chapter, we assume that changes in asset prices happen at discrete time
intervals. At the end of the chapter, we extend the concept of a random walk
to a random process in continuous time.
The concepts introduced in Chapter 12 are reused multiple times when
we discuss valuation of complex securities and multistage investments in
Parts Four and Five of the book. The ﬁrst chapter in Part Four, Chapter 13,
is an introduction to the topic of ﬁnancial derivatives. It lists the main classes
of ﬁnancial derivative contracts (futures and forwards, options, and swaps),
explains the important concepts of arbitrage and hedging, and reviews clas-
sical methods for pricing derivatives, such as the Black-Scholes formula and
binomial trees.
Chapter 14 builds on the material in Chapter 13, but focuses mainly on
the use of simulation for pricing complex securities. Some of the closed-form
formulas provided in Chapter 12 and the assumptions behind them become
more intuitive when illustrated through simulation of the random processes
followed by the underlying securities. A large part of the chapter is dedicated
to variance reduction techniques, such as antithetic variables, stratiﬁed sam-
pling, importance sampling, and control variates, as well as quasi–Monte
Carlo methods. Such techniques are widely used today for efﬁcient imple-
mentation of simulations for pricing securities and estimating sensitivity to
different market factors. We provide speciﬁc examples of these techniques,
and detailed VBA and MATLAB code to illustrate their implementation.
The numerical pricing methods in Chapter 15 are based on similar
techniques to the ones discussed in Chapter 14, but the context is different.
We introduce a complex type of ﬁxed-income securities—mortgage-backed
securities—and discuss in detail a part of the simulation that is speciﬁc to
ﬁxed-income securities—generating scenarios for future interest rates and
the entire yield curve.
Chapter 16 builds on Chapters 7, 8, 9, 13, and 14, and contains a
discussion of how derivatives can be used for portfolio risk management
and return enhancement strategies. Simulation is essential for estimating
the risk of a portfolio that contains complex ﬁnancial instruments, but the

Introduction
7
process can be very slow in the case of large portfolios. We highlight some
numerical issues, standard simulation algorithms, and review methods that
have been suggested for reducing the computational burden.
Chapters 17 and 18 cover a different area of ﬁnance—ﬁnancial manage-
ment—but they provide useful illustrations for the difference applying
simulation and optimization makes in classical ﬁnance decision-making
frameworks. Chapter 17 begins with a review of so-called discounted cash
ﬂow (DCF) methodologies for evaluating company investment projects. It
then discusses (through a case study) how simulation can be used to estimate
stand-alone risk and enhance the analysis of such projects.
Chapter 18 introduces the real options framework, which advocates
for accounting for existing options in project valuation. (The DCF analysis
ignores the potential ﬂexibility in projects—it assumes that there will be no
changes once a decision is made.) While determining the inputs for valu-
ation of real options presents signiﬁcant challenges, the actual techniques
for pricing these real options are based on the techniques for pricing ﬁnan-
cial options introduced in Chapters 13 and 14. Simulation and multistage
optimization can again be used as valuable tools in this new context.


PART
One
Fundamental Concepts


CHAPTER2
Important Finance Concepts
T
his chapter reviews important ﬁnance concepts that are used throughout
the book. We discuss the concepts of the time value of money, different
asset classes, basic trading terminology, calculation of rate of return, valu-
ation, and advanced concepts in ﬁxed income, such as duration, convexity,
key rate duration, and total return.
2.1
BASIC THEORY OF INTEREST
One of the most fundamental concepts in ﬁnance is the concept of the time
value of money. A speciﬁc amount of money received today does not have
the same nominal value in the future because of the possibility of investing
the money today and earning interest. This section explains the rules for
computing interest, and outlines the basic elements of dealing with cash ﬂows
obtained today and in the future. These concepts will reappear many times
throughout the book—they are critical for pricing ﬁnancial instruments and
making investment decisions.
2.1.1
Compound Interest
Most bank accounts, loans, and investments interest calculations utilize
some form of compounding. Simply put, compound interest involves interest
on interest. Let us explain the concept with an example. If you deposit $100
in a bank deposit that pays 3% per year, at the end of the year you will have
$103. Suppose you keep the money in the bank for a second year, again at
3% interest. Compound interest means that the interest during the second
year will be accrued on the entire amount you have in the bank at the end
of the ﬁrst year—not only on your original deposit of $100, but also on the
interest accrued during the ﬁrst year. Therefore, at the end of the second
year you will have
$103 + 0.03 · $103 = $106.09
11

12
FUNDAMENTAL CONCEPTS
If there was no compounding, you would have an additional $3 at the
end of the ﬁrst year, and again at the end of the second year, that is, the total
amount in your account at the end of the second year would be $106.00. In
general, the formula for computing the future value of an initial capital C
invested for n years at interest rate r per year (compounded annually) is
C · (1 + r)n
In our example, computing the interest with and without compounding
made a difference of 9 cents. The effect of compounding on the investment,
however, can be substantial, especially over a long time horizon. For ex-
ample, you can verify that if you invest $C at an interest rate of 7% per
year with annual compounding, your investment will double in size in ap-
proximately 10 years. This increase is signiﬁcantly larger than if interest
is not compounded, that is, if you simply add the interest on the original
investment over the 10 years. (The latter would be 10 · 0.07 = 0.70, or 70%
increase in the original investment.)
Interest does not necessarily need to be compounded once per year—it
can be compounded daily, monthly, quarterly, continuously. Usually, how-
ever, the interest rate r is still quoted as an annual rate. For example, with
quarterly compounding, an interest of r/4 is accrued each quarter on the
amount at the beginning of the quarter. At the end of the ﬁrst quarter, the
original amount C grows to C · (1 + r/4). At the end of the second quarter,
the amount becomes (C · (1 + r/4)·(1 + r/4)). At the end of the ﬁrst year,
the total amount in the account is C · (1 + r/4)4. After n years, $C of initial
capital grows to
C · (1 + r/4)4 · n.
In general, if the frequency of compounding is m times per year at an
annual (called nominal) rate r, the amount at the end of n years will be
C · (1 + r/m)m· n.
The effective annual rate is the actual interest rate that is paid over the
year, that is, the rate reff so that
C · (1 + r/m)m = C · (1 + reff).
So, for example, if there is quarterly compounding and the nominal
annual rate is 3%, the effective interest rate is
reff = (1 + 0.03/4)4 −1 = 0.0303 = 3.03%.

Important Finance Concepts
13
Again, the difference between the nominal and the effective annual rate
does not seem that large (only 0.03%); however, the difference increases
with the frequency of compounding.
Suppose now that we divide the year into very, very small time intervals.
You can think of compounding interest every millisecond. So, the number
m in the expression for computing the compound interest rate becomes so
large, it can be considered inﬁnity. It turns out that when m tends to inﬁnity,
the expression (1 + r/m)m tends to a very speciﬁc number, er, where the
number e has the value 2.7182 . . . (it has inﬁnitely many digits after the
decimal point).1
Therefore, with continuous compounding, $C of initial capital becomes
C · er·1 at the end of the ﬁrst year, C · e r·2 at the end of the second year, and
C · e r·n after n years. If we are interested in the amount of capital after, say
ﬁve months, and we are given the nominal interest rate r as an annual rate,
we ﬁrst convert ﬁve months to years (ﬁve months = 5/12 years), and then
compute the future amount of capital as C · e r·(5/12).
Let us provide a concrete example. If the nominal interest rate is 3% per
year and we invest $100, then with continuous compounding the amount at
the end of the ﬁrst year is 100 · e0.03·1 = $103.05. Therefore, the effective
annual rate is 3.05%—higher than the effective annual rate of 3.03% with
quarterly compounding we computed earlier. After ﬁve months, the amount
in the account will be 100 · e0.03·(5/12) = $101.26.
2.1.2
Present Value and Future Value
In the previous section, we explained the concept of interest. Suppose you
have $100 today, and you put it in a savings account paying 3% interest per
year. At the end of the year, your $100 will become $103. Now suppose that
somebody gives you a choice between receiving $100 today, or $100 one
year from now. The two options would not be equivalent to you. Given the
opportunity to invest the money at 3% interest, you would demand $103
one year from now to make you indifferent between the two options. In
this example, the $103 received at the end of the year can be considered the
future value of $100 received today, whereas $100 is the present value of
$103 received one year from now. This is the important concept of the time
value of money—money to be received in the future is less valuable than the
same nominal amount of money received immediately.
Formally, the present value (sometimes also called the discounted value)
of a single cash ﬂow CF is the amount of money that must be invested today
to generate the future cash ﬂow. The present value of a cash ﬂow depends
on (1) the length of time until the cash ﬂow will be received, and (2) the
interest rate, which is called the discount rate in this context.

14
FUNDAMENTAL CONCEPTS
The present value (PV) of a cash ﬂow CF received n years from now
when the interest rate r is compounded annually is computed as
PV(CF) =
CF
(1 + r)n .
The expression
1
(1 + r)n
is called the discount factor. The discount factor (let us call it dn) is the
number by which we need to multiply the future cash ﬂow to obtain its
present value. Note that the discount factor is a number less than 1—the
present value of the cash ﬂow is less than the future value in nominal terms
because it is assumed that the interest accrued between the present and the
future date will be a nonnegative amount.
The conversion between present and future value follow the interest
calculation rules we introduced in the previous section. For example, if the
annual interest rate r is continuously compounded, the present value of a
cash ﬂow CF received n years from now is
PV(CF) = CF
er · n = CF · e−r · n.
In this case, the discount factor is dn = e−r · n.
It is easy to see how the concepts of present and future value extend
when the “present” is not today’s date. For example, suppose that we
have invested $100 today for three years in an account paying an annual
rate of 3% compounded continuously. At the end of year 1, we will have
$100 · e0.03·1 = $103.05 in the account. At the end of year 2, we will have
$100 · e0.03·2 = $106.18 in the account. The amounts $103.05 and $106.18
are the future values of $100 on hand today, in year 1 and year 2 dollars.
The present values of $103.05 received at the end of year 1 and $106.18
received at the end of year 2 are both $100 ($103.05 · e−0.03·1 and $106.18 ·
e−0.03·2, respectively). Note that we can compute the present value of $106.18
received at the end of year 2 in two ways. The ﬁrst is to discount directly
to the present, $106.18 · e−0.03·2. The second is to discount $106.18 ﬁrst to
its present value in year 1 dollars ($106.18 · e−0.03·1 = $103.05), and then
discount the year 1 dollars to today dollars ($103.05 · e−0.03·1 = $100.00).
The latter technique will be useful when pricing ﬁnancial derivatives and
real options are discussed in Chapters 13 through 16 and Chapter 18.

Important Finance Concepts
15
2.2
ASSET CLASSES
An asset is any possession that has value in an exchange. Assets can be clas-
siﬁed as tangible or intangible. A tangible asset’s value depends on particular
physical properties of the asset. Buildings, land, and machinery are exam-
ples of tangible assets. Intangible assets, by contrast, represent legal claims
to some future beneﬁt and their value bears no relation to the form, physical
or otherwise, in which the claims are recorded. Financial assets, ﬁnancial
instruments, or securities are intangible assets. For these instruments, the
typical future beneﬁt comes in the form of a claim to future cash.
In most developed countries, the four major asset classes are (1) common
stocks, (2) bonds, (3) cash equivalents, and (4) real estate. An asset class is
deﬁned in terms of the investment attributes that the members of an asset
class have in common. These investment characteristics include (1) the major
economic factors that inﬂuence the value of the asset class and, as a result,
correlate highly with the returns of each member included in the asset class;
(2) have a similar risk and return characteristic; and (3) have a common
legal or regulatory structure. Based on this way of deﬁning an asset class,
the correlation between the returns of different asset classes would be low.
The preceding four major asset classes can be extended to create other
asset classes. From the perspective of a U.S. investor, for example, the four
major asset classes listed earlier have been expanded as follows by separating
foreign securities from U.S. securities: (1) U.S. common stocks, (2) non–U.S.
(or foreign) common stocks, (3) U.S. bonds, (4) non-U.S. bonds, (5) cash
equivalents, and (6) real estate.
Common stocks and bonds are further partitioned into more asset
classes. For example, U.S. common stocks (also referred to as U.S. equities),
are differentiated based on market capitalization. Market capitalization (or
market cap) is computed as the number of shares outstanding times the
market price per share. The term is often used as a proxy for the size of a
company. Companies are usually classiﬁed as large cap, medium cap (mid-
cap), small cap, or micro cap, depending on their market capitalization. The
division is somewhat arbitrary, but generally, micro-cap companies have a
market capitalization of less than $250 million, small-cap companies have
a market capitalization between $250 million and $1 billion, mid-cap com-
panies have market capitalization between $1 billion and $5 billion, and
large-cap companies have market capitalization of more than $5 billion.
Companies that have market capitalization of more than $250 billion are
sometimes referred to as mega-caps.
With the exception of real estate, all of the asset classes we have pre-
viously identiﬁed are referred to as traditional asset classes. Real estate and

16
FUNDAMENTAL CONCEPTS
all other asset classes that are not in the preceding list are referred to as
nontraditional asset classes or alternative asset classes. They include hedge
funds, private equity, and commodities.
Along with the designation of asset classes comes a barometer to be
able to quantify the performance of the asset class—the risk, return, and
the correlation of the return of the asset class with that of another asset
class. The barometer is called a benchmark index, market index, or simply
index. An example would be the Standard & Poor’s 500. We describe more
indexes in later chapters. The indexes are also used by investors to evaluate
the performance of professional managers whom they hire to manage their
assets.
2.2.1
Equities
Most generally, equity means ownership in a corporation in the form of
common stock. Common stock is securities that entitle the holder to a share
of a company’s success through dividends and/or capital appreciation, and
provide voting rights in a company. The terms “equities” and “stocks” are
often used interchangeably.
A dividend is a payment (usually, quarterly) disbursed by a company to
its shareholders out of the company’s current or retained earnings. Dividends
can be given as cash (cash dividends), additional stock (stock dividends), or
other property. Dividends are usually paid out by companies that have
reached their growth potential, so they cannot beneﬁt by reinvesting their
earnings into further expansion.
Capital appreciation refers to the growth in a stock price. Because of
capital appreciation, investors can make money by investing in a company
that is still in its growth phase, even if the company does not pay dividends.
2.2.2
Fixed Income Securities
In its simplest form, a ﬁxed income security is a ﬁnancial obligation of an
entity that promises to pay a speciﬁed sum of money at speciﬁed future
dates. The entity that promises to make the payment is called the issuer of
the security. Some examples of issuers are central governments such as the
U.S. government and the French government, government-related agencies
of a central government such as Fannie Mae and Freddie Mac in the United
States, a municipal government such as the state of New York in the United
States and the city of Rio de Janeiro in Brazil, a corporation such as Coca-
Cola in the United States and Yorkshire Water in the United Kingdom, and
supranational governments such as the World Bank.

Important Finance Concepts
17
Fixed income securities fall into two general categories: debt obligations
and preferred stock. In the case of a debt obligation, the issuer is called the
borrower. The investor who purchases such a ﬁxed income security is said to
be the lender or creditor. Debt obligations are virtually loans with interest,
where the interest is paid over time in the form of coupons. The promised
payments that the issuer agrees to make at the speciﬁed dates consist of
two components: interest and principal payments. (The principal represents
repayment of the funds borrowed at the end, that is, at the maturity date
for the debt obligation.) Fixed income securities that are debt obligations
include bonds, asset-backed securities (ABSs), and bank loans. Bonds are
basically loans taken out by corporations, government entities, or munici-
palities. Bank loans are loans by banks to companies or individuals. ABSs
are securities backed by pools of loans—mortgages or assets (e.g., cars). The
assets in ABS pools are typically too small or illiquid to be sold individually.
Pooling the assets allows them to be sold in pieces to investors, a process
known as securitization. The largest number of ABSs by far are backed
by pools of mortgages, and are referred to as mortgage-backed securities
(MBSs). We will discuss MBSs, ABSs, and securitization in more detail in
Chapter 15.
In contrast to a ﬁxed income security that represents a debt obligation,
preferred stock represents an ownership interest in a corporation. Dividend
payments are made to the preferred stockholder and represent a distribu-
tion of the corporation’s proﬁt. Unlike investors who own a corporation’s
common stock, investors who own the preferred stock can only realize a
contractually ﬁxed dividend payment. Moreover, the payments that must
be made to preferred stockholders have priority over the payments that a
corporation pays to common stockholders. In the case of the bankruptcy
of a corporation, preferred stockholders are given preference over common
stockholders. Consequently, preferred stock is a form of equity that has
characteristics similar to bonds.
Prior to the 1980s, ﬁxed income securities were simple investment prod-
ucts. Holding aside default by the issuer, the investor knew how long in-
terest would be received and when the amount borrowed would be repaid.
Moreover, most investors purchased these securities with the intent of hold-
ing them to their maturity date. Beginning in the 1980s, the ﬁxed income
world changed. First, ﬁxed income securities became more complex. There
are features in many ﬁxed income securities that make it difﬁcult to de-
termine when the amount borrowed will be repaid and for how long in-
terest will be received. For some securities it is difﬁcult to determine the
amount of interest that will be received. Second, the hold-to-maturity in-
vestor was replaced by institutional investors who actively trade ﬁxed income
securities.

18
FUNDAMENTAL CONCEPTS
In this book, we will often use the terms “ﬁxed income securities”
and “bonds” interchangeably. Next, we introduce various features of ﬁxed
income securities, and explain how these features affect the risks associated
with investing in ﬁxed income securities. This introduction is only cursory.
For an in-depth overview of ﬁxed income products, we refer the reader to
Fabozzi (2007).
The term to maturity of a bond is the number of years the debt is out-
standing or the number of years remaining prior to ﬁnal principal payment.
The maturity date of a bond refers to the date that the debt will cease to ex-
ist, at which time the issuer will redeem the bond by paying the outstanding
balance.
The par value of a bond is the amount that the issuer agrees to repay
the bondholder at or by the maturity date. This amount is also referred to
as the principal value, face value, redemption value, and maturity value.
Because bonds can have a different par value, the practice is to quote
the price of a bond as a percentage of its par value. A value of 100 means
“100% of par value.” For example, if a bond has a par value of $1,000 and
the issue is selling for $900, this bond would be said to be selling at 90. If
a bond is quoted at 103 19/32 and has a par value of $1 million, then the
dollar price is (103.59375/100) × $1,000,000 = $1,035,937.50.
A bond may trade above or below its par value. When a bond trades
below its par value, it is said to be trading at a discount. When a bond trades
above its par value, it is said to be trading at a premium.
The coupon rate, which is also called the nominal rate, is the interest
rate the issuer agrees to pay each year. The annual amount of the interest
payment made to bondholders during the term of the bond is called the
coupon. The coupon is calculated by multiplying the coupon rate by the par
value of the bond. In other words,
Coupon = (Coupon rate) · (Par value)
For example, a bond with a 5% coupon rate and a par value of $1,000
will pay annual interest of $50 (=0.05 · $1,000).
In the United States, the usual practice is for the issuer to pay the
coupon in two semiannual installments. Mortgage-backed securities and
asset-backed securities typically pay interest monthly. For bonds issued in
some markets outside the United States, coupon payments are made only
once per year.
Not all bonds make periodic coupon payments. For example, zero-
coupon bonds do not pay out coupons during the life of the bond. The holder
of a zero-coupon bond realizes interest by buying the bond substantially
below its par value (i.e., buying the bond at a discount). Interest is then paid

Important Finance Concepts
19
at the maturity date, where the interest is the difference between the par
value and the price paid for the bond.
In addition, the coupon rate on a bond need not be ﬁxed over the bond’s
life. Floating-rate securities, sometimes also called ﬂoaters or variable-rate
securities, have coupon payments that reset periodically according to some
reference rate. The typical formula (called the coupon formula) on certain
determination dates when the coupon rate is reset is as follows:
Coupon rate = (Reference rate) + (Quoted margin)
The quoted margin is the additional amount that the issuer agrees to pay
above the reference rate. For example, suppose that the reference rate is the
1-month London interbank offer rate (LIBOR).2 Suppose that the quoted
margin is 100 basis points.3 Then the coupon formula is
Coupon rate = (1-month LIBOR) + (100 basis points)
An example of a ﬂoating rate security is an inﬂation-linked (or inﬂation-
indexed) bond. For example, in 1987, the U.S. Department of Treasury
began issuing inﬂation-adjusted securities referred to as Treasury Inﬂation
Protection Securities (TIPS). The reference rate for the coupon formula is
the rate of inﬂation as measured by the Consumer Price Index for All Ur-
ban Consumers (called CPI-U). Corporations and agencies in the United
States also issue inﬂation-linked bonds. For example, in February 1997, J.P.
Morgan & Company issued a 15-year bond that pays the CPI plus 400
basis points.
A ﬂoater may have a restriction on the maximum or minimum coupon
rate that will be paid at any reset date. The maximum (respectively, the
minimum) coupon rate is called a cap (respectively, a ﬂoor).
Typically, the coupon formula for a ﬂoater is such that the coupon rate
increases when the reference rate increases, and decreases when the reference
rate decreases. However, there are issues whose coupon rate moves in the
opposite direction from the change in the reference rate. Such issues are
called inverse ﬂoaters or reverse ﬂoaters. Such securities give and investor
who believes that interest rates will decline the opportunity to obtain a
higher coupon interest rate.4
Accrued Interest
Bond issuers do not disburse coupon interest payments
every day. Instead, payments are made at prespeciﬁed dates. (As we men-
tioned earlier, in the United States, for example, coupon interest is typically
paid every six months.) Thus, if an investor sells a bond between coupon
payments and the buyer holds it until the next coupon payment, then the

20
FUNDAMENTAL CONCEPTS
entire coupon interest earned for the period will be paid to the buyer of the
bond since the buyer will be the holder of record. The seller of the bond
gives up the interest from the time of the last coupon payment to the time
until the bond is sold. The amount of interest over this period that will
be received by the buyer even though it was earned by the seller is called
accrued interest.
In the United States and in many countries, the bond buyer must pay the
bond seller the accrued interest. The amount that the buyer pays the seller
is the agreed upon price for the bond plus accrued interest. This amount is
called the full price. (Some market participants refer to this as the dirty price.)
The agreed upon bond price without accrued interest is simply referred to
as the price. (Some refer to it as the clean price.)
There are exceptions to the rule that the bond buyer must pay the bond
seller accrued interest. The most important exception is when the issuer has
not fulﬁlled their promise to make the periodic interest payments. In this
case, the issuer is said to be in default. In such instances, the bond is sold
without accrued interest and is said to be traded ﬂat.
Provisions for Paying Off Bonds
The most common structure in the United
States and Europe for paying off the principal for both corporate and gov-
ernment bonds is to pay the entire amount in one lump sum payment at the
maturity date. Such bonds are said to have a bullet maturity.
Fixed income securities backed by pools of loans, such as MBSs and
ABSs, often have a schedule of partial principal payments. Such ﬁxed income
securities are said to be amortizing securities. For many loans, the payments
are structured so that when the last loan payment is made, the entire amount
owed is fully paid.
An issue may have a call provision granting the issuer the option to
retire (pay off) all or part of the issue prior to the stated maturity date. Some
issues specify that the issuer must retire a predetermined amount of the issue
periodically.
Conversion Privilege
A convertible bond is an issue that grants the bond-
holder the right to convert the bond for a speciﬁed number of shares of
common stock. Such a feature allows the bondholder to take advantage
of favorable movements in the price of the issuer’s common stock. An ex-
changeable bond allows the bondholder to exchange the issue for a speciﬁed
number of shares of common stock of a corporation different from the issuer
of the bond.
Currency Denomination
The payments that the issuer makes to the bond-
holder can be in any currency. For example, an issue in which payments to

Important Finance Concepts
21
bondholders are in U.S. dollars is called a dollar-denominated issue. How-
ever, nothing prevents the issuer from making payments in different curren-
cies. In fact, there can be issues whose coupon payments are in one currency
and whose principal payment is in another. Issues with this characteristic
are called dual-currency issues.
Embedded Options
Some bonds have embedded options granted to the is-
suers or the bondholders. Options granted to issuers may include, for exam-
ple, the right to call the issue (i.e., to pay the issue in full before the maturity
date). As we mentioned earlier in this section, such bonds are referred to as
callable bonds. Options granted to bondholders may include a conversion
privilege, or a right to put the issue (i.e., demand immediate payment of
the remaining principal). The latter option has value when interest rates rise
above the issue’s coupon rate because the bondholder is better off investing
his money elsewhere. We will discuss ﬁnancial options in more detail in
Chapters 13 through 16.
It is important to note whether a bond has embedded options because
those options change a bond’s characteristics and value. As we will see in
section 2.5, estimating the fair price of a bond requires projecting its cash
ﬂows between now and its maturity. These cash ﬂows and their timing are
inﬂuenced by the existence of options.
Credit Risk
Investing in ﬁxed income securities exposes investors to credit
risk. While investors commonly refer to credit risk as if it is one dimensional,
there are actually three forms of this risk: default risk, credit spread risk,
and downgrade risk.
Default risk is the risk that the issuer will fail to satisfy the terms of the
obligation with respect to the timely payment of interest and repayment of
the amount borrowed. To gauge credit default risk, investors rely on analy-
sis performed by nationally recognized statistical rating organizations (that
is, more popularly known as rating agencies) that perform credit analysis of
bond issues and issuers and express their conclusions in the form of a credit
rating. The three major rating agencies are Moody’s, Standard & Poor’s,
and Fitch, and their bond rating systems are summarized in Exhibit 2.1.
Bond issues that are assigned a rating in the top four categories in the ex-
hibit are referred to as investment-grade bonds. Bond issues that carry a
rating below the top four categories are referred to as noninvestment-grade
bonds, or more popularly as high-yield bonds or junk bonds. Thus, the
bond market can be divided into two sectors: the investment-grade sector
and the noninvestment-grade sector. Distressed debt is a subcategory of
noninvestment-grade bonds. These bonds may be in bankruptcy proceed-
ings, may be in default of coupon payments, or may be in some other form of

22
FUNDAMENTAL CONCEPTS
EXHIBIT 2.1
Bond ratings systems of Moody’s, Standard & Poor’s, and Fitch
credit rating agencies.
Moody’s
S&P
Fitch
Summary Description
Investment Grade—High-Credit Worthiness
Aaa
AAA
AAA
Prime, maximum safety
Aa1
AA+
AA+
Aa2
AA
AA
High-grade, high-credit quality
Aa3
AA–
AA–
A1
A+
A+
A2
A
A
Upper-medium grade
A3
A–
A–
Baa1
BBB+
BBB+
Baa2
BBB
BBB
Lower-medium grade
Baa3
BBB–
BBB–
Speculative—Lower-Credit Worthiness
Ba1
BB+
BB+
Ba2
BB
BB
Low-grade, speculative
Ba3
BB–
BB–
B1
B+
B2
B
B
Highly speculative
B3
B–
Predominantly Speculative, Substantial Risk, or in Default
Caa
CCC+
CCC+
Substantial risk, in poor standing
CCC
CCC
Ca
CC
CC
May be in default, very speculative
C
C
C
Extremely speculative
CI
Income bonds, no interest being paid
DDD
D
DD
Default
D
distress. Historically, U.S. Treasuries are not rated because they are viewed
as default-free.
Credit spread is the premium over the government or risk-free rate
required by the market for taking on a certain assumed credit exposure. The
benchmark is often a U.S. Treasury issue for the given maturity. Typically,
if all other factors are held constant, the higher the credit rating, the smaller

Important Finance Concepts
23
the credit spread to the benchmark rate. Credit spread risk, the second type
of credit risk, is the risk of ﬁnancial loss resulting from changes in the level of
credit spreads used in the marking-to-market of a debt instrument. Changes
in market credit spreads affect the value of the portfolio and can lead to
losses for traders or underperformance relative to a benchmark for portfolio
managers.
As just explained, investors gauge the credit default risk of an issue by
looking at the credit ratings assigned to issues by the rating agencies. Once
a credit rating is assigned to a debt obligation, a rating agency monitors
the credit quality of the issuer and can reassign a different credit rating. An
improvement in the credit quality of an issue or issuer is rewarded with a
better credit rating, referred to as an upgrade; a deterioration in the credit
rating of an issue or issuer is penalized by the assignment of an inferior credit
rating, referred to as a downgrade. The actual or anticipated downgrading
of an issue or issuer increases the credit spread and results in a decline
in the price of the issue or the issuer’s bonds. This type of risk is called
downgrade risk, and is closely related to credit spread risk. A rating agency
may announce in advance that it is reviewing a particular credit rating,
and may go further and state that the review is a precursor to a possible
downgrade or upgrade. This announcement is referred to as putting the issue
under credit watch. The rating agencies periodically publish, in the form of
a table, information about how issues that they have rated have changed
over time. This table is called a rating migration table or rating transition
table. The table is useful for investors to assess potential downgrades and
upgrades.
2.3
BASIC TRADING TERMINOLOGY
In this book, we use basic terminology associated with buying and selling
securities. This section brieﬂy explains some important trading terminology.
2.3.1
Borrowing Funds to Purchase Securities
Often, investors borrow funds to purchase securities. Such investment strate-
gies are known as leveraged strategies. The expectation is that the money
earned by investing in the securities purchased with the borrowed funds
will exceed the borrowing cost. There are several sources of funds avail-
able to an investor when borrowing funds. When securities are purchased
with borrowed funds, the most common practice is to use the securities as
collateral for the loan. In such instances, the transaction is referred to as a

24
FUNDAMENTAL CONCEPTS
collateralized loan. Two collateralized borrowing arrangements are used by
investors: margin buying and repurchase agreements.
Margin Buying
In a margin buying arrangement, the funds borrowed to
buy the securities are provided by the broker and the broker gets the money
from a bank. The interest rate banks charge brokers for these transactions
is called the call money rate (or broker loan rate). The broker charges the
investor the call money rate plus a service charge. In the United States,
the Securities and Exchange Act of 1934 prohibits brokers from lending
more than a speciﬁed percentage of the market value of the securities.
Margin buying is the most common collateralized borrowing arrange-
ment for common stock investors—both individual (retail) investors and
institutional investors—and retail bond investors. It is not as common for
bond institutional investors.
Repurchase Agreement
The collateralized borrowing arrangement used
by institutional investors in the bond market is the repurchase agreement.
A repurchase agreement is the sale of a security with a commitment by the
seller to buy the same security back from the purchaser at a speciﬁed price
at a designated future date. The repurchase price is the price at which the
seller and the buyer agree that the seller will repurchase the security on
a speciﬁed future date called the repurchase date. The difference between
the repurchase price and the sale price is the dollar interest cost of the
loan. Based on the dollar interest cost, the sales price, and the length of
the repurchase agreement, and implied interest rate can be computed. This
implied interest rate is called the repo rate. The advantage to the investor
of using this borrowing arrangement is that the interest rate is less than the
cost of bank ﬁnancing. When the term of the loan is one day, it is called an
overnight repo (or overnight RP); a loan for more than one day is called a
term repo (or term RP). The repo rate varies from transaction to transaction
depending on a variety of factors.
2.3.2
Long and Short Positions
When an investor takes a position in the market by buying a security, the
investor is said to be in a long position in the security. Obviously, the investor
gains from a long position if the security’s price increases after the purchase.
When an investor borrows a security from a broker and sells it, with the
understanding that the security must be returned later, the investor is said
to be taking a short position in the security (or selling it short). Short-selling
strategies are useful if the investor believes that the price of the security will
fall. After borrowing the security from the broker today, the investor can sell

Important Finance Concepts
25
the security in the market at today’s price, buy the security back later at a
(hopefully) lower price, and return the security to the broker while realizing
a proﬁt.
2.4
CALCULATING RATE OF RETURN
Section 2.2 discussed two asset classes in detail. In this section, we explain
an important concept associated with assets—the rate of return—which in
some ways bears characteristics of an interest rate.
The simple rate of return (usually called just return) on an asset is the
percentage difference between the amount received from investing in the
asset and the amount originally invested in the asset:
Return = (Amount received −Amount invested)/(Amount invested)
In order to compute the return, of course, we need to specify the invest-
ment horizon in advance.
Suppose we invest $Ct in an asset at time t, and the value of our invest-
ment is $CT at time T. The return on the asset between time t and T, which
we denote r(t,T),5 is
r(t,T) = CT −Ct
Ct
.
If we are given the return and the initial amount invested, and would
like to compute the amount received from our investment, we would use the
equality
CT = Ct · (1 + r(t,T)).
In this sense, the rate of return acts similarly to the rate of interest.
When the asset is a stock, the return can be calculated as
r(t,T) = PT −Pt + Dt
Pt
,
where Pt and PT are the market prices of the stock at times t and T,
respectively, and Dt is the amount of dividends paid between times t
and T.
Returns are compounded much in the way compound interest is. Let us
explain this with an example. Suppose that an initial capital of C0 = $1,000

26
FUNDAMENTAL CONCEPTS
in some investment has value C1 = $1,300 at the end of year 1, and value
C2 = $1,000 at the end of year 2. What is the return on the investment over
the two years?
We know, of course, the return should be 0 since the initial capital is
identical to the capital at the end of two years:
r(0,2) = (C2 −C0)/C0 = (1, 000 −1, 000)/1, 000 = 0
If we compute the returns over the two years separately, we get a return
of 30% (r(0,1) = (1,300 – 1,000)/1,000 = 0.30) over year 1 and a return of
approximately –23% (r(1,2) = (1,000 – 1,300)/1,300 = –0.23) over year 2.
If we add these two returns, we would obtain a return of 30% −23% =
7%, which is intuitively wrong.
Instead, we compound the returns over the two time periods, and obtain
the following for the return at the end of two years:
r(0,2) = (1 + 0.30) · (1 −0.23) −1 = 0.001
This number is 0 (there is some rounding error), which agrees with our
intuition.6
In general, an investment of $1 at time 0 will grow to (1 + r(0,1))(1 +
r(1,2)) . . . (1 + r(t−1,t)) dollars at the end of year t, and the return r(0,t) from
time 0 to time t equals
r(0,t) = (1 + r(0,1))(1 + r(1,2)) . . . (1 + r(t−1,t)) −1
The expression (1 + r(t,T)) is called gross return. In the previous two-year
example, the gross return over the two years is (1 + r(0,2)) = 1.00. The gross
return over year 1 is (1 + r(0,1))= 1.30, and the gross return over year 2 is
(1 + r(1,2))= 0.75.
Returns can also be expressed in geometric (log) form. The log return
between time t and T is deﬁned as
log(1 + r(t,T))
where log is the natural logarithm, that is, the function so that elog(x) =
x.7,8 Note that when using log returns, the implicit assumption is that re-
turns are accumulated continuously (think of the analogy with continuously
compounded interest).

Important Finance Concepts
27
It is easy to see that
log(1 + r(t,T)) = log

1 + CT −Ct
Ct

= log
CT
Ct

.
If the time interval (t,T) is small, the numerical value of the return r(t,T)
will also be small. Therefore, log(1 + r(t,T)) will be approximately r(t,T) for
short time periods.9
If we are dealing with a stock, then
log(1 + r(t,T)) = log

1 + PT −Pt + Dt
Pt

= log
 PT + Dt
Pt

.
There are several advantages to using log returns in ﬁnancial modeling,
whose applications will become clearer when ﬁnancial derivative pricing
models are discussed in Chapters 13 and 14. On an intuitive level, log
returns are more economically meaningful because the asset price can never
become negative regardless of how negative the returns may be. (This is not
the case with the deﬁnition of return we introduced at the beginning of this
section.) Furthermore, the log return over multiple time periods is simply
the sum of the one-period log returns. Namely,
log(1 + r(0,t)) = log

(1 + r(0,1))(1 + r(1,2)) · · · (1 + r(t−1,t))

= log(1 + r(0,1)) + log(1 + r(1,2)) + · · · + log(1 + r(t−1,t))
Finally, a widely used concept in bond portfolio management is total
return. The total return is computed as
Total return = (Amount received)/(Amount invested)
where the amount received is comprised of three sources:
1. The coupon payments.
2. The change in the value of the bond.
3. Income from reinvestment of coupon payments and principal repayment
(in the case of amortizing securities) from the time of receipt to the end
of the investment horizon.
For example, suppose that an investor purchases a ﬁxed income security
for $90 and expects a return over a 1-year investment horizon from the three

28
FUNDAMENTAL CONCEPTS
sources equal to $5. Then the expected total return is 5.56% (= $5/$90).
Total return is discussed in more detail in section 2.6.8.
2.5
VALUATION
Valuation is the process of determining the fair value of a ﬁnancial asset.
This process is also referred to as valuing or pricing a ﬁnancial asset. The
fundamental principle of ﬁnancial asset valuation is that the value of an
asset is equal to the present value of its expected cash ﬂows. This principle
applies regardless of the ﬁnancial asset. Thus, the valuation of a ﬁnancial
asset involves the following three steps:
1. Estimate the expected cash ﬂows.
2. Determine the appropriate interest rate or interest rates that should be
used to discount the cash ﬂows.
3. Calculate the present value of the expected cash ﬂows found in Step 1
using the interest rate or interest rates determined in Step 2.
In this book, we introduce many different valuation models. Here we
discuss classic valuation models for stocks and bonds.
2.5.1
Valuation Models for Equities
Common stock can be thought of as a perpetual security—the owner of the
shares has the right to receive a portion of cash ﬂows from the company
paid out as dividends. The value of one share should equal the present value
of all future cash ﬂows (dividends) the owner of the stock expects to receive
from that share. Hence, to value one share, the investor must forecast future
dividends. This approach to the valuation of common stock is referred to
as the discounted cash ﬂow approach, and the ﬁrst dividend discount model
dates back to John Williams (1938).
The theoretical (also called fair) value of the stock price is
D1
(1 + r) +
D2
(1 + r)2 +
D3
(1 + r)3 + · · ·
where r is an appropriate discount rate. Note that this is an inﬁnite sum.
Future dividends are not known with certainty, and whether a corpo-
ration pays out dividends is decided by its board of directors. If a company
does not pay dividends (e.g., it retains earnings), however, the same principle
applies, as the retained earnings should be paid out as dividends eventually.

Important Finance Concepts
29
In that case, the fair value of the stock is deﬁned to be the present value of
the discounted cash ﬂow stream.
Later in the book, we will discuss optimal portfolio allocation. One of
the inputs to such models is the expected return of a security. It is intuitive
how an estimate of this return can be produced from cash ﬂow discount
models for the stock price—the expected return on a stock would be the
value of r in the previous formula that makes the value calculated with the
formula equal to the observed market price of the stock. Since the formula
for the price contains an inﬁnite sum, additional assumptions must be made
in order to be able to compute the expected return. For example, one can
attempt to forecast the price PT of the stock at some future date T, in which
case the formula becomes
P0 =
D1
(1 + r) +
D2
(1 + r)2 +
D3
(1 + r)3 + · · · +
PT
(1 + r)T .
From here, the value of the expected return can be found by trial
and error.
Alternatively, one can make the assumption that future dividends will
grow at a constant rate g. This model was developed by Gordon (1962) and
is therefore often referred to as the Gordon model. We have
Dt+1 = Dt · (1 + g) = D1 · (1 + g)t−1.
Therefore, the inﬁnite sum in the dividend discount model becomes
D1 ·
1
(1 + r) ·

1 + (1 + g)1
(1 + r)1 + (1 + g)2
(1 + r)2 + · · ·

.
The inﬁnite sum inside the parentheses can now be computed in closed
form because it is a sum of an inﬁnite geometric series of the kind
1 + q + q2 + q3 + · · ·
(where q in this case is (1+g)/(1+r)), which equals
1
1 −q

30
FUNDAMENTAL CONCEPTS
Therefore, the Gordon model results in a stock price of
D1
r −g
Given the current market price of the stock and using the preceding
formula, a value for the expected return r can be derived.
There are numerous other valuation models, and a complete review is
beyond the scope of this book. It is important to keep in mind, however,
that all of the parameters that go into these models need to be estimated,
and if the various quantities are deﬁned by different accounting practices or
forecasting models, they can lead to signiﬁcantly different valuations.
2.5.2
Valuation Models for Fixed
Income Securities
The value of a bond is the discounted sum of its payments. In other words,
B0 =
C1
(1 + r) +
C2
(1 + r)2 +
C3
(1 + r)3 + · · · +
CT
(1 + r)T
where Ct denotes the cash ﬂow (coupons or coupon plus principal) paid at
date t. While the concept is simple, the details of its implementation, in-
cluding how to determine an appropriate discount rate, can lead to different
valuations. The minimum interest rate r the investor should require is the
prevalent discount rate in the marketplace on a default-free cash ﬂow. In
the United States, U.S. Treasuries are considered the norm for default-free
securities. This is one of the reasons the Treasury market is closely watched.
Consider a bond with a $100 principal, a coupon rate of 10% paid
annually, and a term to maturity of 3 years. Assume a discount rate of 6%.
Today’s value of the bond is
10
(1 + 0.06) +
10
(1 + 0.06)2 +
110
(1 + 0.06)3 = $110.69.10
If a 12% annual discount rate was used, the bond value today would
have been
10
(1 + 0.12) +
10
(1 + 0.12)2 +
110
(1 + 0.12)3 = $95.20.

Important Finance Concepts
31
Bond Price 
Interest Rate
EXHIBIT 2.2
Relationship between bond price and
discount rate.
Note that the value of the bond is lower when the interest rate is higher.
This is an important property of bond prices: when interest rates go up, bond
prices generally decline. The opposite is true as well—when interest rates go
down, bond prices generally increase. (See Exhibit 2.2.) The relationship
between bond prices and interest rates is actually nonlinear: the bond price
is a convex function of interest rates.11 You can observe this by computing
the bond values for several different values of the discount rate. The shape
of the relationship between bond prices and interest rates is important for
risk management purposes. We will discuss it in more detail in the context
of bond portfolio management in Chapter 10.
When one observes bond prices in the market, one can use the infor-
mation about the bond and its market price to determine the interest rate
that makes the present value of the stream of cash ﬂows equal to the bond
price. This implied interest rate is called yield to maturity (YTM), or simply
yield. It is quoted on an annual basis. To ﬁnd it, one would use an iterative
trial-and-error procedure. In other words, different values for the yield will
be tried until the computed present value of the bond cash ﬂows equals the
observed value.
Since the cash ﬂows are every six months, the yield to maturity found
by solving the equation for the bond price is a semiannual yield to maturity.
This yield can be annualized by either (1) doubling the semiannual yield or
(2) compounding the yield. The market convention is to annualize the semi-
annual yield by simply doubling its value. The yield to maturity computed
on the basis of this market convention is called the bond-equivalent yield. It
is also referred to as a yield on a bond-equivalent basis.

32
FUNDAMENTAL CONCEPTS
Yield 
Time to Maturity (years)
EXHIBIT 2.3
Upward-sloping yield curve.
Observed bond yields tend to be different depending on the time to
maturity. The plot of bond yields versus the length of time corresponding to
these yields is referred to as the yield curve. An example of a yield curve is
given in Exhibit 2.3. The usual shape of the yield curve is upward-sloping;
however, the yield curve can have different shapes depending on market con-
ditions. The reason why an upward-sloping curve is considered “normal” is
because investors are assumed to demand more yield for long-term invest-
ments than for short-term investments. Long-term investments are subject to
more uncertainty. However, sometimes long-term bonds have lower yields
than short-term bonds. In the latter case, we refer to the yield curve as an
inverted yield curve. If the yields for all maturities were the same, of course,
the yield curve would simply be a ﬂat horizontal line.
Knowledge of the yield curve is helpful because it allows us to position
a particular bond with regard to other bonds in its class. It allows us to
compute the required yield for a bond. The required yield reﬂects the yield
for ﬁnancial instruments with comparable risk to a bond we are trying to
price. Given the required yield, we can determine the price of the bond by
using the required yield as the interest rate r in the pricing formula shown
earlier in this section.
In the previous bond value calculation examples, we assumed that the
discount rate is the same for all cash ﬂows. In reality, the discount rates are
typically different, depending on the length of time until the cash ﬂow will
be received. The U.S. Treasury rates, which are the relevant reference rates
for default-free cash ﬂows, are followed particularly closely. To see how
the value of the bond would be computed when the discount rates for the

Important Finance Concepts
33
cash ﬂows are different, consider again the example of the bond with $100
principal, a coupon rate of 10% paid annually, and a term to maturity of
3 years. Assume that the discount rates for year 1, 2, and 3 are of 6.00%,
6.80%, and 7.20%, respectively. Today’s value of the bond is
10
(1 + 0.06) +
10
(1 + 0.0680)2 +
110
(1 + 0.0720)3 = $108.55.
2.6
IMPORTANT CONCEPTS IN FIXED INCOME
This section reviews important advanced concepts in ﬁxed income.
2.6.1
Spot Rates
The spot rate is the interest rate charged for money held from the present
time until a prespeciﬁed time t. The convention is to quote spot rates as
yearly rates, but the speciﬁc characteristics of the compounding (yearly, m
time periods per year, or continuous) vary. The interest rates we used in the
section on valuation were all spot rates.
Sometimes, spot rates are referred to as zero rates (short for zero-coupon
rates) because they are in fact the return on a zero-coupon bond that is
bought today and paid out a certain number of years in the future. Suppose
the 5-year Treasury spot (zero) rate with continuous compounding is quoted
as 6% per annum. This means that if the price of a 5-year zero-coupon bond
today is B0, and the payout after ﬁve years is B5, then the following holds:
B5 = B0 · e0.06 · 5.
In general, let st denote the spot rate for time period t.12 Then, if Bt
denotes the price of a zero-coupon bond with maturity t, we have
Bt = B0 · est · t.
2.6.2
The Term Structure
The term structure deﬁnes the relationship between time and interest rates,
with spot rates as the underlying interest rates. It is usually presented as a
graph, as the yield curve in Exhibit 2.3. The term structure in interest rates is
in fact a yield curve, but its meaning is a bit more academic, as it focuses on
pure interest rates for default-free securities rather than yields. Knowledge
of the term structure is crucial for pricing and trading purposes.

34
FUNDAMENTAL CONCEPTS
The obvious way to ﬁnd the term structure of interest rates is to compute
the interest rates implied in the prices of a series of zero-coupon default-free
bonds. However, it is difﬁcult to ﬁnd zero-coupon bonds that span all ma-
turities, especially long maturities.13 This does not diminish the importance
or usefulness of constructing the term structure. The term structure can be
constructed from coupon-bearing bonds by a procedure called bootstrap-
ping.14 The idea is to use several coupon-bearing bonds, determine the spot
rates implied by the bonds with the shortest maturity, use that knowledge to
compute the spot rate implied by the bond with the next-shortest maturity,
and proceed in this manner until the whole term structure is constructed.
The same method is used to construct other spot rate curves, such as the
spot rate curve for LIBOR.15 There will obviously be gaps in the term struc-
ture because we cannot necessarily determine every point on the curve from
market prices. Interpolation and polynomial approximations are used to
complete the term structure given a few points.
Given a term structure of interest rates, discount factors for securities of
different maturities can be determined. For example, if a coupon bond pays
coupons six months from now and a year from now, we can read the interest
rates corresponding to six months and one year from the term structure, and
use those rates to discount the cash ﬂows from the bond’s coupons when
valuing the bond.
2.6.3
Forward Rates
Forward rates can be thought of as the current market consensus of future
spot rates: they are interest rates for money to be invested between two dates
in the future, but under terms agreed upon today. The concept of forward
rates is very useful for pricing and investment purposes. Similarly to spot
rates, forward rates are quoted as yearly rates.
Forward rates can be derived from the term structure of interest rates.
Examples of forward rates that can be extrapolated from the Treasury yield
curve include
■6-month forward rate six months from now.
■6-month forward rate three years from now.
■1-year forward rate one year from now.
■3-year forward rate two years from now.
■5-year forward rate three years from now.
We will use the following notation to denote forward rates: t fm, where
the subscript t indicates a t-year interest rate, and the subscript m indicates
that the t years begin m years from now. For example, 0.5f 3 is the 6-month

Important Finance Concepts
35
forward rate three years from now, and 3f 2 is the 3-year forward rate two
years from now. When m = 0, the forward rate is the same as the spot rate;
that is, tf 0 = st.
How do we compute forward rates? Consider, for example, an in-
vestor with a 1-year investment horizon who is faced with the following
two choices:
■Buy a 2-year Treasury note.
■Buy a 1-year Treasury bill and, when it matures in one year, buy another
1-year Treasury bill.
The investor would be indifferent between the two choices only if the
return on the two is the same. If one of them offers a better return than the
other, all investors will prefer that option, which will drive up its price, and
hence reduce its return until it equals the return on the option that was less
desirable at the beginning.16 The value of an investment of $C with the ﬁrst
option after two years will be
C · (1 + s2)2,
where s2 is the 2-year spot rate. The return on a 2-year investment with the
second option will be
C · (1 + s1) · (1 + 1f1),
where s1 is the 1-year spot rate, and 1f 1 is the implied rate in a 1-year
Treasury bill purchased one year from now, that is, the 1-year forward one
year from now. Since the returns on the two investments must be equal, we
get
(1 + s2)2 = (1 + s1) · (1 + 1f1),
which allows us to compute the forward rate 1f 1 as
1f1 = (1 + s2)2
(1 + s1) −1.
For m time periods ahead, we have
1fm = (1 + sm+1)m+1
(1 + sm)
−1.

36
FUNDAMENTAL CONCEPTS
In general, if we are given the term structure, and hence have information
about spot rates st and sT for two times t and T, then we can estimate the
forward rate between t and T, (T–t)ft, as
(T−t) ft = (1 + sT)
(1 + st) −1.
2.6.4
Credit Spreads
When cash ﬂows are not default-free, the Treasury rates cannot be used to
discount them for valuation purposes. This is because, technically, investors
should require a higher yield from default-risky than from default-free se-
curities to compensate for the risk they are taking. For pricing default-risky
securities, a term structure of credit spreads is often used, where a credit
spread is deﬁned as the difference between the yield on a default-free bond
and a default-risky bond with the same cash ﬂow characteristics. Dealer
ﬁrms typically estimate a term structure for credit spreads for each credit
rating and market sector. Generally, the credit spread increases with time
to maturity. In addition, the shape of the term structure is not the same for
all credit ratings. Typically, the lower the credit rating, the steeper the term
structure of credit spreads. This is because the risk of default is higher when
the default-risky security is a longer-term investment.
2.6.5
Duration
The value of a bond investment is sensitive to changes in interest rates. This
is because if the discount rates used to evaluate the different cash ﬂows
from the bond change, so will its price. All other things being equal, bonds
with long maturities are more sensitive to changes in interest rates than
bonds with short maturities. However, maturity alone is not sufﬁcient for
measuring the degree of interest rate sensitivity. Intuitively, the higher the
bond’s coupon rate, the more dependent the bond’s total dollar return will
be on the reinvestment of the coupon payments in order to produce the yield
to maturity at the time of purchase. Hence, a change in interest rates during
the life of the bond can have a substantial impact on the total return.
Duration is a measure of the sensitivity of a bond’s price with respect to
changes in interest rates which takes into consideration the issues previously
discussed. In mathematical terms, it is the derivative of the bond price with
respect to interest rates, that is, it measures ﬁrst-order sensitivity. As Ex-
hibit 2.2 showed, the relationship between the bond price and interest rates
is in fact nonlinear, so the duration would not explain the exact change in
bond prices for a given change in interest rates. Convexity, which we will

Important Finance Concepts
37
describe in the next section, complements duration to provide a more accu-
rate description of the sensitivity. It is important to note, however, that both
duration and convexity describe the sensitivity of bond prices to interest
rates when there is a parallel shift in the yield curve, that is, when the rates
for all maturities move up or down simultaneously and by the same number
of basis points. This clearly places a limitation on the usefulness of duration
and convexity as measures of bond interest rate risk. Nevertheless, duration
and convexity are very popular, fundamental tools in ﬁxed income analysis.
Even though deﬁning duration as the ﬁrst derivative of the price/yield
function is mathematically correct, it is not really used in practice because
it is difﬁcult to explain to clients what the relevance of such a mathematical
concept is to measuring actual investment risk. Instead, duration is typically
explained as the approximate price sensitivity of a bond to a 100-basis-
point change in rates. Thus, a bond with a duration of 5 will change by
approximately 5% for a 100-basis-point change in interest rates (that is, if
the yield required for this bond changes by approximately 100 basis points).
For a 50-basis-point change in interest rates, the bond’s price will change by
approximately 2.5%; for a 25 basis point change in interest rates, 1.25%,
and so on.
Let us now deﬁne duration more rigorously. The exact formulation is
Price if yields decline −Price if yields rise
2 · (Initial price) · (Change in yield in decimal).
Let D denote duration, B0 denote the initial price, y denote the change
in yield, B−denote the price if yields decrease by y, and B+ denote the
price if yields increase by y. We have
D =
B−−B+
2 · B0 · y.
It is important to understand that the two values in the numerator
of the preceding equation, B+ and B−, are the estimated values obtained
from a valuation model if interest rates change. Consequently, the duration
measure is only as good as the valuation model employed to obtain these
estimated values. The more difﬁcult it is to estimate the value of a bond,
the less conﬁdence a portfolio manager may have in the estimated duration.
We will see in Chapter 10 that the duration of a portfolio is nothing more
than a market-weighted average of the duration of the bonds comprising the
portfolio. Hence, a portfolio’s duration is sensitive to the estimated duration
of the individual bonds.

38
FUNDAMENTAL CONCEPTS
To illustrate the duration calculation, consider the following bond: a
6% coupon ﬁve-year bond trading at par value to yield 6%. The current
price is $100. Suppose the yield is changed by 50 basis points. Thus, y =
0.005 and B0 = $100. This is simple bond to value if interest rates or yield is
changed. If the yield is decreased to 5.5%, the value of this bond would be
$102.1600. If the yield is increased to 6.5%, the value of this bond would
be $97.8944. Therefore, B−= $102.1600 and B+ = $97.8944. Substituting
into the equation for duration, we obtain
Duration = 102.1600 −97.8944
2 · (100) · (0.005)
= 4.27.
Dollar Duration
In estimating the sensitivity of the price of bond to changes
in interest rates, we looked at the percentage price change. However, for two
bonds with the same duration but trading at different prices, the dollar price
change will not be the same. To see this, suppose that we have two bonds, A
and B, that both have durations of 5. Suppose further that the current price
of A and B are $100 and $90, respectively. A 100-basis-point change for
both bonds will change the price by approximately 5%. This means a price
change of $5 (5% times $100) for A, and a price change of $4.5 (5% times
$90) for B.
The dollar price change of a bond can be measured by multiplying
duration by the full dollar price and the number of basis points (in decimal
form) and is called the dollar duration. That is,
Dollar duration = (Duration) · (Dollar price) · (Change in rates in decimal)
The dollar duration for a 100-basis-point change in rates is
Dollar duration = (Duration) · (Dollar price) · 0.01
So, for bonds A and B, the dollar duration for a 100-basis-point change
in rates is
For bond A: Dollar duration = 5 · $100 · 0.01 = $5.0
For bond B: Dollar duration = 5 · $90 · 0.01 = $4.5
Knowing the dollar duration allows a portfolio manager to neutralize
the risk of bond position. For example, consider a position in bond B. If a
trader wants to eliminate the interest rate risk exposure of this bond,17 the
trader will look for a position in one or more other ﬁnancial instruments,
such as an interest rate derivative,18 whose value will change in the opposite

Important Finance Concepts
39
direction to bond B’s price by an amount equal to $4.5. So, if the trader
has a long position in B, the position will decline in value by $4.5 for a
100-basis-point increase in interest rates. To eliminate this risk exposure,
the trader can take a position in another ﬁnancial instrument whose value
increases by $4.5 if interest rates increase by 100 basis points.
The dollar duration can also be computed without knowing a bond’s
duration. This is done by simply looking at the average price change for a
bond when interest rates are increased and decreased by the same number
of basis points.
Modified Duration, Macaulay Duration, and Effective Duration
A popular
form of duration that is used by practitioners is modiﬁed duration. Modiﬁed
duration is the approximate percentage change in a bond’s price for a 100-
basis-point change in interest rates, assuming that the bond’s cash ﬂows do
not change when interest rates change. What this means is that in calculating
the values used in the numerator of the duration formula, the cash ﬂows
used to calculate the current price are assumed. Therefore, the change in the
bond’s value when interest rates change by a small number of basis points
is due solely to discounting at the new yield level.
Modiﬁed duration is related to another measure commonly cited in the
bond market: Macaulay duration. The formula for this measure, ﬁrst used
by Frederick Macaulay in 1938, is rarely used in practice, so it will not be
produced here. For a bond that pays coupon interest semiannually, modiﬁed
duration is related to Macaulay duration as follows:
Modiﬁed duration = Macaulay duration/(1 + yield/2),
where yield is the bond’s yield to maturity in decimal form. Practically
speaking, there is very little difference in the computed values for modiﬁed
duration and Macaulay duration.
The assumption that the cash ﬂows will not change when interest rates
change makes sense for bonds because the payments by the issuer are not
altered when interest rates change. This is not the case for bonds with
embedded options, mortgage-backed securities, and certain types of asset-
backed securities. For these securities, a change in interest rates may alter
the expected cash ﬂows.19
For such bonds, there are speciﬁc valuation models that take into ac-
count how changes in interest rates will affect cash ﬂows. When the values
used in the numerator of the equation for duration are obtained from a
valuation model that takes into account both the discounting at different
interest rates and how the cash ﬂows can change, the resulting duration is
referred to as effective duration or option-adjusted duration.

40
FUNDAMENTAL CONCEPTS
Spread Duration for Fixed Rate Bonds
Duration is a measure of the change
in the value of a bond when rates change. The interest rate that is assumed
to shift is the Treasury rate. However, for non-Treasury securities, the yield
is equal to the Treasury yield plus a spread to the Treasury yield curve. The
price of a bond exposed to credit risk can change even though Treasury
yields are unchanged because the spread required by the market changes.
A measure of how a non-Treasury issue’s price will change if the spread
sought by the market changes is called spread duration and is a measure of
credit spread risk, which we described earlier in this chapter. For example,
a spread duration of 2.2 for a security means that if the Treasury rate is
unchanged but spreads change by 100 basis points, the security’s price will
change by approximately 2.2%.
2.6.6
Convexity
The duration measure indicates that regardless of whether interest rates
increase or decrease, the approximate percentage price change is the same.
However, while for small changes in yield the percentage price change will
be the same for an increase or decrease in yield, for large changes in yield
this is not true. This suggests that duration is only a good approximation of
the percentage price change for a small change in yield.
The reason for this is that duration is in fact a ﬁrst approximation
for a small change in yield. The approximation can be improved by using a
second-order approximation. This approximation is referred to as convexity.
The use of this term in the industry is unfortunate since the term convexity
is also used to describe the shape or curvature of the price/yield relationship.
The convexity measure of a security can be used to approximate the change
in price that is not explained by duration.
Convexity Measure
The convexity measure of a bond can be approximated
using the following formula:
Convexity measure = B+ + B−−2 · B0
2 · B0 · (y)2
where the notation is the same as used earlier for deﬁning duration.
For a hypothetical 6%, 25-year bond selling to yield 9%, we can com-
pute that for a 10-basis-point change in yield (y = 0.001), we have B0 =
70.3570, B– = 71.1105, and B+ = 69.6164. Substituting these values into
the convexity measure given by the preceding equation, we obtain
Convexity measure = 69.6164 + 71.1105 −2 · 70.3570
2 · 70.3570 · (0.001)2
= 91.67

Important Finance Concepts
41
We will see how to use this convexity measure shortly. Before doing
so, there are three points that should be noted. First, there is no simple
interpretation of the convexity measure as there is for duration.20 Second, it
is more common for market participants to refer to the value computed in the
previous equation as the “convexity of a bond” rather than the “convexity
measure of a bond.” Finally, the convexity measures reported by dealers and
vendors will differ. The reason is that the convexity value obtained from the
preceding equation will be scaled for the reason explained later.
Convexity Adjustment to Percentage Price Change
Given the convexity
measure, the approximate percentage price change adjustment due to the
bond’s convexity (that is, the percentage price change not explained by
duration) is
Convexity adjustment to percentage
price change = Convexity measure · (y)2 · 100.
For example, for the 6%, 25-year bond selling to yield 9%, the convexity
adjustment to the percentage price change based on duration if the yield
increases from 9% to 11% is
91.67 · (0.02)2 · 100 = 3.67.
If the yield decreases from 9% to 7%, the convexity adjustment to
the approximate percentage price change based on duration would also be
3.67%.
The approximate percentage price change based on duration and the
convexity adjustment is found by adding the two estimates. So, for example,
if yields change from 9% to 11%, the estimated percentage price change
would be:
Estimated change approximated by duration = −21.20%
Convexity adjustment =
−3.66%
Total estimated percentage price change = −17.54%
The actual percentage price change can be computed to be –18.03%.
Hence, the approximation has improved compared to using only duration.
For a decrease of 200 basis points, from 9% to 7%, the approximate
percentage price change would be as follows:
Estimated change approximated by duration = +21.20%
Convexity adjustment =
+3.66%
Total estimated percentage price change = +24.86%

42
FUNDAMENTAL CONCEPTS
The actual percentage price change can be computed to be +25.46%.
Once again, we see that duration combined with the convexity adjustment
does a good job of estimating the sensitivity of a bond’s price change to large
changes in yield.
The bond prices used to calculate the convexity measure can be obtained
by either assuming that when the yield changes, the expected cash ﬂows do
not change, or that they do change. In the former case, the resulting convexity
is referred to as standard convexity. (Actually, in the industry, convexity is
not qualiﬁed by the adjective “standard.”) Effective convexity, in contrast,
assumes that the cash ﬂows do change when yields change. The distinction
is the same as the one made for duration.
As with duration, for bonds with embedded options there can be a
large difference between the calculated standard convexity and effective
convexity. In fact, for all option-free bonds, either convexity measure will
have a positive value. For bonds with embedded options, the calculated
effective convexity can be negative when the calculated modiﬁed convexity
is positive.
2.6.7
Key Rate Duration
As explained earlier, duration assumes that when interest rates change, all
yields on the yield curve change by the same amount. This is a problem when
using duration for a portfolio that will typically have bonds with different
maturities. Consequently, it is necessary to be able to measure the exposure
of a bond or bond portfolio to shifts in the yield curve. There have been
several approaches to measuring yield curve risk. The most commonly used
measure is key rate duration introduced by Thomas Ho.21
The basic principle of key rate duration is to change the yield for a
particular maturity of the yield curve and determine the sensitivity of either
an individual bond or a portfolio to that change holding all other yields
constant. The sensitivity of the change in the bond’s value or portfolio’s
value to a particular change in yield is called rate duration. There is a
rate duration for every point on the yield curve. Consequently, there is not
just one rate duration. Rather, there is a set of durations representing each
maturity on the yield curve. Note that the total change in the value of a
bond or a portfolio if all rates change by the same number of basis points is
in fact the standard duration of a bond or portfolio.
Ho’s approach focuses on 11 key maturities of the Treasury yield curve.
These rate durations are called key rate durations. The speciﬁc maturi-
ties on the spot rate curve for which a key rate duration is measured are
3 months, 1 year, 2 years, 3 years, 5 years, 7 years, 10 years, 15 years,

Important Finance Concepts
43
20 years, 25 years, and 30 years. Changes in rates between any two key
rates are calculated using a linear approximation.
A key rate duration for a particular portfolio maturity should be inter-
preted as follows: Holding the yield for all other maturities constant, the
key rate duration is the approximate percentage change in the value of a
portfolio (or bond) for a 100-basis-point change in the yield for the matu-
rity whose rate has been changed. Thus, a key rate duration is quantiﬁed
by changing the yield of the maturity of interest and determining how the
value or price changes. In fact, the equation we introduced for duration is
used. The prices denoted by B−and B+ in the equation are the prices in the
case of a bond and the portfolio values in the case of a bond portfolio found
by holding all other interest rates constant and changing the yield for the
maturity whose key rate duration is sought.
The concept of key rate durations is very important when evaluating
portfolio risk. We will discuss this concept again in Chapter 16.
2.6.8
Total Return
An investor who purchases a bond can expect to receive a dollar return from
one or more of these three sources:
■The periodic coupon interest payments made by the issuer.
■Income from reinvestment of the periodic interest payments (the interest-
on-interest component).
■Any capital gain (or capital loss—negative dollar return) when the bond
matures or is sold.
Any measure of a bond’s potential yield should take into consideration
each of these three potential sources of return. The yield to maturity takes
into account coupon interest and any capital gain (or loss). It also con-
siders the interest-on-interest component. Implicit in the yield-to-maturity
computation, however, is the assumption that the coupon payments can
be reinvested at the computed yield to maturity. Reinvesting the coupon
interest payments at a rate of interest less than the yield to maturity, for
example, will produce a lower yield than the yield to maturity. This risk is
called reinvestment risk.
Rather than assuming that the coupon interest payments are reinvested
at the yield to maturity, an investor can make an explicit assumption about
the reinvestment rate based on expectations. The total return is a measure of
yield that incorporates an explicit assumption about the reinvestment rate.
The total return measure allows a portfolio manager to project the
performance of a bond on the basis of the planned investment horizon and

44
FUNDAMENTAL CONCEPTS
expectations concerning reinvestment rates and future market yields. This
permits the portfolio manager to evaluate which of several potential bonds
considered for acquisition will perform the best over the planned investment
horizon. As we have emphasized, this cannot be done using the yield to
maturity. Using total return to assess performance over some investment
horizon is called horizon analysis. When a total return is calculated over an
investment horizon, it is referred to as a horizon return. Horizon return and
total return are typically used interchangeably.
An often-cited objection to the total return measure is that it requires
the portfolio manager to formulate assumptions about reinvestment rates
and future yields, as well as to think in terms of an investment horizon.
Unfortunately, some portfolio managers ﬁnd comfort in measures such as
the yield to maturity and yield to call simply because they do not require
incorporating any particular expectations. The horizon analysis framework,
however, enables the portfolio manager to analyze the performance of a
bond under different interest rate scenarios for reinvestment rates and future
market yields. This procedure is referred to as scenario analysis. Only by
investigating multiple scenarios can the portfolio manager see how sensitive
the bond’s performance will be to each scenario.22
To illustrate scenario analysis, consider a portfolio manager who is
deciding on whether to purchase a 20-year, 9% option-free bond selling
at $109.896 per $100 of par value. The yield to maturity for this bond
is 8%. Assume also that the portfolio manager’s investment horizon is
three years. The portfolio manager believes the reinvestment rate can vary
from 3% to 6.5% and the projected yield at the end of the investment
horizon can vary from 5% to 12%. Exhibit 2.4(A) shows different pro-
jected yields at the end of the three-year investment horizon, and Exhibit
2.4(B) gives the corresponding price for the bond at the end of the invest-
ment horizon. For example, consider the 10% projected yield at the end
of the investment horizon. The price of a 17-year option-free bond with
a coupon rate of 9% would be $91.9035. Exhibit 2.4(C) shows the to-
tal future dollars at the end of three years under various scenarios for the
reinvestment rate and the projected yield at the end of the investment hori-
zon. For example, with a reinvestment rate of 4% and a projected yield at
the end of the investment horizon of 10%, the total future dollars would be
$120.290. Exhibit 2.4(D) shows the total return on an effective rate basis for
each scenario.
Exhibit 2.4 is useful for a portfolio manager in assessing the potential
outcome of a bond (or a portfolio) over the investment horizon. For example,
a portfolio manager knows that the maximum and minimum total return for
the scenarios shown in the table will be 16.72% and –1.05%, respectively,
and also knows the scenarios under which each will be realized.

Important Finance Concepts
45
EXHIBIT 2.4
Scenario analysis.
Bond A: 9% coupon, 20-year option-free bond
Price: $109.896
Yield to maturity: 8%
Investment horizon: Three years
A. Projected Yield at End of Investment Horizon
5.00%
6.00%
7.00%
8.00%
9.00%
10.00%
11.00%
12.00%
B. Projected Sale Price at End of Investment Horizon
145.448 131.698 119.701 109.206 100.000 91.9035
84.763
78.4478
C. Total Future Dollars
Reinv.
Rate
5.00%
6.00%
7.00%
8.00%
9.00%
10.00%
11.00%
12.00%
3.0%
173.481 159.731 147.734 137.239 128.033 119.937 112.796 106.481
3.5%
173.657 159.907 147.910 137.415 128.209 120.113 112.972 106.657
4.0%
173.834 160.084 148.087 137.592 128.387 120.290 113.150 106.834
4.5%
174.013 160.263 148.266 137.771 128.565 120.469 113.328 107.013
5.0%
174.192 160.443 148.445 137.950 128.745 120.648 113.508 107.193
5.5%
174.373 160.623 148.626 138.131 128.926 120.829 113.689 107.374
6.0%
174.555 160.806 148.809 138.313 129.108 121.011 113.871 107.556
6.5%
174.739 160.989 148.992 138.497 129.291 121.195 114.054 107.739
D. Total Return (Effective Rate)
Reinv.
Rate
5.00%
6.00%
7.00%
8.00%
9.00%
10.00%
11.00%
12.00%
3.0%
16.44
13.28
10.37
7.69
5.22
2.96
0.87
21.05
3.5%
16.48
13.32
10.41
7.73
5.27
3.01
0.92
20.99
4.0%
16.52
13.36
10.45
7.78
5.32
3.06
0.98
20.94
4.5%
16.56
13.40
10.50
7.83
5.37
3.11
1.03
20.88
5.0%
16.60
13.44
10.54
7.87
5.42
3.16
1.08
20.83
5.5%
16.64
13.49
10.59
7.92
5.47
3.21
1.14
20.77
6.0%
16.68
13.53
10.63
7.97
5.52
3.26
1.19
20.72
6.5%
16.72
13.57
10.68
8.02
5.57
3.32
1.25
20.66
Another way to use scenario analysis is in assessing the likelihood that
an investment objective will not be realized. For example, suppose that a life
insurance company has issued a three-year guaranteed investment contract in
which it has guaranteed an effective annual interest rate of 7.02%. Suppose
that the premiums are invested in the bond analyzed in Exhibit 2.4, and that
the portfolio manager’s investment objective is a minimum return of 7.02%

46
FUNDAMENTAL CONCEPTS
plus a spread of 100 basis points. The spread represents the proﬁt that the
life insurance company seeks to earn. Thus, the minimum return is 8.02%.
From Exhibit 2.4, the portfolio manager can see that if the yield at the end
of the investment horizon is 8% or greater, and that if the reinvestment rate
over the three-year investment horizon is less than 6.5%, a total return on an
effective rate basis will be less than the investment objective of a minimum
return of 8.02%.
SUMMARY
■Compound interest involves earning interest on the interest from an
investment.
■The present value of a future cash ﬂow is the amount of money that
must be invested today to generate the future cash ﬂow.
■The discount factor is the number by which we need to multiply the
future cash ﬂow to obtain its present value.
■In portfolio management, the most important decision made is the allo-
cation of funds among asset classes.
■Asset classes are classiﬁed as traditional and alternative asset classes.
■In most developed countries, the four major asset classes are (1) common
stocks, (2) bonds, (3) cash equivalents, and (4) real estate.
■Borrowing funds to purchase securities is known as a leveraged strategy.
Two borrowing arrangements used by investors are margin buying and
repurchase agreements.
■When an investor takes a position in the market by buying a security, the
investor is said to be in a long position in the security. When an investor
borrows a security from a broker and sells it, with the understanding
that the security must be returned later, the investor is said to be taking
a short position in the security (or selling it short).
■The simple rate of return (usually called just return) on an asset is the
percentage difference between the amount received from investing in the
asset and the amount originally invested in the asset.
■The log return is computed as the natural logarithm of one plus the
return (the latter is called the gross return). When using log returns, the
implicit assumption is that returns are accumulated continuously.
■Investors in ﬁxed income securities are exposed to credit risk, which
includes default risk, credit spread risk, and downgrade risk.
■Default risk is gauged by credit ratings assigned by rating agencies.
■Valuation is the process of determining the fair value of a ﬁnancial asset.
The fundamental principle of ﬁnancial asset valuation is that its value is
equal to the present value of its expected cash ﬂows.

Important Finance Concepts
47
■The implied interest rate that makes the present value of a stream of
cash ﬂows from a bond equal to the bond’s market price is called yield
to maturity or simply yield.
■The spot rate (also called zero rate) is the interest rate charged for money
held from the present time until a prespeciﬁed time t.
■The term structure deﬁnes the relationship between time and interest
rates, with spot rates as the underlying interest rates.
■Forward rates are the current market consensus of future spot rates:
they are interest rates for money to be invested between two dates in the
future, but under terms agreed upon today.
■For pricing default-risky securities, a term structure of credit spreads is
often used, where a credit spread is deﬁned as the difference between
the yield on a default-free bond and a default-risky bond with the same
cash ﬂow characteristics.
■Duration is a measure of the sensitivity of a bond’s price with respect to
changes in interest rates. It is a ﬁrst-order approximation to the change
in bond price when interest rates change by a ﬁxed amount.
■Convexity is a second-order approximation to the change in bond price
when interest rates change by a ﬁxed amount. It allows for estimating
the curvature of the relationship between changes in bond price and
changes in interest rates more accurately.
■Spread duration is a measure of the exposure of a ﬁxed income security
or portfolio to credit spread risk.
■Total return is a more complete measure of a bond’s potential return
than yield-to-maturity. It takes into consideration the periodic coupon
interest payments made by the issuer, the income from reinvestment
of the periodic interest payments (the interest-on-interest component)
without assuming that they will be reinvested at the same rate, and
any capital gain (or capital loss—negative dollar return) when the bond
matures or is sold.
NOTES
1. The value for the number e is so often used in applications, that it can be com-
puted with almost any software package. For example, in Excel, the expression
=exp(1) returns the value of e1, which is 2.7183 rounded to four digits after
the decimal point. In MATLAB, exp(1) gives the same answer.
2. LIBOR is the interest rate which major international banks charge each other
for loans (usually in Eurodollars, where a Eurodollar is an American dollar held
by a foreign institution outside the United States). Such loans allow banks with
liquidity requirements to borrow quickly from other banks with surpluses. The

48
FUNDAMENTAL CONCEPTS
LIBOR rate is used by banks for large loans made over a period of anywhere
between one day and ﬁve years. The 1-month LIBOR rate is the rate charged
on loans with maturity of one month. LIBOR is the primary benchmark for
interest rates around the world. It is set daily by a group of banks, but varies
throughout the day.
3. In the ﬁxed income market, market participants refer to changes in interest
rates of differences in interest rates in terms of basis points. A basis point (bp) is
deﬁned as 0.0001, or equivalently, 0.01%. Consequently, 100 basis points are
equal to 1%. (In our example the coupon formula can be expressed as 1-month
LIBOR + 1%.) A change in interest rates from, say, 5% to 6.2% means that
there is a 1.2% change in rates, or 120 basis points.
4. Inverse ﬂoaters were behind the Orange County bankruptcy of 1994; at the time
the largest municipality bankruptcy that had repercussions across the entire
municipalities bond market, and raised the cost of capital for municipalities
across the United States.
5. In general, we use the notation r(t1,t2) to denote the return between times t1
and t2.
6. To see this, note that the capital at the end of the second year is
C2 = (1 + r(1,2))C1 = (1 + r(1,2))

(1 + r(0,1))C0

= (1 + r(1,2))(1 + r(0,1))C0.
Therefore, the return over the two years is
r(0,2) = C2 −C0
C0
= (1 + r(1,2))(1 + r(0,1))C0 −C0
C0
= (1 + r(1,2))(1 + r(0,1)) −1.
7. We introduced the number e in section 2.1.
8. In Excel, the natural logarithm function is ln. For example, =ln(5) returns
1.6094. The result 1.6094 is the number so that e raised to the power of that
number equals 5, that is, e1.6094 = 5. In MATLAB, the natural logarithm function
is log.
9. It is a mathematical property of the natural logarithm function that log(1 + x)
when x is small is approximately equal to x. To see this, write out the Taylor
expansion of log(1+x):
log(1 + x) = x −1
2 x2 + 1
3 x3 −· · ·
When x is “small,” the terms involving squares, cubes, etc. are even smaller and
can be ignored, so x remains the only term that is signiﬁcant.
10. Most bonds traded in the United States pay coupons semiannually. To value
them, one uses the same formula, but divides the annual coupon rate and the
applicable discount rate by 2. For example, if the bond in this example paid a
$10 coupon semiannually with term to maturity of three years, we would divide

Important Finance Concepts
49
the interest rate of 6% by two (it becomes 3%), and ﬁnd the present value of
six cash ﬂows of $5 (=$10/2). The value of the bond would be
5
(1 + 0.03) +
5
(1 + 0.03)2 +
5
(1 + 0.03)3 +
5
(1 + 0.03)4 +
5
(1 + 0.03)5
+
105
(1 + 0.03)6 = $110.80.
Note that a semiannual interest rate of 3% is not equivalent to an annual rate
of 6% because of the effects of compounding. However, the convention in the
bond market is to quote annual interest rates that are just double the semiannual
interest rates, so this bond value calculation is technically correct.
11. Convex functions are discussed in more detail in Chapter 5. See Exhibit 5.3 in
Chapter 5 for a picture of a convex function.
12. As mentioned earlier, we assume that st is quoted as a yearly rate.
13. The 6-month and 1-year Treasury securities (called Treasury bills) are issued as
zero-coupon instruments. The longest maturity for Treasury bonds is 30 years.
14. Bootstrapping can be a confusing term because it has completely different mean-
ings in ﬁnance and simulation. We will discuss the statistical concept of boot-
strapping in section 3.11.3.
15. See Chapter 6 in Fabozzi (2007) for an illustration of the bootstrapping proce-
dure.
16. This is an example of a no-arbitrage argument: if two investments have the same
cash ﬂows and the same risk, they should have the same return; otherwise there
would be an arbitrage opportunity. We will discuss the concept of arbitrage in
Chapter 13.
17. A strategy that reduces or eliminates risk is called hedging. We will discuss
hedging in more detail in section 13.2.2.
18. Interest rate derivatives are discussed in Chapters 13, 14, and 16.
19. Such securities are discussed in Chapter 15.
20. The intuition is mostly mathematical—convexity represents a quadratic ap-
proximation to the relative curvature at a given point of the price-yield curve,
whereas duration represents a linear approximation. In effect, we are construct-
ing the Taylor series of the bond price around a speciﬁc point of the price-yield
curve, and considering the ﬁrst two terms in the approximation.
21. See, for example, Ho (1999).
22. As we will see later, a more advanced form of scenario analysis is simulation,
which will be the focus of this book. We will see applications of simulation in
ﬁxed income in particular in Chapters 14, 15, and 16.


CHAPTER3
Random Variables, Probability
Distributions, and Important
Statistical Concepts
T
o deal with risk, we need a way to model the uncertainty in the world
around us. Mathematically, information about uncertainty can be sum-
marized in probability distributions. This chapter reviews the concepts of
random variables, discrete and continuous probability distributions, distri-
bution summary measures, and an important law in statistics called the
Central Limit Theorem. We focus on probability distributions that are most
widely used in ﬁnancial applications.
3.1
WHAT IS A PROBABILITY DISTRIBUTION?
A natural way to think of uncertainty is in terms of scenarios. Scenarios
represent the possible events that could happen. For example, the value of
a stock you own but are contemplating selling may go up (one scenario) or
down (another scenario) one year from now. To these scenarios, you could
assign probabilities, which reﬂect your estimate of the likelihood that the
scenarios will occur. For example, you estimate that the probability that the
stock’s value will go up is 0.30 (30%), and the probability that it will go
down is 0.70 (70%).
The information contained in the scenarios and the probabilities can be
summarized in probability distributions. Basically, probability distributions
are listings of the possible uncertain values and their probabilities. This
information is often presented in graphs—we will see examples later in this
chapter. We will also see that in order to analyze and summarize insights
from probability distributions, we need to have numbers (not categories)
on the horizontal axis of the graph, popularly referred to as the “x-axis.”
Thus, it is not a good idea to create a probability distribution for which the
51

52
FUNDAMENTAL CONCEPTS
random event mentioned in the previous paragraph—that the stock’s value
will go up or down—is plotted because “up” and “down” are not numerical
quantities.
In order to create a probability distribution, we need to assign numerical
values to the uncertain outcomes. Let us think of the outcome “up” as a 1,
and of the outcome “down” as a 0. Such mapping of events to numerical
values is called a random variable. The term is actually a misnomer because
random variables are neither random nor variables. They are numerical
representations, or, equivalently, function assignments, of the outcomes of
uncertain events to numbers. Probability distributions are plots of distribu-
tions of random variables, and do not necessarily map one-to-one to a list
of outcomes.
Note, by the way, that the two probabilities of the two scenarios for
the movement of the value of the stock add up to 1 (100%). This is because
we assume that only one of the two events can happen (so, for example,
the stock’s value cannot stay the same), which means that the two scenarios
exhaust the possible states of the world, and thus should add up to 100%.
This is a general feature of probability distributions—the probabilities of
all the values of the random variable in the probability distribution must
add up to 1, or 100%. We should not specify a probability distribution in
which they do not add up to 1. For example, if we wanted to add a third
scenario—say, that the value could of the stock stays the same—then we
would need to reassign probabilities to the three scenarios in such a way
that the total sum of the probabilities remains 1.
3.2
BERNOULLI PROBABILITY DISTRIBUTION AND
PROBABILITY MASS FUNCTIONS
Exhibit 3.1 shows the probability distribution we described in the previous
section when there are two scenarios. It is in fact a special kind of distribu-
tion, and has a name because it is used so often—the Bernoulli distribution.
The random variable that follows this distribution (the random variable
takes values 0 and 1) is called the Bernoulli random variable. Let us call this
random variable ˜X. Notice that a tilde sign (∼) js placed over the X. The
tilde sign is used to denote uncertainty and randomness.
We can describe one possible distribution of type Bernoulli as
P( ˜X = 0) = 0.70,
P( ˜X = 1) = 0.30.
We read a mathematical statement of this kind as “the probability that
the random variable ˜X takes a value of 0 is 0.70 or 70%.” This listing of

Random Variables, Probability Distributions, and Important Statistical Concepts
53
0
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
X
Probability
EXHIBIT 3.1
Bernoulli distribution with p = 0.3.
values of the random variable and the associated probabilities is called the
probability mass function (PMF). It only exists for random variables that
take discrete (countably many) values, that is, that have discrete probability
distributions. More generally, given a probability p, the PMF for a Bernoulli
distribution is
p( ˜X = x) =
1 −p,
x = 0
p,
x = 1 .
We used x inside the parentheses to signal that this is the realization
of the random variable ˜X, not the random variable ˜X itself (which is a
function). x is a speciﬁc value ˜X takes.
The graph in Exhibit 3.1 corresponds to the preceding probability listing
as follows: there is a bar at each of the values the random variable can take
(0 and 1), and the height of the bar equals the probability that the speciﬁc
value for the random variable occurs. The heights of all bars in the graph
add up to 1.
3.3
BINOMIAL PROBABILITY DISTRIBUTION AND
DISCRETE DISTRIBUTIONS
Now suppose that you would like to model whether the value of the stock
will be up or down in three years. Every year, it can go up with probability

54
FUNDAMENTAL CONCEPTS
Time 0
Time 1
(trial 1)
2 outcomes
Time 2
(trial 2)
4 outcomes
Time 3
(trial 3)
8 outcomes
Up
V0
1
0
1,1
1,1,1
0,0,0
1,1,0 or
1,0,1
0,1, 0 or
0,0,1
1,0 or 0,1
0,0
Down
Up
Down
Up
Down
Up
Down
Up
Down
Up
Down
EXHIBIT 3.2
Movement of stock’s value over three years: “1” =
“success” (stock’s value goes up). At the end of three years, we can
have three successes in a row, two successes out of three, one
success out of three, or no successes. The (0,1) combinations in the
tree show the order of the successes or the failures up to that point
in time.
0.30, and down with probability 0.70. Let the speciﬁc realizations of this
Bernoulli random variable for each of the three years be X1, X2, and X3.1
We can visualize the movement of the stock value from the tree drawn in
Exhibit 3.2. (Keep this picture in mind, as variations of it will appear again
and again in ﬁnancial instrument pricing applications.) For example, when
X1 = 1, X2 = 1, and X3 = 1, the movement in all three years is “up” and
the stock’s value will be at its highest.
Since you would like to sell the stock for as much money as you can,
let us call the event of the value of the stock going up in any particular
year a “success.” Assume that the success in one year is independent of
the success in another year, and let us count the number of successes out
of the three possible times. This is going to be an uncertain quantity. The
probability distribution of the number of successes in a preﬁxed number
of trials is called the binomial distribution. In our example, the number of
trials is three because in each of the three years there is a chance that the
trial will be a “success” (the stock’s value will go up) or a “failure” (the
stock’s value will go down). Note that the Bernoulli distribution is in fact a
special case of the binomial distribution, in which the number of trials is 1.

Random Variables, Probability Distributions, and Important Statistical Concepts
55
The binomial distribution is very important and widely used in a variety of
applications—from statistical analysis of polling results to modeling prices
of ﬁnancial securities and evaluating the economic prospects of a capital
budgeting project.
To be mathematically speciﬁc, the binomial distribution can be used
when the following four conditions are satisﬁed:
1. The number of trials is ﬁxed in advance.
2. There can be only two outcomes (success and failure).
3. Success in each trial is independent of the result of the previous trial.
4. The probability of success remains the same from trial to trial.
Perhaps the easiest way to envision whether applying the binomial dis-
tribution is appropriate is to think of whether the situation under evaluation
is equivalent to a sequence of coin ﬂips with the same coin, in which we are
interested in the probability that we get a given number (x) of tails in n ﬂips.
Suppose we would like to plot the binomial distribution of the random
variable describing the price movements of the stock over the next three
years. What would be the values on the x-axis? The values for the random
variable can be 0, 1, 2, or 3—the number of successes can be either 0 (the
stock’s value went down every year), 1 (the stock’s value went down in one
of the three years, but went up in the remaining two), and so on. We will
denote the random variable by ˜X, but note that this is not the same random
variable as the random variable in section 3.2. In order to create the listing
of probabilities, we compute:
P( ˜X = 0) = (0.70) · (0.70) · (0.70) = 0.343 = 34.3%
P( ˜X = 1) = (0.30) · (0.70) · (0.70) + (0.70) · (0.30) · (0.70)
+(0.70) · (0.70) · (0.30) = .441 = 44.1%
P( ˜X = 2) = (0.30) · (0.30) · (0.70) + (0.70) · (0.30) · (0.30)
+(0.30) · (0.70) · (0.30) = .189 = 18.9%
P( ˜X = 3) = (0.30) · (0.30) · (0.30) = 0.027 = 2.70
Therefore, the distribution can be represented as the graph in Exhibit 3.3.
To clarify why the probabilities were computed in the way just illus-
trated, note that there is only one way to have three successes in three trials
( ˜X = 3): when every trial is a success. The probability of this event is the
product of the probabilities that each of the three trials is a success. (The

56
FUNDAMENTAL CONCEPTS
0
1
2
3
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
Probability
Y
EXHIBIT 3.3
Binomial distribution with n = 3 trials and p = 0.30
probability of success.
multiplication of probabilities to obtain the total probability is permitted
because the trials are assumed to be independent.) However, there are three
ways to have one success in three trials: The success can be in the ﬁrst, sec-
ond, or third trial. To account for these different combinations, we can use
the following well-known formula from the branch of mathematics called
combinatorics (sometimes called the science of counting):
n!
x!(n −x)!.
The preceding formula computes the number of ways in which one
can select x out of n objects. The symbol “n!” (pronounced “n factorial”)
stands for the expression 1 · 2 · . . . · n. The exact formula for computing
the probability of obtaining x successes in n trials when the probability of
success is p (in our example, p = 0.30) is
P( ˜X = x) =
n!
x!(n −x)! px(1 −p)n−x, x = 0, . . . , n

Random Variables, Probability Distributions, and Important Statistical Concepts
57
0
1
2
3
4
5
6
7
8
9 10
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0
1
2
3
4
5
6
7
8
9
10
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0
1
2
3
4
5
6
7
8
9
10
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
(C)
(B)
(A)
EXHIBIT 3.4
Shape of binomial distributions with the same number of trials
(n = 10) and different values for the probability of success p: (A) p = 0.3; (B) p =
0.5; (C) p = 0.7.
This is the PMF of the binomial distribution, and is the formula software
packages use to compute the binomial distribution probabilities. Note that
depending on the magnitude of the probability of success, the binomial
distribution can be shaped differently. Exhibit 3.4 illustrates the binomial
distribution for three different values of the probability of success.
3.4
NORMAL DISTRIBUTION AND PROBABILITY
DENSITY FUNCTIONS
The binomial distribution is a discrete probability distribution because the
values the random variable can take are countable (0, 1, 2, etc.). Let us see
what happens if we try to model the movements of the stock in 100 years.

58
FUNDAMENTAL CONCEPTS
0
1
2
3
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
–5
0
5
10
15
20
25
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
–20
0
20
40
60
80
100
120
0
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
0.09
(C)
(B)
(A)
EXHIBIT 3.5
Shape of binomial distributions with the same probability of success
p = 0.3 and an increasing number of trials n: (A) n = 3; (B) n = 20; (C) n = 100.
Exhibit 3.5 shows the binomial distribution for probability of success of
0.30 and number of trials n = 3, 20, and 100.
Note that the binomial distribution begins to look symmetric as the
number of trials increases. Also, the range of values begins to look like a
continuum. When the random variable takes values on a range, as opposed
to at discrete points, the random variable is called continuous, and its proba-
bility distribution is called continuous as well. Continuous distributions are
deﬁned by their probability density functions (PDFs)—basically, functions
that describe the shape of the curve on the graph. They are often denoted by
the standard mathematical notation for functions, f(x), where x represents
the possible values the random variable can take.
A common mistake is to think of f(x) as the probability that the random
variable will take the value x, analogously to the way we deﬁned the PMF

Random Variables, Probability Distributions, and Important Statistical Concepts
59
p(x). This is incorrect. In fact, the value of f(x) may be greater than 1, which
a probability cannot be. Instead, we need to think about probabilities for
continuous distributions in terms of areas under a curve that describes the
probability distribution. Intuitively, the reason continuous distributions are
associated with areas under the PDF f(x) is that a continuum represents an
inﬁnite number of values that the random variable can take. If we try to
assign a bar whose height equals a nonzero probability to each value the
random variable can take, as we did in the case of the binomial distribution,
the total sum of all bars (and, hence the total probability for that distribution)
will be inﬁnity. However, the total probability, added up over all possible
values for the random variable, cannot be more than 1.
Consequently, a better way to think of the probability of each particular
value of the random variable is as inﬁnitely small (virtually, 0), but then
realize that when many, many of these values are added together, they
have a signiﬁcant probability mass. This is the concept of integration in
calculus. The area under a given curve can be computed by adding up an
inﬁnite number of tiny areas above intervals of length dx on the x-axis. The
probability that a continuous random variable takes values between two
constants a and b can be expressed as the integral
b

a
f (x) dx,
and the total probability (the area under the entire curve) should be 1:
∞

−∞
f (x) dx = 1.
It turns out that the binomial distribution approaches a very important
continuous distribution, called the normal distribution, as the number of
trials becomes large. The normal distribution is bell-shaped and is entirely
deﬁned by two parameters: its mean µ and standard deviation σ. This means
that if we know them, we can draw the shape of the distribution. (We will
introduce the concepts of mean and standard deviation shortly. For now,
just think of µ and σ as inputs to the formula for the normal distribution
PDF.) This is because the normal PDF is given by the formula
f (x) =
1
σ
√
2π
e−(x−µ)2
2σ2 .

60
FUNDAMENTAL CONCEPTS
–5
–4
–3
–2
–1
0
1
2
3
4
5
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
x
PDF
EXHIBIT 3.6
Standard normal distribution.
The standard normal distribution has µ = 0 and σ = 1 (see Exhibit 3.6).
You may also encounter the notation f (x|µ, σ), that is,
f (x|µ, σ) =
1
σ
√
2π
e−(x−µ)2
2σ2 .
The symbol | stands for “conditional on” or “given.” In other words,
given speciﬁc values for µ or σ, the PDF for the normal distribution is given
by the preceding formula. The symbol | will be useful in other circumstances
as well, such as stating the PDF of a random variable conditional on the
realization of another random variable. For example, the probability distri-
bution of asset returns in one time period may depend on (“be conditional
on”) the realization of asset returns in the previous time period. We will
provide a more formal deﬁnition of conditioning in section 3.10.
The normal distribution appears surprisingly often in nature and was
studied in detail well before its prominent use in ﬁnance. Modern day ran-
dom process modeling in ﬁnance has borrowed a lot of ﬁndings from natural

Random Variables, Probability Distributions, and Important Statistical Concepts
61
sciences such as physics and biology. For example, a classical assumption in
modeling asset returns is that the changes in asset prices over small periods
of time are normally distributed (despite the fact that the empirical evidence
from real-world markets does not support the position that changes in asset
returns follow a normal distribution). We will use the normal distribution
extensively in this book.
The binomial and the normal distributions are famous representatives of
the two classes of probability distributions: discrete and continuous. How-
ever, there are numerous other useful probability distributions that appear
in practice. We will review some of these distributions later in this chap-
ter. But ﬁrst, let us introduce a couple of important concepts for describing
probability distributions.
3.5
CONCEPT OF CUMULATIVE PROBABILITY
Cumulative probability is the probability that a random variable takes a
value that is less than or equal to a given value. Cumulative probability is
an important concept, and is available as a function from a number of soft-
ware packages, including Excel and MATLAB. The cumulative distribution
function (CDF) can be thought of as a listing of the cumulative probabilities
up to every possible value the random variable can take. Examples of CDFs
for a continuous and a discrete distribution are shown in Exhibit 3.7. The
CDFs always start at 0 and end at 1, but the shape of the curve on the
graph is determined by the PDF or PMF of the underlying random variable.
(The CDF for a discrete random variable has a characteristic staircase-like
shape—i.e., “step function” in mathematical jargon.)
1.0
0.8
0.6
0.4
0.2
0.00
1
2
3
4
5
6
7
1.0
0.8
0.6
0.4
0.2
0.0
0
–1
1
2
3
4
5
6
7
8
9
10
(A)
(B)
EXHIBIT 3.7
The CDF of (A) a continuous random variable (lognormal), and
(B) a discrete random variable (binomial with 10 trials and probability of success
0.30). The values on the horizontal axis are the values the random variable takes.

62
FUNDAMENTAL CONCEPTS
To show how one would compute cumulative probability for a dis-
crete distribution, let us consider the binomial distribution example from
section 3.3, which is also the CDF plotted in Exhibit 3.7(B).
Suppose that the probability of success is 0.30, and we would like to
compute the probability that the number of successes in 10 trials will be at
most six. Intuitively, we are trying to estimate the total height of the ﬁrst six
bars in the ﬁrst picture in Exhibit 3.4(B). We can write this expression as
P( ˜X ≤6) = P( ˜X = 1) + · · · + P( ˜X = 6)
=
10!
1!(10 −1)!0.301(1 −0.30)10−1 + · · ·
+
10!
6!(10 −6)!0.306(1 −0.30)10−6
=
6

k=1
10!
k!(10 −k)!0.30k(1 −0.30)10−k
where we have used the classical symbol  for sum.
To construct the entire CDF, we would perform the same calculation
for all possible values of ˜X, that is, compute P( ˜X ≤0), P( ˜X ≤1), . . . ,
P( ˜X ≤10). We would then plot ˜X on the x-axis, and the corresponding
P( ˜X ≤x) on the vertical axis (by convention referred to as the y-axis).
For continuous distributions, we would replace the sum by an integral,
and ﬁnd the area under the PDF that is less than or equal to a given constant.
For example, if f(x) is the PDF of a continuous probability distribution (such
as the normal distribution and other distributions such as t, chi-square, and
exponential distributions that we describe later), then the CDF (usually
denoted by F(x)) can be computed as
F(x) = P( ˜X ≤x) =
x

−∞
f (x) dx.
Further, the probability that a random variable takes values between
two constants a and b can be linked to the CDF as follows:
P(a ≤˜X ≤b) =
b

a
f (x) dx = F(b) −F(a).
To illustrate this, let us look at the picture in Exhibit 3.8. Suppose we
would like to compute the probability that the random variable takes a value

Random Variables, Probability Distributions, and Important Statistical Concepts
63
0.030
39.9%
–20
0
20
40
60
80
100
120
140
45.7%
14.4%
20.0
60.0
0.025
0.020
0.015
0.010
0.005
0.000
EXHIBIT 3.8
Calculation of the probability that the random variable
falls between 20 and 60 as a difference of cumulative probabilities up to
20 and 60.
between 20 and 60 (which is the area under the PDF between 20 and 60,
and is 45.7% according to the picture). To compute that probability, we can
equivalently compute the cumulative probability (the area) up to 20 (which
is 39.9% according to the picture) and subtract it from the cumulative
probability (the area) up to 60 (which is 100% −14.4% = 85.6%). We
obtain F(60) – F(20) = 85.6% −39.9% = 45.7%, which is the same number.
3.6
DESCRIBING DISTRIBUTIONS
A probability distribution can be used to represent the uncertain outcomes of
a project, or the possible future value of an investment in an asset. But what
does the picture of this probability distributions tell us, and how can we
convey the most important insights to others? This section introduces math-
ematical terminology for describing probability distributions. Speciﬁcally,
the graph of a probability distribution gives us information about:
■Where the most likely or most representative outcomes are (central
tendency).
■Whether we can be optimistic or pessimistic about the future (skew).
■What the risk is (spread and tails of the distribution).

64
FUNDAMENTAL CONCEPTS
Finance practitioners are also often concerned with how “fat” the tails
of the distribution are—which tells us how likely it is that “extreme” events,
that is, events that are very far from the “representative” outcomes in the
middle of the distribution, will occur. We will discuss a measure of this
distribution characteristic (kurtosis) in section 3.6.4.
3.6.1
Measures of Central Tendency
Measures of central tendency include:
■Mean
■Median
■Mode
The mean is by far the most commonly utilized measure in ﬁnancial
applications for theoretical reasons, despite the fact that it has some serious
drawbacks, most notably sensitivity to extreme values. We discuss the mean
in the most detail, and review brieﬂy the other two measures.
Mean
On an intuitive level, the mean (also called the “expected value”
or the “average”) is the weighted average of all possible outcomes in the
distribution, where the weights equal the probabilities that these values are
taken. This is easier to imagine in the case of discrete distributions than in
the case of continuous distributions, but the main idea is the same.
In mathematical jargon, the mean is called the ﬁrst moment of a proba-
bility distribution.2 It is denoted as E[ ˜X] (for “expected value of the random
variable ˜X”).
In the case of a discrete distribution,
E[ ˜X] =

All values x of the random variable
x · P( ˜X = x).
In the case of a continuous distribution,
E[ ˜X] =
∞

−∞
x · f (x) dx.
For example, the mean of the Bernoulli distribution in section 3.2 is
0 · 0.70 + 1 · 0.30 = 0.30

Random Variables, Probability Distributions, and Important Statistical Concepts
65
The mean of a normal distribution can be computed as
E[ ˜X] =
∞

−∞
x ·
1
σ
√
2π
e−(x−µ)2
2σ2 dx
In the case of the normal distribution, of course, this calculation is
redundant since the parameter µ in the expression inside the integral is ac-
tually the mean. However, the mean is not a parameter in the PDF formulas
for most probability distributions, and this is the calculation that would be
used to compute it. To practice, you can compute the preceding integral,
and verify that the calculation indeed gives µ as the answer.
As a ﬁnal remark, we note that the mean is not always the “middle
point” of the range of the distribution. (We will see ample examples in this
book.) One outlier (that is, one value for the random variable that is very
far from the others) can shift the mean signiﬁcantly. Note also that the
mean does not have to be one of the values of the probability distribution,
as the previous Bernoulli example illustrated. (The mean for the Bernoulli
distribution was 0.30, which is not 0 or 1.) The mean is merely the “center
of gravity” of the probability distribution.
Median
The median is a more robust measure of the “middle” of the
distribution. It is the value on the horizontal so that 50% of the distribution
lies on each side of it. Since the median does not take into consideration
where the values on each side of it lie (as opposed to the mean, which
considers the actual values and their probabilities of occurrence), the median
is not as inﬂuenced by the presence of extreme values (values that are very
far from the center of the distribution) as the mean.
Mode
The mode of a distribution is the most likely outcome. One can think
of it as the value at which the PDF/PMF of the distribution is at its highest.
For example, in Exhibit 3.4, the mode of the ﬁrst binomial distribution
is 3, the mode of the second distribution is 5, and the mode of the third
distribution is 7.
You may hear about “unimodal” or “bimodal” distributions. These
terms basically just refer to how many “peaks” the distribution has. Almost
all theoretical distributions used in ﬁnancial modeling are unimodal, as their
properties are easier to model mathematically. The distributions we have
introduced so far, for example, are unimodal. Of course, real-world data
do not always follow neat mathematical rules, and may present you with
distributions that have more than one mode.

66
FUNDAMENTAL CONCEPTS
3.6.2
Measures of Risk
Variance and Standard Deviation
When thinking of risk, one usually
thinks of how far the actual realization of an uncertain variable will fall
from what one expects. Therefore, a natural way to deﬁne a measure of un-
certainty is as the spread, or dispersion of a distribution. Two measures that
describe the spread of the distribution are variance and standard deviation.
The two are strongly related: the standard deviation is the square root of the
variance, and we usually need to compute the variance before computing the
standard deviation. Exhibit 3.9 illustrates the relationship between variance/
standard deviation and the spread of the distribution. Suppose we are con-
sidering investing in two assets, A and B. The probability distribution for B
has a wider spread and higher variance/standard deviation than the proba-
bility distribution for A.
Mathematically, the variance of a random variable is related to the
second moment of a probability distribution, and is computed as follows:
For discrete distributions:
Var( ˜X) =

All values x of the random variable
(x −µ)2 · P( ˜X = x)
−100
−80
−60
−40
−20
0
20
40
60
80
100
0
0.005
0.01
0.015
0.02
0.025
0.03
0.035
0.04
Return (%)
B
A
EXHIBIT 3.9
Comparison of two probability distributions in terms of risk and
central tendency.

Random Variables, Probability Distributions, and Important Statistical Concepts
67
For continuous distributions:
Var( ˜X) =
∞

−∞
(x −µ)2 · f (x) dx
In the preceding equations, µ denotes the mean of the distribution.
In words, the variance is the sum of the squared deviations of all values
in the probability distribution from the mean (used as a measure for the
center) of the distribution. The reason why squared deviations are used is
so that deviations to the left of the mean do not cancel deviations to the
right of the mean when added together.3 Otherwise, a distribution that has
many observations far from the center and, therefore, has a large “spread,”
may end up with the same variance as a distribution with values very close
to the mean and a small spread. In fact, a distribution that has a very wide
spread may end up with a variance of zero if all large positive deviations
from the mean have corresponding large negative deviations. This would
make variance useless as a measure of spread.
Sometimes, a more convenient (and equivalent) way of expressing the
variance is through the equation
Var( ˜X) = E[ ˜X2] −

E[ ˜X]
2
=

All values x
x2 · P( ˜X = x) −


All values x
x · P( ˜X = x)
2
(in the discrete case)
=
∞

−∞
x2 · f (x) dx −
⎛
⎝
∞

−∞
x · f (x) dx
⎞
⎠
2
(in the continuous case)
These expressions link the variance explicitly to the ﬁrst and the second
moments of the distribution.
The variance of a distribution measures the spread in square units of
the random variable, and the number is difﬁcult to interpret. The standard
deviation is widely used instead. The standard deviation simply takes the
square root of the variance (σX =

Var( ˜X)), and presents a measure of the
average deviation of the values in the distribution from the mean that has
the same units as the random variable, hence making it easier to interpret.
In the ﬁnancial context, standard deviation is often used interchangeably
with the term “volatility.”

68
FUNDAMENTAL CONCEPTS
Coefficient of Variation
Let us consider again the picture in Exhibit 3.9.
We mentioned that the probability distribution for A has a smaller standard
deviation than the probability distribution for B, but notice also that the
mean of the distribution for A is lower than the mean for the distribution
for B. If you had to invest in one of them, which one would you choose?
This situation brings up the idea of measuring spread (the “risk” of the
distribution) relative to the mean (the “representative” value of the distribu-
tion). This is the statistical concept of coefﬁcient of variation (CV), which is
reported in percentages, and is mathematically expressed as
CV = σ
µ × 100,
where µ is the mean and σ is the standard deviation of the distribution. The
CV gives us a unit-free ratio that can be used to compare random variables.
If the CV for investment A is 70% and the CV for investment B is 50%, we
may decide that investment A is more “risky” than B relative to the average
return we can expect, even though investment A has the smaller standard
deviation.
CV represents the trade-off between expectation and risk from the sta-
tistical point of view. In ﬁnance, the inverse ratio is often used (that is,
instead of the amount of risk per unit of expected reward, one looks at the
expected reward per unit of risk). The ﬁnancial measure became popular
based on work by Sharpe (see, for example, Sharpe 1994). We will talk
about the Sharpe ratio in the context of portfolio optimization in Chapter 7.
The main idea behind using both measures, however, is the same.
Range
The range of a random variable is the difference between the maxi-
mum and the minimum value a random variable can take. It can sometimes
be used as a measure of “riskiness”; however, be on alert that it is not
applicable in many situations. For example, some important probability dis-
tributions, such as the normal distribution, have an inﬁnite range, as the
random variables can take values from negative inﬁnity to positive inﬁnity.
You should also be extremely careful when using range in the context of
simulation. We will discuss this issue further in Chapter 4.
Percentiles
Another useful term for describing distributions is the per-
centile. The α-percentile of a distribution is the number on the x-axis so
that a percentage α of the total probability lies to the left of that number.
Probability distributions can be compared by their percentiles: for example,
if the 5th percentile of the distribution for investment B in Exhibit 3.9 is less
than the 5th percentile of the distribution for investment A, we may argue

Random Variables, Probability Distributions, and Important Statistical Concepts
69
that investment B is more risky than investment A because it will result in
a lower outcome than investment A with 5% probability. We will use per-
centiles extensively in the context of analyzing simulation results (Chapter 4)
and portfolio risk management (Chapter 8).
3.6.3
Skew
Distributions can be symmetric or asymmetric (skewed), depending on
whether the “tails” at the two ends of the distribution are the same or
different. Whether distributions are further classiﬁed as left-skewed (neg-
atively skewed) or right-skewed (positively skewed) basically depends on
where the mean is relative to the median. Symmetric distributions have the
same mean and median, whereas left-skewed distributions have a longer left
tail (which implies that the mean is to the left of the median, as it has been
skewed by extreme values). There are several rather involved deﬁnitions that
are used to represent skew mathematically, and it is beyond the scope of the
book to present them here. The important thing to note is that all of the
formulas for skew use the third moment of a probability distribution, and
agree on the intuitive deﬁnition of skew: that left skew means longer left tail,
whereas right skew means longer right tail. The normal distribution, which
is symmetric, has a skew of 0.
3.6.4
Kurtosis
In ﬁnance, we are frequently interested in the behavior in the “tails” of
a distribution. If the tails are “fat,” this means that extreme observations
are more likely to happen, and expected values are not as useful. Kurtosis
measures the “fatness” of the tails of a distribution. The normal distribution,
which is used as the standard for comparison, has a kurtosis of 3. A kurtosis
of more than 3 (in general, high value for kurtosis) means that the probability
distribution has fatter tails and a sharper peak than the normal distribution,
whereas a low value for kurtosis means that the tails are “leaner” than the
tails of the normal distribution.4 The mathematical formula for kurtosis, just
as the formula for skew, is rather involved, but the important thing to note
is that kurtosis is related to the fourth moment of a probability distribution.
3.7
BRIEF OVERVIEW OF SOME IMPORTANT
PROBABILITY DISTRIBUTIONS
This section lists some additional important probability distributions, their
PMFs/PDFs, and summary measures. For an overview of these and other

70
FUNDAMENTAL CONCEPTS
probability distributions and how they arise in practice, see, for example,
Evans, Hastings, and Peacock (2000).
3.7.1
Discrete Distributions
We have already discussed two discrete distributions, the binomial distri-
bution and the Bernoulli distribution. Next we discuss two other discrete
distributions: the discrete uniform distribution and the Poisson distribution.
Other interesting discrete distributions that will not be covered here are the
geometric distribution, hypergeometric distribution, and negative binomial
distribution.
Discrete Uniform Distribution
The discrete uniform distribution repre-
sents a situation in which a random variable can take a prespeciﬁed number
of discrete values, and each value has an equal chance of occurring. A simple
example of such distribution is a roll of a fair die: There are six possible out-
comes, 1, 2, 3, 4, 5, 6, and each of them happens with the same probability
(see Exhibit 3.10).
It can be easily seen that if the random variable can take N values
and if the total probability needs to be 1, then the probability of each
1
2
3
4
5
6
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
x
PMF
EXHIBIT 3.10
Discrete uniform distribution.

Random Variables, Probability Distributions, and Important Statistical Concepts
71
individual value should be 1/N. Therefore, the PMF of the discrete uniform
distribution is
P( ˜X = x) = 1
N.
The discrete uniform distribution is very useful in a variety of appli-
cations, and we will encounter it again, for example, when learning about
sampling by bootstrapping in Chapter 8.
Poisson Distribution
The Poisson distribution applies in situations in
which one is concerned about the probability of having a given number
of arrivals in a prespeciﬁed time interval, where these arrivals are assumed
to be independent of one another. It is widely used for modeling jumps in
electricity prices (referred to as “spikes,” because prices typically return to
their original levels), and in credit risk modeling because defaults or other
credit-related events can be modeled as “arrivals” in a random process.5 We
will see applications in Chapter 12.
The Poisson PMF is given by
f (x) = λx
x! e−λ.
It requires an input parameter, λ, that corresponds to the average number
of arrivals during the time period.
A picture of a Poisson distribution with λ = 5 is shown in Exhibit 3.11.
You can imagine incorporating the distribution into a model for the process
followed by the price of electricity, in which the price spikes on average ﬁve
times per day because of transmission constraints or unexpected outages.
The Poisson distribution in the picture is slightly skewed, which means that
the probability that fewer than ﬁve spikes occur in a day is slightly more
than the probability that more than ﬁve spikes occur in a day.
The Poisson distribution has a number of interesting properties. No-
tably, it looks very much like a binomial distribution if the number of trials
in the binomial distribution is large, and the probability of success at ev-
ery trial is adjusted so that the probability of success remains constant as
the number of trials grows large. More precisely, a binomial random vari-
able with number of trials n and probability of success λ/n at every trial
approaches a Poisson distribution with parameter λ as n grows large.
Furthermore, the Poisson distribution looks like the normal distribution
if the parameter λ (mean arrivals per unit time) grows large. In fact, the
effect is noticeable for λ as small as 20 arrivals. (Plot the distribution with

72
FUNDAMENTAL CONCEPTS
–2
0
2
4
6
8
10
12
14
16
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
x
PDF
EXHIBIT 3.11
Poisson distribution with λ = 5.
@RISK or MATLAB to see its shape.) As λ increases, the Poisson distribution
approaches a normal distribution with mean λ and standard deviation
√
λ.
3.7.2
Continuous Distributions
In addition to the normal distribution that we described earlier, the contin-
uous distributions that we review are the
■Continuous uniform distribution
■Triangular distribution
■Student’s t-distribution
■Lognormal distribution
■Exponential distribution
■Chi-square distribution
■Beta distribution
Other interesting continuous distributions that are not discussed here
are gamma (Erlang) distribution, Cauchy distribution, and Gumbel (Extreme
Value) distribution.

Random Variables, Probability Distributions, and Important Statistical Concepts
73
Continuous Uniform Distribution
The continuous uniform distribution
represents a situation in which a random variable can take a continuum
of values on a range (say, between two numbers a and b) with equal prob-
ability. This distribution presents a simple example of why the value of the
PDF f(x) at a point x should not be treated as the probability of x. Since the
total probability mass under the PDF needs to be 1, the height of the line on
the graph of the uniform distribution (that is, the value of the PDF at each
point on the range [a,b]) is 1/(b – a). This number can be greater than 1,
depending on the values of a and b, which is not allowed for a probability.
For example, if a is 3 and b is 3.5, then (b – a) = 0.5, and the PDF f(x) at
any point x between 3 and 3.5 is 1/0.5 = 2 (see Exhibit 3.12(A)).
To summarize, the PDF of the continuous uniform distribution is
f (x) =
1
b −a ,
a ≤x ≤b.
The “standard” continuous uniform distribution on the interval [0,1]
(that is, when a = 0 and b = 1) plays a very important role in simulation.
We will come back to it in Chapters 4 and 14.
Triangular Distribution
The triangular distribution is a simple distribu-
tion with wide applications in capital budgeting, marketing, and decision
analysis. It is often used when we do not have very much information about
2.9
3
3.1
3.2
3.3
3.4
3.5
3.6
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
x
PDF
(A) 
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
x
PDF
(B) 
EXHIBIT 3.12
Examples of continuous uniform distributions: (A) on the interval
[3, 3.5]; (B) on the interval [0, 1].

74
FUNDAMENTAL CONCEPTS
0
0.5
1
1.5
2
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
x
PDF
EXHIBIT 3.13
Triangular distribution.
the underlying distribution, but can specify a worst-case scenario (1), a best-
case scenario (2), and a most likely scenario (3). Exhibit 3.13 shows an
example of a triangular distribution. Its PDF outlines a triangle, and the
triangle does not need to be symmetric. The PDF is given by
f (x) =
⎧
⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎩
2(x −a)
(b −a)(c −a)
for a ≤x ≤c
2(b −x)
(b −a)(b −c)
for c ≤x ≤b
0
otherwise
.
Student’s
t -Distribution
The
Student’s
t-distribution
(or
simply
t-
distribution) looks very much like the normal distribution in shape, but
the weight in the tails is determined by a parameter ν (associated with de-
grees of freedom in statistics).6 Examples t-distributions for different values
of are given in Exhibit 3.14. The PDF for the t-distribution is
f (x) =

ν + 1
2


ν
2

1
√νπ
1

1 + x2
ν
 ν+1
2 ,

Random Variables, Probability Distributions, and Important Statistical Concepts
75
–6
–4
–2
0
2
4
6
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
x
PDF
2 DoF
8 DoF
30 DoF
EXHIBIT 3.14
Examples of t-distributions for different degrees of freedom.
where  (y) is the so-called gamma function ( (y) =
∞
0
ty−1e−tdt).
The t-distribution arises in some very important applications in
statistics, in particular, in calculating conﬁdence interval estimates for the
true mean of a distribution and hypothesis testing (see sections 3.11.2 and
3.11.4). Since simulation bears strong resemblance to statistical sampling,
we will encounter the t-distribution when we discuss simulation in the next
chapter.
Lognormal Distribution
The lognormal distribution has one of the most
prominent uses in modern ﬁnance. It arises when values for the random vari-
able cannot be negative, and tend to be asymmetrically distributed, which
has been observed for stock prices and real estate prices (see Exhibit 3.15).
The PDF of the lognormal distribution is
f (x) =
1
xσ
√
2π
e−(ln(x)−µ)2
2σ 2
,
x > 0

76
FUNDAMENTAL CONCEPTS
0
1
2
3
4
5
6
7
8
9
10
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
x
PDF
EXHIBIT 3.15
Lognormal distribution.
Note the resemblance to the PDF for the normal distribution from 3.4.
In fact, there is a very direct relationship between a lognormal and a normal
random variable. Speciﬁcally, if ˜Y is a normal random variable with mean
µ and standard deviation σ, then the random variable ˜X = e ˜Y is lognormal
with the PDF above.
Exponential Distribution
The exponential distribution is related to the
Poisson distribution. While the Poisson distribution measures the number
of arrivals in a given period of time (assuming arrivals are independent), the
exponential distribution measures the time between independent arrivals.
The PDF of the exponential distribution is
f (x) = λe−λx,
x ≥0.
In fact, the parameter λ is the same parameter we saw in the deﬁnition
of the Poisson distribution.

Random Variables, Probability Distributions, and Important Statistical Concepts
77
0
5
10
15
20
25
30
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
PDF
t
EXHIBIT 3.16
Exponential distribution with λ = 0.02.
If we expect an average of λ arrivals during a unit time period, then the
average time we would expect between arrivals is 1/λ (which happens to
be the mean of the exponential distribution). A picture of the exponential
distribution is shown in Exhibit 3.16. Note that if we “slice” the distribution
vertically and consider the piece of the curve to the right of the value at
which we sliced, that piece has the same shape as the original distribution.
This is the so-called “memoryless” property of the exponential distribution,
which, counterintuitively, means that the distribution of the time until the
next arrival does not depend on how long you have waited. Speciﬁcally,
if 30 minutes have already elapsed, the probability that you will see an
arrival after 10 minutes is the same as the probability you would have
seen an arrival after 10 minutes at the beginning of the ﬁrst time period of
30 minutes.
Similarly to the Poisson distribution, the exponential distribution is
widely used in credit risk modeling and in high-frequency modeling of
arrival time between orders in ﬁnancial markets (referred to as “trade
duration”).

78
FUNDAMENTAL CONCEPTS
Chi-Square Distribution
The chi-square distribution (often denoted χ2
distribution) is used predominantly in hypothesis testing in statistics. The
reason we list it here, given our focus on ﬁnancial applications, is because
it is the basis for goodness-of-ﬁt tests that decide whether a particular dis-
tribution is appropriate for modeling an observed set of data. The sum of k
independent squared normal random variables follows a chi-square distri-
bution with k degrees of freedom. 7
The PDF of the chi-square distribution is given by
f (x) = 2−k/2
(k/2)xk/2−1e−x/2,
x > 0,
where  is the gamma function, as deﬁned earlier in this section, and k is the
“degrees of freedom.” A picture of the distribution is shown in Exhibit 3.17.
Beta Distribution
The beta distribution is very ﬂexible in terms of shape,
and is useful for representing a variety of models of uncertainty. In contrast
to other distributions that have a distinctive skew, the beta distribution is
0
2
4
6
8
10
x
12
14
16
18
20
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
PDF
EXHIBIT 3.17
Chi-square distribution with ﬁve degrees of freedom.

Random Variables, Probability Distributions, and Important Statistical Concepts
79
–0.2
0
0.2
0.4
0.6
0.8
1
1.2
0
0.5
1
1.5
2
2.5
3
x
PDF
(A) 
–0.2
0
0.2
0.4
0.6
0.8
1
1.2
0
0.5
1
1.5
2
2.5
3
x
PDF
(B) 
EXHIBIT 3.18
Examples of beta distributions: (A) A beta distribution with
parameter values equal to 4 and 6; (B) A beta distribution with parameter values
equal to 6 and 4.
deﬁned by two parameters, α and β, which deﬁne the shape and the skew
of the distribution. The precise formula for the PDF is
f (x) = xα−1(1 −x)β−1
(α)(β)
(α + β)
,
x > 0, α > 0, β > 0.
Exhibit 3.18 illustrates the shape with parameter values equal to 4 and
6, and 6 and 4, respectively. You can observe that the skew of the beta
distribution changes depending on the relative magnitudes of α and β.
3.8
DEPENDENCE BETWEEN TWO RANDOM
VARIABLES: COVARIANCE AND CORRELATION
So far, we have shown how one can describe a single random variable. In
ﬁnance, we often need to worry about the relationships between two or more
variables. For example, in the context of investments, if the return investment
A in Exhibit 3.9 goes up on average, does the return on investment B go up
as well? In capital budgeting, if the value of one project we are considering
goes down, will the value of other projects in the company’s portfolio go
up or down? If we can measure these kinds of relationships, we can, for
example, protect ourselves against extreme situations in which all of our
investments crash simultaneously.

80
FUNDAMENTAL CONCEPTS
Two commonly used measures of codependence between random vari-
ables are covariance, often denoted by Cov, and correlation, often denoted
by the Greek letter rho (ρ). The two are strongly related.
The idea behind covariance is to measure simultaneous deviations from
the means for two random variables, X and Y. If ˜X takes a value above its
mean µX, does ˜Y take a value above its mean µY as well? If it does, then we
would like to increase our measure of covariation to reﬂect a higher degree
of codependence. If the two random variables move in opposite directions
(that is, when one of them takes a value above its mean, the other one takes
a value below its mean), then we would like to subtract from our measure
of covariation. Mathematically, this idea is expressed as
Cov( ˜X, ˜Y) = E
 ˜X −µX
  ˜Y −µY

.
Recall that E stands for “expectation,” or “average.” Thus, the covari-
ance measures whether the two random variables move together on average.
If the covariance is 0, the two variables are independent.
The concept of covariance appears very often in modern portfolio
theory, and we will come back to it in Chapter 8. However, sometimes it is
more convenient to use a normalized form of the expression for covariance—
the correlation coefﬁcient. The problem with covariance is that its units are
products of the original units of the two random variables, so the number
for covariance is difﬁcult to interpret. The correlation coefﬁcient divides the
covariance by the product of the standard deviations of the two random
variables:
ρ = Corr( ˜X, ˜Y) = Cov( ˜X, ˜Y)
σXσY
The result is a value that is always between –1 and 1. If the correlation
between two random variables is close to 1, they are strongly positively
correlated; that is, if one of them takes a value above its mean, the other
one is very likely to take a value above its mean as well. If the correlation
is close to –1, they are strongly negatively correlated; that is, if one of
them takes a value above its mean, the other one is very likely to take a
value below its mean. If the correlation is 0, then the two variables are
independent—meaning knowing whether one of them is above or below its
mean value does not tell you anything about where the value of the other
variable may be.
An important observation here is that covariance and correlation exist
only for pairs of random variables. They are not computed for more than
two variables at a time. Thus, if the situation calls for analysis of dependence

Random Variables, Probability Distributions, and Important Statistical Concepts
81
between more than two random variables, the covariances and correlations
are reported in a table (referred to as a “covariance matrix” and “correlation
matrix”, respectively). If there are N variables to analyze, the covariance and
the correlation tables each have N rows and N columns. The entry in the ith
row and jth column is the covariance/correlation of the ith variable and the
jth variable. The values in the diagonal of these matrices (that is, entries in
the ith row and ith column) are equal to the variance of the ith variable (in
the case of covariance matrix) and 1 (in the case of the correlation matrix).
Appendix A, Basic Linear Algebra Concepts, on the companion web site,
brieﬂy introduces matrix arrays. We will discuss covariance and correlation
matrices in more detail in Chapter 7.
When dealing with ﬁnancial data, we often need to be concerned with
autocorrelation. Autocorrelation exists when the realizations of a random
process over time (such as the movement of a stock price) depend on the
history of the process, that is, when a random variable (such as the stock
return) in one time period is correlated with itself (the return) during previous
time periods. We will see examples in Chapters 12, 14 and 15.
It is worth noting that while covariance and correlation are very useful
measures of dependence, and are widely used in ﬁnancial applications, they
do not paint a complete picture of how random variables are codependent,
and can sometimes be misleading. This is particularly true in cases in which
two variables are nonlinearly related.8 Exhibit 3.19 contains one such il-
lustration. Consider two random variables, ˜X and ˜Y, where ˜X follows a
continuous uniform distribution on the interval [0,20], and ˜Y = e ˜X. One
hundred observations from the probability distribution of ˜X are drawn,
the corresponding values for ˜Y are computed, and the points are plotted
in Exhibit 3.19. Note that ˜X and ˜Y are perfectly dependent—knowing the
value of ˜X, we can predict the exact value for ˜Y. Yet, when we compute
the correlation coefﬁcient between ˜X and ˜Y, we get a value of about 0.5.
The latter shows relatively strong positive dependence, but is not 1, that is,
it does not reﬂect the fact that ˜X and ˜Y are actually perfectly dependent. The
correlation coefﬁcient would measure the dependence correctly, however, if
˜X and ˜Y had a linear relationship, that is, if ˜Y were a linear function of ˜X
of the kind a ˜X + b for some constants a and b.
3.9
SUMS OF RANDOM VARIABLES
As we mentioned in section 3.4, we often need to consider more than one
uncertainty at a time, and thus we need tools to deal with sums of random
variables, for example, the behavior of our total investments or overall
return on multiple projects. Summarizing the joint probability distributions

82
FUNDAMENTAL CONCEPTS
0
2
4
6
8
10
12
14
16
18
20
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5 x 10
8
X
Y
EXHIBIT 3.19
A connected graph of the realizations of ˜X versus the
realizations of ˜Y = e ˜X.
for sums of two or more random variables is not as easy as summing the
two distributions. In this section, we review a few important facts about
analyzing sums of random variables.
Suppose the return on investment A in Exhibit 3.9 is the random variable
˜X, and the return on investment B is the random variable ˜Y. Let E[ ˜X] and
E[ ˜Y] be the expected returns of the two investments, and σX and σY be their
standard deviations. Suppose now we invest 0.40 (40%) of our funds in A,
and 0.60 (60%) of our funds in B. Therefore, the return on the portfolio is
0.40 · ˜X + 0.60 · ˜Y. What is the expected return on the portfolio, and what
is the portfolio’s standard deviation?
First, we need to ask what are the expected values of 0.40 · ˜X and
0.60 · ˜Y. Note that even though 0.40 and 0.60 are numbers (constants), the
products 0.40 · ˜X and 0.60 · ˜Y are random variables because they depend
on random variables.
It turns out that for any random variable ˜X,
E[a · ˜X] = a · E[ ˜X]
if a is a constant.

Random Variables, Probability Distributions, and Important Statistical Concepts
83
Furthermore, it is always true that the expectation of the sum of two
random variables is equal to the sum of the expectations:
E[ ˜X + ˜Y] = E[ ˜X] + E[ ˜Y].
Therefore,
E[a · ˜X + b · ˜Y] = a · E[ ˜X] + b · E[ ˜Y].
This allows us to compute the expected value of our portfolio:
E[0.40 · ˜X + 0.60 · ˜Y] = 0.40 · E[ ˜X] + 0.60 · E[ ˜Y].
What about the risk of the portfolio? Most people would be tempted
to extend the preceding reasoning to portfolio variance and standard devi-
ation as well. However, variance and standard deviation are not nearly as
“convenient” as the expectation operator. It turns out that
Var[a · ˜X] = a2 · Var[ ˜X],
Var( ˜X + ˜Y) = Var( ˜X) + Var( ˜Y) + 2 · Cov( ˜X, ˜Y),
and
Var(a · ˜X + b · ˜Y) = a2 · Var( ˜X) + b2 · Var( ˜Y) + 2 · a · b · Cov( ˜X, ˜Y).
There are no “nice” formulas for the standard deviation of a sum of
random variables. We basically need to compute the variance of the sum (as
we just did), and take the square root of the resulting expression to compute
the standard deviation.9
There are two things to note. First, the constants a and b are squared
once they are taken out of the expression inside the parentheses for the
variance. Second, there is an additional term in the sum of the variances,
which involves the covariance of the two random variables. Why does this
hold at an intuitive level? We will provide some examples of this effect in
Chapter 7, but the main idea is that if the random variables move in opposite
directions of each other on average (this means that their covariance is
negative), the variance of their sum (that is, the variance of the portfolio) is
reduced. We are more likely to get extreme values for the combination of
investments if they move in the same direction, that is, if they are strongly
positively correlated. This was one of the great insights that came out of
Harry Markowitz’s theory on optimal portfolio allocation, which won him

84
FUNDAMENTAL CONCEPTS
the 1990 Nobel Prize in Economic Science. It led to the proliferation of
diversiﬁcation as a strategy in managing assets.
So far, we reviewed what happens to the mean and the variance of a sum
of two random variables. What about the actual probability distribution of a
random variable that equals the sum of two random variables, for example,
˜Z = ˜X + ˜Y?
It turns out that computing the distribution of ˜Z is not as easy as adding
up the PMFs or PDFs of ˜X and ˜Y. If it was, a total sum of probabilities
for the distribution of ˜Z would be more than 1. Moreover, the distribution
of the sum of the two random variables may look nothing like the distri-
butions of the individual variables. For example, Exhibit 3.20 illustrates
the distribution of the sum of two uniform random variables on [0,1]. The
resulting distribution is the triangular distribution. Intuitively, this makes
sense. For example, the mean values for both uniform distributions are in
the middle—at 0.5. So, it appears logical that most of the mass for the sum
of the probability distributions would be in the middle too—at the sum of
the expected values, 0.5 + 0.5 = 1. Also, the range for the new variable ˜Z
should be [0,2]. This is because the ranges for ˜X and ˜Y are both [0,1], so
the minimum value for their sum is 0 + 0 = 0, and the maximum value for
their sum is 1 + 1 = 2.
Unfortunately, most sums of probability distributions are not as easy to
visualize. The actual formula for computing the distribution of the sum of
two random variables involves nontrivial integration, and is referred to as
convolution. Let fX(x), fY(y), and fZ(z) be the PDFs of the random variables
˜X, ˜Y and ˜Z at points x, y, and z, respectively. Then the PDF for the sum ˜Z is
fZ(z) =
∞

−∞
fY(z −x) fX(x) dx.
As we learn more about simulation techniques in Chapter 4, the advan-
tages of using simulation to evaluate such complex integrals will become
evident.
3.10
JOINT PROBABILITY DISTRIBUTIONS AND
CONDITIONAL PROBABILITY
The previous section reviewed important facts about sums of random vari-
ables. In this section, we introduce the concepts of joint probability distri-
bution and conditional probability, which are also useful in situations in
which we are dealing with more than one random variable.

Random Variables, Probability Distributions, and Important Statistical Concepts
85
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
x
PDF
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
x
PDF
0
0.5
1
1.5
2
0
0.2
0.4
0.6
0.8
1
x
PDF
X~
Y~
Y
X
Z
~
~
~
+
=
EXHIBIT 3.20
Sum (convolution) of two uniform random variables. The resulting
probability distribution is triangular.
Joint probability is simply the probability that two random variables
take two values at the same time. The joint PMF of two discrete random
variables ˜X and ˜Y is denoted p( ˜X, ˜Y) or p( ˜X = x, ˜Y = y). The joint PDF
of two continuous random variables ˜X and ˜Y is denoted f ( ˜X, ˜Y). When
˜X and ˜Y both follow a speciﬁc probability distribution, their joint proba-
bility distribution is typically referred to as a “multivariate” distribution.
For example, if ˜X and ˜Y both follow normal distributions, their joint dis-
tribution is called multivariate normal distribution. If ˜X and ˜Y both fol-
low binomial distributions, their joint distribution is called multinomial
distribution.

86
FUNDAMENTAL CONCEPTS
In section 3.4, we brieﬂy introduced the notation |, which means “con-
ditional on.” Conditioning on information has important applications in
ﬁnancial modeling, and we will see examples of it, for example, when we
introduce variance reduction techniques in Chapter 14.
When two random variables are dependent, then knowing something
about the realization of one of them should give us information about the
likely realizations of the other one. (If it did not, then the two variables
would be independent by deﬁnition.) The conditional probability that a
random variable ˜X will take a value x given that a random variable ˜Y has
taken value y is
P( ˜X = x| ˜Y = y) = P( ˜X = x and ˜Y = y)
P( ˜Y = y)
.
Intuitively, the fact that ˜Y has taken the value y eliminates some of the
possible outcomes for ˜X, and the revised probability that ˜X will take a value
x is computed as a percentage of all those instances in which ˜X = x given
˜Y = y.
The conditional PDF of a continuous random variable ˜X given ˜Y is
f ˜X| ˜Y(x|y) = f ˜X, ˜Y(x, y)
f ˜Y(y)
.
This concept and notation extend to the summary measures for prob-
ability distributions as well. The conditional expectation of the random
variable ˜X given that ˜Y has taken value y is simply the weighted average
for the values of ˜X that are possible given the realization y of ˜Y. The condi-
tional expectation is denoted E[ ˜X| ˜Y = y], and the notation carries over to
variance, covariance, and so on. The following facts hold:
E[ ˜X] = EY[EX[ ˜X| ˜Y]]
Var( ˜X) = EX[Var( ˜X| ˜Y)] + Var(EX[ ˜X| ˜Y])
Cov( ˜X, ˜Z) = EY[Cov( ˜X, ˜Z)| ˜Y] + Cov(EX[ ˜X| ˜Y], EZ[ ˜Z| ˜Y])
For example, the ﬁrst statement says that if we compute the mean of
the possible values of a random variable ˜X when a speciﬁc realization of a
random variable ˜Y has occurred, and then compute the sum (integral) of the
means of the possible value of ˜X for all possible realizations of ˜Y (weighted
by the probability of obtaining these realizations for ˜Y), we should obtain
the actual mean of ˜X.

Random Variables, Probability Distributions, and Important Statistical Concepts
87
3.11
FROM PROBABILITY THEORY TO
STATISTICAL MEASUREMENT: PROBABILITY
DISTRIBUTIONS AND SAMPLING
More often than not, we are faced with data from which we try to de-
duce how uncertainty should be modeled, rather than knowing the exact
probability distribution that these data should follow. Suppose you have
collected a sample of N independent observations X1, . . . , XN. You can
imagine grouping similar observations together into “bins” (the bins can be
as small as a single number), and creating a histogram of observed values.
This histogram will be an empirical probability distribution. All of the con-
cepts explained in section 3.6 (for describing central tendency, spread, skew,
covariability, etc.) are valid for empirical distributions derived from samples
of data. The difference is that when dealing with real-world data, we need
to take into consideration the fact that there is inevitably some “noise.” This
noise may come from many sources, including inaccuracies in recording or
handling the data, but a substantial source of imprecision in estimation is
the limited number of observations. With ﬁnancial data in particular, we
can never observe or anticipate everything that can happen. We are not only
limited in our ability to reconstruct a probability distribution from a ﬁxed
number of observations and forecasts, but also need to worry about rare
events, which are difﬁcult to observe, and thus are not necessarily a part
of our sample. Hence, our estimates of the parameters of the “underlying”
probability distribution for the empirical data are inherently inaccurate.
We refer to means, standard deviations, correlations, covariances, and
other quantities estimated from data as descriptive statistics or simply statis-
tics, while we refer to their “real” values (assumed to come from a speciﬁc
underlying probability distribution that we cannot observe exactly because
of the noise) as parameters. In fact, different notations are used to differ-
entiate between the two concepts. Parameters are usually denoted by Greek
letters such as µ (for mean), σ (for standard deviation), σ 2 (for variance),
and ρ (for correlation). Statistics are usually denoted by Latin letters, such
as X (for sample mean), s (for sample standard deviation), s2 (for sample
variance), and r (for sample correlation).
To compute these sample statistics, we use formulas very similar to the
formulas for the corresponding parameters:
■Sample mean:
X = 1
N ·
N

n=1
Xn

88
FUNDAMENTAL CONCEPTS
■Sample variance:
s2 =
1
N −1 ·
N

n=1
(Xn −X)2
■Sample standard deviation:
s =




1
N −1 ·
N

n=1
(Xn −X)2
■Sample covariance:
SCov( ˜X, ˜Y) =
1
N −1 ·
N

n=1
(Xn −X)(Yn −Y)
■Sample correlation:
r( ˜X, ˜Y) = SCov( ˜X, ˜Y)
sX sY
Note, for example, that the principle behind computing the sample mean
is very similar to the principle behind computing the mean of a general
distribution. The mean is still a weighted average of the possible values
of the random variable. It is just that our sample contains N independent
observations, so the probability of each of them must be 1/N (otherwise, the
total probability would not add up to 1). Therefore, to compute the mean,
we are weighing each observation by its probability of occurrence (1/N),
and adding up the observations.
A substantial amount of research in statistics has been dedicated to
ﬁnding ways to make the estimation of parameters through sampling ac-
curate. For example, covariance and correlation estimates are widely used
in forecasting the return on assets for portfolio management purposes, and
are notoriously inaccurate because, as surprising as it seems, there are not
actually enough data to estimate them reliably. (This is complicated by the
fact that they vary over time.) The correlation coefﬁcient we described in
section 3.8 is the classical Pearson correlation coefﬁcient. Another kind of
correlation coefﬁcient is the Spearman correlation. It does not incorporate
as much information about the data as the Pearson correlation coefﬁcient,
but tends to be more stable than the Pearson correlation when there is noise
in the data. The Spearman correlation is a rank correlation. In other words,

Random Variables, Probability Distributions, and Important Statistical Concepts
89
instead of considering the values of the random variables, it computes the
correlation between the ranks of the observations in a sample. The mean of
the random variable is replaced by the mean of the rank.
Additionally, inferential statistics is concerned with evaluating the de-
gree of accuracy of sample estimates. Some powerful and far-reaching con-
cepts in this context include the Central Limit Theorem, conﬁdence intervals
estimates, bootstrapping, and hypothesis testing. These concepts are also
widely used in simulation modeling.
3.11.1
Central Limit Theorem
Suppose that we have a sample of N independent observations X1, . . . , XN
drawn from the same underlying distribution. (The shorthand for this state-
ment is that X1, . . . , XN are IID, that is, independent and identically dis-
tributed.) Let us assume that the mean of the underlying distribution is µX
and its standard deviation is σX. Let SN denote the sum of the N observa-
tions, that is,
SN =
N

n=1
Xn.
Then, as long as the sample size N is moderately large (greater than
30), and under some relatively mild technical conditions on the underlying
probability distribution, the distribution of the sum SN is normal with mean
equal to µS = N · µX and standard deviation σS = σX ·
√
N. This means
that if we are to take many, many samples (always of size N) from this
distribution, compute the sums of the N observations for each of these
samples, and plot these sums, we would obtain a graph that looks very
much like the normal distribution.
The expressions for the mean and the standard deviation of the sum
of IID random variables in the Central Limit Theory (CLT) follow easily
from the rules in section 3.9. However, the fact that the distribution of
the sum approaches normal is not at all obvious. It is one of the greatest
demonstrated links between probability theory and applied statistics, and
is to a large extent the reason for the popularity of the normal distribution
in practice. The power of the CLT is the conclusion that many real-world
phenomena should be well described by the normal distribution, even if the
underlying random process that generates them is unknown.
The CLT result serves as the justiﬁcation for many practitioners to use
the normal distribution as an approximation when they analyze the risk of
their investments. The argument is that as returns accumulate over time,
“things become normal.” The problem arises, however, if the assumptions

90
FUNDAMENTAL CONCEPTS
behind the CLT are not satisﬁed in practice. For example, the underlying
distributions from which samples are drawn change over time depending
on market conditions, and there can be correlation across returns from
different time periods, so the IID assumption does not necessarily hold.
The nonnormality of returns is especially pronounced in high-frequency
trading, as the time intervals between trades are too short to allow for
“things to approach” the normal distribution. As we will see in Parts Two
and Three, this kind of reasoning can lead to a gross underestimation of
investment risk.
3.11.2
Confidence Intervals
One of the consequences of the CLT is that it allows us to make statements
about the accuracy of our estimate of the sample mean. The sample mean
X we introduced earlier in this section can be expressed as a sum of N IID
variables, X1/N, . . . , XN/N. Therefore, the CLT applies. Using the rules in
section 3.9, it can be shown that the sample mean X follows an approx-
imately normal distribution with mean µX = µX and standard deviation
σX = σX/
√
N.
Therefore, we know the variability of our sample mean estimate. The
standard deviation of X, also called standard error of the estimate, is in-
versely proportional to the square root of the number of observations in the
sample. Not surprisingly, the more observations we have, the more accu-
rate our estimate of the true average of the distribution will be. In practice,
of course, we do not know the true standard deviation σX (if we knew it,
we would know the mean as well, so we would not be trying to estimate
mean). So, we need to make some adjustments—use the standard deviation
s from the sample to approximate σX—and modify the estimation slightly
to account for the additional inaccuracy that using a sample statistic in the
formula brings.10
The concept of conﬁdence interval (CI) estimates is to present not only
a point estimate for the parameter of interest (in this case, one value for
the sample mean X), but also to state something about how far away this
estimate will be from the true parameter (the true mean of the underlying
distribution). This is achieved by stating an interval centered at X whose
length depends on:
1. The variability of the estimate (the larger the standard error of X, the
less likely it is that we will get the correct estimate for the true mean
from the sample).
2. The degree of conﬁdence we have that this interval will cover the true
mean.

Random Variables, Probability Distributions, and Important Statistical Concepts
91
Typical values for the conﬁdence level include 90%, 95%, and 99%.
The exact formula for a (100 −α)% CI for the sample mean X is

X −t(100−α/2),N−1
s
√
N
, X + t(100−α/2),N−1
s
√
N

,
where t(100−α/2),N−1 is (100 −α)th percentile (the value on the x-axis) of a
t-distribution with N −1 degrees of freedom.11 In words, the (100 −α)% CI
for the sample mean X states that the probability that the interval computed
from the preceding formula covers the true mean µ is (100 −α)%.
As we saw in Exhibit 3.17, the t-distribution becomes very close to
the normal distribution as the parameter for degrees of freedom ν (which
here equals N −1) becomes large. In the context of simulation, where sample
sizes would generally be large, replacing the value of the percentile from the
t-distribution with the value of the percentile from the normal distribution
will make no difference for all practical purposes.
3.11.3
Bootstrapping
The CI estimate for the mean is the conﬁdence interval most widely used
in practice. However, sometimes we need to evaluate the accuracy of other
parameter estimates for one or more distributions. For example, we may be
concerned about how accurate our estimates of the distribution percentile
or skewness are. (This kind of application is relevant in portfolio risk man-
agement.) Alternatively, suppose that you have computed the correlation
between historical returns on Investment A and Investment B from Ex-
hibit 3.9, and have discovered that it is 0.6. Is this a strong correlation in the
statistical sense, that is, does it appear to be strong just by chance (because
we picked a good sample), or can we expect that will remain strong in other
samples, given the overall variability in this sample’s data?
The procedure of computing the CI estimate of the mean is a repre-
sentative of classical methods in statistics, which relied on mathematical
formulas to describe the accuracy of a sample statistic estimate. There are
some theoretical results on conﬁdence interval estimates for distribution
parameters other than the mean, but in general, the results are not as easy
to summarize as the closed-form expression for the CI estimate for the
mean from section 3.2.
Bootstrapping12 is a statistical technique that is useful in such situations.
It involves drawing multiple samples of the same size (say, k samples) at
random from the observations in the original sample of n observations.
Each of the k samples is drawn with replacement—that is, every time an

92
FUNDAMENTAL CONCEPTS
observation is drawn, it is placed back in the original sample, and is eligible
to be drawn again, in the same sample or in future samples.
After drawing k samples from the original sample, the statistic corre-
sponding to the parameter we are interested in estimating (whether it is
percentile, skewness, correlation, or a general function of the random vari-
able) is computed for each of the k samples. The so-obtained k values for the
sample statistic are used to form an approximation for the parameter’s sam-
pling distribution. This sampling distribution can be used, for example, to
determine what values of the sample statistic are most likely to occur, what
is the variability of the estimate, and what the 5th and the 95th percentile
of the approximate sampling distribution are. These percentiles provide an
approximation for the conﬁdence interval for the true parameter we are
trying to estimate.
At ﬁrst glance, this technique appears pointless. Why do we not collect
k more samples instead of reusing the same data set k times? The reason
is that it is expensive to collect data, and that sometimes additional data
collection is not an option, especially with ﬁnancial data.
Bootstrapping is used not only for evaluating the accuracy in the estimate
of a probability distribution parameter, but also as a simple method for
generating forecasts for uncertain quantities based on a set of historical
observations for risk management purposes. The concept of simulation is
necessary to understand how the bootstrap method is actually applied, as
the random draws from the original sample need to be generated with a
random number generator. (See Chapter 4 for a discussion of the simulation
technique, and Practice 4.2 on the companion web site to see an application
of the bootstrapping technique for evaluating the accuracy of the estimate
of the 5th percentile of a portfolio’s return.)
3.11.4
Hypothesis Testing
Hypothesis testing is a fundamental concept in statistics. The procedure is
as follows. We start out by stating a hypothesis (the null hypothesis) about a
parameter for the distribution that corresponds to a variable of interest. For
example, we claim that the skew of the distribution for the returns of the S&P
500 index is zero. (As we will see later in this book, while often unjustiﬁed,
making assumptions like these substantially simpliﬁes risk measurement and
derivative pricing.) Then we take a sample of S&P 500 returns, and estimate
the skew for that sample. Suppose we get a skew of –0.11. The statistical
hypothesis testing methodology allows us to test whether the value obtained
from the sample (–0.11) is sufﬁciently “close” to the hypothesized value (0)
to conclude that, in fact, the “real” skew could indeed be zero, and that the
difference is only a consequence of sampling error.

Random Variables, Probability Distributions, and Important Statistical Concepts
93
To test whether the difference between the hypothesized and the ob-
served value is statistically signiﬁcant, that is, large enough to be con-
sidered a reason to reject the original hypothesis, we would compute a
quantity called test statistic, which is a function of observed and hypoth-
esized parameters. In some cases, this test statistic follows a known prob-
ability distribution. For example, if we are testing a hypothesis about the
sample mean, then the test statistic is called the t-statistic because it fol-
lows a t-distribution with degrees of freedom equal to the sample size mi-
nus one. Knowing that the test statistic follows a speciﬁc distribution, we
can see whether the test statistic obtained from the sample is “very far”
from the center of the distribution, which tells us whether the sample es-
timate we obtained would be a rare occurrence if the hypothesized value
were true.
There are different ways to measure the rarity of the observed statis-
tic. Modern statistical software packages typically report a p-value, which
is the probability that, if our null hypothesis were true, we would get a
more extreme sample statistic than the one we observed. If the p-value is
“small” (the actual cutoff is arbitrary, but the values typically used are 1%,
5%, or 10%), then we would reject the null hypothesis. This is because
a small p-value means that there is very small probability that we would
have obtained a sample statistic as extreme as the one we obtained if the
hypothesis were true, that is, that the current test statistic is in the tails of the
distribution.
The type of hypothesis tests we described so far are called one-sample
hypothesis tests because they interpret the information only for one sample.
There are two-sample hypothesis tests that compare observed statistics from
two samples with the goal of testing whether two populations are statistically
different. They could be used, for example, to compare whether the returns
of one investment have been statistically better on average than the returns
on another investment.
Finally, more sophisticated hypothesis tests are used in the background
for a number of important applications in ﬁnancial modeling. Multivariate
regression analysis, which we will discuss in the context of factor model
estimation in Chapter 11, uses hypothesis testing to determine whether a
forecasting model is statistically signiﬁcant. Goodness-of-ﬁt tests, which are
used in the context of ﬁtting probability distributions to observed data, use
statistical hypothesis testing to determine whether the observed data are
statistically “signiﬁcantly close” to a hypothesized probability distribution.
Chi-square tests, which we mentioned in section 3.7.2, are a very popular
type of goodness-of-ﬁt tests. (See also the discussion on selecting probability
distributions as inputs for simulation models in section 4.1.1 of the next
chapter.)

94
FUNDAMENTAL CONCEPTS
SUMMARY
■Uncertainty can be represented by random variables with associated
probability distributions.
■Probability distributions can be viewed as “listings” of all possible values
that can happen and the corresponding probability of occurrence, and
are conveniently represented in graphs (histograms and bar charts).
■Probability distributions can be discrete or continuous. Discrete dis-
tributions are deﬁned over a countable number of values, whereas
continuous distributions are deﬁned over a range. Discrete distribu-
tions are described by probability mass functions (PMFs), whereas
continuous distributions are described by probability density functions
(PDFs).
■A continuous random variable can take an inﬁnite number of values, and
the probability of each individual value is 0. In the context of continuous
distributions, we replace the concept of probability of a value with the
concept of probability of an interval of values, and the probability is the
area under the PDF.
■Probability distributions can be summarized in terms of central ten-
dency (mean, median, and mode), variability (standard deviation, vari-
ance, coefﬁcient of variance [CV], range, percentile, etc.), skewness, and
kurtosis.
■The mean, variance, skew, and kurtosis of a probability distribution are
related to the ﬁrst, second, third, and fourth moment of the distribution.
The moments of a probability distribution can be computed from its
moment generating function. Inversely, if the moments of a probability
distribution are known, most generally the distribution can be uniquely
identiﬁed. However, sometimes the moments do not exist.
■Important discrete probability distributions include the binomial distri-
bution, the Bernoulli distribution, the discrete uniform distribution, and
the Poisson distribution.
■Important continuous probability distributions include the normal dis-
tribution, the continuous uniform distribution, the triangular distri-
bution, the Student’s t-distribution, the lognormal distribution, the
exponential distribution, the chi-square distribution, and the beta
distribution.
■Covariance and correlation are measures of average codependence of
two random variables.
■Empirical distributions are derived from data. All summary measures
for probability distributions apply to empirical distributions.
■The Central Limit Theorem states that the probability distribution a
sum of N independent and identically distributed observations tends to
a normal distribution with a speciﬁc mean and standard deviation.

Random Variables, Probability Distributions, and Important Statistical Concepts
95
■Conﬁdence intervals allow us to state both our estimate of a parame-
ter of an unknown probability distribution and our conﬁdence in that
estimate.
■Bootstrapping is a statistical technique for evaluating the accuracy of
sample statistics based on one sample of observations. It involves draw-
ing multiple samples from the original sample, calculating the sample
statistic in each of them, and analyzing the resulting distribution of the
sample statistic. Bootstrapping can also be used as a simple way to gen-
erate future forecasts for uncertain quantities based on a sample of past
observations.
■Hypothesis testing is a statistical methodology for evaluating whether a
statistic observed in a sample is signiﬁcantly different from the expected
value of a parameter of interest. It is used in many applications, including
goodness-of-ﬁt tests, multivariate regression analysis, and comparisons
of two populations.
SOFTWARE HINTS
@RISK
@RISK has very convenient features for deﬁning probability distributions. As
explained in Appendix B, Introduction to @RISK (on the companion web
site) you can see the distribution and how its shape changes immediately
after entering the distribution parameters in the dialog box. It is also easy to
compute probabilities and cumulative probabilities with @RISK by simply
sliding the bar on the graph, as shown in Appendix B and Chapter 4. @RISK
provides summary statistics for distributions automatically.
To calculate means, standard deviations, and other summary statistics
for empirical distributions (that is, when you are given data in a sample,
rather than data that have already been processed and organized to ﬁt a
probability distribution), you can use Excel’s built-in functions as well:
■=AVERAGE(Array) computes the sample average value of Array.
■=STDEV(Array) computes the sample standard deviation of Array.
■=VAR(Array) computes the sample variance of Array.
■=PERCENTILE(k,Array) returns the value that represents the kth per-
centile in Array.
■=PERCENRANK(Array,x) returns the rank of the value x inside the data
set Array.
■=COVAR(Array1,Array2) computes the sample covariance of Array1
and Array2.
■=CORREL(Array1,Array2)
computes
the
sample
correlation
of
Array1 and Array2.

96
FUNDAMENTAL CONCEPTS
EXHIBIT 3.21
Example of calculation of the mean of a
general discrete probability distribution with Excel.
Unfortunately, Excel has no built-in functions for computing descrip-
tive statistics for general distributions. In other words, you cannot request
that Excel compute the weighted average of distribution values. However, it
is easy to do this manually. The function SUMPRODUCT(Array1, Array2)
multiplies the corresponding values in Array1 and Array2, and adds them
up. Exhibit 3.21 illustrates an example of its application. In this case,
SUMPRODUCT computes the mean of a general discrete distribution by taking
each of the values in the distribution (2, 5, and 10), multiplying it by its
probability (0.6, 0.1, and 0.3), and adding up all the resulting products.
MATLAB
We provide the MATLAB commands for producing the probability distri-
butions graphs in this chapter.
Bernoulli Distribution
Note that the Bernoulli distribution is just a bino-
mial distribution with one trial, so we can use the MATLAB command for
binomial PDF to plot the PDF of the Bernoulli distribution.
p = 0.3; % Probability of success for each trial
n = 1; % Number of trials
k = 0:n; % Outcomes
m = binopdf(k,n,p); % Probability mass vector
bar(k,m) % Create a bar chart
grid on
Binomial Distribution
p = 0.3; % Probability of success for each trial
n = 3; % Number of trials
k = 0:n; % Outcomes

Random Variables, Probability Distributions, and Important Statistical Concepts
97
m = binopdf(k,n,p); % Probability mass vector
bar(k,m) % Create a bar chart to visualize the probability
distribution
grid on
Normal Distribution
>> mu = 0; sigma = 1;
>> x=linspace(-5,5,45); y = normpdf(x,mu,sigma);
>> plot(x,y); grid on
Discrete Uniform Distribution
>> x = 1:6; y = (1/6)*ones(1,6);
>> bar(x,y); grid on
Continuous Uniform Distribution
To obtain the picture in Exhibit 3.12(A),
use
>> x = 3:0.1:3.5; y = unifpdf(x,3,3.5);
>> plot([3 x 3.5],[0 y 0])
To obtain the picture in Exhibit 3.12(B), use
>> x = 0:0.1:1; y = unifpdf(x);
>> plot([0 x 1],[0 y 0])
Triangular Distribution
MATLAB has no function for computing the tri-
angular PDF directly, but you can plot the function manually by using
plot(x,y). For example, use
>> x = [0 1 2]; y = [0 1 0];
>> plot(x,y)
Student’s t -Distribution
The function tpdf(x,n) computes the PDF of
a t-distribution with n degrees of freedom. To obtain the family of t-
distributions with varying degrees of freedom in Exhibit 3.14, use
>> x=linspace(-6,6,45);
>> y=tpdf(x,2); plot(x,y); grid on;
>> hold on

98
FUNDAMENTAL CONCEPTS
>> y=tpdf(x,8); plot(x,y,’r:’);
>> y=tpdf(x,30); plot(x,y,’g---’); >> hold off
Lognormal Distribution
>> x = (0:0.02:10); y = lognpdf(x,0,1);
>> plot(x,y); grid on;
Exponential Distribution
>> lambda = 0.2; % Failure rate
t = 0:0.3:30; % Outcomes
f = exppdf(t,1/lambda); % Probability density vector
plot(t,f) % Visualize the probability distribution
grid on
Poisson Distribution
>> x = 0:15; y = poisspdf(x,5);
>> bar(x,y); grid on
Chi-Square Distribution
>> x = 0:0.2:20; y = chi2pdf(x,5); plot(x,y); grid on
Beta Distribution
To get the graph in Exhibit 3.18(A), use
>> x=linspace(-.2,1.2,45); y = betapdf(x,4,6);
>> plot(x,y); grid on;
To get the graph in Exhibit 3.18(B), use
>> x=linspace(-.2,1.2,45); y = betapdf(x,6,4);
>> plot(x,y); grid on;
MATLAB has a number of built-in functions for computing descriptive
statistics of samples of data. These include mean (for calculating the mean
of a sample), std (for calculating sample standard deviation), cov (for cal-
culating sample covariance), corrcoef (for calculating sample correlation),
and prctile (for calculating the kth percentile of a given set of data). See
MATLAB’s help for speciﬁc syntax and examples. Also, as explained in
Appendix C, Introduction to MATLAB (on the companion web site) MAT-
LAB’s commands usually use as inputs multidimensional arrays, so you can
compute summary statistics along different dimensions of the arrays. For

Random Variables, Probability Distributions, and Important Statistical Concepts
99
example, suppose you have a set of data for the returns on 30 assets over
100 days, stored in a matrix DataMx with 100 rows and 30 columns. You
can compute the mean return on a speciﬁc asset over the 100 days by com-
puting the mean in that stock’s column (mean(DataMx,2)), or compute the
mean return on the 30 assets on a particular day by computing the mean
in that day’s row (mean(DataMx,1)), with a single command option in the
mean command that speciﬁes which dimension you are considering.
NOTES
1. The notation Xi, a capital letter corresponding to the name of the random
variable, followed by an index, is a standard statistics notation to denote the
ith observation in a sample of observations drawn from the distribution of the
random variable ˜X.
2. A complete review of probability theory is beyond the scope of this book,
but the concept of moments of probability distributions is often mentioned in
quantitative ﬁnance, so let us explain brieﬂy what a moment generating function
(MGF) is. The kth moment of a random variable is deﬁned as
mk
 ˜X

= E
 ˜Xk
=
⎧
⎪⎨
⎪⎩

All values x of the random variable
xk · P( ˜X = x)
∞
−∞
xk · f (x) dx
.
For many useful cases (albeit not for all because for some distributions
some moments may not exist), knowing these moments allows us to indentify
uniquely the actual probability distribution. The MGF lets us generate these
moments. It is deﬁned as
Mt
 ˜X

= E

et ˜X
=
⎧
⎪⎨
⎪⎩

All values x of the random variable
etx · P( ˜X = x)
∞
−∞
etx · f (x) dx
.
By setting the value of the parameter t to different values (that is, 1,2,3,
etc.), we can recover the ﬁrst, second, third, and so on moment. While this con-
struction looks rather awkward, it is very useful for proving theoretical results
such as “The sum of two independent normal random variables is also a normal
random variable.” (The sum of two random variables does not necessarily have
the same distribution as the random variables in the general case.) This is done
by computing the MGF of the sum of two normal variables, and then check-
ing if the resulting MGF is of the same type as the MGF of a normal random
variable, which is computationally more convenient than computing the actual
probability distribution of the sum of two random variables.

100
FUNDAMENTAL CONCEPTS
3. Recall that squaring a number always results in a nonnegative number, so the
sum of squared terms is nonnegative.
4. Some software and simulation software packages report excess kurtosis, rather
than kurtosis, as default. The excess kurtosis is computed as the value for
kurtosis minus 3 (the kurtosis of the normal distribution), so that the normal
distribution has kurtosis of 0. Make sure that you check the help ﬁle for the
software package you are using before you interpret the value for kurtosis in
statistical output.
5. The Poisson distribution is also widely used in operations management ap-
plications, such as queue management, revenue management, and call center
stafﬁng.
6. W. S. Gossett stumbled across this distribution while working for the Guinness
brewery in Dublin. At the time, he was not allowed to publish his discovery
under his own name, so he used the pseudonym Student, and this is how the
distribution is known today.
7. The squared random variables arise when computing squared differences be-
tween observed values (which vary because the sample is random) and expected
values. Chi-square goodness-of-ﬁt tests consider the sum of the total squared
differences between the observed frequencies of values in a sample and the ex-
pected frequencies if the sample came from a particular distribution. Whether
the difference between what was observed and what was expected is statistically
“large” depends on value of the difference relative to the critical value of the
chi-square test statistic, which is computed from the chi-square distribution. See
the brief introduction of hypothesis testing in section 3.11.4.
8. In other words, their relationship cannot be described by a straight line.
9. Note that this also eliminates the possibility that the standard deviation of the
sum of two random variables is the sum of the standard deviations of the two
variables. This is never true if the two random variables have different variances.
If the two variables are independent (and the covariance is 0), we get
σ a· ˜X+b· ˜Y =

Var(a · ˜X + b · ˜Y) =

a2 · Var( ˜X) + b2 · Var( ˜Y)
̸= a ·

Var( ˜X) + b ·

Var( ˜Y) = a · σ ˜X + b · σ ˜Y
10. This is where the discovery of Student’s t-distribution made a substantial con-
tribution to modern statistics.
11. A number of software packages have commands for computing the value of t,
including Excel and MATLAB. For example, in MATLAB (and most statisti-
cal packages) one would use a command of the kind tinv(100-α/2, de-
grees of freedom). Excel has a similar command (=TINV(α, degrees
of freedom)), but it is a bit inconsistent. It takes in as an argument α, not
100-α/2, to compute the (100-α/2)th percentile of the t-distribution.
12. As explained in Chapter 2, there is a methodology commonly used in bond
analysis to derive the term structure of interest rates that is referred to as
bootstrapping. The statistical concept of bootstrapping described in this chapter
has nothing to do with that methodology.

CHAPTER4
Simulation Modeling
T
his chapter reviews the main idea behind Monte Carlo (MC) simulation,
and discusses important issues in its application to business problems,
such as number of scenarios to generate, interpretation of output, and efﬁ-
cient ways to simulate random numbers. Depending on which software you
decide to use for simulation, you may read Appendix B for an introduction
to @RISK or Appendix C for an introduction to MATLAB—both found on
the companion web site.
4.1
MONTE CARLO SIMULATION:
A SIMPLE EXAMPLE
As explained in Chapter 3, the analysis of risk is based on modeling un-
certainty, and uncertainty can be represented mathematically by probabil-
ity distributions. These probability distributions are the building blocks for
simulation models. Namely, simulation models take probability distribution
assumptions on the uncertainties as inputs, and generate scenarios (often re-
ferred to as trials) that happen with probabilities described by the probability
distributions. They then record what happens to variables of interest (called
output variables) over these scenarios, and let us analyze the characteristics
of the output probability distributions (see Exhibit 4.1).
Let us start with a simple example. Suppose you want to invest $1,000
in the U.S. stock market for one year. To do so, you decide that you want to
invest in a stock index that represents the performance of the stock market.
Speciﬁcally, you invest in a mutual fund whose investment objective is to
reproduce the return performance on the S&P 500. A mutual fund with
such an objective is referred to as an index fund. We will denote the initial
investment, or capital, invested in the index fund as C0 (i.e., C0 = $1,000).
How much money do you expect to have at the end of the year? Let us label
the amount of capital at the end of the year by ˜C1.1 Note that ˜C1 will be a
101

102
FUNDAMENTAL CONCEPTS
EXHIBIT 4.1
Typical Monte Carlo simulation system.
random variable because it will depend on how the market (i.e., S&P 500)
performs over the year. In fact, if we let ˜r0,1 denote the market return over
the time period [0,1), then ˜C1 will equal
C0 + ˜r0,1C0
or, equivalently,
(1 + ˜r0,1)C0
As explained in Chapter 2, the return rt, t + 1 over a time period [t, t +
1) can be computed as
Pt+1 −Pt + Dt
Pt
where Pt and Pt+1 are the values of the S&P 500 at times t and t + 1,
respectively, and Dt is the amount of dividends paid over that time period.
In this case, we can think of Pt and Pt+1 as the S&P 500 index levels at the
beginning (t = 0) and at the end of the year (t = 1), respectively, and assume
that Dt is 0.

Simulation Modeling
103
To estimate the end of year capital you would have, you can guess the
return on the market, and compute the resulting value for ˜C1. However,
this would give you only a point estimate of the possible values for your
investment. A more sophisticated approach is to generate scenarios for the
market return over the year, and compute ˜C1 in each of these scenarios. In
other words, you can represent future returns by a probability distribution,2
generate scenarios that are representative of this probability distribution,
and then analyze the resulting distribution of your end-of-year capital. The
resulting probability distribution of ˜C1 will be a set of scenarios itself. You
can create a histogram of the outcomes, that is, collect the outcomes of
the scenarios into nonoverlapping bins and draw bars above all bins with
heights corresponding to the percentage of times outcomes in each bin were
obtained in the simulation. This will allow you to visualize the approximate
probability distribution of ˜C1, and analyze it with the statistical measures
described in section 3.6 (central tendency, skew, variability, etc.) in the pre-
vious chapter. The distribution for ˜C1 from the simulation will be only an
approximation because it will depend both on the number of scenarios and
on the set of scenarios you generated for ˜r0,1. Intuitively, if you generate
1,000 scenarios that cover the possible values for ˜r0,1 well, you would ex-
pect to obtain a better representation of the distribution of ˜C1 than if you
generated only two scenarios.
4.1.1
Selecting Probability Distributions
for the Inputs
The ﬁrst question you need to ask yourself when creating the simulation
model about the future values of your funds is what distribution is appro-
priate for modeling the future market returns. One possible starting point is
to look at a historical distribution of past returns, and assume that the future
will behave in the same way. When creating scenarios for future realizations,
then, you can draw randomly from historical scenarios. This is a very sim-
ple approach, which is based on the bootstrapping technique described in
section 3.11.3.
Another possibility is to assume a particular probability distribution for
future returns, and use historical data to estimate the parameters of this
distribution, that is, the parameters that determine the speciﬁc shape of the
distribution, such as the expected value (µ) and standard deviation (σ) for
a normal distribution (see section 3.4), λ for a Poisson distribution (see
section 3.7.1), or α and β for a beta distribution (see section 3.7.2). For
example, if you assume a normal distribution for returns, then you can use
the historical variability of returns as a measure of the standard deviation σ

104
FUNDAMENTAL CONCEPTS
of this normal distribution, and the historical average (mean) as the expected
return µ of the normal distribution.
A third approach is not to start out with a particular distribution, but
to use historical data to ﬁnd a distribution for returns that provides the
best ﬁt to the data. As we mentioned in sections 3.7.2 and 3.11.4, the chi-
square hypothesis test is one possible goodness-of-ﬁt test. Other goodness-of-
ﬁt tests include the Kolmogorov-Smirnov (K-S) test, the Anderson-Darling
(A-D) test, and root-mean-squared-error (RMSE).3 Most simulation soft-
ware packages, including MATLAB and @RISK, have commands that can
test the goodness of ﬁt for different probability distributions.4
Yet a fourth way is to ignore the past and look forward, constructing
a probability distribution based on your subjective guess about how the
uncertain variable in your model will behave. For example, using the beta
distribution from Exhibit 3.18(A) to model the future market return will
express a more pessimistic view about the market than using the beta dis-
tribution in Exhibit 3.18(B) or a normal distribution because most of the
probability mass in the distribution in 3.18(A) is to the left, so low values
for return will happen more often when scenarios are generated.
It is important to realize that none of these approaches will provide the
answer. Simulation is a great tool for modeling uncertainty, but the outcome
is only as good as the inputs we provide to our models. We discuss ways for
deﬁning input distributions in speciﬁc applications in the book. The art of
simulation modeling is in providing good inputs and interpreting the results
carefully.
4.1.2
Interpreting Monte Carlo Simulation Output
For purposes of our example, let us assume that the return on the mar-
ket over the next year will follow a normal distribution. (This is a widely
used assumption in practice, despite the fact that few empirical studies ﬁnd
evidence to support it.) Between 1977 and 2007, the S&P 500 returned
8.79% per annum on average, with a standard deviation of 14.65%. We
will use these numbers as approximations for the average return and the
standard deviation of the return on your investment in the stock market
over the next year. Relying on historical data is ﬂawed, but is a reasonable
starting point.
This chapter’s Software Hints section goes step-by-step through the
actual implementation of our simple example with only Microsoft Excel
functions, @RISK functions, and MATLAB functions. Here, we discuss the
output one would obtain after generating 100 scenarios for the market
return over the next year. Note that to generate these scenarios, we simply
need to draw 100 numbers from a normal distribution with mean 8.79%

Simulation Modeling
105
and standard deviation 14.65%. The input to the simulation would then be
a sequence of 100 numbers such as
0.0245
-0.1561
0.1063
0.1300
-0.0801
0.2624
0.2621
0.0824
0.1358
0.1135
0.0605
and so on.
The output graph would look like Exhibit 4.2. Summary statistics ob-
tained based on the 100 values of the distribution are provided to the right
of the graph.5
If historical trends hold, you would expect to have $1,087.90 on average
at the end of the ﬁrst year. The standard deviation of the end-year capital
you would expect is $146.15, that is, on average, you would expect to be
$146.15 off the mean value. With 5% probability, you will not be able to
make more than $837.00 (the 5th percentile of the distribution), and with
95% probability you will make less than $1,324.00 (the 95th percentile of
the distribution). The skewness is close to 0, and the kurtosis is close to 3,
which means that the simulated distribution is close to normal. (In fact, the
0.0030
0.837
1.324
Values in Thousands
5.0%
Money at the End of Year 1
5.0%
90.0%
0.0025
0.0020
0.0015
0.0010
0.0005
0.0000
0.7
0.8
0.9
1.0
1.1
1.2
1.3
1.4
1.5
EXHIBIT 4.2
Histogram and summary statistics for the end-of-year distribution
of 100 simulated values for $1,000 invested at the beginning of the year.

106
FUNDAMENTAL CONCEPTS
output distribution is normal because the input distribution we provided for
the simulation of this simple relationship was normal, but the estimate from
the simulation will never be perfectly accurate.)
Be careful with the interpretation of minima and maxima in a simula-
tion. Theoretically, the minimum and maximum we could have obtained
in this simulation are negative and positive inﬁnity because the probability
distribution for the return (the normal distribution) has an inﬁnite range.
We did not obtain a particularly small minimum or a particularly large
maximum because we only simulated 100 values. An event in the tail of
the distribution with probability of occurring of less than 1/100 would be
unlikely to appear in this set of simulated values. The minimum and the max-
imum are highly sensitive to the number of simulated values and whether the
simulated values in the tails of the distribution provide good representation
for the tails of the distribution. There are smart ways to simulate scenarios
so that the tails are well represented (we will talk about such methods later
in this chapter), but the minimum and the maximum values obtained in a
simulation should nevertheless be interpreted with care.
In section 3.11.2 in the previous chapter, we explained the statistical
concept of conﬁdence interval (CI) estimates. The main idea was the fol-
lowing: In statistics, when we want to estimate a speciﬁc parameter of a
distribution, such as the mean, we take a sample and observe what the value
of the parameter is in the sample (in technical terms, we record the value of
the sample statistic for the mean). Instead of reporting a single value for our
estimate for the mean, however, we could report an interval whose length is
related to the probability that the true distribution parameter indeed lies in
that interval.
Simulation is very similar to statistical sampling in that we try to repre-
sent the uncertainty by generating scenarios, that is, “sampling” values for
the output parameter of interest from an underlying probability distribution.
When we estimate the average (or any other parameter of interest) of the
sample of scenarios, we run into the same issue statisticians do—we need to
worry about the accuracy of our estimate. To compute a 95% CI estimate
for the average end-of-year capital, we use the 95% CI formula from sec-
tion 3.11.2, and substitute the values obtained from the simulation statistics:
N = 100, X = 1,087.90, and s = 146.15. The value for t(100−α/2)%,N−1 for
95% CI is the value of the 97.5th percentile of the standard t-distribution
with 99 degrees of freedom, which is 1.98. The 95% CI is therefore

1,087.90 −1.98 · 146.15
√
100
, 1,087.90 + 1.98 · 146.15
√
100

= ($1,058.90, $1,116.90).

Simulation Modeling
107
Therefore, if the 100 scenarios were independent when generated, we
can be 95% conﬁdent that the true average end-of-year capital will be be-
tween $1,058.90 and $1,116.90. It just happens that because of the simplic-
ity of the example, we know exactly what the true mean is. It is (1 + 0.0879) ·
1,000 = $1,087.90 because 8.79% was assumed to be the true mean of the
distribution of returns (see section 3.9 for calculating means of functions
of random variables), and it is indeed contained inside the 95% CI. In 5%
of all possible collections of 100 scenarios, however, we will be unlucky to
draw a very extreme sample of scenarios, and the true mean will not be
contained in the conﬁdence interval we obtain. Note that if we had calcu-
lated a 99% conﬁdence interval, then this would happen in only 1% of the
cases. If we generated 4N (instead of N) scenarios, then the 95% conﬁdence
interval’s length would be half of the current length. (This is because the
square root of the number of scenarios is contained in the denominator of
the expression that determines the length of the conﬁdence interval.) We
will revisit the issue of conﬁdence interval estimation and the implications
for accuracy again later in this chapter when we talk about the number of
scenarios needed in a simulation.
Also later in this chapter, we will explain how random numbers are
actually generated. We will see that drawing “independent” samples from
distributions is not the most efﬁcient way to simulate random numbers that
provide good representation of the underlying probability distribution. Most
simulation engines nowadays (including the simulation engines in @RISK
and MATLAB) use sophisticated methodology that estimates parameters
from the distribution of output variables of interest a lot more accurately.
The previous CI formula we used is in fact a conservative bound, rather than
an exact estimate, for the actual accuracy in estimating the mean. Still, it is
a useful benchmark to have.
4.2
WHY USE SIMULATION?
The example in the previous section illustrated a very basic MC simula-
tion system. We started out with a deterministic model that involved a
relationship between an input variable (market return ˜r0,1) and an output
variable of interest (capital at the end of one year ˜C1). We modeled the
input variable as a realization of a probability distribution (we assumed
a normal distribution), generated scenarios for that input variable, and
tracked what the value of the output variable was in every scenario by
computing it through the formula that deﬁnes the relationship between
˜C1 and ˜r0,1. This is the general form of simulation models illustrated in
Exhibit 4.1.

108
FUNDAMENTAL CONCEPTS
Despite its simplicity, this example allows us to point out one of the ad-
vantages of simulation modeling over pure mathematical modeling. Simula-
tion enables us to evaluate (approximately) a function of a random variable.
In this case, the function is very simple—the end-of-year capital, ˜C1, is de-
pendent on the realization of the returns through the equation (1 + ˜r0,1)C0.
If we are given a probability distribution for ˜r0,1, in some cases we can
compute the probability distribution for ˜C1 in closed form. For example, if
˜r0,1 followed a normal distribution with mean µ0,1 = E[˜r0,1] and standard
deviation σ0,1, then ˜C1 would follow a normal distribution too, with mean
(1 + µ0,1)C0 and standard deviation σ0,1C0.
However, if ˜r0,1 did not follow a normal distribution, or if the output
variable ˜C1 were a more complex function of the input variable ˜r0,1, it would
be difﬁcult and practically impossible to derive the probability distribution
of ˜C1 from the probability distribution of ˜r0,1. Using simulation simpliﬁes
matters substantially.
There are three other important advantages of simulation that can only
be appreciated in more complex situations. The ﬁrst one is that simulation
enables us to visualize the probability distribution resulting from compound-
ing probability distributions for multiple input variables. The second is that
it allows us to incorporate correlations between input variables. The third
is that simulation is a low-cost tool for checking the effect of changing a
strategy on an output variable of interest. Next, we extend the investment
example to provide illustrations of such situations.
4.2.1
Multiple Input Variables and
Compounding Distributions
Suppose now that you are planning for retirement and decide to invest
in the market for the next 30 years (instead of only the next year). Sup-
pose that your initial capital is still $1,000. You are interested in the re-
turn (and, ultimately, in the end-of-year capital, ˜C30) you will have after
30 years.
Let us assume that every year, your investment returns from investing in
the S&P 500 will follow a normal distribution with the mean and standard
deviation from the example in section 4.1.2. The ﬁnal capital you have will
depend on the realizations of 30 random variables—one for each year you
are invested in the market.6 We found through simulation in section 4.1.2
that the probability distribution of the capital at the end of the ﬁrst year
will be normal. What do you think the probability distributions for the total
return and the capital at the end of the 30th year will look like? Will they
be normal?

Simulation Modeling
109
As explained in Chapter 2, an investment of $1 at time 0 will grow to
(1 + ˜r0,1)(1 + ˜r1,2) . . . (1 + ˜rt−1,t) dollars at the end of year t, and the total
return ˜r0,t from time 0 to time t equals
˜r0,t = (1 + ˜r0,1)(1 + ˜r1,2) . . . (1 + ˜rt−1,t) −1.
Interestingly, the probability distribution of ˜r0,t is not normal, and nei-
ther is the distribution of the capital at the end of 30 years. (The latter is
basically a scaled version of the distribution of total return, since it can
be obtained as ˜C0,t = (1 + ˜r0,t) · C0, and the initial capital C0 is a constant
[nonrandom] number). In general, here are some useful facts to keep in mind
when dealing with multiple input probability distributions:
■When a constant is added to a random variable, as in 1 added to the
random variable ˜r0,1, the distribution of (1 + ˜r0,1) has the same shape
as the distribution of ˜r0,1; however, it is shifted to the right by 1.
■As we saw in section 3.9, when a random variable is added to another
random variable (e.g., ˜r0,1 + ˜r1,2), we cannot simply “add” the two
probability distributions. In fact, even in cases when the two distribu-
tions have the same shape, the probability distribution of the sum of
the random variables does not necessarily have the same shape. There
are some exceptions—for instance, if we add two independent normal
random variables, the probability distribution of the sum is normal.
However, holding aside this case, this is not true in general.
■In our example, we are multiplying two random variables, (1 + ˜r0,1)
and (1 + ˜r1,2) in order to obtain the total return. Products of random
variables are even more difﬁcult to visualize than sums of random vari-
ables. Again, it virtually never happens that a product of several random
variables, even if the random variables all follow the same probability
distributions, results in a random variable with that same probability
distribution. The lognormal distribution, which we introduced in sec-
tion 3.7.2 in the previous chapter, is a rare exception, and this is one
of the reasons that the lognormal distribution is used so often in ﬁnan-
cial modeling. (Speciﬁc applications of the lognormal distribution are
discussed in Chapter 12.)
Fortunately, simulation makes visualizing the probability distribution of
the product easy. Exhibit 4.3 presents the output distributions for total re-
turn and capital at the end of 30 years. (For instructions in how to create the
model, see Appendix B or C online, and then the summaries of instructions
in this chapter’s Software Hints.) We can observe (both from the graph and

110
FUNDAMENTAL CONCEPTS
5
6
Values in Thousands
Values x 10^–5
Total Amount of Money in Account
4
3
2
1
0
0
20
40
60
80
100
120
140
160
180
200
EXHIBIT 4.3
Output distribution for amount of capital after 30 years.
from the statistics for skewness and kurtosis) that the distribution is very
skewed, even though the distributions for individual returns in each of the
30 years were symmetric.
4.2.2
Incorporating Correlations
Let us now complicate the situation more. Suppose that you have the op-
portunity to invest in stocks and Treasury bonds over the next 30 years.
Suppose that today you allocate 50% of your capital to the stock market by
investing in the index fund, and 50% in bonds. Furthermore, suppose over
the 30 years you never rebalance your portfolio (i.e., you do not change
the allocation between stocks and bonds). What will be the portfolio return
after 30 years?
Historically, stock market and Treasury bond market returns have ex-
hibited extremely low, but often statistically signiﬁcant, negative correlation.
This is because these two asset classes tend to move in opposite directions.
When the stock market is performing poorly, investors tend to move their
money to what they perceive to be safer investments such as bonds; con-
versely, when the stock market is performing well, investors tend to real-
locate their portfolio increasing their allocation to the stock market and
reducing their allocation to bonds.
Visualizing the impact of multiple input variables at the same time and
incorporating correlations between these variables is very difﬁcult to do in
an analytical way. Simulation eliminates the need for complex mathematics,
but preserves the beneﬁts of creating richer and more accurate models. Cor-
relations can be incorporated implicitly (by generating joint scenarios for
realizations of input variables, e.g., by sampling from observed past data) or

Simulation Modeling
111
1.4
1.6
Values in Thousands
Total Amount of Money in Stocks and Bonds
1.2
1.0
0.8
0.6
0.4
0.2
0.0
0
10
20
30
40
50
60
70
80
Values X 10˄-4
EXHIBIT 4.4
Histogram and summary statistics of the capital after 30 years from
investing in the S&P 500 and Treasury bonds, taking into account the correlation
between the returns on stocks and bonds.
explicitly, by specifying a correlations matrix as an input to the simulation.
We will talk about incorporating the former technique further in Chapter 8.
(See also Practice 4.2 on the companion web site.) Here, we give an example
in which the correlations are speciﬁed as an input.
Let us assume that the correlation between the stock market and the
Treasury bond market returns will be about –0.2. Let us also assume for
the purposes of this exercise that the annualized return on the Treasury
bonds in your portfolio will be normally distributed with mean 4% and
standard deviation 7%. Therefore, the returns on the stock market and
the bond market follow a multivariate normal distribution with correlation
coefﬁcient –0.2.
Exhibit 4.4 shows the output distribution after generating 5,000 scenar-
ios for stock market (as measured by the S&P 500) returns and Treasury
bond returns over 30 years. (See the end of this chapter for instructions
on how to incorporate correlations in a simulation model with @RISK or
MATLAB.) The shape of the distribution of the capital available after
30 years is similar to the shape of the distribution from Exhibit 4.3, but
the variability is smaller. This issue is discussed further in the next section
and in Chapter 7.
4.2.3
Evaluating Decisions
In the end, the goal of using simulation is to help us make decisions. Is
a 50–50 portfolio allocation in stocks and bonds “better” than a 30–70
allocation? We will refer to the former allocation as Strategy A, and to the

112
FUNDAMENTAL CONCEPTS
2.0
1.8
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0
0
20
40
60
80
100
120
2.9
17.8
5.0%
1.2%
90.0%
92.6%
Values in Thousands
Total Amount in Account for A and B (overlayed)
Values X 10˄-4
EXHIBIT 4.5
Comparison of Strategy A (equal allocation to stocks and bonds)
and Strategy B (allocation of 30% to stocks and 70% to bonds).
latter as Strategy B. Let us evaluate the distribution of the capital at the end
of 30 years for each allocation strategy, and use that knowledge to decide
on the “better” allocation. Notice that it is unclear what “better” means in
the context of uncertainty. We need to think about whether “better” for us
means higher return on average, lower risk, acceptable trade-off between the
two, and so on. Exhibit 4.5 contains the summary statistics of the simulated
capital at the end of 30 years with each allocation over 5,000 scenarios.
We can observe that although Strategy A performs better than Strat-
egy B as evaluated based on the mean capital at the end of 30 years,
Strategy A’s standard deviation is higher. In terms of risk–return trade-
off, as measured by the coefﬁcient of variation, Strategy A’s CV is
67.57% (=$5,341.57/$7,905.30), whereas Strategy B’s CV is 53.29%
(=$3,219.06/$6,040.17), which makes Strategy A appear riskier than Strat-
egy B. This is apparent also from the overlay chart shown in Exhibit
4.5—much of the mass of the histogram for Strategy B is contained within
the histogram for Strategy A, which means that Strategy B has less variability
and results in less extreme outcomes than Strategy A. One lesson here, how-
ever, is that the standard deviation may not be a good measure of risk when
the underlying distributions are asymmetric. Strategy A’s 5th percentile, for
example, is higher than Strategy B’s 5th percentile, meaning that if you are
concerned with events that happen with 5% probability, Strategy A would
be less risky. Strategy A also has a higher upside—its 95th percentile is
higher than Strategy B’s 95th percentile.7 The fact that Strategy A has a high
upside “penalizes” its standard deviation relative to the standard deviation
of Strategy B because it results in more outcomes that are far away from the
mean. A high standard deviation is not necessarily a bad thing if the largest
deviations from the mean happen on the upside.

Simulation Modeling
113
3.0
0.00
Values in Thousands
+∞
Difference (A-B)
10.2%
89.8%
2.5
2.0
1.5
1.0
0.5
0.0
–5
0
5
10
15
20
25
30
35
40
45
50
Values X 10?-4
EXHIBIT 4.6
Histogram and summary statistics for the difference between the
capital at the end of 30 years with Strategy A and with Strategy B.
It should be clear from the discussion so far that the summary statistics
do not tell the whole story. It is important to look at the entire distribution
of outcomes. Suppose now that we would like to compare Strategy A to
Strategy B on a scenario-by-scenario basis. In what percentage of scenarios
does Strategy B perform better than Strategy A? One efﬁcient way to answer
this question is to create an additional variable, Difference (A-B), that keeps
track of the difference between the capital at the end of 30 years from
Strategy A and from Strategy B during the simulation. Exhibit 4.6 shows a
histogram of Difference (A-B) and presents its summary statistics.
It is interesting to observe that even though Strategy A appeared riskier
than Strategy B based on the summary statistics in Exhibit 4.5 (Strategy A’s
standard deviation was almost twice the standard deviation of Strategy B),
Strategy A results in lower realized outcomes than Strategy B in only 10.2%
of the 5,000 generated scenarios. (As the graph in Exhibit 4.6 illustrates,
10.2% of the 5,000 scenarios for Difference (A-B) have values less than
0.) This perspective on the risk of one strategy versus the risk of another
is valuable because it can substantially impact the ﬁnal decision on which
strategy to choose. For example, the problematic scenarios can be speciﬁcally
identiﬁed, and in some situations, such as capital budgeting, managerial
action can be taken to avoid them. A strategy that appears more risky may
therefore be selected if it is desirable for other qualitative reasons.
When comparing two alternative decisions under uncertainty, it is tech-
nically correct (and fair) to evaluate them under the same set of scenarios.
For example, when obtaining the summary statistics for Strategy A and
Strategy B earlier, we should have used the same set of 5,000 scenarios
for both. This would eliminate circumstances in which we happened to

114
FUNDAMENTAL CONCEPTS
generate more favorable scenarios when evaluating one of the strategies
than the other, which would have led us to conclude erroneously that the
strategy evaluated over the more favorable set of scenarios is better.
In principle, if we generate a huge number of scenarios for the two
strategies, even if the scenarios are not the same, the estimates will be quite
accurate. However, generating a large number of scenarios is time consum-
ing. Moreover, even a difference of a few digits after the decimal point may
be signiﬁcant in some ﬁnancial applications.
The RiskSimtable command in @RISK does what we want by
default—it generates the number of scenarios we specify, and then eval-
uates the values of the output variable over the same set of scenarios for
each value of the parameters in the RiskSimtable. Thus, comparing sum-
mary statistics of several strategies when the RiskSimtable command is
used is technically correct. However, RiskSimtable can be used only if one
parameter changes at a time. (In our example, we varied one parameter: the
percentage of capital to invest in stocks. The percentage to invest in bonds
was determined automatically based on how much capital was left.) If we
have a more complex situation with several parameters that can be tweaked,
we would need to run every simulation separately. In that case, we would
need to tell @RISK to simulate the same 5,000 scenarios even if we run the
simulation with two separate calls. The way to do this is to specify the seed
of the simulation under the Sampling tab of the dialog box that pops up after
clicking on the Settings Commands button. We will explain what exactly
the seed of the simulation is in section 4.4. For now, it is only important to
understand that it determines how the random numbers are generated. By
default, @RISK changes the seed every time it runs a simulation (as do other
simulation packages). If we enter a particular number for the seed (depend-
ing on the software, different ranges for possible seed values are available),
we will be ﬁxing the scenarios that will be generated, which would enable
@RISK to generate the same sequence of scenarios again next time it runs the
simulation. MATLAB has similar options for setting the seed in a simulation.
If the program is not too long, the relationships are not overly com-
plicated, and the intended number of scenarios is not too large, there is
an easier alternative way to ensure that decisions are evaluated over the
same set of scenarios. If we are evaluating the portfolio allocation example
from this section in a spreadsheet, we can dedicate speciﬁc cells to the input
variables (returns) that are common to all strategies we need to evaluate
(see the models in this chapter’s Software Hints). We can then reference the
same cells during a simultaneous simulation for the capital at the end of the
30 years with each strategy, as is done in worksheet Stock + Bond (2) of
the ﬁle Ch4-ReturnSim.xlsx. This will ensure that the same realizations of
the input random variables in those cells are used for computing the output

Simulation Modeling
115
values for all strategies. In a programming language like MATLAB, we can
dedicate variables in our program that store the generated scenarios, and
then evaluate all the different strategies over that same set of scenarios. Stor-
ing 5,000 scenarios is not a problem, but if there are multiple variables and
the number of scenarios increases substantially, we could run into memory
problems.
4.3
IMPORTANT QUESTIONS IN
SIMULATION MODELING
4.3.1
How Many Scenarios?
A simulation may not be able to capture all possible realizations of un-
certainties in the model. For instance, think about the distribution of the
end-of-year capital in section 4.1.1. As we explained in section 4.1.2., the
possible number of values for the simulation output variable—the end-of-
year capital—is technically inﬁnite. Thus, we could never obtain the exact
distribution of ˜C1 or the exact expected value ˜C1 by simulation. We can,
however, get close. The accuracy of the estimation will depend on the num-
ber of generated scenarios. As discussed in section 4.1.2, if the scenario
generation is truly random, then the variability (the standard error) of the
estimate of the true expected value will be s/
√
N, where s is the standard de-
viation of the simulated values for the output variable, and n is the number
of scenarios.
Hence, to double the accuracy of estimating the mean of the output dis-
tribution, we would need to quadruple (roughly) the number of scenarios.
For instance, in the example in section 4.2, we generated 100 scenarios, and
calculated that the average capital after one year is $1,087.90, and that the
95% CI for the estimate of the average capital is ($1,058.90, $1,116.90).
We concluded that we can be 95% conﬁdent that the true expected capi-
tal will be between $1,058.90 and $1,116.90, that is, that the true mean
will not be further than $29 from the mean estimated from the simula-
tion ($1,087.90). Now suppose that we had obtained the same numbers
for sample mean ($1,087.90) and sample standard deviation ($146.15), but
we had generated four times as many (400) scenarios. The 95% CI would
have been

1,087.90 −1.97 · 146.15
√
400
, 1,087.90 + 1.97 · 146.15
√
400

= ($1,073.53, $1,102.27)8

116
FUNDAMENTAL CONCEPTS
This means that we could be 95% conﬁdent that the true mean would
not be more than $14.37 from the simulated mean of $1,087.90, which is
about half of the amount by which we could be off ($29) when we generate
100 scenarios. Therefore, our accuracy has increased about twofold after
quadrupling the number of generated scenarios.
Increasing the number of scenarios to improve accuracy can get expen-
sive computationally, especially in more complicated multiperiod situations
such as the simulation of a 30-year investment in section 4.2.1. Fortunately,
there are modern methods for generation of random numbers and scenarios
that can help reduce the computational burden.
While the average output from a simulation is important, it is often
not the only quantity of interest, something that practitioners tend to forget
when using simulation to value complex ﬁnancial instruments. As we will
see from the applications in this book, for example, in assessing the risk of
a portfolio, a portfolio manager may be interested in the percentiles of the
distribution of outputs, or the worst-case and best-case scenarios. Unfortu-
nately, it is not as straightforward to determine the accuracy of estimates
of percentiles and other sample statistics from a simulation. There are some
useful results from probability theory that apply (see, for example, Chap-
ter 9 in Glasserman 2004), and we can use bootstrapping, as described in
section 3.11.3. However, in general, the question of how many scenarios
we should generate to get a good representation of the output distribution
does not have an easy answer. This issue is complicated further by the fact
that results from probability theory do not necessarily apply to many of the
scenario generating methods used in practice, which do not simulate “pure”
random samples of observations, but instead use smarter simulation meth-
ods that reduce the number of scenarios needed to achieve good estimate
accuracy. Some of these methods are discussed later in this chapter and in
Chapter 14.
4.3.2
Estimator Bias
The statistical concept of estimator bias is important in simulation applica-
tions because it shows whether an estimator (a sample statistic) estimates the
“right thing” on average (i.e., whether it approaches the true parameter one
needs to estimate given a sufﬁcient number of replications). For example,
the average obtained from a sample of scenarios is an unbiased estimator
of the true mean of a distribution because if we generate many samples and
compute the sample averages, the average of these averages will approach
the true mean. Depending on the way scenarios are generated, however,
one may introduce a bias in the estimate of the parameter of interest. (This
parameter does not need to be the mean of the distribution.) The magnitude
of the bias is determined by the difference between the average value of the

Simulation Modeling
117
estimator that would be obtained if we generated many, many samples, and
the true value of the parameter we are trying to estimate.
Let us go back to the multiperiod retirement planning example in sec-
tion 4.2.1. We compounded the returns of the original capital of $1,000
every year to obtain the return distribution of over 30 years. Intuitively,
though, returns should be compounded a lot more frequently to obtain a fair
representation of a continuously compounded total return. The fact that we
“discretized” the sample space by considering speciﬁc points of evaluation
of the returns introduced an error, a bias, in our estimate of the total return.
This issue is important in the evaluation of ﬁnancial derivatives, which we
will see in Part Four. Prices of ﬁnancial instruments are typically assumed
to follow continuous random processes, but time is often discretized when
constructing simulation models. The average of the outcomes (the expected
present value) is considered the fair price of the ﬁnancial instrument; how-
ever, simulating asset prices in this manner generates a bias in the estimate
of the expected present value because the simulated changes in the asset
price along the way are not continuous or instantaneous, but happen over
a ﬁxed-length time interval. This kind of bias is referred to discretization
error bias. In some cases, such as the case of geometric Brownian motion
with ﬁxed drift and volatility which is discussed in Chapter 12, we can
obtain an unbiased estimator of the average ﬁnancial derivative payoff by
simulating future asset prices with a continuous-time formula. However, in
many instances it is not possible to ﬁnd such a closed-form expression for
the future asset price. For example, such a formula does not exist when the
volatilities for asset prices are time-dependent, or when one uses a mean-
reversion process to describe the evolution of the underlying price. (Such
random processes are discussed in Chapter 12.) In such cases, we can reduce
the time interval length to reduce the bias, but it is important to keep in mind
that reducing the time interval length increases the number of steps neces-
sary to generate a random “path” for the future asset price, and becomes
computationally expensive.
4.3.3
Estimator Efficiency
If there are two ways to obtain an estimate of a quantity of interest and the
estimators are otherwise equivalent in terms of bias, which estimator should
be preferred; that is, which estimator is more “efﬁcient”? For example,
consider two unbiased estimators of the mean, both of which are obtained
as averages from a sample of independent replications. Their standard errors
will be given by
s1
√N1
and
s2
√N2

118
FUNDAMENTAL CONCEPTS
where s1 and s2 are the standard deviations from the samples of scenarios,
and N1 and N2 are the number of scenarios for each of the estimators.
Statistical theory states that one should prefer the estimator with the smaller
standard deviation because it is more accurate.
In the case of simulation, however, such statistical concepts need to
be extended to include numerical and computational considerations. For
example, suppose that it takes longer to generate the scenarios for the esti-
mator with the smaller standard deviation. Is that estimator still preferable,
given that one can use the extra time to generate additional scenarios for
the other estimator, thus reducing the latter estimator’s standard error? It
is natural (and theoretically justiﬁed) to modify the statistical measure of
variability and efﬁciency so that it includes a concept of time. If τ 1 and τ 2
are the times it takes to generate one scenario for each of the two estimators,
then one should select the estimator with the smaller of the time-adjusted
standard errors s1
√τ1, s2
√τ2.
4.4
RANDOM NUMBER GENERATION
At the core of Monte Carlo simulation is the generation of random num-
bers. In fact, however, generating random numbers from a wide variety of
distributions reduces to generating random numbers from the continuous
uniform distribution on the unit interval [0,1], that is, to generating random
numbers on the interval [0,1] in such a way that each value between 0 and
1 is equally likely to occur.9 Many computer languages and software pack-
ages have a command for generating a random number between 0 and 1:
=RAND() in Excel, rand(1) in MATLAB and FORTRAN, and ‘‘rand()’’
in C++.
4.4.1
Inverse Transform Method
A common method for converting a random number between 0 and 1 to a
number from an arbitrary probability distribution is to evaluate the so-called
“inverse” of the cumulative probability distribution function at the random
number u generated from a continuous uniform distribution (denoted by
F −1(u)). The idea works because the total mass for a probability distribution
is always 1, and the cumulative probability for any value of the distribution
(deﬁned as the probability that this particular value or any value below it
will occur) is always between 0 and 1. In effect, you can imagine that by
generating a random number between 0 and 1, you are picking a number
on the horizontal axis of the CDF plots in Exhibit 3.7 in the previous
chapter. As we mentioned in Chapter 3, the shape of the CDF depends on

Simulation Modeling
119
the speciﬁc probability distribution. To generate a random number from a
probability distribution with a speciﬁc CDF, we can track the x-coordinate
for the point on the CDF that has the random number between 0 and 1 as
a y-coordinate. Note that if a particular value from the distribution of the
random variable happens with high probability, the CDF evaluated at that
point on the horizontal axis will contain a long vertical segment. A uniform
random number generated on [0,1] will have a larger chance of falling in a
segment that is long, and so the value from the distribution we would like
to simulate will indeed happen with higher probability.
The Inverse Transform for Discrete Distributions
To give a concrete
example, let us see how “inverting” the cumulative probability distribution
works for discrete distributions. Suppose that given a random number gen-
erator for numbers between 0 and 1, we would like to simulate values for a
random variable that takes the value 5 with probability 50%, the value 15
with probability 30%, and the value 35 with probability 20%. Exhibit 4.7
illustrates the CDF of this probability distribution. Let us split the unit in-
terval [0,1] on the vertical axis into three intervals based on the cumulative
probabilities 50%, 80%, and 100% for obtaining the values 5, 15, and 35:
[0,0.5], (0.5,0.8], and (0.8,1]. If the random number that is drawn from the
uniform distribution falls in the interval [0,0.5] (which happens 50% of the
time if the number generator is truly random), then we trace the value on the
horizontal axis that corresponds to the point on the CDF with y coordinate
equal to the generated random number, and record that value (which is 5)
for that trial. If the random number is in the interval (0.05, 0.8] (which
1.0
0.9
0.8
0.7
0.6
0.5
CDF
0.4
0.3
0.2
0.1
0.0
0
5
10
15
20
25
30
35
40
x
EXHIBIT 4.7
Graph of the CDF of a discrete distribution.

120
FUNDAMENTAL CONCEPTS
happens with probability 30%), then we record a value of 15 for that trial.
Finally, if the random number is in the third interval (which happens with
probability 20%), we record a value of 35. Thus, if many trials are run, the
values 5, 15, and 35 are generated with the desired probabilities.10
The Inverse Transform for Continuous Distributions
Some probabil-
ity distributions have closed-form expressions for their inverse cumulative
distributions. The exponential distribution is one such example. In sec-
tion 3.7.2, we introduced the PDF of the exponential distribution:
f (x) = λe−λx,
x ≥0
The CDF of the exponential distribution can be computed as11
F(x) = P(X ≤x) =
x

0
λe−λtdt
=

−1
λλe−λt

t=x
−

−1
λλe−λt

t=0
= −e−λx −(−e−λ·0)
= 1 −e−λx.
To compute the inverse function, we express x in terms of the CDF F(x).
We have
e−λx = 1 −F(x),
therefore,
x = −1
λ ln (1 −F(x)) .
If we generate a random number between 0 and 1 for F(x), we can use
this expression to ﬁnd the corresponding random number x that comes from
an exponential distribution.
The inverse transform method can be viewed as a method of picking
random percentiles from a particular distribution. To build further intuition,
let us generate a random number from a normal distribution with mean µ
and standard deviation σ. Suppose we request a random number between
0 and 1, and the random number generator returns 0.975. To ﬁnd the
uniquely corresponding random number from a normal distribution with

Simulation Modeling
121
mean µ and standard deviation σ, we ﬁnd the value on the horizontal axis
for a normal distribution with mean µ and standard deviation σ so that
97.5% of the probability mass (the area under the PDF) is to the left of that
value.12 In contrast to the exponential distribution, however, the percentiles
of the normal distribution cannot be calculated in closed form. A random
number generator would approximate the inverse of the cumulative normal
distribution function at a particular point.
While the inverse transform method is widely used, alternative meth-
ods exist for generating random numbers from distributions for which the
inverse of the CDF is not easy to compute. Such methods include:
■The acceptance-rejection method.
■The composition method.
■The ratio of uniforms method.
Most of these methods, however, still rely on generating random num-
bers from the uniform distribution on [0,1]. For more details, see Fishman
(2006) and Glasserman (2004).
Because the normal distribution is so widely used in practice, a num-
ber of methods have been developed speciﬁcally for efﬁcient simulation of
univariate and multivariate normal random variables. Such methods in-
clude the Box-Muller algorithm (Box and Muller 1958), and the Beasley-
Springer-Moro methodology for approximating the inverse normal distri-
bution (Beasley and Springer 1977; Moro 1995).
4.4.2
What Defines a “Good” Random
Number Generator?
Given the discussion in the previous section, generating “good” uniform
random numbers on [0,1] is critical for the performance of simulation algo-
rithms. Interestingly, deﬁning “good” random number generation is not as
straightforward as it appears. Early random number generators tried to use
“truly random” events for random number generation, such as the amount
of background cosmic radiation. In practice, however, this kind of random
number generation is time consuming and difﬁcult. Moreover, it was realized
that the ability to reproduce the random number sequence and to analyze
the random number characteristics is actually a desirable property for ran-
dom number generators. In particular, the ability to reproduce a sequence
of random numbers allows for reducing the variance of estimates and for
debugging computer code by rerunning experiments in the same conditions
in which they were run in previous iterations of code development.
Most simulation software employs random number generation algo-
rithms that produce streams of numbers that appear to be random, but in

122
FUNDAMENTAL CONCEPTS
fact are a result of a clearly deﬁned series of calculation steps in which the
next “random number” xn in the sequence is a function of the previous
“random number” xn−1, that is, xn = g(xn−1). The sequence starts with a
number called the seed, and if the same seed is used in several simulations,
each simulation sequence will contain exactly the same numbers, which is
helpful for running fair comparisons between different strategies evaluated
under uncertainty. It is quite an amazing statistical fact that some of these
recursion formulas (named pseudorandom number generators) deﬁne se-
quences of numbers that imitate random behavior well and appear to obey
(roughly) some major laws of probability, such as the the central limit the-
orem (section 3.11.1) and the Glivenko-Cantelli Theorem.13
In general, a pseudorandom number generator is considered “good” if
it satisﬁes the following conditions:
■The numbers in the generated sequence are uniformly distributed be-
tween 0 and 1. This can be tested by running a chi-square or a
Kolmogorov-Smirnov test.
■The sequence has a long cycle (i.e., it takes many iterations before the
sequence begins repeating itself).14
■The numbers in the sequence are not autocorrelated.15 This can be veri-
ﬁed by running a Durbin-Watson test on the sequence of numbers. The
Durbin-Watson test is widely used in statistics for identifying autocor-
relation in time series of observations.
Next, some important types of pseudorandom number generators are
surveyed. The goal is not to provide comprehensive coverage of random
number generators, but rather to give you a ﬂavor of the main ideas behind
the method of producing apparently random numbers with deterministic
algorithms.
4.4.3
Pseudorandom Number Generators
One of the earliest pseudorandom number generators is called the midsquare
technique. It takes a number (the seed), squares it, and uses the set of middle
digits as the next random number. For example, suppose that the seed is
5381. (It can be any number.) The members of the sequence of random
numbers between 0 and 1 are then generated as
53812 = 28955161; middle four digits = 9551; random number
= 0.9551,
95512 = 91221601; middle four digits = 2216; random number
= 0.2216,
and so forth.

Simulation Modeling
123
It is easy to predict when such an approach may run into difﬁculties.
As soon as the “middle digits” become a small number such as 1 or 0, the
sequence ends with the same numbers generated over and over again, that
is, the sequence converges to a constant value such as 0 or to a very short
cycle of values.
A better, commonly used type of pseudorandom number generator is
congruential pseudorandom number generators. They generate a sequence
of numbers of the form
xn = g(xn−1) mod m,
where mod m stands for “modulus m.” g(xn−1) mod m is the remainder after
dividing g(xn−1) by m. For example, 5 mod 3 = 2, 15 mod 5 = 0, and so on.
The remainder is then scaled by another number, for example, divided by
m, and the resulting number is used as the uniform random number on the
interval [0,1]. Note that g(xn−1) mod m will always be an integer between 0
and m−1. Thus, to create a good representation of randomness, one would
want to make the range for the modulus as large as possible. For a 32-bit
computer, for example, the maximum integer that can be stored is 231 – 1,
which is large enough for practical purposes.
As an example, consider a simple linear congruential pseudorandom
generator of the form
xn = Axn−1 mod m.
(It is called linear because Axn−1 is a linear function of xn−1.) The ﬁrst
number in the sequence, x0, is the seed. Algebraically, the expression for
generating xn above can be written as16
xn = Axn−1 −m
 Axn−1
m

.
(The lower brackets notation is standard for “largest integer less than or
equal to Axn−1/m.) Then, the sequence of fractions xn/m is used as a se-
quence of pseudorandom numbers on the interval [0,1].
Suppose A = 3, m = 10, and the seed x0 = 1052. We have the following
sequence of random numbers:
x1 = 3 · 1052 −10 ·
3 · 1052
10

= 3 · 1052 −10 · ⌊315.6⌋
= 3 · 1052 −10 · 315 = 6.

124
FUNDAMENTAL CONCEPTS
Therefore, the random number is 6/10, or 0.6.
x2 = 3 · 6 −10 ·
3 · 6
10

= 3 · 6 −10 · ⌊1.8⌋= 3 · 6 −10 · 1 = 8
Therefore, the next random number is 8/10, or 0.8, and so on.
More generally, advanced random number generators include:
■Linear congruential generators (LCGs).
■Multiplicative recursive generators (MRGs).
■Feedback shift registers (FSRs).
■Generalized feedback shift registers (GFSRs).
■Combined multiplicative recursive generators (CMRGs).
■Twisted generalized feedback shift registers (TGFSRs).
■Add-with-carry (AWC) and subtract-with-borrow (SWB) generators.
■Inversive generators (IG).
FSRs, GFSRs, and TGFSRs generate new numbers by operating re-
cursively on bits of previously generated random numbers. LCGs, MRGs,
CMRGs, AWC/SWB and IGs operate recursively on previously generated
random numbers. For more details, see, for example, McLeish (2005) and
Fishman (2006). Most pseudorandom number generators used in popular
software products nowadays have been thoroughly tested and are quite
good, but it is important to keep in mind that pseudorandom number gen-
erators in software packages that are not explicitly built for simulation
purposes (such as Excel) are usually not as good as random number gener-
ators in specialized simulation/mathematical software (such as @RISK and
MATLAB).
4.4.4
Quasirandom (Low-Discrepancy) Sequences
A truly random number generator may produce clustered observations
(see Exhibit 4.8(A)), which necessitates generating many scenarios in or-
der to obtain a good representation of the output distribution of interest.
Quasirandom sequences instead ensure a smooth representation of the range
by continuously “ﬁlling in” gaps on the unit interval [0,1] left by previously
generated random numbers (see an example of 1,000 generated values of a
quasirandom sequence in Exhibit 4.8(B)). The term “quasirandom” is actu-
ally a misnomer because, unlike pseudorandom number sequences, quasiran-
dom number sequences do not pretend to be random. They are deterministic
on purpose, and their roots can be found in real analysis and abstract algebra
rather than in simulation or probability theory. The term low discrepancy

Simulation Modeling
125
(A)
(B)
EXHIBIT 4.8
One thousand simulated number values for two uniform random
variables on the interval [0,1]: (A) Pseudorandom number generator; (B) Sobol
quasirandom sequence.
sequences is often used interchangeably with the term quasirandom se-
quences, and is more accurate.
Famous quasirandom sequences include Sobol (1967), Faure (1982),
Halton (1960), and Hammersley (1960). These sequences build on a family
of so-called Van der Corput sequences.17 For example, the Van der Corput
sequence of base 2 is
1
2, 1
4, 3
4, 1
8, 5
8, 3
8, 7
8, . . .
The actual generation of Van der Corput sequences is somewhat tech-
nical, but the outcome is intuitive. Note that as new points are added to the
sequence, they appear on alternate sides of 1
2 in a balanced way. The main
idea is that as the number of generated values increases, the sequence covers
uniformly the unit interval.
The values generated with quasirandom sequences are treated as “ran-
dom” numbers for the purposes of simulation modeling. In particular, in-
stead of generating random numbers between 0 and 1 and “inverting” them
to obtain an arbitrary probability distribution, we would “invert” the num-
bers in the quasirandom sequence. Different sequences have different advan-
tages for speciﬁc ﬁnancial applications, but the Faure and Sobol sequences in
particular have been proven to generate very accurate estimates for deriva-
tive pricing in tests.18 We will see applications of quasirandom sequences
when the pricing of mortgage-backed securities and other ﬁnancial deriva-
tives are discussed in Chapters 14 and 15.

126
FUNDAMENTAL CONCEPTS
4.4.5
Stratified Sampling
A variety of so-called variance reduction techniques are used to speed up
execution and improve accuracy in simulations. We discuss some of them in
the context of ﬁnancial derivative pricing in Chapter 14. Here, we will intro-
duce one kind of random number generation—stratiﬁed sampling—that is
now the default method of sampling in some simulation software packages
such as @RISK. The term stratiﬁed sampling is used because of the anal-
ogy with the statistical methodology of collecting a representative sample
by dividing the population into groups, or strata, of similar characteristics,
and collecting information about each strata. This technique ensures that all
important groups are represented in the ﬁnal sample.
Similar to quasirandom number generation, stratiﬁed sampling tries
to address the problem of “clustering observations” we mentioned in sec-
tion 4.4.4. In contrast to quasirandom number generator techniques, how-
ever, which are deliberately nonrandom, stratiﬁed sampling preserves some
degree of randomness. It just tries to “distribute” the randomness along the
entire range of the probability distribution by dividing the ranges of possible
values for every input random variable into a ﬁxed number of strata, and
simulating values over these ranges.
Stratiﬁed sampling is valuable not only because it improves accuracy,
but also because it helps include extreme observations into the simulation.
Observations in the tails of input distributions that are typically less likely
to be generated may never occur in a simulation because the probability of
their occurrence is small. Such observations, however, contain important
information about extreme events that are of particular interest in ﬁnancial
applications. In order to ensure that they appear in the simulation, one
would have to generate a huge number of scenarios.
A simple example of stratifying the numbers in the [0,1] interval is to
divide the [0,1] interval into k smaller intervals of equal length:

0, 1
k

,
1
k, 2
k

, . . . ,
k −1
k
, 1

.
Random numbers can then be drawn sequentially from each small in-
terval. Therefore, values from the tails of the distribution of interest (which
will be generated when uniform random numbers from the intervals [0, 1
k]
and ( k−1
k , 1] are drawn) obtain better representation.
In multiple dimensions (i.e., when simulating several random variables),
this method extends to dividing a hypercube (as opposed to an interval) into
smaller hypercubes, and drawing an observation along each dimension of the
smaller hypercubes. The sample size required to cover all strata, however,

Simulation Modeling
127
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
x1
x 2
EXHIBIT 4.9
A Latin hypercube sample for two random variables (p = 2) and
10 strata along each dimension (k = 10).
may become prohibitive. Suppose, for example, that you have k intervals
(strata) for each of p dimensions (each of p random variables). This means
that there are kp hypercubes, that is, we need to simulate at least kp random
numbers in order to have a number in each stratum. Generating random
numbers, however, is computationally expensive. An enhanced extension to
the basic stratiﬁed sampling method is Latin Hypercube Sampling (an op-
tion in many advanced simulation software products, including @RISK and
MATLAB), which permutes the coordinates of an initially generated random
vector of observations—one observation within each small hypercube—to
reduce the number of times an actual random number is generated while
ensuring that all strata are sufﬁciently well-represented (see Exhibit 4.9).
The method works as follows. First, we generate a random number
within each small interval along each dimension. In the example in Ex-
hibit 4.9, where we have two random variables (i.e., two dimensions), we
would generate random numbers
x(1)
1 , . . . , x(k)
1

128
FUNDAMENTAL CONCEPTS
along the ﬁrst dimension, and numbers
x(1)
2 , . . . , x(k)
2
along the second dimension. If we consider points with coordinates
(x(1)
1 , x(1)
2 ), . . . , (x(k)
1 , x(k)
2 )
we would have random points in all of the little squares along the diagonal of
the large [0,1] square. The ﬁrst point is a point in the little square [0, 1
k]2, the
second point is a point in the little square ( 1
k, 2
k]2, and so on. (In multiple di-
mensions, combining the random numbers for the corresponding small inter-
vals to create random points with p coordinates would create random points
in the little hypercubes along the main diagonal of the [0,1] hypercube.)
Now permute the coordinates of the points along each dimension.19 For
example, consider the points
(x(10)
1
, x(3)
2 ), (x(2)
1 , x(1)
2 ) . . . , (x(k−3)
1
, x(2)
2 ).
In other words, the ﬁrst coordinates are still the random numbers we
generated along the ﬁrst dimension, and the second coordinates are still
the random numbers we generated along the second dimension, but the
order of the random numbers within each dimension has changed. The new
points are not all in the hypercubes around the diagonal, and, as Exhibit 4.9
illustrates, exactly one random point falls in each of the k small intervals into
which each axis is partitioned. If we consider all possible permutations of
these coordinates, we will ﬁll all small hypercubes. Thus, we would perform
stratiﬁed sampling by generating only k · p random numbers (and permuting
them), rather than generating kp random numbers.20
SUMMARY
■Monte Carlo (MC) simulation is a valuable tool for evaluating func-
tional relationships between variables, visualizing the effect of multiple-
correlated variables, and testing strategies.
■MC simulation involves creating scenarios for output variables of inter-
est by generating scenarios for input variables for which we have more
information. The art of MC simulation modeling is in selecting input
probability distributions wisely and interpreting output distributions
carefully.

Simulation Modeling
129
■The distributions of output variables can be analyzed by statistical
techniques. Statistics of interest include measures of central tendency
(average, mode), measures of volatility (standard deviation, percentiles),
skewness, and kurtosis. Minima and maxima from simulations should
be interpreted with care because they often depend on the input
assumptions and are very sensitive to the number of trials in the
simulation.
■The accuracy of estimation through simulation is related to the number
of generated scenarios. Unfortunately, the relationship is nonlinear—in
order to double the accuracy, we need to more than quadruple the
number of scenarios.
■Generating a random number from an arbitrary probability distribution
in many cases reduces to generating a random number from the uniform
distribution on the interval [0,1].
■Random number generation is not trivial, and simulation software pack-
ages do not produce truly “random” numbers. There is value, however,
in generating random number sequences that are replicable, and thus
not completely random.
■Pseudorandom number generators attempt to imitate random behavior
by creating sequences of random numbers that obey statistical laws.
■Quasirandom number generators do not pretend to generate random
numbers—they try to address the “clustering” problem observed in truly
random number generation, and ensure a smooth representation of the
range of the distribution by continuously “ﬁlling in” gaps on the unit in-
terval [0,1] left by previously generated random numbers. Quasirandom
sequences that have been particularly successful in ﬁnancial applications
include the Faure and Sobol sequences.
■Stratiﬁed sampling, of which Latin Hypercube Sampling is an advanced
example, aims to provide good representation of a probability dis-
tribution by dividing the range of the random variable into smaller
ranges or “strata,” and generating random numbers within each stra-
tum. This method “disperses” simulated values more evenly over the
range of the distribution, addresses the clustering problem of random
number generation, and provides better representation for the tails of the
distribution.
SOFTWARE HINTS
There is a variety of software packages for simulation. Appendixes B and
C, contain introductions to @RISK and MATLAB. Next, we review the
implementation of the examples in Chapter 4 with @RISK and MATLAB.

130
FUNDAMENTAL CONCEPTS
@RISK
The implementation of the models in sections 4.1 and 4.2 is in the ﬁle Ch4-
ReturnSim.xlsx. We use yellow background to indicate input cells, and red
background to indicate output cells in the models. Instructors who would
like to use this example in class can clear the contents of all of the yellow
and red cells, distribute the rest of the ﬁle as a template to the students, and
walk the class through the @RISK commands and the construction of the
spreadsheet during lecture.
Example from Section 4.1.2
Worksheet 1 Year contains the simulation of
the amount of money available at the end of the ﬁrst year after investing
at the stock market. Exhibit 4.10 is a screenshot of the spreadsheet with
the formulas in each cell. Cell B11 contains the @RISK formula for normal
distribution with mean stored in cell B7 and standard deviation stored in
cell C7. Cell D11 is the output cell—it stores the values for the amount of
money in the account at the end of one year as @RISK simulates scenarios
for the return in cell B11.
Example from Section 4.2.1
Worksheet 30 Years contains the simulation
of the amount of money available after investing in the stock market at the
end of 30 years. It is ﬁlled out in the same way as worksheet 1 Year, but
there are 30 rows of data. (The implicit assumption in this model was that
stock returns were not correlated across years.) Exhibit 4.11 is a screenshot
of the spreadsheet with the formulas ﬁlled out. (Note that rows 13–38 are
hidden. To unhide them, highlight rows 2 through 39, right-click and select
Unhide from the shortcut menu.) Start by ﬁlling out the @RISK formula
for normal distribution in cell B11. Copy and paste the formula down to
include cell B40. Then, ﬁll out the amount of money available at the end
of each year as a product of the amount of money available in the previous
EXHIBIT 4.10
Worksheet 1 Year in ﬁle Ch4-ReturnSim.xlsx.

Simulation Modeling
131
EXHIBIT 4.11
Worksheet 30 Years in ﬁle Ch4-ReturnSim.xlsx.
year times (1 + the return realized over the year). Cell D41 is the @RISK
output cell that will keep track of the money at the end of 30 years.
Example from Section 4.2.2
Worksheet Stock + Bond contains the simu-
lation model for the portfolio of stocks and bonds with portfolio weights of
50% in each investment. Exhibit 4.12 is a screenshot of the spreadsheet with
a speciﬁc scenario generated for stock and bond returns over the 30-year pe-
riod. (Note that rows 13–18 are hidden.) Important formulas to note are:
■Columns B and E contain returns as before. Column B contains returns
for the stock market with the same probability distribution (normal) and
the same parameters from cells B7 and C7. Column E contains input
cells for the simulation of bond returns with the mean and the standard
deviation from cells B8 and C8.
■To incorporate the effect of correlations, we need an additional argu-
ment in the @RISK formula for distribution assumptions. For example,
instead of
= RiskNormal($B$7,$C$7)
to simulate a normal random variable for the stock return in cell B11,
we would enter
= RiskNormal($B$7,$C$7,RiskCorrmat($D$7:$E$8,1,A11)),
instead of
= RiskNormal($B$8,$C$8)

132
FUNDAMENTAL CONCEPTS
to simulate a normal random variable for the bond return in cell E11,
we would enter
= RiskNormal($B$8,$C$8,RiskCorrmat($D$7:$E$8,2,A11)).
The additional argument RiskCorrmat(Array,Position,Instance)
refers to a correlation matrix stored in Array in which the variable we
are simulating corresponds to row (and column) Position. (For example,
Stocks were in the ﬁrst row/column of the correlation matrix, and Bonds
were in the second row/column; hence the Position argument for simulat-
ing stock return realizations was 1, and the Position argument for simu-
lating bond return realizations was 2.) Instance is an optional argument
which is used when multiple groups of inputs reference the same correlation
matrix. It basically tells @RISK whether the correlated values it generates
should be correlated within all groups, or only within a particular group.
In our example, we assumed that stock and bond returns are correlated at
each time period, but not across time periods, so we speciﬁed a separate
instance for each time period (which we made equal to the index of the
corresponding time period).
Instead of specifying an extra argument in the @RISK probability dis-
tribution formula for the input variables, we can incorporate correlations
also by clicking on the Deﬁne Correlations button in the @RISK ribbon.
There we have the option also to request that correlations are speciﬁed for
a time series, and @RISK automatically assigns a new instance to each row
of inputs to be correlated.
EXHIBIT 4.12
Worksheet Stock + Bond in ﬁle Ch4-ReturnSim.xlsx.

Simulation Modeling
133
Example from Section 4.2.3
Worksheet Stock + Bond (2) contains the sim-
ulation model for the portfolio of stocks and bonds with portfolio weights
of (50%, 50%) or (30%, 70%) in each investment. Exhibit 4.13 is a screen-
shot of the spreadsheet with a speciﬁc scenario generated for stock and
bond returns over the 30-year period. Cell H41 contains the output variable
for Strategy A. Cell L41 contains the output variable for Strategy B. Cell
I45 contains an output variable for the difference between the outcomes of
Strategy A and Strategy B to enable the scenario-by-scenario analysis in sec-
tion 4.2.3. An important fact to note is that the calculations of the Money
in stocks and Money in Bonds for Strategy B in each time period (columns
J and K) refer to the realization of stock and bond returns in columns B
and E (implicitly by referring to columns C and F)—columns that are also
referenced in the calculations of the Money in stocks and Money in Bonds
for Strategy A in each time period (columns D and G).
To illustrate how RiskSimtable can be used to check different strate-
gies and ensure that we evaluate the strategies over the same set of scenarios,
we have created a worksheet Stock + Bond (3) in the same ﬁle. The spread-
sheet is the same as the spreadsheet used in Exhibit 4.12), but cell F7 now
contains the formula =RiskSimtable({0.5,0.3}). In order for this to work
correctly, you need to also make sure that the portfolio weight for bonds
in cell F8 is linked to the portfolio weight for stocks through the formula
=1-F7, so that when @RISK ends the ﬁrst simulation and changes the weight
for stocks from 0.5 to 0.3, the weight for bonds is modiﬁed automatically in
such a way that the portfolio weights still add up to 1. Finally, as explained
in Appendix B, make sure that the number of simulations in the @RISK
main ribbon is set to 2 before running the simulation—this will ensure that
@RISK runs through the two values for stock portfolio weights speciﬁed in
RiskSimtable.
EXHIBIT 4.13
Worksheet Stock + Bond (2) in ﬁle Ch4-ReturnSim.xlsx.

134
FUNDAMENTAL CONCEPTS
MATLAB
Example from Section 4.1.2
Let us explain how to obtain the output in sec-
tion 4.1.2 in MATLAB. First, we store the initial capital in the variable C0:
>> C0 = 1000;
MATLAB has commands for generating the most commonly used random
numbers directly. For example, a normal random variable can be simulated
with
>> normrnd(mean,stdev,numRows,numColumns)
In the previous expression, mean and stdev are the mean and the stan-
dard deviation of the normal random variables. numRows and numColumns
specify the dimension of the array of random numbers we would like to
generate. For example in section 4.1.2, use the command
>> return01 = normrnd(.0879,.1465,100,1)
to generate 100 values for the return over the next year and assign them to a
vector array return01 of dimension (100 rows, 1 column). Then, compute
the distribution of your money at the end of the ﬁrst year by entering the
command
>> C1 = (1 + return01)*C0
This will create a vector array of 100 values for the capital at the end of
year 1. We can then use this array to create graphs and compute descriptive
statistics. The mean, standard deviation and 5th percentile of the distribution
for C1 can be found with the commands
>> mean(C1)
>> std(C1)
>> prctile(C1,5)
We can also ask for a list of percentile values by passing an array of
percentiles as an argument to the prctile function.
>> prctile(C1,[5 50 95])
This gives us the 5th percentile, the 50th percentile (the median), and
the 95th percentile of the distribution of C1.

Simulation Modeling
135
To plot a histogram of the distribution of outcomes for C1, use the
MATLAB hist function. The command
>>[frequencyCounts,binLocations] = hist(C1,numBins);
will return the frequency counts and the bin locations for the number of
bins (numBins) you have speciﬁed.21 You can then use the command bar
to plot the histogram. In this particular case, the sequence of commands
>>[frequencyCounts,binLocations] = hist(C1,10);
>> bar(binLocations,frequencyCounts)
produce the graph in Exhibit 4.14.22
Technically speaking, bar plots are not the correct representation for
continuous random variables. There should not be any gaps between the
bars on the graph because the possible values for C1 in this case should hap-
pen in a continuum. (This is because the distribution for returns is normal,
i.e., continuous.) So, instead, we can use the command directly (without
specifying output variables [frequencyCounts,binLocations]) to pro-
duce a histogram. (See Exhibit 4.15.)
To learn about commands for generating different random distribu-
tions and to see an overview of methods for random number generators,
700
800
900
1000
1100
1200
1300
1400
0
2
4
6
8
10
12
14
16
18
20
EXHIBIT 4.14
Bar plot of the distribution of the simulation output variable C1.

136
FUNDAMENTAL CONCEPTS
800
900
1000
1100
1200
1300
1400
0
2
4
6
8
10
12
14
16
18
20
EXHIBIT 4.15
Histogram of the distribution of the output variable C1.
type “random number generation” in MATLAB’s help window. Also,
try typing
>> lookfor rnd
at the MATLAB command prompt. This will produce a list of all functions in
MATLAB that contain the string “rnd” in their title. Aside from a couple of
unrelated hits, these are the functions that directly generate random numbers
from different probability distributions.
Example from Section 4.2.1
Now let us generate the distribution of the
total return after 30 years. We can simulate 30 columns of 100 observations
each of single-period returns. (Hence, column k contains the 100 returns
simulated for year k.) We use the following command:
>> singlePeriodReturns30 = normrnd(.0879,.1465,100,30)
Now we can compute the cumulative returns at the end of 30 years and
the corresponding capital at the end of 30 years with the command
>> capital30 = 1000*prod(1+singlePeriodReturns30,2)

Simulation Modeling
137
Let us break up this command and explain each piece.
1+singlePeriodReturns30
returns the original matrix (of 100 rows and 30 columns) of simulated single-
period returns, but it adds 1 to each entry in the matrix. (So, we obtain an
array with entries (1 + r0,1), (1 + r1,2), . . . , (1 + r29,30) for the ﬁrst row
(the ﬁrst generated scenario), and similarly for the remaining 99 rows (the
remaining 99 scenarios.)
The function prod(X,DIM) computes the product of the elements of a
matrix array along the speciﬁed dimension DIM. In this case, we speciﬁed
dimension 2, which means prod will work with the entries in the columns
of the array. In other words,
prod(1+singlePeriodReturns30,2)
will return an array with 100 rows and 1 column, and the column will
contain the products of (1 + r0,1), (1 + r1,2), . . . , (1 + r29,30) for each row
(i.e., for each of the 100 scenarios for 30 years of returns).
Finally, multiplying this array by 1,000 computes the amount of capital
after 30 years (starting with initial capital of $1,000) in each of the 100
scenarios for returns. We name the variable for the amount of capital after
30 years capital30. We can then analyze it by plotting the histogram of its
100 simulated values, computing the descriptive statistics, and so on, as we
showed in the previous section.
Example from Section 4.2.2
To generate scenarios for the joint realizations
of returns for stocks and bonds from a multivariate normal distribution,
we will use the MATLAB function mvnrnd(MU,SIGMA,cases). It takes as
inputs a vector array of means MU and a covariance matrix SIGMA, and
generates as many scenarios as are speciﬁed in cases.
In our example, the vector of means MU is [0.0879,0.04]. The standard
deviations of stock and bond returns are 0.1465 and 0.07, respectively,
and the correlation coefﬁcient is –0.02. Therefore, the covariance matrix
SIGMA is

0.14652
−0.2 · (0.1465) · (0.07)
−0.2 · (0.1465) · (0.07)
0.072

=
 0.0215 −0.0002
−0.0002
0.49

.
At the MATLAB prompt, we enter
>> MU = [0.0879,0.04];
>> SIGMA = [0.0215,-0.0002;-0.0002,0.49];

138
FUNDAMENTAL CONCEPTS
If you then type
>> mvnrnd(MU,SIGMA,5000),
MATLAB will return 5000 rows (scenarios) of pairs of observations that
are correlated with correlation coefﬁcient −0.2:
ans =
0.0245
-0.0901
-0.1563
0.5503
0.1063
-0.3720
0.1301
1.5678
-0.0802
-0.0539
0.2625
0.1181
0.2623
0.7851
0.0824
0.0815
0.1359
-0.0274
0.1135
-0.5429
and so on.
These are the returns on the stock market and the Treasury bond market
for year 1 of your investment. To compute the amount of capital at the end of
the ﬁrst year in each of these 5,000 scenarios (remembering that we invested
50% of the initial $1,000, that is, $500 in stocks and 50% in bonds), we
would compute
>> capital1 = sum(500*(1+mvnrnd(MU,SIGMA,5000)),2)
The sum function, like the prod function we explained in the previous
section, takes a ﬁrst argument which is an array, and sums the correspond-
ing elements in the dimension speciﬁed by the second argument. Here the
command
500*(1+mvnrnd(MU,SIGMA,5000))
creates a matrix with two columns, the ﬁrst one of which represents the
amount invested in stocks at the end of the ﬁrst year, and the second one of
which represents the amount invested in bonds at the end of the ﬁrst year.
When we sum the corresponding elements in the two columns, we obtain a
5,000 × 1 array of values for the capital at the end of the ﬁrst year. We could
use this information to compute the descriptive statistics of the investment
at the end of the ﬁrst year.
If we want to analyze the investment at the end of 30 years, we need to
repeat this process 30 times. The following script computes the distribution

Simulation Modeling
139
of the value of the capital at the end of 30 years (assuming we invest an
equal amount of the original capital in stocks and bonds):
>> stocksRet = ones(5000,1); bondsRet = ones(5000,1);
>> for iYear = 1:30
scenarios = mvnrnd(MU,SIGMA,5000);
stocksRet = stocksRet.*(1+scenarios(:,1));
bondsRet = bondsRet.*(1+scenarios(:,2));
end
>> capital30 = 500*stocksRet + 500*bondsRet;
We can then analyze the distribution of the capital at the end of 30 years.
For example, to compute its mean, we type
>> mean(capital30)
ans =
7.9882e+003
Example from Section 4.2.3
To evaluate different investment strategies,
we just need to loop over a range of weights for our stock investment.
(The weights for the bond investment will be determined by the difference
between 1 and the weight for the stock investment.) To ensure that the
strategies are evaluated over the same set of scenarios, ﬁrst we generate the
scenarios for the returns on the stock and the bond market over 30 years as
in the previous section:
>> stocksRet = ones(5000,1); bondsRet = ones(5000,1);
>> for iYear = 1:30
scenarios = mvnrnd(MU,SIGMA,5000);
stocksRet = stocksRet.*(1+scenarios(:,1));
bondsRet = bondsRet.*(1+scenarios(:,2));
end
Then, we iterate through different weights, storing the 5,000 scenarios
for the capital after 30 years (given initial capital of $1,000) for each of
these combinations of weights:
>> counter = 1;
>> for iWeight = 0.2:0.2:1
capital30(:,counter) = iWeight*1000*stocksRet + (1-
iWeight)*1000*bondsRet;
counter = counter + 1;
end

140
FUNDAMENTAL CONCEPTS
So, for example, the ﬁrst column of the matrix array capital30 con-
tains the 5,000 scenarios for the capital after 30 years when stocks are 20%
of the initial $1,000 investment, and bonds are 80%. Each of the columns
of capital30 can be analyzed and the descriptive statistics for the different
investment strategies can be compared.
NOTES
1. Recall from Chapter 3 that we use tilde (∼) to denote uncertain quantities and
random variables.
2. Note that there are an inﬁnite number of values a return can take, since a return
is expressed as a percentage. So, while you can certainly input a discrete set
of possible scenarios for return, it is not unnatural to assume that the actual
realization of the return is drawn from a continuous probability distribution.
3. There is no rule for which goodness-of-ﬁt test is “best.” Each of them has
advantages and disadvantages. The chi-square test is the most general one, and
can be used for data that come from both continuous and discrete distributions;
however, to calculate the chi-square test statistic, one needs to divide the data
into “bins,” and the results depend strongly on how the bins are determined.
The K-S and the A-D tests apply only for continuous distributions. They do not
depend on dividing the data into bins, so their results are less arbitrary. The K-S
statistic is concerned primarily with whether the centers of the empirical and
the expected distribution are “close,” whereas A-D focuses on the discrepancy
between the tails of the observed and the expected distribution. For all three
tests, the smaller the value of the test statistic, the closer the ﬁt is. (As we
mentioned in section 3.11.4, most statistical software packages report a p-value,
that is, a “probability,” in addition to a test statistic. The larger the p-value, the
closer the ﬁt.) Finally, the RMSE measures the squared error of the differences
between observed and the expected values. The smaller the number, the better,
but the actual magnitude of the RMSE depends on the distribution and data
at hand.
4. @RISK has a Distribution Fitting button in its ribbon in Excel that allows
the user to (1) specify whether the distribution to be ﬁtted is continuous or
discrete (which narrows down the type of goodness-of-ﬁt tests); (2) check a
list of distributions that need to be checked for goodness-of-ﬁt; and (3) tweak
options in the computation of the chi-square goodness-of-ﬁt statistic. @RISK
then lists, in order of goodness-of-ﬁt, the possible probability distributions and
their parameters.
MATLAB’s Statistics Toolbox contains a Distribution Fitting tool as well.
It allows the user to enter a possible distribution for a set of data, and provides
estimates of the parameters of the distribution. To check for goodness-of-ﬁt,
one can use the MATLAB function [h,p]=chi2gof(. . .) from the command
line, which provides the value of the chi-square statistic for the ﬁt of a particular
distribution. The higher the value of the statistic h, the less evidence there is

Simulation Modeling
141
that the data come from the tested distribution. Alternatively, one can look at
p—the p-value of the chi-square test. The p-value measures the probability that
one can have chi-square statistic computed from the data that is more extreme
than the current chi-square statistic. The higher the value for p, the less likely
this is the case. Therefore, a high value of p (e.g., 75%) suggests that the data
ﬁt the chosen distribution quite well.
5. Note that, depending on the speciﬁc set of 100 scenarios we have generated,
the graph will look different. Therefore, the descriptive statistics and the look
of the graph we present here will only be close to what you would obtain if you
try to repeat this experiment.
6. We do not discuss the possibility that returns in different years may be correlated
here. We will learn how to create more sophisticated models for asset returns
in Chapter 12.
7. We could be looking at the minimum and maximum realized outcomes as
measures of the “riskiness” of Strategy A and Strategy B as well, but recall that
those are very sensitive to the number of trials in the simulation, and should be
interpreted with care.
8. Note that the value for t(100−α/2)%,n−1 has decreased slightly as well—this is
because we now have more observations, that is, more degrees of freedom, so
the t-distribution is less spread out and is closer to the normal distribution.
9. Recall that the continuous uniform distribution looks like a simple rectangle
(Exhibit 3.12), and it is very easy to compute probabilities and cumulative
probabilities for the values for the continuous uniform random variable. Because
the length of the interval is 1 and the total area under the PDF must be 1, the
height of the curve should be 1 as well. Therefore, the probability that the
continuous uniform random variable takes a value between two numbers a
and b (the area under the PDF between a and b) is simply (b −a) · 1, that is,
b −a.
10. To understand better how this works, you can practice generating values from a
general discrete probability distribution in Excel. For example, we can simulate
these values with the corresponding probabilities by creating a table with the
interval ranges in the ﬁrst two columns, and the corresponding values (5, 15,
and 35) in the third column, and using the Excel function
VLOOKUP(lookup value,table array,col index num)
to look up the range in which a number generated with RAND() falls.
Fortunately, @RISK contains direct commands for specifying general dis-
crete distributions. MATLAB does not have as many different distribution op-
tions, but many of the most widely used distributions are in its library.
11. We present the calculation here because the exponential distribution is widely
used in modeling the arrival time of credit risky events when pricing credit
derivatives and managing bond portfolio risk (see Chapter 16).
12. In Excel, the function =NORMINV(RAND(), mean, standard devia-
tion) can be used to ﬁnd that random number on the x-axis (the x-percentile)
of a normal distribution with the speciﬁed mean and standard deviation.

142
FUNDAMENTAL CONCEPTS
Specialized simulation software packages use such algorithms to generate a
random variable from any distribution. @RISK does it behind the scenes when
the user speciﬁes directly the probability distribution to be generated by clicking
on the button Deﬁne Distribution. In MATLAB, one can use both the direct and
the indirect approach. For example, to generate a single number from a normal
distribution, one can enter norminv(rand(1), mean, standard devi-
ation). More recent versions of MATLAB’s Statistics Toolbox contain direct
commands for generating random numbers from a variety of distributions, for
example, normrnd for normal random variables, poissrnd for Poisson ran-
dom variables, and so on. Type lookfor rnd at the MATLAB prompt for a
listing of available distributions, and see the end of this chapter for how such
commands are used.
13. The Glivenko-Cantelli Theorem is a statement about the behavior of an em-
pirical CDF as the number of independent and identiﬁcally distribution (IID)
observations recorded from the underlying distribution grows. Glivenko and
Cantelli showed that as the number of observations grows, the empirical CDF
approaches the true CDF uniformly.
14. A long cycle is desirable because if the random number generator converges to
only a small set of values for the random number, we cannot obtain a good
representation of the probability distribution we are trying to sample.
15. See section 3.8 in the previous chapter for a deﬁnition of autocorrelation.
16. The intuition is that the remainder after division with m is the difference between
the number Axn−1 and the largest number that is divisible by m but is still less
than Axn−1.
17. Such sequences are discussed in detail in Chapter 14.
18. See the survey in Boyle, Broadie, and Glasserman (1997).
19. To permute, you can ﬁrst draw one of the coordinates at random, then draw
one coordinate from the remaining ones, and so on until only one is left.
20. The Latin Hypercube method works well for generating independent random
variables, but complications occur when we need to generate correlated ran-
dom variables. See Chapter 4 in Glasserman (2004) for further discussion and
examples.
21. The number of bins you specify for the histogram will make a difference for how
the histogram appears. For example, it is intuitively undesirable for a histogram
to have only two bins. One rule of thumb used in statistics is to compute the
number of bins by taking the square root of the number of observations, and
rounding up.
22. Please note that your graph may look slightly different because the random
numbers you generated will not necessarily be the same as the random numbers
generated to create the picture. They will vary from trial to trial.

CHAPTER5
Optimization Modeling
T
his chapter introduces optimization—a methodology for selecting an op-
timal strategy given an objective and a set of constraints. Optimiza-
tion appears in a variety of ﬁnancial applications, including portfolio
allocation, trading strategies, identifying arbitrage opportunities, and pric-
ing ﬁnancial derivatives. We will encounter it in Chapters 7, 8, 9, 14,
and 18, among others. In this chapter, we motivate the discussion by a
simple example and describe how optimization problems are formulated
and solved.
Let us recall the retirement example from section 4.2.2. We showed
how to compute the realized return on the portfolio of stocks and bonds
if we allocate 50% of our capital in each of the two investments. Can we
obtain a “better” portfolio return with a different allocation? (As discussed
in section 4.2.3 of the previous chapter, a “better” return is not well-deﬁned
in the context of uncertainty, so for the sake of argument, let us assume
that “better” means higher expected return.) We found that if the allocation
is (100%, 0%) instead of (50%, 50%), we end up with a higher portfolio
expected return, but also higher portfolio standard deviation. What about an
allocation of (30%, 70%)? It turned out that the portfolio expected return is
lower, and so is the standard deviation. What about an allocation of (20%,
80%)?
In this example, we are dealing with only two investments, and we have
no additional requirements on the portfolio structure. It is, however, still
difﬁcult to enumerate all the possibilities and ﬁnd those that provide the
optimal trade-off of return and risk. In practice, portfolio managers are
handling thousands of investments and need to worry about transaction
costs, requirements on the portfolio composition, and trading constraints,
which makes it impossible to ﬁnd the “best” portfolio allocation by trial-
and-error. The optimization methodology provides a disciplined way to
approach the problem of optimal asset allocation.
143

144
FUNDAMENTAL CONCEPTS
5.1
OPTIMIZATION FORMULATIONS
The increase in computational power and the tremendous pace of develop-
ments in the operations research ﬁeld in the past 15 to 20 years has led to
highly efﬁcient algorithms and user-friendly software for solving optimiza-
tion problems of many different kinds. The art of optimization modeling is
therefore in framing a situation so that the formulation ﬁts within recognized
frameworks for problem speciﬁcations, and can be passed to optimization
solvers. It is important to understand the main building blocks of optimiza-
tion formulations, as well as the limitations of the software and the insights
that can be gained from the output of optimization solvers.
An optimization problem formulation consists of three parts:1
1. A set of decision variables (usually represented as an N × 1 −dimen-
sional vector array2 x).
2. An objective function, which is a function of the decision variables
(f(x)).
3. A set of constraints deﬁned by functions (gi(x), hj(x)), i = 1,. . .,I, j =
1,. . .,J of the general form gi(x) ≤0 (inequality constraints) and h j(x) =
0 (equality constraints).
The decision variables are numerical quantities that represent the deci-
sions to be made. In the portfolio example, the decision variables could be
the portfolio weights (alternatively, they could be the amounts to allocate
to each asset class). The objective function is a mathematical expression of
the goal, and the constraints are mathematical expressions of the limitations
in the business situation. In our example, the objective function could be
an expression to compute the expected portfolio return, and the constraints
could include an expression that computes total portfolio risk. We can then
maximize the expression of the objective function subject to an upper limit
on the risk we are willing to tolerate. (We will derive actual formulations in
Chapters 7 through 10.)
Optimization software expects users to specify all three components of
an optimization problem, although it is sometimes possible to have optimiza-
tion problems with no constraints. The latter kind of optimization problems
is referred to as unconstrained optimization. Unconstrained optimization
problems are typically solved with standard techniques from calculus,3 and
the optimal solution is selected from all possible points in the N-dimensional
space of the decision variables x. When there are constraints, only some
points in that space will be feasible, that is, will satisfy the constraints.
The values of the decision variables that are feasible and result in the best

Optimization Modeling
145
value for the objective function are called the optimal solution. Optimization
solvers typically return only one optimal solution. However, it is possible
to have multiple optimal solutions, that is, multiple feasible solutions x that
produce the same optimal value for the objective function.4
When formulating optimization problems, it is important to realize that
the decision variables need to participate in the mathematical expressions for
the objective function and the constraints that are passed to an optimization
solver because the whole idea of optimization algorithms is that they can
tweak the values of the decision variables in these expressions in a smart,
computationally efﬁcient way, in order to produce the best value for the
objective function with values for the decision variables that satisfy all of
the constraints. In other words, we cannot simply pass the expression
Maximize
Portfolio expected return
to an optimization solver, unless the portfolio expected return is expressed as
a function of the decision variables (the portfolio weights). As we will derive
in Chapter 7, the expected portfolio return can be expressed in terms of the
portfolio weights as w′µ, where w = (w1, . . . , wN)′ and µ = (µ1, . . . , µN)′
are N-dimensional arrays containing the weights and the expected returns
of the N assets in the portfolio, respectively. So, the objective function would
be written as
max
w
w′µ
which is interpreted as “maximize the value of w′µ over the possible values
for w.”
In addition, the input data in a classical optimization problem formu-
lation need to be ﬁxed numbers, not random variables. For example, the
objective function of an optimization problem cannot be passed to a solver
as
Maximize
Portfolio return
where portfolio return = w′˜r, and ˜r = (˜r1, . . . , ˜rN)′ is the N-dimensional ar-
ray with (uncertain) asset returns with some probability distributions. Some
areas in optimization, such as robust optimization and stochastic program-
ming, study methodologies for solving optimization problems in which the
input data are subject to uncertainty and follow theoretical or empirical
probability distributions. However, in the end, the methods for solving such
problems reduce to specifying the coefﬁcients in the optimization problem
as ﬁxed numbers that are representative of the underlying probability distri-
butions in a particular way.

146
FUNDAMENTAL CONCEPTS
5.1.1
Minimization vs. Maximization
Most generally, optimization solvers require an optimization problem for-
mulation to be of the kind
min
x
f (x)
subject to
gi(x) ≤0
i = 1, . . . , I
h j(x) = 0
j = 1, . . . , J
There are variations on this formulation, and some have to do with
whether the optimization problem falls in a speciﬁc class. (Different cate-
gories of optimization problems based on the form of their objective function
and the shape of their feasible set are discussed in section 5.2.) Some op-
timization software syntax, such as the MATLAB Optimization Toolbox
syntax, allows for specifying only minimization problems, while other opti-
mization software packages are more ﬂexible, and accept both minimization
and maximization problems. Standard formulation requirements, however,
are not as restrictive as they appear at ﬁrst sight. For example, an optimiza-
tion problem that involves ﬁnding the maximum of a function f(x) can be
recast as a minimization problem by minimizing the expression −f(x), and
vice versa—an optimization problem that involves ﬁnding the minimum of
a function f(x) can be recast as a maximization problem by maximizing the
expression −f(x). To obtain the actual value of the objective function, one
then ﬂips the sign of the optimal value. Exhibit 5.1 illustrates the situation
for a quadratic function of one variable x. The optimal value for max f (x)
is obtained at the optimal solution x*. The optimal value for min −f (x) is
obtained at x* as well. Notice also that
max
x
f (x) = −min
x −f (x)
For the previous portfolio expected return maximization example, stat-
ing the objective function as
max
w
w′µ
or
min
w −w′µ
will produce the same optimal values for the decision variables w. To get the
actual optimal objective function value for max
w
w′µ, we would ﬂip the sign
of the optimal objective function value obtained after minimizing −w′µ.

Optimization Modeling
147
–f(x)
f(x)
–f(x*)
x*
max f(x)
min –f(x)
f(x*)
0
EXHIBIT 5.1
Example of the optimal objective function values for a
quadratic objective function f(x) of a single decision variable x.
5.1.2
Local vs. Global Optima
In optimization, we distinguish between two types of optimal solutions:
global and local optimal solutions. A global optimal solution is the “best”
solution for any value of the decision variables vector x in the set of all
feasible solutions. A local optimal solution is the best solution in a neigh-
borhood of feasible solutions. In other words, the objective function value
at any point “close” to a local optimal solution is worse than the objec-
tive function value at the local optimal solution. Exhibit 5.2 illustrates the
global (point A) and local (point B) optimal solution for the unconstrained
minimization of a function of two variables.
Most classical optimization algorithms can only ﬁnd local optima. They
start at a point, and go through solutions in a direction in which the objective
function value improves. Their performance has an element of luck that has
to do with picking a “good” starting point for the algorithm. For example,
if a nonlinear optimization algorithm starts at point C in Exhibit 5.2, it may
ﬁnd the local minimum B ﬁrst, and never get to the global minimum A. In
the general case, ﬁnding the global optimal solution can be difﬁcult and time
consuming, and involves ﬁnding all local optimal solutions ﬁrst, and then
picking the best one among them.
The good news is that in some cases, optimization algorithms can ex-
plore the special structure of the objective function and the constraints to

148
FUNDAMENTAL CONCEPTS
B
C
A
x1
f(x1,x2)
x2
EXHIBIT 5.2
Global (point A) versus local (point B) minimum
for a function of two variables x1 and x2.
deliver stronger results. In addition, for some categories of optimization
problems, a local optimal solution is in fact guaranteed to be the global opti-
mal solution, and many optimization problems in ﬁnance have that property.
(We review the most important kinds of such “nice” optimization problems
in section 5.2.) This makes recognizing the type of optimization problem in
a given situation and formulating the optimization problem in a way that
enables optimization algorithms to take advantage of the special problem
structure even more critical.
5.1.3
Multiple Objectives
In practice, we often encounter situations in which we would like to opti-
mize several objectives at the same time. For example, a portfolio manager
may want to maximize the portfolio expected return and skew, while min-
imizing the variance and the kurtosis. There is no straightforward way to
pass several objectives to an optimization solver. A multiple-objective op-
timization problem needs to be reformulated as an optimization problem
with a single objective. There are a couple of commonly used methods to
do this. We can assign weights to the different objectives, and optimize the
weighted sum of objectives as a single-objective function. Alternatively, we
can optimize the most important objective, and include the other objectives
as constraints, after assigning to each of them a bound on the value we are
willing to tolerate.

Optimization Modeling
149
5.2
IMPORTANT TYPES OF
OPTIMIZATION PROBLEMS
Optimization problems can be categorized based on the form of their objec-
tive function and constraints, and the kind of decision variables. The type
of optimization problem with which we are faced a particular situation de-
termines what software is appropriate, the efﬁciency of the algorithm for
solving the problem, and the degree to which the optimal solution returned
by the optimization solver is trustworthy and useful. Awareness of this fact is
particularly helpful in situations in which there are multiple ways to formu-
late the optimization problem. The way in which we state the formulation
will determine whether the optimization solver will be able to exploit any
special structure in the problem, and whether it can achieve stronger results.
5.2.1
Convex Programming
As mentioned in section 5.1.2, some general optimization problems have
a “nice” structure in the sense that a local optimal solution is guaranteed
to be the global optimal solution. Convex optimization problems have that
property. A general convex optimization problem is of the form
min
x
f (x)
subject to
gi(x) ≤0
i = 1, . . . , I
Ax = b
where both f(x) and gi(x) are convex functions, and Ax = b is a system
of linear equalities. A convex function of a single variable x has the shape
showed in Exhibit 5.3(A). For a convex function, a line that connects any
two points on the curve is always above the curve. The “opposite” of a
convex function is a concave function (see Exhibit 5.3(B)), which looks like
f (x)
x
(A)
f (x)
x
(B)
EXHIBIT 5.3
Examples of (A) a convex function; (B) a concave function.

150
FUNDAMENTAL CONCEPTS
a “cave.” For a concave function, a line that connects any two points on the
curve is always below the curve.
Convex programming problems encompass several classes of problems
with special structure, including linear programming (LP), some quadratic
programming (QP), second-order cone programming (SOCP), and semideﬁ-
nite programming (SDP). Algorithms for solving convex optimization prob-
lems are more efﬁcient than algorithms for solving general nonlinear prob-
lems, but it is important to keep in mind that even within the class of
convex problems, some convex problems are computationally more chal-
lenging than others. LP problems are best studied and easiest to solve with
commercial solvers, followed by convex QP problems, SOCP problems and
SDP problems.
We introduce LP, QP, and SOCP in more detail next. Many classical
problems in ﬁnance involve linear and quadratic programming, including
asset-liability problems, portfolio allocation problems, and some ﬁnancial
derivative pricing applications. SDP problems are advanced formulations
that have become more widely used in ﬁnancial applications with recent
advances in the ﬁeld of robust optimization. They are beyond the scope of
this book, but we refer interested readers to Fabozzi, Kolm, Pachamanova,
and Focardi (2007) for a detailed overview of robust optimization
formulations.
5.2.2
Linear Programming
Linear programming refers to optimization problems in which both the
objective function and the constraints are linear expressions in the deci-
sion variables.5 The standard formulation statement for linear optimization
problems is
min
x
c′x
subject to
Ax = b
x ≥0
All optimization problems involving linear expressions for the objective
function and the decision variables can be converted to this standard form.
Section 5.3.1 will present an example.
Linear optimization problems are the easiest kind of problems to solve.
Modern specialized optimization software can handle LP formulations with
hundreds of thousands of decision variables and constraints in a matter
of seconds. In addition, linear optimization problems belong to the class

Optimization Modeling
151
of convex problems for which a local optimal solution is guaranteed to
be the global optimal solution. (This is discussed in more detail in section
5.4.2.) LPs arise in a number of ﬁnance applications, such as asset alloca-
tion and identiﬁcation of arbitrage opportunities. The sample optimization
problem formulations in section 5.3.1 and 5.3.2 are linear optimization
problems.
5.2.3
Quadratic Programming
Quadratic programming problems have an objective function that is a
quadratic expression in the decision variables, and constraints that are lin-
ear expressions in the decision variables. The standard form of a quadratic
optimization problem is
min
x
1
2x′Qx + c′x
subject to
Ax = b
x ≥0
where x is an N-dimensional vector of decision vectors as before, and the
other arrays are input data:
Q is an N × N matrix.
c is an N-dimensional vector.
A is a J × N matrix.
b is an J-dimensional vector.
When the matrix Q is positive semideﬁnite,6 then the objective function
is convex. (It is a sum of a convex quadratic term and a linear function, and
a linear function is both convex and concave.) Since the objective function
is convex and the constraints are linear expressions, we have a convex op-
timization problem. The problem can be solved by efﬁcient algorithms, and
we can trust that any local optimum they ﬁnd is in fact the global optimum.
When Q is not positive semideﬁnite, however, the quadratic problem can
have several local optimal solutions and stationary points, and is therefore
more difﬁcult to solve.
The most prominent use of quadratic programming in ﬁnance is for
asset allocation and trading models. We will see examples in Chapters 7
through 10.

152
FUNDAMENTAL CONCEPTS
5.2.4
Second-Order Cone Programming
Second-order cone programs (SOCPs) have the general form
min
x
c′x
subject to
Ax = b
||Cix + di|| ≤c′
ix + ei,
i = 1, . . . , I
where x is an N-dimensional vector of decision vectors as before, and the
other arrays are input data:
c is an N-dimensional vector.
A is a J × N matrix.
b is a J-dimensional vector.
Ci are an Ii × N matrix.
di are Ii-dimensional vectors.
ei are scalars.
The notation ∥.∥stands for second norm, or Euclidean norm. (It is
sometimes denoted ∥.∥2 to differentiate it from other types of norms.) The
Euclidean norm of an N-dimensional vector x is deﬁned as
||x|| =

x2
1 + · · · + x2
N
The SOCP class of problems is more general than the classes covered
in sections 5.2.2 and 5.2.3. LPs, convex QPs, and convex problems with
quadratic objective function and quadratic constraints can be reformulated
as SOCPs with some algebra.
It turns out that SOCP problems share many nice properties with lin-
ear programs, so algorithms for their optimization are very efﬁcient. SOCP
formulations arise mostly in robust optimization applications. Such formu-
lations are discussed in section 6.3.
5.2.5
Integer and Mixed Integer Programming
So far, we have classiﬁed optimization problems according to the form of
the objective function and the constraints. Optimization problems can be
classiﬁed also according to the type of decision variables x. Namely, when the
decision variables are restricted to be integer (or, more generally, discrete)

Optimization Modeling
153
values, we refer to the corresponding optimization problem as an integer
programming (IP) or a discrete problem. When some decision variables are
discrete and some are continuous, we refer to the optimization problem as
a mixed integer programming (MIP) problem. In special cases of integer
problems in which the decision variables can only take values 0 or 1, we
refer to the optimization problem as a binary optimization problem.
Integer and mixed integer optimization formulations are useful for
formulating extensions to classical portfolio allocation problems. Index-
tracking formulations and many constraints on portfolio structure faced by
managers in practice require modeling with discrete decision variables. Ex-
amples of constraints include maximum number of assets to be held in the
portfolio (so-called cardinality constraints), maximum number of trades,
round lot constraints (constraints on the size of the orders in which assets
can be traded in the market),7 and ﬁxed transaction costs. Simple illustra-
tions of integer modeling are provided in the next section and are further
discussed in Chapter 9.
5.3
OPTIMIZATION PROBLEM
FORMULATION EXAMPLES
To provide better intuition for how optimization problems are formulated,
we give a few simpliﬁed examples of ﬁnancial problem formulations. We
will see more advanced nonlinear problems formulations in the context of
portfolio applications in Chapters 7 through 9.
The ﬁrst example in this section is explained in detail, so that the
process of optimization problem formulation can be explicitly outlined.
The problem formulation is the crucial step—once we are able to deﬁne
a business situation as one of the optimization problem types reviewed
in the previous section, we can ﬁnd the optimal solution with optimiza-
tion software. Later in this chapter, we explain how optimization formu-
lations can be input into solvers, and how the output can be retrieved and
interpreted.
5.3.1
Portfolio Allocation
The portfolio manager at a large university in the United States is tasked
with investing a $10 million donation to the university endowment. He has
decided to invest these funds only in mutual funds8 and is considering the
following four: an aggressive growth fund (Fund 1), an index fund (Fund
2), a corporate bond fund (Fund 3), and a money market fund (Fund 4),
each with a different expected annual return and risk level.9 The investment

154
FUNDAMENTAL CONCEPTS
EXHIBIT 5.4
Data for the portfolio manager’s problem.
Fund Type
Growth
Index
Bond
Money Market
Fund number
1
2
3
4
Expected return
20.69%
5.87%
10.52%
2.43%
Risk level
4
2
2
1
Max. investment
40%
40%
40%
40%
guidelines established by the Board of Trustees limit the percentage of the
money that can be allocated to any single type of investment to 40% of
the total amount. The data for the portfolio manager’s task are provided in
Exhibit 5.4. In addition, in order to contain the risk of the investment to an
acceptable level, the amount of money allocated to the aggressive growth
and the corporate bond funds cannot exceed 60% of the portfolio, and the
aggregate average risk level of the portfolio cannot exceed 2. What is the
optimal portfolio allocation for achieving the maximum expected return at
the end of the year, if no short selling is allowed?10
To formulate the optimization problem, the ﬁrst thing we need to ask
ourselves is what the objective is. In this case, the logical objective is to
maximize the expected portfolio return. The second step is to think of how
to deﬁne the decision variables. The decision variables need to be speciﬁed
in such a way as to allow for expressing the objective as a mathematical
expression of the quantities the manager can control to achieve his objec-
tive. The latter point is obvious, but sometimes missed when formulating
optimization problems for the ﬁrst time. For example, while the market re-
turn on the assets is a variable and increasing market returns will increase
the portfolio’s return, changing the behavior of the market is not under the
manager’s control. The manager, however, can change the amounts he in-
vests in different assets in order to achieve his objective.11 Thus, the vector
of decision variables can be deﬁned as
x = (x1, x2, x3, x4): amounts (in $) invested in Fund 1, 2, 3, and 4,
respectively
Let the vector of expected returns be µ = (20.69%, 5.87%, 10.52%,
2.43%). Then, the objective function can be written as
f (x) = µ′x = (20.69%) · x1 + (5.87%) · x2 + (10.52%) · x3 + (2.43%) · x4.

Optimization Modeling
155
It is always a good idea to write down the actual description and the
units for the decision variables, the objective function and the constraints.
For example, the units of the objective function value in this example are
dollars.
Finally, we have several constraints:
■The total amount invested should be $10 million. This can be formulated
as x1 + x2 + x3 + x4 = 10,000,000.
■The total amount invested in Fund 1 and Fund 3 cannot be more than
60% of the total investment ($6 million). This can be written as x1 +
x3 ≤6,000,000.
■The average risk level of the portfolio cannot be more than 2. This con-
straint can be expressed as 4*(proportion of investment with risk level
4) + 2*(proportion of investment with risk level 2) + 1*(proportion of
investment with risk level 1) ≤2 or, mathematically,
4 · x1 + 2 · x2 + 2 · x3 + 1 · x4
x1 + x2 + x3 + x4
≤2.
Note that this is not a linear constraint. (We are dividing decision vari-
ables by decision variables.) Based on the discussion in section 5.2.2, from
a computational perspective, it is better to have linear constraints when-
ever we can. There are a couple of different ways to convert this particular
constraint into a linear constraint. For example, we can multiply both sides
of the inequality by x1 + x2 + x3 + x4, which is a nonnegative number and
will preserve the sign of the inequality as is. In addition, in this particular
example we know that the total amount x1 + x2 + x3 + x4 = 10,000,000,
so the constraint can be formulated as
4 · x1 + 2 · x2 + 2 · x3 + 1 · x4 ≤2 · 10,000,000.
The maximum investment in each fund cannot be more than 40% of
the total amount ($4,000,000). These constraints can be written as
x1 ≤4,000,000, x2 ≤4,000,000, x3 ≤4,000,000, x4 ≤4,000,000
Finally, given the no short selling requirement, the amounts in-
vested in each fund cannot be negative. (Note we are assuming that the

156
FUNDAMENTAL CONCEPTS
portfolio manager can invest only the $10,000,000, and cannot borrow
more.)
x1 ≥0, x2 ≥0, x3 ≥0, x4 ≥0.
These are nonnegativity constraints. Even though they seem obvious in
this example, they still need to be speciﬁed explicitly for the optimization
solver.
The ﬁnal optimization formulation can be written in matrix form. The
objective function is
max
x1,x2,x3,x4
0.2069
0.0587
0.1052
0.0243 
·
⎡
⎢⎢⎣
x1
x2
x3
x4
⎤
⎥⎥⎦.
Let us organize the constraints together into groups according to their
signs. (This will be useful when solving the problem with optimization soft-
ware is discussed later.)
Equality(=):
 1
1
1
1 
·
⎡
⎢⎢⎣
x1
x2
x3
x4
⎤
⎥⎥⎦= 10,000,000
Inequality(≤):
⎡
⎢⎢⎢⎢⎢⎢⎣
1
0
1
0
4
2
2
1
1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
1
⎤
⎥⎥⎥⎥⎥⎥⎦
·
⎡
⎢⎢⎣
x1
x2
x3
x4
⎤
⎥⎥⎦≤
⎡
⎢⎢⎢⎢⎢⎢⎣
6,000,000
20,000,000
4,000,000
4,000,000
4,000,000
4,000,000
⎤
⎥⎥⎥⎥⎥⎥⎦
.
Nonnegativity(≥):
⎡
⎢⎢⎣
x1
x2
x3
x4
⎤
⎥⎥⎦≥
⎡
⎢⎢⎣
0
0
0
0
⎤
⎥⎥⎦.
This problem is an LP. It would look like the standard form in section
5.2.2, except for the inequality (≤) constraints. We can rewrite the LP in
standard form by converting them to equality constraints. We introduce six

Optimization Modeling
157
additional nonnegative variables s = (s1, . . . , s6) (called slack variables), one
for each constraint in the group Inequality (≤):
⎡
⎢⎢⎢⎢⎢⎢⎣
1
0
1
0
4
2
2
1
1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
1












1
0
0
0
0
0
0
1
0
0
0
0
0
0
1
0
0
0
0
0
0
1
0
0
0
0
0
0
1
0
0
0
0
0
0
1
⎤
⎥⎥⎥⎥⎥⎥⎦
·
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
x1
x2
x3
x4
s1
s2
s3
s4
s5
s6
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
6,000,000
20,000,000
4,000,000
4,000,000
4,000,000
4,000,000
⎤
⎥⎥⎥⎥⎥⎥⎦
.
Then, we add the nonnegativity constraints on the slack variables to the
problem formulation:
[x1, x2, x3, x4, s1, s2, s3, s4, s5, s6]′ ≥0.
Optimization solvers in the past required that the problem be passed
in standard form; however, solvers and optimization languages are much
more ﬂexible today, and do their own conversion to standard form. In
any case, as this example illustrates, it is easy to go from a general linear
problem formulation to the standard form. The optimization software we
will use in this book—Excel’s Solver, Palisade’s Evolver, and MATLAB’s
Optimization Toolbox—have their own problem input speciﬁcations, but
these speciﬁcations are straightforward to handle. We explain how to solve
this problem with software in this chapter’s Software Hints.
5.3.2
Cash Flow Matching
Consider an asset manager who is managing funds for the corporate spon-
sor of a deﬁned beneﬁt pension plan that needs to ensure a particular
stream of semiannual cash payments over the next four years for retir-
ing plan participants.12 For example, the pension plan may have semian-
nual obligations representing annuity payments. Let the cash obligations for
the eight payment dates of the next four years be represented by a vector
m = (m1, . . . , m8).
The asset manager on behalf of its client, the pension plan, is considering
investing in ﬁve different high investment-grade quality bonds. Over the
next eight payment dates (i.e., semiannually), bond i pays out coupons
ci = (ci1, . . . , ci8). If the bond matures at date t, the corresponding cit equals

158
FUNDAMENTAL CONCEPTS
EXHIBIT 5.5
Cash ﬂow matching example data.
Current Bond
Price (pi)
$102.36
$110.83
$96.94
$114.65
$96.63
Cash Flows (cit)
Obligations (mt)
t = l
$
2.50
$
5.00
$
3.00
$
4.00
$
3.50
$
100,000.00
t = 2
$
2.50
$
5.00
$
3.00
$
4.00
$
3.50
$
200,000.00
t = 3
$
2.50
$
5.00
$
3.00
$
4.00
$
3.50
$
100,000.00
t = 4
$
2.50
$
5.00
$
3.00
$
4.00
$
3.50
$
200,000.00
t = 5
$102.50
$
5.00
$
3.00
$
4.00
$
3.50
$
800,000.00
t = 6
$105.00
$
3.00
$
4.00
$
3.50
$1,200,000.00
t = 7
$103.00
$
4.00
$
3.50
$
400,000.00
t = 8
$104.00
$103.50
$1,000,000.00
the coupon rate plus the principal. The bonds currently trade at ask prices
p = (p1, . . . , p5). The relevant data are provided in Exhibit 5.5. The asset
manager would like to ensure that the coupon payments from the bonds
cover the pension plan’s obligations.13
To formulate this problem, we must, again, ask ourselves what the
objective of the fund is. Although it is not stated explicitly in the problem,
it makes sense for the objective to be to minimize the cost of acquiring the
bonds today while still meeting all expected future obligations.
The decision variables can be deﬁned as the amounts x = (x1, x2,
x3, x4, x5) to invest in each of the ﬁve bonds. The cost of acquiring the
bonds today is
5

i=1
pi · xi = p′x.
The constraints are that at each payment date, the cash ﬂows from the
coupons of all the bonds are at least as large as the liabilities. Therefore, the
optimization problem can be stated as
min
x1,...,x5
5

i=1
pi · xi
subject to
5

i=1
cit · xi ≥mt,
t = 1, . . . , 8
xi ≥0,
i = 1, . . . , 5.

Optimization Modeling
159
Again, this formulation is an LP because both the objective function and
the constraints are linear functions of the decision variables x1, x2, x3, x4, x5.
In practice, the amounts for the bond investments may need to be pre-
sented as round lots. This can be achieved by using integer variables. We
can introduce new integer variables z = (z1, z2, z3, z4, z5) that correspond to
the number of lots to buy of each bond. Suppose that a lot for bond i is li.
To obtain the optimal number of lots of each bond to purchase, we rewrite
the problem formulation above as
min
x1,...,x5,z1,...,z5
5

i=1
pi · xi
subject to
5

i=1
cit · xi ≥mt,
t = 1, . . . , 8
xi ≥0,
i = 1, . . . , 5
xi = zi · li,
i = 1, . . . , 5
zi integer,
i = 1, . . . , 5
Since some of the variables are continuous (x1, x2, x3, x4, x5) and some
are discrete (z1, z2, z3, z4, z5), the LP formulation becomes an MIP, which is
computationally harder to solve.
For implementation of this example of cash ﬂow matching, see this
chapter’s Software Hints and the ﬁles Ch5-CashFlowMatching.xlsx and
CashFlowMatching.m. Note, however, that while the LP formulation can
be solved with any solver, both Excel Solver and MATLAB’s Optimization
Toolbox will have trouble solving the MIP. To solve the MIP problem, we
would need a more advanced solver such as ILOG’s CPLEX.14
5.3.3
Capital Budgeting
The operating manager at a pharmaceutical company is considering funding
proposals for eight different research and development (R&D) projects, but
she has limited funds C (C = $1,000,000). The cost of investing in Project
i is ci, and the present value of Project i’s estimated beneﬁt is bi. Speciﬁc
numbers ci and bi are shown in Exhibit 5.6. (We will explain how projects
are valued in Chapters 17 and 18.) Each project is on a “take it or leave it”
basis, that is, it is not possible to fund a project partially. Which projects
should the operating manager fund in order to maximize the present value
of the expected total beneﬁt?

160
FUNDAMENTAL CONCEPTS
EXHIBIT 5.6
Costs, present value (PV) of project beneﬁts, and beneﬁt/cost ratios
for each of the eight R&D projects. All numbers are in thousands of dollars.
Project
1
2
3
4
5
6
7
8
Project cost
$400.00
$350.00
$200.00
$100.00
$300.00
$250.00
$300.00
$350.00
Project
beneﬁts
(PV)
$950.00
$780.00
$440.00
$215.00
$630.00
$490.00
$560.00
$600.00
Beneﬁt/cost
ratio
2.38
2.23
2.20
2.15
2.10
1.96
1.87
1.71
If we did not know about optimization problem formulations, a logical
approach is to rank the projects according to their beneﬁt to cost ratios,
and to pick as many (in order of decreasing beneﬁt to cost ratios) as can be
funded with the $1 million budget.
Going from left to right in the table in Exhibit 5.6, we select Projects 1,
2, and 3. The total cost is
$400,000 + $350,000 + $200,000 = $950,000,
so we stop after selecting Project 3. The present value of the total beneﬁts is
$950,000 + $780,000 + $440,000 = $2,170,000.
Is this the best we can do? Notice that we were left with a budget of
about $50,000 we could have invested. There is no project that can be had
for $50,000, but suppose that we replaced Project 3 with Project 6, which
had an outlay of $250,000, and would have exhausted the budget of $1
million. The total beneﬁt from investing in Projects 1, 2, and 6 is
$950,000 + $780,000 + $490,000 = $2,220,000,
which is higher than the number we found with the ﬁrst approach. In fact,
there is a combination of projects that results in an even higher expected
beneﬁt: Projects 1, 3, 4, and 5. The total beneﬁt is
$950,000 + $440,000 + $215,000 + $630,000 = $2,235,000,
and it turns out that this is the maximum beneﬁt we can get for an investment
budget of $1 million.

Optimization Modeling
161
It is not easy to see immediately that the combination of Projects 1, 3,
4, and 5 gave the optimal solution, and this was a simple problem, in which
the manager was faced with no additional constraints. It is even harder to
identify the optimal solution once further conditions on the projects are
imposed.
This situation is a good example of how binary optimization can be use-
ful for ﬁnancial applications. Let us introduce decision variables x1, . . . , x8
(one corresponding to each project) that equal 1 if the project is selected,
and 0 otherwise. The total beneﬁt then can be computed as
$950,000 · x1 + $780,000 · x2 + $440,000 · x3 + $215,000 · x4
+ $630,000 · x5 + $490,000 · x6 + $560.000 · x7 + $600,000 · x8
Note that if the decision is not to invest in Project i, then the beneﬁt
of that project is not counted towards the total beneﬁt. The total cost of
funding the selected projects can be computed in a similar manner.
We can now formulate the optimization problem:
min
x1,...,x8
8

i=1
bi · xi
subject to
8

i=1
ci · xi ≤C
xi binary,
i = 1, . . . , 8
Solving this problem will produce the optimal solution we mentioned
above:
(x1, x2, x3, x4, x5, x6, x7, x8) = (1, 0, 1, 1, 1, 0, 0, 0).
Now suppose that the manager is facing additional constraints:
(a) If he funds Project 1, he must fund Project 8 as well.
(b) Projects 4 and 5 are mutually exclusive since their goals are virtually the
same, that is, if the manager funds Project 4, he will not fund Project 5,
and vice versa.
Let us ﬁrst formulate the problem with constraint (a). The condition
needs to be formulated mathematically, that is, classical optimization solvers

162
FUNDAMENTAL CONCEPTS
do not understand “If–then” statements.15 We can express the condition as
the additional constraint
x1 ≤x8
or, equivalently, as
x1 −x8 ≤0.
To gain some intuition, note that if the manager ﬁnds that it is optimal
to invest in Project 1, that is, x1 = 1, then the constraint above will force x8
to be 1 as well, that is, the optimal solution will contain investments in both
Project 1 and Project 8. However, if the manager does not invest in Project
1, that is, x1 = 0, then x8 is free to be 0 or 1, that is, the manager may or
may not invest in Project 8.
The optimal solution with additional constraint (a) turns out to be to
invest in Projects 2, 4, 5, and 6, for a total estimated beneﬁt of $2,115,000.
Now let us formulate constraint (b). Again, we need to express it math-
ematically. We can state the condition as
x4 + x5 ≤1.
This will work because in order for the constraint to be satisﬁed, only
one of the variables x4, x5 can be 1. (They may both be 0, of course.)
Therefore, the manager would be able to invest in at most one of Project 4
or 5. The optimal solution when both constraints (a) and (b) are added to
the original optimization problem is
(x1, x2, x3, x4, x5, x6, x7, x8) = (0, 1, 0, 1, 0, 1, 1, 0)
for a total beneﬁt of $2,045,000, and a total cost of $1,000,000. In other
words, the manager should invest in Projects 2, 4, 6, and 7.
5.4
OPTIMIZATION ALGORITHMS
How do optimization solvers actually ﬁnd the optimal solution for a prob-
lem? As a general rule, optimization algorithms are of iterative nature. They
start with an initial solution and generate a sequence of intermediate solu-
tions until they get “close” to the optimal solution. The degree of “close-
ness” is determined by a parameter called tolerance, which usually has some

Optimization Modeling
163
default value, but can often be modiﬁed by the user. Frequently, the toler-
ance parameter is linked to a measure of the distance between the current
and the subsequent solution, or to the incremental progress made by subse-
quent iterations of the algorithm in improving the objective function value.
If subsequent iterations of the algorithm bring very little change relative to
the status quo, the algorithm is terminated.
The algorithms for optimization in today’s optimization software are
rather sophisticated, and an extensive introduction to these algorithms is
beyond the scope of this book. However, many optimization solvers let the
user select which optimization algorithm to apply to a speciﬁc problem, and
some basic knowledge of what algorithms are used for different classes of
optimization solvers is helpful for deciding what optimization software to
use and what options to select for the problem at hand.
5.4.1
Linear Optimization: The Simplex Algorithm
and Interior Point Methods
The ﬁrst optimization algorithm, called the simplex algorithm, was devel-
oped by George Dantzig in 1947. It solves linear optimization problems
by iteratively solving systems of linear equations to ﬁnd intermediate feasi-
ble solutions in a way that continually improves the value of the objective
function. The name of the algorithm refers to the geometric term simplex.
A 2-dimensional simplex is a triangle—a set of points that lie between the
lines that can be drawn between 2 + 1 points in the 2-dimensional space. In
N-dimensional space, a simplex is a collection of all the points that can be
enclosed by hyperplanes connecting the outermost points in the set.16 (See
Exhibit 5.7.) It turns out that the feasible sets for the decision variables in
linear optimization problems are simplexes, and a pretty amazing fact about
linear optimization problems is that at least one possible optimal solution
must lie at the “corner” of the simplex. (It is possible that other optimal so-
lutions lie on the “edge” of the set, however.) The simplex algorithm takes
advantage of this fact. It visits the corners of the simplex that contains the
feasible solutions to the linear optimization problem iteratively in order to
ﬁnd the corner solution that results in the best possible value for the ob-
jective function, which it then reports as the optimal solution. Despite its
age, the simplex algorithm is still widely used for linear optimization, and is
remarkably efﬁcient in practice.
In the 1980s, another class of efﬁcient algorithms called interior point
methods was developed, inspired by a new algorithm Narendra Karmakar
created for linear programming problems. In contrast to the simplex method,
which traverses the simplex of feasible points along the edges and only
considers the corners, interior point methods reach the optimal solution from

164
FUNDAMENTAL CONCEPTS
EXHIBIT 5.7
Simplex in 3-dimensional space.
the inside of the feasible set. If there are multiple optimal solutions, interior
point algorithms may not ﬁnd the corner one. Thus, if a linear optimization
problem has multiple optimal solutions, solving the problem with a solver
that uses the simplex algorithm versus a solver that uses an interior point
algorithm may result in different optimal solutions. The advantage of interior
point methods is that they can be applied not only to linear optimization
problems, but also to a wider class of convex optimization problems.
5.4.2
Constrained Nonlinear Optimization: The
KKT Conditions and Lagrange Multipliers
Many nonlinear optimization algorithms are based on using information
from a special set of equations that represent necessary conditions that a
solution x is optimal. These conditions are the Karush-Kuhn-Tucker (KKT)
conditions for optimality. We explain the intuition behind them next.
When an optimization problem is unconstrained and the objective func-
tion is differentiable, the optimum can be found using standard techniques
from calculus. If we are minimizing a function f(x) of a single variable x,
then the derivative of f(x), f ′(x), must be 0 at the optimal point x* (see
Exhibit 5.7). To see this, recall that the derivative represents the amount
the function will change when x changes by a small amount. If f ′(x*) is less

Optimization Modeling
165
than 0, then we can move a small distance from x* in the positive direction,
and achieve a smaller value for f(x), so f(x*) is not in fact the minimum.
Similarly, if f ′(x*) is greater than 0, then we can move a small distance from
x* in the negative direction, and achieve a smaller value for f(x).
When there are constraints gi(x) and hj(x), a parallel condition for x*
to be the minimum holds, but it involves the derivatives of the constraint
functions as well. Namely, at the optimum x*, the following equality must
hold:
f ′(x*) +
I

i=1
ui · g′
i(x*) +
J

j=1
v j · h′
j(x*) = 0.
Here ui and vj are special numbers called Lagrange multipliers, and ui
need to be nonnegative. In addition, of course, for a point x* to be the
optimum, it needs to be feasible as well, that is, it must satisfy all constraints
in the optimization problem. The Lagrange multipliers are not known in
advance, but in some cases can be computed from the equality above and
the conditions on feasibility.
The KKT conditions are a generalization of the statements above when
there are multiple decision variables. If f, gi(x) and hj(x) are functions
of an N-dimensional vector of variables x, then we need to consider the
gradients of the objective function and the constraint functions.17 Then,
the KKT necessary conditions for a point x* to be a minimum can be
expressed as
∇f (x*) +
I

i=1
ui · ∇gi(x*) +
J

j=1
v j · ∇h j(x*) = 0
ui ≥0, i = 1, . . . , I
ui · gi(x*) = 0, i = 1, . . . , I
h j(x*) = 0, j = 1, . . . , J
gi(x*) ≤0, i = 1, . . . , I
The last two conditions simply require that the point x* must satisfy all
the constraints, that is, be a feasible solution, in order to be considered a
candidate for the global minimum.
Note that it is not easy to ﬁnd a point x that satisﬁes the KKT conditions
because, depending on the expressions for the objective function and the
constraint functions, some of the equations in the system may be nonlinear.
Even if a point that satisﬁes the KKT conditions is found, it may not be the

166
FUNDAMENTAL CONCEPTS
A
B
f ´(B) = 0
f ´(x*) = 0
f ´(A) = 0
x*
x
f(x)
EXHIBIT 5.8
The condition that the derivative of a
function f(x) is equal to 0 is satisﬁed at (A) the global
minimum x*, (B) a local maximum (point A), and (c) a
local minimum (point B).
global optimum, since the KKT conditions are necessary, but not sufﬁcient
for optimality. In other words, if a point x* is the global optimal solution,
it must satisfy these conditions, but if a point x satisﬁes these conditions, it
is not necessarily the global optimal solution. This reasoning is easiest to vi-
sualize in the simple case in which we have the unconstrained minimization
problem in Exhibit 5.8. The derivative of f(x) is 0 not only at the global
minimum (x*), but also at point A (local maximum), and point B (local min-
imum). The derivative can also be 0 at so-called inﬂection points (or saddle
points), which are neither minima, nor maxima, but points at which the
function changes curvature. The KKT conditions are, fortunately, necessary
and sufﬁcient for optimality in the case of convex optimization problems.
They take a special form in the case of linear optimization problems and
some other classes of convex problems, which is exploited in interior point
algorithms for ﬁnding the optimal solution.
The importance of the KKT conditions for general nonlinear optimiza-
tion is that they enable a nonlinear optimization problem to be reduced to a
system of nonlinear equations, whose solution can be attained by using suc-
cessive approximations. Widely used algorithms for nonlinear optimization
include barrier methods, primal–dual interior point methods, and sequential
quadratic programming methods. The latter try to solve the KKT conditions
for the original nonlinear problem by optimizing a quadratic approximation

Optimization Modeling
167
to a function derived from the objective function and the constraints of the
original problem. For more details, we refer the reader to Bazaraa, Sharali,
and Shetty (1993) and Freund (2004).
5.4.3
Integer Programming Algorithms
At ﬁrst glance, integer and mixed integer optimization problems appear to be
easier than standard optimization problems because the number of feasible
values for the decision variables to be explored appears smaller than the
feasible values for optimization problems with continuous variables. In fact,
however, integer programming problems as a general rule are more difﬁcult
and take longer to solve. Enumeration of all possible solutions for problems
of realistic size is prohibitively expensive computationally, so we still need
to resort to algorithms that search for the optimal solution in a smart way.
Such algorithms are easier to create for problems with continuous variables
than for problems with integer variables.
IP optimization problems are typically solved by branch-and-bound al-
gorithms, branch-and-cut routines, and heuristics18 that exploit the special
structure of the problem.19 The main idea behind many of these algorithms
is to start by solving a relaxation of the optimization problem in which the
decision variables are not restricted to be integer numbers. The algorithms
then begin with the solution found in the initial stage, and narrow down
the choices of integer solutions. In practice, a simple rounding of the initial
fractional optimal solution is sometimes good enough. However, it is im-
portant to understand that simple rounding of the initial solution can lead
to an integer solution that is very far from the actual optimal solution, and
this problem is even more pronounced when the number of integer decision
variables is large.
There are some good commercial optimization solvers that can handle
linear and convex quadratic mixed-integer optimization problems, but there
are virtually no solvers that can handle more general nonlinear mixed integer
problems efﬁciently.
5.4.4
Randomized Search Algorithms
In this chapter, we referred several times to the difﬁculty of ﬁnding the global
optimal solution when there are multiple local optima. Classical nonlinear
optimization algorithms typically stop when they have found a solution that
is the best in its “neighborhood,” and if they come across a local optimum
ﬁrst, they may never reach the global optimum. A number of algorithms try
to avoid these pitfalls by incorporating an element of randomness in their
search. In other words, they allow moves to feasible solutions with worse

168
FUNDAMENTAL CONCEPTS
value of the objective function to happen with some probability, rather than
pursuing always a direction in which the objective function improves. The
hope is that this will avoid getting stuck in a local optimum.
Randomized search algorithms fall into several classes, including sim-
ulated annealing, tabu search, and genetic algorithms. Genetic algorithms
in particular have become an option in several popular software packages
for optimization, such as Premium Solver and Palisade’s Evolver, which
is discussed shortly. MATLAB also has a Genetic Algorithms and Direct
Search Toolbox, which contains simulated annealing and genetic algo-
rithms. We explain simulated annealing and genetic algorithms in more
detail, so that the available options in these software packages become more
intuitive.
At every step, the simulated annealing algorithm generates a new fea-
sible solution to the optimization problem, and generally accepts it as the
next solution if the solution improves the value of the objective function.
However, even if the solution does not improve the value of the objective
function, the simulated annealing algorithm accepts it with some probability.
The magnitude of the probability of accepting a seemingly inferior solution
as the next point in the search is determined by a positive parameter T
(called the temperature) that is an input to the algorithm. If the temperature
is small, the simulated annealing algorithm is less likely to deviate substan-
tially from a path in which the objective function value is improving; if the
temperature is large, the simulated annealing is more adventurous in picking
solutions that can be very different. At an intuitive level, when the algorithm
is close to the optimum, we want the temperature to be small, so that the
algorithm stays in that neighborhood and eventually ﬁnds the optimal solu-
tion. However, at the initial stages of the algorithm, we may be better off
if the temperature is large because the algorithm will scout more areas with
solutions faster, and will not spend time in a particular neighborhood. In ad-
vanced solvers, the default value of the parameter T is usually set to a value
that works reasonably well for a wide variety of difﬁcult, highly nonlinear
problems.
Like simulate annealing, genetic algorithms are useful in cases in which
the objective function or the constraints are highly nonlinear or have dis-
continuities. However, genetic algorithms tend to be slower than classical
optimization algorithms and simulated annealing because they tend to re-
quire more objective function evaluations. Despite this drawback, genetic
algorithms can be more efﬁcient than other randomized algorithms in cases
in which some of the decision variables are integer numbers, or in cases in
which the optimization problem has a special structure.
Before a genetic algorithm starts, a way must be found for any potential
solution to the optimization problem to be encoded as a string of integers,

Optimization Modeling
169
or binary bits. This string is referred to as a chromosome. It looks something
like
1101
0000
1111
0010
The chromosome may be composed of genes, which could be individual
bits or groups of bits. In the preceding example, we may treat groups of four
bits as genes.
At the beginning of the algorithm, a ﬁxed number of such chromosomes
are generated. (This is the initial population.) Each of them is assigned a
ﬁtness score, which evaluates how good the solution represented by that
chromosome is. (The ﬁtness score is related to the objective function value
evaluated at that solution.) Then, two members from the population are
selected at random. (The probability of being selected is typically related
to the ﬁtness score of a particular chromosome.) You can think of them as
the “parents.” The crossover rate, speciﬁed by the user, determines how the
genes of the parents are swapped. It is often speciﬁed to be about 0.7. The
mutation rate, also speciﬁed by the user, determines what percentage of the
bits on average ﬂip from 1 to 0 and from 0 to 1 randomly. It is usually
something small (e.g., 0.001). After going through a number of iterations
speciﬁed by the user, the algorithm stops, and returns the best solution found
so far.
To summarize, randomized search algorithms for optimization have
their drawbacks—they can be slow, and provide no guarantee that they
will ﬁnd the global optimum. However, they are appropriate for handling
difﬁcult integer problems, nonlinear problems and problems with disconti-
nuities, when traditional optimization solvers fail.
5.4.5
Algorithm Efficiency
Thus far we have been using the word “efﬁcient” to describe an optimization
algorithm. While the term is intuitive and generally means “fast,” in some
cases it is important to differentiate between different ways to measure the
efﬁciency of an algorithm. Established conventions estimate the efﬁciency of
an algorithm by the number of steps, or elementary operations it takes to
solve a problem of a given size. (The “size” of a problem is determined by
the number of operations need to solve the problem, which is related to the
number of decision variables and the number of constraints.20) However,
such bounds typically estimate the worst-case performance. A large number
of steps does not necessarily mean worse performance in practice. For most
practical purposes, we care only whether a given algorithm performs well
on typical instances of the problems, not whether the algorithm is slow for

170
FUNDAMENTAL CONCEPTS
some pathological examples. The simplex method for linear optimization,
for example, provides no guarantees on how many steps it may take to come
up with the optimal solution. Yet, the algorithm works remarkably well in
practice.
Still, a theoretical superiority of one algorithm over another does often
lead to better performance in practice as well. Thus, algorithms that run in
polynomial time in the problem size are generally preferable to algorithms
that take exponential time. An algorithm is said to run in polynomial time
if it requires O(nk) operations to solve, where n is the problem size and k
is a positive integer.21 An algorithm is said to run in exponential time if
it requires O(kn) operations to solve the problem. As an example, if k =
10 and n = 80 (the problem size can easily be 80 for real-life problems),
we will need more operations to solve the optimization problem than there
are, arguably, atoms in the universe. No matter how much technology has
improved, algorithms that run in exponential time are very hard to handle
for large problems.
5.5
OPTIMIZATION DUALITY
The Lagrange multipliers u and v from the KKT conditions in section 5.4.2
have a special role in optimization theory and practice. They are in fact vari-
ables in a certain dual optimization problem that is related to the original,
or primal, optimization problem in very speciﬁc ways. If the primal prob-
lem is a minimization problem, then the dual problem is a maximization
problem, and vice versa. The number of variables in the dual problem is
equal to the number of constraints in the primal problem, and vice versa.
Moreover, there is a relationship between the optimal objective function
values of the primal and the dual problem that can frequently be exploited.
Optimization duality theory has numerous critical applications, including,
but not restricted to the following:
■A good dual problem solution can be used to compute a bound for the
value of the objective function of the primal problem, and so can be
used to identify when a primal solution is near-optimal.
■For some types of convex optimization problems, it can be veriﬁed that
an optimal solution to the primal problem has been found by construct-
ing a dual problem solution with the same objective function value.
■Often, the dual problem has better mathematical or computational
structure than the primal problem. This fact can be used to compute
optimal solutions for both the primal and the dual optimization prob-
lems. In addition, computation of dual variables is part of a number of

Optimization Modeling
171
efﬁcient optimization algorithms. The primal-dual interior point method
(mentioned in section 5.4.2) is one such algorithm.
■We can use dual variables to perform sensitivity analysis on the primal
optimization problem. The dual variable corresponding to a particular
constraint in the primal problem represents the incremental change in
the optimal solution value per unit increase in the value on the right
hand side of the constraint equality or inequality.
Duality theory is not as widely used in speciﬁc ﬁnancial applications
as some other aspects of optimization, but has been used in the context of
ﬁnding arbitrage opportunities (see Chapter 13), and it plays a major part
in the methodology for deriving robust optimization problem formulations
for portfolio optimization problems (see section 6.3 in the next chapter).
It is therefore helpful to explain how dual problems are constructed and
interpreted for some important classes of optimization problems.
Consider again the general optimization problem P (the primal prob-
lem):
min
x
f (x)
P:
s.t.
gi(x) ≤0,
i = 1, . . . , I
h j(x) = 0,
j = 1, . . . , J
The dual problem D is constructed in three steps:
■Place the constraints in the objective function by using I nonnegative
multipliers ui and J multipliers vj to form the so-called Lagrangian
function
L(x, u):= f (x) + u′g(x) + v′h(x) = f (x) +
I

i=1
uigi(x) +
J

j=1
vih j(x)
■Create the dual function
L*(u):= min
x

f (x) + u′g(x) + v′h(x)

.
■Write the dual problem
max
u
L*(u)
D:
s.t.
u ≥0

172
FUNDAMENTAL CONCEPTS
EXHIBIT 5.9
Primal and dual formulations for important types of convex
optimization problems.
Primal Problem
Dual Problem
LPs
min
x
c′x
s.t.
Ax = b
x ≥0
max
u
u′b
s.t.
A′u ≤c′
min
x
c′x
s.t.
Ax ≥b
max
u
u′b
s.t.
A′u = c
u ≥0
QPs
min
x
1
2x′Qx + c′x
s.t.
Ax ≥b
max
u
u′b −1
2 (c −A′u)′ Q−1 (c −A′u)
s.t.
u ≥0
SOCPs
min
x
c′x
s.t.
Cix + di
 ≤ci ′x + ei,
i = 1, . . . , I
max
u,v
−
I
i=1
ui ′di + viei
s.t.
I
i=1
uiCi + vici = c
∥ui∥≤vi, i = 1, . . . , I
Usually, we construct the dual problem in the hope that computing the
optimal solution will be an easy task.
Examples of primal and dual problems for linear and quadratic prob-
lems are summarized in Exhibit 5.9. The dual of the dual problem is the
primal problem.
Note that the type of problem (LP, QP, SOCP) in the primal is preserved
in the dual problem for all of these examples of convex problems. (This is
not the case in general nonlinear optimization.) Moreover, it can be shown
that for all of these types of convex problems, the objective function value
of the primal problem for a feasible primal problem solution is at least
as large as the objective function value of the dual problem for a feasible
dual problem. In fact, for these types of convex optimization problems, it is
guaranteed that if the primal problem has an optimal solution, then so does
the dual, and the respective objective function values are the same. This has
important implications for optimization algorithm applications.
5.6
MULTISTAGE OPTIMIZATION
Financial planning and pricing decisions often involve ﬁnding optimal
strategies over multiple time periods ahead. For example, a ﬁrm may be

Optimization Modeling
173
considering a sequence of operational decisions over the next few years.
It is often possible to capture this multistage framework through standard
optimization formulations, but it can be difﬁcult, and it does not always
allow for employing the most efﬁcient algorithms for solving the problem.
Models of dynamic choice in ﬁnance typically involve representation of fu-
ture cash ﬂow streams, and are perhaps best visualized by a graph. On the
horizontal axis, one denotes the time periods at which the cash ﬂows occur.
At each time period, nodes are used to represent different possible states or
conditions of the dynamic system at that point in time. The collection of all
states is called the state space. Our actions inﬂuence which state is reached
at the next point in time. States that are reachable from a particular state
are linked to that state.
5.6.1
Finite State Space
Examples of two simple dynamical systems are illustrated in Exhibit 5.10(A)
and (B). Each node in the graphs represents a state. The graphs are called
binomial trees, or binomial lattices, because there are exactly two branches
emanating from each node. The number of branches corresponds to the
number of options available to the decision maker at each particular state.
If there were three available choices, the number of branches emanating
from each node would be three. There can also be dynamical systems with
an inﬁnite number of branches emanating from each node. We will see an
example later in this section. Note that the branches in Exhibit 5.10(A)
Stage 0
Stage 1
2 nodes
Stage 2
3 nodes
Stage 3
4 nodes
(A)
(B)
x1,1
x2,1
x2,2
x1,2
x2,3
x3,4
x3,3
x3,2
x3,1
x0
Stage 0
Stage 1
2 nodes
Stage 2
4 nodes
Stage 3
8 nodes
x1,1
x2,1
x2,2
x2,3
x1,2
x2,4
x3,8
x3,4
x3,5
x3,6
x3,7
x3,2
x3,3
x3,1
x0
EXHIBIT 5.10
(A) Recombining binomial tree; (B) nonrecombining binomial tree.

174
FUNDAMENTAL CONCEPTS
recombine, whereas the branches in Exhibit 5.10(B) do not. Graphs with
recombining branches are referred to as recombining trees or recombining
lattices.
Let us consider a very simple example. Suppose you have purchased a
3-year lease for an oil well. The estimated reserves of the well are 600,000
barrels. Every year, you can either pump oil normally (Strategy 1), in which
case you pump 100,000 barrels, or use an enhanced pumping method which
allows you to pump 200,000 barrels (Strategy 2). The increased production
capacity through the enhanced pumping method comes at a price: to extract
ut barrels at time t with the enhanced method costs you 20 · u2
t /xt dollars,
where xt is the amount of available reserves at time t. In contrast, the cost
of extracting ut barrels with the normal pumping method is u2
t /xt dollars.
Note that in both cases, as the amount of available oil xt decreases, the cost
of pumping increases. This expression incorporates the implicit assumption
that it becomes harder to pump the oil as the reserves are depleted.
The expected price of a barrel of oil over the ﬁrst, second, and third year
of your lease is $45, $30, and $40, respectively, and the discount factor per
year is 0.9. Assuming that you can pump either 100,000 barrels or 200,000
barrels each year, what is the optimal strategy to maximize the present value
(PV) of your proﬁt from the lease?
One approach to ﬁnding the optimal solution would be to look at
the price of oil in each of the three years, compute the revenue and cost
from each strategy each year, and then pick the strategy that results in the
best proﬁt during that year. Unfortunately, however, the proﬁt every year
depends on the level of current oil reserves. To see this, suppose that the
current reserves are xt and the current price is pt. The proﬁt of Strategy 1
is pt · 100,000 −u2
t /xt. The proﬁt of Strategy 2 is pt · 200,000 −20 · u2
t /xt.
Therefore, optimal decisions across years are interdependent, and we cannot
treat every year separately.
To describe the dynamics of the cash ﬂows and the decisions, we ﬁrst ask
ourselves what would be an appropriate deﬁnition of state in this dynamical
system. The state must incorporate all information about the system at a
particular point in time. In our example, the amount of current reserves at
time t, xt, is an appropriate choice for state. The amount of current reserves
determines the cost of pumping oil, and that impacts the proﬁt and our
decision.
The evolution of our dynamical system can be described by the graph in
Exhibit 5.11. (See also ﬁle Ch5-OilExample.xlsx.) We can pump oil at the
beginning of years 0, 1, and 2. The lease ends in year 3. At every node, we
can make the decision to pump 100,000 or 200,000 barrels of oil, which
takes us to one of the nodes at the next time period. For example, at time 0

Optimization Modeling
175
G
D
300,000
B
400,000
H
A
500,000
E
200,000
600,000
C
300,000
I
400,000
F
100,000
200,000
J
0
3
2
1
0
Year
EXHIBIT 5.11
Binomial tree representing the state space for the oil well
multistage optimization problem. (See ﬁle Ch5-OilExample.xlsx.)
(node A), we start out with x0 = 600,000 barrels of oil. If we pump using the
normal method, that is, our decision u0 = 100,000, the oil reserves decrease
by 100,000, and the system is at node B at time 1. If we pump using the
enhanced method, then the oil reserves decrease by 200,000, and the system
is at node C at time 1. Depending on the node at which we are in year 1
(node B or node C), we can again decide whether to use the normal or the
enhanced method (u1 = 100,000 or u1 = 200,000, respectively). If we are
at node B at time 1, our decision will take us either to node D (if we use the
normal method) or to node E (if we use the enhanced method). If we are
at node C, our decision will take us either to node E (if we use the normal
method) or to node F (if we use the enhanced method). Note that this tree
is recombining because, for example, we can get to node E (have reserves of
300,000 barrels) either by following the path A-B-E (pumping 100,000 in
the ﬁrst year and 200,000 in the second year) or the path A-C-E (pumping
200,000 in the ﬁrst year and 100,000 in the second year).
There are 8 “paths” in the graph: A-B-D-G, A-B-D-H, A-B-E-H, A-
B-E-I, A-C-E-H, A-C-E-I, A-C-F-I, and A-C-F-J. Each path represents a
particular strategy. To ﬁnd the optimal path to take, we could evaluate the
present value of the proﬁt along each path, and select the path that gives
us the maximum present value of proﬁt. The calculation can be done for
this example. However, in practice we may encounter situations in which
there are many more time periods, and many more possible states. The
problem quickly becomes computationally intractable. For example, if we
expand the number of time periods in a binomial tree to 20, the number
of paths to be evaluated becomes 220, which is 1,048,576. For each of
these paths, we need to store information at each time period in order to
add it up and obtain the present value of the proﬁt obtained from selecting

176
FUNDAMENTAL CONCEPTS
that path. Not only is the number of paths large, but it also seems superﬂuous
to recalculate the proﬁt at each node several times, given that some paths
share nodes.
The trick to solving the problem with minimum number of calculations
and minimum amount of storage required is to work backwards starting
from the ﬁnal nodes on the right. At each node, we can store only the
information about the best path so far, and forget about all other paths. This
sequential optimization method is called dynamic programming. Dynamic
programming is based on Bellman’s (1957) Principle of Optimality, which
states that to achieve total optimality in a sequential decision process, all
future decisions after reaching a particular state must be optimal with respect
to that state. In other words, it is impossible to have a suboptimal decision
at some intermediate state, and still reach the overall optimum. Therefore,
we only need to keep track of the optimal decision at each state reachable
from the current state, and can use recursive relationships to describe the
optimal decision at any particular state in terms of the optimal decisions in
future states. We explain the dynamic programming algorithm as it applies
to the oil well problem next.
There is no proﬁt realized at nodes G, H, I, and J because the lease has
expired by then. (We assume that all proﬁt is obtained at the beginning of
the year.) So, we can ignore them in our calculation. At the beginning of year
2, we can be at nodes D, E or F. Suppose we are at D, that is, the current
level of oil reserves is 400,000 barrels. The proﬁt that can be realized using
the normal method is
40 · 100,000 −100,0002/400,000 = $3,975,000.
The proﬁt realized using the enhanced method is
40 · 200,000 −20 · 200,0002/400,000 = $6,000,000.
Obviously, $6,000,000 is the higher proﬁt, so we should use the enhanced
method if we are at node D.
Similarly, we can compute the highest proﬁt at nodes E and F. If we are
at E, the optimal strategy is to use the enhanced method, and the proﬁt we
can realize is $5,333,333.33. If we are at F, the optimal strategy is again to
use the enhanced method, and the realized proﬁt will be $4,000,000.
Next, we consider the previous time period. At the beginning of year 1,
we can be either at node B or at node C.

Optimization Modeling
177
Suppose we are at node B, that is, the oil reserves are 500,000.
If we select the normal method, we will realize a current proﬁt of
30 · 100,000 −100,0002/500,000 = $2,980,000, and will move to node D,
which will realize an additional proﬁt of $5,400,000, which is the present
value of $6,000,000 in year 1 dollars ( = 0.9·$6,000,000). The total proﬁt
from employing the normal method in year 1 is therefore $2,980,000 +
$5,400,000 = $8,380,000.
Suppose now that we select the enhanced method if we are at node B.
This means that in the next year, we will be at node E. The current proﬁt is
$4,400,000, and the best proﬁt we can realize at node E is $5,333,333.33,
so the total proﬁt in year 1 dollars is $4,400,000 + 0.9·$5,333,333.33 =
$9,200,000.00.
Clearly, selecting the enhanced method at node B results in a higher
total proﬁt from year 1 onward (accounting for both the proﬁt in year 1 and
the best proﬁt that can be realized in year 2 if we are at node B in year 1).
We proceed in a similar manner to compute the proﬁts at nodes C and
A. At each node, we only record the present value of the optimal proﬁt
from that node onward, and the best strategy from that point onward. The
optimal path and the proﬁt from the best strategy at each node (from that
node onward) are shown in Exhibit 5.12. The optimal path, that is, the path
that leads to the highest present value of total proﬁt ($14,664,166.67), is
A-C-E-I. This means that the optimal strategy is to use the enhanced method
for the ﬁrst year, the normal method for the second year, and the enhanced
method again for the third year.
Note that the strategies at some nodes are not obvious. For example,
if we are at node A, and we look at the optimal proﬁt realized at nodes B
and C, we may be tempted to use the normal method over the ﬁrst year,
ending up at node B. This is because the optimal proﬁt at node B going
G
D
0
B
6,000,000.00
$   
H
A
9,200,000.00
$   
E
0
14,664,166.67
$    
C
5,333,333.33
$   
I
7,775,000.00
$   
F
0
4,000,000.00
$   
J
0
3
2
1
0
Year
EXHIBIT 5.12
Optimal proﬁt from each state onward and optimal
decision path (marked by bold line segments) for the oil well problem. The
nodes in the tree match the states in Exhibit 5.10.

178
FUNDAMENTAL CONCEPTS
forward ($9,200,000.00) is higher than the optimal proﬁt at node C going
forward ($7,775,000.00). However, the price of oil over the ﬁrst year is
high enough that it turns out that, overall, is it optimal to pump more oil
(using the enhanced method) during the ﬁrst year and then end up in node
C, even though the optimal proﬁt going forward from node C is less than
the optimal proﬁt going forward from B.
Standard Notation Used in Dynamic Programming
Let us summarize the
dynamic programming approach by introducing some standard notation.
The variable that summarizes all necessary information at each state is re-
ferred to as a state variable. In our example, it was xt, the amount of oil
available at time t. Our decisions (the amount of oil to pump) were rep-
resented by a variable ut = {100,000, 200,000}, which is referred to as a
control, or policy, variable. The state variable was a function of the control
variable and the state at which we were in the previous period, and was
updated at every stage by the transition equation
xt+1 = xt −ut.
In the general case, we write xt+1 = g(xt, ut).
The total number of stages in our problem was T = 3. Our goal was to
optimize an objective function, the present value of the total proﬁt, which
was a sum of the present values of the proﬁts at each stage, and was a
function of the state and the control variable at each stage. We can write the
objective function as
T−1

t=0
ft(xt, ut).
In order to compute the optimal value of the objective function (the
optimal total proﬁt), at each node of the dynamic programming algorithm,
we computed the optimal proﬁt from that stage onward. The reward (or
cost, depending on the problem) from a speciﬁc node onward is referred to
as the value function. It is usually denoted by V. The dynamic programming
algorithm maximizes the sum of the immediate reward of the current step
(say, cash ﬂow c(ut)) and the optimal reward from the steps that follow. The
value function recursion can be written as
Vt(xt) = max
ut

c(ut) + d · V*
t+1(ut)


Optimization Modeling
179
where V*
t+1(ut) is the optimal value of the value function at stage t + 1 over
all possible values for the control ut, and d is the discount factor over one
stage. In our oil well example, we had
Vt(xt) = max

pt · 100,000 −100,0002/xt + 0.9 · V*
t+1(xt −100,000),
pt · 200,000 −20 · 200,0002/xt + 0.9 · V*
t+1(xt −200,000)

where pt was the price of oil at time t.
In order to compute the actual values of the value function, a dynamic
programming algorithm requires a boundary condition. As its name implies,
a boundary condition gives information about values at the extremes. In the
oil well example, we knew that the proﬁt that can be realized at the beginning
of year 3 was 0 (because the lease expires in three years). This allowed us to
compute the value function at the beginning of time period 3. From there,
we could compute the optimal values at the previous stages.
On the Relationship between Dynamic Programming and Classical Opti-
mization Formulations
At the beginning of this section, we mentioned that
many dynamic programming formulations can be stated in a standard opti-
mization form, although often this is not the easiest or most efﬁcient way to
approach the problem. To illustrate the relationship between dynamic pro-
gramming and the classical optimization formulations discussed in section
5.2 and 5.3, we formulate the oil well example in this section as a standard
optimization problem.
First, we introduce decision variables x0, x1, and x2 that will store the
optimal amount of reserves at each stage. Technically, x0 is not a variable
(we are given the initial amount of reserves), but we keep the notation for
consistency.
Second, we introduce decision variables u0, u1, and u2 that will store
our optimal decision about the amount of oil to pump at each stage.
Next, we note that our decision choices u0, u1, and u2 are discrete—we
can only pump 100,000 or 200,000 barrels each year. The situation is
reminiscent of the cash ﬂow matching problem in section 5.3.2, and more
speciﬁcally of the modiﬁcation of the problem in which we restricted the
bonds that are purchased to be in round lots by introducing binary variables.
We can approach the oil well problem formulation in a similar way. Let z0,
z1, and z2 be binary variables, with the following interpretation: zt is 1 if we
choose the normal method, that is, we pump 100,000 barrels of oil, and zt
is 0 if we choose the enhanced method, that is, we pump 200,000 barrels

180
FUNDAMENTAL CONCEPTS
of oil. Then, we can link the policy decision variables u0, u1, and u2 to the
binary decision variables z0, z1, and z2 as
ut = 100,000 · zt + 200,000 · (1 −zt),
t = 0, 1, 2.
This equality states the correct relationship because one of the terms in
the sum is always 0. If zt = 1, that is, we use the normal method, the second
term is 0, and ut is 100,000. If zt = 0, that is, we use the enhanced method,
the ﬁrst term is 0, and ut is 200,000.
We also need to state explicitly the relationships between the oil reserves
at each stage x0, x1, and x2, and the policy variables u0, u1, and u2. It is easy
to see that we have
xt = xt−1 −ut−1,
t = 1, 2,
that is, to obtain the optimal amount of reserves to have at each stage, we
subtract the optimal amount that was pumped at the previous stage from
the amount available at the previous stage.
The objective is, of course, to maximize the proﬁt over all three stages,
and we need to discount the proﬁt received at future dates properly to com-
pute the correct total present value. The optimization problem formulation
is therefore
max
x,u,z
p0 · u0 −z0 · u2
0/x0 −(1 −z0) · 20 · u2
0/x0
+ 0.9 ·

p1 · u1 −z1 · u2
1/x1 −(1 −z1) · 20 · u2
1/x1

+ 0.92 ·

p2 · u2 −z2 · u2
2/x2 −(1 −z2) · 20 · u2
2/x2

s.t.
u0 = 100,000 · z0 + 200,000 · (1 −z0)
u1 = 100,000 · z1 + 200,000 · (1 −z1)
u2 = 100,000 · z2 + 200,000 · (1 −z2)
x0 = 600,000
x1 = x0 −u0
x2 = x1 −u1
u0, u1, u2, x1, x2 ≥0
z0, z1, z2 binary
Note that we used a trick in the formulation of the objective function
because the expression for the cost is different depending on the method

Optimization Modeling
181
we use. We subtracted the cost “twice”: once for the normal method and
once for the enhanced method. However, we multiplied the expression for
the cost of each method by an expression containing the binary variable
zt, so that only the cost for the method that is selected is subtracted from
the proﬁt; the cost for the method that is not selected is 0 in the objective
function.
An implementation of the problem is presented in worksheet Classical
Formulation in ﬁle Ch5-OilExample.xlsx. The optimal solution and optimal
strategy at each stage are the same as the solution we would obtain by using
the dynamic programming algorithm:
z0 = 0 (use the enhanced method at stage 0)
z1 = 1 (use the normal method at stage 1)
z2 = 0 (use the enhanced method at stage 2)
u0 = 200,000 (pump 200,000 barrels of oil at stage 0)
u1 = 100,000 (pump 100,000 barrels of oil at stage 1)
u2 = 200,000 (pump 200,000 barrels of oil at stage 2)
x0 = 600,000 (amount of reserves at stage 0 is 600,000 barrels)
x1 = 400,000 (amount of reserves at stage 1 is 400,000 barrels)
x2 = 300,000 (amount of reserves at stage 2 is 300,000 barrels)
5.6.2
Infinite State Space
As we mentioned earlier in this section, in some ﬁnancial applications we
need to deal with dynamical systems with an inﬁnite state space. Think, for
example, of investments that are managed over multiple time periods. If the
state of the system is determined by our current holdings and the percentage
invested in assets represents our policy, then technically, we could have an
inﬁnite number of possible states—the possible combinations of weights of
assets in the portfolio at each point in time can be inﬁnite. In such cases,
we cannot easily visualize the dynamic system, and we cannot compute
the optimal strategy at every state as we did in the example above. The
best we can do is to hope to ﬁnd an expression that describes the optimal
strategy in each state in terms of the information in that state. This is not
always possible, and sometimes approximations are used. Next, we show
an example in which the optimal strategy in each of an inﬁnite number of
states can actually be computed in closed form.
Let us consider a modiﬁcation of the oil well problem from the previous
subsection. As before, suppose that you have purchased a 3-year lease for

182
FUNDAMENTAL CONCEPTS
the oil well. The estimated reserves of the well are 600,000 barrels. You can
use an enhanced method to pump oil that allows you to pump as much oil
as you want during the year at a cost of 20 · u2
t /xt, where ut is the amount of
oil that was pumped, and xt is the amount of available reserves at time t. As
before, the expected price of a barrel of oil over the ﬁrst, second, and third
year of your lease is $45, $30, and $40, respectively, and the discount factor
per year is 0.9. How much oil should you pump in each year to maximize
your proﬁt over the three years?
Given the similarities with the example in section 5.6.1, it is easy to see
that the most appropriate choice of state for the dynamical system is the
amount of oil reserves available at time t. However, we can no longer draw
a binomial tree like the one in Exhibit 5.10—there are an inﬁnite number of
states at each stage.
Fortunately, we can still solve the problem by using the dynamic pro-
gramming recursion. Suppose that we are at the beginning of year 2, with
one year left on the lease. The proﬁt at the beginning of year 2 (again, as-
suming that all cash ﬂows from the oil pumped in that year are received
at that time) is p2 · u2 −20 · u2
2/x2. The value function at any state at the
beginning of year 2, V2(x2), can be written as
V2(x2) = max
u2

p2 · u2 −20 · u2
2/x2

.
This is an actual unconstrained optimization problem. The expression
to maximize, p2 · u2 −20 · u2
2/x2, is a quadratic function in u2, and has the
shape in Exhibit 5.3(B). It is easy to see that the maximum is given at
the point where the derivative is equal to 0. The derivative with respect
to u2 is
p2 −40 · u2/x2.
Setting the derivative to 0 yields
u*
2 = p2 · x2/40.
Technically, there is one constraint in this optimization problem that
we did not include in the calculation. We should make sure that u2 ≤x2,
that is, that we do not pump more oil than we have available. It is easy to
see that this will indeed be the case. Given that p2 = $40, we actually get
u*
2 = x2, that is, we should pump all oil available at time 2.

Optimization Modeling
183
Next, we try to ﬁnd the optimal amount of oil to pump one time period
back—at time 1. The dynamic programming recursion tells us that u1 will
be the solution to the following optimization problem:
V1(x1) = max
u1
⎧
⎪⎨
⎪⎩
p1 · u1 −20 · u2
1/x1



current cash ﬂow (at time 1)
+
0.9

discount factor
·
V2*(u1)
  
optimal proﬁt from next step onward
⎫
⎪⎬
⎪⎭
To solve this problem, we need to know V*
2 (u1). We can ﬁnd it by
plugging the optimal value u*
2 (which we already found) into the expression
for proﬁt at time 2, V2(x2). We get
V*
2 (x2) = p2 · u*
2 −20 ·

u*
2
2 /x2
= p2
2 · x2/40 −20 · p2
2 · x2
2/(402 · x2)
= p2
2 · x2/80
Therefore, the optimal value of the proﬁt in year 1 is
V1(x1) = max
u1

p1 · u1 −20 · u2
1/x1 + 0.9 · p2
2 · x2/80

As we mentioned at the end of section 5.6.1, the state variable is up-
dated as
xt+1 = xt −ut
because the value of the available oil reserves is equal to the value of the oil
reserves from the previous time period reduced by the amount we pumped
over the previous time period. Therefore, we can substitute x2 in the expres-
sion for V1(x1) with x1 −u1. We obtain
V1(x1) = max
u1

−20 · u2
1/x1 + u1 · (p1 −0.9 · p2
2/80) + 0.9 · p2
2 · x1/80

The quadratic function to be maximized looks like the function in Ex-
hibit 5.3(B). We can ﬁnd the maximum by taking the derivative with respect
to u1, and setting it to 0. The value of u1 at which the maximum is attained is
u*
1 = (p1 −0.9 · p2
2/80) · x1/40

184
FUNDAMENTAL CONCEPTS
Substituting p1 = $30 and p2 = $40, we get
u*
1 = (12/40) · x1 = 0.3 · x1.
Therefore, the optimal strategy at time 1 is to pump 30% of the available
reserves. The value function is estimated as
V1(x1) = −20 · 0.32 · x2
1/x1 + 0.3 · x1 · (30 −0.9 · 402/80) + 0.9 · 402 · x1/80
= 19.8 · x1
We proceed in a similar manner to evaluate the optimal strategy at time
0. The value function can be written as
V0(x0) = max
u0
⎧
⎪⎨
⎪⎩
p0 · u0 −20 · u2
0/x0



current cash ﬂow (at time 0)
+
0.9

discount factor
·
V1*(u0)
  
optimal proﬁt from next step onward
⎫
⎪⎬
⎪⎭
.
Again, we have
x1 = x0 −u0
and so
V*
1 (u0) = 19.8 · (x0 −u0).
Therefore,
V0(x0) = max
u0

−20 · u2
0/x0 + 27.18 · u0 + 17.82 · x0

.
(Here we used the fact that the current price of oil is p0 = $45.) The maxi-
mum is attained at
u*
0 = (27.18/40) · x0 = 0.6795 · x0.
Hence, the optimal strategy at time 0 is to pump 67.95% of the available
reserves. We actually know the reserves at time 0: x0 = 600,000. Therefore,
we can compute the actual amount to pump at time 0:
u*
0 = 0.6795 · 600,000 = 407,700.

Optimization Modeling
185
We can now trace the complete optimal strategy over the three years
of the lease. At time 0, pump 67.95% of the optimal reserves, which is
407,700 barrels. At time 1, pump 30% of the remaining reserves, which is
0.30·(600,000 – 407,700) = 57,690 barrels. At time 2, pump all remaining
reserves, which is 600,000 – 407,700 – 57,690 = 134,610 barrels. The
optimal proﬁt over the three years is given by
V0(x0) = −20 · 407,7002/600,000 + 27.18 · 407,700 + 17.82 · 600,000
= $16,232,643
5.6.3
Steps in Formulating Multistage
Optimization Problems
The dynamic programming examples in sections 5.6.1 and 5.6.2 give us
some insights as to the general steps we may want to take in constructing a
dynamic programming algorithm:
■Think of the solution as a sequence of decisions that occur in multiple
stages, and represent the total cost (alternatively, reward) as a sum of
the costs (rewards) of the individual decisions.
■Deﬁne the states in the dynamical system in such a way that they sum-
marize all relevant past information.
■Determine which state transitions are possible, and link those states.
The cost/reward of moving to a state should equal the cost/reward of
the decision that forces that transition.
■Write an expression that computes the optimal cost/reward recursively
starting from the last state and going backward to the state of origin.
While this framework is helpful, in general, it is not straightforward to
describe a given dynamical system in such a way as to allow for ﬁnding the
solution through a dynamic programming recursion. The issue is similar to
the issue of how to consider a business situation and formulate an optimiza-
tion problem in such a way that it can be passed to a solver. In the case of
dynamic programming, the main step to ensure a successful formulation is
to ﬁnd a good deﬁnition of the state space—in other words, to deﬁne the
state variables in such a way that the rewards/costs of the transitions to the
next state variables and the value function depend solely on the current state
and decision variables. It takes practice and skill, and sometimes, it is not
possible to do. However, the dynamic optimization idea in general is useful,
and has many variations in ﬁnance. We will see more examples of multistage
optimization problems in Chapters 6, 13, 14, and 18.

186
FUNDAMENTAL CONCEPTS
5.7
OPTIMIZATION SOFTWARE
When selecting an optimization software product, it is important to differ-
entiate between optimization solvers and optimization modeling languages.
An optimization solver is software that implements numerical routines
for ﬁnding the optimal solution of an optimization problem. Well-known
commercial optimization solvers include MOSEK22 and ILOG’s CPLEX23
for linear, mixed-integer, and quadratic problems, and MINOS, SNOPT,
and CONOPT for general nonlinear problems,24 but there are a number of
other commercial and free solvers available.
Optimization modeling languages have emerged as user-friendly plat-
forms that allow the user to specify optimization problems in a more intuitive
generic fashion, independently of the speciﬁc algorithmic and input require-
ments of optimization routines. Typically, optimization language software
automates the underlying mathematical details of the optimization model
formulation, but does not actually solve the problem. It passes the formu-
lation to a solver, and retrieves the results from the solver in a convenient
format. Popular optimization languages include AMPL25 and GAMS.26
Optimization solvers and modeling languages are often part of model-
ing environments that handle not only the optimization, but also the input
and output processing, statistical analysis, and perform other functions a
user may need for a comprehensive analysis of a situation. MATLAB is an
example of a high-level technical computing and interactive environment for
model development that also enables data visualization, data analysis, and
numerical simulation. The optimization solvers in MATLAB’s Optimization
Toolbox can solve a variety of constrained and unconstrained optimization
problems for linear programming, quadratic programming, nonlinear op-
timization, and binary integer programming. Other examples of modeling
environments include ILOG’s OPL Studio, which allows users to build op-
timization models that are then accessed from a subroutine library using
VBA, Java, or C/C++. Thus, a user can connect optimization systems di-
rectly to data sources, and make calls to optimization subroutines repeatedly.
Palisade’s Decision Tools Suite27 also contains a number of software add-
ins for optimization, statistical analysis, and sensitivity analysis that use a
spreadsheet program—Microsoft Excel—as the underlying platform.
Excel’s inherent capabilities for optimization are rather limited. Excel
Solver, which ships with Excel, can handle only optimization problems of
small size, up to a few hundred variables and constraints. It is a perfectly
acceptable solver for linear optimization problems, but its performance (and
the output one would obtain from it) is unreliable for more complex prob-
lems of the general nonlinear or integer programming type. Premium Solver

Optimization Modeling
187
Platform,28 which is sold by the developers of Excel Solver, is an extended
and improved version of the standard Excel Solver, and can handle linear,
integer, and quadratic problems of larger size. It employs efﬁcient interior
point methods for solving classical optimization formulations, and genetic
algorithms for arbitrary Excel optimization models that contain spreadsheet
functions such as IF, INDEX, and COUNTIF (such functions are not recog-
nized in traditional optimization problem formulations). Palisade’s Evolver
is another add-in for Excel that uses genetic algorithms to solve optimization
problems. The Palisade Decision Tools Suite also contains RiskOptimizer,
which is a tool for optimization given possible scenarios for the uncertain
parameters in the problem.
It is useful to mention that there are numerous optimization software
packages that target ﬁnancial applications in particular, especially portfo-
lio management applications. Established vendors of portfolio management
software include Axioma,29 MSCI Barra,30 ITG,31 and Northﬁeld Informa-
tion Services.32
SUMMARY
■An optimization formulation consists of three parts: (1) an objective
function, (2) a set of decision variables, and (3) a set of constraints.
■A solution is feasible if it satisﬁes all constraints. A solution is optimal if
it is feasible and produces the best value of the objective function among
all feasible solutions.
■A solution is a local optimum if it produces the best value of the objective
function among all feasible solutions in its neighborhood. There may be
multiple local optima, depending on the type of optimization problem.
■Optimization problems are categorized according to: (1) the form of
the objective function and the constraints, and (2) the type of decision
variables (discrete or continuous). Important classes of optimization
problems include linear programming, quadratic programming, convex
programming, integer programming, and mixed integer programming.
■For convex optimization problems, a local optimal solution is also the
global optimal solution.
■Using optimization duality theory, we can construct a dual problem
for a given optimization problem. The dual problem may have better
computational properties, and may help solve the primal problem or
bound the optimal objective function values of the primal problem.
■The Karush-Kuhn-Tucker (KKT) conditions are necessary conditions
for local optima of constrained optimization problems. Their structure

188
FUNDAMENTAL CONCEPTS
is exploited by numerous algorithms for convex and general nonlinear
optimization.
■Most optimization algorithms are iterative in nature. The number of
iterations taken by the algorithm is determined by the stopping criteria
speciﬁed by the user, such as the tolerance level.
■Important types of optimization algorithms include the simplex algo-
rithm (for linear problems), interior point methods (for linear and con-
vex problems), branch-and-bound or branch-and-cut algorithms (for
integer programs), and randomized search algorithms (for all types of
optimization problems).
■Randomized search algorithms, such as genetic algorithms, simulated
annealing, and tabu search, do not guarantee the optimality of the so-
lution they return. Neither do general optimization algorithms when
applied to nonlinear optimization problems that do not have special
structure.
■Linear problems are the “easiest” class of optimization problems in the
sense that today, linear problems with hundreds of thousands of decision
variables and constraints can be solved efﬁciently. Convex problems
(which include linear programs) have nice structure, and are typically
more efﬁcient to solve than general nonlinear programming. Integer
and mixed-integer problems are challenging, and require specialized
optimization software.
■Dynamic programming is a method for optimization over multiple
stages. It solves the problem sequentially, by starting at the last stage and
keeping track only of the best solution from the current stage onward.
■An optimization solver is software that implements numerical routines
for ﬁnding the optimal solution of an optimization problem. Different
solvers handle different kinds of optimization problems.
■An optimization modeling language automates the underlying mathe-
matical details of the optimization model formulation, but typically does
not actually solve the problem. It passes the formulation to a solver, and
retrieves the results from the solver in a convenient format. The advan-
tage of using optimization languages is that the user can formulate the
problem only once, and use different options for solvers.
SOFTWARE HINTS
In this book, we will support optimization solvers that come standard with
Excel and Palisade’s Decision Tools Suite, as well as MATLAB’s Optimiza-
tion Toolbox. On a philosophical level, the solvers employ very different
approaches. The best way to illustrate their use is through examples, so we

Optimization Modeling
189
explain how to implement the linear programming formulation of the port-
folio allocation example in section 5.3.1 and the binary programming formu-
lation of the capital budgeting example in section 5.3.3. The solution to the
third example, the cash ﬂow matching exercise (section 5.3.2) is contained in
the ﬁle Ch5-CashFlowMatching.xlsx (respectively, CashFlowMatching.m).
Please note that both Excel Solver and MATLAB’s Optimization Toolbox
cannot handle IPs well, so the cash ﬂow matching example in section 5.3.2
is solved without the round lot constraints.
Excel Solver
Excel Solver comes prepackaged with Excel. It should be available under the
Data tab. If you do not see it there, go to the main Excel button, click on
Excel Options at the bottom, click Add-Ins, select Solver Add-In, then click
Go. Solver should appear under the Data tab.
The Solver dialog box is shown in Exhibit 5.13. Solver expects users to
input a target cell, changing cells, and constraints, and specify whether the
optimization problem is a maximization or minimization problem.
The entry for the target cell should be a reference to a cell that contains a
formula for the objective function of the optimization problem. This formula
should link the target cell and the changing cells. The changing cells are cells
dedicated to the decision variables—they can be left empty, or have some
initial values that the solver will eventually replace with the optimal values.
The initial values of the changing cells are used by Solver as the starting
point of the algorithm. They do not always matter when the optimization
EXHIBIT 5.13
Solver dialog box.

190
FUNDAMENTAL CONCEPTS
EXHIBIT 5.14
Add Constraint dialog box.
problem is linear, but they can cause Solver to ﬁnd very different solutions
if the problem is nonlinear or contains integer variables.
The constraints can be entered by clicking on the Add button, then
entering the left-hand side and the right-hand side of a constraint, as well as
the sign of the constraint. The constraint dialog box is shown in Exhibit 5.14.
By clicking on the middle button, the user can specify inequality constraints
(≤or ≥) or equality constraints (=). Solver also lets the user specify whether
a set of decision variables is integer (int) or binary (bin). To do that, the
user must have designated the cells corresponding to these decision variables
as changing cells, and then add the int or bin constraint through the Add
Constraint dialog box.
An important fact to remember is that Solver expects constraints to be
entered as cell comparisons, that is, it can compare the value of one cell
to the value of another cell in the spreadsheet. You cannot type a formula
directly into the Add Constraint dialog box—the formula needs to be al-
ready contained in the cell that is referenced. A good way to organize your
optimization formulation in Excel is to create a column of cells containing
the formulas on the left-hand side of all constraints, and a column of cells
containing the right-hand sides (the limits) of all constraints. That allows
for groups of constraints to be entered simultaneously. For example, if there
are three constraints that all have equal signs, you can enter an array refer-
ence to the range of three cells with the left-hand sides of these constraints,
and an array reference to the range of three cells with the right-hand sides.
Solver will compare each cell in the ﬁrst array to the corresponding cell in
the second array. This point will become clearer when we implement the
example in section 5.3.1.
Solver also allows users to specify options for the algorithms it uses
to ﬁnd the optimal solution. This can be done by clicking on the Options
button in its main dialog box. The Solver Options dialog box is shown
in Exhibit 5.15. For most problems, leaving the defaults in works ﬁne;
however, it is always helpful to provide as much information to the solver
as possible to ensure optimal performance. For example, if we know that

Optimization Modeling
191
EXHIBIT 5.15
Solver Options dialog box.
the optimization problem is linear, we can check Assume Linear Model. The
Assume Non-Negative option is a shortcut to declaring all decision variables
nonnegative (rather than entering separate constraints for each decision
variable). The Show Iteration Results option lets the user step through the
search for the optimal solution. The Use Automatic Scaling option is helpful
when there is big difference between the magnitudes of decision variables and
input data because sometimes that leads to problems due to poor scaling. An
optimization problem is poorly scaled if changes in the decision variables
produce large changes in the objective or constraint functions for some
components of the vector of decision variables than for others. (For example,
if we are trying to ﬁnd the optimal percentages to invest, but the rest of the
data in the problem is in the millions, the solver may run into numerical
difﬁculties because a small change in a value measured in percentages will
have a very different magnitude than a small change in a value measured in
millions.) Some optimization techniques are very sensitive to poor scaling.
In that case, checking the Use Automatic Scaling option instructs it to scale
the data so the effect can be minimized.
The options at the bottom of the Solver Options dialog box have to do
with the numerical details of the algorithm used, and can be left at their
default values. The remaining options—Max Time, Iterations, Precision,
Tolerance, and Convergence, let the user specify the tolerance levels in the
search for the optimal value of the objective function—that is, how close
we want to get to the optimal solution. The default for the tolerance level is
5% because optimization algorithms frequently ﬁnd a near-optimal solution

192
FUNDAMENTAL CONCEPTS
quickly, but then spend a lot of time checking whether this is the best possible
solution. Specifying a tolerance level of 0% would require that the algorithm
stops when the best solution in its neighborhood is found.
Implementation of the Portfolio Allocation Example from Section 5.3.1
Let us now solve the portfolio allocation problem in section 5.3.1. The
solution is implemented in ﬁle Ch5-PortfolioAlloc.xlsx. Exhibit 5.16 is a
screenshot of the Excel spreadsheet with the model.
Cells B4:E4 are dedicated for storage of the values of the decision vari-
ables, and will be the changing cells for Solver. It is convenient then to keep
the column corresponding to each variable dedicated to storing data for that
particular variable. For example, row 7 contains the coefﬁcients in front of
each decision variable in the objective function (the expected returns). Simi-
larly, the cell array B10:E16 contains the coefﬁcients in front of each variable
in each constraint in the problem. Cells H10:H16 contain the right-hand side
limits of all constraints. (In fact, we are entering the data in matrix form.)
In cell F7, we enter the formula for calculating the objective function
value in terms of the decision variables:
= SUMPRODUCT($B$4:$E$4,B7:E7)
The SUMPRODUCT function in Excel takes as inputs two arrays, and
returns the sum of the products of the corresponding elements in each array.
In this case, the SUMPRODUCT formula is equivalent to the formula
= B7*B4+C7*C4+D7*D4+E7*E4
but the SUMPRODUCT formula is clearly a lot more efﬁcient to enter, especially
when there are more decision variables.
EXHIBIT 5.16
Excel model of the portfolio allocation example from section 5.3.1.

Optimization Modeling
193
Cells F10:F16 contain the formulas for the left-hand sides of the seven
constraints. For example, cell F10 contains the formula
= SUMPRODUCT($B$4:$E$4,B10:E10)
Now the advantage of organizing the data in this array form in the
spreadsheet is apparent. When creating the optimization model, we can
copy the formula in cell F10 down to all cells until cell F16. Thus, we can
enter the information for multiple constraints very quickly.
Click the Data tab, click Solver in the Analysis group, and enter the
information in Exhibit 5.17.
Our goal is to maximize the expression stored in cell F7 by changing
the values in cells B4:E4, subject to a set of constraints. Note that since
all constraints in rows 11–16 have the same sign (≥), we can pass them to
Solver as one entry. Solver interprets the constraint
$F$11:$F$16 < = $H$11:$H$16
equivalently to the set of constraints
$F$11< = $H$11
$F$12< = $H$12
$F$13< = $H$13
$F$14< = $H$14
$F$15< = $H$15
$F$16< = $H$16
EXHIBIT 5.17
Solver inputs for the portfolio allocation problem.

194
FUNDAMENTAL CONCEPTS
We also check the Assume Linear Model and the Assume Nonnegative
options. The optimal solution is contained in the spreadsheet screenshot in
Exhibit 5.15. To attain the optimal return of $931,800 while satisfying all
required constraints, the manager should invest $2,000,000 in Fund 1, $0
in Fund 2, $4,000,000 in Fund 3, and $4,000,000 in Fund 4.
Implementation of the Capital Budgeting Example from Section 5.3.3
Next, we brieﬂy show an example of implementing a binary programming
problem with Solver. See ﬁle Ch5-CapitalBudgeting.xlsx. Worksheet Model
contains the implementation of the original model, without constraints (a)
and (b). (See a screenshot of the model in Exhibit 5.18.) Worksheet Model 2
contains the original model plus constraint (a). Worksheet Model 3 contains
the original model plus constraints (a) and (b).
The spreadsheet setup of the problem in worksheet Model is very similar
to the setup of the portfolio allocation model from section 5.3.1. Cells B4:I4
are dedicated to storing the values of the binary decision variables x1, . . . , x8,
and will become the changing cells for Solver. Cells B7:I8 contain the coef-
ﬁcients of the objective function (the estimated beneﬁt from each project),
and cell J7 contains the formula = SUMPRODUCT(B7:I7,$B$4:$I$4), which
calculates the total beneﬁt, and will become the target cell for Solver. Cells
B10:I10 contain the coefﬁcients of the total budget constraint, and cell J10
contains the formula = SUMPRODUCT(B10:I10,$B$4:$I$4), which calcu-
lates the total cost of the selected projects. Cell L10 contains the total budget
limit, which is part of the input data.
The Solver dialog box is shown in Exhibit 5.19. Note that one special
set of constraints that is speciﬁed in the Constraints window is $B$4:$I$4
= binary. This instructs Solver to choose only 0–1 values for the changing
cells B4:I4. The suboptimal solution after running Solver is illustrated in
Exhibit 5.20.
An interesting example of the difference the Options speciﬁcations in
Solver make is provided by the example in the worksheet Model 2 in the
same ﬁle, which implements the original capital budgeting problem plus
EXHIBIT 5.18
The capital budgeting optimization model in Excel.

Optimization Modeling
195
EXHIBIT 5.19
Solver dialog box for the capital budgeting
optimization model.
constraint (a) (see section 5.3.3 for the formulation of constraint (a)). If
we start with no entries in cells B7:I7 (the decision variables) and leave the
Solver Options defaults when we run the optimization, Solver returns the so-
lution in Exhibit 5.20, which has an objective function value of $2,065,000.
The optimal solution is actually different: the objective function value is
$2,115,000, and the optimal values for the binary variables are as follows:
(0,1,0,1,1,1,0,0). We can reach the optimal solution if we tighten our toler-
ance, that is, if we set the Tolerance parameter in the Solver Options dialog
box to 0% (instead of the default of 5%). Then, Solver will search until
it ﬁnds the absolute optimal solution, rather than accept a solution that
has an objective function that can be within 5% of the optimal objective
function value.
Changing the defaults does not make much difference in the case of
linear problems, but can be very important when solving difﬁcult nonlinear
or integer problems. Even when the defaults are changed, however, Solver
EXHIBIT 5.20
Suboptimal solution returned by Solver for the model in worksheet
Model 2 when the starting point is 0 for all changing cells, and the options
(including the tolerance level) are left at their default values.

196
FUNDAMENTAL CONCEPTS
may return erroneous or suboptimal solutions when called on nonlinear and
integer problems.
Palisade’s Evolver
As we mentioned in sections 5.4.4 and 5.7, Palisade’s Evolver is an Excel add-
in that employs genetic algorithms to come up with the optimal solution. The
problem speciﬁcation is very similar to the problem speciﬁcation with Excel
Solver, so we will provide only a brief discussion for the implementation of
the portfolio allocation example from section 5.3.1 and the capital budgeting
example from section 5.3.3. When the optimization problem is linear, it
is not really worthwhile to employ genetic algorithms—linear optimization
algorithms in classical solvers are very efﬁcient. However, when the problem
contains integer variables, or nonlinear functions, genetic algorithms may
ﬁnd a better solution than classical algorithms, and may ﬁnd it faster.
Palisade’s Evolver tab in the Excel ribbon contains the commands dis-
played in Exhibit 5.21.
The model is entered by clicking the Model Deﬁnition button. The
Settings button allows for changing the settings of the genetic algorithm and
the length of the search, such as the initial population size, the number of
trials to be run, the maximum time to run the algorithm, and so on. Once
the model and the settings are speciﬁed, the user clicks the Start button to
begin the algorithm.
Implementation of the Portfolio Allocation Example from Section 5.3.1
The spreadsheet setup of the model in Excel is the same as in Exhibit 5.16.
(see also worksheet Model (Evolver) in the ﬁle Ch5-PortfolioAlloc.xlsx.) It
is helpful to dedicate cells in the spreadsheet to the formula for the ob-
jective function, the left and the right hand side of the constraints, and
the decision variables. The Evolver dialog box is then ﬁlled out as follows
(Exhibit 5.22). The objective function value is entered under Cell, and the
user speciﬁes whether the value should be is maximized or minimized. The
Adjustable Cell Ranges ﬁelds are equivalent to the Changing cells range in
EXHIBIT 5.21
Palisade’s Evolver tab.

Optimization Modeling
197
Excel Solver, and are ﬁlled with references to the cells that store the values of
the decision variables. Evolver also allows for specifying the ranges for the
decision variables. These ranges are entered under Minimum and Maximum
in the Adjustable Cell Ranges ﬁelds. Under Values, one can specify whether
the decision variables are continuous (choose Any, which is the entry in
Exhibit 5.22) or discrete (choose Integer).
An additional option under Adjustable Cell Ranges is to specify whether
the Budget rule should be used when trying different solutions (the current
selection in Exhibit 5.22). This option speeds up calculations if the decision
variables in the problem need to add up to a speciﬁc number, which is the
case in many portfolio allocation models, as the portfolio weights often
need to add up to 1. In our example, the amounts invested need to add
up to the amount available for investment, $10,000,000. We can speed up
the search for the optimal solution by entering initial values in all decision
variable cells (cells B4:E4 in Exhibit 5.16) so that they add up to $10 million.
Evolver will then assume that this is the “budget” to which it needs to adhere
while searching for the optimal solution. If no such budget is required,
EXHIBIT 5.22
Evolver dialog box with the formulation of the
portfolio allocation problem.

198
FUNDAMENTAL CONCEPTS
then the Budget option can be changed to Recipe, which is a more generic
speciﬁcation, or some other options. (Click Group and then Edit to see a
list of all options.) If there are different groups of variables, that is, some of
them have to add up to a speciﬁc “budget,” while others do not, or some
are continuous, while other are integer, then separate groups of decision
variables can be entered by clicking Group and then New and specifying a
method with every new group.
Finally, constraints can be entered or edited in the Constraints ﬁeld by
clicking Add or Edit. In contrast to classical solvers such as Excel Solver,
constraints can be speciﬁed as “soft” or “hard.” Hard constraints are ones
that must be satisﬁed, while soft constraints can be violated, and Evolver
will report if they are. Classical optimization solvers treat constraints only
as “hard.” It is useful to enter a description of the constraint, as we have
done in the ﬁrst column of the Constraints ﬁeld.
A screenshot of the Evolver Optimization Settings dialog box is provided
in Exhibit 5.23. It is generally better to leave the general settings at their
defaults, but control the running time of the algorithm. For example, we
can specify the maximum number of trials to run by checking Trials and
entering a value, or the maximum amount of time by checking Time, both
under the Runtime tab.
Once we have speciﬁed the model and the settings, we click the Start
button. A dialog box appears (see Exhibit 5.24) that reports which trial is run
right now (Trial), how many of the solutions so far satisfy all constraints
(Trial/Valid), how long the algorithm has been running (Runtime), what
EXHIBIT 5.23
Evolver Optimization Settings dialog box.

Optimization Modeling
199
EXHIBIT 5.24
Evolver
Progress dialog box.
was the original value of the objective function which, in our case, is the
dollar return on the portfolio (Original), and what is the best value of the
objective function in all iterations of the algorithm so far (Best). We can
stop the algorithm by clicking on the red button in the lower right corner
of the Evolver Progress dialog box, and see a more detailed report of the
optimization results.
As we mentioned before, even after running Evolver for many trials, it
may not ﬁnd the optimal solution. However, in most practical instances, it
will get to a solution that is close to the optimal relatively quickly.
Implementation of the Capital Budgeting Example from Section 5.3.3
We
brieﬂy show the implementation of the capital budgeting example from
section 5.3.3 in order to illustrate some differences in variable speciﬁcation
in Evolver for linear and integer programming optimization problems.
The spreadsheet setup for the model is the same as in Exhibit 5.18
(see also worksheet Model 3 (Evolver) in ﬁle Ch5-CapitalBudgeting.xlsx.)
Exhibit 5.25 illustrates the dialog box for Evolver for that example. The
main ideas are the same as the implementation of the portfolio allocation
example in the previous section, but we would like to draw attention to
a couple of differences. First, the decision variables in this problem (cells
B4:I4) are binary. To enter that information in Evolver, we specify bounds
of 0 and 1 for the Adjustable Cell Ranges, and change the entry under Values
to Integer. Second, we do not have restrictions on the number of projects
that can be funded. Therefore, the budget method does not apply here.
Instead, we select Recipe as the method for this group of decision variables.
We do have a total budget, but the budget refers to the total funding costs
that we are allowed to assume, not to the values of the decision variables

200
FUNDAMENTAL CONCEPTS
EXHIBIT 5.25
Evolver dialog box for the implementation of the
capital budgeting example.
themselves. Therefore, we specify the total budget as a separate constraint
under Constraints.
MATLAB’s Optimization Toolbox
MATLAB’s Optimization Toolbox has a very different approach and syn-
tax for formulating optimization problems. As explained in Appendix C,
MATLAB is an array-based mathematical language. It expects optimization
formulations to be passed to its solvers in an array form, and it contains func-
tions that call speciﬁc solvers for speciﬁc types of optimization problems. (See
Exhibit 5.26 for a quick overview. See also MATLAB’s help for a complete
listing.) If the Genetic Algorithms and Direct Search Toolbox is available,
the range of solvers is expanded to include randomized search algorithms.
The most often used solver in MATLAB is fmincon, which is the solver
for general nonlinear optimization. However, if we know the type of prob-
lem we are trying to solve, we are always better off giving the optimization
software as much information as we can in order to make the optimization

Optimization Modeling
201
EXHIBIT 5.26
MATLAB Optimization Toolbox functions/solvers appropriate for
speciﬁc types of optimization problems. Asterisk (*) is used to denote solvers that
are available only through the Genetic Algorithms and Direct Search Toolbox.
Blank entries mean that there is currently no solver available. Technically, the
Genetic Algorithms and Direct Search Toolbox can be used for solving discrete
problems as well; however, this requires additional programming.
Objective
Constraints
Linear
Quadrtic
Least Squares
Smooth
Nonlinear
Nonsmooth
None
N/A
quadprog
lsqcurvefit,
lsqnonlin
fminsearch,
fminunc
fminseach,*
Bound
linprog
quadprog
lsqucurvefit,
lsqlin,
lsqnonlin,
lsqnonneg
fminbnd,
fmincon,
fseminf
*
Linear
linprog
quadprog
lsqlin
fmincon,
fseminf
*
Smooth
nonlinear
fmincon
fmincom
fmincom
fmincon,
fseminf
*
Discrete
bintprog
process more accurate and efﬁcient. In ﬁnancial applications, we are most
likely to encounter situations in which we will need linprog (an LP solver),
quadprog (a quadratic programming solver), bintprog (a binary program-
ming solver), and randomized search algorithms, such as simulannealbnd
and ga.
We will use linprog and bintprog to solve the portfolio allocation and
capital budgeting examples in sections 5.3.1 and 5.3.3. Before we show the
actual implementation, we need to explain how solvers are actually called
in MATLAB. There are two ways to call the solvers: as functions directly
from the command prompt (equivalently, from within M-ﬁles) or through
the optimization tool.
To solve an LP, we would call linprog(f,A,b,Aeq,beq,lb,ub). The
function arguments f,A,b,Aeq,beq,lb,ub are supposed to correspond to
the following LP formulation:
min
x
f′x
s.t.
Ax ≤b
Aeq · x = beq
lb ≤x ≤ub

202
FUNDAMENTAL CONCEPTS
Therefore, before we call linprog, we need to write our LP in this
particular form. We will show how this is done shortly.
The MATLAB optimization tool provides an interface between the
solvers and the user. While using such an interface may not be optimal when
solving sequences of optimization problems, as in the case of dynamic pro-
gramming or stochastic programming, it is quite convenient when solving a
single optimization problem because it lists all available solvers, prompts the
user for the different inputs that the optimization solvers expect, and allows
for easy manipulation of the options. Options can be speciﬁed directly when
a solver is called from the command prompt as well, but it is more clumsy.
The optimization tool is called by typing optimtool at the MAT-
LAB command prompt. The optimization tool dialog box is shown in Ex-
hibit 5.27. The panel on the left-hand side is dedicated to the speciﬁcation
of the inputs: the type of solver that needs to be called, the arrays with the
problem data, the starting point, and so on. The panel in the middle allows
for changing the level of tolerance in the search for the optimal solution.
For example, the Function tolerance is currently set at the default value of
1e-06, which is 10−6. This means that the selected algorithm will continue
to iterate through solutions until the improvement in successive objective
function values becomes smaller than 10−6. Sometimes, such level of ac-
curacy is unnecessary. For example, if our objective function is measured
in dollars and cents (e.g., the optimal revenue in the portfolio allocation
EXHIBIT 5.27
The optimization tool interface in MATLAB.

Optimization Modeling
203
example in section 5.3.1), then technically we do not need precision beyond
2–3 points after the decimal point. Therefore, we can speed up the algorithm
by relaxing the requirements on tolerance. Other useful options include level
of display (whether to show iterations of the optimization algorithm or not),
and function plots at intermediate stages.
Implementation of the Portfolio Allocation Example from Section 5.3.1
The ﬁle PortfolioAlloc.m contains code for computing the optimal portfolio
allocation for the portfolio allocation example in section 5.3.1, which is an
LP problem.
The process for formulating the optimization problem is as follows.
First, we ask ourselves what corresponds to the vector of decision variables
x in the linprog formulation. In our example, x maps directly to the vector
of amounts to invest in each asset. We then enter problem data, such as
the expected returns vector expReturnsVec. We allocate empty arrays to
store the values of the optimal solution amountsVec and the optimal value
of the objective function optReturn after collecting the information from
the solver.
Next, we create the input data for the linprog solver. The solver expects
a vector of objective function coefﬁcients f, which in our case is the vector
of expected returns on the different assets. Note, however (line 12) that
we specify f as -expReturnsVec. This is because expects a minimization
problem, and our objective function is to maximize expected revenue, so we
need to convert our problem to the required form by minimizing the negative
of the expression for the maximization objective. (See section 5.1.1.) At the
end (line 48), we take the negative of the optimal value for expected return
found by the solver, so that we arrive at the actual optimal value for the
maximization problem. The optimal values of the decision variables, which
in this case are the amounts to invest, amountsVec, do not need to be
modiﬁed after the optimization results are returned by the solver.
Lines 14–40 contain the speciﬁcation of the other inputs in the prob-
lem. Note that we are in fact using the matrices of coefﬁcients for the groups
of constraints (inequality, equality, and nonnegativity) that we deﬁned in
section 5.3.1. Namely, A (lines 15–20) is the matrix of left-hand-side in-
equality constraint coefﬁcients; Aeq (line 28) is the matrix of left-hand-side
equality constraint coefﬁcients, b (line 23) is the vector of right-hand-side
coefﬁcients of the inequality constraints, and beq (line 32) is the vector of
right-hand-side coefﬁcients of the equality constraints (in our example, we
have only one equality constraint). The lower bounds, lb (line 36), are the
zeros from the right-hand side of the nonnegativity constraints on the deci-
sion variables, so we create a vector array with size equal to the number of
decision variables that contains only zeros. We have explicit upper bounds

204
FUNDAMENTAL CONCEPTS
of $4,000,000 on each decision variable since we cannot invest more than
that amount in each individual fund, so we could have stated those bounds
as the input vector ub. However, these bounds have already been included
in the matrix A, so we do not need to state them again. Instead, we state the
individual upper bounds as inﬁnity, that is, as the product of the number
inf (in MATLAB, that denotes inﬁnity) and a vector of ones. (See line 40
of the previous code.)
An equivalent formulation of the constraints from MATLAB’s perspec-
tive would have been to specify the arrays A, beq, and ub as
A =
[1 0 1 0;
4 2 2 1]
b = [6000000 20000000]’
ub = 4000000*ones(numAssets,1)
with all other input arrays remaining the same.
After all inputs have been speciﬁed, the linprog solver is called (line
42). The syntax in line 42 outputs requests that the output from the opti-
mization be stored in the arrays we speciﬁed at the beginning, amountsVec
and optReturn. The results are then printed to screen, and are formatted
according to format(‘bank’) (line 44), which basically rounds numbers to
two decimal places.
After running the M-ﬁle, we obtain the following output:
amountsVec =
2000000.00
0.00
4000000.00
4000000.00
optReturn =
931800.00
If you prefer to solve the problem by using the optimization tool, you
need to ﬁll out the dialog box as shown in Exhibit 5.28. Select linprog
as the solver from the drop-down menu at the top. Under Algorithm, you
can either leave the default (Large Scale), or select Medium scale—simplex,
which is appropriate because our problem is quite small. We entered the
names of the arrays that correspond to the objective function coefﬁcients
and the constraint coefﬁcients in the corresponding ﬁelds in the left panel of
the dialog box. Note that these arrays must be preﬁlled, that is, they must be
entered from the command prompt, or read from a ﬁle before the problem

Optimization Modeling
205
EXHIBIT 5.28
The optimization tool dialog box for the portfolio allocation
problem.
is solved through the optimization tool; otherwise the solver will complain
that these arrays are empty. You can make sure that the arrays f, A, b, Aeq,
beq, lb, and ub are ﬁlled in by checking ﬁrst whether they are listed in the
Workspace window at the upper left corner of the MATLAB desktop. Once
all the input data are speciﬁed, click on the Start button in the left panel to
solve the problem. The solution appears in the ﬁeld below the Start button.
The optimization model can be saved as script in an M-ﬁle by selecting
File | Generate M-ﬁle from the main menu in the optimization tool. In addi-
tion, the optimization results can be exported to the workspace and further
manipulated by selecting File | Export to Workspace. To export only the
results, as opposed to the entire model, check Export results to a MATLAB
structure named: optimresults. This creates a structure of results, optim-
results, that shows up in the Workspace. So, for example, the optimal
solution (the portfolio allocation) can be called by typing optimresults.x
at the command prompt. (See Exhibit 5.29.) Similarly, the optimal value of
the objective function can be retrieved by typing optimresults.fval at the
command prompt.
Implementation of the Capital Budgeting Example from Section 5.3.3
The
ﬁle CapitalBudgeting.m contains code for ﬁnding the best combination of
projects to fund from the capital budgeting example in section 5.3.3, which is

206
FUNDAMENTAL CONCEPTS
EXHIBIT 5.29
Handling the structure of optimization results exported from
MATLAB’s optimization tool.
a binary integer problem. We use the bintprog solver in MATLAB to solve
the optimization problem. The main ideas of the formulation are very similar
to the ones from the portfolio allocation example. The solver bintprog
assumes that all decision variables in the optimization problem are binary,
and requires that the formulation be in the following form:
min
x
f′x
s.t.
Ax ≤b
Aeq · x = beq
x
binary
The code in ﬁle CapitalBudgeting.m solves the original optimization
problem; then solves the original problem with the additional constraint (a),
and then solves the original problem with two additional constraints, (a)
and (b). (See section 5.3.3 for the constraint speciﬁcation.)
The formulation of the original capital budgeting problem is in lines
6–32. Similarly to the portfolio allocation example, in lines 11–12, we cre-
ate arrays in which the optimal values of the objective function (optBene-
fits) and the decision variables (fundBin) will be stored. Again, we have a
maximization problem, so we convert it to the minimization problem

Optimization Modeling
207
required by bintprog by considering the negative of the objective func-
tion. We have only one constraint: that the sum of all costs cannot be more
than the allocated budget of $1,000,000, so the matrix A (line 20) and the
vector of right-hand-side constraint limits b (line 23) are small. We have
no additional equality constraints, so we create empty arrays for the input
matrices Aeq and beq (lines 26 and 27, respectively). We solve the problem
by calling the solver, storing the optimal results in the arrays dedicated to
them, reverting the sign of the optimal value of the objective function, and
printing the output to screen (lines 29–32).
Next, we implement the original capital budgeting problem plus con-
straint (a). Recall from section 5.3.3 that the formulation of the con-
straint was
x1 −x8 ≤0,
so we add a second row to the matrix of inequality constraint coefﬁcients
A, with 1 in the position corresponding to the ﬁrst binary variable, –1 in
the eighth position, and 0s everywhere else (lines 38–39). We also add an
entry of 0 to the vector of right-hand side limits of the inequality constraints,
b (line 40). All other problem speciﬁcations remain the same. We are now
ready to call the solver again, and print the results to screen.
EXHIBIT 5.30
Formulation of the capital budgeting problem with constraints
(a) and (b) with MATLAB’s optimization tool.

208
FUNDAMENTAL CONCEPTS
The addition of constraint (b) happens in a similar manner. The problem
formulation is updated and passed to the solver in lines 50–55. When the
M-ﬁle is run, the optimization results from all three formulations are printed
to screen.
The formulation of the capital budgeting problem with the MATLAB
optimization tool is very similar to the formulation of the portfolio allocation
problem, but the Solver ﬁeld contains a reference to the bintprog solver,
rather than the linprog solver. Again, the data arrays that are input in
the problem need to be speciﬁed before the Start button is pressed. (See
Exhibit 5.30.)
NOTES
1. See Appendix A on the companion web site for a review of the matrix-vector
notation.
2. Optimization formulations can handle decision variables that are matrix arrays
as well, but these types of problems are too advanced for the purposes of this
book. This area of optimization is called semideﬁnite programming. See Fabozzi,
Kolm, Pachamanova, and Focardi (2007) for a discussion of its applications in
ﬁnance.
3. In other words, by setting the derivative of the objective function to zero.
4. Unfortunately, there is no straightforward way to request that all optimal solu-
tions be listed in optimization software output. If we are interested in checking
whether there is another optimal solution, we need to modify the optimization
problem formulation to exclude the current optimal solution, and rerun the
optimization solver again. If a second optimal solution exists, it will be found
by the solver when the ﬁrst optimal solution is no longer a feasible option.
5. Linear expressions involve sums and differences of terms of the kind (constant ·
decision variable), and exclude expressions like (constant · decision variable2),
(decision variable 1 · decision variable 2), (decision variable 1 / decision variable
2), log(decision variable), and so on. Note that an expression of the kind (con-
stant2 · decision variable) is still a linear expression in the decision variable, even
if it is not a linear expression in the constant. Linear optimization formulations
are concerned only with whether the expressions in the objective function and
constraints are linear expressions in the decision variables.
6. See Appendix A on the companion web site for a deﬁnition of positive semidef-
inite matrix.
7. In the stock market, a round lot is 100 shares. In the bond market, a round lot
varies with the type of bond.
8. A mutual fund, more speciﬁcally an open-end investment company, uses pro-
ceeds from the sale of shares to the public to invest in various securities.
The value of one share of a mutual fund is computed by dividing the differ-
ence between the mutual fund’s asset and liabilities by the number of shares

Optimization Modeling
209
outstanding. This value is called the net asset value (NAV). Mutual funds have
different investment objectives. In the case of a money market fund, the fund
manager can only invest in short-term high quality investments (money market
instruments). This type of mutual fund has the lowest risk and therefore the
lowest expected return (see Exhibit 5.4).
9. This is just a simpliﬁed example of portfolio allocation with risk considerations.
Deﬁnitions of risk and more sophisticated portfolio allocation schemes are
discussed in detail in Chapters 7 through 9.
10. See Chapter 2 for a deﬁnition of short selling.
11. As we mentioned earlier, there are often different ways to formulate an opti-
mization problem for the same business situation. For example, the decision
variables for this example can be deﬁned as the percentages invested (rather
than the dollar amounts invested) in each fund. The problem formulation will
be very similar, and the optimal solution will qualitatively be the same.
12. In a deﬁned beneﬁt pension plan, the sponsor of the plan, such as corporation
or a municipality, has contractually agreed to make payments to the plan par-
ticipants of a speciﬁed amount after the participant retires. In contrast, in a
deﬁned contribution retirement plan, the employer agrees only to set aside prior
to the employee’s retirement a certain amount of money each year but it is the
responsibility of the employee to invest those funds.
13. Note that in our illustration, we are assuming high investment-grade quality
bonds. This means that the issuers of these bonds have a low probability of
failing to meet their obligation to make the coupon payments.
14. See http://www.ilog.com/products/cplex/. We will discuss optimization solvers
and software later in this chapter.
15. Some randomized search solvers accept such conditions, see sections 5.4.4 and
5.7. However, such algorithms do not guarantee that they will ﬁnd the optimal
solution.
16. In mathematical terms, a simplex is the convex hull of a set of N + 1 points in
N-dimensional space, that is, the minimum set that contains all the points, and
any line drawn between points in the set stays within the set.
17. Recall that the gradient of a function f of N variables x1, x2,. . ., xN is deﬁned
as the partial derivative with respect to each individual variable,
∇f (x) =
 ∂
∂x1
f (x), . . . ,
∂
∂xN
f (x)
 
18. A heuristic is a logical, approximate way to solve an optimization problem that,
however, is not necessarily guaranteed to produce the optimal result. The initial
selection of projects based on the ranking of their beneﬁt/cost ratios in the capital
budgeting example in section 5.3.3 of this chapter was an example of a greedy
heuristic—our simple investment algorithm selected each subsequent project as
the project with the highest ranking among the projects not already selected.
As we saw, this algorithm did not give us the optimal solution, although it did
produce a good solution.

210
FUNDAMENTAL CONCEPTS
19. For an intuitive overview of some of these algorithms, see Chapter 9 in Fabozzi,
Kolm, Pachamanova, and Focardi (2007). For complete mathematical treatment
of the subject, see, for example, Bertsimas and Tsitsiklis (1997) or Nemhauser
and Wolsey (1999).
20. For more rigorous discussion, see Bertsimas and Tsitsiklis (1997).
21. Order notation (O(.)) allows us to represent the idea that an expression or a
quantity is “about the same size as” another expression or quantity. A function
f(x) is “of the order of” a function g(x) if f(x) does not exceed g(x) in magnitude
(up to a scaling factor c) around any speciﬁc point of interest. If the speciﬁcation
of the point is omitted, it is usually assumed that the statement is valid for all
points on the real line.
22. See
MOSEK
ApS,
The
MOSEK
Optimization
Software,
http://
www.mosek.com/.
23. See IBM ILOG CPLEX Optimizer: High Performance Mathematical Program-
ming Engine, http://www.ilog.com/products/cplex/. At the time of writing of this
book, ILOG became part of IBM. See also http://www-01.ibm.com/software/
integration/optimization/cplex-optimizer.
24. See AIMMS, Optimization Software for Operations Research Applications,
http://www.aimms.com.
25. See
AMPL,
A
Modeling
Language
for
Mathematical
Programming,
http://www.ampl.com/.
26. See GAMS, The GAMS System, http://www.gams.com/.
27. See Palisade, The Decision Tools Suite: Integrated Decision Making in Excel,
http://www.palisade.com/.
28. See Frontline Systems, http://www.solver.com/.
29. See Axioma, Axioma Portfolio Optimizer, http://www.axiomainc.com/.
30. See MSCI Barra, Barra Optimizer, http://www.barra.com/.
31. See ITG, ITG Opt, http://www.itginc.com/.
32. See Northﬁeld, Optimizer Service: Risk Analysis and Portfolio Construction,
http://www.northinfo.com/.

CHAPTER6
Optimization under Uncertainty
T
he optimization formulations presented in Chapter 5 have numerous
applications in ﬁnance and other ﬁelds. However, that discussion omitted
an important aspect of realistic optimization modeling. We assumed that
the input data, such as the coefﬁcients in front of the decision variables in
the objective function and the constraints, or the cash ﬂows that happen
in a multistage system, are certain. In practice, however, optimization often
needs to be performed under conditions in which the input data are random,
or represent statistical estimates and subjective guesses. Models in which all
input data are ﬁxed or nonrandom are often referred to as deterministic.
By contrast, models that contain parameters that vary are referred to as
nondeterministic, probabilistic, or stochastic.
Concepts from probability theory, statistics, and simulation (Chapters
3 and 4) can be used to extend the basic framework of deterministic opti-
mization (Chapter 5) and to deal with uncertainty. It is important to keep
in mind, however, that randomness adds a high level of complexity to opti-
mization formulations, and that the output of the resulting models needs to
be interpreted carefully.
There are three general approaches for incorporating considerations
for uncertainty in optimization problems: dynamic programming, stochas-
tic programming, and robust optimization. As we mentioned in section 5.6
in the previous chapter, dynamic programming methods are speciﬁcally de-
signed to deal with stochastic uncertain systems over multiple stages. The
optimization problem is solved recursively, going backward from the last
state, and computing the optimal solution for each possible state of the sys-
tem at a particular stage. In ﬁnance, dynamic programming is used in the
context of pricing of some derivative instruments, investment strategies such
as statistical arbitrage, and long-term corporate ﬁnancial planning.
Stochastic programming methods can be used in both single-period and
multiperiod settings. They rely on representing the uncertain data by scenar-
ios, and focus on ﬁnding the strategy so that, for example, the expected value
211

212
FUNDAMENTAL CONCEPTS
of the objective function over all scenarios (sometimes, penalized for some
measure of risk) is optimal. Stochastic algorithms have been successfully ap-
plied in a variety of ﬁnancial contexts, such as management of portfolios of
ﬁxed income securities, corporate risk management, security selection, and
asset/liability management for individuals as well as for ﬁnancial entities
such as banks, pension funds, and insurance companies.1 They are partic-
ularly useful in situations in which modeling complicated dependencies in
a number of uncertain parameters over multiple time periods is essential.
This kind of situations often arise, for example, in managing callable bond
portfolios or international asset portfolios, where the callable feature of the
bonds, interest rate risk, default risk, or currency risk need to be taken into
consideration.
Robust optimization is a technique whose applications in ﬁnance have
been explored more recently. It can be used to address the same type of prob-
lems as dynamic programming and stochastic programming do; however, it
takes a worst-case approach to optimization formulations. In addition, in
robust optimization one typically makes relatively general assumptions on
the probability distributions of the uncertain parameters in order to work
with problem formulations that are more tractable computationally.
The ﬁelds of dynamic programming, stochastic programming, and ro-
bust optimization have some overlap, but historically, they have evolved
independently of each other. This chapter explains the three techniques for
optimization under uncertainty in detail.
6.1
DYNAMIC PROGRAMMING
As explained in section 5.6, dynamic programming solves a large multistage
optimization problem sequentially, starting at the last stage and proceeding
backward, thus keeping track only of the optimal paths from any given time
period onward.
Dynamic programming under uncertainty is sometimes also called
stochastic control.2 It shares the main elements of dynamic programming
models we considered in section 5.6: There is an underlying dynamic system
and an objective function (called a reward or a cost function depending on
whether the problem is a maximization or a minimization) that is additive
over time. The dynamic system at any point in time t is described by a vector
of state variables xt that summarizes all past information about the system.
However, while the state variable in the deterministic dynamic programming
problems we considered in section 5.6 evolved according to the relationship
xt+1 = gt(xt, ut)

Optimization under Uncertainty
213
where ut is a vector of control, or policy, variables to be selected by the
decision-maker, when there is uncertainty in the system, we have
xt+1 = gt(xt, ut, ξt),
where ξt is a random variable (also called disturbance or noise depending
on the context). The reward at time t, which we will denote by
ft(xt, ut, ξt),
accumulates over time, as it did in the case of deterministic dynamic pro-
gramming problems.
Dynamic programming problems can be deﬁned over a ﬁnite horizon,
for example, over a period of time T, or over an inﬁnite horizon. In most
ﬁnancial applications, we encounter ﬁnite horizon dynamic programming
systems, so we will assume that the horizon is ﬁnite and time is discrete. The
total reward/cost can then be written as
T

t=0
ft(xt, ut, ξt).
At the end of section 5.6.1, we presented the expression for the dynamic
programming recursion. In the general case, assuming that we would like
to maximize the total reward, at every state our goal was to ﬁnd a policy
vector ut so that
Vt(xt) = max
ut

c(ut) + d · V*
t+1(ut)

.
In other words, we selected ut so that the value of the reward from
this stage forward is highest. Suppose now that there is uncertainty, that is,
our actions do not determine the exact outcome, but instead there is some
probabilistic component in the realization of future rewards. In that case, a
natural goal is to select ut so that the expected value of the reward from this
stage forward is highest, where the term “expected value” is used in the sense
of Chapter 3, that is, it is the weighted average of possible outcomes from
some probability distribution on the future values. In other words, we write
Vt(xt) = max
ut

c(ut) + d · E[V*
t+1(ut)|xt]

where E[V∗
t+1(ut)|xt] is the expected value of the optimal reward from this
stage forward, given that we are currently at state xt.

214
FUNDAMENTAL CONCEPTS
To build some intuition, let us go back to the oil well example from
section 5.6. You have purchased a 3-year lease for an oil well. The estimated
reserves of the well are 600,000 barrels. Every year, you can either pump
oil normally (Strategy 1), in which case you pump 100,000 barrels, or use
an enhanced pumping method which allows you to pump 200,000 barrels
(Strategy 2). To extract ut barrels at time t with the enhanced method costs
you 20 · u2
t /xt dollars, where xt is the amount of available reserves at time t.
To extract ut barrels with the normal pumping method is u2
t /xt dollars. The
discount factor per year is 0.9.
The implicit assumption in that example was that we knew exactly
what oil prices would be in each of the three years of the lease. Suppose
instead that the evolution of oil prices in each year of the lease is described
by the tree in Exhibit 6.1, where the numbers above the branches denote
the probabilities of ending up in that node starting from the node at the
previous stage. (Note that the probabilities on all branches emanating from
the same node add up to 1.) In other words, every year the price can be
20% (1.2 times) higher than the price in the previous year with probability
0.40, or be 20% (0.8 times) lower than the price in the previous year with
probability 0.60.
Assuming that you can pump either 100,000 barrels or 200,000 barrels
each year, what is the optimal strategy to maximize the expected present
value (PV) of your proﬁt from the lease? Note that we can no longer know
the exact value, since the total proﬁt from each node forward (except the
nodes at the third stage) has an element of uncertainty. Note also that the tree
in Exhibit 6.1 does not represent the state space of the problem. The state
space should incorporate all information necessary to make a decision going
forward. To make a decision, we need to know (1) the level of remaining
reserves xt, and (2) the price pt. (In the deterministic version of this problem
in section 5.6.1, the price pt was the same for all nodes at the same stage.)
So, in a sense we have a two-dimensional tree: every state is determined by
64.80
$   
54.00
$   
45.00
0
2
.3
4
   $
$   
36.00
$   
28.80
$   
2
1
0
Year
0.40
0.40
0.40
0.60
0.60
0.60
EXHIBIT 6.1
Price process for the oil well problem.

Optimization under Uncertainty
215
F
400,000
$   64.80
G
300,000
$   64.80
H
B
200,000
$   64.80
500,000
$   54.00
I
C
400,000
$   45.00
A
400,000
$   54.00
J
600,000
$   45.00
D
300,000
$   45.00
500,000
$   36.00
K
E
200,000
$   45.00
400,000
$   36.00
L
400,000
$   28.80
M
300,000
$   28.80
N
200,000
$   28.80
2
1
0
Year
0.40
0.40
0.40
0.40
0.60
0.60
0.60
0.60
EXHIBIT 6.2
State space for the oil well problem.
the pair (xt, pt). Exhibit 6.2 illustrates the state space. Note how much larger
the state space is compared to the state space in section 5.6.1.
To solve the problem, we use a sequential optimization algorithm similar
to the algorithm described in section 5.6.1. (See ﬁle Ch6-OilExample.xlsx.)
First, we compute the value function at the last-stage nodes. For example,
the proﬁt at state F is the maximum of the proﬁts obtained using the normal
or the enhanced methods at the price realized and the reserves available at
node F:
V(F) = max

64.80 · 100,000 −100,0002/400,000,
64.80 · 200,000 −20 · 200,0002/400,000

= max {$6,455,000, $10,960,000}
= $10,960,000
Therefore, if we are in state F in year 3 (i.e., if the price per barrel is
$64.80 and we have 400,000 barrels left), the optimal strategy is to use the
enhanced method.
The values at nodes G, H, I, J, K, L, M, and N are computed similarly
(Exhibit 6.3). To compute the values at nodes B, C, D, and E at the previous
stage, we use the recursive relation for the value function. The value function

216
FUNDAMENTAL CONCEPTS
at all states at stages other than the last stage is the sum of the proﬁt obtained
at that stage and the expected (probability-weighted) discounted proﬁt from
states at the next stage that can be reached from the current state:
Vt(xt, pt) = max
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎩
pt · 100,000 −100,0002/xt
+ 0.9 · (0.4 · V∗
t+1(xt −100,000, 1.2 · pt)
+ 0.6 · V∗
t+1(xt −100,000, 0.8 · pt)),
pt · 200,000 −20 · 200,0002/xt +
+ 0.9 · (0.4 · V∗
t+1(xt −200,000, 1.2 · pt)
+ 0.6 · V∗
t+1(xt −200,000, 0.8 · pt))
⎫
⎪⎪⎪⎪⎪⎪⎪⎪⎬
⎪⎪⎪⎪⎪⎪⎪⎪⎭
For example, the proﬁt at state B is calculated as
V(B) = max
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
pB · 100,000.00 −100,000.002/xB
+ 0.90 · (0.40 · V(F) + 0.60 · V(I)),
pB · 200,000.00 −20 · 200,000.002/xB
+ 0.90 · (0.40 · V(G) + 0.60 · V(J ))
⎫
⎪⎪⎪⎬
⎪⎪⎪⎭
This is because if we use the normal method if we are at B, we will reduce
our reserves by 100,000 to 400,000. This means that we will reach F with
probability 0.40 or I with probability 0.60. By contrast, if we use the en-
hanced method, we will reach G with probability 0.40 or J with probability
0.60. Keeping track of the different states is quite challenging, and needs to
be done with care.
The optimal expected proﬁt from state B onwards is calculated to be:
V(B) = max
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
54.00 · 100,000.00 −100,000.002/500,000.00
+ 0.90 · (0.40 · 10,960,000.00 + 0.60 · 7,000,000.00),
54.00 · 200,000.00 −20 · 200,000.002/500,000.00
+ 0.90 · (0.40 · 10,293,333.33 + 0.60 · 6,333,333.33)
⎫
⎪⎪⎪⎬
⎪⎪⎪⎭
= max{$13,105,600.00, $16,325,600.00)
= $16,325,600.00
Therefore, if we are at state B in year 2, we should choose to pump oil with
the enhanced method.
We proceed in the same manner to compute the best method to use and
the expected proﬁt at nodes C, D, E, and A, in that order. We can now
trace the optimal strategy over the three years (see Exhibit 6.3). We start out

Optimization under Uncertainty
217
with 600,000 barrels as reserves, and a price of $45 per barrel. The optimal
strategy at node A is to use the enhanced method. That takes us either to
state C (with probability 0.40) or to state E (with probability 0.60).
If we are in state C, the optimal strategy is to use the enhanced method
again, which will take us either to state H or to state K. In both states H and
K, it is optimal to use the enhanced method again.
If we are in state E, it is optimal to use the enhanced method, which
takes us to state K (with probability 0.40) or N (with probability 0.60). If
we are at state K, it is optimal to use the enhanced method. However, if we
end up at state N, it is optimal to use the normal method.
The expected total proﬁt from the oil well over the three years is the
value function at node A: $17,573,110.67.
As this example showed, the extension of dynamic programming meth-
ods to incorporate uncertainty is logical, but can substantially increase the
level of complexity of already computationally intensive dynamic program-
ming algorithms. In practice, approximation algorithms are often used in
order to reduce the size and complexity of dynamic programming problems.
In particular, we would try to come up with a good estimate of the form of
the optimal policy as a function of the state in which we are, rather than
evaluate the exact optimal policy in every state of the world.3 We will see
F
10,960,000.00
$
G
10,293,333.33
$
H
B
8,960,000.00
$   
16,325,600.00
$
I
C
7,000,000.00
$   
A
14,725,600.00
$
J
17,573,110.67
$    
D
6,333,333.33
$   
$   9,550,400.00
K
E
$   5,000,000.00
$   8,528,200.00
L
$   3,760,000.00
M
$   3,093,333.33
N
$   2,830,000.00
2
1
0
Year
EXHIBIT 6.3
Optimal strategy and proﬁt at each state.

218
FUNDAMENTAL CONCEPTS
some examples when we talk about derivative pricing in Chapter 14, but in
general, there is no recipe for how we might select the approximation.
6.2
STOCHASTIC PROGRAMMING
Perhaps the easiest way to think of a stochastic programming formulation
is to imagine writing an optimization problem formulation of the kind de-
scribed in section 5.2 of Chapter 5, and searching for an optimal solution
over scenarios for the input data.
Consider a general stochastic optimization (say, maximization) prob-
lem, in which we have an objective function F(x, ξ) that depends on a
decision vector x of dimension N and a vector of uncertain parameters ξ
of dimension d. Such optimization problems are not well-deﬁned since the
objective depends on the unknown value of ξ. Namely, every realization
of the vector of random variables ξ corresponds to a different realization of
the objective function. Thus, we have a different probability distribution of
objective function values for every feasible solution x. It is wrong to say that
one probability distribution is “better” than another unless we specify what
“better” means. Hence, it is impossible to state what the optimal solution
x* is, since by deﬁnition the optimal solution is the one that gives the “best”
value of the objective function.
The simplest way to make the objective well-deﬁned is to optimize it
on average:
max
x
f (x) = E[F(x, ξ)],
where the expectation is taken over scenarios for ξ.4 This means that we
deﬁne the optimal solution x* as the solution that results in a probability
distribution for the objective function value with the highest mean of all
probability distributions of objective function values.
What if uncertainty is present in the constraints? In some cases we can
formulate such problems by introducing penalties for violating the con-
straints, thus deﬁning a mean-risk objective function.5 An alternative ap-
proach is to require that the constraints be satisﬁed for all possible (in
particular, the worst-case) values of the uncertain parameters. This is a
stochastic programming method whose philosophy overlaps with the phi-
losophy of robust optimization, which we will explain in the next section.
Finally, we may impose the requirement that the constraints be satisﬁed with
a high probability. This leads to a stochastic programming formulation with
chance constraints.

Optimization under Uncertainty
219
In summary, stochastic programming can be used to address the pres-
ence of uncertain input data in three types of optimization problems:
1. Expected value for one- and multistage models.
2. Models involving risk measures.
3. Chance-constrained models.
Each model type is discussed next.
6.2.1
Multistage Models
In multistage stochastic programming models, decision variables and con-
straints are divided into groups corresponding to time periods, or stages
t = 1, . . . , T. The information structure of the model (i.e., what is known
at each stage) is speciﬁed in advance. The standard form of a multistage
stochastic linear program is6
min
x
˜c′
0x0 + Eξ1[(˜cξ1
1 )′xξ1
1 + · · · + EξT−1|ξT−2[(˜cξ1,...,ξT−1
T−1
)′xξ1,...,ξT−1
T−1
+ EξT|ξT−1[(˜cξ1,...,ξT
T
)′xξ1,...,ξT
T
]]]
s.t.
A0x0
= b0
Bξ1
0 x0+
Aξ1
1 xξ1
1
= bξ1
1
...
...
BξT
T−1xξ1,...,ξT−1
T−1
+ AξT
T xξ1,...,ξT
T
= bξT
T
x0, xξ1
1 , . . . , xξ1,...,ξT−1
T−1
, xξ1,...,ξT
T
≥0
Here the array ξ = {ξ1, . . . , ξ T} represents the realizations of an under-
lying process that drives the uncertainty in the coefﬁcients of the objective
function, and A and B are matrices with data. Note that the vectors of solu-
tions x are indexed off the vectors of uncertainty ξt at each stage t, except at
the beginning (stage 0). In stochastic programming, decision variables can
be divided into two categories: anticipative and adaptive. Anticipative deci-
sion variables (such as x0 in the above formulation) correspond to decisions
that must be made at that particular stage, and all information for mak-
ing the decision is available. Adaptive decision variables (such as xξ1,...,ξt
t
in the previous formulation) depend on future realizations of the random
parameters.
A large number of ﬁnancial applications—asset-liability management,
index tracking, active investment management—can be treated as a sequence

220
FUNDAMENTAL CONCEPTS
of decisions and observations, and represented in this form. The “block”
formulation of the stochastic optimization problem is preferable because
specialized software (stochastic optimization packages in particular) can
take advantage of the structure when applying decomposition algorithms
for solving the problem. In order to complete the multistage stochastic pro-
gramming model, we need to specify the structure of the random process
for the uncertain coefﬁcients, which is typically reduced to a set of scenarios.
The scenarios are organized in an event tree which at each stage describes
the unfolding of the uncertainties with respect to possible values of the un-
certain parameters. The values of these realizations (denoted ξ previously)
are then plugged into the preceding problem formulation.
Exhibit 6.4 shows an example of such a tree if only one uncertain
parameter is modeled. There are three time periods, and two optimization
stages. The nodes represent points in time at which the information about
the realizations of the uncertain parameter is updated. They are numbered
for each stage t. The numbers in bold above the nodes denote the speciﬁc
realizations of the uncertain parameter. At time 0, its value is known and
unique (it is 33 in this example). At that time, there is only one node (node 0),
which is called the root of the tree. At the last stage, there are ST = 5 possible
scenarios, represented by the paths from the root to the leaves of the tree,
that is, the last-stage nodes. The numbers above the arcs of the tree represent
the probabilities of moving to the next node conditional on having reached
its ancestor node. Note that the probabilities on all branches emanating
from the same node add up to 1.
1
0
33
t = 0
t = 1
t = 2
s = 1
s = 2
s = 3
s = 4
s = 5
18
48
10
20
30
50
40
0.50
0.50
0.40
0.40
0.20
0.80
0.20
2
2
1
3
4
5
EXHIBIT 6.4
Simpliﬁed example of a scenario tree.

Optimization under Uncertainty
221
Given this scenario tree, we can create the block stochastic programming
formulation as follows:
■Deﬁne decision variables x(s)
t
for each possible scenario s at each time
period t. There are different ways to deﬁne a set of decision variables,
but one possibility is to have eight of them: x(0)
0 for stage 0; x(1)
1 and x(2)
1
for stage 1; and x(1)
2 , x(2)
2 , x(3)
2 , x(4)
2 , x(5)
2
for stage 2. In this example, the
number of scenarios at each stage is equal to the number of nodes at
that stage because the tree does not recombine.
■Write out the objective as a function of these decision variables and the
uncertain data:
max
x
(c0)′ x0 + π(1)
1

c(1)
1
′
x(1)
1 + π(2)
1

c(2)
1
′
x(2)
1 + π(1)
2

c(1)
2
′
x(1)
2
+ π(2)
2

c(2)
2
′
x(2)
2 + π(3)
2

c(3)
2
′
x(3)
2 + π(4)
2

c(4)
2
′
x(4)
2
+ π(4)
2

c(4)
2
′
x(4)
2 + π(5)
2

c(5)
2
′
x(5)
2
The objective is a sum of the reward at the initial node and the
expected rewards at all remaining nodes. In the expression above, π(s)
t
denotes the probability of scenario s at time t. For example, π(1)
1
= 0.50
and π(4)
2
= (0.50)(0.80) = 0.40.
■Write a set of constraints for each stage and each scenario:
Stage 0:
A(0)
0 x(0)
0 = b(0)
0
Stage 1:
B(1)
0 x(0)
0 + A(1)
1 x(1)
1 = b(1)
1
B(2)
0 x(0)
0 + A(2)
1 x(2)
1 = b(2)
1
Stage 2:
B(1)
1 x(1)
1 + A(1)
2 x(1)
2 = b(1)
2
B(2)
1 x(1)
1 + A(2)
2 x(2)
2 = b(2)
2
B(3)
1 x(1)
1 + A(3)
2 x(3)
2 = b(3)
2
B(4)
1 x(2)
1 + A(4)
2 x(4)
2 = b(4)
2
B(5)
1 x(2)
1 + A(5)
2 x(5)
2 = b(5)
2
Note that the constraints keep track of the ancestor of each node.
For example, nodes 1, 2, and 3 at stage 2 have a common ancestor:
node 1 from stage 1. So, the decision variables associated with the
scenarios ending at those nodes (x(1)
2 , x(2)
2 , and x(3)
2 ) are linked to the

222
FUNDAMENTAL CONCEPTS
decision variable associated with node 1 from stage 1 (x(1)
1 ) via the ﬁrst
three constraints from Stage 2.
■Write the so-called nonanticipativity conditions, if applicable. Nonan-
ticipativity conditions make sure that scenarios with the same past have
identical decisions up to the stage at which they have the same history.
In this case, the nonanticipativity conditions are incorporated implicitly
by our choice of decision variables and the fact that only one scenario
corresponds to each node. Some formulations that involve alternative
deﬁnitions of the decision variables, such as the original nonblock for-
mulation of the portfolio problem, require stating the nonanticipativity
constraints explicitly.7
Four common ways to create scenario trees for the uncertain parameters
are:8
1. Bootstrapping historical data.
2. Using parametric models in which one assumes speciﬁc probability dis-
tributions and then estimates their parameters from data.
3. Generating simple discrete distributions whose moments are then
matched to moments of real data distributions.
4. Constructing vector autoregressive models.
We need to use caution when creating the tree. Its dimension becomes
unmanageable very quickly, and, as the previous simple example illustrated,
the number of decision variables and constraints in the optimization prob-
lem is directly related to the number of scenarios. If, for example, you are
managing a portfolio, and you allow the possible returns for the N assets in
the portfolio to have just two possible realizations at each stage, the total
number of scenarios at the last stage is 2NT. If your portfolio consists of
only 10 assets, and is rebalanced monthly over one year, you would need
to work with 2120 scenarios for the possible asset returns. Needless to say,
optimization problems of such dimension are impossible to solve. Since the
size of the problem tends to grow exponentially with the number of nodes,
it is important to represent the underlying stochastic process with as few
nodes as possible. However, it is also important to take into consideration
the trade-off between the dimension of the problem and the accuracy of
approximation of the underlying stochastic process, otherwise little insight
is gained from solving the optimization problem.
Let us now formulate a simple stochastic optimization problem explic-
itly. Consider again the oil well example from section 6.1. The scenario
tree for the price of oil over the three years of the lease was presented in
Exhibit 6.1. We reproduce it in Exhibit 6.5, with the scenarios explicitly

Optimization under Uncertainty
223
(1,1)
64.80
$   
(2,1)
(0,1)
54.00
$   
45.00
$   
(1,2)
43.20
$   
36.00
$   
28.80
$   
(2,4)
2
1
0
Year
(2,2) 
(2,3)
0.40
0.40
0.40
0.60
0.60
0.60
EXHIBIT 6.5
Scenario tree for the oil well problem with
scenario labels for each stage.
labeled above or next to each node. The ﬁrst number in the node labels is
the time period, and the second number in the label is the scenario at that
stage. Note that even though there are only 3 nodes at the last stage (year 2),
there are 4 scenarios. Namely, a price of $43.20 can be reached in two
ways: the price in year 0 can go up to $54.00 in year 1 and then down to
$43.20 in year 2, or go down to $36.00 in year 1 and then up to $43.20 in
year 2.
We use the optimization formulation from the end of section 5.6.1 of the
previous chapter as a basis for the formulation of the multistage stochastic
programming problem. Let us introduce decision variables x(1)
0
for stage 0;
x(1)
1
and x(2)
1
for stage 1; and x(1)
2 , x(2)
2 , x(3)
2 , x(4)
2
for stage 2 to denote the
available oil reserves in each scenario at each stage. Let us also introduce
variables u(1)
0
for stage 0; u(1)
1 and u(2)
1
for stage 1; and u(1)
2 , u(2)
2 , u(3)
2 , u(4)
2
to
denote the amounts of oil to pump in each scenario at each stage, as well as
binary variables z(1)
0
for stage 0; z(1)
1
and z(2)
1
for stage 1; and z(1)
2 , z(2)
2 , z(3)
2 ,
z(4)
2
to denote the decision of whether to pump or not in each scenario and
at each stage.
As in the original problem formulation, we have the following relation-
ship between u(1)
0 and z(0)
0 :
u(s)
t
= 100,000 · z(s)
t
+ 200,000 · (1 −z(s)
t ), t = 0, 1, 2; s = 1, . . . , St
We also have the relationship between the amount of oil at each stage,
the amount of oil pumped at that stage, and the available reserves at the next
stage. However, we need to be careful to link only variables that are as-
sociated with a speciﬁc scenario, and so we need to keep track of the
“ancestors” of the node at which we are, that is, we need to know how
we reached a particular node. For example, let us consider the node at
stage 3 in the tree that corresponds to a price of $43.20. Since we have two

224
FUNDAMENTAL CONCEPTS
ways of getting to that node, we need to write a separate equality for each
scenario:
x(2)
2
= x(1)
1 −u(1)
1
x(3)
2
= x(2)
1 −u(2)
1
The ﬁrst equality is associated with scenario 2 at stage 3: we got to the
price of $43.20 by going through node 1 at stage 1 (a price of $54.00) ﬁrst.
The second equality is associated with scenario 3 at stage 3: we got to the
price of $43.20 by going through node 2 at stage 1 (a price of $36.00) ﬁrst.
The ﬁnal step in the formulation is to ﬁgure out the probability of each
scenario. Let us denote those by π(1)
0
for stage 0; π(1)
1
and π(2)
1
for stage 1;
and π(1)
2 , π(2)
2 , π(3)
2 , π(4)
2
for stage 2. We have
π(1)
0
= 1 (we start out at that node, so we can ignore this probability)
π(1)
1
= 0.40 (probability of price going up)
π(2)
1
= 0.60 (probability of price going down)
π(1)
2
= 0.40 · 0.40 = 0.16 (probability of price going up twice)
π(2)
2
= 0.40 · 0.60 = 0.24 (probability of price going up and then down)
π(3)
2
= 0.60 · 0.40 = 0.24 (probability of price going down and then up)
π(4)
2
= 0.60 · 0.60 = 0.36 (probability of price going down twice)
The complete stochastic programming formulation of the oil well ex-
ample is as follows:
max
x,u,z
p(1)
0
·
u(1)
0 −z(1)
0 ·

u(1)
0
2
/x(1)
0 −(1 −z(1)
0 ) · 20 ·

u(1)
0
2
/x(1)
0
+ 0.9 · π (1)
1
·

p(1)
1 · u(1)
1 −z(1)
1 ·

u(1)
1
2
/x(1)
1 −(1 −z(1)
1 ) · 20 ·

u(1)
1
2
/x(1)
1

+ 0.9 · π (2)
1
·

p(2)
1 · u(2)
1 −z(2)
1 ·

u(2)
1
2
/x(2)
1 −(1 −z(2)
1 ) · 20 ·

u(2)
1
2
/x(2)
1

+ 0.92 · π (1)
2
·

p(1)
2 · u(1)
2 −z(1)
2 ·

u(1)
2
2
/x(1)
2 −(1 −z(1)
2 ) · 20 ·

u(1)
2
2
/x(1)
2

+ 0.92 · π (2)
2
·

p(2)
2 · u(2)
2 −z(2)
2 ·

u(2)
2
2
/x(2)
2 −(1 −z(2)
2 ) · 20 ·

u(2)
2
2
/x(2)
2

+ 0.92 · π (3)
2
·

p(3)
2 · u(3)
2 −z(3)
2 ·

u(3)
2
2
/x(3)
2 −(1 −z(3)
2 ) · 20 ·

u(3)
2
2
/x(3)
2

+ 0.92 · π (4)
2
·

p(4)
2 · u(4)
2 −z(4)
2 ·

u(4)
2
2
/x(4)
2 −(1 −z(4)
2 ) · 20 ·

u(4)
2
2
/x(4)
2


Optimization under Uncertainty
225
s.t.
u(1)
0 = 100,000 · z(1)
0 + 200,000 · (1 −z(1)
0 )
u(1)
1 = 100,000 · z(1)
1 + 200,000 · (1 −z(1)
1 )
u(2)
1 = 100,000 · z(2)
1 + 200,000 · (1 −z(2)
1 )
u(1)
2 = 100,000 · z(1)
2 + 200,000 · (1 −z(1)
2 )
u(2)
2 = 100,000 · z(2)
2 + 200,000 · (1 −z(2)
2 )
u(3)
2 = 100,000 · z(3)
2 + 200,000 · (1 −z(3)
2 )
u(4)
2 = 100,000 · z(4)
2 + 200,000 · (1 −z(4)
2 )
x(1)
1
= 600,000
x(1)
1
= x(1)
0 −u(1)
0
x(2)
1
= x(1)
0 −u(1)
0
x(1)
2
= x(1)
1 −u(1)
1
x(2)
2
= x(1)
1 −u(1)
1
x(3)
2
= x(2)
1 −u(2)
1
x(4)
2
= x(2)
1 −u(2)
1
u(1)
0 , u(1)
1 , u(2)
1 , u(1)
2 , u(2)
2 , u(3)
2 , u(4)
2 , x(1)
0 , x(1)
1 , x(2)
1 , x(1)
2 , x(2)
2 , x(3)
2 , x(4)
2
≥0
z(1)
0 , z(1)
1 , z(2)
1 , z(1)
2 , z(2)
2 , z(3)
2 , z(4)
2
binary
In the preceding formulation, p(s)
t
denotes the price in scenario s at stage
t. We have
p(1)
0
= $45.00
p(1)
1
= $54.00
p(2)
1
= $36.00
p(1)
2
= $64.80
p(2)
2
= $43.20
p(3)
2
= $43.20
p(4)
2
= $28.80
The dimension of realistic multistage stochastic programming problems
is typically very large, and optimization is challenging even with today’s
advanced technology. For certain types of stochastic problems, and lin-
ear optimization problems in particular, techniques such as nested Benders
decomposition9 and importance sampling can be used. The idea behind

226
FUNDAMENTAL CONCEPTS
Benders decomposition is to split the multistage problem into a series of
two-stage relations. Subproblems of much smaller size than the original
problem are solved at each stage and scenario—these subproblems receive a
trial solution from their ancestors, and communicate a trial solution to their
successors. Some stochastic programming software packages contain sub-
routines for decomposition of large stochastic programming problems that
can be called directly.10 However, if we want to use standard optimization
solvers, we need to implement the decomposition ourselves by calling the
optimization solver repeatedly for each different subproblem.
Because the number of scenarios substantially impacts the speed with
which multistage stochastic optimization problems can be solved, a sub-
stantial amount of research has been dedicated to developing methodologies
for effective scenario generation. The main idea is that scenario genera-
tion should not try to approximate well the probability distributions of the
uncertain parameters, but rather approximate well the optimal value of
the optimization problem. It has been shown that stochastic programming
problems with two stages can be solved very efﬁciently, and with proven
accuracy, by employing Monte Carlo simulation methods.11 However, little
is known about the computational complexity and the quality of approxi-
mation of Monte Carlo sampling methods for multistage problems. In the
ﬁnancial modeling context, factor models and bundling of similar sample
paths (as opposed to building entire scenario trees) have been used in order
to reduce the dimension of such multistage problems.12 Factor models are
discussed in more detail in Chapter 11.
6.2.2
Mean-Risk Stochastic Models
Mean-risk stochastic models use an objective function that is composed
of two parts: the expectation and some measure of risk.13 As explained
earlier in this section, when there is uncertainty in the coefﬁcients in the
optimization formulation, ﬁnding the optimal solution reduces to ﬁnding
the solution that results in the “best” probability distribution of objec-
tive function values. We mentioned one deﬁnition of “best” probability
distribution—the probability distribution with the highest mean. There are
other plausible deﬁnitions, however. In particular, if we are also concerned
about the degree of variability in the probability distribution of the objective
function values, we can include a term in the objective function that penalizes
for risk.
For example, suppose there are N assets with random returns
˜r1, ˜r2, . . . , ˜rN in the next year. We would like to invest percentages
w1, w2, . . . , wN of our capital so as to maximize the portfolio expected
return and penalize for the variance of the distribution of possible portfolio

Optimization under Uncertainty
227
returns. (Portfolio risk measures are discussed in more detail in Chapter 8.)
Suppose we are given a set of S possible scenarios for returns, and µi are
the average returns for assets i = 1, . . . , N over the scenarios. Let rs
i be the
realization of the return of security i in scenario s. The return of the portfolio
in scenario s is simply the sum of the individual asset returns multiplied by
their weights in the portfolio, that is,
N

i=1
rs
i wi
Let us denote the probabilities of the S scenarios by π1, . . . , πS, where
S

s=1
πs = 1
The expected return on a portfolio with weights w1, w2, . . . , wN over
the N scenarios equals
N

i=1
µiwi
and the variance of the portfolio return over the S scenarios is14
S

s=1
πs
⎛
⎜⎜⎜⎜⎜⎝
N

i=1
rs
i wi



portfolio return in scenario s
−
N

i=1
µiwi



expected portfolio return
⎞
⎟⎟⎟⎟⎟⎠
2
Therefore, we can deﬁne the following objective for our portfolio opti-
mization problem under uncertainty:
max
w
N

i=1
µiwi −κ
⎡
⎢⎢⎢⎢⎢⎣
S

s=1
πs
⎛
⎜⎜⎜⎜⎜⎝
N

i=1
rs
i wi



portfolio return in scenario s
−
N

i=1
µiwi



expected portfolio return
⎞
⎟⎟⎟⎟⎟⎠
2⎤
⎥⎥⎥⎥⎥⎦
.

228
FUNDAMENTAL CONCEPTS
EXHIBIT 6.6
Scenarios for the returns of the four funds.
Fund #
1
2
3
4
Scenario 1
50.39%
15.69%
23.29%
2.50%
Scenario 2
−9.02%
−3.96%
−2.25%
2.36%
Mean return
20.69%
5.87%
10.52%
2.43%
Here, κ is a penalty coefﬁcient that is determined by the user—the more
tolerance we have for uncertainty, the smaller the coefﬁcient is. If we only
cared about the expected portfolio return over the S scenarios, we would
set κ to 0. We can specify additional constraints, as we would do in any
optimization problem.
To gain some additional intuition, let us consider a simpliﬁed exten-
sion of the portfolio allocation example in section 5.3.1. Suppose that the
expected returns of the four funds are the same, but we believe that their
returns could end up in one of two scenarios: a “good” scenario, Scenario
1, or a “bad” scenario, Scenario 2 (see Exhibit 6.6). Suppose also that we
believe that the probability of Scenario 1 is 0.30, and the probability of
Scenario 2 is 0.70.
The stochastic programming mean-risk formulation of this problem is
max
w
20.69 · w1 + 5.87 · w2 + 10.52 · w3 + 2.43 · w4
−κ · 0.3 · (50.39 · w1 + 15.69 · w2 + 23.29 · w3 + 2.50 · w4
−(20.69 · w1 + 5.87 · w2 + 10.52 · w3 + 2.43 · w4))2
−κ · 0.7 · (−9.02 · w1 −3.96 · w2 −2.25 · w3 + 2.36 · w4
−(20.69 · w1 + 5.87 · w2 + 10.52 · w3 + 2.43 · w4))2
subject to the remaining constraints in the problem.
Different risk measures can, of course, be deﬁned. We will return to
mean-risk models in Chapters 7 through 9.
6.2.3
Chance-Constrained Models
Chance-constrained stochastic optimization problems contain requirements
on the probability that the solution will satisfy the constraints for all
realizations of the random parameters in the problem. If the original
constraint is
˜a′x ≤b

Optimization under Uncertainty
229
where x is the vector of decision variables and ˜a is a vector of uncertain
coefﬁcients, then the general form of the chance constraint is
P(˜a′x > b) ≤ε
where P denotes probability, and ε is some small number, such as 0.05 (5%).
In order for the probabilistic constraint above to be satisﬁed, we need to ﬁnd
such a solution x such that the original constraint ˜a′x ≤b is violated for at
most ε% of all possible values for the uncertain coefﬁcients. An important
example of a chance-constrained stochastic programming problem in the
portfolio management context is portfolio value-at-risk (VaR) optimization,
which we will see in Chapter 8.
Based on our introduction to optimization models in Chapter 5, it is clear
that a probabilistic constraint is not part of any of the standard optimization
formulations. We need to apply different tricks to convert the constraint into
a form that can be passed to an optimization solver, and this involves making
different assumptions. In the case in which we are given S scenarios for
vector of uncertain coefﬁcients ˜a, we would need to replace this probabilistic
constraint with an equivalent group of constraints:
(a(s))′x ≤b + M · ys,
s = 1, . . . , S
S!
s=1
ys ≤⌊ε · S⌋
ys ∈{0, 1},
s = 1, . . . , S
In the preceding formulation, M is some “large” constant relative to
the size of the problem that is speciﬁed by the user. Note that we have
introduced S new binary decision variables ys, and have S + 1 constraints
instead of the original one probabilistic constraint. If ys = 0, this forces the
constraint
(a(s))′x ≤b
to be satisﬁed, that is, for ˜a′x ≤b to be satisﬁed in scenario s. However, if
ys = 1, the term M · ys is “large,” that is, the right-hand side of the constraint
is no longer restrictive, and the constraint no longer needs to be satisﬁed.
The additional constraint
S

s=1
ys ≤⌊ε · S⌋

230
FUNDAMENTAL CONCEPTS
limits the number of binary variables that are 1 to not more than ⌊ε · S⌋
(which is the integer part of ε · S). For example, if we are given 115 scenarios
for ˜a, and ε = 5%, we guarantee that not more than 5 (=⌊0.05 · 115⌋=
⌊5.75⌋) of the y’s are 1, that is, the constraint is not violated in more than
95% of the scenarios.
The introduction of binary variables and additional constraints increases
the size and complexity of the original optimization problem signiﬁcantly,
and can overwhelm even the best solvers when the number of scenarios
(and, hence the number of binary variables) is large. Moreover, the problem
type becomes nonconvex, which means that if the solver returns a solution,
we cannot be conﬁdent that it is the optimal one. Therefore, probabilistic
constraints need to be handled with care.
Note that a chance constraint basically requires that the 100(1 −ε)th
percentile of the distribution of the random variable ˜a′x be less than the
right-hand-side limit b. Therefore, in rare cases in which we know the distri-
bution of ˜a′x and can compute a closed-form expression for its 100(1 – ε)th
percentile, we can convert a probabilistic constraint directly into a single
nonprobabilistic constraint.
This is the case when all uncertain coefﬁcients ˜a1, . . . , ˜aN in the chance
constraint are assumed to come from a multivariate normal distribution. We
can compute the exact 100(1 – ε)th percentile of the probability distribution
˜a′x in terms of the means of the uncertain coefﬁcients ˜a, the standard devi-
ations and the covariance structure of the uncertain coefﬁcients ˜a, and the
solution vector x.
The 100(1 −ε)th percentile of the distribution of a normal random
variable ˜z with a mean µ and standard deviation σ is given by µ + −1(1 −
ε) · σ, where −1(.) denotes the inverse of the cumulative standard normal
distribution. (In other words, −1(1 −ε) is the 100(1 – ε)th percentile of
a standard normal distribution.15 ) We often encounter the notation z(1−ε)
for the same concept. From the equations for expectation and variance of a
sum of random variables, we can compute the mean of the normal random
variable ˜a′x as ˆa′x, and its standard deviation—as
√
x′x.16 Therefore,
the deterministic constraint equivalent of the chance constraint under the
assumption of normally distributed uncertain coefﬁcients is
ˆa′x + z(1−ε) ·
√
x′x ≤b.
This is an SOCP constraint (see section 5.2.4), which is easier to han-
dle than a large set of constraints involving mixed-integer decision vari-
ables if you have the right solver. Recently, robust optimization techniques
have been successfully applied for approximating the optimal solutions of
problems with chance constraints in stochastic programming.17 We will
come back to this problem in Chapter 9.

Optimization under Uncertainty
231
6.3
ROBUST OPTIMIZATION
A major problem with dynamic and stochastic programming formulations
is that in practice it is often difﬁcult to obtain detailed information on the
probability distributions of the uncertainties in the model. At the same time,
depending on the number of scenarios involved, dynamic and stochastic
programming methods can be prohibitively costly computationally. Robust
optimization makes optimization models robust with respect to uncertainty
in the input data of optimization problems by solving so-called robust coun-
terparts of these problems for appropriately deﬁned uncertainty sets for the
random parameters. The robust counterparts contain no uncertain coefﬁ-
cients, that is, they are deterministic optimization problems. In fact, the
robust counterparts are worst-case formulations of the original optimiza-
tion problems, where the worst-case is computed over the possible values
the input parameters could take within their uncertainty sets. Typically, the
uncertainty sets are deﬁned in smart ways that do not lead to overly conser-
vative or computationally challenging formulations. If the uncertainty sets
are deﬁned as a set of scenarios for the uncertain coefﬁcients, robust opti-
mization shares some features of stochastic programming. However, classi-
cal robust optimization focuses on the worst-case, while classical stochastic
programming focuses on the average over these scenarios.
6.3.1
Uncertainty Sets and Robust Counterparts
To provide some intuition for the robust optimization philosophy, let us
consider a linear constraint of the kind
˜a′x ≤b.
Let us assume that we use a statistical procedure to estimate some kind
of “nominal,” or expected, values for the elements of the vector of coefﬁ-
cients ˜a. We obtain estimates (let us denote them by ˆa = (ˆa1, . . . , ˆaN)), and
95% conﬁdence intervals for the true parameter values, (ˆai −δi, ˆai + δi) for
i = 1, . . . , N.18 A natural choice for uncertainty set for ˜a is the collection of
conﬁdence intervals, which can be written as
Uδ(ˆa) =
"
a| |ai −ˆai| ≤δi, i = 1, . . . , N
#
·
This mathematical expression states that coefﬁcient ai can take any value
between ˆai −δi and ˆai + δi, where δi is the nonnegative number representing
the half-length of the conﬁdence interval formed around the estimate ˆai.

232
FUNDAMENTAL CONCEPTS
The robust counterpart of the preceding linear constraint is the following
expression:
max
a∈Uδ(ˆa)
"
a′x
#
≤b
In other words, we require that the constraint be satisﬁed even for
the worst-case value of the expression a′x when a varies in the speciﬁed
uncertainty set. In this case, the worst-case value is obtained at the maximum
because if the maximum value of a′x is less than or equal to b, then the
constraint is clearly satisﬁed for all smaller values of a′x. If the inequality
were in the opposite direction, that is,
˜a′x ≥b
then the worst case would happen at the minimum of the expression a′x,
that is, the robust counterpart would be
min
a∈Uδ(ˆa)
"
a′x
#
≥b
We can easily write the robust counterpart of the constraint in a form
that can be passed to an optimization solver. The maximum of the expression
a′x when a varies in Uδ(ˆa) is given by
ˆa′x + δ′|x|
This can be seen without any advanced mathematics. If the value of a
particular decision variable xi is nonnegative, then |xi| = xi, and the maxi-
mum value of ai · xi is obtained by multiplying the maximum possible value
of ai in the uncertainty set, ˆai + δi, by xi. If the value of xi is negative, then
|xi| = −xi, which is a positive number, and the maximum value of ai · xi is
obtained by multiplying the maximum possible value of ai in the uncertainty
set, ˆai + δi, by −xi.
The uncertainty set we considered previously, Uδ(ˆa), is extremely simple,
and in fact its applications in ﬁnance have been very limited because it is
too conservative. The shape of the uncertainty set is a rectangle in two
dimensions, and looks like a box in more dimensions (see Exhibit 6.7(A)).
The robust optimization approach ﬁnds the optimal solution when a is at
one of the corners of the “box”—the corner in which all elements of a are
at their “worst” values in terms of constraint violation, and result in the
maximum value for the expression a′x.
Instead, it may be realistic to be less conservative, and assume that
all uncertain coefﬁcients will not take their worst-case values at the same
time. In addition, we may have information about the standard deviations

Optimization under Uncertainty
233
a3
a2
a1
a3
a2
a1
(A)
(B)
EXHIBIT 6.7
(A) “Box” uncertainty set in 3 dimensions; (B) ellipsoidal
uncertainty set in 3 dimensions.
and the covariance structure of the uncertain coefﬁcients. More advanced
uncertainty sets can be speciﬁed to capture this information. A classical
uncertainty set in robust optimization is the ellipsoidal uncertainty set (see
Exhibit 6.7(B)), which mathematically can be represented as
Uδ(ˆa) =
"
a| (a −ˆa)′ −1
a
(a −ˆa) ≤δ2#
Here, a is the covariance matrix of the uncertain coefﬁcients ˜a, and δ is
some tolerance for robustness that is speciﬁed by the user. This uncertainty
set states that the constraint should be satisﬁed for all values of a whose
total squared distances from their nominal estimated values ˆa (scaled by
their variability) are less than or equal to δ2. Often, this uncertainty set is
seen in the literature as
Uδ(ˆa) =
"
a|
$$−1/2
a
(a −ˆa)
$$ ≤δ
#
where ∥.∥stands for second, or Euclidean norm.19 The two expressions for
the ellipsoidal uncertainty set are equivalent.
Let us now ﬁnd the robust counterpart of the constraint
˜a′x ≤b
when the vector of uncertain coefﬁcients ˜a varies in the ellipsoidal uncer-
tainty set. To obtain it, we need to ﬁnd the maximum value of the expression

234
FUNDAMENTAL CONCEPTS
on the left hand side of the constraint when ˜a is in the uncertainty set. This
reduces to solving the optimization problem
max
a
a′x
s.t.
$$$−1/2
a
(a −ˆa)
$$$ ≤κ
This is a second-order cone problem (SOCP),20 and for the moment we
are treating the original decision variables x as ﬁxed (known). Instead, we
will try to ﬁnd the maximum value of the expression a′x when a are the
decision variables.
Let us write the dual of the problem above (see Exhibit 5.9 in Chapter 5).
We obtain
min
u,v

−u′−1/2
a
ˆa

+ κv
s.t.
−1/2
a
u + 0 · v = x
∥u∥≤v
Note that one of the constraints allows us to express u in terms of v
and w:
u = 1/2
a
x.
Therefore, the dual problem is equivalent to
min
v
x′1/2
a
−1/2
a
ˆa + κv
s.t.
$$$1/2
a
x
$$$ ≤v,
which can be rewritten as
min
v
x′ ˆa + κv
s.t.
$$$1/2
a
x
$$$ ≤v.
Note that the minimum will be obtained when the constrained is satisﬁed
with equality, that is, when
v =
$$1/2
a
x
$$ .

Optimization under Uncertainty
235
and, therefore, the minimum will be
ˆa′x + κ ·
$$1/2
a
x
$$ .
Since this is an SOCP, duality theory states that the optimal objective
function value will be the same as the value of the primal (maximization)
problem. Therefore, the worst-case value for a′x will be given by the same
expression,
ˆa′x + κ ·
$$1/2
a
x
$$
for any ﬁxed values of the decision variables vector x. Note that the preced-
ing expression does not contain the uncertain coefﬁcients ˜a, but instead
computes the worst-case value in terms of parameters that are known,
such as the nominal values of the uncertain coefﬁcients ˆa and the covari-
ance matrix of the uncertain coefﬁcients a. The ﬁnal step is to replace
the expression in the original constraint, and optimize with x as decision
variables again:
ˆa′x + κ ·
$$1/2
a
x
$$ ≤b
This constraint formulation is equivalent to the constraint in the original
problem we wanted to solve. However, now the formulation is in a form that
can be passed to an optimization solver because all coefﬁcients are certain.
Nonlinear solvers such as MINOS can handle it. Alternatively, since it is
an SOCP, a solver such as SeDuMi21 or SDPT322 would be able to take
advantage of its structure and solve it more efﬁciently.
To summarize, the methodology for creating a single optimization prob-
lem to represent the robust counterpart of a constraint is based on a trick
from optimization duality. Namely, we ﬁrst formulate a problem in which
the original variables x are treated as ﬁxed, and we try to ﬁnd the worst-case
value for the expression containing the vector of uncertain parameters ˜a. We
then use optimization duality to convert the expression with uncertain co-
efﬁcients into a constraint that does not contain uncertain parameters, and
plug it into the original constraint. Finally, we solve the original optimiza-
tion problem with the modiﬁed constraint and with x as decision variables.
While a certain amount of preprocessing is involved in formulating the ro-
bust problem, there is only one call to an optimization solver once the robust
counterpart problem is formulated correctly.
The shape of the uncertainty set and the calibration of the different
parameters that enter its speciﬁcation play an important part in the perfor-
mance of the robust counterpart in practice. The uncertainty sets we saw

236
FUNDAMENTAL CONCEPTS
in these examples were symmetric, that is, we assumed that the uncertain
coefﬁcients could deviate from their nominal values by the same amount
in each direction. In theory, we could select uncertainty sets that represent
better the probability distributions of the uncertain coefﬁcients when these
probability distributions are skewed.23 Recently, there has also been interest
in developing “structured” uncertainty sets, that is, uncertainty sets that are
intersections of elementary uncertainty sets, or are constructed for a speciﬁc
purpose.24
6.3.2
Multistage Robust Optimization
Robust optimization formulations can be used in multistage settings to
replace dynamic programming or stochastic programming algorithms.
Namely, instead of considering scenarios with realizations of the different
uncertain parameters in a multistage problem, robust optimization formu-
lations specify uncertainty sets around these parameters at each stage.
To provide an illustration, let us go back to the oil well example from
Section 1 in this chapter. Recall that in section 5.6.1, we derived the classical
optimization problem formulation for the oil problem if we knew the oil
prices for each time period in advance. In a robust optimization framework,
we would treat the future prices ˜p1 and ˜p2 as uncertain coefﬁcients in the
optimization problem. The robust counterpart statement of the problem
would be as follows: Find the optimal strategy when oil prices in each time
period take their “worst” within some prespeciﬁed uncertainty sets. The
robust counterpart is then the following modiﬁcation of the optimization
formulation of the problem in section 5.6.1:
max
x,u,z
p0 · u0 −z0 · u2
0/x0 −(1 −z0) · 20 · u2
0/x0
+ 0.9 ·
min
p1∈U(p1)
"
p1 · u1 −z1 · u2
1/x1 −(1 −z1) · 20 · u2
1/x1
#
+ 0.92 ·
min
p2∈U(p2)
"
p2 · u2 −z2 · u2
2/x2 −(1 −z2) · 20 · u2
2/x2
#
s.t.
u0 = 100,000 · z0 + 200,000 · (1 −z0)
u1 = 100,000 · z1 + 200,000 · (1 −z1)
u2 = 100,000 · z2 + 200,000 · (1 −z2)
x0 = 600,000
x1 = x0 −u0
x2 = x1 −u1
u0, u1, u2, x1, x2 ≥0
z0, z1, z2 binary

Optimization under Uncertainty
237
Here, U(p1) and U(p2) are some uncertainty sets for the parameters ˜p1
and ˜p2. For example, if they are conﬁdence intervals of the kind
[ ˆp1 −δ1, ˆp1 −δ2]
and
[ ˆp2 −δ2, ˆp2 −δ2]
then the robust counterpart is very simple—we only need to replace the
expression for the objective function with
max
x,u,z
p0 · u0 −z0 · u2
0/x0 −(1 −z0) · 20 · u2
0/x0
+ 0.9 ·
%
( ˆp1 −δ1) · |u1| −z1 · u2
1/x1 −(1 −z1) · 20 · u2
1/x1
&
+ 0.92 ·
%
( ˆp2 −δ2) · |u2| −z2 · u2
2/x2 −(1 −z2) · 20 · u2
2/x2
&
The logic behind the derivation of the preceding expression is the same
as the logic behind our derivation of the robust counterpart of a constraint
at the beginning of this section, when the uncertain parameters vary in a box
uncertainty set.25 In fact, since u1 and u2 are restricted to be nonnegative,
we can remove their absolute value signs, which will make the optimization
formulation more solver-friendly.
Suppose that we consider the following intervals for the uncertainty sets
for ˜p1 and ˜p2: [$36.00, $54.00] and [$28.80, $64.80], which are the mini-
mum and the maximum values for the oil prices from the tree in Exhibit 6.1.
To solve the robust counterpart formulation above, we plug ˆp1 −δ1 = 36.00
and ˆp2 −δ2 = 28.80. We obtain the following optimal solution:
z0 = 0 (use the enhanced method at stage 0)
z1 = 0 (use the enhanced method at stage 1)
z2 = 1 (use the normal method at stage 2)
u0 = 200,000 (pump 200,000 barrels of oil at stage 0)
u1 = 200,000 (pump 200,000 barrels of oil at stage 1)
u2 = 100,000 (pump 100,000 barrels of oil at stage 2)
x0 = 600,000 (amount of reserves at stage 0 is 600,000 barrels)
x1 = 400,000 (amount of reserves at stage 1 is 400,000 barrels)
x2 = 200,000 (amount of reserves at stage 2 is 300,000 barrels)
The present value of the total proﬁt from this strategy is $14,638,966.67.
Recall that when we optimized the expected (average) total proﬁt in

238
FUNDAMENTAL CONCEPTS
section 6.1, the optimal expected proﬁt was $17,573,110.67. The optimal
proﬁt with the robust optimization strategy is lower because it is the proﬁt
obtained under the worst case scenario.
The optimal strategy found with the dynamic programming algorithm
was to use the enhanced method in year 0 and 1, which is the same as the
optimal strategy found by the robust optimization formulation for the ﬁrst
two years. In year 2, if the price in year 2 was $28.80, the optimal strategy
of the dynamic programming algorithm also agreed with the year 2 strategy
in the robust optimization solution (to use the normal method). However,
the dynamic programming solution was to use the enhanced method if the
price was higher ($43.30). The multistage robust optimization method does
not give us information about strategies under scenarios other than the
worst-case scenario in the uncertainty set we specify.
Given that the dynamic programming method provided us with a more
detailed solution than the robust optimization worst-case analysis, why
would we want to use robust optimization? The answer is that in most real-
istic situations, dynamic programming algorithms suffer from the “curse of
dimensionality”—the dimensions of the state space and the number of value
function estimations and other calculations that need to be performed are
so large, that they can overwhelm even the most state-of-the-art software.
Robust optimization keeps the dimension of the problem low even as the
number of stages and the number of states increase, but still allows us to
incorporate considerations for uncertainty when searching for the optimal
strategy. Furthermore, the uncertainty sets for the uncertain parameters can
be speciﬁed in clever ways, so that the formulation is not overly conserva-
tive. Whether or not using robust optimization for a particular multistage
problem is a good idea has to do with the trade-off between the amount of
time or memory it will take to solve the problem over multiple scenarios,
and the required degree of accuracy of the solution.
The robust multistage example in which the uncertain parameters are
restricted to fall within intervals is quite simplistic. In practice, we can specify
more sophisticated uncertainty sets. (See Practice 6.4 on the companion web
site for an example of a multistage robust formulation with an ellipsoidal
uncertainty set for the uncertain coefﬁcients.)
SUMMARY
■Dynamic programming, stochastic programming, and robust optimiza-
tion are all methodologies for optimization under uncertainty. Although
there is overlap among the three approaches, historically they have
evolved independently of each other.

Optimization under Uncertainty
239
■The dynamic programming approach is used for optimization over mul-
tiple stages. Its main idea is to break up the large multistage problem
into a sequence of smaller optimization problems, starting from the last
stage and proceeding backwards.
■The stochastic programming approach most generally deals with opti-
mization problems in which scenarios are generated for the values of
the uncertain parameters. The optimization may be performed so that
the objective function is optimized on average, or may include penal-
ties for constraint violation and risk considerations. Stochastic pro-
gramming can be applied to both single- and multistage optimization
problems.
■In most real-world applications, the dimensions of dynamic and stochas-
tic programming methods are too large to handle computationally.
Often, approximation algorithms are used; some such algorithms em-
ploy Monte Carlo simulation and sample the state space efﬁciently.
■Robust optimization handles uncertainty in the coefﬁcients of opti-
mization problems by solving so-called robust counterparts of these
problems. The robust counterparts are optimization problems that are
formulated in terms of the worst-case realizations of the uncertain pa-
rameters within prespeciﬁed uncertainty sets.
■The robust optimization methodology can be applied in both single- and
multistage problems, and can be a computationally attractive alternative
to dynamic and stochastic programming methods.
NOTES
1. See, for example, Ziemba and Mulvey (1998), Consigli and Dempster (1996),
Zenios and Kang (1993), Carino and Ziemba (1998), Bogentoft, Romeijn and
Uryasev (2001), Ziemba (2003), and Hillier and Eckstein (1993).
2. As explained in section 5.6, this technique dates back to Bellman (1957). Mod-
ern treatment of the area with applications in engineering, ﬁnance, and oper-
ations research is provided in Bertsekas (1995). Applications of dynamic pro-
gramming to optimal consumption and portfolio selection are discussed, for
example, in Merton (1995), and Ingersoll (1987).
3. See, for example, Chryssikou (1998) for a development of approximate dynamic
programming approaches that characterize the optimal investment policy for
multistage portfolio optimization problems.
4. In other words, we maximize a weighted average of objective functions, where
each weight is the probability that the scenario that results in that particular
objective function will occur.
5. See, for example, Mulvey et al. (1995) and Ruszczynski and Shapiro (2003).

240
FUNDAMENTAL CONCEPTS
6. The notation Eξt|ξt−1[·] means “expectation of the expression inside the brack-
ets over realizations of the uncertain variable ξt at time t conditional on the
realizations of ξt−1 at time t – 1.”
7. For example, in an alternative formulation we could associate two variables with
every given node: one variable at stage t, and a copy of that decision variable
for each particular “child” of that node. This kind of representation may be
convenient for formulating the problem in a modeling language, depending on
how the scenario data are stored. For instance, in the scenario tree in Exhibit 6.4,
we could have two copies of the variable x(2)
1 (associated with node 2 at stage 1):
x(2,4)
1
for its “child” node 4 at stage 2, and x(2,5)
1
for its “child” node 5 at stage
2. Then, the constraints
B(4)
1 x(2)
1 + A(4)
2 x(4)
2 = b(4)
2
and
B(5)
1 x(2)
1 + A(5)
2 x(5)
2 = b(5)
2
should be written as
B(4)
1 x(2,4)
1
+ A(4)
2 x(4)
2 = b(4)
2
and
B(5)
1 x(2,5)
1
+ A(5)
2 x(5)
2 = b(5)
2
We must specify explicitly that x(2,4)
1
= x(2,5)
1
to make sure that the nonanticipa-
tivity condition is satisﬁed. For further details, see, for example, Fragniere and
Gondzio (2005).
8. For a survey of stochastic programming applications in ﬁnancial optimization
and scenario generation techniques, see Yu, Ji, and Wang (2003), and Gulpinar,
Rustem, and Settergren (2004). For a description of the different econometric
techniques used in scenario generation, see Fabozzi, Focardi, and Kolm (2006).
9. See Birge (1985).
10. For example, OSL/SE by IBM and SPInE by the CHARISMA research center at
Brunel University.
11. A good overview of recent developments in stochastic programming and im-
portance sampling in particular is available in Ruszczynski and Shapiro (2003).
12. See Bogentoft et al. (2001) and Mulvey et al. (2000).
13. See Chapter 3.6.2 for an introduction to risk measures in the context of prob-
ability distributions. We will discuss risk measures in the context of portfolio
allocation in Part Two of the book.
14. The deﬁnition of variance of a discrete probability distribution is provided in
section 3.6.2.

Optimization under Uncertainty
241
15. See section 3.4.
16. To verify that this is the case, see Appendix A at the companion web site and
write out the expressions for expected values and variances of sums of random
variables when the random variables are given in a vector/matrix form. We will
discuss this in more detail in Chapters 7 and 9.
17. See Chen, Sim, and Sun (2007) and Natarajan, Pachamanova, and Sim (2008).
18. See Chapter 3.11.2 for a deﬁnition of conﬁdence intervals, and Chapter 4.1.2
for their use in simulation.
19. See section 5.2.4.
20. See section 5.2.4.
21. See Computational Research at Lehigh, SeDuMi, http://sedumi.ie.lehigh.edu/.
22. See Kim-Chuan Toh, Michael J. Todd, and Reha H. Tutuncu, “SDPT3 version
4.0—a MATLAB software for semideﬁnite-quadratic-linear programming,”
http://www.math.nus.edu.sg/∼mattohkc/sdpt3.html.
23. See, for example, Natarajan, Pachamanova and Sim (2008).
24. For more details, see Chapters 10 and 12 in Fabozzi, Kolm, Pachamanova, and
Focardi (2007).
25. Note that the expression in the objective function can be treated as a constraint.
Namely, we can introduce a new decision variable, and maximize that vari-
able subject to an additional constraint that the new variable be less than the
expression for the objective function. (See Practice 6.3 on the companion web
site.) Therefore, if we have a method for determining the robust counterpart
of a constraint, we can apply it to ﬁnd the robust counterpart of the objective
function as well.


PART
Two
Portfolio Optimization
and Risk Measures


CHAPTER7
Asset Diversiﬁcation and
Efﬁcient Frontiers
T
he concepts of portfolio risk management and diversiﬁcation have been
instrumental in the development of modern ﬁnancial decision making.
These breakthrough ideas originated in an article by Harry Markowitz that
appeared in the Journal of Finance in 1952. Before Markowitz’s publica-
tion, the focus in the investment industry was on identifying and investing
in “winners”—stocks that appeared undervalued relative to some measure
of their potential, or promised sustainable growth, that is, stocks that had
high expected returns. Markowitz reasoned that investors should decide
based on both the expected return from their investment, and on the risk
from that investment. He deﬁned risk as the variance of future returns.
The idea of incorporating risk in investment decisions and applying a dis-
ciplined quantitative framework to investment management was novel at
the time.1
Originally, this investment philosophy generated little interest, but even-
tually, the ﬁnance community adopted it. Over the years, the theory of port-
folio selection formulated by Markowitz has been extended and reinvented
based on a modiﬁcation of the assumptions made in the original model
that limited its application. It has also introduced a whole new terminol-
ogy, which is now the norm in the investment management community.
Markowitz’s investment theory is popularly referred to as mean-variance
analysis, mean-variance portfolio optimization, and Modern Portfolio
Theory (MPT). In 1990, Markowitz was awarded the Nobel Memorial
Prize in Economic Sciences in recognition of his seminal work.
As we will see in this chapter, the deﬁnition of risk as the variance
of returns leads to the conclusion that diversiﬁcation is preferable as an
investment strategy. In essence, Markowitz’s framework quantiﬁed the con-
ventional wisdom of “not putting all of your eggs in one basket.” Mathemat-
ically, the portfolio variance is a sum of terms including both the variances
245

246
PORTFOLIO OPTIMIZATION AND RISK MEASURES
of the returns of the individual assets and the covariances (equivalently, the
correlations) between those returns. Investing all of your money in assets
that are strongly correlated is not considered a prudent strategy, even if
individually each of the stocks appears to be a “winner” based on prelim-
inary analysis. If any single asset performs worse than expectations, it is
likely, due to its high correlation with the other assets, that the other assets
will also perform poorly, decreasing substantially the value of the entire
portfolio.
It is worth mentioning that Markowitz’s theory of portfolio selection
is a normative theory. A normative theory is one that describes a standard
or norm of behavior that investors should pursue in constructing a portfo-
lio, in contrast to a theory that is actually followed. Asset pricing theory,
which discussed in detail in Part Three of the book, goes on to formalize the
relationship that should exist between asset returns and risk if investors con-
struct and select portfolios according to mean-variance analysis. In contrast
to a normative theory, asset pricing theory is a positive theory—a theory that
derives the implications of hypothesized investor behavior. An example of a
positive theory is the Capital Asset Pricing Model, which we will introduce
in Chapter 11.
In this chapter, we explain the basic assumptions in Markowitz’s model,
and show how the model can be implemented in practice. We also show that
the mean-variance approach is consistent with two different frameworks:
expected utility maximization under certain conditions, and the assumption
that future security returns are jointly normally distributed.
7.1
THE CASE FOR DIVERSIFICATION
Consider an investor who is evaluating an investment in two stocks over
the next year. The stocks’ expected returns are E[˜r1] = µ1 = 9.1% and
E[˜r2] = µ2 = 12.1%, and their standard deviations are σ1 = 16.5% and
σ2 = 15.8%.
At ﬁrst glance, Stock 2 is the clear winner. Its expected return is higher
than Stock 1’s, and its standard deviation is lower than Stock 1’s. Thus, by
investing 100% of his wealth in Stock 2, the investor could achieve better
return for less risk, if risk is deﬁned as the standard deviation of possible
outcomes.
Now suppose the investor is given the additional information that the
correlation coefﬁcient between the two stocks’ returns is ρ12 = −0.22. Let
us denote the weight of Stock 1 in the portfolio by w1, and the weight of
Stock 2 by w2. Note that the sum of the weights of the two stocks must be
100%, that is, w2 = 1 −w1.

Asset Diversiﬁcation and Efﬁcient Frontiers
247
The portfolio return (which is a random variable and denoted by a tilde
(∼) over the return variable r) can be expressed as
˜rp = w1 ˜r1 + w2 ˜r2
The portfolio expected return and the variance can be computed from
the rules listed in section 3.9 of Chapter 3. In particular, the portfolio
expected return is
E[˜rp] = E[w1 ˜r1 + w2 ˜r2] = E[w1 ˜r1] + E[w2 ˜r2] = w1E[˜r1] + w2E[˜r2]
= w1µ1 + w2µ2
The portfolio variance is
σ 2
p = Var(w1 ˜r1 + w2 ˜r2) = Var(w1 ˜r1) + Var(w2 ˜r2) + 2Covar(w1 ˜r1, w2 ˜r2)
= w2
1σ 2
1 + w2
1σ 2
1 + 2w1w2σ12.
Since we are given the correlation coefﬁcient instead of the covariance,
we can express the portfolio variance through the correlation coefﬁcient (see
the deﬁnition of correlation coefﬁcient in section 3.8)
σ 2
p = w2
1σ 2
1 + w2
2σ 2
2 + 2w1w2σ1σ2ρ12.
The portfolio standard deviation is, of course, simply the square root of
the portfolio variance computed above.
Exhibit 7.1(A) and (B) illustrate how the portfolio return and standard
deviation change with the fraction of the portfolio invested in Stock 1. (All
of the calculations are contained in the worksheet Diversiﬁcation in the ﬁle
Ch7-Diversiﬁcation2Stocks.xlsm.) We can observe that while the portfolio
expected return is highest when 0% is invested in Stock 1, the portfolio
standard deviation when the weight of Stock 1 is 0% is not the lowest
possible. By investing in both Stock 1 and Stock 2, the investor can reduce
the portfolio standard deviation to a level that is lower than the level of any
of the individual stocks.
In the previous two-stock example, the fact that the stocks were neg-
atively correlated made the effect of diversiﬁcation particularly dramatic
in terms of reducing the overall portfolio standard deviation. It turns
out, actually, that the same conclusions—that diversiﬁcation decreases
the portfolio standard deviation—hold when stock returns are uncorre-
lated, or exhibit weak correlations. The conclusion holds true in observed

248
PORTFOLIO OPTIMIZATION AND RISK MEASURES
15.0
10.0
5.0
0.0
20.0
15.0
10.0
5.0
0.0
0
0.5
Fraction Invested in Stock 1
Portfolio Expected
Return (%)
Portfolio Standard
Deviation (%)
(A)
Fraction Invested in Stock 1
(B)
1
0
0.5
1
EXHIBIT 7.1
(A) Change in portfolio expected return as the fraction invested in
Stock 1 increases from 0 to 1; (B) change in portfolio standard deviation as the
fraction invested in Stock 1 increases from 0 to 1.
stock return behavior as well. Exhibit 7.2 is a screenshot of the ﬁle Ch7-
Diversiﬁcation30Stocks.xlsx. The ﬁle contains monthly returns over a four-
year period for 30 randomly selected stocks from the S&P 500. (The time
period was speciﬁcally selected to include both upturns and downturns in
the market.) The average correlation of these stocks is slightly positive. Yet,
as the graph in Exhibit 7.2 illustrates, the standard deviation of a portfo-
lio obtained by weighting equally a selected number of stocks decreases as
the number of stocks grows larger. Diversiﬁcation in this case is beneﬁcial
even for a portfolio whose weights were determined casually—by weighting
each stock equally. We can do even better by selecting the portfolio weights
in a more targeted way—by calculating the weights that will minimize the
portfolio risk as measured by its variance.
A fact worth noting here is that diversiﬁcation cannot necessarily elim-
inate risk completely. For example, as the graph in Exhibit 7.2 shows, we
reach a point (about 13 stocks in this particular example) beyond which
adding more stocks does not reduce the standard deviation of the portfolio.
A study by Evans and Archer (1968), the ﬁrst of its kind, suggested that the
major beneﬁts of diversiﬁcation can be obtained with 10 to 20 stocks. More
recent studies by Campbell, Lettau, Malkiel, and Xu (2001) and Malkiel
(2002) show that the volatility of individual stocks has increased between
the 1960s and the 1990s. On the other hand, the correlations between indi-
vidual stocks have decreased over the same time period. Together, these two
effects have canceled each other out, leaving the overall market volatility
the same. However, Malkiel’s study suggests that it now takes almost 200
individual equities to obtain the same amount of diversiﬁcation that was
historically possible with as few as 10 individual equities.
Several studies have suggested that real-world asset returns behavior
can be mapped to a probability distribution known as the stable Paretian

EXHIBIT 7.2
A screenshot of ﬁle Ch7-Diversiﬁcation30Stocks.xlsx. The ﬁle contains monthly returns on 30 randomly selected
stocks from the S&P 500 between January 2000 and December 2004. The graph illustrates the decrease in the realized standard
deviation of an equally-weighted portfolio as the number of stocks in the portfolio increases.
249

250
PORTFOLIO OPTIMIZATION AND RISK MEASURES
distribution. Mandelbrot (1963) was the ﬁrst to make this observation. The
variance of a random variable following a stable Paretian distribution is
not bounded (that is, it is inﬁnite and therefore does not exist). This fact
calls into question the principle of diversiﬁcation. Adding assets with very
large or inﬁnite variances to a portfolio cannot reduce the overall portfolio
standard deviation. In particular, Fama (1965) demonstrated that if asset
returns behave like a stable Paretian distribution, diversiﬁcation may no
longer be meaningful. Most practitioners agree, however, that a certain
degree of diversiﬁcation is preferable and attainable in the markets.
7.2
THE CLASSICAL MEAN-VARIANCE
OPTIMIZATION FRAMEWORK
Suppose that an investor would like to invest in N risky assets. The investor’s
choice can be represented as an N × 1 vector array w = (w1, . . . , wN)′ of
asset weights.2 Each weight wi represents the proportion of asset i held in
the portfolio, and the total portfolio weight needs to be 100%, that is,
N

i=1
wi = 1.
In vector notation, the above requirement can be written as3
w′ι = 1,
where ι is an N × 1 vector array of ones. If short selling is allowed,4 then
the weights can be negative.
Markowitz’s framework assumes that the investor is making a deci-
sion for his investment over one time period of a prespeciﬁed length. The
investor is concerned with the return on his portfolio at the end of that
time period, but not during it or after the end of it. The returns of the
N assets in the portfolio during that time period can be represented as a
vector array of random variables: ˜r = (˜r1, . . . , ˜rN)′. Suppose the expected
returns on the N assets are µ = (µ1, . . . , µN)′, and the covariance matrix of
returns is
 =
⎡
⎢⎣
σ11
· · ·
σ1N
...
...
...
σN1
· · ·
σNN
⎤
⎥⎦

Asset Diversiﬁcation and Efﬁcient Frontiers
251
where σi j denotes the covariance between asset i and asset j, and the diagonal
element σii is the variance of asset i, that is, σii = σ 2
i . (Note that σi j = σ ji,
that is, the covariance matrix is symmetric because the covariance between
i and j is the same as the covariance between j and i.) Then, the expected
return on a portfolio that has allocations of w = (w1, . . . , wN)′ is
µp =
N

i=1
µi · wi = µ′w
and the portfolio variance σ 2
p is
σ 2
p = w′w.
If, instead of the covariance matrix, we know the correlation matrix
K =
⎡
⎢⎣
1
· · ·
ρ1N
...
...
...
ρN1
· · ·
1
⎤
⎥⎦
and the standard deviations of the individual assets, we can either convert
the correlation matrix into a covariance matrix element-by-element by using
the relationship5
ρi j = σi j
σiσ j
,
or we can use directly the correlation matrix in the expression for port-
folio variance. To do that, we need to construct a vector ws of products
of the weights of the assets and the corresponding standard deviations,
ws = (w1σ1, . . . , wNσN)′. Then, the portfolio variance can be computed as
σ 2
p = (ws)′Kws
To provide some intuition, let us go back to the case of two assets with
weights w1 and w2. The portfolio return can be written in vector notation
as
˜rp = [ w1
w1 ] ·
 ˜r1
˜r2
	
= w′˜r.

252
PORTFOLIO OPTIMIZATION AND RISK MEASURES
The portfolio expected return in matrix notation is
E[˜rp] = E[w′˜r] = w′E[˜r] = [ w1
w1 ] ·
 E[˜r1]
E[˜r2]
	
= w′µ.
The portfolio variance in matrix notation is
σ 2
p = w′w = [ w1
w2] ·
 σ 2
1
σ12
σ21
σ 2
2
	
·
w1
w2
	
= [w1σ 2
1 + w2σ21
w1σ12 + w2σ 2
2 ] ·
w1
w2
	
.
Note that the last expression equals
w2
1σ 2
1 + w2
2σ 2
2 + 2w1w2σ12
which is the same expression as the expression for variance we derived in
section 7.1.
If we are given the correlation matrix rather than the covariance matrix,
then we can compute the portfolio variance as
σ 2
p = [w1σ1
w2σ2] ·
 1
ρ12
ρ21
1
	
·
 w1σ1
w2σ2
	
= [w1σ1 + w2σ2ρ21
w1σ1ρ12 + w2σ2] ·
w1σ1
w2σ2
	
= w2
1σ 2
1 + w2
2σ 2
2 + 2w1w2σ1σ2ρ12,
which again is equivalent to the expression for variance we derived in sec-
tion 7.1 because σ1σ2ρ12 = σ12.
The classical mean-variance portfolio allocation problem is formulated
as follows:
min
w
w′w
s.t.
w′µ = rtarget
w′ι = 1
Note that the objective function of this optimization problem is
quadratic in the decision variables w.6 It turns out that this minimization
problem is convex because the objective function is convex and all the

Asset Diversiﬁcation and Efﬁcient Frontiers
253
constraints are linear functions of the decision variables.7 To see that the
objective function is a convex function of the decision variables w, consider
the portfolio of two assets. The weight of the second asset, w2, can be ex-
pressed through the weight of the ﬁrst asset, w1, as w2 = 1 −w1. Plugging
into the expression for the portfolio variance, we obtain
σ 2
p = w2
1σ 2
1 + (1 −w1)2σ 2
2 + 2w1(1 −w1)ρ12σ1σ2
= w2
1(σ 2
1 + σ 2
2 −2ρ12σ1σ2) + w1(−2σ 2
2 + 2ρ12σ1σ2) + σ 2
2 .
The sign of the coefﬁcient in front of the decision variable w2
1 determines
whether the quadratic objective function will be concave or convex (see
Exhibit 5.3 in Chapter 5). Note that the coefﬁcient can be written as
σ 2
1 + σ 2
2 −2σ1σ2 + 2σ1σ2 −2ρ12σ1σ2
= (σ 2
1 + σ 2
2 −2σ1σ2) + 2σ1σ2(1 −ρ12)
=
(σ1 −σ2)2



≥0 (squared term)
+ 2σ1σ2(1 −ρ12)



≥0 (because −1≤ρ12≤1)
so it is always nonnegative. Therefore, the objective function has the shape
in Exhibit 5.3(A) and, as a result, minimization will bring us to the global
minimum at the tip of the curve.8
The optimal solution for the classical mean-variance portfolio allocation
problem can be found in closed form by using Lagrange multipliers. The
optimal weights are
w* = g + h · rtarget,
where
g =
1
ac −b2 · −1 · [c · ι −b · µ],
h =
1
ac −b2 · −1 · [a · µ −b · ι]
and
a = ι′−1ι.
b = ι′−1µ.
c = µ′−1µ.

254
PORTFOLIO OPTIMIZATION AND RISK MEASURES
Typically, however, the classical mean-variance optimization is modiﬁed
to include additional constraints or to express the objective in a different
way, so no closed-form solution exists, and an optimization solver must be
used to solve for the optimal weights. We provide instructions and code for
the implementation of the mean-variance problem with Excel Solver and
MATLAB’s Optimization Toolbox in this chapter’s Software Hints.
It is important to note that the problem of minimizing the portfolio
variance is equivalent to the problem of minimizing the portfolio standard
deviation (which is the square root of the portfolio variance) in the sense
that the optimal weights will be the same. Minimizing the portfolio vari-
ance, however, is more solver-friendly. It is preferable that the minimum
variance formulation is implemented with optimization software. The opti-
mal portfolio standard deviation can then be easily derived from the optimal
portfolio variance.
7.3
EFFICIENT FRONTIERS
Let us consider again the two-stock example from section 7.1, which is
illustrated in worksheet Diversiﬁcation in the ﬁle Ch7-Diversiﬁcation2Stocks
.xlsm. As the weight of Stock 1 in the portfolio increases, the portfolio
expected return and risk trace out the solid curve in Exhibit 7.2(A). Each
point on this curve is obtained for a different combination of stock weights.
The point at the top right part of the curve is the portfolio obtained if 100%
is invested in Stock 2. Note that that portfolio’s expected return is 12.1%
(the expected return of Stock 2) and its standard deviation is 15.8% (the
standard deviation of Stock 2). At the other end (the point at the bottom
right part of the curve) is a portfolio in which 100% is invested in Stock 1. As
we trace the curve between its top rightmost point and its bottom rightmost
point, we obtain different portfolio risk-return characteristics. It is difﬁcult
to say which risk-return combination is “optimal”—it will depend on the
individual’s risk tolerance. What we can say, however, is that no rational
investor would prefer portfolios located on the lower part of the curve,
such as Portfolio B in Exhibit 7.3(A). For the same level of portfolio risk
(standard deviation of 13.0%), the investor could obtain a higher expected
return—that of Portfolio A. Therefore, Portfolio A dominates Portfolio B.
Exhibit 7.3(B) illustrates the efﬁcient frontier—the upper part of the curve,
which contains the set of portfolios that dominate all other portfolios given
a speciﬁc tolerance for the level of risk or the level of expected return.
Consider now a portfolio of N assets, where N is greater than two. The
set of all portfolio risk-return pairs obtained when varying the weights of the

Asset Diversiﬁcation and Efﬁcient Frontiers
255
13.0
12.0
11.0
10.0
9.0
9.0
11.0
Portfolio A
Portfolio A
Portfolio B
Stock 2
Stock 1
Stock 1
13.0
(A)
Portfolio Standard Deviation
Portfolio Expected Return
Portfolio Expected Return
15.0
17.0
9.0
11.0
13.0
(B)
Portfolio Standard Deviation
15.0
17.0
8.0
7.0
13.0
12.0
11.0
10.0
9.0
8.0
7.0
EXHIBIT 7.3
(A) Possible pairings of portfolio expected return and standard
deviation as the weights of the two stocks vary between 0 and 1; (B) portfolio
efﬁcient frontier.
individual assets ﬁlls the shaded area in Exhibit 7.4. The Markowitz mean-
variance formulation explained in section 7.2 helps us ﬁnd the portfolios
along the upper part of the curve (between Portfolio D and Portfolio E on the
graph)—that is, the portfolios along the efﬁcient frontier. Those portfolios
offer the lowest standard deviation for a given level of expected return, and
provide the best possible trade-off between return and risk. All portfolios
in the shaded area (such as Portfolio C) and along the lower part of the
curve (such as Portfolio B) are dominated by the portfolios on the efﬁcient
frontier. All portfolios above the efﬁcient frontier (higher on the graph than
the curve deﬁned by Portfolios A, D, and E) are unattainable. Portfolio D has
the lowest possible standard deviation among all combinations of weights
for the assets in the portfolio. It is called the minimum variance portfolio.
Portfolio A
Portfolio D
Portfolio C
Portfolio B
Portfolio Standard Deviation
Portfolio Expected Return
Portfolio E
EXHIBIT 7.4
Feasible and mean-variance
efﬁcient portfolios.

256
PORTFOLIO OPTIMIZATION AND RISK MEASURES
If more assets are added to the portfolio, there is obviously a higher
number of possible combinations of weights for these assets in the port-
folio. The feasible set in Exhibit 7.4 widens and the efﬁcient frontier gets
pushed outward to reﬂect the fact that there are now more possibilities for
diversiﬁcation.
To construct the efﬁcient frontier, we simply solve the portfolio opti-
mization problem from section 7.2 in this chapter, and plot the optimal
standard deviation obtained for any level of target expected return. Code
for calculating the efﬁcient frontier with Excel (using VBA) and MATLAB is
provided on the companion web site, and an explanation of the implemen-
tation is given in this chapter’s Software Hints.
7.4
ALTERNATIVE FORMULATIONS
OF THE CLASSICAL MEAN-VARIANCE
OPTIMIZATION PROBLEM
The mean-variance optimization problem we introduced in section 7.2 has
a couple of alternative but equivalent formulations that are used in practice.
7.4.1
Expected Return Formulation
Instead of imposing a constraint on the expected return and minimizing the
portfolio variance, we could impose a constraint on the portfolio variance
and maximize the expected return. The optimization formulation is then
max
w
w′µ
s.t.
w′w = σ 2
target
w′ι = 1
This formulation, which we will refer to as the expected return maxi-
mization formulation of the classical mean-variance optimization problem,
is particularly widely used by portfolio managers whose goal is to limit their
risk relative to a benchmark. Such applications are discussed in Chapter 9.
7.4.2
Risk Aversion Formulation
Another possible formulation is to model the trade-off between risk
and return directly through the objective function. This can be accom-
plished by assigning a penalty term for high portfolio variance, that is, a

Asset Diversiﬁcation and Efﬁcient Frontiers
257
risk-aversion coefﬁcient λ. The risk aversion mean-variance formulation is
stated as follows:
max
w
w′µ −λ · w′w
s.t.
w′ι = 1
The risk aversion coefﬁcient λ is referred to as the Arrow-Pratt risk
aversion coefﬁcient. When λ is small, the aversion to risk is also small, lead-
ing to more risky portfolios because the portfolio variance is not penalized
as much in the objective of the optimization problem. If we gradually in-
crease λ starting from 0, and we solve the optimization problem for each
value of λ, we in fact calculate every portfolio along the efﬁcient fron-
tier. It is a common practice to calibrate λ so that the portfolio has the
desired risk-return characteristics (“risk proﬁle”). The calibration is often
performed via backtests with historical data. For most portfolio allocation
decisions in practice, the risk aversion coefﬁcient is somewhere between
2 and 4.
7.5
THE CAPITAL MARKET LINE
So far, we described Markowitz’s framework for selecting an optimal port-
folio of risky assets. As demonstrated by Sharpe (1964), Lintner (1965) and
Tobin (1958), however, the efﬁcient set of portfolios available to investors
who can in addition invest in a risk-free asset (think of it as borrowing
or lending money), is superior to the efﬁcient set of portfolios available to
investors who can only invest in risky assets.
Let us assume that there is a risk-free asset, with a risk-free return
denoted by rf, and that the investor can borrow and lend at this rate.9 The
investor still needs to select weights w = (w1, . . . , wN) for the N risky assets,
but the weights for the risky assets no longer need to add up to 1 because
the remainder can be absorbed by the riskless asset. Therefore, the total
portfolio return is
w′r + (1 −w′ι) · rf .
Since the return on the risk-free asset is assumed to be known and ﬁxed,
the total expected portfolio return is
w′µ + (1 + w′ι) · rf

258
PORTFOLIO OPTIMIZATION AND RISK MEASURES
and the portfolio variance is
w′w.
Note that the portfolio variance is the same as in the case of a portfolio
of all risky assets because the risk-free asset does not contribute to the total
portfolio risk.
The minimum variance portfolio optimization problem can therefore be
formulated as
min
w
w′w
s.t.
w′µ + r f · (1 −w′ι) = rtarget
and, similarly to the case with no risk-free asset, the optimal solution can be
found by using an optimizer or computed in closed form. It turns out that
the optimal portfolio weights are given by the formula
w = C · −1 · (µ −r f · ι)
where
C =
rtarget −r f
(µ −r f · ι)′−1(µ −r f · ι)
This formula suggests that the weights of the risky assets are propor-
tional to the vector −1 · (µ – rf · ι), with a proportionality constant C.
Therefore, with a risk-free asset, all minimum variance portfolios are a
combination of the risk-free asset and a given risky portfolio. This risky
portfolio is called the tangency portfolio. Under certain assumptions, it
can be shown that the tangency portfolio must consist of all assets avail-
able to investors, and each asset must be held in proportion to its mar-
ket value relative to the total market value of all assets.10 Hence, the
tangency portfolio is often referred to as the market portfolio, or simply
the market.
The composition of the market portfolio, wM can be computed explicitly
as11
wM =
1
ι′(µ −r f · ι) · −1(µ −r f · ι)

Asset Diversiﬁcation and Efﬁcient Frontiers
259
It turns out, actually, that the market portfolio is also the optimal solu-
tion for the following optimization problem:
max
w
w′µ −r f
√
w′w
s.t.
w′ι = 1
The expression in the objective function is called the Sharpe ratio.12 It
is the ratio of the portfolio excess return (relative to the risk-free asset) to
the portfolio standard deviation, that is, it represents the trade-off between
return (w′µ −r f ) and risk (
√
w′w). The Sharpe ratio is widely used in the
context of evaluating portfolio performance.
The fact that all risky portfolios available to the investor are linear
combinations of the market portfolio and the risk free rate means that they
all lie on a line (see Exhibit 7.5). This line is called the Capital Market
Line (CML). Observe that all portfolios that lie on the Markowitz efﬁcient
frontier are inferior to the portfolios on the CML in the sense that they
result in a lower expected return for the same amount of risk. For example,
in Exhibit 7.5, Portfolio A, which is on the Markowitz efﬁcient frontier,
has a lower expected return than Portfolio B, which is on the CML. The
only portfolio on the Markowitz efﬁcient frontier that is not dominated by
portfolios on the CML is the tangency portfolio.
If we assume that all investors use the mean-variance framework, then
every investor will select a portfolio on the CML that represents a combina-
tion of the market portfolio, and borrowing or lending at the risk-free rate.
Portfolio Expected Return
Portfolio Standard Deviation
Tangency 
(market)
portfolio
Capital market line
Markowitz 
efficient
frontier
Portfolio A
Portfolio B
rf
EXHIBIT 7.5
Capital market line.

260
PORTFOLIO OPTIMIZATION AND RISK MEASURES
This important property of the mean-variance framework is called separa-
tion. Portfolios on the CML to the left of the market portfolio represent
combinations of risky assets and the risk-free asset. Portfolios on the CML
to the right of the market portfolio represent purchases of risky assets made
with funds borrowed at the risk-free rate.
The separation property also has important implications in practice.
Practical portfolio construction usually reduces to the following two steps:
1. Asset allocation: Decide how to allocate the investor’s wealth between
the risk-free security and the set of risky securities.
2. Risky portfolio construction: Decide how to distribute the risky portion
of the investment among the set of risky securities.
We can derive a formula for the CML algebraically. The reason for going
though this exercise will become clear in Chapter 11, when we link the CML
to an important modeling tool used in practical portfolio management: risk
factor models.
If all investors invest a portion wrf of their portfolio in the risk free asset,
and a portion wM in the market portfolio, then their expected portfolio
returns, E[rp], are equal to the weighted averages of the expected returns of
the two assets:
E[rp] = wr f · r f + wM · E[rM].
Since the two portfolio weights must add up to 1, we can rewrite the
preceding equality as
E[rp] = r f + wM · (E[rM] −r f ).
The return on the risk-free asset and the return on the market portfolio
are uncorrelated and the variance of the risk-free asset is equal to zero.
Therefore, the variance of the portfolio consisting of the risk-free asset and
the market portfolio is given by (see section 7.1 in this chapter):
σ 2
p = w2
r f σ 2
r f + w2
Mσ 2
M + 2wr f wMσr f σMρ(r f,M)
= w2
Mσ 2
M
Since the standard deviation is the square root of the variance, we can
write
σp = wMσM

Asset Diversiﬁcation and Efﬁcient Frontiers
261
Hence, the weight of the market portfolio can be expressed as
wM =
σp
σM
.
If we substitute the previous result and rearrange terms, we get an
explicit line equation for the CML:
E[rp] = r f +
 E[rM] −r f
σM

· σp.
The bracketed expression in the second term in the equation for the
CML,
 E[rM] −r f
σM

,
is referred to as the risk premium. It is also referred to as the equilibrium
market price of risk because it, being the slope of the CML, determines the
additional expected return needed to compensate for a unit change in risk
(standard deviation).
7.6
EXPECTED UTILITY THEORY
In the classical Markowitz framework, the investor chooses a desired trade-
off between risk and return, and solves an optimization problem to ﬁnd
the portfolio weights that result in a portfolio with the desired risk proﬁle.
Alternatively, risk preferences can be expressed through utility functions. An
investor’s utility function assigns values to levels of wealth. The expected
utility framework is based on the idea that a rational investor would choose
his portfolio allocation w so as to maximize his expected utility one time
period ahead. More formally, let the investor’s utility function be denoted
by u, and let
˜W denote his end-of-period wealth. The investor’s goal is to
maximize E[u( ˜W)], the “weighted average” of the values for the investor’s
utility evaluated at the possible outcomes for his wealth at the end of the time
period. If his wealth at time 0 is W0, then his expected utility optimization
problem can be formulated as
max
w
E [u(W0 · (1 + w′˜r)]
s.t.
w′ι = 1

262
PORTFOLIO OPTIMIZATION AND RISK MEASURES
The Markowitz framework is consistent with expected utility theory in
two cases. The ﬁrst case is when asset returns are assumed to follow nor-
mal distributions. When returns follow a multivariate normal distribution,
randomness is completely described by the returns’ means, variances, and
covariances. Therefore, w′˜r can be written as a function of means, variances,
and covariances, so u(W0 · (1 + w′˜r)) is also an expression that depends en-
tirely on the means, variances and covariances, and so does its expected
value E. This is consistent with the mean-variance optimization philosophy.
The second case is when investors are assumed to have quadratic utility
functions. We explain the quadratic utility function in more detail next.
Quadratic Utility Function
A quadratic utility function has the form
u(x) = x −b
2x2,
b > 0.
If we plug in x = W0 · (1 + w′˜r), we get the following expression for
expected utility:
E [u(W0 · (1 + w′˜r))] =
= E[W0 · (1 + w′˜r) −b
2 · W2
0 · (1 + w′˜r)2]
= E[W0 + W0 · w′˜r −b
2 · W2
0 −b
2 · W2
0 · (w′˜r)2 −b
2 · 2 · W2
0 · w′˜r]
= W0 + W0 · E[w′˜r] −b
2 · W2
0 −b
2 · W2
0 · E[(w′˜r)2] −b
2 · 2 · W2
0 · E[w′˜r]
= W0 −b
2 · W2
0 + W0 · E[w′˜r] −b
2 · W2
0 ·

E[(w′˜r)2] + 2 · E[w′˜r]

= u(W0) + W0 · µp −b
2 · W2
0 ·

E[(w′˜r)2] + 2 · µp]

= u(W0) + W0 · µp −b
2 · W2
0 · 2 · µp −b
2 · W2
0 ·
⎛
⎜⎜⎝E[(w′˜r)2] + µ2
p



σ 2p
−µ2
p]
⎞
⎟⎟⎠
= u(W0) + W0 · µp · (1 −b · W0) −b
2 · W2
0 · (σ 2
p −µ2
p)
Here µp and σ 2
p denote the mean and the variance of the end-of-period
portfolio return, respectively. The preceding expression illustrates that the

Asset Diversiﬁcation and Efﬁcient Frontiers
263
portfolio mean and variance are sufﬁcient for describing the expected util-
ity of an investor with a quadratic utility function. Moreover, increasing
the expected return of the portfolio increases the investor’s expected util-
ity, and decreasing the portfolio standard deviation decreases the investor’s
expected utility, which is consistent with the mean-variance optimization
framework.
The general shape of the quadratic utility function is illustrated in
Exhibit 7.6. As the graph shows, the quadratic utility function makes some
unrealistic assumptions on investor behavior. The function is not mono-
tonically increasing. At some level of wealth (speciﬁcally, at values greater
than 1/b), the utility of investors decreases as their wealth increases, which
is a fairly unnatural assumption. A justiﬁcation for the use of Markowitz’s
model, however, has been the assumption that asset returns follow normal
distributions, even though many studies indicate otherwise. As we explained
at the beginning of this section, in the case of normal distributions for re-
turns, a mean-variance approach makes sense independently of the shape of
the investors’ utility functions.
The Markowitz model is useful also because it provides an approxi-
mation to other utility functions. Before we discuss approximating general
utility functions, let us introduce a few more examples of utility functions.
As a general rule, the shapes of widely used utility functions assume that in-
vestors are risk averse. A risk-averse investor is somebody who is indifferent
or unwilling to accept a risky payoff at its expected value. Instead, a risk-
averse investor requires additional compensation for accepting a risky payoff
instead of a certain payoff, even if the expected values of the two payoffs are
the same. In other words, the expected utility from an uncertain payoff of a
risk-averse person is always less than or equal to the utility of the expected
payoff. Mathematically, it turns out that risk-averseness translates into con-
cave utility function shapes.13 A“straight-line” utility function corresponds
to indifference to risk, or risk neutrality because it represents a situation in
which the expected utility of the uncertain payoff equals the utility of the
expected payoff. The more “curved” (the less “ﬂat”) the utility functions
are, the more risk-averse investors are assumed to be. The quadratic utility
function (explained above) and the exponential, power, logarithmic utility
functions (explained later) all assume risk averseness.
Linear Utility Function
The linear utility function is the simplest kind of utility function. It has the
form
u(x) = a + b · x

264
PORTFOLIO OPTIMIZATION AND RISK MEASURES
for some parameters a and b. As we mentioned previously, the linear utility
function assumes that investors are risk-neutral, that is, that they are con-
cerned only with expected return, not with risk. Recall from section 3.9 in
Chapter 3 that the expected value of a linear function of a random variable
is a linear function of the expected value of a random variable. The expected
utility of the end-of-period wealth is
E[u( ˜W)] = E[a + b · ˜W] = a + b · E[ ˜W]
whereas the utility of the expected end-of-period wealth is
u(E[ ˜W]) = a + b · E[ ˜W].
Therefore, E[u( ˜W)] = u(E[ ˜W]). An investor with a linear utility func-
tion is indifferent between receiving a certain outcome of E[ ˜W] and an
uncertain outcome that is “on average” equal to E[ ˜W]. See Exhibit 7.6. for
an illustration of the shape of the linear utility function.
Exponential Utility Function
The exponential utility function has the form
u(x) = −1
a e−ax,
a > 0
Note that the exponential utility has negative values; however, this does
not matter because the function is monotonically increasing (see Exhibit 7.6),
and it is possible to compare the relative utilities for different levels of
wealth.
Power Utility Function
The power utility function is of the form
u(x) = axa,
0 < a ≤1
(see Exhibit 7.6).

Asset Diversiﬁcation and Efﬁcient Frontiers
265
Logarithmic Utility Function
The logarithmic utility function has the form
u(x) = ln(x)
Note that this function is only deﬁned for x > 0 (see Exhibit 7.6).
In practice, it is very difﬁcult to determine the utility function of an in-
vestor, and the situation is further complicated by the fact that the investor’s
utility function type and the degree of risk averseness may change depend-
ing on circumstances. The choice of utility function for portfolio allocation
depends on the application, as well as computational considerations. For ex-
ample, the exponential utility function is widely used because it is generally
easier to optimize than some of the other utility functions.
The problem of expected utility optimization is not as intractable as it
used to be, given the advances in computational power today. However,
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
–3
–2
–1
0
1
2
3
4
5
6
Wealth
Utility
Quadratic
Linear
Exponential
Power
Logarithmic
EXHIBIT 7.6
Examples of different utility functions.

266
PORTFOLIO OPTIMIZATION AND RISK MEASURES
virtually no practitioners rely on a full-scale utility optimization approach.
Typically, practitioners work with a mean-variance approximation of a cho-
sen utility function that best represents their investors’ preferences. A general
utility function can be approximated by mean-variance optimization by ex-
panding the expression for expected utility using Taylor series around the
expected end-of-period wealth.14 Jean (1971) was the ﬁrst to suggest this
approach. Later, more general and rigorous discussion was provided by
several authors. The main idea is as follows.
Let us denote the expected end-of-period wealth by ˆW. Note that
ˆW = E[W0 · (1 + w′˜r)] = E[W0] + E[W0 · (w′˜r)] = W0 + W0 · w′µ
The end-of-period expected utility can be expanded in a Taylor series
around the expected end-of-period wealth ˆW:
E[u( ˜W)] = u( ˆW) + u′( ˆW) · E[ ˜W −ˆW] + 1
2! · u′′( ˆW) · E[( ˜W −ˆW)2]
+ 1
3! · u′′′( ˆW) · E[( ˜W −ˆW)3] + 1
4! · u′′′′( ˆW) · E[( ˜W −ˆW)4]
+ O(( ˜W −ˆW)5)
The functions E[( ˜W −ˆW)k], k = 1, 2, 3, . . . are called the central moments of
the random variable ˜W. They are related to the moments of the distribution
of the random variable ˜W.15 It is easy to see that the second central moment,
E[( ˜W −ˆW)2], is actually the variance of the random variable
˜W.16 Since
E[W −ˆW] = E[W] −ˆW = 0, we can write
E[u( ˜W)] = u( ˆW) + 1
2! · u′′( ˆW) · E[( ˜W −ˆW)2]
+ 1
3! · u′′′( ˆW) · E[( ˜W −ˆW)3] + 1
4! · u′′′′( ˆW) · E[( ˜W −ˆW)4]
+ O(( ˜W −ˆW)5)
An approximation for the problem of maximizing the expected utility of
an investor can be achieved by using only the ﬁrst two terms of the preceding
expression. These expressions involve the expected end-of-period wealth
and the variance of the expected end-of-period wealth in a way consistent
with the classical mean-variance framework. A complete formulation of the
optimization problem would, of course, involve the third term (which is

Asset Diversiﬁcation and Efﬁcient Frontiers
267
related to skewness), the fourth term (which is related to kurtosis), and all
other higher-order central moment terms.
Levy and Markowitz (1979) compared the performance of portfolio al-
locations obtained by maximizing expected power utility with that of port-
folio allocations obtained with standard mean-variance optimization, and
found that the mean-variance approximation worked quite well. Cremers,
Kritzman, and Page (2003, 2005) showed empirically that the log and the
power utility functions are fairly insensitive to higher moments, and, there-
fore, mean-variance optimization performs quite well for investors with
logarithmic or power utility. However, for discontinuous or S-shaped utility
functions, this result no longer holds, and mean-variance optimization leads
to a signiﬁcant loss in utility compared to an optimization of the full utility
function.17
SUMMARY
■The basic principle of modern portfolio theory, which originated in
Harry Markowitz’s work from 1952, is that for a given level of ex-
pected return, a rational investor would select the portfolio with the
minimum variance among all possible portfolios. This chapter intro-
duced three equivalent formulations of this principle: (1) the portfolio
variance minimization formulation; (2) the expected return maximiza-
tion formulation; and (3) the risk-aversion formulation.
■Markowitz’s mean-variance framework in effect quantiﬁed the idea of
diversiﬁcation as a prudent strategy. Mathematically, the portfolio vari-
ance is a sum of terms including both the variances of the returns of
the individual assets and the covariances (equivalently, the correlations)
between those returns. In a well-diversiﬁed portfolio, the weak perfor-
mance of a single asset will be compensated by the performance of other
assets that are not strongly correlated with that asset.
■Portfolio allocations obtained by minimizing the portfolio variance are
called mean-variance efﬁcient portfolios. The set of all mean-variance
efﬁcient portfolios is called the efﬁcient frontier.
■The portfolio on the efﬁcient frontier with the smallest variance is called
the global minimum variance portfolio.
■A utility function assigns a value to all possible outcomes faced by an
investor. The expected utility is the weighted average of these values over
all possible outcomes, where the weights correspond to the probabilities
of these outcomes. The concept of expected utility maximization allows
us to generalize the framework of optimal portfolio choice.

268
PORTFOLIO OPTIMIZATION AND RISK MEASURES
■While it is difﬁcult to produce the utility function for a speciﬁc in-
vestor, commonly used types of utility functions include exponential,
logarithmic, power, and quadratic. These functions all incorporate risk
averseness. The linear utility function represents the preferences of an
investor who is risk neutral, that is, who is concerned only with expected
outcome, and not with the risk associated with that outcome.
■The Markowitz mean-variance portfolio optimization framework is
consistent with the expected utility maximization framework in two
cases: when future asset returns are assumed to follow normal distribu-
tions, or when investors are assumed to have quadratic utility functions.
In addition, the Markowitz framework works well as an approximation
to expected utility maximization for several important types of utility
functions.
SOFTWARE HINTS
We illustrate how to implement the mean-variance optimization problem
with Excel Solver and MATLAB’s Optimization Toolbox for the example
with two stocks from section 7.1. Before implementing the code, it would
be helpful to review Chapter 5. Excel Solver cannot handle large problems,
and we recommend that readers switch to a different optimization package,
such as Premium Solver18 and Palisade’s Evolver19 if their problem is of
a larger size. Alternatively, readers can use MATLAB’s or ILOG CPLEX’s
optimization engine from within Excel.
Excel
An example of the implementation of the mean-variance optimiza-
tion problem with two stocks from Chapter 7.1 is provided in ﬁle
Ch7-Diversiﬁcation2Stocks.xlsm. Worksheet Optimization illustrates the
implementation of the mean-variance optimization problem using the
long-hand formulas from Chapter 7.2, whereas worksheet Optimization
(Mx) illustrates the implementation using the array manipulation func-
tion MMULT in Excel, which is useful for portfolios with more than
two assets.
Worksheet Setup
We start out with worksheet Optimization. (See a
screenshot in Exhibit 7.7.) The input data for the problem is stored as
follows: the assets’ expected returns (cells B2:C2), the assets’ standard devi-
ations (cells B3:C3), and their correlation coefﬁcient (cell B5). The worksheet
is set up to enable computing the minimum portfolio variance by considering

Asset Diversiﬁcation and Efﬁcient Frontiers
269
EXHIBIT 7.7
Setup for the mean-variance portfolio optimization problem in
Excel.
either the correlation or the covariance between the two assets. The covari-
ance is computed in cell E5 as =B5*B3*C3 (the correlation coefﬁcient times
the two standard deviations; see section 3.8 in Chapter 3). The portfolio
target return can be speciﬁed in cell B6.
The three building blocks of the optimization model (decision variables,
objective function and constraints; see Chapter 5) are speciﬁcally outlined
in the worksheet for clarity.
Cells B11:C11 will contain the optimal weights. They can be left blank
at the beginning, or some arbitrary values can be entered to make sure that
the formulas for calculating the portfolio mean and variance are correct.
Cell B14 will contain the optimal portfolio variance, and is linked to
the asset weights via the formula
=($B$3ˆ2)*($B$11ˆ2)+($C$3ˆ2)*($C$11ˆ2)+2*$B$11*$C$11*$E$5
(The portfolio standard deviation can be computed by simply taking a square
root, SQRT, of the portfolio variance. See also section 7.2 for an explanation
of the computation of the portfolio standard variance.)

270
PORTFOLIO OPTIMIZATION AND RISK MEASURES
Alternatively, we can compute the portfolio variance by using the cor-
relation between the two assets. The formula is stored in cell E14:
=($B$3ˆ2)*($B$11ˆ2)+($C$3ˆ2)*($C$11ˆ2)+2*$B$5*$B$3*$C$3*$B$
11*$C$11
Rows 17 and 18 contain the two standard constraints: the constraint
that the portfolio expected return should be greater than or equal to the
target return speciﬁed in cell B6, and the “budget” constraint that re-
quires that the sum of the portfolio weights should be 1. Since Excel Solver
requires that the constraints are speciﬁed in a speciﬁc format: a cell represent-
ing the left hand side is compared to a cell representing the right hand side,
cells B17 and B18, dedicated to the “left-hand sides” of the two constraints
contain the formulas
=$B$2*$B$11+$C$2*$C$11
and
=$B$11+$C$11
whereas cells D17 and D18, dedicated to the “right-hand sides” of the two
constraints, contain the bounds: the target return (the number from cell B6)
and 1, respectively.
Using Excel Solver
To solve the problem, we call Excel Solver (click the
Data tab and then click Solver in the Analysis group), and enter the values
for the target cell (the objective function), the changing cells (the decision
variables), and the constraints as shown in Exhibit 7.8.
The optimal portfolio variance for target expected return of 11% is
110.10, for portfolio weights 36.67% and 63.33%. The optimal portfolio
standard deviation for that level of target return is therefore √110.10 =
10.49%.
When the portfolio consists of more than two stocks, it is convenient to
reference inputs as arrays (rather than individual cells) and use Excel array
functions such as SUMPRODUCT and MMULT. Worksheet Optimization (Mx)
contains an example of the implementation of the portfolio problem using
Excel’s array functions (see Exhibit 7.7).
Applying
Array
Functions
As explained in Chapter 5, SUMPRODUCT
(Array1, Array2) returns the sum of the products of the corresponding
individual elements of two arrays. In the portfolio optimization context, we

Asset Diversiﬁcation and Efﬁcient Frontiers
271
EXHIBIT 7.8
Excel Solver inputs for solving the minimum portfolio
standard deviation optimization problem.
can express the expected portfolio return as a “sumproduct” of the indi-
vidual stocks’ returns and their weights. Thus, the formula for portfolio ex-
pected return in cell B17 of worksheet Optimization (Mx) can be written as
=SUMPRODUCT($B$2:$C$2,$B$11:$C$11)
Alternatively, we can use the MMULT function. MMULT(Array1, Array2)
returns the matrix product of two arrays. This implies that the dimen-
sions of the arrays must agree. In other words, while SUMPRODUCT(Array1,
Array2) requires that Array1 and Array2 have the same dimensions,
MMULT requires that the number of columns of Array1 is the same as
the number of rows of Array2. Therefore, to perform the same expected
return calculation we performed with SUMPRODUCT, we would need to
enter the formula
=MMULT(B11:C11,TRANSPOSE(B2:C2))
in cell B17. In addition, to complete the calculation, it is not sufﬁcient to
press simply Enter. After entering the MMULT formula, while the cursor is
still active in the formula bar, press Ctrl-Shift-Enter simultaneously.20
The value of the portfolio variance in cell B14 can be computed similarly.
We create the covariance matrix of the two stock returns in cells G6:H7,
and reference it in the formula in cell B14 as follows:21
=MMULT(MMULT(B11:C11,G6:H7),TRANSPOSE(B11:C11))

272
PORTFOLIO OPTIMIZATION AND RISK MEASURES
EXHIBIT 7.9
Setup for the mean-variance portfolio optimization problem
with array functions in Excel.
If, instead of the covariance matrix, we would like to use the correlation
matrix (cells G2:H2), then we can compute the portfolio variance by ﬁrst
creating an array of products of the weights and the standard deviations for
each stock (cells B12:C12 in worksheet Optimization (Mx); see Exhibit 7.9),
and then using these products in the formula for the variance in cell D14
as follows:
=MMULT(MMULT(B12:C12,G2:H3),TRANSPOSE(B12:C12))
Calling Excel Solver happens in the same way as before.
Calculating the Efficient Frontier with VBA
To calculate the efﬁcient
frontier, we would need to make multiple calls to Solver. Worksheet Ef-
ﬁcient Frontier illustrates the result. The VBA code for creating the efﬁcient
frontier can be seen after opening the VBE in the ﬁle Ch7-Diversiﬁcation2
Stocks.xlsm.
The code takes the inputs in cells named min return, increment, and
iterations in worksheet Efﬁcient Frontier, which happen to be cells N4,
N5, and N6, respectively. It starts at the value for min return, and runs
Solver on the optimization problem in worksheet Optimization (Mx) with
min return as the expected return. It records the minimum value for the

Asset Diversiﬁcation and Efﬁcient Frontiers
273
portfolio variance (actually, the optimal portfolio standard deviation, since
it takes the square root of the variance), and increases min return by the
amount of the increment. This new value becomes the new expected return,
Solver is called, and the optimal solution for the portfolio optimization
problem in worksheet Optimization (Mx) is recorded. The process continues
for a number of times determined by the number of iterations speciﬁed by
the user in cell N6. At the end, the pairs of expected portfolio returns and
optimal portfolio standard deviations are plotted in a graph to obtain the
efﬁcient frontier.
To run the script, we can select the Efﬁcient Frontier macro from the list
of macros, or click on the button Generate efﬁcient frontier in worksheet
Efﬁcient Frontier. For instructions on how to associate a button with a
macro, see section 2.4 in Appendix D on the companion web site.
MATLAB
As explained in Chapter 5, MATLAB’s Optimization Toolbox has a num-
ber of functions that can be called to solve particular types of optimization
problems. To obtain the optimal portfolio allocation, we need to transform
the minimum variance problem into one of the standard forms supported
by MATLAB, and then call the appropriate function with the correct argu-
ments. The minimum variance portfolio allocation problem is a quadratic
optimization problem with linear constraints. The quadprog function in
MATLAB solves exactly problems of this kind:
min
x
1
2x′Hx + f′x
s.t.
Ax ≤b
Aeq · x = beq
lb ≤x ≤ub
and is called with the command
quadprog(H,f,A,b,Aeq,beq,lb,ub)
A MATLAB script that generates the input data and then calls the
optimization solver is contained in the ﬁle EfﬁcientFrontier.m.
Lines 10–36 in the code solve a single instance of the minimum variance
optimization problem, while lines 38–56 repeat the optimization for several
values of the target expected return, and use the results to plot the efﬁcient
frontier.

274
PORTFOLIO OPTIMIZATION AND RISK MEASURES
Note that the function arguments are speciﬁed in terms of the avail-
able data. For example, to map the objective function of the mean-variance
optimization problem
min
w
w′w
into the MATLAB objective function expression
min
x
1
2x′Hx + f′x,
we set H = 2 and create an input vector f whose entries are all zeros (lines
12–16 in the code).
We need to be careful in specifying the dimensions of the arrays when
calling the quadprog function in order for the matrix and vector operations
to work out correctly. We also need to be careful in specifying the inequalities
in the optimization formulation in the correct way. For example, the mean-
variance optimization problem formulation has an inequality constraint of
the kind
w′µ ≥rtarget.
However, the inequality constraint assumed by the quadprog function
is of the general form
Ax ≤b
that is, the inequality sign points the opposite way. Therefore, we need to
specify the required target return constraint in MATLAB as
−w′µ ≤−rtarget.
Lines 19 and 20 in the code above create a matrix A of dimension 1 ×
numAssets equal to the negative of the transpose of the column vector of
weights w, and a scalar b equal to the negative of the target return rtarget so
that the above constraint can be passed to the solver.
The command
[weights,variance] = quadprog(H,f,A,b,Aeq,beq,lb,ub);
on line 32 ensures that the optimal solution to the optimization problem
will be stored in a vector called weights, and the optimal objective function
value (the minimum portfolio variance) will be stored in the scalar variance.

Asset Diversiﬁcation and Efﬁcient Frontiers
275
Lines 35 and 36 print the values of the optimal standard deviation and the
optimal weights to screen.
The MATLAB output from running the previous code is as follows:
stdDev =
10.4928
weights =
0.3667
0.6333
Lines 44–50 contain a for loop that runs the optimization problem for
values of the target return between 9.5 and 12, increasing the target return by
0.5 at each iteration. The expected portfolio return and the optimal standard
deviation obtained from the optimization output are stored in vectors x and
y. Lines 52–56 plot the efﬁcient frontier using the values stored in x and y,
and label the graph.
NOTES
1. We need to clarify here that utility theory, which was developed in the eco-
nomics literature before Markowitz’s publication, allowed for incorporating
risk implicitly by considering special kinds of investor utility functions that de-
scribed risk averseness. However, Markowitz’s publication suggested the ﬁrst
tangible and practical quantitative framework that deﬁned investment decision
making explicitly as a trade-off between risk and return. See section 7.6 in this
chapter for a brief introduction to utility theory.
2. See Appendix A at the companion web site for a review of matrix notation and
deﬁnition of matrix transpose (′).
3. See Appendix A at the companion web site for a review of matrix array multi-
plication.
4. See Chapter 2 for a deﬁnition of the term short selling.
5. See section 3.8.
6. See Chapter 5 for a review of optimization problem formulations, classiﬁcation,
and terminology.
7. See Chapter 5 for use of convex functions in optimization.
8. This statement is a bit simpliﬁed because the function plotted in Exhibit 5.3
is a function of a single variable x, whereas here we have a function of two
variables, so the picture would be three-dimensional. The general conclusion,
however, is the same.
9. In practice, this assumption is not valid for most investors. Speciﬁcally, an
investor may not be able to borrow and lend at the same interest rate, or may
only be permitted to lend. If there are no short selling restrictions on the risky

276
PORTFOLIO OPTIMIZATION AND RISK MEASURES
assets, however, the theoretical conclusions under such conditions are similar to
the results presented in this section. See, for example, Black (1972) and Ingersoll
(1987).
10. See Fama (1970).
11. See Chapter 2 in Fabozzi, Kolm, Pachamanova, and Focardi (2007), p. 37.
12. See, for example, Sharpe (1994).
13. See, for example, Chapter 1 in Huang and Litzenberger (1988).
14. The Taylor series is a representation of a function as an inﬁnite sum of terms
calculated from the values of its derivatives at a single point. The Taylor series
expansion of a function f(x) around a point a is given by
f (a) + f ′(a)
1!
· (x −a) + f ′′(a)
2!
· (x −a)2 + · · ·
where f ′(a), f ′′(a), . . . are the ﬁrst, second, . . . derivatives of the function f eval-
uated at the point a, and n! = 1·2·3·. . .·n.
15. See section 3.6 of Chapter 3.
16. See section 3.6 of Chapter 3.
17. See Kahneman and Tversky (1979).
18. See Frontline Systems, “Our Premium Upgrade for the Excel Solve,” Solver.com,
http://www.solver.com/xlspremsolv.htm.
19. See Palisade, Evolver, http://www.palisade.com/evolver/.
20. Note that to obtain the complete output of the MMULT function in Excel, the
array of cells that will contain the output needs to be highlighted before the
formula is typed and Ctrl-Shift-Enter is pressed. In this example, we did
not need to worry about it because the product of two vectors is an array of
dimension one. The output will be contained in the active cell. If, however, the
expected output array was of dimensions 2 × 3, and we did not highlight a cell
range of size 2 × 3 cells, then only the ﬁrst entry of the output 2 × 3 array
would be calculated and returned in the active cell.
21. Note that in this worksheet example, the array of cells containing the portfolio
weights is horizontal, rather than vertical. So, we compute the portfolio variance
as ww′ rather than w′w, which was the standard form for portfolio variance
used in this chapter.

CHAPTER8
Advances in the Theory of
Portfolio Risk Measures
P
ortfolio risk managers either use their experience in stock picking or rely
on quantitative modeling techniques in the portfolio selection process.
Generally speaking, however, the main objective of portfolio selection is the
construction of a portfolio that maximizes expected returns given a certain
tolerance for risk. We already introduced one such measure of risk, portfolio
variance, in Chapter 7.
As explained in Chapter 7, mean-variance portfolio allocation is optimal
in two cases: when investors have quadratic utility functions, or when returns
follow a multivariate normal distribution. The former condition is difﬁcult to
verify empirically, and it is likely that the utility functions of individuals will
vary with market conditions. With respect to the latter condition, although
there might be exceptions, the overwhelming empirical evidence suggests
that the return distribution for ﬁnancial assets throughout the world are not
normal distributed. This is particularly true of complex derivative securities’
returns, as we will see in Chapters 14 through 16, and observable during
ﬁnancial crises such as the 1997 Asian ﬁnancial crisis, the 1998 Russian
ﬁnancial crisis, and the 2007 subprime mortgage crisis.
In addition to these theoretical reasons, there is an intuitive problem
with the portfolio variance as a measure of risk. As we saw in section 3.6.2
of Chapter 3, the variance of a probability distribution is a measure of the
spread, or dispersion of the distribution. Using the variance in the portfo-
lio optimization context means that outcomes that are above the expected
portfolio returned are deemed as risky as outcomes that are below the ex-
pected portfolio return. This is counterintuitive to many, as investors are
more likely to be concerned about outcomes that fall short of expectations,
rather than outcomes that exceed expectations.
Using the portfolio variance as a risk measure has been a subject of
considerable debate in both academic circles and in practice. The goal of
277

278
PORTFOLIO OPTIMIZATION AND RISK MEASURES
this chapter is to discuss the issue in more detail, and present alternative risk
measures that have been proposed. Since about the mid-1990s, considerable
thought and innovation in the ﬁnancial industry have been directed toward
creating a better understanding of risk and its measurement, and toward
improving the management of risk in ﬁnancial portfolios. There has been an
even greater sense of urgency to establish better risk management practices
after the collapse of the ﬁnancial markets in the fall of 2008. We review
some important types of risk measures, such as semivariance, Roy’s safety-
ﬁrst criterion, and quantile-based risk measures. Also discussed in detail is
the history of, estimation of, and portfolio allocation under value-at-risk
and conditional value-at-risk—two important risk measures that are widely
used in practice.
It is worth noting that Markowitz’s portfolio theory and the Capital
Asset Pricing Model (CAPM),1 which builds upon it, still provide a use-
ful framework for incorporating multiple risk sources into a joint portfolio
risk measure, and are widely used by asset managers and risk managers.
Their use, however, has been mostly restricted to equity portfolio man-
agement. It was realized early on that it is difﬁcult to apply the mean-
variance framework for ﬁxed-income portfolio management, hedge fund
management, or for aggregating risk at the ﬁrm level at major ﬁnancial
institutions.
8.1
CLASSES OF RISK MEASURES
Most generally, risk measures can be divided into two classes: dispersion and
downside risk measures. This section provides examples of risk measures
from the two categories.
8.1.1
Dispersion Risk Measures
Dispersion risk measures measure the amount of dispersion of the returns
around the expected portfolio return. Hence, they are measures of uncer-
tainty in the estimate of the expected portfolio return. Uncertainty, however,
does not necessarily quantify risk. Dispersion measures consider both pos-
itive and negative deviations from the mean, and treat those deviations as
equally risky. In other words, outperformance relative to the mean is penal-
ized as much as underperformance.
Variance and Standard Deviation
Because of the key role it plays in the
theory of portfolio selection as set forth by Markowitz more than 55 years

Advances in the Theory of Portfolio Risk Measures
279
ago, the portfolio variance (or, equivalently, standard deviation) is the most
well-known dispersion measure. The portfolio variance is deﬁned as
σ 2
p = E
˜rp −E[˜rp]
2
= E
⎡
⎣
 N

i=1
wi ˜ri −
N

i=1
wiµi
	2⎤
⎦
and the portfolio standard deviation is deﬁned as
σp =

E
˜rp −E[˜rp]
21/2
=
⎛
⎝E
⎡
⎣
 N

i=1
wi ˜ri −
N

i=1
wiµi
	2⎤
⎦
⎞
⎠
1/2
where ˜ri are the returns of the N individual assets in the portfolio, µi are
their means, and
˜rp =
N

i=1
wi ˜ri
is the return of the portfolio.
As explained in Chapter 7, the expressions for the portfolio variance
and standard deviation can be written using matrix notation as
σ 2
p = w′w
and
σp =
√
w′w
respectively, where  is the covariance matrix of the portfolio.
Absolute Deviation
Konno and Yamazaki (1991) introduced the absolute
deviation (AD) portfolio risk measure. Instead of the portfolio standard
deviation, which is the average of the squared deviations of the possible
realizations of portfolio returns from the expected portfolio return, the ab-
solute deviation measures the average absolute value of the deviations of the
possible realizations of portfolio returns from the expected portfolio return.
Formally, the absolute deviation risk measure can be written as
AD(˜rp) = E
˜rp −E[˜rp]

= E

N

i=1
wi ˜ri −
N

i=1
wiµi



280
PORTFOLIO OPTIMIZATION AND RISK MEASURES
where ˜ri are the returns of the N individual assets in the portfolio, µi are
their means, and ˜rp is the return on the portfolio, as before.2
The computation of the optimal mean-absolute deviation portfolio
is substantially simpliﬁed because the resulting optimization problem is
linear and can be solved by standard linear programming algorithms.3
Another
advantage
of
estimating
the
portfolio
absolute
deviation
compared to the portfolio standard deviation is that there is no need to
estimate the covariance matrix of the assets in the portfolio. Finding a re-
liable and stable estimate of the covariance matrix is a challenging task
in practice.
It can also be shown that if the individual asset returns are multivariate
normally distributed, the AD is a multiple of the standard deviation of the
portfolio (σp). Namely,
AD(˜rp) =

2
π · σp
Hence, if asset returns are multivariate normally distributed, mean-
variance and mean-absolute deviation portfolio optimization result in equiv-
alent allocations.
Absolute Moment
The absolute moment risk measure of order q is deﬁned
as4
AMq(˜rp) =

E
˜rp −E[˜rp]
q1/q =

E

N

i=1
wi ˜ri −
N

i=1
wiµi

q	1/q
,
q ≥1
It is basically a generalization of the standard deviation (q = 2) and the
absolute deviation (q = 1) portfolio risk measures.
8.1.2
Downside Risk Measures
As we mentioned in the introduction to this chapter, most investors are
concerned about the outcomes that fall short of expectations, rather than
the outcomes that exceed expectations. This fact cannot be accurately repre-
sented by the portfolio variance and other dispersion measures. Markowitz
(1959) himself acknowledged this shortcoming of his model, and sug-
gested a downside dispersion risk measure, semivariance, as an alter-
native way of measuring portfolio risk. The same realization prompted
research into a number of other downside dispersion risk measures, many

Advances in the Theory of Portfolio Risk Measures
281
of which are special cases of the lower-partial moment risk measure (also
called the Fishburn risk measure). This section describes several such risk
measures.
Lower-Partial Moment
The lower-partial moment risk measure is deﬁned
as

E

min
˜rp −t, 0
q1/q =

E

min
 N

i=1
wi ˜ri −
N

i=1
wiµi, 0
	q	1/q
In the case of a continuous probability distribution for the portfolio
return, the expression above is equivalent to
t

−∞
(t −r)k f (r) dr
whereas in the case of a discrete probability distribution for the portfolio
return, it is equivalent to5

(t −r)k · P(˜r = r)
where the sum is over all values of the random variable less than or equal
to t.
The constant t represents a cutoff point between the downside of concern
to the investor, and the upside that is not of concern. In practice, the value of
t is often selected to be the short-term interest rate, the expected return, or
a minimum required return. The notation ˜r stands for the random variable
representing portfolio return.
On an intuitive level, you can think of the lower partial moment as the
“weighted average” of the portfolio return deviations from the threshold
(raised to a speciﬁc power k) when the return is less than the threshold t.
Fishburn (1977) showed that q = 1 corresponds to a risk-neutral investor,
0 < q ≤1 corresponds to a risk-seeking investor, and q > 1 corresponds to
a risk-averse investor.
Semivariance
Semivariance is deﬁned as the average of the squared devi-
ations from the mean of all values that are below the mean. Thus, it is a
special case of the lower partial moment risk measure when k = 2 and t

282
PORTFOLIO OPTIMIZATION AND RISK MEASURES
equals the mean of the probability distribution for the portfolio return. The
portfolio semivariance can be written as
E
⎡
⎣min
⎧
⎨
⎩
 N

i=1
wi ˜ri −
N

i=1
wiµi
	2
, 0
⎫
⎬
⎭
⎤
⎦
Roy’s Safety-First Criterion
The theory behind Roy’s safety-ﬁrst criterion
is that rather than thinking in terms of overall portfolio risk, the investor
ﬁrst makes sure that a certain amount of the invested principal is preserved,
so the investor tries to minimize the probability that the return earned is less
than or equal to the threshold t.6 Mathematically, it can be expressed as an
optimization problem:
min
w
P(˜rp ≤t)
that is,
min
w
P
 N

i=1
wi ˜ri ≤t
	
Note that Roy’s safety-ﬁrst criterion is actually a special case of the
lower-partial moment formula when k = 0.
In the ﬁnancial industry, Roy’s safety-ﬁrst criterion is often referred to
as shortfall risk. When the threshold t is zero, the shortfall risk is called the
risk of loss.
Quantile-Based Risk Measures
The theory of stochastic dominance, which
gained popularity in the 1970s, provided new tools for comparing prob-
ability distributions, and drew attention to so-called quantile-based risk
measures. Quantile-based risk measures evaluate volatility in terms of the
percentiles of a distribution, and are justiﬁed from a theoretical point of
view in the sense that they are consistent with the preferences of risk-averse
investors. The most widely used quantile-based risk measure in practice
is value-at-risk. More recently, a related risk measure, conditional value-
at-risk (also encountered as expected shortfall), has gained popularity be-
cause of its desirable theoretical and computational properties. Conditional
value-at-risk is in fact a multiple of the lower-partial moment formula
with k = 1.
Value-at-risk and conditional value-at-risk are two very important de-
velopments in the theory of risk measures. In the remainder of this chapter,

Advances in the Theory of Portfolio Risk Measures
283
we elaborate on the history, estimation, and portfolio allocation under these
two risk measures.
8.2
VALUE-AT-RISK
Value-at-risk (VaR) is related to the percentiles of probability distributions,
and measures the predicted maximum portfolio loss at a speciﬁed probability
level over a certain time horizon. Commonly used probability levels include
0.95 and 0.99, and the corresponding VaR is referred to as 95% VaR or
99% VaR (in other words, the probability is stated as a percentage). Typical
time horizons include 1 day and 10 days. The portfolio loss is deﬁned as the
difference between the initial value of the portfolio at the current time t, Vt,
and the future value of the portfolio at time t + 1, Vt+1.7
VaR can be used for individual assets, trading positions, and portfolios.
Mathematically, VaR at a probability level 100(1 −ε)% is deﬁned as the
value γ such that the probability that the negative of the portfolio return
will exceed γ is not more than some small number ε:
VaR(1−ε)(˜r) = min {γ |P(−˜r > γ ) ≤ε}
(In the preceding expression, ˜r denotes the random variable representing
the portfolio return, and −˜r is associated with the portfolio loss, as we will
see shortly.) For example, when ε = 0.05, then (1 −ε) = 0.95, 100(1 −
ε)% = 95%, and we are interested in the 95% VaR, which is the level
of the portfolio losses that will not be exceeded with probability of more
than 5%.
Asset managers often use a modiﬁed version of VaR, which measures
the loss relative to a benchmark.8 The formula for VaR above still stands,
but ˜r is the excess return relative to the benchmark, that is, the difference
between the return on the portfolio and the return on the benchmark.
VaR is reported as a dollar amount of losses. Let us see how the deﬁni-
tion of VaR in terms of the return can be stated in dollar terms.
Suppose that ˜r is the arithmetic portfolio return.9 It is easy to see that
if we know the value γ and would like to obtain VaR as a dollar amount
for possible losses, we simply need to multiply γ by the portfolio value at
the beginning of the time period of interest. In particular, the negative of the
arithmetic return over time period t, −˜rt,t+1, is
−˜rt,t+1 = Vt −˜Vt+1
Vt

284
PORTFOLIO OPTIMIZATION AND RISK MEASURES
where Vt is the portfolio value at time t. The numerator in this expression
is the loss over time period t, Vt −˜Vt+1. Hence, the loss over time period t
can be written as
Vt −˜Vt+1 = −˜rt,t+1 · Vt
The portfolio value at time t, Vt, is known; it can be treated as a con-
stant. Therefore, the probability distribution of the loss is the same as the
probability distribution of the negative of the return −˜rt,t+1, scaled by a con-
stant. If we know γ , the 100(1 −ε)th percentile of the latter distribution,
the 100(1 −ε)th percentile of the former can be computed as γ · Vt.
Let us now compute VaR in dollar terms if we are working with geo-
metric returns ˜r. We have
−˜rt,t+1 = −ln
# ˜Vt+1
Vt
$
= −

ln
 ˜Vt+1

−ln (Vt)

= ln (Vt) −ln
 ˜Vt+1

Just as before, the portfolio value at time t, Vt, can be treated as a
constant. Therefore, the probability distribution of ln( ˜Vt+1) is the same as
the probability distribution of ˜r. We can rewrite the previous equality as
ln
 ˜Vt+1

= ˜rt,t+1 + ln (Vt)
or, equivalently, as
˜Vt+1 = e˜rt,t+1+ln(Vt) = e˜rt,t+1 · Vt
and, therefore, the loss (Vt – ˜Vt+1) can be expressed as
Vt −˜Vt+1 =

1 −e˜rt,t+1
· Vt
So, if we know the value of γ , we can compute the VaR as

1 −e−γ 
· Vt
The difference in estimating VaR from the two different assump-
tions for returns is not very large for short holding periods and real-
istic return parameters. For example, suppose that we computed γ =
0.004000. (We will explain how to obtain an estimate of γ later.) Then,

1 −e−γ 
=

1 −e−0.004000
= 0.003992. For an initial portfolio value of
$100 million, we have VaR = $400,000 for arithmetic returns, and VaR =
$399,201.07 for geometric returns.

Advances in the Theory of Portfolio Risk Measures
285
In practice, VaR is often computed directly as a dollar amount because
historical data are available in a cash ﬂow form. More speciﬁcally, it is in
either proﬁt/loss (P/L) or loss/proﬁt (L/P) form.
The P/L generated by an asset or a portfolio of assets is the value of the
asset (or portfolio) at the end of time period t plus any interim cash ﬂows
(dividends, interest, realized capital gain or loss on disposal of assets) and
minus the asset value at the beginning of period t:
(P/L)t+1 = Vt+1 + Dt+1 −Vt
(As a general rule, the amounts should be properly discounted, so that all
dollar amounts are commensurate, but if the time periods themselves are
short, the adjustment will be small.) When the data are in P/L form, positive
values indicate proﬁts and negative values indicate losses. The 100(1 −ε)%
VaR is then the εth percentile of the distribution of the P/L values. (See
Exhibit 8.1(A).)
Profits/Returns 
95% VaR 
Probability in 
the tail is 5% 
(A)
Losses 
95% VaR 
Probability in 
the tail is 5%
(B)
EXHIBIT 8.1
(A) 95% VaR computed from P/L data; (B) 95%
VaR computed from L/P data.

286
PORTFOLIO OPTIMIZATION AND RISK MEASURES
The loss/proﬁt (L/P) form is basically the negative of the proﬁt/loss (P/L)
data:
(L/P)t = −(P/L)t
In that case, the 100(1 −ε)% VaR is the 100(1 −ε)th percentile of the
distribution of the L/P values. (See Exhibit 8.1(B).)
8.2.1
The History of the Value-at-Risk Metric
Among banks, the consensus to use the maximum likely loss as a way to
look at risk evolved gradually, and was established formally in 1996, when
the Basel Committee on Banking Supervision of the Bank for International
Settlements (BIS) proposed several amendments to the original 1988 Basel
Accord for minimal capital requirements for banks of its member countries.
While the original accord covered only credit risk (deposits and lending),
the new proposal that took effect in 1998 also covered market risk, in-
cluding organization-wide commodities exposures (measured by the 10-day
95% VaR).
The deliberate effort among the central banks that were members of
the Basel Committee to come up with better risk management schemes
at the ﬁrm level, however, had started almost two decades earlier. The
impetus for this effort was the realization that there was little connection
between the limits that were imposed on trading positions and the risk
that was being taken by banks. Good trades were passed over because of
arbitrary trading limits, and good capital allocation was missed for the
same reason. In addition, banks, whose primary business had been loans,
were beginning to meld with investment banks, whose primary business
was trading stocks, bonds, and complex ﬁnancial instruments, and with
asset management companies whose focus was investments. There was a
need for an integrated approach to risk management that allowed banks
to evaluate their exposure across divisions and for increasingly complex
positions. Hence, a number of banks began developing internal systems for
measuring ﬁrmwide risk.
J.P. Morgan was one of the early leaders in this endeavor. Industry
legend has it that J.P. Morgan’s integrated risk management system was
started when Dennis Weatherstone, the then-chairman of J.P. Morgan, asked
his staff to give him a daily one-page report describing the ﬁrmwide risk
over the next 24 hours, taking into consideration the bank’s entire trading
portfolio. The “4:15” report, as the report became widely known because it
was to be delivered at the close of trading every day, used VaR to estimate
the maximum loss with a given probability over the next trading day. The

Advances in the Theory of Portfolio Risk Measures
287
fact that VaR was quoted as a dollar amount, rather than a percentage, or
a probability, made it convenient for reporting results to management, and
eliminated the need to explain complex mathematics.
The original calculation of VaR was based on a normal approximation
to the distribution of the ﬁrm’s proﬁts over the next day, similar to the cal-
culation of VaR under a normal distribution we will show in section 8.2.2.
While, theoretically, the calculation was straightforward, its practical imple-
mentation was immensely time consuming and complicated, as it involved
compiling data and estimating a number of statistical parameters, such as
expected returns, variances, and covariances among different complex trad-
ing positions. Still, the system was completed by 1990. In 1993, J.P. Morgan
presented the system at its research conference, and witnessed a great deal
of interest from potential clients. Instead of leasing it or attempting to gen-
erate fees from consulting, however, in 1994 J.P. Morgan decided to make
a simpliﬁed version of their internal system, RiskMetrics, available online,
along with the data necessary for the statistical estimation of VaR. This
move generated a huge amount of publicity for J.P. Morgan, and acceler-
ated the adoption of VaR as a risk measure across ﬁnancial institutions. By
the mid-1990s, VaR had established itself as the dominant measure of risk.
As computer equipment became cheaper and faster and developers more
experienced, VaR systems continued to spread and became more elaborate,
including not only measures of market risks, but also credit risks, liquidity
risks, and operational risks.
Unfortunately, as we will see later, VaR was not understood well, and
the simplicity of its risk estimate as a single dollar amount could be very mis-
leading. Complicating matters, while all banks reported and monitored their
VaR, there was no established regulation on how to compute it. Some banks
used the original RiskMetrics approach, incorporating estimates of standard
deviations and correlations between the returns of different traded instru-
ments. Others opted for historical simulation approaches that estimated VaR
from histograms of past P/L data. Yet others used forward-looking Monte
Carlo simulation, generating future scenarios for the underlying drives of
uncertainty in their company’s positions. We explain these methods for es-
timating VaR in more detail in sections 8.2.2 and 8.2.3. A higher-level dis-
cussion of applications of VaR in portfolio risk management with complex
ﬁnancial instruments is provided in Chapter 16.
8.2.2
Calculation of Value-at-Risk for
a Normal Distribution
Let us assume that our P/L data follow a normal distribution. To estimate
100(1 −ε)% VaR, we need to ﬁnd the value of the 100(1 −ε)th percentile

288
PORTFOLIO OPTIMIZATION AND RISK MEASURES
of the distribution. In the case of the normal distribution, there is a closed-
form expression for the percentiles. Every percentile can be expressed as a
sum of the mean of the distribution and the standard deviation scaled by a
multiplier—namely,
VaR(1−ε) = −µP/L + z(1−ε) · σP/L
where µP/L is the mean, and σP/L is the standard deviation of the P/L dis-
tribution, respectively. The number z(1−ε) is the 100(1 −ε)th percentile of
a standard normal distribution. A widely used notation for the same ex-
pression is −1(1 −ε), which we introduced in section 6.2.3.10 The concept
is used in so many applications, that most spreadsheet and statistical soft-
ware packages contain a function for computing it. As we mentioned in
Chapter 4, in Excel z(1−ε) is computed with the formula NORMSINV (1 −ε).
(So, for example, z0.95 corresponding to the 95th percentile is computed as
NORMSINV(0.95), which is 1.6445.) In MATLAB, z(1−ε) can be computed
with a similar command: norminv(1−ε).
If, instead, we have normally distributed L/P data, then we would use
the formula
VaR(1−ε) = µL/P + z(1−ε) · σL/P
If we are given data on asset returns and assume arithmetic returns, the
formula for VaR would be
VaR(1−ε) =

−µr + z(1−ε) · σr

· Vt
where Vt is the portfolio value at the beginning of the period over which
VaR is estimated.
If, instead, we assume geometric returns, then it can be easily shown
(see the derivation at the beginning of section 8.2) that
VaR(1−ε) =

1 −eµr−z(1−ε)·σr 
· Vt
If we are trying to estimate the VaR for a portfolio, the µ and the σ
in the formulas above would be the portfolio mean and standard deviation.
(Depending on the data, they may be reported as dollar amounts or percent-
age returns.) You can now see why we need information on the covariance
structure of the different assets in the portfolio if the VaR is to be computed
this way: as we showed in Chapter 7, the covariances are an input to the
computation of the portfolio variance, which is then used to compute the
portfolio standard deviation.

Advances in the Theory of Portfolio Risk Measures
289
There are some severe problems with the assumption of normality in
the VaR estimation context:
■Using normal-distribution-based VaR is technically correct for elliptical
distributions for returns, of which the normal distribution is an example.
This is because such distributions are entirely described by their means
and variances. Most real-world data, however, exhibit “fat tails” and
are not normally distributed. When a distribution has fatter tails than the
normal distribution, the VaR computed with the normal approximation
can grossly underestimate the real VaR.
■Even when returns are assumed to be normally distributed, inaccuracies
in the estimation of the input parameters to the model can render the
risk evaluation process meaningless. Accurate estimation of the covari-
ance structure even for equities—the “simplest” assets—is challenging
because the covariance structure varies over time.
■Recall from section 3.8 that covariance and correlation measure only
the strength of linear dependence between random variables. A bank
may have thousands of positions in complex types of ﬁnancial securities
with payoffs that are not linearly correlated. (This is discussed in more
detail in Part Three.) Thus, estimating the risk of a ﬁrm’s portfolio by
using only the correlation structure and the mean for estimating the
risk leaves out important information about the actual distribution of
returns for the entire portfolio.
Despite the fact that the normal-distribution-based VaR suffers from a
number of problems, it is unfortunately widely used. It was the model un-
derlying the RiskMetrics system when it became freely available, and many
ﬁnancial companies adopted it, not understanding (or choosing to ignore)
its drawbacks. The whole point of using a risk estimation framework that
is different from the traditional mean-variance framework, however, is that
it should enable ﬁnancial institutions to evaluate risk in highly nonnormal
situations. Thus, it is not satisfactory to measure tail risk as a multiple of
the standard deviation, as the normal approximation to the VaR does.
8.2.3
Calculation of Value-at-Risk Using Historical
and Simulated Data Scenarios
A more realistic way to estimate VaR is to use scenarios for the possible re-
alizations of the uncertainties underlying the prices of the different securities
in the portfolio. The scenario approach allows us to incorporate dependen-
cies between uncertainties implicitly, and to estimate the actual percentile

290
PORTFOLIO OPTIMIZATION AND RISK MEASURES
of the probability distribution of future portfolio losses, eliminating strong
assumptions such as normality.
Suppose we have S scenarios for the possible losses (L/P) over the time
period of interest stored in an array LossData. The 100(1 −ε)% VaR is
found by sorting the data (in an increasing order), and selecting scenario
with index (S −⌊ε · S⌋+ 1) in the sorted data array.11 Intuitively, we select
the scenario that results in the highest magnitude of loss so that the total
number of scenarios in which the loss is greater is not more than ⌊ε · S⌋.
In Excel 2007, the data can be sorted by clicking on the Data tab,
selecting Sort, and referencing the array where the data are stored. In
MATLAB, the data can be sorted with the command SortedLossData
= sort(LossData). The default for the MATLAB command sort is to
order the elements of the array that is passed to it in increasing order,
so the 100(1 −ε)% VaR is the (S −⌊ε · S⌋+ 1)st element of the array
SortedLossData. Requesting that element is accomplished with the com-
mand SortedLossData(S-floor(ε*S)+1)).
For example, if we have 1000 L/P scenarios, then the 95% VaR will be
the 951st highest scenario ((1000 −⌊0.05 · 1000⌋+ 1) = 951). If we have
1005 L/P scenarios, then the 95% VaR will be the 956th highest scenario
((1005 −⌊0.05 · 1005⌋+ 1) = 956).12
How do we actually decide on the set of scenarios to consider for the
VaR estimation procedure? The simplest approach is to use historical scenar-
ios over a given window (e.g., 1000 observations), updating the most recent
scenarios and dropping scenarios that happened before the most recent 1000
observations. Such scenarios may be bootstrapped; that is, simulation tech-
niques may be used to sample from the set of scenarios and generate a new set
with the same general risk proﬁle.13 The advantage of using bootstrapping
is that the bootstrapped data sets are also useful for gauging the accuracy of
the VaR estimate.14
The obvious drawback of this approach is that important insights from
scenarios that happened outside the window may be lost. For example,
the VaR computed from scenarios for market performance over the year
2006 would be quite low because the market generally rose during that
time period. However, including scenarios from previous ﬁnancial crises
would have enabled us to obtain a better estimate for what was to come
in 2008.
Even when such extreme scenarios are included in the data set, an im-
portant cause for concern is that some events, such as the market crash of
October 1987, are single events that will not impact the VaR unless the con-
ﬁdence level is set very high. One way in which this situation can be mended
is by assigning weights to different historical observations, and preserving
a longer-term memory of possible events. The weights can be determined

Advances in the Theory of Portfolio Risk Measures
291
in different ways. One possible assignment is to do it based on age, that
is, to discount older observations relative to newer ones. Another possible
assignment of weights is based on the current volatility forecast. Namely, if
recent market volatility has been 1% and the forecasted volatility over the
time horizon of risk estimation is higher, then we can adjust all historical
returns by a coefﬁcient to reﬂect the greater anticipated market volatility.
Other approaches for determining scenario weights include incorporating
considerations for the correlations between different assets and so-called
semiparametric bootstrap approaches.15 In practice, a thoughtful approach
to risk estimation would combine two sets of scenarios: a “moderate” set
of scenarios based on the current situation in the market and recent history,
and an “extreme” set of scenarios that repeats major stock, bond and cur-
rency market crises, weighing scenarios in a sensible way. To smooth the
gaps in the VaR estimates obtained from historical data, especially in the
tails of the distribution, practitioners also often ﬁt a probability distribu-
tion to observed historical data, so that the tails of the distribution can be
explicitly modeled when VaR is simulated.16
There are multiple advantages to using historical observations to gen-
erate scenarios for the purposes of risk evaluation. First, the fact that these
scenarios have actually occurred gives them plausibility. Second, they are
easy to understand and generate. A statement like “If a market crash sim-
ilar to the crash in October 2008 happens, our portfolio stands to lose
$X” is easy to communicate and conceptualize. However, this approach
is inherently backward-looking. Simulation of random processes can in-
stead be used to generate forward-looking risk models based on modeling
the uncertainty in a set of underlying market risk factors. Such approaches
are discussed in more detail in Chapter 16, after introducing random pro-
cesses and ﬁnancial derivatives in Chapters 11 through 15. Unfortunately,
traditional Monte Carlo simulation approaches can be very time consum-
ing. In Chapters 14 and 16, we will introduce some methodologies for
reducing the number of scenarios while still achieving an accurate risk
estimate.
8.2.4
VaR Calculation Example
To illustrate how VaR can be calculated under the assumptions in sections
8.2.2 and 8.2.3, let us consider two sets of P/L data in column D in work-
sheets VaR 1 and VaR 2, respectively, in the ﬁle Ch8-VaRCalculation.xlsx.
The P/L distribution for the set of data in worksheet VaR 1 is shown
in Exhibit 8.2. The data in this sample are symmetrically distributed (the
mean and the median are approximately the same, and the skewness is close
to 0), with a distribution that is not as peaked as (i.e., is “ﬂatter” than)

292
PORTFOLIO OPTIMIZATION AND RISK MEASURES
12
8
4
0
–4
–8
–12
0.07
0.06
0.05
0.04
0.03
0.02
0.01
0.00
Profit/Loss
 Proportion of Observations
Mean: 0.20 
Standard deviation: 5.79 
Skewness: 0.03 
Kurtosis: –1.17 
Minimum: –9.57 
Maximum: 10.39 
Median: 0.19 
EXHIBIT 8.2
P/L distribution of the data in worksheet VaR 1 of the ﬁle
Ch8-VaRCalculation.xlsx.
the normal distribution. The VaR calculation directly from historical data
is presented in cells F32:F33 in the worksheet VaR 1. The 99% VaR from
historical data is $9.50 (cell F32), whereas the normal approximation to the
99% VaR based on the estimate of the mean and the standard deviation of
the P/L data is $13.27 (cell F33). In this case, the normal approximation to
the 99% VaR overestimates the “true” 99% VaR computed as a percentile
of the P/L historical data.
More often than not, however, historical P/L graphs look like the graph
in Exhibit 8.3. This historical distribution was obtained from the daily stock
prices of a major ﬁnancial institution (Citigroup) between the beginning of
2005 and the end of 2008, after the major ﬁnancial crisis in the fall of 2008,
and is stored in worksheet VaR 2 of the ﬁle Ch8-VaRCalculation.xlsx.
While the distribution still appears symmetric (the skewness is close to 0),
the distribution has “fat tails”—it has a lot more observations in the tails
than a normal distribution would have. This is conﬁrmed also by the high
positive value for the kurtosis. In this case, the normal approximation to the
99% VaR severely underestimates the 99% VaR obtained as a percentile
of the historical data. The normal approximation 99% VaR is $1.67 (cell
F33), whereas the VaR computed directly from historical data is $2.12
(cell F32).
Worksheets VaR 1 and VaR 2 also contain a calculation of the 99%
VaR based on a bootstrapping procedure and simulating portfolio losses
(rather than P/L). There are 500 realizations for L/P (which is the negative
of P/L) that are drawn randomly from the set of historical data (column D in

Advances in the Theory of Portfolio Risk Measures
293
3.75
2.50
1.25
0.00
–1.25
–2.50
–3.75
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
Profit/Loss
 Proportion of Observations
Mean: –0.04 
Standard deviation: 0.70 
Skewness: 0.01 
Kurtosis: 4.89 
Minimum: –4.15 
Maximum: 4.00 
Median: – 0.04 
EXHIBIT 8.3
P/L distribution of the data in worksheet VaR 1 of the ﬁle
Ch8-VaRCalculation.xlsx.
both worksheets), and are sorted in an increasing order in column O in both
worksheets. The 99% VaR is the 496th observation in each data set. The
bootstrapped 99% VaR in VaR 1 is $9.50, whereas the bootstrapped 99%
VaR in VaR 2 is $2.12. (See this chapter’s Software Hints for an explanation
of how the random scenarios can be drawn from historical data with @RISK
and MATLAB.)
8.2.5
Selection of Value-at-Risk Parameters and
Regulatory Requirements
The calculation of VaR requires two input parameters that appear arbitrary:
the conﬁdence level (1 −ε) and the time horizon. How are these parameters
selected?
Theoretically, the best length to use for the time horizon is the amount
of time it would take to liquidate all positions in the portfolio in an orderly
fashion.17 It is typically assumed that a time period of two weeks (10 business
days) is sufﬁcient, and this is the holding period speciﬁed by regulation. (BIS
capital requirements state a holding period of 10 days.) The time horizons
used by ﬁnancial institutions for internal purposes may be one trading day or
one month, and there are some ﬁnancial institutions that operate on longer
holding periods (e.g., a quarter). However, shorter time periods are more
likely to be used for backtesting and validation of VaR models because
robust validation can only be performed with sufﬁciently large data sets,
and the latter are more available for short time periods. To convert VaR
estimates for a short time period (e.g., a day) into a VaR estimate for a long

294
PORTFOLIO OPTIMIZATION AND RISK MEASURES
time period (e.g., 10 days) for the same conﬁdence level, BIS regulations
sanction the use of the approximation
VaR(1−ε),10 = VaR(1−ε),1
√
10
The mathematics behind this conversion will become clearer in Part
Three, but the intuitive reasoning is that for certain types of random pro-
cesses used to model security prices, variability over time increases with the
square root of the length of the time period. Thus, the VaR over T time
periods should be larger than the VaR over one time period by a factor of
square root of
√
T. (In practice, this is an approximation rather than an
exact conversion; it is an exact conversion only when prices of securities do
indeed follow the speciﬁc type of random process.)
Banks can use any conﬁdence level for estimating VaR for internal pur-
poses, but when they report VaR externally, they typically use a conﬁdence
level that is consistent with other banks (typically, a number in the range
95% to 99%). A very useful technique for setting the VaR parameters for
internal risk management purposes is to analyze the value of VaR for pairs
of values of the conﬁdence level parameter and the length of the time hori-
zon. Thus, a VaR surface rather that a single value of VaR is examined to
determine if the risk is acceptable for any values of the two parameters. As
the conﬁdence level increases (i.e., ε becomes smaller), the estimation of VaR
becomes more challenging because there are fewer historical observations in
the “tail” that can be used to calibrate VaR models accurately.
The ofﬁcial capital adequacy standards for banks prescribed by the 1996
Amendment to the 1988 Basel Accord include the following:
■Banks in the G-10 countries18 should report a 10-day VaR at the 99%
level.
■Banks are free to calculate their VaR using their own models under
certain conditions:
■The models used for internal risk management should be the same as
the ones used for reporting to regulators.
■The models must be approved by the regulating body.
■The models must meet certain technical conditions on computing the
risks of relatively complex positions.
■Banks must calibrate their daily VaR measures to daily P/L observations.
They must perform backtesting daily, and must identify the number of
trading days in which losses exceed the VaR.
■The results of these backtests are used to assess VaR models and to
determine a value for a so-called hysteria factor, or a multiplier to
apply to standard VaR estimation results. In particular, the VaR value

Advances in the Theory of Portfolio Risk Measures
295
reported for regulatory purposes should be always the greater of the
standard VaR value and the average of the VaR values over the last 60
days, multiplied by the hysteria factor, which is a number between 3
and 4. For example, if there are fewer than ﬁve exceptions to the VaR
models over the last 250 days, then the multiplier is 3; if there are ﬁve
exceptions, the multiplier is 3.40, and so on.
The more recent Basel Accord, Basel II, which was published in 2004,
retained these main features, but also included new provisions on credit risk
and operational risk models.
It is important to note that while the point of these regulations is to
improve bank solvency, these capital requirements do little to achieve this
goal. Not only are some of the rules arbitrary, but there is also a lot of
leeway given to the individual banks in backtesting and reporting VaR,
which can make the whole process of reporting VaR for regulatory purposes
meaningless.
8.2.6
Optimization of Value-at-Risk
In addition to risk management, VaR can be used in making decisions for
portfolio allocation purposes.
The portfolio VaR optimization problem is in fact a problem with
chance constraints, which we introduced in section 6.2.3. To see this, note
that we can state the VaR minimization problem as
min
γ,w
γ
s.t.
P(−˜r′w > γ ) ≤ε
w′ι = 1
where ˜r is the N-dimensional vector of (uncertain) asset returns over the time
horizon for portfolio optimization, and w is the N-dimensional vector of
asset weights in the portfolio. In words, this optimization formulation states
that we would like to minimize a number γ (which is a decision variable) so
that the probability that the portfolio losses exceed γ is less than or equal
to a small number ε. We also have the standard budget constraint that the
portfolio weights must add up to 1, or 100%.19
Given our discussion about optimization problems with chance con-
straints in section 6.2.3, optimizing a portfolio allocation so that the result-
ing VaR is the lowest among all possible distributions is nontrivial. Suppose,
for example, that we are given data on S possible scenarios for vectors of

296
PORTFOLIO OPTIMIZATION AND RISK MEASURES
individual asset returns r(1), . . . , r(S). The VaR optimization problem can be
written as20
min
γ,w
γ
s.t.
(−r(s))′w ≤γ + M · ys,
s = 1, . . . , S
S

s=1
ys ≤⌊ε · S⌋
w′ι = 1
ys ∈{0, 1},
s = 1, . . . , S
where M is a “large” constant. Since the input data in the formulation are
asset returns (which are small in magnitude), a value of 100 for M is large
enough for all practical purposes. The optimal value of γ returned by the
solver will be the minimum value for the VaR.
Note that for a data set consisting of 1,000 scenarios, this problem
formulation involves solving a mixed integer optimization problem21 with
1,000 binary variables, which can take a very long time. In practice, the
optimization of VaR can be done with approximations, or with additional
assumptions. For example, if we assume that the asset returns follow a
multivariate normal distribution with a vector of means µ and a covariance
matrix , then the portfolio VaR optimization problem can be written as22
min
γ,w
γ
s.t.
−µ′w + z(1−ε) ·
√
w′w ≤γ
w′ι = 1
where z(1−ε) is the 100(1 −ε)th percentile of a standard normal distribution,
as explained in section 8.2.2 of this chapter and section 6.2.3 of Chapter 6.
Notice that this formulation is equivalent to the optimization formulation
min
w
−µ′w + z(1−ε) ·
√
w′w
s.t.
w′ι = 1
which can also be written as
max
w
µ′w −z(1−ε) ·
√
w′w
s.t.
w′ι = 1
This formulation involves optimizing the portfolio allocation using only
the portfolio mean (µ′w) and the portfolio standard deviation
√
w′w. Thus,
the portfolio allocations resulting from solving this will suffer from the same
drawbacks as allocations obtained with mean-variance formulations.

Advances in the Theory of Portfolio Risk Measures
297
8.2.7
Arguments For and Against Value-at-Risk
At its introduction, VaR was hailed as an advanced and comprehensive
way to handle portfolio risk. Its appeal was due to several features not
shared by basic measures used to estimate risk before VaR and its ultimate
endorsement by the Basel Committee:
■As we mentioned earlier, VaR is expressed as a dollar amount, making
it easier to convey information about risk exposure to a wide range of
decision makers.
■VaR estimates downside risk rather than dispersion, and it is a prob-
abilistic measure of risk in the sense that implicit in the number re-
ported for VaR is an estimate of the probability that the loss will exceed
that amount. This is not the case with other measures of risk, such as
variance.
■Before VaR, measures of the risk of trading and portfolio positions
included duration (see Chapter 2), option Greeks (discussed in Chapters
13 and 14) and others. Those risk measures, however, do not give a sense
of the entire distribution of possible outcomes; in a sense they are based
on a “what-if” analysis.
■VaR could be applied to any type of asset and position. This is not the
case for variance (which is meaningful mostly for equity and commodity
positions and portfolios and not for complex ﬁnancial securities with
highly non-normal distributions of possible returns), duration (which is
applicable only to ﬁxed income portfolios), or Greeks (which are ap-
plicable to ﬁnancial option positions). Thus, VaR provides a consistent
way to compare risks of equity, ﬁxed income, and other positions, and
can be used to aggregate risks across the entire ﬁrm.
Even early on, however, many criticisms of VaR surfaced. Two of the
most vocal early critics of VaR included Nassim Taleb (1997a,b), who sum-
marized many of his arguments in his best-selling book The Black Swan
(Taleb 2007), and Richard Hoppe (1998). They criticized the literal trans-
fer of techniques from the mathematical and the physical sciences to model
social systems in which processes are not stationary, and depend on the com-
plex dynamic interactions of rational and irrational market agents. Taleb
(1997a) said:
You are worse off relying on misleading information than on not
having any information at all. If you give a pilot an altimeter that is
sometimes defective he will crash the plane. Give him nothing and
he will look out the window.

298
PORTFOLIO OPTIMIZATION AND RISK MEASURES
Such criticisms are valid for all risk management systems—indeed, risk
estimates are subject to errors, model risk (i.e., making wrong assumptions
about the underlying processes), and implementation risk (i.e., risk of errors
because of the way systems are implemented). However, VaR suffers of some
unique disadvantages that should be understood before it is used as a risk
measure.
First, as has become clear by now, VaR does not tell us how much we
could lose if a low-risk tail event occurs. A trading strategy that has the loss
distribution in Exhibit 8.4(A) appears just as risky as the trading strategy
in Exhibit 8.4(B) in terms of VaR. It is clear, however, that we stand to
lose more, and more often, with trading strategy in Exhibit 8.4(B). Thus,
using VaR as the “threshold” for approving an investment strategy can leave
investors exposed to extreme losses.
Losses 
VaR 
Probability in tail 
is 1- ε
(A)
Losses 
VaR 
Probability in tail 
is 1- ε
(B) 
EXHIBIT 8.4
Two trading strategies (A) and (B) with the same
VaR and different losses in the tail. In (B), the VaR is the same, but
the potential losses in the tail are larger on average.

Advances in the Theory of Portfolio Risk Measures
299
Second, VaR’s reporting of the loss at a certain percentile of the dis-
tribution without consideration for the size of the losses in the tail of the
distribution encourages traders to take more low-probability, high-impact
bets. Such risks do not show up in the VaR estimates, but can have a dev-
astating effect on the ﬁrm and, in fact, can destabilize the entire ﬁnancial
system, as the ﬁnancial system collapse in the fall of 2008 demonstrated.
Taleb (1997a) actually predicted this long before it was a reality. He pointed
out that if everybody uses VaR as a risk measure, taking on low-probability
risks in the tail, then the events in the tail become highly correlated, and are
no longer low-probability risk events if the ﬁnancial system is considered as
a whole. Danielsson and Zigrand (2001) also showed that VaR regulatory
constraints on ﬁnancial institutions can actually aggravate ﬁnancial crises
and even cause them because the markets cannot clear properly.
Third, VaR computation and optimization is difﬁcult. It does not make
sense to use a mean-variance framework to estimate or optimize VaR because
that eliminates the whole purpose of using a tail-risk measure. However, esti-
mating VaR by simulation and optimizing VaR can be very computationally
intensive. VaR optimization based on scenarios in particular has nonsmooth
and nonconvex constraints, which means that we cannot trust the solutions
from the optimization solver even if the solver takes a long time to search
for the optimal solution.
Finally, problems exist with the theoretical foundation of VaR as well. In
a seminal article, Artzner, Delbaen, Eber, and Heath (1999) pointed out that
use of VaR actually discourages diversiﬁcation, which goes against intuition
and established portfolio management practices. Let us consider a simple
example to illustrate this fact.
Suppose we can invest in two zero-coupon bonds, A and B, both with
$100 face value.23 Bond A costs $97.00 today and will pay $111.55 one year
from now. Bond B costs $90.00 today and will pay $103.50 one year from
now. Both bonds, however, have a 4% probability of default. If a particular
bond defaults, we will lose our entire original investment in that bond, and
therefore will not receive any payment.
The original value of the individual bonds, the distribution of the indi-
vidual bond’s losses, and the 95% VaR for the position in each bond are
shown in Exhibit 8.5.
Let us show the calculations for Bond A. The loss on Bond A is computed
as ($97.00 – Final payment), and is therefore −$14.55 (a proﬁt) if the bond
pays as promised, and $97.00 (an actual loss) if the bond defaults. Since the
loss of $97.00 happens with probability of 4%, which is in the tail of the
distribution, the 95% VaR does not account for it, and hence the 95% VaR
equals −$14.55. The interpretation is that we will realize a proﬁt of $14.55
on our position in Bond A with probability no less than 5%. Similarly, we

300
PORTFOLIO OPTIMIZATION AND RISK MEASURES
EXHIBIT 8.5
Calculation of the VaRs of two individual positions in zero-coupon
bonds with 4% probability of default.
Distribution of Losses
Position Today
End Payment
Probability
Amount of Loss
95% VaR
Bond A
$97.00
$111.55
0.96
$(14.55)
$(14.55)
0.04
$ 97.00
Bond B
$90.00
$103.50
0.96
$(13.50)
$(13.50)
0.04
$ 90.00
can obtain the 95% VaR of the individual position in Bond B—it is again a
proﬁt (a loss of −$13.50).
The sum of the VaRs of the two positions is therefore −$14.55
(−$13.50) = −$28.05, that is, it is a proﬁt of $28.05.
Now let us compute the probability distribution of the losses on a
portfolio that consists of a long position in Bond A and a long position
in Bond B.
■With probability 92.16% ( = 0.962), both Bond A and Bond B will
make their ﬁnal payments, in which case the loss on the portfolio will
be −$14.55 + (−$13.50) = −$28.05; that is, there will be a proﬁt of
$28.05.
■With probability 3.84% ( = 0.96·0.04), Bond B will default and Bond
A will pay, in which case the loss on the portfolio will be (−$14.55) +
$90.00 = $75.45.
■With probability 3.84% ( = 0.04·0.96), Bond A will default and Bond
B will pay, in which case the loss on the portfolio will be $97.00 +
(−$13.50) = $83.50.
■With probability 0.16% ( = 0.042), both bonds will default, in which
case the loss will be $97.00 + $90.00 = $187.00.
The probability distribution of the portfolio losses is illustrated in Ex-
hibit 8.6. Note that the cumulative probability becomes 95% at a value of
$75.45 for losses, which determines the value of the 95% VaR.
Hence, in this example the 95% VaR of the portfolio, $75.45, is higher
than the sum of the individual 95% VaRs (−$28.05). In fact, a risk man-
ager who uses the 95% VaR portfolio as a risk measure for this portfolio
would prefer to increase the portfolio’s holdings in one of these bonds rather
than diversify and invest in both at the same time. Ironically, VaR, which
gained popularity because of its ability to summarize ﬁrmwide risk based on

Advances in the Theory of Portfolio Risk Measures
301
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
$(28.05)
$75.45
95% VaR
Amount of Loss
Probability
$83.50
$187.00
92.16%
92.16%
$ (28.05)
3.84%
96.00%
$   75.45
3.84%
99.84%
$   83.50
0.16%
100.00%
$ 187.00
Probability
Cumulative
Probability
Amount
of Loss
EXHIBIT 8.6
Probability distribution of portfolio losses and 95% VaR.
compounding risk reports from different parts of the ﬁrm, is actually ill-
suited for calculating compounded risks!
8.3
CONDITIONAL VALUE-AT-RISK AND THE
CONCEPT OF COHERENT RISK MEASURES
In view of the conceptual difﬁculties associated with classical measures of
risk, Artzner, Delbaen, Eber, and Heath (2001) suggested a new class of risk
measures they called coherent risk measures. A risk measure ρ is a coherent
measure of risk if it satisﬁes the following conditions for any two random
variables ˜x and ˜y:
1. Monotonicity. If ˜x ≥0, then ρ( ˜x) ≤0.
2. Subadditivity. ρ( ˜x + ˜y) ≤ρ( ˜x) + ρ( ˜y).
3. Positive homogeneity. For any positive real number c, ρ(c · ˜x) = c · ρ( ˜x).
4. Translational invariance. For any real number c, ρ( ˜x + c) ≤ρ( ˜x) −c.
In words, these properties can be interpreted as follows:
1. If there are only positive returns, then the risk should be nonpositive.
2. The risk of a portfolio of two assets should be less than or equal to the
sum of the risks of the individual assets.
3. If the amount of assets in the portfolio is increased c times, the risk
becomes c times larger.
4. Cash or another risk-free asset does not contribute to portfolio risk.
Conditions (1), (3), and (4) are rather technical, and arguments have
been presented in the literature that not all of them need to be satisﬁed for a
risk measure to be considered acceptable in practice. Condition (2), however,

302
PORTFOLIO OPTIMIZATION AND RISK MEASURES
is worth noting. It expresses the principle of diversiﬁcation: aggregating
different risks should diversify them away, not increase the overall risk.
As we saw in the example at the end of the previous section, VaR
violates the second condition. In particular, there are instances in which the
sum of the risks of two individual investments as represented by their VaRs
is less than the risk (as represented by the VaR) of the portfolio of the two
investments.
Taken together, the four conditions for coherence are rather restrictive.
The standard deviation does not satisfy them either—it violates the mono-
tonicity property. Artzner, Delbaen, Eber, and Heath (2001) suggested a
tail-based risk measure that we mentioned earlier, conditional value-at-risk
(CVaR), which satisﬁes all four conditions, and is related to the popular risk
measure VaR. The intuitive explanation behind CVaR and the easy way in
which the portfolio allocation problem could be solved rapidly increased its
popularity in practice.
While 100(1 −ε)% VaR only considers the maximum loss with a given
probability ε, the 100(1 −ε)% CVaR asks what happens on average if the
losses exceed the 100(1 −ε)% VaR; that is, what is the expected loss in the
tail. Thus, CVaR addresses a major problem associated with VaR, which is
that VaR ignores losses that may happen with low probability.
The formal deﬁnition of the 100(1 −ε)% CVaR is
CVaR(1−ε)(˜r) = E

−˜r| −˜r ≥VaR(1−ε)(˜r)

Note that this deﬁnition implies that the 100(1 −ε)% CVaR is always
greater than or equal to the 100(1 −ε)% VaR. In other words, if we manage
our portfolio risk using CVaR, we will be implicitly minimizing our portfolio
VaR as well.24
It is difﬁcult to estimate the CVaR for a general distribution but, simi-
larly to VaR, there are methods for estimating CVaR in special cases, such as
the case in which we assume that future losses are normally distributed, or
when we are given a set of scenarios for possible realizations of the portfolio
returns.
8.3.1
Estimation of Conditional Value-at-Risk from
a Normal Distribution
Let us ﬁrst illustrate the calculation of CVaR for a normal distribution when
the data is in P/L format, and is assumed to follow a normal distribution. In
this case, the 100(1 −ε)% CVaR is given by the expression25
CVaR(1−ε) = −µP/L + ϕ(z(1−ε))
ε
· σP/L

Advances in the Theory of Portfolio Risk Measures
303
where
µP/L is the mean of the P/L distribution
σP/L is the standard deviation of the P/L distribution
The number z(1−ε)is the 100(1 −ε)th percentile of a standard normal
distribution, as before, and we use ϕ(z(1−ε)) to denote the value of the normal
probability density at the point z(1−ε). For any z, the value of ϕ(z) can be
found with the command NORMDIST(z,0,1,0) in Excel, or normpdf(z)
in MATLAB. For example, let ε = 0.05. Therefore, 1 – ε = 0.95 and
z(1−ε) = norminv(0.95) = 1.6448. The value of ϕ(z(1−ε)) is then 0.1031
(computed as NORMDIST(1.6448,0,1,0) in Excel or normpdf(1.6448)
in MATLAB).
If, instead, we have normally distributed L/P data, then we would use
the formula
CVaR(1−ε) = µL/P + ϕ(z(1−ε))
ε
· σL/P
Finally, if we are given data on asset returns and assume arithmetic
returns, the formula for CVaR would be
CVaR(1−ε) =
#
−µr + ϕ(z(1−ε))
ε
· σr
$
· Vt
where Vt is the portfolio value at the beginning of the period over which
CVaR is estimated.
8.3.2
Estimation of Conditional Value-at-Risk from
a Discrete Distribution
Suppose we have a discrete distribution of scenarios for portfolio losses, and
a loss amount of lj occurs with probability pj. The 100(1 −ε)% CVaR is
given by
CVaR(1−ε) = 1
ε ·

j such that l j ≥VaR(1−ε)
pj · l j
One special case of a discrete distribution that is encountered often in
practice is a discrete uniform distribution, in which every scenario in a set
of S scenarios could happen with the same probability 1/S. This happens,

304
PORTFOLIO OPTIMIZATION AND RISK MEASURES
for example, when we use historical scenarios as a basis for our CVaR
calculations. In this case, CVaR is the average of all scenarios that exceed
the VaR, or, equivalently, the average of the highest ⌊ε · S⌋scenarios. For
simplicity, suppose that we have sorted the S scenarios for losses in increasing
order (i.e., scenario S is the scenario with the highest loss). We can compute
the 100(1 −ε)% CVaR as
CVaR(1−ε) =
1
⌊ε · S⌋·
S

s=S−⌊ε·S⌋+1
ls
For example, if there are 215 scenarios and ε = 0.05, then ⌊ε · S⌋=
⌊0.05 · 215⌋= ⌊10.75⌋= 10. The 95% CVaR is the average of the 10
scenarios with highest losses. If the scenarios are sorted in increasing order,
we take the average of the losses in scenarios 206, 207, . . . , 215.
If the data are in the form of arithmetic returns, we can compute the
CVaR by using the same expression as above, but replacing the loss with
the negative of the return in each scenario, and multiplying the resulting
amount by the portfolio value at the beginning of the time period under
consideration.
8.3.3
Optimization of Conditional Value-at-Risk
The CVaR of a portfolio of N assets is a function of both the uncertain
returns of the different assets in the portfolio (the N-dimensional vector ˜r),
and the weights w these assets have in the portfolio. For any given set of
weights w, the portfolio return is given by ˜rp = ˜r′w. Suppose the portfolio
return ˜rp follows a probability distribution with density function f. Then,
we can express the 100(1 −ε)% CVaR mathematically as
CVaR(1−ε) = 1
ε ·

−r≥VaR(1−ε)
(−r) · f (r) dr.
We can recognize the term inside the integral as the expected value of
the portfolio loss (as a percentage of amount invested) in the tail of the
distribution.
In fact, CVaR is a function of the portfolio weights for the dif-
ferent assets w, which determine the probability distribution of ˜rp. The
existence of expected value in the deﬁnition of CVaR suggests the pos-
sibility of using stochastic programming methods if we want to ﬁnd the

Advances in the Theory of Portfolio Risk Measures
305
asset allocation that results in the minimum portfolio CVaR.26 Unfortu-
nately, the deﬁnition of CVaR in terms of VaR makes it hard to optimize
the CVaR because we need to go through the VaR, which itself suffers
from computational difﬁculties when it comes to optimization. Rockafellar
and Uryasev (2000) suggested using an auxiliary objective function instead
of CVaR that has better computational properties. Namely, consider the
function
F1−ε(w, ξ) = ξ + 1
ε .

−r≥ξ
(−r −ξ). f (r) dr
which can be equivalently written as
F1−ε(w, ξ) = ξ + 1
ε ·
∞

−∞
max {−r −ξ, 0} · f (r) dr
It turns out that if we try to minimize this function by varying w and ξ, the
minimum value of the function will in fact equal the 100(1 −ε)% CVaR.
Mathematically, this is expressed as
min
w CVaR1−ε = min
w,ξ F1−ε(w, ξ)
Hence, we can ﬁnd the minimum value of CVaR without ﬁnding VaR
ﬁrst.27 The value of ξ in the optimal solution will actually equal the VaR of
the optimal portfolio found by optimizing the CVaR. However, the weights
for the portfolio that minimizes CVaR will not necessarily be the weights
for the portfolio that minimizes VaR. An example is shown in this chapter’s
Software Hints.
Note that the integral in the expression for F1−ε(w, ξ) is multidimen-
sional, and its calculation depends on knowing the joint probability density
function of the returns of all assets in the portfolio. This is not only difﬁcult
to estimate, but is often undesirable to use, as multidimensional integration
is very time consuming. There is a speciﬁc case in which the minimization
of CVaR is a tractable optimization problem: when the joint probability
density function of the returns for the assets in the portfolio is represented
in a set of scenarios. This is typically the kind of data we have in practice:
we can use historical data, or generate scenarios by simulation. Suppose also

306
PORTFOLIO OPTIMIZATION AND RISK MEASURES
that each scenario in the set is equally likely. In that case, the function can
be written as
F(1−ε)(w, ξ) = ξ +
1
⌊ε · S⌋·
S

s=1
max

−(r(s))′w −ξ, 0

where the N-dimensional vector r(s) is the vector of returns on the N assets
in the sth scenario. (Note here that (r(s))′w is the portfolio return in the sth
scenario.)
To make this function more optimization-solver friendly, we get rid of
the expression
max

−(r(s))′w −ξ, 0

by introducing auxiliary decision variables y1,. . ., yS, one for each scenario.
We write the portfolio CVaR minimization problem as
min
w,ξ,y
ξ +
1
⌊ε · S⌋·
S

s=1
ys
s.t.
ys ≥−(r(s))′w −ξ,
s = 1, . . . , S
ys ≥0,
s = 1, . . . , S
w′ι = 1
To understand the meaning of the ﬁrst two sets of constraints, note that
the objective function contains a minimization of the sum of the variables
ys. The optimization solver will try to make the values of these variables
as small as possible. The ﬁrst two sets of constraints, however, restrict the
auxiliary variables ys to be greater than both −(r(s))′w −ξ and 0. Thus, in
order to satisfy both sets of constraints, the solver will set them equal to
the larger of the two values, that is, to the maximum of −(r(s))′w −ξ and 0,
which is the expression in F(1−ε)(w, ξ). See Practice 8.5 on the companion
web site for an alternative derivation of the optimization formulation using
optimization duality theory instead of the auxiliary function F(1−ε)(w, ξ).
The previous formulation is a linear optimization problem, which makes
sample CVaR optimization a particularly attractive option from a compu-
tational perspective. Adding portfolio constraints encountered in practice,
such as number of positions, trading costs, and so on. (see Chapter 9)
generally results in equally tractable (linear or mixed-integer) optimization
formulations. For example, we can formulate an optimization problem of

Advances in the Theory of Portfolio Risk Measures
307
maximizing the expected portfolio return subject to a constraint on the
portfolio CVaR by rewriting the previous problem as
max
w,ξ,y
µ′w
s.t.
ξ +
1
⌊ε · S⌋·
S

s=1
ys ≤b1−ε
ys ≥−(r(s))′w −ξ,
s = 1, . . . , S
ys ≥0,
s = 1, . . . , S
w′ι = 1
where µ is the N-dimensional vector of expected returns on the N assets,
and b1−ε is the average loss in the tail the portfolio manager is willing to
tolerate.
This chapter’s Software Hints contains examples of the implementation
of sample portfolio CVaR optimization with Excel Solver and MATLAB’s
Optimization Toolbox.
SUMMARY
■The mean-variance portfolio optimization framework takes into con-
sideration only the ﬁrst two moments of the distribution of portfolio
returns, the mean and the variance, and does not take into considera-
tion higher moments. Thus, it omits important information about the
skewness, kurtosis, and higher moments of the distribution.
■A number of advanced risk measures have been suggested to incorporate
such considerations better. In particular, many advanced portfolio risk
measures look at the potential for downside risk. Such risk measures in-
clude semivariance, Roy’s safety ﬁrst, and quantile-based risk measures
such as value-at-risk (VaR) and conditional value-at-risk (CVaR).
■VaR measures the maximum portfolio loss at a speciﬁed probability
level over a given time horizon. Speciﬁcally, it is deﬁned as the value
such that the probability that the portfolio loss will exceed it is not
more than some small number.
■The position or portfolio VaR can be estimated via three methods: (1)
based on an approximation by the normal distribution; (2) via historical
simulation; (3) via Monte Carlo (forward-looking) simulation.
■Despite its advantages as a comprehensive measure of risk that can be
applied to any type of asset and position, VaR suffers from a number of

308
PORTFOLIO OPTIMIZATION AND RISK MEASURES
drawbacks. From a practical perspective, VaR does not convey informa-
tion about the size of the possible extreme losses. Moreover, employing
it as a risk management tool in an institution may encourage unde-
sirable behavior, as traders have an incentive to take low-probability,
high-impact bets that do not show up on the VaR radar screen. From a
theoretical perspective, VaR does not support the principle of diversiﬁ-
cation.
■CVaR corrects some of the undesirable properties of VaR in that CVaR
is concerned with measuring extreme losses, and supports the principle
of diversiﬁcation. CVaR is deﬁned as the expected loss in the tail of
the probability distribution of portfolio losses, that is, it reports the
expected loss if the losses exceed the VaR.
■CVaR can be estimated similarly to VaR: (1) based on an approximation
by the normal distribution; (2) via historical simulation; (3) via Monte
Carlo (forward-looking) simulation.
■Portfolio allocation with the goal of minimizing VaR is a difﬁcult
stochastic optimization problem with chance constraints. It is gener-
ally very computationally intensive to solve, and the solution returned
by the solver is not guaranteed to be optimal.
■The portfolio CVaR optimization problem is a difﬁcult problem except
in a case which is widely the context in practice: when the data for the
problem are in the form of scenarios for the possible realizations of asset
returns. In the latter case, the portfolio CVaR minimization problem has
a tractable linear programming formulation.
SOFTWARE HINTS
Excel/Palisade Decision Tools Suite
VaR Estimation
First, we explain how to bootstrap a given random number
of scenarios (say, 500) from a list of historical observations. Let us consider
the example of VaR estimation from section 8.2.4. We focus on worksheet
VaR 1 in the ﬁle Ch8-VaRCalculation.xlsx. In cell P3, we use the formula
= RiskOutput("Boostrapped P/L")+−RiskDuniform(D3:D589)
to create a random variable that draws a number from the array D3:D589
with equal probability (Duniform stands for “discrete uniform distribu-
tion”), and records the negative of that number. Therefore, the value that
is recorded for that cell when the simulation is run is an observation for
L/P (which is the negative of P/L). The ﬁrst part of the preceding expression

Advances in the Theory of Portfolio Risk Measures
309
makes the cell an output cell for @RISK, so that @RISK can keep track of
the values generated during the simulation.
Column O contains 500 scenarios that were generated from the simula-
tion. They can be saved into a spreadsheet by clicking on the Excel Reports
button in the @RISK tab, and checking Simulation Data. The 99% VaR
is the 496th of these scenarios (0.99·500), that is, it is $9.50. The value is
marked in yellow (cell O498) in the spreadsheet.
An alternative way to estimate the 99th percentile of a simulated output
distribution from @RISK is to use the RiskPercentile command. For
example, to ﬁnd the 99% VaR as the 99th percentile of the L/P distribution
simulated by @RISK in cell P3, we write
= RiskPercentile(P3,0.99)
The RiskPercentile formula is a shortcut—it is equivalent to looking
at the output from the simulation, and making a note of the 99th percentile. It
is important to note, however, that the value obtained with RiskPercentile
may not be exactly the same as the value of the 496th sorted scenario for
losses.
CVaR Estimation
To estimate CVaR from a historical or simulated data,
ﬁrst we need to sort the scenarios in increasing order. (In Excel, click the Data
tab, and then Sort in the Sort & Filter group.) The procedure is illustrated in
the ﬁle Ch8-CVaRCalculation.xlsx. Column N in the worksheets CVaR 1
and CVaR 2 contains the P/L data from column D, sorted in increasing
order. The 99% CVaR is the negative of the average of the lowest 1% of the
P/L observations, that is, of the observations in cells N3:N7 in worksheet
CVaR 1 (respectively, cells N3:N12 in worksheet CVaR2).
VaR Optimization
File Ch8-VaRCVaROpt.xlsx contains 60 scenarios for
return realizations of three stocks. We will use the data to implement the
scenario optimization formulation of the VaR minimization problem from
section 8.3.3.
Exhibit 8.7 contains a partial snapshot of the worksheet with the op-
timization setup from worksheet VaR in the ﬁle Ch8-VaRCVaROpt.xlsx.
Cells B3:D3 contain the values of the decision variables (the weights for
the three stocks). Cell G3, the target cell, will be minimized by Solver, but
it contains no formula. It will be speciﬁed as a decision variable (changing
cell) itself as part of the optimization problem (see the Solver dialog box
in Exhibit 8.8). Cells G10:G69 are changing cells as well—they correspond
to the variables y in the formulation in section 8.2.5. Cells I10:I69 con-
tain the formulas that correspond to the ﬁrst set of constraints in the VaR

310
PORTFOLIO OPTIMIZATION AND RISK MEASURES
EXHIBIT 8.7
Solver setup for portfolio VaR optimization based on scenarios for
possible asset returns.
optimization formulation with scenarios for the returns. For example,
cell I10 contains the formula
= (-SUMPRODUCT(B10:D10,$B$3:$D$3)-$G$2)/$B$8
Note that we picked the value of the “large constant” M to be 10,
rather than some extremely large number. M = 10 is large relative to the
other coefﬁcients in the problem, so this is sufﬁcient.
EXHIBIT 8.8
Excel Solver setup for the sample VaR optimization problem.

Advances in the Theory of Portfolio Risk Measures
311
EXHIBIT 8.9
Evolver dialog box for the VaR optimization
problem.
There are also a couple of additional constraints, the budget constraint
(cells G5:I5), and the constraint on the total number of observations to be
considered in the tail (cells G6:I6).
Solving the problem with Excel Solver produces an optimal value for
the VaR of 4.62%, and optimal asset weights of 47.81%, 32.38%, and
19.81%, respectively. This problem is challenging for many optimization
solvers.
The same spreadsheet setup can be used also to solve the problem with
Palisade’s Evolver (see worksheet VaR(Evolver) in the same ﬁle). A screen-
shot of the Evolver dialog box is shown in Exhibit 8.9. Because of the fact
that Evolver uses genetic algorithms, the performance of the solver is ex-
tremely inﬂuenced by the starting point, that is, the initial values for the
changing cells. It may take many iterations to reach a reasonably good
solution.
CVaR Optimization
The worksheet CVaR in the ﬁle Ch8-VaRCVaROpt
.xlsx contains scenarios for return realizations of three stocks, and the setup
for the CVaR optimization problem from section 8.3.3 with Excel Solver.
Since the problem is linear, Excel Solver can handle it easily, and it is not
necessary to use advanced solvers like Evolver.

312
PORTFOLIO OPTIMIZATION AND RISK MEASURES
EXHIBIT 8.10
CVaR worksheet in ﬁle Ch8-VaRCVaROpt.xlsx, which contains
the setup for CVaR optimization with Excel Solver.
A partial screenshot is given in Exhibit 8.10. The setup is very similar to
the one for VaR optimization. However, we have a few additional variables
and constraints.
Cells B3:D3 contain the values of the decision variables (the weights for
the three stocks). We also have the changing cell E3, which will contain the
value of ξ in the formulation for the CVaR optimization objective function.
Finally, we will have the changing cells G10:G69, which will correspond
to the variables y in the formulation in section 8.3.3. The formulas for
the right-hand sides of the constraints in which they participate are in cells
I10:I69. For example, cell I10 contains the formula
=-SUMPRODUCT(B10:D10,$B$3:$D$3)-$E$3
Cell G3, the target cell, will be minimized by Solver, and contains the
formula
=E3+(1/B7)*SUM(G10:G69)
As in the case of VaR optimization, there is also the budget constraint
(cells G5:I5), and the constraint that the variables y need to be nonnega-
tive. (The latter constraint is imposed directly in the Solver dialog box; see
Exhibit 8.11.)
The optimal solution is in Exhibit 8.10. The optimal value for the portfo-
lio CVaR is 6.87% (cell G2), and the optimal portfolio weights are 18.03%,
44.14%, and 37.82% (cells B3:D3). The value for the auxiliary decision

Advances in the Theory of Portfolio Risk Measures
313
EXHIBIT 8.11
Excel Solver dialog box for the CVaR optimization problem.
variable ξ (cell E3) is 5.83%. The value for ξ is actually the portfolio VaR
value. To see that this is the case, consider the simulation output from
10,000 bootstrapped returns for the optimal portfolios obtained with VaR
and CVaR optimization. The portfolio returns were obtained by running the
simulation in spreadsheet Data (cells E4 and E5 record the portfolio return
with the optimal weights for VaR and CVaR, respectively). The output is
stored in worksheet Simulation Output Data.
The realized 95% VaR obtained for the portfolio with optimal weights
in terms of VaR (47.81%, 32.38%, and 19.81%) is 4.62%, as the op-
timization problem forecasted. The realized 95% VaR obtained for the
portfolio with optimal weights in terms of CVaR (18.03%, 44.14%, and
37.82%) is 5.83% – higher than 4.62%, which is to be expected be-
cause the optimization problems had different objective functions. In fact,
5.83% is the optimal value of ξ (cell E3) that we obtained after the CVaR
portfolio optimization. But note that the optimal value of ξ is not actu-
ally the best VaR that we could get for a portfolio consisting of these
three stocks.
You can also observe that the realized 95% CVaR obtained for the
portfolio with optimal weights in terms of VaR (47.81%, 32.38%, and
19.81%) is 8.40%, while the realized 95% CVaR obtained for the portfolio
with optimal weights in terms of CVaR (18.03%, 44.14%, and 37.82%) is
6.87%, as the CVaR optimization forecasted. Again, the simulated portfolio
CVaR for a portfolio with weights obtained by minimizing CVaR is better
than the simulated portfolio CVaR for a portfolio with weights obtained by
minimizing a different objective function, such as VaR.

314
PORTFOLIO OPTIMIZATION AND RISK MEASURES
MATLAB
VaR and CVaR Estimation
File VaRCVaREst.m contains code for com-
puting VaR and CVaR from historical and boostrapped data. As an il-
lustration, we use the data from worksheet VaR 1 in the ﬁle Ch8-VaR
Calculation.xlsx.
After reading in the data from the Excel ﬁle (which is a column array
with P/L data) with the xlsread command and storing it in the array PL-
Data, we record the number of observations in the data set in the variable
numObservations with the command
[numObservations,numColumns] = size(PLData);
Let us use ε = 1% for the VaR and CVaR computation. First, we sort
the array of data in an increasing order:
sortedPLData = sort(PLData);
Since we are given the data in P/L form, we need to ﬁnd the index of
the observation so that 1% of the observations are to the left of it. Let the
name of the variable in which we save this index be obsIndex. We have
obsIndex = floor(epsilon*numObservations);
(The command floor in MATLAB rounds down a fractional value.) If the
data were in L/P form and were sorted in increasing order in the array
sortedLPData, we would have used instead the formula
obsIndex = numObservations −floor(epsilon*numObservations)
+ 1
to ﬁnd the index of the observation so that 1% of the observations are to
the right of it.
The actual computation of VaR involves simply requesting the observa-
tion with index obsIndex from the sorted data array sortedPLData:
VaR = -sortedPLData(obsIndex)
In the case of L/P data, we would have used the formula
VaR = sortedLPData(obsIndex).

Advances in the Theory of Portfolio Risk Measures
315
To ﬁnd the CVaR from the sorted P/L data array, we use the formula
CVaR = -mean(sortedPLData(1:obsIndex))
If the data were in L/P form, we would use
CVaR = mean(sortedLPData(obsIndex:end))
After running the code in MATLAB, we see the output
VaR =
9.5044
CVaR =
9.5384
The estimate of VaR and CVaR from a list of bootstrapped scenarios
is found in an analogous way, and the code is available in the ﬁle VaRC-
VaREst.m. The command
randomIndices = unidrnd(numObservations,1,numScenarios);
generates numScenarios random numbers between 1 and numObserva-
tions, drawing each number between 1 and numObservations with equal
probability. We treat these random numbers as random indices, and use
them to pick a set of numScenarios random scenarios from the array with
P/L data. We use the command
boostrappedData = PLData(randomIndices);
to accomplish that. (Note that when a vector array of indices is passed
as an argument to an array, as in PLData(randomIndices), the result is
an array which only contains the observations with indices in the array
randomIndices).
Next, we sort the array with boostrapped data, determine the observa-
tion number so that 1% of the observations are to the left of it (in the case
of P/L data), and use it to compute the actual values of VaR and CVaR. The
MATLAB code is presented below.
%generate random numScenarios from original data
boostrappedData = PLData(randomIndices);

316
PORTFOLIO OPTIMIZATION AND RISK MEASURES
%sort data to compute VaR and CVaR
sortedBoostrappedData = sort(boostrappedData);
%compute VaR and CVaR
scenarioIndex = floor(epsilon*numScenarios);
boostrappedVaR = -sortedBoostrappedData(scenarioIndex)
boostrappedCVaR = -
mean(sortedBoostrappedData(1:scenarioIndex))
VaR and CVaR Optimization
At present, MATLAB cannot be used to ﬁnd
the optimal portfolio allocation for VaR over scenarios because the op-
timization problem is of the mixed-integer kind, which cannot be han-
dled by MATLAB’s optimization solvers. Instead, one may want to use
good mixed-integer solvers such as CPLEX, and if necessary, link them
to MATLAB code through modeling languages like TOMLAB28 and
ROME.29
It is also difﬁcult to optimize the normal approximation formulation to
the portfolio VaR because of the presence of the square root in the objective
function. However, as we mentioned in Chapter 8, the normal approxi-
mation to the portfolio VaR is basically analogous to using mean-standard
deviation portfolio allocation, so classical mean-variance allocation schemes
can be used instead.
The formulation for the CVaR optimization problem when the uncer-
tain data are presented as scenarios (section 8.3.3) can be solved directly
with MATLAB because the optimization problem formulation is linear. The
MATLAB code is in the ﬁle CVaROpt.m. We use the data set from the ﬁle
Ch8-VaRCVaROpt.xlsx, worksheet CVaR.
In the code, we use the MATLAB function for solving linear optimiza-
tion problems, linprog (see the introduction to MATLAB’s Optimization
Toolbox in the Software Hints for Chapter 5). To prepare the inputs to the
function, we need to write the problem formulation from section 8.3.3 in a
matrix form. First, we rewrite the formulation in the following way:
min
w,ξ,y
ξ +
1
⌊ε · S⌋·
S

s=1
ys
s.t.
−(r(s))′w −ξ −ys ≤0,
s = 1, . . . , S
w′ι = 1
ys ≥0,
s = 1, . . . , S

Advances in the Theory of Portfolio Risk Measures
317
Since the linprog formulation requires a single vector x of decision
variables, we merge all decision variables into it: the weights w, the auxiliary
variable ξ, and the auxiliary variables y. Thus, x is an N + 1 + S dimensional
vector, where N is the number of assets in the portfolio, and S is the number
of scenarios (observations) in the data set.
To represent the objective function vector f, we concatenate three vec-
tors: an N-dimensional vector of zeros (that part of f will correspond to the
weights part of the decision variables vector x), a single-element array with
1 as an entry (that part of f will correspond to the variable ξ in the decision
variables vector x), and an S-dimensional vector of coefﬁcients 1/ ⌊ε · S⌋,
which will correspond to the y part of the decision variables vector x). It is
easy to concatenate vector and matrix arrays in MATLAB; as shown in the
code, the vector f can be represented as
f = [zeros(numAssets,1); 1; (1/K)*ones(numObservations,1)]
You can observe that multiplying the vector array for f,
f =
⎡
⎣0
. . .
0
%
&'
(
N
1
1
⌊ε · S⌋
. . .
1
⌊ε · S⌋
%
&'
(
S
⎤
⎦
by the decision variables array x,
x =

w1
. . .
wN
%
&'
(
N
ξ
y1
. . .
yS
%
&'
(
S

will result in the objective function in the preceding optimization problem
formulation.
To represent the set of constraints
Ax ≤b,
we create the matrix A as a concatenation of three arrays: an S × N array
corresponding to the negatives of the return realizations in each scenario
(those will be multiplied by the weights portion of the vector of decision
variables x), an S × 1 array corresponding to the coefﬁcients of –1 in front of
the auxiliary variable ξ, and an S × S array corresponding to the coefﬁcients
of –1 in front of the auxiliary variable ys in the scenario s in each row.
The latter array is in fact the negative of an identity matrix30 of dimension

318
PORTFOLIO OPTIMIZATION AND RISK MEASURES
S × S, which in MATLAB can be declared with the command eye(S,S).
The vector b is simply an S-dimensional column array of zeros.
The set of equalities w′ι = 1 in the CVaR problem formulation can be
written in the standard Aeq·x = b form of the MATLAB linprog function
by declaring a matrix (in fact, a single row vector) of dimension N + 1 + S,
which contains ones in its ﬁrst N entries, and zeros everywhere else.
Finally, we declare the bounds on the different variables. The upper
bounds on all decision variables are inﬁnity, which can be represented by
the vector
ub = inf*ones(1, numAssets + 1 + numObservations).
The lower bounds are different for the different parts of the decision
variable vector x. The weights are unrestricted in this case, and so is the aux-
iliary variable ξ. However, the variables y are restricted to be nonnegative.
Thus, the vector of lower bounds lb is a concatenation of three different
vectors:
lb = [-inf*ones(numAssets,1); -inf;
zeros(numObservations,1)]
The last three lines of the CVaR optimization code call the MATLAB
linear optimization solver, and print the relevant results. The optimal weights
for the different assets in the portfolio are retrieved as the ﬁrst N entries of
the optimal vector x, and the value of the portfolio CVaR is the optimal
value of the objective function, fval.
NOTES
1. The CAPM is discussed in Chapter 11.
2. |.| is simply the standard notation for absolute value.
3. See section 5.2.2 of Chapter 5.
4. See section 3.6.1 of Chapter 3 for a brief deﬁnition of the moments of a proba-
bility distribution.
5. See sections 3.6.1 and 3.6.2 of Chapter 3 for an introduction to the notation in
these expressions. Section 3.6.1 introduced brieﬂy the concept of moments of a
probability distribution.
6. See Roy (1952).
7. Note that the difference Vt – Vt+1 is a positive number if there is a loss, and a
negative number if there is a proﬁt.
8. A benchmark is a hypothetical portfolio of assets that functions as a performance
standard against which portfolio management is measured. See Siegel (2003)
for a review of benchmarks and their uses.

Advances in the Theory of Portfolio Risk Measures
319
9. See Chapter 2 for a deﬁnition of geometric returns.
10. See section 3.4 of Chapter 3 for a deﬁnition of the standard normal distribution,
section 3.11.2 for the use of a similar notation of percentile in the context
of conﬁdence interval estimation, and section 6.2.3 of Chapter 6 for use in
stochastic programming.
11. As explained in section 6.2.3 of Chapter 6, the notation ⌊a⌋stands for the
integer part of the number a, i.e., for the nearest integer less than or equal to a.
12. Note that the value for the VaR computed with the described method of sorting
the data ﬁrst may be different from the value returned by the commands for
computing percentiles in Excel (PERCENTILE) or MATLAB (prctile). While
for continuous data, the value of the percentile is the value of the VaR, for
discrete data, conventions for computing VaR may vary. The approach for esti-
mation of VaR from discrete data described in this chapter picks a conservative
estimate of VaR—it considers the value of the smallest loss that is greater than
the value for the percentile.
13. See section 3.11.3 of Chapter 3 for an introduction to the bootstrapping
technique.
14. See section 3.11.3 of Chapter 3 and Practice 4.3 on the companion web site for
an illustration of the technique for estimating the accuracy of the VaR estimate.
15. See Chapter 4 in Dowd (2005).
16. Some software packages have functions for ﬁtting probability distributions to
data. For example, in @RISK one can request the software to suggest a list of
distributions that ﬁt the data most closely, in order of relevance. See section
4.1.1 of Chapter 4 and section 3.11.4 of Chapter 3.
17. A quick liquidation of positions may have an effect on the current market prices
of the different securities, which will change the estimate of the VaR. Therefore,
the estimation of VaR is done assuming that markets behave as usual, that is,
positions are liquidated in an orderly fashion.
18. Today, the G-10 countries actually include 11 industrial countries. They are
Belgium, Canada, France, Germany, Italy, Japan, the Netherlands, Sweden,
Switzerland, the United Kingdom, and the United States.
19. See Chapter 7.
20. See section 6.2.3 of Chapter 6.
21. See section 5.4.3 of Chapter 5.
22. See section 6.2.3 of Chapter 6.
23. See Chapter 2 for a deﬁnition of zero-coupon bond.
24. The latter fact can be proved more formally; see, for example, Rockafellar and
Uryasev (2002).
25. See practice problem Practice 8.4 on the companion web site for a derivation of
this expression.
26. See section 6.2 of Chapter 6 for an introduction to stochastic programming.
27. The 100(1 −ε)% VaR is a minimizer of the function F1−ε(w, ξ). In other
words, in some cases the value of ξ that results in the minimum of the function
F1−ε(w, ξ) will in fact be the 100(1 −ε)% VaR, and so VaR will be computed
as a by-product of computing CVaR. However, there is additional nontrivial

320
PORTFOLIO OPTIMIZATION AND RISK MEASURES
amount of work involved in verifying that the value of ξ obtained in the opti-
mization is indeed the 100(1 −ε)% VaR, and hence it cannot be assumed that
CVaR optimization would provide a computationally efﬁcient way of comput-
ing VaR. (For more details, see Rockafellar and Uryasev [2000].) Still, knowing
that CVaR minimization implies VaR minimization is useful when making port-
folio allocation decisions (rather than computing the actual value of VaR).
28. See TOMLAB Optimization, The TOMLAB Optimization Environment,
http://tomopt.com/tomlab/.
29. Robust Optimization, ROME, ROME is currently being developed at the
National University of Singapore Business School. See Robust Optimization,
ROME, http://robustopt.com/resources.html.
30. The identity matrix is an array with 1s in the diagonal, and 0s everywhere else.

CHAPTER9
Equity Portfolio Selection
in Practice
A
s we saw in Chapters 7 and 8, quantitative investment management can
be formulated as a question of determining a probability distribution of
portfolio returns and engineering the optimal trade-off between risk and re-
turn as a function of individual preferences. From a statistical point of view,
a key innovation is the attention paid to the ratio between the bulk of the risk
and the risk in the tails. However, for many quantitative asset management
ﬁrms the starting point for portfolio allocation models is still the mean-
variance framework introduced in Chapter 7. Practitioners have customized
the framework to include practical approaches for parameter estimation
through factor models (which are covered in Chapter 11), considerations
for transaction costs and taxes, and other constraints, such as maximum
exposure to an industry, or maximum tracking error relative to an index.
In investment management, an important decision is the allocation of
funds among asset classes. The funds are then managed within the asset
classes. As explained in Chapter 2, the two major asset classes are equi-
ties and ﬁxed income securities. Equity portfolio management differs from
ﬁxed income portfolio management in substantive ways, and ﬁxed income
portfolio management is discussed separately in Chapter 10. Regardless of
the asset class being managed, however, the investment process follows the
same integrated activities. These activities can be deﬁned as follows:1
■An investor’s objectives, preferences, and constraints are identiﬁed and
speciﬁed to develop explicit investment policies.
■Strategies are developed and implemented through the choice of optimal
combinations of ﬁnancial and real assets in the marketplace.
■Market conditions, relative asset values, and the investor’s circum-
stances are monitored.
■Portfolio adjustments are made as appropriate to reﬂect signiﬁcant
changes in any or all of the relevant variables.
321

322
PORTFOLIO OPTIMIZATION AND RISK MEASURES
It is important to note that banks and ﬁnancial entities engage in ﬁnan-
cial operations other than pure investing. Many of these operations are prof-
itable but risky, and their risk must be managed or eliminated. This is accom-
plished by utilizing ﬁnancial instruments that allow ﬁrms to transfer the risk
to the market, rather than keeping it on their balance sheets. Such strategies
are discussed in a more comprehensive portfolio risk management context
in Chapter 16, after introducing ﬁnancial derivatives in Chapters 13 and 14.
In this chapter, we focus on the second activity of the investment process,
developing and implementing a portfolio strategy. We introduce quantitative
formulations of portfolio allocation problems widely used in equity portfolio
management. Quantitative equity portfolio selection often involves extend-
ing the classical Markowitz framework (Chapter 7) or the more advanced
tail-risk portfolio allocation frameworks (Chapter 8) to include different
constraints that take speciﬁc investment guidelines and institutional features
into account.
We begin by discussing the activities involved in the investment process
in more detail, so that we can provide context for the rest of the discussion.
We then provide a classiﬁcation of the most common portfolio constraints
used in practice, and discuss extensions such as index tracking formulations,
the inclusion of transaction costs, optimization of trades across multiple
client accounts, tax-aware strategies, and incorporating robustness in port-
folio allocation procedures by using robust statistics, simulation, and robust
optimization techniques.
9.1
THE INVESTMENT PROCESS
As outlined in the introduction to this chapter, portfolio management in
practice consists of four activities, which can be summarized as follows:2
1. Setting the investment objectives.
2. Developing and implementing a portfolio strategy.
3. Monitoring the portfolio.
4. Adjusting the portfolio.
This section discusses each of these activities in more detail.
9.1.1
Setting Investment Objectives
Investment objectives vary by the type of ﬁnancial institutions, and are
essentially dictated by the nature of an institution’s liabilities. For banks,
the objective is to earn a return on invested funds that is higher than the cost
of acquiring those funds. For deﬁned beneﬁt pension plans, the investment

Equity Portfolio Selection in Practice
323
objective is to generate sufﬁcient cash ﬂow from the investment portfolio to
satisfy the plan’s pension obligations. Life insurance companies sell a variety
of products guaranteeing a dollar payment or a stream of dollar payments at
some time in the future. They charge policyholders premiums that depend on
the interest rate the company can earn on its investments. To realize a proﬁt,
the company must earn a higher return on the premium it invests than the
implicit (or explicit) interest rate it has guaranteed policyholders. Finally, for
regulated investment companies (i.e., mutual funds and closed-end funds),
hedge funds, and managed accounts by trust departments, the main objective
of portfolio selection is often to maximize expected returns at a certain level
of risk. The target return and risk level can be deﬁned as absolute, or relative
to a benchmark, where a benchmark is a collection of securities against
which the portfolio manager’s performance can be evaluated.
We can therefore divide investors into two general categories based on
the characteristics of their benchmark. The ﬁrst category of investor spec-
iﬁes the benchmark as a function of its liability structure. The investment
objective is to generate a cash ﬂow from their portfolio that, at a minimum,
satisﬁes the liability structure. This is often referred to as asset-liability man-
agement. The second category of investor speciﬁes the benchmark as a target
level of return, or as an index such the S&P 500 or the Russell 1000. The
investment objective is then to outperform the target. In this chapter, we will
focus on investors in the second category, but provide some background on
ﬁxed income liability-driven portfolio management in Chapter 10.
9.1.2
Developing and Implementing
a Portfolio Strategy
Typically, an investment policy is developed by the investor in conjunction
with a consultant. Given the investment policy, investment guidelines are
established for individual managers hired by the investor. The portfolio al-
location among different asset classes (bonds, stocks, etc.) is usually decided
in advance, and then each portfolio manager is hired to manage a speciﬁc
asset class, or a subset of an asset class. In this chapter as well as Chapter 10,
we discuss the actual implementation of portfolio strategies for two speciﬁc
asset classes—equities and ﬁxed income securities.
The implementation of the portfolio strategy can be divided into the
following tasks:
■Selecting the type of investment strategy.
■Formulating the inputs for portfolio construction.
■Constructing the portfolio.
We explain each task next.

324
PORTFOLIO OPTIMIZATION AND RISK MEASURES
Selecting the Type of Investment Strategy
In the broadest terms, portfo-
lio strategies can be classiﬁed either as active strategies or passive strategies.
Active strategies utilize information provided by manager intuition or quan-
titative risk factor models3 to come up with strategies that select the most
attractive investment opportunities in the portfolio manager’s opinion. Pas-
sive strategies require minimal management. One popular type of passive
strategy is indexing, whose objective is to replicate the performance of a
designated equity market index. Quantitative formulations of the portfolio
indexing problem are discussed in section 9.3.
Formulating the Inputs for Portfolio Construction
Formulating the inputs
for portfolio construction in an active quantitative portfolio strategy involves
forecasting the inputs that are expected to impact the performance of a
security and the portfolio as a whole. In the case of mean-variance analysis,
for example, of interest are the factors that determine the expected returns
of the assets in the portfolio and the covariance structure of the portfolio.
Some of these inputs are extrapolated from past market data, others reﬂect
the market’s “expectations” that are priced into observed security prices
in the market today.4 In the end, quantitatively generated forecasts are
combined with the manager’s subjective evaluation to form the inputs to the
portfolio allocation framework.
Constructing the Portfolio
Given the manager’s forecasts and the market-
derived information, the manager identiﬁes attractive investments, and as-
sembles the portfolio. The exact portfolio allocation can be determined
based on the optimization problem formulations introduced later in this
chapter, but the ultimate decision is made after careful human evaluation of
the portfolio strategy.
9.1.3
Monitoring the Portfolio
Once the portfolio has been constructed, it must be monitored. Monitor-
ing involves two activities. The ﬁrst is to assess whether there have been
changes in the market that might suggest that any of the key inputs used in
constructing the portfolio may not be realized. The second task is to monitor
the performance of the portfolio.
The portfolio performance is monitored in two phases. The ﬁrst phase is
performance measurement, which involves the calculation of the return re-
alized by the manager over a speciﬁed time interval (the evaluation period).
The second phase is performance evaluation, which determines whether the
manager has added value, and how the manager achieved the observed re-
turn. The decomposition of the performance results to explain why those

Equity Portfolio Selection in Practice
325
results were achieved is called return attribution analysis. Performance eval-
uation is discussed in more detail in Chapter 11.
9.1.4
Adjusting the Portfolio
Investment management is an ongoing process, and portfolio strategies are
in fact performed in a multiperiod context. Portfolio selection strategies
are designed to take advantage of market conditions, but those conditions
exist temporarily, and as the conditions change, the portfolio manager must
perform portfolio rebalancing. In doing so, the portfolio manager typically
takes the steps discussed in the following sections.
By monitoring developments in the capital market, the portfolio man-
ager determines whether to revise the inputs used in the portfolio construc-
tion process. Based on the new inputs, the manager then constructs a new
portfolio. In constructing a new portfolio, the costs of trading are often
evaluated against the beneﬁts of rebalancing. Such costs include transaction
costs and taxes, and are discussed in more detail in sections 9.4 and 9.5.
9.2
PORTFOLIO CONSTRAINTS COMMONLY
USED IN PRACTICE
Institutional features and investment policy speciﬁcations often lead to more
complicated requirements than simple minimization of risk (whatever the
deﬁnition of risk may be) or maximization of expected portfolio return.
For example, as we mentioned earlier, there can be constraints that limit
the number of trades, the exposure to a speciﬁc industry, or the number
of stocks to be kept in the portfolio. Some of these constraints are im-
posed by the clients, while others are imposed by regulators. For example,
in the case of regulated investment companies, restrictions on asset allo-
cation are set forth in the prospectus and may be changed only with the
approval of the fund’s board of directors. Pension funds must comply with
Employee Retirement Income Security Act (ERISA) requirements.5 The ob-
jective of the portfolio optimization problem can also be modiﬁed to con-
sider speciﬁcally the trade-off between risk and return, transactions costs,
or taxes.
In this section, we will take a single-period view of investing, in the sense
that the goal of the portfolio allocation procedure will be to invest optimally
over a single predetermined period of interest, such as one month.6 We will
use w0 to denote the vector array of stock weights in the portfolio at the
beginning of the period, and w to denote the weights at the end of the period
(to be determined).

326
PORTFOLIO OPTIMIZATION AND RISK MEASURES
Many investment companies, especially institutional investors, have a
long investment horizon. However, in reality, they treat that horizon as a
sequence of shorter period horizons. Risk budgets are often stated over a time
period of a year, and return performance is monitored quarterly or monthly.
9.2.1
Long-Only (No-Short-Selling) Constraints
Many funds and institutional investors face restrictions or outright prohi-
bitions on the amount of short selling they can do. When short selling is
not allowed, the portfolio allocation optimization model contains the con-
straints w ≥0.
9.2.2
Holding Constraints
Diversiﬁcation principles argue against investing a large proportion of the
portfolio in a single asset, or having a large concentration of assets in a
speciﬁc industry, sector, or country. Limits on the holdings of a speciﬁc
stock can be imposed with the constraints
l ≤w ≤u
where l and u are vectors of lower and upper bounds of the holdings of each
stock in the portfolio.
Consider now a portfolio of 10 stocks. Suppose that the issuers of assets
1, 3, and 5 are in the same industry, and that we would like to limit the
portfolio exposure to that industry to be at least 20% but at most 40%. To
limit exposure to that industry, we add the constraint
0.20 ≤w1 + w3 + w5 ≤0.40
to the portfolio allocation optimization problem.
More generally, if we have a speciﬁc set of stocks Ij out of the investment
universe I consisting of stocks in the same category (such as industry or
country), we can write the constraint
Lj ≤

j∈Ij
w j ≤Uj
In words, this constraint requires that the sum of all stock weights in
the particular category of investments with indices Ij is greater than or equal
to a lower bound Lj and less than a maximum exposure of Uj.

Equity Portfolio Selection in Practice
327
9.2.3
Turnover Constraints
High portfolio turnover can result in large transaction costs that make port-
folio rebalancing inefﬁcient and costly. Thus, some portfolio managers limit
the amount of turnover allowed when trading their portfolio. (Another way
to control for transaction costs is to minimize them explicitly, and the ap-
propriate formulations are discussed later in this chapter.)
Most commonly, turnover constraints are imposed for each stock:
|wi −w0,i| ≤ui
that is, the absolute magnitude of the difference between the ﬁnal and the
initial weight of stock i in the portfolio is restricted to be less than some
upper bound ui. Sometimes, a constraint is imposed to minimize the portfolio
turnover as a whole:

j∈Ij
|w j −w0, j| ≤Uj
that is, the total absolute difference between the initial and the ﬁnal weights
of the stocks in the portfolio is restricted to be less than or equal to an upper
bound Ui. Under this constraint, some stock weights may deviate a lot more
than others from their initial weights, but the total deviation is limited.
Turnover constraints are often imposed relative to the average daily vol-
ume (ADV) of a stock.7 For example, we may want to restrict turnover to be
no more than 5% of the ADV. (In the latter case, the upper bound ui is set to
a value equal to 5% of the ADV.) Modiﬁcations of these constraints, such as
limiting turnover in a speciﬁc industry or sector, are also frequently applied.
9.2.4
Risk Factor Constraints
In practice, it is very common for quantitatively oriented portfolio managers
to use factor models to control for risk exposures to different risk factors.
Such risk factors could include the market return, size, and style.8 Let us
assume that the return on stock i has a factor structure with K risk factors,
that is, can be expressed through the equality
ri = αi +
K

k=1
βik · fk + εi
The factors fk are common to all securities. The coefﬁcient βik in front
of each factor fk shows the sensitivity of the return on stock i to factor k. The

328
PORTFOLIO OPTIMIZATION AND RISK MEASURES
value of αi shows the expected excess return of the return on stock i, and εi is
the idiosyncratic (called nonsystematic) part of the return of stock i. The co-
efﬁcients αi and βik are typically estimated by multiple regression analysis.9
To limit the exposure of a portfolio of N stocks to the kth risk factor,
we impose the constraint
N

i=1
βik · wi ≤Uk.
The mathematics behind risk factor models will become more intuitive
in Chapter 11, but this constraint formulation is easy to understand at this
stage as well. The total return on the portfolio can be written as
N

i=1
wi · ri =
N

i=1
wi ·

αi +
K

k=1
βik · fk + εi

=
N

i=1
wi · αi +
N

i=1

wi ·
 K

k=1
βik · fk

+
N

i=1
wi · εi.
The sensitivity of the portfolio to the different factors is represented by
the second term, which can also be written as
K

k=1
 N

i=1
wi · βik

· fk

.
Therefore, the exposure to a particular factor k is the coefﬁcient in front
of fk, that is,
N

i=1
βik · wi.
On an intuitive level, the sensitivity of the portfolio to a factor k will
be larger the larger the presence of factor k in the portfolio through the
exposure of the individual stocks. Thus, when we compute the total exposure
of the portfolio to factor k, we need to take into consideration both how
important this factor is for determining the return on each of the securities
in the portfolio, and how much of each security we have in the portfolio.
A commonly used version of the maximum factor exposure constraint is
N

i=1
βik · wi = 0.

Equity Portfolio Selection in Practice
329
This constraint forces the portfolio optimization algorithm to ﬁnd port-
folio weights so that the overall risk exposure to factor k is 0, that is, so
that the portfolio is neutral with respect to changes in factor k. Portfolio
allocation strategies that claim to be “market-neutral” typically employ this
constraint, and the factor is in fact the return on the market.
9.2.5
Cardinality Constraints
Depending on the portfolio allocation model used, sometimes the optimiza-
tion subroutine recommends holding small amounts of a large number of
stocks, which can be costly when one takes into consideration the transac-
tion costs incurred when acquiring these positions. Alternatively, a portfolio
manager may be interested in limiting the number of stocks used to track
a particular index. (Index tracking is discussed in section 9.3.) Mathemati-
cally, modeling the constraint of a limited number of stocks to be held in the
portfolio is actually very similar to modeling the number of projects to be
selected in the capital budgeting example discussed in section 5.3.3 of Chap-
ter 5. To formulate the constraint on the number of stocks to be held in the
portfolio (called cardinality constraint), we introduce binary variables, one
for each of the N stocks in the portfolio. Let us call these binary variables
δ1, . . . , δN. Variable δi will take value 1 if stock i is included in the portfolio,
and 0 otherwise.
Suppose that out of the N stocks in the investment universe, we would
like to include a maximum of K stocks in the ﬁnal portfolio. K here is a
positive integer, and is less than N. This constraint can be formulated as
N

i=1
δi ≤K
δi binary, i = 1, . . . , N.
We need to make sure, however, that if an stock is not selected in the
portfolio, then the binary variable that corresponds to that stock is set to 0,
so that the stock is not counted as one of the K stocks left in the portfolio.
When the portfolio weights are restricted to be nonnegative, this can be
achieved by imposing the additional constraints
0 ≤wi ≤δi, i = 1, . . . , N.
If the optimal weight for stock i turns out to be different from 0, then the
binary variable δi associated with stock i is forced to take value 1, and stock
i will be counted as one of the K stocks to be kept in the portfolio. If the opti-
mal weight for stock i is 0, then the binary variable δi associated with stock i
can be either 0 or 1, but that will not matter for all practical purposes because

330
PORTFOLIO OPTIMIZATION AND RISK MEASURES
the solver will set it to 0 if there are too many other attractive stocks that will
be counted as the K stocks to be kept in the portfolio. At the same time, since
the portfolio weights wi are between 0 and 1, and δi is 0 or 1, the constraint
wi ≤δi does not restrict the values that the stock weight wi can take.
The constraints are a little different if short sales are allowed, in which
case the weights may be negative. We have
−M · δi ≤wi ≤M · δi, i = 1, . . . , N,
where M is a “large” constant (large relative to the size of the inputs in
the problem; so in this portfolio optimization application M = 10 can be
considered “large”). You can observe that if the weight wi is anything but
0, the value of the binary variable δi will be forced to be different from 0,
that is, δi will need to be 1, since it can only take values 0 or 1.
9.2.6
Minimum Holding and Transaction
Size Constraints
Cardinality constraints are often used in conjunction with minimum hold-
ing/trading constraints. The latter set a minimum limit on the amount of a
stock that can be held in the portfolio, or the amount of a stock that can be
traded, effectively eliminating small trades. Both cardinality and minimum
holding/trading constraints aim to reduce the amount of transaction costs.
Threshold constraints on the amount of stock i to be held in the portfolio
can be imposed with the constraint
|wi| ≥Li · δi
where Li is the smallest holding size allowed for stock i, and δi is a bi-
nary variable, analogous to the binary variables δi deﬁned in the previous
section—it equals 1 if stock i is included in the portfolio, and 0 otherwise.
(All additional constraints relating to δi and wi described in the previous
section still apply.)
Similarly, constraints can be imposed on the minimum trading amount
for stock i. As we explained earlier in this section, the size of the trade
for stock i is determined by the absolute value of the difference between the
current weight of the stock, w0,i, and the new weight wi that will be found by
the solver: |wi −w0,i|. The minimum trading size constraint formulation is
|wi −w0,i| ≥Ltrade
i
· δi
where Ltrade
i
is the smallest trading size allowed for stock i.

Equity Portfolio Selection in Practice
331
As we explained in section 5.2.5 of Chapter 5, adding binary variables
to an optimization problem makes the problem more difﬁcult for the solver,
and can increase the computation time substantially. That is why in prac-
tice, portfolio managers often omit minimum holding and transaction size
constraints from the optimization problem formulation, electing instead to
eliminate weights and trades that appear too small manually, after the op-
timal portfolio is determined by the optimization solver. It is important to
realize, however, that modifying the optimal solution for the simpler portfo-
lio allocation problem (the optimal solution in this case is the weights/trades
for the different stocks) by eliminating small positions manually does not
necessarily produce the optimal solution to an optimization problem that
contained the minimum holding and transaction size constraints from the
beginning. In fact, there can be pathological cases in which the solution is
very different from the true optimal solution. However, for most cases in
practice, the small manual adjustments to the optimal portfolio allocation
do not cause tremendous discrepancies or inconsistencies.
9.2.7
Round Lot Constraints
So far, we have assumed that stocks are inﬁnitely divisible, that is, that we
can trade and invest in fractions of stocks, bonds, and the like. This is, of
course, not true—in reality, securities are traded in multiples of minimum
transaction lots, or rounds (e.g., 100 or 500 shares).
In order to represent the condition that securities should be traded in
rounds, we need to introduce additional decision variables (let us call them
zi, i = 1, . . . , N) that are integer and will correspond to the number of lots
of a particular security that will be purchased. Each zi will then be linked to
the corresponding portfolio weight wi through the equality
wi = zi · fi, i = 1, . . . , N
where fi is measured in dollars, and is a fraction of the total amount to
be invested. For example, suppose there are a total of $100 million to be
invested, and stock i trades at $50 in round lots of 100. Then
fi =
50 · 100
100,000,000 = 5 · 10−7.
All remaining constraints in the portfolio allocation can be expressed
through the weights wi, as usual. However, we also need to specify for the
solver that the decision variables zi are integer.

332
PORTFOLIO OPTIMIZATION AND RISK MEASURES
An issue with imposing round lot constraints is that the budget con-
straint
w′ι = 1,
which is in fact
N

i=1
zi · fi = 1,
may not be satisﬁed exactly. To understand this better, recall the capital
budgeting example from section 5.3.3, which illustrated a similar situation
in a different context—when projects with different budgets were added
up without the ability to adjust their budgets up or down, they did not
necessarily use the entire available budget (or could end up over budget).
One possibility to handle this problem is to relax the budget constraint.
For example, we can state the constraint as
w′ι ≤1,
or, equivalently,
N

i=1
zi · fi ≤1.
This will ensure that we do not go over budget.
If our objective is stated as expected return maximization, the optimiza-
tion solver will attempt to make this constraint as tight as possible, that is,
we will end up using up as much of the budget as we can. Depending on the
objective function and the other constraints in the formulation, however,
this may not always happen. We can try to force the solver to minimize the
slack in the budget constraint by introducing a pair of nonnegative decision
variables (let us call them ε+ and ε−) that account for the amount that is
“overinvested” or “underinvested.” These variables will pick up the slack
left over because of the inability to round the amounts for the different
investments. Namely, we impose the constraints
N

i=1
zi · fi + ε−−ε+ = 1
ε−≥0, ε+ ≥0

Equity Portfolio Selection in Practice
333
and subtract the following term from the objective function,
λrl · (ε−+ ε+),
where λrl is a penalty term associated with the amount of over- or un-
derinvestment the portfolio manager is willing to tolerate (selected by the
portfolio manager). In the ﬁnal solution, the violation of the budget con-
straint will be minimized. Note, however, that this formulation technically
allows for the budget to be overinvested.
Note that the optimal portfolio allocation we obtain after solving this
optimization problem will not be the same as the allocation we would obtain
if we solve an optimization problem without round lot constraints, and then
round the amounts to ﬁt the lots that can be traded in the market.
Cardinality constraints, minimum holding/trading constraints, and es-
pecially round lot constraints, require more sophisticated binary and integer
programming solvers, and are difﬁcult problems to solve in the case of large
portfolios.
9.3
BENCHMARK EXPOSURE AND TRACKING
ERROR MINIMIZATION
Expected portfolio return maximization under the mean-variance frame-
work or other risk measure minimization are examples of active investment
strategies, that is, strategies that identify a universe of attractive investments,
and ignore inferior investments opportunities. As we explained in section
9.1.2, a different approach, referred to as a passive investment strategy, ar-
gues that in the absence of any superior forecasting ability, investors might
as well resign themselves to the fact that they cannot beat the market. From
a theoretical perspective, the analytics of portfolio theory tell them to hold
a broadly diversiﬁed portfolio anyway. Many mutual funds are managed
relative to a particular benchmark or stock universe, such as the S&P 500
or the Russell 1000. The portfolio allocation models are then formulated in
such a way that the tracking error relative to the benchmark is kept small.
9.3.1
Standard Definition of Tracking Error
To incorporate a passive investment strategy, we can change the objective
function of the portfolio allocation problem so that instead of minimizing
a portfolio risk measure, we minimize the tracking error with respect to a
benchmark that represents the market, such as the Russell 3000, or the S&P
500. Such strategies are often referred to as indexing. The tracking error

334
PORTFOLIO OPTIMIZATION AND RISK MEASURES
can be deﬁned in different ways. However, practitioners typically mean a
speciﬁc deﬁnition: the variance (or standard deviation) of the difference
between the portfolio return, w′˜r, and the return on the benchmark, wb′˜r.
Mathematically, the tracking error (TE) can be expressed as
TE = Var(w′˜r −wb
′˜r)
= Var

(w −wb)′˜r

= (w −wb)′Var (˜r) (w −wb)
= (w −wb)′(w −wb)
where  is the covariance matrix of the stock returns. You can observe
that the formula is very similar to the formula for the portfolio variance we
derived in Chapter 7; however, the portfolio weights in the formula from
Chapter 7 are replaced by differences between the weights of the stocks in
the portfolio and the weights of the stocks in the index.
A question that may be on some readers’ minds is why we need to opti-
mize portfolio weights in order to track a benchmark, when technically the
most effective way to track a benchmark is by investing the portfolio in the
stocks in the benchmark portfolio in the same proportions as the propor-
tions of these securities in the benchmark. The problem with this approach
is that, especially with large benchmarks such as the Russell 3000, the trans-
action costs of a proportional investment and the subsequent rebalancing
of the portfolio can be prohibitive (i.e., dramatically adversely impact the
performance of the portfolio relative to the benchmark). Furthermore, in
practice, securities are not inﬁnitely divisible, so investing a portfolio of a
limited size in the same proportions as the composition of the benchmark
will still not achieve zero tracking error. Thus, the optimal formulation is to
require that the portfolio follows the benchmark as closely as possible.
While indexing has become an essential part of many portfolio strate-
gies, most portfolio managers cannot resist the temptation to identify at
least some securities that will outperform others. Hence, restrictions on the
tracking error are often imposed as a constraint, while the objective function
is something different than minimizing the tracking error. The tracking error
constraint takes the form
(w −wb)′(w −wb) ≤σ 2
TE
where σ 2
TE is a limit (imposed by the investor) on the amount of tracking
error the investor is willing to tolerate. This is a quadratic constraint,
which is convex and computationally tractable, but requires specialized
optimization software.

Equity Portfolio Selection in Practice
335
9.3.2
Alternative Ways of Defining Tracking Error
There are alternative ways in which tracking-error type constraints can be
imposed.
For example, we may require that the absolute deviations of the portfolio
weights (w) from the index weights (wb) are less than or equal to a given
vector array of upper bounds u:
|w −wb| ≤u
where the absolute values |.| for the vector differences are taken component-
wise, that is, for pairs of corresponding elements from the two vector arrays.
These constraints can be stated as linear constraints by rewriting them as
w −wb ≤u
−(w −wb) ≤u.
Similarly, we can require that for stocks within a speciﬁc industry (whose
indices in the portfolio belong to a subset Ij of the investment universe I),
the total tracking error is less than a given upper bound Uj:

j∈Ij
(w j −wb, j) ≤Uj.
Finally, tracking error can be expressed through risk measures other
than the absolute deviations or the variance of the deviations from the
benchmark. Rockafellar and Uryasev (2002) suggest using CVaR10 to man-
age the tracking error. (As we know from Chapter 8, CVaR is a computa-
tionally tractable risk measure as long as the data are presented in the form
of scenarios.11 ) We provide below a formulation that is somewhat different
from Rockafellar and Uryasev (2002), but preserves the main idea.
Suppose that we are given S scenarios for the return of a benchmark
portfolio (or an instrument we are trying to replicate), bs, s = 1, . . . , S.
These scenarios can be generated by simulation, or taken from historical
data. We also have N stocks with returns r(s)
i (i = 1, . . . , N, s = 1, . . . , S) in
each scenario. The value of the portfolio in scenario s is
N

i=1
r(s)
i
· wi,
or, equivalently, (r(s))′w, where r(s) is the vector of returns for the N stocks
in scenario s. Consider the differences between the return on the benchmark
and the return on the portfolio,
bs −(r(s))′w = −((r(s))′w −bs).

336
PORTFOLIO OPTIMIZATION AND RISK MEASURES
If this difference is positive, we have a loss; if the difference is negative,
we have a gain; both gains and losses are computed relative to the bench-
mark. Rationally, the portfolio manager should not worry about differences
that are negative; the only cause for concern would be if the portfolio under-
performs the benchmark, which would result in a positive difference. Thus,
it is not necessarily to limit the variance of the deviations of the portfolio
returns from the benchmark, which penalizes for positive and negative de-
viations equally. Instead, we can treat these differences in the same way as
we treated absolute portfolio losses in section 8.3 of Chapter 8, and impose
a limit on the amount of loss we are willing to tolerate in terms of the CVaR
of the distribution of losses relative to the benchmark.
From the formulation of the CVaR optimization problem from section
8.3, it is easy to see that the tracking error constraint in terms of the CVaR
can be stated as the following set of constraints:
ξ +
1
⌊ε · S⌋·
S

s=1
ys ≤UTE
ys ≥−

(r(s))′w −bs

−ξ,
s = 1, . . . , S
ys ≥0, s = 1, . . . , S
where UTE is the upper bound on the negative deviations.
This formulation of tracking error is appealing in two ways. First, it
treats positive and negative deviations relative to the benchmark differently,
which agrees with the strategy of an investor seeking to maximize returns
overall. Second, it results in a linear set of constraints, which are easy to
handle computationally, in contrast to the ﬁrst formulation of the tracking
error constraint in this section, which results in a quadratic constraint.
9.3.3
Actual vs. Predicted Tracking Error
The tracking error calculation in practice is often backward-looking. For
example, in computing the covariance matrix  in the standard tracking
error deﬁnition in section 9.3.1, or in selecting the scenarios used in the
CVaR-type tracking error constraint in section 9.3.2, we may use historical
data. The tracking error calculated in this manner is called the ex post
tracking error, backward-looking error, or actual tracking error.
The problem with using the actual tracking error for assessing future
performance relative to a benchmark is that the actual tracking error does
not reﬂect the effect of the portfolio manager’s current decisions on the
future active returns and hence the tracking error that may be realized in

Equity Portfolio Selection in Practice
337
the future. The actual tracking error has little predictive value and can be
misleading regarding portfolio risk.
Portfolio managers need forward-looking estimates of tracking error
to reﬂect future portfolio performance more accurately. In practice, this is
accomplished by using the services of a commercial vendor that has a multi-
factor risk model12 that has identiﬁed and deﬁned the risks associated with
the benchmark, or by building such a model in-house. Statistical analysis
of historical return data for the stocks in the benchmark are used to ob-
tain the risk factors and to quantify the risks. Using the manager’s current
portfolio holdings, the portfolio’s current exposure to the various risk fac-
tors can be calculated and compared to the benchmark’s exposures to the
risk factors. From the differential factor exposures and the risks of the fac-
tors, a forward-looking tracking error for the portfolio can be computed.
This tracking error is also referred to as ex ante tracking error or predicted
tracking error.
There is no guarantee that the predicted tracking error will match exactly
the tracking error realized over the future time period of interest. However,
this calculation of the tracking error has its use in risk control and portfolio
construction. By performing a simulation analysis on the factors that enter
the calculation, the manager can evaluate the potential performance of port-
folio strategies relative to the benchmark, and eliminate those that result
in tracking errors beyond the client-imposed tolerance for risk. The actual
tracking error, on the other hand, is useful for assessing actual performance
relative to a benchmark.
9.4
INCORPORATING TRANSACTION COSTS
Transaction costs can be generally divided into two categories: explicit (such
as bid-ask spreads, commissions and fees), and implicit (such as price move-
ment risk costs13 and market impact costs14).
The typical portfolio allocation models are built on top of one or several
forecasting models for expected returns and risk. Small changes in these
forecasts can result in reallocations that would not occur if transaction costs
are taken into account. In practice, the effect of transaction costs on portfolio
performance is far from insigniﬁcant. If transaction costs are not taken into
consideration in allocation and rebalancing decisions, they can lead to poor
portfolio performance.
This section describes some common transaction cost models for port-
folio rebalancing. We use the mean-variance framework as the basis for
describing the different approaches. However, it is straightforward to ex-
tend the transaction cost models into other portfolio allocation frameworks.

338
PORTFOLIO OPTIMIZATION AND RISK MEASURES
The earliest, and most widely used, model for transaction costs is the
mean-variance risk-aversion formulation with transaction costs.15 The op-
timization problem has the following objective function:
max
w
w′µ −λ · w′w −λTC · TC
where TC is a transaction cost penalty function, and λTC is the transaction
cost aversion parameter. In other words, the objective is to maximize the
expected portfolio return less the cost of risk and transaction costs. We can
imagine that as the transaction costs increase, at some point it becomes opti-
mal to keep the current portfolio rather than to rebalance. Variations of this
formulation exist. For example, it is common to maximize expected portfolio
return minus transaction costs, and impose limits on the risk as a constraint
(i.e., to move the second term in the objective function in the constraints).
Transaction costs models can involve complicated nonlinear functions.
Although software exists for general nonlinear optimization problems, the
computational time required for solving such problems is often too long
for realistic investment applications, and, as we explained in Chapter 5,
the quality of the solution is not guaranteed. In practice, an observed com-
plicated nonlinear transaction costs function is often approximated with a
computationally tractable function that is assumed to be separable in the
portfolio weights, that is, it is often assumed that the transaction costs for
each individual stock are independent of the transaction costs for another
stock. For the rest of this section, we will denote the individual cost function
for stock i by TCi.
Next, we explain several widely used models for the transaction cost
function.
9.4.1
Linear Transaction Costs
Let us start simple. Suppose that the transaction costs are proportional, that
is, they are a percentage ci of the transaction size |t| = |wi −w0,i|.16 Then, the
portfolio allocation problem with transaction costs can be written simply as
max
w
w′µ −λ · w′w −λTC ·
N

i=1
ci·|wi −w0,i|.
The problem can be made solver-friendly by replacing the absolute value
terms with new decision variables yi, and adding two sets of constraints.
Hence, we rewrite the objective function as
max
w,y
w′µ −λ · w′w −λTC ·
N

i=1
ci·yi

Equity Portfolio Selection in Practice
339
and add the constraints
yi ≥wi −w0,i,
yi ≥−(wi −w0,i).
This preserves the quadratic optimization problem formulation, a
formulation that can be passed to quadratic optimization solvers such as
Excel Solver and MATLAB’s quadprog function because the constraints
are linear expressions, and the objective function contains only linear and
quadratic terms.
In the optimal solution, the optimization solver will in fact set the value
for yi to |wi −w0,i|. This is because this is a maximization problem and yi oc-
curs with a negative sign in the objective function, so the solver will try to set
yi to the minimum value possible. That minimum value will be the maximum
of (wi −w0,i) or −(wi −w0,i), which is in fact the absolute value |wi −w0,i|.
9.4.2
Piecewise-Linear Transaction Costs
Taking the model in the previous section a step further, we can introduce
piecewise-linear approximations to transaction cost function models. This
kind of function is more realistic than the linear cost function, especially
for large trades. As the trading size increases, it becomes increasingly more
costly to trade because of the market impact of the trade.
An example of a piecewise-linear function of transaction costs for a
trade of size t of a particular security is illustrated in Exhibit 9.1. The
transaction cost function illustrated in the graph assumes that the rate of
increase of transaction costs (reﬂected in the slope of the function) changes
at certain threshold points. For example, it is smaller in the range 0 to 15%
of daily volume than in the range 15% to 40% of daily volume (or some
other trading volume index). Mathematically, the transaction cost function
in Exhibit 9.1 can be expressed as
TC(t) =
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
s1t,
s1(0.15 · Vol) + s2(t −0.15 · Vol),
s1(0.15 · Vol) + s2(0.25 · Vol)
+s3(t −0.40 · Vol),
0 ≤t ≤0.15 · Vol
0.15 · Vol ≤t ≤0.40 · Vol
0.40 · Vol ≤t ≤0.50 · Vol
where s1, s2, s3 are the slopes of the three linear segments on the graph.
(They are given data.)
To include piecewise-linear functions for transaction costs in the ob-
jective function of a mean-variance (or any general mean-risk) portfolio
optimization problem, we need to introduce new decision variables that
correspond to the number of pieces in the piecewise-linear approximation

340
PORTFOLIO OPTIMIZATION AND RISK MEASURES
Trade amount (t)
TC
0
0.50·Vol
0.40·Vol
0.15·Vol 
EXHIBIT 9.1
Example of modeling transaction costs (TC) as a piecewise-
linear function of trade size t.
of the transaction cost function (in this case, there are 3 linear segments, so
we introduce variables z1, z2, z3). We write the penalty term in the objective
function for an individual stock as17
λTC · (s1 · z1 + s2 · z2 + s3 · z3) .
If there are N stocks in the portfolio, the total transaction cost will be
the sum of the transaction costs for each individual stock, that is, the penalty
term that involves transaction costs in the objective function becomes
−λTC
N

i=1
(s1,i · z1,i + s2,i · z2,i + s3,i · z3,i).
In addition, we specify the following constraints on the new decision
variables:
0 ≤z1,i ≤0.15 · Voli
0 ≤z2,i ≤0.25 · Voli
0 ≤z3,i ≤0.10 · Voli
Note that because of the increasing slopes of the linear segments and
the goal of making that term as small as possible in the objective func-
tion, the optimizer will never set the decision variable corresponding to the

Equity Portfolio Selection in Practice
341
second segment, z2,i, to a number greater than 0 unless the decision variable
corresponding to the ﬁrst segment, z1,i, is at its upper bound. Similarly, the
optimizer would never set z3,i to a number greater than 0 unless both z1,i
and z2,i are at their upper bounds. So, this set of constraints allows us to
compute the amount of transaction costs incurred in the trading of stock i
as z1,i + z2,i + z3,i.
Of course, we also need to link the amount of transaction costs incurred
in the trading of stock i to the optimal portfolio allocation. This can be done
by adding a few more variables and constraints. We introduce variables yi,
one for each stock in the portfolio, that would represent the amount traded
(but not the direction of the trade), and would be nonnegative. Then, we
require that
yi = z1,i + z2,i + z3,i
for each stock i, and also that yi equals the change in the portfolio position
of stock i. The latter condition can be imposed by writing the constraint
yi =
wi −w0,i

where w0,i and wi are the initial and the ﬁnal amount of stock i in the
portfolio, respectively.18
Despite their apparent complexity, piecewise-linear approximations for
transaction costs are very solver-friendly, and save time (relative to nonlinear
models) in the actual portfolio optimization. Although modeling transaction
costs this way requires introducing new decision variables and constraints,
the increase in the dimension of the portfolio optimization problem does not
affect signiﬁcantly the running time or the performance of the optimization
software because the problem formulation is easy from a computational
perspective.
9.4.3
Quadratic Transaction Costs
The transaction cost function is often parameterized as a quadratic function
of the form
TCi(t) = ci · |t| + di · |t|2.
The coefﬁcients ci and di are calibrated from data, such as by ﬁtting a
quadratic function to an observed pattern of transaction costs realized for
trading a particular stock under normal conditions.19

342
PORTFOLIO OPTIMIZATION AND RISK MEASURES
Including this function in the objective function of the portfolio opti-
mization problem results in a quadratic program that can be solved with
widely available quadratic optimization software.
9.4.4
Fixed Transaction Costs
In some cases, we need to model ﬁxed transaction costs. Those are costs that
are incurred independently of the amount traded. To include such costs in
the portfolio optimization problem, we need to introduce binary variables
δ1, . . . , δN corresponding to each stock, where δi equals 0 if the amount
traded of stock i is 0, and 1 otherwise. The idea is similar to the idea we
used to model the requirement that only a given number of stocks can be
included in the portfolio.
Suppose the ﬁxed transaction cost is ai for stock i. Then, the transaction
cost function is
TCi = ai · δi
The objective function formulation is then
max
w,δ
w′µ −λ · w′w −λTC ·
N

i=1
ai·δi,
and we need to add the following constraints to make sure that the binary
variables are linked to the trades |wi −w0,i|:
|wi −w0,i| ≤M · δi, i = 1, . . . , N,
δi binary
where M is a “large” constant. When the trading size |wi −w0,i| is nonzero,
δi will be forced to be 1. When the trading size is 0, then δi can be either 0
or 1, but the optimizer will set it to 0, since it will try to make its value the
minimum possible in the objective function.
Of course, combinations of different trading cost models can be used
in practice. For example, if the trade involves both a ﬁxed and a variable
quadratic transaction cost, then we could use a transaction cost function of
the kind
TCi(t) = ai · δi + ci · |t| + di · |t|2.

Equity Portfolio Selection in Practice
343
The important thing to take away from this section is that when trans-
action costs are included in the portfolio rebalancing problem, the result
is a reduced amount of trading and rebalancing, and a different portfolio
allocation than the one that would be obtained if transaction costs are not
taken into consideration.
9.5
INCORPORATING TAXES
When stocks in a portfolio appreciate or depreciate in value, capital gains
(respectively, losses) accumulate. When stocks are sold, investors pay taxes
on the realized net capital gains. The taxes are computed as a percentage
of the difference between the current market value of the stocks and their
tax basis, where the tax basis is the price at which the stocks were bought
originally.20 The percentage is less for long-term capital gains (when stocks
have been held for more than a year) than it is for short-term capital gains
(when stocks have been held for less than a year).21 Since shares of the same
stock could have been bought at different points in time (in different lots),
selling one lot of the stock as opposed to another could incur a different
amount of tax. In addition to capital gains taxes, investors who are not
exempt from taxes owe taxes on the dividends paid on stocks in their port-
folios. Those dividends are historically taxed at a higher rate than capital
gains, and after 2010 will be taxed as income, that is, at the investor’s per-
sonal tax rate. The tax liability of a particular portfolio therefore depends
on the timing of the execution of trades, on the tax basis of the portfolio,
on the accumulated short-term and long-term capital gains, and on the tax
bracket of the investor.
Over two-thirds of marketable portfolio assets in the United States are
held by individuals, insurance, and holding companies who pay taxes on
their returns. (Exceptions are, for example, pension funds, which do not
pay taxes year-to-year.) Studies have indicated that taxes are the greatest
expense investors face—greater than commissions and investment manage-
ment fees. To gain some intuition about the effect of taxes on the income of
an investor over the investor’s lifetime, consider a portfolio that has a capi-
tal appreciation of 6.00% per year. After 30 years, $1,000 invested in that
portfolio will turn into $1,000 · (1 + 0.06)30 = $5,743.49. Now suppose
that the capital gains are realized each year, and a tax of 35% is paid on the
gains (the remainder is reinvested). After 30 years, $1,000 invested in the
portfolio will turn into $1,000 · (1 + (1 −0.35)·0.06)30 = $3,151.13, about
half of the amount without taxes even when the tax is about one-third of
the capital gains. In fact, in order to provide the same return as the portfolio
with no taxes, the portfolio with annual realized capital gains would need to

344
PORTFOLIO OPTIMIZATION AND RISK MEASURES
generate a capital appreciation of 9.23% per year! You can imagine that the
same logic would make benchmark tracking and performance measurement
very difﬁcult on an after-tax basis.
As investors have become more aware of the dramatic impact of taxes on
their returns, there is increasing pressure on portfolio managers to include
tax considerations in their portfolio rebalancing decisions and to report
after-tax performance. Consequently, the demand for computationally efﬁ-
cient and quantitatively rigorous methods for taking taxes into consideration
in portfolio allocation decisions has grown in recent years. The complexity
of the problem of incorporating taxes, however, is considerable, both from
a theoretical and practical perspective:
■The presence of tax liabilities changes the interpretation of even funda-
mental portfolio performance summary measures such as market value
and risk. Thus, well-established methods for evaluating portfolio per-
formance on a pretax basis do not work well in the case of tax-aware
portfolio optimization. For example, in traditional portfolio manage-
ment a loss is associated with risk, and is therefore minimized whenever
possible. However, in the presence of taxes, losses may be less dam-
aging because they can be used to offset capital gains and reduce the
tax burden of portfolio rebalancing strategies. Benchmarking is also not
obvious in the presence of taxes: two portfolios that have exactly the
same current holdings are not equivalent if the holdings have a different
tax basis.22
■Tax considerations are too complex to implement in a nonautomated
fashion; at the same time, their automatic inclusion in portfolio rebal-
ancing algorithms requires the ability to solve very difﬁcult, large-scale
optimization problems.
■The best approach for portfolio management with tax considerations
is optimization problem formulations that look at return forecasts
over several time periods (e.g., until the end of the year) before rec-
ommending new portfolio weights. However, the latter multiperiod
view of the portfolio optimization problem is very difﬁcult to handle
computationally—the dimension of the optimization problem, that is,
the number of variables and constraints, increases exponentially with
the number of time periods under considerations.
We need to emphasize that while many of the techniques described
in the previous sections of this chapter are widely known, there are no
standard practices for tax-aware portfolio management that appear to be
established. Different asset management ﬁrms interpret tax-aware portfolio

Equity Portfolio Selection in Practice
345
allocation and approach the problem differently. To some ﬁrms, minimiz-
ing turnover,23 such as by investing in index funds, or selecting strategies
that minimize the portfolio dividend yield24 qualify as tax-aware portfo-
lio strategies. Other asset management ﬁrms employ complex optimization
algorithms that incorporate tax considerations directly in portfolio rebal-
ancing decisions, so that they can keep up with the considerable burden of
keeping track of thousands of managed accounts and their tax preferences.
The fact is, even using simple rules of thumb, such as always selling stocks
from the oldest lots after rebalancing the portfolio with classical portfolio
optimization routines, can have a positive effect on after-tax portfolio re-
turns. The latter strategy minimizes the likelihood that short-term gains will
be incurred, which in turn reduces taxes because short-term capital gains
are taxed at a higher rate than long-term capital gains.
Apelfeld, Fowler, and Gordon (1996) suggested a tax-aware portfolio
rebalancing framework that incorporates taxes directly into the portfolio
optimization process. The main idea of their approach is to treat different
lots of the same stock as different securities, and then penalize for taxes as
if they were different transaction costs associated with the sale of each lot.
(This means, for example, that Microsoft stock bought on Date 1 is treated
as a different security from Microsoft stock bought on Date 2.) Many tax-
aware quantitative investment strategies employ versions of this approach,
but there are a few issues to beware when using it in practice:
■The ﬁrst one is a general problem for all tax-aware approaches when
they are used in the context of active portfolio management. For a
portfolio manager who handles thousands of different accounts with
different tax exposures, it is virtually impossible to pay attention to
the tax cost incurred by each individual investor. While the tax-aware
method described above minimizes the overall tax burden by reducing
the amount of realized short-term sales, it has no provisions for differen-
tiating between investors in different tax brackets because it is difﬁcult
to think of each trade as divided between all investors, and adjusted for
each individual investor’s tax circumstances. This issue is so intractable,
that in practice it is not really brought under consideration.
■The dimension of the problem can become unmanageable very quickly.
For example, a portfolio of 1,000 securities, each of which has 10
different lots, is equivalent to a portfolio of 10,000 securities when each
lot is treated as a different security. Every time a new purchase is realized,
a new security is added to the portfolio, since a new lot is created. One
needs to exercise care and “clean up” lots that have been sold and
therefore have holdings of zero each time the portfolio is rebalanced.

346
PORTFOLIO OPTIMIZATION AND RISK MEASURES
■As we explained in section 9.2, practitioners typically use factor mod-
els for forecasting returns and estimating risk. We will explain factor
models in more detail in Chapter 11, but here we will mention that
one of the assumptions when measuring portfolio risk through factor
models is that the speciﬁc risk of a particular security is uncorrelated
with the speciﬁc risk of other securities. (The only risk they share is the
risk expressed through the factors in the factor model.) This assumption
clearly does not hold when different “securities” are in fact different lots
of the same stock.
DiBartolomeo (2000) describes a modiﬁcation to the model used by
Northﬁeld Information Service’s portfolio management software that elimi-
nates the last two problems. Instead of treating each lot as a separate security,
the software imposes a piecewise linear transaction costs (see section 9.4 and
Exhibit 9.1) where the break points on the horizontal axis correspond to the
current size of different lots of the same security. The portfolio rebalancing
algorithm goes through several iterations for the portfolio weights, and at
each iteration, only the shares in the highest cost basis tax lot can be traded.
Other shares of the same stock can be traded in subsequent iterations of the
algorithm, with their appropriate tax costs attached.
The approaches we described so far take into consideration the short-
term or long-term nature of capital gains, but do not incorporate the ability
the offset capital gains and losses accumulated over the year. This is an in-
herent limitation of single-period portfolio rebalancing approaches, and is
a strong argument in favor of adopting more realistic multiperiod portfolio
optimization approaches. The rebalancing the portfolio at each point in time
should be made not only by considering the immediate consequences for the
market value of the portfolio, but also the opportunity to correct for tax
liabilities by realizing other capital gains or losses by the end of the taxable
year. The scarce theoretical literature on multiperiod tax-aware portfolio
optimization contains some characterizations of optimal portfolio strate-
gies under numerous simplifying assumptions.25 However, even under such
simplifying assumptions, the dimension of the problem grows exponentially
with the number of stocks in a portfolio, and it is difﬁcult to come up with
computationally viable algorithms for portfolios of realistic size.
9.6
MULTIACCOUNT OPTIMIZATION
Portfolio managers who handle multiple accounts face an important prac-
tical issue. When individual clients’ portfolios are managed, portfolio man-
agers incorporate their clients’ preferences and constraints. However, on

Equity Portfolio Selection in Practice
347
any given trading day, the necessary trades for multiple diverse accounts
are pooled and executed simultaneously. Moreover, typically trades may
not be crossed, that is, it is not simply permissible to transfer an asset that
should be sold on behalf of one client into the account of another client
for whom the asset should be bought.26 The trades should be executed in
the market. Thus, each client’s trades implicitly impact the results for the
other clients: the market impact of the combined trades may be such that
the beneﬁts sought for individual accounts through trading are lost due to
increased overall transaction costs. A robust, multiaccount management pro-
cess should ensure accurate accounting and fair distribution of transaction
costs among the individual accounts.
One possibility to handle the effect of trading in multiple accounts is
to use an iterative process in which the market impact of the trades in pre-
vious iterations is taken into account at each iteration.27 More precisely,
single clients’ accounts are optimized as usual, and once the optimal al-
locations are obtained, the portfolio manager aggregates the trades and
computes the actual marginal transaction costs based on the aggregate level
of trading. The portfolio manager then reoptimizes individual accounts us-
ing these marginal transaction costs, and aggregates the resulting trades
again to compute new marginal transaction costs, and so on. The advantage
of this approach is that little needs to be changed in the way individual
accounts are typically handled, so the existing single-account optimization
and management infrastructure can be reused. The disadvantage is that most
generally this iterative approach does not guarantee a convergence (or its
convergence may be slow) to a “fair equilibrium” in which clients’ portfo-
lios receive an unbiased treatment with respect to the size and the constraint
structure of their accounts.28 The latter equilibrium is the one that would
be attained if all clients traded independently and competitively in the mar-
ket for liquidity, and is thus the correct and fair solution to the aggregate
trading problem.
An alternative, more comprehensive approach is to optimize trades
across all accounts simultaneously. O’Cinneide, Scherer, and Xu (2006)
describe such a model, and show that it attains the fair equilibrium we
mentioned previously.29 Assume that client k’s utility function is given by
uk, and is in the form of a dollar return penalized for risk. Assume also
that a transaction cost model τ gives the cost of trading in dollars, and
that τ is a convex increasing function.30 Its exact form will depend on
the details of how trading is implemented. Let t be the vector of trades. It
will typically have the form

t+
1 , . . . , t+
N, t−
1 , . . . , t−
N

, that is, it will specify
the aggregate buys t+
i
and the aggregate sells t−
i
for each asset i = 1, . . . ,
N, but it may also incorporate information about how the trade could be
carried out.31

348
PORTFOLIO OPTIMIZATION AND RISK MEASURES
The multiaccount optimization problem can be formulated as
max
w1,...,wK,t
E[u1(w1)] + · · · + E[uK(wK)] −τ(t)
s.t.
wk ∈Ck, k = 1, . . . , K
where wk is the N-dimensional vector of asset holdings (or weights) of client
k, and Ck is the collection of constraints on the portfolio structure of client
k. The objective can be interpreted as maximization of net expected utility,
that is, as maximization of the expected dollar return penalized for risk and
net of transaction costs.
The problem can be simpliﬁed by making some reasonable assumptions.
For example, it can be assumed that the transaction cost function τ is additive
across different assets, that is, trades in one asset do not inﬂuence trading
costs in another. In such a case, the trading cost function can be split into
more manageable terms:
τ(t) =
N

i=1
τi(t+
i ,t−
i )
where τi(t+
i , t−
i ) is the cost of trading asset i as a function of the aggregate
buys and sells of that asset. Splitting the terms τi(t+
i , t−
i ) further into separate
costs of buying and selling, however, is not a reasonable assumption because
simultaneous buying and selling of an asset tends to have an offsetting effect
on its price.
To formulate the problem completely, let w0
k be the vector of original
holdings (or weights) of client k’s portfolio, wk be the vector of decision
variables for the optimal holdings (or weights) of client k’s portfolio, and
ηk,i be constants that convert the holdings (or weight) of each asset i in client
i’s portfolio wk,i to dollars, i.e., ηk,iwk,i is client k’s dollar holdings of asset
i.32 We also introduce new variables w+
k to represent the an upper bound on
the weight of each asset client k will buy:
wk,i −w0
k,i ≤w+
k,i,
i = 1, . . . , N, k = 1, . . . , K.
The aggregate amount of asset i bought for all clients can then be com-
puted as
t+
i =
K

k=1
ηk,i · w+
k,i.
The aggregate amount of asset i sold for all clients can be easily expressed
by noticing that the difference between the amounts bought and sold of each

Equity Portfolio Selection in Practice
349
asset is exactly equal to the total amount of trades needed to get from the
original position w0
k,i to the ﬁnal position wk,i of that asset:33
t+
i −t−
i =
K

k=1
ηk,i ·

wk,i −w0
k,i

.
Here t+
i and t−
i are nonnegative variables.
The multiaccount optimization problem then takes the following form:
max
w1,...,wK,t+,t−
E[u1(w1)] + · · · + E[uK(wK)] −
N

i=1
τi(t+
i ,t−
i )
s.t.
wk ∈Ck, k = 1, . . . , K
wk,i −w0
k,i ≤w+
k,i,
i = 1, . . . , N, k = 1, . . . , K
t+
i =
K

k=1
ηk,iw+
k,i,
i = 1, . . . , N
t+
i −t−
i =
K

k=1
ηk,i ·

wk,i −w0
k,i

,
i = 1, . . . , N
t+
i ≥0, t−
i ≥0, w+
k,i ≥0,
i = 1, . . . , N, k = 1, . . . , K
O’Cinneide, Scherer, and Xu (2006) studied the behavior of the model in
simulated experiments with a simple model for the transaction cost function,
namely one in which
τ(t) = θ · tγ ,
where t is the trade size, and θ and γ are constants satisfying θ ≥0 and γ ≥
1.34 θ and γ are speciﬁed in advance and calibrated to ﬁt observed trading
costs in the market. The transaction costs for each client k can therefore be
expressed as
τk = θ
N

i=1
wk,i −w0
k,i
γ .
O’Cinneide, Scherer, and Xu observed that key portfolio perfor-
mance measures, such as the information ratio (IR),35 turnover, and total

350
PORTFOLIO OPTIMIZATION AND RISK MEASURES
transaction costs, change under this model relative to the traditional ap-
proach. Not surprisingly, the turnover and the net information ratios of the
portfolios obtained with multiaccount optimization are lower than those ob-
tained with single-account optimization under the assumption that accounts
are traded separately, while transaction costs are higher. These results are in
fact more realistic, and are a better representation of the post-optimization
performance of multiple client accounts in practice.
9.7
ROBUST PARAMETER ESTIMATION
The most commonly used approach for estimating security expected returns,
covariances, and other parameters that are inputs to portfolio optimization
models is to calculate the sample analogues from historical data.36 These are
sample estimates for the parameters we need. It is important to remember
that when we rely on historical data for estimation purposes, we in fact
assume that the past provides a good representation of the future.
It is well-known, however, that expected returns exhibit signiﬁcant time
variation (referred to as nonstationarity). They are impacted by changes in
markets and economic conditions, such as interest rates, the political envi-
ronment, consumer conﬁdence, and the business cycles of different industry
sectors and geographical regions. Consequently, extrapolated historical re-
turns are often poor forecasts of future returns.
Similarly, the covariance matrix is unstable over time. Moreover, sample
estimates of covariances for portfolios with thousands stocks are notoriously
unreliable because we need large data sets to estimate them, and such large
data sets of relevant data are difﬁcult to procure. Estimates of the covariance
matrix based on factor models are often used to reduce the number of
statistical estimates needed from a limited set of data. We return to this
issue after discussing factor models in Chapter 11.
In practice, portfolio managers often alter historical estimates of dif-
ferent parameters subjectively or objectively, based on their expectations
and forecasting models for future trends. They also use statistical methods
for ﬁnding estimators that are less sensitive to outliers and other sampling
errors, such as Bayesian and shrinkage estimators. A complete review of
advanced statistical estimation topics is beyond the scope of this book. We
provide a brief overview of the most widely used concepts, and refer readers
to Chapters 6 and 8 in Fabozzi, Kolm, Pachamanova, and Focardi (2007)
for further details.
Shrinkage is a form of averaging different estimators. The shrinkage
estimator typically consists of three components: (1) an estimator with

Equity Portfolio Selection in Practice
351
little or no structure (like the sample mean); (2) an estimator with a
lot of structure (the shrinkage target); and (3) a coefﬁcient that reﬂects
the shrinkage intensity. Probably the most well-known estimator for ex-
pected returns in the ﬁnancial literature was proposed by Jorion (1986).
The shrinkage target in Jorion’s model is a vector array with the return
on the minimum variance portfolio,37 and the shrinkage intensity is deter-
mined from a speciﬁc formula.38 Shrinkage estimators are used for estimates
of the covariance matrix of returns as well (see, for example, Ledoit and
Wolf 2003), although equally weighted portfolios of covariance matrix es-
timators have been shown to be equally effective as shrinkage estimators
as well.39
Bayesian estimation approaches, named after the English mathematician
Thomas Bayes, are based on subjective interpretations of the probability
that a particular event will occur. A probability distribution, called the
prior distribution, is used to represent the investor’s knowledge about the
probability before any data are observed. After more information is gathered
(e.g., data are observed), a formula (known as Bayes’ rule) is used to compute
the new probability distribution, called the posterior distribution.
In the portfolio parameter estimation context, a posterior distribution of
expected returns is derived by combining the forecast from the empirical data
with a prior distribution. One of the most well-known examples of the ap-
plication of the Bayesian framework in this context is the Black-Litterman
model,40 which produces an estimate of future expected returns by com-
bining the market equilibrium returns (i.e., returns that are derived from
pricing models and observable data) with the investor’s subjective views.
The investor’s views are expressed as absolute or relative deviations from
the equilibrium together with conﬁdence levels of the views (as measured by
the standard deviation of the views).
The ability to incorporate exogenous insight, such as a portfolio man-
ager’s opinion, into quantitative forecasting models is important; this insight
may be the most valuable input to the model. The Bayesian framework pro-
vides a mechanism for forecasting systems to use both important traditional
information sources such as proprietary market data, and subjective external
information sources such as analyst’s forecasts.
It is important to realize that regardless of how sophisticated the esti-
mation and forecasting methods are, they are always subject to estimation
error. What makes matters worse, however, is that different estimation er-
rors can accumulate over the different activities of the portfolio management
process, resulting in large aggregate errors at the ﬁnal stage. It is therefore
critical that the inputs evaluated at each stage are reliable and robust, so
that the aggregate impact of estimation errors is minimized.

352
PORTFOLIO OPTIMIZATION AND RISK MEASURES
9.8
PORTFOLIO RESAMPLING
Robust parameter estimation is only one part of ensuring that the quantita-
tive portfolio management process as a whole is reliable. It has been observed
that portfolio allocation schemes are very sensitive to small changes in the
inputs that go into the optimizer. In particular, a well-known study by Black
and Litterman (1992) demonstrated that in the case of mean-variance opti-
mization, small changes in the inputs for expected returns had a substantial
impact on the portfolio composition. “Optimal” portfolios constructed un-
der conditions of uncertainty can have extreme or nonintuitive weights for
some stocks.
With advances in computational capabilities and new research in the
area of optimization under uncertainty, practitioners in recent years have
been able to incorporate considerations for uncertainty not only at the es-
timation, but also at the portfolio optimization stage. Methods for taking
into consideration inaccuracies in the inputs to the portfolio optimization
problem include simulation (resampling) and robust optimization. We ex-
plain portfolio resampling in this section, and robust portfolio optimization
in the following section.
A logical approach to making portfolio allocation more robust with
respect to changes in the input parameters is to generate different scenarios
for the values these parameters can take, and ﬁnd weights that remain stable
for small changes in the input parameters. Simulation is therefore a natural
technique to use in this context. In the literature, using simulation to generate
robust portfolio weights has been referred to as portfolio resampling.41 To
illustrate the resampling technique, we explain how it is applied to portfolio
mean-variance optimization as an example.
Suppose that we have initial estimates for the expected stock returns, ˆµ,
and covariance matrix ˆ, for the N stocks in the portfolio. (As before, we
use “hat” to denote a statistical estimate.)
■We simulate S samples of N returns from a multivariate normal distri-
bution with mean ˆµ and covariance matrix ˆ.
■We use the S samples we generated in the previous step to compute S
new estimates of vectors of expected returns ˆµ1, . . . , ˆµS and covariance
matrices ˆ1, . . . , ˆS.
■We solve S portfolio optimization problems, one for each estimated pair
of expected returns and covariances ( ˆµs, ˆs), and save the weights for
the N stocks in a vector array w(s), where s = 1, . . . , S. (The optimization
problem itself could be any of the standard mean-variance formulations:
maximize expected return subject to constraints on risk, minimize risk

Equity Portfolio Selection in Practice
353
subject to constraints on the expected return, or maximize the utility
function.42)
■To ﬁnd the ﬁnal portfolio weights, we average out the weight for each
stock over the S weights found for that stock in each of the S optimiza-
tion problems. In other words,
w = 1
S
S

s=1
w(s).
For example, stock i in the portfolio has ﬁnal weight
wi = w(1)
i
+ · · · + w(S)
i
S
.
Perhaps even more valuable than the average estimate of the weights
obtained from the simulation and optimization iterations is the probability
distribution we obtain for the portfolio weights. If we plot the weights for
each stock obtained over the S iterations, w(1)
i , . . . , w(S)
i , we can get a sense
for how variable this stock weight is in the portfolio. A large standard
deviation computed from the distribution of portfolio weight i will be an
indication that the original portfolio weight was not very precise due to
estimation error.
An important question, of course, is how large is “large enough.” Do
we have evidence that the portfolios we obtained through resampling are
statistically different from one another? We can evaluate that by using a test
statistic.43 For example, it can be shown that the test statistic
d(w∗, w) = (w∗−w)′(w∗−w)
follows a chi-square (χ2) distribution44 with degrees of freedom equal to the
number of securities in the portfolio. If the value of this statistic is statistically
“large,” then there will be evidence that the portfolio weights w* and w are
statistically different. This is an important insight for the portfolio manager,
and its applications extend beyond just resampling. Let us provide some
intuition as to why.
Suppose that we are considering rebalancing our current portfolio.
Given our forecasts of expected returns and risk, we could calculate a set
of new portfolios through the resampling procedure. Using the previous test
statistic, we determine whether the new set of portfolio weights are statisti-
cally different from our current weights and, therefore, whether it would be
worthwhile to rebalance. If we decide that it is worthwhile to rebalance, we

354
PORTFOLIO OPTIMIZATION AND RISK MEASURES
could choose any of the resampled portfolios that are statistically different
from our current portfolio. Which one should we choose? A natural choice
would be to select the portfolio that would lead to the lowest transaction
costs. The idea of determining statistically equivalent portfolios, therefore,
has much wider implications than the ones illustrated in the context of
resampling.
Resampling has its drawbacks:
■Since the resampled portfolio is calculated through a simulation pro-
cedure in which a portfolio optimization problem needs to be solved
at each step, the approach is computationally cumbersome, especially
for large portfolios. There is a trade-off between the number of resam-
pling steps and the accuracy of estimation of the effect of errors on the
portfolio composition.
■Due to the averaging in the calculation of the ﬁnal portfolio weights, it
is highly likely that all stocks will end up with nonzero weights. This has
implications for the amount of transaction costs that will be incurred
if the ﬁnal portfolio is to be attained. One possibility is to include
constraints that limit both the turnover and the number of stocks with
nonzero weights. As we saw in section 9.2, however, the formulation of
such constraints adds another level of complexity to the optimization
problem, and will slow down the resampling procedure.
■Since the averaging process happens after the optimization problems are
solved, the ﬁnal weights may not actually satisfy some of the constraints
in the optimization formulation. In general, only convex (e.g., linear)
constraints are guaranteed to be satisﬁed by the averaged ﬁnal weights.
Turnover constraints, for example, may not be satisﬁed. This is a serious
limitation of the resampling approach for practical applications.
Despite these limitations, resampling has advantages, and presents a
good alternative to using only point estimates of inputs to the optimization
problem.
9.9
ROBUST PORTFOLIO OPTIMIZATION
Another way in which uncertainty about the inputs can be modeled is by
incorporating it directly into the optimization process. Robust optimiza-
tion, the technique we introduced in section 6.3 of Chapter 6, is an intuitive
and efﬁcient way to deal with uncertainty. Robust portfolio optimization
does not use the traditional forecasts, such as expected returns and stock
covariances, but rather uncertainty sets containing these point estimates.

Equity Portfolio Selection in Practice
355
An example of such an uncertainty set is a conﬁdence interval around the
forecast for expected returns, but we can also formulate advanced uncer-
tainty sets that incorporate more knowledge about the estimation error. For
example, as we explained in section 6.3.1, a widely used uncertainty set is
the ellipsoidal uncertainty set, which takes into consideration the covariance
structure of the estimation errors.
Let us give a speciﬁc example of how the robust optimization frame-
work can be applied in the portfolio optimization context. Consider the
utility function formulation of the classical mean-variance portfolio alloca-
tion problem from section 7.4.2 of Chapter 7:
max
w
w′µ −λ · w′w
s.t.
w′ι = 1
Suppose that we have estimates ˆµ and ˆ of the vector of expected
returns and the covariance matrix. Instead of the estimate ˆµ, however, we
will consider a set of vectors µ that are “close” to ˆµ. We deﬁne the “box”
uncertainty set45
Uδ( ˆµ) =

µ| |µi −ˆµi| ≤δi, i = 1, . . . , N

In words, the set Uδ( ˆµ) contains all vectors µ = (µ1, . . . , µN) such that
each component µi is in the interval [ ˆµi −δi, ˆµi + δi]. The robust counter-
part of the classical mean-variance problem with this uncertainty set can
be found using the techniques described in section 6.3.1. To see the anal-
ogy, however, we can introduce an auxiliary variable v, and express the
expression in the objective function as a constraint:
max
w
v
s.t.
w′µ −λ · w′w ≥v
w′ι = 1
This is a standard trick in optimization: The value of the decision vari-
able v is to be maximized, but is constrained from above by the expression
w′µ −λ · w′w, so the optimizer will try to make w′µ −λ · w′w as large
as possible (i.e., maximize it) as well. The optimal solution to the problem
does not change, but now we can compute the robust counterpart of the
constraint
w′µ −λ · w′w ≥v

356
PORTFOLIO OPTIMIZATION AND RISK MEASURES
in the same way as we did for a constraint of the general type
˜a′x ≤b
in section 6.3.1 of Chapter 6. Namely, we ﬁrst solve an optimization
problem of the kind
max
µ∈Uδ( ˆµ)

−w′µ + λ · w′w

≤−v.
(Note here that we multiplied both sides of the constraint by −1, which
reversed the sign of the constraint. This is just to demonstrate that we can
bring the constraint exactly into the general form ˜a′x ≤b.) This problem is
actually equivalent to
max
µ∈Uδ( ˆµ)

−w′µ

≤−v −λ · w′w,
and since there is no µ in the expression at the right-hand side of the
constraint, we can treat the whole expression as if it was a constant (with
respect to µ). In other words, we have the constraint ˜a′x ≤b, where ˜a = µ,
x = w, and b = −v −λ · w′w.46
The robust counterpart of the mean-variance optimization problem un-
der the box uncertainty set for expected returns is therefore
max
w
w′µ −δ′|w| −λ · w′w
s.t.
w′ι = 1
where |w| denotes the absolute value of the entries of the vector of weights
w. To gain some intuition, notice that if the weight of stock i in the portfolio
is negative, the worst-case expected return for stock i is µi + δi (we lose
the largest amount possible). If the weight of stock i in the portfolio is
positive, then the worst-case expected return for stock i is µi −δi (we gain
the smallest amount possible). Observe that µiwi −δi |wi| equals (µi −δi) wi
if the weight wi is positive and (µi + δi) wi if the weight wi is negative. Hence,
the mathematical expression in the objective agrees with our intuition: it
minimizes the worst-case expected portfolio return. In this robust version of
the mean-variance formulation, stocks whose mean return estimates are less
accurate (i.e., have a larger estimation error δi) are therefore penalized in
the objective function, and will tend to have a smaller weight in the optimal
portfolio allocation.

Equity Portfolio Selection in Practice
357
This optimization problem has the same computational complexity as
the nonrobust mean-variance formulation—namely, it can be stated as a
quadratic optimization problem. The latter can be achieved by using a stan-
dard trick that allows us to get rid of the absolute values for the weights.
The idea is to introduce an N-dimensional vector of additional variables ψ
to replace the absolute values |w|, and to write an equivalent version of the
optimization problem,
max
w,ψ
w′ ˆµ −δ′ψ −λw′w
s.t.
w′ι = 1
ψi ≥wi; ψi ≥−wi, i = 1, . . . , N
Therefore, incorporating considerations about the uncertainty in the
estimates of the expected returns in this example has virtually no computa-
tional cost.
We can view the effect of this particular “robustiﬁcation” of the mean-
variance portfolio optimization formulation in two different ways. On the
one hand, we can see that the values of the expected returns for the different
stocks have been adjusted downward in the objective function of the opti-
mization problem. In other words, the robust optimization model “shrinks”
the expected return of stocks with large estimation error, meaning, in this
case the robust formulation is related to statistical shrinkage methods.47 On
the other hand, we can interpret the additional term in the objective function
as a “risk-like” term that represents penalty for estimation error. The size of
the penalty is determined by the investor’s aversion to estimation risk, and
is reﬂected in the magnitude of the deltas.
More complicated speciﬁcations for uncertainty sets have more involved
mathematical representations, but can still be selected so that they preserve
an easy computational structure for the robust optimization problem. For
example, a commonly used uncertainty set is the ellipsoidal uncertainty set48
Uδ( ˆµ) =

µ|

µ −ˆµ
′ −1
µ

µ −ˆµ

≤δ2
where µ is the covariance matrix of estimation errors for the vector of
expected returns µ. This uncertainty set represents the requirement that the
scaled sum of squares (scaled by the inverse of the covariance matrix of
estimation errors) between all elements in the set and the point estimates
ˆµ1, ˆµ2, . . . , ˆµN can be no larger than δ2. We note that this uncertainty set
cannot be interpreted as individual conﬁdence intervals around each point
estimate. Instead, it captures the idea of a joint conﬁdence region. In practical

358
PORTFOLIO OPTIMIZATION AND RISK MEASURES
applications, the covariance matrix of estimation errors is often assumed to
be diagonal. For this particular case, the set contains all vectors of expected
returns that are within a certain number of standard deviations from the
point estimate of the vector of expected returns, and the resulting robust
portfolio optimization problem would protect the investor if the vector of
expected returns is within that range.
It can be shown (see Practice 9.3 on the companion web site) that the
robust counterpart of the mean-variance portfolio optimization problem
with an ellipsoidal uncertainty set for the expected return estimates is the
following optimization problem formulation:
max
w
w′µ −λ · w′w −δ

w′µw
s.t.
w′ι = 1
This is a second-order cone problem, and requires specialized software
to solve, but the methods for solving it are very efﬁcient (see section 5.2.4
of Chapter 5).
Just as in the robust counterpart with a box uncertainty set, we can
interpret the extra term in the objective function (δw′µw) as the penalty
for estimation risk, where δ incorporates the degree of the investor’s aver-
sion to estimation risk. Note, by the way, that the covariance matrix in the
estimation error penalty term, µ, is not necessarily the same as the covari-
ance matrix of returns . In fact, it is not immediately obvious how µ can
be estimated from data. µ it is the covariance matrix of the errors in the
estimation of the expected (average) returns. Thus, if a portfolio manager
forecasts 5% active return over the next time period, but gets 1%, he can-
not argue that there was a 4% error in his expected return—the actual error
would consist of both an estimation error in the expected return and the
inherent volatility in actual realized returns. In fact, critics of the approach
have argued that the realized returns typically have large stochastic compo-
nents that dwarf the expected returns, and hence estimating µ from data
is very hard, if not impossible.49
Several approximate methods for estimating µ have been found to
work well in practice. For example, it has been observed that simpler esti-
mation approaches, such as using just the diagonal matrix containing the
variances of the estimates (as opposed to the complete error covariance ma-
trix), often provide most of the beneﬁt in robust portfolio optimization.50
In addition, standard approaches for estimating expected returns, such as
Bayesian statistics and regression-based methods, can produce estimates for
the estimation error covariance matrix in the process of generating the esti-
mates themselves.51

Equity Portfolio Selection in Practice
359
Among practitioners, the notion of robust portfolio optimization is of-
ten equated with the robust mean-variance model discussed in this section,
with the box or the ellipsoidal uncertainty sets for the expected stock re-
turns. While robust optimization applications often involve one form or
another of this model, the actual scope of robust optimization can be much
broader. We note that the term robust optimization refers to the technique
of incorporating information about uncertainty sets for the parameters in
the optimization model, and not to the speciﬁc deﬁnitions of uncertainty
sets or the choice of parameters to model as uncertain. For example, we can
use the robust optimization methodology to incorporate considerations for
uncertainty in the estimate of the covariance matrix in addition to the uncer-
tainty in expected returns, and obtain a different robust portfolio allocation
formulation. Robust optimization can be applied also to portfolio alloca-
tion models that are different from the mean-variance framework, such as
Sharpe ratio optimization and value-at-risk optimization.52 Finally, robust
optimization has the potential to provide a computationally efﬁcient way to
handle portfolio optimization over multiple stages—a problem for which so
far there have been few satisfactory solutions.53 There are numerous useful
robust formulations, but a complete review is beyond the scope of this book.
We refer interested readers to Fabozzi, Kolm, Pachamanova, and Focardi
(2007) for further details.
Is implementing robust optimization formulations worthwhile? Some
tests with simulated and real market data indicate that robust optimization,
when inaccuracy is assumed in the expected return estimates, outperforms
classical mean-variance optimization in terms of total excess return a large
percentage (70%–80%) of the time.54 Other tests have not been as conclu-
sive (Lee, Stefek, and Zhelenyak [2006]). The factor that accounts for much
of the difference is how the uncertainty in parameters is modeled. There-
fore, ﬁnding a suitable degree of robustness and appropriate deﬁnitions of
uncertainty sets can have a signiﬁcant impact on portfolio performance.
(See Practice 9.4 on the companion web site for an example of an alterna-
tive formulation of an uncertainty set for expected returns in the traditional
mean-variance formulation.)
Independent tests by practitioners and academics using both simulated
and market data appear to conﬁrm that robust optimization generally re-
sults in more stable portfolio weights, that is, it eliminates the extreme corner
solutions resulting from traditional mean-variance optimization. This fact
has implications for portfolio rebalancing in the presence of transaction
costs and taxes, as transaction costs and taxes can add substantial expenses
when the portfolio is rebalanced. Depending on the particular robust for-
mulations employed, robust mean-variance optimization also appears to im-
prove worst-case portfolio performance, and results in smoother and more

360
PORTFOLIO OPTIMIZATION AND RISK MEASURES
consistent portfolio returns. Finally, by preventing large swings in positions,
robust optimization typically makes better use of the turnover budget and
risk constraints.
Robust optimization, however, is not a panacea. By using robust portfo-
lio optimization formulations, investors are likely to trade off the optimality
of their portfolio allocation in cases in which nature behaves as they pre-
dicted for protection against the risk of inaccurate estimation. Therefore,
investors using the technique should not expect to do better than classical
portfolio optimization when estimation errors have little impact, or when
typical scenarios occur. They should, however, expect insurance in scenarios
in which their estimates deviate from the actual realized values by up to the
amount they have prespeciﬁed in the modeling process.
SUMMARY
■The portfolio management process consists of four activities: (1) setting
the investment objectives; (2) developing and implementing a portfolio
strategy; (3) monitoring the portfolio; and (4) adjusting the portfolio.
■Portfolio strategies can be active or passive. Active strategies utilize
information provided by manager intuition or quantitative models to
come up with strategies that select the most attractive investment op-
portunities in the portfolio manager’s opinion. Passive strategies require
minimal management. One popular type of passive strategy is indexing,
whose objective is to replicate the performance of a designated mar-
ket index.
■Commonly used constraints in practice include long-only (no short-
selling) constraints, turnover constraints, holding constraints, risk fac-
tor constraints, and tracking error constraints. These constraints can be
handled in a straightforward way by the same type of optimization algo-
rithms used for solving the classical mean-variance portfolio allocation
problem.
■Minimum holding constraints, transaction size constraints, cardinality
constraints, and round-lot constraints are also widely used in practice,
but their nature is such that they require binary and integer model-
ing, which necessitates the use of mixed-integer and other specialized
optimization solvers.
■Transaction costs can easily be incorporated in standard portfolio al-
location models. Typical functions for representing transaction costs
include linear, piecewise linear, and quadratic.
■Taxes can have a dramatic effect on portfolio returns; however, it is
difﬁcult to incorporate them into the classical portfolio optimization

Equity Portfolio Selection in Practice
361
framework. Their importance to the individual investor is a strong ar-
gument for taking a multiperiod view of investments, but the computa-
tional burden of multiperiod portfolio optimization formulations with
taxes is extremely high.
■For investment managers who handle multiple accounts, increased trans-
action costs because of the market impact of simultaneous trades can
be an important practical issue, and should be taken into considera-
tion when individual clients’ portfolio allocation decisions are made to
ensure fairness across accounts.
■As the use of quantitative techniques has become widespread in the
investment industry, the consideration of estimation risk and model
risk has grown in importance. Methods for robust statistical estimation
of parameters include shrinkage and Bayesian techniques.
■Portfolio resampling is a technique that uses simulation to generate
multiple scenarios for possible values of the input parameters in the
portfolio optimization problem, and aims to determine portfolio weights
that remain stable with respect to small changes in model parameters.
■Robust portfolio optimization incorporates uncertainty directly into the
optimization process. The uncertain parameters in the optimization
problem are assumed to vary in prespeciﬁed uncertainty sets that are
selected subjectively or based on data.
SOFTWARE HINTS
Excel Solver
Limiting the Number of Stocks in the Portfolio
Let us give an example
of implementing an optimal portfolio allocation problem with a constraint
on the number of stocks to include. Consider the example in ﬁle Ch9-
Cardinality.xlsx. (A screenshot of the worksheet MV is provided in Ex-
hibit 9.2.) We have a portfolio of three stocks, and would like to maximize
the expected return (cell B7) subject to the budget constraint (row 10), the
constraint on the total number of stocks to have in the portfolio (row 11),
and a constraint on the portfolio variance (row 13). Often, the total port-
folio variance constraint is instead expressed as a tracking error constraint,
that is, the variance of the deviations from a predetermined benchmark is
considered. (See section 9.3.1.)
Cells B3:D3 are changing cells, where Excel Solver will store the optimal
portfolio weights. The difference with the classical mean-variance optimiza-
tion problem is that now we have another set of changing cells, B4:D4, which
will be binary and will detect whether a stock is included in the portfolio or
not. (These are the variables δi from the formulation in section 9.2.5.)

362
PORTFOLIO OPTIMIZATION AND RISK MEASURES
EXHIBIT 9.2
Worksheet MV in the ﬁle Ch9-Cardinality.xlsx.
The formula for the objective function (cell B7) is
= SUMPRODUCT(B3:D3,Data!G9:I9)
(The expected returns for each stock are approximated by simply taking
the averages of time series in the worksheet Data in the same ﬁle, and are
stored in cells G9:I9 in the worksheet Data.)
The formula for the budget constraint (in cell B10) is
= SUM(B3:D3)
The formula for the constraint on the number of stocks (in cell B11) is
= SUM(B4:D4)
(We are adding the binary variables δi for each stock, and restricting the
sum to be less than or equal to 2.)
The formula for the portfolio variance (in cell B12) is
= MMULT(B3:D3,MMULT(Data!G3:I5,TRANSPOSE(B3:D3)))
(The covariance matrix for the stock returns are approximated by simply
taking the sample covariance matrix of the time series in the worksheet Data
in the same ﬁle, and are stored in cells G3:I5 in the worksheet Data.)
There are also additional constraints to ensure that a binary variable is
not set to 0 if the corresponding weight of a stock in the portfolio is different

Equity Portfolio Selection in Practice
363
from 0. They are stored in rows 14 and 15. We have selected the value for
the “large” constant M from the formulation in section 9.2.5 to be 10. (This
is a large number relative to the size of the other inputs in this problem.)
Cells B14:D14 contain the lower limits on the portfolio weights in terms
of M and the corresponding binary variable δi. Cells B15:D15 contain the
upper limits on the portfolio weights in terms of M and the corresponding
binary variable δi. For example, cell B14 corresponding to the lower limit
on the weight of Stock 1 contains the formula
= -$G$2*B4
and cell B15 corresponding to the upper limit on the weight of Stock 1
contains the formula
= $G$2*B4
(The value for the constant M is stored in cell G2.)
The Excel Solver dialog window is shown in Exhibit 9.3. Note that
the options Assume Linear Model and Assume Non-Negative should not
be checked in this particular example. (This problem is nonlinear because
it has a quadratic constraint [the portfolio variance], and the weights are
not restricted to be nonnegative.) Both the portfolio weights (cells B3:B5)
and the binary variables (cells B4:D4) are speciﬁed as changing cells, and a
constraint is also imposed on B4:D4 to be binary.
EXHIBIT 9.3
Solver dialog box for the optimal portfolio allocation problem
with a constraint on the number of stocks to be included.

364
PORTFOLIO OPTIMIZATION AND RISK MEASURES
The optimal solution is shown in Exhibit 9.2. If we are limited to two
stocks, it is optimal to invest in Stock 1 and Stock 2, with −31% in Stock 1
and 131% in Stock 2.
We deliberately chose a very small example to illustrate the setup of the
model in Excel. Excel Solver would have a lot of trouble, and most likely
not produce the correct result, if the portfolio contains a large number of
stocks.
Index Tracking
Let us examine the formulation of another problem that is
easy to do with Solver. Suppose we would like to replicate the performance
of the Dow Jones Composite Index (DJA) with 10 stocks from different
industries (tickers AA, AXP, BAC, DD, GE, HD, INTC, CSCO, MRK,
WMT). We have decided on these stocks in advance, and would like to
determine their weights so as to minimize the tracking error as determined
by the square difference between the portfolio return and the return on
the DJA. The problem is formulated for Solver in the spreadsheet Ch9-
IndexTracking.xlsx. A snapshot of the spreadsheet is provided in Exhibit
9.4. The data on returns are weekly, over the last six months before the
current date. The data can also be generated by simulating possible scenarios
for future stock returns.
The decision variables (changing cells) are B2:K2. They will contain the
optimal portfolio weights. In column M, we compute the square difference
between the portfolio return and the return on the DJA for every scenario.
For example, cell M4 contains the formula
= (SUMPRODUCT($B$1:$K$1,B4:K4)-L4)ˆ2
The objective function is simply the sum of all the squared differences,
that is, it contains the formula
= SUM(M4:M28)
Even though this is a nonlinear problem, the objective function is a
quadratic expression, the decision variables are continuous, and the only
constraint is linear. Solver solves the problem without difﬁculty. However,
if we were to limit the number of stocks to include in the replicating portfolio
(e.g., if we were to require that only 5 out of the 10 stocks be included),
then we would need to introduce integer variables, and Solver would not
produce a reliable solution.
A more advanced example of minimizing portfolio tracking error is de-
scribed in the following section. Such advanced optimization formulations,
including portfolio allocation with the goal of minimizing probability of

EXHIBIT 9.4
Excel worksheet with the formulation of an index tracking problem.
365

366
PORTFOLIO OPTIMIZATION AND RISK MEASURES
loss, minimizing the Sharpe ratio of a portfolio, and others can be formu-
lated with Solver, but the quality of the ﬁnal solutions returned by Solver is
unsatisfactory, so we should formulate them with Evolver instead.
Palisades Decision Tools Suite (Evolver)
We go over several examples of implementation of several portfolio alloca-
tion problems with Evolver.
Limiting the Number of Stocks in the Portfolio
We begin with the port-
folio allocation problem with a constraint on the number of stocks to be
contained in the portfolio. The setup for solving the problem in Evolver
is the same as for Excel Solver. (See worksheet MV (Evolver) in the ﬁle
Ch9-Cardinality.xlsx.) The dialog box for Evolver is shown in Exhibit 9.5.
The optimal solution is the same as the solution obtained with Excel
Solver. (See Exhibit 9.2.)
EXHIBIT 9.5
Evolver dialog box for the optimal portfolio allocation
problem with a constraint on the number of stocks to be included.

Equity Portfolio Selection in Practice
367
Index Tracking
As we saw in the Excel Solver section of the Software
Hints, the formulation of the limited index tracking problem with Solver is
easy to do. The problem is implemented with Evolver in worksheet Index
Tracking (Evolver) in the same ﬁle, Ch9-IndexTracking.xlsx. The Evolver
dialog box is shown in Exhibit 9.6. The only difference is that we do not need
to specify the budget constraint explicitly because it is implicitly followed
when we restrict the values for the decision variables (the weights) to be
selected according to the “budget” method (see the second window in the
Evolver dialog box). The budget method makes sure that if you start out
with weights that add up to 1, all subsequent weights Evolver picks will add
up to 1, that is, the budget constraint will be satisﬁed.
Limited Index Tracking
Now consider the problem of tracking an index
with a limited number of stocks. We will work with the data in the ﬁle
Ch9-IndexTrackingLim.xlsx. As in the case of limiting the number of stocks
in a mean-variance portfolio, we need to introduce binary variables—one
EXHIBIT 9.6
Evolver dialog box for the index tracking problem.

368
PORTFOLIO OPTIMIZATION AND RISK MEASURES
EXHIBIT 9.7
Evolver dialog box for the limited index tracking problem.
for each stock. The formulation of the problem with Evolver is shown in
Exhibit 9.7. Note that the only constraints are the constraints that link the
binary variables and the weights. The remaining constraints (the fact that
the weights have to add up to 1, and that the number of stocks in the
portfolio should be limited) can be imposed by specifying those conditions
when entering the variables (called adjustable cells) in the middle window
in Evolver. Make sure that you specify the weights and the binary variables
as two separate groups of variables, each of which is selected according to
the budget method. If you combine them in the same group, then Evolver
will assume that their total sum needs to be equal to the sum of the values
that were in the cells at the beginning of the algorithm.
MATLAB
As we saw in Chapter 9, many of the real portfolio optimization algorithms
require quadratic constraints or constraints with integer variables. At the

Equity Portfolio Selection in Practice
369
time of writing of this book, MATLAB’s capabilities for solving such prob-
lems directly are limited. It is possible, however, to put together scripts that
take advantage of the Genetic Algorithms Toolbox in MATLAB to solve
such more complex problems. For example, the problem of ﬁnding a port-
folio of a given number of stocks that tracks an index most closely can
be constructed in this manner. The code for implementing the index track-
ing problem is quite involved, and is available from MATLAB’s online ﬁle
depository.55
NOTES
1. See pp. 1–3 and 1–5, Chapter 1, in J. L. Maginn and D. L. Tuttle (1990).
2. See Fabozzi (2007).
3. Risk factor models are discussed in more detail in Chapter 11.
4. Such asset pricing models are discussed in Chapter 11.
5. ERISA was enacted in 1974 as a federal regulatory scheme for private sector
employee beneﬁt plans, including health care plans. It sets forth requirements
for beneﬁt plan participation, funding, and vesting of beneﬁts.
6. Multiperiod portfolio optimization models are still rarely used in practice, not
because the value of multiperiod modeling is questioned, but because such
models are often too intractable from a computational perspective.
7. As the term intuitively implies, the ADV measures the total amount of a given
asset traded in a day on average, where the average is taken over a prespeciﬁed
time period.
8. Risk factors and factor models are discussed in more detail in Chapter 11.
9. See Chapter 11.
10. See section 8.3 of Chapter 8 for an introduction to CVaR.
11. As explained in Chapter 8, another computationally tractable situation is when
the data are normally distributed. In that case, minimizing CVaR is equivalent
to minimizing the standard deviation
12. Such models are discussed in Chapter 11.
13. Price movement risk costs are the costs resulting from the potential for a change
in market price between the time the decision to trade is made and the time the
trade is actually executed.
14. Market impact is the effect a trader has on the market price of an asset when it
sells or buys the asset. It is the extent to which the price moves up or down in
response to the trader’s actions. For example, a trader who tries to sell a large
number of shares of a particular stock may drive down the stock’s market price.
15. Versions of this model have been suggested in Pogue (1970), Schreiner (1980),
Adcock and Meade (1994), Lobo, Fazel, and Boyd (2007), and Mitchell and
Braun (2004).
16. Here we are thinking of wi as the portfolio weights, but in fact it may be more
intuitive to think of the transaction costs as a percentage of amount traded. It

370
PORTFOLIO OPTIMIZATION AND RISK MEASURES
is easy to go back and forth between portfolio weights and portfolio amounts
by simply multiplying wi by the total amount in the portfolio. In fact, we can
switch the whole portfolio optimization formulation around, and write it in
terms of allocation of dollars, instead of weights. We just need to replace the
vector of weights w by a vector x of dollar holdings.
17. See, for example, Bertsimas, Darnell, and Soucy (1999).
18. As we explained earlier, this constraint can be written in an equivalent, more
optimization solver-friendly form, namely,
yi ≥wi −w0,i,
yi ≥−(wi −w0,i)
19. Both MATLAB and Excel have tools for ﬁtting quadratic functions to data.
20. The computation of the tax basis is different for stocks and bonds. For bonds,
there are special tax rules, and the original price is not the tax basis.
21. The exact rates vary depending on the current version of the tax code, but the
main idea behind the preferential treatment of long-term gains to short-term
gains is to encourage long-term capital investments and fund entrepreneurial
activity.
22. See Stein (1998).
23. Apelfeld, Fowler, and Gordon (1996) showed that a manager can outperform
on an after-tax basis with high turnover as well, as long as the turnover does
not result in net capital gains taxes. (There are other issues with high turnover,
however, such as higher transaction costs that may result in a lower overall
portfolio return.)
24. Dividends are taxed as regular income, that is, at a higher rate than capital
gains, so minimizing the portfolio dividend yield should theoretically result in
a lower tax burden for the investor.
25. See Constantinides (1984), Dammon and Spatt (1996), and Dammon, Spatt,
and Zhang (2001, 2004).
26. The SEC in general prohibits cross-trading but does provide exemptions if
prior to the execution of the cross-trade the asset manager can demonstrate to
the SEC that a particular cross-trade beneﬁts both parties. Similarly, Section
406(b)(3) of the Employee Retirement Income Security Act of 1974 (ERISA)
forbids cross-trading, but there is a new cross-trading exemption in Section
408(b)(19) adopted in the Pension Protection Act of 2006.
27. See Khodadadi, Tutuncu, and Zangari (2006).
28. The iterative procedure is known to converge to the equilibrium, however, under
special conditions; see O’Cinneide, Scherer and Xu (2006).
29. The issue of considering transaction costs in multiaccount optimization has
been discussed by others as well. See, for example, Bertsimas, Darnell, and
Soucy (1999).
30. As mentioned in section 9.4, realistic transaction costs are in fact described by
nonlinear functions because costs per share traded typically increase with the
size of the trade due to market impact.

Equity Portfolio Selection in Practice
371
31. For example, if asset i is a euro-pound forward, then a trade in that asset can
also be implemented as a euro-dollar forward plus a dollar-forward, so there
will be two additional assets in the aggregate trade vector t. Such concepts will
become more intuitive after introducing ﬁnancial derivatives in Chapters 13
and 14.
32. Note that ηk,i equals 1 if wk,i is the actual dollar holdings.
33. Note that, similarly to w+
k , we could introduce additional sell variables w−
k ,
but this is not necessary. By expressing aggregate sales through aggregate buys
and total trades, we reduce the dimension of the optimization problem because
there are fewer decision variables. This would make a difference for the speed of
obtaining a solution, especially in the case of large portfolios and complicated
representation of transaction costs.
34. Note that γ = 1 deﬁnes linear transaction costs. For linear transaction costs,
multiaccount optimization produces the same allocation as single-account op-
timization because linear transaction costs assume that an increased aggregate
amount of trading does not have an impact on prices.
35. The information ratio is the ratio of (annualized) portfolio residual return
(alpha) to (annualized) portfolio residual risk, where risk is deﬁned as stan-
dard deviation. The concept of alpha is discussed in Chapter 11.
36. See sections 3.6 and 3.11 of Chapter 3 for how to obtain sample estimates, and
sections 8.2.3 and 8.3.2 for how to use historical data to estimate VaR and
CVaR, respectively.
37. See section 7.3 of Chapter 7 for a deﬁnition of the minimum variance portfolio.
38. See Fabozzi, Kolm, Pachamanova, and Focardi (2007, 217).
39. See Disatnik and Benninga (2007) for an overview of such models.
40. See Chapter 8 in Fabozzi, Kolm, Pachamanova, and Focardi (2007) for a step-
by-step description of the Black-Litterman model.
41. See Michaud (1998), Jorion (1992), and Scherer (2002).
42. See Chapter 7.
43. See section 3.11.4 of Chapter 3 for a brief introduction to statistical hypothesis
testing.
44. See section 3.7.2 of Chapter 3.
45. See Exhibit 6.7(A) in Chapter 6.
46. Observe that this model incorporates the notion of aversion to estimation error
in the following sense. When the interval [ ˆµi −δi, ˆµi + δi] for the expected
return of the ith asset is large, meaning that the expected return has been
estimated with large estimation error, then the minimization problem over µ
is less constrained. Consequently, the minimum is smaller than it would be
in situations when the interval for the expected return is smaller. Obviously,
when the interval is small enough, the minimization problem will be so tightly
constrained that it would deliver a solution that is close to the optimal solution
of the classical portfolio optimization problem in which estimation errors are
ignored. In other words, it is the size of the intervals (in general, the size of the
uncertainty set) that controls the aversion to the uncertainty that comes from
estimation errors.

372
PORTFOLIO OPTIMIZATION AND RISK MEASURES
47. See section 9.7 for a deﬁnition of statistical shrinkage.
48. See Exhibit 6.7(B) in Chapter 6.
49. See Lee, Stefek, and Zhelenyak (2006).
50. See Stubbs and Vance (2005).
51. See Chapter 12 in Fabozzi, Kolm, Pachamanova, and Focardi (2007) for a
more in-depth coverage of the topic of estimating input parameters for robust
optimization formulations.
52. See, for example, Goldfarb and Iyengar (2003) and Natarajan, Pachamanova,
and Sim (2008).
53. See Ben-Tal, Margalit, and Nemirovski (2000) and Bertsimas and Pachamanova
(2008).
54. See Ceria and Stubbs (2006).
55. See
the
collection
of
ﬁles
at
Mathworks
Inc.,
MATLAB
Central,
http://www.mathworks.com/matlabcentral/ﬁleexchange/authors/30003.

CHAPTER10
Fixed Income Portfolio
Management in Practice
C
hapters 7, 8, and 9 introduced fundamental concepts in risk measure-
ment and quantitative equity portfolio management. We discussed risk
measures such as variance, tracking error relative to an index, value-at-risk
(VaR), and conditional value-at-risk (CVaR), as well as portfolio manage-
ment strategies and formulations. Many of these concepts are used in ﬁxed
income portfolio management as well; however, ﬁxed income securities have
some fundamental differences from equities, so the concepts cannot always
be applied in the same way in which they would be applied for stock portfo-
lios. Furthermore, ﬁxed income securities are strongly inﬂuenced by changes
in interest rates and credit quality, which adds another dimension to port-
folio analysis.
This chapter focuses on the basics of ﬁxed income portfolio manage-
ment in practice. We begin by reviewing measures of bond portfolio risk.
Many bond portfolio strategies can be understood in terms of the risk and
return relative to a benchmark, so we provide an overview of bond market
indices and a classiﬁcation of bond index strategies. We then proceed with
a discussion of asset-liability portfolio strategies such as cash ﬂow matching
and immunization. We give examples of how optimization and simulation
can be applied in bond portfolio allocation and risk management.
10.1
MEASURING BOND PORTFOLIO RISK
As just mentioned, many of the risk measures we discussed in the context
of risk management of equity portfolios in Chapter 8 hold in the case of
bond portfolios: we can evaluate a bond portfolio’s standard deviation,
tracking error, VaR, and CVaR similarly to the way we evaluated these
risk measures by considering the portfolio returns in the case of equity
373

374
PORTFOLIO OPTIMIZATION AND RISK MEASURES
portfolios. However, there are some additional measures of bond portfolio
risk that are not really used in equity portfolio management. To appreciate
these measures, we next discuss sources of bond portfolio risk, starting with
classical measures of bond portfolio risk and moving on to more recent ways
to look at risk, such as VaR and CVaR.
10.1.1
Interest Rate Risk
A portfolio’s duration is the measure used to quantify the portfolio’s ex-
posure to changes in the level of interest rates. This risk measure is valid
only if we make the assumption of a parallel shift in the yield curve. As we
explained in Chapter 2, the duration of an individual bond is the approx-
imate percentage change in market value for a 100 basis points change in
interest rates. The interpretation of the duration of a portfolio is the same.
A portfolio duration of 4, for example, means that the portfolio’s market
value will change by approximately 4% for a 100 basis point change in the
interest rate for all maturities.
As explained in Chapter 2, three different versions of the duration mea-
sure are modiﬁed duration, Macaulay duration, and effective duration. Mod-
iﬁed duration assumes that, when interest rates change, the cash ﬂows do not
change. This is a limitation when measuring the exposure of bonds with em-
bedded options (e. g., callable bonds, mortgage-backed securities, and some
asset-backed securities).1 Macaulay duration is related to modiﬁed duration
and suffers from the same failure to consider changes in cash ﬂows when
interest rates change. In contrast, effective duration takes these changes in
cash ﬂows into account and thus is the appropriate measure for bonds with
embedded options. Effective duration is also referred to as option-adjusted
duration or adjusted duration.2
The calculation of a portfolio’s duration begins with the calculation
of the duration for each of the individual bonds comprising the portfolio.
This calculation requires the use of a valuation model. Duration is found
by shocking (i.e., changing) interest rates up and down, computing the new
value of the bond in both cases, and then computing the average percentage
price change for the change in interest rates used. Consequently, the duration
measure is only as good as the valuation model.
A portfolio’s duration is obtained by calculating the weighted average
of the durations of the bonds in the portfolio. The weight for a bond is the
proportion of the market value of the portfolio represented by the bond.
Mathematically, we have
Dp = w1 · D1 + w2 · D2 + · · · + wN · DN,

Fixed Income Portfolio Management in Practice
375
where N is the number of bonds in the portfolio, wi is the weight of the
ith bond, Di is the duration of the ith bond, and Dp is the duration of the
portfolio.
The duration of a bond index is computed in the same way since an
index is simply a portfolio with particular weights.
A measure of the portfolio exposure to an individual issue or sector is
given by its contribution to portfolio duration. This contribution is found by
multiplying the percentage of the market value of the portfolio represented
by the individual issue or sector ties the duration of the individual issue or
sector. That is,
Contribution to portfolio duration =
(Weight of issue or sector in portfolio) · (Duration of issue or sector)
In Chapter 2, we explained that convexity helps to improve the esti-
mate of interest rate risk provided by the duration of an individual bond.
Convexity is used for measuring the interest risk of portfolios as well.
10.1.2
Yield Curve Risk
Duration provides a measure of the exposure of a portfolio or a benchmark
index to changes in the level of interest rates. However, duration does not
indicate the exposure of a portfolio or a benchmark index to changes in the
shape of the yield curve.
One way to get a feel for the risk exposure resulting from yield curve
shifts is to analyze the distribution of the present values of the cash ﬂows
for the portfolio under different scenarios for the yield curve. Another way
is to compute the key rate durations of the portfolio and the benchmark.
Key rate duration, which was described in Chapter 2, is the sensitivity of
a portfolio’s value to the change in a particular key spot rate. The speciﬁc
maturities on the spot rate curve for which key rate durations are measured
vary from ﬁrm to ﬁrm.
10.1.3
Spread Risk
For non-Treasury securities, the yield is equal to the Treasury yield plus
a spread to the Treasury yield curve. Non-Treasury securities are referred
to as spread products. The risk that the price of a bond changes due to
changes in spreads is referred to as spread risk. A measure of how a spread
product’s price changes if the spread sought by the market changes is called
spread duration.

376
PORTFOLIO OPTIMIZATION AND RISK MEASURES
Spread duration measures are typically used to capture the spread risk.
There are three spread duration measures: nominal spread, zero-volatility
spread, and option-adjusted spread.
The nominal spread is the traditional spread measure. That is, it is the
difference between the yield on a spread product and the yield on a compa-
rable maturity Treasury issue. Thus, when spread is deﬁned as the nominal
spread, spread duration indicates the approximate percentage change in
price for a 100 basis points change in the nominal spread, holding the Trea-
sury yield constant. It is important to note that, for any spread product,
spread duration is the same as duration if the nominal spread is used. For
example, suppose that the duration of a corporate bond is 5. This means
that, for a 100 basis point change in interest rates, the value of the corporate
bond changes by approximately 5%. It does not matter whether the change
in rates is due to a change in the level of rates (i.e., a change in the Treasury
rate) or a change in the nominal spread.
The zero-volatility spread, or static spread, is the spread that, when
added to the Treasury spot rate curve, makes the present value of the
cash ﬂows (when discounted at the spot rates plus the spread) equal to
the price of the bond plus accrued interest. It is a measure of the spread over
the Treasury spot rate curve. When spread is deﬁned in this way, spread
duration is the approximate percentage change in price for a 100 basis
point change in the zero-volatility spread, holding the Treasury spot rate
curve constant.
The option-adjusted spread (OAS) is another spread measure that can
be interpreted as the approximate percentage change in price of a spread
product for a 100 basis point change in the OAS, holding Treasury rates
constant. So, for example, if a corporate bond has a spread duration of 3,
this means that if the OAS changes by 20 basis points, then the price of this
corporate bond will change by approximately 0.6% ( = 0.03 · 0.02 · 100).
We will encounter OAS again in Chapter 15, when we discuss mortgage-
backed securities.
The spread duration for a portfolio or a bond index is computed as a
market weighted average of the spread duration for each sector.
10.1.4
Credit Risk
The credit risk of a portfolio on a stand-alone basis or relative to a bench-
mark index can be gauged by the portfolio allocation to each credit rating.3
However, a better gauge is the contribution to duration by credit rating.
Basically, the portfolio is divided into groups of bonds with the same credit
rating, and the contribution to duration for each group is computed.

Fixed Income Portfolio Management in Practice
377
10.1.5
Estimating Value-at-Risk for Fixed
Income Securities
Even though the measures described in the previous sections in this chapter
are classical measures in bond portfolio management, many bond portfolio
managers use additional measures, such as VaR and CVaR,4 to obtain a
fuller picture of portfolio risk.
To estimate the VaR or the CVaR of a bond portfolio, we need to
simulate the distribution of possible values for the portfolio (or the total
return of the portfolio5) at the end of the holding period. This requires
the simulation of the term structure of interest rates. As we will explain in
Chapter 15, there is a large literature on interest rate models. We will need
the material in Chapters 12 and 15 to explain how term structure scenarios
can be generated. However, we can understand the intuition behind the
simulation now as well. Consider a simple example: Suppose that we are
trying to estimate the VaR of a $1 position in a bond with 10 years to
maturity after a one-year investment. We do the following:
■We calculate the initial price of the bond (given the yield curve observ-
able today).
■We generate scenarios for the future values of interest rates, and estimate
the price of the bond (given those future interest rates) after one year.
Let us call this price the “terminal price,” because it is at the end of the
investment horizon.
■In each interest rate scenario, we calculate the losses from the position as
the difference between the initial price and the terminal price (plus any
coupon payments, appropriately discounted, that happened between
today and one year from now).
■We now have a series of observations from losses for the bond position.
The VaR or the CVaR can be estimated using the techniques described
in Chapter 8.
Suppose we would like to incorporate not only interest rate risk, but
also credit risk, in our VaR or CVaR estimate. To do that, we would need
to take into consideration the following additional factors:
■The default process. A default is a binary event, and the cash ﬂows
associated with default are distributed far from normal. The only time
we can make the assumption of normality is if we have a lot of small
independent default events, in which case the Central Limit Theorem
applies.6

378
PORTFOLIO OPTIMIZATION AND RISK MEASURES
■The recovery rate. The recovery rate is the amount recovered in the event
of default. (The exact speciﬁcation of recovery rate depends on the credit
risk model used. For example, it could be measured as a percentage of
the expected cash ﬂows.)
■The dependence between market and default risk. Even though the two
are often assumed to be independent in many pricing models, the reality
is that the price difference between credit risky and riskless bonds will
depend on both types of risks in a complex way. In addition, the default
probability may change over time.
■The complicated nature of credit enhancement agreements that often
accompany credit risky positions. Such agreements include collateral
requirements, credit triggers, credit guarantee arrangements, and the
like. In practice, these agreements help the institution manage its credit
risk, but they make it more complicated to assess the actual impact of a
credit event on a bond portfolio.
These complications actually make simulation a good way to approach
the modeling of credit-risky positions. The procedure for evaluating the VaR
or CVaR of a credit risky bond is similar to the procedure for a nondefault-
able bond described earlier in this section. However, to evaluate future cash
ﬂows, we simulate the realizations of binary variables that tell us whether
the cash ﬂows are actually received. (Once a bond has defaulted, we make
sure that no future cash ﬂows are received.)
Estimating the VaR or the CVaR of a portfolio of credit risky bonds
(as opposed to a position in a single bond) is more complicated because
we need to simulate the dependencies between the defaults of the differ-
ent bonds. Such dependencies have been often modeled through different
types of copula functions.7 Through transformations of the original vari-
ables, copula functions allow for modeling dependence between the random
variables in a tractable way. The Gaussian copula is one such example.8
Gaussian copula dependency models in particular, however, have received
bad press after their failure to account for the high tail losses observed during
the ﬁnancial crisis of the fall of 2008. In addition, calibrating (i.e., ﬁnding
the input parameters for) such models is very difﬁcult in practice, because
historically there have been few observations of multiple defaults happening
simultaneously.
Let us now consider an example that takes advantage of both simulation
and optimization to manage the credit risk of a bond portfolio. Anderson,
Mausser, Rosen, and Uryasev (2001) describe an approach to optimizing
bond portfolios so as to minimize the losses stemming from credit risk
exposure. They consider a portfolio of 197 bonds from 29 different countries
with a market value of $8.8 billion and duration of approximately 5. The

Fixed Income Portfolio Management in Practice
379
goal is to rebalance the portfolio in order to minimize credit risk over a
one-year horizon, that is, to minimize losses resulting from default and from
a decline in market value because of downgrades in credit ratings.
To address the problem, they ﬁrst generate scenarios for the future
values of the losses due to credit migration (i.e., changes in the credit rating
of obligors). This is done by simulation. They simulate 20,000 scenarios of
joint credit states for bond issuers and the related losses. Based on these
scenarios, they can evaluate the total losses on all bonds in the portfolio,
equal to the sum of the differences between the value of each bond without
credit migration and the value of that bond with credit migration. Then, they
solve a CVaR minimization problem using the optimization formulation that
we presented in section 8.3.3 of Chapter 8.
10.2
THE SPECTRUM OF BOND PORTFOLIO
MANAGEMENT STRATEGIES
As in equity portfolio management, there is a spectrum of bond portfolio
management strategies that ranges from passive (pure index matching) to
active (completely at the portfolio manager’s discretion). This spectrum is
illustrated in Exhibit 10.1. The ﬁgure, developed by Volpert (1997) of the
Vanguard Group, shows the risk and return of a bond strategy versus a
benchmark. Volpert classiﬁes bond management strategies as follows:
■Pure bond index matching.
■Enhanced indexing/matching primary risk factor approach.
■Enhanced indexing/minor risk factor mismatches.
■Active management/larger risk factor mismatches.
■Active management/full-blown active.
The difference between indexing and active management is the extent
to which the portfolio can deviate from the primary risk factors that impact
the performance of an index. The primary risk factors associated with an
index are:
■The duration of the index
■The present value distribution of the cash ﬂows
■Percent in sector and quality
■Duration contribution of sector
■Duration contribution of credit quality
■Sector/coupon/maturity cell weights
■Issuer exposure control

380
PORTFOLIO OPTIMIZATION AND RISK MEASURES
Index
Enhanced Index
Active
Risk and Expected Return versus Benchmark
No Duration Bets
Duration Bets
• Pure Index
 Match (overly
 constrained)
• Attempted
 match issue
 by issue
 where
 possible
• No value
 judgments
• Matching
 Primary Index
 Risk Factors
• Duration
• Cash flows
• Sectors
• Quality
• Callability
• Fullblown
 Active
• Large
 duration
 mismatch
• Large sector
 and quality
 mismatch
• Larger
 Mismatches
• Cash flows
• Sectors
• Quality
• Callability
• Duration = 
 Index ± x%
• Minor
 Mismatches
• Cash flows
• Sectors
• Quality
• Callability
• Duration = 
 Index
EXHIBIT 10.1
Bond management spectrum.
Source: Exhibit 1 in Volpert (1997, 192).
The ﬁrst primary risk factor deals with the sensitivity of the value of the
index to a parallel shift in interest rates. The second factor is important for
controlling the yield curve9 risk associated with an index. We discuss the
different strategies and associated risk factors in more detail. Before we do
that, however, we provide some information on the most frequently used
bond indices.
10.2.1
Bond Market Indices
There is a wide range of bond market indices. They can be classiﬁed as
broad-based bond market indices, specialized bond market indices, and in-
ternational bond indices.
Broad-Based Bond Market Indices
The three broad-based bond market
indices most commonly used by institutional investors are the Barclays Cap-
ital U.S. Aggregate Index (previously the Lehman Brothers U.S. Aggregate
Index), the Salomon Smith Barney Broad Investment-Grade Bond Index
(SSBBIG), and the Merrill Lynch Domestic Market Index. There are more
than 5,500 issues in each index, and a strong correlation (of the order of
98%) between the three indices.

Fixed Income Portfolio Management in Practice
381
The three broad-based indices are computed daily and are market-value
weighted. This means that for each issue, the ratio of the market value of
an issue relative to the market value of all issues in the index is used as the
weight of the issue in all calculations. The securities in the SSBBIG index are
all trader-priced. For the two other indices, the securities are either trader-
priced or model-priced. Each index has a different way in which it handles
intramonth cash ﬂows that must be reinvested. For the SSBBIG index, these
cash ﬂows are assumed to be reinvested at the one-month Treasury bill rate,
while for the Merrill Lynch index, they are assumed to be reinvested in the
speciﬁc issue. There is no reinvestment of intramonth cash ﬂows for the
Barclays Capital index.
Each index is broken into sectors. The Barclays Capital index, for ex-
ample, is divided into the following six sectors: (1) Treasury, (2) agency,
(3) mortgage, (4) commercial mortgage-backed securities, (5) asset-backed
securities, and (6) credit.
The nature of sectors (3), (4), and (5) will become clearer in Chapter
15. The credit sector includes domestic corporate issues and U.S.-dollar-
denominated bonds of European issuers. The four sectors within the credit
sector are (1) ﬁnancial, (2) utility, (3) industrial, and (4) noncorporates.
All three indices exclude issues that are non-investment grade (i.e., below
BBB) and issues that have a maturity of one year or less. To be included in the
Barclays Capital index, the size of the issue must be more than $150 million;
for the Merrill Lynch and SSB indices, the issue size needs to be $50 million.
Only taxable issues are included in the broad-based bond market indices.
Specialized Bond Market Indices
The specialized bond market indices
focus on a sector or a subsector of the bond market. Indices on sectors of the
market are published by the three ﬁrms that produce the broad-based bond
market indices, as well as other brokerage ﬁrms and non-brokerage ﬁrms.
Moreover, there is a family of U.S. bond municipal indices. The Barclays
Capital municipal bond indices are the ones most commonly used. There
are specialized indices such as the managed money and insurance industry
tax-exempt indices to serve the benchmark needs of investor groups whose
permissible investments in the tax-exempt municipal bond market are not
likely to be met by the Barclays Capital Municipal Bond Index.
International Bond Indices
Indices that comprise international (i.e., not
only U.S.) bonds fall into three categories. The ﬁrst category is indices that
includes both U.S. and non-U.S. bonds. Such indices are referred to as global
bond indices or world bond indices. The Barclays Capital Global Aggregate
Bond Index is one such example.

382
PORTFOLIO OPTIMIZATION AND RISK MEASURES
The second category of international indices includes only non-U.S.
bonds. Such indices are commonly referred to as international bond indices
or ex-U.S. bond indices.
The third category includes specialized bond indices for particular non-
U.S. bond sectors. Two examples of this type of index are Barclays Capital’s
Pan-European Aggregate Index and the Asian-Paciﬁc Aggregate Index.
10.2.2
Pure Bond Indexing Strategy
In terms of risk and return, a pure bond index matching strategy minimizes
the risk of underperforming an index. The factors that explain the popular-
ity of bond indexing are similar to those for equity index strategies. First,
the empirical evidence suggests that historically the overall performance of
active bond managers has been worse than for passive managers. Second,
the advisory management fees charged for an indexed portfolio are lower
compared to active management advisory fees. Advisory fees charged by
active managers typically range from 15 to 50 basis points. The range for
indexed portfolios, in contrast, is 1 to 20 basis points (with the upper range
representing the fees for enhanced indexing discussed later).
Critics of indexing point out that while an indexing strategy matches the
performance of some index, the performance of that index does not necessar-
ily represent optimal performance. Moreover, matching an index does not
mean that the manager will satisfy a client’s return requirement objective.
For example, if the objective of a life insurance company or a pension fund
is to have sufﬁcient funds to satisfy a predetermined liability, indexing only
reduces the likelihood that performance will not be materially worse than
the index. The return on the index is not necessarily related to the liability.
Similarly to equities index strategies, pure bond indexing strategies in-
volve creating a portfolio so as to replicate the performance of the index.
And, similarly to equities index strategies, exact replication is too costly or
impossible. First, the prices for each issue used by the organization that pub-
lishes the index may not be the execution prices available to the portfolio
manager. Second, the prices used by organizations reporting the value of
indices are based on bid prices. However, portfolio managers must transact
at ask prices when constructing or rebalancing the indexed portfolio. Third,
there are logistical problems unique to certain sectors in the bond market.
For example, consider the corporate bond market. There are typically about
5,000 issues in the corporate bond sector of a broad-based market index.
Because of the illiquidity for many of the issues, not only may the prices
used by the organization that publishes the index be unreliable, but many
of the issues may not even be available. Finally, recall that the total return10
depends on the reinvestment rate available on interim cash ﬂows received

Fixed Income Portfolio Management in Practice
383
prior to month end. If the organization publishing the index regularly overes-
timates the reinvestment rate, then the indexed portfolio could underperform
the index.
10.2.3
Enhanced Indexing/Matching Primary Risk
Factors Approach
An enhanced indexing strategy can be pursued so as to construct a portfolio
to match the primary risk factors without acquiring each issue in the index.
Smaller funds often use this strategy because of the difﬁculties of acquiring
all of the issues comprising the index. Generally speaking, the fewer the num-
ber of issues used to replicate the index, the smaller the tracking error due to
transaction costs but the greater the tracking error risk because of the difﬁ-
culties of matching the primary risk factors perfectly. In contrast, the more
issues purchased to replicate the index, the greater the tracking error due to
transaction costs, but the smaller the tracking error risk due to the mismatch
of the primary factors between the indexed portfolio and the index.
10.2.4
Enhanced Indexing/Minor Risk
Factor Mismatches
Another enhanced strategy is one where the portfolio is constructed so as to
have minor deviations from the risk factors that affect the performance of the
index. For example, there might be a slight overweighting of issues or sectors
if the manager believes there is relative value. However, it is important to
point out that the duration of the constructed portfolio is matched to the
duration of the index. As Exhibit 10.1 shows, there are no duration bets
(i.e., duration is matched exactly) for the pure index match strategy and the
two enhanced index strategies.
10.2.5
Active Management/Larger Risk
Factor Mismatches
Active bond strategies attempt to outperform the market by intentionally
constructing a portfolio that will have a greater index mismatch than in the
case of enhanced indexing. The decision to pursue an active strategy or to en-
gage a client to request a portfolio manager to pursue an active strategy must
be based on the belief that there is some type of gain from such costly efforts;
for there to be a gain, pricing inefﬁciencies must exist. The particular strategy
chosen depends on why the portfolio manager believes this is the case.
Volpert (1997) classiﬁes two types of active strategies. In the more con-
servative of the two active strategies, the portfolio manager makes large

384
PORTFOLIO OPTIMIZATION AND RISK MEASURES
mismatches relative to the index in terms of risk factors. This includes mi-
nor mismatches of duration. Typically, there will be a limitation as to the
degree of duration mismatch. For example, the portfolio manager may be
constrained to be within ±1 of the duration of the index. So, if the duration
of the index is 4, the portfolio manager may have a duration that is between
3 and 5. Alternatively, if the manager believes that he can take advantage
of an anticipated reshaping of the yield curve, there can be signiﬁcant dif-
ferences in the cash ﬂow distribution between the index and the portfolio
constructed by the manager. As another example, if the portfolio manager
believes that issues rated A will outperform issues rated AA within the cor-
porate sector, the portfolio manager may overweight the issues rated A and
underweight issues rated AA.
10.2.6
Active Management/Full-Blown Active
In the full-blown active management case, the portfolio manager is permitted
to make a signiﬁcant duration bet without any constraint. The portfolio
manager can have a duration of zero (i.e., be all in cash) or can leverage
the portfolio to a high multiple of the duration of the index. The portfolio
manager can decide not to invest in only one or more of the major sectors
of the broad-based bond market indices. The portfolio manager can make a
signiﬁcant allocation to sectors not included in the index. For example, there
can be a substantial allocation to nonagency mortgage-backed securities.11
Active portfolio strategies and enhanced indexing/minor risk factor mis-
match strategies seek to generate additional return after adjusting for risk.
This additional return is popularly referred to as alpha.12 These strategies
are referred to as value added strategies and can be classiﬁed as strategic
strategies and tactical strategies.
Strategic strategies, sometimes referred to as top-down value added
strategies, involve the following:
■Interest rate expectations strategies.
■Yield curve strategies.
■Inter- and intrasector allocation strategies.
Tactical strategies, sometimes referred to as relative value strategies, are
short-term trading strategies. They include:
■Strategies based on rich/cheap analysis.
■Yield curve trading strategies.
■Return enhancing strategies employing futures and options.
Next, we discuss these strategies in more detail.

Fixed Income Portfolio Management in Practice
385
Interest Rate Expectations Strategies
A portfolio manager who believes
that he or she can accurately forecast the future level of interest rates will
alter the portfolio’s duration based on the forecast. Because duration is
a measure of interest rate sensitivity, this involves increasing a portfolio’s
duration if interest rates are expected to fall and reducing duration if interest
rates are expected to rise. For those portfolio managers whose benchmark is
a bond market index, this means increasing the portfolio duration relative
to the benchmark index if interest rates are expected to fall and reducing
it if interest rates are expected to rise. The degree to which the duration of
the managed portfolio is permitted to diverge from that of the benchmark
index may be limited by the client. Interest rate expectations strategies are
commonly referred to as duration strategies.
A portfolio’s duration may be altered in the cash market by swapping (or
exchanging) bonds in the portfolio for other bonds that will achieve the tar-
get portfolio duration. Alternatively, a more efﬁcient means for altering the
duration of a bond portfolio is to use interest rate futures contracts.13 Buying
futures increases a portfolio’s duration, while selling futures decreases it.
The key to this active strategy is, of course, an ability to forecast the
direction of future interest rates. The academic literature does not support
the view that interest rates can be forecasted so that risk-adjusted excess
returns can be consistently realized. It is doubtful whether betting on future
interest rates will provide a consistently superior return.
Yield Curve Strategies
As we explained in Chapter 2, the yield curve
for U.S. Treasury securities shows the relationship between maturity and
yield. The shape of the yield curve changes over time. A shift in the yield
curve refers to the relative change in the yield for each Treasury maturity.
A parallel shift in the yield curve refers to a shift in which the change in
the yield for all maturities is the same. A nonparallel shift in the yield curve
means that the yield for every maturity does not change by the same number
of basis points.
Top-down yield curve strategies involve positioning a portfolio to cap-
italize on expected changes in the shape of the Treasury yield curve. There
are three yield curve strategies: (1) bullet strategies, (2) barbell strategies,
and (3) ladder strategies. In a bullet strategy, the portfolio is constructed
so that the maturities of the bonds in the portfolio are highly concentrated
at one point on the yield curve. In a barbell strategy, the maturity of the
bonds included in the portfolio is concentrated at two extreme maturities.
Actually, in practice when managers refer to a barbell strategy it is rela-
tive to a bullet strategy. For example, a bullet strategy might be to create
a portfolio with maturities concentrated around 10 years, while a corre-
sponding barbell strategy might be a portfolio with 5-year and 20-year

386
PORTFOLIO OPTIMIZATION AND RISK MEASURES
maturities. In a ladder strategy the portfolio is constructed to have ap-
proximately equal amounts of each maturity. So, for example, a portfolio
might have equal amounts of bonds with one year to maturity, two years to
maturity, and so on.
Each of these strategies will result in different performance when the
yield curve shifts. The actual performance will depend on both the type of
shift and the magnitude of the shift. Thus, no general statements can be
made about the optimal yield curve strategy.
Inter- and Intrasector Allocation Strategies
A manager can allocate
funds among the major bond sectors that is different from that the allo-
cation in the index. This is referred to as an intersector allocation strategy.
In an intrasector allocation strategy, the portfolio manager’s allocation of
funds within a sector differs from that of the index.
In making inter- and intrasector allocations, a portfolio manager is an-
ticipating how spreads will change. Spreads reﬂect differences in credit risk,
call risk, and liquidity risk.14 When the spread for a particular sector or sub-
sector is expected to decline or “narrow,” a portfolio manager may decide to
overweight that particular sector or subsector. The sector or subsector will
be underweighted if the portfolio manager expects the spread to increase
or “widen.”
Credit spreads change because of expected changes in economic
prospects. Credit spreads between Treasury and non-Treasury issues widen
in a declining or contracting economy and narrow during economic expan-
sion. The economic rationale is that in a declining or contracting economy,
corporations experience a decline in revenue and cash ﬂow, making it dif-
ﬁcult for corporate issuers to service their contractual debt obligations. To
induce investors to hold non-Treasury securities, the yield spread relative to
Treasury securities must widen. The converse is that during economic expan-
sion and brisk economic activity, revenue and cash ﬂow pick up, increasing
the likelihood that corporate issuers will have the capacity to service their
contractual debt obligations. Yield spreads between Treasury and federal
agency securities will vary depending on investor expectations about the
prospects that an implicit government guarantee will be honored.
A portfolio manager can therefore use economic forecasts of the econ-
omy in developing forecasts of credit spreads. Also, some managers base
forecasts on historical credit spreads. The underlying principle is that there
is a “normal” credit spread relationship that exists. If the current credit
spread in the market differs materially from that “normal” credit spread,
then the portfolio manager should position the portfolio so as to beneﬁt
from a return to the “normal” credit spread. The assumption is that the
“normal” credit spread is some type of average or mean value and that

Fixed Income Portfolio Management in Practice
387
mean reversion will occur. If, in fact, there has been a structural shift in the
marketplace, this may not occur as the normal spread may change.
A portfolio manager will also look at technical factors to assess relative
value. For example, a manager may analyze the prospective supply and de-
mand for new issues on spreads in individual sectors or issuers to determine
whether they should be overweighted or underweighted. This commonly
used tactical strategy is referred to as primary market analysis.
Individual Security Selection Strategies
Once the allocation to a sector
or subsector has been made, the portfolio manager must decide on the
speciﬁc issues to select. This is because a manager will typically not invest in
all issues within a sector or subsector. Instead, depending on the dollar size
of the portfolio, the manager will select a representative number of issues.
It is at this stage that a portfolio manager makes an intrasector alloca-
tion decision to the speciﬁc issues. The portfolio manager may believe that
there are securities that are mispriced within a subsector and therefore will
outperform other issues within the same sector over the investment horizon.
There are several active strategies that portfolio managers pursue to identify
mispriced securities. The most common strategy identiﬁes an issue as under-
valued because either (1) its yield is higher than that of comparably rated
issues or (2) its yield is expected to decline (and price therefore rise) because
credit analysis indicates that its rating will be upgraded.
Once a portfolio is constructed, a portfolio manager may undertake a
swap that involves exchanging one bond for another bond that is similar in
terms of coupon, maturity, and credit quality, but offers a higher yield. This
is called a substitution swap and depends on a capital market imperfection.
Such situations sometimes exist in the bond market owing to temporary
market imbalances and the fragmented nature of the non-Treasury.15
10.2.7
Using Quantitative Methods for
Portfolio Allocation
The portfolio allocation strategies we described so far in this section are
often aided by quantitative approaches and software that enable portfolio
managers to sort through alternative strategies quickly. For example, there
are two methodologies used to construct a portfolio to replicate an index:
the stratiﬁed sampling and the optimization approach. Both approaches
assume that the performance of an individual bond depends on a number
of systematic factors that affect the performance of all bonds and on a
factor unique to the individual issue.16 This last risk is diversiﬁable risk. The
objective of the two approaches is to construct an indexed portfolio that
eliminates this diversiﬁable risk.

388
PORTFOLIO OPTIMIZATION AND RISK MEASURES
Stratified Sampling Approach
In the stratiﬁed sampling approach (or cel-
lular approach) to indexing, the index is divided into cells representing the
primary risk factors. The objective is then to select from all of the issues in
the index one or more issues in each cell that can be used to represent that
entire cell. The total dollar amount purchased of the issues from each cell
will be based on the percentage of the index’s total market value that the cell
represents. For example, consider two factors: credit quality and duration.
Imagine a table with rows that correspond to the different credit ratings17
and columns that correspond to different ranges for durations. In effect, we
have “buckets” in which we place all bonds under consideration depending
on their credit quality and duration.
The number of cells that the indexer uses will depend on the dollar
amount of the portfolio to be indexed. In indexing a portfolio of less than $50
million, for example, using a large number of cells would require purchasing
odd lots of issues. This increases the cost of buying the issues to represent
a cell, and hence increases the tracking error risk. However, reducing the
number of cells to overcome this problem also increases tracking error risk,
because the major risk factors of the indexed portfolio may differ materially
from those of the index.
Optimization Approach
In the optimization approach, the manager seeks
to design an indexed portfolio that will match the cell breakdown just as
described, but that will also satisfy other constraints, and optimize some
objective. An objective might be to maximize convexity or to maximize
expected total returns or to minimize tracking error.18 Constraints other
than matching the cell breakdown might include not purchasing more than
a speciﬁed amount of one issuer or group of issuers within the same strategy.
Although on the surface the stratiﬁed sampling approach is more
straightforward to use than the optimization approach, it is extremely dif-
ﬁcult to implement the stratiﬁed sampling approach when large, diversiﬁed
portfolios are taken as the benchmark. In this case, many cells are required,
and the problem becomes complex. Also, because the handpicking of issues
to match each cell is subjective, large tracking errors may result. Opti-
mization modeling reduces the work for the manager, allowing for efﬁcient
analysis of large quantities of data.
10.3
LIABILITY-DRIVEN STRATEGIES
Thus far, the bond portfolio strategies discussed in this chapter have focused
on managing funds relative to a benchmark that is a market index. In a
liability-driven strategy, the goal is to manage funds to satisfy contractual

Fixed Income Portfolio Management in Practice
389
liabilities. The two liability-driven strategies are immunization and cash ﬂow
matching. Insurance companies, sponsors of deﬁned beneﬁt pension plans,
and other institutions with liabilities often take advantage of such strategies.
10.3.1
Immunization Strategy for a
Single-Period Liability
Immunization is a hybrid strategy that has elements of both active and
passive strategies. Classical immunization can be deﬁned as the process by
which a bond portfolio is created so that it has an assured return for a
speciﬁc time horizon irrespective of interest rate changes. The following are
the important characteristics:
1. A speciﬁed time horizon.
2. An assured rate of return during the holding period to a ﬁxed horizon
date.
3. Insulation from the effects of potential adverse interest rate changes on
the portfolio value at the horizon date.
The fundamental mechanism underlying immunization is a portfolio
structure that balances the change in the value of the portfolio at the end
of the investment horizon with the return from the reinvestment of port-
folio cash ﬂows (coupon payments and maturing securities). That is, im-
munization requires offsetting interest rate risk and reinvestment risk. To
accomplish this balancing act requires controlling duration and setting the
present value of the cash ﬂows from the bond portfolio to the present value
of the liability. By setting the duration of the portfolio equal to the desired
portfolio time horizon, the offsetting of positive and negative incremental
return sources can under certain circumstances be assured. However, given
the fact that duration is the tool that is used, the portfolio is only immunized
if there is a parallel shift in the yield curve. If there is a change in interest
rates that does not correspond to this shape-preserving shift, matching the
duration to the investment horizon no longer assures immunization.
A Simple Example
Let us see an example of how immunization works.
Suppose we have a liability of $1,000,000 that must be paid ﬁve years
from now. We would like to invest enough money today to meet this future
obligation. Our investment universe consists of two bonds, B1 and B2, with
face values of $100, maturities of 12 years and 5 years, and coupon rates of
6% and 5%, respectively. For simplicity, we will assume that the coupons
are paid once per year (as opposed to semiannually). How much should we

390
PORTFOLIO OPTIMIZATION AND RISK MEASURES
EXHIBIT 10.2
Current yield curve, discount factors, cash ﬂows from bonds 1 and
2, as well as present values of cash ﬂows from the two bonds.
Year
Spot
df
B1
PV1
B2
PV2
1
3.64%
0.965
6
5.79
10
9.65
2
4.17%
0.922
6
5.53
10
9.22
3
4.70%
0.871
6
5.23
10
8.71
4
5.21%
0.816
6
4.90
10
8.16
5
5.45%
0.767
6
4.60
110
84.36
6
6.06%
0.703
6
4.22
7
6.43%
0.646
6
3.88
8
6.75%
0.593
6
3.56
9
7.10%
0.539
6
3.24
10
7.35%
0.492
6
2.95
11
7.57%
0.448
6
2.69
12
7.79%
0.406
106
43.09
Price of bond today
B1
89.66
B2
120.10
invest in the two bonds so that the overall portfolio (bonds and liability) is
immunized against changes in interest rates?
Exhibit 10.2 contains the current yield curve (column “Spot”), the dis-
count factors computed from the yield curve (column “df”), the cash ﬂows
from bonds 1 and 2 (columns “B1” and “B2”), and the present values of
the cash ﬂows from the two bonds (columns “PV1” and “PV2”). (See also
Excel workbook Ch10-Immunization.xlsx.) The current prices of the bonds
are determined by summing up the present values of the cash ﬂows for each
bond. They are $89.66 and $120.10, respectively.
Now let us compute the durations of the bonds and the liabilities. As
we explained in Chapter 2, duration can be interpreted as the change in the
value of the bond per unit change in interest rates, and the formula can be
stated as
D =
B−−B+
2 · B0 · y.
Exhibit 10.3 shows how the duration can be determined for bonds 1
and 2. We consider a shift in interest rates of y = 25 basis points,19 and
compute the new yield curves, present values, and bond prices if interest
rates shift up or down by this amount. The notation used is as follows: df–
and df+ are the discount factors under a negative shift and a positive shift
of the yield curve, respectively, PV1– and PV1+ are the present values of the

Fixed Income Portfolio Management in Practice
391
EXHIBIT 10.3
Effect of shift of y = 25 basis points on bond prices.
df−
PV1−
PV2−
df+
PV1+
PV2+
0.967
5.80
9.67
0.963
5.78
9.63
0.926
5.56
9.26
0.917
5.50
9.17
0.878
5.27
8.78
0.865
5.19
8.65
0.824
4.94
8.24
0.808
4.85
8.08
0.776
4.66
85.37
0.758
4.55
83.37
0.713
4.28
0.693
4.16
0.657
3.94
0.636
3.82
0.604
3.63
0.582
3.49
0.551
3.31
0.528
3.17
0.504
3.02
0.481
2.88
0.460
2.76
0.437
2.62
0.418
44.31
0.395
41.91
91.46
121.32
87.91
118.90
cash ﬂows for bond 1 under a negative shift and a positive shift of interest
rates, and similarly, PV2−and PV2+ are the present values of the cash ﬂows
for bond 2 under a negative shift and a positive shift of interest rates. The
bond prices are as follows: under a negative shift in interest rates, B1– =
$91.46 and B2– = $121.32. Under a positive shift in interest rates, B1+ =
$87.91 and B2+ = $118.90. This allows us to compute the durations for
the two bonds. For example, for bond 1, we have
D1 =
91.46 −87.91
2 · 89.66 · 0.0025 = 7.91.
Similarly, the duration for bond 2 can be computed to be 4.02.
To compute the duration of the liability of $1,000,000, we go through
a similar procedure. The 5-year spot rate is 5.45%, so the present value of
the liability is
1,000,000
(1 + 0.0545)5 = $766,950.05.
Under a negative shift in interest rates of 25 basis points, the value of
the liability becomes
1,000,000
(1 + 0.0545 −0.0025)5 = $776,106.46,

392
PORTFOLIO OPTIMIZATION AND RISK MEASURES
and under a positive shift in interest rates, it becomes $757,922.96. There-
fore, the duration of the liability is 4.74.
To immunize against interest rate changes, we look for the number of
units of bonds (x1 and x2) to invest so that the present value of the cash ﬂows
from the bonds equals the present value of the liability and the duration of
the portfolio of bonds matches the duration of the liability. How do we
compute the duration of the portfolio of bonds? Recall from section 10.1.1
in this chapter that the duration of the portfolio is the weighted average of
the durations of the individual bonds, where the weights are the weights
of the bonds in the portfolio. In this case, the weights can be expressed
as x1/(x1 + x2) and x2/(x1 + x2). (This is because (x1 + x2) is the total
amount invested.)
We need to solve the following system of equation, in which the un-
knowns are the number of units x1 and x2 to invest in bond 1 and bond 2,
respectively:
B1 · x1 + B2 · x2 = PV(Liability)
D1 · x1/(x1 + x2) + D2 · x1/(x1 + x2) = D(Liability)
In order to make this a linear system of equations, we will multiply both
sides of the second equation by (x1 + x2). Hence, we want to ﬁnd x1 and x2
that satisfy
B1 · x1 + B2 · x2 = PV(Liability)
D1 · x1 + D2 · x1 = D(Liability) · (x1 + x2)
This can be done with a simple linear optimization solver or a numerical
procedure. (In the case of two bonds, it is easy to solve by hand, but in the
case of larger portfolios it would require numerical implementation.) If we
have an optimization solver, the decision variables will be the number of
units to invest in bond 1 and bond 2, x1 and x2. We can minimize, for
example, the expression on the left hand side of the ﬁrst equation, subject to
constraints that are represented by the two equations.20 This will make sure
that the two equations are satisﬁed. In our example, the optimal solution is
to purchase 1,239.14 of bond 1 and 5,460.68 of bond 2.
Let us now verify that this investment will indeed cover the liability
if there are parallel shifts in the yield curve. Exhibit 10.4 summarizes the
information on the price of the bonds, the value of the liability, and the total
portfolio value under a positive and a negative shift of 1% (100 basis points)

Fixed Income Portfolio Management in Practice
393
EXHIBIT 10.4
Immunization results.
y = 0
y = 100 bp
y = –100 bp
Bond 1
Units
1,239.14
1,239.14
1,239.14
Price
$89.66
$82.93
$97.15
Bond 2
Units
5,460.68
5,460.68
5,460.68
Price
$120.10
$115.40
$125.07
Liability value
$766,950.05
$731,596.59
$804,373.54
Portfolio value (Bonds – Liability)
0
$1,324.19
−$1,048.30
in interest rates. We can see that the portfolio remains largely (although not
perfectly) immunized against changes in interest rates.21
Further Issues
How often should the portfolio be rebalanced to adjust
its duration? On the one hand, more frequent rebalancing increases trans-
action costs, thereby reducing the likelihood of achieving the target return.
On the other hand, less frequent rebalancing results in the portfolio’s du-
ration wandering from the target duration, which will also reduce the like-
lihood of achieving the target return. Thus a portfolio manager faces a
trade-off: some transaction costs must be accepted to prevent the portfolio
duration from wandering too far from its target, but some misalignment in
the portfolio duration must be tolerated, or transaction costs will become
prohibitively high.
In the actual process leading to the construction of an immunized port-
folio, the selection of the investment universe is extremely important. Im-
munization theory assumes there will be no defaults and that securities will
be responsive only to overall changes in interest rates. The lower the credit
quality permitted in the portfolio, the greater the likelihood that these as-
sumptions will not be met. Furthermore, securities with embedded options
such as call features or mortgage-backed prepayments complicate and may
even prevent the accurate estimation of cash ﬂows and hence duration, which
prevents immunization from achieving the desired effect. Finally, liquidity is
a consideration for immunized portfolios because, as just noted, they must
be rebalanced over time.
A natural extension of classical immunization theory is a technique for
modifying the assumption of parallel shifts in the yield curve. One approach
is a strategy that can handle any arbitrary interest rate change so that it

394
PORTFOLIO OPTIMIZATION AND RISK MEASURES
Portfolio A: High-risk immunized portfolio:
Portfolio B: Low-risk immunized portfolio:
A.
B.
Note: Portfolio duration matches horizon length. Portfolio’s cash flow dispersed.
Note: Portfolio duration matches horizon length. Portfolio’s cash flow
concentrated around horizon dates.
Portfolio
cash flow
Portfolio
cash flow
T = 0
Current date
T = H
Horizon date
Time
T = 0
Current date
T = H
Horizon date
Time
EXHIBIT 10.5
Immunization risk measure.
Source: Fabozzi (2009).
is not necessary to specify an alternative duration measure. The approach,
developed by Fong and Vasicek (1984), establishes a measure of immuniza-
tion risk against any arbitrary interest rate change. The immunization risk
measure can then be minimized subject to the constraint that the duration
of the portfolio is equal to the investment horizon, resulting in a portfolio
with minimum exposure to any interest rate movements.
One way of minimizing immunization risk is shown in Exhibit 10.5.
The spikes in the two panels of the exhibit represent actual portfolio cash
ﬂows. The taller spikes depict the actual cash ﬂows generated by matured
securities while the smaller spikes represent coupon payments. Both port-
folio A and portfolio B are composed of two bonds with duration equal
to the investment horizon. Portfolio A is, in effect, a barbell portfolio—a
portfolio comprising short and long maturities and interim coupon pay-
ments. For portfolio B, the two bonds mature very close to the investment
horizon and the coupon payments are nominal over the investment horizon,
so portfolio B is a bullet portfolio. It is not difﬁcult to see why the barbell
portfolio should be riskier than the bullet portfolio. Assume that both port-
folios have durations equal to the horizon length, so that both portfolios
are immune to parallel rate changes. This immunity is attained as a conse-
quence of balancing the effect of changes in reinvestment rates on payments
received during the investment horizon against the effect of changes in mar-
ket value of the portion of the portfolio still outstanding at the end of the
investment horizon.

Fixed Income Portfolio Management in Practice
395
When interest rates change in an arbitrary nonparallel way, however, the
effect on the two portfolios is very different. Suppose, for instance, that short
rates decline while long rates go up. Both portfolios would realize a decline
of the portfolio value at the end of the investment horizon below the target
investment value, since they experience a capital loss in addition to lower
reinvestment rates. The decline, however, would be substantially higher for
the barbell portfolio for two reasons. First, the lower reinvestment rates
are experienced on the barbell portfolio for longer time intervals than on
the bullet portfolio, so that the opportunity loss is much greater. Second, the
portion of the barbell portfolio still outstanding at the end of the investment
horizon is much longer than that of the bullet portfolio, which means that
the same rate increase would result in a much greater capital loss. Thus the
bullet portfolio has less exposure to whatever the change in the interest rate
structure may be than the barbell portfolio.
It should be clear from the foregoing discussion that immunization risk
is the risk of reinvestment. The portfolio that has the least reinvestment risk
will have the least immunization risk. When there is a high dispersion of
cash ﬂows around the horizon date, as in the barbell portfolio, the portfolio
is exposed to higher reinvestment risk. However, when the cash ﬂows are
concentrated around the horizon date, as in the bullet portfolio, the portfolio
is subject to minimum reinvestment risk.
10.3.2
Cash Flow Matching Strategy
The immunization strategy described in the previous section is used to im-
munize a portfolio created to satisfy a single liability in the future against
adverse interest rate movements. However, it is more common to have mul-
tiple future liabilities. One example is the liability structure of pension funds.
Another example is a life insurance annuity contract. It is possible to extend
the principles of immunization to multiple future liabilities. However, it is
more common in practice to use a cash ﬂow matching strategy. This strategy
is used to construct a portfolio that can fund a schedule of liabilities from
portfolio return and asset value, with the portfolio’s value diminishing to
zero after payment of the last liability.
A cash ﬂow matching strategy can be described intuitively as follows. A
bond is selected with a maturity that matches the last liability. An amount
of principal equal to the amount of the last liability is then invested in this
bond. The remaining elements of the liability stream are then reduced by
the coupon payments on this bond, and another bond is chosen for the
next-to-last liability, adjusted for any coupon payments of the ﬁrst bond se-
lected. Going backward in time, this sequence is continued until all liabilities
have been matched by payments on the securities selected for the portfolio.

396
PORTFOLIO OPTIMIZATION AND RISK MEASURES
However, optimization techniques are more effective for constructing a least-
cost cash ﬂow matching portfolio from an acceptable universe of bonds. We
saw an example of a using optimization to design a cash ﬂow matching
strategy in section 5.3.2 of Chapter 5.
SUMMARY
■Most generally, bond portfolio management strategies can be classi-
ﬁed in ﬁve categories: pure bond index matching, enhanced indexing/
matching primary risk factors approach, enhanced indexing/minor risk
factor mismatches, active management/larger risk factor mismatches,
and active management/full-blown active.
■The difference between indexing and active management is the extent
to which the portfolio can deviate from the primary risk factors as-
sociated with the index. The primary risk factors associated with an
index are: (1) the duration of the index, (2) the present value distri-
bution of the cash ﬂows, (3) percent in sector and quality, (4) dura-
tion contribution of sector, (5) duration contribution of credit quality,
(6) sector/coupon/maturity cell weights, and (7) issuer exposure control.
■Value added strategies seek to enhance return relative to an index and
can be strategic or tactical. Strategic strategies include interest rate ex-
pectations strategies, yield curve strategies, and inter- and intrasector
allocation strategies. Tactical strategies are short-term trading strategies
that include strategies based on rich/cheap analysis, yield curve trading
strategies, and return enhancing strategies employing derivatives (fu-
tures and options).
■Interest rate expectations strategies involve adjusting the duration of the
portfolio relative to the index based on expected movements in interest
rates. Top-down yield curve strategies involve positioning a portfolio to
capitalize on expected changes in the shape of the Treasury yield curve
by following either a bullet strategy, a barbell strategy, or a ladder
strategy.
■An intersector allocation strategy involves a manager’s allocation of
funds among the major bond sectors. In making inter- and intrasector
allocations, a manager is anticipating how spreads due to differences in
credit risk, call risk, and liquidity risk will change.
■Immunization and cash ﬂow matching are two liability-driven strategies
whose goal is to make sure that the investor can meet a schedule of
future liabilities.
■Classical immunization can be deﬁned as the process by which a bond
portfolio is created so that it has an assured return for a speciﬁc time

Fixed Income Portfolio Management in Practice
397
horizon irrespective of interest rate changes. It is accomplished by
matching the present value of the liability as well as the duration of
the liability. However, in practice immunization protects only against
parallel changes in the yield curve.
■A cash ﬂow matching strategy is used to construct a portfolio that
can fund a schedule of liabilities from portfolio return and asset value,
with the portfolio’s value diminishing to zero after payment of the last
liability.
■Optimization and simulation are valuable tools for bond portfolio risk
management. Optimization is used in portfolio allocation under differ-
ent measures of risk, such as tracking error relative to a benchmark,
or CVaR. Simulation aids in estimating portfolio interest rate risk and
portfolio credit risk by allowing the portfolio manager to understand
the performance of the portfolio under different scenarios.
NOTES
1. See Chapter 2 for deﬁnitions of callable bonds, asset-backed, and mortgage-
backed securities. We will discuss mortgage-backed securities in detail in Chap-
ter 15.
2. We come back to the concept of option-adjusted duration in section 15.5.1 of
Chapter 15.
3. See Chapter 2 for an introduction to credit ratings.
4. See Chapter 8.
5. See Chapter 2 for a deﬁnition of total return.
6. See section 3.11.1 of Chapter 3.
7. See, for example, Chapter 9 in Glasserman (2004).
8. MATLAB’s Statistical Toolbox has built-in functions, such as copularnd,
that allow for generating co-dependent random variables with a speciﬁc copula
function, such as the Gaussian or t-copula.
9. See Chapter 2 for a deﬁnition of a yield curve.
10. See Chapter 2 for a deﬁnition of the total return of a bond.
11. Such securities are discussed in Chapter 15.
12. The concept of alpha is discussed in more detail in Chapter 11.
13. Futures contracts are derivatives. Financial derivatives are explained in Chap-
ter 13.
14. Liquidity risk is the risk that issues will not be traded as quickly as anticipated.
See Chapter 2 for deﬁnitions of credit risk and call risk.
15. Swaps are ﬁnancial derivative contracts, which are discussed in Chapter 13.
16. This is referred to as a factor model. Factor models are discussed in detail in
Chapter 11.
17. See Exhibit 2.1 in Chapter 2.

398
PORTFOLIO OPTIMIZATION AND RISK MEASURES
18. See section 9.3 in the previous chapter for a mathematical deﬁnition of tracking
error.
19. This means that we change the interest rate for each maturity in the table by
the amount y.
20. See the Solver dialog box in the ﬁle Ch10-Immunization.xlsx.
21. Try different investment amounts to see that the change in the portfolio value
for a different number of units invested in the two bonds is worse. For example,
a combination of 1,000 units of bond 1 and 5,639.21 units of bond 2 also
results in a present value of $766,950.05, which offsets the present value of the
liability. However, if interest rates shift by 100 basis points, the value of the
overall portfolio is –$1,952.73 (in the case of a negative shift) and $2,094.94
(in the case of a positive shift), which is a larger discrepancy than in the case of
the immunized portfolio found in this section.

PART
Three
Asset Pricing Models


CHAPTER11
Factor Models
T
he investment management industry dedicates a large part of its resources
to forecasting future returns on securities. Quantitative ﬁnance practition-
ers use sophisticated mathematical models for calculating future returns.
Some of these models represent relationships between the returns of differ-
ent assets at any given point in time (cross-sectional relationships), and some
analyze time-dependent components of the movements of asset prices.
This chapter focuses on basic asset pricing models that establish links
between prices and returns and their lagged values or exogenous variables.
The latter variables are referred to as factors. When a factor is a measure
of risk, it is referred to as a risk factor. Predominantly, the justiﬁcation
of econometric models is empirical, that is, they are valid insofar as they
ﬁt empirical data. However, economic theory does offer some theoretical
justiﬁcation for factor models. The theoretical foundations of factor models
stem from the idea that in a well-functioning capital market, investors should
be rewarded for tolerating the risk that comes with investing in a security,
and therefore the return on these securities should be higher than the return
on a riskless security such as a Treasury bill. A part of the security’s risk
is shared by groups of other securities, while another part is unique to the
speciﬁc security. Therefore, some of the risk of a security can be understood
better by studying the underlying processes that determine how the economy
behaves.
To identify the relevant factors, we would use regression analysis, or
one of two econometric techniques, principal components analysis or factor
analysis, both of which we will introduce brieﬂy in this chapter. The factors
identiﬁed with the latter two techniques, referred to as statistical factors, are
not necessarily observable factors.
Our discussion begins with the classical factor models: the Capital Asset
Pricing Model and the Arbitrage Pricing Theory. Next, we discuss practical
issues in the estimation of factor models, and applications of factor models
for portfolio performance, risk decomposition, and optimization.
401

402
ASSET PRICING MODELS
This chapter does not directly deal with applications of simulation in
ﬁnance, although, as we mentioned, it does discuss the importance of factor
models in portfolio allocation decisions made using optimization (section
11.4.3 in this chapter). However, the concept of factor models is very im-
portant for more advanced asset pricing and risk estimation models, so it is
useful to touch upon this subject. Our focus in this chapter is on applica-
tions in equities; however, factor models are widely used in ﬁxed-income risk
management as well. We illustrate one application in the Practice section on
the companion web site.
11.1
THE CAPITAL ASSET PRICING MODEL
The ﬁrst asset pricing model was derived independently by William Sharpe
(1964), John Lintner (1965), and Jan Mossin (1966). They extended the mi-
croview of risk and return taken by Harry Markowitz (1952) in his statement
of the individual investor’s mean-variance problem to a statement about the
entire economy. Their model holds if every investor optimizes his portfolio
allocation by taking into consideration only the mean and the variance of his
portfolio, subject to some additional assumptions, such as (1) investors are
rational and risk-averse, (2) investors all invest for the same period of time,
(3) there is a risk-free asset, (4) all investors can borrow or lend any amount
at the risk-free rate, and (5) capital markets are perfectly competitive and
frictionless.
It turns out that, given that security prices must clear in equilibrium, this
assumed investor behavior implies something very speciﬁc about the returns
of assets.1 More precisely, the expected return E(˜ri) on any security i in the
market should follow the equality
E(˜ri) = rf + βi(E(˜rM) −rf ).
Here rf is the risk-free return (the return on a Treasury bill), rM is the
return on the market, and
βi = Cov(˜ri, ˜rM)
Var(˜rM) .
The equation E(˜ri) is known as the Capital Asset Pricing Model
(CAPM), and has had a signiﬁcant impact on investment theory over the
last ﬁve decades. The importance of Sharpe’s contribution to ﬁnance the-
ory and practice was recognized in 1990, when he was awarded the Nobel
Memorial Prize in Economic Sciences together with Harry Markowitz and
Merton Miller.

Factor Models
403
An alternative equivalent way of writing the equality is
E(˜ri) −rf = βi(E(˜rM) −rf ) + εi.
In words, this pricing model states that the excess return (i.e., return
over the risk-free rate) on any security should be proportional to the excess
market return. The coefﬁcient βi is known just as that: “beta.” It can be
interpreted as the sensitivity of the speciﬁc security’s return to changes in the
market return. For example, a beta of 1 means that the return of a security
is perfectly correlated with the market return: for every point increase in
excess market return, the excess return on the security should increase by
one point. Beta is used as a measure of systematic risk; that is, risk that is
exogenous to the particular security and is associated with the market itself.
The remaining variability in the security’s returns is nonsystematic risk; that
is, risk that is speciﬁc to the security itself.
A security’s beta can be estimated from a set of observed returns for the
security and the market return using the following simple linear regression:2
rit −rft = αi + βi · (rMt −rft) + eit
where
rit is the observed return on security i for time t.
rft is the observed return on the risk-free asset for time t.
rMt is the observed return on the market portfolio for time t.
eit is the error term for time t.
This equation (the equation of a line in the space determined by x coordi-
nate (rM −rf) and y coordinate (ri −rf) describes the so-called characteristic
line. The characteristic line can be expressed as
yt = αi + βi · xt + εit.
Note that, technically, the intercept term αi should be statistically equiv-
alent to 0 in order for this equation to be consistent with the CAPM. The
intercept term has a speciﬁc interpretation in portfolio performance analysis,
as will be explained in section 11.4.1.
To estimate the characteristic line for a security using regression analysis,
we consider three time series of returns for (1) the security, (2) the market
portfolio, and (3) the risk-free rate. Consider, for example, the monthly data
on Oracle stock returns in the ﬁle Ch11-Beta.xlsx. For the market portfolio,
we used the Standard & Poor’s 500 (S&P 500) and for the risk-free rate we
used the returns for the one-month Treasury bill rate. The estimate obtained

404
ASSET PRICING MODELS
for beta is 1.41. This means that if the market excess return is up by a
point, we would expect the Oracle excess return to be up by 1.41 points
on average. Clearly, the beta estimates will vary with the particular market
index selected as well as with the sample period and the observations used
(i.e., daily, weekly, monthly).
Some researchers and practitioners estimate a stock’s beta by using re-
turns rather than excess returns in the equation above. The estimated regres-
sion model is referred to as the single-index market model. This model was
ﬁrst suggested by Markowitz (1959) as a proxy measure of the covariance
of a stock with an index so that the full mean-variance analysis need not be
performed. While the approach was mentioned by Markowitz in a footnote
in his book, it was Sharpe (1963) who investigated it further. It turns out that
the betas estimated using the characteristic line and the single-index market
model do not differ materially. In the Oracle example, the beta estimated
with the single-index market model is 1.40—within a rounding difference
of the beta estimated with the characteristic line. (See section 11.3.1 in for
more detailed interpretation of the regression output and the Software Hints
for instructions on how to run regression with Excel and MATLAB.)
The CAPM has come under much scrutiny over the past 50 years.
Note that it can only be tested if the market portfolio can be identiﬁed,
which is not easy. Is the market portfolio a domestic or an international
portfolio? Does the market portfolio include, for example, real estate? In
practical applications, these issues are not of as much concern because typ-
ically the candidates for the market portfolio are very highly correlated.
One can use stock indices such as the Russell 3000, or composite indices.
It comes as no surprise, however, that the stock beta estimates reported in
different publications (Yahoo Finance, Wall Street Journal, etc.) may vary
signiﬁcantly.
It has been established also that the assumptions on which the CAPM
is based do not hold in the real world. Namely, investor behavior is not
inﬂuenced only by means and variances of returns, but also other parameters
such as skewness and kurtosis. Empirically, it has been observed also that
return distributions do not follow the distribution assumed by the CAPM.
That is, real-world asset returns are not normally distributed. The ideas and
the terminology introduced by the CAPM, however, continue to be widely
used in investment practice today.
11.2
THE ARBITRAGE PRICING THEORY
The Arbitrage Pricing Theory (APT), developed by Stephen Ross (1976),
starts from a different vantage point than the CAPM. Instead of making
assumptions on investment behavior or asset return distributions, it assumes

Factor Models
405
that there are a limited number of independent factors inﬂuencing returns.
Namely, asset returns can be expressed as
˜ri = E(˜ri) + βi1 ˜f1 + · · · βi K ˜fK.
It turns out that the CAPM is a special case of the APT, in which there
is only one factor—the market. However, the APT provides a more ﬂexible
and general framework that is more consistent with numerous studies on
returns.
The derivation of the APT is based purely on arbitrage principles. We
will explain the basics of arbitrage as a concept in detail in Chapter 13,
and will not go through the formal derivation of the APT here. Instead, let
us discuss several major advantages of the APT over the CAPM. First, the
APT makes less restrictive assumptions about investor preferences toward
risk and return than the CAPM. While the CAPM requires that investors
consider trade-offs between risk and return solely on the basis of the expected
returns and standard deviations of prospective investments, the APT simply
requires that some bounds be placed on investors’ utility functions.3 Second,
the APT is a “relative” pricing model, in the sense that it prices securities
on the basis of the prices of other securities. By contrast, the CAPM is an
“absolute” pricing model, in the sense that it relates returns on the securities
to the fundamental source of risk inherent in the portfolio of total wealth.
Finally, the APT does not rely on identifying the market portfolio, and does
not require any assumptions about the distribution of asset returns except
for the factor structure.
From a practical point of view, multifactor asset pricing models rather
than single-factor models have long shown better promise. Regression-based
tests seeking to dispute the CAPM have helped to identify factors that have
been found to be statistically signiﬁcant in explaining the variation in asset
returns. Typically, these factors fall into one of three categories:
1. External (economic) factors, such as gross domestic product (GDP), con-
sumer price index (CPI), unemployment rate, credit spreads on bonds,
and the steepness of the yield curve.
2. Fundamental factors (ﬁrm characteristics), such as the price-earnings
ratio, the dividend-payout ratio, the earnings growth forecast, and ﬁ-
nancial leverage.4
3. Extracted (statistical) factors, such as the return on the market portfolio
(computed as the compilation of returns on the individual securities) and
the average of the returns of stocks in a particular industry (utilities,
transportation, aerospace, etc.). Factors can be computed also through
the methods of principal component analysis or factor analysis, as we
will explain in section 11.3.

406
ASSET PRICING MODELS
Proprietary multifactor models are widely used in industry. For exam-
ple, Robert Jones (1998) of Goldman Sachs Asset Management reported
factors found in the U.S. stock market for the period 1979 through 1996.
He regressed monthly stock returns against “value,” “momentum,” and
“risk” factors. The value factors included four ratios: book-market ratio,
price-earnings ratio, sales-price ratio, and cash ﬂow-price ratio. The three
momentum factors included estimate revisions for earnings, revisions ratio,
and price momentum. The ﬁrst risk factor was the systematic risk or beta
from the CAPM.5 The second risk factor was the residual risk from the
CAPM; this is the risk not explained by the CAPM. The third risk factor
was an uncertainty estimate measure. The factors were beginning-of-month
values that are properly lagged where necessary.6 Jones calculated the av-
erage monthly regression coefﬁcient and t-statistic for the series. All of the
factors were found to be highly statistically signiﬁcant. The conclusion from
the regression results was that there are factors other than the CAPM beta
that explain returns.
Some well-known factor models for the equity market are the mod-
els developed by Chen, Roll, and Ross (1986), Fama and French (1993,
1995, 1996, 1998), MSCI Barra, and Northﬁeld Information Services. For
example, an old version of MCSI Barra’s factor model included 13 risk
indices, such as volatility, momentum, size, and trading activity, and 55
industry groups, further classiﬁed into 13 sectors: basic materials, energy,
consumer noncyclicals, consumer cyclicals, consumer services, industrials,
utility, transport, health care, technology, telecommunications, commercial
services, and ﬁnancial services (Barra 1998). As an example, the energy
sector comprises the following three industries: energy reserves and produc-
tion, oil reﬁning, and oil services. Given the risk factors, information about
the exposure of every stock i to each risk factor k (βi,k) is estimated using
regression analysis.
11.3
BUILDING MULTIFACTOR MODELS
IN PRACTICE
The APT provides a theoretical framework for asset pricing models that
improve risk measurement and estimation by attributing it to multiple fac-
tors. Unfortunately, the APT does not explain how one may ﬁnd these
factors. Moreover, while these theoretical models are focused on estimat-
ing expected returns for long-term asset allocation, they are of little use
in everyday trading. As we mentioned at the end of the previous section,
practitioners usually employ sophisticated proprietary methods for return
estimation. These methods are typically based on statistical techniques for
identifying factors that drive returns and allow for establishing an advantage

Factor Models
407
in asset allocation and trading by virtue of knowing something about how
these underlying factors behave. By identifying the important factors that
contribute to changes in security prices, portfolio managers can control
portfolio risk more effectively.
There are two philosophically different approaches to identifying such
factors. The ﬁrst is to start by stating a hypothesis about which market fac-
tors inﬂuence returns, and then test whether the data conﬁrm the hypothesis.
The statistical technique used to test the hypothesis is regression analysis.
The second approach is to “let the data speak for themselves.” We start
with data on security returns, and try to identify underlying factors by ob-
serving groups of securities that exhibit strong correlations in returns. The
statistical methodology used to identify such factors is called factor analysis.
While factor analysis helps to identify sources of risk common to groups of
securities, it does not identify what these sources are.
Principal component analysis is also used in the context of empirical
multifactor model building. It also attempts to identify factors that underlie
asset return processes, but its general goal is to reduce the dimension of the
representation, that is, to identify factors one by one in such a way that
the ﬁrst factor explains the largest percentage of the variability in the data;
the second factor explains the second-largest percentage of the variability
in the data, and so on. This enables the modeler to drop from consideration
factors that contribute relatively little to the explanatory power of the model.
The factors discovered by principal components analysis are also orthogonal
to each other, that is, they are uncorrelated, which can be very useful for
modeling purposes.
A comprehensive review of these approaches is beyond the scope of
this book, but we provide some intuition and detail next.7 Understanding
how a security’s risk can be attributed to different factors is important
not only because it helps with the estimation of parameters of interest to
portfolio managers. It also reduces substantially the computational burden
of optimizing a portfolio and simulating possible states of the world in order
to evaluate portfolio risk. We will come back to this point in section 11.4.3
of this chapter and Chapter 16.
11.3.1
Regression Analysis
In regression analysis, the modeler speciﬁes the factors he thinks drive the
covariation in asset returns, and the statistical analysis conﬁrms or rejects
this hypothesis. A regression equation assumes a linear relationship between
the returns and the factors, that is, it assumes that the return on a particular
stock i can be represented as
ri = αi +
K

k=1
βik · fk + εi,

408
ASSET PRICING MODELS
where αi is the mean return, f 1, . . . , fK are the K factors, βik are the coef-
ﬁcients in front of the factors, and εi is the residual error. In practice, the
linearity assumption is not very restrictive because nonlinear relationships
can be represented by transforming the data.
The factors fk in this regression are the explanatory variables (also called
independent variables). They help explain the variability in the response
variable (also called dependent variable) ri.
Exhibit 11.1 contains regression output obtained with Excel. Even
though the output formats for different statistical packages differ, the in-
formation conveyed in them is standard, so we will use the Excel output in
Exhibit 11.1 to discuss the most important terms.
The value for the coefﬁcient beta in front of the explanatory variable (the
S&P 500 excess return in our example) is 1.40556642 (cell B18). This value
tells us the amount of change in the response variable when the explana-
tory variable increases by one unit. (In a regression with multiple explanatory
variables, we would also have to hold the values of the other explanatory
variables constant.) The value of the intercept alpha is −0.005062781 (cell
B17). The intercept tells us the value of the response variable if the values
for all explanatory variables are zero. If the regression coefﬁcient beta is
statistically different from 0, the explanatory variable to which the regres-
sion coefﬁcient corresponds will be signiﬁcant for explaining the response
variable. To check whether the regression coefﬁcient is statistically differ-
ent from zero, we can check its p-value (cell E18) or the conﬁdence inter-
val associated with the coefﬁcient (cells F18:G18). If the p-value is small
EXHIBIT 11.1
Excel regression output for the beta estimation example in
section 11.1.1.

Factor Models
409
(generally, less than 5% is considered small enough), then the beta coef-
ﬁcient is statistically different from zero. In this example, the p-value is
0.000113, so we can conclude that the S&P 500 excess return is a signif-
icant factor for forecasting the Oracle stock returns. The same conclusion
can be reached by checking whether zero is contained in the conﬁdence in-
terval for the regression coefﬁcient. In this case, the 95% conﬁdence interval
for beta is (0.726236179, 2.084896661). Zero is not contained in the in-
terval; therefore, the beta coefﬁcient is statistically different from zero, and
the S&P 500 excess return is a signiﬁcant factor for forecasting the Oracle
stock returns.
There are several other statistics we should consider in evaluating the
regression model. The p-value for the F-statistic (cell F12), which in Excel
appears as “Signiﬁcance F,” tells us whether the regression model as a whole
is statistically signiﬁcant, i.e., whether the model explains a large part of the
variability in asset returns. Since in our example the p-value is small, the
regression model is signiﬁcant.
Three measures of goodness of ﬁt are reported as standard output for
a regression. The coefﬁcient of determination R2 (which in Excel appears
as “R square” in cell B5) tells us what percentage of the variability of the
response variable is explained by the explanatory variable. The higher the
number, ranging from 0% to 100%, the better it is. In this example, 22.82%
of the variability in Oracle excess returns can be explained by the variability
in the S&P 500 excess returns. The problem with R2 is that as the number
of explanatory variables (factors) increases, R2 stays the same or continues
to increase, even if the additional factors are not important. To control for
that, in multiple regression models one typically uses the Adjusted R2 (cell
B6), which penalizes the model for having too many explanatory variables,
rather than the R2.
Another measure of goodness of ﬁt is the standard error of the regression
(cell B7), which equals the standard deviation of the regression residuals. The
units of the standard error are the units of the residuals, which are also the
units of the response variable. In our example, a standard error of 0.1126
tells us that the forecasts for the Oracle excess returns based on this regres-
sion model will be on average 0.1126 off from the real Oracle excess returns.
In order for the regression model to be valid, we need to check that three
residual assumptions are satisﬁed:
■The residuals ε follow a normal distribution.
■The residuals ε exhibit homoschedasticity, that is, they have the same
variability independently of the values of the response and the explana-
tory variables.
■The residuals ε are not autocorrelated, that is, they do not exhibit pat-
terns with the order of the data in the data set.

410
ASSET PRICING MODELS
Many statistical software packages produce graphs that allow for check-
ing these assumptions as part of the standard regression output.
In regression models with multiple explanatory variables, we are also
concerned about multicollinearity, which happens when the explanatory
variables are highly correlated among themselves. This makes the estimates
of the regression coefﬁcients (the betas) meaningless because they can take
on multiple values; inﬂates the value of the R2 of the regression artiﬁcially,
and leads to estimates of the p-values and other measures of the signiﬁcance
of the regression coefﬁcients that cannot be trusted. To check for multi-
collinearity, we would examine the correlation matrix and other measures
of codependence such as the variance inﬂation factors (VIFs), which are
standard output in advanced statistical packages.
Finally, when we build factor models, there is a trade-off between ﬁnd-
ing a model with good explanatory power and parsimony, that is, limiting
the number of factors that go into the model. On the one hand, we want
to include all factors that are signiﬁcant for explaining returns. On the
other hand, including too many factors requires collecting a lot of data,
and increases the risk of problems with the regression model, such as mul-
ticollinearity.
11.3.2
Factor Analysis
To illustrate the main idea behind factor analysis, let us begin with a simple
nonﬁnance example. Suppose that we have the grades for 1,000 students
in nine different subjects: literature, composition, Spanish, algebra, calcu-
lus, geometry, physics, biology, and chemistry. If we compute the pairwise
correlations for grades in each subject, we would expect to ﬁnd higher cor-
relations between grades within the literature, composition, Spanish group
than between grades in, say, literature and calculus. Suppose we observe that
we have high correlations for grades in the literature, composition, Spanish
group, high correlations for grades in the algebra, calculus, geometry group,
and high correlations for grades in the physics, biology, chemistry group.
There will still be some correlations between grades in different groups, but
suppose that they are not nearly as high as the correlations within the groups.
This may indicate that there are three factors that determine a student’s per-
formance in these subjects: a verbal aptitude, an aptitude for math, and an
aptitude for science. A single factor does not necessarily determine a stu-
dent’s performance; otherwise all correlations would be 0 or 1. However,
some factors will be weighted more than others for a particular student.
Note, by the way, that these factors (the aptitudes for different subjects) are
invisible. We can only observe the strength of the correlations within the

Factor Models
411
groups and between them, and we need to provide interpretation for what
the factors might be based on our intuition.
How does this example translate for ﬁnancial applications? Suppose we
have data on the returns of N stocks. You can think of the returns as the
grades recorded for N different students. We compute the pairwise correla-
tions between the different stock returns, and look for patterns. There may
be a group of stocks for which the returns are highly correlated. All stocks in
the group receive a large portion of their earnings from foreign operations,
so we may conclude that exchange risk is one underlying factor. Another
group of highly correlated stocks may have high debt-to-equity ratios, so we
may conclude that the level of interest rates is another underlying factor. We
proceed in the same way, and try to identify common factors from groups
that exhibit high correlations.
There is a speciﬁc statistical technique for computing such underlying
factors. Most advanced statistical packages have a function that can per-
form the calculations. Excel’s statistical capabilities are unfortunately not
as advanced, but MATLAB’s Statistical Toolbox contains the function
factoran, which allows a user to provide the data, specify the number
of factors (which he can try to guess based on the preliminary analysis and
intuition), and obtain the factor loadings. The factor loadings are the coefﬁ-
cients in front of the factors that determine how to compute the value of the
observation (the grade or the stock return) from the hidden factors, and can
be interpreted as the sensitivities of the stock returns to the different factors.
A factor model equation in fact looks like the familiar regression equation;
the difference is in the way the factors are computed. The output from run-
ning factor analysis with statistical software on our data set of stock returns
will be a model
ri = αi +
K

k=1
βik · fk + εi
or, in terms of the vector of returns for the assets in the portfolio,
r = α + B · f + ε,
where α is the N-dimensional vector of mean returns, f is the K-dimensional
vector of factors, B is the K × N matrix of factor loadings (the coefﬁcients in
front of every factor), and ε is the N-dimensional vector of residual errors.
The problem with the factor analysis procedure is that even if we have
accounted for all the variability in the data and have identiﬁed the factors
numerically, we may not be able to provide a good interpretation of their

412
ASSET PRICING MODELS
meaning. This makes factor analysis difﬁcult to apply for risk management
purposes.
11.3.3
Principal Components Analysis
Principal components analysis (PCA) is similar to factor analysis in the sense
that the goal of the statistical procedure is to compute factors (principal
components) out of a given set of data that explain the variability in the
data. These factors are statistical, that is, they are not input by the user, but
computed by software. However, the difference is that the main goal of PCA
is to ﬁnd uncorrelated factors in such a way that the ﬁrst factor explains as
much of the variability in the data as possible, the second factor explains
as much of the remaining variability as possible, and so on. PCA is even
less concerned with interpretation of the factors than factor analysis is, and
this is a drawback in the sense that it is difﬁcult to use the results from
PCA for understanding portfolio risk. However, PCA models are helpful for
modeling purposes8 and can be used as a way to reduce the dimensionality
of the data. Let us explain the latter point in more detail.
As mentioned earlier, each subsequent principal component explains a
smaller portion of the variability in the original data. If we observe that a
large percentage of the variability in the original data is explained by the ﬁrst
few components, we can drop the remaining components from considera-
tion. For example, if we have data for the returns on 1,000 stocks and ﬁnd
that the ﬁrst seven principal components explain 99% of the variability, we
can drop the other principal components, and model only with seven vari-
ables (instead of the original 1,000). The representation of the data will in a
sense be “inverse” to the original representation: each principal component
will be expressed as a linear combination of the original data. For example,
if we are given N stock returns r1, . . . , rN, the principal components x1, . . . ,
xN will be given by
xk =
N

i=1
βik · ri.
As with factor analysis, most advanced statistical packages have a func-
tion that can compute the principal components for a set of data. There is no
such function in Excel; however, MATLAB’s Statistical Toolbox contains
the function princomp, which allows a user to provide the data and obtain
useful output such as the coefﬁcients in front of the original data, that is, βik
in the equation above, the scores (i.e., the principal components themselves),
and the percentage of the variability of the original data explained by each
principal component.

Factor Models
413
11.4
APPLICATIONS OF FACTOR MODELS IN
PORTFOLIO MANAGEMENT
In this section, we review several applications of factor models in portfolio
management. The list of applications is by no means exhaustive. We discuss
a classical portfolio performance measure, portfolio risk decomposition,
and mean-variance optimization. Factor models are also widely used when
pricing ﬁxed-income securities and ﬁnancial derivative contracts by Monte
Carlo simulation.
11.4.1
Portfolio Performance Measurement
In evaluating the performance of a money manager, one must adjust for the
risks accepted by the manager in generating return. Asset pricing models
such as the CAPM or a multifactor model provide the expected return after
adjusting for risk.
Various measures have been used to assess performance based on the
excess return. One such measure is the Jensen measure (also called the Jensen
index). In 1968, Michael Jensen used simple linear regression to analyze the
performance of mutual fund managers. Basically, using time-series data for
the return on the portfolio managed by the particular fund manager and
the market index, Jensen estimated the same regression as the characteris-
tic line explained in section 11.1. The intercept term, αi, is interpreted as
the unique return realized by the portfolio manager and is the estimated
value of the Jensen measure. A statistically signiﬁcant intercept term that
is positive means that the portfolio manager outperformed the market; a
negative value means that the portfolio manager underperformed the mar-
ket. The Jensen measure is appropriate only when the portfolio is diversi-
ﬁed. Hence, there are limitations in applying this measure to hedge funds,
for example.
When Jensen proposed the model for measuring performance, he used
the Greek letter alpha to represent the intercept term in the regression equa-
tion, as we did in section 11.1. Hence, the Jensen measure is also called the
Jensen alpha. Consequently, the market sometimes refers to the “alpha” of
a portfolio manager as a measure of performance. However, the concept of
alpha used today in the investment industry is not the Jensen measure but
rather the average excess return (also called active return) over a period of
time. The active return is the difference between the return of a portfolio
and the return of a benchmark index. Notice that unlike the Jensen measure
or Jensen alpha, measuring performance by the average active return does
not adjust for market risk.

414
ASSET PRICING MODELS
11.4.2
Risk Decomposition in Equity Portfolios
As explained earlier in this chapter, the CAPM is not the typical asset pric-
ing model used by professional money manager today. Rather, multifactor
models are used. Money management ﬁrms will either develop proprietary
multifactor models or use factor models provided by vendors such as MSCI
Barra and Northﬁeld Information Services. The multifactor models are used
to evaluate exposure to different risk factors and to monitor performance.
The predicted return for a portfolio can be computed from the factor
models for the returns on the individual assets in the portfolio. The exposure
to a given risk factor of a portfolio is simply the weighted average of the
exposure of each stock in the portfolio to that risk factor. For example,
suppose a portfolio has 42 stocks. Suppose further that stocks 1 through
40 are equally weighted in the portfolio at 2.2%, stock 41 is 5% of the
portfolio, and stock 42 is 7% of the portfolio. Then the exposure of the
portfolio to risk factor k is
0.022 · β1,k + 0.022·β2,k + · · · + 0.022 · β40,k + 0.050 · β41,k + 0.007 · β42,k
This expression can then be added as a constraint in the portfolio
construction process using an optimizer, as explained in section 9.2.4 of
Chapter 9.
The nonfactor error term is measured in the same way as in the case of
an individual stock. However, in a well diversiﬁed portfolio, the nonfactor
error term will be considerably less for the portfolio than for the individual
stocks in the portfolio.
Limiting the number of factors for portfolio risk management purposes
has a number of advantages. First, an asset’s sensitivity to a particular source
of risk may be a lot more stable over time than its sensitivity to other
securities in the portfolio. Second, having fewer sources of risk to estimate
and control simpliﬁes the portfolio management process signiﬁcantly.
In addition to decomposing the total portfolio risk in a useful way for
the purposes of portfolio allocation, multifactor risk models have the beneﬁt
of enabling managers and clients to decompose risk in order to assess the
performance, both potential and actual, of a portfolio relative to factors or
a benchmark. The idea is similar to the portfolio performance evaluation
idea explained in section 11.4.1.
11.4.3
Efficient Mean-Variance Optimization
The real usefulness of a linear multifactor model lies in the ease with which
the risk of a portfolio with a large number of assets can be estimated.

Factor Models
415
Consider a portfolio with N assets. As we explained in Chapter 7, risk is
traditionally deﬁned as the variance of the portfolio’s returns. So, in this
case, we need to ﬁnd the covariance matrix of the N assets. That would
require us to estimate N variances (one for each of the N assets) and N
· (N-1)/2 covariances. If we have a portfolio of 1,000 assets, this means
we need to estimate 1,000 variances and 499,500 covariances. Adding the
1,000 estimates of expected returns (one for each asset), this is a total of
501,500 values to estimate, a very difﬁcult undertaking.
Suppose, instead, that we use a three-factor model to represent asset
returns. Then, we need to estimate (1) the three factor loadings (the beta
coefﬁcients) for each of the 1,000 assets (i.e., 3,000 values); (2) the six
values of the factor variance-covariance matrix; and (3) the 1,000 residual
variances (one for each asset). That is, in all, we need to estimate only
4,006 values. This represents a 99% reduction from the original number of
501,500 values, a huge improvement. Hence, with well-chosen factors, we
can substantially reduce the work involved in estimating a portfolio’s risk.
From a statistical estimation point of view, factor covariance matrices also
tend to be much more stable and reliable than asset covariance matrices.
Let us explain how the portfolio optimization would be done when asset
returns are expressed through factors. Suppose that the vector of N asset
returns r can be written as
r = α + B · f + ε,
where α is the N-dimensional vector of mean returns, f is the K-dimensional
vector of factors, B is the K × N matrix of factor loadings (the coefﬁcients in
front of every factor), and ε is the N-dimensional vector of residual errors.
If the portfolio weights invested in each asset are represented by the
N-dimensional vector w, it is easy to see that the expected excess portfolio
return can be written as
α′ · w,
the expected portfolio return can be written as
α′ · w + B · f · w,
where f is the vector of factor means, and the variance of the portfolio return
can be written as
w′ · (B′ · f · B + D) · w,
where f is the factor covariance matrix, and D is the diagonal matrix (with
zeros in all off-diagonal elements) containing the variance of the error terms.

416
ASSET PRICING MODELS
These expressions for the mean and the variance of the portfolio return
can be used directly in the mean-variance portfolio optimization problem
introduced in Chapter 7.
11.4.4
Risk Decomposition in Bond Portfolios
In section 11.4.2 of this chapter, we explained that a factor risk model can be
used in common stock portfolio management. Factor models are widely used
in bond portfolio management as well. They allow a bond portfolio manager
to assess the portfolio’s risk and reconstruct or rebalance a portfolio if the
risk exposures are unacceptable.
In particular, in many bond portfolio strategies, a factor model is used
to identify the speciﬁc risks that contribute to the forward-looking tracking
error relative to a benchmark, which is typically a market index.9 All of the
risks are quantiﬁed in terms of forward-looking tracking error as opposed
to backward-looking tracking error or simple portfolio variance.10
In order to identify the speciﬁc risk factors, the tracking error is de-
composed. We give an example of such decomposition based on Fabozzi
(2009). The analysis begins with a decomposition of the risks into two gen-
eral categories—systematic risk and nonsystematic risk (also referred to as
residual risk).
Systematic risk can in turn be decomposed into two risks: term structure
factor risk and nonterm structure factor risk. Term structure risk comprises
the portfolio’s exposure to changes in the general level of interest rates,
measured in terms of exposure to (1) a parallel shift in the yield curve and
(2) a nonparallel shift in the yield curve. A simple way to get a feel for the
yield curve risk exposure of a portfolio relative to a benchmark is to look at
the distribution of the present values of the cash ﬂows for the portfolio and
the benchmark index, and note the difference between the two distributions.
A superior approach for assessing yield curve risk exposure is to determine
the key rate durations of the portfolio and the benchmark. As we explained in
section 2.6.7 of Chapter 2, key rate duration is the sensitivity of a portfolio’s
value to the change in a particular key spot rate. The speciﬁc maturities on
the spot rate curve for which key rate durations are measured vary from
vendor to vendor.
Nonterm structure systematic risk is the systematic risk that is not due
to exposure to changes in interest rates. The risk factors that contribute to
nonterm structure risk include quality risk, optionality risk, coupon risk,
and MBS risk (sector, prepayment, and convexity risks). Quality risk refers
to risk associated with the credit quality of the bond issues in the portfolio.
Optionality risk has to do with embedded options that may exist in the
bonds in the portfolio.11 A change in interest rates, for example, may have

Factor Models
417
an effect on the value of an embedded option, which in turn changes the
value of the bond. The intuition behind the remaining risks will become
clearer in Chapter 15.
Nonsystematic risk is divided into risks that are issuer-speciﬁc and com-
ponents that are issue-speciﬁc. This risk is due to the fact that any portfolio
has greater exposure to speciﬁc issues and issuers than the benchmark in-
dex. To understand this point, note that a portfolio typically has a lot fewer
issues than a benchmark. Each issue may therefore make up a nontrivial
fraction of the portfolio. Speciﬁcally, suppose that three corporate issuers
individually represent more than 5% of the portfolio. If any of three issuers
is downgraded, this would cause large losses in a, say, 80-bond portfolio,
but it would not have a signiﬁcant effect on the benchmark which could
include more than 5,000 issues. Consequently, a large exposure to a speciﬁc
corporate issuer represents a material mismatch between the exposure of the
portfolio and the exposure of a benchmark index that must be taken into
account in assessing a portfolio’s risk relative to a benchmark index.
After constructing a factor model for the purposes of risk decompo-
sition, the factor model is typically used to rebalance or restructure the
portfolio. This is done using an optimizer. For example, a portfolio man-
ager may want to rebalance the portfolio so as to minimize tracking error,
or exposure to speciﬁc risk factors such as term structure risk.
SUMMARY
■The Capital Asset Pricing Model (CAPM) is an equilibrium model of
asset prices that links the expected return on an asset or a portfolio to
the expected return of the market.
■The Arbitrage Pricing Theory (APT) states that investors want to be
compensated for the risk factors that systematically affect the return on
a portfolio. The compensation in the APT is the sum of the products of
each risk factor’s systematic risk and the risk premium assigned to it by
the ﬁnancial market.
■In practice, the factors used in factor models can be external (economic),
fundamental (ﬁrm characteristics), and extracted (statistical).
■Factor models can be constructed by using regression, factor analysis,
or principal component analysis.
■Factor analysis is a statistical technique for identifying unobservable
factors that drive correlations between observable quantities.
■Principal components analysis is a statistical technique for identifying
uncorrelated factors that are linear combinations of the original data.
The ﬁrst principal component is constructed in such a way as to explain

418
ASSET PRICING MODELS
the largest portion of the variability in the data, the second factor is con-
structed in such a way as to explain the largest portion of the remaining
variability in the data, and the like.
■Factor models are used for portfolio performance evaluation, portfolio
risk decomposition, and portfolio optimization.
SOFTWARE HINTS
Running a Regression with Excel
Let us use the data in the ﬁle Ch11-Beta.xlsx, worksheet Data. To run a re-
gression, click on the Data tab, then on Data Analysis, and select Regression
from the list of statistical functions in the dialog box. Enter the array of data
in which the response variable (Y, in this case the Oracle excess stock re-
turns) is recorded (F3:F63), then the array of data in which the explanatory
variables are recorded, D3:D63 (in this case, there is only one, the S&P 500
excess return). The Regression dialog box is shown in Exhibit 11.2. Click
OK, and you should obtain the output in Exhibit 11.1.
EXHIBIT 11.2
Excel regression dialog box for the Oracle example, ﬁle
Ch11-Beta.xlsx.

Factor Models
419
Running a Regression with MATLAB
To run a regression in MATLAB, we use the regress function from the
Statistics Toolbox. A note of caution when using the regress function: by
default, MATLAB runs the regression with the intercept term set to 0. If
we want MATLAB to estimate an intercept term, we need to take an extra
step, and add a vector of ones to the array of explanatory variables. As
an example, we can read in the data on the excess returns of the Oracle
stock and the S&P 500, and run a regression to estimate the beta with the
following code:
SP500ExcessRet = xlsread(‘Ch11-Beta.xlsx’,’Data’,’D4:D63’);
OracleExcessRet = xlsread(‘Ch11-Beta.xlsx’,’Data’,’F4:F63’);
beta = regress(OracleExcessRet,[ones(length(OracleExcessRet),
1), SP500ExcessRet])
This code returns a value of 1.41 for beta, which agrees with the Excel
estimate. We can obtain additional information about the regression. For
example, the command
[beta,betaint] = regress(OracleExcessRet,SP500ExcessRet)
will return not only the value for beta, but also a 95% conﬁdence interval
for beta (which turns out to be (0.7262, 2.0849). Since 0 is not contained
within the conﬁdence interval, we can conclude that the S&P 500 excess
return is statistically signiﬁcant for predicting the expected return on Oracle
stock.
Further regression output can be obtained as well by adding more argu-
ments in the function regress.
NOTES
1. For a full derivation, see, for example, Chapter 5 in Fabozzi, Kolm,
Pachamanova, and Focardi (2007).
2. See section 11.3.1 for an overview of linear regression terminology.
3. See discussion of investor utility functions in section 7.5 of Chapter 7.
4. These characteristics are not technically “factors” in the sense of the APT, but
they help reduce the variance of the error in the regression.
5. Jones used the Russell 1000 Index as a proxy for the market portfolio in the
CAPM. This index includes large-cap stocks.
6. Lagging is required because certain ﬁnancial information is reported with lag.
For example, year-end income and balance sheet information for a given year is
not reported until three months after the corporation’s year end. When creating

420
ASSET PRICING MODELS
a regression model for forecasting purposes, it is important to include only
information that is available at the time the decision needs to be made. Thus,
for example, we cannot use a regression equation to forecast returns at time t
based on information that will become available at time t + 1.
7. For a more comprehensive overview and examples, see Rachev, Mittnik,
Fabozzi, Focardi, and Jai (2006).
8. We will see an example in Chapter 16 in which PCA is used to create a more
efﬁcient simulation model for evaluating portfolio risk.
9. As we explained in section 9.3 of Chapter 9, the standard deﬁnition of track-
ing error is the variance of the deviations of the portfolio returns from the
benchmark returns.
10. See Chapter 23, “Bond Portfolio Strategies,” in Fabozzi (2009).
11. Embedded options were ﬁrst mentioned in section 2.2.2 of Chapter 2; options
and other ﬁnancial derivative instruments are discussed in Chapter 13.

CHAPTER12
Modeling Asset Price Dynamics
O
ur discussion so far has focused mostly on models that take a myopic
view. For example, the CAPM and the APT consider events that happen
one time period ahead, where the length of the time period is determined by
the investor. In practice, asset prices are subject to ever-present uncertainty,
and ﬂuctuate continuously. Investors’ decisions are updated dynamically.
The volatility of asset prices is accounted for in market participants’ views
of the fair prices to pay for ﬁnancial securities that depend on the realizations
of continuing uncertainties. We therefore need to introduce new apparatus
that can handle asset dynamics and volatility over time. The roots for the
techniques described in this chapter are in physics and the other natural
sciences. They were ﬁrst applied in ﬁnance at the beginning of the twentieth
century, and have represented the foundations of asset pricing ever since.
The dynamics of price processes in discrete time increments are typically
described by two kinds of models: trees (such as binomial trees) and random
walks. When the time increment used to model the asset price dynamics
becomes inﬁnitely small, we talk about stochastic processes in continuous
time. We will discuss the special notation and terminology associated with
stochastic processes later in this chapter; however, our focus in this book
will be on interpretation and simulation of processes in discrete time.
This chapter will introduce the fundamentals of these models, and will
provide examples for how they can be used in practice. Speciﬁcally, we will
discuss arithmetic random walks, geometric random walks, mean reverting
walks, and more complex combinations of walks.
Let us ﬁrst introduce some deﬁnitions and notation. A ﬁnancial time
series is a sequence of observations of the values of a ﬁnancial variable, such
as an asset price (index level) or asset (index) returns, over time. Exhibit
12.1 shows an example of a time series, consisting of weekly observations
of the S&P 500 price level over a period of ﬁve years (August 19, 2005 to
August 19, 2009).
421

422
ASSET PRICING MODELS
1,600
1,400
1,200
1,000
800
600
2005
Jul
Jul
Jul
Jul
Jul
2006
2007
2008
2009
EXHIBIT 12.1
S&P 500 index level between August 19, 2005 and August 19,
2009.
Source: Dow Jones Factiva.
When we describe a time series, we talk about its drift and volatility.
The term drift is used to indicate the direction of any observable trend in
the time series. In the example in Exhibit 12.1, it appears that the time
series has a positive drift up from August 2005 until about the middle of
2007, as the level of prices appears to have been generally increasing over
that time period. From the middle of 2007 until the beginning of 2009,
there is a negative drift. The volatility was smaller (the time series was less
“squiggly”) from August 2005 until about the middle of 2007, but increased
dramatically between the middle of 2007 and the beginning of 2009. We
are usually interested also in whether the volatility increases when the price
level increases, decreases when the price level increases, or remains constant
independently of the current price level. In this example, the volatility
was lower when the price level was increasing, and was higher when the
price level was decreasing. Finally, we talk about the continuity of the
time series—is the time series smooth, or are there jumps whose magnitude
appears to be large relative to the price movements the rest of the time? From
August 2005 until about the middle of 2007, the time series is quite smooth.
However, some dramatic drops in price levels can be observed between the
middle of 2007 and the beginning of 2009—notably in the fall of 2008.
For the remainder of the chapter, we will use the following notation:
■St is the value of the underlying the variable (price, interest rate, index
level, etc.) at time t;
■St+1 is the value of the underlying variable (price, interest rate, etc.) at
time t + 1;

Modeling Asset Price Dynamics
423
■ωt is a random error term observed at time t. (For the applications in
this chapter, it will follow a normal distribution with mean equal to 0
and standard deviation equal to σ.)
■εt is a realization of a normal random variable with mean equal to 0 and
standard deviation equal to 1 at time t. (We will use it in the context of
modeling the random error term.)
12.1
BINOMIAL TREES
We introduced binomial trees (also called binomial lattices) earlier in the
book, in the context of formulating dynamic programming problems in sec-
tion 5.6.1 of Chapter 5. They provide a natural way to model the dynamics
of a random process over time. The initial value of the security S0 (at time
0) is known. The length of a time period, t, is speciﬁed before the tree
is built.1 The binomial tree model assumes that at the next time period,
only two values are possible for the price, that is, the price may go up with
probability p or down with probability (1 – p) . Usually, these values are
represented as multiples of the price at the beginning of the period. The
factor u is used for an up movement, and d is used for a down movement.
For example, the two prices at the end of the ﬁrst time period are u · S0 and
d · S0. If the tree is recombining, there will be three possible prices at the
end of the second time period: u2 · S0, u · d · S0, and d2 · S0. Proceeding in a
similar manner, we can build the tree in Exhibit 12.2.
The binomial tree model may appear simple because, given a current
price, it only allows for two possibilities for the price at each time period.
However, if the length of the time period is small, it is possible to represent
a wide range of values for the price after only a few steps. To see this, notice
that each step in the tree can be thought of as a Bernoulli trial2—it is a
“success” with probability p, and a “failure” with probability (1 – p). (The
deﬁnition of success and failure here is arbitrary because an increase in price
is not always desirable, but we deﬁne them in this way for the example’s
sake.) After n steps, each particular value for the price will be reached by
realizing k successes and (n – k) failures, where k is a number between 0 and
n. The probability of reaching each value for the price after n steps will be3
P(k successes) =
n!
k!(n −k)! pk(1 −p)n−k
As Exhibit 3.5 in Chapter 3 illustrated, for large values of n, the shape
of the binomial distribution becomes more and more symmetric, and looks
like a continuum. In fact, it approximates the normal distribution.4 One

424
ASSET PRICING MODELS
Time 0
Time 1
Time 2
Time 3
p
p
p
p
1-p
1-p
1-p
1-p
p
p
1-p
1-p
S0
dS0
uS0
udS0
u 2S0
u 3S0
u 2dS0
ud 2S0
d 3S0
d 2S0
EXHIBIT 12.2
Example of a binomial tree.
can therefore represent a large range of values for the price as long as the
number of time periods used in the binomial tree is large. Practitioners often
use also trinomial trees, that is, trees with three branches emanating from
each node, in order to obtain a better representation of the range of possible
prices in the future.
12.2
ARITHMETIC RANDOM WALKS
Instead of assuming that at each step, the asset price can only move up or
down by a certain multiple with a given probability, we could assume that
the price moves by an amount that follows a normal distribution with mean
µ and standard deviation σ. In other words, the price for each period is
determined from the price of the previous period by the equation
St+1 = St + µ + ˜ωt

Modeling Asset Price Dynamics
425
where ˜ωt is a normal random variable with mean 0 and standard deviation
σ. We also assume that the random variable ˜ωt describing the change in the
price in one time period is independent of the random variables describing
the change in the price in any other time period.5 A sequence of independent
and identically distributed (IID) random variables ˜ω0,. . ., ˜ωt,. . . with zero
mean and ﬁnite variance σ 2 is sometimes referred to as white noise.
The movement of the price expressed through the equation above is
called an arithmetic random walk with drift. The drift term, µ, represents
the average change in price over a single time period. Note that for every
time period t, we can write the equation for the arithmetic random walk as
St = St−1 + µ + ˜ωt−1
= (St−2 + µ + ˜ωt−2) + µ + ˜ωt−1
= (St−3 + µ + ˜ωt−2) + 2 · µ + ˜ωt−1 + ˜ωt−2
= · · ·
= S0 + µ · t +
t−1

i=0
˜ωi
Therefore, an arithmetic random walk can be thought of as a sum of
two terms: a deterministic straight line St = S0 + µ · t and a sum of all past
noise terms (see Exhibit 12.3).
$-
$10.00 
$20.00 
$30.00 
$40.00 
$50.00 
$60.00 
$70.00 
$80.00 
$90.00 
$100.00 
1
2
3
4
5
6
7
8
9 10 11 12 13 14 15 16 17 18 19 20 21
EXHIBIT 12.3
Five paths of an arithmetic random walk with µ = −0.1697
and σ = 3.1166. See worksheet ARW in Ch12-RandomWalks.xlsx, or
RandomWalks.m and ARWPaths.m.

426
ASSET PRICING MODELS
12.2.1
Simulation
The equation for the arithmetic random walk can be expressed also as
St+1 = St + µ + σ · ˜εt,
where ˜εt is a standard normal random variable.6
This equation makes it easy to generate paths for the arithmetic random
walk by simulation. All we need is a way of generating the normal random
variables ˜εt. We start with an initial price S0, which is known. To generate
the price at the next time period, S1, we add µ to S0, simulate a normal
random variable from a standard normal distribution, multiply it by σ,
and add it to S0 + µ. At the next step (time period 2), we use the price
at time period 1 we already generated, S1, add to it µ, simulate a new
random variable from a standard normal distribution, multiply it by σ,
and add it to S1 + µ. We proceed in the same way until we generate the
desired number of steps of the random walk. For example, given a current
price S:
■In Excel, the price for the next time period can be generated with the
formula
S + µ + σ ∗NORMINV(RAND(),0,1)
■With @RISK, the price for the next time period can be generated with
the formula
S + µ + σ ∗RISKNORMAL(0,1)
■In MATLAB, the price for the next time period can be generated with
the formula7
S + µ + σ ∗normrnd(0,1)
(See this chapter’s Software Hints and ﬁles Ch12-RandomWalks.xlsx and
ARWPaths.m for implementation of an example.)
12.2.2
Parameter Estimation
In order to simulate paths of the arithmetic random walk, we need to
have estimates of the parameters µ and σ. We need to assume that these

Modeling Asset Price Dynamics
427
parameters remain constant over the time period of estimation. Note that
the equation for the arithmetic random walk can be written as
St+1 −St = µ + σ · ˜εt.
Given a historical series of T prices for an asset, we can therefore do the
following to estimate µ and σ:
1. Compute the price changes St+1 – St for each time period t, t = 0, . . . ,
T – 1.
2. Estimate the drift of the arithmetic random walk, µ, as the average of
all the price changes.
3. Estimate the volatility of the arithmetic random walk, σ, as the standard
deviation of all the price changes.
(See this chapter’s Software Hints and ﬁles Ch12-RandomWalks.xlsx and
RandomWalks.m for implementation of an example.)
An important point to keep in mind is the units in which the parame-
ters are estimated. If we are given time series in monthly increments, then
the estimates of µ and σ we will obtain through steps 1–3 will be for a
monthly drift and monthly volatility. If we then need to simulate future
paths for monthly observations, we can use the same µ and σ. However,
if, for example, we need to simulate weekly observations, we will need to
adjust µ and σ to account for the difference in the length of the time period.
In general, the parameters should be stated as annual estimates. The annual
estimates can then be adjusted for daily, weekly, monthly, as well as other
increments.
12.2.3
Arithmetic Random Walk: Some
Additional Facts
In general, if we use the arithmetic random walk model, any price in the
future, St, can be expressed through the initial (known) price S0 as
St = S0 + µ · t + σ
t−1

i=0
˜εt.
The random variable corresponding to the sum of t independent normal
random variables ˜ε0, . . . , ˜εt−1 is a normal random variable with mean equal
to the sum of the means and standard deviation equal to the square root of

428
ASSET PRICING MODELS
the sum of variances. Since ˜ε0, . . . , ˜εt−1 are independent standard normal
variables, their sum is a normal variable with mean 0 and standard deviation
equal to
√
1 + · · · + 1



t times
=
√
t.
Therefore, we can have a closed-form expression for computing the
asset price at time t given the asset price at time 0:
St = S0 + µ · t + σ ·
√
t · ˜ε
where ˜ε is a standard normal random variable.
Based on the discussion so far in this section, we can state the following
observations about the arithmetic random walk:
■The arithmetic random walk has a constant drift µ and volatility.
■At every time period, the change in price is normally distributed, on
average equal to µ, with a standard deviation of σ.
■The overall noise in an arithmetic random walk never decays. The price
change over t time periods is distributed as a normal distribution with
mean equal to µ · t and standard deviation equal to σ√t. That is why in
industry one often encounters the phrase “The uncertainty grows with
the square root of time.”
■Prices that follow an arithmetic random walk meander around a straight
line St = S0 + µ · t. They may depart from the line, and then cross it
again.
■Because the distribution of future prices is normal, we can theoretically
ﬁnd the probability that the future price at any time will be within a
given range.
■Because the distribution of future prices is normal, future prices can
theoretically take inﬁnitely large or inﬁnitely small values. Thus, they
can be negative, which is an undesirable consequence of using the model.
Asset prices, of course, cannot be negative. In practice, the probability
of the price becoming negative can be made quite small as long as the drift
and the volatility parameters are selected carefully. However, the possibility
of generating negative prices with the arithmetic random walk model is real.
Another problem with the assumptions underlying the arithmetic ran-
dom walk is that the change in the asset price is drawn from the same

Modeling Asset Price Dynamics
429
random probability distribution, independent of the current level of the
prices. A more natural model is to assume that the parameters of the ran-
dom probability distribution for the change in the asset price vary depending
on the current price level. For example, a $1 change in a stock price is more
likely when the stock price is $100 than when it is $4. Empirical studies con-
ﬁrm that over time, asset prices tend to grow, and so do ﬂuctuations. Only
returns appear to remain stationary, that is, to follow the same probability
distribution over time. A more realistic model for asset prices may therefore
be that returns are an IID sequence. We describe such a model in the next
section.
12.3
GEOMETRIC RANDOM WALKS
Consider the following model:
rt = µ + σ · ˜εt,
where ˜ε0, . . . , ˜εt is a sequence of independent normal variables, and rt, the
return, is computed as8
rt = St+1 −St
St
.
Returns are therefore normally distributed, and the return over each
interval of length 1 has mean µ and standard deviation σ. How can we
express future prices if returns are determined by the equations above?
Suppose we know the price at time t, St. The price at time t + 1 can be
written as
St+1 = St · St+1
St
= St ·
 St
St
+ St+1 −St
St

= St ·

1 + St+1 −St
St

= St · (1 + ˜rt)
= St + µ · St + σ · St · ˜εt

430
ASSET PRICING MODELS
The equation is very similar to the equation for the arithmetic random
walk, except that the price from the previous time period appears as a factor
in all of the terms.
The equation for the geometric random walk makes it clear how paths
for the geometric random walk can be generated. As in the case of the
arithmetic random walk, all we need is a way of generating the normal
random variables ˜εt. We start with an initial price S0, which is known. To
generate the price at the next time period, S1, we add µ · S0 to S0, simulate a
normal random variable from a standard normal distribution, multiply it by
σ and S0, and add it to S0 + µ · S0. At the next step (time period 2), we use
the price at time period 1 we already generated, S1, add to it µ · S1, simulate
a new random variable from a standard normal distribution, multiply it by
σ and S1, and add it to S1 + µ · S1. We proceed in the same way until we
generate the desired number of steps of the geometric random walk. Given
a current price S:
■In Excel, the price for the next time period can be generated with the
formula
S + µ∗S + σ ∗S∗NORMINV(RAND(),0,1)
■In @RISK, the price for the next time period can be generated with the
formula
S + µ∗S + σ ∗S∗RISKNORMAL(0,1)
■In MATLAB, the price for the next time period can be generated with
the formula9
S + µ∗S + σ ∗S∗normrnd(0,1)
Using similar logic to the derivation of the price equation earlier, we can
express the price at any time t in terms of the known initial price S0. Note
that we can write the price at time t as
St = S0 · S1
S0
· . . . · St−1
St−2
·
St
St−1
.
Therefore,
St = S0 · (1 + ˜r0) · . . . · (1 + ˜rt−1).

Modeling Asset Price Dynamics
431
In the case of the arithmetic random walk, we determined that the
price at any time period follows a normal distribution. That is, if we know
the starting price S0, then the price at any time period could be obtained
by adding a sum of independent normal random variables to a constant
term and S0. The sum of independent normal random variables is a normal
random variable itself. In the equation for the geometric random walk, each
of the terms (1 + ˜r0), . . . , (1 + ˜rt−1) is a normal random variable as well (it
is the sum of a normal random variable and a constant). However, these
terms are multiplied together. The product of normal random variables is
not a normal random variable, which means that we cannot have a nice
closed-form expression for computing the price St based on S0.
To avoid this problem, let us consider the logarithm of prices.10 If we
take natural logarithms of both sides of the equation for St, we get
ln(St) = ln(S0 · (1 + ˜r0) · . . . · (1 + ˜rt−1))
= ln(S0) + ln(1 + ˜r0) + · . . . · + ln(1 + ˜rt−1).
Log returns are in fact differences of log prices. To see this, recall the
deﬁnition of log return from Chapter 2:
ln(1 + rt) = ln

1 + St+1 −St
St

= ln
 St+1
St

= ln(St+1) −ln(St).
Now assume that log returns (not returns) are independent, and follow
a normal distribution with mean µ and standard deviation σ:
ln(1 + ˜rt) = ln(St+1) −ln(St) = µ + σ · ˜εt
As a sum of independent normal variables, the expression
ln(S0) + ln(1 + ˜r0) + . . . + ln(1 + ˜rt−1)
is also normally distributed. This means that ln(St) is normally distributed,
that is, St is a lognormal random variable.11,12

432
ASSET PRICING MODELS
In fact, similarly to the case of an arithmetic random walk, we can
compute a closed-form expression for the price St given S0:
ln(St) = ln(S0) +

µ −1
2 · σ 2

· t + σ ·
√
t · ˜ε
or, equivalently,
St = S0 · e(µ−1
2 ·σ 2)·t+σ·√t·˜ε
where ˜ε is a standard normal variable.
Notice that the only inconsistency with the formula for the arithmetic
random walk is the presence of the extra term

−1
2 · σ 2

· t
in the drift term

µ −1
2 · σ 2

· t.
Why is there an adjustment of one half of the variance in the expected
drift? In general, if ˜Y is a normal random variable with mean µ and variance
σ 2, then the random variable which is an exponential of the normal random
variable ˜Y, ˜X = e ˜Y, has mean
E[ ˜X] = eµ+ 1
2 ·σ 2.
At ﬁrst, this seems unintuitive—why is the expected value of ˜X not
E[ ˜X] = eµ?
As we discussed in section 3.9 of Chapter 3, the expected value of a
linear function of a random variable is a linear function of the expected
value of the random variable. For example, if a is a constant, then
E[a · ˜Y] = a · E[ ˜Y]
However, determining the expected value of a nonlinear function of
a random variable (in particular, the exponential function, which is the

Modeling Asset Price Dynamics
433
function we are using here) is not as trivial. For example, there is a well-
known relationship, the Jensen inequality, which states that the expected
value of a convex function of a random variable is less than the value of the
function at the expected value of the random variable.
In our example, ˜X is a lognormal random variable, so its probability
distribution has the shape shown in Exhibit 3.15 in Chapter 3. The random
variable ˜X cannot take values less than 0. Since its variance is related to
the variance of the normal random variable ˜Y, as the variance σ 2 of ˜Y
increases, the distribution of ˜X will spread out in the upward direction. This
means that the mean of the lognormal variable ˜X will increase not only as
the mean of the normal variable ˜Y, µ, increases, but also as ˜Y’s variance,
σ 2, increases. In the context of the geometric random walk, ˜Y represents the
normally distributed log returns, and ˜Xis in fact the factor by which the asset
price from the previous period is multiplied to generate the asset price in the
next time period. In order to make sure that the geometric random process
grows exponentially at average rate µ, we need to subtract a term (that term
turns out to be σ 2/2), which will correct the bias.
Speciﬁcally, suppose that we know the price at time t, St. We have
ln(St+1) = ln(St) + ln(1 + ˜rt)
that is,
St+1 = St · eln(1+˜rt)
Note that we are explicitly assuming a multiplicative model for asset
prices here—the price in the next time period is obtained by multiplying
the price from the previous time period by a random factor. In the case of
an arithmetic random walk in section 12.2, we had an additive model—a
random shock was added to the asset price from the previous time period.
If the log-return log(1 + ˜r) is normally distributed with mean µ and
standard deviation σ, then the expected value of
eln(1+˜r)
is
eµ+ 1
2 ·σ 2.
and hence
E[St+1] = St · eµ+ 1
2 ·σ 2.

434
ASSET PRICING MODELS
In order to make sure that the geometric random walk process grows
exponentially at an average rate µ (rather than (µ + 0.5 · σ 2)), we need
to subtract the term 0.5 · σ 2 when we generate the future price from this
process. This argument can be extended to determining prices for more than
one time period ahead.
We will understand better why this formula holds in section 12.6.
12.3.1
Simulation
It is easy to see that future prices can be simulated based on the initial price
S0. In general, for a current price of S:
■In Excel, the price t periods from now can be generated as
S∗exp((µ −0.5∗σˆ2)∗t −σ ∗√
t∗NORMINV(RAND(),0,1))
■With @RISK, the price t periods from now can be generated with the
formula
S∗exp((µ −0.5∗σˆ2)∗t −σ ∗√t∗RISKNORMAL(0,1))
■In MATLAB, the price t periods from now can be generated with the
formula
S∗exp((µ −0.5∗σˆ2)∗t −σ ∗√
t∗normrnd(0,1))
(See this chapter’s Software Hints and ﬁles Ch12-RandomWalks.xlsx or
GRWPaths.m for an example.)
One might wonder whether this approach for simulating realizations
of an asset price following a geometric random walk is equivalent to the
simulation approach mentioned earlier in this section, which is based on the
discrete version of the equation for a random walk. The two approaches
are different (for example, the approach based on the discrete version of
the equation for the geometric random walk does not produce the expected
lognormal price distribution), but it can be shown that the differences in the
two simulation approaches tend to cancel over many steps.
12.3.2
Parameter Estimation
In order to simulate paths of the geometric random walk, we need to have
estimates of the parameters µ and σ. The implicit assumption here, of course,
is that these parameters remain constant over the time period of estimation.

Modeling Asset Price Dynamics
435
(We will discuss how to incorporate considerations for changes in volatility
in section 12.5.) Note that the equation for the geometric random walk can
be written as
ln(St+1) −ln(St) = ln(1 + ˜rt),
Equivalently,
log
 St+1
St

= µ + σ · ˜εt.
Given a historical series of T prices for an asset, we can therefore do the
following to estimate µ and σ:
1. Compute ln(St+1 / St) for each time period t, t = 0, . . . , T – 1.
2. Estimate the volatility of the geometric random walk, σ, as the standard
deviation of all ln(St+1 / St).
3. Estimate for the drift of the arithmetic random walk, µ, as the average
of all ln(St+1 / St), plus one half of the standard deviation squared.
Note that
log
 St+1
St

= log

1 + St+1 −St
St

= log(1 + ˜rt)
Therefore, if we are given data on returns, rather than asset prices, we
can compute ln(1 + ˜rt), and use it to replace ln(St+1 / St) in steps 1–3 above.
(See this chapter’s Software Hints and ﬁles Ch12-RandomWalks.xlsx and
RandomWalks.m for implementation of an example.)
12.3.3
Geometric Random Walk:
Some Additional Facts
To summarize, the geometric random walk has several important character-
istics:
■It is a multiplicative model, that is, the price at the next time period is a
multiple of a random term and the price from the previous time period.
■It has a constant drift µ and volatility σ. At every time period, the
percentage change in price is normally distributed, on average equal to
µ, with a standard deviation of σ.

436
ASSET PRICING MODELS
■The overall noise in a geometric random walk never decays. The per-
centage price change over t time periods is distributed as a normal
distribution with mean equal to µ · t and standard deviation equal to
σ√t.
■The exact distribution of the future price knowing the initial price can
be found. The price at time t is lognormally distributed with speciﬁc
probability distribution parameters.
■Prices that follow a geometric random walk in continuous time never
become negative.
The geometric random walk model is not perfect. However, its compu-
tational simplicity makes the geometric random walk and its variations the
most widely used processes for modeling asset prices. The geometric ran-
dom walk deﬁned with log returns never becomes negative because future
prices are always a multiple of the initial stock price and a positive term (see
Exhibit 12.4). In addition, observed historical stock prices can actually be
quite close to lognormal.
It is important to note that, actually, the assumption that log returns
are normal is not required to justify the lognormal model for prices. If the
$-
$10.00 
$20.00 
$30.00 
$40.00 
$50.00 
$60.00 
$70.00 
$80.00 
$90.00 
1
2
3
4
5
6
7
8
9
10 11 12 13 14 15 16 17 18 19 20 21
EXHIBIT 12.4
Five paths of a geometric random walk with µ = −0.0014 and
σ = 0.0411. Note that although the drift is slightly negative, it is still possible to
generate paths that generally increase over time. See worksheet GRW in
Ch12-RandomWalks.xlsx, or RandomWalks.m and GRWPaths.m.

Modeling Asset Price Dynamics
437
distribution of log returns is nonnormal, but the log returns are IID with
ﬁnite variance, the sum of the log returns is asymptotically normal.13 Stated
differently, the log return process is approximately normal if we consider
changes over sufﬁciently long intervals of time.
Price processes, however, are not always geometric random walks, even
asymptotically. A very important assumption for the geometric random
walk is that price increments are independently distributed; if the time series
exhibits autocorrelation, the geometric random walk is not a good rep-
resentation. We will see some models that incorporate considerations for
autocorrelation and other factors later in this chapter.
12.4
MEAN REVERSION
The geometric random walk provides the foundation for modeling the dy-
namics for asset prices of many different securities, including stock prices.
However, in some cases it is not justiﬁed to assume that asset prices evolve
with a particular drift, or can deviate arbitrarily far from some kind of a
representative value. Interest rates, exchange rates, and the prices of some
commodities are examples for which the geometric random walk does not
provide a good representation over the long term. For example, if the price
of copper becomes high, copper mines would increase production in order
to maximize proﬁts. This would increase the supply of copper in the mar-
ket, therefore decreasing the price of copper back to some equilibrium level.
Consumer demand plays a role as well—if the price of copper becomes too
high, consumers may look for substitutes, which would reduce the price of
copper back to its equilibrium level.
Exhibit 12.5 illustrates the behavior of the one-year Treasury bill yield
from the beginning of January 1962 through the end of July 2009. It can be
observed that, even though the variability of Treasury bill rates has changed
over time, there is some kind of a long-term average level of interest rates
to which they return after deviating up or down. This behavior is known as
mean reversion.
The simplest mean reversion (MR) model is similar to an arithmetic
random walk, but the means of the increments change depending on the
current price level. The price dynamics are represented by the equation
St+1 = St + κ · (µ −St) + σ · ˜εt,
where ˜εt is a standard normal random variable. The parameter κ is a nonneg-
ative number that represents the speed of adjustment of the mean-reverting

438
ASSET PRICING MODELS
0
2
4
6
8
10
12
14
16
18
20
1/5/1962
1/5/1965
1/5/1968
1/5/1971
1/5/1974
1/5/1977
1/5/1980
1/5/1983
1/5/1986
1/5/1989
1/5/1992
1/5/1995
1/5/1998
1/5/2001
1/5/2004
1/5/2007
EXHIBIT 12.5
Weekly data on 1-Year Treasury Yield rates, January
5, 1962–July 31, 2009.
process—the larger its magnitude, the faster the process returns to its long-
term mean. The parameter µ is the long-term mean of the process. When
the current price St is lower than the long-term mean µ, the term (µ – St)
is positive. Hence, on average there will be an upward adjustment to ob-
tain the value of the price in the next time period, St+1. (We add a positive
number, κ · (µ – St), to the current price current price St.) By contrast, if the
current price St is higher than the long-term mean µ, the term (µ – St) is neg-
ative. Hence, on average there will be a downward adjustment to obtain the
value of the price in the next time period, St+1. (We add a negative number,
κ · (µ – St), to the current price current price St.) Thus, the mean-reverting
process will behave in the way we desire—if the price becomes lower or
higher than the long-term mean, it will be drawn back to the long-term mean.
In the case of the arithmetic and the geometric random walks, the volatil-
ity of the process increases over time. The volatility for one step of the
mean-reverting process is σ 2; however, as the number of steps increases, the
volatility peaks at
σ 2
κ · (2 −κ).
In continuous time, this basic mean-reversion process is called the
Ornstein-Uhlenbeck process (see section 12.5). It is widely used when mod-
eling interest rates and exchange rates in the context of computing bond

Modeling Asset Price Dynamics
439
1.20
1.25
1.30
1.35
1.40
1.45
1.50
1.55
1.60
1.65
1.70
1
3
5
7
9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51
EXHIBIT 12.6
Five paths with 50 steps each of a mean reverting process with
µ = 1.4404, κ = 0.0347 and σ = 0.0248. See worksheet MR in
Ch12-RandomWalks.xlsx, or MRPaths.m.
prices and prices of more complex ﬁxed income securities. When used in the
context of modeling interest rates, this simple mean-reversion process is also
referred to as the Vasicek model.14
The mean-reversion process suffers from some of the disadvantages
of the arithmetic random walk—for example, it can technically become
negative. However, if the long-run mean is positive, and the speed of mean
reversion is large relative to the volatility, the price will be pulled back to
the mean quickly if it becomes negative. Exhibit 12.6 contains an example
of ﬁve paths generated from a mean-reverting process.
12.4.1
Simulation
The formula for the mean-reverting process makes it clear how paths for
the mean-reverting random walk can be generated with software. Given a
current price S:
■In Excel, the price for the next time period can be generated with the
formula
S + κ∗(µ −S) + σ ∗NORMINV(RAND(),0,1)

440
ASSET PRICING MODELS
■With @RISK, the price for the next time period can be generated with
the formula
S + κ∗(µ −S) + σ ∗RISKNORMAL(0,1)
■In MATLAB, the price for the next time period can be generated with
the formula
S + κ∗(µ −S) + σ ∗normrnd(0,1)
12.4.2
Parameter Estimation
In order to simulate paths of the geometric random walk, we need to have
estimates of the parameters κ, µ, and σ of the mean-reverting process. Again,
we assume that these parameters remain constant over the time period of
estimation. The equation for the mean-reverting process can be written as
St+1 −St = κ · (µ −St) + σ · ˜εt
or, equivalently,
St+1 −St = κ · µ −κ · St + σ · ˜εt
This equation has the characteristics of a linear regression model, with
the absolute price change (St+1 – St) as the response variable, and St as the
explanatory variable. Given a historical series of T prices for an asset, we
can therefore do the following to estimate κ, µ, and σ:
1. Compute the price changes (St+1 – St) for each time period t, t = 0, . . . ,
T–1.
2. Run a linear regression with (St+1 – St) as the response variable and
St as the explanatory variable. In Excel, click the Data tab, click Data
Analysis, select Regression from the Analysis Tools. With MATLAB’s
Statistical Toolbox, use the regress(Y,X) function.15
3. Verify that the estimates from the linear regression model are valid:
(a) Plot the values of St versus (St+1 – St). The points in the scatter plot
should approximately vary around a straight line with no visible
cyclical or other patterns.
(b) The p-value for the coefﬁcient in front of the explanatory variable
St should be small, preferably less than 0.05.

Modeling Asset Price Dynamics
441
4. An estimate for the speed of adjustment of the mean-reversion process,
κ, can be obtained as the negative of the coefﬁcient in front of St. Since
the speed of adjustment cannot be a negative number, if the coefﬁcient in
front of St is positive, the regression model cannot be used for estimating
the parameters of the mean reverting process.
5. An estimate for the long-term mean of the mean-reverting process, µ,
can be obtained as the ratio of the intercept term estimated from the
regression and the slope coefﬁcient in front of St (if that slope coefﬁcient
is valid, that is, negative and with low p-value).
6. An estimate for the volatility of the mean-reverting process, σ, can be
obtained as the standard error of the regression.16
(See this chapter’s Software Hints and ﬁles Ch12-RandomWalks.xlsx and
RandomWalks.m for implementation of an example.)
12.4.3
The Cox-Ingersoll-Ross Model for Interest
Rates Dynamics
More advanced mean-reversion processes have been used to avoid the pitfalls
of the simple mean-reversion process.
A commonly used model for interest rates, called the Cox-Ingersoll-
Ross (CIR) model,17 includes the square root of the current asset price as a
factor in the random term of the mean reversion where we use r to denote
the short-term interest rate in this section:
rt+1 = rt + κ · (µ −rt) + σ · √rt · ˜εt
The effect is that if the current interest rate is low, the variability of
the process is relatively low, thus reducing the probability that the mean-
reverting random walk will become negative. When the current interest rate
is high, the variability of the process can afford to be higher without the
risk that the interest rate will become negative. Future interest rates are easy
to simulate with this model. Historically, the appeal of this model has been
that a closed-form solution for the future interest rates knowing the current
interest rate can be found. It turns out that
r1 = r0 + (1 −e−κ·t) · σ 2
2 · κ
· ˜η

442
ASSET PRICING MODELS
where ˜η has a chi-square distribution with 4 · κ · µ/σ 2 degrees of freedom
and noncentrality parameter18
2 · r0 · e−κ·t · (1 −e−κ·t) · σ 2
2 · κ
It is worth noting that while the random processes described in previous
sections are widely used for modeling stock and commodity prices, they
cannot be directly applied to modeling bond prices. The prices of ﬁxed
income securities, such as bonds, evolve in a substantially more complex
fashion than the evolution of stock or commodity prices described in this
chapter. In some cases, such as in the case of the CIR model, there is a closed-
form formula for bond prices based on the assumptions for the process
followed by the short-term interest rate. This enables us to generate the
entire yield curve,19 and calculate the price of a ﬁxed income security tied
to these interest rates.
12.4.4
Geometric Mean Reversion
A more advanced mean-reversion models that bears some similarity to the
geometric random walk is the geometric mean reversion (GMR) model20
St+1 = St + κ · (µ −St) · St + σ · St · ˜εt
The intuition behind this model is similar to the intuition behind the
discrete version of the geometric random walk—the variability of the pro-
cess changes with the current level of the price, and we think of the change
in price as a percentage change (roughly) rather than an absolute change.
However, the GMR model allows for incorporating mean reversion. Ex-
hibit 12.7 contains an example of ﬁve paths generated with a geometric
mean-reversion model.
Even though it is difﬁcult to estimate the future price analytically from
this model, it is easy to simulate. As before, ˜εt is a standard normal random
variable, which can be generated with standard commands in Excel, @RISK,
or MATLAB. Given a current price S:
■In Excel, the price for the next time period can be generated with the
formula
S + κ∗(µ −S)∗S + σ ∗S∗NORMINV(RAND(),0,1)

Modeling Asset Price Dynamics
443
1.20
1.25
1.30
1.35
1.40
1.45
1.50
1.55
1.60
1
3
5
7
9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51
EXHIBIT 12.7
Five paths with 50 steps each of a geometric mean reverting
process with µ = 1.4464, κ = 0.0253, and σ = 0.0177. See worksheet GMR in
Ch12-RandomWalks.xlsx, or GMRPaths.m.
■With @RISK, the price for the next time period can be generated with
the formula
S + κ∗(µ −S)∗S + σ ∗S∗RISKNORMAL(0,1)
■In MATLAB, the price for the next time period can be generated with
the formula
S + κ∗(µ −S)∗S + σ ∗S∗normrnd(0,1)
To estimate the parameters κ, µ, and σ to use in the simulation, we can
use a series of T observations. Assume that the parameters of the geometric
mean reversion remain constant during the time period of estimation.
Note that the equation for the geometric mean reversion can be writ-
ten as
St+1 −St
St
= κ · (µ −St) + σ · ˜εt

444
ASSET PRICING MODELS
or, equivalently, as
St+1 −St
St
= κ · µ −κ · St + σ · ˜εt
Again, this equation bears characteristics of a linear regression model,
with the percentage price change (St+1 – St)/St as the response variable, and St
as the explanatory variable. Given a series of T asset prices, we can therefore
do the following to estimate κ, µ, and σ:
1. Compute the percentage price changes (St+1 – St)/St for each time period
t, t = 0, . . . , T–1.
2. Run a linear regression with (St+1 – St)/St as the response variable and
St as the explanatory variable. In Excel, click the Data tab, click Data
Analysis, and then select Regression from the Analysis Tools. With
MATLAB’s Statistical Toolbox, use the regress(Y,X) function.
3. Verify that the estimates from the linear regression model are valid:
(a) Plot the values of St versus (St+1 – St)/St. The points in the scatter
plot should approximately vary around a straight line with no visible
cyclical or other patterns.
(b) The p-value for the coefﬁcient in front of the explanatory variable
St should be small, preferably less than 0.05.
4. An estimate for the speed of adjustment of the mean-reverting process,
κ, can be obtained as the negative of the coefﬁcient in front of St. Since
the speed of adjustment cannot be a negative number, if the coefﬁcient in
front of St is positive, the regression model cannot be used for estimating
the parameters of the geometric mean-reverting process.
5. An estimate for the long-term mean of the mean-reverting process, µ,
can be obtained as the ratio of the intercept term estimated from the
regression and the slope coefﬁcient in front of St (if that slope coefﬁcient
is valid, that is, negative and with low p-value).
6. An estimate for the volatility of the mean-reverting process, σ, can be
obtained as the standard error of the regression.21
(See this chapter’s Software Hints and ﬁles Ch12-RandomWalks.xlsx and
RandomWalks.m for implementation of an example.)
12.5
ADVANCED RANDOM WALK MODELS
The models we described so far provide building blocks for representing the
asset price dynamics. However, observed real-world asset price dynamics
has features that cannot be incorporated in these basic models. For example,

Modeling Asset Price Dynamics
445
asset prices exhibit correlation—both with each other, and with themselves
over time. Their volatility typically cannot be assumed constant. This sec-
tion reviews several techniques for making asset price models more realistic
depending on observed price behavior.
12.5.1
Correlated Random Walks
So far, we have discussed models for asset prices that assume that the dy-
namic processes for the prices of different assets evolve independently of
each other. This is an unrealistic assumption—it is expected that market
conditions and other factors will have an impact on the prices of groups of
assets simultaneously. For example, it is likely that stock prices for compa-
nies in the oil industry will generally move together, as will stock prices for
companies in the telecommunications industry.
The argument that asset prices are codependent has theoretical and
empirical foundations as well. If asset prices were independent random
walks, then large portfolios would be fully diversiﬁed, have no variability,
and therefore be completely deterministic. Empirically, this is not the case.
Even large aggregates of stock prices, such as the S&P 500, exhibit random
behavior.
If we make the assumption that log returns are jointly normally dis-
tributed, then their dependencies can be represented through the covariance
matrix (equivalently, through the correlation matrix).22
Let us give an example of how one can model two correlated stock prices
assumed to follow geometric random walks. Suppose we are given two series
of T observations each of observed asset prices for Stock 1 and Stock 2. We
follow steps 1 and 2 from section 12.3.2 to estimate the drifts and the
volatilities for the two processes. To estimate the correlation structure, we
ﬁnd the correlation between
ln

S(1)
t+1
S(1)
t
	
and
ln

S(2)
t+1
S(2)
t
	
where the indices (1) and (2) correspond to the stock number. In Excel, the
correlation between two data series can be computed with the function
CORREL(Array1, Array2)

446
ASSET PRICING MODELS
whereas in MATLAB, the correlation can be computed with the function
CORR([Array1 Array2])
for two vertical arrays Array1 and Array2.
This correlation can then be incorporated in the simulation. Excel can-
not generate correlated normal random variables without special add-ins,
but @RISK and MATLAB have functions for it. As explained in Chapter 4’s
Software Hints, to generate two correlated random variables in @RISK, use
the formula
RISKCORRMAT(CorrMx, RowNumber, InstanceNumber)
where
CorrMx
is the array in which the correlation matrix is
stored.
RowNumber
is the row number in the correlation matrix that
stores the correlations that correspond to that
stock.
InstanceNumber
basically refers to whether the random vari-
ables that are generated need to be correlated
across time periods. If we do not want them to
be correlated across time periods (only within
one time period), then we need to specify a dif-
ferent instance number for every time period
for which we generate a new price.
To generate the price for Stock 1 t periods from now, given a current
price of S, use
S*exp((µ1-0.5*σ 1ˆ2)*t - σ 1*
√t*RISKNORMAL(0,1,RISKCORRMAT
(CorrMx,1,t)))
To generate the price for Stock 2 t periods from now, given a current
price of S, use
S*exp((µ2-0.5*σ 2ˆ2)*t - σ 2*
√t*RISKNORMAL(0,1,RISKCORRMAT
(CorrMx,2,t)))
To generate two correlated normal random variables in MATLAB, use
the formula
mvnrnd(muVec,CovMx,numObs)

Modeling Asset Price Dynamics
447
where
muVec
is the vector of expected values.
CovMx
is the covariance matrix.
numObs
is the number of random observations we would like to
generate.
In the case of arithmetic or geometric random walk, we will need to
simulate correlated standard normal random variables, so we will enter a
vector of expected values of zero, a covariance matrix, and the number of
steps we need to generate.
When we consider many different assets, the covariance matrix becomes
very large, and cannot be estimated accurately. Instead, factor models23 can
be used to reduce the dimension of the covariance structure. Multivariate
random walks are in fact dynamic factor models for asset prices. A multi-
factor model for the return of asset i can be written in the following general
form:
r(i)
t
= µ(i) +
K

k=1
β(i,k) · f (k)
t
+ ε(i)
t
where the K factors f (k) follow random walks, β(i,k) are the factor loadings,
and ε(i)
t
are normal random variables with zero mean.
It is important to note that the covariance matrix cannot capture corre-
lations at lagged times (i.e., correlations of dynamic nature). Furthermore,
the assumptions that log returns behave as multivariate normal variables is
not always applicable—some assets exhibit dependency of nonlinear kind,
which cannot be captured by the covariance or correlation matrix. Alterna-
tive tools for modeling covariability include copula functions and transfer
entropies.24
12.5.2
Incorporating Jumps
Many of the dynamic asset price processes used in industry assume contin-
uous sample paths, as was the case with the arithmetic, geometric, and the
different mean-reverting random walks we considered earlier in this chap-
ter. However, there is empirical evidence that the prices of many securities
incorporate jumps. The prices of some commodities, such as electricity and
oil, are notorious for exhibiting “spikes.” The logarithm of a price process
with jumps is not normally distributed, but is instead characterized by a
high peak and heavy tails, which are more typical of market data than the
normal distribution. Thus, more advanced models are needed to incorporate
realistic price behavior.

448
ASSET PRICING MODELS
A classical way to include jumps in models for asset price dynamics is
to add a Poisson process to the process (geometric random walk or mean
reversion) used to model the asset price. A Poisson process is a discrete
process in which arrivals occur at random discrete points in time, and the
times between arrivals are drawn from an exponential distribution with
average time between arrivals equal to 1/λ.25 Recall from sections 3.7.1 and
3.7.2 of Chapter 3 that this means that the number of arrivals in a speciﬁc
time interval follows a Poisson distribution with mean rate of arrival λ. The
“jump” Poisson process is assumed to be independent of the underlying
“smooth” random walk.
The Poisson process is typically used to ﬁgure out the times at which
the jumps occur. The magnitude of the jumps itself could come from
any distribution, although the lognormal distribution is often used for
tractability.
Let us explain in more detail how one would model and simulate a
geometric random walk with jumps. At every point in time, the process
moves as a geometric random walk, and updates the price St to St+1. If a
jump happens, the size of the jump is added to St as well to obtain St+1. In
order to avoid confusion about whether or not we have included the jump
in the calculation, let us denote the price right before we ﬁnd out whether
or not a jump has occurred S(−)
t+1, and keep the total price for the next time
period as St+1. We therefore have
S(−)
t+1 = St + µ · St + σ · St · ˜εt
that is, S(−)
t+1 is computed according to the normal geometric random walk
rule. Now suppose that a jump of magnitude ˜J t occurs between time t and
time t+1. Let us express the jump magnitude as a percentage of the asset
price, that is, let
St+1 = S(−)
t+1 · ˜J t
If we restrict the magnitude of the jumps ˜J t to be nonnegative, we will
make sure that the asset price itself does not become negative.
Let us now express the changes in price in terms of the jump size. Based
on the relationship between St+1, S(−)
t+1, and ˜J t, we can write
St+1 −S(−)
t+1 = S(−)
t+1 · ( ˜J t −1)

Modeling Asset Price Dynamics
449
and, therefore,
S(−)
t+1 = St+1 −S(−)
t+1 · ( ˜J t −1)
Thus we can substitute this expression for S(−)
t+1 and write the geometric
random walk with jumps model as
St+1 = St + µ · St + σ · St · ˜εt+S(−)
t+1 · ( ˜J t −1)
How would we simulate a path for the jump-geometric random walk
process? Note that given the relationship between St+1, S(−)
t+1, and ˜J t, we can
write
ln(St+1) = ln(S(−)
t+1) + ln( ˜J t)
Since S(−)
t+1 is the price resulting only from the geometric random walk
at time t, we already know what ln(S(−)
t+1) is. Recall based on our discussion
of the geometric random walk in section 12.3 that
ln(S(−)
t+1) = ln(St) + (µ −0.5 · σ 2) + σ · ˜εt
Therefore, the overall equation will be
ln(St+1) = ln(St) + (µ −0.5 · σ 2) + σ · ˜εt +

i
ln

J (i)
t

where J (i)
t
are all the jumps that occur during the time period between t and
t+1. This means that
St+1 = St · eµ−0.5·σ 2+σ·˜εt ·

i
J (i)
t
where the symbol 	 denotes product. (If no jumps occurred between t and
t+1, we set the product to 1.)
Hence, to simulate the price at time t+1, we need to simulate the fol-
lowing:
■A standard normal random variable ˜εt, as in the case of a geometric
random walk.
■How many jumps occur between t and t+1.
■The magnitude of each jump.

450
ASSET PRICING MODELS
The exact simulation procedure is as follows:
1. Generate a standard normal random variable ˜εt. With @RISK, this can
be done with the command RISKNORMAL(0,1). In MATLAB, use norm-
rnd(0,1).
2. Simulate the number of arrivals in the time period (t, t + 1) by
drawing a number from a Poisson distribution with arrival rate per
unit period λ. In @RISK, use RISKPOISSON(λ). In MATLAB, use
poissrnd(λ).
3. Suppose the number of arrivals generated in step 2 was K. For each ar-
rival, generate a random number from the probability distribution that
the jump size ˜J t is assumed to follow. For example, if the jumps are as-
sumed to come from a lognormal distribution with mean m and standard
deviation s, then use the function RISKLOGNORM(m,s) in @RISK or the
function lognrnd(m,s) in MATLAB to generate K random numbers
J1, . . . , JK from that distribution.
4. Compute the sum of the natural logarithms of the random numbers
generated in step 3, ln(J1) + · · · + ln(JK).
5. Compute the natural logarithm of the price at the next time period as
ln(St+1) = ln(St) + (µ −0.5 · σ 2) + σ · εt + ln(J1) + · · · + ln(JK)
Note that we could compute St+1 directly as well, as in the equation we
showed earlier. However, if we are simulating a path for the random walk
with jumps, we will need ln(St+1), rather than St+1, for the calculation of
the next step, so this equation is sufﬁcient.
As Merton (1976) noted, if we assume that the jumps follow a lognormal
distribution, then ln( ˜J t) is normal, and the simulation is even easier. See
Glasserman (2004) for more advanced examples.
12.5.3
Stochastic Volatility
The models we considered so far all assumed that the volatility of the stochas-
tic process remains constant over time. Empirical evidence suggests that the
volatility changes over time, and more advanced models recognize that fact.
Such models assume that the volatility parameter σ itself follows a random
walk of some kind. Since there is some evidence that volatility tends to be
mean-reverting, often different versions of mean-reversion models are used.
For more details on stochastic volatility models and their simulation see, for
example, Glasserman (2004) and Hull (2008).

Modeling Asset Price Dynamics
451
12.6
STOCHASTIC PROCESSES
In this section, we provide an introduction to what is known as stochas-
tic calculus. Our goal is not to achieve a working knowledge in the
subject, but rather to provide context for some of the terminology and
the formulas encountered in the literature on modeling asset prices with
random walks.
So far, we discussed random walks for which every step is taken at a
speciﬁc discrete point in time. When the time increments are very small,
almost zero in length, the equation of a random walk describes a stochastic
process in continuous time. In this context, the arithmetic random walk
model is known as a generalized Wiener process or Brownian motion (BM).
The geometric random walk is referred to as Geometric Brownian Motion
(GBM), and the arithmetic mean-reverting walk is the Ornstein-Uhlenbeck
process mentioned earlier.
Special notation is used to denote stochastic processes in continuous
time. Increments are denoted by d or . (For example, (St+1 – St) is denoted
dSt, meaning a change in St over an inﬁnitely small interval.) The equations
describing the process, however, have a very similar form to the equations
we introduced earlier in this section:
dSt = µ dt + σdW
Equations involving small changes (“differences”) in variables are re-
ferred to as differential equations. In words, the equation above reads “The
change in the price St over a small time period dt equals the average drift µ
multiplied by the small time change plus a random term equal to the volatil-
ity σ multiplied by dW, where dW is the increment of a Wiener process.”
The Wiener process, or Brownian motion, is the fundamental building block
for many of the classical asset price processes. A standard Wiener process
W(t) has the following properties:
■For any time s < t, the difference W(t) – W(s) is a normal random
variable with mean zero and variance (t – s). It can be expressed as
√t −s · ˜ε, where ˜ε is a standard normal random variable.26
■For any times 0 ≤t1 < t2 ≤t3 < t4, the differences (W(t2) – W(t1)) and
(W(t4) – W(t3)) (which are random variables) are independent.27 Note
that independent implies uncorrelated.
■The value of the Wiener process at the beginning is zero, W(t0) = 0.

452
ASSET PRICING MODELS
Using the new notation, the ﬁrst two properties can be restated as
Property 1. The change dW during a small period of time dt is normally
distributed with mean 0 and variance dt, and can be expressed as
√
dt · ˜ε.
Property 2. The values of dW for any two nonoverlapping time intervals
are independent.
The arithmetic random walk can be obtained as a generalized Wiener
process, which has the form
dSt = a dt + bdW
The appeal of the generalized Wiener process is that we can ﬁnd a
closed-form expression for the price at any time period. Namely,
St = S0 + a · t + b · W(t)
The generalized Wiener process is a special case of the more general
class of Ito processes, in which both the drift term and the coefﬁcient in
front of the random term are allowed to be nonconstant. The equation for
an Ito process is
dSt = a(S, t) dt + b(S, t) dW
GBM and the Ornstein-Uhlenbeck process are both special cases of Ito
processes.
In contrast to the generalized Wiener process, the equation for the Ito
process does not allow us to write a general expression for the price at time t
in closed form. However, an expression can be found for some special cases,
such as GBM. We now show how this can be derived.
The main relevant result from stochastic calculus is the so-called Ito
Lemma, which states the following. Suppose that a variable x follows an Ito
process
dxt = a(x, t) dt + b(x, t) dW
and let y be a function of x, that is,
yt = f (x, t)

Modeling Asset Price Dynamics
453
Then, y evolves according to the following differential equation:
dy =
∂f
∂x · a + ∂f
∂t + 1
2 · ∂2 f
∂x2 · b2

dt + ∂f
∂x · b · dW
where the symbol ∂is standard notation for the partial derivative of the
function f with respect to the variable in the denominator. For example,
∂f
∂t
is the derivative of the function f with respect to t assuming that all terms
in the expression for f that do not involve t are constant. Respectively, ∂2
denotes the second derivative of the function f with respect to the variable
in the denominator, that is, the derivative of the derivative.
This expression shows that a function of a variable that follows an Ito
process also follows an Ito process.
A rigorous proof of Ito’s Lemma is beyond the scope of this book, but
let us provide some intuition. Let us see how we would go about computing
the expression for y in Ito’s Lemma.
In ordinary calculus, we could obtain an expression for a function of a
variable in terms of that variable by writing the Taylor series extension:
dy = ∂f
∂x · dx+ ∂f
∂t · dt + 1
2 · ∂2 f
∂x2 · dx2 + 1
2 · ∂2 f
∂t2 · dt2 + ∂2 f
∂x∂x · dxdt + · · ·
We will get rid of all terms of order dt2 or higher, deeming them “too
small.” We need to expand the terms that contain dx, however, because they
will contain terms of order dt. We have
dy = ∂f
∂x · (a(x, t) dt + b(x, t) dW) + ∂f
∂t · dt
+ 1
2 · ∂2 f
∂x2 · (a(x, t) dt + b(x, t) dW)2
The last expression in parentheses, when expanded, becomes (dropping
the arguments of a and b for notational convenience)
(a dt + bdW)2 = a2(dt)2 + b2(dW)2 + 2ab · dt · dW
= b2dt

454
ASSET PRICING MODELS
To obtain this expression, we dropped the ﬁrst and the last term in the
expanded expression because they are of order higher than dt. The middle
term, b2(dW)2, in fact equals b2 · dt as dt goes to 0. The latter is not an
obvious fact, but it follows from the properties of the standard Wiener
process. The intuition behind it is that the variance of (dW)2 is of order dt2,
so we can ignore it and treat the expression as deterministic and equal to its
expected value. The expected value of (dW)2 is in fact dt.28
Substituting this expression back into the expression for dy, we obtain
the expression in Ito’s Lemma.
Using Ito’s Lemma, let us derive the equation for the price at time t, St,
that was the basis for the simulation method in section 12.3.1. Suppose that
St follows the GBM
dSt = (µ · St) dt + (σ · St) dW
We will use Ito’s Lemma to compute the equation for the process fol-
lowed by the logarithm of the stock price. In other words, in the notation
we used in the deﬁnition of Ito’s Lemma, we have
yt = f (x, t) = ln St
We also have
a = µ · S
and
b = σ · S
Finally, we have
∂f
∂x = ∂(ln S)
∂S
= 1
S
and
∂2 f
∂x2 = ∂(1/S)
∂S
= −1
S2
Plugging into the equation for y in Ito’s Lemma, we obtain
d lnS =
1
S · a + 0 + 1
2 ·

−1
S2

· b2

dt + 1
S · b · dW
=

µ −1
2 · σ 2

dt + σ · dW

Modeling Asset Price Dynamics
455
which is the equation we presented earlier. This explains also the presence
of the
−1
2 · σ 2
term in the expression for the drift of the GBM.
As we will see in Chapters 13 and 14, some stochastic processes lead to
closed-form formulas for the prices of the underlying securities and ﬁnancial
derivatives on those securities. When the pricing is instead done by simu-
lation, we refer to the discretization of the underlying stochastic process,
and talk about the discretization error which occurs because in practice it is
computationally intractable (and in fact impossible) to simulate future prices
at inﬁnitely small time intervals. We need to resign to using time intervals of
ﬁnite length, and the larger the length of the time intervals, the greater the
divergence between the range of simulated prices and the prices we would
expect based on the closed-form formula, that is, the larger the discretization
error.
To illustrate the concept of discretization error, let us go back to the
example of simulation of a geometric random walk in section 12.3. The real
process for the price is described by the differential equation
dSt = µSt dt + σ St dW
To simulate paths for the price, we need to ﬁnd an approximation for
the terms dSt, dt, and dW. The simplest scheme for doing that is the Euler
scheme.29 Then we would get
St+t −St = µ · St · t + σ · St ·
√
t · ˜εt
As we mentioned in section 12.3.2, however, the distribution of each
St+t we generate in this manner is normal, not lognormal. (This is because
each St+t is the sum of constants plus a normal random variable, ˜εt.) If t
is very small, this discretization error can be reduced and the distribution of
the price after many steps will indeed approximate a lognormal distribution
with the correct parameters. However, this is computationally intensive and
time consuming. We can eliminate the discretization error altogether by
using Ito’s Lemma and the exact expression for the asset price we derived in
this section:
St = S0 · e(µ−1
2 ·σ 2)·t+σ·√t·˜ε

456
ASSET PRICING MODELS
However, such closed form results are not readily available for all
stochastic processes. Thus, when simulating in practice we must tolerate
some discretization error. With complicated stochastic differential equa-
tions, we can reduce the error by generating the whole path of the under-
lying variable (e.g., the stock price), even if we are only interested in what
happens at the end of the time horizon. Such reﬁned discretization schemes
are widely used in practice.
SUMMARY
■Models of asset dynamics include trees (such as binomial trees) and
random walks (such as arithmetic, geometric, and mean-reverting ran-
dom walks). Such models are called discrete when the changes in the
asset price are assumed to happen at discrete time increments. When
the length of the time increment is assumed inﬁnitely small, we refer to
them as stochastic processes in continuous time.
■The arithmetic random walk is an additive model for asset prices—at
every time period, the new price is determined by the price at the previous
time period plus a deterministic drift term and a random shock that
is distributed as a normal random variable with mean equal to zero
and a standard deviation proportional to the square root of the length
of the time period. The probability distribution of future asset prices
conditional on a known current price is normal.
■The arithmetic random walk model is analytically tractable and con-
venient; however, it has some undesirable features such as a nonzero
probability that the asset price will become negative.
■The geometric random walk is a multiplicative model for asset prices—at
every time period, the new price is determined by the price at the previous
time period multiplied by a deterministic drift term and a random shock
that is distributed as a lognormal random variable. The volatility of the
process grows with the square root of the elapsed amount of time. The
probability distribution of future asset prices conditional on a known
current price is lognormal.
■The geometric random walk is not only analytically tractable, but is
more realistic than the arithmetic random walk because the asset price
cannot become negative. It is widely used in practice, particularly for
modeling stock prices.
■Mean reversion models assume that the asset price will meander, but
will tend to return to a long-term mean at a speed called the speed of

Modeling Asset Price Dynamics
457
adjustment. They are particularly useful for modeling prices of some
commodities, interest rates and exchange rates.
■The codependence structure between the price processes for different as-
sets can be incorporated directly (by computing the correlation between
the random terms in their random walks), by using dynamic multifac-
tor models, or by more advanced means such as copula functions and
transfer entropies.
■A variety of more advanced random walk models are used to incorporate
different assumptions, such as time-varying volatility and “spikes,” or
jumps, in the asset price. They are not as tractable analytically as the
classical random walk models, but can easily be simulated.
■The Wiener process, a stochastic process in continuous time, is a basic
building block for many of the stochastic processes used to model asset
prices. The increments of a Wiener process are independent, normally
distributed random variables with variance proportional to the length
of the time period.
■An Ito process is a generalized Wiener process with drift and volatility
terms that can be functions of the asset price and time.
■A main result in stochastic calculus is Ito’s Lemma, which states that
a variable that is a function of a variable that follows an Ito process
follows an Ito process itself with speciﬁc drift and volatility terms.
SOFTWARE HINTS
@RISK
File Ch12-RandomWalks.xlsx contains examples of the estimation and sim-
ulation of four different types of random walks: arithmetic (worksheet
ARW), geometric (worksheet GRW), mean reversion (worksheet MR), and
geometric mean reversion (worksheet GMR).
Arithmetic random walk
Consider two years of historical data (104 ob-
servations) on Exxon Mobil weekly stock prices. The data are stored in cells
B4:B107 in worksheet ARW (cells B26:C106 are hidden). A screenshot of
the worksheet is provided in Exhibit 12.8.
To estimate the drift and the volatility of the arithmetic random walk,
we ﬁrst create a column (C), in which we compute the price changes St+1 –
St. For example, cell C5 contains the formula
=B5-B4

EXHIBIT 12.8
Worksheet ARW in spreadsheet Ch12-RandomWalks.xlsx.
458

Modeling Asset Price Dynamics
459
The drift µ of the arithmetic random walk is computed in cell E2 with
the formula
=AVERAGE(C5:C107)
The volatility σ of the arithmetic random walk is computed in cell E3
with the formula
=STDEV(C5:C107)
Note that these are estimates of the weekly drift and volatility of the
Exxon Mobil stock price because we estimated them from weekly data. If
we need to convert them to annual values, we should multiply the estimate
of the weekly drift by 52 (the number of weeks in a year), and the estimate
of the weekly volatility by
√
52.
In columns G through K, we simulate ﬁve paths for the arithmetic
random walk. Since the simulation implementations are identical, let us
focus on one of the columns, column G.
Cell G4 contains the starting price for the random walk (which is iden-
tical to the last price in our data set from cell B107). To simulate the price
at the next step in cell G5, we use the equation for the arithmetic random
walk from section 12.2.1. Cell G5 contains the formula
=G4+$E$2+$E$3*SQRT($F$5)*RiskNormal(0,1)
In words, we are adding the drift (from cell E2) to the current price, and
adding a random term that involves the volatility (from cell E3) multiplied
by the amount of time that expired during the ﬁrst step (one unit of time is
one week in this example, so we reference cell F5 and continue to reference
it as we generate further values for the random walk).
The path for the arithmetic random walk is plotted in the ﬁgure next to
columns G:K.
Geometric Random Walk
Consider two years of historical data (104 obser-
vations) on Exxon Mobil weekly stock prices. The data are stored in cells
B4:B107 in worksheet GRW (cells B26:C106 are hidden). A screenshot of
the worksheet is provided in Exhibit 12.9.
To estimate the drift and the volatility of the arithmetic random walk,
we ﬁrst create a column (C), in which we compute the natural logarithms of
the price ratios (St+1 / St). For example, cell C5 contains the formula
=LN(B5/B4)

EXHIBIT 12.9
Worksheet GRW in worksheet Ch12-RandomWalks.xlsx.
460

Modeling Asset Price Dynamics
461
The volatility σ of the geometric random walk is computed in cell E3
with the formula
=STDEV(C5:C107)
The drift µ of the geometric random walk is computed in cell E2 with
the formula
=AVERAGE(C5:C107)+0.5*E3ˆ2
Again, these are estimates of the weekly drift and volatility of the Exxon
Mobil stock price because we estimated them from weekly data. If we need
to convert them to annual values, we should multiply the estimate of the
weekly drift by 52 (the number of weeks in a year), and the estimate of the
weekly volatility by
√
52.
In columns G through K, we simulate ﬁve paths for the geometric ran-
dom walk. Since the simulation implementations are identical, let us focus
on one of the columns, column G.
Cell G4 contains the starting price for the random walk (which is iden-
tical to the last price in our data set from cell B107). To simulate the price
at the next step in cell G5, we use the equation for the geometric random
walk from section 12.3.1. Cell G5 contains the formula
=G4*EXP(($E$2-0.5*$E$3ˆ2)*$F$5+$E$3*SQRT($F$5)
*RiskNormal(0,1))
Again, the amount of time that expired during the ﬁrst step is one week
in this example, so we reference cell F5 and continue to reference it as we
generate further values for the random walk.
The path for the arithmetic random walk is plotted in the ﬁgure next to
columns G:K.
Mean Reversion
Consider two years of historical data (104 observations)
of the weekly USD/Euro exchange rate. The data are stored in cells B4:B107
in worksheet MR (cells B26:C106 are hidden). A screenshot of the worksheet
is provided in Exhibit 12.10.
To estimate the drift and the volatility of the arithmetic random walk, we
ﬁrst create a column (C), in which we compute the rate changes (St+1 – St).
In contrast to the arithmetic and geometric random walk, the matching
of rate changes with current rates is important because we will need to

EXHIBIT 12.10
Worksheet MR in worksheet Ch12-RandomWalks.xlsx.
462

Modeling Asset Price Dynamics
463
run a regression on these observations. For example, cell C4 contains the
formula
=B5-B4
and should be paired (in the same row) with cell B4, which contains the
current rate.
We run a regression with cells C3:C106 (the rate changes) as the real-
izations of the response variable, and cells B3:B106 as the realizations of the
explanatory variable (the current rate). In Excel, click the Data tab, click
Data Analysis, select Regression from the Analysis Tools, and ﬁll out the
dialog box as shown in Exhibit 12.11.
The output of the regression is in worksheet MR Regression. (See a
screenshot of the worksheet in Exhibit 12.12.) The important values are
highlighted.
The volatility σ of the mean reverting walk is stored in cell E3 of
worksheet MR, and equals the standard error of the regression (cell B7
EXHIBIT 12.11
Excel regression dialog box.

464
ASSET PRICING MODELS
EXHIBIT 12.12
Regression output for mean reversion model in worksheet
MR in the ﬁle Ch12-RandomWalks.xlsx.
in worksheet MR Regression), that is, cell E3 in worksheet MR contains the
formula
=’MR Regression’!B7
The speed of adjustment κ of the mean reverting walk is stored in cell
E4 of worksheet MR. It equals the negative of the slope coefﬁcient in the
regression (cell B18 in worksheet MR Regression), that is, the formula in
cell E4 is
=-’MR Regression’!B18
Note that the slope coefﬁcient in the regression (–0.0347) is negative,
which makes the speed of adjustment a positive number. If the slope coefﬁ-
cient was positive, we would not have been able to use the mean reverting
model. Technically, we should also make sure that the slope coefﬁcient is
statistically signiﬁcant. The p-value (cell E18 in worksheet MR Regression)
is somewhat large (0.1732), certainly larger than our threshold value of 0.05
(see section 12.4.2). However, the thresholds are not always clear-cut, and
it is the judgment call of the modeler as to whether to proceed and use the
model anyway. For the sake of example, let us use these estimates.

Modeling Asset Price Dynamics
465
The drift µ of the mean reverting walk is computed in cell E2 of work-
sheet MR with the formula
=-’MR Regression’!B17/’MR Regression’!B18
It is the ratio of the intercept term and the slope coefﬁcient in the
regression.
Again, these are estimates of the weekly drift, volatility, and speed of
adjustment of the random walk followed by the USD/Euro exchange rate
because we estimated them from weekly data. If we need to convert them to
annual values, we should multiply the estimate of the weekly drift by 52 (the
number of weeks in a year), and the estimate of the weekly volatility by
√
52.
In columns G through K of worksheet MR, we simulate ﬁve paths for
the mean reverting walk. Since the simulation implementations are identical,
let us focus on one of the columns, column G.
Cell G4 contains the starting rate for the random walk (which is identical
to the last price in our data set from cell B107). To simulate the rate at the
next step in cell G5, we use the equation for the mean reverting walk from
section 12.4.1. Cell G5 contains the formula
=G4+$E$4*($E$2-G4)+$E$3*SQRT($F$5)*RiskNormal(0,1)
Again, the amount of time that expired during the ﬁrst step is one week
in this example, so we reference cell F5 and continue to reference it as we
generate further values for the random walk.
The path for the mean-reverting walk is plotted in the ﬁgure next to
columns G:K.
Geometric Mean Reversion
Consider two years of historical data (104
observations) of the weekly USD/Euro exchange rate. The data are stored in
cells B4:B107 in worksheet GMR (cells B26:C106 are hidden). A screenshot
of the worksheet is provided in Exhibit 12.13.
To estimate the drift and the volatility of the arithmetic random walk, we
ﬁrst create a column (C), in which we compute the percentage rate changes
(St+1 – St)/St. As with the mean-reverting walk, the matching of rate changes
with current rates is important because we will need to run a regression on
these observations. For example, cell C4 contains the formula
= (B5-B4)/B4
and should be paired (in the same row) with cell B4, which contains the
current rate.

EXHIBIT 12.13
Worksheet GMR in worksheet Ch12-RandomWalks.xlsx.
466

Modeling Asset Price Dynamics
467
EXHIBIT 12.14
Excel regression dialog box.
We run a regression with cells C3:C106 (the percentage rate changes) as
the realizations of the response variable, and cells B3:B106 as the realizations
of the explanatory variable (the current rate). In Excel 2007, click the Data
tab, Data Analysis in the Analysis group, select Regression from the Analysis
tools and click OK. Fill out the dialog box as shown in Exhibit 12.14.
The output of the regression is in worksheet GMR Regression. (See a
screenshot of the worksheet in Exhibit 12.15.) The important values are
highlighted.
The volatility σ of the geometric mean reversion is stored in cell E3 of
worksheet GMR, and equals the standard error of the regression (cell B7 in
worksheet GMR Regression), that is, cell E3 in worksheet GMR contains
the formula
=’GMR Regression’!B7
The speed of adjustment κ of the geometric mean reversion is stored in
cell E4 of worksheet GMR. It equals the negative of the slope coefﬁcient in

468
ASSET PRICING MODELS
EXHIBIT 12.15
Regression output for mean reversion model in worksheet GMR
in the ﬁle Ch12-RandomWalks.xlsx.
the regression (cell B18 in worksheet GMR Regression), that is, the formula
in cell E4 is
=-’GMR Regression’!B18
Note that the slope coefﬁcient in the regression (–0.0253) is negative,
which makes the speed of adjustment a positive number. If the slope co-
efﬁcient was positive, we would not have been able to use the geometric
mean reversion model. As in the case of mean reversion, technically, we
should also make sure that the slope coefﬁcient is statistically signiﬁcant.
The p-value (cell E18 in worksheet GMR Regression) is somewhat large
(0.1646), certainly larger than our threshold value of 0.05. However, as in
the case of mean reversion, the thresholds are not exactly clear-cut, and it is
the judgment call of the modeler as to whether to proceed and use the model
anyway. For the sake of example, let us use these estimates.
The drift µ of the geometric mean reversion is computed in cell E2 of
worksheet GMR with the formula
=-’GMR Regression’!B17/’GMR Regression’!B18

Modeling Asset Price Dynamics
469
In columns G through K of worksheet GMR, we simulate ﬁve paths for
the mean reverting walk. Since the simulation implementations are identical,
let us focus on one of the columns, column G.
Cell G4 contains the starting rate for the random walk (which is the
same as the last price in our data set from cell B107). To simulate the rate
at the next step in cell G5, we use the equation for the mean reverting walk
from Chapter 12.4.3. Cell G5 contains the formula
=G4+$E$4*($E$2-G4)*G4+$E$3*SQRT($F$5)*RiskNormal(0,1))
Again, the amount of time that expired during the ﬁrst step is one week
in this example, so we reference cell F5 and continue to reference it as we
generate further values for the random walk.
The path for the mean reverting walk is plotted in the ﬁgure next to
columns G:K.
MATLAB
In this section, we will show how to generate paths for the arithmetic random
walk (ARW), geometric random walk (GWR), mean reversion (MR), and
geometric mean reversion (GMR). The implementation is summarized in the
following ﬁles:
Files ARWPaths.m, GRWPaths.m, MRPaths.m, and GMRPaths.m con-
tain functions that simulate and plot a given number of paths of the
corresponding random walk. (Recall from Appendix C that functions in
MATLAB need to be speciﬁed in separate ﬁles, and the name of the function
should be the same as the name of the ﬁle.)
File RandomWalks.m contains a script that puts everything together—it
reads in historical data on Exxon Mobil prices and on the US/Euro exchange
rate, estimates the parameters for the different random walks, and calls
the functions ARWPaths, GRWPaths, MRPaths, and GMRPaths to simulate
possible paths.
First, we read in the data that is stored in the Excel ﬁle Ch12-
RandomWalks.xlsx. To read in the Exxon Mobil stock price data we will use
for the arithmetic and the geometric random walk and record the number of
observations in the data set (numObsRW), we write the following commands:
ExxonPriceData = xlsread(’Ch12-RandomWalks.xlsx’,’ARW’,
’b4:b107’);
[numObsRW,nn] = size(ExxonPriceData);

470
ASSET PRICING MODELS
To read in the US/Euro exchange rate data we will use for the mean
reversion and the geometric mean reversion and to record the number of ob-
servations (numObsMR) in the corresponding data set, we write the following
commands:
USEuroRateData = xlsread(’Ch12-RandomWalks.xlsx’,’MR’,
’b4:b107’);
[numObsMR,nn] = size(USEuroRateData);
Arithmetic and Geometric Random Walks
To estimate the parameters
of the arithmetic random walk, we ﬁrst create a vector of price changes
priceChangesARW, and ﬁnd its mean muARW and standard deviation
sigmaARW. We then use those parameters as arguments to the function
ARWPaths to generate a number of paths (numPaths) speciﬁed by the user.
Similarly, to estimate the parameters of the geometric random walk,
we ﬁrst create a vector of natural logarithms of price ratios priceRatios-
GRW, and ﬁnd its mean muGRW and standard deviation sigmaGRW. We then
use those parameters as arguments to the function GRWPaths to generate
paths.
Mean Reversion and Geometric Mean Reversion
To estimate the pa-
rameters of the mean reversion, we ﬁrst create a vector of differences
priceChangesMR. We then use the regress function in MATLAB to run a
regression with priceChangesMR as the response variable and the original
data as the explanatory variable. Recall that when using the regress func-
tion in MATLAB, if we want MATLAB to estimate an intercept term, we
need to take an extra step, and add a vector of ones to the array of explana-
tory variables. At the end, the regression output is stored in a data structure
that can be retrieved: the ﬁrst element is a vector of coefﬁcients b (intercept
term and slopes), then output that is not of direct concern to us, and ﬁnally
a vector of statistics (stats). The fourth element in the stats vector is the
variance of error terms, which we can use to calculate the standard error of
estimate. (The standard error of estimate is the square root of the variance
of error terms, and is an estimate for the volatility parameter σ in the mean
reversion equation.)
We use the parameters we ﬁnd from the estimation step as arguments
to the function MRPaths to generate paths.
Similarly to the case of mean reversion, to estimate the parameters of the
geometric mean reversion, we ﬁrst create a vector of percentage differences
percentageChangesGMR. We then use the regress function in MATLAB

Modeling Asset Price Dynamics
471
to run a regression with percentageChangesGMR as the response variable
and the original data as the explanatory variable.
We then use the parameters we ﬁnd from the estimation step as argu-
ments to the function GMRPaths to generate paths.
NOTES
1. In general, we use the symbol  to denote difference. The notation t therefore
means time difference, that is, length of one time period.
2. See section 3.2 of Chapter 3.
3. See section 3.3 of Chapter 3.
4. See section 3.4 of Chapter 3.
5. This is known as the Markov property. It implies that past prices are irrelevant
for forecasting the future, and only the current value of the price is relevant for
predicting the price in the next time period.
6. To show this, we need to mention that every normal distribution can be ex-
pressed in terms of the standard normal distribution. Namely, if ˜ε is a standard
normal variable with mean 0 and standard deviation 1, and ˜x is a normal
random variable with mean µ and standard deviation σ, we have
˜ε = ˜x −µ
σ
(equivalently, ˜x = σ · ˜ε + µ)
This is a property unique to the normal distribution—no other family of prob-
ability distributions can be transformed in the same way. In the context of the
equation for the arithmetic random walk, we have a normal random variable ˜ωt
with mean 0 and standard deviation σ. It can be expressed through a standard
normal variable ˜εt as σ · ˜ε + 0.
7. The function normrnd in MATLAB requires the Simulation Toolbox.
8. See Chapter 2.
9. The function normrnd in MATLAB requires the Simulation Toolbox.
10. See Chapter 2 for a deﬁnition of log returns. Unless otherwise speciﬁed, we use
“logarithm” to refer to the natural logarithm, that is, the logarithm of base e. In
many references, as well as software packages such as Excel, the abbreviation
used for the natural logarithm is ln. In MATLAB, however, the function log
is the default for natural logarithm.
11. See section 3.7.2 of Chapter 3. There we stated that if ˜Y is a normal random
variable, then the random variable ˜X = e ˜Y is lognormal. In this case, log(St) is
a normal random variable. Therefore, eln(St) (i.e., St) is lognormally distributed.
12. As a general matter, if the logarithm of a random variable is normally dis-
tributed, then the random variable itself follows a lognormal distribution. The
lognormal distribution has a very convenient property, which is that products
of independent lognormal random variables are themselves lognormal random

472
ASSET PRICING MODELS
variables. This is another way to see that St is a lognormal random variable
given S0: it is a product of lognormal random variables, scaled by a constant
(S0):
St = (1 + ˜rt−1). . . . .(1 + ˜r0) · S0
13. This is based on a version of the Central Limit Theorem (see section 3.11.1).
14. See Vasicek (1977).
15. Y is a standard notation for the response variable, and X is a standard notation
for the array of explanatory variables data. See the instructions for running a
regression in the Software Hints for Chapter 11.
16. The standard error of the regression measures the standard deviation of the
points around the regression line.
17. See Cox, Ingersoll, and Ross (1985).
18. See section 3.7.2 of Chapter 3 for a deﬁnition of the chi-square random variable.
19. See Chapter 2 for a deﬁnition of yield and yield curve.
20. This is a special case of the mean reversion model St+1 = St + κ · (µ – St) · St +
σ · Sγ
t · ˜εt, where γ is a parameter selected in advance. The most commonly
used model has γ = 1.
21. As we explained earlier, the standard error of the regression measures the aver-
age variability of the points around the line.
22. Recall from Chapter 3 that covariance and correlation are, in general, not
equivalent with dependence of random variables. Covariance and correlation
measure only the strength of linear dependence between two random variables.
However, in the case of a multivariate normal distribution, covariance and
correlation are sufﬁcient to represent dependence.
23. See Chapter 11 for an introduction to factor models.
24. See, for example, Chapter 17 and Appendix B in Fabozzi, Focardi, and Kolm
(2006).
25. See section 3.7.2 for a deﬁnition of an exponential distribution.
26. To show this, recall that if ˜ε is a standard normal variable with mean 0 and stan-
dard deviation 1, and ˜x is a normal random variable with mean µ and standard
deviation σ, we have
˜ε = ˜x −µ
σ
(equivalently, ˜x = σ · ˜ε + µ)
In the context of Property 1 of the Wiener process, we have a normal random
variable (W(t) −W(s)) with mean 0 and standard deviation √t −s. It can be
expressed through a standard normal variable ˜ε as √t −s · ˜ε + 0.
27. These differences are the actual increments of the process at different points in
time.
28. To see this, recall from the properties of the standard Wiener process that the
difference between the values of the process between any two points in time
is distributed as a normal random variable with mean 0 and variance equal to

Modeling Asset Price Dynamics
473
the time difference itself. Therefore, dW (the difference over a very small time
interval dt) is distributed as a normal random variable with mean 0 and variance
dt, that is,
dW = ε ·
√
dt
where ε is a standard normal random variable. Finding the distribution of the
squared difference (dW)2 = ε2 · dt is not as easy (it is no longer normal). How-
ever, we can say something about the mean and the variance of that distribution.
The variance of a standard normal variable ε equals 1, and can be expressed as
E[ε2] – (E[ε])2 (see section 3.6.2 in Chapter 3). Since E[ε] = 0, we must have
E[ε2] = 1. Therefore, the expected value of (dW)2 = E[ε2] · dt = 1 · dt = dt.
29. The Euler scheme replaces small terms with discrete differences.


PART
Four
Derivative Pricing
and Use


CHAPTER13
Introduction to Derivatives
C
hapters 7 through 9 introduced the concept of risk management in the
context of investment management. We saw that diversiﬁcation was in-
strumental, and that a key statistical determinant of risk management poli-
cies was the ratio between the bulk of the risk and the risk of the tails of the
probability distribution of portfolio returns.
Financial ﬁrms and insurance companies have taken the concept of risk
management in three different directions: (1) by recognizing that the kind
of risk is an important determinant of the risk-return trade-off; (2) by en-
gineering contracts (“derivatives”) able to transfer selected portions of risk;
and (3) by trading these contracts. This part of the book focuses on item (2).
Derivative instruments, or simply derivatives, are contracts that derive
their value from underlying ﬁnancial securities such as stocks or bonds,
market indices, interest rates, currencies, or commodities. There are many
applications of ﬁnancial derivatives, but the two main purposes of including
them in an investor’s portfolio are risk management (with hedging as a
special case) and return enhancement (speculation). Risk management refers
to investment strategies whose goal is to control risk, and hedging is a
special case in which the goal is to eliminate risk. Return enhancement or
speculation refer to investment strategies that bet on the direction in which
the underlying uncertainties will be resolved, or attempt to take advantage
of perceived discrepancies in pricing to make a proﬁt. We discuss advanced
portfolio strategies that involve derivatives in Chapter 16.
Derivatives are either traded on an exchange or in the over-the-counter
(OTC) market. In other words, there are exchange-traded derivatives (also
referred to as listed derivatives) and OTC derivatives. OTC derivatives of-
fer portfolio managers customized solutions to deal with an investment
strategy. Exchange-traded derivatives are standardized contracts, and thus
may not provide the exact strategy the investment manager needs. How-
ever, exchange-traded derivatives are guaranteed by the exchange, whereas
OTC derivatives are the obligation of a nonexchange entity that is the
477

478
DERIVATIVE PRICING AND USE
counterparty in the contract. Thus, the user of an OTC derivative is subject
to the risk that the counterparty will not fulﬁll its contractual obligations.
This is referred to as credit risk or counterparty risk.
This chapter introduces the basic types of derivatives and explains some
standard principles for pricing these derivatives. A fundamental concept
underlying the construction and trading of derivatives is the concept of
arbitrage, so we discuss this concept in detail in this chapter. In the next
chapter, we discuss pricing derivative contracts by simulation.
13.1
BASIC TYPES OF DERIVATIVES
There are three general classes of derivatives: (1) forwards and futures, (2)
options, and (3) swaps. We review each class in this section.
13.1.1
Forwards and Futures
A forward contract is perhaps the simplest derivative. It is an agreement
to buy or sell an asset at a speciﬁc time in the future for a speciﬁc price.
Forward contracts are sold in the OTC market, that is, they are nonstandard
and negotiated directly between a buyer and a seller. The buyer of a forward
contract assumes a long position in the forward contract, and agrees to buy
the underlying asset at the prespeciﬁed price and date in the future. The
seller of a forward contract assumes a short position in the contract, and
agrees to sell the underlying asset at the prespeciﬁed price and date in the
future. The prespeciﬁed price (or “delivery price”) in the future is called the
forward price. When the underlying is a rate such as an interest rate or a
foreign exchange rate, the prespeciﬁed rate is referred to as a forward rate.
Forward contracts on currencies and commodities such as oil are par-
ticularly popular. For example, an American company that needs to make
a payment of €1 million in six months can eliminate its exchange rate risk
by buying a forward contract from a bank with settlement date six months
from now for €1 million that is, by assuming a long position in a forward
contract on euros at a USD/Euro forward exchange rate. The bank that
holds the short position in the forward contract will have to sell €1 million
in six months at the USD/Euro forward exchange rate.
Let T be the time to delivery of the forward contract, K be the forward
price at which the underlying asset will be traded at time T, and ST be the
cash market price of the underlying asset at T. It is easy to see that the ﬁnal
payoff from a long position in a forward contract is
ST −K

Introduction to Derivatives
479
This is because if the cash market price of the underlying asset ST is
higher than the forward price K, the holder of the long position will have
made a positive proﬁt by locking in the lower price through the contract. If,
on the other hand, the cash market price of the underlying asset ST is lower
than the forward price K, the holder of the long position will realize a loss
by locking in the higher price for the underlying. By similar reasoning, the
ﬁnal payoff from a short position in a forward contract will be
K −ST
Futures are very similar to forwards, but they are standardized con-
tracts traded on exchanges. Associated with every futures exchange is a
clearinghouse, which performs several functions. One of these functions is
to guarantee that the two parties to the transaction will perform. Because
of the clearinghouse, one party need not worry about the ﬁnancial strength
and integrity of the party taking the opposite side of the contract. After
initial execution of an order, the relationship between the two parties ends.
The clearinghouse interposes itself as the buyer for every sale and as the
seller for every purchase. Thus, the two parties are then free to liquidate
their positions without involving the other party in the original contract,
and without worry that the other party may default.
When a position is ﬁrst taken in a futures contract, the investor must
deposit a minimum dollar amount per contract as speciﬁed by the exchange.
This amount, called initial margin, is required as a deposit for the contract.
The initial margin may be in the form of an interest-bearing security such as
a Treasury bill. The initial margin is placed in an account, and the amount in
this account is referred to as the investor’s equity. As the price of the futures
contract ﬂuctuates each trading day, the value of the investor’s equity in the
position changes.
At the end of each trading day, the exchange determines the settlement
price for the futures contract. The settlement price is different from the
closing price, which is the price of the security in the ﬁnal trade of the day
(whenever that trade occurred during the day). By contrast, the settlement
price is that value which the exchange considers to be representative of
trading at the end of the day. The exchange uses the settlement price to
mark to market the investor’s position, so that any gain or loss from the
position is quickly reﬂected in the investor’s equity account.
Given that futures contracts are marked to market at the end of each
trading day, they are subject to interim cash ﬂows because additional mar-
gin may be required in the case of adverse price movements or because cash
may be withdrawn in the case of favorable price movements. In contrast,
a forward contract may or may not be marked to market.1 Thus, when a

480
DERIVATIVE PRICING AND USE
forward contract is marked to market, there are interim cash ﬂows just as
with a futures contract. When a forward contract is not marked to mar-
ket, then there are no interim cash ﬂows. Because there is no clearinghouse
that guarantees the performance of a counterparty in a forward contract,
the parties to a forward contract are exposed to counterparty risk. As we
explained earlier, this is not the case for futures contracts. Once a futures
contract is traded between two parties, the exchange itself (or the clearing-
house associated with the exchange) becomes the counterparty to the trade.
That is, neither party to the trade need be concerned with the other party to
the original trade. Rather both parties are exposed to the counterparty risk
of the exchange.
However, by virtue of being standardized contracts, futures contracts
may not meet the precise needs of investment managers. For example, most
ﬁnancial futures contracts have settlement dates in March, June, September,
and December. Thus, if an investment manager needs to lock in the price
for the underlying asset at dates that do not coincide with the standardized
settlement dates, he needs to ﬁnd a futures contract with terms that are
closest to the terms he would like to have.
13.1.2
Options
An option is a contract in which the option seller grants the option buyer
the right but not the obligation to enter into a transaction with the seller
to either buy or sell an underlying asset at a speciﬁed price on or before a
speciﬁed date. The speciﬁed price is called the strike price or exercise price,
and the speciﬁed date is called the expiration date or the maturity date. The
option seller grants this right in exchange for a certain amount of money
called the option premium or option price.
The option seller is also known as the option writer, while the option
buyer is known as the option holder. The asset that is the subject of the
option is called the underlying. The underlying can be an individual stock,
a stock index, a bond, an interest rate, an exchange rate, or even another
derivative instrument such as a futures contract. The option writer can
grant the option holder one of two rights. If the right is to purchase the
underlying, the option is referred to as a call option. If the right is to sell the
underlying, the option is referred to as a put option.
An option can also be categorized according to when it may be exercised
by the buyer, that is, by its exercise style. A European option can only be
exercised at the option’s expiration date. An American option, in contrast,
can be exercised any time on or before the expiration date. An option that can
be exercised before the expiration date but only on speciﬁed dates is called
a Bermuda option or an Atlantic option.

Introduction to Derivatives
481
Complex option contracts are referred to as exotic options or exotics.
Examples of exotic options include Asian options, which pay the difference
between the strike price and the average price of the underlying over a
prespeciﬁed period, and barrier options, whose payoff is determined by
whether the price of the underlying reaches a certain barrier over the life
of the option. There is, however, virtually no limit to the possibilities for
designing nonstandard derivatives.
Options, like other ﬁnancial instruments, may be traded either on an
organized exchange or in the OTC market. An option that is traded on
an exchange is referred to as a listed option or an exchange-traded option.
An option traded in the OTC market is called an OTC option or a dealer
option. The advantages of a listed option are as follows. First, the exercise
price and expiration date of the contract are standardized, making them
more liquid (that is, easier to trade prior to the expiration date). Second, as
in the case of futures contracts, the direct link between buyer and seller is
severed after the trade is executed because of the interchangeability of listed
options. Finally, the transactions costs are lower for listed options than for
OTC options.
The higher cost of an OTC option reﬂects the cost of customizing the
option for an investor whose investment objectives are not satisﬁed by the
standardized listed options. While an OTC option is less liquid than a listed
option, this is typically not of concern to the user of such an option. The
explosive growth in OTC options suggests that portfolio managers ﬁnd that
these products serve an important investment purpose.
Note that, unlike in a forward or a futures contract, one party to an
option contract is not obligated to transact—speciﬁcally, the option buyer
has the right but not the obligation to transact. The option writer does have
that obligation. In the case of a forward or futures contract, both buyer and
seller are obligated to transact. Of course, at the outset of the trade a forward
or a futures buyer does not pay the seller to accept the obligation, while an
option buyer pays the seller the option price. Consequently, the risk/reward
characteristics of option contracts are also different from those of futures
and forwards. In the case of a forward or a futures contract, the buyer of
the contract realizes a dollar-for-dollar gain when the price of the futures
contract increases and suffers a dollar-for-dollar loss when the price of the
futures contract decreases. The opposite occurs for the seller of a forward or
futures contract. Because of this relationship, forward and futures contracts
are said to have a linear payoff.
Options do not provide this symmetric risk/reward relationship. The
most that the buyer of an option can lose is the option price. While the
buyer of an option retains all the potential beneﬁts from a favorable price
movement of the underlying, the gain is always reduced by the amount of

482
DERIVATIVE PRICING AND USE
the option price. The maximum proﬁt that the writer may realize is the
option price; this is offset against substantial downside risk. Because of this
characteristic, options are said to have a nonlinear payoff.
The difference in the type of payoff between futures and options is very
important because market participants can use futures to protect against
symmetric risk and options to protect against asymmetric risk.2
Exhibit 13.1 shows the payoffs of different options graphically. For
comparison, the payoffs from a long and a short position in a forward
contract are shown as well, in Exhibit 13.1(A) and (B).
-80
-60
-40
-20
0
20
40
60
40
60
80
100
120
140
160
Stock Price at Expiration
(A)
-60
-40
-20
0
20
40
60
80
40
60
80
100
120
140
160
Stock Price at Expiration
(B)
-10
-5
0
5
10
15
20
25
30
35
40
50
55
60
65
70
75
80
85
90
95
100
105
110
115
120
125
130
135
140
145
150
Profit
Stock Price at Expiration
(C)
-40
-35
-30
-25
-20
-15
-10
-5
0
5
10
50
55
60
65
70
75
80
85
90
95
100
105
110
115
120
125
130
135
140
145
150
Profit
Stock Price at Expiration
(D)
-10
0
10
20
30
40
50
60
50
55
60
65
70
75
80
85
90
95
100
105
110
115
120
125
130
135
140
145
150
Profit
Stock Price at Expiration
(E)
-60
-50
-40
-30
-20
-10
0
10
50
55
60
65
70
75
80
85
90
95
100
105
110
115
120
125
130
135
140
145
150
Profit
Stock Price at Expiration
(F)
EXHIBIT 13.1
(A), (B): Payoffs of a long and a short position in a forward
contract, respectively, at their expiration date. Forward price = $110. (C), (D), (E),
(F): Payoffs of a call and a put option at their expiration date with assumed market
price of $5.00 each. Strike price = $110.00; initial stock price = $100. (C) Long
call; (D) Short call; (E) Long put; (F) Short put.

Introduction to Derivatives
483
Let us explain how the payoff of the basic option contract is determined
at the expiration date. We will denote the time to maturity of the option by
T, the underlying asset’s price at maturity by ST, and the strike price by K.
Buying a European Call Option (Long a Call Option)
A European call option
gives the option holder the right to buy the underlying asset for a price K
at maturity. If the market price ST at the expiration date is lower than the
strike price, the option holder will not exercise the option because it will
be cheaper to buy the underlying in the market, that is, the payoff from
the option will be zero, and the proﬁt from holding the option will be –C,
where C is the price of the call. If the market price ST at expiration date is
higher than the strike price, the option holder will exercise the option and
the payoff will be ST – K. Summarizing, the payoff from a European call
option to the option holder is
max{ST −K, 0}
and the proﬁt from the position is
max{ST −K, 0} −C
(See Exhibit 13.1(C).)
Selling a Call Option (Short a Call Option)
A European call option ob-
ligates the option writer to buy the underlying asset for a price K at the
expiration date if the option holder desires to buy it. Thus, the payoff and
proﬁt are exactly the mirror images of the payoff and proﬁt of the call op-
tion holder. If the market price ST at the expiration date is lower than the
strike price, the option holder will not exercise the option because it will be
cheaper to buy the underlying in the market. Therefore, the payoff from the
option to the writer will be C, the call option price. If the market price ST at
the expiration date is higher than the strike price, the option holder will ex-
ercise the option, resulting in a payoff to the option writer will be –(ST – K)
before considering the option price received. Summarizing, the payoff from
a European call option to the option writer is
−max{ST −K, 0}
and the proﬁt is
C −max{ST −K, 0}
(See Exhibit 13.1(D).)

484
DERIVATIVE PRICING AND USE
Buying a Put Option (Long a Put Option)
A European put option gives
the option holder the right to sell the underlying asset for a price K at the
expiration date. If the market price ST at the expiration date is higher than
the strike price, the option holder will not exercise the option because it will
be more proﬁtable to sell the underlying in the market, that is, the payoff
from the option will be zero, and the proﬁt from holding the option will
be –P, where P is the price paid for the put. If the market price ST at the
expiration date is lower than the strike price, the option holder will exercise
the option, that is, the payoff will be K – ST, before considering the cost of
acquiring the option. Summarizing, the payoff from a European put option
to the option holder is
max{K −ST, 0}
and the proﬁt from the position is
max{K −ST, 0} −P
(See Exhibit 13.1(E).)
Selling a Put Option (Short a Put Option)
A European put option obligates
the option writer to buy the underlying asset for a price K at the expiration
date if the option holder desires to sell it. Thus, the payoff and proﬁt of the
put option writer are exactly the mirror images of the payoff and proﬁt of
the put option holder. If the market price ST at the expiration date is higher
than the strike price, the option holder will not exercise the option because it
will be more proﬁtable to sell the underlying in the market. Thus, the payoff
from the option will be zero, and the proﬁt from holding the option to the
option writer will be P, where P is the price of the put. (When the market
price ST is higher than the strike price K for a European put option, we say
that the option is out-of-the-money.) If the market price ST at maturity is
lower than the strike price, the option holder will exercise the option, that
is, the payoff to the option writer will be –(K – ST). (When the market price
ST is lower than the strike price K for a European put option, we say that
the option is in-the-money.) Summarizing, the payoff from a European put
option to the option writer is
−max{K −ST, 0}
and the proﬁt from the position is
P −max{K −ST, 0}
(See Exhibit 13.1(F).)

Introduction to Derivatives
485
13.1.3
Swaps
Most generally, swaps are contractual agreements in which two counterpar-
ties agree to exchange returns on different assets over a prespeciﬁed period
of time. There are numerous types of swaps, including equity swaps, interest
rate swaps, and credit default swaps. We review some important types next.
Equity Swaps
Equity swaps are contractual agreements between two coun-
terparties which provide for the periodic exchange of cash ﬂows over a
speciﬁed time period. At least one of the two payments is linked to the
performance of an equity index, a basket of stocks, or a single stock. In
a standard or plain vanilla equity swap, one party agrees to pay the other
the total return to an equity index in exchange for receiving either the total
return of another asset or a ﬁxed or ﬂoating interest rate. All payments are
based on a notional amount and payments are made over a ﬁxed time period.
Equity swap structures are very ﬂexible, with maturities ranging from a
few months to 10 years. The returns of virtually any asset can be swapped for
another without incurring the transaction costs associated with trading in the
cash market. Payments that are exchanged between the two parties can be
denominated in any currency irrespective of the underlying equity asset and
payments can be exchanged monthly, quarterly, annually, or at maturity.
The equity asset can be any equity index or portfolio of stocks. An example
of an equity swap is a one-year agreement in which one party agrees to pay
the counterparty on a quarterly basis the total return on the S&P 500 index
in exchange for receiving the London Interbank Exchange Rate (LIBOR)
plus a speciﬁed spread. Both payments would be based on the notional
amount of the contract. This type of equity swap is the economic equivalent
of ﬁnancing a long position in the S&P 500 index at a spread to LIBOR. The
advantages of using the swap are no transaction costs, no sales or dividend
withholding tax, and no tracking error or basis risk versus the index.3
The basic mechanics of equity swaps are the same regardless of the struc-
ture. However, the rules governing the exchange of payments may differ.
For example, a U.S. investor who wants to diversify internationally can enter
into an equity swap and, depending on the investor’s investment objective,
exchange payments in such a way that he is protected against currency ﬂuc-
tuations. If the investment objective is to reduce U.S. equity exposure and
increase Japanese equity exposure, for example, an equity swap could be
structured to exchange the total returns to the S&P 500 index for the total
returns to the Nikkei 225 index. If, however, the investment objective is to
gain access to the Japanese equity market, an equity swap can be structured
to exchange LIBOR plus a spread for the total returns to the Nikkei 225
Index. The latter is an example of diversifying internationally and the cash

486
DERIVATIVE PRICING AND USE
ﬂows can be denominated in either yen or dollars. The advantages of enter-
ing into an equity swap to obtain international diversiﬁcation are that the
investor exposure is devoid of tracking error, and the investor incurs no sales
tax, custodial fees, withholding fees, or market impact cost associated with
entering and exiting a market. This swap is the economic equivalent of being
long the Nikkei 225 ﬁnanced at a spread to LIBOR at a ﬁxed exchange rate.
Interest Rate Swaps
Interest rate swaps are actually far more common
than equity swaps. Different types of interest rate swaps exist, including
plain vanilla (or generic) swaps, basis swaps, indexed-amortizing swaps,
and callable swaps, to name a few.
In its most basic form, an interest rate swap is an agreement between
two parties to exchange cash ﬂows periodically. In a plain vanilla swap,
one party pays a ﬁxed rate of interest based on a notional amount in return
for the receipt of a ﬂoating rate of interest based on the same notional
amount from the counterparty. These cash ﬂows are exchanged periodically
for the life (also known as the tenor) of the swap. Typically, no principal is
exchanged at the beginning or end of a swap.
The ﬁxed rate on a swap is ordinarily set at a rate such that the net
present value of the swap’s cash ﬂow is zero at the start of the swap contract.
This type of swap is known as a par swap, and the ﬁxed rate is called
the swap rate. The difference between the swap rate and the yield on an
equivalent-maturity Treasury is called the swap spread.
The ﬂoating rate on a swap is typically benchmarked off LIBOR or
constant maturity Treasury (CMT) rate. In a plain vanilla swap, the ﬂoating
rate is three-month LIBOR, which resets and pays quarterly.
Interest rate swaps can be callable or putable prior to the swap’s maturity
by one of the parties in the swap. They can also be part of popular interest
rate options called swaptions. We will discuss swaptions in section 14.4.4
of the next chapter.
Credit Default Swaps
Credit default swaps are the simplest example of
a credit derivative.4 They are contracts in which one party (the protection
buyer) pays a periodic premium to the counterparty (the protection seller)
in exchange for protection against a prespeciﬁed credit event. That is, a
credit default swap has a payout that is contingent upon the occurrence
of a credit event. The documentation on credit default swaps provides a
list of eight possible credit events: bankruptcy, credit event upon merger,
cross acceleration, cross default, downgrade, failure to pay, repudiation/
moratorium, and restructuring. Bankruptcy is deﬁned as a variety of acts
that are associated with bankruptcy or insolvency laws. Failure to pay results

Introduction to Derivatives
487
when a reference entity fails to make one or more required payments when
due. When a reference entity breaches a covenant, it has defaulted on its
obligation. When a default occurs, the obligation becomes due and payable
prior to the original scheduled due date (had the reference entity not de-
faulted). This is referred to as an obligation acceleration. A reference entity
may disafﬁrm or challenge the validity of its obligation. This is a credit event
that is covered by repudiation/moratorium. A restructuring occurs when the
terms of the obligation are altered so as to make the new terms less attractive
to the debt holder than the original terms.
The settlement of the contract can be physical or through a cash valu-
ation mechanism. With physical settlement, the protection buyer transfers
the reference obligations, typically bonds or loans, to the protection seller.
In return, the protection seller pays to the protection buyer a cash amount
equal to 100% of the notional of the transaction. In the case of cash set-
tlement, the protection seller pays to the protection buyer the difference
between the notional amount of the transaction and a ﬁnal value for the ref-
erence obligations. The ﬁnal value is typically determined through a dealer
poll. Cash settlement is less popular than physical settlement because of the
wide bid-offer spread on the obligation once the reference credit is distressed.
Credit default swaps can be more complex—for example, they can be
written on multiple reference obligations. In the latter case, they are referred
to as basket credit default swaps. We will discuss credit default swaps further
in the context of managing portfolio credit risk in Chapter 16.
13.2
IMPORTANT CONCEPTS FOR DERIVATIVE
PRICING AND USE
In the rest of this chapter, we will review classical approaches to the valu-
ation of some plain types of ﬁnancial derivatives in order to introduce im-
portant pricing concepts and terminology. These classical methods will be
contrasted with simulation methods for pricing classical and exotic deriva-
tives in Chapter 14.
Two concepts that underlie all derivative pricing methods we will
present are arbitrage and hedging. We explain their meaning next.
13.2.1
Arbitrage
Most generally, arbitrage is the opportunity to make “free money,” that
is, to realize a proﬁt with no risk. Academic deﬁnitions are more technical,
and generally refer to the opportunity to hold a portfolio of securities that

488
DERIVATIVE PRICING AND USE
can realize positive cash ﬂows today or at some point in the future without
realizing negative cash ﬂows at any point in time. Type A arbitrage is asso-
ciated with a situation in which an investor can make money immediately
and never has to pay anything in the future. You can think of it as investing
in a security that pays zero with certainty, but has a negative price today.
Type B arbitrage is associated with a situation in which an investment has a
nonpositive cost but a positive probability of yielding a positive payoff and
no probability of yielding a negative payoff.
When an investor attempts to make money by taking advantage of a
perceived arbitrage opportunity, he is said to have an arbitrage strategy.
Originally, realizing arbitrage opportunities was all about access to the right
information. Classic arbitrage involved buying a currency or a commodity
in one market and selling it as close to simultaneously as possible in another
market. Improved communications and increased competition have eroded
meaningful proﬁt opportunities in such traditional forms of arbitrage. Many
traders, however, switched to relative value arbitrage, which involves watch-
ing for distortions in the price relationship between different commodities
or currencies, or between them and ﬁnancial derivative instruments whose
payoff is based on them, using interest rates and other factors to estimate
the appropriate relative values.
In this and the following chapters, we will often talk about pricing a
ﬁnancial instrument by arbitrage. A ﬁnancial instrument can be either a
security or a derivative. What this means is that we can construct a portfolio
of other securities with observable prices that mimics the payoff of the
ﬁnancial instrument whose price we are trying to ﬁnd. If such a replicating
portfolio exists, then the price of the ﬁnancial instrument should be equal
to the cost of the replicating portfolio. If this is not the case, there will be
an arbitrage opportunity. Namely, if the price of the replicating portfolio is
higher than the price of the ﬁnancial instrument, then investors will choose
to short the replicating portfolio and buy the ﬁnancial instrument (which
will be cheaper relative to the replicating portfolio). This will realize an
immediate positive cash ﬂow with no future obligations, since the payoffs of
the two securities will be the same. Inversely, if the price of the replicating
portfolio is lower, then investors will choose to short the security and buy
the replicating portfolio, again realizing riskless proﬁt.
Typically, for pricing purposes, it is assumed that no arbitrage exists in
the market, otherwise investors would have already taken advantage of the
arbitrage opportunities and brought the prices of the securities involved into
alignment. Obviously, this is an assumption that does not always hold in
practice, and some investment managers focus explicitly on identifying and
exploiting such arbitrage opportunities.

Introduction to Derivatives
489
To illustrate the concept of arbitrage, let us consider a simple example.
Exhibit 13.2 presents a strategy for taking advantage of a Type A arbi-
trage opportunity. The prices of ﬁve bonds are $102.36, $110.83, $96.94,
$114.65, and $96.63. Their coupon payments at eight future dates are listed
in columns underneath the prices. For example, Bond 1 has a principal value
of $100, a 5% coupon rate paid semiannually, and a maturity of 2.5 years.
It makes four coupon payments of $2.50, after which it pays the principal
value and the last coupon payment.
Based on the output in Exhibit 13.2, consider the following portfolio:
Bond
Amount Invested
1
0
2
1,400.25
3
70.01
4
−14,927.40
5
14,999.51
The negative sign for the amount invested in Bond 4 means that this
bond was shorted.
This portfolio provides a nonnegative cash ﬂow at each coupon date
($0.00 at coupon payment dates 1, 2, 3, 4, 5, 7, and 8 and $140,025.33 at
date 6), and a cash ﬂow of $100,000 today. The cash ﬂow today appears
with a negative sign, but it is in fact a net inﬂow of cash generated by short
selling Bond 4 (that is, borrowing it and selling it in the market) and buying
the other bonds. The net cash ﬂows at the future coupon dates consist of the
positive cash ﬂows from long bond positions and the negative cash ﬂows for
the short position in Bond 4.
To ﬁnd the arbitrage strategy, we used linear programming, imposing
the constraints that at each coupon payment date, the cash ﬂow generated
from coupons should be nonnegative, and we minimized the cash ﬂow today.
In this example, we arbitrarily imposed a limit of $100,000 on the cash ﬂow
today. If an arbitrage strategy exists in this situation, technically, we could
make as much money as desired, since we can just invest multiples of the
amounts invested here. (See this chapter’s Software Hints and ﬁles Ch13-
Arbitrage.xlsx and Arbitrage.m for an actual implementation.)
Of course, we ignored many issues in this example. We assumed that
the bonds were inﬁnitely divisible (that is, we could trade portions of ac-
tual issues).5 We assumed that the bid and ask prices for the bonds were
the same.6 We also ignored transaction costs, issue size, and possible differ-
ences in the credit quality of these bonds that can account for the apparent

EXHIBIT 13.2
Five bonds that are priced in such a way that they allow for an arbitrage strategy.
Bond 1
Bond 2
Bond 3
Bond 4
Bond 5
Amounts
0.00
1,400.25
70.01
(14,927.40)
14,999.15
Cash ﬂow today
Prices
$102.36
$
110.83
$ 96.94
$
114.65
$
96.63
$(100,000.00)
Total
t=1
$
2.50
$
5.00
$
3.00
$
4.00
$
3.50
$
(0.00)
>=
0
t=2
$
2.50
$
5.00
$
3.00
$
4.00
$
3.50
$
(0.00)
>=
0
t=3
$
2.50
$
5.00
$
3.00
$
4.00
$
3.50
$
(0.00)
>=
0
t=4
$
2.50
$
5.00
$
3.00
$
4.00
$
3.50
$
(0.00)
>=
0
t=5
$102.50
$
5.00
$
3.00
$
4.00
$
3.50
$
(0.00)
>=
0
t=6
$
−
$
105.00
$
3.00
$
4.00
$
3.50
$ 140,025.33
>=
0
t=7
$
−
$
−
$103.00
$
4.00
$
3.50
$
(0.00)
>=
0
t=8
$
−
$
−
$
−
$
104.00
$
103.50
$
(0.00)
>=
0
490

Introduction to Derivatives
491
discrepancy. These issues should be carefully considered before a strategy is
actually implemented.
Sophisticated analytical models can be built to explore mispricing in
baskets of assets or derivatives on multiple assets, and optimization modeling
is a handy technique to help identify such opportunities. See Practice 13.2
on the companion web site for an example of using optimization to identify
arbitrage opportunities in the currency markets; and see Cornuejols and
Tutuncu (2007) for an example of using optimization to identify mispricing
in options on the same stock with different strike prices.
A special kind of arbitrage strategies often used in practice are so-called
risk arbitrage strategies, or equity arbitrage strategies. They are strategies
that involve the simultaneous purchase of shares in one company and the
short sale of shares in another. Such strategies are typically used in expec-
tation of a pending announcement of a takeover by a company or a merger
of two companies. By purchasing shares in the company that is expected to
be taken over (with the anticipation that its market value will increase) and
selling short shares in the acquiring company (with the anticipation that its
market value will decrease), an investor hopes to gain from both sides of
the trade.
Risk arbitrage strategies are not textbook arbitrage strategies because
they do not guarantee riskless proﬁt. The proﬁt depends on a number of
uncertain events. Simulation can be helpful for evaluating the risk of such
strategies. By incorporating assumptions about the behavior of the stock
prices and the likelihood that the deal goes through, an investor can obtain
an estimate of the risk involved in betting on the deal.
13.2.2
Hedging
A hedging strategy is a trading or investment strategy that reduces risk. For
example, consider an airline that will lose $1 million for every cent increase
in the price of jet fuel, and gain $1 million for every cent decrease in the
price of jet fuel. The airline sells tickets well in advance of the date of travel,
and incurs the risk of fuel price increases. To reduce that risk, suppose that
the airline buys futures on the price of jet fuel, which will guarantee that
it can buy jet fuel at a particular price. If the price of jet fuel increases, the
airline will lose money when it buys jet fuel but will make money on the
futures because they will be more valuable.7 So the airline will be able to
offset its risk.
If there were jet fuel futures in the market with the appropriate set-
tlement date, the airline may have been able to achieve a perfect hedge. A
perfect hedging strategy eliminates risk completely. However, in practice,
perfect hedge opportunities rarely exist. Even in cases in which one can

492
DERIVATIVE PRICING AND USE
ﬁnd a counterparty to take the opposite side in a contract with the desired
speciﬁcations, one incurs counterparty risk.
In the airline example, the airline would not be able to achieve a perfect
hedge. Two important reasons are that, ﬁrst, there are no futures on jet fuel,
and second, futures contracts are traded in the market and have prespeciﬁed
delivery dates that may not coincide with dates that are relevant to the
airline. The airline could purchase futures on crude or heating oil with
longer settlement dates than it needs. Generally, prices of jet fuel and oil
go hand in hand, although they are not perfectly correlated. If the price of
jet fuel goes up, the airline could sell the oil futures, which should go up
in value as well, and make up for at least some of its losses. See Case 13.1
in the Practice section on the companion web site for an example of how
simulation can be used to evaluate the risk of such a hedging strategy.
Who would take the opposite side in the futures contracts the airline
buys? There are companies that risk incurring losses if the price of oil goes
down. For example, an oil and gas company such as ExxonMobil would
hedge its risk by selling futures on oil.
The hedging strategy we discussed involved a hedge that was constructed
once, at the beginning. Hedging strategies can be also dynamic, that is, assets
can be traded over the duration of time for which the hedge is needed. The
celebrated Black-Scholes formula for pricing European options, which we
will discuss later in this chapter, relies on such a hedging strategy to come
up with the fair price of an option.
We will discuss more advanced portfolio hedging strategies in Chap-
ter 16.
13.3
PRICING FORWARDS AND FUTURES
The classical models for pricing futures are in fact models for pricing for-
wards. Different adjustments can be made depending on the speciﬁc features
of the contracts as well as the type of underlying asset. We will use the fol-
lowing notation:
■T is the time until the delivery date of the forward or futures contract
(in years);
■S0 is the cash price of the asset underlying the futures or forward contract
at time 0 (today);
■F0 is the price of the forward or futures contract at time 0 (today);
■r is the annual risk-free interest rate (with continuous compounding) for
an investment maturing at the delivery date T.

Introduction to Derivatives
493
The simplest forward contract is one written on an asset with no income,
such as a zero-coupon bond or a stock that does not pay dividends. In this
case, the forward price is given by
F0 = S0 · er·T
To see this, observe that if F0 > S0 · er · T, an investor can borrow S0 at
time 0 at the risk-free rate r, buy the asset, and take a short position in the
forward contract. At time T, the investor can deliver the asset under the
forward contract for a price of F0, and repay the loan, which at that time
is S0 · er · T. The investor will realize a riskless positive proﬁt F0 – S0 · er · T at
the settlement date, that is, there will be an arbitrage opportunity.
If the opposite holds, that is, F0 < S0 · er · T, an investor can take a long
position in the forward contract and short the asset. By shorting the asset,
the investor realizes a cash ﬂow of S0, which can then be invested at the
risk-free rate of r for a time period T. At the delivery date, the investor can
buy the asset for F0 under the terms of the forward contract, and close out
the short position in the asset. The proﬁt realized at maturity is S0 · er · T – F0.
Even though we used shorting in this argument, the formula above holds
also when shorting is not allowed.8
The formula can be generalized to include the case when the underlying
asset provides an income of I during the life of the forward contract. A
similar argument can be used to show that in that case, the fair forward
price should be
F0 = (S0 −I) · er·T
If, instead, we know that the asset will pay a continuous dividend yield
of q per annum, the formula is
F0 = S0 · e(r−q)·T
These pricing formulas also apply to futures prices; however, in such
cases they are only approximations. It can be shown that if the risk-free
interest rate is constant during the life of the contract, and the same for all
maturities, the price of a forward and a futures contract will be the same.
However, when interest rates vary, which is the case in the real world, we no
longer have such guarantees. For example, when interest rates increase and
the price of the underlying asset is strongly positively correlated with the level
of interest rates, futures prices tend to be higher than forward prices. This is
because an investor who holds a long futures position gains due to the daily
settlement procedure, which then allows the investor to invest the gains at

494
DERIVATIVE PRICING AND USE
a higher interest rate, whereas an investor holding a forward contract is not
necessarily affected in the same way. There are also a number of factors that
affect the theoretical prices of forward and futures contracts and the actual
trading price, such as the interim cash ﬂows, differences in borrowing and
lending rates, taxes, transaction costs, and treatment of margins.9 However,
for futures and forward contracts with short times to delivery (up to several
months), the price differences are often sufﬁciently small.
13.4
PRICING OPTIONS
Now let us look at the general principles of pricing options. The price of
an option is made up of two components: the intrinsic value and the time
premium over the intrinsic value.
The intrinsic value of an option is the maximum of zero and the value
the option would have if exercised immediately. The intrinsic value for an
American call option at any point in time t before its expiration, for example,
is max{St – K, 0}. When the intrinsic value of an option is positive, we say
that the option is in-the-money. When the intrinsic value is 0, we say that
the option is out-of-the-money.
The time premium, also called the time value of an option, is so named
because of the possibility of future favorable movements in the underlying’s
price. It equals the amount by which the market price of the option exceeds
its intrinsic value. For example, if the price of a call option with a strike
price of $100 is $12 when the underlying’s market price is $104, the time
premium of this option is $8 ($12 minus its intrinsic value of $4). Had the
underlying’s market price been $95 instead of $104, then the time premium
of this option would be the entire $12 because the option has no intrinsic
value. All other things being equal, the time premium of an option will
increase with the amount of time remaining to expiration. The time value
of the option equals zero after the expiration date, or when it is optimal to
exercise the option.
One can come up with bounds on the price of an option based on its
intrinsic value and its time premium. It can be shown, for example, that the
minimum price of an American call option at any point in time is its intrinsic
value. However, for most practical purposes this is not enough. Traders and
investors need a way to calculate the exact price of an option.
For a long time, practitioners did not know how to approach pricing
options. It was not until the Black and Scholes option pricing model was
introduced in 1973 that the tools for tackling problems of pricing options
of all kinds became available. Among those tools were:
■No-arbitrage pricing. The idea that the only kind of pricing that can be
stable is one that does not give rise to arbitrage opportunities.

Introduction to Derivatives
495
■Perfect hedging. The idea of creating a replicating portfolio that mimics
that payoffs of the option to be priced in all states of the world.
■Ito’s stochastic calculus. A previously obscure tool for modeling random
processes in physics that allowed for certain types of options to be priced
exactly given assumptions about the random process followed by the
price of underlying asset.
Basically, the idea behind deriving option pricing models is that if the
payoff from owning, say, a call option can be replicated by (1) purchasing
the underlying for the call option and (2) borrowing funds, then the price of
the option will be (at most) the cost of creating the replicating strategy.
This section introduces the binomial method for pricing European
and American equity options, as well as the Black-Scholes formula for
European options. Chronologically, binomial methods appeared after the
Black-Scholes model—they were suggested by Sharpe (1978), Cox, Ross,
and Rubinstein (1979), and Rendleman and Bartter (1979). However, the
binomial methods provide an intuitive introduction to the main ideas of
option pricing, so we discuss the binomial tree method ﬁrst.
13.4.1
Using Binomial Trees to Price
European Options
Binomial trees are a very popular method for pricing both European and
American options. In this section, we focus on European options. In section
13.4.3, we illustrate how the same concepts, together with the dynamic
programming technique, can be applied for pricing American options.
A Simple One-Period Example
Suppose we would like to ﬁnd the fair price
of a European call option with strike price K = $52 and time to maturity
T = 6 months (0.5 years) on a stock whose current price is $50. Let us start
simple. Suppose that at the end of T = 0.5 years the stock price can only
be in one of two states: it can go up to $60, or it can go down to $42. The
probability of the stock price going up is 60%. The probability of the stock
price going down is 40%. The risk-free rate is 10%.
In what follows, we use the assumption that there is no arbitrage in the
market to derive the price of the option. The main idea is the following.
We set up a portfolio of the stock and the option in such a way that there
is no uncertainty about the value of the portfolio at the end of six months.
We then argue that, because there is no risk, the return the portfolio will
earn should equal the risk-free rate (otherwise, there will be an arbitrage
opportunity). This will enable us to work out the cost of setting up the
portfolio and, therefore, the price of the option. Since there are two assets
(the stock and the option) and only two possible outcomes (up or down),

496
DERIVATIVE PRICING AND USE
Stock price
60.00
$
50.00
$
42.00
$
Call payoffs
8.00
$
C=?
-
$
Portfolio value
60*Δ - 8
50*Δ-C
42*Δ
EXHIBIT 13.3
One-period binomial
tree with values for the stock, payoffs
for the call option, and the value of a
portfolio consisting of a long position in
 shares of stock and a short position in
the option.
it is always possible to set up the riskless portfolio. While this is a simple
argument, it can be extended to a more general setting in which there are
inﬁnitely many possible states for the stock price. This is the idea behind the
Black-Scholes formula, which we will introduce in the next section.
Consider a portfolio that consists of a long position in  shares of stock
and a short position in one call option. What is the value of  that makes
the portfolio riskless?
If the stock price goes up from $50 to $60, the value of the shares is
$60, and the value of the call option is max{$60 – $52,0} = $8. Therefore,
the total value of the portfolio is ($60 – $8).
If the stock price goes down from $50 to $42, then the value of the
shares is $42, and the value of the call option is max{$42 −$52,0} =
$0. Therefore, the total value of the portfolio is $42. This is illustrated in
Exhibit 13.3.
In order for the portfolio to be riskless, its future value should be the
same independently of the state of the world in which the stock price ends
up. Therefore, we have the condition
$60 −$8 = $42
that is,  = $8/$18 = 0.4444. Therefore, a riskless portfolio would consist
of a long position in 0.4444 shares of the stock, and a short position in 1 call
option. The value of the portfolio is $60 · 0.4444 – $8 (or 42 · 0.4444) =
$18.67 in both states of the world.

Introduction to Derivatives
497
Since the portfolio is riskless, it must earn the risk-free rate of interest,
10%. Given that the portfolio value is $18.67 half a year from the current
date, the present value of the portfolio can be calculated by discounting
its future value, $18.67, by the risk-free rate. Therefore, the value of the
portfolio today is
$18.67 · e−0.10·0.5 = $17.76
We know the value of the stock part of the portfolio today—it is the
current price of the stock ($50) times the number of shares (0.44). Therefore,
we can ﬁnd the value of the call option (C) today. Namely, we have
$50 · 0.4444 (the value of the shares today) −1 · C
= $17.76 (the present value of the portfolio),
or
C = $4.46
By the way, notice that we never used the information about the prob-
abilities of the stock price going up or down. In fact, all the information
we needed about the stock was already incorporated into the values of the
stock prices in the up and the down state. It turns out that there are different
probabilities that are at play, and those are the probabilities that determine
possible values for the stock price one period from now. We explain the
intuition behind this fact next.
Risk-Neutral Probabilities
Now let us generalize the method from the
previous section. Suppose that the stock price today is S0, and it can go up
to uS0 or down to dS0 over a given period t. We would like to ﬁnd the
value f of an option written on the stock. Let the payoffs of the derivative
in the up and the down state of the world be fu and fd, respectively.
We take a long position in  shares of stock and a short position in one
call option. The portfolio values in the up and the down states are
(uS0) ·  −fu
and
(dS0) ·  −fd
respectively. The two portfolio values are the same when
(uS0) ·  −fu = (dS0) ·  −fd
that is, when
 =
fu −fd
uS0 −dS0

498
DERIVATIVE PRICING AND USE
The above equation shows that  is actually the ratio of the change in
the option price and the change in the stock price. We will come back to
this observation in section 13.4.4.
The present value of the portfolio is
((uS0) ·  −fu) · e−r·(t)
The value of the portfolio today is also (S0 ·  – f), therefore,
((uS0) ·  −fu) · e−r·(t) = (S0 ·  −f )
From here we deduce that the fair value of the option today is
f = S0 ·  −((uS0) ·  −fu) · e−r·(t)
Substituting the value for , we get
f = e−r·(t) · (p · fu + (1 −p) · fd)
where
p = er·(t) −d
u −d
The parameter p in the expression for the option price f can be viewed
as a special probability. It is in fact called a risk-neutral probability. Note
that if we use this new probability, the value of the option today equals
the expected value of its future payoffs, fu and fd. In fact, this is the same
probability that makes the value of the stock today equal to the expected
value of its discounted future values when the discount rate is the risk-free
rate. To see this, note that in our example in the previous section, we had
u = $60/$50 = 1.20
d = $42/$50 = 0.84
t = 0.5
fu = $8
fd = $0
p = e0.10·(0.5) −0.84
1.20 −0.84
= 0.5869
1 −p = 0.4131

Introduction to Derivatives
499
The value of the call option today was10
C = e−0.10·0.5 · (0.5869 · $8 + (1 −0.5869) · $0) = $4.47
The expected value of the stock under this probability distribution to-
day, assuming that the return on the stock is the risk-free rate, is
e−0.10·0.5 · (0.5869 · $60 + (1 −0.5869) · $42) = $50.00
which was indeed its current value.
Generalization to Multiple Periods
The formula for the price of the option
as an expected value of its discounted payoffs under a risk-neutral proba-
bility measure can be derived for multiple time periods. For example, if we
have two time periods, we get
f = e−2r·(t) 
p2 · fuu + 2 · p · (1 −p) · fud + (1 −p)2 · fdd

Note that the coefﬁcients in front of the terms containing the probabil-
ities p count how many ways there are to get to the particular end node in
the tree. For example, there are two ways to get a payoff of fud: the stock
price can go up ﬁrst and then down (probability p · (1 – p)), or down ﬁrst
and then up (probability (1 – p) · p). So, the probability of getting a payoff
of fud is 2 · p · (1 – p). To get f, the expected value of the option today, we
take the weighted average of all possible future payoffs (with weights that
are products of the risk-neutral probabilities), and discount it to the present.
Exhibit 13.4 shows the example of pricing the same call option as
in the previous section, but over two time periods (rather than one). The
parameters u, d, and p are slightly different—they are adjusted for the fact
that each time period has a shorter length than the time period considered in
the previous section. Now u = 1.13, d = 0.88, p = 56.99%. We will explain
their exact computation in section 13.4.2.
At time 0, we start with an initial stock price of $50. At time 1, we have
two possible prices: $50 · 1.19 = $56.67 and $50 · 0.88 = $44.12. At the
option’s expiration date, we have three (instead of two) possible values for
the underlying stock price: $64.22, $50.00, and $38.93.11 You can imagine
that as you continue to divide the time to maturity into smaller and smaller
intervals, you will obtain a large number of possible stock prices at the
expiration date, which will represent the possible states of the world better.
In Exhibit 13.4, we show the value of the option in the possible states of
the world at time 0, 1, and 2. At time 2, we simply compute the payoffs of

500
DERIVATIVE PRICING AND USE
64.22
$
Stock price
56.67
$
50.00
$
50.00
$
44.12
$
38.93
$
12.22
$
Call value
6.79
$
3.78
$
-
$
-
$
-
$
t =0
t =1
t =2
EXHIBIT 13.4
Pricing of a European call option using
a two-period binomial tree.
the option. For example, the top payoff at time 2 is $12.22 = max{$64.22 –
$52.00,0}. We ﬁll out the remaining two nodes at time 2 similarly. If we use
the formula for the value of the option at the beginning of this section, we
get the following value for the European call price:
C = e−0.10·0.5 · (0.56992 · $12.22 + 2 · 0.5699 · (1 −0.5699) · $0
+ (1 −0.5699)2 · $0) = $3.78
Basically, we weighted all ﬁnal payoffs at time 2 by the probabilities of
obtaining them, and discounted the weighted average to time 0. For example,
the payoff of $12.22 was weighted by 0.56992 because in order to obtain
it, the stock price needs to go up at time period 1, and then up again at time
period 2.
Let us show how we would compute the option value at each time
period. Although we do not need to do it in the case of European options,
it is instructive for when we discuss American options in section 13.4.3.
The value of $6.79 obtained at time 1 in Exhibit 13.4 is the discounted
expected payoff from the two nodes at time 2 that are reachable from the
node at time 1:
$6.79 = e−0.10·(0.5/2) · (0.5699 · $12.22 + (1 −0.5699) · $0)
Note that the discount factor takes into consideration the fact that the
time period is of length T/2. Similarly, we can compute the second possible
value for the option at time 1. (It turns out that value is 0, since it is the
expected value of two zero payoffs.)

Introduction to Derivatives
501
$       -
Put value
$  0.84
3.23
$
$  2.00
$  6.60
$  13.07
t =0
t =1
t = 2
EXHIBIT 13.5
Pricing a European put option with a
two-period binomial tree.
At time 0, we compute the discounted expected value of the option
values at time 1, that is,
e−0.10·(0.5/2) · (0.5699 · $6.79 + (1 −0.5699) · $0)
This gives us the price of the option, $3.78.
We can similarly compute the price of a put option on the same stock.
The only thing we need to change is how we compute the option payoffs
at time 2, which in turn changes the option values at time 0 and 1 (see
Exhibit 13.5).
What if there are more time periods? Suppose there are n time periods,
each of length t (that is, t = T/n, where T is the maturity of the option).
Then,
f = e−n·r·(t)

pn · fn +
n
n −1

· pn−1 · (1 −p) · fn−1 + . . .
+
 n
1

· p · (1 −p) ·n−1 · f1 + (1 −p)n · f0

= e−n·r·(t)

n
j=0
n
j

· pj · (1 −p)n−j · fj
	
In the above formula, fj = max(u jdn−j S0 −K, 0) for a European call
option, and fj = max(K −u jdn−j S0, 0) for a European put option (j = 0,
1, . . . , n).12
As we mentioned earlier, even though we assume that the stock price
can only take a discrete set of values, if we divide the time to maturity of the
option T into many small time periods, there will be many possible values
(end nodes) for the ﬁnal stock price. This allows us to price the option quite
accurately.

502
DERIVATIVE PRICING AND USE
13.4.2
The Black-Scholes Formula for
European Options
Instead of assuming that the future stock price can take only two values—uS0
or dS0—the Black-Scholes model assumes that the future stock price can
take a continuous range of values with a speciﬁc probability distribution,
the lognormal distribution. The Black-Scholes formulas for a European call
(C) and put (P) option are as follows:
C = S0 · e−qT · (d1) −K · e−rT · (d2)
and
P = K · e−rT · (−d2) −S0 · e−qT · (−d1)
where
d1 = ln(S0/K) + (r −q + σ 2/2) · T
σ ·
√
T
d2 = d1 −σ ·
√
T
K is the strike price.
T is the time to maturity.
q is the percentage of stock value paid annually in dividends.
 denotes the cumulative probability density function for the normal
distribution.13
To illustrate the Black-Scholes option pricing formula, assume the fol-
lowing values:
Current stock price (S0) = $50
Strike price (K) = $52
Time remaining to expiration (T) = 183 days = 0.5 years (183 days/365,
rounded)
Stock return volatility (σ) = 0.25 (25%)
Short-term risk-free interest rate = 0.10 (10%)

Introduction to Derivatives
503
Plugging into the formula, we obtain
d1 = ln(50/52) + (0.10 −0 + 0.252/2) · 0.5
0.25 ·
√
0.5
= 0.1502
d2 = 0.1502 −0.25 ·
√
0.5 = −0.0268
(0.1502) = 0.5597
(−0.0268) = 0.4893
C = 50 · 1 · 0.5597 −52 · e−0.10·0.5 · 0.4893 = $3.79
(See this chapter’s Software Hints, worksheets B-S and B-S VBA in the ﬁle
Ch13-BlackScholes.xlsm, and ﬁle BSPrice.m for an implementation of the
formula.)
It is a good idea to check how sensitive the Black-Scholes price is to
the values of different inputs. We have implemented that using Excel Data
Tables14 in worksheet B-S of ﬁle Ch13-Pricing.xlsx, and you can also easily
create a script in MATLAB that computes the value of Black-Scholes call
price for different values of one of the input parameters, such as time to
expiration or volatility.
Prices of European call and put options with the parameters above, but
using the Black-Scholes formula for different values of the time to maturity
T and the volatility σ, are given in Exhibit 13.6.
EXHIBIT 13.6
Prices of European call and put options for different values of the
time to maturity T and the volatility σ.
Time to Expiration
(Years)
Call
Put
Volatility
Call
Put
0.5
$ 3.78
$3.24
10%
$ 1.69
$ 1.15
1.0
$ 6.44
$3.49
20%
$ 3.09
$ 2.54
1.5
$ 8.76
$3.51
30%
$ 4.48
$ 3.94
2.0
$10.86
$3.43
40%
$ 5.88
$ 5.33
2.5
$12.81
$3.31
50%
$ 7.26
$ 6.72
3.0
$14.63
$2.15
60%
$ 8.64
$ 8.10
3.5
$16.35
$2.99
70%
$10.10
$ 9.46
4.0
$17.97
$2.82
80%
$11.36
$10.82

504
DERIVATIVE PRICING AND USE
It is easy to observe that both calls and puts become more valuable as
the volatility of the process for the underlying price increases. Also, the call
option becomes more valuable as the time to expiration increases.
While the Black-Scholes formula is still widely used in practice, it is
not always well understood. It is important to realize that the formula only
applies under very speciﬁc assumptions.
■Assumption 1. The option to be priced is a European option.
The Black-Scholes model assumes that the call option is a European
call option. It is not appropriate to use the Black-Scholes model (except
as a part of approximation schemes) when derivatives with American
features are priced. The binomial option pricing model, which we de-
scribed in the previous section, can easily handle American call options.
■Assumption 2. The stock return volatility σ is constant over the life of
the option and known with certainty.
If the ﬁrst part of the assumption does not hold, an option pricing
model can be developed that allows the variance to change. The violation
of the second part of the assumption, however, is more serious. Because
the Black-Scholes model depends on the riskless hedge argument and, in
turn, the stock return volatility must be known to construct the proper
hedge, if the stock return volatility is uncertain, the hedge will not be
riskless.
■Assumption 3. The risk-free rate r is constant over the life of the option,
and is the same for borrowing and lending.
The ﬁrst part of the assumption is unrealistic because interest rates
change daily. As we will show in section 14.1.1, the model can be made
more realistic by using simulation. The second part of the assumption is
unlikely to hold as well because in real-world ﬁnancial markets borrow-
ing rates are higher than lending rates. Realistically, the market price
for a call option would be between the call prices derived from the
Black-Scholes model using the two interest rates.
■Assumption 4. The stochastic process generating stock prices is a diffu-
sion process.
To derive an exact option pricing model, an assumption is needed
about the way stock prices move. As we will show shortly, the Black-
Scholes model is based on the assumption that stock prices follow a
diffusion process (geometric random walk). In other words, the future
stock price is assumed to be determined from the equation
ST = S0e(r−q−1
2 σ 2)·T+σ·
√
T·˜ε
where ˜ε is a standard normal random variable, ˜ε ∼(0,1). Recall that
in a diffusion process, the stock price can take on any positive value, but

Introduction to Derivatives
505
it does not jump from one stock price to another, skipping over interim
prices. The Black-Scholes formula does not apply when stock prices fol-
low a jump process; that is, when prices are not continuous and smooth,
but exhibit jumps. Merton (1973) and Cox and Ross (1979) have de-
veloped alternative option-pricing models assuming a jump process for
the price of the underlying.
■Assumption 5. There are no transaction costs and taxes.
The Black-Scholes model ignores taxes and transaction costs. The
model can be modiﬁed to account for taxes, but the problem is that there
is not just one tax rate. Transaction costs include both commissions and
the bid-ask spreads for the stock and the option, as well as other costs
associated with trading options.
Estimating the Parameters in the Black-Scholes Formula
Most of the
parameters in the Black-Scholes formula—the initial stock price, the time
to maturity, the short-term risk-free interest rate—can be observed directly.
The one parameter that needs to be estimated is the volatility of the un-
derlying asset’s price. Market participants determine this input into the
Black-Scholes option pricing model in one of two ways: (1) by calculating
the implied volatility from current option prices or (2) by calculating the
standard deviation using historical daily stock returns.
Calculation of the implied probability relies on the fact that an option
pricing model relates a given volatility estimate to a unique price for the
option. If the option price is known, the same option pricing model can
be used to determine the corresponding volatility. Therefore, the volatility
to use in the pricing model for an option we seek to value can be implied
from observed market prices for other options on the same stock. (See this
chapter’s Software Hints for the implementation of an example.)
In addition to its use as input in an option pricing model, implied volatil-
ity has other applications in strategies employing options. The most straight-
forward application is a comparison of implied volatility with the estimate
of volatility using historical return data, which we will describe shortly. If
an investor believes that the estimated volatility using historical data is a
better estimate than implied volatility, then the two volatility estimates can
be compared to assess whether an option is cheap or expensive. Speciﬁ-
cally, if the estimate of volatility using historical data is higher than implied
volatility, then the option is cheap; if it is less than implied volatility, then
the option is expensive.
A further use for implied volatility is to compare put and call options
on the same stock and with the same time to expiration. Implied volatility
can also be used to compare options on the same underlying stock and
time to expiration but with different strike prices. For example, suppose

506
DERIVATIVE PRICING AND USE
Strike Price
Implied Volatility
EXHIBIT 13.7
Volatility smile for
in-the-money call options.
that the implied volatility for a call option with a strike price of 90 is 8%
when a call option with a strike of 100 has an implied volatility of 12%.
Then, on a relative basis, the call option with a strike of 90 is cheaper
than the call option with a strike of 100. One fact to keep in mind for
latter application, however, is that a phenomenon called volatility smile is
often naturally observed in option markets. Namely, implied volatilities for
options on the same stock but with different strike prices exhibit a pattern
similar to the pattern in Exhibit 13.7. More speciﬁcally, options that are
at-the-money tend to have a lower implied volatility than options that are
out-of the-money or in-the-money. When trying to determine the “correct”
volatility to use for pricing a new option, practitioners often use a quick and
dirty approach: they interpolate between volatility values on the smile.15
The second method used to estimate stock return volatility is to calculate
the standard deviation of historical daily stock returns. Market practices
with respect to the number of trading days that are used to calculate the
daily standard deviation vary. The number of trading days can be as few as
10 or as many as 100. Since market participants are interested in annualized
volatility, the daily standard deviation is annualized as follows:
Daily standard deviation ·

Number of trading days in a year
Conventions about the number of trading days in a year to use vary as
well. Typically, either 250, 260, or 365 trading days are used. The ﬁrst two
are used because they represent the number of actual trading days for certain
options. Given the different conventions about the number of trading days
of data to use for the estimation and the number of trading days in a year
to use for annualizing the estimated historical daily volatility, estimates of
historical volatility can vary signiﬁcantly.

Introduction to Derivatives
507
Whereas historical volatility estimates are backward-looking, implied
volatility estimates are forward-looking, in the sense that the latter incor-
porate market participants’ expectations about where the volatility will be.
Generally, implied volatility estimates are preferred, but sometimes they are
not easy to produce. Sometimes, a combination of historical and implied
volatilities is used.
The Black-Scholes Option Pricing Formula and Geometric Random Walks
We will now show that the assumption that the underlying asset price follows
a geometric random walk leads to the Black-Scholes formula. We will focus
on deriving the formula for the price of a European call option. (The formula
for the price of a European put option can be derived in a similar way.) Recall
that the assumption that the stock price follows a geometric random walk
means that the future stock price at time T is lognormally distributed (that
is, that the log of the stock returns at time T is normally distributed).
The call value equals the discounted expected value of the call payoffs
under the risk neutral probability distribution. We can write
C = e−rTE[max(ST −K, 0)]
This expression can be rewritten as
C = e−rTE[ST|ST > K] −e−rTE[K|ST > K]
As explained in Chapter 3, E[. | .] denotes conditional expectation. For
example, E[ST|ST > K] is the expectation of the possible values for the
future stock price conditional on the fact that the future stock price value is
greater than the strike price K. (This is because we do not worry about the
case when the stock price is less than the strike price; the payoff from the
call option in the latter case is zero.)
As mentioned before, the fact that the log of the stock returns is normally
distributed means that ST = S0e ˜ωT, where ˜ωT is a normal random variable
with mean m = (r −q −0.5 · σ 2) · T and standard deviation s = σ ·
√
T.
(Note that we replaced µ, the drift of the geometric random walk for the
stock price, with r, the risk-free rate. This is because we will be doing the
computations in a risk-neutral world, where the rate of return for all assets
is assumed to be the risk-free rate.)
Recalling the fact that an expectation is a weighted average, the expected
value in the second term of the formula for the call price can be written as
K · P(ST > K), where “P” stands for “probability.” Since ST = S0e ˜ωT, the
expectation can be written as
K · P(S0e ˜ωT > K) = K · P( ˜ωT > ln(K/S0))

508
DERIVATIVE PRICING AND USE
This expression implies that the option will be exercised only if the value
of ˜ωT is greater than ln(K/S0).
˜ωT can be converted to a standard normal variable, ˜εT, by subtracting
its mean and dividing by its standard deviation.16 Thus, the variable
˜εT = ˜ωT −m
s
has a standard normal distribution. The cumulative normal distribution
function, (d), gives the probability in the left-hand tail of the distribution,
that is, P(˜εT < d). The expression (−d) then gives the probability in the
right-hand tail of the standard normal distribution. (Here we are using the
fact that the normal distribution is symmetric.)
We can write
P( ˜ωT > ln(K/S0)) = P

˜εT > ln(K/S0) −m
s

= P

˜ε < −ln(K/S0) −m
s

= P

˜ε < −ln(K/S0) + m
s

= P

˜ε < ln(S0/K) + (r −q −1
2σ 2)T
σ
√
T

= P (˜ε < d2)
This is where the second term in the Black-Scholes call option pricing
formula comes from. The ﬁrst term can be derived similarly, but involves
more complicated mathematical transformations, so we will omit it here.
Relationship between the Black-Scholes Option Pricing Formula and the
Binomial Tree Pricing Model
We showed in section 13.4.1 that
f = e−n·r·(t) ·
⎡
⎣
n

j=0
n
j

· pj · (1 −p)n−j · fj
⎤
⎦
is the generalized expression for the price of a call or put option with the
binomial tree model with n steps. Let us focus on the call option price. In
that case,
fj = max(u jdn−j S0 −K, 0)

Introduction to Derivatives
509
We will show that as the number of time periods increases, the binomial
option pricing formula and the Black-Scholes pricing formula produce the
same option price.
We are not interested in states of the world in which the future stock
price is less than the strike price (the option payoffs in those cases are zero),
so we would like to eliminate them from consideration. Then, we would
no longer have to deal with a clumsy formula of the kind max{.,0}, and
can compute the expression for the option price in closed form. Let a =
minimum number of steps so that the payoff is nonnegative, that is, so that
the option is in the money. We have
uadn−aS0 > K > ua−1dn−(a−1)S0
Dividing both sides of the inequalities by dnS0, we have
u
d
a
>
K
dnS0
>
u
d
a−1
Taking natural logarithms of both sides, we get
a · ln
u
d

> ln
 K
dnS0

> (a −1) · ln
u
d

This trick allows us to compute the value of a. Since
a >
ln

K
dnS0

ln
u
d

> (a −1)
it follows that
a =
⎢⎢⎢⎢⎣
ln

K
dnS0

ln
u
d

⎥⎥⎥⎥⎦+ 1
Here ⌊.⌋stands for “the largest integer less than or equal to the number
inside the brackets.”
Knowing a allows us to rewrite the call option pricing formula as
f = e−n·r·(t) ·
⎡
⎣
n

j=a
 n
j

· pj · (1 −p)n−j · (u jdn−j S0 −K)
⎤
⎦

510
DERIVATIVE PRICING AND USE
which in turn can be written as
f = e−n·r·(t) ·

n
j=a
 n
j

· pj · (1 −p)n−j · u jdn−j S0
−
n
j=a
n
j

·pj · (1 −p)n−j · K
	
=
n
j=a
n
j

·

p · u · e−r·(t) j ·

(1 −p) · d · e−r·(t)n−j · S0
−

n
j=a
 n
j

· pj · (1 −p)n−j
	
· K · e−n·r·(t)
=
n
j=a
n
j

·

p · u · e−r·(t) j ·

1 −p · u · e−r·(t)n−j · S0
−

n
j=a
 n
j

· pj · (1 −p)n−j
	
· K · e−n·r·(t)
= S0 · B(n, a, probability of success = p · u · e−r(t))
−K · e−n·r·(t) · B(n, a, probability of success = p)
where B(.) stands for “1 minus the cumulative binomial probability distri-
bution up to a.”
As we illustrated in Exhibit 3.5 in section 3.4 of Chapter 3, as n be-
comes larger, the binomial distribution starts looking more symmetric, and
approximates the normal distribution more and more closely. Therefore, for
carefully selected parameters u and d, the formula derived with the binomial
tree will approximate the call option price derived using the assumption of
a geometric random walk (that is, the original Black-Scholes formula).
While it is reassuring to know that two popular different models for
pricing European options lead to consistent estimates, one may ask why
we need to work with binomial trees when the Black-Scholes expression
provides such a nice closed-form formula. More complicated options and
other derivatives (American options are one example) cannot be priced in
closed form. So, trees are often used to come up with a set of possible values
for the stock price, evaluate the possible payoffs for these types of options,
and discount the payoffs to the present to obtain a fair price.
Matching Parameters
How can we make the parameters used in construct-
ing a binomial tree consistent with the parameters used in the Black-Scholes
model and at the same time, ensure that the tree will be recombining? One
can derive speciﬁc formulas by so-called moment matching. The parameters

Introduction to Derivatives
511
in the binomial tree model are selected in such a way that the ﬁrst and the
second moment of the stock price (that is, its expected value and its variance)
are the same in both models. For example, the expected stock price for the
ﬁrst time period on the tree is
(p · u · S0 + (1 −p) · d · S0)
where p and (1 – p) are the risk-neutral probabilities. The expected stock
price at the end of the ﬁrst step if the stock price follows a geometric random
walk (the assumption behind the Black-Scholes model) is
S0 · eµ·(t)
(When pricing the actual option under the risk-neutral probability mea-
sure, the drift parameter µ will be replaced by the risk-free rate r.) These
two expressions must be equal.
Similarly, we can come up with a condition that links the volatility
in the binomial tree model and the Black-Scholes model. From these two
conditions and the condition that the tree should be recombining, we can
derive the following equivalency relationship:
u = eσ·
√
t
d = 1
u = e−σ·
√
t
p = er·(t) −d
u −d
Here, σ is the observed (implied or historical) volatility.
So, for instance, the example we gave to illustrate the Black-Scholes
formula can be matched directly to the one-period and the two-period bi-
nomial trees we considered in section 13.4.1. That is also why the option
prices computed with both the Black-Scholes and the binomial tree models
turned out to be close. (The binomial tree with two periods gave us an es-
timate closer to the price of the Black-Scholes option than the single-period
binomial tree. The more time periods we consider for the binomial tree, the
closer the approximation will be.)
The Black-Scholes Formula and Bonds
While the Black-Scholes formula is
still widely used in the valuation of European options on equities, it is not
as straightforward to apply it to the valuation of options on bonds. There
are three assumptions underlying the Black-Scholes model that limit its use
in pricing options on Treasury securities.

512
DERIVATIVE PRICING AND USE
First, the probability distribution for the prices assumed by the Black-
Scholes model permits some probability—no matter how small—that the
price can take on any positive value. But in the case of a zero-coupon bond,
for example, cannot take on a value above the maturity value. In the case of a
coupon bond, we know that the price cannot exceed the sum of the coupon
payments plus the maturity value. Thus, unlike stock prices, bond prices
have a maximum value. So, any probability distribution for prices assumed
by an option pricing model that permits bond prices to be higher than the
maximum value could generate nonsensical option prices. The Black-Scholes
model does allow bond prices to exceed the maximum bond value.
The second assumption of the Black-Scholes model is that the short-term
interest rate is constant over the life of the option. Yet the price of a bond
will change as interest rates change. A change in the short-term interest rate
changes the rates along the yield curve. Therefore, to assume that the short-
term rate will be constant is inappropriate for options where the underlying
is a bond.
The third assumption is that the variance of prices is constant over
the life of the option. However, as a bond moves closer to maturity, its
price volatility declines. This is a fundamental mathematical property of
ﬁxed-rate coupon bonds. Therefore, the assumption that price variance is
constant over the life of a bond option is inappropriate.
The most common type of bond options are options on Treasury fu-
tures. For such options, referred to as futures options, the option buyer has
the right to establish a position in a bond futures contract (a long futures
position if the case of a call futures option and a short futures position in
the case of a put futures option). The model used for valuing bond futures
options is the one developed by Black (1976). The Black model was ini-
tially developed for valuing European options on forward contracts. There
are two problems with this model. First, the Black model does not over-
come the problems just identiﬁed for the Black-Scholes model. Failing to
recognize the yield curve means that there will not be a consistency between
pricing Treasury futures and options on Treasury futures. Second, the Black
model was developed for pricing European-exercise style options on fu-
tures contracts. Treasury futures options that are exchange traded, however,
are American-exercise style options. The second problem can be overcome.
The Black model was extended by Barone-Adesi and Whaley (1987) to
American options on futures contracts. This is the model used by the ex-
change where Treasury futures options are traded, the Chicago Board of
Trade, to settle the certain types of Treasury futures options. However,
this model was also developed for equities and is subject to the ﬁrst problem
noted above. Despite its limitations, the Black model is a very popular model
for pricing options on Treasury futures.

Introduction to Derivatives
513
13.4.3
Pricing American Options with
Binomial Trees
As we explained in section 13.1.2, American-exercise style options can be ex-
ercised at any time up to and including the expiration date. This makes pric-
ing them more challenging because we need to model not only the possible
probability distribution of underlying asset prices at the expiration date, but
also the dynamics of the asset price between time 0 and the expiration date.
In practice, the possible paths for the asset price between time 0 and the ex-
piration date are discretized—that is, the option value is computed at a ﬁnite
number of intermediate time periods. If the number of such time periods is
large, the approximation is reasonable. In section 14.4.2, we will show how
to use simulation to generate paths for the price of the underlying, and price
the option using this information. Such methods have been developed rela-
tively recently. The classical methods for pricing American options include
binomial (or trinomial) trees and ﬁnite difference methods. In this section,
we show the idea behind a traditional pricing method for American options:
binomial trees. The main technique underlying the methodology is dynamic
programming—that is, ﬁnding an optimal solution over multiple stages.17
To illustrate the approach, let us consider the same example as in section
13.4.1 when we discussed a two-period binomial tree for pricing a European
call option. Instead of the call option, however, let us consider a put option
with the same strike price. (The price of an American call option on a
nondividend-paying stock is the same as the price of a European call option
on the stock, so let us consider the put option in order to make the example
more interesting.18) In Exhibit 13.8, we show the value of the American put
option in the possible states of the world at time 0, 1, and 2. To compute the
price of the option, we start at the last time period (that is, the expiration
date), and work our way backwards.
Similarly to the case of the European option, at the last time period
(time 2), we simply compute the payoffs of the option. For example, the top
payoff at time 2 is $0 = max{$52.00 – $64.22,0}. The idea is that if the
option holder has not exercised the option before the expiration date, he
will only exercise it if the intrinsic value of the option is greater than 0. In
the latter case, the payoff to the option holder will be the discounted payoff
of the intrinsic value.
Computing the values for the option at time 1 is not as straightforward
as at time 2. At time 1, we need to determine whether to exercise the option
or continue to hold it (that is, not exercise), and the payoff will depend
on our decision. We will exercise if the intrinsic value of the option (that
is, the immediate payoff from exercising the option) is greater than the
expected value of continuing to hold it. Note that here we are dealing with

514
DERIVATIVE PRICING AND USE
64.22
$    
7
6
.6
5
Stock Price
$   
50.00
0
0
.0
5
$
$    
44.12
$   
38.93
$    
-
$        
4
8
.0
Put Value
$     
3.77
0
0
.2
$
$      
7.88
$     
13.07
$     
EXHIBIT 13.8
Pricing an American put option in a
two-period binomial tree.
a relatively simple value function in a dynamic program: the value function
is the maximum of the intrinsic value of the option, and the discounted
expected payoff if we do not exercise.19
For example, the value of $0.84 obtained at the top node at time 1 in
Exhibit 13.8 is the maximum of the discounted expected payoff from the
two nodes at time 2 that are reachable from the node at time 1, and the
intrinsic value of the option:
$0.84 = max{$52.00 −$56.67, e−0.10·(0.5/2) · (0.5699 · $0.00
+ (1 −0.5699) · $2.00)}
Note that the discount factor takes into consideration the fact that the
time period is of length T/2. It turns out that the intrinsic value of the option
is negative, and less than the value of continuing to hold it, so the option
holder would not choose to exercise the option at that node.
Similarly, we can compute the second possible value for the option at
time 1. The computation is as follows
$7.88 = max{$52.00 −$44.12, e−0.10·(0.5/2) · (0.5699 · $2.00
+ (1 −0.5699) · $13.07)}
In this case, it turns out that it is optimal to exercise the option. The in-
trinsic value is $7.88 (= $52.00 – $44.12), whereas the discounted expected
payoff of continuing is
e−0.10·(0.5/2) · (0.5699 · $2.00 + (1 −0.5699) · $13.07) = $6.60

Introduction to Derivatives
515
At time 0, we similarly compute the value of the option as
max{$52.00 −$50.00, e−0.10·(0.5/2) · (0.5699 · $0.84 + (1 −0.5699) · $7.88)}
This gives us the price of the option, $3.77. It is clear that it is not
optimal to exercise at time 0—the intrinsic value of the option is $2.00,
whereas the value of continuing to hold it is $3.77.
Exhibit 13.5 in section 13.4.1 shows that the price of the European
put was $3.23. The American put option on the same stock was more
expensive—this is to be expected since the American option gives the option
holder more ﬂexibility than the European option.
The binomial tree technique for pricing American options can be
extended to multiple periods. (See this chapter’s Software Hints for
MATLAB and VBA code for implementing the dynamic programming algo-
rithm.) Moreover, the binomial tree model can be advanced to incorporate
more than one underlying factor. However, as the number of factors grows,
the dimension and the tractability of the tree become more and more prob-
lematic. For example, if we have two factors (e. g., suppose that the American
option payoff depends on the performance of two stocks, rather than one),
then at time 1, we have 4 nodes; at time 2, we have 9 nodes, and the number
of nodes becomes larger and larger after that. Simulation techniques are use-
ful in such applications. We will discuss one class of simulation techniques
for pricing American options, regression-based methods, in section 14.4.2
of Chapter 14.
13.4.4
Measuring Sensitivities
In employing option strategies, an investor needs to know how sensitive the
option price is to changes in any of the factors that determine it. Measures
for the sensitivity of the option price with respect to the underlying factors
are denoted by Greek letters, and are usually referred to as “the Greeks.”
Here, we discuss measures of the sensitivity of the option price with respect
to the underlying stock, the time to expiration, and the volatility in the
underlying stock price.
Delta
We have seen the importance of understanding the relationship be-
tween the option price and the price of the underlying stock in developing
the option pricing model. Option traders and portfolio managers employing
options to control the price risk of a portfolio need to know how the option
position will change as the price of the underlying stock changes. The ratio
of the change in the option price and the change in the price of the under-
lying is referred to as delta (). On an intuitive level,  is the number of

516
DERIVATIVE PRICING AND USE
units of the stock we should hold for each option shorted in order to create
a riskless hedge. (The selection of the notation  in section 13.4.1 was not
by chance.) The option delta is formally deﬁned as
 = ∂f
∂S
where f is the derivative price, and S is the price of the underlying.
Gamma
Oftentimes, it is of interest to estimate the rate of change of the
option delta as the stock price changes. The ratio of the change in delta and
the change in the underlying stock price is commonly referred to as gamma
(), and is formally deﬁned as
 = ∂
∂S = ∂2 f
∂S2
Gamma can therefore be also viewed as the second derivative of the
option price with respect to the price of the underlying.
Theta
All other factors remaining constant, the longer the time to expira-
tion, the greater the option price. Because each day the option moves closer
to the expiration date, the time to expiration decreases. The theta () of an
option measures the change in the option price relative to the decrease in the
time to expiration, or, equivalently, it is a measure of time decay. Formally,
theta is deﬁned as follows:
 = ∂f
∂T
Assuming that the price of the underlying stock does not change (which
means that the intrinsic value of the option does not change), theta measures
how quickly the time premium of the option changes as the option moves
toward expiration. Theta is usually negative for an option (although there
are exceptions) because as the time to maturity decreases, the option tends
to become less valuable.
Buyers of options prefer a low theta so that the option price does not
decline quickly as it moves toward the expiration date. An option writer, on
the other hand, beneﬁts from an option that has a high theta.
Vega
The option pricing models we considered so far assume that the
volatility of the price of the underlying, σ, remains constant over time. In
reality, this is not the case. The vega (V) of a derivative is the rate of change

Introduction to Derivatives
517
of the derivative value with respect to the volatility of the underlying stock
price20
V = ∂f
∂σ
If vega is high, the option value is very sensitive to small changes in the
volatility of the underlying stock price.
13.5
PRICING SWAPS
As we explained in section 13.1.3, there is a wide variety of swaps. The
main idea when pricing all of them, however, is that the fair value of a swap
should be the difference between the present values of the expected cash
ﬂows exchanged between the two parties in the swap.
By far, the type of swaps most often used by asset managers and traders
is interest rate swaps. Speciﬁcally, it is the generic interest rate swap (that is,
swapping of ﬁxed rate for ﬂoating rate interest rate payments). We discuss
the pricing of a generic interest rate swap in detail in this section.
In a generic interest rate swap, the cash ﬂows on the ﬁxed component
(that is, the ﬁxed rate payments) are known at the inception of the swap.
However, the future cash ﬂows on the ﬂoating component are unknown
since they depend on the future value of the reference rate. The future
ﬂoating rates for purposes of valuing a swap are derived from forward rates
that are embedded in the current yield curve.
By utilizing forward rates, a swap net cash ﬂow can be derived through-
out the life of a swap. The sum of these cash ﬂows discounted at the corre-
sponding forward rate for each time period is the current value of the swap.
Mathematically, the value of a swap position is
Swap value =
T

t=1
PV(Fixed cash ﬂowt −Floating cash ﬂowt]
where PV(x) denotes the present value of x, and t are the dates at which
payments are made. The fair swap rate is the ﬁxed rate that makes the swap
value zero.
An alternative approach to pricing a generic interest rate swap is to view
it as two simultaneous bond payments made by the two parties. Namely,
think of the ﬁxed rate payer as paying the notional amount to the ﬂoating
rate payer at the termination date, and of the ﬂoating rate payer as paying the
notional amount to the ﬁxed rate payer at the termination date. This slight

518
DERIVATIVE PRICING AND USE
modiﬁcation does not change the actual cash ﬂows and value of the swap
because the payments of the notional amounts cancel out at the termination
date. However, it does help us imagine the stream of payments from the
ﬁxed rate payer as the value of a ﬁxed coupon bond, and the stream of
payments from the ﬂoating rate payer as the value of a ﬂoating rate bond.
Let the notional amounts be 100, and let ν denote the premium (per
annum) paid by the ﬁxed rate payer. Assume that the payments happen at
dates 1, 2, . . . , T, and that the time interval between payments is t. (The
latter time interval is typically a quarter.)
At time 0, the value of the ﬁxed rate bond is
100 · ν · (t) ·
T

t=1
B(0, t) + 100 · B(0, T)
where B(0, t) denotes the value (at time 0) of a zero-coupon bond with a face
value of 1 and maturity t. (This is because the collection of payments during
the life of the swap can be thought of as a portfolio of zero-coupon bonds of
face value 1 with time to maturities equal to the times of the swap payments.)
The value of the ﬂoating rate bond at time 0 is 100. To see this, note
that the ﬂoating rate payer can replicate the value of the bond by investing
100 today at the current interest rate, and earning just enough interest to pay
the ﬁrst coupon on the ﬂoating rate bond to the ﬁxed rate payer. Then, the
ﬂoating rate payer can invest 100 again at the prevailing interest rates after
the ﬁrst swap payment, and earn enough interest to pay the second ﬂoating
rate coupon, with 100 left over. Continuing in the same way, the ﬂoating
rate payer can reinvest the 100 until the last time period, when he pays the
100 to the ﬁxed rate payer. Therefore, the present value of the investment
from the perspective of the ﬂoating rate payer is 100. From the perspective of
the ﬂoating rate payer, the value of the swap today is the difference between
the ﬁxed rate payer’s payments and his payments, that is,
100 · ν · (t) ·
T

t=1
B(0, t) + 100 · B(0, T) −100
The ﬁxed rate ν that makes the value of the swap equal to zero at time
0 is the fair price of the swap at time 0. It is easy to see that the value of ν
should be
ν =
1 −B(0, T)
(t) ·
T
t=1
B(0, t)

Introduction to Derivatives
519
The values of B(0, t) can be determined from today’s yield curve. (In
practice, they are determined from the swap rate curve, which is a plot
of swap rates against maturities in much the same manner as the bond
yield curve.) They are in fact the discount factors that apply to different
maturities.
SUMMARY
■Derivatives are contracts that derive their value from underlying ﬁnan-
cial securities, such as stocks, bonds, market indices, currencies, and
commodities.
■There are three general classes of derivatives: (1) forwards and futures,
(2) options, and (3) swaps.
■A forward contract is an agreement to buy or sell an asset at a spe-
ciﬁc time in the future for a speciﬁc price. Forward contracts are sold
in the over-the-counter market, that is, they are nonstandard and are
negotiated directly between a buyer and a seller.
■Futures are very similar to forwards, but they are standardized contracts
traded on exchanges.
■An option is a contract in which the option seller grants the option buyer
the right to enter into a transaction with the seller to either buy or sell
an underlying asset at a speciﬁed price on or before a speciﬁed date. If
the right is to purchase the underlying, the option is referred to as a call
option. If the right is to sell the underlying, the option is referred to as
a put option.
■An option can also be categorized according to when it may be exercised
by the buyer. A European option can only be exercised at the option’s
expiration date. An American option can be exercised any time on or
before the expiration date.
■More sophisticated option contracts are referred to as exotic options or
exotics. Examples of exotic options include Asian options and barrier
options.
■Options do not have a linear payoff, while futures and forwards do. The
difference in the type of payoff between futures and options is important
because market participants can use futures to protect against symmetric
risk and options to protect against asymmetric risk.
■Swaps are contractual agreements in which two counterparties agree to
exchange returns on different assets over a prespeciﬁed period of time.
■Arbitrage is the opportunity to make “free money,” that is, to realize a
proﬁt with little or no risk of losing money in the future.
■A hedging strategy is a trading or investment strategy that reduces risk.

520
DERIVATIVE PRICING AND USE
■The concept of no arbitrage and the idea of creating a replicating port-
folio that mimics the payoff of a ﬁnancial derivative provide the foun-
dation for pricing complex ﬁnancial instruments.
■Classical methods for pricing European options include binomial trees
and the Black-Scholes formula. Those two methods result in similar
estimates for appropriately chosen model parameters.
■The Black-Scholes formula holds under very speciﬁc conditions, and as-
sumes that the price of the underlying asset follows a geometric random
walk. It is not appropriate for use when pricing ﬁxed income securities.
■Binomial and trinomial trees are widely used for pricing American
options.
■Measures for the sensitivity of the option price with respect to underlying
factors (such as the stock price, the time to maturity, and the volatility
of the underlying) are denoted by Greek letters, and are usually referred
to as Greeks. Such sensitivity measures include delta, gamma, theta,
and vega.
■The value of a swap can be found by computing the difference between
the discounted cash ﬂows on the ﬂoating leg and the discounted cash
ﬂows on the ﬁxed leg of the swap. The value of a swap can be also
viewed as the difference between the value of a ﬂoating rate bond and a
ﬁxed rate bond.
■The fair swap rate is the ﬁxed premium that makes the value of the swap
zero.
SOFTWARE HINTS
Excel/VBA
Bond Arbitrage Using Optimization
Let us explain the bond arbitrage ex-
ample implementation in section 13.2.1 of Chapter 13 in more detail. Ex-
hibit 13.9 shows worksheet Arbitrage in the ﬁle Ch13-Arbitrage.xlsx.
Cells B4:F4 are changing cells for Solver—they store the optimal
amounts to invest in each bond for the arbitrage strategy. Positive values in-
dicate long positions, whereas negative values indicate short positions. Cell
G7 is the target cell, and contains the objective function value. The formula
in G7 is
=SUMPRODUCT(B7:F7,$B$4:$F$4)
This is the portfolio value at time 0. It equals the value of all short
positions plus the value of all long positions. A negative value for cell G7

Introduction to Derivatives
521
EXHIBIT 13.9
Worksheet Arbitrage in the ﬁle Ch13-Arbitrage.xlsx.
means a positive realized cash ﬂow at time 0—this is because it indicates a
higher amount in short positions than in long positions. The short positions
generate a cash inﬂow at time 0 (after the bonds are borrowed, they are sold
in the market). The long positions generate a cash outﬂow at time 0, when
the bonds are purchased in the market.
Cells G10:G17 contain the left-hand side of the constraints on the cash
ﬂows at each future time period. These future cash ﬂows consist of positive
cash ﬂows from coupon payments on the long positions, and negative cash
ﬂows from coupon payments on the short positions. For example, cell G10
contains the formula
=SUMPRODUCT(B10:F10,$B$4:$F$4)
If we are able to ﬁnd a portfolio of bonds such that all future payments
are nonnegative, but which has a negative value (that is, a positive cash
ﬂow) today, that would be an arbitrage opportunity. That is why, in the
search of such an opportunity, we try to ﬁnd the minimum cost portfolio
(by minimizing the target cell G7) subject to the constraints that the cash
ﬂows are nonnegative at each future time period. If the optimal objective
function value is positive, no such arbitrage opportunity exists.
The last row in the array of constraints, row 18, contains an artiﬁcially
imposed bound just to make the problem well-behaved. We restrict the
initial position not to be less than –$100,000, but it could have been any
other amount consistent with our investment budget. The point is that if an
arbitrage opportunity is available (that is, if all the constraints are satisﬁed
and the optimal objective function value is negative), we may be able to

522
DERIVATIVE PRICING AND USE
EXHIBIT 13.10
Solver dialog box for bond arbitrage problem, worksheet
Arbitrage in ﬁle Ch13-Arbitrage.xlsx.
drive the objective function value to negative inﬁnity. Solver reports that as
an error and does not provide values for the changing cells. In order to ﬁgure
out the optimal investment strategy, it is a good idea to bound the value of
the objective function. If we have a larger or a smaller investment budget,
we can always change the right-hand side of the bound.
The Solver dialog box is shown in Exhibit 13.10. We also check the
Assume Linear Model option in Solver.
Implementing the Black-Scholes Formula with Excel
Worksheet B-S in
ﬁle Ch13-BlackScholes.xlsm contains a simple implementation in Excel
of the Black-Scholes option pricing formula for European calls and puts
(see Exhibit 13.11). Cells B3:B8, with self-explanatory descriptions, con-
tain the inputs to the model, such as the strike price, the initial price,
the volatility, and the like. Cells B10:B13 contain other inputs for the
Black-Scholes formula. The parameter d1 is computed in cell B10 with the
formula
=(LN(B3/B4)+(B6-B8+B7ˆ2/2)*B5)/(B7*SQRT(B5))
The parameter d2 is computed in cell B11 with the formula
=B10-B7*SQRT(B5)

Introduction to Derivatives
523
EXHIBIT 13.11
Calculation of call and put prices with the Black-Scholes formula
in Excel.
The values for the cumulative normal distribution at d1 and d2, respec-
tively, are computed in cells B12 and B13, respectively, with the formulas
=NORMDIST(B10,0,1,1)
(in cell B12) and
=NORMDIST(B11,0,1,1)
(in cell B13).
The Black-Scholes price for a European call option is computed in cell
B15 with the formula
=B3*EXP(-B8*B5)*B12-B4*EXP(-B6*B5)*B13
The Black-Scholes formula for a European put option (cell E15) is im-
plemented in a similar manner.
To determine the sensitivity of the option price with respect to different
inputs, we create Excel data tables. Data tables allow one to enter a formula,
point to an input in the formula, and ask Excel to create a table with the
values of the formula for the different values of the prespeciﬁed input. For
example, to create the data table in cells G3:I11 of worksheet B-S, take the
following steps:
■Type the list of values you would like to substitute for the time to
maturity of the option in a column (cells G4:G11).
■Type the formula you would like to have evaluated one cell above the
top entry for time to maturity, and one column to the right (cell H3).

524
DERIVATIVE PRICING AND USE
EXHIBIT 13.12
Data table dialog
box.
In this case, we already have a cell (B15) with the exact formula for a
European call, so we simply enter
=B15
in cell H3.
■If there are additional formulas you would like to have evaluated based
on changes in the same input (time to maturity), enter them in the same
row in the columns to the right of the cell with the ﬁrst formula. In this
case, we wanted to evaluate also the price of a European put option, so
we entered the formula for a European put option in cell I3. However,
we could leave the data table with a single formula to be evaluated.
■Select the range of cells with the changing input parameter to the left
and the columns under the formulas that need to be evaluated (Cells
G3:I11).
■On the Data tab, in the Data Tools group, click What-If Analysis, and
then click Data Table. You should see a window like the window in
Exhibit 13.12. Since our data is in columns, enter the cell that contains
the input to be changed (in this case, cell B4, which contains the time to
expiration) under Column input cell. Click OK, and the data table will
appear.
Implementing the Black-Scholes Formula with VBA
The code for a call and
a put option price (BSCallPrice and BSPutPrice) is provided in the ﬁle
Ch13-BlackScholes.xlsm. For convenience, ﬁrst we create a function dOne
that computes the value of d1 in the Black-Scholes formula.
Finding the Black-Scholes Implied Volatility with Excel Solver
Work-
sheet B-S Implied Vol in the ﬁle Ch13-BlackScholes.xlsm illustrates how the
implied volatility can be computed from an observed option price. (See a
screenshot of the worksheet in Exhibit 13.13.) In the example in the previous

Introduction to Derivatives
525
EXHIBIT 13.13
Worksheet B-S Implied Vol in the ﬁle Ch13-BlackScholes.xlsm.
section, we found that the price of a call option with the input parameters in
Exhibit 13.13 should be $3.79. Now suppose that we have observed a mar-
ket price of $5.18 for the option. What is the implied value of the volatility
that will make the price of the option in the spreadsheet consistent with
market prices?
We can use Excel’s Solver to ﬁnd that out. One of the options in Excel
Solver is to ﬁnd the value of a changing cell so that the target cell equals a
speciﬁc value, instead of minimizing or maximizing, which is how we used
Solver in previous applications. We ﬁll out the Solver dialog box as shown
in Exhibit 13.14. Namely, we set the target cell to be the cell that contains
the Black-Scholes formula for the price of a European call option, and we
ask Solver to set that cell’s value to 4.20 by changing the cell that stores the
value for the volatility (B7).
After clicking on Solve, Solver ﬁlls cells B15 and B17 with the best values
it found. It turns out that the implied volatility in this case is 35.00%. You
can use the same method to ﬁnd the implied volatility from put prices. For
practice, ﬁll out columns D and E of the worksheet and change the inputs
to Solver to ﬁnd the implied volatility if the observed market put price
is $3.63.

526
DERIVATIVE PRICING AND USE
EXHIBIT 13.14
Solver dialog box for the implied volatility example.
Finding the Black-Scholes Implied Volatility with VBA
The ﬁle Ch13-
BlackScholes.xlsm contains VBA code (the function BSImpliedVol) for
computing the implied volatility with Excel VBA. This is a brute-force rather
than an optimization approach, in which we start with a low and a high
estimate for the volatility (0 and 1, respectively), and we tune it until we get
an option price that is close to the observed market price and is within a
certain tolerance band.
American Option Pricing with the Binomial Method
The VBA code
saved as the function
AmericanPutBin in a module in ﬁle Ch13-
BinomialTrees.xlsm computes the price of an American put option us-
ing a binomial tree with numSteps time periods. We use two arrays—
OptionValueCurrent and OptionValueNext—to store the option values
at the current time period and one time period ahead. We resize the ar-
rays periodically with the command ReDim so that they equal the num-
ber of nodes at the corresponding time period. At every step, we ﬁll the
OptionValueCurrent array with the current value of the option at each
node as a maximum of the intrinsic value and the value of continuing,
using the information about the current price (computed as initial price
times a given number of up moves and a given number of down moves)
and the expected payoffs from the next time period (stored in the array
OptionValueNext). Once we have computed these values, the array
OptionValueCurrent becomes OptionValueNext, and we proceed back-
wards in the same fashion, calculating the OptionValueCurrent array for
the previous time period.

Introduction to Derivatives
527
At
the
bottom
of
worksheet
American
in
the
ﬁle
Ch13-
BinomialTrees.xlsm, cell B33, we call the VBA function with the formula
=AmericanPutBin(B3,B4,B5,B6,B7,2)
(Here we used the input data for the two-period binomial tree on the
same worksheet.) The value returned by the function is $3.77—the same
price we computed manually from the tree in the spreadsheet.
MATLAB
Bond Arbitrage Using Optimization
The arbitrage example from section
13.2.1 can be repeated in MATLAB with the code provided in the ﬁle
Arbitrage.m.
We use the function linprog because the optimization problem is linear.
Note that since linprog assumes that the inequalities in the constraints are
of the kind Ax ≤b, we create a matrix A that is the negative of the matrix
of coupon cash ﬂows, and a right-hand-side vector b that is the negative of
the right-hand side in the Excel ﬁle.
Since MATLAB can ﬁnd a solution to this problem, there is a potential
arbitrage opportunity.
Implementing the Black-Scholes Formula
The function BSPrice in the
ﬁle BSPrice.m computes the price of a call and a put option with the Black-
Scholes formula.
Finding the Black-Scholes Implied Volatility
MATLAB’s Financial Tool-
box has a built-in function (blsimpv) for ﬁnding the implied volatility of
the underlying stock price from the price of a given call (or put) option,
assuming that the option price is derived from the Black-Scholes model.
The function can be implemented also without the Financial Toolbox.
We can use a brute force approach, in which we start with a low and a high
estimate for the volatility (0 and 1, respectively), and we tune it until we get
an option price that is close to the observed market price and is within a
certain tolerance band. Alternatively, if you have the Optimization Toolbox,
you can use the fzero function in MATLAB to compute an estimate in a
more optimal way.
The ﬁle BSImpliedVol.m implements the brute force approach.
American Option Pricing with the Binomial Method
The function available
in the ﬁle AmericanPutBin.m computes the price of an American put option

528
DERIVATIVE PRICING AND USE
with the binomial tree method. We use two arrays—OptionValueCurrent
and OptionValueNext—to store the option values at the current time period
and one time period ahead. At every step, we ﬁll the OptionValueCurrent
array with the current value of the option at each node as a maximum of the
intrinsic value and the value of continuing, using the information about the
current price (computed as initial price times a given number of up moves
and a given number of down moves) and the expected payoffs from the
next time period (stored in the array OptionValueNext). Once we have
computed these values, the array OptionValueCurrent becomes Option-
ValueNext, and we proceed backwards in the same fashion, calculating
the OptionValueCurrent array for the previous time period. Note that, in
contrast to VBA, indices in arrays in MATLAB cannot be zero.
NOTES
1. When the counterparties are two high-credit-quality entities, the two parties
may agree not to mark positions to market. However, if one or both of the
parties are concerned with the counterparty risk of the other, then positions
may be marked to market.
2. This statement will become clearer when we discuss risk management strategies
with derivatives in Chapter 16.
3. We will explain basis risk in more detail in Chapter 16.
4. As the name implies, credit derivatives are contracts whose payoff depends on
the credit worthiness of the underlying asset.
5. This issue can be ﬁxed by restricting the amounts to be invested in the bonds
to be integers. For computational issues with integer programming, see section
5.2.5 of Chapter 5.
6. See Practice 13.1 on the companion web site for an example in which the bid
and ask prices are different.
7. Note that since we are talking about futures contracts, no physical delivery of
jet fuel would actually take place. Instead, the futures contracts will be traded
or settled in cash (at the delivery date).
8. See Hull (2008).
9. For more details, see Fabozzi (2009).
10. There is a one-cent difference with the previous estimate due to rounding error.
11. We have three ﬁnal nodes because we built the binomial tree to be recombining.
This keeps the dimension of the problem manageable. With a recombining tree,
we have t + 1 nodes at time t. With a nonrecombining tree, we have 2t nodes at
time t. Thus, with a nonrecombining tree the number of nodes quickly becomes
unmanageable.
12. As we saw in Chapter 3, the numbers ( n
k) (pronounced “n choose k”) are the
binomial coefﬁcients. They count how many ways there are to choose k objects
out of n. (In the particular context of option pricing, they count how many ways

Introduction to Derivatives
529
there are to get k “up” moves of the stock price out of n possible moves.) These
coefﬁcients appear in the formula for the binomial probability distribution.
(Recall from section 3.3 of Chapter 3 that the binomial distribution associates
a probability with k successes out of n trials, and the probability is computed
exactly in the same way as in the option pricing formula above.)
13. As explained previously in this book, the value for (d) can be found with
the formula =NORMDIST(d,0,1,1) in Excel, and normcdf(d,0,1) in
MATLAB.
14. Data tables are a very useful tool in Excel. They allow one to reference a
formula, and compute the values of the formula for different input values of
one of the arguments in the formula. See this chapter’s Software Hints for an
implementation in the context of computing the price of a call and a put option
with the Black-Scholes formula.
15. Note that if the Black-Scholes model truly applied to markets, the volatility
smile phenomenon should not be observed. The fact that it exists implies that
practitioners do not believe that the lognormal probability distribution for stock
prices correctly represents extreme events. In the real world, extreme events
(events that happen in the tails of the distribution) are more likely than the
lognormal distribution would imply.
16. See section 3.4 of Chapter 3.
17. See sections 5.6 and 6.1 of Chapters 5 and 6, respectively, for an introduction
to dynamic programming.
18. The price of an American call option in the two-period binomial tree example
is computed in worksheet American in the ﬁle Ch13-BinomialTrees.xlsm. You
can observe that the price of the American call is the same as the price of the
European call. This is not a coincidence. The price of an American call option on
a nondividend-paying stock is the same as the price of a European call option on
the stock because it is never optimal to exercise early, that is, one would never
take advantage of the early exercise feature of the American call option. There
are a couple of reasons for this, one of which is the time value of money—from
the perspective of the option holder, the later the strike price is paid out, the
better. See Hull (2008) for a detailed explanation.
19. See section 6.1 of Chapter 6 for a deﬁnition and examples of value function in
dynamic programming.
20. Even though vega is the term used in the context of option “Greeks,” there is
no actual letter vega in the Greek alphabet.


CHAPTER14
Pricing Derivatives by Simulation
I
n Chapter 13, we introduced the main ideas behind the pricing of standard
ﬁnancial derivative instruments, or simply derivatives. We saw that the
main assumption underlying derivative pricing schemes is the assumption
that there is no arbitrage in the markets. When there is no arbitrage, the
price of a derivative can be found as the expected value of its discounted
payouts when the expected value is taken with respect to a transformation
of the original probability distribution of outcomes, called the risk-neutral
probability measure.
The same principles that guide the computation of the fair price of stan-
dard derivatives extend to the pricing of more complex derivatives. How-
ever, the difference is that nice closed-form formulas of the Black-Scholes
type cannot necessarily be found for complex derivatives. Such derivatives
must be priced with different numerical techniques, and simulation is one
such tool.
We begin this chapter by showing how simulation can be used to price
some of the simple derivatives we discussed in Chapter 13, such as Eu-
ropean call options. Although simulation does not need to be applied in
this context, techniques that make the simulation procedures more efﬁ-
cient can be demonstrated in a familiar setting, and benchmarked against
a known ﬁnal price. These examples help us illustrate more advanced sim-
ulation techniques, called variance reduction methods, whose goal is to
make the simulation process as efﬁcient as possible, and minimize the vari-
ance of the estimate. We review several such methods, including antithetic
variables, stratiﬁed sampling, importance sampling, and control variates.
We also review quasirandom (also called quasi–Monte Carlo) methods for
simulation that use low discrepancy number sequences to obtain a good rep-
resentation for the probability distribution being simulated. We then give
examples of pricing more complex derivatives, such as barrier options and
American options, by simulation, and discuss evaluating the sensitivity of
531

532
DERIVATIVE PRICING AND USE
derivative to changes in underlying parameters by crude and pathwise sim-
ulation methods.
14.1
COMPUTING OPTION PRICES WITH CRUDE
MONTE CARLO SIMULATION
As we mentioned at the beginning of this chapter, the main idea behind
computing prices of options (and other ﬁnancial securities) by simulation
is to generate a set of payoffs, and discount them to the present to ﬁnd the
expected value of all discounted payoffs under a probability distribution
called the risk-neutral probability measure. The expected value of payoffs
is the “fair” price of the derivative. Typically, when pricing ﬁnancial
derivatives, the prices of the underlying securities are assumed to follow
speciﬁc kinds of random walks.1 The most straightforward way to price
a derivative is to create paths of realizations of the random walks for the
derivative’s underlying, compute the payoff along each path, discount to
the present, and ﬁnd the appropriate weighted average of the payoffs as
an estimator for the expected value of the payoff. This is referred to as
using crude Monte Carlo. It is not always the most efﬁcient way to ﬁnd a
derivative’s price, but it is tangible and easy to implement.
In this section, we give a couple of examples of how crude Monte Carlo
can be used for pricing options. Smart ways to simulate the prices of op-
tions that exploit knowledge about the simulation process or the underlying
distributions are discussed in section 14.2.
14.1.1
Pricing a European Call Option
by Simulation
As we explained in section 13.4.2, a widely used formula for European
options is the Black-Scholes formula.2 It provides a closed-form expression
for computing the price of the option. In section 13.4.2, we also showed
that the underlying assumption used in the derivation of the Black-Scholes
formula is that the underlying asset price follows a geometric Brownian
motion.3 The evolution of the asset price can then be described by the
equation
dSt = µSt dt + σ St dWt
where Wt is standard Brownian motion and µ and σ are the drift and
the volatility of the process, respectively. For technical reasons (absence of

Pricing Derivatives by Simulation
533
arbitrage), when pricing an option, the drift µ is replaced by the risk-free
rate r in the Black-Scholes formula.
Under the assumption for the random process followed by the asset
price, the value of the asset price ST at time T given the asset price St at time
t can be computed as
ST = St e(r−1
2 σ 2)·(T−t)+σ·√
(T−t)·˜ε
where ˜ε is a standard normal random variable.4
Hence, the option price obtained from the Black-Scholes formula can
be approximated by simulation if a large number of values for the normal
random variable ˜εt are generated. By creating scenarios for the stock price
ST at time T, we can compute the discounted payoffs of the option, and ﬁnd
the expected payoff. Suppose we generate N scenarios for ˜ε: ε(1), . . . , ε(N).
Then the price of a European call option with strike price K will be
Ct = e−r·(T−t) ·
N

n=1
1
N · max

St e(r−1
2 σ 2)·(T−t)+σ·√
(T−t)·ε(n) −K, 0

The expression above is the expected value of the option payoffs, that
is, the weighted average of the option payoffs. The “weight,” or the proba-
bility of each scenario, is assumed to be 1/N since the scenarios are picked
at random, and the frequency of their occurrence already incorporates the
probability distribution of ˜ε. (See this chapter’s Software Hints, as well as
ﬁles Ch14-PricingBySimulation.xlsx, Ch14-OptionPricingVBA.xlsm, and
EuropeanCall.m, for an actual implementation of the simulation.)
It appears unnecessarily complicated to price the option this way, and
indeed, in practice simulation is rarely used for this kind of simple prob-
lem. There are more complex derivatives and more sophisticated models for
asset price behavior; in such cases, it can be simpler to generate scenarios
and evaluate prices by simulation than to derive closed-form analytical for-
mulas mathematically. For example, if the underlying asset follows a mean
reversion process, the Black-Scholes formula will not work for a European
call option, but simulation can help us evaluate the option price easily. In
addition, in the case of portfolios and baskets of multiple assets, generating
joint scenarios for multiple securities through simulation can help capture
the otherwise complicated effect of interactions among different risk factors
inﬂuencing the future value of the portfolio or derivatives.
Let us illustrate another advantage of simulating the price of a European
call option rather than using the Black-Scholes formula. Recall that one
of the assumptions in the Black-Scholes formula is that the interest rate r

534
DERIVATIVE PRICING AND USE
remains constant during the life of the option, which is a limitation of the
model. Simulation makes it easy to calibrate model parameters to observed
market factors and to incorporate additional layers of modeling complexity.
For example, suppose that at time 0 we observe a term structure5 of zero-
coupon bond prices B(0, 1), . . . , B(0, T) that is not necessarily consistent
with a single interest rate r. In other words, we cannot ﬁnd a short rate r
such that
B(0, t) = e−r·t
for all intermediate time periods t. It would be difﬁcult to correct for this
in a closed-form formula such as the Black-Scholes formula. However, the
correction can be easily implemented in the simulation: we only need to
simulate future asset prices at each step as
St+1 = St ·
B(0, t)
B(0, t + 1) · e−1
2 ·σ 2·1+σ·
√
1·˜εt
(See also Practice 14.3 on the companion web site for European call option
pricing with simulation when interest rates are assumed to follow a mean
reverting process.)
Similarly, if we have information about a collection of observed forward
prices6 F(0, t), . . . , F(0, T) on the underlying asset, we can obtain a more
accurate representation of the possible scenarios in the simulation by using
the formula
St+1 = St · F(0, t + 1)
F(0, t)
· e−1
2 ·σ 2·1+σ·
√
1·˜εt
The complexity of the simulation model can be increased further by
incorporating random walk models for the volatility σ. The simulation tech-
nique therefore offers a great range of modeling capabilities. The need for
such a technique will hopefully become more evident also in the Asian option
pricing example in the next section.
14.1.2
Pricing an Asian Option by Simulation
As we mentioned in section 13.1.2, an Asian option is a contract whose value
is determined by the average price of the underlying asset either continuously
over the option’s time to maturity or at a prespeciﬁed set of monitoring dates
t1, . . . , tT. In particular, the payoff of an Asian call option is
VT = max

Saverage −K, 0


Pricing Derivatives by Simulation
535
The average is usually deﬁned as the arithmetic average, that is, as
S1 + · · · + ST
T
where T is the number of discrete time periods until the option’s expiration
date. The speciﬁc characteristics of an Asian option vary depending on how
the average price is calculated (instead of the arithmetic average, it could be
the geometric average7), whether there are early exercise features (in which
case the average of the underlying asset price over the life of the option so
far is calculated), and whether the option is a put or a call.
To ﬁnd the value of an Asian option, we need information not only on
the value of the asset at the expiration date (time T), but also on the possible
paths the asset could take to reach its terminal value. This is referred to
as path dependency, and is one of the situations in which simulation is
particularly useful.
If the underlying asset price S is assumed to follow a geometric random
walk, and if the average is computed as a geometric rather than arithmetic
average, there are analytical formulas for pricing continuous Asian options.8
However, there are no exact formulas in the case of an arithmetic average
Asian call option with discrete monitoring dates or different assumptions on
the process followed by the asset price.
Pricing the option is rather straightforward if we use crude Monte
Carlo simulation. We simulate possible paths for the underlying asset price.
Let Sti( j) be the simulated asset price at time ti, i = 1, . . . ,T, for path n,
n = 1, . . . , N. For example, if the underlying asset price S is assumed to fol-
low a geometric random walk, then the asset price at time t1 can be simulated
given the asset price at time 0 as
St1 = S0e(r−1
2 σ 2)·(t1−0)+σ·√
(t1−0)·˜ε0
where, as deﬁned earlier, ˜ε0 is a random variable following a normal dis-
tribution with mean 0 and standard deviation 1 (the subscript “0” stands
for the fact that this realization of ˜ε0 is for the time period (0, t1). Having
generated a realization of St1, we simulate a possible value for St2 by using
the formula
St2 = St1e(µ−1
2 σ 2)·(t2−t1)+σ·√
(t2−t1)·˜ε1
and generating a realization of the normal random variable ˜ε1. After re-
peating this T times, we have generated a path for the asset price. Aver-
aging the (properly discounted) option payoff over N paths produces the

536
DERIVATIVE PRICING AND USE
fair price of the Asian option. (See this chapter’s Software Hints and ﬁles
Ch14-PricingBySimulation.xlsx, Ch14-OptionPricingVBA.xlsm and Arith-
meticAsianCall.m for an implementation of an example.) There are more
efﬁcient ways to estimate the price of an arithmetic average Asian option.
(We will discuss one such method in section 14.2.4.)
14.2
VARIANCE REDUCTION TECHNIQUES
As we explained in section 4.4 of Chapter 4, paradoxically, truly random
numbers can be too random for practical purposes. Recall that the error in
the average estimate obtained from “truly random” Monte Carlo simulation
is proportional to 1/
√
N, where N is the number of scenarios for the ran-
dom variable (this fact would be approximately true for good pseudorandom
number generators as well).9 In order to make the estimate of a European
call option price twice as accurate, for example, we would have to increase
the number of generated scenarios for the underlying asset price four times.
Much research has been dedicated in recent years to ﬁnding ways to reduce
that error and to be computationally savvy when generating scenarios. Tech-
niques for increasing the accuracy of the estimate from simulation are often
referred to as variance reduction methods because their goal is to reduce
the variability of the estimator. Stratiﬁed sampling, which we discussed in
section 4.4.5, is one such method. In this section, we deﬁne and provide
intuition for several variance reduction methods that are widely used in
ﬁnancial applications. There are numerous ways to achieve computational
efﬁciency in speciﬁc situations, and we will not be able to review all here. For
a detailed introduction to other advanced variance reduction techniques, see
Glasserman (2004), Brandimarte (2006), and McLeish (2005).
14.2.1
Antithetic Variables
Simulating a random number is computationally expensive. One technique
that is used to reduce the error in the average estimate in derivative pricing
without increasing the number of simulated values is to incorporate the
generated random number twice in computing the derivative payoff: once
as the original simulated number, and another as its “antithetic” number.
For example, recall from our option pricing example in section 14.1
that the value of the stock price ST at time T can be computed from the
equation for a geometric random walk. In that expression, ˜ε is a random
variable that follows a standard normal distribution. Suppose that N values
for the normal random variable ˜ε are generated. With the antithetic variable
method, the value of the derivative payoff in each of the N scenarios is

Pricing Derivatives by Simulation
537
computed as the average of two payoffs: one obtained by plugging in the
simulated value for ˜ε, and another obtained by plugging in the negative of
the simulated value for ˜ε. These N “adjusted” payoffs are otherwise treated
in the same way as in the traditional simulation method described earlier in
this chapter: at the end, the N payoffs are averaged and properly discounted
to obtain the fair estimate of the derivative price. The difference is that this
approach substantially reduces the standard error in the average estimate,
while keeping the number of simulation trials at N.
The antithetic variable approach does not apply only to normal ran-
dom variables. As explained in section 4.4.1 of Chapter 4, random number
generation from an arbitrary probability distribution is often done by the
inverse transform method, that is, a random number is generated in two
stages. At the ﬁrst stage, a uniform random number U between 0 and 1 is
simulated. At the second stage, this random number is “inverted” to obtain
a random number from the desired probability distribution. Thus, we can
apply the antithetic technique at the ﬁrst stage, and treat the randomly gen-
erated number U as two realizations: U and its “antithetic” number 1−U.
For example, if the number generated on the interval [0,1] is 0.7, then the
antithetic number is 0.3. Both of these numbers can then be “inverted” to
obtain a pair of antithetic variables from a prespeciﬁed distribution such as
the normal distribution.
It is important to realize, however, that antithetic sampling is not a cure-
all. In some cases, the variance of the estimator of the expected price may
actually increase if we use antithetic sampling. Basically, for the antithetic
approach to work successfully, the payoffs generated with the antithetic
variables must have a negative correlation. Speciﬁcally, the antithetic vari-
ables approach relies on generating two sets of N realizations each of a
random variable simultaneously:
ε(1)
1 , . . . , ε(N)
1
and
ε(1)
2 , . . . , ε(N)
2
In the example of the European call option, we had ε(n)
2
= −ε(n)
1 , n =
1, . . . , N, which was a cheap way to produce another realization of the ran-
dom variable given a generated observation ε(n)
1 . The “vertical” dependencies
between the sets of observations were perfectly negatively correlated, that
is, each ε(n)
1
was perfectly negatively correlated with ε(n)
2
= −ε(n)
1 , and that
fortunately meant also that the resulting option payoffs ended up negatively
correlated.

538
DERIVATIVE PRICING AND USE
We produced a new sample of payoffs based on pairwise averages of
the payoffs corresponding to each of the two samples of realizations for ˜ε,
pf (1) = pf (1)
1
+ pf (1)
2
2
, . . . , pf (N) = pf (N)
1
+ pf (N)
2
2
Since the original observations for ˜ε were “horizontally” indepen-
dent (we drew an independent and identically distributed [IID] sample
ε(1)
1 , . . . , ε(N)
1 ), the pairwise averaged observations pf (1), . . . , pf (N) are also
IID. The variance of the average of the new sample of observations pf (1), . . . ,
pf (N) is
Var(pf ) = Var
 pf (1) + · · · + pf (N)
N

= 1
N2 ·

N · Var
	
pf (n)

= 1
N · Var

pf (n)
1
+ pf (n)
2
2

=
1
4N ·

Var(pf (n)
1 ) + Var(pf (n)
2 ) + 2 · Covar(pf (n)
1 , pf (n)
2 )

=
1
2N · Var(pf (n)
1 ) + 1
2N · Covar(pf (n)
1 , pf (n)
2 )
=
1
2N · Var(pf (n)
1 ) + 1
2N · σpf (n)
1 · σpf (n)
2



Var(pf (n)
1 )
·ρ(pf (n)
1 , pf (n)
2 )
= Var(pf (n)
1 )
2N
·

1 + ρ(pf (n)
1 , pf (n)
2 )

If we did not generate N regular and N antithetic variables, but instead
simply took a sample of 2·N IID random variables, the variance of the
estimate of the average payoff would have been
Var(pf (n)
1 )
2N
Thus, to reduce the variance of the average estimator Var(pf ), we would
ideally want the correlation ρ(pf (n)
1 , pf (n)
2 ) to be less than zero. This was true

Pricing Derivatives by Simulation
539
in the case of European option payoffs; however, there are some cases for
which this will not happen:
■The payoffs are not monotonic functions of the random variables. In the
case of the European call option simulation, the formula for the payoff
had the random variable ˜ε in the power of the exponential, and the
exponential function is a monotonic function—it increases as its expo-
nent increases. Imagine, however, a payoff function that increases and
then decreases with the values of the random variable, so that U and
1−U generate the same value for the payoff. In this case, the antithetic
variables method actually backﬁres, resulting in increased variance be-
cause the correlation between pf (n)
1 , pf (n)
2
is 1. Therefore, the payoffs for
some derivatives may not end up negatively correlated even if the anti-
thetic variables based on the uniform random numbers U and 1–U are
negatively correlated. An example of a payoff function that is nonmono-
tonic is that of a butterﬂy spread. (See Practice 14.4 on the companion
web site.)
■The generated random variables and their antithetic variables are not
negatively correlated. We assumed that we would use the inverse trans-
form method to generate the random numbers and the antithetic random
numbers. However, as we mentioned in section 4.4.1, other simula-
tion methods, such as the acceptance-rejection method and the Box-
Muller method are used as well. The inverse transform method uses
a monotonic function—the cumulative distribution function—to pro-
duce random variable realizations from different distributions based on
the realization of the uniform random numbers U and 1−U. With the
acceptance-rejection method and the Box-Muller method, we no longer
have the same guarantees.
14.2.2
Stratified Sampling
In section 4.4.5 of Chapter 4, we introduced stratiﬁed sampling as a tech-
nique that allows us to create a representative sample of the entire range
of outcomes. Variations of stratiﬁed sampling are already incorporated in
many random number generator software products, so it is not always nec-
essary to implement the algorithm manually. For example, as we mentioned
in section 4.4.5, an enhanced version of stratiﬁed sampling, Latin Hypercube
Sampling, is the default option for simulation with @RISK.
Nevertheless, it is instructive to see a speciﬁc, relatively simple example
of how stratiﬁed sampling would be implemented. We will price a European
option with maturity T and a strike price K under the assumption that the
asset price follows a geometric random walk.

540
DERIVATIVE PRICING AND USE
When the underlying price follows a geometric random walk, we can
simulate the price at maturity T using the equation
ST = S0 e(r−1
2 σ 2)·T+σ·
√
T·˜ε
where ˜ε is a standard normal variable. Stratiﬁed sampling is applied for
random numbers on the interval [0,1]. We generate the values for ˜ε by using
the inverse transform method: ﬁrst, generate N scenarios for realizations of
a uniform random variable ˜U on the interval [0,1] and then use the inverse
cumulative normal distribution function −1 to get the values for ˜ε.10
The scenarios U1, . . . , UN for the realizations of the uniform random
variable ˜U will be generated in such a way that every realization falls in its
own stratum n, n = 1, . . . , N. To have N strata of equal probabilities, we
divide the unit interval into N little intervals, each of length 1/N. If we then
consider the inverse cumulative normal distribution function,
−1
n −1
N
+ Un
N

, n = 1, . . . , N
then we will have divided the standard normal distribution into N strata
of equal probability. (Note that this does not mean that the corresponding
intervals on the horizontal axis of the normal distribution will be of equal
length, only that the area above them under the normal distribution PDF
will be the same.) Thus, if we generate the N scenarios for ˜ε using the
formula
ST = S0 e(r−1
2 σ 2)·T+σ·
√
T·−1( n−1
N + Un
N ), n = 1, . . . , N
we will obtain a representative sample of values for the ﬁnal asset price.11
To compute the price of the option, we would then compute the pay-
offs in all scenarios, discount them to the present, and ﬁnd their average
as usual:
C0 = e−r·T ·
N

n=1
1
N max

S0 e(r−1
2 σ 2)·T+σ·
√
T·−1( n−1
N + Un
N ) −K, 0

14.2.3
Importance Sampling
Importance sampling is an alternative to stratiﬁed sampling for dealing with
rare events, or extreme observations, and for reducing the number of simu-
lation trials necessary to achieve a particular level of accuracy. The method

Pricing Derivatives by Simulation
541
changes the underlying scenario probabilities so as to give more weight to
important outcomes in the simulation. Such outcomes are generated with
greater frequency than they otherwise would. At the end, the observations’
weights are scaled back in the computation of the expression of interest, so
that the estimation is correct.
There is no single recipe for how to construct good importance sam-
pling methods. The speciﬁc construction depends on the underlying random
process dynamics. Let us consider the example of pricing European call op-
tion in the Black-Scholes setting. In this setting, generating paths that are
out-of-the-money is wasteful.12 This is because only paths that are in-the-
money count in the ﬁnal computation of the option price—the contribution
of out-of-the-money paths to the option price is zero. Although in practice
one would not use importance sampling for pricing a European call option
for which there is a closed-form formula, we use the European call example
to provide some intuition about the idea behind the importance sampling
method.
First, note that in-the-money paths will occur only if the asset price at
the expiration date is greater than the strike price; that is, they will result
from realizations of the standard normal random variable ˜ε such that
ST = St e(r−1
2 σ 2)·(T−t)+σ·√
(T−t)·˜ε > K
From this inequality, we can derive that only normal random numbers
higher than
ln(K/St) −(r −σ 2/2) · (T −t)
σ · √T −t
will lead to in-the-money paths. Equivalently, this means that only random
numbers between

ln(K/St) −(r −σ 2/2) · (T −t)
σ · √T −t

and 1 on the unit interval [0,1], when “inverted” to obtain normal random
numbers, will lead to in-the-money paths. ((.) denotes the cumulative nor-
mal distribution, as before.) Thus, we only need to simulate random numbers
in that range of the [0,1] interval. When computing the option price at the
end, instead of weighing each payoff equally by multiplying it by 1/N as
we would do in standard Monte Carlo sampling, we would multiply the
sum of the payoffs obtained from the simulation by the probability that a

542
DERIVATIVE PRICING AND USE
particular random path would be in-the-money assuming truly random sam-
pling, which is the standard Monte Carlo method. The latter probability is
1 −
ln(K/St) −(r −σ 2/2) · (T −t)
σ · √T −t

= 
ln(St/K) + (r −σ 2/2) · (T −t)
σ · √T −t

The call option price is then
Ct = e−r(T−t) · 
ln(St/K) + (r −σ 2/2) · (T −t)
σ · √T −t

N

n=1
max

Ste(r−1
2 σ 2)·(T−t)+σ·√
(T−t)·ε(n) −K, 0

where ε(1), . . . , ε(N) are random numbers generated from the range of a
normal distribution higher than
ln(K/St) −(r −σ 2/2) · (T −t)
σ · √T −t
Now let us formalize the importance sampling approach.
When we attempt to ﬁnd the expected value of the discounted payoffs
from a derivative, we are in effect trying to evaluate an integral of a speciﬁc
function over all values the random variable can take.13 We evaluate that
integral approximately—we generate the value of the function at multiple
points, and we multiply those values by the probabilities that they happen.
(With crude Monte Carlo simulation, each scenario we generate happens
with the same probability, so we multiply the estimated value of the payoff
function by one over the number of scenarios.)
The main idea of the importance sampling method is to introduce an
importance distribution that rescales the original distribution and makes
important scenarios more likely to appear. Suppose that the original integral
we were trying to evaluate was
E[h(X)] =

h(x) · f (x)dx
where X is a vector of random variables with joint probability density
f(x) and h(X) is the discounted payoff function. If we can ﬁnd another

Pricing Derivatives by Simulation
543
probability density function g such that f(x) = 0 whenever g(x) = 0, we
have
E f [h(X)] =

h(x) · f (x) dx
=
 h(x) · f (x)
g(x)
· g(x) dx
=

h∗(x) · g(x)dx
= Eg[h∗(X)]
In other words, we can ﬁnd the expected value of the payoff h(X)
with respect to the original probability density function f(x) by ﬁnding the
expected value of the modiﬁed payoff function
h∗(x) = h(x) · f (x)
g(x)
with respect to the new probability density g(x). The ratio
f (x)
g(x)
corrects the change in probability measure. It is called the likelihood ratio,
but is also referred to as the Radon-Nikodym derivative in the context of
stochastic calculus.
We see that on average, we will get the same answer by using impor-
tance sampling as when we use crude Monte Carlo sampling. How can we
guarantee, however, that the function g(x) we select will indeed reduce the
variance of the estimator? Let us compute the variances of the two estimators
h(X) and h*(X). Using the equality14
Var( ˜X) =
∞

−∞
x2 · f (x) dx −
⎛
⎝
∞

−∞
x · f (x) dx
⎞
⎠
2
we get
Var f [h(X)] =

h2(x) · f (x) dx −
	
E f [h(X)]

2
Varg[h∗(X)] =

h2(x) · f 2(x)
g2(x) · g(x) dx−
	
Eg[h∗(X)]

2
=

h2(x) · f (x)
g(x) · f (x) dx−
	
E f [h(X)]

2

544
DERIVATIVE PRICING AND USE
The difference between the two variances is
Var f [h(X)] −Varg[h∗(X)] =

h2(x) ·

1 −f (x)
g(x)

· f (x) dx
Therefore, to ensure that the variance becomes smaller when we use
important sampling, we should select g(x) to be large (greater than f(x))
when the term h2(x) · f (x) is large, and g(x) to be small (smaller than f(x))
when the term h2(x) · f (x) is small. In other words, we emphasize important
observations.
How is this procedure applied in the case of the European call option?
The discounted payoff function in the case of a European call option is
h(x) = e−rT · max {ST −K, 0}
We observed that important scenarios would be generated only if the
simulated paths end up in-the-money, that is, above the strike price K. Sup-
pose we decide to generate the values for the ﬁnal price ST from a probability
distribution that is more likely to produce scenarios above the strike price
K. Suppose further that instead of the original probability distribution f for
the logarithm of the ﬁnal asset price, which was normal with mean (r –
σ 2/2) · T and variance σ 2 · T, we consider a normal distribution with mean
ln(K/S0) – σ 2 · T/2 and the same variance, σ 2·T. In other words, in the
notation used in this section,
f (x) = N(x, (r −σ 2/2) · T, σ 2 · T)
=
1
σ
√
2π
e
−(x−(rT−σ2T/2)2
2(σ2T)
g(x) = N(x, ln(K/S0) −σ 2 · T/2, σ 2 · T)
=
1
σ
√
2π
e
−
(x−(ln(K/S0)−σ2T/2)2
2(σ2T)
The likelihood ratio is then simply the ratio of two normal density
functions with different means. Therefore,
E f [h(x)] = E f

e−rT · max {ST −K, 0}
= Eg

e−rT · max {ST −K, 0} · f (x)
g(x)


Pricing Derivatives by Simulation
545
Hence, the estimator from the simulation is the average for all scenarios
generated with the formula
e−rT · max

S0 · eZ −K, 0

·
1
σ
√
2π · e
−(Z−(rT−σ2T/2)2
2(σ2T)
1
σ
√
2π · e
−
(Z−(ln(K/S0)−σ2T/2)2
2(σ2T)
where Z is simulated as a normal random variable with mean ln(K/S0) –
σ 2·T/2 and variance σ 2·T. The paths generated in this manner will be less
likely to produce payoffs that are zero.
As we mentioned at the beginning of this section, European call pricing
with importance sampling was only a simple example in order to illustrate
the main idea of importance sampling. More practical (albeit more tech-
nically challenging) applications can be found, for instance, in section 4.6
in Glasserman (2004). One such important application is importance sam-
pling in the context of estimating value-at-risk. As we discussed in Chapter
8, the estimation of value-at-risk is very sensitive to the quality of sampled
observations in the tail of the distribution of portfolio losses, but by deﬁni-
tion observations in the tail of the distribution are very unlikely to happen
during a simulation unless we generate an enormous number of scenarios.
Importance sampling can be applied in this context, and the importance
distribution is often selected to be a member of the exponential family of
distributions, which increases the tilt in the right tail of the original distri-
bution for speciﬁc values of its input parameters. See Chapter 4 in McLeish
(2005) for a more detailed introduction to this application.
14.2.4
Control Variates
Like importance sampling, the control variates method uses knowledge
about a function that is related somehow to the original function we are
trying to estimate by simulation. Also, like importance sampling, the choice
of function is subjective.
The main idea of the control variates method is to ﬁnd the expected value
of the discounted payoffs of a derivative for which no analytical formula is
known by using knowledge about an expected value of a related variable
that is known. Such a situation would arise, for example, if we are trying to
price an Asian call option. Intuitively, the price of an Asian call option for
which the payoff involves the arithmetic average of stock prices over the life
of the option should be related to the price of an Asian call option for which
the payoff involves the geometric average of stock prices over the life of the
option. While there is no closed-form formula for the price of an Asian call

546
DERIVATIVE PRICING AND USE
option with arithmetic average, there is a closed-form formula for the price
of an Asian call option with geometric average when the underlying asset
follows a geometric random walk, so we can exploit this knowledge.
More generally, suppose that we would like to estimate the expected
value of a random variable X, E[X], and that there is another random
variable Y with expected value E[Y], which is somehow correlated to X.
The variable Y is called the control variate. The estimator for X can be
written as
X(b) = X −b · (Y −E[Y])
where b is a parameter that must be speciﬁed. We employ the following
procedure. We simulate N observations for the variable X, and along with
those, compute N observations for the variable Y. Think of the observations
X1, . . . , XN as the payoffs for the arithmetic average Asian call option, and of
the observations Y1, . . . , YN as the payoffs for the geometric average Asian
call option. Both sets of payoffs are generated based on N sample paths for
the underlying asset price St.
Now, instead of computing E[X] directly as the average of X1, . . . , XN,
consider the average of Xi(b) obtained as
1
N ·
N

i=1
(Xi −b · (Yi −E[Y]) = X −b ·
	
Y −E[Y]

where we use the standard notation X to denote the sample average, as
opposed to the true expected value.15 Again, note that we assume that E[Y]
is known. In the example of computing the arithmetic average Asian call
option price, E[Y] is the price of the geometric mean Asian call option.
It turns out that the optimal value for the constant b (the value that will
minimize the variance of the estimator X(b)) is actually
b∗= Cov(X, Y)
Var(Y)
When we use this value of b, it can be shown that
Var(X −b∗· (Y −E[Y]))
Var(X)
= 1 −ρ2(X, Y)
where ρ is the correlation coefﬁcient between X and Y.

Pricing Derivatives by Simulation
547
Therefore, the stronger the correlation between the variable of interest,
X, and the control variate Y, the more signiﬁcant the impact of using the
control variable method for reducing the variance in the estimation of E[X].
Note, however, that whereas a correlation of 0.95 between X and Y results
in a tenfold decrease in variance of the estimator for E[X] (1 – 0.952 =
0.0975, which is approximately 1/10), a correlation of 0.70, which would
be considered a strong correlation for all practical purposes, results in a
twofold decrease in the variance of the estimator (1 – 0.702 = 0.51, which
is approximately 1/2). Therefore, a rather strong correlation between the
original variable and the control variate is needed in order to achieve a sig-
niﬁcant improvement. For example, using the geometric mean Asian option
price as a control variate for the estimation of the arithmetic average Asian
option price is a very successful approach, whereas using other quantities
that are generally related to the Asian option payoff, such as the price of
a European call option on the underlying asset, or the average of the asset
prices realized with a geometric random walk, is not worth the additional
computational effort.
We did not elaborate on how one may compute the actual estimate of
the coefﬁcient b. In practice, since we do not know E[X] (we are trying to
estimate it), it is unlikely that we will know the covariance between X and
Y. The best we can do is estimate b. Typically, a preliminary simulation is
run (with fewer trials than would be necessary to estimate the quantity of
interest, E[X], accurately), and the coefﬁcient b is estimated as
ˆb =
Np

i=1
(Xi −X) · (Yi −Y)
Np

i=1
(Yi −Y)2
where Np is the number of preliminary simulation trials.
To make the control variates method more intuitive, let us go through
the Asian option pricing example in detail. We will take the following steps:
1. Compute the price of a geometric Asian call option, which will serve as
our control variate.
The price at time 0 of a geometric average Asian call option with
time to maturity T and M intermediate evaluation steps of length t
can be shown to be
CA,G = e−r·T 
ea+ 1
2 ·c · (x) −K · (x −√c)


548
DERIVATIVE PRICING AND USE
where
t = T
M
v = r −q −1
2 · σ 2
a = ln(S0) + v · (t) + 1
2 · v · (T −t)
c = σ 2 · (t) + σ 2 · (T −t) · (2 · M −1)/(6 · M)
x = a −ln(K) + c
√
b
2. Run a preliminary simulation to estimate the value of the coefﬁcient
b. Namely, we will simulate Np paths for the underlying asset price,
ﬁnd the discounted payoffs for the geometric and the arithmetic Asian
call along each path, compute their covariance, compute the variance of
the discounted payoffs of the geometric Asian call, and use the formula
Cov(X,Y)/Var(Y) to estimate the value of b.
3. Simulate the number of paths for the price of the underlying stock we
originally intended, and evaluate the payoffs for the geometric and the
arithmetic Asian call along each path. For each of these paths, knowing
the exact price for the geometric Asian call from Step 1, and a value for
b from step 2, we can calculate an estimate for the arithmetic Asian call
payoff as follows:
Estimate = Arithmetic Asian payoff −b ∗
(Geometric Asian payoff −Exact geometric price)
4. The average of the estimates from step 3 over all the paths is the estimate
of the arithmetic Asian call price with the control variates method.
(See this chapter’s Software Hints and ﬁles Ch14-OptionPricingVBA
.xlsm and ArithmeticAsianCallCV.m for an exact implementation.)
As we mentioned earlier, using the geometric Asian call price as a control
variate is a very successful method for reducing the overall variance in
computing the price of an arithmetic Asian call by simulation. Let us do a
simple comparison of the estimation of the arithmetic Asian option price
with and without control variates. Consider the example of an arithmetic

Pricing Derivatives by Simulation
549
Asian call option with strike price $65, time to maturity 1 year, and monthly
intermediate dates (that is, we will simulate a geometric random walk with
12 steps between time 0 and the maturity of the option). The annual risk-
free rate is 10%. The volatility of the underlying stock is 40%; the initial
stock price is $60. We will generate 100 paths for a geometric random walk
for the underlying asset, and evaluate the price of the Asian option using
crude Monte Carlo and the control variates method with 20 preliminary
scenarios. The whole estimation will be repeated 30 times, and we will
record the mean and the standard deviation of the 30 arithmetic Asian
option prices generated with the crude Monte Carlo method and the 30
arithmetic Asian option prices generated with the control variates method.
(See this chapter’s Software Hints and ﬁles Ch14-OptionPricingVBA.xlsm
and ArithmeticAsianCallEstimationComparison.m for the actual code.)
The results will vary from simulation to simulation, of course, but the
order of magnitude of the difference between the variability of the prices ob-
tained with the crude Monte Carlo and the control variates method remains
the same. In our trial run, we obtained $5.40 for the mean price with the
crude Monte Carlo method, and the variability of the 30 prices was 1.4046.
With the control variates method, we obtained $5.02 for the mean price, and
0.0037 for the variability. The reduction in the variability of the estimate
of the option price was approximately 380 times, and that happened with
only 20 preliminary simulations to estimate the coefﬁcient b in the control
variates method!
14.3
QUASIRANDOM NUMBER SEQUENCES
In some sense, quasi–Monte Carlo methods ﬁt in the section on variance
reduction methods. You can think of them as an extreme version of stratiﬁ-
cation methods. As we explained in section 4.4.4 of Chapter 4, quasi–Monte
Carlo methods rely on number theory to produce sequences of numbers that
do not pretend to be random, but instead cover the unit interval in a uniform
way, so that every part of the probability distribution is represented when
simulating. Some quasi–Monte Carlo methods work better than others for
pricing speciﬁc derivatives, but there is no comprehensive way to determine
that in advance without testing. In this section, we review some of the most
common types of quasi–Monte Carlo sequences used in derivative pricing,
and give an example of how the actual implementation would work.
The exposition in this section is rather technical because quasirandom
methods for pricing derivatives draw on concepts from calculus, statistics,

550
DERIVATIVE PRICING AND USE
and number theory. In fact, many of the techniques we will describe in this
section are based on research in the most efﬁcient ways to integrate a func-
tion. As we mentioned earlier in this chapter, integrals show up in derivative
pricing because the expected value of a random variable can be expressed
as a sum, or an integral.16 In the context of derivative pricing, the random
variable is the discounted payoff from the derivative. Under conditions of no
arbitrage, the expected value of that random variable provides the deriva-
tive’s fair value. Monte Carlo simulation has been a technique for numerical
integration for a long time. The main idea is to simulate a representative set
of points, and to evaluate the values of the function at the simulated points.
As the concept of ever-more representative samples of points over which to
evaluate the function has been pushed to the limit, the idea of low discrep-
ancy sequences emerged. Such sequences must be evenly distributed in some
sense, and cover the range [0,1] in a way that minimizes the discrepancies
between the points.
We begin with the most fundamental sequence, the Van der Corput
sequence. More advanced sequences, such as Halton and Faure, build on the
Van der Corput sequence. There are three parameters that we will associate
with a quasirandom sequence (some sequences may require more): N, the
number of points from the sequence to generate; d, the dimension (that is,
how many random variables are we generating at the same time), and b, the
base, which we will explain in more detail next.
14.3.1
Van der Corput Sequence
In section 4.4.4 of Chapter 4, we showed an example of the Van der Corput
sequence of base 2:
1
2, 1
4, 3
4, 1
8, 5
8, 3
8, 7
8, . . .
Let us see how such a sequence would be generated.
Consider a sequence of natural numbers in base 10:17
1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, . . .
The same sequence in base 2 is
1, 10, 11, 100, 101, 110, 111, 1000, 1001, 1010, 1011, 1100, 1101, . . .

Pricing Derivatives by Simulation
551
Constructing the Van der Corput sequence in base b, involves two steps:
1. Express every natural number n in the sequence in base b, that is, as
(0.a0(n)
a1(n)
a2(n)
a3(n) . . . am(n))b =
m

k=0
ak(n) · b−(k+1)
where am(n), . . . , a0(n) are the digits in the representation of the number
n in base b. For example, the number 13 in base 10, (13)10, converted
to base 2 is (1101)2. In this case, m = 3 and a3(13) = 1, a2(13) = 0,
a1(13) = 1, a0(13) = 1.
2. Reverse the digits and add a decimal point to obtain a number within
the interval [0,1] (we dropped the index n for notational convenience):
(0.a0a1a2a3 . . . am)b =
m

k=0
ak · b−(k+1)
For example, the digits of the number (13)10 = (1101)2 get reversed
to 1011, and then we transform that number to
1 · 2−1 + 0 · 2−2 + 0 · 2−3 + 1 · 2−4 = 11/16
Applying this method to the entire sequence, we obtain
1
2, 1
4, 3
4, 1
8, 5
8, 3
8, 7
8, 1
16, 9
16, 5
16, 13
16, 3
16, 11
16 . . .
As we mentioned in section 4.4.4 of Chapter 4, these values tend to
ﬁll the unit interval evenly. The larger the base, the greater the number of
points needed to achieve uniform coverage of the interval. You can test
this by using the Van der Corput sequence generating code in ﬁles Ch14-
OptionPricingVBA.xlsm and VanDerCorput.m. (See also this chapter’s
Software Hints.)
14.3.2
Halton Sequence
The Halton sequence is basically the multivariate extension of the Van der
Corput sequence. If we need to simulate multiple random variables (if there
are d of them, we need to construct a sequence in dimension d), we choose
d distinct prime numbers, b1, . . . , bd to serve as bases. (Usually, we select
the smallest possible prime numbers.) For example, if we need to generate

552
DERIVATIVE PRICING AND USE
three random variables, d = 3. Suppose we select bases b1 = 2, b2 = 3, and
b3 = 5 (2, 3, and 5 are the smallest three prime numbers). We have three
sequences:
Base 2:
1
2, 1
4, 3
4, 1
8, 5
8, 3
8, 7
8, 1
16, 9
16, 5
16, . . .
Base 3:
1
3, 2
3, 1
9, 4
9, 7
9, 2
9, 5
9, 8
9, 1
27, 10
27, . . .
Base 5:
1
5, 2
5, 3
5, 4
5, 1
25, 6
25, 11
25, 16
25, 21
25, 2
25, . . .
The points generated with the Halton sequence of dimension 3 will have
three coordinates that correspond to the points with the same index in each
Van der Corput sequence above, that is, the Halton sequence will be
1
2, 1
3, 1
5

,
1
4, 2
3, 2
5

,
3
4, 1
9, 3
5

, . . .
(See this chapter’s Software Hints and ﬁles Ch14-OptionPricingVBA.xlsm
and Halton.m for an implementation of the algorithm with Visual Basic and
MATLAB.)
14.3.3
Faure Sequence
As the dimension d of the Halton sequence grows large, the uniformity of
covering the unit cube becomes worse and worse. This is because the in-
creasing value for the base b makes the coverage more and more sparse.
The Faure sequence attempts to rectify that by keeping the base the same
independent of the number of dimensions. The value for the base needs to
be at least as large as the number of dimensions d, and is usually selected
to be the smallest prime number greater than or equal to d. For example,
if d is 15, the Halton sequence uses the 15th prime number (which is 47)
to generate the values of the sequence in its 15th dimension, whereas the
Faure sequence uses the ﬁrst prime number after 15 (which is 17). Thus,

Pricing Derivatives by Simulation
553
the components of the Faure sequence ﬁll in the gaps faster than the com-
ponents of the Halton sequence when the dimension d is large. (If d = 1,
however, notice that the Van der Corput, Halton, and Faure sequences are
equivalent.)
Instead of matching points with the same index in the individual Van der
Corput sequences to create the coordinates of a point in d dimensions, the
Faure sequence uses permutations of the indices for each of the coordinates.
In fact, the coordinates of a Faure sequence are constructed by permuting
segments of a single Van der Corput sequence. Recall that when generating
a Van der Corput sequence, we expressed the nth point in the form
(am(n)
. . .
a3(n)
a2(n)
a1(n)
a0(n))b =
m

k=0
ak(n) · bk
and those numbers were then transformed into
(0.a0(n)
a1(n)
a2(n)
a3(n)
. . . am(n))b =
m

k=0
ak(n) · b−(k+1)
When generating the ith coordinate in a Faure sequence, the transforma-
tion uses different coefﬁcients in front of b–(k+1) for every dimension. These
coefﬁcients (let us denote them c(i)
k (n)) are related to the coefﬁcients ak(n),
but use only the last (m – k + 1) values of the coefﬁcients a. In particular,
to generate the nth point in the ith coordinate in a Faure sequence, we use
the expression
m

k=0
c(i)
k (n) · b−(k+1)
where the coefﬁcients c(i)
k (n), k = 0, . . . , m are computed as
c(i)
k (n) =
m

j=k
 j
k

· (i −1) j−k · a j(n)
mod
b18
As a consequence of these adjustments, the Faure sequence has better
uniformity properties than the Halton sequence for moderately high dimen-
sionality.

554
DERIVATIVE PRICING AND USE
14.3.4
Sobol Sequence
The Sobol sequence is a yet more sophisticated quasirandom sequence that
uses so-called direction numbers to generate the terms of the sequence.
Similarly to the Faure sequence, it incorporates the idea of permuting the
coordinates of the points generated by Van der Corput sequences in a clever
way, but uses base 2 independently of the number of dimensions. Working
in a small base has certain computational advantages.
The computation of the Sobol sequence is more technical than the com-
putation of the Van der Corput, Halton, or Faure sequences, so we omit
the details here and refer readers to Chapter 6 in McLeish (2005) or section
5.2.3 of Chapter 5 in Glasserman (2004) for a comprehensive introduction.
Some software packages, and in particular MATLAB’s Statistics Toolbox,
have built-in capabilities for computing the elements of the Sobol sequence.
(See the MATLAB section of this chapter’s Software Hints.)
14.3.5
Illustrations
To illustrate how quasi–Monte Carlo methods can be used, let us implement
a simple example. We know the exact value of a European call option
when the underlying asset price is assumed to follow a geometric random
walk—the value is given by the Black-Scholes formula (see Chapter 13).
Let us compute the price of the European call option with crude Monte
Carlo simulation and with quasi–Monte Carlo simulation, using the Halton
and the Sobol sequences. Calculating the price of the European call option
requires generating only one random variable—the normal random variable
that represents the change in the underlying asset’s price. Therefore, the
quasirandom sequences have only one dimension. It follows that the Halton,
Faure, and Van der Corput sequences will all give the same result.
To implement the algorithm, we generate the price of the underlying
asset at maturity T as
ST = St e(r−1
2 σ 2)·(T−t)+σ·√
(T−t)·˜ε
where ˜ε is a standard normal random variable.
When using the crude Monte Carlo method, ˜ε can be generated with
the formula =NORMINV(rand()) in Excel, =RISKNORMAL(0,1) in @RISK, or
normrnd(0,1) in MATLAB, as explained earlier in the book. We create N
scenarios for ˜ε, and average out the discounted payoffs over the scenarios.
When using quasi–Monte Carlo simulation, we generate N values from
one of the low discrepancy sequences we discussed—Halton or Sobol, and
use the norminv function in Excel or MATLAB to convert those values

Pricing Derivatives by Simulation
555
into values from a standard normal distribution. For example, to gener-
ate the number from the standard normal distribution that corresponds to
the value 0.5 from the Halton sequence in one dimension, we will enter
norminv(0.5,0,1) in both Excel and MATLAB. Repeating this for each
of the N values in the quasirandom sequence, we obtain N scenarios for
˜ε, which can be used to compute N asset prices at maturity. These N asset
prices in turn can be used to compute the discounted payoffs of the op-
tion over all scenarios, and the discounted payoffs are then averaged out to
compute the price of the option.
Exhibit 14.1 illustrates the performance of the crude Monte Carlo and
a quasi–Monte Carlo method with the Halton sequences with base 2. We
generated 1, 2, 3, . . . , 100 scenarios with each of the methods, and evaluated
the option price in each case. The Black-Scholes price is also given on the
0
10
20
30
40
50
60
70
80
90
100
0
2
4
6
8
10
12
14
16
18
Number of Scenarios
Estimated Option Price ($)
Black-Scholes price
Crude Monte Carlo
Halton sequence
EXHIBIT 14.1
Comparison of performance of crude Monte Carlo and a
quasi–Monte Carlo method (Halton sequence of base 2) for evaluating the price of
a European call option. The initial stock price is assumed to be $60, the strike price
is $65, the maturity of the option is 1 year, the volatility of the underlying stock is
0.4, and the risk-free rate is 10%. The true (Black-Scholes) price of the option is
$10.02.

556
DERIVATIVE PRICING AND USE
graph for reference. It can be observed that the crude Monte Carlo simula-
tion method produces rather volatile estimates of the option price, especially
for a small number of scenarios. The quasi–Monte Carlo method produces
price estimates that tend to the real option price relatively monotonically.
(See ﬁles Ch14-OptionPricingVBA.xlsm, EuropeanCallHalton.m, Eu-
ropeanCallSobol.m, as well as this chapter’s Software Hints for details on
implementing the algorithms with Excel and MATLAB.)
Now let us think through a somewhat more complicated example. Sup-
pose that we would like to price an Asian option by simulation. The time to
maturity of the option is 1 year, and we would like to sample the price of
the underlying asset monthly. This means that we want to generate N paths
for the price of the underlying with 12 points each. Suppose also we would
like to use a Halton sequence. How many dimensions should the Halton
sequence have? Since we are sampling at 12 time instances, and at each
time instance we are drawing a price for the underlying that is assumed to
follow a speciﬁc (lognormal) probability distribution, we need to generate
a Halton sequence of dimension 12, that is, we need to generate 12 Van
der Corput sequences of length N. Note that each Van der Corput sequence
(each dimension of the Halton sequence) is associated with a time instance,
not with a path. The length of each Van der Corput sequence equals the
number of scenarios we desire, which is N.
As we mentioned earlier, the advantages of using one versus another
quasirandom sequence are not clear. There is a substantial amount of litera-
ture comparing the performance of different sequences, but the comparisons
are typically for a small number of select applications. There is not strong
evidence that if the dimension of the problem is small (e.g., less than 15), it
makes a big difference whether we use the Halton, Faure, or Sobol sequence.
14.4
MORE SIMULATION APPLICATION EXAMPLES
While the features of derivatives are different, the main ideas behind using
simulation to price them remain the same. This section contains several
additional examples that illustrate the main ideas and show some further
twists in the implementation.
14.4.1
Pricing a Barrier Option
There are many types of barrier options, but their common feature is that
there is a trigger event that activates or cancels the option contract. For
knock-in options, the option contract is activated if a barrier value is crossed
by the underlying during the life of the option. For knock-out options, the

Pricing Derivatives by Simulation
557
option contract is canceled if the barrier value is crossed. When the barrier
Sb is above the initial asset price S0, the barrier option is an up option. When
the barrier Sb is below the initial asset price S0, the barrier option is a down
option.
As an example, consider a down-and-out put option. This option con-
tract becomes void if the asset price falls below the barrier Sb. Such an
option provides a payoff to the option holder for relatively small drops in
the asset price. It also protects the option writer from large risks, and so the
option would be cheaper than a regular, or “vanilla” put option. From the
point of view of the option holder, the down-and-out put option provides
cheaper insurance than a vanilla put option, although the drawback is that
the option holder will not be able to realize a large payoff if the price of the
underlying drops substantially.
Let us now price a down-and-out put option with a strike price K and
time to maturity T. In order to ﬁnd its value, we need to keep track of whether
the barrier has been crossed or not. We simulate paths for the underlying
asset. Suppose that the underlying asset follows a geometric random walk.
For every path we then have a variable, say crossed (in Excel, we can
dedicate a cell) that stores the value 0 if the barrier has not been crossed,
and 1 otherwise. When we compute the ﬁnal payoffs, we set the payoff for
a particular path to 0 if the value of the crossed variable for that path is 1,
and we compute the payoff as max{K – ST, 0}, similarly to the payoff of a
vanilla put option, when the value of the crossed variable for that path is 0.
(See this chapter’s Software Hints and ﬁles Ch14-OptionPricingVBA.xlsm
and DownAndOutPut.m for the implementation of an example.)
14.4.2
Pricing an American Option
As mentioned in section 13.1.2 of Chapter 13, in contrast to European
options, American options are contracts in which the option holder has the
right to exercise the option at any time during the life of the option, rather
than only at maturity.19 The payoff of American options therefore depends
on the time at which the option holder decides to exercise the option. Under
certain conditions (no transaction costs, equal borrowing and lending costs),
it can be shown that the price of an American call option should always be
equal to the price of a European call option.20 This, however, is not the case
for American and European put options.
Until fairly recently, simulation was not considered a viable technique
for pricing American options. The dynamic programming technique applied
on binomial and trinomial trees, as illustrated in section 13.4.3 of Chap-
ter 13, as well as ﬁnite difference methods21 were the dominant techniques
for pricing securities with early exercise features. However, binomial trees

558
DERIVATIVE PRICING AND USE
and ﬁnite difference methods become impractical when there are multiple
stochastic factors that drive the price of the underlying security. Simulation,
on the other hand, can handle multiple factors and their codependencies.
In the last decade, various techniques for applying simulation to American
option pricing have been suggested.22 In this section, we present a simple
example of a regression-based technique for approximating the price of an
American option. Regression-based methods for approximating the value
function in a dynamic program are a well-known approximate dynamic
programming technique that has its roots in control theory.
Regression-based methods for pricing derivatives with American fea-
tures have been suggested by Longstaff and Schwartz (2001) and Tsitsiklis
and Van Roy (1999, 2001), among others. The main idea in these ap-
proaches is to generate possible scenarios for the future price by simulation,
and use regression analysis to produce an approximate estimate of the dy-
namic programming value function.23 This estimate is a function only of the
time period, and not of the speciﬁc state (price). Based on that estimate, we
decide whether to exercise early, or hold the option for another time period.
When pricing American options by simulation, as with pricing any other
option by simulation, we discretize the time and possible space of outcomes;
thus, we do not obtain a complete picture of the range of uncertainties that
can occur. Furthermore, with regression-based methods for value function
estimation, only an approximation of the state space is obtained in order to
decide whether to exercise or not. The price estimate we obtain is in fact a
lower bound on the true price of the American option.
A number of approaches have been suggested for producing an upper
bound on the true price of the American option, but they are more technical
than the exposition of this book, so we will not discuss them in detail. The
simplest method is actually to assume that we have “perfect vision”: that
is, to compute the optimal strategy and payoff along each path we have
simulated, and to ﬁnd the expected value of the discounted payoffs along
all simulated paths.24 This upper bound on the option price is not particu-
larly tight. More sophisticated approaches based on duality and resulting in
tighter bounds have been suggested in Haugh and Kogan (2004) and Rogers
(2002).
Let us now explain regression-based methods for estimating a lower
bound on the price of the American option in more detail. For simplicity,
assume that we have a vanilla American put option on a single stock. (The
approach obviously applies to, and is more useful for, pricing of more com-
plex securities with American features.) We generate N sample paths for
the stock price S(1), . . . , S(N). Each of these paths contains T observations
of the stock price. If we used the dynamic programming approach to ﬁnd
the price of the American option (see section 13.4.3), we would proceed

Pricing Derivatives by Simulation
559
backwards from the last time period. At every time period, we would com-
pare the intrinsic value of the option (that is, the value of exercising the
option at that time) to the expected value of continuing. The latter is the
quantity that is difﬁcult to estimate because in practice we can have an inﬁ-
nite number of possible values for the stock price. Instead of evaluating that
quantity precisely, we replace it with an estimate from a regression model.
In the regression model, we use the conditional expectation of the value
of continuing (based on the generated scenarios) as the response variable,
and a collection of basis functions of the current stock price to create the
explanatory variables. The simplest basis functions of the stock price S are
ϕ0(S) = 1, ϕ1(S) = S and ϕ2(S) = S2. It turns out, actually, that the choice
of basis functions does not make a big difference in the end.25
At expiration, the value function in the dynamic program is
VT(ST(i)) = max{K −ST(i), 0}
for each sample path i, i = 1, . . . , N.
At the second-to-last time period (time T – 1), we need to compare the
value of exercising the option, or the intrinsic value
IT−1(i) = max{K −ST−1(i), 0}
to the value of continuing,
E[e−r·t · VT( ˜ST)]
(Note that we have discounted the payoff at time T in order to compare
both cash ﬂows in time [T – 1] dollars.)
We run a regression in which the values estimated from the last time
period, max{K – ST(i),0}, are the response variable (Y) values, and each
generated scenario represents a data point. The regression equation is
e−r·t · max{K −ST(i), 0}
= β0 · ϕ0(ST−1(i)) + β1 · ϕ1(ST−1(i)) + β2 · ϕ2(ST−1(i)),
i = 1, . . . , N
or, for our choice of basis functions,
e−r·t · max{K −ST(i), 0} = β0 + β1 · ST−1(i) + β2 · S2
T−1(i), i = 1, . . . , N

560
DERIVATIVE PRICING AND USE
After determining the regression coefﬁcients β0, β1, and β2, we have a
way of approximating the value of continuing from every state for the stock
price, i, i = 1, . . . , N, at time T – 1. This approximate value can then be
compared to the intrinsic value at that state to ﬁgure out whether to continue
or not.
The procedure is repeated going backwards in time, including at time
period 0.
To improve the speed of the calculations, we may want to run the
regressions only for the subsets of paths at each time period for which the
option is in the money because these are the only paths for which a decision
needs to be made. For paths that are not in the money, it is clear that it is
not optimal to exercise.
The best way to illustrate the approach is to show an example. We
will use a simple example from Longstaff and Schwartz (2001). Consider a
three-year American put option that can be exercised at the end of year 1, at
the end of year 2, and at the end of year 3. The current stock price is $1, and
the strike price is $1.10. The interest rate is 6% per annum. The discount
factor for one time period is therefore e–0.06·1 = 0.9418.
Suppose we have simulated eight paths for the price of the underlying
stock. (In practice, we would simulate many more paths, but we want to
keep the example tractable.) The values for the stock price in each of the
paths are shown in Exhibit 14.2.
We begin at the last time period, t = 3. The cash ﬂows at expiration are
easy to compute (see Exhibit 14.3).
We next ﬁgure out which paths are in the money one period back (at
time 2). There are ﬁve of them: paths 1, 3, 4, 6, and 7. For those paths,
we compute the discounted values of the ﬁnal cash ﬂows, and use them as
the response variable Y in a regression. (For example, the Y variable in the
EXHIBIT 14.2
Eight simulated paths for the price
of the underlying stock.
Path
t = 0
t = 1
t = 2
t = 3
1
1.00
1.09
1.08
1.34
2
1.00
1.16
1.26
1.54
3
1.00
1.22
1.07
1.03
4
1.00
0.93
0.97
0.92
5
1.00
1.11
1.56
1.52
6
1.00
0.76
0.77
0.90
7
1.00
0.92
0.84
1.01
8
1.00
0.88
1.22
1.34

Pricing Derivatives by Simulation
561
EXHIBIT 14.3
Cash ﬂows at expiration.
Path
t = 0
t = 1
t = 2
t = 3
1
–
–
–
0.00
2
–
–
–
0.00
3
–
–
–
0.07
4
–
–
–
0.18
5
–
–
–
0.00
6
–
–
–
0.20
7
–
–
–
0.09
8
–
–
–
0.00
case of path 1 equals 0.00·0.9418.) The explanatory variables data in the
regression are given by a constant, the stock price in the corresponding path
at that time period, and the square of the stock price. Exhibit 14.4 contains
the regression input data.
The estimated regression equation from the data in Exhibit 14.4 is
Y = −1.070 + 2.983 · X −1.813 · X2
Using this regression equation, we compute the estimates for the ex-
pected value of continuing at time t = 2.26 For example, the approximate
expected value of continuing at time 2 for path 1 is
−1.070 + 2.983 · 1.08 −1.813 · 1.082 = 0.0369
EXHIBIT 14.4
Input data for the regression at time 2. Only
paths 1, 3, 4, 6, and 7 are considered because they are
in-the-money.
Regression Data at Time 2
Path
Y
Constant
X
X2
1
0.00*0.9418
1.00
1.08
1.17
2
–
–
–
–
3
0.07*0.9418
1.00
1.07
1.14
4
0.18*0.9418
1.00
0.97
0.94
5
–
–
–
–
6
0.20*0.9418
1.00
0.77
0.59
7
0.09*0.9418
1.00
0.84
0.71
8
–
–
–
–

562
DERIVATIVE PRICING AND USE
EXHIBIT 14.5
Value of continuing and exercising at time 2, optimal strategy at
time 2, and cash ﬂows for the eight simulated paths at time periods 2 and 3.
Cash Flow Matrix at
Time 2
Path
Exercise
Continue
Strategy?
t = 1
t = 2
t = 3
1
0.02
0.0369
Continue
–
0.00
0.00
2
–
–
–
–
0.00
0.00
3
0.03
0.0461
Continue
–
0.00
0.07
4
0.13
0.1176
Exercise
–
0.13
0.00
5
–
–
–
–
0.00
0.00
6
0.33
0.1520
Exercise
–
0.33
0.00
7
0.26
0.1565
Exercise
–
0.26
0.00
8
–
–
–
–
0.00
0.00
(We used the simulated stock price at time 2 for path 1, $1.08.) We can now
compare the intrinsic value of the option (the value of exercise at that time
period) with the expected value of continuing. The value of exercise is given
by max{K – S2(i),0}, that is, by 1.10 – S2(i) for the ﬁve paths of interest. The
results are presented in Exhibit 14.5. Exhibit 14.5 also shows the cash ﬂows
at time periods 2 and 3 based on the optimal strategy computed so far and
conditional on not exercising the option before time 2. Observe that if the
option is exercised at time 2, the cash ﬂow in the column for time 3 becomes
0. Once the option is exercised, there are no further cash ﬂows because the
option can be exercised only once. Note also that if the optimal strategy is
to continue at time period 2, the cash ﬂow is 0 (no immediate cash ﬂow is
realized), and the cash ﬂow in time period 3 is determined independently
based on whether it is optimal to exercise then or not. For example, for path
1, it is not optimal to exercise neither at time period 2, not at time period 3.
In both cases, the cash ﬂows are 0.
Now let us take a step back and consider time period 1. From the
simulated data in Exhibit 14.2, there are again ﬁve paths where the option
is in-the-money at time 1: 1, 4, 6, 7, and 8. For these paths, we create
the regression data matrix in Exhibit 14.6. The values for the response
variable Y are the discounted cash ﬂows from time period 2. Note that
we use the actual cash ﬂows (computed in the second table in Exhibit 14.5),
rather than the approximate expected values for Y computed for time period
2 (computed in the column with title Exercise in the ﬁrst table in Exhibit
14.5). This is because there can be only one stopping (exercise) time per
path.

Pricing Derivatives by Simulation
563
EXHIBIT 14.6
Input data matrix for the regression at time 1.
Regression Data at Time 3
Path
Y
Constant
X
X2
1
0.00*0.9418
1.00
1.09
1.19
2
–
–
–
–
3
–
–
–
–
4
0.13*0.9418
1.00
0.93
0.86
5
–
–
–
–
6
0.33*0.9418
1.00
0.76
0.58
7
0.26*0.9418
1.00
0.92
0.85
8
0.00*0.9418
1.00
0.88
0.77
The estimated regression equation from the data in Exhibit 14.6 is
Y = 2.038 −3.335 · X + 1.356 · X2
Again, using this regression equation, we compute the estimates for the
expected value of continuing at time t = 1. For example, the approximate
expected value of continuing at time 1 for path 1 is
2.038 −3.335 · 1.09 + 1.356 · 1.092 = 0.0139
(We used the simulated stock price at time 1 for path 1, $1.09.) We can
now compare the intrinsic value of the option with the expected value of
continuing. The results are presented in Exhibit 14.7. Exhibit 14.7 also
shows the cash ﬂows at time periods 1, 2, and 3 based on the optimal strategy
computed so far and conditional on not exercising the option before time 1.
The matrix of optimal stopping (exercise) times is given in Exhibit 14.8.
For paths 4, 6, 7, and 8, it is optimal to exercise the option at time 1. For
path 3, it is optimal to exercise at time 3.
Discounting all cash ﬂows in the second table in Exhibit 14.7 with the
appropriate discount factor and averaging over the eight sample paths, we
obtain
(0.07 · e−0.06·3 + 0.17 · e−0.06·1 + 0.34 · e−0.06·1 + 0.18 · e−0.06·1
+0.22 · e−0.06·1)/8 = 0.1144
This is the value of continuing at time 0. The intrinsic value of the option
at time 0 is 1.10 – 1.00 = 0.10, which is less than 0.1144. Therefore, 0.1144
is the fair value of the option.

564
DERIVATIVE PRICING AND USE
EXHIBIT 14.7
Value of continuing and exercising at time 1, optimal strategy at
time 1, and cash ﬂows for the eight simulated paths at time periods 1, 2, and 3.
Cash Flow Matrix at Time 1
Path
Exercise
Continue
Strategy?
t = 1
t = 2
t = 3
1
0.01
0.0139
Continue
0.00
0.00
0.00
2
–
–
–
0.00
0.00
0.00
3
–
–
–
0.00
0.00
0.07
4
0.17
0.1092
Exercise
0.17
0.00
0.00
5
–
–
–
0.00
0.00
0.00
6
0.34
0.2866
Exercise
0.34
0.00
0.00
7
0.18
0.1175
Exercise
0.18
0.00
0.00
8
0.22
0.1533
Exercise
0.22
0.00
0.00
Files Ch14-OptionPricingVBA.xlsm and AmericanPutLS.m contain
code for implementing the generalized algorithm with VBA and MATLAB,
respectively. See this chapter’s Software Hints for a detailed explanation of
the code. You may also want to modify the inputs to the programs to test
whether the results in the example presented in this section are correct and
to check how American put price estimates obtained with regression-based
methods compare with American put price estimates obtained with binomial
trees, as explained in section 13.4.3 of the previous chapter.
As we mentioned at the beginning of this section, simulation-based
methods for pricing derivatives with American features are most valuable in
situations in which multiple factors drive the price of the underlying. Such
situations often present themselves in ﬁxed income markets, where modeling
EXHIBIT 14.8
Optimal exercise times. (One denotes
optimal stopping time along each path.)
Path
t = 0
t = 1
t = 2
t = 3
1
0
0
0
0
2
0
0
0
0
3
0
0
0
1
4
0
1
0
0
5
0
0
0
0
6
0
1
0
0
7
0
1
0
0
8
0
1
0
0

Pricing Derivatives by Simulation
565
basic building blocks like the yield curve can require speciﬁcation of tens
of factors. The pricing of a swaption—a widely used type of derivative
in ﬁxed income markets—is one such application described in Longstaff
and Schwartz (2001). We discuss swaptions later in this section. For more
examples, see Longstaff and Schwartz (2001) and Glasserman (2004).
14.4.3
Evaluating Greeks
Measuring price sensitivities is an important aspect of trading and risk man-
agement. In fact, while prices of securities can be observed in the market,
and so new securities’ prices can be calibrated, sensitivities are not directly
observable, so one may argue that their estimation is even more important
than pricing applications.
Simulation is a valuable tool for producing estimates for the various
Greeks, but a few important issues that have to do with estimation bias and
tractability need to be kept in mind. In order to illustrate these issues, let us
discuss the estimation of the parameter () in the Black-Scholes setting.27
We will use f to denote the price of the ﬁnancial derivative in general, and
C to denote the price of a call option in the Black-Scholes setting in this
particular example.
By deﬁnition,
 = df
dS = lim
δS→0
f (S + δS) −f (S)
δS
This is called a forward-difference approximation because we are using
the difference between the current price and a price that is slightly higher than
the current price. The formula above suggests a quick-and-dirty approach
to estimating : Simulate sample paths, and estimate  as the mean of the
differences of the payoffs from an option with initial price equal to the
current stock price and an option with initial price equal to the current
stock price plus a “small” increment δS, divided by the increment δS.
This approach suffers from several problems. First, it is not very efﬁcient.
An immediate improvement that comes to mind is to use the same random
numbers for computing the paths for both f(S + δS) and f(S).28 This would
reduce the variability of the estimate.
Second, in statistical terms, we are using a biased estimator for . Recall
that the fair prices of the ﬁnancial derivatives can be viewed as the expected
values of the discounted payoffs. We are interested in estimating
lim
δS→0
E[pf (S + δS)] −E[pf (S)]
δS

566
DERIVATIVE PRICING AND USE
where pf is the discounted payoff. In fact, what we are estimating, however,
is
E
 pf (S + δS) −pf (S)
δS

At ﬁrst sight, the two expressions appear similar. However, in effect
we are exchanging the order of the limit and the expectation. This is not
generally allowed.
The quality of the estimator can be improved somewhat if we use central,
rather than forward, differences. In other words, we should be computing
pf (S + δS) −pf (S −δS)
2 · δS
The problem is that this involves many, many simulations. We need
to repeat the same computations three times—once for S + δS, once for
S – δS, and since we are typically also interested in pricing the option itself,
once for S.
So-called pathwise derivative estimates provide a solution to many of
the problems listed above. They differentiate each simulated outcome with
respect to the parameter of interest, such as the underlying stock price, and
produce unbiased estimates. The problem is that they use information about
the simulated stochastic process to produce exact calculations, and can only
be applied under speciﬁc circumstances. Fortunately, such estimators exist
for many important options. The Black-Scholes delta, for example, can be
determined in this way.
As we have noted several times, the price of a European call option in
the Black-Scholes setting C equals the discounted payoff
e−r·T · max{ST −K, 0}
where
ST = S0 e(r−1
2 σ 2)T+σ
√
T·˜ε
Using the chain rule of differentiation, we get
dC
dS0
= dC
dST
· dST
dS0

Pricing Derivatives by Simulation
567
To evaluate the ﬁrst factor in this product, we note that
d
dST
max{ST −K, 0} =
0,
ST < K
1,
ST > K
There is no derivative at ST = K, but we will ignore this because the
assumption that ST follows a continuous probability distribution means that
the probability that ST actually takes the value K is 0.29 Therefore,
dC
dST
= e−r·T · 1{ST > K}
where 1 (sometimes I) is standard notation for the indicator function. The
indicator function equals 1 over the set speciﬁed in the brackets that follow,
and 0 otherwise.
To evaluate the second factor, observe that ST is a linear function of S0.
(ST equals S0 multiplied by a number.) Therefore,
dST
dS0
= ST
S0
Putting everything together, we have the following estimator:
dC
dS0
= e−r·T · 1{ST > K} · ST
S0
The delta of the option is the average of these quantities computed over
all simulated paths for the stock option price. The expression above shows
that an estimate of  can be produced in the process of simulating the
price at maturity ST, which is very efﬁcient. The code for implementing this
approach, as well as the na¨ıve approach described at the beginning of this
section can be found in the Software Hints section for this chapter.
In the Black-Scholes setting, we had a closed-form formula for the option
price, which is rarely the case with more complex derivatives. Interestingly,
however, in some cases we may be able to obtain similarly convenient path-
wise estimators of the Greeks even when there is no closed-form formula for
the price of the ﬁnancial derivative. As we discussed in section 14.1.2, there
is no closed-form expression for the price of an arithmetic Asian option.
However, there is a formula for computing the delta of such an option in
closed form when the price of the underlying asset is assumed to follow a

568
DERIVATIVE PRICING AND USE
geometric random walk. It is
dCA
dS0
= e−r·T · I{ ¯S > K} ·
¯S
S0
30
where ¯S is the average price over the life of the option. The latter is a quantity
that is easy to track during the simulation, so estimating the sensitivity of
the option with respect to the initial price comes at virtually no additional
computational cost.
14.4.4
Examples of Pricing Interest
Rate Derivatives
In this section, we introduce brieﬂy two popular interest rate derivatives:
interest rate caps and swaptions, and we discuss how simulation can be
useful in modeling their price.
Interest Rate Caps
An interest rate cap is a portfolio of options that limits
the interest paid on a ﬂoating rate note over a set of consecutive payment
(reset) dates. Suppose that cap resets every three months. The interest rate
paid for the ﬁrst three months is the three-month LIBOR rate observed at
time 0; the interest rate paid for the second three months is the three-month
LIBOR observed at the ﬁrst payment date (at three months), and so on.
If the cap rate has been set to, say, 5%, and the three-month LIBOR at a
particular date is greater, then only 5% (appropriately scaled for the time
between payments) will be paid by the ﬂoating rate note, thus resulting in a
positive payoff to the issuer of the ﬂoating rate note.
Each individual option is referred to as a caplet, and can be valued
separately. The value of the cap is the sum of the values of the individual
caplets. Let c be the cap rate, t be the time between reset dates, rt be the
interest rate for the period between reset dates t and t + 1, and the value of
the principal be L. At time t + 1, the payoff to the ﬂoating rate issues is
L · (t) · max{rt −c, 0}
Thus, a caplet is a call option on the LIBOR rate observed at time t. (By
convention, the payoff occurs at time t + 1.)
To price the caplet, we need to make an assumption about the movement
of the interest rate rt. There are a number of interest rate models that we can
use, such as the Vasicek model, or the Cox-Ingersoll-Ross (CIR) model.32
In some cases (e.g., if we assume that the interest rate follows a geometric

Pricing Derivatives by Simulation
569
random walk), we can derive a closed-form formula for the price of the
caplet.33 When this is not possible, we can value the option by simulation in
much the same way in which we valued European options on stocks earlier
in this chapter.
Swaptions
Swaptions are a widely used type of interest rate derivative.
There are two types of swaptions—a payer swaption and a receiver swap-
tion. A payer swaption entitles the option buyer to enter into an interest
rate swap in which the buyer of the option pays a ﬁxed rate and receives a
ﬂoating rate. In a receiver swaption, the buyer of the swaption has the right
to enter into an interest-rate swap that requires paying a ﬂoating rate and
receiving a ﬁxed rate.
Consider a receiver swaption with notional of 1 that consists of an
option (expiring at time To) to enter into a swap with payment dates (To +
1), (To + 2), . . . , Ts. Following the notation and the discussion in section
13.5, we know that the value of the underlying swap at time To to the option
holder is
ν · (t) ·
Ts

t=To+1
B(To, t) + 1 · B(To, Ts) −1
The holder of the option will exercise if this value is greater than 0, and
let the option expire of the value is negative.
The value of the swap at time To can be written as
(t) ·
Ts

t=To+1
B(To, t) · max{ν −ν(To + 1), 0}
where ν(To+1) is the fair value of the swap rate for a swap starting at time
To+1.34 Hence, the swaption can be viewed as an option on the swap rate.
In order to price a swaption, we therefore need to model the dynamics of
the process followed by the swap rate.
Pricing a swaption becomes more complicated if the option to enter into
a swap is American. As we mentioned at the end of section 4.2, regression-
based methods for pricing American options can be very helpful in this
situation. Longstaff and Schwartz (2001) describe one such application.
They consider a receiver swaption such that the option holder has the right
to enter into a swap in which the option holder receives ﬁxed coupons and
pays ﬂoating coupons on a semiannual cycle. The ﬂoating coupon paid at
the end of the semiannual cycle is tied to the six-month rate determined

570
DERIVATIVE PRICING AND USE
at the beginning of the semiannual cycle. The time to maturity is 10 years,
that is, there are 20 coupon payments. Since the underlying swap makes
coupon payments at 20 different points in time, its value is sensitive to
20 different points along the yield curve. Longstaff and Schwartz (2001)
consider each of these 20 points a separate but correlated factor, and model
the joint dynamics of the 20 factors. These factors can be represented, for
example, as the prices of zero-coupon bonds that mature at each of the 20
coupon payment dates. The simulation then consists of paths for which at
each coupon date, the entire vector of zero-coupon bond prices is speciﬁed.
The value of the underlying swap at that coupon date can be computed by
discounting the remaining ﬁxed coupon payments. The basis functions could
consist of a constant, the ﬁrst three powers of the value of the underlying
swap, and all unmatured discount bond prices with ﬁnal maturity dates up
to and including the ﬁnal maturity date of the swap, a total of 22 basis
functions.
SUMMARY
■Crude Monte Carlo simulation methods involve most straightforward
application of simulation for pricing derivatives: generating paths for
the price of the underlying asset, and evaluating the average of the
resulting discounted payoffs from the derivative. While not always the
most efﬁcient methods, they are intuitive and easy to apply.
■Various variance reduction methods exist to speed up the simulation
and reduce the variance of the estimate. Such methods include using an-
tithetic variables, stratiﬁed sampling, importance sampling, and control
variates.
■The idea behind using antithetic variables is to generate one set of ran-
dom numbers which can then be used twice in the estimation in a smart
way. A set of “antithetic” numbers is created out of the originally gen-
erated set of random numbers, and paths for the underlying asset price
are computed with both sets of random numbers. This information is
then used in the calculation of the ﬁnal derivative price. Since generat-
ing random numbers is computationally intensive, this method reduces
both the computational time (by “reusing” already generated random
numbers) and the variance of the estimate (by incorporating two sets of
random numbers that are hopefully negatively correlated).
■Stratiﬁed sampling creates a representative sample of the entire range
of outcomes by dividing the unit interval into pieces, called strata, and
sampling within each stratum.

Pricing Derivatives by Simulation
571
■Importance sampling changes the underlying scenario probabilities so as
to give more weight to important outcomes in the simulation. Such out-
comes are generated with greater frequency than they otherwise would.
At the end, the observations’ weights are scaled back in the computation
of the expression of interest, so that the estimation is correct.
■The control variates method uses knowledge about a function that is
related somehow to the original function we are trying to estimate by
simulation. In the context of derivative pricing, the control variates
method attempts to ﬁnd the expected value of the discounted payoffs of a
derivative for which no analytical formula is known by using knowledge
about an expected value of a related variable that is known.
■Quasirandom, or quasi–Monte Carlo methods can be thought of as an
extreme version of stratiﬁcation methods. They rely on number theory
to produce sequences of numbers (called low-discrepancy sequences)
that do not pretend to be random, but instead cover the unit interval
in a uniform way, so that every part of the probability distribution is
represented when simulating.
■Widely used quasirandom sequences include the Van der Corput se-
quence, the Halton sequence, the Faure sequence, and the Sobol se-
quence. Some sequences work better than others for pricing speciﬁc
derivatives, but there is no comprehensive way to determine that in ad-
vance without testing. For simulations in up to 15 dimensions (that is,
simulations of up to 15 random variables at the same time), the choice
of a quasirandom sequence does not make a big difference.
■Simulation is a ﬂexible technique for determining the prices of complex
derivatives for which no closed-form formulas exist. It can be used,
for example, for pricing exotic options such as Asian and barrier op-
tions, pricing American options and interest rate derivatives, as well as
evaluating sensitivities of derivative prices with respect to a variable of
interest.
SOFTWARE HINTS
@RISK
The pricing of some of the simpler derivatives by simulation can be done
directly in an Excel spreadsheet. We show here the examples of pricing a
call option in the Black-Scholes setting and pricing an arithmetic Asian op-
tion when the price of the underlying asset is assumed to follow a geomet-
ric random walk. The more complicated algorithms explained in sections

572
DERIVATIVE PRICING AND USE
EXHIBIT 14.9
Worksheet B-S Sim in the ﬁle Ch14-PricingBySimulation.xlsx.
14.4.2 through 14.4.4 of this chapter are implemented using VBA in the
next section.
Pricing a European Call Option
Worksheet B-S Sim in the ﬁle Ch14-
PricingBySimulation.xlsx contains a simple illustration of the assumptions
underlying the Black-Scholes option pricing formula (see section 14.1.1). A
snapshot of the spreadsheet is shown in Exhibit 14.9.
Cells B3:B8 contain the input data—initial price, strike price, time to
expiration, interest rate, volatility, and dividend yield. In cell B10, we simu-
late the price of the underlying stock at expiration. It contains the formula
=B3*EXP((B6-0.5*B7ˆ2)*B5+B7*SQRT(B5)*RiskNormal(0,1))
Cell B11 is an output cell for @RISK: it computes the discounted payoff
for the call from the simulation of the stock price at maturity, and contains
the formula
=RiskOutput("Discounted payoff (call)")+EXP(-B6*B5)*MAX(B10-
B4,0)

Pricing Derivatives by Simulation
573
Similarly, cell B12 computes the discounted payoff for the put from the
simulation of the stock price at maturity, and contains the formula
=RiskOutput("Discounted payoff (put)")+EXP(-B6*B5)*MAX(B4-
B10,0)
Cells B15 and E15 compute the fair price of the call (respectively, the
put), and contain the formulas =RiskMean(B11) and =RiskMean(B12),
respectively. The RiskMean command is a shortcut to recording the average
realized in the simulation. Alternatively, we can simply look at the output
from the simulation (output cells B11 and B12), and make a note of the
realized mean.
Pricing an Asian Call Option
Suppose now that we have an arithmetic
Asian option with the parameters speciﬁed in cells B3:B8 in worksheet Asian
Sim of the ﬁle Ch14-PricingBySimulation.xlsx (see Exhibit 14.10). The time
to maturity is still 0.5 years, and we need to keep track of the average
realized price of the option during the simulation. We simulate paths for the
price of the underlying stock price. The larger the number of intermediate
time periods, the better. For illustration purposes, we choose to record the
value of the underlying price 12 times over the life of the option, that is,
approximately every two weeks. The simulated values for the stock price
are in cells F4:F15. For example, cell F4 contains the formula
=F3*EXP(($B$6-0.5*$B$7ˆ2)*$B$5/12+$B$7*SQRT($B$5/12)
*RiskNormal(0,1))
EXHIBIT 14.10
Worksheet Asian Sim in the ﬁle Ch14-PricingBySimulation.xlsm.

574
DERIVATIVE PRICING AND USE
Note that the time parameter in the above formula is $B$5/12 (i.e.,
0.5/12) because we are simulating each of the 12 steps of the geometric
random walk for the stock price between the initial time and maturity. The
drift and the volatility parameter therefore get adjusted.
The average realized stock price over the 12 steps is recorded in cell H4,
which contains the formula =AVERAGE(F4:F15). The discounted payoff for
the call and the put are recorded in cells B10 and B11, respectively. For
example, cell B10 contains the formula
=RiskOutput("Discounted payoff (call)")+EXP(-B6*B5)
*MAX(H4-B4,0)
Cells B13 and B14 compute the fair arithmetic Asian option price using
the @RISK formula RiskMean.
Visual Basic
The VBA code for the different option pricing models presented in this
section is in the ﬁle Ch14-OptionPricingVBA.xlsm. In many of these models,
we generate the paths for the underlying assuming a geometric random walk.
The code for generating geometric random walk paths in VBA is similar to
the code for generating geometric random walk paths in MATLAB from
the Software Hints section in Chapter 12. It can be found in the function
GRWPaths in the ﬁle Ch14-OptionPricingVBA.xlsm. When the underlying
stock pays a continuous dividend yield (denoted by q in the code), we use
the same function GRWPaths to generate paths, but we pass the interest rate
minus the dividend rate as an argument in place of r. (In other words, we
reduce the growth rate by the amount of the continuous dividend.)
Pricing a European Call Option Using Crude Monte Carlo
The code for a
function that returns the price of a European call option given a number of
geometric random walk paths numPaths for the underlying is in the function
EuropeanCall (see section 14.1.1).
Pricing an Asian Call Option with Crude Monte Carlo
The code for gener-
ating the Asian call option price with crude Monte Carlo is in the function
ArithmeticAsianCall (see section 14.1.2).
Pricing a European Call Option with Antithetic Variables
The code for
ﬁnding the value of a European call option is in the function Euro-
peanCallAntithetic. We create two arrays with payoffs, payoffsOrig
(obtained with the originally generated random numbers stored in array

Pricing Derivatives by Simulation
575
randNumOrig), and payoffsAnt (obtained with the antithetic variables
stored in array randNumAnt). The payoffs we consider for the pricing of
the option are the averages of payoffsOrig and payoffsAnt (see sec-
tion 14.2.1).
Pricing an Asian Call Option with the Control Variates Method
The code
for ﬁnding the value of a geometric average Asian call option is in the
function GeometricAsianCall (see section 14.2.4.)
To use the control variates method, we need to estimate the value of the
coefﬁcient b. The ﬁrst part of the code does that—it runs Np (numPrelim)
preliminary trials, and uses the observations to estimate b. The second part of
the code estimates the actual value of the arithmetic Asian call option with
the control variates method. To simulate paths for the underlying stock,
we assume that the stock follows a geometric random walk, and use the
GRWPaths function.
The function uses the user-deﬁned functions MeanSub and ProdSub,
which ﬁnd the sum and the product of a subarray. The code for the functions
is provided earlier in the same module.
The code for comparing the performance of the simulation algorithm
for evaluating the Asian option price with and without the control variates
method is provided in the function ArithmeticAsianCallEstimation-
Comparison.
Constructing a Van der Corput Quasirandom Sequence
The code for con-
structing N points from a Van der Corput sequence of base b is in the
function VanDerCorput (see section 14.3.1).
The vector array vVec stores the values of the points in the sequence.
For a given index (which varies from 1 to the total number of points to
be calculated), the Do While loop creates the point in the Van der Corput
sequence by effectively computing the representation of the index in base b,
and then inverting that representation.
Constructing a Halton Quasirandom Sequence
The code in the Halton
function generates the ﬁrst K points from a Halton sequence of dimension
d (see section 14.3.2). If we are given a dimension d, we need to generate
d prime numbers. The function Primes ﬁnds all prime numbers up to a
given number d. A well-known fact from number theory is that there are
approximately d/ln(d) prime numbers that are less than or equal to d. The
dth prime number should be approximately d·ln(d). This is not an exact
approximation—for some values of d, it will be quite accurate; for others,
not. So, to make sure that we generate at least d prime numbers to use in the
Halton function, we will take at least double the number. The rest of the

576
DERIVATIVE PRICING AND USE
Halton function code calls the function for computing a Van der Corput
sequence in each dimension.
Computing the Price of a European Call Option with the Halton Sequence
The function EuropeanCallHalton illustrates how to calculate the price of
a European call option with the Halton sequences. (See section 14.3.5.) We
use the function Halton(N,d), which we introduced in the previous section.
Pricing a Down-and-Out Put Option with Crude Monte Carlo
The code for
ﬁnding the value of a down-and-out put is in the function DownAndOutPut.
(See section 14.4.1.)
In the code of the DownAndOutPut function, we check whether any
of the elements in the path array generated as a geometric random walk
path is less than or equal to the barrier Sb. If it is, then the value of the
variable crossedPaths for that path will be 1; otherwise, it will be 0. If the
barrier has been crossed on a particular path, we consider the payoff on that
path; otherwise, the payoff is set to zero. We then take the average of the
discounted payoffs along all paths.
Pricing an American Put Option with Regression Methods
The general-
ized code for computing the price of an American put option with least-
squares (regression) methods is in the AmericanPutLS function. (See also
section 14.4.2.)
There are several challenges of implementing this code in VBA compared
to more advanced modeling languages like MATLAB. First, in contrast
to MATLAB, one cannot pass function references as an input to a VBA
function, so the three functions used to create the regression matrix were
hard-coded in a separate function, AmericanPutLSFn.
Second, it is in general difﬁcult to take advantage of other Excel add-ins
from within VBA. In the American put option pricing example, we need to
run a regression and estimate the regression coefﬁcients. There are two ways
to run regressions in Excel: through the Analysis ToolPak (under the Data
tab) and through the linest function. Both of these options are problematic
to use from within VBA. The regression function in the Analysis ToolPak
requires writing data into the actual spreadsheet, which can be done from
within a VBA script (starting with a Sub), but not from a function call
(a script that starts with Function) such as our American option pricing
function. The linest function behaves erratically when called with speciﬁc
options (such as when we request that an intercept term is not included
in the regression), and more frustratingly, it does not alert the user that
the estimates are wrong, so it needs to be handled with care. While we
provide working code below, we alert the reader that in order to work

Pricing Derivatives by Simulation
577
around the bug with the linest function, we need to assume that there
will always be a constant term in the regression. This part of the code can
be ﬁxed when the linest function in Excel is ﬁxed. While VBA can get
the job done for small tasks, the American option pricing model with least
squares requires complex enough calculations that illustrate the advantage
of integrated modeling environments like MATLAB.
To test the AmericanPutLS function, you can enter the data for the
eight generated paths from section 14.4.2, and verify that the option price
is indeed $0.1144.
Evaluating a European Call Option Delta with Na¨ıve Monte Carlo and a
Pathwise Method
The function EuropeanCallDeltaMC contains the code
for calculating the delta of a European call in the Black-Scholes setting
with crude Monte Carlo, central differences, and blocking. (The same set
of random numbers, randomNumbers, are used for computing both the call
price with starting price S0 + δS0 and S0 – δS0.) See section 14.4.3 for a
description of the method.
The function EuropeanCallDeltaPW contains the code for calculating
the delta of a European call in the Black-Scholes setting with the pathwise
method described in section 14.4.3.
MATLAB
Pricing a European Call Option Using Crude Monte Carlo
The code for a
function that returns the price of a European call option given a number of
geometric random walk paths numPaths for the underlying is in the function
EuropeanCall. (See section 14.1.1 and ﬁle EuropeanCall.m.)
Pricing an Asian Call Option with Crude Monte Carlo
The code for gen-
erating the Asian call option price with crude Monte Carlo is in the func-
tion ArithmeticAsianCall. (See section 14.1.2. and ﬁle ArithmeticAsian-
Call.m.)
Pricing a European Call Option with Antithetic Variables
The code for
ﬁnding the value of a European call option is in the function European-
CallAntithetic. We create two arrays with payoffs, payoffsOrig (ob-
tained with the originally generated random numbers stored in array rand-
NumOrig), and payoffsAnt (obtained with the antithetic variables stored
in array randNumAnt). The payoffs we consider for the pricing of the option
are the averages of payoffsOrig and payoffsAnt. See section 14.2.1 and
ﬁle EuropeanCallAntithetic.m.

578
DERIVATIVE PRICING AND USE
Pricing an Asian Call Option with the Control Variates Method
The code
for ﬁnding the value of a geometric average Asian call option is in the
function GeometricAsianCall (see section 14.2.4 and ﬁle GeometricAs-
ianCall.m).
To use the control variates method, we need to estimate the value of
the coefﬁcient b. The ﬁrst part of the code below does that—it runs N p
preliminary trials, and uses the observations to estimate b. The second part
of the code estimates the actual value of the arithmetic Asian call option
with the control variates method. To simulate paths for the underlying
stock, we assume that the stock follows a geometric random walk, and
use the GRWPaths function we wrote in Chapter 12. The code is in ﬁle
ArithmeticAsianCallCV.m.
The code for comparing the performance of the simulation al-
gorithm for evaluating the Asian option price with and without the
control variates method is provided in the ﬁle ArithmeticAsianCall-
EstimationComparison.m).35
Constructing a Van der Corput Quasirandom Sequence
The code for con-
structing N points from a Van der Corput sequence of base b is provided in
the function VanDerCorput (see section 14.3.1 and ﬁle VanDerCorput.m).
The vector array vVec stores the values of the points in the sequence.
For a given index (which varies from 1 to the total number of points to be
calculated), the while loop creates the point in the Van der Corput sequence
by effectively computing the representation of the index in base b, and then
inverting that representation.
Constructing a Halton Quasirandom Sequence
MATLAB’s Statistics Tool-
box contains built-in syntax for computing the elements of a Halton se-
quence. The function haltonset(d) computes the sequence of dimension
d, and the sequence can be retrieved with the command net. For example,
>> seq = haltonset(3); net(seq,5)
returns the ﬁrst ﬁve elements of a Halton sequence of dimension 3.
Nevertheless, it is instructive to see a program that generates the ﬁrst K
points from a Halton sequence of dimension d (see section 14.3.2 and ﬁle
Halton.m). If we are given a dimension d, we need to generate d prime num-
bers. In MATLAB, a function that generates all prime numbers less than or
equal to d is primes (d). However, there is no function that returns d prime
numbers. So, we need to approximate. A well-known fact from number the-
ory is that there are approximately d/ln(d) prime numbers that are less than
or equal to d. The dth prime number should be approximately d/ln(d). This is
not an exact approximation—for some values of d, it will be quite accurate;

Pricing Derivatives by Simulation
579
for others, not. So, to make sure that we generate at least d prime numbers,
we double the number, and use the command primes(2·d·max(1,log(d)).
The rest of the code calls the function for computing a Van der Corput
sequence in each dimension.
Constructing a Sobol Quasirandom Sequence
MATLAB’s Statistics Tool-
box contains built-in syntax for computing the elements of a Sobol sequence
(see section 14.3.4). The function sobolset(d) computes the sequence of
dimension d, and the sequence can be retrieved with the command net. For
example,
>> seq = sobolset(3); net(seq,5)
returns the ﬁrst ﬁve elements of a Sobol sequence of dimension 3.
Computing the Price of a European Call Option with the Halton or the
Sobol Sequence
The following two functions illustrate how to calculate
the price of a European call option with the Halton and the Sobol sequences
(see section 14.3.5). In the case of the Halton sequence, we use the func-
tion Halton(N,d), which we introduced earlier. In the case of the Sobol
sequence, we use the function sobolset in MATLAB’s Statistics Toolbox.
Note that the Halton sequence implementation can also be done directly by
using the function haltonset in MATLAB’s Statistics Toolbox. We offer
two different implementations for illustration purposes.
The code for pricing a European call option using a Halton sequence is
in ﬁle EuropeanCallHalton.m.
In this function, we use a nice feature in MATLAB, which is that we
can pass an array (HaltonPoints) into a formula (initPrice*exp((r-
q-0.5*sigmaˆ2)*T + sigma*sqrt(T)*norminv(HaltonPoints))), and
MATLAB automatically creates an array with results (assetPrices). In
other programming languages, we would need to implement this by creating
a for loop.
The code for pricing a European call option using a Sobol sequence is
in the ﬁle EuropeanCallSobol.m. Here we generate the Sobol sequence of
dimension 1 and length N+1 with the commands
seq = sobolset(1);
SobolPoints = net(seq,numPaths+1);
and remove the ﬁrst element, which is 0, with the command
SobolPoints = SobolPoints(2:numPaths+1);

580
DERIVATIVE PRICING AND USE
It is common to drop some number of elements of quasirandom se-
quences, so that we can use directly scenarios that represent the unit interval
well. As Exhibit 14.1 illustrated, it takes a certain “warming up” for the
quasirandom sequence to begin producing stable and accurate estimates.
Pricing a Down-and-Out Put Option with Crude Monte Carlo
The code for
ﬁnding the value of a down-and-out put is in the function DownAndOutPut
(see section 14.4.1 and ﬁle DownAndOutPut.m).
In the code of the DownAndOutPut function, we use the MATLAB func-
tion any. It returns one (“True”) if the condition in the parentheses is satis-
ﬁed, and 0 otherwise. In this example, it checks whether any of the elements
in the path array generated as a geometric random walk path is less than
or equal to the barrier Sb. If it is, then the expression path <= Sb is true,
and value of the variable crossedPaths for that path will be 1; otherwise,
it will be 0.
Pricing an American Put Option with Regression Methods
File American-
PutLS.m contains generalized code for computing the price of an American
put option with least-squares (regression) methods (see also section 14.4.2).
Let us brieﬂy explain the idea behind the algorithm, as well as some new
MATLAB syntax.
We begin by computing the discount factors for every time period. We
create a vector, discountFactors, which has as many elements as there are
time periods. The ﬁrst element in the vector contains the discount factor for
one time period (it will be used to discount the cash ﬂows for the second-to-
last time period), the next element contains the discount factor for two time
periods (it will be used to discount the cash ﬂows for the third-to-last time
period), and the like.
Next, we handle the basis functions that are passed as arguments to
the function through the expression fhandles (function handles). Function
handles are a way in MATLAB to call functions indirectly. In our case, we
need a way to state the functions of the stock price that will be used in the
regression as an argument of the function AmericanPutLS. This needs to be
done symbolically. So, if the basis functions of the stock price are a constant,
S, and S2, the argument fhandles to the function AmericanPutLS will have
the following form:
{@(x)ones(length(x),1),@(x)x,@(x)x.ˆ2}
The interpretation is as follows: there are three functions, each of them
is a function of a single variable (x), and when an argument is passed to the

Pricing Derivatives by Simulation
581
function handles (which is what the @ signs mean), the following operations
will be performed:
1. The ﬁrst function (called with fhandle{1}) will take the argument that
is passed to it and will create a vector of ones of length equal to that
argument.
2. The second function (called with fhandle{2}) will take the argument
that is passed to it and return that argument.
3. The third function (called with fhandle{3}) will take the argument that
is passed to it and return the square of that argument.
We use these function handles later, when we iterate through the data
at each time period, and compute each column of the regression matrix by
calling the corresponding basis function. To execute a function in the body
of the program, we can use one of two methods. The ﬁrst is to call the
function handle directly with an argument. For example, the command
>fhandles{3}(5)
will return 25, which is the square of the argument 5. (fhandles{3} calls
the third element of the structure of function handles, which is the function
computing the square of a number.)
Alternatively, we can execute a function that is an element of the array
fhandles by using the command feval. The command
>>feval(fhandles{3},5)
will produce the same result: 25. In the program, we evaluate the function for
the array XData, which contains the values of the stock prices at a particular
time period. By evaluating calling each element of the array fhandles on
XData, we create the columns of the regression data matrix.
The parameter numBasisFns stores the number of basis functions we
consider. (We use that parameter when we specify the number of columns
of data in the regression matrix as well.)
We also have a vector cashFlows, which stores the intrinsic value (in the
case of an American put option, this is the maximum of the strike price minus
the current price and 0) along every path at a particular point in time. (We
work backwards, so that the initial cashFlows vector is simply the intrinsic
value of the option at the ﬁnal time period, assuming the option has not
been exercised until then. At the second-to-last period, we store the intrinsic
value for those paths for which the intrinsic value is greater than the value
of continuing (that is, the paths for which it is optimal to exercise the option

582
DERIVATIVE PRICING AND USE
at that time)). MATLAB’s syntax is quite convenient—referencing only of
the cash ﬂows for which it is optimal to exercise the option is accomplished
with the expression cashFlows(exercisePaths).
The vector inMoneyPathIndices stores the indices of the paths which
are in the money at the current time period (iStep). These are the sample
paths that get used in the regression to determine a function (only of the
current time period) that approximates the value of continuing. We run the
regression with a response variable (YData) that contains the cash ﬂows from
the previous step, discounted properly. The explanatory variables (stored in
the array regressionMx) are a constant, a vector of current prices, and a
vector of current prices squared. To determine the regression coefﬁcients,
we use a new (very useful) syntax,
betaCoefficients = regressionMx\YData
This is sort of a “division” of two matrices—basically since
YData = betaCoefficients*regressionMx
this command is an efﬁcient way to determine the regression coefﬁcients.
The same result can be obtained with the command
[betaCoefficients,nn,nn,nn,nn]= regress(YData,regressionMx)36
but the latter command requires MATLAB’s Statistics Toolbox.
At the end of the loop, we discount the cash ﬂows from the last step
in the for loop (the ﬁrst time period since we are working backwards) to
the present depending on when the option was exercised along a particular
simulated path. If the option was never exercised, then the exercise time
was never modiﬁed from its initial value (the last time period), and so use
a discount factor for the entire duration of the option (the discount factor
does not matter because if the option was not exercised, the payoff along
that path will be zero anyway).
Finally, at time 0 we compare the intrinsic value of the option with the
value of continuing (which is the mean of the discounted payoffs along all
the sampled paths) to determine whether we should exercise the option at
time 0. The maximum of the intrinsic value and the value of continuing
equals the value of the option.
You can verify that the code works by testing the simple example de-
scribed in section 14.4.2. Instead of generating paths for a stock price that
follows a geometric random walk, enter the data for the eight simulated
paths directly into the function, and print out intermediate results (or step

Pricing Derivatives by Simulation
583
through the function using the debugger) to see whether you obtain the cash
ﬂows, the exercise times, the regression equations, and the ﬁnal option price
described in the example.
Evaluating a European Call Option Delta with Na¨ıve Monte Carlo and a
Pathwise Method
File EuropeanCallDeltaMC.m contains the code for cal-
culating the delta of a European call in the Black-Scholes setting with crude
Monte Carlo, central differences, and blocking. (The same set of random
numbers, randomNumbers, are used for computing both the call price with
starting price S0 + δS0 and S0 – δS0.) See section 14.4.3 for a description of
the method.
File EuropeanCallDeltaPW.m contains the code for calculating the delta
of a European call in the Black-Scholes setting with the pathwise method
described in section 14.4.3.
You can verify that the pathwise estimator method above produces
much more accurate estimates for the option delta than the crude Monte
Carlo method. To see this, compare the results from using the two functions
in this section to the results obtained with MATLAB’s built-in function
blsdelta.37
NOTES
1. See Chapter 12 for an introduction to different types of random walks.
2. See Black and Scholes (1973).
3. See Chapter 12, Sections 3 and 6.
4. If the stock pays a continuously compounded dividend yield of q, then we use
(r – q – 0.5·σ2) instead of (r – 0.5·σ2) as the drift term.
5. See Chapter 2 for a deﬁnition of term structure of interest rates.
6. See Chapter 13 for a deﬁnition of forward price.
7. Recall that the geometric average would be computed as (S1 · . . . · ST)1/T.
8. See the example in section 14.2.4.
9. See section 4.3 of Chapter 4 for a discussion of estimator efﬁciency and bias.
10. Recall that this function can be called with the command =NORMINV(number,
mean, standard deviation) in Excel, or norminv(number, mean,
standard deviation) in MATLAB. In the case of the standard normal
distribution, mean = 0 and standard deviation = 1.
11. The formula for –1 can be entered as =NORMINV((n−1+Un)/N,0,1) in
Excel or norminv((n−1+ Un)/N,0,1) in MATLAB. The subscripts are, of
course, not entered: Un represents the value for the nth simulated number from
the uniform distribution.
12. See section 13.1.2 of Chapter 13 for a deﬁnition of in-the-money and out-of-
the-money options.

584
DERIVATIVE PRICING AND USE
13. See section 3.6.1 of Chapter 3 for the deﬁnition of expected value as an integral
over all values the random variable can take.
14. See section 3.6.2 of Chapter 3.
15. See Chapter 3.
16. See section 3.6.1 of Chapter 3.
17. The base is essentially how many digits are used to express a number. The
conventional way to work with numbers is in base 10—it derives from the fact
that humans have 10 ﬁngers, and the earliest counting systems were often based
on that fact. We use 10 digits—0,1,2,3,4,5,6,7,8,9 to express every number in
base 10. Nothing prevents us, however, from working with numbers in different
bases. The idea is to express the number as a sum of powers of the base. For
example, the number 13 in base 10 can be written as 13 = 1 · 101 + 3 · 100.
The same number, 13, in base 2 will contain only two digits—0 and 1—and
will be expressed as 1101: 1 · 23 + 1 · 22 + 0 · 21 + 1 · 20.
18. Here we have used several standard notations. The expression a mod b returns
the remainder of a after division with b, that is, the amount by which a exceeds
the largest multiple of b that is less than a. The notation
 j
k

(read “j choose k”) returns a number that equals the number of ways in which k
items can be selected out of j items. As we saw in the context of pricing options
with binomial trees, it equals
j!
k!( j −k)!
if j ≥k, and 0 otherwise. As we explained earlier in the book, the expression j!
(read “j factorial”) equals the product 1·2·. . .·j. If j = 0, j! = 1 by convention.
19. When the option holder has the right to exercise the option contract at speciﬁc
preset dates, the options are referred to as Bermudan options or Mid-Atlantic
options since their features are somewhere between European and American
option features.
20. See, for example, Hull (2008).
21. See, for example, Brandimarte (2006).
22. For a nice overview, see Glasserman (2004).
23. Recall that the value function measures of the expected reward going forward
from the current state. See the introduction to dynamic programming in sec-
tion 6.1 in Chapter 6, and the introduction to American option pricing with
binomial trees in Chapter 13.
24. Readers may wonder why we do not do this to estimate the value of the option
to begin with. Note that assuming perfect vision means that you can anticipate
what happens in the future when you make the decision of whether to exercise or
not today. In practice, we do not have that knowledge, so it would be incorrect
to assume that we can use the knowledge to compute the optimal price of the
option.

Pricing Derivatives by Simulation
585
25. See Longstaff and Schwartz (2001).
26. Typically, we would care about the validity of the regression equation, and
pay attention to the signiﬁcance of the regression coefﬁcients as well as to
multicollinearity issues (that is, whether the explanatory variables are corre-
lated among themselves, which would produce poor estimates of the regression
coefﬁcients). However, in this application we use the regression equation for
forecasting purposes, so we are concerned with the model as a whole, and not
with the signiﬁcance of the individual explanatory variables.
27. See section 13.4.4 of Chapter 13 for a deﬁnition of delta.
28. See section 4.2.3 of Chapter 4 for a justiﬁcation for this approach.
29. See section 3.4 of Chapter 3.
30. See section 7.2 of Chapter 7 in Glasserman (2004).
31. See Chapter 2 for a deﬁnition of term structure.
32. See section 12.4.3.
33. See Hull (2008).
34. This can be derived with some simple algebra following the arguments in section
13.5; see also Appendix C in Glasserman (2004).
35. Make sure that you comment out the figure and plot command from the
ﬁle GRWPaths.m before you run this code, so that you do not overwhelm the
memory with thousands of ﬁgures for every generated geometric random walk
path.
36. Recall that we used the command in the code for estimating random walk
parameters in Chapter 12.
37. The MATLAB function blsdelta requires the Financial Toolbox.


CHAPTER15
Structuring and
Pricing Residential
Mortgage-Backed Securities
C
hapter 2 brieﬂy introduced the different types of ﬁxed income securities
such as bonds, asset-backed securities (ABSs), and bank loans. This chap-
ter deals with the valuation of speciﬁc types of ABSs, which is challenging
both from a theoretical and from an implementation point of view: residen-
tial mortgage-backed securities. As shown in this chapter, simulation and
dynamic programming are valuable tools for handling the structuring and
pricing of this type of ABS.
We begin with a detailed account ABS types and important terminology.
Then we proceed with deﬁning concepts relevant for pricing these securi-
ties, such as prepayment models. We conclude with a discussion of how
simulation and dynamic programming are applied in this context.
15.1
TYPES OF ASSET-BACKED SECURITIES
Asset-backed securities are debt instruments that are backed by a pool of
loans or receivables. They are also referred to as structured products. The
process for creating ABSs, referred to as securitization, is as follows. The
owner of assets sells a pool of assets to a bankruptcy remote vehicle called
a special purpose entity (SPE). The SPE obtains the proceeds to acquire the
asset pool, referred to as the collateral, by issuing debt instruments. The
cash ﬂow of the asset pool is used to satisfy the obligations of the debt
instruments issued by the SPE. The debt instruments issued by the SPE are
generically referred to as asset-backed securities, asset-backed notes, asset-
backed bonds, and asset-backed obligations.
ABSs issued in a single securitization can have different credit exposure.
Based on the credit priority, securities are described as senior notes and
587

588
DERIVATIVE PRICING AND USE
junior notes (subordinate notes). In the prospectus for a securitization trans-
action, the securities are actually referred to as certiﬁcates: pass-through
certiﬁcates or pay-through certiﬁcates. The distinction between these two
types is the nature of the claim that the investor has on the cash ﬂow gen-
erated by the asset pool. If the investor has a direct claim on all of the cash
ﬂows, and the certiﬁcate holder has a proportionate share of the collateral’s
cash ﬂow, the term pass-through certiﬁcate (or beneﬁcial interest certiﬁcate)
is used. When there are rules to allocate the collateral’s cash ﬂow among
different classes of investors, the asset-backed securities are referred to as
pay-through certiﬁcates.
There is considerable variety of types of assets that have been securitized.
Most generally, these assets can be classiﬁed as mortgage assets and non-
mortgage assets. Securities backed by residential and commercial mortgage
loans1 are referred to as residential mortgage-backed securities (RMBSs)
and commercial mortgage-backed securities (CMBSs), respectively. In turn,
RMBSs can be further classiﬁed as agency RMBSs and private-label (or
nonagency) RMBSs. Agency RMBSs are those issued by three government-
related entities, and constitute by far the largest sector in the investment-
grade bond market (more than 35%). Private-label RMBSs are issued by any
other entity. Because of the credit risk associated with private-label RMBSs,
they require credit enhancement to provide some form of credit protection
against default on the pool of assets backing a transaction.
Credit enhancement mechanisms are typical in ABS transactions. In
the case of agency RMBSs, the credit enhancement is either a government
guarantee or the guarantee of a government-sponsored enterprise. Private-
label RMBSs are further classiﬁed based on the credit quality of the mortgage
loans in the pool: prime loans and subprime loans. Subprime loans are loans
made to borrowers with impaired credit ratings, and RMBSs backed by
them are referred to as subprime RMBSs. The market classiﬁes prime loans
as part of the nonagency RMBS market, while those backed by subprime
loans are part of the ABS market.
In addition to mortgages, other traditional assets that have been securi-
tized include credit card loans, auto loans, bonds (corporate and sovereign),
and bank loans. Some examples of nontraditional assets include future mu-
sic royalties that were securitized for recording artists David Bowie, James
Brown, the Isley Brothers, and Rod Stewart.2
15.2
MORTGAGE-BACKED SECURITIES:
IMPORTANT TERMINOLOGY
A mortgage is a loan secured by the collateral of some speciﬁed real es-
tate property that obliges the borrower to make a predetermined series of

Structuring and Pricing Residential Mortgage-Backed Securities
589
payments. The mortgage gives the lender (mortgagee) the right, if the bor-
rower (the mortgagor) defaults (i.e., fails to make the contractual payments),
to foreclose on the loan and seize the property in order to ensure that the
debt is paid off. The interest rate on the mortgage loan is called the note rate.
The fundamental unit in a mortgage-backed security (MBS) is the pool.
At its lowest common denominator, mortgage-backed pools are aggrega-
tions of large numbers of mortgage loans with similar (but not identical)
characteristics. Loans with common attributes such as note rate, term to
maturity, credit quality, loan balance, and type of mortgage design are com-
bined using a variety of legal mechanisms to create relatively fungible invest-
ment vehicles. With the creation of MBSs, mortgage loans are transformed
from a heterogeneous group of disparate assets into sizeable and homoge-
nous securities that trade in a liquid market.
The transformation of groups of mortgage loans with common at-
tributes into MBS occurs using one of two mechanisms. Loans that meet
the underwriting guidelines of three entities—Ginnie Mae, Fannie Mae, and
Freddie Mac—are securitized as an agency pool. While Ginnie Mae (Govern-
ment National Mortgage Association) is an agency of the U.S. government,
carrying the full faith and credit of U.S. government, Fannie Mae and Freddie
Mac are government-sponsored enterprises. Despite this distinction, MBSs
issued by these three entities are referred to as agency MBSs. There are three
types of agency MBSs: pass-through securities, stripped mortgage-backed
securities, and collateralized mortgage obligations.
Loans that do not qualify for agency pools are securitized in nonagency
or “private-label” transactions. These types of securities do not have an
agency guaranty, and must therefore be issued under the registration entity
or “shelf” of the issuer. Private-label deals share many features and struc-
turing techniques with agency collateralized mortgage obligations that we
will describe below. There are some important differences, however, due to
the nature of the loans collateralizing the deal as well as legal and regula-
tory issues associated with the different shelves. One important distinction
is that such deals must have some form of credit enhancement in order to
create large amounts of investment-grade bonds. Another is that they may
include assets other than mortgages. We discuss these differences later in
this chapter.
As noted in the previous section, there is a special category of mortgage-
related asset-backed securities called subprime MBSs. Such securities are
riskier than those in prime deals, either because the loans in the pool are
granted to borrowers with impaired credit (which greatly increases their
expected defaults and losses), or because they are in an inferior lien position
(which creates high-loss severities). As such, these loans are characterized by
higher note rates than those in the prime sector, reﬂecting risk-based pricing
on the part of the lenders.

590
DERIVATIVE PRICING AND USE
15.2.1
Cash Flow Characteristics
of a Residential Mortgage Loan
Although a mortgagor may select from many types of mortgage loans, for
the sake of simplicity we use the most common mortgage design: the level
payment, ﬁxed rate mortgage. The basic idea behind the design of the level
payment, ﬁxed rate mortgage, or simply level payment mortgage, is that the
borrower pays interest and repays principal in equal installments over an
agreed-upon period of time, called the maturity or term of the mortgage. At
the end of the term, the loan has been fully amortized. For a level payment
mortgage, each monthly mortgage payment is due on the ﬁrst of each month
and consists of:
■Interest of one-twelfth of the ﬁxed annual note rate times the amount
of the outstanding mortgage balance at the beginning of the previous
month.
■A repayment of a portion of the outstanding mortgage balance (princi-
pal).
The difference between the monthly mortgage payment and the portion
of the payment that represents interest equals the amount that is applied
to reduce the outstanding mortgage balance. The monthly mortgage pay-
ment is designed so that after the last scheduled monthly payment of the
loan is made, the amount of the outstanding mortgage balance is zero (i.e.,
the mortgage is fully repaid). Thus, the portion of the monthly mortgage
payment applied to interest declines each month, and the portion applied to
reducing the mortgage balance increases. The reason for this is that because
the mortgage balance is reduced with each monthly mortgage payment,
the interest on the mortgage balance declines. Since the monthly mortgage
payment is ﬁxed, an increasingly larger portion of the monthly payment is
applied to reduce the principal in each subsequent month.
For the mortgagee, the cash ﬂow from the mortgage loan is not the
same as what the mortgagor pays. This is because of a servicing fee, which
covers the collection of monthly payments and forwarding the proceeds to
the owners of the loan, maintaining records, sending payment notices when
payments are overdue, furnishing tax information for mortgagors, and so
on. Therefore, the monthly cash ﬂow from a mortgage loan can be divided
into three parts:
1. The servicing fee.
2. The interest payment net of the servicing fee.
3. The scheduled principal payment (referred to as amortization).

Structuring and Pricing Residential Mortgage-Backed Securities
591
15.2.2
Prepayments and Cash Flow Uncertainty
The most critical feature of the mortgages underlying a RMBS is that
the mortgagor may pay off any portion of the mortgage balance prior
to the scheduled due date. Payments made in excess of the scheduled
principal repayment are called prepayments. Hence, the mortgagor holds a
prepayment option.
Prepayments occur for a variety reasons. First, borrowers prepay the
entire mortgage balance when they sell their home. Second, borrowers may
be economically motivated to pay off the loan as market rates fall below the
loan’s note rate. This reason for prepaying a mortgage loan is referred to as
reﬁnancing. Third, in the case of borrowers who cannot meet their mortgage
obligations, the property is repossessed and sold. The proceeds from the sale
are used to pay off the mortgage loan. Finally, if property is destroyed by ﬁre
or if another insured catastrophe occurs, the insurance proceeds are used to
pay off the mortgage loan.
The effect of prepayments is that the cash ﬂow from a mortgage is not
known with certainty—by this, we mean that the amount and the timing of
the cash ﬂows is uncertain. Consequently, ignoring defaults, the mortgagor
knows that as long as the loan is outstanding, interest will be received
and the principal will be repaid at the scheduled date each month. By the
maturity date of the mortgage loan, the investor (mortgagee) would recover
the amount lent. However, what the mortgagee does not know is for how
long the mortgage loan will be outstanding, as well as the timing of the
principal payments.
The embedded prepayment option beneﬁts the mortgagor at the expense
of the lender. For example, a borrower who takes out a mortgage at a 10%
interest rate may choose to reﬁnance if rates fall to 7%. This will lower the
borrower’s monthly payment; he will be paying 7% interest instead of 10%.
However, the lender must now reinvest the returned principal at 7%, below
the 10% rate he previously enjoyed.
The risk of receiving principal back at an inopportune time (i.e., in
a lower-rate environment) is called prepayment risk. The prepayment risk
associated with the individual mortgages passes through to the holder of a
MBS, although this risk for a pool of mortgages can be divided up unequally
depending on the MBS structure.
15.2.3
Prepayments and Prepayment Conventions
In the RMBS market, several conventions have been used as a bench-
mark for prepayment rates. Today the benchmarks used are the conditional
prepayment rate and the Public Securities Association (PSA) prepayment
benchmark.

592
DERIVATIVE PRICING AND USE
The conditional prepayment rate (CPR) as a measure of the speed of
prepayments assumes that some fraction of the remaining principal in the
mortgage pool is prepaid each month for the remaining term of the collateral.
The CPR used for a particular deal is based on the characteristics of the
collateral (including its historical prepayment experience) and the current
and expected future economic environment.
The CPR is an annual prepayment rate. To estimate monthly prepay-
ments, the CPR must be converted into a monthly prepayment rate, com-
monly referred to as the single-monthly mortality rate (SMM). The following
formula is used to determine the SMM for a given CPR:
SMM = 1 −[(1 −CPR)1/12]
An SMM of w percent means that approximately w percent of the re-
maining mortgage balance at the beginning of the month, less the scheduled
principal payment, will prepay that month. That is,
Prepayment for month t = SMM · (Beginning mortgage balance for month t
−Scheduled principal payment for month t)
One problem with using the CPR is that it assumes a constant pre-
payment rate from the very outset of the origination of the loans. For ex-
ample, it is not likely that prepayments will be larger in dollar amount
shortly after loans are originated than later on after loans have seasoned.
Yet using a constant CPR makes that assumption. For residential mort-
gage loans, the PSA prepayment benchmark deals with this problem.3 The
PSA prepayment benchmark is expressed as a monthly series of annual
prepayment rates. The basic PSA benchmark model assumes that prepay-
ment rates are low for newly originated loans, speed up as the mort-
gages become seasoned, and eventually reach a plateau and remain at
that level. This is a phenomenon observed in reality. Usually, new mort-
gages tend to have lower prepayments because homeowners stay in the
home for several years before moving. After several years, the expected
turnover increases as people move to larger houses or new locations. The
remaining homeowners will exhibit a steady pattern of prepayments for the
years left.
The PSA standard benchmark assumes the following prepayment rates
for 30-year residential mortgages loans:
■A CPR of 0.2% for the ﬁrst month, increased by 0.2% per year per
month for the next 29 months, at which point it reaches 6% per year.
■A 6% CPR per annum (0.5% per month) for the remaining years.

Structuring and Pricing Residential Mortgage-Backed Securities
593
Mathematically, the monthly value for the CPR can be expressed as
CPR = (6%) · (t/30), t < 30
and
CPR = (6%)/12, t > 30
where t is the number of months since the origination of the pool.
In other words, the prepayment rate is 0.2% (on an annual basis) for
the ﬁrst month, 0.4% for the second month, 0.6% for the third month, and
so on until month 30, at which point it becomes ﬁxed at 0.5% per month.
All months above are counted with reference to origination of the pool.
This benchmark is referred to as 100% PSA. Slower or faster speeds
are then referred to as some percentage of PSA. For example, 50% PSA
means one-half the CPR of the PSA benchmark prepayment rate, and 165%
PSA means 1.65 times the CPR of the PSA benchmark prepayment rate.
A prepayment rate of 0% PSA means that no prepayments are assumed.
See Exhibit 15.1 for calculated CPR and SMM for assumed 100% PSA
prepayments and 165% PSA prepayments. (See also worksheet CPR in ﬁle
Ch15-Examples.xlsx.)
The PSA benchmark is commonly referred to as a prepayment model,
suggesting that it can be used to estimate prepayment. However, it is impor-
tant to note that characterizing this market convention for prepayments as a
prepayment model is wrong. We will discuss an actual prepayment models
in section 15.4.1.
15.2.4
Prepayments and Path Dependency
A complicated aspect of prepayments is that they are a function of the
entire history of interest rates during the life of the RMBS. For instance,
an RMBS may experience signiﬁcant reﬁnancing when interest rates fall.
Some borrowers will reﬁnance quickly, but others may lag because they are
less aware of the reﬁnancing opportunity, or do not have sufﬁcient credit
worthiness to reﬁnance. After the ﬁrst wave of reﬁnancing, the RMBS is
backed by mortgages of borrowers that are less likely to reﬁnance. This
effect is called burnout. So, if interest rates go up and then come down
again, the prepayments are expected to be much less than the ﬁrst time rates
dropped. The fact that prepayments depend on the path interest rates have
taken up to a particular time is referred to as path dependency, and it makes
pricing and structuring RMBSs much more challenging.

594
DERIVATIVE PRICING AND USE
EXHIBIT 15.1
Monthly CPR and SMM at 100% PSA and 165% PSA for
32 months.
100% PSA
165% PSA
Month
CPR
SMM
CPR
SMM
1
0.02%
0.0167%
0.03%
0.0023%
2
0.03%
0.0333%
0.06%
0.0552%
3
0.05%
0.0500%
0.08%
0.0829%
4
0.07%
0.0667%
0.11%
0.1107%
5
0.08%
0.0833%
0.14%
0.1386%
6
0.10%
0.1000%
0.17%
0.1665%
7
0.12%
0.1167%
0.19%
0.1946%
8
0.13%
0.1333%
0.22%
0.2227%
9
0.15%
0.1500%
0.25%
0.2509%
10
0.17%
0.1667%
0.28%
0.2792%
11
0.18%
0.1833%
0.30%
0.3077%
12
0.20%
0.2000%
0.33%
0.3361%
13
0.22%
0.2167%
0.36%
0.3647%
14
0.23%
0.2333%
0.39%
0.3934%
15
0.25%
0.2500%
0.41%
0.4222%
16
0.27%
0.2667%
0.44%
0.4510%
17
0.28%
0.2833%
0.47%
0.4800%
18
0.30%
0.3000%
0.50%
0.5090%
19
0.32%
0.3167%
0.52%
0.5381%
20
0.33%
0.3333%
0.55%
0.5674%
21
0.35%
0.3500%
0.58%
0.5967%
22
0.37%
0.3667%
0.61%
0.6261%
23
0.38%
0.3833%
0.63%
0.6556%
24
0.40%
0.4000%
0.66%
0.6852%
25
0.42%
0.4167%
0.69%
0.7150%
26
0.43%
0.4333%
0.72%
0.7448%
27
0.45%
0.4500%
0.74%
0.7747%
28
0.47%
0.4667%
0.77%
0.8047%
29
0.48%
0.4833%
0.80%
0.8348%
30
0.50%
0.5000%
0.83%
0.8650%
31
0.50%
0.5000%
0.83%
0.8650%
32
0.50%
0.5000%
0.83%
0.8650%

Structuring and Pricing Residential Mortgage-Backed Securities
595
15.3
TYPES OF RMBS STRUCTURES
As we mentioned in the previous section, there are three basic types of
agency RMBS structures. They are pass-through RMBSs, stripped RMBSs,
and collateralized mortgage obligations. There are also private-label RMBSs
that share a lot of common characteristics with collateralized mortgage
obligations. We explain the main ideas behind these structures in this section.
15.3.1
Agency Pass-Through RMBS
In a mortgage pass-through security, or simply a pass-through, the monthly
cash ﬂow from the pool of mortgage loans is distributed on a pro rata basis
to the certiﬁcate holders. To illustrate the structure of a pass-through, we will
look at the monthly cash ﬂow for a hypothetical pass-through given a PSA
assumption. We will assume the following for the underlying mortgages:
■Type: ﬁxed rate, level payment mortgages
■Weighted average coupon (WAC) rate:4 6.0%
■Weighted average maturity (WAM):5 358 months
■Servicing fee: 0.5%
■Outstanding balance: $660 million
The pass-through security has a coupon rate of 5.5% (WAC of 6% minus
the servicing fee of 0.5%).
This ﬁrst step in structuring the pass-through requires a projection of
the cash ﬂow of the mortgage pool. The cash ﬂow is decomposed into three
components:
■Interest (based on WAC of 6% and pass-through rate of 5.5%).
■Regularly scheduled principal (i.e., amortization).
■Prepayments based on some prepayment assumption.
To generate the cash ﬂow for the hypothetical pass-through secu-
rity we will assume a prepayment speed of 165% PSA. The cash ﬂow
is shown in Exhibit 15.2. (See also worksheet Pass-Through in the ﬁle
Ch15-Examples.xlsx.) Column 2 shows the outstanding mortgage balance
at the beginning of the month (i.e., outstanding balance at the beginning
of the previous month reduced by the total principal payment in the pre-
vious month). Column 3 gives the SMM for 165% PSA. The aggregate
monthly mortgage payment is reported in column 4.6 Notice that the
total monthly mortgage payment declines over time, as prepayments reduce
the mortgage balance outstanding.
Column 5 shows the monthly interest that is determined by multiplying
the outstanding mortgage balance at the beginning of the month by the pass-
through rate of 5.5% and dividing by 12. The regularly scheduled principal

596
DERIVATIVE PRICING AND USE
repayment (amortization), shown in column 6 is the difference between the
total monthly mortgage payment (column 4) and the gross coupon interest
for the month (6.0% multiplied by the outstanding mortgage balance at
the beginning of the month, then divided by 12). The prepayment for the
month is reported in column 7 and is found by using the equation we
introduced in section 15.2.3. The sum of the regularly scheduled principal
and the prepayment is the total principal payment, which is shown in column
8. The projected monthly cash ﬂow is then the sum of the monthly interest
plus the total principal payment as shown in the last column of Exhibit 15.2.
At 165% PSA, the average life for this pass-through security can be
computed to be 8.54 years. The average life is a weighted average of the
principal cash ﬂows divided by the par value where the weight is the month
when the projected principal is expected to be received.7
15.3.2
Agency Stripped MBS
A stripped mortgage-backed security (stripped MBS) is created by altering
that distribution of principal and interest from a pro rata distribution to an
unequal distribution.
In the most common type of stripped MBS, all of the interest is allocated
to one class—the interest-only class, and all of the principal to the other
class—the principal-only class.
Principal-Only Securities
A principal-only security, also called a PO or a
principal-only mortgage strip, is purchased at a substantial discount from
par value. The return an investor realizes depends on the speed at which
prepayments are made. The faster the prepayments, the higher the investor’s
return. For example, suppose that there is a mortgage pool consisting only
of 30-year mortgages, with $400 million in principal, and that investors can
purchase POs backed by this mortgage pool for $175 million. The dollar
return on this investment will be $225 million. How quickly that dollar
return is recovered by PO investors determines the actual return that will be
realized. In the extreme case, if all homeowners in the underlying mortgage
pool decide to prepay their mortgage loans immediately, PO investors will
realize the $225 million immediately. At the other extreme, if all homeown-
ers decide to remain in their homes for 30 years and make no prepayments,
the $225 million will be spread out over 30 years, which would result in a
lower return for PO investors.
Let us see how the price of the PO would be expected to change as
mortgage rates in the market change. When mortgage rates decline below
the note rate for the loans in the mortgage pool, prepayments are expected
to speed up, accelerating payments to the PO holder. Thus, the cash ﬂow of
a PO improves (in the sense that principal repayments are received earlier).

EXHIBIT 15.2
Monthly cash ﬂow for a $660 million pass-through security with a 5.5% pass-through rate, a WAC of 6.00%,
and a WAM of 358 months, assuming 165% PSA. Note that rows 31–348 are hidden.
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)
(9)
Month
Outstanding
Balance
SMM
Mortgage
Payment
Net Interest
Scheduled
Principal
Prepayments
Total Principal
Cash Flow
1
$660,000,000.00
0.0829%
$3,964,947.45
$3,025,000.00
$664,947.45
$546,435.32
$1,211,382.78
$4,236,382.78
2
$658,788,617.22
0.1107%
$3,961,661.43
$3,019,447.83
$667,718.35
$728,350.08
$1,396,068.43
$4,415,516.26
3
$657,392,548.80
0.1386%
$3,957,277.02
$3,013,049.18
$670,314.27
$909,894.82
$1,580,209.10
$4,593,258.28
4
$655,812,339.70
0.1665%
$3,951,794.17
$3,005,806.56
$672,732.48
$1,090,916.16
$1,763,648.64
$4,769,455.20
5
$654,048,691.06
0.1946%
$3,945,213.78
$2,997,723.17
$674,970.33
$1,271,260.68
$1,946,231.01
$4,943,954.17
6
$652,102,460.06
0.2227%
$3,937,537.63
$2,988,802.94
$677,025.33
$1,450,775.13
$2,127,800.46
$5,116,603.41
7
$649,974,659.59
0.2509%
$3,928,768.43
$2,979,050.52
$678,895.13
$1,629,306.69
$2,308,201.82
$5,287,252.34
8
$647,666,457.77
0.2792%
$3,918,909.79
$2,968,471.26
$680,577.51
$1,806,703.12
$2,487,280.62
$5,455,751.89
9
$645,179,177.15
0.3077%
$3,907,966.27
$2,957,071.23
$682,070.38
$1,982,813.03
$2,664,883.42
$5,621,954.64
10
$642,514,293.73
0.3361%
$3,895,943.30
$2,944,857.18
$683,371.83
$2,157,486.08
$2,840,857.92
$5,785,715.10
11
$639,673,435.82
0.3647%
$3,882,847.26
$2,931,836.58
$684,480.08
$2,330,573.19
$3,015,053.27
$5,946,889.86
12
$636,658,382.54
0.3934%
$3,868,685.42
$2,918,017.59
$685,393.51
$2,501,926.75
$3,187,320.26
$6,105,337.85
13
$633,471,062.28
0.4222%
$3,853,465.96
$2,903,409.04
$686,110.65
$2,671,400.85
$3,357,511.50
$6,260,920.54
14
$630,113,550.78
0.4510%
$3,837,197.95
$2,888,020.44
$686,630.19
$2,838,851.49
$3,525,481.68
$6,413,502.13
15
$626,588,069.10
0.4800%
$3,819,891.36
$2,871,861.98
$686,951.01
$3,004,136.77
$3,691,087.78
$6,562,949.76
16
$622,896,981.32
0.5090%
$3,801,557.03
$2,854,944.50
$687,072.12
$3,167,117.12
$3,854,189.24
$6,709,133.74
17
$619,042,792.08
0.5381%
$3,782,206.68
$2,837,279.46
$686,992.72
$3,327,655.50
$4,014,648.22
$6,851,927.68
18
$615,028,143.86
0.5674%
$3,761,852.90
$2,818,878.99
$686,712.18
$3,485,617.58
$4,172,329.76
$6,991,208.75
19
$610,855,814.10
0.5967%
$3,740,509.10
$2,799,755.81
$686,230.03
$3,640,871.98
$4,327,102.01
$7,126,857.83
20
$606,528,712.09
0.6261%
$3,718,189.54
$2,779,923.26
$685,545.98
$3,793,290.42
$4,478,836.40
$7,258,759.67
(Continued)
597

EXHIBIT 15.2
(Continued)
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)
(9)
Month
Outstanding
Balance
SMM
Mortgage
Payment
Net Interest
Scheduled
Principal
Prepayments
Total Principal
Cash Flow
21
$602,049,875.68
0.6556%
$3,694,909.30
$2,759,395.26
$684,659.93
$3,942,747.93
$4,627,407.86
$7,386,803.12
22
$597,422,467.83
0.6852%
$3,670,684.27
$2,738,186.31
$683,571.93
$4,089,123.02
$4,772,694.95
$7,510,881.26
23
$592,649,772.87
0.7150%
$3,645,531.09
$2,716,311.46
$682,282.22
$4,232,297.89
$4,914,580.11
$7,630,891.57
24
$587,735,192.76
0.7448%
$3,619,467.20
$2,693,786.30
$680,791.24
$4,372,158.55
$5,052,949.78
$7,746,736.08
25
$582,682,242.98
0.7747%
$3,592,510.78
$2,670,626.95
$679,099.57
$4,508,595.02
$5,187,694.59
$7,858,321.54
26
$577,494,548.39
0.8047%
$3,564,680.73
$2,646,850.01
$677,207.99
$4,641,501.51
$5,318,709.50
$7,965,559.51
27
$572,175,838.89
0.8348%
$3,535,996.66
$2,622,472.59
$675,117.46
$4,770,776.51
$5,445,893.98
$8,068,366.57
28
$566,729,944.91
0.8650%
$3,506,478.85
$2,597,512.25
$672,829.12
$4,896,323.00
$5,569,152.12
$8,166,664.37
29
$561,160,792.79
0.8650%
$3,476,148.25
$2,571,986.97
$670,344.28
$4,848,172.03
$5,518,516.31
$8,090,503.28
30
$555,642,276.48
0.8650%
$3,446,080.00
$2,546,693.77
$667,868.62
$4,800,458.97
$5,468,327.59
$8,015,021.35
. . .
349
$2,098,411.25
0.8650%
$215,654.93
$9,617.72
$205,162.87
$16,376.36
$221,539.23
$231,156.95
350
$1,876,872.02
0.8650%
$213,789.54
$8,602.33
$204,405.18
$14,466.63
$218,871.81
$227,474.14
351
$1,658,000.21
0.8650%
$211,940.29
$7,599.17
$203,650.28
$12,579.94
$216,230.23
$223,829.40
352
$1,441,769.98
0.8650%
$210,107.03
$6,608.11
$202,898.18
$10,716.09
$213,614.26
$220,222.38
353
$1,228,155.72
0.8650%
$208,289.63
$5,629.05
$202,148.85
$8,874.83
$211,023.68
$216,652.73
354
$1,017,132.04
0.8650%
$206,487.95
$4,661.86
$201,402.29
$7,055.96
$208,458.25
$213,120.10
355
$808,673.79
0.8650%
$204,701.85
$3,706.42
$200,658.49
$5,259.26
$205,917.74
$209,624.16
356
$602,756.05
0.8650%
$202,931.21
$2,762.63
$199,917.43
$3,484.50
$203,401.93
$206,164.56
357
$399,354.11
0.8650%
$201,175.88
$1,830.37
$199,179.11
$1,731.49
$200,910.60
$202,740.97
358
$198,443.52
0.8650%
$199,435.73
$909.53
$198,443.52
$0.00
$198,443.52
$199,353.05
598

Structuring and Pricing Residential Mortgage-Backed Securities
599
The cash ﬂow will be discounted at a lower interest rate because the mortgage
rate in the market has declined. The result is that the PO price will increase
when mortgage rates decline. When mortgage rates rise above the note
rate for the loans in the mortgage pool, prepayments are expected to slow
down. The cash ﬂow deteriorates (in the sense that it takes longer to recover
principal repayments). Couple this with a higher discount rate, and the price
of a PO will fall when mortgage rates rise.
Interest-Only Securities
An interest-only security, also called an IO or
an interest-only mortgage strip, has no par value. In contrast to the PO
investor, the IO investor wants prepayments to be slow because the IO
investor receives interest only on the amount of the principal outstanding.
When prepayments are made, less dollar interest will be received as the
outstanding principal declines. In fact, if prepayments are too fast, the IO
investor may not recover the amount paid for the IO even if the IO is held
to maturity.
Let us look at the expected price response of an IO to changes in mort-
gage rates. If mortgage rates decline below the note rate for the loans in the
mortgage pool, prepayments are expected to accelerate. This would result
in a deterioration of the expected cash ﬂow for an IO. While the cash ﬂow
will be discounted at a lower rate, the net effect typically is a decline in the
price of an IO. If mortgage rates rise above the note rate for the loans in
the mortgage pool, the expected cash ﬂow improves, but the cash ﬂow is
discounted at a higher interest rate. The net effect may be either a rise or fall
for the IO’s price.
Thus, we see an interesting characteristic of an IO: Its price tends to move
in the same direction as the change in mortgage rates (1) when mortgage
rates fall below the note rate for the loans in the mortgage pool and (2) for
some range of mortgage rates above the note rate. Both POs and IOs exhibit
substantial price volatility when mortgage rates change. The greater price
volatility of the IO and PO compared to the pass-through from which they
were created is because the combined price volatility of the IO and PO must
be equal to the price volatility of the pass-through.
15.3.3
Agency Collateralized
Mortgage Obligations
A collateralized mortgage obligation (CMO) is a security backed by a pool
of mortgage pass-through securities. CMOs are structured so that there are
several classes of bondholders—also called tranches—with varying average
lives. The principal payments from the underlying pool of pass-through
securities are used to retire the bonds on a priority basis as speciﬁed in the
prospectus.

600
DERIVATIVE PRICING AND USE
EXHIBIT 15.3
Example of a sequential-pay structure
(“Structure 1”).
Bond Class
Par Amount ($)
Coupon Rate (%)
A
$320,925,000.00
5.50%
B
$59,400,000.00
5.50%
C
$159,225,000.00
5.50%
D
$120,450,000.00
5.50%
Although we will not explain the wide range of bond classes or tranches
created in a CMO structure, we will provide a few for the purposes of
showing how they are structured and how they alter the investment char-
acteristics compared to the mortgage pass-through securities from which
they were created: sequential-pay bonds, planned amortization class bonds,
and support bonds. For a more detailed description of the different types of
CMO bond classes, see Fabozzi, Bhattacharya, and Berliner (2007).
Sequential-Pay Structures
The simplest type of CMO structure is the
sequential-pay structure. To illustrate this structure, we will use the $660
million, 5.5% pass-through security (which is comprised of residential mort-
gage loans that conﬁrm to the underwriting standards of Ginnie Mae, Fannie
Mae, and Freddie Mac) to create a simple structure. The structure is given
in Exhibit 15.3, and we refer to this structure as “Structure 1.”
In structuring an agency deal, there are only rules speciﬁed for the
distribution of principal and interest. There are no rules for deals with
defaults and delinquencies because payments are guaranteed by the issuer.
In Structure 1 we will use the following rules:
■Interest. The monthly interest is distributed to each bond class on the
basis of the amount of principal outstanding at the beginning of the
month.
■Principal. All monthly principal (i.e., regularly scheduled principal and
prepayments) is distributed ﬁrst to bond class A until it is completely
paid off. After bond class A has completely paid off its par amount,
all monthly principal payments are made to bond class B until it is
completely paid off. After bond class B has completely paid off its par
amount, all monthly principal payments are made to bond class C un-
til it has completely paid off its par amount. Finally, after bond C is
completely paid off, all monthly principal payments are made to bond
class D.
Based on these rules for the distribution of interest and principal, Ex-
hibits 15.4 and 15.5 show the cash ﬂows for each bond class assuming one

EXHIBIT 15.4
Monthly cash ﬂows for selected months for Structure 1, classes A and B.
A
B
Month
Beginning
Balance
Principal
Interest
Beginning
Balance
Principal
Interest
1
$320,925,000.00
$1,211,382.78
$1,470,906.25
$59,400,000.00
$0.00
$272,250.00
2
$319,713,617.22
$1,396,068.43
$1,465,354.08
$59,400,000.00
$0.00
$272,250.00
3
$318,317,548.80
$1,580,209.10
$1,458,955.43
$59,400,000.00
$0.00
$272,250.00
4
$316,737,339.70
$1,763,648.64
$1,451,712.81
$59,400,000.00
$0.00
$272,250.00
5
$314,973,691.06
$1,946,231.01
$1,443,629.42
$59,400,000.00
$0.00
$272,250.00
6
$313,027,460.06
$2,127,800.46
$1,434,709.19
$59,400,000.00
$0.00
$272,250.00
7
$310,899,659.59
$2,308,201.82
$1,424,956.77
$59,400,000.00
$0.00
$272,250.00
8
$308,591,457.77
$2,487,280.62
$1,414,377.51
$59,400,000.00
$0.00
$272,250.00
9
$306,104,177.15
$2,664,883.42
$1,402,977.48
$59,400,000.00
$0.00
$272,250.00
10
$303,439,293.73
$2,840,857.92
$1,390,763.43
$59,400,000.00
$0.00
$272,250.00
11
$300,598,435.82
$3,015,053.27
$1,377,742.83
$59,400,000.00
$0.00
$272,250.00
12
$297,583,382.54
$3,187,320.26
$1,363,923.84
$59,400,000.00
$0.00
$272,250.00
. . .
74
$17,687,935.97
$3,648,575.33
$81,069.71
$59,400,000.00
$0.00
$272,250.00
75
$14,039,360.63
$3,614,937.79
$64,347.07
$59,400,000.00
$0.00
$272,250.00
(Continued)
601

EXHIBIT 15.4
(Continued)
A
B
Month
Beginning
Balance
Principal
Interest
Beginning
Balance
Principal
Interest
76
$10,424,422.85
$3,581,598.87
$47,778.60
$59,400,000.00
$0.00
$272,250.00
77
$6,842,823.97
$3,548,555.98
$31,362.94
$59,400,000.00
$0.00
$272,250.00
78
$3,294,267.99
$3,294,267.99
$15,098.73
$59,400,000.00
$221,538.54
$272,250.00
79
$0.00
$0.00
$0.00
$59,178,461.46
$3,483,347.94
$271,234.62
80
$0.00
$0.00
$0.00
$55,695,113.52
$3,451,177.68
$255,269.27
81
$0.00
$0.00
$0.00
$52,243,935.84
$3,419,293.21
$239,451.37
82
$0.00
$0.00
$0.00
$48,824,642.63
$3,387,692.05
$223,779.61
83
$0.00
$0.00
$0.00
$45,436,950.58
$3,356,371.72
$208,252.69
84
$0.00
$0.00
$0.00
$42,080,578.86
$3,325,329.75
$192,869.32
85
$0.00
$0.00
$0.00
$38,755,249.12
$3,294,563.71
$177,628.23
95
$0.00
$0.00
$0.00
$7,149,733.68
$3,001,558.67
$32,769.61
96
$0.00
$0.00
$0.00
$4,148,175.01
$2,973,673.07
$19,012.47
97
$0.00
$0.00
$0.00
$1,174,501.93
$1,174,501.93
$5,383.13
98
$0.00
$0.00
$0.00
$0.00
$0.00
$0.00
602

EXHIBIT 15.5
Monthly cash ﬂows for selected months for Structure 1, classes C and D.
C
D
Month
Beginning
Balance
Principal
Interest
Beginning
Balance
Principal
Interest
1
$159,225,000.00
$0.00
$729,781.25
$120,450,000.00
$0.00
$552,062.50
2
$159,225,000.00
$0.00
$729,781.25
$120,450,000.00
$0.00
$552,062.50
3
$159,225,000.00
$0.00
$729,781.25
$120,450,000.00
$0.00
$552,062.50
4
$159,225,000.00
$0.00
$729,781.25
$120,450,000.00
$0.00
$552,062.50
5
$159,225,000.00
$0.00
$729,781.25
$120,450,000.00
$0.00
$552,062.50
6
$159,225,000.00
$0.00
$729,781.25
$120,450,000.00
$0.00
$552,062.50
7
$159,225,000.00
$0.00
$729,781.25
$120,450,000.00
$0.00
$552,062.50
8
$159,225,000.00
$0.00
$729,781.25
$120,450,000.00
$0.00
$552,062.50
9
$159,225,000.00
$0.00
$729,781.25
$120,450,000.00
$0.00
$552,062.50
10
$159,225,000.00
$0.00
$729,781.25
$120,450,000.00
$0.00
$552,062.50
11
$159,225,000.00
$0.00
$729,781.25
$120,450,000.00
$0.00
$552,062.50
12
$159,225,000.00
$0.00
$729,781.25
$120,450,000.00
$0.00
$552,062.50
. . .
95
$159,225,000.00
$0.00
$729,781.25
$120,450,000.00
$0.00
$552,062.50
96
$159,225,000.00
$0.00
$729,781.25
$120,450,000.00
$0.00
$552,062.50
97
$159,225,000.00
$1,771,533.84
$729,781.25
$120,450,000.00
$0.00
$552,062.50
98
$157,453,466.16
$2,918,644.62
$721,661.72
$120,450,000.00
$0.00
$552,062.50
99
$154,534,821.54
$2,891,497.43
$708,284.60
$120,450,000.00
$0.00
$552,062.50
100
$151,643,324.11
$2,864,592.09
$695,031.90
$120,450,000.00
$0.00
$552,062.50
101
$148,778,732.01
$2,837,926.47
$681,902.52
$120,450,000.00
$0.00
$552,062.50
102
$145,940,805.54
$2,811,498.48
$668,895.36
$120,450,000.00
$0.00
$552,062.50
(Continued)
603

EXHIBIT 15.5
(Continued)
C
D
Month
Beginning
Balance
Principal
Interest
Beginning
Balance
Principal
Interest
103
$143,129,307.06
$2,785,306.03
$656,009.32
$120,450,000.00
$0.00
$552,062.50
104
$140,344,001.04
$2,759,347.06
$643,243.34
$120,450,000.00
$0.00
$552,062.50
105
$137,584,653.98
$2,733,619.52
$630,596.33
$120,450,000.00
$0.00
$552,062.50
. . .
171
$2,747,229.44
$1,458,601.26
$12,591.47
$120,450,000.00
$0.00
$552,062.50
172
$1,288,628.18
$1,288,628.18
$5,906.21
$120,450,000.00
$155,905.11
$552,062.50
173
$0.00
$0.00
$0.00
$120,294,094.89
$1,430,592.36
$551,347.93
174
$0.00
$0.00
$0.00
$118,863,502.53
$1,416,777.37
$544,791.05
175
$0.00
$0.00
$0.00
$117,446,725.16
$1,403,087.19
$538,297.49
176
$0.00
$0.00
$0.00
$116,043,637.98
$1,389,520.73
$531,866.67
177
$0.00
$0.00
$0.00
$114,654,117.25
$1,376,076.90
$525,498.04
178
$0.00
$0.00
$0.00
$113,278,040.36
$1,362,754.61
$519,191.02
179
$0.00
$0.00
$0.00
$111,915,285.74
$1,349,552.81
$512,945.06
180
$0.00
$0.00
$0.00
$110,565,732.93
$1,336,470.42
$506,759.61
. . .
350
$0.00
$0.00
$0.00
$1,876,872.02
$218,871.81
$8,602.33
351
$0.00
$0.00
$0.00
$1,658,000.21
$216,230.23
$7,599.17
352
$0.00
$0.00
$0.00
$1,441,769.98
$213,614.26
$6,608.11
353
$0.00
$0.00
$0.00
$1,228,155.72
$211,023.68
$5,629.05
354
$0.00
$0.00
$0.00
$1,017,132.04
$208,458.25
$4,661.86
355
$0.00
$0.00
$0.00
$808,673.79
$205,917.74
$3,706.42
356
$0.00
$0.00
$0.00
$602,756.05
$203,401.93
$2,762.63
357
$0.00
$0.00
$0.00
$399,354.11
$200,910.60
$1,830.37
358
$0.00
$0.00
$0.00
$198,443.52
$198,443.52
$909.53
604

Structuring and Pricing Residential Mortgage-Backed Securities
605
prepayment speed, 165% PSA. (See also worksheet Sequential-Pay in the
ﬁle Ch15-Examples.xlsx.) Note that bond class A is fully paid off in month
78. In the same month, principal payments begin for bond class B, which is
fully paid off in month 97. Bond class C starts receiving principal payments
in month 97, and bond class D—in month 172.
Before explaining what has been accomplished in Structure 1, a few
comments are in order. First, the total par value of the four bond classes
in the structure is equal to $660 million, which is equal to the par value
of the collateral (the pass-through security). Second, we have simpliﬁed the
illustration by assuming that all bond classes have the same coupon rate.
In actual deals, the coupon rate would be determined by prevailing market
conditions (i.e., the yield curve) and would not necessarily be equal to each
bond class. A condition that must be satisﬁed is that the total interest to be
paid to all the bond classes in a month may not exceed the interest from
the collateral; otherwise an interest shortfall will occur. Equivalently, the
weighted average coupon rate for the bond classes in the structure may not
exceed the coupon rate for the collateral (6% in our illustration). Finally,
although the payment rules for the distribution of the principal payments are
known, the exact amount of monthly principal is not. The monthly principal
will depend on the principal cash ﬂows generated by the collateral, which
in turn depends on the actual payment rate of the collateral. Thus, in order
to project monthly cash ﬂows, a prepayment assumption must be made. We
will discuss prepayment models in section 15.4.1.
Now let us look at Structure 1. To see what has been accomplished, a
summary of the average life (in years) of the collateral and the four bond
classes under a range of prepayment assumptions is shown in Exhibit 15.6.
Notice the substantial differences in the average life for the collateral
depending on the speed of prepayment. Given this risk, the collateral in
its original form is unappealing to institutional investors who have speciﬁc
EXHIBIT 15.6
Average life for the collateral and the different bond classes of
the CMO depending on the assumptions about prepayment speed as a percentage
of PSA.
Prepayment Speed
100%
125%
165%
250%
400%
500%
Collateral
11.22
10.04
8.54
6.42
4.45
3.72
Bond Class
A
4.70
4.09
3.42
2.63
1.98
1.74
B
10.33
8.90
7.28
5.32
3.73
3.17
C
15.05
13.15
10.85
7.84
5.31
4.41
D
24.01
22.36
19.75
15.17
10.25
8.33

606
DERIVATIVE PRICING AND USE
liability structures and are trying to match their liabilities with their assets.
However, the average lives for the different bond classes tell a different story.
They are both shorter and longer than the collateral, thereby attracting
institutional investors who have a preference for an average life different
from that of the collateral. For example, a depository institution interested
in shorter-term paper would ﬁnd bond class A more appealing than the
collateral because within a reasonable range of prepayment speeds, bond
class A’s average life will be less than ﬁve years under slow prepayment
speeds, while the collateral’s average life can extend to a little more than
11 years. At the other end of the maturity preference spectrum, consider a
deﬁned beneﬁt pension plan that is seeking longer-term investments. That
institutional investor would prefer bond class D to the collateral. While bond
class D has considerable variation in its average life, the average life does
remain long on average. Notice, for example, that at the fastest prepayment
speed shown in Exhibit 15.6 (500 PSA), the average life for the collateral
can contract to 3.7 years, but for bond class D to only 8.3 years.
Consequently, we can see that the rules for distribution of principal
among the bond classes in this structure have redistributed the prepayment
risk of the collateral among the bond classes. As a result, an unattractive
asset or collateral from the perspective of some investors can be used to
create securities that better match the needs of those investors.
Planned Amortization Class Bonds and Support Bonds
There are investors
who seek securities (bond classes) that have even greater protection against
prepayment risk. Planned amortization class bond structures are designed
with this goal in mind. The main idea is to create a bond class, planned
amortization class bond (popularly referred to as a PAC), that has priority
over all other bond classes in the structure with respect to receiving the
scheduled principal repayment. The non-PAC bond classes in the structure
are referred to as the support bonds or companion bonds. The support
bonds accept the prepayment risk if actual prepayment speeds are faster
or slower than so-called structuring speeds or structuring bands. Hence,
unlike a sequential-pay structure, in which the bond classes are given some
protection against fast prepayments or slow prepayments, but not both,
PAC bonds offer protection against both fast and slow prepayments, thus
minimizing the variability for the investor.
In practice, a typical structure may have more than one class of PAC
bonds. That is, there may be a series of PAC bonds. The ﬁrst PAC bond in
the series has a priority over the others, the second PAC bond has a priority
over the others (except the ﬁrst PAC bond), and so on. Similarly, typically
there are several classes of support bonds.

Structuring and Pricing Residential Mortgage-Backed Securities
607
15.3.4
Private-Label RMBS
The private-label RMBS market encompasses a variety of product and struc-
turing variations. Technically, any deal that is not securitized under an
agency (i.e., Ginnie Mae) or GSE shelf (i.e., Freddie Mac or Fannie Mae)
can be considered private label, as the issuing entity has no connection to the
U.S. government (either explicit or implicit). Private-label RMBSs are fur-
ther classiﬁed based on the credit quality of the mortgage loans in the pool:
prime loans (for higher-quality loans) and subprime loans (for lower-quality
loans with high default risk).
As we mentioned earlier, because of the lack of federal guarantee,
private-label RMBS deals must have some form of credit enhancement in
order to create large amounts of investment-grade bonds. Aside from the
presence of credit enhancement, private-label deals share many features and
structuring techniques with agency CMOs. There are some important dif-
ferences, however, due to the nature of the loans collateralizing the deal
as well as legal and regulatory issues associated with the different shelves.
First, private-label deals can be structured such that derivatives, such as in-
terest rate swaps, can be inserted into the structures as risk mitigators. The
GSEs, by contrast, do not allow for inclusion of derivatives in deals. Second,
the loans collateralizing private-label deals are generally assumed to prepay
faster than those in agency pools. The convention in the agency market is to
structure deals using a base-case prepayment speed consistent with median
prepayment speeds reported by Bloomberg. Private-label deals, by contrast,
are structured either to a market convention (i.e., PSA speeds ranging from
250% to 300%) or a predeﬁned ramp (i.e., 6% to 18% CPR ramping over
12 months). The ramp is deﬁned in the prospectus and it is typically called
the prospectus prepayment curve, or PPC. (100% PPC is simply the base
ramp deﬁned at the time of pricing.) Finally, private-label deals typically
have cleanup calls. These are inserted into deals to relieve the trustees from
the burden of having to oversee deals with very small remaining balances.
The calls are triggered when the current face of the deal and/or collateral
group declines below a predetermined level.
Next, we brieﬂy review the mechanisms involved in creating the internal
credit enhancement typically utilized in private-label deals.
The ﬁrst step in structuring the credit enhancement for a private-label
deal is to split the face value of the loans into senior and subordinated
interests. The senior bonds have higher priority with respect to both the
receipt of interest and principal and the allocation of realized losses, and are
generally created with enough subordination to be rated AAA by the credit
rating agencies. In most cases, the subordinate interests are subdivided (or
tranched) into a series of bonds that decline sequentially in priority. The

608
DERIVATIVE PRICING AND USE
EXHIBIT 15.7
Subordination by percentage of deal size for a hypothetical $400
million deal with 3.5% initial subordination.
Face Value
Percent of Deal
AAA
$386,000,000.00
96.50%
AA
$6,000,000.00
1.50%
A
$2,600,000.00
0.65%
BBB
$1,800,000.00
0.45%
BB
$1,200,000.00
0.30%
B
$1,200,000.00
0.30%
First loss (nonrated)
$1,200,000.00
0.30%
Total subordination
$400,000,000.00
3.50%
subordinate classes normally range from AA in rating to an unrated ﬁrst-
loss piece. These securities are often referenced as the six-pack since there
are six broad rating grades generally issued by the rating agencies. In the
investment-grade category, bonds range from AA to BBB; noninvestment
grade ratings decline from BB to the unrated ﬁrst-loss piece.8 The ratings
are assigned according to the amount of credit support (also referred to
as buffer) behind each bond. The structure (or splits) of a hypothetical
$400 million deal with 3.5% initial subordination is shown in Exhibits 15.7
and 15.8.
Internal credit enhancement requires two complimentary mechanisms.
The cash ﬂows for deals are allocated through the mechanism of a waterfall,
EXHIBIT 15.8
Tranche size measured by percentage of subordination for each
rating level (i.e., credit support). Calculated by summing the deal percentages of all
tranches junior in priority. As an example, if cumulative losses on the deal were
0.40%, the ﬁrst loss and the rated B tranche would be fully exhausted, but tranches
rated BB and above would not be affected.
Face Value
Credit Support
AAA
$386,000,000.00
3.50%
AA
$6,000,000.00
2.00%
A
$2,600,000.00
1.35%
BBB
$1,800,000.00
0.90%
BB
$1,200,000.00
0.60%
B
$1,200,000.00
0.30%
First loss (nonrated)
$1,200,000.00
0.00%

Structuring and Pricing Residential Mortgage-Backed Securities
609
which dictates the allocation of principal and interest payments to tranches
with different degrees of seniority. The allocation of realized losses is gov-
erned by a separate prioritization schedule, with the subordinates typically
being impacted in reverse order of priority.
While the original subordination levels are set at the time of issuance (or,
more precisely, at the time the attributes of the deal’s collateral are ﬁnalized),
deals with internal credit enhancement are designed so that the amount of
credit enhancement grows over time. Private-label structures generally use
a so-called shifting interest mechanism, in which the subordinate classes
(or subs) do not receive principal prepayments for a period of time after
issuance, generally ﬁve years for ﬁxed rate deals. After the lockout period
expires, the subs begin to receive prepayments on an escalating basis. It is
only after 10 years that the subs receive a pro rata allocation of prepayments.
Locking out the subs means that as the collateral experiences prepayments,
the face value of the subs grows in proportion relative to the senior classes.
The senior classes receive all of the collateral prepayments during the lockout
period and, for that reason, decline proportionately over time. Deals often
have more than one collateral group securitized in the same transaction to
minimize costs. Typically, the collateral groups have different characteristics
that make them difﬁcult to commingle. For example, a deal may have sep-
arate collateral groups comprised of 30- and 15-year loans. Depending on
the collateral in question, the two groups can have separate subordination
groups. Alternatively, one set of subs can serve as credit support for both
groups, in a so-called Y-structure. This creates larger subordinate classes,
which are generally more liquid.
15.4
PRICING RMBS BY SIMULATION
The pricing of RMBSs involves the estimation of the present value of the
uncertain future cash ﬂows, and presents a number of challenges. There are
two building blocks to RMBS pricing models: an interest rate model, which
determines the discount factor, and a prepayment model, which determines
the behavior of the mortgagor. However, the two models do not exist inde-
pendently of one another. Historical evidence clearly indicates that interest
rates impact prepayments. Furthermore, not only the current interest rate,
but also past interest rates matter for the amount of current prepayments.
As we explained in section 15.2.4, this is often referred to as the burnout
effect: a mortgage pool that has already experienced low interest rates will
prepay less quickly than a pool that has always experienced high interest
rates, even if the two pools currently face the same interest rates. This means
that valuation of RMBSs is path-dependent; that is, it depends on the path

610
DERIVATIVE PRICING AND USE
taken by interest rates so far. Pricing models like binomial trees get out of
hand very quickly in this context.9
Simulation is therefore the preferred and more practical method for
pricing RMBSs. Yet given the complexity of RMBS structures, simulation
is often too slow for practical purposes. More recently, variance-reduction
techniques (especially quasirandom number sequences)10 have been success-
fully applied to RMBS pricing.
In this section, we explain the main ideas behind RMBS pricing by
simulation. We start with a discussion of interest and prepayment models
used in RMBS pricing, and explain how the models are put together. We then
discuss more recent developments, speciﬁcally how quasirandom Monte
Carlo methods can be applied to RMBS pricing.
15.4.1
Prepayment Models
In section 15.2.3, we introduced a prepayment function convention. Pre-
payment models are a very important factor for accurate pricing of RMBSs,
and there is a variety of proprietary models.
Traditionally, prepayment models have been based on econometrics—
they often include macroeconomic factors, such as the health of the economy
or the housing market activity, or identify a prepayment pattern as a function
of speciﬁc characteristics of the individual mortgages in the pool. Three
classical models are (1) the arctangent model from the Ofﬁce of Thrift
Supervision (OTS), (2) Schwarz and Torous’s proportional hazard model
(1989), and (3) Richard and Roll’s modiﬁed Goldman Sachs model (1989).
Other models (see, for example Kalotay, Yang, and Fabozzi 2004) take into
consideration borrower intelligence and are based on option theory, under
the assumption that the borrower acts optimally to maximize the value of
the option to prepay the mortgage.
Technically, prepayment models should be based on option pricing
theory. The fact that a homeowner can pay off the outstanding princi-
pal of a mortgage in full at any time and be freed from the obligations
to make further payments means that the homeowner/borrower holds an
American call option on an otherwise identical, nonprepayable mortgage.
The strike of the option equals the principal amount of the outstanding
loan, and changes after every payment. Similarly, we can think of the
homeowner as the issuer of a callable bond—the homeowner sells the
bond, receives the proceeds, and undertakes to make a set of scheduled
payments.
When pricing callable bonds issued by governments, agencies, and cor-
porations, we may be able to assume that the driving force behind pre-
payments is the level of interest rates. However, individuals do not always

Structuring and Pricing Residential Mortgage-Backed Securities
611
act rationally. Furthermore, residential mortgages are often prepaid for rea-
sons independent of the level of interest rates—homeowners move, sell their
home, and pay off the mortgage; or there are natural disasters, and the in-
surance policy covers the value of the home. Even if interest rates provide
a strong incentive for homeowners to change the terms of their mortgages,
homeowners vary greatly in ﬁnancial sophistication. The cost to them to
analyze the prepayment options and handle all the necessary paperwork
may turn out to be too high. When they do reﬁnance, there is still usually
a noticeable delay, and valuation models from the ﬁnancial markets do not
reﬂect this properly.
As mentioned, most prepayment function models used in practice are
based on statistical models. The concern with such approaches is that his-
torical data, on which these models are based, may render the models out-
dated as economic conditions change. However, the theoretically superior
approaches based on modeling the homeowner’s decision process have not
been too successful in practice, and have not gained widespread industry
acceptance.
It is important to keep in mind also that in the case of nonagency RMBSs,
prepayments can be involuntary. In other words, prepayments can arise
because of a default by homeowners.11 These defaults should be projected
in modeling prepayments. Modeling defaults involves modeling the timing
of defaults, as well as the severity of defaults (i.e., the recovery rate after the
default). Both voluntary and involuntary prepayments are included in the
calculation of the cash ﬂow from the RMBS.
Next, we introduce two simple econometric prepayment models for
agency RMBSs used in practice. Our goal is not to provide a comprehensive
review of the subject, but to give the reader an idea of the kind of modeling
that is involved in the pricing of RMBSs. For more details on prepayment
models, see, for example, Fabozzi (2005).
Arctangent Model
The arctangent model expresses the CPR at time t as
a function of the weighted average coupon (WAC) and the 10-year rate at
time t, r10(t):
CPR(t) = 0.2406 −0.1389 · arctan

5.9518 ·

1.089 −WAC
r10(t)

This kind of model is derived empirically based on the observed rela-
tionship between different factors and the prepayment rate.
Modified Goldman Sachs Model
In the modiﬁed Goldman Sachs model,12
the CPR is assumed to be a product of four factors: the reﬁnancing incentive

612
DERIVATIVE PRICING AND USE
RI, the month multiplier MM, the seasoning factor Age, and the burnout
multiplier BM:
CPR(t) = RI(t) · MM(t) · Age(t) · BM(t)
The reﬁnancing incentive in this model is related to the ratio or the
spread between the weighted average coupon rate and the interest rate.
The idea is that if the interest rate is much lower than the weighted average
coupon rate, there is a higher incentive for homeowners to reﬁnance the
mortgage, that is, RI is higher. RI can be expressed as
RI = a + b · arctan(c + d · (WAC −r))
or
RI = a + b · arctan(c + d · (WAC/r)
The relevant interest rate r can be, for example, the 10-year rate r10(t).
The 10-year rate is often the one used as an approximation for the reﬁ-
nancing rate for new loans. Often a time lag is assumed to incorporate the
observation that investors reﬁnance after observing a fall in mortgage rates,
that is, r10(t – 1) is used. A speciﬁc function for RI used in practice is
RI(t) = 0.28 + 0.14 · arctan(−8.571 + 430 · (WAC −r10(t)))
The monthly multiplier MM is associated with the speciﬁc month of
the year. It has been observed that prepayments peak during the summer-
fall months, and bottom out in the winter. The month multipliers from the
original Richard and Roll (1989) paper are as follows (starting with month
i = January):
MM(i) = (0.94, 0.76, 0.74, 0.95, 0.98, 0.92, 0.98, 1.10, 1.18, 1.22, 1.23, 0.98)
The seasoning factor Age reﬂects the empirical observation that newer
loans tend to prepay slower than old or “seasoned” loans. This factor usually
follows the convention behind the standard PSA model (see section 15.2.3).
A speciﬁc function used for Age is
Age(t) = min{1, t/30}
Finally, as we explained earlier, the burnout multiplier reﬂects the em-
pirical observation that prepayments tend to decrease over time, even when

Structuring and Pricing Residential Mortgage-Backed Securities
613
conditions for reﬁnancing are favorable. The reason is that not all mort-
gagors prepay in an identical fashion. Some reﬁnance as soon as mortgage
rates become lower than the rate they are paying; others wait until rates
drop further; and others never prepay. The “fast” prepayers leave, and as
the pool ages, only the “slow” ones stay behind. Richard and Roll (1989)
use the following function for the burnout multiplier:
BM(t) = 0.3 + 0.7 · MB(t)
MB(0)
where MB(0) is the mortgage balance at the beginning, and MB(t) is the
mortgage balance at time t. In effect, Richard and Roll (1989) quantify the
burnout by estimating how deep in-the-money the prepayment option is at
time t. If it has been deep in-the-money, this suggests that all else being
equal, the prepayments are smaller.
15.4.2
Interest Rate Models
There is a variety of interest rate models that can be used to generate scenar-
ios for the term structure of interest rates. They can be most generally split
into two categories: equilibrium models, and no-arbitrage models. Equilib-
rium models, which include the Vasicek model and the CIR model, start with
assumptions about economic variables and a process for the instantaneous
(short) rate r.13 They then derive the bond prices that the process for the
short-term rate imply, and use those bond prices to construct the implied
term structure. The disadvantage of equilibrium models is that they do not
automatically ﬁt today’s term structure, so adjustments need to be made
by selecting the parameters of the processes carefully to make sure that the
pricing of securities using the term structure implied from these models does
not create arbitrage opportunities.
The Vasicek model and the CIR model are one-factor models of the
short-term interest rate because they include only one random variable. A
popular two-factor model is the one proposed by Brennan and Schwartz
(1979), in which the process for the short rate is assumed to revert to a long
rate, which in turn follows a particular stochastic process itself. Another
two-factor model assumes that the volatility in the process followed by the
short-term interest rate itself follows a stochastic process.14
No-arbitrage models include the Ho-Lee model and the Hull-White
model.15 Those models are designed to be exactly consistent with today’s
term structure. Some equilibrium models can be converted to no-arbitrage
models by making the assumption that the drift term in the process for the
short rate depends on time. (Both the Ho-Lee and the Hull-White model

614
DERIVATIVE PRICING AND USE
do.) This allows to ﬁt the parameters of the process to the shape of the
term structure at time 0, and to incorporate that information for the process
followed by the interest rate in the future as well.
How do we use the interest rate models for MBS pricing and risk evalu-
ation purposes? The procedure is as follows. We use the realizations of the
short-term interest rate to generate discount factors for different maturities.
Usually, we need to generate long-term rates as well, such as the 10-year
rate. Such long-term rates can be determined by computing zero-coupon
bond prices. (For some interest rate models, this is easier to do than for
others.) Namely, from those prices, we generate a yield curve. From this
yield curve, we can estimate the long-term rates or forward rates.16
Let us give a speciﬁc example by using the Vasicek and the CIR models
for the short rate. Recall from section 12.4 of Chapter 12 that the Vasicek
model assumes that the short rate r follows the random walk
rt+1 = rt + κ · (µ −rt) + σ · ˜εt.
Similarly, recall from section 12.4.3 that the CIR model assumes that
the short rate r follows the random walk
rt+1 = rt + κ · (µ −rt) + σ · √rt · ˜εt.
Under these assumptions, one can generate paths for the short-term rate
and use them to compute discount factors. One can also derive a closed-
form expression for the price (at any time t) of a zero-coupon bond with
face value of $1 maturing at time T, B(t, T), in terms of rt. The details of
the derivation are beyond the scope of this book, but the formulas turn out
to be:
■In the Vasicek model,
B(t, T) = A(t, T) · e−C(t,T)·rt
where
C(t, T) = 1 −eκ·(T−t)
κ
and
A(t, T) = e
(C(t,T)−T+t)·(κ2µ−σ2/2)
κ2
−σ2·C(t,T)2
4·κ
■In the CIR model,
B(t, T) = A(t, T) · e−C(t,T)·rt

Structuring and Pricing Residential Mortgage-Backed Securities
615
where
C(t, T) =
2 ·

eγ ·(T−t) −1

(γ + κ) ·

eγ ·(T−t) −1

+ 2 · γ
A(t, T) =

2 · γ · e(γ +κ)·(T−t)/2
(γ + κ) ·

eγ ·(T−t) −1

+ 2 · γ
2·κ·µ/σ 2
and
γ =

κ2 + 2 · σ 2
Given a realization of rt, we can plug it into the above formulas,
and determine B(t, T). B(t, T) is the price of a zero-coupon bond with
a face value of 1. Thus, we can interpret the value for B(t, T) as the
discount factor between t and T. We also have
B(t, T) = e−r(t,T)·(T−t)
This allows us to compute the long-term interest rate applicable for
the period (t, T) as17
r(t,T) = −ln(B(t, T))/(T −t)
Thus, we can build the term structure of interest rates. Forward
rates can be computed from the term structure as well. In particular, we
can compute the 10-year interest rate, 10rt in our notation from Chapter
2, at each point in time t, to use in prepayment models.
15.4.3
Putting It All Together
As we explained in the previous two sections, the pricing of an RMBS
requires a prepayment model and an interest rate model. The price of the
RMBS is the expected value of the future cash ﬂows over all generated
scenarios for the interest rates and the corresponding prepayments. The
procedure is as follows:
1. Generate N scenarios for interest rate paths, where a “path” includes
the short interest rate and the corresponding discount factors for 360
months ahead. Record also the corresponding values for a required
long-term rate, such as the 10-year rate.

616
DERIVATIVE PRICING AND USE
For each interest rate path n, n = 1, . . . ,N:
A. At each point in time (360 of them), calculate the expected prepay-
ment using a particular prepayment function. For example, if we use
the modiﬁed Goldman Sachs prepayment function, we will plug in
the estimated 10-year rate r10 at each point in time for each interest
rate path.
B. After calculating the prepayment rates, compute the cash ﬂow CFn(t)
from the mortgage pool for each time t along that interest rate path.
This is a difﬁcult step, as RMBS structures can be incredibly complex.
For pass-through RMBS, we have a speciﬁc formula for CFn(t):18
CFn(t) = MPn(t) + PPn(t) = TPPn(t) + IPn(t)
MPn(t) = SPn(t) + IPn(t)
TPPn(t) = SPn(t) + PPn(t)
where
MPn(t) is the scheduled mortgage payment for month t.
TPPn(t) is the total principal payment for month t.
IPn(t) is the interest payment for month t.
SPn(t) is the scheduled principal payment for month t.
PPn(t) is the principal prepayment for month t.
These quantities are calculated as follows:
MPn(t) = MBn(t −1) ·

WAC/12
1 −(1 + WAC/12)−WAM+t

IPn(t) = MBn(t −1) · (WAC/12)
PPn(t) = SMMn(t) · (MBn(t −1) −SPn(t))
MBn(t) = MBn(t −1) −TPPn(t)
SMMn(t) = 1 −
12
1 −CPRn(t)
where
MPn(t) is the principal mortgage balance of the RMBS at
the end of month t.
WAC is the weighted average coupon rate for the RMBS
(weighted by the balance of each mortgage).
WAM is the weighted average maturity for the RMBS
(weighted by the balance of each mortgage).
SMMn(t) is the single monthly mortality for month t, ob-
served at the end of month t.
CPRn(t) is the conditional prepayment rate for month t,
observed at the end of month t.

Structuring and Pricing Residential Mortgage-Backed Securities
617
2. Calculate the total cash ﬂow over the entire interest rate path as a sum
of the cash ﬂows at each point in time, properly discounted with the
discount factor for that interest rate path at that time plus an appropriate
risk-adjusted spread K.
3. Calculate the average of the cash ﬂows over the N interest rate paths.
It is clear from the above algorithm that once we know CPR(t) for each
time and each interest rate path, everything else can be calculated. CPR(t)
will, of course, be different depending on the prepayment model used.
This procedure is valid for pricing more complex types of RMBSs as
well; we just need to be careful about estimating the cash ﬂows CF(t). For
example, in a sequential-pay structure, we apply the procedure to estimate
the cash ﬂows for classes A, B, C, and so on separately. This determines the
price for each class.
15.4.4
Further Analysis
In the process of evaluating the RMBS price by simulation, we obtain a
variety of other information that can be useful.
Distribution of Path Values
The average of the cash ﬂows obtained along
the N simulated interest rate paths gives us the price of the RMBS. However,
we also obtain the distribution of cash ﬂows, that is, N points from the
probability distribution of cash ﬂow values. This allows us to observe the
variability in the cash ﬂows and to decide how much conﬁdence we can have
in the estimate of the RMBS price obtained from the simulation.
Average Life
In the process of simulating the price of an RMBS, we work
with estimates of the average life of the RMBS along each interest rate path.
This allows us to obtain the probability distribution of the average life,
which is useful for risk management purposes.
Option-Adjusted Spread
Traders like to compute a quantity called the
option-adjusted spread (OAS) that allows them to have an estimate of the
spread of the yield of the RMBS over Treasuries when the optionality has
been taken into account. The OAS is the spread above the risk-free rate
that makes the price of the RMBS equal to the observed market price. In
the Monte Carlo simulation, it is the spread that makes the average present
value of the RMBS cash ﬂows along all the interest rate paths equal to the
observed market price.

618
DERIVATIVE PRICING AND USE
15.4.5
Improving the Degree of Accuracy
with Variance-Reduction Methods
In Chapter 4, we discussed the issue of how many trials are needed in a
simulation. The short answer is that this is not known. However, we can
decide if the number of paths we generated in the simulation resulted in an
estimate of the quantity of interest with small variance (i.e., with sufﬁcient
accuracy), and increase the number of generated paths if the estimate is too
variable.19 A typical RMBS is priced using between 512 and 1,024 paths.
However, this number can be brought down to as few as 128 or 64 paths by
using variance reduction methods. The actual variance reduction methods
used in practice are proprietary, but Akesson and Lehoczky (2000) describe
the basics of how to apply quasi–Monte Carlo number sequences in the
context of RMBS pricing.
To price an RMBS, we need to simulate 360 monthly observations for
interest rates N times. Therefore, we are dealing with generating N ran-
dom points in a 360-dimensional cube, that is, a 360-dimensional problem.
Quasi–Monte Carlo methods (low discrepancy sequences) are appropriate in
this situation because they can generate points that can cover the space a lot
better than purely random points, thus necessitating fewer points to achieve
the same degree of accuracy as random number generators. It is important
to keep in mind, though, that not all low discrepancy sequences outperform
traditional Monte Carlo simulation. The selection of the speciﬁc low dis-
crepancy sequence to use must be accompanied by a lot of tests. Akesson
and Lehoczky (2000) use the Sobol low discrepancy sequence, together with
other simulation speed enhancements, such as principal components20 and
Brownian bridge21 constructions for the interest rate paths. They note a
substantial improvement in the speed of RMBS pricing algorithms.
15.5
USING SIMULATION TO ESTIMATE
SENSITIVITY OF RMBS PRICES TO
DIFFERENT FACTORS
Investors in RMBSs are exposed to many different types of risk, such as in-
terest rate risk, credit risk, and model risk. The sensitivity of the RMBS price
to these factors is typically evaluated by simulation. This section discusses
risk assessment in more detail.
15.5.1
Interest Rate Risk
One of the main risks of RMBSs is interest rate risk. MBSs are ﬁxed income
securities and, as such, are very sensitive to shifts in yields. Similarly to

Structuring and Pricing Residential Mortgage-Backed Securities
619
simpler ﬁxed income securities, RMBS prices fall when interest rates rise,
and RMBS prices rise when interest rates fall. However, recall that RMBSs
in effect have embedded options; that is, mortgage holders have the option
to reﬁnance if interest rates fall. This has an effect on the life of the RMBSs.
Hence, classical measures of interest sensitivity such as Macaulay duration
and modiﬁed duration do not work well in the case of RMBSs.
Furthermore, in the case of plain vanilla bonds (without embedded
options) duration measures underestimate price gains and overestimate price
losses. In the case of a noncallable bond, this estimation error is due to the
positive convexity and favors the investor. However, the opposite is the case
for RMBSs, which have prepayment risk. Duration overestimates price gains
and underestimates price losses. This is due to negative convexity, and works
against the investor. The more prepayment risk a security has, the worse the
estimation error will be and, in turn, the more negative its convexity will be.
That is why in the case of RMBSs, an option-adjusted duration is used.22
The option-adjusted duration is computed by assuming changes of equal
amounts (usually, increments of 50 basis points to 100 basis points) up or
down, and evaluating the new RMBS prices. The sensitivity of the RMBS
price computed in this way is the option-adjusted duration.
Other measures of interest rate sensitivity that are sometimes quoted
are the average life (also called weighted average life, or WAL), which is
an average time to receive back principal on the underlying loans, and
weighted average maturity (WAM), which is weighted average maturity of
the underlying loans. These can be evaluated directly, without generating
scenarios. However, they are less useful as measures of sensitivity to interest
rates because they do not take into consideration the inherent optionality in
RMBSs.
15.5.2
Credit Risk
The credit risk associated with one type of agency RMBSs, those issued
by Ginnie Mae, is minimal—Ginnie Mae MBS can be basically treated as
credit-risk-free securities because they are backed by an explicit federal guar-
antee. There is uncertainty as to the credit risk of securities issued by the
two government sponsored enterprises—Fannie Mae and Freddie Mac. Al-
though both have a line of credit with the Treasury, the credit line is not
sufﬁcient to meet all obligations. There is no explicit or implicit government
guarantee in the case of nonagency RMBSs. Private-label RMBSs are rated
by rating agencies in order to incorporate information about credit risk.
Considerations for their credit risk are used when pricing such RMBSs by
simulating the spread over the risk-free U.S. Treasury yield curve in addition
to the U.S. Treasury yield curve itself.

620
DERIVATIVE PRICING AND USE
15.5.3
Model Risk
Virtually all security pricing models are exposed to model risk. Model risk is
the risk of using an incorrect model.23 In the case of RMBSs, the assumptions
in the prepayment model can make an enormous difference in the RMBS
price estimate and risk evaluation. There is no way to ﬁx this, but it is
important to conduct sensitivity analysis and scenario analysis that can raise
a ﬂag if the RMBS price and risk estimates are very sensitive to assumptions
in the model.
15.6
STRUCTURING RMBS DEALS USING
DYNAMIC PROGRAMMING
So far, we have taken the RMBS structure as given, and discussed how
to price it and evaluate its sensitivity with respect to different factors. We
mentioned that the procedure for determining the value of the RMBS by sim-
ulation is the same for all types of RMBSs, but that estimating the cash ﬂow
along each interest rate path is challenging. The cash ﬂow is found according
to the principal repayment and interest distributions rules of the deal. In
the case of CMOs, a structuring model is needed. In any analysis of CMOs,
one of the major stumbling blocks is getting a good CMO structuring deal.
Dynamic programming and integer programming methods can be used
to approach the problem of optimal structuring of a CMO. From the per-
spective of the CMO issuer, for example, the tranches could be designed in
many different ways. The issuers make money on the difference between the
interest collected by the mortgage holders whose mortgages are in the pool,
and the interest paid out to investors who buy the RMBS. While the mort-
gage holders pay 10- and 30-year interest rates on the principal outstanding,
some tranches in a CMO pay out two-, four-, six-, and eight-year rates plus
a spread. A natural question that arises is if there is a way to design a CMO
so that the proﬁt to the issuer is the largest. How many tranches should there
be? How large should the tranches be? What coupon rates can the issuer
afford to pay to the RMBS investors?
Cornuejols and Tutuncu (2007) describe a dynamic programming algo-
rithm for answering these questions for a sequential-pay MBS. We provide
some discussion of their approach next. The problem formulation that is
described is one of private-label CMOs, where credit quality is an issue.24
When structuring a CMO, several constraints need to be taken into
consideration. First, we need to make sure that the payments over the life
of the CMO can service the promised payments to the bond holders under
different scenarios. Two extreme such scenarios include the case of full
early prepayments and no early prepayments. Second, we need to estimate

Structuring and Pricing Residential Mortgage-Backed Securities
621
the average life of each tranche.25 The price of the tranche will then be
determined based on the rate of a Treasury bond with the same duration,
and an appropriate spread which depends on the tranche’s credit rating.
Third, we need to calculate the required credit support, or buffer, for each
tranche as a function of the average life of the tranche and rating. The
required buffer is computed as
Average life of tranche · Expected default rate · Loss multiple
and the size of the buffer determines the credit rating that will be assigned
to a tranche. The larger the buffer, the more collateral is “behind” the
tranche. If the buffer of a particular tranche is large, the CMO will have
to experience a lot of defaults before payments to that tranche are stopped.
The last tranche in the CMO has no buffer.26
The loss multiple is a multiplier that is set by the rating agencies. For
example, a tranche with AAA rating must have a buffer equal to six times
the expected default rate, so its loss multiple is six.
Finally, the coupon paid out on each tranche is estimated based on
the tranche’s credit rating and rates on comparable securities. Spreads on
corporate bonds with similar credit ratings typically provide a benchmark.
Suppose we would like to structure a CMO with four tranches. The
objective is to maximize the proﬁts from the issuance by choosing the size
of each tranche. A dynamic programming algorithm can be developed to
ﬁnd the optimal sizes. As we mentioned in section 5.6.3 of Chapter 5, one
of the most difﬁcult problems in dynamic programming is identifying the
states and the stages. In this case, the states are t, the indices of the months,
and the stages are k, the number of tranches up to month t. This enumerates
all possible tranches—there are t possible maturities for the tranches, and k
possible starting dates for the tranche (k ≤t). Tranche (k, t) starts amortizing
at the beginning of month k and ends at the end of month t.
Let Tkt be the present value of the payments on tranche (k, t). (Tkt can
be computed exactly for every pair (k, t).) Let f(k, t) denote the minimum
present value of total payments to bondholders in months 1 through t when
the CMO has k tranches up to year t. It is easy to see that f(1, t) = T1t. (If
there is only one tranche up to year t, then there is nothing to minimize—we
know the present value of that tranche.) For larger values of k, the dynamic
programming recursion can be written as follows:
f (k, t) =
min
j=k−1,...t−1

f (k −1, j) + Tj+1,t
	
For example, if k = 2 and t = 5, we compute f(1, j) + Tj+1,5 for each
j = 1, 2, 3, 4, and take the minimum. Note that for k = 4, there is no need

622
DERIVATIVE PRICING AND USE
to compute the minimum of thousands of possible combinations of four
tranches. We just need to use the value f(3, j) found at the previous stage,
and enumerate over the size of the fourth tranche.
In the example of an RMBS (“Structure 1”) from section 15.3.3, we had
k = 4 and t = 358. Suppose that we would like to ﬁnd the optimal size of
the four tranches. (Assume also that this is a nonagency CMO.) We would
compute f(4,358), which would give us the minimum cost for structuring
the CMO with four tranches. To ﬁnd out what the actual tranche sizes are,
we need to backtrack from the last stage and identify how the minimum was
achieved at each stage.
SUMMARY
■Securitization is used to create various structured products referred to
as asset-backed securities.
■An asset-backed security is a debt instrument backed by a pool of loans
or receivables. The cash ﬂow from the pool of loans is used to satisfy
the obligations of the debt instruments.
■MBSs are a type of asset-backed securities which are backed by pools
of mortgages.
■An RMBS is an MBS backed by a pool of residential mortgage loans; a
CMBS is backed by a pool of commercial mortgage loans.
■RMBSs can be agency RMBSs or private-label RMBSs. Agency RMBSs
are backed by three government-related entities (Ginnie Mae, Fannie
Mae, and Freddie Mac).
■There are three types of agency RMBSs: pass-through securities, stripped
MBSs, and collateralized mortgage obligations (CMOs).
■In a mortgage pass-through security, the monthly cash ﬂow from the
pool of mortgage loans is distributed on a pro rata basis to the certiﬁcate
holders.
■A stripped MBS is created by altering the distribution of principal and
interest from a pro rata distribution to an unequal distribution. In the
most common type of stripped MBS, all of the interest is allocated to
one class—the interest-only class, and all of the principal to the other
class—the principal-only class.
■An agency CMO is a security backed by a pool of mortgage pass-
through securities. Agency CMOs are structured so that there are several
classes of bonds (called tranches) with varying maturities. The principal
payments from the underlying pool of pass-through securities are used
to retire the bonds on a priority basis as speciﬁed in the prospectus.
■There are numerous types of agency CMO bonds, including sequential-
pay bonds, PAC bonds, and support bonds.

Structuring and Pricing Residential Mortgage-Backed Securities
623
■Private-label RMBSs are issued by any entity other than Ginnie Mae,
Fannie Mae, or Freddie Mac. Because of the credit risk associated with
private-label RMBSs, they require credit enhancements to provide dif-
ferent degrees of credit protection against defaults on the pool of assets
backing a transaction.
■The uncertainty about the cash ﬂow attributable to prepayments is called
prepayment risk and is the major risk in agency RMBSs.
■The pricing of RMBSs involves the estimation of the present value of
the uncertain future cash ﬂows, and presents a number of challenges.
There are two building blocks to RMBS pricing models: an interest rate
model, which determines the discount factor, and a prepayment model,
which determines the behavior of the mortgagor.
■Prepayments depend on interest rates. Moreover, they depend on the his-
tory of interest rates, which makes RMBSs path-dependent, and makes
their pricing challenging. Simulation is the preferred method for han-
dling path dependency.
■Traditionally, prepayment models have been based on econometrics—
they often include macroeconomic factors, such as the health of the
economy or the housing market activity, or identify a prepayment pat-
tern as a function of speciﬁc characteristics of the individual mortgages
in the pool. Other models are based on option theory, and assume that
the borrower acts optimally to maximize the value of the option to pre-
pay the mortgage. The latter models are more complex, and less widely
used in practice.
■Estimating the price of a RMBS involves simulating a particular num-
ber of interest rate paths. Along each path, the expected prepayments
are simulated at each point in time (each month), and the cash ﬂows
are evaluated. The cash ﬂows along that interest rate path are then dis-
counted using the simulated interest rates plus an appropriate spread.
The average of the total cash ﬂows over all interest rate paths is the
price of the RMBS.
■Simulation is an effective way to price the RMBS, but it can be very
slow because of the large dimension of the problem. Quasi–Monte Carlo
methods have shown promise for reducing the necessary number of gen-
erated paths and the amount of computational time without sacriﬁcing
accuracy.
■As a by-product of estimating the price of a RMBS by simulation, we
obtain other useful information, such as the distribution of RMBS values
for different interest rate scenarios, and the distribution of the average
life of the RMBS.
■Simulation is useful also for estimating the sensitivity of the price of
the RMBS to different factors, such as interest rates, credit events, and
model risk.

624
DERIVATIVE PRICING AND USE
■Dynamic programming can be used to structure CMOs optimally so
as to maximize the proﬁt for the issuer while satisfying a number of
constraints.
NOTES
1. Residential mortgages are loans to individual households. Commercial mort-
gages are loans on income-producing property, such as multifamily proper-
ties (i.e., apartment buildings), ofﬁce buildings, industrial properties (including
warehouses), shopping centers, hotels, and health care facilities (i.e., senior
housing care facilities).
2. David Bowie’s music rights were the ﬁrst such securitization in 1997. The $55
million of securities issued were backed by the current and future revenues
of Bowie’s ﬁrst 25 music albums (287 songs) recorded prior to 1990. These
bonds, popularly referred to as “Bowie bonds,” were purchased by Prudential
Insurance Company and had a maturity of 10 years. When the bonds matured
in 2007, the royalty rights reverted back to David Bowie.
3. The PSA and the CPR approaches are not mutually exclusive alternatives but
are mostly used together—the PSA to explain the ramp-up of the expected
CPR over the initial months of seasoning. Thereafter, the pool undergoes a
constant CPR.
4. The weighted average coupon rate is obtained by weighting the mortgage rate of
each mortgage loan in the pool by the amount of mortgage balance outstanding.
5. The weighted average maturity is obtained by weighting the remaining number
of months to maturity for each mortgage loan in the pool by the amount of
mortgage balance outstanding.
6. The aggregate mortgage payment is the payment that will amortize (i.e., reduce
to 0) the outstanding loan, after accounting for interest and principal payments.
The formula for computing the mortgage payment needed to bring the balance
to zero after T years is
P ·
I
(1 −(1 + I))T
where P is the outstanding principal, and I is the interest rate (in decimal). In
our example, we are working with months (rather than years). To compute
the aggregate mortgage payment for the ﬁrst month, for example, we use the
formula
660,000,000 ·
(0.06/12)
(1 −(1 + (0.06/12)))358
7. In other words, the average life in years is obtained by multiplying the entries
in column 8, Total Principal, by the corresponding entries in column 1, Month,

Structuring and Pricing Residential Mortgage-Backed Securities
625
then dividing by the collateral ($660 million) and by 12 to convert the number
to years instead of months.
8. See Chapter 2 for an introduction to credit ratings.
9. See section 14.9 in Luenberger (1998) for an example of how a binomial tree
for the process followed by interest rates can be applied for pricing a simple
RMBS. The example points out the difﬁculty of using binomial lattices, and the
need to employ nonrecombining binomial trees. The dimension of the problem
then quickly becomes computationally prohibitive.
10. See Chapter 14.
11. Recall that in the case of nonagency RMBS, the mortgages do not have federal
guarantees.
12. The modiﬁed Goldman Sachs model was developed by Richard and Roll (1989)
and modiﬁed by the OTS. Typically, the details of prepayment models by
banks are proprietary. The Goldman Sachs model as formulated by Richard
and Roll has probably changed dramatically over the past 20 or so years since
the article appeared.
13. As we saw in section 12.4.3 of Chapter 12, the Vasicek and the CIR model
assume that the short-term interest rate is mean-reverting.
14. See Longstaff and Schwartz (1992).
15. See Hull (2008).
16. See Chapter 2 for how to compute forward rates off the given term structure of
interest rates.
17. We simply took logarithms of both sides of the equation.
18. See Chapter 19 in Fabozzi (1993).
19. Note that this criterion does not tell us how good the estimate is relative to the
truth; only how good it is relative to the model we are using.
20. See Chapter 11.
21. A Brownian bridge construction is the generation of a sequence of values for
a Brownian motion in a not necessarily sequential mode after generating the
end points (the ﬁrst point and the last point in the process) ﬁrst. The remaining
points are then ﬁlled out in different order depending on the variance reduction
method or low discrepancy sequence used. See section 12.6 for a deﬁnition of
Brownian motion, and Glasserman (2004) for more details on Brownian bridge
construction.
22. See section 2.6.5 of Chapter 2 and Goldman Sachs Asset Management (2007).
23. Note that model risk is different from estimation error. The latter assumes that
the model is correct, but the estimates of the inputs to the model are inaccurate.
24. See section 15.3.4.
25. See sections 15.3.1 and 15.3.2 for how to estimate the average life of a tranche.
26. See Exhibit 15.7.


CHAPTER16
Using Derivatives in
Portfolio Management
A
s mentioned in Chapter 13, there are many applications of ﬁnancial
derivatives, but the two main reasons for including them in an investor’s
portfolio are (1) risk management and (2) return enhancement. Risk man-
agement refers to strategies whose goal is to control risk with hedging as a
special case. Return enhancement refers to investment strategies that seek
to capitalize on the direction in which the underlying uncertainties will be
resolved or take advantage of discrepancies in pricing to make proﬁt. This
is more popularly referred to as “taking a view” on some factor that is
expected to drive returns. Prior to the existence of futures, for example, an
investor who wanted to take a view on the direction of future stock prices
had to buy or short individual stocks to do it. Now, one can buy futures on
entire market indices, and the transaction costs of such strategies are a lot
smaller than the transaction costs of individual stock purchases.
The decision of whether to use derivatives in portfolio construction is
not unlike any other business decision—it requires careful analysis. Sanford
and Borge (1993) suggested a process that investment managers go through
before deciding whether to make derivatives a part of their portfolio. They
outlined some necessary steps:
■Deﬁne the investment process in terms of risk management.
■Establish clear investment objectives and acceptable risk tolerance level.
■Create a set of boundary conditions for the level of risk.
■Assess the full range of possible outcomes from using derivatives.
■Assess the impact of using derivatives on the portfolio’s risk proﬁle.
■Establish monitoring protocol to measure risk.
■Develop an adjustment response mechanism.
This chapter provides some examples of equity and ﬁxed income in-
vestment strategies with derivatives, and explains the use of simulation for
627

628
DERIVATIVE PRICING AND USE
evaluating the effect of including derivatives on the portfolio risk proﬁle.
The list of investment strategies involving derivatives provided here is by no
means exhaustive—there is an inﬁnite variety of possible uses of derivatives
for risk management or return enhancement purposes.
16.1
USING DERIVATIVES IN EQUITY
PORTFOLIO MANAGEMENT
Investors can use the listed options market to address a range of investment
problems. In this section, we consider the use of calls, puts, and combina-
tions in the context of the investment process, which could involve (1) risk
management or (2) return enhancement. Recall from the discussion in sec-
tion 13.1.2 of Chapter 13 that the distinction between options and futures
is that the former have nonlinear payoffs that will fundamentally alter the
risk proﬁle of an existing portfolio. The following basic strategies can be
used to establish a hedged position in an individual stock or a portfolio.
16.1.1
Risk Management Strategies
Risk management in the context of equity portfolio management focuses on
price risk. Consequently, the strategies discussed in this section in some way
address the risk of a price decline or a loss due to adverse price movement.
Options can be used to create asymmetric risk exposures across all or part
of the core equity portfolio. This allows the investor to hedge downside risk
at a ﬁxed cost with a speciﬁc limit to losses should the market turn down.
The basic risk management objective is to create the optimal risk exposure
and to achieve the target rate of return. Options can help accomplish this
by reducing risk exposure. The various risk management strategies will
also affect the expected rate of return on the position unless some form of
inefﬁciency is involved. This may involve the current mix of risk and return
or be the result of the use of options. Below we discuss two risk management
strategies: protective put and collar.
Protective Put Strategies
Protective put strategies are valuable to port-
folio managers who currently hold a long position in the underlying security
or investors who desire upside exposure and downside protection by using
put options. The motivation is to hedge some or all of the total risk. In-
dex put options hedge mostly market risk, while equity put options hedge
the total risk associated with a speciﬁc stock. This allows portfolio man-
agers to use protective put strategies for separating tactical and strategic

Using Derivatives in Portfolio Management
629
strategies. Consider, for example, a portfolio manager who is concerned
about exogenous or nonﬁnancial events increasing the level of risk in the
marketplace. Furthermore, assume the portfolio manager is satisﬁed with
the core portfolio holdings and the strategic mix. Put options could be em-
ployed as a tactical risk reduction strategy designed to preserve capital and
still maintain strategic targets for portfolio returns. Protective put strategies
may not be suitable for all portfolio managers, but the value of protective
put strategies is that they provide the investor with the ability to invest
in volatile stocks with a degree of desired insurance and unlimited proﬁt
potential over the life of the strategy.
The protective put involves the purchase of a put option combined with
a long stock position. This is the equivalent of a position in a call option on
the stock combined with the purchase of risk-free bond. In fact, the combined
position yields the call option payoff pattern described in section 13.1.2 of
Chapter 13. The put option is comparable to an insurance policy written
against the long stock position. The option price is the cost of the insurance
premium and the amount the option is out-of-the-money is the deductible.
Just as in the case of insurance, the deductible is inversely related to the
insurance premium. The deductible is reduced as the strike price increases,
which makes the put option more in-the-money or less out-of-the-money. A
higher strike price causes the put price to increase and makes the insurance
policy more expensive.
The proﬁtability of the strategy from inception to termination can be
expressed as follows:
Proﬁt = Ns · (ST −St) + Np · (max{K −ST, 0} −P)
where
Ns is the number of stocks.
Np is the number of put options.
P is the price of the put.
St is the current stock price.
ST is the stock price at maturity.
K is the strike price.
The proﬁtability of the protective put strategy is the sum of the proﬁt
from the long stock position and the put option. If held to expiration, the
minimum payout is the strike price (K) and the maximum is the stock price
(ST). If the stock price is below the strike price of the put option at expiration,
the investor exercises the option and sells the stock to the option writer for K.

630
DERIVATIVE PRICING AND USE
If we assume that the number of shares Ns is equal to Np, the number of put
options, then the loss would amount to
Proﬁt = ST −St + K −ST −P = K −St −P
Notice that the price of the stock at the termination date does not enter into
the proﬁt equation.
For example, if the original stock price St was $100, the strike price K
was $95, the closing stock price ST was $80, and the put price P was $4,
then the proﬁt would equal
Proﬁt = $95 −$100 −$4 = −$9
Without the protective put strategy, the manager would have realized a loss
of $20 (= $100 – $80).
If, on the other hand, the stock closed up $20, then the proﬁt would be
Proﬁt = ST −St −P = $120 −$100 −$4 = $16
The cost of the insurance is 4% in percentage terms, and manifests itself
as a loss of upside potential. If we add transaction costs, the shortfall is
increased slightly. The maximum loss, however, is the sum of the put pre-
mium and the difference between the strike price and the original stock price,
which is the amount of the deductible. The problem arises when the portfolio
manager is measured against a benchmark and the cost of what amounted
to an unused insurance policy causes the portfolio to underperform the
benchmark. Equity managers can use stock selection, market timing, and
options to reduce the cost of insurance. The break-even stock price is given
by the sum of the original stock price and the put price. In this example, the
break-even stock price is $104, which is the stock price necessary to recover
the put premium. The put premium is never really recovered because of the
performance lag. This lag falls in signiﬁcance as the return increases.
A graphical depiction of a protective put strategy is provided in Ex-
hibit 16.1. The ﬁgure shows the individual long stock and long put positions
and the combined impact, which is essentially a long call option. The max-
imum loss is the put premium plus the out-of-the-money amount, which is
the insurance premium plus the deductible.
Collar Strategies
An alternative to a protective put is a collar. A collar
strategy consists of a long stock, a long put, and a short call. By varying the
strike prices, a range of trade-offs among downside protection, costs, and
upside potential is possible.

Using Derivatives in Portfolio Management
631
–60
–40
–20
0
20
40
60
40
60
80
100
120
140
160
Long put
Long stock
Protective put
EXHIBIT 16.1
Example of a protective put strategy.
When the long put is completely ﬁnanced by the short call position (i.e.,
the put premium is paid for by the proceeds from shorting the call), the
strategy is referred to as a zero-cost collar.
Collars are designed for investors who currently hold a long equity
position and want to achieve a level of risk reduction. The put exercise
price establishes a ﬂoor and the call exercise price a ceiling. An example of
the resulting payout pattern is shown in Exhibit 16.2. The graph includes
the components of the strategy and the combined position. This particular
example is a near zero-cost collar. In order to pay for the put option, a call
option was written with a strike price of $110. Selling this call option pays
for the put premium, but caps the upside to 10.23%. The ﬂoor completes
the collar and limits downside losses to the out-of-the money amount of the
put option. In order to provide full insurance, an at-the-money put option
would cost slightly above 6%, which would be paid for by limiting upside
potential returns to 5%. Portfolio managers can determine the appropriate
trade-offs and protection consistent with their objectives.
The proﬁt equation for a collar is simply the sum of a long stock position,
a long put, and a short call:
Proﬁt = Ns · (ST −St) + Np · (max{Kp −ST, 0} −P)
−Nc · (max{ST −Kc, 0} −C)
where Kp and Kc are the strike prices of the put and the call, respectively,
Nc is the number of calls, and C is the call premium.

632
DERIVATIVE PRICING AND USE
–60
–40
–20
0
20
40
60
40
60
80
100
120
140
160
Short call
Long put
Long stock
Collar
EXHIBIT 16.2
Example of a collar strategy.
16.1.2
Return Enhancement Strategies
Options can be used for return enhancement. Here we describe the most
popular return enhance strategy: covered call strategy. Other return en-
hancement strategies include covered combination strategy and volatility
valuation strategy.
We introduced covered call strategies in the last case in the practice
section for Chapter 13. There are many variations of covered call strategies.
If the portfolio manager owns the stock and writes a call on that stock,
the strategy has been referred to as an overwrite strategy. If the strategy
is implemented all at once (i.e., buy the stock and sell the call option),
it is referred to as a buy-write strategy. The essence of the covered call
is to trade price appreciation for income. The strategy is appropriate for
slightly bullish investors who don’t expect much out of the stock and want
to produce additional income. These are investors who are willing either
to limit upside appreciation for limited downside protection or to manage
the costs of selling the underlying stock. The primary motive is to generate
additional income from owning the stock.
Although the call premium provides some limited downside protec-
tion, the covered call is not an insurance strategy because it has signiﬁcant
downside risk. Consequently, investors should proceed with caution when
considering a covered call strategy.
A covered call is less risky than buying the stock because the call pre-
mium lowers the break-even recovery price. The strategy behaves like a long
stock position when the stock price is below the strike price. On the other

Using Derivatives in Portfolio Management
633
–60
–40
–20
0
20
40
60
40
60
80
100
120
140
160
Short call
Long stock
Covered call
EXHIBIT 16.3
Example of a covered call strategy.
hand, the strategy is insensitive to stock prices above the strike price and
is therefore capped on the upside. The maximum proﬁt is given by the call
premium and the out-the-money amount of the call option.
The payout pattern diagram is presented in Exhibit 16.3. It includes the
long stock, short call, and covered call positions.
16.2
USING DERIVATIVES IN BOND
PORTFOLIO MANAGEMENT
Derivatives are widely used in bond portfolio management for controlling
different types of risk, such as interest rate and credit risk. We describe some
applications next.
16.2.1
Controlling Interest Rate Risk
As we explained in Chapter 10, investment managers with strong expecta-
tions about the direction of the future course of interest rates will adjust
the duration of their ﬁxed income portfolios so as to capitalize on their
expectations. It is easy to see that a money manager who expects rates to
increase will shorten duration; a money manager who expects interest rates
to decrease will lengthen duration.1 While this can be achieved by altering
the portfolio composition, using derivative contracts provides a quicker and
less expensive means for changing the interest rate sensitivity, or duration,
of a portfolio (on either a temporary or permanent basis).

634
DERIVATIVE PRICING AND USE
Using Futures
A formula to approximate the number of futures contracts
necessary to adjust the portfolio duration to some target duration is
Target portfolio duration −Current portfolio duration
Dollar duration of the futures contract
· Market value of
the portfolio
The dollar duration of the futures contract is the dollar price sensitivity
of the futures contract to a change in interest rates.
Notice that if the asset manager wishes to increase the portfolio’s cur-
rent duration, the numerator of the formula is positive. This means that
futures contracts will be purchased. That is, buying futures increases the
duration of the portfolio. The opposite is true if the objective is to shorten
the portfolio’s current duration: The numerator of the formula is negative
and this means that futures must be sold. Hence, selling futures contracts
reduces the portfolio’s duration.
Hedging is a special case of risk control where the target duration
sought is zero. If cash and futures prices move together, any loss real-
ized by the hedger from one position (whether cash or futures) will be
offset by a proﬁt on the other position. When the net proﬁt or loss from
the positions is exactly as anticipated, the hedge is referred to as a perfect
hedge.
In bond portfolio management, typically the bond to be hedged is not
identical to the bond underlying the futures contract and therefore there is
cross hedging. This may result in substantial risk, referred to as basis risk.2
For example, suppose that on December 24, 2007, a bond portfolio
manager wants to hedge a position in a Procter & Gamble (P&G) 5.55%
of 3/5/2037 bond that he anticipates selling on March 31, 2008. The par
value of the P&G bonds is $10 million. The portfolio manager decides
that he will use the March 2008 Treasury bond futures to hedge the bond
position, which he can settle on March 31, 2008. Because the portfolio
manager is trying to protect against a decline in the value of the P&G
bonds between December 24, 2007, and the anticipated sale date, he will
short (sell) a number of March 2008 Treasury bond futures contracts. Be-
cause the bond to be hedged is a corporate bond and the hedging instru-
ment is a Treasury bond futures contract, this is an example of a cross
hedge.
Using Options
Interest rate options can be written on a ﬁxed income se-
curity or an interest rate futures contract. The former options are called
options on physicals and the latter are called futures options. The most
liquid exchange-traded option on a ﬁxed income security is an option on

Using Derivatives in Portfolio Management
635
Treasury bonds traded on the Chicago Board of Trade (CBOT). Options on
interest rate futures have been far more popular than options on physicals.
However, portfolio managers have made increasingly greater use of over-
the-counter (OTC) options. Typically they are purchased by investors who
want to hedge the risk associated with a speciﬁc security or index. Besides
options on ﬁxed income securities, there are OTC options on the shape of
the yield curve or the yield spread between two securities.
Buying puts on Treasury futures options is one of the easiest ways
to purchase protection against rising interest rates. The mechanics of this
strategy involve more background in ﬁxed income than we have given in
this book.3
Using Swaps
Hedging bonds with interest rates swaps is similar to hedging
bonds with Treasury notes or futures contracts. To hedge a long position in
a bond, an asset manager needs to establish a pay-ﬁxed swap position since
changes in the value of a swap are inversely related to changes in the value
of the bond being hedged. In a pay-ﬁxed swap position, which is analogous
to a short-bond position, the asset manager pays a ﬁxed rate to receive a
ﬂoating rate. In designing a hedge using interest rate swaps, the maturity of
the interest rate swap should match the maturity of the instrument that is
used as the pricing reference for the security being hedged. This is analogous
to hedging in the Treasury market.
For example, if a two-year corporate bond is priced relative to the two-
year Treasury, the corporate bond’s price changes as yield spreads change
and as the yield on the two-year Treasury changes. The appropriate swap
hedge for this corporate bond is a two-year swap since it is also priced
relative to the two-year Treasury. A two-year swap’s value changes as swap
spreads change and as the two-year Treasury’s yield changes. As a result of
using a two-year swap to hedge the corporate bond, the interest rate risk of
the two-year corporate bond that is attributable to movements in two-year
Treasury yields can be mitigated. To the extent that the two-year corporate
bond’s yield spread is correlated to two-year swap spreads, spread risk also
may be mitigated.
Usually, bonds are hedged in the cash market using Treasury securities
or in the futures markets with Treasury futures. The Treasury market can
provide effective and similar protection as interest rate swaps when hedging
against interest rate risk. The advantage of the Treasury market is that it is
a highly liquid market with very small bid/offer costs, especially in on-the-
run maturities. It is also easy to enter into and liquidate Treasury positions
quickly and efﬁciently. In contrast, interest rate swaps, although liquid, have
higher bid/offer costs (typically one basis point in yield) and are more time
consuming to enter and exit. Since swaps are customized contracts between

636
DERIVATIVE PRICING AND USE
two parties and are not exchange traded, they cannot be sold and actually
have to be terminated, which is time consuming and can be less efﬁcient.
Alternatively, a swap position can be effectively terminated by entering into
an opposite position in another interest rate swap; however, this strategy
is not efﬁcient. For short-term hedging purposes, Treasuries may be more
desirable hedge instruments.
Many times in the hedging context, however, hedging in the Treasury
market may be expensive if a Treasury security that is on “special” or if an
off-the-run Treasury needs to be utilized in the hedge. Interest rate swaps
can be cheaper alternatives in these cases.
Swaps have other advantages over Treasury securities. Swaps are off-
balance-sheet instruments, unlike Treasury securities, and therefore should
not affect the capital structure. In addition, to the extent that swap spreads
are correlated with the spread of the security being hedged, an interest rate
swap will provide some protection against spread risk, unlike both Treasury
securities and Treasury futures contracts. Another advantage of an interest
rate swap is that, because it is a structured agreement, call options and
amortization can be embedded into a swap. This is particularly useful when
hedging amortizing and callable securities.
The use of futures in the hedging context exposes the hedged portfolio
to basis risk. Thus, when hedging a security that is priced relative to an on-
the-run Treasury with a futures contract, there is the risk that movements in
futures prices will not fully hedge price movements in the bond. An interest
rate swap does not have the basis risk that is inherent in a futures contract
since on-the-run swaps are priced relative to on-the-run Treasuries. From
a basis risk standpoint, interest rate swaps are better hedging instruments
than futures contracts.
16.2.2
Managing Credit Risk
Credit risk can be effectively managed by the purchase of credit deriva-
tives. Consider, for example, a credit default swap (CDS). As we explained
in Chapter 13, a CDS provides the buyer with insurance should a prespec-
iﬁed credit event, such as a default of the underlying, occur. This is in fact
the most obvious way for an asset manager to use a CDS—to acquire credit
protection for the holding of a credit name in the portfolio. The question is
why doesn’t the asset manager just sell the bonds? There are two reasons.
First, the market for corporate bonds is not very liquid. The asset manager
may ﬁnd it beneﬁcial to acquire protection rather than sell the bond when
there is poor liquidity. Second, there may be a tax reason for doing so. For
example, the asset manager may have to hold a corporate bond for, say,
two months in order to beneﬁt from a favorable capital gains treatment.

Using Derivatives in Portfolio Management
637
A CDS can be used to provide protection against credit risk during that
two-month period.
If an asset manager wants to purchase the obligation of a corporate
entity (i.e., gain long exposure), then the most obvious way to do so is to
purchase the bond in the cash market. However, as just noted, because of
the illiquidity of the corporate bond market, there may be better execution
by transacting in the CDS market. More speciﬁcally, the selling of credit
protection on a corporate entity provides long credit exposure to that entity.
To understand why, consider what happens when an asset manager sells
credit protection on a reference entity. The asset manager receives the swap
premium and if there is no credit event, the swap premium is received over
the life of the CDS contract. However, this is equivalent to buying the bond
of the corporate entity. Instead of receiving coupon interest payments, the
asset manager receives the swap premium payments. If there is a credit event,
then the asset manager under the terms of the CDS must make a payment to
the credit protection buyer. However, this is equivalent to a loss that would
be realized if the bond was purchased. Hence, selling credit protection via a
CDS is economically equivalent to a long position in the reference entity.
Suppose that an asset manager wants to short a corporate bond because
it is believed that the corporation is going to experience a credit event that
will cause a decline in the value of the bond. In the absence of a CDS, the
asset manager would have to short the bonds in the cash market. However,
it is extremely difﬁcult to short corporate bonds. With a liquid CDS, it is
easy effectively to short the bond of a corporate entity. Recall that shorting a
bond involves making payments to another party, and then if the investor is
correct and the bond’s price declines, selling the bond at a higher price (i.e.,
realizing a gain). That is precisely what occurs when a CDS is purchased:
the investor makes payments (the swap premium payments) and realizes a
gain if a credit event occurs. Hence, buying credit protection via a CDS is
equivalent to shorting.
Finally, for an asset manager seeking a leveraged position4 in a corpo-
rate bond, this can be achieved by selling credit protection. As just noted,
selling credit protection is equivalent to a long position in the reference en-
tity. Moreover, as with other derivatives, CDS allows this to be done on a
leveraged basis.
So far, we discussed the use of a single-name CDS—in other words, a
CDS that involves a single bond issue. Alternatively, an investment manager
can reduce or eliminate exposure to a whole index of underlying securities.
Unlike a single-name CDS, the underlying for a credit default swap index
(CDX) is a standardized basket of reference entities. There are standardized
CDX compiled and managed by Dow Jones. For the corporate bond indices,
there are separate indices for investment-grade corporate entities, the most

638
DERIVATIVE PRICING AND USE
actively traded being the North America Investment Grade Index (denoted
by DJ.CDX.NA.IG). As the index name suggests, the reference entities in
this index are those with an investment-grade rating. The index includes
125 corporate names in North America with each corporate name having
an equal weight in the index (0.8%). The index is updated semiannually by
Dow Jones.
The mechanics of a CDX are different from that of a single-name CDS.
For both types of CDS, there is a swap premium that is paid periodically.
If a credit event occurs, the swap premium payment ceases in the case of
a single-name CDS and the contract is terminated. In contrast, for a CDX,
the swap payment continues to be made by the credit protection buyer.
However, the amount of the quarterly swap premium payment is reduced.
This is because the notional amount is reduced as result of a credit event for
a reference entity.
A CDX allows the management of exposure to a diversiﬁed portfolio of
investment-grade corporate names. Thus, an asset manager seeking credit
protection for the investment-grade corporate sector of a portfolio can ob-
tain that protection by buying a CDX. This is the same as reducing credit
exposure to that sector. A corporate manager seeking to increase exposure
to the investment-grade corporate sector can do so by selling a CDX.
16.3
USING FUTURES TO IMPLEMENT
AN ASSET ALLOCATION DECISION
As explained in Chapter 9, one of the major tasks in investment management
is the allocation of funds among major asset classes. As the asset allocation
of a client changes, it is necessary to shift funds among the asset classes.
Funds can be shifted in one of two ways. The most obvious is by buying
or selling the amount speciﬁed in the asset mix in the cash market, that is,
purchasing or selling stocks and bonds in the portfolio. The costs associated
with shifting funds in this manner are the transaction costs with respect to
commissions, bid-ask spreads, and market impact. Moreover, there will be
a disruption of the activities of the asset managers who are managing funds
for each asset class. For example, a pension sponsor typically engages certain
assets managers for managing equity funds, and different ones for managing
bond funds. An asset allocation decision requiring the reallocation of funds
will necessitate the withdrawal of funds from some asset managers and the
placement of funds with others. If the shift is temporary, there will be a
subsequent revision of the asset allocation, further disrupting the activities
of the asset managers.

Using Derivatives in Portfolio Management
639
An alternative approach is to use the futures market to change an ex-
posure to an asset class. As we explained earlier in this chapter, buying
futures contracts increases exposure to the asset class underlying the fu-
tures contract, while selling futures contracts reduces it. For the major as-
set classes, equities and bonds, a client can use stock index futures and
Treasury bond futures to alter the asset mix. The advantages of using ﬁ-
nancial futures contracts over transacting in the cash market for each asset
class are (1) transaction costs are lower; (2) execution is faster in the fu-
tures market; (3) market impact costs are avoided or reduced because the
asset manager has more time to buy and sell securities in the cash mar-
ket; and (4) activities of the asset managers employed by the client are not
disrupted. A strategy of using futures for asset allocation to avoid disrupt-
ing the activities of asset managers is sometimes referred to as an overlay
strategy.
16.4
MEASURING PORTFOLIO RISK WHEN
THE PORTFOLIO CONTAINS DERIVATIVES
We have introduced some important uses of derivatives for equity and bond
portfolio management. While at an intuitive level the applications we de-
scribed make sense, one may ask for more accurate estimates of the impact
of including derivative securities on a portfolio risk proﬁle.
Simulation is essential for measuring the portfolio risk in the presence
of derivatives. Closed-form measures of risk that are widely used for eq-
uity portfolios, such as variance and standard deviation, can be especially
misleading when the payoffs of the ﬁnancial instruments in the portfolio
are not symmetric, which is the case when there are derivatives. As an ex-
ample, consider the distribution of a call option payoff at expiration and
the distribution of the price of the underlying stock (Exhibit 16.4(B) and
(A), respectively). The skewness in the distribution of the option payoffs is
a lot more pronounced than the skewness in the distribution of the stock
prices. In fact, the stock prices we generated came from a geometric random
walk, so the distribution in Exhibit 16.4(A) is lognormal. If we worked in
return space (rather than payoff space), we would have obtained a nor-
mal distribution—a perfect bell-shaped curve. Option payoffs do not follow
such symmetric distributions. Using the expected value and the volatility
of the probability distribution for an option payoff is not very informa-
tive (and can in fact be misleading), given how far the distribution is from
normal.

640
DERIVATIVE PRICING AND USE
0.30
0.25
0.20
0.15
0.10
0.05
0.00
(B)
–10
0
10
20
20
30
30
40
40
50
50
60
60
70
70
80
90
100
110
120
130
(A)
0.035
0.030
0.025
0.020
0.015
0.010
0.005
0.000
EXHIBIT 16.4
Probability distribution of (A) the price of a stock at
expiration, and (B) the discounted payoff of a call option on the stock
at expiration.
Estimating the risk of a portfolio by simulation is simple in concept. The
following steps are implemented:
1. Generate N realizations of the vector whose elements are the changes in
value for the M securities in the portfolio, S.
2. For each of the N vectors (knowing the current portfolio weights),
compute the resulting change in portfolio value.

Using Derivatives in Portfolio Management
641
3. Analyze different characteristics of the so-obtained future portfolio
value probability distribution.
For example, if we would like to evaluate the value-at-risk (VaR), we
can record the change in portfolio value L = V(S,t) – V(S + S, t + t),
which represents the loss realized in each of the N scenarios. We can then
estimate the 95th percentile of the loss distribution by using the method
described in Chapter 8. Alternatively, if we would like to compute the prob-
ability that the loss will be greater than a certain value x, we can compute
the loss probability as the percentage of all losses over the value x, that
is, as
1
N ·
N

i=1
1{Li > x}
where 1 is the indicator function, as introduced in section 14.4.3 of Chap-
ter 14.
This is a theoretically sound algorithm for evaluating the probability
distribution of portfolio changes. The problem arises in its actual implemen-
tation for large and complex portfolios, especially in step 2, the portfolio
revaluation step. Generating every scenario in step 2 for a portfolio of thou-
sands of securities requires running thousands of numerical algorithms, in-
cluding additional simulations. This can be a very time consuming process.
For example, suppose that we are trying to simulate N scenarios for each of
M securities in the portfolio. The total number of scenarios for the portfolio
value would be NM. For a portfolio of 1,000 securities, each of which can
be in one of 100 scenarios, we could have a total of 1001,000 scenarios—this
is
basically
impossible
to
evaluate,
even
with
today’s
advanced
technology.
One technique that can help reduce the number of scenarios is to identify
factors that drive the changes in portfolio value, and simulate scenarios for
those factors. (Hopefully, there are a lot fewer of these factors than the
number of securities in the portfolio.) We already encountered this idea
in Chapter 11. Consider, for example, a bond portfolio of 100 bonds. To
simulate the future value of the portfolio, we would use the current yield
curve, the volatilities of the risk factors that drive the yield curve evolution
process, and their correlation matrix. For instance, the yield curve could be
described by 10 risk factors representing the following key rates: 6-month,
1-, 2-, 3-, 4-, 5-, 10-, 15-, 20-, and 30-year zero-coupon rates.
Jamshidian and Zhu (1997) suggested a method for further reduc-
ing the number of factors by using principal components analysis5 and

642
DERIVATIVE PRICING AND USE
keeping only the ﬁrst two to three components. For example, suppose that
the 10 key rates in this example (assume they are the rates on zero-coupon
bonds), r1, . . . , r10, follow simple geometric random walks
r(i)
t+1 = r(i)
t
+ µ(i) · r(i)
t
+ σ · r(i)
t
· ˜ε(i)
t , i = 1, . . . , 10
These random walks are correlated with some correlation matrix C (i.e.,
the normal random variables ˜ε(i)
t are correlated with a 10 × 10 correlation
matrix C). If we were to simulate realizations of these ten random walks,
we would generate scenarios for the standard normal random variables
˜ε(i)
t
by drawing them from a multivariate normal distribution with corre-
lation matrix C, and computing the values of the key rates in each of the
scenarios.
Instead, we run principal components on the data which we would
normally use to estimate the drifts µ(i), the volatilities σ (i), and the correlation
matrix C, and we obtain estimates for the loadings (i.e., the coefﬁcients) β(i)
j
in front of the principal components j.
Suppose we keep only the ﬁrst three principal components, that is,
j = 1,2,3. The random walk for each key rate i becomes
(i)
t+1 ≈r(i)
t
+ µ(i) · r(i)
t
+ σ · r(i)
t
· β(i)
1 · ˜z(1)
t
+ σ · r(i)
t
· β(i)
2 · ˜z(2)
t
+ σ · r(i)
t
· β(i)
3 · ˜z(3)
t
where ˜z(1)
t , ˜z(2)
t , ˜z(3)
t
are three uncorrelated standard normal random vari-
ables.
The dimension of the simulation is therefore reduced to three—we need
to simulate three uncorrelated, rather than ten correlated standard normal
random variables. Each simulation trial will produce values for ˜z(1)
t , ˜z(2)
t , ˜z(3)
t ,
which we would plug into the equations for r(i)
t+1 to estimate the realizations
for the future values for the key rates, which will then give us estimates for
possible yield curves.
Suppose we generate 10,000 scenarios for possible yield curves. Each
of the 10,000 scenarios will have an equal probability of occurring. All
positions in the portfolio will then be evaluated in each of the 10,000 sce-
narios, and the distribution of the portfolio values will be stored. Still,
the revaluation of the portfolio in 10,000 scenarios can be a daunting
task. Furthermore, if the number of scenarios is not enough, we may still
have difﬁculty obtaining a good representation of the tail of the distribu-
tion of portfolio values, which would skew the portfolio risk estimation
results.

Using Derivatives in Portfolio Management
643
One technique used in practice is simply to run a historical simulation.
Using historical scenarios allows for a compact representation of the data,
and the portfolio evaluation process can be sped up signiﬁcantly. Unfortu-
nately, historical simulation suffers from many problems, as we discussed in
Chapter 8. Forward-looking simulation is preferable, but ideally, it should
be done with methods that reduce computational time. Such methods in-
clude (Glasserman 2004):
1. Reduce the time required for computing each scenario for the portfolio
value by approximate portfolio revaluation.
2. Reduce the number of scenarios required to achieve a target precision
by applying a variance reduction technique.6
We explain the intuition behind each of these approaches next.
16.4.1
Approximate Portfolio Revaluation
The approximate portfolio revaluation approach uses ideas similar to the
ideas underlying American option pricing with regression methods, de-
scribed in section 14.4.2 of Chapter 14. A ﬁxed (relatively small) number of
scenarios are generated, and the portfolio value is evaluated exactly in those
scenarios. The next step is to ﬁt a function to the portfolio values obtained in
the scenarios using some kind of interpolation or nonlinear regression. If the
ﬁtted approximation is easy to evaluate, then it can be used in a simulation
algorithm to generate more (approximate) scenarios for the portfolio value,
and analyze the resulting probability distribution of portfolio values. The
issue in this approach is how to select the appropriate function, and how
to decide on the appropriate number of scenarios to generate for the initial
valuation. While the former issue is difﬁcult to address in a general way, the
latter issue has been addressed in the literature.
Jamshidian and Zhu (1997) were among the ﬁrst to propose this ap-
proach in combination with the principal components decomposition to
reduce the number of factors for simulation we described earlier. In their
model, each of the three principal components ˜z(1)
t , ˜z(2)
t , ˜z(3)
t
is allowed to
take on one of a limited number of states, and the probability of being in
that state is drawn from a special case of a multinomial probability distribu-
tion (a generalization of the binomial distribution in multiple dimensions).
Recall that the binomial distribution assumes that there are n trials and
two outcomes, success and failure, in each trial. The multinomial distribu-
tion considers n trials as well, but assumes that there are (k + 1) possible

644
DERIVATIVE PRICING AND USE
categorical outcomes in each trial. If we assume that each of these states is
equally likely, we have the following expression for the probability of the
principal component being in state i:
P(i) =
1
2
k
·
k!
i!(k −i)!,
i = 0, . . . , k
In our example, we could consider ﬁve states (outcomes) for a partic-
ular principal component: “no change” (middle state), “moderate up” and
“moderate down” states, and “extreme up” and “extreme down” states. In
this case, k = 4. Therefore, the probabilities of the ﬁrst principal component
being in each of these ﬁve states are
1
16, 1
4, 3
8, 1
4, 1
16
The middle state is more likely than the moderate states, which in turn
are more likely than the extreme states. Given that the ﬁrst principal compo-
nent is more important than the second, and the second is more important
than the third, we could consider more scenarios for the ﬁrst component
than for the second and the third. Jamshidian and Zhu suggest using seven
scenarios (states) for the ﬁrst component, ﬁve for the second, and three for
the third. We can then deﬁne a yield curve scenario to be a set of states
for each principal component, which amounts to a total of 7 · 5 · 3 = 105
scenarios for the yield curve. The probability of the yield curve being in one
of these 105 scenarios is given by the product of the multinomial probabil-
ities for each state (since the states for the different principal components
are independent). Moreover, we only need to do (k1 + 1) · (k2 + 1) ·
(k3
+
1)
portfolio
revaluations,
where
k1,
k2,
and
k3
are
the
number of states considered for principal component 1, 2, and 3,
respectively.
Technically speaking, this is not exactly Monte Carlo simulation—we
do not need to draw random numbers. However, it is a scenario simula-
tion method in the sense that it involves evaluating portfolio performance
over different scenarios, and it associates probabilities with the different
scenarios. An attractive feature of the method is that we can generate sce-
narios that have very low probability of occurrence. Some of the scenarios
in Jamshidian and Zhu’s example of 105 scenarios for portfolio values have
only 0.024% probability of occurring, which is useful in evaluating tail risk
measures such as VaR.

Using Derivatives in Portfolio Management
645
Jamshidian and Zhu’s scenario simulation method can also be extended
to more complex portfolios such as multicurrency portfolios or portfolios
with credit exposures. Of course, such complex situations require model-
ing with greater number of risk factors, and the dimension of the problem
does increase. In a special case—when different types of risks can be as-
sumed to be independent, the number of scenarios can be kept down. For
example, we may assume that credit and market risks are independent, or
that interest rates and exchange rates are independent. Not all of these
assumptions are reasonable, and risk managers need to weigh considera-
tions for realism versus considerations for speed when implementing the
model.
Given the low computational burden, Jamshidian and Zhu’s sce-
nario simulation method is expected to perform well compared to other
methods for portfolio revaluation. Jamshidian and Zhu’s own computa-
tional studies indicate that. However, Abken (2000) tests the method on
portfolios of multicurrency interest rate derivatives, and reports mixed
results.
16.4.2
Variance Reduction Techniques
Glasserman, Heidelberger, and Shahabuddin (2000) suggested and studied
the performance of different variance reduction techniques for improving
simulation performance in the context of estimating the VaR of a portfolio.
Most generally, their idea is to use a control variate method7 that relies
on already available information. Such information can include results of
simulations of the portfolio’s value in recent days under similar market con-
ditions, or approximations to the portfolio value such as the linear delta
approximation or the quadratic delta-gamma approximation, which we dis-
cuss next.
The linear delta approximation is basically an approximation to the
portfolio value given a change of S in the prices of the securities in the
portfolio and assuming that the change in the portfolio value is propor-
tional to the change in the prices of the securities. If the changes S are
multivariate normal, then the change in the value of the portfolio V (and,
hence the portfolio loss L) is also normally distributed. Speciﬁcally, if S
has multivariate normal distribution with mean 0 and covariance matrix
S, then if we assume that the change in the portfolio value is proportional
to the change S, we can write
V = δ′ · (S)

646
DERIVATIVE PRICING AND USE
where δ is a vector of sensitivities. Then the loss L is normally distributed
with mean 0 and variance σ 2
L = δ′ · S · δ, and the 95% VaR, for example,
equals −1(0.95) = 1.65 · σ L.8
The assumption that the portfolio value V is a linear function of S
(which also implies that the change in the portfolio value is proportional to
the change S) may work if we are dealing with an equity portfolio in which
S is the vector of stock prices. The change in stock prices could be evaluated
using a factor model (as in Chapter 11), which is also a linear function in
the underlying factors. However, a portfolio that contains derivatives has
a nonlinear dependence on the prices of the underlying assets, and a bond
portfolio depends nonlinearly on changes in interest rates.
A better approximation in this case so that some of the nonlinearity is
captured (although not a perfect solution) may be the delta-gamma approx-
imation, which in effect is a second-order approximation to the value of the
portfolio, based on the Taylor series expansion:
V = ∂V
∂t · t + δ · S + 1
2 · (S)′ ·  · S
where
δi = ∂V
∂Si
and
i j =
∂2V
∂Si∂Sj
are the ﬁrst and second partial derivatives of V evaluated at (St , t).
Although the calculation of δ and  can be challenging, these coefﬁ-
cients, which represent sensitivities,9 are often routinely calculated by indi-
vidual trading desks, and are generally available.
We can use the delta-gamma approximation to the portfolio value as
a control variate in the simulation to obtain an estimate for the actual
portfolio value VaR. Glasserman, Heidelberger, and Shahabuddin (2000)
report that the method reduces the variance of the estimate for the portfolio
VaR obtained from the simulation by a factor of between 2 and 5.
Alternatively, improvement in the accuracy of estimation can be
achieved if the delta-gamma approximation is used to guide the sampling of
scenarios before computing portfolio losses, rather than to adjust the esti-
mate after the scenarios are generated. This is done through importance sam-
pling, another variance reduction technique introduced in section 14.2.3 of

Using Derivatives in Portfolio Management
647
Chapter 14. Finally, stratiﬁed sampling10 on the values for the delta-gamma
approximation can be applied in order to reduce the variance further. In
other words, we ﬁnd intervals of known (and perhaps equal) probability for
the portfolio loss realized according to the delta-gamma approximation.
The actual details of the implementation are technical, but the un-
derlying ideas are intuitive. In their computational experiments, Glasser-
man, Heidelberger, and Shahabuddin (2000) report that the most effec-
tive variance reduction method for estimating portfolio VaR was realized
when using a combination of importance sampling and stratiﬁed sampling
methods.
SUMMARY
■In equity portfolio management, derivatives are used for (1) risk man-
agement and (2) return enhancement.
■Two risk management strategies that focus on hedging downside risk at
a ﬁxed cost with a speciﬁc limit to losses are protective put and collar
strategies.
■The protective put strategy involves the purchase of a put option com-
bined with a long stock position. This is the equivalent of a position
in a call option on the stock combined with the purchase of risk-free
bond. Protective put strategies are valuable to portfolio managers who
currently hold a long position in the underlying security or investors
who desire upside exposure and downside protection.
■A collar strategy consists of a long stock, a long put, and a short call.
By varying the strike prices, a range of trade-offs among downside
protection, costs, and upside potential is possible. Collars are designed
for investors who currently hold a long equity position and want to
achieve a level of risk reduction.
■A covered call strategy is a return enhancement strategy. It involves
selling a call while holding the underlying stock. The strategy is appro-
priate for slightly bullish investors who don’t expect much out of the
stock and want to produce additional income. The strategy behaves like
a long stock position when the stock price is below the strike price, but
is capped on the upside.
■Derivatives are widely used in bond portfolio management for control-
ling different types of risk, such as interest rate and credit risk.
■Futures, options, and swaps can all be used for managing portfolio
interest rate risk.

648
DERIVATIVE PRICING AND USE
■Credit risk can be effectively managed using credit default swaps.
■An investment manager can reduce credit exposure to a single bond
issue by entering into a credit default swap, and paying a premium
for protection against prespeciﬁed credit events. An investor seeking a
leveraged position in a corporate bond can enter a credit default swap
and sell credit protection.
■An investor can reduce credit exposure to an entire index of underlying
securities by buying a credit default swap index.
■Futures can be used to change allocation of assets among classes with
minimum disruption to activities of asset managers managing funds for
each asset class.
■Simulation is essential for measuring the portfolio risk in the pres-
ence of derivatives. Closed-form measures of risk that are widely used
in the case of equity portfolios, such as variance and standard devi-
ation, can be very misleading when the payoffs of the securities in
the portfolio are not symmetric, which is the case when there are
derivatives.
■Revaluating the portfolio value for every simulation trial can be very
time consuming. One technique that can help reduce the number of
scenarios is to identify factors that drive the changes in portfolio value,
and simulate scenarios for those factors.
■Methods to reduce the time for revaluation further include approximate
portfolio revaluation and variance reduction techniques.
NOTES
1. See the immunization example in section 10.3.1 of Chapter 10, and check this
fact by using the setup in ﬁle Ch10-Immunization.xlsx.
2. Speciﬁcally, basis risk is the risk that supposedly offsetting investments in a
hedging strategy will not experience price changes in entirely opposite directions
from each other. This imperfect correlation between the two investments adds
risk to the position.
3. For more information, see Fabozzi (2009).
4. See section 2.3.1 of Chapter 2 for a deﬁnition of leveraged position.
5. As we explained in section 11.3.3 of Chapter 11, principal component anal-
ysis is a multivariate statistical technique that transforms a number of corre-
lated variables (in this case, the factors driving the evolution of prices) into a
smaller number of uncorrelated components. The ﬁrst principal component
accounts for as much of the variability in the data as possible, and each
succeeding component accounts for as much of the remaining variability as
possible.

Using Derivatives in Portfolio Management
649
6. See sections 14.2 and 14.3 of Chapter 14 for an introduction to variance reduc-
tion techniques.
7. See the introduction to the control variate method in section 14.2.4.
8. See section 8.2.2 of Chapter 8 for calculation of the VaR for normally distributed
returns.
9. See section 13.4.4 of Chapter 13.
10. See section 14.2.2 for an introduction to stratiﬁed sampling.


PART
Five
Capital Budgeting
Decisions


CHAPTER17
Capital Budgeting under
Uncertainty
C
ompanies continually invest funds in assets, and these assets produce
income and cash ﬂows that the company may either reinvest in more
assets or pay to the owners. The total amounts of assets a company owns,
including both tangible and intangible assets, are its capital. These assets
include physical (tangible) assets (such as land, buildings, equipment, and
machinery), as well as assets that represent property rights (intangible assets),
such as accounts receivable, securities, patents, and copyrights. When we
refer to capital investment, we are referring to the company’s investment in
its assets, where the term “capital” also has come to mean the funds used
to ﬁnance the company’s assets and, in some contexts, refers to the sum of
equity and interest-bearing debt.
Capital budgeting decisions involve the long-term commitment of a com-
pany’s resources in capital investments. These decisions play a prominent
role in determining whether a company will be successful. The commitment
of funds to a particular capital project can be enormous and may be irre-
versible. Whereas some capital budgeting decisions are routine decisions that
do not change the course or risk of a company, there are strategic capital
budgeting decisions that either impact the company’s future market position
in its current product lines or permit it to expand into a new product line in
the future.
The company’s capital investment decision may be comprised of a num-
ber of distinct decisions, each referred to as a project. A capital project is a set
of assets that are contingent on one another and are considered together. For
example, suppose a company is considering the production of a new product.
This capital project requires the company to acquire land, build facilities,
and purchase production equipment. And this project may also require the
company to increase its investment in its working capital—inventory, cash,
653

654
CAPITAL BUDGETING DECISIONS
or accounts receivable. Working capital is the collection of assets needed for
day-to-day operations that support a company’s long-term investments.
There are several techniques that are used to evaluate capital budgeting
proposals. These include the payback and discounted payback techniques,
net present value technique, proﬁtability index technique, internal rate of
return technique, and modiﬁed internal rate of return technique. While used
in practice, some of these techniques are limited in their ability to help
managers identify proposed capital projects that are proﬁtable, and are not
necessarily consistent with maximization of shareholder wealth. Moreover,
where capital rationing exists, some techniques give conﬂicting rankings of
the relative attractiveness of capital projects.
Evaluating whether a company should invest in a capital project requires
an analysis of whether the project adds value to the company. What is
essential in this analysis is an assessment of the project’s risk. The risk
analysis of a project is challenging because most capital projects are unique
and a project’s contribution to the company’s risk is difﬁcult to quantify.
There are several tools available to help incorporate a project’s risk into the
decision. Monte Carlo simulation methods are one such tool that has grown
in importance over the years.
This chapter reviews capital budgeting under uncertainty. It provides
an overview of the classiﬁcation of investment projects and tools for evalu-
ating projects, such as net present value, proﬁtability index, internal rate of
return, and payback period. The chapter also contains speciﬁc instructions
for evaluating project risk, such as creating an investment proﬁle, estimat-
ing market risk, and estimating project stand-along risk using simulation.
Section 17.3 of this chapter is a case study that incorporates every stage of
the process.
17.1
CLASSIFYING INVESTMENT PROJECTS
There are different ways managers classify capital investment projects. One
way of classifying projects is by project life, whether short term or long
term. This is done because in the case of long-term projects, the time value
of money plays an important role in evaluating long-term projects. Another
ways of classifying projects is by their risk. The riskier the project’s future
cash ﬂows, the greater the role of the cost of capital in decision-making.
Still another way of classifying projects is by their dependence on other
projects. The relationship between a project’s cash ﬂows and the cash ﬂows
of some other project of the company must be incorporated explicitly into
the analysis since we want to analyze how a project affects the total cash
ﬂows of the company.

Capital Budgeting under Uncertainty
655
17.1.1
Classification According to Economic Life
An investment project generally provides beneﬁts over a limited period of
time, referred to as its economic life. The economic life or useful life of an
asset is determined by:
■Physical deterioration.
■Obsolescence.
■The degree of competition in the market for a product.
The economic life is an estimate of the length of time that the asset will
provide beneﬁts to the company. After its useful life, the revenues generated
by the asset tend to decline rapidly and its expenses tend to increase.
Typically, an investment requires an immediate expenditure and pro-
vides beneﬁts in the form of cash ﬂows received in the future. If beneﬁts
are received only within the current period—within one year of making the
investment—we refer to the investment as a short-term investment. If these
beneﬁts are received beyond the current period, we refer to the investment as
a long-term investment and refer to the expenditure as a capital expenditure.
An investment project may comprise one or more capital expenditures.
For example, a new product may require investment in production equip-
ment, a building, and transportation equipment.
Short-term investment decisions involve primarily investments in current
assets: cash, marketable securities, accounts receivable, and inventory. The
objective of investing in short-term assets is the same as long-term assets:
maximizing owners’ wealth. Nevertheless, we consider them separately for
two practical reasons:
■Decisions about long-term assets are based on projections of cash ﬂows
far into the future and require us to consider the time value of money.
■Long-term assets do not ﬁgure into the daily operating needs of the
company.
Decisions regarding short-term investments, or current assets, are con-
cerned with day-to-day operations. A company needs some level of current
assets to act as a cushion in case of unusually poor operating periods, when
cash ﬂows from operations are less than expected.
17.1.2
Classification According to Risk
Suppose you are faced with two investments, A and B, each promising a
$10 million cash inﬂow 10 years from today. If A is riskier than B, what are

656
CAPITAL BUDGETING DECISIONS
they worth to you today? If you are risk averse, you would consider A less
valuable than B because the chance of getting the $10 million in 10 years is
less for A than for B. Therefore, valuing a project requires considering the
risk associated with its future cash ﬂows.
The investment’s risk of return can be classiﬁed according to the nature
of the project represented by the investment:
■Replacement projects. Investments in the replacement of existing equip-
ment or facilities.
■Expansion projects. Investments in projects that broaden existing prod-
uct lines and existing markets.
■New products and markets. Projects that involve introducing a new
product or entering into a new market.
■Mandated projects. Projects required by government laws or agency
rules.
Replacement projects include the maintenance of existing assets to con-
tinue the current level of operating activity. Projects that reduce costs, such
as replacing old equipment or improving the efﬁciency, are also considered
replacement projects. Evaluating replacement projects requires us to com-
pare the value of the company with the replacement asset to the value of the
company without that same replacement asset. What we are really doing
in this comparison is looking at opportunity costs: what cash ﬂows would
have been if the company had stayed with the old asset.
There is little risk in the cash ﬂows from replacement projects. The
company is simply replacing equipment or buildings already operating and
producing cash ﬂows. And the company typically has experience in manag-
ing similar new equipment.
Expansion projects, when intended to enlarge a company’s established
product or market, also involve little risk. However, investment projects that
involve introducing new products or entering into new markets are riskier
because the company has little or no management experience in the new
product or market.
A company is forced or coerced into its mandated projects. These are
government-mandated projects typically found in “heavy” industries, such
as utilities, transportation, and chemicals, all industries requiring a large por-
tion of their assets in production activities. Government agencies, such as the
Occupational Health and Safety Agency (OSHA) or the Environmental Pro-
tection Agency (EPA), may impose requirements that companies install spe-
ciﬁc equipment or alter their activities (such as how they dispose of waste).
We can further classify mandated projects into two types: contingent
and retroactive. Suppose, as a steel manufacturer, we are required by law to

Capital Budgeting under Uncertainty
657
include pollution control devices on all smoke stacks. If we are considering
a new plant, this mandated equipment is really part of our new plant invest-
ment decision—the investment in pollution control equipment is contingent
on our building the new plant. On the other hand, if a company is required
by law to place pollution control devices on existing smoke stacks, the law is
retroactive. A company does not have a choice. The company must invest in
the equipment whether it increases the value of the company or not. In this
case, the company has three choices: select from among possible equipment
that satisﬁes the mandate, weigh the decision whether to halt production
in the offending plant, or, if available, consider the purchase of pollution
emissions allowances.
17.1.3
Classification According to
Dependence on Other Projects
In addition to considering the future cash ﬂows generated by a project, a
company must consider how it affects the assets already in place—the results
of previous project decisions—as well as other projects that may be under-
taken. Projects can be classiﬁed according to the degree of dependence with
other projects: independent projects, mutually exclusive projects, contingent
projects, and complementary projects.
An independent project is one whose cash ﬂows are not related to the
cash ﬂows of any other project. Accepting or rejecting an independent project
does not affect the acceptance or rejection of other projects. Projects are mu-
tually exclusive if the acceptance of one precludes the acceptance of other
projects. For example, suppose a manufacturer is considering whether to
replace its production facilities with more modern equipment. The company
may solicit bids among the different manufacturers of this equipment. The
decision consists of comparing two choices, either keeping its existing pro-
duction facilities or replacing the facilities with the modern equipment of
one manufacturer. Because the company cannot use more than one produc-
tion facility, it must evaluate each bid and choose the most attractive one.
The alternative production facilities are mutually exclusive projects: The
company can accept only one bid.
Contingent projects are dependent on the acceptance of another project.
Suppose a greeting card company develops a new character, Pippy, and is
considering starting a line of Pippy cards. If Pippy catches on, the com-
pany will consider producing a line of Pippy T-shirts—but only if the Pippy
character becomes popular. The T-shirt project is a contingent project.
Another form of dependence is found in complementary projects, where
the investment in one enhances the cash ﬂows of one or more other projects.
Consider a manufacturer of personal computer equipment and software. If

658
CAPITAL BUDGETING DECISIONS
it develops new software that enhances the abilities of a computer mouse,
the introduction of this new software may enhance its mouse sales as well.
17.2
INVESTMENT DECISIONS AND
WEALTH MAXIMIZATION
The value of a company today is the present value of all of its future cash
ﬂows. These future cash ﬂows come from assets that are already in place
and from future investment opportunities. The value of the company today
is therefore represented as
∞

t=1
CFt
(1 + r)t
where CFt is the cash ﬂow obtained by the company in time period t, and r
is the required rate of return.
A company’s management makes decisions about which capital projects
to undertake by evaluating their value to the company. This process is re-
ferred to as capital budgeting. The capital budgeting decision for a project
requires analysis of (1) the project’s future cash ﬂows, (2) the degree of un-
certainty associated with the project’s future cash ﬂows, and (3) the value
of the project’s future cash ﬂows considering their uncertainty. The evalu-
ation of future cash ﬂows involves estimation of changes in operating cash
ﬂows (changes in revenues, expenses, and taxes) and changes in investment
cash ﬂows (cash ﬂows from the acquisition and disposition of the project’s
assets). The degree of risk associated with obtaining these cash ﬂows is typ-
ically incorporated in the project’s cost of capital. The cost of capital is the
cost of the funds for the company’s investment in the project. The value of
the project’s future cash ﬂows considering the risk is computed using disci-
plined methods such as net present value, proﬁtability index, internal rate of
return, modiﬁed internal rate of the return, payback period, and discounted
payback period. In general, project value evaluation techniques should:
■Consider all future incremental cash ﬂows from the project.
■Consider the time value of money.
■Consider the risk associated with future cash ﬂows.
■Have an objective criterion by which to select a project.
Not all of the techniques listed above satisfy all these criteria. We will
focus on the most popular methods for project value estimation: net present
value, internal rate of return, proﬁtability index, and payback period.

Capital Budgeting under Uncertainty
659
17.2.1
Cost of Capital, Required Rate
of Return, and Discount Rate
As we mentioned earlier, the future cash ﬂows of a project are discounted
to the present using an interest rate that incorporates to some extent
the degree of risk associated with these cash ﬂows. At an intuitive level,
the greater the risk associated with the cash ﬂows, the higher the discount
rate that should be used, which is equivalent to assigning a lower present
value to these future cash ﬂows. In the case of internal rate of return, the
term used to describe this discount rate is the hurdle rate. The hurdle rate
must be exceeded by the project’s return.
This rate—whether the discount or the hurdle rate—is the opportunity
cost of funds. For a corporation, the opportunity cost of funds reﬂects the
cost of capital to be paid to suppliers of capital (the creditors and owners).
The term cost of capital is used interchangeably with the term required rate of
return (RRR). The RRR is the rate of return that suppliers of capital demand
on their investment. Cost of capital and RRR are the same concepts, but from
different perspectives—that of the company versus that of the investors.
The cost of capital impacts almost all methods for project valuation,
and is therefore very important. We will review common methods for its
estimation later in this chapter.
17.2.2
Net Present Value
The net present value (NPV) project valuation method considers the present
value of all cash ﬂows expected over the life of the project, and nets the
positive and the negative expected cash ﬂows. Speciﬁcally,
NPV = Present value of future cash ﬂows −Initial cash outlay
All cash ﬂows are discounted by a rate involving the estimated cost
of capital, which we denote by r. This is to allow for “apples-to-apples”
comparison, that is, to net cash ﬂows in today’s dollars.
We can write all cash ﬂows in the equation above with their correspond-
ing sign, using “plus” for inﬂows and “minus” for outﬂows. Assuming that
the life of the project is N time periods, the NPV can then be computed as
NPV =
N

t=0
CFt
(1 + r)t
Note that the calculation involves the cash ﬂow at time 0, and since
(1 + r)0 = 1, the initial cash ﬂow is not actually discounted. Typically, the

660
CAPITAL BUDGETING DECISIONS
EXHIBIT 17.1
Example of calculating NPV from a sequence
of cash ﬂows.
Year
Cash Flow
Discounted Cash Flow
0
−$1,500,000.00
−$1,500,000.00
1
$0.00
$0.00
2
$200,000.00
$165,289.26
3
$500,000.00
$375,657.40
4
$900,000.00
$614,712.11
5
$1,000,000.00
$620,921.32
NPV =
$276,580.09
initial cash ﬂow is an outlay, and therefore has a negative sign, but project
speciﬁcations vary.
The decision rule is simple: If the NPV is greater than 0, then the value
of the expected cash inﬂows is higher than the value of the expected cash
outﬂows, and management should consider investing in the project. An
example of an NPV calculation for Project X is presented in Exhibit 17.1.
Project X requires an investment of $1.5 million today, and returns $0,
$200,000, $500,000, $900,000, and $1 million in years 1, 2, 3, 4, and 5 of
the project. Assuming a 10% cost of capital, the NPV is1
NPV = −1,500,000
(1 + 0.10)0 +
0
(1 + 0.10)1 +
200,000
(1 + 0.10)2 +
500,000
(1 + 0.10)3
+
900,000
(1 + 0.10)4 + 1,000,000
(1 + 0.10)5
= $276,580.09.
Since the NPV is positive, Project X is expected to contribute to the
value of the company, and should be considered.
It is important to study the sensitivity of the NPV estimate to the as-
sumption made about the cost of capital. Graphing the value of the NPV for
different values for the cost of capital is referred to as the investment proﬁle,
or the NPV proﬁle. Exhibit 17.2 illustrates the investment proﬁle for Project
X described above. The NPV of Project X is positive for values of the cost of
capital of less than 14.84%, and negative for values of the cost of capital of
more than 14.84%. As we will see in section 17.2.4, 14.84% is the internal
rate of return (discussed below); that is, the discount rate at which the NPV
is equal to zero.
Creating the investment proﬁle is useful not only because it allows us to
study the sensitivity of the project NPV to the assumption about the discount

Capital Budgeting under Uncertainty
661
Cost of
Capital
NPV
10%
$276,580.09
11%
$214,229.38
12%
$154,722.03
13%
$97,901.21
14%
$43,620.18
15%
–$8,258.49
16%
–$57,863.58
18%
–$150,728.47
19%
–$194,207.88
20%
–$235,853.91
(A)
–$300,000.00
–$200,000.00
–$100,000.00
$0.00
$100,000.00
$200,000.00
$300,000.00
$400,000.00
8%
10%
12%
14.84%
14%
16%
18%
20%
22%
NPV
Cost of Capital
(B)
EXHIBIT 17.2
(A) Data table with the value of the NPV for Project X for values
of the cost of capital between 10% and 20%. (B) NPV proﬁle of Project X.
rate. It is also a tool for comparing the NPVs of two or more projects. By
plotting the investment proﬁles of two projects on the same graph, we can
visualize for what assumptions of the discount rate one is preferable to the
other.
17.2.3
Profitability Index
The proﬁtability index (PI) uses the same information as the NPV, but is
stated in terms of an index. While the NPV is computed as
NPV = Present value of future cash ﬂows −Initial cash outlay
the PI is computed as
P I = Present value of future cash ﬂows
Initial cash outlay
Since the PI measures performance in terms of an index and not dollar
amounts, it provides a measure of the beneﬁt per dollar investment. There-
fore, the PI translates the NPV into an indexed value, and has an advantage
relative to NPV when ranking projects. This advantage may be a disadvan-
tage, however, when the capital budget is limited (a situation referred to as
capital rationing) and the actual dollar amounts for the different projects
are of very different orders of magnitude. In this case, prioritizing projects

662
CAPITAL BUDGETING DECISIONS
based on their PI, rather than their NPV, will not necessarily result in the
most proﬁtable decision for the company.2
For Project X,
P I = $1,776,580.09
1,500,000
= 1.18.
Since the PI is greater than 1, this means that the investment produces
more beneﬁts than costs.
17.2.4
Internal Rate of Return
The internal rate of return (IRR) is the discount rate that makes the present
value of all cash ﬂows (positive and negative) equal to zero. In other words,
the IRR solves the equation
0 =
N

t=0
CFt
(1 + I RR)t
Consider the projected cash ﬂows for Project X from section 17.2.2. We
want to ﬁnd a value for IRR such that
0 = −1,500,000
(1 + I RR)0 +
0
(1 + I RR)1 +
200,000
(1 + I RR)2 +
500,000
(1 + I RR)3
+
900,000
(1 + I RR)4 + 1,000,000
(1 + I RR)5
It turns out that
0 = −
1,500,000
(1 + 0.1484)0 +
0
(1 + 0.1484)1 +
200,000
(1 + 0.1484)2 +
500,000
(1 + 0.1484)3
+
900,000
(1 + 0.1484)4 +
1,000,000
(1 + 0.1484)5
Therefore, the IRR for Project X is 14.84%.3
The IRR is a yield—what is earned, on average, per year. To make a
decision on whether to choose an investment, we compare the IRR of the
project with the cost of capital. The decision rule for the IRR is to invest
in a project if it provides a return greater than the cost of capital. The
cost of capital, in the context of the IRR, is the hurdle rate—the minimum
acceptable rate of return.

Capital Budgeting under Uncertainty
663
We need to be careful, however, when we use the IRR to distinguish
between projects. The project with the highest IRR may not be the one
with the best NPV.4 The IRR and the NPV methods may suggest different
decisions because of the assumption about what rate can be earned when
reinvesting the cash ﬂows. While we have not discussed this assumption, it
is a property of any yield calculation, and the IRR is a yield calculation. To
realize the computed yield, it is assumed that the cash ﬂows are reinvested
at the computed IRR. Thus we have:
■NPV assumes cash ﬂows reinvested at the cost of capital.
■IRR assumes cash ﬂows reinvested at the internal rate of return.
This reinvestment assumption may cause different decisions in choosing
among projects when:
■The timing of the cash ﬂows is different among the projects.
■There are scale differences (that is, very different cash ﬂow amounts).
■The projects have different useful lives.
To understand the points above, note that a part of the return on a
project is from the reinvestment of its future cash ﬂows to the expected
terminal date of the project. If Project Y’s cash ﬂows are received sooner
than Project X’s, there will be more return from the reinvestment of the
future cash ﬂows in the case of Project Y. The question is what is done
by the company with the future cash ﬂows from a project when they are
received. We generally assume that when the company receives future cash
ﬂows, they are reinvested in other assets. If the best we can do is reinvest
cash ﬂows at the cost of capital, then we should evaluate projects on the
basis of the NPV.
Another problem with the IRR becomes apparent if we note that the IRR
is a percentage, not a dollar amount. Because of this, we cannot determine
how to distribute the capital budget to maximize wealth because a project
that produces the highest yield does not necessarily produce the greatest
wealth.
Finally, the IRR suffers from a purely mathematical problem. It has to
do with the uniqueness of the IRR estimate depending on the cash ﬂow
structure of the project (i.e., the pattern of positive and negative future cash
ﬂows).
Project X, the example we considered, was characterized by a negative
cash ﬂow at the beginning, followed by a sequence of positive future cash
ﬂows. Many projects have the same characteristics, but not all. Suppose, for
example, that management is considering a project that uses environmentally

664
CAPITAL BUDGETING DECISIONS
EXHIBIT 17.3
Example of a project with multiple IRRs.
Year
End of Year Cash Flow
0
−$1,000.00
1
$1,500.00
2
$1,500.00
3
−$2,100.00
sensitive chemicals. It may cost a great deal to dispose of them at the end of
the project’s life, and that will mean a negative cash ﬂow at the end of the
project.
The IRR for projects for which there is an initial negative cash ﬂow
followed by positive future cash ﬂows has only one IRR. However, there
could be multiple IRRs for projects for which negative and positive future
cash ﬂows happen in a different order. Consider, for example, a project with
the cash ﬂows in Exhibit 17.3.
What is this project’s IRR? One possible solution is IRR = 7.21%, yet
another possible solution is IRR = 62.97%. That is, both IRRs will make
the present value of the cash ﬂows equal to zero.
The NPV of these cash ﬂows are shown in Exhibit 17.4 for discount
rates from 0% to 70%. Remember that the IRR is the discount rate that
causes the NPV to be zero. In terms of Exhibit 17.4, this means that the
–$150.00
–$100.00
–$50.00
$0.00
$50.00
$100.00
0%
10%
20%
30%
40%
50%
60%
70%
80%
NPV
Cost of Capital
IRR = 7.21%
IRR = 62.97%
EXHIBIT 17.4
NPV of a project with multiple IRRs.

Capital Budgeting under Uncertainty
665
IRR is the discount rate where the NPV is zero, the point at which the NPV
changes sign—from positive to negative or from negative to positive. In the
case of this project, the NPV changes from negative to positive at 7.21%,
and from positive to negative at 62.97%. Hence, the IRR needs to be applied
with care.
17.2.5
Modified Internal Rate of Return
The NPV method assumes that future cash ﬂows from a project are rein-
vested at the project’s cost of capital, whereas the IRR method assumes that
future cash ﬂows are reinvested at the project’s IRR. These assumptions are
built into the mathematics of the methods, but they may not represent the
actual opportunities of the company.
The modiﬁed internal rate of return (MIRR) method is an alternative
that considers a speciﬁc reinvestment rate for cash inﬂows from a project.
MIRR is a yield on an investment considering a speciﬁc interest rate on the
reinvestment of funds.
To understand this reinvestment rate assumption better, consider Project
X from section 17.2.2. The IRR is 14.84%. If each of the cash inﬂows from
Project X is reinvested at 14.84%, the sum of these future cash ﬂows will
be $2,995,815.12 at the end of year 5 (see Exhibit 17.5). For example, year
3’s cash ﬂow of $200,000 is reinvested at 14.84% for three years (years 3,
4, and 5), so its future value is $200,000 · (1 + 0.1484)3 = $302,889.52.
The $2,995,815.12 is referred to as the project’s terminal value. The
terminal value is how much the company has from an investment at the end
of the project if all proceeds are reinvested at the assumed reinvestment rate.
In our illustration, we assumed the reinvestment rate is the IRR. So what is
EXHIBIT 17.5
Concept of terminal value of a project.
Number of Periods
Earning Return
Cash Flow
Future Value of Cash Flow
Reinvested at 14.84%
5
−$1,500,000.00
$0.00
4
$0.00
$0.00
3
$200,000.00
$302,889.52
2
$500,000.00
$659,385.67
1
$900,000.00
$1,033,539.93
0
$1,000,000.00
$1,000,000.00
Terminal value =
$2,995,815.12

666
CAPITAL BUDGETING DECISIONS
the return on this project? Using the terminal value as the future value and
the investment outlay as the present value, we have
PV = $1,500,000 (amount invested).
FV = $2,995,815.12 (amount at the end).
N = 5 years (investment horizon).
r =
4

$2,995,815.12
$1,500,000
−1 = 14.84%.
The last procedure shows how to compute the MIRR for an investment
in general. Given the project’s initial investment, the terminal value of its
future cash ﬂows based on the assumed reinvestment rate, and the length of
the investment horizon, we determine the implied return of the investment.
The latter is the MIRR. The example above was a special case. The MIRR
was the same as the IRR because we assumed that all cash ﬂows from the
project are reinvested at the IRR.
Note that the pattern of the project’s future cash ﬂows makes a differ-
ence. If a project’s future cash ﬂows are received mostly at the beginning
of the project, the MIRR is more sensitive to the reinvestment rate because
the future cash ﬂows are invested at the reinvestment rate for longer time
periods.
The decision rule for the MIRR is to invest in a project if it provides
a return (MIRR) greater than the cost of capital. As in the case of IRR,
the cost of capital is the hurdle rate. Clearly, all else being equal, a higher
reinvestment rate makes a project more attractive in terms of its MIRR.
17.2.6
Payback Period and
Discounted Payback Period
The payback period for a project is the time from the initial cash outlay to
invest in it until the time when its future cash ﬂows add up to the initial
cash outlay. In other words, how long it takes to recover the initial cash
outlay. The payback period is also referred to as the payoff period or the
capital recovery period. If $10 million is invested today and the investment
is expected to generate $5 million one year from today and $5 million two
years from today, the payback period is two years—it takes two years to
recoup the $10 million investment.
Let us calculate the payback period for Project X. We invest $1,500,000
at the beginning. By year 3, the entire $1,500,000 has not been paid back, but
in year 4, we have not only recouped the $1,500,000, but in fact exceeded

Capital Budgeting under Uncertainty
667
EXHIBIT 17.6
Payback period for Project X.
Year
Cash Flow
Received Up to That Period
0
−$1,500,000.00
$0.00
1
$0.00
$0.00
2
$200,000.00
$200,000.00
3
$500,000.00
$700,000.00
4
$900,000.00
$1,600,000.00
5
$1,000,000.00
$2,600,000.00
the investment amount (we have $1,600,000) (see Exhibit 17.6). Therefore,
the payback period for Project X is 4 years.
Payback period analysis is a type of “break-even” measure. It tends to
provide a measure of the economic life of the investment in terms of its pay-
back period. The more likely the economic life exceeds the payback period,
the more attractive the investment. The economic life beyond the payback
period is referred to as the postpayback duration. If the postpayback dura-
tion is zero, the investment is unattractive no matter how short the payback.
This is because the sum of the future cash ﬂows is no greater than the initial
investment outlay. And since these future cash ﬂows are really worth less to-
day than in the future, a zero postpayback duration means that the present
value of the future cash ﬂows is less than the project’s initial investment
outlay.
A shorter payback period is better than a longer payback period, but
it is not clear how short is good. The payback method should only be
used as a coarse initial screen of investment projects—it can, however, be a
useful indicator of some things. Because a dollar of cash ﬂow in the early
years is worth more than a dollar of cash ﬂow in later years, the payback
period method provides a crude, but simple measure of the liquidity of the
investment. The payback period also offers some indication on the risk of
the investment. In industries where equipment becomes obsolete rapidly or
where there are very competitive conditions, investments with earlier pay-
back are more valuable. This is because cash ﬂows farther into the future
are more uncertain and therefore have lower present value. In the computer
industry, for example, the ﬁerce competition and rapidly changing technol-
ogy require investment in projects that have a payback of less than one year
since there is no expectation of project beneﬁts beyond one year.
The payback measure can be adjusted to account for the time value of
the future cash ﬂows. The resulting measure is called the discounted payback
period. More precisely, the discounted payback period is the time needed to

668
CAPITAL BUDGETING DECISIONS
EXHIBIT 17.7
Calculation of the discounted payback period for Project X.
Year
Cash Flow
Cash Flow Discounted
to Year 0
Discounted Cash Flows
Up to That Period
0
−$1,500,000.00
−$1,500,000.00
−$1,500,000.00
1
$0.00
$0.00
−$1,500,000.00
2
$200,000.00
$165,289.26
−$1,334,710.74
3
$500,000.00
$375,657.40
−$959,053.34
4
$900,000.00
$614,712.11
−$344,341.23
5
$1,000,000.00
$620,921.32
$276,580.09
pay back the original investment in terms of discounted future cash ﬂows.
In this technique, each cash ﬂow is discounted back to the beginning of
the investment at a rate that reﬂects both the time value of money and the
perceived riskiness of the future cash ﬂows.
Returning to Project X, suppose that the cost of capital is 10%. The
ﬁrst step in determining the discounted payback period is to discount each
year’s cash ﬂow to the beginning of the investment (year 0) at the cost of
capital. As Exhibit 17.7 illustrates, the accumulated future cash ﬂows from
the investment discounted to year 0 (the last column in the table) do not
become positive until year 5. Therefore, the discounted payback period of
Project X is 5 years.
17.2.7
Issues in Capital Budgeting
Not all discounted cash ﬂows methods are appropriate in all circumstances.
Care must be exercised when faced with mutually exclusive projects, scale
differences, different project lives, and capital rationing.
Scale Differences
Scale differences between projects—that is, differences
in the amount of the initial investment—can lead to conﬂicting investment
decisions among the discounted cash ﬂow techniques. Consider two projects,
Project Bigger and Project Smaller, each with a cost of capital of 5% per
year with the cash ﬂows in Exhibit 17.8. Applying the discounted cash ﬂow
techniques to each project, we obtain the estimates in Exhibit 17.9.
If there is no limit to the capital budget—that is, there is no capital
rationing—then both projects are acceptable, value-increasing projects as
indicated by all four techniques. However, if the projects are mutually ex-
clusive projects or there is a limit to the capital budget, then the four methods
provide differing accept-reject decisions.

Capital Budgeting under Uncertainty
669
EXHIBIT 17.8
Cash ﬂows for Projects Bigger and Smaller.
Year
Project Bigger
Project Smaller
0
−$4,000.00
−$2,000.00
1
$1,250.00
$650.00
2
$1,250.00
$650.00
3
$1,250.00
$650.00
4
$1,250.00
$650.00
If Project Bigger and Project Smaller are mutually exclusive projects and
if the company goes strictly by the PI, IRR, or MIRR criteria, management
would choose Project Smaller. But is this the better project? Project Bigger
provides more value—$432.44 versus $304.87. The techniques that ignore
the scale of the investment—PI, IRR, and MIRR—may lead to an incorrect
decision.
If the company is subject to capital rationing—say a limit of
$5,000—and the two projects are independent projects, the company can
only choose one project—spend $4,000 or $2,000, but not $6,000. Applying
the PI, IRR, or MIRR criteria, the company would choose Project Smaller.
But is this the better project? According to the NPV criterion, the dollar con-
tribution of Project Smaller is worse. Again, the techniques that ignore the
scale of the investment—PI, IRR, and MIRR—lead to an incorrect decision.
Unequal Lives
If projects have unequal lives, the comparison strictly on the
basis of the techniques discussed in this chapter may lead to an incorrect de-
cision, whether choosing among mutually exclusive projects or independent
projects when there is capital rationing. Consider the projects whose cash
ﬂows are provided in Exhibit 17.10. Project AA has a life of ﬁve years, Project
BB a life of 10 years, and Project CC a life of 15 years. Projects AA and CC
have a cost of capital of 4% and Project BB has a cost of capital of 5%.5
EXHIBIT 17.9
NPV, IRR, MIRR, and PI for Projects Bigger and Smaller.
Method
Project Bigger
Project Smaller
NFV
$432.44
$304.87
IRR
9.56%
11.39%
MIRR
7.73%
8.79%
PI
1.11
1.15

670
CAPITAL BUDGETING DECISIONS
EXHIBIT 17.10
Projects AA, BB, and CC.
Year
AA
BB
CC
0
−$1,000.00
−$1,000.00
−$1,000.00
1
$260.00
$160.00
$120.00
2
$260.00
$160.00
$120.00
3
$260.00
$160.00
$120.00
4
$260.00
$160.00
$120.00
5
$260.00
$160.00
$120.00
6
$160.00
$120.00
7
$160.00
$120.00
8
$160.00
$120.00
9
$160.00
$120.00
10
$160.00
$120.00
11
$120.00
12
$120.00
13
$120.00
14
$120.00
15
$120.00
Applying the four discounted cash ﬂow techniques without consider-
ing their different lives suggests that Project CC provides the most value
added; Project CC produces the higher IRR beneﬁt per $1 invested (see
Exhibit 17.11).
However, comparing these projects without any adjustment for the dif-
ferent lives ignores the fact that at the completion of the shorter projects,
there is reinvestment necessary that is not reﬂected in the straightforward
application of the techniques. In other words, this is an “apples to oranges”
comparison if an adjustment is not made. One alternative is to ﬁnd the
common denominator life for the projects. In the case of projects AA, BB,
and CC, this would be 30 years. This requires then looking at Project AA
EXHIBIT 17.11
NPV, IRR, MIRR, and PI for Projects AA, BB, and CC.
Method
AA
BB
CC
NPV
$157.47
$235.48
$334.21
IRR
9.43%
9.61%
8.44%
MIRR
7.09%
7.24%
6.02%
PI
1.16
1.24
1.33

Capital Budgeting under Uncertainty
671
as reinvested in the same project ﬁve more times, resulting in a “life” for
analysis of 30 years.
The common denominator approach may be cumbersome when there
are many projects. An alternative is to use the equivalent annual annuity
method.6 This method requires two steps:
1. Calculate the annual annuity that is equivalent to the NPV of the project,
considering the discount rate and the original life of the project. In the
case of Project AA, the annuity amount is $35.37.7
2. Calculate the present value of this annuity if received ad inﬁnitum. In
the case of Project AA, this is $35.37/0.04 = $884.32. This allows for
comparing the projects assuming an inﬁnite life (which is the same for
each of them, so we can compare “apples to apples”).
The second step is only necessary if the comparison involves projects
with different costs of capital. If the costs of capital are the same for the
projects, the ranking of the projects in Step 1 is identical to that of Step 2. The
values in perpetuity for the three projects are given in Exhibit 17.12. After
adjusting for the different lives, the conclusion is that Project AA provides
the most value added of the three projects.
17.2.8
Capital Budgeting in Practice
Among the project evaluation methods, NPV is the only one that is con-
sistent and maximizes owner wealth under the most general circumstances.
According to surveys and anecdotal evidence, it is also the most widely used
in practice. Observations from recent surveys also indicate:
■Techniques that use discounted cash ﬂows are preferred over techniques
that fail to take into consideration the time value of money.
■There is an increased use of the NPV method.
EXHIBIT 17.12
Value in perpetuity for Projects AA, BB, and CC, with
different lives.
AA
BB
CC
Equivalent annual annuity
$35.37
$30.50
$30.06
Value in perpetuity
$884.32
$609.91
$751.47

672
CAPITAL BUDGETING DECISIONS
■Management uses more than one technique to evaluate the same
projects, with a discounted cash ﬂow techniques used as a primary
method and payback period used as a secondary method.
■The most commonly used technique is the NPV method, though the IRR
method is still widely used.
The mechanics of calculating the measures in this chapter given (1) the
initial cash outlay, (2) the future cash ﬂow, and (3) the required return
(or hurdle rate) are not complicated. The most complex activity of the
capital budgeting procedure in practice is actually estimating cash ﬂows.
How can such cash ﬂows be estimated, especially in situations like the
introduction of a new technology, which may have not only an impact
on the company’s future cash ﬂows, but also on the company’s domestic
and global competitive positioning? Even when cash ﬂows can be estimated
reliably, these cash ﬂows must be discounted at an assumed discount rate.
Estimating this discount rate is a problem in itself. Given the number of
assumptions made in estimating various inputs to the model, Monte Carlo
simulation emerges as an even more important tool to evaluate the risk in
the decisions made by using these models. We will discuss Monte Carlo
simulation applications in sections 17.4.3 through 17.4.5.
Finally, in addition to the possible inaccuracies associated with esti-
mating future cash ﬂows or the discount rate associated with investment
projects, there is the potential problem of ignoring the real options that are
present in projects. A real option associated with an investment project has
value arising from the option the company possesses, for example, to defer
investment in the project, abandon the project, or expand the project. It may
be the case, for example, that a new technology that provides a comparative
or competitive advantage is unique, patented technology. If this is the case,
the company may have a real option to defer investment, which enhances
the value of the project beyond the value attributed simply to discounted
cash ﬂows. (Real options are discussed in detail in Chapter 18.)
17.3
EVALUATING PROJECT RISK
The capital budgeting decisions require analyzing a proposed project’s future
cash ﬂows, the risk associated with its future cash ﬂows, and the value of the
future cash ﬂows. When looking at the available investment opportunities,
management must determine the project or set of projects that is expected
to add the most value to the company. This requires evaluating how each
project’s beneﬁts compare with its costs. The projects that are expected to
increase owners’ wealth the most are the best ones. In weighing a project’s

Capital Budgeting under Uncertainty
673
beneﬁts and its costs, the costs include both the cash ﬂow necessary to make
the investment (the initial investment outlay) and the opportunity costs of
not using the cash tied up in this investment.
The beneﬁts are the future cash ﬂows generated by the investment. But
nothing in the future is certain, so there is risk associated with the future
cash ﬂows. Therefore, for an evaluation of any investment to be meaningful,
management must represent how much risk there is that its cash ﬂows will
differ from what is expected in terms of both the amount and the timing of
the cash ﬂows.
The risk associated with the cash ﬂow estimates arises from different
sources, depending on the type of investment being considered, as well as
the circumstances and the industry in which the company is operating. A
project’s risk may be attributable to many sources, including:
■Economic conditions. Will consumers be spending or saving? Will the
economy be in a recession? Will the government stimulate spending?
What will be the rate of inﬂation?
■Market conditions. Is the market competitive? How long does it take
competitors to enter into the market? Are there any barriers, such as
patents or trademarks, that will keep competitors away? Is there sufﬁ-
cient supply of raw materials and labor? How much will raw materials
and labor cost in the future?
■Interest rates. What will be the cost of raising capital in future years?
■Taxes. What will tax rates be? Will Congress alter the tax system?
■International conditions. Will the exchange rate between different coun-
tries’ currencies where the company transacts change? Are the govern-
ments of the countries in which the company does business stable?
Risk is typically incorporated in one of two ways (1) discount future
cash ﬂows using a higher discount rate, the greater the cash ﬂow’s risk and
(2) require a higher hurdle rate on a project, the greater the cash ﬂow’s risk.
As we explained earlier in this chapter, the required rate of return is also
called the cost of capital. An additional layer of risk can be incorporated by
using Monte Carlo simulation to generate scenarios for the factors driving
the future cash ﬂows. These approaches for incorporating risk are the focus
of section 17.3.2.
It is important to realize that a company typically has a portfolio of
projects, and so management needs to estimate not only the stand-alone risk
of the project, but also how the addition of the project to the company’s
portfolio of assets changes the risk of the company’s portfolio. Taking this
one step further, if the company’s owners hold diversiﬁed investments—a
safe assumption to make for all large corporations—it is the project’s market

674
CAPITAL BUDGETING DECISIONS
risk that is relevant to the company’s decision making because investors
would require compensation for market risk, the risk they cannot diversify
away.
Even though market risk is generally the most important risk to analyze,
stand-alone risk should not be ignored, especially when making decisions
for a small, closely held company, whose owners do not hold well-diversiﬁed
portfolios. Stand-alone risk is usually easier to measure than market risk, and
can be gauged by evaluating the project’s future cash ﬂows using statistical
measures, sensitivity analysis, and simulation.
17.3.1
Measuring a Project’s Market Risk
When an investor is trying to evaluate the risk of an investment in a share
of stock, he can look at that stock’s returns and the returns of the entire
market over some time period as a way of measuring the stock’s market
risk. While this is not a perfect measurement, it provides an estimate of the
sensitivity of the particular stock’s returns to changes in the returns of the
market. Things are more complicated when one tries to evaluate the market
risk of a new project. A manager can do the next best thing: He can estimate
the market risk of the stock of another company whose only line of business
is the same as the project’s risk. If he could ﬁnd such a company, he could
estimate its stock’s market risk and use that as a ﬁrst step in estimating the
project’s market risk.
As we explained in Chapter 11, the Greek letter β (beta) is used to
denote a measure of the market risk—the sensitivity of an asset’s returns
to changes in the returns of the market. To distinguish the beta of an asset
from the beta we used for a company’s stock, the asset’s beta is denoted
by βasset and the beta of a company’s stock by βequity. If a company has no
debt, the market risk of its common stock is the same as the market risk of
its assets. However, it is rarely the case that a company has no debt in its
capital structure, so we must consider the effect of ﬁnancial leverage on a
company’s equity beta.
Financial leverage is the use of debt obligations that require ﬁxed con-
tractual payments to ﬁnance a company’s assets.8 The greater the use of
debt obligations, the more ﬁnancial leverage there is, and the greater the
risk associated with cash ﬂows to owners. This is because creditors have
seniority and receive a ﬁxed amount (interest and principal), so a greater
portion of the market risk of the equity is born by the owners as opposed to
the creditors. In fact, the following equality holds:
βasset = βdebt · Proportion of assets ﬁnanced with debt
+ βequity · Proportion of assets ﬁnanced with equity

Capital Budgeting under Uncertainty
675
or, equivalently,
βasset = βdebt · wdebt + βequity · wequity
Since interest on debt is deducted to arrive at taxable income, the claim
that creditors have on the company’s assets does not cost the company the
full amount, but rather the after-tax claim, so the burden of debt ﬁnancing
is actually less. Let D denote the market value of debt,9 E denote the market
value of equity, and τ be the marginal tax rate. The relationship between
the asset beta and the equity beta can be written as
βasset = βdebt
(1 −τ)D
(1 −τ)D + E + βequity
E
(1 −τ)D + E
If βdebt is assumed equal to 0, that is, if debt is assumed not to be subject
to market risk, we have
βasset = βequity
1

1 + (1 −τ) D
E

This means that an asset’s beta is related to the company’s equity beta,
with adjustments for ﬁnancial leverage. If a company does not use debt,
βequity = βasset, and if the company does use debt, βequity > βasset. Therefore,
a βequity may be translated into a βasset by removing the inﬂuence of the
company’s ﬁnancial risk from βequity. To accomplish this, the following
must be known:
■The company’s marginal tax rate.
■The amount of the company’s debt ﬁnancing in market value terms.
■The amount of the company’s equity ﬁnancing in market value terms.
The process of translating an equity beta into an asset beta is referred to
as unlevering because the effects of ﬁnancial leverage are removed from the
equity beta, βequity, to arrive at a beta for the company’s assets, βasset. This
beta therefore is an estimate of the market risk of a company’s assets.
The insights in this section can be used to compute the cost of capital, the
discount rate to use in evaluating risky future cash ﬂows. As we explained
in section 17.2.1, the cost of capital is the cost of funds from the providers
of capital, creditors, and owners. This cost is the return required by these
suppliers of capital. The greater the risk of a project, the greater the return
required and, hence, the greater the cost of capital.

676
CAPITAL BUDGETING DECISIONS
The project’s cost of capital is comprised of two parts:
■The return if the project were risk-free, which provides compensation
for the time value of money.
■The compensation for risk.
The compensation for the time value of money includes compensation
for any anticipated inﬂation. The risk-free rate of interest, such as the yield on
a long-term U.S. Treasury bond, is typically used to represent the time value
of money. The compensation for risk is the extra return required because the
project’s future cash ﬂows are uncertain. The greater the project’s market
risk, the greater the return investors should require.
Computing the Cost of Capital Based on the CAPM
A commonly used
method for estimating a project’s cost of capital is to use the return for-
mula from the capital asset pricing model (CAPM).10 This requires ﬁrst
specifying the premium for bearing the average amount of risk for the mar-
ket as a whole and then, using a measure of market risk, ﬁne tuning this
to reﬂect the market risk of the project. The market risk premium for the
market as a whole is the difference between the average expected market
return, rM, and the expected risk-free rate of interest, rf.11 If a company
buys an asset whose market risk is the same as that of the market as a
whole, the company expects a return of rM – rf to compensate investors for
market risk.
Adjusting the market risk premium for the market risk of the particular
project requires multiplying the market risk premium by that project’s asset
beta, βasset:
Compensation for market risk = βasset · (rM −r f )
This is the extra return necessary to compensate for the project’s market
risk. The asset beta ﬁne-tunes the risk premium for the market as a whole to
reﬂect the market risk of the particular project. If we then add the risk-free
interest rate, we arrive at the cost of capital:
Cost of capital = r f + βasset · (rM −r f )
Suppose the expected risk-free rate of interest is 4% and the expected
return on the market as a whole is 10%. If βasset = 2, this means that if
there is a 1% change in the market risk premium, a 2% change (in the same

Capital Budgeting under Uncertainty
677
direction) in the return on the project is expected. In this case, the cost of
capital is 16%:
Cost of capital = 0.04 + 2 · (0.10 −0.04) = 0.16
or 16%. If, instead, βasset = 0.75, the cost of capital is 8.5%:
Cost of capital = 0.04 + 0.75 · (0.06) = 0.085
or 8.5%.
The calculation of the cost of capital takes advantage of the information
in the asset beta. The application is not always straightforward, however.
There are many instances in which a company invests in assets with differing
risks. Using the company’s asset beta would be inappropriate for evaluat-
ing the risk of a single project because the asset beta reﬂects the market
risk of all of the company’s assets and this may not be the same risk as
for the project being evaluated. One approach to handle this situation is
to estimate the cost of capital of a company that has a single line of busi-
ness that is similar to the project under consideration. A company with a
single line of business is referred to as a pure-play company. Selecting the
company or companies that have a single line of business, where this line
of business is similar to the project’s, helps in estimating the market risk of
a project.
One method of estimating the pure-play company’s equity beta is re-
gressing the returns on the pure-play company’s stock and the returns on
the market. Once the pure-play company’s equity beta is calculated, man-
agement unlevers it by adjusting it for the ﬁnancial leverage of the pure-play
company.
Because many U.S. corporations whose stock’s returns are readily avail-
able have more than one line of business, ﬁnding an appropriate pure-play
company may be difﬁcult. Care must be taken to identify those that have
lines of business similar to the project’s. Estimating a pure-play asset beta is
useful in many other applications, including valuing divisions or segments
of a business and valuing small businesses.
Adjusting the Company’s Cost of Capital
It is often the case that man-
agement is not able to estimate the project’s market risk, not even the
expected risk-free rate. Another way to estimate the cost of capital for a
project without estimating the risk premium directly is to use the company’s
weighted average cost of capital (WACC) as a starting point. The WACC
is the company’s marginal cost of raising one more dollar of capital—the

678
CAPITAL BUDGETING DECISIONS
cost of raising one more dollar in the context of all the company’s projects
considered altogether, not just the project being evaluated.
The WACC is computed as follows:
rWACC = (1 −τ) · rD · D + rE · E
D + E
where, as before D is the market value of debt, E is the market value of
equity, and τ is the marginal tax rate. rD and rE are the cost of debt and
cost of equity, respectively. rD can be computed by considering the yields of
the outstanding company bonds, weighted appropriately by the percentage
they represent of the total company debt. rE is simply rf + βequity · (rM – rf).
The WACC of the company can be adjusted to suit the perceived risk
of the project:
■If a new project being considered is riskier than the average project of
the company, the cost of capital of the new project is greater than the
WACC.
■If the new project is less risky, its cost of capital is less than the WACC.
■If the new project is as risky as the average project of the company, the
new project’s cost of capital is equal to the WACC.
However, altering the company’s cost of capital to reﬂect a project’s
cost of capital requires judgment. How much do we adjust it? If the project
is riskier than the typical project, do we add 2%? 4%? 10%? There is no
prescription here. It depends on the judgment and experience of the decision
maker. But this is where the measures of a project’s stand-alone risk can be
used to help form that judgment.
17.3.2
Measuring a Project’s Stand-Alone Risk
A project’s stand-alone risk can be evaluated by performing sensitivity anal-
ysis. For example, we can create data tables in Excel to study the dependence
of the project outcomes to slight changes in the forecasts of different vari-
ables in the model. A step further is to conduct scenario analysis, in which
scenarios are explicitly created for the factors that impact the future cash
ﬂows. Conducting a scenario analysis is an important part of the process
of assessing a project’s total risk because different realizations of uncertain
variables (such as sales forecasts, acquired market share, and cannibaliza-
tion with other projects) can substantially change the decision of whether
or not to undertake a project. While speciﬁc scenario analysis has many

Capital Budgeting under Uncertainty
679
strong points, it is often useful to elevate the level of analysis to considering
multiple scenarios at the same time. Monte Carlo simulation is the tool for
analyzing the joint effects of changes in uncertain variables.
The risk associated with the future cash ﬂows can be expressed sta-
tistically in terms of measures such as the range, the standard deviation,
and the coefﬁcient of variation.12 Given the probability distributions of the
project’s future cash ﬂows, these statistical tools can be applied to evaluate a
project’s risk.
The management arrives at these probability distributions based on
research, judgment, and experience—for example, sensitivity analysis or
simulation analysis using past experience of similar projects, if available, to
get an idea of a project’s possible future cash ﬂows and their uncertainty
can be used. Estimates of cash ﬂows are based on assumptions about the
economy, competitors, consumer tastes and preferences, construction costs,
and taxes, among a host of other possible assumptions.
17.3.3
Assessment of Project Risk in Practice
Most U.S. companies consider risk in some manner in evaluating investment
projects. But considering risk is usually a subjective analysis as opposed to
the more objective results obtainable with simulation or sensitivity analysis.
Surveys indicate that companies that use discounted cash ﬂow tech-
niques, such as net present value and internal rate of return methods, tend to
use a risk-adjusted cost of capital, but generally use the company’s weighted
average cost of capital as a benchmark.13 But a signiﬁcant portion of com-
panies use a single cost of capital for all projects, which can be problematic.
The company’s cost of capital reﬂects the company’s average risk
project. What happens when this cost of capital is applied in discounted
cash ﬂow techniques, such as the net present value or the internal rate of
return, to all projects? This will result in the company’s:
■Rejecting proﬁtable projects (which would have increased owners’
wealth) that have risk below the risk of the average risk project be-
cause the company has discounted the project’s future cash ﬂows too
much.
■Accepting unproﬁtable projects whose risk is above the risk of the av-
erage project because the company did not discount the project’s future
cash ﬂows enough.
Companies that use a risk-adjusted discount rate usually do so by classi-
fying projects into risk classes by the type of project. For example, a company

680
CAPITAL BUDGETING DECISIONS
with a cost of capital of 10% may use a 14% cost of capital for new products
and a much lower rate of 8% for replacement projects. Given a set of costs
of capital, management need only ﬁgure out what class a project belongs to
and then apply the rate assigned to that class.
Companies may also make adjustments in the cost of capital for factors
other than the type of project. For example, companies investing in projects
in foreign countries will sometimes make an adjustment for the additional
risk of the foreign project, such as exchange rate risk, inﬂation risk, and
political risk.
There are tools available to assist the decision maker in measuring and
evaluating project risk. But much of what is actually done in practice is
subjective. Judgment, with a large dose of experience, is used more often
than scientiﬁc means of incorporating risk. Is this bad? Well, the scien-
tiﬁc approaches to measurement and evaluation of risk depend, in part,
on subjective assessments of risk, the probability distributions of future
cash ﬂows, and judgments about market risk. So, it is possible that by-
passing the more technical analyses in favor of completely subjective as-
sessment of risk may result in cost-of-capital estimates that better reﬂect
the project’s risk. But then again, it may not. The proof may be in the
pudding, but it is difﬁcult to assess the “proof” because it can never be
determined how well a company may have done had it used more technical
techniques.
17.4
CASE STUDY
In order to illustrate the classical ﬁnancial concepts behind project valuation
and the richer perspective that simulation provides, let us discuss the real-
life-based case study of AirMax Shoes, Inc.14
AirMax Shoes, Inc. is considering introducing a new basketball shoe,
“Rapid Bounce.” The shoe would be endorsed by the most valuable NBA
player for the previous year. However, the company has done a poor job of
anticipating consumer preferences in the basketball shoe market in recent
years. Its market share had decreased from 21.6% to about 16% of the $18
billion athletic shoe industry. Moreover, the overall trend in the industry is
away from basketball shoes.
Another proposal under consideration is to launch an AirMax hiking
shoe called “Persistence.” The hiking sector is one of the fastest growing
areas of the footwear industry—and one that AirMax has not yet entered.
AirMax only has the resources to undertake the “Rapid Bounce” or “Persis-
tence” projects, but not both. There are a number of uncertainties associated
with both projects. The question is which project to choose.

Capital Budgeting under Uncertainty
681
The project lives for both projects are three years, and the federal plus
state marginal tax rate for AirMax is 40%. Speciﬁc characteristics of the
two projects are as follows:
Rapid Bounce
Revenues
■The athletic shoe market is projected to be $18.3 billion during year 1
and to continue growing at a rate of 3% per year. The market share
projections for AirMax’s “Rapid Bounce” are: year 1: 1.80%; year 2:
2.00%; year 3: 1.70%.
Costs
■Sales of Rapid Bounce are expected to reduce sales of other AirMax bas-
ketball sneakers. Speciﬁcally, AirMax’s other sneaker sales are expected
to decrease by $170 million during each year of the project. We will
assume that these lost sales have the same margins as Rapid Bounce.
■In order to produce the shoe, AirMax will need to build a factory in
New Delhi, India. This will require an immediate outlay of $100 million,
which will be depreciated on a 20-year straight-line basis.15 (In other
words, the depreciation amounts for each of the three years of the project
life will be $100/20 = $5 million per year.)
■AirMax must also immediately purchase equipment costing $15 mil-
lion. Freight and installation of the equipment will cost $5 million. The
equipment and freight/installation costs will be depreciated on a ﬁve-
year straight-line basis. (In other words, the depreciation amounts for
each of the three years of the project life will be $20/5 = $4 million per
year.)
■Variable costs of producing the shoe are expected to be 31% of the
shoe’s sales.
■Selling, general, and administrative expenses are expected to be $7 mil-
lion per year for the project.
■AirMax would pay its celebrity endorser $10 million dollars annually
for three years.
■Other advertising and promotion costs are expected to be $20 million
per year.
■In order to manufacture Rapid Bounce, two of AirMax’s working capital
accounts (the inventory balance and the accounts payable) are expected
to increase immediately. The net change in the working capital for the
duration of the project will be –$45 million. These balances will be
maintained until the ﬁnal year of the project, at which time they will be
recovered.

682
CAPITAL BUDGETING DECISIONS
Persistence
Revenues
■The hiking and walking segment of the athletic shoe market is projected
to reach $350 million during year 1 and is growing at a rate of 15% per
year. The segment market share projections for “Persistence” are: year
1: 12%; year 2: 13%; year 3: 16%.
Costs
■AirMax will be able to use an idle section of one of its factories to
produce the hiking shoe.
■AirMax must purchase manufacturing equipment costing $9 million.
The equipment will be depreciated on a 3-year straight-line basis, with
annual depreciation amounts for the three years equal to $3 million.
The cash outlay will be today, in year 0, and depreciation will start in
year 1.
■Variable costs of producing the shoe are expected to be 17% of the
shoe’s sales.
■General and administrative expenses for Persistence will be 20% of
revenues per year.
■The product will not have a celebrity endorser, and advertising and
promotion costs are expected to be $3 million per year, beginning in
year 1.
■The net change in the working capital for the duration of the project
will be –$15 million. The balances will be maintained until the ﬁnal year
of the project, at which time they will be recovered.
■In order to begin immediate production of Persistence, the design tech-
nology and manufacturing speciﬁcations for a simple hiking shoe will
be purchased from an outside source for $50 million before taxes. It
is assumed this outlay takes place immediately and will be expensed
immediately for tax purposes.
This information is entered into a worksheet (see Exhibits 17.13 and
17.14 and ﬁle Ch17-AirMax.xlsx), and the NPV and IRR for the two
projects are computed. In order to do the computation, we need to esti-
mate the cost of capital. Once the base case worksheet models for the two
projects are created by using our estimate of market risk, we incorporate
stand-alone risk by modeling a number of the input parameters as uncer-
tain variables. For example, the forecasts for the market share of the two
products are estimates, and so is the amount of cannibalization that project
Rapid Bounce will cause on other AirMax basketball shoes.

EXHIBIT 17.13
Rapid Bounce’s NPV and IRR calculation.
683

EXHIBIT 17.14
Persistence’s NPV and IRR calculation.
684

Capital Budgeting under Uncertainty
685
17.4.1
Computing the Cost of Capital
First, let us show how we would evaluate the cost of capital for the two
projects. We will use the company WACC as a starting point. In order to
compute it, we need the values of the risk-free rate rf, the company beta, the
excess return on the market, the yields to maturity for AirMax’s outstanding
debt, and the market value weights of debt and equity for AirMax. We will
assume the following:
1. The risk-free rate rf is 5%. This input should be the yield on Treasury
securities with approximately the same maturity as the life of the project.
2. The market risk premium (rM – rf) is 6.2%. This is the approximate
historical excess return on the market. We cannot observe the market
risk premium relevant for evaluating this project, but we make the
assumption that investors will demand a premium that its consistent
with historically observed values.
3. The company beta β is 1.08. This was estimated using data on past
company stock returns and the returns on the Russell 3000, a broad
market index (see worksheet Beta Data in the ﬁle Ch17-AirMax.xlsx).
4. The cost of equity is therefore
re = r f + β · (rM −r f ) = 0.05 + 1.08 · 0.062 = 0.11696 = 11.70%
5. AirMax’s current stock price is $36.42, and there are 59.7 million shares
outstanding. Therefore, the market value of AirMax’s equity is E =
$36.42·(59.7 million) = $2,174.27 million.
6. Suppose AirMax has two bond issues, short-term debt with yield to
maturity 2.72% and long-term debt with yield to maturity 7.05%. The
price per unit for the short-term debt is $1,078.53, and there are 101,408
units in the market. The price per unit of the long-term debt is $1,032.50,
and there are 250,000 units in the market. The total market value of
short-term debt is therefore ($1,078.53 101,408) = $109.37 million,
and the total market value of long-term debt is ($1,032.50 250,000) =
$258.13 million.
7. Based on 6., the total market value for debt is D = $109.37 +
$258.13 = $367.5 million. Of those, 29.8% are short-term debt, and
70.2% are long-term debt.
8. The cost of debt is therefore
rD = (2.72%) · (29.8%) + (7.05%) · (70.2%) = 0.057597 = 5.76%
9. The after-tax cost of debt is
(1 −τ) · rD = (1 −0.40) · 5.76% = 3.46%

686
CAPITAL BUDGETING DECISIONS
10. Based on 5. and 7., the total market value for debt plus equity (D +
E) is $367.5 + $2,174.27 = $2541.77 million. The weight of debt is
14.5% of the total, and the weight of the equity is 85.5% of the total.
11. Based on 4., 9., and 10., the WACC is
rWACC = (1 −τ) · rD · D + rE · E
D + E
= (1 −τ) · rD ·
D
D + E + rE ·
E
D + E
= (3.46%) · (14.5%) + (11.70%) · (85.5%)
= 10.51%
Rapid Bounce is a project that is similar to the company’s existing
projects, so we will assume that it carries the same magnitude of risk and its
cash ﬂows can be discounted using the WACC as the discount rate (i.e., we
will use a discount rate of 10.51%). The Persistence project, on the other
hand, is outside AirMax’s current line of business, so we may deem it more
risky and use a higher discount rate than WACC, say 13%.
With these discount rates, the NPV for Rapid Bounce is $15.31 million,
and the IRR is 15.04%. The NPV for Persistence is $3.92 million, and the
IRR is 16.55%.
If we use the IRR as a criterion, we would pick Persistence. But here we
have an example of capital rationing and two projects with differences of
scale. NPV is the more appropriate criterion to use. Based on the NPV, we
would pick Rapid Bounce.
17.4.2
Computing the NPV Profiles
The next step is to analyze how sensitive the solution is to the assumptions
made about the discount rates to use in the case of each project. Exhibit 17.15
shows the NPV proﬁles for the two projects. We can observe that the NPV
for Rapid Bounce is higher than the NPV for Persistence for low values of
cost of capital, including the current assumed values. At about cost of capital
of 14.5%, the two NPVs become equal, and then eventually both become
negative, with the NPV for Rapid Bounce decreasing faster than the NPV for
Persistence. Clearly, deciding which project to pick is very sensitive to small
changes in the current estimates of the cost of capital for the two projects,
so we may want additional information to make the ﬁnal decision. Note
that so far, we have incorporated only considerations for market risk in the
analysis of the two projects. The next step is to include the stand-alone risks
as well by running a Monte Carlo simulation.

Capital Budgeting under Uncertainty
687
–$80.00
–$60.00
–$40.00
–$20.00
$0.00
$20.00
$40.00
$60.00
$80.00
0%
10%
20%
30%
40%
NPV
Cost of Capital
NPV Rapid Bounce
NPV Persistence
EXHIBIT 17.15
NPV proﬁles for Rapid Bounce and Persistence.
17.4.3
Running a Simulation to Estimate Project
Stand-Alone Risk
Let us list some sources of uncertainty for the two projects, and how we could
model them with probability distributions. See Exhibits 17.16 and 17.17 for
a graphical representation of the different probability distributions used in
the simulation. If you are using @RISK, see also worksheet Simulation in
the ﬁle Ch17-AirMax.xlsx.
Rapid Bounce
1. The projected market size ($18.3 billion) for the athletic shoe market in
Year 1 is an estimate. We will assume that $18.3 billion is the expected
value of the market size, but that the actual value for the market size
will follow a normal distribution that is on average $18,300 million, and
has a standard deviation of $1,100 million. (We explain how we came
up with these numbers later.) This distribution assumes that deviations
above and below the expected market size of 18,300 are equally likely,
and that the average deviation from the estimate will be $1,100 million.
See Exhibit 17.16(A).16
2. The growth of the athletic footwear market was assumed to be 3% per
year. Let us assume instead that it follows a general beta distribution
with parameters α = 5.5, β = 4, minimum = –0.08, and maximum =
0.11. This results in a mean value for growth of 3%; however, it also
allows us to input an anticipated range for the market growth (between
–8% and 11%), and express general optimism about the growth of the

Athletic Footwear Market
Growth of Market
(A)
(B)
Market Share (year 1)
Market Share (year 2)
(C)
(D)
EXHIBIT 17.16
Probability distributions used in the simulation of the NPV of Rapid Bounce. (A) Size of athletic shoe market;
(B) Growth of the athletic shoe market; (C) Market share in year 1; (D) Market share in year 2.
688

Capital Budgeting under Uncertainty
689
market. (The latter is because the probability distribution is left-skewed,
which means that most of the mass is to the right side of the mean, and
higher values for the actual market growth will be more likely to happen
in the simulation.) See Exhibit 17.16(B).
3. One of the important items with the Rapid Bounce project is the reliance
on the celebrity endorser’s reputation for advertising the new basketball
shoe. His image would have a signiﬁcant impact on the market share
AirMax will be able to achieve in the ﬁrst year. AirMax could consider
three possible scenarios: with 95% probability, there will be a very
positive perception of the NBA player, and AirMax’s market share in the
ﬁrst year will be between 1.65% and 2.00%. With 3% probability, the
NBA player’s name will not generate the expected buzz, and AirMax’s
market share in the ﬁrst year will be between 1.40% and 1.60%. Finally,
there is a 2% chance that the NBA player will have a negative image,
and AirMax’s market share in the ﬁrst year will be between 0.20% and
0.40%.17 See Exhibit 17.16(C).
4. We assume that the market shares in years 2 and 3 depend on the
market share established in year 1 with some probability of deviating
from the previous year’s market share. The market share for year 2 will
follow a normal distribution, truncated at 0, with mean equal to the
realized market share in year 1, and a standard deviation of 0.7%. The
market share for year 3 will follow a normal distribution, truncated at 0,
with mean equal to the realized market share in year 2, and a standard
deviation of 0.7%.18 See Exhibit 17.16(D).
5. The estimate for the amount of cannibalization (erosion of sales of
current basketball shoe models) is very rough, and it makes sense to
generate multiple scenarios for this assumption. We assume that the
actual amount of sales erosion is normally distributed with mean equal
to $170 million, and a standard deviation of $20 million.
Persistence
1. The projected market size ($350 million) for the athletic shoe market
in year 1 is an estimate. We assume that $350 million is the expected
value of the market size, but that the actual value for the market size
follows a normal distribution that is on average $350 million, and has
a standard deviation of $10 million. See Exhibit 17.17(A).19
2. The growth of the hiking and walking shoe market was assumed to
be 15% per year. Let us assume instead that it follows a general beta
distribution with parameters α = 2.6, β = 1.9, minimum = 0.08, and
maximum = 0.20. This results in a mean value for growth of approx-
imately 15%; however, it also allows us to input an anticipated range
for the market growth (between 8% and 11%), and express general

Hiking and Walking Market
Growth of Market
(A)
(B)
Market Share (year 1)
Market Share (year 2)
(C)
(D)
EXHIBIT 17.17
Probability distributions used in the simulation of the NPV of Persistence. (A) Size of hiking and walking shoe
market; (B) Growth of the hiking and walking shoe market; (C) Market share in year 1; (D) Market share in year 2.
690

Capital Budgeting under Uncertainty
691
optimism about the growth of the market. (As in item 2 for Rapid
Bounce, the latter is because the probability distribution is left-skewed,
which means that most of the mass is to the right side of the mean, and
higher values for the actual market growth will be more likely to happen
in the simulation.) See Exhibit 17.17(B).
3. We assume that the AirMax market shares for years 1, 2, and 3 are,
as forecasted, 12%, 13%, and 16% on average. The actual market
share for each year will follow normal distributions with standard de-
viations of 5%, 6%, and 7%, respectively. We need to truncate these
normal distributions at 0 because the standard deviations are large rel-
ative to the means, and there is a large probability that a negative
number will be generated for market share in the simulation. When we
truncate the normal distribution at 0, however, its mass shifts to the
right, and its mean increases. In order to preserve means of 12%, 13%,
and 16% for the actual simulated numbers, we draw random numbers
with truncated normal distributions with means of 11.88%, 12.75%,
and 15.78%.
4. We also assume that the market shares in the three years are positively
correlated: with correlation of 0.8 for years 1 and 2 and years 2 and 3,
and with correlation of 0.4 for years 1 and 3.20
We can, of course, incorporate further assumptions. For example, we
may assume that variable costs are uncertain with a particular probabil-
ity distribution. The assumptions we have modeled so far, however, are
sufﬁcient for illustration of the main ideas.
If we plug in the expected values for all assumed probability distributions
into the worksheet, we will get NPV and IRR estimates for Rapid Bounce
and Persistence that are very close to the estimates we obtained in the last
section. However, analyzing the probability distributions of the NPVs tells
a different story. The distributions for the NPVs for Rapid Bounce and
Persistence, as well as relevant statistical summaries from the simulation,
are presented in Exhibit 17.18.
We can observe that while the NPV for Rapid Bounce is higher on
average than the NPV for Persistence ($12.68 versus $3.90 million), its vari-
ability is also higher (standard deviation of $111.04 million versus $18.42
million), higher standard deviation as a percentage of the mean (the coef-
ﬁcient of variation is $8.76 million versus $4.72 million), and lower ﬁfth
percentile of –$160.74 million versus –$26.01 million). The NPV for Rapid
Bounce also has a slightly lower probability of being positive (53.11% ver-
sus 57.32% for the NPV of Persistence). Hence, in terms of risk, Persistence
appears to be the more attractive project.

692
CAPITAL BUDGETING DECISIONS
"Rapid Bounce"
NPV
"Persistence"
NPV
Minimum
–$353.12
–$44.88
Maximum
$539.69
$78.75
Mean
$12.68
$3.90
Standard
deviation
$111.04
$18.42
Coefficient of
variation
$8.76
$4.72
Skewness
0.1840
0.1692
Kurtosis
3.1529
2.8641
Mode
$12.03
–$0.49
5% Percentile
–$160.74
–$26.01
50% Percentile
$8.33
$3.55
95% Percentile
$205.64
$35.09
Prob. NPV >=0
53.11%
57.32%
EXHIBIT 17.18
Simulation output: Distribution for the NPV of Rapid Bounce;
Distribution for the NPV of Persistence; Statistical summary.
Additional useful information can be obtained if we compare the NPVs
on a scenario-by-scenario basis. As discussed in section 4.2.3 of Chapter 4,
this can be accomplished by creating an additional output variable in the
worksheet that measures the difference between the two NPVs, and ana-
lyzing its simulated distribution. The results are presented in Exhibit 17.19.
NPV("RapidBounce")-
NPV("Persistence")
Minimum
–$383.47
Maximum
$551.78
Mean
$8.78
Standard deviation
$112.58
Coefficient of variation
$12.83
Skewness
0.1813
Kurtosis
$3.15
Mode
–$13.50
5% Perc
–$167.18
50% Perc
–$9.42
95% Perc
$202.21
EXHIBIT 17.19
Simulation output for the difference between the NPV of Rapid
Bounce and the NPV of Persistence.

Capital Budgeting under Uncertainty
693
It can be seen that the NPV of Rapid Bounce was higher than the NPV of
Persistence in about 51.5% of the generated scenarios, and by about $8.78
million on average. So, on a scenario-by-scenario basis, Rapid Bounce ap-
pears to be the more attractive project.
It is difﬁcult to decide which one of the two options to choose. The
answer will depend on management’s priorities. However, the information
obtained by running a simulation adds to the information obtained from the
ﬁnancial analysis at the ﬁrst step of the project evaluation process and this
helps management make a more informed decision.
17.4.4
Determining the Inputs to the Simulation
In the last section, we explained how one can incorporate uncertainty about
the inputs in the model, and interpret the results from the simulation. How
can one come up with the parameters used to construct the different proba-
bility distributions?
The ﬁrst question to ask ourselves is whether the probability distribu-
tion representing an estimate should be symmetric or skewed. A symmetric
distribution would assume that deviations above and below the estimated
value are equally likely. A skewed distribution would enable us to impart
some subjective judgment. Recall the probability distributions we used to
model the growth of the athletic footwear and the hiking and walking shoe
markets. A right-skewed distribution would have more of its probability
mass to the right of the mean, and most simulation trials will result in out-
comes that are below the mean. A left-skewed distribution would have more
of its probability mass to the left of the mean, and most simulation trials
will generate outcomes that are above the mean.
The second question to ask is whether the actual values are clustered
around the estimate, or could be far from the estimate. For example, both
the normal distribution and the uniform distribution are symmetric, but
the uniform distribution assumes that the values can be anywhere on the
speciﬁed range with the same probability, while the normal distribution
incorporates the assumption that the values are likely to be close to the
mean—the closer to the mean they are, the more likely they will be generated
during the simulation.
Important variables that have a big impact on the bottom line, such as
sales or market share, are often forecast by analysts with a lot of experience
in the industry. Simulation can be used to combine forecasts from multiple
analysts by ﬁguring out the average estimate and the variability in these
estimates.
Finally, statistical techniques can be used to derive estimates from his-
torical data. For example, our estimate of $18.3 billion for the size of the

694
CAPITAL BUDGETING DECISIONS
athletic footwear market was derived by recording the market size for the
20 years prior to the present time, running a regression to determine if there
is a trend, and using the regression to forecast the next point, as well as
the variability in the estimate. The data and the regression output can be
found in worksheet Market Size Data of the ﬁle Ch17-AirMax.xlsx, and are
shown in Exhibit 17.20.
The response variable in the regression is the market size, and the ex-
planatory variable is the year. The regression equation can be recovered
from the regression output. We have
Market size ($ billions) = 11.68 + 0.32 · Year
Therefore, to make a forecast for next year (year 21), we plug in 21 for
Year:
Market size forecast ($ billions) = $11.68 + $0.32 · 21 = $18.30
This is the point estimate. The standard error of the regression ($1.0792
billion, or approximately $1080 million) tells us how far the actual point
will be from this estimate on average. This is why we plugged in 18,300 as
the mean, and $1,100 (a slightly more conservative estimate) as the standard
deviation for the normal distribution we used to model the market size for
athletic footwear in year 1.
Estimating inputs to the simulation reliably adds an additional step to
the simulation process, and may require a lot of time and resources. Some
software packages focused speciﬁcally on simulation, such as @RISK, con-
tain tools that allow the modeler to decide whether achieving an additional
degree of accuracy in the estimate of given simulation inputs is worth the
extra time. In particular, @RISK can create tornado graphs, graphs that list
the simulation input variables that impact the variability in the simulation
output variable in order of importance. Exhibit 17.21 contains the tornado
graphs for the NPVs of Rapid Bounce and Persistence.
There are several types of tornado graphs, including regression coefﬁ-
cient graphs, correlation graphs, and regression-mapped values graphs. A
user of @RISK can toggle between the different types of graphs.21 We choose
to show regression-mapped values tornado graphs in Exhibit 17.21 because
the interpretation is quite intuitive. The length of the bar that corresponds
to a speciﬁc simulation input variable is the amount of change in the output
variable that will result from a change in the input variable equal to one
standard deviation change. In other words, when the input changes by +1
standard deviation, the output will change by the value on the horizontal
axis associated with the length of the bar. For example, Exhibit 17.21(A)

Year
Market Size
($ billions)
1
11.44
2
11.72
3
13.85
4
13.68
5
12.23
6
12.01
7
13.92
8
13.25
9
15.61
10
14.64
11
16.11
12
15.07
13
17.16
14
16.37
15
17.82
16
18.08
17
17.65
18
16.12
19
15.87
20
17.21
SUMMARY OUTPUT
Regression Statistics
Multiple R
0.871153984
R-square
0.758909264
Adjusted R-square
0.745515334
Standard Error
1.079220811
Observations
20
ANOVA
df
SS
MS
F
Significance F
Regression
1
65.99369721
65.9937
56.66069
5.77E-07
Residual
18
20.96491608
1.164718
Total
19
86.95861329
Coefficients
Standard Error
t-stat
P-value
Lower 95%
Upper 95%
Intercept
11.68333317
0.501332015
23.30458
6.77E-15
10.63007
12.73659
Year
0.315021654
0.041850388
7.527329
5.77E-07
0.227097
0.402946
EXHIBIT 17.20
Data for determining the size of the athletic footwear market.
695

696
CAPITAL BUDGETING DECISIONS
EXHIBIT 17.21
Sensitivity of (A) Rapid Bounce NPV and (B) Persistence
NPV to different factors.
tells us that the most signiﬁcant variable for the variability in the NPV of
Rapid Bounce is the market share in year 3. A change of +1 standard de-
viation in the market share from year 3 will increase the NPV of Rapid
Bounce by $61.088 million. The fourth most-inﬂuential input variable is
the amount of cannibalization of sales in a year. A change of +1 standard
deviation in the amount of cannibalization will decrease the NPV of Rapid
Bounce by $20.503 million. These estimates will vary from simulation to

Capital Budgeting under Uncertainty
697
simulation—they are obtained by running a regression on the generated
simulation inputs and outputs.
Tornado graphs showing regression coefﬁcients and correlation coef-
ﬁcients contain similar information. In the regression coefﬁcients tornado
graph, the length of the bar shown for input variable shows the number of
standard deviation the NPV will change if the input variable changes by one
standard deviation. In the correlation coefﬁcients tornado graph, the length
of the bar shows the strength of the correlation between the changes in the
input variable and the NPV.
In this example, the conclusion is that it is most important to make sure
that the estimates of the market shares in year 3 and year 2, as well as the
size of the market, are accurate. Those input distributions are responsible
for the majority of the variability in the estimate of the NPV.
17.5
MANAGING PORTFOLIOS OF PROJECTS
Capital budgeting shares many aspects of ﬁnancial investment management.
Although investment projects at companies have traditionally been evaluated
on a single-project basis, there are many arguments for using tools from
the management of ﬁnancial investments in the corporate ﬁnance context.
Projects are often linked to one another, and subject to common risk factors.
They can be characterized by their risk-return proﬁles. The theory of optimal
portfolio management and operations research tools such as optimization
can and should be applied in this area, although few companies actually do.
This area of research is known as project portfolio management (PPM).
Most known PPM methods and tools are based on subjective weighted
scoring methods, not quantitatively rigorous methods with roots in mod-
ern portfolio theory or operations research. The ﬁeld has traditionally been
tied to information technology projects at companies, and has only recently
begun to attract attention as an important area of study. It is easy to un-
derstand how the problem of optimal project management can be related to
the problem of optimal investment management. The important thing is to
deﬁne project outcomes and risks in terms of easily quantiﬁable, statistically
meaningful metrics.
SUMMARY
■One of the most important functions in ﬁnancial management is the
evaluation of capital expenditures. Decisions involving capital expendi-
tures are known as capital budgeting decisions.

698
CAPITAL BUDGETING DECISIONS
■Unlike working capital decisions, capital budgeting decisions commit
funds for a time period longer than one year and may have an impact
of a company’s strategic position within its industry.
■The capital budgeting process encompasses the initial investment screen-
ing and selection through the post-completion audit of the project. Clas-
sifying capital projects along different dimensions (that is, economic life,
risk, and dependence on other projects) is necessary because these char-
acteristics of the projects affect the analysis of the projects.
■The six most commonly used techniques for evaluating capital budget-
ing proposals are net present value, proﬁtability index, internal rate of
return, modiﬁed internal rate of return, payback period, and discounted
payback period.
■The net present value method and the proﬁtability index are preferred
methods because they consider all the project’s cash ﬂows, involve dis-
counting (which considers the time value of money and risk), and are
useful in cases in which projects are mutually exclusive.
■The net present value method produces an amount that is the expected
value added from investing in a project. That is, the net present value is
an estimate of the value added from an investment project.
■The proﬁtability index translates the NPV into an indexed value, and
can be useful in ranking projects.
■The internal rate of return is the yield on the investment. It is the discount
rate that causes the net present value to be equal to zero. The internal rate
of return is hazardous to use when selecting among mutually exclusive
projects or when there is a limit on capital spending.
■The modiﬁed internal rate of return is a yield on the investment, assum-
ing that cash inﬂows are reinvested at some rate other than the internal
rate of return. This method overcomes the problems associated with
unrealistic reinvestment rate assumptions inherent in the internal rate
of return method. However, this method is hazardous to use when se-
lecting among mutually exclusive projects or when there is a limit on
capital spending.
■The payback period and the discounted payback period methods pro-
vide a measure of the time it takes to recover the initial investment in
a project. Both of these methods have limitations in that they fail to
consider all cash ﬂows from a project.
■When there are scale differences among projects, the net present value
should be used.
■When evaluating projects that have different economics lives, the differ-
ent lives must be taken into account before selecting projects based on
one of the six methods described in this chapter.

Capital Budgeting under Uncertainty
699
■Evaluating capital projects requires assessing the risk associated with
the future cash ﬂows. This risk may be measured in terms of the market
risk or the stand-alone risk.
■Market risk is typically incorporated into decision making by using a
cost of capital that reﬂects the project’s risk in relation to the company’s
capital structure and the portfolio of projects it holds.
■The stand-alone risk of a project can be estimated using statistics and
simulation techniques.
■Simulation can be used to determine the distributions of possible out-
comes for different metrics of a project’s promise, and to compare out-
comes from different projects on a scenario-by-scenario basis.
SOFTWARE HINTS
@RISK
This section explains how the simulation in the AirMax case was run. Of
course, we start by ﬁlling out a static worksheet model in which all de-
pendencies between the different variables are incorporated through Excel
formulas. For the rest of this section, we will be referring to worksheet
Simulation in the ﬁle Ch17-AirMax.xlsx.
Creating the Simulation Inputs
The simulation inputs are created by sim-
ply clicking on the Deﬁne Distribution in the Model group under the @RISK
tab, and entering the appropriate distribution. Given the assumptions in the
model, we have the following entries for simulation input distributions (see
Exhibit 17.22):
The two more complex modeling issues are:
1. How to model the scenarios for the market share in year 1 in the case
of Rapid Bounce, and
2. How to create the correlated variables for the market shares in different
years in the case of Persistence.
To accomplish 1. we create an array in cells A27:D30 (see Exhibit
17.23). It contains the scenario number (cells A28:30), the lower and
upper bounds of the intervals from which the random number for the mar-
ket share will be drawn in each scenario (cells B28:B30), and the probability
with which each scenario occurs (cells D28:D30). Cell B31 contains a for-
mula (RiskDiscrete(A28:A30,D28:D30)) that makes sure that a random

700
CAPITAL BUDGETING DECISIONS
EXHIBIT 17.22
Simulation input distributions.
Variable
Cell
Reference
@RISK/Excel Formula
Rapid Bounce
Size of athletic
footwear market
B4
RiskNormal(18300,1100)
Growth of market
B5
RiskBetaGeneral(5.5,4,-0.08,0.11)
Random scenario
for market share
in year 1
B31
RiskDiscrete(A28:A30,D28:D30)
Market share for
year 1
B6
RiskUniform(VLOOKUP(B31,A28:C30,2),
VLOOKUP(B31,A28:C30,3))
Market share for
year 2
B7
RiskNormal(B6,0.007,RiskTruncate(0,))
Market share for
year 3
B8
RiskNormal(B7,0.007,RiskTruncate(0,))
Cannibalization
per year
B13
RiskNormal(l70,20)
Persistence
Size of hiking and
walking market
K4
RiskNormal(350,10)
Growth of market
K5
RiskBetaGeneral(2.6,1.9,0.08,0.2)
Market share in
year 1
K6
RiskNormal(0.1188,0.05,
RiskTruncate(0,),
RiskCorrmat(PMktShareCorrelations,1))
Market share in
year 2
K7
RiskNormal(0.1275,0.06,
RiskTruncate(0,),
RiskCorrmat(PMktShareCorrelations,2))
Market share in
year 3
K8
RiskNormal(0.1578,0.07,
RiskTruncate(0,),
RiskCorrmat(PMktShareCorrelations,3))
number (1, 2, or 3) is drawn from the scenarios in cells A28:30 with the
probabilities assigned in cells D28:D30. To generate the actual market share
in year 1 in cell B6, we use VLOOKUP22 to look up the upper and lower bound
for the interval corresponding to the random scenario drawn in cell B31.
The formula
RiskUniform(VLOOKUP(B31,A28:C30,2),VLOOKUP(B31,A28:C30,3))

Capital Budgeting under Uncertainty
701
EXHIBIT 17.23
Array for modeling the market scenarios for Rapid Bounce for
year 1.
draws a random number between the lower bound for the range
(found in the second column of the array A28:C30 with the for-
mula VLOOKUP(B31,A28:C30,2)) and the upper bound for the range
(found in the third column of the array A28:C30 with the formula
VLOOKUP(B31,A28:C30,3)).
To accomplish 2. select the three cells corresponding to the market
shares in years 1, 2, and 3 and right-click on them, then select @RISK and
click Deﬁne Correlations (see Exhibit 17.24.) This opens the @RISK Deﬁne
Correlations dialog box (see Exhibit 17.25), which we can use to specify a
EXHIBIT 17.24
Deﬁning correlations for market shares in years 1, 2, and 3 for
Persistence.

702
CAPITAL BUDGETING DECISIONS
EXHIBIT 17.25
@RISK Deﬁne Correlations dialog box.
correlation matrix and name it. The matrix then can be saved somewhere
on the worksheet. (We saved it in cells S2:V5 in worksheet Simulation.)
We then need to make sure to specify which cells were output cells
by clicking the Add Output button. These cells are E24 (NPV for Rapid
Bounce), N20 (NPV for Persistence), and N23 (Difference in the NPVs of
Rapid Bounce and Persistence).
Running the Simulation and Formatting Output
The simulation is run by
clicking the Start Simulation in the Simulation group under the @RISK tab.
The output can be obtained by clicking the Browse Results in the Results
group, and then clicking the cell in the worksheet that contains the output
variable of interest. Detailed statistics and output directly in Excel worksheet
format can be obtained by clicking the Excel Reports in the Tools group
under the @RISK tab, and selecting the simulation data of interest.

Capital Budgeting under Uncertainty
703
EXHIBIT 17.26
Creating a tornado graph.
Creating Tornado Graphs
Tornado graphs are created by clicking on the
tornado button in the graph for the output variable (see Exhibit 17.26). As
explained in Appendix B on the companion web site, such a graph appears
automatically at the end of a simulation run if you click on an output or
input cell. Alternatively, it can be called by clicking on the Browse Results
button in the Results group in the @RISK tab after a simulation.
MATLAB
MATLAB is not as well-suited for performing a simple simulation directly
off a worksheet as @RISK, but the whole model for NPV and IRR cal-
culation for the two projects can be implemented in a MATLAB script,
scenarios can be generated for the different input variables, and the output
variable distributions saved and evaluated. The important thing is to repre-
sent correctly the relationships between the different variables in the base
case model.
NOTES
1. MS Excel and MATLAB’s Financial Toolbox have commands for comput-
ing NPV. Excel’s command is =NPV(Discount rate, Array of cash

704
CAPITAL BUDGETING DECISIONS
flows). Excel assumes that the ﬁrst value in Array of cash ﬂows occurs one
time period from now, and it discounts it to the present. Therefore, to obtain
the correct estimate, we need to add the cash ﬂow at time 0 to the NPV for the
remaining cash ﬂows. In this particular example, we would enter
-1500000 + NPV(0.10,0,200000,500000,900000,1000000)
In MATLAB, the appropriate function to use is pvvar(CashFlows,
DiscountRate). In contrast to Excel, MATLAB assumes that the ﬁrst cash
ﬂow happens at time 0, and does not discount it. To calculate the NPV in our
example, we would enter
pvvar([-1500000,0,200000,500000,900000,1000000],0.10)
2. We will see an example of this situation in section 17.2.7.
3. In Excel, the IRR can be computed with the formula =IRR(Array of cash
flows, initial guess), where initial guess is an optional argu-
ment, and speciﬁes the starting point from which the numerical algorithm tries
to determine the value of the IRR. It is best if initial guess is a point close
to the actual IRR. In the case of Project X, we used the investment proﬁle to
determine an approximate starting point of 14.5%. In MATLAB, the Financial
Toolbox contains the function irr(CashFlow), which can be used to compute
the IRR for a stream of cash ﬂows at equal time periods, or xirr(CashFlows,
CashFlowDates), which can be used to compute the IRR for a stream of cash
ﬂows at unequal time periods.
4. It may or may not—and that is the problem. It is possible to make a value-
maximizing decision by using the IRR method, but it is also possible to make a
decision that is not value-maximizing by using the IRR method.
5. We will explain the concept of cost of capital and its estimation in more detail
in sections 17.3.1 and 17.3.3 in this chapter. For now, it is important to know
that different projects for the same company may have different costs of capital
depending on the riskiness of the projects. A company with a large portfolio of
projects has an “averaged-out” cost of capital that can be estimated from the
information available from capital markets, but estimating the cost of capital
for individual projects requires additional care.
6. An annuity is an income payable in equal installments at speciﬁc intervals for a
period of length N. The present value of an annuity is
PV =
N

i=1
A
(1 + r)i
where r is the interest rate per period. It can be shown that
PV = A
r −
A
r · (1 + r)N = A
r ·

1 −
1
(1 + r)N


Capital Budgeting under Uncertainty
705
and from there it follows that the equal installments each period should be
A = r · (1 + r)N · PV
(1 + r)N −1
If the annuity is paid for an inﬁnite number of periods (i.e., N is inﬁnity), its
present value is
PV = A
r
7. Based on the equation for A in endnote 6, we have PV = $157.47, r = 4%,
N = 5, and, therefore, A = $35.37.
8. See also section 2.3 of Chapter 2.
9. It is sometimes difﬁcult to value the market value of debt. Generally, we would
take all outstanding bond issues for the company, and multiply the number of
units issued by their market price. In some cases, we may substitute the book
value.
10. See section 11.1 of Chapter 11 for an introduction to the CAPM.
11. See section 11.1 of Chapter 11.
12. See section 3.6 of Chapter 3.
13. See, for example, the survey by Graham and Harvey (2002).
14. All names and references in this case are ﬁctional, and the situation is simpliﬁed
on purpose so as to illustrate the main points of this chapter. This case study
is based on the case Reebok International: Strategic Asset Allocation by Mark
Potter, Babson College, 1998. We thank Professor Potter for allowing us to
create a version of the case for this example. We also thank Professors Kathleen
Hevert and Richard Bliss, Babson College, for providing some of the data and
ideas for the simulation application.
15. Under the straight-line depreciation method, annual depreciation equals a con-
stant proportion of the initial investment (less salvage value, which here we
assume to be 0). In general, including salvage value in the calculations is done
for ﬁnancial reporting purposes. Here, we are concerned with the cash ﬂow
impact of taxes. For tax purposes, it is not necessary for ﬁrms to include salvage
value.
16. Note that the assumption that the market size follows a normal distribution
technically does not preclude the possibility that in the process of the simulation,
negative numbers for market size would be simulated. (This is because the
normal distribution stretches from negative inﬁnity to positive inﬁnity.) In this
particular case, we do not need to worry much about this issue because the
distance between 18,300 and 0 is approximately 17 standard deviations (where
the standard deviation is 1,100). Outcomes that are more than 6 standard
deviations from the mean have a miniscule probability of occurring.
17. This kind of assumption—where a range for possible values needs to be selected
randomly before the number within that range is selected randomly—is a little

706
CAPITAL BUDGETING DECISIONS
bit more difﬁcult to model than what we have seen so far. The trick is to create
a random variable that corresponds to the scenario number drawn (in this case,
there are three possible scenarios—one for each range of values) and then base
the random number generation on the outcome of this random variable. If
we use @RISK in Excel, we can create a cell dedicated to storing the random
scenario drawn (cell B31 in worksheet Simulation), and then use VLOOKUP to
reference that cell and the range of values to which the scenario corresponds
when simulating market share in the ﬁrst year (cell B6).
18. Here, we truncate the normal distribution at 0 because we have a nontrivial
probability of generating a negative number for the market share during the
simulation if we do not. If the standard deviation is 0.7%, then 0 is approxi-
mately two to three standard deviations from the mean of the distribution, and
even though the probability of generating a negative number is still small (less
than 2.5%), the event is not as unlikely to happen as it was in the case of the
projected market size.
19. Similarly to the projected market size for Rapid Bounce, here we are not con-
cerned about truncating the normal distribution so that 0 is the minimum value
we can generate. The standard deviation is small relative to the mean value of
the normal distribution.
20. See worksheet Simulation in the ﬁle Ch17-AirMax.xlsx and Chapter 4’s Soft-
ware Hints for instructions on how to simulate correlated random variables.
21. See this chapter’s Software Hints.
22. Recall that VLOOKUP(Value, Array, ColumnNumber) tries to ﬁnd Value
in the ﬁrst column of Array, and returns the entry in the same row and in
column ColumnNumber.

CHAPTER18
Real Options
T
he capital budgeting tools presented in Chapter 17 are widely used and
represent the fundamentals of the so-called discounted cash ﬂow (DCF)
analysis framework for evaluating investment decisions. However, an ex-
plicit assumption underlying the DCF framework is that once the decision
is made at the beginning, future stages of the project happen as planned. In
reality, companies are constantly reevaluating their strategies and modifying
their decisions. If cash ﬂows are better than expected, the project may be
expanded. If cash ﬂows are worse than expected, the project may be aban-
doned. Management may decide to postpone the project by a year hoping
for better market conditions, or change the input mix in response to changes
in the prices of raw materials.
What all of these situations have in common is that the company has
options—an option to change its course of action in the future, an option to
acquire an asset in the future, or an option to delay the project. These options
enhance a project’s investment value because management has the right, but
not the obligation, to take actions in the future. In each case, management
can do that because it will have access to information not available at the
time of the original decision.
Options in the corporate ﬁnance context are referred to as real options.
In contrast to ﬁnancial options, in which the underlying is a ﬁnancial instru-
ment or ﬁnancial index, the underlying in the case of real options is a physical
asset. The importance of including real options in ﬁnancial valuation can be
appreciated by realizing that virtually no research-and-development (R&D)
project would be undertaken according to the net present value (NPV) crite-
rion (the overall cash ﬂows would be negative), were it not for the option to
exploit potential results from the research with follow-up investments. We
will see some examples in this chapter.
Pharmaceutical companies embraced real options as a tool early on. This
is not surprising because they face such situations all the time. Beginning
with a small number of chemical components with the potential to induce
707

708
CAPITAL BUDGETING DECISIONS
the necessary reaction in the human body to cope with a particular illness,
only about 1 in 15 eventually shows enough potential to become an actual
drug. The drug then needs to undergo a number of stages of clinical tests
to achieve Federal Drug Administration (FDA) approval: preclinical testing
involving animals, testing on healthy humans to evaluate side effects, and
testing on human subjects with the actual illness. The life of such projects is
often in the 12- to 15-year range. When the traditional NPV of such projects
is evaluated at the beginning, it is often negative, given the small probability
that a drug will make it through the process. However, what the traditional
NPV does not take into consideration is the fact that at any stage, the
company can drop a project that does not appear promising. The company
therefore does not need to incur all subsequent costs in the process. Instead
of thinking of such projects as a series of cash ﬂows, it is more correct to
think of them as a series of options on options. For example, the investment
in the study of the chemical components can be thought of as the purchase of
an option to develop the drug, the development of the drug can be thought
of as the purchase of an option to do preclinical testing, and so forth.
While real options analysis has become a standard tool for many com-
panies’ capital budgeting decisions, there are also many that have tried and
abandoned the approach. A 2001 “Management Tools and Techniques”
survey by Bain & Company of 451 senior executives who had tried the real
options approach found that a third of them had given up using it in the
same year (Copeland and Tufano 2004). Real option valuation is indeed a
challenging undertaking. We will obtain a better intuition about this fact
as we discuss examples in this chapter, but most generally, the difﬁculty
stems from the fact that fundamental option pricing formulas from the se-
curities markets, such as the Black-Scholes formula,1 do not apply exactly
to situations in which the underlying securities are not liquid and traded
in markets in which no arbitrage can be assumed. Nevertheless, there is
widespread recognition of the fact that the insights one can obtain from real
options analysis are valuable. Given the fact that ﬁnancial derivative pric-
ing formulas do not apply easily in the real options framework, however,
sensitivity analysis and simulation become even more important tools in
this context.
This chapter covers some basic types of real options, such as options to
expand, abandon, and wait. The variety of real option types is even greater
than the variety of ﬁnancial options, so we cannot easily cover even all
basic types of real options. We focus on a few fundamental applications
in order to illustrate the advantages of simulation and dynamic program-
ming techniques for real options valuation. For a recent treatment of the
subject and more examples, see also Moore (2008), Finnerty (2008), and
Mun (2006).

Real Options
709
18.1
TYPES OF REAL OPTIONS
Real options can most generally be divided into the following types:
■Option to expand
■Option to abandon
■Option to delay
■Option to choose
■Option to switch
■Option for sequential investments
Let us consider some examples:
■Option to expand or abandon. When considering an acquisition, man-
agement thinks not only about the cash ﬂows that are generated from
the operations of the company to be acquired, but also about the strate-
gic advantages that come with the deal. Suppose that the company to
be acquired owns the intellectual property on a new technology, but it
needs development funding. If the new technology is highly successful,
buying the company and investing capital into development will pro-
vide the acquiring company the option to expand into further proﬁtable
areas. If the new technology is not successful, the acquiring company
will have the option to abandon the project at some point in the devel-
opment phase, and perhaps sell off any remaining tangible assets of the
acquired company.
■Option to delay. Consider an American company that needs to forecast
demand for equipment it produces months in advance, so that it can
have sufﬁcient time to order the parts, assemble them, and ship them
to its customers in Europe. Management could consider the project of
building assembly plants in Europe, so that it can do assembly there and
reduce the risks associated with its forecasts. While building assembly
plants in Europe will incur costs, an evaluation of the overall costs
and beneﬁts of the project the company should include the value of
the option that building these plants will give the company—the option
to delay making the decision on how much equipment to produce until
demand is known better. In other words, the cost of acquiring an option
to delay production is the cost of building the assembly plants in Europe,
and the beneﬁts from holding the option are the savings associated with
not having to forecast demand too far in advance.
■Option to choose. Consider a company like Boeing that has a huge
amount of development costs and many years of development for its

710
CAPITAL BUDGETING DECISIONS
product. The company can only produce a limited number of models
at a time, and cannot afford to be wrong about the type of aircraft it
should be building. Such a company beneﬁts from creating an option
to choose by investing in several promising projects at the same time
and running them in parallel, with the goal of eliminating all but one
at the end. This way, the company can evaluate the merits and the
drawbacks of each version of the product as more information becomes
available over time, and learn from product prototypes even if they do
not become the model it produces in the end. The cost of the option to
choose is the development cost of the parallel projects, and the beneﬁt
is the hedge this strategy provides against choosing the wrong direction
at the beginning.
■Option to switch. Consider a company in the oil and gas industry.
The management of such a company may consider a project to invest
in making its reﬁneries more ﬂexible with respect to output. Outputs
include heating oil, diesel, or different kinds of fuel. This project will
give the company the option to switch its output to one that is more
proﬁtable depending on prevailing market prices.
Similarly, a company may vary its input mix in order to minimize
the impact of market prices of raw materials on its operations. For
example, a company may hold an inventory of excess raw materials (thus
increasing inventory costs), or maintain excess contractual obligations
with multiple vendors for similar materials in different parts of the
world, so that it can switch vendors when a particular raw material
becomes relatively expensive in that part of the world.
■Option for sequential investments. The pharmaceutical company that
invests in the research and development (R&D) of a new drug is an
example of a company that creates options for sequential investment. At
each stage of the project, the company’s management has the option to
wait, abandon, or expand into subsequent stages. Thus, an R&D project
that may appear unproﬁtable according to the NPV criterion could in
fact be proﬁtable because the options to defer costs and proceed only if
the current stage is promising create additional value for the project.
18.2
REAL OPTIONS AND FINANCIAL OPTIONS
There are many similarities between real options and ﬁnancial options. For
example, the proﬁle of a typical option to expand looks very much like the
proﬁle of a long position in a classical ﬁnancial call option.2 Speciﬁcally, it
is often the case that a company pays a setup cost for the option to acquire
a larger project, or expand, in the future. This setup cost is equivalent to

Real Options
711
paying the premium on a call option—the option to purchase an asset at
a predetermined (strike) price in the future. The estimated current value
of this future expansion project is today’s “stock price” in the classical
option pricing framework. Over time, the value of the project may change
depending on market conditions and the company’s strategy. In the future,
management may choose to expand if the immediate cost of doing so (paying
the “strike price”) is lower than the value of the project at the future date.
Note that the company will not have the obligation to expand, and will
expand only of the conditions are favorable. The maximum loss incurred by
the company would be the value of the premium of the call option.
Similarly, the proﬁle of a typical option to abandon looks very much
like the proﬁle of a long position in a classical ﬁnancial put option.3 Namely,
a company may invest money into a project today (which is equivalent to
paying the premium on a put option). If in the future the estimated beneﬁt
of continuing the project (equivalent to the future “stock price”) is less than
the estimated cost of continuing with the project (equivalent to the “strike
price”), then the company’s management can exercise the option to abandon
the project. Again, the maximum loss the company can incur is the value of
the premium for acquiring the option.
Sequential investment decisions such as R&D are best understood as
compound options, that is, options on options. Other types of real options
have their own interpretations, as we will see later in this chapter. The
takeaway from this discussion is that, given the many parallels between real
options and ﬁnancial options, we should be able to tap into the large amount
of research on pricing ﬁnancial options to value investment projects as well.
In fact, the Black-Scholes option pricing formula4 and binomial trees are
widely used for real option valuation.
However, it is important to keep in mind that there are limitations in
applying ﬁnancial option pricing methods for valuing real options. These
limitations include:
■The underlying asset for a ﬁnancial option is a publicly traded asset, and
its market value is observable. The underlying asset for a real option
is typically a physical asset, such as a plant or a resource deposit, and
its value is not readily available. Real options are therefore inherently
proprietary in nature, with no market comparables.
■Financial options typically have short maturities. Real options have
multiyear durations.
■Financial options have clearly spelled out exercise features. This is not
the case for real options, where there is ﬂexibility with respect to the
timing and nature of exercise of the option, and therefore additional
assumptions must be made for the purposes of valuing the real option.

712
CAPITAL BUDGETING DECISIONS
■The value of ﬁnancial options cannot be manipulated by the trader
because the prices of ﬁnancial options are driven by the value of the
underlying, which in turn is determined by exogenous market forces. In
contrast, the value of strategic real options can be changed by timing,
management actions, and ﬂexibility.
■As we explained in Chapter 13, a fundamental principle underlying
ﬁnancial option pricing is the assumption that no arbitrage exists in
the markets. This condition allowed us to price ﬁnancial options as the
expected values (under risk-neutral probabilities) of their future payoffs
at the risk-free rate. Given the fact that the underlying asset is not
traded in the case of real options, the no-arbitrage condition does not
hold exactly, so it is not clear if the same principle can be applied. It is
applied in practice for lack of a better method, but one needs to exercise
caution in interpreting the results.
■Given our discussion in the previous item, there is no easy way to
determine the rate appropriate for discounting the cash ﬂows from real
options. The conclusion that we should use the risk-free rate when
discounting cash ﬂows from ﬁnancial options came from the assumption
of no-arbitrage. This principle does not quite hold in the case of real
options. We will discuss this issue further in section 18.7.1.
Some real options are directly valued by adjusting ﬁnancial option pric-
ing methods. Others require more creative modeling. Since the focus of this
book is on applications of simulation and optimization in ﬁnance, we will
give examples mainly of real options that allow for pricing using simulation
or optimization (dynamic programming) techniques. For further examples,
see, for instance, Mun (2006).
18.3
NEW VIEW OF NPV
As the concept of real options became widespread, some economists began
referring to the traditional NPV as the neoclassical NPV.5 In other words,
NPV is the value of a project assuming there is no ﬂexibility and no option-
ality. If we add the present value of all options inherent in the project to
NPV, we obtain NPV*—the total value of the project, including options.
We may think of NPV* as a “postmodern” NPV. The decision rule for
evaluating project that we associate with NPV* is the same as the decision
rule we associate with NPV—if NPV* is greater than 0, we should accept
the project; otherwise we should reject it. Similarly, if we are considering
several projects and there is capital rationing, the project with the highest

Real Options
713
NPV* should be selected. The only difference is that NPV* reﬂects project
potential more fully than NPV.
Is the traditional NPV bad? Not necessarily. As with any model, NPV
is good as long as the underlying assumptions hold. And, as we will see
in this chapter, the valuation of the options embedded in projects can be
challenging and not very accurate. Hence, it is valuable to have an estimate
of the traditional NPV. If it is negative, we could interpret the amount it
takes to make it zero as the minimum amount at which we should value the
ﬂexibility in order to make the project worthwhile. The NPV method still
provides the framework within which to evaluate the overall proﬁtability of
the project.
Let us consider a simple example to illustrate this point. Management is
evaluating the opportunity to invest in an R&D project for a new product.
The life of the project is four years, and the costs are $1.2 million per year.
After the end of the R&D project (in year 5), the management can spend
an additional $10 million to launch the product, and the expected NPV of
the cash ﬂows from that point on (in year 5 dollars) is $21 million. Assume
that the risk-free rate is 5% per year and that the discount rate is 14%. (For
consistency, assume that both are continuously compounded.) Should the
company invest in the R&D project?
Exhibit 18.1 contains a snapshot of worksheet Classical NPV of the
ﬁle Ch18-ExpansionAbandonOptions.xlsx, in which the classical NPV is
computed. The costs for each year are listed in cells B7:F7. The revenue of
$21 million (in year 5 dollars) is shown in cell F8. To compute the NPV, we
discount the costs and the revenues to the present by multiplying each cash
ﬂow by e–r·t, where r is the applicable discount rate, and t is the time period in
which the cash ﬂow happens. Since the costs are certain cash ﬂows (we will
deﬁnitely spend them), and the revenues are uncertain cash ﬂows, we use
the risk-free interest rate of 5% to discount the costs, and the discount rate
of 14% to discount the revenues.6 The discounted costs and revenues are
shown in cells B10:F11. For example, the discounted value of the revenues
in year 5 is e–0.14·5 · ($21) = $10.43 million, and the discounted value of the
costs in year 5 is e–0.05·5 · ($10) = $7.79 million.
The sum of all discounted cash ﬂows results in an NPV of –$1.6 million.
Since the NPV is negative, the company should technically not invest in the
R&D project. However, this valuation omits a very important detail. The
NPV is computed with the information we have currently. The revenues
in year 5 are a rough estimate. That estimate can change a lot during the
four years of R&D. For example, the R&D stage may not result in a viable
product. If the projected value of future revenues falls, the company may
decide, at the end of the R&D project, that it is not worthwhile to spend
the additional $10 million to launch the product. Additionally, the company

714
CAPITAL BUDGETING DECISIONS
EXHIBIT 18.1
Calculation of classical NPV.
may have the option to abandon the project while it is still in development
in years 1 through 4.
The NPV that takes into consideration this ﬂexibility, NPV*, can be
computed. It will be higher than the NPV. If NPV* is greater than 0, this is
an argument for investing in the R&D project. We will discuss the valuation
method in section 18.4.
18.4
OPTION TO EXPAND
Let us consider again the example in the previous section. Suppose that after
the company invests in R&D for four years, management has the option to
proceed with the next stage (product launch) at a cost of $10 million, or not
proceed. How much is this option worth?
In order to estimate the value of this option, we need to make some
assumptions on how the estimated value of future revenues from the product
will change between today and year 5. Suppose that the company estimates,
based on experience with similar products in the past, that there is a 10%
chance that the R&D project will result in a viable product, and bring in a
revenue of $210 million (in year 5 dollars), but that there is a 90% chance
that the R&D project will be a failure, and will not bring in any revenue.
It is not difﬁcult to see that the expected value of the future revenue is
(10%) · ($210) + (90%) · ($0) = $21 million, as in the example in the
previous section.

Real Options
715
However, note that if the R&D part of the project is a failure, the
company does not have to spend $10 million to launch the product. In this
case, the company would realize nothing in future revenues.
We can think of the $10 million as the strike price of a European
call option, and the future revenue estimate in year 5 as the price of the
underlying. Management will only exercise the option if the price of the
underlying is higher than the strike price. There are only two possible states
of the world in the future, and the discounted payoff of the option is
e−0.05·5 · (0.10 · max{$210 −$10, $0} + 0.90 · max{$0 −$10, $0})
= $15.58 million.7
The value of the option is very high because there the volatility of the
future cash ﬂows is high.8
The present value of the remaining cash ﬂows for the project (the costs
incurred in years 1–4) equals
$1.2 · e−0.05·4 + $1.2 · e−0.05·4 + $1.2 · e−0.05·4 + $1.2 · e−0.05·4 = $4.24
Therefore, the NPV taking into consideration optionality, NPV*, equals
$15.58 −$4.24 = $11.34 million
Since NPV* is positive, the project should be considered for funding.
The example we gave was very simple—we assumed that the project
value in the future can be either $210 million or zero with certain proba-
bilities. We could assume a more complex process for the random variable
that is the value of the project between time 0 and time 5. For exam-
ple, we can assume that it follows a geometric random walk. If this is the
case, we can value the real option by using the Black-Scholes formula for
European call options. Suppose the volatility of the process is 35%. (We
will talk more about estimating volatility in section 18.7.2.) The strike price
is $10 million. What about the initial price? For the initial price, we use the
present value of the project discounted at the cost of capital (14%), that
is, $10.43. The risk-free rate is assumed to be 5%, as before. According
to the Black-Scholes formula, the value of the real option is $4.27 million.
(See Exhibit 18.2 and worksheet Expansion B-S Price in the ﬁle Ch18-
ExpansionAbandonOptions.xlsx.) Based on this estimate, it is worthwhile
to invest in the R&D project, but only barely—NPV* equals $4.27 – $4.24
(the present value of the costs in years 1–4) = $0.03 million.

716
CAPITAL BUDGETING DECISIONS
EXHIBIT 18.2
Valuation of the option to
expand using the Black-Scholes formula for
European call options.
It is very important to conduct sensitivity analysis and determine how
inﬂuenced the option price is by our assumption about the volatility of
the project. Exhibit 18.3 contains a data table with the price of the real
option for different values for the volatility. We can see that the option
price estimates for NPV* around the current value for volatility (35%) are
very unstable—they go from positive to negative with a small change in the
volatility parameter. Therefore, the fact that NPV* is positive is not by itself
a reason to undertake the project.
Finally, recall from Chapter 13 that we can use simulation to price
the call option. The advantage of using simulation is that we can assume
different processes for the price of the underlying (in this case, the value of
the project). If we assume that the underlying follows a geometric random
walk with volatility 35%, we should obtain the same estimate for the price
of the option (or very close) as the estimate we obtained with the Black-
Scholes formula. To implement the simulation, we treat the present value
of the project, $10.43 million (obtained as $21 million discounted at a rate
equal to the cost of capital, i.e., 14%) as the initial price of the underlying.
We then simulate the price of the underlying ﬁve years from now using

Real Options
717
EXHIBIT 18.3
Sensitivity of the value of the
expansion option to the volatility estimate.
Volatility
Option Price ($m)
NPV* ($m)
10%
$2.73
−$1.51
15%
$2.96
−$1.28
20%
$3.26
−$0.98
25%
$3.58
−$0.66
30%
$3.93
−$0.31
35%
$4.27
$0.03
40%
$4.62
$0.38
45%
$4.96
$0.72
50%
$5.30
$1.06
55%
$5.63
$1.39
60%
$5.94
$1.70
65%
$6.25
$2.01
70%
$6.55
$2.31
75%
$6.83
$2.59
80%
$7.11
$2.87
the formula for the geometric random walk. We computed the drift of the
geometric random walk as the risk-free rate of 5% minus one half of the
volatility squared, but the value of the drift may need to be adjusted. (See
section 18.7.) In some situations, it may be more appropriate to assume a
mean-reverting process or a speciﬁc probability distribution for the value of
the project in ﬁve years.
18.5
OPTION TO ABANDON
Let us consider a slightly different example of a development project in or-
der to illustrate how a real option to abandon the current course of action
translates into owning a put option, and increases the value of a project.
Consider a pharmaceutical company (Company A) that owns a patent and
is trying to develop a drug based on that patent. The patent has 10 years
remaining, and so the life of the project is 10 years. Company A is spending
$50 million in year 0 to build a new research facility for the drug devel-
opment project, and $2.5 per year in years 1 and 2. The development is
expected to end at the end of year 2, and the drug is expected to generate
$8 million per year from year 3 onwards. At the end of year 2, Company
A has the option to reevaluate its investment. It has entered into a contract

718
CAPITAL BUDGETING DECISIONS
EXHIBIT 18.4
Classical NPV of drug development project (worksheet Abandon
in the ﬁle Ch18-ExpansionAbandonOptions.xlsx).
with another pharmaceutical company (Company B) that lets Company A
sell its intellectual property and research facility to Company B in year 3
for a salvage value of $70 million if the development process is not going as
well as planned. What is this option worth?
Exhibit 18.4 illustrates the different cash ﬂows and the NPV of the
project without considering optionality. Both costs and revenues are dis-
counted at the cost of capital, 10%. The NPV of the project is −$20.01
million.
At the end of year 2, Company A can sell the project for a salvage value
of $70 million. The present value of all revenues in year 3 and onward is the
sum of the values in cells E11:L11, which is $34.29 million. Thus, Company
A owns a put option to sell an asset with initial value of $34.29 million for
$70 million two years from now. We can use the Black-Scholes put option
pricing formula to value this option (see Exhibit 18.5). The value obtained
from the formula is $30.21 million.
Therefore, it is worthwhile to invest in the drug development project.
We can obtain a similar estimate by simulating the value of the future cash
ﬂows at the end of year 2 (assuming that the total value follows a geometric
random walk).
18.6
MORE REAL OPTIONS EXAMPLES
The real option examples we considered in sections 18.4 and 18.5 were very
basic. Most real life projects are more complicated, and the Black-Scholes
formula is not as useful. In this section, to give a ﬂavor of the variety of
real option models, we discuss an example of a timing option that takes

Real Options
719
EXHIBIT 18.5
Valuation of the option
to abandon the development project
with the Black-Scholes put option
pricing formula (worksheet Abandon
B-S Price in the ﬁle Ch18-
ExpansionAbandonOptions.xlsx).
advantage of simulation to value a project, as well as examples of projects
that are of a multiperiod nature. Binomial trees9 can be applied in the latter
context because they allow for greater ﬂexibility in modeling the continuous
nature of adjustments in investment decisions. Dynamic programming is
then used to determine the optimal strategy given some assumptions about
the way the underlying process behaves.
18.6.1
Project to Abandon or Expand
Let us consider a variation on the project described in section 18.4. Sup-
pose that, as before, the company’s management has the option to invest
$10 million in the project in year 5, or not invest. However, suppose also
that management has the additional ﬂexibility of abandoning the project in
any of years 1 through 4 if it is not satisﬁed with the direction of the project.

720
CAPITAL BUDGETING DECISIONS
We therefore have two implicit options to value: (1) a European call option
with a maturity of ﬁve years, as before and (2) an American put option with
a maturity of four years. To value them together, we create a binomial tree
for the process followed by the estimated value of the revenues starting in
year 5.
As explained in section 18.4, the present value of the estimated cash
ﬂows of the project (discounted at the cost of capital, 14%) is $10.43 million.
We assume that the volatility of the project (σ) is 35% and the risk-free rate
(r) is 5%, and construct a recombining binomial tree in which the value of
the project each year is expected to go up or down by certain multipliers
(u and d) with certain probabilities (p and 1 – p). These parameters can be
found from our assumptions about the volatility of the process and the time
increment.10 We have:
r = 0.05.
t = 1 year.
σ = 0.35.
Discount factor for each time period df = e−r·t = 0.9512.
u = eσ·
√
t = e0.35·
√
1 = 1.42.
d = e−σ·
√
t = e−0.35·
√
1 = 0.70.
p = er·(t) −d
u −d
= 48.52%.
The binomial tree with the values of the project for years 1 through 5 is
shown in Exhibit 18.6.
EXHIBIT 18.6
Binomial tree for the process followed by the value of future
revenues (worksheet Expansion and Abandon in the ﬁle
Ch18-ExpansionAbandonOptions.xlsx).

Real Options
721
EXHIBIT 18.7
Valuation of the real option to expand in year 5 or abandon in
years 1–4 (worksheet Expansion and Abandon in the ﬁle
Ch18-ExpansionAbandonOptions.xlsx).
The value of the project with the option to abandon at any time be-
tween 1 and 4 or expand at time 5 can be computed by using dynamic
programming. The results are presented in Exhibit 18.7.
We start at the last time period, year 5. The value at each node can be
computed as the maximum of the difference between the project value at
that node (Exhibit 18.6) and the “strike price” of $10 million to expand. For
example, in cell G29, we compute the maximum of ($60.01 – $10) million
and 0, which is $50.01 million. In cell G32, we compute the maximum of
($7.35 – $10) million and 0, which is 0.
At the previous step (year 4), we have the option to abandon the project
if the expected value of continuing is less than the value of abandoning,
which carries a value of 0. The expected value of continuing is the cost of
$1.2 million plus the discounted value of the expected payoffs in the next
time period. For example, in cell F30, we compute
max

0, −$1.2 + 0.9512 · (0.4852 · $50.01 + (1 −0.4852) · $19.80

which equals $31.58 million. At this node, it is optimal to continue. We
proceed backwards through the tree until we reach time 0. At that time, the
value of the node is simply
0.9512 · (0.4852 · $3.41 + (1 −0.4852) · $0 = $1.57 million
If we did not have the option to abandon the project during years 1
through 4, the value of the project would have been $0.13 million (see

722
CAPITAL BUDGETING DECISIONS
EXHIBIT 18.8
Valuation of the real option to expand without the option to
abandon (worksheet Expansion and Abandon in the ﬁle
Ch18-ExpansionAbandonOptions.xlsx).
Exhibit 18.8 and worksheet Expansion and Abandon in the ﬁle Ch18-
ExpansionAbandonOptions.xlsx). This is because instead of computing the
maximum value of continuing or abandoning at each node, we would have
been forced to continue. Having the option to abandon increases the value
of the project.
18.6.2
Valuing an Option to Wait
There is a wide variety of situations in which real option models apply,
and oftentimes there is a lot of ﬂexibility as to how management can model
its choices. In this section, we present a simulation model for estimating
the value of the choice to wait or execute today. See Moore (2008) for a
more general principle for valuing timing options over multiple periods that
involves the proﬁtability index.11
We use a classical example introduced in Titman (1985).12 Suppose we
are considering buying a parcel of land that has been zoned for multifamily
housing. The size of the lot is such that we can use it either for a two-story
building, or for a three-story building. Each building can have three units
per ﬂoor. A two-story building will therefore have six apartments, whereas
a three-story building will have nine apartments. Taller buildings are more
expensive because of additional foundation and elevator costs. It will cost
$80,000 to build a unit in a six-unit building, and $90,000 to build a unit
in a nine-unit building. The current market value of each unit is $100,000.
We also have the option to time the development. We can either build
the building this year (as soon as we buy the land), or wait until next year.
The question is, how much should we be willing to pay for the land, and
what is the optimal policy?

Real Options
723
If we build this year, the optimal strategy is easy to calculate. The six-
unit building will bring in proﬁt of
6 · ($100,000 −$80,000) = $120,000
The nine-unit building will bring in proﬁt of
9 · ($100,000 −$90,000) = $90,000
Therefore, we should build the six-unit building, and we should be willing
to pay up to $120,000 for the land.
If we wait until next year, the market price of a unit is likely to change.
For simplicity, however, we assume that the building costs will stay the same.
In order to estimate whether it makes sense to wait, we need to make as-
sumptions on the process followed by the market price of the unit. Suppose
that apartment prices follow a geometric random walk. Next year, they are
expected to be 5% higher on average, but the volatility in real estate prices
has been about 35%. Suppose also that the risk-free rate is 3% per year.
To value the option to build and sell the units, we assume that the
market price of the unit grows at the risk-free rate. We can compute the
market price of a unit next year with the formula
S1 = ($100,000) · e(0.03−1
2 ·0.352+0.35·˜ε)
where ˜ε is a standard normal random variable. We will build as many units
as are optimal in a year, that is, the number of units that results in the
maximum proﬁt given the market price of a unit in a year. In fact, if the
market price of a unit is such that we would realize a loss by building any
number of units, we can choose to not build for a proﬁt of 0.
We also need to discount the proﬁt in year 1 in order to value the real
option and to make sure that we have a fair comparison with the proﬁt in
year 1. We have the following expression for the discounted proﬁt if we wait
a year:
e−0.03·1 · max

6 · (S1 −80,000), 9 · (S1 −90,000), 0

After simulating 10,000 paths for the market price of a unit in a year,
we obtain the output in Exhibit 18.9.13 Therefore, the value of waiting to
develop for a year is approximately $193,094.49. This number is higher than
the proﬁt that would be obtained by developing immediately ($120,000),
and is in fact the estimate we should use to determine how much we should

724
CAPITAL BUDGETING DECISIONS
EXHIBIT 18.9
Simulation output for the discounted proﬁt from waiting to
develop the land for a year.
be willing to pay for the land. Having the ﬂexibility to wait increases the
value of the project.
18.6.3
Valuing a Multiperiod Real Estate Project
Many projects require modeling the price of a commodity or the level of an
index. Such variables determine the cash ﬂows of the project, and change
with market conditions. Examples include multistage oil ﬁeld development
(Smit 1997), in which the proﬁtability of operations is determined by the
market price of oil, and gold mine exploitation,14 which depends on the
price of gold (Luenberger 1998 and Winston 2000). Let us consider a real
estate example related to the example in section 18.6.2, but over multiple
years. The underlying variable is an index of property values. A real estate
developer is considering investing in land that can be used for condominium
development. The life of the project is 10 years. Every year, the developer
can build and sell up to three condominiums. The cost of a single condo-
minium is $250,000, and the current selling price for a single condominium
is $350,000. How much should the developer be willing to pay for the land?
Note that the developer has the option not to build condominiums in any
particular year in which the cost of building them is greater than the market
value at which they can be sold.
We have the following additional information. The value of the real
estate index in year 0 is 1893, and past data indicate an annual drift of
10.30% and a volatility of 5.90%. Building costs have been increasing at
a relatively constant rate of 5.53% per year. We assume that the market
price for the condominiums is perfectly correlated with the price of the real
estate index.

Real Options
725
EXHIBIT 18.10
Binomial tree for the process followed by the real estate index.
Based on this information, we can create a binomial tree for the process
followed by the index level over the next 10 years:
r = 0.03.
t = 1 year.
σ = 0.059.
Discount factor for each time period df = e−r·t = 0.9704.
u = eσ·
√
t = e0.059·
√
1 = 1.06.
d = e−σ·
√
t = e−0.059·
√
1 = 0.94.
p = er·(t) −d
u −d
= 74.32%.
The tree for the index levels is shown in Exhibit 18.10. The correspond-
ing tree for the revenues from selling three condos per year, as well as the
costs of building three condos per year, are shown in Exhibit 18.11.15
EXHIBIT 18.11
Binomial tree for the revenues and costs associated with building
and selling three condos per year.

726
CAPITAL BUDGETING DECISIONS
We are now ready to compute the value of the option to develop the
land (see Exhibit 18.12). At every node, except at time 0, the developer will
build three condos only if the price of building them exceeds the cost of
building them in that particular year (based on the data in Exhibit 18.11).
For example, at the ﬁrst node in year 10 (cell L42), the value of the project
is the maximum of the revenues minus the costs, or 0:
max

$2029.49 −$1303.85, 0

= $725.64
For the second node in year 10 (cell L43), we have
max

$1803.60 −$1303.85, 0

= $499.75
Going backwards through the tree, at each node we record the reward
from being at that node,16 which is the maximum of the proﬁt the developer
can achieve at that node and 0, as well as the discounted expected value of
the proﬁt from that node on. For example, at the ﬁrst node in year 9 (cell
K42), we have
max {$1, 913.21 −$1, 233.70, 0} + 0.9704 · (0.7432 · $725.64
+ (1 −0.7432) · 499.75) = $1, 327.41
The value of the land with the ﬂexibility to develop or not develop in
any particular year (cell B42) is $2,652.83 thousand (i.e., $2,652,830). The
developer should be willing to pay up to this amount for the land.
It is useful to do some sensitivity analysis to ﬁgure out if this estimate is
very sensitive to assumptions we have made about different input parame-
ters. For example, a data table can be created that references the estimated
value of the project, and computes it based on different estimates of the
EXHIBIT 18.12
Value of the project with ﬂexibility to develop or not develop
each year.

Real Options
727
EXHIBIT 18.13
Variability in project value as the cost estimate varies.
volatility in the process for the property value index level. Finally, addi-
tional simulation and scenario analysis can be done. For example, so far, we
assumed that costs every year are growing at a constant rate. It is possible,
however, that there is some variability in our estimate. We can use simula-
tion to determine the effect of the variability in costs on the variability in
the estimated value of the project. For example, suppose that our estimate
of the costs in each year has a standard deviation of 3.40% of the current
value. (This is consistent with historical observed volatility in the building
cost index.) What is the resulting variability in the estimated project value?
Exhibit 18.13 shows the distribution of possible project values for 1,000
generated scenarios for the costs over 10 years.17 We can see that 90% of
the time, the project value can be expected to be between $2,516,000 and
$2,792,000.
18.7
ESTIMATION OF INPUTS FOR
REAL OPTION VALUATION MODELS
An overview of real option valuation is not complete without a discussion
of how important parameters, such as the discount rate and the volatility,
are estimated.

728
CAPITAL BUDGETING DECISIONS
18.7.1
Discount Rate
As explained in Chapter 17, the discount rate commonly used for computing
the classical NPV is the WACC. (As we mentioned earlier in this chapter,
however, different cash ﬂows in a project can be discounted using different
discount rates, depending on their perceived risk.) Determining a good es-
timate of the WACC for calculating “pure” NPV with no optionality can
itself be problematic because it is based on evaluating the risk of similar
projects, and many of these projects have their own options.
Finding the appropriate discount rate for the purposes of real option
valuation has its own issues. As we mentioned in section 18.2, ﬁnancial
options are priced by discounting the cash ﬂows from the options at the
risk-free rate. This is not quite the appropriate rate to use in pricing real
options, however, because the concept of no-arbitrage and the idea of a
risk-neutral world do not exactly apply in this context. If we use the risk-
free rate to discount the cash ﬂows relevant for the valuation for the real
option, we may end up with an overly optimistic estimate of the real option
value. Several adjustments are made in practice:
1. An artiﬁcially inﬂated discount rate is applied to cash ﬂows impacting
the real option value, so that the real option value is reduced. This
method can be very subjective, and difﬁcult to apply. A theoretically
justiﬁed approach for inﬂating the discount rate is discussed next, but it
can only be applied in circumstances in which we have historical data
on the process followed by the underlying asset for the real option and
a strongly correlated traded asset.
2. It can be shown18 that under certain assumptions, the appropriate risk-
adjusted rate to use so that options are priced correctly even if we cannot
talk about a risk-neutral world is
µ −λ · σ
where µ and σ are the drift and the volatility of the process followed by
the underlying, respectively, and is λ the market price of risk. In other
words, if we assume that the rate of growth of the underlying asset is
µ – λ · σ (which equals the asset’s rate of growth µ adjusted downward
by λ · σ), and then discount the cash ﬂows at the risk-free rate, we can
price the real option correctly.
The market price of risk is related to the excess return of a traded
asset over the risk-free rate rrf; in other words,
µ −rr f = λ · σ

Real Options
729
If we have historical data on a traded asset and a nontraded variable
(e.g., company sales), we can do the following to estimate the market
price of risk for company sales:
A. Estimate the coefﬁcient of correlation ρ between the returns on the
traded asset and the percentage changes in the nontraded variable.
B. Estimate the volatility of returns of the market, σ M. (This is usually
done by estimating the volatility of a broad stock market index.)
C. Estimate the expected return on the market, rM.
D. Find the short-term risk-free rate, rrf.
E. Compute the market price of risk of the nontraded variable as
λ = ρ
σM
· (rM −rr f )
3. Sometimes, to adjust the value of the real option downward, the price of
the real option is reduced by the price of a put option.19 The idea is that
since the underlying asset in the real option is not tradable, it cannot
be sold to realize its assumed value for the purposes of valuation. This
inﬂexibility decreases the value of the real option. The maturity of the
put option is typically assumed to be lower than the maturity of the real
option in order to reﬂect the time period over which tradability is an
important factor, and the strike price is set at the asset value to reﬂect
the ability to sell the asset at its estimated price at a moment’s notice.
Often in practice, however, none of these approaches are taken. A simple
adjustment is to use the WACC reduced by the risk-free rate as a discount
rate for the purposes of valuing the real options in the project. The exact
valuation is not of as big importance when comparing multiple projects, as
long as we use the same methodology to value each project. In this chapter,
for simplicity, we used the risk-free rate for discounting. However, it is
important to understand the underlying problems with this assumption.
18.7.2
Volatility
The volatility σ we have been using in real option valuation is the annual-
ized standard deviation of the continuously compounded rate of the return
on the underlying asset. As we discussed in section 13.6.2 of Chapter 13,
the volatility in ﬁnancial options can be estimated from observed market
prices of ﬁnancial derivatives. But where do we get such an estimate for the
volatility of company projects? One possibility is to use data on the volatility
of the company’s stock prices (where the volatility is estimated either from
historical returns, or from market prices of options on the company’s stock),

730
CAPITAL BUDGETING DECISIONS
but this volatility is “levered” volatility, that is, it incorporates information
about the company’s debt-to-equity ratio D/E. Before using it for project
valuation purposes, we need to “delever” it. If σ L is the implied volatility
estimated from the company’s stock price, we can estimate the “unlevered”
volatility σ U from the following relationship:
σL = (1 + D/E) · σU
What about an estimate for the volatility of a company that is not
publicly traded? We can attempt to estimate it by estimating the volatility
for similar companies that are publicly traded, but needless to say, this
method introduces a lot of subjectivity and inaccuracy into the process.
What about the volatility of nontraded variables that determine the
value of projects, such as company sales or the value of a research facility?
There is not a good solution. The best approach in general is to use sensitivity
analysis to evaluate whether the recommended course of action is sensitive to
the current estimate of the volatility. As Moore (2008) said, “. . . real options
analysis is hardly an arena for an obsession with precision. Precision can be
pushed only so far.”
SUMMARY
■Evaluation of capital investment decisions is a dynamic process. Com-
panies typically have the option to change their initial course of action.
Options in context of capital investment decisions are referred to as real
options (as opposed to ﬁnancial options).
■Real options enhance investment value because the company has the
right, but not the obligation, to take actions in the future. The company
can do that because in the future, it will have access to information not
available at the time of the original decision.
■Most generally, real options fall into the following categories: option to
expand, option to abandon, option to delay, option to choose, option
to switch, option for sequential investments.
■There are many similarities between real options and ﬁnancial options.
However, it is also important to keep in mind that models for pricing
ﬁnancial options cannot be automatically translated into models for real
option valuation because the assumptions made for pricing ﬁnancial
options do not hold for real options.
■A typical option to expand looks very much like a long position in a
classical ﬁnancial call option. The company has the right, but not the

Real Options
731
obligation, to buy an asset in the future if the future estimate of the
value of that asset is more than the cost of acquiring it at that time.
■A typical option to abandon looks very much like a long position in a
classical ﬁnancial put option. The company has the right, but not the
obligation, to abandon a project (get rid of an asset) if the estimated
beneﬁt of continuing the project in the future is less than the estimated
cost of continuing with the project.
■Given the similarity between real options and ﬁnancial options, the
Black-Scholes formula and binomial trees are often applied for real
option valuation.
■The inputs to real option valuation models, such as volatility and the
correct discount rate to use, are difﬁcult to estimate. Sensitivity analysis
and simulation are even more important in the real options valuation
context.
SOFTWARE HINTS
The tools for valuing real options are similar to the tools for valuing ﬁnancial
options, so we omit speciﬁc details about the implementation of the models
in this section. For instructions on building binomial trees and evaluating the
Black-Scholes formula with Excel and MATLAB, see Chapter 13’s Software
Hints.
NOTES
1. See section 13.4.2 of Chapter 13.
2. See Chapter 13 and Exhibit 13.1(C).
3. See Chapter 13 and Exhibit 13.1(E).
4. See Chapter 13.
5. See, for example, Dixit and Pindyck (1994).
6. This is a commonly used method in practice. More risky cash ﬂows are dis-
counted at a higher discount rate.
7. Here we used the risk-free rate to discount the cash ﬂows from the option. The
issue of what discount rate to use is complex, and we will come back to it in
section 18.7.1.
8. Recall from Chapter 13 that the price of a call option increases with the volatility
of the process followed by the underlying asset.
9. See section 13.4.1 of Chapter 13.
10. See section 13.4.2 of Chapter 13.
11. See section 17.2.3 of Chapter 17 for a deﬁnition of the proﬁtability index.
12. See also Shockley (2007) and Winston (2000).

732
CAPITAL BUDGETING DECISIONS
13. See ﬁle Ch18-OptionToWait.xlsx.
14. See also Practice 18.1 on the companion web site.
15. See section 13.4.1 of Chapter 13 for explanation of how to build binomial trees,
and ﬁle Ch18-RealEstateOption.xlsx for an implementation of this particular
binomial tree.
16. See section 6.1 of Chapter 6.
17. Note that this calculation involves recomputing the binomial tree to determine
the value of the option for each scenario for the costs (i.e., in this case, computing
1000 binomial trees).
18. See Hull (2008).
19. See Mun (2006).

References
Abken, P. 2000. An empirical evaluation of value at risk by scenario simulation.
Journal of Derivatives 7 (4): 12–29.
Adcock, C., and N. Meade. 1994. A simple algorithm to incorporate transaction
costs in quadratic optimization. European Journal of Operational Research
79 (1): 85–94.
Akesson, F., and J. P. Lehoczky. 2000. Path generation for quasi-monte carlo simu-
lation of mortgage-backed securities. Management Science 46 (9): 1171–1187.
Anderson, F., H. Mausser, D. Rosen, and S. Uryasev. 2001. Credit risk optimiza-
tion with conditional value-at-risk criteria. Mathematical Programming B 89:
273–291.
Apelfeld, R., G. B. Fowler, and J. P. Gordon. 1996. Tax-aware equity investing.
Journal of Portfolio Management 22 (2): 18–28.
Artzner, P., F. Delbaen, J.-M. Eber, and D. Heath. 1999. Coherent measures of risk.
Mathematical Finance 9 (November): 203–228.
Barra. 1998. Risk model handbook united states equity: Version 3. Berkeley, CA:
Barra.
Bazaraa, M., H. Sharali, and C. Shetty. 1993. Nonlinear programming: Theory and
algorithms. New York: John Wiley & Sons.
Beasley, J. D., and S. G. Springer. 1977. The percentage points of the normal distri-
bution. Applied Statistics 26: 118–121.
Bellman, R. 1957. Dynamic programming. Princeton, NJ: Princeton University Press.
Ben-Tal, A., T. Margalit, and A. Nemirovski. 2000. Robust modeling of multi-stage
portfolio problems. In High-Performance Optimization, edited by H. Frenk,
K. Roos, T. Terlaky, and S. Zhang, pp. 303–328. Dordrecht: Kluwer.
Bertsekas, D. 1995. Dynamic programming and optimal control, vols. 1 and 2.
Belmont, MA: Athena Scientiﬁc.
Bertsimas, D., C. Darnell, and R. Soucy. 1999. Portfolio construction through mixed-
integer programming at Grantham, Mayo, Van Otterloo and Company. Inter-
faces 29 (1): 49–66.
Bertsimas, D., and D. Pachamanova. 2008. Robust multiperiod portfolio manage-
ment with transaction costs. Computers and Operations Research, special issue
of Applications of Operations Research in Finance 35 (1): 3–17.
Bertsimas, D., and J. Tsitsiklis. 1997. Introduction to linear optimization. Belmont,
MA: Athena Scientiﬁc.
Birge, J. 1985. Decomposition and partitioning methods for multistage stochastic
linear programs. Operations Research 33: 989–1007.
733

734
REFERENCES
Black, F. 1972. Capital market equilibrium with restricted borrowings. Journal of
Business 45 (3): 444–455.
Black, F., and R. Litterman. 1992. Global portfolio optimization. Financial Analysts
Journal 48 (5): 28–43.
Black, F., and M. Scholes. 1973. The pricing of options and corporate liabilities.
Journal of Political Economy 81 (3): 637–654.
Bogentoft, E., H. E. Romeijn, and S. Uryasev. 2001. Asset/liability management for
pension funds using CVaR constraints. Journal of Risk Finance (Fall): 57–71.
Box, G. E. P., and M. E. Muller. 1958. A note on the generation of random normal
deviates. Annals of Mathematical Statistics 29: 610–611.
Boyle, P. 1977. Options: A Monte Carlo approach. Journal of Financial Economics
4 (3): 323–338.
Boyle, P., M. Broadie, and P. Glasserman. 1997. Monte Carlo methods for security
pricing. Journal of Economic Dynamics & Control 21: 1267–1321.
Brandimarte, P. 2006. Numerical methods in ﬁnance and economics. 2nd ed. Hobo-
ken, NJ: John Wiley & Sons.
Brennan, M. J., and E. S. Schwartz. 1979. A continuous time approach to pricing
bonds. Journal of Banking and Finance 3 (July): 133–155.
Campbell, J. Y., M. L. Lettau, B. G. Malkiel, and Y. Xu. 2001. Have individual
stocks become more volatile? An empirical exploration of idiosyncratic risk.
Journal of Finance 56 (1): 1–43.
Canuel, D., and C. Melchreit. 1998. Total return Analysis in CMO portfolio man-
agement. In Advances in the valuation and management of mortgage-backed
securities, edited by F. Fabozzi, pp. 41–58. Hoboken, NJ: John Wiley & Sons.
Carino, D., and W. Ziemba. 1998. Formulation of the Russell-Yasuda Kasai ﬁnancial
planning model. Operations Research 46 (4): 433–449.
Ceria, S., and R. Stubbs. 2006. Incorporating estimation errors into portfolio se-
lection: Robust portfolio construction. Journal of Asset Management 7 (2):
109–127.
Chen, N., R. Roll, and S. A. Ross. 1986. Economic forces and the stock market.
Journal of Business 59 (July): 383–403.
Chen, X., M. Sim, and P. Sun. 2007. A robust optimization perspective on stochastic
programming. Operations Research 55 (6): 1058–1107.
Chewlow, L., and C. Strickland. 1998. Implementing derivatives models. Chichester:
John Wiley & Sons.
Chryssikou, E. 1998. Multiperiod portfolio optimization in the presence of transac-
tion costs. Ph.D. thesis, MIT.
Consigli, G., and M. A. H. Dempster. 1998. Dynamic stochastic programming for
asset-liability management. Annals of Operations Research 81: 131–161.
Constantinides, G. 1983. Capital market equilibrium with personal taxes. Econo-
metrica 51: 611–636.
Copeland, T., and P. Tufano. 2004. A real world way to manage real options.
Harvard Business Review 82 (3): 90–99.
Cox, J. C., J. E. Ingersoll, and S. A. Ross. 1985. A theory of the term structure of
interest rates. Econometrica 53: 385–407.

References
735
Cox, J. C., S. A. Ross, and M. Rubinstein. 1979. Option pricing: A simpliﬁed
approach. Journal of Financial Economics 7 (3): 229–263.
Cremers, J. H., M. Kritzman, and S. Page. 2003. Portfolio formation with higher
moments and plausible utility. Revere Street Working Papers, November 22.
———. 2005. Optimal hedge fund allocations: Do higher moments matter? Journal
of Portfolio Management 31 (3): 70–81.
Dammon, R. M., and C. S. Spatt. 1996. The optimal trading and pricing of securities
with asymmetric capital gains taxes and transaction costs. Review of Financial
Studies 9 (3): 921–952.
Dammon, R. M., C. S. Spatt, and H. H. Zhang. 2001. Optimal consumption and
investment with capital gains taxes. Review of Financial Studies 14 (3): 583–617.
———. 2004. Optimal asset location and allocation with taxable and tax-deferred
investing. Journal of Finance 59 (3): 999–1037.
Danielsson, J., and J.-P. Zigrand. 2001. What happens when you regulate risk?
Evidence from a simple general equilibrium model. Memo, London School of
Economics.
DiBartolomeo, D. 2000. Recent advances in management of taxable portfolios. Pa-
per, Northﬁeld Information Services.
Disatnik, D. and S. Benninga. 2007. Shrinking the covariance matrix—simpler is
better. Journal of Portfolio Management 33 (4): 56–63.
Dixit, A. K., and R. S. Pindyck. 1994. Investment under uncertainty. Princeton, NJ:
Princeton University Press.
Dufﬁe, D., and N. Garleanu. 2001. Risk and valuation of collateralized debt obliga-
tions. Financial Analysts Journal 57 (1): 41–59.
Evans, J., and D. Olson. 2002. Introduction to simulation and risk analysis, 2nd ed.
Upper Saddle River, NJ: Prentice Hall.
Evans, J. L., and S. H. Archer. 1968. Diversiﬁcation and the reduction of dispersion:
An empirical analysis. Journal of Finance 23 (5): 761–767.
Evans, M., N. Hastings, and B. Peacock. 2000. Statistical distributions, 3rd ed. New
York: John Wiley & Sons.
Fabozzi, F. J. 1993. Fixed income mathematics, New York: McGraw-Hill.
———. (ed.). 2005. The handbook of mortgage-backed securities, 6th ed. New York:
McGraw-Hill.
———. 2007. Fixed income analysis, 2nd ed. Hoboken, NJ: John Wiley & Sons.
———. 2009. Institutional investment management. Hoboken, NJ: John Wiley &
Sons.
Fabozzi, F. J., A. K. Bhattacharya, and W. S. Berliner. 2007. Mortgage-backed
securities: Products, structuring, and analytical techniques. Hoboken, NJ: John
Wiley & Sons.
Fabozzi, F. J., S. Focardi, and P. Kolm. 2006. Financial modeling of the equity
market. Hoboken, NJ: John Wiley & Sons.
Fabozzi, F. J., P. Kolm, D. Pachamanova, and S. Focardi. 2007. Robust portfolio
optimization and management. Hoboken, NJ: John Wiley & Sons.
Fama, E. F. 1965. Portfolio analysis in a stable Paretian market. Management Science
11 (3): 404–419.

736
REFERENCES
———. 1970. Efﬁcient capital markets: A review of theory and empirical work.
Journal of Finance 25 (2): 383–417.
Fama, E. F., and K. French. 1993. Common risk factors in the returns on stocks and
bonds. Journal of Financial Economics 33: 3–56.
———. 1995. Size and book-to-market factors in earnings and returns. Journal of
Finance 50: 131–155.
———. 1996. Multifactor explanations of asset pricing anomalies. Journal of Fi-
nance 51: 55–84.
———. 1998. Value versus growth: The international evidence. Journal of Finance
53: 1975–1999.
Faure, H. 1982. Discr´epence de suites associ´ees ´a un syst´eme de num´eration (en
Simension s). Acta Arithmetica 41: 337–351.
Finnerty, J. D. 2008. Real options. Chapter 69 in Handbook of Finance, edited by
F. Fabozzi, pp. 2:697–2:714. Hoboken, NJ: John Wiley & Sons.
Fishburn, P. 1977. Mean-risk analysis with risk associated with below-target returns.
American Economic Review 67 (2): 116–126.
Fishman, G. 2006. A ﬁrst course in Monte Carlo. Stamford: CT: Thomson Learning.
Fong, H. G., and O. A. Vasicek. 1984. A risk minimizing strategy for portfolio
immunization. Journal of Finance 30: 1541–1546.
Fragniere, E., and J. Gondzio. 2005. Stochastic programming from modeling
languages. Chapter 7 in Applications of stochastic programming, edited by
S. Wallace and W. Ziemba, pp. 95–114. Philadelphia, PA: MPS-SIAM Series on
Optimization.
Freund, R. 2004. Lecture notes in nonlinear optimization. Unpublished manu-
script, MIT Open CourseWare, http://ocw.mit.edu/OcwWeb/Sloan-School-of-
Management/15–084JSpring2004/LectureNotes/index.htm.
Glasserman, P. 2004. Monte Carlo methods in ﬁnancial engineering. New York:
Springer.
Glasserman, P., P. Heidelberger, and P. Shahabuddin. 2000. Variance reduction
techniques for estimating value-at-risk. Management Science 46 (10): 1349–
1364.
Goldfarb, D., and G. Iyengar. 2003. Robust portfolio selection problems. Mathe-
matics of Operations Research 28 (1): 1–38.
Goldman Sachs Asset Management. 2007. Introduction to mortgage-backed securi-
ties and other securitized assets.
Gordon, M. 1962. The investment, ﬁnancing, and valuation of the corporation.
Homewood, IL: Irwin.
Graham, J., and C. R. Harvey. 2002. How do CFOs make capital budgeting and
capital structure decisions? Journal of Applied Corporate Finance 15 (1): 8–23.
Gulpinar, N., B. Rustem, and R. Settergren. 2004. Simulation and optimization
approaches to scenario tree generation. Journal of Economic Dynamics and
Control 28: 1291–1315.
Halton, J. 1960. On the efﬁciency of certain quasi-random sequences of points in
evaluating multi-dimensional integrals. Numerische Mathematik 2: 84–90.
Hammersley, J. 1960. Monte Carlo methods for solving multivariable problems.
Annals of the New York Academy of Sciences 86: 844–874.

References
737
Haug, E. 2007. The complete guide to option pricing formulas, 2nd ed. New York:
McGraw-Hill.
Haugh, M., and L. Kogan. 2004. Pricing American options: A duality approach.
Operations Research 52 (2): 258–270.
Hertz, D. B. 1964. Risk analysis in capital investment. Harvard Business Review
42 (1): 95–106.
Hillier, R. S., and J. Eckstein. 1993. Stochastic dedication: Designing ﬁxed income
portfolios using massively parallel Benders decomposition. Management Science
39 (11): 1422–1438.
Ho, Thomas S. Y. 1999. Key rate duration: A measure of interest rate risk exposure.
In Interest Rate risk measurement and management, edited by S. Nawalkha and
D. R. Chambers. New York, NY: Institutional Investors.
Hoppe, R. 1998. VaR and the unreal world. Risk (July): 45–50.
Huang, C., and R. Litzenberger. 1988. Foundations for ﬁnancial economics. Engle-
wood Cliffs, NJ: Prentice Hall.
Hull, J. 2008. Options, futures and other derivatives, 7th ed. Upper Saddle River,
NJ: Prentice Hall.
Ingersoll, J., Jr. 1987. Theory of ﬁnancial decision making. Savage, MD: Rowman
and Littleﬁeld.
Jamshidian, F., and Y. Zhu. 1997. Scenario simulation: Theory and methodology.
Finance and Stochastics 1: 43–67.
———. 2006. Scenario simulation model for ﬁxed income portfolio risk manage-
ment. In Advanced bond portfolio management, edited by F. J. Fabozzi, L.
Martellini, and P. Priaulet, pp. 291–310. Hoboken, NJ: John Wiley & Sons.
Jean, W. H. 1971. The extension of portfolio analysis to three or more parameters.
Journal of Financial and Quantitative Analysis 6 (1): 505–515.
Jones, R. C. 1998. The active versus passive debate: perspectives on an active quant.
Chapter 3 in Active Equity Portfolio Management, edited by F. J. Fabozzi. New
York: John Wiley & Sons.
Jorion, P. 1986. Bayes-Stein estimator for portfolio analysis. Journal of Financial
and Quantitative Analysis 21 (3): 279–292.
———. 1992. Portfolio optimization in practice. Financial Analysts Journal 48 (1):
68–74.
Kahneman, D., and A. Tversky. 1979. Prospect theory: An analysis of decision under
risk. Econometrica 47 (2): 263–290.
Kalotay, A., D. Yang, and F. J. Fabozzi. 2004. An option-theoretic prepayment
model for mortgages and mortgage-backed securities. International Journal of
Theoretical and Applied Finance 7 (December): 949–978.
Kalvelagen, E. 2003. Benders decomposition for stochastic programming with
GAMS.
Paper,
17
January.
http://www.amsterdamoptimization.com/pdf/
stochbenders.pdf.
Khodadadi, A., R. Tutuncu, and P. Zangari. 2006. Optimization and Quantitative
Investment Management. Journal of Asset Management 7 (2): 83–92.
Konno, H., and H. Yamazaki. 1991. Mean-absolute deviation portfolio optimization
model and its applications to the Tokyo stock market. Management Science
37 (5): 519–531.

738
REFERENCES
Ledoit, O., and M. Wolf. 2003. Improved estimation of the covariance matrix of
stock returns with an application to portfolio selection. Journal of Empirical
Finance 10 (5): 603–621.
Lee, J.-H., D. Stefek, and A. Zhelenyak. 2006. Robust portfolio optimization—A
closer look. Report, MSCI Barra Research Insights, June.
Levy, H. 1992. Stochastic dominance and expected utility: survey and analysis.
Management Science 38 (4): 555–593.
Levy, H., and Y. Kroll. 1978. Ordering uncertain options with borrowing and lend-
ing. Journal of Finance 33 (2): 553–574.
Levy, H., and H. M. Markowitz. 1979. Approximating expected utility by a function
of mean and variance. American Economic Review 69 (3): 308–317.
Lintner, J. 1965. The valuation of risk assets and the selection of risky investments
in stock portfolio and capital budgets. Review of Economics and Statistics
47 (1): 13–37.
Lobo, M. S., M. Fazel, and S. Boyd. 2007. Portfolio optimization with linear and
ﬁxed transaction costs. Annals of Operations Research 152 (1): 376–394.
Longstaff, F. A., and E. S. Schwartz. 1992. Interest rate volatility and the term
structure: A two-factor general equilibrium model. Journal of Finance 47 (4):
1259–1282.
———. 2001. Valuing American options by simulation: A simple least-squares ap-
proach. Review of Financial Studies 14: 113–147.
Maginn, J. L., and D. L. Tuttle (eds.). 1990. Managing investment portfolios: A
dynamic process, 2nd ed. New York: Warren, Gorham & Lamont.
Malkiel, B. G. 2002. How much diversiﬁcation is enough? Proceedings of the
AIMR seminar: The Future of the Equity Portfolio Construction (March):
26–27.
Mandelbrot, B. B. 1963. The variation of certain speculative prices. Journal of Busi-
ness 26: 394–419.
Markowitz, H. 1952. Portfolio selection. Journal of Finance 7: 77–91.
———. 1959. Portfolio selection: Efﬁcient diversiﬁcation of investments. New York:
John Wiley & Sons.
McLeish, D. 2005. Monte Carlo simulation and ﬁnance. Hoboken, NJ: John Wiley
& Sons.
Merton, R. C. 1976. Option pricing when underlying stock returns are discontinu-
ous. Journal of Finance 29: 449–470.
———. 1995. Continuous-time ﬁnance, rev. ed. Cambridge, MA: Blackwell.
Michaud, R. O. 1998. Efﬁcient asset management: A practical guide to stock port-
folio optimization and asset allocation. Oxford: Oxford University Press.
Mitchell, J. E., and S. Braun. 2004. Rebalancing an investment portfolio in the pres-
ence of convex transaction costs. Technical report, Department of Mathematical
Sciences, Rensselaer Polytechnic Institute.
Moore, W. T. 2008. Real options and modern capital investment decisions. Chap-
ter 70 in Handbook of ﬁnance, edited by F. Fabozzi, pp. 2:715–2:726. Hoboken,
NJ: John Wiley & Sons.
Moro, B. 1995. The Full Monte. Risk 8 (February): 57–58.

References
739
Mossin, J. 1966. Equilibrium in a Capital Asset Market. Econometrica 34 (4):
768–783.
Mulvey, J., R. Rush, J. Mitchell, and T. Willemain. 2000. Stratiﬁed ﬁltered sam-
pling in stochastic optimization. Journal of Applied Mathematics and Decision
Sciences 4 (1): 17–38.
Mulvey, J., R. Vanderbei, and S. Zenios. 1995. Robust optimization of large-scale
systems. Operations Research 43 (2): 264–281.
Natarajan, K., D. Pachamanova, and M. Sim. 2008. Incorporating asymmetric distri-
butional information in robust value-at-risk optimization. Management Science
54 (3): 573–585.
Nemhauser, G., and L. Wolsey. 1999. Integer and combinatorial optimization. New
York: John Wiley & Sons.
Nocera, J. 2009. Risk mismanagement. New York Times, January 4.
O’Cinneide, C., B. Scherer, and X. Xu. 2006. Pooling trades in a quantitative invest-
ment process. Journal of Portfolio Management 32 (4): 33–43.
O’Harrow, R., Jr., and J. Gerth. 2009. Geithner pressed but fell short. Washington
Post, April 3.
Overbye, D. 2009. They tried to outsmart Wall Street. New York Times,
March 10.
Peterson, P., and F. Fabozzi. 2002. Traditional fundamental analysis III: Earnings
analysis, cash analysis, dividends, and dividend discount models. Chapter 11 in
The theory and practice of investment management, edited by F. J. Fabozzi and
H. M. Markowitz. Hoboken, NJ: John Wiley & Sons.
Pogue, G. 1970. An extension of the Markowitz portfolio selection model to include
variable transactions costs, short sales, leverage policies, and taxes. Journal of
Finance 25 (5): 1005–1027.
Rachev, S. T., S. Mittnik, F. J. Fabozzi, S. M. Focardi, and T. Jai. 2006. Financial
econometrics: From basics to advanced modeling techniques. Hoboken, NJ:
John Wiley & Sons.
Rendleman, R., and B. Bartter. 1979. Two-state option pricing. Journal of Finance
34: 1093–1110.
Richard, S., and R. Roll. 1989. Prepayment and the valuation of mortgage-backed
securities. Journal of Portfolio Management 15: 73–82.
Rockafellar, R. T., and S. Uryasev. 2000. Optimization of conditional value-at-risk.
Journal of Risk 3: 21–41.
Rockafellar, R. T., and S. Uryasev. 2002. Conditional value-at-risk for general loss
distributions. Journal of Banking and Finance 26: 1443–1471.
Rogers, L. C. G. 2002. Monte Carlo valuation of American options. Mathematical
Finance 12: 271–286.
Roman, S. 2002. Writing Excel macros with VBA, 2nd ed. Sebastopol, CA: O’Reilly
Media, Inc.
Ross, S. A. 1976. The arbitrage theory of capital asset pricing. Journal of Economic
Theory 16 (December): 343–362.
Roy, A. 1952. Safety-ﬁrst and the holding of assets. Econometrica 20 (3): 431–
449.

740
REFERENCES
Ruszczynski, A., and A. Shapiro. 2003. Stochastic programming, handbook in op-
erations research and management science. Amsterdam: Elsevier Science.
Sanford, C., and D. Borge. 1993. The Risk Management Revolution. Paper, October.
http://www.libs.uga.edu/hargrett/manuscrip/sanford/charles.html.
Scherer, B. 2002. Portfolio resampling: Review and critique. Financial Analysts Jour-
nal 58 (6): 98–109.
Schreiner, J. 1980. Portfolio revision: A turnover-constrained approach. Financial
Management 9 (1): 67–75.
Schwartz, E., and W. Torous. 1989. Prepayment and the valuation of mortgage-
backed securities. Journal of Finance 44: 375–392.
Sharpe, W. F. 1963. A simpliﬁed model for portfolio analysis. Management Science
9 (January): 277–293.
———. 1964. Capital asset prices. Journal of Finance 19 (3): 425–442.
———. 1978. Investments. Englewood Cliffs, NJ: Prentice-Hall.
———. 1994. The Sharpe ratio. Journal of Portfolio Management 21 (1): 49–58.
Shokley, R. L., Jr. 2007. An applied course in real options valuation. Mason, OH:
Thomson South-Western.
Siegel, L. 2003. Benchmarks and investment management, Charlottesville, VA: Re-
search Foundation of AIMR.
Smit, H. T. J. 1997. Investment analysis of offshore concessions in the Netherlands.
Financial Management 26 (Summer): 5–17.
Sobol, I. 1967. The distribution of points in a cube and the approximate evalua-
tion of integrals. USSR Computational Mathematics and Mathematical Physics
7 (4): 86–112.
Spearman, C. 1904. General intelligence, objectively determined and measured.
American Journal of Psychology 15: 201–293.
Stein, D. M. 1998. Measuring and evaluating portfolio performance after taxes.
Journal of Portfolio Management 24 (2): 117–124.
Stubbs, R., and P. Vance. 2005. Computing return estimation error matrices for
robust optimization. Report, Axioma.
Taleb, N. 1997a. The World According to Nassim Taleb. Derivatives Strategy 2
(December–January): 37–40.
———. 1997b. Against VaR. Derivatives Strategy 2 (April): 21–26.
———. 2007. The black swan: The impact of the highly improbable. New York:
Random House.
Titman, S. 1985. Urban land prices under uncertainty. American Economic Review
75 (3): 505–513.
Tobin, J. 1958. Liquidity preference as a behavior towards risk. Review of Economic
Studies 67 (February): 65–86.
Tsitsiklis, J., and B. Van Roy. 1999. Optimal stopping of markov processes:
Hilbert space theory, approximation algorithms, and an application to pricing
high-dimensional ﬁnancial derivatives. IEEE Transactions on Automatic Con-
trol 44: 1840–1851.
———. 2001. Regression methods for pricing complex American-style options. IEEE
Transactions on Neural Networks 12: 694–703.

References
741
Vasicek, O. 1977. An equilibrium characterisation of the term structure. Journal of
Financial Economics 5: 177–188.
Volpert, V. E. 1997. Managing indexed and enhanced indexed bond portfolios. In
Managing ﬁxed income portfolios, edited by F. J. Fabozzi, pp. 191–211. New
York: John Wiley & Sons.
Walkenbach, J. 2004. Excel 2003 power programming with VBA. Hoboken, NJ:
John Wiley & Sons.
Wallace, S., and W. Ziemba. 2005. Applications of stochastic programming.
Philadelphia, PA: MPS-SIAM Series on Optimization.
Williams, J. 1938. The theory of investment value. Cambridge, MA: Harvard Uni-
versity Press.
Winston, W. 2000. Financial models using simulation and optimization, vols. 1 and
2. Newﬁeld, NY: Palisade Corporation.
Yu, L., X. Ji, and S. Wang. 2003. Stochastic programming models in ﬁnancial opti-
mization: A survey. Paper, http://en.scientiﬁccommons.org/42910402.
Zenios, S., and P. Kang. 1993. Mean-absolute deviation portfolio optimization for
mortgage-backed securities. Annals of Operations Research 45: 433–450.
Ziemba, W. T. 2003. The stochastic programming approach to asset, liability, and
wealth management. Charlottesville, VA: CFA Institute.
Ziemba, W. T., and J. M. Mulvey (eds.). 1998. Worldwide asset and liability mod-
eling. Cambridge: Cambridge University Press.


Index
Absolute deviation (AD) portfolio risk measure,
279–280
Absolute moment risk measure, 280
Accrued interest, 19–20
Active investment management, 219–220
Active management/full-blown active approach,
384–387
Active management/larger risk factor mismatches,
383–384
Active strategies, 324
types, classiﬁcation, 383–384
Actual tracking error, 336–337
Adaptive decision variables, 219–220
Additive model, 433–434
Add-with-carry (AWC) generator, 124
Adjusted duration, 374–375
Advanced random walk models, 444–450
simulation procedure, 450
After-tax performance, reporting, 344
After-tax portfolio return, 345
Agency CMOs, 589, 599–606
Agency deal, structuring, 600
Agency pass-through RMBS, 595–596
Agency pool
qualiﬁcation, absence, 589
securitization, 589
Agency RMBSs, 588, 589
Agency stripped MBS, 596–599
Algorithm efﬁciency, 169–170
Alpha percentile (α-percentile), 69
Alternative asset classes, 16
American equity options, pricing (binomial
method), 495
American option, 480
price, lower bound estimation (regression-based
methods), 558–559
pricing, 557–565
binomial method, usage, 526–528
binomial trees, usage, 513–515
simulation, usage (avoidance), 557–558
true price, upper bound (production), 558
American put option, pricing
regression methods, usage, 576–577, 580–583
two-period binomial tree, usage, 514e
Amortization, 590
Amortizing securities, 20
AMPL, 186
Anderson-Darling (A-D) test, 104
Annual discount rate, usage, 30–31
Anticipative decision variables, 219–220
Antithetic variables, 536–539
approach, 537
negative correlation, 539
usage, 574–575
Approximate dynamic programming technique,
558
Arbitrage, 487–491
concept, illustration, 489
opportunity, 487–488
strategy, 488
Arbitrage Pricing Theory (APT), 6, 401
derivation, 405
examination, 404–406
Arctangent model (OTS), 610, 611
Arithmetic Asian option price
closed-form expression, 567–568
mean/standard deviation, 549
Arithmetic random walk (ARW), 424–429
assumptions, problems, 428–429
constant drift/volatility, 428
disadvantages, 439
drift
estimation, 465, 467
inclusion, 425
facts, 428–430
model, 451
observations, 428
parameter estimation, 426–427
paths, 425e
generation, 469
price, closed-form expression (computation),
432
simulation, 426
software, advice, 457, 459
volatility, estimation, 465, 467
Array functions, application, 270–272
Arrow-Pratt risk aversion coefﬁcient, 257
Asian call option
price, 545–546
closed-form formula, 546
pricing, 573–574
control variates method, 575, 578
crude Monte Carlo, usage, 574, 577
Asian options, 481
payoff, 547
price, simulation (usage), 556
743

744
INDEX
Asian options (Continued )
pricing
example, 547–549
simulation, usage, 534–536
value, discovery, 535
Asset allocation, 260
advantage, establishment, 406–407
decision (implementation), futures (usage),
639–640
Asset-backed securities (ABSs), 17
interest, payment, 18
types, 587–588
Asset classes, 15–23
types, 15
Asset diversiﬁcation, 245
MATLAB, usage, 273–275
software, advice, 268–275
Asset-liability management, 219–220
Asset managers, activities, 640
Asset price dynamics
arithmetic random walk, 470
software, usage, 457, 459
ARW worksheet, 458e
Excel 2007 regression dialog box, 463e, 467e
geometric mean reversion, 465–471
geometric random walk, 470
software, usage, 459, 461
GMR worksheet, 466e
GRW worksheet, 460e
jumps, inclusion, 448
MATLAB, usage, 469–471
mean reversion, 461–465, 470–471
model, regression output, 464e
modeling, 421
MR worksheet, 462e
observation, 444–445
@RISK, usage, 457–469
software, advice, 457–471
Asset prices
codependence, argument, 445
correlation, 445
dynamic factor models, 447
estimates, 444
multiplicative model, 433–434
realizations, simulation, 434
series, 427
volatility, 421
Asset pricing, 402
theory (positive theory), 246
Asset returns
distributions, 404–405
N-dimensional vector, 295–296
Assets
aggregate amount, 348–349
baskets, mispricing, 491
beta, 675–677
forward contract, 493
future cash ﬂows, 658
management, 1
portfolio weights, 415–416
Asset weights, N-dimensional vector, 295–296
Asymmetric risk, protection, 481
Atlantic option, 480
Average daily volume (ADV), 327
Average estimator, variance (reduction), 538–539
Average life, 596, 617
Axioma, 187
Backward-looking error, 336
Backward-looking tracking error, 416
Bank for International Settlements (BIS)
Basel Committee on Banking Supervision, 286
regulations sanction, 294
Bank loans, 17
Bankruptcy, 486–487
Barbell portfolio, 394–395
Barbell strategy, 385–386
Barclays Capital Global Aggregate Bond Index,
381
Barclays Capital U.S. Aggregate Index, 380
Barra, 187
Barrier options, 481
pricing, 556–557
Basel Committee on Banking Supervision (BIS),
286
Basis functions, 559
Basis risk, 634
Basis swaps, 486
Basket credit default swaps, 487
Bayesian estimation approaches, 351
Bayes’ rule, 351
Benchmark exposure, 333–337
Benchmark index, 16
Benders decomposition, 225–226
Beneﬁcial interest certiﬁcate, 588
Bermuda option, 480
Bernoulli distribution, 53e, 54–55
MATLAB, usage, 96
mean, 64
Bernoulli probability distribution, 52–53
Bernoulli random variable, 52
Bernoulli trial, 423–424
Beta (β), 403
estimation, Excel regression, 408e
usage, 674–675
Beta distribution, 72, 78–79
examples, 79e
MATLAB, usage, 98–99
Biased estimator, 565–566
Bias magnitude, determination, 116–117
Bid-ask spreads, 639
Bid/offer costs, increase, 636
Bimodal distributions, 66
Binary optimization problem, 153
Binary variables
introduction, 230
usage, 331
Binomial distribution
example, 56e
MATLAB, usage, 96–97
shape, 57e, 58e
usage, 54–55
Binomial lattices, 173–174
Binomial probability distribution, 53–57

Index
745
Binomial trees, 173–174
application, 719
dynamic programming technique, application,
557–558
example, 424e, 720e
model, simplicity, 423
price process dynamics description, 422–423
pricing model, Black-Scholes option pricing
formula (relationship), 508–512
state space representation, 175e
time periods, usage, 424
usage, 423–424, 495–501, 513–515, 711
Black-Litterman model, 351
Black-Scholes delta, 566
closed-form formula, 567–568
Black-Scholes formula, 495, 708
bonds, relationship, 511–512
call/put prices, calculation, 523e
implementation, 527
Excel, usage, 522–524
parameters, estimation, 505–507
risk-free rate, 533
usage, 502–512
Black-Scholes implied volatility, discovery, 527
Excel Solver, usage, 524–525
Black-Scholes model, assumptions, 512
Black-Scholes option pricing formula, 502–503,
507–508
binomial tree pricing model, relationship,
508–512
parameters, matching, 510–512
usage, 711
Bond-equivalent basis, yield, 31–32
Bond-equivalent yield, 31–32
Bond portfolio management
derivatives, usage, 633–639
futures, usage, 634–635
interest rate risk, control, 633–637
options, usage, 635
strategies, 379–388
swaps, usage, 635–637
total return, 27–28
Bond portfolio risk
decomposition, 416–417
measurement, 373–379
Bond prices
change, impact, 391e
derivation, 613
discount rate, relationship, 31e
sensitivity, 36–37
Bonds, 17
arbitrage
optimization, usage, 520–522, 527
problem, Solver dialog box, 522e
asset class, 15
Black-Scholes formula, relationship,
511–512
cash ﬂows, 390e
convexity, 41
current yield curve, 390e
discount factors, 390e
hedge ratio, 635
hedging, 635–636
cash market, 636
management spectrum, 380e
management strategies, classiﬁcation, 379
market indices, 380–382
par value, 18
payment, provisions, 20
pricing, 490e
principal level, example, 30–31
rating systems, 22e
strategy, comparison, 112e
term, interchangeability, 18
term to maturity, 18
traded ﬂat, 20
trading at a discount, 18
trading at a premium, 18
value
calculation, examples, 32–33
change, 27
volatility, 635
Bootstrapping, 91–92
historical data, 222
technique, 103
Borrower (issuer), 17
Boundary condition, 179
Box-Muller method, usage, 539
Box uncertainty set, 233e
usage, 358
Broad-based bond market indices, 380–381
Broad-based market indices, corporate bond
sector, 382–383
Broker loan rate, 24
Brownian motion (BM), 451, 532–533
Buffer, 608
calculation, 621
Bullet maturity, 20
Bullet portfolio, 394–395
Bullet strategy, 385–386
Burnout, 593
effect, 609–610
Burnout multiplier (BM), 612
function, usage, 613
Business ﬁnance, 1
Buy-write strategy, 632
Callable bonds, 21
pricing, 610–611
Callable swaps, 486
Call money rate (broker loan rate), 24
Call option, 480
implied volatility, 505–506
long, 483
payoff, 641e
premium, payment, 711
price, denotation, 565
pricing, simulation (usage), 716–717
purchase, 495
sale, 483
short, 483
value, 499
Call premium, downside protection, 632
Call provision, 20

746
INDEX
Cap, 19
Capital, 653
adequacy, 294–295
appreciation, 16
budget, limit (absence), 668
expenditure, 655
histogram/summary statistics, 111e, 113e
investment, 653–654
company resources, long-term commitment,
653
loss, 43
accumulation, 343
markets, 1
output distribution, 110e
project, investment (evaluation), 654
rationing, 661–662
Capital Asset Pricing Model (CAPM), 5–6, 278,
401
explanation, 402–404
risk/return trade-off, 405
scrutiny, 404
usage, 676–677
Capital budgeting, 1, 159–162, 332, 653
case study, 680–697
costs, 682
decisions, 653
implementation, example, 194–196, 199–200,
205–208
issues, 668–671
market shares, correlations (deﬁning),
702e
MATLAB, usage, 703
modeling issues, 700
NPV/IRR calculation, 683e, 684e
NPV proﬁles, 687
optimization model (Excel), 194e
output, formatting, 701, 703
practice, 671–672
problem, formulation, 207e
process, 658
projects, mathematical tools (usage), 2
revenues, 682
@RISK
Deﬁne Correlations dialog box, 702e
usage, 699–703
scale differences, 668–669
simulation
inputs, creation, 699–701
usage, 701, 703
software, advice, 699–703
tornado graphs, creation, 703
unequal lives, 669–671
variable costs, impact, 681
Capital cost, 658, 659
calculation
CAPM, usage, 676–677
computation, 685–686
hurdle rate, 666
Capital gains, 43
accumulation, 343
short-term/long-term nature, 346
Capital Market Line (CML), 257–261
example, 259e
explicit line equation, 261
portfolio, presence, 260
Capital market theory, 1
Caplet, 568–569
pricing, 568
Cardinality constraints, 153, 329–330, 333
Cash dividends, 16
Cash equivalents, separation, 15
Cash ﬂow (CF)
amount, 13–14
average, calculation, 617
change, 42
discounting, 659–660
dynamics, description, 174
estimates, 673
examples, 597e–598e, 601e–604e
expiration, 561e
generation, 595–596
matching, 157–159
data, example, 158e
strategy, 395–396
present value, 14
reinvestment, assumption, 663
time periods, simulated paths, 562e, 564e
uncertainty, 591
Cash inﬂows, reinvestment rate, 665
Cash market (bond hedging), Treasury securities
(usage), 636
Cash matching, example, 159
Cellular approach, 388
Central Limit Theorem (CLT), 89–90, 122
Central moments, 266
Central tendency, measure, 64–65
Certiﬁcates, 588
Chance-constrained stochastic optimization
models, 228–230
Chance constraints, 218–219
requirements, 230
Characteristic line, 403
estimation, 403–404
usage, 404
Chicago Board of Trade (CBOT), Treasury bonds
(trading), 635
Chi-square distribution, 72, 78, 353
degrees of freedom/noncentrality parameter,
inclusion, 442
example, 78e
MATLAB, usage, 98
Chi-square test, 122
Classical immunization, 389
theory, extension, 393–394
Classical NPV
calculation, 714e
computation, discount rate (usage), 728
project example, 718e
Clean price, 20
Closed-form expression, derivation, 614
Closed-form formula, 455, 546
Clustering observations, 126

Index
747
Coefﬁcient of variation (CV), 68
usage, 112
Coefﬁcient value, simulation, 548
Coherent risk measures, CVaR (relationship),
301–307
Collar strategies, 630–631
example, 632e
Collateral
average life, 605e
par value, 605
prepayments, 609
Collateralized loan, 23–24
Collateralized mortgage obligations (CMOs),
594
analysis, 620
bond classes, 605e
sequential-pay structures, 600, 605–606
structure, tranches (inclusion), 621
structuring, 620–621
Combinatorics, 56–57
Combined multiplicative recursive generators
(CMRGs), 124
Commercial mortgage-backed securities (CMBSs),
588
Commodities
forward contracts, 478–479
prices, 447–448
Common stocks
asset class, 15
securities, 16
Companion bonds, 606
Company
beta, 685
capital cost, adjustment, 677–678
debt-to-equity ratio, 730
ﬁnancial risk, 675
options, 707
stock, beta, 674
voting rights, 16
Complementary projects, 657–658
Complex option contracts, 481
Compounding
absence, 12
distributions, 108–110
Compound interest, 11–13
Concave function, 149–150, 149e
Conditional expectation, 86
Conditional PDF, 86
Conditional prepayment rate (CPR), 592
expression, arctangent model (usage), 611
monthly CPR, 594e
monthly value, 593
ramp, 607
Conditional probability, 84–86
Conditional Value-at-Risk (CVaR), 5, 282–283
calculation, 302–303
coherent risk measures, relationship, 301–307
estimation, 309
discrete distribution, usage, 303–304
MATLAB, usage, 314–316
normal distribution, usage, 302–303
risk measure, 302
worksheet, 312e
Conditional Value-at-Risk (CVaR) optimization,
304–307
MATLAB, usage, 316–318
problem
Excel Solver dialog box, 313e
formulation, 336
worksheet, 311–313
Conﬁdence, degree, 90
Conﬁdence interval (CI), 90–91, 237
calculation, 115–116
estimate, computing procedure, 91, 106
Congruential pseudorandom number generators,
123
CONOPT, 186
Constant drift, 428, 435
Constant maturity Treasury (CMT) rate, 486
Constrained nonlinear optimization, 164–167
Constraint functions, derivatives, 165
Constraints
introduction, 230
objective function placement, 171
robust counterpart, 233–234
writing, 221
Consumer demand, 437
Consumer Price Index for All Urban Consumers
(CPI-U), 19
Contingent projects, 656–657
dependence, 657
Continuous compounding, 13
Continuous distributions, 58–59, 72–79
calculation, 64, 67
inverse transform, 120–121
Continuous time, stochastic processes,
422–423
Continuous-time formula, 117
Continuous uniform distribution, 72, 73
example, 73e
MATLAB, usage, 97
Contract settlement, 487
Control variables, 178
Control variates, 545–549
method, 575
Control vector, 213
Conversion privilege, 20
Convertible bond, 20
Convex function, 149e
Convexity, 40–42
adjustment, 41–42
measure, 40–41
calculation, bond prices (usage), 42
risks, 416
Convex optimization problems, 149
types, primal/dual formulations, 172e
Convex programming, 149–150
Copula function, 378, 447
Corporate bond
market, 637
pricing, example, 636
shorting, difﬁculty, 638

748
INDEX
Corporate ﬁnance, 1
options, 707
Correlated coefﬁcients, 697
estimation, 729
Correlated random walks, 445–447
Correlation (ρ), 79–81
coefﬁcient, 80
incorporation, 110–111
matrix, 81, 642–643
examination, 410
sample, 88
Cost estimate, variation, 727e
Cost function, 212
Costs, binomial tree, 725e
Counterparty risk, 477, 480, 492
Coupon payments, 27, 389
reinvestment income, 27–28
Coupon rate, 18
calculation, 19
determination, 605
Coupon risk, 416–417
Covariance (Cov), 79–81
matrix, 81
problems, 447
sample, 88
Covered call risk, 632–633
Covered call strategy, 632
example, 633e
Cox-Ingersoll-Ross (CIR) model, 459–460, 569,
613
usage, 614
CPLEX (ILOG), 186
Credit default swap index (CDX), 638–639
Credit default swaps (CDSs), 486–487
consideration, 637–638
contract, life, 637–638
Credit enhancement
agreements, complication, 378
mechanisms, 588
Credit event, 486–487
Creditor (investor), 17
Credit rating, 21–22
Credit risk, 21–23, 376, 477
exposure, 378–379
impact, 619
management, 637–639
minimization, 379
Credit-risky positions, modeling approach,
378
Credit spread, 22–23, 36
change, 386
risk, 23
term structure, 36
Credit support
amount, 608
calculation, 621
Cross acceleration/default, 486–487
Cross hedge, risk minimization, 634–635
Cross hedging, 634
Crossover rate, 169
Crude Monte Carlo method, performance
(example), 555e
Crude Monte Carlo simulation, usage, 532–536,
542, 549
Cumulative distribution function (CDF), 61–63
construction, 62
example, 61e
inverse, approximation, 121
plots, 118–119
Cumulative normal distribution function, 508
Cumulative probability
concept, 61–63
distribution, inversion, 119
Currency
denomination, 20–21
forward contracts, 478–479
Current earnings, 16
Dealer option, 481
Debt
after-tax cost, 685
cost, 685
ﬁnancing, market value terms, 675
obligations, 17
usage, 674–675
Debt-to-equity ratios (D/E), 411
usage, 730
Decisions, evaluation, 111–115
Decision Tools Suite (Palisade), 186–187
Decision variables, 144
deﬁning, 221
introduction, 306
objective, writing, 221
vector
deﬁning, 154
ﬁxed values, 235
Decision vectors, N-dimensional vector, 151
Default, binary event, 377
Default-free cash ﬂow, 30
Default-free securities, pure interest rates,
33–34
Default risk, 21–22
Deﬁned beneﬁt pension plan, longer-term
investments, 606
Degrees of freedom, 78
Delivery price, 478
Delta (), 515–516
equation, 565
Delta-gamma approximation, 646–647
Dependence, 79–81
measures, covariance/correlation (usage), 81
Dependent variables, 408–409
Derivatives, 477
American option pricing, binomial method
(usage), 526–527
baskets, mispricing, 491
Black-Scholes formula, implementation
Excel, usage, 522–524
VBA, usage, 524
Black-Scholes implied volatility, discovery
Excel Solver, usage, 525–526
VBA, usage, 526
data table dialog box, 524e
example, 166e

Index
749
Excel/VBA, usage, 520–527
fair price, 532
implied volatility, Solver dialog box, 526e
MATLAB, usage, 527–528
pricing
estimate, 536–537
simulation-based methods, 564–565
software, advice, 520–528
Solver dialog box, 522e
types, 478–487
usage, 626–633
use, concepts, 487–492
worksheet, 521e, 526e
Derivatives pricing
concepts, 487–492
MATLAB, usage, 577–583
@RISK, usage, 571–574
simulation, usage, 531
software, advice, 571–583
Visual Basic, 574–577
worksheets, 572e, 573e
Descriptive statistics, 87
Deterministic constraint, 230
Deterministic models, 211
Diagonal matrix, 415–416
Differential equations, 451
Direction numbers, 554
Dirty price, 20
Discontinuous utility functions, 267
Discounted cash ﬂow (DCF)
approach, 28
methodologies, 7
sum, 713–714
usage, techniques, 671
Discounted payback period, 666–668
calculation, 668e
measure, 667–668
Discounted payoff, 566
Discounted proﬁt, simulation output, 724e
Discounted value, 13–14
Discount factor, 14
Discount future cash ﬂows, 673
Discount rate, 659, 728–729
bond price, relationship, 31e
differences, 32–33
Discrete distributions, 53–57, 70–72
calculation, 64, 66
CDF, graph, 119e
generation, 222
inverse transform, 119–120
usage, 303–304
Discrete probability distributions, 57–58
Discrete uniform distributions, 70–71
example, 70e
MATLAB, usage, 97
Discretization error
bias, 117
concept, illustration, 455
elimination, Ito’s lemma (usage), 455–456
Dispersion, 66
risk measures, 278–280
Distressed debt, 21–22
Distributions
description, 63–69
percentile, usage, 68–69
parameters, estimation, 103–104
spread/dispersion, 66
Disturbance, 213
Diversiﬁable risk, elimination, 387
Diversiﬁcation
beneﬁt, 248
examination, 246–250
preference, 245–246
Dividend, payment, 16
Dividend discount model, 28
Dollar amount of losses, 283
Dollar-denominated issue, 21
Dollar duration, 38–39
Down-and-out put option, 557
pricing, crude Monte Carlo (usage), 576, 580
Downgrade, 23
Downgrade risk, 23
Downside dispersion risk measures, 280–281
Downside protection, call premium (usage), 632
Downside risk
hedge, 628
measures, 278, 280–283
portfolio manager concern, 629
Drift
computation, 468–469
estimation, 465, 467
meaning, 421–422
parameters, selection, 428
term, 432
usage, 425
Dual-currency issues, 21
Duality theory, 235
Duration, 36–40
calculation, 38
deﬁning, 37
strategies, 385
Durbin-Watson test, 122
Dynamic factor models, 447
Dynamic programming, 176, 212–218
algorithm, description, 620
classical optimization formulations,
relationship, 179–181
problems, size/complexity (reduction), 217–218
recursion, usage, 182
standard notation, usage, 178–179
technique, application, 557–558
usage, 620–622
Economic conditions, 673
Economic factors, 405
Economic forecasts, usage, 386–387
Economic life, 655
Effective annual rate, 12
Effective duration, 39, 42, 374–375
Efﬁcient frontiers, 245, 254–256
calculation, VBA (usage), 272–273
MATLAB, usage, 273–275
software, advice, 268–275
Efﬁcient mean-variance optimization, 414–416

750
INDEX
Ellipsoidal uncertainty set, 233e
Embedded options, 21
existence, 416–417
Empirical probability distribution, 87
Employee Retirement Income Security Act
(ERISA), 325
End-of-year capital, estimation, 103
End-of-year distribution, histogram/summary
statistics, 105e
Enhanced indexing/matching primary risk factors
approach, 383
Enhanced indexing/minor risk factor mismatches,
383
Entity, ﬁnancial obligation, 16
Environmental Protection Agency (EPA),
656–657
Equilibrium market price, 261
Equilibrium models, 613
Equities, 16
arbitrage strategies, 491
beta, 677
cost, 685
ﬁnancing, market value terms, 675
index strategies, 382–383
portfolios
management, derivatives (usage),
628–633
risk decomposition, 414
valuation models, 28–30
Equity funds, management, 639
Equity portfolio selection, 321
Excel Solver
dialog box, 363e
usage, 361–366
worksheet, 365e
index tracking, 364–366
MATLAB, usage, 368–369
Palisades Decision Tools Suite (Evolver),
366–368
dialog box, 366e–368e
index tracking, 367–368
stock number, limitation, 366
software, advice, 361–369
worksheet, 362e
Equity swaps, 485–486
structures, ﬂexibility, 485
Equivalent annual annuity method, 671
Estimates
standard error, 90
variability, 90
Estimation error
covariance matrix, 358
penalty, 357
Estimator
bias, 116–117
efﬁciency, 117–118
Euclidean norm, 233
European call option, 501
delta (evaluation), naive Monte Carlo/pathwise
method (usage), 577, 583
purchase, 483
European call option prices, 503e, 513
computation, 554–555
Halton sequence, usage, 576, 579–580
Sobol sequence, usage, 579–580
simulation, advantage, 533–534
strike price, impact, 533
European call option pricing, 541, 572–573
antithetic variables, usage, 574–575, 577
crude Monte Carlo, usage, 574, 577
simulation, usage, 532–534
two-period binomial tree, usage, 500e
European equity options, pricing (binomial
method), 495
European-exercise style options, pricing, 512
European options, 480
Black-Scholes formula, 495
usage, 502–512
multiple periods, generalization, 499–501
one-period example, 495–497
pricing, binomial trees (usage), 495–501
risk-neutral probabilities, 497–499
European put option
prices, 503e
pricing, two-period binomial tree (usage), 501e
Evaluation period, 324–325
Events mapping, 52
Evolver (Palisade), 157, 168
dialog box, 197e, 200e
Optimization Settings dialog box, 198e
Progress dialog box, 199e
tab, example, 196e
usage, 196–200
Ex ante tracking error, 337
Excel
Solver, 157
usage, 270
2007 regression dialog box, 463e, 467e
usage, 61
worksheet setup, 268–270
Excess return, 283
Exchangeable bond, 20
Exchange rates, 437
Exchange-traded derivatives (listed derivatives),
477
Exchange-traded option, 481
Exercise price, 480
Exercise style, 480
Exercise value, 562
Exogenous events, portfolio manager concern,
629
Exogenous insight, incorporation, 351
Exotic options (exotics), 481
Expansion projects, 656
Expectation (average), 80
operator, 83
Expected cash ﬂows
estimation, 28
present value, calculation, 28
Expected discounted proﬁt (probability-weighted
discounted proﬁt), 216
Expected dollar return, maximization, 348

Index
751
Expected end-of-period wealth, denotation,
266–267
Expected loss, 302
Expected portfolio return, expression, 415
Expected prepayments, calculation, 616
Expected return, 143, 245
equality, 402
estimates, 358
formulation, 256
maximization, 332–333
formulation, 256
Expected shortfall, 282–283
Expected utility framework, 261
Expected utility optimization problem,
formulation, 261–262
Expected utility theory, 261–267
Expected value, 64
estimates, computation, 563
usage, 640
Expiration date, 480
Explanatory variables (independent variables),
408–409
coefﬁcient, p-value, 441
linear regression, 440
Exponential distribution, 72, 76–77
CDF, computation, 120
example, 77e
MATLAB, usage, 98
memoryless property, 77
Exponential function, 432–433
Exponential time, 170
Exponential utility function, 264
Ex post tracking error, 336
External factors (economic factors), 405
Extracted factors (statistical factors), 405
Factor analysis, 405, 407, 410–412
procedure, problem, 411–412
Factor covariance matrix, 415–416
Factor loadings, 411
Factor models, 327–328, 350, 401
Excel regression dialog box, 418e
regression, running, 419
software, advice, 418–419
usage, 413
Factors, 401
choice, 415
K-dimensional vector, 411–412
Failure to pay, 487
Fair equilibrium, 347
Fair value, 28–29
Fat tails, 69
presence, 292
Faure sequences, 125
components, usage, 553
ith coordinate, generation, 553
usage, 552–553
Feasible efﬁcient portfolios, 255e
Federal Drug Administration (FDA) approval, 708
Federal Home Loan Mortgage Corporation
(FHLMC), 16, 589, 607
Federal National Mortgage Association (FNMA),
16, 589, 607
Feedback shift registers (FSRs), 124
Finance concepts, 11
Financial applications, 219–220
Financial asset, valuation/pricing, 28
Financial call option, 710
Financial derivatives, 455
application, 477–478
Financial instruments
payoffs, 640
pricing applications, 54
Financial leverage, 674–675
Financial management, 1
Financial modeling, log returns (usage), 27
Financial options
exercise features, 711
maturities, 711
pricing, 712
real options, relationship, 710–712
underlying asset, 711
value, 712
Financial time series, 421
Finite horizon, 213
Finite state space, 173–181
Firm characteristics, 405
First order sensitivity, 26–27
Fishburn risk measure, 281
Fitch Credit Rating, bond ratings system, 22e
Fitness score, 169
Fixed income concepts, 33–46
Fixed income portfolio management, 372
Fixed-income risk management, factor models
(usage), 402
Fixed income securities, 16–23
complexity, 17–18
term, interchangeability, 18
valuation models, 30–33
Value-at-Risk estimation, 377–379
Fixed rate, level payment mortgage (ﬁxed rate
mortgage), 590, 595
Fixed rate bonds
spread duration, 40
value, 518
Fixed rate interest rate payments, swapping, 517
Fixed transaction costs, 342–343
Floating rate bond, value, 518
Floating-rate securities (ﬂoaters), 19
Floor, 19
Forward contracts (forwards), 478–480
long position, 478
payoffs, 482e
short position, 478
payoffs, 482e
Forward-looking tracking error, 416
Forward price, 478
Forward rates, 34–36, 478
computation, 35
Forwards
pricing, 492–494
Free money, 488

752
INDEX
Full price, 20
Fundamental factors, 405
Funds
borrowing, 23–24, 495
management, 639
opportunity cost, 659
portfolio manager allocation, 386
returns, scenarios, 228e
Future cash ﬂows, 658
beneﬁts, generation, 673
risk, association, 656, 658, 679
terminal value, 666
Future interest rates, simulation (ease), 459–460
Future market yields, 44
Future portfolio value probability distribution, 640
Future price, distribution, 428, 436
Future revenues (value), binomial tree (usage),
720e
Futures, 478–480
contract
dollar duration, 634
dollar-for-dollar gain/loss, 481
forwards, comparison, 479
market
execution, 639–640
usage, alternative, 639–640
option, 512
prices, pricing formula, 493–494
pricing, 492–494
usage, 634–635
hedging context, 637
Future value, 13–14
conversion, 14
Gamma function, 78
Gamma (), 516
GAMS, 186
Gaussian copula dependency models, 378
Generalized feedback shift registers (GFSRs), 124
Generalized Wiener process, 451
Ito process, relationship, 452
Generated random variables, negative correlation,
539
Genetic algorithms, 168
usefulness, 168–169
Geometric Brownian Motion (GBM), 117, 451
Geometric (log) form, 26–27
Geometric mean Asian option price, control
variate usage, 547
Geometric mean reversion (GMR), 442–444
drift, computation, 468–469
paths, generation, 469
process, paths, 443e
software, usage, 465–469
volatility, 467–468
Geometric random process, exponential growth,
433
Geometric random walk (GRW), 429–437,
507–508, 715
drift, 507
equation, 430
expression, 435
facts, 435–437
parameter constancy, 443–444
parameter estimation, 434–435
paths
example, 436e
generation, 469
simulation, 434–435, 440
process, exponential growth, 434
simulation, 434
software, usage, 459, 461
volatility, 461
Geometric returns, 288–289
Glivenko-Cantelli Theorem, 122
Global bond indices, 381–382
Global optima, local optima (contrast), 147–148
Goldman Sachs model, modiﬁcation, 610,
611–613
Goodness-of-ﬁt tests, 93
Gordon model, 29–30
Government National Mortgage Association
(GNMA), 589, 607
Gradients, 165
Greeks, evaluation, 565–568
GSE shelf, 607
Halton quasirandom sequence, 575–576, 578–579
Halton sequence, 551–552
prime numbers, usage, 552–553
Hedge ratio, selection, 635
Hedging, 491–492
strategy, 491
High-loss severities, creation, 589
High-yield bonds, 21–22
Historical data scenarios, usage, 289–291
Historical simulation, usage, 643
Holding constraints, 326
Holdings, conversion, 348–349
Hold-to-maturity investor, replacement, 17
Ho-Lee model, 613–614
Homoschedasticity, 409
Hoppe, Richard, 297–298
Horizon analysis, 44
Hull-White model, 613–614
Hurdle rate, 659, 662
capital cost, 666
requirement, 673
simplicity, 672
Hybercubes, random point generation, 128
Hypothesis testing, 92–93
If-then statements, 162
Immunization
results, 393e
risk measure, 394e
strategy, 389–395
Implied probability
calculation, 505
example, Solver dialog box, 526e
Importance distribution, 542–543
Importance sampling, 225–226
stratiﬁed sampling alternative, 540–545
Incremental cash ﬂows, consideration, 658

Index
753
Independent and identically distributed (IID),
89–90
log returns, 436–437
random variables sequence, 425
sample, examination, 538
sequence, returns, 429
Independent normal random variables, sum,
427–428
Independent normal variables, sum, 431–432
Independent project, 657
Independent scenarios, generation, 107
Independent variables, 408–409
Index, 16
risk factors, 379
tracking, 219–220
limitation, 367–368
usage, 364–366
Indexed-amortizing swaps, 486
Index fund, 101–102
Indexing, 324, 333
points, criticism, 382
Inﬁnite horizon, 213
Inﬁnite state space, 181–185
Inﬂation-indexed bonds, 19
Inﬂation-linked bonds, 19
Inﬂection points (saddle points), 166
Information ratio (IR), 349–350
Initial capital, 26
Initial stock price, multiple, 436
Inputs, probability distributions, 103–104
Institutional investor, replacement, 17
Insurance industry tax-exempt indices, 381
Integer programming (IP), 152–153
algorithms, 167
optimization problems, 167
Integrated risk management system (J.P. Morgan),
286–287
Integration, concept, 59–60
Intercept alpha, value, 408
Intercept term, alpha (representation), 413
Interest
compounding, 13
requirement, absence, 12
expected risk-free rate, 676–677
shortfall, occurrence, 605
theory, 11–14
Interest on interest, 11
Interest-on-interest component, 43
Interest-only class, 596
Interest-only mortgage strip, 599
Interest-only security (IO), 599
price movement, 599
Interest rate, 437, 673
caps, 568–569
changes
immunization, 392
impact, insulation, 389
computation, 615
derivatives, pricing (examples), 568–570
determination, 28
dynamics, Cox-Ingersoll-Ross model (usage),
459–460
expectations strategies, 385
futures contracts, usage, 385
increase, 635
level, impact, 610–611
minimum, 30–31
models, 613–615
usage, 614
negative shift, usage, 391–392
risk, 374–375
impact, 618–619
scenario, 377
swaps, 486–487
advantages, 636–637
term structure, 34
Interior point methods, 163–164
Internal rate of return (IRR), 658, 662–665
cash ﬂow reinvestment, 666
criteria, 669
inclusion, 660e
methods, decision process, 663
multiple IRRs, 664e
value, 662
yield, 662
International bond indices, 381–382
International conditions, 673
Intersector strategies, 386–387
In-the-money call option, volatility smile, 506e
In-the-money option, 494
In-the-money random path, 542
Intrasector allocation strategies, 386–387
Inverse ﬂoaters, 19
Inverse transform method, 118–121
Inversive generator (IG), 124
Inverted yield curve, 32
Investment
behavior, assumptions, 404–405
compounding, impact, 12
decisions, 658–672
horizon, 27–28, 35
duration, equivalence, 394
length, 666
liquidity, measurement, 667
management, 1
objectives
setting, 322–323
type, variation, 322–323
process, 322–325
proﬁle, creation, 660–661
projects, classiﬁcation, 654–658
economic life, basis, 655
project dependence, 657–658
risk, basis, 655–657
reevaluation, 717–718
single-period view, 325
strategy, 477–478
type, selection, 324
Investment-grade bonds, 21–22
Investment-grade corporate entities, indices, 638
Investment-grade sector, 21–22
Investors, equity, 479
ITG, 187
Ito processes, 452

754
INDEX
Ito’s lemma, 452–453
usage, 454–456
Ito’s stochastic calculus, 495
Jensen alpha, 413
Jensen measure, 413
Joint conﬁdence, 357–358
Joint probability
distributions, 84–86
random variables, values, 85
Jones, Robert, 406
Jump-geometric random walk process, path
simulation, 449
Jumps
incorporation, 447–450
size, price changes (relationship), 448–449
Junior notes (subordinate notes), 587–588
Junk bonds, 21–22
Karmakar, Narendra, 163–164
Karush-Kuhn-Tucker (KKT) conditions, 164–167,
170
importance, 166–167
Key rate duration, 42–43, 375
Kolmogorov-Smirnov (K-S) test, 104, 122
Kurtosis, 69
k values, 92
Ladder strategy, 385–386
Lagrange multipliers, 164–167, 170
Large cap, company classiﬁcation, 15
Last-stage nodes, 220
Latin hypercube sample, 127e
Latin Hypercube Sampling, 127
Left-skewed distribution (negatively skewed
distribution), 69
Lehman Brothers U.S. Aggregate Index, 380
Lender (investor), 17
Level payment mortgage, 590
Leveraged strategies, 23–24
Liability, duration (computation), 391
Liability-driven strategies, 388–396
Likelihood ratio, 544–545
Linear congruential generators (LCGs), 124
Linear congruential pseudorandom number
generators, 123
Linear constraints, 155
robust counterpart, 232
Linear delta approximation, 646
Linear optimization, 163–164
problem, 306–307
formulation statement, 150
solver, 392–393
Linear payoff, 481
Linear programming (LP), 150–151, 156, 172
Linear regression, 403
model, estimates (validity), 440
Linear transaction costs, 338–339
Linear utility function, 263–264
Lintner, John, 402
Liquid CDS, 638
Listed derivatives, 477
Listed option, 481
Local optima, global optima (contrast), 147–148
Logarithmic utility function, 265–267
Lognormal distribution, 72, 75–76, 502
example, 76e
MATLAB, usage, 98
Lognormal probability distribution, 556
Lognormal random variable, 433
Log return, 26–27
usage, advantages, 27
Log-return log, distribution, 433–434
London Interbank Exchange Rate, 485
London Interbank Offered Rate (LIBOR), 19
call option, caplet, 567
rate, observation, 568
spot rate curve, 34
Long-only constraints (no-short-selling
constraints), 326
Long positions, 24–25
Long put (ﬁnancing), short call position (usage),
631
Long stock position, long put/short call (sum), 631
Long-term assets, 655
Long-term corporate ﬁnancial planning, 211
Long-term investment, 655
Long-term mean, 438
Loss
dollar amount, 283
risk, 282
VaR reporting, 299
Loss multiple, 621
Loss/proﬁt (L/P) form, 285–286
Lots, 343
Low-discrepancy sequences, 124–125
Lower bound estimation, 558–559
Lower-partial moment risk measure, 281
Low-risk tail event, occurrence, 289
Macaulay, Frederick, 39
Macaulay duration, 39, 374, 619
Managed money tax-exempt indices, 381
Mandated projects, 656
Mapping, 52
Marginal tax rate, 675
Margin buying, 24
Market
conditions, 673
index, 16
portfolio, 258–259
Standard & Poor’s 500, usage, 403–404
weight, 261
price, example, 723
scenarios, modeling array, 701e
shares, correlations (deﬁning), 702e
size, determination (data), 695e
volatility, 291
Market capitalization (market cap), 15
Market impact costs, avoidance, 639–640
Market-neutral portfolio allocation strategies,
329

Index
755
Market risk
compensation, 676
default risk, dependence, 378
premium, 685
Markowitz, Harry, 2, 83–84, 245, 402
framework, 262
investment theory, 278
model, 263
Matching parameters, 510–511
Mathematical tools, usage, 2
MATLAB, 4, 6
command, default, 290
Direct Search Toolbox, 168
Genetic Algorithms, 168
Optimization Toolbox, 146, 157, 200–208, 254
functions/solvers, 201e
optimization tool interface, 202e
software, 96–99, 134–140
Statistical Toolbox, 411, 412
usage, 61, 72, 256
Maturity date, 17, 480
Maxima, interpretation, 106
Maximization, minimization (contrast), 146
Mean, 64–65
returns, N-dimensional vector, 411–412
sample, 87
Mean reversion (MR), 437–444
adjustment, speed, 437–438
geometric mean reversion, relationship, 470–471
models
regression output, 464e, 468e
versions, 450
parameter estimation, 440–441
paths, generation, 469
random walk, generation, 439–440
simulation, 439–440
software, usage, 461–465
Mean reversion (MR) process
adjustment speed, estimate, 441
long-term mean, estimate, 441
paths, 439e
volatility, 438–439
Mean reverting walk
drift, computation, 465
volatility, 463–464
Mean-risk stochastic models, 226–228
Mean-variance analysis, 245, 324
Mean-variance efﬁcient portfolios, 255e
Mean-variance formulation, 359–360
Mean-variance optimization, 266, 413
efﬁciency, 414–415
framework, 250–254
problem
formulations, alternatives, 256–257
robust counterpart, 356–357
Mean-variance portfolio allocation, 355
Mean-variance portfolio optimization, 245
problem, Excel setup, 269e
array functions, inclusion, 272e
Median, 64, 65
Medium capitalization, company classiﬁcation, 15
Mega-capitalization, company classiﬁcation,
15–16
Memoryless property, 77
Merrill Lynch Domestic Market Index, 380
Micro capitalization, company classiﬁcation, 15
Midsquare technique, 122–123
Miller, Merton, 402
Minima, interpretation, 106
Minimization, maximization (contrast), 146–147
Minimum holding, 330–331
constraints, 333
Minimum interest rate, 30–31
Minimum portfolio standard deviation
optimization problem, Excel Solver inputs,
271e
Minimum variance portfolio, 255e
optimization problem, formulation, 258
MINOS, 186, 235
Mixed-integer optimization formulations,
306–307
Mixed integer programming (MIP), 152–153
Mode, 64, 65
Modeling issues, 700
Model risk, 619–620
Modern Portfolio Theory (MPT), 245
Modiﬁed duration, 39, 374
Modiﬁed Goldman Sachs model (Richard/Roll),
610, 611–613
Modiﬁed internal rate of return (MIRR),
665–666
criteria, 669
decision rule, 666
Moment matching, 510–511
Money, time value, 658
Money management, 1
ﬁrms, proprietary multifactor model
development, 414
Monotonic functions, 539
Monotonicity, 301
Monte Carlo sampling methods, approximation
quality, 226
Monte Carlo simulation, 101, 645, 679
numerical integration technique, 550
output, interpretation, 104–107
proportionality, 536
scenario generation, 673
system, 102e
usage, 672, 673
Month multiplier (MM), 612
Moody’s, bond ratings system, 22e
Moratorium, 487
Morgan, J.P., 286–287
Mortgage
loans
cash ﬂow, 590
transformation, 589
maturity/term, 590
mortgage loan cash ﬂow, 590
pass-through security (pass-through), cash ﬂow,
595
rates, change, 596, 599

756
INDEX
Mortgage-backed securities (MBSs), 17
interest, payment, 18
pool, 589
pricing, interest rate models (usage), 614
risk, 416–417
evaluation, interest rate models (usage), 614
terminology, 588–594
Mortgagor, embedded prepayment option
(impact), 591
MOSEK, 186
Mossin, Jan, 402
MSCI Barra, 406
Multi-account optimization, 346–350
problem, 348–349
Multicollinearity, 410
Multifactor models
construction, 406–412
usage, 406
Multinomial distribution, 85
Multinomial probability distribution, 644
Multiperiod real estate project, valuation, 724–727
Multi-period situations, complexity, 116
Multi-period tax aware portfolio optimization,
346
Multiple input probability distributions, 109
Multiple input variables, 108–110
impact, visualization, 110–111
Multiple-objective optimization problem, 148
Multiple objectives, 148
Multiplicative model, 433–435
Multiplicative recursive generators (MRGs), 124
Multistage optimization, 4, 172–185
problems, formulation steps, 185
Multistage problems, Monte Carlo sampling
methods (approximation quality), 226
Multistage robust optimization, 236–238
Multistage stochastic programming
models, 219–226
problems, dimension, 225–226
Multivariate normal distribution, 85
Multivariate normal variables
log returns, behavior, 447
Multivariate regression analysis, 93
Naive Monte Carlo method, usage, 577
Natural logarithm
function, 26–27
usage, 509–510
N-dimensional arrays, usage, 145
Negative cash ﬂow, 663–664
Negative dollar return, 43
Neoclassical NPV, 712–713
Net present value (NPV), 658, 659–661
calculation, 714e
criterion, 669
execution, 707
data table, 661e
indexed value, 661
methods
process, 663
usage, increase, 671
multiple IRRs, 664e
optionality, 715
proﬁle, 660
computation, 686
scenario-by-scenario basis, comparison, 692
viewpoint, 712–714
New products/markets, 656
Next-to-last liability, 395–396
n factorial, 56–57
Nikkei 225 index, 485–486
No-arbitrage concept, 728
No-arbitrage models, 613–614
No-arbitrage pricing, 495
Noise, 213
decay, absence, 428
observation difﬁculty, 87
Nominal annual rate, 12–13
Nominal rate, 12, 18
Nominal spread, 376
Nonagency mortgage-backed securities, allocation,
384
Nonagency RMBSs, 588
prepayments, involuntary status, 611
Nonanticipativity conditions, 222
Noncentrality parameter, 442
Nondeterministic models, 211
Nonfactor error term, 414
Nonﬁnancial events, portfolio manager concern,
629
Noninvestment-grade bonds, 21–22
Non-investment grade indices, 381
Nonlinear payoff, 482
Nonlinear solvers, 235
Nonnegative cash ﬂow, provision, 489
Nonnegativity constraints, 156–157
Nonoverlapping time intervals, 452
Non-PAC bond classes, 606
Nonrecombining binomial tree, 173e
Nonstationarity, 350
Nonsystematic risk, division, 417
Nonterm structure systematic risk, 416–417
Nontraded variable, risk (market price), 729
Nontraditional asset classes, 16
Non-Treasury issue, price (change), 40
Non-U.S. bonds, separation, 15
Non-U.S. common stocks, separation, 15
Normal credit spread, 386–387
Normal distribution, 57–61
MATLAB, usage, 97
mean, 65
standard, 60e
usage, 302–303
VaR calculation, 287–289
Normal-distribution-based VaR, usage, 289
Normal random variable, 431
correlation, generation, 446–447
realization, generation, 535–536
Normative theory, 246
Northﬁeld Information Services, 187, 406
No-short-selling constraints, 326
Note rate, 589

Index
757
Null hypothesis, 92
Numerical integration, 550
Objective function, 144
expected value, 211–212
optimization, goal, 179
Obligation acceleration, 487
Obligors, credit rating (changes), 379
Observations, pure random samples (simulation
problem), 116
Obsolescence, 655
Occupational Health and Safety Agency (OSHA),
656–657
Ofﬁce of Thrift Supervision (OTS), arctangent
model, 610, 611
Oil wells, problem
price process, 214e
scenario tree, 223e
state space, 215e
stochastic programming formulation, 224–225
One-factor models, 613
100% PSA, 593
One-period binomial trees, 496e
One-period log returns, 27
One-sample hypothesis tests, 93
On-the-run swaps, pricing, 637
Operating periods, problems, 655
Optimal decision path, 177e
Optimal exercise times, 564e
Optimal mean-absolute deviation portfolio,
computation, 280
Optimal portfolio
allocation, 29, 333
construction, 352
weights, 258
Optimal solution, 145
Optimal state, 177e
Optimal stopping times (exercise times), matrix,
563
Optimization, 2
algorithms, 162–170
usage, 2, 147
approach, 388
duality, 170–172
theory, 170
formulations, 144–148
dynamic programming, relationship, 179–180
matrix form, 156
modeling, 143
software advice, 188–208
results, structure (handling), 206e
software, 186–187
user expectation, 144–145
tool interface (MATLAB), 202e
uncertainty, 211
usage, 520–522
Optimization problems
binary variables, addition, 331
constraints, 182–183
examples, 153–162
formulation, 145, 154, 161
solutions, 144
types, 149–153
Optimization Toolbox (MATLAB), 200–208, 254
functions/solvers, 201e
Option-adjusted duration, 39, 374–375
computation, 619
Option-adjusted spread (OAS), 376, 617
Optionality, 715
risk, 416–417
Option for sequential investments, 710
Options, 480–484
contracts, risk-reward characteristics, 481
exercise, 562
holder, 480
intrinsic value, 494
payoffs, 509
expected value, 533
symmetric distributions, relationship, 640
premium, 480
price, 480
closed-form formula, 567–568
computation, crude Monte Carlo simulation
(usage), 532–536
pricing, 535–536
model, input, 505
theory model, basis, 610
time value, 494
usage, 635
value, 715
Black-Scholes formula, usage, 716e
computation, 500
writer, 480
Option to abandon, 709, 717–718
valuation, 719e
Option to choose, 709–710
Option to delay, 709
Option to expand, 709, 714–717
Option to switch, 710
Option to wait, valuation, 722–724
Oracle excess returns, 409
Ornstein-Uhlenbeck process, 438–439
Ito process, relationship, 452
Out-of-the-money option, 484, 494
deductibility, 629
Out-of-the-money paths, generation, 541
Output variables, 101
distribution
bar plot, 135e
histogram, 136e
Overlay strategy, 640
Overnight repo (overnight RP), 24
Over-the-counter (OTC) derivatives, 477
Over-the-counter (OTC) market, 477
Over-the-counter (OTC) options, 481
usage, 635
Overwrite strategy, 632
Parameters, 87
estimation, 103–104, 426–427
sampling distribution, 92
tolerance, 162–163

758
INDEX
Parametric models, usage, 222
Par swap, 486
Partial derivative, usage, 453
Par value, 18
Passive strategies, 324
Pass-through, cash ﬂow, 595
Pass-through certiﬁcate (beneﬁcial interest
certiﬁcate), 588
Pass-through RMBSs, 594
formula, 616
Pass-through security
average life, 596
cash ﬂow
example, 597e–598e
generation, 595–596
coupon rate, 595
Path dependency, 535
prepayments, relationship, 593
Path values, distribution, 617
Pathwise derivative estimates, 566, 583
Pathwise method, usage, 577
Payback period, 658, 666–668
analysis, break-even measure, 667
calculation, 666–667
Payer swaption, 569
Pay-ﬁxed swap position, asset manager
establishment, 635–636
Payoff period, 66–667
Pay-through certiﬁcates, 588
Pearson correlation, 88–89
Penalty coefﬁcient, 228
Pension funds, ERISA requirements (compliance),
325–326
Percentage price change, 435–436
convexity adjustment, 41–42
Percentiles, 68–69
Perfect hedge, 491–492
net proﬁt/loss, anticipation, 634
Perfect hedging, 495
Performance measurement, 324–325
Periodic coupon interest payments, 43
Periodic coupon payments, 18–19
Periodic interest payments, reinvestment income,
43
Physical deterioration, 655
Piecewise-linear approximations, complexity,
341
Piecewise-linear function, 340e
Piecewise-linear transaction costs, 339–341
Plain vanilla bonds
duration measures, impact, 619
Plain vanilla swap, 486
Planned amortization class (PAC) bonds, 600,
606
Poisson distribution, 71–72
example, 72e
MATLAB, usage, 98
time interval, relationship, 448
Poisson process, 448
Policy variable, 178
Policy vector, 213
Polynomial time, 170
Pool, 589
Population, 169
Portfolio
adjustment, 325
assets, marketability, 343–344
cash ﬂows, reinvestment, 389–390
constraints, 325–333
construction, 324
inputs, formulation, 324
derivatives, components, 640–647
duration, 374
calculation, 374–375
contribution, 375
expected return, 227
change, 248e
computation, 247
maximization, 146
pairings, possibility, 255e
interest rate risk, control, 633–637
losses
probability distribution, 300, 301e
scenario, 303–304
manager
problem, data, 154
protection buyer, 638–639
market value, 634
maturity, key rate duration, 43
monitoring, 324–325
optimization, 415
parameter, estimation, 351
performance measurement, 413
rebalancing, 337–338
resampling, 352–354
problems, 354
revaluation, approximation, 643–645
risk factor exposure, 414
risk-return characteristics, 254–255
selection, Markowitz theory, 246
sensitivity, 328
standard deviation, pairings (possibility), 255e
stocks, number (limitation), 361–364
strategy
development, 323–324
implementation, tasks (division), 323
value, 284
assumption, 646
equivalence, 497–498
probability distribution, 644
Value-at-Risk (VaR) estimation, 645–646
Value-at-Risk (VaR) optimization, 229, 310e
problem, 295
variance, 83, 258, 279
calculation, 247
usage, 277–278
Portfolio allocation, 153–157
evaluation, 114–115
implementation, example, 192–194, 196–199,
203–205
optimization problem, 326
performance, comparison, 267

Index
759
problem
optimization tool dialog box, 205e
Solver inputs, 193e
quantitative methods, usage, 387–388
Portfolio management, 1
derivatives, usage, 627
execution, 697–698
factor models, applications, 413–417
tax considerations, 344
Portfolio return, 145
expression, 247
time-series data, usage, 413
variance, 227
Portfolio risk, 227, 301
decomposition, 413
estimation, simulation (usage), 640–641
measurement, 640–647
proﬁle, 640
understanding, PCA (usage), 412
Portfolio risk measures
Excel/Palisade decision tools suite, usage,
308–313
MATLAB, usage, 314–318
software, advice, 308–318
theory, advances, 277
Portfolio weights
assets, combinations, 181
discovery, 353
optimization, 334–335
Positive homogeneity, 301
Positive theory, 246
Posterior distribution, 351
Postmodern NPV, 712–713
Postpayback duration, 667
Power utility function, 264
Predicted tracking error, 336–337
Preferred stock, representation, 17
Premium Solver, 168
Platform, 186–187
Prepayments, 591–594
conventions, 591–593
effects, 591
function models, 611
involuntary status, 611
models, 610–613
option pricing theory basis, 610
option, 591
path dependency, relationship, 593
pro rata allocation, 609
rates, calculation, 616
risk, 591
Present value (PV), 13–14
calculation, 28
future value, conversion, 14
Prices, 20
changes, computation, 440
closed-form expression, computation, 432
dynamics, 437
logarithm, consideration, 431
percentage change, 435
process, random walks (relationship), 437
Pricing options, 494–517
Primary market analysis, 387
Prime loans, 588
private-label RMBS classiﬁcation, 607
Principal component analysis (PCA), 407, 412
Principal-only class, 596
Principal-only mortgage strip, 596
Principal-only security (PO), 596, 599
price, increase, 599
Principle of Optimality (Bellman), 176
Private-label deals, 589
Private-label RMBSs (nonagency RMBSs), 588,
607–609
classiﬁcation, 607
CMOs, comparison, 594–595
Private-label transactions, 589
Probabilistic models, 211
Probability
calculation, 63e
denotation, 229
density, 543
distribution, 502, 641e
theory, 87–93
Probability density function (PDF), 57–61
discovery, 543
impact, 58–59
Probability distribution, 51, 87–93
center of gravity, 65
comparison, 66e
creation, 52
deﬁnition, 51–52
ﬁrst moment, 64
fourth moment, 69
input selection, 103–104
overview, 69–79
representatives, 61
second moment, 67
software, advice, 95–99
third moment, 69
usage, 688e, 690e
visualization, 109–110
Probability mass function (PMF), 52–53, 65
Probability-weighted discounted proﬁt, 216
Product market, competition degree, 655
Proﬁtability index (PI), 658, 661–662
criteria, 669
Proﬁt/loss (P/L) data distribution, 292e, 293e
Proﬁt/loss (P/L) form, 285–286
Proﬁt maximization, objective, 180
Project portfolio management (PPM), 697–698
Projects, 653–654
beneﬁts, costs/PV, 160e
capital cost, 661e
components, 676
cash ﬂows, 669e
relationship, 654
classical NPV, example, 718e
classiﬁcation, 656–657
dependence, 657–658
estimated cash ﬂows, present value, 720
examples, 670e

760
INDEX
Projects (Continued )
IRR, 669e
market risk, measurement, 674–678
MIRR, 669e
multiple IRRs, 664e
NPV, 669
IRRs, inclusion, 660e, 664e
payback period, 666–667
example, 667e
PI, 669e
portfolio management, 697–698
rejection, 679
risk
assessment, 679–680
evaluation, 672–680
risk-free return, 676
stand-alone risk
estimation, simulation (usage), 687–693
measurement, 678–679
terminal value, 665–666
concept, 665e
total risk, assessment, 678–679
value
evaluation techniques, 658
ﬂexibility, 726e
variability, 727e
value in perpetuity, 671e
Project to abandon, 719–722
Project to expand, 719–722
Proportional hazard model (Schwarz/Torous),
610
Prospectus prepayment curve (PPC), 607
Protection buyer, 486–487
Protection seller, 486–487
Protective put strategies, 628–630
example, 631e
proﬁtability, 629–630
Pseudorandom number generators, 122–124
types, 123
Public Securities Association (PSA) prepayment
benchmark, 591–593
100% PSA, 593, 594e
165% PSA, 594e
speeds, range, 607
Pure bond indexing strategy, 382–383
Pure interest rates, 33–34
Pure-play company, estimation, 677
Pure random samples, simulation (absence),
116
Put option, 480
implied volatility, 505–506
long, 484
number, determination, 630
purchase, 484
protective put, involvement, 629
sale, 484
short, 484
Putting the issue under credit watch, 23
p-value, 93, 408–409
estimation, 410
usage, 441
Quadratic constraint, 334
Quadratic objective function, optimal objective
function, 147e
Quadratic optimization problem formulation, 339
Quadratic programming (QP), 150, 151, 172
Quadratic transaction costs, 341–342
Quadratic utility function, 262–263
shape, 263
Quality risk, 416–417
Quantile-based risk measures, 282–283
Quarterly compounding, 12–13
Quasi-Monte Carol method, 531–532, 610
examples, 554–556
performance, example, 555e
usage, improvement, 549–550
Quasi-random method, 531–532
Quasi-random number sequences, 549–556, 610
Quasi-random sequences (low-discrepancy
sequences), 124–125
values generation, 125
Random error term, 423
Randomized search algorithms, 167–169
classes, 168
Random number generation, 118–128
truly random events, 121
Random number generator, deﬁning, 121–122
Random percentiles, selection method, 120–121
Random processes
assumptions, 533
simulation, 291
Random variables, 51, 213
central moments, 266
conditional expectation, 86
conditional probability, 86
covariance/correlation, 79–81
dependence, 79–81, 86
events mapping, 52
function, 108
generation, 554–555
determination, 114
Latin hypercube sample, 127e
monotonic functions, payoffs, 539
multiplication, 109
nonlinear function, expected value
(determination), 432–433
PDF, 60
range, 68
realization, 53, 423
simulation, 426
software, advice, 95–99
sums, 81–84
convolution, example, 85e
expectation, 83
values, 59, 89
variance, 66–67
Random walks, 422–423
correlation, 445–447
models, 444–450
simulation procedure, 450
noise, absence, 428

Index
761
Range, 68
Rank correlation, 88–89
Rate duration, 42–43
Rate of return, 25
Rating migration table, 23
Rating transition table, 23
Real estate
asset class, 15
index, binomial tree, 725e
Realized net capital gains, 343
Real options, 672, 707
analysis, standard, 708
examples, 718–727
ﬁnancial options, relationship, 710–712
software, advice, 731
types, 708, 709–710
valuation, 721e, 722e
ﬁnancial option pricing methods, application,
711–712
models, inputs (estimation), 727–730
Receiver swaption, 569
Recombining binomial tree, 173e
Recombining lattices, 174
Recombining trees, 174
Recovery rate, 378
Reﬁnancing, 591
conditions, 612–613
Reﬁnancing incentive (RI), 611–612
Regression
analysis, 407–410
input data, 561e
matrix, 563e
model, estimate, 559
response variable, 694
running, Excel (usage), 418
slope coefﬁcient, 468
standard error, 409
Regression-based technique, 558
Regression coefﬁcient, 406
determination, 560
display, 697
signiﬁcance, 410
Reinvestment risk, 43–44, 395
Relative value arbitrage, 488
Relative value strategies, 384
Replacement projects, 656
cash ﬂow risk, 656
Replicating portfolio, existence, 488
Repudiation, 487
Repurchase agreement (repo), 24
rate, 24
Repurchase date, 24
Repurchase price, 24
Required rate of return (RRR), 659
Required return, simplicity, 672
Required yield, 32
Resampling. See Portfolio
Research and development (R&D)
investment, 710, 714
projects, 159, 713–714
execution, 707
Residential mortgage-backed securities
(RMBSs)
accuracy (improvement), variance-reduction
methods (usage), 618
analysis, 617
average life, 617
cash ﬂow uncertainty, 591
credit risk, 619
interest rate risk, 618–619
model risk, 619–620
option-adjusted spread, 617
prepayments, 591–594
price sensitivity (estimation), simulation (usage),
618–620
pricing, 587, 618
overview, 615–617
simulation, usage, 609–618
structures
complexity, 616
types, 594–609
structuring, 587
dynamic programming, usage, 620–622
Residential mortgage loan
cash ﬂow characteristics, 590
prepayment rates, assumption, 592–593
Residual errors, N-dimensional vector, 415
Residual risk, 416
Residuals
assumptions, satisfaction, 409–410
autcorrelation, absence, 409
homoschedasticity, 409
normal distribution, 409
Response variables (dependent variables),
408–409, 694
linear regression, 440
Restructuring, occurrence, 487
Retained earnings, 16
Retroactive projects, 656–657
Return
assured rate, 389
attribution analysis, 325
calculation, 25
compounding, 25–26
distribution, 289
enhancement (speculation), 477–478
reference, 627
strategies, 632–633
expression, geometric (log) form, 26–27
factor, linear relationship, 407–408
internal rate, 658
numerical value, 27
rate, calculation, 25–28
required rate, 659
volatility, estimation, 729
Return/risk, optimal trade-off, 143
Revenue, binomial tree, 725e
Reverse ﬂoaters, 19
Reward, expected value, 213
Reward function, 212
Richard/Roll, modiﬁed Goldman Sachs model,
610, 611–613

762
INDEX
Right-skewed distribution (positively skewed
distribution), 69, 693–694
Risk
classiﬁcation, 655–657
closed-form measures, 640
compensation, 676
control, 634
degree, 658
elimination, goal, 477–478
equilibrium market price, 261
estimation models, 402
exposure, 375
management, 1–2, 477–478
strategies, 628–632
systems, VaR criticisms, 298
market price, 728–729
measures, 66–69, 297
classes, 278–283
minimization, 634–635
neutrality, 263
premium, 261
proﬁle, 256
@RISK, 4, 72
scenario simulation, 114
software, 95–96, 130–133
Risk-adjusted discount rate, usage, 679–680
Risk-adjusted excess returns, realization, 385
Risk-adjusted rate, 728
Risk arbitrage strategies, 491
Risk aversion
formulation, 256–257
mean-variance formulation, 257
Risk-based pricing, 589
Risk factor, 401
constraints, 327–329
models, 324
mathematics, 328
Risk-free asset, 257–260
return, 260
Risk-free bond, purchase, 629
Risk-free rate, 403, 685
constancy, 504
parameter replacement, 511
Riskless portfolio, setup, 496–497
RiskMetrics, 287
Risk-neutral investors, 264
Risk-neutral probabilities, 497–499
Risk neutral probability distribution, 507
Risk of loss, 282
RiskOptimizer (Palisade Decision Tools Suite), 187
Risk-return characteristics, 256
Risk-return trade-off, 112
risk determinant, 477
RiskSimtable command, 114
Risky assets, investment, 257–258
Risky future cash ﬂows, evaluation, 675
Risky portfolio construction, 260
Robust counterparts, 231–236
Robust optimization, 145, 231–238
formulations, value, 359
philosophy, 218
reference, 359
Robust parameter estimation, 350–351
Robust portfolio optimization, 354–360
Root-mean-squared-error (RMSE), 104
Ross, Stephen, 404
Round lots, 159
constraints, 331–333
Roy’s safety-ﬁrst criterion, 282
Russell 3000 (benchmark), 334
Saddle points, 166
Salomon Smith Barney Broad Investment-Grade
Bond Index (SSB BIG), 380–381
Sampling, 87–93
distribution, 92
Scenario analysis, 44
conducting, 678–679
example, 45e
Scenarios
generation, 673
impact, 226
number, 115–116
simulation, 114
method, 645
uncertainty, 51
Scenario trees
creation, 222
example, 223e
simpliﬁcation, 220e
Scheduled principal payment, 590
Schwarz/Torous, proportional hazard model, 610
Scores, 412
SDPT3, 235
Seasoning factor, 612
Second-order approximation, 40
Second-order cone problem (SOCP), 234–235
Second-order cone programming (SOCP), 150,
152, 172
constraint, 230
Securities
agency guaranty, absence, 589
beta, 403
certiﬁcates, 588
characteristic line, estimation, 403–404
discount factors, 34
purchase, funds (borrowing), 23–24
selection strategies, 387
Securities and Exchange Act of 1934, 24
Securitization, 17, 587
SeDuMi, 235
Semiannual yield, doubling, 31
Semideﬁnite programming (SDP), 150
Semiparametric bootstrap approaches, 291
Semivariance, 281–282
Senior notes, 587–588
Sensitivities
example, 696e
measurement, 515–517
Sensitivity analysis (performing), dual variables
(usage), 171
Separation, 260
Sequential-pay bonds, 600
Sequential-pay structure, example, 600e

Index
763
Servicing fee, 590, 595
Settlement price, 479
Sharpe, William, 402
Sharpe ratio, 259
Short call position, usage, 631
Shorter-term paper, depository institution interest,
606
Shortfall risk, 282
Short positions, 24–25
Short-term gains, 345
Short-term interest rate, one-factor model, 613
Short-term investment, 655
Short-term risk-free rate, 729
Short-term trading strategies, 384
Shrinkage, 350–351
Simple discrete distributions, generation, 222
Simple rate of return, 25
Simplex algorithm, 163–164
three-dimensional space, 164e
Simulated annealing, 168
Simulated data scenarios, usage, 289–291
Simulation, 3, 352, 426
application, examples, 556–570
default option, 539
dimension, 643
estimator, 545
inputs
determination, 693–697
distributions, 700e
model, complexity (increase), 534
modeling, 101
questions, 115–118
software advice, 129–140
output, 692e, 693e
variable, distribution (bar plot), 135e
procedure, 450
software, 101, 129–140
packages, commands (usage), 104
statistical sampling, comparison, 106–107
usage, 609, 618–620
reason, 107–115
Single-account optimization, 350
Single-index market model, 404
Single-monthly mortality rate (SMM), 592–593
monthly SMM, 594e
Single-name CDS, usage, 638
Single-period liability, immunization strategy,
389–395
Six-pack securities, 608
Skew, 69
Slack variables, 157
Small capitalization, company classiﬁcation, 15
SNOPT, 186
Sobol quasirandom sequences, construction,
579
Sobol sequences, 125
usage, 554
Solver (Excel), 157, 189–196
Add Constraint dialog box, 190
dialog box, 189e, 195e
inputs, 193e
Options dialog box, 191e
suboptimal solution, 195
usage, 270
Spearman correlation, 88–89
Specialized bond market indices, 381
Special purpose entity (SPE), 587–588
Speculation, 478
Spikes, 71
exhibition, 447–448
Splits, 609
Spot rates, 33
Spread, 66
duration, 40, 375–376
measures, 376
products, 375
risk, 375–376
S-shaped utility functions, 267
Stable Paretian distribution, 248, 250
Stand-alone risk, measurement, 678–679
Standard deviation, 66–67, 83
dispersion measure, 279
sample, 88
usage, 67
variance, relationship, 278–279
Standard error, 90
Standard normal distribution, 60e
Standard & Poor’s 500 (S&P500), 16
excess returns, 409
index
level, 422e
long position, ﬁnancing, 485
investing, 108–109
returns, 249e
sample, 92
usage, 403–404
values, 102–103
Standard & Poor’s bond rating system, 22e
State, optimal strategy/proﬁt, 217e
State space, 173
representation, 175e
State variable, 178
update, 183
Static spread, 376
Statistical arbitrage, 211
Statistical concepts, 51
software, advice, 95–99
Statistical factors, 401, 405
Statistical measurement, 87–93
Statistical sampling, simulation (comparison),
106–107
Statistical Toolbox (MATLAB), 411, 412
Step function, 61
Stochastic algorithms, 212
Stochastic control, 212
Stochastic differential equations, 456
Stochastic models, 211
Stochastic optimization problem
block formulation, 220
formulation, 222–223
Stochastic processes, 451–456, 613
discretization, 455
Stochastic processes in continuous time, 422–423,
451

764
INDEX
Stochastic programming, 145, 218–230
formulation, 218–219
methods, 211–212
Stochastic volatility, 450
Stock market returns, 110–111
Stock price, 711
correlation, 445–446
generation, stochastic process (usage), 504–505
logarithm, usage, 454
movements, 55
path number, simulation, 548
path simulation, 560e
simulation, usage, 562
strike price, contrast, 630
theoretical value (fair value), 28–29
Stock returns
covariance matrix, 334
idiosyncratic/nonsystematic component, 328
volatility
constancy, 504
estimation, 506
Stocks
dividends, 16
expected return, 29
strategy, comparison, 112e
threshold constraints, 330–331
value, movement, 54e
Straight-line utility function, 263
Strategic strategies, 384
Stratiﬁed sampling, 126–128, 539–540
alternative, 540–545
application, 540
approach, 388
example, 126
method, 536
Strike price, 480
payment, 711
stock price, contrast, 630
Stripped MBS, creation, 596
Stripped RMBSs, 594
Structured products, 587
Structuring bands, 606
Structuring speeds, 606
Student’s t-distribution, 72, 74–75
example, 75e
MATLAB, usage, 97–98
Subadditivity, 301
Subordinate notes, 587–588
Subordination
deal size percentage, 608e
levels, 609
Subprime loans, 588
private-label RMBS classiﬁcation, 607
Subprime MBSs, 589
Substitution swap, 387
Subtract-with-borrow (SWB) generator, 124
Summary statistics, 105
Support bonds, 600, 606
Swaps, 485–487
position, value, 517
premium payments, asset manager receipt,
637–638
pricing, 517–519
spread, 486
tenor, 486
usage, 635–637
value, 518–519
change, 636
Swaptions, 486, 569–570
pricing, 569–570
Symmetric distributions, 69
Systematic risk, decomposition, 416
Tactical strategies, 384
Taleb, Nassim, 297–298
Tangency portfolio, 258
Tax-aware portfolio allocation, interpretation,
344–345
Tax-aware portfolio rebalancing framework,
345–346
Taxes, 673
absence, 505
consideration, complexity, 344
usage, 343–346
Taylor series
expansion, 646
extension, expression, 453
usage, 266
t-distribution, 91
example, 75e
Temperature (T parameter), 168
Tenor, 486
Terminal price, 377
Terminal value, 665
Term repo (term RP), 24
Term structure, 33–34
risk, components, 416
Term to maturity, 18
Theta (), 516
Time decay, 516
Time horizon
speciﬁcation, 389
usage, 293–294
Time intervals, length (increase), 455
Time periods
price, closed-form expression, 452
usage, 424
Time premium, 494
Time series, 421
continuity, 422
monthly increments, 427
Tolerance (parameter), 162–163
Top-down value added strategies, 384
Tornado graphs
creation, 696, 703
example, 703e
types, 696–697
Total beneﬁt, computation, 161
Total cash ﬂow, calculation, 617
Total portfolio risk, decomposition, 414
Total probability, 59–60
Total return, 27–28, 43–46
measurement, 43–44
Total transaction costs, 349–350

Index
765
Tracking error (TE)
deﬁning, 333–334
methods, alternatives, 335–336
expression, 335–336
forward-looking estimates, 337
minimization, 333–337, 388
risk, increase, 388
standard deﬁnition, 333–334
types, constraints, 335
Traded ﬂat, 20
Trades
market impact, 347
optimization, 347–348
Trade size, piecewise-linear function, 340e
Trading at a discount, 18
Trading at a premium, 18
Trading constraints, 333
Trading cost models, combinations (usage),
342–343
Trading strategies, 298e
Trading terminology, 23–25
Traditional asset classes, 15–16
Tranches, 599
average life, 621
credit support/buffer, calculation, 621
size, measurement, 608e
Transaction costs
absence, 505
amount, linkage, 341
function, 342
incorporation, 337–343
mean-variance risk-aversion formulation, 338
models, 338
reduction, 639–640
Transaction size constraints, 330–331
Transfer entropies, 447
Translational invariance, 301
Treasuries, short-term hedging, 636
Treasury bill
rates, variability, 437
riskless security, 401
Treasury bond market returns, 110–111
Treasury bonds, CBOT trading, 635
Treasury Inﬂation Protection Securities (TIPS),
19
Treasury securities, swaps (advantages), 636–637
Treasury yield rates, weekly data, 438e
Trees, 422–423
Triangular distribution, 72, 74
example, 74e
MATLAB, usage, 97
Trinomial trees, dynamic programming technique
(application), 557–558
t-statistic, 406
Turnover, 349–350
constraints, 327
Twisted generalized feedback shift registers
(TGFSRs), 124
Two-factor models, 613
Two-period binomial tree, usage, 500e, 501e, 514e
Two-sample hypothesis tests, 93
Two-stage relations, series, 226
Type A arbitrage, 488
Type B arbitrage, 488
Uncertainty
capital budgeting, 653
optimization, 211
Uncertainty sets, 231–236
consideration, 232–233
shape, 235–236
worst-case scenario, 238
Unconstrained optimization, 144–145
Uncorrelated factors, 412
Underlying, 480
Unequal lives, 669–671
Uniform random number, generation, 119
Uniform random variables, simulated number
values, 125e
Unimodal distributions, 66
Upgrade, 23
Upward-sloping yield curve, 32e
U.S. bonds, separation, 15
U.S. common stocks, separation, 15
U.S. corporations, stock returns, 677
U.S. equities, 15
U.S. securities, foreign securities (separation), 15
U.S. Treasuries, default-free securities
consideration, 30–31
USD/Euro forward exchange rate, 478–479
Useful life, 655
Utility functions, 261
examples, 265e
Valuation, 28–33
Value added strategies, 384
Value-at-Risk (VaR), 5, 282–301
application, 297
arguments, 297–301
calculation
example, 292–293
historical/simulated data scenarios, usage,
289–291
zero-coupon bonds, involvement, 300e
computation, 284–285
P/L data, usage, 285e
criticisms, 297–298
estimation, 308–309, 545
MATLAB, usage, 314–316
normality, assumption, 289
history, 286–287
internal purposes, estimation, 294
optimization, 229, 295–297, 309–311
MATLAB, usage, 316–318
optimization problem
display, 296
Evolver dialog box, 311e
Excel solver setup, 310e
original calculation, 287
parameters, 293–295
regulatory requirements, 293–295
Value function, 178–179
estimation, 184
Values, hypothesized/observed signiﬁcance, 93

766
INDEX
Van der Corput quasirandom sequences,
construction, 575, 578
Van der Corput sequences, 550–551
construction, 551
generation, 125
multivariate extension, 551–552
Vanilla put option, 557
Variable-rate securities, 19
Variables (function), global/local minimum
(contrast), 148e
Variance, 66–67
adjustment, 432
computation, 247
expression, 67
minimization, 546–547
order, 454
sample, 88
standard deviation, relationship, 278–279
sum, 428
Variance inﬂation factors (VIFs), 410
Variance reduction method/technique, 531–532,
536–549, 610
usage, 618, 646–647
Variation, coefﬁcient, 68
Vasicek model, 439, 569, 613
usage, 614
Vector array, multiplication, 317
Vector autoregressive models, construction, 222
Vega (V), 516–517
Visual Basic for Applications (VBA), 4, 6
usage, 256
Volatility, 67, 729–730
changes, considerations, 435
estimates, 461, 465
expansion option, sensitivity value, 717e
estimation, 465, 467
irrelevance, 635
parameters, selection, 428
smile, 506e
Wall Street Journal, usage, 404
Wealth maximization, 658–672
Weatherstone, Dennis, 286–287
Weekly drift, estimates, 461, 465
Weighted average cost of capital (WACC),
677–678
computation, 678
usage, 728
Weighted average coupon (WAC)
function, CPR (relationship), 611
rate, 595
Weighted average life (WAL), 619
Weighted average maturity (WAM), 619
rate, 595
What-if analysis, 3
White noise, 425
Williams, John, 28
Working capital
asset collection, 654
investment, increase, 653–654
World Bank, 16
World bond indices, 381–382
Worst-case computation, 231
Worst case-expected portfolio return, 356
Worst-case performance, estimation, 169
Yahoo Finance, usage, 404
Yield
annualization, 31–32
change, 42
compounding, 31
shift, impact, 618–619
Yield curve
nonparallel shift, 385–386, 416
parallel shift, 37, 385, 416
risk, 375
risk exposure, 416
scenarios, generation, 643
strategies, 385–386
Yield to maturity (YTM), location, 31
Zero-coupon bonds, 18–19, 33
investment, 299
location, 34
price, closed-form expression (derivation),
614
Zero rates, 33
Zero-volatility spread, 376

Engaging and accessible, this book and its companion Web site provide an 
introduction to the simulation and optimization techniques most widely used in 
ﬁ nance, while, at the same time, offering essential information on the ﬁ nancial 
concepts surrounding these applications.
This practical guide is divided into ﬁ ve informative parts:
• Part I, Fundamental Concepts, provides insights on the most important 
issues in ﬁ nance, simulation, optimization, and optimization under uncertainty
• Part II, Portfolio Optimization and Risk Measures, reviews the theory 
and practice of equity and ﬁ xed income portfolio management, from classical 
frameworks to recent advances in the theory of risk measurement
• Part III, Asset Pricing Models, discusses classical static and dynamic models 
for asset pricing, such as factor models and different types of random walks
• Part IV, Derivative Pricing and Use, introduces important types of ﬁ nancial 
derivatives, shows how their value can be determined by simulation, and 
discusses how derivatives can be employed for portfolio risk management 
and return enhancement purposes
• Part V, Capital Budgeting Decisions, reviews capital budgeting decision 
models, including real options, and discusses applications of simulation and 
optimization in capital budgeting under uncertainty
Supplemented with models and code in both spreadsheet-based software (@RISK, 
Solver, and VBA) and mathematical modeling software (MATLAB), Simulation 
and Optimization in Finance is a well-rounded guide to a dynamic discipline.
SIMULATION AND 
OPTIMIZATION IN FINANCE 
+ Web Site

