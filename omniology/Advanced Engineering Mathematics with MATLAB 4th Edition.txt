
Dean G. Duffy
Advanced 
Engineering 
Mathematics  
FOURTH EDITION
with MATLAB

CRC Press
Taylor & Francis Group
6000 Broken Sound Parkway NW, Suite 300
Boca Raton, FL 33487-2742
© 2017 by Taylor & Francis Group, LLC
CRC Press is an imprint of Taylor & Francis Group, an Informa business
Printed on acid-free paper
Version Date: 20161121
International Standard Book Number-13: 978-1-4987-3964-1 (Hardback)
Library of Congress Cataloging‑in‑Publication Data
Names: Katzman, Steve (IT auditor)
Title: Operational assessment of IT / Steve Katzman.
Description: Boca Raton, FL : CRC Press, 2016. | Series: Internal audit and 
IT audit ; 4 | Includes bibliographical references and index.
Identifiers: LCCN 2015037136 | ISBN 9781498737685
Subjects: LCSH: Information technology--Management. | Information 
technology--Auditing. | Auditing, Internal.
Classification: LCC HD30.2 .K3857 2016 | DDC 004.068--dc23
LC record available at http://lccn.loc.gov/2015037136
Visit the Taylor & Francis Web site at
http://www.taylorandfrancis.com
and the CRC Press Web site at
http://www.crcpress.com

Contents
Introduction
xix
List of Deﬁnitions
xxiii
CLASSIC ENGINEERING MATHEMATICS
Chapter 1:
First-Order Ordinary
Diﬀerential Equations
1
1.1 Classiﬁcation of Diﬀerential Equations
1
1.2 Separation of Variables
4
1.3 Homogeneous Equations
16

viii
Advanced Engineering Mathematics with MATLAB
1.4 Exact Equations
17
1.5 Linear Equations
20
1.6 Graphical Solutions
31
1.7 Numerical Methods
34
Chapter 2:
Higher-Order Ordinary
Diﬀerential Equations
45
2.1 Homogeneous Linear Equations with Constant Coeﬃcients
49
2.2 Simple Harmonic Motion
57
2.3 Damped Harmonic Motion
61
2.4 Method of Undetermined Coeﬃcients
66
2.5 Forced Harmonic Motion
71
2.6 Variation of Parameters
78
2.7 Euler-Cauchy Equation
83
2.8 Phase Diagrams
87
2.9 Numerical Methods
91
Chapter 3:
Linear Algebra
97
3.1 Fundamentals of Linear Algebra
97
3.2 Determinants
104
3.3 Cramer’s Rule
108
3.4 Row Echelon Form and Gaussian Elimination
111
3.5 Eigenvalues and Eigenvectors
124
3.6 Systems of Linear Diﬀerential Equations
133
3.7 Matrix Exponential
139

Table of Contents
ix
Chapter 4:
Vector Calculus
145
4.1 Review
145
4.2 Divergence and Curl
152
4.3 Line Integrals
156
4.4 The Potential Function
161
4.5 Surface Integrals
162
4.6 Green’s Lemma
169
4.7 Stokes’ Theorem
173
4.8 Divergence Theorem
179
Chapter 5:
Fourier Series
187
5.1 Fourier Series
187
5.2 Properties of Fourier Series
198
5.3 Half-Range Expansions
206
5.4 Fourier Series with Phase Angles
211
5.5 Complex Fourier Series
213
5.6 The Use of Fourier Series in the Solution of Ordinary Diﬀerential Equations
217
5.7 Finite Fourier Series
225
Chapter 6:
The Sturm-Liouville
Problem
239
6.1 Eigenvalues and Eigenfunctions
239

x
Advanced Engineering Mathematics with MATLAB
6.2 Orthogonality of Eigenfunctions
249
6.3 Expansion in Series of Eigenfunctions
251
6.4 A Singular Sturm-Liouville Problem: Legendre’s Equation
256
6.5 Another Singular Sturm-Liouville Problem: Bessel’s Equation
271
6.6 Finite Element Method
289
1
4
0
1
Chapter 7:
The Wave Equation
297
7.1 The Vibrating String
297
7.2 Initial Conditions: Cauchy Problem
300
7.3 Separation of Variables
300
7.4 D’Alembert’s Formula
318
7.5 Numerical Solution of the Wave Equation
325
Chapter 8:
The Heat Equation
337
8.1 Derivation of the Heat Equation
337
8.2 Initial and Boundary Conditions
339
8.3 Separation of Variables
340
8.4 Numerical Solution of the Heat Equation
377
Chapter 9:
Laplace’s Equation
385
9.1 Derivation of Laplace’s Equation
385

Table of Contents
xi
9.2 Boundary Conditions
387
9.3 Separation of Variables
388
9.4 Poisson’s Equation on a Rectangle
425
9.5 Numerical Solution of Laplace’s Equation
428
9.6 Finite Element Solution of Laplace’s Equation
433
TRANSFORM METHODS
Chapter 10:
Complex Variables
441
10.1
Complex Numbers
441
10.2
Finding Roots
445
10.3
The Derivative in the Complex Plane: The Cauchy-Riemann Equations
448
10.4
Line Integrals
456
10.5
The Cauchy-Goursat Theorem
460
10.6
Cauchy’s Integral Formula
463
10.7
Taylor and Laurent Expansions and Singularities
466
10.8
Theory of Residues
472
10.9
Evaluation of Real Deﬁnite Integrals
477
10.10 Cauchy’s Principal Value Integral
485
10.11 Conformal Mapping
490
Chapter 11:
The Fourier Transform
509
11.1 Fourier Transforms
509
11.2 Fourier Transforms Containing the Delta Function
518
11.3 Properties of Fourier Transforms
520
11.4 Inversion of Fourier Transforms
532

xii
Advanced Engineering Mathematics with MATLAB
11.5 Convolution
544
11.6 The Solution of Ordinary Diﬀerential Equations by Fourier Transforms
547
11.7 The Solution of Laplace’s Equation on the Upper Half-Plane
549
11.8 The Solution of the Heat Equation
551
Chapter 12:
The Laplace Transform
559
12.1
Deﬁnition and Elementary Properties
559
12.2
The Heaviside Step and Dirac Delta Functions
563
12.3
Some Useful Theorems
571
12.4
The Laplace Transform of a Periodic Function
579
12.5
Inversion by Partial Fractions: Heaviside’s Expansion Theorem
581
12.6
Convolution
588
12.7
Integral Equations
592
12.8
Solution of Linear Diﬀerential Equations with Constant Coeﬃcients
597
12.9
Inversion by Contour Integration
613
12.10 The Solution of the Wave Equation
619
12.11 The Solution of the Heat Equation
637
12.12 The Superposition Integral and the Heat Equation
651
12.13 The Solution of Laplace’s Equation
662
Chapter 13:
The Z-Transform
667
13.1 The Relationship of the Z-Transform to the Laplace Transform
668
13.2 Some Useful Properties
674
13.3 Inverse Z-Transforms
681
13.4 Solution of Diﬀerence Equations
691
13.5 Stability of Discrete-Time Systems
697

Table of Contents
xiii
Chapter 14:
The Hilbert Transform
703
14.1 Deﬁnition
703
14.2 Some Useful Properties
713
14.3 Analytic Signals
718
14.4 Causality: The Kramers-Kronig Relationship
721
Chapter 15:
Green’s Functions
725
15.1 What Is a Green’s Function?
725
15.2 Ordinary Diﬀerential Equations
732
15.3 Joint Transform Method
752
15.4 Wave Equation
756
15.5 Heat Equation
766
15.6 Helmholtz’s Equation
775
15.7 Galerkin Methods
795
STOCHASTIC PROCESSES
Chapter 16:
Probability
803
16.1 Review of Set Theory
804
16.2 Classic Probability
805
16.3 Discrete Random Variables
817

xiv
Advanced Engineering Mathematics with MATLAB
16.4 Continuous Random Variables
822
16.5 Mean and Variance
828
16.6 Some Commonly Used Distributions
834
16.7 Joint Distributions
842
Chapter 17:
Random Processes
855
17.1 Fundamental Concepts
858
17.2 Power Spectrum
864
17.3 Two-State Markov Chains
867
17.4 Birth and Death Processes
874
17.5 Poisson Processes
886
Chapter 18:
Itˆo’s Stochastic Calculus
895
18.1 Random Diﬀerential Equations
896
18.2 Random Walk and Brownian Motion
905
18.3 Itˆo’s Stochastic Integral
916
18.4 Itˆo’s Lemma
920
18.5 Stochastic Diﬀerential Equations
928
18.6 Numerical Solution of Stochastic Diﬀerential Equations
936
Answers to the Odd-Numbered Problems
945
Index
971

Introduction
Today’s STEM (science, technology, engineering, and mathematics) student must mas-
ter vast quantities of applied mathematics.
This is why I wrote Advanced Engineering
Mathematics with MATLAB. Three assumptions underlie its structure: (1) All students
need a ﬁrm grasp of the traditional disciplines of ordinary and partial diﬀerential equa-
tions, vector calculus, and linear algebra. (2) The digital revolution will continue. Thus
the modern student must have a strong foundation in transform methods because they
provide the mathematical basis for electrical and communication studies. (3) The biologi-
cal revolution will become more mathematical and require an understanding of stochastic
(random) processes. Already, stochastic processes play an important role in ﬁnance, the
physical sciences, and engineering. These techniques will enjoy an explosive growth in the
biological sciences. For these reasons, an alternative title for this book could be Advanced
Engineering Mathematics for the Twenty-First Century.
This is my fourth attempt at realizing these goals. It continues the tradition of including
technology into the conventional topics of engineering mathematics. Of course, I took this
opportunity to correct misprints and include new examples, problems, and projects. I now
use the small rectangle ⊓⊔to separate the end of an example or theorem from the continuing
text. The two major changes are a section on conformal mapping (Section 10.11) and a
new chapter on stochastic calculus.
A major change is the reorganization of the order of the chapters. In line with my
goals I have subdivided the material into three groups: classic engineering mathematics,
transform methods, and stochastic processes. In its broadest form, there are two general
tracks:
Diﬀerential Equations Course: Most courses on diﬀerential equations cover three gen-
eral topics: fundamental techniques and concepts, Laplace transforms, and separation of
variable solutions to partial diﬀerential equations.
The course begins with ﬁrst- and higher-order ordinary diﬀerential equations, Chapters
1 and 2, respectively. After some introductory remarks, Chapter 1 devotes itself to present-
ing general methods for solving ﬁrst-order ordinary diﬀerential equations. These methods

include separation of variables, employing the properties of homogeneous, linear, and exact
diﬀerential equations, and ﬁnding and using integrating factors.
The reason most students study ordinary diﬀerential equations is for their use in ele-
mentary physics, chemistry, and engineering courses. Because these diﬀerential equations
contain constant coeﬃcients, we focus on how to solve them in Chapter 2, along with
a detailed analysis of the simple, damped, and forced harmonic oscillator. Furthermore,
we include the commonly employed techniques of undetermined coeﬃcients and variation
of parameters for ﬁnding particular solutions. Finally, the special equation of Euler and
Cauchy is included because of its use in solving partial diﬀerential equations in spherical
coordinates.
Some courses include techniques for solving systems of linear diﬀerential equations. A
chapter on linear algebra (Chapter 3) is included if that is a course objective.
After these introductory chapters, the course would next turn to Laplace transforms.
Laplace transforms are useful in solving nonhomogeneous diﬀerential equations where the
initial conditions have been speciﬁed and the forcing function “turns on and oﬀ.”
The
general properties are explored in Section 12.1 to Section 12.7; the actual solution technique
is presented in Section 12.8.
Most diﬀerential equations courses conclude with a taste of partial diﬀerential equa-
tions via the method of separation of variables. This topic usually begins with a quick
introduction to Fourier series, Sections 5.1 to 5.4, followed by separation of variables as
it applies to the heat (Sections 8.1–8.3), wave (Sections 7.1–7.3), or Laplace’s equations
(Sections 9.1–9.3). The exact equation that is studied depends upon the future needs of the
students.
Engineering Mathematics Course: This book can be used in a wide variety of engi-
neering mathematics classes. In all cases the student should have seen most of the material
in Chapters 1 and 2. There are at least four possible combinations:
•Option A: The course is a continuation of a calculus reform sequence where elementary
diﬀerential equations have been taught. This course begins with Laplace transforms and
separation of variables techniques for the heat, wave, and/or Laplace’s equations, as outlined
above. The course then concludes with either vector calculus or linear algebra. Vector
calculus is presented in Chapter 4 and focuses on the gradient operator as it applies to
line integrals, surface integrals, the divergence theorem, and Stokes’ theorem.
Chapter
3 presents linear algebra as a method for solving systems of linear equations and includes
such topics as matrices, determinants, Cramer’s rule, and the solution of systems of ordinary
diﬀerential equations via the classic eigenvalue problem.
•Option B: This is the traditional situation where the student has already studied diﬀeren-
tial equations in another course before he takes engineering mathematics. Here separation of
variables is retaught from the general viewpoint of eigenfunction expansions. Sections 9.1–
9.3 explain how any piece-wise continuous function can be reexpressed in an eigenfunction
expansion using eigenfunctions from the classic Sturm-Liouville problem. Furthermore, we
include two sections that focus on Bessel functions (Section 6.5) and Legendre polynomials
(Section 6.4). These eigenfunctions appear in the solution of partial diﬀerential equations
in cylindrical and spherical coordinates, respectively.
The course then covers linear algebra and vector calculus as given in Option A.
•Option C: I originally wrote this book for an engineering mathematics course given to
sophomore and junior communication, systems, and electrical engineering majors at the
U.S. Naval Academy. In this case, you would teach all of Chapter 10 with the possible

exception of Section 10.10 on Cauchy principal-value integrals. This material was added to
prepare the student for Hilbert transforms, Chapter 14.
Because most students come to this course with a good knowledge of diﬀerential equa-
tions, we begin with Fourier series, Chapter 5, and proceed through Chapter 14. Chapter 11
generalizes the Fourier series to aperiodic functions and introduces the Fourier transform.
This leads naturally to Laplace transforms, Chapter 12. Throughout these chapters, I make
use of complex variables in the treatment and inversion of the transforms.
With the rise of digital technology and its associated diﬀerence equations, a version
of the Laplace transform, the z-transform, was developed. Chapter 13 introduces the z-
transform by ﬁrst giving its deﬁnition and then developing some of its general properties.
We also illustrate how to compute the inverse by long division, partial fractions, and con-
tour integration. Finally, we use z-transforms to solve diﬀerence equations, especially with
respect to the stability of the system.
Finally, there is a chapter on the Hilbert transform. With the explosion of interest in
communications, today’s engineer must have a command of this transform. The Hilbert
transform is introduced in Section 14.1 and its properties are explored in Section 14.2.
Two important applications of Hilbert transforms are introduced in Sections 14.3 and 14.4,
namely the concept of analytic signals and the Kramers-Kronig relationship.
•Option D: Many engineering majors now require a course in probability and statistics
because of the increasing use of probabilistic concepts in engineering analysis. To incorpo-
rate this development into an engineering mathematics course we adopt a curriculum that
begins with Fourier transforms (minus inversion by complex variables) given in Chapter
11. The remaining portion involves the fundamental concepts of probability presented in
Chapter 16 and random processes in Chapter 17. Chapter 16 introduces the student to
the concepts of probability distributions, mean, and variance because these topics appear
so frequently in random processes. Chapter 17 explores common random processes such as
Poisson processes and birth and death. Of course, this course assumes a prior knowledge
of ordinary diﬀerential equations and Fourier series.
A unique aspect of this book appears in Chapter 18, which is devoted to stochastic
calculus. We start by exploring deterministic diﬀerential equations with a stochastic forcing.
Next, the important stochastic process of Brownian motion is developed in depth. Using this
Brownian motion, we introduce the concept of (Itˆo) stochastic integration, Itˆo’s lemma, and
stochastic diﬀerential equations. The chapter concludes with various numerical methods to
integrate stochastic diﬀerential equations.
In addition to the revisions of the text and topics covered in this new addition, MATLAB
is still employed to reinforce the concepts that are taught. Of course, this book still continues
my principle of including a wealth of examples from the scientiﬁc and engineering literature.
The answers to the odd problems are given in the back of the book, while worked solutions
to all of the problems are available from the publisher. Most of the MATLAB scripts may
be found at http://www.crcpress.com/product/isbn/9781439816240.

Function
Deﬁnition
δ(t −a)
=
 ∞,
t = a,
0,
t ̸= a,
Z ∞
−∞
δ(t −a) dt = 1
erf(x)
=
2
√π
Z x
0
e−y2 dy
Γ(x)
gamma function
H(t −a)
=
 1,
t > a,
0,
t < a.
H(1)
n (x), H(2)
n (x)
Hankel functions of ﬁrst and second kind and of order n
ℑ(z)
imaginary part of the complex variable z
In(x)
modiﬁed Bessel function of the ﬁrst kind and order n
Jn(x)
Bessel function of the ﬁrst kind and order n
Kn(x)
modiﬁed Bessel function of the second kind and order n
Pn(x)
Legendre polynomial of order n
ℜ(z)
real part of the complex variable z
sgn(t −a)
=
 −1,
t < a,
1,
t > a.
Yn(x)
Bessel function of the second kind and order n
Deﬁnitions

Chapter 1
First-Order Ordinary
Diﬀerential Equations
A diﬀerential equation is any equation that contains the derivatives or diﬀerentials of
one or more dependent variables with respect to one or more independent variables. Because
many of the known physical laws are expressed as diﬀerential equations, a sound knowledge
of how to solve them is essential. In the next two chapters we present the fundamental
methods for solving ordinary diﬀerential equations - a diﬀerential equation that contains
only ordinary derivatives of one or more dependent variables. Later, in Sections 11.6 and
12.8, we show how transform methods can be used to solve ordinary diﬀerential equations,
while systems of linear ordinary diﬀerential equations are treated in Section 3.6. Solutions
for partial diﬀerential equations—a diﬀerential equation involving partial derivatives of one
or more dependent variables of two or more independent variables—are given in Chapters
7, 8, and 9.
1.1 CLASSIFICATION OF DIFFERENTIAL EQUATIONS
Diﬀerential equations are classiﬁed three ways: by type, order, and linearity. There
are two types: ordinary and partial diﬀerential equations, which have already been deﬁned.
Examples of ordinary diﬀerential equations include
dy
dx −2y = x,
(1.1.1)
(x −y) dx + 4y dy = 0,
(1.1.2)
du
dx + dv
dx = 1 + 5x,
(1.1.3)
1

2
Advanced Engineering Mathematics with MATLAB
and
d2y
dx2 + 2dy
dx + y = sin(x).
(1.1.4)
On the other hand, examples of partial diﬀerential equations include
∂u
∂x + ∂u
∂y = 0,
(1.1.5)
y ∂u
∂x + x∂u
∂y = 2u,
(1.1.6)
and
∂2u
∂t2 + 2∂u
∂t = ∂2u
∂x2 .
(1.1.7)
In the examples that we have just given, we have explicitly written out the diﬀer-
entiation operation. However, from calculus we know that dy/dx can also be written y′.
Similarly the partial diﬀerentiation operator ∂4u/∂x2∂y2 is sometimes written uxxyy. We
will also use this notation from time to time.
The order of a diﬀerential equation is given by the highest-order derivative. For exam-
ple,
d3y
dx3 + 3d2y
dx2 +
dy
dx
2
−y = sin(x)
(1.1.8)
is a third-order ordinary diﬀerential equation. Because we can rewrite
(x + y) dy −x dx = 0
(1.1.9)
as
(x + y)dy
dx = x
(1.1.10)
by dividing Equation 1.1.9 by dx, we have a ﬁrst-order ordinary diﬀerential equation here.
Finally
∂4u
∂x2∂y2 = ∂2u
∂t2
(1.1.11)
is an example of a fourth-order partial diﬀerential equation. In general, we can write an
nth-order, ordinary diﬀerential equation as
f

x, y, dy
dx, · · · , dny
dxn

= 0.
(1.1.12)
The ﬁnal classiﬁcation is according to whether the diﬀerential equation is linear or
nonlinear. A diﬀerential equation is linear if it can be written in the form:
an(x)dny
dxn + an−1(x)dn−1y
dxn−1 + · · · + a1(x)dy
dx + a0(x)y = f(x).
(1.1.13)
Note that the linear diﬀerential equation, Equation 1.1.13, has two properties: (1) The
dependent variable y and all of its derivatives are of ﬁrst degree (the power of each term
involving y is 1). (2) Each coeﬃcient depends only on the independent variable x. Examples
of linear ﬁrst-, second-, and third-order ordinary diﬀerential equations are
(x + 1) dy −y dx = 0,
(1.1.14)

First-Order Ordinary Diﬀerential Equations
3
y′′ + 3y′ + 2y = ex,
(1.1.15)
and
xd3y
dx3 −(x2 + 1)dy
dx + y = sin(x),
(1.1.16)
respectively. If the diﬀerential equation is not linear, then it is nonlinear. Examples of
nonlinear ﬁrst-, second-, and third-order ordinary diﬀerential equations are
dy
dx + xy + y2 = x,
(1.1.17)
d2y
dx2 −
dy
dx
5
+ 2xy = sin(x),
(1.1.18)
and
yy′′′ + 2y = ex,
(1.1.19)
respectively.
At this point it is useful to highlight certain properties that all diﬀerential equations
have in common regardless of their type, order, and whether they are linear or not. First, it
is not obvious that just because we can write down a diﬀerential equation, a solution exists.
The existence of a solution to a class of diﬀerential equations constitutes an important aspect
of the theory of diﬀerential equations. Because we are interested in diﬀerential equations
that arise from applications, their solution should exist. In Section 1.2 we address this
question further.
Quite often a diﬀerential equation has the solution y = 0, a trivial solution.
For
example, if f(x) = 0 in Equation 1.1.13, a quick check shows that y = 0 is a solution.
Trivial solutions are generally of little value.
Another important question is how many solutions does a diﬀerential equation have?
In physical applications uniqueness is not important because, if we are lucky enough to
actually ﬁnd a solution, then its ties to a physical problem usually suggest uniqueness.
Nevertheless, the question of uniqueness is of considerable importance in the theory of
diﬀerential equations. Uniqueness should not be confused with the fact that many solutions
to ordinary diﬀerential equations contain arbitrary constants, much as indeﬁnite integrals
in integral calculus. A solution to a diﬀerential equation that has no arbitrary constants is
called a particular solution.
• Example 1.1.1
Consider the diﬀerential equation
dy
dx = x + 1,
y(1) = 2.
(1.1.20)
This condition y(1) = 2 is called an initial condition and the diﬀerential equation plus the
initial condition constitute an initial-value problem. Straightforward integration yields
y(x) =
Z
(x + 1) dx + C = 1
2x2 + x + C.
(1.1.21)
Equation 1.1.21 is the general solution to the diﬀerential equation, Equation 1.1.20, because
it is a solution to the diﬀerential equation for every choice of C. However, if we now satisfy

4
Advanced Engineering Mathematics with MATLAB
the initial condition y(1) = 2, we obtain a particular solution. This is done by substituting
the corresponding values of x and y into Equation 1.1.21, or
2 = 1
2(1)2 + 1 + C = 3
2 + C,
or
C = 1
2.
(1.1.22)
Therefore, the solution to the initial-value problem Equation 1.1.20 is the particular solution
y(x) = (x + 1)2/2.
(1.1.23)
⊓⊔
Finally, it must be admitted that most diﬀerential equations encountered in the “real”
world cannot be written down either explicitly or implicitly. For example, the simple diﬀer-
ential equation y′ = f(x) does not have an analytic solution unless you can integrate f(x).
This begs the question of why it is useful to learn analytic techniques for solving diﬀerential
equations that often fail us. The answer lies in the fact that diﬀerential equations that we
can solve share many of the same properties and characteristics of diﬀerential equations
which we can only solve numerically. Therefore, by working with and examining the dif-
ferential equations that we can solve exactly, we develop our intuition and understanding
about those that we can only solve numerically.
Problems
Find the order and state whether the following ordinary diﬀerential equations are linear or
nonlinear:
1. y′/y = x2 + x
2. y2y′ = x + 3
3. sin(y′) = 5y
4. y′′′ = y
5. y′′ = 3x2
6. (y3)′ = 1 −3y
7. y′′′ = y3
8. y′′ −4y′ + 5y = sin(x)
9. y′′ + xy = cos(y′′)
10. (2x + y) dx + (x −3y) dy = 0
11. (1 + x2)y′ = (1 + y)2
12. yy′′ = x(y2 + 1)
13. y′ + y + y2 = x + ex
14. y′′′ + cos(x)y′ + y = 0
15. x2y′′ + x1/2(y′)3 + y = ex
16. y′′′ + xy′′ + ey = x2
1.2 SEPARATION OF VARIABLES
The simplest method of solving a ﬁrst-order ordinary diﬀerential equation, if it works, is
separation of variables. It has the advantage of handling both linear and nonlinear problems,
especially autonomous equations.1 From integral calculus, we already met this technique
when we solved the ﬁrst-order diﬀerential equation
dy
dx = f(x).
(1.2.1)
1 An autonomous equation is a diﬀerential equation where the independent variable does not explicitly
appear in the equation, such as y′ = f(y).

First-Order Ordinary Diﬀerential Equations
5
By multiplying both sides of Equation 1.2.1 by dx, we obtain
dy = f(x) dx.
(1.2.2)
At this point we note that the left side of Equation 1.2.2 contains only y while the right
side is purely a function of x. Hence, we can integrate directly and ﬁnd that
y =
Z
f(x) dx + C.
(1.2.3)
For this technique to work, we must be able to rewrite the diﬀerential equation so that all
of the y dependence appears on one side of the equation while the x dependence is on the
other. Finally we must be able to carry out the integration on both sides of the equation.
One of the interesting aspects of our analysis is the appearance of the arbitrary constant
C in Equation 1.2.3.
To evaluate this constant we need more information.
The most
common method is to require that the dependent variable give a particular value for a
particular value of x. Because the independent variable x often denotes time, this condition
is usually called an initial condition, even in cases when the independent variable is not
time.
• Example 1.2.1
Let us solve the ordinary diﬀerential equation
dy
dx = ey
xy .
(1.2.4)
Because we can separate variables by rewriting Equation 1.2.4 as
ye−y dy = dx
x ,
(1.2.5)
its solution is simply
−ye−y −e−y = ln |x| + C
(1.2.6)
by direct integration.
⊓⊔
• Example 1.2.2
Let us solve
dy
dx + y = xexy,
(1.2.7)
subject to the initial condition y(0) = 1.
Multiplying Equation 1.2.7 by dx, we ﬁnd that
dy + y dx = xexy dx,
(1.2.8)
or
dy
y = (xex −1) dx.
(1.2.9)

6
Advanced Engineering Mathematics with MATLAB
A quick check shows that the left side of Equation 1.2.9 contains only the dependent variable
y while the right side depends solely on x and we have separated the variables onto one side
or the other. Finally, integrating both sides of this equation, we have
ln(y) = xex −ex −x + C.
(1.2.10)
Since y(0) = 1, C = 1 and
y(x) = exp[(x −1)ex + 1 −x] .
(1.2.11)
In addition to the tried-and-true method of solving ordinary diﬀerential equations by
hand, scientiﬁc computational packages such as MATLAB provide symbolic toolboxes that
are designed to do the work for you. In the present case, typing
dsolve(’Dy+y=x*exp(x)*y’,’y(0)=1’,’x’)
yields
ans =
1/exp(-1)*exp(-x+x*exp(x)-exp(x))
which is equivalent to Equation 1.2.11.
Our success here should not be overly generalized. Sometimes these toolboxes give
the answer in a rather obscure form or they fail completely. For example, in the previous
example, MATLAB gives the answer
ans =
-lambertw((log(x)+C1)*exp(-1))-1
The MATLAB function lambertw is Lambert’s W function, where w = lambertw(x) is the
solution to wew = x. Using this deﬁnition, we can construct the solution as expressed in
Equation 1.2.6.
⊓⊔
• Example 1.2.3
Consider the nonlinear diﬀerential equation
x2y′ + y2 = 0.
(1.2.12)
Separating variables, we ﬁnd that
−dy
y2 = dx
x2 ,
or
1
y = −1
x + C,
or
y =
x
Cx −1.
(1.2.13)
Equation 1.2.13 shows the wide variety of solutions possible for an ordinary diﬀerential
equation. For example, if we require that y(0) = 0, then there are inﬁnitely many diﬀerent
solutions satisfying this initial condition because C can take on any value. On the other
hand, if we require that y(0) = 1, there is no solution because we cannot choose any constant
C such that y(0) = 1. Finally, if we have the initial condition that y(1) = 2, then there is
only one possible solution corresponding to C = 3
2.
Consider now the trial solution y = 0. Does it satisfy Equation 1.2.12? Yes, it does.
On the other hand, there is no choice of C that yields this solution. The solution y = 0 is
called a singular solution to this equation. Singular solutions are solutions to a diﬀerential
equation that cannot be obtained from a solution with arbitrary constants.

First-Order Ordinary Diﬀerential Equations
7
−5
0
5
−1
−0.5
0
y
c = −2
−5
0
5
−5
0
5
c = 0
−5
0
5
0
0.5
1
x
y
c = 2
−5
0
5
0
0.2
0.4
x
c = 4
Figure 1.2.1: The solution to Equation 1.2.13 when C = −2, 0, 2, 4.
Finally, we illustrate Equation 1.2.13 using MATLAB. This is one of MATLAB’s strengths
— the ability to convert an abstract equation into a concrete picture. Here the MATLAB
script
clear
hold on
x = -5:0.5:5;
for c = -2:2:4
y = x ./ (c*x-1);
if (c== -2) subplot(2,2,1), plot(x,y,’*’)
axis tight; title(’c = -2’); ylabel(’y’,’Fontsize’,20); end
if (c== 0) subplot(2,2,2), plot(x,y,’^’)
axis tight; title(’c = 0’); end
if (c== 2) subplot(2,2,3), plot(x,y,’s’)
axis tight; title(’c = 2’); xlabel(’x’,’Fontsize’,20);
ylabel(’y’,’Fontsize’,20); end
if (c== 4) subplot(2,2,4), plot(x,y,’h’)
axis tight; title(’c = 4’); xlabel(’x’,’Fontsize’,20); end
end
yields Figure 1.2.1, which illustrates Equation 1.2.13 when C = −2, 0, 2, and 4.
⊓⊔
The previous example showed that ﬁrst-order ordinary diﬀerential equations may have a
unique solution, no solution, or many solutions. From a complete study2 of these equations,
we have the following theorem:
2 The proof of the existence and uniqueness of ﬁrst-order ordinary diﬀerential equations is beyond the
scope of this book.
See Ince, E. L., 1956: Ordinary Diﬀerential Equations.
Dover Publications, Inc.,
Chapter 3.

8
Advanced Engineering Mathematics with MATLAB
Theorem: Existence and Uniqueness
Suppose some real-valued function f(x, y) is continuous on some rectangle in the xy-
plane containing the point (a, b) in its interior. Then the initial-value problem
dy
dx = f(x, y),
y(a) = b,
(1.2.14)
has at least one solution on the same open interval I containing the point x = a. Further-
more, if the partial derivative ∂f/∂y is continuous on that rectangle, then the solution is
unique on some (perhaps smaller) open interval I0 containing the point x = a.
⊓⊔
• Example 1.2.4
Consider the initial-value problem y′ = 3y1/3/2 with y(0) = 1. Here f(x, y) = 3y1/3/2
and fy = y−2/3/2. Because fy is continuous over a small rectangle containing the point
(0, 1), there is a unique solution around x = 0, namely y = (x + 1)3/2, which satisﬁes the
diﬀerential equation and the initial condition. On the other hand, if the initial condition
reads y(0) = 0, then fy is not continuous on any rectangle containing the point (0, 0) and
there is no unique solution. For example, two solutions to this initial-value problem, valid
on any open interval that includes x = 0, are y1(x) = x3/2 and
y2(x) =

(x −1)3/2,
x ≥1,
0,
x < 1.
(1.2.15)
⊓⊔
• Example 1.2.5: Hydrostatic equation
Consider an atmosphere where its density varies only in the vertical direction. The
pressure at the surface equals the weight per unit horizontal area of all of the air from sea
level to outer space. As you move upward, the amount of air remaining above decreases
and so does the pressure. This is why we experience pressure sensations in our ears when
ascending or descending in an elevator or airplane. If we rise the small distance dz, there
must be a corresponding small decrease in the pressure, dp. This pressure drop must equal
the loss of weight in the column per unit area, −ρg dz. Therefore, the pressure is governed
by the diﬀerential equation
dp = −ρg dz,
(1.2.16)
commonly called the hydrostatic equation.
To solve Equation 1.2.16, we must express ρ in terms of pressure. For example, in
an isothermal atmosphere at constant temperature Ts, the ideal gas law gives p = ρRTs,
where R is the gas constant. Substituting this relationship into our diﬀerential equation
and separating variables yields
dp
p = −g
RTs
dz.
(1.2.17)
Integrating Equation 1.2.17 gives
p(z) = p(0) exp

−gz
RTs

.
(1.2.18)

First-Order Ordinary Diﬀerential Equations
9
Thus, the pressure (and density) of an isothermal atmosphere decreases exponentially with
height.
In particular, it decreases by e−1 over the distance RTs/g, the so-called “scale
height.”
⊓⊔
• Example 1.2.6: Terminal velocity
As an object moves through a ﬂuid, its viscosity resists the motion. Let us ﬁnd the
motion of a mass m as it falls toward the earth under the force of gravity when the drag
varies as the square of the velocity.
From Newton’s second law, the equation of motion is
mdv
dt = mg −CDv2,
(1.2.19)
where v denotes the velocity, g is the gravitational acceleration, and CD is the drag coeﬃ-
cient. We choose the coordinate system so that a downward velocity is positive.
Equation 1.2.19 can be solved using the technique of separation of variables if we change
from time t as the independent variable to the distance traveled x from the point of release.
This modiﬁcation yields the diﬀerential equation
mv dv
dx = mg −CDv2,
(1.2.20)
since v = dx/dt. Separating the variables leads to
v dv
1 −kv2/g = g dx,
(1.2.21)
or
ln

1 −kv2
g

= −2kx,
(1.2.22)
where k = CD/m and v = 0 for x = 0. Taking the inverse of the natural logarithm, we
ﬁnally obtain
v2(x) = g
k
 1 −e−2kx
.
(1.2.23)
Thus, as the distance that the object falls increases, so does the velocity, and it eventually
approaches a constant value
p
g/k, commonly known as the terminal velocity.
Because the drag coeﬃcient CD varies with the superﬁcial area of the object while
the mass depends on the volume, k increases as an object becomes smaller, resulting in a
smaller terminal velocity. Consequently, although a human being of normal size will acquire
a terminal velocity of approximately 120 mph, a mouse, on the other hand, can fall any
distance without injury.
⊓⊔
• Example 1.2.7: Interest rate
Consider a bank account that has been set up to pay out a constant rate of P dollars
per year for the purchase of a car. This account has the special feature that it pays an
annual interest rate of r on the current balance. We would like to know the balance in the
account at any time t.

10
Advanced Engineering Mathematics with MATLAB
Although ﬁnancial transactions occur at regularly spaced intervals, an excellent ap-
proximation can be obtained by treating the amount in the account x(t) as a continuous
function of time governed by the equation
x(t + ∆t) ≈x(t) + rx(t)∆t −P∆t,
(1.2.24)
where we have assumed that both the payment and interest are paid in time increments
of ∆t. As the time between payments tends to zero, we obtain the ﬁrst-order ordinary
diﬀerential equation
dx
dt = rx −P.
(1.2.25)
If we denote the initial deposit into this account by x(0), then at any subsequent time
x(t) = x(0)ert −P
 ert −1

/r.
(1.2.26)
Although we could compute x(t) as a function of P, r, and x(0), there are only three
separate cases that merit our close attention. If P/r > x(0), then the account will eventually
equal zero at rt = ln{P/ [P −rx(0)]}. On the other hand, if P/r < x(0), the amount
of money in the account will grow without bound. Finally, the case x(0) = P/r is the
equilibrium case where the amount of money paid out balances the growth of money due
to interest so that the account always has the balance of P/r.
⊓⊔
• Example 1.2.8: Steady-state ﬂow of heat
When the inner and outer walls of a body, for example the inner and outer walls
of a house, are maintained at diﬀerent constant temperatures, heat will ﬂow from the
warmer wall to the colder one. When each surface parallel to a wall has attained a constant
temperature, the ﬂow of heat has reached a steady state. In a steady-state ﬂow of heat,
each surface parallel to a wall, because its temperature is now constant, is referred to as an
isothermal surface. Isothermal surfaces at diﬀerent distances from an interior wall will have
diﬀerent temperatures. In many cases the temperature of an isothermal surface is only a
function of its distance x from the interior wall, and the rate of ﬂow of heat Q in a unit
time across such a surface is proportional both to the area A of the surface and to dT/dx,
where T is the temperature of the isothermal surface. Hence,
Q = −κAdT
dx ,
(1.2.27)
where κ is called the thermal conductivity of the material between the walls.
In place of a ﬂat wall, let us consider a hollow cylinder whose inner and outer surfaces
are located at r = r1 and r = r2, respectively. At steady state, Equation 1.2.27 becomes
Qr = −κAdT
dr = −κ(2πrL)dT
dr ,
(1.2.28)
assuming no heat generation within the cylindrical wall.
We can ﬁnd the temperature distribution inside the cylinder by solving Equation 1.2.28
along with the appropriate conditions on T(r) at r = r1 and r = r2 (the boundary con-
ditions). To illustrate the wide choice of possible boundary conditions, let us require that
inner surface is maintained at the temperature T1. We assume that along the outer surface

First-Order Ordinary Diﬀerential Equations
11
heat is lost by convection to the environment, which has the temperature T∞. This heat
loss is usually modeled by the equation
κ dT
dr

r=r2
= −h(T −T∞),
(1.2.29)
where h > 0 is the convective heat transfer coeﬃcient. Upon integrating Equation 1.2.28,
T(r) = −Qr
2πκL ln(r) + C,
(1.2.30)
where Qr is also an unknown. Substituting Equation 1.2.30 into the boundary conditions,
we obtain
T(r) = T1 +
Qr
2πκL ln(r1/r),
(1.2.31)
with
Qr =
2πκL(T1 −T∞)
κ/r2 + h ln(r2/r1).
(1.2.32)
As r2 increases, the ﬁrst term in the denominator of Equation 1.2.32 decreases while the
second term increases. Therefore, Qr has its largest magnitude when the denominator is
smallest, assuming a ﬁxed numerator. This occurs at the critical radius rcr = κ/h, where
Qmax
r
= 2πκL(T1 −T∞)
1 + ln(rcr/r1) .
(1.2.33)
⊓⊔
• Example 1.2.9: Population dynamics
Consider a population P(t) that can change only by a birth or death but not by immi-
gration or emigration. If B(t) and D(t) denote the number of births or deaths, respectively,
as a function of time t, the birth rate and death rate (in births or deaths per unit time) is
b(t) = lim
∆t→0
B(t + ∆t) −B(t)
P(t)∆t
= 1
P
dB
dt ,
(1.2.34)
and
d(t) = lim
∆t→0
D(t + ∆t) −D(t)
P(t)∆t
= 1
P
dD
dt .
(1.2.35)
Now,
P ′(t) = lim
∆t→0
P(t + ∆t) −P(t)
∆t
(1.2.36)
= lim
∆t→0
[B(t + ∆t) −B(t)] −[D(t + ∆t) −D(t)]
∆t
(1.2.37)
= B′(t) −D′(t).
(1.2.38)
Therefore,
P ′(t) = [b(t) −d(t)]P(t).
(1.2.39)

12
Advanced Engineering Mathematics with MATLAB
When the birth and death rates are constants, namely b and d, respectively, the pop-
ulation evolves according to
P(t) = P(0) exp
 b −d

t

.
(1.2.40)
⊓⊔
• Example 1.2.10: Logistic equation
The study of population dynamics yields an important class of ﬁrst-order, nonlinear,
ordinary diﬀerential equations: the logistic equation. This equation arose in Pierre Fran¸cois
Verhulst’s (1804–1849) study of animal populations.3 If x(t) denotes the number of species
in the population and k is the (constant) environment capacity (the number of species that
can simultaneously live in the geographical region), then the logistic or Verhulst’s equation
is
x′ = ax(k −x)/k,
(1.2.41)
where a is the population growth rate for a small number of species.
To solve Equation 1.2.41, we rewrite it as
dx
(1 −x/k)x = dx
x +
x/k
1 −x/k dx = r dt.
(1.2.42)
Integration yields
ln |x| −ln |1 −x/k| = rt + ln(C),
(1.2.43)
or
x
1 −x/k = Cert.
(1.2.44)
If x(0) = x0,
x(t) =
kx0
x0 + (k −x0)e−rt .
(1.2.45)
As t →∞, x(t) →k, the asymptotically stable solution.
⊓⊔
• Example 1.2.11: Chemical reactions
Chemical reactions are often governed by ﬁrst-order ordinary diﬀerential equations.
For example, ﬁrst-order reactions, which describe reactions of the form A
k→B, yield the
diﬀerential equation
−1
a
d[A]
dt
= k[A],
(1.2.46)
where k is the rate at which the reaction is taking place. Because for every molecule of A
that disappears one molecule of B is produced, a = 1 and Equation 1.2.46 becomes
−d[A]
dt
= k[A].
(1.2.47)
3 Verhulst, P. F., 1838: Notice sur la loi que la population suit dans son accroissement. Correspond.
Math. Phys., 10, 113–121.

First-Order Ordinary Diﬀerential Equations
13
Integration of Equation 1.2.47 leads to
−
Z d[A]
[A] = k
Z
dt.
(1.2.48)
If we denote the initial value of [A] by [A]0, then integration yields
−ln [A] = kt −ln [A]0,
(1.2.49)
or
[A] = [A]0e−kt.
(1.2.50)
The exponential form of the solution suggests that there is a time constant τ, which is called
the decay time of the reaction. This quantity gives the time required for the concentration
of decrease by 1/e of its initial value [A]0. It is given by τ = 1/k.
Turning to second-order reactions, there are two cases. The ﬁrst is a reaction between
two identical species: A + A
k→products. The rate expression here is
−1
2
d[A]
dt
= k[A]2.
(1.2.51)
The second case is an overall second-order reaction between two unlike species, given by A
+ B
k→X. In this case, the reaction is ﬁrst order in each of the reactants A and B and the
rate expression is
−d[A]
dt
= k[A][B].
(1.2.52)
Turning to Equation 1.2.51 ﬁrst, we have by separation of variables
−
Z [A]
[A]0
d[A]
[A]2 = 2k
Z t
0
dτ,
(1.2.53)
or
1
[A] =
1
[A]0
+ 2kt.
(1.2.54)
Therefore, a plot of the inverse of A versus time will yield a straight line with slope equal
to 2k and intercept 1/[A]0.
With regard to Equation 1.2.52, because an increase in X must be at the expense
of A and B, it is useful to express the rate equation in terms of the concentration of X,
[X] = [A]0 −[A] = [B]0 −[B], where [A]0 and [B]0 are the initial concentrations. Then, this
equation becomes
d[X]
dt
= k ([A]0 −[X]) ([B]0 −[X]) .
(1.2.55)
Separation of variables leads to
Z [X]
[X]0
dξ
([A]0 −ξ) ([B]0 −ξ) = k
Z t
0
dτ.
(1.2.56)
To integrate the left side, we rewrite the integral
Z
dξ
([A]0 −ξ) ([B]0 −ξ) =
Z
dξ
([A]0 −[B]0) ([B]0 −ξ)−
Z
dξ
([A]0 −[B]0) ([A]0 −ξ). (1.2.57)

14
Advanced Engineering Mathematics with MATLAB
Carrying out the integration,
1
[A]0 −[B]0
ln
[B]0[A]
[A]0[B]

= kt.
(1.2.58)
Again the reaction rate constant k can be found by plotting the data in the form of the left
side of Equation 1.2.58 against t.
Problems
For Problems 1–10, solve the following ordinary diﬀerential equations by separation of
variables. Then use MATLAB to plot your solution. Try and ﬁnd the symbolic solution
using MATLAB’s dsolve.
1. dy
dx = xey
2. (1 + y2) dx −(1 + x2) dy = 0
3. ln(x)dx
dy = xy
4. y2
x
dy
dx = 1 + x2
5. dy
dx = 2x + xy2
y + x2y
6. dy
dx = (xy)1/3
7. dy
dx = ex+y
8. dy
dx = (x3 + 5)(y2 + 1)
9. Solve the initial-value problem
dy
dt = −ay + b
y2 ,
y(0) = y0,
where a and b are constants.
10. Setting u = y −x, solve the ﬁrst-order ordinary diﬀerential equation
dy
dx = y −x
x2
+ 1.
11. Using the hydrostatic equation, show that the pressure within an atmosphere where
the temperature decreases uniformly with height, T(z) = T0 −Γz, varies as
p(z) = p0
T0 −Γz
T0
g/(RΓ)
,
where p0 is the pressure at z = 0.
12. Using the hydrostatic equation, show that the pressure within an atmosphere with the
temperature distribution
T(z) =

T0 −Γz,
0 ≤z ≤H,
T0 −ΓH,
H ≤z,

First-Order Ordinary Diﬀerential Equations
15
is
p(z) = p0









T0 −Γz
T0
g/(RΓ)
,
0 ≤z ≤H,
T0 −ΓH
T0
g/(RΓ)
exp

−
g(z −H)
R(T0 −ΓH)

,
H ≤z,
where p0 is the pressure at z = 0.
13.
The voltage V as a function of time t within an electrical circuit4 consisting of a
capacitor with capacitance C and a diode in series is governed by the ﬁrst-order ordinary
diﬀerential equation
C dV
dt + V
R + V 2
S = 0,
where R and S are positive constants. If the circuit initially has a voltage V0 at t = 0, ﬁnd
the voltage at subsequent times.
14. A glow plug is an electrical element inside a reaction chamber, which either ignites the
nearby fuel or warms the air in the chamber so that the ignition will occur more quickly.
An accurate prediction of the wire’s temperature is important in the design of the chamber.
Assuming that heat convection and conduction are not important,5 the temperature T
of the wire is governed by
AdT
dt + B(T 4 −T 4
a ) = P,
where A equals the speciﬁc heat of the wire times its mass, B equals the product of the
emissivity of the surrounding ﬂuid times the wire’s surface area times the Stefan-Boltzmann
constant, Ta is the temperature of the surrounding ﬂuid, and P is the power input. The
temperature increases due to electrical resistance and is reduced by radiation to the sur-
rounding ﬂuid.
Show that the temperature is given by
4Bγ3t
A
= 2

tan−1
T
γ

−tan−1
T0
γ

−ln
(T −γ)(T0 + γ)
(T + γ)(T0 −γ)

,
where γ4 = P/B + T 4
a and T0 is the initial temperature of the wire.
15. Let us denote the number of tumor cells by N(t). Then a widely used deterministic
tumor growth law6 is
dN
dt = bN ln(K/N),
where K is the largest tumor size and 1/b is the length of time required for the speciﬁc
growth to decrease by 1/e. If the initial value of N(t) is N(0), ﬁnd N(t) at any subsequent
time t.
4 See Aiken, C. B., 1938: Theory of the diode voltmeter. Proc. IRE, 26, 859–876.
5 See Clark, S. K., 1956: Heat-up time of wire glow plugs. Jet Propulsion, 26, 278–279.
6 See Hanson, F. B., and C. Tier, 1982: A stochastic model of tumor growth. Math. Biosci., 61, 73–100.

16
Advanced Engineering Mathematics with MATLAB
16. The drop in laser intensity in the direction of propagation x due to one- and two-photon
absorption in photosensitive glass is governed7 by
dI
dx = −αI −βI2,
where I is the laser intensity, α and β are the single-photon and two-photon coeﬃcients,
respectively. Show that the laser intensity distribution is
I(x) =
αI(0)e−αx
α + βI(0) (1 −e−αx),
where I(0) is the laser intensity at the entry point of the media, x = 0.
17. The third-order reaction A + B + C
k→X is governed by the kinetics equation
d[X]
dt
= k ([A]0 −[X]) ([B]0 −[X]) ([C]0 −[X]) ,
where [A]0, [B]0, and [C]0 denote the initial concentration of A, B, and C, respectively. Find
how [X] varies with time t.
18. The reversible reaction A
k1
−→
←−
k2
B is described by the kinetics equation8
d[X]
dt
= k1 ([A]0 −[X]) −k2 ([B]0 + [X]) ,
where [X] denotes the increase in the concentration of B while [A]0 and [B]0 are the initial
concentrations of A and B, respectively. Find [X] as a function of time t. Hint: Show that
this diﬀerential equation can be written
d[X]
dt
= (k1 −k2) (α + [X]) ,
α = k1[A]0 −k2[B]0
k1 + k2
.
1.3 HOMOGENEOUS EQUATIONS
A homogeneous ordinary diﬀerential equation is a diﬀerential equation of the form
M(x, y) dx + N(x, y) dy = 0,
(1.3.1)
where both M(x, y) and N(x, y) are homogeneous functions of the same degree n. That
means: M(tx, ty) = tnM(x, y) and N(tx, ty) = tnN(x, y).
For example, the ordinary
diﬀerential equation
(x2 + y2) dx + (x2 −xy) dy = 0
(1.3.2)
7 See Weitzman, P. S., and U. ¨Osterberg, 1996:
Two-photon absorption and photoconductivity in
photosensitive glasses. J. Appl. Phys., 79, 8648–8655.
8 See K¨uster, F. W., 1895: Ueber den Verlauf einer umkehrbaren Reaktion erster Ordnung in homogenem
System. Z. Physik. Chem., 18, 171–179.

First-Order Ordinary Diﬀerential Equations
17
is a homogeneous equation because both coeﬃcients are homogeneous functions of degree
2:
M(tx, ty) = t2x2 + t2y2 = t2(x2 + y2) = t2M(x, y),
(1.3.3)
and
N(tx, ty) = t2x2 −t2xy = t2(x2 −xy) = t2N(x, y).
(1.3.4)
Why is it useful to recognize homogeneous ordinary diﬀerential equations? Let us set
y = ux so that Equation 1.3.2 becomes
(x2 + u2x2) dx + (x2 −ux2)(u dx + x du) = 0.
(1.3.5)
Then,
x2(1 + u) dx + x3(1 −u) du = 0,
(1.3.6)
1 −u
1 + u du + dx
x = 0,
(1.3.7)
or

−1 +
2
1 + u

du + dx
x = 0.
(1.3.8)
Integrating Equation 1.3.8,
−u + 2 ln|1 + u| + ln|x| = ln|c|,
(1.3.9)
−y
x + 2 ln
1 + y
x
 + ln|x| = ln|c|,
(1.3.10)
ln
(x + y)2
cx

= y
x,
(1.3.11)
or
(x + y)2 = cxey/x.
(1.3.12)
Problems
First show that the following diﬀerential equations are homogeneous and then ﬁnd their
solution. Then use MATLAB to plot your solution. Try and ﬁnd the symbolic solution using
MATLAB’s dsolve.
1. (x + y)dy
dx = y
2. (x + y)dy
dx = x −y
3. 2xy dy
dx = −(x2 + y2)
4. x(x + y)dy
dx = y(x −y)
5. xy′ = y + 2√xy
6. xy′ = y −
p
x2 + y2
7. y′ = sec(y/x) + y/x
8. y′ = ey/x + y/x.
1.4 EXACT EQUATIONS
Consider the multivariable function z = f(x, y). Then the total derivative is
dz = ∂f
∂x dx + ∂f
∂y dy = M(x, y) dx + N(x, y) dy.
(1.4.1)

18
Advanced Engineering Mathematics with MATLAB
If the solution to a ﬁrst-order ordinary diﬀerential equation can be written as f(x, y) = c,
then the corresponding diﬀerential equation is
M(x, y) dx + N(x, y) dy = 0.
(1.4.2)
How do we know if we have an exact equation, Equation 1.4.2?
From the deﬁnition of
M(x, y) and N(x, y),
∂M
∂y = ∂2f
∂y∂x = ∂2f
∂x∂y = ∂N
∂x ,
(1.4.3)
if M(x, y) and N(x, y) and their ﬁrst-order partial derivatives are continuous. Consequently,
if we can show that our ordinary diﬀerential equation is exact, we can integrate
∂f
∂x = M(x, y)
and
∂f
∂y = N(x, y)
(1.4.4)
to ﬁnd the solution f(x, y) = c.
• Example 1.4.1
Let us check and see if
[y2 cos(x) −3x2y −2x] dx + [2y sin(x) −x3 + ln(y)] dy = 0
(1.4.5)
is exact.
Since M(x, y) = y2 cos(x) −3x2y −2x, and N(x, y) = 2y sin(x) −x3 + ln(y), we ﬁnd
that
∂M
∂y = 2y cos(x) −3x2,
(1.4.6)
and
∂N
∂x = 2y cos(x) −3x2.
(1.4.7)
Because Nx = My, Equation 1.4.5 is an exact equation.
⊓⊔
• Example 1.4.2
Because Equation 1.4.5 is an exact equation, let us ﬁnd its solution. Starting with
∂f
∂x = M(x, y) = y2 cos(x) −3x2y −2x,
(1.4.8)
direct integration gives
f(x, y) = y2 sin(x) −x3y −x2 + g(y).
(1.4.9)
Substituting Equation 1.4.9 into the equation fy = N, we obtain
∂f
∂y = 2y sin(x) −x3 + g′(y) = 2y sin(x) −x3 + ln(y).
(1.4.10)
Thus, g′(y) = ln(y), or g(y) = y ln(y) −y + C. Therefore, the solution to the ordinary
diﬀerential equation, Equation 1.4.5, is
y2 sin(x) −x3y −x2 + y ln(y) −y = c.
(1.4.11)

First-Order Ordinary Diﬀerential Equations
19
⊓⊔
• Example 1.4.3
Consider the diﬀerential equation
(x + y) dx + x ln(x) dy = 0
(1.4.12)
on the interval (0, ∞). A quick check shows that Equation 1.4.12 is not exact since
∂M
∂y = 1,
and
∂N
∂x = 1 + ln(x).
(1.4.13)
However, if we multiply Equation 1.4.12 by 1/x so that it becomes

1 + y
x

dx + ln(x) dy = 0,
(1.4.14)
then this modiﬁed diﬀerential equation is exact because
∂M
∂y = 1
x,
and
∂N
∂x = 1
x.
(1.4.15)
Therefore, the solution to Equation 1.4.12 is
x + y ln(x) = C.
(1.4.16)
This mysterious function that converts an inexact diﬀerential equation into an exact one
is called an integrating factor. Unfortunately there is no general rule for ﬁnding one unless
the equation is linear.
Problems
Show that the following equations are exact. Then solve them, using MATLAB to plot them.
Finally, try and ﬁnd the symbolic solution using MATLAB’s dsolve.
1. 2xyy′ = x2 −y2
2. (x + y)y′ + y = x
3. (y2 −1) dx + [2xy −sin(y)] dy = 0
4. [sin(y) −2xy + x2] dx
+[x cos(y) −x2] dy = 0
5. −y dx/x2 + (1/x + 1/y) dy = 0
6. (3x2 −6xy) dx −(3x2 + 2y) dy = 0
7. y sin(xy) dx + x sin(xy) dy = 0
8. (2xy2 + 3x2) dx + 2x2y dy = 0
9. (2xy3 + 5x4y) dx
10. (x3 + y/x) dx + [y2 + ln(x)] dy = 0
+(3x2y2 + x5 + 1) dy = 0
11. [x + e−y + x ln(y)] dy
12. cos(4y2) dx −8xy sin(4y2) dy = 0
+[y ln(y) + ex] dx = 0
13. sin2(x + y) dx −cos2(x + y) dy = 0

20
Advanced Engineering Mathematics with MATLAB
14. Show that the integrating factor for (x −y)y′ + αy(1 −y) = 0 is µ(y) = ya/(1 −y)a+2,
a + 1 = 1/α. Then show that the solution is
αx
ya+1
(1 −y)a+1 −
Z y
0
ξa+1
(1 −ξ)a+2 dξ = C.
1.5 LINEAR EQUATIONS
In the case of ﬁrst-order ordinary diﬀerential equations, any diﬀerential equation of the
form
a1(x)dy
dx + a0(x)y = f(x)
(1.5.1)
is said to be linear.
Consider now the linear ordinary diﬀerential equation
xdy
dx −4y = x6ex
(1.5.2)
or
dy
dx −4
xy = x5ex.
(1.5.3)
Let us now multiply Equation 1.5.3 by x−4. (How we knew that it should be x−4 and not
something else will be addressed shortly.) This magical factor is called an integrating factor
because Equation 1.5.3 can be rewritten
1
x4
dy
dx −4
x5 y = xex,
(1.5.4)
or
d
dx
 y
x4

= xex.
(1.5.5)
Thus, our introduction of the integrating factor x−4 allows us to use the diﬀerentiation
product rule in reverse and collapse the right side of Equation 1.5.4 into a single x derivative
of a function of x times y. If we had selected the incorrect integrating factor, the right side
would not have collapsed into this useful form.
With Equation 1.5.5, we may integrate both sides and ﬁnd that
y
x4 =
Z
xex dx + C,
(1.5.6)
or
y
x4 = (x −1)ex + C,
(1.5.7)
or
y = x4(x −1)ex + Cx4.
(1.5.8)
From this example, it is clear that ﬁnding the integrating factor is crucial to solving
ﬁrst-order, linear, ordinary diﬀerential equations. To do this, let us ﬁrst rewrite Equation
1.5.1 by dividing through by a1(x) so that it becomes
dy
dx + P(x)y = Q(x),
(1.5.9)

First-Order Ordinary Diﬀerential Equations
21
or
dy + [P(x)y −Q(x)] dx = 0.
(1.5.10)
If we denote the integrating factor by µ(x), then
µ(x)dy + µ(x)[P(x)y −Q(x)] dx = 0.
(1.5.11)
Clearly, we can solve Equation 1.5.11 by direct integration if it is an exact equation. If this
is true, then
∂µ
∂x = ∂
∂y {µ(x)[P(x)y −Q(x)]} ,
(1.5.12)
or
dµ
dx = µ(x)P(x),
and
dµ
µ = P(x) dx.
(1.5.13)
Integrating Equation 1.5.13,
µ(x) = exp
 Z x
P(ξ) dξ

.
(1.5.14)
Note that we do not need a constant of integration in Equation 1.5.14 because Equation
1.5.11 is unaﬀected by a constant multiple. It is also interesting that the integrating factor
only depends on P(x) and not Q(x).
We can summarize our ﬁndings in the following theorem.
Theorem: Linear First-Order Equation
If the functions P(x) and Q(x) are continuous on the open interval I containing the
point x0, then the initial-value problem
dy
dx + P(x)y = Q(x),
y(x0) = y0,
has a unique solution y(x) on I, given by
y(x) =
C
µ(x) +
1
µ(x)
Z x
Q(ξ)µ(ξ) dξ
with an appropriate value of C, and µ(x) is deﬁned by Equation 1.5.14.
⊓⊔
The procedure for implementing this theorem is as follows:
• Step 1: If necessary, divide the diﬀerential equation by the coeﬃcient of dy/dx. This
gives an equation of the form Equation 1.5.9 and we can ﬁnd P(x) by inspection.
• Step 2: Find the integrating factor by Equation 1.5.14.
• Step 3: Multiply the equation created in Step 1 by the integrating factor.
• Step 4: Run the derivative product rule in reverse, collapsing the left side of the
diﬀerential equation into the form d[µ(x)y]/dx. If you are unable to do this, you have
made a mistake.

22
Advanced Engineering Mathematics with MATLAB
• Step 5: Integrate both sides of the diﬀerential equation to ﬁnd the solution.
The following examples illustrate the technique.
• Example 1.5.1
Let us solve the linear, ﬁrst-order ordinary diﬀerential equation
xy′ −y = 4x ln(x).
(1.5.15)
We begin by dividing through by x to convert Equation 1.5.15 into its canonical form.
This yields
y′ −1
xy = 4 ln(x).
(1.5.16)
From Equation 1.5.16, we see that P(x) = 1/x. Consequently, from Equation 1.5.14, we
have that
µ(x) = exp
 Z x
P(ξ) dξ

= exp

−
Z x dξ
ξ

= 1
x.
(1.5.17)
Multiplying Equation 1.5.16 by the integrating factor, we ﬁnd that
y′
x −y
x2 = 4 ln(x)
x
,
(1.5.18)
or
d
dx
y
x

= 4 ln(x)
x
.
(1.5.19)
Integrating both sides of Equation 1.5.19,
y
x = 4
Z ln(x)
x
dx = 2 ln2(x) + C.
(1.5.20)
Multiplying Equation 1.5.20 through by x yields the general solution
y = 2x ln2(x) + Cx.
(1.5.21)
Although it is nice to have a closed-form solution, considerable insight can be gained
by graphing the solution for a wide variety of initial conditions. To illustrate this, consider
the MATLAB script
clear
% use symbolic toolbox to solve Equation 1.5.15
y = dsolve(’x*Dy-y=4*x*log(x)’,’y(1) = c’,’x’);
% take the symbolic version of the solution
%
and convert it into executable code
solution = inline(vectorize(y),’x’,’c’);
close all; axes; hold on
% now plot the solution for a wide variety of initial conditions
x = 0.1:0.1:2;
for c = -2:4
if (c==-2) plot(x,solution(x,c),’.’); end
if (c==-1) plot(x,solution(x,c),’o’); end
if (c== 0) plot(x,solution(x,c),’x’); end

First-Order Ordinary Diﬀerential Equations
23
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
−2
0
2
4
6
8
x
y
c = −2
c = −1
c = 0
c = 1
c = 2
c = 3
c = 4
Figure 1.5.1: The solution to Equation 1.5.15 when the initial condition is y(1) = c.
if (c== 1) plot(x,solution(x,c),’+’); end
if (c== 2) plot(x,solution(x,c),’*’); end
if (c== 3) plot(x,solution(x,c),’s’); end
if (c== 4) plot(x,solution(x,c),’d’); end
end
axis tight
xlabel(’x’,’Fontsize’,20); ylabel(’y’,’Fontsize’,20)
legend(’c = -2’,’c = -1’,’c = 0’,’c = 1’,...
’c = 2’,’c = 3’,’c = 4’); legend boxoff
This script does two things.
First, it uses MATLAB’s symbolic toolbox to solve Equa-
tion 1.5.15.
Alternatively, we could have used Equation 1.5.21 and introduced it as a
function. The second portion of this script plots this solution for y(1) = C where C =
−2, −1, 0, 1, 2, 3, 4.
Figure 1.5.1 shows the results.
As x →0, we note how all of the
solutions behave like 2x ln2(x).
⊓⊔
• Example 1.5.2
Let us solve the ﬁrst-order ordinary diﬀerential equation
dy
dx =
y
y −x
(1.5.22)
subject to the initial condition y(2) = 6.
Beginning as before, we rewrite Equation 1.5.22 in the canonical form
(y −x)y′ −y = 0.
(1.5.23)
Examining Equation 1.5.23 more closely, we see that it is a nonlinear equation in y. On the
other hand, if we treat x as the dependent variable and y as the independent variable, we
can write Equation 1.5.23 as the linear equation
dx
dy + x
y = 1.
(1.5.24)

24
Advanced Engineering Mathematics with MATLAB
I
+
-
L
R
E
Figure 1.5.2: Schematic diagram for an electric circuit that contains a resistor of resistance R and an
inductor of inductance L.
Proceeding as before, we have that P(y) = 1/y and µ(y) = y so that Equation 1.5.24
can be rewritten
d
dy (yx) = y
(1.5.25)
or
yx = 1
2y2 + C.
(1.5.26)
Introducing the initial condition, we ﬁnd that C = −6. Solving for y, we obtain
y = x ±
p
x2 + 12.
(1.5.27)
We must take the positive sign in order that y(2) = 6 and
y = x +
p
x2 + 12.
(1.5.28)
⊓⊔
• Example 1.5.3: Electric circuits
A rich source of ﬁrst-order diﬀerential equations is the analysis of simple electrical
circuits. These electrical circuits are constructed from three fundamental components: the
resistor, the inductor, and the capacitor. Each of these devices gives the following voltage
drop: In the case of a resistor, the voltage drop equals the product of the resistance R
times the current I. For the inductor, the voltage drop is L dI/dt, where L is called the
inductance, while the voltage drop for a capacitor equals Q/C, where Q is the instantaneous
charge and C is called the capacitance.
How are these voltage drops applied to mathematically describe an electrical circuit?
This question leads to one of the fundamental laws in physics, Kirchhoﬀ’s law:The alge-
braic sum of all the voltage drops around an electric loop or circuit is zero.
To illustrate Kirchhoﬀ’s law, consider the electrical circuit shown in Figure 1.5.2. By
Kirchhoﬀ’s law, the electromotive force E, provided by a battery, for example, equals the
sum of the voltage drops across the resistor RI and L dI/dt. Thus the (diﬀerential) equation
that governs this circuit is
LdI
dt + RI = E.
(1.5.29)
Assuming that E, I, and R are constant, we can rewrite Equation 1.5.29 as
d
dt
h
eRt/LI(t)
i
= E
L eRt/L.
(1.5.30)

First-Order Ordinary Diﬀerential Equations
25
I(t)
1
2
3
Rt/L
E/R
Figure 1.5.3: The temporal evolution of current I(t) inside an electrical circuit shown in Figure 1.5.2 with
a constant electromotive force E.
Integrating both sides of Equation 1.5.30,
eRt/LI(t) = E
ReRt/L + C1,
(1.5.31)
or
I(t) = E
R + C1e−Rt/L.
(1.5.32)
To determine C1, we apply the initial condition.
Because the circuit is initially dead,
I(0) = 0, and
I(t) = E
R

1 −e−Rt/L
.
(1.5.33)
Figure 1.5.3 illustrates Equation 1.5.33 as a function of time. Initially the current increases
rapidly but the growth slows with time. Note that we could also have solved this problem
by separation of variables.
Quite often, the solution is separated into two parts: the steady-state solution and the
transient solution. The steady-state solution is that portion of the solution which remains
as t →∞. It can equal zero. Presently it equals the constant value, E/R. The transient
solution is that portion of the solution which vanishes as time increases. Here it equals
−Ee−Rt/L/R.
Although our analysis is a useful approximation to the real world, a more realistic one
would include the nonlinear properties of the resistor.9 To illustrate this, consider the case
of an RL circuit without any electromotive source (E = 0) where the initial value for the
current is I0. Equation 1.5.29 now reads
LdI
dt + RI(1 −aI) = 0,
I(0) = I0.
(1.5.34)
Separating the variables,
dI
I(aI −1) =
dI
I −1/a −dI
I = R
L dt.
(1.5.35)
9 For the analysis of
L dI
dt + RI + KIβ = 0,
see Fairweather, A., and J. Ingham, 1941: Subsidence transients in circuits containing a non-linear resistor,
with reference to the problem of spark-quenching. J. IEE, Part 1, 88, 330–339.

26
Advanced Engineering Mathematics with MATLAB
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Rt/L
0.0
0.2
0.4
0.6
0.8
1.0
1.2
I/I0
0
0
0
aI  = 0.5
aI  = 0.9
aI  = 1.0
0
aI  = 0.0
Figure 1.5.4: The variation of current I/I0 as a function of time Rt/L with diﬀerent values of aI0.
Upon integrating and applying the initial condition, we have that
I =
I0e−Rt/L
1 −aI0 + aI0e−Rt/L .
(1.5.36)
Figure 1.5.4 shows I(t) for various values of a. As the nonlinearity reduces resistance,
the decay in the current is reduced. If aI0 > 1, Equation 1.5.36 predicts that the current
would grow with time. The point here is that nonlinearity can have a dramatic inﬂuence
on a physical system.
Consider now the electrical circuit shown in Figure 1.5.5, which contains a resistor with
resistance R and a capacitor with capacitance C. Here the voltage drop across the resistor
is still RI while the voltage drop across the capacitor is Q/C. Therefore, by Kirchhoﬀ’s
law,
RI + Q
C = E.
(1.5.37)
Equation 1.5.37 is not a diﬀerential equation. However, because current is the time rate of
change in charge I = dQ/dt, our diﬀerential equation becomes
RdQ
dt + Q
C = E,
(1.5.38)
which is the diﬀerential equation for the instantaneous charge.
Let us solve Equation 1.5.38 when the resistance and capacitance are constant but the
electromotive force equals E0 cos(ωt). The corresponding diﬀerential equation is now
RdQ
dt + Q
C = E0 cos(ωt).
(1.5.39)
The diﬀerential equation has the integrating factor et/(RC) so that it can be rewritten
d
dt
h
et/(RC)Q(t)
i
= E0
R et/(RC) cos(ωt).
(1.5.40)
Integrating Equation 1.5.40,
et/(RC)Q(t) =
CE0
1 + R2C2ω2 et/(RC) [cos(ωt) + RCω sin(ωt)] + C1
(1.5.41)

First-Order Ordinary Diﬀerential Equations
27
R
C
I
+
-
E
Figure 1.5.5: Schematic diagram for an electric circuit that contains a resistor of resistance R and a
capacitor of capacitance C.
or
Q(t) =
CE0
1 + R2C2ω2 [cos(ωt) + RCω sin(ωt)] + C1e−t/(RC).
(1.5.42)
If we take the initial condition as Q(0) = 0, then the ﬁnal solution is
Q(t) =
CE0
1 + R2C2ω2
h
cos(ωt) −e−t/(RC) + RCω sin(ωt)
i
.
(1.5.43)
Figure 1.5.6 illustrates Equation 1.5.43. Note how the circuit eventually supports a purely
oscillatory solution (the steady-state solution) as the exponential term decays to zero (the
transient solution). Indeed, the purpose of the transient solution is to allow the system to
adjust from its initial condition to the ﬁnal steady state.
⊓⊔
• Example 1.5.4: Terminal velocity
When an object passes through a ﬂuid, the viscosity of the ﬂuid resists the motion by
exerting a force on the object proportional to its velocity. Let us ﬁnd the motion of a mass
m that is initially thrown upward with the speed v0.
If we choose the coordinate system so that it increases in the vertical direction, then
the equation of motion is
mdv
dt = −kv −mg
(1.5.44)
with v(0) = v0 and k > 0. Rewriting Equation 1.5.44, we obtain the ﬁrst-order linear
diﬀerential equation
dv
dt + k
mv = −g.
(1.5.45)
Its solution in nondimensional form is
kv(t)
mg
= −1 +

1 + kv0
mg

e−kt/m.
(1.5.46)
The displacement from its initial position is
k2x(t)
m2g
= k2x0
m2g −kt
m +

1 + kv0
mg
 
1 −e−kt/m
.
(1.5.47)

28
Advanced Engineering Mathematics with MATLAB
0
2
4
6
8
10
12
14
16
18
20
NONDIMENSIONAL TIME
−3
−2
−1
0
1
2
3
NONDIMENSIONAL CHARGE
Figure 1.5.6: The temporal evolution of the nondimensional charge (1 + R2C2ω2)Q(t) /(CE0) in the
electric circuit shown in Figure 1.5.4 as a function of nondimensional time ωt when the circuit is driven by
the electromotive force E0 cos(ωt) and RCω = 2.
As t →∞, the velocity tends to a constant downward value, −mg/k, the so-called “terminal
velocity,” where the aerodynamic drag balances the gravitational acceleration. This is the
steady-state solution.
Why have we written Equation 1.5.46 and Equation 1.5.47 in this nondimensional
form? There are two reasons. First, the solution reduces to three fundamental variables,
a nondimensional displacement x∗= k2x(t)/(m2g), velocity v∗= kv(t)/(mg), and time
t∗= kt/m, rather than the six original parameters and variables: g, k, m, t, v, and x.
Indeed, if we had substituted t∗, v∗, and x∗into Equation 1.5.45, we would have obtained
the following simpliﬁed initial-value problem:
dv∗
dt∗
+ v∗= −1,
dx∗
dt∗
= v∗,
v∗(0) = kv0
mg ,
x∗(0) = k2x0
m2g
(1.5.48)
right from the start. The second advantage of the nondimensional form is the compact
manner in which the results can be displayed, as Figure 1.5.7 shows.
From Equation 1.5.46 and Equation 1.5.47, the trajectory of the ball is as follows: If
we deﬁne the coordinate system so that x0 = 0, then the object will initially rise to the
height H given by
k2H
m2g = kv0
mg −ln

1 + kv0
mg

(1.5.49)
at the time
ktmax
m
= ln

1 + kv0
mg

,
(1.5.50)
when v(tmax) = 0. It will then fall toward the earth. Given suﬃcient time kt/m ≫1, it
would achieve terminal velocity.
⊓⊔
• Example 1.5.5: The Bernoulli equation
Bernoulli’s equation,
dy
dx + p(x)y = q(x)yn,
n ̸= 0, 1,
(1.5.51)

First-Order Ordinary Diﬀerential Equations
29
0
1
2
3
4
5
6
7
8
9
10
NONDIMENSIONAL TIME
−10
−8
−6
−4
−2
0
2
4
6
8
10
NONDIMENSIONAL DISPLACEMENT
ν = 10
ν = 3
ν = 0.1
Figure 1.5.7: The nondimensional displacement k2x(t)/(m2g) as a function of nondimensional time kt/m
of an object of mass m thrown upward at the initial nondimensional speed ν = kv0/(mg) in a ﬂuid that
retards its motion as −kv.
is a ﬁrst-order, nonlinear diﬀerential equation. This equation can be transformed into a
ﬁrst-order, linear diﬀerential equation by introducing the change of variable z = y1−n.
Because
dz
dx = (1 −n)y−n dy
dx,
(1.5.52)
the transformed Bernoulli equation becomes
dz
dx + (1 −n)p(x)z = (1 −n)q(x).
(1.5.53)
This is now a ﬁrst-order linear diﬀerential equation for z and can be solved using the
methods introduced in this section. Once z is known, the solution is found by transforming
back from z to y.
To illustrate this procedure, consider the nonlinear ordinary diﬀerential equation
x2y dy
dx −xy2 = 1,
(1.5.54)
or
dy
dx −y
x = y−1
x2 .
(1.5.55)
Equation 1.5.55 is a Bernoulli equation with p(x) = −1/x, q(x) = 1/x2, and n = −1.
Introducing z = y2, it becomes
dz
dx −2z
x = 2
x2 .
(1.5.56)
This ﬁrst-order linear diﬀerential equation has the integrating factor µ(x) = 1/x2 and
d
dx
 z
x2

= 2
x4 .
(1.5.57)
Integration gives
z
x2 = C −
2
3x3 .
(1.5.58)

30
Advanced Engineering Mathematics with MATLAB
Therefore, the general solution is
y2 = z = Cx2 −2
3x.
(1.5.59)
Problems
Find the solution for the following diﬀerential equations. State the interval on which the
general solution is valid. Then use MATLAB to examine their behavior for a wide class of
initial conditions.
1. y′ + y = ex
2. y′ + 2xy = x
3. x2y′ + xy = 1
4. (2y + x2) dx = x dy
5. y′ −3y/x = 2x2
6. y′ + 2y = 2 sin(x)
7. y′ + 2 cos(2x)y = 0
8. xy′ + y = ln(x)
9. y′ + 3y = 4,
y(0) = 5
10. y′ −y = ex/x,
y(e) = 0
11. sin(x)y′ + cos(x)y = 1
12. [1 −cos(x)]y′ + 2 sin(x)y = tan(x)
13. y′ + [a tan(x) + b sec(x)]y = c sec(x)
14. (xy + y −1) dx + x dy = 0
15. y′ + 2ay = x
2 −sin(2ωx)
4ω
,
y(0) = 0.
16. y′ + 2k
x3 y = ln
x + 1
x

, k > 0, y(1) = 0.
17. Solve the following initial-value problem:
kxy dy
dx = y2 −x,
y(1) = 0.
Hint: Introduce the new dependent variable p = y2.
18. If x(t) denotes the equity capital of a company, then under certain assumptions10 x(t)
is governed by
dx
dt = (1 −N)rx + S,
where N is the dividend payout ratio, r is the rate of return of equity, and S is the rate of
net new stock ﬁnancing. If the initial value of x(t) is x(0), ﬁnd x(t).
19. The assimilation11 of a drug into a body can be modeled by the chemical reaction A
k1
→
B
k2
→C, which is governed by the chemical kinetics equations
d[A]
dt
= −k1[A],
d[B]
dt
= k1[A] −k2[B],
d[C]
dt
= k2[B],
10 See Lebowitz, J. L., C. O. Lee, and P. B. Linhart, 1976: Some eﬀects of inﬂation on a ﬁrm with
original cost depreciation. Bell J. Economics, 7, 463–477.
11 See Calder, G. V., 1974: The time evolution of drugs in the body: An application of the principle of
chemical kinetics. J. Chem. Educ., 51, 19–22.

First-Order Ordinary Diﬀerential Equations
31
where [A] denotes the concentration of the drug in the gastrointestinal tract or in the site
of injection, [B] is the concentration of the drug in the body, and [C] is either the amount
of drug eliminated by various metabolic functions or the amount of the drug utilized by
various action sites in the body. If [A]0 denotes the initial concentration of A, ﬁnd [A], [B],
and [C] as a function of time t.
20. Find the current in an RL circuit when the electromotive source equals E0 cos2(ωt).
Initially the circuit is dead.
Find the general solution for the following Bernoulli equations:
21. dy
dx + y
x = −y2
22. x2 dy
dx = xy + y2
23. dy
dx −4y
x = x√y
24. dy
dx + y
x = −xy2
25. 2xy dy
dx −y2 + x = 0
26. xdy
dx + y = 1
2xy3
1.6 GRAPHICAL SOLUTIONS
In spite of the many techniques developed for their solution, many ordinary diﬀeren-
tial equations cannot be solved analytically. In the next two sections, we highlight two
alternative methods when analytical methods fail. Graphical methods seek to understand
the nature of the solution by examining the diﬀerential equations at various points and
infer the complete solution from these results. In the last section, we highlight the numeri-
cal techniques that are now commonly used to solve ordinary diﬀerential equations on the
computer.
• Direction ﬁelds
One of the simplest numerical methods for solving ﬁrst-order ordinary diﬀerential equa-
tions follows from the fundamental concept that the derivative gives the slope of a straight
line that is tangent to a curve at a given point.
Consider the ﬁrst-order diﬀerential equation
y′ = f(x, y),
(1.6.1)
which has the initial value y(x0) = y0. For any (x, y) it is possible to draw a short line
segment whose slope equals f(x, y). This graphical representation is known as the direction
ﬁeld or slope ﬁeld
of Equation 1.6.1. Starting with the initial point (x0, y0), we can then
construct the solution curve by extending the initial line segment in such a manner that
the tangent of the solution curve parallels the direction ﬁeld at each point through which
the curve passes.
Before the days of computers, it was common to ﬁrst draw lines of constant slope
(isoclines) or f(x, y) = c. Because along any isocline all of the line segments had the same
slope, considerable computational savings were realized. Today, computer software exists
that performs these graphical computations with great speed.
To illustrate this technique, consider the ordinary diﬀerential equation
dx
dt = x −t2.
(1.6.2)

32
Advanced Engineering Mathematics with MATLAB
−2
−1
0
1
2
3
−1
−0.5
0
0.5
1
1.5
2
t
x
Figure 1.6.1: The direction ﬁeld for Equation 1.6.2. The solid lines are plots of the solution with various
initial conditions.
Its exact solution is
x(t) = Cet + t2 + 2t + 2,
(1.6.3)
where C is an arbitrary constant. Using the MATLAB script
clear
% create grid points in t and x
[t,x] = meshgrid(-2:0.2:3,-1:0.2:2);
% load in the slope
slope = x - t.*t;
% find the length of the vector (1,slope)
length = sqrt(1 + slope .* slope);
% create and plot the vector arrows
quiver(t,x,1./length,slope./length,0.5)
axis equal tight
hold on
% plot the exact solution for various initial conditions
tt = [-2:0.2:3];
for cval = -10:1:10
x exact = cval * exp(tt) + tt.*tt + 2*tt + 2;
plot(tt,x exact)
xlabel(’t’,’Fontsize’,20)
ylabel(’x’,’Fontsize’,20)
end
we show in Figure 1.6.1 the directional ﬁeld associated with Equation 1.6.2 along with
some of the particular solutions. Clearly the vectors are parallel to the various particular
solutions. Therefore, without knowing the solution, we could choose an arbitrary initial
condition and sketch its behavior at subsequent times. The same holds true for nonlinear
equations.
• Rest points and autonomous equations
In the case of autonomous diﬀerential equations (equations where the independent
variable does not explicitly appear in the equation), considerable information can be gleaned
from a graphical analysis of the equation.

First-Order Ordinary Diﬀerential Equations
33
x’ < 0
x’ > 0 
x’ > 0 
x’ < 0
−1
0
1
Figure 1.6.2: The phase line diagram for the ordinary diﬀerential equation, Equation 1.6.4.
Consider the nonlinear ordinary diﬀerential equation
x′ = dx
dt = x(x2 −1).
(1.6.4)
The time derivative x′ vanishes at x = −1, 0, 1. Consequently, if x(0) = 0, x(t) will remain
zero forever.
Similarly, if x(0) = 1 or x(0) = −1, then x(t) will equal 1 or −1 for all
time. For this reason, values of x for which the derivative x′ is zero are called rest points,
equilibrium points, or critical points of the diﬀerential equation.
The behavior of solutions near rest points is often of considerable interest. For example,
what happens to the solution when x is near one of the rest points x = −1, 0, 1?
Consider the point x = 0. For x slightly greater than zero, x′ < 0. For x slightly less
than 0, x′ > 0. Therefore, for any initial value of x near x = 0, x will tend to zero. In
this case, the point x = 0 is an asymptotically stable critical point because whenever x is
perturbed away from the critical point, it tends to return there again.
Turning to the point x = 1, for x slightly greater than 1, x′ > 0; for x slightly less
than 1, x′ < 0. Because any x near x = 1, but not equal to 1, will move away from x = 1,
the point x = 1 is called an unstable critical point. A similar analysis applies at the point
x = −1. This procedure of determining the behavior of an ordinary diﬀerential equation
near its critical points is called a graphical stability analysis.
• Phase line
A graphical representation of the results of our graphical stability analysis is the phase
line. On a phase line, the equilibrium points are denoted by circles. See Figure 1.6.2. Also
on the phase line we identify the sign of x′ for all values of x. From the sign of x′, we then
indicate whether x is increasing or deceasing by an appropriate arrow. If the arrow points
toward the right, x is increasing; toward the left x decreases. Then, by knowing the sign
of the derivative for all values of x, together with the starting value of x, we can determine
what happens as t →∞. Any solution that is approached asymptotically as t →∞is called
a steady-state output. In our present example, x = 0 is a steady-state output.
Problems
In previous sections, you used various techniques to solve ﬁrst-order ordinary diﬀerential
equations. Now check your work by using MATLAB to draw the direction ﬁeld and plot
your analytic solution for the following problems taken from previous sections:
1. Section 1.2, Problem 5
2. Section 1.3, Problem 1
3. Section 1.4, Problem 5
4. Section 1.5, Problem 3

34
Advanced Engineering Mathematics with MATLAB
For the following autonomous ordinary diﬀerential equations, draw the phase line. Then
classify each equilibrium solution as either stable or unstable.
5. x′ = αx(1 −x)(x −1
2)
6. x′ = (x2 −1)(x2 −4)
7. x′ = −4x −x3
8. x′ = 4x −x3
1.7 NUMERICAL METHODS
By now you have seen most of the exact methods for ﬁnding solutions to ﬁrst-order
ordinary diﬀerential equations. The methods have also given you a view of the general
behavior and properties of solutions to diﬀerential equations. However, it must be admitted
that in many instances exact solutions cannot be found and we must resort to numerical
solutions.
In this section we present the two most commonly used methods for solving diﬀeren-
tial equations: Euler and Runge-Kutta methods. There are many more methods and the
interested student is referred to one of countless numerical methods books. A straightfor-
ward extension of these techniques can be applied to systems of ﬁrst-order and higher-order
diﬀerential equations.
• Euler and modiﬁed Euler methods
Consider the following ﬁrst-order diﬀerential equation and initial condition:
dy
dx = f(x, y),
y(x0) = y0.
(1.7.1)
Euler’s method is based on a Taylor series expansion of the solution about x0 or
y(x0 + h) = y(x0) + hy′(x0) + 1
2y′′(ξ)h2,
x0 < ξ < x0 + h,
(1.7.2)
where h is the step size. Euler’s method consists of taking a suﬃciently small h so that
only the ﬁrst two terms of this Taylor expansion are signiﬁcant.
Let us now replace y′(x0) by f(x0, y0). Using subscript notation, we have that
yi+1 = yi + hf(xi, yi) + O(h2).
(1.7.3)
Equation 1.7.3 states that if we know the values of yi and f(xi, yi) at the position xi, then
the solution at xi+1 can be obtained with an error12 O(h2).
The trouble with Euler’s method is its lack of accuracy, often requiring an extremely
small time step. How might we improve this method with little additional eﬀort?
One possible method would retain the ﬁrst three terms of the Taylor expansion rather
than the ﬁrst two. This scheme, known as the modiﬁed Euler method, is
yi+1 = yi + hy′(xi) + 1
2h2y′′
i + O(h3).
(1.7.4)
This is clearly more accurate than Equation 1.7.3.
12 The symbol O is a mathematical notation indicating relative magnitude of terms, namely that f(ǫ) =
O(ǫn) provided limǫ→0 |f(ǫ)/ǫn| < ∞.
For example, as ǫ →0, sin(ǫ) = O(ǫ), sin(ǫ2) = O(ǫ2), and
cos(ǫ) = O(1).

First-Order Ordinary Diﬀerential Equations
35
An obvious question is how do we evaluate y′′
i , because we do not have any information
on its value. Using the forward derivative approximation, we ﬁnd that
y′′
i = y′
i+1 −y′
i
h
.
(1.7.5)
Substituting Equation 1.7.5 into Equation 1.7.4 and simplifying
yi+1 = yi + h
2
 y′
i + y′
i+1

+ O(h3).
(1.7.6)
Using the diﬀerential equation,
yi+1 = yi + h
2 [f(xi, yi) + f(xi+1, yi+1)] + O(h3).
(1.7.7)
Although f(xi, yi) at (xi, yi) are easily calculated, how do we compute f(xi+1, yi+1) at
(xi+1, yi+1)?
For this we compute a ﬁrst guess via the Euler method, Equation 1.7.3;
Equation 1.7.7 then provides a reﬁnement on the value of yi+1.
In summary then, the simple Euler scheme is
yi+1 = yi + k1 + O(h2),
k1 = hf(xi, yi),
(1.7.8)
while the modiﬁed Euler method is
yi+1 = yi + 1
2(k1 + k2) + O(h3), k1 = hf(xi, yi), k2 = hf(xi + h, yi + k1).
(1.7.9)
• Example 1.7.1
Let us illustrate Euler’s method by numerically solving
x′ = x + t,
x(0) = 1.
(1.7.10)
A quick check shows that Equation 1.7.10 has the exact solution xexact(t) = 2et −t −1.
Using the MATLAB script
clear
for i = 1:3
% set up time step increment and number of time steps
h = 1/10^i; n = 10/h;
% set up initial conditions
t=zeros(n+1,1); t(1) = 0;
x euler=zeros(n+1,1); x euler(1) = 1;
x modified=zeros(n+1,1); x modified(1) = 1;
x exact=zeros(n+1,1); x exact(1) = 1;
% set up difference arrays for plotting purposes
diff1 = zeros(n,1); diff2 = zeros(n,1); tplot = zeros(n,1);
% define right side of differential equation, Equation 1.7.10
f = inline(’xx+tt’,’tt’,’xx’);
for k = 1:n
t(k+1) = t(k) + h;
% compute exact solution

36
Advanced Engineering Mathematics with MATLAB
x exact(k+1) = 2*exp(t(k+1)) - t(k+1) - 1;
% compute solution via Euler’s method
k1 = h * f(t(k),x euler(k));
x euler(k+1) = x euler(k) + k1;
tplot(k) = t(k+1);
diff1(k) = x euler(k+1) - x exact(k+1);
diff1(k) = abs(diff1(k) / x exact(k+1));
% compute solution via modified Euler method
k1 = h * f(t(k),x modified(k));
k2 = h * f(t(k+1),x modified(k)+k1);
x modified(k+1) = x modified(k) + 0.5*(k1+k2);
diff2(k) = x modified(k+1) - x exact(k+1);
diff2(k) = abs(diff2(k) / x exact(k+1));
end
% plot relative errors
semilogy(tplot,diff1,’-’,tplot,diff2,’:’)
hold on
xlabel(’TIME’,’Fontsize’,20)
ylabel(’|RELATIVE ERROR|’,’Fontsize’,20)
legend(’Euler method’,’modified Euler method’)
legend boxoff;
num1 = 0.2*n; num2 = 0.8*n;
text(3,diff1(num1),[’h = ’,num2str(h)],’Fontsize’,15,...
’HorizontalAlignment’,’right’,...
’VerticalAlignment’,’bottom’)
text(9,diff2(num2),[’h = ’,num2str(h)],’Fontsize’,15,...
’HorizontalAlignment’,’right’,...
’VerticalAlignment’,’bottom’)
end
Both the Euler and modiﬁed Euler methods have been used to numerically integrate Equa-
tion 1.7.10 and the absolute value of the relative error is plotted in Figure 1.7.1 as a function
of time for various time steps. In general, the error grows with time. The decrease of error
with smaller time steps, as predicted in our analysis, is quite apparent. Furthermore, the
superiority of the modiﬁed Euler method over the original Euler method is clearly seen. ⊓⊔
• Runge-Kutta method
As we have just shown, the accuracy of numerical solutions of ordinary diﬀerential
equations can be improved by adding more terms to the Taylor expansion. The Runge-
Kutta method13 builds upon this idea, just as the modiﬁed Euler method did.
Let us assume that the numerical solution can be approximated by
yi+1 = yi + ak1 + bk2,
(1.7.11)
13 Runge, C., 1895: Ueber die numerische Auﬂ¨osung von Differentialgleichungen. Math. Ann., 46, 167–
178; Kutta, W., 1901: Beitrag zur N¨aherungsweisen Integration totaler Diﬀerentialgleichungen. Zeit. Math.
Phys., 46, 435–453. For a historical review, see Butcher, J. C., 1996: A history of Runge-Kutta methods.
Appl. Numer. Math., 20, 247–260 and Butcher, J. C., and G. Wanner, 1996: Runge-Kutta methods: Some
historical notes. Appl. Numer. Math., 22, 113–151.

First-Order Ordinary Diﬀerential Equations
37
0
2
4
6
8
10
10
−10
10
−8
10
−6
10
−4
10
−2
10
0
TIME
|RELATIVE ERROR|
h = 0.1
h = 0.1
h = 0.01
h = 0.01
h = 0.001
h = 0.001
Euler method
modified Euler method
Figure 1.7.1: The relative error [x(t) −xexact(t)]/xexact(t) of the numerical solution of Equation 1.7.10
using Euler’s method (the solid line) and modiﬁed Euler’s method (the dotted line) with diﬀerent time steps
h.
where
k1 = hf(xi, yi)
and
k2 = hf(xi + A1h, yi + B1k1).
(1.7.12)
Here a, b, A1, and B1 are four unknowns. Equation 1.7.11 was suggested by the modiﬁed
Euler method that we just presented. In that case, the truncated Taylor series had an error
of O(h3). We anticipate such an error in the present case.
Because the Taylor series expansion of f(x + h, y + k) about (x, y) is
f(x + h, y + k) = f(x, y) + (hfx + kfy) + 1
2
 h2fxx + 2hkfxy + k2fyy

+ 1
6
 h3fxxx + 3h2kfxxy + 3hk2fxyy + k3fyyy

+ · · · ,
(1.7.13)
k2 can be rewritten
k2 = hf[xi + A1h, yi + Bhf(xi, yi)]
(1.7.14)
= h [f(xi, yi) + (A1hfx + B1hffy)]
(1.7.15)
= hf + A1h2fx + B1h2ffy,
(1.7.16)
where we have retained only terms up to O(h2) and neglected all higher-order terms. Finally,
substituting Equation 1.7.16 into Equation 1.7.11 gives
yi+1 = yi + (a + b)hf + (A1bfx + B1bffy)h2.
(1.7.17)
This equation corresponds to the second-order Taylor expansion:
yi+1 = yi + hy′
i + 1
2h2y′′
i .
(1.7.18)
Therefore, if we wish to solve the diﬀerential equation y′ = f(x, y), then
y′′ = fx + fyy′ = fx + ffy.
(1.7.19)
Substituting Equation 1.7.19 into Equation 1.7.18, we have that
yi+1 = yi + hf + 1
2h2(fx + ffy).
(1.7.20)

38
Advanced Engineering Mathematics with MATLAB
Although Carl David Tolm´e Runge (1856–1927) began his studies in Munich, his friendship with
Max Planck led him to Berlin and pure mathematics with Kronecker and Weierstrass. It was his
professorship at Hanover beginning in 1886 and subsequent work in spectroscopy that led him to his
celebrated paper on the numerical integration of ordinary diﬀerential equations. Runge’s ﬁnal years
were spent in G¨ottingen as a professor in applied mathematics. (Portrait taken with permission from
Reid, C., 1976: Courant in G¨ottingen and New York: The Story of an Improbable Mathematician.
Springer-Verlag, 314 pp. c⃝1976, by Springer-Verlag New York Inc.)
A direct comparison of Equation 1.7.17 and Equation 1.7.20 yields
a + b = 1,
A1b = 1
2,
and
B1b = 1
2.
(1.7.21)
These three equations have four unknowns. If we choose a = 1
2, we immediately calculate
b = 1
2 and A1 = B1 = 1. Hence the second-order Runge-Kutta scheme is
yi+1 = yi + 1
2(k1 + k2),
(1.7.22)
where k1 = hf(xi, yi) and k2 = hf(xi + h, yi + k1). Thus, the second-order Runge-Kutta
scheme is identical to the modiﬁed Euler method.
Although the derivation of the second-order Runge-Kutta scheme yields the modiﬁed
Euler scheme, it does provide a framework for computing higher-order and more accurate
schemes. A particularly popular one is the fourth-order Runge-Kutta scheme
yi+1 = yi + 1
6(k1 + 2k2 + 2k3 + k4),
(1.7.23)
where
k1 = hf(xi, yi),
(1.7.24)
k2 = hf(xi + 1
2h, yi + 1
2k1),
(1.7.25)
k3 = hf(xi + 1
2h, yi + 1
2k2),
(1.7.26)

First-Order Ordinary Diﬀerential Equations
39
and
k4 = hf(xi + h, yi + k3).
(1.7.27)
• Example 1.7.2
Let us illustrate the fourth-order Runge-Kutta by redoing the previous example using
the MATLAB script
clear
% test out different time steps
for i = 1:4
% set up time step increment and number of time steps
if i==1 h = 0.50; end; if i==2 h = 0.10; end;
if i==3 h = 0.05; end; if i==4 h = 0.01; end;
n = 10/h;
% set up initial conditions
t=zeros(n+1,1); t(1) = 0;
x rk=zeros(n+1,1); x rk(1) = 1;
x exact=zeros(n+1,1); x exact(1) = 1;
% set up difference arrays for plotting purposes
diff = zeros(n,1); tplot = zeros(n,1);
% define right side of differential equation
f = inline(’xx+tt’,’tt’,’xx’);
for k = 1:n
x local = x rk(k); t local = t(k);
k1 = h * f(t local,x local);
k2 = h * f(t local + h/2,x local + k1/2);
k3 = h * f(t local + h/2,x local + k2/2);
k4 = h * f(t local + h,x local + k3);
t(k+1) = t local + h;
x rk(k+1) = x local + (k1+2*k2+2*k3+k4) / 6;
x exact(k+1) = 2*exp(t(k+1)) - t(k+1) - 1;
tplot(k) = t(k);
diff(k) = x rk(k+1) - x exact(k+1);
diff(k) = abs(diff(k) / x exact(k+1));
end
% plot relative errors
semilogy(tplot,diff,’-’)
hold on
xlabel(’TIME’,’Fontsize’,20)
ylabel(’|RELATIVE ERROR|’,’Fontsize’,20)
num1 = 2*i; num2 = 0.2*n;
text(num1,diff(num2),[’h = ’,num2str(h)],’Fontsize’,15,...
’HorizontalAlignment’,’right’,...
’VerticalAlignment’,’bottom’)
end
The error growth with time is shown in Figure 1.7.2. Although this script could be used
for any ﬁrst-order ordinary diﬀerential equation, the people at MATLAB have an alternative
called ode45, which combines a fourth-order and a ﬁfth-order method that are similar to
our fourth-order Runge-Kutta method. Their scheme is more eﬃcient because it varies the

40
Advanced Engineering Mathematics with MATLAB
0
2
4
6
8
10
10
−12
10
−10
10
−8
10
−6
10
−4
10
−2
TIME
|RELATIVE ERROR|
h = 0.5
h = 0.1
h = 0.05
h = 0.01
Figure 1.7.2: Same as Figure 1.7.1 except that we have used the fourth-order Runge-Kutta method.
step size, choosing a new time step at each step in an attempt to achieve a given desired
accuracy.
⊓⊔
• Adams-Bashforth method
All of the methods presented so far (Euler, modiﬁed Euler, Runge-Kutta) are single
point methods; the solution at i+1 depends solely on a single point i. A popular alternative
to these schemes are multistep methods that compute yi+1 by reusing previously obtained
values of yn where n < i.
We begin our derivation of a multistep method by rewriting Equation 1.7.1 as
dy = f(x, y) dx.
(1.7.28)
Integrating both sides of Equation 1.7.28, we obtain
y(xi+1) −y(xi) =
Z xi+1
xi
dy =
Z xi+1
xi
f(x, y) dx.
(1.7.29)
The Adams-Bashforth method14 replaces the integrand in Equation 1.7.29 with an approx-
imation derived from Newton’s backward diﬀerence formula:
f(x, y) ≈fi + ξ∇fi + 1
2ξ(ξ + 1)∇2fi + 1
6ξ(ξ + 1)(ξ + 2)∇3fi,
(1.7.30)
where ξ = (x −xi)/h or x = xi + hξ,
∇fi = f(xi, yi) −f(xi−1, yi−1),
(1.7.31)
∇2fi = f(xi, yi) −2f(xi−1, yi−1) + f(xi−2, yi−2),
(1.7.32)
14 Bashforth, F., and J. C. Adams, 1883: An Attempt to Test the Theories of Capillary Action by
Comparing the Theoretical and Measured Forms of Drops of Fluid. With an Explanation of the Method
of Integration Employed in Constructing the Tables Which Give the Theoretical Forms of Such Drops.
Cambridge University Press, 139 pp.

First-Order Ordinary Diﬀerential Equations
41
and
∇3fi = f(xi, yi) −3f(xi−1, yi−1) + 3f(xi−2, yi−2) −f(xi−3, yi−3).
(1.7.33)
Substituting Equation 1.7.30 into Equation 1.7.29 and carrying out the integration, we ﬁnd
that
y(xi+1) = y(xi) + h
24

55f(xi, yi) −59f(xi−1, yi−1) + 37f(xi−2, yi−2) −9f(xi−3, yi−3)

.
(1.7.34)
Thus, the Adams-Bashforth method is an explicit ﬁnite diﬀerence formula that has a global
error of O(h4). Additional computational savings can be realized if the old values of the
slope are stored and used later. A disadvantage is that some alternative scheme (usually
Runge-Kutta) must provide the ﬁrst three starting values.
• Example 1.7.3
The ﬂight of projectiles provides a classic application of ﬁrst-order diﬀerential equa-
tions. If the projectile has a mass m and its motion is opposed by the drag mgkv2, where
g is the acceleration due to gravity and k is the quadratic drag coeﬃcients, Newton’s law
of motion gives
dv
dt = −g sin(θ) −gkv2,
(1.7.35)
where θ is the slope of the trajectory to the horizon. From kinematics,
dx
dt = v cos(θ),
dy
dt = v sin(θ),
dθ
dt = −g cos(θ)
v
.
(1.7.36)
An interesting aspect of this problem is the presence of a system of ordinary diﬀerential
equations.
Although we can obtain an exact solution to this problem,15 let us illustrate the Adams-
Bashforth method to compute the solution to Equation 1.7.35 and Equation 1.7.36. We
begin by computing the ﬁrst three time steps using the Runge-Kutta method. Note that
we ﬁrst compute the k1 for all of the dependent variables before we start computing the
values of k2. Similar considerations hold for k3 and k4.
clear
a = 0; b = 7.85; N = 100; g = 9.81; c = 0.000548;
h = (b-a)/N; t = (a:h:b+h);
% set initial conditions
v(1) = 44.69; theta(1) = pi/3; x(1) = 0; y(1) = 0;
for i = 1:3
angle = theta(i); vv = v(i);
k1 vel = -g*sin(angle) - g*c*vv*vv;
k1 angle = -g*cos(angle) / vv;
k1 x = vv * cos(angle);
k1 y = vv * sin(angle);
angle = theta(i)+h*k1 angle/2; vv = v(i)+h*k1 vel/2;
k2 vel = -g*sin(angle) - g*c*vv*vv;
15 Tan, A., C. H. Frick, and O. Castillo, 1987: The ﬂy ball trajectory: An older approach revisited. Am.
J. Phys., 55, 37–40; Chudinov, P. S., 2001: The motion of a point mass in a medium with a square law of
drag. J. Appl. Math. Mech., 65, 421–426.

42
Advanced Engineering Mathematics with MATLAB
k2 angle = -g*cos(angle) / vv;
k2 x = vv * cos(angle);
k2 y = vv * sin(angle);
angle = theta(i)+h*k2 angle/2; vv = v(i)+h*k2 vel/2;
k3 vel = -g*sin(angle) - g*c*vv*vv;
k3 angle = -g*cos(angle) / vv;
k3 x = vv * cos(angle);
k3 y = vv * sin(angle);
angle = theta(i)+h*k3 angle; vv = v(i)+h*k3 vel;
k4 vel = -g*sin(angle) - g*c*vv*vv;
k4 angle = -g*cos(angle) / vv;
k4 x = vv * cos(angle);
k4 y = vv * sin(angle);
v(i+1) = v(i) + h*(k1 vel+2*k2 vel+2*k3 vel+k4 vel)/6;
x(i+1) = x(i) + h*(k1 x+2*k2 x+2*k3 x+k4 x)/6;
y(i+1) = y(i) + h*(k1 y+2*k2 y+2*k3 y+k4 y)/6;
theta(i+1) = theta(i) + h*(k1 angle+2*k2 angle ...
+2*k3 angle+k4 angle)/6;
end
Having computed the ﬁrst three values of each of the dependent variables, we turn to
the Adams-Bashforth method to compute the remaining portion of the numerical solution:
for i = 4:N
angle = theta(i); vv = v(i);
k1 vel = -g*sin(angle) - g*c*vv*vv;
k1 angle = -g*cos(angle) / vv;
k1 x = vv * cos(angle);
k1 y = vv * sin(angle);
angle = theta(i-1); vv = v(i-1);
k2 vel = -g*sin(angle) - g*c*vv*vv;
k2 angle = -g*cos(angle) / vv;
k2 x = vv * cos(angle);
k2 y = vv * sin(angle);
angle = theta(i-2); vv = v(i-2);
k3 vel = -g*sin(angle) - g*c*vv*vv;
k3 angle = -g*cos(angle) / vv;
k3 x = vv * cos(angle);
k3 y = vv * sin(angle);
angle = theta(i-3); vv = v(i-3);
k4 vel = -g*sin(angle) - g*c*vv*vv;
k4 angle = -g*cos(angle) / vv;
k4 x = vv * cos(angle);
k4 y = vv * sin(angle);
% Use Equation 1.7.35 and Equation 1.7.36 for v, x, y and θ
v(i+1) = v(i) + h*(55*k1 vel-59*k2 vel+37*k3 vel-9*k4 vel)/24;
x(i+1) = x(i) + h*(55*k1 x-59*k2 x+37*k3 x-9*k4 x)/24;
y(i+1) = y(i) + h*(55*k1 y-59*k2 y+37*k3 y-9*k4 y)/24;
theta(i+1) = theta(i) + h*(55*k1 angle-59*k2 angle ...
+37*k3 angle-9*k4 angle)/24;
end

First-Order Ordinary Diﬀerential Equations
43
0
20
40
60
80
100
120
140
160
180
0
10
20
30
40
50
60
70
80
 x
 y
k = 0.000548
k = 0
Figure 1.7.3: The trajectory of a projectile with and without air resistance when it is initial ﬁred with a
muzzle velocity of 44.69 m/s and an elevation of θ = 60◦. All units are in the MKS system.
Figure 1.7.3 illustrates this numerical solution when k = 0 and k = 0.000548 s2/m2
and the shell is ﬁred with the initial velocity v(0) = 44.69 m/s and elevation θ(0) = π/3
with x(0) = y(0) = 0.
Problems
Using Euler’s, Runge-Kutta, or the Adams-Bashforth method for various values of h =
10−n, ﬁnd the numerical solution for the following initial-value problems.
Check your
answer by ﬁnding the exact solution.
1. x′ = x −t,
x(0) = 2
2. x′ = tx,
x(0) = 1
3. x′ = x2/(t + 1),
x(0) = 1
4. x′ = x + e−t,
x(1) = 0
5. Consider the integro-diﬀerential equation
dx
dt +
Z t
0
x(τ) dτ + B sgn(x)|x|β = 1,
B, β ≥0,
where the signum function is deﬁned by Equation 11.2.11.
This equation describes the
(nondimensional) current,16 x(t), within an electrical circuit that contains a capacitor,
inductor, and nonlinear resistor. Assuming that the circuit is initially dead, x(0) = 0, write
a MATLAB script that uses Euler’s method to compute x(t). Use a simple Riemann sum to
approximate the integral. See Figure 1.7.4. Examine the solution for various values of B
and β as well as time step ∆t.
16 Monahan, T. F., 1960: Calculation of the current in non-linear surge-current-generation circuits. Proc.
IEE, Part C, 107, 288–291.

44
Advanced Engineering Mathematics with MATLAB
0
5
10
−1
−0.5
0
0.5
1
time
x(t)
B = 0
0
5
10
−0.5
0
0.5
1
time
x(t)
B = 0.2
0
5
10
−0.5
0
0.5
1
time
x(t)
B = 0.4
0
5
10
−0.5
0
0.5
1
time
x(t)
B = 0.6
Figure 1.7.4: The numerical solution of the equation describing an electrical circuit with a nonlinear
resistor. Here β = 0.2 and ∆t = 0.01.
Further Readings
Boyce, W. E., and R. C. DiPrima, 2004: Elementary Diﬀerential Equations and Boundary
Value Problems. Wiley, 800 pp. Classic textbook.
Ince, E. L., 1956: Ordinary Diﬀerential Equations. Dover, 558 pp. The source book on
ordinary diﬀerential equations.
Zill, D. G., and M. R. Cullen, 2008: Diﬀerential Equations with Boundary-Value Problems.
Brooks Cole, 640 pp. Nice undergraduate textbook.

Chapter 2
Higher-Order Ordinary
Diﬀerential Equations
Although ﬁrst-order ordinary diﬀerential equations exhibit most of the properties of
diﬀerential equations, higher-order ordinary diﬀerential equations are more ubiquitous in
the sciences and engineering. This chapter is devoted to the most commonly employed
techniques for their solution.
A linear nth-order ordinary diﬀerential equation is a diﬀerential equation of the form
an(x)dny
dxn + an−1(x)dn−1y
dxn−1 + · · · + a1(x)dy
dx + a0(x)y = f(x).
(2.0.1)
If f(x) = 0, then Equation 2.0.1 is said to be homogeneous; otherwise, it is nonhomogeneous.
A linear diﬀerential equation is normal on an interval I if its coeﬃcients and f(x) are
continuous, and the value of an(x) is never zero on I.
Solutions to Equation 2.0.1 generally must satisfy not only the diﬀerential equations
but also certain speciﬁed conditions at one or more points.
Initial-value problems are
problems where all of the conditions are speciﬁed at a single point x = a and have the
form: y(a) = b0, y′(a) = b1, y′′(a) = b2, ...., y(n−1)(a) = bn−1, where b0, b1, b2, ...., bn−1
are arbitrary constants. A quick check shows that if Equation 2.0.1 is homogeneous and
normal on an interval I and all of the initial conditions equal zero at the point x = a that
lies in I, then y(x) ≡0 on I. This follows because y = 0 is a solution of Equation 2.0.1 and
satisﬁes the initial conditions.
45

46
Advanced Engineering Mathematics with MATLAB
At this point a natural question would be whether the solution exists for this initial-
value problem and, if so, whether it is unique. From a detailed study of this question,1 we
have the following useful theorem.
Theorem: Existence and Uniqueness
Suppose that the diﬀerential equation, Equation 2.0.1, is normal on the open interval
I containing the point x = a. Then, given n numbers b0, b1, . . ., bn−1, the nth-order linear
equation, Equation 2.0.1, has a unique solution on the entire interval I that satisﬁes the n
initial conditions y(a) = b0, y′(a) = b1, . . . , y(n−1)(a) = bn−1.
⊓⊔
• Example 2.0.1
The solution y(x) = 4
3ex−1
3e−2x to the ordinary diﬀerential equation y′′′+2y′′−y′−2y =
0 satisﬁes the initial conditions y(0) = 1, y′(0) = 2, and y′′(0) = 0 at x = 0. Our theorem
guarantees us that this is the only solution with these initial values.
⊓⊔
Another class of problems, commonly called (two-point) boundary-value problems, oc-
curs when conditions are speciﬁed at two diﬀerent points x = a and x = b with b > a.
An important example, in the case of second-order ordinary diﬀerential equations, is the
Sturm-Liouville problem where the boundary conditions are α1y(a) + β1y′(a) = 0 at x = a
and α2y(b) + β2y′(b) = 0 at x = b. The Sturm-Liouville problem is treated in Chapter 6.
Having introduced some of the terms associated with higher-order ordinary linear dif-
ferential equations, how do we solve them? One way is to recognize that these equations
are really a set of linear, ﬁrst-order ordinary diﬀerential equations. For example, the linear
second-order linear diﬀerential equation
y′′ −3y′ + 2y = 3x
(2.0.2)
can be rewritten as the following system of ﬁrst-order ordinary diﬀerential equations:
y′ −y = v,
and
v′ −2v = 3x
(2.0.3)
because
y′′ −y′ = v′ = 2v + 3x = 2y′ −2y + 3x,
(2.0.4)
which is the same as Equation 2.0.2. This suggests that Equation 2.0.2 can be solved by
applying the techniques from the previous chapter. Proceeding along this line, we ﬁrst ﬁnd
that
v(x) = C1e2x −3
2x −3
4.
(2.0.5)
Therefore,
y′ −y = C1e2x −3
2x −3
4.
(2.0.6)
Again, applying the techniques from the previous chapter, we have that
y = C1e2x + C2ex + 3
2x + 9
4.
(2.0.7)
Note that the solution to this second-order ordinary diﬀerential equation contains two ar-
bitrary constants.
1 The proof of the existence and uniqueness of solutions to Equation 2.0.1 is beyond the scope of this
book. See Ince, E. L., 1956: Ordinary Diﬀerential Equations. Dover Publications, Inc., Section 3.32.

Higher-Order Ordinary Diﬀerential Equations
47
• Example 2.0.2
In the case of linear, second-order ordinary diﬀerential equations, a similar technique,
called reduction in order, provides a method for solving diﬀerential equations if we know
one of its solutions.
Consider the second-order ordinary diﬀerential equation
x2y′′ −5xy′ + 9y = 0.
(2.0.8)
A quick check shows that y1(x) = x3 ln(x) is a solution of Equation 2.0.8. Let us now
assume that the general solution can be written y(x) = u(x)x3 ln(x). Then
y′ = u′(x)x3 ln(x) + u(x)

3x2 ln(x) + x2
,
(2.0.9)
and
y′′ = u′′(x)x3 ln(x) + 2u′(x)

3x2 ln(x) + x2
+ u(x) [6x ln(x) + 5x] .
(2.0.10)
Substitution of y(x), y′(x), and y′′(x) into (2.0.8) yields
x5 ln(x)u′′ +

x4 ln(x) + 2x4
u′ = 0.
(2.0.11)
Setting u′ = w, separation of variables leads to
w′
w = −1
x −
2
x ln(x).
(2.0.12)
Note how our replacement of u′(x) with w(x) has reduced the second-order ordinary diﬀer-
ential equation to a ﬁrst-order one. Solving Equation 2.0.12, we ﬁnd that
w(x) = u′(x) = −
C1
x ln2(x),
(2.0.13)
and
u(x) =
C1
ln(x) + C2.
(2.0.14)
Because y(x) = u(x)x3 ln(x), the complete solution is
y(x) = C1x3 + C2x3 ln(x).
(2.0.15)
Substitution of Equation 2.0.15 into Equation 2.0.8 conﬁrms that we have the correct solu-
tion.
We can verify our answer by using the symbolic toolbox in MATLAB. Typing the com-
mand:
dsolve(’x*x*D2y-5*x*Dy+9*y=0’,’x’)
yields
ans =
C1*x^3+C2*x^3*log(x)
⊓⊔

48
Advanced Engineering Mathematics with MATLAB
In summary, we can reduce (in principle) any higher-order, linear ordinary diﬀerential
equations into a system of ﬁrst-order ordinary diﬀerential equations. This system of diﬀer-
ential equations can then be solved using techniques from the previous chapter. In Chapter
3 we will pursue this idea further. Right now, however, we will introduce methods that
allow us to ﬁnd the solution in a more direct manner.
• Example 2.0.3
An autonomous diﬀerential equation is one where the independent variable does not
appear explicitly. In certain cases we can reduce the order of the diﬀerential equation and
then solve it.
Consider the autonomous ordinary diﬀerential equation
y′′ = 2y3.
(2.0.16)
The trick here is to note that
y′′ = dv
dx = v dv
dy = 2y3,
(2.0.17)
where v = dy/dx. Integrating both sides of Equation 2.0.17, we ﬁnd that
v2 = y4 + C1.
(2.0.18)
Solving for v,
dy
dx = v =
p
C1 + y4.
(2.0.19)
Integrating once more, we have the ﬁnal result that
x + C2 =
Z
dy
p
C1 + y4 .
(2.0.20)
Problems
For the following diﬀerential equations, use reduction of order to ﬁnd a second solution.
Can you obtain the general solution using dsolve in MATLAB?
1. xy′′ + 2y′ = 0,
y1(x) = 1
2. y′′ + y′ −2y = 0,
y1(x) = ex
3. x2y′′ + 4xy′ −4y = 0,
y1(x) = x
4. xy′′ −(x + 1)y′ + y = 0,
y1(x) = ex
5. (2x −x2)y′′ + 2(x −1)y′ −2y = 0,
6. y′′ + tan(x)y′ −6 cot2(x)y = 0,
y1(x) = x −1
y1(x) = sin3(x)
7. 4x2y′′ + 4xy′ + (4x2 −1)y = 0,
8. y′′ + ay′ + b(1 + ax −bx2)y = 0,
y1(x) = cos(x)/√x
y1(x) = e−bx2/2
Solve the following autonomous ordinary diﬀerential equations:
9. yy′′ = y′2
10. y′′ = 2yy′,
y(0) = y′(0) = 1

Higher-Order Ordinary Diﬀerential Equations
49
11. yy′′ = y′ + y′2
12. 2yy′′ = 1 + y′2
13. y′′ = e2y,
y(0) = 0, y′(0) = 1
14. y′′′ = 3yy′,
y(0) = y′(0) = 1, y′′(0) = 3
2
15. Solve the nonlinear second-order ordinary diﬀerential equation
d2y
dx2 −1
x
dy
dx −1
2
dy
dx
2
= 0
by (1) reducing it to the Bernoulli equation
dv
dx −v
x −v2
2 = 0,
v(x) = u′(x),
(2) solving for v(x), and ﬁnally (3) integrating u′ = v to ﬁnd u(x).
16. Consider the diﬀerential equation
a2(x)y′′ + a1(x)y′ + a0(x)y = 0,
a2(x) ̸= 0.
Show that this ordinary diﬀerential equation can be rewritten
u′′ + f(x)u = 0,
f(x) = a0(x)
a2(x) −1
4
a1(x)
a2(x)
2
−1
2
d
dx
a1(x)
a2(x)

,
using the substitution
y(x) = u(x) exp

−1
2
Z x a1(ξ)
a2(ξ) dξ

.
2.1 HOMOGENEOUS LINEAR EQUATIONS WITH CONSTANT COEFFICIENTS
In our drive for more eﬃcient methods to solve higher-order, linear, ordinary diﬀerential
equations, let us examine the simplest possible case of a homogeneous diﬀerential equation
with constant coeﬃcients:
an
dny
dxn + an−1
dn−1y
dxn−1 + · · · + a2y′′ + a1
dy
dx + a0y = 0.
(2.1.1)
Although we could explore Equation 2.1.1 in its most general form, we will begin by studying
the second-order version, namely
ay′′ + by′ + cy = 0,
(2.1.2)
since it is the next step up the ladder in complexity from ﬁrst-order ordinary diﬀerential
equations.
Motivated by the fact that the solution to the ﬁrst-order ordinary diﬀerential equation
y′ + ay = 0 is y(x) = C1e−ax, we make the educated guess that the solution to Equation
2.1.2 is y(x) = Aemx. Direct substitution into Equation 2.1.2 yields
 am2 + bm + c

Aemx = 0.
(2.1.3)

50
Advanced Engineering Mathematics with MATLAB
The constant A cannot equal 0 because that would give y(x) = 0 and we would have a
trivial solution. Furthermore, since emx ̸= 0 for arbitrary x, Equation 2.1.3 simpliﬁes to
am2 + bm + c = 0.
(2.1.4)
Equation 2.1.4 is called the auxiliary or characteristic equation. At this point we must
consider three separate cases.
• Distinct real roots
In this case the roots to Equation 2.1.4 are real and unequal. Let us denote these roots
by m = m1, and m = m2. Thus, we have the two solutions:
y1(x) = C1em1x,
and
y2(x) = C2em2x.
(2.1.5)
We will now show that the most general solution to Equation 2.1.2 is
y(x) = C1em1x + C2em2x.
(2.1.6)
This result follows from the principle of (linear) superposition.
Theorem: Let y1, y2, . . . , yk be solutions of the homogeneous equation, Equation 2.1.1, on
an interval I. Then the linear combination
y(x) = C1y1(x) + C2y2(x) + · · · + Ckyk(x),
(2.1.7)
where Ci, i = 1, 2, . . . , k, are arbitrary constants, is also a solution on the interval I.
Proof : We will prove this theorem for second-order ordinary diﬀerential equations; it is
easily extended to higher orders. By the superposition principle, y(x) = C1y1(x)+C2y2(x).
Upon substitution into Equation 2.1.2, we have that
a (C1y′′
1 + C2y′′
2) + b (C1y′
1 + C2y′
2) + c (C1y1 + C2y2) = 0.
(2.1.8)
Recombining the terms, we obtain
C1 (ay′′
1 + by′
1 + cy1) + C2 (ay′′
2 + by′
2 + cy2) = 0,
(2.1.9)
or
0C1 + 0C2 = 0.
(2.1.10)
⊓⊔
• Example 2.1.1
A quick check shows that y1(x) = ex and y2(x) = e−x are two solutions of y′′ −y = 0.
Our theorem tells us that any linear combination of these solutions, such as y(x) = 5ex −
3e−x, is also a solution.
How about the converse? Is every solution to y′′ −y = 0 a linear combination of y1(x)
and y2(x)? We will address this question shortly.
⊓⊔

Higher-Order Ordinary Diﬀerential Equations
51
• Example 2.1.2
Let us ﬁnd the general solution to
y′′ + 2y′ −15y = 0.
(2.1.11)
Assuming a solution of the form y(x) = Aemx, we have that
(m2 + 2m −15)Aemx = 0.
(2.1.12)
Because A ̸= 0 and emx generally do not equal zero, we obtain the auxiliary or characteristic
equation
m2 + 2m −15 = (m + 5)(m −3) = 0.
(2.1.13)
Therefore, the general solution is
y(x) = C1e3x + C2e−5x.
(2.1.14)
⊓⊔
• Repeated real roots
When m = m1 = m2, we have only the single exponential solution y1(x) = C1em1x.
To ﬁnd the second solution we apply the reduction of order technique shown in Example
2.0.2. Performing the calculation, we ﬁnd
y2(x) = C2em1x
Z e−bx/a
e2m1x dx.
(2.1.15)
Since m1 = −b/(2a), the integral simpliﬁes to
R
dx and
y(x) = C1em1x + C2xem1x.
(2.1.16)
• Example 2.1.3
Let us ﬁnd the general solution to
y′′ + 4y′ + 4y = 0.
(2.1.17)
Here the auxiliary or characteristic equation is
m2 + 4m + 4 = (m + 2)2 = 0.
(2.1.18)
Therefore, the general solution is
y(x) = (C1 + C2x)e−2x.
(2.1.19)
⊓⊔

52
Advanced Engineering Mathematics with MATLAB
• Complex conjugate roots
When b2 −4ac < 0, the roots become the complex pair m1 = α + iβ and m2 = α −βi,
where α and β are real and i2 = −1. Therefore, the general solution is
y(x) = C1e(α+iβ)x + C2e(α−βi)x.
(2.1.20)
Although Equation 2.1.20 is quite correct, most engineers prefer to work with real
functions rather than complex exponentials.
To this end, we apply Euler’s formula2 to
eliminate eiβx and e−iβx since
eiβx = cos(βx) + i sin(βx),
(2.1.21)
and
e−iβx = cos(βx) −i sin(βx).
(2.1.22)
Therefore,
y(x) = C1eαx [cos(βx) + i sin(βx)] + C2eαx [cos(βx) −i sin(βx)]
(2.1.23)
= C3eαx cos(βx) + C4eαx sin(βx),
(2.1.24)
where C3 = C1 + C2, and C4 = iC1 −iC2.
• Example 2.1.4
Let us ﬁnd the general solution to
y′′ + 4y′ + 5y = 0.
(2.1.25)
Here the auxiliary or characteristic equation is
m2 + 4m + 5 = (m + 2)2 + 1 = 0,
(2.1.26)
or m = −2 ± i. Therefore, the general solution is
y(x) = e−2x[C1 cos(x) + C2 sin(x)].
(2.1.27)
⊓⊔
So far we have only dealt with second-order diﬀerential equations.
When we turn
to higher-order ordinary diﬀerential equations, similar considerations hold.
In place of
Equation 2.1.4, we now have the nth-degree polynomial equation
anmn + an−1mn−1 + · · · + a2m2 + a1m + a0 = 0
(2.1.28)
for its auxiliary equation.
When we treated second-order ordinary diﬀerential equations, we were able to classify
the roots to the auxiliary equation as distinct real roots, repeated roots, and complex
roots. In the case of higher-order diﬀerential equations, such classiﬁcations are again useful
2 If you are unfamiliar with Euler’s formula, see Section 10.1.

Higher-Order Ordinary Diﬀerential Equations
53
although all three types may occur with the same equation. For example, the auxiliary
equation
m6 −m5 + 2m4 −2m3 + m2 −m = 0
(2.1.29)
has the distinct roots m = 0 and m = 1 with the twice repeated, complex roots m = ±i.
Although the possible combinations increase with higher-order diﬀerential equations,
the solution technique remains the same. For each distinct real root m = m1, we have a
corresponding homogeneous solution em1x. For each complex pair m = α ± βi, we have the
corresponding pair of homogeneous solutions eαx cos(βx) and eαx sin(βx). For a repeated
root m = m1 of multiplicity k, regardless of whether it is real or complex, we have either
em1x, xem1x, x2em1x, . . . , xkem1x in the case of real m1 or
eαx cos(βx), eαx sin(βx), xeαx cos(βx), xeαx sin(βx),
x2eαx cos(βx), x2eαx sin(βx), . . . , xkeαx cos(βx), xkeαx sin(βx)
in the case of complex roots α ± βi. For example, the general solution for the roots to
Equation 2.1.29 is
y(x) = C1 + C2ex + C3 cos(x) + C4 sin(x) + C5x cos(x) + C6x sin(x).
(2.1.30)
• Example 2.1.5
Let us ﬁnd the general solution to
y′′′ + y′ −10y = 0.
(2.1.31)
Here the auxiliary or characteristic equation is
m3 + m −10 = (m −2)(m2 + 2m + 5) = (m −2)[(m + 1)2 + 4] = 0,
(2.1.32)
or m = −2 and m = −1 ± 2i. Therefore, the general solution is
y(x) = C1e−2x + e−x[C2 cos(2x) + C3 sin(2x)].
(2.1.33)
⊓⊔
Having presented the technique for solving constant coeﬃcient, linear, ordinary diﬀer-
ential equations, an obvious question is: How do we know that we have captured all of the
solutions? Before we can answer this question, we must introduce the concept of linear
dependence.
A set of functions f1(x), f2(x), . . . , fn(x) is said to be linearly dependent on an interval
I if there exist constants C1, C2, . . . , Cn, not all zero, such that
C1f1(x) + C2f2(x) + C3f3(x) + · · · + Cnfn(x) = 0
(2.1.34)
for each x in the interval; otherwise, the set of functions is said to be linearly independent.
This concept is easily understood when we have only two functions f1(x) and f2(x). If the
functions are linearly dependent on an interval, then there exist constants C1 and C2 that
are not both zero, where
C1f1(x) + C2f2(x) = 0
(2.1.35)

54
Advanced Engineering Mathematics with MATLAB
for every x in the interval. If C1 ̸= 0, then
f1(x) = −C2
C1
f2(x).
(2.1.36)
In other words, if two functions are linearly dependent, then one is a constant multiple of
the other. Conversely, two functions are linearly independent when neither is a constant
multiple of the other on an interval.
• Example 2.1.6
Let us show that f(x) = 2x, g(x) = 3x2, and h(x) = 5x −8x2 are linearly dependent
on the real line.
To show this, we must choose three constants, C1, C2, and C3, such that
C1f(x) + C2g(x) + C3h(x) = 0,
(2.1.37)
where not all of these constants are nonzero. A quick check shows that
15f(x) −16g(x) −6h(x) = 0.
(2.1.38)
Clearly, f(x), g(x), and h(x) are linearly dependent.
⊓⊔
• Example 2.1.7
This example shows the importance of deﬁning the interval on which a function is
linearly dependent or independent. Consider the two functions f(x) = x and g(x) = |x|.
They are linearly dependent on the interval (0, ∞) since C1x + C2|x| = C1x + C2x = 0
is satisﬁed for any nonzero choice of C1 and C2 where C1 = −C2. What happens on the
interval (−∞, 0)? They are still linearly dependent but now C1 = C2.
⊓⊔
Although we could use the fundamental concept of linear independence to check and see
whether a set of functions is linearly independent or not, the following theorem introduces
a procedure that is very straightforward.
Theorem: Wronskian Test of Linear Independence
Suppose f1(x), f2(x), . . . , fn(x) possess at least n −1 derivatives. If the determinant3

f1
f2
· · ·
fn
f ′
1
f ′
2
· · ·
f ′
n
...
...
...
f (n−1)
1
f (n−1)
2
· · ·
f (n−1)
n

is not zero for at least one point in the interval I, then the functions f1(x), f2(x), . . . , fn(x)
are linearly independent on the interval. The determinant in this theorem is denoted by
W[f1(x), f2(x), . . . , fn(x)] and is called the Wronskian of the functions.
3 If you are unfamiliar with determinants, see Section 3.2.

Higher-Order Ordinary Diﬀerential Equations
55
Proof : We prove this theorem by contradiction when n = 2. Let us assume that W[f1(x0),
f2(x0)] ̸= 0 for some ﬁxed x0 in the interval I and that f1(x) and f2(x) are linearly
dependent on the interval. Since the functions are linearly dependent, there exists C1 and
C2, both not zero, for which
C1f1(x) + C2f2(x) = 0
(2.1.39)
for every x in I. Diﬀerentiating Equation 2.1.39 gives
C1f ′
1(x) + C2f ′
2(x) = 0.
(2.1.40)
We may view Equation 2.1.39 and Equation 2.1.40 as a system of equations with C1 and C2
as the unknowns. Because the linear dependence of f1 and f2 implies that C1 ̸= 0 and/or
C2 ̸= 0 for each x in the interval,
W[f1(x), f2(x)] =

f1
f2
f ′
1
f ′
2
 = 0
(2.1.41)
for every x in I. This contradicts the assumption that W[f1(x0), f2(x0)] ̸= 0 and f1 and f2
are linearly independent.
⊓⊔
• Example 2.1.8
Are the functions f(x) = x, g(x) = xex, and h(x) = x2ex linearly dependent on the
real line? To ﬁnd out, we compute the Wronskian or
W[f(x), g(x), h(x)] =

ex
xex
x2ex
ex
(x + 1)ex
(x2 + 2x)ex
ex
(x + 2)ex
(x2 + 4x + 2)ex

= e3x

1
x
x2
0
1
2x
0
0
2

= 2e3x ̸= 0.
(2.1.42)
Therefore, x, xex, and x2ex are linearly independent.
⊓⊔
Having introduced this concept of linear independence, we are now ready to address
the question of how many linearly independent solutions a homogeneous linear equation
has.
Theorem:
On any interval I over which an n-th order homogeneous linear diﬀerential equation is
normal, the equation has n linearly independent solutions y1(x), y2(x), . . . , yn(x) and any
particular solution of the equation on I can be expressed as a linear combination of these
linearly independent solutions.
Proof : Again for convenience and clarity we prove this theorem for the special case of n = 2.
Let y1(x) and y2(x) denote solutions on I of Equation 2.1.2. We know that these solutions
exist by the existence theorem and have the following values:
y1(a) = 1,
y2(a) = 0,
y′
1(a) = 0,
y′
2(a) = 1
(2.1.43)
at some point a on I. To establish the linear independence of y1 and y2 we note that,
if C1y1(x) + C2y2(x) = 0 holds identically on I, then C1y′
1(x) + C2y′
2(x) = 0 there too.
Because x = a lies in I, we have that
C1y1(a) + C2y2(a) = 0,
(2.1.44)

56
Advanced Engineering Mathematics with MATLAB
and
C1y′
1(a) + C2y′
2(a) = 0,
(2.1.45)
which yields C1 = C2 = 0 after substituting Equation 2.1.43. Hence, the solutions y1 and
y2 are linearly independent.
To complete the proof we must now show that any particular solution of Equation
2.1.2 can be expressed as a linear combination of y1 and y2. Because y, y1, and y2 are all
solutions of Equation 2.1.2 on I, so is the function
Y (x) = y(x) −y(a)y1(x) −y′(a)y2(x),
(2.1.46)
where y(a) and y′(a) are the values of the solution y and its derivative at x = a. Evaluating
Y and Y ′ at x = a, we have that
Y (a) = y(a) −y(a)y1(a) −y′(a)y2(a) = y(a) −y(a) = 0,
(2.1.47)
and
Y ′(a) = y′(a) −y(a)y′
1(a) −y′(a)y′
2(a) = y′(a) −y′(a) = 0.
(2.1.48)
Thus, Y is the trivial solution to Equation 2.1.2. Hence, for every x in I,
y(x) −y(a)y1(x) −y′(a)y2(x) = 0.
(2.1.49)
Solving Equation 2.1.49 for y(x), we see that y is expressible as the linear combination
y(x) = y(a)y1(x) + y′(a)y2(x)
(2.1.50)
of y1 and y2, and the proof is complete for n = 2.
Problems
Find the general solution to the following diﬀerential equations. Check your general solution
by using dsolve in MATLAB.
1. y′′ + 6y′ + 5y = 0
2. y′′ −6y′ + 10y = 0
3. y′′ −2y′ + y = 0
4. y′′ −3y′ + 2y = 0
5. y′′ −4y′ + 8y = 0
6. y′′ + 6y′ + 9y = 0
7. y′′ + 6y′ −40y = 0
8. y′′ + 4y′ + 5y = 0
9. y′′ + 8y′ + 25y = 0
10. 4y′′ −12y′ + 9y = 0
11. y′′ + 8y′ + 16y = 0
12. y′′′ + 4y′′ = 0
13. y′′′′ + 4y′′ = 0
14. y′′′′ + 2y′′′ + y′′ = 0
15. y′′′ −8y = 0
16. y′′′′ −3y′′′ + 3y′′ −y′ = 0
17. The simplest diﬀerential equation with “memory” — its past behavior aﬀects the present
— is
y′ = −A
2τ
Z t
−∞
e−(t−x)/τy(x) dx.
Solve this integro-diﬀerential equation by diﬀerentiating it with respect to t to eliminate
the integral.

Higher-Order Ordinary Diﬀerential Equations
57
                                       


                                       


                                       


m
m
L+s
s
L
L
x
(a)
(b)
(c)
Figure 2.2.1: Various conﬁgurations of a mass/spring system. The spring alone has a length L, which
increases to L+s when the mass is attached. During simple harmonic motion, the length of the mass/spring
system varies as L + s + x.
2.2 SIMPLE HARMONIC MOTION
Second-order, linear, ordinary diﬀerential equations often arise in mechanical or elec-
trical problems. The purpose of this section is to illustrate how the techniques that we just
derived may be applied to these problems.
We begin by considering the mass-spring system illustrated in Figure 2.2.1 where a
mass m is attached to a ﬂexible spring suspended from a rigid support.
If there were
no spring, then the mass would simply fall downward due to the gravitational force mg.
Because there is no motion, the gravitational force must be balanced by an upward force
due to the presence of the spring. This upward force is usually assumed to obey Hooke’s
law, which states that the restoring force is opposite to the direction of elongation and
proportional to the amount of elongation. Mathematically the equilibrium condition can
be expressed mg = ks.
Consider now what happens when we disturb this equilibrium.
This may occur in
one of two ways: We could move the mass either upward or downward and then release
it. Another method would be to impart an initial velocity to the mass. In either case,
the motion of the mass/spring system would be governed by Newton’s second law, which
states that the acceleration of the mass equals the imbalance of the forces. If we denote the
downward displacement of the mass from its equilibrium position by positive x, then
md2x
dt2 = −k(s + x) + mg = −kx,
(2.2.1)
since ks = mg. After dividing Equation 2.2.1 by the mass, we obtain the second-order
diﬀerential equation
d2x
dt2 + k
mx = 0,
(2.2.2)
or
d2x
dt2 + ω2x = 0,
(2.2.3)
where ω2 = k/m and ω is the circular frequency. Equation 2.2.3 describes simple harmonic
motion or free undamped motion. The two initial conditions associated with this diﬀerential

58
Advanced Engineering Mathematics with MATLAB
Summary of Simple Harmonic Motion
Displacement,x(t)
Initial 
displacement
Phase =ϕ
Time,
Amplitude,A
velocity
Maximum
2π
ω
x0
Period
ωt
Velocity = 0
x(t) =

x2
0 + v2
0
ω2
1/2
sin(ωt + ϕ)
ϕ = tan−1
ωx0
v0

,
v0 = initial velocity
equation are
x(0) = α,
x′(0) = β.
(2.2.4)
The ﬁrst condition gives the initial amount of displacement while the second condition
speciﬁes the initial velocity. If α > 0 while β < 0, then the mass starts from a point below
the equilibrium position with an initial upward velocity. On the other hand, if α < 0 with
β = 0 the mass is at rest when it is released |α| units above the equilibrium position. Similar
considerations hold for other values of α and β.
To solve Equation 2.2.3, we note that the solutions of the auxiliary equation m2+ω2 = 0
are the complex numbers m1 = ωi, and m2 = −ωi. Therefore, the general solution is
x(t) = A cos(ωt) + B sin(ωt).
(2.2.5)
The (natural) period of free vibrations is T = 2π/ω while the (natural) frequency is f =
1/T = ω/(2π).
• Example 2.2.1
Let us solve the initial-value problem
d2x
dt2 + 4x = 0,
x(0) = 10,
x′(0) = 0.
(2.2.6)
The physical interpretation is that we have pulled the mass on a spring down 10 units
below the equilibrium position and then release it from rest at t = 0. Here, ω = 2 so that
x(t) = A cos(2t) + B sin(2t)
(2.2.7)
from Equation 2.2.5.

Higher-Order Ordinary Diﬀerential Equations
59
Because x(0) = 10, we ﬁnd that
x(0) = 10 = A · 1 + B · 0
(2.2.8)
so that A = 10. Next, we note that
dx
dt = −20 sin(2t) + 2B cos(2t).
(2.2.9)
Therefore, at t = 0,
x′(0) = 0 = −20 · 0 + 2B · 1
(2.2.10)
and B = 0. Thus, the equation of motion is x(t) = 10 cos(2t).
What is the physical interpretation of our equation of motion? Once the system is set
into motion, it stays in motion with the mass oscillating back and forth 10 units above and
below the equilibrium position x = 0. The period of oscillation is 2π/2 = π units of time.⊓⊔
• Example 2.2.2
A weight of 45 N stretches a spring 5 cm. At time t = 0, the weight is released from
its equilibrium position with an upward velocity of 28 cm s−1. Determine the displacement
x(t) that describes the subsequent free motion.
From Hooke’s law,
F = mg = 45 N = k × 5 cm
(2.2.11)
so that k = 9 N cm−1. Therefore, the diﬀerential equation is
d2x
dt2 + 196 s−2x = 0.
(2.2.12)
The initial displacement and initial velocity are x(0) = 0 cm and x′(0) = −28 cm s−1. The
negative sign in the initial velocity reﬂects the fact that the weight has an initial velocity
in the negative or upward direction.
Because ω2 = 196 s−2 or ω = 14 s−1, the general solution to the diﬀerential equation
is
x(t) = A cos(14 s−1t) + B sin(14 s−1t).
(2.2.13)
Substituting for the initial displacement x(0) in Equation 2.2.13, we ﬁnd that
x(0) = 0 cm = A · 1 + B · 0,
(2.2.14)
and A = 0 cm. Therefore,
x(t) = B sin(14 s−1t)
(2.2.15)
and
x′(t) = 14 s−1B cos(14 s−1t).
(2.2.16)
Substituting for the initial velocity,
x′(0) = −28 cm s−1 = 14 s−1B,
(2.2.17)
and B = −2 cm. Thus the equation of motion is
x(t) = −2 cm sin(14 s−1t).
(2.2.18)

60
Advanced Engineering Mathematics with MATLAB
h
A
x
equilibrium
static
Figure 2.2.2: Schematic of a ﬂoating body partially submerged in pure water.
⊓⊔
• Example 2.2.3: Vibration of ﬂoating bodies
Consider a solid cylinder of radius a that is partially submerged in a bath of pure water
as shown in Figure 2.2.2. Let us ﬁnd the motion of this cylinder in the vertical direction
assuming that it remains in an upright position.
If the displacement of the cylinder from its static equilibrium position is x, the weight of
water displaced equals Agρwx, where ρw is the density of the water and g is the gravitational
acceleration. This is the restoring force according to the Archimedes principle. The mass
of the cylinder is Ahρ, where ρ is the density of cylinder. From second Newton’s law, the
equation of motion is
ρAhx′′ + Agρwx = 0,
(2.2.19)
or
x′′ + ρwg
ρh x = 0.
(2.2.20)
From Equation 2.2.20 we see that the cylinder will oscillate about its static equilibrium
position x = 0 with a frequency of
ω =
ρwg
ρh
1/2
.
(2.2.21)
⊓⊔
When both A and B are both nonzero, it is often useful to rewrite the homogeneous
solution, Equation 2.2.5, as
x(t) = C sin(ωt + ϕ)
(2.2.22)
to highlight the amplitude and phase of the oscillation. Upon employing the trigonometric
angle-sum formula, Equation 2.2.22 can be rewritten
x(t) = C sin(ωt) cos(ϕ) + C cos(ωt) sin(ϕ) = A cos(ωt) + B sin(ωt).
(2.2.23)
From Equation 2.2.23, we see that A = C sin(ϕ) and B = C cos(ϕ). Therefore,
A2 + B2 = C2 sin2(ϕ) + C2 cos2(ϕ) = C2,
(2.2.24)
and C =
√
A2 + B2. Similarly, tan(ϕ) = A/B. Because the tangent is positive in both the
ﬁrst and third quadrants and negative in both the second and fourth quadrants, there are

Higher-Order Ordinary Diﬀerential Equations
61
two possible choices for ϕ. The proper value of ϕ satisﬁes the equations A = C sin(ϕ) and
B = C cos(ϕ).
If we prefer the amplitude/phase solution
x(t) = C cos(ωt −ϕ),
(2.2.25)
we now have
x(t) = C cos(ωt) cos(ϕ) + C sin(ωt) sin(ϕ) = A cos(ωt) + B sin(ωt).
(2.2.26)
Consequently, A = C cos(ϕ) and B = C sin(ϕ). Once again, we obtain C =
√
A2 + B2. On
the other hand, tan(ϕ) = B/A.
Problems
Solve the following initial-value problems and write their solutions in terms of amplitude
and phase:
1. x′′ + 25x = 0,
x(0) = 10,
x′(0) = −10
2. 4x′′ + 9x = 0,
x(0) = 2π,
x′(0) = 3π
3. x′′ + π2x = 0,
x(0) = 1,
x′(0) = π
√
3
4. A 4-kg mass is suspended from a 100 N/m spring. The mass is set in motion by giving it
an initial downward velocity of 5 m/s from its equilibrium position. Find the displacement
as a function of time.
5. A spring hangs vertically. A weight of mass M kg stretches it L m. This weight is
removed. A body weighing m kg is then attached and allowed to come to rest. It is then
pulled down s0 m and released with a velocity v0. Find the displacement of the body from
its point of rest and its velocity at any time t.
6. A particle of mass m moving in a straight line is repelled from the origin by a force
F. (a) If the force is proportional to the distance from the origin, ﬁnd the position of the
particle as a function of time. (b) If the initial velocity of the particle is a
√
k, where k is
the proportionality constant and a is the distance from the origin, ﬁnd the position of the
particle as a function of time. What happens if m < 1 and m = 1?
2.3 DAMPED HARMONIC MOTION
Free harmonic motion is unrealistic because there are always frictional forces that act to
retard motion. In mechanics, the drag is often modeled as a resistance that is proportional
to the instantaneous velocity. Adopting this resistance law, it follows from Newton’s second
law that the harmonic oscillator is governed by
md2x
dt2 = −kx −β dx
dt ,
(2.3.1)
where β is a positive damping constant. The negative sign is necessary since this resistance
acts in a direction opposite to the motion.

62
Advanced Engineering Mathematics with MATLAB
Dividing Equation 2.3.1 by the mass m, we obtain the diﬀerential equation of free
damped motion,
d2x
dt2 + β
m
dx
dt + k
mx = 0,
(2.3.2)
or
d2x
dt2 + 2λdx
dt + ω2x = 0.
(2.3.3)
We have written 2λ rather than just λ because it simpliﬁes future computations.
The
auxiliary equation is m2 + 2λm + ω2 = 0, which has the roots
m1 = −λ +
p
λ2 −ω2,
and
m2 = −λ −
p
λ2 −ω2.
(2.3.4)
From Equation 2.3.4 we see that there are three possible cases which depend on the
algebraic sign of λ2 −ω2. Because all of the solutions contain the damping factor e−λt,
λ > 0, x(t) vanishes as t →∞.
• Case I: λ > ω
Here the system is overdamped because the damping coeﬃcient β is large compared to
the spring constant k. The corresponding solution is
x(t) = Aem1t + Bem2t,
(2.3.5)
or
x(t) = e−λt 
Aet
√
λ2−ω2 + Be−t
√
λ2−ω2
.
(2.3.6)
In this case the motion is smooth and nonoscillatory.
• Case II: λ = ω
The system is critically damped because any slight decrease in the damping force would
result in oscillatory motion. The general solution is
x(t) = Aem1t + Btem1t,
(2.3.7)
or
x(t) = e−λt(A + Bt).
(2.3.8)
The motion is quite similar to that of an overdamped system.
• Case III: λ < ω
In this case the system is underdamped because the damping coeﬃcient is small com-
pared to the spring constant. The roots m1 and m2 are complex:
m1 = −λ + i
p
ω2 −λ2,
and
m2 = −λ −i
p
ω2 −λ2.
(2.3.9)
The general solution now becomes
x(t) = e−λt h
A cos

t
p
ω2 −λ2

+ B sin

t
p
ω2 −λ2
i
.
(2.3.10)

Higher-Order Ordinary Diﬀerential Equations
63
0
2
4
6
8
10
0
0.5
1
1.5
2
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
 ζ
 ω t
 x(t)
Figure 2.3.1: The displacement x(t) of a damped harmonic oscillator as a function of time and ζ = λ/ω.
Equation 2.3.10 describes oscillatory motion that decays as e−λt. Equations 2.3.6, 2.3.8, and
2.3.10 are illustrated in Figure 2.3.1 when the initial conditions are x(0) = 1 and x′(0) = 0.
Just as we could write the solution for the simple harmonic motion in the ampli-
tude/phase format, we can write any damped solution Equation 2.3.10 in the alternative
form
x(t) = Ce−λt sin

t
p
ω2 −λ2 + ϕ

,
(2.3.11)
where C =
√
A2 + B2 and the phase angle ϕ is given by tan(ϕ) = A/B such that A =
C sin(ϕ) and B = C cos(ϕ). The coeﬃcient Ce−λt is sometimes called the damped coeﬃcient
of vibrations. Because Equation 2.3.11 is not a periodic function, the quantity 2π/
√
ω2 −λ2
is called the quasi period and
√
ω2 −λ2 is the quasi frequency. The quasi period is the time
interval between two successive maxima of x(t).
• Example 2.3.1
A body with mass m = 1
2 kg is attached to the end of a spring that is stretched 2 m
by a force of 100 N. Furthermore, there is also attached a dashpot4 that provides 6 N of
resistance for each m/s of velocity. If the mass is set in motion by further stretching the
spring 1
2 m and giving it an upward velocity of 10 m/s, let us ﬁnd the subsequent motion.
We begin by ﬁrst computing the constants. The spring constant is k = (100 N)/(2 m)
= 50 N/m. Therefore, the diﬀerential equation is
1
2x′′ + 6x′ + 50x = 0
(2.3.12)
with x(0) = 1
2 m and x′(0) = −10 m/s. Here the units of x(t) are meters. The characteristic
or auxiliary equation is
m2 + 12m + 100 = (m + 6)2 + 64 = 0,
(2.3.13)
4 A mechanical device — usually a piston that slides within a liquid-ﬁlled cylinder — used to damp the
vibration or control the motion of a mechanism to which is attached.

64
Advanced Engineering Mathematics with MATLAB
Review of the Solution of the
Underdamped Homogeneous Oscillator Problem
mx′′ + βx′ + kx = 0 subject to x(0) = x0, x′(0) = v0 has the solution
x(t) = Ae−λt sin(ωdt + ϕ),
where
ω =
p
k/m is the undamped natural frequency,
λ = β/(2m) is the damping factor,
ωd =
p
ω2 −λ2 is the damped natural frequency,
and the constants A and ϕ are determined by
A =
s
x2
0 +
v0 + λx0
ωd
2
and
ϕ = tan−1

x0ωd
v0 + λx0

.
or m = −6 ± 8i. Therefore, we have an underdamped harmonic oscillator and the general
solution is
x(t) = e−6t [A cos(8t) + B sin(8t)] .
(2.3.14)
Consequently, each cycle takes 2π/8 = 0.79 second. This is longer than the 0.63 second
that would occur if the system were undamped.
From the initial conditions,
x(0) = A = 1
2,
and
x′(0) = −10 = −6A + 8B.
(2.3.15)
Therefore, A = 1
2 and B = −7
8. Consequently,
x(t) = e−6t  1
2 cos(8t) −7
8 sin(8t)

=
√
65
8 e−6t cos(8t + 2.62244).
(2.3.16)
⊓⊔
• Example 2.3.2: Design of a wind vane
In its simplest form a wind vane is a ﬂat plate or airfoil that can rotate about a vertical
shaft. See Figure 2.3.2. In static equilibrium it points into the wind. There is usually a
counterweight to balance the vane about the vertical shaft.
A vane uses a combination of the lift and drag forces on the vane to align itself with
the wind. As the wind shifts direction from θ0 to the new direction θi, the direction θ in
which the vane currently points is governed by the equation of motion5
I d2θ
dt2 + NR
V
dθ
dt = N(θi −θ),
(2.3.17)
5 For a derivation of Equation 2.3.12 and Equation 2.3.13, see subsection 2 of Section 3 in Barthelt,
H. P., and G. H. Ruppersberg, 1957: Die mechanische Windfahne, eine theoretische und experimentelle
Untersuchung. Beitr. Phys. Atmos., 29, 154–185.

Higher-Order Ordinary Diﬀerential Equations
65
ε
Vertical axis of rotation
R
Vane
Wind vector
Figure 2.3.2: Schematic of a wind vane. The counterbalance is not shown.
where I is the vane’s moment of inertia, N is the aerodynamic torque per unit angle, and
R is the distance from the axis of rotation to the eﬀective center of the aerodynamic force
on the vane. The aerodynamic torque is given by
N = 1
2CLρAV 2R,
(2.3.18)
where CL is the lift coeﬃcient, ρ is the air density, A is the vane area, and V is the wind
speed.
Dividing Equation 2.3.17 by I, we obtain the second-order ordinary diﬀerential equation
d2(θ −θi)
dt2
+ NR
IV
d(θ −θi)
dt
+ N
I (θ −θi) = 0.
(2.3.19)
The solution to Equation 2.3.19 is
θ −θi = A exp

−NRt
2IV

cos(ωt + ϕ),
(2.3.20)
where
ω2 = N
I −N 2R2
4I2V 2 ,
(2.3.21)
and A and ϕ are the two arbitrary constants that would be determined by presently unspec-
iﬁed initial conditions. Consequently an ideal wind vane is a damped harmonic oscillator
where the wind torque should be large and its moment of inertia should be small.
Problems
For the following values of m, β, and k, ﬁnd the position x(t) of a damped oscillator for the
given initial conditions:
1. m = 1
2,
β = 3,
k = 4,
x(0) = 2,
x′(0) = 0
2. m = 1,
β = 10,
k = 125,
x(0) = 3,
x′(0) = 25
3. m = 4,
β = 20,
k = 169,
x(0) = 4,
x′(0) = 16
4. For a ﬁxed value of λ/ω, what is the minimum number of cycles required to produce a
reduction of at least 50% in the maxima of an underdamped oscillator?

66
Advanced Engineering Mathematics with MATLAB
5. For what values of c does x′′ + cx′ + 4x = 0 have critically damped solutions?
6. For what values of c are the motions governed by 4x′′ + cx′ + 9x = 0 (a) overdamped,
(b) underdamped, and (c) critically damped?
7. For an overdamped mass-spring system, prove that the mass can pass through its equi-
librium position x = 0 at most once.
2.4 METHOD OF UNDETERMINED COEFFICIENTS
Homogeneous ordinary diﬀerential equations become nonhomogeneous when the right
side of Equation 2.0.1 is nonzero. How does this case diﬀer from the homogeneous one that
we have treated so far?
To answer this question, let us begin by introducing a function yp(x) — called a par-
ticular solution — whose only requirement is that it satisﬁes the diﬀerential equation
an(x)dnyp
dxn + an−1(x)dn−1yp
dxn−1 + · · · + a1(x)dyp
dx + a0(x)yp = f(x).
(2.4.1)
Then, by direct substitution, it can be seen that the general solution to any nonhomoge-
neous, linear, ordinary diﬀerential equation is
y(x) = yH(x) + yp(x),
(2.4.2)
where yH(x) — the homogeneous or complementary solution — satisﬁes
an(x)dnyH
dxn + an−1(x)dn−1yH
dxn−1 + · · · + a1(x)dyH
dx + a0(x)yH = 0.
(2.4.3)
Why have we introduced this complementary solution - because the particular solution
already satisﬁes the ordinary diﬀerential equation.
The purpose of the complementary
solution is to introduce the arbitrary constants that any general solution of an ordinary
diﬀerential equation must have. Thus, because we already know how to ﬁnd yH(x), we
must only invent a method for ﬁnding the particular solution to have our general solution.
• Example 2.4.1
Let us illustrate this technique with the second-order, linear, nonhomogeneous ordinary
diﬀerential equation
y′′ −4y′ + 4y = 2e2x + 4x −12.
(2.4.4)
Taking y(x) = yH(x) + yp(x), direction substitution yields
y′′
H + y′′
p −4(y′
H + y′
p) + 4(yH + yp) = 2e2x + 4x −12.
(2.4.5)
If we now require that the particular solution yp(x) satisﬁes the diﬀerential equation
y′′
p −4y′
p + 4yp = 2e2x + 4x −12,
(2.4.6)
Equation 2.4.5 simpliﬁes to the homogeneous ordinary diﬀerential equation
y′′
H −4y′
H + 4yH = 0.
(2.4.7)

Higher-Order Ordinary Diﬀerential Equations
67
A quick check6 shows that the particular solution to Equation 2.4.6 is yp(x) = x2e2x +x−2.
Using techniques from the previous section, the complementary solution is yH(x) = C1e2x+
C2xe2x.
⊓⊔
In general, ﬁnding yp(x) is a formidable task. In the case of constant coeﬃcients, several
techniques have been developed.
The most commonly employed technique is called the
method of undetermined coeﬃcients, which is used with linear, constant coeﬃcient, ordinary
diﬀerential equations when f(x) is a constant, a polynomial, an exponential function eαx,
sin(βx), cos(βx), or ﬁnite sum and products of these functions. Thus, this technique applies
when the function f(x) equals ex sin(x) −(3x −2)e−2x but not when it equals ln(x).
Why does this technique work? The reason lies in the set of functions that we have
allowed to be included in f(x). They enjoy the remarkable property that derivatives of
their sums and products yield sums and products that are also constants, polynomials,
exponentials, sines, and cosines. Because a linear combination of derivatives such as ay′′
p +
by′
p + cyp must equal f(x), it seems reasonable to assume that yp(x) has the same form as
f(x). The following examples show that our conjecture is correct.
• Example 2.4.2
Let us illustrate the method of undetermined coeﬃcients by ﬁnding the particular
solution to
y′′ −2y′ + y = x + sin(x)
(2.4.8)
by the method of undetermined coeﬃcients.
From the form of the right side of Equation 2.4.8, we guess the particular solution
yp(x) = Ax + B + C sin(x) + D cos(x).
(2.4.9)
Therefore,
y′
p(x) = A + C cos(x) −D sin(x),
(2.4.10)
and
y′′
p(x) = −C sin(x) −D cos(x).
(2.4.11)
Substituting into Equation 2.4.8, we ﬁnd that
y′′
p −2y′
p + yp = Ax + B −2A −2C cos(x) + 2D sin(x) = x + sin(x).
(2.4.12)
Since Equation 2.4.12 must be true for all x, the constant terms must sum to zero or
B −2A = 0. Similarly, all of the terms involving the polynomial x must balance, yielding
A = 1 and B = 2A = 2. Turning to the trigonometric terms, the coeﬃcients of sin(x) and
cos(x) give 2D = 1 and −2C = 0, respectively. Therefore, the particular solution is
yp(x) = x + 2 + 1
2 cos(x),
(2.4.13)
and the general solution is
y(x) = yH(x) + yp(x) = C1ex + C2xex + x + 2 + 1
2 cos(x).
(2.4.14)
6 We will show how yp(x) was obtained momentarily.

68
Advanced Engineering Mathematics with MATLAB
We can verify our result by using the symbolic toolbox in MATLAB. Typing the com-
mand:
dsolve(’D2y-2*Dy+y=x+sin(x)’,’x’)
yields
ans =
x+2+1/2*cos(x)+C1*exp(x)+C2*exp(x)*x
⊓⊔
• Example 2.4.3
Let us ﬁnd the particular solution to
y′′ + y′ −2y = xex
(2.4.15)
by the method of undetermined coeﬃcients.
From the form of the right side of Equation 2.4.15, we guess the particular solution
yp(x) = Axex + Bex.
(2.4.16)
Therefore,
y′
p(x) = Axex + Aex + Bex,
(2.4.17)
and
y′′
p(x) = Axex + 2Aex + Bex.
(2.4.18)
Substituting into Equation 2.4.15, we ﬁnd that
3Aex = xex.
(2.4.19)
Clearly we cannot choose a constant A such that Equation 2.4.19 is satisﬁed. What went
wrong?
To understand why, let us ﬁnd the homogeneous or complementary solution to Equation
2.4.15; it is
yH(x) = C1e−2x + C2ex.
(2.4.20)
Therefore, one of the assumed particular solutions, Bex, is also a homogeneous solution
and cannot possibly give a nonzero left side when substituted into the diﬀerential equation.
Consequently, it would appear that the method of undetermined coeﬃcients does not work
when one of the terms on the right side is also a homogeneous solution.
Before we give up, let us recall that we had a similar situation in the case of linear
homogeneous second-order ordinary diﬀerential equations when the roots from the auxiliary
equation were equal. There we found one of the homogeneous solutions was em1x. We
eventually found that the second solution was xem1x. Could such a solution work here? Let
us try.
We begin by modifying Equation 2.4.16 by multiplying it by x. Thus, our new guess
for the particular solution reads
yp(x) = Ax2ex + Bxex.
(2.4.21)
Then,
y′
p = Ax2ex + 2Axex + Bxex + Bex,
(2.4.22)

Higher-Order Ordinary Diﬀerential Equations
69
and
y′′
p = Ax2ex + 4Axex + 2Aex + Bxex + 2Bex.
(2.4.23)
Substituting Equation 2.4.21 into Equation 2.4.15 gives
y′′
p + y′
p −2yp = 6Axex + 2Aex + 3Bex = xex.
(2.4.24)
Grouping together terms that vary as xex, we ﬁnd that 6A = 1. Similarly, terms that vary
as ex yield 2A + 3B = 0. Therefore,
yp(x) = 1
6x2ex −1
9xex,
(2.4.25)
so that the general solution is
y(x) = yH(x) + yp(x) = C1e−2x + C2ex + 1
6x2ex −1
9xex.
(2.4.26)
⊓⊔
In summary, the method of ﬁnding particular solutions to higher-order ordinary diﬀer-
ential equations by the method of undetermined coeﬃcients is as follows:
• Step 1: Find the homogeneous solution to the diﬀerential equation.
• Step 2: Make an initial guess at the particular solution. The form of yp(x) is a lin-
ear combination of all linearly independent functions that are generated by repeated
diﬀerentiations of f(x).
• Step 3: If any of the terms in yp(x) given in Step 2 duplicate any of the homogeneous
solutions, then that particular term in yp(x) must be multiplied by xn, where n is the
smallest positive integer that eliminates the duplication.
• Example 2.4.4
Let us apply the method of undetermined coeﬃcients to solve
y′′ + y = sin(x) −e3x cos(5x).
(2.4.27)
We begin by ﬁrst ﬁnding the solution to the homogeneous version of Equation 2.4.27:
y′′
H + yH = 0.
(2.4.28)
Its solution is
yH(x) = A cos(x) + B sin(x).
(2.4.29)
To ﬁnd the particular solution we examine the right side of Equation 2.4.27 or
f(x) = sin(x) −e3x cos(5x).
(2.4.30)
Taking a few derivatives of f(x), we ﬁnd that
f ′(x) = cos(x) −3e3x cos(5x) + 5e3x sin(5x),
(2.4.31)
f ′′(x) = −sin(x) −9e3x cos(5x) + 30e3x sin(5x) + 25e3x cos(5x),
(2.4.32)

70
Advanced Engineering Mathematics with MATLAB
and so forth. Therefore, our guess at the particular solution is
yp(x) = Cx sin(x) + Dx cos(x) + Ee3x cos(5x) + Fe3x sin(5x).
(2.4.33)
Why have we chosen x sin(x) and x cos(x) rather than sin(x) and cos(x)? Because sin(x)
and cos(x) are homogeneous solutions to Equation 2.4.27, we must multiply them by a
power of x.
Since
y′′
p(x) = 2C cos(x) −Cx sin(x) −2D sin(x) −Dx cos(x)
+ (30F −16E)e3x cos(5x) −(30E + 16F)e3x sin(5x),
(2.4.34)
y′′
p + yp = 2C cos(x) −2D sin(x)
+ (30F −15E)e3x cos(5x) −(30E + 15F)e3x sin(5x)
(2.4.35)
= sin(x) −e3x cos(5x).
(2.4.36)
Therefore, 2C = 0, −2D = 1, 30F −15E = −1, and 30E + 15F = 0. Solving this system
of equations yields C = 0, D = −1
2, E =
1
75, and F = −2
75. Thus, the general solution is
y(x) = A cos(x) + B sin(x) −1
2x cos(x) + 1
75e3x[cos(5x) −2 sin(5x)].
(2.4.37)
Problems
Use the method of undetermined coeﬃcients to ﬁnd the general solution of the following
diﬀerential equations. Verify your solution by using dsolve in MATLAB.
1. y′′ + 4y′ + 3y = x + 1
2. y′′ −y = ex −2e−2x
3. y′′ + 2y′ + 2y = 2x2 + 2x + 4
4. y′′ + y′ = x2 + x
5. y′′ + 2y′ = 2x + 5 −e−2x
6. y′′ −4y′ + 4y = (x + 1)e2x
7. y′′ + 4y′ + 4y = xex
8. y′′ −4y = 4 sinh(2x)
9. y′′ + 9y = x cos(3x)
10. y′′ + y = sin(x) + x cos(x)
11. Solve
y′′ + 2ay′ = sin2(ωx),
y(0) = y′(0) = 0,
by (a) the method of undetermined coeﬃcients and (b) integrating the ordinary diﬀerential
equation so that it reduces to
y′ + 2ay = x
2 −sin(2ax)
4a
,
and then using the techniques from the previous chapter to solve this ﬁrst-order ordinary
diﬀerential equation.

Higher-Order Ordinary Diﬀerential Equations
71
2.5 FORCED HARMONIC MOTION
Let us now consider the situation when an external force f(t) acts on a vibrating mass
on a spring. For example, f(t) could represent a driving force that periodically raises and
lowers the support of the spring. The inclusion of f(t) in the formulation of Newton’s second
law yields the diﬀerential equation
md2x
dt2 = −kx −β dx
dt + f(t),
(2.5.1)
d2x
dt2 + β
m
dx
dt + k
mx = f(t)
m ,
(2.5.2)
or
d2x
dt2 + 2λdx
dt + ω2x = F(t),
(2.5.3)
where F(t) = f(t)/m, 2λ = β/m, and ω2 = k/m. To solve this nonhomogeneous equation
we will use the method of undetermined coeﬃcients.
• Example 2.5.1
Let us ﬁnd the solution to the nonhomogeneous diﬀerential equation
y′′ + 2y′ + y = 2 sin(t),
(2.5.4)
subject to the initial conditions y(0) = 2 and y′(0) = 1.
The homogeneous solution is easily found and equals
yH(t) = Ae−t + Bte−t.
(2.5.5)
From the method of undetermined coeﬃcients, we guess that the particular solution is
yp(t) = C cos(t) + D sin(t),
(2.5.6)
so that
y′
p(t) = −C sin(t) + D cos(t),
(2.5.7)
and
y′′
p(t) = −C cos(t) −D sin(t).
(2.5.8)
Substituting yp(t), y′
p(t), and y′′
p(t) into Equation 2.5.4 and simplifying, we ﬁnd that
−2C sin(t) + 2D cos(t) = 2 sin(t)
(2.5.9)
or D = 0 and C = −1.
To ﬁnd A and B, we now apply the initial conditions on the general solution
y(t) = Ae−t + Bte−t −cos(t).
(2.5.10)
The initial condition y(0) = 2 yields
y(0) = A + 0 −1 = 2,
(2.5.11)

72
Advanced Engineering Mathematics with MATLAB
or A = 3. The initial condition y′(0) = 1 gives
y′(0) = −A + B = 1,
(2.5.12)
or B = 4, since
y′(t) = −Ae−t + Be−t −Bte−t + sin(t).
(2.5.13)
Therefore, the solution that satisﬁes the diﬀerential equation and initial conditions is
y(t) = 3e−t + 4te−t −cos(t).
(2.5.14)
⊓⊔
• Example 2.5.2
Let us solve the diﬀerential equation for a weakly damped harmonic oscillator when
the constant forcing F0 “turns on” at t = t0. The initial conditions are that x(0) = x0 and
x′(0) = v0. Mathematically, the problem is
x′′ + 2λx′ + ω2x =
 0,
0 < t < t0,
F0,
t0 < t,
(2.5.15)
with x(0) = x0 and x′(0) = v0.
To solve Equation 2.5.15, we ﬁrst divide the time domain into two regions: 0 < t < t0
and t0 < t. For 0 < t < t0,
x(t) = Ae−λt cos(ωdt) + Be−λt sin(ωdt),
(2.5.16)
where ω2
d = ω2 −λ2. Upon applying the initial conditions,
x(t) = x0e−λt cos(ωdt) + v0 + λx0
ωd
e−λt sin(ωdt),
(2.5.17)
as before.
For the region t0 < t, we write the general solution as
x(t) = Ae−λt cos(ωdt) + Be−λt sin(ωdt) + F0
ω2
+ Ce−λ(t−t0) cos[ωd(t −t0)] + De−λ(t−t0) sin[ωd(t −t0)].
(2.5.18)
Why have we written our solution in this particular form rather than the simpler
x(t) = Ce−λt cos(ωdt) + De−λt sin(ωdt) + F0
ω2 ?
(2.5.19)
Both solutions satisfy the diﬀerential equation, as direct substitution veriﬁes. However, the
algebra is greatly simpliﬁed when Equation 2.5.18 rather than Equation 2.5.19 is used in
matching the solution from each region at t = t0. There both the solution and its ﬁrst
derivative must be continuous or
x(t−
0 ) = x(t+
0 ),
and
x′(t−
0 ) = x′(t+
0 ),
(2.5.20)

Higher-Order Ordinary Diﬀerential Equations
73
Review of the Solution of the
Forced Harmonic Oscillator Problem
The undamped system mx′′+kx = F0 cos(ω0t) subject to the initial conditions x(0) =
x0 and x′(0) = v0 has the solution
x(t) = v0
ω sin(ωt) +

x0 −
f0
ω2 −ω2
0

cos(ωt) +
f0
ω2 −ω2
0
cos(ω0t),
where f0 = F0/m and ω =
p
k/m. The underdamped system mx′′ + βx′ + kx =
F0 cos(ω0t) has the steady-state solution
x(t) =
f0
p
(ω2 −ω2
0)2 + (2λω0)2 cos

ω0t −tan−1
 2λω0
ω2 −ω2
0

,
where 2λ = β/m.
where t−
0 and t+
0 are points just below and above t0, respectively. When Equation 2.5.17
and Equation 2.5.18 are substituted, we ﬁnd that C = −F0/ω2, and ωdD = λC. Thus, the
solution for the region t0 < t is
x(t) = x0e−λt cos(ωdt) + v0 + λx0
ωd
e−λt sin(ωdt) + F0
ω2
(2.5.21)
−F0
ω2 e−λ(t−t0) cos[ωd(t −t0)] −λF0
ωdω2 e−λ(t−t0) sin[ωd(t −t0)].
As we will see in Chapter 12, the technique of Laplace transforms is particularly well suited
for this type of problem when the forcing function changes abruptly at one or more times.⊓⊔
As noted earlier, nonhomogeneous solutions consist of the homogeneous solution plus
a particular solution. In the case of a damped harmonic oscillator, another, more physical,
way of describing the solution involves its behavior at large time.
That portion of the
solution which eventually becomes negligible as t →∞is often referred to as the transient
term, or transient solution. In Equation 2.5.14 the transient solution equals 3e−t + 4te−t.
On the other hand, the portion of the solution that remains as t →∞is called the steady-
state solution. In Equation 2.5.14 the steady-state solution equals −cos(t).
One of the most interesting forced oscillator problems occurs when β = 0 and the
forcing function equals F0 sin(ω0t), where F0 is a constant. Then the initial-value problem
becomes
d2x
dt2 + ω2x = F0 sin(ω0t).
(2.5.22)
Let us solve this problem when x(0) = x′(0) = 0.
The homogeneous solution to Equation 2.5.22 is
xH(t) = A cos(ωt) + B sin(ωt).
(2.5.23)
To obtain the particular solution, we assume that
xp(t) = C cos(ω0t) + D sin(ω0t).
(2.5.24)

74
Advanced Engineering Mathematics with MATLAB
0
200
400
600
800
1000
TIME
−1.8
−1.2
−0.6
0.0
0.6
1.2
1.8
−8
−4
0
4
8
−80
−40
0
40
80
(a)
(b)
(c)
Figure 2.5.1: The solution, Equation 2.5.31, as a function of time when ω = 1 and ω0 equals (a) 1.02, (b)
1.2, and (c) 2.
This leads to
x′
p(t) = −Cω0 sin(ω0t) + Dω0 cos(ω0t),
(2.5.25)
x′′
p(t) = −Cω2
0 cos(ω0t) + Dω2
0 sin(ω0t),
(2.5.26)
and
x′′
p + ω2xp = C(ω2 −ω2
0) cos(ω0t) + D(ω2 −ω2
0) sin(ω0t) = F0 sin(ω0t).
(2.5.27)
We immediately conclude that C(ω2 −ω2
0) = 0, and D(ω2 −ω2
0) = F0. Therefore,
C = 0,
and
D =
F0
ω2 −ω2
0
,
(2.5.28)
provided that ω ̸= ω0. Thus,
xp(t) =
F0
ω2 −ω2
0
sin(ω0t).
(2.5.29)
To ﬁnish the problem, we must apply the initial conditions to the general solution
x(t) = A cos(ωt) + B sin(ωt) +
F0
ω2 −ω2
0
sin(ω0t).
(2.5.30)
From x(0) = 0, we ﬁnd that A = 0. On the other hand, x′(0) = 0 yields B = −ω0F0/[ω(ω2−
ω2
0)]. Thus, the ﬁnal result is
x(t) =
F0
ω(ω2 −ω2
0) [ω sin(ω0t) −ω0 sin(ωt)] .
(2.5.31)
Equation 2.5.31 is illustrated in Figure 2.5.1 as a function of time.

Higher-Order Ordinary Diﬀerential Equations
75
The most arresting feature in Figure 2.5.1 is the evolution of the uniform amplitude
of the oscillation shown in frame (c) into the one shown in frame (a) where the amplitude
exhibits a sinusoidal variation as ω0 →ω. In acoustics these ﬂuctuations in the amplitude
are called beats, the loud sounds corresponding to the larger amplitudes.
As our analysis indicates, Equation 2.5.31 does not apply when ω = ω0. As we shall
shortly see, this is probably the most interesting conﬁguration. We can use Equation 2.5.31
to examine this case by applying L’Hˆopital’s rule in the limiting case of ω0 →ω. This
limiting process is analogous to “tuning in” the frequency of the driving frequency [ω0/(2π)]
to the frequency of free vibrations [ω/(2π)]. From experience, we expect that given enough
time we should be able to substantially increase the amplitudes of vibrations. Mathematical
conﬁrmation of our physical intuition is as follows:
x(t) = lim
ω0→ω F0
ω sin(ω0t) −ω0 sin(ωt)
ω(ω2 −ω2
0)
(2.5.32)
= F0 lim
ω0→ω
d[ω sin(ω0t) −ω0 sin(ωt)]/dω0
d[ω(ω2 −ω2
0)]/dω0
(2.5.33)
= F0 lim
ω0→ω
ωt cos(ω0t) −sin(ωt)
−2ω0ω
(2.5.34)
= F0
ωt cos(ωt) −sin(ωt)
−2ω2
(2.5.35)
= F0
2ω2 sin(ωt) −F0t
2ω cos(ωt).
(2.5.36)
As we suspected, as t →∞, the displacement grows without bounds. This phenomenon is
known as pure resonance. We could also have obtained Equation 2.5.36 directly using the
method of undetermined coeﬃcients involving the initial value problem
d2x
dt2 + ω2x = F0 sin(ωt),
x(0) = x′(0) = 0.
(2.5.37)
Because there is almost always some friction, pure resonance rarely occurs and the
more realistic diﬀerential equation is
d2x
dt2 + 2λdx
dt + ω2x = F0 sin(ω0t).
(2.5.38)
Its solution is
x(t) = Ce−λt sin

t
q
ω2 −ω2
0 + ϕ

+
F0
p
(ω2 −ω2
0)2 + 4λ2ω2
0
sin(ω0t −θ),
(2.5.39)
where
sin(θ) =
2λω0
p
(ω2 −ω2
0)2 + 4λ2ω2
0
,
cos(θ) =
ω2 −ω2
0
p
(ω2 −ω2
0)2 + 4λ2ω2
0
,
(2.5.40)
and C and ϕ are determined by the initial conditions. To illustrate Equation 2.5.39 we
rewrite the amplitude and phase of the particular solution as
F0
p
(ω2 −ω2
0)2 + 4λ2ω2
0
=
F0
ω2p
(1 −r2)2 + 4β2r2
and
tan(θ) =
2βr
1 −r2 ,
(2.5.41)

76
Advanced Engineering Mathematics with MATLAB
0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00
r
0.0
1.0
2.0
3.0
4.0
5.0
6.0
amplitude
β = 0.1
β = 1
β = 10
Figure 2.5.2:
The amplitude of the particular solution Equation 2.5.39 for a forced, damped simple
harmonic oscillator (normalized with F0/ω2) as a function of r = ω0/ω.
where r = ω0/ω and β = λ/ω. Figures 2.5.2 and 2.5.3 graph Equation 2.5.41 as functions
of r for various values of β.
• Example 2.5.3: Electrical circuits
In the previous chapter, we saw how the mathematical analysis of electrical circuits
yields ﬁrst-order linear diﬀerential equations. In those cases we only had a resistor and
capacitor or a resistor and inductor. One of the fundamental problems of electrical circuits
is a circuit where a resistor, capacitor, and inductor are connected in series, as shown in
Figure 2.5.4.
In this RCL circuit, an instantaneous current ﬂows when the key or switch K is closed.
If Q(t) denotes the instantaneous charge on the capacitor, Kirchhoﬀ’s law yields the diﬀer-
ential equation
LdI
dt + RI + Q
C = E(t),
(2.5.42)
where E(t), the electromotive force, may depend on time, but where L, R, and C are
constant. Because I = dQ/dt, Equation 2.5.42 becomes
Ld2Q
dt2 + RdQ
dt + Q
C = E(t).
(2.5.43)
Consider now the case when resistance is negligibly small. Equation 2.5.43 will become
identical to the diﬀerential equation for the forced simple harmonic oscillator, Equation
2.5.3, with λ = 0. Similarly, the general case yields various analogs to the damped harmonic
oscillator:
Case 1
Overdamped
R2 > 4L/C
Case 2
Critically damped
R2 = 4L/C
Case 3
Underdamped
R2 < 4L/C
In each of these three cases, Q(t) →0 as t →∞. (See Problem 6.) Therefore, an RLC
electrical circuit behaves like a damped mass-spring mechanical system, where inductance
acts like mass, resistance is the damping coeﬃcient, and 1/C is the spring constant.

Higher-Order Ordinary Diﬀerential Equations
77
0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00
r
0.00
0.50
1.00
1.50
2.00
2.50
3.00
3.50
phase (radians)
β = 1
β = 10
β = 0.1
Figure 2.5.3: The phase of the particular solution, Equation 2.5.39, for a forced, damped simple harmonic
oscillator as a function of r = ω0/ω.
Problems
1. Find the values of γ so that x′′ + 6x′ + 18 = cos(γt) is in resonance.
2. The diﬀerential equation
x′′ + 2x′ + 2x = 10 sin(2t)
describes a damped, forced oscillator. If the initial conditions are x(0) = x0 and x′(0) = 0,
ﬁnd its solution by hand and by using MATLAB. Plot the solution when x0 = −10, −9, . . . ,9
, 10. Give a physical interpretation to what you observe.
3. At time t = 0, a mass m is suddenly attached to the end of a hanging spring with a
spring constant k. Neglecting friction, ﬁnd the subsequent motion if the coordinate system
is chosen so that x(0) = 0.
Step 1: Show that the diﬀerential equation is
md2x
dt2 + kx = mg,
with the initial conditions x(0) = x′(0) = 0.
Step 2: Show that the solution to Step 1 is
x(t) = mg [1 −cos(ωt)] /k,
ω2 = k/m.
4.
Consider the electrical circuit shown in Figure 2.5.4, which now possesses negligible
resistance and has an applied voltage E(t) = E0[1−cos(ωt)]. Find the current if the circuit
is initially dead.
5. Find the general solution to the diﬀerential equation governing a forced, damped har-
monic equation
mx′′ + cx′ + kx = F0 sin(ωt),

78
Advanced Engineering Mathematics with MATLAB
I
+
-
L
R
E
C
K
Figure 2.5.4: A simple electrical circuit containing a resistor of constant resistance R, capacitor of constant
capacitance C, and inductor of constant inductance L driven by a time-dependent electromotive force E(t).
where m, c, k, F0, and ω are constants. Write the particular solution in amplitude/phase
format.
6. Prove that the transient solution to Equation 2.5.45 tends to zero as t →∞if R, C, and
L are greater than zero.
2.6 VARIATION OF PARAMETERS
As the previous section has shown, the method of undetermined coeﬃcients can be
used when the right side of the diﬀerential equation contains constants, polynomials, expo-
nentials, sines, and cosines. On the other hand, when the right side contains terms other
than these, variation of parameters provides a method for ﬁnding the particular solution.
To understand this technique, let us return to our solution of the ﬁrst-order ordinary
diﬀerential equation
dy
dx + P(x)y = f(x).
(2.6.1)
Its solution is
y(x) = C1e−R
P (x) dx + e−R
P (x) dx
Z
e
R
P (x) dxf(x) dx.
(2.6.2)
The solution, Equation 2.6.2, consists of two parts: The ﬁrst term is the homogeneous
solution and can be written yH(x) = C1y1(x), where y1(x) = e−R
P (x) dx. The second term
is the particular solution and equals the product of some function of x, say u1(x), times
y1(x):
yp(x) = e−R
P (x) dx
Z
e
R
P (x) dxf(x) dx = u1(x)y1(x).
(2.6.3)
This particular solution bears a striking resemblance to the homogeneous solution if we
replace u1(x) with C1.
Variation of parameters builds upon this observation by using the homogeneous solution
y1(x) to construct a guess for the particular solution yp(x) = u1(x)y1(x). Upon substituting
this guessed yp(x) into Equation 2.6.1, we have that
d
dx (u1y1) + P(x)u1y1 = f(x),
(2.6.4)
u1
dy1
dx + y1
du1
dx + P(x)u1y1 = f(x),
(2.6.5)
or
y1
du1
dx = f(x),
(2.6.6)

Higher-Order Ordinary Diﬀerential Equations
79
since y′
1 + P(x)y1 = 0.
Using the technique of separating the variables, we have that
du1 = f(x)
y1(x) dx,
and
u1(x) =
Z
f(x)
y1(x) dx.
(2.6.7)
Consequently, the particular solution equals
yp(x) = u1(x)y1(x) = y1(x)
Z
f(x)
y1(x) dx.
(2.6.8)
Upon substituting for y1(x), we obtain Equation 2.6.3.
How do we apply this method to the linear second-order diﬀerential equation
a2(x)y′′ + a1y′(x) + a0(x)y = g(x),
(2.6.9)
or
y′′ + P(x)y′ + Q(x)y = f(x),
(2.6.10)
where P(x), Q(x), and f(x) are continuous on some interval I?
Let y1(x) and y2(x) denote the homogeneous solutions of Equation 2.6.10. That is,
y1(x) and y2(x) satisfy
y′′
1 + P(x)y′
1 + Q(x)y1 = 0,
(2.6.11)
and
y′′
2 + P(x)y′
2 + Q(x)y2 = 0.
(2.6.12)
Following our previous example, we now seek two functions u1(x) and u2(x) such that
yp(x) = u1(x)y1(x) + u2(x)y2(x)
(2.6.13)
is a particular solution of Equation 2.6.10. Once again, we replaced our arbitrary constants
C1 and C2 by the “variable parameters” u1(x) and u2(x). Because we have two unknown
functions, we require two equations to solve for u1(x) and u2(x). One of them follows from
substituting yp(x) = u1(x)y1(x) + u2(x)y2(x) into Equation 2.6.10. The other equation is
y1(x)u′
1(x) + y2(x)u′
2(x) = 0.
(2.6.14)
This equation is an assumption that is made to simplify the ﬁrst and second derivative,
which is clearly seen by computing
y′
p = u1y′
1 + y1u′
1 + u2y′
2 + y2u′
2 = u1y′
1 + u2y′
2,
(2.6.15)
after applying Equation 2.6.14. Continuing to the second derivative,
y′′
p = u1y′′
1 + y′
1u′
1 + u2y′′
2 + y′
2u′
2.
(2.6.16)
Substituting these results into Equation 2.6.10, we obtain
y′′
p + P(x)y′
p + Q(x)yp = u1y′′
1 + y′
1u′
1 + u2y′′
2 + y′
2u′
2
+ Pu1y′
1 + Pu2y′
2 + Qu1y1 + Qu2y2,
(2.6.17)
= u1 [y′′
1 + P(x)y′
1 + Q(x)y1] + u2 [y′′
2 + P(x)y′
2 + Q(x)y2]
+ y′
1u′
1 + y′
2u′
2 = f(x).
(2.6.18)
Hence, u1(x) and u2(x) must be functions that also satisfy the condition
y′
1u′
1 + y′
2u′
2 = f(x).
(2.6.19)
It is important to note that the diﬀerential equation must be written so that it conforms to
Equation 2.6.10. This may require the division of the diﬀerential equation by a2(x) so that
you have the correct f(x).
Equations 2.6.14 and 2.6.19 constitute a linear system of equations for determining the
unknown derivatives u′
1 and u′
2. By Cramer’s rule,7 the solutions of Equation 2.6.14 and
7 If you are unfamiliar with Cramer’s rule, see Section 3.3.

80
Advanced Engineering Mathematics with MATLAB
Equation 2.6.19 equal
u′
1(x) = W1
W ,
and
u′
2(x) = W2
W ,
(2.6.20)
where
W =

y1
y2
y′
1
y′
2
 ,
W1 =

0
y2
f(x)
y′
2
 ,
and
W2 =

y1
0
y′
1
f(x)
 .
(2.6.21)
The determinant W is the Wronskian of y1 and y2. Because y1 and y2 are linearly indepen-
dent on I, the Wronskian will never equal to zero for every x in the interval.
These results can be generalized to any nonhomogeneous, nth-order, linear equation of
the form
y(n) + Pn−1(x)y(n−1) + P1(x)y′ + P0(x) = f(x).
(2.6.22)
If yH(x) = C1y1(x) + C2y2(x) + · · · + Cnyn(x) is the complementary function for Equation
2.6.22, then a particular solution is
yp(x) = u1(x)y1(x) + u2(x)y2(x) + · · · + un(x)yn(x),
(2.6.23)
where the u′
k, k = 1, 2, . . . , n, are determined by the n equations:
y1u′
1 + y2u′
2+ · · · + ynu′
n = 0,
(2.6.24)
y′
1u′
1 + y′
2u′
2+ · · · + y′
nu′
n = 0,
(2.6.25)
...
y(n−1)
1
u′
1 + y(n−1)
2
u′
2+ · · · + y(n−1)
n
u′
n = f(x).
(2.6.26)
The ﬁrst n −1 equations in this system, like Equation 2.6.14, are assumptions made to
simplify the ﬁrst n −1 derivatives of yp(x). The last equation of the system results from
substituting the n derivative of yp(x) and the simpliﬁed lower derivatives into Equation
2.6.22. Then, by Cramer’s rule, we ﬁnd that
u′
k = Wk
W ,
k = 1, 2, . . . , n,
(2.6.27)
where W is the Wronskian of y1, y2, ...., yn, and Wk is the determinant obtained by replacing
the kth column of the Wronskian by the column vector [0, 0, 0, · · · , f(x)]T .
• Example 2.6.1
Let us apply variation of parameters to ﬁnd the general solution to
y′′ + y′ −2y = xex.
(2.6.28)
We begin by ﬁrst ﬁnding the homogeneous solution that satisﬁes the diﬀerential equa-
tion
y′′
H + y′
H −2yH = 0.
(2.6.29)
Applying the techniques from Section 2.1, the homogeneous solution is
yH(x) = Aex + Be−2x,
(2.6.30)

Higher-Order Ordinary Diﬀerential Equations
81
yielding the two independent solutions y1(x) = ex, and y2(x) = e−2x. Thus, the method of
variation of parameters yields the particular solution
yp(x) = exu1(x) + e−2xu2(x).
(2.6.31)
From Equation 2.6.14, we have that
exu′
1(x) + e−2xu′
2(x) = 0,
(2.6.32)
while
exu′
1(x) −2e−2xu′
2(x) = xex.
(2.6.33)
Solving for u′
1(x) and u′
2(x), we ﬁnd that
u′
1(x) = 1
3x,
(2.6.34)
or
u1(x) = 1
6x2,
(2.6.35)
and
u′
2(x) = −1
3xe3x,
(2.6.36)
or
u2(x) =
1
27(1 −3x)e3x.
(2.6.37)
Therefore, the general solution is
y(x) = Aex + Be−2x + exu1(x) + e−2xu2(x)
(2.6.38)
= Aex + Be−2x + 1
6x2ex + 1
27(1 −3x)ex
(2.6.39)
= Cex + Be−2x +
  1
6x2 −1
9x

ex.
(2.6.40)
⊓⊔
• Example 2.6.2
Let us ﬁnd the general solution to
y′′ + 2y′ + y = e−x ln(x)
(2.6.41)
by variation of parameters on the interval (0, ∞).
We start by ﬁnding the homogeneous solution that satisﬁes the diﬀerential equation
y′′
H + 2y′
H + yH = 0.
(2.6.42)
Applying the techniques from Section 2.1, the homogeneous solution is
yH(x) = Ae−x + Bxe−x,
(2.6.43)
yielding the two independent solutions y1(x) = e−x and y2(x) = xe−x. Thus, the particular
solution equals
yp(x) = e−xu1(x) + xe−xu2(x).
(2.6.44)

82
Advanced Engineering Mathematics with MATLAB
From Equation 2.6.14, we have that
e−xu′
1(x) + xe−xu′
2(x) = 0,
(2.6.45)
while
−e−xu′
1(x) + (1 −x)e−xu′
2(x) = e−x ln(x).
(2.6.46)
Solving for u′
1(x) and u′
2(x), we ﬁnd that
u′
1(x) = −x ln(x),
(2.6.47)
or
u1(x) = 1
4x2 −1
2x2 ln(x),
(2.6.48)
and
u′
2(x) = ln(x),
(2.6.49)
or
u2(x) = x ln(x) −x.
(2.6.50)
Therefore, the general solution is
y(x) = Ae−x + Bxe−x + e−xu1(x) + xe−xu2(x)
(2.6.51)
= Ae−x + Bxe−x + 1
2x2 ln(x)e−x −3
4x2e−x.
(2.6.52)
We can verify our result by using the symbolic toolbox in MATLAB. Typing the com-
mand:
dsolve(’D2y+2*Dy+y=exp(-x)*log(x)’,’x’)
yields
ans =
1/2*exp(-x)*x^2*log(x)-3/4*exp(-x)*x^2+C1*exp(-x)+C2*exp(-x)*x ⊓⊔
• Example 2.6.3
So far, all of our examples have yielded closed-form solutions. To show that this is not
necessarily so, let us solve
y′′ −4y = e2x/x
(2.6.53)
by variation of parameters.
Again we begin by solving the homogeneous diﬀerential equation
y′′
H −4yH = 0,
(2.6.54)
which has the solution
yH(x) = Ae2x + Be−2x.
(2.6.55)
Thus, our two independent solutions are y1(x) = e2x and y2(x) = e−2x. Therefore, the
particular solution equals
yp(x) = e2xu1(x) + e−2xu2(x).
(2.6.56)
From Equation 2.6.14, we have that
e2xu′
1(x) + e−2xu′
2(x) = 0,
(2.6.57)

Higher-Order Ordinary Diﬀerential Equations
83
while
2e2xu′
1(x) −2e−2xu′
2(x) = e2x/x.
(2.6.58)
Solving for u′
1(x) and u′
2(x), we ﬁnd that
u′
1(x) = 1
4x,
(2.6.59)
or
u1(x) = 1
4 ln |x|,
(2.6.60)
and
u′
2(x) = −e4x
4x ,
(2.6.61)
or
u2(x) = −1
4
Z x
x0
e4t
t dt.
(2.6.62)
Therefore, the general solution is
y(x) = Ae2x + Be−2x + e2xu1(x) + e−2xu2(x)
(2.6.63)
= Ae2x + Be−2x + 1
4 ln |x|e2x −1
4e−2x
Z x
x0
e4t
t dt.
(2.6.64)
Problems
Use variation of parameters to ﬁnd the general solution for the following diﬀerential equa-
tions. Then see if you can obtain your solution by using dsolve in MATLAB.
1. y′′ −4y′ + 3y = e−x
2. y′′ −y′ −2y = x
3. y′′ −4y = xex
4. y′′ + 9y = 2 sec(x)
5. y′′ + 4y′ + 4y = xe−2x
6. y′′ + 2ay′ = sin2(ωx)
7. y′′ −4y′ + 4y = (x + 1)e2x
8. y′′ −4y = sin2(x)
9. y′′ −2y′ + y = ex/x
10. y′′ + y = tan(x)
2.7 EULER-CAUCHY EQUATION
The Euler-Cauchy or equidimensional equation is a linear diﬀerential equation of the
form
anxn dny
dxn + an−1xn−1 dn−1y
dxn−1 + · · · + a1xdy
dx + a0y = f(x),
(2.7.1)
where an, an−1, ...., a0 are constants. The important point here is that in each term the
power to which x is raised equals the order of diﬀerentiation.
To illustrate this equation, we will focus on the homogeneous, second-order, ordinary
diﬀerential equation
ax2 d2y
dx2 + bxdy
dx + cy = 0.
(2.7.2)

84
Advanced Engineering Mathematics with MATLAB
The solution of higher-order ordinary diﬀerential equations follows by analog. If we wish to
solve the nonhomogeneous equation
ax2 d2y
dx2 + bxdy
dx + cy = f(x),
(2.7.3)
we can do so by applying variation of parameters using the complementary solutions that
satisfy Equation 2.7.2.
Our analysis starts by trying a solution of the form y = xm, where m is presently
undetermined. The ﬁrst and second derivatives are
dy
dx = mxm−1,
and
d2y
dx2 = m(m −1)xm−2,
(2.7.4)
respectively. Consequently, substitution yields the diﬀerential equation
ax2 d2y
dx2 + bxdy
dx + cy = ax2 · m(m −1)xm−2 + bx · mxm−1 + cxm
(2.7.5)
= am(m −1)xm + bmxm + cxm
(2.7.6)
= [am(m −1) + bm + c] xm.
(2.7.7)
Thus, y = xm is a solution of the diﬀerential equation whenever m is a solution of the
auxiliary equation
am(m −1) + bm + c = 0,
or
am2 + (b −a)m + c = 0.
(2.7.8)
At this point we must consider three diﬀerent cases that depend upon the values of a, b,
and c.
• Distinct real roots
Let m1 and m2 denote the real roots of Equation 2.7.8 such that m1 ̸= m2. Then,
y1(x) = xm1
and
y2(x) = xm2
(2.7.9)
are homogeneous solutions to Equation 2.7.2. Therefore, the general solution is
y(x) = C1xm1 + C2xm2.
(2.7.10)
• Repeated real roots
If the roots of Equation 2.7.8 are repeated [m1 = m2 = −(b −a)/2], then we presently
have only one solution, y = xm1. To construct the second solution y2, we use reduction in
order. We begin by ﬁrst rewriting the Euler-Cauchy equation as
d2y
dx2 + b
ax
dy
dx +
c
ax2 y = 0.
(2.7.11)
Letting P(x) = b/(ax), we have
y2(x) = xm1
Z e−R
[b/(ax)] dx
(xm1)2
dx = xm1
Z e−(b/a) ln(x)
x2m1
dx
(2.7.12)
= xm1
Z
x−b/ax−2m1 dx = xm1
Z
x−b/ax(b−a)/a dx
(2.7.13)
= xm1
Z dx
x = xm1 ln(x).
(2.7.14)

Higher-Order Ordinary Diﬀerential Equations
85
The general solution is then
y(x) = C1xm1 + C2xm1 ln(x).
(2.7.15)
For higher-order equations, if m1 is a root of multiplicity k, then it can be shown that
xm1, xm1 ln(x), xm1[ln(x)]2, . . . , xm1[ln(x)]k−1
are the k linearly independent solutions. Therefore, the general solution of the diﬀerential
equation equals a linear combination of these k solutions.
• Conjugate complex roots
If the roots of Equation 2.7.8 are the complex conjugate pair m1 = α + iβ, and m2 =
α −iβ, where α and β are real and β > 0, then a solution is
y(x) = C1xα+iβ + C2xα−iβ.
(2.7.16)
However, because xiθ = [eln(x)]iθ = eiθ ln(x), we have by Euler’s formula
xiθ = cos [θ ln(x)] + i sin [θ ln(x)] ,
(2.7.17)
and
x−iθ = cos [θ ln(x)] −i sin [θ ln(x)] .
(2.7.18)
Substitution into Equation 2.7.16 leads to
y(x) = C3xα cos [β ln(x)] + C4xα sin [β ln(x)] ,
(2.7.19)
where C3 = C1 + C2, and C4 = iC1 −iC2.
• Example 2.7.1
Let us ﬁnd the general solution to
x2y′′ + 5xy′ −12y = ln(x)
(2.7.20)
by the method of undetermined coeﬃcients and variation of parameters.
In the case of undetermined coeﬃcients, we begin by letting t = ln(x) and y(x) = Y (t).
Substituting these variables into Equation 2.7.20, we ﬁnd that
Y ′′ + 4Y ′ −12Y = t.
(2.7.21)
The homogeneous solution to Equation 2.7.21 is
YH(t) = A′e−6t + B′e2t,
(2.7.22)
while the particular solution is
Yp(t) = Ct + D
(2.7.23)
from the method of undetermined coeﬃcients. Substituting Equation 2.7.23 into Equation
2.7.21 yields C = −1
12 and D = −1
36. Therefore,
Y (t) = A′e−6t + B′e2t −1
12t −1
36,
(2.7.24)

86
Advanced Engineering Mathematics with MATLAB
or
y(x) = A
x6 + Bx2 −1
12 ln(x) −1
36.
(2.7.25)
To ﬁnd the particular solution via variation of parameters, we use the homogeneous
solution
yH(x) = A
x6 + Bx2
(2.7.26)
to obtain y1(x) = x−6 and y2(x) = x2. Therefore,
yp(x) = x−6u1(x) + x2u2(x).
(2.7.27)
Substitution of Equation 2.7.27 in Equation 2.7.20 yields the system of equations:
x−6u′
1(x) + x2u′
2(x) = 0,
(2.7.28)
and
−6x−7u′
1(x) + 2xu′
2(x) = ln(x)/x2.
(2.7.29)
Solving for u′
1(x) and u′
2(x),
u′
1(x) = −x5 ln(x)
8
,
and
u′
2(x) = −ln(x)
8x3 .
(2.7.30)
The solutions of these equations are
u1(x) = −x6 ln(x)
48
+ x6
288,
and
u2(x) = −ln(x)
16x2 −
1
32x2 .
(2.7.31)
The general solution then equals
y(x) = A
x6 + Bx2 + x−6u1(x) + x2u2(x) = A
x6 + Bx2 −1
12 ln(x) −1
36.
(2.7.32)
We can verify this result by using the symbolic toolbox in MATLAB. Typing the com-
mand:
dsolve(’x^2*D2y+5*x*Dy-12*y=log(x)’,’x’)
yields
ans =
-1/12*log(x)-1/36+C1*x^2+C2/x^6
Problems
Find the general solution for the following Euler-Cauchy equations valid over the domain
(−∞, ∞). Then check your answer by using dsolve in MATLAB.
1. x2y′′ + xy′ −y = 0
2. x2y′′ + 2xy′ −2y = 0
3. x2y′′ −2y = 0
4. x2y′′ −xy′ + y = 0
5. x2y′′ + 3xy′ + y = 0
6. x2y′′ −3xy′ + 4y = 0
7. x2y′′ −y′ + 5y = 0
8. 4x2y′′ + 8xy′ + 5y = 0
9. x2y′′ + xy′ + y = 0
10. x2y′′ −3xy′ + 13y = 0
11. x3y′′′ −2x2y′′ −2xy′ + 8y = 0
12. x2y′′ −2xy′ −4y = x

Higher-Order Ordinary Diﬀerential Equations
87
2.8 PHASE DIAGRAMS
In Section 1.6 we showed how solutions to ﬁrst-order ordinary diﬀerential equations
could be qualitatively solved through the use of the phase line. This concept of qualita-
tively studying diﬀerential equations showed promise as a method for deducing many of
the characteristics of the solution to a diﬀerential equation without actually solving it. In
this section we extend these concepts to second-order ordinary diﬀerential equations by
introducing the phase plane.
Consider the diﬀerential equation
x′′ + sgn(x) = 0,
(2.8.1)
where the signum function is deﬁned by Equation 11.2.11. Equation 2.8.1 describes, for
example, the motion of an inﬁnitesimal ball rolling in a “V”-shaped trough in a constant
gravitational ﬁeld.8
Our analysis begins by introducing the new dependent variable v = x′ so that Equation
2.8.1 can be written
v dv
dx + sgn(x) = 0,
(2.8.2)
since
x′′ = d2x
dt2 = dv
dt = dx
dt
dv
dx = v dv
dx.
(2.8.3)
Equation 2.8.2 relates v to x and t has disappeared explicitly from the problem. Integrating
Equation 2.8.2 with respect to x, we obtain
Z
v dv +
Z
sgn(x) dx = C,
(2.8.4)
or
1
2v2 + |x| = C.
(2.8.5)
Equation 2.8.5 expresses conservation of energy because the ﬁrst term on the left side of
this equation expresses the kinetic energy while the second term gives the potential energy.
The value of C depends upon the initial condition x(0) and v(0). Thus, for a speciﬁc initial
condition, our equation gives the relationship between x and v for the motion corresponding
to the initial condition.
Although there is a closed-form solution for Equation 2.8.1, let us imagine that there
is none. What could we learn from Equation 2.8.5?
Equation 2.8.5 can be represented in a diagram, called a phase plane, where x and v
are its axes. A given pair of (x, v) is called a state of the system. A given state determines
all subsequent states because it serves as initial conditions for any subsequent motion.
For each diﬀerent value of C, we will obtain a curve, commonly known as phase paths,
trajectories, or integral curves, on the phase plane. In Figure 2.8.1, we used the MATLAB
script
clear
% set up grid points in the (x,v) plane
[x,v] = meshgrid(-5:0.5:5,-5:0.5:5);
% compute slopes
8 See Lipscomb, T., and R. E. Mickens, 1994:
Exact solution to the axisymmetric, constant force
oscillator equation. J. Sound Vib., 169, 138–140.

88
Advanced Engineering Mathematics with MATLAB
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x
v
Figure 2.8.1: Phase diagram for the diﬀerential equation, Equation 2.8.1.
dxdt = v; dvdt = -sign(x);
% find magnitude of vector [dxdt,dydt]
L = sqrt(dxdt.*dxdt + dvdt.*dvdt);
% plot scaled vectors
quiver(x,v,dxdt./L,dvdt./L,0.5); axis equal tight
hold
% contour trajectories
contour(x,v,v.*v/2 + abs(x),8)
h = findobj(’Type’,’patch’); set(h,’Linewidth’,2);
xlabel(’x’,’Fontsize’,20); ylabel(’v’,’Fontsize’,20)
to graph the phase plane for Equation 2.8.1. Here the phase paths are simply closed, oval-
shaped curves that are symmetric with respect to both the x and v phase space axes. Each
phase path corresponds to a particular possible motion of the system. Associated with each
path is a direction, indicated by an arrow, showing how the state of the system changes as
time increases.
An interesting feature on Figure 2.8.1 is the point (0, 0). What is happening there?
In our discussion of phase line, we sought to determine whether there were any equilibrium
or critical points. Recall that at an equilibrium or critical point the solution is constant
and was given by x′ = 0. In the case of second-order diﬀerential equations, we again have
the condition x′ = v = 0. For this reason, equilibrium points are always situated on the
abscissa of the phase diagram.
The condition x′ = 0 is insuﬃcient for determining critical points. For example, when
a ball is thrown upward, its velocity equals zero at the peak height. However, this is clearly
not a point of equilibrium. Consequently, we must impose the additional constraint that
x′′ = v′ = 0. In the present example, equilibrium points occur where x′ = v = 0 and
v′ = −sgn(x) = 0 or x = 0. Therefore, the point (0, 0) is the critical point for Equation
2.8.1.
The closed curves immediately surrounding the origin in Figure 2.8.1 show that we
have periodic solutions there because on completing a circuit, the original state returns and

Higher-Order Ordinary Diﬀerential Equations
89
−10
−8
−6
−4
−2
0
2
4
6
8
10
−3
−2
−1
0
1
2
3
θ
θ′
Figure 2.8.2: Phase diagram for a simple pendulum.
the motion simply repeats itself indeﬁnitely.
Once we have found an equilibrium point, an obvious question is whether it is stable
or not. To determine this, consider what happens if the initial state is displaced slightly
from the origin. It lands on one of the nearby closed curves and the particle oscillates with
small amplitude about the origin. Thus, this critical point is stable.
In the following examples, we further illustrate the details that may be gleaned from a
phase diagram.
• Example 2.8.1
The equation describing a simple pendulum is
ma2θ′′ + mga sin(θ) = 0,
(2.8.6)
where m denotes the mass of the bob, a is the length of the rod or light string, and g is the
acceleration due to gravity. Here the conservation of energy equation is
1
2ma2θ′2 −mga cos(θ) = C.
(2.8.7)
Figure 2.8.2 is the phase diagram for the simple pendulum. Some of the critical points
are located at θ = ±2nπ, n = 0, 1, 2, . . ., and θ′ = 0. Near these critical points, we have
closed patterns surrounding these critical points, just as we did in the earlier case of an
inﬁnitesimal ball rolling in a “V”-shaped trough.
Once again, these critical points are
stable and the region around these equilibrium points corresponds to a pendulum swinging
to and fro about the vertical. On the other hand, there is a new type of critical point at
θ = ±(2n−1)π, n = 0, 1, 2, . . . and θ′ = 0. Here the trajectories form hyperbolas near these
equilibrium points. Thus, for any initial state that is near these critical points, we have
solutions that move away from the equilibrium point. This is an example of an unstable
critical point. Physically these critical points correspond to a pendulum that is balanced
on end. Any displacement from the equilibrium results in the bob falling from the inverted
position.
Finally, we have a wavy line as θ′ →±∞. This corresponds to whirling motions of the
pendulum where θ′ has the same sign and θ continuously increases or decreases.
⊓⊔
• Example 2.8.2: Damped harmonic oscillator
Consider the ordinary diﬀerential equation
x′′ + 2x′ + 5x = 0.
(2.8.8)

90
Advanced Engineering Mathematics with MATLAB
−3
−2
−1
0
1
2
3
−3
−2
−1
0
1
2
3
x
v
Figure 2.8.3: Phase diagram for the damped harmonic oscillator, Equation 2.8.8.
The exact solution to this diﬀerential equation is
x(t) = e−t [A cos(2t) + B sin(2t)] ,
(2.8.9)
and
x′(t) = 2e−t [B cos(2t) −A sin(2t)] −e−t [A cos(2t) + B sin(2t)] .
(2.8.10)
To construct its phase diagram, we again deﬁne v = x′ and replace Equation 2.8.8 with
v′ = −2v −5x. The MATLAB script
clear
% set up grid points in the x,x’ plane
[x,v] = meshgrid(-3:0.5:3,-3:0.5:3);
% compute slopes
dxdt = v; dvdt = -2*v - 5*x;
% find length of vector
L = sqrt(dxdt.*dxdt + dvdt.*dvdt);
% plot direction field
quiver(x,v,dxdt./L,dvdt./L,0.5); axis equal tight
hold
% compute x(t) and v(t) at various times and a’s and b’s
for b = -3:2:3; for a = -3:2:3;
t = [-5:0.1:5];
xx = exp(-t) .* (a*cos(2*t) + b*sin(2*t));
vv = 2 * exp(-t) .* (b*cos(2*t) - a*sin(2*t)) - xx;
% plot these values
plot(xx,vv)
end; end;
xlabel(’x’,’Fontsize’,20); ylabel(’v’,’Fontsize’,20)
was used to construct the phase diagram for Equation 2.8.8 and is shown in Figure 2.8.3.
Here the equilibrium point is at x = v = 0. This is a new type of critical point. It is called
a stable node because all slight displacements from this critical point eventually return to
this equilibrium point.

Higher-Order Ordinary Diﬀerential Equations
91
Problems
1. Using MATLAB, construct the phase diagram for x′′ −3x′ + 2x = 0. What happens
around the point x = v = 0?
2. Consider the nonlinear diﬀerential equation x′′ = x3 −x. This equation arises in the
study of simple pendulums with swings of moderate amplitude.
(a) Show that the conservation law is
1
2v2 −1
4x4 + 1
2x2 = C.
What is special about C = 0 and C = 1
4?
(b) Show that there are three critical points: x = 0 and x = ±1 with v = 0.
(c) Using MATLAB, graph the phase diagram with axes x and v.
For the following ordinary diﬀerential equations, ﬁnd the equilibrium points and then clas-
sify them. Use MATLAB to draw the phase diagrams.
3. x′′ = 2x′
4. x′′ + sgn(x)x = 0
5. x′′ =

1,
|x| > 2,
0,
|x| < 2.
2.9 NUMERICAL METHODS
When diﬀerential equations cannot be integrated in closed form, numerical methods
must be employed. In the ﬁnite diﬀerence method, the discrete variable xi or ti replaces the
continuous variable x or t and the diﬀerential equation is solved progressively in increments
h starting from known initial conditions. The solution is approximate, but with a suﬃciently
small increment, you can obtain a solution of acceptable accuracy.
Although there are many diﬀerent ﬁnite diﬀerence schemes available, we consider here
only two methods that are chosen for their simplicity. The interested student may read any
number of texts on numerical analysis if he or she wishes a wider view of other possible
schemes.
Let us focus on second-order diﬀerential equations; the solution of higher-order diﬀeren-
tial equations follows by analog. In the case of second-order ordinary diﬀerential equations,
the diﬀerential equation can be rewritten as
x′′ = f(x, x′, t),
x0 = x(0),
x′
0 = x′(0),
(2.9.1)
where the initial conditions x0 and x′
0 are assumed to be known.
For the present moment, let us treat the second-order ordinary diﬀerential equation
x′′ = f(x, t),
x0 = x(0),
x′
0 = x′(0).
(2.9.2)
The following scheme, known as the central diﬀerence method, computes the solution from
Taylor expansions at xi+1 and xi−1:
xi+1 = xi + hx′
i + 1
2h2x′′
i + 1
6h3x′′′
i + O(h4)
(2.9.3)

92
Advanced Engineering Mathematics with MATLAB
and
xi−1 = xi −hx′
i + 1
2h2x′′
i −1
6h3x′′′
i + O(h4),
(2.9.4)
where h denotes the time interval ∆t. Subtracting and ignoring higher-order terms, we
obtain
x′
i = xi+1 −xi−1
2h
.
(2.9.5)
Adding Equation 2.9.3 and Equation 2.9.4 yields
x′′
i = xi+1 −2xi + xi−1
h2
.
(2.9.6)
In both Equation 2.9.5 and Equation 2.9.6 we ignored terms of O(h2). After substituting
into the diﬀerential equation, Equation 2.9.2, Equation 2.9.6 can be rearranged to
xi+1 = 2xi −xi−1 + h2f(xi, ti),
i ≥1,
(2.9.7)
which is known as the recurrence formula.
Consider now the situation when i = 0. We note that although we have x0 we do
not have x−1. Thus, to start the computation, we need another equation for x1. This is
supplied by Equation 2.9.3, which gives
x1 = x0 + hx′
0 + 1
2h2x′′
0 = x0 + hx′
0 + 1
2h2f(x0, t0).
(2.9.8)
Once we have computed x1, then we can switch to Equation 2.9.6 for all subsequent calcu-
lations.
In this development we have ignored higher-order terms that introduce what is known
as truncation errors. Other errors, such as round-oﬀerrors, are introduced due to loss
of signiﬁcant ﬁgures.
These errors are all related to the time increment h in a rather
complicated manner that is investigated in numerical analysis books. In general, better
accuracy is obtained by choosing a smaller h, but the number of computations will then
increase together with errors.
• Example 2.9.1
Let us solve x′′ −4x = 2t subject to x(0) = x′(0) = 1. The exact solution is
x(t) = 7
8e2t + 1
8e−2t −1
2t.
(2.9.9)
The MATLAB script
clear
% test out different time steps
for i = 1:3
% set up time step increment and number of time steps
h = 1/10^i; n = 10/h;
% set up initial conditions
t=zeros(n+1,1); t(1) = 0; x(1) = 1; x exact(1) = 1;
% define right side of differential equation
f = inline(’4*xx+2*tt’,’tt’,’xx’);
% set up difference arrays for plotting purposes
diff = zeros(n,1); t plot = zeros(n,1);

Higher-Order Ordinary Diﬀerential Equations
93
0
2
4
6
8
10
10
−10
10
−8
10
−6
10
−4
10
−2
10
0
h = 0.1
TIME
|RELATIVE ERROR|
h = 0.01
h = 0.001
Figure 2.9.1: The numerical solution of x′′ −4x = 2t when x(0) = x′(0) = 1 using a simple ﬁnite diﬀerence
approach.
% compute first time step
t(2) = t(1) + h; x(2) = x(1) + h + 0.5*h*h*f(t(1),x(1));
x exact(2) = (7/8)*exp(2*t(2))+(1/8)*exp(-2*t(2))-t(2)/2;
t plot(1) = t(2);
diff(1)=x(2)-x exact(2); diff(1)=abs(diff(1)/x exact(2));
% compute the remaining time steps
for k = 2:n
t(k+1) = t(k) + h; t plot(k) = t(k+1);
x(k+1) = 2*x(k) - x(k-1) + h*h*f(t(k),x(k));
x exact(k+1) = (7/8)*exp(2*t(k+1))+(1/8)*exp(-2*t(k+1)) ...
- t(k+1)/2;
diff(k) = x(k+1) - x exact(k+1);
diff(k) = abs(diff(k) / x exact(k+1));
end
% plot the relative error
semilogy(t plot,diff,’-’)
hold on
num = 0.2*n;
text(3*i,diff(num),[’h = ’,num2str(h)],’Fontsize’,15,...
’HorizontalAlignment’,’right’,’VerticalAlignment’,’bottom’)
xlabel(’TIME’,’Fontsize’,20);
ylabel(’|RELATIVE ERROR|’,’Fontsize’,20);
end
implements our simple ﬁnite diﬀerence method of solving a second-order ordinary diﬀerential
equation. In Figure 2.9.1 we have plotted results for three diﬀerent values of the time step.
As our analysis suggests, the relative error is related to h2.
⊓⊔
An alternative method for integrating higher-order ordinary diﬀerential equations is
Runge-Kutta. It is popular because it is self-starting and the results are very accurate.
For second-order ordinary diﬀerential equations, this method ﬁrst reduces the diﬀeren-
tial equation into two ﬁrst-order equations. For example, the diﬀerential equation
x′′ = f(t) −kx −cx′
m
= F(x, x′, t)
(2.9.10)

94
Advanced Engineering Mathematics with MATLAB
0
2
4
6
8
10
10
−12
10
−10
10
−8
10
−6
10
−4
10
−2
10
0
TIME
|RELATIVE ERROR|
h = 0.5
h = 0.1
h = 0.05
h = 0.01
Figure 2.9.2: The numerical solution of x′′ −4x = 2t when x(0) = x′(0) = 1 using the Runge-Kutta
method.
becomes the ﬁrst-order diﬀerential equations
x′ = y,
y′ = F(x, y, t).
(2.9.11)
The Runge-Kutta procedure can then be applied to each of these equations. Using a fourth-
order scheme, the procedure is as follows:
xi+1 = xi + 1
6h(k1 + 2k2 + 2k3 + k4),
(2.9.12)
and
yi+1 = yi + 1
6h(K1 + 2K2 + 2K3 + K4),
(2.9.13)
where
k1 = yi,
K1 = F(xi, yi, ti),
(2.9.14)
k2 = yi + h
2 K1,
K2 = F(xi + h
2 k1, k2, ti + h
2 ),
(2.9.15)
k3 = yi + h
2 K2,
K3 = F(xi + h
2 k2, k3, ti + h
2 ),
(2.9.16)
and
k4 = yi + K3h,
K4 = F(xi + hk3, k4, ti + h).
(2.9.17)
• Example 2.9.2
The MATLAB script
clear
% test out different time steps
for i = 1:4
% set up time step increment and number of time steps
if i==1 h = 0.50; end; if i==2 h = 0.10; end;
if i==3 h = 0.05; end; if i==4 h = 0.01; end;
nn = 10/h;
% set up initial conditions
t=zeros(n+1,1); t(1) = 0;
x rk=zeros(n+1,1); x rk(1) = 1;
y rk=zeros(n+1,1); y rk(1) = 1;
x exact=zeros(n+1,1); x exact(1) = 1;
% set up difference arrays for plotting purposes
t plot = zeros(n,1); diff = zeros(n,1);
% define right side of differential equation
f = inline(’4*xx+2*tt’,’tt’,’xx’,’yy’);

Higher-Order Ordinary Diﬀerential Equations
95
for k = 1:n
t local = t(k); x local = x rk(k); y local = y rk(k);
k1 = y local; K1 = f(t local,x local,y local);
k2 = y local + h*K1/2;
K2 = f(t local + h/2,x local + h*k1/2,k2);
k3 = y local + h*K2/2;
K3 = f(t local + h/2,x local + h*k2/2,k3);
k4 = y local + h*K3; K4 = f(t local + h,x local + h*k3,k4);
t(k+1) = t local + h;
x rk(k+1) = x local + (h/6) * (k1+2*k2+2*k3+k4);
y rk(k+1) = y local + (h/6) * (K1+2*K2+2*K3+K4);
x exact(k+1) = (7/8)*exp(2*t(k+1))+(1/8)*exp(-2*t(k+1)) ...
- t(k+1)/2;
t plot(k) = t(k);
diff(k) = x rk(k+1) - x exact(k+1);
diff(k) = abs(diff(k) / x exact(k+1));
end
% plot the relative errors
semilogy(t plot,diff,’-’)
hold on
xlabel(’TIME’,’Fontsize’,20);
ylabel(’|RELATIVE ERROR|’,’Fontsize’,20);
text(2*i,diff(0.2*n),[’h = ’,num2str(h)],’Fontsize’,15,...
’HorizontalAlignment’,’right’,’VerticalAlignment’,’bottom’)
end
was used to resolve Example 2.9.1 using the Runge-Kutta approach. Figure 2.9.2 illustrates
the results for time steps of various sizes.
Problems
In previous sections, you found exact solutions to second-order ordinary diﬀerential equa-
tions. Conﬁrm these earlier results by using MATLAB and the Runge-Kutta scheme to ﬁnd
the numerical solution to the following problems drawn from previous sections.
1. Section 2.1, Problem 1
2. Section 2.1, Problem 5
3. Section 2.4, Problem 1
4. Section 2.4, Problem 5
5. Section 2.6, Problem 1
6. Section 2.6, Problem 5
Project: Pendulum Clock
In his exposition on pendulum clocks, M. Denny9 modeled the system by the second-
order diﬀerential equation in time t:
θ′′ + bθ′ + ω2
0θ = kf(θ, θ′),
(1)
9 Denny, M., 2002: The pendulum clock: A venerable dynamical system. Eur. J. Phys., 23, 449–458.

96
Advanced Engineering Mathematics with MATLAB
θ
-0.2
-0.1
0
0.1
0.2
θ′
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
Figure 2.9.3: The phase diagram of the dynamical system given by Equations (1) and (2) by modiﬁed
Euler method.
Here the parameters are g = 9.8 m/sec2, L = 1 m, b = 0.22/sec, k = 0.02/sec, and
∆t = 0.005. The initial conditions are θ(0) = π/18 and θ′(0) = 0.
where
f(θ, θ′) =

1/(∆t),
|θ| < ∆t/2,
θ′ > 0;
0,
otherwise;
(2)
and ω2 = g/L −b2/4. Here ∆t denotes some arbitrarily small nondimensional time. In
Chapter 12 we identify this forcing as the Dirac delta function.
Using the numerical scheme of your choice, develop a MATLAB code to numerically
integrate this diﬀerential equation.
Plot the results as a phase diagram with θ as the
abscissa and θ′ as the ordinate. What happens with time? What happens as k varies?
Figure 2.9.3 illustrates the solution.
Further Readings
Boyce, W. E., and R. C. DiPrima, 2004: Elementary Diﬀerential Equations and Boundary
Value Problems. Wiley, 800 pp. Classic textbook.
Ince, E. L., 1956: Ordinary Diﬀerential Equations. Dover, 558 pp. The source book on
ordinary diﬀerential equations.
Zill, D. G., and M. R. Cullen, 2008: Diﬀerential Equations with Boundary-Value Problems.
Brooks Cole, 640 pp. Nice undergraduate textbook.

Chapter 3
Linear Algebra
Linear algebra involves the systematic solving of linear algebraic or diﬀerential equa-
tions that arise during the mathematical modeling of an electrical, mechanical, or even
human system where two or more components are interacting with each other.
In this
chapter we present eﬃcient techniques for expressing these systems and their solutions.
3.1 FUNDAMENTALS OF LINEAR ALGEBRA
Consider the following system of m simultaneous linear equations in n unknowns
x1, x2, x3, . . . , xn:
a11x1 + a12x2 + · · · + a1nxn = b1,
a21x1 + a22x2 + · · · + a2nxn = b2,
...
(3.1.1)
am1x1 + am2x2 + · · · + amnxn = bm,
where the coeﬃcients aij and constants bj denote known real or complex numbers. The
purpose of this chapter is to show how matrix algebra can be used to solve these systems by
ﬁrst introducing succinct notation so that we can replace Equation 3.1.1 with rather simple
expressions, and then by employing a set of rules to manipulate these expressions. In this
section we focus on developing these simple expressions.
The fundamental quantity in linear algebra is the matrix.1
A matrix is an ordered
rectangular array of numbers or mathematical expressions. We shall use upper case letters
1 This term was ﬁrst used by J. J. Sylvester, 1850: Additions to the articles, “On a new class of
theorems,” and “On Pascal’s theorem.” Philos. Mag., Ser. 4, 37, 363–370.
97

98
Advanced Engineering Mathematics with MATLAB
to denote them. The m × n matrix
A =







a11
a12
a13
·
·
·
a1n
a21
a22
a23
·
·
·
a2n
·
·
·
·
·
·
·
·
·
·
·
aij
·
·
·
·
·
·
·
·
·
am1
am2
am3
·
·
·
amn







(3.1.2)
has m rows and n columns. The order (or size) of a matrix is determined by the number
of rows and columns; Equation 3.1.2 is of order m by n. If m = n, the matrix is a square
matrix; otherwise, A is rectangular. The numbers or expressions in the array aij are the
elements of A and can be either real or complex. When all of the elements are real, A is
a real matrix. If some or all of the elements are complex, then A is a complex matrix. For
a square matrix, the diagonal from the top left corner to the bottom right corner is the
principal diagonal.
From the limitless number of possible matrices, certain ones appear with suﬃcient
regularity that they are given special names. A zero matrix (sometimes called a null matrix)
has all of its elements equal to zero. It fulﬁlls the role in matrix algebra that is analogous
to that of zero in scalar algebra. The unit or identity matrix is an n × n matrix having 1’s
along its principal diagonal and zero everywhere else. The unit matrix serves essentially
the same purpose in matrix algebra as does the number one in scalar algebra. A symmetric
matrix is one where aij = aji for all i and j.
• Example 3.1.1
Examples of zero, identity, and symmetric matrices are
O =


0
0
0
0
0
0
0
0
0

,
I =

1
0
0
1

,
and
A =


3
2
4
2
1
0
4
0
5

,
(3.1.3)
respectively.
⊓⊔
A special class of matrices are column vectors and row vectors:
x =




x1
x2
...
xm



,
y = ( y1
y2
· · ·
yn ) .
(3.1.4)
We denote row and column vectors by lower case, boldfaced letters. The length or norm of
the vector x of n elements is
||x|| =
 n
X
k=1
x2
k
!1/2
.
(3.1.5)
Two matrices A and B are equal if and only if aij = bij for all possible i and j and
they have the same dimensions.
Having deﬁned a matrix, let us explore some of its arithmetic properties.
For two
matrices A and B with the same dimensions (conformable for addition), the matrix C =

Linear Algebra
99
A + B contains the elements cij = aij + bij. Similarly, C = A −B contains the elements
cij = aij −bij. Because the order of addition does not matter, addition is commutative:
A + B = B + A.
Consider now a scalar constant k. The product kA is formed by multiplying every
element of A by k. Thus the matrix kA has elements kaij.
So far the rules for matrix arithmetic conform to their scalar counterparts. However,
there are several possible ways of multiplying two matrices together. For example, we might
simply multiply together the corresponding elements from each matrix. As we will see, the
multiplication rule is designed to facilitate the solution of linear equations.
We begin by requiring that the dimensions of A be m × n while for B they are n × p.
That is, the number of columns in A must equal the number of rows in B. The matrices A
and B are then said to be conformable for multiplication. If this is true, then C = AB is a
matrix m × p, where its elements equal
cij =
n
X
k=1
aik bkj.
(3.1.6)
The right side of Equation 3.1.6 is referred to as an inner product of the ith row of A and the
jth column of B. Although Equation 3.1.6 is the method used with a computer, an easier
method for human computation is as a running sum of the products given by successive
elements of the ith row of A and the corresponding elements of the jth column of B.
The product AA is usually written A2; the product AAA, A3, and so forth.
• Example 3.1.2
If
A =

−1
4
2
−3

,
and
B =

1
2
3
4

,
(3.1.7)
then
AB =

[(−1)(1) + (4)(3)]
[(−1)(2) + (4)(4)]
[(2)(1) + (−3)(3)]
[(2)(2) + (−3)(4)]

=

11
14
−7
−8

.
(3.1.8)
Checking our results using MATLAB, we have that
>> A = [-1 4; 2 -3];
>> B = [1 2; 3 4];
>> C = A*B
C =
11
14
−7
−8
Note that there is a tremendous diﬀerence between the MATLAB command for matrix
multiplication ∗and element-by-element multiplication .∗.
⊓⊔
Matrix multiplication is associative and distributive with respect to addition:
(kA)B = k(AB) = A(kB),
(3.1.9)
A(BC) = (AB)C,
(3.1.10)
(A + B)C = AC + BC,
(3.1.11)

100
Advanced Engineering Mathematics with MATLAB
and
C(A + B) = CA + CB.
(3.1.12)
On the other hand, matrix multiplication is not commutative. In general, AB ̸= BA.
• Example 3.1.3
Does AB = BA if
A =

1
0
0
0

,
and
B =

1
1
1
0

?
(3.1.13)
Because
AB =

1
0
0
0
 
1
1
1
0

=

1
1
0
0

,
(3.1.14)
and
BA =

1
1
1
0
 
1
0
0
0

=

1
0
1
0

,
(3.1.15)
AB ̸= BA.
(3.1.16)
⊓⊔
• Example 3.1.4
Given
A =

1
1
3
3

,
and
B =

−1
1
1
−1

,
(3.1.17)
ﬁnd the product AB.
Performing the calculation, we ﬁnd that
AB =

1
1
3
3
 
−1
1
1
−1

=

0
0
0
0

.
(3.1.18)
The point here is that just because AB = 0, this does not imply that either A or B equals
the zero matrix.
⊓⊔
We cannot properly speak of division when we are dealing with matrices. Nevertheless,
a matrix A is said to be nonsingular or invertible if there exists a matrix B such that
AB = BA = I. This matrix B is the multiplicative inverse of A or simply the inverse of A,
written A−1. An n × n matrix is singular if it does not have a multiplicative inverse.
• Example 3.1.5
If
A =


1
0
1
3
3
4
2
2
3

,
(3.1.19)
let us verify that its inverse is
A−1 =


1
2
−3
−1
1
−1
0
−2
3

.
(3.1.20)

Linear Algebra
101
We perform the check by ﬁnding AA−1 or A−1A,
AA−1 =


1
0
1
3
3
4
2
2
3




1
2
−3
−1
1
−1
0
−2
3

=


1
0
0
0
1
0
0
0
1

.
(3.1.21)
In a later section we will show how to compute the inverse, given A.
⊓⊔
Another matrix operation is transposition. The transpose of a matrix A with dimen-
sions m × n is another matrix, written AT , where we interchanged the rows and columns
from A.
In MATLAB, AT is computed by typing A’. Clearly, (AT )T = A as well as
(A + B)T = AT + BT , and (kA)T = kAT . If A and B are conformable for multiplica-
tion, then (AB)T = BT AT . Note the reversal of order between the two sides. To prove this
last result, we ﬁrst show that the results are true for two 3 × 3 matrices A and B and then
generalize to larger matrices.
Having introduced some of the basic concepts of linear algebra, we are ready to rewrite
Equation 3.1.1 in a canonical form so that we can present techniques for its solution. We
begin by writing Equation 3.1.1 as a single column vector:







a11x1
+
a12x2
+
· · ·
+
a1nxn
a21x1
+
a22x2
+
· · ·
+
a2nxn
...
...
...
...
...
...
...
...
am1x1
+
am2x2
+
· · ·
+
amnxn







=







b1
b2
...
...
bm







.
(3.1.22)
We now use the multiplication rule to rewrite Equation 3.1.22 as







a11
a12
· · ·
a1n
a21
a22
· · ·
a2n
...
...
...
...
...
...
...
...
am1
am2
· · ·
amn














x1
x2
...
...
xn







=







b1
b2
...
...
bm







,
(3.1.23)
or
Ax = b,
(3.1.24)
where x is the solution vector. If b = 0, we have a homogeneous set of equations; otherwise,
we have a nonhomogeneous set. In the next few sections, we will give a number of methods
for ﬁnding x.
• Example 3.1.6: Solution of a tridiagonal system
A common problem in linear algebra involves solving systems such as
b1y1 + c1y2 = d1,
(3.1.25)
a2y1 + b2y2 + c2y3 = d2,
(3.1.26)
...
aN−1yN−2 + bN−1yN−1 + cN−1yN = dN−1,
(3.1.27)
bNyN−1 + cNyN = dN.
(3.1.28)

102
Advanced Engineering Mathematics with MATLAB
Such systems arise in the numerical solution of ordinary and partial diﬀerential equations.
We begin by rewriting Equation 3.1.25 through Equation 3.1.28 in the matrix notation:








b1
c1
0
· · ·
0
0
0
a2
b2
c2
· · ·
0
0
0
0
a3
b3
· · ·
0
0
0
...
...
...
...
...
...
...
0
0
0
· · ·
aN−1
bN−1
cN−1
0
0
0
· · ·
0
aN
bN
















y1
y2
y3
...
yN−1
yN








=








d1
d2
d3
...
dN−1
dN








.
(3.1.29)
The matrix in Equation 3.1.29 is an example of a banded matrix: a matrix where all of
the elements in each row are zero except for the diagonal element and a limited number
on either side of it. In the present case, we have a tridiagonal matrix in which only the
diagonal element and the elements immediately to its left and right in each row are nonzero.
Consider the nth equation. We can eliminate an by multiplying the (n −1)th equation
by an/bn−1 and subtracting this new equation from the nth equation. The values of bn and
dn become
b′
n = bn −ancn−1/bn−1,
and
d′
n = dn −andn−1/bn−1
(3.1.30)
for n = 2, 3, . . . , N. The coeﬃcient cn is unaﬀected. Because elements a1 and cN are never
involved, their values can be anything or they can be left undeﬁned. The new system of
equations may be written








b′
1
c1
0
· · ·
0
0
0
0
b′
2
c2
· · ·
0
0
0
0
0
b′
3
· · ·
0
0
0
...
...
...
...
...
...
...
0
0
0
· · ·
0
b′
N−1
cN−1
0
0
0
· · ·
0
0
b′
N
















y1
y2
y3
...
yN−1
yN








=








d′
1
d′
2
d′
3
...
d′
N−1
d′
N








.
(3.1.31)
The matrix in Equation 3.1.31 is in upper triangular form because all of the elements
below the principal diagonal are zero. This is particularly useful because yn can be computed
by back substitution. That is, we ﬁrst compute yN. Next, we calculate yN−1 in terms of
yN. The solution yN−2 can then be computed in terms of yN and yN−1. We continue this
process until we ﬁnd y1 in terms of yN, yN−1, . . . , y2. In the present case, we have the rather
simple:
yN = d′
N/b′
N,
and
yn = (d′
n −cnd′
n+1)/b′
n
(3.1.32)
for n = N −1, N −2, . . . , 2, 1.
As we shall show shortly, this is an example of solving a system of linear equations
by Gaussian elimination. For a tridiagonal case, we have the advantage that the solution
can be expressed in terms of a recurrence relationship, a very convenient feature from
a computational point of view.
This algorithm is very robust, being stable2 as long as
|ai + ci| < |bi|. By stability, we mean that if we change b by ∆b so that x changes by ∆x,
then ||∆x|| < Mǫ, where ||∆b|| ≤ǫ, 0 < M < ∞, for any N.
2 Torii, T., 1966: Inversion of tridiagonal matrices and the stability of tridiagonal systems of linear
systems. Tech. Rep. Osaka Univ., 16, 403–414.

Linear Algebra
103
• Example 3.1.7: Linear transformation
Consider a set of linear equations
y1 = a11x1 + a12x2 + a13x3 + a14x4,
y2 = a21x1 + a22x2 + a23x3 + a14x4,
(3.1.33)
y3 = a31x1 + a31x2 + a33x3 + a34x4.
Each of the right-side expressions is called a linear combination of x1, x2, x3, and x4: a sum
where each term consists of a constant times xi raised to the ﬁrst power. An expression
such as a11x2
1 + a12x2
2 + a13x2
3 + a14x2
4 is an example of a nonlinear combination. Note that
we are using 4 values of xi to ﬁnd only 3 values of yi.
If we were given values of xi, we can determine a set of values for yi using Equation
3.1.33. Such a set of linear equations that yields values of yi for given xi’s is called a linear
transform of x into y. The point here is that given x, the corresponding y will be evaluated.
Matrix notation and multiplication are very convenient in expressing linear transfor-
mation. In the present case, we would have that
y = Ax,
where
x =



x1
x2
x3
x4


,
A =


a11
a12
a13
a14
a21
a22
a23
a24
a31
a32
a33
a34

,
y =


y1
y2
y3

. (3.1.34)
In general, a transformation A(x) is a linear transformation that satisﬁes two conditions:
(1) A(x + y) = A(x) + A(y) and (2) A(kx) = kA(x), where k is a scalar.
Problems
Given A =

3
4
1
2

, and B =

1
1
2
2

, ﬁnd
1. A + B, B + A
2. A −B, B −A
3. 3A −2B, 3(2A −B)
4. AT ,BT ,(BT )T
5. (A + B)T , AT + BT
6. B + BT , B −BT
7. AB,AT B,BA,BT A
8. A2, B2
9. BBT , BT B
10. A2 −3A + I
11. A3 + 2A
12. A4 −4A2 + 2I
by hand and using MATLAB.
Can multiplication occur between the following matrices? If so, compute it.
13.

3
5
1
−2
1
2
 

2
1
4
1
1
3


14.


−2
4
−4
6
−6
1

( 1
2
3 )
15.


1
4
2
0
0
4
0
1
2




3
2
1
1
2
1


16.

4
6
1
2
 
1
3
6
1
2
5

17.

6
4
2
1
2
3
 
3
1
4
2
0
6

If A =


1
1
1
2
3
1

, verify that

104
Advanced Engineering Mathematics with MATLAB
18. 7A = 4A + 3A,
19. 10A = 5(2A),
20. (AT )T = A
by hand and using MATLAB.
If A =

2
1
3
1

, B =

1
−2
4
0

, and C =

1
1
1
1

, verify that
21. (A + B) + C = A + (B + C),
22. (AB)C = A(BC),
23. A(B + C) = AB + AC,
24. (A + B)C = AC + BC
by hand and using MATLAB.
Verify that the following A−1 are indeed the inverse of A:
25. A =

3
−1
−5
2

A−1 =

2
1
5
3

26. A =


0
1
0
1
0
0
0
0
1


A−1 =


0
1
0
1
0
0
0
0
1


by hand and using MATLAB.
Write the following linear systems of equations in matrix form: Ax = b.
27. x1 −2x2 = 5
3x1 + x2 = 1
28. 2x1 + x2 + 4x3 = 2
4x1 + 2x2 + 5x3 = 6
6x1 −3x2 + 5x3 = 2
29. x2 + 2x3 + 3x4 = 2
3x1 −4x3 −4x4 = 5
x1 + x2 + x3 + x4 = −3
2x1 −3x2 + x3 −3x4 = 7
3.2 DETERMINANTS
Determinants appear naturally during the solution of simultaneous equations. Con-
sider, for example, two simultaneous equations with two unknowns x1 and x2,
a11x1 + a12x2 = b1,
(3.2.1)
and
a21x1 + a22x2 = b2.
(3.2.2)
The solution to these equations for the value of x1 and x2 is
x1 =
b1a22 −a12b2
a11a22 −a12a21
,
(3.2.3)
and
x2 =
b2a11 −a21b1
a11a22 −a12a21
.
(3.2.4)
Note that the denominator of Equation 3.2.3 and Equation 3.2.4 is the same. This term,
which always appears in the solution of 2 × 2 systems, is formally given the name of deter-
minant and written
det(A) =

a11
a12
a21
a22
 = a11a22 −a12a21.
(3.2.5)

Linear Algebra
105
MATLAB provides a simple command det(A), which computes the determinant of A.
For example, in the present case,
>> A = [2 -1 2; 1 3 2; 5 1 6];
>> det(A)
ans =
0
Although determinants have their origin in the solution of systems of equations, any
square array of numbers or expressions possesses a unique determinant, independent of
whether it is involved in a system of equations or not. This determinant is evaluated (or
expanded) according to a formal rule known as Laplace’s expansion of cofactors.3
The
process revolves around expanding the determinant using any arbitrary column or row of
A. If the ith row or jth column is chosen, the determinant is given by
det(A) = ai1Ai1 + ai2Ai2 + · · · + ainAin = a1jA1j + a2jA2j + · · · + anjAnj,
(3.2.6)
where Aij, the cofactor of aij, equals (−1)i+jMij. The minor Mij is the determinant of the
(n −1) × (n −1) submatrix obtained by deleting row i, column j of A. This rule, of course,
was chosen so that determinants are still useful in solving systems of equations.
• Example 3.2.1
Let us evaluate

2
−1
2
1
3
2
5
1
6

by an expansion in cofactors.
Using the ﬁrst column,

2
−1
2
1
3
2
5
1
6

= 2(−1)2

3
2
1
6
 + 1(−1)3

−1
2
1
6
 + 5(−1)4

−1
2
3
2

(3.2.7)
= 2(16) −1(−8) + 5(−8) = 0.
(3.2.8)
The greatest source of error is forgetting to take the factor (−1)i+j into account during the
expansion.
⊓⊔
Although Laplace’s expansion does provide a method for calculating det(A), the num-
ber of calculations equals n!. Consequently, for hand calculations, an obvious strategy is to
select the column or row that has the greatest number of zeros. An even better strategy
would be to manipulate a determinant with the goal of introducing zeros into a particular
column or row. In the remaining portion of this section, we show some operations that may
be performed on a determinant to introduce the desired zeros. Most of the properties follow
from the expansion of determinants by cofactors.
• Rule 1
: For every square matrix A, det(AT ) = det(A).
3 Laplace, P. S., 1772: Recherches sur le calcul int´egral et sur le syst`eme du monde. Hist. Acad. R.
Sci., IIe Partie, 267–376. Œuvres, 8, pp. 369–501. See Muir, T., 1960: The Theory of Determinants in
the Historical Order of Development, Vol. I, Part 1, General Determinants Up to 1841. Dover Publishers,
pp. 24–33.

106
Advanced Engineering Mathematics with MATLAB
The proof is left as an exercise.
• Rule 2
: If any two rows or columns of A are identical, det(A) = 0.
To see that this is true, consider the following 3 × 3 matrix:

b1
b1
c1
b2
b2
c2
b3
b3
c3

= c1(b2b3 −b3b2) −c2(b1b3 −b3b1) + c3(b1b2 −b2b1) = 0.
(3.2.9)
• Rule 3
: The determinant of a triangular matrix is equal to the product of its diagonal
elements.
If A is lower triangular, successive expansions by elements in the ﬁrst column give
det(A) =

a11
0
· · ·
0
a21
a22
· · ·
0
...
...
...
...
an1
an2
· · ·
ann

= a11

a22
· · ·
0
...
...
...
an2
· · ·
ann

= · · · = a11a22 · · · ann.
(3.2.10)
If A is upper triangular, successive expansions by elements of the ﬁrst row prove the prop-
erty.
• Rule 4
: If a square matrix A has either a row or a column of all zeros, then det(A) = 0.
The proof is left as an exercise.
• Rule 5
: If each element in one row (column) of a determinant is multiplied by a number
c, the value of the determinant is multiplied by c.
Suppose that |B| has been obtained from |A| by multiplying row i (column j) of |A| by
c. Upon expanding |B| in terms of row i (column j), each term in the expansion contains
c as a factor. Factor out the common c, and the result is just c times the expansion |A| by
the same row (column).
• Rule 6
: If each element of a row (or a column) of a determinant can be expressed as a
binomial, the determinant can be written as the sum of two determinants.
To understand this property, consider the following 3 × 3 determinant:

a1 + d1
b1
c1
a2 + d2
b2
c2
a3 + d3
b3
c3

=

a1
b1
c1
a2
b2
c2
a3
b3
c3

+

d1
b1
c1
d2
b2
c2
d3
b3
c3

.
(3.2.11)
The proof follows by expanding the determinant by the row (or column) that contains the
binomials.
• Rule 7
: If B is a matrix obtained by interchanging any two rows (columns) of a square
matrix A, then det(B) = −det(A).

Linear Algebra
107
The proof is by induction. It is easily shown for any 2 × 2 matrix. Assume that this
rule holds for any (n −1) × (n −1) matrix. If A is n × n, then let B be a matrix formed by
interchanging rows i and j. Expanding |B| and |A| by a diﬀerent row, say k, we have that
|B| =
n
X
s=1
(−1)k+sbksMks,
and
|A| =
n
X
s=1
(−1)k+saksNks,
(3.2.12)
where Mks and Nks are the minors formed by deleting row k, column s from |B| and |A|,
respectively. For s = 1, 2, . . . , n, we obtain Nks and Mks by interchanging rows i and j. By
the induction hypothesis and recalling that Nks and Mks are (n−1)×(n−1) determinants,
Nks = −Mks for s = 1, 2, . . . , n. Hence, |B| = −|A|. Similar arguments hold if two columns
are interchanged.
• Rule 8
: If one row (column) of a square matrix A equals to a number c times some
other row (column), then det(A) = 0.
Suppose one row of a square matrix A is equal to c times some other row. If c = 0,
then |A| = 0. If c ̸= 0, then |A| = c|B|, where |B| = 0 because |B| has two identical rows.
A similar argument holds for two columns.
• Rule 9
: The value of det(A) is unchanged if any arbitrary multiple of any line (row or
column) is added to any other line.
To see that this is true, consider the simple example:

a1
b1
c1
a2
b2
c2
a3
b3
c3

+

cb1
b1
c1
cb2
b2
c2
cb3
b3
c3

=

a1 + cb1
b1
c1
a2 + cb2
b2
c2
a3 + cb3
b3
c3

,
(3.2.13)
where c ̸= 0. The ﬁrst determinant on the left side is our original determinant. In the
second determinant, we again expand the ﬁrst column and ﬁnd that

cb1
b1
c1
cb2
b2
c2
cb3
b3
c3

= c

b1
b1
c1
b2
b2
c2
b3
b3
c3

= 0.
(3.2.14)
• Example 3.2.2
Let us evaluate

1
2
3
4
−1
1
2
3
1
−1
1
2
−1
1
−1
5

using a combination of the properties stated above and expansion by cofactors.
By adding or subtracting the ﬁrst row to the other rows, we have that

1
2
3
4
−1
1
2
3
1
−1
1
2
−1
1
−1
5

=

1
2
3
4
0
3
5
7
0
−3
−2
−2
0
3
2
9

=

3
5
7
−3
−2
−2
3
2
9

(3.2.15)
=

3
5
7
0
3
5
0
−3
2

= 3

3
5
−3
2
 = 3

3
5
0
7
 = 63.
(3.2.16)

108
Advanced Engineering Mathematics with MATLAB
Problems
Evaluate the following determinants. Check your answer using MATLAB.
1.

3
5
−2
−1

2.

5
−1
−8
4

3.

3
1
2
2
4
5
1
4
5

4.

4
3
0
3
2
2
5
−2
−4

5.

1
3
2
4
1
1
2
1
3

6.

2
−1
2
1
3
3
5
1
6

7.

2
0
0
1
0
1
0
0
1
6
1
0
1
1
−2
3

8.

2
1
2
1
3
0
2
2
−1
2
−1
1
−3
2
3
1

9. Using the properties of determinants, show that

1
1
1
1
a
b
c
d
a2
b2
c2
d2
a3
b3
c3
d3

= (b −a)(c −a)(d −a)(c −b)(d −b)(d −c).
This determinant is called Vandermonde’s determinant.
10. Show that

a
b + c
1
b
a + c
1
c
a + b
1

= 0.
11. Show that if all of the elements of a row or column are zero, then det(A) = 0.
12. Prove that det(AT ) = det(A).
3.3 CRAMER’S RULE
One of the most popular methods for solving simple systems of linear equations is
Cramer’s rule.4 It is very useful for 2 × 2 systems, acceptable for 3 × 3 systems, and of
doubtful use for 4 × 4 or larger systems.
Let us have n equations with n unknowns, Ax = b. Cramer’s rule states that
x1 = det(A1)
det(A) ,
x2 = det(A2)
det(A) ,
· · · ,
xn = det(An)
det(A) ,
(3.3.1)
where Ai is a matrix obtained from A by replacing the ith column with b and n is the
number of unknowns and equations. Obviously, det(A) ̸= 0 if Cramer’s rule is to work.
4 Cramer, G., 1750: Introduction `a l’analyse des lignes courbes alg´ebriques. Geneva, p. 657.

Linear Algebra
109
To prove5 Cramer’s rule, consider
x1 det(A) =

a11x1
a12
a13
· · ·
a1n
a21x1
a22
a23
· · ·
a2n
a31x1
a32
a33
· · ·
a3n
...
...
...
...
...
an1x1
an2
an3
· · ·
ann

(3.3.2)
by Rule 5 from the previous section. By adding x2 times the second column to the ﬁrst
column,
x1 det(A) =

a11x1 + a12x2
a12
a13
· · ·
a1n
a21x1 + a22x2
a22
a23
· · ·
a2n
a31x1 + a32x2
a32
a33
· · ·
a3n
...
...
...
...
...
an1x1 + an2x2
an2
an3
· · ·
ann

.
(3.3.3)
Multiplying each of the columns by the corresponding xi and adding it to the ﬁrst column
yields
x1 det(A) =

a11x1 + a12x2 + · · · + a1nxn
a12
a13
· · ·
a1n
a21x1 + a22x2 + · · · + a2nxn
a22
a23
· · ·
a2n
a31x1 + a32x2 + · · · + a3nxn
a32
a33
· · ·
a3n
...
...
...
...
...
an1x1 + an2x2 + · · · + annxn
an2
an3
· · ·
ann

.
(3.3.4)
The ﬁrst column of Equation 3.3.4 equals Ax and we replace it with b. Thus,
x1 det(A) =

b1
a12
a13
· · ·
a1n
b2
a22
a23
· · ·
a2n
b3
a32
a33
· · ·
a3n
...
...
...
...
...
bn
an2
an3
· · ·
ann

= det(A1),
(3.3.5)
or
x1 = det(A1)
det(A)
(3.3.6)
provided det(A) ̸= 0. To complete the proof we do exactly the same procedure to the jth
column.
• Example 3.3.1
Let us solve the following system of equations by Cramer’s rule:
2x1 + x2 + 2x3 = −1,
(3.3.7)
x1 + x3 = −1,
(3.3.8)
5 First proved by Cauchy, L. A., 1815: M´emoire sur les fonctions quine peuvent obtemir que deux valeurs
´egales et de signes contraires par suite des transportations op´er´ees entre les variables q´uelles renferment. J.
l’ ´Ecole Polytech., 10, 29–112.

110
Advanced Engineering Mathematics with MATLAB
and
−x1 + 3x2 −2x3 = 7.
(3.3.9)
From the matrix form of the equations,


2
1
2
1
0
1
−1
3
−2




x1
x2
x3

=


−1
−1
7

,
(3.3.10)
we have that
det(A) =

2
1
2
1
0
1
−1
3
−2

= 1,
(3.3.11)
det(A1) =

−1
1
2
−1
0
1
7
3
−2

= 2,
(3.3.12)
det(A2) =

2
−1
2
1
−1
1
−1
7
−2

= 1,
(3.3.13)
and
det(A3) =

2
1
−1
1
0
−1
−1
3
7

= −3.
(3.3.14)
Finally,
x1 = 2
1 = 2,
x2 = 1
1 = 1,
and
x3 = −3
1 = −3.
(3.3.15)
You can also use MATLAB to perform Cramer’s rule. In the present example, the script
is as follows:
clear; % clear all previous computations
A = [2 1 2; 1 0 1; -1 3 -2]; % input coefficient matrix
b = [-1 ; -1; 7]; % input right side
A1 = A; A1(:,1) = b; % compute A 1
A2 = A; A2(:,2) = b; % compute A 2
A3 = A; A3(:,3) = b; % compute A 3
% compute solution vector
x = [det(A1), det(A2), det(A3)] / det(A)
Problems
Solve the following systems of equations by Cramer’s rule:
1. x1 + 2x2 = 3,
3x1 + x2 = 6
2. 2x1 + x2 = −3,
x1 −x2 = 1
3. x1 + 2x2 −2x3 = 4,
2x1 + x2 + x3 = −2,
−x1 + x2 −x3 = 2
4. 2x1 + 3x2 −x3 = −1,
−x1 −2x2 + x3 = 5,
3x1 −x2 = −2.
Check your answer using MATLAB.

Linear Algebra
111
3.4 ROW ECHELON FORM AND GAUSSIAN ELIMINATION
So far, we assumed that every system of equations has a unique solution. This is not
necessarily true, as the following examples show.
• Example 3.4.1
Consider the system
x1 + x2 = 2
(3.4.1)
and
2x1 + 2x2 = −1.
(3.4.2)
This system is inconsistent because the second equation does not follow after multiplying
the ﬁrst by 2. Geometrically, Equation 3.4.1 and Equation 3.4.2 are parallel lines; they
never intersect to give a unique x1 and x2.
⊓⊔
• Example 3.4.2
Even if a system is consistent, it still may not have a unique solution. For example,
the system
x1 + x2 = 2
(3.4.3)
and
2x1 + 2x2 = 4
(3.4.4)
is consistent, with the second equation formed by multiplying the ﬁrst by 2. However, there
are an inﬁnite number of solutions.
⊓⊔
Our examples suggest the following:
Theorem: A system of m linear equations in n unknowns may: (1) have no solution, in
which case it is called an inconsistent system, or (2) have exactly one solution (called a
unique solution), or (3) have an inﬁnite number of solutions. In the latter two cases, the
system is said to be consistent.
Before we can prove this theorem at the end of this section, we need to introduce some
new concepts.
The ﬁrst one is equivalent systems.
Two systems of equations involving the same
variables are equivalent if they have the same solution set.
Of course, the only reason
for introducing equivalent systems is the possibility of transforming one system of linear
systems into another that is easier to solve. But what operations are permissible? Also,
what is the ultimate goal of our transformation?
From a complete study of possible operations, there are only three operations for trans-
forming one system of linear equations into another. These three elementary row operations
are
(1) interchanging any two rows in the matrix,
(2) multiplying any row by a nonzero scalar, and
(3) adding any arbitrary multiple of any row to any other row.

112
Advanced Engineering Mathematics with MATLAB
Armed with our elementary row operations, let us now solve the following set of linear
equations:
x1 −3x2 + 7x3 = 2,
(3.4.5)
2x1 + 4x2 −3x3 = −1,
(3.4.6)
and
−x1 + 13x2 −21x3 = 2.
(3.4.7)
We begin by writing Equation 3.4.5 through Equation 3.4.7 in matrix notation:


1
−3
7
2
4
−3
−1
13
−21




x1
x2
x3

=


2
−1
2

.
(3.4.8)
The matrix in Equation 3.4.8 is called the coeﬃcient matrix of the system.
We now introduce the concept of the augmented matrix: a matrix B composed of A
plus the column vector b or
B =


1
−3
7
2
4
−3
−1
13
−21

2
−1
2

.
(3.4.9)
We can solve our original system by performing elementary row operations on the augmented
matrix. Because xi functions essentially as a placeholder, we can omit them until the end
of the computation.
Returning to the problem, the ﬁrst row can be used to eliminate the elements in the
ﬁrst column of the remaining rows. For this reason the ﬁrst row is called the pivotal row
and the element a11 is the pivot. By using the third elementary row operation twice (to
eliminate the 2 and −1 in the ﬁrst column), we have the equivalent system
B =


1
−3
7
0
10
−17
0
10
−14

2
−5
4

.
(3.4.10)
At this point we choose the second row as our new pivotal row and again apply the third
row operation to eliminate the last element in the second column. This yields
B =


1
−3
7
0
10
−17
0
0
3

2
−5
9

.
(3.4.11)
Thus, elementary row operations transformed Equation 3.4.5 through Equation 3.4.7 into
the triangular system:
x1 −3x2 + 7x3 = 2,
(3.4.12)
10x2 −17x3 = −5,
(3.4.13)
3x3 = 9,
(3.4.14)
which is equivalent to the original system. The ﬁnal solution is obtained by back substitution,
solving from Equation 3.4.14 back to Equation 3.4.12. In the present case, x3 = 3. Then,
10x2 = 17(3) −5, or x2 = 4.6. Finally, x1 = 3x2 −7x3 + 2 = −5.2.

Linear Algebra
113
In general, if an n × n linear system can be reduced to triangular form, then it has a
unique solution that we can obtain by performing back substitution. This reduction involves
n −1 steps. In the ﬁrst step, a pivot element, and thus the pivotal row, is chosen from the
nonzero entries in the ﬁrst column of the matrix. We interchange rows (if necessary) so that
the pivotal row is the ﬁrst row. Multiples of the pivotal row are then subtracted from each
of the remaining n −1 rows so that there are 0’s in the (2, 1), ..., (n, 1) positions. In the
second step, a pivot element is chosen from the nonzero entries in column 2, rows 2 through
n, of the matrix. The row containing the pivot is then interchanged with the second row
(if necessary) of the matrix and is used as the pivotal row. Multiples of the pivotal row are
then subtracted from the remaining n −2 rows, eliminating all entries below the diagonal
in the second column. The same procedure is repeated for columns 3 through n −1. Note
that in the second step, row 1 and column 1 remain unchanged, in the third step the ﬁrst
two rows and ﬁrst two columns remain unchanged, and so on.
If elimination is carried out as described, we arrive at an equivalent upper triangular
system after n −1 steps. However, the procedure fails if, at any step, all possible choices
for a pivot element equal zero. Let us now examine such cases.
Consider now the system
x1 + 2x2 + x3 = −1,
(3.4.15)
2x1 + 4x2 + 2x3 = −2,
(3.4.16)
x1 + 4x2 + 2x3 = 2.
(3.4.17)
Its augmented matrix is
B =


1
2
1
2
4
2
1
4
2

−1
−2
2

.
(3.4.18)
Choosing the ﬁrst row as our pivotal row, we ﬁnd that
B =


1
2
1
0
0
0
0
2
1

−1
0
3

,
(3.4.19)
or
B =


1
2
1
0
2
1
0
0
0

−1
3
0

.
(3.4.20)
The diﬃculty here is the presence of the zeros in the third row. Clearly any ﬁnite numbers
satisfy the equation 0x1 +0x2 +0x3 = 0 and we have an inﬁnite number of solutions. Closer
examination of the original system shows an underdetermined system; Equation 3.4.15 and
Equation 3.4.16 diﬀer by a multiplicative factor of 2. An important aspect of this problem
is the fact that the ﬁnal augmented matrix is of the form of a staircase or echelon form
rather than of triangular form.
Let us modify Equation 3.4.15 through Equation 3.4.17 to read
x1 + 2x2 + x3 = −1,
(3.4.21)
2x1 + 4x2 + 2x3 = 3,
(3.4.22)
x1 + 4x2 + 2x3 = 2,
(3.4.23)

114
Advanced Engineering Mathematics with MATLAB
then the ﬁnal augmented matrix is
B =


1
2
1
0
2
1
0
0
0

−1
3
5

.
(3.4.24)
We again have a problem with the third row because 0x1+0x2+0x3 = 5, which is impossible.
There is no solution in this case and we have an inconsistent system. Note, once again, that
our augmented matrix has a row echelon form rather than a triangular form.
In summary, to include all possible situations in our procedure, we must rewrite the
augmented matrix in row echelon form. We have row echelon form when:
(1) The ﬁrst nonzero entry in each row is 1.
(2) If row k does not consist entirely of zeros, the number of leading zero entries in
row k + 1 is greater than the number of leading zero entries in row k.
(3) If there are rows whose entries are all zero, they are below the rows having
nonzero entries.
The number of nonzero rows in the row echelon form of a matrix is known as its rank. In
MATLAB, the rank is easily found using the command rank( ). Gaussian elimination is
the process of using elementary row operations to transform a linear system into one whose
augmented matrix is in row echelon form.
• Example 3.4.3
Each of the following matrices is not of row echelon form because they violate one of
the conditions for row echelon form:


2
2
3
0
2
1
0
0
4

,

0
0
0
0
2
0

,

0
1
1
0

.
(3.4.25)
⊓⊔
• Example 3.4.4
The following matrices are in row echelon form:


1
2
3
0
1
1
0
0
1

,


1
4
6
0
0
1
0
0
0

,


1
3
4
0
0
0
1
3
0
0
0
0

.
(3.4.26)
⊓⊔
• Example 3.4.5
Gaussian elimination can also be used to solve the general problem AX = B. One of
the most common applications is in ﬁnding the inverse. For example, let us ﬁnd the inverse
of the matrix
A =


4
−2
2
−2
−4
4
−4
2
8


(3.4.27)

Linear Algebra
115
by Gaussian elimination.
Because the inverse is deﬁned by AA−1 = I, our augmented matrix is


4
−2
2
−2
−4
4
−4
2
8

1
0
0
0
1
0
0
0
1

.
(3.4.28)
Then, by elementary row operations,


4
−2
2
−2
−4
4
−4
2
8

1
0
0
0
1
0
0
0
1

=


−2
−4
4
4
−2
2
−4
2
8

0
1
0
1
0
0
0
0
1


(3.4.29)
=


−2
−4
4
4
−2
2
0
0
10

0
1
0
1
0
0
1
0
1


(3.4.30)
=


−2
−4
4
0
−10
10
0
0
10

0
1
0
1
2
0
1
0
1


(3.4.31)
=


−2
−4
4
0
−10
0
0
0
10

0
1
0
0
2
−1
1
0
1


(3.4.32)
=


−2
−4
0
0
−10
0
0
0
10

−2/5
1
−2/5
0
2
−1
1
0
1


(3.4.33)
=


−2
0
0
0
−10
0
0
0
10

−2/5
1/5
0
0
2
−1
1
0
1


(3.4.34)
=


1
0
0
0
1
0
0
0
1

1/5
−1/10
0
0
−1/5
1/10
1/10
0
1/10

.
(3.4.35)
Thus, the right half of the augmented matrix yields the inverse and it equals
A−1 =


1/5
−1/10
0
0
−1/5
1/10
1/10
0
1/10

.
(3.4.36)
MATLAB has the ability of doing Gaussian elimination step by step.
We begin by
typing
>>% input augmented matrix
>>aug = [4 -2 2 1 0 0 ; -2 -4 4 0 1 0;-4 2 8 0 0 1];
>>rrefmovie(aug);
The MATLAB command rrefmovie(A) produces the reduced row echelon form of A.
Repeated pressing of any key gives the next step in the calculation along with a statement
of how it computed the modiﬁed augmented matrix. Eventually you obtain
A =
1
0
0
1/5
-1/10
0

116
Advanced Engineering Mathematics with MATLAB
0
1
0
0
-1/5
1/10
0
0
1
1/10
0
1/10
You can read the inverse matrix just as we did earlier.
⊓⊔
Gaussian elimination may be used with overdetermined systems. Overdetermined sys-
tems are linear systems where there are more equations than unknowns (m > n). These
systems are usually (but not always) inconsistent.
• Example 3.4.6
Consider the linear system
x1 + x2 = 1,
(3.4.37)
−x1 + 2x2 = −2,
(3.4.38)
x1 −x2 = 4.
(3.4.39)
After several row operations, the augmented matrix


1
1
−1
2
1
−1

1
−2
4


(3.4.40)
becomes


1
1
0
1
0
0

1
2
−7

.
(3.4.41)
From the last row of the augmented matrix, Equation 3.4.41, we see that the system is
inconsistent.
If we test this system using MATLAB by typing
>>% input augmented matrix
>>aug = [1 1 1 ; -1 2 -2; 1 -1 4];
>>rrefmovie(aug);
eventually you obtain
A =
1
0
0
0
1
0
0
0
1
Although the numbers have changed from our hand calculation, we still have an inconsistent
system because x1 = x2 = 0 does not satisfy x1 + x2 = 1.
Considering now a slight modiﬁcation of this system to
x1 + x2 = 1,
(3.4.42)
−x1 + 2x2 = 5,
(3.4.43)
x1 = −1,
(3.4.44)

Linear Algebra
117
the ﬁnal form of the augmented matrix is


1
1
0
1
0
0

1
2
0

,
(3.4.45)
which has the unique solution x1 = −1 and x2 = 2.
How does MATLAB handle this problem? Typing
>>% input augmented matrix
>>aug = [1 1 1 ; -1 2 5; 1 0 -1];
>>rrefmovie(aug);
we eventually obtain
A =
1
0
-1
0
1
2
0
0
0
This yields x1 = −1 and x2 = 2, as we found by hand.
Finally, by introducing the set:
x1 + x2 = 1,
(3.4.46)
2x1 + 2x2 = 2,
(3.4.47)
3x1 + 3x3 = 3,
(3.4.48)
the ﬁnal form of the augmented matrix is


1
1
0
0
0
0

1
0
0

.
(3.4.49)
There are an inﬁnite number of solutions: x1 = 1 −α, and x2 = α.
Turning to MATLAB, we ﬁrst type
>>% input augmented matrix
>>aug = [1 1 1 ; 2 2 2; 3 3 3];
>>rrefmovie(aug);
and we eventually obtain
A =
1
1
1
0
0
0
0
0
0
This is the same as Equation 3.4.49 and the ﬁnal answer is the same.
⊓⊔
Gaussian elimination can also be employed with underdetermined systems. An under-
determined linear system is one where there are fewer equations than unknowns (m < n).
These systems usually have an inﬁnite number of solutions although they can be inconsis-
tent.

118
Advanced Engineering Mathematics with MATLAB
• Example 3.4.7
Consider the underdetermined system:
2x1 + 2x2 + x3 = −1,
(3.4.50)
4x1 + 4x2 + 2x3 = 3.
(3.4.51)
Its augmented matrix can be transformed into the form:

2
2
1
0
0
0

−1
5

.
(3.4.52)
Clearly this case corresponds to an inconsistent set of equations. On the other hand, if
Equation 3.4.51 is changed to
4x1 + 4x2 + 2x3 = −2,
(3.4.53)
then the ﬁnal form of the augmented matrix is

2
2
1
0
0
0

−1
0

(3.4.54)
and we have an inﬁnite number of solutions, namely x3 = α, x2 = β, and 2x1 = −1−α−2β.⊓⊔
Consider now one of the most important classes of linear equations: the homogeneous
equations Ax = 0. If det(A) ̸= 0, then by Cramer’s rule x1 = x2 = x3 = · · · = xn = 0.
Thus, the only possibility for a nontrivial solution is det(A) = 0. In this case, A is singular,
no inverse exists, and nontrivial solutions exist but they are not unique.
• Example 3.4.8
Consider the two homogeneous equations:
x1 + x2 = 0,
(3.4.55)
x1 −x2 = 0.
(3.4.56)
Note that det(A) = −2. Solving this system yields x1 = x2 = 0.
However, if we change the system to
x1 + x2 = 0,
(3.4.57)
x1 + x2 = 0,
(3.4.58)
which has the det(A) = 0 so that A is singular. Both equations yield x1 = −x2 = α,
any constant. Thus, there is an inﬁnite number of solutions for this set of homogeneous
equations.
⊓⊔
We close this section by outlining the proof of the theorem, which we introduced at
the beginning.
Consider the system Ax = b. By elementary row operations, the ﬁrst equation in this
system can be reduced to
x1 + α12x2 + · · · + α1nxn = β1.
(3.4.59)

Linear Algebra
119
The second equation has the form
xp + α2p+1xp+1 + · · · + α2nxn = β2,
(3.4.60)
where p > 1. The third equation has the form
xq + α3q+1xq+1 + · · · + α3nxn = β3,
(3.4.61)
where q > p, and so on. To simplify the notation, we introduce zi where we choose the
ﬁrst k values so that z1 = x1, z2 = xp, z3 = xq, . . .. Thus, the question of the existence
of solutions depends upon the three integers: m, n, and k. The resulting set of equations
have the form:











1
γ12
· · ·
γ1k
γ1k+1
· · ·
γ1n
0
1
· · ·
γ2k
γ2k+1
· · ·
γ2n
...
0
0
· · ·
1
γkk+1
· · ·
γkn
0
0
· · ·
0
0
· · ·
0
...
0
0
· · ·
0
0
· · ·
0






















z1
z2
...
zk
zk+1
...
zn











=











β1
β2
...
βk
βk+1
...
βm











.
(3.4.62)
Note that βk+1, . . ., βm need not be all zero.
There are three possibilities:
(a) k < m and at least one of the elements βk+1, . . . , βm is nonzero. Suppose that an
element βp is nonzero (p > k). Then the pth equation is
0z1 + 0z2 + · · · + 0zn = βp ̸= 0.
(3.4.63)
However, this is a contradiction and the equations are inconsistent.
(b) k = n and either (i) k < m and all of the elements βk+1, . . . , βm are zero, or
(ii) k = m. Then the equations have a unique solution that can be obtained by back-
substitution.
(c) k < n and either (i) k < m and all of the elements βk+1, . . . , βm are zero, or (ii)
k = m. Then, arbitrary values can be assigned to the n −k variables zk+1, . . . , zn. The
equations can be solved for z1, z2, . . . , zk and there is an inﬁnity of solutions.
For homogeneous equations b = 0, all of the βi are zero. In this case, we have only
two cases:
(b′) k = n, then Equation 3.4.62 has the solution z = 0, which leads to the trivial
solution for the original system Ax = 0.
(c′) k < n, the equations possess an inﬁnity of solutions given by assigning arbitrary
values to zk+1, . . . , zn.
Problems
Solve the following systems of linear equations by Gaussian elimination. Check your answer
using MATLAB.
1. 2x1 + x2 = 4,
5x1 −2x2 = 1
2. x1 + x2 = 0,
3x1 −4x2 = 1
3. −x1 + x2 + 2x3 = 0,
3x1 + 4x2 + x3 = 0,
−x1 + x2 + 2x3 = 0

120
Advanced Engineering Mathematics with MATLAB
4. 4x1 + 6x2 + x3 = 2,
2x1 + x2 −4x3 = 3,
3x1 −2x2 + 5x3 = 8
5. 3x1 + x2 −2x3 = −3,
x1 −x2 + 2x3 = −1,
−4x1 + 3x2 −6x3 = 4
6. x1 −3x2 + 7x3 = 2,
2x1 + 4x2 −3x3 = −1,
−3x1 + 7x2 + 2x3 = 3
7. x1 −x2 + 3x3 = 5,
2x1 −4x2 + 7x3 = 7,
4x1 −9x2 + 2x3 = −15
8. x1 + x2 + x3 + x4 = −1,
2x1 −x2 + 3x3 = 1,
2x2 + 3x4 = 15,
−x1 + 2x2 + x4 = −2
Find the inverse of each of the following matrices by Gaussian elimination. Check your
answers using MATLAB.
9.

−3
5
2
1

10.

3
−1
−5
2

11.


19
2
−9
−4
−1
2
−2
0
1


12.


1
2
5
0
−1
2
2
4
11


13. Does (A2)−1 = (A−1)2? Justify your answer.
Project: Construction of a Finite Fourier Series
In Example 5.1.1 we show that the function f(t) given by Equation 5.1.8 can be reex-
pressed
f(t) = a0
2 +
∞
X
n=1
an cos(nt) + bn sin(nt),
−π < t < π,
if
a0 = π
2 ,
an = (−1)n −1
n2π
,
and
bn = (−1)n+1
n
.
There we stated the Fourier series ﬁts f(t) in a “least squares sense.” In Section 5.7 we will
show that we could approximate f(t) with the ﬁnite Fourier series
f(t) = 1
2A0 +
M−1
X
k=1
Ak cos(kt) + Bk sin(kt) + 1
2AM cos(Mt),
if we sample f(t) at tm = (2m + 1 −M)π/M, where m = 0, 1, 2, . . . , M −1 and M is an
even integer. Then we can use Equation 5.7.12 and Equation 5.7.13 to compute Ak and Bk.
Because MATLAB solves linear equations in a least-squares sense, this suggests that we could
use MATLAB as an alternative method for ﬁnding a ﬁnite Fourier series approximation.
Let us assume that
f(t) = A0
2 +
N
X
n=1
An cos(nt) + Bn sin(nt).
Then sampling f(t) at the temporal points tm = −π+(2m−1)π/M, we obtain the following
system of linear equations:
A0
2 +
N
X
n=1
An cos(ntm) + Bn sin(ntm) = f(tm),
where m = 1, 2, . . . , M. Write a MATLAB program that solves this system for given N and
M and compare your results with the exact answers a0, an and bn for various N and M.

Linear Algebra
121
Consider the case when M > 2N + 1 (overspeciﬁed system), M < 2N + 1 (underspeciﬁed
system), and M = 2N + 1 (equal number of unknowns and equations). Does this method
yield any good results? If so, under which conditions?
Project: Solving Fredholm Integral Equation of the Second Kind
Fredholm equations of the second kind and their variants appear in many scientiﬁc and
engineering applications. In this project you will use matrix methods to solve this equation:
u(x) =
Z b
a
K(x, t)u(t) dt + f(x),
a < x < b,
where the kernel K(x, t) is a given real-valued and continuous function and u(x) is the
unknown. One method for solving this integral equation replaces the integral with some
grid-point representation. The goal of this project is examine how we can use linear algebra
to solve this numerical approximation to Fredholm’s integral equation.
Step 1: Using Simpson’s rule, show that our Fredholm equation can be written in the matrix
form (I −KD)u = f, where
D =






A0
0
· · ·
0
0
0
A1
· · ·
0
0
...
...
...
...
...
0
0
· · ·
An−1
0
0
0
· · ·
0
An






,
K =






K(x0, x0)
K(x0, x1)
· · ·
K(x0, xn−1)
K(x0, xn)
K(x1, x0)
K(x1, x1)
· · ·
K(x1, xn−1)
K(x1, xn)
...
...
...
...
...
K(xn−1, x0)
K(xn−1, x1)
· · ·
K(xn−1, xn−1)
K(xn−1, xn)
K(xn, x0)
K(xn, x1)
· · ·
K(xn, xn−1)
K(xn, xn)






,
u = [u(x0), u(x1), · · · , u(xn)]T ,
and
f = [f(x0), f(x1), · · · , f(xn)]T ,
where A0 = An = h/3, A2 = A4 = · · · = An−2 = 2h/3, A1 = A3 = · · · = An−1 = 4h/3,
xi = ih, and h = (b −a)/n. Here n must be an even integer.
Step 2: Use MATLAB to solve our matrix equation to ﬁnd u. Use the following known
solutions:
(a)
K(x, t) = 1
2x2t2,
f(x) = 0.9x2,
u(x) = x2,
(b)
K(x, t) = x2et(x−1),
f(x) = x + (1 −x)ex,
u(x) = ex,
(c)
K(x, t) = 1
3ex−t,
f(x) = 2
3ex,
u(x) = ex,
(d)
K(x, t) = −1
3e2x−5t/3,
f(x) = e2x + 1
3,
u(x) = e2x,
(e)
K(x, t) = −x (ext −1) ,
f(x) = ex −x,
u(x) = 1,
(f)
K(x, t) = 1
2xt,
f(x) = 5
6x,
u(x) = x,
when 0 ≤x ≤1. How does the accuracy of this method vary with n (or h)? What happens
when n becomes large? Figure 3.4.1 shows the absolute value of the relative error in the

122
Advanced Engineering Mathematics with MATLAB
n
0
5
10
15
20
25
30
35
40
|relative error|
10 -12
10 -11
10 -10
10 -9
10 -8
10 -7
10 -6
10 -5
10 -4
10 -3
10 -2
(a)
(b)
(d)
(e)
Figure 3.4.1: The absolute value of the relative error of the numerical solution of a Fredholm integral
equation of the second kind as a function of n for test problems (a), (b), (d), and (e).
numerical solution at x = 1
2 as a function of n. For test cases (c) and (f) the error was the
same order of magnitude as the round-oﬀerror.
Project: LU Decomposition
In this section we showed how Gaussian elimination can be used to ﬁnd solutions to sets
of linear equations. A popular alternative involves rewriting the n × n coeﬃcient matrix:
A =







a11
a12
a13
·
·
·
a1n
a21
a22
a23
·
·
·
a2n
·
·
·
·
·
·
·
·
·
·
·
aij
·
·
·
·
·
·
·
·
·
an1
an2
an3
·
·
·
ann







as the product of a lower n × n triangular matrix:
L =







ℓ11
0
0
·
·
·
0
ℓ21
ℓ22
0
·
·
·
0
·
·
·
·
·
·
·
·
·
·
·
ℓij
·
·
·
·
·
·
·
·
·
ℓn1
ℓn2
ℓn3
·
·
·
ℓnn







and an upper n × n triangular matrix:
U =







1
u12
u13
·
·
·
u1n
0
1
u23
·
·
·
u2n
·
·
·
·
·
·
·
·
·
·
·
1
·
·
·
·
·
·
·
·
·
0
0
0
·
·
·
1







,

Linear Algebra
123
so that A = LU. By simply doing the matrix multiplication, we ﬁnd the following Crout
algorithm to compute ℓij and uij:
ℓij = aij −
j−1
X
k=1
ℓikukj,
j ≤i,
i = 1, 2, . . . , n;
and
uij =
"
aij −
i−1
X
k=1
ℓikukj
#
ℓii,
i < j,
j = 2, 3, . . . , n.
For the special case of j = 1, ℓi1 = ai1; for i = 1, u1j = a1j/ℓ11 = ai1/a11. Clearly we could
write code to compute L and U given A. However, MATLAB has a subroutine for doing this
factorization [L,U] = lu(A).
How does this factorization help us to solve Ax = b? The goal of this project is to
answer this question.
Step 1: Show that Ly = b and Ux = y can be combined together to yield Ax = b.
Step 2: Show that yi and xi can be computed from y1 = b1/ℓ11,
yi =

bi −
i−1
X
j=1
ℓijbj



ℓii,
i = 2, 3, . . . , n;
and xn = yn/unn,
xi =

yi −
n
X
j=i+1
uijyj



uii,
i = n −1, n −2, . . . , 1.
Step 3: Write a MATLAB script to solve Ax = b using LU decomposition.
Step 4: Check your program by resolving Problems 4, 6, 7, and 8.
The principal reason that this scheme is so popular is its ecomony of storage. The 0’s
in either L or U are not stored. Furthermore, after the element aij is used, it never appears
again.
Project: QR Decomposition
In the previous project you discovered that by factoring the matrix A into upper and
lower diagonal matrices, we could solve Ax = b. Here we will again factor the matrix A
into the product QR but Q will have the property that QT Q = I (orthogonal matrix) and
R is an upper triangular matrix.
Step 1: Assuming that we can rewrite Ax = b as QRx = b, multiply both sides of this
second equation by QT and show that you obtain Rx = QT b = y.

124
Advanced Engineering Mathematics with MATLAB
Step 2: Show that xi can be computed from xn = yn/rnn and
xi =

yi −
n
X
j=i+1
rijyj



rii,
i = n −1, n −2, . . . , 1.
Step 3: Write a MATLAB script to solve Ax = b using QR decomposition.
Step 4: Check your program by resolving Problems 4, 6, 7, and 8.
What advantages does QR decomposition have over LU decomposition? First, solving
Ax = b via Rx = QT b is as well-conditioned as the original problem. Second, QR decom-
position ﬁnds the least-squares solutions when no exact solution exists. When there are
exact solutions, it ﬁnds all of them.
3.5 EIGENVALUES AND EIGENVECTORS
One of the classic problems of linear algebra6 is ﬁnding all of the λ’s that satisfy the
n × n system
Ax = λx.
(3.5.1)
The nonzero quantity λ is the eigenvalue or characteristic value of A. The vector x is the
eigenvector or characteristic vector belonging to λ. The set of the eigenvalues of A is called
the spectrum of A. The largest of the absolute values of the eigenvalues of A is called the
spectral radius of A.
To ﬁnd λ and x, we ﬁrst rewrite Equation 3.5.1 as a set of homogeneous equations:
(A −λI)x = 0.
(3.5.2)
From the theory of linear equations, Equation 3.5.2 has trivial solutions unless its determi-
nant equals zero. On the other hand, if
det(A −λI) = 0,
(3.5.3)
there are an inﬁnity of solutions.
The expansion of the determinant, Equation 3.5.3, yields an nth-degree polynomial in λ,
the characteristic polynomial. The roots of the characteristic polynomial are the eigenvalues
of A. Because the characteristic polynomial has exactly n roots, A has n eigenvalues, some
of which can be repeated (with multiplicity k ≤n) and some of which can be complex
numbers. For each eigenvalue λi, there is a corresponding eigenvector xi. This eigenvector
is the solution of the homogeneous equations (A −λiI)xi = 0.
An important property of eigenvectors is their linear independence if there are n distinct
eigenvalues. Vectors are linearly independent if the equation
α1x1 + α2x2 + · · · + αnxn = 0
(3.5.4)
can be satisﬁed only by taking all of the coeﬃcients αn equal to zero.
6 The standard reference is Wilkinson, J. H., 1965: The Algebraic Eigenvalue Problem. Oxford Univer-
sity Press, 662 pp.

Linear Algebra
125
This concept of linear independence or dependence actually extends to vectors in gen-
eral, not just eigenvectors. Algebraists would say that our n linearly independent vectors
form a basis that spans a vector space V . A vector space is simply a set V of vectors that
can be added and scaled. The maximum number of linearly independent vectors in a vector
space gives its dimension of V . A vector space V can have many diﬀerent bases, but there
are always the same number of basis vectors in each of them.
Returning to the eigenvalue problem, we now show that in the case of n distinct eigen-
values λ1, λ2, . . . , λn, each eigenvalue λi having a corresponding eigenvector xi, the eigen-
vectors form a basis. We ﬁrst write down the linear dependence condition
α1x1 + α2x2 + · · · + αnxn = 0.
(3.5.5)
Premultiplying Equation 3.5.5 by A,
α1Ax1 + α2Ax2 + · · · + αnAxn = α1λ1x1 + α2λ2x2 + · · · + αnλnxn = 0.
(3.5.6)
Premultiplying Equation 3.5.5 by A2,
α1A2x1 + α2A2x2 + · · · + αnA2xn = α1λ2
1x1 + α2λ2
2x2 + · · · + αnλ2
nxn = 0.
(3.5.7)
In a similar manner, we obtain the system of equations:






1
1
· · ·
1
λ1
λ2
· · ·
λn
λ2
1
λ2
2
· · ·
λ2
n
...
...
...
...
λn−1
1
λn−1
2
· · ·
λn−1
n












α1x1
α2x2
α3x3
...
αnxn






=






0
0
0
...
0






.
(3.5.8)
Because

1
1
· · ·
1
λ1
λ2
· · ·
λn
λ2
1
λ2
2
· · ·
λ2
n
...
...
...
...
λn−1
1
λn−1
2
· · ·
λn−1
n

= (λ2 −λ1)(λ3 −λ2)(λ3 −λ1)(λ4 −λ3)
(λ4 −λ2) · · · (λn −λ1) ̸= 0,
(3.5.9)
since it is a Vandermonde determinant, α1x1 = α2x2 = α3x3 = · · · = αnxn = 0. Because
the eigenvectors are nonzero, α1 = α2 = α3 = · · · = αn = 0, and the eigenvectors are
linearly independent.
⊓⊔
This property of eigenvectors allows us to express any arbitrary vector x as a linear
sum of the eigenvectors xi, or
x = c1x1 + c2x2 + · · · + cnxn.
(3.5.10)
We will make good use of this property in Example 3.5.3.
• Example 3.5.1
Let us ﬁnd the eigenvalues and corresponding eigenvectors of the matrix
A =

−4
2
−1
−1

.
(3.5.11)

126
Advanced Engineering Mathematics with MATLAB
We begin by setting up the characteristic equation:
det(A −λI) =

−4 −λ
2
−1
−1 −λ
 = 0.
(3.5.12)
Expanding the determinant,
(−4 −λ)(−1 −λ) + 2 = λ2 + 5λ + 6 = (λ + 3)(λ + 2) = 0.
(3.5.13)
Thus, the eigenvalues of the matrix A are λ1 = −3, and λ2 = −2.
To ﬁnd the corresponding eigenvectors, we must solve the linear system:

−4 −λ
2
−1
−1 −λ
 
x1
x2

=

0
0

.
(3.5.14)
For example, for λ1 = −3,

−1
2
−1
2
 
x1
x2

=

0
0

,
(3.5.15)
or
x1 = 2x2.
(3.5.16)
Thus, any nonzero multiple of the vector

2
1

is an eigenvector belonging to λ1 = −3.
Similarly, for λ2 = −2, the eigenvector is any nonzero multiple of the vector

1
1

.
Of course, MATLAB will do all of the computations for you via the command eig, which
computes the eigenvalues and corresponding eigenvalues. In the present case, you would
type
>> A = [-4 2; -1 -1]; % load in array A
>> % find eigenvalues and eigenvectors
>> [eigenvector,eigenvalue] = eig(A)
This yields
eigenvector =
-0.8944
-0.7071
-0.4472
-0.7071
and
eigenvalue =
-3
0
0
-2.
The eigenvalues are given as the elements along the principal diagonal of eigenvalue.
The corresponding vectors are given by the corresponding column of eigenvector.
As
this example shows, these eigenvectors have been normalized so that their norm, Equation
3.1.5, equals one. Also, their sign may be diﬀerent than any you would choose. We can
recover our hand-computed results by dividing the ﬁrst eigenvector by −0.4472 while in
the second case we would divide by −0.7071. Finally, note that the product eigenvec-
tor*eigenvalue*inv(eigenvector) would yield A.
⊓⊔

Linear Algebra
127
• Example 3.5.2
Let us now ﬁnd the eigenvalues and corresponding eigenvectors of the matrix
A =


−4
5
5
−5
6
5
−5
5
6

.
(3.5.17)
Setting up the characteristic equation:
det(A −λI)
=

−4 −λ
5
5
−5
6 −λ
5
−5
5
6 −λ

=

−4 −λ
5
5
−5
6 −λ
5
0
λ −1
1 −λ

(3.5.18)
= (λ −1)

−4 −λ
5
5
−5
6 −λ
5
0
1
−1

= (λ −1)2

−1
1
0
−5
6 −λ
5
0
1
−1

(3.5.19)
det(A −λI) = (λ −1)2

−1
0
0
−5
6 −λ
0
0
1
−1

= (λ −1)2(6 −λ) = 0.
(3.5.20)
Thus, the eigenvalues of the matrix A are λ1,2 = 1 (twice), and λ3 = 6.
To ﬁnd the corresponding eigenvectors, we must solve the linear system:
(−4 −λ)x1 + 5x2 + 5x3 = 0,
(3.5.21)
−5x1 + (6 −λ)x2 + 5x3 = 0,
(3.5.22)
and
−5x1 + 5x2 + (6 −λ)x3 = 0.
(3.5.23)
For λ3 = 6, Equations 3.5.21 through 3.5.23 become
−10x1 + 5x2 + 5x3 = 0,
(3.5.24)
−5x1 + 5x3 = 0,
(3.5.25)
and
−5x1 + 5x2 = 0.
(3.5.26)
Thus, x1 = x2 = x3 and the eigenvector is any nonzero multiple of the vector


1
1
1

.
The interesting aspect of this example centers on ﬁnding the eigenvector for the eigen-
value λ1,2 = 1. If λ1,2 = 1, then Equations 3.5.21 through 3.5.23 collapse into one equation,
−x1 + x2 + x3 = 0,
(3.5.27)
and we have two free parameters at our disposal. Let us take x2 = α, and x3 = β. Then
the eigenvector equals α


1
1
0

+ β


1
0
1

for λ1,2 = 1.

128
Advanced Engineering Mathematics with MATLAB
In this example, we may associate the eigenvector


1
1
0

with λ1 = 1, and


1
0
1

with
λ2 = 1 so that, along with the eigenvector


1
1
1

with λ3 = 6, we still have n linearly
independent eigenvectors for our 3 × 3 matrix. However, with repeated eigenvalues this is
not always true. For example,
A =

1
−1
0
1

(3.5.28)
has the repeated eigenvalues λ1,2 = 1. However, there is only a single eigenvector

1
0

for
both λ1 and λ2.
What happens in MATLAB in the present case? Typing in
>> A = [-4 5 5; -5 6 5; -5 5 6]; % load in array A
>> % find eigenvalues and eigenvectors
>> [eigenvector,eigenvalue] = eig(A)
we obtain
eigenvector =
-0.8165
0.5774
0.4259
-0.4082
0.5774
-0.3904
-0.4082
0.5774
0.8162
and
eigenvalue =
1
0
0
0
6
0
0
0
1
The second eigenvector is clearly the same as the hand-computed one if you normalize it with
0.5774. The equivalence of the ﬁrst and third eigenvectors is not as clear. However, if you
choose α = β = −0.4082, then the ﬁrst eigenvector agrees with the hand-computed value.
Similarly, taking α = −0.3904 and β = 0.8162 result in agreement with the third MATLAB
eigenvector. Finally, note that the product eigenvector*eigenvalue*inv(eigenvector)
would yield A.
⊓⊔
• Example 3.5.3
When we discussed the stability of numerical schemes for the wave equation in Section
7.6, we will examine the behavior of a prototypical Fourier harmonic to variations in the
parameter c∆t/∆x. In this example we shall show another approach to determining the
stability of a numerical scheme via matrices.
Consider the explicit scheme for the numerical integration of the wave equation, Equa-
tion 7.6.11. We can rewrite that single equation as the coupled diﬀerence equations:
un+1
m
= 2(1 −r2)un
m + r2(un
m+1 + un
m−1) −vn
m,
(3.5.29)
and
vn+1
m
= un
m,
(3.5.30)

Linear Algebra
129
where r = c∆t/∆x. Let un
m+1 = eiβ∆xun
m, and un
m−1 = e−iβ∆xun
m, where β is real. Then
Equation 3.5.29 and Equation 3.5.30 become
un+1
m
= 2

1 −2r2 sin2
β∆x
2

un
m −vn
m,
(3.5.31)
and
vn+1
m
= un
m,
(3.5.32)
or in the matrix form
un+1
m
=
 
2
h
1 −2r2 sin2
β∆x
2
i
−1
1
0
!
un
m,
(3.5.33)
where un
m =

un
m
vn
m

. The eigenvalues λ of this ampliﬁcation matrix are given by
λ2 −2

1 −2r2 sin2
β∆x
2

λ + 1 = 0,
(3.5.34)
or
λ1,2 = 1 −2r2 sin2
β∆x
2

± 2r sin
β∆x
2
 s
r2 sin2
β∆x
2

−1.
(3.5.35)
Because each successive time step consists of multiplying the solution from the previous
time step by the ampliﬁcation matrix, the solution is stable only if un
m remains bounded.
This occurs only if all of the eigenvalues have a magnitude less or equal to one, because
un
m =
X
k
ckAnxk =
X
k
ckλn
kxk,
(3.5.36)
where A denotes the ampliﬁcation matrix and xk denotes the eigenvectors corresponding to
the eigenvalues λk. Equation 3.5.36 follows from our ability to express any initial condition
in terms of an eigenvector expansion
u0
m =
X
k
ckxk.
(3.5.37)
In our particular example, two cases arise. If r2 sin2(β∆x/2) ≤1,
λ1,2 = 1 −2r2 sin2
β∆x
2

± 2ri sin
β∆x
2
 s
1 −r2 sin2
β∆x
2

(3.5.38)
and |λ1,2| = 1. On the other hand, if r2 sin2(β∆x/2) > 1, |λ1,2| > 1. Thus, we have stability
only if c∆t/∆x ≤1.

130
Advanced Engineering Mathematics with MATLAB
y
∆
y
y
y
y
y
y
N+1
y
0
1
2
3
N
N-1
N-2
x
Figure 3.5.1: Schematic for ﬁnite-diﬀerencing a Sturm-Liouville problem into a set of diﬀerence equations.
Problems
Find the eigenvalues and corresponding eigenvectors for the following matrices. Check your
answers using MATLAB.
1. A =

3
2
3
−2

2. A =

3
−1
1
1

3. A =


2
−3
1
1
−2
1
1
−3
2


4. A =


0
1
0
0
0
1
0
0
0


5. A =


1
1
1
0
2
1
0
0
1


6. A =


1
2
1
0
3
1
0
5
−1


7. A =


4
−5
1
1
0
−1
0
1
−1


8. A =


−2
0
1
3
0
−1
0
1
1


Project: Numerical Solution of the Sturm-Liouville Problem
You may have been struck by the similarity of the algebraic eigenvalue problem to the
Sturm-Liouville problem. (See Section 6.1.) In both cases nontrivial solutions exist only
for characteristic values of λ. The purpose of this project is to further deepen your insight
into these similarities.
Consider the Sturm-Liouville problem
y′′ + λy = 0,
y(0) = y(π) = 0.
(3.5.39)
We know that it has the nontrivial solutions λm = m2, ym(x) = sin(mx), where m =
1, 2, 3, . . ..
Step 1: Let us solve this problem numerically. Introducing centered ﬁnite diﬀerencing and
the grid shown in Figure 3.5.1, show that
y′′ ≈yn+1 −2yn + yn−1
(∆x)2
,
n = 1, 2, . . . , N,
(3.5.40)

Linear Algebra
131
Table 3.5.1: Eigenvalues Computed from Equation 3.5.42 as a Numerical Approximation
of the Sturm-Liouville Problem, Equation 3.5.39
N
λ1
λ2
λ3
λ4
λ5
λ6
λ7
1
0.81057
2
0.91189
2.73567
3
0.94964
3.24228
5.53491
4
0.96753
3.50056
6.63156
9.16459
5
0.97736
3.64756
7.29513
10.94269
13.61289
6
0.98333
3.73855
7.71996
12.13899
16.12040
18.87563
7
0.98721
3.79857
8.00605
12.96911
17.93217
22.13966
24.95100
8
0.98989
3.84016
8.20702
13.56377
19.26430
24.62105
28.98791
20
0.99813
3.97023
8.84993
15.52822
23.85591
33.64694
44.68265
50
0.99972
3.99498
8.97438
15.91922
24.80297
35.59203
48.24538
where ∆x = π/(N + 1). Show that the ﬁnite-diﬀerenced form of Equation 3.5.39 is
−h2yn+1 + 2h2yn −h2yn−1 = λyn
(3.5.41)
with y0 = yN+1 = 0, and h = 1/(∆x).
Step 2: Solve Equation 3.5.41 as an algebraic eigenvalue problem using N = 1, 2, . . .. Show
that Equation 3.5.41 can be written in the matrix form of








2h2
−h2
0
· · ·
0
0
0
−h2
2h2
−h2
· · ·
0
0
0
0
−h2
2h2
· · ·
0
0
0
...
...
...
...
...
...
...
0
0
0
· · ·
−h2
2h2
−h2
0
0
0
· · ·
0
−h2
2h2
















y1
y2
y3
...
yN−1
yN








= λ








y1
y2
y3
...
yN−1
yN








.
(3.5.42)
Note that the coeﬃcient matrix is symmetric.
Step 3: You are now ready to compute the eigenvalues. For small N this could be done by
hand. However, it is easier just to write a MATLAB program that will handle any N ≥2.
Table 3.5.1 has been provided so that you can check your program.
With your program, answer the following questions: How do your computed eigenvalues
compare to the eigenvalues given by the Sturm-Liouville problem? What happens as you
increase N? Which computed eigenvalues agree best with those given by the Sturm-Liouville
problem? Which ones compare the worst?
Step 4: Let us examine the eigenfunctions now. Starting with the smallest eigenvalue, use
MATLAB to plot Cyj as a function of xi where yj is the jth eigenvector, j = 1, 2, . . . , N,
xi = i∆x, i = 1, 2, . . . , N, and C is chosen so that C2∆x P
i y2
j (xi) = 1. On the same
plot, graph yj(x) =
p
2/π sin(jx). Why did we choose C as we did? Which eigenvectors
and eigenfunctions agree the best? Which eigenvectors and eigenfunctions agree the worst?
Why? Why are there N eigenvectors and an inﬁnite number of eigenfunctions?

132
Advanced Engineering Mathematics with MATLAB
Step 5: The most important property of eigenfunctions is orthogonality. But what do we
mean by orthogonality in the case of eigenvectors? Recall from three-dimensional vectors
we had the scalar dot product
a · b = a1b1 + a2b2 + a3b3.
(3.5.43)
For n-dimensional vectors, this dot product is generalized to the inner product
x · y =
n
X
k=1
xkyk.
(3.5.44)
Orthogonality implies that x · y = 0 if x ̸= y. Are your eigenvectors orthogonal? How
might you use this property with eigenvectors?
Project: Singular Value Decomposition and Linear Least Squares
In the previous section we showed two ways that linear equations can be solved by
factoring the matrix A in Ax = b into a product of two matrices.
The LU and QR
decompositions are not the only possible factorization. One popular version rewrites the
square matrix A as PDP −1, where D is a diagonal matrix with the n eigenvalues along the
principal diagonal and P contains the eigenvectors in the transition matrix P. MATLAB’s
routine eig yields both D and P via [P,D] = eig(A). See Example 3.6.4. In this project we
focus on singular value decomposition, possibly the most important matrix decomposition
of them all. It is used in signal processing, statistics, and numerical methods and theory.
Singular value decomposition factorizes a matrix A of dimension m×n into the product
of three matrices: A = UDV T , where U is an m × m orthogonal matrix, V is an n × n
orthogonal matrix, and D is an m×n diagonal matrix. The diagonal entries of D are called
the singular values of A. The rank of a matrix equals the number of non-zero singular
values.
Step 1: Consider the matrix A given by
A =





45
−108
36
−45
21
−68
26
−33
72
−32
−16
24
−56
64
−8
8
50
−32
−6
10




.
Using MATLAB’s subroutine svd, conﬁrm that it can factorize the array A into U, D, and
V . Then check that A = UDV T and ﬁnd the rank of this matrix.
The goal of this project is to ﬁnd the parameters m and c so that the line y = mx + c
gives the best ﬁt to n data points. If there are only two data points, there is no problem
because we could immediately ﬁnd the slope m and the intercept c. However, if n > 2
we cannot hope to choose these coeﬃcients so that the straight line ﬁts them. How does
singular value decomposition come to the rescue?
To ﬁnd the answer, we begin by noting that each data point (xi, yi) must satisfy the
linear equation mxi + c = yi, or
m




x1
x2
...
xn



+ c




1
1
...
1



=




x1
1
x2
1
...
...
xn
1





m
c

= Ax =




y1
y2
...
yn



= y.

Linear Algebra
133
x
10
20
30
40
50
60
70
80
90
100
y
0
50
100
150
200
250
300
350
Figure 3.5.2: Using 50 “data points,” the singular value decomposition provides a least-squares ﬁt to the
data.
We can write this over-determined system of linear equations Ax = b. Let the residual r be
a vector deﬁned by r = Ax −b. The vector x∗that yields the smallest possible residual in
the least-squares sense is ||r|| = ||Ax∗−b|| ≤||Ax −b||, where || · || denotes the Euclidean
norm. Although a least-squares solution always exists, it might not be unique. However,
the least-squares solution x with the smallest norm ||x|| is unique and equals AT Ax = AT b
or x = (AT A)−1AT b. This solution can be found using singular value decomposition as
x = V D−1
0 U T b, where the n × m matrix D−1
0
has the diagonal terms:
 D−1
0

ii =

1/Σi,
if Σi > ǫ,
0,
otherwise,
even when A is singular or ill-conditioned.
Step 2: In Step 1, we found that the rank for the matrix A is 2. What values of x does
singular value decomposition give if b = ( −2 4 4 6 −4 )T ? This solution equals the least-
squares solution of minimum length.
Step 3: Returning to our original goal of ﬁnding the best linear ﬁt to data, create data for
your numerical experiment. One way would use the simple line y = mx + c (with arbitrary
chosen values of m and c) to create the initial data and then use the random number
generator rand to modify this initial data (both x and y) so that both have “noise.”
Step 4: Construct the array A and column vector y. Using the MATLAB routine svd, ﬁnd
x = V D−1
0 U T b.
Step 5: Construct the least-squares ﬁt for the data and plot this curve and your data on
the same ﬁgure. See Figure 3.5.2.
3.6 SYSTEMS OF LINEAR DIFFERENTIAL EQUATIONS
In this section we show how we may apply the classic algebraic eigenvalue problem to
solve a system of ordinary diﬀerential equations.
Let us solve the following system:
x′
1 = x1 + 3x2,
(3.6.1)

134
Advanced Engineering Mathematics with MATLAB
and
x′
2 = 3x1 + x2,
(3.6.2)
where the primes denote the time derivative.
We begin by rewriting Equation 3.6.1 and Equation 3.6.2 in matrix notation:
x′ = Ax,
(3.6.3)
where
x =

x1
x2

,
and
A =

1
3
3
1

.
(3.6.4)
Note that

x′
1
x′
2

= d
dt

x1
x2

= x′.
(3.6.5)
Assuming a solution of the form
x = x0eλt,
where
x0 =

a
b

(3.6.6)
is a constant vector, we substitute Equation 3.6.6 into Equation 3.6.3 and ﬁnd that
λeλtx0 = Aeλtx0.
(3.6.7)
Because eλt does not generally equal zero, we have that
(A −λI)x0 = 0,
(3.6.8)
which we solved in the previous section. This set of homogeneous equations is the classic
eigenvalue problem. In order for this set not to have trivial solutions,
det(A −λI) =

1 −λ
3
3
1 −λ
 = 0.
(3.6.9)
Expanding the determinant,
(1 −λ)2 −9 = 0
or
λ = −2, 4.
(3.6.10)
Thus, we have two real and distinct eigenvalues: λ = −2 and 4.
We must now ﬁnd the corresponding x0 or eigenvector for each eigenvalue.
From
Equation 3.6.8,
(1 −λ)a + 3b = 0,
(3.6.11)
and
3a + (1 −λ)b = 0.
(3.6.12)
If λ = 4, these equations are consistent and yield a = b = c1. If λ = −2, we have that
a = −b = c2. Therefore, the general solution in matrix notation is
x = c1

1
1

e4t + c2

1
−1

e−2t.
(3.6.13)

Linear Algebra
135
To evaluate c1 and c2, we must have initial conditions. For example, if x1(0) = x2(0) =
1, then

1
1

= c1

1
1

+ c2

1
−1

.
(3.6.14)
Solving for c1 and c2, c1 = 1, c2 = 0, and the solution with this particular set of initial
conditions is
x =

1
1

e4t.
(3.6.15)
• Example 3.6.1
Let us solve the following set of linear ordinary diﬀerential equations
x′
1 = −x2 + x3,
(3.6.16)
x′
2 = 4x1 −x2 −4x3,
(3.6.17)
and
x′
3 = −3x1 −x2 + 4x3;
(3.6.18)
or in matrix form,
x′ =


0
−1
1
4
−1
−4
−3
−1
4

x,
x =


x1
x2
x3

.
(3.6.19)
Assuming the solution x = x0eλt,


0
−1
1
4
−1
−4
−3
−1
4

x0 = λx0,
(3.6.20)
or


−λ
−1
1
4
−1 −λ
−4
−3
−1
4 −λ

x0 = 0.
(3.6.21)
For nontrivial solutions,

−λ
−1
1
4
−1 −λ
−4
−3
−1
4 −λ

=

0
0
1
4 −4λ
−5 −λ
−4
−3 + 4λ −λ2
3 −λ
4 −λ

= 0,
(3.6.22)
and
(λ −1)(λ −3)(λ + 1) = 0,
or
λ = −1, 1, 3.
(3.6.23)
To determine the eigenvectors, we rewrite Equation 3.6.21 as
−λa −b + c = 0,
(3.6.24)
4a −(1 + λ)b −4c = 0,
(3.6.25)
and
−3a −b + (4 −λ)c = 0.
(3.6.26)

136
Advanced Engineering Mathematics with MATLAB
For example, if λ = 1,
−a −b + c = 0,
(3.6.27)
4a −2b −4c = 0,
(3.6.28)
and
−3a −b + 3c = 0;
(3.6.29)
or a = c, and b = 0. Thus, the eigenvector for λ = 1 is x0 =


1
0
1

. Similarly, for λ = −1,
x0 =


1
2
1

; and for λ = 3, x0 =


1
−1
2

. Thus, the most general solution is
x = c1


1
0
1

et + c2


1
2
1

e−t + c3


1
−1
2

e3t.
(3.6.30)
⊓⊔
• Example 3.6.2
Let us solve the following set of linear ordinary diﬀerential equations:
x′
1 = x1 −2x2,
(3.6.31)
and
x′
2 = 2x1 −3x2;
(3.6.32)
or in matrix form,
x′ =

1
−2
2
−3

x,
x =

x1
x2

.
(3.6.33)
Assuming the solution x = x0eλt,

1 −λ
−2
2
−3 −λ

x0 = 0.
(3.6.34)
For nontrivial solutions,

1 −λ
−2
2
−3 −λ
 = (λ + 1)2 = 0.
(3.6.35)
Thus, we have the solution
x = c1

1
1

e−t.
(3.6.36)
The interesting aspect of this example is the single solution that the traditional ap-
proach yields because we have repeated roots.
To ﬁnd the second solution, we try the
solution
x =

a + ct
b + dt

e−t.
(3.6.37)

Linear Algebra
137
We guessed Equation 3.6.37 using our knowledge of solutions to diﬀerential equations when
the characteristic polynomial has repeated roots. Substituting Equation 3.6.37 into Equa-
tion 3.6.33, we ﬁnd that c = d = 2c2, and a −b = c2. Thus, we have one free parameter,
which we choose to be b, and set it equal to zero. This is permissible because Equation
3.6.37 can be broken into two terms: b

1
1

e−t and c2

1 + 2t
2t

e−t. The ﬁrst term can
be incorporated into the c1

1
1

e−t term. Thus, the general solution is
x = c1

1
1

e−t + c2

1
0

e−t + 2c2

1
1

te−t.
(3.6.38)
⊓⊔
• Example 3.6.3
Let us solve the system of linear diﬀerential equations:
x′
1 = 2x1 −3x2,
(3.6.39)
and
x′
2 = 3x1 + 2x2;
(3.6.40)
or in matrix form,
x′ =

2
−3
3
2

x,
x =

x1
x2

.
(3.6.41)
Assuming the solution x = x0eλt,

2 −λ
−3
3
2 −λ

x0 = 0.
(3.6.42)
For nontrivial solutions,

2 −λ
−3
3
2 −λ
 = (2 −λ)2 + 9 = 0,
(3.6.43)
and λ = 2 ± 3i. If x0 =

a
b

, then b = −ai if λ = 2 + 3i, and b = ai if λ = 2 −3i. Thus,
the general solution is
x = c1

1
−i

e2t+3it + c2

1
i

e2t−3it,
(3.6.44)
where c1 and c2 are arbitrary complex constants. Using Euler relationships, we can rewrite
Equation 3.6.44 as
x = c3

cos(3t)
sin(3t)

e2t + c4

sin(3t)
−cos(3t)

e2t,
(3.6.45)
where c3 = c1 + c2 and c4 = i(c1 −c2).
⊓⊔

138
Advanced Engineering Mathematics with MATLAB
• Example 3.6.4: Diagonalization of a matrix A
Let x1, x2, · · · , xn denote the eigenvectors, with corresponding eigenvalues λ1, λ2, · · · ,
λn, of an n×n matrix A. If we introduce a matrix X = [x1x2 · · · xn] (the eigenvectors form
the columns of X) and recall that Axj = λjxj, then
AX = A[x1x2 · · · xn] = [Ax1Ax2 · · · Axn] = [λ1x1λ2x2 · · · λnxn].
(3.6.46)
Therefore, AX = XD, where
D =




λ1
0
· · ·
0
0
λ2
· · ·
0
...
...
...
...
0
0
· · ·
λn



.
(3.6.47)
Because X has rank n, X−1 exists and X−1AX = X−1XD = D. Thus, X−1AX = D is a
process whereby we can diagonalize the matrix A using the eigenvectors of A. Diagonalizable
matrices are of interest because diagonal matrices are especially easy to use. Furthermore,
we note that
D2 = DD = X−1AXX−1AX = X−1AAX = X−1A2X.
(3.6.48)
Repeating this process, we eventually obtain the general result that Dm = X−1AmX.
To verify X−1AX = D, let us use
A =

3
4
1
3

.
(3.6.49)
This matrix has the eigenvalues λ1,2 = 1, 5 with the corresponding eigenvectors x1 =
( 2
1 )T and x2 = ( 2
−1 )T . Therefore,
X =

2
2
−1
1

,
and
X−1 =

1/4
−1/2
1/4
1/2

.
(3.6.50)
Therefore,
X−1AX =

1/4
−1/2
1/4
1/2
 
3
4
1
3
 
2
2
−1
1

(3.6.51)
=

1/4
−1/2
1/4
1/2
 
2
10
−1
5

=

1
0
0
5

.
(3.6.52)
Problems
Find the general solution of the following sets of ordinary diﬀerential equations using matrix
technique. You may ﬁnd the eigenvalues and eigenvectors either by hand or use MATLAB.
1. x′
1 = x1 + 2x2
x′
2 = 2x1 + x2
2. x′
1 = x1 −4x2
x′
2 = 3x1 −6x2
3. x′
1 = x1 + x2
x′
2 = 4x1 + x2

Linear Algebra
139
4. x′
1 = x1 + 5x2
x′
2 = −2x1 −6x2
5. x′
1 = −3
2x1 −2x2
x′
2 = 2x1 + 5
2x2.
6. x′
1 = −3x1 −2x2
x′
2 = 2x1 + x2
7. x′
1 = x1 −x2
x′
2 = x1 + 3x2
8. x′
1 = 3x1 + 2x2
x′
2 = −2x1 −x2
9. x′
1 = −2x1 −13x2
x′
2 = x1 + 4x2
10. x′
1 = 3x1 −2x2
x′
2 = 5x1 −3x2
11. x′
1 = 4x1 −2x2
x′
2 = 25x1 −10x2
12. x′
1 = −3x1 −4x2
x′
2 = 2x1 + x2
13. x′
1 = 3x1 + 4x2
x′
2 = −2x1 −x2
14. x′
1 + 5x1 + x′
2 + 3x2 = 0
2x′
1 + x1 + x′
2 + x2 = 0
15. x′
1 −x1 + x′
2 −2x2 = 0
x′
1 −5x1 + 2x′
2 −7x2 = 0
16. x′
1 = x1 −2x2
x′
2 = 0
x′
3 = −5x1 + 7x3.
17. x′
1 = 2x1
x′
2 = x1 + 2x3
x′
3 = x3.
18. x′
1 = 3x1 −2x3
x′
2 = −x1 + 2x2 + x3
x′
3 = 4x1 −3x3
19. x′
1 = 3x1 −x3
x′
2 = −2x1 + 2x2 + x3
x′
3 = 8x1 −3x3
3.7 MATRIX EXPONENTIAL
In the previous section we solved initial-value problems involving systems of linear
ordinary diﬀerential equations via the eigenvalue problem. Here we introduce an alternative
method based on the matrix exponential, deﬁned by
eAt = I + At + 1
2!A2t2 + · · · + 1
k!Aktk + · · · .
(3.7.1)
Clearly
e0 = eA0 = I,
and
d
dt
 eAt
= AeAt.
(3.7.2)
Therefore, using the matrix exponential function, the solution to the system of homogeneous
linear ﬁrst-order diﬀerential equations with constant coeﬃcients
x′ = Ax,
x(0) = x0,
(3.7.3)
is x(t) = eAtx0.

140
Advanced Engineering Mathematics with MATLAB
The question now arises as to how to compute this matrix exponential. There are
several methods. For example, from the concept of diagonalization of a matrix (see Example
3.6.4) we can write A = PDP −1, where P are the eigenvectors of A. Then,
eA =
∞
X
k=0
(PDP −1)k
k!
=
∞
X
k=0
P Dk
k! P −1 = P
 ∞
X
k=0
Dk
k!
!
P −1 = PeDP −1,
(3.7.4)
where
eD =




eλ1
0
· · ·
0
0
eλ2
· · ·
0
...
...
...
...
0
0
· · ·
eλn



.
(3.7.5)
Because many software packages contain routines for ﬁnding eigenvalues and eigenvectors,
Equation 3.7.4 provides a convenient method for computing eA. In the case of MATLAB,
we just have to invoke the intrinsic function expm(·).
In this section we focus on a recently developed method by Liz,7 who improved a
method constructed by Leonard.8 The advantage of this method is that it uses techniques
that we have already introduced. We will ﬁrst state the result and then illustrate its use.
The main result of Liz’s analysis is:
Theorem: Let A be a constant n × n matrix with characteristic polynomial p(λ) = λn +
cn−1λn−1 + · · · + c1λ + c0. Then
eAt = x1(t)I + x2(t)A + · · · + xn(t)An−1,
(3.7.6)
where




x1(t)
x2(t)
...
xn(t)



= B−1
0




ϕ1(t)
ϕ2(t)
...
ϕn(t)



,
(3.7.7)
Bt =





ϕ1(t)
ϕ′
1(t)
· · ·
ϕ(n−1)
1
(t)
ϕ2(t)
ϕ′
2(t)
· · ·
ϕ(n−1)
2
(t)
...
...
· · ·
...
ϕn(t)
ϕ′
n(t)
· · ·
ϕ(n−1)
n
(t)




,
(3.7.8)
and S = {ϕ1(t), ϕ2(t), . . . , ϕn(t)} being a fundamental system of solutions for the homoge-
neous linear diﬀerential equations whose characteristic equation is the characteristic equa-
tion of A, p(λ) = 0. The proof is given in Liz’s paper. Note that for this technique to work,
x1(0) = 1 and x2(0) = x3(0) = · · · = xn(0) = 0.
• Example 3.7.1
Let us illustrate this method of computing the matrix exponential by solving
x′ = 2x −y + z,
(3.7.9)
7 Liz, E., 1998: A note on the matrix exponential. SIAM Rev., 40, 700–702.
8 Leonard, I. E., 1996: The matrix exponential. SIAM Rev., 38, 507–512.

Linear Algebra
141
y′ = 3y −z,
(3.7.10)
and
z′ = 2x + y + 3z.
(3.7.11)
The solution to this system of equations is x = eAtx0, where
A =


2
−1
1
0
3
−1
2
1
3


and
x =


x(t)
y(t)
z(t)

.
(3.7.12)
The vector x0 is the value of x(t) at t = 0.
Our ﬁrst task is to compute the characteristic polynomial p(λ) = 0. This is simply
|λI −A| =

λ −2
1
−1
0
λ −3
1
−2
−1
λ −3

= (λ −2)2(λ −4) = 0.
(3.7.13)
Consequently, λ = 2 twice and λ = 4, and the fundamental solutions are S = {e2t, te2t, e4t}.
Therefore,
Bt =


e4t
4e4t
16e4t
e2t
2e2t
4e2t
te2t
e2t + 2te2t
4e2t + 4te2t

,
(3.7.14)
and
A2 =


6
−4
6
−2
8
−6
10
4
10

, B0 =


1
4
16
1
2
4
0
1
4

, B−1
0
=


−1
0
−4
−1
1
3
1
4
−1
4
−1
2

.
(3.7.15)
The inverse B−1
0
can be found using either Gaussian elimination or MATLAB.
To ﬁnd x1(t), x2(t) and x3(t), we have from Equation 3.7.7 that


x1(t)
x2(t)
x3(t)

=


−1
0
−4
−1
1
3
1
4
−1
4
−1
2




e4t
e2t
te2t

=


e4t −4te2t
e2t −e4t + 3te2t
1
4e4t −1
4e2t −1
2te2t

,
(3.7.16)
or
x1(t) = e4t −4te2t, x2(t) = e2t −e4t + 3te2t, x3(t) = 1
4e4t −1
4e2t −1
2te2t.
(3.7.17)
Note that x1(0) = 1 while x2(0) = x3(0) = 0.
Finally, we have that
eAt = x1(t)


1
0
0
0
1
0
0
0
1

+ x2(t)


2
−1
1
0
3
−1
2
1
3

+ x3(t)


6
−4
6
−2
8
−6
10
4
10

.
(3.7.18)
Substituting for x1(t), x2(t) and x3(t) and simplifying, we ﬁnally obtain
eAt = 1
2


e4t + e2t −2te2t
−2te2t
e4t −e2t
e2t −e4t + 2te2t
2(t + 1)e2t
e2t −e4t
e4t −e2t + 2te2t
2te2t
e4t + e2t

;
(3.7.19)

142
Advanced Engineering Mathematics with MATLAB
or
x1(t) =
  1
2e4t + 1
2e2t −te2t
x1(0) −te2tx2(0) +
  1
2e4t −1
2e2t
x3(0),
(3.7.20)
x2(t) =
  1
2e2t −1
2e4t + te2t
x1(0) + (t + 1)e2tx2(0) +
  1
2e2t −1
2e4t
x3(0),
(3.7.21)
and
x3(t) =
  1
2e4t −1
2e2t + te2t
x1(0) + te2tx2(0) +
  1
2e4t + 1
2e2t
x3(0).
(3.7.22)
⊓⊔
• Example 3.7.2
The matrix exponential can also be used to solve systems of ﬁrst-order, nonhomoge-
neous linear ordinary diﬀerential equations. To illustrate this, consider the following system
of linear ordinary diﬀerential equations:
x′ = x −4y + e2t,
(3.7.23)
and
y′ = x + 5y + t.
(3.7.24)
We can rewrite this system as
x′ = Ax + b,
(3.7.25)
where
A =

1
−4
1
5

,
b =

e2t
t

,
and
x =

x(t)
y(t)

.
(3.7.26)
We leave as an exercise the computation of the matrix exponential and ﬁnd that
eAt =

e3t −2te3t
−4te3t
te3t
e3t + 2te3t

.
(3.7.27)
Clearly the homogeneous solution is xH(t) = eAtC, where C is the arbitrary constant
that is determined by the initial condition. But how do we ﬁnd the particular solution,
xp(t)? Let xp(t) = eAty(t). Then
x′
p(t) = AeAty(t) + eAty′(t),
(3.7.28)
or
x′
p(t) = Axp(t) + eAty′(t).
(3.7.29)
Therefore,
eAty′(t) = b(t),
or
y(t) = e−Atb(t),
(3.7.30)
since
 eA−1 = e−A. Integrating both sides of Equation 3.7.29 and multiplying through by
eAt, we ﬁnd that
xp(t) =
Z t
0
eA(t−s)b(s) ds =
Z t
0
eAsb(t −s) ds.
(3.7.31)

Linear Algebra
143
Returning to our original problem,
Z t
0
eAsb(t −s) ds =
Z t
0

e3s −2se3s
−4se3s
se3s
e3s + 2se3s
 
e2(t−s)
t −s

ds
(3.7.32)
=
Z t
0

e2t (es −2ses) −4s(t −s)e3s
e2tses + (t −s)e3s + 2s(t −s)e3s

ds
(3.7.33)
=


89
27e3t −3e2t −22
9 te3t −4
9t −8
27
−28
27e3t + e2t + 11
9 te3t −1
9t + 1
27

.
(3.7.34)
The ﬁnal answer consists of the homogeneous solution plus the particular solution.
Problems
Find eAt for the following matrices A:
1. A =

1
3
0
1

2. A =

3
5
0
3

3. A =


1
1
0
0
1
1
0
0
1


4. A =


2
3
4
0
2
3
0
0
2


5. A =


1
2
0
0
1
2
0
0
1


For each of the following A’s and b’s, use the matrix exponential to ﬁnd the general solution
for the system of ﬁrst-order, linear ordinary diﬀerential equations x′ = Ax + b:
6. A =

3
−2
4
−1

, b =

et
et

7. A =

2
−1
3
−2

, b =

et
t

8. A =

2
1
−4
2

, b =

te2t
−e2t

9. A =

2
−5
1
−2

, b =

−cos(t)
sin(t)

10. A =

2
−1
5
−2

, b =

cos(t)
sin(t)

11. A =


2
1
1
1
2
1
1
1
2

, b =


0
tet
et


12. A =


1
1
1
0
2
1
0
0
3

, b =


2t
t + 2
3t


13. A =


1
0
1
0
−2
0
4
0
1

, b =


−3et
6et
−4et


14. A =


1
0
2
0
1
0
1
0
0

, b =


et
et
et


15. A =


1
1
2
−1
3
4
0
0
2

, b =


t
1
et

.
Further Readings
Bronson, R., and G. B. Costa, 2007: Linear Algebra: An Introduction. Academic Press,
520 pp. Provides a step-by-step explanation of linear algebra.

144
Advanced Engineering Mathematics with MATLAB
Davis, H. T., and K. T. Thomson, 2000: Linear Algebra and Linear Operators in Engi-
neering with Applications in Mathematica. Academic Press, 547 pp. Advanced textbook
designed for ﬁrst-year graduate students in the physical sciences and engineering.
Hoﬀman, J., 2001: Numerical Methods for Engineers and Scientists. Mc-Graw Hill, 823 pp.
A ﬁrst course in numerical methods that is both lucid and in depth.
Munakata, T., 1979: Matrices and Linear Programming with Applications. Holden-Day,
469 pp. Provides the basic concepts with clarity.
Noble, B., and J. W. Daniel, 1977: Applied Linear Algebra. Prentice Hall, 494 pp. Excellent
conceptual explanations with well-motivated proofs.
Strang, G., 2009: Linear Algebra and Its Applications. Academic Press, 584 pp. A good
supplement to a formal text that provides intuitive understanding.
Wilkinson, J. H., 1988: The Algebraic Eigenvalue Problem. Clarendon Press, 662 pp. The
classic source book on the eigenvalue problem

Chapter 4
Vector Calculus
Physicists invented vectors and vector operations to facilitate their mathematical ex-
pression of such diverse topics as mechanics and electromagnetism. In this chapter we focus
on multivariable diﬀerentiations and integrations of vector ﬁelds, such as the velocity of a
ﬂuid, where the vector ﬁeld is solely a function of its position.
4.1 REVIEW
The physical sciences and engineering abound with vectors and scalars. Scalars are
physical quantities that only possess magnitude.
Examples include mass, temperature,
density, and pressure. Vectors are physical quantities that possess both magnitude and
direction. Examples include velocity, acceleration, and force. We shall denote vectors by
boldfaced letters.
Two vectors are equal if they have the same magnitude and direction. From the limitless
number of possible vectors, two special cases are the zero vector 0, which has no magnitude
and unspeciﬁed direction, and the unit vector, which has unit magnitude.
The most convenient method for expressing a vector analytically is in terms of its
components. A vector a in three-dimensional real space is any order triplet of real numbers
(components) a1, a2, and a3 such that a = a1i + a2j + a3k, where a1i, a2j, and a3k are
vectors that lie along the coordinate axes and have their origin at a common initial point.
The magnitude, length, or norm of a vector a, |a|, equals
p
a2
1 + a2
2 + a2
3. A particularly
important vector is the position vector, deﬁned by r = xi + yj + zk.
As in the case of scalars, certain arithmetic rules hold. Addition and subtraction are
very similar to their scalar counterparts:
a + b = (a1 + b1)i + (a2 + b2)j + (a3 + b3)k,
(4.1.1)
145

146
Advanced Engineering Mathematics with MATLAB
and
a −b = (a1 −b1)i + (a2 −b2)j + (a3 −b3)k.
(4.1.2)
In contrast to its scalar counterpart, there are two types of multiplication. The dot
product is deﬁned as
a · b = |a||b| cos(θ) = a1b1 + a2b2 + a3b3,
(4.1.3)
where θ is the angle between the vector such that 0 ≤θ ≤π. The dot product yields a
scalar answer. A particularly important case is a · b = 0 with |a| ̸= 0, and |b| ̸= 0. In this
case the vectors are orthogonal (perpendicular) to each other.
The other form of multiplication is the cross product, which is deﬁned by a × b =
|a||b| sin(θ)n, where θ is the angle between the vectors such that 0 ≤θ ≤π, and n is a unit
vector perpendicular to the plane of a and b, with the direction given by the right-hand
rule. A convenient method for computing the cross product from the scalar components of
a and b is
a × b =

i
j
k
a1
a2
a3
b1
b2
b3

=

a2
a3
b2
b3
 i −

a1
a3
b1
b3
 j +

a1
a2
b1
b2
 k.
(4.1.4)
Two nonzero vectors a and b are parallel if and only if a × b = 0.
Most of the vectors that we will use are vector-valued functions. These functions are
vectors that vary either with a single parametric variable t or multiple variables, say x, y,
and z.
The most commonly encountered example of a vector-valued function that varies with
a single independent variable involves the trajectory of particles. If a space curve is param-
eterized by the equations x = f(t), y = g(t), and z = h(t) with a ≤t ≤b, the position
vector r(t) = f(t)i + g(t)j + h(t)k gives the location of a point P as it moves from its initial
position to its ﬁnal position. Furthermore, because the increment quotient ∆r/∆t is in the
direction of a secant line, then the limit of this quotient as ∆t →0, r′(t) gives the tangent
(tangent vector) to the curve at P.
• Example 4.1.1: Foucault pendulum
One of the great experiments of mid-nineteenth-century physics was the demonstration
by J. B. L. Foucault (1819-1868) in 1851 of the earth’s rotation by designing a (spherical)
pendulum, supported by a long wire, that essentially swings in an nonaccelerating coor-
dinate system. This problem demonstrates many of the fundamental concepts of vector
calculus.
The total force1 acting on the bob of the pendulum is F = T + mG, where T is
the tension in the pendulum and G is the gravitational attraction per unit mass. Using
Newton’s second law,
d2r
dt2

inertial
= T
m + G,
(4.1.5)
where r is the position vector from a ﬁxed point in an inertial coordinate system to the bob.
This system is inconvenient because we live on a rotating coordinate system. Employing
1 See Broxmeyer, C., 1960: Foucault pendulum eﬀect in a Schuler-tuned system. J. Aerosp. Sci., 27,
343–347.

Vector Calculus
147
the conventional geographic coordinate system,2 Equation 4.1.5 becomes
d2r
dt2 + 2Ω× dr
dt + Ω× (Ω× r) = T
m + G,
(4.1.6)
where Ωis the angular rotation vector of the earth and r now denotes a position vector in
the rotating reference system with its origin at the center of the earth and terminal point at
the bob. If we deﬁne the gravity vector g = G −Ω× (Ω× r), then the dynamical equation
is
d2r
dt2 + 2Ω× dr
dt = T
m + g,
(4.1.7)
where the second term on the left side of Equation 4.1.7 is called the Coriolis force.
Because the equation is linear, let us break the position vector r into two separate
vectors: r0 and r1, where r = r0 + r1. The vector r0 extends from the center of the earth
to the pendulum’s point of support, and r1 extends from the support point to the bob.
Because r0 is a constant in the geographic system,
d2r1
dt2 + 2Ω× dr1
dt = T
m + g.
(4.1.8)
If the length of the pendulum is L, then for small oscillations r1 ≈xi + yj + Lk and
the equations of motion are
d2x
dt2 + 2Ωsin(λ)dy
dt = Tx
m ,
(4.1.9)
d2y
dt2 −2Ωsin(λ)dx
dt = Ty
m ,
(4.1.10)
and
2Ωcos(λ)dy
dt −g = Tz
m ,
(4.1.11)
where λ denotes the latitude of the point and Ωis the rotation rate of the earth. The
relationships between the components of tension are Tx = xTz/L, and Ty = yTz/L. From
Equation 4.1.11,
Tz
m + g = 2Ωcos(λ)dy
dt ≈0.
(4.1.12)
Substituting the deﬁnitions of Tx, Ty, and Equation 4.1.12 into Equation 4.1.9 and Equation
4.1.10,
d2x
dt2 + g
Lx + 2Ωsin(λ)dy
dt = 0,
(4.1.13)
and
d2y
dt2 + g
Ly −2Ωsin(λ)dx
dt = 0.
(4.1.14)
The approximate solution to these coupled diﬀerential equations is
x(t) ≈A0 cos[Ωsin(λ)t] sin
p
g/L t

,
(4.1.15)
and
y(t) ≈A0 sin[Ωsin(λ)t] sin
p
g/L t

,
(4.1.16)
2 For the derivation, see Marion, J. B., 1965: Classical Dynamics of Particles and Systems. Academic
Press, Sections 12.2–12.3.

148
Advanced Engineering Mathematics with MATLAB
T
x
y
T=0  C
10
20
30
Figure 4.1.1: For a two-dimensional ﬁeld T(x, y), the gradient is a vector that is perpendicular to the
isotherms T(x, y) = constant and points in the direction of most rapidly increasing temperatures.
if Ω2 ≪g/L. Thus, we have a pendulum that swings with an angular frequency
p
g/L.
However, depending upon the latitude λ, the direction in which the pendulum swings
changes counterclockwise with time, completing a full cycle in 2π/[Ωsin(λ)]. This result is
most clearly seen when λ = π/2 and we are at the North Pole. There the earth is turning
underneath the pendulum. If initially we set the pendulum swinging along the 0◦longitude,
the pendulum will shift with time to longitudes east of the Greenwich median. Eventually,
after 24 hours, the process repeats itself.
⊓⊔
Consider now vector-valued functions that vary with several variables. A vector func-
tion of position assigns a vector value for every value of x, y, and z within some domain.
Examples include the velocity ﬁeld of a ﬂuid at a given instant:
v = u(x, y, z)i + v(x, y, z)j + w(x, y, z)k.
(4.1.17)
Another example arises in electromagnetism where electric and magnetic ﬁelds often vary
as a function of the space coordinates. For us, however, probably the most useful example
involves the vector diﬀerential operator, del or nabla,
∇= ∂
∂xi + ∂
∂y j + ∂
∂z k,
(4.1.18)
which we apply to the multivariable diﬀerentiable scalar function F(x, y, z) to give the
gradient ∇F.
An important geometric interpretation of the gradient-one which we shall use frequent-
ly-is the fact that ∇f is perpendicular (normal) to the level surface at a given point P. To
prove this, let the equation F(x, y, z) = c describe a three-dimensional surface.
If the
diﬀerentiable functions x = f(t), y = g(t), and z = h(t) are the parametric equations of a
curve on the surface, then the derivative of F[f(t), g(t), h(t)] = c is
∂F
∂x
dx
dt + ∂F
∂y
dy
dt + ∂F
∂z
dz
dt = 0,
(4.1.19)
or
∇F · r′ = 0.
(4.1.20)
When r′ ̸= 0, the vector ∇F is orthogonal to the tangent vector. Because our argument
holds for any diﬀerentiable curve that passes through the arbitrary point (x, y, z), then ∇F
is normal to the level surface at that point.

Vector Calculus
149
Figure 4.1.1 gives a common application of the gradient. Consider a two-dimensional
temperature ﬁeld T(x, y). The level curves T(x, y) = constant are lines that connect points
where the temperature is the same (isotherms). The gradient in this case ∇T is a vector that
is perpendicular or normal to these isotherms and points in the direction of most rapidly
increasing temperature.
• Example 4.1.2
Let us ﬁnd the gradient of the function f(x, y, z) = x2z2 sin(4y).
Using the deﬁnition of gradient,
∇f = ∂[x2z2 sin(4y)]
∂x
i + ∂[x2z2 sin(4y)]
∂y
j + ∂[x2z2 sin(4y)]
∂z
k
(4.1.21)
= 2xz2 sin(4y)i + 4x2z2 cos(4y)j + 2x2z sin(4y)k.
(4.1.22)
⊓⊔
• Example 4.1.3
Let us ﬁnd the unit normal to the unit sphere at any arbitrary point (x, y, z).
The surface of a unit sphere is deﬁned by the equation f(x, y, z) = x2 + y2 + z2 = 1.
Therefore, the normal is given by the gradient
N = ∇f = 2xi + 2yj + 2zk,
(4.1.23)
and the unit normal
n = ∇f
|∇f| =
2xi + 2yj + 2zk
p
4x2 + 4y2 + 4z2 = xi + yj + zk,
(4.1.24)
because x2 + y2 + z2 = 1.
⊓⊔
• Example 4.1.4
In Figure 4.1.2, MATLAB has been used to illustrate the unit normal of the surface
z = 4 −x2 −y2. Here f(x, y, z) = z + x2 + y2 = 4 so that ∇f = 2xi + 2yj + k. The
corresponding script is:
clear % clear variables
clf % clear figures
[x,y] = meshgrid(-2:0.5:2); % create the grid
z = 4 - x.^2 - y.^2; % compute surface within domain
% compute the gradient of f(x,y,z) = z + x^2 + y^2 = 4
% the x, y, and z components are u, v, and w
u = 2*x; v = 2*y; w = 1;
% find magnitude of gradient at each point
magnitude = sqrt(u.*u + v.*v + w.*w);
% compute unit gradient vector
u = u./magnitude; v = v./magnitude; w = w./magnitude;
mesh(x,y,z) % plot the surface
axis square
xlabel(’x’); ylabel(’y’)

150
Advanced Engineering Mathematics with MATLAB
−4
−2
0
2
4
−4
−2
0
2
4
−4
−3
−2
−1
0
1
2
3
4
5
y
x
Figure 4.1.2: MATLAB plot of the function z = 4 −x2 −y2. The arrows give the unit normal to this
surface.
hold on
% plot the unit gradient vector
quiver3(x,y,z,u,v,w,0)
This ﬁgure clearly shows that gradient gives a vector which is perpendicular to the
surface.
⊓⊔
A popular method for visualizing a vector ﬁeld F is to draw space curves that are
tangent to the vector ﬁeld at each x, y, z. In ﬂuid mechanics these lines are called streamlines
while in physics they are generally called lines of force or ﬂux lines for an electric, magnetic,
or gravitational ﬁeld. For a ﬂuid with a velocity ﬁeld that does not vary with time, the
streamlines give the paths along which small parcels of the ﬂuid move.
To ﬁnd the streamlines of a given vector ﬁeld F with components P(x, y, z), Q(x, y, z),
and R(x, y, z), we assume that we can parameterize the streamlines in the form r(t) =
x(t)i + y(t)j + z(t)k. Then the tangent line is r′(t) = x′(t)i + y′(t)j + z′(t)k. Because the
streamline must be parallel to the vector ﬁeld at any t, r′(t) = λF, or
dx
dt = λP(x, y, z),
dy
dt = λQ(x, y, z),
and
dz
dt = λR(x, y, z),
(4.1.25)
or
dx
P(x, y, z) =
dy
Q(x, y, z) =
dz
R(x, y, z).
(4.1.26)
The solution of this system of diﬀerential equations yields the streamlines.
• Example 4.1.5
Let us ﬁnd the streamlines for the vector ﬁeld F = sec(x)i −cot(y)j + k that passes
through the point (π/4, π, 1). In this particular example, F represents a measured or com-
puted ﬂuid’s velocity at a particular instant.
From Equation 4.1.26,
dx
sec(x) = −
dy
cot(y) = dz
1 .
(4.1.27)

Vector Calculus
151
This yields two diﬀerential equations:
cos(x) dx = −sin(y)
cos(y) dy,
and
dz = −sin(y)
cos(y) dy.
(4.1.28)
Integrating these equations gives
sin(x) = ln | cos(y)| + c1,
and
z = ln | cos(y)| + c2.
(4.1.29)
Substituting for the given point, we ﬁnally have that
sin(x) = ln | cos(y)| +
√
2/2,
and
z = ln | cos(y)| + 1.
(4.1.30)
⊓⊔
• Example 4.1.6
Let us ﬁnd the streamlines for the vector ﬁeld F = sin(z)j + eyk that passes through
the point (2, 0, 0).
From Equation 4.1.26,
dx
0 =
dy
sin(z) = dz
ey .
(4.1.31)
This yields two diﬀerential equations:
dx = 0,
and
sin(z) dz = ey dy.
(4.1.32)
Integrating these equations gives
x = c1,
and
ey = −cos(z) + c2.
(4.1.33)
Substituting for the given point, we ﬁnally have that
x = 2,
and
ey = 2 −cos(z).
(4.1.34)
Note that Equation 4.1.34 only applies for a certain strip in the yz-plane.
Problems
Given the following vectors a and b, verify that a · (a × b) = 0, and b · (a × b) = 0:
1. a = 4i −2j + 5k,
b = 3i + j −k
2. a = i −3j + k,
b = 2i + 4k
3. a = i + j + k,
b = −5i + 2j + 3k
4. a = 8i + j −6k,
b = i −2j + 10k
5. a = 2i + 7j −4k,
b = i + j −k.
6. Prove a × (b × c) = (a · c)b −(a · b)c.
7. Prove a × (b × c) + b × (c × a) + c × (a × b) = 0.

152
Advanced Engineering Mathematics with MATLAB
Find the gradient of the following functions:
8. f(x, y, z) = xy2/z3
9. f(x, y, z) = xy cos(yz)
10. f(x, y, z) = ln(x2 + y2 + z2)
11. f(x, y, z) = x2y2(2z + 1)2 12. f(x, y, z) = 2x −y2 + z2.
Use MATLAB to illustrate the following surfaces as well as the unit normal.
13. z = 3
14. x2 + y2 = 4
15. z = x2 + y2
16. z =
p
x2 + y2
17. z = y
18. x + y + z = 1
19. z = x2.
Find the streamlines for the following vector ﬁelds that pass through the speciﬁed point:
20. F = i + j + k; (0, 1, 1)
21. F = 2i −y2j + zk; (1, 1, 1)
22. F = 3x2i −y2j + z2k; (2, 1, 3)
23. F = x2i + y2j −z3k; (1, 1, 1)
24. F = (1/x)i + eyj −k; (2, 0, 4).
25. Solve the diﬀerential equations, Equation 4.1.13 and Equation 4.1.14 with the initial
conditions x(0) = y(0) = y′(0) = 0, and x′(0) = A0
p
g/L assuming that Ω2 ≪g/L.
26. If a ﬂuid is bounded by a ﬁxed surface f(x, y, z) = c, show that the ﬂuid must satisfy
the boundary condition v · ∇f = 0, where v is the velocity of the ﬂuid.
27. A sphere of radius a is moving in a ﬂuid with the constant velocity u. Show that the
ﬂuid satisﬁes the boundary condition (v −u) · (r −ut) = 0 at the surface of the sphere, if
the center of the sphere coincides with the origin at t = 0 and v denotes the velocity of the
ﬂuid.
4.2 DIVERGENCE AND CURL
Consider a vector ﬁeld v deﬁned in some region of three-dimensional space. The func-
tion v(r) can be resolved into components along the i, j, and k directions, or
v(r) = u(x, y, z)i + v(x, y, z)j + w(x, y, z)k.
(4.2.1)
If v is a ﬂuid’s velocity ﬁeld, then we can compute the ﬂow rate through a small (diﬀerential)
rectangular box deﬁned by increments (∆x, ∆y, ∆z) centered at the point (x, y, z). See
Figure 4.2.1.
The ﬂow out from the box through the face with the outwardly pointing
normal n = −j is
v · (−j) = −v(x, y −∆y/2, z)∆x∆z,
(4.2.2)
and the ﬂow through the face with the outwardly pointing normal n = j is
v · j = v(x, y + ∆y/2, z)∆x∆z.
(4.2.3)
The net ﬂow through the two faces is
[v(x, y + ∆y/2, z) −v(x, y −∆y/2, z)]∆x∆z ≈vy(x, y, z)∆x∆y∆z.
(4.2.4)

Vector Calculus
153
+
1
v
1
2
v
y dy
u
x
u+
dx
1
v
y
2
x
u
u
2
2
dx
dy
v
w
1
2
dz
w
21
dz
z
z
+
w
w
1
z
x
y
Figure 4.2.1: Divergence of a vector function v(x, y, z).
A similar analysis of the other faces and combination of the results give the approximate
total ﬂow from the box as
[ux(x, y, z) + vy(x, y, z) + wz(x, y, z)]∆x∆y∆z.
(4.2.5)
Dividing by the volume ∆x∆y∆z and taking the limit as the dimensions of the box tend
to zero yield ux + vy + wz as the ﬂow out from (x, y, z) per unit volume per unit time. This
scalar quantity is called the divergence of the vector v:
div(v) = ∇· v =
 ∂
∂xi + ∂
∂y j + ∂
∂z k

· (ui + vj + wk) = ux + vy + wz.
(4.2.6)
Thus, if the divergence is positive, either the ﬂuid is expanding and its density at the point
is falling with time, or the point is a source at which ﬂuid is entering the ﬁeld. When the
divergence is negative, either the ﬂuid is contracting and its density is rising at the point,
or the point is a negative source or sink at which ﬂuid is leaving the ﬁeld.
If the divergence of a vector ﬁeld is zero everywhere within a domain, then the ﬂux
entering any element of space exactly balances that leaving it and the vector ﬁeld is called
nondivergent or solenoidal (from a Greek word meaning a tube). For a ﬂuid, if there are no
sources or sinks, then its density cannot change.
Some useful properties of the divergence operator are
∇· (F + G) = ∇· F + ∇· G,
(4.2.7)
∇· (ϕF) = ϕ∇· F + F · ∇ϕ
(4.2.8)
and
∇2ϕ = ∇· ∇ϕ = ϕxx + ϕyy + ϕzz.
(4.2.9)
Equation 4.2.9 is very important in physics and is given the special name of the Laplacian.3
• Example 4.2.1
If F = x2zi −2y3z2j + xy2zk, compute the divergence of F.
∇· F = ∂
∂x
 x2z

+ ∂
∂y
 −2y3z2
+ ∂
∂z
 xy2z

= 2xz −6y2z2 + xy2.
(4.2.10)
3 Some mathematicians write ∆instead of ∇2.

154
Advanced Engineering Mathematics with MATLAB
no curl
curl
no divergence
divergence
divergence
and curl
no curl
no divergence
Figure 4.2.2: Examples of vector ﬁelds with and without divergence and curl.
⊓⊔
• Example 4.2.2
If r = xi + yj + zk, show that r/|r|3 is nondivergent.
∇·
 r
|r|3

= ∂
∂x

x
(x2 + y2 + z2)3/2

+ ∂
∂y

y
(x2 + y2 + z2)3/2

+ ∂
∂z

z
(x2 + y2 + z2)3/2

(4.2.11)
=
3
(x2 + y2 + z2)3/2 −3x2 + 3y2 + 3z2
(x2 + y2 + z2)5/2 = 0.
(4.2.12)
⊓⊔
Another important vector function involving the vector ﬁeld v is the curl of v, written
curl(v) or rot(v) in some older textbooks. In ﬂuid ﬂow problems it is proportional to the
instantaneous angular velocity of a ﬂuid element. In rectangular coordinates,
curl(v) = ∇× v = (wy −vz)i + (uz −wx)j + (vx −uy)k,
(4.2.13)
where v = ui + vj + wk as before. However, it is best remembered in the mnemonic form:
∇× F =

i
j
k
∂
∂x
∂
∂y
∂
∂z
u
v
w

= (wy −vz)i + (uz −wx)j + (vx −uy)k.
(4.2.14)
If the curl of a vector ﬁeld is zero everywhere within a region, then the ﬁeld is irrotational.
Figure 4.2.2 illustrates graphically some vector ﬁelds that do and do not possess diver-
gence and curl. Let the vectors that are illustrated represent the motion of ﬂuid particles.
In the case of divergence only, ﬂuid is streaming from the point, at which the density is
falling. Alternatively the point could be a source. In the case where there is only curl,
the ﬂuid rotates about the point and the ﬂuid is incompressible. Finally, the point that
possesses both divergence and curl is a compressible ﬂuid with rotation.
Some useful computational formulas exist for both the divergence and curl operations:
∇× (F + G) = ∇× F + ∇× G,
(4.2.15)
∇× ∇ϕ = 0,
(4.2.16)
∇· ∇× F = 0,
(4.2.17)

Vector Calculus
155
∇× (ϕF) = ϕ∇× F + ∇ϕ × F,
(4.2.18)
∇(F · G) = (F · ∇)G + (G · ∇)F + F × (∇× G) + G × (∇× F),
(4.2.19)
∇× (F × G) = (G · ∇)F −(F · ∇)G + F(∇· G) −G(∇· F),
(4.2.20)
∇× (∇× F) = ∇(∇· F) −(∇· ∇)F,
(4.2.21)
and
∇· (F × G) = G · ∇× F −F · ∇× G.
(4.2.22)
In this book the operation ∇F is undeﬁned.
• Example 4.2.3
If F = xz3i −2x2yzj + 2yz4k, compute the curl of F and verify that ∇· ∇× F = 0.
From the deﬁnition of curl,
∇× F =

i
j
k
∂
∂x
∂
∂y
∂
∂z
xz3
−2x2yz
2yz4

(4.2.23)
=
h
∂
∂y
 2yz4
−∂
∂z
 −2x2yz
i
i −
 ∂
∂x
 2yz4
−∂
∂z
 xz3
j
+
h
∂
∂x
 −2x2yz

−∂
∂y
 xz3i
k
(4.2.24)
= (2z4 + 2x2y)i −(0 −3xz2)j + (−4xyz −0)k
(4.2.25)
= (2z4 + 2x2y)i + 3xz2j −4xyzk.
(4.2.26)
From the deﬁnition of divergence and Equation 4.2.26,
∇· ∇× F = ∂
∂x
 2z4 + 2x2y

+ ∂
∂y
 3xz2
+ ∂
∂z
 −4xyz

= 4xy + 0 −4xy = 0.
(4.2.27)
⊓⊔
• Example 4.2.4: Potential ﬂow theory
One of the topics in most elementary ﬂuid mechanics courses is the study of irrotational
and nondivergent ﬂuid ﬂows. Because the ﬂuid is irrotational, the velocity vector ﬁeld v
satisﬁes ∇× v = 0.
From Equation 4.2.16 we can introduce a potential ϕ such that
v = ∇ϕ. Because the ﬂow ﬁeld is nondivergent, ∇· v = ∇2ϕ = 0. Thus, the ﬂuid ﬂow
can be completely described in terms of solutions to Laplace’s equation. This area of ﬂuid
mechanics is called potential ﬂow theory.
Problems
Compute ∇· F, ∇× F, ∇· (∇× F), and ∇(∇· F), for the following vector ﬁelds:
1. F = x2zi + yz2j + xy2k
2. F = 4x2y2i + (2x + 2yz)j + (3z + y2)k
3. F = (x −y)2i + e−xyj + xze2yk
4. F = 3xyi + 2xz2j + y3k
5. F = 5yzi + x2zj + 3x3k
6. F = y3i + (x3y2 −xy)j −(x3yz −xz)k

156
Advanced Engineering Mathematics with MATLAB
7. F = xe−yi + yz2j + 3e−zk
8. F = y ln(x)i + (2 −3yz)j + xyz3k
9. F = xyzi + x3yzezj + xyezk
10. F = (xy3 −z4)i + 4x4y2zj −y4z5k
11. F = xy2i + xyz2j + xy cos(z)k
12. F = xy2i + xyz2j + xy sin(z)k
13. F = xy2i + xyzj + xy cos(z)k
14. (a) Assuming continuity of all partial derivatives, show that
∇× (∇× F) = ∇(∇· F) −∇2F.
(b) Using F = 3xyi + 4yzj + 2xzk, verify the results in part (a).
15. If E = E(x, y, z, t) and B = B(x, y, z, t) represent the electric and magnetic ﬁelds in a
vacuum, Maxwell’s ﬁeld equations are:
∇· E = 0,
∇× E = −1
c
∂B
∂t ,
∇· B = 0,
∇× B = 1
c
∂E
∂t ,
where c is the speed of light. Using the results from Problem 14, show that E and B satisfy
∇2E = 1
c2
∂2E
∂t2 ,
and
∇2B = 1
c2
∂2B
∂t2 .
16. If f and g are continuously diﬀerentiable scalar ﬁelds, show that ∇f × ∇g is solenoidal.
Hint: Show that ∇f × ∇g = ∇× (f∇g).
17. An inviscid (frictionless) ﬂuid in equilibrium obeys the relationship ∇p = ρF, where
ρ denotes the density of the ﬂuid, p denotes the pressure, and F denotes the body forces
(such as gravity). Show that F · ∇× F = 0.
4.3 LINE INTEGRALS
Line integrals are ubiquitous in physics. In mechanics they are used to compute work.
In electricity and magnetism, they provide simple methods for computing the electric and
magnetic ﬁelds for simple geometries.
The line integral most frequently encountered is an oriented one in which the path C
is directed and the integrand is the dot product between the vector function F(r) and the
tangent of the path dr. It is usually written in the economical form
Z
C
F · dr =
Z
C
P(x, y, z) dx + Q(x, y, z) dy + R(x, y, z) dz,
(4.3.1)
where F = P(x, y, z)i + Q(x, y, z)j + R(x, y, z)k. If the starting and terminal points are the
same so that the contour is closed, then this closed contour integral will be denoted by
H
C.

Vector Calculus
157
0
0.5
1
0
0.5
1
0
0.2
0.4
0.6
0.8
1
y
x
z
Figure 4.3.1: Diagram for the line integration in Example 4.3.1.
In the following examples we show how to evaluate the line integrals along various types of
curves.
• Example 4.3.1
If F = (3x2 + 6y)i −14yzj + 20xz2k, let us evaluate the line integral
R
C F · dr along
the parametric curves x(t) = t, y(t) = t2, and z(t) = t3 from the point (0, 0, 0) to (1, 1, 1).
Using the MATLAB commands
>> clear
>> t = 0:0.02:1
>> stem3(t,t.^2,t.^3); xlabel(’x’,’Fontsize’,20); ...
ylabel(’y’,’Fontsize’,20); zlabel(’z’,’Fontsize’,20);
we illustrate these parametric curves in Figure 4.3.1.
We begin by ﬁnding the values of t, which give the corresponding endpoints. A quick
check shows that t = 0 gives (0, 0, 0) while t = 1 yields (1, 1, 1). It should be noted that
the same value of t must give the correct coordinates in each direction. Failure to do so
suggests an error in the parameterization. Therefore,
Z
C
F · dr =
Z 1
0
(3t2 + 6t2) dt −14t2(t3) d(t2) + 20t(t3)2d(t3)
(4.3.2)
=
Z 1
0
9t2 dt −28t6 dt + 60t9 dt =
 3t3 −4t7 + 6t101
0 = 5.
(4.3.3)
⊓⊔
• Example 4.3.2
Let us redo the previous example with a contour that consists of three “dog legs,”
namely straight lines from (0, 0, 0) to (1, 0, 0), from (1, 0, 0) to (1, 1, 0), and from (1, 1, 0) to
(1, 1, 1). See Figure 4.3.2.
In this particular problem we break the integration down into integrals along each of
the legs:
Z
C
F · dr =
Z
C1
F · dr +
Z
C2
F · dr +
Z
C3
F · dr.
(4.3.4)

158
Advanced Engineering Mathematics with MATLAB
(1,0,0)
z
x
y
(1,1,0)
(1,1,1)
(0,0,0)
Figure 4.3.2: Diagram for the line integration in Example 4.3.2.
For C1, y = z = dy = dz = 0, and
Z
C1
F · dr =
Z 1
0
(3x2 + 6 · 0) dx −14 · 0 · 0 · 0 + 20x · 02 · 0 =
Z 1
0
3x2 dx = 1.
(4.3.5)
For C2, x = 1 and z = dx = dz = 0, so that
Z
C2
F · dr =
Z 1
0
(3 · 12 + 6y) · 0 −14y · 0 · dy + 20 · 1 · 02 · 0 = 0.
(4.3.6)
For C3, x = y = 1 and dx = dy = 0, so that
Z
C3
F · dr =
Z 1
0
(3 · 12 + 6 · 1) · 0 −14 · 1 · z · 0 + 20 · 1 · z2 dz =
Z 1
0
20z2 dz = 20
3 . (4.3.7)
Therefore,
Z
C
F · dr = 23
3 .
(4.3.8)
⊓⊔
• Example 4.3.3
For our third calculation, we redo the ﬁrst example where the contour is a straight line.
The parameterization in this case is x = y = z = t with 0 ≤t ≤1. See Figure 4.3.3. Then,
Z
C
F · dr =
Z 1
0
(3t2 + 6t) dt −14(t)(t) dt + 20t(t)2 dt
(4.3.9)
=
Z 1
0
(3t2 + 6t −14t2 + 20t3) dt = 13
3 .
(4.3.10)
⊓⊔
An interesting aspect of these three examples is that, although we used a common
vector ﬁeld and moved from (0, 0, 0) to (1, 1, 1) in each case, we obtained a diﬀerent answer
in each case. Thus, for this vector ﬁeld, the line integral is path dependent. This is generally

Vector Calculus
159
(0,0,0)
z
x
y
(1,1,1)
Figure 4.3.3: Diagram for the line integration in Example 4.3.3.
true. In the next section we will meet conservative vector ﬁelds where the results will be
path independent.
• Example 4.3.4
If F = (x2 + y2)i −2xyj + xk, let us evaluate
R
C F · dr if the contour is that portion of
the circle x2 + y2 = a2 from the point (a, 0, 3) to (−a, 0, 3). See Figure 4.3.4.
The parametric equations for this example are x = a cos(θ), dx = −a sin(θ) dθ, y =
a sin(θ), dy = a cos(θ) dθ, z = 3, and dz = 0 with 0 ≤θ ≤π. Therefore,
Z
C
F · dr =
Z π
0
[a2 cos2(θ) + a2 sin2(θ)][−a sin(θ) dθ]
−2a2 cos(θ) sin(θ)[a cos(θ) dθ] + a cos(θ) · 0
(4.3.11)
= −a3
Z π
0
sin(θ) dθ −2a3
Z π
0
cos2(θ) sin(θ) dθ
(4.3.12)
= a3 cos(θ)
π
0 + 2
3a3 cos3(θ)
π
0 = −2a3 −4
3a3 = −10
3 a3.
(4.3.13)
⊓⊔
• Example 4.3.5: Circulation
Let v(x, y, z) denote the velocity at the point (x, y, z) in a moving ﬂuid. If it varies
with time, this is the velocity at a particular instant of time. The integral
H
C v·dr around a
closed path C is called the circulation around that path. The average component of velocity
along the path is
vs =
H
C vs ds
s
=
H
C v · dr
s
,
(4.3.14)
where s is the total length of the path. The circulation is thus
H
C v · dr = vss, the product
of the length of the path and the average velocity along the path. When the circulation is
positive, the ﬂow is more in the direction of integration than opposite to it. Circulation is
thus an indication and to some extent a measure of motion around the path.

160
Advanced Engineering Mathematics with MATLAB
(-a,0,3)
z
x
y
(a,0,3)
Figure 4.3.4: Diagram for the line integration in Example 4.3.4.
Problems
Evaluate
R
C F · dr for the following vector ﬁelds and curves:
1. F = y sin(πz)i + x2eyj + 3xzk and C is the curve x = t, y = t2, and z = t3 from (0, 0, 0)
to (1, 1, 1). Use MATLAB to illustrate the parametric curves.
2. F = yi + zj + xk and C consists of the line segments from (0, 0, 0) to (2, 3, 0), and from
(2, 3, 0) to (2, 3, 4). Use MATLAB to illustrate the parametric curves.
3. F = exi + xexyj + xyexyzk and C is the curve x = t, y = t2, and z = t3 with 0 ≤t ≤2.
Use MATLAB to illustrate the parametric curves.
4. F = yzi + xzj + xyk and C is the curve x = t3, y = t2, and z = t with 1 ≤t ≤2. Use
MATLAB to illustrate the parametric curves.
5. F = yi −xj + 3xyk and C consists of the semicircle x2 + y2 = 4, z = 0, y > 0, and the
line segment from (−2, 0, 0) to (2, 0, 0). Use MATLAB to illustrate the parametric curves.
6. F = (x + 2y)i + (6y −2x)j and C consists of the sides of the triangle with vertices
at (0, 0, 0), (1, 1, 1), and (1, 1, 0). Proceed from (0, 0, 0) to (1, 1, 1) to (1, 1, 0) and back to
(0, 0, 0). Use MATLAB to illustrate the parametric curves.
7. F = 2xzi+4y2j+x2k and C is taken counterclockwise around the ellipse x2/4+y2/9 = 1,
z = 1. Use MATLAB to illustrate the parametric curves.
8. F = 2xi + yj + zk and C is the contour x = t, y = sin(t), and z = cos(t) + sin(t) with
0 ≤t ≤2π. Use MATLAB to illustrate the parametric curves.
9.
F = (2y2 + z)i + 4xyj + xk and C is the spiral x = cos(t), y = sin(t), and z = t
with 0 ≤t ≤2π between the points (1, 0, 0) and (1, 0, 2π). Use MATLAB to illustrate the
parametric curves.
10. F = x2i + y2j + (z2 + 2xy)k and C consists of the edges of the triangle with vertices
at (0, 0, 0), (1, 1, 0), and (0, 1, 0). Proceed from (0, 0, 0) to (1, 1, 0) to (0, 1, 0) and back to
(0, 0, 0). Use MATLAB to illustrate the parametric curves.

Vector Calculus
161
4.4 THE POTENTIAL FUNCTION
In Section 4.2 we showed that the curl operation applied to a gradient produces the
zero vector: ∇× ∇ϕ = 0. Consequently, if we have a vector ﬁeld F such that ∇× F ≡0
everywhere, then that vector ﬁeld is called a conservative ﬁeld and we can compute a
potential ϕ such that F = ∇ϕ.
• Example 4.4.1
Let us show that the vector ﬁeld F = yexy cos(z)i + xexy cos(z)j −exy sin(z)k is con-
servative and then ﬁnd the corresponding potential function.
To show that the ﬁeld is conservative, we compute the curl of F or
∇× F =

i
j
k
∂
∂x
∂
∂y
∂
∂z
yexy cos(z)
xexy cos(z)
−exy sin(z)

= 0.
(4.4.1)
To ﬁnd the potential we must solve three partial diﬀerential equations:
ϕx = yexy cos(z) = F · i,
(4.4.2)
ϕy = xexy cos(z) = F · j,
(4.4.3)
and
ϕz = −exy sin(z) = F · k.
(4.4.4)
We begin by integrating any one of these three equations. Choosing Equation 4.4.2,
ϕ(x, y, z) = exy cos(z) + f(y, z).
(4.4.5)
To ﬁnd f(y, z) we diﬀerentiate Equation 4.4.5 with respect to y and ﬁnd that
ϕy = xexy cos(z) + fy(y, z) = xexy cos(z)
(4.4.6)
from Equation 4.4.3. Thus, fy = 0 and f(y, z) can only be a function of z, say g(z). Then,
ϕ(x, y, z) = exy cos(z) + g(z).
(4.4.7)
Finally,
ϕz = −exy sin(z) + g′(z) = −exy sin(z)
(4.4.8)
from Equation 4.4.4 and g′(z) = 0. Therefore, the potential is
ϕ(x, y, z) = exy cos(z) + constant.
(4.4.9)
⊓⊔
Potentials can be very useful in computing line integrals, because
Z
C
F · dr =
Z
C
ϕx dx + ϕy dy + ϕz dz =
Z
C
dϕ = ϕ(B) −ϕ(A),
(4.4.10)

162
Advanced Engineering Mathematics with MATLAB
where the point B is the terminal point of the integration while the point A is the starting
point. Thus, any path integration between any two points is path independent.
Finally, if we close the path so that A and B coincide, then
I
C
F · dr = 0.
(4.4.11)
It should be noted that the converse is not true. Just because
H
C F · dr = 0, we do not
necessarily have a conservative ﬁeld F.
In summary then, an irrotational vector in a given region has three fundamental prop-
erties: (1) its integral around every simply connected circuit is zero, (2) its curl equals zero,
and (3) it is the gradient of a scalar function. For continuously diﬀerentiable vectors, these
properties are equivalent. For vectors that are only piece-wise diﬀerentiable, this is not
true. Generally the ﬁrst property is the most fundamental and is taken as the deﬁnition of
irrotationality.
• Example 4.4.2
Using the potential found in Example 4.4.1, let us ﬁnd the value of the line integral
R
C F · dr from the point (0, 0, 0) to (−1, 2, π).
From Equation 4.4.9,
Z
C
F · dr =

exy cos(z) + constant

(−1,2,π)
(0,0,0)
= −1 −e−2.
(4.4.12)
Problems
Verify that the following vector ﬁelds are conservative and then ﬁnd the corresponding
potential:
1.F = 2xyi + (x2 + 2yz)j + (y2 + 4)k
2.F = (2x + 2ze2x)i + (2y −1)j + e2xk
3.F = yzi + xzj + xyk
4.F = 2xi + 3y2j + 4z3k
5.F = [2x sin(y) + e3z]i + x2 cos(y)j + (3xe3z + 4)k 6.F = (2x + 5)i + 3y2j + (1/z)k
7.F = e2zi + 3y2j + 2xe2zk
8.F = yi + (x + z)j + yk
9.F = (z + y)i + xj + xk.
4.5 SURFACE INTEGRALS
Surface integrals appear in such diverse ﬁelds as electromagnetism and ﬂuid mechanics.
For example, if we were oceanographers we might be interested in the rate of volume of
seawater through an instrument that has the curved surface S. The volume rate equals
RR
S v · n dσ, where v is the velocity and n dσ is an inﬁnitesimally small element on the
surface of the instrument. The surface element n dσ must have an orientation (given by n)
because it makes a considerable diﬀerence whether the ﬂow is directly through the surface

Vector Calculus
163
k
x
y
z
(0,0,1)
(0,1,1)
(1,1,1)
(1,0,1)
Figure 4.5.1: Diagram for the surface integration in Example 4.5.1.
or at right angles. In the special case when the surface encloses a three-dimensional volume,
then we have a closed surface integral.
To illustrate the concept of computing a surface integral, we will do three examples
with simple geometries. Later we will show how to use surface coordinates to do more
complicated geometries.
• Example 4.5.1
Let us ﬁnd the ﬂux out the top of a unit cube if the vector ﬁeld is F = xi + yj + zk.
See Figure 4.5.1.
The top of a unit cube consists of the surface z = 1 with 0 ≤x ≤1 and 0 ≤y ≤1. By
inspection the unit normal to this surface is n = k, or n = −k. Because we are interested
in the ﬂux out of the unit cube, n = k, and
ZZ
S
F · n dσ =
Z 1
0
Z 1
0
(xi + yj + k) · k dx dy = 1,
(4.5.1)
because z = 1.
⊓⊔
• Example 4.5.2
Let us ﬁnd the ﬂux out of that portion of the cylinder y2 + z2 = 4 in the ﬁrst octant
bounded by x = 0, x = 3, y = 0, and z = 0. The vector ﬁeld is F = xi + 2zj + yk. See
Figure 4.5.2.
Because we are dealing with a cylinder, cylindrical coordinates are appropriate. Let
y = 2 cos(θ), z = 2 sin(θ), and x = x with 0 ≤θ ≤π/2. To ﬁnd n, we use the gradient in
conjunction with the deﬁnition of the surface of the cylinder f(x, y, z) = y2 +z2 = 4. Then,
n = ∇f
|∇f| =
2yj + 2zk
p
4y2 + 4z2 = y
2j + z
2k,
(4.5.2)
because y2 + z2 = 4 along the surface. Since we want the ﬂux out of the surface, then
n = yj/2 + zk/2, whereas the ﬂux into the surface would require n = −yj/2 −zk/2.
Therefore,
F · n = (xi + 2zj + yk) ·
y
2j + z
2k

= 3yz
2
= 6 cos(θ) sin(θ).
(4.5.3)

164
Advanced Engineering Mathematics with MATLAB
(3,2,0)
n
x
z
y
(3,0,0)
(0,2,0)
(0,0,2)
Figure 4.5.2: Diagram for the surface integration in Example 4.5.2.
What is dσ? Our inﬁnitesimal surface area has a side in the x direction of length dx and
a side in the θ direction of length 2 dθ because the radius equals 2. Therefore, dσ = 2 dx dθ.
Bringing all of these elements together,
ZZ
S
F · n dσ =
Z 3
0
Z π/2
0
12 cos(θ) sin(θ) dθ dx = 6
Z 3
0
h
sin2(θ)
π/2
0
i
dx = 6
Z 3
0
dx = 18.
(4.5.4)
As counterpoint to this example, let us ﬁnd the ﬂux out of the pie-shaped surface at
x = 3. In this case, y = r cos(θ), z = r sin(θ), and
ZZ
S
F · n dσ =
Z π/2
0
Z 2
0
[3i + 2r sin(θ)j + r cos(θ)k] · i r dr dθ = 3
Z π/2
0
Z 2
0
r dr dθ = 3π.
(4.5.5)
⊓⊔
• Example 4.5.3
Let us ﬁnd the ﬂux of the vector ﬁeld F = y2i + x2j + 5zk out of the hemispheric
surface x2 + y2 + z2 = a2, z > 0. See Figure 4.5.3.
We begin by ﬁnding the outwardly pointing normal. Because the surface is deﬁned by
f(x, y, z) = x2 + y2 + z2 = a2,
n = ∇f
|∇f| =
2xi + 2yj + 2zk
p
4x2 + 4y2 + 4z2 = x
ai + y
aj + z
ak,
(4.5.6)
because x2 +y2 +z2 = a2. This is also the outwardly pointing normal since n = r/a, where
r is the radial vector.
Using spherical coordinates, x = a cos(ϕ) sin(θ), y = a sin(ϕ) sin(θ), and z = a cos(θ),
where ϕ is the angle made by the projection of the point onto the equatorial plane, measured
from the x-axis, and θ is the colatitude or “cone angle” measured from the z-axis.
To
compute dσ, the inﬁnitesimal length in the θ direction is a dθ while in the ϕ direction it
is a sin(θ) dϕ, where the sin(θ) factor takes into account the convergence of the meridians.
Therefore, dσ = a2 sin(θ) dθ dϕ, and
ZZ
S
F · n dσ =
Z 2π
0
Z π/2
0
 y2i + x2j + 5zk
 x
ai + y
aj + z
ak

a2 sin(θ) dθ dϕ
(4.5.7)

Vector Calculus
165
n
y
z
x
Figure 4.5.3: Diagram for the surface integration in Example 4.5.3.
ZZ
S
F · n dσ =
Z 2π
0
Z π/2
0
xy2
a
+ x2y
a
+ 5z2
a

a2 sin(θ) dθ dϕ
(4.5.8)
=
Z π/2
0
Z 2π
0

a4 cos(ϕ) sin2(ϕ) sin4(θ)
+ a4 cos2(ϕ) sin(ϕ) sin4(θ) + 5a3 cos2(θ) sin(θ)

dϕ dθ
(4.5.9)
=
Z π/2
0
a4
3 sin3(ϕ)

2π
0
sin4(θ) −a4
3 cos3(ϕ)

2π
0
sin4(θ)
+ 5a3 cos2(θ) sin(θ)ϕ
2π
0

dθ
(4.5.10)
= 10πa3
Z π/2
0
cos2(θ) sin(θ) dθ = −10πa3
3
cos3(θ)

π/2
0
= 10πa3
3
.
(4.5.11)
⊓⊔
Although these techniques apply for simple geometries such as a cylinder or sphere, we
would like a general method for treating any arbitrary surface. We begin by noting that
a surface is an aggregate of points whose coordinates are functions of two variables. For
example, in the previous example, the surface was described by the coordinates ϕ and θ.
Let us denote these surface coordinates in general by u and v. Consequently, on any surface
we can reexpress x, y, and z in terms of u and v: x = x(u, v), y = y(u, v), and z = z(u, v).
Next, we must ﬁnd an inﬁnitesimal element of area. The position vector to the surface
is r = x(u, v)i + y(u, v)j + z(u, v)k. Therefore, the tangent vectors along v = constant, ru,
and along u = constant, rv, equal
ru = xui + yuj + zuk,
(4.5.12)
and
rv = xvi + yvj + zvk.
(4.5.13)
Consequently, the sides of the inﬁnitesimal area are ru du and rv dv. Therefore, the vectorial
area of the parallelogram that these vectors form is
n dσ = ru × rv du dv
(4.5.14)

166
Advanced Engineering Mathematics with MATLAB
z
x
y
n
(2,0,0)
(0,3,0)
(0,0,6)
Figure 4.5.4: Diagram for the surface integration in Example 4.5.4.
and is called the vector element of area on the surface. Thus, we may convert F · n dσ into
an expression involving only u and v and then evaluate the surface integral by integrating
over the appropriate domain in the uv-plane. Of course, we are in trouble if ru × rv = 0.
Therefore, we only treat regular points where ru × rv ̸= 0. In the next few examples, we
show how to use these surface coordinates to evaluate surface integrals.
• Example 4.5.4
Let us ﬁnd the ﬂux of the vector ﬁeld F = xi + yj + zk through the top of the plane
3x + 2y + z = 6, which lies in the ﬁrst octant. See Figure 4.5.4.
Our parametric equations are x = u, y = v, and z = 6 −3u −2v. Therefore,
r = ui + vj + (6 −3u −2v)k,
(4.5.15)
so that
ru = i −3k,
rv = j −2k,
(4.5.16)
and
ru × rv = 3i + 2j + k.
(4.5.17)
Bring all of these elements together,
ZZ
S
F · n dσ =
Z 2
0
Z 3−3u/2
0
(3u + 2v + 6 −3u −2v) dv du = 6
Z 2
0
Z 3−3u/2
0
dv du (4.5.18)
= 6
Z 2
0
(3 −3u/2) du = 6
 3u −3
4u22
0 = 18.
(4.5.19)
To set up the limits of integration, we note that the area in u, v space corresponds to the
xy-plane. On the xy-plane, z = 0 and 3u + 2v = 6, along with boundaries u = v = 0.
⊓⊔
• Example 4.5.5
Let us ﬁnd the ﬂux of the vector ﬁeld F = xi + yj + zk through the top of the surface
z = xy + 1, which covers the square 0 ≤x ≤1, 0 ≤y ≤1 in the xy-plane. See Figure 4.5.5.
Our parametric equations are x = u, y = v, and z = uv + 1 with 0 ≤u ≤1 and
0 ≤v ≤1. Therefore,
r = ui + vj + (uv + 1)k,
(4.5.20)

Vector Calculus
167
                                                                







n
                        

                                                





x
y
z
Figure 4.5.5: Diagram for the surface integration in Example 4.5.5.
so that
ru = i + vk,
rv = j + uk,
(4.5.21)
and
ru × rv = −vi −uj + k.
(4.5.22)
Bring all of these elements together,
ZZ
S
F · n dσ =
Z 1
0
Z 1
0
[ui + vj + (uv + 1)k] · (−vi −uj + k) du dv
(4.5.23)
=
Z 1
0
Z 1
0
(1 −uv) du dv =
Z 1
0
 u −1
2u2v
1
0 dv
(4.5.24)
=
Z 1
0
 1 −1
2v

dv =
 v −1
4v21
0 = 3
4.
(4.5.25)
⊓⊔
• Example 4.5.6
Let us ﬁnd the ﬂux of the vector ﬁeld F = 4xzi + xyz2j + 3zk through the exterior
surface of the cone z2 = x2 + y2 above the xy-plane and below z = 4. See Figure 4.5.6.
A natural choice for the surface coordinates is polar coordinates r and θ. Because
x = r cos(θ) and y = r sin(θ), z = r. Then,
r = r cos(θ)i + r sin(θ)j + rk
(4.5.26)
with 0 ≤r ≤4 and 0 ≤θ ≤2π so that
rr = cos(θ)i + sin(θ)j + krθ = −r sin(θ)i + r cos(θ)j,
(4.5.27)
and
rr × rθ = −r cos(θ)i −r sin(θ)j + rk.
(4.5.28)

168
Advanced Engineering Mathematics with MATLAB
x
y
z
n
Figure 4.5.6: Diagram for the surface integration in Example 4.5.6.
This is the unit area inside the cone. Because we want the exterior surface, we must take
the negative of Equation 4.5.28. Bring all of these elements together,
ZZ
S
F · n dσ =
Z 4
0
Z 2π
0

[4r cos(θ)]r[r cos(θ)]
+ [r2 sin(θ) cos(θ)]r2[r sin(θ)] −3r2	
dθ dr
(4.5.29)
=
Z 4
0

2r3
θ + 1
2 sin(2θ)
2π
0 + r5 1
3 sin3(θ)
2π
0 −3r2θ
2π
0

dr (4.5.30)
=
Z 4
0
 4πr3 −6πr2
dr =
 πr4 −2πr34
0 = 128π.
(4.5.31)
Problems
Compute the surface integral
RR
S F · n dσ for the following vector ﬁelds and surfaces:
1. F = xi −zj + yk and the surface is the top side of the z = 1 plane where 0 ≤x ≤1 and
0 ≤y ≤1.
2. F = xi + yj + xzk and the surface is the top side of the cylinder x2 + y2 = 9, z = 0, and
z = 1.
3. F = xyi + zj + xzk and the surface consists of both exterior ends of the cylinder deﬁned
by x2 + y2 = 4, z = 0, and z = 2.
4. F = xi + zj + yk and the surface is the lateral and exterior sides of the cylinder deﬁned
by x2 + y2 = 4, z = −3, and z = 3.
5. F = xyi + z2j + yk and the surface is the curved exterior side of the cylinder y2 + z2 = 9
in the ﬁrst octant bounded by x = 0, x = 1, y = 0, and z = 0.
6. F = yj + z2k and the surface is the exterior of the semicircular cylinder y2 + z2 = 4,
z ≥0, cut by the planes x = 0 and x = 1.
7. F = zi + xj + yk and the surface is the curved exterior side of the cylinder x2 + y2 = 4
in the ﬁrst octant cut by the planes z = 1 and z = 2.

Vector Calculus
169
8.
F = x2i −z2j + yzk and the surface is the exterior of the hemispheric surface of
x2 + y2 + z2 = 16 above the plane z = 2.
9. F = yi + xj + yk and the surface is the top of the surface z = x + 1, where −1 ≤x ≤1
and −1 ≤y ≤1.
10. F = zi + xj −3zk and the surface is the top side of the plane x + y + z = 2a that lies
above the square 0 ≤x ≤a, 0 ≤y ≤a in the xy-plane.
11. F = (y2 + z2)i + (x2 + z2)j + (x2 + y2)k and the surface is the top side of the surface
z = 1 −x2 with −1 ≤x ≤1 and −2 ≤y ≤2.
12. F = y2i+xzj−k and the surface is the cone z =
p
x2 + y2, 0 ≤z ≤1, with the normal
pointing away from the z-axis.
13. F = y2i + x2j + 5zk and the surface is the top side of the plane z = y + 1, where
−1 ≤x ≤1 and −1 ≤y ≤1.
14. F = −yi + xj + zk and the surface is the exterior or bottom side of the paraboloid
z = x2 + y2, where 0 ≤z ≤1.
15. F = −yi + xj + 6z2k and the surface is the exterior of the paraboloids z = 4 −x2 −y2
and z = x2 + y2.
4.6 GREEN’S LEMMA
Consider a rectangle in the xy-plane that is bounded by the lines x = a, x = b,
y = c, and y = d. We assume that the boundary of the rectangle is a piece-wise smooth
curve that we denote by C. If we have a continuously diﬀerentiable vector function F =
P(x, y)i + Q(x, y)j at each point of enclosed region R, then
ZZ
R
∂Q
∂x dA =
Z d
c
"Z b
a
∂Q
∂x dx
#
dy =
Z d
c
Q(b, y) dy −
Z d
c
Q(a, y) dy =
I
C
Q(x, y) dy,
(4.6.1)
where the last integral is a closed line integral counterclockwise around the rectangle because
the horizontal sides vanish, since dy = 0. By similar arguments,
ZZ
R
∂P
∂y dA = −
I
C
P(x, y) dx
(4.6.2)
so that
ZZ
R
∂Q
∂x −∂P
∂y

dA =
I
C
P(x, y) dx + Q(x, y) dy.
(4.6.3)
This result, often known as Green’s lemma, may be expressed in vector form as
I
C
F · dr =
ZZ
R
∇× F · k dA.
(4.6.4)

170
Advanced Engineering Mathematics with MATLAB
(1,1)
x
y
(0,0)
Figure 4.6.1: Diagram for the veriﬁcation of Green’s lemma in Example 4.6.1.
Although this proof was for a rectangular area, it can be generalized to any simply
closed region on the xy-plane as follows. Consider an area that is surrounded by simply
closed curves. Within the closed contour we can divide the area into an inﬁnite number of
inﬁnitesimally small rectangles and apply Equation 4.6.4 to each rectangle. When we sum
up all of these rectangles, we ﬁnd
RR
R ∇× F · k dA, where the integration is over the entire
surface area. On the other hand, away from the boundary, the line integral along any one
edge of a rectangle cancels the line integral along the same edge in a contiguous rectangle.
Thus, the only nonvanishing contribution from the line integrals arises from the outside
boundary of the domain
H
C F · dr.
• Example 4.6.1
Let us verify Green’s lemma using the vector ﬁeld F = (3x2 −8y2)i + (4y −6xy)j, and
the enclosed area lies between the curves y = √x and y = x2. The two curves intersect at
x = 0 and x = 1. See Figure 4.6.1.
We begin with the line integral:
I
C
F · dr =
Z 1
0
(3x2 −8x4) dx + (4x2 −6x3)(2x dx)
+
Z 0
1
(3x2 −8x) dx + (4x1/2 −6x3/2)( 1
2x−1/2 dx)
(4.6.5)
=
Z 1
0
(−20x4 + 8x3 + 11x −2) dx = 3
2.
(4.6.6)
In Equation 4.6.6 we used y = x2 in the ﬁrst integral and y = √x in our return integration.
For the areal integration,
Z Z
R
∇× F · k dA =
Z 1
0
Z √x
x2
10y dy dx =
Z 1
0
5y2
√x
x2 dx = 5
Z 1
0
(x −x4) dx = 3
2
(4.6.7)
and Green’s lemma is veriﬁed in this particular case.
⊓⊔

Vector Calculus
171
x
y
Figure 4.6.2: Diagram for the veriﬁcation of Green’s lemma in Example 4.6.3.
• Example 4.6.2
Let us redo Example 4.6.1 except that the closed contour is the triangular region deﬁned
by the lines x = 0, y = 0, and x + y = 1.
The line integral is
I
C
F · dr =
Z 1
0
(3x2 −8 · 02)dx + (4 · 0 −6x · 0) · 0
+
Z 1
0
[3(1 −y)2 −8y2](−dy) + [4y −6(1 −y)y] dy
+
Z 0
1
(3 · 02 −8y2) · 0 + (4y −6 · 0 · y) dy
(4.6.8)
=
Z 1
0
3x2 dx −
Z 1
0
4y dy +
Z 1
0
(−3 + 4y + 11y2) dy
(4.6.9)
= x31
0 −2y21
0 +
 −3y + 2y2 + 11
3 y31
0 = 5
3.
(4.6.10)
On the other hand, the areal integration is
Z Z
R
∇× F · k dA =
Z 1
0
Z 1−x
0
10y dy dx =
Z 1
0
5y21−x
0
dx
(4.6.11)
= 5
Z 1
0
(1 −x)2 dx = −5
3(1 −x)31
0 = 5
3
(4.6.12)
and Green’s lemma is veriﬁed in this particular case.
⊓⊔
• Example 4.6.3
Let us verify Green’s lemma using the vector ﬁeld F = (3x + 4y)i + (2x −3y)j, and the
closed contour is a circle of radius two centered at the origin of the xy-plane. See Figure
4.6.2.

172
Advanced Engineering Mathematics with MATLAB
Beginning with the line integration,
I
C
F · dr =
Z 2π
0
[6 cos(θ) + 8 sin(θ)][−2 sin(θ) dθ] + [4 cos(θ) −6 sin(θ)][2 cos(θ) dθ]
(4.6.13)
=
Z 2π
0
[−24 cos(θ) sin(θ) −16 sin2(θ) + 8 cos2(θ)] dθ
(4.6.14)
= 12 cos2(θ)
2π
0 −8

θ −1
2 sin(2θ)
2π
0 + 4

θ + 1
2 sin(2θ)
2π
0
= −8π. (4.6.15)
For the areal integration,
Z Z
R
∇× F · k dA =
Z 2
0
Z 2π
0
−2 r dθ dr = −8π
(4.6.16)
and Green’s lemma is veriﬁed in the special case.
Problems
Verify Green’s lemma for the following two-dimensional vector ﬁelds and contours:
1. F = (x2 + 4y)i + (y −x)j and the contour is the square bounded by the lines x = 0,
y = 0, x = 1, and y = 1.
2. F = (x −y)i + xyj and the contour is the square bounded by the lines x = 0, y = 0,
x = 1, and y = 1.
3. F = −y2i + x2j and the contour is the triangle bounded by the lines x = 1, y = 0, and
y = x.
4. F = (xy −x2)i + x2yj and the contour is the triangle bounded by the lines y = 0, x = 1,
and y = x.
5. F = sin(y)i + x cos(y)j and the contour is the triangle bounded by the lines x + y = 1,
y −x = 1, and y = 0.
6. F = y2i + x2j and the contour is the same contour used in Problem 4.
7. F = −y2i + x2j and the contour is the circle x2 + y2 = 4.
8. F = −x2i + xy2j and the contour is the closed circle of radius a.
9. F = (6y + x)i + (y + 2x)j and the contour is the circle (x −1)2 + (y −2)2 = 4.
10. F = (x + y)i + (2x2 −y2)j and the contour is the boundary of the region determined
by the curves y = x2 and y = 4.
11. F = 3yi + 2xj and the contour is the boundary of the region determined by the curves
y = 0 and y = sin(x) with 0 ≤x ≤π.

Vector Calculus
173
12. F = −16yi + (4ey + 3x2)j and the contour is the pie wedge deﬁned by the lines y = x,
y = −x, x2 + y2 = 4, and y > 0.
4.7 STOKES’ THEOREM4
In Section 4.2 we introduced the vector quantity ∇× v, which gives a measure of the
rotation of a parcel of ﬂuid lying within the velocity ﬁeld v. In this section we show how
the curl can be used to simplify the calculation of certain closed line integrals.
This relationship between a closed line integral and a surface integral involving the curl
is
Stokes’ Theorem: The circulation of F = Pi + Qj + Rk around the closed boundary C
of an oriented surface S in the direction counterclockwise with respect to the surface’s unit
normal vector n equals the integral of ∇× F · n over S, or
I
C
F · dr =
Z Z
S
∇× F · n dσ.
(4.7.1)
Stokes’ theorem requires that all of the functions and derivatives be continuous.
The proof of Stokes’ theorem is as follows: Consider a ﬁnite surface S whose boundary
is the loop C. We divide this surface into a number of small elements n dσ and compute
the circulation dΓ =
H
L F · dr around each element. When we add all of the circulations
together, the contribution from an integration along a boundary line between two adjoining
elements cancels out because the boundary is transversed once in each direction. For this
reason, the only contributions that survive are those parts where the element boundaries
form part of C. Thus, the sum of all circulations equals
H
C F · dr, the circulation around
the edge of the whole surface.
Next, let us compute the circulation another way. We begin by ﬁnding the Taylor
expansion for P(x, y, z) about the arbitrary point (x0, y0, z0):
P(x, y, z) = P(x0, y0, z0) + (x −x0)∂P(x0, y0, z0)
∂x
+ (y −y0)∂P(x0, y0, z0)
∂y
+ (z −z0)∂P(x0, y0, z0)
∂z
+ · · ·
(4.7.2)
with similar expansions for Q(x, y, z) and R(x, y, z). Then
dΓ =
I
L
F · dr = P(x0, y0, z0)
I
L
dx + ∂P(x0, y0, z0)
∂x
I
L
(x −x0) dx
(4.7.3)
+ ∂P(x0, y0, z0)
∂y
I
L
(y −y0) dy + · · · + ∂Q(x0, y0, z0)
∂x
I
L
(x −x0) dy + · · · ,
where L denotes some small loop located in the surface S. Note that integrals such as
H
L dx
and
H
L(x −x0) dx vanish.
4 For the history behind the development of Stokes’ theorem, see Katz, V. J., 1979: The history of
Stokes’ theorem. Math. Mag., 52, 146–156.

174
Advanced Engineering Mathematics with MATLAB
Sir George Gabriel Stokes (1819–1903) was Lucasian Professor of Mathematics at Cambridge Uni-
versity from 1849 until his death. Having learned of an integral theorem from his friend Lord Kelvin,
Stokes included it a few years later among his questions on an examination that he wrote for the
Smith Prize. It is this integral theorem that we now call Stokes’ theorem. (Portrait courtesy of the
Royal Society of London.)
If we now require that the loop integrals be in the clockwise or positive sense so that
we preserve the right-hand screw convention, then
n · k δσ =
I
L
(x −x0) dy = −
I
L
(y −y0) dx,
(4.7.4)
n · j δσ =
I
L
(z −z0) dx = −
I
L
(x −x0) dz,
(4.7.5)
n · i δσ =
I
L
(y −y0) dz = −
I
L
(z −z0) dy,
(4.7.6)
and
dΓ =
∂R
∂y −∂Q
∂z

i · n δσ +
∂P
∂z −∂R
∂x

j · n δσ +
∂Q
∂x −∂P
∂y

k · n δσ = ∇× F · n δσ.
(4.7.7)
Therefore, the sum of all circulations in the limit when all elements are made inﬁnitesimally
small becomes the surface integral
RR
S ∇× F · n dσ and Stokes’ theorem is proven.
⊓⊔
In the following examples we ﬁrst apply Stokes’ theorem to a few simple geometries.
We then show how to apply this theorem to more complicated surfaces.5
5 Thus, diﬀerent Stokes for diﬀerent folks.

Vector Calculus
175
x
y
z
(1,0,3)
k
(1,1,3)
(0,1,3)
(0,0,3)
C
C
C
C1
2
3
4
Figure 4.7.1: Diagram for the veriﬁcation of Stokes’ theorem in Example 4.7.1.
• Example 4.7.1
Let us verify Stokes’ theorem using the vector ﬁeld F = x2i+2xj+z2k, and the closed
curve is a square with vertices at (0, 0, 3), (1, 0, 3), (1, 1, 3), and (0, 1, 3). See Figure 4.7.1.
We begin with the line integral:
I
C
F · dr =
Z
C1
F · dr +
Z
C2
F · dr +
Z
C3
F · dr +
Z
C4
F · dr,
(4.7.8)
where C1, C2, C3, and C4 represent the four sides of the square. Along C1, x varies while
y = 0 and z = 3. Therefore,
Z
C1
F · dr =
Z 1
0
x2 dx + 2x · 0 + 9 · 0 = 1
3,
(4.7.9)
because dy = dz = 0, and z = 3. Along C2, y varies with x = 1 and z = 3. Therefore,
Z
C2
F · dr =
Z 1
0
12 · 0 + 2 · 1 · dy + 9 · 0 = 2.
(4.7.10)
Along C3, x again varies with y = 1 and z = 3, and so,
Z
C3
F · dr =
Z 0
1
x2 dx + 2x · 0 + 9 · 0 = −1
3.
(4.7.11)
Note how the limits run from 1 to 0 because x is decreasing. Finally, for C4, y again varies
with x = 0 and z = 3. Hence,
Z
C4
F · dr =
Z 0
1
02 · 0 + 2 · 0 · dy + 9 · 0 = 0.
(4.7.12)
Hence,
I
C
F · dr = 2.
(4.7.13)

176
Advanced Engineering Mathematics with MATLAB
  
x
y
k
z
(0,0,1)
(0,a,1)
(a,0,1)
C3
C 2
1
C
Figure 4.7.2: Diagram for the veriﬁcation of Stokes’ theorem in Example 4.7.2.
Turning to the other side of the equation,
∇× F =

i
j
k
∂
∂x
∂
∂y
∂
∂z
x2
2x
z2

= 2k.
(4.7.14)
Our line integral has been such that the normal vector must be n = k. Therefore,
Z Z
S
∇× F · n dσ =
Z 1
0
Z 1
0
2k · k dx dy = 2
(4.7.15)
and Stokes’ theorem is veriﬁed for this special case.
⊓⊔
• Example 4.7.2
Let us verify Stokes’ theorem using the vector ﬁeld F = (x2 −y)i + 4zj + x2k, where
the closed contour consists of the x and y coordinate axes and that portion of the circle
x2 + y2 = a2 that lies in the ﬁrst quadrant with z = 1. See Figure 4.7.2.
The line integral consists of three parts:
I
C
F · dr =
Z
C1
F · dr +
Z
C2
F · dr +
Z
C3
F · dr.
(4.7.16)
Along C1, x varies while y = 0 and z = 1. Therefore,
Z
C1
F · dr =
Z a
0
(x2 −0) dx + 4 · 1 · 0 + x2 · 0 = a3
3 .
(4.7.17)
Along the circle C2, we use polar coordinates with x = a cos(t), y = a sin(t), and z = 1.
Therefore,
Z
C2
F · dr =
Z π/2
0
[a2 cos2(t) −a sin(t)][−a sin(t) dt] + 4 · 1 · a cos(t) dt + a2 cos2(t) · 0,
(4.7.18)
=
Z π/2
0
−a3 cos2(t) sin(t) dt + a2 sin2(t) dt + 4a cos(t) dt
(4.7.19)
= a3
3 cos3(t)

π/2
0
+ a2
2

t −1
2 sin(2t)

π/2
0
+ 4a sin(t)

π/2
0
(4.7.20)
= −a3
3 + a2π
4
+ 4a,
(4.7.21)

Vector Calculus
177
x
y
z
3
n
(1,0,0)
(0,1,0)
(0,0,1)
C
C1
C 2
Figure 4.7.3: Diagram for the veriﬁcation of Stokes’ theorem in Example 4.7.3.
because dx = −a sin(t) dt, and dy = a cos(t) dt. Finally, along C3, y varies with x = 0 and
z = 1. Therefore,
Z
C3
F · dr =
Z 0
a
(02 −y) · 0 + 4 · 1 · dy + 02 · 0 = −4a,
(4.7.22)
so that
I
C
F · dr = a2π
4 .
(4.7.23)
Turning to the other side of the equation,
∇× F =

i
j
k
∂
∂x
∂
∂y
∂
∂z
x2 −y
4z
x2

= −4i −2xj + k.
(4.7.24)
From the path of our line integral, our unit normal vector must be n = k. Then,
Z Z
S
∇× F · n dσ =
Z a
0
Z π/2
0
[−4i −2r cos(θ)j + k] · k r dθ dr = πa2
4
(4.7.25)
and Stokes’ theorem is veriﬁed for this case.
⊓⊔
• Example 4.7.3
Let us verify Stokes’ theorem using the vector ﬁeld F = 2yzi−(x+3y −2)j+(x2 +z)k,
where the closed triangular region is that portion of the plane x + y + z = 1 that lies in the
ﬁrst octant.
As shown in Figure 4.7.3, the closed line integration consists of three line integrals:
I
C
F · dr =
Z
C1
F · dr +
Z
C2
F · dr +
Z
C3
F · dr.
(4.7.26)
Along C1, z = 0 and y = 1 −x. Therefore, using x as the independent variable,
Z
C1
F·dr =
Z 0
1
2(1−x)·0·dx−(x+3−3x−2)(−dx)+(x2+0)·0 = −x20
1+ x|0
1 = 0. (4.7.27)

178
Advanced Engineering Mathematics with MATLAB
Along C2, x = 0 and y = 1 −z. Thus,
Z
C2
F · dr =
Z 1
0
2(1 −z)z · 0 −(0 + 3 −3z −2)(−dz) + (02 + z) dz = −3
2z2 + z + 1
2z21
0 = 0.
(4.7.28)
Finally, along C3, y = 0 and z = 1 −x. Hence,
Z
C3
F·dr =
Z 1
0
2·0·(1−x) dx−(x+0−2)·0+(x2+1−x)(−dx) = −1
3x3 −x + 1
2x21
0 = −5
6.
(4.7.29)
Thus,
I
C
F · dr = −5
6.
(4.7.30)
On the other hand,
∇× F =

i
j
k
∂
∂x
∂
∂y
∂
∂z
2yz
−x −3y + 2
x2 + z

= (−2x + 2y)j + (−1 −2z)k.
(4.7.31)
To ﬁnd n dσ, we use the general coordinate system x = u, y = v, and z = 1 −u −v.
Therefore, r = ui + vj + (1 −u −v)k and
ru × rv =

i
j
k
1
0
−1
0
1
−1

= i + j + k.
(4.7.32)
Thus,
Z Z
S
∇× F · n dσ =
Z 1
0
Z 1−u
0
[(−2u + 2v)j + (−1 −2 + 2u + 2v)k] · [i + j + k] dv du
(4.7.33)
=
Z 1
0
Z 1−u
0
(4v −3) dv du =
Z 1
0
[2(1 −u)2 −3(1 −u)] du
(4.7.34)
=
Z 1
0
(−1 −u + 2u2) du = −5
6
(4.7.35)
and Stokes’ theorem is veriﬁed for this case.
Problems
Verify Stokes’ theorem using the following vector ﬁelds and surfaces:
1. F = 5yi −5xj + 3zk and the surface S is that portion of the plane z = 1 with the square
at the vertices (0, 0, 1), (1, 0, 1), (1, 1, 1), and (0, 1, 1).
2. F = x2i + y2j + z2k and the surface S is the rectangular portion of the plane z = 2
deﬁned by the corners (0, 0, 2), (2, 0, 2), (2, 1, 2), and (0, 1, 2).
3. F = zi + xj + yk and the surface S is the triangular portion of the plane z = 1 deﬁned
by the vertices (0, 0, 1), (2, 0, 1), and (0, 2, 1).

Vector Calculus
179
4. F = 2zi −3xj + 4yk and the surface S is that portion of the plane z = 5 within the
cylinder x2 + y2 = 4.
5. F = zi + xj + yk and the surface S is that portion of the plane z = 3 bounded by the
lines y = 0, x = 0, and x2 + y2 = 4.
6. F = (2z + x)i + (y −z)j + (x + y)k and the surface S is the interior of the triangularly
shaped plane with vertices at (1, 0, 0), (0, 1, 0), and (0, 0, 1).
7. F = zi + xj + yk and the surface S is that portion of the plane 2x + y + 2z = 6 in the
ﬁrst octant.
8. F = xi + xzj + yk and the surface S is that portion of the paraboloid z = 9 −x2 −y2
within the cylinder x2 + y2 = 4.
4.8 DIVERGENCE THEOREM
Although Stokes’ theorem is useful in computing closed line integrals, it is usually very
diﬃcult to go the other way and convert a surface integral into a closed line integral because
the integrand must have a very special form, namely ∇× F · n. In this section we introduce
a theorem that allows with equal facility the conversion of a closed surface integral into a
volume integral and vice versa. Furthermore, if we can convert a given surface integral into
a closed one by the introduction of a simple surface (for example, closing a hemispheric
surface by adding an equatorial plate), it may be easier to use the divergence theorem
and subtract oﬀthe contribution from the new surface integral rather than do the original
problem.
This relationship between a closed surface integral and a volume integral involving the
divergence operator is
The Divergence or Gauss’s Theorem: Let V be a closed and bounded region in three-
dimensional space with a piece-wise smooth boundary S that is oriented outward.
Let
F = P(x, y, z)i + Q(x, y, z)j + R(x, y, z)k be a vector ﬁeld for which P, Q, and R are
continuous and have continuous ﬁrst partial derivatives in a region of three-dimensional
space containing V . Then
ZZ
S
⊂⊃F · n dσ =
ZZZ
V
∇· F dV.
(4.8.1)
Here, the circle on the double integral signs denotes a closed surface integral.
A nonrigorous proof of Gauss’s theorem is as follows. Imagine that our volume V is
broken down into small elements dτ of volume of any shape so long as they include all of
the original volume. In general, the surfaces of these elements are composed of common
interfaces between adjoining elements. However, for the elements at the periphery of V ,
part of their surface will be part of the surface S that encloses V . Now dΦ = ∇· F dτ is
the net ﬂux of the vector F out from the element dτ. At the common interface between
elements, the ﬂux out of one element equals the ﬂux into its neighbor. Therefore, the sum
of all such terms yields
Φ =
ZZZ
V
∇· F dτ
(4.8.2)

180
Advanced Engineering Mathematics with MATLAB
Carl Friedrich Gauss (1777–1855), the prince of mathematicians, must be on the list of the greatest
mathematicians who ever lived. Gauss, a child prodigy, is almost as well known for what he did not
publish during his lifetime as for what he did. This is true of Gauss’s divergence theorem, which he
proved while working on the theory of gravitation. It was only when his notebooks were published
in 1898 that his precedence over the published work of Ostrogradsky (1801–1862) was established.
(Portrait courtesy of Photo AKG, London, with permission.)
and all of the contributions from these common interfaces cancel; only the contribution
from the parts on the outer surface S is left. These contributions, when added together,
give
RR
S
⊂⊃F · n dσ over S and the proof is completed.
⊓⊔
• Example 4.8.1
Let us verify the divergence theorem using the vector ﬁeld F = 4xi −2y2j + z2k and
the enclosed surface is the cylinder x2 + y2 = 4, z = 0, and z = 3. See Figure 4.8.1.
We begin by computing the volume integration. Because
∇· F = ∂(4x)
∂x
+ ∂(−2y2)
∂y
+ ∂(z2)
∂z
= 4 −4y + 2z,
(4.8.3)
ZZZ
V
∇· F dV =
ZZZ
V
(4 −4y + 2z) dV
(4.8.4)
=
Z 3
0
Z 2
0
Z 2π
0
[4 −4r sin(θ) + 2z] dθ r dr dz
(4.8.5)
=
Z 3
0
Z 2
0

4θ
2π
0 + 4r cos(θ)
2π
0 + 2zθ
2π
0

r dr dz
(4.8.6)
=
Z 3
0
Z 2
0
(8π + 4πz) r dr dz =
Z 3
0
4π(2 + z) 1
2r22
0 dz
(4.8.7)
= 4π
Z 3
0
2(2 + z) dz = 8π(2z + 1
2z2)
3
0 = 84π.
(4.8.8)

Vector Calculus
181
2
z
y
x
S1
S
k
-k
n
3
S
Figure 4.8.1: Diagram for the veriﬁcation of the divergence theorem in Example 4.8.1.
Turning to the surface integration, we have three surfaces:
ZZ
S
⊂⊃F · n dσ =
ZZ
S1
F · n dσ +
ZZ
S2
F · n dσ +
ZZ
S3
F · n dσ.
(4.8.9)
The ﬁrst integral is over the exterior to the cylinder. Because the surface is deﬁned by
f(x, y, z) = x2 + y2 = 4,
n = ∇f
|∇f| =
2xi + 2yj
p
4x2 + 4y2 = x
2 i + y
2j.
(4.8.10)
Therefore,
ZZ
S1
F · n dσ =
ZZ
S1
(2x2 −y3) dσ =
Z 3
0
Z 2π
0

2[2 cos(θ)]2 −[2 sin(θ)]3	
2 dθ dz
(4.8.11)
= 8
Z 3
0
Z 2π
0

1
2[1 + cos(2θ)] −sin(θ) + cos2(θ) sin(θ)

2 dθ dz
(4.8.12)
= 16
Z 3
0

1
2θ + 1
4 sin(2θ) + cos(θ) −1
3 cos3(θ)

2π
0
dz
(4.8.13)
= 16π
Z 3
0
dz = 48π,
(4.8.14)
because x = 2 cos(θ), y = 2 sin(θ), and dσ = 2 dθ dz in cylindrical coordinates.
Along the top of the cylinder, z = 3, the outward pointing normal is n = k, and
dσ = r dr dθ. Then,
ZZ
S2
F · n dσ =
ZZ
S2
z2 dσ =
Z 2π
0
Z 2
0
9 r dr dθ = 2π × 9 × 2 = 36π.
(4.8.15)
However, along the bottom of the cylinder, z = 0, the outward pointing normal is n = −k
and dσ = r dr dθ. Then,
ZZ
S3
F · n dσ =
ZZ
S3
z2 dσ =
Z 2π
0
Z 2
0
0 r dr dθ = 0.
(4.8.16)

182
Advanced Engineering Mathematics with MATLAB
Consequently, the ﬂux out of the entire cylinder is
ZZ
S
⊂⊃F · n dσ = 48π + 36π + 0 = 84π,
(4.8.17)
and the divergence theorem is veriﬁed for this special case.
⊓⊔
• Example 4.8.2
Let us verify the divergence theorem given the vector ﬁeld F = 3x2y2i + yj −6xy2zk
and the volume is the region bounded by the paraboloid z = x2 + y2, and the plane z = 2y.
See Figure 4.8.2.
Computing the divergence,
∇· F = ∂(3x2y2)
∂x
+ ∂(y)
∂y + ∂(−6xy2z)
∂z
= 6xy2 + 1 −6xy2 = 1.
(4.8.18)
Then,
ZZZ
V
∇· F dV =
ZZZ
V
dV =
Z π
0
Z 2 sin(θ)
0
Z 2r sin(θ)
r2
dz r dr dθ
(4.8.19)
=
Z π
0
Z 2 sin(θ)
0
[2r sin(θ) −r2] r dr dθ
(4.8.20)
=
Z π
0

2
3r3

2 sin(θ)
0
sin(θ) −1
4r4

2 sin(θ)
0

dθ
(4.8.21)
=
Z π
0
 16
3 sin4(θ) −4 sin4(θ)

dθ =
Z π
0
4
3 sin4(θ) dθ
(4.8.22)
= 1
3
Z π
0
[1 −2 cos(2θ) + cos2(2θ)] dθ
(4.8.23)
= 1
3

θ

π
0
−sin(2θ)

π
0
+ 1
2θ

π
0
+ 1
8 sin(4θ)

π
0

= π
2 .
(4.8.24)
The limits in the radial direction are given by the intersection of the paraboloid and plane:
r2 = 2r sin(θ), or r = 2 sin(θ), and y is greater than zero.
Turning to the surface integration, we have two surfaces:
ZZ
S
⊂⊃F · n dσ =
ZZ
S1
F · n dσ +
ZZ
S2
F · n dσ,
(4.8.25)
where S1 is the plane z = 2y, and S2 is the paraboloid. For either surface, polar coordinates
are best so that x = r cos(θ), and y = r sin(θ). For the integration over the plane, z =
2r sin(θ). Therefore,
r = r cos(θ)i + r sin(θ)j + 2r sin(θ)k,
(4.8.26)
so that
rr = cos(θ)i + sin(θ)j + 2 sin(θ)k,
(4.8.27)
and
rθ = −r sin(θ)i + r cos(θ)j + 2r cos(θ)k.
(4.8.28)

Vector Calculus
183
y
z
n2
n1
x
Figure 4.8.2: Diagram for the veriﬁcation of the divergence theorem in Example 4.8.2. The dashed line
denotes the curve r = 2 sin(θ).
Then,
rr × rθ =

i
j
k
cos(θ)
sin(θ)
2 sin(θ)
−r sin(θ)
r cos(θ)
2r cos(θ)

= −2rj + rk.
(4.8.29)
This is an outwardly pointing normal so that we can immediately set up the surface integral:
ZZ
S1
F · n dσ =
Z π
0
Z 2 sin(θ)
0

3r4 cos2(θ) sin2(θ)i + r sin(θ)j
−6[2r sin(θ)][r cos(θ)][r2 sin2(θ)]k
	
·
 −2rj + rk

dr dθ
(4.8.30)
=
Z π
0
Z 2 sin(θ)
0

−2r2 sin(θ) −12r5 sin3(θ) cos(θ)

dr dθ
(4.8.31)
=
Z π
0

−2
3r32 sin(θ)
0
sin(θ) −2r62 sin(θ)
0
sin3(θ) cos(θ)

dθ
(4.8.32)
=
Z π
0

−16
3 sin4(θ) −128 sin9(θ) cos(θ)

dθ
(4.8.33)
= −4
3

θ
π
0 −sin(2θ)
π
0 + 1
2θ
π
0 + 1
8 sin(4θ)
π
0

−64
5 sin10(θ)
π
0
(4.8.34)
= −2π.
(4.8.35)
For the surface of the paraboloid,
r = r cos(θ)i + r sin(θ)j + r2k,
(4.8.36)
so that
rr = cos(θ)i + sin(θ)j + 2rk,
(4.8.37)
and
rθ = −r sin(θ)i + r cos(θ)j.
(4.8.38)

184
Advanced Engineering Mathematics with MATLAB
Then,
rr × rθ =

i
j
k
cos(θ)
sin(θ)
2r
−r sin(θ)
r cos(θ)
0

= −2r2 cos(θ)i −2r2 sin(θ)j + rk.
(4.8.39)
This is an inwardly pointing normal, so that we must take the negative of it before we do
the surface integral. Then,
ZZ
S2
F · n dσ =
Z π
0
Z 2 sin(θ)
0

3r4 cos2(θ) sin2(θ)i + r sin(θ)j −6r2[r cos(θ)][r2 sin2(θ)]k
	
·

2r2 cos(θ)i + 2r2 sin(θ)j −rk

dr dθ
(4.8.40)
=
Z π
0
Z 2 sin(θ)
0

6r6 cos3(θ) sin2(θ) + 2r3 sin2(θ) + 6r6 cos(θ) sin2(θ)

dr dθ
(4.8.41)
=
Z π
0

6
7r72 sin(θ)
0
cos3(θ) sin2(θ) + 1
2r42 sin(θ)
0
sin2(θ)
+ 6
7r72 sin(θ)
0
cos(θ) sin2(θ)

dθ
(4.8.42)
=
Z π
0

768
7 sin9(θ)[1 −sin2(θ)] cos(θ) + 8 sin6(θ) + 768
7 sin9(θ) cos(θ)

dθ
(4.8.43)
= 1536
70 sin10(θ)
π
0 −64
7 sin12(θ)
π
0 +
Z π
0
[1 −cos(2θ)]3 dθ
(4.8.44)
=
Z π
0

1 −3 cos(2θ) + 3 cos2(2θ) −cos(2θ)[1 −sin2(2θ)]

dθ
(4.8.45)
= θ
π
0 −3
2 sin(2θ)
π
0 + 3
2[θ + 1
4 sin(4θ)]
π
0 −1
2 sin(2θ)
π
0 + 1
3 sin3(2θ)
π
0
(4.8.46)
= π + 3
2π = 5
2π.
(4.8.47)
Consequently,
ZZ
S
⊂⊃F · n dσ = −2π + 5
2π = 1
2π,
(4.8.48)
and the divergence theorem is veriﬁed for this special case.
⊓⊔
• Example 4.8.3: Archimedes’ principle
Consider a solid6 of volume V and surface S that is immersed in a vessel ﬁlled with a
ﬂuid of density ρ. The pressure ﬁeld p in the ﬂuid is a function of the distance from the
liquid/air interface and equals
p = p0 −ρgz,
(4.8.49)
6 Adapted from Altintas, A., 1990: Archimedes’ principle as an application of the divergence theorem.
IEEE Trans. Educ., 33, 222.

Vector Calculus
185
where g is the gravitational acceleration, z is the vertical distance measured from the in-
terface (increasing in the k direction), and p0 is the constant pressure along the liquid/air
interface.
If we deﬁne F = −pk, then F·n dσ is the vertical component of the force on the surface
due to the pressure and
RR
S
⊂⊃F · n dσ is the total lift. Using the divergence theorem and
noting that ∇· F = ρg, the total lift also equals
ZZZ
V
∇· F dV = ρg
ZZZ
V
dV = ρgV,
(4.8.50)
which is the weight of the displaced liquid. This is Archimedes’ principle: The buoyant force
on a solid immersed in a ﬂuid of constant density equals the weight of the ﬂuid displaced.
⊓⊔
• Example 4.8.4: Conservation of charge
Let a charge of density ρ ﬂow with an average velocity v. Then the charge crossing the
element dS per unit time is ρv · dS = J · dS, where J is deﬁned as the conduction current
vector or current density vector. The current across any surface drawn in the medium is
RR
S
⊂⊃J · dS.
The total charge inside the closed surface is
RRR
V ρ dV . If there are no sources or sinks
inside the surface, the rate at which the charge decreases is −
RRR
V ρt dV . Because this
change is due to the outward ﬂow of charge,
−
ZZZ
V
∂ρ
∂t dV =
ZZ
S
⊂⊃J · dS.
(4.8.51)
Applying the divergence theorem,
ZZZ
V
∂ρ
∂t + ∇· J

dV = 0.
(4.8.52)
Because the result holds true for any arbitrary volume, the integrand must vanish identically
and we have the equation of continuity or the equation of conservation of charge:
∂ρ
∂t + ∇· J = 0.
(4.8.53)
Problems
Verify the divergence theorem using the following vector ﬁelds and volumes:
1. F = x2i+y2j+z2k and the volume V is the cube cut from the ﬁrst octant by the planes
x = 1, y = 1, and z = 1.
2. F = xyi + yzj + xzk and the volume V is the cube bounded by 0 ≤x ≤1, 0 ≤y ≤1,
and 0 ≤z ≤1.
3. F = (y −x)i + (z −y)j + (y −x)k and the volume V is the cube bounded by −1 ≤x ≤1,
−1 ≤y ≤1, and −1 ≤z ≤1.

186
Advanced Engineering Mathematics with MATLAB
4. F = x2i + yj + zk and the volume V is the cylinder deﬁned by the surfaces x2 + y2 = 1,
z = 0, and z = 1.
5. F = x2i+y2j+z2k and the volume V is the cylinder deﬁned by the surfaces x2 +y2 = 4,
z = 0, and z = 1.
6. F = y2i + xz3j + (z −1)2k and the volume V is the cylinder bounded by the surface
x2 + y2 = 4, and the planes z = 1 and z = 5.
7. F = 6xyi+4yzj+xe−yk and the volume V is that region created by the plane x+y+z = 1,
and the three coordinate planes.
8. F = yi + xyj −zk and the volume V is that solid created by the paraboloid z = x2 + y2
and plane z = 1.
Further Readings
Davis, H. F., and A. D. Snider, 1995: Introduction to Vector Analysis. Wm. C. Brown
Publ., 416 pp. Designed as a reference book for engineering majors.
Kendall, P. C., and D. E. Bourne, 1992: Vector Analysis and Cartesian Tensors. Wm.
C. Brown, Publ., 304 pp. A clear introduction to the concepts and techniques of vector
analysis.
Matthews, P. C., 2005: Vector Calculus. Springer, 200 pp. A good book for self-study with
complete solutions to the problems.
Schey, H. M., 2005: Div, Grad, Curl, and All That. Chapman & Hall, 176 pp. A book to
hone your vector calculus skills.

Chapter 5
Fourier Series
Fourier series arose during the eighteenth century as a formal solution to the classic
wave equation. Later on, it was used to describe physical processes in which events re-
cur in a regular pattern. For example, a musical note usually consists of a simple note,
called the fundamental, and a series of auxiliary vibrations, called overtones. Fourier’s the-
orem provides the mathematical language that allows us to precisely describe this complex
structure.
5.1 FOURIER SERIES
One of the crowning glories1 of nineteenth-century mathematics was the discovery that
the inﬁnite series
f(t) = a0
2 +
∞
X
n=1
an cos
nπt
L

+ bn sin
nπt
L

(5.1.1)
can represent a function f(t) under certain general conditions. This series, called a Fourier
series, converges to the value of the function f(t) at every point in the interval [−L, L] with
the possible exceptions of the points at any discontinuities and the endpoints of the interval.
1 “Fourier’s Theorem . . . is not only one of the most beautiful results of modern analysis, but may be
said to furnish an indispensable instrument in the treatment of nearly every recondite question in modern
physics. To mention only sonorous vibrations, the propagation of electric signals along a telegraph wire,
and the conduction of heat by the earth’s crust, as subjects in their generality intractable without it, is to
give but a feeble idea of its importance.” (Quote taken from Thomson, W., and P. G. Tait, 1879: Treatise
on Natural Philosophy, Part 1. Cambridge University Press, Section 75.)
187

188
Advanced Engineering Mathematics with MATLAB
Because each term has a period of 2L, the sum of the series also has the same period. The
fundamental of the periodic function f(t) is the n = 1 term while the harmonics are the
remaining terms whose frequencies are integer multiples of the fundamental. We must now
ﬁnd some easy method for computing the coeﬃcients an and bn for a given function f(t).
As a ﬁrst attempt, we integrate Equation 5.1.1 term by term2 from −L to L. On the right
side, all of the integrals multiplied by an and bn vanish because the average of cos(nπt/L)
and sin(nπt/L) is zero. Therefore, we are left with
a0 = 1
L
Z L
−L
f(t) dt.
(5.1.2)
Consequently a0 is twice the mean value of f(t) over one period.
We next multiply each side of Equation 5.1.1 by cos(mπt/L), where m is a ﬁxed integer.
Integrating from −L to L,
Z L
−L
f(t) cos
mπt
L

dt = a0
2
Z L
−L
cos
mπt
L

dt +
∞
X
n=1
an
Z L
−L
cos
nπt
L

cos
mπt
L

dt
+
∞
X
n=1
bn
Z L
−L
sin
nπt
L

cos
mπt
L

dt.
(5.1.3)
The a0 and bn terms vanish by direct integration. Finally, all of the an integrals vanish
when n ̸= m. Consequently, Equation 5.1.3 simpliﬁes to
an = 1
L
Z L
−L
f(t) cos
nπt
L

dt,
(5.1.4)
because
R L
−L cos2(nπt/L) dt = L. Finally, by multiplying both sides of Equation 5.1.1 by
sin(mπt/L) (m is again a ﬁxed integer) and integrating from −L to L,
bn = 1
L
Z L
−L
f(t) sin
nπt
L

dt.
(5.1.5)
Although Equation 5.1.2, Equation 5.1.4, and Equation 5.1.5 give us a0, an, and bn for
periodic functions over the interval [−L, L], in certain situations it is convenient to use the
interval [τ, τ + 2L], where τ is any real number. In that case, Equation 5.1.1 still gives the
2 We assume that the integration of the series can be carried out term by term. This is sometimes
diﬃcult to justify but we do it anyway.

Fourier Series
189
Fourier series of f(t) and
a0 = 1
L
Z τ+2L
τ
f(t) dt,
an = 1
L
Z τ+2L
τ
f(t) cos
nπt
L

dt,
bn = 1
L
Z τ+2L
τ
f(t) sin
nπt
L

dt.
(5.1.6)
These results follow when we recall that the function f(t) is a periodic function that extends
from minus inﬁnity to plus inﬁnity. The results must remain unchanged, therefore, when
we shift from the interval [−L, L] to the new interval [τ, τ + 2L].
We now ask the question: what types of functions have Fourier series? Secondly, if a
function is discontinuous at a point, what value will the Fourier series give? Dirichlet3,4
answered these questions in the ﬁrst half of the nineteenth century. His results may be
summarized as follows.
Dirichlet’s Theorem: If for the interval [−L, L] the function f(t) (1) is single-valued,
(2) is bounded, (3) has at most a ﬁnite number of maxima and minima, and (4) has only
a ﬁnite number of discontinuities (piecewise continuous), and if (5) f(t + 2L) = f(t) for
values of t outside of [−L, L], then
f(t) = a0
2 +
N
X
n=1
an cos
nπt
L

+ bn sin
nπt
L

(5.1.7)
converges to f(t) as N →∞at values of t for which f(t) is continuous and to 1
2[f(t+) +
f(t−)] at points of discontinuity. The quantities t+ and t−denote points inﬁnitesimally
to the right and left of t. The coeﬃcients in Equation 5.1.7 are given by Equation 5.1.2,
Equation 5.1.4, and Equation 5.1.5. A function f(t) is bounded if the inequality |f(t)| ≤M
holds for some constant M for all values of t. Because the Dirichlet’s conditions (1)–(4) are
very mild, it is very rare that a convergent Fourier series does not exist for a function that
appears in an engineering or scientiﬁc problem.
⊓⊔
• Example 5.1.1
Let us ﬁnd the Fourier series for the function
f(t) =
 0,
−π < t ≤0,
t,
0 ≤t < π.
(5.1.8)
We compute the Fourier coeﬃcients an and bn using Equation 5.1.6 by letting L = π
and τ = −π. We then ﬁnd that
a0 = 1
π
Z π
−π
f(t) dt = 1
π
Z π
0
t dt = π
2 ,
(5.1.9)
3 Dirichlet, P. G. L., 1829: Sur la convergence des s´eries trigonom´etriques qui servent `a repr´esenter une
fonction arbitraire entre des limites donn´ees. J. Reine Angew. Math., 4, 157–169.
4 Dirichlet, P. G. L., 1837: Sur l’usage des int´egrales d´eﬁnies dans la sommation des s´eries ﬁnies ou
inﬁnies. J. Reine Angew. Math., 17, 57–67.

190
Advanced Engineering Mathematics with MATLAB
A product of the French Revolution, (Jean Baptiste) Joseph Fourier (1768–1830) held positions
within the Napoleonic Empire during his early career. After Napoleon’s fall from power, Fourier
devoted his talents exclusively to science. Although he won the Institut de France prize in 1811 for
his work on heat diﬀusion, criticism of its mathematical rigor and generality led him to publish the
classic book Th´eorie analytique de la chaleur in 1823. Within this book he introduced the world to
the series that bears his name. (Portrait courtesy of the Archives de l’Acad´emie des sciences, Paris.)
an = 1
π
Z π
0
t cos(nt) dt = 1
π
t sin(nt)
n
+ cos(nt)
n2

π
0
= cos(nπ) −1
n2π
= (−1)n −1
n2π
(5.1.10)
because cos(nπ) = (−1)n, and
bn = 1
π
Z π
0
t sin(nt) dt = 1
π
−t cos(nt)
n
+ sin(nt)
n2

π
0
= −cos(nπ)
n
= (−1)n+1
n
(5.1.11)
for n = 1, 2, 3, . . .. Thus, the Fourier series for f(t) is
f(t) = π
4 +
∞
X
n=1
(−1)n −1
n2π
cos(nt) + (−1)n+1
n
sin(nt)
(5.1.12)
= π
4 −2
π
∞
X
m=1
cos[(2m −1)t]
(2m −1)2
−
∞
X
n=1
(−1)n
n
sin(nt).
(5.1.13)
We note that at the points t = ±(2n −1)π, where n = 1, 2, 3, . . ., the function jumps
from zero to π. To what value does the Fourier series converge at these points? From
Dirichlet’s theorem, the series converges to the average of the values of the function just
to the right and left of the point of discontinuity, i.e., (π + 0)/2 = π/2. At the remaining
points the series converges to f(t).

Fourier Series
191
Second to Gauss, Peter Gustav Lejeune Dirichlet (1805–1859) was Germany’s leading mathematician
during the ﬁrst half of the nineteenth century. Initially drawn to number theory, his later studies
in analysis and applied mathematics led him to consider the convergence of Fourier series. These
studies eventually produced the modern concept of a function as a correspondence that associates
with each real x in an interval some unique value denoted by f(x). (Taken from the frontispiece of
Dirichlet, P. G. L., 1889: Werke. Druck und Verlag von Georg Reimer, 644 pp.)
Figure 5.1.1 shows how well Equation 5.1.12 approximates the function by graphing
various partial sums of this expansion as we include more and more terms (harmonics). The
MATLAB script that created this ﬁgure is:
clear;
t = [-4:0.1:4]; % create time points in plot
f = zeros(size(t)); % initialize function f(t)
for k = 1:length(t) % construct function f(t)
if t(k) < 0; f(k) = 0; else f(k) = t(k); end;
if t(k) < -pi; f(k) = t(k) + 2*pi; end;
if t(k) > pi ; f(k) = 0; end;
end
% initialize Fourier series with the mean term
fs = (pi/4) * ones(size(t));
clf % clear any figures
for n = 1:6
% create plot of truncated FS with only n harmonic
fs = fs - (2/pi) * cos((2*n-1)*t) / (2*n-1)^2;
fs = fs - (-1)^n * sin(n*t) / n;
subplot(3,2,n), plot(t,fs,t,f,’--’)

192
Advanced Engineering Mathematics with MATLAB
−4
−2
0
2
4
−2
0
2
4
mean plus 1 term
f(t)
−4
−2
0
2
4
−2
0
2
4
mean plus 2 terms
f(t)
−4
−2
0
2
4
−2
0
2
4
mean plus 3 terms
f(t)
−4
−2
0
2
4
−2
0
2
4
mean plus 4 terms
f(t)
−4
−2
0
2
4
−2
0
2
4
t
mean plus 5 terms
f(t)
−4
−2
0
2
4
−2
0
2
4
t
mean plus 6 terms
f(t)
Figure 5.1.1: Partial sum of the Fourier series for Equation 5.1.8.
if n==1
legend(’mean plus 1 term’,’f(t)’); legend boxoff;
else
legend([’mean plus ’,num2str(n),’ terms’],’f(t)’)
legend boxoff
end
if n >= 5; xlabel(’t’); end;
end
As the ﬁgure shows, successive corrections are made to the mean value of the series, π/2.
As each harmonic is added, the Fourier series ﬁts the function better in the sense of least
squares:
Z τ+2L
τ
[f(x) −fN(x)]2 dx = minimum,
(5.1.14)
where fN(x) is the truncated Fourier series of N terms.
⊓⊔
• Example 5.1.2
Let us calculate the Fourier series of the function f(t) = |t|, which is deﬁned over the
range −π ≤t ≤π.
From the deﬁnition of the Fourier coeﬃcients,
a0 = 1
π
Z 0
−π
−t dt +
Z π
0
t dt

= π
2 + π
2 = π,
(5.1.15)
an = 1
π
Z 0
−π
−t cos(nt) dt +
Z π
0
t cos(nt) dt

(5.1.16)

Fourier Series
193
−4
−2
0
2
4
0
1
2
3
4
mean plus 1 term
f(t)
−4
−2
0
2
4
0
1
2
3
4
mean plus 2 terms
f(t)
−4
−2
0
2
4
0
1
2
3
4
mean plus 3 terms
f(t)
−4
−2
0
2
4
0
1
2
3
4
mean plus 4 terms
f(t)
−4
−2
0
2
4
0
1
2
3
4
t
mean plus 5 terms
f(t)
−4
−2
0
2
4
0
1
2
3
4
t
mean plus 6 terms
f(t)
Figure 5.1.2: Partial sum of the Fourier series for f(t) = |t|.
= −nt sin(nt) + cos(nt)
n2π

0
−π
+ nt sin(nt) + cos(nt)
n2π

π
0
(5.1.17)
=
2
n2π [(−1)n −1]
(5.1.18)
and
bn = 1
π
Z 0
−π
−t sin(nt) dt +
Z π
0
t sin(nt) dt

(5.1.19)
= nt cos(nt) −sin(nt)
n2π

0
−π
−nt cos(nt) −sin(nt)
n2π

π
0
= 0
(5.1.20)
for n = 1, 2, 3, . . .. Therefore,
|t| = π
2 + 2
π
∞
X
n=1
[(−1)n −1]
n2
cos(nt) = π
2 −4
π
∞
X
m=1
cos[(2m −1)t]
(2m −1)2
(5.1.21)
for −π ≤t ≤π.
In Figure 5.1.2 we show how well Equation 5.1.21 approximates the function by graph-
ing various partial sums of this expansion. As the ﬁgure shows, the Fourier series does very
well even when we use very few terms. The reason for this rapid convergence is the nature
of the function: it does not possess any jump discontinuities.
⊓⊔
• Example 5.1.3
Sometimes the function f(t) is an even or odd function.5 Can we use this property to
simplify our work? The answer is yes.
5 An even function fe(t) has the property that fe(−t) = fe(t); an odd function fo(t) has the property
that fo(−t) = −fo(t).

194
Advanced Engineering Mathematics with MATLAB
Let f(t) be an even function. Then
a0 = 1
L
Z L
−L
f(t) dt = 2
L
Z L
0
f(t) dt,
(5.1.22)
and
an = 1
L
Z L
−L
f(t) cos
nπt
L

dt = 2
L
Z L
0
f(t) cos
nπt
L

dt,
(5.1.23)
whereas
bn = 1
L
Z L
−L
f(t) sin
nπt
L

dt = 0.
(5.1.24)
Here we used the properties that
R L
−L fe(x) dx = 2
R L
0 fe(x) dx and
R L
−Lfo(x)dx = 0. Thus,
if we have an even function, we merely compute a0 and an via Equation 5.1.22 and Equation
5.1.23, and bn = 0. Because the corresponding series contains only cosine terms, it is often
called a Fourier cosine series.
Similarly, if f(t) is odd, then
a0 = an = 0,
and
bn = 2
L
Z L
0
f(t) sin
nπt
L

dt.
(5.1.25)
Thus, if we have an odd function, we merely compute bn via Equation 5.1.25 and a0 = an =
0. Because the corresponding series contains only sine terms, it is often called a Fourier
sine series.
⊓⊔
• Example 5.1.4
In the case when f(x) consists of a constant and/or trigonometric functions, it is much
easier to ﬁnd the corresponding Fourier series by inspection rather than by using Equation
5.1.6. For example, let us ﬁnd the Fourier series for f(x) = sin2(x) deﬁned over the range
−π ≤x ≤π.
We begin by rewriting f(x) = sin2(x) as f(x) = 1
2[1−cos(2x)]. Next, we note that any
function deﬁned over the range −π < x < π has the Fourier series
f(x) = a0
2 +
∞
X
n=1
an cos(nx) + bn sin(nx)
(5.1.26)
= a0
2 + a1 cos(x) + b1 sin(x) + a2 cos(2x) + b2 sin(2x) + · · · .
(5.1.27)
On the other hand,
f(x) = 1
2 −1
2 cos(2x) = 1
2 + 0 cos(x) + 0 sin(x) −1
2 cos(2x) + 0 sin(2x) + · · · .
(5.1.28)
Consequently, by inspection, we can immediately write that
a0 = 1,
a1 = b1 = 0,
a2 = −1
2,
b2 = 0,
an = bn = 0,
n ≥3.
(5.1.29)
Thus, instead of the usual expansion involving an inﬁnite number of sine and cosine terms,
our Fourier series contains only two terms and is simply
f(x) = 1
2 −1
2 cos(2x),
−π ≤x ≤π.
(5.1.30)

Fourier Series
195
⊓⊔
• Example 5.1.5: Quieting snow tires
An application of Fourier series to a problem in industry occurred several years ago,
when drivers found that snow tires produced a loud whine6 on dry pavement. Tire sounds
are produced primarily by the dynamic interaction of the tread elements with the road
surface.7 As each tread element passes through the contact patch, it contributes a pulse of
acoustic energy to the total sound ﬁeld radiated by the tire.
For evenly spaced treads we envision that the release of acoustic energy resembles the
top of Figure 5.1.3. If we perform a Fourier analysis of this distribution, we ﬁnd that
a0 = 1
π
"Z −π/2+ǫ
−π/2−ǫ
1 dt +
Z π/2+ǫ
π/2−ǫ
1 dt
#
= 4ǫ
π ,
(5.1.31)
where ǫ is half of the width of the tread and
an = 1
π
"Z −π/2+ǫ
−π/2−ǫ
cos(nt) dt +
Z π/2+ǫ
π/2−ǫ
cos(nt) dt
#
(5.1.32)
= 1
nπ
h
sin(nt)
−π/2+ǫ
−π/2−ǫ + sin(nt)
π/2+ǫ
π/2−ǫ
i
(5.1.33)
= 1
nπ

sin

−nπ
2 + nǫ

−sin

−nπ
2 −nǫ

+ sin
nπ
2 + nǫ

−sin
nπ
2 −nǫ

(5.1.34)
= 1
nπ
h
2 cos

−nπ
2

+ 2 cos
nπ
2
i
sin(nǫ) = 4
nπ cos
nπ
2

sin(nǫ).
(5.1.35)
Because f(t) is an even function, bn = 0.
The question now arises of how to best illustrate our Fourier coeﬃcients. In Section 5.4
we will show that any harmonic can be represented as a single wave An cos(nπt/L + ϕn) or
An sin(nπt/L + ψn), where the amplitude An =
p
a2n + b2n. In the bottom frame of Figure
5.1.3, MATLAB was used to plot this amplitude, usually called the amplitude or frequency
spectrum 1
2
p
a2n + b2n, as a function of n for an arbitrarily chosen ǫ = π/12. Although the
value of ǫ will aﬀect the exact shape of the spectrum, the qualitative arguments that we
will present remain unchanged. We have added the factor 1
2 so that our deﬁnition of the
frequency spectrum is consistent with that for a complex Fourier series stated after Equation
5.5.12. The amplitude spectrum in Figure 5.1.3 shows that the spectrum for periodically
placed tire treads has its largest amplitude at small n. This produces one loud tone plus
strong harmonic overtones because the fundamental and its overtones are the dominant
terms in the Fourier series representation.
Clearly this loud, monotone whine is undesirable. How might we avoid it? Just as
soldiers marching in step produce a loud uniform sound, we suspect that our uniform tread
pattern is the problem. Therefore, let us now vary the interval between the treads so that
the distance between any tread and its nearest neighbor is not equal, as illustrated in Figure
5.1.4. Again we perform its Fourier analysis and obtain that
a0 = 1
π
"Z −π/2+ǫ
−π/2−ǫ
1 dt +
Z π/4+ǫ
π/4−ǫ
1 dt
#
= 4ǫ
π ,
(5.1.36)
6 See Varterasian, J. H., 1969: Math quiets rotating machines. SAE J., 77(10), 53.
7 Willett, P. R., 1975: Tire tread pattern sound generation. Tire Sci. Tech., 3, 252–266.

196
Advanced Engineering Mathematics with MATLAB
f(t)
t
−2π
−π
π
2π
2ε
π
π
1
0
5
10
15
20
0
0.05
0.1
0.15
0.2
0.25
n
( an
2 + bn
2 )1/2 / 2
Figure 5.1.3: Temporal spacing (over two periods) and frequency spectrum of uniformly spaced snow tire
treads.
an = 1
π
"Z −π/2+ǫ
−π/2−ǫ
cos(nt) dt +
Z π/4+ǫ
π/4−ǫ
cos(nt) dt
#
(5.1.37)
= 1
nπ sin(nt)

−π/2+ǫ
−π/2−ǫ
+ 1
nπ sin(nt)

π/4+ǫ
π/4−ǫ
(5.1.38)
= −1
nπ
h
sin
nπ
2 −nǫ

−sin
nπ
2 + nǫ
i
+ 1
nπ
h
sin
nπ
4 + nǫ

−sin
nπ
4 −nǫ
i
(5.1.39)
an = 2
nπ
h
cos
nπ
2

+ cos
nπ
4
i
sin(nǫ),
(5.1.40)
and
bn = 1
π
"Z −π/2+ǫ
−π/2−ǫ
sin(nt) dt +
Z π/4+ǫ
π/4−ǫ
sin(nt) dt
#
(5.1.41)
= −1
nπ
h
cos
nπ
2 −nǫ

−cos
nπ
2 + nǫ
i
−1
nπ
h
cos
nπ
4 + nǫ

−cos
nπ
4 −nǫ
i
(5.1.42)
= 2
nπ
h
sin
nπ
4

−sin
nπ
2
i
sin(nǫ).
(5.1.43)
The MATLAB script
epsilon = pi/12; % set up parameter for fs coefficient
n = 1:20; % number of harmonics

Fourier Series
197
t
−2π
−π
π
2π
2ε
5π/4
f(t)
3π/4
1
0
5
10
15
20
0
0.05
0.1
0.15
0.2
0.25
n
( an
2 + bn
2 )1/2 / 2
Figure 5.1.4: Temporal spacing and frequency spectrum of nonuniformly spaced snow tire treads.
arg1 = (pi/2)*n; arg2 = (pi/4)*n; arg3 = epsilon*n;
% compute the Fourier coefficient a n
an = (cos(arg1) + cos(arg2)).*sin(arg3);
an = (2/pi) * an./n;
% compute the Fourier coefficient b n
bn = (sin(arg2) - sin(arg1)).*sin(arg3);
bn = (2/pi) * bn./n;
% compute the magnitude
cn = 0.5 * sqrt(an.*an + bn.*bn);
% add in the a 0 term
cn = [2*epsilon/pi,cn];
n = [0,n];
clf % clear any figures
axes(’FontSize’,20) % set font size
stem(n,cn,’filled’) % plot spectrum
set (gca,’PlotBoxAspectRatio’,[8 4 1]) % set aspect ratio
xlabel(’n’) % label x-axis
ylabel(’( a n^2 + b n^2 )^{1/2}/2’) % label y-axis,
was used to compute the amplitude of each harmonic as a function of n and the results
were plotted. See Figure 5.1.4. The important point is that our new choice for the spacing
of the treads has reduced or eliminated some of the harmonics compared to the case of
equally spaced treads. On the negative side we have excited some of the harmonics that
were previously absent. However, the net eﬀect is advantageous because the treads produce
less noise at more frequencies rather than a lot of noise at a few select frequencies.

198
Advanced Engineering Mathematics with MATLAB
If we were to extend this technique so that the treads occurred at completely random
positions, then the treads would produce very little noise at many frequencies and the total
noise would be comparable to that generated by other sources within the car. To ﬁnd the
distribution of treads with the whitest noise8 is a process of trial and error. Assuming
a distribution, we can perform a Fourier analysis to obtain its frequency spectrum.
If
annoying peaks are present in the spectrum, we can then adjust the elements in the tread
distribution that may contribute to the peak and analyze the revised distribution. You are
ﬁnished when no peaks appear.
Problems
Find the Fourier series for the following functions. Using MATLAB, plot the Fourier spec-
trum. Then plot various partial sums and compare them against the exact function.
1. f(t) =
 1,
−π < t < 0
0,
0 < t < π
3. f(t) =
 −π,
−π < t < 0
t,
0 < t < π
5. f(t) =



0,
−π ≤t ≤0
t,
0 ≤t ≤π/2
π −t,
π/2 ≤t ≤π
7. f(t) = eat,
−L < t < L
9. f(t) =

0,
−π ≤t ≤0
sin(t),
0 ≤t ≤π
11. f(t) =
 0,
−a < t < 0
2t,
0 < t < a
13. f(t) = (π −t)/2,
0 < t < 2
15. f(t) = sinh[a (π/2 −|t|)] , −π ≤t ≤π
2. f(t) =
 t,
−π < t ≤0
0,
0 ≤t < π
4. f(t) =

1/2 + t,
−1 ≤t ≤0
1/2 −t,
0 ≤t ≤1
6. f(t) =



0,
−π ≤t ≤−π/2
sin(2t),
−π/2 ≤t ≤π/2
0,
π/2 ≤t ≤π
8. f(t) = t + t2,
−L < t < L
10. f(t) =

t,
−1
2 ≤t ≤1
2
1 −t,
1
2 ≤t ≤3
2
12. f(t) =
 0,
−π < t ≤0
t2,
0 ≤t < π
14. f(t) = t cos(πt/L) , −L < t < L
16. f(t) =



x(2L −x),
0 ≤t ≤2L
x2 −6Lx + 8L2,
2L ≤t ≤4L
5.2 PROPERTIES OF FOURIER SERIES
In the previous section we introduced the Fourier series and showed how to compute
one given the function f(t). In this section we examine some particular properties of these
series.
8 White noise is sound that is analogous to white light in that it is uniformly distributed throughout
the complete audible sound spectrum.

Fourier Series
199
Diﬀerentiation of a Fourier series
In certain instances we only have the Fourier series representation of a function f(t).
Can we ﬁnd the derivative or the integral of f(t) merely by diﬀerentiating or integrating the
Fourier series term by term? Is this permitted? Let us consider the case of diﬀerentiation
ﬁrst.
Consider a function f(t) of period 2L, which has the derivative f ′(t). Let us assume
that we can expand f ′(t) as a Fourier series. This implies that f ′(t) is continuous except
for a ﬁnite number of discontinuities and f(t) is continuous over an interval that starts at
t = τ and ends at t = τ + 2L. Then
f ′(t) = a′
0
2 +
∞
X
n=1
a′
n cos
nπt
L

+ b′
n sin
nπt
L

,
(5.2.1)
where we denoted the Fourier coeﬃcients of f ′(t) with a prime. Computing the Fourier
coeﬃcients,
a′
0 = 1
L
Z τ+2L
τ
f ′(t) dt = 1
L [f(τ + 2L) −f(τ)] = 0,
(5.2.2)
if f(τ + 2L) = f(τ). Similarly, by integrating by parts,
a′
n = 1
L
Z τ+2L
τ
f ′(t) cos
nπt
L

dt
(5.2.3)
= 1
L

f(t) cos
nπt
L

τ+2L
τ
+ nπ
L2
Z τ+2L
τ
f(t) sin
nπt
L

dt
(5.2.4)
= nπbn
L
,
(5.2.5)
and
b′
n = 1
L
Z τ+2L
τ
f ′(t) sin
nπt
L

dt
(5.2.6)
= 1
L

f(t) sin
nπt
L

τ+2L
τ
−nπ
L2
Z τ+2L
τ
f(t) cos
nπt
L

dt
(5.2.7)
= −nπan
L
.
(5.2.8)
Consequently, if we have a function f(t) whose derivative f ′(t) is continuous except for a
ﬁnite number of discontinuities and f(τ) = f(τ + 2L), then
f ′(t) =
∞
X
n=1
nπ
L

bn cos
nπt
L

−an sin
nπt
L

.
(5.2.9)
That is, the derivative of f(t) is given by a term-by-term diﬀerentiation of the Fourier series
of f(t).

200
Advanced Engineering Mathematics with MATLAB
• Example 5.2.1
The Fourier series for the periodic function
f(t) =
(
0,
−π ≤t ≤0,
t,
0 ≤t ≤π/2,
π −t,
π/2 ≤t ≤π,
f(t) = f(t + 2π),
(5.2.10)
is
f(t) = π
8 −1
π
∞
X
n=1
cos[2(2n −1)t]
(2n −1)2
−2
π
∞
X
n=1
(−1)n
(2n −1)2 sin[(2n −1)t].
(5.2.11)
Because f(t) is continuous over the entire interval (−π, π) and f(−π) = f(π) = 0, we can
ﬁnd f ′(t) by taking the derivative of Equation 5.2.11 term by term:
f ′(t) = 2
π
∞
X
n=1
sin[2(2n −1)t]
2n −1
−2
π
∞
X
n=1
(−1)n
2n −1 cos[(2n −1)t].
(5.2.12)
This is the same Fourier series that we would obtain by computing the Fourier series for
f ′(t) =
( 0,
−π < t < 0,
1,
0 < t < π/2,
−1,
π/2 < t < π.
(5.2.13)
⊓⊔
Integration of a Fourier series
To determine whether we can ﬁnd the integral of f(t) by term-by-term integration of
its Fourier series, consider a form of the antiderivative of f(t):
F(t) =
Z t
0
h
f(τ) −a0
2
i
dτ.
(5.2.14)
Now
F(t + 2L) =
Z t
0
h
f(τ) −a0
2
i
dτ +
Z t+2L
t
h
f(τ) −a0
2
i
dτ
(5.2.15)
= F(t) +
Z L
−L
h
f(τ) −a0
2
i
dτ
(5.2.16)
= F(t) +
Z L
−L
f(τ) dτ −La0 = F(t),
(5.2.17)
so that F(t) has a period of 2L. Consequently we may expand F(t) as the Fourier series
F(t) = A0
2 +
∞
X
n=1
An cos
nπt
L

+ Bn sin
nπt
L

.
(5.2.18)

Fourier Series
201
For An,
An = 1
L
Z L
−L
F(t) cos
nπt
L

dt
(5.2.19)
= 1
L

F(t)sin(nπt/L)
nπ/L

L
−L
−1
nπ
Z L
−L
h
f(t) −a0
2
i
sin
nπt
L

dt
(5.2.20)
= −
bn
nπ/L.
(5.2.21)
Similarly,
Bn =
an
nπ/L.
(5.2.22)
Therefore,
Z t
0
f(τ) dτ = a0t
2 + A0
2 +
∞
X
n=1
an sin(nπt/L) −bn cos(nπt/L)
nπ/L
.
(5.2.23)
This is identical to a term-by-term integration of the Fourier series for f(t). Thus, we can
always ﬁnd the integral of f(t) by a term-by-term integration of its Fourier series.
• Example 5.2.2
The Fourier series for f(t) = t for −π < t < π is
f(t) = −2
∞
X
n=1
(−1)n
n
sin(nt).
(5.2.24)
To ﬁnd the Fourier series for f(t) = t2, we integrate Equation 5.2.24 term by term and ﬁnd
that
τ 2
2

t
0
= 2
∞
X
n=1
(−1)n
n2
cos(nt) −2
∞
X
n=1
(−1)n
n2
.
(5.2.25)
But P∞
n=1(−1)n/n2 = −π2/12. Substituting and multiplying by 2, we obtain the ﬁnal
result that
t2 = π2
3 + 4
∞
X
n=1
(−1)n
n2
cos(nt).
(5.2.26)
⊓⊔
Parseval’s equality
One of the fundamental quantities in engineering is power. The power content of a
periodic signal f(t) of period 2L is
R τ+2L
τ
f 2(t) dt/L. This mathematical deﬁnition mirrors
the power dissipation I2R that occurs in a resistor of resistance R where I is the root mean
square (RMS) of the current. We would like to compute this power content as simply as
possible given the coeﬃcients of its Fourier series.

202
Advanced Engineering Mathematics with MATLAB
Assume that f(t) has the Fourier series
f(t) = a0
2 +
∞
X
n=1
an cos
nπt
L

+ bn sin
nπt
L

.
(5.2.27)
Then,
1
L
Z τ+2L
τ
f 2(t) dt = a0
2L
Z τ+2L
τ
f(t) dt +
∞
X
n=1
an
L
Z τ+2L
τ
f(t) cos
nπt
L

dt
+
∞
X
n=1
bn
L
Z τ+2L
τ
f(t) sin
nπt
L

dt
(5.2.28)
= a2
0
2 +
∞
X
n=1
(a2
n + b2
n).
(5.2.29)
Equation 5.2.29 is Parseval’s equality.9 It allows us to sum squares of Fourier coeﬃcients
(which we have already computed) rather than performing the integration
R τ+2L
τ
f 2(t) dt
analytically or numerically.
• Example 5.2.3
The Fourier series for f(t) = t2 over the interval [−π, π] is
t2 = π2
3 + 4
∞
X
n=1
(−1)n
n2
cos(nt).
(5.2.30)
Then, by Parseval’s equality,
1
π
Z π
−π
t4 dt = 2t5
5π

π
0
= 4π4
18 + 16
∞
X
n=1
1
n4 ,
or
2
5 −4
18

π4 = 16
∞
X
n=1
1
n4 .
(5.2.31)
Consequently,
π4/90 =
∞
X
n=1
1
n4 .
(5.2.32)
⊓⊔
Gibbs phenomena
In the actual application of Fourier series, we cannot sum an inﬁnite number of terms
but must be content with N terms. If we denote this partial sum of the Fourier series by
9 Parseval, M.-A., 1805: M´emoire sur les s´eries et sur l’int´egration compl`ete d’une ´equation aux dif-
f´erences partielles lin´eaires du second ordre, `a coeﬃcients constants. M´emoires pr´esent´es a l’Institut des
sciences, lettres et arts, par divers savans, et lus dans ses assembl´ees: Sciences math´ematiques et Physiques,
1, 638–648.

Fourier Series
203
0.00
1.26
2.52
3.78
5.04
6.30
x
-4.0
-2.0
0.0
2.0
4.0
6.0
8.0
10.0
scanning function
2N+1
t
Figure 5.2.1: The scanning function over 0 ≤x ≤2π for N = 5.
SN(t), we have from the deﬁnition of the Fourier series:
SN(t) = 1
2a0 +
N
X
n=1
an cos(nt) + bn sin(nt)
(5.2.33)
= 1
2π
Z 2π
0
f(x) dx + 1
π
Z 2π
0
f(x)
"
N
X
n=1
cos(nt) cos(nx) + sin(nt) sin(nx)
#
dx (5.2.34)
= 1
π
Z 2π
0
f(x)
(
1
2 +
N
X
n=1
cos[n(t −x)]
)
dx
(5.2.35)
= 1
2π
Z 2π
0
f(x)sin[(N + 1
2)(x −t)]
sin[ 1
2(x −t)]
dx.
(5.2.36)
The quantity sin[(N + 1
2)(x −t)]/ sin[ 1
2(x −t)] is called a scanning function.
Over the
range 0 ≤x ≤2π it has a very large peak at x = t where the amplitude equals 2N + 1.
See Figure 5.2.1. On either side of this peak there are oscillations that decrease rapidly
with distance from the peak. Consequently, as N →∞, the scanning function becomes
essentially a long narrow slit corresponding to the area under the large peak at x = t. If we
neglect for the moment the small area under the minor ripples adjacent to this slit, then
the integral, Equation 5.2.36, essentially equals f(t) times the area of the slit divided by
2π. If 1/2π times the area of the slit equals unity, then the value of SN(t) ≈f(t) to a good
approximation for large N.
For relatively small values of N, the scanning function deviates considerably from its
ideal form, and the partial sum SN(t) only crudely approximates f(t). As the partial sum
includes more terms and N becomes relatively large, the form of the scanning function
improves and so does the agreement between SN(t) and f(t). The improvement in the
scanning function is due to the large hump becoming taller and narrower. At the same time,
the adjacent ripples become more numerous as well as narrower in the same proportion as
the large hump does.

204
Advanced Engineering Mathematics with MATLAB
−1.0
1.0
3.0
5.0
7.0
t
−1.5
−0.5
0.5
1.5
−1.5
−0.5
0.5
1.5
N = 27
N = 81
S N (t)
Figure 5.2.2: The ﬁnite Fourier series representation SN(t) for the function, Equation 5.2.38, for the range
−1 ≤t ≤7 for N = 27 and N = 81.
The reason why SN(t) and f(t) will never become identical, even in the limit of N →∞,
is the presence of the positive and negative side lobes near the large peak. Because
sin[(N + 1
2)(x −t)]
sin[ 1
2(x −t)]
= 1 + 2
N
X
n=1
cos[n(t −x)],
(5.2.37)
an integration of the scanning function over the interval 0 to 2π shows that the total area
under the scanning function equals 2π. However, from Figure 5.2.1 the net area contributed
by the ripples is numerically negative so that the area under the large peak must exceed 2π
if the total area equals 2π. Although the exact value depends upon N, it is important to
note that this excess does not become zero as N →∞.
Thus, the presence of these negative side lobes explains the departure of our scanning
function from the idealized slit of area 2π. To illustrate this departure, consider the function:
f(t) =
 1,
0 < t < π,
−1,
π < t < 2π.
(5.2.38)
Then,
SN(t) = 1
2π
Z π
0
sin[(N + 1
2)(x −t)]
sin[ 1
2(x −t)]
dx −1
2π
Z 2π
π
sin[(N + 1
2)(x −t)]
sin[ 1
2(x −t)]
dx
(5.2.39)
= 1
2π
Z π
0
sin[(N + 1
2)(x −t)]
sin[ 1
2(x −t)]
dx + sin[(N + 1
2)(x + t)]
sin[ 1
2(x + t)]
dx

(5.2.40)
= 1
2π
Z π−t
−t
sin[(N + 1
2)θ]
sin( 1
2θ)
dθ −1
2π
Z π+t
t
sin[(N + 1
2)θ]
sin( 1
2θ)
dθ.
(5.2.41)
The ﬁrst integral in Equation 5.2.41 gives the contribution to SN(t) from the jump dis-
continuity at t = 0 while the second integral gives the contribution from t = π. In Figure

Fourier Series
205
5.2.2 we have plotted SN(t) when N = 27 and N = 81. Residual discrepancies remain
even for very large values of N. Indeed, as N increases, this ﬁgure changes only in that
the ripples in the vicinity of the discontinuity of f(t) proportionally increase their rate of
oscillation as a function of t while their relative magnitude remains the same. As N →∞
these ripples compress into a single vertical line at the point of discontinuity. True, these
oscillations occupy smaller and smaller spaces but they still remain. Thus, we can never
approximate a function in the vicinity of a discontinuity by a ﬁnite Fourier series without
suﬀering from this over- and undershooting of the series. This peculiarity of Fourier series
is called the Gibbs phenomena.10 Gibbs phenomena can only be eliminated by removing
the discontinuity.11
Problems
Additional Fourier series representations can be generated by diﬀerentiating or integrating
known Fourier series. Work out the following two examples.
1. Given
π2 −2πx
8
=
∞
X
n=0
cos[(2n + 1)x]
(2n + 1)2
,
0 ≤x ≤π,
obtain
π2x −πx2
8
=
∞
X
n=0
sin[(2n + 1)x]
(2n + 1)3
,
0 ≤x ≤π,
by term-by-term integration. Could we go the other way, i.e., take the derivative of the
second equation to obtain the ﬁrst? Explain.
2. Given
π2 −3x2
12
=
∞
X
n=1
(−1)n+1 cos(nx)
n2
,
−π ≤x ≤π,
obtain
π2x −x3
12
=
∞
X
n=1
(−1)n+1 sin(nx)
n3
,
−π ≤x ≤π,
by term-by-term integration. Could we go the other way, i.e., take the derivative of the
second equation to obtain the ﬁrst? Explain.
3. (a) Show that the Fourier series for the odd function:
f(t) =

2t + t2,
−2 ≤t ≤0,
2t −t2,
0 ≤t ≤2,
is
f(t) = 32
π3
∞
X
n=1
1
(2n −1)3 sin
(2n −1)πt
2

.
10 Gibbs, J. W., 1898: Fourier’s series. Nature, 59, 200; Gibbs, J. W., 1899: Fourier’s series. Nature,
59, 606. For the historical development, see Hewitt, E., and R. E. Hewitt, 1979: The Gibbs-Wilbraham
phenomenon: An episode in Fourier analysis. Arch. Hist. Exact Sci., 21, 129–160.
11 For a particularly clever method for improving the convergence of a trigonometric series, see Kan-
torovich, L. V., and V. I. Krylov, 1964: Approximate Methods of Higher Analysis. Interscience, pp. 77–88.

206
Advanced Engineering Mathematics with MATLAB
(b) Use Parseval’s equality to show that
π6
960 =
∞
X
n=1
1
(2n −1)6 .
This series converges very rapidly to π6/960 and provides a convenient method for comput-
ing π6.
5.3 HALF-RANGE EXPANSIONS
In certain applications, we will ﬁnd that we need a Fourier series representation for
a function f(x) that applies over the interval (0, L) rather than (−L, L). Because we are
completely free to deﬁne the function over the interval (−L, 0), it is simplest to have a series
that consists only of sines or cosines. In this section we shall show how we can obtain these
so-called half-range expansions.
Recall in Example 5.1.3 how we saw that if f(x) is an even function, then bn = 0 for all
n. Similarly, if f(x) is an odd function, then a0 = an = 0 for all n. We now use these results
to ﬁnd a Fourier half-range expansion by extending the function deﬁned over the interval
(0, L) as either an even or odd function into the interval (−L, 0). If we extend f(x) as an
even function, we will get a half-range cosine series; if we extend f(x) as an odd function,
we obtain a half-range sine series.
It is important to remember that half-range expansions are a special case of the general
Fourier series. For any f(x) we can construct either a Fourier sine or cosine series over the
interval (−L, L). Both of these series will give the correct answer over the interval of (0, L).
Which one we choose to use depends upon whether we wish to deal with a cosine or sine
series.
• Example 5.3.1
Let us ﬁnd the half-range sine expansion of
f(x) = 1,
0 < x < π.
(5.3.1)
We begin by deﬁning the periodic odd function
ef(x) =
 −1,
−π < x < 0,
1,
0 < x < π,
(5.3.2)
with ef(x + 2π) = ef(x). Because ef(x) is odd, a0 = an = 0 and
bn = 2
π
Z π
0
1 sin(nx) dx = −2
nπ cos(nx)
π
0 = −2
nπ [cos(nπ) −1] = −2
nπ [(−1)n −1] .
(5.3.3)
The Fourier half-range sine series expansion of f(x) is therefore
f(x) = 2
π
∞
X
n=1
[1 −(−1)n]
n
sin(nx) = 4
π
∞
X
m=1
sin[(2m −1)x]
2m −1
.
(5.3.4)

Fourier Series
207
-0.3
-0.1
0.1
0.3
x
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
-0.3
-0.1
0.1
0.3
x
N = 25
exact 
N = 50
N = 10
Figure 5.3.1: Partial sum of N terms in the Fourier half-range sine representation of a square wave.
As counterpoint, let us ﬁnd the half-range cosine expansion of f(x) = 1, 0 < x < π.
Now, we have that bn = 0,
a0 = 2
π
Z π
0
1 dx = 2,
(5.3.5)
and
an = 2
π
Z π
0
cos(nx) dx = 2
nπ sin(nx)
π
0 = 0.
(5.3.6)
Thus, the Fourier half-range cosine expansion equals the single term:
f(x) = 1,
0 < x < π.
(5.3.7)
This is perfectly reasonable.
To form a half-range cosine expansion we extend f(x) as
an even function into the interval (−π, 0).
In this case, we would obtain ef(x) = 1 for
−π < x < π. Finally, we note that the Fourier series of a constant is simply that constant.
In practice it is impossible to sum Equation 5.3.4 exactly and we actually sum only the
ﬁrst N terms. Figure 5.3.1 illustrates f(x) when this Fourier series contains N terms. As
seen from the ﬁgure, the truncated series tries to achieve the inﬁnite slope at x = 0, but in
the attempt, it overshoots the discontinuity by a certain amount (in this particular case, by
17.9%). This is another example of the Gibbs phenomena. Increasing the number of terms
does not remove this peculiarity; it merely shifts it nearer to the discontinuity.
⊓⊔
• Example 5.3.2: Inertial supercharging of an engine
An important aspect of designing any gasoline engine involves the motion of the fuel,
air, and exhaust gas mixture through the engine. Ordinarily an engineer would consider the
motion as steady ﬂow; but in the case of a four-stroke, single-cylinder gasoline engine, the
closing of the intake valve interrupts the steady ﬂow of the gasoline-air mixture for nearly
three quarters of the engine cycle. This periodic interruption sets up standing waves in the

208
Advanced Engineering Mathematics with MATLAB
intake pipe - waves that can build up an appreciable pressure amplitude just outside the
input value.
When one of the harmonics of the engine frequency equals one of the resonance fre-
quencies of the intake pipe, then the pressure ﬂuctuations at the valve will be large. If the
intake valve closes during that portion of the cycle when the pressure is less than average,
then the waves will reduce the power output. However, if the intake valve closes when the
pressure is greater than atmospheric, then the waves will have a supercharging eﬀect and
will produce an increase of power. This eﬀect is called inertia supercharging.
While studying this problem, Morse et al.12 found it necessary to express the velocity
of the air-gas mixture in the valve, given by
f(t) =



0,
−π < ωt < −π/4,
π cos(2ωt)/2,
−π/4 < ωt < π/4,
0,
π/4 < ωt < π,
(5.3.8)
in terms of a Fourier expansion. The advantage of working with the Fourier series rather
than the function itself lies in the ability to write the velocity as a periodic forcing function
that highlights the various harmonics that might resonate with the structure comprising
the fuel line.
Clearly f(t) is an even function and its Fourier representation will be a cosine series.
In this problem τ = −π/ω, and L = π/ω. Therefore,
a0 = 2ω
π
Z π/4ω
−π/4ω
π
2 cos(2ωt) dt = 1
2 sin(2ωt)
π/4ω
−π/4ω = 1,
(5.3.9)
and
an = 2ω
π
Z π/4ω
−π/4ω
π
2 cos(2ωt) cos
 nπt
π/ω

dt
(5.3.10)
= ω
2
Z π/4ω
−π/4ω
{cos[(n + 2)ωt] + cos[(n −2)ωt]} dt
(5.3.11)
=











sin[(n+2)ωt]
2(n+2)
+ sin[(n−2)ωt]
2(n−2)

π/4ω
−π/4ω
,
n ̸= 2,
ωt
2 + sin(4ωt)
4

π/4ω
−π/4ω
,
n = 2,
(5.3.12)
=
(
−
4
n2−4 cos
  nπ
4

,
n ̸= 2,
π
4 ,
n = 2.
(5.3.13)
Plotting these Fourier coeﬃcients using the MATLAB script:
for m = 1:21;
n = m-1; % compute the indices for the harmonic
% compute the Fourier coefficients a n
if n == 2; an(m) = pi/4; else;
an(m) = 4.*cos(pi*n/4)/(4-n*n); end;
12 Morse, P. M., R. H. Boden, and H. Schecter, 1938: Acoustic vibrations and internal combustion engine
performance. I. Standing waves in the intake pipe system. J. Appl. Phys., 9, 16–23.

Fourier Series
209
0
5
10
15
20
−0.5
0
0.5
1
n
an
Figure 5.3.2: The spectral coeﬃcients of the Fourier cosine series of the function given by Equation 5.3.9.
end
nn=0:20; % create indices for x-axis
fzero=zeros(size(nn)); % create the zero line
clf % clear any figures
axes(’FontSize’,20) % set font size
stem(nn,an,’filled’) % plot spectrum
hold on
plot(nn,fzero,’-’) % plot the zero line
set (gca,’PlotBoxAspectRatio’,[8 4 1]) % set aspect ratio
xlabel(’n’) % label x-axis
ylabel(’a n’) % label y-axis,
we see that these Fourier coeﬃcients become small rapidly (see Figure 5.3.2). For that
reason, Morse et al. showed that there are only about three resonances where the acoustic
properties of the intake pipe can enhance engine performance. These peaks occur when
q = 30c/NL = 3, 4, or 5, where c is the velocity of sound in the air-gas mixture, L is the
eﬀective length of the intake pipe, and N is the engine speed in rpm. See Figure 5.3.3.
Subsequent experiments13 veriﬁed these results.
Such analyses are valuable to automotive engineers. Engineers are always seeking ways
to optimize a system with little or no additional cost. Our analysis shows that by tuning
the length of the intake pipe so that it falls on one of the resonance peaks, we could obtain
higher performance from the engine with little or no extra work. Of course, the problem is
that no car always performs at some optimal condition.
Problems
Find the Fourier cosine and sine series for the following functions. Then, use MATLAB to
plot the Fourier coeﬃcients.
1. f(t) = t,
0 < t < π
2. f(t) = π −t,
0 < t < π
3. f(t) = t(a −t),
0 < t < a
4. f(t) = ekt,
0 < t < a
13 Boden, R. H., and H. Schecter, 1944: Dynamics of the inlet system of a four-stroke engine. NACA
Tech. Note 935.

210
Advanced Engineering Mathematics with MATLAB
Figure 5.3.3: Experimental veriﬁcation of inertial supercharging within a gasoline engine resulting from
the resonance of the air-gas mixture and the intake pipe system. The peaks correspond to the n = 3, 4,
and 5 harmonics of the Fourier representation, Equation 5.3.13, and the parameter q is deﬁned in the text.
(From Morse, P., R. H. Boden, and H. Schecter, 1938: Acoustic vibrations and internal combustion engine
performance. J. Appl. Phys., 9, 17 with permission.)
5. f(t) =
(
t,
0 ≤t ≤1
2
1 −t,
1
2 ≤t ≤1
7. f(t) = π2 −t2,
0 < t < π
9. f(t) =













0,
0 < t ≤a
3
t −a
3,
a
3 ≤t ≤2a
3
a
3,
2a
3 ≤t < a
11. f(t) =





1
2,
0 < t < a
2
1,
a
2 < t < a
13. f(t) =







t,
0 < t ≤a
2
a
2,
a
2 ≤t < a
6. f(t) =
 t,
0 < t ≤1
1,
1 ≤t < 2
8. f(t) =





0,
0 < t < a
2
1,
a
2 < t < a
10. f(t) =













0,
0 < t < a
4
1,
a
4 < t < 3a
4
0,
3a
4 < t < a
12. f(t) =





2t
a ,
0 < t ≤a
2
3a −2t
2a
,
a
2 ≤t < a
14. f(t) = a −t
a
,
0 < t < a
15. Using the relationships14 that
14 Gradshteyn, I. S., and I. M. Ryzhik, 1965: Table of Integrals, Series, and Products. Academic Press,
Section 3.753, Formula 2 and Section 3.771, Formula 8.
Honest and trustworthy 
Honest and trustworthy 
Understanding 
Understanding 
Loyal 
Loyal 

Fourier Series
211
Z 1
0
cos(ax)
√
1 −x2 dx = π
2 J0(a), and
Z u
0
(u2−x2)ν−1
2 cos(ax) dx =
√π
2
2u
a
ν
Γ
 ν + 1
2

Jν(au),
with a > 0, u > 0, ℜ(ν) > −1
2, obtain the following half-range expansions:
1
√
1 −x2 = π
2 + π
∞
X
n=1
J0(nπ) cos(nπx),
0 < x < 1,
and
p
1 −x2 = 2
∞
X
n=1
J1[(2n −1)π/2]
2n −1
cos[(2n −1)πx/2],
0 < x < 1.
Here Jν(·) denotes the Bessel function of the ﬁrst kind and order ν (see Section 6.5) and
Γ(·) is the gamma function.15
16. The function
f(t) = 1 −(1 + a) t
π + (a −1) t2
π2 + (a + 1) t3
π3 −a t4
π4 ,
0 < t < π
is a curve ﬁt to the observed pressure trace of an explosion wave in the atmosphere. Because
the observed transmission of atmospheric waves depends on the ﬁve-fourths power of the
frequency, Reed16 had to re-express this curve ﬁt as a Fourier sine series before he could
use the transmission law. He found that
f(t) = 1
π
∞
X
n=1
1
n

1 −3(a −1)
2π2n2

sin(2nt)
+ 1
π
∞
X
n=1
2
2n −1

1 +
2(a −1)
π2(2n −1)2 −
48a
π4(2n −1)4

sin[(2n −1)t].
Conﬁrm his result.
5.4 FOURIER SERIES WITH PHASE ANGLES
Sometimes it is desirable to rewrite a general Fourier series as a purely cosine or purely
sine series with a phase angle. Engineers often speak of some quantity leading or lagging
another quantity. Re-expressing a Fourier series in terms of amplitude and phase provides
a convenient method for determining these phase relationships.
Suppose, for example, that we have a function f(t) of period 2L, given in the interval
[−L, L], whose Fourier series expansion is
f(t) = a0
2 +
∞
X
n=1
an cos
nπt
L

+ bn sin
nπt
L

.
(5.4.1)
15 Gradshteyn and Ryzhik, op. cit., Section 6.41.
16 Reed, J. W., 1977: Atmospheric attenuation of explosion waves. J. Acoust. Soc. Am., 61, 39–47.

212
Advanced Engineering Mathematics with MATLAB
We wish to replace Equation 5.4.1 by the series:
f(t) = a0
2 +
∞
X
n=1
Bn sin
nπt
L + ϕn

.
(5.4.2)
To do this we note that
Bn sin
nπt
L + ϕn

= an cos
nπt
L

+ bn sin
nπt
L

(5.4.3)
= Bn sin
nπt
L

cos(ϕn) + Bn sin(ϕn) cos
nπt
L

.
(5.4.4)
We equate coeﬃcients of sin(nπt/L) and cos(nπt/L) on both sides and obtain
an = Bn sin(ϕn),
and
bn = Bn cos(ϕn).
(5.4.5)
Hence, upon squaring and adding,
Bn =
p
a2n + b2n,
(5.4.6)
while taking the ratio gives
ϕn = tan−1(an/bn).
(5.4.7)
Similarly we could rewrite Equation 5.4.1 as
f(t) = a0
2 +
∞
X
n=1
An cos
nπt
L + ϕn

,
(5.4.8)
where
An =
p
a2n + b2n,
and
ϕn = tan−1(−bn/an),
(5.4.9)
and
an = An cos(ϕn),
and
bn = −An sin(ϕn).
(5.4.10)
In both cases, we must be careful in computing ϕn because there are two possible values of
ϕn that satisfy Equation 5.4.7 or Equation 5.4.9. These angles ϕn must give the correct an
and bn using either Equation 5.4.5 or Equation 5.4.10.
• Example 5.4.1
The Fourier series for f(t) = et over the interval −L < t < L is
f(t) = sinh(aL)
aL
+ 2 sinh(aL)
∞
X
n=1
aL(−1)n
a2L2 + n2π2 cos
nπt
L

−2 sinh(aL)
∞
X
n=1
nπ(−1)n
a2L2 + n2π2 sin
nπt
L

.
(5.4.11)
Let us rewrite Equation 5.4.11 as a Fourier series with a phase angle. Regardless of whether
we want the new series to contain cos(nπt/L + ϕn) or sin(nπt/L + ϕn), the amplitude An
or Bn is the same in both series:
An = Bn =
p
a2n + b2n =
2 sinh(aL)
√
a2L2 + n2π2 .
(5.4.12)

Fourier Series
213
If we want our Fourier series to read
f(t) = sinh(aL)
aL
+ 2 sinh(aL)
∞
X
n=1
cos(nπt/L + ϕn)
√
a2L2 + n2π2 ,
(5.4.13)
then
ϕn = tan−1

−bn
an

= tan−1nπ
aL

,
(5.4.14)
where ϕn lies in the ﬁrst quadrant if n is even and in the third quadrant if n is odd. This
ensures that the sign from the (−1)n is correct.
On the other hand, if we prefer
f(t) = sinh(aL)
aL
+ 2 sinh(aL)
∞
X
n=1
sin(nπt/L + ϕn)
√
a2L2 + n2π2 ,
(5.4.15)
then
ϕn = tan−1
an
bn

= −tan−1
aL
nπ

,
(5.4.16)
where ϕn lies in the fourth quadrant if n is odd and in the second quadrant if n is even.
Problems
Write the following Fourier series in both the cosine and sine phase angle form:
1. f(t) = 1
2 + 2
π
∞
X
n=1
sin[(2n −1)πt]
2n −1
3. f(t) = −2
∞
X
n=1
(−1)n
n
sin(nt)
2. f(t) = 3
2 + 2
π
∞
X
n=1
(−1)n
2n −1 cos
(2n −1)πt
2

4. f(t) = π
2 −4
π
∞
X
n=1
cos[(2n −1)t]
(2n −1)2
5.5 COMPLEX FOURIER SERIES
So far in our discussion, we expressed Fourier series in terms of sines and cosines. We
are now ready to re-express a Fourier series as a series of complex exponentials. There
are two reasons for this. First, in certain engineering and scientiﬁc applications of Fourier
series, the expansion of a function in terms of complex exponentials results in coeﬃcients
of considerable simplicity and clarity. Second, these complex Fourier series point the way
to the development of the Fourier transform in the next chapter.
We begin by introducing the variable ωn = nπ/L, where n = 0, ±1, ±2, . . . Using
Euler’s formula we can replace the sine and cosine in the Fourier series by exponentials and
ﬁnd that
f(t) = a0
2 +
∞
X
n=1
an
2
 eiωnt + e−iωnt
+ bn
2i
 eiωnt −e−iωnt
(5.5.1)
= a0
2 +
∞
X
n=1
an
2 −bni
2

eiωnt +
an
2 + bni
2

e−iωnt.
(5.5.2)

214
Advanced Engineering Mathematics with MATLAB
If we deﬁne cn = 1
2(an −ibn), then
cn = 1
2(an −ibn) = 1
2L
Z τ+2L
τ
f(t)[cos(ωnt) −i sin(ωnt)] dt = 1
2L
Z τ+2L
τ
f(t)e−iωntdt.
(5.5.3)
Similarly, the complex conjugate of cn, c∗
n, equals
c∗
n = 1
2(an + ibn) = 1
2L
Z τ+2L
τ
f(t)eiωntdt.
(5.5.4)
To simplify Equation 5.5.2 we note that
ω−n = (−n)π
L
= −nπ
L = −ωn,
(5.5.5)
which yields the result that
c−n = 1
2L
Z τ+2L
τ
f(t)e−iω−ntdt = 1
2L
Z τ+2L
τ
f(t)eiωntdt = c∗
n
(5.5.6)
so that we can write Equation 5.5.2 as
f(t) = a0
2 +
∞
X
n=1
cneiωnt + c∗
ne−iωnt = a0
2 +
∞
X
n=1
cneiωnt + c−ne−iωnt.
(5.5.7)
Letting n = −m in the second summation on the right side of Equation 5.5.7,
∞
X
n=1
c−ne−iωnt =
−∞
X
m=−1
cme−iω−mt =
−1
X
m=−∞
cmeiωmt =
−1
X
n=−∞
cneiωnt,
(5.5.8)
where we introduced m = n into the last summation in Equation 5.5.8. Therefore,
f(t) = a0
2 +
∞
X
n=1
cneiωnt +
−1
X
n=−∞
cneiωnt.
(5.5.9)
On the other hand,
a0
2 = 1
2L
Z τ+2L
τ
f(t) dt = c0 = c0eiω0t,
(5.5.10)
because ω0 = 0π/L = 0. Thus, our ﬁnal result is
f(t) =
∞
X
n=−∞
cneiωnt,
(5.5.11)
where
cn = 1
2L
Z τ+2L
τ
f(t)e−iωnt dt
(5.5.12)

Fourier Series
215
and n = 0, ±1, ±2, . . .. Note that even though cn is generally complex, the summation
Equation 5.5.11 always gives a real-valued function f(t).
Just as we can represent the function f(t) graphically by a plot of t against f(t), we
can plot cn as a function of n, commonly called the frequency spectrum. Because cn is
generally complex, it is necessary to make two plots. Typically the plotted quantities are
the amplitude spectra |cn| and the phase spectra ϕn, where ϕn is the phase of cn. However,
we could just as well plot the real and imaginary parts of cn. Because n is an integer, these
plots consist merely of a series of vertical lines representing the ordinates of the quantity
|cn| or ϕn for each n. For this reason we refer to these plots as the line spectra.
Because 2cn = an −ibn, the coeﬃcients cn for an even function will be purely real; the
coeﬃcients cn for an odd function are purely imaginary. It is important to note that we
lose the advantage of even and odd functions in the sense that we cannot just integrate over
the interval 0 to L and then double the result. In the present case we have a line integral
of a complex function along the real axis.
• Example 5.5.1
Let us ﬁnd the complex Fourier series for
f(t) =
 1,
0 < t < π,
−1,
−π < t < 0,
(5.5.13)
which has the periodicity f(t + 2π) = f(t).
With L = π and τ = −π, ωn = nπ/L = n. Therefore,
cn = 1
2π
Z 0
−π
(−1)e−int dt + 1
2π
Z π
0
(1)e−int dt
(5.5.14)
=
1
2nπie−int

0
−π
−
1
2nπie−int

π
0
(5.5.15)
= −
i
2nπ
 1 −enπi
+
i
2nπ
 e−nπi −1

,
(5.5.16)
if n ̸= 0. Because enπi = cos(nπ)+i sin(nπ) = (−1)n and e−nπi = cos(−nπ)+i sin(−nπ) =
(−1)n, then
cn = −i
nπ [1 −(−1)n] =

0,
n even,
−2i
nπ,
n odd,
(5.5.17)
with
f(t) =
∞
X
n=−∞
cneint.
(5.5.18)
In this particular problem we must treat the case n = 0 specially because Equation
5.5.15 is undeﬁned for n = 0. In that case,
c0 = 1
2π
Z 0
−π
(−1) dt + 1
2π
Z π
0
(1) dt = 1
2π (−t)
0
−π + 1
2π (t)
π
0 = 0.
(5.5.19)
Because c0 = 0, we can write the expansion:
f(t) = −2i
π
∞
X
m=−∞
e(2m−1)it
2m −1 ,
(5.5.20)

216
Advanced Engineering Mathematics with MATLAB
−15
−10
−5
0
5
10
15
0
0.5
1
amplitude
−15
−10
−5
0
5
10
15
−2
−1
0
1
2
phase
n
Figure 5.5.1: Amplitude and phase spectra for the function, Equation 5.5.13.
since we can write all odd integers as 2m −1, where m = 0, ±1, ±2, ±3, . . .. Using the
MATLAB script
max = 31; % total number of harmonics
mid = (max+1)/2; % in the array, location of c 0
for m = 1:max;
n = m - mid; % compute value of harmonic
% compute complex Fourier coefficient c n = (cnr,cni)
if mod(n,2) == 0; cnr(m) = 0; cni(m) = 0; else;
cnr(m) = 0; cni(m) = - 2/(pi*n); end;
end
nn=(1-mid):(max-mid); % create indices for x-axis
fzero=zeros(size(nn)); % create the zero line
clf % clear any figures
amplitude = sqrt(cnr.*cnr+cni.*cni);
phase = atan2(cni,cnr);
% plot amplitude of c n
subplot(2,1,1), stem(nn,amplitude,’filled’)
% label amplitude plot
text(6,0.75,’amplitude’,’FontSize’,20)
subplot(2,1,2), stem(nn,phase,’filled’) % plot phases of c n
text(7,1,’phase’,’FontSize’,20) % label phase plot
xlabel(’n’,’Fontsize’,20) % label x-axis,
we plot the amplitude and phase spectra for the function, Equation 5.5.13, as a function of
n in Figure 5.5.1.
⊓⊔
• Example 5.5.2
The concept of Fourier series can be generalized to multivariable functions. Consider
the function f(x, y) deﬁned over 0 < x < L and 0 < y < H. Taking y constant, we have

Fourier Series
217
that
cn(y) = 1
L
Z L
0
f(x, y)e−iξnx dx,
ξn = 2πn
L .
(5.5.21)
Similarly, holding ξn constant,
cnm = 1
H
Z H
0
cn(y)e−iηmy dy,
ηm = 2πm
H .
(5.5.22)
Therefore, the (complex) Fourier coeﬃcient for the two-dimensional function f(x, y) is
cnm =
1
LH
Z L
0
Z H
0
f(x, y)e−i(ξnx+ηmy) dx dy,
(5.5.23)
assuming that the integral exists.
To recover f(x, y) given cnm, we reverse the process of deriving cnm. Starting with
cn(y) =
∞
X
m=−∞
cnmeiηmy,
(5.5.24)
we ﬁnd that
f(x, y) =
∞
X
n=−∞
cn(y)eiξnx.
(5.5.25)
Therefore,
f(x, y) =
∞
X
n=−∞
∞
X
m=−∞
cnmei(ξnx+ηmy).
(5.5.26)
Problems
Find the complex Fourier series for the following functions. Then use MATLAB to plot the
corresponding spectra.
1. f(t) = |t|,
−π ≤t ≤π
3. f(t) = t,
0 < t < 2
5. f(t) =

0,
−π/2 < t < 0
1,
0 < t < π/2
2. f(t) = et,
0 < t < 2
4. f(t) = t2,
−π ≤t ≤π
6. f(t) = t,
−1 < t < 1
5.6 THE USE OF FOURIER SERIES IN THE SOLUTION OF ORDINARY
DIFFERENTIAL EQUATIONS
An important application of Fourier series is the solution of ordinary diﬀerential equa-
tions. Structural engineers especially use this technique because the occupants of buildings
and bridges often subject these structures to forcings that are periodic in nature.17
17 Timoshenko, S. P., 1943: Theory of suspension bridges. Part II. J. Franklin Inst., 235, 327–349; Inglis,
C. E., 1934: A Mathematical Treatise on Vibrations in Railway Bridges. Cambridge University Press, 203
pp.

218
Advanced Engineering Mathematics with MATLAB
• Example 5.6.1
Let us ﬁnd the general solution to the ordinary diﬀerential equation
y′′ + 9y = f(t),
(5.6.1)
where the forcing is
f(t) = |t|,
−π ≤t ≤π,
f(t + 2π) = f(t).
(5.6.2)
This equation represents an oscillator forced by a driver whose displacement is the saw-tooth
function.
We begin by replacing the function f(t) by its Fourier series representation because
the forcing function is periodic. The advantage of expressing f(t) as a Fourier series is its
validity for any time t. The alternative would be to construct a solution over each interval
nπ < t < (n+1)π and then piece together the ﬁnal solution assuming that the solution and
its ﬁrst derivative are continuous at each junction t = nπ. Because the function is an even
function, all of the sine terms vanish and the Fourier series is
|t| = π
2 −4
π
∞
X
n=1
cos[(2n −1)t]
(2n −1)2
.
(5.6.3)
Next, we note that the general solution consists of the complementary solution, which
equals
yH(t) = A cos(3t) + B sin(3t),
(5.6.4)
and the particular solution yp(t), which satisﬁes the diﬀerential equation
y′′
p + 9yp = π
2 −4
π
∞
X
n=1
cos[(2n −1)t]
(2n −1)2
.
(5.6.5)
To determine this particular solution, we write Equation 5.6.5 as
y′′
p + 9yp = π
2 −4
π cos(t) −4
9π cos(3t) −
4
25π cos(5t) −· · · .
(5.6.6)
By the method of undetermined coeﬃcients, we guess the particular solution:
yp(t) = a0
2 + a1 cos(t) + b1 sin(t) + a2 cos(3t) + b2 sin(3t) + · · ·
(5.6.7)
or
yp(t) = 1
2a0 +
∞
X
n=1
an cos[(2n −1)t] + bn sin[(2n −1)t].
(5.6.8)
Because
y′′
p(t) =
∞
X
n=1
−(2n −1)2{an cos[(2n −1)t] + bn sin[(2n −1)t]},
(5.6.9)
∞
X
n=1
−(2n −1)2{an cos[(2n −1)t] + bn sin[(2n −1)t]}
(5.6.10)
+ 9
2a0 + 9
∞
X
n=1
an cos[(2n −1)t] + bn sin[(2n −1)t] = π
2 −4
π
∞
X
n=1
cos[(2n −1)t]
(2n −1)2
,

Fourier Series
219
or
9a0
2
−π
2 +
∞
X
n=1

[9 −(2n −1)2]an +
4
π(2n −1)2

cos[(2n −1)t]
+
∞
X
n=1
[9 −(2n −1)2]bn sin[(2n −1)t] = 0.
(5.6.11)
Because Equation 5.6.11 must hold true for any time, each harmonic must vanish separately
and
a0 = π
9 ,
an = −
4
π(2n −1)2[9 −(2n −1)2]
(5.6.12)
and bn = 0. All of the coeﬃcients an are ﬁnite except for n = 2, where a2 becomes undeﬁned.
This coeﬃcient is undeﬁned because the harmonic cos(3t) in the forcing function resonates
with the natural mode of the system.
Let us review our analysis to date. We found that each harmonic in the forcing func-
tion yields a corresponding harmonic in the particular solution, Equation 5.6.8. The only
diﬃculty arises with the harmonic n = 2. Although our particular solution is not correct
because it contains cos(3t), we suspect that if we remove that term then the remaining
harmonic solutions are correct. The problem is linear, and diﬃculties with one harmonic
term should not aﬀect other harmonics. But how shall we deal with the cos(3t) term in the
forcing function? Let us denote that particular solution by Y (t) and modify our particular
solution as follows:
yp(t) = 1
2a0 + a1 cos(t) + Y (t) + a3 cos(5t) + · · · .
(5.6.13)
Substituting this solution into the diﬀerential equation and simplifying, everything cancels
except
Y ′′ + 9Y = −4
9π cos(3t).
(5.6.14)
The solution of this equation by the method of undetermined coeﬃcients is
Y (t) = −2
27π t sin(3t).
(5.6.15)
This term, called a secular term, is the most important one in the solution. While the other
terms merely represent simple oscillatory motion, the term t sin(3t) grows linearly with time
and eventually becomes the dominant term in the series. Consequently, the general solution
equals the complementary plus the particular solution, or
y(t) = A cos(3t)+B sin(3t)+ π
18 −
2
27π t sin(3t)−4
π
∞
X
n=1
n̸=2
cos[(2n −1)t]
(2n −1)2[9 −(2n −1)2]. (5.6.16)
⊓⊔
• Example 5.6.2
Let us redo the previous problem only using complex Fourier series. That is, let us ﬁnd
the general solution to the ordinary diﬀerential equation
y′′ + 9y = π
2 −2
π
∞
X
n=−∞
ei(2n−1)t
(2n −1)2 .
(5.6.17)

220
Advanced Engineering Mathematics with MATLAB
From the method of undetermined coeﬃcients we guess the particular solution for
Equation 5.6.17 to be
yp(t) = c0 +
∞
X
n=−∞
cnei(2n−1)t.
(5.6.18)
Then
y′′
p(t) =
∞
X
n=−∞
−(2n −1)2cnei(2n−1)t.
(5.6.19)
Substituting Equation 5.6.18 and Equation 5.6.19 into Equation 5.6.17,
9c0 +
∞
X
n=−∞
[9 −(2n −1)2]cnei(2n−1)t = π
2 −2
π
∞
X
n=−∞
ei(2n−1)t
(2n −1)2 .
(5.6.20)
Because Equation 5.6.20 must be true for any t,
c0 = π
18,
and
cn =
2
π(2n −1)2[(2n −1)2 −9].
(5.6.21)
Therefore,
yp(t) = π
18 + 2
π
∞
X
n=−∞
ei(2n−1)t
(2n −1)2[(2n −1)2 −9]ei(2n−1)t.
(5.6.22)
However, there is a problem when n = −1 and n = 2. Therefore, we modify Equation 5.6.22
to read
yp(t) = π
18 + c2te3it + c−1te−3it + 2
π
∞
X
n=−∞
n̸=−1,2
ei(2n−1)t
(2n −1)2[(2n −1)2 −9]ei(2n−1)t.
(5.6.23)
Introducing Equation 5.6.23 into Equation 5.6.17 and simplifying,
c2 = −
1
27πi,
and
c−1 = −
1
27πi.
(5.6.24)
The general solution is then
y(t) = Ae3it + Be−3it + π
18 −te3it
27πi + te−3it
27πi + 2
π
∞
X
n=−∞
n̸=−1,2
ei(2n−1)t
(2n −1)2[(2n −1)2 −9]. (5.6.25)
The ﬁrst two terms on the right side of Equation 5.6.25 represent the complementary solu-
tion. Although this expansion is equivalent to Equation 5.6.16, we have all of the advantages
of dealing with exponentials rather than sines and cosines. These advantages include ease
of diﬀerentiation and integration, and writing the series in terms of amplitude and phase.
⊓⊔
• Example 5.6.3: Temperature within a spinning satellite
In the design of artiﬁcial satellites, it is important to determine the temperature distri-
bution on the spacecraft’s surface. An interesting special case is the temperature ﬂuctuation

Fourier Series
221
in the skin due to the spinning of the vehicle. If the craft is thin-walled so that there is
no radial dependence, Hrycak18 showed that he could approximate the nondimensional
temperature ﬁeld at the equator of the rotating satellite by
d2T
dη2 + bdT
dη −c

T −3
4

= −πc
4
F(η) + β/4
1 + πβ/4 ,
(5.6.26)
where
b = 4π2r2f/a,
c = 16πS
γT∞

1 + πβ
4

,
T∞=
 S
πσǫ
1/4 1 + πβ/4
1 + β
1/4
,
(5.6.27)
F(η) =





cos(2πη),
0 ≤η ≤1
4,
0,
1
4 ≤η ≤3
4,
cos(2πη),
3
4 ≤η ≤1,
(5.6.28)
a is the thermal diﬀusivity of the shell, f is the rate of spin, r is the radius of the spacecraft,
S is the net direct solar heating, β is the ratio of the emissivity of the interior shell to the
emissivity of the exterior surface, ǫ is the overall emissivity of the exterior surface, γ is
the satellite’s skin conductance, and σ is the Stefan-Boltzmann constant. The independent
variable η is the longitude along the equator with the eﬀect of rotation subtracted out
(2πη = ϕ−2πft). The reference temperature T∞equals the temperature that the spacecraft
would have if it spun with inﬁnite angular speed so that the solar heating would be uniform
around the craft. We nondimensionalized the temperature with respect to T∞.
We begin by introducing the new variables
y = T −3
4 −
πβ
16 + 4πβ ,
ν0 = 2π2r2f
aρ0
,
A0 = −
πρ2
4 + πβ
(5.6.29)
and ρ2
0 = c so that Equation 5.6.26 becomes
d2y
dη2 + 2ρ0ν0
dy
dη −ρ2
0y = A0F(η).
(5.6.30)
Next, we expand F(η) as a Fourier series because it is a periodic function of period 1.
Because it is an even function,
f(η) = 1
2a0 +
∞
X
n=1
an cos(2nπη),
(5.6.31)
where
a0 =
1
1/2
Z 1/4
0
cos(2πx) dx +
1
1/2
Z 1
3/4
cos(2πx) dx = 2
π ,
(5.6.32)
a1 =
1
1/2
Z 1/4
0
cos2(2πx) dx +
1
1/2
Z 1
3/4
cos2(2πx) dx = 1
2
(5.6.33)
18 From Hrycak, P., 1963: Temperature distribution in a spinning spherical space vehicle. AIAA J., 1,
96–99. Reprinted with permission of the American Institute of Aeronautics and Astronautics.

222
Advanced Engineering Mathematics with MATLAB
and
an =
1
1/2
Z 1/4
0
cos(2πx) cos(2nπx) dx +
1
1/2
Z 1
3/4
cos(2πx) cos(2nπx) dx
(5.6.34)
= −2(−1)n
π(n2 −1) cos
nπ
2

,
(5.6.35)
if n ≥2. Therefore,
f(η) = 1
π + 1
2 cos(2πη) −2
π
∞
X
n=1
(−1)n
4n2 −1 cos(4nπη).
(5.6.36)
From the method of undetermined coeﬃcients, the particular solution is
yp(η) = 1
2a0 + a1 cos(2πη) + b1 sin(2πη) +
∞
X
n=1
a2n cos(4nπη) + b2n sin(4nπη),
(5.6.37)
which yields
y′
p(η) = −2πa1 sin(2πη) + 2πb1 cos(2πη) +
∞
X
n=1
[−4nπa2n sin(4nπη) + 4nπb2n cos(4nπη)],
(5.6.38)
and
y′′
p(η) = −4π2[a1 cos(2πη) + b1 sin(2πη)] −
∞
X
n=1
16n2π2[a2n cos(4nπη) + b2n sin(4nπη)].
(5.6.39)
Substituting into Equation 5.6.30,
−1
2ρ2
0a0 −A0
π +

−4π2a1 + 4πρ0ν0b1 −ρ2
0a1 −A0
2

cos(2πη)
+
 −4π2b1 −4πρ0ν0a1 −ρ2
0b1

sin(2πη)
+
∞
X
n=1

−16n2π2a2n + 8nπρ0ν0b2n −ρ2
0a2n + 2A0(−1)n
π(4n2 −1)

cos(4nπη)
+
∞
X
n=1
 −16n2π2b2n −8nπρ0ν0a2n −ρ2
0b2n

sin(4nπη) = 0.
(5.6.40)
To satisfy Equation 5.6.40 for any η, we set
a0 = −2A0
πρ2
0
,
(5.6.41)
−(4π2 + ρ2
0)a1 + 4πρ0ν0b1 = A0
2 ,
(5.6.42)
4πρ0ν0a1 + (4π2 + ρ2
0)b1 = 0,
(5.6.43)
(16n2π2 + ρ2
0)a2n −8nπρ0ν0b2n = 2A0(−1)n
π(4n2 −1),
(5.6.44)

Fourier Series
223
Figure 5.6.1: Temperature distribution along the equator of a spinning spherical satellite. (From Hrycak,
P., 1963: Temperature distribution in a spinning spherical space vehicle. AIAA J., 1, 97.
c⃝1963 AIAA,
reprinted with permission.)
and
8nπρ0ν0a2n + (16n2π2 + ρ2
0)b2n = 0,
(5.6.45)
or
[16π2ρ2
0ν2
0 + (4π2 + ρ2
0)2]a1 = −(4π2 + ρ2
0)A0
2
,
(5.6.46)
[16π2ρ2
0ν2
0 + (4π2 + ρ2
0)2]b1 = 2πρ0ν0A0,
(5.6.47)
[64n2π2ρ2
0ν2
0 + (16n2π2 + ρ2
0)2]a2n = 2A0(−1)n(16n2π2 + ρ2
0)
π(4n2 −1)
,
(5.6.48)
and
[64n2π2ρ2
0ν2
0 + (16n2π2 + ρ2
0)2]b2n = −16(−1)nρ0ν0nA0
4n2 −1
.
(5.6.49)
Substituting for a0, a1, b1, a2n, and b2n, the particular solution is
yp(η)= −A0
πρ2
0
−
(4π2 + ρ2
0)A0 cos(2πη)
2[(4π2 + ρ2
0)2 + 16π2ρ2
0ν2
0] +
2πρ0ν0A0 sin(2πη)
(4π2 + ρ2
0)2 + 16π2ρ2
0ν2
0
+ 2A0
π
∞
X
n=1
(−1)n(16n2π2 + ρ2
0) cos(2nπη)
(4n2 −1)[64n2π2ρ2
0ν2
0 + (16n2π2 + ρ2
0)2]
−16ρ0ν0A0
∞
X
n=1
(−1)nn sin(2nπη)
(4n2 −1)[64n2π2ρ2
0ν2
0 + (16n2π2 + ρ2
0)2].
(5.6.50)
Figure 5.6.1 is from Hrycak’s paper and shows the variation of the nondimensional
temperature as a function of η for the spinning rate ν0. The other parameters are typical
of a satellite with aluminum skin and fully covered with glass-protected solar cells.
As
1.6 
I 
I 
I 
I 
I 
I 
-- SOLUTION OF LiNEARIZED EQUATION 
1.5 ______.,. I 
r--
._ __ EXACT SOLUTION CONDUCTION, 
1.4 
DISREGAROED 
I 
I 
-
{J = I THROUGHOUT 
I' • 23.7 
1.3 
1.2 
8 1.1 
t-
·~ 1.0 
Ooll 
0.8 
~ 
U0=0.370~ ~ 
~ 
;! 
' 
lj /'u0=20 
~ 
u0•0 
~ 
"'-u0•a> 
,~ 
···- z _/ 
..._u0=o-
\.._ -- -
-_-:: 
0.7 
-· 
0.6 
0 
0.1 
0.2 
0.3 
0.4 0.5 0.6 
0.7 
0.8 
0.9 
1.0 
"1 

224
Advanced Engineering Mathematics with MATLAB
a check on the solution, we show the temperature ﬁeld (the dashed line) of a nonrotating
satellite where we neglect the eﬀects of conduction and only radiation occurs. The diﬀerence
between the ν0 = 0 solid and dashed lines arises primarily due to the linearization of the
nonlinear radiation boundary condition during the derivation of the governing equations.
Problems
Solve the following ordinary diﬀerential equations by Fourier series if the forcing is given
by the periodic function
f(t) =
 1,
0 < t < π,
0,
π < t < 2π,
and f(t) = f(t + 2π):
1. y′′ −y = f(t),
2. y′′ + y = f(t),
3. y′′ −3y′ + 2y = f(t).
Solve the following ordinary diﬀerential equations by complex Fourier series if the forcing is
given by the periodic function
f(t) = |t|,
−π ≤t ≤π,
and f(t) = f(t + 2π):
4. y′′ −y = f(t),
5. y′′ + 4y = f(t).
6. An object radiating into its nocturnal surrounding has a temperature y(t) governed by
the equation19
dy
dt + ay = A0 +
∞
X
n=1
An cos(nωt) + Bn sin(nωt),
where the constant a is the heat loss coeﬃcient and the Fourier series describes the temporal
variation of the atmospheric air temperature and the eﬀective sky temperature. If y(0) = T0,
ﬁnd y(t).
7. The equation that governs the charge q on the capacitor of an LRC electrical circuit is
q′′ + 2αq′ + ω2q = ω2E,
where α = R/(2L), ω2 = 1/(LC), R denotes resistance, C denotes capacitance, L denotes
the inductance, and E is the electromotive force driving the circuit. If E is given by
E =
∞
X
n=−∞
ϕneinω0t,
ﬁnd q(t).
8. Use Fourier series to ﬁnd the particular solution20 of the ordinary diﬀerential equation
y′′(x) + k2y(x) = −k2VL

1,
0 < x < λ/4,
−1,
λ/4 < x < λ/2,
19 See Sodha, M. S., 1982: Transient radiative cooling. Solar Energy, 28, 541.
20 See Chabert, P., J. L. Raimbault, J. M. Rax, and M. A. Lieberman, 2004: Self-consistent nonlinear
transmission line model of standing wave eﬀects in a capacitive discharge. Phys. Plasmas, 11, 1775–1785.

Fourier Series
225
where k, VL and λ are constants. Extend the forcing function as an even function into the
interval (−λ/2, 0).
5.7 FINITE FOURIER SERIES
In many applications we must construct a Fourier series from values given by data or
a graph. Unlike the situation with analytic formulas where we have an inﬁnite number of
data points and, consequently, an inﬁnite number of terms in the Fourier series, the Fourier
series contains a ﬁnite number of sines and cosines where the number of coeﬃcients equals
the number of data points.
Assuming that these series are useful, the next question is how do we ﬁnd the Fourier
coeﬃcients? We could compute them by numerically integrating Equation 5.1.6. However,
the results would suﬀer from the truncation errors that aﬄict all numerical schemes. On
the other hand, we can avoid this problem if we again employ the orthogonality properties
of sines and cosines, now in their discrete form. Just as in the case of conventional Fourier
series, we can use these properties to derive formulas for computing the Fourier coeﬃcients.
These results will be exact except for roundoﬀerrors.
We start by deriving some preliminary results. Let us deﬁne xm = mP/(2N). Then,
if k is an integer,
2N−1
X
m=0
exp
2πikxm
P

=
2N−1
X
m=0
exp
kmπi
N

=
2N−1
X
m=0
rm =



1−r2N
1−r
= 0,
r ̸= 1,
2N,
r = 1,
(5.7.1)
because r2N = exp(2πki) = 1 if r ̸= 1. If r = 1, then the sum consists of 2N terms, each
of which equals one. The condition r = 1 corresponds to k = 0, ±2N, ±4N, . . .. Taking the
real and imaginary part of Equation 5.7.1,
2N−1
X
m=0
cos
2πkxm
P

=

0,
k ̸= 0, ±2N, ±4N, . . .,
2N,
k = 0, ±2N, ±4N, . . .,
(5.7.2)
and
2N−1
X
m=0
sin
2πkxm
P

= 0
(5.7.3)
for all k.
Consider now the following sum:
2N−1
X
m=0
cos
2πkxm
P

cos
2πjxm
P

= 1
2
2N−1
X
m=0

cos
2π(k + j)xm
P

+ cos
2π(k −j)xm
P

(5.7.4)
=



0,
|k −j| and |k + m| ̸= 0, 2N, 4N, . . .,
N,
|k −j| or |k + m| ̸= 0, 2N, 4N, . . .,
2N,
|k −j| and |k + m| = 0, 2N, 4N, . . ..
(5.7.5)
Let us simplify the right side of Equation 5.7.5 by restricting ourselves to k+j lying between
0 to 2N. This is permissible because of the periodic nature of this equation. If k + j = 0,
k = j = 0; if k+j = 2N, k = j = N. In either case, k−j = 0 and the right side of Equation
5.7.5 equals 2N. Consider now the case k ̸= j. Then k + j ̸= 0 or 2N and k −j ̸= 0 or 2N.

226
Advanced Engineering Mathematics with MATLAB
The right side of this equaton must equal 0. Finally, if k = j ̸= 0 or N, then k + j ̸= 0 or
2N but k −j = 0 and the right side of this equation equals N. In summary,
2N−1
X
m=0
cos
2πkxm
P

cos
2πjxm
P

=
( 0,
k ̸= j
N,
k = j ̸= 0, N
2N,
k = j = 0, N.
(5.7.6)
In a similar manner,
2N−1
X
m=0
cos
2πkxm
P

sin
2πjxm
P

= 0
(5.7.7)
for all k and j and
2N−1
X
m=0
sin
2πkxm
P

sin
2πjxm
P

=
( 0,
k ̸= j
N,
k = j ̸= 0, N,
0,
k = j = 0, N.
(5.7.8)
Armed with these equations we are ready to ﬁnd the coeﬃcients An and Bn of the
ﬁnite Fourier series,
f(x) = A0
2 +
N−1
X
k=1

Ak cos
2πkx
P

+ Bk sin
2πkx
P

+ AN
2 cos
2πNx
P

,
(5.7.9)
where we have 2N data points and now deﬁne P as the period of the function.
To ﬁnd Ak we proceed as before and multiply Equation 5.7.9 by cos(2πjx /P) (j may
take on values from 0 to N) and sum from 0 to 2N −1. At the point x = xm,
2N−1
X
m=0
f(xm) cos
2πj
P xm

= A0
2
2N−1
X
m=0
cos
2πj
P xm

+
N−1
X
k=1
Ak
2N−1
X
m=0
cos
2πk
P xm

cos
2πj
P xm

+
N−1
X
k=1
Bk
2N−1
X
m=0
sin
2πk
P xm

cos
2πj
P xm

+ AN
2
2N−1
X
m=0
cos
2πN
P
xm

cos
2πj
P xm

.
(5.7.10)
If j ̸= 0 or N, then the ﬁrst summation on the right side vanishes by Equation 5.7.2, the
third by Equation 5.7.8, and the fourth by Equation 5.7.6. The second summation does not
vanish if k = j and equals N. Similar considerations lead to the formulas for the calculation
of Ak and Bk:
Ak = 1
N
2N−1
X
m=0
f(xm) cos
2πk
P xm

,
k = 0, 1, 2, . . . , N,
(5.7.11)
and
Bk = 1
N
2N−1
X
m=0
f(xm) sin
2πk
P xm

,
k = 1, 2, . . . , N −1.
(5.7.12)

Fourier Series
227
Table 5.7.1: The Depth of Water in the Harbor at Buﬀalo, NY (Minus the Low-Water
Datum of 568.8 ft) on the 15th Day of Each Month During 1977
mo
n
depth
mo
n
depth
mo
n
depth
Jan
1
1.61
May
5
3.16
Sep
9
2.42
Feb
2
1.57
Jun
6
2.95
Oct
10
2.95
Mar
3
2.01
Jul
7
3.10
Nov
11
2.74
Apr
4
2.68
Aug
8
2.90
Dec
12
2.63
If there are 2N +1 data points and f(x0) = f(x2N), then Equation 5.7.11 and Equation
5.7.12 are still valid and we need only consider the ﬁrst 2N points. If f(x0) ̸= f(x2N), we can
still use our formulas if we require that the endpoints have the value of [f(x0) + f(x2N)]/2.
In this case the formulas for the coeﬃcients Ak and Bk are
Ak = 1
N
"
f(x0) + f(x2N)
2
+
2N−1
X
m=1
f(xm) cos
2πk
P xm
#
,
(5.7.13)
where k = 0, 1, 2, . . . , N, and
Bk = 1
N
2N−1
X
m=1
f(xm) sin
2πk
P xm

,
(5.7.14)
where k = 1, 2, . . . , N −1.
It is important to note that 2N data points yield 2N Fourier coeﬃcients Ak and Bk.
Consequently our sampling frequency will always limit the amount of information, whether
in the form of data points or Fourier coeﬃcients. It might be argued that from the Fourier
series representation of f(t) we could ﬁnd the value of f(t) for any given t, which is more
than we can do with the data alone. This is not true. Although we can calculate f(t) at any
t using the ﬁnite Fourier series, the values may or may not be correct since the constraint on
the ﬁnite Fourier series is that the series must ﬁt the data in a least-squared sense. Despite
the limitations imposed by only having a ﬁnite number of Fourier coeﬃcients, the Fourier
analysis of ﬁnite data sets yields valuable physical insights into the processes governing
many physical systems.
• Example 5.7.1: Water depth at Buﬀalo, NY
Each entry21 in Table 5.7.1 gives the observed depth of water at Buﬀalo, NY (minus the
low-water datum of 568.6 ft) on the 15th of the corresponding month during 1977. Assuming
that the water level is a periodic function of 1 year, and that we took the observations at
equal intervals, let us construct a ﬁnite Fourier series from these data. This corresponds to
computing the Fourier coeﬃcients A0, A1, . . . , A6, B1, . . . , B5, which give the mean level and
harmonic ﬂuctuations of the depth of water, the harmonics having the periods 12 months,
6 months, 4 months, and so forth.
21 National Ocean Survey, 1977: Great Lakes Water Level, 1977, Daily and Monthly Average Water
Surface Elevations. National Oceanic and Atmospheric Administration.

228
Advanced Engineering Mathematics with MATLAB
In this problem, P equals 12 months, N = P/2 = 6 mo, and xm = mP/(2N) =
m(12 mo)/12 mo = m.
That is, there should be a data point for each month.
From
Equation 5.7.11 and Equation 5.7.12,
Ak = 1
6
11
X
m=0
f(xm) cos
mkπ
6

,
k = 0, 1, 2, 3, 4, 5, 6,
(5.7.15)
and
Bk = 1
6
11
X
m=0
f(xm) sin
mkπ
6

,
k = 1, 2, 3, 4, 5.
(5.7.16)
Substituting the data into these equations yields
A0
= twice the mean level
= +5.120 ft
A1
= harmonic component with a period of
12
mo
= −0.566 ft
B1
= harmonic component with a period of
12
mo
= −0.128 ft
A2
= harmonic component with a period of
6
mo
= −0.177 ft
B2
= harmonic component with a period of
6
mo
= −0.372 ft
A3
= harmonic component with a period of
4
mo
= −0.110 ft
B3
= harmonic component with a period of
4
mo
= −0.123 ft
A4
= harmonic component with a period of
3
mo
= +0.025 ft
B4
= harmonic component with a period of
3
mo
= +0.052 ft
A5
= harmonic component with a period of
2.4
mo
= −0.079 ft
B5
= harmonic component with a period of
2.4
mo
= −0.131 ft
A6
= harmonic component with a period of
2
mo
= −0.107 ft
Figure 5.7.1 is a plot of our results using Equation 5.7.9. Note that when we include
all of the harmonic terms, the ﬁnite Fourier series ﬁts the data points exactly. The values
given by the series at points between the data points may be right or they may not. To
illustrate this, we also plotted the values for the ﬁrst of each month. Sometimes the values
given by the Fourier series and these intermediate data points are quite diﬀerent.
Let us now examine our results in terms of various physical processes. In the long
run the depth of water in the harbor at Buﬀalo, NY depends upon the three-way balance
between precipitation, evaporation, and inﬂow-outﬂow of any rivers. Because the inﬂow and
outﬂow of the rivers depends strongly upon precipitation, and evaporation is of secondary
importance, the water level should correlate with the precipitation rate. It is well known
that more precipitation falls during the warmer months rather than the colder months.
The large amplitude of the Fourier coeﬃcient A1 and B1, corresponding to the annual cycle
(k = 1), reﬂects this.
Another important term in the harmonic analysis corresponds to the semiannual cycle
(k = 2).
During the winter months around Lake Ontario, precipitation falls as snow.
Therefore, the inﬂow from rivers is greatly reduced. When spring comes, the snow and ice
melt and a jump in the water level occurs. Because the second harmonic gives periodic
variations associated with seasonal variations, this harmonic is absolutely necessary if we
want to get the correct answer while the higher harmonics do not represent any speciﬁc
physical process.
⊓⊔
• Example 5.7.2: Numerical computation of Fourier coeﬃcients
At the beginning of this chapter, we showed how you could compute the Fourier coeﬃ-
cients a0, an, and bn from Equation 5.1.6 given a function f(t). All of this assumed that you

Fourier Series
229
1.0
1.5
2.0
2.5
3.0
3.5
4.0
water level
1.0
1.5
2.0
2.5
3.0
3.5
4.0
water level
mean plus first harmonic
mean plus first two harmonics
1.0
1.5
2.0
2.5
3.0
3.5
4.0
4.5
5.0
water level
1.0
1.5
2.0
2.5
3.0
3.5
4.0
water level
J
F
mean plus first three harmonics
mean plus all of the harmonics
M A
M
J
J
A
S
O
N
D
Figure 5.7.1: Partial sums of the ﬁnite Fourier series for the depth of water in the harbor of Buﬀalo, NY
during 1977. Circles indicate observations on the 15th of the month; crosses are observations on the ﬁrst.
could carry out the integrations. What do you do if you cannot perform the integrations?
The obvious solution is perform it numerically. In this section we showed that the best
approximation to Equation 5.1.6 is given by Equation 5.7.11 and Equation 5.7.12. In the
case when we have f(t) this is still true but we may choose N as large as necessary to obtain
the desired number of Fourier coeﬃcients.
To illustrate this we have redone Example 5.1.1 and plotted the exact (analytic) and

230
Advanced Engineering Mathematics with MATLAB
0
2
4
6
8
10
12
14
−1
0
1
2
an
0
2
4
6
8
10
12
14
−0.5
0
0.5
1
n
bn
Figure 5.7.2: The computation of Fourier coeﬃcients using a ﬁnite Fourier series when f(t) is given by
Equation 5.1.8. The circles give an and bn as computed from Equation 5.1.9, Equation 5.1.10, and Equation
5.1.11. The crosses give the corresponding Fourier coeﬃcients given by the ﬁnite Fourier series with N = 15.
numerically computed Fourier coeﬃcients in Figure 5.7.2. This ﬁgure was created using the
MATLAB script
clear;
N = 15, M = 2*N; dt = 2*pi/M; % number of points in interval
% create time points assuming x(t) = x(t+period)
t = [-pi:dt:pi-dt];
%
f = zeros(size(t)); % initialize function f(t)
for k = 1:length(t) % construct function f(t)
if t(k) < 0; f(k) = 0; else f(k) = t(k); end; end;
%
% compute Fourier coefficients using fast Fourier transform
%
fourier = fft(f) / N;
a 0 comp = real(fourier(1)); sign = 1;
for n = 2:N;
a n comp(n-1) = - sign * real(fourier(n));
b n comp(n-1) = sign * imag(fourier(n));
sign = - sign;
end
%
% plot comparisons
%
NN = linspace(0,N-1,N);
exact coeff(1) = pi/2;
numer coeff(1) = a 0 comp;

Fourier Series
231
for n = 1:N-1;
exact coeff(n+1) = ((-1)^n-1) / (pi*(2*n-1)^2);
numer coeff(n+1) = a n comp(n);
end;
subplot(2,1,1),plot(NN,exact coeff,’o’,NN,numer coeff,’kx’)
ylabel(’a n’,’Fontsize’,20)
clear exact coeff numer coeff
NN = linspace(1,N-1,N-1);
for n = 1:N-1;
exact coeff(n) = -(-1)^n/n; numer coeff(n) = b n comp(n);
end;
subplot(2,1,2), plot(NN,exact coeff,’o’,NN,numer coeff,’kx’)
xlabel(’n’,’Fontsize’,20); ylabel(’b n’,’Fontsize’,20);
It shows that a relative few data points can yield quite reasonable answers.
Let us examine this script a little closer. One of the ﬁrst things that you will note is
that there is no explicit reference to Equation 5.7.11 and Equation 5.7.12. How did we get
the correct answer?
Although we could have coded Equation 5.7.11 and Equation 5.7.12, no one does that
any more.
In the 1960s, J. W. Cooley and J. W. Tukey22 devised an incredibly clever
method of performing these calculations.
This method, commonly called a fast Fourier
transform or FFT, is so popular that all computational packages contain it as an intrinsic
function and MATLAB is no exception, calling it fft. This is what has been used here.
Although we now have an fft to compute the coeﬃcients, this routine does not directly
give the coeﬃcients an and bn but rather some mysterious (complex) number that is related
to an + ibn. This is a common problem in using a package’s FFT rather than your own
and why the script divides by N and we keep changing the sign. The best method for
discovering how to extract the coeﬃcients an and bn is to test it with a dataset created by
a simple, ﬁnite series such as
f(x) = 20 + cos(t) + 3 sin(t) + 6 cos(2t) −20 sin(2t) −10 cos(3t) −30 sin(3t).
(5.7.17)
If the code is correct, it must give back the coeﬃcient in Equation 5.7.17 to within round-oﬀ.
Otherwise, something is wrong.
Finally, most FFTs assume that the dataset will start repeating after the ﬁnal data
point. Therefore, when reading in the dataset, the point corresponding to x = L must be
excluded.
⊓⊔
• Example 5.7.3: Aliasing
In the previous example, we could only resolve phenomena with a period of 2 months
or greater although we had data for each of the 12 months. This is an example of Nyquist’s
sampling criteria:23 At least two samples are required to resolve the highest frequency in a
periodically sampled record.
Figure 5.7.3 will help explain this phenomenon. In case (a) we have quite a few data
points over one cycle. Consequently our picture, constructed from data, is fairly good. In
22 Cooley, J. W., and J. W. Tukey, 1965: An algorithm for machine calculation of complex Fourier series.
Math. Comput., 19, 297–301.
23 Nyquist, H., 1928: Certain topics in telegraph transmission theory. AIEE Trans., 47, 617–644.

232
Advanced Engineering Mathematics with MATLAB
instrument data points
(a)
(b)
(c)
real world
Figure 5.7.3: The eﬀect of sampling in the representation of periodic functions.
0
50
100
150
200
time (days)
−4.0
−2.0
0.0
2.0
4.0
6.0
sealevel (feet)
Figure 5.7.4: The sea elevation at the mouth of the Chesapeake Bay from its average depth as a function
of time after 1 July 1985.
case (b), we took only samples at the ridges and troughs of the wave. Although our picture
of the real phenomenon is poor, at least we know that there is a wave. From this picture
we see that even if we are lucky enough to take our observations at the ridges and troughs
of a wave, we need at least two data points per cycle (one for the ridge, the other for the
trough) to resolve the highest-frequency wave.
In case (c) we have made a big mistake. We have taken a wave of frequency N Hz and
misrepresented it as a wave of frequency N/2 Hz. This misrepresentation of a high-frequency
wave by a lower-frequency wave is called aliasing.
It arises because we are sampling a
continuous signal at equal intervals. By comparing cases (b) and (c), we see that there is

Fourier Series
233
1
10
100
1000
10000
0.1
1.0
10.0
100.0
1000.0
10000.0
amplitude spectrum (ft) times 10000
Bay bridge and tunnel
1
10
100
1000
10000
period (hours)
1
10
100
1000
10000
amplitude spectrum (ft) times 10000
Baltimore harbor
Figure 5.7.5: The amplitude of the Fourier coeﬃcients for the sea elevation at the Chesapeake Bay bridge
and tunnel (top) and Baltimore harbor (bottom) as a function of period.
a cutoﬀbetween aliased and nonaliased frequencies. This frequency is called the Nyquist
or folding frequency. It corresponds to the highest frequency resolved by our ﬁnite Fourier
analysis.
Because most periodic functions require an inﬁnite number of harmonics for their rep-
resentation, aliasing of signals is a common problem. Thus the question is not “can I avoid
aliasing?” but “can I live with it?” Quite often, we can construct our experiments to say
yes. An example where aliasing is unavoidable occurs in a Western at the movies when
we see the rapidly rotating spokes of the stagecoach’s wheel. A movie is a sampling of
continuous motion where we present the data as a succession of pictures. Consequently, a
ﬁlm aliases the high rate of revolution of the stagecoach’s wheel in such a manner so that
it appears to be stationary or rotating very slowly.
⊓⊔

234
Advanced Engineering Mathematics with MATLAB
0
50
100
150
200
time (days)
−2.0
−1.0
0.0
1.0
2.0
3.0
sea−level (feet)
Figure 5.7.6: Same as Figure 5.7.4 but with the tides removed.
• Example 5.7.4: Spectrum of the Chesapeake Bay
For our ﬁnal example, we perform a Fourier analysis of hourly sea-level measurements
taken at the mouth of the Chesapeake Bay during the 2000 days from 9 April 1985 to 29
June 1990. Figure 5.7.4 shows 200 days of this record, starting from 1 July 1985. As this
ﬁgure shows, the measurements contain a wide range of oscillations. In particular, note the
large peak near day 90 that corresponds to the passage of Hurricane Gloria during the early
hours of 27 September 1985.
Utilizing the entire 2000 days, we plotted the amplitude of the Fourier coeﬃcients as
a function of period in Figure 5.7.5. We see a general rise of the amplitude as the period
increases. Especially noteworthy are the sharp peaks near periods of 12 and 24 hours. The
largest peak is at 12.417 hours and corresponds to the semidiurnal tide. Thus, our Fourier
analysis shows that the dominant oscillations at the mouth of the Chesapeake Bay are the
tides.
A similar situation occurs in Baltimore harbor.
Furthermore, with this spectral
information we could predict high and low tides very accurately.
Although the tides are of great interest to some, they are a nuisance to others because
they mask other physical processes that might be occurring. For that reason we would like
to remove them from the tidal gauge history and see what is left. One way would be to
zero out the Fourier coeﬃcients corresponding to the tidal components and then plot the
resulting Fourier series. Another method is to replace each hourly report with an average
of hourly reports that occurred 24 hours ahead of and behind a particular report.
We
construct this average in such a manner that waves with periods of the tides sum to zero.24
Such a ﬁlter is a popular method for eliminating unwanted waves from a record. Filters
play an important role in the analysis of data. We plotted the ﬁltered sea level data in
Figure 5.7.6. Note that summertime (0–50 days) produces little variation in the sea level
compared to wintertime (100–150 days) when intense coastal storms occur.
24 See Godin, G., 1972: The Analysis of Tides. University of Toronto Press, Section 2.1.

Fourier Series
235
0
1000
2000
3000
4000
topography
0
50
100
150
200
amplitude spectrum      
28S
28S
−180−120 −60
0
60
120 180
longitude
0
1000
2000
3000
topography
0
1000
2000
3000
4000
5000
6000
topography
0
10
20
30
40
50
zonal wavenumber
0
100
200
300
400
amplitude spectrum     
0
200
400
600
amplitude spectrum    
36N
66N
36N
66N
Figure 5.7.7: The orography of the earth and its spectrum in meters along three latitude belts using a
topography dataset with a resolution of 1.25◦longitude.
Problems
Find the ﬁnite Fourier series for the following pieces of data:
1. f(0) = 0, f(1) = 1, f(2) = 2, f(3) = 3, and N = 2.
2. f(0) = 1, f(1) = 1, f(2) = −1, f(3) = −1, and N = 2.

236
Advanced Engineering Mathematics with MATLAB
Project: Spectrum of the Earth’s Orography
Table 5.7.2 gives the orographic height of the earth’s surface used in an atmospheric
general circulation model (GCM) at a resolution of 2.5◦longitude along the latitude belts
of 28◦S, 36◦N, and 66◦N. In this project you will ﬁnd the spectrum of this orographic ﬁeld
along the various latitude belts.
Step 1: Write a MATLAB script that reads in the data and ﬁnd An and Bn and then
construct the amplitude spectra for this data.
Step 2: Construct several spectra by using every data point, every other data point, etc.
How do the magnitudes of the Fourier coeﬃcient change? You might like to read about
leakage from a book on harmonic analysis.25
Step 3: Compare and contrast the spectra from the various latitude belts. How do the
magnitudes of the Fourier coeﬃcients decrease with n? Why are there these diﬀerences?
Step 4: You may have noted that some of the heights are negative, even in the middle of
the ocean! Take the original data (for any latitude belt) and zero out all of the negative
heights. Find the spectra for this new data set. How have the spectra changed? Is there a
reason why the negative heights were introduced?
Further Readings
Carslaw, H. S., 1950: An Introduction to the Theory of Fourier’s Series and Integrals.
Dover, 368 pp. A classic treatment of the Fourier technique.
Tolstov, Georgi P., 1976: Fourier Series. Dover, 336 pp. This book covers the basic theory
of Fourier series and its use in mathematical physics.
25 For example, Bloomﬁeld, P., 1976: Fourier Analysis of Time Series: An Introduction. John Wiley &
Sons, 258 pp.

Fourier Series
237
Table 5.7.2: Orographic Heights (in m) Times the Gravitational Acceleration Constant
(g = 9.81 m/s2) along Three Latitude Belts
Longitude
28◦S
36◦N
66◦N
Longitude
28◦S
36◦N
66◦N
−180.0
4.
3.
2532.
−82.5
36.
4047.
737.
−177.5
1.
−2.
1665.
−80.0
−64.
3938.
185.
−175.0
1.
2.
1432.
−77.5
138.
1669.
71.
−172.5
1.
−3.
1213.
−75.0
−363.
236.
160.
−170.0
1.
1.
501.
−72.5
4692.
31.
823.
−167.5
1.
−3.
367.
−70.0
19317.
−8.
1830.
−165.0
1.
1.
963.
−67.5
21681.
0.
3000.
−162.5
0.
0.
1814.
−65.0
9222.
−2.
3668.
−160.0
−1.
6.
2562.
−62.5
1949.
−2.
2147.
−157.5
0.
1.
3150.
−60.0
774.
0.
391.
−155.0
0.
3.
4008.
−57.5
955.
5.
−77.
−152.5
1.
−2.
4980.
−55.0
2268.
6.
601.
−150.0
−1.
4.
6011.
−52.5
4636.
−1.
3266.
−147.5
6.
−1.
6273.
−50.0
4621.
2.
9128.
−145.0
14.
3.
5928.
−47.5
1300.
−4.
17808.
−142.5
6.
−1.
6509.
−45.0
−91.
1.
22960.
−140.0
−2.
6.
7865.
−42.5
57.
−1.
20559.
−137.5
0.
3.
7752.
−40.0
−25.
4.
14296.
−135.0
−2.
5.
6817.
−37.5
13.
−1.
9783.
−132.5
1.
−2.
6272.
−35.0
−10.
6.
5969.
−130.0
−2.
0.
5582.
−32.5
8.
2.
1972.
−127.5
0.
5.
4412.
−30.0
−4.
22.
640.
−125.0
−2.
423.
3206.
−27.5
6.
33.
379.
−122.5
1.
3688.
2653.
−25.0
−2.
39.
286.
−120.0
−3.
10919.
2702.
−22.5
3.
2.
981.
−117.5
2.
16148.
3062.
−20.0
−3.
11.
1971.
−115.0
−3.
17624.
3344.
−17.5
1.
−6.
2576.
−112.5
7.
18132.
3444.
−15.0
−1.
19.
1692.
−110.0
12.
19511.
3262.
−12.5
0.
−18.
357.
−107.5
9.
22619.
3001.
−10.0
−1.
490.
−21.
−105.0
−5.
20273.
2931.
−7.5
0.
2164.
−5.
−102.5
3.
12914.
2633.
−5.0
1.
4728.
−10.
−100.0
−5.
7434.
1933.
−2.5
0.
5347.
0.
−97.5
6.
4311.
1473.
0.0
4.
2667.
−6.
−95.0
−8.
2933.
1689.
2.5
−5.
1213.
−1.
−92.5
8.
2404.
2318.
5.0
7.
1612.
−31.
−90.0
−12.
1721.
2285.
7.5
−13.
1744.
−58.
−87.5
18.
1681.
1561.
10.0
28.
1153.
381.
−85.0
−23.
2666.
1199.
12.5
107.
838.
2472.
15.0
2208.
1313.
5263.
97.5
0.
35538.
6222.
17.5
6566.
862.
5646.
100.0
−2.
31985.
5523.
20.0
9091.
1509.
3672.
102.5
0.
23246.
4823.
22.5
10690.
2483.
1628.
105.0
−4.
17363.
4689.
25.0
12715.
1697.
889.
107.5
2.
14315.
4698.

238
Advanced Engineering Mathematics with MATLAB
Table 5.7.2, contd.: Orographic Heights (in m) Times the Gravitational Acceleration
Constant (g = 9.81 m/s2) along Three Latitude Belts
Longitude
28◦S
36◦N
66◦N
Longitude
28◦S
36◦N
66◦N
27.5
14583.
3377.
1366.
110.0
−17.
12639.
4674.
30.0
11351.
7682.
1857.
112.5
302.
10543.
4435.
32.5
3370.
9663.
1534.
115.0
1874.
4967.
3646.
35.0
15.
10197.
993.
117.5
4005.
1119.
2655.
37.5
49.
10792.
863.
120.0
4989.
696.
2065.
40.0
−31.
11322.
756.
122.5
4887.
475.
1583.
42.5
20.
13321.
620.
125.0
4445.
1631.
3072.
45.0
−17.
15414.
626.
127.5
4362.
2933.
7290.
47.5
−19.
12873.
836.
130.0
4368.
1329.
8541.
50.0
−18.
6114.
1029.
132.5
3485.
88.
7078.
52.5
6.
2962.
946.
135.0
1921.
598.
7322.
55.0
−2.
4913.
828.
137.5
670.
1983.
9445.
57.5
3.
6600.
1247.
140.0
666.
2511.
10692.
60.0
−3.
4885.
2091.
142.5
1275.
866.
9280.
62.5
2.
3380.
2276.
145.0
1865.
13.
8372.
65.0
−1.
5842.
1870.
147.5
2452.
11.
6624.
67.5
2.
12106.
1215.
150.0
3160.
−4.
3617.
70.0
0.
23032.
680.
152.5
2676.
−1.
2717.
72.5
2.
35376.
531.
155.0
697.
0.
3474.
75.0
−1.
36415.
539.
157.5
−67.
−3.
4337.
77.5
1.
26544.
579.
160.0
25.
3.
4824.
80.0
0.
19363.
554.
162.5
−12.
−1.
5525.
82.5
1.
17915.
632.
165.0
10.
4.
6323.
85.0
−2.
22260.
791.
167.5
−5.
−2.
5899.
87.5
−1.
30442.
1455.
170.0
0.
1.
4330.
90.0
−3.
33601.
3194.
172.5
0.
−4.
3338.
92.5
−1.
30873.
4878.
175.0
4.
3.
3408.
95.0
0.
31865.
5903.
177.5
3.
−1.
3407.

Chapter 6
The Sturm-Liouville Problem
In the next three chapters we will be solving partial diﬀerential equations using the
technique of separation of variables. This technique requires that we expand a piece-wise
continuous function f(x) as a linear sum of eigenfunctions, much as we used sines and
cosines to re-express f(x) in a Fourier series. The purpose of this chapter is to explain and
illustrate these eigenfunction expansions.
6.1 EIGENVALUES AND EIGENFUNCTIONS
Repeatedly, in the next three chapters on partial diﬀerential equations, we will solve
the following second-order linear diﬀerential equation:
d
dx

p(x)dy
dx

+ [q(x) + λr(x)]y = 0,
a ≤x ≤b,
(6.1.1)
together with the boundary conditions:
αy(a) + βy′(a) = 0
and
γy(b) + δy′(b) = 0.
(6.1.2)
In Equation 6.1.1, p(x), q(x), and r(x) are real functions of x; λ is a parameter; and
p(x) and r(x) are functions that are continuous and positive on the interval a ≤x ≤b.
239

240
Advanced Engineering Mathematics with MATLAB
By the time that Charles-Fran¸cois Sturm (1803–1855) met Joseph Liouville in the early 1830s, he
had already gained fame for his work on the compression of ﬂuids and his celebrated theorem on the
number of real roots of a polynomial. An eminent teacher, Sturm spent most of his career teaching
at various Parisian colleges. (Portrait courtesy of the Archives de l’Acad´emie des sciences, Paris.)
Taken together, Equation 6.1.1 and Equation 6.1.2 constitute a regular Sturm-Liouville
problem, named after the French mathematicians Sturm and Liouville1 who ﬁrst studied
these equations in the 1830s. In the case when p(x) or r(x) vanishes at one of the endpoints
of the interval [a, b] or when the interval is of inﬁnite length, the problem becomes a singular
Sturm-Liouville problem.
Consider now the solutions to the regular Sturm-Liouville problem. Clearly there is the
trivial solution y = 0 for all λ. However, nontrivial solutions exist only if λ takes on speciﬁc
values; these values are called characteristic values
or eigenvalues.
The corresponding
nontrivial solutions are called the characteristic! functions or eigenfunctions.
In particular,
we have the following theorems.
Theorem: For a regular Sturm-Liouville problem with p(x) > 0, all of the eigenvalues are
real if p(x), q(x), and r(x) are real functions and the eigenfunctions are diﬀerentiable and
continuous.
Proof : Let y(x) = u(x) + iv(x) be an eigenfunction corresponding to an eigenvalue λ =
1 For the complete history as well as the relevant papers, see L¨utzen, J., 1984: Sturm and Liouville’s
work on ordinary linear diﬀerential equations. The emergence of Sturm-Liouville theory. Arch. Hist. Exact
Sci., 29, 309–376.

The Sturm-Liouville Problem
241
Although educated as an engineer, Joseph Liouville (1809–1882) would devote his life to teaching
pure and applied mathematics in the leading Parisian institutions of higher education. Today he
is most famous for founding and editing for almost 40 years the Journal de Liouville. (Portrait
courtesy of the Archives de l’Acad´emie des sciences, Paris.)
λr + iλi, where λr, λi are real numbers and u(x), v(x) are real functions of x. Substituting
into the Sturm-Liouville equation yields
{p(x)[u′(x) + iv′(x)]}′ + [q(x) + (λr + iλi)r(x)][u(x) + iv(x)] = 0.
(6.1.3)
Separating the real and imaginary parts gives
[p(x)u′(x)]′ + [q(x) + λr]u(x) −λir(x)v(x) = 0,
(6.1.4)
and
[p(x)v′(x)]′ + [q(x) + λr]v(x) + λir(x)u(x) = 0.
(6.1.5)
If we multiply Equation 6.1.4 by v and Equation 6.1.5 by u and subtract the results, we
ﬁnd that
u(x)[p(x)v′(x)]′ −v(x)[p(x)u′(x)]′ + λir(x)[u2(x) + v2(x)] = 0.
(6.1.6)
The derivative terms in Equation 6.1.6 can be rewritten so that it becomes
d
dx {[p(x)v′(x)]u(x) −[p(x)u′(x)]v(x)} + λir(x)[u2(x) + v2(x)] = 0.
(6.1.7)
Integrating from a to b, we ﬁnd that
−λi
Z b
a
r(x)[u2(x) + v2(x)] dx = {p(x)[u(x)v′(x) −v(x)u′(x)]}|b
a .
(6.1.8)
From the boundary conditions, Equation 6.1.2,

242
Advanced Engineering Mathematics with MATLAB
α[u(a) + iv(a)] + β[u′(a) + iv′(a)] = 0,
(6.1.9)
and
γ[u(b) + iv(b)] + δ[u′(b) + iv′(b)] = 0.
(6.1.10)
Separating the real and imaginary parts yields
αu(a) + βu′(a) = 0,
and
αv(a) + βv′(a) = 0,
(6.1.11)
and
γu(b) + δu′(b) = 0,
and
γv(b) + δv′(b) = 0.
(6.1.12)
Both α and β cannot be zero; otherwise, there would be no boundary condition at x = a.
Similar considerations hold for γ and δ. Therefore,
u(a)v′(a) −u′(a)v(a) = 0,
and
u(b)v′(b) −u′(b)v(b) = 0,
(6.1.13)
if we treat α, β, γ, and δ as unknowns in a system of homogeneous equations, Equation
6.1.11 and Equation 6.1.12, and require that the corresponding determinants equal zero.
Applying Equation 6.1.13 to the right side of Equation 6.1.8, we obtain
λi
Z b
a
r(x)[u2(x) + v2(x)] dx = 0.
(6.1.14)
Because r(x) > 0, the integral is positive and λi = 0. Since λi = 0, λ is purely real. This
implies that the eigenvalues are real.
⊓⊔
If there is only one independent eigenfunction for each eigenvalue, that eigenvalue is
simple. When more than one eigenfunction belongs to a single eigenvalue, the problem is
degenerate.
Theorem: The regular Sturm-Liouville problem has inﬁnitely many real and simple eigen-
values λn, n = 0, 1, 2, . . ., which can be arranged in a monotonically increasing sequence
λ0 < λ1 < λ2 < · · · such that limn→∞λn = ∞. Every eigenfunction yn(x) associated
with the corresponding eigenvalue λn has exactly n zeros in the interval (a, b). For each
eigenvalue there exists only one eigenfunction (up to a multiplicative constant).
The proof is beyond the scope of this book but may be found in more advanced treatises.2
⊓⊔
In the following examples we illustrate how to ﬁnd these real eigenvalues and their
corresponding eigenfunctions.
• Example 6.1.1
Let us ﬁnd the eigenvalues and eigenfunctions of
y′′ + λy = 0,
(6.1.15)
2 See, for example, Birkhoﬀ, G., and G.-C. Rota, 1989: Ordinary Diﬀerential Equations. John Wiley &
Sons, Chapters 10 and 11; Sagan, H., 1961: Boundary and Eigenvalue Problems in Mathematical Physics.
John Wiley & Sons, Chapter 5.

The Sturm-Liouville Problem
243
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
x
−1.0
0.0
1.0
2.0
3.0
4.0
y
y=tan( x)
y=x
π
Figure 6.1.1: Graphical solution of tan(πx) = x.
subject to the boundary conditions
y(0) = 0,
and
y(π) −y′(π) = 0.
(6.1.16)
Our ﬁrst task is to check to see whether the problem is indeed a regular Sturm-Liouville
problem. A comparison between Equation 6.1.1 and Equation 6.1.15 shows that they are
the same if p(x) = 1, q(x) = 0, and r(x) = 1. Similarly, the boundary conditions, Equation
6.1.16, are identical to Equation 6.1.2 if α = γ = 1, δ = −1, β = 0, a = 0, and b = π.
Because the form of the solution to Equation 6.1.15 depends on λ, we consider three
cases: λ negative, positive, or equal to zero. The general solution3 of the diﬀerential equation
is
y(x) = A cosh(mx) + B sinh(mx),
if
λ < 0,
(6.1.17)
y(x) = C + Dx,
if
λ = 0,
(6.1.18)
and
y(x) = E cos(kx) + F sin(kx),
if
λ > 0,
(6.1.19)
where for convenience λ = −m2 < 0 in Equation 6.1.17 and λ = k2 > 0 in Equation 6.1.19.
Both k and m are real and positive by these deﬁnitions.
Turning to the condition that y(0) = 0, we ﬁnd that A = C = E = 0. The other
boundary condition y(π) −y(π) = 0 gives
B[sinh(mπ) −m cosh(mπ)] = 0,
(6.1.20)
D = 0,
(6.1.21)
and
F[sin(kπ) −k cos(kπ)] = 0.
(6.1.22)
If we graph sinh(mπ)−m cosh(mπ) for all positive m, this quantity is always negative.
Consequently, B = 0. However, in Equation 6.1.22, a nontrivial solution (i.e., F ̸= 0) occurs
if
F cos(kπ)[tan(kπ) −k] = 0,
or
tan(kπ) = k.
(6.1.23)
3 In many diﬀerential equations courses, the solution to y′′ −m2y = 0, m > 0 is written y(x) = c1emx +
c2e−mx. However, we can rewrite this solution as y(x) = (c1+c2) 1
2(emx+e−mx)+(c1−c2) 1
2 (emx−e−mx) =
A cosh(mx) + B sinh(mx), where cosh(mx) = (emx + e−mx)/2 and sinh(mx) = (emx −e−mx)/2. The
advantage of using these hyperbolic functions over exponentials is the simpliﬁcation that occurs when we
substitute the hyperbolic functions into the boundary conditions.

244
Advanced Engineering Mathematics with MATLAB
0.0 0.5 1.0
1.5 2.0
2.5 3.0
3.5
x
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
2.0
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
2.0
0.0 0.5 1.0
1.5 2.0
2.5 3.0
3.5
x
k   = 3.40918
3
k   = 1.29011
1
k   = 4.42032
4
k   = 2.37305
2
Figure 6.1.2: The ﬁrst four eigenfunctions sin(knx) corresponding to the eigenvalue problem tan(kπ) = k.
In summary, we found nontrivial solutions only when λn = k2
n > 0, where kn is the nth
root of the transcendental equation, Equation 6.1.23. We can ﬁnd the roots either graph-
ically or through the use of a numerical algorithm. Figure 6.1.1 illustrates the graphical
solution to the problem. We exclude the root k = 0 because λ must be greater than zero.
Let us now ﬁnd the corresponding eigenfunctions. Because A = B = C = D = E = 0,
we are left with y(x) = F sin(kx). Consequently, the eigenfunction, traditionally written
without the arbitrary amplitude constant, is
yn(x) = sin(knx),
(6.1.24)
because k must equal kn. Figure 6.1.2 shows the ﬁrst four eigenfunctions.
⊓⊔
• Example 6.1.2
For our second example let us solve the Sturm-Liouville problem,4
y′′ + λy = 0,
(6.1.25)
with the boundary conditions
y(0) −y′(0) = 0,
and
y(π) −y′(π) = 0.
(6.1.26)
Once again the three possible solutions to Equation 6.1.25 are
y(x) = A cosh(mx) + B sinh(mx),
if
λ = −m2 < 0,
(6.1.27)
y(x) = C + Dx,
if
λ = 0,
(6.1.28)
4 Sosov and Theodosiou [Sosov, Y., and C. E. Theodosiou, 2002: On the complete solution of the
Sturm-Liouville problem (d2X/dx2) + λ2X = 0 over a closed interval. J. Math. Phys. (Woodbury, NY),
43, 2831–2843] have analyzed this problem with the general boundary conditions, Equation 6.1.2.

The Sturm-Liouville Problem
245
and
y(x) = E cos(kx) + F sin(kx),
if
λ = k2 > 0.
(6.1.29)
Let us ﬁrst check and see if there are any nontrivial solutions for λ < 0. Two simulta-
neous equations result from the substitution of Equation 6.1.27 into Equation 6.1.26:
A −mB = 0,
(6.1.30)
and
[cosh(mπ) −m sinh(mπ)]A + [sinh(mπ) −m cosh(mπ)]B = 0.
(6.1.31)
The elimination of A between the two equations yields
sinh(mπ)(1 −m2)B = 0.
(6.1.32)
If Equation 6.1.27 is a nontrivial solution, then B ̸= 0, and
sinh(mπ) = 0,
or
m2 = 1.
(6.1.33)
The condition sinh(mπ) = 0 cannot hold because it implies m = λ = 0, which contradicts
the assumption used in deriving Equation 6.1.27 that λ < 0. On the other hand, m2 = 1 is
quite acceptable. It corresponds to the eigenvalue λ = −1 and the eigenfunction is
y0 = cosh(x) + sinh(x) = ex,
(6.1.34)
because it satisﬁes the diﬀerential equation
y′′
0 −y0 = 0,
(6.1.35)
and the boundary conditions
y0(0) −y′
0(0) = 0,
and
y0(π) −y′
0(π) = 0.
(6.1.36)
An alternative method of ﬁnding m, which is quite popular because of its use in more
diﬃcult problems, follows from viewing Equation 6.1.30 and Equation 6.1.31 as a system
of homogeneous linear equations, where A and B are the unknowns. It is well known5 that
for Equation 6.1.30 and Equation 6.1.31 to have a nontrivial solution (i.e., A ̸= 0 and/or
B ̸= 0) the determinant of the coeﬃcients must vanish:

1
−m
cosh(mπ) −m sinh(mπ)
sinh(mπ) −m cosh(mπ)
 = 0.
(6.1.37)
Expanding the determinant,
sinh(mπ)(1 −m2) = 0,
(6.1.38)
which leads directly to Equation 6.1.33.
We consider next the case of λ = 0. Substituting Equation 6.1.28 into Equation 6.1.26,
we ﬁnd that
C −D = 0,
and
C + Dπ −D = 0.
(6.1.39)
5 See Chapter 3.

246
Advanced Engineering Mathematics with MATLAB
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
x
−4
−2
0
2
4
6
0
5
10
15
20
25
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
x
−4
−2
0
2
4
6
−4
−2
0
2
4
6
λ  = −1
λ  = 1
λ  = 4
λ  = 9
0
1
2
3
Figure 6.1.3: The ﬁrst four eigenfunctions for the Sturm-Liouville problem, Equation 6.1.25 and Equation
6.1.26.
This set of simultaneous equations yields C = D = 0 and we have only trivial solutions for
λ = 0.
Finally, we examine the case when λ > 0. Substituting Equation 6.1.29 into Equation
6.1.26, we obtain
E −kF = 0,
(6.1.40)
and
[cos(kπ) + k sin(kπ)]E + [sin(kπ) −k cos(kπ)]F = 0.
(6.1.41)
The elimination of E from Equation 6.1.40 and Equation 6.1.41 gives
F(1 + k2) sin(kπ) = 0.
(6.1.42)
If Equation 6.1.29 is nontrivial, F ̸= 0, and
k2 = −1,
or
sin(kπ) = 0.
(6.1.43)
The condition k2 = −1 violates the assumption that k is real, which follows from the fact
that λ = k2 > 0. On the other hand, we can satisfy sin(kπ) = 0 if k = 1, 2, 3, . . .; a negative
k yields the same λ. Consequently we have the additional eigenvalues λn = n2.
Let us now ﬁnd the corresponding eigenfunctions. Because E = kF, y(x) = F sin(kx)+
Fk cos(kx) from Equation 6.1.29. Thus, the eigenfunctions for λ > 0 are
yn(x) = sin(nx) + n cos(nx).
(6.1.44)
Figure 6.1.3 illustrates some of the eigenfunctions given by Equation 6.1.34 and Equation
6.1.44.
⊓⊔
• Example 6.1.3
Consider now the Sturm-Liouville problem
y′′ + λy = 0,
(6.1.45)

The Sturm-Liouville Problem
247
with
y(π) = y(−π),
and
y′(π) = y′(−π).
(6.1.46)
This is not a regular Sturm-Liouville problem because the boundary conditions are periodic
and do not conform to the canonical boundary condition, Equation 6.1.2.
The general solution to Equation 6.1.45 is
y(x) = A cosh(mx) + B sinh(mx),
if
λ = −m2 < 0,
(6.1.47)
y(x) = C + Dx,
if
λ = 0,
(6.1.48)
and
y(x) = E cos(kx) + F sin(kx),
if
λ = k2 > 0.
(6.1.49)
Substituting these solutions into the boundary condition, Equation 6.1.46,
A cosh(mπ) + B sinh(mπ) = A cosh(−mπ) + B sinh(−mπ),
(6.1.50)
C + Dπ = C −Dπ,
(6.1.51)
and
E cos(kπ) + F sin(kπ) = E cos(−kπ) + F sin(−kπ),
(6.1.52)
or
B sinh(mπ) = 0,
D = 0,
and
F sin(kπ) = 0,
(6.1.53)
because cosh(−mπ) = cosh(mπ), sinh(−mπ) = −sinh(mπ), cos(−kπ) = cos(kπ), and
sin(−kπ) = −sin(kπ). Because m must be positive, sinh(mπ) cannot equal zero and B = 0.
On the other hand, if sin(kπ) = 0 or k = n, n = 1, 2, 3, . . ., we have a nontrivial solution
for positive λ and λn = n2. Note that we still have A, C, E, and F as free constants.
From the boundary condition, Equation 6.1.46,
A sinh(mπ) = A sinh(−mπ),
(6.1.54)
and
−E sin(kπ) + F cos(kπ) = −E sin(−kπ) + F cos(−kπ).
(6.1.55)
The solution y0(x) = C identically satisﬁes the boundary condition, Equation 6.1.46, for
all C. Because m and sinh(mπ) must be positive, A = 0. From Equation 6.1.53, we once
again have sin(kπ) = 0, and k = n. Consequently, the eigenfunction solutions to Equation
6.1.45 and Equation 6.1.46 are
λ0 = 0,
y0(x) = 1,
(6.1.56)
and
λn = n2,
yn(x) =

sin(nx),
cos(nx),
(6.1.57)
and we have a degenerate set of eigenfunctions to the Sturm-Liouville problem, Equation
6.1.45, with the periodic boundary condition, Equation 6.1.46.

248
Advanced Engineering Mathematics with MATLAB
Problems
Find the eigenvalues and eigenfunctions for each of the following:
1. y′′ + λy = 0,
y′(0) = 0,
y(L) = 0
2. y′′ + λy = 0,
y′(0) = 0,
y′(π) = 0
3. y′′ + λy = 0,
y(0) + y′(0) = 0,
y(π) + y′(π) = 0
4. y′′ + λy = 0,
y′(0) = 0,
y(π) −y′(π) = 0
5. y(iv) + λy = 0,
y(0) = y′′(0) = 0,
y(L) = y′′(L) = 0
Find an equation from which you could ﬁnd λ and give the form of the eigenfunction for
each of the following:
6. y′′ + λy = 0,
y(0) + y′(0) = 0,
y(1) = 0
7. y′′ + λy = 0,
y(0) = 0,
y(π) + y′(π) = 0
8. y′′ + λy = 0,
y′(0) = 0,
y(1) −y′(1) = 0
9. y′′ + λy = 0,
y(0) + y′(0) = 0,
y′(π) = 0
10. y′′ + λy = 0,
y(0) + y′(0) = 0,
y(π) −y′(π) = 0
11. Find the eigenvalues and eigenfunctions of the Sturm-Liouville problem
d
dx

xdy
dx

+ λ
xy = 0,
1 ≤x ≤e
for each of the following boundary conditions: (a) u(1) = u(e) = 0, (b) u(1) = u′(e) = 0,
and (c) u′(1) = u′(e) = 0.
Find the eigenvalues and eigenfunctions of the following Sturm-Liouville problems:
12.
x2y′′ + 2xy′ + λy = 0,
y(1) = y(e) = 0,
1 ≤x ≤e
13.
d
dx
 x3y′
+ λxy = 0,
y(1) = y(eπ) = 0,
1 ≤x ≤eπ
14.
d
dx
 1
xy′

+ λ
xy = 0,
y(1) = y(e) = 0,
1 ≤x ≤e
15.
y′′′′ −λ4y = 0,
y′′′(0) = y′′(0) = y′′′(1) = y′(1) = 0,
0 < x < 1

The Sturm-Liouville Problem
249
6.2 ORTHOGONALITY OF EIGENFUNCTIONS
In the previous section we saw how nontrivial solutions to the regular Sturm-Liouville
problem consist of eigenvalues and eigenfunctions. The most important property of eigen-
functions is orthogonality.
Theorem: Let the functions p(x), q(x), and r(x) of the regular Sturm-Liouville problem,
Equation 6.1.1 and Equation 6.1.2, be real and continuous on the interval [a, b]. If yn(x)
and ym(x) are continuously diﬀerentiable eigenfunctions corresponding to the distinct eigen-
values λn and λm, respectively, then yn(x) and ym(x) satisfy the orthogonality condition:
Z b
a
r(x)yn(x)ym(x) dx = 0,
(6.2.1)
if λn ̸= λm.
When Equation 6.2.1 is satisﬁed, the eigenfunctions yn(x) and ym(x) are
said to be orthogonal to each other with respect to the weight function r(x). The term
orthogonality appears to be borrowed from linear algebra where a similar relationship holds
between two perpendicular or orthogonal vectors.
Proof : Let yn(x) and ym(x) denote the eigenfunctions associated with two diﬀerent eigen-
values λn and λm. Then
d
dx

p(x)dyn
dx

+ [q(x) + λnr(x)]yn(x) = 0,
(6.2.2)
d
dx

p(x)dym
dx

+ [q(x) + λmr(x)]ym(x) = 0,
(6.2.3)
and both solutions satisfy the boundary conditions. Let us multiply the ﬁrst diﬀerential
equation by ym; the second by yn. Next, we subtract these two equations and move the
terms containing ynym to the right side. The resulting equation is
yn
d
dx

p(x)dym
dx

−ym
d
dx

p(x)dyn
dx

= (λn −λm)r(x)ynym.
(6.2.4)
Integrating Equation 6.2.4 from a to b yields
Z b
a

yn
d
dx

p(x)dym
dx

−ym
d
dx

p(x)dyn
dx

dx = (λn −λm)
Z b
a
r(x)ynym dx.
(6.2.5)
We can simplify the left side of Equation 6.2.5 by integrating by parts to give
Z b
a

yn
d
dx

p(x)dym
dx

−ym
d
dx

p(x)dyn
dx

dx
= [p(x)y′
myn −p(x)y′
nym]b
a −
Z b
a
p(x)[y′
ny′
m −y′
ny′
m] dx.
(6.2.6)
The second integral equals zero since the integrand vanishes identically. Because yn(x) and
ym(x) satisfy the boundary condition at x = a,
αyn(a) + βy′
n(a) = 0,
(6.2.7)

250
Advanced Engineering Mathematics with MATLAB
and
αym(a) + βy′
m(a) = 0.
(6.2.8)
These two equations are simultaneous equations in α and β. Hence, the determinant of the
equations must be zero:
y′
n(a)ym(a) −y′
m(a)yn(a) = 0.
(6.2.9)
Similarly, at the other end,
y′
n(b)ym(b) −y′
m(b)yn(b) = 0.
(6.2.10)
Consequently, the right side of Equation 6.2.6 vanishes and Equation 6.2.5 reduces to Equa-
tion 6.2.1.
⊓⊔
• Example 6.2.1
Let us verify the orthogonality condition for the eigenfunctions that we found in Ex-
ample 6.1.1.
Because r(x) = 1, a = 0, b = π, and yn(x) = sin(knx), we ﬁnd that
Z b
a
r(x)ynym dx =
Z π
0
sin(knx) sin(kmx) dx
(6.2.11)
= 1
2
Z π
0
{cos[(kn −km)x] −cos[(kn + km)x]} dx
(6.2.12)
= sin[(kn −km)x]
2(kn −km)

π
0
−sin[(kn + km)x]
2(kn + km)

π
0
(6.2.13)
= sin[(kn −km)π]
2(kn −km)
−sin[(kn + km)π]
2(kn + km)
(6.2.14)
= sin(knπ) cos(kmπ) −cos(knπ) sin(kmπ)
2(kn −km)
−sin(knπ) cos(kmπ) + cos(knπ) sin(kmπ)
2(kn + km)
(6.2.15)
= kn cos(knπ) cos(kmπ) −km cos(knπ) cos(kmπ)
2(kn −km)
−kn cos(knπ) cos(kmπ) + km cos(knπ) cos(kmπ)
2(kn + km)
(6.2.16)
= (kn −km) cos(knπ) cos(kmπ)
2(kn −km)
−(kn + km) cos(knπ) cos(kmπ)
2(kn + km)
= 0.
(6.2.17)
We used the relationships kn = tan(knπ), and km = tan(kmπ) to simplify Equation 6.2.15.
Note, however, that if n = m,
Z π
0
sin(knx) sin(knx) dx = 1
2
Z π
0
[1−cos(2knx)] dx = π
2 −sin(2knπ)
4kn
= 1
2[π−cos2(knπ)] > 0,
(6.2.18)

The Sturm-Liouville Problem
251
because sin(2A) = 2 sin(A) cos(A), and kn = tan(knπ). That is, any eigenfunction cannot
be orthogonal to itself.
In closing, we note that had we deﬁned the eigenfunction in our example as
yn(x) =
sin(knx)
p
[π −cos2(knπ)]/2
(6.2.19)
rather than yn(x) = sin(knx), the orthogonality condition would read
Z π
0
yn(x)ym(x) dx =

0,
m ̸= n,
1,
m = n.
(6.2.20)
This process of normalizing an eigenfunction so that the orthogonality condition becomes
Z b
a
r(x)yn(x)ym(x) dx =

0,
m ̸= n,
1,
m = n,
(6.2.21)
generates orthonormal eigenfunctions. We will see the convenience of doing this in the next
section.
Problems
1. The Sturm-Liouville problem y′′+λy = 0, y(0) = y(L) = 0 has the eigenfunction solution
yn(x) = sin(nπx/L). By direct integration, verify the orthogonality condition, Equation
6.2.1.
2. The Sturm-Liouville problem y′′ + λy = 0, y′(0) = y′(L) = 0 has the eigenfunction
solutions y0(x) = 1 and yn(x) = cos(nπx/L). By direct integration, verify the orthogonality
condition, Equation 6.2.1.
3.
The Sturm-Liouville problem y′′ + λy = 0, y(0) = y′(L) = 0 has the eigenfunction
solution yn(x) = sin[(2n −1)πx/(2L)].
By direct integration, verify the orthogonality
condition, Equation 6.2.1.
4.
The Sturm-Liouville problem y′′ + λy = 0, y′(0) = y(L) = 0 has the eigenfunction
solution yn(x) = cos[(2n −1)πx/(2L)].
By direct integration, verify the orthogonality
condition, Equation 6.2.1.
6.3 EXPANSION IN SERIES OF EIGENFUNCTIONS
In calculus we learned that under certain conditions we could represent a function
f(x) by a linear and inﬁnite sum of polynomials (x −x0)n. In this section we show that an
analogous procedure exists for representing a piece-wise continuous function by a linear sum
of eigenfunctions. These eigenfunction expansions will be used in the next three chapters
to solve partial diﬀerential equations.
Let the function f(x) be deﬁned in the interval a < x < b. We wish to re-express f(x)
in terms of the eigenfunctions yn(x) given by a regular Sturm-Liouville problem. Assuming

252
Advanced Engineering Mathematics with MATLAB
that the function f(x) can be represented by a uniformly convergent series,6 we write
f(x) =
∞
X
n=1
cnyn(x).
(6.3.1)
The orthogonality relation, Equation 6.2.1, gives us the method for computing the coeﬃ-
cients cn. First we multiply both sides of Equation 6.3.1 by r(x)ym(x), where m is a ﬁxed
integer, and then integrate from a to b. Because this series is uniformly convergent and
yn(x) is continuous, we can integrate the series term by term, or
Z b
a
r(x)f(x)ym(x) dx =
∞
X
n=1
cn
Z b
a
r(x)yn(x)ym(x) dx.
(6.3.2)
The orthogonality relationship states that all of the terms on the right side of Equation
6.3.2 must disappear except the one for which n = m. Thus, we are left with
Z b
a
r(x)f(x)ym(x) dx = cm
Z b
a
r(x)ym(x)ym(x) dx
(6.3.3)
or
cn =
R b
a r(x)f(x)yn(x) dx
R b
a r(x)y2n(x) dx
,
(6.3.4)
if we replace m by n in Equation 6.3.3.
Usually, both integrals in Equation 6.3.4 are evaluated by direct integration. In the
case when the evaluation of the denominator is very diﬃcult, Lockshin7 has shown that the
denominator of Equation 6.3.4 always equals
Z b
a
r(x)y2(x) dx = p(x)
∂y
∂x
∂y
∂λ −y ∂2y
∂λ∂x

b
a
,
(6.3.5)
for a regular Sturm-Liouville problem with eigenfunction solution y, where p(x), q(x), and
r(x) are continuously diﬀerentiable on the interval [a, b].
The series, Equation 6.3.1, with the coeﬃcients found by Equation 6.3.4, is a generalized
Fourier series of the function f(x) with respect to the eigenfunction yn(x). It is called a
generalized Fourier series because we generalized the procedure of re-expressing a function
f(x) by sines and cosines into one involving solutions to regular Sturm-Liouville problems.
Note that if we had used an orthonormal set of eigenfunctions, then the denominator of
6 If Sn(x) = Pn
k=1 uk(x), S(x) = limn→∞Sn(x), and 0 < |Sn(x) −S(x)| < ǫ for all n > M > 0, the
series P∞
k=1 uk(x) is uniformly convergent if M is dependent on ǫ alone and not x.
7 Lockshin, J. L, 2001: Explicit closed-form expression for eigenfunction norms. Appl. Math. Lett., 14,
553–555.

The Sturm-Liouville Problem
253
Equation 6.3.4 would equal one and we reduce our work by half. The coeﬃcients cn are the
Fourier coeﬃcients.
One of the most remarkable facts about generalized Fourier series is their applicability
even when the function has a ﬁnite number of bounded discontinuities in the range [a, b].
We may formally express this fact by the following theorem:
Theorem: If both f(x) and f ′(x) are piece-wise continuous in a ≤x ≤b, then f(x) can
be expanded in a uniformly convergent Fourier series, Equation 6.3.1, whose coeﬃcients cn
are given by Equation 6.3.4. It converges to [f(x+) + f(x−)]/2 at any point x in the open
interval a < x < b.
The proof is beyond the scope of this book but can be found in more advanced treatises.8
If we are willing to include stronger constraints, we can make even stronger statements about
convergence. For example,9 if we require that f(x) be a continuous function with a piece-
wise continuous ﬁrst derivative, then the eigenfunction expansion, Equation 6.3.1, converges
to f(x) uniformly and absolutely in [a, b] if f(x) satisﬁes the same boundary conditions as
does yn(x).
⊓⊔
In the case when f(x) is discontinuous, we are not merely rewriting f(x) in a new form.
We are actually choosing the coeﬃcients cn so that the eigenfunction expansion ﬁts f(x) in
the “least squares” sense that
Z b
a
r(x)
f(x) −
∞
X
n=1
cnyn(x)

2
dx = 0.
(6.3.6)
Consequently we should expect peculiar things, such as spurious oscillations, to occur in
the neighborhood of the discontinuity. These are Gibbs phenomena,10 the same phenomena
discovered with Fourier series. See Section 5.2.
• Example 6.3.1
To illustrate the concept of an eigenfunction expansion, let us ﬁnd the expansion for
f(x) = x over the interval 0 < x < π using the solution to the regular Sturm-Liouville
problem of
y′′ + λy = 0,
y(0) = y(π) = 0.
(6.3.7)
This problem arises when we solve the wave or heat equation by separation of variables in
the next two chapters.
Because the eigenfunctions are yn(x) = sin(nx), n = 1, 2, 3, . . ., r(x) = 1, a = 0, and
b = π, Equation 6.3.4 yields
cn =
R π
0 x sin(nx) dx
R π
0 sin2(nx) dx = −x cos(nx)/n + sin(nx)/n2π
0
x/2 −sin(2nx)/(4n)|π
0
= −2
n cos(nπ) = −2
n(−1)n.
(6.3.8)
8 For example, Titchmarsh, E. C., 1962: Eigenfunction Expansions Associated with Second-Order Dif-
ferential Equations. Part 1. Oxford University Press, pp. 12–16.
9 Tolstov, G. P., 1962: Fourier Series. Dover Publishers, p. 255.
10 Apparently ﬁrst discussed by Weyl, H., 1910: Die Gibbs’sche Erscheinung in der Theorie der Sturm-
Liouvilleschen Reihen. Rend. Circ. Mat. Palermo, 29, 321–323.

254
Advanced Engineering Mathematics with MATLAB
Equation 6.3.1 then gives
f(x) = −2
∞
X
n=1
(−1)n
n
sin(nx).
(6.3.9)
This particular example is in fact an example of a half-range sine expansion.
Finally we must state the values of x for which Equation 6.3.9 is valid. At x = π the
series converges to zero while f(π) = π. At x = 0 both the series and the function converge
to zero. Hence this series expansion is valid for 0 ≤x < π.
⊓⊔
• Example 6.3.2
For our second example let us ﬁnd the expansion for f(x) = x over the interval 0 ≤
x < π using the solution to the regular Sturm-Liouville problem of
y′′ + λy = 0,
y(0) = y(π) −y′(π) = 0.
(6.3.10)
We will encounter this problem when we solve the heat equation with radiative boundary
conditions by separation of variables.
Because r(x) = 1, a = 0, b = π, and the eigenfunctions are yn(x) = sin(knx), where
kn = tan(knπ), Equation 6.3.4 yields
cn =
R π
0 x sin(knx) dx
R π
0 sin2(knx) dx =
R π
0 x sin(knx) dx
1
2
R π
0 [1 −cos(2knx)] dx = 2 sin(knx)/k2
n −2x cos(knx)/kn
π
0
x −sin(2knx)/(2kn)|π
0
(6.3.11)
= 2 sin(knπ)/k2
n −2π cos(knπ)/kn
π −sin(2knπ)/(2kn)
= 2(1 −π) cos(knπ)/kn
π −cos2(knπ)
,
(6.3.12)
where we used the property that sin(knπ) = kn cos(knπ). Equation 6.3.1 then gives
f(x) = 2(1 −π)
∞
X
n=1
cos(knπ)
kn[π −cos2(knπ)] sin(knx).
(6.3.13)
To illustrate the use of Equation 6.3.5, we note that
y(x) = sin(
√
λ x),
∂y
∂x =
√
λ cos(
√
λ x),
∂y
∂λ =
x
2
√
λ
cos(
√
λ x),
(6.3.14)
and
∂2y
∂λ∂x = ∂2y
∂x∂λ =
1
2
√
λ
cos(
√
λ x) −x
2 sin(
√
λ x).
(6.3.15)
Therefore,
Z π
0
r(x)y2
n(x) dx =
x
2 cos2(knx) −sin(knx)
 1
2kn
cos(knx) −x
2 sin(knx)

π
0
(6.3.16)
=
x
2 −
1
2kn
sin(knx) cos(knx)

π
0
= π
2 −cos2(knπ)
2
.
(6.3.17)
Note that we set λ = λn = k2
n after taking the derivatives with respect to λ.

The Sturm-Liouville Problem
255
Problems
1.
The Sturm-Liouville problem y′′ + λy = 0, y(0) = y(L) = 0 has the eigenfunction
solution yn(x) = sin(nπx/L). Find the eigenfunction expansion for f(x) = x using this
eigenfunction.
2. The Sturm-Liouville problem y′′ + λy = 0, y′(0) = y′(L) = 0 has the eigenfunction
solutions y0(x) = 1, and yn(x) = cos(nπx/L). Find the eigenfunction expansion for f(x) =
x using these eigenfunctions.
3.
The Sturm-Liouville problem y′′ + λy = 0, y(0) = y′(L) = 0 has the eigenfunction
solution yn(x) = sin[(2n−1)πx/(2L)]. Find the eigenfunction expansion for f(x) = x using
this eigenfunction.
4.
The Sturm-Liouville problem y′′ + λy = 0, y′(0) = y(L) = 0 has the eigenfunction
solution yn(x) = cos[(2n −1)πx/(2L)]. Find the eigenfunction expansion for f(x) = x
using this eigenfunction.
5. Consider the eigenvalue problem
y′′ + (λ −a2)y = 0,
0 < x < 1,
with the boundary conditions
y′(0) + ay(0) = 0
and
y′(1) + ay(1) = 0.
Step 1: Show that this is a regular Sturm-Liouville problem.
Step 2: Show that the eigenvalues and eigenfunctions are λ0 = 0, y0(x) = e−ax and
λn = a2 + n2π2, yn(x) = a sin(nπx) −nπ cos(nπx).
where n = 1, 2, 3, . . ..
Step 3: Given a function f(x), show that we can expand it as follows:
f(x) = C0e−ax +
∞
X
n=1
Cn [a sin(nπx) −nπ cos(nπx)] ,
where
 1 −e−2a
C0 = 2a
Z 1
0
f(x)e−ax dx,
and
(a2 + n2π2)Cn = 2
Z 1
0
f(x) [a sin(nπx) −nπ cos(nπx)] dx.
6. Consider the eigenvalue problem
y′′′′ + λy′′ = 0,
0 < x < 1,
with the boundary conditions y(0) = y′(0) = y(1) = y′(1) = 0. Prove the following points:

256
Advanced Engineering Mathematics with MATLAB
Step 1: Show that the eigenfunctions are
yn(x) = 1 −cos(knx) + 1 −cos(kn)
kn −sin(kn)[sin(knx) −knx],
where kn denotes the nth root of
2 −2 cos(k) −k sin(k) = sin(k/2)[sin(k/2) −(k/2) cos(k/2)] = 0.
Step 2: Show that there are two classes of eigenfunctions:
κn = 2nπ,
yn(x) = 1 −cos(2nπx),
and
tan(κn/2) = κn/2,
yn(x) = 1 −cos(κnx) + 2
κn
[sin(κnx) −κnx].
Step 3: Show that the orthogonality condition for this problem is
Z 1
0
y′
n(x)y′
m(x) dx = 0,
n ̸= m,
where yn(x) and ym(x) are two distinct eigenfunction solutions of this problem. Hint: Follow
the proof in Section 6.2 and integrate repeatedly by parts to eliminate higher derivative
terms.
Step 4: Show that we can construct an eigenfunction expansion for an arbitrary function
f(x) via
f(x) =
∞
X
n=1
Cnyn(x),
0 < x < 1,
provided
Cn =
R 1
0 f ′(x)y′
n(x) dx
R 1
0 [y′n(x)]2 dx
.
What are the condition(s) on f(x)?
6.4 A SINGULAR STURM-LIOUVILLE PROBLEM: LEGENDRE’S EQUATION
In the previous sections we used solutions to a regular Sturm-Liouville problem in the
eigenfunction expansion of the function f(x). The fundamental reason why we could form
such an expansion was the orthogonality condition, Equation 6.2.1. This crucial property
allowed us to solve for the Fourier coeﬃcient cn given by Equation 6.3.4.
In the next few chapters, when we solve partial diﬀerential equations in cylindrical
and spherical coordinates, we will ﬁnd that f(x) must be expanded in terms of eigenfunc-
tions from singular Sturm-Liouville problems. Is this permissible? How do we compute the
Fourier coeﬃcients in this case? The ﬁnal two sections of this chapter deal with these ques-
tions by examining the two most frequently encountered singular Sturm-Liouville problems,
those involving Legendre’s and Bessel’s equations.

The Sturm-Liouville Problem
257
Born into an aﬄuent family, Adrien-Marie Legendre’s (1752–1833) modest family
fortune was suﬃcient to allow him to devote his life to research in celestial mechanics,
number theory, and the theory of elliptic functions. In July 1784 he read before the
Acad´emie des sciences his Recherches sur la ﬁgure des plan`etes. It is in this paper
that Legendre polynomials ﬁrst appeared.
(Portrait courtesy of the Archives de
l’Acad´emie des sciences, Paris.)
We begin by determining the orthogonality condition for singular Sturm-Liouville prob-
lems. Returning to the beginning portions of Section 6.2, we combine Equation 6.2.5 and
Equation 6.2.6 to obtain
(λn −λm)
Z b
a
r(x)ynym dx =[p(b)y′
m(b)yn(b) −p(b)y′
n(b)ym(b)
−p(a)y′
m(a)yn(a) + p(a)y′
n(a)ym(a)].
(6.4.1)
From Equation 6.4.1 the right side vanishes and we preserve orthogonality if yn(x) is ﬁnite
and p(x)y′
n(x) tends to zero at both endpoints. This is not the only choice but let us see
where it leads.
Consider now Legendre’s equation:
(1 −x2)d2y
dx2 −2xdy
dx + n(n + 1)y = 0,
(6.4.2)
or
d
dx

(1 −x2)dy
dx

+ n(n + 1)y = 0,
(6.4.3)

258
Advanced Engineering Mathematics with MATLAB
where we set a = −1, b = 1, λ = n(n + 1), p(x) = 1 −x2, q(x) = 0, and r(x) = 1. This
equation arises in the solution of partial diﬀerential equations involving spherical geometry.
Because p(−1) = p(1) = 0, we are faced with a singular Sturm-Liouville problem. Before
we can determine if any of its solutions can be used in an eigenfunction expansion, we must
ﬁnd them.
Equation 6.4.2 does not have a simple general solution. [If n = 0, then y(x) = 1 is a
solution.] Consequently we try to solve it with the power series:
y(x) =
∞
X
k=0
Akxk,
(6.4.4)
y′(x) =
∞
X
k=0
kAkxk−1,
(6.4.5)
and
y′′(x) =
∞
X
k=0
k(k −1)Akxk−2.
(6.4.6)
Substituting into Equation 6.4.2,
∞
X
k=0
k(k −1)Akxk−2 +
∞
X
k=0
[n(n + 1) −2k −k(k −1)] Akxk = 0,
(6.4.7)
which equals
∞
X
m=2
m(m −1)Amxm−2 +
∞
X
k=0
[n(n + 1) −k(k + 1)] Akxk = 0.
(6.4.8)
If we deﬁne k = m −2 in the ﬁrst summation, then
∞
X
k=0
(k + 2)(k + 1)Ak+2xk +
∞
X
k=0
[n(n + 1) −k(k + 1)] Akxk = 0.
(6.4.9)
Because Equation 6.4.9 must be true for any x, each power of x must vanish separately. It
then follows that
(k + 2)(k + 1)Ak+2 = [k(k + 1) −n(n + 1)]Ak,
(6.4.10)
or
Ak+2 = [k(k + 1) −n(n + 1)]
(k + 1)(k + 2)
Ak,
(6.4.11)
where k = 0, 1, 2, . . .. Note that we still have the two arbitrary constants A0 and A1 that
are necessary for the general solution of Equation 6.4.2.
The ﬁrst few terms of the solution associated with A0 are
up(x) = 1 −n(n + 1)
2!
x2 + n(n −2)(n + 1)(n + 3)
4!
x4
−n(n −2)(n −4)(n + 1)(n + 3)(n + 5)
6!
x6 + · · · ,
(6.4.12)

The Sturm-Liouville Problem
259
Table 6.4.1: The First Ten Legendre Polynomials
P0(x) = 1
P1(x) = x
P2(x) = 1
2(3x2 −1)
P3(x) = 1
2(5x3 −3x)
P4(x) = 1
8(35x4 −30x2 + 3)
P5(x) = 1
8(63x5 −70x3 + 15x)
P6(x) =
1
16(231x6 −315x4 + 105x2 −5)
P7(x) =
1
16(429x7 −693x5 + 315x3 −35x)
P8(x) =
1
128(6435x8 −12012x6 + 6930x4 −1260x2 + 35)
P9(x) =
1
128(12155x9 −25740x7 + 18018x5 −4620x3 + 315x)
P10(x) =
1
256(46189x10 −109395x8 + 90090x6 −30030x4 + 3465x2 −63)
while the ﬁrst few terms associated with the A1 coeﬃcient are
vp(x) = x −(n −1)(n + 2)
3!
x3 + (n −1)(n −3)(n + 2)(n + 4)
5!
x5
−(n −1)(n −3)(n −5)(n + 2)(n + 4)(n + 6)
7!
x7 + · · · .
(6.4.13)
If n is an even positive integer (including n = 0), then the series, Equation 6.4.12, terminates
with the term involving xn: The solution is a polynomial of degree n. Similarly, if n is an
odd integer, the series, Equation 6.4.13, terminates with the term involving xn. Otherwise,
for n noninteger the expressions are inﬁnite series.
For reasons that will become apparent, we restrict ourselves to positive integers n.
Actually, this includes all possible integers because the negative integer −n −1 has the
same Legendre’s equation and solution as the positive integer n. These polynomials are
Legendre polynomials11 and we may compute them by the power series:
Pn(x) =
m
X
k=0
(−1)k
(2n −2k)!
2nk!(n −k)!(n −2k)!xn−2k,
(6.4.14)
where m = n/2, or m = (n −1)/2, depending upon which is an integer. We chose to use
Equation 6.4.14 over Equation 6.4.12 or Equation 6.4.13 because Equation 6.4.14 has the
advantage that Pn(1) = 1. Table 6.4.1 gives the ﬁrst ten Legendre polynomials.
The other solution, the inﬁnite series, is the Legendre function of the second kind,
Qn(x). Figure 6.4.1 illustrates the ﬁrst four Legendre polynomials Pn(x) while Figure 6.4.2
11 Legendre, A. M., 1785: Sur l’attraction des sph´ero¨ıdes homog´enes. M´em. math. phys. pr´esent´es `a
l’Acad. sci. pars divers savants, 10, 411–434. The best reference on Legendre polynomials is Hobson, E.
W., 1965:The Theory of Spherical and Ellipsoidal Harmonics. Chelsea Publishing Co., 500 pp.

260
Advanced Engineering Mathematics with MATLAB
-1.0
-0.5
0.0
0.5
1.0
x
-1.0
-0.5
0.0
0.5
1.0
1.5
P
P
P
P
0
3
1
2
(x)
(x)
(x)
(x)
Figure 6.4.1: The ﬁrst four Legendre functions of the ﬁrst kind.
gives the ﬁrst four Legendre functions of the second kind Qn(x). From this ﬁgure we see
that Qn(x) becomes inﬁnite at the points x = ±1. As shown earlier, this is important
because we are only interested in solutions to Legendre’s equation that are ﬁnite over the
interval [−1, 1]. On the other hand, in problems where we exclude the points x = ±1,
Legendre functions of the second kind will appear in the general solution.12
In the case that n is not an integer, we can construct a solution13 that remains ﬁnite
at x = 1 but not at x = −1. Furthermore, we can construct a solution that is ﬁnite at
x = −1 but not at x = 1. Because our solutions must be ﬁnite at both endpoints so that
we can use them in an eigenfunction expansion, we must reject these solutions from further
consideration and are left only with Legendre polynomials. From now on, we will only
consider the properties and uses of these polynomials.
Although we have the series, Equation 6.4.14, to compute Pn(x), there are several
alternative methods.
We obtain the ﬁrst method, known as Rodrigues’s formula,14 by
writing Equation 6.4.14 in the form
Pn(x) =
1
2nn!
n
X
k=0
(−1)k
n!
k!(n −k)!
(2n −2k)!
(n −2k)! xn−2k
(6.4.15)
=
1
2nn!
dn
dxn
" n
X
k=0
(−1)k
n!
k!(n −k)!x2n−2k
#
.
(6.4.16)
The last summation is the binomial expansion of (x2 −1)n so that
Pn(x) =
1
2nn!
dn
dxn (x2 −1)n.
(6.4.17)
12 See Smythe, W. R., 1950: Static and Dynamic Electricity. McGraw-Hill, Section 5.215, for an example.
13 See Carrier, G. F., M. Krook, and C. E. Pearson, 1966: Functions of the Complex Variable: Theory
and Technique. McGraw-Hill, pp. 212–213.
14 Rodrigues, O., 1816: M´emoire sur l’attraction des sph´ero¨ıdes.
Correspond.
l’ ´Ecole Polytech., 3,
361–385.

The Sturm-Liouville Problem
261
-1.0
-0.5
0.0
0.5
1.0
x
-2.0
-1.0
0.0
1.0
2.0
Q
Q
Q
(x)
0
1
2
3
(x)
Q (x)
(x)
Figure 6.4.2: The ﬁrst four Legendre functions of the second kind.
Another method for computing Pn(x) involves the use of recurrence formulas. The ﬁrst
step in ﬁnding these formulas is to establish the fact that
(1 + h2 −2xh)−1/2 = P0(x) + hP1(x) + h2P2(x) + · · · .
(6.4.18)
The function (1 + h2 −2xh)−1/2 is the generating function for Pn(x).
We obtain the
expansion via the formal binomial expansion
(1 + h2 −2xh)−1/2 = 1 + 1
2(2xh −h2) + 1
2
3
2
1
2!(2xh −h2)2 + · · · .
(6.4.19)
Upon expanding the terms contained in 2x −h2 and grouping like powers of h,
(1 + h2 −2xh)−1/2 = 1 + xh + ( 3
2x2 −1
2)h2 + · · · .
(6.4.20)
A direct comparison between the coeﬃcients of each power of h and the Legendre polynomial
Pn(x) completes the demonstration. Note that these results hold only if |x| and |h| < 1.
Next we deﬁne W(x, h) = (1 + h2 −2xh)−1/2.
A quick check shows that W(x, h)
satisﬁes the ﬁrst-order partial diﬀerential equation
(1 −2xh + h2)∂W
∂h + (h −x)W = 0.
(6.4.21)
The substitution of Equation 6.4.18 into Equation 6.4.21 yields
(1 −2xh + h2)
∞
X
n=0
nPn(x)hn−1 + (h −x)
∞
X
n=0
Pn(x)hn = 0.
(6.4.22)
Setting the coeﬃcients of hn equal to zero, we ﬁnd that
(n + 1)Pn+1(x) −2nxPn(x) + (n −1)Pn−1(x) + Pn−1(x) −xPn(x) = 0,
(6.4.23)
or
(n + 1)Pn+1(x) −(2n + 1)xPn(x) + nPn−1(x) = 0
(6.4.24)
with n = 1, 2, 3, . . ..

262
Advanced Engineering Mathematics with MATLAB
Similarly, the ﬁrst-order partial diﬀerential equation
(1 −2xh + h2)∂W
∂x −hW = 0
(6.4.25)
leads to
(1 −2xh + h2)
∞
X
n=0
P ′
n(x)hn −
∞
X
n=0
Pn(x)hn+1 = 0,
(6.4.26)
which implies
P ′
n+1(x) −2xP ′
n(x) + P ′
n−1(x) −Pn(x) = 0.
(6.4.27)
Diﬀerentiating Equation 6.4.24, we ﬁrst eliminate P ′
n−1(x) and then P ′
n+1(x) from the
resulting equations and Equation 6.4.27. This gives two further recurrence relationships:
P ′
n+1(x) −xP ′
n(x) −(n + 1)Pn(x) = 0,
n = 0, 1, 2, . . . ,
(6.4.28)
and
xP ′
n(x) −P ′
n−1(x) −nPn(x) = 0,
n = 1, 2, 3, . . . .
(6.4.29)
Adding Equation 6.4.28 and Equation 6.4.29, we obtain the more symmetric formula
P ′
n+1(x) −P ′
n−1(x) = (2n + 1)Pn(x), n = 1, 2, 3, . . . .
(6.4.30)
Given any two of the polynomials Pn+1(x), Pn(x), and Pn−1(x), Equation 6.4.24 or Equation
6.4.30 yields the third.
Having determined several methods for ﬁnding the Legendre polynomial Pn(x), we now
turn to the actual orthogonality condition.15 Consider the integral
J =
Z 1
−1
dx
√
1 + h2 −2xh
√
1 + t2 −2xt
,
|h|, |t| < 1
(6.4.31)
=
Z 1
−1
[P0(x) + hP1(x) + · · · + hnPn(x) + · · ·]
× [P0(x) + tP1(x) + · · · + tnPn(x) + · · ·] dx
(6.4.32)
=
∞
X
n=0
∞
X
m=0
hntm
Z 1
−1
Pn(x)Pm(x) dx.
(6.4.33)
On the other hand, if a = (1 + h2)/2h, and b = (1 + t2)/2t, the integral J is
J =
Z 1
−1
dx
√
1 + h2 −2xh
√
1 + t2 −2xt
(6.4.34)
=
1
2
√
ht
Z 1
−1
dx
√a −x
√
b −x =
1
√
ht
Z 1
−1
1
2

1
√a−x +
1
√b−x

√a −x +
√
b −x dx
(6.4.35)
= −1
√
ht
ln(
√
a −x +
√
b −x)

1
−1 =
1
√
ht
ln
√a + 1 +
√
b + 1
√a −1 +
√
b −1

.
(6.4.36)
15 See Symons, B., 1982: Legendre polynomials and their orthogonality. Math. Gaz., 66, 152–154.

The Sturm-Liouville Problem
263
Some Useful Relationships Involving Legendre Polynomials
Rodrigues’s formula
Pn(x) =
1
2nn!
dn
dxn (x2 −1)n
Recurrence formulas
(n + 1)Pn+1(x) −(2n + 1)xPn(x) + nPn−1(x) = 0,
n = 1, 2, 3, . . .
P ′
n+1(x) −P ′
n−1(x) = (2n + 1)Pn(x),
n = 1, 2, 3, . . .
Orthogonality condition
Z 1
−1
Pn(x)Pm(x) dx =





0,
m ̸= n,
2
2n + 1,
m = n.
But a + 1 = (1 + h2 + 2h)/2h = (1 + h)2/2h, and a −1 = (1 −h)2/2h. After a little algebra,
J =
1
√
ht
ln
 
1 +
√
ht
1 −
√
ht
!
=
2
√
ht
√
ht + 1
3
p
(ht)3 + 1
5
p
(ht)5 + · · ·

(6.4.37)
= 2

1 + ht
3 + h2t2
5
+ · · · + hntn
2n + 1 + · · ·

.
(6.4.38)
As we noted earlier, the coeﬃcient of hntm in this series is
R 1
−1 Pn(x)Pm(x) dx. If we match
the powers of hntm, the orthogonality condition is
Z 1
−1
Pn(x)Pm(x) dx =

0,
m ̸= n,
2
2n+1,
m = n.
(6.4.39)
With the orthogonality condition, Equation 6.4.39, we are ready to show that we can
represent a function f(x), which is piece-wise diﬀerentiable in the interval (−1, 1), by the
series:
f(x) =
∞
X
m=0
AmPm(x),
−1 ≤x ≤1.
(6.4.40)
To ﬁnd Am we multiply both sides of Equation 6.4.40 by Pn(x) and integrate from −1 to 1:
Z 1
−1
f(x)Pn(x) dx =
∞
X
m=0
Am
Z 1
−1
Pn(x)Pm(x) dx.
(6.4.41)

264
Advanced Engineering Mathematics with MATLAB
All of the terms on the right side vanish except for n = m because of the orthogonality
condition, Equation 6.4.39. Consequently, the coeﬃcient An is
An
Z 1
−1
P 2
n(x) dx =
Z 1
−1
f(x)Pn(x) dx,
(6.4.42)
or
An = 2n + 1
2
Z 1
−1
f(x)Pn(x) dx.
(6.4.43)
In the special case when f(x) and its ﬁrst n derivatives are continuous throughout the
interval (−1, 1), we may use Rodrigues’ formula to evaluate
Z 1
−1
f(x)Pn(x) dx =
1
2nn!
Z 1
−1
f(x)dn(x2 −1)n
dxn
dx = (−1)n
2nn!
Z 1
−1
(x2 −1)nf (n)(x) dx
(6.4.44)
by integrating by parts n times. Consequently,
An = 2n + 1
2n+1n!
Z 1
−1
(1 −x2)nf (n)(x) dx.
(6.4.45)
A particularly useful result follows from Equation 6.4.45 if f(x) is a polynomial of degree k.
Because all derivatives of f(x) of order n vanish identically when n > k, An = 0 if n > k.
Consequently, any polynomial of degree k can be expressed as a linear combination of the
ﬁrst k +1 Legendre polynomials [P0(x), . . . , Pk(x)]. Another way of viewing this result is to
recognize that any polynomial of degree k is an expansion in powers of x. When we expand
in Legendre polynomials we are merely regrouping these powers of x into new groups that
can be identiﬁed as P0(x), P1(x), P2(x), . . . , Pk(x).
• Example 6.4.1
Let us use Rodrigues’ formula to compute P2(x). From Equation 6.4.17 with n = 2,
P2(x) =
1
222!
d2
dx2 [(x2 −1)2] = 1
8
d2
dx2 (x4 −2x2 −1) = 1
2(3x2 −1).
(6.4.46)
⊓⊔
• Example 6.4.2
Let us compute P3(x) from a recurrence relation. From Equation 6.4.24 with n = 2,
3P3(x) −5xP2(x) + 2P1(x) = 0.
(6.4.47)
But P2(x) = (3x2 −1)/2, and P1(x) = x, so that
3P3(x) = 5xP2(x) −2P1(x) = 5x[(3x2 −1)/2] −2x = 15
2 x3 −9
2x,
(6.4.48)

The Sturm-Liouville Problem
265
or
P3(x) = (5x3 −3x)/2.
(6.4.49)
⊓⊔
• Example 6.4.3
We want to show that
Z 1
−1
Pn(x) dx = 0,
n > 0.
(6.4.50)
From Equation 6.4.30,
(2n + 1)
Z 1
−1
Pn(x) dx =
Z 1
−1
[P ′
n+1(x) −P ′
n−1(x)] dx
(6.4.51)
= Pn+1(x) −Pn−1(x)|1
−1
(6.4.52)
= Pn+1(1) −Pn−1(1) −Pn+1(−1) + Pn−1(−1) = 0,
(6.4.53)
because Pn(1) = 1 and Pn(−1) = (−1)n.
⊓⊔
• Example 6.4.4
Let us express f(x) = x2 in terms of Legendre polynomials. The results from Equation
6.4.45 mean that we need only worry about P0(x), P1(x), and P2(x):
x2 = A0P0(x) + A1P1(x) + A2P2(x).
(6.4.54)
Substituting for the Legendre polynomials,
x2 = A0 + A1x + 1
2A2(3x2 −1),
(6.4.55)
and
A0 = 1
3,
A1 = 0,
and
A2 = 2
3.
(6.4.56)
⊓⊔
• Example 6.4.5
Let us ﬁnd the expansion in Legendre polynomials of the function:
f(x) =
 0,
−1 < x < 0,
1,
0 < x < 1.
(6.4.57)
We could have done this expansion as a Fourier series but in the solution of partial diﬀer-
ential equations on a sphere we must make the expansion in Legendre polynomials.
In this problem, we ﬁnd that
An = 2n + 1
2
Z 1
0
Pn(x) dx.
(6.4.58)

266
Advanced Engineering Mathematics with MATLAB
Therefore,
A0 = 1
2
Z 1
0
1 dx = 1
2,
A1 = 3
2
Z 1
0
x dx = 3
4,
(6.4.59)
A2 = 5
2
Z 1
0
1
2(3x2 −1) dx = 0,
and
A3 = 7
2
Z 1
0
1
2(5x3 −3x) dx = −7
16,
(6.4.60)
so that
f(x) = 1
2P0(x) + 3
4P1(x) −7
16P3(x) + 11
32P5(x) + · · · .
(6.4.61)
Figure 6.4.3 illustrates the expansion, Equation 6.4.61, where we used only the ﬁrst four
terms. It was created using the MATLAB script
clear;
x = [-1:0.01:1]; % create x points in plot
f = zeros(size(x)); % initialize function f(x)
for k = 1:length(x) % construct function f(x)
if x(k) < 0; f(k) = 0; else f(k) = 1; end;
end
% initialize Fourier-Legendre series with zeros
flegendre = zeros(size(x));
% read in Fourier coefficients
a(1) = 1/2; a(2) = 3/4; a(3) = 0;
a(4) = -7/16; a(5) = 0; a(6) = 11/32;
clf % clear any figures
for n = 1:6
% compute Legendre polynomial
N = n-1; P = legendre(N,x);
% compute Fourier-Legendre series
flegendre = flegendre + a(n) * P(1,:);
% create plot of truncated Fourier-Legendre series
%
with n terms
if n==1 subplot(2,2,1), plot(x,flegendre,x,f,’--’);
legend(’one term’,’f(x)’); legend boxoff; end
if n==2 subplot(2,2,2), plot(x,flegendre,x,f,’--’);
legend(’two terms’,’f(x)’); legend boxoff; end
if n==4 subplot(2,2,3), plot(x,flegendre,x,f,’--’);
legend(’four terms’,’f(x)’); legend boxoff;
xlabel(’x’,’Fontsize’,20); end
if n==6 subplot(2,2,4), plot(x,flegendre,x,f,’--’);
legend(’six terms’,’f(x)’); legend boxoff;
xlabel(’x’,’Fontsize’,20); end
axis([-1 1 -0.5 1.5])
end
As we add each additional term in the orthogonal expansion, the expansion ﬁts f(x) better
in the “least squares” sense of Equation 6.3.5. The spurious oscillations arise from trying
to represent a discontinuous function by four continuous, oscillatory functions.
Even if

The Sturm-Liouville Problem
267
−1
0
1
−0.5
0
0.5
1
1.5
one term
f(x)
−1
0
1
−0.5
0
0.5
1
1.5
two terms
f(x)
−1
0
1
−0.5
0
0.5
1
1.5
x
four terms
f(x)
−1
0
1
−0.5
0
0.5
1
1.5
x
six terms
f(x)
Figure 6.4.3: Representation of the function f(x) = 1 for 0 < x < 1 and 0 for −1 < x < 0 by various
partial summations of its Legendre polynomial expansion. The dashed lines denote the exact function.
we add additional terms, the spurious oscillations persist, although located nearer to the
discontinuity. This is another example of Gibbs phenomena.16 See Section 5.2.
⊓⊔
• Example 6.4.6: Iterative solution of the radiative transfer equation
One of the fundamental equations of astrophysics is the integro-differential equation
that describes radiative transfer (the propagation of energy by radiative, rather than con-
ductive or convective, processes) in a gas.
Consider a gas that varies in only one spatial direction and that we divide into inﬁnites-
imally thin slabs. As radiation enters a slab, it is absorbed and scattered. If we assume
that all of the radiation undergoes isotropic scattering, the radiative transfer equation is
µdI
dτ = I −1
2
Z 1
−1
I dµ,
(6.4.62)
where I is the intensity of the radiation, τ is the optical depth (a measure of the absorbing
power of the gas and related to the distance that you travel within the gas), µ = cos(θ),
and θ is the angle at which radiation enters the slab. In this example, we show how the
Fourier-Legendre expansion17
I(τ, µ) =
∞
X
n=0
In(τ)Pn(µ)
(6.4.63)
may be used to solve Equation 6.4.62. Here In(τ) is the Fourier coeﬃcient in the Fourier-
Legendre expansion involving the Legendre polynomial Pn(µ).
We begin by substituting Equation 6.4.63 into Equation 6.4.62,
∞
X
n=0
[(n + 1)Pn+1(µ) + nPn−1(µ)]
2n + 1
dIn
dτ =
∞
X
n=0
InPn(µ) −I0,
(6.4.64)
16 Weyl, H., 1910: Die Gibbs’sche Erscheinung in der Theorie der Kugelfunktionen. Rend. Circ. Mat.
Palermo, 29, 308–321.
17 See Chandrasekhar, S., 1944: On the radiative equilibrium of a stellar atmosphere. Astrophys. J., 99,
180–190.

268
Advanced Engineering Mathematics with MATLAB
where we used Equation 6.4.24 to eliminate µPn(µ). Note that only the I0(τ) term remains
after integrating because of the orthogonality condition:
Z 1
−1
1 · Pn(µ) dµ =
Z 1
−1
P0(µ)Pn(µ) dµ = 0,
(6.4.65)
if n > 0. Equating the coeﬃcients of the various Legendre polynomials,
n
2n −1
dIn−1
dτ
+ n + 1
2n + 3
dIn+1
dτ
= In,
(6.4.66)
for n = 1, 2, . . . and
dI1
dτ = 0.
(6.4.67)
Thus, the solution for I1 is I1 = constant = 3F/4, where F is the net integrated ﬂux and
an observable quantity.
For n = 1,
dI0
dτ + 2
5
dI2
dτ = I1 = 3F
4 .
(6.4.68)
Therefore,
I0 + 2
5I2 = 3
4Fτ + A.
(6.4.69)
The next diﬀerential equation arises from n = 2 and equals
2
3
dI1
dτ + 3
7
dI3
dτ = I2.
(6.4.70)
Because I1 is a constant and we only retain I0, I1, and I2 in the simplest approximation,
we neglect dI3/dτ and I2 = 0. Thus, the simplest approximate solution is
I0 = 3
4Fτ + A,
I1 = 3
4F,
and
I2 = 0.
(6.4.71)
To complete our approximate solution, we must evaluate A. If we are dealing with a
stellar atmosphere where we assume no external radiation incident on the star, I(0, µ) = 0
for −1 ≤µ < 0. Therefore,
Z 1
−1
I(τ, µ)Pn(µ) dµ =
∞
X
m=0
Im(τ)
Z 1
−1
Pm(µ)Pn(µ) dµ =
2
2n + 1In(τ).
(6.4.72)
Taking the limit τ →0 and using the boundary condition,
2
2n + 1In(0) =
Z 1
0
I(0, µ)Pn(µ) dµ =
∞
X
m=0
Im(0)
Z 1
0
Pn(µ)Pm(µ) dµ.
(6.4.73)
Thus, we must satisfy, in principle, an inﬁnite set of equations. For example, for n = 0, 1,
and 2,
2I0(0) = I0(0) + 1
2I1(0) −1
8I3(0) + 1
16I5(0) + · · · ,
(6.4.74)
2
3I1(0) = 1
2I0(0) + 1
3I1(0) + 1
8I2(0) −1
48I4(0) + · · · ,
(6.4.75)
and
2
5I2(0) = 1
8I1(0) + 1
5I2(0) + 1
8I3(0) −
5
128I5(0) + · · · .
(6.4.76)

The Sturm-Liouville Problem
269
Using I1(0) = 3F/4,
1
2I0(0) + 1
16I3(0) −1
32I5(0) + · · · =
3
16F,
(6.4.77)
1
2I0(0) + 1
8I2(0) −1
48I4(0) + · · · = 1
4F,
(6.4.78)
and
2
5I2(0) −1
4I3(0) + 5
64I5(0) + · · · =
3
16F.
(6.4.79)
Of the two possible equations, Equation 6.4.77 or Equation 6.4.78, Chandrasekhar chose
Equation 6.4.78 from physical considerations. Thus, to ﬁrst approximation, the solution is
I(µ, τ) = 3
4F
 τ + 2
3

+ 3
4Fµ + · · · .
(6.4.80)
Better approximations can be obtained by including more terms; the interested reader is
referred to the original article. In the early 1950s, Wang and Guth18 improved the proce-
dure for ﬁnding the successive approximations and formulating the approximate boundary
conditions.
Problems
Find the ﬁrst three nonvanishing coeﬃcients in the Legendre polynomial expansion for the
following functions:
1.
f(x) =
 0,
−1 < x < 0,
x,
0 < x < 1.
3.
f(x) = |x|,
|x| < 1.
5.
f(x) =
 −1,
−1 < x < 0,
1,
0 < x < 1.
2.
f(x) =



1/(2ǫ),
|x| < ǫ,
0,
ǫ < |x| < 1,
x,
0 < x < 1.
4.
f(x) = x3,
|x| < 1.
6.
f(x) =
 −1,
−1 < x < 0,
x,
0 < x < 1.
Then use MATLAB to illustrate various partial sums of the Fourier-Legendre series.
7. Use Rodrigues’ formula to show that P4(x) = 1
8(35x4 −30x2 + 3).
8. Given P5(x) = 63
8 x5 −70
8 x3 + 15
8 x and P4(x) from Problem 7, use the recurrence formula
for Pn+1(x) to ﬁnd P6(x).
9. Show that (a) Pn(1) = 1, (b) Pn(−1) = (−1)n, (c) P2n+1(0) = 0, and (d) P2n(0) =
(−1)n(2n)!/(22nn!n!).
10. Prove that
Z 1
x
Pn(t) dt =
1
2n + 1[Pn−1(x) −Pn+1(x)],
n > 0.
18 Wang, M. C., and E. Guth, 1951: On the theory of multiple scattering, particularly of charged particles.
Phys. Rev., Ser. 2, 84, 1092–1111.

270
Advanced Engineering Mathematics with MATLAB
11. Given19
Pn[cos(θ)] = 2
π
Z θ
0
cos[(n + 1
2)x]
p
2[cos(x) −cos(θ)]
dx = 2
π
Z π
θ
sin[(n + 1
2)x]
p
2[cos(θ) −cos(x)]
dx,
show that the following generalized Fourier series holds:
H(θ −t)
p
2 cos(t) −2 cos(θ)
=
∞
X
n=0
Pn[cos(θ)] cos
 n + 1
2

t

,
0 ≤t < θ ≤π,
if we use the eigenfunction yn(x) = cos
 n + 1
2

x

, 0 < x < π, r(x) = 1 and H(·) is
Heaviside’s step function, and
H(t −θ)
p
2 cos(θ) −2 cos(t)
=
∞
X
n=0
Pn[cos(θ)] sin
 n + 1
2

t

,
0 ≤θ < t ≤π,
if we use the eigenfunction yn(x) = sin
 n + 1
2

x

, 0 < x < π, r(x) = 1 and H(·) is
Heaviside’s step function.
12. The series given in Problem 11 are also expansions in Legendre polynomials. In that
light, show that
Z t
0
Pn[cos(θ)] sin(θ)
p
2 cos(θ) −2 cos(t)
dθ = sin
 n + 1
2

t

n + 1
2
,
and
Z π
t
Pn[cos(θ)] sin(θ)
p
2 cos(t) −2 cos(θ)
dθ = cos
 n + 1
2

t

n + 1
2
,
where 0 < t < π.
13. (a) Use the generating function, Equation 6.4.18, to show that
1
√
1 −2tx + t2 =
∞
X
n=0
t−n−1Pn(x),
|x| < 1, 1 < |t|.
(b) Use the results from part (a) to show that
1
p
cosh(µ) −x
=
√
2
∞
X
n=0
e−(n+ 1
2 )|µ|Pn(x),
|x| < 1.
Hint:
1
p
cosh(µ) −x
=
√
2
√
e|µ| −2x + e−|µ| .
19 Hobson, E. W., 1965: The Theory of Spherical and Ellipsoidal Harmonics. Chelsea Publishing Co.,
pp. 26–27.

The Sturm-Liouville Problem
271
14. The generating function, Equation 6.4.18, actually holds20 for |h| ≤1 if |x| < 1. Using
this relationship, show that
∞
X
n=0
Pn(x) =
1
p
2(1 −x)
,
|x| < 1,
and
∞
X
n=0
Pn(x)
n + 1 = ln
"
1 +
p
(1 −x)/2
p
(1 −x)/2
#
,
|x| < 1.
Use these relationships to show that
∞
X
n=1
2n + 1
n + 1 Pn(x) = 2
∞
X
n=1
Pn(x) −
∞
X
n=1
Pn(x)
n + 1 =
1
p
(1 −x)/2
−ln
"
1 +
p
(1 −x)/2
p
(1 −x)/2
#
−1,
if |x| < 1.
6.5 ANOTHER SINGULAR STURM-LIOUVILLE PROBLEM: BESSEL’S EQUATION
In the previous section we discussed the solutions to Legendre’s equation, especially
with regard to their use in orthogonal expansions. In this section we consider another classic
equation, Bessel’s equation21
x2y′′ + xy′ + (µ2x2 −n2)y = 0,
(6.5.1)
or
d
dx

xdy
dx

+

µ2x −n2
x

y = 0.
(6.5.2)
Once again, our ultimate goal is the use of its solutions in orthogonal expansions. These
orthogonal expansions, in turn, are used in the solution of partial diﬀerential equations in
cylindrical coordinates.
A quick check of Bessel’s equation shows that it conforms to the canonical form of the
Sturm-Liouville problem: p(x) = x, q(x) = −n2/x, r(x) = x, and λ = µ2. Restricting
our attention to the interval [0, L], the Sturm-Liouville problem involving Equation 6.5.2 is
singular because p(0) = 0. From Equation 6.4.1 in the previous section, the eigenfunctions
to a singular Sturm-Liouville problem will still be orthogonal over the interval [0, L] if (1)
y(x) is ﬁnite and xy′(x) is zero at x = 0, and (2) y(x) satisﬁes the homogeneous boundary
condition, Equation 6.1.2, at x = L. Consequently, we only seek solutions that satisfy these
conditions.
We cannot write down the solution to Bessel’s equation in a simple closed form; as in
the case with Legendre’s equation, we must ﬁnd the solution by power series. Because we
intend to make the expansion about x = 0 and this point is a regular singular point, we must
20 Ibid., p. 28.
21 Bessel, F. W., 1824: Untersuchung des Teils der planetarischen St¨orungen, welcher aus der Bewegung
der Sonne entsteht. Abh. d. K. Akad. Wiss. Berlin, 1–52. See Dutka, J., 1995: On the early history of
Bessel functions. Arch. Hist. Exact Sci., 49, 105–134. The classic reference on Bessel functions is Watson,
G. N., 1966: A Treatise on the Theory of Bessel Functions. Cambridge University Press, 804 pp.

272
Advanced Engineering Mathematics with MATLAB
It was Friedrich Wilhelm Bessel’s (1784–1846) apprenticeship to the famous mercantile ﬁrm of
Kulenkamp that ignited his interest in mathematics and astronomy. As the founder of the German
school of practical astronomy, Bessel discovered his functions while studying the problem of planetary
motion. Bessel functions arose as coeﬃcients in one of the series that described the gravitational
interaction between the sun and two other planets in elliptic orbit.
(Portrait courtesy of Photo
AKG, London, with permission.)
use the method of Frobenius, where n is an integer.22 Moreover, because the quantity n2
appears in Equation 6.5.2, we may take n to be nonnegative without any loss of generality.
To simplify matters, we ﬁrst ﬁnd the solution when µ = 1; the solution for µ ̸= 1
follows by substituting µx for x. Consequently, we seek solutions of the form
y(x) =
∞
X
k=0
Bkx2k+s,
(6.5.3)
y′(x) =
∞
X
k=0
(2k + s)Bkx2k+s−1,
(6.5.4)
and
y′′(x) =
∞
X
k=0
(2k + s)(2k + s −1)Bkx2k+s−2,
(6.5.5)
22 This case is much simpler than for arbitrary n. See Hildebrand, F. B., 1962: Advanced Calculus for
Applications. Prentice-Hall, Section 4.8.

The Sturm-Liouville Problem
273
where we formally assume that we can interchange the order of diﬀerentiation and summa-
tion. The substitution of Equation 6.5.3 and Equation 6.5.5 into Equation 6.5.1 with µ = 1
yields
∞
X
k=0
(2k+s)(2k+s−1)Bkx2k+s +
∞
X
k=0
(2k+s)Bkx2k+s +
∞
X
k=0
Bkx2k+s+2 −n2
∞
X
k=0
Bkx2k+s = 0,
(6.5.6)
or
∞
X
k=0
[(2k + s)2 −n2]Bkx2k +
∞
X
k=0
Bkx2k+2 = 0.
(6.5.7)
If we explicitly separate the k = 0 term from the other terms in the ﬁrst summation in
Equation 6.5.7,
(s2 −n2)B0 +
∞
X
m=1
[(2m + s)2 −n2]Bmx2m +
∞
X
k=0
Bkx2k+2 = 0.
(6.5.8)
We now change the dummy integer in the ﬁrst summation of Equation 6.5.8 by letting
m = k + 1 so that
(s2 −n2)B0 +
∞
X
k=0
{[(2k + s + 2)2 −n2]Bk+1 + Bk}x2k+2 = 0.
(6.5.9)
Because Equation 6.5.9 must be true for all x, each power of x must vanish identically. This
yields s = ±n, and
[(2k + s + 2)2 −n2]Bk+1 + Bk = 0.
(6.5.10)
Since the diﬀerence of the larger indicial root from the lower root equals the integer 2n, we
are only guaranteed a power series solution of the form given by Equation 6.5.3 for s = n. If
we use this indicial root and the recurrence formula, Equation 6.5.10, this solution, known
as the Bessel function of the ﬁrst kind of order n and denoted by Jn(x), is
Jn(x) =
∞
X
k=0
(−1)k(x/2)n+2k
k!(n + k)!
.
(6.5.11)
To ﬁnd the second general solution to Bessel’s equation, the one corresponding to
s = −n, the most economical method23 is to express it in terms of partial derivatives of
Jn(x) with respect to its order n:
Yn(x) =
∂Jν(x)
∂ν
−(−1)n ∂J−ν(x)
∂ν

ν=n
.
(6.5.12)
Upon substituting the power series representation, Equation 6.5.11, into Equation 6.5.12,
Yn(x) = 2
π Jn(x) ln(x/2) −1
π
n−1
X
k=0
(n −k −1)!
k!
x
2
2k−n
−1
π
∞
X
k=0
(−1)k(x/2)n+2k
k!(n + k)!
[ψ(k + 1) + ψ(k + n + 1)],
(6.5.13)
23 See Watson, G. N., 1966: A Treatise on the Theory of Bessel Functions. Cambridge University Press,
Section 3.5, for the derivation.

274
Advanced Engineering Mathematics with MATLAB
0.0
2.0
4.0
6.0
8.0
x
-0.5
0.0
0.5
1.0
J0
J (x)
J (x) J (x)
(x)
1
2
3
Figure 6.5.1: The ﬁrst four Bessel functions of the ﬁrst kind over 0 ≤x ≤8.
where
ψ(m + 1) = −γ + 1 + 1
2 + · · · + 1
m,
(6.5.14)
ψ(1) = −γ, and γ is Euler’s constant (0.5772157). In the case of n = 0, the ﬁrst sum in
Equation 6.5.13 disappears. This function Yn(x) is Neumann’s Bessel function of the second
kind of order n. Consequently, the general solution to Equation 6.5.1 is
y(x) = AJn(µx) + BYn(µx).
(6.5.15)
Figure 6.5.1 illustrates the functions J0(x), J1(x), J2(x), and J3(x) while Figure 6.5.2 gives
Y0(x), Y1(x), Y2(x), and Y3(x).
An alternative solution to Equation 6.5.1 is
y(x) = CH(1)
n (x) + DH(2)
n (x),
(6.5.16)
where
H(1)
n (x) = Jn(x) + iYn(x),
(6.5.17)
and
H(2)
n (x) = Jn(x) −iYn(x).
(6.5.18)
These functions H(1)
n (x), H(2)
n (x) are referred to as Bessel functions of the third kind or
Hankel functions, after the German mathematician Hermann Hankel (1839–1873).
The
advantage of Hankel functions over the conventional Bessel function is most clearly seen in
their asymptotic expansions:
H(1)
n (z) ∼
r
2
πz ei(z−nπ/2−π/4),
(6.5.19)
and
H(2)
n (z) ∼
r
2
πz e−i(z−nπ/2−π/4).
(6.5.20)
for |z| →∞.
An equation that is very similar to Equation 6.5.1 is
x2 d2y
dx2 + xdy
dx −(n2 + x2)y = 0.
(6.5.21)

The Sturm-Liouville Problem
275
0.0
2.0
4.0
6.0
8.0
x
-1.0
-0.5
0.0
0.5
1.0
Y (x)
Y (x)
Y (x)
Y (x)
0
1
2
3
Figure 6.5.2: The ﬁrst four Bessel functions of the second kind over 0 ≤x ≤8.
It arises in the solution of partial diﬀerential equations in cylindrical coordinates. If we
substitute ix = t (where i = √−1 ) into Equation 6.5.21, it becomes Bessel’s equation:
t2 d2y
dt2 + tdy
dt + (t2 −n2)y = 0.
(6.5.22)
Consequently, we may immediately write the solution to Equation 6.5.21 as
y(x) = c1Jn(ix) + c2Yn(ix),
(6.5.23)
if n is an integer. Traditionally the solution to Equation 6.5.21 has been written
y(x) = c1In(x) + c2Kn(x)
(6.5.24)
rather than in terms of Jn(ix) and Yn(ix), where
In(x) =
∞
X
k=0
(x/2)2k+n
k!(k + n)! ,
(6.5.25)
and
Kn(x) = π
2 in+1 [Jn(ix) + iYn(ix)] .
(6.5.26)
The function In(x) is the modiﬁed Bessel function of the ﬁrst kind, of order n, while Kn(x)
is the modiﬁed Bessel function of the second kind, of order n. Figure 6.5.3 illustrates I0(x),
I1(x), I2(x), and I3(x) while in Figure 6.5.3 K0(x), K1(x), K2(x), and K3(x) are graphed.
Note that Kn(x) has no real zeros while In(x) equals zero only at x = 0 for n ≥1.
As our derivation suggests, modiﬁed Bessel functions are related to ordinary Bessel
functions via complex variables. In particular, Jn(iz) = inIn(z), and In(iz) = inJn(z) for
z complex.
Although we found solutions to Bessel’s equation, Equation 6.5.1, as well as Equation
6.5.21, can we use any of them in an eigenfunction expansion? From Figures 6.5.1–6.5.4 we
see that Jn(x) and In(x) remain ﬁnite at x = 0 while Yn(x) and Kn(x) do not. Furthermore,
the products xJ′
n(x) and xI′
n(x) tend to zero at x = 0. Thus, both Jn(x) and In(x) satisfy
the ﬁrst requirement of an eigenfunction for a Fourier-Bessel expansion.
What about the second condition, that the eigenfunction must satisfy the homogeneous
boundary condition, Equation 6.1.2, at x = L? From Figure 6.5.3 we see that In(x) can

276
Advanced Engineering Mathematics with MATLAB
0.0
1.0
2.0
3.0
x
0.0
1.0
2.0
3.0
4.0
5.0
1I
I
I
2
I
0
3
Figure 6.5.3: The ﬁrst four modiﬁed Bessel functions of the ﬁrst kind over 0 ≤x ≤3.
never satisfy this condition, while from Figure 6.5.1, Jn(x) can. For that reason, we discard
In(x) from further consideration and continue our analysis only with Jn(x).
Before we can derive the expressions for a Fourier-Bessel expansion, we need to ﬁnd
how Jn(x) is related to Jn+1(x) and Jn−1(x). Assuming that n is a positive integer, we
multiply the series, Equation 6.5.11, by xn and then diﬀerentiate with respect to x. This
gives
d
dx [xnJn(x)] =
∞
X
k=0
(−1)k(2n + 2k)x2n+2k−1
2n+2kk!(n + k)!
= xn
∞
X
k=0
(−1)k(x/2)n−1+2k
k!(n −1 + k)!
= xnJn−1(x)
(6.5.27)
or
d
dx[xnJn(x)] = xnJn−1(x)
(6.5.28)
for n = 1, 2, 3, . . .. Similarly, multiplying Equation 6.5.11 by x−n, we ﬁnd that
d
dx

x−nJn(x)

= −x−nJn+1(x)
(6.5.29)
for n = 0, 1, 2, 3, . . .. If we now carry out the diﬀerentiation on Equation 6.5.28 and Equation
6.5.29 and divide by the factors x±n, we have that
J′
n(x) + n
xJn(x) = Jn−1(x),
(6.5.30)
and
J′
n(x) −n
xJn(x) = −Jn+1(x).
(6.5.31)

The Sturm-Liouville Problem
277
0.0
1.0
2.0
3.0
x
0.0
1.0
2.0
3.0
4.0
K
K
K2
0
1
K3
Figure 6.5.4: The ﬁrst four modiﬁed Bessel functions of the second kind over 0 ≤x ≤3.
Equation 6.3.30 and Equation 6.3.31 immediately yield the recurrence relationships
Jn−1(x) + Jn+1(x) = 2n
x Jn(x)
(6.5.32)
and
Jn−1(x) −Jn+1(x) = 2J′
n(x)
(6.5.33)
for n = 1, 2, 3, . . .. For n = 0, we replace Equation 6.5.33 by J′
0(x) = −J1(x). Many of the
most useful recurrence formulas are summarized in Table 6.5.1 for Bessel functions and in
Table 6.5.2 for Hankel functions.
Let us now construct a Fourier-Bessel series. The exact form of the expansion depends
upon the boundary condition at x = L. There are three possible cases. One of them is
y(L) = 0 and results in the condition that Jn(µkL) = 0. Another condition is y′(L) = 0
and gives J′
n(µkL) = 0. Finally, if hy(L) + y′(L) = 0, then hJn(µkL) + µkJ′
n(µkL) = 0. In
all of these cases, the eigenfunction expansion is the same, namely
f(x) =
∞
X
k=1
AkJn(µkx),
(6.5.34)
where µk is the kth positive solution of either Jn(µkL) = 0, J′
n(µkL) = 0, or hJn(µkL) +
µkJ′
n(µkL) = 0.
We now need a mechanism for computing Ak. We begin by multiplying Equation 6.5.34
by xJn(µmx) dx and integrate from 0 to L. This yields
∞
X
k=1
Ak
Z L
0
xJn(µkx)J(µmx) dx =
Z L
0
xf(x)Jn(µmx) dx.
(6.5.35)

278
Advanced Engineering Mathematics with MATLAB
Table 6.5.1: Some Useful Relationships Involving Bessel Functions of Integer Order
Jn−1(z) + Jn+1(z) = 2n
z Jn(z),
n = 1, 2, 3, . . .
Jn−1(z) −Jn+1(z) = 2J′
n(z), n = 1, 2, 3, . . . ;
J′
0(z) = −J1(z)
d
dz

znJn(z)

= znJn−1(z),
n = 1, 2, 3, . . .
d
dz

z−nJn(z)

= −z−nJn+1(z),
n = 0, 1, 2, 3, . . .
In−1(z) −In+1(z) = 2n
z In(z),
n = 1, 2, 3, . . .
In−1(z) + In+1(z) = 2I′
n(z), n = 1, 2, 3, . . . ;
I′
0(z) = I1(z)
Kn−1(z) −Kn+1(z) = −2n
z Kn(z),
n = 1, 2, 3, . . .
Kn−1(z) + Kn+1(z) = −2K′
n(z), n = 1, 2, 3, . . . ;
K′
0(z) = −K1(z)
Jn(zemπi) = enmπiJn(z)
In(zemπi) = enmπiIn(z)
Kn(zemπi) = e−mnπiKn(z) −mπicos(mnπ)
cos(nπ) In(z)
In(z) = e−nπi/2Jn(zeπi/2),
−π < arg(z) ≤π/2
In(z) = e3nπi/2Jn(ze−3πi/2),
π/2 < arg(z) ≤π
From the general orthogonality condition, Equation 6.2.1,
Z L
0
xJn(µkx)Jn(µmx) dx = 0,
(6.5.36)
if k ̸= m. Equation 6.5.35 then simpliﬁes to
Am
Z L
0
xJ2
n(µmx) dx =
Z L
0
xf(x)Jn(µmx) dx,
(6.5.37)
or
Ak = 1
Ck
Z L
0
xf(x)Jn(µkx) dx,
(6.5.38)
where
Ck =
Z L
0
xJ2
n(µkx) dx,
(6.5.39)

The Sturm-Liouville Problem
279
Table 6.5.2: Some Useful Recurrence Relations for Hankel Functions
d
dx
h
xnH(p)
n (x)
i
= xnH(p)
n−1(x), n = 1, 2, . . . ; d
dx
h
H(p)
0 (x)
i
= −H(p)
1 (x)
d
dx
h
x−nH(p)
n (x)
i
= −x−nH(p)
n+1(x),
n = 0, 1, 2, 3, . . .
H(p)
n−1(x) + H(p)
n+1(x) = 2n
x H(p)
n (x),
n = 1, 2, 3, . . .
H(p)
n−1(x) −H(p)
n+1(x) = 2dH(p)
n (x)
dx
,
n = 1, 2, 3, . . .
and k replaces m in Equation 6.5.37.
The factor Ck depends upon the nature of the boundary conditions at x = L. In all
cases we start from Bessel’s equation
[xJ′
n(µkx)]′ +

µ2
kx −n2
x

Jn(µkx) = 0.
(6.5.40)
If we multiply both sides of Equation 6.5.40 by 2xJ′
n(µkx), the resulting equation is
 µ2
kx2 −n2 
J2
n(µkx)
′ = −d
dx[xJ′
n(µkx)]2 .
(6.5.41)
An integration of Equation 6.5.41 from 0 to L, followed by the subsequent use of integration
by parts, results in
(µ2
kx2 −n2)J2
n(µkx)
L
0 −2µ2
k
Z L
0
xJ2
n(µkx) dx = −[xJ′
n(µkx)]2
L
0 .
(6.5.42)
Because Jn(0) = 0 for n > 0, J0(0) = 1 and xJ′
n(x) = 0 at x = 0, the contribution from the
lower limits vanishes. Thus,
Ck =
Z L
0
xJ2
n(µkx) dx =
1
2µ2
k

(µ2
kL2 −n2)J2
n(µkL) + L2J′
n
2(µkL)

.
(6.5.43)
Because
J′
n(µkx) = n
xJn(µkx) −µkJn+1(µkx)
(6.5.44)
from Equation 6.5.31, Ck becomes
Ck = 1
2L2J2
n+1(µkL),
(6.5.45)

280
Advanced Engineering Mathematics with MATLAB
if Jn(µkL) = 0. Otherwise, if J′
n(µkL) = 0, then
Ck = µ2
kL2 −n2
2µ2
k
J2
n(µkL).
(6.5.46)
Finally,
Ck = µ2
kL2 −n2 + h2L2
2µ2
k
J2
n(µkL),
(6.5.47)
if µkJ′
n(µkL) = −hJn(µkL).
All of the preceding results must be slightly modiﬁed when n = 0 and the boundary
condition is J′
0(µkL) = 0 or µkJ1(µkL) = 0. This modiﬁcation results from the additional
eigenvalue µ0 = 0 being present and we must add the extra term A0 to the expansion. For
this case the series reads
f(x) = A0 +
∞
X
k=1
AkJ0(µkx),
(6.5.48)
where the equation for ﬁnding A0 is
A0 = 2
L2
Z L
0
f(x) x dx,
(6.5.49)
and Equation 6.5.38 and Equation 6.5.46 with n = 0 give the remaining coeﬃcients.
• Example 6.5.1
Starting with Bessel’s equation, we show that the solution to
y′′ + 1 −2a
x
y′ +

b2c2x2c−2 + a2 −n2c2
x2

y = 0
(6.5.50)
is
y(x) = AxaJn(bxc) + BxaYn(bxc),
(6.5.51)
provided that bxc > 0 so that Yn(bxc) exists.
The general solution to
ξ2 d2η
dξ2 + ξ dη
dξ + (ξ2 −n2)η = 0
(6.5.52)
is
η = AJn(ξ) + BYn(ξ).
(6.5.53)
If we now let η = y(x)/xa and ξ = bxc, then
d
dξ = dx
dξ
d
dx = x1−c
bc
d
dx,
(6.5.54)

The Sturm-Liouville Problem
281
d2
dξ2 = x2−2c
b2c2
d2
dx2 −(c −1)x1−2c
b2c2
d
dx,
(6.5.55)
d
dx
 y
xa

= 1
xa
dy
dx −
a
xa+1 y,
(6.5.56)
and
d2
dx2
 y
xa

= 1
xa
d2y
dx2 −
2a
xa+1
dy
dx + a(1 + a)
xa+2
y.
(6.5.57)
Substituting Equation 6.5.54 and Equation 6.5.57 into Equation 6.5.52 and simplifying
yields the desired result.
⊓⊔
• Example 6.5.2
Let us ﬁnd24 the general solution to the nonhomogeneous diﬀerential equation
d2y
dr2 + 1
r
dy
dr −k2y = −S(r),
(6.5.58)
where k is a real parameter.
The homogeneous solution is
yH(r) = C1I0(kr) + C2K0(kr).
(6.5.59)
Using variation of parameters, we assume that the particular solution can be written
yp(r) = A(r)I0(kr) + B(r)K0(kr),
(6.5.60)
where
A′(r) =

0
K0(kr)
−S(r)
kK′
0(kr)

 
I0(kr)
K0(kr)
kI′
0(kr)
kK′
0(kr)
 ,
(6.5.61)
and
B′(r) =

I0(kr)
0
kI′
0(kr)
−S(r)

 
I0(kr)
K0(kr)
kI′
0(kr)
kK′
0(kr)
 .
(6.5.62)
Expanding the determinants, we ﬁnd
A′(r) = S(r)K0(kr)/ {k [I0(kr)K′
0(kr) −I′
0(kr)K0(kr)]}
(6.5.63)
and
B′(r) = −S(r)I0(kr)/ {k [I0(kr)K′
0(kr) −I′
0(kr)K0(kr)]} .
(6.5.64)
Evaluating the Wronskian25 for modiﬁed Bessel functions,
I0(z)K′
0(z) −I′
0(z)K0(z) = −1/z,
(6.5.65)
A′(r) = −rS(r)K0(kr)
and
B′(r) = rS(r)I0(kr).
(6.5.66)
24 See Hassan, M. H. A., 1988: Ion distribution functions during ion cyclotron resonance heating at the
fundamental frequency. Phys. Fluids, 31, 596–599.
25 Watson, op. cit., p. 80, Formula 19.

282
Advanced Engineering Mathematics with MATLAB
Integrating Equation 6.5.66,
A(r) = −
Z r
xS(x)K0(kx) dx,
and
B(r) =
Z r
xS(x)I0(kx) dx.
(6.5.67)
Consequently, the general solution is the sum of the particular and homogeneous solution,
y(r) = C1I0(kr) + C2K0(kr) −I0(kr)
Z r
xS(x)K0(kx) dx + K0(kr)
Z r
xS(x)I0(kx) dx.
(6.5.68)
⊓⊔
• Example 6.5.3
Let us show that
x2J′′
n(x) = (n2 −n −x2)Jn(x) + xJn+1(x).
(6.5.69)
From Equation 6.5.31,
J′
n(x) = n
xJn(x) −Jn+1(x),
(6.5.70)
J′′
n(x) = −n
x2 Jn(x) + n
xJ′
n(x) −J′
n+1(x),
(6.5.71)
and
J′′
n(x) = −n
x2 Jn(x) + n
x
hn
xJn(x) −Jn+1(x)
i
−

Jn(x) −n + 1
x
Jn+1(x)

(6.5.72)
after using Equation 6.5.30 and Equation 6.5.31. Simplifying,
J′′
n(x) =
n2 −n
x2
−1

Jn(x) + Jn+1(x)
x
.
(6.5.73)
After multiplying Equation 6.5.73 by x2, we obtain Equation 6.5.69.
⊓⊔
• Example 6.5.4
Let us show that
Z a
0
x5J2(x) dx = a5J3(a) −2a4J4(a).
(6.5.74)
We begin by integrating Equation 6.5.74 by parts. If u = x2, and dv = x3J2(x) dx,
then
Z a
0
x5J2(x) dx = x5J3(x)
a
0 −2
Z a
0
x4J3(x) dx,
(6.5.75)
because d[x3J3(x)]/dx = x2J2(x) by Equation 6.5.28. Finally,
Z a
0
x5J2(x) dx = a5J3(a) −2x4J4(x)
a
0 = a5J3(a) −2a4J4(a),
(6.5.76)
since x4J3(x) = d[x4J4(x)]/dx by Equation 6.5.28.
⊓⊔

The Sturm-Liouville Problem
283
• Example 6.5.5
Let us expand f(x) = x, 0 < x < 1, in the series
f(x) =
∞
X
k=1
AkJ1(µkx),
(6.5.77)
where µk denotes the kth zero of J1(µ). From Equation 6.5.38 and Equation 6.5.46,
Ak =
2
J2
2(µk)
Z 1
0
x2J1(µkx) dx.
(6.5.78)
However, from Equation 6.5.28,
d
dx

x2J2(x)

= x2J1(x),
(6.5.79)
if n = 2. Therefore, Equation 6.5.78 becomes
Ak = 2x2J2(x)
µ3
kJ2
2(µk)

µk
0
=
2
µkJ2(µk),
(6.5.80)
and the resulting expansion is
x = 2
∞
X
k=1
J1(µkx)
µkJ2(µk),
0 ≤x < 1.
(6.5.81)
Figure 6.5.5 shows the Fourier-Bessel expansion of f(x) = x in truncated form when we
only include one, two, three, and four terms. It was created using the MATLAB script
clear;
x = [0:0.01:1]; % create x points in plot
f = x; % construct function f(x)
% initialize Fourier-Bessel series
fbessel = zeros(size(x));
% read in the first four zeros of J 1(mu) = 0
mu(1) =
3.83171; mu(2) =
7.01559;
mu(3) = 10.17347; mu(4) = 13.32369;
clf % clear any figures
for n = 1:4
% Fourier coefficient
factor = 2 / (mu(n) * besselj(2,mu(n)));
% compute Fourier-Bessel series
fbessel = fbessel + factor * besselj(1,mu(n)*x);
% create plot of truncated Fourier-Bessel series
%
with n terms
subplot(2,2,n), plot(x,fbessel,x,f,’--’)
axis([0 1 -0.25 1.25])
if n == 1 legend(’1 term’,’f(x)’); legend boxoff;
else legend([num2str(n) ’ terms’],’f(x)’); legend boxoff;
end

284
Advanced Engineering Mathematics with MATLAB
0
0.5
1
0
0.5
1
1 term
f(x)
0
0.5
1
0
0.5
1
2 terms
f(x)
0
0.5
1
0
0.5
1
x
3 terms
f(x)
0
0.5
1
0
0.5
1
x
4 terms
f(x)
Figure 6.5.5: The Fourier-Bessel series representation, Equation 6.5.81, for f(x) = x, 0 < x < 1, when we
truncate the series so that it includes only the ﬁrst, ﬁrst two, ﬁrst three, and ﬁrst four terms.
if n > 2 xlabel(’x’,’Fontsize’,20); end
end
⊓⊔
• Example 6.5.6
Let us expand the function f(x) = x2, 0 < x < 1, in the series
f(x) =
∞
X
k=1
AkJ0(µkx),
(6.5.82)
where µk denotes the kth positive zero of J0(µ). From Equation 6.5.38 and Equation 6.5.46,
Ak =
2
J2
1(µk)
Z 1
0
x3J0(µkx) dx.
(6.5.83)
If we let t = µkx, the integration, Equation 6.5.83, becomes
Ak =
2
µ4
kJ2
1(µk)
Z µk
0
t3J0(t) dt.
(6.5.84)
We now let u = t2 and dv = tJ0(t) dt so that integration by parts results in
Ak =
2
µ4
kJ2
1(µk)

t3J1(t)
µk
0 −2
Z µk
0
t2J1(t) dt

=
2
µ4
kJ2
1(µk)

µ3
kJ1(µk) −2
Z µk
0
t2J1(t) dt

,
(6.5.85)
because v = tJ1(t) from Equation 6.5.28. If we integrate by parts once more, we ﬁnd that
Ak =
2
µ4
kJ2
1(µk)

µ3
kJ1(µk) −2µ2
kJ2(µk)

=
2
J2
1(µk)
J1(µk)
µk
−2J2(µk)
µ2
k

.
(6.5.86)
However, from Equation 6.5.32 with n = 1,
J1(µk) = 1
2µk [J2(µk) + J0(µk)] ,
(6.5.87)

The Sturm-Liouville Problem
285
0.0
0.2
0.4
0.6
0.8
1.0
x
-0.50
-0.25
0.00
0.25
0.50
0.75
1.00
-0.50
-0.25
0.00
0.25
0.50
0.75
1.00
0.0
0.2
0.4
0.6
0.8
1.0
x
three terms
one term
four terms
two terms
Figure 6.5.6: The Fourier-Bessel series representation, Equation 6.5.90, for f(x) = x2, 0 < x < 1, when
we truncate the series so that it includes only the ﬁrst, ﬁrst two, ﬁrst three, and ﬁrst four terms.
or
J2(µk) = 2J1(µk)
µk
,
(6.5.88)
because J0(µk) = 0. Therefore,
Ak = 2(µ2
k −4)J1(µk)
µ3
kJ2
1(µk)
,
(6.5.89)
and
x2 = 2
∞
X
k=1
(µ2
k −4)J0(µkx)
µ3
kJ1(µk)
,
0 < x < 1.
(6.5.90)
Figure 6.5.6 shows the representation of x2 by the Fourier-Bessel series, Equation 6.5.90
when we truncate it so that it includes only one, two, three, or four terms. As we add each
additional term in the orthogonal expansion, the expansion ﬁts f(x) better in the “least
squares” sense of Equation 6.3.5.
Problems
1. Show from the series solution that
d
dx [J0(kx)] = −kJ1(kx).
From the recurrence formulas, show the following relations:
2.
2J′′
0 (x) = J2(x) −J0(x)
3.
J2(x) = J′′
0 (x) −J′
0(x)/x
4.
J′′′
0 (x) = J0(x)
x
+
 2
x2 −1

J′
0(x)

286
Advanced Engineering Mathematics with MATLAB
5.
J2(x)
J1(x) = 1
x −J′′
0 (x)
J′
0(x) = 2
x −J0(x)
J1(x) = 2
x + J0(x)
J′
0(x)
6.
J4(x) =
48
x3 −8
x

J1(x) −
24
x2 −1

J0(x)
7.
Jn+2(x) =

2n + 1 −2n(n2 −1)
x2

Jn(x) + 2(n + 1)J′′
n(x)
8.
J3(x) =
 8
x2 −1

J1(x) −4
xJ0(x)
9.
4J′′
n(x) = Jn−2(x) −2Jn(x) + Jn+2(x)
10. Show that the maximum and minimum values of Jn(x) occur when
x = nJn(x)
Jn+1(x),
x = nJn(x)
Jn−1(x),
and
Jn−1(x) = Jn+1(x).
Show that
11.
d
dx

x2J3(2x)

= −xJ3(2x) + 2x2J2(2x)
12.
d
dx

xJ0(x2)

= J0(x2) −2x2J1(x2)
13.
Z
x3J2(3x) dx = 1
3x3J3(3x) + C
14.
Z
x−2J3(2x) dx = −1
2x−2J2(2x) + C
15.
Z
x ln(x)J0(x) dx = J0(x) + x ln(x)J1(x) + C
16.
Z a
0
xJ0(kx) dx = a2J1(ka)
ka

The Sturm-Liouville Problem
287
17.
Z 1
0
x(1 −x2)J0(kx) dx = 4
k3 J1(k) −2
k2 J0(k)
18.
Z 1
0
x3J0(kx) dx = k2 −4
k3
J1(k) + 2
k2 J0(k)
19. Show that
1 = 2
∞
X
k=1
J0(µkx)
µkJ1(µk),
0 ≤x < 1,
where µk is the kth positive root of J0(µ) = 0. Then use MATLAB to illustrate various
partial sums of the Fourier-Bessel series.
20. Show that
1 −x2
8
=
∞
X
k=1
J0(µkx)
µ3
kJ1(µk),
0 ≤x ≤1,
where µk is the kth positive root of J0(µ) = 0. Then use MATLAB to illustrate various
partial sums of the Fourier-Bessel series.
21. Show that
4x −x3 = −16
∞
X
k=1
J1(µkx)
µ3
kJ0(2µk),
0 ≤x ≤2,
where µk is the kth positive root of J1(2µ) = 0. Then use MATLAB to illustrate various
partial sums of the Fourier-Bessel series.
22. Show that
x3 = 2
∞
X
k=1
(µ2
k −8)J1(µkx)
µ3
kJ2(µk)
,
0 ≤x ≤1,
where µk is the kth positive root of J1(µ) = 0. Then use MATLAB to illustrate various
partial sums of the Fourier-Bessel series.
23. Show that
x = 2
∞
X
k=1
µkJ2(µk)J1(µkx)
(µ2
k −1)J2
1(µk) ,
0 ≤x ≤1,
where µk is the kth positive root of J′
1(µ) = 0. Then use MATLAB to illustrate various
partial sums of the Fourier-Bessel series.
24. Show that
1 −x4 = 32
∞
X
k=1
(µ2
k −4)J0(µkx)
µ5
kJ1(µk)
,
0 ≤x ≤1,
where µk is the kth positive root of J0(µ) = 0. Then use MATLAB to illustrate various
partial sums of the Fourier-Bessel series.

288
Advanced Engineering Mathematics with MATLAB
25. Show that
1 = 2αL
∞
X
k=1
J0(µkx/L)
(µ2
k + α2L2)J0(µk),
0 ≤x ≤L,
where µk is the kth positive root of µJ1(µ) = αLJ0(µ). Then use MATLAB to illustrate
various partial sums of the Fourier-Bessel series.
26. Using the relationship26
Z a
0
Jν(αr)Jν(βr) r dr = aβJν(αa)J′
ν(βa) −aαJν(βa)J′
ν(αa)
α2 −β2
,
show that
J0(bx) −J0(ba)
J0(ba)
= 2b2
a
∞
X
k=1
J0(µkx)
µk(µ2
k −b2)J1(µka),
0 ≤x ≤a,
where µk is the kth positive root of J0(µa) = 0 and b is a constant.
27. Given the deﬁnite integral27
Z 1
0
x J0(bx)
√
1 −x2 dx = sin(b)
b
,
0 < b,
show that
H(t −x)
√
t2 −x2 = 2
∞
X
k=1
sin(µkt)J0(µkx)
µkJ2
1(µk)
,
0 < x < 1,
0 < t ≤1,
where µk is the kth positive root of J0(µ) = 0 and H(·) is Heaviside’s step function.
28. Using the same deﬁnite integral from the previous problem, show28 that
H(a −x)
√
a2 −x2 = 2
b
∞
X
n=1
sin(µna/b)J0(µnx/b)
µnJ2
0(µn)
,
0 ≤x < b,
where a < b, µn is the nth positive root of J′
0(µ) = −J1(µ) = 0, and H(·) is Heaviside’s
step function.
29. Given the deﬁnite integral29
Z a
0
cos(cx) J0

b
p
a2 −x2

dx = sin
 a
√
b2 + c2 
√
b2 + c2
,
0 < b,
26 Watson, op. cit., Section 5.11, Equation 8.
27 Gradshteyn, I. S., and I. M. Ryzhik, 1965: Table of Integrals, Series, and Products. Academic Press,
Section 6.567, Formula 1 with ν = 0 and µ = −1/2.
28 See Wei, X. X., 2000: Finite solid circular cylinders subjected to arbitrary surface load.
Part II–
Application to double-punch test. Int. J. Solids Struct., 37, 5733–5744.
29 Gradshteyn and Ryzhik, op. cit., Section 6.677, Formula 6.

The Sturm-Liouville Problem
289
show that
cosh
 b
√
t2 −x2 
√
t2 −x2
H(t −x) = 2
a2
∞
X
k=1
sin

t
p
µ2
k −b2

J0(µkx)
p
µ2
k −b2 J2
1(µka)
,
where 0 < x < a, µk is the kth positive root of J0(µa) = 0, H(·) is Heaviside’s step function,
and b is a constant.
30. Using the integral deﬁnition of the Bessel function30 for J1(z):
J1(z) = 2
π
Z 1
0
t sin(zt)
√
1 −t2 dt,
0 < z,
show that
x
t
√
t2 −x2 H(t −x) = π
L
∞
X
n=1
J1
nπt
L

sin
nπx
L

,
0 ≤x < L,
where H(·) is Heaviside’s step function.
Hint: Treat this as a Fourier half-range sine
expansion.
31. Show that
δ(x −b) = 2b
a2
∞
X
k=1
J0(µkb/a)J0(µkx/a)
J2
1(µk)
,
0 ≤x, b < a,
where µk is the kth positive root of J0(µ) = 0 and δ(·) is the Dirac delta function.
32. Show that
δ(x)
2πx =
1
πa2
∞
X
k=1
J0(µkx/a)
J2
1(µk)
,
0 ≤x < a,
where µk is the kth positive root of J0(µ) = 0 and δ(·) is the Dirac delta function.
6.6 FINITE ELEMENT METHOD
In Section 1.7 we showed how to solve ordinary diﬀerential equations using ﬁnite diﬀer-
ences. Here we introduce a popular alternative, the ﬁnite element method, and will use it
to solve the Sturm-Liouville problem. One advantage of this approach is that we can focus
on the details of the numerical scheme.
The ﬁnite element method breaks the global solution domain into a number of simply
shaped subdomains, called elements. The global solution is then constructed by assembling
the results from all of the elements.
A particular strength of this method is that the
elements do not have to be the same size; this allows us to have more resolution in regions
where the solution is rapidly changing and fewer elements where the solution changes slowly.
Overall the solution of the ordinary diﬀerential equation is given by a succession of piecewise
continuous functions.
30 Gradshteyn and Ryzhik, Ibid., Section 3.753, Formula 5.

290
Advanced Engineering Mathematics with MATLAB
Consider the Sturm-Liouville problem
−d
dx

p(x)dy
dx

+ q(x)y(x) −λr(x)y(x) = 0,
a < x < b,
(6.6.1)
with
y(a) = 0,
or
p(a)y′(a) = 0,
(6.6.2)
and
y(b) = 0,
or
p(b)y′(b) = 0.
(6.6.3)
Our formulation of the ﬁnite element approximation to the exact solution is called the
Galerkin weighted residual approach. This is not the only possible way of formulating the
ﬁnite element equations but it is similar to the eigenfunction expansions that we highlighted
in this chapter. Our approach consists of two steps: First we assume that y(x) can be
expressed over a particular element by
y(x) =
J
X
j=1
yjϕj(x),
(6.6.4)
where ϕj(x) is the jth approximation or shape function, and J is the total number of
elements.
Let us deﬁne the residue
R(x) = −d
dx

p(x)dy
dx

+ q(x)y(x) −λr(x)y(x).
(6.6.5)
We now require that for each element along the segment Ωe = (xn, xn+1),
Z
Ωe
R(x)ϕi(x) dx = 0,
i = 1, 2, 3, . . . , J.
(6.6.6)
The points xn and xn+1 are known as nodes. Substituting Equation 6.6.5 into Equation
6.6.6,
Z
Ωe

−d
dx

p(x)dy
dx

+ q(x)y(x) −λr(x)y(x)

ϕi(x) dx = 0.
(6.6.7)
Because
−
Z xn+1
xn
d
dx

p(x)dy
dx

ϕi(x) dx = −p(x)dy
dxϕi(x)

xn+1
xn
+
Z xn+1
xn
p(x)dy
dx
dϕi(x)
dx
dx, (6.6.8)
then
Z xn+1
xn

p(x)dy
dx
dϕi(x)
dx
+q(x)y(x)ϕi(x)−λr(x)y(x)φi(x)

dx = p(x)dy
dxϕi(x)

xn+1
xn
. (6.6.9)
Upon using Equation 6.6.4 to eliminate y(x) and reversing the order of summation and
integration, our second step in the ﬁnite element method involves solving for yj via
J
X
j=1
Z xn+1
xn
p(x)dϕi(x)
dx
dϕj(x)
dx
dx +
Z xn+1
xn
q(x)ϕi(x)ϕj(x) dx
−λ
Z xn+1
xn
r(x)ϕi(x)ϕj(x) dx

yj = p(x)dy
dxϕi(x)

xn+1
xn
,
(6.6.10)

The Sturm-Liouville Problem
291
or using matrix notation
Ky −λMy = b,
(6.6.11)
where
K =




K11
K12
. . .
K1J
K21
K22
. . .
K2J
...
...
...
...
KJ1
KJ2
. . .
KJJ



,
M =




M11
M12
. . .
M1J
M21
M22
. . .
M2J
...
...
...
...
MJ1
MJ2
. . .
MJJ




(6.6.12)
b =




b1
b2
...
bJ



,
y =




y1
y2
...
yJ



,
(6.6.13)
bi = p(xn+1)y′(xn+1)ϕi(xn+1) −p(xn)y′(xn)ϕi(xn),
(6.6.14)
Kij =
Z xn+1
xn
p(x)dϕi(x)
dx
dϕj(x)
dx
dx +
Z xn+1
xn
q(x)ϕi(x)ϕj(x) dx,
(6.6.15)
and
Mij =
Z xn+1
xn
r(x)ϕi(x)ϕj(x) dx.
(6.6.16)
Why do we prefer to use Equation 6.6.10 rather than Equation 6.6.7?
There are
two reasons. First, it oﬀers a convenient method for introducing the speciﬁed boundary
conditions, Equation 6.6.2 and Equation 6.6.3. Second, it has lowered the highest-order
derivatives from a second to a ﬁrst derivative. This yields the signiﬁcant beneﬁt that ϕi(x)
must only be continuous but not necessarily a continuous slope at the nodes.
An important question is how we will evaluate the integrals in Equation 6.6.15 and
Equation 6.6.16. Because p(x), q(x), and r(x) are known, we could substitute these quanti-
ties along with ϕi(x) and ϕj(x) into Equation 6.6.15 and Equation 6.6.16 and perform the
integration, presumably numerically. In a similar vein, we could develop curve ﬁts for p(x),
q(x), and r(x) and again perform the integrations. However, we simply use their values at
the midpoint between the nodes, xn = (xn+1 + xn)/2, because p(x), q(x) and r(x) usually
vary slowly over the interval (xn, xn+1).
At this point we will specify J. The simplest case is J = 2 and we have the linear
element:
ϕ1(x) = x −x1
x2 −x1
and
ϕ2(x) = x2 −x
x2 −x1
,
(6.6.17)
where x1 and x2 are local nodal points located at the end of the element. It directly follows
that
dy
dx = dϕ1
dx y1 + dϕ2
dx y2 = y2 −y1
x2 −x1
.
(6.6.18)
In other words, dy/dx equals the slope of the straight line connecting the nodes. Similarly,
Z x2
x1
y(x) dx = 1
2 (y2 + y1) (x2 −x1)
(6.6.19)
and we simply have the trapezoidal rule.

292
Advanced Engineering Mathematics with MATLAB
Table 6.6.1: The System Topology for 4 Finite-Element Segmentations When a Linear
Interpolation Is Used
Node Numbers
Element
Local
Global
1
1
1
2
2
2
1
2
2
3
3
1
3
2
4
4
1
4
2
5
Substituting ϕ1(x) and ϕ2(x) into Equation 6.6.15 and Equation 6.6.16 and carrying
out the integration, we obtain
K11 = p(xc)
L
+ q(xc)L
3
,
K12 = −p(xc)
L
+ q(xc)L
6
,
K21 = K12,
and
K22 = K11,
(6.6.20)
with L = x2 −x1 and xc = (x1 + x2)/2. Similarly,
M11 = r(xc)L
3
= M22,
and
M12 = r(xc)L
6
= M21.
(6.6.21)
Finally, because ϕ1(x1) = 0, ϕ1(x2) = 1, ϕ2(x1) = 1, and ϕ2(x2) = 0, b1 = −p(x1)y′(x1)
and b2 = p(x2)y2(x2).
Having obtained the ﬁnite element representation for nodes 1 and 2, we would like to
extend these results to an arbitrary number of additional nodes. This is done by setting up
a look-up table that relates the global nodal points to the local ones. For example, suppose
we would like 5 nodes between a and b with x = x1, x2, x3, x4, and x5. Then Table 6.6.1
illustrates our look-up table.
Having developed the spatial layout, we are now ready to assemble the matrix for the
entire interval (a, b). For clarity we will give the intermediate steps. Taking the ﬁrst element
into account,
K =






K(1)
11
K(1)
12
0
0
0
K(1)
21
K(1)
22
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0






,
M =






M (1)
11
M (1)
12
0
0
0
M (1)
21
M (1)
22
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0






,
(6.6.22)
b =





−p(x1)y′(x1)
p(x2)y′(x2)
0
0
0




,
and
y =





y1
y2
0
0
0




.
(6.6.23)

The Sturm-Liouville Problem
293
Here we have added a subscript (1) to Kij and Mij to denote that value for the ﬁrst element
should be used in computing p(xc), q(xc), r(xc), and L. Consequently, when we introduce
the second element, K, M, and y become
K =






K(1)
11
K(1)
12
0
0
0
K(1)
21
K(1)
22 + K(2)
11
K(2)
12
0
0
0
K(2)
21
K(2)
22
0
0
0
0
0
0
0
0
0
0
0
0






,
(6.6.24)
M =






M (1)
11
M (1)
12
0
0
0
M (1)
21
M (1)
22 + M (2)
11
M (2)
12
0
0
0
M (2)
21
M (2)
22
0
0
0
0
0
0
0
0
0
0
0
0






,
(6.6.25)
b =





−p(x1)y′(x1)
0
p(x3)y′(x3)
0
0




,
and
y =





y1
y2
y3
0
0




.
(6.6.26)
Note that the numbering for yi corresponds to ith global node number. Continuing with
this process of adding additional elements to the system matrix, we ﬁnally have
K =







K(1)
11
K(1)
12
0
0
0
K(1)
21
K(1)
22 + K(2)
11
K(2)
12
0
0
0
K(2)
21
K(2)
22 + K(3)
11
K(3)
12
0
0
0
K(3)
21
K(3)
22 + K(4)
11
K(4)
12
0
0
0
K(4)
21
K(4)
22







,
(6.6.27)
M =







M (1)
11
M (1)
12
0
0
0
M (1)
21
M (1)
22 + M (2)
11
M (2)
12
0
0
0
M (2)
21
M (2)
22 + M (3)
11
M (3)
12
0
0
0
M (3)
21
M (3)
22 + M (4)
11
M (4)
12
0
0
0
M (4)
21
M (4)
22







,
(6.6.28)
where
b =





−p(x1)y′(x1)
0
0
0
p(x5)y′(x5)




,
and
y =





y1
y2
y3
y4
y5




.
(6.6.29)
Let us examine the b vector more closely. In the ﬁnal form of the ﬁnite element formu-
lation, b has non-zero values only at the end points; the contributions from intermediate
nodal points vanish because p(x)y′(x) is continuous within the interval (a, b). Furthermore,
if y′(a) = y′(b) = 0 from the boundary conditions, then the b vector becomes the zero
vector. On the other hand, if y(a) = y(b) = 0, then y1 = y5 = 0 and the eigenvalue problem
involves a 3 × 3 matrix with the unknowns y2, y3, and y4. Similarly, if y′(a) = y(b) = 0,
then we have a 4 × 4 matrix with the unknowns y1, y2, y3, y4, and y5 = 0. Finally, if

294
Advanced Engineering Mathematics with MATLAB
Table 6.6.2: The Lowest Eigenvalue for Equation 6.6.30, Which Is Solved Using a Finite
Element Method
L
λ
0.250
10.6745
0.100
10.2335
0.050
10.1717
0.020
10.1544
0.010
10.1520
0.002
10.1512
y(a) = y′(b) = 0, we again have a 4 × 4 matrix involving y1 = 0 and the unknowns y2, y3,
y4, and y5.
To illustrate this scheme, consider the Sturm-Liouville problem
y′′ + (λ −x2)y = 0,
0 < x < 1
(6.6.30)
with y(0) = y(1) = 0. Here p(x) = 1, q(x) = x2, and r(x) = 1.
The MATLAB begins with the choice of the number of elements, N. Once that is done,
L immediately follows because L = 1/(N-1). We will also need to have the value of x at
the node points x(n) = L*(n-1) where n = 1:N.
With these preliminaries out of the way, we begin by setting up the matrices K and
M given by Equation 6.6.27 and Equation 6.6.28. The corresponding MATLAB code is
for i = 1:N-1
x c = 0.5*(x(i) + x(i+1));
p = 1; q = x c*x c; r = 1;
K 11 = p/L + q*L/3; K 22 = K 11;
K 12 = -p/L + q*L/6; K 21 = K 12;
M 11 = r*L/3; M 22 = M 11;
M 12 = r*L/6; M 21 = M 12;
KK( i , i ) = KK( i , i ) + K 11;
KK( i ,i+1) = KK( i ,i+1) + K 12;
KK(i+1, i ) = KK(i+1, i ) + K 21;
KK(i+1,i+1) = KK(i+1,i+1) + K 22;
MM( i , i ) = MM( i , i ) + M 11;
MM( i ,i+1) = MM( i ,i+1) + M 12;
MM(i+1, i ) = MM(i+1, i ) + M 21;
MM(i+1,i+1) = MM(i+1,i+1) + M 22;
end
Note that the arrays KK and MM have already been deﬁned as N × N arrays with all of their
elements set to zero.
Finally, because y1 and yN are zero, we must extract that portion of K and M for
which ym ̸= 0. This is done as follows:
for j = 1:N-2
for i = 1:N-2
A(i,j) = KK(i+1,j+1);
B(i,j) = MM(i+1,j+1);
end; end

The Sturm-Liouville Problem
295
0
0.2
0.4
0.6
0.8
1
−5.2
−5
−4.8
−4.6
−4.4
−4.2
−4
−3.8
−3.6
x
y(x)
Figure 6.6.1: Numerical solution of y′′ + 2y′ + y = 2x + 3 sin(x) with y′(0) = −2 and y′(1) = 3 using ﬁnite
elements with ∆x = 0.1. The crosses indicate the exact solution.
Finally, the eigenvalues are found by eig(A,B). If the corresponding eigenfunction is
desired, then the corresponding eigenfunction gives yj for j = 2, 3, . . . , N −1 using Equation
6.6.4.
Table 6.6.2 illustrates how the lowest eigenvalue for Equation 6.6.30 improves in
accuracy as the number of nodes is increased.
Project: Finite Element Solution of Boundary-Value Problems
In addition to solving the Sturm-Liouville problem, ﬁnite element methods can be used
to solve the standard boundary-value problem:
−d
dx

p(x)dy
dx

+ q(x)y = f(x),
0 < x < 1,
where we specify y(0) or y′(0) at x = 0 and y(1) or y′(1) at x = 1. Although you could
create your MATLAB code to solve this problem, MATLAB code has already been developed
and is available online.31 The purpose of this project is for you to become comfortable using
this scheme.
Step 1: Using the method of undetermined coeﬃcients, solve the boundary-value problem
y′′ + 2y′ + y = 2x + 3 sin(x),
y′(0) = −2,
y′(1) = 3.
Show that
y(x) = 2x −4 −3
2 cos(x) + 1
2 [3 sin(1) −2] e1−x + 1
2 [3 sin(1) −2 −8/e] xe1−x.
Step 2: Show that the ordinary diﬀerential equation can be written as
d
dx

e2x dy
dx

+ e2xy = 2xe2x + 3e2x sin(x),
y′(0) = −2,
y′(1) = 3.
Step 3: Find the numerical solution of the boundary-value problem using ﬁnite elements.
Figure 6.6.1 illustrates the solution.
31 For example, http://people.sc.fsu.edu/~burkardt/m src/fem1d/fem1d.html

296
Advanced Engineering Mathematics with MATLAB
Further Readings
Hobson, E. W., 1965: The Theory of Spherical and Ellipsoidal Harmonics. Chelsea Pub-
lishers, 500 pp. The classic treatise on Legendre polynomials.
Lebedev, N. N., 1972: Special Functions and Their Applications. Dover, 308 pp. A very
practical guide to the special functions found in the natural sciences and engineering.
Titchmarsh, E. C., 1946: Eigenfunction Expansions Associated with Second Order Diﬀeren-
tial Equations. Camp Press, 188 pp. A rigorous treatment of the Sturm-Liouville problem.
Watson, G. N., 1966: A Treatise on the Theory of Bessel Functions. Cambridge University
Press, 804 pp. The standard reference on Bessel functions.

Chapter 7
The Wave Equation
In this chapter we will study problems associated with the equation
∂2u
∂t2 = c2 ∂2u
∂x2 ,
(7.0.1)
where u = u(x, t), x and t are the two independent variables, and c is a constant. This
equation, called the wave equation, serves as the prototype for a wider class of hyperbolic
equations
a(x, t)∂2u
∂x2 + b(x, t) ∂2u
∂x∂t + c(x, t)∂2u
∂t2 = f

x, t, u, ∂u
∂x, ∂u
∂t

,
(7.0.2)
where b2 > 4ac.
It arises in the study of many important physical problems involving
wave propagation, such as the transverse vibrations of an elastic string and the longitudinal
vibrations or torsional oscillations of a rod.
7.1 THE VIBRATING STRING
The motion of a string of length L and constant density ρ (mass per unit length) is
a simple example of a physical system described by the wave equation. See Figure 7.1.1.
Assuming that the equilibrium position of the string and the interval [0, L] along the x-axis
297

298
Advanced Engineering Mathematics with MATLAB
x
∆
x+
L
T2
α2
T1
1
α
u(x,t)
0
x
Figure 7.1.1: The vibrating string.
coincide, the equation of motion that describes the vertical displacement u(x, t) of the string
follows by considering a short piece whose ends are at x and x+∆x and applying Newton’s
second law.
If we assume that the string is perfectly ﬂexible and oﬀers no resistance to bending,
Figure 7.1.1 shows the forces on an element of the string. Applying Newton’s second law
in the x-direction, the sum of forces equals
−T(x) cos(α1) + T(x + ∆x) cos(α2),
(7.1.1)
where T(x) denotes the tensile force. If we assume that a point on the string moves only
in the vertical direction, the sum of forces in Equation 7.1.1 equals zero and the horizontal
component of tension is constant:
−T(x) cos(α1) + T(x + ∆x) cos(α2) = 0,
(7.1.2)
and
T(x) cos(α1) = T(x + ∆x) cos(α2) = T, a constant.
(7.1.3)
If gravity is the only external force, Newton’s law in the vertical direction gives
−T(x) sin(α1) + T(x + ∆x) sin(α2) −mg = m∂2u
∂t2 ,
(7.1.4)
where utt is the acceleration. Because
T(x) =
T
cos(α1),
and
T(x + ∆x) =
T
cos(α2),
(7.1.5)
then
−T tan(α1) + T tan(α2) −ρg∆x = ρ∆x∂2u
∂t2 .
(7.1.6)
The quantities tan(α1) and tan(α2) equal the slope of the string at x and x + ∆x, respec-
tively; that is,
tan(α1) = ∂u(x, t)
∂x
,
and
tan(α2) = ∂u(x + ∆x, t)
∂x
.
(7.1.7)
Substituting Equation 7.1.7 into Equation 7.1.6,
T
∂u(x + ∆x, t)
∂x
−∂u(x, t)
∂x

= ρ∆x
∂2u
∂t2 + g

.
(7.1.8)

The Wave Equation
299
After dividing through by ∆x, we have a diﬀerence quotient on the left:
T
∆x
∂u(x + ∆x, t)
∂x
−∂u(x, t)
∂x

= ρ
∂2u
∂t2 + g

.
(7.1.9)
In the limit as ∆x →0, this diﬀerence quotient becomes a partial derivative with respect
to x, leaving Newton’s second law in the form
T ∂2u
∂x2 = ρ∂2u
∂t2 + ρg,
(7.1.10)
or
∂2u
∂x2 = 1
c2
∂2u
∂t2 + g
c2 ,
(7.1.11)
where c2 = T/ρ. Because utt is generally much larger than g, we can neglect the last term,
giving the equation of the vibrating string as
∂2u
∂x2 = 1
c2
∂2u
∂t2 .
(7.1.12)
Equation 7.1.12 is the one-dimensional wave equation.
As a second example1 we derive the threadline equation, which describes how a thread
composed of yarn vibrates as we draw it between two eyelets spaced a distance L apart.
We assume that the tension in the thread is constant, the vibrations are small, the thread
is perfectly ﬂexible, the eﬀects of gravity and air drag are negligible, and the mass of the
thread per unit length is constant. Unlike the vibrating string between two ﬁxed ends, we
draw the threadline through the eyelets at a speed V so that a segment of thread experiences
motion in both the x and y directions as it vibrates about its equilibrium position. The
eyelets may move in the vertical direction.
From Newton’s second law,
d
dt

mdy
dt

=
X
forces,
(7.1.13)
where m is the mass of the thread. But
dy
dt = ∂y
∂t + dx
dt
∂y
∂x.
(7.1.14)
Because dx/dt = V ,
dy
dt = ∂y
∂t + V ∂y
∂x,
(7.1.15)
and
d
dt

mdy
dt

= ∂
∂t

m
∂y
∂t + V ∂y
∂x

+ V ∂
∂x

m
∂y
∂t + V ∂y
∂x

.
(7.1.16)
Because both m and V are constant, it follows that
d
dt

mdy
dt

= m∂2y
∂t2 + 2mV ∂2y
∂x∂t + mV 2 ∂2y
∂x2 .
(7.1.17)
1 See Swope, R. D., and W. F. Ames, 1963: Vibrations of a moving threadline. J. Franklin Inst., 275,
36–55.

300
Advanced Engineering Mathematics with MATLAB
The sum of the forces again equals
T ∂2y
∂x2 ∆x
(7.1.18)
so that the threadline equation is
T ∂2y
∂x2 ∆x = m∂2y
∂t2 + 2mV ∂2y
∂x∂t + mV 2 ∂2y
∂x2 ,
(7.1.19)
or
∂2y
∂t2 + 2V ∂2y
∂x∂t +

V 2 −gT
ρ
 ∂2y
∂x2 = 0,
(7.1.20)
where ρ is the density of the thread. Although Equation 7.1.20 is not the classic wave
equation given in Equation 7.1.12, it is an example of a hyperbolic equation. As we shall see,
the solutions to hyperbolic equations share the same behavior, namely, wave-like motion.
7.2 INITIAL CONDITIONS: CAUCHY PROBLEM
Any mathematical model of a physical process must include not only the governing
diﬀerential equation but also any conditions that are imposed on the solution. For exam-
ple, in time-dependent problems the solution must conform to the initial condition of the
modeled process. Finding those solutions that satisfy the initial conditions (initial data) is
called the Cauchy problem.
In the case of partial diﬀerential equations with second-order derivatives in time, such
as the wave equation, we correctly pose the Cauchy boundary condition if we specify the
value of the solution u(x, t0) = f(t) and its time derivative ut(x, t0) = g(t) at some initial
time t0, usually taken to be t0 = 0. The functions f(t) and g(t) are called the Cauchy data.
We require two conditions involving time because the diﬀerential equation has two time
derivatives.
In addition to the initial conditions, we must specify boundary conditions in the spa-
tial direction. For example, we may require that the end of the string be ﬁxed. In the
next chapter, we discuss boundary conditions in greater depth. However, one boundary
condition that is uniquely associated with the wave equation on an open domain is the
radiation condition. It requires that the waves radiate oﬀto inﬁnity and remain ﬁnite as
they propagate there.
In summary, Cauchy boundary conditions, along with the appropriate spatial boundary
conditions, uniquely determine the solution to the wave equation; any additional information
is extraneous. Having developed the diﬀerential equation and initial conditions necessary to
solve the wave equation, let us now turn to the actual methods used to solve this equation.
7.3 SEPARATION OF VARIABLES
Separation of variables is the most popular method for solving the wave equation.
Despite its current widespread use, its initial application to the vibrating string problem
was controversial because of the use of a half-range Fourier sine series to represent the initial
conditions. On one side, Daniel Bernoulli claimed (in 1775) that he could represent any
general initial condition with this technique. To d’Alembert and Euler, however, the half-
range Fourier sine series, with its period of 2L, could not possibly represent any arbitrary

The Wave Equation
301
function.2
However, by 1807 Bernoulli was proven correct by the use of separation of
variables in the heat conduction problem and it rapidly grew in acceptance.3 In the following
examples we show how to apply this method.
Separation of variables consists of four distinct steps that convert a second-order par-
tial diﬀerential equation into two ordinary diﬀerential equations. First, we assume that
the solution equals the product X(x)T(t). Direct substitution into the partial diﬀerential
equation and boundary conditions yields two ordinary diﬀerential equations and the corre-
sponding boundary conditions. Step two involves solving a boundary-value problem of the
Sturm-Liouville type. In step three we ﬁnd the corresponding time dependence. Finally we
construct the complete solution as a sum of all product solutions. Upon applying the initial
conditions, we have an eigenfunction expansion and must compute the Fourier coeﬃcients.
The substitution of these coeﬃcients into the summation yields the complete solution.
• Example 7.3.1
Let us solve the wave equation for the special case when we clamp the string at x = 0
and x = L. Mathematically, we ﬁnd the solution to the wave equation
∂2u
∂t2 = c2 ∂2u
∂x2 ,
0 < x < L,
0 < t,
(7.3.1)
which satisﬁes the initial conditions
u(x, 0) = f(x),
∂u(x, 0)
∂t
= g(x),
0 < x < L,
(7.3.2)
and the boundary conditions
u(0, t) = u(L, t) = 0,
0 < t.
(7.3.3)
For the present, we leave the Cauchy data quite arbitrary.
We begin by assuming that the solution u(x, t) equals the product X(x)T(t). (Here T
no longer denotes tension.) Because
∂2u
∂t2 = X(x)T ′′(t),
(7.3.4)
and
∂2u
∂x2 = X′′(x)T(t),
(7.3.5)
the wave equation becomes
c2X′′T = T ′′X,
(7.3.6)
or
X′′
X = T ′′
c2T ,
(7.3.7)
2 See Hobson, E. W., 1957: The Theory of Functions of a Real Variable and the Theory of Fourier’s
Series, Vol. 2. Dover Publishers, Sections 312–314.
3 L¨utzen, J., 1984: Sturm and Liouville’s work on ordinary linear diﬀerential equations. The emergence
of Sturm-Liouville theory. Arch. Hist. Exact Sci., 29, 317.

302
Advanced Engineering Mathematics with MATLAB
after dividing through by c2X(x)T(t). Because the left side of Equation 7.3.7 depends only
on x and the right side depends only on t, both sides must equal a constant. We write this
separation constant −λ and separate Equation 7.3.7 into two ordinary diﬀerential equations:
T ′′ + c2λT = 0,
0 < t,
(7.3.8)
and
X′′ + λX = 0,
0 < x < L.
(7.3.9)
We now rewrite the boundary conditions in terms of X(x) by noting that the boundary
conditions become
u(0, t) = X(0)T(t) = 0,
(7.3.10)
and
u(L, t) = X(L)T(t) = 0
(7.3.11)
for 0 < t. If we were to choose T(t) = 0, then we would have a trivial solution for u(x, t).
Consequently,
X(0) = X(L) = 0.
(7.3.12)
This concludes the ﬁrst step.
In the second step we consider three possible values for λ: λ < 0, λ = 0, and λ > 0.
Turning ﬁrst to λ < 0, we set λ = −m2 so that square roots of λ will not appear later on
and m is real. The general solution of Equation 7.3.9 is
X(x) = A cosh(mx) + B sinh(mx).
(7.3.13)
Because X(0) = 0, A = 0. On the other hand, X(L) = B sinh(mL) = 0. The function
sinh(mL) does not equal to zero since mL ̸= 0 (recall m > 0). Thus, B = 0 and we have
trivial solutions for a positive separation constant.
If λ = 0, the general solution now becomes
X(x) = C + Dx.
(7.3.14)
The condition X(0) = 0 yields C = 0 while X(L) = 0 yields DL = 0 or D = 0. Hence, we
have a trivial solution for the λ = 0 separation constant.
If λ = k2 > 0, the general solution to Equation 7.3.9 is
X(x) = E cos(kx) + F sin(kx).
(7.3.15)
The condition X(0) = 0 results in E = 0. On the other hand, X(L) = F sin(kL) = 0.
If we wish to avoid a trivial solution in this case (F ̸= 0), sin(kL) = 0, or kn = nπ/L,
and λn = n2π2/L2. The x-dependence equals Xn(x) = Fn sin(nπx/L). We added the n
subscript to k and λ to indicate that these quantities depend on n. This concludes the
second step.
Turning to Equation 7.3.8 for the third step, the solution to the T(t) equation is
Tn(t) = Gn cos(knct) + Hn sin(knct),
(7.3.16)
where Gn and Hn are arbitrary constants. For each n = 1, 2, 3, . . ., a particular solution
that satisﬁes the wave equation and prescribed boundary conditions is
un(x, t) = Fn sin
nπx
L
 
Gn cos
nπct
L

+ Hn sin
nπct
L

,
(7.3.17)

The Wave Equation
303
or
un(x, t) = sin
nπx
L
 
An cos
nπct
L

+ Bn sin
nπct
L

,
(7.3.18)
where An = FnGn and Bn = FnHn. This concludes the third step.
An equivalent method of ﬁnding the product solution is to treat Equation 7.3.9 along
with X(0) = X(L) = 0 as a Sturm-Liouville problem.
In this method we obtain the
spatial dependence by solving the Sturm-Liouville problem and ﬁnding the corresponding
eigenvalues λn and eigenfunctions. Next we solve for Tn(t). Finally we form the product
solution un(x, t) by multiplying the eigenfunction times the temporal dependence.
For any choice of An and Bn, Equation 7.3.18 is a solution of the partial diﬀerential
equation, Equation 7.3.1, also satisfying the boundary conditions, Equation 7.3.3. There-
fore, any linear combination of un(x, t) also satisﬁes the partial diﬀerential equation and the
boundary conditions. In making this linear combination we need no new constants because
An and Bn are still arbitrary. We have, then,
u(x, t) =
∞
X
n=1
sin
nπx
L
 
An cos
nπct
L

+ Bn sin
nπct
L

.
(7.3.19)
Our method of using particular solutions to build up the general solution illustrates
the powerful principle of linear superposition, which is applicable to any linear system.
This principle states that if u1 and u2 are any solutions of a linear homogeneous partial
diﬀerential equation in any region, then u = c1u1 + c2u2 is also a solution of that equation
in that region, where c1 and c2 are any constants. We can generalize this to an inﬁnite
sum. It is extremely important because it allows us to construct general solutions to partial
diﬀerential equations from particular solutions to the same problem.
Our fourth and ﬁnal task remains to determine An and Bn. At t = 0,
u(x, 0) =
∞
X
n=1
An sin
nπx
L

= f(x),
(7.3.20)
and
ut(x, 0) =
∞
X
n=1
nπc
L Bn sin
nπx
L

= g(x).
(7.3.21)
Both of these series are Fourier half-range sine expansions over the interval (0, L). Applying
the results from Section 5.3,
An = 2
L
Z L
0
f(x) sin
nπx
L

dx,
(7.3.22)
and
nπc
L Bn = 2
L
Z L
0
g(x) sin
nπx
L

dx,
(7.3.23)
or
Bn =
2
nπc
Z L
0
g(x) sin
nπx
L

dx.
(7.3.24)
At this point we might ask ourselves whether the Fourier series solution to the wave equation
always converges. For the case g(x) = 0, Carslaw4 showed that if the initial position of the
4 Carslaw, H. S., 1902: Note on the use of Fourier’s series in the problem of the transverse vibrations of
strings. Proc. Edinburgh Math. Soc., Ser. 1, 20, 23–28.

304
Advanced Engineering Mathematics with MATLAB
string forms a curve so that f(x) or the slope f ′(x) is continuous between x = 0 and x = L,
then the series converges uniformly.
As an example, let us take the initial conditions
f(x) =







0,
0 < x ≤L/4,
4h
  x
L −1
4

,
L/4 ≤x ≤L/2,
4h
  3
4 −x
L

,
L/2 ≤x ≤3L/4,
0,
3L/4 ≤x < L,
(7.3.25)
and
g(x) = 0,
0 < x < L.
(7.3.26)
In this particular example, Bn = 0 for all n because g(x) = 0. On the other hand,
An = 8h
L
Z L/2
L/4
 x
L −1
4

sin
nπx
L

dx + 8h
L
Z 3L/4
L/2
3
4 −x
L

sin
nπx
L

dx
(7.3.27)
=
8h
n2π2

2 sin
nπ
2

−sin
3nπ
4

−sin
nπ
4

(7.3.28)
=
8h
n2π2

2 sin
nπ
2

−2 sin
nπ
2

cos
nπ
4

(7.3.29)
= 16h
n2π2 sin
nπ
2
 h
1 −cos
nπ
4
i
= 32h
n2π2 sin
nπ
2

sin2nπ
8

,
(7.3.30)
because sin(A) + sin(B) = 2 sin[ 1
2(A + B)] cos[ 1
2(A −B)], and 1 −cos(2A) = 2 sin2(A).
Therefore,
u(x, t) = 32h
π2
∞
X
n=1
sin
nπ
2

sin2nπ
8
 1
n2 sin
nπx
L

cos
nπct
L

.
(7.3.31)
Because sin(nπ/2) vanishes for n even, so does An. If Equation 7.3.31 were evaluated on
a computer, considerable time and eﬀort would be wasted. Consequently it is preferable to
rewrite Equation 7.3.31 so that we eliminate these vanishing terms. The most convenient
method introduces the general expression n = 2m −1 for any odd integer, where m =
1, 2, 3, . . ., and notes that sin[(2m−1)π/2] = (−1)m+1. Therefore, Equation 7.3.31 becomes
u(x, t) = 32h
π2
∞
X
m=1
(−1)m+1
(2m −1)2 sin2
(2m −1)π
8

sin
(2m −1)πx
L

cos
(2m −1)πct
L

.
(7.3.32)
Although we completely solved the problem, it is useful to rewrite Equation 7.3.32 as
u(x, t) = 1
2
∞
X
n=1
An

sin
hnπ
L (x −ct)
i
+ sin
hnπ
L (x + ct)
i
(7.3.33)
through the application of the trigonometric identity sin(A) cos(B) =
1
2 sin(A −B) +
1
2 sin(A + B). From general physics we ﬁnd expressions like sin[kn(x −ct)] or sin(kx −ωt)
arising in studies of simple wave motions. The quantity sin(kx −ωt) is the mathematical
description of a propagating wave in the sense that we must move to the right at the speed
c if we wish to keep in the same position relative to the nearest crest and trough. The

The Wave Equation
305
−1.0
0.0
1.0
−1.0
0.0
1.0
−1.0
0.0
1.0
         
−1.0
0.0
1.0
       u(x,t)/h
−1.0
0.0
1.0
0.0
0.5
1.0
x/L
−1.0
0.0
1.0
ct/L = 0
ct/L = 0.2
ct/L = 0.4
ct/L = 0.6
ct/L = 0.8
ct/L = 1
Figure 7.3.1: The vibration of a string u(x, t)/h at various positions x/L at the times ct/L = 0, 0.2, 0.4,
0.6, 0.8, and 1. For times 1 < ct/L < 2 the pictures appear in reverse time order.
quantities k, ω, and c are the wavenumber, frequency, and phase speed or wave velocity,
respectively. The relationship ω = kc holds between the frequency and phase speed.
It may seem paradoxical that we are talking about traveling waves in a problem dealing
with waves conﬁned on a string of length L. Actually we are dealing with standing waves
because at the same time that a wave is propagating to the right its mirror image is running
to the left so that there is no resultant progressive wave motion. Figures 7.3.1 and 7.3.2
illustrate our solution. Figure 7.3.1 gives various cross sections. The single large peak at
t = 0 breaks into two smaller peaks that race towards the two ends. At each end, they
reﬂect and turn upside down as they propagate back towards x = L/2 at ct/L = 1. This
large, negative peak at x = L/2 again breaks apart, with the two smaller peaks propagating
towards the endpoints. They reﬂect and again become positive peaks as they propagate
back to x = L/2 at ct/L = 2. After that time, the whole process repeats itself.
MATLAB can be used to examine the solution in its totality. The script
% set parameters for the calculation
clear; M = 50; dx = 0.02; dt = 0.02;
% compute Fourier coefficients
sign = 32;
for m = 1:M
temp1 = (2*m-1)*pi; temp2 = sin(temp1/8);
a(m) = sign * temp2 * temp2 / (temp1 * temp1);
sign = -sign;
end
% compute grid and initialize solution
X = [0:dx:1]; T = [0:dt:2];
u = zeros(length(T),length(X));
XX = repmat(X,[length(T) 1]);
TT = repmat(T’,[1 length(X)]);
% compute solution from Equation 7.3.32
for m = 1:M
temp1 = (2*m-1)*pi;
u = u + a(m) .* sin(temp1*XX) .* cos(temp1*TT);

306
Advanced Engineering Mathematics with MATLAB
0
0.2
0.4
0.6
0.8
1
0
0.5
1
1.5
2
−1
0
1
DISTANCE
TIME
SOLUTION
Figure 7.3.2: Two-dimensional plot of the vibration of a string u(x, t)/h at various times ct/L and positions
x/L.
end
% plot space/time picture of the solution
surf(XX,TT,u)
xlabel(’DISTANCE’,’Fontsize’,20); ylabel(’TIME’,’Fontsize’,20)
zlabel(’SOLUTION’,’Fontsize’,20)
gives a three-dimensional view of Equation 7.3.32. The solution can be viewed in many
diﬀerent prospects using the interactive capacity of MATLAB.
An important dimension to the vibrating string problem is the fact that the wavenum-
ber kn is not a free parameter but has been restricted to the values of nπ/L. This restriction
on wavenumber is common in wave problems dealing with limited domains (for example, a
building, ship, lake, or planet) and these oscillations are given the special name of normal
modes or natural vibrations.
In our problem of the vibrating string, all of the components propagate with the same
phase speed. That is, all of the waves, regardless of wavenumber kn, move the characteristic
distance c∆t or −c∆t after the time interval ∆t elapsed. In the next example we will see
that this is not always true.
⊓⊔
• Example 7.3.2: Dispersion
In the preceding example, the solution to the vibrating string problem consisted of two
simple waves, each propagating with a phase speed c to the right and left. In many problems
where the equations of motion are a little more complicated than Equation 7.3.1, all of the
harmonics no longer propagate with the same phase speed but at a speed that depends
upon the wavenumber. In such systems the phase relation varies between the harmonics
and these systems are referred to as dispersive.
A modiﬁcation of the vibrating string problem provides a simple illustration. We now
subject each element of the string to an additional applied force that is proportional to its
displacement:
∂2u
∂t2 = c2 ∂2u
∂x2 −hu,
0 < x < L,
0 < t,
(7.3.34)

The Wave Equation
307
where h > 0 is constant. For example, if we embed the string in a thin sheet of rubber,
then in addition to the restoring force due to tension, there is a restoring force due to the
rubber on each portion of the string. From its use in the quantum mechanics of “scalar”
mesons, Equation 7.3.34 is often referred to as the Klein-Gordon equation.
We shall again look for particular solutions of the form u(x, t) = X(x)T(t). This time,
however,
XT ′′ −c2X′′T + hXT = 0,
(7.3.35)
or
T ′′
c2T + h
c2 = X′′
X = −λ,
(7.3.36)
which leads to two ordinary diﬀerential equations
X′′ + λX = 0,
(7.3.37)
and
T ′′ + (λc2 + h)T = 0.
(7.3.38)
If we attach the string at x = 0 and x = L, the X(x) solution is
Xn(x) = sin
nπx
L

(7.3.39)
with kn = nπ/L, and λn = n2π2/L2. On the other hand, the T(t) solution becomes
Tn(t) = An cos
p
k2nc2 + h t

+ Bn sin
p
k2nc2 + h t

,
(7.3.40)
so that the product solution is
un(x, t) = sin
nπx
L
 
An cos
p
k2nc2 + h t

+ Bn sin
p
k2nc2 + h t

.
(7.3.41)
Finally, the general solution becomes
u(x, t) =
∞
X
n=1
sin
nπx
L
 
An cos
p
k2nc2 + h t

+ Bn sin
p
k2nc2 + h t

(7.3.42)
from the principle of linear superposition. Let us consider the case when Bn = 0. Then we
can write Equation 7.3.42 as
u(x, t) =
∞
X
n=1
An
2

sin

knx +
p
k2nc2 + h t

+ sin

knx −
p
k2nc2 + h t

.
(7.3.43)
Comparing our results with Equation 7.3.33, the distance that a particular mode kn moves
during the time interval ∆t depends not only upon external parameters such as h, the tension
and density of the string, but also upon its wavenumber (or equivalently, wavelength).
Furthermore, the frequency of a particular harmonic is larger than that when h = 0. This
result is not surprising, because the added stiﬀness of the medium should increase the
natural frequencies.
The importance of dispersion lies in the fact that if the solution u(x, t) is a superpo-
sition of progressive waves in the same direction, then the phase relationship between the
diﬀerent harmonics changes with time. Because most signals consist of an inﬁnite series

308
Advanced Engineering Mathematics with MATLAB
−1.0
0.0
1.0
−1.0
0.0
1.0
−1.0
0.0
1.0
         
−1.0
0.0
1.0
       u(x,t)/h
−1.0
0.0
1.0
0.0
0.5
1.0
x/L
−1.0
0.0
1.0
ct/L = 0
ct/L = 0.2
ct/L = 0.4
ct/L = 0.6
ct/L = 0.8
ct/L = 1
Figure 7.3.3: The vibration of a string u(x, t)/h embedded in a thin sheet of rubber at various positions
x/L at the times ct/L = 0, 0.2, 0.4, 0.6, 0.8, and 1 for hL2/c2 = 10. The same parameters were used as in
Figure 7.3.1.
of these progressive waves, dispersion causes the signal to become garbled. We show this
by comparing the solution, Equation 7.3.42 given in Figures 7.3.3 and 7.3.4 for the initial
conditions, Equation 7.3.25 and Equation 7.3.26, with hL2/c2 = 10, to the results given in
Figures 7.3.1 and 7.3.2. In the case of Figure 7.3.4, the MATLAB script line
u = u + a(m) .* sin(temp1*XX) .* cos(temp1*TT);
has been replaced with
temp2 = temp1 * sqrt(1 + H/(temp1*temp1));
u = u + a(m) .* sin(temp1*XX) .* cos(temp2*TT);
where H = 10 is deﬁned earlier in the script. Note how garbled the picture becomes at
ct/L = 2 in Figure 7.3.4 compared to the nondispersive solution at the same time in Figure
7.3.2.
⊓⊔
• Example 7.3.3: Damped wave equation
In the previous example a slight modiﬁcation of the wave equation resulted in a wave
solution where each Fourier harmonic propagates with its own particular phase speed. In
this example we introduce a modiﬁcation of the wave equation that results not only in
dispersive waves but also in the exponential decay of the amplitude as the wave propagates.
So far we neglected the reaction of the surrounding medium (air or water, for example)
on the motion of the string. For small-amplitude motions this reaction opposes the motion
of each element of the string and is proportional to the element’s velocity. The equation of
motion, when we account for the tension and friction in the medium but not its stiﬀness or
internal friction, is
∂2u
∂t2 + 2h∂u
∂t = c2 ∂2u
∂x2 ,
0 < x < L,
0 < t.
(7.3.44)
Because Equation 7.3.44 ﬁrst arose in the mathematical description of the telegraph,5 it is
5 The ﬁrst published solution was by Kirchhoﬀ, G., 1857: ¨Uber die Bewegung der Electrit¨at in Dr¨ahten.
Ann. Phys. Chem., 100, 193–217. English translation: Kirchhoﬀ, G., 1857: On the motion of electricity
in wires. Philos. Mag., Ser. 4, 13, 393–412.

The Wave Equation
309
0
0.2
0.4
0.6
0.8
1
0
0.5
1
1.5
2
−1
0
1
DISTANCE
TIME
SOLUTION
Figure 7.3.4: The two-dimensional plot of the vibration of a string u(x, t)/h embedded in a thin sheet of
rubber at various times ct/L and positions x/L for hL2/c2 = 10.
generally known as the equation of telegraphy. The eﬀect of friction is, of course, to damp
out the free vibration.
Let us assume a solution of the form u(x, t) = X(x)T(t) and separate the variables to
obtain the two ordinary diﬀerential equations:
X′′ + λX = 0,
(7.3.45)
and
T ′′ + 2hT ′ + λc2T = 0
(7.3.46)
with X(0) = X(L) = 0. Friction does not aﬀect the shape of the normal modes; they are
still
Xn(x) = sin
nπx
L

(7.3.47)
with kn = nπ/L and λn = n2π2/L2.
The solution for the T(t) equation is
Tn(t) = e−ht

An cos
p
k2nc2 −h2 t

+ Bn sin
p
k2nc2 −h2 t

(7.3.48)
with the condition that knc > h. If we violate this condition, the solutions are two ex-
ponentially decaying functions in time. Because most physical problems usually fulﬁll this
condition, we concentrate on this solution.
From the principle of linear superposition, the general solution is
u(x, t) = e−ht
∞
X
n=1
sin
nπx
L
h
An cos
p
k2nc2 −h2 t

+Bn sin
p
k2nc2 −h2 t
i
,
(7.3.49)
where πc > hL. From Equation 7.3.49 we see two important eﬀects. First, the presence
of friction slows all of the harmonics. Furthermore, friction dampens all of the harmonics.

310
Advanced Engineering Mathematics with MATLAB
−1.0
0.0
1.0
−1.0
0.0
1.0
−1.0
0.0
1.0
         
−1.0
0.0
1.0
       u(x,t)/h
−1.0
0.0
1.0
0.0
0.5
1.0
x/L
−1.0
0.0
1.0
ct/L = 0
ct/L = 0.2
ct/L = 0.4
ct/L = 0.6
ct/L = 0.8
ct/L = 1
Figure 7.3.5: The vibration of a string u(x, t)/h with frictional dissipation at various positions x/L at the
times ct/L = 0, 0.2, 0.4, 0.6, 0.8, and 1 for hL/c = 1. The same parameters were used as in Figure 7.3.1.
0
0.2
0.4
0.6
0.8
1
0
0.5
1
1.5
2
−0.5
0
0.5
1
DISTANCE
TIME
SOLUTION
Figure 7.3.6: The vibration of a string u(x, t)/h with frictional dissipation at various times ct/L and
positions x/L for hL/c = 1.
Figures 7.3.5 and 7.3.6 illustrate the solution using the initial conditions given by Equation
7.3.25 and Equation 7.3.26 with hL/c = 1. In the case of Figure 7.3.6, the script line that
produced Figure 7.3.2:
u = u + a(m) .* sin(temp1*XX) .* cos(temp1*TT);
has been replaced with
temp2 = temp1 * sqrt(1 - (H*H)/(temp1*temp1));
u = u + a(m) .* exp(-H*TT) .* sin(temp1*XX) .* cos(temp2*TT);
where H = 1 is deﬁned earlier in the script. Because this is a rather large coeﬃcient of
friction, Figures 7.3.5 and 7.3.6 exhibit rapid damping as well as dispersion.
This damping and dispersion of waves also occurs in solutions of the equation of teleg-
raphy where the solutions are progressive waves. Because early telegraph lines were short,
time delay eﬀects were negligible. However, when engineers laid the ﬁrst transoceanic cables

The Wave Equation
311
Table 7.3.1: Technological Innovation on Transatlantic Telegraph Cables
Year
Technological Innovation
Performance
(words/min)
1857–58
Mirror galvanometer
3–7
1870
Condensers
12
1872
Siphon recorder
17
1879
Duplex
24
1894
Larger diameter cable
72–90
1915–20
Brown drum repeater and Heurtley
100
magniﬁer
1923–28
Magnetically loaded lines
300–320
1928–32
Electronic signal shaping ampliﬁers
480
and time division multiplexing
1950
Repeaters on the continental shelf
100–300
1956
Repeater telephone cables
21600
From Coates, V. T., and B. Finn, 1979: A Retrospective Technology Assessment: Submarine Telegraphy.
The Transatlantic Cable of 1866. San Francisco Press, Inc., 268 pp.
in the 1850s, the time delay became seconds and diﬀerences in the velocity of propagation of
diﬀerent frequencies, as predicted by Equation 7.3.49, became noticeable to the operators.
Table 7.3.1 gives the transmission rate for various transatlantic submarine telegraph lines.
As it shows, increases in the transmission rates during the nineteenth century were due
primarily to improvements in terminal technology.
When they instituted long-distance telephony just before the turn of the twentieth
century, this diﬀerence in velocity between frequencies should have limited the circuits to a
few tens of miles.6 However, in 1899, Prof. Michael Pupin at Columbia University showed
that by adding inductors (“loading coils”) to the line at regular intervals the velocities at
the diﬀerent frequencies could be equalized.7 Heaviside8 and the French engineer Vaschy9
made similar suggestions in the nineteenth century. Thus, adding resistance and inductance,
which would seem to make things worse, actually made possible long-distance telephony.
Today you can see these loading coils as you drive along the street; they are the black
cylinders, approximately one between each pair of telephone poles, spliced into the telephone
cable. The loading of long submarine telegraph cables had to wait for the development of
permalloy and mu-metal materials of high magnetic induction.
⊓⊔
6 Rayleigh, J. W., 1884: On telephoning through a cable. Brit. Assoc. Rep., 632–633; Jordan, D. W.,
1982: The adoption of self-induction by telephony, 1886–1889. Ann. Sci., 39, 433–461.
7 There is considerable controversy concerning who is exactly the inventor. See Brittain, J. E., 1970:
The introduction of the loading coil: George A. Campbell and Michael I. Pupin. Tech. Culture, 11, 36–57.
8 First published 3 June 1887. Reprinted in Heaviside, O., 1970: Electrical Papers, Vol. 2. Chelsea
Publishing, pp. 119–124.
9 See Devaux-Charbonnel, X. G. F., 1917: La contribution des ing´enieurs fran¸cais `a la t´el´ephonie `a
grande distance par cˆables souterrains: Vaschy et Barbarat. Rev. G´en. ´Electr., 2, 288–295.

312
Advanced Engineering Mathematics with MATLAB
• Example 7.3.4: Axisymmetric vibrations of a circular membrane
The wave equation
∂2u
∂r2 + 1
r
∂u
∂r = 1
c2
∂2u
∂t2 ,
0 ≤r < a,
0 < t
(7.3.50)
governs axisymmetric vibrations of a circular membrane, where u(r, t) is the vertical dis-
placement of the membrane, r is the radial distance, t is time, c is the square root of the
ratio of the tension of the membrane to its density, and a is the radius of the membrane.
We will solve Equation 7.3.50 when the membrane is initially at rest, u(r, 0) = 0, and struck
so that its initial velocity is
∂u(r, 0)
∂t
=

P/(πǫ2ρ),
0 ≤r < ǫ,
0,
ǫ < r < a.
(7.3.51)
If this problem can be solved by separation of variables, then u(r, t) = R(r)T(t).
Following the substitution of this u(r, t) into Equation 7.3.50, separation of variables leads
to
1
rR
d
dr

rdR
dr

=
1
c2T
d2T
dt2 = −k2,
(7.3.52)
or
1
r
d
dr

rdR
dr

+ k2R = 0,
(7.3.53)
and
d2T
dt2 + k2c2T = 0.
(7.3.54)
The separation constant −k2 must be negative so that we obtain solutions that remain
bounded in the region 0 ≤r < a and can satisfy the boundary condition. This boundary
condition is u(a, t) = R(a)T(t) = 0, or R(a) = 0.
The solutions of Equation 7.3.53 and Equation 7.3.54, subject to the boundary condi-
tion, are
Rn(r) = J0
λnr
a

,
(7.3.55)
and
Tn(t) = An sin
λnct
a

+ Bn cos
λnct
a

,
(7.3.56)
where λn satisﬁes the equation J0(λ) = 0. Because u(r, 0) = 0, and Tn(0) = 0, Bn = 0.
Consequently, the product solution is
u(r, t) =
∞
X
n=1
AnJ0
λnr
a

sin
λnct
a

.
(7.3.57)
To determine An, we use the condition
∂u(r, 0)
∂t
=
∞
X
n=1
λnc
a AnJ0
λnr
a

=

P/(πǫ2ρ),
0 ≤r < ǫ,
0,
ǫ < r < a.
(7.3.58)

The Wave Equation
313
−0.5
0.5
1.5
−0.5
0.5
1.5
−0.5
0.5
1.5
         
−0.5
0.5
1.5
       u’(r,t)
−0.5
0.5
1.5
0.0
0.5
1.0
r/a
−0.5
0.5
1.5
ct/a = 0
ct/a = 0.2
ct/a = 0.4
ct/a = 0.6
ct/a = 0.8
ct/a = 1
Figure 7.3.7: The axisymmetric vibrations u′(r, t) = caρu(r, t)/P of a circular membrane at various
positions r/a at the times ct/a = 0, 0.2, 0.4, 0.6, 0.8, and 1 for ǫ = a/4. Initially the membrane is struck
by a hammer.
Equation 7.3.58 is a Fourier-Bessel expansion employing the orthogonal function J0(λnr/a),
where
λnc
a An =
2
a2J2
1(λn)
Z ǫ
0
P
πǫ2ρJ0
λnr
a

r dr
(7.3.59)
from Equation 6.5.38 and Equation 6.5.45 in Section 6.5. Carrying out the integration,
An = 2PJ1(λnǫ/a)
cπǫρλ2nJ2
1(λn),
(7.3.60)
or
u(r, t) = 2P
cπǫρ
∞
X
n=1
J1(λnǫ/a)
λ2nJ2
1(λn) J0
λnr
a

sin
λnct
a

.
(7.3.61)
Figures 7.3.7, 7.3.8, and 7.3.9 illustrate the solution, Equation 7.3.61, for various times
and positions when ǫ = a/4, and ǫ = a/20. They were generated using the MATLAB script
% initialize parameters
clear; eps over a = 0.25; M = 20; dr = 0.02; dt = 0.02;
% load in zeros of J 0
zero( 1) =
2.40483; zero( 2) =
5.52008; zero( 3) =
8.65373;
zero( 4) = 11.79153; zero( 5) = 14.93092; zero( 6) = 18.07106;
zero( 7) = 21.21164; zero( 8) = 24.35247; zero( 9) = 27.49347;
zero(10) = 30.63461; zero(11) = 33.77582; zero(12) = 36.91710;
zero(13) = 40.05843; zero(14) = 43.19979; zero(15) = 46.34119;
zero(16) = 49.48261; zero(17) = 52.62405; zero(18) = 55.76551;
zero(19) = 58.90698; zero(20) = 62.04847;
% compute Fourier-Bessel coefficients
for m = 1:M
a(m) = 2 * besselj(1,eps over a*zero(m)) ...
/ (eps over a*pi*zero(m)*zero(m)*besselj(1,zero(m))^2);
end

314
Advanced Engineering Mathematics with MATLAB
0
0.5
1
0
1
2
3
4
−2
−1
0
1
2
TIME
R
SOLUTION
Figure 7.3.8: The axisymmetric vibrations caρu(r, t)/P of a circular membrane resulting from an initial
hammer blow with ǫ = a/4. The solution is plotted at various times ct/a and positions r/a.
R = [0:dr:1]; T = [0:dt:4];
u = zeros(length(T),length(R));
RR = repmat(R,[length(T) 1]);
TT = repmat(T’,[1 length(R)]);
% compute solution from series solution
for m = 1:M
u = u + a(m) .* besselj(0,zero(m)*RR) .* sin(zero(m)*TT);
end
% plot results
surf(RR,TT,u)
xlabel(’R’,’Fontsize’,20); ylabel(’TIME’,’Fontsize’,20)
zlabel(’SOLUTION’,’Fontsize’,20)
Figures 7.3.8 and 7.3.9 show that striking the membrane with a hammer generates a pulse
that propagates out to the rim, reﬂects, inverts, and propagates back to the center. This
process then repeats forever.
Problems
Solve the wave equation utt = c2uxx, 0 < x < L, 0 < t, subject to the boundary conditions
that u(0, t) = u(L, t) = 0, 0 < t, and the following initial conditions for 0 < x < L. Use
MATLAB to illustrate your solution.
1. u(x, 0) = 0,
ut(x, 0) = 1
2. u(x, 0) = 1,
ut(x, 0) = 0
3. u(x, 0) =

3hx/2L,
0 < x < 2L/3,
3h(L −x)/L,
2L/3 < x < L,
ut(x, 0) = 0

The Wave Equation
315
0
0.5
1
0
1
2
3
4
−10
−5
0
5
TIME
R
SOLUTION
Figure 7.3.9: Same as Figure 7.3.8 except ǫ = a/20.
4. u(x, 0) = [3 sin(πx/L) −sin(3πx/L)]/4,
ut(x, 0) = 0,
5. u(x, 0) = sin(πx/L) ,
ut(x, 0) =



0,
0 < x < L/4
a,
L/4 < x < 3L/4
0,
3L/4 < x < L
6. u(x, 0) = 0,
ut(x, 0) =

ax/L,
0 < x < L/2
a(L −x)/L,
L/2 < x < L
7. u(x, 0) =

x,
0 < x < L/2,
L −x,
L/2 < x < L,
ut(x, 0) = 0
8. Solve the wave equation
∂2u
∂t2 = c2 ∂2u
∂x2 ,
0 < x < π,
0 < t,
subject to the boundary conditions
∂u(0, t)
∂x
= ∂u(π, t)
∂x
= 0,
0 < t,
and the initial conditions
u(x, 0) = 0,
∂u(x, 0)
∂t
= 1 + cos3(x),
0 < x < π.
Hint: You must include the separation constant of zero.

316
Advanced Engineering Mathematics with MATLAB
9. Solve10 the wave equation
∂2u
∂t2 = ∂
∂x

x∂u
∂x

,
0 ≤x < 1,
0 < t,
subject to the boundary conditions
lim
x→0 |u(x, t)| < ∞,
u(1, t) = 0,
0 < t,
and the initial conditions
u(x, 0) = 0,
0 ≤x ≤1,
∂u(x, 0)
∂t
=
 1,
0 ≤x < a,
0,
a < x ≤1,
where a < 1. Hint: Use the substitution 4x = r2.
10. The diﬀerential equation for the longitudinal vibrations of a rod within a viscous ﬂuid
is
∂2u
∂t2 + 2h∂u
∂t = c2 ∂2u
∂x2 ,
0 < x < L,
0 < t,
where c is the velocity of sound in the rod and h is the damping coeﬃcient. If the rod is
ﬁxed at x = 0 so that u(0, t) = 0, and allowed to freely oscillate at the other end x = L, so
that ux(L, t) = 0, ﬁnd the vibrations for any location x and subsequent time t if the rod has
the initial displacement of u(x, 0) = x and the initial velocity ut(x, 0) = 0 for 0 < x < L.
Assume that h < cπ/(2L). Why?
11. A closed pipe of length L contains air whose density is slightly greater than that of the
outside air in the ratio of 1 + s0 to 1. Everything being at rest, we suddenly draw aside the
disk closing one end of the pipe. We want to determine what happens inside the pipe after
we remove the disk.
As the air rushes outside, it generates sound waves within the pipe. The wave equation
∂2u
∂t2 = c2 ∂2u
∂x2
governs these waves, where c is the speed of sound and u(x, t) is the velocity potential.
Without going into the ﬂuid mechanics of the problem, the boundary conditions are
a. No ﬂow through the closed end: ux(0, t) = 0.
b. No inﬁnite acceleration at the open end: uxx(L, t) = 0.
c. Air is initially at rest: ux(x, 0) = 0.
d. Air initially has a density greater than the surrounding air by the amount s0: ut(x, 0) =
−c2s0.
Find the velocity potential at all positions within the pipe and all subsequent times.
12. One of the classic applications of the wave equation has been the explanation of the
acoustic properties of string instruments. Usually we excite a string in one of three ways:
10 Solved in a slightly diﬀerent manner by Bailey, H., 2000: Motions of a hanging chain after the free
end is given an initial velocity. Am. J. Phys., 68, 764–767.

The Wave Equation
317
by plucking (as in the harp, zither, etc.), by striking with a hammer (piano), or by bowing
(violin, violoncello, etc.). In all of these cases, the governing partial diﬀerential equation is
∂2u
∂t2 = c2 ∂2u
∂x2
with the boundary conditions u(0, t) = u(L, t) = 0, 0 < t. For each of the following methods
of exciting a string instrument, ﬁnd the complete solution to the problem:
(a) Plucked string
For the initial conditions:
u(x, 0) =

βx/a,
0 < x < a,
β(L −x)/(L −a),
a < x < L,
and
ut(x, 0) = 0,
0 < x < L,
show that
u(x, t) =
2βL2
π2a(L −a)
∞
X
n=1
1
n2 sin
nπa
L

sin
nπx
L

cos
nπct
L

.
We note that the harmonics are absent where sin(nπa/L) = 0.
Thus, if we pluck
the string at the center, all of the harmonics of even order are absent. Furthermore, the
intensity of the successive harmonics varies as n−2. The higher harmonics (overtones) are
therefore relatively feeble compared to the n = 1 term (the fundamental).
(b) String excited by impact
The eﬀect of the impact of a hammer depends upon the manner and duration of the contact,
and is more diﬃcult to estimate. However, as a ﬁrst estimate, let
u(x, 0) = 0,
0 < x < L,
and
ut(x, 0) =
n µ,
a −ǫ < x < a + ǫ,
0,
otherwise,
where ǫ ≪1. Show that the solution in this case is
u(x, t) = 4µL
π2c
∞
X
n=1
1
n2 sin
nπǫ
L

sin
nπa
L

sin
nπx
L

sin
nπct
L

.
As in part (a), the nth mode is absent if the origin is at a node. The intensity of
the overtones are now of the same order of magnitude; higher harmonics (overtones) are
relatively more in evidence than in part (a).

318
Advanced Engineering Mathematics with MATLAB
(c) Bowed violin string
The theory of the vibration of a string when excited by bowing is poorly understood. The
bow drags the string for a time until the string springs back. After a while the process
repeats. It can be shown11 that the proper initial conditions are
u(x, 0) = 0,
0 < x < L,
and
ut(x, 0) = 4βc(L −x)/L2,
0 < x < L,
where β is the maximum displacement. Show that the solution is now
u(x, t) = 8β
π2
∞
X
n=1
1
n2 sin
nπx
L

sin
nπct
L

.
7.4 D’ALEMBERT’S FORMULA
In the previous section we sought solutions to the homogeneous wave equation in the
form of a product X(x)T(t). For the one-dimensional wave equation there is a more general
method for constructing the solution, published by d’Alembert12 in 1747.
Let us determine a solution to the homogeneous wave equation
∂2u
∂t2 = c2 ∂2u
∂x2 ,
−∞< x < ∞,
0 < t,
(7.4.1)
which satisﬁes the initial conditions
u(x, 0) = f(x),
∂u(x, 0)
∂t
= g(x),
−∞< x < ∞.
(7.4.2)
We begin by introducing two new variables ξ, η deﬁned by ξ = x + ct, and η = x −ct,
and set u(x, t) = w(ξ, η). The variables ξ and η are called the characteristics of the wave
equation. Using the chain rule,
∂
∂x = ∂ξ
∂x
∂
∂ξ + ∂η
∂x
∂
∂η = ∂
∂ξ + ∂
∂η
(7.4.3)
∂
∂t = ∂ξ
∂t
∂
∂ξ + ∂η
∂t
∂
∂η = c ∂
∂ξ −c ∂
∂η
(7.4.4)
∂2
∂x2 = ∂ξ
∂x
∂
∂ξ
 ∂
∂ξ + ∂
∂η

+ ∂η
∂x
∂
∂η
 ∂
∂ξ + ∂
∂η

(7.4.5)
= ∂2
∂ξ2 + 2 ∂2
∂ξ∂η + ∂2
∂η2 ,
(7.4.6)
11 See Lamb, H., 1960: The Dynamical Theory of Sound. Dover Publishers, Section 27.
12 D’Alembert, J., 1747: Recherches sur la courbe que forme une corde tendu¨e mise en vibration. Hist.
Acad. R. Sci. Belles Lett., Berlin, 214–219.

The Wave Equation
319
Although largely self-educated in mathematics, Jean Le Rond d’Alembert (1717–1783) gained equal
fame as a mathematician and philosophe of the continental Enlightenment. By the middle of the
eighteenth century, he stood with such leading European mathematicians and mathematical physi-
cists as Clairaut, D. Bernoulli, and Euler.
Today we best remember him for his work in ﬂuid
dynamics and applying partial diﬀerential equations to problems in physics. (Portrait courtesy of
the Archives de l’Acad´emie des sciences, Paris.)
and similarly
∂2
∂t2 = c2
 ∂2
∂ξ2 −2 ∂2
∂ξ∂η + ∂2
∂η2

,
(7.4.7)
so that the wave equation becomes
∂2w
∂ξ∂η = 0.
(7.4.8)
The general solution of Equation 7.4.8 is
w(ξ, η) = F(ξ) + G(η).
(7.4.9)
Thus, the general solution of Equation 7.4.1 is of the form
u(x, t) = F(x + ct) + G(x −ct),
(7.4.10)
where F and G are arbitrary functions of one variable and are assumed to be twice diﬀeren-
tiable. Setting t = 0 in Equation 7.4.10 and using the initial condition that u(x, 0) = f(x),
F(x) + G(x) = f(x).
(7.4.11)

320
Advanced Engineering Mathematics with MATLAB
−10
−5
0
5
10
0
5
10
0
0.5
1
TIME
DISTANCE
SOLUTION
Figure 7.4.1: D’Alembert’s solution, Equation 7.4.18, to the wave equation.
The partial derivative of Equation 7.4.10 with respect to t yields
∂u(x, t)
∂t
= cF ′(x + ct) −cG′(x −ct).
(7.4.12)
Here primes denote diﬀerentiation with respect to the argument of the function. If we set
t = 0 in Equation 7.4.12 and apply the initial condition that ut(x, 0) = g(x),
cF ′(x) −cG′(x) = g(x).
(7.4.13)
Integrating Equation 7.4.13 from 0 to any point x gives
F(x) −G(x) = 1
c
Z x
0
g(τ) dτ + C,
(7.4.14)
where C is the constant of integration. Combining this result with Equation 7.4.11,
F(x) = f(x)
2
+ 1
2c
Z x
0
g(τ) dτ + C
2 ,
(7.4.15)
and
G(x) = g(x)
2
−1
2c
Z x
0
g(τ) dτ −C
2 .
(7.4.16)
If we replace the variable x in the expression for F and G by x + ct and x −ct, respectively,
and substitute the results into Equation 7.4.10, we ﬁnally arrive at the formula
u(x, t) = f(x + ct) + f(x −ct)
2
+ 1
2c
Z x+ct
x−ct
g(τ) dτ.
(7.4.17)
This is known as d’Alembert’s formula for the solution of the wave equation, Equation 7.4.1,
subject to the initial conditions, Equation 7.4.2. It gives a representation of the solution in
terms of known initial conditions.

The Wave Equation
321
• Example 7.4.1
To illustrate d’Alembert’s formula, let us ﬁnd the solution to the wave equation, Equa-
tion 7.4.1, satisfying the initial conditions u(x, 0) = H(x + 1) −H(x −1) and ut(x, 0) = 0,
−∞< x < ∞. By d’Alembert’s formula, Equation 7.4.17,
u(x, t) = 1
2 [H(x + ct + 1) + H(x −ct + 1) −H(x + ct −1) −H(x −ct −1)] .
(7.4.18)
We illustrate this solution in Figure 7.4.1 generated by the MATLAB script
% set mesh size for solution
clear; dx = 0.1; dt = 0.1;
% compute grid
X=[-10:dx:10]; T = [0:dt:10];
for j=1:length(T); t = T(j);
for i=1:length(X); x = X(i);
% compute characteristics
characteristic 1 = x + t; characteristic 2 = x - t;
% compute solution
XX(i,j) = x; TT(i,j) = t;
u(i,j) = 0.5*(stepfun(characteristic 1,-1)+stepfun(characteristic 2,-1)...
-stepfun(characteristic 1, 1)-stepfun(characteristic 2, 1));
end; end
surf(XX,TT,u); colormap autumn;
xlabel(’DISTANCE’,’Fontsize’,20); ylabel(’TIME’,’Fontsize’,20)
zlabel(’SOLUTION’,’Fontsize’,20)
In this ﬁgure, you can clearly see the characteristics as they emanate from the discontinuities
at x = ±1.
⊓⊔
• Example 7.4.2
Let us ﬁnd the solution to the wave equation, Equation 7.4.1, when u(x, 0) = 0, and
ut(x, 0) = sin(2x), −∞< x < ∞. By d’Alembert’s formula, the solution is
u(x, t) = 1
2c
Z x+ct
x−ct
sin(2τ) dτ = sin(2x) sin(2ct)
2
.
(7.4.19)
In addition to providing a method of solving the wave equation, d’Alembert’s solution
can also provide physical insight into the vibration of a string. Consider the case when we
release a string with zero velocity after giving it an initial displacement of f(x). According
to Equation 7.4.17, the displacement at a point x at any time t is
u(x, t) = f(x + ct) + f(x −ct)
2
.
(7.4.20)
Because the function f(x−ct) is the same as the function of f(x) translated to the right by
a distance equal to ct, f(x−ct) represents a wave of form f(x) traveling to the right with the
velocity c, a forward wave. Similarly, we can interpret the function f(x+ct) as representing
a wave with the shape f(x) traveling to the left with the velocity c, a backward wave. Thus,
the solution, Equation 7.4.17, is a superposition of forward and backward waves traveling
with the same velocity c and having the shape of the initial proﬁle f(x) with half of the

322
Advanced Engineering Mathematics with MATLAB
t=0
x
x
x
x
x
u(x,t)
-a
a
characteristic
x+ct
characteristic
x-ct
(E)
(D)
(C)
(B)
(A)
t=2a/c
t=3a/2c
t=a/c
t=a/2c
Figure 7.4.2: The propagation of waves due to an initial displacement according to d’Alembert’s formula.
amplitude. Clearly the characteristics x + ct and x −ct give the propagation paths along
which the waveform f(x) propagates.
⊓⊔
• Example 7.4.3
To illustrate our physical interpretation of d’Alembert’s solution, suppose that the
string has an initial displacement deﬁned by
f(x) =

a −|x|,
−a ≤x ≤a,
0,
otherwise.
(7.4.21)
In Figure 7.4.2(A) the forward and backward waves, indicated by the dashed line, coincide
at t = 0. As time advances, both waves move in opposite directions. In particular, at t =
a/(2c), they moved through a distance a/2, resulting in the displacement of the string shown
in Figure 7.4.2(B). Eventually, at t = a/c, the forward and backward waves completely
separate. Finally, Figures 7.4.2(D) and 7.4.3(E) show how the waves radiate oﬀto inﬁnity
at the speed of c. Note that at each point the string returns to its original position of rest
after the passage of each wave.
Consider now the opposite situation when u(x, 0) = 0, and ut(x, 0) = g(x).
The
displacement is
u(x, t) = 1
2c
Z x+ct
x−ct
g(τ) dτ.
(7.4.22)
If we introduce the function
ϕ(x) = 1
2c
Z x
0
g(τ) dτ,
(7.4.23)
then we can write Equation 7.4.22 as
u(x, t) = ϕ(x + ct) −ϕ(x −ct),
(7.4.24)
which again shows that the solution is a superposition of a forward wave −ϕ(x −ct) and
a backward wave ϕ(x + ct) traveling with the same velocity c. The function ϕ, which we

The Wave Equation
323
Figure 7.4.3: Displacement of an inﬁnite, moving threadline when c = 10, and V = 1.
compute from Equation 7.4.23 and the initial velocity g(x), determines the exact form of
these waves.
⊓⊔
• Example 7.4.4: Vibration of a moving threadline
The characterization and analysis of the oscillations of a string or yarn have an impor-
tant application in the textile industry because they describe the way that yarn winds on a
bobbin.13 As we showed in Section 7.1, the governing equation, the “threadline equation,”
is
∂2u
∂t2 + α ∂2u
∂x∂t + β ∂2u
∂x2 = 0,
(7.4.25)
where α = 2V , β = V 2 −gT/ρ, V is the windup velocity, g is the gravitational attraction,
T is the tension in the yarn, and ρ is the density of the yarn.
We now introduce the
characteristics ξ = x + λ1t, and η = x + λ2t, where λ1 and λ2 are yet undetermined. Upon
substituting ξ and η into Equation 7.4.25,
(λ2
1 + 2V λ1 + V 2 −gT/ρ)uξξ + (λ2
2 + 2V λ2 + V 2 −gT/ρ)uηη
+ [2V 2 −2gT/ρ + 2V (λ1 + λ2) + 2λ1λ2]uξη = 0.
(7.4.26)
If we choose λ1 and λ2 to be roots of the equation
λ2 + 2V λ + V 2 −gT/ρ = 0,
(7.4.27)
Equation 7.4.26 reduces to the simple form
uξη = 0,
(7.4.28)
which has the general solution
u(x, t) = F(ξ) + G(η) = F(x + λ1t) + G(x + λ2t).
(7.4.29)
Solving Equation 7.4.27 yields
λ1 = c −V,
and
λ2 = −c −V,
(7.4.30)
13 See Swope, R. D., and W. F. Ames, 1963: Vibrations of a moving threadline. J. Franklin Inst., 275,
36–55.
-16 -14 -12 -10 -8 -6 -4 -2 
0 
DISPLACEMENT OF STRING 
D'ALEMBERT SOLUTION 
CASE I 
A1 = 9 
A2 =-ll 
t=l.O 
4 
6 
8 
10 
12 
14 
16 

324
Advanced Engineering Mathematics with MATLAB
Figure 7.4.4: Displacement of an inﬁnite, moving threadline when c = 11, and V = 10.
where c =
p
gT/ρ. If the initial conditions are
u(x, 0) = f(x),
and
ut(x, 0) = g(x),
(7.4.31)
then
u(x, t) = 1
2c

λ1f(x + λ2t) −λ2f(x + λ1t) +
Z x+λ1t
x+λ2t
g(τ) dτ

.
(7.4.32)
Because λ1 does not generally equal to λ2, the two waves that constitute the motion of
the string move with diﬀerent speeds and have diﬀerent shapes and forms. For example, if
f(x) =
1
x2 + 1,
and
g(x) = 0,
(7.4.33)
u(x, t) = 1
2c

c −V
1 + [x −(c + V )t]2 +
c + V
1 + [x −(c −V )t]2

.
(7.4.34)
Figures 7.4.3 and 7.4.4 illustrate this solution for several diﬀerent parameters.
Problems
Use d’Alembert’s formula to solve the wave equation, Equation 7.4.1, for the following initial
conditions deﬁned for |x| < ∞. Then illustrate your solution using MATLAB.
1.
u(x, 0) = 2 sin(x) cos(x)
ut(x, 0) = cos(x)
2.
u(x, 0) = x sin(x)
ut(x, 0) = cos(2x)
3.
u(x, 0) = 1/(x2 + 1)
ut(x, 0) = ex
4.
u(x, 0) = e−x
ut(x, 0) = 1/(x2 + 1)
5.
u(x, 0) = cos(πx/2)
ut(x, 0) = sinh(ax)
6.
u(x, 0) = sin(3x)
ut(x, 0) = sin(2x) −sin(x)
7. Assuming that the functions F and G are diﬀerentiable, show by direct substitution that
u(x, t) = EF(x + ct) −EG(x −ct) −1
8kc2t2 + 3
8kx2,
0 
1•0 
,. 2 
DISPLACEMENT OF STRING 
D'ALEMBERT SOLUTION 
CASE II 
x,• 1 
x2=-19 

The Wave Equation
325
and
v(x, t) = cF(x + ct) + cG(x −ct) −kc2xt
4E
are the d’Alembert solutions to the hyperbolic system
∂u
∂t = E ∂v
∂x,
∂u
∂x = ρ∂v
∂t + kx,
−∞< x < ∞,
0 < t,
where c2 = E/ρ and E, k, and ρ are constants.
8. D’Alembert’s solution can also be used in problems over the limited domain 0 < x < L.
To illustrate this, let us solve the wave equation, Equation 7.4.1, with the initial conditions
u(x, 0) = 0, ut(x, 0) = Vmax(1 −x/L), 0 < x < L, and the boundary conditions u(0, t) =
u(L, t) = 0, 0 < t.
Step 1: Show that the solution to this problem is
u(x, t) = 1
2[V0(x + ct) −V0(x −ct)],
where
V0(χ) = 1
c
Z χ
0
ut(ξ, 0) dξ = Vmaxχ
c

1 −χ
2L

,
0 < χ < L,
along with the periodicity conditions V0(χ) = V0(−χ), and V0(L + χ) = V0(L −χ) to take
care of those cases when the argument of V0(·) is outside of (0, L). Hint: Substitute the
solution into the boundary conditions.
Step 2: Show that at any point x within the interval (0, L), the solution repeats with a
period of 2L/c if ct > 2L. Therefore, if we know the behavior of the solution for the time
interval 0 < ct < 2L, we know the behavior for any other time.
Step 3: Show that the solution at any point x within the interval (0, L) and time t + L/c,
where 0 < ct < L, is the mirror image (about u = 0) of the solution at the point L −x and
time t, where 0 < ct < L.
Step 4: Show that the maximum value of u(x, t) occurs at x = ct, where 0 < x < L and
when 0 < ct < L. At that point,
umax = Vmaxx
c

1 −x
L

,
where umax equals the largest magnitude of u(x, t) for any time t. Plot umax as a function
x and show that it is a parabola. Hint: Find the maximum value of u(x, t) when 0 < x ≤ct
and ct ≤x < L with 0 < x + ct < L or L < x + ct < 2L.
7.5 NUMERICAL SOLUTION OF THE WAVE EQUATION
Despite the powerful techniques shown in the previous sections for solving the wave
equation, often these analytic techniques fail and we must resort to numerical techniques. In
contrast to the continuous solutions, ﬁnite diﬀerence methods, a type of numerical solution
technique, give discrete numerical values at a speciﬁc location (xm, tn), called a grid point.
These numerical values represent a numerical approximation of the continuous solution
over the region (xm −∆x/2, xm + ∆x/2) and (tn −∆t/2, tn + ∆t/2), where ∆x and ∆t are
the distance and time intervals between grid points, respectively. Clearly, in the limit of

326
Advanced Engineering Mathematics with MATLAB
∆x, ∆t →0, we recover the continuous solution. However, practical considerations such as
computer memory or execution time often require that ∆x and ∆t, although small, are not
negligibly small.
The ﬁrst task in the numerical solution of a partial diﬀerential equation is the re-
placement of its continuous derivatives with ﬁnite diﬀerences. The most popular approach
employs Taylor expansions. If we focus on the x-derivative, then the value of the solution
at u[(m + 1)∆x, n∆t] in terms of the solution at (m∆x, n∆t) is
u[(m + 1)∆x, n∆t] = u(xm, tn) + ∆x
1!
∂u(xm, tn)
∂x
+ (∆x)2
2!
∂2u(xm, tn)
∂x2
+ (∆x)3
3!
∂3u(xm, tn)
∂x3
+ (∆x)4
4!
∂4u(xm, tn)
∂x4
+ · · ·
(7.5.1)
= u(xm, tn) + ∆x∂u(xm, tn)
∂x
+ O[(∆x)2],
(7.5.2)
where O[(∆x)2] gives a measure of the magnitude of neglected terms.14
From Equation 7.5.2, one possible approximation for ux is
∂u(xm, tn)
∂x
= un
m+1 −un
m
∆x
+ O(∆x),
(7.5.3)
where we use the standard notation that un
m = u(xm, tn). This is an example of a one-
sided ﬁnite diﬀerence approximation of the partial derivative ux. The error in using this
approximation grows as ∆x.
Another possible approximation for the derivative arises from using u(m∆x, n∆t) and
u[(m −1)∆x, n∆t]. From the Taylor expansion:
u[(m −1)∆x, n∆t] = u(xm, tn) −∆x
1!
∂u(xm, tn)
∂x
+ (∆x)2
2!
∂2u(xm, tn)
∂x2
−(∆x)3
3!
∂3u(xm, tn)
∂x3
+ (∆x)4
4!
∂4u(xm, tn)
∂x4
−· · · ,
(7.5.4)
we can also obtain the one-sided diﬀerence formula
u(xm, tn)
∂x
= un
m −un
m−1
∆x
+ O(∆x).
(7.5.5)
A third possibility arises from subtracting Equation 7.5.4 from Equation 7.5.1:
un
m+1 −un
m−1 = 2∆x∂u(xm, tn)
∂x
+ O[(∆x)3],
(7.5.6)
or
∂u(xm, tn)
∂x
= un
m+1 −un
m−1
2∆x
+ O[(∆x)2].
(7.5.7)
Thus, the choice of the ﬁnite diﬀerencing scheme can produce profound diﬀerences in the
accuracy of the results. In the present case, centered ﬁnite diﬀerences can yield results that
are markedly better than using one-sided diﬀerences.
14 The symbol O is a mathematical notation indicating relative magnitude of terms, namely that f(ǫ) =
O(ǫn) provided limǫ→0 |f(ǫ)/ǫn| < ∞.
For example, as ǫ →0, sin(ǫ) = O(ǫ), sin(ǫ2) = O(ǫ2), and
cos(ǫ) = O(1).

The Wave Equation
327
x
t
x
t
u
u
u
u
u n
n
n
m
n-1
n+1
∆
∆
u0=f(x
g(x
t
∆
-
u
=
-1
u
u 1
n =0
u L
n =0
)
)
0
m
m
m
m
m+1
m
m-1
m
m
Figure 7.5.1: Schematic of the numerical solution of the wave equation with ﬁxed endpoints.
To solve the wave equation, we need to approximate uxx. If we add Equation 7.5.1 and
Equation 7.5.4,
un
m+1 + un
m−1 = 2un
m + ∂2u(xm, tn)
∂x2
(∆x)2 + O[(∆x)4],
(7.5.8)
or
∂2u(xm, tn)
∂x2
= un
m+1 −2un
m + un
m−1
(∆x)2
+ O[(∆x)2].
(7.5.9)
Similar considerations hold for the time derivative. Thus, by neglecting errors of O[(∆x)2]
and O[(∆t)2], we may approximate the wave equation by
un+1
m
−2un
m + un−1
m
(∆t)2
= c2 un
m+1 −2un
m + un
m−1
(∆x)2
.
(7.5.10)
Because the wave equation represents evolutionary change of some quantity, Equation 7.5.10
is generally used as a predictive equation where we forecast un+1
m
by
un+1
m
= 2un
m −un−1
m
+
c∆t
∆x
2  un
m+1 −2un
m + un
m−1

.
(7.5.11)
Figure 7.5.1 illustrates this numerical scheme.
The greatest challenge in using Equation 7.5.11 occurs with the very ﬁrst predic-
tion. When n = 0, clearly u0
m+1, u0
m, and u0
m−1 are speciﬁed from the initial condition
u(m∆x, 0) = f(xm). But what about u−1
m ? Recall that we still have ut(x, 0) = g(x). If we
use the backward diﬀerence formula, Equation 7.5.5,
u0
m −u−1
m
∆t
= g(xm).
(7.5.12)
Solving for u−1
m ,
u−1
m = u0
m −∆tg(xm).
(7.5.13)

328
Advanced Engineering Mathematics with MATLAB
One disadvantage of using the backward ﬁnite-diﬀerence formula is the larger error
associated with this term compared to those associated with the ﬁnite-diﬀerenced form of
the wave equation. In the case of the barotropic vorticity equation, a partial diﬀerential
equation with wave-like solutions, this inconsistency eventually leads to a separation of
solution between adjacent time levels.15 This diﬃculty is avoided by stopping after a certain
number of time steps, averaging the solution, and starting again.
A better solution for computing that ﬁrst time step employs the centered diﬀerence
form
u1
m −u−1
m
2∆t
= g(xm),
(7.5.14)
along with the wave equation
u1
m −2u0
m + u−1
m
(∆t)2
= c2 u0
m+1 −2u0
m + u0
m−1
(∆x)2
,
(7.5.15)
so that
u1
m =
c∆t
∆x
2 f(xm+1) + f(xm−1)
2
+
"
1 −
c∆t
∆x
2#
f(xm) + ∆tg(xm).
(7.5.16)
Although it appears that we are ready to start calculating, we need to check whether
our numerical scheme possesses three properties: convergence, stability, and consistency.
By consistency we mean that the diﬀerence equations approach the diﬀerential equation as
∆x, ∆t →0. To prove consistency, we ﬁrst write un
m+1, un
m−1, un−1
m
, and un+1
m
in terms of
u(x, t) and its derivatives evaluated at (xm, tn). From Taylor expansions,
un
m+1 = un
m + ∆x∂u
∂x

m
n
+ 1
2(∆x)2 ∂2u
∂x2

m
n
+ 1
6(∆x)3 ∂3u
∂x3

m
n
+ · · · ,
(7.5.17)
un
m−1 = un
m −∆x∂u
∂x

m
n
+ 1
2(∆x)2 ∂2u
∂x2

m
n
−1
6(∆x)3 ∂3u
∂x3

m
n
+ · · · ,
(7.5.18)
un+1
m
= un
m + ∆t∂u
∂t

m
n
+ 1
2(∆t)2 ∂2u
∂t2

m
n
+ 1
6(∆t)3 ∂3u
∂t3

m
n
+ · · · ,
(7.5.19)
and
un−1
m
= un
m −∆t∂u
∂t

m
n
+ 1
2(∆t)2 ∂2u
∂t2

m
n
−1
6(∆t)3 ∂3u
∂t3

m
n
+ · · · .
(7.5.20)
Substituting Equations 7.5.17 through 7.5.20 into Equation 7.5.10, we obtain
un+1
m
−2un
m + un−1
m
(∆t)2
−c2 un
m+1 −2un
m + un
m−1
(∆x)2
(7.5.21)
=
∂2u
∂t2 −c2 ∂2u
∂x2

m
n
+ 1
12(∆t)2 ∂4u
∂t4

m
n
−1
12(c∆x)2 ∂4u
∂x4

m
n
+ · · · .
The ﬁrst term on the right side of Equation 7.5.21 vanishes because u(x, t) satisﬁes the wave
equation. As ∆x →0, ∆t →0, the remaining terms on the right side of Equation 7.5.21
15 Gates, W. L., 1959: On the truncation error, stability, and convergence of diﬀerence solutions of the
barotropic vorticity equation. J. Meteorol., 16, 556–568. See Section 4.

The Wave Equation
329
tend to zero and Equation 7.5.10 is a consistent ﬁnite diﬀerence approximation of the wave
equation.
Stability is another question. Under certain conditions the small errors inherent in
ﬁxed precision arithmetic (round oﬀ) can grow for certain choices of ∆x and ∆t. During
the 1920s the mathematicians Courant, Friedrichs, and Lewy16 found that if c∆t/∆x > 1,
then our scheme is unstable. This CFL criterion has its origin in the fact that if c∆t > ∆x,
then we are asking signals in the numerical scheme to travel faster than their real-world
counterparts and this unrealistic expectation leads to instability!
One method of determining stability, commonly called the von Neumann method,17
involves examining solutions to Equation 7.5.11 that have the form
un
m = eimθeinλ,
(7.5.22)
where θ is an arbitrary real number and λ is a yet undetermined complex number. Our
choice of Equation 7.5.22 is motivated by the fact that the initial condition u0
m can be
represented by a Fourier series where a typical term behaves as eimθ.
If we substitute Equation 7.5.22 into Equation 7.5.10 and divide out the common factor
eimθeinλ, we have that
eiλ −2 + e−iλ
(∆t)2
= c2 eiθ −2 + e−iθ
(∆x)2
,
(7.5.23)
or
sin2
λ
2

=
c∆t
∆x
2
sin2
θ
2

.
(7.5.24)
The behavior of un
m is determined by the values of λ given by Equation 7.5.24. If c∆t/∆x ≤
1, then λ is real and un
m is bounded for all θ as n →∞. If c∆t/∆x > 1, then it is possible
to ﬁnd a value of θ such that the right side of Equation 7.5.24 exceeds unity and the
corresponding values of λ occur as complex conjugate pairs.
The λ with the negative
imaginary part produces a solution with exponential growth because n = tn/∆t →∞as
∆t →0 for a ﬁxed tn and c∆t/∆x. Thus, the value of un
m becomes inﬁnitely large, even
though the initial data may be arbitrarily small.
Finally, we must check for convergence. A numerical scheme is convergent if the numer-
ical solution approaches the continuous solution as ∆x, ∆t →0. The general procedure for
proving convergence involves the evolution of the error term en
m, which gives the diﬀerence
between the true solution u(xm, tn) and the ﬁnite diﬀerence solution un
m. From Equation
7.5.21,
en+1
m
=
c∆t
∆x
2  en
m+1 + en
m−1

+ 2
"
1 −
c∆t
∆x
2 #
en
m −en−1
m
+ O[(∆t)4] + O[(∆x)2(∆t)2].
(7.5.25)
Let us apply Equation 7.5.25 to work backwards from the point (xm, tn) by changing n to
n −1. The nonvanishing terms in en
m reduce to a sum of n + 1 values on the line n = 1 plus
1
2(n + 1)n terms of the form A(∆x)4. If we deﬁne the max norm ||en|| = maxm |en
m|, then
||en|| ≤nB(∆x)3 + 1
2(n + 1)nA(∆x)4.
(7.5.26)
16 Courant, R., K. O. Friedrichs, and H. Lewy, 1928:
¨Uber die partiellen Diﬀerenzengleichungen der
mathematischen Physik. Math. Annalen, 100, 32–74. Translated into English in IBM J. Res. Dev., 11,
215–234.
17 After its inventor, J. von Neumann. See O’Brien, G. G., M. A. Hyman, and S. Kaplan, 1950: A study
of the numerical solution of partial diﬀerential equations. J. Math. Phys. (Cambridge, MA), 29, 223–251.

330
Advanced Engineering Mathematics with MATLAB
0
2
4
6
8
10
ct
10
−8
10
−7
10
−6
10
−5
10
−4
10
−3
10
−2
10
−1
error
Figure 7.5.2: The growth of error ||en|| as a function of ct for various resolutions.
For the top line,
∆x = 0.1; for the middle line, ∆x = 0.01; and for the bottom line, ∆x = 0.001.
Because n∆x ≤ctn, Equation 7.5.26 simpliﬁes to
||en|| ≤ctnB(∆x)2 + 1
2c2t2
nA(∆x)2.
(7.5.27)
Thus, the error tends to zero as ∆x →0, verifying convergence. We illustrate Equation
7.5.27 by using the ﬁnite diﬀerence equation, Equation 7.5.11, to compute ||en|| during a
numerical experiment that used c∆t/∆x = 0.5, f(x) = sin(πx), and g(x) = 0; ||en|| is
plotted in Figure 7.5.2. Note how each increase of resolution by 10 results in a drop in the
error by 100.
In the following examples we apply our scheme to solve a few simple initial and bound-
ary conditions:
• Example 7.5.1
For our ﬁrst example, we resolve Equation 7.3.1 through Equation 7.3.3 and Equation
7.3.25 and Equation 7.3.26 numerically using MATLAB. The MATLAB code is
clear
coeff = 0.5; coeffsq = coeff * coeff % coeff = c∆t/∆x
dx = 0.04; dt = coeff * dx; N = 100; x = 0:dx:1;
M = 1/dx + 1; % M = number of spatial grid points
% introduce the initial conditions via F and G
F = zeros(M,1); G = zeros(M,1);
for m = 1:M
if x(m) >= 0.25 & x(m) <= 0.5
F(m) = 4 * x(m) - 1; end
if x(m) >= 0.5 & x(m) <= 0.75
F(m) = 3 - 4 * x(m); end; end
% at t = 0, the solution is:
tplot(1) = 0; u = zeros(M,N+1); u(1:M,1) = F(1:M);
% at t = ∆t, the solution is given by Equation 7.5.16
tplot(2) = dt;
for m = 2:M-1

The Wave Equation
331
0
0.2
0.4
0.6
0.8
1
0
0.5
1
1.5
2
−1
0
1
DISTANCE
TIME
SOLUTION
Figure 7.5.3: The numerical solution u(x, t)/h of the wave equation with c∆t/∆x = 1
2 using Equation
7.5.11 at various positions x′ = x/L and times t′ = ct/L. The exact solution is plotted in Figure 7.3.2.
u(m,2) = 0.5*coeffsq*(F(m+1)+F(m-1)) + (1-coeffsq)*F(m)+dt*G(m);
end
% in general, the solution is given by Equation 7.5.11
for n = 2:N
tplot(n+1) = dt * n;
for m = 2:M-1
u(m,n+1) = 2*u(m,n)-u(m,n-1) + coeffsq*(u(m+1,n)-2*u(m,n)+u(m-1,n));
end; end
X = x’ * ones(1,length(tplot)); T = ones(M,1) * tplot;
surf(X,T,u)
xlabel(’DISTANCE’,’Fontsize’,20); ylabel(’TIME’,’Fontsize’,20)
zlabel(’SOLUTION’,’Fontsize’,20)
Overall, the numerical solution shown in Figure 7.5.3 approximates the exact or analytic
solution well. However, we note small-scale noise in the numerical solution at later times.
Why does this occur? Recall that the exact solution could be written as an inﬁnite sum
of sines in the x dimension. Each successive harmonic adds a contribution from waves of
shorter and shorter wavelength. In the case of the numerical solution, the longer-wavelength
harmonics are well represented by the numerical scheme because there are many grid points
available to resolve a given wavelength. As the wavelengths become shorter, the higher
harmonics are poorly resolved by the numerical scheme, move at incorrect phase speeds,
and their misplacement (dispersion) creates the small-scale noise that you observe rather
than giving the sharp angular features of the exact solution. The only method for avoiding
this problem is to devise schemes that minimize dispersion.
⊓⊔
• Example 7.5.2
Let us redo Example 7.5.1 except that we introduce the boundary condition that
ux(L, t) = 0. This corresponds to a string where we ﬁx the left end and allow the right
end to freely move up and down. This requires a new diﬀerence condition along the right

332
Advanced Engineering Mathematics with MATLAB
0
0.2
0.4
0.6
0.8
1
0
0.5
1
1.5
2
−1
0
1
DISTANCE
TIME
SOLUTION
Figure 7.5.4: The numerical solution u(x, t)/h of the wave equation when the right end moves freely with
c∆t/∆x = 1
2 using Equation 7.5.11 and Equation 7.5.30 at various positions x′ = x/L and times t′ = ct/L.
boundary. If we employ centered diﬀerencing,
un
L+1 −un
L−1
2∆x
= 0,
(7.5.28)
and
un+1
L
= 2un
L −un−1
L
+
c∆t
∆x
2  un
L+1 −2un
L + un
L−1

.
(7.5.29)
Eliminating un
L+1 between Equation 7.5.28 and Equation 7.5.29,
un+1
L
= 2un
L −un−1
L
+
c∆t
∆x
2  2un
L−1 −2un
L

.
(7.5.30)
For the special case of n = 1, Equation 7.5.30 becomes
u1
L = f(xL) +
c∆t
∆x
2
[f(xL−1) −f(xL)] + ∆tf(xL).
(7.5.31)
The MATLAB code used to numerically solve the wave equation with a Neumann bound-
ary condition is very similar to the one used in the previous example that we must add the
line
u(M,2) = coeffsq * F(M-1) + (1-coeffsq) * F(M) + dt*G(M);
after
for m = 2:M-1
u(m,2) = 0.5*coeffsq*(F(m+1)+F(m-1)) + (1-coeffsq)*F(m)+dt*G(m);
end
and
u(M,n+1) = 2*u(M,n)-u(M,n-1) + 2*coeffsq*(u(M-1,n)-u(M,n));
after

The Wave Equation
333
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
5
10
15
20
−0.5
0
0.5
1
TIME
DISTANCE
U(X,T)
Figure 7.5.5: The numerical solution u(x, t) of the ﬁrst-order hyperbolic partial diﬀerential equation
ut + ux = 0 using the Lax-Wendroﬀformula as observed at t = 0, 1, 2, . . . , 20. The initial conditions are
given by Equation 7.3.25 with h = 1, ∆t/∆x = 2
3 , and ∆x = 0.02.
for m = 2:M-1
u(m,n+1) = 2*u(m,n)-u(m,n-1) + coeffsq*(u(m+1,n)-2*u(m,n)+u(m-1,n));
end
Figure 7.5.4 shows the results. The numerical solution agrees well with the exact solution
u(x, t) = 32h
π2
∞
X
n=1
1
(2n −1)2 sin
(2n −1)πx
2L

cos
(2n −1)πct
2L

×

2 sin
(2n −1)π
4

−sin
3(2n −1)π
8

−sin
(2n −1)π
8

.
(7.5.32)
The results are also consistent with those presented in Example 7.5.1, especially with regard
to small-scale noise due to dispersion.
Project: Numerical Solution of First-Order Hyperbolic Equations
The equation ut+ux = 0 is the simplest possible hyperbolic partial diﬀerential equation.
Indeed, the classic wave equation consists of a system of these equations: ut + cvx = 0, and
vt + cux = 0. In this project you will examine several numerical schemes for solving such a
partial diﬀerential equation using MATLAB.
Step 1: One of the simplest numerical schemes is the forward-in-time, centered-in-space of
un+1
m
−un
m
∆t
+ un
m+1 −un
m−1
2∆x
= 0.
Use von Neumann’s stability analysis to show that this scheme is always unstable.

334
Advanced Engineering Mathematics with MATLAB
0
0.2
0.4
0.6
0.8
1
0
10
20
−0.5
0
0.5
1
TIME
DISTANCE
U(X,T)
Figure 7.5.6: Same as Figure 7.5.5 except that the centered-in-time, centered-in-space scheme was used.
Step 2: The most widely used method for numerically integrating ﬁrst-order hyperbolic
equations is the Lax-Wendroﬀmethod:18
un+1
m
= un
m −∆t
2∆x
 un
m+1 −un
m−1

+ (∆t)2
2(∆x)2
 un
m+1 −2un
m + un
m−1

.
This method introduces errors of O[(∆t)2] and O[(∆x)2]. Show that this scheme is stable
if it satisﬁes the CFL criteria of ∆t/∆x ≤1.
Using the initial condition given by Equation 7.3.25, write a MATLAB code that uses
this scheme to numerically integrate ut + ux = 0. Plot the results for various ∆t/∆x over
the interval 0 ≤x ≤1 given the periodic boundary conditions of u(0, t) = u(1, t) for the
temporal interval 0 ≤t ≤20. See Figure 7.5.5. Discuss the strengths and weaknesses of
the scheme with respect to dissipation or damping of the numerical solution and preserving
the phase of the solution. Most numerical methods books discuss this.19
Step 3: Another simple scheme is the centered-in-time, centered-in-space of
un+1
m
−un−1
m
2∆t
+ un
m+1 −un
m−1
2∆x
= 0.
This method introduces errors of O[(∆t)2] and O[(∆x)2].
Repeat the analysis from Step 1 for this scheme. One of the diﬃculties is taking the
ﬁrst time step. Use the scheme in Step 1 to take this ﬁrst time step. See Figure 7.5.6.
Further Reading
King, G. C., 2009: Vibrations and Waves. Wiley, 228 pp. This book emphasises the physical
principles, rather than the mathematics.
18 Lax, P. D., and B. Wendroﬀ, 1960: Systems of conservative laws. Comm. Pure Appl. Math., 13,
217–237.
19 For example, Lapidus, L., and G. F. Pinder, 1982: Numerical Solution of Partial Diﬀerential Equations
in Science and Engineering. John Wiley & Sons, 677 pp.

The Wave Equation
335
Koshlyakov, N. S., M. M. Smirnov, and E. B. Gliner, 1964: Diﬀerential Equations of Math-
ematical Physics. North-Holland Publishing, 701 pp. See Part I. Detailed presentations of
solution techniques.
Morse, P. M., and H. Feshback, 1953: Methods of Theoretical Physics. McGraw -Hill Book
Co., 997 pp. Chapter 11 is devoted to solving the wave equation.

Chapter 8
The Heat Equation
In this chapter we deal with the linear parabolic diﬀerential equation
∂u
∂t = a2 ∂2u
∂x2
(8.0.1)
in the two independent variables x and t. This equation, known as the one-dimensional
heat equation, serves as the prototype for a wider class of parabolic equations
a(x, t)∂2u
∂x2 + b(x, t) ∂2u
∂x∂t + c(x, t)∂2u
∂t2 = f

x, t, u, ∂u
∂x, ∂u
∂t

,
(8.0.2)
where b2 = 4ac. It arises in the study of heat conduction in solids as well as in a variety
of diﬀusive phenomena. The heat equation is similar to the wave equation in that it is also
an equation of evolution. However, the heat equation is not “conservative” because if we
reverse the sign of t, we obtain a diﬀerent solution. This reﬂects the presence of entropy,
which must always increase during heat conduction.
8.1 DERIVATION OF THE HEAT EQUATION
To derive the heat equation, consider a heat-conducting homogeneous rod, extending
from x = 0 to x = L along the x-axis (see Figure 8.1.1). The rod has uniform cross section
A and constant density ρ, is insulated laterally so that heat ﬂows only in the x-direction,
and is suﬃciently thin so that the temperature at all points on a cross section is constant.
Let u(x, t) denote the temperature of the cross section at the point x at any instant of time
t, and let c denote the speciﬁc heat of the rod (the amount of heat required to raise the
337

338
Advanced Engineering Mathematics with MATLAB
x
x
x+ ∆
Figure 8.1.1: Heat conduction in a thin bar.
temperature of a unit mass of the rod by a degree). In the segment of the rod between the
cross section at x and the cross section at x + ∆x, the amount of heat is
Q(t) =
Z x+∆x
x
cρAu(s, t) ds.
(8.1.1)
On the other hand, the rate at which heat ﬂows into the segment across the cross section
at x is proportional to the cross section and the gradient of the temperature at the cross
section (Fourier’s law of heat conduction):
−κA∂u(x, t)
∂x
,
(8.1.2)
where κ denotes the thermal conductivity of the rod. The sign in Equation 8.1.2 indicates
that heat ﬂows in the direction of decreasing temperature. Similarly, the rate at which heat
ﬂows out of the segment through the cross section at x + ∆x equals
−κA∂u(x + ∆x, t)
∂x
.
(8.1.3)
The diﬀerence between the amount of heat that ﬂows in through the cross section at x and
the amount of heat that ﬂows out through the cross section at x+∆x must equal the change
in the heat content of the segment x ≤s ≤x + ∆x. Hence, by subtracting Equation 8.1.3
from Equation 8.1.2 and equating the result to the time derivative of Equation 8.1.1,
∂Q
∂t =
Z x+∆x
x
cρA∂u(s, t)
∂t
ds = κA
∂u(x + ∆x, t)
∂x
−∂u(x, t)
∂x

.
(8.1.4)
Assuming that the integrand in Equation 8.1.4 is a continuous function of s, then by the
mean value theorem for integrals,
Z x+∆x
x
∂u(s, t)
∂t
ds = ∂u(ξ, t)
∂t
∆x,
x < ξ < x + ∆x,
(8.1.5)
so that Equation 8.1.4 becomes
cρ∆x∂u(ξ, t)
∂t
= κ
∂u(x + ∆x, t)
∂x
−∂u(x, t)
∂x

.
(8.1.6)
Dividing both sides of Equation 8.1.6 by cρ∆x and taking the limit as ∆x →0,
∂u(x, t)
∂t
= a2 ∂2u(x, t)
∂x2
(8.1.7)
with a2 = κ/(cρ). Equation 8.1.7 is called the one-dimensional heat equation. The constant
a2 is called the diﬀusivity within the solid.

The Heat Equation
339
If an external source supplies heat to the rod at a rate f(x, t) per unit volume per unit
time, we must add the term
R x+∆x
x
f(s, t) ds to the time derivative term of Equation 8.1.4.
Thus, in the limit ∆x →0,
∂u(x, t)
∂t
−a2 ∂2u(x, t)
∂x2
= F(x, t),
(8.1.8)
where F(x, t) = f(x, t)/(cρ) is the source density. This equation is called the nonhomoge-
neous heat equation.
8.2 INITIAL AND BOUNDARY CONDITIONS
In the case of heat conduction in a thin rod, the temperature function u(x, t) must
satisfy not only the heat equation, Equation 8.1.7, but also how the two ends of the rod
exchange heat energy with the surrounding medium. If (1) there is no heat source, (2) the
function f(x), 0 < x < L describes the temperature in the rod at t = 0, and (3) we maintain
both ends at zero temperature for all time, then the partial diﬀerential equation
∂u
∂t = a2 ∂2u
∂x2 ,
0 < x < L,
0 < t,
(8.2.1)
describes the temperature distribution u(x, t) in the rod at any later time 0 < t subject to
the conditions
u(x, 0) = f(x),
0 < x < L,
(8.2.2)
and
u(0, t) = u(L, t) = 0,
0 < t.
(8.2.3)
Equations 8.2.1 and 8.2.3 describe the initial-boundary-value problem for this particular
heat conduction problem; Equation 8.2.3 is the boundary condition while Equation 8.2.2
gives the initial condition. Note that in the case of the heat equation, the problem only
demands the initial value of u(x, t) and not ut(x, 0), as with the wave equation.
Historically most linear boundary conditions have been classiﬁed in one of three ways.
The condition, Equation 8.2.3, is an example of a Dirichlet problem1 or condition of the
ﬁrst kind. This type of boundary condition gives the value of the solution (which is not
necessarily equal to zero) along a boundary.
The next simplest condition involves derivatives. If we insulate both ends of the rod so
that no heat ﬂows from the ends, then according to Equation 7.1.2 the boundary condition
assumes the form
∂u(0, t)
∂x
= ∂u(L, t)
∂x
= 0,
0 < t.
(8.2.4)
This is an example of a Neumann problem2 or condition of the second kind. This type of
boundary condition speciﬁes the value of the normal derivative (which may not be equal to
zero) of the solution along the boundary.
1 Dirichlet, P. G. L., 1850: ¨Uber einen neuen Ausdruck zur Bestimmung der Dichtigkeit einer unendlich
d¨unnen Kugelschale, wenn der Werth des Potentials derselben in jedem Punkte ihrer Oberﬂ¨ache gegeben
ist. Abh. K¨oniglich. Preuss. Akad. Wiss., 99–116.
2 Neumann, C. G., 1877: Untersuchungen ¨uber das Logarithmische und Newton’sche Potential.

340
Advanced Engineering Mathematics with MATLAB
Finally, if there is radiation of heat from the ends of the rod into the surrounding
medium, we shall show that the boundary condition is of the form
∂u(0, t)
∂x
−hu(0, t) = a constant,
(8.2.5)
and
∂u(L, t)
∂x
+ hu(L, t) = another constant
(8.2.6)
for 0 < t, where h is a positive constant. This is an example of a condition of the third kind
or Robin problem3 and is a linear combination of Dirichlet and Neumann conditions.
8.3 SEPARATION OF VARIABLES
As with the wave equation, the most popular and widely used technique for solving
the heat equation is separation of variables. Its success depends on our ability to express
the solution u(x, t) as the product X(x)T(t). If we cannot achieve this separation, then the
technique must be abandoned for others. In the following examples we show how to apply
this technique.
• Example 8.3.1
Let us ﬁnd the solution to the homogeneous heat equation
∂u
∂t = a2 ∂2u
∂x2 ,
0 < x < L,
0 < t,
(8.3.1)
which satisﬁes the initial condition
u(x, 0) = f(x),
0 < x < L,
(8.3.2)
and the boundary conditions
u(0, t) = u(L, t) = 0,
0 < t.
(8.3.3)
This system of equations models heat conduction in a thin metallic bar where both ends are
held at the constant temperature of zero and the bar initially has the temperature f(x).
We shall solve this problem by the method of separation of variables. Accordingly, we
seek particular solutions of Equation 8.3.1 of the form
u(x, t) = X(x)T(t),
(8.3.4)
which satisfy the boundary conditions, Equation 8.3.3. Because
∂u
∂t = X(x)T ′(t),
(8.3.5)
and
∂2u
∂x2 = X′′(x)T(t),
(8.3.6)
3 Robin, G., 1886: Sur la distribution de l’´electricit´e `a la surface des conducteurs ferm´es et des conduc-
teurs ouverts. Ann. Sci. l’Ecole Norm. Sup., Ser. 3, 3, S1–S58.

The Heat Equation
341
Equation 8.3.1 becomes
T ′(t)X(x) = a2X′′(x)T(t).
(8.3.7)
Dividing both sides of Equation 8.3.7 by a2X(x)T(t) gives
T ′
a2T = X′′
X = −λ,
(8.3.8)
where −λ is the separation constant. Equation 8.3.8 immediately yields two ordinary dif-
ferential equations:
X′′ + λX = 0,
(8.3.9)
and
T ′ + a2λT = 0
(8.3.10)
for the functions X(x) and T(t), respectively.
We now rewrite the boundary conditions in terms of X(x) by noting that the boundary
conditions are u(0, t) = X(0)T(t) = 0, and u(L, t) = X(L)T(t) = 0 for 0 < t.
If we
were to choose T(t) = 0, then we would have a trivial solution for u(x, t). Consequently,
X(0) = X(L) = 0.
We now solve Equation 8.3.9. There are three possible cases: λ = −m2, λ = 0, and
λ = k2. If λ = −m2 < 0, then we must solve the boundary-value problem
X′′ −m2X = 0,
X(0) = X(L) = 0.
(8.3.11)
The general solution to Equation 8.3.11 is
X(x) = A cosh(mx) + B sinh(mx).
(8.3.12)
Because X(0) = 0, it follows that A = 0. The condition X(L) = 0 yields B sinh(mL) = 0.
Since sinh(mL) ̸= 0, B = 0, and we have a trivial solution for λ < 0.
If λ = 0, the corresponding boundary-value problem is
X′′(x) = 0,
X(0) = X(L) = 0.
(8.3.13)
The general solution is
X(x) = C + Dx.
(8.3.14)
From X(0) = 0, we have that C = 0. From X(L) = 0, DL = 0, or D = 0. Again, we obtain
a trivial solution.
Finally, we assume that λ = k2 > 0. The corresponding boundary-value problem is
X′′ + k2X = 0,
X(0) = X(L) = 0.
(8.3.15)
The general solution to Equation 8.3.15 is
X(x) = E cos(kx) + F sin(kx).
(8.3.16)
Because X(0) = 0, it follows that E = 0; from X(L) = 0, we obtain F sin(kL) = 0.
For a nontrivial solution, F ̸= 0 and sin(kL) = 0. This implies that knL = nπ, where
n = 1, 2, 3, . . .. In summary, the x-dependence of the solution is
Xn(x) = Fn sin
nπx
L

,
(8.3.17)

342
Advanced Engineering Mathematics with MATLAB
where λn = n2π2/L2.
Turning to the time dependence, we use λn = n2π2/L2 in Equation 8.3.10
T ′
n + a2n2π2
L2
Tn = 0.
(8.3.18)
The corresponding general solution is
Tn(t) = Gn exp

−a2n2π2
L2
t

.
(8.3.19)
Thus, the functions
un(x, t) = Bn sin
nπx
L

exp

−a2n2π2
L2
t

, n = 1, 2, 3, . . . ,
(8.3.20)
where Bn = FnGn, are particular solutions of Equation 8.3.1 and satisfy the homogeneous
boundary conditions, Equation 8.3.3.
As we noted in the case of the wave equation, we can solve the x-dependence equation
as a regular Sturm-Liouville problem. After ﬁnding the eigenvalue λn and eigenfunction,
we solve for Tn(t). The product solution un(x, t) equals the product of the eigenfunction
and Tn(t).
Having found particular solutions to our problem, the most general solution equals a
linear sum of these particular solutions:
u(x, t) =
∞
X
n=1
Bn sin
nπx
L

exp

−a2n2π2
L2
t

.
(8.3.21)
The coeﬃcient Bn is chosen so that Equation 8.3.21 yields the initial condition, Equation
8.3.2, if t = 0. Thus, setting t = 0 in Equation 8.3.21, we see from Equation 8.3.2 that the
coeﬃcients Bn must satisfy the relationship
f(x) =
∞
X
n=1
Bn sin
nπx
L

,
0 < x < L.
(8.3.22)
This is precisely a Fourier half-range sine series for f(x) on the interval (0, L). Therefore,
the formula
Bn = 2
L
Z L
0
f(x) sin
nπx
L

dx,
n = 1, 2, 3, . . .
(8.3.23)
gives the coeﬃcients Bn. For example, if L = π and u(x, 0) = x(π −x), then
Bn = 2
π
Z π
0
x(π −x) sin(nx) dx = 2
Z π
0
x sin(nx) dx −2
π
Z π
0
x2 sin(nx) dx = 41 −(−1)n
n3π
.
(8.3.24)
Hence,
u(x, t) = 8
π
∞
X
n=1
sin[(2n −1)x]
(2n −1)3
e−(2n−1)2a2t.
(8.3.25)

The Heat Equation
343
0
1
2
3
4
0
0.5
1
1.5
2
0
0.5
1
1.5
2
2.5
DISTANCE
TIME
U(X,T)
Figure 8.3.1: The temperature u(x, t) within a thin bar as a function of position x and time a2t when we
maintain both ends at zero and the initial temperature equals x(π −x).
Figure 8.3.1 illustrates Equation 8.3.25 for various times.
It was created using the
MATLAB script
clear
M = 20; dx = pi/25; dt = 0.05;
% compute grid and initialize solution
X = [0:dx:pi]; T = [0:dt:2];
u = zeros(length(T),length(X));
XX = repmat(X,[length(T) 1]); TT = repmat(T’,[1 length(X)]);
% compute solution from Equation 8.3.25
for m = 1:M
temp1 = 2*m-1; coeff = 8 / (pi * temp1 * temp1 * temp1);
u = u + coeff * sin(temp1*XX) .* exp(-temp1 * temp1 * TT);
end
surf(XX,TT,u)
xlabel(’DISTANCE’,’Fontsize’,20); ylabel(’TIME’,’Fontsize’,20)
zlabel(’U(X,T)’,’Fontsize’,20)
Note that both ends of the bar satisfy the boundary conditions, namely that the temperature
equals zero. As time increases, heat ﬂows out from the center of the bar to both ends where
it is removed. This process is reﬂected in the collapse of the original parabolic shape of the
temperature proﬁle toward zero as time increases.
⊓⊔
• Example 8.3.2
As a second example, let us solve the heat equation
∂u
∂t = a2 ∂2u
∂x2 ,
0 < x < L,
0 < t,
(8.3.26)
which satisﬁes the initial condition
u(x, 0) = x,
0 < x < L,
(8.3.27)

344
Advanced Engineering Mathematics with MATLAB
and the boundary conditions
∂u(0, t)
∂x
= u(L, t) = 0,
0 < t.
(8.3.28)
The condition ux(0, t) = 0 expresses mathematically the constraint that no heat ﬂows
through the left boundary (insulated end condition).
Once again, we employ separation of variables; as in the previous example, the positive
and zero separation constants yield trivial solutions. For a negative separation constant,
however,
X′′ + k2X = 0,
(8.3.29)
with
X′(0) = X(L) = 0,
(8.3.30)
because ux(0, t) = X′(0)T(t) = 0, and u(L, t) = X(L)T(t) = 0.
This regular Sturm-
Liouville problem has the solution
Xn(x) = cos
(2n −1)πx
2L

,
n = 1, 2, 3, . . . .
(8.3.31)
The temporal solution then becomes
Tn(t) = Bn exp

−a2(2n −1)2π2t
4L2

.
(8.3.32)
Consequently, a linear superposition of the particular solutions gives the total solution,
which equals
u(x, t) =
∞
X
n=1
Bn cos
(2n −1)πx
2L

exp

−a2(2n −1)2π2
4L2
t

.
(8.3.33)
Our ﬁnal task remains to ﬁnd the coeﬃcients Bn. Evaluating Equation 8.3.33 at t = 0,
u(x, 0) = x =
∞
X
n=1
Bn cos
(2n −1)πx
2L

,
0 < x < L.
(8.3.34)
Equation 8.3.34 is not a half-range cosine expansion; it is an expansion in the orthog-
onal functions cos[(2n −1)πx/(2L)] corresponding to the regular Sturm-Liouville problem,
Equation 8.3.29 and Equation 8.3.30. Consequently, Bn is given by Equation 6.3.4 with
r(x) = 1 as
Bn =
R L
0 x cos[(2n −1)πx/(2L)] dx
R L
0 cos2[(2n −1)πx/(2L)] dx
(8.3.35)
=
4L2
(2n−1)2π2 cos
h
(2n−1)πx
2L
iL
0 +
2Lx
(2n−1)π sin
h
(2n−1)πx
2L
iL
0
x
2
L
0 +
L
2(2n−1)π sin
h
(2n−1)πx
L
iL
0
(8.3.36)
=
8L
(2n −1)2π2

cos
(2n −1)π
2

−1

+
4L
(2n −1)π sin
(2n −1)π
2

(8.3.37)
= −
8L
(2n −1)2π2 −4L(−1)n
(2n −1)π ,
(8.3.38)

The Heat Equation
345
0
0.5
1
0
0.5
1
0
0.5
1
DISTANCE
TIME
SOLUTION
Figure 8.3.2: The temperature u(x, t)/L within a thin bar as a function of position x/L and time a2t/L2
when we insulate the left end and hold the right end at the temperature of zero. The initial temperature
equals x.
as cos[(2n −1)π/2] = 0, and sin[(2n −1)π/2] = (−1)n+1.
Consequently, the complete
solution is
u(x, t) = −4L
π
∞
X
n=1

2
(2n −1)2π + (−1)n
2n −1

cos
(2n −1)πx
2L

exp

−(2n −1)2π2a2t
4L2

.
(8.3.39)
Figure 8.3.2 illustrates the evolution of the temperature ﬁeld with time. It was gener-
ated using the MATLAB script
clear
M = 200; dx = 0.02; dt = 0.05;
% compute Fourier coefficients
sign = -1;
for m = 1:M
temp1 = 2*m-1;
a(m) = 2/(pi*temp1*temp1) + sign/temp1;
sign = - sign;
end
% compute grid and initialize solution
X = [0:dx:1]; T = [0:dt:1];
u = zeros(length(T),length(X));
XX = repmat(X,[length(T) 1]);
TT = repmat(T’,[1 length(X)]);
% compute solution from Equation 8.3.39
for m = 1:M
temp1 = (2*m-1)*pi/2;
u = u + a(m) * cos(temp1*XX) .* exp(-temp1 * temp1 * TT);
end

346
Advanced Engineering Mathematics with MATLAB
u = - (4/pi) * u;
surf(XX,TT,u); axis([0 1 0 1 0 1]);
xlabel(’DISTANCE’,’Fontsize’,20); ylabel(’TIME’,’Fontsize’,20)
zlabel(’SOLUTION’,’Fontsize’,20)
Initially, heat near the center of the bar ﬂows toward the cooler, insulated end, resulting in
an increase of temperature there. On the right side, heat ﬂows out of the bar because the
temperature is maintained at zero at x = L. Eventually the heat that has accumulated at
the left end ﬂows rightward because of the continual heat loss on the right end. In the limit
of t →∞, all of the heat has left the bar.
⊓⊔
• Example 8.3.3
A slight variation on Example 8.3.1 is
∂u
∂t = a2 ∂2u
∂x2 ,
0 < x < L,
0 < t,
(8.3.40)
where
u(x, 0) = u(0, t) = 0,
and
u(L, t) = θ.
(8.3.41)
We begin by blindly employing the technique of separation of variables. Once again, we
obtain the ordinary diﬀerential equation, Equation 8.3.9 and Equation 8.3.10. The initial
and boundary conditions become, however,
X(0) = T(0) = 0,
(8.3.42)
and
X(L)T(t) = θ.
(8.3.43)
Although Equation 8.3.42 is acceptable, Equation 8.3.43 gives us an impossible condition
because T(t) cannot be constant. If it were, it would have to equal to zero by Equation
8.3.42.
To ﬁnd a way around this diﬃculty, suppose that we want the solution to our problem
at a time long after t = 0. From experience we know that heat conduction with time-
independent boundary conditions eventually results in an evolution from the initial condi-
tion to some time-independent (steady-state) equilibrium. If we denote this steady-state
solution by w(x), it must satisfy the heat equation
a2w′′(x) = 0,
(8.3.44)
and the boundary conditions
w(0) = 0,
and
w(L) = θ.
(8.3.45)
We can integrate Equation 8.3.44 immediately to give
w(x) = A + Bx,
(8.3.46)
and the boundary condition, Equation 8.3.45, results in
w(x) = θx
L .
(8.3.47)

The Heat Equation
347
Clearly Equation 8.3.47 cannot hope to satisfy the initial conditions; that was never
expected of it. However, if we add a time-varying (transient) solution v(x, t) to w(x) so
that
u(x, t) = w(x) + v(x, t),
(8.3.48)
we could satisfy the initial condition if
v(x, 0) = u(x, 0) −w(x),
(8.3.49)
and v(x, t) tends to zero as t →∞. Furthermore, because w′′(x) = w(0) = 0, and w(L) = θ,
∂v
∂t = a2 ∂2v
∂x2 ,
0 < x < L,
0 < t,
(8.3.50)
with the boundary conditions
v(0, t) = v(L, t) = 0,
0 < t.
(8.3.51)
We can solve Equation 8.3.49, Equation 8.3.50, and Equation 8.3.51 by separation of vari-
ables; we did it in Example 8.3.1. However, in place of f(x) we now have u(x, 0) −w(x), or
−w(x) because u(x, 0) = 0. Therefore, the solution v(x, t) is
v(x, t) =
∞
X
n=1
Bn sin
nπx
L

exp

−a2n2π2
L2
t

(8.3.52)
with
Bn = 2
L
Z L
0
−w(x) sin
nπx
L

dx = 2
L
Z L
0
−θx
L sin
nπx
L

dx
(8.3.53)
= −2θ
L2
 L2
n2π2 sin
nπx
L

−xL
nπ cos
nπx
L
L
0
= (−1)n 2θ
nπ .
(8.3.54)
Thus, the entire solution is
u(x, t) = θx
L + 2θ
π
∞
X
n=1
(−1)n
n
sin
nπx
L

exp

−a2n2π2
L2
t

.
(8.3.55)
The quantity a2t/L2 is the Fourier number.
Figure 8.3.3 illustrates our solution and was created with the MATLAB script
clear
M = 1000; dx = 0.01; dt = 0.01;
% compute grid and initialize solution
X = [0:dx:1]; T = [0:dt:0.2];
XX = repmat(X,[length(T) 1]); TT = repmat(T’,[1 length(X)]);
u = XX;
% compute solution from Equation 8.3.55
sign = -2/pi;
for m = 1:M
coeff = sign/m;

348
Advanced Engineering Mathematics with MATLAB
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0
0.2
0.4
0.6
0.8
1
DISTANCE
TIME
SOLUTION
Figure 8.3.3: The temperature u(x, t)/θ within a thin bar as a function of position x/L and time a2t/L2
with the left end held at a temperature of zero and right end held at a temperature θ while the initial
temperature of the bar is zero.
u = u + coeff * sin((m*pi)*XX) .* exp(-(m*m*pi*pi) * TT);
sign = -sign;
end
surf(XX,TT,u); axis([0 1 0 0.2 0 1]);
xlabel(’DISTANCE’,’Fontsize’,20); ylabel(’TIME’,’Fontsize’,20)
zlabel(’SOLUTION’,’Fontsize’,20)
Clearly it satisﬁes the boundary conditions. Initially, heat ﬂows rapidly from right to left.
As time increases, the rate of heat transfer decreases until the ﬁnal equilibrium (steady-
state) is established and no more heat ﬂows.
⊓⊔
• Example 8.3.4
Let us ﬁnd the solution to the heat equation
∂u
∂t = a2 ∂2u
∂x2 ,
0 < x < L,
0 < t,
(8.3.56)
subject to the Neumann boundary conditions
∂u(0, t)
∂x
= ∂u(L, t)
∂x
= 0,
0 < t,
(8.3.57)
and the initial condition that
u(x, 0) = x,
0 < x < L.
(8.3.58)
We have now insulated both ends of the bar.
Assuming that u(x, t) = X(x)T(t),
T ′
a2T = X′′
X = −k2,
(8.3.59)

The Heat Equation
349
where we have presently assumed that the separation constant is negative. The Neumann
conditions give ux(0, t) = X′(0)T(t) = 0, and ux(L, t) = X′(L)T(t) = 0 so that X′(0) =
X′(L) = 0.
The Sturm-Liouville problem
X′′ + k2X = 0,
(8.3.60)
and
X′(0) = X′(L) = 0
(8.3.61)
gives the x-dependence. The eigenfunction solution is
Xn(x) = cos
nπx
L

,
(8.3.62)
where kn = nπ/L and n = 1, 2, 3, . . ..
The corresponding temporal part equals the solution of
T ′
n + a2k2
nTn = T ′
n + a2n2π2
L2
Tn = 0,
(8.3.63)
which is
Tn(t) = An exp

−a2n2π2
L2
t

.
(8.3.64)
Thus, the product solution given by a negative separation constant is
un(x, t) = Xn(x)Tn(t) = An cos
nπx
L

exp

−a2n2π2
L2
t

.
(8.3.65)
Unlike our previous problems, there is a nontrivial solution for a separation constant
that equals zero. In this instance, the x-dependence equals
X(x) = Ax + B.
(8.3.66)
The boundary conditions X′(0) = X′(L) = 0 force A to be zero but B is completely free.
Consequently, the eigenfunction in this particular case is
X0(x) = 1.
(8.3.67)
Because T ′
0(t) = 0 in this case, the temporal part equals a constant that we shall take to be
A0/2. Therefore, the product solution corresponding to the zero separation constant is
u0(x, t) = X0(x)T0(t) = A0/2.
(8.3.68)
The most general solution to our problem equals the sum of all of the possible solutions:
u(x, t) = A0
2 +
∞
X
n=1
An cos
nπx
L

exp

−a2n2π2
L2
t

.
(8.3.69)
Upon substituting t = 0 into Equation 8.3.69, we can determine An because
u(x, 0) = x = A0
2 +
∞
X
n=1
An cos
nπx
L

(8.3.70)

350
Advanced Engineering Mathematics with MATLAB
0
0.5
1
0
0.1
0.2
0.3
0
0.2
0.4
0.6
0.8
1
DISTANCE
TIME
SOLUTION
Figure 8.3.4: The temperature u(x, t)/L within a thin bar as a function of position x/L and time a2t/L2
when we insulate both ends. The initial temperature of the bar is x.
is merely a half-range Fourier cosine expansion of the function x over the interval (0, L).
From Equation 5.1.22 and Equation 5.1.23,
A0 = 2
L
Z L
0
x dx = L,
(8.3.71)
and
An = 2
L
Z L
0
x cos
nπx
L

dx = 2
L
 L2
n2π2 cos
nπx
L

+ xL
nπ sin
nπx
L
L
0
=
2L
n2π2 [(−1)n −1] .
(8.3.72)
The complete solution is
u(x, t) = L
2 −4L
π2
∞
X
m=1
1
(2m −1)2 cos
(2m −1)πx
L

exp

−a2(2m −1)2π2
L2
t

,
(8.3.73)
because all of the even harmonics vanish and we may rewrite the odd harmonics using
n = 2m −1, where m = 1, 2, 3, 4, . . ..
Figure 8.3.4 illustrates Equation 8.3.73 for various positions and times. It was generated
using the MATLAB script
clear
M = 100; dx = 0.01; dt = 0.01;
% compute grid and initialize solution
X = [0:dx:1]; T = [0:dt:0.3];
u = zeros(length(T),length(X)); u = 0.5;
XX = repmat(X,[length(T) 1]); TT = repmat(T’,[1 length(X)]);
% compute solution from Equation 8.3.73
for m = 1:M
temp1 = (2*m-1) * pi;

The Heat Equation
351
coeff = 4 / (temp1*temp1);
u = u - coeff * cos(temp1*XX) .* exp(-temp1 * temp1 * TT);
end
surf(XX,TT,u); axis([0 1 0 0.3 0 1]);
xlabel(’DISTANCE’,’Fontsize’,20); ylabel(’TIME’,’Fontsize’,20)
zlabel(’SOLUTION’,’Fontsize’,20)
The physical interpretation is quite simple. Since heat cannot ﬂow in or out of the rod
because of the insulation, it can only redistribute itself. Thus, heat ﬂows from the warm
right end to the cooler left end. Eventually the temperature achieves steady-state when the
temperature is uniform throughout the bar.
⊓⊔
• Example 8.3.5
So far we have dealt with problems where the temperature or ﬂux of heat has been
speciﬁed at the ends of the rod. In many physical applications, one or both of the ends
may radiate to free space at temperature u0. According to Stefan’s law, the amount of heat
radiated from a given area dA in a given time interval dt is
σ(u4 −u4
0) dA dt,
(8.3.74)
where σ is called the Stefan-Boltzmann constant. On the other hand, the amount of heat
that reaches the surface from the interior of the body, assuming that we are at the right
end of the bar, equals
−κ∂u
∂x dA dt,
(8.3.75)
where κ is the thermal conductivity. Because these quantities must be equal,
−κ∂u
∂x = σ(u4 −u4
0) = σ(u −u0)(u3 + u2u0 + uu2
0 + u3
0).
(8.3.76)
If u and u0 are nearly equal, we may approximate the second bracketed term on the right
side of Equation 8.3.76 as 4u3
0. We write this approximate form of Equation 8.3.76 as
−∂u
∂x = h(u −u0),
(8.3.77)
where h, the surface conductance or the coeﬃcient of surface heat transfer, equals 4σu3
0/κ.
Equation 8.3.77 is a “radiation” boundary condition. Sometimes someone will refer to it
as “Newton’s law” because Equation 8.3.77 is mathematically identical to Newton’s law of
cooling of a body by forced convection.
Let us now solve the problem of a rod that we initially heat to the uniform temperature
of 100. We then allow it to cool by maintaining the temperature at zero at x = 0 and
radiatively cooling to the surrounding air at the temperature of zero4 at x = L. We may
restate the problem as
∂u
∂t = a2 ∂2u
∂x2 ,
0 < x < L,
0 < t,
(8.3.78)
4 Although this would appear to make h = 0, we have merely chosen a temperature scale so that the
air temperature is zero and the absolute temperature used in Stefan’s law is nonzero.

352
Advanced Engineering Mathematics with MATLAB
Table 8.3.1: The First Ten Roots of Equation 8.3.87 and Cn for hL = 1
n
αn
Approximate αn
Cn
1
2.0288
2.2074
118.9221
2
4.9132
4.9246
31.3414
3
7.9787
7.9813
27.7549
4
11.0855
11.0865
16.2891
5
14.2074
14.2079
14.9916
6
17.3364
17.3366
10.8362
7
20.4692
20.4693
10.2232
8
23.6043
23.6044
8.0999
9
26.7409
26.7410
7.7479
10
29.8786
29.8786
6.4626
with
u(x, 0) = 100,
0 < x < L,
(8.3.79)
u(0, t) = 0,
0 < t,
(8.3.80)
and
∂u(L, t)
∂x
+ hu(L, t) = 0,
0 < t.
(8.3.81)
Once again, we assume a product solution u(x, t) = X(x)T(t) with a negative separa-
tion constant so that
X′′
X = T ′
a2T = −k2.
(8.3.82)
We obtain for the x-dependence that
X′′ + k2X = 0,
(8.3.83)
but the boundary conditions are now
X(0) = 0,
and
X′(L) + hX(L) = 0.
(8.3.84)
The most general solution of Equation 8.3.83 is
X(x) = A cos(kx) + B sin(kx).
(8.3.85)
However, A = 0, because X(0) = 0. On the other hand,
k cos(kL) + h sin(kL) = kL cos(kL) + hL sin(kL) = 0,
(8.3.86)
if B ̸= 0. The nondimensional number hL is the Biot number and depends completely upon
the physical characteristics of the rod.
In Chapter 6 we saw how to ﬁnd the roots of the transcendental equation
α + hL tan(α) = 0,
(8.3.87)
where α = kL. Consequently, if αn is the nth root of Equation 8.3.87, then the eigenfunction
is
Xn(x) = sin(αnx/L).
(8.3.88)
In Table 8.3.1, we list the ﬁrst ten roots of Equation 8.3.87 for hL = 1.

The Heat Equation
353
In general, we must solve Equation 8.3.87 either numerically or graphically. If α is
large, however, we can ﬁnd approximate values5 by noting that
cot(α) = −hL/α ≈0,
(8.3.89)
or
αn = (2n −1)π/2,
(8.3.90)
where n = 1, 2, 3, . . .. We can obtain a better approximation by setting
αn = (2n −1)π/2 −ǫn,
(8.3.91)
where ǫn ≪1. Substituting into Equation 8.3.89,
[(2n −1)π/2 −ǫn] cot[(2n −1)π/2 −ǫn] + hL = 0.
(8.3.92)
We can simplify Equation 8.3.92 to
ǫ2
n + (2n −1)πǫn/2 + hL = 0,
(8.3.93)
because cot[(2n −1)π/2 −θ] = tan(θ), and tan(θ) ≈θ for θ ≪1. Solving for ǫn,
ǫn ≈−
2hL
(2n −1)π ,
(8.3.94)
and
αn ≈(2n −1)π
2
+
2hL
(2n −1)π .
(8.3.95)
In Table 8.3.1 we compare the approximate roots given by Equation 8.3.95 with the actual
roots.
The temporal part equals
Tn(t) = Cn exp
 −k2
na2t

= Cn exp

−α2
na2t
L2

.
(8.3.96)
Consequently, the general solution is
u(x, t) =
∞
X
n=1
Cn sin
αnx
L

exp

−α2
na2t
L2

,
(8.3.97)
5 Using the same technique, Stevens and Luck [Stevens, J. W., and R. Luck, 1999: Explicit approxima-
tions for all eigenvalues of the 1-D transient heat conduction equations. Heat Transfer Eng., 20(2), 35–41]
have found approximate solutions to ζn tan(ζn) = Bi. They showed that
ζn ≈zn + −B +
√
B2 −4C
2
,
where
B = zn + (1 + Bi) tan(zn),
C = Bi −zn tan(zn),
zn = cn + π
4
 Bi −cn
Bi + cn

,
cn =

n −3
4

π.

354
Advanced Engineering Mathematics with MATLAB
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0
20
40
60
80
100
120
DISTANCE
TIME
U(X,T)
Figure 8.3.5: The temperature u(x, t) within a thin bar as a function of position x/L and time a2t/L2
when we allow the bar to radiatively cool at x = L while the temperature is zero at x = 0. Initially the
temperature was 100.
where αn is the nth root of Equation 8.3.87.
To determine Cn, we use the initial condition, Equation 8.3.79, and ﬁnd that
100 =
∞
X
n=1
Cn sin
αnx
L

.
(8.3.98)
Equation 8.3.98 is an eigenfunction expansion of 100 employing the eigenfunctions from the
Sturm-Liouville problem
X′′ + k2X = 0,
(8.3.99)
and
X(0) = X′(L) + hX(L) = 0.
(8.3.100)
Thus, the coeﬃcient Cn is given by Equation 6.3.4 or
Cn =
R L
0 100 sin(αnx/L) dx
R L
0 sin2(αnx/L) dx
,
(8.3.101)
as r(x) = 1. Performing the integrations,
Cn =
100L[1 −cos(αn)]/αn
1
2[L −L sin(2αn)/(2αn)] =
200[1 −cos(αn)]
αn[1 + cos2(αn)/(hL)],
(8.3.102)
because sin(2αn) = 2 cos(αn) sin(αn), and αn = −hL tan(αn). The complete solution is
u(x, t) =
∞
X
n=1
200[1 −cos(αn)]
αn[1 + cos2(αn)/(hL)] sin
αnx
L

exp

−α2
na2t
L2

.
(8.3.103)
Figure 8.3.5 illustrates this solution for hL = 1 at various times and positions.
It was
generated using the MATLAB script

The Heat Equation
355
clear
hL = 1; M = 200; dx = 0.02; dt = 0.02;
% create initial guess at alpha n
zero = zeros(M,1);
for n = 1:M
temp = (2*n-1)*pi; zero(n) = 0.5*temp + 2*hL/temp;
end;
% use Newton-Raphson method to improve values of alpha n
for n = 1:M; for k = 1:10
f = zero(n) + hL * tan(zero(n)); fp =1 + hL * sec(zero(n))^2;
zero(n) = zero(n) - f / fp;
end; end;
% compute Fourier coefficients
for m = 1:M
a(m) = 200*(1-cos(zero(m)))/(zero(m)*(1+cos(zero(m))^2/hL));
end
% compute grid and initialize solution
X = [0:dx:1]; T = [0:dt:0.5];
u = zeros(length(T),length(X));
XX = repmat(X,[length(T) 1]);
TT = repmat(T’,[1 length(X)]);
% compute solution from Equation 8.3.103
for m = 1:M
u = u + a(m) * sin(zero(m)*XX) .* exp(-zero(m)*zero(m)*TT);
end
surf(XX,TT,u)
xlabel(’DISTANCE’,’Fontsize’,20); ylabel(’TIME’,’Fontsize’,20)
zlabel(’U(X,T)’,’Fontsize’,20)
It is similar to Example 8.3.1 in that the heat lost to the environment occurs either be-
cause the temperature at an end is zero or because it radiates heat to space that has the
temperature of zero.
⊓⊔
• Example 8.3.6: Refrigeration of apples
Some decades ago, shiploads of apples, going from Australia to England, deteriorated
from a disease called “brown heart,” which occurred under insuﬃcient cooling conditions.
Apples, when placed on shipboard, are usually warm and must be cooled to be carried in
cold storage. They also generate heat by their respiration. It was suspected that this heat
generation eﬀectively counteracted the refrigeration of the apples, resulting in the “brown
heart.”
This was the problem that induced Awberry6 to study the heat distribution within a
sphere in which heat is being generated. Awberry ﬁrst assumed that the apples are initially
at a uniform temperature. We can take this temperature to be zero by the appropriate
choice of temperature scale. At time t = 0, the skins of the apples assume the temperature
θ immediately when we introduce them into the hold.
6 Awberry, J. H., 1927: The ﬂow of heat in a body generating heat. Philos. Mag., Ser. 7, 4, 629–638.

356
Advanced Engineering Mathematics with MATLAB
Because of the spherical geometry, the nonhomogeneous heat equation becomes
1
a2
∂u
∂t = 1
r2
∂
∂r

r2 ∂u
∂r

+ G
κ ,
0 ≤r < b,
0 < t,
(8.3.104)
where a2 is the thermal diﬀusivity, b is the radius of the apple, κ is the thermal conductivity,
and G is the heating rate (per unit time per unit volume).
If we try to use separation of variables on Equation 8.3.104, we ﬁnd that it does not
work because of the G/κ term. To circumvent this diﬃculty, we ask the simpler question
of what happens after a very long time. We anticipate that a balance will eventually be
established where conduction transports the heat produced within the apple to the surface
of the apple where the surroundings absorb it. Consequently, just as we introduced a steady-
state solution in Example 8.3.3, we again anticipate a steady-state solution w(r) where the
heat conduction removes the heat generated within the apples. The ordinary diﬀerential
equation
1
r2
d
dr

r2 dw
dr

= −G
κ
(8.3.105)
gives the steady-state. Furthermore, just as we introduced a transient solution that allowed
our solution to satisfy the initial condition, we must also have one here, and the governing
equation is
∂v
∂t = a2
r2
∂
∂r

r2 ∂v
∂r

.
(8.3.106)
Solving Equation 8.3.106 ﬁrst,
w(r) = C + D
r −Gr2
6κ .
(8.3.107)
The constant D equals zero because the solution must be ﬁnite at r = 0. Since the steady-
state solution must satisfy the boundary condition w(b) = θ,
C = θ + Gb2
6κ .
(8.3.108)
Turning to the transient problem, we introduce a new dependent variable y(r, t) =
rv(r, t). This new dependent variable allows us to replace Equation 8.3.106 with
∂y
∂t = a2 ∂2y
∂r2 ,
(8.3.109)
which we can solve. If we assume that y(r, t) = R(r)T(t) and we only have a negative
separation constant, the R(r) equation becomes
d2R
dr2 + k2R = 0,
(8.3.110)
which has the solution
R(r) = A cos(kr) + B sin(kr).
(8.3.111)
The constant A equals zero because the solution, Equation 8.3.111, must vanish at r = 0
so that v(0, t) remains ﬁnite. However, because θ = w(b) + v(b, t) for all time and v(b, t) =
R(b)T(t)/b = 0, then R(b) = 0. Consequently, kn = nπ/b, and
vn(r, t) = Bn
r sin
nπr
b

exp

−n2π2a2t
b2

.
(8.3.112)

The Heat Equation
357
Superposition gives the total solution, which equals
u(r, t) = θ + G
6κ(b2 −r2) +
∞
X
n=1
Bn
r sin
nπr
b

exp

−n2π2a2t
b2

.
(8.3.113)
Finally, we determine the coeﬃcients Bn by the initial condition that u(r, 0) = 0.
Therefore,
Bn = −2
b
Z b
0
r

θ + G
6κ(b2 −r2)

sin
nπr
b

dr = 2θb
nπ (−1)n + 2G
κ
 b
nπ
3
(−1)n.
(8.3.114)
The complete solution is
u(r, t) = θ + 2θb
rπ
∞
X
n=1
(−1)n
n
sin
nπr
b

exp

−n2π2a2t
b2

(8.3.115)
+ G
6κ(b2 −r2) + 2Gb3
rκπ3
∞
X
n=1
(−1)n
n3
sin
nπr
b

exp

−n2π2a2t
b2

.
The ﬁrst line of Equation 8.3.115 gives the temperature distribution due to the imposition
of the temperature θ on the surface of the apple while the second line gives the rise in the
temperature due to the interior heating.
Returning to our original problem of whether the interior heating is strong enough to
counteract the cooling by refrigeration, we merely use the second line of Equation 8.3.115
to ﬁnd how much the temperature deviates from what we normally expect. Because the
highest temperature exists at the center of each apple, its value there is the only one of
interest in this problem. Assuming b = 4 cm as the radius of the apple, a2G/κ = 1.33×10−5
◦C/s, and a2 = 1.55 × 10−3 cm2/s, the temperature eﬀect of the heat generation is very
small, only 0.0232 ◦C when, after about 2 hours, the temperatures within the apples reach
equilibrium. Thus, we must conclude that heat generation within the apples is not the
cause of brown heart.
We now know that brown heart results from an excessive concentration of carbon diox-
ide and an insuﬃcient amount of oxygen in the storage hold.7 Presumably this atmosphere
aﬀects the metabolic activities that are occurring in the apple8 and leads to low-temperature
breakdown.
⊓⊔
• Example 8.3.7
In this example we illustrate how separation of variables can be employed in solving
the axisymmetric heat equation in an inﬁnitely long cylinder. In circular coordinates the
heat equation is
∂u
∂t = a2
∂2u
∂r2 + 1
r
∂u
∂r

,
0 ≤r < b,
0 < t,
(8.3.116)
7 Thornton, N. C., 1931: The eﬀect of carbon dioxide on fruits and vegetables in storage. Contrib.
Boyce Thompson Inst., 3, 219–244.
8 Fidler, J. C., and C. J. North, 1968: The eﬀect of conditions of storage on the respiration of apples.
IV. Changes in concentration of possible substrates of respiration, as related to production of carbon dioxide
and uptake of oxygen by apples at low temperatures. J. Hortic. Sci., 43, 429–439.

358
Advanced Engineering Mathematics with MATLAB
where r denotes the radial distance and a2 denotes the thermal diﬀusivity. Let us assume
that we heated this cylinder of radius b to the uniform temperature T0 and then allowed it
to cool by having its surface held at the temperature of zero starting from the time t = 0.
We begin by assuming that the solution is of the form u(r, t) = R(r)T(t) so that
1
R
d2R
dr2 + 1
r
dR
dr

=
1
a2T
dT
dt = −k2
b2 .
(8.3.117)
The only values of the separation constant that yield nontrivial solutions are negative. The
nontrivial solutions are R(r) = J0(kr/b), where J0 is the Bessel function of the ﬁrst kind
and zeroth order. A separation constant of zero gives R(r) = ln(r), which becomes inﬁnite
at the origin. Positive separation constants yield the modiﬁed Bessel function I0(kr/b).
Although this function is ﬁnite at the origin, it cannot satisfy the boundary condition that
u(b, t) = R(b)T(t) = 0, or R(b) = 0.
The boundary condition that R(b) = 0 requires that J0(k) = 0. This transcendental
equation yields an inﬁnite number of constants kn. For each kn, the temporal part of the
solution satisﬁes the diﬀerential equation
dTn
dt + k2
na2
b2 Tn = 0,
(8.3.118)
which has the solution
Tn(t) = An exp

−k2
na2
b2 t

.
(8.3.119)
Consequently, the product solutions are
un(r, t) = AnJ0

kn
r
b

exp

−k2
na2
b2 t

.
(8.3.120)
The total solution is a linear superposition of all of the particular solutions or
u(r, t) =
∞
X
n=1
AnJ0

kn
r
b

exp

−k2
na2
b2 t

.
(8.3.121)
Our ﬁnal task remains to determine An. From the initial condition that u(r, 0) = T0,
u(r, 0) = T0 =
∞
X
n=1
AnJ0

kn
r
b

.
(8.3.122)
From Equation 6.5.38 and Equation 6.5.45,
An =
2T0
J2
1(kn)b2
Z b
0
rJ0

kn
r
b

dr =
2T0
k2nJ2
1(kn)
knr
b

J1

kn
r
b

b
0 =
2T0
knJ1(kn)
(8.3.123)
from Equation 6.5.28. Thus, the complete solution is
u(r, t) = 2T0
∞
X
n=1
1
knJ1(kn)J0

kn
r
b

exp

−k2
na2
b2 t

.
(8.3.124)

The Heat Equation
359
0
0.5
1
0
0.2
0.4
0.60
0.2
0.4
0.6
0.8
1
1.2
R
TIME
SOLUTION
Figure 8.3.6: The temperature u(r, t)/T0 within an inﬁnitely long cylinder at various positions r/b and
times a2t/b2 that we initially heated to the uniform temperature T0 and then allowed to cool by forcing its
surface to equal zero.
Figure 8.3.6 illustrates the solution, Equation 8.3.124, for various Fourier numbers a2t/b2.
It was generated using the MATLAB script
clear
M = 20; dr = 0.02; dt = 0.02;
% load in zeros of J 0
zero( 1) =
2.40482; zero( 2) =
5.52007; zero( 3) =
8.65372;
zero( 4) = 11.79153; zero( 5) = 14.93091; zero( 6) = 18.07106;
zero( 7) = 21.21164; zero( 8) = 24.35247; zero( 9) = 27.49347;
zero(10) = 30.63461; zero(11) = 33.77582; zero(12) = 36.91710;
zero(13) = 40.05843; zero(14) = 43.19979; zero(15) = 46.34119;
zero(16) = 49.48261; zero(17) = 52.62405; zero(18) = 55.76551;
zero(19) = 58.90698; zero(20) = 62.04847;
% compute Fourier coefficients
for m = 1:M
a(m) = 2 / (zero(m)*besselj(1,zero(m)));
end
% compute grid and initialize solution
R = [0:dr:1]; T = [0:dt:0.5];
u = zeros(length(T),length(R));
RR = repmat(R,[length(T) 1]);
TT = repmat(T’,[1 length(R)]);
% compute solution from Equation 8.3.124
for m = 1:M
u = u + a(m)*besselj(0,zero(m)*RR).*exp(-zero(m)*zero(m)*TT);
end
surf(RR,TT,u)
xlabel(’R’,’Fontsize’,20); ylabel(’TIME’,’Fontsize’,20)
zlabel(’SOLUTION’,’Fontsize’,20)

360
Advanced Engineering Mathematics with MATLAB
It is similar to Example 8.3.1 except that we are in cylindrical coordinates. Heat ﬂows from
the interior and is removed at the cylinder’s surface where the temperature equals zero. The
initial oscillations of the solution result from Gibbs phenomena because we have a jump in
the temperature ﬁeld at r = b.
⊓⊔
• Example 8.3.8
In this example9 we ﬁnd the evolution of the temperature ﬁeld within a cylinder of
radius b as it radiatively cools from an initial uniform temperature T0. The heat equation
is
∂u
∂t = a2
∂2u
∂r2 + 1
r
∂u
∂r

,
0 ≤r < b,
0 < t,
(8.3.125)
which we will solve by separation of variables u(r, t) = R(r)T(t). Therefore,
1
R
d2R
dr2 + 1
r
dR
dr

=
1
a2T
dT
dt = −k2
b2 ,
(8.3.126)
because only a negative separation constant yields an R(r) that is ﬁnite at the origin and
satisﬁes the boundary condition. This solution is R(r) = J0(kr/b), where J0 is the Bessel
function of the ﬁrst kind and zeroth order.
The radiative boundary condition can be expressed as
∂u(b, t)
∂r
+ hu(b, t) = T(t)
dR(b)
dr
+ hR(b)

= 0.
(8.3.127)
Because T(t) ̸= 0,
kJ′
0(k) + hbJ0(k) = −kJ1(k) + hbJ0(k) = 0,
(8.3.128)
where the product hb is the Biot number. The solution of the transcendental equation,
Equation 8.3.128, yields an inﬁnite number of distinct constants kn.
For each kn, the
temporal part equals the solution of
dTn
dt + k2
na2
b2 Tn = 0,
(8.3.129)
or
Tn(t) = An exp

−k2
na2
b2 t

.
(8.3.130)
The product solution is, therefore,
un(r, t) = AnJ0

kn
r
b

exp

−k2
na2
b2 t

(8.3.131)
and the most general solution is a sum of these product solutions
u(r, t) =
∞
X
n=1
AnJ0

kn
r
b

exp

−k2
na2
b2 t

.
(8.3.132)
9 For another example of solving the heat equation with Robin boundary conditions, see Section 3.2 in
Balakotaiah, V., N. Gupta, and D. H. West, 2000: A simpliﬁed model for analyzing catalytic reactions in
short monoliths. Chem. Eng. Sci., 55, 5367–5383.

The Heat Equation
361
0
0.5
1
0
0.2
0.4
0.6
0.2
0.4
0.6
0.8
1
R
TIME
SOLUTION
Figure 8.3.7: The temperature u(r, t)/T0 within an inﬁnitely long cylinder at various positions r/b and
times a2t/b2 that we initially heated to the temperature T0 and then allowed to radiatively cool with hb = 1.
Finally, we must determine An. From the initial condition that u(r, 0) = T0,
u(r, 0) = T0 =
∞
X
n=1
AnJ0

kn
r
b

,
(8.3.133)
where
An =
2k2
nT0
b2[k2n + b2h2]J2
0(kn)
Z b
0
rJ0

kn
r
b

dr =
2T0
[k2n + b2h2]J2
0(kn)
knr
b

J1

kn
r
b

b
0
(8.3.134)
=
2knT0J1(kn)
[k2n + b2h2]J2
0(kn) =
2knT0J1(kn)
k2nJ2
0(kn) + b2h2J2
0(kn) =
2knT0J1(kn)
k2nJ2
0(kn) + k2nJ2
1(kn)
(8.3.135)
=
2T0J1(kn)
kn[J2
0(kn) + J2
1(kn)],
(8.3.136)
which follows from Equation 6.5.28, Equation 6.5.38, Equation 6.5.45, and Equation 8.3.128.
Consequently, the complete solution is
u(r, t) = 2T0
∞
X
n=1
J1(kn)
kn[J2
0(kn) + J2
1(kn)]J0

kn
r
b

exp

−k2
na2
b2 t

.
(8.3.137)
Figure 8.3.7 illustrates the solution, Equation 8.3.137, for various Fourier numbers
a2t/b2 with hb = 1. It was created using the MATLAB script
clear
hb = 1; m=0; M = 100; dr = 0.02; dt = 0.02;
% find k n which satisfies hb J 0(k) = k J 1(k)
for n = 1:10000

362
Advanced Engineering Mathematics with MATLAB
k1 = 0.05*n; k2 = 0.05*(n+1);
y1 = hb * besselj(0,k1) - k1 * besselj(1,k1);
y2 = hb * besselj(0,k2) - k2 * besselj(1,k2);
if y1*y2 <= 0; m = m+1; zero(m) = k1; end;
end;
% use Newton-Raphson method to improve values of k n
for n = 1:M; for k = 1:5
term0 = besselj(0,zero(n));
term1 = besselj(1,zero(n));
term2 = besselj(2,zero(n));
f = hb * term0 - zero(n) * term1;
fp = 0.5*zero(n)*(term2-term0) - (1+hb)*term1;
zero(n) = zero(n) - f / fp;
end; end;
% compute Fourier coefficients
for m = 1:M
denom = zero(m)*(besselj(0,zero(m))^2+besselj(1,zero(m))^2);
a(m) = 2 * besselj(1,zero(m)) / denom;
end
% compute grid and initialize solution
R = [0:dr:1]; T = [0:dt:0.5];
u = zeros(length(T),length(R));
RR = repmat(R,[length(T) 1]);
TT = repmat(T’,[1 length(R)]);
% compute solution from Equation 8.3.137
for m = 1:M
u = u + a(m)*besselj(0,zero(m)*RR).*exp(-zero(m)*zero(m)*TT);
end
surf(RR,TT,u)
xlabel(’R’,’Fontsize’,20); ylabel(’TIME’,’Fontsize’,20)
zlabel(’SOLUTION’,’Fontsize’,20)
These results are similar to Example 8.3.5 except that we are in cylindrical coordinates.
Heat ﬂows from the interior and is removed at the cylinder’s surface where it radiates to
space at the temperature zero. Note that we do not suﬀer from Gibbs phenomena in this
case because there is no initial jump in the temperature distribution.
⊓⊔
• Example 8.3.9: Temperature within an electrical cable
In the design of cable installations we need the temperature reached within an elec-
trical cable as a function of current and other parameters.
To this end,10 let us solve
the nonhomogeneous heat equation in cylindrical coordinates with a radiation boundary
condition.
The derivation of the heat equation follows from the conservation of energy:
heat generated = heat dissipated + heat stored,
10 Iskenderian, H. P., and W. J. Horvath, 1946: Determination of the temperature rise and the maximum
safe current through multiconductor electric cables. J. Appl. Phys., 17, 255–262.

The Heat Equation
363
or
I2RN dt = −κ

2πr ∂u
∂r

r
−2π(r + ∆r) ∂u
∂r

r+∆r

dt + 2πr∆rcρ du,
(8.3.138)
where I is the current through each wire, R is the resistance of each conductor, N is the
number of conductors in the shell between radii r and r + ∆r = 2πmr∆r/(πb2), b is the
radius of the cable, m is the total number of conductors in the cable, κ is the thermal
conductivity, ρ is the density, c is the average speciﬁc heat, and u is the temperature. In
the limit of ∆r →0, Equation 8.3.138 becomes
∂u
∂t = A + a2
r
∂
∂r

r∂u
∂r

,
0 ≤r < b,
0 < t,
(8.3.139)
where A = I2Rm/(πb2cρ), and a2 = κ/(ρc).
Equation 8.3.139 is the nonhomogeneous heat equation for an inﬁnitely long, axisym-
metric cylinder. From Example 8.3.3, we know that we must write the temperature as the
sum of a steady-state and transient solution: u(r, t) = w(r) + v(r, t). The steady-state
solution w(r) satisﬁes
1
r
d
dr

rdw
dr

= −A
a2 ,
(8.3.140)
or
w(r) = Tc −Ar2
4a2 ,
(8.3.141)
where Tc is the (yet unknown) temperature in the center of the cable.
The transient solution v(r, t) is governed by
∂v
∂t = a2 1
r
∂
∂r

r∂v
∂r

,
0 ≤r < b,
0 < t,
(8.3.142)
with the initial condition that u(r, 0) = Tc −Ar2/(4a2) + v(0, t) = 0. At the surface r = b,
heat radiates to free space so that the boundary condition is ur = −hu, where h is the
surface conductance. Because the temperature equals the steady-state solution when all
transient eﬀects die away, w(r) must satisfy this radiation boundary condition regardless of
the transient solution. This requires that
Tc = A
a2
b2
4 + b
2h

.
(8.3.143)
Therefore, v(r, t) must satisfy vr(b, t) = −hv(b, t) at r = b.
We ﬁnd the transient solution v(r, t) by separation of variables v(r, t) = R(r)T(t).
Substituting into Equation 8.3.142,
1
rR
d
dr

rdR
dr

=
1
a2T
dT
dt = −k2,
(8.3.144)
or
d
dr

rdR
dr

+ k2rR = 0,
(8.3.145)
and
dT
dt + k2a2T = 0,
(8.3.146)

364
Advanced Engineering Mathematics with MATLAB
with R′(b) = −hR(b). The only solution of Equation 8.3.145 that remains ﬁnite at r = 0 and
satisﬁes the boundary condition is R(r) = J0(kr), where J0 is the zero-order Bessel function
of the ﬁrst kind.
Substituting J0(kr) into the boundary condition, the transcendental
equation is
kbJ1(kb) −hbJ0(kb) = 0.
(8.3.147)
For a given value of h and b, Equation 8.3.147 yields an inﬁnite number of unique zeros kn.
The corresponding temporal solution to the problem is
Tn(t) = An exp(−a2k2
nt),
(8.3.148)
so that the sum of the product solutions is
v(r, t) =
∞
X
n=1
AnJ0(knr) exp(−a2k2
nt).
(8.3.149)
Our ﬁnal task remains to compute An. By evaluating Equation 8.3.149 at t = 0,
v(r, 0) = Ar2
4a2 −Tc =
∞
X
n=1
AnJ0(knr),
(8.3.150)
which is a Fourier-Bessel series in J0(knr). In Section 6.5 we showed how to compute the
coeﬃcient of a Fourier-Bessel series that is expanded in J0(knr) and that has a boundary
condition of the form given Equation 8.3.147. Applying those results here, we have that
An =
2k2
n
(k2nb2 + h2b2)J2
0(knb)
Z b
0
r
Ar2
4a2 −Tc

J0(knr) dr
(8.3.151)
from Equation 6.5.38 and Equation 6.5.47. Carrying out the indicated integrations,
An =
2
(k2n + h2)J2
0(knb)
Aknb
4a2 −
A
knba2 −Tckn
b

J1(knb) + A
2a2 J0(knb)

.
(8.3.152)
We obtained Equation 8.3.152 by using Equation 6.5.28 and integrating by parts as shown
in Example 6.5.5.
To illustrate this solution, let us compute it for the typical parameters b = 4 cm, hb = 1,
a2 = 1.14 cm2/s, A = 2.2747 ◦C/s, and Tc = 23.94◦C. The value of A corresponds to 37
wires of #6 AWG copper wire within a cable carrying a current of 22 amp.
Figure 8.3.8 illustrates the solution as a function of radius at various times. It was
created using the MATLAB script
clear
asq = 1.14; A = 2.2747; b = 4; dr = 0.02; dt = 0.02;
hb = 1; m=0; M = 10; T c = 23.94;
const1 = A * b * b / (4 * asq); const2 = A * b * b / asq;
const3 = A * b * b / (2 * asq);
% find k nb which satisfies hb J 0(kb) = kb J 1(kb)
for n = 1:10000
k1 = 0.05*n; k2 = 0.05*(n+1);
y1 = hb * besselj(0,k1) - k1 * besselj(1,k1);
y2 = hb * besselj(0,k2) - k2 * besselj(1,k2);

The Heat Equation
365
0
0.5
1
0
1
2
0
5
10
15
20
25
TIME
R
TEMPERATURE,° C
Figure 8.3.8: The temperature ﬁeld (in degrees Celsius) within an electric copper cable containing 37
wires and a current of 22 amperes at various positions r/b and times a2t/b2. Initially the temperature was
zero and then we allow the cable to cool radiatively as it is heated. The parameters are hb = 1 and the
radius of the cable b = 4 cm.
if y1*y2 <= 0; m = m+1; zero(m) = k1; end;
end;
% use Newton-Raphson method to improve values of k n
for n = 1:M; for k = 1:5
term0 = besselj(0,zero(n));
term1 = besselj(1,zero(n));
term2 = besselj(2,zero(n));
f = hb * term0 - zero(n) * term1;
fp = 0.5*zero(n)*(term2-term0) - (1+hb)*term1;
zero(n) = zero(n) - f / fp;
end; end;
for m = 1:M
denom = (zero(m)*zero(m)+hb*hb)*besselj(0,zero(m))^2;
a(m) = ((const1-T c)*zero(m) ...
- const2/zero(m))*besselj(1,zero(m)) ...
+ const3 * besselj(0,zero(m));
a(m) = 2 * a(m) / denom;
end
% compute grid and initialize solution
R = [0:dr:1]; T = [0:dt:2];
u = T c * ones(length(T),length(R));
RR = repmat(R,[length(T) 1]);
TT = repmat(T’,[1 length(R)]);
% compute solution u(r,t) = w(r) + v(r,t)
u = u - const1 * RR .* RR;
for m = 1:M
u = u + a(m)*besselj(0,zero(m)*RR).*exp(-zero(m)*zero(m)*TT);
end

366
Advanced Engineering Mathematics with MATLAB
surf(RR,TT,u); axis([0 1 0 2 0 25]);
xlabel(’R’,’Fontsize’,20); ylabel(’TIME’,’Fontsize’,20)
zlabel(’TEMPERATURE,^\circ C’,’Fontsize’,20)
From an initial temperature of zero, the temperature rises due to the constant electrical
heating.
After a short period of time, it reaches its steady-state distribution given by
Equation 8.3.140. The cable is coolest at the surface where heat is radiating away. Heat
ﬂows from the interior to replace the heat lost by radiation.
Problems
For Problems 1–5, solve the heat equation ut = a2uxx, 0 < x < π, 0 < t, subject to the
boundary conditions that u(0, t) = u(π, t) = 0, 0 < t, and the following initial conditions
for 0 < x < π. Then plot your results using MATLAB.
1. u(x, 0) = A, a constant
2. u(x, 0) = sin3(x) = [3 sin(x) −sin(3x)]/4
3. u(x, 0) = x
4. u(x, 0) = π −x
5. u(x, 0) =

x,
0 < x < π/2,
π −x,
π/2 < x < π.
For Problems 6–10, solve the heat equation ut = a2uxx, 0 < x < π, 0 < t, subject to the
boundary conditions that ux(0, t) = ux(π, t) = 0, 0 < t, and the following initial conditions
for 0 < x < π. Then plot your results using MATLAB.
6. u(x, 0) = 1
7. u(x, 0) = x
8. u(x, 0) = cos2(x) = [1 + cos(2x)]/2
9. u(x, 0) = π −x
10. u(x, 0) =

T0,
0 < x < π/2,
T1,
π/2 < x < π.
For Problems 11–17, solve the heat equation ut = a2uxx, 0 < x < π, 0 < t, subject to the
following boundary conditions and initial condition. Then plot your results using MATLAB.
11. ux(0, t) = u(π, t) = 0, 0 < t; u(x, 0) = x2 −π2, 0 < x < π
12. u(0, t) = u(π, t) = T0, 0 < t; u(x, 0) = T1 ̸= T0, 0 < x < π
13. u(0, t) = 0, ux(π, t) = 0, 0 < t; u(x, 0) = 1, 0 < x < π
14. u(0, t) = 0, ux(π, t) = 0, 0 < t; u(x, 0) = x, 0 < x < π

The Heat Equation
367
15. u(0, t) = 0, ux(π, t) = 0, 0 < t; u(x, 0) = π −x, 0 < x < π
16. u(0, t) = T0, ux(π, t) = 0, 0 < t; u(x, 0) = T1 ̸= T0, 0 < x < π
17. u(0, t) = 0, u(π, t) = T0, 0 < t; u(x, 0) = T0, 0 < x < π
18. It is well known that a room with masonry walls is often very diﬃcult to heat. Consider
a wall of thickness L, conductivity κ, and diﬀusivity a2, which we heat by a surface heat
ﬂux at a constant rate H. The temperature of the outside (out-of-doors) face of the wall
remains constant at T0 and the entire wall initially has the uniform temperature T0. Let us
ﬁnd the temperature of the inside face as a function of time.11
We begin by solving the heat conduction problem
∂u
∂t = a2 ∂2u
∂x2 ,
0 < x < L,
0 < t,
subject to the boundary conditions that
∂u(0, t)
∂x
= −H
κ ,
and
u(L, t) = T0,
and the initial condition that u(x, 0) = T0. Show that the temperature ﬁeld equals
u(x, t) = T0 + HL
κ

1 −x
L −8
π2
∞
X
n=1
1
(2n −1)2 cos
(2n −1)πx
2L

exp

−(2n −1)2π2a2t
4L2

.
Therefore, the rise of temperature at the interior wall x = 0 is
HL
κ

1 −8
π2
∞
X
n=1
1
(2n −1)2 exp

−(2n −1)2π2a2t
4L2

,
or
8HL
κπ2
∞
X
n=1
1
(2n −1)2

1 −exp

−(2n −1)2π2a2t
4L2

.
For a2t/L2 ≤1, this last expression can be approximated12 by 2Hat1/2/ π1/2κ. We thus
see that the temperature will initially rise as the square root of time and diﬀusivity and
11 See Dufton, A. F., 1927: The warming of walls. Philos. Mag., Ser. 7, 4, 888–889.
12 Let us deﬁne the function:
f(t) =
∞
X
n=1
1 −exp[−(2n −1)2π2a2t/L2]
(2n −1)2
.
Then
f′(t) = a2π2
L2
∞
X
n=1
exp[−(2n −1)2π2a2t/L2].
Consider now the integral
Z ∞
0
exp

−a2π2t
L2
x2

dx =
L
2a
√
πt
.
If we approximate this integral by using the trapezoidal rule with ∆x = 2, then
Z ∞
0
exp

−a2π2t
L2
x2

dx ≈2
∞
X
n=1
exp[−(2n −1)2π2a2t/L2],
and f′(t) ≈aπ3/2/(4Lt1/2). Integrating and using f(0) = 0, we ﬁnally have f(t) ≈aπ3/2t1/2/(2L). The
smaller a2t/L2 is, the smaller the error will be. For example, if t = L2/a2, then the error is 2.4%.

368
Advanced Engineering Mathematics with MATLAB
inversely with conductivity. For an average rock, κ = 0.0042 g/cm-s, and a2 = 0.0118
cm2/s, while for wood (spruce) κ = 0.0003 g/cm-s, and a2 = 0.0024 cm2/s.
The same set of equations applies to heat transfer within a transistor operating at low
frequencies.13 At the junction (x = 0) heat is produced at the rate of H and ﬂows to the
transistor’s supports (x = ±L) where it is removed. The supports are maintained at the
temperature T0, which is also the initial temperature of the transistor.
19. The linearized Boussinesq equation14
∂u
∂t = ∂2u
∂x2 ,
0 < x < L,
0 < t,
governs the height of the water table u(x, t) above some reference point, where a2 is the
product of the storage coeﬃcient times the hydraulic coeﬃcient divided by the aquifer
thickness. A typical value of a2 is 10 m2/min. Consider the problem of a strip of land of
width L that separates two reservoirs of depth h1. Initially the height of the water table
would be h1. Suddenly we lower the reservoir on the right x = L to a depth h2 [u(0, t) = h1,
u(L, t) = h2, and u(x, 0) = h1]. Find the height of the water table at any position x within
the aquifer and any time t > 0.
20. The equation (see Problem 19)
∂u
∂t = ∂2u
∂x2 ,
0 < x < L,
0 < t,
governs the height of the water table u(x, t). Consider the problem15 of a piece of land that
suddenly has two drains placed at the points x = 0 and x = L so that u(0, t) = u(L, t) = 0.
If the water table initially has the proﬁle u(x, 0) = 8H(L3x −3L2x2 + 4Lx3 −2x4)/L4, ﬁnd
the height of the water table at any point within the aquifer and any time t > 0.
21. We want to ﬁnd the rise of the water table of an aquifer, which we sandwich between a
canal and impervious rocks if we suddenly raise the water level in the canal h0 units above
its initial elevation and then maintain the canal at this level. The linearized Boussinesq
equation (see Problem 19)
∂u
∂t = ∂2u
∂x2 ,
0 < x < L,
0 < t,
governs the level of the water table with the boundary conditions u(0, t) = h0, and ux(L, t) =
0, and the initial condition u(x, 0) = 0. Find the height of the water table at any point in
the aquifer and any time t > 0.
22. Solve the nonhomogeneous heat equation
∂u
∂t −a2 ∂2u
∂x2 = e−x,
0 < x < π,
0 < t,
13 Mortenson, K. E., 1957: Transistor junction temperature as a function of time.
Proc.
IRE, 45,
504–513. Equation 2a should read Tx = −F/k.
14 See, for example, Van Schilfgaarde, J., 1970: Theory of ﬂow to drains. Advances in Hydroscience, No.
6, Academic Press, 81–85.
15 For a similar problem, see Dumm, L. D., 1954: New formula for determining depth and spacing of
subsurface drains in irrigated lands. Agric. Eng., 35, 726–730.

The Heat Equation
369
subject to the boundary conditions u(0, t) = ux(π, t) = 0, 0 < t, and the initial condition
u(x, 0) = f(x), 0 < x < π.
23. Solve the nonhomogeneous heat equation
∂u
∂t −∂2u
∂x2 = −1,
0 < x < 1,
0 < t,
subject to the boundary conditions ux(0, t) = ux(1, t) = 0, 0 < t, and the initial condition
u(x, 0) = 1
2(1 −x2), 0 < x < 1. Hint: Note that any function of time satisﬁes the boundary
conditions.
24. Solve the nonhomogeneous heat equation
∂u
∂t −a2 ∂2u
∂x2 = A cos(ωt),
0 < x < π,
0 < t,
subject to the boundary conditions ux(0, t) = ux(π, t) = 0, 0 < t, and the initial condition
u(x, 0) = f(x), 0 < x < π. Hint: Note that any function of time satisﬁes the boundary
conditions.
25. Solve the nonhomogeneous heat equation
∂u
∂t −∂2u
∂x2 =

x,
0 < x ≤π/2,
π −x,
π/2 ≤x < π,
0 < x < π,
0 < t,
subject to the boundary conditions u(0, t) = u(π, t) = 0, 0 < t, and the initial condition
u(x, 0) = 0, 0 < x < π. Hint: Represent the forcing function as a half-range Fourier sine
expansion over the interval (0, π).
26. A uniform conducting rod of length L and thermometric diﬀusivity a2 is initially at
temperature zero. We supply heat uniformly throughout the rod so that the heat conduction
equation is
a2 ∂2u
∂x2 = ∂u
∂t −P,
0 < x < L,
0 < t,
where P is the rate at which the temperature would rise if there was no conduction. If
we maintain the ends of the rod at the temperature of zero, ﬁnd the temperature at any
position and subsequent time. How would the solution change if the boundary conditions
became u(0, t) = u(L, t) = A ̸= 0, 0 < t, and the initial conditions read u(x, 0) = A,
0 < x < L?
27. Solve the nonhomogeneous heat equation
∂u
∂t = a2 ∂2u
∂x2 + A0
cρ ,
0 < x < L,
0 < t,
where a2 = κ/cρ, with the boundary conditions that
∂u(0, t)
∂x
= 0,
κ∂u(L, t)
∂x
+ hu(L, t) = 0,
0 < t,
and the initial condition that u(x, 0) = 0, 0 < x < L.

370
Advanced Engineering Mathematics with MATLAB
28. Find the solution of
∂u
∂t = ∂2u
∂x2 −u,
0 < x < L,
0 < t,
with the boundary conditions u(0, t) = 1, and u(L, t) = 0, 0 < t, and the initial condition
u(x, 0) = 0, 0 < x < L.
29. Solve16
∂u
∂t + k1u = ∂2u
∂x2 ,
0 < x < L,
0 < t,
with the boundary conditions
∂u(0, t)
∂x
= 0,
a2 ∂u(L, t)
∂x
+ k2u(L, t) = 0,
0 < t,
and the initial condition u(x, 0) = u0, 0 < x < L.
30. Solve
∂u
∂t + ∂u
∂x = a2 ∂2u
∂x2 ,
0 < x < 1,
0 < t,
with the boundary conditions
a2 ∂u(0, t)
∂x
= u(0, t),
∂u(1, t)
∂x
= 0,
0 < t,
and the initial condition u(x, 0) = 1, 0 < x < 1. Hint: Let u(x, t) = v(x, t) exp[(2x −
t)/(4a2)] so that the problem becomes
∂v
∂t = a2 ∂2v
∂x2 ,
0 < x < 1,
0 < t,
with the boundary conditions
2a2 ∂v(0, t)
∂x
= v(0, t),
2a2 ∂v(1, t)
∂x
= −v(1, t),
0 < t,
and the initial condition v(x, 0) = exp[−x/(2a2)], 0 < x < 1.
31. Solve the heat equation in spherical coordinates
∂u
∂t = a2
r2
∂
∂r

r2 ∂u
∂r

= a2
r
∂2(ru)
∂r2
,
0 ≤r < 1,
0 < t,
subject to the boundary conditions limr→0 |u(r, t)| < ∞, and u(1, t) = 0, 0 < t, and the
initial condition u(r, 0) = 1, 0 ≤r < 1.
32. Solve the heat equation in spherical coordinates
∂u
∂t = a2
r2
∂
∂r

r2 ∂u
∂r

= a2
r
∂2(ru)
∂r2
,
α < r < β,
0 < t,
16 Motivated by problems solved in Gomer, R., 1951: Wall reactions and diﬀusion in static and ﬂow
systems. J. Chem. Phys., 19, 284–289.

The Heat Equation
371
subject to the boundary conditions u(α, t) = ur(β, t) = 0, 0 < t, and the initial condition
u(r, 0) = u0, α < r < β.
33. Solve17 the heat equation in spherical coordinates
∂u
∂t = a2
∂2u
∂r2 + 2
r
∂u
∂r

= a2
r
∂2(ru)
∂r2
,
0 ≤r < b,
0 < t,
subject to the boundary conditions
lim
r→0
∂u(r, t)
∂r
→0,
and
∂u(b, t)
∂r
= −A
b u(b, t),
0 < t,
and the initial condition u(r, 0) = u0, 0 ≤r < b.
34. Solve18 the heat equation in cylindrical coordinates
∂u
∂t = a2
∂2u
∂r2 + 1
r
∂u
∂r

,
0 ≤r < b,
0 < t,
subject to the boundary conditions limr→0 |u(r, t)| < ∞, and u(b, t) = u0, 0 < t, and the
initial condition u(r, 0) = 0, 0 ≤r < b.
35. Solve the heat equation in cylindrical coordinates
∂u
∂t = a2
r
∂
∂r

r∂u
∂r

,
0 ≤r < b,
0 < t,
subject to the boundary conditions limr→0 |u(r, t)| < ∞, and u(b, t) = θ, 0 < t, and the
initial condition u(r, 0) = 1, 0 ≤r < b.
36. Solve the heat equation in cylindrical coordinates
∂u
∂t = a2
r
∂
∂r

r∂u
∂r

,
0 ≤r < 1,
0 < t,
subject to the boundary conditions limr→0 |u(r, t)| < ∞, and u(1, t) = 0, 0 < t, and the
initial condition
u(x, 0) =

A,
0 ≤r < b,
B,
b < r < 1.
37. The equation19
∂u
∂t = G
ρ + ν
∂2u
∂r2 + 1
r
∂u
∂r

,
0 ≤r < b,
0 < t,
17 Zhou, H., S. Abanades, G. Flamant, D. Gauthier, and J. Lu, 2002: Simulation of heavy metal vapor-
ization dynamics of a ﬂuidized bed. Chem. Eng. Sci., 57, 2603–2614. See also Mantell, C., M. Rodriguez,
and E. Martinez de la Ossa, 2002: Semi-batch extraction of anthocyanins from red grape pomace in packed
beds: Experimental results and process modelling. Chem. Eng. Sci., 57, 3831–3838.
18 See Destriau, G., 1946: Propagation des charges ´electriques sur les pellicules faiblement conductrices
“probl`em plan.” J. Phys. Radium, 7, 43–48.
19 See Szymanski, P., 1932: Quelques solutions exactes des ´equations de l’hydrodynamique du ﬂuide
visqueux dans le cas d’un tube cylindrique. J. Math. Pures Appl., Ser. 9, 11, 67–107.

372
Advanced Engineering Mathematics with MATLAB
governs the velocity u(r, t) of an incompressible ﬂuid of density ρ and kinematic viscosity
ν ﬂowing in a long circular pipe of radius b with an imposed, constant pressure gradient
−G. If the ﬂuid is initially at rest, u(r, 0) = 0, 0 ≤r < b, and there is no slip at the wall
u(b, t) = 0, 0 < t, ﬁnd the velocity at any subsequent time and position.
38. Solve the heat equation in cylindrical coordinates
∂u
∂t = a2
r
∂
∂r

r∂u
∂r

,
0 ≤r < b,
0 < t,
subject to the boundary conditions limr→0 |u(r, t)| < ∞, and ur(b, t) = −h u(b, t), 0 < t,
and the initial condition u(r, 0) = b2 −r2, 0 ≤r < b.
39. Solve20 the heat equation in cylindrical coordinates
∂u
∂t = a2
∂2u
∂r2 + 1
r
∂u
∂r

−κu,
0 ≤r < L,
0 < t,
subject to the boundary conditions limr→0 |u(r, t)| < ∞, and ur(L, t) = −hu(L, t), 0 < t,
and the initial condition
u(r, 0) =

0,
0 ≤r < b,
T0,
b < r ≤L,
where b < L, and 0 < h, κ.
40. In their study of heat conduction within a thermocouple through which a steady current
ﬂows, Reich and Madigan21 solved the following nonhomogeneous heat conduction problem:
∂u
∂t −a2 ∂2u
∂x2 = J −P δ(x −b),
0 < x < L,
0 < t,
0 < b < L,
where J represents the Joule heating generated by the steady current and the P term
represents the heat loss from Peltier cooling.22 Find u(x, t) if both ends are kept at zero
[u(0, t) = u(L, t) = 0] and initially the temperature is zero [u(x, 0) = 0]. The interesting
aspect of this problem is the presence of the delta function.
Step 1: Assuming that u(x, t) equals the sum of a steady-state solution w(x) and a transient
solution v(x, t), show that the steady-state solution is governed by
a2 d2w
dx2 = P δ(x −b) −J,
w(0) = w(L) = 0.
Step 2: Show that the steady-state solution is
w(x) =

Jx(L −x)/2a2 + Ax,
0 < x < b,
Jx(L −x)/2a2 + B(L −x),
b < x < L.
20 Mack, W., M. Pl¨ochl, and U. Gamer, 2000: Eﬀects of a temperature cycle on an elastic-plastic shrink
ﬁt with solid inclusion. Chinese J. Mech., 16, 23–30.
21 Reich, A. D., and J. R. Madigan, 1961: Transient response of a thermocouple circuit under steady
currents. J. Appl. Phys., 32, 294–301.
22 In 1834 Jean Charles Athanase Peltier (1785–1845) discovered that there is a heating or cooling
eﬀect, quite apart from ordinary resistance heating, whenever an electric current ﬂows through the junction
between two diﬀerent metals.

The Heat Equation
373
Step 3: The temperature must be continuous at x = b; otherwise, we would have inﬁnite
heat conduction there. Use this condition to show that Ab = B(L −b).
Step 4: To ﬁnd a second relationship between A and B, integrate the steady-state diﬀer-
ential equation across the interface at x = b and show that
lim
ǫ→0 a2 dw
dx

b+ǫ
b−ǫ
= P.
Step 5: Using the result from Step 4, show that A + B = −P/a2, and
w(x) =

Jx(L −x)/2a2 −Px(L −b)/a2L,
0 < x < b,
Jx(L −x)/2a2 −Pb(L −x)/a2L,
b < x < L.
Step 6: Re-express w(x) as a half-range Fourier sine expansion and show that
w(x) = 4JL2
a2π3
∞
X
m=1
sin[(2m −1)πx/L]
(2m −1)3
−2LP
a2π2
∞
X
n=1
sin(nπb/L) sin(nπx/L)
n2
.
Step 7: Use separation of variables to ﬁnd the transient solution by solving
∂v
∂t = a2 ∂2v
∂x2 ,
0 < x < L,
0 < t,
subject to the boundary conditions v(0, t) = v(L, t) = 0, 0 < t, and the initial condition
v(x, 0) = −w(x), 0 < x < L.
Step 8: Add the steady-state and transient solutions together and show that
u(x, t) = 4JL2
a2π3
∞
X
m=1
sin[(2m −1)πx/L]
(2m −1)3
h
1 −e−a2(2m−1)2π2t/L2i
−2LP
a2π2
∞
X
n=1
sin(nπb/L) sin(nπx/L)
n2
h
1 −e−a2n2π2t/L2i
.
41. Use separation of variables to solve23 the partial diﬀerential equation
∂u
∂t = ∂2u
∂x2 + 2a∂u
∂x,
0 < x < 1,
0 < t,
subject to the boundary conditions that ux(0, t) + 2au(0, t) = 0, ux(1, t) + 2au(1, t) = 0,
0 < t, and the initial condition that u(x, 0) = 1, 0 < x < 1.
Step 1: Introducing u(x, t) = e−axv(x, t), show that the problem becomes
∂v
∂t = ∂2v
∂x2 −a2v,
0 < x < 1,
0 < t,
subject to the boundary conditions that vx(0, t) + av(0, t) = 0, vx(1, t) + av(1, t) = 0, 0 < t,
and the initial condition that u(x, 0) = eax, 0 < x < 1.
23 See DeGroot, S. R., 1942: Th´eorie ph´enom´enologique de l’eﬀet Soret. Physica, 9, 699–707.

374
Advanced Engineering Mathematics with MATLAB
Step 2: Assuming that v(x, t) = X(x)T(t), show that the problem reduces to the ordinary
diﬀerential equations
X′′ + (λ −a2)X = 0,
X′(0) + aX(0) = 0,
X′(1) + aX(1) = 0,
and T ′ + λT = 0, where λ is the separation constant.
Step 3: Solve the eigenvalue problem and show that λ0 = 0, X0(x) = e−ax, T0(t) = A0,
and λn = a2 +n2π2, Xn(x) = a sin(nπx)−nπ cos(nπx), and Tn(t) = Ane−(a2+n2π2)t, where
n = 1, 2, 3, . . ., so that
v(x, t) = A0e−ax +
∞
X
n=1
An [a sin(nπx) −nπ cos(nπx)] e−(a2+n2π2)t.
Step 4: Evaluate A0 and An and show that
u(x, t) = 2ae−2ax
1 −e−2a + 4aπ
∞
X
n=1
n [1 −(−1)nea]
(a2 + n2π2)2
[a sin(nπx) −nπ cos(nπx)] e−ax−(a2+n2π2)t.
42. Use separation of variables to solve24 the partial diﬀerential equation
∂3u
∂x2∂t = ∂4u
∂x4 ,
0 < x < 1,
0 < t,
subject to the boundary conditions that u(0, t) = ux(0, t) = u(1, t) = ux(1, t) = 0, 0 < t,
and the initial condition that u(x, 0) = Ax/2 −(1 −A)x2   3
2 −x

, 0 ≤x ≤1.
Step 1: Assuming that u(x, t) = X(x)T(t), show that the problem reduces to the ordinary
diﬀerential equations X′′′′ +k2X′′ = 0, X(0) = X′(0) = X(1) = X′(1) = 0, and T ′ +k2T =
0, where k2 is the separation constant.
Step 2: Solving the eigenvalue problem ﬁrst, show that
Xn(x) = 1 −cos(knx) + 1 −cos(kn)
kn −sin(kn)[sin(knx) −knx],
where kn denotes the nth root of
2 −2 cos(k) −k sin(k) = sin(k/2)[sin(k/2) −(k/2) cos(k/2)] = 0.
Step 3: Using the results from Step 2, show that there are two classes of eigenfunctions:
κn = 2nπ , Xn(x) = 1 −cos(2nπx), and
tan(κn/2) = κn/2,
Xn(x) = 1 −cos(κnx) + 2
κn
[sin(κnx) −κnx].
Step 4: Consider the eigenvalue problem
X′′′′ + λX′′ = 0,
0 < x < 1,
24 See Hamza, E. A., 1999: Impulsive squeezing with suction and injection. J. Appl. Mech., 66, 945–951.

The Heat Equation
375
with the boundary conditions X(0) = X′(0) = X(1) = X′(1) = 0. Show that the orthogo-
nality condition for this problem is
Z 1
0
X′
n(x)X′
m(x) dx = 0,
n ̸= m,
where Xn(x) and Xm(x) are two distinct eigenfunctions of this problem. Then show that
we can construct an eigenfunction expansion for an arbitrary function f(x) via
f(x) =
∞
X
n=1
CnXn(x),
provided
Cn =
R 1
0 f ′(x)X′
n(x) dx
R 1
0 [X′n(x)]2 dx
and f ′(x) exists over the interval (0, 1). Hint: Follow the proof in Section 6.2 and integrate
repeatedly by parts to eliminate the higher derivative terms.
Step 5: Show that
Z 1
0
[X′
n(x)]2 dx = 2n2π2,
if Xn(x) = 1 −cos(2nπx), and
Z 1
0
[X′
n(x)]2 dx = κ2
n/2,
if Xn(x) = 1 −cos(κnx) + 2[sin(κnx) −κnx]/κn. Hint: sin(κn) = κn[1 + cos(κn)]/2.
Step 6: Use the above results to show that
u(x, t) =
∞
X
n=1
An[1 −cos(2nπx)]e−4n2π2t
+
∞
X
n=1
Bn

1 −cos(κnx) −2
κn
[sin(κnx) −κnx]

e−κ2
nt,
where An is the Fourier coeﬃcient corresponding to the eigenfunction 1 −cos(2nπx) while
Bn is the Fourier coeﬃcient corresponding to the eigenfunction 1 −cos(κnx) −2[sin(κnx) −
κnx]/κn.
Step 7: Show that An = 0 and Bn = 2(1 −A)/κ2
n, so that
u(x, t) = 2(1 −A)
∞
X
n=1

1 −cos(κnx) −2
κn
[sin(κnx) −κnx]
 e−κ2
nt
κ2n
.
Hint: sin(κn) = κn[1+cos(κn)]/2, sin(κn) = 2[1−cos(κn)]/κn, and cos(κn) = (4−κ2
n)/(4+
κ2
n).
43. Use separation of variables to solve25 the partial diﬀerential equation
∂u
∂t = a2
∂2u
∂r2 + 1
r
∂u
∂r −u
r2

,
0 ≤r < 1,
0 < t,
25 See Littleﬁeld, D. L., 1991: Finite conductivity eﬀects on the MHD instabilities in uniformly elongating
plastic jets. Phys. Fluids, Ser. A, 3, 1666–1673.

376
Advanced Engineering Mathematics with MATLAB
subject to the boundary conditions that
lim
r→0 |u(r, t)| < ∞,
u(1, t) = K,
0 < t,
and the initial condition that
u(r, 0) = g(r),
0 < r < 1.
Step 1: Setting u(r, t) = Kr + v(r, t), show that the problem becomes
∂v
∂t = a2
∂2v
∂r2 + 1
r
∂v
∂r −v
r2

,
0 ≤r < 1,
0 < t,
subject to the boundary conditions that
lim
r→0 |v(r, t)| < ∞,
v(1, t) = 0,
0 < t,
and the initial condition that
u(r, 0) = g(r) −Kr,
0 < r < 1.
Step 2: Assuming that v(r, t) = R(r)T(t), show that the problem reduces to the ordinary
diﬀerential equations
R′′ + 1
r R′ +

k2 −1
r2

R = 0,
and
T ′ + a2k2T = 0
with the boundary conditions limr→0 |R(r)| < ∞and R(1) = 0, where k2 is the separation
constant.
Step 3: Solving the eigenvalue problem ﬁrst, show that Rn(r) = J1(knr) where kn denotes
the nth root of J1(k) = 0 and n = 1, 2, 3, . . ..
Step 4: Show that Tn(t) = Ane−a2k2
nt so that
v(r, t) =
∞
X
n=1
AnJ1(knr)e−a2k2
nt.
Step 5: Using the initial condition, show that
v(r, 0) = g(r) −Kr =
∞
X
n=1
AnJ1(knr).
Step 6: Evaluate An and show that it equals
An =
2
knJ0(kn)

K +
kn
J0(kn)
Z 1
0
g(r)J1(knr) r dr

.

The Heat Equation
377
x
t
x
t
u
)
u
u
u n
n
n
n+1
∆
∆
u 1
n =0
u L
n =0
=f(x
0
u m
m
m+1
m
m-1
m
Figure 8.4.1: Schematic of the numerical solution of the heat equation when we hold both ends at a
temperature of zero.
8.4 NUMERICAL SOLUTION OF THE HEAT EQUATION
In the previous chapter we showed how we may use ﬁnite diﬀerence techniques to solve
the wave equation. In this section we show that similar considerations hold for the heat
equation.
Starting with the heat equation
∂u
∂t = a2 ∂2u
∂x2 ,
(8.4.1)
we must ﬁrst replace the exact derivatives with ﬁnite diﬀerences. Drawing upon our work
in Section 7.6,
∂u(xm, tn)
∂t
= un+1
m
−un
m
∆t
+ O(∆t),
(8.4.2)
and
∂2u(xm, tn)
∂x2
= un
m+1 −2un
m + un
m−1
(∆x)2
+ O[(∆x)2],
(8.4.3)
where the notation un
m denotes u(xm, tn). Figure 8.4.1 illustrates our numerical scheme
when we hold both ends at the temperature of zero.
Substituting Equation 8.4.2 and
Equation 8.4.3 into Equation 8.4.1 and rearranging,
un+1
m
= un
m + a2∆t
(∆x)2
 un
m+1 −2un
m + un
m−1

.
(8.4.4)
The numerical integration begins with n = 0 and the value of u0
m+1, u0
m, and u0
m−1 are
given by f(m∆x).
Once again we must check the convergence, stability, and consistency of our scheme. We
begin by writing un
m+1, un
m−1, and un+1
m
in terms of the exact solution u and its derivatives
evaluated at the point xm = m∆x and tn = n∆t. By Taylor’s expansion,
un
m+1 = un
m + ∆x∂u
∂x

m
n
+ 1
2(∆x)2 ∂2u
∂x2

m
n
+ 1
6(∆x)3 ∂3u
∂x3

m
n
+ · · · ,
(8.4.5)

378
Advanced Engineering Mathematics with MATLAB
un
m−1 = un
m −∆x∂u
∂x

m
n
+ 1
2(∆x)2 ∂2u
∂x2

m
n
−1
6(∆x)3 ∂3u
∂x3

m
n
+ · · · ,
(8.4.6)
and
un+1
m
= un
m + ∆t∂u
∂t

m
n
+ 1
2(∆t)2 ∂2u
∂t2

m
n
+ 1
6(∆t)3 ∂3u
∂t3

m
n
+ · · · .
(8.4.7)
Substituting into Equation 8.4.4, we obtain
un+1
m
−un
m
∆t
−a2 un
m+1 −2un
m + un
m−1
(∆x)2
=
∂u
∂t −a2 ∂2u
∂x2

m
n
+ 1
2∆t∂2u
∂t2

m
n
−1
12(a∆x)2 ∂4u
∂x4

m
n
+ · · · .
(8.4.8)
The ﬁrst term on the right side of Equation 8.4.8 vanishes because u(x, t) satisﬁes the heat
equation. Thus, in the limit of ∆x →0, ∆t →0, the right side of Equation 8.4.8 vanishes
and the scheme is consistent.
To determine the stability of the explicit scheme, we again use the Fourier method.
Assuming a solution of the form:
um
n = eimθeinλ,
(8.4.9)
we substitute Equation 8.4.9 into Equation 8.4.4 and ﬁnd that
eiλ −1
∆t
= a2 eiθ −2 + e−iθ
(∆x)2
,
(8.4.10)
or
eiλ = 1 −4 a2∆t
(∆x)2 sin2
θ
2

.
(8.4.11)
The quantity eiλ will grow exponentially unless
−1 ≤1 −4 a2∆t
(∆x)2 sin2
θ
2

< 1.
(8.4.12)
The right inequality is trivially satisﬁed if a2∆t/(∆x)2 > 0, while the left inequality yields
a2∆t
(∆x)2 ≤
1
2 sin2 (θ/2),
(8.4.13)
leading to the stability condition 0 < a2∆t/(∆x)2 ≤1
2. This is a rather restrictive condition
because doubling the resolution (halving ∆x) requires that we reduce the time step by a
quarter. Thus, for many calculations the required time step may be unacceptably small. For
this reason, many use an implicit form of the ﬁnite diﬀerencing (Crank-Nicholson implicit
method26):
un+1
m
−un
m
∆t
= a2
2
un
m+1 −2un
m + un
m−1
(∆x)2
+ un+1
m+1 −2un+1
m
+ un+1
m−1
(∆x)2

,
(8.4.14)
26 Crank, J., and P. Nicholson, 1947: A practical method for numerical evaluation of solutions of partial
diﬀerential equations of the heat-conduction type. Proc. Cambridge. Philos. Soc., 43, 50–67.

The Heat Equation
379
0.0
0.2
0.4
0.6
0.8
1.0
a  t
10
−10
10
−8
10
−6
10
−4
10
−2
error
2
Figure 8.4.2: The growth of error ||en|| as a function of a2t for various resolutions. For the top line,
∆x = 0.1; for the middle line, ∆x = 0.01; and for the bottom line, ∆x = 0.001.
although it requires the solution of a simultaneous set of linear equations. However, there
are several eﬃcient methods for their solution.
Finally we must check and see if our explicit scheme converges to the true solution. If
we let en
m denote the diﬀerence between the exact and our ﬁnite diﬀerenced solution to the
heat equation, we can use Equation 8.4.8 to derive the equation governing en
m and ﬁnd that
en+1
m
= en
m + a2∆t
(∆x)2
 en
m+1 −2en
m + en
m−1

+ O[(∆t)2 + ∆t(∆x)2],
(8.4.15)
for m = 1, 2, . . . , M. Assuming that a2∆t/(∆x)2 ≤1
2, then
en+1
m
 ≤a2∆t
(∆x)2
en
m−1
 +

1 −2 a2∆t
(∆x)2

|en
m| + a2∆t
(∆x)2
en
m+1
 + A[(∆t)2 + ∆t(∆x)2]
(8.4.16)
≤||en|| + A[(∆t)2 + ∆t(∆x)2],
(8.4.17)
where ||en|| = maxm=0,1,...,M |en
m|. Consequently,
||en+1|| ≤||en|| + A[(∆t)2 + ∆t(∆x)2].
(8.4.18)
Because ||e0|| = 0 and n∆t ≤tn, we ﬁnd that
||en+1|| ≤An[(∆t)2 + ∆t(∆x)2] ≤Atn[∆t + (∆x)2].
(8.4.19)
As ∆x →0, ∆t →0, the errors tend to zero and we have convergence. We have illustrated
Equation 8.4.19 in Figure 8.4.2 by using the ﬁnite diﬀerence equation, Equation 8.4.4, to
compute ||en|| during a numerical experiment that used a2∆t/(∆x)2 = 0.5, and f(x) =
sin(πx). Note how each increase of resolution by 10 results in a drop in the error by 100.
The following examples illustrate the use of numerical methods.

380
Advanced Engineering Mathematics with MATLAB
0
0.5
1
0
0.2
0.4
0.6
0
0.2
0.4
0.6
0.8
1
TIME
DISTANCE
TEMPERATURE
Figure 8.4.3: The numerical solution u(x, t) of the heat equation with a2∆t/(∆x)2 = 0.47 at various
positions x′ = x/L and times t′ = a2t/L2 using Equation 8.4.4. The initial temperature u(x, 0) equals
4x′(1 −x′) and we hold both ends at a temperature of zero.
• Example 8.4.1
For our ﬁrst example, we redo Example 8.3.1 with a2∆t/(∆x)2 = 0.47 and 0.53. Our
numerical solution was computed using the MATLAB script
clear
coeff = 0.47; % coeff = a2∆t/(∆x)2
ncount = 1; dx = 0.1; dt = coeff * dx * dx;
N = 99; x = 0:dx:1;
M = 1/dx + 1; % M = number of spatial grid points
tplot(1) = 0; u = zeros(M,N+1);
for m = 1:M; u(m,1)=4*x(m)*(1-x(m)); temp(m,1)=u(m,1); end
% integrate forward in time
for n = 1:N
t = dt * n;
for m = 2:M-1
u(m,n+1) = u(m,n) + coeff*(u(m+1,n)-2*u(m,n)+u(m-1,n));
end
if mod(n+1,2) == 0
ncount = ncount + 1; tplot(ncount) = t;
for m = 1:M; temp(m,ncount) = u(m,n+1); end
end; end
% plot the numerical solution
X = x’ * ones(1,length(tplot)); T = ones(M,1) * tplot;
surf(X,T,temp)
xlabel(’DISTANCE’,’Fontsize’,20); ylabel(’TIME’,’Fontsize’,20)
zlabel(’TEMPERATURE’,’Fontsize’,20)
As Figure 8.4.3 shows, the solution with a2∆t/(∆x)2 < 1/2 performs well. On the other
hand, Figure 8.4.4 shows small-scale, growing disturbances when a2∆t/(∆x)2 > 1/2. It

The Heat Equation
381
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
−0.5
0
0.5
1
TIME
DISTANCE
TEMPERATURE
Figure 8.4.4: Same as Figure 8.4.3 except that a2∆t/(∆x)2 = 0.53.
should be noted that for the reasonable ∆x = L/100, it takes approximately 20,000 time
steps before we reach a2t/L2 = 1.
⊓⊔
• Example 8.4.2
In this example, we redo the previous example with an insulated end at x = L. Using
the centered diﬀerencing formula,
un
M+1 −un
M−1 = 0,
(8.4.20)
because ux(L, t) = 0. Also, at i = M,
un+1
M
= un
M + a2∆t
(∆x)2
 un
M+1 −2un
M + un
M−1

.
(8.4.21)
Eliminating un
M+1 between the two equations,
un+1
M
= un
M + a2∆t
(∆x)2
 2un
M−1 −2un
M

.
(8.4.22)
To implement this new boundary condition in our MATLAB script, we add the line
u(M,n+1) = u(M,n) + 2 * coeff * (u(M-1,n) - u(M,n));
after the lines
for m = 2:M-1
u(m,n+1) = u(m,n) + coeff * (u(m+1,n) - 2 * u(m,n) + u(m-1,n));
end

382
Advanced Engineering Mathematics with MATLAB
0
0.5
1
0
0.1
0.2
0.3
0.4
0.5
0
0.2
0.4
0.6
0.8
1
TIME
DISTANCE
TEMPERATURE
Figure 8.4.5: Same as Figure 8.4.4 except that we now have an insulated boundary condition ux(L, t) = 0.
Figure 8.4.5 illustrates our numerical solution at various positions and times.
Project: Implicit Numerical Integration of the Heat Equation
The diﬃculty in using explicit time diﬀerencing to solve the heat equation is the very
small time step that must be taken at moderate spatial resolutions to ensure stability. This
small time step translates into an unacceptably long execution time. In this project you will
investigate the Crank-Nicholson implicit scheme, which allows for a much more reasonable
time step.
Step 1: Develop a MATLAB script that uses the Crank-Nicholson equation, Equation 8.4.14,
to numerically integrate the heat equation. To do this, you will need a tridiagonal solver to
ﬁnd un+1
m
. This is explained at the end of Section 3.1. However, many numerical methods
books27 actually have code already developed for your use. You might as well use this code.
Step 2: Test your code by solving the heat equation given the initial condition u(x, 0) =
sin(πx), and the boundary conditions u(0, t) = u(1, t) = 0. Find the solution for various
values of ∆t with ∆x = 0.01. Compare this numerical solution against the exact solution
that you can ﬁnd. How does the error (between the numerical and exact solutions) change
with ∆t? For small ∆t, the errors should be small. If not, then you have a mistake in your
code.
Step 3: Once you have conﬁdence in your code, discuss the behavior of the scheme for
various values of ∆x and ∆t for the initial condition u(x, 0) = 0 for 0 ≤x <
1
2, and
u(x, 0) = 1 for 1
2 < x ≤1 with the boundary conditions u(0, t) = u(1, t) = 0. See Figure
8.4.6. Although you can take quite a large ∆t, what happens? Did a similar problem arise
27 For example, Press, W. H., B. P. Flannery, S. A. Teukolsky, and W. T. Vetterling, 1986: Numerical
Recipes: The Art of Scientiﬁc Computing. Cambridge University Press, Section 2.6.

The Heat Equation
383
0
0.5
1
0
0.05
0.1
0
0.2
0.4
0.6
0.8
1
TIME
DISTANCE
U(X,T)
Figure 8.4.6: The numerical solution u(x, t) of the heat equation ut = a2uxx using the Crank-Nicholson
method. The parameters used in the numerical solution are a2∆t = 0.005 and ∆x = 0.05. Both ends are
held at zero with an initial condition of u(x, 0) = 0 for 0 ≤x < 1
2 , and u(x, 0) = 1 for 1
2 < x ≤1.
in Step 2? Explain your results.28 Zvan et al.29 have reported a similar problem in the
numerical integration of the Black-Scholes equation from mathematical ﬁnance.
Further Readings
Carslaw, H. S., and J. C. Jaeger, 1959: Conduction of Heat in Solids. Oxford University
Press, 510 pp. The source book on solving the heat equation.
Crank, J., 1970: The Mathematics of Diﬀusion. Oxford University Press, 347 pp. A source
book on the solution of the heat equation.
Koshlyakov, N. S., M. M. Smirnov, and E. B. Gliner, 1964: Diﬀerential Equations of Math-
ematical Physics. North-Holland Publishing, 701 pp. See Part III. Nice presentation of
mathematical techniques.
Morse, P. M., and H. Feshback, 1953: Methods of Theoretical Physics. McGraw-Hill Book
Co., 997 pp. A portion of Chapter 12 is devoted to solving the heat equation.
28 Luskin, M., and R. Rannacher, 1982: On the smoothing property of the Crank-Nicolson scheme.
Applicable Anal., 14, 117–135.
29 Zvan, R., K. Vetzal, and P. Forsyth, 1998: Swing low, swing high. Risk, 11(3), 71–75.

Chapter 9
Laplace’s Equation
In the previous chapter we solved the one-dimensional heat equation. Quite often we
found that the transient solution died away, leaving a steady state. The partial diﬀerential
equation that describes the steady state for two-dimensional heat conduction is Laplace’s
equation
∂2u
∂x2 + ∂2u
∂y2 = 0.
(9.0.1)
In general, this equation governs physical processes where equilibrium has been reached. It
also serves as the prototype for a wider class of elliptic equations
a(x, t)∂2u
∂x2 + b(x, t) ∂2u
∂x∂t + c(x, t)∂2u
∂t2 = f

x, t, u, ∂u
∂x, ∂u
∂t

,
(9.0.2)
where b2 < 4ac. Unlike the heat and wave equations, there are no initial conditions and
the boundary conditions completely specify the solution. In this chapter we present some
of the common techniques for solving this equation.
9.1 DERIVATION OF LAPLACE’S EQUATION
Imagine a thin, ﬂat plate of heat-conducting material between two sheets of insulation.
Suﬃcient time has passed so that the temperature depends only on the spatial coordinates
x and y. Let us now apply the law of conservation of energy (in rate form) to a small
rectangle with sides ∆x and ∆y.
385

386
Advanced Engineering Mathematics with MATLAB
If qx(x, y) and qy(x, y) denote the heat ﬂow rates in the x- and y-direction, respectively,
conservation of energy requires that the heat ﬂow into the slab equals the heat ﬂow out of
the slab if there is no storage or generation of heat. Now
rate in = qx(x, y + ∆y/2)∆y + qy(x + ∆x/2, y)∆x,
(9.1.1)
and
rate out = qx(x + ∆x, y + ∆y/2)∆y + qy(x + ∆x/2, y + ∆y)∆x.
(9.1.2)
If the plate has unit thickness,
[qx(x, y + ∆y/2) −qx(x + ∆x, y + ∆y/2)]∆y
+ [qy(x + ∆x/2, y) −qy(x + ∆x/2, y + ∆y)]∆x = 0.
(9.1.3)
Upon dividing through by ∆x∆y, we obtain two diﬀerences quotients on the left side of
Equation 9.1.3. In the limit as ∆x, ∆y →0, they become partial derivatives, giving
∂qx
∂x + ∂qy
∂y = 0
(9.1.4)
for any point (x, y).
We now employ Fourier’s law to eliminate the rates qx and qy, yielding
∂
∂x

a2 ∂u
∂x

+ ∂
∂y

a2 ∂u
∂y

= 0,
(9.1.5)
if we have an isotropic (same in all directions) material. Finally, if a2 is constant, Equation
9.1.5 reduces to
∂2u
∂x2 + ∂2u
∂y2 = 0,
(9.1.6)
which is the two-dimensional, steady-state heat equation (i.e., ut ≈0 as t →∞).
Solutions of Laplace’s equation (called harmonic functions) diﬀer fundamentally from
those encountered with the heat and wave equations. These latter two equations describe
the evolution of some phenomena. Laplace’s equation, on the other hand, describes things
at equilibrium. Consequently, any change in the boundary conditions aﬀects to some degree
the entire domain because a change to any one point causes its neighbors to change in order
to reestablish the equilibrium. Those points will, in turn, aﬀect others. Because all of these
points are in equilibrium, this modiﬁcation must occur instantaneously.
Further insight follows from the maximum principle. If Laplace’s equation governs a
region, then its solution cannot have a relative maximum or minimum inside the region
unless the solution is constant.1 If we think of the solution as a steady-state temperature
distribution, this principle is clearly true because at any one point the temperature cannot
be greater than at all other nearby points. If that were so, heat would ﬂow away from the
hot point to cooler points nearby, thus eliminating the hot spot when equilibrium was once
again restored.
It is often useful to consider the two-dimensional Laplace’s equation in other coordinate
systems.
In polar coordinates, where x = r cos(θ), y = r sin(θ), and z = z, Laplace’s
equation becomes
∂2u
∂r2 + 1
r
∂u
∂r + ∂2u
∂z2 = 0,
(9.1.7)
1 For the proof, see Courant, R., and D. Hilbert, 1962: Methods of Mathematical Physics, Vol.
2:
Partial Diﬀerential Equations. Interscience, pp. 326–331.

Laplace’s Equation
387
Today we best remember Pierre-Simon Laplace (1749–1827) for his work in celestial mechanics and
probability.
In his ﬁve volumes Trait´e de M´ecanique c´eleste (1799–1825), he accounted for the
theoretical orbits of the planets and their satellites. Laplace’s equation arose during this study of
gravitational attraction. (Portrait courtesy of the Archives de l’Acad´emie des sciences, Paris.)
if the problem possesses axisymmetry. On the other hand, if the solution is independent of
z, Laplace’s equation becomes
∂2u
∂r2 + 1
r
∂u
∂r + 1
r2
∂2u
∂θ2 = 0.
(9.1.8)
In spherical coordinates, x = r cos(ϕ) sin(θ), y = r sin(ϕ) sin(θ), and z = r cos(θ), where
r2 = x2 + y2 + z2, θ is the angle measured down to the point from the z-axis (colatitude)
and ϕ is the angle made between the x-axis and the projection of the point on the xy plane.
In the case of axisymmetry (no ϕ dependence), Laplace’s equation becomes
∂
∂r

r2 ∂u
∂r

+
1
sin(θ)
∂
∂θ

sin(θ)∂u
∂θ

= 0.
(9.1.9)
9.2 BOUNDARY CONDITIONS
Because Laplace’s equation involves time-independent phenomena, we must only spec-
ify boundary conditions. As we discussed in Section 8.2, we can classify these boundary
conditions as follows:
1. Dirichlet condition: u given

388
Advanced Engineering Mathematics with MATLAB
2. Neumann condition: ∂u
∂n given, where n is the unit normal direction
3. Robin condition: u + α∂u
∂n given
along any section of the boundary. In the case of Laplace’s equation, if all of the boundaries
have Neumann conditions, then the solution is not unique. This follows from the fact that
if u(x, y) is a solution, so is u(x, y) + c, where c is any constant.
Finally we note that we must specify the boundary conditions along each side of the
boundary. These sides may be at inﬁnity as in problems with semi-inﬁnite domains. We
must specify values along the entire boundary because we could not have an equilibrium
solution if any portion of the domain was undetermined.
9.3 SEPARATION OF VARIABLES
As in the case of the heat and wave equations, separation of variables is the most
popular technique for solving Laplace’s equation. Although the same general procedure
carries over from the previous two chapters, the following examples ﬁll out the details.
• Example 9.3.1: Groundwater ﬂow in a valley
Over a century ago, a French hydraulic engineer named Henri-Philibert-Gaspard Darcy
(1803–1858) published the results of a laboratory experiment on the ﬂow of water through
sand. He showed that the apparent ﬂuid velocity q relative to the sand grains is directly
proportional to the gradient of the hydraulic potential −k∇ϕ, where the hydraulic potential
ϕ equals the sum of the elevation of the point of measurement plus the pressure potential
(p/ρg). In the case of steady ﬂow, the combination of Darcy’s law with conservation of
mass ∇· q = 0 yields Laplace’s equation ∇2ϕ = 0 if the aquifer is isotropic (same in all
directions) and homogeneous.
To illustrate how separation of variables can be used to solve Laplace’s equation, we
will determine the hydraulic potential within a small drainage basin that lies in a shallow
valley. See Figure 9.3.1. Following T´oth,2 the governing equation is the two-dimensional
Laplace equation
∂2u
∂x2 + ∂2u
∂y2 = 0,
0 < x < L,
0 < y < z0,
(9.3.1)
along with the boundary conditions
u(x, z0) = gz0 + gcx,
(9.3.2)
ux(0, y) = ux(L, y) = 0,
and
uy(x, 0) = 0,
(9.3.3)
where u(x, y) is the hydraulic potential, g is the acceleration due to gravity, and c gives the
slope of the topography. The conditions ux(L, y) = 0, and uy(x, 0) = 0 specify a no-ﬂow
condition through the bottom and sides of the aquifer. The condition ux(0, y) = 0 ensures
symmetry about the x = 0 line. Equation 9.3.1 gives the ﬂuid potential at the water table,
where z0 is the elevation of the water table above the standard datum. The term gcx in
2 T´oth, J., 1962: A theory of groundwater motion in small drainage basins in central Alberta, Canada.
J. Geophys. Res., 67, 4375–4387.

Laplace’s Equation
389
x
y
land surface
z0
valley
bottom
theoretical 
impermeable
impermeable boundary (standard datum)
water
divide
boundaries
Figure 9.3.1: Cross section of a valley.
Equation 9.3.2 expresses the increase of the potential from the valley bottom toward the
water divide. On average it closely follows the topography.
Following the pattern set in the previous two chapters, we assume that u(x, y) =
X(x)Y (y). Then Equation 9.3.1 becomes
X′′Y + XY ′′ = 0.
(9.3.4)
Separating the variables yields
X′′
X = −Y ′′
Y .
(9.3.5)
Both sides of Equation 9.3.5 must be constant, but the sign of that constant is not obvious.
From previous experience we anticipate that the ordinary diﬀerential equation in the x-
direction leads to a Sturm-Liouville problem because it possesses homogeneous boundary
conditions. Proceeding along this line of reasoning, we consider three separation constants.
Trying a positive constant (say, m2), Equation 9.3.5 separates into the two ordinary
diﬀerential equations
X′′ −m2X = 0,
and
Y ′′ + m2Y = 0,
(9.3.6)
which have the solutions
X(x) = A cosh(mx) + B sinh(mx),
(9.3.7)
and
Y (y) = C cos(my) + D sin(my).
(9.3.8)
Because the boundary conditions, Equation 9.3.3, imply X′(0) = X′(L) = 0, both A and
B must be zero, leading to the trivial solution u(x, y) = 0.
When the separation constant equals zero, we ﬁnd a nontrivial solution given by the
eigenfunction X0(x) = 1, and Y0(y) =
1
2A0 + B0y. However, because Y ′
0(0) = 0 from
Equation 9.3.3, B0 = 0. Thus, the particular solution for a zero separation constant is
u0(x, y) = A0/2.
Finally, taking both sides of Equation 9.3.5 equal to −k2,
X′′ + k2X = 0,
and
Y ′′ −k2Y = 0.
(9.3.9)

390
Advanced Engineering Mathematics with MATLAB
The ﬁrst of these equations, along with the boundary conditions X′(0) = X′(L) = 0, gives
the eigenfunction Xn(x) = cos(knx), with kn = nπ/L, n = 1, 2, 3, . . .. The function Yn(y)
for the same separation constant is
Yn(y) = An cosh(kny) + Bn sinh(kny).
(9.3.10)
We must take Bn = 0 because Y ′
n(0) = 0.
We now have the product solution Xn(x)Yn(y), which satisﬁes Laplace’s equation and
all of the boundary conditions except Equation 9.3.2. By the principle of superposition, the
general solution is
u(x, y) = A0
2 +
∞
X
n=1
An cos
nπx
L

cosh
nπy
L

.
(9.3.11)
Applying Equation 9.3.2, we ﬁnd that
u(x, z0) = gz0 + gcx = A0
2 +
∞
X
n=1
An cos
nπx
L

cosh
nπz0
L

,
(9.3.12)
which we recognize as a Fourier half-range cosine series such that
A0 = 2
L
Z L
0
(gz0 + gcx) dx,
(9.3.13)
and
cosh
nπz0
L

An = 2
L
Z L
0
(gz0 + gcx) cos
nπx
L

dx.
(9.3.14)
Performing the integrations,
A0 = 2gz0 + gcL,
(9.3.15)
and
An = −2gcL[1 −(−1)n]
n2π2 cosh(nπz0/L).
(9.3.16)
Finally, the complete solution is
u(x, y) = gz0 + gcL
2
−4gcL
π2
∞
X
m=1
cos[(2m −1)πx/L] cosh[(2m −1)πy/L]
(2m −1)2 cosh[(2m −1)πz0/L]
.
(9.3.17)
Figure 9.3.2 presents two graphs by T´oth for two diﬀerent aquifers. We see that the solution
satisﬁes the boundary condition at the bottom and side boundaries. Water ﬂows from the
elevated land (on the right) into the valley (on the left), from regions of high to low hydraulic
potential.
⊓⊔
• Example 9.3.2
In the previous example, we had the advantage of homogeneous boundary conditions
along x = 0 and x = L. In a diﬀerent hydraulic problem, Kirkham3 solved the more diﬃcult
problem of
∂2u
∂x2 + ∂2u
∂y2 = 0,
0 < x < L,
0 < y < h,
(9.3.18)
3 Kirkham, D., 1958: Seepage of steady rainfall through soil into drains. Trans. Am. Geophys. Union,
39, 892–908.

Laplace’s Equation
391
Figure 9.3.2: Two-dimensional potential distribution and ﬂow patterns for diﬀerent depths of the hori-
zontally impermeable boundary.
subject to the Dirichlet boundary conditions
u(x, 0) = Rx,
u(x, h) = RL,
u(L, y) = RL,
(9.3.19)
and
u(0, y) =
(
0,
0 < y < a,
RL
b−a(y −a),
a < y < b,
RL,
b < y < h.
(9.3.20)
This problem arises in ﬁnding the steady ﬂow within an aquifer resulting from the intro-
duction of water at the top due to a steady rainfall and its removal along the sides by
drains. The parameter L equals half of the distance between the drains, h is the depth of
the aquifer, and R is the rate of rainfall.
The point of this example is: We need homogeneous boundary conditions along either
the x or y boundaries for separation of variables to work. We achieve this by breaking the
original problem into two parts, namely
u(x, y) = v(x, y) + w(x, y) + RL,
(9.3.21)
where
∂2v
∂x2 + ∂2v
∂y2 = 0,
0 < x < L,
0 < y < h,
(9.3.22)
with
v(0, y) = v(L, y) = 0,
v(x, h) = 0,
(9.3.23)
and
v(x, 0) = R(x −L);
(9.3.24)
∂2w
∂x2 + ∂2w
∂y2 = 0,
0 < x < L,
0 < y < h,
(9.3.25)
with
w(x, 0) = w(x, h) = 0,
w(L, y) = 0,
(9.3.26)

392
Advanced Engineering Mathematics with MATLAB
and
w(0, y) =
(
−RL,
0 < y < a,
RL
b−a(y −a) −RL,
a < y < b,
0,
b < y < h.
(9.3.27)
Employing the same technique as in Example 9.3.1, we ﬁnd that
v(x, y) =
∞
X
n=1
An sin
nπx
L
 sinh[nπ(h −y)/L]
sinh(nπh/L)
,
(9.3.28)
where
An = 2
L
Z L
0
R(x −L) sin
nπx
L

dx = −2RL
nπ .
(9.3.29)
Similarly, the solution to w(x, y) is found to be
w(x, y) =
∞
X
n=1
Bn sin
nπy
h
 sinh[nπ(L −x)/h]
sinh(nπL/h)
,
(9.3.30)
where
Bn = 2
h

−RL
Z a
0
sin
nπy
h

dy + RL
Z b
a
y −a
b −a −1

sin
nπy
h

dy

(9.3.31)
= 2RL
π

h
(b −a)n2π

sin
nπb
h

−sin
nπa
h

−1
n

.
(9.3.32)
The complete solution consists of substituting Equation 9.3.28 and Equation 9.3.30 into
Equation 9.3.21.
⊓⊔
• Example 9.3.3
The electrostatic potential is deﬁned as the amount of work that must be done against
electric forces to bring a unit charge from a reference point to a given point. It is readily
shown4 that the electrostatic potential is described by Laplace’s equation if there is no
charge within the domain. Let us ﬁnd the electrostatic potential u(r, z) inside a closed
cylinder of length L and radius a. The base and lateral surfaces have the potential 0 while
the upper surface has the potential V .
Because the potential varies in only r and z, Laplace’s equation in cylindrical coordi-
nates reduces to
1
r
∂
∂r

r∂u
∂r

+ ∂2u
∂z2 = 0,
0 ≤r < a,
0 < z < L,
(9.3.33)
subject to the boundary conditions
u(a, z) = u(r, 0) = 0,
and
u(r, L) = V.
(9.3.34)
4 For static ﬁelds, ∇× E = 0, where E is the electric force. From Section 4.4, we can introduce a
potential ϕ such that E = ∇ϕ. From Gauss’ law, ∇· E = ∇2ϕ = 0.

Laplace’s Equation
393
To solve this problem by separation of variables,5 let u(r, z) = R(r)Z(z) and
1
rR
d
dr

rdR
dr

= −1
Z
d2Z
dz2 = −k2
a2 .
(9.3.35)
Only a negative separation constant yields nontrivial solutions in the radial direction. In
that case, we have that
1
r
d
dr

rdR
dr

+ k2
a2 R = 0.
(9.3.36)
The solutions of Equation 9.3.36 are the Bessel functions J0(kr/a) and Y0(kr/ a). Because
Y0(kr/a) becomes inﬁnite at r = 0, the only permissible solution is J0(kr/a). The condition
that u(a, z) = R(a)Z(z) = 0 forces us to choose values of k such that J0(k) = 0. Therefore,
the solution in the radial direction is J0(knr/a), where kn is the nth root of J0(k) = 0.
In the z direction,
d2Zn
dz2 + k2
n
a2 Zn = 0.
(9.3.37)
The general solution to Equation 9.3.37 is
Zn(z) = An sinh
knz
a

+ Bn cosh
knz
a

.
(9.3.38)
Because u(r, 0) = R(r)Z(0) = 0 and cosh(0) = 1, Bn must equal zero. Therefore, the
general product solution is
u(r, z) =
∞
X
n=1
AnJ0
knr
a

sinh
knz
a

.
(9.3.39)
The condition that u(r, L) = V determines the arbitrary constant An. Along z = L,
u(r, L) = V =
∞
X
n=1
AnJ0
knr
a

sinh
knL
a

,
(9.3.40)
where
sinh
knL
a

An =
2V
a2J2
1(kn)
Z L
0
r J0
knr
a

dr
(9.3.41)
from Equation 6.5.38 and Equation 6.5.45. Thus,
sinh
knL
a

An =
2V
k2nJ2
1(kn)
knr
a

J1
knr
a

a
0
=
2V
knJ1(kn).
(9.3.42)
The solution is then
u(r, z) = 2V
∞
X
n=1
J0(knr/a)
knJ1(kn)
sinh(knz/a)
sinh(knL/a).
(9.3.43)
5 Wang and Liu [Wang, M.-L., and B.-L. Liu, 1995: Solution of Laplace equation by the method of
separation of variables. J. Chinese Inst. Eng., 18, 731–739] have written a review article on the solutions
to Equation 9.3.33 based upon which order the boundary conditions are satisﬁed.

394
Advanced Engineering Mathematics with MATLAB
0
0.5
1
0
0.5
1
0
0.2
0.4
0.6
0.8
1
1.2
R/A
Z/A
U(R,Z)
Figure 9.3.3: The steady-state potential (divided by V ) within a cylinder of equal radius and height a
when the top has the potential V while the lateral side and bottom are at potential 0.
Figure 9.3.3 illustrates Equation 9.3.43 for the case when L = a where we included the
ﬁrst 20 terms of the series. It was created using the MATLAB script
clear
L over a = 1; M = 20; dr = 0.02; dz = 0.02;
% load in zeros of J 0
zero( 1) =
2.40482; zero( 2) =
5.52007; zero( 3) =
8.65372;
zero( 4) = 11.79153; zero( 5) = 14.93091; zero( 6) = 18.07106;
zero( 7) = 21.21164; zero( 8) = 24.35247; zero( 9) = 27.49347;
zero(10) = 30.63461; zero(11) = 33.77582; zero(12) = 36.91710;
zero(13) = 40.05843; zero(14) = 43.19979; zero(15) = 46.34119;
zero(16) = 49.48261; zero(17) = 52.62405; zero(18) = 55.76551;
zero(19) = 58.90698; zero(20) = 62.04847;
% compute Fourier coefficients
for m = 1:M
a(m) = 2/(zero(m)*besselj(1,zero(m))*sinh(L over a*zero(m)));
end
% compute grid and initialize solution
R over a = [0:dr:1]; Z over a = [0:dz:1];
u = zeros(length(Z over a),length(R over a));
RR over a = repmat(R over a,[length(Z over a) 1]);
ZZ over a = repmat(Z over a’,[1 length(R over a)]);
% compute solution from Equation 9.3.43
for m = 1:M
u=u+a(m).*besselj(0,zero(m)*RR over a) .* sinh(zero(m)*ZZ over a);
end
surf(RR over a,ZZ over a,u)
xlabel(’R/A’,’Fontsize’,20); ylabel(’Z/A’,’Fontsize’,20)
zlabel(’U(R,Z)’,’Fontsize’,20)

Laplace’s Equation
395
Of particular interest are the ripples along the line z = L. Along that line, the solution must
jump from V to 0 at r = a. For that reason our solution suﬀers from Gibbs phenomena
along this boundary. As we move away from that region the electrostatic potential varies
smoothly.
⊓⊔
• Example 9.3.4
Let us now consider a similar, but slightly diﬀerent, version of Example 9.3.3, where
the ends are held at zero potential while the lateral side has the value V . Once again, the
governing equation is Equation 9.3.33 with the boundary conditions
u(r, 0) = u(r, L) = 0,
and
u(a, z) = V.
(9.3.44)
Separation of variables yields
1
rR
d
dr

rdR
dr

= −1
Z
d2Z
dz2 = k2
L2
(9.3.45)
with Z(0) = Z(L) = 0. We chose a positive separation constant because a negative con-
stant would give hyperbolic functions in z that cannot satisfy the boundary conditions. A
separation constant of zero would give a straight line for Z(z). Applying the boundary
conditions gives a trivial solution. Consequently, the only solution in the z direction that
satisﬁes the boundary conditions is Zn(z) = sin(nπz/L).
In the radial direction, the diﬀerential equation is
1
r
d
dr

rdRn
dr

−n2π2
L2 Rn = 0.
(9.3.46)
As we showed in Section 6.5, the general solution is
Rn(r) = AnI0
nπr
L

+ BnK0
nπr
L

,
(9.3.47)
where I0 and K0 are modiﬁed Bessel functions of the ﬁrst and second kind, respectively, of
order zero. Because K0(x) behaves as −ln(x) as x →0, we must discard it and our solution
in the radial direction becomes Rn(r) = AnI0(nπr/L). Hence, the product solution is
un(r, z) = AnI0
nπr
L

sin
nπz
L

,
(9.3.48)
and the general solution is a sum of these particular solutions, namely
u(r, z) =
∞
X
n=1
AnI0
nπr
L

sin
nπz
L

.
(9.3.49)
Finally, we use the boundary conditions that u(a, z) = V to compute An. This condition
gives
u(a, z) = V =
∞
X
n=1
AnI0
nπa
L

sin
nπz
L

,
(9.3.50)
so that
I0
nπa
L

An = 2
L
Z L
0
V sin
nπz
L

dz = 2V [1 −(−1)n]
nπ
.
(9.3.51)

396
Advanced Engineering Mathematics with MATLAB
Therefore, the ﬁnal answer is
u(r, z) = 4V
π
∞
X
m=1
I0[(2m −1)πr/L] sin[(2m −1)πz/L]
(2m −1)I0[(2m −1)πa/L]
.
(9.3.52)
Figure 9.3.4 illustrates the solution, Equation 9.3.52, for the case when L = a. It was
created using the MATLAB script
clear
a over L = 1; M = 200; dr = 0.02; dz = 0.02;
% compute grid and initialize solution
R over L = [0:dr:1]; Z over L = [0:dz:1];
u = zeros(length(Z over L),length(R over L));
RR over L = repmat(R over L,[length(Z over L) 1]);
ZZ over L = repmat(Z over L’,[1 length(R over L)]);
for m = 1:M
temp = (2*m-1)*pi; prod1 = temp*a over L;
% compute modified bessel functions in Equation 9.3.52
for j = 1:length(Z over L); for i = 1:length(R over L);
prod2 = temp*RR over L(i,j);
if prod2 - prod1 > -10
if prod2 < 20
ratio(i,j) = besseli(0,prod2) / besseli(0,prod1);
else
% for large values of prod, use asymptotic expansion
%
for modified bessel function
ratio(i,j) = sqrt(prod1/prod2) * exp(prod2-prod1); end;
else
ratio(i,j) = 0; end
end; end;
% compute solution from Equation 9.3.52
u = u + (4/temp) * ratio .* sin(temp*ZZ over L);
end
surf(RR over L,ZZ over L,u)
xlabel(’R/L’,’Fontsize’,20); ylabel(’Z/L’,’Fontsize’,20)
zlabel(’SOLUTION’,’Fontsize’,20)
Once again, there is a convergence of equipotentials at the corners along the right side. If
we had plotted more contours, we would have observed Gibbs phenomena in the solution
along the top and bottom of the cylinder.
⊓⊔
• Example 9.3.5
In the previous examples, the domain was always of ﬁnite extent.
Assuming axial
symmetry, let us now solve Laplace’s equation
1
r
∂
∂r

r∂u
∂r

+ ∂2u
∂z2 = 0,
0 ≤r < ∞,
0 < z < ∞,
(9.3.53)

Laplace’s Equation
397
0
0.5
1
0
0.5
1
0
0.2
0.4
0.6
0.8
1
R/L
Z/L
SOLUTION
Figure 9.3.4: Potential (divided by V ) within a conducting cylinder when the top and bottom have a
potential 0 while the lateral side has a potential V .
in the half-plane z > 0 subject to the boundary conditions
lim
z→∞|u(r, z)| < ∞,
u(r, 0) =
n u0,
r < a,
0,
r > a,
(9.3.54)
lim
r→0 |u(r, z)| < ∞,
and
lim
r→∞|u(r, z)| < ∞.
(9.3.55)
This problem gives the steady-state temperature distribution in the half-space z > 0 where
the temperature on the bounding plane z = 0 equals u0 within a circle of radius a and
equals 0 outside of the circle.
As before, we begin by assuming the product solution u(r, z) = R(r)Z(z) and separate
the variables. Again, the separation constant may be positive, negative, or zero. Turning
to the positive separation constant ﬁrst, we have that
R′′
R + 1
r
R′
R = −Z′′
Z = m2.
(9.3.56)
Focusing on the R equation,
R′′
R + 1
r
R′
R −m2 = 0,
or
r2R′′ + rR −m2r2R = 0.
(9.3.57)
The solution to Equation 9.3.57 is
R(r) = A1I0(mr) + A2K0(mr),
(9.3.58)
where I0(·) and K0(·) denote modiﬁed Bessel functions of order zero and the ﬁrst and second
kind, respectively. Because u(r, z), and hence R(r), must be bounded as r →0, A2 = 0.
Similarly, since u(r, z) must also be bounded as r →∞, A1 = 0 because limr→∞I0(mr) →
∞. Thus, there is only a trivial solution for a positive separation constant.
We next try the case when the separation constant equals 0. This yields
R′′
R + 1
r
R′
R = 0,
or
r2R′′ + rR = 0.
(9.3.59)

398
Advanced Engineering Mathematics with MATLAB
The solution here is
R(r) = A1 + A2 ln(r).
(9.3.60)
Again, boundedness as r →0 requires that A2 = 0. What about A1? Clearly, for any
arbitrary value of z, the amount of internal energy must be ﬁnite. This corresponds to
Z ∞
0
|u(r, z)| dr < ∞
or
Z ∞
0
|R(r)| dr < ∞
(9.3.61)
and A1 = 0. The choice of the zero separation constant yields a trivial solution.
Finally, when the separation constant equals −k2, the equations for R(r) and Z(z) are
r2R′′ + rR + k2r2R = 0,
and
Z′′ −k2Z = 0,
(9.3.62)
respectively. Solving for R(r) ﬁrst, we have that
R(r) = A1J0(kr) + A2Y0(kr),
(9.3.63)
where J0(·) and Y0(·) denote Bessel functions of order zero and the ﬁrst and second kind,
respectively. The requirement that u(r, z), and hence R(r), is bounded as r →0 forces us
to take A2 = 0, leaving R(r) = A1J0(kr). From the equation for Z(z), we conclude that
Z(z) = B1ekz + B2e−kz.
(9.3.64)
Since u(r, z), and hence Z(z), must be bounded as z →∞, it follows that B1 = 0, leaving
Z(z) = B2e−kz.
Presently our analysis follows closely those for a ﬁnite domain. However, we have sat-
isﬁed all of the boundary conditions and yet there is still no restriction on k. Consequently,
we conclude that k is completely arbitrary and any product solution
uk(r, z) = A1B2 J0(kr) e−kz
(9.3.65)
is a solution to our partial diﬀerential equation and satisﬁes the boundary conditions. From
the principle of linear superposition, the most general solution equals the sum of all of the
possible solutions, or
u(r, z) =
Z ∞
0
A(k) k J0(kr) e−kz dk,
(9.3.66)
where we have written the arbitrary constant A1B2 as A(k)k. Our ﬁnal task remains to
compute A(k).
Before we can ﬁnd A(k), we must derive an intermediate result. If we deﬁne our Fourier
transform in an appropriate manner, we can write the two-dimensional Fourier transform
pair as
f(x, y) = 1
2π
Z ∞
−∞
Z ∞
−∞
F(k, ℓ) ei(kx+ℓy) dk dℓ,
(9.3.67)
where
F(k, ℓ) = 1
2π
Z ∞
−∞
Z ∞
−∞
f(x, y) e−i(kx+ℓy) dx dy.
(9.3.68)
Consider now the special case where f(x, y) is only a function of r =
p
x2 + y2, so that
f(x, y) = g(r). Then, changing to polar coordinates through the substitution x = r cos(θ),
y = r sin(θ), k = ρ cos(ϕ), and ℓ= ρ sin(ϕ), we have that
kx + ℓy = rρ[cos(θ) cos(ϕ) + sin(θ) sin(ϕ)] = rρ cos(θ −ϕ),
(9.3.69)

Laplace’s Equation
399
and
dA = dx dy = r dr dθ.
(9.3.70)
Therefore, the integral in Equation 9.3.68 becomes
F(k, ℓ) = 1
2π
Z ∞
0
Z 2π
0
g(r) e−irρ cos(θ−ϕ)r dr dθ
(9.3.71)
= 1
2π
Z ∞
0
r g(r)
Z 2π
0
e−irρ cos(θ−ϕ) dθ

dr.
(9.3.72)
If we introduce λ = θ −ϕ, the integral
Z 2π
0
e−irρ cos(θ−ϕ) dθ =
Z 2π−ϕ
−ϕ
e−irρ cos(λ) dλ =
Z 2π
0
e−irρ cos(λ) dλ = 2πJ0(ρr).
(9.3.73)
The third integral in Equation 9.3.73 is equivalent to the second integral because the integral
of a periodic function over one full period is the same regardless of where the integration
begins. The ﬁnal result follows from the integral deﬁnition of the Bessel function.6 There-
fore,
F(k, ℓ) =
Z ∞
0
r g(r) J0(ρr) dr.
(9.3.74)
Finally, because Equation 9.3.74 is clearly a function of ρ =
√
k2 + ℓ2, F(k, ℓ) = G(ρ) and
G(ρ) =
Z ∞
0
r g(r) J0(ρr) dr.
(9.3.75)
Conversely, if we begin with Equation 9.3.67, make the same substitution, and integrate
over the kℓplane, we have that
f(x, y) = g(r) = 1
2π
Z ∞
0
Z 2π
0
F(k, ℓ) eirρ cos(θ−ϕ)ρ dρ dϕ
(9.3.76)
= 1
2π
Z ∞
0
ρ G(ρ)
Z 2π
0
eirρ cos(θ−ϕ) dϕ

dρ
(9.3.77)
=
Z ∞
0
ρ G(ρ) J0(ρr) dρ.
(9.3.78)
Thus, we obtain the result that if
R ∞
0
|F(r)| dr exists, then
g(r) =
Z ∞
0
ρ G(ρ) J0(ρr) dρ,
(9.3.79)
where
G(ρ) =
Z ∞
0
r g(r) J0(ρr) dr.
(9.3.80)
Taken together, Equation 9.3.79 and Equation 9.3.80 constitute the Hankel transform pair
for Bessel function of order 0. The function G(ρ) is called the Hankel transform of g(r).
6 Watson, G. N., 1966: A Treatise on the Theory of Bessel Functions. Cambridge University Press,
Section 2.2, Equation 5.

400
Advanced Engineering Mathematics with MATLAB
Figure 9.3.5: The axisymmetric potential u(r, z)/u0 in the half-space z > 0 when u(r, 0) = u0 if r < a
and u(r, 0) = 0 if r > a.
Why did we introduce Hankel transforms? First, setting z = 0 in Equation 9.3.66, we
ﬁnd that
u(r, 0) =
Z ∞
0
A(k) k J0(kr) dk.
(9.3.81)
If we now compare Equation 9.3.79 with Equation 9.3.81, we recognize that A(k) is the
Hankel transform of u(r, 0). Therefore,
A(k) =
Z ∞
0
r u(r, 0) J0(kr) dr = u0
Z a
0
r J0(kr) dr = u0
k r J1(kr)|a
0 = au0
k J1(ka).
(9.3.82)
Thus, the complete solution is
u(r, z) = au0
Z ∞
0
J1(ka) J0(kr) e−kz dk.
(9.3.83)
Equation 9.3.83 is illustrated in Figure 9.3.5.
⊓⊔
• Example 9.3.6: Mixed boundary-value problem
In all of our previous examples, the boundary condition along any speciﬁc boundary
remained the same. In this example, we relax this condition and consider a mixed boundary-
value problem.
Consider7 the axisymmetric Laplace equation
1
r
∂
∂r

r∂u
∂r

+ ∂2u
∂z2 = 0,
0 ≤r < ∞,
0 < z < 1,
(9.3.84)
subject to the boundary conditions
lim
r→0 |u(r, z)| < ∞,
lim
r→∞|u(r, z)| < ∞,
u(r, 0) = 0,
(9.3.85)
and





u(r, 1) = 1,
0 < r ≤a,
u(r, 1) + uz(r, 1)
σ
= 1,
a < r < ∞.
(9.3.86)
7 See Nir, A., and R. Pfeﬀer, 1979: Transport of macromolecules across arterial wall in the presence of
local endothial injury. J. Theor. Biol., 81, 685–711.

Laplace’s Equation
401
The interesting aspect of this example is the mixture of boundary conditions along the
boundary z = 1. For r ≤a, we have a Dirichlet boundary condition, which becomes a
Robin boundary condition when r > a.
Our analysis begins as it did in the previous examples with separation of variables and
a superposition of solutions. In the present case the solution is
u(r, z) =
σz
1 + σ +
a
1 + σ
Z ∞
0
A(k, a) sinh(kz)J0(kr) dk.
(9.3.87)
The ﬁrst term on the right side of Equation 9.3.87 arises from a separation constant that
equals zero while the second term is the contribution from a negative separation constant.
Note that this equation satisﬁes all of the boundary conditions given in Equation 9.3.85.
Substitution of Equation 9.3.87 into Equation 9.3.86 leads to the dual integral equations:
a
Z ∞
0
A(k, a) sinh(k)J0(kr) dk = 1,
(9.3.88)
if 0 < r ≤a, and
Z ∞
0
A(k, a)

sinh(k) + k cosh(k)
σ

J0(kr) dk = 0,
(9.3.89)
if a < r < ∞.
What sets this problem apart from the routine separation of variables is the solution
of dual integral equations;8 in general, they are very diﬃcult to solve. The process usually
begins with ﬁnding a solution that satisﬁes Equation 9.3.89 via the orthogonality condition
involving Bessel functions. This is the technique employed by Tranter,9 who proved that
the dual integral equations:
Z ∞
0
G(λ)f(λ)J0(λa) dλ = g(a),
(9.3.90)
and
Z ∞
0
f(λ)J0(λa) dλ = 0
(9.3.91)
have the solution
f(λ) = λ1−κ
∞
X
n=0
AnJ2m+κ(λ),
(9.3.92)
if G(λ) and g(a) are known. The value of κ is chosen so that the diﬀerence G(λ) −λ2κ−2
is fairly small.
In the present case, f(λ) = sinh(λ)A(λ, a), g(a) = 1, and G(λ) = 1 +
λ coth(λ)/σ.
What is the value of κ here? Clearly we would like our solution to be valid for a wide
range of σ. Because G(λ) →1 as σ →∞, a reasonable choice is κ = 1. Therefore, we take
sinh(k)A(k, a) =
∞
X
n=1
An
1 + k coth(k)/σ J2n−1(ka).
(9.3.93)
8 The standard reference is Sneddon, I. N., 1966: Mixed Boundary Value Problems in Potential Theory.
Wiley, 283 pp.
9 Tranter, C. J., 1950: On some dual integral equations occurring in potential problems with axial
symmetry. Quart. J. Mech. Appl. Math., 3, 411–419.

402
Advanced Engineering Mathematics with MATLAB
Our ﬁnal task remains to ﬁnd An.
We begin by writing
An
1 + k coth(k)/σ J2n−1(ka) =
∞
X
m=1
Bmn J2m−1(ka),
(9.3.94)
where Bmn depends only on a and σ. Multiplying Equation 9.3.94 by the factor J2p−1(ka)
dk/k and integrating,
Z ∞
0
An
1 + k coth(k)/σ J2n−1(ka) J2p−1(ka) dk
k =
Z ∞
0
∞
X
m=1
Bnm J2m−1(ka) J2p−1(ka)dk
k .
(9.3.95)
Because10
Z ∞
0
J2n−1(ka) J2p−1(ka) dk
k =
δmp
2(2m −1),
(9.3.96)
where δmp is the Kronecker delta:
δmp =
 1,
m = p,
0,
m ̸= p,
(9.3.97)
Equation 9.3.95 reduces to
An
Z ∞
0
J2n−1(ka)J2p−1(ka)
1 + k coth(k)/σ
dk
k =
Bmn
2(2m −1).
(9.3.98)
If we deﬁne
Z ∞
0
J2n−1(ka) J2m−1(ka)
1 + k coth(k)/σ
dk
k = Smn,
(9.3.99)
then we can rewrite Equation 9.3.98 as
AnSmn =
Bmn
2(2m −1).
(9.3.100)
Because11
a
Z ∞
0
J0(kr) J2m−1(ka) dk = Pm−1

1 −2r2
a2

,
(9.3.101)
if r < a, where Pm( ) is the Legendre polynomial of order m, Equation 9.3.88 can be
rewritten
∞
X
n=1
∞
X
m=1
BmnPm−1

1 −2r2
a2

= 1.
(9.3.102)
Equation 9.3.102 follows from the substitution of Equation 9.3.93 into Equation 9.3.88
and then using Equation 9.3.101. Multiplying Equation 9.3.102 by Pm−1(ξ) dξ, integrating
10 Gradshteyn, I. S., and I. M. Ryzhik, 1965: Table of Integrals, Series, and Products. Academic Press,
Section 6.538, Formula 2.
11 Ibid., Section 6.512, Formula 4.

Laplace’s Equation
403
Table 9.3.1: The Convergence of the Coeﬃcients An Given by Equation 9.3.104 Where
Smn Has Nonzero Values for 1 ≤m, n ≤N
N
A1
−A2
A3
−A4
A5
−A6
A7
−A8
1
2.9980
2
3.1573
1.7181
3
3.2084
2.0329
1.5978
4
3.2300
2.1562
1.9813
1.4517
5
3.2411
2.2174
2.1548
1.8631
1.3347
6
3.2475
2.2521
2.2495
2.0670
1.7549
1.2399
7
3.2515
2.2738
2.3073
2.1862
1.9770
1.6597
1.1620
8
3.2542
2.2882
2.3452
2.2626
2.1133
1.8925
1.5772
1.0972
between −1 and 1, and using the orthogonality properties of the Legendre polynomial, we
have that
∞
X
n=1
Bmn
Z 1
−1
[Pm−1(ξ)]2 dξ =
Z 1
−1
Pm−1(ξ) dξ =
Z 1
−1
P0(ξ)Pm−1(ξ) dξ,
(9.3.103)
which shows that only m = 1 yields a nontrivial sum. Thus,
∞
X
n=1
Bmn = 2(2m −1)
∞
X
n=1
AnSmn = 0,
m ≥2,
(9.3.104)
and
∞
X
n=1
B1n = 2
∞
X
n=1
AnS1n = 1,
or
∞
X
n=1
SmnAn = 1
2δm1.
(9.3.105)
Thus, we have reduced the problem to the solution of an inﬁnite number of linear equations
which yield An — a common occurrence in the solution of dual integral equations. Selecting
some maximum value for n and m, say N, each term in the matrix Smn, 1 ≤m, n ≤N, is
evaluated numerically for a given value of a and σ. By inverting Equation 9.3.104, we obtain
the coeﬃcients An for n = 1, . . . , N. Because we solved a truncated version of Equation
9.3.105, they will only be approximate. To ﬁnd more accurate values, we can increase N by
1 and again invert Equation 9.3.104. In addition to the new AN+1, the previous coeﬃcients
will become more accurate. We can repeat this process of increasing N until the coeﬃcients
converge to their correct value. This is illustrated in Table 9.3.1 when σ = a = 1.
Once we have computed the coeﬃcients An necessary for the desired accuracy, we use
Equation 9.3.93 to ﬁnd A(k, a) and then obtain u(r, z) from Equation 9.3.87 via numerical
integration. Figure 9.3.6 illustrates the solution when σ = 1 and a = 2.
Mixed boundary-value problems over a ﬁnite domain can be solved in a similar manner.
Consider the partial diﬀerential equation12
∂2u
∂r2 + 1
r
∂u
∂r −u
r2 + ∂2u
∂z2 = 0,
0 ≤r < a,
0 < z < 1,
(9.3.106)
12 See Vrentas, J. S., D. C. Venerus, and C. M. Vrentes, 1991: An exact analysis of reservoir eﬀects for
rotational viscometers. Chem. Eng. Sci., 46, 33–37.

404
Advanced Engineering Mathematics with MATLAB
Figure 9.3.6: The solution of the axisymmetric Laplace’s equation, Equation 9.3.84, with u(r, 0) = 0 and
the mixed boundary condition, Equation 9.3.86. Here we have chosen σ = 1 and a = 2.
subject to the boundary conditions
lim
r→0 |u(r, z)| < ∞,
u(a, z) = 0,
0 ≤z ≤1,
(9.3.107)
and
u(r, 0) = 0,
0 ≤r ≤a,

u(r, 1) = r,
0 ≤r < 1,
uz(r, 1) = 0,
1 < r ≤a.
(9.3.108)
We begin by solving Equation 9.3.106 via separation of variables. This yields
u(r, z) =
∞
X
n=1
An sinh(knz) J1(knr),
(9.3.109)
where kn is the nth root of J1(ka) = 0. Note that Equation 9.3.109 satisﬁes all of the
boundary conditions except those along z = 1. Substituting Equation 9.3.109 into Equation
9.3.108, we ﬁnd that
∞
X
n=1
An sinh(kn) J1(knr) = r,
0 ≤r < 1,
(9.3.110)
and
∞
X
n=1
knAn cosh(kn) J1(knr) = 0,
1 < r ≤a.
(9.3.111)
Equations 9.3.110 and 9.3.111 show that in place of dual integral equations, we now have
dual Fourier-Bessel series. Cooke and Tranter13 have shown that the dual Fourier-Bessel
series
∞
X
n=1
anJν(knr) = 0,
1 < r < a,
−1 < ν,
(9.3.112)
Other examples include:
Sherwood, J. D., and H. A. Stone, 1997: Added mass of a disc accelerating within a pipe. Phys.
Fluids, 9, 3141–3148.
Galceran, J., J. Cec´ılia, E. Companys, J. Salvador, and J. Puy, 2000: Analytical expressions for
feedback currents at the scanning electrochemical microscope. J. Phys. Chem. B, 104, 7993–8000.
13 Cooke, J. C., and C. J. Tranter, 1959: Dual Fourier-Bessel series. Quart. J. Mech. Appl. Math., 12,
379–386.

Laplace’s Equation
405
Figure 9.3.7: The solution of Equation 9.3.106, which satisﬁes the boundary condition, Equation 9.3.107,
and the mixed boundary condition, Equation 9.3.108. Here we have chosen a = 2.
where Jν(kna) = 0, will be automatically satisﬁed if
k1+p/2
n
J2
ν+1(kna)an =
∞
X
m=0
bmJν+2m+1+p/2(km),
(9.3.113)
where |p| ≤1. Because an = knAn cosh(kn) and ν = 1 here, An is given by
k2
n cosh(kn)J2
2(kna)An =
∞
X
m=1
BmJ2m(kn),
(9.3.114)
if we take p = 0.
Substitution of Equation 9.3.114 into Equation 9.3.110 gives
∞
X
m=1
Bm
∞
X
n=1
sinh(kn)J2m(kn)J1(knr)
k2n cosh(kn)J2
2(kna)
= r.
(9.3.115)
Multiplying both sides of this equation by rJ1(kpr) dr, p = 1, 2, 3, . . ., and integrating from
0 to 1, we ﬁnd that
∞
X
m=1
Bm
∞
X
n=1
sinh(kn)J2m(kn)Qpn
k2n cosh(kn)J2
2(kna) =
Z 1
0
r2Jp(kpr) dr,
(9.3.116)
where
Qpn =
Z 1
0
J1(kpr)J1(knr) r dr =
( kpJ1(kn)J0(kp)−knJ1(kp)J0(kn)
k2
n−k2
p
,
n ̸= p,
J2
1 (kp)−J0(kp)J2(kp)
2
,
n = p.
(9.3.117)
Carrying out the integration, Equation 9.3.116 yields the inﬁnite set of equations
∞
X
m=1
MpmBm = J2(kp)
kp
,
(9.3.118)
where
Mpm =
∞
X
n=1
sinh(kn)J2m(kn)Qpn
k2n cosh(kn)J2
2(kna) .
(9.3.119)
Once again, we compute Bm by truncating Equation 9.3.118 to M terms and inverting the
systems of equations. Increasing the value of M yields more accurate results. Once we have
Bm, we use Equation 9.3.114 to ﬁnd An. Finally, u(r, z) follows from Equation 9.3.109.
Figure 9.3.7 illustrates u(r, z) when a = 2.
⊓⊔

406
Advanced Engineering Mathematics with MATLAB
• Example 9.3.7
Let us ﬁnd the potential at any point P within a conducting sphere of radius a. At the
surface, the potential is held at V0 in the hemisphere 0 < θ < π/2, and −V0 for π/2 < θ < π.
Laplace’s equation in spherical coordinates is
∂
∂r

r2 ∂u
∂r

+
1
sin(θ)
∂
∂θ

sin(θ)∂u
∂θ

= 0,
0 ≤r < a,
0 ≤θ ≤π.
(9.3.120)
To solve Equation 9.3.120 we set u(r, θ) = R(r)Θ(θ) by separation of variables. Substituting
into this equation, we have that
1
R
d
dr

r2 dR
dr

= −
1
sin(θ)Θ
d
dθ

sin(θ)dΘ
dθ

= k2,
(9.3.121)
or
r2R′′ + 2rR′ −k2R = 0,
(9.3.122)
and
1
sin(θ)
d
dθ

sin(θ)dΘ
dθ

+ k2Θ = 0.
(9.3.123)
A common substitution replaces θ with µ = cos(θ). Then, as θ varies from 0 to π, µ varies
from 1 to −1. With this substitution, Equation 9.3.123 becomes
d
dµ

(1 −µ2)dΘ
dµ

+ k2Θ = 0.
(9.3.124)
This is Legendre’s equation, which we examined in Section 6.4. Consequently, because the
solution must remain ﬁnite at the poles, k2 = n(n + 1), and
Θn(θ) = Pn(µ) = Pn[cos(θ)],
(9.3.125)
where n = 0, 1, 2, 3, . . ..
Turning to Equation 9.3.122, this equation is the equidimensional or Euler-Cauchy
linear diﬀerential equation. One method of solving this equation consists of introducing a
new independent variable s so that r = es, or s = ln(r). Because
d
dr = ds
dr
d
ds = e−s d
ds,
(9.3.126)
it follows that
d2
dr2 = d
dr

e−s d
ds

= e−s d
ds

e−s d
ds

= e−2s
 d2
ds2 −d
ds

.
(9.3.127)
Substituting into Equation 9.3.122,
d2Rn
ds2
+ dRn
ds −n(n + 1)Rn = 0.
(9.3.128)
Equation 9.3.128 is a second-order, constant coeﬃcient ordinary diﬀerential equation, which
has the solution
Rn(s) = Cnens + Dne−(n+1)s = Cn exp[n ln(r)] + Dn exp[−(n + 1) ln(r)]
(9.3.129)
= Cn exp[ln(rn)] + Dn exp[ln(r−1−n)] = Cnrn + Dnr−1−n.
(9.3.130)

Laplace’s Equation
407
A more convenient form of the solution is
Rn(r) = An
r
a
n
+ Bn
r
a
−1−n
,
(9.3.131)
where An = anCn and Bn = Dn/an+1. We introduced the constant a, the radius of the
sphere, to simplify future calculations.
Using the results from Equation 9.3.125 and Equation 9.3.130, the solution to Laplace’s
equation in axisymmetric problems is
u(r, θ) =
∞
X
n=0

An
r
a
n
+ Bn
r
a
−1−n
Pn[cos(θ)].
(9.3.132)
In our particular problem we must take Bn = 0 because the solution becomes inﬁnite at
r = 0 otherwise. If the problem had involved the domain a < r < ∞, then An = 0 because
the potential must remain ﬁnite as r →∞.
Finally, we must evaluate An. Finding the potential at the surface,
u(a, µ) =
∞
X
n=0
AnPn(µ) =

V0,
0 < µ ≤1,
−V0,
−1 ≤µ < 0.
(9.3.133)
Upon examining Equation 9.3.133, it is merely an expansion in Legendre polynomials of
the function
f(µ) =

V0,
0 < µ ≤1,
−V0,
−1 ≤µ < 0.
(9.3.134)
Consequently, from Equation 9.3.133,
An = 2n + 1
2
Z 1
−1
f(µ) Pn(µ) dµ.
(9.3.135)
Because f(µ) is an odd function, An = 0 if n is even. When n is odd, however,
An = (2n + 1)
Z 1
0
V0 Pn(µ) dµ.
(9.3.136)
We can further simplify Equation 9.3.136 by using the relationship that
Z 1
x
Pn(t) dt =
1
2n + 1 [Pn−1(x) −Pn+1(x)] ,
(9.3.137)
where n ≥1. In our problem, then,
An =

V0[Pn−1(0) −Pn+1(0)],
n odd,
0,
n even.
(9.3.138)
The ﬁrst few terms are A1 = 3V0/2, A3 = −7V0/8, and A5 = 11V0/16.
Figure 9.3.8 illustrates our solution. It was created using the MATLAB script
clear
N = 51; dr = 0.05; dtheta = pi / 15;
% compute grid and set solution equal to zero
r = [0:dr:1]; theta = [0:dtheta:2*pi];

408
Advanced Engineering Mathematics with MATLAB
−1
0
1
−1
−0.5
0
0.5
1
−1.5
−1
−0.5
0
0.5
1
1.5
Z
X
u(R,θ )
Figure 9.3.8: Electrostatic potential within a conducting sphere when the upper hemispheric surface has
the potential 1 and the lower surface has the potential −1.
mu = cos(theta); Z = r’ * mu;
for L = 1:2
if L == 1 X = r’ * sin(theta);
else X = -r’ * sin(theta); end
u = zeros(size(X));
% compute solution from Equation 9.3.132
rfactor = r;
for n = 1:2:N
A = legendre(n-1,0); B = legendre(n+1,0); coeff = A(1)-B(1);
C = legendre(n,mu); Theta = C(1,:);
u = u + coeff * rfactor’ * Theta;
rfactor = rfactor .* r .* r;
end
surf(Z,X,u); hold on; end
xlabel(’Z’,’Fontsize’,20); ylabel(’X’,’Fontsize’,20)
zlabel(’u(R,\theta )’,’Fontsize’,20);
Here we have the convergence of the equipotentials along the equator and at the surface.
The slow rate at which the coeﬃcients are approaching zero suggests that the solution
suﬀers from Gibbs phenomena along the surface.
⊓⊔
• Example 9.3.8
We now ﬁnd the steady-state temperature ﬁeld within a metallic sphere of radius a,
which we place in direct sunlight and allow to radiatively cool. This classic problem, ﬁrst
solved by Rayleigh,14 requires the use of spherical coordinates with its origin at the center
14 Rayleigh, J. W., 1870: On the values of the integral R 1
0 QnQn′ dµ, Qn, Qn′ being Laplace’s coeﬃcients
of the orders n, n′, with application to the theory of radiation. Philos. Trans. R. Soc. London, Ser. A,
160, 579–590.

Laplace’s Equation
409
of the sphere and its z-axis pointing toward the sun. With this choice for the coordinate
system, the incident sunlight is
D(θ) =

D(0) cos(θ),
0 ≤θ ≤π/2,
0,
π/2 ≤θ ≤π.
(9.3.139)
If heat dissipation takes place at the surface r = a according to Newton’s law of
cooling and the temperature of the surrounding medium is zero, the solar heat absorbed by
the surface dA must balance the Newtonian cooling at the surface plus the energy absorbed
into the sphere’s interior. This physical relationship is
(1 −ρ)D(θ) dA = ǫu(a, θ) dA + κ∂u(a, θ)
∂r
dA,
(9.3.140)
where ρ is the reﬂectance of the surface (the albedo), ǫ is the surface conductance or
coeﬃcient of surface heat transfer, and κ is the thermal conductivity. Simplifying Equation
9.3.140, we have that
∂u(a, θ)
∂r
= 1 −ρ
κ
D(θ) −ǫ
κu(a, θ)
(9.3.141)
for r = a.
If the sphere has reached thermal equilibrium, Laplace’s equation describes the tem-
perature ﬁeld within the sphere. In the previous example, we showed that the solution to
Laplace’s equation in axisymmetric problems is
u(r, θ) =
∞
X
n=0

An
r
a
n
+ Bn
r
a
−1−n
Pn[cos(θ)].
(9.3.142)
In this problem, Bn = 0 because the solution would become inﬁnite at r = 0 otherwise.
Therefore,
u(r, θ) =
∞
X
n=0
An
r
a
n
Pn[cos(θ)].
(9.3.143)
Diﬀerentiation gives
∂u
∂r =
∞
X
n=0
An
nrn−1
an
Pn[cos(θ)].
(9.3.144)
Substituting into the boundary condition leads to
∞
X
n=0
An
n
a + ǫ
κ

Pn[cos(θ)] =
1 −ρ
κ

D(θ),
(9.3.145)
or
D(µ) =
∞
X
n=0
 nκ + ǫa
a(1 −ρ)

AnPn(µ) =
∞
X
n=0
CnPn(µ),
(9.3.146)
where
Cn =
 nκ + ǫa
a(1 −ρ)

An,
and
µ = cos(θ).
(9.3.147)
We determine the coeﬃcients by
Cn = 2n + 1
2
Z 1
−1
D(µ)Pn(µ) dµ = 2n + 1
2
D(0)
Z 1
0
µPn(µ) dµ.
(9.3.148)

410
Advanced Engineering Mathematics with MATLAB
−1
−0.5
0
0.5
1
−1
−0.5
0
0.5
1
59
59.5
60
60.5
61
61.5
62
Z
X
U(R,θ )
Figure 9.3.9: The diﬀerence (in ◦C) between the temperature ﬁeld within a blackened iron surface of
radius 0.1 m and the surrounding medium when we heat the surface by sunlight and allow it to radiatively
cool.
Evaluation of the ﬁrst few coeﬃcients gives
A0 = (1 −ρ)D(0)
4ǫ
,
A1 = a(1 −ρ)D(0)
2(κ + ǫa)
,
A2 = 5a(1 −ρ)D(0)
16(2κ + ǫa) ,
A3 = 0,
(9.3.149)
A4 = −3a(1 −ρ)D(0)
32(4κ + ǫa) ,
A5 = 0,
A6 = 13a(1 −ρ)D(0)
256(6κ + ǫa) ,
A7 = 0,
(9.3.150)
A8 = −17a(1 −ρ)D(0)
512(8κ + ǫa) ,
A9 = 0,
and
A10 = 49a(1 −ρ)D(0)
2048(10κ + ǫa) .
(9.3.151)
Figure 9.3.9 illustrates the temperature ﬁeld within the sphere with D(0) = 1200 W/m2,
κ = 45 W/m K, ǫ = 5 W/m2 K, ρ = 0, and a = 0.1 m. This corresponds to a cast iron
sphere with blackened surface in sunlight. This ﬁgure was created by the MATLAB script
clear
dr = 0.05; dtheta = pi / 15;
D 0 = 1200; kappa = 45; epsilon = 5; rho = 0; a = 0.1;
% compute grid and set solution equal to zero
r = [0:dr:1]; theta = [0:dtheta:pi];
mu = cos(theta); Z = r’ * mu;
aaaa = (1-rho) * D 0 / ( 4 * epsilon);
aa(1) = a * (1-rho) * D 0 / ( 2 * ( kappa+epsilon*a));
aa(2) = 5 * a * (1-rho) * D 0 / ( 16 * (2*kappa+epsilon*a));
aa(3) = 0;
aa(4) = - 3 * a * (1-rho) * D 0 / ( 32 * (4*kappa+epsilon*a));
aa(5) = 0;
aa(6) = 13 * a * (1-rho) * D 0 / ( 256 * (6*kappa+epsilon*a));
aa(7) = 0;
aa(8) = -17 * a * (1-rho) * D 0 / ( 512 * (8*kappa+epsilon*a));

Laplace’s Equation
411
θ
q
a
a
r0
s
r
s
P(r, )
Figure 9.3.10: Point charge +q in the presence of a grounded conducting sphere.
aa(9) = 0;
aa(10) = 49 * a * (1-rho) * D 0 / (2048 * (10*kappa+epsilon*a));
for L = 1:2
if L == 1 X = r’ * sin(theta);
else X = -r’ * sin(theta); end
u = aaaa * ones(size(X));
rfactor = r;
for n = 1:10
A = legendre(n,mu); Theta = A(1,:);
u = u + aa(n) * rfactor’ * Theta;
rfactor = rfactor .* r;
end
surf(Z,X,u); hold on; end
xlabel(’Z’,’Fontsize’,20); ylabel(’X’,’Fontsize’,20);
zlabel(’U(R,\theta )’,’Fontsize’,20);
The temperature is quite warm with the highest temperature located at the position where
the solar radiation is largest; the coolest temperatures are located in the shadow region. ⊓⊔
• Example 9.3.9
In this example we ﬁnd the potential at any point P exterior to a conducting, grounded
sphere centered at z = 0 after we place a point charge +q at z = a on the z-axis. See Figure
9.3.10. From the principle of linear superposition, the total potential u(r, θ) equals the sum
of the potential from the point charge and the potential v(r, θ) due to the induced charge
on the sphere
u(r, θ) = q
s + v(r, θ).
(9.3.152)

412
Advanced Engineering Mathematics with MATLAB
In common with the ﬁrst term q/s, v(r, θ) must be a solution of Laplace’s equation. In
Example 9.3.7 we showed that the general solution to Laplace’s equation in axisymmetric
problems is
v(r, θ) =
∞
X
n=0

An
 r
r0
n
+ Bn
 r
r0
−1−n
Pn[cos(θ)].
(9.3.153)
Because the solutions must be valid anywhere outside of the sphere, An = 0; otherwise, the
solution would not remain ﬁnite as r →∞. Hence,
v(r, θ) =
∞
X
n=0
Bn
 r
r0
−1−n
Pn[cos(θ)].
(9.3.154)
We determine the coeﬃcient Bn by the condition that u(r0, θ) = 0, or
q
s

on sphere +
∞
X
n=0
BnPn[cos(θ)] = 0.
(9.3.155)
We need to expand the ﬁrst term on the left side of Equation 9.3.155 in terms of
Legendre polynomials. From the law of cosines,
s =
p
r2 + a2 −2ar cos(θ).
(9.3.156)
Consequently, if a > r, then
1
s = 1
a

1 −2 cos(θ)r
a +
r
a
2−1/2
.
(9.3.157)
In Section 6.4, we showed that
(1 −2xz + z2)−1/2 =
∞
X
n=0
Pn(x)zn.
(9.3.158)
Therefore,
1
s = 1
a
∞
X
n=0
Pn[cos(θ)]
r
a
n
.
(9.3.159)
From Equation 9.3.155,
∞
X
n=0
hq
a
r0
a
n
+ Bn
i
Pn[cos(θ)] = 0.
(9.3.160)
We can only satisfy Equation 9.3.160 if the square-bracketed term vanishes identically so
that
Bn = −q
a
r0
a
n
.
(9.3.161
On substituting Equation 9.3.161 back into Equation 9.3.154,
v(r, θ) = −qr0
ra
∞
X
n=0
 r2
0
ar
n
Pn[cos(θ)].
(9.3.162)

Laplace’s Equation
413
−3
−2
−1
0
1
2
3
−3
−2
−1
0
1
2
3
X
Z
0.3
0.4
0.6
Figure 9.3.11: Electrostatic potential outside of a grounded conducting sphere in the presence of a point
charge located at a/r0 = 2. Contours are in units of −q/r0.
The physical interpretation of Equation 9.3.162 is as follows: Consider a point, such as
a′ (see Figure 9.3.10) on the z-axis. If r > a′, the Legendre expansion of 1/s′ is
1
s′ = 1
r
∞
X
n=0
Pn[cos(θ)]
a′
r
n
,
r > a′.
(9.3.163)
Using Equation 9.3.163, we can rewrite it as
v(r, θ) = −qr0
as′ ,
(9.3.164)
if we set a′ = r2
0/a. Our ﬁnal result is then
u(r, θ) = q
s −q′
s′ ,
(9.3.165)
provided that q′ equals r0q/a. In other words, when we place a grounded conducting sphere
near a point charge +q, it changes the potential in the same manner as would a point charge
of the opposite sign and magnitude q′ = r0q/a, placed at the point a′ = r2
0/a. The charge
q′ is the image of q.
Figure 9.3.11 illustrates the solution, Equation 9.3.162, and was created using the
MATLAB script
clear
a over r0 = 2;
% set up x-z array
dx = 0.02; x = -3:dx:3; dz = 0.02; z = -3:dz:3;
u = 1000 * zeros(length(x),length(z));
X = x’ * ones(1,length(z)); Z = ones(length(x),1) * z;
% compute r and theta

414
Advanced Engineering Mathematics with MATLAB
rr = sqrt(X .* X + Z .* Z);
theta = atan2(X,Z);
% find the potential
r over aprime = a over r0 * rr;
s = 1 + r over aprime .* r over aprime ...
- 2 * r over aprime .* cos(theta);
for j = 1:length(z); for i = 1:length(x);
if rr(i,j) >= 1; u(i,j) = 1 ./ sqrt(s(i,j)); end;
end; end
% plot the solution
[cs,h] = contourf(X,Z,u); colormap(hot); brighten(hot,0.5);
axis square; clabel(cs,h,’manual’,’Fontsize’,16);
xlabel(’X’,’Fontsize’,20); ylabel(’Z’,’Fontsize’,20);
Because the charge is located directly above the sphere, the electrostatic potential for any
ﬁxed r is largest at the point θ = 0 and weakest at θ = π.
⊓⊔
• Example 9.3.10: Poisson’s integral formula
In this example we ﬁnd the solution to Laplace’s equation within a unit disc. The
problem can be posed as
∂2u
∂r2 + 1
r
∂u
∂r + 1
r2
∂2u
∂ϕ2 = 0,
0 ≤r < 1,
0 ≤ϕ ≤2π,
(9.3.166)
with the boundary condition u(1, ϕ) = f(ϕ).
We begin by assuming the separable solution u(r, ϕ) = R(r)Φ(ϕ) so that
r2R′′ + rR′
R
= −Φ′′
Φ = k2.
(9.3.167)
The solution to Φ′′ + k2Φ = 0 is
Φ(ϕ) = A cos(kϕ) + B sin(kϕ).
(9.3.168)
The solution to R(r) is
R(r) = Crk + Dr−k.
(9.3.169)
Because the solution must be bounded for all r and periodic in ϕ, we must take D = 0 and
k = n, where n = 0, 1, 2, 3, . . .. Then, the most general solution is
u(r, ϕ) = 1
2a0 +
∞
X
n=1
[an cos(nϕ) + bn sin(nϕ)] rn,
(9.3.170)
where an and bn are chosen to satisfy
u(1, ϕ) = f(ϕ) = 1
2a0 +
∞
X
n=1
an cos(nϕ) + bn sin(nϕ).
(9.3.171)
Because
an = 1
π
Z π
−π
f(θ) cos(nθ) dθ,
bn = 1
π
Z π
−π
f(θ) sin(nθ) dθ,
(9.3.172)

Laplace’s Equation
415
we may write u(r, ϕ) as
u(r, ϕ) = 1
π
Z π
−π
f(θ)
(
1
2 +
∞
X
n=1
rn cos[n(θ −ϕ)]
)
dθ.
(9.3.173)
If we let α = θ −ϕ, and z = r[cos(α) + i sin(α)], then
∞
X
n=0
rn cos(nα) = ℜ
 ∞
X
n=0
zn
!
= ℜ

1
1 −z

= ℜ

1
1 −r cos(α) −ir sin(α)

(9.3.174)
= ℜ
1 −r cos(α) + ir sin(α)
1 −2r cos(α) + r2

(9.3.175)
for all r such that |r| < 1. Consequently,
∞
X
n=0
rn cos(nα) =
1 −r cos(α)
1 −2r cos(α) + r2
(9.3.176)
1
2 +
∞
X
n=1
rn cos(nα) =
1 −r cos(α)
1 −2r cos(α) + r2 −1
2
(9.3.177)
= 1
2
1 −r2
1 −2r cos(α) + r2 .
(9.3.178)
Substituting Equation 9.3.178 into Equation 9.3.173, we ﬁnally have that
u(r, ϕ) = 1
2π
Z π
−π
f(θ)
1 −r2
1 −2r cos(θ −ϕ) + r2 dθ.
(9.3.179)
This solution to Laplace’s equation within the unit circle is referred to as Poisson’s integral
formula.15
Problems
Rectangular Coordinates
Solve Laplace’s equation over the rectangular region 0 < x < a, 0 < y < b with the following
boundary conditions. Illustrate your solution using MATLAB.
1. u(x, 0) = u(x, b) = u(a, y) = 0, u(0, y) = 1
2. u(x, 0) = u(0, y) = u(a, y) = 0, u(x, b) = x
3. u(x, 0) = u(0, y) = u(a, y) = 0, u(x, b) = x −a
4. u(x, 0) = u(0, y) = u(a, y) = 0,
15 Poisson, S. D., 1820: M´emoire sur la mani`ere d’exprimer les fonctions par des s´eries de quantit´es
p´eriodiques, et sur l’usage de cette transformation dans la r´esolution de diﬀ´erens probl`emes.
J. ´Ecole
Polytech., 18, 417–489.

416
Advanced Engineering Mathematics with MATLAB
u(x, b) =

2x/a,
0 < x < a/2,
2(a −x)/a,
a/2 < x < a.
5. ux(0, y) = u(a, y) = u(x, 0) = 0, u(x, b) = 1
6. uy(x, 0) = u(x, b) = u(a, y) = 0, u(0, y) = 1
7. uy(x, 0) = uy(x, b) = 0, u(0, y) = u(a, y) = 1
8. ux(a, y) = uy(x, b) = 0, u(0, y) = u(x, 0) = 1
9. uy(x, 0) = u(x, b) = 0, u(0, y) = u(a, y) = 1
10. u(a, y) = u(x, b) = 0, u(0, y) = u(x, 0) = 1
11. ux(0, y) = 0, u(a, y) = u(x, 0) = u(x, b) = 1
12. ux(0, y) = ux(a, y) = 0, u(x, b) = u1,
u(x, 0) =

f(x),
0 < x < α,
0,
α < x < a.
13.
Variations in the earth’s surface temperature can arise as a result of topographic
undulations and the altitude dependence of the atmospheric temperature. These variations,
in turn, aﬀect the temperature within the solid earth. To show this, solve Laplace’s equation
with the surface boundary condition that
u(x, 0) = T0 + ∆T cos(2πx/λ),
where λ is the wavelength of the spatial temperature variation. What must be the condition
on u(x, y) as we go towards the center of the earth (i.e., y →∞)?
14. T´oth16 generalized his earlier analysis of groundwater in an aquifer when the water
table follows the topography.
Find the groundwater potential if it varies as u(x, z0) =
g[z0 + cx + a sin(bx)] at the surface y = z0, while ux(0, y) = ux(L, y) = uy(x, 0) = 0, where
g is the acceleration due to gravity. Assume that bL ̸= nπ, where n = 1, 2, 3, . . ..
15. During his study of ﬂuid ﬂow within a packed bed, Grossman17 solved
∂2u
∂x2 + ∂2u
∂y2 = 0,
0 < x < 1,
0 < y < L,
subject to the boundary conditions
u(x, 0) = L,
u(x, L) = 0,
0 < x < 1,
and
ux(0, y) = 0,
ux(1, y) = −γ,
0 < y < L.
16 T´oth, J. A., 1963: A theoretical analysis of groundwater ﬂow in small drainage basins. J. Geophys.
Res., 68, 4795–4812.
17 Grossman, G., 1975: Stresses and friction forces in moving packed beds. AICHE J., 21, 720–730.

Laplace’s Equation
417
What should he have found? Hint: Introduce u(x, y) = L −y + γv(x, y).
Cylindrical Coordinates in Finite Domains
16. Solve
∂2u
∂r2 + 1
r
∂u
∂r + ∂2u
∂z2 = 0,
0 ≤r < a,
−L < z < L,
with
u(a, z) = 0,
and
∂u(r, −L)
∂z
= ∂u(r, L)
∂z
= 1.
17.
During their study of the role that diﬀusion plays in equalizing gas concentrations
within that portion of the lung that is connnected to terminal bronchioles, Chang et al.18
solved Laplace’s equation in cylindrical coordinates
∂2u
∂r2 + 1
r
∂u
∂r + ∂2u
∂z2 = 0,
0 ≤r < b,
−L < z < L,
subject to the boundary conditions that
lim
r→0 |u(r, z)| < ∞,
∂u(b, z)
∂r
= 0,
−L < z < L,
and
∂u(r, −L)
∂z
= ∂u(r, L)
∂z
=

A,
0 ≤r < a,
0,
a < r < b.
What should they have found?
18. Solve19
∂2u
∂r2 + 1
r
∂u
∂r + ∂2u
∂z2 = 0,
0 ≤r < b,
0 < z < L,
with the boundary conditions
lim
r→0 |u(r, z)| < ∞,
∂u(b, z)
∂r
= 0,
0 ≤z ≤L,
u(r, L) = A,
0 ≤r ≤b,
and
∂u(r, 0)
∂z
=

B,
0 ≤r < a,
0,
a < r < b.
19. Solve
∂2u
∂r2 + 1
r
∂u
∂r + ∂2u
∂z2 = 0,
0 ≤r < a,
0 < z < h,
18 Chang, D. B., S. M. Lewis, and A. C. Young, 1976: A theoretical discussion of diﬀusion and convection
in the lung. Math. Biosci., 29, 331–349.
19 See Keller, K. H., and T. R. Stein, 1967: A two-dimensional analysis of porous membrane transfer.
Math. Biosci., 1, 421–437.

418
Advanced Engineering Mathematics with MATLAB
with
∂u(a, z)
∂r
= u(r, h) = 0
and
∂u(r, 0)
∂z
=
 1,
0 ≤r < r0,
0,
r0 < r < a.
20. Solve
∂2u
∂r2 + 1
r
∂u
∂r + ∂2u
∂z2 = 0,
0 ≤r < 1,
0 < z < d,
with
∂u(1, z)
∂r
= ∂u(r, 0)
∂z
= 0,
and
u(r, d) =

−1,
0 ≤r < a,
b < r < 1,
1/(b2 −a2) −1,
a < r < b.
21. Solve20
∂2u
∂r2 + 1
r
∂u
∂r −u
r2 + ∂2u
∂z2 = 0,
0 ≤r < 1,
0 < z < 1.
Take for the boundary conditions either (a)
lim
r→0 |u(r, z)| < ∞,
u(1, z) = −1,
0 < z < 1,
and
uz(r, 0) = u(r, 1) = 0,
0 < r < 1;
or (b)
lim
r→0 |u(r, z)| < ∞,
u(1, z) = 0,
0 < z < 1,
and
uz(r, 0) = 0,
u(r, 1) = r,
0 < r < 1.
22. Solve
∂2u
∂r2 + 1
r
∂u
∂r −u
r2 + ∂2u
∂z2 = 0,
0 ≤r < a,
0 < z < h,
with
lim
r→0 |u(r, z)| < ∞,
u(a, z) = 0,
0 < z < h,
and
u(r, 0) = 0,
uz(r, h) = Ar,
0 ≤r < a.
23. Solve
∂2u
∂r2 + 1
r
∂u
∂r −u
r2 + ∂2u
∂z2 = 0,
0 ≤r < a,
0 < z < 1,
20 See Muite, B. K., 2004: The ﬂow in a cylindrical container with a rotating end wall at small but ﬁnite
Reynolds number. Phys. Fluids, 16, 3614–3626.

Laplace’s Equation
419
with
lim
r→0 |u(r, z)| < ∞,
u(a, z) = z,
0 < z < 1,
and
u(r, 0) = u(r, 1) = 0,
0 ≤r < a.
24. Solve
∂2u
∂r2 + 1
r
∂u
∂r −u
r2 + ∂2u
∂z2 = 0,
0 ≤r < a,
0 < z < h,
with
lim
r→0 |u(r, z)| < ∞,
∂u(a, z)
∂r
= 0,
0 < z < h,
and
u(r, 0) = 0,
∂u(r, h)
∂z
= r,
0 ≤r < a.
25. Solve
∂2u
∂r2 + 1
r
∂u
∂r −u
r2 + ∂2u
∂z2 = 0,
0 ≤r < 1,
−a < z < a,
with the boundary conditions
lim
r→0 |u(r, z)| < ∞,
∂u(1, z)
∂r
= u(1, z),
−a < z < a,
and
−∂u(r, −a)
∂z
= ∂u(r, a)
∂z
= r,
0 ≤r < 1.
26. Solve21
∂2u
∂r2 + 1
r
∂u
∂r + ∂2u
∂z2 −u = 0,
0 ≤r < 1,
0 < z < L,
subject to the boundary conditions that
lim
r→0 |u(r, z)| < ∞,
ur(1, z) = −h u(1, z),
0 < z < L,
and
u(r, 0) = u0,
u(r, L) = 0,
0 ≤r < 1,
using the Fourier-Bessel series
u(r, z) =
∞
X
n=1
AnZn(z)J0(knr)
where kn is the nth root of k J′
0(k) + h J0(k) = h J0(k) −k J1(k) = 0.
21 See Stripp, K. F., and A. R. Moore, 1955: The eﬀects of junction shape and surface recombination on
transistor current gain – Part II. Proc. IRE, 43, 856–866.

420
Advanced Engineering Mathematics with MATLAB
27. Solve22 Laplace’s equation in cylindrical coordinates
∂2u
∂r2 + 1
r
∂u
∂r + ∂2u
∂z2 = 0,
0 ≤r < a,
0 < z < L,
subject to the boundary conditions that
lim
r→0 |u(r, z)| < ∞,
−Dur(a, z) = Ku(a, z),
0 < z < L,
and
u(r, 0) = u0,
uz(r, L) = 0,
0 ≤r < a.
28. Solve23 the partial diﬀerential equation
∂2u
∂r2 + 1
r
∂u
∂r + ∂2u
∂z2 = a2u,
0 ≤r < 1,
0 < z < 1,
subject to the boundary conditions that
lim
r→0 |u(r, z)| < ∞,
u(1, z) = 1,
0 < z < 1,
and
u(r, 0) = 1,
u(r, 1) = 1,
0 ≤r < 1.
Hint: Break the problem into three parts: u(r, z) = u1(r, z) + u2(r, z) + u3(r, z), where
∂2u1
∂r2 + 1
r
∂u1
∂r + ∂2u1
∂z2 = a2u1,
0 ≤r < 1,
0 < z < 1,
subject to the boundary conditions that
lim
r→0 |u1(r, z)| < ∞,
u1(1, z) = 1,
0 < z < 1,
and
u1(r, 0) = 0,
u1(r, 1) = 0,
0 ≤r < 1;
∂2u2
∂r2 + 1
r
∂u2
∂r + ∂2u2
∂z2 = a2u2,
0 ≤r < 1,
0 < z < 1,
subject to the boundary conditions that
lim
r→0 |u2(r, z)| < ∞,
u2(1, z) = 0,
0 < z < 1,
22 See Bischoﬀ, K. B., 1966: Transverse diﬀusion in catalyst pores. Indust. Engng. Chem. Fund., 5,
135–136.
23 See Gunn, D. J., 1967: Diﬀusion and chemical reaction in catalysis and absorption. Chem. Engng.
Sci., 22, 1439–1455; Ho, T. C., and G. C. Hsiao, 1977: Estimation of the eﬀectiveness factor for a cylindrical
catalyst support: A singular perturbation approach. Chem. Engng. Sci., 32, 63–66.

Laplace’s Equation
421
and
u2(r, 0) = 1,
u2(r, 1) = 0,
0 ≤r < 1;
and
∂2u3
∂r2 + 1
r
∂u3
∂r + ∂2u3
∂z2 = a2u3,
0 ≤r < 1,
0 < z < 1,
subject to the boundary conditions that
lim
r→0 |u3(r, z)| < ∞,
u3(1, z) = 0,
0 < z < 1,
and
u3(r, 0) = 0,
u3(r, 1) = 0,
0 ≤r < 1.
Cylindrical Coordinates on Inﬁnite and Semi-Inﬁnite Domains
29. Solve24 Laplace’s equation in cylindrical coordinates
∂2u
∂r2 + 1
r
∂u
∂r + ∂2u
∂z2 = 0,
0 ≤r < a,
−∞< z < ∞,
subject to the boundary conditions that
lim
r→0 |u(r, z)| < ∞,
u(a, z) =

−V,
|z| < d/2,
0,
|z| > d/2,
and
lim
|z|→∞u(r, z) →0,
0 ≤r < a.
Hint: Show that the solution can be written
u(r, z) = −V +
∞
X
n=1
An cosh
knz
a

J0
knr
a

,
|z| < d/2,
and
u(r, z) =
∞
X
n=1
Bn exp

−kn|z|
a

J0
knr
a

,
|z| > d/2
with the additional conditions that
u(r, d−/2) = u(r, d+/2) and uz(r, d−/2) = uz(r, d+/2),
0 ≤r < a,
where kn is the nth root of J0(k) = 0. Then ﬁnd An and Bn.
30. Solve Laplace’s equation in cylindrical coordinates
∂2u
∂r2 + 1
r
∂u
∂r + ∂2u
∂z2 = 0,
0 ≤r < b,
0 < z < ∞,
24 See Striﬄer, C. D., C. A. Kapetanakos, and R. C. Davidson, 1975: Equilibrium properties of a rotating
nonneutral E layer in a coupled magnetic ﬁeld. Phys. Fluids, 18, 1374–1382.

422
Advanced Engineering Mathematics with MATLAB
subject to the boundary conditions that
lim
r→0 |u(r, z)| < ∞,
∂u(b, z)
∂r
= 0,
0 < z < ∞,
and
lim
z→∞|u(r, z)| < ∞,
u(r, 0) =

A,
0 ≤r < a,
0,
a < r < b.
31. Solve25
∂2u
∂r2 + 1
r
∂u
∂r + ∂2u
∂z2 −∂u
∂z = 0,
0 ≤r < 1,
0 < z < ∞,
with the boundary conditions
lim
r→0 |u(r, z)| < ∞,
∂u(1, z)
∂r
= −Bu(1, z),
0 < z,
and
u(r, 0) = 1,
lim
z→∞|u(r, z)| < ∞,
0 ≤r < 1,
where B is a constant.
32. Solve26
∂2u
∂r2 + 1
r
∂u
∂r + ∂2u
∂z2 −1
H
∂u
∂z = 0,
0 ≤r < b,
0 < z < ∞,
with the boundary conditions
lim
r→0 |u(r, z)| < ∞,
∂u(b, z)
∂r
= −hu(b, z),
0 < z,
lim
z→∞|u(r, z)| < ∞,
0 ≤r < b,
and
u(r, 0)
H
−uz(r, 0) =

Q,
0 ≤r < a,
0,
a ≤r < b,
where b > a.
Mixed Boundary-Value Problems
33. Solve27
∂2u
∂r2 + 1
r
∂u
∂r + ∂2u
∂z2 = 0,
0 ≤r < ∞,
0 < z < ∞,
25 See Kern, J., and J. O. Hansen, 1976: Transient heat conduction in cylindrical systems with an axially
moving boundary. Int. J. Heat Mass Transfer, 19, 707–714.
26 See Smirnova, E. V., and I. A. Krinberg, 1970: Spatial distribution of the atoms of an impurity element
in an arc discharge. I. J. Appl. Spectroscopy, 13, 859–864.
27 See Fleischmann, M., and S. Pons, 1987: The behavior of microdisk and microring electrodes.
J.
Electroanal. Chem., 222, 107–115.

Laplace’s Equation
423
subject to the boundary conditions
lim
r→0 |u(r, z)| < ∞,
lim
r→∞|u(r, z)| < ∞,
0 < z < ∞,
lim
z→∞u(r, z) →u∞,
0 ≤r < ∞,
and the mixed boundary condition

u(r, 0) = u∞−∆u,
0 ≤r < a,
uz(r, 0) = 0,
a ≤r < ∞,
where u∞and ∆u are constants.
Step 1: Show that
u(r, z) = u∞−
Z ∞
0
A(k)e−kzJ0(kr) dk
satisﬁes the partial diﬀerential equation and the boundary conditions as r →0, r →∞,
and z →∞.
Step 2: Show that
Z ∞
0
kA(k)J0(kr) dk = 0,
a < r < ∞.
Step 3: Using the relationship28
Z ∞
0
sin(ka)J0(kr) dk =

(a2 −r2)−1
2 ,
r < a,
0,
r > a.
show that kA(k) = C sin(ka).
Step 4: Using the relationship29
Z ∞
0
sin(ka)J0(kr) dk
k =

π/2,
r ≤a,
sin−1(a/r),
r ≥a,
show that
u(r, z) = u∞−2∆u
π
Z ∞
0
e−kz sin(ka)J0(kr) dk
k .
34. Solve Laplace’s equation30
∂2u
∂x2 + ∂2u
∂y2 = 0,
−∞< x < ∞,
0 < y < ∞,
28 Gradshteyn and Ryzhik, op. cit., Section 6.671, Formula 7.
29 Ibid., Section 6.693, Formula 1 with ν = 0.
30 See Yang, F.-Q., and J. C. M. Li, 1995: Impression and diﬀusion creep of anisotropic media. J. Appl.
Phys., 77, 110–117.
See also Shindo, Y., H. Tamura, and Y. Atobe, 1990: Transient singular stresses
of a ﬁnite crack in an elastic conductor under electromagnetic force (in Japanese). Nihon Kikai Gakkai
Rombunshu (Trans. Japan Soc. Mech. Engrs.), Ser. A, 56, 278–282.

424
Advanced Engineering Mathematics with MATLAB
−3
−2
−1
0
1
2
3
0
0.5
1
1.5
2
2.5
3
−1
−0.8
−0.6
−0.4
−0.2
0
x
y
u(x,y)
Problem 34
with the boundary conditions
lim
|x|→∞u(x, y) →0,
0 < y < ∞,
lim
y→∞u(x, y) →0,
−∞< x < ∞,
and the mixed boundary condition

uy(x, 0) = 1,
0 ≤|x| < 1,
u(x, 0) = 0,
1 < |x| < ∞.
(1)
This problem would arise in ﬁnding the electrostatic potential inside the half-space y > 0
when the boundary x = 0 is grounded for |x| > 1 and the vertical electric ﬁeld equals one
for |x| < 1.
Step 1: Using separation of variables or transform methods, show that the general solution
to the problem is
u(x, y) =
Z ∞
0
A(k)e−ky cos(kx) dk.
Step 2: Using boundary condition (1), show that A(k) satisﬁes the dual integral equations
Z ∞
0
kA(k) cos(kx) dk = −π
2 ,
0 ≤|x| < 1,
and
Z ∞
0
A(k) cos(kx) dk = 0,
1 < |x| < ∞.
Step 3: Using integral tables,31 show that
A(k) = −πJ1(k)
2k
satisﬁes both integral equations given in Step 2.
Step 4: Show that the solution to this problem is
u(x, y) = −
Z ∞
0
J1(k)e−ky cos(kx)dk
k .
In particular, verify that u(x, 0) = −
√
1 −x2 if |x| < 1.
31 Gradshteyn and Ryzhik, op. cit., Section 6.671, Formula 2 and Section 6.693, Formula 2 with ν = 1.

Laplace’s Equation
425
Spherical Coordinates
35. Find the steady-state temperature within a sphere of radius a if the temperature along
its surface is maintained at the temperature u(a, θ) = 100[cos(θ) −cos5(θ)].
36. Find the steady-state temperature within a sphere if the upper half of the exterior
surface at radius a is maintained at the temperature 100 while the lower half is maintained
at the temperature 0.
37. The surface of a sphere of radius a has a temperature of zero everywhere except in a
spherical cap at the north pole (deﬁned by the cone θ = α), where it equals T0. Find the
steady-state temperature within the sphere.
Poisson’s Integral Formula
38. Using the relationship
Z 2π
0
dϕ
1 −b cos(ϕ) =
2π
√
1 −b2 ,
|b| < 1
and Poisson’s integral formula, ﬁnd the solution to Laplace’s equation within a unit disc if
u(1, ϕ) = f(ϕ) = T0, a constant.
9.4 POISSON’S EQUATION ON A RECTANGLE
Poisson’s equation32 is Laplace’s equation with a source term:
∂2u
∂x2 + ∂2u
∂y2 = f(x, y).
(9.4.1)
It arises in such diverse areas as groundwater ﬂow, electromagnetism, and potential theory.
Let us solve it if u(0, y) = u(a, y) = u(x, 0) = u(x, b) = 0.
We begin by solving a similar partial diﬀerential equation:
∂2u
∂x2 + ∂2u
∂y2 = λu,
0 < x < a,
0 < y < b,
(9.4.2)
by separation of variables. If u(x, y) = X(x)Y (y), then
X′′
X + Y ′′
Y
= λ.
(9.4.3)
Because we must satisfy the boundary conditions that X(0) = X(a) = Y (0) = Y (b) = 0,
we have the following eigenfunction solutions:
Xn(x) = sin
nπx
a

,
Ym(x) = sin
mπy
b

(9.4.4)
32 Poisson, S. D., 1813: Remarques sur une ´equation qui se pr´esente dans la th´eorie des attractions des
sph´ero¨ıdes. Nouv. Bull. Soc. Philomath. Paris, 3, 388–392.

426
Advanced Engineering Mathematics with MATLAB
Sim´eon-Denis Poisson (1781–1840) was a product as well as a member of the French
scientiﬁc establishment of his day. Educated at the ´Ecole Polytechnique, he devoted
his life to teaching, both in the classroom and with administrative duties, and to
scientiﬁc research. Poisson’s equation dates from 1813 when Poisson sought to extend
Laplace’s work on gravitational attraction.
(Portrait courtesy of the Archives de
l’Acad´emie des sciences, Paris.)
with λnm = −n2π2/a2 −m2π2/b2; otherwise, we would only have trivial solutions. The
corresponding particular solutions are
unm = Anm sin
nπx
a

sin
mπy
b

,
(9.4.5)
where n = 1, 2, 3, . . ., and m = 1, 2, 3, . . ..
For a ﬁxed y, we can expand f(x, y) in the half-range Fourier sine series
f(x, y) =
∞
X
n=1
An(y) sin
nπx
a

,
(9.4.6)
where
An(y) = 2
a
Z a
0
f(x, y) sin
nπx
a

dx.
(9.4.7)
However, we can also expand An(y) in a half-range Fourier sine series
An(y) =
∞
X
m=1
anm sin
mπy
b

,
(9.4.8)

Laplace’s Equation
427
where
anm = 2
b
Z b
0
An(y) sin
mπy
b

dy = 4
ab
Z b
0
Z a
0
f(x, y) sin
nπx
a

sin
mπy
b

dx dy,
(9.4.9)
and
f(x, y) =
∞
X
n=1
∞
X
m=1
anm sin
nπx
a

sin
mπy
b

.
(9.4.10)
In other words, we re-expressed f(x, y) in terms of a double Fourier series.
Because Equation 9.4.2 must hold for each particular solution,
∂2unm
∂x2
+ ∂2unm
∂y2
= λnmunm = anm sin
nπx
a

sin
mπy
b

,
(9.4.11)
if we now associate Equation 9.4.1 with Equation 9.4.2. Therefore, the solution to Poisson’s
equation on a rectangle where the boundaries are held at zero is the double Fourier series
u(x, y) = −
∞
X
n=1
∞
X
m=1
anm
n2π2/a2 + m2π2/b2 sin
nπx
a

sin
mπy
b

.
(9.4.12)
Problems
1. The equation
∂2u
∂x2 + ∂2u
∂y2 = −R
T ,
|x| < a,
|y| < b
describes the hydraulic potential (elevation of the water table) u(x, y) within a rectangular
island on which a recharging well is located at (0, 0). Here R is the rate of recharging and
T is the product of the hydraulic conductivity and aquifer thickness. If the water table
is at sea level around the island so that u(−a, y) = u(a, y) = u(x, −b) = u(x, b) = 0, ﬁnd
u(x, y) everywhere in the island. Hint: Use symmetry and redo the above analysis with the
boundary conditions: ux(0, y) = u(a, y) = uy(x, 0) = u(x, b) = 0.
2. Let us apply the same approach that we used to ﬁnd the solution of Poisson’s equation
on a rectangle to solve the axisymmetric Poisson equation inside a circular cylinder
1
r
∂
∂r

r∂u
∂r

+ ∂2u
∂z2 = f(r, z),
0 ≤r < a,
|z| < b,
subject to the boundary conditions
lim
r→0 |u(r, z)| < ∞,
u(a, z) = 0,
|z| < b,
and
u(r, −b) = u(r, b) = 0,
0 ≤r < a.
Step 1: Replace the original problem with
1
r
∂
∂r

r∂u
∂r

+ ∂2u
∂z2 = λu,
0 ≤r < a,
|z| < b,

428
Advanced Engineering Mathematics with MATLAB
subject to the same boundary conditions. Use separation of variables to show that the
solution to this new problem is
unm(r, z) = AnmJ0

kn
r
a

cos
" m + 1
2

πz
b
#
,
where kn is the nth zero of J0(k) = 0, n = 1, 2, 3, . . ., and m = 0, 1, 2, . . ..
Step 2: Show that f(r, z) can be expressed as
f(r, z) =
∞
X
n=1
∞
X
m=0
anmJ0

kn
r
a

cos
" m + 1
2

πz
b
#
,
where
anm =
2
a2bJ2
1(kn)
Z b
−b
Z a
0
f(r, z)J0

kn
r
a

cos
" m + 1
2

πz
b
#
r dr dz.
Step 3: Show that the general solution is
u(r, z) = −
∞
X
n=1
∞
X
m=0
anm
J0(knr/a) cos
 m + 1
2

πz/b

(kn/a)2 +
 m + 1
2

π/b
2
.
9.5 NUMERICAL SOLUTION OF LAPLACE’S EQUATION
As in the case of the heat and wave equations, numerical methods can be used to solve
elliptic partial diﬀerential equations when analytic techniques fail or are too cumbersome.
They are also employed when the domain diﬀers from simple geometries.
The numerical analysis of an elliptic partial diﬀerential equation begins by replacing the
continuous partial derivatives by ﬁnite-diﬀerence formulas. Employing centered diﬀerencing,
∂2u
∂x2 = um+1,n −2um,n + um−1,n
(∆x)2
+ O[(∆x)2],
(9.5.1)
and
∂2u
∂y2 = um,n+1 −2um,n + um,n−1
(∆y)2
+ O[(∆y)2],
(9.5.2)
where um,n denotes the solution value at the grid point m, n.
If ∆x = ∆y, Laplace’s
equation becomes the diﬀerence equation
um+1,n + um−1,n + um,n+1 + um,n−1 −4um,n = 0.
(9.5.3)
Thus, we must now solve a set of simultaneous linear equations that yield the value of the
solution at each grid point.
The solution of Equation 9.5.3 is best done using techniques developed by algebraists.
Later on, in Chapter 3, we will show that a very popular method for directly solving sys-
tems of linear equations is Gaussian elimination. However, for many grids at a reasonable
resolution, the number of equations is generally in the tens of thousands. Because most

Laplace’s Equation
429
of the coeﬃcients in the equations are zero, Gaussian elimination is unsuitable, both from
the point of view of computational expense and accuracy. For this reason alternative meth-
ods have been developed that generally use successive corrections or iterations. The most
common of these point iterative methods are the Jacobi method, unextrapolated Liebmann
or Gauss-Seidel method, and extrapolated Liebmann or successive over-relaxation (SOR).
None of these approaches is completely satisfactory because of questions involving conver-
gence and eﬃciency. Because of its simplicity we will focus on the Gauss-Seidel method.
We may illustrate the Gauss-Seidel method by considering the system:
10x + y + z = 39,
(9.5.4)
2x + 10y + z = 51,
(9.5.5)
and
2x + 2y + 10z = 64.
(9.5.6)
An important aspect of this system is the dominance of the coeﬃcient of x in the ﬁrst
equation of the set and that the coeﬃcients of y and z are dominant in the second and third
equations, respectively.
The Gauss-Seidel method may be outlined as follows:
• Assign an initial value for each unknown variable. If possible, make a good ﬁrst guess.
If not, any arbitrarily selected values may be chosen. The initial value will not aﬀect the
convergence but will aﬀect the number of iterations until convergence.
• Starting with Equation 9.5.4, solve that equation for a new value of the unknown which
has the largest coeﬃcient in that equation, using the assumed values for the other unknowns.
• Go to Equation 9.5.5 and employ the same technique used in the previous step to compute
the unknown that has the largest coeﬃcient in that equation. Where possible, use the latest
values.
• Proceed to the remaining equations, always solving for the unknown having the largest
coeﬃcient in the particular equation and always using the most recently calculated values
for the other unknowns in the equation. When the last equation, Equation 9.5.6, has been
solved, you have completed a single iteration.
• Iterate until the value of each unknown does not change within a predetermined value.
Usually a compromise must be struck between the accuracy of the solution and the desired
rate of convergence. The more accurate the solution is, the longer it will take for the solution
to converge.
To illustrate this method, let us solve our system Equation 9.5.4 through Equation
9.5.6 with the initial guess x = y = z = 0. The ﬁrst iteration yields x = 3.9, y = 4.32, and
z = 4.756. The second iteration yields x = 2.9924, y = 4.02592, and z = 4.996336. As can
be readily seen, the solution is converging to the correct solution of x = 3, y = 4, and z = 5.
Applying these techniques to Equation 9.5.3,
uk+1
m,n = 1
4
 uk
m+1,n + uk+1
m−1,n + uk
m,n+1 + uk+1
m,n−1

,
(9.5.7)

430
Advanced Engineering Mathematics with MATLAB
where we assume that the calculations occur in order of increasing m and n.
• Example 9.5.1
To illustrate the numerical solution of Laplace’s equation, let us redo Example 9.3.1
with the boundary condition along y = H simpliﬁed to u(x, H) = 1 + x/L.
We begin by ﬁnite-diﬀerencing the boundary conditions.
The condition ux(0, y) =
ux(L, y) = 0 leads to u1,n = u−1,n and uM+1,n = uM−1,n if we employ centered diﬀerences
at m = 0 and m = M. Substituting these values in Equation 9.5.7, we have the following
equations for the left and right boundaries:
uk+1
0,n = 1
4
 2uk
1,n + uk
0,n+1 + uk+1
0,n−1

(9.5.8)
and
uk+1
M,n = 1
4

2uk+1
M−1,n + uk
M,n+1 + uk+1
M,n−1

.
(9.5.9)
On the other hand, uy(x, 0) = 0 yields um,1 = um,−1, and
uk+1
m,0 = 1
4
 uk
m+1,0 + uk+1
m−1,0 + 2uk
m,1

.
(9.5.10)
At the bottom corners, Equation 9.5.8 through Equation 9.5.10 simplify to
uk+1
0,0 = 1
2
 uk
1,0 + uk
0,1

(9.5.11)
and
uk+1
L,0 = 1
2

uk+1
L−1,0 + uk
L,1

.
(9.5.12)
These equations along with Equation 9.5.7 were solved with the Gauss-Seidel method
using the MATLAB script
clear
dx = 0.1; x = 0:dx:1; M = 1/dx+1; % M = number of x grid points
dy = 0.1; y = 0:dy:1; N = 1/dy+1; % N = number of y grid points
X = x’ * ones(1,N); Y = ones(M,1) * y;
u = zeros(M,N); % create initial guess for the solution
% introduce boundary condition along y = H
for m = 1:M; u(m,N) = 1 + x(m); end
% start Gauss-Seidel method for Laplace’s equation
for iter = 1:256
% do the interior first
for n = 2:N-1; for m = 2:M-1;
u(m,n) = (u(m+1,n)+u(m-1,n)+u(m,n+1)+u(m,n-1)) / 4;
end; end
% now do the x = 0 and x = L sides
for n = 2:N-1
u(1,n) = (2*u( 2 ,n)+u(1,n+1)+u(1,n-1)) / 4;
u(M,n) = (2*u(M-1,n)+u(M,n+1)+u(M,n-1)) / 4;
end
% now do the y = 0 side
for m = 2:M-1
u(m,1) = (u(m+1,1)+u(m-1,1)+2*u(m,2)) / 4;

Laplace’s Equation
431
0
0.5
1
0
0.5
1
Y/H
after 4 iterations
0.2
0.6
1
1
1.4
0
0.5
1
0
0.5
1
Y/H
after 16 iterations
0.2
0.2
0.4
0.6
0.6
0.8
0.8
1
1
1.2
1.41.6
0
0.5
1
0
0.5
1
X/L
Y/H
after 64 iterations
0.6
0.8
0.8
1
1
1.2
1.4
1.6
0
0.5
1
0
0.5
1
X/L
Y/H
after 256 iterations
1.2
1.3
1.4
1.5
1.6
1.7
Figure 9.5.1: The solution to Laplace’s equation by the Gauss-Seidel method. The boundary conditions
are ux(0, y) = ux(L, y) = uy(x, 0) = 0, and u(x, H) = 1 + x/L.
end
% finally do the corners
u(1,1) = (u(2,1)+u(1,2))/2; u(M,1) = (u(M-1,1)+u(M,2))/2;
% plot the solution
if (iter == 4) subplot(2,2,1), [cs,h] = contourf(X,Y,u);
clabel(cs,h,[0.2 0.6 1 1.4],’Fontsize’,16)
axis tight; title(’after 4 iterations’,’Fontsize’,20);
ylabel(’Y/H’,’Fontsize’,20); end
if (iter == 16) subplot(2,2,2), [cs,h] = contourf(X,Y,u);
clabel(cs,h,’Fontsize’,16)
axis tight; title(’after 16 iterations’,’Fontsize’,20);
ylabel(’Y/H’,’Fontsize’,20); end
if (iter == 64) subplot(2,2,3), [cs,h] = contourf(X,Y,u);
clabel(cs,h,’Fontsize’,16)
axis tight; title(’after 64 iterations’,’Fontsize’,20);
xlabel(’X/L’,’Fontsize’,20); ylabel(’Y/H’,’Fontsize’,20);
end
if (iter == 256) subplot(2,2,4), [cs,h] = contourf(X,Y,u);
clabel(cs,h,’Fontsize’,16)
axis tight; title(’after 256 iterations’,’Fontsize’,20);
xlabel(’X/L’,’Fontsize’,20); ylabel(’Y/H’,’Fontsize’,20);
end
end

432
Advanced Engineering Mathematics with MATLAB
1
1.1
1.3
1.4
1.6
1.8
2
ω
100
126
158
200
251
316
398
501
631
794
1000
number of iterations
Figure 9.5.2: The number of iterations required so that |Rm,n| ≤10−3 as a function of ω during the
iterative solution of the problem posed in the project. We used ∆x = ∆y = 0.01, and L = z0 = 1. The
iteration count for the boundary conditions stated in Step 1 is given by the solid line while the iteration
count for the boundary conditions given in Step 2 is shown by the dotted line. The initial guess equaled
zero.
The initial guess everywhere except along the top boundary was zero. In Figure 9.5.1
we illustrate the numerical solution after 4, 16, 64, and 256 iterations, where we have taken
11 grid points in the x and y directions.
Project: Successive Over-Relaxation
The fundamental diﬃculty with relaxation methods used in solving Laplace’s equation
is the rate of convergence. Assuming ∆x = ∆y, the most popular method for accelerating
convergence of these techniques is successive over-relaxation (SOR):
uk+1
m,n = (1 −ω)uk
m,n + ωRm,n,
where
Rm,n = 1
4
 uk
m+1,n + uk+1
m−1,n + uk
m,n+1 + uk+1
m,n−1

.
Most numerical methods books dealing with partial diﬀerential equations discuss the the-
oretical reasons behind this technique;33 the optimum value always lies between one and
two. In the present case, a theoretical analysis34 gives
ωopt =
4
2 +
√
4 −c2 ,
where
c = cos
 π
N

+ cos
 π
M

,
33 For example, Young, D. M., 1971: Iterative Solution of Large Linear Systems. Academic Press, 570
pp.
34 Yang, S., and M. K. Gobbert, 2009: The optimal relaxation parameter for the SOR method applied
to the Poisson equation in any space dimensions. Appl. Math. Letters, 22, 325–331.

Laplace’s Equation
433
and N and M are the number of mesh divisions on each side of the rectangular domain.
Recently Yang and Gobbert35 generalized the analysis and found the optimal relaxation pa-
rameter for the successive-overrelaxation method when it is applied to the Poisson equation
in any space dimensions.
Step 1: Write a MATLAB script that uses the Gauss-Seidel method to numerically solve
Laplace’s equation for 0 ≤x ≤L, 0 ≤y ≤z0 with the following boundary conditions:
u(x, 0) = 0, u(x, z0) = 1 + x/L, u(0, y) = y/z0, and u(L, y) = 2y/z0. Because this solution
will act as “truth” in this project, you should iterate until the solution does not change.
Step 2: Now redo the calculation using successive over-relaxation. Count the number of
iterations until |Rm,n| ≤10−3 for all m and n. Plot the number of iterations as a function
of ω. How does the curve change with resolution ∆x? How does your answer compare to
the theoretical value? See Figure 9.5.2.
Step 3: Redo Steps 1 and 2 with the exception of u(0, y) = u(L, y) = 0. How has the
convergence rate changed? Can you explain why? How sensitive are your results to the
ﬁrst guess?
9.6 FINITE ELEMENT SOLUTION OF LAPLACE’S EQUATION
In Section 6.6 we showed how the ﬁnite element method can be used to solve boundary-
value problems. Here we extend this approach to two dimensions. The main diﬃculty will
be the increase in the complexity of the “bookkeeping.”
Triangular elements
Our ﬁrst concern is with the element equations. Essentially there are two types: trian-
gles and quadrilaterals. Triangular elements use the linear polynomial:
u(x, y) = a0 + a1x + a2y,
(9.6.1)
where u(x, y) is the dependent variable, the ai’s are coeﬃcients, and x and y are the
independent variables. This function must pass through the values of u(x, y) at the triangle’s
nodes (x1, y1), (x2, y2), and (x3, y3). Therefore,
u1 = a0 + a1x1 + a2y1,
(9.6.2)
u2 = a0 + a1x2 + a2y2,
(9.6.3)
and
u3 = a0 + a1x3 + a2y3.
(9.6.4)
Solving for a0, a1 and a2, we have that
a0 = [u1(x2y3 −x3y2) + u2(x3y1 −x1y3) + u3(x1y2 −x2y1)]/A,
(9.6.5)
a1 = [u1(y2 −y3) + u2(y3 −y1) + u3(y1 −y2)]/A,
(9.6.6)
35 Ibid.

434
Advanced Engineering Mathematics with MATLAB
and
a2 = [u1(x3 −x2) + u2(x1 −x3) + u3(x2 −x1)]/A,
(9.6.7)
where A is the area of the triangular element
A = 1
2[(x2y3 −x3y2) + (x3y1 −x1y3) + (x1y2 −x2y1)].
(9.6.8)
To avoid a small A you should avoid elements with narrow geometries on the ﬁnite mesh.
Equation 9.6.5 through Equation 9.6.7 can be substituted into Equation 9.6.1. Collecting
terms, the result can be expressed as
u(x, y) = N1u1 + N2u2 + N3u3,
(9.6.9)
where
N1 = [(x2y3 −x3y2) + (y2 −y1)x + (x3 −x2)y]/(2A),
(9.6.10)
N2 = [(x3y1 −x1y3) + (y3 −y1)x + (x1 −x3)y]/(2A),
(9.6.11)
and
N3 = [(x1y2 −x2y1) + (y1 −y2)x + (x2 −x1)y]/(2A).
(9.6.12)
Bilinear rectangular elements
Bilinear rectangular elements use the interpolation formula:
u(x, y) = N1u1 + N2u2 + N3u3 + N4u4.
(9.6.13)
We wish Equation 9.6.13 to be linear in both x and y. Applying the same procedure as
before, we have that
N1 = (b −x)(a −y)/(4ab),
N2 = (b + x)(a −y)/(4ab),
(9.6.14)
N3 = (b + x)(a + y)/(4ab),
and
N4 = (b −x)(a + y)/(4ab),
(9.6.15)
where 2b and 2a are the length and height of the element, respectively.
Finite element formulation
Having introduced the two most common ﬁnite element representations, we are ready
to apply them to Laplace’s equation. As in the one dimension we develop the ﬁnite element
formulation using the variational formulation (weak formulation) of the boundary-value
problem by considering the integral
I =
Z Z
A
w(x, y)
∂2u
∂x2 + ∂2u
∂y2

dx dy −
Z
Γe
w(x, y)∂u
∂n dΓ,
(9.6.16)
where w(x, y) is a weighting function and Γe is that portion of the boundary where the
Dirichlet condition applies. Integrating Equation 9.6.16 by parts,
I = −
Z Z
A
∂w
∂x
∂u
∂x + ∂w
∂y
∂u
∂y

dx dy +
Z
Γn
w(x, y)∂u
∂n dΓ,
(9.6.17)

Laplace’s Equation
435
where Γn is that portion of the boundary where any Neumann condition exists.
For a linear triangular element, we have
[Ke]ue] =
Z Z
Ωe
∂w
∂x
∂u
∂x + ∂w
∂y
∂u
∂y

dx dy
(9.6.18)
=
(Z Z
Ωe
3
X
n=1
"∂Nn
∂x
2
+
∂Nn
∂y
2#
dx dy
)
ue
(9.6.19)
where Ωe is the element’s domain. Upon substituting for N1, N2, and N3 and carrying out
the integrations,
[Ke] =


k11
k12
k13
k21
k22
k23
k31
k32
k33

,
(9.6.20)
where
k11 = [(x3 −x2)2 + (y2 −y3)2]/(4A),
(9.6.21)
k12 = [(x3 −x2)(x1 −x3) + (y2 −y3)(y3 −y1)]/(4A),
(9.6.22)
k13 = [(x3 −x2)(x2 −x1) + (y2 −y3)(y1 −y2)]/(4A),
(9.6.23)
k21 = k12,
(9.6.24)
k22 = [(x1 −x3)2 + (y3 −y1)2]/(4A),
(9.6.25)
k23 = [(x1 −x3)(x2 −x1) + (y3 −y1)(y1 −y2)]/(4A),
(9.6.26)
k31 = k13,
(9.6.27)
k32 = k23,
(9.6.28)
and
k33 = [(x2 −x1)2 + (y1 −y2)2]/(4A).
(9.6.29)
In the case of a bilinear element, we now have
[Ke]ue] =
(Z Z
Ωe
4
X
n=1
"∂Nn
∂x
2
+
∂Nn
∂y
2#
dx dy
)
ue.
(9.6.30)
Carrying out the integration, we obtain
K =



k11
k12
k13
k14
k21
k22
k23
k24
k31
k32
k33
k34
k41
k42
k43
k44



(9.6.31)
where
k11 = b2 + a2
3ab
,
k12 = b2 −2a2
6ab
(9.6.32)
k13 = −b2 + a2
6ab
,
k14 = a2 −2b2
6ab
(9.6.33)
k22 = k11,
k23 = k14,
k24 = k13,
(9.6.34)

436
Advanced Engineering Mathematics with MATLAB
x
y
1
3
4
2
1
5
6
7
8 
10
9
11
12
3
5
6
4
2
7
9
11
12
10
8 
0
1
2
3
0
1
2
(a)
(b)
insulated
insulated
u(3,y) = 0
x/6)
cos(
u(x,2) = 
π
Figure 9.6.1: The (a) domain and (b) layout of nodes for Example 9.6.1. The numbers within the circles
give the number for each triangular element.
and
k33 = k11,
k34 = k12,
k44 = k11.
(9.6.35)
• Example 9.6.1
Let us illustrate the ﬁnite element method by ﬁnding the solution to Laplace’s equation
in a rectangular domain shown in Figure 9.6.1(a). The origin is taken at the lower left corner.
The boundaries x = 0 and y = 0 are insulated, the boundary x = 3 is maintained at zero,
and the boundary y = 2 is described by the equation u(x, 2) = cos(πx/6).
If we use 12 nodes, Figure 9.6.1(b) gives the global node number, element number,
and element node numbers. The global node and element numberings are arbitrary. If we
used some software package we would have to take care that we follow their convention.
The element node numbering scheme used here is consistent with the element interpolation
function, a counterclockwise system. According to the element node numbering scheme
shown in Figure 9.6.1(b), all elements in the mesh fall into one of two geometric shapes:
one with its base at the bottom of the element and another with its base at the top of the
element. Our choice results in all of the elements having a common geometric shape, and
thus the element coeﬃcients must be computed only for a single element.
For a typical element of the mesh of triangles in Figure 9.6.1(b), the element coeﬃcient
matrix is
[Ke] = 1
2


1
−1
0
−1
2
−1
0
−1
1

.
(9.6.36)
The element matrix is independent of the size of the element, as long as the element is a
right-angled triangle where the base equals height.

Laplace’s Equation
437
x
y
3
4
2
1
5
6
7
8 
10
9
11
12
0
1
2
3
0
1
2
(a)
(b)
4
5
6
3
2
1
insulated
u(3,y) = 0
insulated
x/6)
cos(
u(x,2) = 
π
Figure 9.6.2: The (a) domain and (b) layout of nodes for Example 9.6.2. The numbers within the circles
give the number for each rectangular element.
The boundary conditions require that u4 = u8 = u12 = 0, u9 = 1, u10 =
√
3/2,
u11 = 1/2, and there is no heat ﬂow at the insulated boundary. Consequently the line
integral vanishes and [Ke]ue = 0.
We ﬁrst write the six ﬁnite element equations for the six unknown primary variables.
These equations come from nodes 1, 2, 3, 5, 6, and 7:







2
−1
0
−1
0
0
−1
4
−1
0
−2
0
0
−1
4
0
0
−2
−1
0
0
4
−2
0
0
−2
0
−2
8
−2
0
0
−2
0
−2
8














u1
u2
u3
u5
u6
u7







=







0
0
0
1
√
3
1







.
(9.6.37)
The solution to these equations is u1 = 0.6362, u2 = 0.5510, u3 = 0.3181, u5 = 0.7214,
u6 = 0.6248, and u7 = 0.3607. The exact solution is uexact
1
= 0.6249, uexact
2
= 0.5412,
uexact
3
= 0.3124, uexact
5
= 0.7125, uexact
6
= 0.6171, and uexact
7
= 0.3563.
⊓⊔
• Example 9.6.2
Let us redo Example 9.6.3 using rectangular elements. Figure 9.6.2 illustrates the grid
now. The stiﬀness matrix for an element now becomes
[Ke] = 1
6



4
−1
−2
−1
−1
4
−1
−2
−2
−1
4
−1
−1
−2
−1
4


.
(9.6.38)

438
Advanced Engineering Mathematics with MATLAB
1
2
3
4
5
6
8 9
10
11
12
13
14
15
16
1718
19
20
21
23
22
25
24
26
27
29
28
30
37
35
36
34
33
32
31
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
99
98
100 101 102 103 104 105 106 107
108 109 110
113
112
111
114 115 116 117 118
119 120 121 122 123
128
127
126
124 125
129 130 131 132
133 134 135 136 137 138 139 140 141 142 143 144 145 146
147 148 149 150 151 152 153 154 155 156 157 158 159 160
161 162 163 164 165 166 167 168 169 170 171 172 173 174
177
175 176
179 180
178
181 182 183 184 185 186 187 188
189 190 191 192 193 194 195
197
196
198 199 200 201 202
203 204 205 206 207 208 209 210 211 212 213 214 215 216
7
Figure 9.6.3: One of the possible nodal maps for the project.
If we consider only the number of nodes, the present mesh, shown in Figure 9.6.2(b), is
the same as the triangular mesh that we used in Example 9.6.1. Hence the boundary condi-
tions are unchanged here. The six ﬁnite elements equations for the unknown temperatures
u1, u2, u3, u5, u6, and u7 are







4
−1
0
−1
−2
0
−1
8
−1
−2
−2
−2
0
−1
8
0
−2
−2
−1
−2
0
8
−2
0
−2
−2
−2
−2
16
−2
0
−2
−2
0
−2
16














u1
u2
u3
u5
u6
u7







=







0
0
0
1 +
√
3
3 +
√
3
1 +
√
3







.
(9.6.39)
The solution to Equation 9.6.38 is u1 = 0.6128, u2 = 0.5307, u3 = 0.3064, u5 = 0.7030,
u6 = 0.6088, and u7 = 0.3515. Note that our present results are not as accurate as those
in the previous example. This occurs because there are only one-half of the elements as in
the triangular element formulation.
Project: Solving Laplace’s Equation Using Finite Elements
In this project you will use ﬁnite elements to solve Laplace’s equation. The domain
is square with a quarter circle removed from the lower right side of the square. Along the
quarter circle, the solution equals one while along the straight edges the solution equals
zero.
Although you could write your own MATLAB code, there already exist several codes36
that are available online.37 Consequently your principal task will be to construct the tri-
angular and quadrilateral elements by choosing reasonable nodal positions.
With those
36 See, for example, Alberty, J., C. Carstensen, and S. A. Funken, 1999: Remarks about 50 lines of
Matlab: Short ﬁnite element implementation. Numer. Algorithms, 20, 117–137. This paper includes the
MATLAB code that you will need.
37 For example, http://people.sc.fsu.edu/~burkardt/m src/fem 50/fem 50.html

Laplace’s Equation
439
0
5
10
15
0
5
10
15
0
0.5
1
 y
Finite Element Solution to Laplace′s Equation
 x
u(x,y)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Figure 9.6.4: The ﬁnite element solution of Laplace’s equation where the solution equals 0 along the
straight edges and 1 along the quarter circle.
in place, the coding of the Dirichlet boundary conditions is straightforward. Figure 9.6.3
shows one possible nodal conﬁguration. Figure 9.6.4 illustrates how your solution should
appear.
Further Reading
Duﬀy, D. G., 2008: Mixed Boundary Value Problems. Chapman & Hall, 467 pp. This book
gives a detailed account of mixed boundary value problems.
Koshlyakov, N. S., M. M. Smirnov, and E. B. Gliner, 1964: Diﬀerential Equations of Math-
ematical Physics. North-Holland Publishing, 701 pp. See Part II. Detailed presentation of
mathematical techniques.
Morse, P. M., and H. Feshback, 1953: Methods of Theoretical Physics. McGraw-Hill Book
Co., 997 pp. Chapter 10 is devoted to solving both Laplace’s and Poisson’s equations.

Chapter 10
Complex Variables
The theory of complex variables was originally developed by mathematicians as an aid
in understanding functions. Functions of a complex variable enjoy many powerful properties
that their real counterparts do not. That is not why we will study them. For us they provide
the keys for the complete mastery of transform methods and diﬀerential equations.
In this chapter all of our work points to one objective: integration on the complex
plane by the method of residues. For this reason we minimize discussions of limits and
continuity, which play such an important role in conventional complex variables, in favor
of the computational aspects. We begin by introducing some simple facts about complex
variables. Then we progress to diﬀerential and integral calculus on the complex plane.
10.1 COMPLEX NUMBERS
A complex number is any number of the form a+bi, where a and b are real and i = √−1.
We denote any member of a set of complex numbers by the complex variable z = x + iy.
The real part of z, usually denoted by ℜ(z), is x while the imaginary part of z, ℑ(z), is y.
The complex conjugate, z or z∗, of the complex number a + bi is a −bi.
Complex numbers obey the fundamental rules of algebra. Thus, two complex numbers
a + bi and c + di are equal if and only if a = c and b = d. Just as real numbers have
the fundamental operations of addition, subtraction, multiplication, and division, so too do
complex numbers. These operations are deﬁned:
Addition
(a + bi) + (c + di) = (a + c) + (b + d)i
(10.1.1)
Subtraction
(a + bi) −(c + di) = (a −c) + (b −d)i
(10.1.2)
441

442
Advanced Engineering Mathematics with MATLAB
Multiplication
(a + bi)(c + di) = ac + bci + adi + i2bd = (ac −bd) + (ad + bc)i
(10.1.3)
Division
a + bi
c + di = a + bi
c + di
c −di
c −di = ac −adi + bci −bdi2
c2 + d2
= ac + bd + (bc −ad)i
c2 + d2
.
(10.1.4)
The absolute value or modulus
of a complex number a + bi, written |a + bi|, equals
√
a2 + b2. Additional properties include:
|z1z2z3 · · · zn| = |z1||z2||z3| · · · |zn|
(10.1.5)
|z1/z2| = |z1|/|z2|
if
z2 ̸= 0
(10.1.6)
|z1 + z2 + z3 + · · · + zn| ≤|z1| + |z2| + |z3| + · · · + |zn|
(10.1.7)
and
|z1 + z2| ≥|z1| −|z2|.
(10.1.8)
The use of inequalities with complex variables has meaning only when they involve absolute
values.
It is often useful to plot the complex number x + iy as a point (x, y) in the xy-plane,
now called the complex plane. Figure 10.1.1 illustrates this representation.
This geometrical interpretation of a complex number suggests an alternative method
of expressing a complex number: the polar form. From the polar representation of x and y,
x = r cos(θ)
and
y = r sin(θ),
(10.1.9)
where r =
p
x2 + y2 is the modulus, amplitude, or absolute value of z and θ is the argument
or phase, we have that
z = x + iy = r[cos(θ) + i sin(θ)].
(10.1.10)
However, from the Taylor expansion of the exponential in the real case,
eiθ =
∞
X
k=0
(θi)k
k! .
(10.1.11)
Expanding Equation 10.1.11,
eiθ = 1 −θ2
2! + θ4
4! −θ6
6! + · · · + i

θ −θ3
3! + θ5
5! −θ7
7! + · · ·

(10.1.12)
= cos(θ) + i sin(θ).
(10.1.13)
Equation 10.1.13 is Euler’s formula. Consequently, we may express Equation 10.1.10 as
z = reiθ,
(10.1.14)
which is the polar form of a complex number. Furthermore, because
zn = rneinθ
(10.1.15)

Complex Variables
443
θ
(x,y)
r
y
x
Figure 10.1.1: The complex plane.
by the law of exponents,
zn = rn[cos(nθ) + i sin(nθ)].
(10.1.16)
Equation 10.1.16 is De Moivre’s theorem.
• Example 10.1.1
Let us simplify the following complex number:
3 −2i
−1 + i = 3 −2i
−1 + i × −1 −i
−1 −i = −3 −3i + 2i + 2i2
1 + 1
= −5 −i
2
= −5
2 −i
2.
(10.1.17)
⊓⊔
• Example 10.1.2
Let us reexpress the complex number −
√
6 −i
√
2 in polar form. From Equation 10.1.9
r = √6 + 2 and θ = tan−1(b/a) = tan−1(1/
√
3) = π/6 or 7π/6. Because −
√
6 −i
√
2 lies in
the third quadrant of the complex plane, θ = 7π/6 and
−
√
6 −i
√
2 = 2
√
2e7πi/6.
(10.1.18)
Note that Equation 10.1.18 is not a unique representation because ±2nπ may be added to
7π/6 and we still have the same complex number since
ei(θ±2nπ) = cos(θ ± 2nπ) + i sin(θ ± 2nπ) = cos(θ) + i sin(θ) = eiθ.
(10.1.19)
For uniqueness we often choose n = 0 and deﬁne this choice as the principal branch. Other
branches correspond to diﬀerent values of n.
⊓⊔
• Example 10.1.3
Find the curve described by the equation |z −z0| = a.
From the deﬁnition of the absolute value,
p
(x −x0)2 + (y −y0)2 = a
(10.1.20)

444
Advanced Engineering Mathematics with MATLAB
or
(x −x0)2 + (y −y0)2 = a2.
(10.1.21)
Equation 10.1.21, and hence |z−z0| = a, describes a circle of radius a with its center located
at (x0, y0). Later on, we shall use equations such as this to describe curves in the complex
plane.
⊓⊔
• Example 10.1.4
As an example in manipulating complex numbers, let us show that

a + bi
b + ai
 = 1.
(10.1.22)
We begin by simplifying
a + bi
b + ai = a + bi
b + ai × b −ai
b −ai =
2ab
a2 + b2 + b2 −a2
a2 + b2 i.
(10.1.23)
Therefore,

a + bi
b + ai
 =
s
4a2b2
(a2 + b2)2 + b4 −2a2b2 + a4
(a2 + b2)2
=
s
a4 + 2a2b2 + b4
(a2 + b2)2
= 1.
(10.1.24)
MATLAB can also be used to solve this problem. Typing the commands
>> syms a b real
>> abs((a+b*i)/(b+a*i))
yields
ans =
1
Note that you must declare a and b real in order to get the ﬁnal result.
Problems
Simplify the following complex numbers. Represent the solution in the Cartesian form a+bi.
Check your answers using MATLAB.
1.
5i
2 + i
2. 5 + 5i
3 −4i +
20
4 + 3i
3. 1 + 2i
3 −4i + 2 −i
5i
4. (1 −i)4
5. i(1 −i
√
3)(
√
3 + i)
Represent the following complex numbers in polar form:
6.
−i
7.
−4
8.
2 + 2
√
3 i
9.
−5 + 5i
10.
2 −2i
11.
−1 +
√
3 i
12. By the law of exponents, ei(α+β) = eiαeiβ. Use Euler’s formula to obtain expressions
for cos(α + β) and sin(α + β) in terms of sines and cosines of α and β.

Complex Variables
445
13.
Using the property that PN
n=0 qn = (1 −qN+1)/(1 −q) and the geometric series
PN
n=0 eint, obtain the following sums of trigonometric functions:
N
X
n=0
cos(nt) = cos
Nt
2
 sin[(N + 1)t/2]
sin(t/2)
and
N
X
n=1
sin(nt) = sin
Nt
2
 sin[(N + 1)t/2]
sin(t/2)
.
These results are often called Lagrange’s trigonometric identities.
14. (a) Using the property that P∞
n=0 qn = 1/(1 −q), if |q| < 1, and the geometric series
P∞
n=0 ǫneint, |ǫ| < 1, show that
∞
X
n=0
ǫn cos(nt) =
1 −ǫ cos(t)
1 + ǫ2 −2ǫ cos(t)
and
∞
X
n=1
ǫn sin(nt) =
ǫ sin(t)
1 + ǫ2 −2ǫ cos(t).
(b) Let ǫ = e−a, where a > 0. Show that
2
∞
X
n=1
e−na sin(nt) =
sin(t)
cosh(a) −cos(t).
10.2 FINDING ROOTS
The concept of ﬁnding roots of a number, which is rather straightforward in the case of
real numbers, becomes more diﬃcult in the case of complex numbers. By ﬁnding the roots
of a complex number, we wish to ﬁnd all of the solutions w of the equation wn = z, where
n is a positive integer for a given z.
We begin by writing z in the polar form:
z = reiϕ,
(10.2.1)
while we write
w = ReiΦ
(10.2.2)
for the unknown. Consequently,
wn = RneinΦ = reiϕ = z.
(10.2.3)
We satisfy Equation 10.2.3 if
Rn = r
and
nΦ = ϕ + 2kπ,
k = 0, ±1, ±2, . . . ,
(10.2.4)
because the addition of any multiple of 2π to the argument is also a solution.
Thus,
R = r1/n, where R is the uniquely determined real positive root, and
Φk = ϕ
n + 2πk
n ,
k = 0, ±1, ±2, . . . .
(10.2.5)
Because wk = wk±n, it is suﬃcient to take k = 0, 1, 2, . . . , n−1. Therefore, there are exactly
n solutions:
wk = ReΦki = r1/n exp

i
ϕ
n + 2πk
n

(10.2.6)

446
Advanced Engineering Mathematics with MATLAB
x
y
1
z
z
z
z
z
0
4
3
2
Figure 10.2.1: The zeros of z5 = −32.
with k = 0, 1, 2, . . . , n −1. They are the n roots of z. Geometrically we can locate these
solutions wk on a circle, centered at the point (0, 0), with radius R and separated from each
other by 2π/n radians. These roots also form the vertices of a regular polygon of n sides
inscribed inside of a circle of radius R. (See Example 10.2.1.)
In summary, the method for ﬁnding the n roots of a complex number z0 is as follows.
First, write z0 in its polar form: z0 = reiϕ. Then multiply the polar form by e2iπk. Using
the law of exponents, take the 1/n power of both sides of the equation.
Finally, using
Euler’s formula, evaluate the roots for k = 0, 1, . . . , n −1.
• Example 10.2.1
Let us ﬁnd all of the values of z for which z5 = −32 and locate these values on the
complex plane.
Because
−32 = 32eπi = 25eπi,
(10.2.7)
zk = 2 exp
πi
5 + 2πik
5

,
k = 0, 1, 2, 3, 4,
(10.2.8)
or
z0 = 2 exp
πi
5

= 2
h
cos
π
5

+ i sin
π
5
i
,
(10.2.9)
z1 = 2 exp
3πi
5

= 2

cos
3π
5

+ i sin
3π
5

,
(10.2.10)
z2 = 2eπi = −2,
(10.2.11)
z3 = 2 exp
7πi
5

= 2

cos
7π
5

+ i sin
7π
5

(10.2.12)
and
z4 = 2 exp
9πi
5

= 2

cos
9π
5

+ i sin
9π
5

.
(10.2.13)
Figure 10.2.1 shows the location of these roots in the complex plane.
⊓⊔

Complex Variables
447
y
0
x
z
z
z
1
2
Figure 10.2.2: The zeros of z3 = −1 + i.
• Example 10.2.2
Let us ﬁnd the cube roots of −1 + i and locate them graphically.
Because −1 + i =
√
2 exp(3πi/4),
zk = 21/6 exp
πi
4 + 2iπk
3

,
k = 0, 1, 2,
(10.2.14)
or
z0 = 21/6 exp
πi
4

= 21/6 h
cos
π
4

+ i sin
π
4
i
,
(10.2.15)
z1 = 21/6 exp
11πi
12

= 21/6

cos
11π
12

+ i sin
11π
12

,
(10.2.16)
and
z2 = 21/6 exp
19πi
12

= 21/6

cos
19π
12

+ i sin
19π
12

.
(10.2.17)
Figure 10.2.2 gives the location of these zeros on the complex plane.
⊓⊔
• Example 10.2.3
The routine solve in MATLAB can also be used to compute the roots of complex
numbers. For example, let us ﬁnd all of the roots of z4 = −a4.
The MATLAB commands are as follows:
>> syms a z
>> solve(z^4+a^4)
This yields the solution
ans=
[
(1/2*2^(1/2)+1/2*i*2^(1/2))*a]
[ (-1/2*2^(1/2)+1/2*i*2^(1/2))*a]
[
(1/2*2^(1/2)-1/2*i*2^(1/2))*a]
[ (-1/2*2^(1/2)-1/2*i*2^(1/2))*a]

448
Advanced Engineering Mathematics with MATLAB
2
x
y
v
u
z-plane 
w-plane
2
1
3
3
1
Figure 10.3.1: The complex function w = z2.
Problems
Extract all of the possible roots of the following complex numbers. Verify your answer using
MATLAB.
1.
81/6
2.
(−1)1/3
3.
(−i)1/3
4.
(−27i)1/6
5. Find algebraic expressions for the square roots of a −bi, where a > 0 and b > 0.
6. Find all of the roots for the algebraic equation z4 −3iz2 −2 = 0. Then check your answer
using solve in MATLAB.
7. Find all of the roots for the algebraic equation z4 + 6iz2 + 16 = 0. Then check your
answer using solve in MATLAB.
10.3 THE DERIVATIVE IN THE COMPLEX PLANE: THE CAUCHY-RIEMANN EQUATIONS
In the previous two sections, we introduced complex arithmetic. We are now ready for
the concept of function as it applies to complex variables.
We already deﬁned the complex variable z = x+iy, where x and y are variable. We now
introduce another complex variable w = u+iv so that for each value of z there corresponds
a value of w = f(z). From all of the possible complex functions that we might invent, we
focus on those functions where for each z there is one, and only one, value of w. These
functions are single-valued. They diﬀer from functions such as the square root, logarithm,
and inverse sine and cosine, where there are multiple answers for each z. These multivalued
functions do arise in various problems. However, they are beyond the scope of this book
and we shall always assume that we are dealing with single-valued functions.
A popular method for representing a complex function involves drawing some closed
domain in the z-plane and then showing the corresponding domain in the w-plane. This
procedure is called mapping and the z-plane illustrates the domain of the function while
the w-plane illustrates its image or range. Figure 10.3.1 shows the z-plane and w-plane for
w = z2; a pie-shaped wedge in the z-plane maps into a semicircle on the w-plane.
• Example 10.3.1
Given the complex function w = e−z2, let us ﬁnd the corresponding u(x, y) and v(x, y).
From Euler’s formula,
w = e−z2 = e−(x+iy)2 = ey2−x2e−2ixy = ey2−x2[cos(2xy) −i sin(2xy)].
(10.3.1)

Complex Variables
449
Therefore, by inspection,
u(x, y) = ey2−x2 cos(2xy),
and
v(x, y) = −ey2−x2 sin(2xy).
(10.3.2)
Note that there is no i in the expression for v(x, y). The function w = f(z) is single-valued
because for each distinct value of z, there is a unique value of u(x, y) and v(x, y).
⊓⊔
• Example 10.3.2
As counterpoint, let us show that w = √z is a multivalued function.
We begin by writing z = reiθ+2πik, where r =
p
x2 + y2 and θ = tan−1(y/x). Then,
wk = √reiθ/2+πik,
k = 0, 1,
(10.3.3)
or
w0 = √r [cos(θ/2) + i sin(θ/2)]
and
w1 = −w0.
(10.3.4)
Therefore,
u0(x, y) = √r cos(θ/2),
v0(x, y) = √r sin(θ/2),
(10.3.5)
and
u1(x, y) = −√r cos(θ/2),
v1(x, y) = −√r sin(θ/2).
(10.3.6)
Each solution w0 or w1 is a branch of the multivalued function √z. We can make √z single-
valued by restricting ourselves to a single branch, say w0. In that case, the ℜ(w) > 0 if we
restrict −π < θ < π. Although this is not the only choice that we could have made, it is a
popular one. For example, most digital computers use this deﬁnition in their complex square
root function. The point here is our ability to make a multivalued function single-valued
by deﬁning a particular branch.
⊓⊔
Although the requirement that a complex function be single-valued is important, it is
still too general and would cover all functions of two real variables. To have a useful theory,
we must introduce additional constraints. Because an important property associated with
most functions is the ability to take their derivative, let us examine the derivative in the
complex plane.
Following the deﬁnition of a derivative for a single real variable, the derivative of a
complex function w = f(z) is deﬁned as
dw
dz = lim
∆z→0
∆w
∆z = lim
∆z→0
f(z + ∆z) −f(z)
∆z
.
(10.3.7)
A function of a complex variable that has a derivative at every point within a region of the
complex plane is said to be analytic (or regular or holomorphic) over that region. If the
function is analytic everywhere in the complex plane, it is entire.
Because the derivative is deﬁned as a limit and limits are well behaved with respect
to elementary algebraic operations, the following operations carry over from elementary
calculus:
d
dz

cf(z)

= cf ′(z),
c a constant
(10.3.8)
d
dz

f(z) ± g(z)

= f ′(z) ± g′(z)
(10.3.9)

450
Advanced Engineering Mathematics with MATLAB
d
dz

f(z)g(z)

= f ′(z)g(z) + f(z)g′(z)
(10.3.10)
d
dz
f(z)
g(z)

= g(z)f ′(z) −g′(z)f(z)
g2(z)
(10.3.11)
d
dz

f[g(z)]

= f ′[g(z)]g′(z),
the chain rule.
(10.3.12)
Another important property that carries over from real variables is l’Hˆospital’s rule:
Let f(z) and g(z) be analytic at z0, where f(z) has a zero1 of order m and g(z) has a zero
of order n. Then, if m > n,
lim
z→z0
f(z)
g(z) = 0;
(10.3.13)
if m = n,
lim
z→z0
f(z)
g(z) = f (m)(z0)
g(m)(z0) ;
(10.3.14)
and if m < n,
lim
z→z0
f(z)
g(z) = ∞.
(10.3.15)
• Example 10.3.3
Let us evaluate limz→i(z10 + 1)/(z6 + 1). From l’Hˆospital’s rule,
lim
z→i
z10 + 1
z6 + 1 = lim
z→i
10z9
6z5 = 5
3 lim
z→i z4 = 5
3.
(10.3.16)
⊓⊔
So far, we introduced the derivative and some of its properties. But how do we actually
know whether a function is analytic or how do we compute its derivative? At this point we
must develop some relationships involving the known quantities u(x, y) and v(x, y).
We begin by returning to the deﬁnition of the derivative. Because ∆z = ∆x + i∆y,
there is an inﬁnite number of diﬀerent ways of approaching the limit ∆z →0. Uniqueness
of that limit requires that Equation 10.3.7 must be independent of the manner in which
∆z approaches zero. A simple example is to take ∆z in the x-direction so that ∆z = ∆x;
another is to take ∆z in the y-direction so that ∆z = i∆y. These examples yield
dw
dz = lim
∆z→0
∆w
∆z = lim
∆x→0
∆u + i∆v
∆x
= ∂u
∂x + i∂v
∂x
(10.3.17)
and
dw
dz = lim
∆z→0
∆w
∆z = lim
∆y→0
∆u + i∆v
i∆y
= ∂v
∂y −i∂u
∂y .
(10.3.18)
1 An analytic function f(z) has a zero of order m at z0 if and only if f(z0) = f′(z0) = · · · = f(m−1)(z0) =
0 and f(m)(z0) ̸= 0.

Complex Variables
451
Although educated as an engineer, Augustin-Louis Cauchy (1789–1857) would become a mathe-
matician’s mathematician, publishing 789 papers and 7 books in the ﬁelds of pure and applied
mathematics. His greatest writings established the discipline of mathematical analysis as he reﬁned
the notions of limit, continuity, function, and convergence. It was this work on analysis that led him
to develop complex function theory via the concept of residues. (Portrait courtesy of the Archives
de l’Acad´emie des sciences, Paris.)
In both cases we are approaching zero from the positive side. For the limit to be unique
and independent of path, Equation 10.3.17 must equal Equation 10.3.18, or
∂u
∂x = ∂v
∂y
and
∂u
∂y = −∂v
∂x.
(10.3.19)
These equations that u and v must both satisfy are the Cauchy-Riemann equations.
They are necessary but not suﬃcient to ensure that a function is diﬀerentiable. The follow-
ing example illustrates this.
• Example 10.3.4
Consider the complex function
w =

z5/|z|4,
z ̸= 0
0,
z = 0.
(10.3.20)
The derivative at z = 0 is given by
dw
dz = lim
∆z→0
(∆z)5/|∆z|4 −0
∆z
= lim
∆z→0
(∆z)4
|∆z|4 ,
(10.3.21)

452
Advanced Engineering Mathematics with MATLAB
Despite his short life, (Georg Friedrich) Bernhard Riemann’s (1826–1866) mathematical work con-
tained many imaginative and profound concepts. It was in his doctoral thesis on complex function
theory (1851) that he introduced the Cauchy-Riemann diﬀerential equations. Riemann’s later work
dealt with the deﬁnition of the integral and the foundations of geometry and non-Euclidean (elliptic)
geometry. (Portrait courtesy of Photo AKG, London, with permission.)
provided that this limit exists. However, this limit does not exist because, in general, the
numerator depends upon the path used to approach zero. For example, if ∆z = reπi/4 with
r →0, dw/dz = −1. On the other hand, if ∆z = reπi/2 with r →0, dw/dz = 1.
Are the Cauchy-Riemann equations satisﬁed in this case? To check this, we ﬁrst com-
pute
ux(0, 0) = lim
∆x→0
 ∆x
|∆x|
4
= 1,
vy(0, 0) = lim
∆y→0
 i∆y
|∆y|
4
= 1,
(10.3.22)
uy(0, 0) = lim
∆y→0 ℜ
 (i∆y)5
∆y|∆y|4

= 0,
and
vx(0, 0) = lim
∆x→0 ℑ
" ∆x
|∆x|
4#
= 0. (10.3.23)
Hence, the Cauchy-Riemann equations are satisﬁed at the origin. Thus, even though the
derivative is not uniquely deﬁned, Equation 10.3.21 happens to have the same value for
paths taken along the coordinate axes so that the Cauchy-Riemann equations are satisﬁed.
⊓⊔
In summary, if a function is diﬀerentiable at a point, the Cauchy-Riemann equations
hold. Similarly, if the Cauchy-Riemann equations are not satisﬁed at a point, then the
function is not diﬀerentiable at that point. This is one of the important uses of the Cauchy-
Riemann equations: the location of nonanalytic points. Isolated nonanalytic points of an
otherwise analytic function are called isolated singularities.
Functions that contain isolated
singularities are called meromorphic.
The Cauchy-Riemann condition can be modiﬁed so that it is suﬃcient for the derivative
to exist. Let us require that ux, uy, vx, and vy be continuous in some region surrounding a

Complex Variables
453
point z0 and satisfy the Cauchy-Riemann equations there. Then
f(z) −f(z0) = [u(z) −u(z0)] + i[v(z) −v(z0)]
(10.3.24)
= [ux(z0)(x −x0) + uy(z0)(y −y0) + ǫ1(x −x0) + ǫ2(y −y0)]
+ i[vx(z0)(x −x0) + vy(z0)(y −y0) + ǫ3(x −x0) + ǫ4(y −y0)]
(10.3.25)
= [ux(z0) + ivx(z0)](z −z0) + (ǫ1 + iǫ3)(x −x0)
+ (ǫ2 + iǫ4)(y −y0),
(10.3.26)
where we used the Cauchy-Riemann equations and ǫ1, ǫ2, ǫ3, ǫ4 →0 as ∆x, ∆y →0. Hence,
f ′(z0) = lim
∆z→0
f(z) −f(z0)
∆z
= ux(z0) + ivx(z0),
(10.3.27)
because |∆x| ≤|∆z| and |∆y| ≤|∆z|. Using Equation 10.3.27 and the Cauchy-Riemann
equations, we can obtain the derivative from any of the following formulas:
dw
dz = ∂u
∂x + i∂v
∂x = ∂v
∂y −i∂u
∂y ,
(10.3.28)
and
dw
dz = ∂v
∂y + i∂v
∂x = ∂u
∂x −i∂u
∂y .
(10.3.29)
Furthermore, f ′(z0) is continuous because the partial derivatives are.
• Example 10.3.5
Let us show that sin(z) is an entire function.
w = sin(z)
(10.3.30)
u + iv = sin(x + iy) = sin(x) cos(iy) + cos(x) sin(iy)
(10.3.31)
= sin(x) cosh(y) + i cos(x) sinh(y),
(10.3.32)
because
cos(iy) = 1
2

ei(iy) + e−i(iy)
= 1
2

ey + e−y
= cosh(y),
(10.3.33)
and
sin(iy) = 1
2i

ei(iy) −e−i(iy)
= −1
2i

ey −e−y
= i sinh(y),
(10.3.34)
so that
u(x, y) = sin(x) cosh(y),
and
v(x, y) = cos(x) sinh(y).
(10.3.35)
Diﬀerentiating both u(x, y) and v(x, y) with respect to x and y, we have that
∂u
∂x = cos(x) cosh(y),
∂u
∂y = sin(x) sinh(y),
(10.3.36)

454
Advanced Engineering Mathematics with MATLAB
∂v
∂x = −sin(x) sinh(y),
∂v
∂y = cos(x) cosh(y),
(10.3.37)
and u(x, y) and v(x, y) satisfy the Cauchy-Riemann equations for all values of x and y.
Furthermore, ux, uy, vx, and vy are continuous for all x and y. Therefore, the function
w = sin(z) is an entire function.
⊓⊔
• Example 10.3.6
Consider the function w = 1/z. Then
w = u + iv =
1
x + iy =
x
x2 + y2 −
iy
x2 + y2 .
(10.3.38)
Therefore,
u(x, y) =
x
x2 + y2 ,
and
v(x, y) = −
y
x2 + y2 .
(10.3.39)
Now
∂u
∂x = (x2 + y2) −2x2
(x2 + y2)2
=
y2 −x2
(x2 + y2)2 ,
(10.3.40)
∂v
∂y = −(x2 + y2) −2y2
(x2 + y2)2
=
y2 −x2
(x2 + y2)2 = ∂u
∂x,
(10.3.41)
∂v
∂x = −0 −2xy
(x2 + y2)2 =
2xy
(x2 + y2)2 ,
(10.3.42)
and
∂u
∂y =
0 −2xy
(x2 + y2)2 = −
2xy
(x2 + y2)2 = −∂v
∂x.
(10.3.43)
The function is analytic at all points except the origin because the function itself ceases to
exist when both x and y are zero and the modulus of w becomes inﬁnite.
⊓⊔
• Example 10.3.7
Let us ﬁnd the derivative of sin(z).
Using Equation 10.3.28 and Equation 10.3.32,
d
dz

sin(z)

= ∂u
∂x + i∂v
∂x = cos(x) cosh(y) −i sin(x) sinh(y) = cos(x + iy) = cos(z).
(10.3.44)
Similarly,
d
dz
1
z

=
y2 −x2
(x2 + y2)2 +
2ixy
(x2 + y2)2 = −
1
(x + iy)2 = −1
z2 .
(10.3.45)
⊓⊔
The results in the above examples are identical to those for z real.
As we showed
earlier, the fundamental rules of elementary calculus apply to complex diﬀerentiation. Con-
sequently, it is usually simpler to apply those rules to ﬁnd the derivative rather than breaking
f(z) down into its real and imaginary parts, applying either Equation 10.3.28 or Equation
10.3.29, and then putting everything back together.

Complex Variables
455
An additional property of analytic functions follows by cross diﬀerentiating the Cauchy-
Riemann equations, or
∂2u
∂x2 = ∂2v
∂x∂y = −∂2u
∂y2 ,
or
∂2u
∂x2 + ∂2u
∂y2 = 0,
(10.3.46)
and
∂2v
∂x2 = −∂2u
∂x∂y = −∂2v
∂y2 ,
or
∂2v
∂x2 + ∂2v
∂y2 = 0.
(10.3.47)
Any function that has continuous partial derivatives of second order and satisﬁes Laplace’s
equation, Equation 10.3.46 or Equation 10.3.47, is called a harmonic function. Because
both u(x, y) and v(x, y) satisfy Laplace’s equation if f(z) = u + iv is analytic, u(x, y) and
v(x, y) are called conjugate harmonic functions.
• Example 10.3.8
Given that u(x, y) = e−x[x sin(y) −y cos(y)], let us show that u is harmonic and ﬁnd
a conjugate harmonic function v(x, y) such that f(z) = u + iv is analytic.
Because
∂2u
∂x2 = −2e−x sin(y) + xe−x sin(y) −ye−x cos(y),
(10.3.48)
and
∂2u
∂y2 = −xe−x sin(y) + 2e−x sin(y) + ye−x cos(y),
(10.3.49)
it follows that uxx + uyy = 0. Therefore, u(x, y) is harmonic. From the Cauchy-Riemann
equations,
∂v
∂y = ∂u
∂x = e−x sin(y) −xe−x sin(y) + ye−x cos(y),
(10.3.50)
and
∂v
∂x = −∂u
∂y = e−x cos(y) −xe−x cos(y) −ye−x sin(y).
(10.3.51)
Integrating Equation 10.3.50 with respect to y,
v(x, y) = ye−x sin(y) + xe−x cos(y) + g(x).
(10.3.52)
Using Equation 10.3.51,
vx = −ye−x sin(y) −xe−x cos(y) + e−x cos(y) + g′(x)
= e−x cos(y) −xe−x cos(y) −ye−x sin(x).
(10.3.53
Therefore, g′(x) = 0 or g(x) = constant. Consequently,
v(x, y) = e−x[y sin(y) + x cos(y)] + constant.
(10.3.54)
Hence, for our real harmonic function u(x, y), there are inﬁnitely many harmonic conjugates
v(x, y), which diﬀer from each other by an additive constant.

456
Advanced Engineering Mathematics with MATLAB
Problems
Show that the following functions are entire:
1. f(z) = iz + 2
2. f(z) = e−z
3. f(z) = z3
4. f(z) = cosh(z)
Find the derivative of the following functions:
5. f(z) = (1 + z2)3/2
6. f(z) = (z + 2z1/2)1/3
7. f(z) = (1 + 4i)z2 −3z −2
8. f(z) = (2z −i)/(z + 2i)
9.
f(z) = (iz −1)−3
Evaluate the following limits:
10.
lim
z→i
z2 −2iz −1
z4 + 2z2 + 1
11.
lim
z→0
z −sin(z)
z3
12. Show that the function f(z) = z∗is nowhere diﬀerentiable.
For each of the following u(x, y), show that it is harmonic and then ﬁnd a corresponding
v(x, y) such that f(z) = u + iv is analytic.
13. u(x, y) = x2 −y2
14. u(x, y) = x4 −6x2y2 + y4 + x
15. u(x, y) = x cos(x)e−y −y sin(x)e−y
16. u(x, y) = (x2 −y2) cos(y)ex −2xy sin(y)ex
10.4 LINE INTEGRALS
So far, we discussed complex numbers, complex functions, and complex diﬀerentiation.
We are now ready for integration.
Just as we have integrals involving real variables, we can deﬁne an integral that involves
complex variables. Because the z-plane is two-dimensional, there is clearly greater freedom
in what we mean by a complex integral. For example, we might ask whether the integral of
some function between points A and B depends upon the curve along which we integrate.
(In general it does.) Consequently, an important ingredient in any complex integration is
the contour that we follow during the integration.
The result of a line integral is a complex number or expression. Unlike its counterpart
in real variables, there is no physical interpretation for this quantity, such as area under
a curve.
Generally, integration in the complex plane is an intermediate process with a
physically realizable quantity occurring only after we take its real or imaginary part. For
example, in potential ﬂuid ﬂow, the lift and drag are found by taking the real and imaginary
part of a complex integral, respectively.
How do we compute
R
C f(z) dz? Let us deal with the deﬁnition; we illustrate the actual
method by examples.
A popular method for evaluating complex line integrals consists of breaking everything
up into real and imaginary parts. This reduces the integral to line integrals of real-valued
functions, which we know how to handle. Thus, we write f(z) = u(x, y) + iv(x, y) as usual,
and because z = x + iy, formally dz = dx + i dy. Therefore,
Z
C
f(z) dz =
Z
C
[u(x, y) + iv(x, y)][dx + i dy]
(10.4.1)
=
Z
C
u(x, y) dx −v(x, y) dy + i
Z
C
v(x, y) dx + u(x, y) dy.
(10.4.2)

Complex Variables
457
y
C
x
2
4
2
2a
C b
C
2
1
Figure 10.4.1: Contour used in Example 10.4.1.
The exact method used to evaluate Equation 10.4.2 depends upon the exact path speciﬁed.
From the deﬁnition of the line integral, we have the following self-evident properties:
Z
C
f(z) dz = −
Z
C′ f(z) dz,
(10.4.3)
where C′ is the contour C taken in the opposite direction of C and
Z
C1+C2
f(z) dz =
Z
C1
f(z) dz +
Z
C2
f(z) dz.
(10.4.4)
• Example 10.4.1
Let us evaluate
R
C z∗dz from z = 0 to z = 4+2i along two diﬀerent contours. The ﬁrst
consists of the parametric equation z = t2 + it. The second consists of two “dog legs”: the
ﬁrst leg runs along the imaginary axis from z = 0 to z = 2i and then along a line parallel
to the x-axis from z = 2i to z = 4 + 2i. See Figure 10.4.1.
For the ﬁrst case, the points z = 0 and z = 4 + 2i on C1 correspond to t = 0 and t = 2,
respectively. Then the line integral equals
Z
C1
z∗dz =
Z 2
0
(t2 + it)∗d(t2 + it) =
Z 2
0
(2t3 −it2 + t) dt = 10 −8i
3 .
(10.4.5)
The line integral for the second contour C2 equals
Z
C2
z∗dz =
Z
C2a
z∗dz +
Z
C2b
z∗dz,
(10.4.6)
where C2a denotes the integration from z = 0 to z = 2i while C2b denotes the integration
from z = 2i to z = 4 + 2i. For the ﬁrst integral,
Z
C2a
z∗dz =
Z
C2a
(x −iy)(dx + i dy) =
Z 2
0
y dy = 2,
(10.4.7)
because x = 0 and dx = 0 along C2a. On the other hand, along C2b, y = 2 and dy = 0 so
that
Z
C2b
z∗dz =
Z
C2b
(x −iy)(dx + i dy) =
Z 4
0
x dx + i
Z 4
0
−2 dx = 8 −8i.
(10.4.8)

458
Advanced Engineering Mathematics with MATLAB
C
1
C
C
y
1
x
2 b
2 a
1
2
Figure 10.4.2: Contour used in Example 10.4.2.
Thus the value of the entire C2 contour integral equals the sum of the two parts, or 10−8i.
The point here is that integration along two diﬀerent paths has given us diﬀerent results
even though we integrated from z = 0 to z = 4 + 2i both times. This result foreshadows
a general result that is extremely important. Because the integrand contains nonanalytic
points along and inside the region enclosed by our two curves, as shown by the Cauchy-
Riemann equations, the results depend upon the path taken. Since complex integrations
often involve integrands that have nonanalytic points, many line integrations depend upon
the contour taken.
⊓⊔
• Example 10.4.2
Let us integrate the entire function f(z) = z2 along the two paths from z = 0 to
z = 2 + i shown in Figure 10.4.2. For the ﬁrst integration, x = 2y, while along the second
path we have two straight paths: z = 0 to z = 2 and z = 2 to z = 2 + i.
For the ﬁrst contour integration,
Z
C1
z2dz =
Z 1
0
(2y + iy)2(2 dy + i dy) =
Z 1
0
(3y2 + 4y2i)(2 dy + i dy)
(10.4.9)
=
Z 1
0
6y2 dy + 8y2i dy + 3y2i dy −4y2 dy =
Z 1
0
2y2 dy + 11y2i dy
(10.4.10)
= 2
3y3|1
0 + 11
3 iy3|1
0 = 2
3 + 11i
3 .
(10.4.11)
For our second integration,
Z
C2
z2 dz =
Z
C2a
z2 dz +
Z
C2b
z2 dz.
(10.4.12)
Along C2a we ﬁnd that y = dy = 0 so that
Z
C2a
z2 dz =
Z 2
0
x2 dx = 1
3x3|2
0 = 8
3,
(10.4.13)
and
Z
C2b
z2 dz =
Z 1
0
(2 + iy)2i dy = i

4y + 2iy2 −y3
3

1
0
= 4i −2 −i
3,
(10.4.14)
because x = 2 and dx = 0. Consequently,
Z
C2
z2 dz = 2
3 + 11i
3 .
(10.4.15)

Complex Variables
459
y
x
(0,−1)
C
C
C 
2
1
3
(−1,0)
(0,1)
(1,0)
Figure 10.4.3: Contour used in Example 10.4.3.
In this problem we obtained the same results from two diﬀerent contours of integration.
Exploring other contours, we would ﬁnd that the results are always the same; the integration
is path-independent. But what makes these results path-independent while the integration
in Example 10.4.1 was not? Perhaps it is the fact that the integrand is analytic everywhere
on the complex plane and there are no nonanalytic points. We will explore this later.
⊓⊔
Finally, an important class of line integrals involves closed contours. We denote this
special subclass of line integrals by placing a circle on the integral sign:
H
. Consider now
the following examples:
• Example 10.4.3
Let us integrate f(z) = z around the closed contour shown in Figure 10.4.3.
From Figure 10.4.3,
I
C
z dz =
Z
C1
z dz +
Z
C2
z dz +
Z
C3
z dz.
(10.4.16)
Now
Z
C1
z dz =
Z 0
1
iy (i dy) = −
Z 0
1
y dy = −y2
2

0
1
= 1
2,
(10.4.17)
Z
C2
z dz =
Z −1
0
x dx = x2
2

−1
0
= 1
2,
(10.4.18)
and
Z
C3
z dz =
Z π/2
−π
eθiieθidθ = e2θi
2

π/2
−π
= −1,
(10.4.19)
where we used z = eθi around the portion of the unit circle. Therefore, the closed line
integral equals zero.
⊓⊔
• Example 10.4.4
Let us integrate f(z) = 1/(z −a) around any circle centered on z = a. The Cauchy-
Riemann equations show that f(z) is a meromorphic function. It is analytic everywhere
except at the isolated singularity z = a.

460
Advanced Engineering Mathematics with MATLAB
If we introduce polar coordinates by letting z −a = reθi and dz = ireθidθ,
I
C
dz
z −a =
Z 2π
0
ireθi
reθi dθ = i
Z 2π
0
dθ = 2πi.
(10.4.20)
Note that the integrand becomes undeﬁned at z = a. Furthermore, the answer is indepen-
dent of the size of the circle. Our example suggests that when we have a closed contour
integration it is the behavior of the function within the contour rather than the exact shape
of the closed contour that is of importance. We will return to this point in later sections.
Problems
1. Evaluate
H
C(z∗)2 dz around the circle |z| = 1 taken in the counterclockwise direction.
2. Evaluate
H
C |z|2 dz around the square with vertices at (0,0), (1,0), (1,1), and (0,1) taken
in the counterclockwise direction.
3. Evaluate
R
C |z| dz along the right half of the circle |z| = 1 from z = −i to z = i.
4. Evaluate
R
C ez dz along the line y = x from (−1, −1) to (1, 1).
5. Evaluate
R
C(z∗)2 dz along the line y = x2 from (0, 0) to (1, 1).
6. Evaluate
R
C z−1/2 dz, where C is (a) the upper semicircle |z| = 1 and (b) the lower semi-
circle |z| = 1. If z = reθi, restrict −π < θ < π. Take both contours in the counterclockwise
direction.
10.5 THE CAUCHY-GOURSAT THEOREM
In the previous section we showed how to evaluate line integrations by brute-force
reduction to real-valued integrals. In general, this direct approach is quite diﬃcult and we
would like to apply some of the deeper properties of complex analysis to work smarter. In
the remaining portions of this chapter we introduce several theorems that will do just that.
If we scan over the examples worked in the previous section, we see considerable diﬀer-
ences when the function was analytic inside and on the contour and when it was not. We
may formalize this anecdotal evidence into the following theorem:
Cauchy-Goursat theorem:2 Let f(z) be analytic in a domain D and let C be a simple
Jordan curve3 inside D so that f(z) is analytic on and inside of C. Then
H
C f(z) dz = 0.
Proof : Let C denote the contour around which we will integrate w = f(z). We divide the
region within C into a series of inﬁnitesimal rectangles. See Figure 10.5.1. The integration
2 Goursat, E., 1900: Sur la d´eﬁnition g´en´erale des fonctions analytiques, d’apr`es Cauchy. Trans. Am.
Math. Soc., 1, 14–16.
3 A Jordan curve is a simply closed curve. It looks like a closed loop that does not cross itself. See
Figure 10.5.2.

Complex Variables
461
C
x
y
Figure 10.5.1: Diagram used in proving the Cauchy-Goursat theorem.
around each rectangle equals the product of the average value of w on each side and its
length,

w + ∂w
∂x
dx
2

dx +

w + ∂w
∂x dx + ∂w
∂(iy)
d(iy)
2

d(iy)
+

w + ∂w
∂x
dx
2 + ∂w
∂(iy) d(iy)

(−dx) +

w + ∂w
∂(iy)
d(iy)
2

d(−iy)
=
∂w
∂x −∂w
i∂y

(i dx dy).
(10.5.1)
Substituting w = u + iv into Equation 10.5.1,
∂w
∂x −∂w
i ∂y =
∂u
∂x −∂v
∂y

+ i
∂v
∂x + ∂u
∂y

.
(10.5.2)
Because the function is analytic, the right side of Equation 10.5.1 and Equation 10.5.2
equals zero. Thus, the integration around each of these rectangles also equals zero.
We note next that in integrating around adjoining rectangles we transverse each side
in opposite directions, the net result being equivalent to integrating around the outer curve
C. We therefore arrive at the result
H
C f(z) dz = 0, where f(z) is analytic within and on
the closed contour.
⊓⊔
The Cauchy-Goursat theorem has several useful implications. Suppose that we have a
domain where f(z) is analytic. Within this domain let us evaluate a line integral from point
A to B along two diﬀerent contours C1 and C2. Then, the integral around the closed contour
formed by integrating along C1 and then back along C2, only in the opposite direction, is
I
C
f(z) dz =
Z
C1
f(z) dz −
Z
C2
f(z) dz = 0
(10.5.3)
or
Z
C1
f(z) dz =
Z
C2
f(z) dz.
(10.5.4)

462
Advanced Engineering Mathematics with MATLAB
x
y
(a)
(b)
Figure 10.5.2: Examples of a (a) simply closed curve and (b) not simply closed curve.
Because C1 and C2 are completely arbitrary, we have the result that if, in a domain, f(z)
is analytic, the integral between any two points within the domain is path independent.
One obvious advantage of path independence is the ability to choose the contour so
that the computations are made easier. This obvious choice immediately leads to
The principle of deformation of contours: The value of a line integral of an analytic
function around any simple closed contour remains unchanged if we deform the contour in
such a manner that we do not pass over a nonanalytic point.
⊓⊔
• Example 10.5.1
Let us integrate f(z) = z−1 around the closed contour C in the counterclockwise
direction. This contour consists of a square, centered on the origin, with vertices at (1, 1),
(1, −1), (−1, 1), and (−1, −1).
The direct integration of
H
C z−1dz around the original contour is very cumbersome.
However, because the integrand is analytic everywhere except at the origin, we may deform
the origin contour into a circle of radius r, centered on the origin. Then, z = reθi and
dz = rieθidθ so that
I
C
dz
z =
Z 2π
0
rieθi
reθi dθ = i
Z 2π
0
dθ = 2πi.
(10.5.5)
The point here is that no matter how bizarre the contour is, as long as it encircles the origin
and is a simply closed contour, we can deform it into a circle and we get the same answer
for the contour integral. This suggests that it is not the shape of the closed contour that
makes the diﬀerence but whether we enclose any singularities (points where f(z) becomes
undeﬁned) that matters. We shall return to this idea many times in the next few sections.⊓⊔
Finally, suppose that we have a function f(z) such that f(z) is analytic in some domain.
Furthermore, let us introduce the analytic function F(z) such that f(z) = F ′(z). We would
like to evaluate
R b
a f(z) dz in terms of F(z).
We begin by noting that we can represent F, f as F(z) = U + iV and f(z) = u + iv.
From Example 10.3.28 we have that u = Ux and v = Vx. Therefore,
Z b
a
f(z) dz =
Z b
a
(u + iv)(dx + i dy) =
Z b
a
Ux dx −Vx dy + i
Z b
a
Vx dx + Ux dy
(10.5.6)

Complex Variables
463
=
Z b
a
Ux dx + Uy dy + i
Z b
a
Vx dx + Vy dy =
Z b
a
dU + i
Z b
a
dV = F(b) −F(a)
(10.5.7)
or
Z b
a
f(z) dz = F(b) −F(a).
(10.5.8)
Equation 10.5.8 is the complex variable form of the fundamental theorem of calculus. Thus,
if we can ﬁnd the antiderivative of a function f(z) that is analytic within a speciﬁc region,
we can evaluate the integral by evaluating the antiderivative at the endpoints for any curves
within that region.
• Example 10.5.2
Let us evaluate
R πi
0 z sin(z2) dz.
The integrand f(z) = z sin(z2) is an entire function and its antiderivative equals
−1
2 cos(z2). Therefore,
Z πi
0
z sin(z2) dz = −1
2 cos(z2)
πi
0 = 1
2[cos(0) −cos(−π2)] = 1
2[1 −cos(π2)].
(10.5.9)
Problems
For the following integrals, show that they are path independent and determine the value
of the integral:
1.
Z 2+3πi
1−πi
e−2z dz
2.
Z 2π
0
[ez −cos(z)] dz
3.
Z π
0
sin2(z) dz
4.
Z 2i
−i
(z + 1) dz
10.6 CAUCHY’S INTEGRAL FORMULA
In the previous section, our examples suggested that the presence of a singularity
within a contour really determines the value of a closed contour integral. Continuing with
this idea, let us consider a class of closed contour integrals that explicitly contain a single
singularity within the contour, namely
H
C g(z) dz, where g(z) = f(z)/(z −z0), and f(z) is
analytic within and on the contour C. We closed the contour in the positive sense where
the enclosed area lies to your left as you move along the contour.
We begin by examining a closed contour integral where the closed contour consists of
the C1, C2, C3, and C4 as shown in Figure 10.6.1. The gap or cut between C2 and C4 is
very small. Because g(z) is analytic within and on the closed integral, we have that
Z
C1
f(z)
z −z0
dz +
Z
C2
f(z)
z −z0
dz +
Z
C3
f(z)
z −z0
dz +
Z
C4
f(z)
z −z0
dz = 0.
(10.6.1)
It can be shown that the contribution to the integral from the path C2 going into the
singularity cancels the contribution from the path C4 going away from the singularity as
the gap between them vanishes. Because f(z) is analytic at z0, we can approximate its

464
Advanced Engineering Mathematics with MATLAB
2
C1
x
y
C
C
C
3
4
Figure 10.6.1: Diagram used to prove Cauchy’s integral formula.
value on C3 by f(z) = f(z0) + δ(z), where δ is a small quantity. Substituting into Equation
10.6.1,
I
C1
f(z)
z −z0
dz = −f(z0)
Z
C3
1
z −z0
dz −
Z
C3
δ(z)
z −z0
dz.
(10.6.2)
Consequently, as the gap between C2 and C4 vanishes, the contour C1 becomes the closed
contour C so that Equation 10.6.2 may be written
I
C
f(z)
z −z0
dz = 2πif(z0) + i
Z 2π
0
δ dθ,
(10.6.3)
where we set z −z0 = ǫeθi and dz = iǫeθidθ.
Let M denote the value of the integral on the right side of Equation 10.6.3 and ∆equal
the greatest value of the modulus of δ along the circle. Then
|M| <
Z 2π
0
|δ| dθ ≤
Z 2π
0
∆dθ = 2π∆.
(10.6.4)
As the radius of the circle diminishes to zero, ∆also diminishes to zero. Therefore, |M|,
which is positive, becomes less than any ﬁnite quantity, however small, and M itself equals
zero. Thus, we have that
f(z0) =
1
2πi
I
C
f(z)
z −z0
dz.
(10.6.5)
This equation is Cauchy’s integral formula. By taking n derivatives of Equation 10.6.5, we
can extend Cauchy’s integral formula4 to
f (n)(z0) = n!
2πi
I
C
f(z)
(z −z0)n+1 dz
(10.6.6)
4 See Carrier, G. F., M. Krook, and C. E. Pearson, 1966: Functions of a Complex Variable: Theory
and Technique. McGraw-Hill, pp. 39–40 for the proof.

Complex Variables
465
for n = 1, 2, 3, . . .. For computing integrals, it is convenient to rewrite Equation 10.6.6 as
I
C
f(z)
(z −z0)n+1 dz = 2πi
n! f (n)(z0).
(10.6.7)
• Example 10.6.1
Let us ﬁnd the value of the integral
I
C
cos(πz)
(z −1)(z −2) dz,
(10.6.8)
where C is the circle |z| = 5. Using partial fractions,
1
(z −1)(z −2) =
1
z −2 −
1
z −1,
(10.6.9)
and
I
C
cos(πz)
(z −1)(z −2) dz =
I
C
cos(πz)
z −2 dz −
I
C
cos(πz)
z −1 dz.
(10.6.10)
By Cauchy’s integral formula with z0 = 2 and z0 = 1,
I
C
cos(πz)
z −2 dz = 2πi cos(2π) = 2πi,
(10.6.11)
and
I
C
cos(πz)
z −1 dz = 2πi cos(π) = −2πi,
(10.6.12)
because z0 = 1 and z0 = 2 lie inside C and cos(πz) is analytic there. Thus the required
integral has the value
I
C
cos(πz)
(z −1)(z −2) dz = 4πi.
(10.6.13)
⊓⊔
• Example 10.6.2
Let us use Cauchy’s integral formula to evaluate
I =
I
|z|=2
ez
(z −1)2(z −3) dz.
(10.6.14)
We need to convert Equation 10.6.14 into the form Equation 10.6.7. To do this, we
rewrite Equation 10.6.14 as
I
|z|=2
ez
(z −1)2(z −3) dz =
I
|z|=2
ez/(z −3)
(z −1)2
dz.
(10.6.15)
Therefore, f(z) = ez/(z −3), n = 1, and z0 = 1. The function f(z) is analytic within
the closed contour because the point z = 3 lies outside of the contour. Applying Cauchy’s
integral formula,
I
|z|=2
ez
(z −1)2(z −3) dz = 2πi
1!
d
dz
 ez
z −3

z=1
= 2πi
 ez
z −3 −
ez
(z −3)2

z=1
= −3πie
2
.
(10.6.16)

466
Advanced Engineering Mathematics with MATLAB
Project: Computing Derivatives of Any Order of a Complex or Real Function
The most common technique for computing a derivative is ﬁnite diﬀerencing. Recently
Mahajerin and Burgess5 showed how Cauchy’s integral formula can be used to compute the
derivatives of any order of a complex or real function via numerical quadrature. In this
project you will derive the algorithm, write code implementing it, and ﬁnally test it.
Step 1: Consider the complex function f(z) = u + iv, which is analytic inside the closed
circular contour C of radius R centered at z0. Using Cauchy’s integral formula, show that
f (n)(z0) =
n!
2πRn
Z 2π
0
[u(x, y) + iv(x, y)][cos(nθ) −i sin(nθ)] dθ,
where x = x0 + R cos(θ), and y = y0 + R sin(θ).
Step 2: Using ﬁve-point Gaussian quadrature, write code to implement the results from
Step 1.
Step 3: Test out this scheme by ﬁnding the ﬁrst, sixth, and eleventh derivative of f(x) =
8x/(x2 + 4) for x = 2. The exact answers are 0, 2.8125, and 1218.164, respectively. What
is the maximum value of R? How does the accuracy vary with the number of subdivisions
used in the numerical integration? Is the algorithm sensitive to the value of R and the
number of subdivisions? For a ﬁxed number of subdivisions, is there an optimal R?
Problems
Use Cauchy’s integral formula to evaluate the following integrals. Assume all of the contours
are in the positive sense.
1.
I
|z|=1
sin6(z)
z −π/6 dz
2.
I
|z|=1
sin6(z)
(z −π/6)3 dz
3.
I
|z|=1
1
z(z2 + 4) dz
4.
I
|z|=1
tan(z)
z
dz
5.
I
|z−1|=1/2
1
(z −1)(z −2) dz
6.
I
|z|=5
exp(z2)
z3
dz
7.
I
|z−1|=1
z2 + 1
z2 −1 dz
8.
I
|z|=2
z2
(z −1)4 dz
9.
I
|z|=2
z3
(z + i)3 dz
10.
I
|z|=1
cos(z)
z2n+1 dz
10.7 TAYLOR AND LAURENT EXPANSIONS AND SINGULARITIES
In the previous section we showed what a crucial role singularities play in complex
integration. Before we can ﬁnd the most general way of computing a closed complex integral,
our understanding of singularities must deepen. For this, we employ power series.
5 Mahajerin, E., and G. Burgess, 1993: An algorithm for computing derivatives of any order of a complex
or real function. Computers & Struct., 49, 385–387.

Complex Variables
467
One reason why power series are so important is their ability to provide locally a general
representation of a function even when its arguments are complex. For example, when we
were introduced to trigonometric functions in high school, it was in the context of a right
triangle and a real angle. However, when the argument becomes complex, this geometrical
description disappears and power series provide a formalism for deﬁning the trigonometric
functions, regardless of the nature of the argument.
Let us begin our analysis by considering the complex function f(z), which is analytic
everywhere on the boundary, and the interior of a circle whose center is at z = z0. Then, if
z denotes any point within the circle, we have from Cauchy’s integral formula that
f(z) =
1
2πi
I
C
f(ζ)
ζ −z dζ =
1
2πi
I
C
f(ζ)
ζ −z0

1
1 −(z −z0)/(ζ −z0)

dζ,
(10.7.1)
where C denotes the closed contour. Expanding the bracketed term as a geometric series,
we ﬁnd that
f(z) =
1
2πi
I
C
f(ζ)
ζ −z0
dζ +(z−z0)
I
C
f(ζ)
(ζ −z0)2 dζ +· · ·+(z−z0)n
I
C
f(ζ)
(ζ −z0)n+1 dζ +· · ·

.
(10.7.2)
Applying Cauchy’s integral formula to each integral in Equation 10.7.2, we ﬁnally obtain
f(z) = f(z0) + (z −z0)
1!
f ′(z0) + · · · + (z −z0)n
n!
f (n)(z0) + · · ·
(10.7.3)
or the familiar formula for a Taylor expansion. Consequently, we can expand any analytic
function into a Taylor series. Interestingly, the radius of convergence6 of this series may be
shown to be the distance between z0 and the nearest nonanalytic point of f(z).
• Example 10.7.1
Let us ﬁnd the expansion of f(z) = sin(z) about the point z0 = 0.
Because f(z) is an entire function, we can construct a Taylor expansion anywhere on
the complex plane. For z0 = 0,
f(z) = f(0) + 1
1!f ′(0)z + 1
2!f ′′(0)z2 + 1
3!f ′′′(0)z3 + · · · .
(10.7.4)
Because f(0) = 0, f ′(0) = 1, f ′′(0) = 0, f ′′′(0) = −1 and so forth,
f(z) = z −z3
3! + z5
5! −z7
7! + · · · .
(10.7.5)
Because sin(z) is an entire function, the radius of convergence is |z −0| < ∞, i.e., all z. ⊓⊔
• Example 10.7.2
Let us ﬁnd the expansion of f(z) = 1/(1 −z) about the point z0 = 0.
From the formula for a Taylor expansion,
f(z) = f(0) + 1
1!f ′(0)z + 1
2!f ′′(0)z2 + 1
3!f ′′′(0)z3 + · · · .
(10.7.6)
6 A positive number h such that the series diverges for |z −z0| > h but converges absolutely for
|z −z0| < h.

468
Advanced Engineering Mathematics with MATLAB
0
C
C
C
z
y
x
2
1
z
Figure 10.7.1: Contour used in deriving the Laurent expansion.
Because f (n)(0) = n!, we ﬁnd that
f(z) = 1 + z + z2 + z3 + z4 + · · · =
1
1 −z .
(10.7.7)
Equation 10.7.7 is the familiar result for a geometric series. Because the only nonanalytic
point is at z = 1, the radius of convergence is |z −0| < 1, the unit circle centered at z = 0.⊓⊔
Consider now the situation where we draw two concentric circles about some arbitrary
point z0; we denote the outer circle by C while we denote the inner circle by C1. See Figure
10.7.1.
Let us assume that f(z) is analytic inside the annulus between the two circles.
Outside of this area, the function may or may not be analytic. Within the annulus we pick
a point z and construct a small circle around it, denoting the circle by C2. As the gap or
cut in the annulus becomes inﬁnitesimally small, the line integrals that connect the circle
C2 to C1 and C sum to zero, leaving
I
C
f(ζ)
ζ −z dζ =
I
C1
f(ζ)
ζ −z dζ +
I
C2
f(ζ)
ζ −z dζ.
(10.7.8)
Because f(ζ) is analytic everywhere within C2,
2πif(z) =
I
C2
f(ζ)
ζ −z dζ.
(10.7.9)
Using the relationship:
I
C1
f(ζ)
ζ −z dζ = −
I
C1
f(ζ)
z −ζ dζ,
(10.7.10)
Equation 10.7.8 becomes
f(z) =
1
2πi
I
C
f(ζ)
ζ −z dζ +
1
2πi
I
C1
f(ζ)
z −ζ dζ.
(10.7.11)
Now,
1
ζ −z =
1
ζ −z0 −z + z0
=
1
ζ −z0
1
1 −(z −z0)/(ζ −z0)
(10.7.12)
=
1
ζ −z0
"
1 +
z −z0
ζ −z0

+
z −z0
ζ −z0
2
+ · · · +
z −z0
ζ −z0
n
+ · · ·
#
,
(10.7.13)

Complex Variables
469
where |z −z0|/|ζ −z0| < 1 and
1
z −ζ =
1
z −z0 −ζ + z0
=
1
z −z0
1
1 −(ζ −z0)/(z −z0)
(10.7.14)
=
1
z −z0
"
1 +
ζ −z0
z −z0

+
ζ −z0
z −z0
2
+ · · · +
ζ −z0
z −z0
n
+ · · ·
#
,
(10.7.15)
where |ζ −z0|/|z −z0| < 1. Upon substituting these expressions into Equation 10.7.11,
f(z) =
 1
2πi
I
C
f(ζ)
ζ −z0
dζ + z −z0
2πi
I
C
f(ζ)
(ζ −z0)2 dζ + · · ·
+ (z −z0)n
2πi
I
C
f(ζ)
(ζ −z0)n+1 dζ + · · ·

+

1
z −z0
1
2πi
I
C1
f(ζ) dζ +
1
(z −z0)2
1
2πi
I
C1
f(ζ)(ζ −z0) dζ + · · ·
+
1
(z −z0)n
1
2πi
I
C1
f(ζ)(ζ −z0)n−1 dζ + · · ·

(10.7.16)
or
f(z) =
a1
z −z0
+
a2
(z −z0)2 + · · · +
an
(z −z0)n + · · · + b0 + b1(z −z0) + · · · + bn(z −z0)n + · · · .
(10.7.17)
Equation 10.7.17 is a Laurent expansion.7 If f(z) is analytic at z0, then a1 = a2 = · · · =
an = · · · = 0 and the Laurent expansion reduces to a Taylor expansion. If z0 is a singu-
larity of f(z), then the Laurent expansion includes both positive and negative powers. The
coeﬃcient of the (z −z0)−1 term, a1, is the residue, for reasons that will appear in the next
section.
Unlike the Taylor series, a Laurent series provides no straightforward method for ob-
taining the coeﬃcients. For the remaining portions of this section we illustrate their con-
struction. These techniques include replacing a function by its appropriate power series,
the use of geometric series to expand the denominator, and the use of algebraic tricks to
assist in applying the ﬁrst two methods.
• Example 10.7.3
Laurent expansions provide a formalism for the classiﬁcation of singularities of a func-
tion. Isolated singularities fall into three types; they are
• Essential Singularity: Consider the function f(z) = cos(1/z). Using the expansion for
cosine,
cos
1
z

= 1 −
1
2!z2 +
1
4!z4 −
1
6!z6 + · · ·
(10.7.18)
for 0 < |z| < ∞. Note that this series never truncates in the inverse powers of z. Essential
singularities have Laurent expansions, which have an inﬁnite number of inverse powers of
z −z0. The value of the residue for this essential singularity at z = 0 is zero.
7 Laurent, M., 1843: Extension du th´eor`eme de M. Cauchy relatif `a la convergence du d´eveloppement
d’une fonction suivant les puissances ascendantes de la variable x. C. R. l’Acad. Sci., 17, 938–942.

470
Advanced Engineering Mathematics with MATLAB
• Removable Singularity: Consider the function f(z) = sin(z)/z.
This function has a
singularity at z = 0. Upon applying the expansion for sine,
sin(z)
z
= 1
z

z −z3
3! + z5
5! −z7
7! + z9
9! −. . .

= 1 −z2
3! + z4
5! −z6
7! + z8
9! −. . .
(10.7.19)
for all z, if the division is permissible. We made f(z) analytic by deﬁning it by Equation
10.7.19 and, in the process, removed the singularity. The residue for a removable singularity
always equals zero.
• Pole of order n: Consider the function
f(z) =
1
(z −1)3(z + 1).
(10.7.20)
This function has two singularities: one at z = 1 and the other at z = −1. We shall only
consider the case z = 1. After a little algebra,
f(z) =
1
(z −1)3
1
2 + (z −1) = 1
2
1
(z −1)3
1
1 + (z −1)/2
(10.7.21)
= 1
2
1
(z −1)3

1 −z −1
2
+ (z −1)2
4
−(z −1)3
8
+ · · ·

(10.7.22)
=
1
2(z −1)3 −
1
4(z −1)2 +
1
8(z −1) −1
16 + · · ·
(10.7.23)
for 0 < |z −1| < 2. Because the largest inverse (negative) power is three, the singularity
at z = 1 is a third-order pole; the value of the residue is 1/8. Generally, we refer to a
ﬁrst-order pole as a simple pole.
⊓⊔
• Example 10.7.4
Let us ﬁnd the Laurent expansion for
f(z) =
z
(z −1)(z −3)
(10.7.24)
about the point z = 1.
We begin by rewriting f(z) as
f(z) =
1 + (z −1)
(z −1)[−2 + (z −1)] = −1
2
1 + (z −1)
(z −1)[1 −1
2(z −1)]
(10.7.25)
= −1
2
1 + (z −1)
(z −1)
[1 + 1
2(z −1) + 1
4(z −1)2 + · · ·]
(10.7.26)
= −1
2
1
z −1 −3
4 −3
8 (z −1) −3
16 (z −1)2 −· · ·
(10.7.27)
provided 0 < |z −1| < 2. Therefore we have a simple pole at z = 1 and the value of the
residue is −1/2. A similar procedure would yield the Laurent expansion about z = 3.
⊓⊔

Complex Variables
471
• Example 10.7.5
Let us ﬁnd the Laurent expansion for
f(z) =
zn + z−n
z2 −2z cosh(α) + 1,
α > 0,
n ≥0,
(10.7.28)
about the point z = 0.
We begin by rewriting f(z) as
f(z) =
zn + z−n
(z −eα)(z −e−α) =
1
2 sinh(α)
zn + z−n
z −eα
−zn + z−n
z −e−α

.
(10.7.29)
Because
1
z −eα = −
e−α
1 −ze−α = −e−α  1 + ze−α + z2e−2α + · · ·

(10.7.30)
if |z| < eα and
1
z −e−α = −
eα
1 −zeα = −eα  1 + zeα + z2e2α + · · ·

(10.7.31)
if |z| < e−α,
f(z) =
eα
2 sinh(α)
 zn + zn+1eα + zn+2e2α + · · · + z−n + z1−neα + z2−ne2α + · · ·

(10.7.32)
−
e−α
2 sinh(α)
 zn + zn+1e−α + zn+2e−2α + · · · + z−n + z1−ne−α + z2−ne−2α + · · ·

,
if |z| < e−α. Clearly we have an nth-order pole at z = 0. The residue, the coeﬃcient of all
of the z−1 terms in Equation 10.7.32, is found directly and equals
Res[f(z); 0] = sinh(nα)
sinh(α) .
(10.7.33)
⊓⊔
For complicated complex functions, it is very diﬃcult to determine the nature of the
singularities by ﬁnding the complete Laurent expansion, and we must try another method.
We shall call it “a poor man’s Laurent expansion.” The idea behind this method is the
fact that we generally need only the ﬁrst few terms of the Laurent expansion to discover
its nature. Consequently, we compute these terms through the application of power series
where we retain only the leading terms. Consider the following example.
• Example 10.7.6
Let us discover the nature of the singularity at z = 0 of the function
f(z) =
etz
z sinh(az),
(10.7.34)
where a and t are real.

472
Advanced Engineering Mathematics with MATLAB
We begin by replacing the exponential and hyperbolic sine by their Taylor expansion
about z = 0. Then
f(z) = 1 + tz + t2z2/2 + · · ·
z(az + a3z3/6 + · · ·) .
(10.7.35)
Factoring out az in the denominator,
f(z) = 1 + tz + t2z2/2 + · · ·
az2(1 + a2z2/6 + · · ·).
(10.7.36)
Within the parentheses all of the terms except the leading one are small. Therefore, by long
division, we formally have that
f(z) =
1
az2 (1 + tz + t2z2/2 + · · ·)(1 −a2z2/6 + · · ·)
(10.7.37)
=
1
az2 (1 + tz + t2z2/2 −a2z2/6 + · · ·) =
1
az2 + t
az + 3t2 −a2
6a
+ · · · .
(10.7.38)
Thus, we have a second-order pole at z = 0 and the residue equals t/a.
Problems
1. Find the Taylor expansion of f(z) = (1 −z)−2 about the point z = 0.
2. Find the Taylor expansion of f(z) = (z −1)ez about the point z = 1. (Hint: Don’t ﬁnd
the expansion by taking derivatives.)
By constructing a Laurent expansion, describe the type of singularity and give the residue
at z0 for each of the following functions:
3. f(z) = z10e−1/z;
z0 = 0
4. f(z) = z−3 sin2(z);
z0 = 0
5. f(z) = cosh(z) −1
z2
;
z0 = 0
6. f(z) =
z
(z + 2)2 ;
z0 = −2
7. f(z) = ez + 1
e−z −1;
z0 = 0
8. f(z) =
eiz
z2 + b2 ;
z0 = bi
9. f(z) =
1
z(z −2);
z0 = 2
10. f(z) = exp(z2)
z4
;
z0 = 0
10.8 THEORY OF RESIDUES
Having shown that around any singularity we may construct a Laurent expansion,
we now use this result in the integration of closed complex integrals. Consider a closed
contour in which the function f(z) has a number of isolated singularities. As we did in the
case of Cauchy’s integral formula, we introduce a new contour C′ that excludes all of the
singularities because they are isolated. See Figure 10.8.1. Therefore,
I
C
f(z) dz −
I
C1
f(z) dz −· · · −
I
Cn
f(z) dz =
I
C′ f(z) dz = 0.
(10.8.1)

Complex Variables
473
1
x
y
C
n
2
1
z
z
z
Cn
C
C   
2
Figure 10.8.1: Contour used in deriving the residue theorem.
Consider now the mth integral, where 1 ≤m ≤n. Constructing a Laurent expansion for
the function f(z) at the isolated singularity z = zm, this integral equals
I
Cm
f(z) dz =
∞
X
k=1
ak
I
Cm
1
(z −zm)k dz +
∞
X
k=0
bk
I
Cm
(z −zm)k dz.
(10.8.2)
Because (z −zm)k is an entire function if k ≥0, the integrals equal zero for each term in
the second summation. We use Cauchy’s integral formula to evaluate the remaining terms.
The analytic function in the numerator is 1. Because dk−1(1)/dzk−1 = 0 if k > 1, all of
the terms vanish except for k = 1. In that case, the integral equals 2πia1, where a1 is the
value of the residue for that particular singularity. Applying this approach to each of the
singularities, we obtain
Cauchy’s residue theorem:8 If f(z) is analytic inside and on a closed contour C (taken
in the positive sense) except at points z1, z2, . . ., zn where f(z) has singularities, then
I
C
f(z) dz = 2πi
n
X
j=1
Res[f(z); zj],
(10.8.3)
where Res[f(z); zj] denotes the residue of the jth isolated singularity of f(z) located at
z = zj.
⊓⊔
• Example 10.8.1
Let us compute
H
|z|=2 z2/(z + 1) dz by the residue theorem, assuming that we take the
contour in the positive sense.
Because the contour is a circle of radius 2, centered on the origin, the singularity at
z = −1 lies within the contour. If the singularity were not inside the contour, then the
8 See Mitrinovi´c, D. S., and J. D. Ke˘cki´c, 1984: The Cauchy Method of Residues: Theory and Ap-
plications.
D. Reidel Publishing, 361 pp.
Section 10.3 gives the historical development of the residue
theorem.

474
Advanced Engineering Mathematics with MATLAB
integrand would have been analytic inside and on the contour C. In this case, the answer
would then be zero by the Cauchy-Goursat theorem.
Returning to the original problem, we construct the Laurent expansion for the integrand
around the point z = 1 by noting that
z2
z + 1 = [(z + 1) −1]2
z + 1
=
1
z + 1 −2 + (z + 1).
(10.8.4)
The singularity at z = −1 is a simple pole and by inspection the value of the residue equals
1. Therefore,
I
|z|=2
z2
z + 1 dz = 2πi.
(10.8.5)
⊓⊔
As it presently stands, it would appear that we must always construct a Laurent expan-
sion for each singularity if we wish to use the residue theorem. This becomes increasingly
diﬃcult as the structure of the integrand becomes more complicated.
In the following
paragraphs we show several techniques that avoid this problem in practice.
We begin by noting that many functions which we will encounter consist of the ratio of
two polynomials, i.e., rational functions: f(z) = g(z)/h(z). Generally, we can write h(z) as
(z −z1)m1(z −z2)m2 · · ·. Here we assumed that we divided out any common factors between
g(z) and h(z) so that g(z) does not vanish at z1, z2, . . .. Clearly z1, z2, . . ., are singularities
of f(z). Further analysis shows that the nature of the singularities are a pole of order m1
at z = z1, a pole of order m2 at z = z2, and so forth.
Having found the nature and location of the singularity, we compute the residue as
follows. Suppose that we have a pole of order n. Then we know that its Laurent expansion
is
f(z) =
an
(z −z0)n +
an−1
(z −z0)n−1 + · · · + b0 + b1(z −z0) + · · · .
(10.8.6)
Multiplying both sides of Equation 10.8.6 by (z −z0)n,
F(z) = (z −z0)nf(z) = an +an−1(z −z0)+· · ·+b0(z −z0)n +b1(z −z0)n+1 +· · · . (10.8.7)
Because F(z) is analytic at z = z0, it has the Taylor expansion
F(z) = F(z0) + F ′(z0)(z −z0) + · · · + F (n−1)(z0)
(n −1)! (z −z0)n−1 + · · · .
(10.8.8)
Matching powers of z −z0 in Equation 10.8.7 and Equation 10.8.8, the residue equals
Res[f(z); z0] = a1 = F (n−1)(z0)
(n −1)! .
(10.8.9)
Substituting in F(z) = (z −z0)nf(z), we can compute the residue of a pole of order n by
Res[f(z); zj] =
1
(n −1)! lim
z→zj
dn−1
dzn−1

(z −zj)nf(z)

.
(10.8.10)

Complex Variables
475
For a simple pole, Equation 10.8.10 simpliﬁes to
Res[f(z); zj] = lim
z→zj(z −zj)f(z).
(10.8.11)
Quite often, f(z) = p(z)/q(z).
From l’Hˆospital’s rule, it follows that Equation 10.8.11
becomes
Res[f(z); zj] = p(zj)
q′(zj).
(10.8.12)
Recall that these formulas work only for ﬁnite-order poles. For an essential singularity we
must compute the residue from its Laurent expansion; however, essential singularities are
very rare in applications.
• Example 10.8.2
Let us evaluate
I
C
eiz
z2 + a2 dz,
(10.8.13)
where C is any contour that includes both poles at z = ±ai and is in the positive sense.
From Cauchy’s residue theorem,
I
C
eiz
z2 + a2 dz = 2πi

Res

eiz
z2 + a2 ; ai

+ Res

eiz
z2 + a2 ; −ai

.
(10.8.14)
The singularities at z = ±ai are simple poles. The corresponding residues are
Res

eiz
z2 + a2 ; ai

= lim
z→ai(z −ai)
eiz
(z −ai)(z + ai) = e−a
2ia
(10.8.15)
and
Res

eiz
z2 + a2 ; −ai

=
lim
z→−ai(z + ai)
eiz
(z −ai)(z + ai) = −ea
2ia.
(10.8.16)
Consequently,
I
C
eiz
z2 + a2 dz = −2π
2a
 ea −e−a
= −2π
a sinh(a).
(10.8.17)
⊓⊔
• Example 10.8.3
Let us evaluate
1
2πi
I
C
etz
z2(z2 + 2z + 2) dz,
(10.8.18)
where C includes all of the singularities and is in the positive sense.

476
Advanced Engineering Mathematics with MATLAB
The integrand has a second-order pole at z = 0 and two simple poles at z = −1 ± i,
which are the roots of z2 + 2z + 2 = 0. Therefore, the residue at z = 0 is
Res

etz
z2(z2 + 2z + 2); 0

= lim
z→0
1
1!
d
dz

(z −0)2

etz
z2(z2 + 2z + 2)

(10.8.19)
= lim
z→0

tetz
z2 + 2z + 2 −
(2z + 2)etz
(z2 + 2z + 2)2

= t −1
2
.
(10.8.20)
The residue at z = −1 + i is
Res

etz
z2(z2 + 2z + 2); −1 + i

=
lim
z→−1+i[z −(−1 + i)]
etz
z2(z2 + 2z + 2)
(10.8.21)
=

lim
z→−1+i
etz
z2
 
lim
z→−1+i
z + 1 −i
z2 + 2z + 2

(10.8.22)
= exp[(−1 + i)t]
2i(−1 + i)2
= exp[(−1 + i)t]
4
.
(10.8.23)
Similarly, the residue at z = −1 −i is
Res

etz
z2(z2 + 2z + 2); −1 −i

=
lim
z→−1−i[z −(−1 −i)]
etz
z2(z2 + 2z + 2)
(10.8.24)
=

lim
z→−1−i
etz
z2
 
lim
z→−1−i
z + 1 + i
z2 + 2z + 2

(10.8.25)
= exp[(−1 −i)t]
(−2i)(−1 −i)2 = exp[(−1 −i)t]
4
.
(10.8.26)
Then by the residue theorem,
1
2πi
I
C
etz
z2(z2 + 2z + 2) dz = Res

etz
z2(z2 + 2z + 2); 0

+ Res

etz
z2(z2 + 2z + 2); −1 + i

+ Res

etz
z2(z2 + 2z + 2); −1 −i

(10.8.27)
= t −1
2
+ exp[(−1 + i)t]
4
+ exp[(−1 −i)t]
4
(10.8.28)
= 1
2 [t −1 + e−t cos(t)] .
(10.8.29)
Problems
Assuming that all of the following closed contours are in the positive sense, use the residue
theorem to evaluate the following integrals:
1.
I
|z|=1
z + 1
z4 −2z3 dz
2.
I
|z|=1
(z + 4)3
z4 + 5z3 + 6z2 dz
3.
I
|z|=1
1
1 −ez dz
4.
I
|z|=2
z2 −4
(z −1)4 dz
5.
I
|z|=2
z3
z4 −1 dz
6.
I
|z|=1
zne2/z dz,
n > 0

Complex Variables
477
1
x
y
C
C
2
Figure 10.9.1: Contour used in evaluating the integral, Equation 10.9.1.
7.
I
|z|=1
e1/z cos(1/z) dz
8.
I
|z|=2
2 + 4 cos(πz)
z(z −1)2
dz
10.9 EVALUATION OF REAL DEFINITE INTEGRALS
One of the important applications of the theory of residues consists in the evaluation of
certain types of real deﬁnite integrals. Similar techniques apply when the integrand contains
a sine or cosine. See Section 11.4.
• Example 10.9.1
Let us evaluate the integral
Z ∞
0
dx
x2 + 1 = 1
2
Z ∞
−∞
dx
x2 + 1.
(10.9.1)
This integration occurs along the real axis. In terms of complex variables, we can rewrite
Equation 10.9.1 as
Z ∞
0
dx
x2 + 1 = 1
2
Z
C1
dz
z2 + 1,
(10.9.2)
where the contour C1 is the line ℑ(z) = 0. However, the use of the residue theorem requires
an integration along a closed contour. Let us choose the one pictured in Figure 10.9.1. Then
I
C
dz
z2 + 1 =
Z
C1
dz
z2 + 1 +
Z
C2
dz
z2 + 1,
(10.9.3)
where C denotes the complete closed contour and C2 denotes the integration path along
a semicircle at inﬁnity. Clearly we want the second integral on the right side of Equation
10.9.3 to vanish; otherwise, our choice of the contour C2 is poor. Because z = Reθi and
dz = iReθi dθ,

Z
C2
dz
z2 + 1
 =

Z π
0
iR exp(θi)
1 + R2 exp(2θi) dθ
 ≤
Z π
0
R
R2 −1 dθ,
(10.9.4)
which tends to zero as R →∞. On the other hand, the residue theorem gives
I
C
dz
z2 + 1 = 2πi Res

1
z2 + 1; i

= 2πi lim
z→i
z −i
z2 + 1 = 2πi × 1
2i = π.
(10.9.5)
Therefore,
Z ∞
0
dx
x2 + 1 = π
2 .
(10.9.6)
Note that we only evaluated the residue in the upper half-plane because it is the only one
inside the contour.
⊓⊔

478
Advanced Engineering Mathematics with MATLAB
This example illustrates the basic concepts of evaluating deﬁnite integrals by the residue
theorem.
We introduce a closed contour that includes the real axis and an additional
contour. We must then evaluate the integral along this additional contour as well as the
closed contour integral. If we properly choose our closed contour, this additional integral
vanishes. For certain classes of general integrals, we shall now show that this additional
contour is a circular arc at inﬁnity.
Theorem: If, on a circular arc CR with a radius R and center at the origin, zf(z) →0
uniformly with |z| ∈CR and as R →∞, then
lim
R→∞
Z
CR
f(z) dz = 0.
(10.9.7)
The proof is as follows: If |zf(z)| ≤MR, then |f(z)| ≤MR/R. Because the length of
CR is αR, where α is the subtended angle,

Z
CR
f(z) dz
 ≤MR
R αR = αMR →0,
(10.9.8)
because MR →0 as R →∞.
⊓⊔
• Example 10.9.2
A simple illustration of this theorem is the integral
Z ∞
−∞
dx
x2 + x + 1 =
Z
C1
dz
z2 + z + 1.
(10.9.9)
A quick check shows that z/(z2 + z + 1) tends to zero uniformly as R →∞. Therefore, if
we use the contour pictured in Figure 10.9.1,
Z ∞
−∞
dx
x2 + x + 1 =
I
C
dz
z2 + z + 1 = 2πi Res

1
z2 + z + 1; −1
2 +
√
3
2 i

(10.9.10)
= 2πi
lim
z→−1
2 +
√
3
2 i

1
2z + 1

= 2π
√
3.
(10.9.11)
⊓⊔
• Example 10.9.3
Let us evaluate
Z ∞
0
dx
x6 + 1.
(10.9.12)
In place of an inﬁnite semicircle in the upper half-plane, consider the following integral
I
C
dz
z6 + 1,
(10.9.13)
where we show the closed contour in Figure 10.9.2. We chose this contour for two reasons.
First, we only have to evaluate one residue rather than the three enclosed in a traditional

Complex Variables
479
x
π/3
1
C
πi
e
/6
3
y
C2
C
Figure 10.9.2: Contour used in evaluating the integral, Equation 10.9.13.
upper half-plane contour. Second, the contour integral along C3 simpliﬁes to a particularly
simple and useful form.
Because the only enclosed singularity lies at z = eπi/6,
I
C
dz
z6 + 1 = 2πi Res

1
z6 + 1; eπi/6

= 2πi
lim
z→eπi/6
z −eπi/6
z6 + 1
(10.9.14)
= 2πi
lim
z→eπi/6
1
6z5 = −πi
3 eπi/6.
(10.9.15)
Let us now evaluate Equation 10.9.12 along each of the legs of the contour:
Z
C1
dz
z6 + 1 =
Z ∞
0
dx
x6 + 1,
(10.9.16)
Z
C2
dz
z6 + 1 = 0,
(10.9.17)
because of Equation 10.9.7 and
Z
C3
dz
z6 + 1 =
Z 0
∞
eπi/3 dr
r6 + 1 = −eπi/3
Z ∞
0
dx
x6 + 1,
(10.9.18)
since z = reπi/3.
Substituting into Equation 10.9.15,

1 −eπi/3 Z ∞
0
dx
x6 + 1 = −πi
3 eπi/6
(10.9.19)
or
Z ∞
0
dx
x6 + 1 = πi
6
2ieπi/6
eπi/6  eπi/6 −e−πi/6 =
π
6 sin(π/6) = π
3 .
(10.9.20)
⊓⊔

480
Advanced Engineering Mathematics with MATLAB
  

C
C
C
C
1
2
3
4
(−R,0)
(R,0)
(R,2  i)
(−R,2  i)
π
π
y
x
zs
Figure 10.9.3: Rectangular closed contour used to obtain Equation 10.9.31.
• Example 10.9.4
Rectangular closed contours are best for the evaluation of integrals that involve hyper-
bolic sines and cosines. To illustrate9 this, let us evaluate the integral
2
Z ∞
0
sin(ax) sinh(x)
[b + cosh(x)]2 dx =
Z ∞
−∞
sin(ax) sinh(x)
[b + cosh(x)]2 dx = ℑ
Z ∞
−∞
sinh(x)eiax
[b + cosh(x)]2 dx

,
(10.9.21)
where a > 0 and b > 1.
We begin by determining the value of
I
C
sinh(z)eiaz
[b + cosh(z)]2 dz
about the closed contour shown in Figure 10.9.3. Writing this contour integral in terms of
the four line segments that constitute the closed contour, we have
I
C
sinh(z)eiaz
[b + cosh(z)]2 dz =
Z
C1
sinh(z)eiaz
[b + cosh(z)]2 dz +
Z
C2
sinh(z)eiaz
[b + cosh(z)]2 dz
+
Z
C3
sinh(z)eiaz
[b + cosh(z)]2 dz +
Z
C4
sinh(z)eiaz
[b + cosh(z)]2 dz.
(10.9.22)
Because the integrand behaves as e−R as R →∞, the integrals along C2 and C4 vanish.
On the other hand,
Z
C1
sinh(z)eiaz
[b + cosh(z)]2 dz =
Z ∞
−∞
sinh(x)eiax
[b + cosh(x)]2 dx,
(10.9.23)
and
Z
C3
sinh(z)eiaz
[b + cosh(z)]2 dz = −e−2πa
Z ∞
−∞
sinh(x)eiax
[b + cosh(x)]2 dx,
(10.9.24)
because cosh(x + 2πi) = cosh(x) and sinh(x + 2πi) = sinh(x).
9 This is a slight variation on a problem solved by Spyrou, K. J., B. Cotton, and B. Gurd, 2002:
Analytical expressions of capsize boundary for a ship with roll bias in beam waves.
J. Ship Res., 46,
167–174.

Complex Variables
481
Within the closed contour C, we have a single singularity where b + cosh(zs) = 0 or
ezs = −b −
√
b2 −1 or zs = ln(b +
√
b2 −1 ) + πi. To discover the nature of this singularity,
we expand b + cosh(z) in a Taylor expansion and ﬁnd that
b + cosh(z) = sinh(zs)(z −zs) + 1
2 cosh(zs)(z −zs)2 + · · · .
(10.9.25)
Therefore, we have a second-order pole at z = zs. Therefore, the value of the residue there
is
Res
 sinh(z)eiaz
[b + cosh(z)]2 ; zs

= lim
z→zs
d
dz

sinh(z)eiaz
sinh2(zs) + sinh(zs) cosh(zs)(z −zs) + · · ·

(10.9.26)
= ia e−πa
sinh(zs) exp[ia cosh−1(b)].
(10.9.27)
Therefore,
Z ∞
−∞
sinh(x)eiax
[b + cosh(x)]2 dx = −2πa exp[−πa + ai cosh−1(b)]
(1 −e−2πa) sinh(zs)
= πa exp[ai cosh−1(b)]
√
b2 −1 sinh(πa)
,
(10.9.28)
because
sinh(zs) = 1
2

−b −
p
b2 −1 +
1
b +
√
b2 −1

= −
p
b2 −1.
(10.9.29)
Substituting Equation 10.9.28 into Equation 10.9.21 yields
Z ∞
0
sin(ax) sinh(x)
[b + cosh(x)]2 dx = πa sin[a cosh−1(b)]
2
√
b2 −1 sinh(πa)
.
(10.9.30)
⊓⊔
• Example 10.9.5
The method of residues is also useful in the evaluation of deﬁnite integrals of the form
R 2π
0
F[sin(θ), cos(θ)] dθ, where F is a quotient of polynomials in sin(θ) and cos(θ).
For
example, let us evaluate the integral10
I =
Z 2π
0
cos3(θ)
cos2(θ) −a2 dθ,
a > 1.
(10.9.31)
We begin by introducing the complex variable z = eiθ. This substitution yields the
closed contour integral
I = 1
2i
I
C
(z2 + 1)3
(z2 + 1)2 −4a2z2
dz
z2 ,
(10.9.32)
where C is a circle of radius 1 taken in the positive sense. The integrand of Equation 10.9.32
has ﬁve singularities: a second-order pole at z5 = 0 and simple poles located at
z1 = −a −
p
a2 −1,
z2 = −a +
p
a2 −1,
(10.9.33)
10 Simpliﬁed version of an integral presented by Jiang, Q. F., and R. B. Smith, 2000: V-waves, bow
shocks, and wakes in supercritical hydrostatic ﬂow. J. Fluid Mech., 406, 27–53.

482
Advanced Engineering Mathematics with MATLAB
z3 = a −
p
a2 −1,
and
z4 = a +
p
a2 −1.
(10.9.34)
Only the singularities z2, z3, and z5 lie within C. Consequently, the value of I equals 2πi
times the sum of the residues at these three singularities. The residues equal
Res

(z2 + 1)3
z2[(z2 + 1)2 −4a2z2]; −a +
p
a2 −1

=
lim
z→−a+
√
a2−1
(z2 + 1)3
z2
lim
z→−a+
√
a2−1
z + a −
√
a2 −1
(z2 + 1)2 −4a2z2
(10.9.35)
=
lim
z→−a+
√
a2−1
(z2 + 1)3
4z3(z2 + 1 −2a2)
(10.9.36)
= −
a2(a −
√
a2 −1 )3
(2a2 −1 −2a
√
a2 −1 )(a2 −1 −a
√
a2 −1 )
,
(10.9.37)
Res

(z2 + 1)3
z2[(z2 + 1)2 −4a2z2]; a −
p
a2 −1

=
lim
z→a−
√
a2−1
(z2 + 1)3
z2
lim
z→a−
√
a2−1
z −a +
√
a2 −1
(z2 + 1)2 −4a2z2
(10.9.38)
=
lim
z→a−
√
a2−1
(z2 + 1)3
4z3(z2 + 1 −2a2)
(10.9.39)
=
a2(a −
√
a2 −1 )3
(2a2 −1 −2a
√
a2 −1 )(a2 −1 −a
√
a2 −1 )
,
(10.9.40)
and
Res

(z2 + 1)3
z2[(z2 + 1)2 −4a2z2]; 0

= lim
z→0
d
dz

(z2 + 1)3
(z2 + 1)2 −4a2z2

(10.9.41)
= lim
z→0
6z[(z2 + 1)4 −4a2z2(z2 + 1)2] −4z(z2 + 1)3(z2 + 1 −2a2)
[(z2 + 1)2 −4a2z2]2
(10.9.42)
= 0.
(10.9.43)
Summing the residues, we obtain 0. Therefore,
Z 2π
0
cos3(θ)
cos2(θ) −a2 dθ = 0,
a > 1.
(10.9.44)
Problems
Use the residue theorem to verify the following integrals:
1.
Z ∞
0
dx
x4 + 1 = π
√
2
4
2.
Z ∞
−∞
dx
(x2 + 4x + 5)2 = π
2

Complex Variables
483
3.
Z ∞
−∞
x dx
(x2 + 1)(x2 + 2x + 2) = −π
5
4.
Z ∞
0
x2
x6 + 1 dx = π
6
5.
Z ∞
0
dx
(x2 + 1)2 = π
4
6.
Z ∞
0
dx
(x2 + 1)(x2 + 4)2 = 5π
288
7.
Z ∞
−∞
x2 dx
(x2 + a2)(x2 + b2)2 =
π
2b(a + b)2 ,
a, b > 0
8.
Z ∞
0
t2
(t2 + 1)[t2(a/h + 1) + (a/h −1)] dt = π
4
"
1 −
r
a −h
a + h
#
,
a > h
9.
Z π/2
0
dθ
a + sin2(θ) =
π
2
√
a + a2 ,
a > 0
10.
Z π/2
0
dθ
a2 cos2(θ) + b2 sin2(θ) =
π
2ab,
b ≥a > 0
11.
Z π
0
sin2(θ)
a + b cos(θ) dθ = π
b2

a −
p
a2 −b2

,
a > b > 0
12.
Z 2π
0
einθ
1 + 2r cos(θ) + r2 dθ = 2π (−r)n
1 −r2 ,
1 > |r|,
n = 0, 1, 2, . . .
13.
Z 2π
0
sin2n(θ) dθ = 2π(2n)!
(2nn!)2
14.
Z π
−π
cos(nθ)
cos(θ) + α dθ = 2π (−α +
√
α2 −1 )n
√
α2 −1
,
α > 1,
n ≥0
Hint:
2
√
α2 −1
z2 + 2αz + 1 =
1
z + α −
√
α2 −1
−
1
z + α +
√
α2 −1
15.
Z π
0
cos(nθ)
cosh(α) −cos(θ) dθ =
π
sinh(α)e−nα,
α ̸= 0,
n ≥0
Hint: See Example 10.7.5.
16. Show that
Z ∞
0
x2
(1 −x2)2 + a2x2 dx =
π
2|a|,
where a is real and not equal to zero. Hint: Show that the poles of
f(z) =
z2
(1 −z2)2 + a2z2

484
Advanced Engineering Mathematics with MATLAB
are simple and equal
zn =



± 1
2
 ±
√
4 −a2 + |a|i

,
if
0 < |a| < 2,
± i
2
 |a| ±
√
a2 −4

,
if
2 < |a|.
If |a| = 2, we have second-order poles at zn = ±i.
17. Show that
Z ∞
0
cos(ax)
cosh2(bx) dx =
πa
2b2 sinh[aπ/(2b)],
a, b > 0.
Hint: Evaluate the closed contour integral
I
C
eiaz
cosh2(bz) dz,
where C is a rectangular contour with vertices at (∞, 0), (−∞, 0), (∞, π/b), and (−∞, π/b).
18. Show11 that
Z ∞
0
dx
cosh(x) cosh(x + a) =

2a/ sinh(a),
if
a ̸= 0,
2,
if
a = 2.
Hint: Evaluate the closed contour integral
I
C
z
cosh(z) cosh(z + a) dz,
where C is a rectangular contour with vertices at (∞, 0), (−∞, 0), (∞, π), and (−∞, π).
19. During an electromagnetic calculation, Strutt12 needed to prove that
π sinh(σx)
cosh(σπ) = 2σ
∞
X
n=0
cos
 n + 1
2

(x −π)

σ2 +
 n + 1
2
2
,
|x| ≤π.
Verify his proof by doing the following:
Step 1: Using the residue theorem, show that
1
2πi
I
CN
π sinh(xz)
cosh(πz)
dz
z −σ = π sinh(σx)
cosh(σπ) −
N
X
n=−N−1
(−1)n sin
 n + 1
2

x

σ −i
 n + 1
2

,
where CN is a circular contour that includes the poles z = σ and zn = ±i
 n + 1
2

, n =
0, 1, 2, . . . , N.
11 See Yan, J. R., X. H. Yan, J. Q. You, and J. X. Zhong, 1993: On the interaction between two
nonpropagating hydrodynamic solitons. Phys. Fluids A, 5, 1651–1656.
12 Strutt, M. J. O., 1934: Berechnung des hochfrequenten Feldes einer Kreiszylinderspule in einer konzen-
trischen leitenden Schirmh¨ulle mit ebenen Deckeln. Hochfrequenztechn. Elecktroak., 43, 121–123.

Complex Variables
485
Step 2: Show that in the limit of N →∞, the contour integral vanishes. Hint: Examine
the behavior of z sinh(xz)/[(z −σ) cosh(πz)] as |z| →∞. Use Equation 10.9.7 where CR is
the circular contour.
Step 3: Break the inﬁnite series in Step 1 into two parts and simplify.
In the chapter on Fourier series, we shall show how we can obtain the same series by
direct integration.
10.10 CAUCHY’S PRINCIPAL VALUE INTEGRAL
The conventional deﬁnition of the integral of a function f(x) of the real variable x over
a ﬁnite interval a ≤x ≤b assumes that f(x) has a deﬁnite ﬁnite value at each point within
the interval. We shall now extend this deﬁnition to cover cases when f(x) is inﬁnite at a
ﬁnite number of points within the interval.
Consider the case when there is only one point c at which f(x) becomes inﬁnite. If c
is not an endpoint of the interval, we take two small positive numbers ǫ and η and examine
the expression
Z c−ǫ
a
f(x) dx +
Z b
c+η
f(x) dx.
(10.10.1)
If Equation 10.10.1 exists and tends to a unique limit as ǫ and η tend to zero independently,
we say that the improper integral of f(x) over the interval exists, its value being deﬁned by
Z b
a
f(x) dx = lim
ǫ→0
Z c−ǫ
a
f(x) dx + lim
η→0
Z b
c+η
f(x) dx.
(10.10.2)
If, however, the expression does not tend to a limit as ǫ and η tend to zero independently,
it may still happen that
lim
ǫ→0
(Z c−ǫ
a
f(x) dx +
Z b
c+ǫ
f(x) dx
)
(10.10.3)
exists. When this is the case, we call this limit the Cauchy principal value of the improper
integral and denote it by
PV
Z b
a
f(x) dx.
(10.10.4)
Finally, if f(x) becomes inﬁnite at an endpoint, say a, of the range of integration, we say
that f(x) is integrable over a ≤x ≤b if
lim
ǫ→0+
Z b
a+ǫ
f(x) dx
(10.10.5)
exists.
• Example 10.10.1
Consider the integral
R 2
−1 dx/x.
This integral does not exist in the ordinary sense
because of the strong singularity at the origin. However, the integral would exist if
lim
ǫ→0
Z ǫ
−1
dx
x + lim
δ→0
Z 2
δ
dx
x
(10.10.6)

486
Advanced Engineering Mathematics with MATLAB
C
a
-a
C
-R
1
2
x
x
R
η
ε
Figure 10.10.1: Contour C used in Example 10.10.2.
existed and had a unique value as ǫ and δ independently approach zero. Because this limit
equals
lim
ǫ,δ→0 [ ln(ǫ) + ln(2) −ln(δ)] = lim
ǫ,δ→0 [ ln(2) −ln(δ/ǫ)] ,
(10.10.7)
our integral would have the value of ln(2) if δ = ǫ. This particular limit is the Cauchy
principal value of the improper integral, which we express as
PV
Z 2
−1
dx
x = ln(2).
(10.10.8)
⊓⊔
We can extend these ideas to complex integrals used to determine the value or prin-
cipal value of an improper integral by Cauchy’s residue theorem when the integrand has a
singularity on the contour of integration. We avoid this diﬃculty by deleting from the area
within the contour that portion which also lies within a small circle |z −c| = ǫ and then
integrate around the boundary of the remaining region. This process is called indenting the
contour.
The integral around the indented contour is calculated by the theorem of residues
and then the radius of each indentation is made to tend to zero. This process gives the
Cauchy principal value of the improper integral. The details of this method are shown in
the following examples.
• Example 10.10.2
Let us show that
PV
Z ∞
−∞
cos(x)
a2 −x2 dx = π sin(a)
a
,
a > 0.
(10.10.9)
Consider the integral
I
C
eiz
a2 −z2 dz,
(10.10.10)
where the closed contour C consists of the real axis from −R to R and a semicircle in the
upper half of the z-plane where this segment is its diameter. See Figure 10.10.1. Because
the integrand has poles at z = ±a, which lie on this contour, we modify C by making an
indentation of radius ǫ at a and another of radius η at −a. The integrand is now analytic
within and on C and Equation 10.10.10 equals zero by the Cauchy-Goursat theorem.

Complex Variables
487
Evaluating each part of the integral, Equation 10.10.10, we have that
Z π
0
eiR cos(θ)−R sin(θ)
a2 −R2e2θi
iReθi dθ +
Z
C1
eiz
a2 −z2 dz +
Z
C2
eiz
a2 −z2 dz
+
Z −a−η
−R
eix
a2 −x2 dx +
Z a−ǫ
−a+η
eix
a2 −x2 dx +
Z R
a−ǫ
eix
a2 −x2 dx = 0,
(10.10.11)
where C1 and C2 denote the integrals around the indentations at a and −a, respectively.
The modulus of the ﬁrst term on the left side of Equation 10.10.11 is less than πR/(R2−a2)
so that this term tends to zero as R →∞. To evaluate C1, we observe that z = a + ǫeθi
along C1, where θ decreases from π to 0. Hence,
Z
C1
eiz
a2 −z2 dz = lim
ǫ→0
Z 0
π
exp
 ia + iǫeθi
ǫieθi
−2aǫeθi −ǫ2e2θi dθ
(10.10.12)
= lim
ǫ→0
Z π
0
exp
 ia + iǫeθi
i
2a + ǫeθi dθ = πieia
2a .
(10.10.13)
Similarly,
Z
C2
eiz
a2 −z2 dz = −πie−ia
2a
,
(10.10.14)
as η tends to zero.
Upon letting R →∞, ǫ →0, and η →0, we ﬁnd that
PV
Z ∞
−∞
eix
a2 −x2 dx = −πi
2a
 eia −e−ia
= π sin(a)
a
.
(10.10.15)
Finally, equating the real and imaginary parts, we obtain
PV
Z ∞
−∞
cos(x)
a2 −x2 dx = π sin(a)
a
,
PV
Z ∞
−∞
sin(x)
a2 −x2 dx = 0.
(10.10.16)
⊓⊔
• Example 10.10.3
Let us show that
Z ∞
−∞
sin(x)
x
dx = π.
(10.10.17)
Consider the integral
I
C
eiz
z dz,
(10.10.18)
where the closed contour C consists of the real axis from −R to R and a semicircle in the
upper half of the z-plane where this segment is its diameter. Because the integrand has a
pole at z = 0, which lies on the contour, we modify C by making an indentation of radius
ǫ at z = 0. See Figure 10.10.2. Because eiz/z is analytic along C,
Z π
0
eiR cos(θ)−R sin(θ)i dθ +
Z −ǫ
−R
eix
x dx +
Z
C1
eiz
z dz +
Z R
ǫ
eix
x dx = 0.
(10.10.19)

488
Advanced Engineering Mathematics with MATLAB
-R
x
1
ε
C
R
Figure 10.10.2: Contour C used in Example 10.10.3.
Since e−R sin(θ) < e−Rθ for 0 < θ < π,

Z π
0
eiR cos(θ)−R sin(θ)i dθ
 ≤
Z π
0
e−Rθ dθ = 1 −e−πR
R
,
(10.10.20)
which tends to zero as R →∞. Therefore,
Z −ǫ
−∞
eix
x dx +
Z ∞
ǫ
eix
x dx = −
Z
C1
eiz
z dz.
(10.10.21)
Now,
Z
C1
eiz
z dz =
Z
C1
dz
z + i
Z
C1
dz −
Z
C1
z
2 dz + · · · = −πi
(10.10.22)
in the limit ǫ →0 because z = ǫeθi. Consequently, in the limit of ǫ →0,
PV
Z ∞
−∞
eix
x dx = π.
(10.10.23)
Upon separating the real and imaginary parts, we obtain
PV
Z ∞
−∞
cos(x)
x
dx = 0,
Z ∞
−∞
sin(x)
x
dx = π.
(10.10.24)
Problems
1. Noting that
Z θ−ǫ
0
dϕ
cos(ϕ) −cos(θ) =
1
sin(θ) ln

sin
 1
2(θ + ϕ)

sin
 1
2(θ −ϕ)


θ−ǫ
0
,
and
Z π
θ+ǫ
dϕ
cos(ϕ) −cos(θ) =
1
sin(θ) ln

sin
 1
2(θ + ϕ)

sin
 1
2(θ −ϕ)


π
θ+ǫ
,
show that
PV
Z π
0
dϕ
cos(ϕ) −cos(θ) = 0,
0 < θ < π.

Complex Variables
489
2. Using f(z) = eiπz/2/(z2 −1), show that
Z ∞
−∞
cos(πx/2)
x2 −1
dx = −π.
3. Show that
Z ∞
−∞
eax −ebx
1 −ex
dx = π[cot(aπ) −cot(bπ)],
0 < a, b < 1.
Use a rectangular contour with vertices at (−R, 0), (R, 0), (−R, π), and (R, π) with a
semicircle indentation at the origin.
4. Show13 that
Z ∞
−∞
1 −cos[2a(x + ζ)]
(x + ζ)2(x2 + α2) dx =
π
α(ζ2 + α2)2

2aα(ζ2 + α2) + (ζ2 −α2)
−e−2aα 
(ζ2 −α2) cos(2aζ) + 2αζ sin(2aζ)
	
,
where a, α, and ζ are real. Use a semicircular contour of inﬁnite radius with the real axis
as its diameter.
5. Using the complex function eimz/(z −a) and a closed contour similar to that shown in
Figure 10.10.2, show that
PV
Z ∞
−∞
cos(mx)
x −a
dx = −π sin(ma),
and
PV
Z ∞
−∞
sin(mx)
x −a
dx = π cos(ma),
where m > 0 and a is real.
6. Using a closed contour similar to that shown in Figure 10.10.2, except that we now have
two small semicircles around the singularities on the real axis, show that
PV
Z ∞
−∞
xexi
x2 −π2 dx = −πi,
and
PV
Z ∞
−∞
eimx
(x −1)(x −3) dx = πi
2
 e3mi −emi
,
where m > 0.
7. Redo Example 10.10.3 except the contour is now a rectangle with vertices at ±R and
±R + Ri indented at the origin.
8. Let us show14 that
G(α) = PV
Z 1
−1
dx
(x + α)
√
1 −x2 =
(
απ
|α|
√
α2 −1
,
|α| > 1,
0,
|α| < 1.
13 Ko, S. H., and A. H. Nuttall, 1991: Analytical evaluation of ﬂush-mounted hydrophone array response
to the Corcos turbulent wall pressure spectrum. J. Acoust. Soc. Am., 90, 579–588.
14 Ott, E., T. M. Antonsen, and R. V. Lovelace, 1977: Theory of foil-less diode generation of intense
relativistic electron beams. Phys. Fluids, 20, 1180–1184.

490
Advanced Engineering Mathematics with MATLAB
Step 1: Using the transformation 2ix = z −z−1, show that
G(α) = PV
I
|z|=1
dz
z2 + 2iαz −1,
which has singularities at z = ±
√
1 −α2 + αi.
Step 2: To evaluate G(α) given in Step 1, the principal value can be evaluated using
G(α) =
I
|z|=1−ǫ
dz
z2 + 2iαz −1 +
I
|z|=1+ǫ
dz
z2 + 2iαz −1,
where ǫ →0+. Use the residue theorem and evaluate these contour integrals, yielding the
desired result.
9. Let the function f(z) possess a simple pole with a residue Res[f(z); c] on a simply closed
contour C. If C is indented at c, show that the integral of f(z) around the indentation
tends to −Res[f(z); c]αi as the radius of the indentation tends to zero, α being the internal
angle between the two parts of C meeting at c.
10.11 CONFORMAL MAPPING
Conformal mapping is a powerful technique for ﬁnding solutions, or for simplifying
the process of ﬁnding solutions, to Laplace’s diﬀerential equation in two dimensions. This
method involves introducing two complex variables: z = x + iy and τ = ρ + iσ. These
two complex variables are related to each other via the mapping z = f(τ). Under this
mapping the Argand diagram for the z-variable is mapped into one for the τ-variable. In
certain cases, for example τ = √z, the complex z-plane may only map into a portion of the
τ-plane. In other cases, say τ = z + 3i, the complete z-plane would be mapped into the
complete τ-plane.
Once we map the original domain into a simpler geometry (a half-plane, circle or
square), how do we ﬁnd the solution? There are several techniques available. One method,
for example, recalls that the real and imaginary part of an analytic function satisﬁes La-
place’s equation. Therefore, if we could construct an analytic function whose real or imagi-
nary part satisﬁes the boundary conditions in the new domain, we would have the solution
in the τ-plane. Then we could use the transformation to obtain the solution in the original
z-plane.
What types of functions f(z) are useful? Consider an arbitrary point z0 in the complex
z-plane. Assuming that f ′(z0) ̸= 0, a straightforward transformation yields
∂2u
∂x2 + ∂2u
∂y2

z0
= |f ′(z0)|2
∂2v
∂ρ2 + ∂2v
∂σ2

τ0
,
(10.11.1)
where u(x, y) and v(ρ, σ) are solutions to Laplace’s equation in the z and τ planes, respec-
tively. Thus, f(z) must be analytic.

Complex Variables
491
                                                                                                                  


                                                                                                                                                                                                                                                














                                                                                                                                                                                                                                                














               














z−plane
σ
τ−
ρ
plane
x
a/2
y
τ = 1
                                          
                                          
              













                     




















      


      


              













              













A
D
E
B C
C
B
A
D
E
Figure 10.11.1: The conformal mapping used to ﬁnd the ﬁelds of a semi-inﬁnite ring head with a ﬁnite gap
of width a. The potential on the right pole face equals 1 while the potential of the left pole face equals −1.
In the z-plane the point A is located at (0, ∞) while point B is located at (0, −∞). Because of symmetry
the potential along the center of the gap AB equals 0.
• Example 10.11.1
In their study of magnetic recording, Curland and Judy15 modeled the ring heads as
two semi-inﬁnite regions located below the x-axis and running to the right of x = a/2 and
to the left of x = −a/2. See Figure 10.11.1.
From symmetry we need only consider the half-space x > 0. Consequently, the new
boundary consists of the four line segments: AB, BC, CD and DE. If we require that the
point D in the τ-plane lies at τ = 1, we shall show in Example 10.11.7 that the desired
conformal mapping is
z = a
π
√
τ −1 −i
2 log
1 −i√τ −1
1 + i√τ −1

+ a
2.
(10.11.2)
A useful method for illustrating this conformal mapping is to draw lines of constant ρ and σ
in the z-plane. See Figure 10.11.2. This ﬁgure shows the local orthogonality between lines
of constant ρ and σ.
The greatest diﬃculty in creating this ﬁgure was computing τ for a given z. This was
done using the Newton-Raphson method. Starting at the top of the domain, the ﬁrst guess
there was given by τ = 1 + π2z2. Marching downward, the τ from the previous grid point
was used for the initial guess. The corresponding MATLAB script is:
clear; delta = 0.01; % resolution of the grid
for jj = 1:201
for ii = 1:201
XX(jj,ii) = delta*ii; YY(jj,ii) = delta*(jj-101);
RHO(jj,ii) = NaN; SIGMA(jj,ii) = NaN;
end; end
% code for the domain x, y > 0
15 Curland, N., and J. H. Judy, 1986: Calculation of exact ring head ﬁelds using conformal mapping.
IEEE Trans. Magnet., MAG-22, 1901–1903.

492
Advanced Engineering Mathematics with MATLAB
0.002
0.05
0.5
0.5
0.5
0.5
5
5
5
10
10
20
20
30
-8
-4
0
0
0
4
4
10
20
30
x/a
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
y/a
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
Figure 10.11.2: Lines of constant ρ (dashed lines) and σ (solid lines) given by the conformal mapping
expressed by Equation 10.11.2.
for jj = 1:100
y = 1 - delta*(jj-1);
for ii = 1:201
x = delta*ii; z = complex(x,y);
if (jj == 1) tau = 1+pi*pi*z*z; else tau = TAU(ii); end
for icount = 1:10
temp1 = sqrt(tau-1);
temp2 = temp1 - 0.5*i*log(1-i*temp1) + 0.5*i*log(1+i*temp1);
ff = temp2/pi + 0.5 - z; deriv = temp1 /(2*pi*tau);
temp3 = ff/deriv; tau = tau - temp3; % Newton-Raphson method
end
TAU(ii) = tau; RHO(202-jj,ii) = real(tau);
SIGMA(202-jj,ii) = imag(tau);
end; end
% code for the domain 0 < x < 1
2 and y < 0
for jj = 1:101
y = delta - delta*jj;
for ii = 1:49
x = delta*ii; z = complex(x,y);
tau = TAU(ii); % first guess
for icount = 1:10
temp1 = sqrt(tau-1);
temp2 = temp1 - 0.5*i*log(1-i*temp1) + 0.5*i*log(1+i*temp1);
ff = temp2/pi + 0.5 - z; deriv = temp1 /(2*pi*tau);
temp3 = ff/deriv; tau = tau - temp3; % Newton-Raphson method
end

Complex Variables
493
0.1
0.1
0.3
0.3
0.5
0.5
0.5
0.7
0.7
0.7
0.9
0.9
0.9
x/a
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
y/a
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
Figure 10.11.3: The solution to Laplace’s equation when the left boundary is held at 0 while the left and
top sides of the shaded rectangle are held at 1. This ﬁgure shows only a portion of the domain x > 0 and
|y| < ∞.
TAU(ii) = tau; RHO(102-jj,ii) = real(tau);
SIGMA(102-jj,ii) = imag(tau);
end; end
% plot the conformal mapping Equation 10.11.2
figure
[C,h] = contour(XX,YY,SIGMA,[0.002,0.05,0.5,5,10,20,30],’k’);
clabel(C,h,’FontSize’,10,’Color’,’k’,’Rotation’,0)
xlabel(’x/a’,’FontSize’,20); ylabel(’y/a’,’FontSize’,20);
hold on
v = [-8,-4,0,4,10,20,30];
[C,h] = contour(XX,YY,RHO,v,’--b’);
clabel(C,h,’FontSize’,10,’Color’,’b’,’Rotation’,0)
Now that we can transform between the z-plane and the τ-plane, and vice versa, let us
turn our attention to ﬁnding the solution to Laplace’s equation in the τ-plane. There the
solution equals 1 for ρ > 0 and 0 for ρ < 0 along σ = 0.
Consider now the analytic function (except at the branch point τ = 0)
f(τ) = i −log(τ)/π.
(10.11.3)
A quick check (using τ = reiθ) shows that the imaginary part of f(τ), v(r, θ) = 1 −θ/π,
satisﬁes Laplace’s equation and the boundary conditions. Thus, constructing the solution
is as follows: For a given x and y, we use our MATLAB code to compute τ. Substituting
that τ into Equation 10.11.3 we compute f(τ). Taking the imaginary part, we have the
solution at x and y. Figure 10.11.3 illustrates the solution for the domain 0 < x < 2 and
−1 < y < 1.
⊓⊔

494
Advanced Engineering Mathematics with MATLAB
                                                                                                                  


                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        













x
z−plane
σ
τ−plane
y
ρ
−a
a
0
z2= ai
α
α
α
1 
3
2
= 0
= 0
z1 
z3
+
_
ρ  = 
ρ  = 
ρ  = 
1 
2
3
                                          
                                          
                     




















      


      


      


      


      


      


Figure 10.11.4: The conformal mapping between the z-plane and τ-plane achieved by the conformal
mapping τ =
√
z2 + a2.
In summary, conformal mapping allowed us to transform the original domain into one
(an upper half-plane) where we could construct another analytic function whose imaginary
part satisﬁed Laplace’s equation and the boundary conditions. A natural question is what
do we do if we cannot ﬁnd this analytic function in the τ-plane? The next example shows
an alternative approach.
• Example 10.11.2
For our second example of conformal mapping, consider τ =
√
z2 + a2. To illustrate
this mapping we have constructed two Argand diagrams; one is for the z-plane while the
second is for the τ-plane. Figure 10.11.4 shows how a particular boundary in the z-plane
maps into the τ-plane. The advantage here is that the inﬁnitely thin ﬁlament or peg located
at z = 0 is completely eliminated in the τ-plane.
One source of concern is the presence of the square root; for any value of z we would
have two possible solutions. We make the mapping unique by requiring that ℑ(τ) ≥0.
To better understand this transformation, Figure 10.11.5 illustrates various lines of
constant ℜ(τ/a) and ℑ(τ/a) as a function of x/a and y/a. This ﬁgure was constructed
using the MATLAB code:
clear;
% compute τ for various values of z
for jj = 1:40
y = 0.05 * jj;
for ii = 1:42
x = 0.05 * (ii-21.5); z = x + i*y; tau(ii,jj) = sqrt(z*z+a*a);
if (imag(tau(ii,jj)) <= 0) tau(ii,jj) = -tau(ii,jj); end
X(ii,jj) = x; Y(ii,jj) = y;
IM(ii,jj) = imag(tau(ii,jj)); REAL(ii,jj) = real(tau(ii,jj));

Complex Variables
495
0.1
0.25
0.5
0.75
1
1.5
-1
-0.5
-0.25
0.25
0.5
1
x/a
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
y/a
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
Figure 10.11.5: Lines of constant ℜ(τ/a) (dashed line) and ℑ(τ/a) (solid lines) as a function of x and y
for the conformal mapping τ =
√
z2 + a2.
end; end
% plot the conformal mapping Equation τ =
√
z2 + a2
figure
[C,h] = contour(X,Y,IM,[0.1,0.25,0.5,0.75,1,1.5,2],’k’);
clabel(C,’FontSize’,10,’Color’,’k’,’Rotation’,0)
xlabel(’x’,’FontSize’,20); ylabel(’y’,’FontSize’,20);
hold on
v = [-1,-0.5,-0.25,-0.01,0.01,0.25,0.5,1];
[C,h] = contour(X,Y,REAL,v,’--b’);
clabel(C,’manual’,’FontSize’,10,’Color’,’b’,’Rotation’,0)
As y →∞, lines of constant ℑ(τ/a) become parallel to the boundary y = 0. Only for
smaller values of y and as we approach the peg at x = 0 do these lines deviate strongly
from the horizontal as they pass over the obstacle. The smaller the value of ℑ(τ/a) the
more they conform to the shape of the obstacle.
The behavior of lines of constant ℜ(τ/a) are more diﬃcult to understand. There are
two general classes, depending upon whether the absolute value of ℜ(τ/a) is less or greater
than 1. When |ℜ(τ/a)| > 1 they are clearly orthogonal to constant lines of ℑ(τ/a). Positive
values of ℜ(τ/a) exist for x > 0 while negative values occur when x < 0. |ℜ(τ/a)| < 1 for
y ≥a.
This example has two interesting aspects to it. The ﬁrst is the presence of the square
root. The second involves how we will ﬁnd the solution to Laplace’s equation in the τ-plane.
Let us assume that in the original z-plane the solution equals to zero along the entire
boundary except along the “peg.” There, the solution equals 1. In the τ-plane the solution
equals zero along the entire boundary except for the segment −a < ρ < a, where σ = 0,
along which the solution equals 1. Instead of ﬁnding an analytic function whose real or
imaginary part satisﬁes this boundary condition, we employ the results from Section 11.7.

496
Advanced Engineering Mathematics with MATLAB
In the present case, we ﬁnd that
u(ρ, σ) = 1
π
Z a
−a
σ
σ2 + (ξ −ρ)2 dξ
(10.11.4)
= 1
π

tan−1
a −ρ
σ

+ tan−1
a + ρ
σ

.
(10.11.5)
Given Equation 10.11.5 we can compute the solution as follows: For a speciﬁc value of
x and y, we ﬁnd the corresponding value of ρ and σ. Equation 10.11.5 gives us the solution
to Laplace’s equation at that point and the corresponding x and y. The MATLAB code is:
clear; a = 1;
for jj = 1:100
y = 0.02 * jj;
for ii = 1:202
x = 0.02 * (ii-101.5); z = x + i*y; tau = sqrt(z*z+a*a);
if (imag(tau) <= 0) tau = -tau; end
sigma = imag(tau); rho = real(tau);
X(ii,jj) = x; Y(ii,jj) = y;
% Equation 10.11.5
arg1 = (a-rho)/sigma; arg2 = (a+rho)/sigma;
T(ii,jj) = (atan(arg1)+atan(arg2)) / pi;
end; end
% plot the solution to Laplace’s equation
figure
[C,h] = contourf(X,Y,T,[0,0.05,0.2,0.4,0.6,0.8],’k’);
colormap autumn
clabel(C,’FontSize’,10,’Color’,’k’,’Rotation’,0)
xlabel(’x’,’FontSize’,20); ylabel(’y’,’FontSize’,20);
Figure 10.11.6 illustrates this solution.
⊓⊔
So far we have not presented a strategy for ﬁnding our conformal mappings.
One
method would be to simply experiment with transforms that had been used in similar
problems. Fortunately, during the 1860s two German mathematicians, E. B. Christoﬀel16
and H. A. Schwarz,17 developed a very popular method of mapping a polygon into a half
plane.
Example 10.11.1 illustrated one of their transforms.
Indeed, if we imagine that
the boundary of the polygon is constructed from a thin wire, the purpose of the Schwarz-
Christoﬀel transformation is to unbend the corners so that the wire becomes straight.
Our derivation begins by considering a mapping z = f(τ) where
dz
dτ = C(τ −ρ1)k1(τ −ρ2)k2 · · · (τ −ρn)kn,
(10.11.6)
16 Christoﬀel, E. B., 1868: Sul problema delle temperature stazionarie e la rappresentazione di una data
superﬁcie.
Ann.
Mat.
Pura Appl., Series 2, 1, 89–103; Christoﬀel, E. B., 1870: Sopra un problema
proposto da Dirichlet. Ann. Mat. Pura Appl., Series 2, 4, 1–9.
17 Schwarz, H. A., 1868: ¨Uber einige Abbildungsaufgaben. J. Reine Angew. Math., 70, 105–120.

Complex Variables
497
0.05
0.05
0.2
0.2
0.4
0.6
0.8
x
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
y
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
Figure 10.11.6: The solution of Laplace’s equation when the solution (potential) along the boundary
equals zero except along the peg located at x = 0. There the solution (potential) equals one.
and ρ1, ρ2, . . . , ρn are any n points arranged in order along the real axis in the τ-plane such
that ρ1 < ρ2 < . . . < ρn. Here the ki’s are real constants and C is a real or complex
constant. By taking the logarithm of both sides of Equation 10.11.6 we ﬁnd that
log
dz
dτ

= log(C) + k1 log(τ −ρ1) + k2 log(τ −ρ2) + · · · + kn log(τ −ρn).
(10.11.7)
We have assumed that the principal value18 of each logarithm is taken. The local magniﬁ-
cation factor of the mapping from the τ-plane to the z-plane equals dz/dτ while the angle
of dz/dτ gives the angle through which a small portion of the mapped curve in the τ-plane
is rotated by the mapping. This angle is given by
̸ )
dz
dτ

= ̸ ) (C) + k1̸ ) (τ −ρ1) + k2̸ ) (τ −ρ2) + · · · + kn̸ ) (τ −ρn).
(10.11.8)
Equation 10.11.8 follows by ﬁrst taking the imaginary part of Equation 10.11.7 and then
noting that ̸ ) (C) = ℑ[log(C)].
Let the point (ρ, σ) = (−∞, 0) in the τ-plane be mapped into the point z∗in the
z-plane. See Figure 10.11.7. If we consider the image of a point ρ as it moves to the right
along the negative real axis in the τ-plane, then all of the ρ −ρi are real and negative as
long as ρ < ρ1. Hence the angles for all of the ρ−ρi are constant and equal to π in Equation
10.11.8. Therefore, this equation simpliﬁes to
̸ )
dz
dτ

= ̸ ) (C) + (k1 + k2 + · · · + kn)π.
(10.11.9)
Thus the portion of the ρ axis to the left of the point ρ1 is mapped into a straight line
segment, making the angle deﬁned by Equation 10.11.9 with the real axis in the z-plane,
and extending from z∗to z1 the image of ρ −ρ1.
18 For the complex number z = reθi, r ̸= 0, the principle value of the logarithm is log(z) = ln(r) + θi,
where θ must lie between 0 and 2π.

498
Advanced Engineering Mathematics with MATLAB
                                                                                                                                                                                                                                                                                                                                                               












                                                                            

x
z−plane
σ
τ−
ρ
plane
y
1 
2
n
α
α
1 
2
z
z1 
2z
*
ρ
ρ
ρ
                                         
              













                     




















      


      


      


      


      


      


              













              













Figure 10.11.7: Diagram used in the derivation of the Schwarz-Christoﬀel method.
Now as the point ρ crosses the point ρ1 on the real axis, the real number ρ−ρ1 becomes
positive so that its angle abruptly changes from π to 0. Hence ̸ ) (dz/dτ) abruptly decreases
by an amount k1π and then remains constant as τ travels from ρ1 to ρ2. It follows that
the image of the segment (ρ1ρ2) in the z-plane makes an angle of −k1π with the segment
(z∗z1).
Proceeding in this way, we see that each segment (ρn, ρn+1) is mapped into a line
segment (zn, zn+1) in the z-plane, making the angle of −knπ with the segment previously
mapped. Thus, if the interior angle of the resultant polynomial contour at the point zn is
to have the magnitude αn, we must set π −αn = −knπ, or kn = αn/π −1 in Equation
10.11.6. After an integration, we then conclude that the mapping
z = C
Z τ
(η −ρ1)k1(η −ρ2)k2 · · · (η −ρn)kn dη + K,
(10.11.10)
where the arbitrary complex constants C and K map the real axis σ = 0 of the τ-plane into
a polynomial boundary in the z-plane in such a way that the vertices z1, z2, . . . , zn with
interior angles α1, α2, . . . , αn are the images of the points ρ1, ρ2, . . . , ρn.
For the ﬁnal segment τ −ρ > ρn the numbers τ −ρi are all real, positive, and equal to
zero, so that this segment is rotated through the angle
̸ )(dz/dτ) = ̸ ) (C),
ρ > ρn.
(10.11.11)
For a closed polynomial the sum of the interior angles is
α1 + α2 + · · · + αn = (n −2)π.
(10.11.12)
Therefore,
k1 + k2 + · · · + kn = (n −2)π
π
−n = −2.
(10.11.13)
Thus, according to Equations 10.11.8 and 10.11.11, the two inﬁnite segments of the line
σ = 0 are rotated through the angle ̸ ) (C) −2π and ̸ ) (C), as is clearly necessary for a
closed ﬁgure.

Complex Variables
499
                                                                                    


                                                                                                                                                                                                                                                                                                                           














                                                                                                                                                      














  

 
 
  

                                                                                                                  


x
z−plane
σ
τ−
ρ
plane
1
y
α
β
C
A
B
C
A
B
z1 
= 1
2
z
0
C
= 0
ρ  = 
ρ  = 
1 
2
                                         
                                         
              













                     




















      


      


      


      


              













              













Figure 10.11.8: The complex z- and τ-planes used in Example 10.11.4.
What roles do C and K play? Because C is often complex, this constant introduces
any necessary magniﬁcation and rotation of the transformation so that any prescribed
polynomial in the z-plane is made to correspond point by point to the real axis σ = 0 in
the τ-plane. In fact, this correspondence can be set up in inﬁnitely many ways, in that
three of the numbers ρ1, ρ2, . . . , ρn can be determined arbitrarily. Finally, the mapping can
be shown to establish a one-to-one correspondence between points in the interior of the
polygon in the z-plane and points in the upper half of the τ-plane.
• Example 10.11.3
Let us derive the conformal mapping used in Example 10.11.2. Referring back to Figure
10.11.4, we see that α1 = π/2, k1 = −1/2, and ρ1 = −a at z1 = 0−; α2 = 2π, k2 = 1, and
ρ2 = 0 at z2 = ai; and α3 = π/2, k3 = −1/2, and ρ3 = a at z3 = 0+. Therefore, from
Equation 10.11.6,
dz
dτ = C(τ + a)−1/2τ(τ −a)−1/2 = C
τ
√
τ 2 −a2 .
(10.11.14)
Integrating this diﬀerential equation,
z = C
p
τ 2 −a2 + K.
(10.11.15)
Because the point ρ1 = −a corresponds to z = 0−, K = 0. Similarly, at ρ2 = 0, we have
that
ai = C
p
−a2,
or
C = 1.
(10.11.16)
Therefore, the conformal mapping is given by z =
√
τ 2 −a2, or τ =
√
z2 + a2.
⊓⊔
• Example 10.11.4
Consider the triangle ABC located in the z-plane as shown on Figure 10.11.8. Here
we desire to map the interior space of this triangle into the upper half of the τ-plane. At

500
Advanced Engineering Mathematics with MATLAB
                
                                                                                                                                                                                                                                                                                                                                    











                

A
E
                                                                            

 
 
 
  

 
x
z−plane
σ
τ−plane
y
α
α
z
z1 
z2
3
= −a
= 0
C
B
D
1
−1
E
ρ
C
D
B
A
0
= a
ρ  = 
ρ  = 
ρ  = 
1 
2
3
                                          
                                          
                     




















      


      


      


      


      


      


              













              













Figure 10.11.9: The complex z- and τ-planes used in Example 10.11.5.
point C, points along the boundary and to the left of C are to be mapped out to −∞in
the τ-plane while points along the boundary and to the right of C are mapped to +∞.
From Equation 10.11.6 we have that
dz
dτ = C′τ α/π−1(τ −1)β/π−1 = Cτ α/π−1(1 −τ)β/π−1.
(10.11.17)
Integrating this diﬀerential equation,
z = C
Z τ
ηα/π−1(1 −η)β/π−1 dη + K.
(10.11.18)
Because we want the points τ = 0 and z = 0 to correspond to each other, K = 0. On the
other hand, if we wish τ = 1 and z = 1 to correspond, Equation 10.11.18 yields
C
Z 1
0
ηα/π−1(1 −η)β/π−1 dη = C Γ(α/π)Γ(β/π)
Γ[(α + β)/π] = 1,
(10.11.19)
where Γ(·) is the gamma function deﬁned by
Γ(x) =
Z ∞
0
tx−1e−t dt.
(10.11.20)
Consequently,
C = Γ[(α + β)/π]
Γ(α/π)Γ(β/π),
(10.11.21)
and
z = Γ[(α + β)/π]
Γ(α/π)Γ(β/π)
Z τ
0
ηα/π−1(1 −η)β/π−1 dη.
(10.11.22)
A noteworthy aspect of this example is that the conformal mapping is given by an integral
and not some analytic expression.
⊓⊔

Complex Variables
501
                                      


















                                                                                 


                      










                                          


            





                                                


F
F
A
E
                                                                                                                  


 
 
 
 
 
 
  

x
z−plane
σ
τ−plane
y
ρ
1 
−1
−a
a
1
B
C
D
C
D
E
A
B
A
0
ρ  = 
ρ  = 
ρ  = 
ρ  = 
2
3
4
5
ρ  = 
                                          
                                           
      


      


      


      


      


      


      


      


      


      


              













Figure 10.11.10: The complex z- and τ-planes used in Example 10.11.6 with a < 1.
• Example 10.11.5
Consider the domain lying in the upper half of the z-plane except for a triangular section
BCD shown in Figure 10.11.9. We wish to construct the Schwarz-Christoﬀel transformation
that maps this domain into the upper half of the τ-plane. From Equation 10.11.6 we have
that
dz
dτ = C′(τ + 1)(π−α)/π−1τ (π+2α)/π−1(τ −1)(π−α)/π−1
(10.11.23)
= C′
τ 2α/π
(τ 2 −1)α/π = C
τ 2α/π
(1 −τ 2)α/π .
(10.11.24)
Integrating this diﬀerential equation,
z = C
Z τ
0
η2α/π
(1 −η2)α/π dη + K.
(10.11.25)
If we want the point τ = 0 to correspond to the point z = ki, then K = ki. On the other
hand, if the point τ = 1 corresponds to z = a, then
a = C
Z 1
0
η2α/π
(1 −η2)α/π dη + ki.
(10.11.26)
Solving for C,
C =
√π(a −ki)
Γ
 α/π + 1
2

Γ(1 −α/π).
(10.11.27)
Therefore, the ﬁnal answer is
z =
√π(a −ki)
Γ
 α/π + 1
2

Γ(1 −α/π)
Z τ
0
η2α/π
(1 −η2)α/π dη + ki.
(10.11.28)
⊓⊔

502
Advanced Engineering Mathematics with MATLAB
                    









                                                      


























                        

                    

ai
                                      

σ
plane
τ−
ρ
1
y
x
plane
z−
                      
                      





















      


      


      


                       






















A
E
D
C
B
A
D
E
B
C
Figure 10.11.11: The complex z- and τ-planes used in Example 10.11.7.
• Example 10.11.6
Consider the domain within the L-shaped boundary shown in Figure 10.11.10. We wish
to construct the Schwarz-Christoﬀel transform that maps the interior into the upper half
of the τ-plane. Note that we broke the boundary in such a manner that points slightly to
the left of point A are mapped to −∞while points slightly below the point A are mapped
to +∞.
Because a < 1, Equation 10.11.6 gives
dz
dτ = C(τ + 1)−1/2(τ + a)−1/2τ −1/2(τ −a)−1/2(τ −1)1/2.
(10.11.29)
Integrating this diﬀerential equation,
z = C
Z τ
0
(η −1) dη
η
p
(η2 −1)(η2 −a2)
+ K = C
a
Z τ
0
(η −1) dη
η
p
(1 −η2)(1 −p2η2)
+ K,
(10.11.30)
where p2 = 1/a2. To compute C and K, we would need further information.
⊓⊔
• Example 10.11.7
Let us derive the conformal mapping, Equation 10.11.2, used in Example 10.11.1. The
z−and τ−planes are shown in Figure 10.11.11. From this ﬁgure we see that α1 = 3π/2,
α2 = π/2, α3 = π/2, ρ1 = 1, ρ2 = 0−, and ρ3 = 0+. This yields
dz
dτ = K(τ −1)(3π)/(2π)−1(τ −0−)(π)/(2π)−1(τ −0+)(π)/(2π)−1 = K
√τ −1
τ
.
(10.11.31)
Integrating Equation 10.11.31, we ﬁnd that
z = 2K
√
τ −1 −arctan
 √
τ −1

+ C = 2K
√
τ −1 + i
2 log
1 + i√τ −1
1 −i√τ −1

+ C.
(10.11.32)

Complex Variables
503
                                      

                            













                                                               


σ
plane
τ−
ρ
x
y
plane
z−
1 
2
3
(−π,π)
ρ
ρ
ρ
                     
                     
                      





















      


      


        



      


                       






















A
C
B
C
A
B
Problem 3
                                                                                                                                                                                                                                                            

















                                      

                                                


σ
plane
τ−
ρ
1 
2
3
y
x
plane
z−
ρ
ρ
ρ
                      
                      
                      





















      


      


        



                        























B
C
A
B
C
A
Problem 4
Because at τ = 1, z = a/2, we have C = a/2.
The computation of K is more complicated. Referring to Figure 10.11.11, we note that
Z C
B
dz =
Z C′
B′ K
√τ −1
τ
dτ.
(10.11.33)
Setting τ = r eθi with r →0, Equation 10.11.34 becomes
a
2 = K lim
r→0
Z 0
π
√
r eθi −1
r eθi
ir eθi dθ = Kπ.
(10.11.34)
Thus K = a/(2π) and we recover Equation 10.11.2.
Problems
1. Verify that the function τ = ez maps the strip 0 < ℑ(z) < π into the half-plane ℑ(τ) > 0.
2. Verify that the function τ 2 = 1 −ez maps the strip −π < ℑ(z) < π, except for the
negative real axis, into the upper half of the τ-plane.
3. Use the Schwarz-Christoﬀel method to ﬁnd the conformal mapping that maps the quarter
plane x > −π, y < π into the upper half of the τ-plane. We require that the point (−π, π)
in the z-plane maps to the point (0, 0) in the τ-plane.
4. Use the Schwarz-Christoﬀel method to ﬁnd the conformal mapping that maps the sector
lying between the x-axis and the line θ = π/3 into the upper half of the τ-plane. We require
that the point (0, 0) in the z-plane maps to the point (0, 0) in the τ-plane.

504
Advanced Engineering Mathematics with MATLAB
                                                                                                                                                                                                   












                    

                                        

σ
plane
τ−
ρ
y
x
1
1
plane
z−
7π/4
                      
                     
                      





















      


         


                       






















C
D
B
A
A
B
C
D
Problem 5
                                        



















                                                         


                                      

                                        



















σ
1
−1
plane
τ−
ρ
x
y
plane
z−
ρ  = 
ρ  = 
2
1 
                      





















      


      


                       






















B
C
B
C
a
−a
Problem 6
                        











                                          

                                      

                                      

y
z−plane
x
σ
1 
1
2
−1
plane
τ−
ρ
ρ  = 
ρ  = 
                     
                     
                      





















      


      


                       






















a B
C
B
C
Problem 7
5. Use the Schwarz-Christoﬀel method to ﬁnd the conformal mapping that maps the portion
of the z-plane deﬁned by 0 < r < ∞, 0 < θ < 7π/4 into the upper half of the τ-plane. We
require that the points (0, 0) and (1, 0) in the z-plane map to the points (0, 0) and (1, 0) in
the τ-plane, respectively.
6. Use the Schwarz-Christoﬀel method to ﬁnd the conformal mapping that maps the domain
|x| < a, 0 < y into the upper half of the τ-plane. Let the point (−a, 0) become the point
(−1, 0) while the point (a, 0) becomes the point (1, 0).
7. Use the Schwarz-Christoﬀel method to ﬁnd the conformal mapping that maps the region
x > 0, 0 < y < a into the upper half of the τ-plane. We require that the point (0, a) maps
to (−1, 0) in the τ-plane while the point (0, 0) maps to (1, 0) in the τ-plane.
8. Use the Schwarz-Christoﬀel method to ﬁnd the conformal mapping that maps the region
shown in the ﬁgure into the upper half of the τ-plane. We require that the points (0, 0) and
(0, a) in the z-plane map to the points (0, 0) and (1, 0) in the τ-plane, respectively.

Complex Variables
505
                      










                        

                    

ai
                                                         


          
σ
plane
τ−
ρ
1
y
x
plane
z−
                     
                     
                      





















      


         


                       






















C
D
A
B
C
D
A
B
Problem 8
                                                                                                                                                        







                                                                                                            





                                                                              

                                                                

 
 
 
 
x
z−plane
σ
τ−
ρ
plane
y
A
B
C
D
A
B
C
D
α
                                           
              













              













                                           
                     




















              













              













1
Problem 9a
9. Referring to the ﬁgure entitled Problem 9b, construct a transform between a z-plane
which has a barrier that runs parallel to the x-axis from z = L + πL i to ∞+ πL i and a
τ-plane that has no barrier.
Step 1: Referring to the ﬁgure entitled Problem 9a, use the Schwarz-Christoffel method to
show that the transform is given by
dz
dτ = Cτ k1(τ −1)k2,
where k1 = −α/(2π) and k2 = α/π −1.
Step 2: Consider the situation as the points B and D in the z-plane move out to inﬁnity
(so that α →2π). Show that the transform approaches
dz
dτ = C τ −1
τ
,
or
z = C[τ −log(τ)] + K.
Here we have taken the principal branch of the logarithm so that log(z) = ln(|z|)+iθ where
0 ≤θ ≤π. (We do not require that 0 ≤θ < 2π because we are always in the upper
half-plane.) See the ﬁgure entitled Problem 9b.

506
Advanced Engineering Mathematics with MATLAB
                                                                            

  

  

                                                                                                                                                                



 
  

  

x
z−plane
σ
τ−
ρ
plane
y
A
C
D
A
B
B
D
B
B
C
              













                                           
                     




















              













              













1
1
2
1
2
Problem 9b
Step 3: Following Example 10.11.7, consider the area around τ = 0. Show that
dz ≈−C dτ
τ = −iC dθ,
where τ = r eθi. Integrating from point B′
1 to point B′
2, show that C = L.
Step 4: To compute K, note that if the point C, located at z = L + πLi, corresponds to
the point C′, located at τ = 1, then K = πLi.
10. Use conformal mapping to solve Laplace’s equation for the inﬁnite strip −∞< x < ∞,
0 ≤y ≤π. The solution equals zero everywhere along the boundary except for x > 0,
y = 0, where u(x, 0) = 1.
Step 1: Consider the mapping τ = ez. Show that ρ = ex cos(y) and σ = ex sin(y). In
particular, (∞, π) →(−∞, 0), (0, π) →(−1, 0), (−∞, y) →(0, 0), (0, 0) →(1, 0), and
(∞, 0) →(∞, 0).
Step 2: Using the Fourier method from Section 11.7, show that
u(ρ, σ) = 1
π
π
2 −tan−1
1 −x
y

= 1 −1
π tan−1

y
x −1

.
Step 3: Show that
u(x, y) = 1 −1
π tan−1

ex sin(y)
ex cos(y) −1

.
11. Use conformal mapping to solve Laplace’s equation for a pie-shaped sector in the ﬁrst
quadrant. See Figure 10.11.12. The solution equals zero along the entire boundary except
for 0 < x < 1 where it equals one.
Step 1: Show that the mapping z = τ α/π or τ = zπ/α maps the pie-shaped sector into the
half-plane ℑ(τ) > 0. See Figure 10.11.12.

Complex Variables
507
                                                              

                                                                                                                                                                                                                                                                                                                                                                                















                                                                                                                                                                                                                                                                                                                















                                                                            

x
z−plane
σ
τ−
ρ
plane
0
1
y
= 0
z1 
z2 = 1
α
ρ  = 
ρ  = 
1 
2
                                          
              













                     




















      


      


      


              













              













Figure 10.11.12: The conformal mapping between the z-plane and τ-plane achieved by the conformal
mapping τ = zπ/α.
Step 2: Using the Fourier method from Section 11.7, show that
u(ρ, σ) = 1
π cot−1
ρ2 + σ2 −ρ
σ

.
Step 3: Show that
u(r, θ) = 1
π cot−1
rπ/α −cos(πθ/α)
sin(πθ/α)

,
where x = r cos(θ) and y = r sin(θ).
12. Use conformal mapping to solve Laplace’s equation for the semi-inﬁnite strip 0 ≤x ≤a,
0 ≤y < ∞, where u(x, 0) = 1, 0 ≤x ≤a, and u(0, y) = u(a, y) = 0, 0 ≤y < ∞.
Step 1: Consider the mapping τ = −cos(πz/a). Show that
ρ = −cos(πx/a) cosh(πy/a),
and
σ = sin(πx/a) sinh(πy/a).
In particular, (0, ∞) →(−∞, 0), (0, 0) →(−1, 0), (a/2, 0) →(0, 0), (a, 0) →(1, 0), and
(a, ∞) →(∞, 0).
Step 2: Using the Fourier method from Section 11.7, show that
u(ρ, σ) = 1
π cot−1
ρ2 + σ2 −1
2σ

.
Step 3: Show that
u(x, y) = 1
π cot−1
h
sinh2πy
a

−sin2πx
a
i 
2 sin
πx
a

sinh
πy
a

= 2
π tan−1

sin
πx
a
 
sinh
πy
a

.

508
Advanced Engineering Mathematics with MATLAB
Step 4: In the case that boundary conditions read u(0, y) = u(a, y) = 1 for 0 ≤y < ∞
and u(x, 0) = 0 for 0 ≤x ≤a, how could you use the solution in Step 3 to solve this new
problem?
Further Readings
Ablowitz, M. J., and A. S. Fokas, 2003: Complex Variables: Introduction and Applications.
Cambridge University Press, 660 pp. Covers a wide variety of topics, including complex
numbers, analytic functions, singularities, conformal mapping and the Riemann-Hilbert
problem.
Carrier, G. F., M. Krook, and C. E. Pearson, 1966: Functions of a Complex Variable:
Theory and Technique. McGraw-Hill Book Co., 438 pp. Graduate-level textbook.
Churchill, R. V., 1960: Complex Variables and Applications. McGraw-Hill Book Co., 297
pp. Classic textbook.
Flanigan, F. J., 1983: Complex Variables. Dover, 364 pp. A crystal clear exposition and
emphasis on an intuitive understanding of complex analysis.

Chapter 11
The Fourier Transform
In the previous chapter we showed how we could expand a periodic function in terms
of an inﬁnite sum of sines and cosines. However, most functions encountered in engineering
are aperiodic. As we shall see, the extension of Fourier series to these functions leads to the
Fourier transform.
11.1 FOURIER TRANSFORMS
The Fourier transform is the natural extension of Fourier series to a function f(t) of
inﬁnite period. To show this, consider a periodic function f(t) of period 2T that satisﬁes
the so-called Dirichlet’s conditions.1 If the integral
R b
a |f(t)| dt exists, this function has the
complex Fourier series
f(t) =
∞
X
n=−∞
cneinπt/T ,
(11.1.1)
where
cn = 1
2T
Z T
−T
f(t)e−inπt/T dt.
(11.1.2)
Equation 11.1.1 applies only if f(t) is continuous at t; if f(t) suﬀers from a jump discon-
tinuity at t, then the left side of Equation 11.1.1 equals 1
2[f(t+) + f(t−)], where f(t+) =
limx→t+ f(x) and f(t−) = limx→t−f(x). Substituting Equation 11.1.2 into Equation 11.1.1,
f(t) = 1
2T
∞
X
n=−∞
einπt/T
Z T
−T
f(x)e−inπx/T dx.
(11.1.3)
1 A function f(t) satisﬁes Dirichlet’s conditions in the interval (a, b) if (1) it is bounded in (a, b), and
(2) it has at most a ﬁnite number of discontinuities and a ﬁnite number of maxima and minima in that
interval.
509

510
Advanced Engineering Mathematics with MATLAB
Let us now introduce the notation ωn = nπ/T so that ∆ωn = ωn+1 −ωn = π/T. Then,
f(t) = 1
2π
∞
X
n=−∞
F(ωn)eiωnt∆ωn,
(11.1.4)
where
F(ωn) =
Z T
−T
f(x)e−iωnxdx.
(11.1.5)
As T →∞, ωn approaches a continuous variable ω, and ∆ωn may be interpreted as the
inﬁnitesimal dω. Therefore, ignoring any possible diﬃculties,2
f(t) = 1
2π
Z ∞
−∞
F(ω)eiωtdω,
(11.1.6)
and
F(ω) =
Z ∞
−∞
f(t)e−iωtdt.
(11.1.7)
Equation 11.1.7 is the Fourier transform of f(t) while Equation 11.1.6 is the inverse Fourier
transform that converts a Fourier transform back to f(t). Alternatively, we may combine
Equation 11.1.6 and Equation 11.1.7 to yield the equivalent real form
f(t) = 1
π
Z ∞
0
Z ∞
−∞
f(x) cos[ω(t −x)] dx

dω.
(11.1.8)
Hamming3 suggested the following analog in understanding the Fourier transform. Let
us imagine that f(t) is a light beam. Then the Fourier transform, like a glass prism, breaks
up the function into its component frequencies ω, each of intensity F(ω). In optics, the
various frequencies are called colors; by analogy the Fourier transform gives us the color
spectrum of a function. On the other hand, the inverse Fourier transform blends a function’s
spectrum to give back the original function.
Most signals encountered in practice have Fourier transforms because they are abso-
lutely integrable, since they are bounded and of ﬁnite duration. However, there are some
notable exceptions. Examples include the trigonometric functions sine and cosine.
2 For a rigorous derivation, see Titchmarsh, E. C., 1948: Introduction to the Theory of Fourier Integrals.
Oxford University Press, Chapter 1.
3 Hamming, R. W., 1977: Digital Filters. Prentice-Hall, p. 136.

The Fourier Transform
511
• Example 11.1.1
Let us ﬁnd the Fourier transform for
f(t) =

1,
|t| < a,
0,
|t| > a.
(11.1.9)
From the deﬁnition of the Fourier transform,
F(ω) =
Z −a
−∞
0 e−iωt dt +
Z a
−a
1 e−iωt dt +
Z ∞
a
0 e−iωt dt
(11.1.10)
= eωai −e−ωai
ωi
= 2 sin(ωa)
ω
= 2a sinc(ωa),
(11.1.11)
where sinc(x) = sin(x)/x is the sinc function.
Although this particular example does not show it, the Fourier transform is, in general,
a complex function. The most common method of displaying it is to plot its amplitude and
phase on two separate graphs for all values of ω. Another problem here is ratio of 0/0 when
ω = 0. Applying L’Hˆopital’s rule, we ﬁnd that F(0) = 2. Thus, we can plot the amplitude
and phase of F(ω) using the MATLAB script:
clear; % clear all previous computations
omegan = [-20:0.01:-0.01]; % set up negative frequencies
omegap = [0.01:0.01:20]; % set up positive frequencies
% compute Fourier transform for negative frequencies
f omegan = 2.*sin(omegan)./omegan;
% compute Fourier transform for positive frequencies
f omegap = 2.*sin(omegap)./omegap;
% concatenate all of the frequencies
omega = [omegan,0,omegap];
% bring together the Fourier transforms found
%
at positive and negative frequencies
f omega = [f omegan,2,f omegap];
amplitude = abs(f omega); % compute the amplitude
phase = atan2(0,f omega); % compute the phase
clf; % clear all previous figures
% plot frequency spectrum
subplot(2,1,1), plot(omega,amplitude)
% label amplitude plot
ylabel(’|F(\omega)|/a’,’FontSize’,15)
subplot(2,1,2), plot(omega,phase) % plot phase of transform
ylabel(’phase’,’FontSize’,15) % label amplitude plot
xlabel(’\omega’,’FontSize’,15) % label x-axis.
Figure 11.1.1 shows the output from the MATLAB script.
Of these two quantities, the
amplitude is by far the more popular one and is given the special name of frequency spectrum.
⊓⊔
From the deﬁnition of the inverse Fourier transform,
f(t) = 1
π
Z ∞
−∞
sin(ωa)
ω
eiωt dω =

1,
|t| < a,
0,
|t| > a.
(11.1.12)

512
Advanced Engineering Mathematics with MATLAB
−20
−15
−10
−5
0
5
10
15
20
0
0.5
1
1.5
2
|F(ω)|/a
−20
−15
−10
−5
0
5
10
15
20
0
1
2
3
4
phase
ω
Figure 11.1.1: Graph of the Fourier transform for Equation 11.1.9.
An important question is what value does f(t) converge to in the limit as t →a and
t →−a? Because Fourier transforms are an extension of Fourier series, the behavior at a
jump is the same as that for a Fourier series. For that reason, f(a) = 1
2[f(a+)+f(a−)] = 1
2
and f(−a) = 1
2[f(−a+) + f(−a−)] = 1
2.
• Example 11.1.2: Dirac delta function
Of the many functions that have a Fourier transform, a particularly important one is
the (Dirac) delta function.4 For example, in Section 11.6 we will use it to solve diﬀerential
equations. We deﬁne it as the inverse of the Fourier transform F(ω) = 1. Therefore,
δ(t) = 1
2π
Z ∞
−∞
eiωtdω.
(11.1.13)
⊓⊔
To give some insight into the nature of the delta function, consider another band-limited
transform
FΩ(ω) =

1,
|ω| < Ω,
0,
|ω| > Ω,
(11.1.14)
where Ωis real and positive. Then,
fΩ(t) = 1
2π
Z Ω
−Ω
eiωtdω = Ω
π
sin(Ωt)
Ωt
.
(11.1.15)
Figure 11.1.2 illustrates fΩ(t) for a large value of Ω. We observe that as Ω→∞, fΩ(t)
becomes very large near t = 0 as well as very narrow. On the other hand, fΩ(t) rapidly
approaches zero as |t| increases. Therefore, the delta function is given by the limit
δ(t) = lim
Ω→∞
sin(Ωt)
πt
, =
 ∞,
t = 0,
0,
t ̸= 0.
(11.1.16)
4 Dirac, P. A. M., 1947: The Principles of Quantum Mechanics. Oxford University Press, Section 15.

The Fourier Transform
513
(t)
-0.25
-0.15
-0.05
0.05
0.15
0.25
t
-30.0
-10.0
10.0
30.0
50.0
70.0
90.0
Ω
f
Figure 11.1.2: Graph of the function given in Equation 11.1.15 for Ω= 300.
Because the Fourier transform of the delta function equals one,
Z ∞
−∞
δ(t)e−iωtdt = 1.
(11.1.17)
Since Equation 11.1.17 must hold for any ω, we take ω = 0 and ﬁnd that
Z ∞
−∞
δ(t) dt = 1.
(11.1.18)
Thus, the area under the delta function equals unity. Taking Equation 11.1.16 into account,
we can also write Equation 11.1.18 as
Z b
−a
δ(t) dt = 1,
a, b > 0.
(11.1.19)
Finally, from the law of the mean of integrals, we have the sifting property that
Z b
a
f(t)δ(t −t0) dt = f(t0),
(11.1.20)
if a < t0 < b. This property is given its name because δ(t −t0) acts as a sieve, selecting
from all possible values of f(t) its value at t = t0.
We can also use several other functions with equal validity to represent the delta func-
tion. These include the limiting case of the following rectangular or triangular distributions:
δ(t) = lim
ǫ→0
(
1
ǫ ,
|t| < ǫ
2,
0,
|t| > ǫ
2,
or
δ(t) = lim
ǫ→0
(
1
ǫ

1 −|t|
ǫ

,
|t| < ǫ,
0,
|t| > ǫ,
(11.1.21)
and the Gaussian function:
δ(t) = lim
ǫ→0
exp(−πt2/ǫ)
√ǫ
.
(11.1.22)
Note that the delta function is an even function.

514
Advanced Engineering Mathematics with MATLAB
The Fourier Transforms of Some Commonly Encountered Functions
f(t), |t| < ∞
F(ω)
1.
e−atH(t),
a > 0
1
a + ωi
2.
eatH(−t),
a > 0
1
a −ωi
3.
te−atH(t),
a > 0
1
(a + ωi)2
4.
teatH(−t),
a > 0
−1
(a −ωi)2
5.
tne−atH(t), ℜ(a) > 0, n = 1, 2, . . .
n!
(a + ωi)n+1
6.
e−a|t|,
a > 0
2a
ω2 + a2
7.
te−a|t|,
a > 0
−4aωi
(ω2 + a2)2
8.
1
1 + a2t2
π
|a|e−|ω/a|
9.
cos(at)
1 + t2
π
2
 e−|ω−a| + e−|ω+a|
10.
sin(at)
1 + t2
π
2i
 e−|ω−a| −e−|ω+a|
11.

1,
|t| < a
0,
|t| > a
2 sin(ωa)
ω
12.
sin(at)
at

π/a,
|ω| < a
0,
|ω| > a
13.
e−at2,
a > 0
rπ
a exp

−ω2
4a

Note: The Heaviside step function H(t) is deﬁned by Equation 11.1.31.
• Example 11.1.3: Multiple Fourier transforms
The concept of Fourier transforms can be extended to multivariable functions. Consider
a two-dimensional function f(x, y). Then, holding y constant,
G(ξ, y) =
Z ∞
−∞
f(x, y) e−iξx dx.
(11.1.23)
Then, holding ξ constant,
F(ξ, η) =
Z ∞
−∞
G(ξ, y) e−iηy dy.
(11.1.24)
Therefore, the double Fourier transform of f(x, y) is
F(ξ, η) =
Z ∞
−∞
Z ∞
−∞
f(x, y) e−i(ξx+ηy) dx dy,
(11.1.25)

The Fourier Transform
515
assuming that the integral exists.
In a similar manner, we can compute f(x, y) given F(ξ, η) by reversing the process.
Starting with
G(ξ, y) = 1
2π
Z ∞
−∞
F(ξ, η) eiηy dη,
(11.1.26)
followed by
f(x, y) = 1
2π
Z ∞
−∞
G(ξ, y) eiξx dξ,
(11.1.27)
we ﬁnd that
f(x, y) =
1
4π2
Z ∞
−∞
Z ∞
−∞
F(ξ, η) ei(ξx+ηy) dξ dη.
(11.1.28)
⊓⊔
• Example 11.1.4: Computation of Fourier transforms using MATLAB
The Heaviside (unit) step function is a piecewise continuous function deﬁned by
H(t −a) =
 1,
t > a,
0,
t < a,
(11.1.29)
where a ≥0. We will have much to say about this very useful function in the chapter on
Laplace transforms. Presently we will use it to express functions whose deﬁnition changes
over diﬀerent ranges of t. For example, the “top hat” function Equation 11.1.9 can be
rewritten f(t) = H(t + a) −H(t −a). We can see that this is correct by considering various
ranges of t. For example, if t < −a, both step functions equal zero and f(t) = 0. On
the other hand, if t > a, both step functions equal one and again f(t) = 0. Finally, for
−a < t < a, the ﬁrst step function equals one while the second one equals zero. In this
case, f(t) = 1. Therefore, f(t) = H(t + a) −H(t −a) is equivalent to Equation 11.1.9.
This ability to rewrite functions in terms of the step function is crucial if you want to
use MATLAB to compute the Fourier transform via the MATLAB routine fourier. For ex-
ample, how would we compute the Fourier transform of the signum function? The MATLAB
commands
>> syms omega t; syms a positive
>> fourier(’Heaviside(t+a)-Heaviside(t-a)’,t,omega)
>> simplify(ans)
yields
ans =
2*sin(a*omega)/omega
the correct answer.
Problems
1. (a) Show that the Fourier transform of
f(t) = e−a|t|,
a > 0,
is
F(ω) =
2a
ω2 + a2 .
Using MATLAB, plot the amplitude and phase spectra for this transform.

516
Advanced Engineering Mathematics with MATLAB
(b) Use MATLAB’s fourier to ﬁnd F(ω).
2. (a) Show that the Fourier transform of
f(t) = te−a|t|,
a > 0,
is
F(ω) = −
4aωi
(ω2 + a2)2 .
Using MATLAB, plot the amplitude and phase spectra for this transform.
(b) Use MATLAB’s fourier to ﬁnd F(ω).
3. (a) Show that the Fourier transform of
f(t) = e−at2,
a > 0,
is
F(ω) =
rπ
a exp

−ω2
4a

.
Using MATLAB, plot the amplitude and phase spectra for this transform.
(b) Use MATLAB’s fourier to ﬁnd F(ω).
4. (a) Show that the Fourier transform of
f(t) =

e2t,
t < 0,
e−t,
t > 0,
is
F(ω) =
3
(2 −iω)(1 + iω).
Using MATLAB, plot the amplitude and phase spectra for this transform.
(b) Rewrite f(t) in terms of step functions. Then use MATLAB’s fourier to ﬁnd F(ω).
5. (a) Show that the Fourier transform of
f(t) =

e−(1+i)t,
t > 0,
−e(1−i)t,
t < 0,
is
F(ω) = −2i(ω + 1)
(ω + 1)2 + 1.
Using MATLAB, plot the amplitude and phase spectra for this transform.
(b) Rewrite f(t) in terms of step functions. Then use MATLAB’s fourier to ﬁnd F(ω).
6. (a) Show that the Fourier transform of
f(t) =

cos(at),
|t| < 1,
0,
|t| > 1,
is
F(ω) = sin(ω −a)
ω −a
+ sin(ω + a)
ω + a
.
Using MATLAB, plot the amplitude and phase spectra for this transform.
(b) Rewrite f(t) in terms of step functions. Then use MATLAB’s fourier to ﬁnd F(ω).
7. (a) Show that the Fourier transform of
f(t) =

sin(t),
0 ≤t < 1,
0,
otherwise,

The Fourier Transform
517
is
F(ω) = −1
2
1 −cos(ω −1)
ω −1
+ cos(ω + 1) −1
ω + 1

−i
2
sin(ω −1)
ω −1
−sin(ω + 1)
ω + 1

.
Using MATLAB, plot the amplitude and phase spectra for this transform.
(b) Rewrite f(t) in terms of step functions. Then use MATLAB’s fourier to ﬁnd F(ω).
8. (a) Show that the Fourier transform of
f(t) =

t/a,
|t| < a,
0,
|t| > a,
is
F(ω) = 2i cos(ωa)
ω
−2i sin(ωa)
ω2a
.
Using MATLAB, plot the amplitude and phase spectra for this transform.
(b) Rewrite f(t) in terms of step functions. Then use MATLAB’s fourier to ﬁnd F(ω).
9. (a) Show that the Fourier transform of
f(t) =

(t/a)2,
|t| < a,
0,
|t| > a,
is
F(ω) = 4 cos(ωa)
ω2a
−4 sin(ωa)
ω3a2
+ 2 sin(ωa)
ω
.
Using MATLAB, plot the amplitude and phase spectra for this transform.
(b) Rewrite f(t) in terms of step functions. Then use MATLAB’s fourier to ﬁnd F(ω).
10. (a) Show that the Fourier transform of
f(t) =

1 −t/τ,
0 ≤t < 2τ,
0,
otherwise,
is
F(ω) = 2e−iωτ
iω
sin(ωτ)
ωτ
−cos(ωτ)

.
Using MATLAB, plot the amplitude and phase spectra for this transform.
(b) Rewrite f(t) in terms of step functions. Then use MATLAB’s fourier to ﬁnd F(ω).
11. (a) Show that the Fourier transform of
f(t) =

1 −(t/a)2,
|t| ≤a,
0,
|t| ≥a,
and
F(ω) = 4 sin(ωa) −4aω cos(ωa)
a2ω3
.
Using MATLAB, plot the amplitude and phase spectra for this transform.
(b) Rewrite f(t) in terms of step functions. Then use MATLAB’s fourier to ﬁnd F(ω).
12. The integral representation5 of the modiﬁed Bessel function Kν(·) is
Kν (a|ω| ) = Γ
 ν + 1
2

(2a)ν
|ω|νΓ
  1
2

Z ∞
0
cos(ωt)
(t2 + a2)ν+1/2 dt,
5 Watson, G. N., 1966: A Treatise on the Theory of Bessel Functions. Cambridge University Press, p.
185.

518
Advanced Engineering Mathematics with MATLAB
where Γ(·) is the gamma function, ν ≥0 and a > 0. Use this relationship to show that
F

1
(t2 + a2)ν+1/2

= 2|ω|νΓ
  1
2

Kν (a|ω| )
Γ
 ν + 1
2

(2a)ν
.
13. Show that the Fourier transform of a constant K is 2πδ(ω)K.
14. Show that
Z b
a
τ δ(t −τ) dτ = t [H(t −a) −H(t −b)] .
Hint: Use integration by parts.
15. For the real function f(t) with Fourier transform F(ω), prove that |F(ω)| = |F(−ω)|
and the phase of F(ω) is an odd function of ω.
11.2 FOURIER TRANSFORMS CONTAINING THE DELTA FUNCTION
In the previous section we stressed the fact that such simple functions as cosine and
sine are not absolutely integrable. Does this mean that these functions do not possess a
Fourier transform? In this section we shall show that certain functions can still have a
Fourier transform even though we cannot compute them directly.
The reason why we can ﬁnd the Fourier transform of certain functions that are not
absolutely integrable lies with the introduction of the delta function because
Z ∞
−∞
δ(ω −ω0)eitω dω = eiω0t
(11.2.1)
for all t. Thus, the inverse of the Fourier transform δ(ω −ω0) is the complex exponential
eiω0t/2π or
F
 eiω0t
= 2πδ(ω −ω0).
(11.2.2)
This immediately yields the result that
F (1) = 2πδ(ω),
(11.2.3)
if we set ω0 = 0. Thus, the Fourier transform of 1 is an impulse at ω = 0 with weight
2π. Because the Fourier transform equals zero for all ω ̸= 0, f(t) = 1 does not contain a
nonzero frequency and is consequently a DC signal.
Another set of transforms arises from Euler’s formula because we have that
F[sin(ω0t)] =

F
 eiω0t
−F
 e−iω0t
/(2i)
(11.2.4)
= π [δ(ω −ω0) −δ(ω + ω0)] /i
(11.2.5)
= −πiδ(ω −ω0) + πiδ(ω + ω0)
(11.2.6)
and
F[cos(ω0t)] = 1
2

F
 eiω0t
+ F
 e−iω0t
= π [δ(ω −ω0) + δ(ω + ω0)] .
(11.2.7)
Note that although the amplitude spectra of sin(ω0t) and cos(ω0t) are the same, their phase
spectra are diﬀerent.

The Fourier Transform
519
Let us consider the Fourier transform of any arbitrary periodic function. Recall that
any such function f(t) with period 2L can be rewritten as the complex Fourier series
f(t) =
∞
X
n=−∞
cneinω0t,
(11.2.8)
where ω0 = π/L. The Fourier transform of f(t) is
F(ω) = F[f(t)] =
∞
X
n=−∞
2πcnδ(ω −nω0).
(11.2.9)
Therefore, the Fourier transform of any arbitrary periodic function is a sequence of impulses
with weight 2πcn located at ω = nω0 with n = 0, ±1, ±2, . . .. Thus, the Fourier series and
transform of a periodic function are closely related.
• Example 11.2.1: Fourier transform of the sign function
Consider the sign function
sgn(t) =
( 1,
t > 0,
0,
t = 0,
−1,
t < 0.
(11.2.10)
The function is not absolutely integrable. However, let us approximate it by e−ǫ|t|sgn(t),
where ǫ is a small positive number. This new function is absolutely integrable and we have
that
F[sgn(t)] = lim
ǫ→0

−
Z 0
−∞
eǫte−iωt dt +
Z ∞
0
e−ǫte−iωt dt

= lim
ǫ→0
 −1
ǫ −iω +
1
ǫ + iω

.
(11.2.11)
If ω ̸= 0, Equation 11.2.11 equals 2/iω. If ω = 0, Equation 11.2.11 equals 0 because
lim
ǫ→0
−1
ǫ + 1
ǫ

= 0.
(11.2.12)
Thus, we conclude that
F[sgn(t)] =

2/iω,
ω ̸= 0,
0,
ω = 0.
(11.2.13)
⊓⊔
• Example 11.2.2: Fourier transform of the step function
An important function in transform methods is the (Heaviside) step function
H(t) =
 1,
t > 0,
0,
t < 0.
(11.2.14)
In terms of the sign function it can be written
H(t) = 1
2 + 1
2sgn(t).
(11.2.15)

520
Advanced Engineering Mathematics with MATLAB
Because the Fourier transforms of 1 and sgn(t) are 2πδ(ω) and 2/iω, respectively, we have
that
F[H(t)] = πδ(ω) + 1
iω .
(11.2.16)
These transforms are used in engineering but the presence of the delta function requires
extra care to ensure their proper use.
Problems
1. Verify that
F[sin(ω0t)H(t)] =
ω0
ω2
0 −ω2 + πi
2 [δ(ω + ω0) −δ(ω −ω0)].
2. Verify that
F[cos(ω0t)H(t)] =
iω
ω2
0 −ω2 + π
2 [δ(ω + ω0) + δ(ω −ω0)].
3. Using the deﬁnition of Fourier transforms and Equation 11.2.17, show that
Z ∞
0
e−iωt dt = πδ(ω) −i
ω ,
or
Z ∞
0
eiωt dt = πδ(ω) + i
ω .
4. Following Example 11.2.1, show that
F[sgn(t) sin(ω0t)] =
2ω0
ω2
0 −ω2 ,
and
F[sgn(t) cos(ω0t)] =
2ωi
ω2
0 −ω2 .
11.3 PROPERTIES OF FOURIER TRANSFORMS
In principle we can compute any Fourier transform from its deﬁnition. However, it is
far more eﬃcient to derive some simple relationships that relate transforms to each other.
This is the purpose of this section.
Linearity
If f(t) and g(t) are functions with Fourier transforms F(ω) and G(ω), respectively,
then
F[c1f(t) + c2g(t)] = c1F(ω) + c2G(ω),
(11.3.1)
where c1 and c2 are (real or complex) constants.
This result follows from the integral deﬁnition
F[c1f(t) + c2g(t)] =
Z ∞
−∞
[c1f(t) + c2g(t)]e−iωtdt
(11.3.2)
= c1
Z ∞
−∞
f(t)e−iωtdt + c2
Z ∞
−∞
g(t)e−iωtdt
(11.3.3)
= c1F(ω) + c2G(ω).
(11.3.4)

The Fourier Transform
521
−10.0
−5.0
0.0
5.0
10.0
ω
−4.0
−2.0
0.0
2.0
4.0
phase (radians)
0.0
1.0
2.0
3.0
4.0
amplitude 
Figure 11.3.1: The amplitude and phase spectra of the Fourier transform for cos(2t) H(t) (solid line) and
cos[2(t −1)]H(t −1) (dashed line). The amplitude becomes inﬁnite at ω = ±2.
Time shifting
If f(t) is a function with a Fourier transform F(ω), then F[f(t −τ)] = e−iωτF(ω).
This follows from the deﬁnition of the Fourier transform
F[f(t −τ)] =
Z ∞
−∞
f(t −τ)e−iωtdt =
Z ∞
−∞
f(x)e−iω(x+τ)dx
(11.3.5)
= e−iωτ
Z ∞
−∞
f(x)e−iωxdx = e−iωτF(ω).
(11.3.6)
• Example 11.3.1
The Fourier transform of f(t) = cos(at)H(t) is F(ω) = iω/(a2 −ω2) + π[δ(ω + a) +
δ(ω −a)]/2. Therefore,
F{cos[a(t −k)]H(t −k)} = e−ikωF[cos(at)H(t)],
(11.3.7)
or
F{cos[a(t −k)]H(t −k)} = iωe−ikω
a2 −ω2 + π
2 e−ikω[δ(ω + a) + δ(ω −a)].
(11.3.8)
In Figure 11.3.1 we present the amplitude and phase spectra for cos(2t) H(t) (the solid
line) while the dashed line gives these spectra for cos[2(t −1)]H(t −1). This ﬁgure shows
that the amplitude spectra are identical (why?) while the phase spectra are considerably
diﬀerent.
⊓⊔

522
Advanced Engineering Mathematics with MATLAB
Scaling factor
Let f(t) be a function with a Fourier transform F(ω) and k be a real, nonzero constant.
Then F[f(kt)] = F(ω/k)/|k|.
From the deﬁnition of the Fourier transform:
F[f(kt)] =
Z ∞
−∞
f(kt)e−iωtdt = 1
|k|
Z ∞
−∞
f(x)e−i(ω/k)xdx = 1
|k|F
ω
k

.
(11.3.9)
• Example 11.3.2
The Fourier transform of f(t) = e−tH(t) is F(ω) = 1/(1 + ωi). Therefore, the Fourier
transform for f(at) = e−atH(t), a > 0, is
F[f(at)] =
1
a
 
1
1 + iω/a

=
1
a + ωi.
(11.3.10)
To illustrate this scaling property we use the MATLAB script
clear; % clear all previous computations
omega = [-10:0.01:10]; % set up frequencies
% real part of transform with a = 1
f1r omega = 1./(1+omega.*omega);
% imaginary part of transform with a = 1
f1i omega = - omega./(1+omega.*omega);
% real part of transform with a = 2
f2r omega = 2./(4+omega.*omega);
% imaginary part of transform with a = 2
f2i omega = - omega./(4+omega.*omega);
% compute the amplitude of the first transform
ampl1 = sqrt(f1r omega.*f1r omega + f1i omega.*f1i omega);
% compute the amplitude of the second transform
ampl2 = sqrt(f2r omega.*f2r omega + f2i omega.*f2i omega);
% compute phase of first transform
phase1 = atan2(f1i omega,f1r omega);
% compute phase of second transform
phase2 = atan2(f2i omega,f2r omega);
clf; % clear all previous figures
% plot amplitudes of Fourier transforms
subplot(2,1,1), plot(omega,ampl1,omega,ampl2,’--’)
ylabel(’|F(\omega)|’,’FontSize’,15) % label amplitude plot
% plot phases of Fourier transforms
subplot(2,1,2), plot(omega,phase1,omega,phase2,’--’)
ylabel(’phase’,’FontSize’,15) % label amplitude plot
xlabel(’\omega’,’FontSize’,15) % label x-axis

The Fourier Transform
523
−10
−5
0
5
10
0
0.5
1
|F(ω)|
−10
−5
0
5
10
−2
−1
0
1
2
phase
ω
Figure 11.3.2: The amplitude and phase spectra of the Fourier transform for e−tH(t) (solid line) and
e−2tH(t) (dashed line).
to plot the amplitude and phase when a = 1 and a = 2. Figure 11.3.2 shows the results
from the MATLAB script: The amplitude spectra decreased by a factor of two for e−2tH(t)
compared to e−tH(t) while the diﬀerences in the phase are smaller.
⊓⊔
Symmetry
If the function f(t) has the Fourier transform F(ω), then F[F(t)] = 2πf(−ω).
From the deﬁnition of the inverse Fourier transform,
f(t) = 1
2π
Z ∞
−∞
F(ω)eiωtdω = 1
2π
Z ∞
−∞
F(x)eixtdx.
(11.3.11)
Then
2πf(−ω) =
Z ∞
−∞
F(x)e−iωxdx =
Z ∞
−∞
F(t)e−iωtdt = F[F(t)].
(11.3.12)
• Example 11.3.3
The Fourier transform of 1/(1 + t2) is πe−|ω|. Therefore,
F

πe−|t|
=
2π
1 + ω2
or
F

e−|t|
=
2
1 + ω2 .
(11.3.13)
⊓⊔
Derivatives of functions
Let f (k)(t), k = 0, 1, 2, . . . , n−1, be continuous and f (n)(t) be piecewise continuous. Let
|f (k)(t)| ≤Ke−bt, b > 0, 0 ≤t < ∞; |f (k)(t)| ≤Meat, a > 0, −∞< t ≤0, k = 0, 1, . . . , n.
Then, F[f (n)(t)] = (iω)nF(ω).

524
Advanced Engineering Mathematics with MATLAB
-20.0
-10.0
0.0
10.0
20.0
ω
0.0
5.0
10.0
15.0
20.0
spectrum
-20.0
-10.0
0.0
10.0
20.0
t
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
f(t)
Figure 11.3.3: The (amplitude) spectrum of a rectangular pulse Equation 11.1.9 with a half width a = 10
that has been modulated with cos(5t).
We begin by noting that if the transform F[f ′(t)] exists, then
F[f ′(t)] =
Z ∞
−∞
f ′(t)e−iωtdt =
Z ∞
−∞
f ′(t)eωit[cos(ωrt) −i sin(ωrt)] dt
(11.3.14)
= (−ωi + iωr)
Z ∞
−∞
f(t)eωit[cos(ωrt) −i sin(ωrt)] dt
(11.3.15)
= iω
Z ∞
−∞
f(t)e−iωtdt = iωF(ω).
(11.3.16)
Finally,
F[f (n)(t)] = iωF[f (n−1)(t)] = (iω)2F[f (n−2)(t)] = · · · = (iω)nF(ω).
(11.3.17)
• Example 11.3.4
The Fourier transform of f(t) = 1/(1 + t2) is F(ω) = πe−|ω|. Therefore,
F

−
2t
(1 + t2)2

= iωπe−|ω|,
or
F

t
(1 + t2)2

= −iωπ
2 e−|ω|.
(11.3.18)
⊓⊔
Modulation
In communications a popular method of transmitting information is by amplitude mod-
ulation (AM). In this process the signal is carried according to the expression f(t)eiω0t,
where ω0 is the carrier frequency and f(t) is an arbitrary function of time whose amplitude
spectrum peaks at some frequency that is usually small compared to ω0. We now show that

The Fourier Transform
525
-20.0
-10.0
0.0
10.0
20.0
ω
0.0
10.0
20.0
30.0
40.0
50.0
spectrum
-20.0
-10.0
0.0
10.0
20.0
t
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
f(t)
Figure 11.3.4: The (amplitude) spectrum of a rectangular pulse Equation 11.1.9 with a half width a = 10
that has been modulated with cos(t/2).
the Fourier transform of f(t)eiω0t is F(ω −ω0), where F(ω) is the Fourier transform of f(t).
We begin by using the deﬁnition of the Fourier transform, or
F[f(t)eiω0t] =
Z ∞
−∞
f(t)eiω0te−iωtdt =
Z ∞
−∞
f(t)e−i(ω−ω0)tdt = F(ω −ω0).
(11.3.19)
Therefore, if we have the spectrum of a particular function f(t), then the Fourier transform
of the modulated function f(t)eiω0t is the same as that for f(t) except that it is now centered
on the frequency ω0 rather than on the zero frequency.
• Example 11.3.5
Let us determine the Fourier transform of a square pulse modulated by a cosine wave
as shown in Figures 11.3.3 and 11.3.4. Because cos(ω0t) = 1
2[eiω0t + e−iω0t] and the Fourier
transform of a square pulse is F(ω) = 2 sin(ωa)/ω,
F[f(t) cos(ω0t)] = sin[(ω −ω0)a]
ω −ω0
+ sin[(ω + ω0)a]
ω + ω0
.
(11.3.20)
Therefore, the Fourier transform of the modulated pulse equals one half of the sum of the
Fourier transform of the pulse centered on ω0 and −ω0. See Figures 11.3.3 and 11.3.4.
In many practical situations, ω0 ≫π/a.
In this case we may treat each term as
completely independent from the other; the contribution from the peak at ω = ω0 has a
negligible eﬀect on the peak at ω = −ω0.
⊓⊔
• Example 11.3.6
The Fourier transform of f(t) = e−btH(t) is F(ω) = 1/(b + iω). Therefore,
F[e−bt cos(at)H(t)] = 1
2F
 eiate−bt + e−iate−bt
(11.3.21)

526
Advanced Engineering Mathematics with MATLAB
−10.0
−5.0
0.0
5.0
10.0
ω
−2.0
−1.0
0.0
1.0
2.0
phase (radians)
0.0
0.1
0.2
0.3
0.4
0.5
amplitude 
Figure 11.3.5: The amplitude and phase spectra of the Fourier transform for e−2t H(t) (solid line) and
e−2t cos(4t)H(t) (dashed line).
F[e−bt cos(at)H(t)] = 1
2

1
b + iω′

ω′=ω−a
+
1
b + iω′

ω′=ω+a

(11.3.22)
= 1
2

1
(b + iω) −ai +
1
(b + iω) + ai

(11.3.23)
=
b + iω
(b + iω)2 + a2 .
(11.3.24)
We illustrate this result using e−2tH(t) and e−2t cos(4t)H(t) in Figure 11.3.5.
⊓⊔
• Example 11.3.7: Frequency modulation
In contrast to amplitude modulation, frequency modulation (FM) transmits information by
instantaneous variations of the carrier frequency. It can be expressed mathematically as
exp
h
i
R t
−∞f(τ) dτ +iC
i
eiω0t, where C is a constant. To illustrate this concept, let us ﬁnd
the Fourier transform of a simple frequency modulation
f(t) =

ω1,
|t| < T/2,
0 ,
|t| > T/2,
(11.3.25)
and C = −ω1T/2. In this case, the signal in the time domain is
g(t) = exp

i
Z t
−∞
f(τ) dτ + iC

eiω0t =



e−iω1T/2eiω0t,
t < −T/2,
eiω1teiω0t,
−T/2 < t < T/2,
eiω1T/2eiω0t,
T/2 < t.
(11.3.26)
We illustrate this signal in Figures 11.3.6 and 11.3.7.
The Fourier transform of the signal G(ω) equals
G(ω) = e−iω1T/2
Z −T/2
−∞
ei(ω0−ω)t dt +
Z T/2
−T/2
ei(ω0+ω1−ω)t dt + eiω1T/2
Z ∞
T/2
ei(ω0−ω)t dt

The Fourier Transform
527
−20.0
−10.0
0.0
10.0
20.0
(ω−ω )Τ
10
−4
10
−3
10
−2
10
−1
10
0
10
1
10
2
  Amplitude spectrum  
−1.0
−0.5
0.0
0.5
1.0
t/T
−1.0
−0.5
0.0
0.5
1.0
Re[g(t)]
0
Figure 11.3.6: The (amplitude) spectrum |G(ω)|/T of a frequency-modulated signal (shown top) when
ω1T = 2π and ω0T = 10π. The transform becomes undeﬁned at ω = ω0.
(11.3.27)
= e−iω1T/2
Z 0
−∞
ei(ω0−ω)t dt + eiω1T/2
Z ∞
0
ei(ω0−ω)t dt −e−iω1T/2
Z 0
−T/2
ei(ω0−ω)t dt
+
Z T/2
−T/2
ei(ω0+ω1−ω)t dt −eiω1T/2
Z T/2
0
ei(ω0−ω)t dt.
(11.3.28)
Applying the fact that
Z ∞
0
e±iαt dt = πδ(α) ± i
α,
(11.3.29)
G(ω) = πδ(ω −ω0)
h
eiω1T/2 + e−iω1T/2i
+

ei(ω0+ω1−ω)T/2 −e−i(ω0+ω1−ω)T/2
i(ω0 + ω1 −ω)
−

ei(ω0+ω1−ω)T/2 −e−i(ω0+ω1−ω)T/2
i(ω0 −ω)
(11.3.30)
= 2πδ(ω −ω0) cos(ω1T/2) + 2ω1 sin[(ω −ω0 −ω1)T/2]
(ω −ω0)(ω −ω0 −ω1)
.
(11.3.31)
Figures 11.3.6 and 11.3.7 illustrate the amplitude spectrum for various parameters.
In
general, the transform is not symmetric, with an increasing number of humped curves as
ω1T increases.
⊓⊔
Parseval’s equality
In applying Fourier methods to practical problems we may encounter a situation where
we are interested in computing the energy of a system. Energy is usually expressed by the
integral
R ∞
−∞|f(t)|2 dt. Can we compute this integral if we only have the Fourier transform
of F(ω)?

528
Advanced Engineering Mathematics with MATLAB
−20.0
−10.0
0.0
10.0
20.0
(ω−ω )Τ
10
−4
10
−3
10
−2
10
−1
10
0
10
1
10
2
  Amplitude spectrum  
−1.0
−0.5
0.0
0.5
1.0
t/T
−1.0
−0.5
0.0
0.5
1.0
Re[g(t)]
0
Figure 11.3.7: The (amplitude) spectrum |G(ω)|/T of a frequency-modulated signal (shown top) when
ω1T = 8π and ω0T = 10π. The transform becomes undeﬁned at ω = ω0.
From the deﬁnition of the inverse Fourier transform
f(t) = 1
2π
Z ∞
−∞
F(ω)eiωtdω,
(11.3.32)
we have that
Z ∞
−∞
|f(t)|2 dt = 1
2π
Z ∞
−∞
f(t)
Z ∞
−∞
F(ω)eiωtdω

dt.
(11.3.33)
Interchanging the order of integration on the right side of Equation 11.3.33,
Z ∞
−∞
|f(t)|2 dt = 1
2π
Z ∞
−∞
F(ω)
Z ∞
−∞
f(t)eiωtdt

dω.
(11.3.34)
However,
F ∗(ω) =
Z ∞
−∞
f(t)eiωtdt.
(11.3.35)
Therefore,
Z ∞
−∞
|f(t)|2 dt = 1
2π
Z ∞
−∞
|F(ω)|2 dω.
(11.3.36)
This is Parseval’s equality6 as it applies to Fourier transforms. The quantity |F(ω)|2 is
called the power spectrum.
6 Apparently ﬁrst derived by Rayleigh, J. W., 1889: On the character of the complete radiation at a
given temperature. Philos. Mag., Ser. 5, 27, 460–469.

The Fourier Transform
529
Some General Properties of Fourier Transforms
function, f(t)
Fourier transform, F(ω)
1. Linearity
c1f(t) + c2g(t)
c1F(ω) + c2G(ω)
2. Complex
f ∗(t)
F ∗(−ω)
conjugate
3. Scaling
f(αt)
F(ω/α)/|α|
4. Delay
f(t −τ)
e−iωτF(ω)
5. Frequency
eiω0tf(t)
F(ω −ω0)
translation
6. Duality-time
F(t)
2πf(−ω)
frequency
7. Time
f ′(t)
iωF(ω)
diﬀerentiation
• Example 11.3.8
In Example 11.1.1, we showed that the Fourier transform for a unit rectangular pulse
between −a < t < a is 2 sin(ωa)/ω. Therefore, by Parseval’s equality,
2
π
Z ∞
−∞
sin2(ωa)
ω2
dω =
Z a
−a
12 dt = 2a,
or
Z ∞
−∞
sin2(ωa)
ω2
dω = πa.
(11.3.37)
⊓⊔
Poisson’s summation formula
If f(x) is integrable over (−∞, ∞), there exists a relationship between the function and
its Fourier transform, commonly called Poisson’s summation formula.7
We begin by inventing a periodic function g(x) deﬁned by
g(x) =
∞
X
k=−∞
f(x + 2πk).
(11.3.38)
Because g(x) is a periodic function of 2π, it can be represented by the complex Fourier
series:
g(x) =
∞
X
n=−∞
cneinx,
or
g(0) =
∞
X
k=−∞
f(2πk) =
∞
X
n=−∞
cn.
(11.3.39)
7 Poisson, S. D., 1823: Suite du m´emoire sur les int´egrales d´eﬁnies et sur la sommation des s´eries. J.
´Ecole Polytech., 19, 404–509. See page 451.

530
Advanced Engineering Mathematics with MATLAB
Computing cn, we ﬁnd that
cn = 1
2π
Z π
−π
g(x)e−inx dx = 1
2π
Z π
−π
∞
X
k=−∞
f(x + 2kπ)e−inx dx
(11.3.40)
= 1
2π
∞
X
k=−∞
Z π
−π
f(x + 2kπ)e−inx dx = 1
2π
Z ∞
−∞
f(x)e−inx dx = F(n)
2π ,
(11.3.41)
where F(ω) is the Fourier transform of f(x). Substituting Equation 11.3.41 into the right
side of Equation 11.3.39, we obtain
∞
X
k=−∞
f(2πk) = 1
2π
∞
X
n=−∞
F(n)
(11.3.42)
or
∞
X
k=−∞
f(αk) = 1
α
∞
X
n=−∞
F
2πn
α

.
(11.3.43)
• Example 11.3.9
One of the popular uses of Poisson’s summation formula is the evaluation of inﬁnite
series.
For example, let f(x) = 1/(a2 + x2) with a real and nonzero.
Then, F(ω) =
πe−|aω|/|a| and
∞
X
k=−∞
1
a2 + (2πk)2 = 1
2
∞
X
n=−∞
1
|a|e−|an| =
1
2|a|
 
1 + 2
∞
X
n=1
e−|a|n
!
(11.3.44)
=
1
2|a|

−1 +
2
1 −e−|a|

=
1
2|a| coth
|a|
2

.
(11.3.45)
Problems
1. Find the Fourier transform of 1/(1 + a2t2), where a is real, given that F[1/(1 + t2)] =
πe−|ω|.
2. Find the Fourier transform of cos(at)/(1+t2), where a is real, given that F[1/(1+t2)] =
πe−|ω|.
3. Use the fact that F[e−atH(t)] = 1/(a + iω) with a > 0 and Parseval’s equality to show
that
Z ∞
−∞
dx
x2 + a2 = π
a .

The Fourier Transform
531
4. Use the fact that F[1/(1 + t2)] = πe−|ω| and Parseval’s equality to show that
Z ∞
−∞
dx
(x2 + 1)2 = π
2 .
5. Use the function f(t) = e−at sin(bt)H(t) with a > 0 and Parseval’s equality to show that
2
Z ∞
0
dx
(x2 + a2 −b2)2 + 4a2b2 =
Z ∞
−∞
dx
(x2 + a2 −b2)2 + 4a2b2 =
π
2a(a2 + b2).
6. Using the modulation property and F[e−btH(t)] = 1/(b + iω), show that
F

e−bt sin(at)H(t)

=
a
(b + iω)2 + a2 .
Use MATLAB to plot and compare the amplitude and phase spectra for e−t H(t) and
e−t sin(2t) H(t).
7. Use Poisson’s summation formula with f(t) = e−|t| to show that
∞
X
n=−∞
1
n2 + 1 = π 1 + e−2π
1 −e−2π .
8. Use Poisson’s summation formula to prove8 that
∞
X
n=−∞
e−a(n+c)2+2b(n+c) =
rπ
a eb2/a
∞
X
n=−∞
e−n2π2/a−2nπi(b/a−c).
9. Use Poisson’s summation formula to prove that
∞
X
n=−∞
e−ianT = 2π
T
∞
X
n=−∞
δ
2πn
T
−a

,
where δ(·) is the Dirac delta function.
10. Prove the two-dimensional form9 of Poisson’s summation formula:
∞
X
k1=−∞
∞
X
k2=−∞
f(α1k1, α2k2) =
1
α1α2
∞
X
n1=−∞
∞
X
n2=−∞
F
2πn1
α1
, 2πn2
α2

,
8 First proved by Ewald, P. P., 1921: Die Berechnung optischer und elektrostatischer Gitterpotentiale.
Ann. Phys., 4te Folge, 64, 253–287.
9 Lucas, S. K., R. Sipcic, and H. A. Stone, 1997: An integral equation solution for the steady-state
current at a periodic array of surface microelectrodes. SIAM J. Appl. Math., 57, 1615–1638.

532
Advanced Engineering Mathematics with MATLAB
where
F(ω1, ω2) =
Z ∞
−∞
Z ∞
−∞
f(x, y)e−iω1x−iω2y dx dy.
11.4 INVERSION OF FOURIER TRANSFORMS
Having focused on the Fourier transform in the previous sections, we now consider the
inverse Fourier transform. Recall that the improper integral, Equation 11.1.6, deﬁnes the
inverse. Consequently, one method of inversion is direct integration.
• Example 11.4.1
Let us ﬁnd the inverse of F(ω) = πe−|ω|.
From the deﬁnition of the inverse Fourier transform,
f(t) = 1
2π
Z ∞
−∞
πe−|ω|eiωtdω = 1
2
Z 0
−∞
e(1+it)ωdω + 1
2
Z ∞
0
e(−1+it)ωdω
(11.4.1)
=1
2
"
e(1+it)ω
1 + it

0
−∞
+ e(−1+it)ω
−1 + it

∞
0
#
= 1
2

1
1 + it −
1
−1 + it

=
1
1 + t2 .
(11.4.2)
An alternative to direct integration is the MATLAB function ifourier. For example,
to invert F(ω) = πe−|ω|, we type in the commands:
>> syms pi omega t
>> ifourier(’pi*exp(-abs(omega))’,omega,t)
This yields
ans =
1/(1+t^2)
⊓⊔
Another method for inverting Fourier transforms is rewriting the Fourier transform
using partial fractions so that we can use transform tables. The following example illustrates
this technique.
• Example 11.4.2
Let us invert the transform
F(ω) =
1
(1 + iω)(1 −2iω)2 .
(11.4.3)
We begin by rewriting (11.4.3) as
F(ω) = 1
9

1
1 + iω +
2
1 −2iω +
6
(1 −2iω)2

=
1
9(1 + iω) +
1
9( 1
2 −iω) +
1
6( 1
2 −iω)2 . (11.4.4)
Using a table of Fourier transforms (see Section 11.1), we invert Equation 11.4.4 term by
term and ﬁnd that
f(t) = 1
9e−tH(t) + 1
9et/2H(−t) −1
6tet/2H(−t).
(11.4.5)

The Fourier Transform
533
To check our answer, we type the following commands into MATLAB:
>> syms omega t
>> ifourier(1/((1+i*omega)*(1-2*i*omega)^2),omega,t)
which yields
ans =
1/9*exp(-t)*Heaviside(t)-1/6*exp(1/2*t)*t*Heaviside(-t)
+1/9*exp(1/2*t)*Heaviside(-t)
⊓⊔
Although we may ﬁnd the inverse by direct integration or partial fractions, in many
instances the Fourier transform does not lend itself to these techniques. On the other hand,
if we view the inverse Fourier transform as a line integral along the real axis in the complex
ω-plane, then some of the techniques that we developed in Chapter 10 can be applied to
this problem. To this end, we rewrite the inversion integral, Equation 11.1.6, as
f(t) = 1
2π
Z ∞
−∞
F(ω)eitω dω = 1
2π
I
C
F(z)eitz dz −1
2π
Z
CR
F(z)eitz dz,
(11.4.6)
where C denotes a closed contour consisting of the entire real axis plus a new contour
CR that joins the point (∞, 0) to (−∞, 0). There are countless possibilities for CR. For
example, it could be the loop (∞, 0) to (∞, R) to (−∞, R) to (−∞, 0) with R > 0. However,
any choice of CR must be such that we can compute
R
CR F(z)eitz dz. When we take that
constraint into account, the number of acceptable contours decreases to just a few. The
best is given by Jordan’s lemma.10
Jordan’s lemma: Suppose that, on a circular arc CR with radius R and center at the
origin, f(z) →0 uniformly as R →∞. Then
(1)
lim
R→∞
Z
CR
f(z)eimz dz = 0,
(m > 0)
(11.4.7)
if CR lies in the ﬁrst and/or second quadrant;
(2)
lim
R→∞
Z
CR
f(z)e−imz dz = 0,
(m > 0)
(11.4.8)
if CR lies in the third and/or fourth quadrant;
(3)
lim
R→∞
Z
CR
f(z)emz dz = 0,
(m > 0)
(11.4.9)
if CR lies in the second and/or third quadrant; and
(4)
lim
R→∞
Z
CR
f(z)e−mz dz = 0,
(m > 0)
(11.4.10)
if CR lies in the ﬁrst and/or fourth quadrant.
10 Jordan, C., 1894: Cours D’Analyse de l’ ´Ecole Polytechnique. Vol. 2. Gauthier-Villars, pp. 285–286.
See also Whittaker, E. T., and G. N. Watson, 1963: A Course of Modern Analysis. Cambridge University
Press, p. 115.

534
Advanced Engineering Mathematics with MATLAB
Technically, only (1) is actually Jordan’s lemma while the remaining points are varia-
tions.
Proof : We shall prove the ﬁrst part; the remaining portions follow by analog. We begin by
noting that
|IR| =

Z
CR
f(z)eimz dz
 ≤
Z
CR
|f(z)|
eimz |dz|.
(11.4.11)
Now
|dz| = R dθ,
|f(z)| ≤MR,
(11.4.12)
eimz =
exp(imReθi)
 = |exp{imR[cos(θ) + i sin(θ)]}| = e−mR sin(θ).
(11.4.13)
Therefore,
|IR| ≤RMR
Z θ1
θ0
exp[−mR sin(θ)] dθ,
(11.4.14)
where 0 ≤θ0 < θ1 ≤π. Because the integrand is positive, the right side of Equation 11.4.14
is largest if we take θ0 = 0 and θ1 = π. Then
|IR| ≤RMR
Z π
0
e−mR sin(θ) dθ = 2RMR
Z π/2
0
e−mR sin(θ) dθ.
(11.4.15)
We cannot evaluate the integrals in Equation 11.4.15 as they stand.
However, because
sin(θ) ≥2θ/π if 0 ≤θ ≤π/2, we can bound the value of the integral by
|IR| ≤2RMR
Z π/2
0
e−2mRθ/π dθ = π
mMR
 1 −e−mR
.
(11.4.16)
If m > 0, |IR| tends to zero with MR as R →∞.
⊓⊔
Consider now the following inversions of Fourier transforms:
• Example 11.4.3
For our ﬁrst example we ﬁnd the inverse for
F(ω) =
1
ω2 −2ibω −a2 −b2 ,
a, b > 0.
(11.4.17)
From the inversion integral,
f(t) = 1
2π
Z ∞
−∞
eitω
ω2 −2ibω −a2 −b2 dω,
(11.4.18)
or
f(t) = 1
2π
I
C
eitz
z2 −2ibz −a2 −b2 dz −1
2π
Z
CR
eitz
z2 −2ibz −a2 −b2 dz,
(11.4.19)
where C denotes a closed contour consisting of the entire real axis plus CR.
Because
f(z) = 1/(z2 −2ibz −a2 −b2) tends to zero uniformly as |z| →∞and m = t, the second
integral in Equation 11.4.19 vanishes by Jordan’s lemma if CR is a semicircle of inﬁnite

The Fourier Transform
535
                                 
original   contour
x
y
a+bi
-a+bi
R
R
C     for t > 0
C     for t < 0
Figure 11.4.1: Contour used to ﬁnd the inverse of the Fourier transform, Equation 11.4.17. The contour
C consists of the line integral along the real axis plus CR.
radius in the upper half of the z-plane when t > 0 and a semicircle in the lower half of the
z-plane when t < 0.
Next we must ﬁnd the location and nature of the singularities. They are located at
z2 −2ibz −a2 −b2 = 0,
or
z = ±a + bi.
(11.4.20)
Therefore we can rewrite Equation 11.4.19 as
f(t) = 1
2π
I
C
eitz
(z −a −bi)(z + a −bi) dz.
(11.4.21)
Thus, all of the singularities are simple poles.
Consider now t > 0.
As stated earlier, we close the line integral with an inﬁnite
semicircle in the upper half-plane. See Figure 11.4.1. Inside this closed contour there are
two singularities: z = ±a + bi. For these poles,
Res

eitz
z2 −2ibz −a2 −b2 ; a + bi

=
lim
z→a+bi
(z −a −bi)eitz
(z −a −bi)(z + a −bi)
(11.4.22)
= eiate−bt
2a
= e−bt
2a [cos(at) + i sin(at)],
(11.4.23)
where we used Euler’s formula to eliminate eiat. Similarly,
Res

eitz
z2 −2ibz −a2 −b2 ; −a + bi

= −e−bt
2a [cos(at) −i sin(at)].
(11.4.24)
Consequently, the inverse Fourier transform follows from Equation 11.4.21 after applying
the residue theorem, and equals
f(t) = −e−bt
2a sin(at)
(11.4.25)
for t > 0.

536
Advanced Engineering Mathematics with MATLAB
For t < 0, the semicircle is in the lower half-plane because the contribution from the
semicircle vanishes as R →∞. Because there are no singularities within the closed contour,
f(t) = 0. Therefore, we can write in general that
f(t) = −e−bt
2a sin(at)H(t).
(11.4.26)
⊓⊔
• Example 11.4.4
Let us ﬁnd the inverse of the Fourier transform
F(ω) =
e−ωi
ω2 + a2 ,
(11.4.27)
where a is real and positive.
From the inversion integral,
f(t) = 1
2π
Z ∞
−∞
ei(t−1)ω
ω2 + a2 dω = 1
2π
I
C
ei(t−1)z
z2 + a2 dz −1
2π
Z
CR
ei(t−1)z
z2 + a2 dz,
(11.4.28)
where C denotes a closed contour consisting of the entire real axis plus CR. The contour
CR is determined by Jordan’s lemma because 1/(z2 + a2) →0 uniformly as |z| →∞. Since
m = t −1, the semicircle CR of inﬁnite radius lies in the upper half-plane if t > 1 and in
the lower half-plane if t < 1. Thus, if t > 1,
f(t) = 1
2π (2πi)Res
ei(t−1)z
z2 + a2 ; ai

= e−a(t−1)
2a
,
(11.4.29)
whereas for t < 1,
f(t) = 1
2π (−2πi)Res
ei(t−1)z
z2 + a2 ; −ai

= ea(t−1)
2a
.
(11.4.30)
The minus sign in front of the 2πi arises from the clockwise direction or negative sense of
the contour. We can write the inverse as the single expression
f(t) = e−a|t−1|
2a
.
(11.4.31)
⊓⊔
• Example 11.4.5
Let us evaluate the integral
Z ∞
−∞
cos(kx)
x2 + a2 dx,
(11.4.32)
where a, k > 0.

The Fourier Transform
537
                



                



                    

              

                    

 
x
y
R
R
C     for t > 0
C     for t < 0
original   contour
a
-a
Figure 11.4.2: Contour used in Example 11.4.6.
We begin by noting that
Z ∞
−∞
cos(kx)
x2 + a2 dx = ℜ
Z ∞
−∞
eikx
x2 + a2 dx

= ℜ
Z
C1
eikz
z2 + a2 dz

,
(11.4.33)
where C1 denotes a line integral along the real axis from −∞to ∞. A quick check shows
that the integrand of the right side of Equation 11.4.33 satisﬁes Jordan’s lemma. Therefore,
Z ∞
−∞
eikx
x2 + a2 dx =
I
C
eikz
z2 + a2 dz = 2πi Res

eikz
z2 + a2 ; ai

(11.4.34)
= 2πi lim
z→ai
(z −ai)eikz
z2 + a2
= π
a e−ka,
(11.4.35)
where C denotes the closed inﬁnite semicircle in the upper half-plane. Taking the real and
imaginary parts of Equation 11.4.35,
Z ∞
−∞
cos(kx)
x2 + a2 dx = π
a e−ka
and
Z ∞
−∞
sin(kx)
x2 + a2 dx = 0.
(11.4.36)
⊓⊔
• Example 11.4.6
Let us now invert the Fourier transform F(ω) = 2a/(a2 −ω2), where a is real. The
interesting aspect of this problem is the presence of singularities at ω = ±a that lie along
the contour of integration. How do we use contour integration to compute
f(t) = a
π
Z ∞
−∞
eitω
a2 −ω2 dω?
(11.4.37)
The answer to this question involves the concept of Cauchy principal value integrals,
which allows us to extend the conventional deﬁnition of integrals to include integrands

538
Advanced Engineering Mathematics with MATLAB
that become inﬁnite at a ﬁnite number of points. See Section 10.10. Thus, by treating
Equation 11.4.37 as a Cauchy principal value integral, we again convert it into a closed
contour integration by closing the line integration along the real axis as shown in Figure
11.4.2. The semicircles at inﬁnity vanish by Jordan’s lemma and
f(t) = a
π
I
C
eitz
a2 −z2 dz.
(11.4.38)
For t > 0,
f(t) = −2πia
π
1
2Res

eitz
z2 −a2 ; −a

−2πia
π
1
2Res

eitz
z2 −a2 ; a

.
(11.4.39)
We have the factor 1
2 because we are only passing over the “top” of the singularity at z = a
and z = −a. Computing the residues and simplifying the results, we obtain f(t) = sin(at).
Similarly, when t < 0,
f(t) = 2πia
π
1
2Res

eitz
z2 −a2 ; −a

+ 2πia
π
1
2Res

eitz
z2 −a2 ; a

= −sin(at).
(11.4.40)
These results can be collapsed down to the single expression f(t) = sgn(t) sin(at).
⊓⊔
• Example 11.4.7
An additional beneﬁt of understanding inversion by the residue method is the ability
to qualitatively anticipate the inverse by knowing the location of the poles of F(ω). This
intuition is important because many engineering analyses discuss stability and performance
entirely in terms of the properties of the system’s Fourier transform. In Figure 11.4.3 we
graphed the location of the poles of F(ω) and the corresponding f(t). The student should
go through the mental exercise of connecting the two pictures.
• Example 11.4.8
So far, we used only the ﬁrst two points of Jordan’s lemma. In this example11 we
illustrate how the remaining two points may be applied.
Consider the contour integral
I
C
cot(πz)

e−cz
(τ + 2πz)2 + β2 +
e−cz
(τ −2πz)2 + β2

dz,
where c > 0 and β, τ are real. Let us evaluate this contour integral where the contour is
shown in Figure 11.4.3.
11 See Hsieh, T. C., and R. Greif, 1972: Theoretical determination of the absorption coeﬃcient and the
total band absorptance including a speciﬁc application to carbon monoxide. Int. J. Heat Mass Transfer,
15, 1477–1487.

The Fourier Transform
539
-plane
f(t)
t
f(t)
t
ω -plane
ω
-plane
f(t)
t
f(t)
t
ω -plane
ω
-plane
f(t)
t
f(t)
t
ω -plane
ω
Figure 11.4.3: The correspondence between the location of the simple poles of the Fourier transform F(ω)
and the behavior of f(t).

540
Advanced Engineering Mathematics with MATLAB
2π
ε
|τ|−ιβ
|τ|+ιβ
2π
Figure 11.4.4: Contour used in Example 11.4.7.
From the residue theorem,
I
C
cot(πz)

e−cz
(τ + 2πz)2 + β2 +
e−cz
(τ −2πz)2 + β2

dz
= 2πi
∞
X
n=1
Res

cot(πz)

e−cz
(τ + 2πz)2 + β2 +
e−cz
(τ −2πz)2 + β2

; n

+ 2πi Res

cot(πz)

e−cz
(τ + 2πz)2 + β2 +
e−cz
(τ −2πz)2 + β2

; |τ| + βi
2π

+ 2πi Res

cot(πz)

e−cz
(τ + 2πz)2 + β2 +
e−cz
(τ −2πz)2 + β2

; |τ| −βi
2π

.
(11.4.41)
Now
Res

cot(πz)

e−cz
(τ + 2πz)2 + β2 +
e−cz
(τ −2πz)2 + β2

; n

= lim
z→n
(z −n) cos(πz)
sin(πz)
lim
z→n

e−cz
(τ + 2πz)2 + β2 +
e−cz
(τ −2πz)2 + β2

(11.4.42)
= 1
π

e−nc
(τ + 2nπ)2 + β2 +
e−nc
(τ −2nπ)2 + β2

,
(11.4.43)
Res

cot(πz)

e−cz
(τ + 2πz)2 + β2 +
e−cz
(τ −2πz)2 + β2

; |τ| + βi
2π

=
lim
z→(|τ|+βi)/2π
cot(πz)
4π2

(z −|τ| −βi)e−cz
(z + τ/2π)2 + β2/4π2 +
(z −|τ| −βi)e−cz
(z −τ/2π)2 + β2/4π2

(11.4.44)
= cot(|τ|/2 + βi/2) exp(−c|τ|/2π)[cos(cβ/2π) −i sin(cβ/2π)]
4πβi
,
(11.4.45)
and
Res

cot(πz)

e−cz
(τ + 2πz)2 + β2 +
e−cz
(τ −2πz)2 + β2

; |τ| −βi
2π


The Fourier Transform
541
=
lim
z→(|τ|−βi)/2π
cot(πz)
4π2

(z −|τ| + βi)e−cz
(z + τ/2π)2 + β2/4π2 +
(z −|τ| + βi)e−cz
(z −τ/2π)2 + β2/4π2

(11.4.46)
= cot(|τ|/2 −βi/2) exp(−c|τ|/2π)[cos(cβ/2π) + i sin(cβ/2π)]
−4πβi
.
(11.4.47)
Therefore,
I
C
cot(πz)

e−cz
(τ + 2πz)2 + β2 +
e−cz
(τ −2πz)2 + β2

dz
= 2i
∞
X
n=1

e−nc
(τ + 2nπ)2 + β2 +
e−nc
(τ −2nπ)2 + β2

+ i
2β
ei|τ| + eβ
ei|τ| −eβ e−c|τ|/2π[cos(cβ/2π) −i sin(cβ/2π)]
−i
2β
ei|τ| + e−β
ei|τ| −e−β e−c|τ|/2π[cos(cβ/2π) + i sin(cβ/2π)]
(11.4.48)
= 2i
∞
X
n=1

e−nc
(τ + 2nπ)2 + β2 +
e−nc
(τ −2nπ)2 + β2

−i
β
sinh(β) cos(cβ/2π) + sin(|τ|) sin(cβ/2π)
cosh(β) −cos(τ)
e−c|τ|/2π,
(11.4.49)
where cot(α) = i(e2iα + 1)/(e2iα −1), and we made extensive use of Euler’s formula.
Let us now evaluate the contour integral by direct integration. The contribution from
the integration along the semicircle at inﬁnity vanishes according to Jordan’s lemma. In-
deed, that is why this particular contour was chosen. Therefore,
I
C
cot(πz)

e−cz
(τ + 2πz)2 + β2 +
e−cz
(τ −2πz)2 + β2

dz
=
Z iǫ
i∞
cot(πz)

e−cz
(τ + 2πz)2 + β2 +
e−cz
(τ −2πz)2 + β2

dz
+
Z
Cǫ
cot(πz)

e−cz
(τ + 2πz)2 + β2 +
e−cz
(τ −2πz)2 + β2

dz
+
Z −i∞
−iǫ
cot(πz)

e−cz
(τ + 2πz)2 + β2 +
e−cz
(τ −2πz)2 + β2

dz.
(11.4.50)
Now, because z = iy,
Z iǫ
i∞
cot(πz)

e−cz
(τ + 2πz)2 + β2 +
e−cz
(τ −2πz)2 + β2

dz
=
Z ǫ
∞
coth(πy)

e−icy
(τ + 2πiy)2 + β2 +
e−icy
(τ −2πiy)2 + β2

dy
(11.4.51)
= −2
Z ∞
ǫ
coth(πy)(τ 2 + β2 −4π2y2)e−icy
(τ 2 + β2 −4π2y2)2 + 16π2τ 2y2 dy,
(11.4.52)
Z −i∞
−iǫ
cot(πz)

e−cz
(τ + 2πz)2 + β2 +
e−cz
(τ −2πz)2 + β2

dz

542
Advanced Engineering Mathematics with MATLAB
=
Z −∞
−ǫ
coth(πy)

e−icy
(τ + 2πiy)2 + β2 +
e−icy
(τ −2πiy)2 + β2

dy (11.4.53)
= 2
Z ∞
ǫ
coth(πy)(τ 2 + β2 −4π2y2)eicy
(τ 2 + β2 −4π2y2)2 + 16π2τ 2y2 dy,
(11.4.54)
and
Z
Cǫ
cot(πz)

e−cz
(τ + 2πz)2 + β2 +
e−cz
(τ −2πz)2 + β2

dz
=
Z −π/2
π/2

1
πǫeθi −πǫeθi
3
−· · ·

ǫieθi dθ
×

exp(−cǫeθi)
(τ + 2πǫeθi)2 + β2 +
exp(−cǫeθi)
(τ −2πǫeθi)2 + β2

.
(11.4.55)
In the limit of ǫ →0,
I
C
cot(πz)

e−cz
(τ + 2πz)2 + β2 +
e−cz
(τ −2πz)2 + β2

dz
= 4i
Z ∞
0
coth(πy)(τ 2 + β2 −4π2y2) sin(cy)
(τ 2 + β2 −4π2y2)2 + 16π2τ 2y2
dy −
2i
τ 2 + β2
(11.4.56)
= 2i
∞
X
n=1

e−nc
(τ + 2nπ)2 + β2 +
e−nc
(τ −2nπ)2 + β2

−i
β
sinh(β) cos(cβ/2π) + sin(|τ|) sin(cβ/2π)
cosh(β) −cos(τ)
e−c|τ|/2π,
(11.4.57)
or
4
Z ∞
0
coth(πy)(τ 2 + β2 −4π2y2) sin(cy)
(τ 2 + β2 −4π2y2)2 + 16π2τ 2y2
dy
= 2
∞
X
n=1

e−nc
(τ + 2nπ)2 + β2 +
e−nc
(τ −2nπ)2 + β2

(11.4.58)
−1
β
sinh(β) cos(cβ/2π) + sin(|τ|) sin(cβ/2π)
cosh(β) −cos(τ)
e−c|τ|/2π +
2
τ 2 + β2 .
If we let y = x/2π,
β
π
Z ∞
0
coth(x/2)(τ 2 + β2 −x2) sin(cx/2π)
(τ 2 + β2 −x2)2 + 4τ 2x2
dx
= 2β
∞
X
n=1

e−nc
(τ + 2nπ)2 + β2 +
e−nc
(τ −2nπ)2 + β2

(11.4.59)
−sinh(β) cos(cβ/2π) + sin(|τ|) sin(cβ/2π)
cosh(β) −cos(τ)
e−c|τ|/2π +
2β
τ 2 + β2 .
⊓⊔
Problems
1. Use direct integration to ﬁnd the inverse of the Fourier transform F(ω) = iωπe−|ω|/2.
Check your answer using MATLAB.

The Fourier Transform
543
Use partial fractions to invert the following Fourier transforms:
2.
1
(1 + iω)(1 + 2iω)
3.
1
(1 + iω)(1 −iω)
4.
iω
(1 + iω)(1 + 2iω)
5.
1
(1 + iω)(1 + 2iω)2
Then check your answer using MATLAB.
By taking the appropriate closed contour, ﬁnd the inverse of the following Fourier transforms
by contour integration. The parameter a is real and positive.
6.
1
ω2 + a2
7.
ω
ω2 + a2
8.
ω
(ω2 + a2)2
9.
ω2
(ω2 + a2)2
10.
1
ω2 −3iω −3
11.
1
(ω −ia)2n+2
12.
ω2
(ω2 −1)2 + 4a2ω2
13.
3
(2 −ωi)(1 + ωi)
Then check your answer using MATLAB.
14. Find the inverse of F(ω) = cos(ω)/(ω2 + a2), a > 0, by ﬁrst rewriting the transform as
F(ω) =
eiω
2(ω2 + a2) +
e−iω
2(ω2 + a2)
and then using the residue theorem on each term.
15. Find12 the inverse Fourier transform for
F±(ω) =
e±iω
(ω −ai) (R2eωi −e−ωi) =
e±iω−iω
(ω −ai) (R2 −e−2ωi),
where a > 0 and R > 1. Hint: You must ﬁnd separate inverses for diﬀerent time intervals.
For example, in the case of F+(ω), you must examine the special cases of t < 0 and t > 0.
16. As we shall show shortly, Fourier transforms can be used to solve diﬀerential equations.
During the solution of the heat equation, Taitel et al.13 inverted the Fourier transform
F(ω) =
cosh(y
√
ω2 + 1 )
√
ω2 + 1 sinh(p
√
ω2 + 1/2)
,
12 See Scharstein, R. W., 1992: Transient electromagnetic plane wave reﬂection from a dielectric slab.
IEEE Trans. Educ., 35, 170–175.
13 Taitel, Y., M. Bentwich, and A. Tamir, 1973: Eﬀects of upstream and downstream boundary conditions
on heat (mass) transfer with axial diﬀusion. Int. J. Heat Mass Transfer, 16, 359–369.

544
Advanced Engineering Mathematics with MATLAB
where y and p are real. Show that they should have found
f(t) = e−|t|
p
+ 2
p
∞
X
n=1
(−1)n
p
1 + 4n2π2/p2 cos
2nπy
p

e−√
1+4n2π2/p2 |t|.
In this case, our time variable t was their spatial variable x −ξ.
17. Find the inverse of the Fourier transform
F(ω) =

cos

ωL
β[1 + iγ sgn(ω)]
−1
,
where L, β, and γ are real and positive and sgn(z) = 1 if ℜ(z) > 0 and −1 if ℜ(z) < 0.
Use the residue theorem to verify the following integrals:
18.
Z ∞
−∞
sin(x)
x2 + 4x + 5 dx = −π
e sin(2)
19.
Z ∞
0
cos(x)
(x2 + 1)2 dx = π
2e
20.
Z ∞
−∞
x sin(ax)
x2 + 4
dx = πe−2a
21.
Z ∞
0
x2 cos(ax)
(x2 + b2)2 dx = π
4b(1 −ab)e−ab
where a, b > 0.
22. The concept of forced convection is normally associated with heat streaming through
a duct or past an obstacle. Bentwich14 showed that a similar transport can exist when
convection results from a wave traveling through an essentially stagnant ﬂuid. In the process
of computing the amount of heating, he proved the following identity:
Z ∞
−∞
cosh(hx) −1
x sinh(hx)
cos(ax) dx = ln[coth(|a|π/h)],
h > 0.
Conﬁrm his result.
11.5 CONVOLUTION
The most important property of Fourier transforms is convolution. We shall use it
extensively in the solution of diﬀerential equations and the design of ﬁlters because it yields
in time or space the eﬀect of multiplying two transforms together.
The convolution operation is
f(t) ∗g(t) =
Z ∞
−∞
f(x)g(t −x) dx =
Z ∞
−∞
f(t −x)g(x) dx.
(11.5.1)
Then,
F[f(t) ∗g(t)] =
Z ∞
−∞
f(x)e−iωx
Z ∞
−∞
g(t −x)e−iω(t−x)dt

dx
(11.5.2)
=
Z ∞
−∞
f(x)G(ω)e−iωxdx = F(ω)G(ω).
(11.5.3)
14 Bentwich, M., 1966: Convection enforced by surface and tidal waves. Int. J. Heat Mass Transfer, 9,
663–670.

The Fourier Transform
545
Thus, the Fourier transform of the convolution of two functions equals the product of the
Fourier transforms of each of the functions.
• Example 11.5.1
Let us verify the convolution theorem using the functions f(t) = H(t + a) −H(t −a)
and g(t) = e−tH(t), where a > 0.
The convolution of f(t) with g(t) is
f(t) ∗g(t) =
Z ∞
−∞
e−(t−x)H(t −x) [H(x + a) −H(x −a)] dx = e−t
Z a
−a
exH(t −x) dx.
(11.5.4)
If t < −a, then the integrand of Equation 11.5.4 is always zero and f(t) ∗g(t) = 0. If t > a,
f(t) ∗g(t) = e−t
Z a
−a
exdx = e−(t−a) −e−(t+a).
(11.5.5)
Finally, for −a < t < a,
f(t) ∗g(t) = e−t
Z t
−a
exdx = 1 −e−(t+a).
(11.5.6)
In summary,
f(t) ∗g(t) =
(
0,
t ≤−a,
1 −e−(t+a),
−a ≤t ≤a,
e−(t−a) −e−(t+a),
a ≤t.
(11.5.7)
⊓⊔
As an alternative to examining various cases involving the value of t, we could have
used MATLAB to evaluate Equation 11.5.4. The MATLAB instructions are as follows:
>> syms f t x
>> syms a positive
>> f = ’exp(x-t)*Heaviside(t-x)*(Heaviside(x+a)-Heaviside(x-a))’
>> int(f,x,-inf,inf)
This yields
ans =
Heaviside(t+a)-Heaviside(t+a)*exp(-a-t)
-Heaviside(t-a)+Heaviside(t-a)*exp(a-t)
The Fourier transform of f(t) ∗g(t) is
F[f(t) ∗g(t)] =
Z a
−a
h
1 −e−(t+a)i
e−iωtdt +
Z ∞
a
h
e−(t−a) −e−(t+a)i
e−iωtdt
(11.5.8)
= 2 sin(ωa)
ω
−2i sin(ωa)
1 + ωi
= 2 sin(ωa)
ω

1
1 + ωi

= F(ω)G(ω)
(11.5.9)
and the convolution theorem is true for this special case. The Fourier transform Equation
11.5.9 could also be obtained by substituting our earlier MATLAB result into fourier and
then using simplify(ans).

546
Advanced Engineering Mathematics with MATLAB
• Example 11.5.2
Let us consider the convolution of f(t) = f+(t)H(t) with g(t) = g+H(t). Note that
both of the functions are nonzero only for t > 0.
From the deﬁnition of convolution,
f(t) ∗g(t) =
Z ∞
−∞
f+(t −x)H(t −x)g+(x)H(x) dx =
Z ∞
0
f+(t −x)H(t −x)g+(x) dx.
(11.5.10)
For t < 0, the integrand is always zero and f(t) ∗g(t) = 0. For t > 0,
f(t) ∗g(t) =
Z t
0
f+(t −x)g+(x) dx.
(11.5.11)
Therefore, in general,
f(t) ∗g(t) =
Z t
0
f+(t −x)g+(x) dx

H(t).
(11.5.12)
This is the deﬁnition of convolution that we will use for Laplace transforms where all of the
functions equal zero for t < 0.
⊓⊔
The convolution operation also applies to Fourier transforms, in what is commonly
known as frequency convolution. We now prove that
F[f(t)g(t)] = F(ω) ∗G(ω)
2π
,
(11.5.13)
where
F(ω) ∗G(ω) =
Z ∞
−∞
F(τ)G(ω −τ) dτ,
(11.5.14)
where F(ω) and G(ω) are the Fourier transforms of f(t) and g(t), respectively.
Proof : Starting with
f(t) = 1
2π
Z ∞
−∞
F(τ)eiτt dτ,
(11.5.15)
we can multiply the inverse of F(τ) by g(t) so that we obtain
f(t)g(t) = 1
2π
Z ∞
−∞
F(τ)g(t)eiτt dτ.
(11.5.16)
Then, taking the Fourier transform of Equation 11.5.16, we ﬁnd that
F[f(t)g(t)] =
Z ∞
−∞
 1
2π
Z ∞
−∞
F(τ)g(t)eiτt dτ

e−iωt dt
(11.5.17)
= 1
2π
Z ∞
−∞
F(τ)
Z ∞
−∞
g(t)e−i(ω−τ)t dt

dτ
(11.5.18)
= 1
2π
Z ∞
−∞
F(τ)G(ω −τ) dτ = F(ω) ∗G(ω)
2π
.
(11.5.19)

The Fourier Transform
547
Thus, the multiplication of two functions in the time domain is equivalent to the convolution
of their spectral densities in the frequency domain.
⊓⊔
Problems
1. Show that e−tH(t) ∗e−tH(t) = te−tH(t). Then verify your result using MATLAB.
2. Show that e−tH(t) ∗etH(−t) = 1
2e−|t|. Then verify your result using MATLAB.
3.
Show that e−tH(t) ∗e−2tH(t) =
 e−t −e−2t
H(t).
Then verify your result using
MATLAB.
4. Show that
etH(−t) ∗[H(t) −H(t −2)] =



et −et−2,
t ≤0,
1 −et−2,
0 ≤t ≤2,
0,
2 ≤t.
Then verify your result using MATLAB.
5. Show that
[H(t) −H(t −2)] ∗[H(t) −H(t −2)] =





0,
t ≤0,
t,
0 ≤t ≤2,
4 −t,
2 ≤t ≤4,
0,
4 ≤t.
Then try and verify your result using MATLAB. What do you have to do to make it work?
6. Show that e−|t| ∗e−|t| = (1 + |t|)e−|t|.
7. Prove that the convolution of two Dirac delta functions is a Dirac delta function.
11.6 THE SOLUTION OF ORDINARY DIFFERENTIAL EQUATIONS
BY FOURIER TRANSFORMS
As with Laplace transforms, we may use Fourier transforms to solve ordinary diﬀerential
equations. However, this method gives only the particular solution and we must ﬁnd the
complementary solution separately.
Consider the diﬀerential equation
y′ + y = 1
2e−|t|,
−∞< t < ∞.
(11.6.1)
Taking the Fourier transform of both sides of Equation 11.6.1,
iωY (ω) + Y (ω) =
1
ω2 + 1,
(11.6.2)
where we used the derivative rule, Equation 11.3.17, to obtain the transform of y′ and
Y (ω) = F[y(t)]. Therefore,
Y (ω) =
1
(ω2 + 1)(1 + ωi).
(11.6.3)

548
Advanced Engineering Mathematics with MATLAB
Applying the inversion integral to Equation 11.6.3,
y(t) = 1
2π
Z ∞
−∞
eitω
(ω2 + 1)(1 + ωi) dω.
(11.6.4)
We evaluate Equation 11.6.4 by contour integration. For t > 0 we close the line integral
with an inﬁnite semicircle in the upper half of the ω-plane. The integration along this arc
equals zero by Jordan’s lemma. Within this closed contour we have a second-order pole at
z = i. Therefore,
Res

eitz
(z2 + 1)(1 + zi); i

= lim
z→i
d
dz

(z −i)2
eitz
i(z −i)2(z + i)

= te−t
2i
+ e−t
4i
(11.6.5)
and
y(t) = 1
2π (2πi)
te−t
2i
+ e−t
4i

= e−t
4 (2t + 1).
(11.6.6)
For t < 0, we again close the line integral with an inﬁnite semicircle but this time it is in
the lower half of the ω-plane. The contribution from the line integral along the arc vanishes
by Jordan’s lemma. Within the contour, we have a simple pole at z = −i. Therefore,
Res

eitz
(z2 + 1)(1 + zi); −i

= lim
z→−i(z + i)
eitz
i(z + i)(z −i)2 = −et
4i,
(11.6.7)
and
y(t) = 1
2π (−2πi)

−et
4i

= et
4 .
(11.6.8)
The minus sign in front of the 2πi results from the contour being taken in the clockwise
direction or negative sense. Using the step function, we can combine Equation 11.6.6 and
Equation 11.6.8 into the single expression
y(t) = 1
4e−|t| + 1
2te−tH(t).
(11.6.9)
Note that we only found the particular or forced solution to Equation 11.6.1. The most
general solution therefore requires that we add the complementary solution Ae−t, yielding
y(t) = Ae−t + 1
4e−|t| + 1
2te−tH(t).
(11.6.10)
The arbitrary constant A would be determined by the initial condition, which we have not
speciﬁed.
We could also have solved this problem using MATLAB. The MATLAB script
clear
% define symbolic variables
syms omega t Y
% take Fourier transform of left side of differential equation
LHS = fourier(diff(sym(’y(t)’))+sym(’y(t)’),t,omega);
% take Fourier transform of right side of differential equation
RHS = fourier(1/2*exp(-abs(t)),t,omega);
% set Y for Fourier transform of y
%
and introduce initial conditions
newLHS = subs(LHS,’fourier(y(t),t,omega)’,Y);

The Fourier Transform
549
% solve for Y
Y = solve(newLHS-RHS,Y);
% invert Fourier transform and find y(t)
y = ifourier(Y,omega,t)
yields
y =
1/4*exp(t)*Heaviside(-t)+1/2*exp(-t)*t*Heaviside(t)
+1/4*exp(-t)*Heaviside(t)
which is equivalent to Equation 11.6.9.
Consider now a more general problem of
y′ + y = f(t),
−∞< t < ∞,
(11.6.11)
where we assume that f(t) has the Fourier transform F(ω). Then the Fourier-transformed
solution to Equation 11.6.11 is
Y (ω) =
1
1 + ωiF(ω) = G(ω)F(ω)
or
y(t) = g(t) ∗f(t),
(11.6.12)
where g(t) = F−1[1/(1 + ωi)] = e−tH(t). Thus, we can obtain our solution in one of two
ways. First, we can take the Fourier transform of f(t), multiply this transform by G(ω),
and ﬁnally compute the inverse. The second method requires a convolution of f(t) with
g(t). Which method is easiest depends upon f(t) and g(t).
In summary, we can use Fourier transforms to ﬁnd particular solutions to diﬀerential
equations. The complete solution consists of this particular solution plus any homogeneous
solution that we need to satisfy the initial conditions. Convolution of the Green’s function
with the forcing function also gives the particular solution.
Problems
Find the particular solutions for the following diﬀerential equations. For Problems 1–3,
verify your solution using MATLAB.
1. y′′ + 3y′ + 2y = e−tH(t)
2. y′′ + 4y′ + 4y = 1
2e−|t|
3. y′′ −4y′ + 4y = e−tH(t)
4. yiv −λ4y = δ(x),
where λ has a positive real part and a negative imaginary part.
11.7 THE SOLUTION OF LAPLACE’S EQUATION ON THE UPPER HALF-PLANE
In this section we shall use Fourier integrals and convolution to ﬁnd the solution of
Laplace’s equation on the upper half-plane y > 0. We require that the solution remains
bounded over the entire domain and specify it along the x-axis, u(x, 0) = f(x). Under these
conditions, we can take the Fourier transform of Laplace’s equation and ﬁnd that
Z ∞
−∞
∂2u
∂x2 e−iωx dx +
Z ∞
−∞
∂2u
∂y2 e−iωx dx = 0.
(11.7.1)

550
Advanced Engineering Mathematics with MATLAB
If everything is suﬃciently diﬀerentiable, we may successively integrate by parts the ﬁrst
integral in Equation 11.7.1, which yields
Z ∞
−∞
∂2u
∂x2 e−iωx dx = ∂u
∂xe−iωx

∞
−∞
+ iω
Z ∞
−∞
∂u
∂xe−iωx dx
(11.7.2)
= iω u(x, y)e−iωx∞
−∞−ω2
Z ∞
−∞
u(x, y)e−iωx dx
(11.7.3)
= −ω2U(ω, y),
(11.7.4)
where
U(ω, y) =
Z ∞
−∞
u(x, y)e−iωx dx.
(11.7.5)
The second integral becomes
Z ∞
−∞
∂2u
∂y2 e−iωx dx = d2
dy2
Z ∞
−∞
u(x, y)e−iωx dx

= d2U(ω, y)
dy2
,
(11.7.6)
along with the boundary condition that
F(ω) = U(ω, 0) =
Z ∞
−∞
f(x)e−iωx dx.
(11.7.7)
Consequently, we reduced Laplace’s equation, a partial diﬀerential equation, to an ordinary
diﬀerential equation in y, where ω is merely a parameter:
d2U(ω, y)
dy2
−ω2U(ω, y) = 0,
(11.7.8)
with the boundary condition U(ω, 0) = F(ω). The solution to Equation 11.7.8 is
U(ω, y) = A(ω)e|ω|y + B(ω)e−|ω|y,
0 ≤y.
(11.7.9)
We must discard the e|ω|y term because it becomes unbounded as we go to inﬁnity along
the y-axis. The boundary condition results in B(ω) = F(ω). Consequently,
U(ω, y) = F(ω)e−|ω|y.
(11.7.10)
The inverse of the Fourier transform e−|ω|y equals
1
2π
Z ∞
−∞
e−|ω|yeiωx dω = 1
2π
Z 0
−∞
eωyeiωx dω + 1
2π
Z ∞
0
e−ωyeiωx dω
(11.7.11)
= 1
2π
Z ∞
0
e−ωye−iωx dω + 1
2π
Z ∞
0
e−ωyeiωx dω
(11.7.12)
= 1
π
Z ∞
0
e−ωy cos(ωx) dω
(11.7.13)
= 1
π
exp(−ωy)
x2 + y2
[−y cos(ωx) + x sin(ωx)]

∞
0
(11.7.14)
= 1
π
y
x2 + y2 .
(11.7.15)

The Fourier Transform
551
Furthermore, because Equation 11.7.10 is a convolution of two Fourier transforms, its inverse
is
u(x, y) = 1
π
Z ∞
−∞
yf(t)
(x −t)2 + y2 dt.
(11.7.16)
Equation 11.7.16 is Poisson’s integral formula15 for the half-plane y > 0 or Schwarz’ integral
formula.16
• Example 11.7.1
As an example, let u(x, 0) = 1 if |x| < 1 and u(x, 0) = 0 otherwise. Then,
u(x, y) = 1
π
Z 1
−1
y
(x −t)2 + y2 dt = 1
π

tan−1
1 −x
y

+ tan−1
1 + x
y

.
(11.7.17)
Problems
Find the solution to Laplace’s equation in the upper half-plane for the following boundary
conditions:
1. u(x, 0) =
 1,
0 < x < 1,
0,
otherwise.
3. u(x, 0) =
( T0,
x < 0,
0,
x > 0.
5. u(x, 0) =
(
T0,
−1 < x < 0,
T0 + (T1 −T0)x,
0 < x < 1,
0,
otherwise.
2. u(x, 0) =
 1,
x > 0,
−1,
x < 0.
4. u(x, 0) =
( 2T0,
x < −1,
T0,
−1 < x < 1,
0,
1 < x.
6. u(x, 0) =











T0,
x < a1,
T1,
a1 < x < a2,
T2,
a2 < x < a3,
...
...
Tn,
an < x.
11.8 THE SOLUTION OF THE HEAT EQUATION
We now consider the problem of one-dimensional heat ﬂow in a rod of inﬁnite length
with insulated sides. Although there are no boundary conditions because the slab is of
inﬁnite extent, we do require that the solution remains bounded as we go to either positive
or negative inﬁnity. The initial temperature within the rod is u(x, 0) = f(x).
Employing the product solution technique of Section 8.3, we begin by assuming that
u(x, t) = X(x)T(t) with
T ′ + a2λT = 0,
(11.8.1)
15
Poisson, S. D., 1823: Suite du m´emoire sur les int´egrales d´eﬁnies et sur la sommation des s´eries. J.
´Ecole Polytech., 19, 404–509. See pg. 462.
16 Schwarz, H. A., 1870: ¨Uber die Integration der partiellen Diﬀerentialgleichung∂2u/∂x2 +∂2u/∂y2 = 0
f¨ur die Fl¨ache eines Kreises. Vierteljahrsschr. Naturforsch. Ges. Z¨urich, 15, 113–128.

552
Advanced Engineering Mathematics with MATLAB
and
X′′ + λX = 0.
(11.8.2)
Solutions to Equation 11.8.1 and Equation 11.8.2, which remain ﬁnite over the entire x-
domain, are
X(x) = E cos(kx) + F sin(kx),
(11.8.3)
and
T(t) = C exp(−k2a2t).
(11.8.4)
Because we do not have any boundary conditions, we must include all possible values of
k. Thus, when we sum all of the product solutions according to the principle of linear
superposition, we obtain the integral
u(x, t) =
Z ∞
0
[A(k) cos(kx) + B(k) sin(kx)]e−k2a2t dk.
(11.8.5)
We can satisfy the initial condition by choosing
A(k) = 1
π
Z ∞
−∞
f(x) cos(kx) dx,
(11.8.6)
and
B(k) = 1
π
Z ∞
−∞
f(x) sin(kx) dx,
(11.8.7)
because the initial condition has the form of a Fourier integral
f(x) =
Z ∞
0
[A(k) cos(kx) + B(k) sin(kx)] dk,
(11.8.8)
when t = 0.
Several important results follow by rewriting Equation 11.8.8 as
u(x, t) = 1
π
Z ∞
0
Z ∞
−∞
f(ξ) cos(kξ) cos(kx) dξ +
Z ∞
−∞
f(ξ) sin(kξ) sin(kx) dξ

e−k2a2t dk.
(11.8.9)
Combining terms,
u(x, t) = 1
π
Z ∞
0
Z ∞
−∞
f(ξ)[cos(kξ) cos(kx) + sin(kξ) sin(kx)] dξ

e−k2a2t dk
(11.8.10)
= 1
π
Z ∞
0
Z ∞
−∞
f(ξ) cos[k(ξ −x)] dξ

e−k2a2t dk.
(11.8.11)
Reversing the order of integration,
u(x, t) = 1
π
Z ∞
−∞
f(ξ)
Z ∞
0
cos[k(ξ −x)]e−k2a2t dk

dξ.
(11.8.12)
The inner integral is called the source function. We may compute its value through an
integration on the complex plane; it equals
Z ∞
0
cos[k(ξ −x)] exp(−k2a2t) dk =
 π
4a2t
1/2
exp

−(ξ −x)2
4a2t

,
(11.8.13)

The Fourier Transform
553
if 0 < t. This gives the ﬁnal form for the temperature distribution:
u(x, t) =
1
√
4a2πt
Z ∞
−∞
f(ξ) exp

−(ξ −x)2
4a2t

dξ.
(11.8.14)
• Example 11.8.1
Let us ﬁnd the temperature ﬁeld if the initial distribution is
u(x, 0) =

T0,
x > 0,
−T0,
x < 0.
(11.8.15)
Then
u(x, t) =
T0
√
4a2πt
Z ∞
0
exp

−(ξ −x)2
4a2t

dξ −
Z 0
−∞
exp

−(ξ −x)2
4a2t

dξ

(11.8.16)
= T0
√π
Z ∞
−x/2a
√
t
e−τ 2 dτ −
Z ∞
x/2a
√
t
e−τ 2 dτ

= T0
√π
Z x/2a
√
t
−x/2a
√
t
e−τ 2 dτ
(11.8.17)
= 2T0
√π
Z x/2a
√
t
0
e−τ 2 dτ = T0 erf

x
2a
√
t

,
(11.8.18)
where erf(·) is the error function.
⊓⊔
• Example 11.8.2: Kelvin’s estimate of the age of the earth
In the middle of the nineteenth century, Lord Kelvin17 estimated the age of the earth
using the observed vertical temperature gradient at the earth’s surface. He hypothesized
that the earth was initially formed at a uniform high temperature T0 and that its surface
was subsequently maintained at the lower temperature of TS. Assuming that most of the
heat conduction occurred near the earth’s surface, he reasoned that he could neglect the
curvature of the earth, consider the earth’s surface planar, and employ our one-dimensional
heat conduction model in the vertical direction to compute the observed heat ﬂux.
Following Kelvin, we model the earth’s surface as a ﬂat plane with an inﬁnitely deep
earth below (z > 0). Initially the earth has the temperature T0. Suddenly we drop the
temperature at the surface to TS. We wish to ﬁnd the heat ﬂux across the boundary at
z = 0 from the earth into an inﬁnitely deep atmosphere.
The ﬁrst step is to redeﬁne our temperature scale v(z, t) = u(z, t)+TS, where v(z, t) is
the observed temperature so that u(0, t) = 0 at the surface. Next, in order to use Equation
11.8.14, we must deﬁne our initial state for z < 0. To maintain the temperature u(0, t) = 0,
the initial temperature ﬁeld f(z) must be an odd function, or
f(z) =

T0 −TS,
z > 0,
TS −T0,
z < 0.
(11.8.19)
17 Thomson, W., 1863: On the secular cooling of the earth. Philos. Mag., Ser. 4, 25, 157–170.

554
Advanced Engineering Mathematics with MATLAB
From Equation 11.8.14,
u(z, t) = T0 −TS
√
4a2πt
Z ∞
0
exp

−(ξ −z)2
4a2t

dξ −
Z 0
−∞
exp

−(ξ −z)2
4a2t

dξ

(11.8.20)
= (T0 −TS) erf

z
2a
√
t

,
(11.8.21)
following the work in the previous example.
The heat ﬂux q at the surface z = 0 is obtained by diﬀerentiating Equation 11.8.21
according to Fourier’s law and evaluating the result at z = 0:
q = −κ∂v
∂z

z=0
= κ(TS −T0)
a
√
πt
.
(11.8.22)
The surface heat ﬂux is inﬁnite at t = 0 because of the sudden application of the temperature
TS at t = 0. After that time, the heat ﬂux decreases with time. Consequently, the time t
at which we have the temperature gradient ∂v(0, t)/∂z is
t =
(T0 −TS)2
πa2[∂v(0, t)/∂z]2 .
(11.8.23)
For the present near-surface thermal gradient of 25 K/km, T0 −TS = 2000 K, and a2 = 1
mm2/s, the age of the earth from Equation 11.8.23 is 65 million years.
Although Kelvin realized that this was a very rough estimate, his calculation showed
that the earth had a ﬁnite age.
This was in direct contradiction to the contemporary
geological principle of uniformitarianism: that the earth’s surface and upper crust had
remained unchanged in temperature and other physical quantities for millions and millions
of years.
The resulting debate would rage throughout the latter half of the nineteenth
century and feature such luminaries as Kelvin, Charles Darwin, Thomas Huxley, and Oliver
Heaviside.18
Eventually Kelvin’s arguments would prevail and uniformitarianism would
fade into history.
Today, Kelvin’s estimate is of academic interest because of the discovery of radioactivity
at the turn of the twentieth century. During the ﬁrst half of the twentieth century, geologists
assumed that the radioactivity was uniformly distributed around the globe and restricted to
the upper few tens of kilometers of the crust. Using this model they would then use observed
heat ﬂuxes to compute the distribution of radioactivity within the solid earth.19 Now we
know that the interior of the earth is quite dynamic; the oceans and continents are mobile
and interconnected according to the theory of plate tectonics. However, geophysicists still
use measured surface heat ﬂuxes to infer the interior20 of the earth.
⊓⊔
• Example 11.8.3
So far we have shown how a simple application of separation of variables and the
Fourier transform yields solutions to the heat equation over the semi-inﬁnite interval (0, ∞)
18 See Burchﬁeld, J. D., 1975: Lord Kelvin and the Age of the Earth. Science History Publ., 260 pp.
19 See Slichter, L. B., 1941: Cooling of the earth. Bull. Geol. Soc. Am., 52, 561–600.
20 Sclater, J. G., C. Jaupart, and D. Galson, 1980: The heat ﬂow through oceanic and continental crust
and the heat loss of the earth. Rev. Geophys. Space Phys., 18, 269–311.

The Fourier Transform
555
via Equation 11.8.5. Can we still use this technique for more complicated versions of the
heat equation? The answer is yes but the procedure is more complicated. We illustrate it
by solving21
∂u
∂t = α ∂3u
∂t∂x2 + a2 ∂2u
∂x2 ,
0 < x < ∞,
0 < t,
(11.8.24)
subject to the boundary conditions
u(0, t) = f(t),
lim
x→0 |u(x, t)| < ∞,
0 < t,
(11.8.25)
lim
x→∞u(x, t) →0, lim
x→∞ux(x, t) →0,
0 < t,
(11.8.26)
and the initial condition
u(x, 0) = 0,
0 < x < ∞.
(11.8.27)
We begin by multiplying Equation 11.8.24 by sin(kx) and integrating over x from 0 to
∞:
α
Z ∞
0
utxx sin(kx) dx + a2
Z ∞
0
uxx sin(kx) dx =
Z ∞
0
ut sin(kx) dx.
(11.8.28)
Next, we integrate by parts. For example,
Z ∞
0
uxx sin(kx) dx = ux sin(kx)

∞
0
−k
Z ∞
0
ux cos(kx) dx
(11.8.29)
= −k
Z ∞
0
ux cos(kx) dx
(11.8.30)
= −ku(x, t) cos(kx)

∞
0
−k2
Z ∞
0
u(x, t) sin(kx) dx
(11.8.31)
= kf(t) −k2U(k, t),
(11.8.32)
where
U(k, t) =
Z ∞
0
u(x, t) sin(kx) dx,
(11.8.33)
and the boundary conditions have been used to simplify Equation 11.8.29 and Equation
11.8.31. Equation 11.8.33 is the deﬁnition of the Fourier sine transform. It and its math-
ematical cousin, the Fourier cosine transform
R ∞
0
u(x, t) cos(kx) dx, are analogous to the
half-range sine and cosine expansions that appear in solving the heat equation over the
ﬁnite interval (0, L). The diﬀerence here is that our range runs from 0 to ∞.
Applying the same technique to the other terms, we obtain
α[kf ′(t) −k2U ′(k, t)] + a2[kf(t) −k2U(k, t)] = U ′(k, t)
(11.8.34)
with U(k, 0) = 0, where the primes denote diﬀerentiation with respect to time. Solving
Equation 11.8.34,
ea2k2t/(1+αk2)U(k, t) =
αk
1 + αk2
Z t
0
f ′(τ)ea2k2τ/(1+αk2)dτ +
a2k
1 + αk2
Z t
0
f(τ)ea2k2τ/(1+αk2)dτ.
(11.8.35)
21 See Fetec˘au, C., and J. Zierep, 2001: On a class of exact solutions of the equations of motion of a
second grade ﬂuid. Acta Mech., 150, 135–138.

556
Advanced Engineering Mathematics with MATLAB
Using integration by parts on the second integral in Equation 11.8.35, we ﬁnd that
U(k, t) = 1
k

f(t) −f(0)e−a2k2t/(1+αk2) −
1
1 + αk2
Z t
0
f ′(τ)e−a2k2(t−τ)/(1+αk2) dτ

.
(11.8.36)
Because
u(x, t) = 2
π
Z ∞
0
U(k, t) sin(kx) dk,
(11.8.37)
u(x, t) = 2
π f(t)
Z ∞
0
sin(kx)
k
dk
−2
π
Z ∞
0
sin(kx)
k
e−a2k2t/(1+αk2) dk

f(0) +
1
1 + αk2
Z t
0
f ′(τ)ea2k2τ/(1+αk2) dτ

(11.8.38)
= f(t) −2
π
Z ∞
0
sin(kx)
k
e−a2k2t/(1+αk2)dk

f(0) +
1
1 + αk2
Z t
0
f ′(τ)ea2k2τ/(1+αk2)dτ

.
(11.8.39)
Problems
For Problems 1–4, ﬁnd the solution of the heat equation
∂u
∂t = a2 ∂2u
∂x2 ,
−∞< x < ∞,
0 < t,
subject to the stated initial conditions.
1. u(x, 0) =

1,
|x| < b,
0,
|x| > b.
3. u(x, 0) =
( 0,
−∞< x < 0,
T0,
0 < x < b,
0,
b < x < ∞.
2. u(x, 0) = e−b|x|
4. u(x, 0) = δ(x)
Lovering22 has applied the solution to Problem 1 to cases involving the cooling of lava.
5. Solve the spherically symmetric equation of diﬀusion,23
∂u
∂t = a2
∂2u
∂r2 + 2
r
∂u
∂r

,
0 ≤r < ∞,
0 < t,
22 Lovering, T. S., 1935: Theory of heat conduction applied to geological problems. Bull. Geol. Soc.
Am., 46, 69–94.
23 See Shklovskii, I. S., and V. G. Kurt, 1960: Determination of atmospheric density at a height of 430
km by means of the diﬀusion of sodium vapors. Am. Rocket Soc. J., 30, 662–667.

The Fourier Transform
557
with u(r, 0) = u0(r).
Step 1: Assuming v(r, t) = r u(r, t), show that the problem can be recast as
∂v
∂t = a2 ∂2v
∂r2 ,
0 ≤r < ∞,
0 < t,
with v(r, 0) = r u0(r).
Step 2: Using Equation 11.8.14, show that the general solution is
u(r, t) =
1
2ar
√
πt
Z ∞
0
u0(ρ)

exp

−(r −ρ)2
4a2t

−exp

−(r + ρ)2
4a2t

ρ dρ.
Hint: What is the constraint on Equation 11.8.14 so that the solution remains radially
symmetric?
Step 3: For the initial concentration of
u0(r) =

N0,
0 ≤r < r0,
0,
r0 < r,
show that
u(r, t) = 1
2N0

erf
r0 −r
2a
√
t

+erf
r0 + r
2a
√
t

+ 2a
√
t
r√π

exp

−(r0 + r)2
4a2t

−exp

−(r0 −r)2
4a2t

,
where erf(·) is the error function.
Further Readings
Bracewell, R. N., 2000: The Fourier Transform and Its Applications. McGraw -Hill Book
Co., 616 pp. This book presents the theory as well as a wealth of applications.
K¨orner, T. W., 1988: Fourier Analyis.
Cambridge University Press, 591 pp.
Presents
several interesting applications.
Sneddon, I. N., 1995: Fourier Transforms. Dover, 542 pp. A wonderful book that illustrates
the use of Fourier and Bessel transforms in solving a wealth of problems taken from the
sciences and engineering.
Titchmarch, E. C., 1948: Introduction to the Theory of Fourier Integrals. Oxford University
Press, 391. A source book on the theory of Fourier integrals until 1950.

Chapter 12
The Laplace Transform
The previous chapter introduced the concept of the Fourier integral. If the function is
nonzero only when t > 0, a similar transform, the Laplace transform,1 exists. It is particu-
larly useful in solving initial-value problems involving linear, constant coeﬃcient, ordinary,
and partial diﬀerential equations. The present chapter develops the general properties and
techniques of Laplace transforms.
12.1 DEFINITION AND ELEMENTARY PROPERTIES
Consider a function f(t) such that f(t) = 0 for t < 0. Then the Laplace integral:
L[f(t)] = F(s) =
Z ∞
0
f(t)e−st dt
(12.1.1)
deﬁnes the Laplace transform of f(t), which we shall write L[f(t)] or F(s). The Laplace
transform converts a function of t into a function of the transform variable s.
Not all functions have a Laplace transform because the integral, Equation 12.1.1, may
fail to exist. For example, the function may have inﬁnite discontinuities. For this reason,
f(t) = tan(t) does not have a Laplace transform. We can avoid this diﬃculty by requiring
that f(t) be piece-wise continuous. That is, we can divide a ﬁnite range into a ﬁnite number
of intervals in such a manner that f(t) is continuous inside each interval and approaches
ﬁnite values as we approach either end of any interval from the interior.
1 The standard reference for Laplace transforms is Doetsch, G., 1950: Handbuch der Laplace-Trans-
formation. Band 1. Theorie der Laplace-Transformation. Birkh¨auser Verlag, 581 pp.; Doetsch, G., 1955:
Handbuch der Laplace-Transformation. Band 2. Anwendungen der Laplace-Transformation. 1. Abteilung.
Birkh¨auser Verlag, 433 pp.; Doetsch, G., 1956: Handbuch der Laplace-Transformation. Band 3. Anwen-
dungen der Laplace-Transformation. 2. Abteilung. Birkh¨auser Verlag, 298 pp.
559

560
Advanced Engineering Mathematics with MATLAB
Another unacceptable function is f(t) = 1/t because the integral Equation 12.1.1 fails
to exist. This leads to the requirement that the product tn|f(t)| is bounded near t = 0 for
some number n < 1.
Finally, |f(t)| cannot grow too rapidly or it could overwhelm the e−st term. To express
this, we introduce the concept of functions of exponential order. By exponential order we
mean that there exist some constants, M and k, for which |f(t)| ≤Mekt for all t > 0.
Then, the Laplace transform of f(t) exists if s, or just the real part of s, is greater than k.
In summary, the Laplace transform of f(t) exists, for suﬃciently large s, provided f(t)
satisﬁes the following conditions:
• f(t) = 0 for t < 0,
• f(t) is continuous or piece-wise continuous in every interval,
• tn|f(t)| < ∞as t →0 for some number n, where n < 1,
• e−s0t|f(t)| < ∞as t →∞, for some number s0. The quantity s0 is called the abscissa
of convergence.
• Example 12.1.1
Let us ﬁnd the Laplace transform of 1, eat, sin(at), cos(at), and tn from the deﬁnition
of the Laplace transform. From Equation 12.1.1, direct integration yields
L(1) =
Z ∞
0
e−stdt = −e−st
s

∞
0
= 1
s,
s > 0,
(12.1.2)
L(eat) =
Z ∞
0
eate−stdt =
Z ∞
0
e−(s−a)tdt
(12.1.3)
= −e−(s−a)t
s −a

∞
0
=
1
s −a,
s > a,
(12.1.4)
L[sin(at)] =
Z ∞
0
sin(at)e−stdt = −
e−st
s2 + a2 [s sin(at) + a cos(at)]

∞
0
(12.1.5)
=
a
s2 + a2 ,
s > 0,
(12.1.6)
L[cos(at)] =
Z ∞
0
cos(at)e−stdt =
e−st
s2 + a2 [−s cos(at) + a sin(at)]

∞
0
(12.1.7)
=
s
s2 + a2 ,
s > 0,
(12.1.8)
and
L(tn) =
Z ∞
0
tne−stdt = n!e−st
n
X
m=0
tn−m
(n −m)!sm+1

∞
0
=
n!
sn+1 ,
s > 0,
(12.1.9)
where n is a positive integer.
MATLAB provides the routine laplace to compute the Laplace transform for a given
function. For example,

The Laplace Transform
561
>> syms a n s t
>> laplace(1,t,s)
ans =
1/s
>> laplace(exp(a*t),t,s)
ans =
1/(s-a)
>> laplace(sin(a*t),t,s)
ans =
a/(s^2+a^2)
>> laplace(cos(a*t),t,s)
ans =
s/(s^2+a^2)
>> laplace(t^5,t,s)
ans =
120/s^6
⊓⊔
The Laplace transform inherits two important properties from its integral deﬁnition.
First, the transform of a sum equals the sum of the transforms, or
L[c1f(t) + c2g(t)] = c1L[f(t)] + c2L[g(t)].
(12.1.10)
This linearity property holds with complex numbers and functions as well.
• Example 12.1.2
Success with Laplace transforms often rests with the ability to manipulate a given
transform into a form that you can invert by inspection. Consider the following examples.
Given F(s) = 4/s3, then
F(s) = 2 × 2
s3 ,
and
f(t) = 2t2
(12.1.11)
from Equation 12.1.9.
Given
F(s) = s + 2
s2 + 1 =
s
s2 + 1 +
2
s2 + 1,
(12.1.12)
then
f(t) = cos(t) + 2 sin(t)
(12.1.13)
by Equation 12.1.6, Equation 12.1.8, and Equation 12.1.10.
Because
F(s) =
1
s(s −1) =
1
s −1 −1
s
(12.1.14)
by partial fractions, then
f(t) = et −1
(12.1.15)

562
Advanced Engineering Mathematics with MATLAB
by Equation 12.1.2, Equation 12.1.4, and Equation 12.1.10.
MATLAB also provides the routine ilaplace to compute the inverse Laplace transform
for a given function. For example,
>> syms s t
>> ilaplace(4/s^3,s,t)
ans =
2*t^2
>> ilaplace((s+2)/(s^2+1),s,t)
ans =
cos(t)+2*sin(t)
>> ilaplace(1/(s*(s-1)),s,t)
ans =
-1+exp(t)
⊓⊔
The second important property deals with derivatives. Suppose f(t) is continuous and
has a piece-wise continuous derivative f ′(t). Then
L[f ′(t)] =
Z ∞
0
f ′(t)e−stdt = e−stf(t)
∞
0 + s
Z ∞
0
f(t)e−stdt
(12.1.16)
by integration by parts. If f(t) is of exponential order, e−stf(t) tends to zero as t →∞, for
large enough s, so that L[f ′(t)] = sF(s) −f(0). Similarly, if f(t) and f ′(t) are continuous,
f ′′(t) is piece-wise continuous, and all three functions are of exponential order, then
L[f ′′(t)] = sL[f ′(t)] −f ′(0) = s2F(s) −sf(0) −f ′(0).
(12.1.17)
In general,
L[f (n)(t)] = snF(s) −sn−1f(0) −· · · −sf (n−2)(0) −f (n−1)(0)
(12.1.18)
on the assumption that f(t) and its ﬁrst n−1 derivatives are continuous, f (n)(t) is piece-wise
continuous, and all are of exponential order so that the Laplace transform exists.
The converse of Equation 12.1.18 is also of some importance. If
u(t) =
Z t
0
f(τ) dτ,
(12.1.19)
then
L[u(t)] =
Z ∞
0
e−st
Z t
0
f(τ) dτ

dt = −e−st
s
Z t
0
f(τ) dτ

∞
0
+ 1
s
Z ∞
0
f(t)e−stdt,
(12.1.20)
and
L
Z t
0
f(τ) dτ

= F(s)/s,
(12.1.21)

The Laplace Transform
563
where u(0) = 0.
Problems
Using the deﬁnition of the Laplace transform, ﬁnd the Laplace transform of the following
functions. For Problems 1–4, check your answers using MATLAB.
1. f(t) = cosh(at)
2. f(t) = cos2(at)
3. f(t) = (t + 1)2
4. f(t) = (t + 1)e−at
5. f(t) =

et,
0 < t < 2
0,
2 < t
6. f(t) =

sin(t),
0 ≤t ≤π
0,
π ≤t
Using your knowledge of the transform for 1, eat, sin(at), cos(at), and tn, ﬁnd the Laplace
transform of
7. f(t) = 2 sin(t) −cos(2t) + cos(3) −t
8. f(t) = t −2 + e−5t −sin(5t) + cos(2).
Find the inverse of the following transforms. Verify your result using MATLAB.
9. F(s) = 1/(s + 3)
10. F(s) = 1/s4
11. F(s) = 1/(s2 + 9)
12. F(s) = (2s + 3)/(s2 + 9)
13. F(s) = 2/(s2 + 1) −15/s3 + 2/(s + 1) −6s/(s2 + 4)
14. F(s) = 3/s + 15/s3 + (s + 5)/(s2 + 1) −6/(s −2).
15. Verify the derivative rule for Laplace transforms using the function f(t) = sin(at).
16. Show that L[f(at)] = F (s/a) /a, where F(s) = L[f(t)].
17. Using the trigonometric identity sin2(x) = [1 −cos(2x)]/2, ﬁnd the Laplace transform
of f(t) = sin2[πt/(2T)].
12.2 THE HEAVISIDE STEP AND DIRAC DELTA FUNCTIONS
Change can occur abruptly. We throw a switch and electricity suddenly ﬂows. In this
section we introduce two functions, the Heaviside step and Dirac delta, that will give us the
ability to construct complicated discontinuous functions to express these changes.
Heaviside step function
We deﬁne the Heaviside step function as
H(t −a) =
 1,
t > a,
0,
t < a,
(12.2.1)

564
Advanced Engineering Mathematics with MATLAB
Largely a self-educated man, Oliver Heaviside (1850–1925) lived the life of a recluse. It was during
his studies of the implications of Maxwell’s theory of electricity and magnetism that he re-invented
Laplace transforms.
Initially rejected, it would require the work of Bromwich to justify its use.
(Portrait courtesy of the Institution of Engineering and Technology Archives.)
where a ≥0. From this deﬁnition,
L[H(t −a)] =
Z ∞
a
e−stdt = e−as
s
,
s > 0.
(12.2.2)
Note that this transform is identical to that for f(t) = 1 if a = 0. This should not surprise
us.
As pointed out earlier, the function f(t) is zero for all t < 0 by deﬁnition.
Thus,
when dealing with Laplace transforms, f(t) = 1 and H(t) are identical. Generally we will
take 1 rather than H(t) as the inverse of 1/s.
The Heaviside step function is essentially a
bookkeeping device that gives us the ability to “switch on” and “switch oﬀ” a given function.
For example, if we want a function f(t) to become nonzero at time t = a, we represent this
process by the product f(t)H(t −a). On the other hand, if we only want the function to
be “turned on” when a < t < b, the desired expression is then f(t)[H(t −a) −H(t −b)].
For t < a, both step functions in the brackets have the value of zero. For a < t < b, the
ﬁrst step function has the value of unity and the second step function has the value of zero,
so that we have f(t). For t > b, both step functions equal unity so that their diﬀerence is
zero.
• Example 12.2.1
Quite often we need to express the graphical representation of a function by a math-
ematical equation.
We can conveniently do this through the use of step functions in a
two-step procedure. The following example illustrates this procedure.

The Laplace Transform
565
3-t
1
3
4
2
1
t
f(t)
t
Figure 12.2.1: Graphical representation of Equation 12.2.5.
Consider Figure 12.2.1.
We would like to express this graph in terms of Heaviside
step functions. We begin by introducing step functions at each point where there is a kink
(discontinuity in the ﬁrst derivative) or jump in the graph - in the present case at t = 0,
t = 1, t = 2, and t = 3. These are the points of abrupt change. Thus,
f(t) = a0(t)H(t) + a1(t)H(t −1) + a2(t)H(t −2) + a3(t)H(t −3),
(12.2.3)
where the coeﬃcients a0(t), a1(t), . . . are yet to be determined. Proceeding from left to right
in Figure 12.2.1, the coeﬃcient of each step function equals the mathematical expression
that we want after the kink or jump minus the expression before the kink or jump. As
each Heaviside turns on, we need to add in the new t behavior and subtract out the old t
behavior. Thus, in the present example,
f(t) = (t −0)H(t) + (1 −t)H(t −1) + [(3 −t) −1]H(t −2) + [0 −(3 −t)]H(t −3) (12.2.4)
or
f(t) = tH(t) −(t −1)H(t −1) −(t −2)H(t −2) + (t −3)H(t −3).
(12.2.5)
We can easily ﬁnd the Laplace transform of Equation 12.2.5 by the “second shifting” theorem
introduced in the next section.
⊓⊔
• Example 12.2.2
Laplace transforms are particularly useful in solving initial-value problems involving
linear, constant coeﬃcient, ordinary diﬀerential equations where the nonhomogeneous term
is discontinuous. As we shall show in the next section, we must ﬁrst rewrite the nonhomo-
geneous term using the Heaviside step function before we can use Laplace transforms. For
example, given the nonhomogeneous ordinary diﬀerential equation:
y′′ + 3y′ + 2y =
 t,
0 < t < 1
0,
1 < t,
(12.2.6)
we can rewrite the right side of Equation 12.2.6 as
y′′ + 3y′ + 2y = t −tH(t −1) = t −(t −1)H(t −1) −H(t −1).
(12.2.7)
In Section 12.8 we will show how to solve this type of ordinary diﬀerential equation using
Laplace transforms.
⊓⊔

566
Advanced Engineering Mathematics with MATLAB
The Laplace Transforms of Some Commonly Encountered Functions
f(t), t ≥0
F(s)
1.
1
1
s
2.
e−at
1
s + a
3.
1
a (1 −e−at)
1
s(s + a)
4.
1
a−b(e−bt −e−at)
1
(s + a)(s + b)
5.
1
b−a(be−bt −ae−at)
s
(s + a)(s + b)
6.
sin(at)
a
s2 + a2
7.
cos(at)
s
s2 + a2
8.
sinh(at)
a
s2 −a2
9.
cosh(at)
s
s2 −a2
10.
t sin(at)
2as
(s2 + a2)2
11.
1 −cos(at)
a2
s(s2 + a2)
12.
at −sin(at)
a3
s2(s2 + a2)
13.
t cos(at)
s2 −a2
(s2 + a2)2
14.
sin(at) −at cos(at)
2a3
(s2 + a2)2
15.
t sinh(at)
2as
(s2 −a2)2
16.
t cosh(at)
s2 + a2
(s2 −a2)2
17.
at cosh(at) −sinh(at)
2a3
(s2 −a2)2
18.
e−bt sin(at)
a
(s + b)2 + a2
19.
e−bt cos(at)
s + b
(s + b)2 + a2
20.
(1 + a2t2) sin(at) −at cos(at)
8a3s2
(s2 + a2)3

The Laplace Transform
567
The Laplace Transforms of Some Commonly Encountered Functions (Continued)
f(t), t ≥0
F(s)
21.
sin(at) cosh(at) −cos(at) sinh(at)
4a3
s4 + 4a4
22.
sin(at) sinh(at)
2a2s
s4 + 4a4
23.
sinh(at) −sin(at)
2a3
s4 −a4
24.
cosh(at) −cos(at)
2a2s
s4 −a4
25.
a sin(at) −b sin(bt)
a2 −b2
, a2 ̸= b2
s2
(s2 + a2)(s2 + b2)
26.
b sin(at) −a sin(bt)
ab(b2 −a2)
, a2 ̸= b2
1
(s2 + a2)(s2 + b2)
27.
cos(at) −cos(bt)
b2 −a2
, a2 ̸= b2
s
(s2 + a2)(s2 + b2)
28.
tn, n ≥0
n!
sn+1
29.
tn−1e−at
(n −1)! , n > 0
1
(s + a)n
30.
(n −1) −at
(n −1)!
tn−2e−at, n > 1
s
(s + a)n
31.
tne−at, n ≥0
n!
(s + a)n+1
32.
2ntn−(1/2)
1 · 3 · 5 · · · (2n −1)√π , n ≥1
s−[n+(1/2)]
33.
J0(at)
1
√
s2 + a2
34.
I0(at)
1
√
s2 −a2
35.
1
√a erf(
√
at )
1
s√s + a
36.
1
√
πte−at + √a erf(
√
at )
√s + a
s
37.
1
√
πt −aea2terfc(a
√
t )
1
a + √s
38.
eaterfc(
√
at )
1
s + √as
39.
1
2
√
πt3
 ebt −eat
√s −a −
√
s −b

568
Advanced Engineering Mathematics with MATLAB
The Laplace Transforms of Some Commonly Encountered Functions (Continued)
f(t), t ≥0
F(s)
40.
1
√
πt + aea2terf(a
√
t )
√s
s −a2
41.
1
√
πteat(1 + 2at)
s
(s −a)√s −a
42.
1
aea2terf(a
√
t )
1
(s −a2)√s
43.
r a
πt3 e−a/t, a > 0
e−2√as
44.
1
√
πte−a/t, a ≥0
1
√se−2√as
45.
erfc
ra
t

, a ≥0
1
se−2√as
46.
2
r
t
π exp

−a2
4t

−a erfc
 a
2
√
t

, a ≥0
e−a√s
s √s
47.
−eb2t+aberfc

b
√
t +
a
2
√
t

+ erfc

a
2
√
t

, a ≥0
be−a√s
s(b + √s )
48.
eabeb2terfc

b
√
t +
a
2
√
t

, a ≥0
e−a√s
√s (b + √s )
Notes:
Error function: erf(x) =
2
√π
Z x
0
e−y2 dy
Complementary error function: erfc(x) = 1 −erf(x)
Dirac delta function
The second special function is the Dirac delta function or impulse function. We deﬁne
it by
δ(t −a) =
 ∞,
t = a,
0,
t ̸= a,
Z ∞
0
δ(t −a) dt = 1,
(12.2.8)
where a ≥0.
A popular way of visualizing the delta function is as a very narrow rectangular pulse:
δ(t −a) = lim
ǫ→0

1/ǫ,
0 < |t −a| < ǫ/2,
0,
|t −a| > ǫ/2,
(12.2.9)
where ǫ > 0 is some small number and a > 0. See Figure 12.2.2. This pulse has a width
ǫ, height 1/ǫ, and its center at t = a so that its area is unity. Now, as this pulse shrinks
in width (ǫ →0), its height increases so that it remains centered at t = a and its area
equals unity.
If we continue this process, always keeping the area unity and the pulse

The Laplace Transform
569
t = a
ε
t
1/
δ(t)
ε
Figure 12.2.2: The Dirac delta function.
symmetric about t = a, eventually we obtain an extremely narrow, very large amplitude
pulse at t = a. If we proceed to the limit, where the width approaches zero and the height
approaches inﬁnity (but still with unit area), we obtain the delta function δ(t −a).
The delta function was introduced earlier during our study of Fourier transforms. So
what is the diﬀerence between the delta function introduced then and the delta function
now? Simply put, the delta function can now only be used on the interval [0, ∞). Outside
of that, we shall use it very much as we did with Fourier transforms.
Using Equation 12.2.9, the Laplace transform of the delta function is
L[δ(t −a)] =
Z ∞
0
δ(t −a)e−stdt = lim
ǫ→0
1
ǫ
Z a+ǫ/2
a−ǫ/2
e−stdt
(12.2.10)
= lim
ǫ→0
1
ǫs

e−as+ǫs/2 −e−as−ǫs/2

(12.2.11)
= lim
ǫ→0
e−as
ǫs

1 + ǫs
2 + ǫ2s2
8
+ · · · −1 + ǫs
2 −ǫ2s2
8
+ · · ·

(12.2.12)
= e−as.
(12.2.13)
In the special case when a = 0, L[δ(t)] = 1, a property that we will use in Section 12.9.
Note that this is exactly the result that we obtained for the Fourier transform of the delta
function.
If we integrate the impulse function,
Z t
0
δ(τ −a) dτ =
 0,
t < a,
1,
t > a,
(12.2.14)
according to whether the impulse does or does not come within the range of integration.
This integral gives a result that is precisely the deﬁnition of the Heaviside step function, so
that we can rewrite Equation 12.2.14:
Z t
0
δ(τ −a) dτ = H(t −a).
(12.2.15)

570
Advanced Engineering Mathematics with MATLAB
Consequently, the delta function behaves like the derivative of the step function, or
d
dt

H(t −a)

= δ(t −a).
(12.2.16)
Because the conventional derivative does not exist at a point of discontinuity, we can only
make sense of Equation 12.2.16 if we extend the deﬁnition of the derivative.
Here we
extended the deﬁnition formally, but a richer and deeper understanding arises from the
theory of generalized functions.2
• Example 12.2.3
Let us ﬁnd the (generalized) derivative of
f(t) = 3t2 [H(t) −H(t −1)] .
(12.2.17)
Proceeding formally,
f ′(t) = 6t [H(t) −H(t −1)] + 3t2 [δ(t) −δ(t −1)]
(12.2.18)
= 6t [H(t) −H(t −1)] + 0 −3δ(t −1)
(12.2.19)
= 6t [H(t) −H(t −1)] −3δ(t −1),
(12.2.20)
because f(t)δ(t −t0) = f(t0)δ(t −t0).
⊓⊔
• Example 12.2.4
MATLAB also includes the step and Dirac delta functions among its intrinsic functions.
There are two types of step functions. In symbolic calculations, the function is Heaviside
while stepfunction is used in numerical calculations. For example, the Laplace transform
of Equation 12.2.5 is
>>syms s,t
>>laplace(’t-(t-1)*Heaviside(t-1)-(t-2)*Heaviside(t-2)’...
’+(t-3)*Heaviside(t-3)’,t,s)
ans =
1/s^2-exp(-s)/s^2-exp(-2*s)/s^2+exp(-3*s)/s^2
In a similar manner, the symbolic function for the Dirac delta function is Dirac. There-
fore, the Laplace transform of (t −1)δ(t −2) is
>>syms s,t
>>laplace(’(t-1)*Dirac(t-2)’,t,s)
ans =
exp(-2*s)
2 The generalization of the deﬁnition of a function so that it can express in a mathematically correct
form such idealized concepts as the density of a material point, a point charge or point dipole, the space
charge of a simple or double layer, the intensity of an instantaneous source, etc.

The Laplace Transform
571
Problems
Sketch the following functions and express them in terms of the Heaviside step functions:
1. f(t) =
(
0,
0 ≤t ≤2
t −2,
2 ≤t < 3
0,
3 < t
2. f(t) =





0,
0 < t < a
1,
a < t < 2a
−1,
2a < t < 3a
0,
3a < t
Rewrite the following nonhomogeneous ordinary diﬀerential equations using the Heaviside
step functions:
3. y′′ + 3y′ + 2y =
 0,
0 < t < 1
1,
1 < t
5. y′′ + 4y′ + 4y =
 0,
0 < t < 2
t,
2 < t
7. y′′ −3y′ + 2y =
 0,
0 < t < 2
e−t,
2 < t
9. y′′ + y =

sin(t),
0 ≤t ≤π
0,
π ≤t
4. y′′ + 4y =
 0,
0 < t < 4
3,
4 < t
6. y′′ + 3y′ + 2y =
 0,
0 < t < 1
et,
1 < t
8. y′′ −3y′ + 2y =
 0,
0 < t < 1
t2,
1 < t
10. y′′ + 3y′ + 2y =

t,
0 ≤t ≤a
ae−(t−a),
a ≤t
12.3 SOME USEFUL THEOREMS
Although at ﬁrst sight there would appear to be a bewildering number of transforms
to either memorize or tabulate, there are several useful theorems, that can extend the
applicability of a given transform.
First shifting theorem
Consider the transform of the function e−atf(t), where a is any real number. Then, by
deﬁnition,
L

e−atf(t)

=
Z ∞
0
e−ste−atf(t) dt =
Z ∞
0
e−(s+a)tf(t) dt,
(12.3.1)
or
L

e−atf(t)

= F(s + a).
(12.3.2)
That is, if F(s) is the transform of f(t) and a is a constant, then F(s + a) is the transform
of e−atf(t).
• Example 12.3.1
Let us ﬁnd the Laplace transform of f(t) = e−at sin(bt). Because the Laplace transform
of sin(bt) is b/(s2 + b2),
L

e−at sin(bt)

=
b
(s + a)2 + b2 ,
(12.3.3)

572
Advanced Engineering Mathematics with MATLAB
where we simply replaced s by s + a in the transform for sin(bt).
⊓⊔
• Example 12.3.2
Let us ﬁnd the inverse of the Laplace transform
F(s) =
s + 2
s2 + 6s + 1.
(12.3.4)
Rearranging terms,
F(s) =
s + 2
s2 + 6s + 1 =
s + 2
(s + 3)2 −8 =
s + 3
(s + 3)2 −8 −
1
2
√
2
2
√
2
(s + 3)2 −8.
(12.3.5)
Immediately, from the ﬁrst shifting theorem,
f(t) = e−3t cosh(2
√
2t) −e−3t
2
√
2 sinh(2
√
2t).
(12.3.6)
⊓⊔
Second shifting theorem
The second shifting theorem states that if F(s) is the transform of f(t), then e−bsF(s)
is the transform of f(t −b)H(t −b), where b is real and positive. To show this, consider the
Laplace transform of f(t −b)H(t −b). Then, from the deﬁnition,
L[f(t −b)H(t −b)] =
Z ∞
0
f(t −b)H(t −b)e−st dt
(12.3.7)
=
Z ∞
b
f(t −b)e−st dt =
Z ∞
0
e−bse−sxf(x) dx
(12.3.8)
= e−bs
Z ∞
0
e−sxf(x) dx,
(12.3.9)
or
L[f(t −b)H(t −b)] = e−bsF(s),
(12.3.10)
where we set x = t −b. This theorem is of fundamental importance because it allows us to
write down the transforms for “delayed” time functions. That is, functions that “turn on”
b units after the initial time.
• Example 12.3.3
Let us ﬁnd the inverse of the transform (1 −e−s)/s. Since
1 −e−s
s
= 1
s −e−s
s ,
(12.3.11)
L−1
1
s −e−s
s

= L−1
1
s

−L−1
e−s
s

= H(t) −H(t −1),
(12.3.12)
because L−1(1/s) = f(t) = 1, and f(t −1) = 1.
⊓⊔

The Laplace Transform
573
• Example 12.3.4
Let us ﬁnd the Laplace transform of f(t) = (t2 −1)H(t −1).
We begin by noting that
(t2 −1)H(t −1) = [(t −1 + 1)2 −1]H(t −1)
(12.3.13)
= [(t −1)2 + 2(t −1)]H(t −1)
(12.3.14)
= (t −1)2H(t −1) + 2(t −1)H(t −1).
(12.3.15)
A direct application of the second shifting theorem then leads to
L[(t2 −1)H(t −1)] = 2e−s
s3
+ 2e−s
s2 .
(12.3.16)
⊓⊔
• Example 12.3.5
In Example 12.2.2 we discussed the use of Laplace transforms in solving ordinary
diﬀerential equations. One further step along the road consists of ﬁnding Y (s) = L[y(t)].
Now that we have the second shifting theorem, let us do this.
Continuing Example 12.2.2 with y(0) = 0 and y′(0) = 1, let us take the Laplace
transform of Equation 12.2.7. Employing the second shifting theorem and Equation 12.1.18,
we ﬁnd that
s2Y (s) −sy(0) −y′(0) + 3sY (s) −3y(0) + 2Y (s) = 1
s2 −e−s
s2 −e−s
s .
(12.3.17)
Substituting in the initial conditions and solving for Y (s), we ﬁnally obtain
Y (s) =
1
(s + 2)(s + 1) +
1
s2(s + 2)(s + 1) +
e−s
s2(s + 2)(s + 1) +
e−s
s(s + 2)(s + 1). (12.3.18)
⊓⊔
Laplace transform of tnf(t)
In addition to the shifting theorems, there are two other particularly useful theorems
that involve the derivative and integral of the transform F(s). For example, if we write
F(s) = L[f(t)] =
Z ∞
0
f(t)e−stdt
(12.3.19)
and diﬀerentiate with respect to s, then
F ′(s) =
Z ∞
0
−tf(t)e−stdt = −L[tf(t)].
(12.3.20)
In general, we have that
F (n)(s) = (−1)nL[tnf(t)].
(12.3.21)

574
Advanced Engineering Mathematics with MATLAB
Laplace transform of f(t)/t
Consider the following integration of the Laplace transform F(s):
Z ∞
s
F(z) dz =
Z ∞
s
Z ∞
0
f(t)e−ztdt

dz.
(12.3.22)
Upon interchanging the order of integration, we ﬁnd that
Z ∞
s
F(z) dz =
Z ∞
0
f(t)
Z ∞
s
e−ztdz

dt = −
Z ∞
0
f(t) e−zt
t

∞
s
dt =
Z ∞
0
f(t)
t
e−stdt.
(12.3.23)
Therefore,
Z ∞
s
F(z) dz = L
f(t)
t

.
(12.3.24)
• Example 12.3.6
Let us ﬁnd the transform of t sin(at). From Equation 12.3.20,
L[t sin(at)] = −d
ds

L[sin(at)]

= −d
ds

a
s2 + a2

=
2as
(s2 + a2)2 .
(12.3.25)
⊓⊔
• Example 12.3.7
Let us ﬁnd the transform of [1 −cos(at)]/t. To solve this problem, we apply Equation
12.3.24 and ﬁnd that
L
1 −cos(at)
t

=
Z ∞
s
L[1 −cos(at)]

s=z
dz =
Z ∞
s
1
z −
z
z2 + a2

dz
(12.3.26)
= ln(z) −1
2 ln(z2 + a2)

∞
s
= ln

z
√
z2 + a2

∞
s
(12.3.27)
= ln(1) −ln

s
√
s2 + a2

= −ln

s
√
s2 + a2

.
(12.3.28)
⊓⊔
Initial-value theorem
Let f(t) and f ′(t) possess Laplace transforms. Then, from the deﬁnition of the Laplace
transform,
Z ∞
0
f ′(t)e−st dt = sF(s) −f(0).
(12.3.29)
Because s is a parameter in Equation 12.3.29 and the existence of the integral is implied
by the derivative rule, we can let s →∞before we integrate. In that case, the left side of
Equation 12.3.29 vanishes to zero, which leads to
lim
s→∞sF(s) = f(0).
(12.3.30)
This is the initial-value theorem.

The Laplace Transform
575
• Example 12.3.8
Let us verify the initial-value theorem using f(t) = e3t. Because F(s) = 1/(s −3),
lims→∞s/(s −3) = 1. This agrees with f(0) = 1.
In the common case when the Laplace transform is ratio to two polynomials, we can use
MATLAB to ﬁnd the initial value. This consists of two steps. First, we construct sF(s) by
creating vectors that describe the numerator and denominator of sF(s) and then evaluate
the numerator and denominator using very large values of s. For example, in the previous
example,
>>num = [1 0];
>>den = [1 -3];
>>initialvalue = polyval(num,1e20) / polyval(den,1e20)
initialvalue =
1
⊓⊔
Final-value theorem
Let f(t) and f ′(t) possess Laplace transforms. Then, in the limit of s →0, Equation
12.3.29 becomes
Z ∞
0
f ′(t) dt = lim
t→∞
Z t
0
f ′(τ) dτ = lim
t→∞f(t) −f(0) = lim
s→0 sF(s) −f(0).
(12.3.31)
Because f(0) is not a function of t or s, the quantity f(0) cancels from Equation 12.3.31,
leaving
lim
t→∞f(t) = lim
s→0 sF(s).
(12.3.32)
Equation 12.3.32 is the ﬁnal-value theorem. It should be noted that this theorem assumes
that limt→∞f(t) exists. For example, it does not apply to sinusoidal functions. Thus, we
must restrict ourselves to Laplace transforms that have singularities in the left half of the
s-plane unless they occur at the origin.
In the case when f(t) is a periodic function with a period T, Gluskin3 showed that
lim
s→0 sF(s) = 1
T
Z T
0
f(t) dt.
(12.3.33)
• Example 12.3.9
Let us verify the ﬁnal-value theorem using f(t) = t. Because F(s) = 1/s2,
lim
s→0 sF(s) = lim
s→0 1/s = ∞.
(12.3.34)
The limit of f(t) as t →∞is also undeﬁned.
3 Gluskin, E., 2003: Let us teach this generalization of the ﬁnal-value theorem. Eur. J. Phys., 24,
591–597.

576
Advanced Engineering Mathematics with MATLAB
Just as we can use MATLAB to ﬁnd the initial value of a Laplace transform in the case
when F(s) is a ratio of two polynomials, we can do the same here for the ﬁnal value. Again
we deﬁne vectors num and den that give sF(s) and then evaluate them at s = 0. Using the
previous example, the MATLAB commands are:
>>num = [0 1 0];
>>den = [1 0 0];
>>finalvalue = polyval(num,0) / polyval(den,0)
Warning:
Divide by zero.
finalvalue =
NaN
This agrees with the result from a hand calculation and shows what happens when the
denominator has a zero.
⊓⊔
• Example 12.3.10
Looking ahead, we will shortly need to ﬁnd the Laplace transform of y(t), which is
deﬁned by a diﬀerential equation. For example, we will want Y (s) where y(t) is governed
by
y′′ + 2y′ + 2y = cos(t) + δ(t −π/2),
y(0) = y′(0) = 0.
(12.3.35)
Applying Laplace transforms to both sides of Equation 12.3.35, we have that
L(y′′) + 2L(y′) + 2L(y) = L[cos(t)] + L[δ(t −π/2)],
(12.3.36)
or
s2Y (s) −sy(0) −y′(0) + 2sY (s) −2y(0) + 2Y (s) =
s
s2 + 1 + e−sπ/2.
(12.3.37)
Substituting for y(0) and y′(0) and solving for Y (s), we ﬁnd that
Y (s) =
s
(s2 + 1)(s2 + 2s + 2) +
e−sπ/2
s2 + 2s + 2.
(12.3.38)
Presently this is as far as we can go.
How would we use MATLAB to ﬁnd Y (s)? The following MATLAB script shows you
how:
clear
% define symbolic variables
syms pi s t Y
% take Laplace transform of left side of differential equation
LHS = laplace(diff(diff(sym(’y(t)’)))+2*diff(sym(’y(t)’))...
+2*sym(’y(t)’));
% take Laplace transform of right side of differential equation
RHS = laplace(cos(t)+’Dirac(t-pi/2)’,t,s);
% set Y for Laplace transform of y
%
and introduce initial conditions
newLHS = subs(LHS,’laplace(y(t),t,s)’,’y(0)’,’D(y)(0)’,Y,0,0);
% solve for Y
Y = solve(newLHS-RHS,Y)
It yields

The Laplace Transform
577
Y =
(s+exp(-1/2*pi*s)*s^2+exp(-1/2*pi*s))/(s^4+3*s^2+2*s^3+2*s+2)
Problems
Find the Laplace transform of the following functions and then check your work using
MATLAB.
1. f(t) = e−t sin(2t)
2. f(t) = e−2t cos(2t)
3. f(t) = t2H(t −1)
4. f(t) = e2tH(t −3)
5. f(t) = tet + sin(3t)et + cos(5t)e2t
6. f(t) = t4e−2t + sin(3t)et + cos(4t)e2t
7. f(t) = t2e−t + sin(2t)et + cos(3t)e−3t
8. f(t) = t2H(t −1) + etH(t −2)
9. f(t) = (t2 + 2)H(t −1) + H(t −2)
10. f(t) = (t + 1)2H(t −1) + etH(t −2)
11. f(t) =

sin(t),
0 ≤t ≤π
0,
π ≤t
12. f(t) =
 t,
0 ≤t ≤2
2,
2 ≤t
13. f(t) = te−3t sin(2t)
Find the inverse of the following Laplace transforms by hand and using MATLAB:
14. F(s) =
1
(s + 2)4
15. F(s) =
s
(s + 2)4
16. F(s) =
s
s2 + 2s + 2
17. F(s) =
s + 3
s2 + 2s + 2
18. F(s) =
s
(s + 1)3 +
s + 1
s2 + 2s + 2
19. F(s) =
s
(s + 2)2 +
s + 2
s2 + 2s + 2
20. F(s) =
s
(s + 2)3 +
s + 4
s2 + 4s + 5
21. F(s) = e−3s
s −1
22. F(s) =
e−2s
(s + 1)2
23. F(s) =
s e−s
s2 + 2s + 2
24. F(s) =
e−4s
s2 + 4s + 5
25. F(s) = s e−s
s2 + 4 +
e−3s
(s −2)4
26. F(s) =
e−s
s2 + 4 + (s −1) e−3s
s4
27. F(s) = (s + 1) e−s
s2 + 4
+ e−3s
s4
28. Find the Laplace transform of f(t) = tet[H(t−1)−H(t−2)] by using (a) the deﬁnition of
the Laplace transform, and (b) a joint application of the ﬁrst and second shifting theorems.
29. Write the function
f(t) =
 t,
0 < t < a,
0,
a < t,
in terms of Heaviside’s step functions. Then ﬁnd its transform using (a) the deﬁnition of
the Laplace transform, and (b) the second shifting theorem.

578
Advanced Engineering Mathematics with MATLAB
In Problems 30–33, write the function f(t) in terms of the Heaviside step functions and then
ﬁnd its transform using the second shifting theorem. Check your answer using MATLAB.
30. f(t) =

t/2,
0 ≤t < 2
0,
2 < t
32. f(t) =
(
t,
0 ≤t ≤2
4 −t,
2 ≤t ≤4
0,
4 ≤t
31. f(t) =
( t,
0 ≤t ≤1
1,
1 ≤t < 2
0,
2 < t
33. f(t) =





0,
0 ≤t ≤1
t −1,
1 ≤t ≤2
1,
2 ≤t < 3
0,
3 < t
Find Y (s) for the following ordinary diﬀerential equations and then use MATLAB to check
your work.
34. y′′ + 3y′ + 2y = H(t −1);
y(0) = y′(0) = 0
35. y′′ + 4y = 3H(t −4);
y(0) = 1, y′(0) = 0
36. y′′ + 4y′ + 4y = tH(t −2);
y(0) = 0, y′(0) = 2
37. y′′ + 3y′ + 2y = etH(t −1);
y(0) = y′(0) = 0
38. y′′ −3y′ + 2y = e−tH(t −2);
y(0) = 2, y′(0) = 0
39. y′′ −3y′ + 2y = t2H(t −1);
y(0) = 0, y′(0) = 5
40. y′′ + y = sin(t)[1 −H(t −π)];
y(0) = y′(0) = 0
41. y′′ + 3y′ + 2y = t +

ae−(t−a) −t

H(t −a);
y(0) = y′(0) = 0.
For each of the following functions, ﬁnd its value at t = 0. Then check your answer using
the initial-value theorem by hand and using MATLAB.
42. f(t) = t
43. f(t) = cos(at)
44. f(t) = te−t
45. f(t) = et sin(3t)
For each of the following Laplace transforms, state whether you can or cannot apply the
ﬁnal-value theorem. If you can, ﬁnd the ﬁnal value by hand and using MATLAB. Check
your result by ﬁnding the inverse and ﬁnding the limit as t →∞.
46. F(s) =
1
s −1
47. F(s) = 1
s
48. F(s) =
1
s + 1
49. F(s) =
s
s2 + 1
50. F(s) =
2
s(s2 + 3s + 2)
51. F(s) =
2
s(s2 −3s + 2)

The Laplace Transform
579
52. Using the fact that
e−cξ = 1 −c
Z ξ
0
e−cη dη,
show4 that
1
s exp

−asx
s + b

= 1
s −
Z ax
0
e−η
s + b exp
 bη
s + b

dη
if x > 0. Therefore, using the fact5 that
L−1
s−ν−1eα/s
=
 t
α
ν/2
Iν

2
√
αt

,
ℜ(ν) > −1,
and the ﬁrst shifting theorem, show
L−1
1
s exp

−asx
s + b

= 1 −e−bt
Z ax
0
e−ηI0

2
p
2tη

dη,
where Iν(·) is a modiﬁed Bessel function of the ﬁrst kind and order ν introduced in Section
6.5.
12.4 THE LAPLACE TRANSFORM OF A PERIODIC FUNCTION
Periodic functions frequently occur in engineering problems and we shall now show how
to calculate their transform. They possess the property that f(t + T) = f(t) for t > 0 and
equal zero for t < 0, where T is the period of the function.
For convenience, let us deﬁne a function x(t) that equals zero except over the interval
(0, T) where it equals f(t):
x(t) =

f(t),
0 < t < T
0,
T < t.
(12.4.1)
By deﬁnition,
F(s) =
Z ∞
0
f(t)e−stdt =
Z T
0
f(t)e−stdt +
Z 2T
T
f(t)e−stdt + · · · +
Z (k+1)T
kT
f(t)e−stdt + · · · .
(12.4.2)
Now let z = t −kT, where k = 0, 1, 2, . . ., in the kth integral and F(s) becomes
F(s) =
Z T
0
f(z)e−sz dz +
Z T
0
f(z + T)e−s(z+T ) dz + · · · +
Z T
0
f(z + kT)e−s(z+kT ) dz + · · · .
(12.4.3)
However,
x(z) = f(z) = f(z + T) = . . . = f(z + kT) = . . . ,
(12.4.4)
because the range of integration in each integral is from 0 to T. Thus, F(s) becomes
F(s) =
Z T
0
x(z)e−sz dz +e−sT
Z T
0
x(z)e−sz dz +· · ·+e−ksT
Z T
0
x(z)e−sz dz +· · · (12.4.5)
4 Liaw, C. H., J. S. P. Wang, R. A. Greenkorn, and K. C. Chao, 1979: Kinetics of ﬁxed-bed absorption:
A new solution. AICHE J., 25, 376–381.
5 Watson, E. J., 1981: Laplace Transforms and Applications. Van Nostrand Reinhold Co., p. 195.

580
Advanced Engineering Mathematics with MATLAB
or
F(s) =
 1 + e−sT + e−2sT + · · · + e−ksT + · · ·

X(s).
(12.4.6)
The ﬁrst term on the right side of Equation 12.4.6 is a geometric series with common ratio
e−sT . If |e−sT | < 1, then the series converges and
F(s) =
X(s)
1 −e−sT .
(12.4.7)
• Example 12.4.1
Let us ﬁnd the Laplace transform of the square wave with period T:
f(t) =

h,
0 < t < T/2,
−h,
T/2 < t < T.
(12.4.8)
By deﬁnition x(t) is
x(t) =



h,
0 < t < T/2,
−h,
T/2 < t < T,
0,
T < t.
(12.4.9)
Then
X(s) =
Z ∞
0
x(t)e−st dt =
Z T/2
0
h e−st dt +
Z T
T/2
(−h) e−st dt
(12.4.10)
= h
s

1 −2e−sT/2 + e−sT 
= h
s

1 −e−sT/22
,
(12.4.11)
and
F(s) = h
 1 −e−sT/22
s (1 −e−sT )
= h
 1 −e−sT/2
s
 1 + e−sT/2 .
(12.4.12)
If we multiply numerator and denominator by exp(sT/4) and recall that tanh(u) = (eu −
e−u)/(eu + e−u), we have that
F(s) = h
s tanh
sT
4

.
(12.4.13)
⊓⊔
• Example 12.4.2
Let us ﬁnd the Laplace transform of the periodic function
f(t) =

sin(2πt/T),
0 ≤t ≤T/2,
0,
T/2 ≤t ≤T.
(12.4.14)
By deﬁnition x(t) is
x(t) =

sin(2πt/T),
0 ≤t ≤T/2,
0,
T/2 ≤t.
(12.4.15)

The Laplace Transform
581
Then
X(s) =
Z T/2
0
sin
2πt
T

e−st dt =
2πT
s2T 2 + 4π2

1 + e−sT/2
.
(12.4.16)
Hence,
F(s) =
X(s)
1 −e−sT =
2πT
s2T 2 + 4π2 × 1 + e−sT/2
1 −e−sT
=
2πT
s2T 2 + 4π2 ×
1
1 −e−sT/2 .
(12.4.17)
Problems
Find the Laplace transform for the following periodic functions:
1. f(t) = sin(t),
0 ≤t ≤π,
f(t) = f(t + π)
2. f(t) =

sin(t),
0 ≤t ≤π,
0,
π ≤t ≤2π,
f(t) = f(t + 2π)
3. f(t) =
 t,
0 ≤t < a,
0,
a < t ≤2a,
f(t) = f(t + 2a)
4. f(t) =





1,
0 < t < a,
0,
a < t < 2a,
−1,
2a < t < 3a,
0,
3a < t < 4a,
f(t) = f(t + 4a)
12.5 INVERSION BY PARTIAL FRACTIONS: HEAVISIDE’S EXPANSION THEOREM
In the previous sections, we devoted our eﬀorts to calculating the Laplace transform
of a given function. Obviously, we must have a method for going the other way. Given a
transform, we must ﬁnd the corresponding function. This is often a very formidable task.
In the next few sections we shall present some general techniques for the inversion of a
Laplace transform.
The ﬁrst technique involves transforms that we can express as the ratio of two poly-
nomials: F(s) = q(s)/p(s). We shall assume that the order of q(s) is less than p(s) and
we have divided out any common factor between them. In principle we know that p(s) has
n zeros, where n is the order of the p(s) polynomial. Some of the zeros may be complex,
some of them may be real, and some of them may be duplicates of other zeros. In the case
when p(s) has n simple zeros (nonrepeating roots), a simple method exists for inverting the
transform.
We want to rewrite F(s) in the form:
F(s) =
a1
s −s1
+
a2
s −s2
+ · · · +
an
s −sn
= q(s)
p(s),
(12.5.1)
where s1, s2, . . . , sn are the n simple zeros of p(s). We now multiply both sides of Equation
12.5.1 by s −s1 so that
(s −s1)q(s)
p(s)
= a1 + (s −s1)a2
s −s2
+ · · · + (s −s1)an
s −sn
.
(12.5.2)

582
Advanced Engineering Mathematics with MATLAB
If we set s = s1, the right side of Equation 12.5.2 becomes simply a1. The left side takes
the form 0/0 and there are two cases. If p(s) = (s −s1)g(s), then a1 = q(s1)/g(s1). If we
cannot explicitly factor out s −s1, l’Hˆopital’s rule gives
a1 = lim
s→s1
(s −s1)q(s)
p(s)
= lim
s→s1
(s −s1)q′(s) + q(s)
p′(s)
= q(s1)
p′(s1).
(12.5.3)
In a similar manner, we can compute all of the coeﬃcients ak, where k = 1, 2, . . . , n.
Therefore,
L−1[F(s)] = L−1
q(s)
p(s)

= L−1

a1
s −s1
+
a2
s −s2
+ · · · +
an
s −sn

(12.5.4)
= a1es1t + a2es2t + · · · + anesnt.
(12.5.5)
This is Heaviside’s expansion theorem, applicable when p(s) has only simple poles.
• Example 12.5.1
Let us invert the transform s/[(s + 2)(s2 + 1)]. It has three simple poles at s = −2 and
s = ±i. From our earlier discussion, q(s) = s, p(s) = (s+2)(s2+1), and p′(s) = 3s2+4s+1.
Therefore,
L−1

s
(s + 2)(s2 + 1)

=
−2
12 −8 + 1e−2t +
i
−3 + 4i + 1eit +
−i
−3 −4i + 1e−it
(12.5.6)
= −2
5e−2t +
i
−2 + 4ieit −
i
−2 −4ie−it
(12.5.7)
= −2
5e−2t + i−2 −4i
4 + 16 eit −i−2 + 4i
4 + 16 e−it
(12.5.8)
= −2
5e−2t + 1
5 sin(t) + 2
5 cos(t),
(12.5.9)
where we used sin(t) = 1
2i(eit −e−it), and cos(t) = 1
2(eit + e−it).
⊓⊔
• Example 12.5.2
Let us invert the transform 1/[(s −1)(s −2)(s −3)]. There are three simple poles at
s1 = 1, s2 = 2, and s3 = 3. In this case, the easiest method for computing a1, a2, and a3 is
a1 = lim
s→1
s −1
(s −1)(s −2)(s −3) = 1
2,
(12.5.10)
a2 = lim
s→2
s −2
(s −1)(s −2)(s −3) = −1
(12.5.11)
and
a3 = lim
s→3
s −3
(s −1)(s −2)(s −3) = 1
2.
(12.5.12)
Therefore,
L−1

1
(s −1)(s −2)(s −3)

= L−1
 a1
s −1 +
a2
s −2 +
a3
s −3

= 1
2et −e2t + 1
2e3t. (12.5.13)

The Laplace Transform
583
⊓⊔
Note that for inverting transforms of the form F(s)e−as with a > 0, you should use
Heaviside’s expansion theorem to ﬁrst invert F(s) and then apply the second shifting the-
orem.
Let us now ﬁnd the expansion when we have multiple roots, namely
F(s) = q(s)
p(s) =
q(s)
(s −s1)m1(s −s2)m2 · · · (s −sn)mn ,
(12.5.14)
where the order of the denominator, m1 + m2 + · · · + mn, is greater than that for the
numerator.
Once again we eliminated any common factor between the numerator and
denominator. Now we can write F(s) as
F(s) =
n
X
k=1
mk
X
j=1
akj
(s −sk)mk−j+1 .
(12.5.15)
Multiplying Equation 12.5.15 by (s −sk)mk,
(s −sk)mkq(s)
p(s)
= ak1 + ak2(s −sk) + · · · + akmk(s −sk)mk−1
+ (s −sk)mk

a11
(s −s1)m1 + · · · + anmn
s −sn

,
(12.5.16)
where we grouped together into the square-bracketed term all of the terms except for those
with akj coeﬃcients. Taking the limit as s →sk,
ak1 = lim
s→sk
(s −sk)mkq(s)
p(s)
.
(12.5.17)
Let us now take the derivative of Equation 12.5.16,
d
ds
(s −sk)mkq(s)
p(s)

= ak2 + 2ak3(s −sk) + · · · + (mk −1)akmk(s −sk)mk−2
+ d
ds

(s −sk)mk

a11
(s −s1)m1 + · · · + anmn
s −sn

.
(12.5.18)
Taking the limit as s →sk,
ak2 = lim
s→sk
d
ds
(s −sk)mkq(s)
p(s)

.
(12.5.19)
In general,
akj = lim
s→sk
1
(j −1)!
dj−1
dsj−1
(s −sk)mkq(s)
p(s)

,
(12.5.20)
and by direct inversion,
f(t) =
n
X
k=1
mk
X
j=1
akj
(mk −j)!tmk−jeskt.
(12.5.21)

584
Advanced Engineering Mathematics with MATLAB
• Example 12.5.3
Let us ﬁnd the inverse of
F(s) =
s
(s + 2)2(s2 + 1).
(12.5.22)
We ﬁrst note that the denominator has simple zeros at s = ±i and a repeated root at
s = −2. Therefore,
F(s) =
A
s −i +
B
s + i +
C
s + 2 +
D
(s + 2)2 ,
(12.5.23)
where
A = lim
s→i (s −i)F(s) =
1
6+8i,
(12.5.24)
B = lim
s→−i (s + i)F(s) =
1
6−8i,
(12.5.25)
C = lim
s→−2
d
ds

(s + 2)2F(s)

= lim
s→−2
d
ds

s
s2 + 1

= −3
25,
(12.5.26)
and
D = lim
s→−2 (s + 2)2F(s) = −2
5.
(12.5.27)
Thus,
f(t) =
1
6+8ieit +
1
6−8ie−it −3
25e−2t −2
5te−2t =
3
25 cos(t) + 4
25 sin(t) −3
25e−2t −10
25te−2t.
(12.5.28)
⊓⊔
In Section 12.9 we shall see that we can invert transforms just as easily with the residue
theorem.
Let us now ﬁnd the inverse of
F(s) = cs + (ca −ωd)
(s + a)2 + ω2 =
cs + (ca −ωd)
(s + a −ωi)(s + a + ωi)
(12.5.29)
by Heaviside’s expansion theorem. Then
F(s) =
c + di
2(s + a −ωi) +
c −di
2(s + a + ωi) =
√
c2 + d2eθi
2(s + a −ωi) +
√
c2 + d2e−θi
2(s + a + ωi),
(12.5.30)
where θ = tan−1(d/c). Note that we must choose θ so that it gives the correct sign for c
and d.
Taking the inverse of Equation 12.5.30,
f(t) = 1
2
√
c2 + d2e−at+ωti+θi + 1
2
√
c2 + d2e−at−ωti−θi =
√
c2 + d2e−at cos(ωt + θ).
(12.5.31)
Equation 12.5.31 is the amplitude/phase form of the inverse of Equation 12.5.29.
It is
particularly popular with electrical engineers.
• Example 12.5.4
Let us express the inverse of
F(s) =
8s −3
s2 + 4s + 13
(12.5.32)

The Laplace Transform
585
in the amplitude/phase form.
Starting with
F(s) =
8s −3
(s + 2 −3i)(s + 2 + 3i) = 4 + 19i/6
s + 2 −3i + 4 −19i/6
s + 2 + 3i
(12.5.33)
= 5.1017e38.3675◦i
s + 2 −3i
+ 5.1017e−38.3675◦i
s + 2 + 3i
,
(12.5.34)
or
f(t) = 5.1017e−2t+3it+38.3675◦i + 5.1017e−2t−3it−38.3675◦i
(12.5.35)
= 10.2034e−2t cos(3t + 38.3675◦).
(12.5.36)
⊓⊔
• Example 12.5.5: The design of ﬁlm projectors
For our ﬁnal example we anticipate future work. The primary use of Laplace transforms
is the solution of diﬀerential equations. In this example we illustrate this technique that
includes Heaviside’s expansion theorem in the form of amplitude and phase.
This problem6 arose in the design of projectors for motion pictures. An early problem
was ensuring that the speed at which the ﬁlm passed the electric eye remained essentially
constant; otherwise, a frequency modulation of the reproduced sound resulted.
Figure
12.5.1(A) shows a diagram of the projector. Many will remember this design from their
days as a school projectionist. In this section we shall show that this particular design ﬁlters
out variations in the ﬁlm speed caused by irregularities either in the driving-gear trains or
in the engagement of the sprocket teeth with the holes in the ﬁlm.
Let us now focus on the ﬁlm head - a hollow drum of small moment of inertia J1. See
Figure 12.5.1(B). Within it there is a concentric inner ﬂywheel of moment of inertia J2,
where J2 ≫J1. The remainder of the space within the drum is ﬁlled with oil. The inner
ﬂywheel rotates on precision ball bearings on the drum shaft. The only coupling between the
drum and ﬂywheel is through ﬂuid friction and the very small friction in the ball bearings.
The ﬂection of the ﬁlm-loops between the drum head and idler pulleys provides the spring
restoring force for the system as the ﬁlm runs rapidly through the system.
From Figure 12.5.1 the dynamical equations governing the outer case and inner ﬂywheel
are (1) the rate of change of the outer casing of the ﬁlm head equals the frictional torque
given to the casing from the inner ﬂywheel plus the restoring torque due to the ﬂection of
the ﬁlm, and (2) the rate of change of the inner ﬂywheel equals the negative of the frictional
torque given to the outer casing by the inner ﬂywheel.
Assuming that the frictional torque between the two ﬂywheels is proportional to the
diﬀerence in their angular velocities, the frictional torque given to the casing from the inner
ﬂywheel is B(ω2−ω1), where B is the frictional resistance, ω1 and ω2 are the deviations of the
drum and inner ﬂywheel from their normal angular velocities, respectively. If r is the ratio
of the diameter of the winding sprocket to the diameter of the drum, the restoring torque
due to the ﬂection of the ﬁlm and its corresponding angular twist equals K
R t
0(rω0 −ω1) dτ,
where K is the rotational stiﬀness and ω0 is the deviation of the winding sprocket from its
6 Cook, E. D., 1935: The technical aspects of the high-ﬁdelity reproducer. J. Soc. Motion Pict. Eng.,
25, 289–312.

586
Advanced Engineering Mathematics with MATLAB
B
J2
Scanning
light
Film drum 
head
Film
Winding
sprocket
B
J1
A
Figure 12.5.1: (A) The schematic for the scanning light in a motion-picture projector and (B) interior of
the ﬁlm drum head.
normal angular velocity. The quantity rω0 gives the angular velocity at which the ﬁlm is
running through the projector because the winding sprocket is the mechanism that pulls
the ﬁlm. Consequently, the equations governing this mechanical system are
J1
dω1
dt = K
Z t
0
(rω0 −ω1) dτ + B(ω2 −ω1),
(12.5.37)
and
J2
dω2
dt = −B(ω2 −ω1).
(12.5.38)
With the winding sprocket, the drum, and the ﬂywheel running at their normal uniform
angular velocities, let us assume that the winding sprocket introduces a disturbance equiv-
alent to a unit increase in its angular velocity for 0.15 second, followed by the resumption
of its normal velocity. It is assumed that the ﬁlm in contact with the drum cannot slip.
The initial conditions are ω1(0) = ω2(0) = 0.
Taking the Laplace transform of Equation 12.5.37 and Equation 12.5.38 and using
Equation 12.1.18,

J1s + B + K
s

Ω1(s) −BΩ2(s) = rK
s Ω0(s) = rKL
Z t
0
ω0(τ) dτ

,
(12.5.39)
and
−BΩ1(s) + (J2s + B)Ω2(s) = 0.
(12.5.40)
The solution of Equation 12.5.39 and Equation 12.5.40 for Ω1(s) is
Ω1(s) = rK
J1
(s + a0)Ω0(s)
s3 + b2s2 + b1s + b0
,
(12.5.41)
where typical values7 are
rK
J1
= 90.8,
a0 = B
J2
= 1.47,
b0 = BK
J1J2
= 231,
(12.5.42)
7 J1 = 1.84 × 104 dyne cm sec2 per radian, J2 = 8.43 × 104 dyne cm sec2 per radian, B = 12.4 × 104
dyne cm sec per radian, K = 2.89 × 106 dyne cm per radian, and r = 0.578.

The Laplace Transform
587
b1 = K
J1
= 157,
and
b2 = B(J1 + J2)
J1J2
= 8.20.
(12.5.43)
The transform Ω1(s) has three simple poles located at s1 = −1.58, s2 = −3.32 + 11.6i, and
s3 = −3.32 −11.6i.
Because the sprocket angular velocity deviation ω0(t) is a pulse of unit amplitude and
0.15 second duration, we express it as the diﬀerence of two Heaviside step functions
ω0(t) = H(t) −H(t −0.15).
(12.5.44)
Its Laplace transform is
Ω0(s) = 1
s −1
se−0.15s
(12.5.45)
so that Equation 12.5.41 becomes
Ω1(s) = rK
J1
(s + a0)
s(s −s1)(s −s2)(s −s3)
 1 −e−0.15s
.
(12.5.46)
The inversion of Equation 12.5.46 follows directly from the second shifting theorem
and Heaviside’s expansion theorem, or
ω1(t) = K0 + K1es1t + K2es2t + K3es3t
(12.5.47)
−[K0 + K1es1(t−0.15) + K2es2(t−0.15) + K3es3(t−0.15)]H(t −0.15),
where
K0 = rK
J1
s + a0
(s −s1)(s −s2)(s −s3)

s=0
= 0.578,
(12.5.48)
K1 = rK
J1
s + a0
s(s −s2)(s −s3)

s=s1
= 0.046,
(12.5.49)
K2 = rK
J1
s + a0
s(s −s1)(s −s3)

s=s2
= 0.326e165◦i,
(12.5.50)
and
K3 = rK
J1
s + a0
s(s −s1)(s −s2)

s=s3
= 0.326e−165◦i.
(12.5.51)
Using Euler’s identity cos(t) = (eit + e−it)/2, we can write Equation 12.5.47 as
ω1(t) = 0.578 + 0.046e−1.58t + 0.652e−3.32t cos(11.6t + 165◦)
−{0.578 + 0.046e−1.58(t−0.15) + 0.652e−3.32(t−0.15)
× cos[11.6(t −0.15) + 165◦]}H(t −0.15).
(12.5.52)
Equation 12.5.52 is plotted in Figure 12.5.2. Note that ﬂuctuations in ω1(t) are damped
out by the particular design of this ﬁlm projector. Because this mechanical device dampens
unwanted ﬂuctuations (or noise) in the motion-picture projector, this particular device is
an example of a mechanical ﬁlter.

588
Advanced Engineering Mathematics with MATLAB
1
0.0
0.5
1.0
1.5
2.0
time (seconds)
−0.4
−0.2
0.0
0.2
0.4
0.6
0.8
ω (t)
Figure 12.5.2: The deviation ω1(t) of a ﬁlm drum head from its uniform angular velocity when the sprocket
angular velocity is perturbed by a unit amount for the duration of 0.15 second.
Problems
Use Heaviside’s expansion theorem to ﬁnd the inverse of the following Laplace transforms:
1. F(s) =
1
s2 + 3s + 2
2. F(s) =
s + 3
(s + 4)(s −2)
3. F(s) =
s −4
(s + 2)(s + 1)(s −3)
4. F(s) =
s −3
(s2 + 4)(s + 1)
Find the inverse of the following transforms and express them in amplitude/phase form:
5. F(s) =
1
s2 + 4s + 5
6. F(s) =
1
s2 + 6s + 13
7. F(s) = 2s −5
s2 + 16
8. F(s) =
1
s(s2 + 2s + 2)
9. F(s) =
s + 2
s(s2 + 4)
12.6 CONVOLUTION
In this section we turn to a fundamental concept in Laplace transforms: convolution.
We shall restrict ourselves to its use in ﬁnding the inverse of a transform when that transform
consists of the product of two simpler transforms. In subsequent sections we will use it to
solve ordinary diﬀerential equations.
We begin by formally introducing the mathematical operation of the convolution prod-
uct
f(t) ∗g(t) =
Z t
0
f(t −x)g(x) dx =
Z t
0
f(x)g(t −x) dx.
(12.6.1)
In most cases the operations required by Equation 12.6.1 are straightforward.
• Example 12.6.1
Let us ﬁnd the convolution between cos(t) and sin(t).
cos(t) ∗sin(t) =
Z t
0
sin(t −x) cos(x) dx = 1
2
Z t
0
[sin(t) + sin(t −2x)] dx
(12.6.2)

The Laplace Transform
589
= 1
2
Z t
0
sin(t) dx + 1
2
Z t
0
sin(t −2x) dx
(12.6.3)
= 1
2 sin(t) x
t
0 + 1
4 cos(t −2x)
t
0 = 1
2t sin(t).
(12.6.4)
⊓⊔
• Example 12.6.2
Similarly, the convolution between t2 and sin(t) is
t2 ∗sin(t) =
Z t
0
(t −x)2 sin(x) dx
(12.6.5)
= −(t −x)2 cos(x)
t
0 −2
Z t
0
(t −x) cos(x) dx
(12.6.6)
= t2 −2(t −x) sin(x)
t
0 −2
Z t
0
sin(x) dx
(12.6.7)
= t2 + 2 cos(t) −2
(12.6.8)
by integration by parts.
⊓⊔
• Example 12.6.3
Consider now the convolution between et and the discontinuous function H(t −1) −
H(t −2):
et ∗[H(t −1) −H(t −2)] =
Z t
0
et−x[H(x −1) −H(x −2)] dx
(12.6.9)
= et
Z t
0
e−x[H(x −1) −H(x −2)] dx.
(12.6.10)
In order to evaluate the integral, Equation 12.6.10, we must examine various cases. If t < 1,
then both of the step functions equal zero and the convolution equals zero. However, when
1 < t < 2, the ﬁrst step function equals one while the second equals zero as the dummy
variable x runs between 1 and t. Therefore,
et ∗[H(t −1) −H(t −2)] = et
Z t
1
e−xdx = et−1 −1,
(12.6.11)
because the portion of the integral from zero to one equals zero. Finally, when t > 2, the
integrand is only nonzero for that portion of the integration when 1 < x < 2. Consequently,
et ∗[H(t −1) −H(t −2)] = et
Z 2
1
e−xdx = et−1 −et−2.
(12.6.12)
Thus, the convolution of et with the pulse H(t −1) −H(t −2) is
et ∗[H(t −1) −H(t −2)] =
(
0,
0 ≤t ≤1,
et−1 −1,
1 ≤t ≤2,
et−1 −et−2,
2 ≤t.
(12.6.13)

590
Advanced Engineering Mathematics with MATLAB
MATLAB can also be used to ﬁnd the convolution of two functions. For example, in
the present case the commands
syms x t positive
int(’exp(t-x)*(Heaviside(x-1)-Heaviside(x-2))’,x,0,t)
yield
ans =
-Heaviside(t-1)+Heaviside(t-1)*exp(t-1)+Heaviside(t-2)
-Heaviside(t-2)*exp(t-2)
⊓⊔
The reason why we introduced convolution stems from the following fundamental the-
orem (often called Borel’s theorem8). If
w(t) = u(t) ∗v(t)
(12.6.14)
then
W(s) = U(s)V (s).
(12.6.15)
In other words, we can invert a complicated transform by convoluting the inverses to two
simpler functions. The proof is as follows:
W(s) =
Z ∞
0
Z t
0
u(x)v(t −x) dx

e−stdt
(12.6.16)
=
Z ∞
0
Z ∞
x
u(x)v(t −x)e−stdt

dx
(12.6.17)
=
Z ∞
0
u(x)
Z ∞
0
v(r)e−s(r+x)dr

dx
(12.6.18)
=
Z ∞
0
u(x)e−sxdx
 Z ∞
0
v(r)e−srdr

= U(s)V (s),
(12.6.19)
where t = r + x.
⊓⊔
• Example 12.6.4
Let us ﬁnd the inverse of the transform
s
(s2 + 1)2 =
s
s2 + 1 ×
1
s2 + 1 = L[cos(t)]L[sin(t)] = L[cos(t) ∗sin(t)] = L[ 1
2t sin(t)]
(12.6.20)
from Example 12.6.1.
⊓⊔
• Example 12.6.5
Let us ﬁnd the inverse of the transform
1
(s2 + a2)2 = 1
a2

a
s2 + a2 ×
a
s2 + a2

= 1
a2 L[sin(at)]L[sin(at)].
(12.6.21)
8 Borel, ´E., 1901: Le¸cons sur les s´eries divergentes. Gauthier-Villars, p. 104.

The Laplace Transform
591
Therefore,
L−1

1
(s2 + a2)2

= 1
a2
Z t
0
sin[a(t −x)] sin(ax) dx
(12.6.22)
=
1
2a2
Z t
0
cos[a(t −2x)] dx −
1
2a2
Z t
0
cos(at) dx
(12.6.23)
= −1
4a3 sin[a(t −2x)]

t
0
−1
2a2 cos(at) x

t
0
(12.6.24)
=
1
2a3 [sin(at) −at cos(at)].
(12.6.25)
⊓⊔
• Example 12.6.6
Let us use the results from Example 12.6.3 to verify the convolution theorem.
We begin by rewriting Equation 12.6.13 in terms of the Heaviside step functions. Using
the method outline in Example 12.2.1,
f(t) ∗g(t) =
 et−1 −1

H(t −1) +
 1 −et−2
H(t −2).
(12.6.26)
Employing the second shifting theorem,
L[f ∗g] = e−s
s −1 −e−s
s
+ e−2s
s
−e−2s
s −1
(12.6.27)
=
e−s
s(s −1) −
e−2s
s(s −1) =
1
s −1
e−s
s
−e−2s
s

(12.6.28)
= L[et]L[H(t −1) −H(t −2)]
(12.6.29)
and the convolution theorem holds true. If we had not rewritten Equation 12.6.13 in terms
of step functions, we could still have found L[f ∗g] from the deﬁnition of the Laplace
transform.
Problems
Verify the following convolutions and then show that the convolution theorem is true. Use
MATLAB to check your answer.
1. 1 ∗1 = t
2. 1 ∗cos(at) = sin(at)/a
3. 1 ∗et = et −1
4. t ∗t = t3/6
5. t ∗sin(t) = t −sin(t)
6. t ∗et = et −t −1
7. t2 ∗sin(at) = t2
a −4
a3 sin2
at
2

8. t ∗H(t −1) = 1
2(t −1)2H(t −1)
9. H(t −a) ∗H(t −b) = (t −a −b)H(t −a −b)

592
Advanced Engineering Mathematics with MATLAB
10. t ∗[H(t) −H(t −2)] = t2
2 −(t −2)2
2
H(t −2)
Use the convolution theorem to invert the following functions:
11. F(s) =
1
s2(s −1)
12. F(s) =
1
s2(s + a)2
13. Given9
L−1
eα/s
s

= I0

2
√
αt

,
α > 0,
show that
ea/s
s −1 =

1 +
1
s −1
 ea/s
s ,
a > 0,
and
L−1
 ea/s
s −1

=

δ(t) + et
∗I0

2
√
at

= et + et
Z √
4at
0
exp

−τ 2
4a

I1(τ) dτ,
where In(·) denotes a modiﬁed Bessel function of the ﬁrst kind and order n, which was
introduced in Section 6.5. There we will show that I′
0(τ) = I1(τ).
14. Prove that the convolution of two Dirac delta functions is a Dirac delta function.
12.7 INTEGRAL EQUATIONS
An integral equation contains the dependent variable under an integral sign. The convo-
lution theorem provides an excellent tool for solving a very special class of these equations,
Volterra equation of the second kind:10
f(t) −
Z t
0
K[t, x, f(x)] dx = g(t),
0 ≤t ≤T.
(12.7.1)
These equations appear in history-dependent problems, such as epidemics,11 vibration prob-
lems,12 and viscoelasticity.13
9 Watson, op. cit., p. 195.
10 Fock, V., 1924: ¨Uber eine Klasse von Integralgleichungen. Math. Z., 21, 161–173; Koizumi, S., 1931:
On Heaviside’s operational solution of a Volterra’s integral equation when its nucleus is a function of (x−ξ).
Philos. Mag., Ser. 7, 11, 432–441.
11 Wang, F. J. S., 1978: Asymptotic behavior of some deterministic epidemic models. SIAM J. Math.
Anal., 9, 529–534.
12 Lin, S. P., 1975: Damped vibration of a string. J. Fluid Mech., 72, 787–797.
13 Rogers, T. G., and E. H. Lee, 1964: The cylinder problem in viscoelastic stress analysis. Q. Appl.
Math., 22, 117–131.

The Laplace Transform
593
• Example 12.7.1
Let us ﬁnd f(t) from the integral equation
f(t) = 4t −3
Z t
0
f(x) sin(t −x) dx.
(12.7.2)
The integral in Equation 12.7.2 is such that we can use the convolution theorem to ﬁnd
its Laplace transform. Then, because L[sin(t)] = 1/(s2 +1), the convolution theorem yields
L
Z t
0
f(x) sin(t −x) dx

= F(s)
s2 + 1.
(12.7.3)
Therefore, the Laplace transform converts Equation 12.7.2 into
F(s) = 4
s2 −3F(s)
s2 + 1.
(12.7.4)
Solving for F(s),
F(s) = 4(s2 + 1)
s2(s2 + 4).
(12.7.5)
By partial fractions, or by inspection,
F(s) = 1
s2 +
3
s2 + 4.
(12.7.6)
Therefore, inverting term by term,
f(t) = t + 3
2 sin(2t).
(12.7.7)
Note that the integral equation
f(t) = 4t −3
Z t
0
f(t −x) sin(x) dx
(12.7.8)
also has the same solution.
⊓⊔
• Example 12.7.2
Let us solve the equation
f ′(t) + α2
Z t
0
f(τ) dτ = B −C cos(ωt),
f(0) = 0.
(12.7.9)
Again the integral is one of the convolution type; it diﬀers from the previous example
in that it includes a derivative. Taking the Laplace transform of Equation 12.7.9,
sF(s) −f(0) + α2F(s)
s
= B
s −
sC
s2 + ω2 .
(12.7.10)
Because f(0) = 0, Equation 12.7.10 simpliﬁes to
(s2 + α2)F(s) = B −
Cs2
s2 + ω2 .
(12.7.11)

594
Advanced Engineering Mathematics with MATLAB
Solving for F(s),
F(s) =
B
s2 + α2 −
Cs2
(s2 + α2)(s2 + ω2).
(12.7.12)
Using partial fractions to invert Equation 12.7.12,
f(t) =
B
α +
αC
ω2 −α2

sin(αt) −
ωC
ω2 −α2 sin(ωt).
(12.7.13)
⊓⊔
• Example 12.7.3
Let us solve14 the integral equation
f(t) =
a
2(1 + 2a)
Z t
0
f(t −x)f(x) dx + e−t.
(12.7.14)
Taking the Laplace transform of Equation 12.7.14, we obtain
F(s) =
a F 2(s)
2(1 + 2a) +
1
s + 1.
(12.7.15)
Solving for F(s) so that F(s) →0 as s →∞, we have
F(s) = 2a + 1
a
−2a + 1
a
s
(2a + 1)(s + 1) −2a
(2a + 1)(s + 1)
= 2a + 1
a
−
√2a + 1
a
r
(2a + 1)s + 1
s + 1
.
(12.7.16)
Taking the inverse of Equation 12.7.16,
f(t) = 2a + 1
a
δ(t) −
√2a + 1
a
g(t),
(12.7.17)
where g(t) is the inverse of the Laplace transform G(s),
G(s) =
r
(2a + 1)s + 1
s + 1
=
√
2a + 1
s + 1/(1 + 2a)
√s + 1
p
s + 1/(2a + 1)
(12.7.18)
=
√
2a + 1 sH(s) +
H(s)
√2a + 1
(12.7.19)
and
H(s) =
1
√s + 1
p
s + 1/(2a + 1)
.
(12.7.20)
Taking the inverse of H(s), we ﬁnd that
h(t) = exp

−a + 1
2a + 1t

I0

at
2a + 1

(12.7.21)
14 Hounslow, M. J., 1990: A discretized population balance for continuous systems at steady state.
AICHE J., 36, 106–116.

The Laplace Transform
595
and
h′(t) = −a + 1
2a + 1 exp

−a + 1
2a + 1t

I0

at
2a + 1

+
a
2a + 1 exp

−a + 1
2a + 1t

I1

at
2a + 1

,
(12.7.22)
where I0(·) and I1(·) are modiﬁed Bessel functions of the ﬁrst kind. See Section 6.5.
Because sH(s) = L[h′(t)]+h(0) and h(0) = 1, h′(t) = L−1[sH(s)]−δ(t) or L−1[sH(s)]
= h′(t) + δ(t). Then,
g(t) =
√
2a + 1

h′(t) +
h(t)
2a + 1 + δ(t)

(12.7.23)
=
√
2a + 1

δ(t) +
a
2a + 1 exp

−a + 1
2a + 1t

I1

at
2a + 1

−
a
2a + 1 exp

−a + 1
2a + 1t

I0

at
2a + 1

.
(12.7.24)
Finally, substituting Equation 12.7.24 into Equation 12.7.17,
f(t) = exp

−a + 1
2a + 1t
 
I0

at
2a + 1

−I1

at
2a + 1

.
(12.7.25)
Problems
Solve the following integral equations:
1. f(t) = 1 + 2
Z t
0
f(t −x)e−2x dx
2. f(t) = 1 +
Z t
0
f(x) sin(t −x) dx
3. f(t) = t +
Z t
0
f(t −x)e−x dx
4. f(t) = 4t2 −
Z t
0
f(t −x)e−x dx
5. f(t) = t3 +
Z t
0
f(x) sin(t −x) dx
6. f(t) = 8t2 −3
Z t
0
f(x) sin(t −x) dx
7. f(t) = t2 −2
Z t
0
f(t −x) sinh(2x) dx
8. f(t) = 1 + 2
Z t
0
f(t −x) cos(x) dx
9. f(t) = e2t + 2
Z t
0
f(t −x) cos(x) dx
10. f(t) = t2 +
Z t
0
f(x) sin(t −x) dx
11. f(t) = e−t −2
Z t
0
f(x) cos(t −x) dx
12. f(t) = 6t + 4
Z t
0
f(x)(x −t)2 dx
13. f(t) = a
√
t −
Z t
0
f(t −x)
√x
dx
14. Solve the following equation for f(t) with the condition that f(0) = 4:
f ′(t) = t +
Z t
0
f(t −x) cos(x) dx.
15. Solve the following equation for f(t) with the condition that f(0) = 0:
f ′(t) = sin(t) +
Z t
0
f(t −x) cos(x) dx.

596
Advanced Engineering Mathematics with MATLAB
16. During a study of nucleation involving idealized active sites along a boiling surface,
Marto and Rohsenow15 solved the integral equation
A = B
√
t + C
Z t
0
x′(τ)
√t −τ dτ
to ﬁnd the position x(t) of the liquid/vapor interface. If A, B, and C are constants and
x(0) = 0, ﬁnd the solution for them.
17. Solve the following equation for x(t) with the condition that x(0) = 0:
x(t) + t =
1
c√π
Z t
0
x′(τ)
√t −τ dτ,
where c is constant.
18. During a study of the temperature f(t) of a heat reservoir attached to a semi-inﬁnite
heat-conducting rod, Huber16 solved the integral equation
f ′(t) = α −β
√π
Z t
0
f ′(τ)
√t −τ dτ,
where α and β are constants and f(0) = 0. Find f(t) for him. Hint:
α
s3/2(s1/2 + β) =
α
s(s −β2) −
αβ
s3/2(s −β2).
19.
During the solution of a diﬀusion problem, Zhdanov, Chikhachev, and Yavlinskii17
solved an integral equation similar to
Z t
0
f(τ)

1 −erf
 a
√
t −τ

dτ = at,
where erf(x) =
2
√π
Z x
0
e−y2 dy is the error function. What should they have found? Hint:
You will need to prove that
L

t erf(a
√
t ) −
1
2a2 erf(a
√
t ) +
√
t
a√π e−a2t

=
a
s2√
s + a2 .
20. The Laguerre polynomial18
y(t) = Ln(t) = et
n!
dn
dtn
 tne−t
,
n = 0, 1, 2, 3, . . .
15 Marto, P. J., and W. M. Rohsenow, 1966: Nucleate boiling instability of alkali metals.
J. Heat
Transfer, 88, 183–193.
16 Huber, A., 1934: Eine Methode zur Bestimmung der W¨arme- und Temperaturleitf¨ahigkeit. Monatsh.
Math. Phys., 41, 35–42.
17 Zhdanov, S. K., A. S. Chikhachev, and Yu. N. Yavlinskii, 1976: Diﬀusion boundary-value problem for
regions with moving boundaries and conservation of particles. Sov. Phys. Tech. Phys., 21, 883–884.
18 See Section 5.3 in Andrews, L. C., 1985: Special Functions for Engineers and Applied Mathematicians.
MacMillan, 357 pp.

The Laplace Transform
597
satisﬁes the ordinary diﬀerential equation
ty′′ + (1 −t)y′ + ny = (ty′)′ −ty′ + ny = 0,
with y(0) = 1 and y′(0) = −n.
Step 1: Using Equation 12.1.18 and Equation 12.3.20, show that the Laplace transformed
version of this diﬀerential equation is
Y ′(s) = n + 1 −s
s(s −1) Y (s) =
n
s −1Y (s) −n + 1
s
Y (s),
where Y (s) is the Laplace transform of y(t).
Step 2: Using Equation 12.3.20 and the convolution theorem, show that Laguerre polyno-
mials are the solution to the integral equation
ty(t) = (n + 1)
Z t
0
y(τ) dτ −net
Z t
0
y(τ) e−τ dτ.
12.8 SOLUTION OF LINEAR DIFFERENTIAL EQUATIONS WITH
CONSTANT COEFFICIENTS
For the engineer, as it was for Oliver Heaviside, the primary use of Laplace transforms is
the solution of ordinary, constant coeﬃcient, linear diﬀerential equations. These equations
are important not only because they appear in many engineering problems but also because
they may serve as approximations, even if locally, to ordinary diﬀerential equations with
nonconstant coeﬃcients or to nonlinear ordinary diﬀerential equations.
For all of these reasons, we wish to solve the initial-value problem
dny
dtn + a1
dn−1y
dtn−1 + · · · + an−1
dy
dt + any = f(t),
t > 0,
(12.8.1)
by Laplace transforms, where a1, a2, . . . are constants and we know the value of y, y′, . . . ,
y(n−1) at t = 0. The procedure is as follows. Applying the derivative rule Equation 12.1.18
to Equation 12.8.1, we reduce the diﬀerential equation to an algebraic one involving the
constants a1, a2, . . . , an, the parameter s, the Laplace transform of f(t), and the values of
the initial conditions. We then solve for the Laplace transform of y(t), Y (s). Finally, we
apply one of the many techniques of inverting a Laplace transform to ﬁnd y(t).
Similar considerations hold with systems of ordinary diﬀerential equations. The Laplace
transform of the system of ordinary diﬀerential equations results in an algebraic set of
equations containing Y1(s), Y2(s), . . . , Yn(s). By some method we solve this set of equations
and invert each transform Y1(s), Y2(s), . . . , Yn(s) in turn to give y1(t), y2(t), . . . , yn(t).
The following examples will illustrate the details of the process.
• Example 12.8.1
Let us solve the ordinary diﬀerential equation
y′′ + 2y′ = 8t,
(12.8.2)

598
Advanced Engineering Mathematics with MATLAB
subject to the initial conditions that y′(0) = y(0) = 0. Taking the Laplace transform of
both sides of Equation 12.8.2,
L(y′′) + 2L(y′) = 8L(t),
(12.8.3)
or
s2Y (s) −sy(0) −y′(0) + 2sY (s) −2y(0) = 8
s2 ,
(12.8.4)
where Y (s) = L[y(t)]. Substituting the initial conditions into Equation 12.8.4 and solving
for Y (s),
Y (s) =
8
s3(s + 2) = A
s3 + B
s2 + C
s +
D
s + 2 = (s + 2)A + s(s + 2)B + s2(s + 2)C + s3D
s3(s + 2)
.
(12.8.5)
Matching powers of s in the numerators of Equation 12.8.5, C + D = 0, B + 2C = 0,
A + 2B = 0, and 2A = 8 or A = 4, B = −2, C = 1, and D = −1. Therefore,
Y (s) = 4
s3 −2
s2 + 1
s −
1
s + 2.
(12.8.6)
Finally, performing term-by-term inversion of Equation 12.8.6, the ﬁnal solution is
y(t) = 2t2 −2t + 1 −e−2t.
(12.8.7)
We could have done the same operations using the symbolic toolbox with MATLAB.
The MATLAB script
clear
% define symbolic variables
syms s t Y
% take Laplace transform of left side of differential equation
LHS = laplace(diff(diff(sym(’y(t)’)))+2*diff(sym(’y(t)’)));
% take Laplace transform of right side of differential equation
RHS = laplace(8*t);
% set Y for Laplace transform of y
%
and introduce initial conditions
newLHS = subs(LHS,’laplace(y(t),t,s)’,’y(0)’,’D(y)(0)’,Y,0,0);
% solve for Y
Y = solve(newLHS-RHS,Y);
% invert Laplace transform and find y(t)
y = ilaplace(Y,s,t)
yields the result
y =
1-exp(-2*t)-2*t+2*t^2
which agrees with Equation 12.8.7.
⊓⊔
• Example 12.8.2
Let us solve the ordinary diﬀerential equation
y′′ + y = H(t) −H(t −1)
(12.8.8)

The Laplace Transform
599
with the initial conditions that y′(0) = y(0) = 0. Taking the Laplace transform of both
sides of Equation 12.8.8,
s2Y (s) −sy(0) −y′(0) + Y (s) = 1
s −e−s
s ,
(12.8.9)
where Y (s) = L[y(t)]. Substituting the initial conditions into Equation 12.8.9 and solving
for Y (s),
Y (s) =
1
s −
s
s2 + 1

−
1
s −
s
s2 + 1

e−s.
(12.8.10)
Using the second shifting theorem, the ﬁnal solution is
y(t) = 1 −cos(t) −[1 −cos(t −1)]H(t −1).
(12.8.11)
We can check our results using the MATLAB script
clear
% define symbolic variables
syms s t Y
% take Laplace transform of left side of differential equation
LHS = laplace(diff(diff(sym(’y(t)’)))+sym(’y(t)’));
% take Laplace transform of right side of differential equation
RHS = laplace(’Heaviside(t) - Heaviside(t-1)’,t,s);
% set Y for Laplace transform of y
%
and introduce initial conditions
newLHS = subs(LHS,’laplace(y(t),t,s)’,’y(0)’,’D(y)(0)’,Y,0,0);
% solve for Y
Y = solve(newLHS-RHS,Y);
% invert Laplace transform and find y(t)
y = ilaplace(Y,s,t)
which yields
y =
1-cos(t)-Heaviside(t-1)+Heaviside(t-1)*cos(t-1)
⊓⊔
• Example 12.8.3
Let us solve the ordinary diﬀerential equation
y′′ + 2y′ + y = f(t)
(12.8.12)
with the initial conditions that y′(0) = y(0) = 0, where f(t) is an unknown function whose
Laplace transform exists. Taking the Laplace transform of both sides of Equation 12.8.12,
s2Y (s) −sy(0) −y′(0) + 2sY (s) −2y(0) + Y (s) = F(s),
(12.8.13)
where Y (s) = L[y(t)]. Substituting the initial conditions into Equation 12.8.13 and solving
for Y (s),
Y (s) =
1
(s + 1)2 F(s).
(12.8.14)

600
Advanced Engineering Mathematics with MATLAB
We wrote Equation 12.8.14 in this form because the transform Y (s) equals the product
of two transforms 1/(s + 1)2 and F(s).
Therefore, by the convolution theorem we can
immediately write
y(t) = te−t ∗f(t) =
Z t
0
xe−xf(t −x) dx.
(12.8.15)
Without knowing f(t), this is as far as we can go.
⊓⊔
• Example 12.8.4: Forced harmonic oscillator
Let us solve the simple harmonic oscillator forced by a harmonic forcing
y′′ + ω2y = cos(ωt),
(12.8.16)
subject to the initial conditions that y′(0) = y(0) = 0. Although the complete solution
could be found by summing the complementary solution and a particular solution obtained,
say, from the method of undetermined coeﬃcients, we now illustrate how we can use Laplace
transforms to solve this problem.
Taking the Laplace transform of both sides of Example 12.8.16, substituting in the
initial conditions, and solving for Y (s),
Y (s) =
s
(s2 + ω2)2 ,
(12.8.17)
and
y(t) = 1
ω sin(ωt) ∗cos(ωt) = t
2ω sin(ωt).
(12.8.18)
Equation 12.8.18 gives an oscillation that grows linearly with time although the forcing
function is simply periodic. Why does this occur? Recall that our simple harmonic oscillator
has the natural frequency ω. But that is exactly the frequency at which we drive the system.
Consequently, our choice of forcing has resulted in resonance where energy continuously
feeds into the oscillator.
⊓⊔
• Example 12.8.5
Let us solve the system of ordinary diﬀerential equations:
2x′ + y = cos(t),
(12.8.19)
and
y′ −2x = sin(t),
(12.8.20)
subject to the initial conditions that x(0) = 0, and y(0) = 1. Taking the Laplace transform
of Equation 12.8.19 and Equation 12.8.20,
2sX(s) + Y (s) =
s
s2 + 1,
(12.8.21)
and
−2X(s) + sY (s) = 1 +
1
s2 + 1,
(12.8.22)

The Laplace Transform
601
after introducing the initial conditions. Solving for X(s) and Y (s),
X(s) = −
1
(s2 + 1)2 ,
(12.8.23)
and
Y (s) =
s
s2 + 1 +
2s
(s2 + 1)2 .
(12.8.24)
Taking the inverse of Equation 12.8.23 and Equation 12.8.24 term by term,
x(t) = 1
2[t cos(t) −sin(t)],
(12.8.25)
and
y(t) = t sin(t) + cos(t).
(12.8.26)
The MATLAB script
clear
% define symbolic variables
syms s t X Y
% take Laplace transform of left side of differential equations
LHS1 = laplace(2*diff(sym(’x(t)’))+sym(’y(t)’));
LHS2 = laplace(diff(sym(’y(t)’))-2*sym(’x(t)’));
% take Laplace transform of right side of differential equations
RHS1 = laplace(cos(t)); RHS2 = laplace(sin(t));
% set X and Y for Laplace transforms of x and y
%
and introduce initial conditions
newLHS1 = subs(LHS1,’laplace(x(t),t,s)’,’laplace(y(t),t,s)’,...
’x(0)’,’y(0)’,X,Y,0,1);
newLHS2 = subs(LHS2,’laplace(x(t),t,s)’,’laplace(y(t),t,s)’,...
’x(0)’,’y(0)’,X,Y,0,1);
% solve for X and Y
[X,Y] = solve(newLHS1-RHS1,newLHS2-RHS2,X,Y);
% invert Laplace transform and find x(t) and y(t)
x = ilaplace(X,s,t); y = ilaplace(Y,s,t)
uses the symbolic toolbox to solve Equation 12.8.19 and Equation 12.8.20. MATLAB ﬁnally
gives
x =
1/2*t*cos(t)-1/2*sin(t)
y =
t*sin(t)+cos(t)
⊓⊔
• Example 12.8.6
Let us determine the displacement of a mass m attached to a spring and excited by
the driving force
F(t) = mA

1 −t
T

e−t/T .
(12.8.27)
The dynamical equation governing this system is
y′′ + ω2y = A

1 −t
T

e−t/T ,
(12.8.28)

602
Advanced Engineering Mathematics with MATLAB
where ω2 = k/m and k is the spring constant. Assuming that the system is initially at rest,
the Laplace transform of the dynamical system is
(s2 + ω2)Y (s) =
A
s + 1/T −
A
T(s + 1/T)2 ,
(12.8.29)
or
Y (s) =
A
(s2 + ω2)(s + 1/T) −
A
T(s2 + ω2)(s + 1/T)2 .
(12.8.30)
Partial fractions yield
Y (s) =
A
ω2 + 1/T 2

1
s + 1/T −s −1/T
s2 + ω2

−
A
T(ω2 + 1/T 2)2
×
1/T 2 −ω2
s2 + ω2
−
2s/T
s2 + ω2 + ω2 + 1/T 2
(s + 1/T)2 +
2/T
s + 1/T

.
(12.8.31)
Inverting Equation 12.8.31 term by term,
y(t) =
AT 2
1 + ω2T 2

e−t/T −cos(ωt) + sin(ωt)
ωT

−
AT 2
(1 + ω2T 2)2

(1 −ω2T 2)sin(ωt)
ωT
+ 2
h
e−t/T −cos(ωt)
i
+ (1 + ω2T 2)(t/T)e−t/T

.
(12.8.32)
The solution to this problem consists of two parts.
The exponential terms result from
the forcing and will die away with time. This is the transient portion of the solution. The
sinusoidal terms are those natural oscillations that are necessary so that the solution satisﬁes
the initial conditions. They are the steady-state portion of the solution and endure forever.
Figure 12.8.1 illustrates the solution when ωT = 0.1, 1, and 2. Note that the displacement
decreases in magnitude as the nondimensional frequency of the oscillator increases.
⊓⊔
• Example 12.8.7
Let us solve the equation
y′′ + 16y = δ(t −π/4)
(12.8.33)
with the initial conditions that y(0) = 1, and y′(0) = 0.
Taking the Laplace transform of Equation 12.8.33 and inserting the initial conditions,
(s2 + 16)Y (s) = s + e−sπ/4,
(12.8.34)
or
Y (s) =
s
s2 + 16 + e−sπ/4
s2 + 16.
(12.8.35)
Applying the second shifting theorem,
y(t) = cos(4t) + 1
4 sin[4(t −π/4)]H(t −π/4) = cos(4t) −1
4 sin(4t)H(t −π/4).
(12.8.36)
We can check our results using the MATLAB script
clear
% define symbolic variables
syms pi s t Y

The Laplace Transform
603
y(t)/AT
-1.0
-0.5
0.0
0.5
1.0
-0.5
0.0
0.5
1.0
ωΤ = 0.5
forcing
2
f(t)/mA
y(t)/AT
0.0
2.0
4.0
6.0
8.0
t/T
-1.0
-0.5
0.0
0.5
1.0
-1.0
-0.5
0.0
0.5
1.0
ωΤ = 1
ωΤ = 2
2
2
y(t)/AT
Figure 12.8.1: Displacement of a simple harmonic oscillator with nondimensional frequency ωT as a
function of time t/T. The top frame shows the forcing function.
% take Laplace transform of left side of differential equation
LHS = laplace(diff(diff(sym(’y(t)’)))+16*sym(’y(t)’));
% take Laplace transform of right side of differential equation
RHS = laplace(’Dirac(t-pi/4)’,t,s);
% set Y for Laplace transform of y
%
and introduce initial conditions
newLHS = subs(LHS,’laplace(y(t),t,s)’,’y(0)’,’D(y)(0)’,Y,1,0);
% solve for Y
Y = solve(newLHS-RHS,Y);
% invert Laplace transform and find y(t)
y = ilaplace(Y,s,t)
which yields
y =
cos(4*t)-1/4*Heaviside(t-1/4*pi)*sin(4*t)
We can also verify that Equation 12.8.36 is the solution to our initial-value problem by
computing the (generalized) derivative of Equation 12.8.36, or
y′(t) = −4 sin(4t) −cos(4t)H(t −π/4) −1
4 sin(4t)δ(t −π/4)
(12.8.37)
= −4 sin(4t) −cos(4t)H(t −π/4) −1
4 sin(π)δ(t −π/4)
(12.8.38)
= −4 sin(4t) −cos(4t)H(t −π/4),
(12.8.39)

604
Advanced Engineering Mathematics with MATLAB
since f(t)δ(t −t0) = f(t0)δ(t −t0). Similarly,
y′′(t) = −16 cos(4t) + 4 sin(4t)H(t −π/4) −cos(4t)δ(t −π/4)
(12.8.40)
= −16 cos(4t) + 4 sin(4t)H(t −π/4) −cos(π)δ(t −π/4)
(12.8.41)
= −16 cos(4t) + 4 sin(4t)H(t −π/4) + δ(t −π/4).
(12.8.42)
Substituting Equation 12.8.36 and Equation 12.8.42 into Equation 12.8.32 completes the
veriﬁcation. A quick check of y(0) and y′(0) also shows that we have the correct solution.⊓⊔
• Example 12.8.8: Oscillations in electric circuits
During the middle of the nineteenth century, Lord Kelvin19 analyzed the LCR electrical
circuit shown in Figure 12.8.2, which contains resistance R, capacitance C, and inductance
L. For reasons that we shall shortly show, this LCR circuit has become one of the quintessen-
tial circuits for electrical engineers. In this example, we shall solve the problem by Laplace
transforms.
Because we can add the potential diﬀerences across the elements, the equation govern-
ing the LCR circuit is
LdI
dt + RI + 1
C
Z t
0
I dτ = E(t),
(12.8.43)
where I denotes the current in the circuit. Let us solve Equation 12.8.43 when we close
the circuit and the initial conditions are I(0) = 0 and Q(0) = −Q0. Taking the Laplace
transform of Equation 12.8.43,

Ls + R + 1
Cs

I(s) = LI(0) −Q(0)
Cs .
(12.8.44)
Solving for I(s),
I(s) =
Q0
Cs(Ls + R + 1/Cs) =
ω2
0Q0
s2 + 2αs + ω2
0
=
ω2
0Q0
(s + α)2 + ω2
0 −α2 ,
(12.8.45)
where α = R/(2L), and ω2
0 = 1/(LC). From the ﬁrst shifting theorem,
I(t) = ω2
0Q0
ω
e−αt sin(ωt),
(12.8.46)
where ω2 = ω2
0 −α2 > 0. The quantity ω is the natural frequency of the circuit, which
is lower than the free frequency ω0 of a circuit formed by a condenser and coil.
Most
importantly, the solution decays in amplitude with time.
Although Kelvin’s solution was of academic interest when he originally published it,
this radically changed with the advent of radio telegraphy20 because the LCR circuit de-
scribed the fundamental physical properties of wireless transmitters and receivers.21 The
19 Thomson, W., 1853: On transient electric currents. Philos. Mag., Ser. 4, 5, 393–405.
20 Stone, J S., 1914: The resistance of the spark and its eﬀect on the oscillations of electrical oscillators.
Proc. IRE, 2, 307–324.
21 See Hogan, J. L., 1916: Physical aspects of radio telegraphy. Proc. IRE, 4, 397–420.

The Laplace Transform
605
C
L
I
R
Figure 12.8.2: Schematic of a LCR circuit.
inescapable conclusion from numerous analyses was that no matter how cleverly the re-
ceiver was designed, eventually the resistance in the circuit would dampen the electrical
oscillations and thus limit the strength of the received signal.
This technical problem was overcome by Armstrong,22 who invented an electrical circuit
that used De Forest’s audion (the ﬁrst vacuum tube) for generating electrical oscillations
and for amplifying externally impressed oscillations by “regenerative action.” The eﬀect of
adding the “thermionic ampliﬁer” is seen by again considering the LRC circuit as shown in
Figure 12.8.3 with the modiﬁcation suggested by Armstrong.23
The governing equations of this new circuit are
L1
dI
dt + RI + 1
C
Z t
0
I dτ + M dIp
dt = 0,
(12.8.47)
and
L2
dIp
dt + R0Ip + M dI
dt + µ
C
Z t
0
I dτ = 0,
(12.8.48)
where the plate circuit has the current Ip, the resistance R0, the inductance L2, and the
electromotive force (emf) of µ
R t
0 I dτ/C. The mutual inductance between the two circuits
is given by M. Taking the Laplace transform of Equation 12.8.47 and Equation 12.8.48,
L1sI(s) + RI(s) + I(s)
sC + MsIp(s) = Q0
sC ,
(12.8.49)
and
L2sIp(s) + R0Ip(s) + MsI(s) + µ
sC I(s) = 0.
(12.8.50)
Eliminating Ip(s) between Equation 12.8.49 and Equation 12.8.50 and solving for I(s),
I(s) =
(L2s + R0)Q0
(L1L2 −M 2)Cs3 + (RL2 + R0L1)Cs2 + (L2 + CRR0 −µM)s + R0
.
(12.8.51)
22 Armstrong, E. H., 1915: Some recent developments in the audion receiver. Proc. IRE, 3, 215–247.
23 See Ballantine, S., 1919: The operational characteristics of thermionic ampliﬁers.
Proc.
IRE, 7,
129–161.

606
Advanced Engineering Mathematics with MATLAB
R
I
M
L2
Ip
L1
C
Figure 12.8.3: Schematic of an LCR circuit with the addition of a thermionic ampliﬁer. (From Ballantine,
S., 1919: The operational characteristics of thermionic ampliﬁers. Proc. IRE, 7, 155.)
For high-frequency radio circuits, we can approximate the roots of the denominator of
Equation 12.8.51 as
s1 ≈−
R0
L2 + CRR0 −µM ,
(12.8.52)
and
s2,3 ≈
R0
2(L2 + CRR0 −µM) −R0L1 + RL2
2(L1L2 −M 2) ± iω.
(12.8.53)
In the limit of M and R0 vanishing, we recover our previous result for the LRC circuit.
However, in reality, R0 is very large and our solution has three terms. The term associated
with s1 is a rapidly decaying transient while the s2 and s3 roots yield oscillatory solutions
with a slight amount of damping. Thus, our analysis shows that in the ordinary regenerative
circuit, the tube eﬀectively introduces suﬃcient “negative” resistance so that the resultant
positive resistance of the equivalent LCR circuit is relatively low, and the response of an
applied signal voltage at the resonant frequency of the circuit is therefore relatively great.
Later, Armstrong24 extended his work on regeneration by introducing an electrical circuit
- the superregenerative circuit - where the regeneration is made large enough so that the
resultant resistance is negative, and self-sustained oscillations can occur.25
It was this
circuit26 that led to the explosive development of radio in the 1920s and 1930s.
⊓⊔
• Example 12.8.9: Resonance transformer circuit
One of the fundamental electrical circuits of early radio telegraphy27 is the resonance
transformer circuit shown in Figure 12.8.4. Its development gave transmitters and receivers
the ability to tune to each other.
The governing equations follow from Kirchhoﬀ’s law and are
L1
dI1
dt + M dI2
dt + 1
C1
Z t
0
I1 dτ = E(t),
(12.8.54)
24 Armstrong, E. H., 1922: Some recent developments of regenerative circuits. Proc. IRE, 10, 244–260.
25 See Frink, F. W., 1938: The basic principles of superregenerative reception. Proc. IRE, 26, 76–106.
26 Lewis, T., 1991: Empire of the Air: The Men Who Made Radio. HarperCollins Publishers, 421 pp.
27 Fleming, J. A., 1919: The Principles of Electric Wave Telegraphy and Telephony. Longmans, Green,
911 pp.

The Laplace Transform
607
I
I
E(t)
L
L
R
1
2
M
1
2
C1
2
C
primary
secondary
Figure 12.8.4: Schematic of a resonance transformer circuit.
and
M dI1
dt + L2
dI2
dt + RI2 + 1
C2
Z t
0
I2 dτ = 0.
(12.8.55)
Let us examine the oscillations generated if initially the system has no currents or charges
and the forcing function is E(t) = δ(t).
Taking the Laplace transform of Equation 12.8.54 and Equation 12.8.55,
L1sI1 + MsI2 + I1
sC1
= 1,
(12.8.56)
and
MsI1 + L2sI2 + RI2 + I2
sC2
= 0.
(12.8.57)
Because the current in the second circuit is of greater interest, we solve for I2 and ﬁnd that
I2(s) = −
Ms3
L1L2[(1 −k2)s4 + 2αω2
2s3 + (ω2
1 + ω2
2)s2 + 2αω2
1s + ω2
1ω2
2],
(12.8.58)
where α = R/(2L2), ω2
1 = 1/(L1C1), ω2
2 = 1/(L2C2), and k2 = M 2/ (L1L2), the so-called
coeﬃcient of coupling.
We can obtain analytic solutions if we assume that the coupling is weak (k2 ≪1).
Equation 12.8.58 becomes
I2 = −
Ms3
L1L2(s2 + ω2
1)(s2 + 2αs + ω2
2).
(12.8.59)
Using partial fractions and inverting term by term, we ﬁnd that
I2(t) =
M
L1L2

2αω3
1 sin(ω1t)
(ω2
2 −ω2
1)2 + 4α2ω2
1
+ ω2
1(ω2
2 −ω2
1) cos(ω1t)
(ω2
2 −ω2
1)2 + 4α2ω2
1
(12.8.60)
+ αω4
2 −3αω2
1ω2
2 + 4α3ω2
1
(ω2
2 −ω2
1)2 + 4α2ω2
1
e−αt sin(ωt)
ω
−ω2
2(ω2
2 −ω2
1) + 4α2ω2
1
(ω2
2 −ω2
1)2 + 4α2ω2
1
e−αt cos(ωt)

,

608
Advanced Engineering Mathematics with MATLAB
0.0
0.5
1.0
1.5
2.0
r
0.0
2.0
4.0
6.0
8.0
10.0
amplitude
Figure 12.8.5: The resonance curve 1/
p
(r2 −1)2 + 0.01 for a resonance transformer circuit with r =
ω2/ω1.
where ω2 = ω2
2 −α2.
The exponentially damped solutions will eventually disappear, leaving only the steady-
state oscillations that vibrate with the angular frequency ω1, the natural frequency of the
primary circuit. If we rewrite this steady-state solution in amplitude/phase form, the am-
plitude is
M
L1L2
p
(r2 −1)2 + 4α2/ω2
1
,
(12.8.61)
where r = ω2/ω1. As Figure 12.8.5 shows, as r increases from zero to two, the amplitude
rises until a very sharp peak occurs at r = 1 and then decreases just as rapidly as we
approach r = 2. Thus, the resonance transformer circuit provides a convenient way to tune
a transmitter or receiver to the frequency ω1.
⊓⊔
• Example 12.8.10: Delay diﬀerential equation
Laplace transforms provide a valuable tool in solving a general class of ordinary dif-
ferential equations called delay diﬀerential equations. These equations arise in such diverse
ﬁelds as chemical kinetics28 and population dynamics.29
To illustrate the technique,30 consider the diﬀerential equation
x′ = −ax(t −1)
(12.8.62)
with x(t) = 1 −at for 0 < t < 1. Clearly, x(0) = 1.
Multiplying Equation 12.8.62 by e−st and integrating from 1 to ∞,
Z ∞
1
x′(t)e−st dt = −a
Z ∞
1
x(t −1)e−st dt
(12.8.63)
28 See Roussel, M. R., 1996: The use of delay diﬀerential equations in chemical kinetics. J. Phys. Chem.,
100, 8323–8330.
29 See the ﬁrst chapter of MacDonald, N., 1989: Biological Delay Systems: Linear Stability Theory.
Cambridge University Press, 235 pp.
30 See Epstein, I. R., 1990: Diﬀerential delay equations in chemical kinetics: Some simple linear model
systems. J. Chem. Phys., 92, 1702–1712.

The Laplace Transform
609
0
5
10
0
0.5
1
1.5
2
−6
−4
−2
0
2
4
 a
 t
 x(t)
Figure 12.8.6: The solution to the delay diﬀerential equation, Equation 12.8.62, at various times t and
values of a.
Z ∞
0
x′(t)e−st dt −
Z 1
0
x′(t)e−st dt = −a
Z ∞
0
x(τ)e−s(τ+1) dτ
(12.8.64)
sX(s) −1 + a
Z 1
0
e−st dt = −ae−sX(s)
(12.8.65)
sX(s) −1 −a
s e−st1
0 = −ae−sX(s)
(12.8.66)
since x′(t) = −a for 0 < t < 1. Solving for X(s),
X(s) = (1 + ae−s/s −a/s)/[s(1 + ae−s/s)].
(12.8.67)
To facilitate the inversion of Equation 12.8.67, we expand its denominator in terms of a
geometric series and ﬁnd that
X(s) =
∞
X
n=0
(−a)ne−ns/sn+1 +
∞
X
n=0
(−a)n+1e−ns/sn+2 −
∞
X
n=0
(−a)n+1e−(n+1)s/sn+2.
(12.8.68)
The ﬁrst and third sums cancel, except for the n = 0 term in the ﬁrst sum. Therefore,
X(s) = 1
s +
∞
X
n=0
(−a)n+1e−ns/sn+2
(12.8.69)
and
x(t) = 1 +
∞
X
n=0
(−a)n+1
(n + 1)! H(t −n)(t −n)n+1.
(12.8.70)
Figure 12.8.6 illustrates Equation 12.8.70 as a function of time for various values of
a. For 0 < a < e−1, x(t) decays monotonically from 1 to an asymptotic limit of zero.
For e−1 < a < π/2, the solution is a damped oscillatory function. If π/2 < a, then x(t)
is oscillatory with an exponentially increasing envelope.
When a = π/2, x(t) oscillates
periodically.
⊓⊔

610
Advanced Engineering Mathematics with MATLAB
• Example 12.8.11
Laplace transforms can sometimes be used to solve ordinary diﬀerential equations where
the coeﬃcients are powers of t. To illustrate this, let us solve
y′′ + 2ty′ −4y = 0,
y(0) = 1,
lim
t→∞y(t) →0.
(12.8.71)
We begin by taking the Laplace transform of Equation 12.8.71 and ﬁnd that
s2Y (s) −sy(0) −y′(0) −2 d
ds[sY (s) −y(0)] −4Y (s) = 0.
(12.8.72)
An interesting aspect of this problem is the fact that we do not know y′(0). To circumvent
this diﬃculty, let us temporarily set y′(0) = −A so that Equation 12.8.72 becomes
dY
ds +
3
s −s
2

Y = A
2s −1
2.
(12.8.73)
Later on, we will ﬁnd A.
Equation 12.8.73 is a ﬁrst-order, linear, ordinary diﬀerential equation with s as its
independent variable. To ﬁnd Y (s), we use the standard technique of multiplying it by its
integrating factor, here µ(s) = s3e−s2/4, and rewriting it as
d
ds
h
s3e−s2/4Y (s)
i
= 1
2As2e−s2/4 −1
2s3e−s2/4.
(12.8.74)
Integrating Equation 12.8.74 from s to ∞, we obtain
s3e−s2/4Y (s) = (s2 + 4)e−s2/4 −A
h
se−s2/4 + √π erfc(s/2)
i
,
(12.8.75)
or
Y (s) = 4
s3 + 1
s −A
s2 −A√π
s3
es2/4 erfc(s/2).
(12.8.76)
We must now evaluate A. From the ﬁnal-value theorem, limt→∞y(t) = lims→0 sY (s) =
0. Therefore, multiplying Equation 12.8.76 by s and using the expansion for the comple-
mentary error function for small s, we have that
sY (s) = 4
s2 + 1 −A
s −A√π
s2

1 + s2
4 −
s
√π + · · ·

.
(12.8.77)
In order that lims→0 sY (s) = 0, A = 4/√π. Therefore,
Y (s) = 4
s3 + 1
s −
4
√π s2 −4
s3 es2/4 erfc(s/2).
(12.8.78)
The ﬁnal step is to invert Equation 12.8.78.
Applying tables and the convolution
theorem,
y(t) = 2t2 + 1 −4t
√π −4
√π
Z t
0
(t −x)2e−x2 dx = (2t2 + 1)[1 −erf(t)] −2t
√π e−t2. (12.8.79)

The Laplace Transform
611
Problems
Solve the following ordinary diﬀerential equations by Laplace transforms. Then use MATLAB
to verify your solution.
1.
y′ −2y = 1 −t;
y(0) = 1
2.
y′′ −4y′ + 3y = et;
y(0) = 0, y′(0) = 0
3.
y′′ −4y′ + 3y = e2t;
y(0) = 0, y′(0) = 1
4.
y′′ −6y′ + 8y = et;
y(0) = 3, y′(0) = 9
5.
y′′ + 4y′ + 3y = e−t;
y(0) = 1, y′(0) = 1
6.
y′′ + y = t;
y(0) = 1, y′(0) = 0
7.
y′′ + 4y′ + 3y = et;
y(0) = 0, y′(0) = 2
8.
y′′ −4y′ + 5y = 0;
y(0) = 2, y′(0) = 4
9.
y′ + y = tH(t −1);
y(0) = 0
10.
y′′ + 3y′ + 2y = H(t −1);
y(0) = 0, y′(0) = 1
11.
y′′ −3y′ + 2y = H(t −1);
y(0) = 0, y′(0) = 1
12.
y′′ + 4y = 3H(t −4);
y(0) = 1, y′(0) = 0
13.
y′′ + 4y′ + 4y = 4H(t −2);
y(0) = 0, y′(0) = 0
14.
y′′ + 3y′ + 2y = et−1H(t −1);
y(0) = 0, y′(0) = 1
15.
y′′ −3y′ + 2y = e−(t−2)H(t −2);
y(0) = 0, y′(0) = 0
16.
y′′ −3y′ + 2y = H(t −1) −H(t −2);
y(0) = 0, y′(0) = 0
17.
y′′ + y = 1 −H(t −T);
y(0) = 0, y′(0) = 0
18.
y′′ + y =

sin(t),
0 ≤t ≤π,
0,
π ≤t;
y(0) = 0, y′(0) = 0
19.
y′′ + 3y′ + 2y =

t,
0 ≤t ≤a,
ae−(t−a),
a ≤t;
y(0) = 0, y′(0) = 0
20.
y′′ + ω2y =



t/a,
0 ≤t ≤a,
1 −(t −a)/(b −a),
a ≤t ≤b,
0,
b ≤t;
y(0) = 0, y′(0) = 0
21.
y′′ −2y′ + y = 3δ(t −2);
y(0) = 0, y′(0) = 1

612
Advanced Engineering Mathematics with MATLAB
22.
y′′ −5y′ + 4y = δ(t −1);
y(0) = 0, y′(0) = 0
23.
y′′ + 5y′ + 6y = 3δ(t −2) −4δ(t −5);
y(0) = y′(0) = 0
24.
y′′ + ωy′ = Aδ(t −τ) −BH(t −τ);
y(0) = y′(0) = 0
25.
x′ −2x + y = 0,
y′ −3x −4y = 0;
x(0) = 1, y(0) = 0
26.
x′ −2y′ = 1,
x′ + y −x = 0;
x(0) = y(0) = 0
27.
x′ + 2x −y′ = 0,
x′ + y + x = t2;
x(0) = y(0) = 0
28.
x′ + 3x −y = 1,
x′ + y′ + 3x = 0;
x(0) = 2, y(0) = 0
29.
Forster, Escobal, and Lieske31 used Laplace transforms to solve the linearized equa-
tions of motion of a vehicle in a gravitational ﬁeld created by two other bodies. A simpliﬁed
form of this problem involves solving the following system of ordinary diﬀerential equations:
x′′ −2y′ = F1 + x + 2y,
2x′ + y′′ = F2 + 2x + 3y,
subject to the initial conditions that x(0) = y(0) = x′(0) = y′(0) = 0. Find the solution to
this system.
Use Laplace transforms to ﬁnd the solution for the following ordinary diﬀerential equations:
30. y′′ + 2ty′ −8y = 0,
y(0) = 1,
y′(0) = 0
Step 1: Show that the Laplace transform for this diﬀerential equation is 2sY ′(s) + (10 −
s2)Y (s) = −s.
Step 2: Solve these ﬁrst-order ordinary diﬀerential equations and show that Y (s) = 1/s +
8/s3 + 32/s5 + Aes2/4/s5.
Step 3: Invert Y (s) and show that the general solution is y(t) = 1 + 4t2 + 4t4/3.
31. y′′ −ty′ + 2y = 0,
y(0) = −1,
y′(0) = 0
Step 1: Show that the Laplace transform for this diﬀerential equation is sY ′(s) + (s2 +
3)Y (s) = −s.
Step 2: Solve the ﬁrst-order ordinary diﬀerential equations and show that Y (s) = (A −
2)e−s2/2/s3 + 2/s3 −1/s.
Step 3: Invert Y (s) and show that the general solution is y(t) = t2 −1.
32. ty′′ −(2 −t)y′ −y = 0
Step 1: Show that the Laplace transform for this diﬀerential equation is s(s + 1)Y ′(s) +
2(2s + 1)Y (s) = 3y(0).
Step 2: Solve the ﬁrst-order ordinary diﬀerential equation and show that Y (s) = y(0)/
(s + 1) + y(0)/[2(s + 1)2] + A/[s2(s + 1)2].
Step 3: Invert Y (s) and show that the general solution is y(t) = C1(t + 2)e−t + C2(t −2).
31 Forster, K., P. R. Escobal, and H. A. Lieske, 1968: Motion of a vehicle in the transition region of the
three-body problem. Astronaut. Acta, 14, 1–10.

The Laplace Transform
613
33. ty′′ −2(a + bt)y′ + b(2a + bt)y = 0,
a ≥0
Step 1: Show that the Laplace transform for this diﬀerential equation is (s −b)2Y ′(s) +
2(1 + a)(s −b)Y (s) = (1 + 2a)y(0).
Step 2: Solve the ﬁrst-order ordinary diﬀerential equation and show that Y (s) = y(0)/(s −
b) + A/(s −b)2+2a.
Step 3: Invert Y (s) and show that the general solution is y(t) = C1ebt + C2t2a+1ebt.
12.9 INVERSION BY CONTOUR INTEGRATION
In Section 12.5 and Section 12.6 we showed how we can use partial fractions and
convolution to ﬁnd the inverse of the Laplace transform F(s). In many instances these
methods fail simply because of the complexity of the transform to be inverted. In this
section we shall show how we can invert transforms through the powerful method of contour
integration. Of course, the student must be proﬁcient in the use of complex variables.
Consider the piece-wise diﬀerentiable function f(x), which vanishes for x < 0. We can
express the function e−cxf(x) by the complex Fourier representation of
f(x)e−cx = 1
2π
Z ∞
−∞
eiωx
Z ∞
0
e−ctf(t)e−iωt dt

dω,
(12.9.1)
for any value of the real constant c, where the integral
I =
Z ∞
0
e−ct|f(t)| dt
(12.9.2)
exists. By multiplying both sides of Equation 12.9.1 by ecx and bringing it inside the ﬁrst
integral,
f(x) = 1
2π
Z ∞
−∞
e(c+ωi)x
Z ∞
0
f(t)e−(c+ωi)t dt

dω.
(12.9.3)
With the substitution z = c + ωi, where z is a new, complex variable of integration,
f(x) =
1
2πi
Z c+∞i
c−∞i
ezx
Z ∞
0
f(t)e−zt dt

dz.
(12.9.4)
The quantity inside the square brackets is the Laplace transform F(z). Therefore, we can
express f(t) in terms of its transform by the complex contour integral
f(t) =
1
2πi
Z c+∞i
c−∞i
F(z)etzdz.
(12.9.5)
This line integral, the Bromwich integral,32 runs along the line x = c parallel to the imagi-
nary axis and c units to the right of it, the so-called Bromwich contour. We select the value
32 Bromwich, T. J. I’A., 1916: Normal coordinates in dynamical systems. Proc. London Math. Soc.,
Ser. 2, 15, 401–448.

614
Advanced Engineering Mathematics with MATLAB
An outstanding mathematician at Cambridge University at the turn of the twentieth century,
Thomas John I’Anson Bromwich (1875–1929) came to Heaviside’s operational calculus through
his interest in divergent series. Beginning a correspondence with Heaviside, Bromwich was able to
justify operational calculus through the use of contour integrals by 1915. After his premature death,
individuals such as J. R. Carson and Sir H. Jeﬀreys brought Laplace transforms to the increasing
attention of scientists and engineers. (Portrait courtesy of the Royal Society of London.)
of c suﬃciently large so that the integral, Equation 12.9.2, exists; subsequent analysis shows
that this occurs when c is larger than the real part of any of the singularities of F(z).
We must now evaluate the contour integral.
Because of the power of the residue
theorem in complex variables, the contour integral is usually transformed into a closed
contour through the use of Jordan’s lemma. See Section 11.4, Equations 11.4.9 and Equation
11.4.10. The following examples will illustrate the proper use of Equation 12.9.5.
• Example 12.9.1
Let us invert
F(s) =
e−3s
s2(s −1).
(12.9.6)
From Bromwich’s integral,
f(t) =
1
2πi
Z c+∞i
c−∞i
e(t−3)z
z2(z −1) dz =
1
2πi
I
C
e(t−3)z
z2(z −1) dz −
1
2πi
Z
CR
e(t−3)z
z2(z −1) dz,
(12.9.7)
where CR is a semicircle of inﬁnite radius in either the right or left half of the z-plane and
C is the closed contour that includes CR and Bromwich’s contour. See Figure 12.9.1.

The Laplace Transform
615
t > 3
(c,0)
t < 3
Figure 12.9.1: Contours used in the inversion of Equation 12.9.6.
Our ﬁrst task is to choose an appropriate contour so that the integral along CR vanishes.
By Jordan’s lemma this requires a semicircle in the right half-plane if t −3 < 0 and a
semicircle in the left half-plane if t−3 > 0. Consequently, by considering these two separate
cases, we force the second integral in Equation 12.9.7 to zero and the inversion simply equals
the closed contour.
Consider the case t < 3 ﬁrst. Because Bromwich’s contour lies to the right of any
singularities, there are no singularities within the closed contour and f(t) = 0.
Consider now the case t > 3. Within the closed contour in the left half-plane, there is
a second-order pole at z = 0 and a simple pole at z = 1. Therefore,
f(t) = Res
 e(t−3)z
z2(z −1); 0

+ Res
 e(t−3)z
z2(z −1); 1

,
(12.9.8)
where
Res
 e(t−3)z
z2(z −1); 0

= lim
z→0
d
dz

z2 e(t−3)z
z2(z −1)

= lim
z→0
(t −3)e(t−3)z
z −1
−e(t−3)z
(z −1)2

= 2 −t,
(12.9.9)
and
Res
 e(t−3)z
z2(z −1); 1

= lim
z→1 (z −1) e(t−3)z
z2(z −1) = et−3.
(12.9.10)
Taking our earlier results into account, the inverse equals
f(t) =

et−3 −(t −3) −1

H(t −3),
(12.9.11)
which we would have obtained from the second shifting theorem and tables.
⊓⊔

616
Advanced Engineering Mathematics with MATLAB
-
(c,0)
πi/a
πi/a
2πi/a
2πi/a
3πi/a
3πi/a
-
-
Figure 12.9.2: Contours used in the inversion of Equation 12.9.12.
• Example 12.9.2
For our second example of the inversion of Laplace transforms by complex integration,
let us ﬁnd the inverse of
F(s) =
1
s sinh(as),
(12.9.12)
where a is real. From Bromwich’s integral,
f(t) =
1
2πi
Z c+∞i
c−∞i
etz
z sinh(az) dz.
(12.9.13)
Here c is greater than the real part of any of the singularities in Equation 12.9.12. Using
the inﬁnite product for the hyperbolic sine,33
etz
z sinh(az) =
etz
az2[1 + a2z2/π2][1 + a2z2/(4π2)][1 + a2z2/(9π2)] · · ·.
(12.9.14)
Thus, we have a second-order pole at z = 0 and simple poles at zn = ±nπi/a, where
n = 1, 2, 3, . . ..
We can convert the line integral Equation 12.9.13, with the Bromwich contour lying
parallel and slightly to the right of the imaginary axis, into a closed contour using Jordan’s
lemma through the addition of an inﬁnite semicircle joining i∞to −i∞, as shown in Figure
12.9.2. We now apply the residue theorem. For the second-order pole at z = 0,
Res

etz
z sinh(az); 0

= 1
1! lim
z→0
d
dz
(z −0)2etz
z sinh(az)

= lim
z→0
d
dz

zetz
sinh(az)

(12.9.15)
= lim
z→0

etz
sinh(az) +
ztetz
sinh(az) −az cosh(az)etz
sinh2(az)

= t
a
(12.9.16)
33 Gradshteyn, I. S., and I. M. Ryzhik, 1965: Table of Integrals, Series and Products. Academic Press,
Section 1.431, Formula 2.

The Laplace Transform
617
after using sinh(az) = az + O(z3). For the simple poles zn = ±nπi/a,
Res

etz
z sinh(az); zn

= lim
z→zn
(z −zn)etz
z sinh(az) = lim
z→zn
etz
sinh(az) + az cosh(az)
(12.9.17)
= exp(±nπit/a)
(−1)n(±nπi) ,
(12.9.18)
because cosh(±nπi) = cos(nπ) = (−1)n. Thus, summing up all of the residues gives
f(t) = t
a +
∞
X
n=1
(−1)n exp(nπit/a)
nπi
−
∞
X
n=1
(−1)n exp(−nπit/a)
nπi
(12.9.19)
= t
a + 2
π
∞
X
n=1
(−1)n
n
sin(nπt/a).
(12.9.20)
⊓⊔
In addition to computing the inverse of Laplace transforms, Bromwich’s integral places
certain restrictions on F(s) in order that an inverse exists. If α denotes the minimum value
that c may possess, the restrictions are threefold.34 First, F(z) must be analytic in the
half-plane x ≥α, where z = x + iy. Second, in the same half-plane it must behave as z−k,
where k > 1. Finally, F(x) must be real when x ≥α.
• Example 12.9.3
Is the function sin(s)/(s2 + 4) a proper Laplace transform? Although the function
satisﬁes the ﬁrst and third criteria listed in the previous paragraph on the half-plane x > 2,
the function becomes unbounded as y →±∞for any ﬁxed x > 2. Thus, sin(s)/(s2 + 4)
cannot be a Laplace transform.
⊓⊔
• Example 12.9.4
An additional beneﬁt of understanding inversion by the residue method is the ability
to qualitatively anticipate the inverse by knowing the location of the poles of F(s). This
intuition is important because many engineering analyses discuss stability and performance
entirely in terms of the properties of the system’s Laplace transform. In Figure 12.9.3 we
have graphed the location of the poles of F(s) and the corresponding f(t). The student
should go through the mental exercise of connecting the two pictures.
Problems
Use Bromwich’s integral to invert the following Laplace transforms:
1. F(s) =
s + 1
(s + 2)2(s + 3)
2. F(s) =
1
s2(s + a)2
34 For the proof, see Churchill, R. V., 1972: Operational Mathematics. McGraw-Hill, Section 67.

618
Advanced Engineering Mathematics with MATLAB
t
f(t)
f(t)
s-plane
s-plane
t
t
f(t)
f(t)
s-plane
s-plane
t
t
f(t)
f(t)
s-plane
s-plane
t
Figure 12.9.3: The correspondence between the location of the simple poles of the Laplace transform F(s)
and the behavior of f(t).

The Laplace Transform
619
3. F(s) =
1
s(s −2)3
4. F(s) =
1
s(s + a)2(s2 + b2)
5. F(s) =
e−s
s2(s + 2)
6. F(s) =
1
s(1 + e−as)
7. F(s) =
1
(s + b) cosh(as)
8. F(s) =
1
s(1 −e−as)
9. Consider a function f(t) that has the Laplace transform F(z), which is analytic in the
half-plane Re(z) > s0. Can we use this knowledge to ﬁnd g(t), whose Laplace transform
G(z) equals F[ϕ(z)], where ϕ(z) is also analytic for Re(z) > s0? The answer to this question
leads to the Schouten35–Van der Pol36 theorem.
Step 1: Show that the following relationships hold true:
G(z) = F[ϕ(z)] =
Z ∞
0
f(τ)e−ϕ(z)τ dτ,
and
g(t) =
1
2πi
Z c+∞i
c−∞i
F[ϕ(z)]etz dz.
Step 2: Using the results from Step 1, show that
g(t) =
Z ∞
0
f(τ)
 1
2πi
Z c+∞i
c−∞i
e−ϕ(z)τetz dz

dτ.
This is the Schouten-Van der Pol theorem.
Step 3: If G(z) = F(√z ) show that
g(t) =
1
2
√
πt3
Z ∞
0
τf(τ) exp

−τ 2
4t

dτ.
Hint: Do not evaluate the contour integral. Instead, ask yourself: What function of time
has a Laplace transform that equals e−ϕ(z)τ, where τ is a parameter? Then use tables.
12.10 THE SOLUTION OF THE WAVE EQUATION
The solution of linear partial diﬀerential equations by Laplace transforms is the most
commonly employed analytic technique after separation of variables. Because the transform
consists solely of an integration with respect to time, the transform U(x, s) of the solution
of the wave equation u(x, t) is
U(x, s) =
Z ∞
0
u(x, t)e−st dt,
(12.10.1)
assuming that the wave equation only varies in a single spatial variable x and time t.
35 Schouten, J. P., 1935: A new theorem in operational calculus together with an application of it.
Physica, 2, 75–80.
36 Van der Pol, B., 1934: A theorem on electrical networks with applications to ﬁlters.
Physica, 1,
521–530.

620
Advanced Engineering Mathematics with MATLAB
Partial derivatives involving time have transforms similar to those that we encountered
in the case of functions of a single variable. They include
L[ut(x, t)] = sU(x, s) −u(x, 0),
(12.10.2)
and
L[utt(x, t)] = s2U(x, s) −su(x, 0) −ut(x, 0).
(12.10.3)
These transforms introduce the initial conditions via u(x, 0) and ut(x, 0). On the other
hand, derivatives involving x become
L[ux(x, t)] = d
dx {L[u(x, t)]} = dU(x, s)
dx
,
(12.10.4)
and
L[uxx(x, t)] = d2
dx2 {L[u(x, t)]} = d2U(x, s)
dx2
.
(12.10.5)
Because the transformation eliminates the time variable, only U(x, s) and its derivatives
remain in the equation. Consequently, we transform the partial diﬀerential equation into a
boundary-value problem involving an ordinary diﬀerential equation. Because this equation
is often easier to solve than a partial diﬀerential equation, the use of Laplace transforms
considerably simpliﬁes the original problem. Of course, the Laplace transforms must exist
for this technique to work.
The following schematic summarizes the Laplace transform method:
solution of boundary-value
Inverse transform
solution to original problem
partial differential equation
+ initial conditions
+ boundary conditions
ordinary differential equation
+ boundary conditions
problem
Laplace transform
In the following examples, we illustrate transform methods by solving the classic equa-
tion of telegraphy as it applies to a uniform transmission line. The line has a resistance R,
an inductance L, a capacitance C, and a leakage conductance G per unit length. We denote
the current in the direction of positive x by I; V is the voltage drop across the transmission
line at the point x. The dependent variables I and V are functions of both distance x along
the line and time t.
To derive the diﬀerential equations that govern the current and voltage in the line,
consider the points A at x and B at x + ∆x in Figure 12.10.1. The current and voltage
at A are I(x, t) and V (x, t); at B, I + ∂I
∂x∆x and V + ∂V
∂x ∆x. Therefore, the voltage drop
from A to B is −∂V
∂x ∆x and the current in the line is I + ∂I
∂x∆x. Neglecting terms that are
proportional to (∆x)2,

L∂I
∂t + RI

∆x = −∂V
∂x ∆x.
(12.10.6)

The Laplace Transform
621
x
K
H
L
R
B
V+
C
A
x
x
∆x
1 ∆x
∆x
∆
I
+∆
x
δ I
δ x
δ V
δ x
+
I
δ
δ x
I
x
∆x
∆
G
V
Figure 12.10.1: Schematic of a uniform transmission line.
The voltage drop over the parallel portion HK of the line is V while the current in this
portion of the line is −∂I
∂x∆x. Thus,

C ∂V
∂t + GV

∆x = −∂I
∂x∆x.
(12.10.7)
Therefore, the diﬀerential equations for I and V are
L∂I
∂t + RI = −∂V
∂x ,
(12.10.8)
and
C ∂V
∂t + GV = −∂I
∂x.
(12.10.9)
Turning to the initial conditions, we solve these simultaneous partial diﬀerential equa-
tions with the initial conditions
I(x, 0) = I0(x),
(12.10.10)
and
V (x, 0) = V0(x)
(12.10.11)
for 0 < t. There are also boundary conditions at the ends of the line; we will introduce
them for each speciﬁc problem. For example, if the line is short-circuited at x = a, V = 0
at x = a; if there is an open circuit at x = a, I = 0 at x = a.
To solve Equation 12.10.8 and Equation 12.10.9 by Laplace transforms, we take the
Laplace transform of both sides of these equations, which yields
(Ls + R)I(x, s) = −dV (x, s)
dx
+ LI0(x),
(12.10.12)
and
(Cs + G)V (x, s) = −dI(x, s)
dx
+ CV0(x).
(12.10.13)
Eliminating I gives an ordinary diﬀerential equation in V
d2V
dx2 −q2V = LdI0(x)
dx
−C(Ls + R)V0(x),
(12.10.14)

622
Advanced Engineering Mathematics with MATLAB
where q2 = (Ls + R)(Cs + G). After ﬁnding V , we may compute I from
I = −
1
Ls + R
dV
dx + LI0(x)
Ls + R.
(12.10.15)
At this point we treat several classic cases.
• Example 12.10.1: The semi-inﬁnite transmission line
We consider the problem of a semi-inﬁnite line 0 < x with no initial current and charge.
The end x = 0 has a constant voltage E for 0 < t.
In this case,
d2V
dx2 −q2V = 0,
0 < x.
(12.10.16)
The boundary conditions at the ends of the line are
V (0, t) = E,
0 < t,
(12.10.17)
and V (x, t) is ﬁnite as x →∞. The transform of these boundary conditions is
V (0, s) = E/s,
and
lim
x→∞V (x, s) →0.
(12.10.18)
The general solution of Equation 12.10.16 is
V (x, s) = Ae−qx + Beqx.
(12.10.19)
The requirement that V remains ﬁnite as x →∞forces B = 0. The boundary condition at
x = 0 gives A = E/s. Thus,
V (x, s) = E
s exp
h
−
p
(Ls + R)(Cs + G) x
i
.
(12.10.20)
We discuss the general case later. However, for the so-called “lossless” line, where R = G =
0,
V (x, s) = E
s exp(−sx/c),
(12.10.21)
where c = 1/
√
LC. Consequently,
V (x, t) = EH

t −x
c

,
(12.10.22)
where H(t) is Heaviside’s step function. The physical interpretation of this solution is as
follows: V (x, t) is zero up to the time x/c at which time a wave traveling with speed c from
x = 0 would arrive at the point x. V (x, t) has the constant value E afterwards.
For the so-called “distortionless” line,37 R/L = G/C = ρ,
V (x, t) = Ee−ρx/cH

t −x
c

.
(12.10.23)
37 Prechtl and Sch¨urhuber (Prechtl, A., and R. Sch¨urhuber, 2000: Nonuniform distortionless transmission
lines. Electr. Eng. [Berlin], 82, 127–134) generalized this problem to nonuniform transmission lines.

The Laplace Transform
623
In this case, the disturbance not only propagates with velocity c but also attenuates as we
move along the line.
Suppose now, that instead of applying a constant voltage E at x = 0, we apply a
time-dependent voltage, f(t). The only modiﬁcation is that in place of Equation 12.10.20,
V (x, s) = F(s)e−qx.
(12.10.24)
In the case of the distortionless line, q = (s + ρ)/c, this becomes
V (x, s) = F(s)e−(s+ρ)x/c
(12.10.25)
and
V (x, t) = e−ρx/cf

t −x
c

H

t −x
c

.
(12.10.26)
Thus, our solution shows that the voltage at x is zero up to the time x/c. Afterwards V (x, t)
follows the voltage at x = 0 with a time lag of x/c and decreases in magnitude by e−ρx/c.⊓⊔
• Example 12.10.2: The ﬁnite transmission line
We now discuss the problem of a ﬁnite transmission line 0 < x < l with zero initial
current and charge. We ground the end x = 0 and maintain the end x = l at constant
voltage E for 0 < t.
The transformed partial diﬀerential equation becomes
d2V
dx2 −q2V = 0,
0 < x < l.
(12.10.27)
The boundary conditions are
V (0, t) = 0,
and
V (l, t) = E,
0 < t.
(12.10.28)
The Laplace transform of these boundary conditions is
V (0, s) = 0,
and
V (l, s) = E/s.
(12.10.29)
The solution of Equation 12.10.27 that satisﬁes the boundary conditions is
V (x, s) = E sinh(qx)
s sinh(ql) .
(12.10.30)
Let us rewrite Equation 12.10.30 in a form involving negative exponentials and expand the
denominator by the binomial theorem,
V (x, s) = E
s e−q(l−x) 1 −e−2qx
1 −e−2ql
(12.10.31)
= E
s e−q(l−x)(1 −e−2qx)
 1 + e−2ql + e−4ql + · · ·

(12.10.32)
= E
s

e−q(l−x) −e−q(l+x) + e−q(3l−x) −e−q(3l+x) + · · ·

.
(12.10.33)
In the special case of the lossless line where q = s/c,
V (x, s) = E
s

e−s(l−x)/c −e−s(l+x)/c + e−s(3l−x)/c −e−s(3l+x)/c + · · ·

,
(12.10.34)

624
Advanced Engineering Mathematics with MATLAB
(l-x)/c
t
E
V(x,t)
(3l-x)/c
(3l+x)/c
direct
once
twice
thrice reflected
(l+x)/c
Figure 12.10.2: The voltage within a lossless, ﬁnite transmission line of length l as a function of time t.
or
V (x, t) = E

H

t −l −x
c

−H

t −l + x
c

+ H

t −3l −x
c

−H

t −3l + x
c

+ · · ·

.
(12.10.35)
We illustrate Equation 12.10.35 in Figure 12.10.2. The voltage at x is zero up to the
time (l −x)/c, at which time a wave traveling directly from the end x = l would reach the
point x. The voltage then has the constant value E up to the time (l + x)/c, at which time
a wave traveling from the end x = l and reﬂected back from the end x = 0 would arrive.
From this time up to the time of arrival of a twice-reﬂected wave, it has the value zero, and
so on.
⊓⊔
• Example 12.10.3: The semi-inﬁnite transmission line reconsidered
In the ﬁrst example, we showed that the transform of the solution for the semi-inﬁnite
line is
V (x, s) = E
s e−qx,
(12.10.36)
where q2 = (Ls + R)(Cs + G). In the case of a lossless line (R = G = 0), we found traveling
wave solutions.
In this example, we shall examine the case of a submarine cable,38 where L = G = 0.
In this special case,
V (x, s) = E
s e−x√
s/κ,
(12.10.37)
where κ = 1/(RC).
From a table of Laplace transforms,39 we can immediately invert
Equation 12.10.37 and ﬁnd that
V (x, t) = E erfc

x
2
√
κt

,
(12.10.38)
where erfc is the complementary error function. Unlike the traveling wave solution, the
voltage diﬀuses into the cable as time increases. We illustrate Equation 12.10.38 in Figure
12.10.3.
⊓⊔
38 First solved by Thomson, W., 1855: On the theory of the electric telegraph. Proc. R. Soc. London,
Ser. A, 7, 382–399.
39 See Churchill, R. V., 1972: Operational Mathematics. McGraw-Hill Book, Section 27.

The Laplace Transform
625
1
10
100
1000
x
0.0
0.2
0.4
0.6
0.8
1.0
V(x,t)/E
κt=10
100
1000
10000
Figure 12.10.3: The voltage within a submarine cable as a function of distance for various values of κt.
• Example 12.10.4: A short-circuited, ﬁnite transmission line
Let us ﬁnd the voltage of a lossless transmission line of length l that initially has the
constant voltage E. At t = 0, we ground the line at x = 0 while we leave the end x = l
insulated.
The transformed partial diﬀerential equation now becomes
d2V
dx2 −s2
c2 V = −sE
c2 ,
(12.10.39)
where c = 1/
√
LC. The boundary conditions are
V (0, s) = 0,
(12.10.40)
and
I(l, s) = −1
Ls
dV (l, s)
dx
= 0
(12.10.41)
from Equation 12.10.15.
The solution to this boundary-value problem is
V (x, s) = E
s −E cosh[s(l −x)/c]
s cosh(sl/c)
.
(12.10.42)
The ﬁrst term on the right side of Equation 12.10.42 is easy to invert and the inversion
equals E.
The second term is much more diﬃcult to handle.
We will use Bromwich’s
integral.
In Section 12.9 we showed that
L−1
cosh[s(l −x)/c]
s cosh(sl/c)

=
1
2πi
Z c+∞i
c−∞i
cosh[z(l −x)/c]etz
z cosh(zl/c)
dz.
(12.10.43)
To evaluate this integral we must ﬁrst locate and then classify the singularities. Using the
product formula for the hyperbolic cosine,
cosh[z(l −x)/c]
z cosh(zl/c)
= [1 + 4z2(l−x)2
c2π2
][1 + 4z2(l−x)2
9c2π2
] · · ·
z[1 + 4z2l2
c2π2 ][1 + 4z2l2
9c2π2 ] · · ·
.
(12.10.44)

626
Advanced Engineering Mathematics with MATLAB
This shows that we have an inﬁnite number of simple poles located at z = 0, and zn =
±(2n −1)πci/(2l), where n = 1, 2, 3, . . .. Therefore, Bromwich’s contour can lie along, and
just to the right of, the imaginary axis. By Jordan’s lemma we close the contour with a
semicircle of inﬁnite radius in the left half of the complex plane. Computing the residues,
Res
cosh[z(l −x)/c]etz
z cosh(zl/c)
; 0

= lim
z→0
cosh[z(l −x)/c]etz
cosh(zl/c)
= 1,
(12.10.45)
and
Res
cosh[z(l −x)/c]etz
z cosh(zl/c)
; zn

= lim
z→zn
(z −zn) cosh[z(l −x)/c]etz
z cosh(zl/c)
(12.10.46)
= cosh[(2n −1)π(l −x)i/(2l)] exp[±(2n −1)πcti/(2l)]
[(2n −1)πi/2] sinh[(2n −1)πi/2]
(12.10.47)
=
2(−1)n
(2n −1)π cos
(2n −1)π(l −x)
2l

exp

±(2n −1)πcti
2l

.
(12.10.48)
Summing the residues and using the relationship that cos(t) = (eti + e−ti)/2,
V (x, t) = E −E

1 −4
π
∞
X
n=1
(−1)n+1
2n −1 cos
(2n −1)π(l −x)
2l

cos
(2n −1)πct
2l

(12.10.49)
= 4E
π
∞
X
n=1
(−1)n+1
2n −1 cos
(2n −1)π(l −x)
2l

cos
(2n −1)πct
2l

.
(12.10.50)
An alternative to contour integration is to rewrite Equation 12.10.42 as
V (x, s) = E
s
(
1 −e−sx/c 
1 + e−2s(l−x)/c
1 + e−2sl/c
#
(12.10.51)
= E
s
h
1 −e−sx/c −e−s(2l−x)/c + e−s(2l+x)/c + · · ·
i
(12.10.52)
so that
V (x, t) = E

1 −H

t −x
c

−H

t −2l −x
c

+ H

t −2l + x
c

+ · · ·

.
(12.10.53)
⊓⊔
• Example 12.10.5: The general solution of the equation of telegraphy
In this example we solve the equation of telegraphy without any restrictions on R, C,
G, or L. We begin by eliminating the dependent variable I(x, t) from the set of equations,
Equation 12.10.8 and Equation 12.10.9. This yields
CL∂2V
∂t2 + (GL + RC)∂V
∂t + RG V = ∂2V
∂x2 .
(12.10.54)

The Laplace Transform
627
We next take the Laplace transform of Equation 12.10.54 assuming that V (x, 0) = f(x),
and Vt(x, 0) = g(x). The transformed version of Equation 12.10.54 is
d2V
dx2 −[CLs2 + (GL + RC)s + RG]V = −CLg(x) −(CLs + GL + RC)f(x), (12.10.55)
or
d2V
dx2 −(s + ρ)2 −σ2
c2
V = −g(x)
c2
−
 s
c2 + 2ρ
c2

f(x),
(12.10.56)
where c2 = 1/LC, ρ = c2(RC + GL)/2, and σ = c2(RC −GL)/2.
We solve Equation 12.10.56 by Fourier transforms (see Section 11.6) with the require-
ment that the solution dies away as |x| →∞. The most convenient way of expressing this
solution is the convolution product (see Section 11.5)
V (x, s) =
g(x)
c
+
s
c + 2ρ
c

f(x)

∗exp[−|x|
p
(s + ρ)2 −σ2/c]
2
p
(s + ρ)2 −σ2
.
(12.10.57)
From a table of Laplace transforms,
L−1
"
exp
 −b
√
s2 −a2 
√
s2 −a2
#
= I0

a
p
t2 −b2

H(t −b),
(12.10.58)
where b > 0 and I0( ) is the zeroth order modiﬁed Bessel function of the ﬁrst kind. Therefore,
by the ﬁrst shifting theorem,
L−1



exp
h
−|x|
p
(s + ρ)2 −σ2/c
i
p
(s + ρ)2 −σ2


= e−ρtI0
h
σ
p
t2 −(x/c)2
i
H

t −|x|
c

. (12.10.59)
Using Equation 12.10.59 to invert Equation 12.10.57, we have that
V (x, t) =
1
2ce−ρtg(x) ∗I0
h
σ
p
t2 −(x/c)2
i
H(t −|x|/c)
+ 1
2ce−ρtf(x) ∗∂
∂t
n
I0[σ
p
t2 −(x/c)2]
o
H(t −|x|/c)
+ ρ
ce−ρtf(x) ∗I0
h
σ
p
t2 −(x/c)2
i
H(t −|x|/c)
+ 1
2e−ρt[f(x + ct) + f(x −ct)].
(12.10.60)
The last term in Equation 12.10.60 arises from noting that sF(s) = L[f(t)] + f(0). If we
explicitly write out the convolution, the ﬁnal form of the solution is
V (x, t) = 1
2e−ρt[f(x + ct) + f(x −ct)]
+ 1
2ce−ρt
Z x+ct
x−ct
[g(η) + 2ρf(η)]I0

σ
p
c2t2 −(x −η)2

c

dη
+ 1
2ce−ρt
Z x+ct
x−ct
f(η) ∂
∂t

I0

σ
p
c2t2 −(x −η)2

c

dη.
(12.10.61)

628
Advanced Engineering Mathematics with MATLAB
−10
−5
0
5
10
0
5
10
0
0.2
0.4
0.6
0.8
1
1.2
TIME
DISTANCE
SOLUTION
Figure 12.10.4: The evolution of the voltage with time given by the general equation of telegraphy for
initial conditions and parameters stated in the text.
There is a straightforward physical interpretation of the ﬁrst line of Equation 12.10.61.
It represents damped progressive waves; one is propagating to the right and the other to
the left. In addition to these progressive waves, there is a contribution from the integrals,
even after the waves pass. These integrals include all of the points where f(x) and g(x)
are nonzero within a distance ct from the point in question. This eﬀect persists through all
time, although dying away, and constitutes a residue or tail. Figure 12.10.4 illustrates this
for ρ = 0.1, σ = 0.2, and c = 1. This ﬁgure was obtained using the MATLAB script:
% initialize parameters in calculation
clear; dx = 0.1; dt = 0.5; rho over c = 0.1; sigma over c = 0.2;
X=[-10:dx:10]; T = [0:dt:10]; % compute locations of x and t
for j=1:length(T); t = T(j);
for i=1:length(X); x = X(i);
XX(i,j) = x; TT(i,j) = t; deta i = 0.05 % set up grid
% compute characteristics x+ct and x-ct
characteristic 1 = x - t; characteristic 2 = x + t;
% compute first term in Equation 12.10.61
F = inline(’stepfun(x,-1.0001)-stepfun(x,1.0001)’);
u(i,j ) = F(characteristic 1) + F(characteristic 2);
% find the upper and lower limits of the integration
upper = characteristic 2; lower = characteristic 1;
if t > 0 & upper > -1 & lower < 1
if upper > 1 upper = 1; end
if lower < -1 lower = -1; end
% set up parameters needed for integration
interval = upper-lower;
NN = interval / deta i;
if mod(NN,2) > 0 NN = NN + 1; end;

The Laplace Transform
629
deta = interval / NN;
% compute integrals in Equation 12.10.61 by Simpson’s rule
% sum1 deals with the first integral while sum2 is the second
sum1 = 0; sum2 = 0; eta = lower;
for k = 0:2:NN-2
arg = sigma over c * sqrt(t*t-(x-eta)*(x-eta));
sum1 = sum1 + besseli(0,arg);
if (arg == 0)
sum2 = sum2 + 0.5 * sigma over c * t;
else
sum2 = sum2 + t * besseli(1,arg) / arg; end
eta = eta + deta;
arg = sigma over c * sqrt(t*t-(x-eta)*(x-eta));
sum1 = sum1 + 4*besseli(0,arg);
if (arg == 0)
sum2 = sum2 + 4 * 0.5 * sigma over c * t;
else
sum2 = sum2 + 4 * t * besseli(1,arg) / arg; end
eta = eta + deta;
arg = sigma over c * sqrt(t*t-(x-eta)*(x-eta));
sum1 = sum1 + besseli(0,arg);
if (arg == 0)
sum2 = sum2 + 0.5 * sigma over c * t;
else
sum2 = sum2 + t * besseli(1,arg) / arg; end
end
u(i,j) = u(i,j) + 2 * rho over c * deta * sum1 / 3 ...
+ sigma over c * deta * sum2 / 3;
end
% multiply final answer by damping coefficient
u(i,j) = 0.5 * exp(-rho over c * t) * u(i,j);
end;end;
% plot results
mesh(XX,TT,real(u)); colormap spring;
xlabel(’DISTANCE’,’Fontsize’,20); ylabel(’TIME’,’Fontsize’,20)
zlabel(’SOLUTION’,’Fontsize’,20)
We evaluated the integrals by Simpson’s rule for the initial conditions f(x) = H(x + 1) −
H(x −1), and g(x) = 0. If there was no loss, then two pulses would propagate to the left
and right. However, with resistance and leakage the waves leave a residue after their leading
edge has passed.
Problems
1. Use transform methods to solve the wave equation
∂2u
∂t2 = ∂2u
∂x2 ,
0 < x < 1,
0 < t,
with the boundary conditions u(0, t) = u(1, t) = 0, 0 < t, and the initial conditions u(x, 0) =
0, ut(0, t) = 1, 0 < x < 1.

630
Advanced Engineering Mathematics with MATLAB
2. Use transform methods to solve the wave equation
∂2u
∂t2 = ∂2u
∂x2 ,
0 < x < 1,
0 < t,
with the boundary conditions u(0, t) = ux(1, t) = 0, 0 < t, and the initial conditions
u(x, 0) = 0, ut(0, t) = x, 0 < x < 1.
3. Use transform methods to solve the wave equation
∂2u
∂t2 = ∂2u
∂x2 ,
0 < x < 1,
0 < t,
with the boundary conditions u(0, t) = u(1, t) = 0, 0 < t, and the initial conditions u(x, 0) =
sin(πx), ut(x, 0) = −sin(πx), 0 < x < 1.
4. Use transform methods to solve the wave equation
∂2u
∂t2 = c2 ∂2u
∂x2 ,
0 < x < a,
0 < t,
with the boundary conditions u(0, t) = sin(ωt), u(a, t) = 0, 0 < t, and the initial conditions
u(x, 0) = ut(x, 0) = 0, 0 < x < a. Assume that ωa/c is not an integer multiple of π. Why?
5. Use transform methods to solve the wave equation
∂2u
∂t2 = c2 ∂2u
∂x2 ,
0 < x < L,
0 < t,
with the boundary conditions ux(0, t) = −f(t), ux(L, t) = 0, 0 < t, and the initial conditions
u(x, 0) = ut(x, 0) = 0, 0 < x < L.
Hint: Invert the Laplace transform following the
procedure used in Example 12.10.2.
6. Use transform methods to solve the wave equation
∂2u
∂t2 = c2 ∂2u
∂x2 −q′(t),
a < x < b,
0 < t,
with the boundary conditions u(a, t) = 0, ux(b, t) = 0, 0 < t, and the initial conditions
u(x, 0) = 0, ut(x, 0) = −q(0), a < x < b. Hint: To ﬁnd U(x, s), express both U(x, s) and
the right side of the ordinary diﬀerential equation governing U(x, s) in an eigenfunction
expansion using sin{(2n+1)π(x−a)/[2(b−a)]}. These eigenfunctions satisfy the boundary
conditions.
7. Use transform methods to solve the wave equation
∂2u
∂t2 −∂2u
∂x2 = te−x,
0 < x < ∞,
0 < t,
with the boundary conditions
u(0, t) = 1 −e−t,
lim
x→∞|u(x, t)| ∼xn, n ﬁnite,
0 < t,

The Laplace Transform
631
and the initial conditions u(x, 0) = 0, ut(x, 0) = x, 0 < x < ∞.
8. Use transform methods to solve the wave equation
∂2u
∂t2 −∂2u
∂x2 = xe−t,
0 < x < ∞,
0 < t,
with the boundary conditions
u(0, t) = cos(t),
lim
x→∞|u(x, t)| ∼xn, n ﬁnite,
0 < t,
and the initial conditions u(x, 0) = 1, ut(x, 0) = 0, 0 < x < ∞.
9. Use transform methods to solve the wave equation
∂2u
∂t2 = ∂2u
∂x2 ,
0 < x < L,
0 < t,
with the boundary conditions
u(0, t) = 0,
∂2u(L, t)
∂t2
+ k
m
∂u(L, t)
∂x
= g,
0 < t,
and the initial conditions u(x, 0) = ut(x, 0) = 0, 0 < x < L, where k, m, and g are constants.
10. Use transform methods40 to solve the wave equation
∂2u
∂t2 = c2 ∂
∂x

x∂u
∂x

,
0 < x < 1,
0 < t,
with the boundary conditions
lim
x→0 |u(x, t)| < ∞,
u(1, t) = A sin(ωt),
0 < t,
and the initial conditions u(x, 0) = ut(x, 0) = 0, 0 < x < 1. Assume that 2ω ̸= cβn, where
J0(βn) = 0. Hint: The ordinary diﬀerential equation
d
dx

xdU
dx

−s2
c2 U = 0
has the solution
U(x, s) = c1I0
s
c
√x

+ c2K0
s
c
√x

,
where I0(x) and K0(x) are modiﬁed Bessel functions of the ﬁrst and second kind, respec-
tively. Note that Jn(iz) = inIn(z) and In(iz) = inJn(z) for complex z.
11. A lossless transmission line of length ℓhas a constant voltage E applied to the end
x = 0 while we insulate the other end [Vx(ℓ, t) = 0]. Find the voltage at any point on the
line if the initial current and charge are zero.
40 Suggested by a problem solved by Brown, J., 1975: Stresses in towed cables during re-entry. J. Spacecr.
Rockets, 12, 524–527.

632
Advanced Engineering Mathematics with MATLAB
12. Solve the equation of telegraphy without leakage
∂2u
∂x2 = CR∂u
∂t + CL∂2u
∂t2 ,
0 < x < ℓ,
0 < t,
subject to the boundary conditions u(0, t) = 0, u(ℓ, t) = E, 0 < t, and the initial conditions
u(x, 0) = ut(x, 0) = 0, 0 < x < ℓ. Assume that 4π2L/CR2ℓ2 > 1. Why?
13. The pressure and velocity oscillations from water hammer in a pipe without friction41
are given by the equations
∂p
∂t = −ρc2 ∂u
∂x,
and
∂u
∂t = −1
ρ
∂p
∂x,
where p(x, t) denotes the pressure perturbation, u(x, t) is the velocity perturbation, c is
the speed of sound in water, and ρ is the density of water. These two ﬁrst-order partial
diﬀerential equations can be combined to yield
∂2p
∂t2 = c2 ∂2p
∂x2 .
Find the solution to this partial diﬀerential equation if p(0, t) = p0, and u(L, t) = 0, and
the initial conditions are p(x, 0) = p0, pt(x, 0) = 0, and u(x, 0) = u0.
14. Use Laplace transforms to solve the wave equation42
∂2u
∂t2 = c2
∂2u
∂r2 + 2
r
∂u
∂r −2u
r2

,
a < r < ∞,
0 < t,
subject to the boundary conditions that
u(a, t) = A

1 −e−ct/a
H(t),
lim
r→∞u(r, t) →0,
0 < t,
and the initial conditions that u(r, 0) = ut(r, 0) = 0, a < r < ∞. Hint: The homogeneous
solution to the ordinary diﬀerential equation
d2y
dr2 + 2
r
dy
dr −2y
r2 −b2y = 0
is
y(r) = C1
cosh(br)
br
−sinh(br)
b2r2

+ C2
 1
br +
1
b2r2

e−br.
15. Use Laplace transforms to solve the wave equation43
∂2(ru)
∂t2
= c2 ∂2(ru)
∂r2
,
a < r < ∞,
0 < t,
41 See Rich, G. R., 1945: Water-hammer analysis by the Laplace-Mellin transformation. Trans. ASME,
67, 361–376.
42 Wolf, J. P., and G. R. Darbre, 1986: Time-domain boundary element method in visco-elasticity with
application to a spherical cavity. Soil Dynam. Earthq. Eng., 5, 138–148.
43 Originally solved using Fourier transforms by Sharpe, J. A., 1942: The production of elastic waves by
explosion pressures. I. Theory and empirical ﬁeld observations. Geophysics, 7, 144–154.

The Laplace Transform
633
subject to the boundary conditions that
−ρc2
∂2u
∂r2 + 2
3r
∂u
∂r

r=a
= p0e−αtH(t),
lim
r→∞u(r, t) →0,
0 < t,
where α > 0, and the initial conditions that u(r, 0) = ut(r, 0) = 0, a < r < ∞.
16. Consider a vertical rod or column of length L that is supported at both ends. The
elastic waves that arise when the support at the bottom is suddenly removed are governed
by the wave equation44
∂2u
∂t2 = c2 ∂2u
∂x2 + g,
0 < x < L,
0 < t,
where g denotes the gravitational acceleration, c2 = E/ρ, E is Young’s modulus, and ρ is the
mass density. Find the wave solution if the boundary conditions are ux(0, t) = ux(L, t) = 0,
0 < t, and the initial conditions are
u(x, 0) = −gx2
2c2 ,
∂u(x, 0)
∂t
= 0,
0 < x < L.
17. Use Laplace transforms to solve the hyperbolic equation
∂2u
∂t2 −∂2u
∂x2 + 1 = 0,
0 < x < 1,
0 < t,
subject to the boundary conditions that ux(0, t) = 0, ux(1, t) = 1, 0 < t, and the initial
conditions that u(x, 0) = ut(x, 0) = 0, 0 < x < 1.
18. Solve the telegraph-like equation45
∂2u
∂t2 + k ∂u
∂t = c2
∂2u
∂x2 + α∂u
∂x

,
0 < x < ∞,
0 ≤t
subject to the boundary conditions
∂u(0, t)
∂x
= −u0δ(t),
lim
x→∞u(x, t) →0,
0 ≤t,
and the initial conditions u(x, 0) = u0, ut(x, 0) = 0, 0 < x < ∞, with αc > k.
Step 1: Take the Laplace transform of the partial diﬀerential equation and boundary con-
ditions and show that
d2U(x, s)
dx2
+ αdU(x, s)
dx
−
s2 + ks
c2

U(x, s) = −
s + k
c2

u0,
44 See Hall, L. H., 1953: Longitudinal vibrations of a vertical column by the method of Laplace transform.
Am. J. Phys., 21, 287–292.
45 See Abbott, M. R., 1959: The downstream eﬀect of closing a barrier across an estuary with particular
reference to the Thames. Proc. R. Soc. London, Ser. A, 251, 426–439.

634
Advanced Engineering Mathematics with MATLAB
with U ′(0, s) = −u0, and limx→∞U(x, s) →0.
Step 2: Show that the solution to the previous step is
U(x, s) = u0
s + u0e−αx/2
exp

−x
q s + k
2
2 + a2/c

α
2 +
q
(s + k
2)2 + a2/c
,
where 4a2 = α2c2 −k2 > 0.
Step 3: Using the ﬁrst and second shifting theorems and the property that
F
p
s2 + a2

= L
"
f(t) −a
Z t
0
J1
 a
√
t2 −τ 2 
√
t2 −τ 2
τf(τ) dτ
#
,
show that
u(x, t) = u0 + u0ce−kt/2H(t −x/c)
"
e−αct/2 −a
Z t
x/c
J1
 a
√
t2 −τ 2 
√
t2 −τ 2
τe−αcτ/2dτ
#
.
19. As an electric locomotive travels down a track at the speed V , the pantograph (the
metallic framework that connects the overhead power lines to the locomotive) pushes up
the line with a force P. Let us ﬁnd the behavior46 of the overhead wire as a pantograph
passes between two supports of the electrical cable that are located a distance L apart. We
model this system as a vibrating string with a point load:
∂2u
∂t2 = c2 ∂2u
∂x2 + P
ρV δ

t −x
V

,
0 < x < L,
0 < t.
Let us assume that the wire is initially at rest [u(x, 0) = ut(x, 0) = 0 for 0 < x < L] and
ﬁxed at both ends [u(0, t) = u(L, t) = 0 for 0 < t].
Step 1: Take the Laplace transform of the partial diﬀerential equation and show that
s2U(x, s) = c2 d2U(x, s)
dx2
+ P
ρV e−xs/V .
Step 2: Solve the ordinary diﬀerential equation in Step 1 as a Fourier half-range sine series
U(x, s) =
∞
X
n=1
Bn(s) sin
nπx
L

,
where
Bn(s) =
2Pβn
ρL(β2n −α2n)

1
s2 + α2n
−
1
s2 + β2n
 h
1 −(−1)ne−Ls/V i
,
46 See Oda, O., and Y. Ooura, 1976: Vibrations of catenary overhead wire. Q. Rep., (Tokyo) Railway
Tech. Res. Inst., 17, 134–135.

The Laplace Transform
635
αn = nπc/L and βn = nπV/L. This solution satisﬁes the boundary conditions.
Step 3: By inverting the solution in Step 2, show that
u(x, t) = 2P
ρL
∞
X
n=1
sin(βnt)
α2n −β2n
−V
c
sin(αnt)
α2n −β2n

sin
nπx
L

−2P
ρL H

t −L
V
 ∞
X
n=1
(−1)n sin
nπx
L
 sin[βn(t −L/V )]
α2n −β2n
−V
c
sin[αn(t −L/V )]
α2n −β2n

or
u(x, t) = 2P
ρL
∞
X
n=1
sin(βnt)
α2n −β2n
−V
c
sin(αnt)
α2n −β2n

sin
nπx
L

−2P
ρL H

t −L
V
 ∞
X
n=1
sin
nπx
L
 sin(βnt)
α2n −β2n
−V
c (−1)n sin[αn(t −L/V )]
α2n −β2n

.
The ﬁrst term in both summations represents the static uplift on the line; this term dis-
appears after the pantograph passes. The second term in both summations represents the
vibrations excited by the traveling force. Even after the pantograph passes, they continue
to exist.
20. Solve the wave equation
1
c2
∂2u
∂t2 −∂2u
∂r2 −1
r
∂u
∂r + u
r2 = δ(r −α)
α2
,
0 ≤r < a,
0 < t,
where 0 < α < a, subject to the boundary conditions
lim
r→0 |u(r, t)| < ∞,
∂u(a, t)
∂r
+ h
au(a, t) = 0,
0 < t,
and the initial conditions u(r, 0) = ut(r, 0) = 0, 0 ≤r < a.
Step 1: Take the Laplace transform of the partial diﬀerential equation and show that
d2U(r, s)
dr2
+ 1
r
dU(r, s)
dr
−
s2
c2 + 1
r2

U(r, s) = −δ(r −α)
sα2
,
0 ≤r < a,
with
lim
r→0 |U(r, s)| < ∞,
dU(a, s)
dr
+ h
aU(a, s) = 0.
Step 2: Show that the Dirac delta function can be reexpressed as the Fourier-Bessel series
δ(r −α) = 2α
a2
∞
X
n=1
β2
n J1(βnα/a)
(β2n + h2 −1)J2
1(βn)J1(βnr/a),
0 ≤r < a,
where βn is the nth root of βJ′
1(β) + h J1(β) = βJ0(β) + (h −1)J1(β) = 0 and J0( ), J1( )
are the zeroth and ﬁrst-order Bessel functions of the ﬁrst kind, respectively.

636
Advanced Engineering Mathematics with MATLAB
Step 3: Show that the solution to the ordinary diﬀerential equation in Step 1 is
U(r, s) = 2
α
∞
X
n=1
J1(βnα/a)J1(βnr/a)
(β2n + h2 −1) J2
1(βn)
1
s −
s
s2 + c2β2n/a2

.
Note that this solution satisﬁes the boundary conditions.
Step 4: Taking the inverse of the Laplace transform in Step 3, show that the solution to
the partial diﬀerential equation is
u(r, t) = 2
α
∞
X
n=1
J1(βnα/a)J1(βnr/a)
(β2n + h2 −1) J2
1(βn)

1 −cos
cβnt
a

.
21. Solve the hyperbolic equation
∂2u
∂x∂t + u = 0,
0 < x, t,
subject to the boundary conditions u(0, t) = e−t, limx→∞u(x, t) →0, 0 < t, and u(x, 0) = 1,
limt→∞|u(x, t)| < Mekt, 0 < k, M, x, t.
Step 1: Take the Laplace transform of the partial diﬀerential equation and show that
sdU(x, s)
dx
+ U = 0,
U(0, s) =
1
s + 1,
lim
x→∞U(x, s) →0.
Step 2: Show that
U(x, s) = e−x/s
s + 1 = e−x/s
s
−
e−x/s
s(s + 1).
Step 3: Using tables and the convolution theorem, show that the solution is
u(x, t) = J0(2
√
xt ) −e−t
Z t
0
eτJ0(2√xτ ) dτ,
where J0(·) is the Bessel function of the ﬁrst kind and order zero.
22. Solve the hyperbolic equation
∂2u
∂x∂t + a∂u
∂t + b∂u
∂x = 0,
0 < a, b, x, t,
subject to the boundary conditions u(0, t) = ect, limx→∞u(x, t) →0, 0 < t, and the initial
conditions u(x, 0) = 1, limt→∞|u(x, t)| < Mekt, 0 < k, M, t, x.
Step 1: Take the Laplace transform of the partial diﬀerential equation and show that
(s + b)dU(x, s)
dx
+ asU = a,
U(0, s) =
1
s −c,
lim
x→∞U(x, s) →0.

The Laplace Transform
637
Step 2: Show that
U(x, s) = 1
s + c e−ax
s(s −c) exp
 bx
s + b

.
Step 3: Using tables, the ﬁrst shifting theorem, and the convolution theorem, show that
the solution is
u(x, t) = 1 + c ect−ax
Z t
0
e−(b+c)τI0

2
√
bxτ

dτ,
where I0(·) is the modiﬁed Bessel function of the ﬁrst kind and order zero.
12.11 THE SOLUTION OF THE HEAT EQUATION
In the previous section we showed that we can solve the wave equation by the method
of Laplace transforms. This is also true for the heat equation. Once again, we take the
Laplace transform with respect to time. From the deﬁnition of Laplace transforms,
L[u(x, t)] = U(x, s),
(12.11.1)
L[ut(x, t)] = sU(x, s) −u(x, 0),
(12.11.2)
and
L[uxx(x, t)] = d2U(x, s)
dx2
.
(12.11.3)
We next solve the resulting ordinary diﬀerential equation, known as the auxiliary equation,
along with the corresponding Laplace transformed boundary conditions. The initial condi-
tion gives us the value of u(x, 0). The ﬁnal step is the inversion of the Laplace transform
U(x, s). We typically use the inversion integral.
• Example 12.11.1
To illustrate these concepts, we solve a heat conduction problem47 in a plane slab of
thickness 2L. Initially the slab has a constant temperature of unity. For 0 < t, we allow
both faces of the slab to radiatively cool in a medium that has a temperature of zero.
If u(x, t) denotes the temperature, a2 is the thermal diﬀusivity, h is the relative emis-
sivity, t is the time, and x is the distance perpendicular to the face of the slab and measured
from the middle of the slab, then the governing equation is
∂u
∂t = a2 ∂2u
∂x2 ,
−L < x < L,
0 < t,
(12.11.4)
with the initial condition
u(x, 0) = 1,
−L < x < L,
(12.11.5)
and boundary conditions
∂u(L, t)
∂x
+ hu(L, t) = 0,
∂u(−L, t)
∂x
+ hu(−L, t) = 0,
0 < t.
(12.11.6)
47 Goldstein, S., 1932: The application of Heaviside’s operational method to the solution of a problem
in heat conduction. Z. Angew. Math. Mech., 12, 234–243.

638
Advanced Engineering Mathematics with MATLAB
Taking the Laplace transform of Equation 12.11.4 and substituting the initial condition,
a2 d2U(x, s)
dx2
−sU(x, s) = −1.
(12.11.7)
If we write s = a2q2, Equation 12.11.7 becomes
d2U(x, s)
dx2
−q2U(x, s) = −1
a2 .
(12.11.8)
From the boundary conditions, U(x, s) is an even function in x and we may conveniently
write the solution as
U(x, s) = 1
s + A cosh(qx).
(12.11.9)
From Equation 12.11.6,
qA sinh(qL) + h
s + hA cosh(qL) = 0,
(12.11.10)
and
U(x, s) = 1
s −
h cosh(qx)
s[q sinh(qL) + h cosh(qL)].
(12.11.11)
The inverse of U(x, s) consists of two terms. The ﬁrst term is simply unity. We will
invert the second term by contour integration.
We begin by examining the nature and location of the singularities in the second term.
Using the product formulas for the hyperbolic cosine and sine functions, the second term
equals
h

1 + 4q2x2
π2
 
1 + 4q2x2
9π2

· · ·
s

q2L

1 + q2L2
π2
 
1 + q2L2
4π2

· · · + h

1 + 4q2L2
π2
 
1 + 4q2L2
9π2

· · ·
.
(12.11.12)
Because q2 = s/a2, Equation 12.11.12 shows that we do not have any √s in the transform
and we need not concern ourselves with branch points and cuts. Furthermore, we have only
simple poles: one located at s = 0 and the others where
q sinh(qL) + h cosh(qL) = 0.
(12.11.13)
If we set q = iλ, Equation 12.11.13 becomes
h cos(λL) −λ sin(λL) = 0,
or
λL tan(λL) = hL.
(12.11.14)
From Bromwich’s integral,
L−1

h cosh(qx)
s[q sinh(qL) + h cosh(qL)]

=
1
2πi
I
C
h cosh(qx)etz
z[q sinh(qL) + h cosh(qL)] dz,
(12.11.15)

The Laplace Transform
639
0
0.2
0.4
0.6
0.8
1
0
0.5
1
1.5
2
0
0.2
0.4
0.6
0.8
1
1.2
distance
time
U(X,T)
Figure 12.11.1: The temperature within the portion of a slab 0 < x/L < 1 at various times a2t/L2 if the
faces of the slab radiate to free space at temperature zero and the slab initially has the temperature 1. The
parameter hL = 1.
where q = z1/2/a and the closed contour C consists of Bromwich’s contour plus a semicircle
of inﬁnite radius in the left half of the z-plane. The residue at z = 0 is 1 while at zn = −a2λ2
n,
Res

h cosh(qx)etz
z[q sinh(qL) + h cosh(qL)]; zn

= lim
z→zn
h(z + a2λ2
n) cosh(qx)etz
z[q sinh(qL) + h cosh(qL)]
(12.11.16)
= lim
z→zn
h cosh(qx)etz
z[(1 + hL) sinh(qL) + qL cosh(qL)]/(2a2q)
(12.11.17)
=
2ha2λni cosh(iλnx) exp(−λ2
na2t)
(−a2λ2n)[(1 + hL)i sin(λnL) + iλnL cos(λnL)]
(12.11.18)
= −
2h cos(λnx) exp(−a2λ2
nt)
λn[(1 + hL) sin(λnL) + λnL cos(λnL)].
(12.11.19)
Therefore, the inversion of U(x, s) is
u(x, t) = 1 −

1 −2h
∞
X
n=1
cos(λnx) exp(−a2λ2
nt)
λn[(1 + hL) sin(λnL) + λnL cos(λnL)]

,
(12.11.20)
or
u(x, t) = 2h
∞
X
n=1
cos(λnx) exp(−a2λ2
nt)
λn[(1 + hL) sin(λnL) + λnL cos(λnL)].
(12.11.21)
We can further simplify Equation 12.11.21 by using h/λn = tan(λnL). This yields hL =
λnL tan(λnL). Substituting these relationships into Equation 12.11.21 and simplifying,
u(x, t) = 2
∞
X
n=1
sin(λnL) cos(λnx) exp(−a2λ2
nt)
λnL + sin(λnL) cos(λnL)
.
(12.11.22)
Figure 12.11.1 illustrates Equation 12.11.23. It was created using the MATLAB script

640
Advanced Engineering Mathematics with MATLAB
clear
hL = 1; m = 0; M = 100; dx = 0.05; dt = 0.05;
% create initial guess at zero n
zero = zeros(length(M));
for n = 1:10000
k1 = 0.1*n; k2 = 0.1*(n+1);
prod = k1 * tan(k1); y1 = hL - prod; y2 = hL - k2 * tan(k2);
if (y1*y2 <= 0 & prod < 2 & m < M) m = m+1; zero(m) = k1; end;
end;
% use Newton-Raphson method to improve values of zero n
for n = 1:M; for k = 1:10
f = hL - zero(n) * tan(zero(n));
fp = - tan(zero(n)) - zero(n) * sec(zero(n))^2;
zero(n) = zero(n) - f / fp;
end; end;
% compute Fourier coefficients
for m = 1:M
a(m) = 2 * sin(zero(m)) / (zero(m) + sin(zero(m))*cos(zero(m)));
end
% compute grid and initialize solution
X = [0:dx:1]; T = [0:dt:2];
u = zeros(length(T),length(X));
XX = repmat(X,[length(T) 1]); TT = repmat(T’,[1 length(X)]);
% compute solution from Equation 12.11.22
for m = 1:M
u = u + a(m) * cos(zero(m)*XX) .* exp(-zero(m)*zero(m)*TT);
end
surf(XX,TT,u)
xlabel(’distance’,’Fontsize’,20); ylabel(’time’,’Fontsize’,20)
zlabel(’U(X,T)’,’Fontsize’,20)
⊓⊔
• Example 12.11.2: Heat dissipation in disc brakes
Disc brakes consist of two blocks of frictional material known as pads that press against
each side of a rotating annulus, usually made of a ferrous material. In this problem we deter-
mine the transient temperatures reached in a disc brake during a single brake application.48
If we ignore the errors introduced by replacing the cylindrical portion of the drum by a
rectangular plate, we can model our disc brakes as a one-dimensional solid, which friction
heats at both ends. Assuming symmetry about x = 0, the boundary condition there is
ux(0, t) = 0. To model the heat ﬂux from the pads, we assume a uniform disc deceleration
that generates heat from the frictional surfaces at the rate N(1 −Mt), where M and N are
experimentally determined constants.
If u(x, t), κ, and a2 denote the temperature, thermal conductivity, and diﬀusivity of
the rotating annulus, respectively, then the heat equation is
∂u
∂t = a2 ∂2u
∂x2 ,
0 < x < L,
0 < t,
(12.11.23)
48 From Newcomb, T. P., 1958: The ﬂow of heat in a parallel-faced inﬁnite solid. Brit. J. Appl. Phys.,
9, 370–372. See also Newcomb, T. P., 1958/59: Transient temperatures in brake drums and linings. Proc.
Inst. Mech. Eng., Auto. Div., 227–237; Newcomb, T. P., 1959: Transient temperatures attained in disk
brakes. Brit. J. Appl. Phys., 10, 339–340.

The Laplace Transform
641
with the boundary conditions
∂u(0, t)
∂x
= 0,
κ∂u(L, t)
∂x
= N(1 −Mt),
0 < t.
(12.11.24)
The boundary condition at x = L gives the frictional heating of the disc pads.
Introducing the Laplace transform of u(x, t), deﬁned as
U(x, s) =
Z ∞
0
u(x, t)e−st dt,
(12.11.25)
the equation to be solved becomes
d2U
dx2 −s
a2 U = 0,
(12.11.26)
subject to the boundary conditions that
dU(0, s)
dx
= 0,
and
dU(L, s)
dx
= N
κ
1
s −M
s2

.
(12.11.27)
The solution of Equation 12.11.26 is
U(x, s) = A cosh(qx) + B sinh(qx),
(12.11.28)
where q = s1/2/a. Using the boundary conditions, the solution becomes
U(x, s) = N
κ
1
s −M
s2
 cosh(qx)
q sinh(qL).
(12.11.29)
It now remains to invert the transform, Equation 12.11.29. We will invert cosh(qx)/
[sq sinh(qL)]; the inversion of the second term follows by analog.
Our ﬁrst concern is the presence of s1/2 because this is a multivalued function. However,
when we replace the hyperbolic cosine and sine functions with their Taylor expansions,
cosh(qx)/[sq sinh(qL)] contains only powers of s and is, in fact, a single-valued function.
From Bromwich’s integral,
L−1
 cosh(qx)
sq sinh(qL)

=
1
2πi
Z c+∞i
c−∞i
cosh(qx)etz
zq sinh(qL) dz,
(12.11.30)
where q = z1/2/a. Just as in the previous example, we replace the hyperbolic cosine and
sine with their product expansion to determine the nature of the singularities. The point
z = 0 is a second-order pole. The remaining poles are located where z1/2
n
L/a = nπi, or
zn = −n2π2a2/L2, where n = 1, 2, 3, . . .. We have chosen the positive sign because z1/2
must be single-valued; if we had chosen the negative sign the answer would have been the
same. Our expansion also shows that the poles are simple.
Having classiﬁed the poles, we now close Bromwich’s contour, which lies slightly to the
right of the imaginary axis, with an inﬁnite semicircle in the left half-plane, and use the

642
Advanced Engineering Mathematics with MATLAB
residue theorem. The values of the residues are
Res
cosh(qx)etz
zq sinh(qL) ; 0

= 1
1! lim
z→0
d
dz
(z −0)2 cosh(qx)etz
zq sinh(qL)

(12.11.31)
= lim
z→0
d
dz
z cosh(qx)etz
q sinh(qL)

(12.11.32)
= a2
L lim
z→0
d
dz
z
h
1 + zx2
2!a2 + · · ·
i h
1 + tz + t2z2
2! + · · ·
i
z + L2z2
3!a2 + · · ·

(12.11.33)
= a2
L lim
z→0
d
dz

1 + tz + zx2
2a2 −zL2
3!a2 + · · ·

(12.11.34)
= a2
L

t + x2
2a2 −L2
6a2

,
(12.11.35)
and
Res
cosh(qx)etz
zq sinh(qL) ; zn

=

lim
z→zn
cosh(qx)
zq
etz

lim
z→zn
z −zn
sinh(qL)

(12.11.36)
= lim
z→zn
cosh(qx)etz
zq cosh(qL)L/(2a2q)
(12.11.37)
= cosh(nπxi/L) exp(−n2π2a2t/L2)
(−n2π2a2/L2) cosh(nπi)L/(2a2)
(12.11.38)
= −2L(−1)n
n2π2
cos(nπx/L)e−n2π2a2t/L2.
(12.11.39)
When we sum all of the residues from both inversions, the solution is
u(x, t) = a2N
κL

t + x2
2a2 −L2
6a2

−2LN
κπ2
∞
X
n=1
(−1)n
n2
cos(nπx/L)e−n2π2a2t/L2
−a2NM
κL
t2
2 + tx2
2a2 −tL2
6a2 +
x4
24a4 −x2L2
12a4 + 7L4
360a4

−2L3NM
a2κπ4
∞
X
n=1
(−1)n
n4
cos(nπx/L)e−n2π2a2t/L2.
(12.11.40)
Figure 12.11.2 shows the temperature in the brake lining at various places within the
lining [x′ = x/L] if a2 = 3.3 × 10−3 cm2/sec, κ = 1.8 × 10−3 cal/(cm sec◦C), L = 0.48 cm,
and N = 1.96 cal/(cm2 sec). Initially the frictional heating results in an increase in the disc
brake’s temperature. As time increases, the heating rate decreases and radiative cooling
becomes suﬃciently large that the temperature begins to fall.
⊓⊔
• Example 12.11.3
In the previous example we showed that Laplace transforms are particularly useful
when the boundary conditions are time dependent. Consider now the case when one of the
boundaries is moving.

The Laplace Transform
643
Figure 12.11.2: Typical curves of transient temperature at diﬀerent locations in a brake lining. Circles
denote computed values while squares are experimental measurements. (From Newcomb, T. P., 1958: The
ﬂow of heat in a parallel-faced inﬁnite solid. Brit. J. Appl. Phys., 9, 372 with permission.)
We wish to solve the heat equation
∂u
∂t = a2 ∂2u
∂x2 ,
βt < x < ∞,
0 < t,
(12.11.41)
subject to the boundary conditions
u(x, t)

x=βt = f(t),
and
lim
x→∞u(x, t) →0,
0 < t,
(12.11.42)
and the initial condition
u(x, 0) = 0,
0 < x < ∞.
(12.11.43)
This type of problem arises in combustion problems where the boundary moves due to the
burning of the fuel.
We begin by introducing the coordinate η = x −βt. Then the problem can be refor-
mulated as
∂u
∂t −β ∂u
∂η = a2 ∂2u
∂η2 ,
0 < η < ∞,
0 < t,
(12.11.44)
subject to the boundary conditions
u(0, t) = f(t),
lim
η→∞u(η, t) →0,
0 < t,
(12.11.45)
and the initial condition
u(η, 0) = 0,
0 < η < ∞.
(12.11.46)
80 
70 
60 
6 
'2... 
50 
w 
a: 
::J 
f-
40 
<t: 
a: 
w 
a.. 
::;: 
w 
f-
30 
20 
10 
2 
3 
4 
5 
TIME (SECONDS) 

644
Advanced Engineering Mathematics with MATLAB
Taking the Laplace transform of Equation 12.11.44, we have that
d2U(η, s)
dη2
+ β
a2
dU(η, s)
dη
−s
a2 U(η, s) = 0,
(12.11.47)
with
U(0, s) = F(s),
and
lim
η→∞U(η, s) →0.
(12.11.48)
The solution to Equation 12.11.47 and Equation 12.11.48 is
U(η, s) = F(s) exp
 
−βη
2a2 −η
a
r
s + β2
4a2
!
.
(12.11.49)
Because
L [Φ(η, t)] = exp
 
−η
a
r
s + β2
4a2
!
,
(12.11.50)
where
Φ(η, t) = 1
2

e−βη/2a2erfc

η
2a
√
t −β
√
t
2a

+ eβη/2a2erfc

η
2a
√
t + β
√
t
2a

,
(12.11.51)
and
erfc(x) = 1 −
2
√π
Z x
0
e−η2 dη,
(12.11.52)
we have by the convolution theorem that
u(η, t) = e−βη/2a2 Z t
0
f(t −τ)Φ(η, τ) dτ,
(12.11.53)
or
u(x, t) = e−β(x−βt)/2a2 Z t
0
f(t −τ)Φ(x −βτ, τ) dτ.
(12.11.54)
Problems
1. Solve
∂u
∂t = ∂2u
∂x2 −a2(u −T0),
0 < x < 1,
0 < t,
subject to the boundary conditions ux(0, t) = ux(1, t) = 0, 0 < t, and the initial condition
u(x, 0) = 0, 0 < x < 1.
2. Solve
∂u
∂t = ∂2u
∂x2 ,
0 < x < 1,
0 < t,
subject to the boundary conditions ux(0, t) = 0, u(1, t) = t, 0 < t, and the initial condition
u(x, 0) = 0, 0 < x < 1.
3. Solve
∂u
∂t = ∂2u
∂x2 ,
0 < x < 1,
0 < t,

The Laplace Transform
645
subject to the boundary conditions u(0, t) = 0, u(1, t) = 1, 0 < t, and the initial condition
u(x, 0) = 0, 0 < x < 1.
4. Solve
∂u
∂t = ∂2u
∂x2 ,
−1
2 < x < 1
2,
0 ≤t,
subject to the boundary conditions ux
 −1
2, t

= 0, ux
  1
2, t

= δ(t), 0 ≤t, and the initial
condition u(x, 0) = 0, −1
2 < x < 1
2.
5. Solve
∂u
∂t −∂2u
∂x2 = 1,
0 < x < 1,
0 < t,
subject to the boundary conditions u(0, t) = u(1, t) = 0, 0 < t, and the initial condition
u(x, 0) = 0, 0 < x < 1.
6. Solve49
∂u
∂t = a2 ∂2u
∂x2 ,
0 < x < ∞,
0 < t,
subject to the boundary conditions
u(0, t) = 1,
lim
x→∞u(x, t) →0,
0 < t,
and the initial condition u(x, 0) = 0, 0 < x < ∞. Hint: Use tables to invert the Laplace
transform.
7. Solve
∂u
∂t = ∂2u
∂x2 ,
0 < x < ∞,
0 < t,
subject to the boundary conditions
∂u(0, t)
∂x
= 1,
lim
x→∞u(x, t) →0,
0 < t,
and the initial condition u(x, 0) = 0, 0 < x < ∞. Hint: Use tables to invert the Laplace
transform.
8. Solve
∂u
∂t = ∂2u
∂x2 ,
0 < x < ∞,
0 < t,
subject to the boundary conditions
u(0, t) = 1,
lim
x→∞u(x, t) →0,
0 < t,
and the initial condition u(x, 0) = e−x, 0 < x < ∞. Hint: Use tables to invert the Laplace
transform.
49 If u(x, t) denotes the Eulerian velocity of a viscous ﬂuid in the half space x > 0 and parallel to the wall
located at x = 0, then this problem was ﬁrst solved by Stokes, G. G., 1850: On the eﬀect of the internal
friction of ﬂuids on the motions of pendulums. Proc. Cambridge Philos. Soc., 9, Part II, [8]–[106].

646
Advanced Engineering Mathematics with MATLAB
9. Solve
∂u
∂t = a2
∂2u
∂x2 + (1 + δ)∂u
∂x + δu

,
0 < x < ∞,
0 < t,
where δ is a constant, subject to the boundary conditions
u(0, t) = u0,
lim
x→∞u(x, t) →0,
0 < t,
and the initial condition u(x, 0) = 0, 0 < x < ∞. Note that
L−1
1
s exp

−2α
p
s + β2

= 1
2e2αβerfc
 α
√
t + β
√
t

+ 1
2e−2αβerfc
 α
√
t −β
√
t

,
where erfc(·) is the complementary error function.
10. During their modeling of a chemical reaction with a back reaction, Agmon et al.50
solved
∂u
∂t = a2 ∂2u
∂x2 ,
0 < x < ∞,
0 < t,
subject to the boundary conditions
κd + a2ux(0, t) + a2κd
Z t
0
ux(0, τ) dτ = κru(0, t),
lim
x→∞u(x, t) →0,
0 < t,
and the initial condition u(x, 0) = 0, 0 < x < ∞, where κd and κr denote the intrinsic
dissociation and recombination rate coeﬃcients, respectively. What should they have found?
11. Solve51
∂u
∂t = ∂2u
∂x2 −βu,
0 < x < ∞,
0 < t,
subject to the boundary conditions
ρu(0, t) −ux(0, t) = e(σ2−β)t,
lim
x→∞u(x, t) →0,
0 < t,
and the initial condition u(x, 0) = 0, 0 < x < ∞, where β, ρ, and σ are constants and
σ ̸= ρ.
12. Solve
∂u
∂t = a2 ∂2u
∂x2 + Ae−kx,
0 < x < ∞,
0 < t,
subject to the boundary conditions
∂u(0, t)
∂x
= 0,
lim
x→∞u(x, t) = u0,
0 < t,
50 Agmon, N., E. Pines, and D. Huppert, 1988: Geminate recombination in proton-transfer reactions.
II. Comparison of diﬀusional and kinetic schemes. J. Chem. Phys., 88, 5631–5638.
51 Saidel, G. M., E. D. Morris, and G. M. Chisolm, 1987: Transport of macromolecules in arterial wall
in vivo: A mathematical model and analytic solutions. Bull. Math. Biol., 49, 153–169.

The Laplace Transform
647
and the initial condition u(x, 0) = u0, 0 < x < ∞.
13. Solve
∂u
∂t = a2 ∂2u
∂x2 −P,
0 < x < L,
0 < t,
subject to the boundary conditions u(0, t) = t, u(L, t) = 0, 0 < t, and the initial condition
u(x, 0) = 0, 0 < x < L.
14. Solve
∂u
∂t = a2 ∂2u
∂x2 + ku,
0 < x < L,
0 < k, t,
subject to the boundary conditions u(0, t) = u(L, t) = T0, 0 < t, and the initial condition
u(x, 0) = T0, 0 < x < L.
15. An electric fuse protects electrical devices by using resistance heating to melt an en-
closed wire when excessive current passes through it. A knowledge of the distribution of
temperature along the wire is important in the design of the fuse. If the temperature rises
to the melting point only over a small interval of the element, the melt will produce a
small gap, resulting in an unnecessary prolongation of the fault and a considerable release
of energy. Therefore, the desirable temperature distribution should melt most of the wire.
For this reason, Guile and Carne52 solved the heat conduction equation
∂u
∂t = a2 ∂2u
∂x2 + q(1 + αu),
−L < x < L,
0 < t,
to understand the temperature structure within the fuse just before meltdown. The second
term on the right side of the heat conduction equation gives the resistance heating, which is
assumed to vary linearly with temperature. If the terminals at x = ±L remain at a constant
temperature, which we can take to be zero, the boundary conditions are u(−L, t) = u(L, t) =
0, 0 < t. The initial condition is u(x, 0) = 0, −L < x < L. Find the temperature ﬁeld as a
function of the parameters a, q, and α.
16. Solve53
∂u
∂t = ∂2u
∂r2 + 2
r
∂u
∂r ,
0 ≤r < 1,
0 < t,
subject to the boundary conditions
lim
r→0 |u(r, t)| < ∞,
∂u(1, t)
∂r
= 1,
0 < t,
and the initial condition u(r, 0) = 0, 0 ≤r < 1. Hint: Use the new dependent variable
v(r, t) = ru(r, t).
17. Solve54
∂u
∂t = a2
∂2u
∂r2 + 2
r
∂u
∂r

+ q(t) = a2
r
∂2(ru)
∂r2
+ q(t),
b < r < ∞,
0 < t,
52 Guile, A. E., and E. B. Carne, 1954: An analysis of an analogue solution applied to the heat conduction
problem in a cartridge fuse. AIEE Trans., Part 1, 72, 861–868.
53 See Reismann, H., 1962: Temperature distribution in a spinning sphere during atmospheric entry. J.
Aerosp. Sci., 29, 151–159.
54 See Frisch, H. L, and F. C. Collins, 1952: Diﬀusional processes in the growth of aerosol particles. J.
Chem. Phys., 20, 1797–1803.

648
Advanced Engineering Mathematics with MATLAB
subject to the boundary conditions
∂u(b, t)
∂r
= u(b, t),
lim
r→∞u(r, t) = u0 +
Z t
0
q(τ) dτ,
0 < t,
and the initial condition u(r, 0) = u0, b < r < ∞.
18. Consider55 a viscous ﬂuid located between two ﬁxed walls x = ±L. At x = 0 we
introduce a thin, inﬁnitely long rigid barrier of mass m per unit area and let it fall under
the force of gravity, which points in the direction of positive x. We wish to ﬁnd the velocity
of the ﬂuid u(x, t). The ﬂuid is governed by the partial diﬀerential equation
∂u
∂t = ν ∂2u
∂x2 ,
0 < x < L,
0 < t,
subject to the boundary conditions
u(L, t) = 0,
∂u(0, t)
∂t
−2µ
m
∂u(0, t)
∂x
= g,
0 < t,
and the initial condition u(x, 0) = 0, 0 < x < L.
19. Consider56 a viscous ﬂuid located between two ﬁxed walls x = ±L. At x = 0 we
introduce a thin, inﬁnitely long rigid barrier of mass m per unit area. The barrier is acted
upon by an elastic force in such a manner that it would vibrate with a frequency ω if the
liquid were absent. We wish to ﬁnd the barrier’s deviation from equilibrium, y(t). The ﬂuid
is governed by the partial diﬀerential equation
∂u
∂t = ν ∂2u
∂x2 ,
0 < x < L,
0 < t.
The boundary conditions are
u(L, t) = md2y
dt2 −2µ∂u(0, t)
∂x
+ mω2y = 0,
dy
dt = u(0, t),
0 < t,
and the initial conditions are u(x, 0) = 0, 0 < x < L, and y(0) = A, y′(0) = 0.
20. Solve57
∂u
∂t = a2 ∂2u
∂x2 ,
0 < x < L,
0 < t,
subject to the boundary conditions ux(0, t) = 0, a2ux(L, t) + αu(L, t) = F, 0 < t, and the
initial condition u(x, 0) = 0, 0 < x < L.
55 See Havelock, T. H., 1921: The solution of an integral equation occurring in certain problems of viscous
ﬂuid motion. Philos. Mag., Ser. 6, 42, 620–628.
56 See Havelock, T. H., 1921: On the decay of oscillation of a solid body in a viscous ﬂuid. Philos. Mag.,
Ser. 6, 42, 628–634.
57 See McCarthy, T. A., and H. J. Goldsmid, 1970: Electro-deposited copper in bismuth telluride. J.
Phys. D, 3, 697–706.

The Laplace Transform
649
21. Solve
∂u
∂t = ∂2u
∂x2 ,
0 ≤x < 1,
0 ≤t,
subject to the boundary conditions
u(0, t) = 0,
3a
∂u(1, t)
∂x
−u(1, t)

+ ∂u(1, t)
∂t
= δ(t),
0 ≤t,
and the initial condition u(x, 0) = 0, 0 ≤x < 1.
22. Solve58 the partial diﬀerential equation
∂u
∂t + V ∂u
∂x = ∂2u
∂x2 ,
0 < x < 1,
0 < t,
where V is a constant, subject to the boundary conditions
u(0, t) = 1,
ux(1, t) = 0,
0 < t,
and the initial condition u(x, 0) = 0, 0 < x < 1.
23. Solve59 the partial diﬀerential equation
∂2u
∂x∂t + a∂u
∂t + b∂u
∂x = 0,
0 < x < ∞,
0 < a, b, t,
subject to the boundary conditions
u(0, t) = 1,
lim
x→∞u(x, t) →0,
0 < t,
and the initial condition ux(x, 0) + au(x, 0) = 0, 0 < x < ∞.
To invert the Laplace
transform, you may want to review Problem 52 at the end of Section 12.3.
24. Solve
1
r
∂
∂r

r∂u
∂r

−∂u
∂t = δ(t),
0 ≤r < a,
0 ≤t,
subject to the boundary conditions
lim
r→0 |u(r, t)| < ∞,
u(a, t) = 0,
0 ≤t,
and the initial condition u(r, 0) = 0, 0 ≤r < a, where δ(t) is the Dirac delta function. Note
that Jn(iz) = inIn(z) and In(iz) = inJn(z) for all complex z.
25. Solve
∂u
∂t = 1
r
∂
∂r

r∂u
∂r

+ H(t),
0 ≤r < a,
0 < t,
58 See Yoo, H., and E.-T. Pak, 1996: Analytical solutions to a one-dimensional ﬁnite-domain model for
stratiﬁed thermal storage tanks. Sol. Energy, 56, 315–322.
59 See Liaw, C. H., J. S. P. Wang, R. A. Greenhorn, and K. C. Chao, 1979: Kinetics of ﬁxed-bed
absorption: A new solution. AICHE J., 25, 376–381.

650
Advanced Engineering Mathematics with MATLAB
subject to the boundary conditions
lim
r→0 |u(r, t)| < ∞,
u(a, t) = 0,
0 < t,
and the initial condition u(r, 0) = 0, 0 ≤r < a. Note that Jn(iz) = inIn(z) and In(iz) =
inJn(z) for all complex z.
26. Solve
∂u
∂t = 1
r
∂
∂r

r∂u
∂r

,
0 ≤r < a,
0 < t,
subject to the boundary conditions
lim
r→0 |u(r, t)| < ∞,
u(a, t) = e−t/τ0,
0 < t,
and the initial condition u(r, 0) = 1, 0 ≤r < a. Note that Jn(iz) = inIn(z) and In(iz) =
inJn(z) for all complex z.
27. Solve
∂u
∂t = a2
∂2u
∂r2 + 1
r
∂u
∂r

,
0 ≤r < b,
0 < t,
subject to the boundary conditions
lim
r→0 |u(r, t)| < ∞,
u(b, t) = kt,
0 < t,
and the initial condition u(r, 0) = 0, 0 ≤r < b. Note that Jn(iz) = inIn(z) and In(iz) =
inJn(z) for all complex z.
28. Solve the nonhomogeneous heat equation for the spherical shell60
∂u
∂t = a2
∂2u
∂r2 + 2
r
∂u
∂r + A
r4

,
α < r < β,
0 < t,
subject to the boundary conditions
∂u(α, t)
∂r
= u(β, t) = 0,
0 < t,
and the initial condition u(r, 0) = 0, α < r < β.
Step 1: By introducing v(r, t) = r u(r, t), show that the problem simpliﬁes to
∂v
∂t = a2
∂2v
∂r2 + A
r3

,
α < r < β,
0 < t,
subject to the boundary conditions
∂v(α, t)
∂r
−v(α, t)
α
= v(β, t) = 0,
0 < t,
60 See Malkovich, R. Sh., 1977: Heating of a spherical shell by a radial current. Sov. Phys. Tech. Phys.,
22, 636.

The Laplace Transform
651
and the initial condition
v(r, 0) = 0,
α < r < β.
Step 2: Using Laplace transforms and variation of parameters, show that the Laplace
transform of u(r, t) is
U(r, s) = A
srq

sinh[q(β −r)]
αq cosh(qℓ) + sinh(qℓ)
Z ℓ
0
αq cosh(qη) + sinh(qη)
(α + η)3
dη−
Z β−r
0
sinh(qη)
(r + η)3 dη

,
where q = √s/a, and ℓ= β −α.
Step 3: Take the inverse of U(r, s) and show that
u(r, t) = A
1
r −1
β
  1
α −1
2
1
r + 1
β

−2α2
rℓ2
∞
X
n=0
sin[γn(β −r)] exp(−a2γ2
nt)
sin2(γnℓ)(β + α2ℓγ2n)
Z 1
0
sin(γnℓη)
(δ −η)3 dη

,
where γn is the nth root of αγ + tan(ℓγ) = 0, and δ = 1 + α/ℓ.
12.12 THE SUPERPOSITION INTEGRAL AND THE HEAT EQUATION
In our study of Laplace transforms, we showed that we can construct solutions to
ordinary diﬀerential equations with a general forcing f(t) by ﬁrst ﬁnding the solution to
a similar problem where the forcing equals Heaviside’s step function. Then we can write
the general solution in terms of a superposition integral according to Duhamel’s theorem.
In this section we show that similar considerations hold in solving the heat equation with
time-dependent boundary conditions or forcings.
Let us solve the heat condition problem
∂u
∂t = a2 ∂2u
∂x2 ,
0 < x < L,
0 < t,
(12.12.1)
with the boundary conditions
u(0, t) = 0,
u(L, t) = f(t),
0 < t,
(12.12.2)
and the initial condition
u(x, 0) = 0,
0 < x < L.
(12.12.3)
The solution of Equation 12.12.1 through Equation 12.12.3 is diﬃcult because of the
time-dependent boundary condition. Instead of solving this system directly, let us solve the
easier problem
∂A
∂t = a2 ∂2A
∂x2 ,
0 < x < L,
0 < t,
(12.12.4)
with the boundary conditions
A(0, t) = 0,
A(L, t) = 1,
0 < t,
(12.12.5)
and the initial condition
A(x, 0) = 0,
0 < x < L.
(12.12.6)

652
Advanced Engineering Mathematics with MATLAB
Separation of variables yields the solution
A(x, t) = x
L + 2
π
∞
X
n=1
(−1)n
n
sin
nπx
L

exp

−a2n2π2t
L2

.
(12.12.7)
Consider the following case. Suppose that we maintain the temperature at zero at the
end x = L until t = τ1 and then raise it to the value of unity. The resulting temperature
distribution equals zero everywhere when t < τ1 and equals A(x, t−τ1) for t > τ1. We have
merely shifted our time axis so that the initial condition occurs at t = τ1.
Consider an analogous, but more complicated, situation of the temperature at the end
position x = L held at f(0) from t = 0 to t = τ1 at which time we abruptly change it by
the amount f(τ1) −f(0) to the value f(τ1). This temperature remains until t = τ2 when
we again abruptly change it by an amount f(τ2) −f(τ1). We can imagine this process
continuing up to the instant t = τn.
Because of linear superposition, the temperature
distribution at any given time equals the sum of these temperature increments:
u(x, t) = f(0)A(x, t) + [f(τ1) −f(0)]A(x, t −τ1) + [f(τ2) −f(τ1)]A(x, t −τ2)
+ · · · + [f(τn) −f(τn−1)]A(x, t −τn),
(12.12.8)
where τn is the time of the most recent temperature change. If we write
∆fk = f(τk) −f(τk−1),
and
∆τk = τk −τk−1,
(12.12.9)
Equation 12.12.8 becomes
u(x, t) = f(0)A(x, t) +
n
X
k=1
A(x, t −τk)∆fk
∆τk
∆τk.
(12.12.10)
Consequently, in the limit of ∆τk →0, Equation 12.12.10 becomes
u(x, t) = f(0)A(x, t) +
Z t
0
A(x, t −τ)f ′(τ) dτ,
(12.12.11)
assuming that f(t) is diﬀerentiable. Equation 12.12.11 is the superposition integral. We can
obtain an alternative form by integration by parts:
u(x, t) = f(t)A(x, 0) −
Z t
0
f(τ)∂A(x, t −τ)
∂τ
dτ,
(12.12.12)
or
u(x, t) = f(t)A(x, 0) +
Z t
0
f(τ)∂A(x, t −τ)
∂t
dτ,
(12.12.13)
because
∂A(x, t −τ)
∂τ
= −∂A(x, t −τ)
∂t
.
(12.12.14)

The Laplace Transform
653
To illustrate61 the superposition integral, suppose f(t) = t.
Then, by Equation
12.12.11,
u(x, t) =
Z t
0
 x
L + 2
π
∞
X
n=1
(−1)n
n
sin
nπx
L

exp

−a2n2π2
L2
(t −τ)

dτ
(12.12.15)
= xt
L + 2L2
a2π3
∞
X
n=1
(−1)n
n3
sin
nπx
L
 
1 −exp

−a2n2π2t
L2

.
(12.12.16)
• Example 12.12.1: Temperature oscillations in a wall heated by an alternating current
In addition to ﬁnding solutions to heat conduction problems with time-dependent
boundary conditions, we can also apply the superposition integral to the nonhomogeneous
heat equation when the source depends on time. Jeglic62 used this technique in obtaining
the temperature distribution within a slab heated by alternating electric current. If we
assume that the ﬂat plate has a surface area A and depth L, then the heat equation for the
plate when electrically heated by an alternating current of frequency ω is
∂u
∂t −a2 ∂2u
∂x2 =
2q
ρCpAL sin2(ωt),
0 < x < L,
0 < t,
(12.12.17)
where q is the average heat rate caused by the current, ρ is the density, Cp is the speciﬁc
heat at constant pressure, and a2 is the diﬀusivity of the slab. We will assume that we
insulated the inner wall so that
∂u(0, t)
∂x
= 0,
0 < t,
(12.12.18)
while we allow the outer wall to radiatively cool to free space at the temperature of zero or
κ∂u(L, t)
∂x
+ hu(L, t) = 0,
0 < t,
(12.12.19)
where κ is the thermal conductivity and h is the heat transfer coeﬃcient.
The slab is
initially at the temperature of zero or
u(x, 0) = 0,
0 < x < L.
(12.12.20)
To solve the heat equation, we ﬁrst solve the simpler problem of
∂A
∂t −a2 ∂2A
∂x2 = 1,
0 < x < L,
0 < t,
(12.12.21)
61 This occurs, for example, in McAfee, K. B., 1958: Stress-enhanced diﬀusion in glass. I. Glass under
tension and compression. J. Chem. Phys., 28, 218–226. McAfee used an alternative method of guessing
the solution.
62 Jeglic, F. A., 1962:
An analytical determination of temperature oscillations in a wall heated by
alternating current. NASA Tech. Note No. D–1286. In a similar vein, Al-Nimr and Abdallah (Al-Nimr,
M. A., and M. R. Abdallah, 1999: Thermal behavior of insulated electric wires producing pulsating signals.
Heat Transfer Eng., 20(4), 62–74) found the heat transfer with an insulated wire that carries an alternating
current.

654
Advanced Engineering Mathematics with MATLAB
Table 12.12.1: The First Six Roots of the Equation kn tan(kn) = h∗
h∗
k1
k2
k3
k4
k5
k6
0.001
0.03162
3.14191
6.28334
9.42488
12.56645
15.70803
0.002
0.04471
3.14223
6.28350
9.42499
12.56653
15.70809
0.005
0.07065
3.14318
6.28398
9.42531
12.56677
15.70828
0.010
0.09830
3.14477
6.28478
9.42584
12.56717
15.70860
0.020
0.14095
3.14795
6.28637
9.42690
12.56796
15.70924
0.050
0.22176
3.15743
6.29113
9.43008
12.57035
15.71115
0.100
0.31105
3.17310
6.29906
9.43538
12.57432
15.71433
0.200
0.43284
3.20393
6.31485
9.44595
12.58226
15.72068
0.500
0.65327
3.29231
6.36162
9.47748
12.60601
15.73972
1.000
0.86033
3.42562
6.43730
9.52933
12.64529
15.77128
2.000
1.07687
3.64360
6.57833
9.62956
12.72230
15.83361
5.000
1.31384
4.03357
6.90960
9.89275
12.93522
16.01066
10.000
1.42887
4.30580
7.22811
10.20026
13.21418
16.25336
20.000
1.49613
4.49148
7.49541
10.51167
13.54198
16.58640
∞
1.57080
4.71239
7.85399
10.99557
14.13717
17.27876
with the boundary conditions
∂A(0, t)
∂x
= 0,
κ∂A(L, t)
∂x
+ hA(L, t) = 0,
0 < t,
(12.12.22)
and the initial condition
A(x, 0) = 0,
0 < x < L.
(12.12.23)
The solution A(x, t) is the indicial admittance because it is the response of a system to
forcing by the step function H(t).
We solve Equation 12.12.21 through Equation 12.12.23 by separation of variables. We
begin by assuming that A(x, t) consists of a steady-state solution w(x) plus a transient
solution v(x, t), where
a2w′′(x) = −1,
w′(0) = 0,
κw′(L) + hw(L) = 0,
(12.12.24)
∂v
∂t = a2 ∂2v
∂x2 ,
∂v(0, t)
∂x
= 0,
κ∂v(L, t)
∂x
+ hv(L, t) = 0,
(12.12.25)
and
v(x, 0) = −w(x).
(12.12.26)
Solving Equation 12.12.24,
w(x) = L2 −x2
2a2
+ κL
ha2 .
(12.12.27)
Turning to the transient solution v(x, t), we use separation of variables and ﬁnd that
v(x, t) =
∞
X
n=1
Cn cos
knx
L

exp

−a2k2
nt
L2

,
(12.12.28)
where kn is the nth root of the transcendental equation: kn tan(kn) = hL/κ = h∗. Table
12.12.1 gives the ﬁrst six roots for various values of hL/κ.

The Laplace Transform
655
Our ﬁnal task is to compute Cn. After substituting t = 0 into Equation 12.12.28, we
are left with a orthogonal expansion of −w(x) using the eigenfunctions cos(knx/L). From
Equation 6.3.4,
Cn =
R L
0 −w(x) cos(knx/L) dx
R L
0 cos2(knx/L) dx
=
−L3 sin(kn)/(a2k3
n)
L[kn + sin(2kn)/2]/(2kn) = −
2L2 sin(kn)
a2k2n[kn + sin(2kn)/2].
(12.12.29)
Combining Equation 12.12.28 and Equation 12.12.29,
v(x, t) = −2L2
a2
∞
X
n=1
sin(kn) cos(knx/L)
k2n[kn + sin(2kn)/2] exp

−a2k2
nt
L2

.
(12.12.30)
Consequently, A(x, t) equals
A(x, t) = L2 −x2
2a2
+ κL
ha2 −2L2
a2
∞
X
n=1
sin(kn) cos(knx/L)
k2n[kn + sin(2kn)/2] exp

−a2k2
nt
L2

.
(12.12.31)
We now wish to use the solution Equation 12.12.31 to ﬁnd the temperature distribution
within the slab when it is heated by a time-dependent source f(t). As in the case of time-
dependent boundary conditions, we imagine that we can break the process into an inﬁnite
number of small changes to the heating, which occur at the times t = τ1, t = τ2, etc.
Consequently, the temperature distribution at the time t following the change at t = τn and
before the change at t = τn+1 is
u(x, t) = f(0)A(x, t) +
n
X
k=1
A(x, t −τk)∆fk
∆τk
∆τk,
(12.12.32)
where
∆fk = f(τk) −f(τk−1),
and
∆τk = τk −τk−1.
(12.12.33)
In the limit of ∆τk →0,
u(x, t) = f(0)A(x, t) +
Z t
0
A(x, t −τ)f ′(τ) dτ = f(t)A(x, 0) +
Z t
0
f(τ)∂A(x, t −τ)
∂τ
dτ.
(12.12.34)
In our present problem,
f(t) =
2q
ρCpAL sin2(ωt),
and
f ′(t) =
2qω
ρCpAL sin(2ωt).
(12.12.35)
Therefore,
u(x, t) =
2qω
ρCpAL
Z t
0
sin(2ωτ)
L2 −x2
2a2
+ κL
ha2
−2L2
a2
∞
X
n=1
sin(kn)
k2n[kn + sin(2kn)/2] cos
knx
L

exp

−a2k2
n(t −τ)
L2

dτ
(12.12.36)
= −
q
ρCpAL
L2 −x2
2a2
+ κL
ha2

cos(2ωτ)|t
0
(12.12.37)

656
Advanced Engineering Mathematics with MATLAB
0
0.5
1
0
2
4
6
0
0.5
1
1.5
2
DISTANCE
TIME
SOLUTION
Figure 12.12.1: The nondimensional temperature a2AρCpu(x, t)/qL within a slab that we heat by alter-
nating electric current as a function of position x/L and time a2t/L2 when we insulate the x = 0 end and
let the x = L end radiate to free space at temperature zero. The initial temperature is zero, hL/κ = 1, and
a2/(L2ω) = 1.
−
4L2qω
a2ρCpAL
∞
X
n=1
sin(kn) exp(−a2k2
nt/L2)
k2n[kn + sin(2kn)/2]
cos
knx
L
 Z t
0
sin(2ωτ) exp
a2k2
nτ
L2

dτ
=
qL
a2AρCp
L2 −x2
2L2
+ κ
hL

[1 −cos(2ωt)]
−
∞
X
n=1
4 sin(kn) cos(knx/L)
k2n[kn + sin(2kn)/2][4 + a4k4n/(L4ω2)]
×
a2k2
n
ωL2 sin(2ωt) −2 cos(2ωt) + 2 exp

−a2k2
nt
L2

.
(12.12.38)
Figure 12.12.1 illustrates Equation 12.12.38 for hL/κ = 1, and a2/(L2ω) = 1. This ﬁgure
was created using the MATLAB script
clear
asq over omegaL2 = 1; h star = 1; m = 0; M = 10;
dx = 0.1; dt = 0.1;
% create initial guess at k n
zero = zeros(length(M));
for n = 1:10000
k1 = 0.1*n; k2 = 0.1*(n+1);
prod = k1 * tan(k1);
y1 = h star - prod; y2 = h star - k2 * tan(k2);
if (y1*y2 <= 0 & prod < 2 & m < M) m = m+1; zero(m) = k1; end;
end;
% use Newton-Raphson method to improve values of k n
for n = 1:M; for k = 1:10
f = h star - zero(n) * tan(zero(n));
fp = - tan(zero(n)) - zero(n) * sec(zero(n))^2;
zero(n) = zero(n) - f / fp;

The Laplace Transform
657
end; end;
% compute grid and initialize solution
X = [0:dx:1]; T = [0:dt:6];
temp1 = (0.5 + 1/h star)*ones(1,length(X)) - 0.5*X.*X;
temp2 = ones(1,length(T)) - cos(2*T);
u = temp1’ * temp2;
XX = X’ * ones(1,length(T));
TT = ones(1,length(X))’ * T;
% compute solution from Equation 12.12.38
for m = 1:M
xtemp1 = zero(m) * zero(m);
xtemp2 = 4 + asq over omegaL2*asq over omegaL2*xtemp1*xtemp1;
xtemp3 = asq over omegaL2 * xtemp1;
xtemp4 = zero(m) + sin(2*zero(m))/2;
xtemp5 = asq over omegaL2 * xtemp1;
aaaaa = 4 * sin(zero(m)) / (xtemp1 * xtemp2 * xtemp4);
u = u - aaaaa * cos(zero(m)*X)’ ...
* (xtemp5 * sin(2*T) - 2 * cos(2*T) + 2 * exp(-xtemp5 * T));
end
surf(XX,TT,u)
xlabel(’DISTANCE’,’Fontsize’,20); ylabel(’TIME’,’Fontsize’,20)
zlabel(’SOLUTION’,’Fontsize’,20)
The oscillating solution, reﬂecting the periodic heating by the alternating current, rapidly
reaches equilibrium. Because heat is radiated to space at x = L, the temperature is maxi-
mum at x = 0 at any given instant as heat ﬂows from x = 0 to x = L.
⊓⊔
• Example 12.12.2
Consider the following heat conduction problem with time-dependent forcing and/or
boundary conditions:
∂u
∂t = a2L(u) + f(P, t),
0 < t,
(12.12.39)
B(u) = g(Q, t),
0 < t,
(12.12.40)
and
u(P, 0) = h(P),
(12.12.41)
where
L(u) = C0 + C1
∂
∂x1

K1
∂u
∂x1

+ C2
∂
∂x2

K2
∂u
∂x2

+ C3
∂
∂x3

K3
∂u
∂x3

,
(12.12.42)
B(u) = c0 + c1
∂u
∂x1
+ c2
∂u
∂x2
+ c3
∂u
∂x3
,
(12.12.43)
P denotes an arbitrary interior point at (x1, x2, x3) of a region R, and Q is any point on
the boundary of R. Here ci, Ci, and Ki are functions of x1, x2, and x3 only.
Many years ago, Bartels and Churchill63 extended Duhumel’s theorem to solve this heat
conduction problem. They did this by ﬁrst introducing the simpler initial-boundary-value
63 Bartels, R. C. F., and R. V. Churchill, 1942:
Resolution of boundary problems by the use of a
generalized convolution. Am. Math. Soc. Bull., 48, 276–282.

658
Advanced Engineering Mathematics with MATLAB
problem:
∂v
∂t = a2L(v) + f(P, t1),
0 < t,
(12.12.44)
B(v) = g(Q, t1),
0 < t,
(12.12.45)
and
v(P, 0) = h(P),
(12.12.46)
which has a constant forcing and boundary conditions in place of the time-dependent ones.
Here t1 denotes an arbitrary but ﬁxed instant of time. Then Bartels and Churchill proved
that the solution to the original problem is given by the convolution integral
u(P, t) = ∂
∂t
Z t
0
v(P, t −τ, τ) dτ

.
(12.12.47)
To illustrate64 this technique, let us solve
∂u
∂t = a2
∂2u
∂r2 + 2
r
∂u
∂r

= a2
r
∂2(ru)
∂r2
,
α < r < β,
0 < t,
(12.12.48)
subject to the boundary conditions
u(α, t) = u0e−ct,
∂u(β, t)
∂r
= 0,
0 < t,
(12.12.49)
and the initial condition u(r, 0) = u0, α < r < β.
We begin by solving the alternative problem
∂v
∂t = a2
∂2v
∂r2 + 2
r
∂v
∂r

= a2
r
∂2(rv)
∂r2
,
α < r < β,
0 < t,
(12.12.50)
subject to the boundary conditions
v(α, t, t′) = u0e−ct′,
∂v(β, t, t′)
∂r
= 0,
0 < t,
(12.12.51)
and the initial condition v(r, 0, t′) = u0, α < r < β, or equivalently
∂w
∂t = a2
∂2w
∂r2 + 2
r
∂w
∂r

= a2
r
∂2(rw)
∂r2
,
α < r < β,
0 < t,
(12.12.52)
subject to the boundary conditions
w(α, t, t′) = 0,
∂w(β, t, t′)
∂r
= 0,
0 < t,
(12.12.53)
and the initial condition w(r, 0, t′) = u0(1 −e−ct′), α < r < β, where v(r, t, t′) = u0e−ct′ +
w(r, t, t′).
64 See Reiss, H., and V. K. LaMer, 1950: Diﬀusional boundary value problems involving moving bound-
aries, connected with the growth of colloidal particles. J. Chem. Phys., 18, 1–12.

The Laplace Transform
659
The heat condition problem Equation 12.12.52 and Equation 12.12.53 can be solved
using separation of variables. Following Example 8.3.6, we ﬁnd that
w(r, t, t′) = αu0(1 −e−ct′)
r
∞
X
n=1
sin[kn(r −α)]
kncn
e−a2k2
nt,
(12.12.54)
where kn is the nth root of βk = tan[k(β−α)], and 2cn = {β sin2[kn(β−α)]−α}. Therefore,
u(x, t) = αu0
r
∂
∂t
(Z t
0
(1 −e−cτ)
∞
X
n=1
sin[kn(r −α)]
kncn
e−a2k2
n(t−τ) dτ
)
(12.12.55)
= αu0
r
∞
X
n=1
sin[kn(r −α)]
kncn
∂
∂t
Z t
0
e−a2k2
n(t−τ) −e−a2k2
n(t−τ)−cτ dτ

(12.12.56)
= αu0
r
∞
X
n=1
sin[kn(r −α)]
kncn
∂
∂t
(
1 −e−a2k2
nt
a2k2n
−e−ct −e−a2k2
nt
a2k2n −c
)
(12.12.57)
= αcu0
r
∞
X
n=1
sin[kn(r −α)]
kncn
e−a2k2
nt −e−ct
c −a2k2n
,
(12.12.58)
and the ﬁnal answer is
u(x, t) = u0e−ct + αcu0
r
∞
X
n=1
e−a2k2
nt −e−ct
(c −a2k2n)kncn
sin[kn(r −α)].
(12.12.59)
Problems
1. Solve the heat equation65
∂u
∂t = a2 ∂2u
∂x2 ,
0 < x < L,
0 < t,
subject to the boundary conditions u(0, t) = u(L, t) = f(t), 0 < t, and the initial condition
u(x, 0) = 0, 0 < x < L.
Step 1: First solve the heat conduction problem
∂A
∂t = a2 ∂2A
∂x2 ,
0 < x < L,
0 < t,
subject to the boundary conditions A(0, t) = A(L, t) = 1, 0 < t, and the initial condition
A(x, 0) = 0, 0 < x < L. Show that
A(x, t) = 1 −4
π
∞
X
n=1
sin[(2n −1)πx/L]
2n −1
e−a2(2n−1)2π2t/L2.
65 See Tao, L. N., 1960: Magnetohydrodynamic eﬀects on the formation of Couette ﬂow. J. Aerosp. Sci.,
27, 334–338.

660
Advanced Engineering Mathematics with MATLAB
Step 2: Use Duhamel’s theorem and show that
u(x, t) = 4πa2
L2
∞
X
n=1
(2n −1) sin
(2n −1)πx
L

e−a2(2n−1)2π2t/L2 Z t
0
f(τ)ea2(2n−1)2π2τ/L2 dτ.
2. A thermometer measures temperature by the thermal expansion of a liquid (usually
mercury or alcohol) stored in a bulb into a glass stem containing an empty cylindrical
channel. Under normal conditions, temperature changes occur suﬃciently slowly so that
the temperature within the liquid is uniform.
However, for rapid temperature changes
(such as those that would occur during the rapid ascension of an airplane or meteorological
balloon), signiﬁcant errors could occur. In such situations the recorded temperature would
lag behind the actual temperature because of the time needed for the heat to conduct in or
out of the bulb. During his investigation of this question, McLeod66 solved
∂u
∂t = a2 1
r
∂
∂r

r∂u
∂r

,
0 ≤r < b,
0 < t,
subject to the boundary conditions limr→0 |u(r, t)| < ∞, and u(b, t) = ϕ(t), 0 < t, and the
initial condition u(r, 0) = 0, 0 ≤r < b. The analysis was as follows:
Step 1: First solve the heat conduction problem
∂A
∂t = a2
r
∂
∂r

r∂A
∂r

,
0 ≤r < b,
0 < t,
subject to the boundary conditions limr→0 |A(r, t)| < ∞, and A(b, t) = 1, 0 < t, and the
initial condition A(r, 0) = 0, 0 ≤r < b. Show that
A(r, t) = 1 −2
∞
X
n=1
J0(knr/b)
kn J1(kn) e−a2k2
nt/b2,
where J0(kn) = 0.
Step 2: Use Duhamel’s theorem and show that
u(r, t) = 2a2
b2
∞
X
n=1
kn J0(knr/b)
J1(kn)
Z t
0
ϕ(τ) e−a2k2
n(t−τ)/b2 dτ.
Step 3: If ϕ(t) = Gt, show that
u(r, t) = 2G
∞
X
n=1
J0(knr/b)
kn J1(kn)

t +
b2
a2k2n

e−a2k2
nt/b2 −1

.
McLeod found that for a mercury thermometer of 10-cm length a lag of 0.01◦C would
occur for a warming rate of 0.032◦C s−1 (a warming gradient of 1.9◦C per thousand feet
66 McLeod, A. R., 1919: On the lags of thermometers with spherical and cylindrical bulbs in a medium
whose temperature is changing at a constant rate. Philos. Mag., Ser. 6, 37, 134–144. See also Bromwich,
T. J. I’A., 1919: Examples of operational methods in mathematical physics. Philos. Mag., Ser. 6, 37,
407–419; McLeod, A. R., 1922: On the lags of thermometers. Philos. Mag., Ser. 6, 43, 49–70.

The Laplace Transform
661
and a descent of one thousand feet per minute). Although this is a very small number,
when he included the surface conductance of the glass tube, the lag increased to 0.85◦C.
Similar problems plague bimetal thermometers67 and thermistors68 used in radiosondes
(meteorological sounding balloons).
3. A classic problem69 in ﬂuid mechanics is the motion of a semi-inﬁnite viscous ﬂuid that
results from the sudden movement of the adjacent wall starting at t = 0. Initially the ﬂuid
is at rest. If we denote the velocity of the ﬂuid parallel to the wall by u(x, t), the governing
equation is
∂u
∂t = ν ∂2u
∂x2 ,
0 < x < ∞,
0 < t,
with the boundary conditions u(0, t) = V (t), limx→∞u(x, t) →0, 0 < t, and the initial
condition u(x, 0) = 0, 0 < x < ∞.
Step 1: Find the step response by solving
∂A
∂t = ν ∂2A
∂x2 ,
0 < x < ∞,
0 < t,
subject to the boundary conditions
A(0, t) = 1,
lim
x→∞A(x, t) →0,
0 < t,
and the initial condition A(x, 0) = 0, 0 < x < ∞. Show that
A(x, t) = erfc

x
2
√
νt

=
2
√π
Z ∞
x/2
√
νt
e−η2 dη,
where erfc(·) is the complementary error function. Hint: Use Laplace transforms.
Step 2: Use Duhamel’s theorem and show that the solution is
u(x, t) =
Z t
0
V (t −τ)x exp(−x2/4ντ)
2
√
πντ 3
dτ = 2
π
Z ∞
x/
√
4νt
V

t −
x2
4νη2

e−η2 dη.
4. During their study of the propagation of a temperature step in a nearly supercritical van
der Waals gas, Zappoli and Durand-Daubin70 solved
∂u
∂t = a2 ∂2u
∂x2 ,
0 < x < ∞,
0 < t,
with the boundary conditions u(0, t) = u0 −2
3f(t), limx→∞u(x, t) →0, 0 < t, and the
initial condition u(x, 0) = 0, 0 < x < ∞, where u0 is a constant.
67 Mitra, H., and M. B. Datta, 1954: Lag coeﬃcient of bimetal thermometer of chronometric radiosonde.
Indian J. Meteorol. Geophys., 5, 257–261.
68 Badgley, F. I., 1957: Response of radiosonde thermistors. Rev. Sci. Instrum., 28, 1079–1084.
69 This problem was ﬁrst posed and partially solved by Stokes, G. G., 1850: On the eﬀect of the internal
friction of ﬂuids on the motions of pendulums. Proc. Cambridge Philos. Soc., 9, Part II, [8]–[106].
70 Zappoli, B., and A. Durand-Daubin, 1994: Heat and mass transport in a near supercritical ﬂuid. Phys.
Fluids, 6, 1929–1936.

662
Advanced Engineering Mathematics with MATLAB
Step 1: Find the step response by solving
∂A
∂t = a2 ∂2A
∂x2 ,
0 < x < ∞,
0 < t,
subject to the boundary conditions A(0, t) = 1, limx→∞A(x, t) →0, 0 < t, and the initial
condition A(x, 0) = 0, 0 < x < ∞. Show that
A(x, t) = erfc

x
2a
√
t

=
2
√π
Z ∞
x/(2a
√
t )
e−η2 dη,
where erfc(·) is the complementary error function. Hint: Use Laplace transforms.
Step 2: Use Duhamel’s theorem and show that the solution is
u(x, t) = u0 erfc

x
2a
√
t

−
4
3√π
Z ∞
x/(2a
√
t )
f

t −
x2
4a2η2

e−η2 dη.
5. Solve the heat equation
∂u
∂t = ∂2u
∂x2 ,
0 < x < 1,
0 < t,
subject to the boundary conditions u(0, t) = f(t), ux(1, t) = −hu(1, t), 0 < t, and the initial
condition u(x, 0) = 0, 0 < x < 1.
Step 1: First solve the heat conduction problem
∂A
∂t = ∂2A
∂x2 ,
0 < x < 1,
0 < t,
subject to the boundary conditions A(0, t) = 1, Ax(1, t) = −hA(1, t), 0 < t, and the initial
condition A(x, 0) = 0, 0 < x < 1. Show that
A(x, t) = 1 −
hx
1 + h −2
∞
X
n=1
k2
n + h2
kn (k2n + h2 + h) sin(knx)e−k2
nt,
where kn is the nth root of k cot(k) = −h.
Step 2: Use Duhamel’s theorem and show that
u(x, t) = 2
∞
X
n=1
kn(k2
n + h2)
k2n + h2 + h sin(knx)e−k2
nt
Z t
0
f(τ)ek2
nτ dτ.
12.13 THE SOLUTION OF LAPLACE’S EQUATION
Laplace transforms are useful in solving Laplace’s or Poisson’s equation over a semi-
inﬁnite strip. The following problem illustrates this technique.
Let us solve Poisson’s equation within a semi-inﬁnite circular cylinder
1
r
∂
∂r

r∂u
∂r

+ ∂2u
∂z2 = 2
b n(z)δ(r −b),
0 ≤r < a,
0 < z < ∞,
(12.13.1)

The Laplace Transform
663
subject to the boundary conditions
u(r, 0) = 0,
lim
z→∞|u(r, z)| < ∞,
0 ≤r < a,
(12.13.2)
and
u(a, z) = 0,
0 < z < ∞,
(12.13.3)
where 0 < b < a. This problem gives the electrostatic potential within a semi-inﬁnite cylin-
der of radius a that is grounded and has the charge density of n(z) within an inﬁnitesimally
thin shell located at r = b.
Because the domain is semi-inﬁnite in the z direction, we introduce the Laplace trans-
form
U(r, s) =
Z ∞
0
u(r, z) e−sz dz.
(12.13.4)
Thus, taking the Laplace transform of Equation 12.13.1, we have that
1
r
d
dr

rdU(r, s)
dr

+ s2U(r, s) −su(r, 0) −uz(r, 0) = 2
b N(s)δ(r −b).
(12.13.5)
Although u(r, 0) = 0, uz(r, 0) is unknown and we denote its value by f(r).
Therefore,
Equation 12.13.5 becomes
1
r
d
dr

rdU(r, s)
dr

+ s2U(r, s) = f(r) + 2
b N(s)δ(r −b),
0 ≤r < a,
(12.13.6)
with limr→0 |U(r, s)| < ∞, and U(a, s) = 0.
To solve Equation 12.13.6 we ﬁrst assume that we can rewrite f(r) as the Fourier-Bessel
series
f(r) =
∞
X
n=1
AnJ0(knr/a),
(12.13.7)
where kn is the nth root of the J0(k) = 0, and
An =
2
a2J2
1(kn)
Z a
0
f(r) J0(knr/a) r dr.
(12.13.8)
Similarly, the expansion for the delta function is
δ(r −b) = 2b
a2
∞
X
n=1
J0(knb/a)J0(knr/a)
J2
1(kn)
,
(12.13.9)
because
Z a
0
δ(r −b)J0(knr/a) r dr = b J0(knb/a).
(12.13.10)
Why we chose this particular expansion will become apparent shortly.
Thus, Equation 12.13.6 may be rewritten as
1
r
d
dr

rdU(r, s)
dr

+ s2U(r, s) = 2
a2
∞
X
n=1
2N(s)J0(knb/a) + ak
J2
1(kn)
J0(knr/a),
(12.13.11)
where ak =
R a
0 f(r) J0(knr/a) r dr.

664
Advanced Engineering Mathematics with MATLAB
The form of the right side of Equation 12.13.11 suggests that we seek solutions of the
form
U(r, s) =
∞
X
n=1
BnJ0(knr/a),
0 ≤r < a.
(12.13.12)
We now understand why we rewrote the right side of Equation 12.13.6 as a Fourier-Bessel
series; the solution U(r, s) automatically satisﬁes the boundary condition U(a, s) = 0. Sub-
stituting Equation 12.13.12 into Equation 12.13.11, we ﬁnd that
U(r, s) = 2
a2
∞
X
n=1
2N(s)J0(knb/a) + ak
(s2 −k2n/a2)J2
1(kn) J0(knr/a),
0 ≤r < a.
(12.13.13)
We have not yet determined ak. Note, however, that in order for the inverse of Equation
12.13.13 not to grow as eknz/a, the numerator must vanish when s = kn/a and s = kn/a is
a removable pole. Thus,
ak = −2N(kn/a)J0(knb/a),
(12.13.14)
and
U(r, s) = 4
a2
∞
X
n=1
[N(s) −N(kn/a)]J0(knb/a)
(s2 −k2n/a2)J2
1(kn)
J0(knr/a),
0 ≤r < a.
(12.13.15)
The inverse of U(r, s) then follows directly from simple inversions, the convolution theorem,
and the deﬁnition of the Laplace transform. The complete solution is
u(r, z) = 2
a
∞
X
n=1
J0(knb/a)J0(knr/a)
kn J2
1(kn)
×
Z z
0
n(τ)ekn(z−τ)/a dτ −
Z z
0
n(τ)e−kn(z−τ)/a dτ
−
Z ∞
0
n(τ)e−knτ/aeknz/a dτ +
Z ∞
0
n(τ)e−knτ/ae−knz/a dτ

(12.13.16)
= 2
a
∞
X
n=1
J0(knb/a)J0(knr/a)
kn J2
1(kn)
(12.13.17)
×
Z ∞
0
n(τ)e−kn(z+τ)/a dτ −
Z z
0
n(τ)e−kn(z−τ)/a dτ −
Z ∞
z
n(τ)e−kn(τ−z)/a dτ

.
Problems
1. Use Laplace transforms to solve
∂2u
∂x2 + ∂2u
∂y2 = 0,
0 < x < ∞,
0 < y < a,
subject to the boundary conditions
u(0, y) = 1,
lim
x→∞|u(x, y)| < ∞,
0 < y < a,

The Laplace Transform
665
and
u(x, 0) = u(x, a) = 0,
0 < x < ∞.
2. Use Laplace transforms to solve
1
r
∂
∂r

r∂u
∂r

+ ∂2u
∂z2 = 0,
0 ≤r < a,
0 < z < ∞,
subject to the boundary conditions
u(r, 0) = 1,
lim
z→∞|u(r, z)| < ∞,
0 ≤r < a,
and
lim
r→0 |u(r, z)| < ∞,
u(a, z) = 0,
0 < z < ∞.
Further Readings
Churchill, R. V., 1972: Operational Mathematics. McGraw-Hill Book Co., 481 pp. A classic
textbook on Laplace transforms.
Doetsch, G., 1950: Handbuch der Laplace-Transformation. Band 1. Theorie der Laplace-
Transformation. Birkh¨auser Verlag, 581 pp.; Doetsch, G., 1955: Handbuch der Laplace-
Transformation. Band 2. Anwendungen der Laplace-Transformation. 1. Abteilung. Birk-
h¨auser Verlag, 433 pp.; Doetsch, G., 1956: Handbuch der Laplace-Transformation. Band 3.
Anwendungen der Laplace-Transformation. 2. Abteilung. Birkh¨auser Verlag, 298 pp. One
of the standard reference books on Laplace transforms.
LePage, W. R., 1980: Complex Variables and the Laplace Transform for Engineers. Dover,
483 pp. Laplace transforms approached from complex variable theory and a few applica-
tions.
McLachlan, N. W., 1944: Complex Variables & Operational Calculus with Technical Appli-
cations. Cambridge Press, 355 pp. An early book on Laplace transforms from the view of
complex variables.
Thomson, W. T., 1960: Laplace Transformation. Prentice-Hall, 255 pp. Presents Laplace
transforms in the engineering applications that gave them birth.
Watson, E. J., 1981: Laplace Transforms and Applications. Van Nostrand Reinhold, 205
pp. A brief and very complete guide to Laplace transforms.

Chapter 13
The Z-Transform
Since the Second World War, the rise of digital technology has resulted in a corre-
sponding demand for designing and understanding discrete-time (data sampled) systems.
These systems are governed by diﬀerence equations in which members of the sequence yn
are coupled to each other.
One source of diﬀerence equations is the numerical evaluation of integrals on a digital
computer.
Because we can only have values at discrete time points tk = kT for k =
0, 1, 2, . . ., the value of the integral y(t) =
R t
0 f(τ) dτ is
y(kT) =
Z kT
0
f(τ) dτ =
Z (k−1)T
0
f(τ) dτ +
Z kT
(k−1)T
f(τ) dτ
(13.0.1)
= y[(k −1)T] +
Z kT
(k−1)T
f(τ) dτ = y[(k −1)T] + Tf(kT),
(13.0.2)
because
R kT
(k−1)T f(τ) dτ ≈Tf(kT).
The right side of Equation 13.0.2 is an example of
a ﬁrst-order diﬀerence equation because the numerical scheme couples the sequence value
y(kT) directly to the previous sequence value y[(k −1)T]. If Equation 13.0.2 had contained
y[(k −2)T], then it would have been a second-order diﬀerence equation, and so forth.
Although we could use the conventional Laplace transform to solve these diﬀerence
equations, the use of z-transforms can greatly facilitate the analysis, especially when we
only desire responses at the sampling instants. Often the entire analysis can be done using
only the transforms and the analyst does not actually ﬁnd the sequence y(kT).
In this chapter we will ﬁrst deﬁne the z-transform and discuss its properties. Then we
will show how to ﬁnd its inverse. Finally we shall use them to solve diﬀerence equations.
667

668
Advanced Engineering Mathematics with MATLAB
f(t)
t
t
t
T
2T
3T
T
2T
3T
0
0
0
ε
f  (t)
S
f  (t)
S*
Figure 13.1.1: Schematic of how a continuous function f(t) is sampled by a narrow-width pulse sampler
f∗
S(t) and an ideal sampler fS(t).
13.1 THE RELATIONSHIP OF THE Z-TRANSFORM TO THE LAPLACE TRANSFORM1
Let f(t) be a continuous function that an instrument samples every T units of time.
We denote this data-sampled function by f ∗
S(t). See Figure 13.1.1. Taking ǫ, the duration
of an individual sampling event, to be small, we may approximate the narrow-width pulse
in Figure 13.1.1 by ﬂat-topped pulses. Then f ∗
S(t) approximately equals
f ∗
S(t) ≈1
ǫ
∞
X
n=0
f(nT) [H(t −nT + ǫ/2) −H(t −nT −ǫ/2)] ,
(13.1.1)
if ǫ ≪T.
Clearly the presence of ǫ is troublesome in Equation 13.1.1; it adds one more parameter
to our problem. For this reason we introduce the concept of the ideal sampler, where the
sampling time becomes inﬁnitesimally small so that
fS(t) = lim
ǫ→0
∞
X
n=0
f(nT)
H(t −nT + ǫ/2) −H(t −nT −ǫ/2)
ǫ

=
∞
X
n=0
f(nT)δ(t −nT).
(13.1.2)
Let us now ﬁnd the Laplace transform of this data-sampled function. From the linearity
property of Laplace transforms,
FS(s) = L[fS(t)] = L
"
∞
X
n=0
f(nT)δ(t −nT)
#
=
∞
X
n=0
f(nT)L[δ(t −nT)].
(13.1.3)
1 Gera (Gera, A. E., 1999: The relationship between the z-transform and the discrete-time Fourier
transform.
IEEE Trans.
Auto.
Control, AC-44, 370–371) explored the general relationship between
the one-sided discrete-time Fourier transform and the one-sided z-transform. See also Naumovi´c, M. B.,
2001: Interrelationship between the one-sided discrete-time Fourier transform and one-sided delta transform.
Electr. Engng., 83, 99–101.

The Z-Transform
669
Because L[δ(t −nT)] = e−nsT , Equation 13.1.3 simpliﬁes to
FS(s) =
∞
X
n=0
f(nT)e−nsT .
(13.1.4)
If we now make the substitution that z = esT , then FS(s) becomes
F(z) = Z(fn) =
∞
X
n=0
fnz−n,
(13.1.5)
where F(z) is the one-sided z-transform2 of the sequence f(nT), which we shall now denote
by fn. Here Z denotes the operation of taking the z-transform while Z−1 represents the
inverse z-transformation. We will consider methods for ﬁnding the inverse z-transform in
Section 13.3.
Just as the Laplace transform was deﬁned by an integration in t, the z-transform is
deﬁned by a power series (Laurent series) in z. Consequently, every z-transform has a region
of convergence that must be implicitly understood if not explicitly stated. Furthermore,
just as the Laplace integral diverged for certain functions, there are sequences where the
associated power series diverges and its z-transform does not exist.
Consider now the following examples of how to ﬁnd the z-transform.
• Example 13.1.1
Given the unit sequence fn = 1, n ≥0, let us ﬁnd F(z). Substituting fn into the
deﬁnition of the z-transform leads to
F(z) =
∞
X
n=0
z−n =
z
z −1,
(13.1.6)
because P∞
n=0 z−n is a complex-valued geometric series with common ratio z−1. This series
converges if |z−1| < 1 or |z| > 1, which gives the region of convergence of F(z).
MATLAB’s symbolic toolbox provides an alternative to the hand computation of the
z-transform. In the present case, the command
>> syms z; syms n positive
>> ztrans(1,n,z)
yields
ans =
z/(z-1)
⊓⊔
• Example 13.1.2
Let us ﬁnd the z-transform of the sequence
fn = e−anT ,
n ≥0,
(13.1.7)
2 The standard reference is Jury, E. I., 1964: Theory and Application of the z-Transform Method. John
Wiley & Sons, 330 pp.

670
Advanced Engineering Mathematics with MATLAB
for a real and a imaginary.
For a real, substitution of the sequence into the deﬁnition of the z-transform yields
F(z) =
∞
X
n=0
e−anT z−n =
∞
X
n=0
 e−aT z−1n.
(13.1.8)
If u = e−aT z−1, then Equation 13.1.8 is a geometric series so that
F(z) =
∞
X
n=0
un =
1
1 −u.
(13.1.9)
Because |u| = e−aT |z−1|, the condition for convergence is that |z| > e−aT . Thus,
F(z) =
z
z −e−aT ,
|z| > e−aT .
(13.1.10)
For imaginary a, the inﬁnite series in Equation 13.1.8 converges if |z| > 1, because
|u| = |z−1| when a is imaginary. Thus,
F(z) =
z
z −e−aT ,
|z| > 1.
(13.1.11)
Although the z-transforms in Equation 13.1.10 and Equation 13.1.11 are the same in these
two cases, the corresponding regions of convergence are diﬀerent. If a is a complex number,
then
F(z) =
z
z −e−aT ,
|z| > |e−aT |.
(13.1.12)
Checking our work using MATLAB, we type the commands:
>> syms a z; syms n T positive
>> ztrans(exp(-a*n*T),n,z);
>> simplify(ans)
which yields
ans =
z*exp(a*T)/(z*exp(a*T)-1)
⊓⊔
• Example 13.1.3
Let us ﬁnd the z-transform of the sinusoidal sequence
fn = cos(nωT),
n ≥0.
(13.1.13)
Substituting Equation 13.1.13 into the deﬁnition of the z-transform results in
F(z) =
∞
X
n=0
cos(nωT)z−n.
(13.1.14)
From Euler’s formula,
cos(nωT) = 1
2(einωT + e−inωT ),
(13.1.15)

The Z-Transform
671
so that Equation 13.1.14 becomes
F(z) = 1
2
∞
X
n=0

einωT z−n + e−inωT z−n

,
(13.1.16)
or
F(z) = 1
2

Z(einωT ) + Z(e−inωT )

.
(13.1.17)
From Equation 13.1.11,
Z(e±inωT ) =
z
z −e±iωT ,
|z| > 1.
(13.1.18)
Substituting Equation 13.1.18 into Equation 13.1.17 and simplifying yields
F(z) =
z[z −cos(ωT)]
z2 −2z cos(ωT) + 1,
|z| > 1.
(13.1.19)
⊓⊔
• Example 13.1.4
Let us ﬁnd the z-transform for the sequence
fn =
 1,
0 ≤n ≤5,
( 1
2)n,
6 ≤n.
(13.1.20)
From the deﬁnition of the z-transform,
Z(fn) = F(z) =
5
X
n=0
z−n +
∞
X
n=6
 1
2z
n
.
(13.1.21)
= 1 + 1
z + 1
z2 + 1
z3 + 1
z4 + 1
z5 +
2z
2z −1
−1 −1
2z −
1
4z2 −
1
8z3 −
1
16z4 −
1
32z5
(13.1.22)
=
2z
2z −1 + 1
2z +
3
4z2 +
7
8z3 +
15
16z4 +
31
32z5 .
(13.1.23)
We could also have obtained Equation 13.1.23 via MATLAB by typing the commands:
>> syms z; syms n positive
>> ztrans(’1+((1/2)^n-1)*Heaviside(n-6)’,n,z)
which yields
ans =
2*z/(2*z-1)+1/2/z+3/4/z^2+7/8/z^3+15/16/z^4+31/32/z^5
⊓⊔
We summarize some of the more commonly encountered sequences and their transforms
in Table 13.1.1 along with their regions of convergence.

672
Advanced Engineering Mathematics with MATLAB
Table 13.1.1: Z-Transforms of Some Commonly Used Sequences
fn, n ≥0
F(z)
Region of
convergence
1.
f0 = k = const.
k
|z| > 0
fn = 0, n ≥1
2.
fm = k = const.
kz−m
|z| > 0
fn = 0, for all values
of n ̸= m
3.
k = constant
kz/(z −1)
|z| > 1
4.
kn
kz/(z −1)2
|z| > 1
5.
kn2
kz(z + 1)/(z −1)3
|z| > 1
6. ke−anT , a complex
kz/
 z −e−aT 
|z| > |e−aT |
7. kne−anT , a complex
kze−aT
(z−e−aT )2
|z| > |e−aT |
8.
sin(ω0nT)
z sin(ω0T )
z2−2z cos(ω0T )+1
|z| > 1
9.
cos(ω0nT)
z[z−cos(ω0T )]
z2−2z cos(ω0T )+1
|z| > 1
10.
e−anT sin(ω0nT)
ze−aT sin(ω0T )
z2−2ze−aT cos(ω0T )+e−2aT
|z| > e−aT
11.
e−anT cos(ω0nT)
ze−aT [zeaT −cos(ω0T )]
z2−2ze−aT cos(ω0T )+e−2aT
|z| > e−aT
12.
αn , α constant
z/(z −α)
|z| > |α|
13.
nαn
αz/(z −α)2
|z| > |α|
14.
n2αn
αz(z + α)/(z −α)3
|z| > |α|
15.
sinh(ω0nT)
z sinh(ω0T )
z2−2z cosh(ω0T )+1
|z| > cosh(ω0T)
16.
cosh(ω0nT)
z[z−cosh(ω0T )]
z2−2z cosh(ω0T )+1
|z| > sinh(ω0T)
17.
an/n!
ea/z
|z| > 0
18.
[ln(a)]n/n!
a1/z
|z| > 0

The Z-Transform
673
0.0
2.5
5.0
7.5
10.0
12.5
ω
10
−4
10
−3
10
−2
10
−1
10
0
amplitude of transform
a = 0.1
a = 0.01
a = 0.001
Figure 13.1.2: The amplitude of the Laplace or Fourier transform (solid line) for the function ae−atH(t)
and the z-transform (dashed line) for the sequence fn = ae−anT as a function of frequency ω for various
positive values of a and T = 1.
• Example 13.1.5
In many engineering studies, the analysis is done entirely using transforms without
actually ﬁnding any inverses. Consequently, it is useful to compare and contrast how various
transforms behave in very simple test problems.
Consider the time function f(t) = ae−atH(t), a > 0. Its Laplace and Fourier transform
are identical, namely a/(a+iω), if we set s = iω. In Figure 13.1.2 we illustrate its behavior
as a function of positive ω.
Let us now generate the sequence of observations that we would measure if we sampled
f(t) every T units of time apart: fn = ae−anT . Taking the z-transform of this sequence, it
equals az/
 z −e−aT 
. Recalling that z = esT = eiωT , we can also plot this transform as
a function of positive ω. For small ω, the transforms agree, but as ω becomes larger they
diverge markedly. Why does this occur?
Recall that the z-transform is computed from a sequence comprised of samples from a
continuous signal. One very important ﬂaw in sampled data is the possible misrepresenta-
tion of high-frequency eﬀects as lower-frequency phenomena. It is this aliasing or folding
eﬀect that we are observing here. Consequently, the z-transform of a sampled record can
diﬀer markedly from the corresponding Laplace or Fourier transforms of the continuous
record at frequencies above one half of the sampling frequency. This also suggests that care
should be exercised in interpolating between sampling instants. Indeed, in those applica-
tions where the output between sampling instants is very important, such as in a hybrid
mixture of digital and analog systems, we must apply the so-called “modiﬁed z-transform.”
Problems
From the fundamental deﬁnition of the z-transform, ﬁnd the transform of the following
sequences, where n ≥0. Then check your answer using MATLAB.
1. fn =
  1
2
n
2. fn = einθ

674
Advanced Engineering Mathematics with MATLAB
3. fn =
 1,
0 ≤n ≤5
0,
5 < n
5. fn =
( 0,
n = 0
−1,
n = 1
an,
n ≥2
4. fn =
(   1
2
n ,
n = 0, 1, . . . , 10
  1
4
n ,
n ≥11
13.2 SOME USEFUL PROPERTIES
In principle we could construct any desired transform from the deﬁnition of the z-
transform. However, there are several general theorems that are much more eﬀective in
ﬁnding new transforms.
Linearity
From the deﬁnition of the z-transform, it immediately follows that
if
hn = c1fn + c2gn,
then
H(z) = c1F(z) + c2G(z),
(13.2.1)
where F(z) = Z(fn), G(z) = Z(gn), H(z) = Z(hn), and c1, c2 are arbitrary constants.
Multiplication by an expo-
nential sequence
If
gn = e−anT fn,
n ≥0,
then
G(z) = F(zeaT ).
(13.2.2)
This follows from
G(z) = Z(gn) =
∞
X
n=0
gn z−n =
∞
X
n=0
e−anT fn z−n =
∞
X
n=0
fn(zeaT )−n = F(zeaT ).
(13.2.3)
This is the z-transform analog to the ﬁrst shifting theorem in Laplace transforms.
Shifting
The eﬀect of shifting depends upon whether it is to the right or to the left, as Table
13.2.1 illustrates. For the sequence fn−2, no values from the sequence fn are lost; thus,
we anticipate that the z-transform of fn−2 only involves F(z). However, in forming the
sequence fn+2, the ﬁrst two values of fn are lost, and we anticipate that the z-transform of
fn+2 cannot be expressed solely in terms of F(z) but must include those two lost pieces of
information.

The Z-Transform
675
Table 13.2.1: Examples of Shifting Involving Sequences
n
fn
fn−2
fn+2
0
1
0
4
1
2
0
8
2
4
1
16
3
8
2
64
4
16
4
128
...
...
...
...
Let us now conﬁrm these conjectures by ﬁnding the z-transform of fn+1, which is a
sequence that has been shifted one step to the left. From the deﬁnition of the z-transform,
it follows that
Z(fn+1) =
∞
X
n=0
fn+1z−n = z
∞
X
n=0
fn+1z−(n+1)
(13.2.4)
or
Z(fn+1) = z
∞
X
k=1
fkz−k + zf0 −zf0,
(13.2.5)
where we added zero in Equation 13.2.5. This algebraic trick allows us to collapse the ﬁrst
two terms on the right side of Equation 13.2.5 into one and
Z(fn+1) = zF(z) −zf0.
(13.2.6)
In a similar manner, repeated applications of Equation 13.2.6 yield
Z(fn+m) = zmF(z) −zmf0 −zm−1f1 −. . . −zfm−1,
(13.2.7)
where m > 0. This shifting operation transforms fn+m into an algebraic expression involv-
ing m. Furthermore, we introduced initial sequence values, just as we introduced initial
conditions when we took the Laplace transform of the nth derivative of f(t). We will make
frequent use of this property in solving diﬀerence equations in Section 13.4.
Consider now shifting to the right by the positive integer k,
gn = fn−kHn−k,
n ≥0,
(13.2.8)
where Hn−k = 0 for n < k and 1 for n ≥k. Then the z-transform of Equation 13.2.8 is
G(z) = z−kF(z),
(13.2.9)
where G(z) = Z(gn), and F(z) = Z(fn). This follows from
G(z) =
∞
X
n=0
gnz−n =
∞
X
n=0
fn−kHn−kz−n = z−k
∞
X
n=k
fn−kz−(n−k) = z−k
∞
X
m=0
fmz−m = z−kF(z).
(13.2.10)
This result is the z-transform analog to the second shifting theorem in Laplace transforms.

676
Advanced Engineering Mathematics with MATLAB
In symbolic calculations involving MATLAB, the operator Hn−k can be expressed by
Heaviside(n-k).
Initial-value theorem
The initial value of the sequence fn, f0, can be computed from F(z) using the initial-
value theorem:
f0 = lim
z→∞F(z).
(13.2.11)
From the deﬁnition of the z-transform,
F(z) =
∞
X
n=0
fnz−n = f0 + f1z−1 + f2z−2 + . . . .
(13.2.12)
In the limit of z →∞, we obtain the desired result.
Final-value theorem
The value of fn, as n →∞, is given by the ﬁnal-value theorem:
f∞= lim
z→1 (z −1)F(z),
(13.2.13)
where F(z) is the z-transform of fn.
We begin by noting that
Z(fn+1 −fn) = lim
n→∞
n
X
k=0
(fk+1 −fk)z−k.
(13.2.14)
Using the shifting theorem on the left side of Equation 13.2.14,
zF(z) −zf0 −F(z) = lim
n→∞
n
X
k=0
(fk+1 −fk)z−k.
(13.2.15)
Applying the limit as z approaches 1 to both sides of Equation 13.2.15:
lim
z→1 (z −1)F(z) −f0 = lim
n→∞
n
X
k=0
(fk+1 −fk)
(13.2.16)
= lim
n→∞

(f1 −f0) + (f2 −f1) + . . . + (fn −fn−1) + (fn+1 −fn) + . . .

(13.2.17)
= lim
n→∞(−f0 + fn+1)
(13.2.18)
= −f0 + f∞.
(13.2.19)
Consequently,
f∞= lim
z→1 (z −1)F(z).
(13.2.20)

The Z-Transform
677
Note that this limit has meaning only if f∞exists. This occurs if F(z) has no second-order
or higher poles on the unit circle and no poles outside the unit circle.
Multiplication by n
Given
gn = nfn,
n ≥0,
(13.2.21)
this theorem states that
G(z) = −z dF(z)
dz
,
(13.2.22)
where G(z) = Z(gn), and F(z) = Z(fn).
This follows from
G(z) =
∞
X
n=0
gnz−n =
∞
X
n=0
nfnz−n = z
∞
X
n=0
nfnz−n−1 = −z dF(z)
dz
.
(13.2.23)
Periodic sequence theorem
Consider the N-periodic sequence:
fn = {f0f1f2 . . . fN−1
|
{z
}
ﬁrst period
f0f1 . . .},
(13.2.24)
and the related sequence:
xn =

fn,
0 ≤n ≤N −1,
0,
N ≤n.
(13.2.25)
This theorem allows us to ﬁnd the z-transform of fn if we can ﬁnd the z-transform of xn
via the relationship
F(z) =
X(z)
1 −z−N ,
|zN| > 1,
(13.2.26)
where X(z) = Z(xn).
This follows from
F(z) =
∞
X
n=0
fnz−n =
N−1
X
n=0
xnz−n +
2N−1
X
n=N
xn−Nz−n +
3N−1
X
n=2N
xn−2Nz−n + · · · .
(13.2.27)
Application of the shifting theorem in Equation 13.2.27 leads to
F(z) = X(z) + z−NX(z) + z−2NX(z) + · · ·
(13.2.28)
= X(z)

1 + z−N + z−2N + · · ·

.
(13.2.29)

678
Advanced Engineering Mathematics with MATLAB
Equation 13.2.29 contains an inﬁnite geometric series with common ratio z−N, which con-
verges if |z−N| < 1. Thus,
F(z) =
X(z)
1 −z−N ,
|zN| > 1.
(13.2.30)
Convolution
Given the sequences fn and gn, the convolution product of these two sequences is
wn = fn ∗gn =
n
X
k=0
fkgn−k =
n
X
k=0
fn−kgk.
(13.2.31)
Given F(z) and G(z), we then have that W(z) = F(z)G(z).
This follows from
W(z) =
∞
X
n=0
"
n
X
k=0
fkgn−k
#
z−n =
∞
X
n=0
∞
X
k=0
fkgn−kz−n,
(13.2.32)
because gn−k = 0 for k > n. Reversing the order of summation and letting m = n −k,
W(z) =
∞
X
k=0
∞
X
m=−k
fkgmz−(m+k) =
" ∞
X
k=0
fkz−k
# "
∞
X
m=0
gmz−m
#
= F(z)G(z).
(13.2.33)
We can use MATLAB’s command conv( ), which multiplies two polynomials to perform
discrete convolution as follows:
>>x = [1 1 1 1 1 1 1];
>>y = [1 2 4 8 16 32 64];
>>z = conv(x,y)
produces
z =
1 3 7 15 31 63 127 126 124 120 112 96 64
The ﬁrst seven values of z contain the convolution of the sequence x with the sequence y.
Consider now the following examples of the properties discussed in this section.
• Example 13.2.1
From
Z (an) =
1
1 −az−1 ,
(13.2.34)
for n ≥0 and |z| > |a| , we have that
Z
 einx
=
1
1 −eixz−1 ,
(13.2.35)

The Z-Transform
679
and
Z
 e−inx
=
1
1 −e−ixz−1 ,
(13.2.36)
if n ≥0 and |z| > 1. Therefore, the sequence fn = cos(nx) has the z-transform
F(z) = Z[cos(nx)] = 1
2Z
 einx
+ 1
2Z
 e−inx
(13.2.37)
= 1
2
1
1 −eixz−1 + 1
2
1
1 −e−ixz−1 =
1 −cos(x)z−1
1 −2 cos(x)z−1 + z−2 .
(13.2.38)
⊓⊔
• Example 13.2.2
Using the z-transform,
Z (an) =
1
1 −az−1 ,
n ≥0,
(13.2.39)
we ﬁnd that
Z (nan) = −z d
dz
h 1 −az−1−1i
= (−z)(−1)
 1 −az−1−2 (−a)(−1)z−2
(13.2.40)
=
az−1
(1 −az−1)2 =
az
(z −a)2 .
(13.2.41)
⊓⊔
• Example 13.2.3
Consider F(z) = 2az−1/(1 −az−1)3, where |a| < |z| and |a| < 1. Here we have that
f0 = lim
z→∞F(z) = lim
z→∞
2az−1
(1 −az−1)3 = 0
(13.2.42)
from the initial-value theorem. This agrees with the inverse of F(z):
fn = n(n + 1)an,
n ≥0.
(13.2.43)
If the z-transform consists of the ratio of two polynomials, we can use MATLAB to ﬁnd
f0. For example, if F(z) = 2z2/(z −1)3, we can ﬁnd f0 as follows:
>>num = [2 0 0];
>>den = conv([1 -1],[1 -1]);
>>den = conv(den,[1 -1]);
>>initialvalue = polyval(num,1e20) / polyval(den,1e20)
initialvalue =
2.0000e-20
Therefore, f0 = 0.
⊓⊔

680
Advanced Engineering Mathematics with MATLAB
• Example 13.2.4
Given the z-transform F(z) = (1 −a)z/[(z −1)(z −a)], where |z| > 1 > a > 0, then
from the ﬁnal-value theorem we have that
lim
n→∞fn = lim
z→1(z −1)F(z) = lim
z→1
1 −a
1 −az−1 = 1.
(13.2.44)
This is consistent with the inverse transform fn = 1 −an with n ≥0.
⊓⊔
• Example 13.2.5
Using the sequences fn = 1 and gn = an, where a is real, verify the convolution
theorem.
We ﬁrst compute the convolution of fn with gn, namely
wn = fn ∗gn =
n
X
k=0
ak =
1
1 −a −an+1
1 −a.
(13.2.45)
Taking the z-transform of wn,
W(z) =
z
(1 −a)(z −1) −
az
(1 −a)(z −a) =
z2
(z −1)(z −a) = F(z)G(z),
(13.2.46)
and the convolution theorem holds true for this special case.
Problems
Use the properties of z-transforms and Table 13.1.1 to ﬁnd the z-transform of the following
sequences. Then check your answer using MATLAB.
1. fn = nTe−anT
2. fn =

0,
n = 0
nan−1,
n ≥1
3. fn =

0,
n = 0
n2an−1,
n ≥1
4. fn = an cos(n)
[Hint : Use cos(n) = 1
2(ein + e−in)]
5. fn = cos(n −2)Hn−2
6. fn = 3 + e−2nT
7. fn = sin(nω0T + θ),
8. fn =





0,
n = 0
1,
n = 1
2,
n = 2
1,
n = 3,
fn+4 = fn
9. fn = (−1)n
(Hint: fn is a periodic sequence.)
10. Using the property stated in Equation 13.2.21 and Equation 13.2.22 twice, ﬁnd the
z-transform of n2 = n[n(1)n]. Then verify your result using MATLAB.

The Z-Transform
681
11. Verify the convolution theorem using the sequences fn = gn = 1. Then check your
results using MATLAB.
12. Verify the convolution theorem using the sequences fn = 1 and gn = n. Then check
your results using MATLAB.
13. Verify the convolution theorem using the sequences fn = gn = 1/(n!). Then check
your results using MATLAB. Hint: Use the binomial theorem with x = 1 to evaluate the
summation.
14. If a is a real number, show that Z(anfn) = F(z/a), where Z(fn) = F(z).
13.3 INVERSE Z-TRANSFORMS
In the previous two sections we dealt with ﬁnding the z-transform. In this section we
ﬁnd fn by inverting the z-transform F(z). There are four methods for ﬁnding the inverse:
(1) power series, (2) recursion, (3) partial fractions, and (4) the residue method. We will
discuss each technique individually. The ﬁrst three apply only to those functions F(z) that
are rational functions while the residue method is more general. For symbolic computations
with MATLAB, you can use iztrans.
Power series
By means of the long-division process, we can always rewrite F(z) as the Laurent
expansion:
F(z) = a0 + a1z−1 + a2z−2 + · · · .
(13.3.1)
From the deﬁnition of the z-transform,
F(z) =
∞
X
n=0
fnz−n = f0 + f1z−1 + f2z−2 + · · · ,
(13.3.2)
the desired sequence fn is given by an.
• Example 13.3.1
Let
F(z) = z + 1
2z −2 = N(z)
D(z) .
(13.3.3)
Using long division, N(z) is divided by D(z) and we obtain
F(z) = 1
2 + z−1 + z−2 + z−3 + z−4 + · · · .
(13.3.4)
Therefore,
a0 = 1
2, a1 = 1, a2 = 1, a3 = 1, a4 = 1, etc.,
(13.3.5)
which suggests that f0 = 1
2 and fn = 1 for n ≥1 is the inverse of F(z).
⊓⊔

682
Advanced Engineering Mathematics with MATLAB
• Example 13.3.2
Let us ﬁnd the inverse of the z-transform:
F(z) =
2z2 −1.5z
z2 −1.5z + 0.5.
(13.3.6)
By the long-division process, we have that
2
+
1.5z−1
+
1.25z−2
+
1.125z−3
+
· · ·
z2 −1.5z + 0.5
2z2
−
1.5z
2z2
−
3z
+
1
1.5z
−
1
1.5z
−
2.25
+
0.750z−1
1.25
−
0.750z−1
1.25
−
1.870z−1
+
· · ·
1.125z−1
+
· · ·
Thus, f0 = 2, f1 = 1.5, f2 = 1.25, f3 = 1.125, and so forth, or fn = 1 + ( 1
2)n. In general,
this technique only produces numerical values for some of the elements of the sequence.
Note also that our long division must always yield the power series Equation 13.3.1 in order
for this method to be of any use.
To check our answer using MATLAB, we type the commands:
syms z; syms n positive
iztrans((2*z^2 - 1.5*z)/(z^2 - 1.5*z + 0.5),z,n)
which yields
ans =
1 + (1/2)^n
⊓⊔
Recursive method
An alternative to long division was suggested3 several years ago. It obtains the inverse
recursively.
We begin by assuming that the z-transform is of the form
F(z) = a0zm + a1zm−1 + a2zm−2 + · · · + am−1z + am
b0zm + b1zm−1 + b2zm−2 + · · · + bm−1z + bm
,
(13.3.7)
where some of the coeﬃcients ai and bi may be zero and b0 ̸= 0. Applying the initial-value
theorem,
f0 = lim
z→∞F(z) = a0/b0.
(13.3.8)
3 Jury, E. I., 1964: Theory and Application of the z-Transform Method. John Wiley & Sons, p. 41;
Pierre, D. A., 1963:
A tabular algorithm for z-transform inversion.
Control Engng., 10(9), 110–111;
Jenkins, L. B., 1967: A useful recursive form for obtaining inverse z-transforms. Proc. IEEE, 55, 574–575.

The Z-Transform
683
Next, we apply the initial-value theorem to z[F(z) −f0] and ﬁnd that
f1 = lim
z→∞z[F(z) −f0]
(13.3.9)
= lim
z→∞z (a0 −b0f0)zm + (a1 −b1f0)zm−1 + · · · + (am −bmf0)
b0zm + b1zm−1 + b2zm−2 + · · · + bm−1z + bm
(13.3.10)
= (a1 −b1f0)/b0.
(13.3.11)
Note that the coeﬃcient a0 −b0f0 = 0 from Equation 13.3.8. Similarly,
f2 = lim
z→∞z[zF(z) −zf0 −f1]
(13.3.12)
= lim
z→∞z (a0 −b0f0)zm+1 + (a1 −b1f0 −b0f1)zm + (a2 −b2f0 −b1f1)zm−1 + · · · −bmf1
b0zm + b1zm−1 + b2zm−2 + · · · + bm−1z + bm
(13.3.13)
= (a2 −b2f0 −b1f1)/b0
(13.3.14)
because a0 −b0f0 = a1 −b1f0 −f1b0 = 0. Continuing this process, we ﬁnally have that
fn = (an −bnf0 −bn−1f1 −· · · −b1fn−1) /b0,
(13.3.15)
where an = bn ≡0 for n > m.
• Example 13.3.3
Let us redo Example 13.3.2 using the recursive method. Comparing Equation 13.3.7 to
Equation 13.3.6, a0 = 2, a1 = −1.5, a2 = 0, b0 = 1, b1 = −1.5, b2 = 0.5, and an = bn = 0 if
n ≥3. From Equation 13.3.15,
f0 = a0/b0 = 2/1 = 2,
(13.3.16)
f1 = (a1 −b1f0)/b0 = [−1.5 −(−1.5)(2)]/1 = 1.5,
(13.3.17)
f2 = (a2 −b2f0 −b1f1)/b0
(13.3.18)
= [0 −(0.5)(2) −(−1.5)(1.5)]/1 = 1.25,
(13.3.19)
and
f3 = (a3 −b3f0 −b2f1 −b1f2)/b0
(13.3.20)
= [0 −(0)(2) −(0.5)(1.5) −(−1.5)(1.25)]/1 = 1.125.
(13.3.21)
⊓⊔
Partial fraction expansion
One of the popular methods for inverting Laplace transforms is partial fractions. A
similar, but slightly diﬀerent, scheme works here.

684
Advanced Engineering Mathematics with MATLAB
• Example 13.3.4
Given F(z) = z/
 z2 −1

, let us ﬁnd fn. The ﬁrst step is to obtain the partial fraction
expansion of F(z)/z.
Why we want F(z)/z rather than F(z) will be made clear in a
moment. Thus,
F(z)
z
=
1
(z −1)(z + 1) =
A
z −1 +
B
z + 1,
(13.3.22)
where
A = (z −1) F(z)
z

z=1
= 1
2,
(13.3.23)
and
B = (z + 1) F(z)
z

z=−1
= −1
2.
(13.3.24)
Multiplying Equation 13.3.22 by z,
F(z) = 1
2

z
z −1 −
z
z + 1

.
(13.3.25)
Next, we ﬁnd the inverse z-transform of z/(z −1) and z/(z + 1) in Table 13.1.1. This
yields
Z−1

z
z −1

= 1,
and
Z−1

z
z + 1

= (−1)n.
(13.3.26)
Thus, the inverse is
fn = 1
2 [1 −(−1)n] , n ≥0.
(13.3.27)
⊓⊔
From this example it is clear that there are two steps: (1) obtain the partial fraction
expansion of F(z)/z, and (2) ﬁnd the inverse z-transform by referring to Table 13.1.1.
• Example 13.3.5
Given F(z) = 2z2/[(z + 2)(z + 1)2], let us ﬁnd fn. We begin by expanding F(z)/z as
F(z)
z
=
2z
(z + 2)(z + 1)2 =
A
z + 2 +
B
z + 1 +
C
(z + 1)2 ,
(13.3.28)
where
A = (z + 2) F(z)
z

z=−2
= −4,
(13.3.29)
B = d
dz

(z + 1)2 F(z)
z

z=−1
= 4,
(13.3.30)
and
C = (z + 1)2 F(z)
z

z=−1
= −2,
(13.3.31)
so that
F(z) =
4z
z + 1 −
4z
z + 2 −
2z
(z + 1)2 ,
(13.3.32)

The Z-Transform
685
or
fn = Z−1
 4z
z + 1

−Z−1
 4z
z + 2

−Z−1

2z
(z + 1)2

.
(13.3.33)
From Table 13.1.1,
Z−1

z
z + 1

= (−1)n,
(13.3.34)
Z−1

z
z + 2

= (−2)n,
(13.3.35)
and
Z−1

z
(z + 1)2

= −Z−1

−z
(z + 1)2

= −n(−1)n = n(−1)n+1.
(13.3.36)
Applying Equation 13.3.34 through Equation 13.3.36 to Equation 13.3.33,
fn = 4(−1)n −4(−2)n + 2n(−1)n, n ≥0.
(13.3.37)
⊓⊔
• Example 13.3.6
Given F(z) = (z2 + z)/(z −2)2, let us determine fn. Because
F(z)
z
=
z + 1
(z −2)2 =
1
z −2 +
3
(z −2)2 ,
(13.3.38)
fn = Z−1

z
z −2

+ Z−1

3z
(z −2)2

.
(13.3.39)
Referring to Table 13.1.1,
Z−1

z
z −2

= 2n,
and
Z−1

3z
(z −2)2

= 3
2n2n.
(13.3.40)
Substituting Equation 13.3.40 into Equation 13.3.39 yields
fn =
  3
2n + 1

2n, n ≥0.
(13.3.41)
⊓⊔
Residue method
The power series, recursive, and partial fraction expansion methods are rather limited.
We now prove that fn may be computed from the following inverse integral formula:
fn =
1
2πi
I
C
zn−1F(z) dz,
n ≥0,
(13.3.42)
where C is any simple curve, taken in the positive sense, that encloses all of the singularities
of F(z). It is readily shown that the power series and partial fraction methods are special
cases of the residue method.

686
Advanced Engineering Mathematics with MATLAB
Proof : Starting with the deﬁnition of the z-transform
F(z) =
∞
X
n=0
fnz−n,
|z| > R1,
(13.3.43)
we multiply Equation 13.3.43 by zn−1 and integrating both sides around any contour C
that includes all of the singularities:
1
2πi
I
C
zn−1F(z) dz =
∞
X
m=0
fm
1
2πi
I
C
zn−m dz
z .
(13.3.44)
Let C be a circle of radius R, where R > R1. Then, changing variables to z = R eiθ, and
dz = iz dθ,
1
2πi
I
C
zn−m dz
z = Rn−m
2π
Z 2π
0
ei(n−m)θdθ =
 1,
m = n,
0,
otherwise.
(13.3.45)
Substituting Equation 13.3.45 into Equation 13.3.44 yields the desired result that
1
2πi
I
C
zn−1F(z) dz = fn.
(13.3.46)
⊓⊔
We can easily evaluate the inversion integral, Equation 13.3.42, using Cauchy’s residue
theorem.
• Example 13.3.7
Let us ﬁnd the inverse z-transform of
F(z) =
1
(z −1)(z −2).
(13.3.47)
From the inversion integral,
fn =
1
2πi
I
C
zn−1
(z −1)(z −2) dz.
(13.3.48)
Clearly the integral has simple poles at z = 1 and z = 2. However, when n = 0 we also have
a simple pole at z = 0. Thus the cases n = 0 and n > 0 must be considered separately.
Case 1: n = 0. The residue theorem yields
f0 = Res

1
z(z −1)(z −2); 0

+ Res

1
z(z −1)(z −2); 1

+ Res

1
z(z −1)(z −2); 2

.
(13.3.49)
Evaluating these residues,
Res

1
z(z −1)(z −2); 0

=
1
(z −1)(z −2)

z=0
= 1
2,
(13.3.50)

The Z-Transform
687
Res

1
z(z −1)(z −2); 1

=
1
z(z −2)

z=1
= −1,
(13.3.51)
and
Res

1
z(z −1)(z −2); 2

=
1
z(z −1)

z=2
= 1
2.
(13.3.52)
Substituting Equation 13.3.50 through Equation 13.3.52 into Equation 13.3.49 yields f0 = 0.
Case 2: n > 0. Here we only have contributions from z = 1 and z = 2.
fn = Res

zn−1
(z −1)(z −2); 1

+ Res

zn−1
(z −1)(z −2); 2

,
n > 0,
(13.3.53)
where
Res

zn−1
(z −1)(z −2); 1

= zn−1
z −2

z=1
= −1,
(13.3.54)
and
Res

zn−1
(z −1)(z −2); 2

= zn−1
z −1

z=2
= 2n−1, n > 0.
(13.3.55)
Thus,
fn = 2n−1 −1,
n > 0.
(13.3.56)
Combining our results,
fn =

0,
n = 0,
1
2 (2n −2) ,
n > 0.
(13.3.57)
⊓⊔
• Example 13.3.8
Let us use the inversion integral to ﬁnd the inverse of
F(z) = z2 + 2z
(z −1)2 .
(13.3.58)
The inversion theorem gives
fn =
1
2πi
I
C
zn+1 + 2zn
(z −1)2
dz = Res
zn+1 + 2zn
(z −1)2
; 1

,
(13.3.59)
where the pole at z = 1 is second order. Consequently, the corresponding residue is
Res
zn+1 + 2zn
(z −1)2
; 1

= d
dz

zn+1 + 2zn

z=1
= 3n + 1.
(13.3.60)
Thus, the inverse z-transform of Equation 13.3.58 is
fn = 3n + 1,
n ≥0.
(13.3.61)
⊓⊔

688
Advanced Engineering Mathematics with MATLAB
• Example 13.3.9
Let F(z) be a z-transform whose poles lie within the unit circle |z| = 1. Then
F(z) =
∞
X
n=0
fnz−n,
|z| > 1,
(13.3.62)
and
F(z)F(z−1) =
∞
X
n=0
f 2
n +
∞
X
n=0
∞
X
m=0
n̸=m
fmfnzm−n.
(13.3.63)
We now multiply both sides of Equation 13.3.63 by z−1 and integrate around the unit circle
C. Therefore,
I
|z|=1
F(z)F(z−1)z−1 dz =
∞
X
n=0
I
|z|=1
f 2
nz−1 dz +
∞
X
n=0
∞
X
m=0
n̸=m
fmfn
I
|z|=1
zm−n−1 dz,
(13.3.64)
after interchanging the order of integration and summation. Performing the integration,
∞
X
n=0
f 2
n =
1
2πi
I
|z|=1
F(z)F(z−1)z−1 dz,
(13.3.65)
which is Parseval’s theorem for one-sided z-transforms. Recall that there are similar theo-
rems for Fourier series and transforms.
⊓⊔
• Example 13.3.10: Evaluation of partial summations4
Consider the partial summation SN = PN
n=1 fn. We shall now show that z-transforms
can be employed to compute SN.
We begin by noting that
SN =
N
X
n=1
fn =
1
2πi
I
C
F(z)
N
X
n=1
zn−1 dz.
(13.3.66)
Here we employed the inversion integral to replace fn and reversed the order of integration
and summation. This interchange is permissible since we only have a partial summation.
Because the summation in Equation 13.3.66 is a geometric series, we have the ﬁnal result
that
SN =
1
2πi
I
C
F(z)(zN −1)
z −1
dz.
(13.3.67)
Therefore, we can use the residue theorem and z-transforms to evaluate partial summations.
4 See Bunch, K. J., W. N. Cain, and R. W. Grow, 1990: The z-transform method of evaluating partial
summations in closed form. J. Phys. A, 23, L1213–L1215.

The Z-Transform
689
Let us ﬁnd SN = PN
n=1 n3.
Because fn = n3, F(z) = z(z2 + 4z + 1)/(z −1)4.
Consequently
SN = Res
z(z2 + 4z + 1)(zN −1)
(z −1)5
; 1

= 1
4!
d4
dz4

z(z2 + 4z + 1)(zN −1)

z=1
(13.3.68)
= 1
4!
d4
dz4
 zN+3 + 4zN+2 + zN+1 −z3 −4z2 −z

z=1
= 1
4(N + 1)2N 2.
(13.3.69)
⊓⊔
• Example 13.3.11
An additional beneﬁt of understanding inversion by the residue method is the ability
to qualitatively anticipate the inverse by knowing the location of the poles of F(z). This
intuition is important because many engineering analyses discuss stability and performance
entirely in terms of the properties of the system’s z-transform. In Figure 13.3.1 we graphed
the location of the poles of F(z) and the corresponding fn. The student should go through
the mental exercise of connecting the two pictures.
Problems
Use the power series or recursive method to compute the ﬁrst few values of fn of the
following z-transforms. Then check your answers with MATLAB.
1. F(z) = 0.09z2 + 0.9z + 0.09
12.6z2 −24z + 11.4
2. F(z) =
z + 1
2z4 −2z3 + 2z −2
3. F(z) =
1.5z2 + 1.5z
15.25z2 −36.75z + 30.75
4. F(z) =
6z2 + 6z
19z3 −33z2 + 21z −7
Use partial fractions to ﬁnd the inverse of the following z-transforms. Then verify your
answers with MATLAB.
5. F(z) =
z(z + 1)
(z −1)(z2 −z + 1/4)
6. F(z) =
(1 −e−aT )z
(z −1)(z −e−aT )
7. F(z) =
z2
(z −1)(z −α)
8. F(z) = (2z −a −b)z
(z −a)(z −b)
9. Using the property that the z-transform of gn = fn−kHn−k if n ≥0 is G(z) = z−kF(z),
ﬁnd the inverse of
F(z) =
z + 1
z10(z −1/2).
Then check your answer with MATLAB.
Use the residue method to ﬁnd the inverse z-transform of the following z-transforms. Then
verify your answer with MATLAB.
10. F(z) =
z2 + 3z
(z −1/2)3
11. F(z) =
z
(z + 1)2(z −2)

690
Advanced Engineering Mathematics with MATLAB
n
|z|=1
n
n
|z|=1
n
f
f
n
|z|=1
n
n
|z|=1
n
f
f
n
|z|=1
n
n
|z|=1
n
f
f
Figure 13.3.1: The correspondence between the location of the simple poles of the z-transform F(z) and
the behavior of fn.

The Z-Transform
691
12. F(z) =
z
(z + 1)2(z −1)2
13. F(z) = ea/z
13.4 SOLUTION OF DIFFERENCE EQUATIONS
Having reached the point where we can take a z-transform and then ﬁnd its inverse,
we are ready to use it to solve diﬀerence equations. The procedure parallels that of solving
ordinary diﬀerential equations by Laplace transforms. Essentially we reduce the diﬀerence
equation to an algebraic problem. We then ﬁnd the solution by inverting Y (z).
• Example 13.4.1
Let us solve the second-order diﬀerence equation
2yn+2 −3yn+1 + yn = 5 3n, n ≥0,
(13.4.1)
where y0 = 0 and y1 = 1.
Taking the z-transform of both sides of Equation 13.4.1, we obtain
2Z(yn+2) −3Z(yn+1) + Z(yn) = 5 Z(3n).
(13.4.2)
From the shifting theorem and Table 13.1.1,
2z2Y (z) −2z2y0 −2zy1 −3[zY (z) −zy0] + Y (z) =
5z
z −3.
(13.4.3)
Substituting y0 = 0 and y1 = 1 into Equation 13.4.3 and simplifying yields
(2z −1)(z −1)Y (z) = z(2z −1)
z −3
,
(13.4.4)
or
Y (z) =
z
(z −3)(z −1).
(13.4.5)
To obtain yn from Y (z) we can employ partial fractions or the residue method. Applying
partial fractions gives
Y (z)
z
=
A
z −1 +
B
z −3,
(13.4.6)
where
A = (z −1) Y (z)
z

z=1
= −1
2,
(13.4.7)
and
B = (z −3) Y (z)
z

z=3
= 1
2.
(13.4.8)
Thus,
Y (z) = −1
2
z
z −1 + 1
2
z
z −3,
(13.4.9)
or
yn = −1
2Z−1

z
z −1

+ 1
2Z−1

z
z −3

.
(13.4.10)

692
Advanced Engineering Mathematics with MATLAB
From Equation 13.4.10 and Table 13.1.1,
yn = 1
2 (3n −1) ,
n ≥0.
(13.4.11)
An alternative to this hand calculation is to use MATLAB’s ztrans and iztrans to
solve diﬀerence equations. In the present case, the MATLAB script would read
clear
% define symbolic variables
syms z Y; syms n positive
% take z-transform of left side of difference equation
LHS = ztrans(2*sym(’y(n+2)’)-3*sym(’y(n+1)’)+sym(’y(n)’),n,z);
% take z-transform of right side of difference equation
RHS = 5 * ztrans(3^n,n,z);
% set Y for z-transform of y and introduce initial conditions
newLHS = subs(LHS,’ztrans(y(n),n,z)’,’y(0)’,’y(1)’,Y,0,1);
% solve for Y
Y = solve(newLHS-RHS,Y);
% invert z-transform and find y(n)
y = iztrans(Y,z,n)
This script produced
y =
-1/2+1/2*3^n
Two checks conﬁrm that we have the correct solution. First, our solution must satisfy
the initial values of the sequence. Computing y0 and y1,
y0 = 1
2(30 −1) = 1
2(1 −1) = 0,
(13.4.12)
and
y1 = 1
2(31 −1) = 1
2(3 −1) = 1.
(13.4.13)
Thus, our solution gives the correct initial values.
Our sequence yn must also satisfy the diﬀerence equation. Now
yn+2 = 1
2(3n+2 −1) = 1
2(9 3n −1),
(13.4.14)
and
yn+1 = 1
2(3n+1 −1) = 1
2(3 3n −1).
(13.4.15)
Therefore,
2yn+2 −3yn+1 + yn =
 9 −9
2 + 1
2

3n −1 + 3
2 −1
2 = 5 3n
(13.4.16)
and our solution is correct.
Finally, we note that the term 3n/2 is necessary to give the right side of Equation 13.4.1;
it is the particular solution. The −1/2 term is necessary so that the sequence satisﬁes the
initial values; it is the complementary solution.
⊓⊔

The Z-Transform
693
• Example 13.4.2
Let us ﬁnd the yn in the diﬀerence equation
yn+2 −2yn+1 + yn = 1,
n ≥0
(13.4.17)
with the initial conditions y0 = 0 and y1 = 3/2.
From Equation 13.4.17,
Z(yn+2) −2Z(yn+1) + Z(yn) = Z(1).
(13.4.18)
The z-transform of the left side of Equation 13.4.18 is obtained from the shifting theorem,
and Table 13.1.1 yields Z(1). Thus,
z2Y (z) −z2y0 −zy1 −2zY (z) + 2zy0 + Y (z) =
z
z −1.
(13.4.19)
Substituting y0 = 0 and y1 = 3/2 in Equation 13.4.19 and simplifying gives
Y (z) = 3z2 −z
2(z −1)3
(13.4.20)
or
yn = Z−1
 3z2 −z
2(z −1)3

.
(13.4.21)
We ﬁnd the inverse z-transform of Equation 13.4.21 by the residue method, or
yn =
1
2πi
I
C
3zn+1 −zn
2(z −1)3 dz = 1
2!
d2
dz2
3zn+1
2
−zn
2

z=1
(13.4.22)
= 1
2n2 + n.
(13.4.23)
Thus,
yn = 1
2n2 + n,
n ≥0.
(13.4.24)
Note that n2/2 gives the particular solution to Equation 13.4.17, while n is there so that
yn satisﬁes the initial conditions.
This problem is particularly interesting because our
constant forcing produces a response that grows as n2, just as in the case of resonance in
a time-continuous system when a ﬁnite forcing such as sin(ω0t) results in a response whose
amplitude grows as tm.
⊓⊔
• Example 13.4.3
Let us solve the diﬀerence equation
b2yn + yn+2 = 0,
(13.4.25)
where the initial conditions are y0 = b2 and y1 = 0.
We begin by taking the z-transform of each term in Equation 13.4.25. This yields
b2Z(yn) + Z(yn+2) = 0.
(13.4.26)

694
Advanced Engineering Mathematics with MATLAB
From the shifting theorem, it follows that
b2Y (z) + z2Y (z) −z2y0 −zy1 = 0.
(13.4.27)
Substituting y0 = b2 and y1 = 0 into Equation 13.4.27,
b2Y (z) + z2Y (z) −b2z2 = 0,
(13.4.28)
or
Y (z) =
b2z2
z2 + b2 .
(13.4.29)
To ﬁnd yn we employ the residue method or
yn =
1
2πi
I
C
b2zn+1
(z −ib)(z + ib) dz.
(13.4.30)
Thus,
yn = b2zn+1
z + ib

z=ib
+ b2zn+1
z −ib

z=−ib
= bn+2in
2
+ bn+2(−i)n
2
(13.4.31)
= bn+2einπ/2
2
+ bn+2e−inπ/2
2
= bn+2 cos
nπ
2

,
(13.4.32)
because cos(x) = 1
2
 eix + e−ix
. Consequently, we obtain the desired result that
yn = bn+2 cos
nπ
2

for n ≥0.
(13.4.33)
⊓⊔
• Example 13.4.4: Compound interest
Diﬀerence equations arise in ﬁnance because the increase or decrease in an account
occurs in discrete steps. For example, the amount of money in a compound interest savings
account after n + 1 conversion periods (the time period between interest payments) is
yn+1 = yn + ryn,
(13.4.34)
where r is the interest rate per conversion period. The second term on the right side of
Equation 13.4.34 is the amount of interest paid at the end of each period.
Let us ask a somewhat more diﬃcult question of how much money we will have if we
withdraw the amount A at the end of every period starting after the period ℓ. Now the
diﬀerence equation reads
yn+1 = yn + ryn −AHn−ℓ−1.
(13.4.35)
Taking the z-transform of Equation 13.4.35,
zY (z) −zy0 = (1 + r)Y (z) −Az2−ℓ
z −1
(13.4.36)

The Z-Transform
695
0
5
10
15
20
25
30
0
1
2
3
4
5
6
7
8
9
10
number of conversion periods
amount left in account (K$)
Figure 13.4.1: The amount in a savings account as a function of an annual conversion period when interest
is compounded at the annual rate of 12% and $1000 is taken from the account every period starting with
period 10.
after using Equation 13.2.9 or
Y (z) =
y0z
z −(1 + r) −
Az2−ℓ
(z −1)[z −(1 + r)].
(13.4.37)
Taking the inverse of Equation 13.4.37,
yn = y0(1 + r)n −A
r

(1 + r)n−ℓ+1 −1

Hn−ℓ.
(13.4.38)
The ﬁrst term in Equation 13.4.38 represents the growth of money by compound interest
while the second term gives the depletion of the account by withdrawals.
Figure 13.4.1 gives the values of yn for various starting amounts assuming an annual
conversion period with r = 0.12, ℓ= 10 years, and A = $1000. These computations were
done two ways using MATLAB as follows:
% load in parameters
clear; r = 0.12; A = 1; k = 0:30;
y = zeros(length(k),3); yanswer = zeros(length(k),3);
% set initial condition
for m=1:3
y(1,m) = m;
% compute other y values
for n = 1:30
y(n+1,m) = y(n,m)+r*y(n,m);
y(n+1,m) = y(n+1,m)-A*stepfun(n,11);
end
% now use Equation 13.4.38
for n = 1:31
yanswer(n,m) = y(1,m)*(1+r)^(n-1);
yanswer(n,m) = yanswer(n,m)-A*((1+r)^(n-10)-1)
*stepfun(n,11)/r;
end; end;
plot(k,y,’o’); hold; plot(k,yanswer,’s’);

696
Advanced Engineering Mathematics with MATLAB
axis([0 30 0 10])
xlabel(’number of conversion periods’,’Fontsize’,20)
ylabel(’amount left in account (K$)’,’Fontsize’,20)
Figure 13.4.1 shows that if an investor places an initial amount of $3000 in an account
bearing 12% annually, after 10 years he can withdraw $1000 annually, essentially forever.
This is because the amount that he removes every year is replaced by the interest on the
funds that remain in the account.
⊓⊔
• Example 13.4.5
Let us solve the following system of diﬀerence equations:
xn+1 = 4xn + 2yn,
(13.4.39)
and
yn+1 = 3xn + 3yn,
(13.4.40)
with the initial values of x0 = 0 and y0 = 5.
Taking the z-transform of Equation 13.4.39 and Equation 13.4.40,
zX(z) −x0z = 4X(z) + 2Y (z),
(13.4.41)
zY (z) −y0z = 3X(z) + 3Y (z),
(13.4.42)
or
(z −4)X(z) −2Y (z) = 0,
(13.4.43)
3X(z) −(z −3)Y (z) = −5z.
(13.4.44)
Solving for X(z) and Y (z),
X(z) =
10z
(z −6)(z −1) =
2z
z −6 −
2z
z −1,
(13.4.45)
and
Y (z) =
5z(z −4)
(z −6)(z −1) =
2z
z −6 +
3z
z −1.
(13.4.46)
Taking the inverse of Equation 13.4.45 and Equation 13.4.46 term by term,
xn = −2 + 2 6n,
and
yn = 3 + 2 6n.
(13.4.47)
We can also check our work using the MATLAB script
clear
% define symbolic variables
syms X Y z; syms n positive
% take z-transform of left side of differential equations
LHS1 = ztrans(sym(’x(n+1)’)-4*sym(’x(n)’)-2*sym(’y(n)’),n,z);
LHS2 = ztrans(sym(’y(n+1)’)-3*sym(’x(n)’)-3*sym(’y(n)’),n,z);
% set X and Y for the z-transform of x and y
%
and introduce initial conditions

The Z-Transform
697
newLHS1 = subs(LHS1,’ztrans(x(n),n,z)’,’ztrans(y(n),n,z)’,...
’x(0)’,’y(0)’,X,Y,0,5);
newLHS2 = subs(LHS2,’ztrans(x(n),n,z)’,’ztrans(y(n),n,z)’,...
’x(0)’,’y(0)’,X,Y,0,5);
% solve for X and Y
[X,Y] = solve(newLHS1,newLHS2,X,Y);
% invert z-transform and find x(n) and y(n)
x = iztrans(X,z,n)
y = iztrans(Y,z,n)
This script yields
x =
2*6^n-2
y =
2*6^n+3
Problems
Solve the following diﬀerence equations using z-transforms, where n ≥0. Check your answer
using MATLAB.
1. yn+1 −yn = n2,
y0 = 1.
2. yn+2 −2yn+1 + yn = 0,
y0 = y1 = 1.
3. yn+2 −2yn+1 + yn = 1,
y0 = y1 = 0.
4. yn+1 + 3yn = n,
y0 = 0.
5. yn+1 −5yn = cos(nπ),
y0 = 0.
6. yn+2 −4yn = 1,
y0 = 1, y1 = 0.
7. yn+2 −1
4yn = ( 1
2)n, y0 = y1 = 0.
8. yn+2 −5yn+1 + 6yn = 0, y0 = y1 = 1.
9. yn+2 −3yn+1 + 2yn = 1,
y0 = y1 = 0.
10. yn+2 −2yn+1 + yn = 2,
y0 = 0, y1 = 2.
11. xn+1 = 3xn −4yn, yn+1 = 2xn −3yn,
x0 = 3, y0 = 2.
12. xn+1 = 2xn −10yn, yn+1 = −xn −yn,
x0 = 3, y0 = −2.
13. xn+1 = xn −2yn, yn+1 = −6yn,
x0 = −1, y0 = −7.
14. xn+1 = 4xn −5yn, yn+1 = xn −2yn,
x0 = 6, y0 = 2.
13.5 STABILITY OF DISCRETE-TIME SYSTEMS
When we discussed the solution of ordinary diﬀerential equations by Laplace trans-
forms, we introduced the concept of transfer function and impulse response. In the case of
discrete-time systems, similar considerations come into play.
Consider the recursive system
yn = a1yn−1Hn−1 + a2yn−2Hn−2 + xn,
n ≥0,
(13.5.1)
where Hn−k is the unit step function. It equals 0 for n < k and 1 for n ≥k. Equation
13.5.1 is called a recursive system because future values of the sequence depend upon all of
the previous values. At present, a1 and a2 are free parameters that we shall vary.

698
Advanced Engineering Mathematics with MATLAB
Using Equation 13.2.7,
z2Y (z) −a1zY (z) −a2Y (z) = z2X(z),
(13.5.2)
or
G(z) = Y (z)
X(z) =
z2
z2 −a1z −a2
.
(13.5.3)
As in the case of Laplace transforms, the ratio Y (z)/X(z) is the transfer function. The
inverse of the transfer function gives the impulse response for our discrete-time system.
This particular transfer function has two poles, namely
z1,2 = a1
2 ±
r
a2
1
4 + a2.
(13.5.4)
At this point, we consider three cases.
Case 1: a2
1/4 + a2 < 0. In this case z1 and z2 are complex conjugates. Let us write them
as z1,2 = re±iω0T . Then
G(z) =
z2
(z −reiω0T )(z −re−iω0T ) =
z2
z2 −2r cos(ω0T)z + r2 ,
(13.5.5)
where r2 = −a2, and ω0T = cos−1(a1/2r). From the inversion integral,
gn = Res

zn+1
z2 −2r cos(ω0T)z + r2 ; z1

+ Res

zn+1
z2 −2r cos(ω0T)z + r2 ; z2

,
(13.5.6)
where gn denotes the impulse response. Now
Res

zn+1
z2 −2r cos(ω0T)z + r2 ; z1

= lim
z→z1
(z −z1)zn+1
(z −z1)(z −z2)
(13.5.7)
= rn exp[i(n + 1)ω0T]
eiω0T −e−iω0T
(13.5.8)
= rn exp[i(n + 1)ω0T]
2i sin(ω0T)
.
(13.5.9)
Similarly,
Res

zn+1
z2 −2r cos(ω0T)z + r2 ; z2

= −rn exp[−i(n + 1)ω0T]
2i sin(ω0T)
,
(13.5.10)
and
gn = rn sin[(n + 1)ω0T]
sin(ω0T)
.
(13.5.11)
A graph of sin[(n + 1)ω0T]/ sin(ω0T) with respect to n gives a sinusoidal envelope.
More importantly, if |r| < 1 these oscillations vanish as n →∞and the system is stable.
On the other hand, if |r| > 1 the oscillations grow without bound as n →∞and the system
is unstable.
Recall that |r| > 1 corresponds to poles that lie outside the unit circle while |r| < 1 is
exactly the opposite. Our example suggests that for discrete-time systems to be stable, all

The Z-Transform
699
of the poles of the transfer function must lie within the unit circle while an unstable system
has at least one pole that lies outside of this circle.
Case 2: a2
1/4 + a2 > 0. This case leads to two real roots, z1 and z2. From the inversion
integral, the sum of the residues gives the impulse response
gn = zn+1
1
−zn+1
2
z1 −z2
.
(13.5.12)
Once again, if the poles lie within the unit circle, |z1| < 1 and |z2| < 1, the system is stable.
Case 3: a2
1/4 + a2 = 0. This case yields z1 = z2,
G(z) =
z2
(z −a1/2)2
(13.5.13)
and
gn =
1
2πi
I
C
zn+1
(z −a1/2)2 dz =
a1
2
n
(n + 1).
(13.5.14)
This system is obviously stable if |a1/2| < 1 and the pole of the transfer function lies within
the unit circle.
In summary, ﬁnding the transfer function of a discrete-time system is important in
determining its stability. Because the location of the poles of G(z) determines the response
of the system, a stable system has all of its poles within the unit circle. Conversely, if
any of the poles of G(z) lie outside of the unit circle, the system is unstable. Finally, if
limn→∞gn = c, the system is marginally stable. For example, if G(z) has simple poles,
some of the poles must lie on the unit circle.
• Example 13.5.1
Numerical methods of integration provide some of the simplest, yet most important,
diﬀerence equations in the literature. In this example,5 we show how z-transforms can be
used to highlight the strengths and weaknesses of such schemes.
Consider the trapezoidal integration rule in numerical analysis.
The integral yn is
updated by adding the latest trapezoidal approximation of the continuous curve. Thus, the
integral is computed by
yn = 1
2T(xn + xn−1Hn−1) + yn−1Hn−1,
(13.5.15)
where T is the interval between evaluations of the integrand.
We ﬁrst determine the stability of this rule because it is of little value if it is not stable.
Using Equation 13.2.7, the transfer function is
G(z) = Y (z)
X(z) = T
2
z + 1
z −1

.
(13.5.16)
To ﬁnd the impulse response, we use the inversion integral and ﬁnd that
gn = T
4πi
I
C
zn−1 z + 1
z −1 dz.
(13.5.17)
5 See Salzer, J. M., 1954: Frequency analysis of digital computers operating in real time. Proc. IRE,
42, 457–466.

700
Advanced Engineering Mathematics with MATLAB
0.0
1.0
2.0
3.0
ωΤ
0.1
1.0
10.0
Ratio of quadrature amplitudes to ideal integration      
Trapezoidal
Simpson’s
3/8−rule
Rule
Simpson’s
1/3−rule
Ideal Rule
Figure 13.5.1: Comparison of various quadrature formulas by ratios of their amplitudes to that of an ideal
integrator. (From Salzer, J. M., 1954: Frequency analysis of digital computers operating in real time. Proc.
IRE, 42, p. 463.)
At this point, we must consider two cases: n = 0 and n > 0. For n = 0,
g0 = T
2 Res
 z + 1
z(z −1); 0

+ T
2 Res
 z + 1
z(z −1); 1

= T
2 .
(13.5.18)
For n > 0,
g0 = T
2 Res
zn−1(z + 1)
z −1
; 1

= T.
(13.5.19)
Therefore, the impulse response for this numerical scheme is g0 = T
2 and gn = T for n > 0.
Note that this is a marginally stable system (the solution neither grows nor decays with n)
because the pole associated with the transfer function lies on the unit circle.
Having discovered that the system is not unstable, let us continue and explore some
of its properties. Recall now that z = esT = eiωT if s = iω. Then the transfer function
becomes
G(ω) = T
2
1 + e−iωT
1 −e−iωT = −iT
2 cot
ωT
2

.
(13.5.20)
On the other hand, the transfer function of an ideal integrator is 1/s or −i/ω. Thus, the
trapezoidal rule has ideal phase but its shortcoming lies in its amplitude characteristic; it
lies below the ideal integrator for 0 < ωT < π. We show this behavior, along with that for
Simpson’s one-third rule and Simpson’s three-eighths rule, in Figure 13.5.1.
Figure 13.5.1 conﬁrms the superiority of Simpson’s one-third rule over his three-eighths
rule. The ﬁgure also shows that certain schemes are better at suppressing noise at higher
frequencies, an eﬀect not generally emphasized in numerical calculus but often important in
system design. For example, the trapezoidal rule is inferior to all others at low frequencies
but only to Simpson’s one-third rule at higher frequencies. Furthermore, the trapezoidal
rule might actually be preferred, not only because of its simplicity but also because it
attenuates at higher frequencies, thereby counteracting the eﬀect of noise.
⊓⊔
• Example 13.5.2
Given the transfer function
G(z) =
z2
(z −1)(z −1/2),
(13.5.21)

The Z-Transform
701
0
5
10
15
20
0.5
1
1.5
2
2.5
n+1
impulse response
Figure 13.5.2: The impulse response for a discrete system with a transform function given by Equation
13.5.21.
is this discrete-time system stable or marginally stable?
This transfer function has two simple poles. The pole at z = 1/2 gives rise to a term
that varies as ( 1
2)n in the impulse response while the z = 1 pole gives a constant. Because
this constant neither grows nor decays with n, the system is marginally stable.
⊓⊔
• Example 13.5.3
In most cases the transfer function consists of a ratio of two polynomials.
In this
case we can use the MATLAB function filter to compute the impulse response as follows:
Consider the Kronecker delta sequence, x0 = 1, and xn = 0 for n > 0. From the deﬁnition
of the z-transform, X(z) = 1. Therefore, if our input into filter is the Kronecker delta
sequence, the output yn will be the impulse response since Y (z) = G(z). If the impulse
response grows without bound as n increases, the system is unstable. If it goes to zero as
n increases, the system is stable. If it remains constant, it is marginally stable.
To illustrate this concept, the following MATLAB script ﬁnds the impulse response
corresponding to the transfer function, Equation 13.5.21:
% enter the coefficients of the numerator
%
of the transfer function, Equation 13.5.21
num = [1 0 0];
% enter the coefficients of the denominator
%
of the transfer function, Equation 13.5.21
den = [1 -1.5 0.5];
% create the Kronecker delta sequence
x = [1 zeros(1,20)];
% find the impulse response
y = filter(num,den,x);
% plot impulse response
plot(y,’o’), axis([0 20 0.5 2.5])
xlabel(’n+1’,’Fontsize’,20)
ylabel(’impulse response’,’Fontsize’,20)
Figure 13.5.2 shows the computed impulse response. The asymptotic limit is two, so the
system is marginally stable as we found before.

702
Advanced Engineering Mathematics with MATLAB
We note in closing that the same procedure can be used to ﬁnd the inverse of any
z-transform that consists of a ratio of two polynomials. Here we simply set G(z) equal to
the given z-transform and perform the same analysis.
Problems
For the following time-discrete systems, ﬁnd the transfer function and determine whether
the systems are unstable, marginally stable, or stable. Check your answer by graphing the
impulse response using MATLAB.
1. yn = yn−1Hn−1 + xn
2. yn = 2yn−1Hn−1 −yn−2Hn−2 + xn
3. yn = 3yn−1Hn−1 + xn
4. yn = 1
4yn−2Hn−2 + xn
Further Readings
Jury, E. I., 1964: Theory and Application of the z-Transform Method. John Wiley & Sons,
330 pp. The classic text on z-transforms.
LePage, W. R., 1980: Complex Variables and the Laplace Transform for Engineers. Dover,
483 pp. Chapter 16 is on z-transforms.

Chapter 14
The Hilbert Transform
In addition to the Fourier, Laplace, and z-transforms, there are many other linear
transforms that have their own special niche in engineering.
Examples include Hankel,
Walsh, Radon, and Hartley transforms. In this chapter we consider the Hilbert transform,
which is a commonly used technique for relating the real and imaginary parts of a spectral
response, particularly in communication theory.
We begin our study of Hilbert transforms by ﬁrst deﬁning them and then exploring
their properties. Next, we develop the concept of the analytic signal. Finally, we explore
a property of Hilbert transforms that is frequently applied to data analysis: the Kramers-
Kronig relationship.
14.1 DEFINITION
In Chapter 13 we motivated the development of z-transforms by exploring the concept
of the ideal sampler. In the case of Hilbert transforms, we introduce another fundamental
operation, namely quadrature phase shifting or the ideal Hilbert transformer. This proce-
dure does nothing more than shift the phase of all input frequency components by −π/2.
Hilbert transformers are frequently used in communication systems and signal processing;
examples include the generation of single-sideband modulated signals and radar and speech
signal processing.
Because a −π/2 phase shift is equivalent to multiplying the Fourier transform of a
signal by e−iπ/2 = −i, and because phase shifting must be an odd function of frequency,1
1 For a real function the phase of its Fourier transform must be an odd function of ω.
703

704
Advanced Engineering Mathematics with MATLAB
the transfer function of the phase shifter is G(ω) = −i sgn(ω), where sgn(·) is deﬁned by
Equation 11.2.11. In other words, if X(ω) denotes the input spectrum to the phase shifter,
the output spectrum must be −i sgn(ω)X(ω). If the process is repeated, the total phase
shift is −π, a complete phase reversal of all frequency components. The output spectrum
then equals [−i sgn(ω)]2X(ω) = −X(ω).
This agrees with the notion of phase reversal
because the output function is −x(t).
Consider now the impulse response of the quadrature phase shifter, g(t) = F−1[G(ω)].
From the deﬁnition of Fourier transforms,
dG
dω = −i
Z ∞
−∞
tg(t)e−iωt dt,
(14.1.1)
and
g(t) = i
tF−1
dG
dω

.
(14.1.2)
Since G′(ω) = −2iδ(ω), the corresponding impulse response is
g(t) = i
tF−1[−2iδ(ω)] = 1
πt.
(14.1.3)
Consequently, if x(t) is the input to a quadrature phase shifter, the superposition integral
gives the output time function as
bx(t) = x(t) ∗1
πt = 1
π
Z ∞
−∞
x(τ)
t −τ dτ.
(14.1.4)
We shall deﬁne bx(t) as the Hilbert transform of x(t), although some authors use the negative
of Equation 14.1.4 corresponding to a +π/2 phase shift. The transform bx(t) is also called
the harmonic conjugate of x(t).
In similar fashion, bbx(t) is the Hilbert transform of the Hilbert transform of x(t) and
corresponds to the output of two cascaded phase shifters. However, this output is known
to be −x(t), so bbx(t) = −x(t), and we arrive at the inverse Hilbert transform relationship
that
x(t) = −bx(t) ∗1
πt = −1
π
Z ∞
−∞
bx(τ)
t −τ dτ.
(14.1.5)
Taken together, x(t) and bx(t) are called a Hilbert pair.
Hilbert pairs enjoy the unique
property that x(t) + ibx(t) is an analytic function.2
2 For the proof, see Titchmarsh, E. C., 1948: Introduction to the Theory of Fourier Integrals. Oxford
University Press, p. 125.

The Hilbert Transform
705
Descended from a Prussian middle-class family, David Hilbert (1862–1943) would make signiﬁcant
contributions in the ﬁelds of algebraic form, algebraic number theory, foundations of geometry,
analysis, mathematical physics, and the foundations of mathematics.
Hilbert transforms arose
during his study of integral equations (Hilbert, D., 1912: Grundz¨uge einer allgemeinen Theorie der
linearen Integralgleichungen. Teubner, p. 75). (Portrait courtesy of Photo AKG, London, with
permission.)
Because of the singularity at τ = t, the integrals in Equation 14.1.4 and Equation
14.1.5 must be taken in the Cauchy principal value sense by approaching the singularity
point from both sides, namely
Z ∞
−∞
f(τ) dτ = lim
ǫ→0
Z t−ǫ
−∞
f(τ) dτ +
Z ∞
t+ǫ
f(τ) dτ

,
(14.1.6)
so that the inﬁnities to the right and left of τ = t cancel each other. See Section 10.10.
We also note that the Hilbert transform is basically a convolution and does not produce a
change of domain; if x is a function of time, then bx is also a function of time. This is quite
diﬀerent from what we encountered with Laplace or Fourier transforms.
From its origin in phase shifting, Hilbert transforms of sinusoidal functions are trivial.
Some examples are
d
cos(ωt + ϕ) = cos
 ωt + ϕ −π
2

= sgn(ω) sin(ωt + ϕ).
(14.1.7)
Similarly,
d
sin(ωt + ϕ) = −sgn(ω) cos(ωt + ϕ),
(14.1.8)

706
Advanced Engineering Mathematics with MATLAB
and
d
eiωt+iϕ = −i sgn(ω)eiωt+iϕ.
(14.1.9)
Thus, Hilbert transformation does not change the amplitude of sine or cosine but does
change their phase by ±π/2.
• Example 14.1.1
Let us apply the integral deﬁnition of the Hilbert transform, Equation 14.1.4, to ﬁnd
the Hilbert transform of sin(ωt), ω ̸= 0.
From the deﬁnition,
H [sin(ωt)] = 1
π
Z ∞
−∞
sin(ωτ)
t −τ
dτ.
(14.1.10)
If x = t −τ, then
H [sin(ωt)] = −cos(ωt)
π
Z ∞
−∞
sin(ωx)
x
dx = −cos(ωt) sgn(ω).
(14.1.11)
⊓⊔
• Example 14.1.2
Let us compute the Hilbert transform of x(t) = sin(t)/(t2 + 1) from the deﬁnition of
the Hilbert transform, Equation 14.1.4.
From the deﬁnition,
bx(t) = 1
π PV
Z ∞
−∞
sin(τ)
(t −τ)(τ 2 + 1) dτ = 1
π ℑ

PV
Z ∞
−∞
eiτ
(t −τ)(τ 2 + 1) dτ

.
(14.1.12)
Because of the singularity on the real axis at τ = t, we treat the integrals in Equation
14.1.12 in the sense of Cauchy principal value.
To evaluate Equation 14.1.12, we convert it into a closed contour integration by in-
troducing a semicircle CR of inﬁnite radius in the upper half-plane. This yields a closed
contour C, which consists of the real line plus this semicircle. Therefore, Equation 14.1.12
can be rewritten
PV
Z ∞
−∞
eiτ
(t −τ)(τ 2 + 1) dτ = PV
I
C
eiz
(t −z)(z2 + 1) dz −
Z
CR
eiz
(t −z)(z2 + 1) dz.
(14.1.13)
The second integral on the right side of Equation 14.1.13 vanishes by Equation 10.9.7.
The evaluation of the closed integral in Equation 14.1.13 follows from the residue
theorem. We have that
Res

eiz
(t −z)(z2 + 1); t

= lim
z→t
(z −t) eiz
(t −z)(z2 + 1) = −
eit
t2 + 1,
(14.1.14)
and
Res

eiz
(t −z)(z2 + 1); i

= lim
z→i
(z −i) eiz
(t −z)(z2 + 1) =
e−1
2i(t −i).
(14.1.15)
We do not have a contribution from z = −i because it lies outside of the closed contour.

The Hilbert Transform
707
The Hilbert Transform of Some Common Functions
function, x(t)
Hilbert transform, bx(t)
1.

1,
a < t < b
0,
otherwise
1
π ln

t −a
t −b

2.
sin(ωt + ϕ)
−sgn(ω) cos(ωt + ϕ)
3.
cos(ωt + ϕ)
sgn(ω) sin(ωt + ϕ)
4.
eiωt+ϕi
−i sgn(ω)eiωt+ϕi
5.
1
t
−πδ(t)
6.
1
t2 + a2 ,
0 < ℜ(a)
t
a(t2 + a2)
7.
λt + µa
t2 + a2 ,
0 < ℜ(a)
µt −λa
t2 + a2
8.
1
1 + t4
t(1 + t2)
√
2 (1 + t4)
9.
sin(at)
t
,
0 < a
1 −cos(at)
t
10.
sin(t)
1 + t2
e−1 −cos(t)
1 + t2
11.
sin(at)J1(at),
0 < a
−cos(at)J1(at)
12.
sin(at)Jn(bt),
0 < b < a
−cos(at)Jn(bt)
13.
cos(at)J1(at),
0 < a
sin(at)J1(at)
14.
cos(at)Jn(bt),
0 < b < a
sin(at)Jn(at)
15.
 √
a2 −t2,
−a < t < a
0,
otherwise



t +
√
t2 −a2,
−∞< t < −a
t,
−a < t < a
t −
√
t2 −a2,
a < t < ∞
16.
sin
 a
√
t

H(t),
0 < a
(
−e−a√
|t|,
−∞< t < 0
−cos
 a
√
t

,
0 < t < ∞

708
Advanced Engineering Mathematics with MATLAB
Therefore,
PV
Z ∞
−∞
eiτ
(t −τ)(τ 2 + 1) dτ = −πi eit
t2 + 1 + π e−1(t + i)
t2 + 1
.
(14.1.16)
Only one half of the value of the residue at z = t was included; this reﬂects the semicircular
indentation around the singularity there.
Substituting Equation 14.1.16 into Equation
14.1.12, we obtain the ﬁnal result that
H
 sin(t)
t2 + 1

= e−1 −cos(t)
t2 + 1
.
(14.1.17)
⊓⊔
• Example 14.1.3
Let us employ the relationship that the Fourier transform of bx(t) equals −i sgn(ω) times
the Fourier transform of x(t) to ﬁnd the Hilbert transform of x(t) = e−t2.
Because F(e−t2) = √πe−ω2/4,
b
X(ω) = −i√π sgn(ω)e−ω2/4.
(14.1.18)
Therefore,
bx(t) =
i
2√π
Z 0
−∞
eitω−ω2/4 dω −
i
2√π
Z ∞
0
eitω−ω2/4 dω
(14.1.19)
=
i
√π
Z 0
−∞
e2itη−η2 dη −
i
√π
Z ∞
0
e2itη−η2 dη
(14.1.20)
= e−t2
√π
Z t
−i∞
e−s2 ds −e−t2
√π
Z i∞
t
e−s2 ds = 2e−t2
√π
Z t
0
e−s2 ds,
(14.1.21)
where s = t + ηi. The integral in Equation 14.1.21 is the well-known Dawson’s integral.3
See Gautschi and Waldvogel4 for an alternative derivation.
⊓⊔
• Example 14.1.4: Numerical computation of the Hilbert transform
Recently Andr´e Weideman5 devised a particularly eﬃcient method for numerically
computing the Hilbert transform when x(t) is known exactly for any real t and enjoys the
property that
Z ∞
−∞
|x(t)|2 dt < ∞.
(14.1.22)
3 Press, W. H., S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery, 1992: Numerical Recipes in
Fortran: The Art of Scientiﬁc Computing. Cambridge University Press, Section 6.10.
4 Gautschi, W., and J. Waldvogel, 2000: Computing the Hilbert transform of the generalized Laguerre
and Hermite weight functions. BIT, 41, 490–503.
5 Weideman, J. A. C., 1995: Computing the Hilbert transform on the real line. Math. Comput., 64,
745–762.

The Hilbert Transform
709
Given Equation 14.1.22, the function x(t) can be represented by the rational expansion
x(t) =
∞
X
n=−∞
anρn(t),
(14.1.23)
where ρn(t) is the set of rational functions
ρn(t) =
(1 + it)n
(1 −it)n+1 ,
n = 0, ±1, ±2, · · · ,
(14.1.24)
and
an = 1
π
Z ∞
−∞
x(t)ρ∗
n(t) dt
(14.1.25)
or
an = 1
2π
Z π
−π

1 −i tan
  1
2θ

x

tan
  1
2θ

e−inθ dθ,
(14.1.26)
if we introduce the substitution t = tan(θ/2).
Why is Equation 14.1.23 useful? Taking the Hilbert transform of both sides of this
equation,
bx(t) =
∞
X
n=−∞
anbρn(t).
(14.1.27)
Using contour integration, we ﬁnd that
bρn(t) = 1
π PV
Z ∞
−∞
(1 + iτ)n
(1 −iτ)n+1(t −τ) dτ = −i sgn(n)ρn(t),
(14.1.28)
where sgn(t) is the signum function with sgn(0) = 1. Therefore,
bx(t) = −i
∞
X
n=−∞
sgn(n) an ρn(t).
(14.1.29)
We must now approximate Equation 14.1.29 so that we can evaluate it numerically.
We do this by introducing the following truncated version:
bxN(t) = −i
N−1
X
n=−N
sgn(n) An ρn(t).
(14.1.30)
This particular truncation was chosen because ρn(t) and ρ−n−1(t) are a conjugate pair. The
coeﬃcient an has become An, which equals
An = 1
N
N−1
X
j=−N+1

1 −i tan
  1
2θj

x

tan
  1
2θj

e−inθj,
(14.1.31)
where θj = πj/N. The terms corresponding to j = ±N have been set to zero because it
is assumed that x(t) vanishes rapidly with t →±∞. Finally, we substitute θ for t and
transform Equation 14.1.30 into
bxN(tj) = −
i
1 −i tan(θj)
N−1
X
n=−N
sgn(n)Aneinθj.
(14.1.32)

710
Advanced Engineering Mathematics with MATLAB
−15
−10
−5
0
5
10
15
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
t
exact Hilbert transform
computed Hilbert transform
Figure 14.1.1: The Hilbert transform for x(t) = 1/(1 + t4) computed from Weideman’s algorithm.
The advantage of Equation 14.1.31 and Equation 14.1.32 is that they can be evalu-
ated using fast Fourier transforms. For example, the following MATLAB script devised by
Weideman illustrates his methods for x(t) = 1/(1 + t4):
% initialize parameters used in computation
b = 1; N = 8; n = [-N:N-1]’;
% set up collocation points and evaluate function there
t = b * tan(pi*(n+1/2)/(2*N)); F = 1./(1+t.^4);
% evaluate Equation 14.1.31
an = fftshift(fft(F.*(b-i*t)));
% compute Hilbert transform via Equation 14.1.32
hilbert = ifft(fftshift(i*(sign(n+1/2).*an)))./(b-i*t);
hilbert = -real(hilbert);
% find points at which we will compute exact answer
tt = [-12:0.02:12];
% compute exact answer
answer = tt.*(1+tt.^2)./(1+tt.^4)./sqrt(2);
fzero = zeros(size(tt));
% plot both computed Hilbert transform and exact answer
plot(tt,answer,’-’,t,hilbert,’o’,tt,fzero,’--’)
xlabel(’t’,’Fontsize’,20)
legend(’exact Hilbert transform’,’computed Hilbert transform’)
legend boxoff
Figure 14.1.1 illustrates Weideman’s algorithm for numerically computing the Hilbert
transform of 1/(1 + t4).
There are two important points concerning Weideman’s implementation of his algo-
rithm. First, the collocation points originally given by tj = tan[πj/(2N)], j = −N, . . . , N−1
have changed to tj = tan[(j + 1
2)π/(2N)], j = −N, . . . , N −1. This change replaces the
trapezoidal rule discretization for the Fourier coeﬃcients with a midpoint rule. The advan-
tages are twofold: First, it avoids the nuisance of dealing with a collocation point at inﬁnity.
Second, it actually yields more accurate results in many cases.

The Hilbert Transform
711
The discerning student will also notice that Weideman introduced a free parameter b,
which we set to one. This rescaling parameter can have a major inﬂuence on the accuracy.
The interested student is referred to the bottom of page 756 in Weideman’s paper for further
details.
⊓⊔
• Example 14.1.5: Discrete Hilbert transform
Quite often the function is given as discrete data points. How do we ﬁnd the Hilbert
transform in this case? We will now prove6 that the equivalent discrete Hilbert transform
is
H(fn) = bfk =









2
π
X
n odd
fn
k −n,
k even,
2
π
X
n even
fn
k −n,
k odd,
(14.1.33)
where fn denotes a set of discrete data values that are sampled at t = nT and both k and
n run from −∞to ∞. The corresponding inverse is
fn =











2
π
X
k odd
bfk
k −n,
n even,
2
π
X
k even
bfk
k −n,
n odd.
(14.1.34)
We begin our proof by inserting Equation 14.1.33 into Equation 14.1.34. For n even,
fn = 2
π
X
k odd
1
k −n
 
2
π
X
p even
fp
k −p
!
= 4
π2
X
p even
X
k odd
fp
(k −p)(k −n)
(14.1.35)
= 4
π2
X
k odd
fn
(k −n)2 + 4
π2
X
p even,p̸=n
X
k odd
(n −p)fp

1
k −n −
1
k −p

.
(14.1.36)
The term within the curly brackets equals zero as k runs through all of its values. Therefore,
Equation 14.1.36 reduces to
fn = 8
π2 fn

1 + 1
32 + 1
52 + + 1
72 + · · ·

.
(14.1.37)
However, the term in the brackets of Equation 14.1.37 equals π2/8. Therefore, Equation
14.1.33 and Equation 14.1.34 is proved for n even. An identical proof follows for n odd.
A popular alternative7 to Equation 14.1.33 involves the (fast) Fourier transform and
the relationship that b
X(ω) = −i sgn(ω)X(ω), where X(ω) and b
X(ω) denote the Fourier
transform of x(t) and bx(t), respectively. In this technique, a fast Fourier transform is taken
of the data.
This transformed dataset is then multiplied by −i sgn(ω) and then back
transformed to give the Hilbert transform.
6 See Kak, S. C., 1970: The discrete Hilbert transform. Proc. IEEE, 58, 585–586. For an alternative
derivation, see Kress, R., and E. Martensen, 1970: Anwendung der Rechteckregel auf die reelle Hilbert-
transformation mit unendlichem Intervall. Z. Angew. Math. Mech., 50, T61–T64.
7 ˇC´ıˇzek, V., 1970: Discrete Hilbert transform. IEEE Trans. Audio Electroacoust., AU-18, 340–343.

712
Advanced Engineering Mathematics with MATLAB
Let x(t) be a real, even function. Then X(ω), the Fourier transform of x(t), is also an
even function. Consequently,
bx(t) = 1
2π
Z ∞
−∞
b
X(ω)eiωt dω = 1
2π
Z ∞
−∞
−i sgn(ω)X(ω) [cos(ωt) + i sin(ωt)] dω (14.1.38)
= −i
2π
Z ∞
−∞
sgn(ω)X(ω) cos(ωt) dω + 1
2π
Z ∞
−∞
sgn(ω)X(ω) sin(ωt) dω
(14.1.39)
= 1
π
Z ∞
0
X(ω) sin(ωt) dω.
(14.1.40)
Note that the Hilbert transform in this case is an odd function. Similarly, if x(t) is a real,
odd function,
bx(t) = −i
π
Z ∞
0
X(ω) cos(ωt) dω,
(14.1.41)
and the Hilbert transform is an even function.
Problems
1. Show that the Hilbert transform of a constant function is zero.
2. Use Equation 14.1.4 to compute the Hilbert transform of cos(ωt), ω ̸= 0.
3. Use Equation 14.1.4 to show that the Hilbert transform of the Dirac delta function δ(t)
is 1/(πt).
4. Use Equation 14.1.4 to show that the Hilbert transform of 1/(t2 + 1) is t/(t2 + 1).
5. The output y(t) from an ideal lowpass ﬁlter can be expressed by the convolution integral
y(t) = x(t) ∗sin(2πωt)
πt
,
where x(t) is the input signal. Show that this expression can also be expressed in terms of
Hilbert transforms as
y(t) = H[x(t) cos(2πωt)] sin(2πωt) −H[x(t) sin(2πωt)] cos(2πωt).
Following Example 14.1.3, ﬁnd the Hilbert transforms of
6. x(t) =
1
1 + t2
7. x(t) =
 1,
−a < t < a
0,
otherwise
8. Using the commutative and associate properties of convolution, f(t) ∗g(t) = g(t) ∗f(t)
and [f(t) ∗g(t)] ∗v(t) = f(t) ∗[g(t) ∗v(t)], respectively, and the deﬁnition of the Hilbert
transform, Equation 14.1.4, show8 that
H[f(t) ∗g(t)] = bf(t) ∗g(t) = f(t) ∗bg(t).
8 For an application, see Sakai, H., and G. A. Vanasse, 1966: Hilbert transform in Fourier spectroscopy.
J. Opt. Soc. Am., 56, 131–132.

The Hilbert Transform
713
Using MATLAB, test Weideman’s algorithm for the following cases. Why does the algorithm
do well or not?
9.
 1,
−1 < t < 1
0,
otherwise
10. sin(t)
11.
1
t2 + 1
12. sin(t)
1 + t4
For Problem 12, you will need
H
 sin(t)
t4 + 1

= e−1/
√
2[cos(1/
√
2 ) + sin(1/
√
2 )t2] −cos(t)
t4 + 1
.
14.2 SOME USEFUL PROPERTIES
In principle we could construct any desired transform from the deﬁnition of the Hilbert
transform. However, there are several general theorems that are much more eﬀective in
ﬁnding new transforms.
Linearity
From the deﬁnition of the Hilbert transform, it immediately follows that if z(t) =
c1x(t) + c2y(t), where c1 and c2 are arbitrary constants, then bz(t) = c1bx(t) + c2by(t).
The energy in a signal and its Hilbert
transform are the same.
Consider the energy spectral densities at input and output of a quadrature phase shifter.
The output equals
| b
X(ω)|2 =
F[bx(t)]
2 = | −i sgn(ω)|2|X(ω)|2 = |X(ω)|2.
(14.2.1)
Because the energy spectral density at input and output are the same, so are the total
energies.
A signal and its Hilbert transform
are orthogonal.
From Parseval’s theorem,
Z ∞
−∞
x(t)bx(t) dt =
Z ∞
−∞
X(ω) b
X∗(ω) dω,
(14.2.2)
where b
X(ω) = F[bx(t)]. Then,
Z ∞
−∞
X(ω) b
X∗(ω) dω =
Z ∞
−∞
i sgn(ω)|X(ω)|2 dω = 0,
(14.2.3)
because the integrand in the middle expression of Equation 14.2.3 is odd. Thus,
Z ∞
−∞
x(t)bx(t) dt = 0.
(14.2.4)
The reason why a function and its Hilbert transform are orthogonal to each other follows
from the fact that a Hilbert transformation of a function shifts the phase of each Fourier
component of the function forward by π/2 for positive frequencies and backward for negative
frequencies.

714
Advanced Engineering Mathematics with MATLAB
• Example 14.2.1
Let us verify the orthogonality condition for Hilbert transforms using x(t) = 1/(1+t2).
Because bx(t) = t/(1 + t2),
Z ∞
−∞
x(t)bx(t) dt =
Z ∞
−∞
t
(1 + t2)2 dt = 0,
(14.2.5)
since the integrand is an odd function.
⊓⊔
Shifting
Let us ﬁnd the Hilbert transform of x(t + a) if we know bx(t). From the deﬁnition of
Hilbert transforms,
H[x(t + a)] = 1
π
Z ∞
−∞
x(η + a)
t −η
dη = 1
π
Z ∞
−∞
x(τ)
(t + a) −τ dτ = bx(t + a)
(14.2.6)
or H[x(t + a)] = bx(t + a).
Time scaling
Let a > 0. Then,
H[x(at)] = 1
π
Z ∞
−∞
x(aη)
t −η dη = 1
π
Z ∞
−∞
x(τ)
at −τ dτ = bx(at).
(14.2.7)
On the other hand, if a < 0,
H[x(at)] = 1
π
Z ∞
−∞
x(aη)
t −η dη = −1
π
Z ∞
−∞
x(τ)
at −τ dτ = −bx(at).
(14.2.8)
Thus, we have that H[x(at)] = sgn(a) bx(at).
Derivatives
Let us ﬁnd the relationship between the nth derivative of x(t) and its Hilbert transform.
Using the derivative rule as it applies to Fourier transforms,
H

F
dnx
dtn

= −i sgn(ω)(iω)nX(ω) = (iω)n[−i sgn(ω)X(ω)] = (iω)n b
X(ω) = F
dnbx
dtn

.
(14.2.9)
Taking the inverse Fourier transforms, we have that
H
dnx
dtn

= dnbx
dtn .
(14.2.10)

The Hilbert Transform
715
Some General Properties of Hilbert Transforms
function, x(t)
Hilbert transform, bx(t)
1.
bx(t)
−x(t)
2.
x(t) + y(t)
bx(t) + by(t)
3.
x(t + a),
a real
bx(t + a)
4.
dnx(t)
dtn
dnbx(t)
dtn
5.
x(at)
sgn(a) bx(at)
6.
tx(t)
tbx(t) + 1
π
R ∞
−∞x(τ) dτ
7.
(t + a)x(t)
(t + a)bx(t) + 1
π
R ∞
−∞x(τ) dτ
Convolution
Hilbert transforms enjoy a similar, but not identical, property with Fourier transforms
with respect to convolution. If
w(t) = u(t) ∗v(t) =
Z ∞
−∞
u(τ)v(t −τ) dτ =
Z ∞
−∞
u(t −τ)v(τ) dτ,
(14.2.11)
then
bw(t) = v(t) ∗bu(t).
(14.2.12)
Proof : From the convolution theorem for Fourier transforms, W(ω) = V (ω)U(ω). Multi-
plying both sides of the equation by −i sgn(ω),
c
W(ω) = −i sgn(ω)W(ω) = V (ω)[−i sgn(ω)U(ω)] = V (ω)bU(ω).
(14.2.13)
Again, using the convolution theorem as it applies to Fourier transforms, we arrive at the
ﬁnal result.
⊓⊔
• Example 14.2.2
Given the functions u(t) = cos(t) and v(t) = 1/(1 + t4), let us verify the convolution
theorem as it applies to Hilbert transforms.

716
Advanced Engineering Mathematics with MATLAB
With u(t) = cos(t) and v(t) = 1/(1 + t4),
w(t) = u(t) ∗v(t) =
Z ∞
−∞
cos(t −x)
1 + x4
dx
(14.2.14)
=
Z ∞
−∞
cos(t) cos(x)
1 + x4
dx +
Z ∞
−∞
sin(t) sin(x)
1 + x4
dx
(14.2.15)
= π
√
2e−1/
√
2

cos
 1
√
2

+ sin
 1
√
2

cos(t)
(14.2.16)
so that
bw(t) = π
√
2e−1/
√
2

cos
 1
√
2

+ sin
 1
√
2

sin(t).
(14.2.17)
Because bv(t) = t(1 + t2)/[
√
2 (1 + t4)],
u(t) ∗bv(t) =
1
√
2
Z ∞
−∞
cos(t −x)x(1 + x2)
1 + x4
dx
(14.2.18)
=
1
√
2
Z ∞
−∞
cos(t) cos(x)x(1 + x2)
1 + x4
dx + 1
√
2
Z ∞
−∞
sin(t) sin(x)x(1 + x2)
1 + x4
dx
(14.2.19)
=
1
√
2 sin(t)
Z ∞
−∞
x(1 + x2) sin(x)
1 + x4
dx
(14.2.20)
= π
√
2e−1/
√
2

cos
 1
√
2

+ sin
 1
√
2

sin(t),
(14.2.21)
and the convolution theorem for Hilbert transforms holds true in this case.
⊓⊔
Product theorem
Let f(t) and g(t) denote complex functions with Fourier transforms F(ω) and G(ω),
respectively. If
1) F(ω) vanishes for |ω| > a, and G(ω) vanishes for |ω| < a, where a > 0,
or
2) f(t) and g(t) are analytic functions (their real and imaginary parts are Hilbert pairs),
then the Hilbert transform of the product of f(t) and g(t) is
H[f(t)g(t)] = f(t)bg(t).
(14.2.22)
Proof :9 The product f(t)g(t) can be expressed as
f(t)g(t) =
1
4π2
Z ∞
−∞
Z ∞
−∞
F(u)G(v)ei(u+v)t dv du.
(14.2.23)
9 See Bedrosian, E., 1963: A product theorem for Hilbert transforms. Proc. IEEE, 51, 868–869. This
theorem has been extended to functions of n-dimensional real vectors by Stark, H., 1971: An extension of
the Hilbert transform product theorem. Proc. IEEE, 59, 1359–1360.

The Hilbert Transform
717
F(u) = 0, u<0
(b)
(a) 
G(u) = 0, |v| < a
G(u) = 0, v<0
v
v
u+v = 0
u+v = 0
F(u) = 0, |u| > a
u
u
a
-a
a
-a
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      




























                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    





























Figure 14.2.1: Region of integration in the proof of the product theorem.
Because H(eibt) = i sgn(b)eibt,
H[f(t)g(t)] =
i
4π2
Z ∞
−∞
Z ∞
−∞
F(u)G(v) sgn(u + v)ei(u+v)t dv du.
(14.2.24)
The shaded regions of Figure 14.2.1 are those in which the product F(u)G(v) is nonvanishing
for the conditions of the theorem. In Figure 14.2.1(a) the nonoverlapping Fourier transforms
yield two semi-inﬁnite strips in which the product is nonvanishing. In Figure 14.2.1(b),
for analytic functions, the Fourier transforms vanish for negative arguments10 so that the
product is nonvanishing only in the ﬁrst quadrant. In both cases sgn(u + v) = sgn(v) over
the regions of integration in which the integrand is nonvanishing. Thus,
H[f(t)g(t)] =
i
4π2
Z ∞
−∞
Z ∞
−∞
F(u)G(v) sgn(v)ei(u+v)t dv du
(14.2.25)
= f(t) i
2π
Z ∞
−∞
G(v) sgn(v)eivt dv = f(t)bg(t).
(14.2.26)
⊓⊔
• Example 14.2.3: Hilbert transforms of band-pass functions
In communications, we have the double-sideband, amplitude-modulated signal given
by a(t) cos(ωt + ϕ), where ϕ is constant. From the product theorem its Hilbert transform
equals a(t) sin(ωt + ϕ), ω > 0, provided that the highest frequency component in a(t) is
less than ω. Paradoxically, the Hilbert transform of more general a(t) cos[ωt + ϕ(t)], which
equals a(t) sin[ωt + ϕ(t)], has no such restriction.
Problems
Verify the orthogonality property of Hilbert transforms using
1. x(t) = 1/(1 + t4)
2. x(t) = sin(t)/(1 + t2)
3. x(t) =
 1,
0 < t < a
0,
otherwise
10 Titchmarsh, E. C., 1948: Introduction to the Theory of Fourier Integrals. Oxford University Press,
p. 128.

718
Advanced Engineering Mathematics with MATLAB
Verify the convolution theorem for Hilbert transforms using
4. u(t) =
 1,
0 < t < a,
0,
otherwise,
v(t) = sin(t)
5. u(t) = cos(t),
v(t) =
1
1 + t2
6. Use the product theorem to show that
H[sin(at)Jn(bt)] = −cos(at)Jn(bt),
0 < b < a,
if n = 0, 1, 2, 3, . . . .
Hint:
F[Jn(bt)] = 2(−1)m
√
b2 −ω2 Tn
|ω|
b

H(b −|ω|),
where Tn(·) is a Chebyshev polynomial of the ﬁrst kind and m = n/2 or (n−1)/2, depending
upon which deﬁnition gives an integer.
7. Given cosine and sine integrals:
Ci(x) = −
Z ∞
x
cos(t)
t
dt,
Si(x) = −
Z ∞
x
sin(t)
t
dt,
and
H[Ci(a|t|)] = −sgn(t)Si(a|t|),
0 < a,
use the product rule to show that
H[sin(bt)Ci(a|t|)] = −sgn(t) sin(bt)Si(a|t|),
0 < b < a.
Hint:
F[Ci(a|t|)] =

0,
0 < |ω| < a,
−π/|ω|,
a < |ω| < ∞,
0 < a.
8. Prove that
H[tx(t)] = tbx(t) −1
π
Z ∞
−∞
x(τ) dτ.
Hint:
τx(τ)
t −τ = tx(τ)
t −τ −x(τ).
14.3 ANALYTIC SIGNALS
The monochromatic signal A cos(ω0t + ϕ) appears in many physical and engineering
applications. It is common to represent this signal by the complex representation Aei(ω0t+ϕ).
These two representations are related to each other by
A cos(ω0t + ϕ) = ℜ
h
Aei(ω0t+ϕ)i
= 1
2

Aei(ω0t+ϕ) + Ae−i(ω0t+ϕ)
.
(14.3.1)
Furthermore, the Fourier transform of A cos(ω0t + ϕ) is
F[A cos(ω0t + ϕ)] = 1
2

Aeiϕδ(ω −ω0) + Ae−iϕδ(ω + ω0)

,
(14.3.2)

The Hilbert Transform
719
−20.0
−10.0
0.0
10.0
20.0
 a
−1.0
0.0
1.0
2.0
3.0
4.0
phase (radians)
−1.0
0.0
1.0
2.0
3.0
4.0
5.0
amplitude / a
ω
Figure 14.3.1: The spectrum of the analytic signal when x(t) is the rectangular pulse given by Equation
11.1.9.
while the Fourier transform of Aei(ω0t+ϕ) is
F
h
Aei(ω0t+ϕ)i
= Aeiϕδ(ω −ω0).
(14.3.3)
As Equation 14.3.2 and Equation 14.3.3 clearly show, in passing from the real signal to
its complex representation, we double the strength of the positive frequencies and remove
entirely the negative frequencies.
Let us generalize these concepts to nonmonochromatic signals. For the real signal x(t)
with Fourier transform X(ω) and the complex signal z(t) with Fourier transform Z(ω), the
previous paragraph shows that our generalization must have the property:
Z(ω) = X(ω) + sgn(ω)X(ω)
(14.3.4)
or
Z(ω) =



2X(ω),
ω > 0,
X(ω),
ω = 0,
0,
ω < 0.
(14.3.5)
Taking the inverse of Equation 14.3.4, we have the deﬁnition of an analytic signal as
z(t) = x(t) + ibx(t),
(14.3.6)
where x(t) is a real signal and bx(t) is its Hilbert transform.
• Example 14.3.1
In Figure 14.3.1 the amplitude spectrum of the analytic signal is graphed when x(t) is
the rectangular pulse, Equation 11.1.9. Note that the amplitude spectrum equals zero for
ω < 0 and twice the amplitude spectrum for ω > 0.
⊓⊔

720
Advanced Engineering Mathematics with MATLAB
(b)
(d)
(a)
(c)
X(  )
ω
ω
ω
−ω
ω
−ω
Z(  )
0
0
ω
0
0
ω
ω
−ω
max
max
ωmax
ω
ω
Figure 14.3.2: Given a function x(t) with an amplitude spectrum shown in (a), frame (b) shows the
amplitude spectrum of the amplitude-modulated signal x(t) cos(ω0t) while frames (c) and (d) give the
amplitude spectrum of the analytic signal z(t) and x(t) cos(ω0t) −bx(t) sin(ω0t), respectively.
• Example 14.3.2
Let us ﬁnd the energy of an analytic signal.
The energy of an analytic signal is
Z ∞
−∞
|z(t)|2 dt =
Z ∞
−∞
x2(t) dt +
Z ∞
−∞
bx2(t) dt = 2
Z ∞
−∞
x2(t) dt = 2
Z ∞
−∞
|X(ω)|2 dω
(14.3.7)
by Parseval’s theorem. Thus, the analytic signal has twice the energy of the corresponding
real signal.
⊓⊔
Consider the function x(t) whose amplitude spectrum is shown in Figure 14.3.2(a). If
we were to amplitude modulate x(t) with cos(ω0t), then the amplitude spectrum of this
modulated signal would appear as pictured in Figure 14.3.2(b).
Consider now the signal
y(t) = x(t) cos(ω0t) −bx(t) sin(ω0t) = ℜ

[x(t) + ibx(t)]eiω0t	
(14.3.8)
= ℜ

z(t)eiω0t	
= 1
2

z(t)eiω0t + z∗(t)e−iω0t
,
(14.3.9)
where z(t) is the analytic signal of x(t). We have plotted the amplitude spectrum |Z(ω)| in
Figure 14.3.2(c). If we computed the amplitude spectrum of y(t), we would ﬁnd that
Y (ω) = 1
2Z(ω −ω0) + 1
2Z(−ω −ω0)
(14.3.10)
=



X(ω −ω0),
ω0 ≤ω ≤ω0 + ωmax,
X∗(−ω −ω0),
−ω0 −ωmax ≤ω ≤ω0,
0,
otherwise.
(14.3.11)
We have sketched this amplitude spectrum |Y (ω)| in Figure 14.3.2(d). Each triangular part
is called the single sideband signal because it contains the upper frequencies (|ω| > ω0) of
the modulated signal x(t) cos(ω0t). Similarly, if we had used x(t) cos(ω0t) + bx(t) sin(ω0t),
we would only have obtained the lower sidebands. Consequently, a communication system
using x(t) cos(ω0t)−bx(t) sin(ω0t) or x(t) cos(ω0t)+bx(t) sin(ω0t) would realize a 50% savings
in its frequency bandwidth over one transmitting x(t) cos(ω0t).

The Hilbert Transform
721
Problems
1. Find the analytic signal corresponding to x(t) = cos(ωt), ω > 0.
2. Show that the polar form of an analytic signal can be written
z(t) = |z(t)|eiϕ(t),
where
|z(t)|2 = x2(t) + bx2(t),
ϕ(t) = tan−1
 bx(t)
x(t)

.
3. Analytic signals are often used with narrow-band waveforms with carrier frequency ω0.
If ϕ(t) = ω0t + ϕ′(t), show that the analytic signal can be written z(t) = r(t)eiω0t, where
r(t) = |z(t)|eiϕ′(t). The function r(t) is called the complex envelope or the phasor amplitude;
this is a generalization of the phasor idea beyond pure alternating currents.
14.4 CAUSALITY: THE KRAMERS-KRONIG RELATIONSHIP
Causality is the physical principle which states that an event cannot proceed its cause.
In this section we explore what eﬀect this principle has on Hilbert transforms.
We begin by introducing the concept of causal functions. A causal function is a function
that equals zero for all t < 0. As with all functions we can write it in terms of an even xe(t)
and an odd xo(t) part as x(t) = xe(t) + xo(t). Because x(t) is causal, xo(t) = sgn(t)xe(t)
and
x(t) = xe(t) + sgn(t)xe(t).
(14.4.1)
Taking the Fourier transform of Equation 14.4.1, we ﬁnd that the Fourier transform of all
causal functions are of the form
X(ω) = Xe(ω) −i b
Xe(ω),
(14.4.2)
where
b
Xe(ω) = 1
π
Z ∞
−∞
Xe(τ)
ω −τ dτ,
(14.4.3)
and
Xe(ω) = −1
π
Z ∞
−∞
b
Xe(τ)
ω −τ dτ,
(14.4.4)
because
2πF[xe(t)sgn(t)] = 2
iω ∗Xe(ω) = 2
i
Z ∞
−∞
Xe(τ)
ω −τ dτ.
(14.4.5)
Equations 14.4.3 and 14.4.4 ﬁrst arose in dielectric theory and, taken together, are called
the Kramers11 and Kronig12 relation after their discoverers, who derived these relationships
during their work on the dispersion of light by gaseous atoms or molecules.
11 Kramers, H. A., 1929: Die Dispersion und Absorption von R¨ontgenstrahlen. Phys. Z., 30, 522–523.
12 Kronig, R. de L., 1926: On the theory of dispersion of x-rays. J. Opt. Soc. Am., 12, 547–551.

722
Advanced Engineering Mathematics with MATLAB
• Example 14.4.1
Let us verify the Kramers-Kronig relation using the causal time function x(t) = H(t).
Because xe(t) = 1
2 and Xe(ω) = πδ(ω) by Equation 11.2.3,
b
Xe(ω) = 1
π
Z ∞
−∞
π δ(τ)
ω −τ dτ = −1
ω .
(14.4.6)
Consequently, by the Kramers-Kronig relation,
F[H(t)] = Xe(ω) −i b
Xe(ω) = πδ(ω) + i
ω .
(14.4.7)
This agrees with the result given in Example 11.2.2.
⊓⊔
• Example 14.4.2
A simple example of a causal function is the impulse response or Green’s function
introduced in earlier chapters. From Equation 14.4.2 we have the result that the trans-
fer function G(ω), the Fourier transform of the impulse response, must yield the Hilbert
transform pair Ge(ω) −i bGe(ω).
For example, if g(t) = e−tH(t), then G(ω) = 1/(1 + iω). Because
1
1 + iω =
1
ω2 + 1 −i
ω
ω2 + 1,
(14.4.8)
we have the Hilbert transform pair of
x(t) =
1
t2 + 1
and
bx(t) =
t
t2 + 1.
(14.4.9)
⊓⊔
• Example 14.4.3
Let us verify the Kramers-Kronig relation for the Hilbert transform pair
x(t) =
1
t4 + 1
and
bx(t) =
t(t2 + 1)
√
2(t4 + 1)
(14.4.10)
by direct integration.
From Equation 14.4.3, we have that
ω(ω2 + 1)
√
2(ω4 + 1) = 1
π
Z ∞
−∞
dτ
(τ 4 + 1)(ω −τ).
(14.4.11)
Applying the residue theorem to the right side of Equation 14.4.11, we obtain
ω(ω2 + 1)
√
2(ω4 + 1) = i Res

1
(z4 + 1)(ω −z); ω

+ 2i Res

1
(z4 + 1)(ω −z); eπi/4

+ 2i Res

1
(z4 + 1)(ω −z); e3πi/4

.
(14.4.12)

The Hilbert Transform
723
We only include one half of the value of the residue at τ = ω because the singularity lies
on the path of integration and we must treat this integration along the lines of a Cauchy
principal value. Evaluating the residues, we ﬁnd
Res

1
(z4 + 1)(ω −z); ω

= −
1
ω4 + 1,
(14.4.13)
Res

1
(z4 + 1)(ω −z); eπi/4

=
√
2 −(1 + i)ω
4
√
2

ω −
1
√
2
2
+ 1
2
,
(14.4.14)
and
Res

1
(z4 + 1)(ω −z); e3πi/4

=
√
2 + (1 −i)ω
4
√
2

ω +
1
√
2
2
+ 1
2
.
(14.4.15)
Substituting Equation 14.4.13 through Equation 14.4.15 into the right side of Equation
14.4.12, we obtain the left side.
Problems
1. For a causal function x(t), prove that xo(t) = sgn(t)xe(t) and xe(t) = sgn(t)xo(t).
2. Redo our analysis if x(t) is a negative time function, i.e., x(t) = 0 if t > 0. Verify your
result using x(t) = etH(−t).
3. Using g(t) = te−tH(t), ﬁnd the corresponding Hilbert transform pairs.
4. Using g(t) = e−t cos(ωt)H(t), ﬁnd the corresponding Hilbert transform pairs.
5. Verify the Kramers-Kronig relation for the Hilbert transform pair:
x(t) =
1
t2 + 1
and
bx(t) =
t
t2 + 1
by direct integration.
Further Reading
Hahn, S. L., 1996: Hilbert Transforms in Signal Processing. Artech House, 442 pp. Covers
the basic theory and gives some practical applications.

Chapter 15
Green’s Functions
We have devoted a major portion of this book to solving linear ordinary and partial
diﬀerential solutions. For example, in the case of partial diﬀerential equations we introduced
the method of separation of variables, which leads to a solution in terms of an eigenfunction
expansion. However, this method is not the only one; in Section 12.12 we showed how a
solution can be constructed using the superposition integral. Here we expand upon this idea
and illustrate how a solution, called a Green’s function, to a diﬀerential equation forced by
the Dirac delta function can be used in an integral representation of a solution when the
forcing is arbitrary.
15.1 WHAT IS A GREEN’S FUNCTION?
The following examples taken from engineering show how Green’s functions naturally
appear during the solution of initial-value and boundary-value problems. We also show that
the solution u(x) can be expressed as an integral involving the Green’s function and f(x).
Circuit theory
In electrical engineering, one of the simplest electrical devices consists of a voltage
source v(t) connected to a resistor with resistance R and an inductor with inductance L.
See Figure 15.1.1. Denoting the current by i(t), the equation that governs this circuit is
Ldi
dt + Ri = v(t).
(15.1.1)
725

726
Advanced Engineering Mathematics with MATLAB
v(t)
-
+
L
i(t)
R
Figure 15.1.1: The RL electrical circuit driven by the voltage v(t).
Consider now the following experiment: With the circuit initially dead, we allow the
voltage to suddenly become V0/∆τ during a very short duration ∆τ starting at t = τ.
Then, at t = τ + ∆τ, we again turn oﬀthe voltage supply. Mathematically, for t > τ + ∆τ,
the circuit’s performance obeys the homogeneous diﬀerential equation
Ldi
dt + Ri = 0,
t > τ + ∆τ,
(15.1.2)
whose solution is
i(t) = I0e−Rt/L,
t > τ + ∆τ,
(15.1.3)
where I0 is a constant and L/R is the time constant of the circuit. Because the voltage v(t)
during τ < t < τ + ∆τ is V0/∆τ, then
Z τ+∆τ
τ
v(t) dt = V0.
(15.1.4)
Therefore, over the interval τ < t < τ + ∆τ, Equation 15.1.1 can be integrated to yield
L
Z τ+∆τ
τ
di + R
Z τ+∆τ
τ
i(t) dt =
Z τ+∆τ
τ
v(t) dt,
(15.1.5)
or
L [i(τ + ∆τ) −i(τ)] + R
Z τ+∆τ
τ
i(t) dt = V0.
(15.1.6)
If i(t) remains continuous as ∆τ becomes small, then
R
Z τ+∆τ
τ
i(t) dt ≈0.
(15.1.7)
Finally, because
i(τ) = 0,
(15.1.8)
and
i(τ + ∆τ) = I0e−R(τ+∆τ)/L ≈I0e−Rτ/L,
(15.1.9)
for small ∆τ, Equation 15.1.6 reduces to
LI0e−Rτ/L = V0,
(15.1.10)

Green’s Functions
727
t
τ+∆τ
τ
V  /L
0
i(t)
Figure 15.1.2: The current i(t) within an RL circuit when the voltage V0/∆τ is introduced between the
times τ < t < τ + ∆τ.
or
I0 = V0
L eRτ/L.
(15.1.11)
Therefore, Equation 15.1.3 can be written as
i(t) =
(
0,
t < τ,
V0e−R(t−τ)/L/L,
τ ≤t,
(15.1.12)
after using Equation 15.1.11. Equation 15.1.12 is plotted in Figure 15.1.2.
Consider now a new experiment with the same circuit where we subject the circuit
to N voltage impulses, each of duration ∆τ and amplitude Vi/∆τ with i = 0, 1, . . . , N,
occurring at t = τi. See Figure 15.1.3. The current response is then
i(t) =

































0,
t < τ0,
V0e−R(t−τ0)/L/L,
τ0 < t < τ1,
V0e−R(t−τ0)/L/L + V1e−R(t−τ1)/L/L,
τ1 < t < τ2,
...
...
N
X
i=0
Vie−R(t−τi)/L/L,
τN < t < τN+1.
(15.1.13)
Finally, consider our circuit subjected to a continuous voltage source v(t). Over each
successive interval dτ, the step change in voltage is v(τ) dτ. Consequently, from Equation
15.1.13 the response i(t) is now given by the superposition integral
i(t) =
Z t
τ
v(τ)
L e−R(t−τ)/L dτ,
(15.1.14)
or
i(t) =
Z t
τ
v(τ)g(t|τ) dτ,
(15.1.15)

728
Advanced Engineering Mathematics with MATLAB
τ
τ
τ2
1
0
τN
t
i(t)
Figure 15.1.3: The current i(t) within an RL circuit when the voltage is changed at t = τ0, t = τ1, and
so forth.
where
g(t|τ) = e−R(t−τ)/L
L
,
τ < t.
(15.1.16)
Here we have assumed that i(t) = v(t) = 0 for t < τ. In Equation 15.1.15, g(t|τ) is called
the Green’s function. As this equation shows, given the Green’s function to Equation 15.1.1,
the response i(t) to any voltage source v(t) can be obtained by convolving the voltage source
with the Green’s function.
We now show that we could have found the Green’s function, Equation 15.1.16, by
solving Equation 15.1.1 subject to an impulse- or delta-forcing function. Mathematically,
this corresponds to solving the following initial-value problem:
Ldg
dt + Rg = δ(t −τ),
g(0|τ) = 0.
(15.1.17)
Taking the Laplace transform of Equation 15.1.17, we ﬁnd that
G(s|τ) =
e−sτ
Ls + R,
(15.1.18)
or
g(t|τ) = e−R(t−τ)/L
L
H(t −τ),
(15.1.19)
where H(·) is the Heaviside step function. As our short derivation showed, the most direct
route to ﬁnding a Green’s function is solving the diﬀerential equation when its forcing
equals the impulse or delta function. This is the technique that we will use throughout this
chapter.
Statics
Consider a string of length L that is connected at both ends to supports and is subjected
to a load (external force per unit length) of f(x). We wish to ﬁnd the displacement u(x) of
the string. If the load f(x) acts downward (negative direction), the displacement u(x) of
the string is given by the diﬀerential equation
T d2u
dx2 = f(x),
(15.1.20)

Green’s Functions
729
ξ
f(
ξ )
ξ)
g(x
x
L
Figure 15.1.4: The response, commonly called a Green’s function, of a string ﬁxed at both ends to a point
load at x = ξ.
where T denotes the uniform tensile force of the string. Because the string is stationary at
both ends, the displacement u(x) satisﬁes the boundary conditions
u(0) = u(L) = 0.
(15.1.21)
Instead of directly solving for the displacement u(x) of the string subject to the load
f(x), let us ﬁnd the displacement that results from a load δ(x −ξ) concentrated at the
point x = ξ. See Figure 15.1.4. For this load, the diﬀerential equation, Equation 15.1.20,
becomes
T d2g
dx2 = δ(x −ξ),
(15.1.22)
subject to the boundary conditions
g(0|ξ) = g(L|ξ) = 0.
(15.1.23)
In Equation 15.1.22, g(x|ξ) denotes the displacement of the string when it is subjected to
an impulse load at x = ξ. In line with our circuit theory example, it gives the Green’s
function for our statics problem. Once found, the displacement u(x) of the string subject to
any arbitrary load f(x) can be found by convolving the load f(x) with the Green’s function
g(x|ξ) as we did earlier.
Let us now ﬁnd this Green’s function. At any point x ̸= ξ, Equation 15.1.22 reduces
to the homogeneous diﬀerential equation
d2g
dx2 = 0,
(15.1.24)
which has the solution
g(x|ξ) =

ax + b,
0 ≤x < ξ,
cx + d,
ξ < x ≤L.
(15.1.25)
Applying the boundary conditions, Equation 15.1.23, we ﬁnd that
g(0|ξ) = a · 0 + b = b = 0,
(15.1.26)
and
g(L|ξ) = cL + d = 0,
or
d = −cL.
(15.1.27)

730
Advanced Engineering Mathematics with MATLAB
Therefore, we can rewrite Equation 15.1.25 as
g(x|ξ) =

ax,
0 ≤x < ξ,
c(x −L),
ξ < x ≤L,
(15.1.28)
where a and c are undetermined constants.
At x = ξ, the displacement u(x) of the string must be continuous; otherwise, the string
would be broken. Therefore, the Green’s function given by Equation 15.1.28 must also be
continuous there. Thus,
aξ = c(ξ −L),
or
c =
aξ
ξ −L.
(15.1.29)
From Equation 15.1.22 the second derivative of g(x|ξ) must equal the impulse function.
Therefore, the ﬁrst derivative of g(x|ξ), obtained by integrating this equation, must be
discontinuous by the amount 1/T or
lim
ǫ→0
dg(ξ + ǫ|ξ)
dx
−dg(ξ −ǫ|ξ)
dx

= 1
T ,
(15.1.30)
in which case
dg(ξ+|ξ)
dx
−dg(ξ−|ξ)
dx
= 1
T ,
(15.1.31)
where ξ+ and ξ−denote points lying just above or below ξ, respectively. Using Equation
15.1.28, we ﬁnd that
dg(ξ−|ξ)
dx
= a,
(15.1.32)
and
dg(ξ+|ξ)
dx
= c =
aξ
ξ −L.
(15.1.33)
Thus, Equation 15.1.31 leads to
aξ
ξ −L −a = 1
T ,
or
aL
ξ −L = 1
T ,
or
a = ξ −L
LT ,
(15.1.34)
and the Green’s function is
g(x|ξ) =
1
TL(x> −L)x<,
(15.1.35)
where x< = min(x, ξ) and x> = max(x, ξ). To ﬁnd the displacement u(x) subject to the
load f(x), we proceed as we did in the previous example. The result of this analysis is
u(x) =
Z L
0
f(ξ)g(x|ξ) dξ = x −L
TL
Z x
0
f(ξ) ξ dξ + x
TL
Z L
x
f(ξ) (ξ −L) dξ,
(15.1.36)
since ξ < x in the ﬁrst integral and x < ξ in the second integral of Equation 15.1.36.

Green’s Functions
731
Integral Equations
Consider the Sturm-Liouville problem
y′′ + λy = 0,
y(0) = y(L) = 0.
(15.1.37)
From Section 6.1, nontrivial solutions exist only if
λn = n2π2
L2 ,
yn(x) = sin
nπx
L

,
(15.1.38)
where n = 1, 2, 3, . . ..
Consider now a new boundary-value problem:
d2y
dx2 = −f(x),
y(0) = y(L) = 0.
(15.1.39)
In the next section (Equation 15.2.76), we will show that we can write its solution by
y(x) =
Z L
0
f(ξ)g(x|ξ) dξ,
(15.1.40)
where the Green’s function g(x|ξ) is given by
d2g
dx2 = −δ(x −ξ),
g(0|ξ) = g(L|ξ) = 0,
(15.1.41)
or
g(x|ξ) = (L −x>)x</L,
(15.1.42)
where x> = max(x, ξ) and x< = min(x, ξ).
We can now use Equation 15.1.39 to rewrite Equation 15.1.37 as
λy(ξ) = f(ξ).
(15.1.43)
Multiplying Equation 15.1.43 by g(x|ξ) and integrating from 0 to L, we ﬁnd that
Z L
0
f(ξ)g(x|ξ) dξ = λ
Z L
0
y(ξ)g(x|ξ) dξ,
(15.1.44)
or
y(x) −λ
Z L
0
y(ξ)g(x|ξ) dξ = 0.
(15.1.45)
Because of the equivalence of Equation 15.1.37 and Equation 15.1.45, the solutions to the
integral equation Equation 15.1.45 are λn = n2π2/L2 with yn(x) = sin(nπx/L). Direct
substitution veriﬁes this result. Thus, we can use Green’s functions to construct integral
equations that have known solutions. Indeed, it was the use of Green’s functions to solve
Fredholm integral equations that drew the attention of mathematicians at the turn of the
twentieth century.1
1 See Section 36 in Kneser, A., 1911: Integralgleichungen und ihre Anwendungen in der mathematischen
Physik. Braunschweig, 293 pp.

732
Advanced Engineering Mathematics with MATLAB
15.2 ORDINARY DIFFERENTIAL EQUATIONS
Second-order diﬀerential equations are ubiquitous in engineering. In electrical engi-
neering, many electrical circuits are governed by second-order, linear ordinary diﬀerential
equations. In mechanical engineering they arise during the application of Newton’s second
law.
One of the drawbacks of solving ordinary diﬀerential equations with a forcing term is
its lack of generality. Each new forcing function requires a repetition of the entire process.
In this section we give some methods for ﬁnding the solution in a somewhat more gen-
eral manner for stationary systems where the forcing, not any initially stored energy (i.e.,
nonzero initial conditions), produces the total output. Unfortunately, the solution must be
written as an integral.
In Example 12.8.3 we solved the linear diﬀerential equation
y′′ + 2y′ + y = f(t),
(15.2.1)
subject to the initial conditions y(0) = y′(0) = 0.
At that time we wrote the Laplace
transform of y(t), Y (s), as the product of two Laplace transforms:
Y (s) =
1
(s + 1)2 F(s).
(15.2.2)
One drawback in using Equation 15.2.2 is its dependence upon an unspeciﬁed Laplace
transform F(s). Is there a way to eliminate this dependence and yet retain the essence of
the solution?
One way of obtaining a quantity that is independent of the forcing is to consider the
ratio:
Y (s)
F(s) = G(s) =
1
(s + 1)2 .
(15.2.3)
This ratio is called the transfer function because we can transfer the input F(s) into the
output Y (s) by multiplying F(s) by G(s).
It depends only upon the properties of the
system.
Let us now consider a related problem to Equation 15.2.1, namely
g′′ + 2g′ + g = δ(t),
t > 0,
(15.2.4)
with g(0) = g′(0) = 0. Because the forcing equals the Dirac delta function, g(t) is called
the impulse response or Green’s function.2 Computing G(s),
G(s) =
1
(s + 1)2 .
(15.2.5)
From Equation 15.2.3 we see that G(s) is also the transfer function. Thus, an alternative
method for computing the transfer function is to subject the system to impulse forcing and
the Laplace transform of the response is the transfer function.
From Equation 15.2.3,
Y (s) = G(s)F(s),
(15.2.6)
2 For the origin of the Green’s function, see Farina, J. E. G., 1976: The work and signiﬁcance of George
Green, the miller mathematician, 1793–1841. Bull. Inst. Math. Appl., 12, 98–105.

Green’s Functions
733
or
y(t) = g(t) ∗f(t).
(15.2.7)
That is, the convolution of the impulse response with the particular forcing gives the re-
sponse of the system. Thus, we may describe a stationary system in one of two ways: (1)
in the transform domain we have the transfer function, and (2) in the time domain there is
the impulse response.
Despite the fundamental importance of the impulse response or Green’s function for a
given linear system, it is often quite diﬃcult to determine, especially experimentally, and a
more convenient practice is to deal with the response to the unit step H(t). This response
is called the indicial admittance or step response, which we shall denote by a(t). Because
L[H(t)] = 1/s, we can determine the transfer function from the indicial admittance because
L[a(t)] = G(s)L[H(t)] or sA(s) = G(s). Furthermore, because
L[g(t)] = G(s) = L[a(t)]
L[H(t)],
(15.2.8)
then
g(t) = da(t)
dt
(15.2.9)
from Equation 12.1.18.
• Example 15.2.1
Let us ﬁnd the transfer function, impulse response, and step response for the system
y′′ −3y′ + 2y = f(t),
(15.2.10)
with y(0) = y′(0) = 0. To ﬁnd the impulse response, we solve
g′′ −3g′ + 2g = δ(t −τ),
(15.2.11)
with g(0) = g′(0) = 0. We have generalized the problem to an arbitrary forcing at t = τ
and now denote the Green’s function by g(t|τ). We have done this so that our discussion
will be consistent with the other sections in the chapter.
Taking the Laplace transform of Equation 15.2.11, we ﬁnd that
G(s|τ) =
e−sτ
s2 −3s + 2,
(15.2.12)
which is the transfer function for this system when τ = 0. The impulse response or Green’s
function equals the inverse of G(s|τ) or
g(t|τ) =
h
e2(t−τ) −et−τi
H(t −τ).
(15.2.13)
To ﬁnd the step response, we solve
a′′ −3a′ + 2a = H(t),
(15.2.14)
with a(0) = a′(0) = 0. Taking the Laplace transform of Equation 15.2.14,
A(s) =
1
s(s −1)(s −2),
(15.2.15)

734
Advanced Engineering Mathematics with MATLAB
0
0.2
0.4
0.6
0.8
1
1.2
0
1
2
3
indicial response
0
0.2
0.4
0.6
0.8
1
1.2
0
2
4
6
8
impulse response
time
Figure 15.2.1: The impulse and step responses corresponding to the transfer function, Equation 15.2.12,
with τ = 0.
and the indicial admittance is given by the inverse of Equation 15.2.15, or
a(t) = 1
2 + 1
2e2t −et.
(15.2.16)
Note that a′(t) = g(t|0).
⊓⊔
• Example 15.2.2
MATLAB’s control toolbox contains several routines for the numerical computation
of impulse and step responses if the transfer function can be written as the ratio of two
polynomials. To illustrate this capacity, let us redo the previous example where the transfer
function is given by Equation 15.2.12 with τ = 0. The transfer function is introduced by
loading in the polynomial in the numerator num and in the denominator den followed by
calling tf. The MATLAB script
clear
% load in coefficients of the numerator and denominator
%
of the transfer function
num = [0 0 1]; den = [1 -3 2];
% create the transfer function
sys = tf(num,den);
% find the step response, a
[a,t] = step(sys);
% plot the indicial admittance
subplot(2,1,1), plot(t, a, ’o’)
ylabel(’indicial response’,’Fontsize’,20)
% find the impulse response, g
[g,t] = impulse(sys);
% plot the impulse response
subplot(2,1,2), plot(t, g, ’o’)
ylabel(’impulse response’,’Fontsize’,20)
xlabel(’time’,’Fontsize’,20)
shows how the impulse and step responses are found. Both of them are shown in Figure
15.2.1.
⊓⊔

Green’s Functions
735
• Example 15.2.3
There is an old joke about a man who took his car into a garage because of a terrible
knocking sound. Upon his arrival the mechanic took one look at it and gave it a hefty
kick.3 Then, without a moment’s hesitation he opened the hood, bent over, and tightened
up a loose bolt. Turning to the owner, he said, “Your car is ﬁne. That’ll be $50.” The
owner felt that the charge was somewhat excessive, and demanded an itemized account.
The mechanic said, “The kicking of the car and tightening one bolt, cost you a buck. The
remaining $49 comes from knowing where to kick the car and ﬁnding the loose bolt.”
Although the moral of the story may be about expertise as a marketable commodity,
it also illustrates the concept of transfer function.4 Let us model the car as a linear system
where the equation
an
dny
dtn + an−1
dn−1y
dtn−1 + · · · + a1
dy
dt + a0y = f(t)
(15.2.17)
governs the response y(t) to a forcing f(t). Assuming that the car has been sitting still, the
initial conditions are zero and the Laplace transform of Equation 15.2.17 is
K(s)Y (s) = F(s),
(15.2.18)
where
K(s) = ansn + an−1sn−1 + · · · + a1s + a0.
(15.2.19)
Hence,
Y (s) = F(s)
K(s) = G(s)F(s),
(15.2.20)
where the transfer function G(s) clearly depends only on the internal workings of the car.
So if we know the transfer function, we understand how the car vibrates because
y(t) =
Z t
0
g(t −x)f(x) dx.
(15.2.21)
But what does this have to do with our mechanic? He realized that a short sharp kick
mimics an impulse forcing with f(t) = δ(t) and y(t) = g(t). Therefore, by observing the
response of the car to his kick, he diagnosed the loose bolt and ﬁxed the car.
⊓⊔
In the previous examples, we used Laplace transforms to solve for the Green’s functions.
However, there is a rich tradition of using Fourier transforms rather than Laplace transforms.
In these particular cases, the Fourier transform of the Green’s function is called frequency
response or steady-state transfer function of our system when τ = 0. Consider the following
examples.
3 This is obviously a very old joke.
4 Originally suggested by Stern, M. D., 1987: Why the mechanic kicked the car - A teaching aid for
transfer functions. Math. Gaz., 71, 62–64.

736
Advanced Engineering Mathematics with MATLAB
• Example 15.2.4: Spectrum of a damped harmonic oscillator
In mechanics the damped oscillations of a mass m attached to a spring with a spring
constant k and damped with a velocity-dependent resistance are governed by the equation
my′′ + cy′ + ky = f(t),
(15.2.22)
where y(t) denotes the displacement of the oscillator from its equilibrium position, c denotes
the damping coeﬃcient, and f(t) denotes the forcing.
Assuming that both f(t) and y(t) have Fourier transforms, let us analyze this system
by ﬁnding its frequency response.
We begin by solving for the Green’s function g(t|τ),
which is given by
mg′′ + cg′ + kg = δ(t −τ),
(15.2.23)
because the Green’s function is the response of a system to a delta function forcing. Taking
the Fourier transform of both sides of Equation 15.2.23, the frequency response is
G(ω|τ) =
e−iωτ
k + icω −mω2 =
e−iωτ/m
ω2
0 + icω/m −ω2 ,
(15.2.24)
where ω2
0 = k/m is the natural frequency of the system. The most useful quantity to plot
is the frequency response or
|G(ω|τ)| =
ω2
0
k
p
(ω2 −ω2
0)2 + ω2ω2
0(c2/km)
(15.2.25)
=
1
k
p
[(ω/ω0)2 −1]2 + (c2/km)(ω/ω0)2 .
(15.2.26)
In Figure 15.2.2 we plotted the frequency response as a function of c2/(km). Note that as the
damping becomes larger, the sharp peak at ω = ω0 essentially vanishes. As c2/(km) →0,
we obtain a very ﬁnely tuned response curve. Let us now ﬁnd the Green’s function. From
the deﬁnition of the inverse Fourier transform,
mg(t|τ) = −1
2π
Z ∞
−∞
eiωt
ω2 −icω/m −ω2
0
dω = −1
2π
Z ∞
−∞
eiωt
(ω −ω1)(ω −ω2) dω,
(15.2.27)
where
ω1,2 = ±
q
ω2
0 −γ2 + γi,
(15.2.28)
and γ = c/(2m) > 0. We can evaluate Equation 15.2.27 by residues. Clearly the poles
always lie in the upper half of the ω-plane. Thus, if t < τ in Equation 15.2.27 we can
close the line integration along the real axis with a semicircle of inﬁnite radius in the lower
half of the ω-plane by Jordan’s lemma. Because the integrand is analytic within the closed
contour, g(t|τ) = 0 for t < τ. This is simply the causality condition,5 the impulse forcing
5 The principle stating that an event cannot precede its cause.

Green’s Functions
737
ω/ω 0
k
0.0
0.5
1.0
1.5
2.0
0.0
1.0
2.0
3.0
4.0
5.0
6.0
7.0
8.0
9.0
10.0
11.0
c /km = 0.01
2
c /km = 0.1
c /km = 1
2
2
|
)
G(ω |
Figure 15.2.2: The variation of the frequency response for a damped harmonic oscillator as a function of
driving frequency ω. See the text for the deﬁnition of the parameters.
being the cause of the excitation. Clearly, causality is closely connected with the analyticity
of the frequency response in the lower half of the ω-plane.
If t > τ, we close the line integration along the real axis with a semicircle of inﬁnite
radius in the upper half of the ω-plane and obtain
mg(t|τ) = 2πi

−1
2π
 
Res

eiz(t−τ)
(z −ω1)(z −ω2); ω1

+ Res

eiz(t−τ)
(z −ω1)(z −ω2); ω2

(15.2.29)
=
−i
ω1 −ω2
h
eiω1(t−τ) −eiω2(t−τ)i
=
e−γ(t−τ) sin
h
(t −τ)
p
ω2
0 −γ2
i
p
ω2
0 −γ2
H(t −τ).
(15.2.30)
Let us now examine the damped harmonic oscillator by describing the migration of the
poles ω1,2 in the complex ω-plane as γ increases from 0 to ∞.
See Figure 15.2.3.
For
γ ≪ω0 (weak damping), the poles ω1,2 are very near to the real axis, above the points
±ω0, respectively. This corresponds to the narrow resonance band discussed earlier and
we have an underdamped harmonic oscillator.
As γ increases from 0 to ω0, the poles
approach the positive imaginary axis, moving along a semicircle of radius ω0 centered at
the origin. They coalesce at the point iω0 for γ = ω0, yielding repeated roots, and we have
a critically damped oscillator. For γ > ω0, the poles move in opposite directions along
the positive imaginary axis; one of them approaches the origin, while the other tends to
i∞as γ →∞. The solution then has two purely decaying, overdamped solutions. During
the early 1950s, a similar diagram was invented by Evans6 where the movement of closed-
loop poles is plotted for all values of a system parameter, usually the gain. This root-locus
method is very popular in system control theory for two reasons. First, the investigator can
easily determine the contribution of a particular closed-loop pole to the transient response.
Second, he can determine the manner in which open-loop poles or zeros should be introduced
or their location modiﬁed so that he will achieve a desired performance characteristic for
his system.
⊓⊔
6 Evans, W. R., 1948: Graphical analysis of control systems. Trans. AIEE, 67, 547–551; Evans, W.
R., 1954: Control-System Dynamics. McGraw-Hill, 282 pp.

738
Advanced Engineering Mathematics with MATLAB
τ
τ
x
y
−ω0
0
ω
t > 
t < 
Figure 15.2.3: The migration of the poles of the frequency response of a damped harmonic oscillator as
a function of γ.
• Example 15.2.5: Low-frequency ﬁlter
Consider the ordinary diﬀerential equation
Ry′ + y
C = f(t),
(15.2.31)
where R and C are real, positive constants. If y(t) denotes current, then Equation 15.2.31
would be the equation that gives the voltage across a capacitor in an RC circuit. Let us ﬁnd
the frequency response and Green’s function for this system. We begin by writing Equation
15.2.31 as
Rg′ + g
C = δ(t −τ),
(15.2.32)
where g(t|τ) denotes the Green’s function. If the Fourier transform of g(t|τ) is G(ω|τ), the
frequency response G(ω|τ) is given by
iωRG(ω|τ) + G(ω|τ)
C
= e−iωτ,
(15.2.33)
or
G(ω|τ) =
e−iωτ
iωR + 1/C =
Ce−iωτ
1 + iωRC ,
(15.2.34)
and
|G(ω|τ)| =
C
√
1 + ω2R2C2 =
C
q
1 + ω2/ω2p
,
(15.2.35)
where ωp = 1/(RC) is an intrinsic constant of the system. In Figure 15.2.4 we plotted
|G(ω|τ)| as a function of ω. From this ﬁgure, we see that the response is largest for small
ω and decreases as ω increases.
This is an example of a low-frequency ﬁlter because relatively more signal passes through
at lower frequencies than at higher frequencies. To understand this, let us drive the system

Green’s Functions
739
p
ω/ω
|
0.0
1.0
2.0
3.0
4.0
5.0
0.0
0.2
0.4
0.6
0.8
1.0
G(ω
/C
|)
Figure 15.2.4: The variation of the frequency response, Equation 15.2.35, as a function of driving frequency
ω. See the text for the deﬁnition of the parameters.
with a forcing function that has the Fourier transform F(ω). The response of the system
will be G(ω, 0)F(ω). Thus, that portion of the forcing function’s spectrum at the lower
frequencies is relatively unaﬀected because |G(ω, 0)| is near unity.
However, at higher
frequencies where |G(ω, 0)| is smaller, the magnitude of the output is greatly reduced.
⊓⊔
• Example 15.2.6
During his study of tumor growth, Adam7 found the particular solution to an ordinary
diﬀerential equation which, in its simplest form, is
y′′ −α2y =

|x|/L −1,
|x| < L,
0,
|x| > L,
(15.2.36)
by the method of Green’s functions. Let us retrace his steps and see how he did it.
The ﬁrst step is ﬁnding the Green’s function. We do this by solving
g′′ −α2g = δ(x),
(15.2.37)
subject to the boundary conditions lim|x|→∞g(x) →0. Taking the Fourier transform of
Equation 15.2.37, we obtain
G(ω) = −
1
ω2 + α2 .
(15.2.38)
The function G(ω) is the frequency response for our problem. Straightforward inversion
yields the Green’s function
g(x) = −e−α|x|
2α
.
(15.2.39)
Therefore, by the convolution integral, y(x) = g(x) ∗f(x),
y(x) =
Z L
−L
g(x −ξ) (|ξ|/L −1) dξ = 1
2α
Z L
−L
(1 −|ξ|/L) e−α|x−ξ| dξ.
(15.2.40)
7 Adam, J. A., 1986: A simpliﬁed mathematical model of tumor growth. Math. Biosci., 81, 229–244.

740
Advanced Engineering Mathematics with MATLAB
To evaluate Equation 15.2.40 we must consider four separate cases: −∞< x < −L,
−L < x < 0, 0 < x < L, and L < x < ∞. Turning to the −∞< x < −L case ﬁrst, we have
y(x) = 1
2α
Z L
−L
(1 −|ξ|/L) eα(x−ξ) dξ
(15.2.41)
= eαx
2α
Z 0
−L
(1 + ξ/L) e−αξ dξ + eαx
2α
Z L
0
(1 −ξ/L) e−αξ dξ
(15.2.42)
= eαx
2α3L
 eαL + e−αL −2

.
(15.2.43)
Similarly, for x > L,
y(x) = 1
2α
Z L
−L
(1 −|ξ|/L) e−α(x−ξ) dξ
(15.2.44)
= e−αx
2α
Z 0
−L
(1 + ξ/L) eαξ dξ + e−αx
2α
Z L
0
(1 −ξ/L) eαξ dξ
(15.2.45)
= e−αx
2α3L
 eαL + e−αL −2

.
(15.2.46)
On the other hand, for −L < x < 0, we ﬁnd that
y(x) = 1
2α
Z x
−L
(1 −|ξ|/L) e−α(x−ξ) dξ + 1
2α
Z L
x
(1 −|ξ|/L) eα(x−ξ) dξ
(15.2.47)
= e−αx
2α
Z x
−L
(1 + ξ/L) eαξ dξ + eαx
2α
Z 0
x
(1 + ξ/L) e−αξ dξ + eαx
2α
Z L
0
(1 −ξ/L) e−αξ dξ
(15.2.48)
=
1
α3L

e−αL cosh(αx) + α(x + L) −eαx 
.
(15.2.49)
Finally, for 0 < x < L, we have that
y(x) = 1
2α
Z x
−L
(1 −|ξ|/L) e−α(x−ξ) dξ + 1
2α
Z L
x
(1 −|ξ|/L) eα(x−ξ) dξ
(15.2.50)
= e−αx
2α
Z 0
−L
(1 + ξ/L) eαξ dξ + e−αx
2α
Z x
0
(1 −ξ/L) eαξ dξ + eαx
2α
Z L
x
(1 −ξ/L) e−αξ dξ
(15.2.51)
=
1
α3L

e−αL cosh(αx) + α(L −x) −e−αx 
.
(15.2.52)
These results can be collapsed down into
y(x) =
1
α3L
h
e−αL cosh(αx) + α(L −|x|) −e−α|x| i
(15.2.53)
if |x| < L, and
y(x) = e−α|x|
2α3L
 eαL + e−αL −2

(15.2.54)
if |x| > L.
⊓⊔

Green’s Functions
741
Superposition integral
So far we showed how the response of any system can be expressed in terms of its
Green’s function and the arbitrary forcing. Can we also determine the response using the
indicial admittance a(t)?
Consider ﬁrst a system that is dormant until a certain time t = τ1. At that instant we
subject the system to a forcing H(t −τ1). Then the response will be zero if t < τ1 and will
equal the indicial admittance a(t −τ1) when t > τ1 because the indicial admittance is the
response of a system to the step function. Here t−τ1 is the time measured from the instant
of change.
Next, suppose that we now force the system with the value f(0) when t = 0 and hold
that value until t = τ1. We then abruptly change the forcing by an amount f(τ1) −f(0)
to the value f(τ1) at the time τ1 and hold it at that value until t = τ2. Then we again
abruptly change the forcing by an amount f(τ2) −f(τ1) at the time τ2, and so forth (see
Figure 15.2.5). From the linearity of the problem the response after the instant t = τn
equals the sum
y(t) = f(0)a(t) + [f(τ1) −f(0)]a(t −τ1) + [f(τ2) −f(τ1)]a(t −τ2)
+ · · · + [f(τn) −f(τn−1)]a(t −τn).
(15.2.55)
If we write f(τk) −f(τk−1) = ∆fk and τk −τk−1 = ∆τk, Equation 15.2.55 becomes
y(t) = f(0)a(t) +
n
X
k=1
a(t −τk)∆fk
∆τk
∆τk.
(15.2.56)
Finally, proceeding to the limit as the number n of jumps becomes inﬁnite, in such a manner
that all jumps and intervals between successive jumps tend to zero, this sum has the limit
y(t) = f(0)a(t) +
Z t
0
f ′(τ)a(t −τ) dτ.
(15.2.57)
Because the total response of the system equals the weighted sum (the weights being a(t))
of the forcing from the initial moment up to the time t, we refer to Equation 15.2.57 as
the superposition integral, or Duhamel’s integral,8 named after the French mathematical
physicist Jean-Marie-Constant Duhamel (1797–1872) who ﬁrst derived it in conjunction
with heat conduction.
We can also express Equation 15.2.57 in several diﬀerent forms. Integration by parts
yields
y(t) = f(t)a(0) +
Z t
0
f(τ)a′(t −τ) dτ = d
dt
Z t
0
f(τ)a(t −τ) dτ

.
(15.2.58)
8 Duhamel, J.-M.-C., 1833: M´emoire sur la m´ethode g´en´erale relative au mouvement de la chaleur dans
les corps solides plong´es dans des milieux dont la temp´erature varie avec le temps. J. ´Ecole Polytech., 22,
20–77.

742
Advanced Engineering Mathematics with MATLAB
t
τ
τ
τ
1
2
3
∆τ
f(t)
τn
Figure 15.2.5: Diagram used in the derivation of Duhamel’s integral.
• Example 15.2.7
Suppose that a system has the step response of a(t) = A[1 −e−t/T ], where A and T
are positive constants. Let us ﬁnd the response if we force this system by f(t) = kt, where
k is a constant.
From the superposition integral, Equation 15.2.57,
y(t) = 0 +
Z t
0
kA[1 −e−(t−τ)/T ] dτ = kA[t −T(1 −e−t/T )].
(15.2.59)
⊓⊔
Boundary-value problem
One of the purposes of this book is the solution of a wide class of nonhomogeneous
ordinary diﬀerential equations of the form
d
dx

p(x)dy
dx

+ s(x)y = −f(x),
a ≤x ≤b,
(15.2.60)
with
α1y(a) + α2y′(a) = 0,
β1y(b) + β2y′(b) = 0.
(15.2.61)
For example, in Chapter 6 we examined the Sturm-Liouville-like equation
d
dx

p(x)dy
dx

+ [q(x) + λr(x)]y = −f(x),
a ≤x ≤b,
(15.2.62)
where λ is a parameter. Here we wish to develop the Green’s function for this class of
boundary-value problems.
We begin by determining the Green’s function for the equation
d
dx

p(x)dg
dx

+ s(x)g = −δ(x −ξ),
(15.2.63)
subject to yet undetermined boundary conditions. We know that such a function exists for
the special case p(x) = 1 and s(x) = 0, and we now show that this is almost always true

Green’s Functions
743
in the general case. Presently we construct Green’s functions by requiring that they satisfy
the following conditions:
• g(x|ξ) satisﬁes the homogeneous equation f(x) = 0 except at x = ξ,
• g(x|ξ) satisﬁes certain homogeneous conditions, and
• g(x|ξ) is continuous at x = ξ.
These homogeneous boundary conditions for a ﬁnite interval (a, b) will be
α1g(a|ξ) + α2g′(a|ξ) = 0,
β1g(b|ξ) + β2g′(b|ξ) = 0,
(15.2.64)
where g′ denotes the x derivative of g(x|ξ) and neither a nor b equals ξ. The coeﬃcients
α1 and α2 cannot both be zero; this also holds for β1 and β2. These conditions include the
commonly encountered Dirichlet, Neumann, and Robin boundary conditions.
What about the value of g′(x|ξ) at x = ξ? Because g(x|ξ) is a continuous function of
x, Equation 15.2.63 dictates that there must be a discontinuity in g′(x|ξ) at x = ξ. We now
show that this discontinuity consists of a jump in the value g′(x|ξ) at x = ξ. To prove this,
we begin by integrating Equation 15.2.63 from ξ −ǫ to ξ + ǫ, which yields
p(x)dg(x|ξ)
dx

ξ+ǫ
ξ−ǫ
+
Z ξ+ǫ
ξ−ǫ
s(x)g(x|ξ) dx = −1.
(15.2.65)
Because g(x|ξ) and s(x) are both continuous at x = ξ,
lim
ǫ→0
Z ξ+ǫ
ξ−ǫ
s(x)g(x|ξ) dx = 0.
(15.2.66)
Applying the limit ǫ →0 to Equation 15.2.65, we have that
p(ξ)
dg(ξ+|ξ)
dx
−dg(ξ−|ξ)
dx

= −1,
(15.2.67)
where ξ+ and ξ−denote points just above and below x = ξ, respectively. Consequently,
our last requirement on g(x|ξ) will be that
• dg/dx must have a jump discontinuity of magnitude −1/p(ξ) at x = ξ.
Similar conditions hold for higher-order ordinary diﬀerential equations.9
Consider now the region a ≤x < ξ. Let y1(x) be a nontrivial solution of the homo-
geneous diﬀerential equation satisfying the boundary condition at x = a; then α1y1(a) +
α2y′
1(a) = 0. Because g(x|ξ) must satisfy the same boundary condition, α1g(a|ξ)+α2g′(a|ξ)
= 0. Since the set α1, α2 is nontrivial, then the Wronskian of y1 and g must vanish at x = a
9 Ince, E. L., 1956: Ordinary Diﬀerential Equations. Dover Publications, Inc. See Section 11.1.

744
Advanced Engineering Mathematics with MATLAB
or y1(a)g′(a|ξ) −y′
1(a)g(a|ξ) = 0. However, for a ≤x < ξ, both y1(x) and g(x|ξ) satisfy
the same diﬀerential equation, the homogeneous one. Therefore, their Wronskian is zero
at all points and g(x|ξ) = c1y1(x) for a ≤x < ξ, where c1 is an arbitrary constant. In
a similar manner, if the nontrivial function y2(x) satisﬁes the homogeneous equation and
the boundary conditions at x = b, then g(x|ξ) = c2y2(x) for ξ < x ≤b. The continuity
condition of g and the jump discontinuity of g′ at x = ξ imply
c1y1(ξ) −c2y2(ξ) = 0,
c1y′
1(ξ) −c2y′
2(ξ) = 1/p(ξ).
(15.2.68)
We can solve Equation 15.2.68 for c1 and c2 provided the Wronskian of y1 and y2 does not
vanish at x = ξ, or
y1(ξ)y′
2(ξ) −y2(ξ)y′
1(ξ) ̸= 0.
(15.2.69)
In other words, y1(x) must not be a multiple of y2(x). Is this always true? The answer is
“generally yes.” If the homogeneous equation admits no nontrivial solutions satisfying both
boundary conditions at the same time,10 then y1(x) and y2(x) must be linearly independent.
On the other hand, if the homogeneous equation possesses a single solution, say y0(x), which
also satisﬁes α1y0(a)+ α2y′
0(a) = 0 and β1y0(b)+ β2y′
0(b) = 0, then y1(x) will be a multiple
of y0(x) and so is y2(x). Then they are multiples of each other and their Wronskian vanishes.
This would occur, for example, if the diﬀerential equation is a Sturm-Liouville equation, λ
equals the eigenvalue, and y0(x) is the corresponding eigenfunction. No Green’s function
exists in this case.
• Example 15.2.8
Consider the problem of ﬁnding the Green’s function for g′′ +k2g = −δ(x−ξ), 0 < x <
L, subject to the boundary conditions g(0|ξ) = g(L|ξ) = 0 with k ̸= 0. The corresponding
homogeneous equation is y′′ + k2y = 0. Consequently, g(x|ξ) = c1y1(x) = c1 sin(kx) for
0 ≤x ≤ξ, while g(x|ξ) = c2y2(x) = c2 sin[k(L −x)] for ξ ≤x ≤L.
Let us compute the Wronskian. For our particular problem,
W(x) = y1(x)y′
2(x) −y′
1(x)y2(x)
(15.2.70)
= −k sin(kx) cos[k(L −x)] −k cos(kx) sin[k(L −x)]
(15.2.71)
= −k sin[k(x + L −x)] = −k sin(kL),
(15.2.72)
and W(ξ) = −k sin(kL). Therefore, the Green’s function will exist as long as kL ̸= nπ. If
kL = nπ, y1(x) and y2(x) are linearly dependent with y0(x) = c3 sin(nπx/L), the solution
to the regular Sturm-Liouville problem y′′ + λy = 0, and y(0) = y(L) = 0.
⊓⊔
Let us now proceed to ﬁnd g(x|ξ) when it does exist. The system, Equation 15.2.68,
has the unique solution
c1 = −
y2(ξ)
p(ξ)W(ξ),
and
c2 = −
y1(ξ)
p(ξ)W(ξ),
(15.2.73)
where W(ξ) is the Wronskian of y1(x) and y2(x) at x = ξ. Therefore,
g(x|ξ) = −y1(x<)y2(x>)
p(ξ)W(ξ)
.
(15.2.74)
10 In the theory of diﬀerential equations, this system would be called incompatible: one that admits no
solution, save y = 0, which is also continuous for all x in the interval (a, b) and satisﬁes the homogeneous
boundary conditions.

Green’s Functions
745
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
−0.2
−0.15
−0.1
−0.05
0
0.05
0.1
0.15
0.2
 x/L
 ξ/L
 L g(x|ξ)
Figure 15.2.6: The Green’s function, Equation 15.2.75, divided by L, as functions of x and ξ when
kL = 10.
Clearly g(x|ξ) is symmetric in x and ξ. It is also unique. The proof of the uniqueness is as
follows: We can always choose a diﬀerent y1(x), but it will be a multiple of the “old” y1(x),
and the Wronskian will be multiplied by the same factor, leaving g(x|ξ) the same. This is
also true if we modify y2(x) in a similar manner.
• Example 15.2.9
Let us ﬁnd the Green’s function for g′′ + k2g = −δ(x −ξ), 0 < x < L, subject to
the boundary conditions g(0|ξ) = g(L|ξ) = 0.
As we showed in the previous example,
y1(x) = c1 sin(kx), y2(x) = c2 sin[k(L −x)], and W(ξ) = −k sin(kL). Substituting into
Equation 15.2.74, we have that
g(x|ξ) = sin(kx<) sin[k(L −x>)]
k sin(kL)
,
(15.2.75)
where x< = min(x, ξ) and x> = max(x, ξ). Figure 15.2.6 illustrates Equation 15.2.75.
⊓⊔
So far, we showed that the Green’s function for Equation 15.2.63 exists, is symmetric,
and enjoys certain properties (see the material in the boxes after Equation 15.2.63 and
Equation 15.2.67). But how does this help us solve Equation 15.2.63? We now prove that
y(x) =
Z b
a
g(x|ξ)f(ξ) dξ
(15.2.76)
is the solution to the nonhomogeneous diﬀerential equation, Equation 15.2.63, and the
homogeneous boundary conditions, Equation 15.2.64.
We begin by noting that in Equation 15.2.76 x is a parameter while ξ is the dummy
variable. As we perform the integration, we must switch from the form for g(x|ξ) for ξ ≤x
to the second form for ξ ≥x when ξ equals x; thus,
y(x) =
Z x
a
g(x|ξ)f(ξ) dξ +
Z b
x
g(x|ξ)f(ξ) dξ.
(15.2.77)

746
Advanced Engineering Mathematics with MATLAB
Diﬀerentiation yields
d
dx
Z x
a
g(x|ξ)f(ξ) dξ =
Z x
a
dg(x|ξ)
dx
f(ξ) dξ + g(x|x−)f(x),
(15.2.78)
and
d
dx
Z b
x
g(x|ξ)f(ξ) dξ =
Z b
x
dg(x|ξ)
dx
f(ξ) dξ −g(x|x+)f(x).
(15.2.79)
Because g(x|ξ) is continuous everywhere, we have that g(x|x+) = g(x|x−) so that
dy
dx =
Z x
a
dg(x|ξ)
dx
f(ξ) dξ +
Z b
x
dg(x|ξ)
dx
f(ξ) dξ.
(15.2.80)
Diﬀerentiating once more gives
d2y
dx2 =
Z x
a
d2g(x|ξ)
dx2
f(ξ) dξ + dg(x|x−)
dx
f(x) +
Z b
x
d2g(x|ξ)
dx2
f(ξ) dξ −dg(x|x+)
dx
f(x).
(15.2.81)
The second and fourth terms on the right side of Equation 15.2.81 will not cancel in this
case; on the contrary,
dg(x|x−)
dx
−dg(x|x+)
dx
= −1
p(x).
(15.2.82)
To show this, we note that the term dg(x|x−)/dx denotes a diﬀerentiation of g(x|ξ) with
respect to x using the x > ξ form and then letting ξ →x. Thus,
dg(x|x−)
dx
= −lim
ξ→x
ξ<x
y′
2(x)y1(ξ)
p(ξ)W(ξ) = −y′
2(x)y1(x)
p(x)W(x) ,
(15.2.83)
while for dg(x|x+)/dx we use the x < ξ form or
dg(x|x+)
dx
= −lim
ξ→x
ξ>x
y′
1(x)y2(ξ)
p(ξ)W(ξ) = −y′
1(x)y2(x)
p(x)W(x) .
(15.2.84)
Upon introducing these results into the diﬀerential equation
p(x)d2y
dx2 + p′(x)dy
dx + s(x)y = −f(x),
(15.2.85)
we have
Z x
a
[p(x)g′′(x|ξ) + p′(x)g′(x|ξ) + s(x)g(x|ξ)]f(ξ) dξ
(15.2.86)
+
Z b
x
[p(x)g′′(x|ξ) + p′(x)g′(x|ξ) + s(x)g(x|ξ)]f(ξ) dξ −p(x)f(x)
p(x) = −f(x).
Because
p(x)g′′(x|ξ) + p′(x)g′(x|ξ) + s(x)g(x|ξ) = 0,
(15.2.87)

Green’s Functions
747
except for x = ξ, Equation 15.2.86, and thus Equation 15.2.63, is satisﬁed.
Although
Equation 15.2.87 does not hold at the point x = ξ, the results are still valid because that
one point does not aﬀect the values of the integrals. As for the boundary conditions,
y(a) =
Z b
a
g(a|ξ)f(ξ) dξ,
y′(a) =
Z b
a
dg(a|ξ)
dx
f(ξ) dξ,
(15.2.88)
and α1y(a) + α2y′(a) = 0 from Equation 15.2.64. A similar proof holds for x = b.
Finally, let us consider the solution for the nonhomogeneous boundary conditions
α1y(a) + α2y′(a) = α, and β1y(b) + β2y′(b) = β. The solution in this case is
y(x) =
αy2(x)
α1y2(a) + α2y′
2(a) +
βy1(x)
β1y1(b) + β2y′
1(b) +
Z b
a
g(x|ξ)f(ξ) dξ.
(15.2.89)
A quick check shows that Equation 15.2.89 satisﬁes the diﬀerential equation and both
nonhomogeneous boundary conditions.
Eigenfunction expansion
We just showed how Green’s functions can be used to solve the nonhomogeneous linear
diﬀerential equation. The next question is how do you ﬁnd the Green’s function? Here we
present the most common method: series expansion. This is not surprising given its success
in solving the Sturm-Liouville problem.
Consider the nonhomogeneous problem
y′′ = −f(x),
with
y(0) = y(L) = 0.
(15.2.90)
The Green’s function g(x|ξ) must therefore satisfy
g′′ = −δ(x −ξ),
with
g(0|ξ) = g(L|ξ) = 0.
(15.2.91)
Because g(x|ξ) vanishes at the ends of the interval (0, L), this suggests that it can be
expanded in a series of suitably chosen orthogonal functions such as, for instance, the
Fourier sine series
g(x|ξ) =
∞
X
n=1
Gn(ξ) sin
nπx
L

,
(15.2.92)
where the expansion coeﬃcients Gn are dependent on the parameter ξ. Although we chose
the orthogonal set of functions sin(nπx/L), we could have used other orthogonal functions
as long as they vanish at the endpoints.
Because
g′′(x|ξ) =
∞
X
n=1

−n2π2
L2

Gn(ξ) sin
nπx
L

,
(15.2.93)

748
Advanced Engineering Mathematics with MATLAB
and
δ(x −ξ) =
∞
X
n=1
An(ξ) sin
nπx
L

,
(15.2.94)
where
An(ξ) = 2
L
Z L
0
δ(x −ξ) sin
nπx
L

dx = 2
L sin
nπξ
L

,
(15.2.95)
we have that
−
∞
X
n=1
n2π2
L2

Gn(ξ) sin
nπx
L

= −2
L
∞
X
n=1
sin
nπξ
L

sin
nπx
L

,
(15.2.96)
after substituting Equation 15.2.93 through Equation 15.2.95 into the diﬀerential equation,
Equation 15.2.91. Since Equation 15.2.96 must hold for any arbitrary x,
n2π2
L2

Gn(ξ) = 2
L sin
nπξ
L

.
(15.2.97)
Thus, the Green’s function is
g(x|ξ) = 2L
π2
∞
X
n=1
1
n2 sin
nπξ
L

sin
nπx
L

.
(15.2.98)
How might we use Equation 15.2.98? We can use this series to construct the solution
of the nonhomogeneous equation, Equation 15.2.90, via the formula
y(x) =
Z L
0
g(x|ξ) f(ξ) dξ.
(15.2.99)
This leads to
y(x) = 2L
π2
∞
X
n=1
1
n2 sin
nπx
L
 Z L
0
f(ξ) sin
nπξ
L

dξ,
(15.2.100)
or
y(x) = L2
π2
∞
X
n=1
an
n2 sin
nπx
L

,
(15.2.101)
where an are the Fourier sine coeﬃcients of f(x).
• Example 15.2.10
Consider now the more complicated boundary-value problem
y′′ + k2y = −f(x),
with
y(0) = y(L) = 0.
(15.2.102)
The Green’s function g(x|ξ) must now satisfy
g′′ + k2g = −δ(x −ξ),
and
g(0|ξ) = g(L|ξ) = 0.
(15.2.103)

Green’s Functions
749
Once again, we use the Fourier sine expansion
g(x|ξ) =
∞
X
n=1
Gn(ξ) sin
nπx
L

.
(15.2.104)
Direct substitution of Equation 15.2.104 and Equation 15.2.94 into Equation 15.2.103 and
grouping by corresponding harmonics yields
−n2π2
L2 Gn(ξ) + k2Gn(ξ) = −2
L sin
nπξ
L

,
(15.2.105)
or
Gn(ξ) = 2
L
sin(nπξ/L)
n2π2/L2 −k2 .
(15.2.106)
Thus, the Green’s function is
g(x|ξ) = 2
L
∞
X
n=1
sin(nπξ/L) sin(nπx/L)
n2π2/L2 −k2
.
(15.2.107)
Examining Equation 15.2.107 more closely, we note that it enjoys the symmetry property
that g(x|ξ) = g(ξ|x).
⊓⊔
• Example 15.2.11
Let us ﬁnd the series expansion for the Green’s function for
xg′′ + g′ +

k2x −m2
x

g = −δ(x −ξ),
0 < x < L,
(15.2.108)
where m ≥0 and is an integer. The boundary conditions are
lim
x→0 |g(x|ξ)| < ∞,
and
g(L|ξ) = 0.
(15.2.109)
To ﬁnd this series, consider the Fourier-Bessel series
g(x|ξ) =
∞
X
n=1
Gn(ξ)Jm(knmx),
(15.2.110)
where knm is the nth root of Jm(knmL) = 0. This series enjoys the advantage that it satisﬁes
the boundary conditions and we will not have to introduce any homogeneous solutions so
that g(x|ξ) satisﬁes the boundary conditions.
Substituting Equation 15.2.110 into Equation 15.2.108 after we divide by x and using
the Fourier-Bessel expansion for the delta function, we have that
(k2 −k2
nm)Gn(ξ) = −2k2
nmJm(knmξ)
L2[Jm+1(knmL)]2 = −
2Jm(knmξ)
L2[J′m(knmL)]2 ,
(15.2.111)
so that
g(x|ξ) = 2
L2
∞
X
n=1
Jm(knmξ)Jm(knmx)
(k2nm −k2)[J′m(knmL)]2 .
(15.2.112)

750
Advanced Engineering Mathematics with MATLAB
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
−2
−1
0
1
2
3
4
 x/L
 ξ/L
 L g(x|ξ)
Figure 15.2.7: The Green’s function, Equation 15.2.112, as functions of x/L and ξ/L when kL = 10 and
m = 1.
Equation 15.2.112 is plotted in Figure 15.2.7.
⊓⊔
We summarize the expansion technique as follows: Suppose that we want to solve the
diﬀerential equation
Ly(x) = −f(x),
(15.2.113)
with some condition By(x) = 0 along the boundary, where L now denotes the Sturm-
Liouville diﬀerential operator
L = d
dx

p(x) d
dx

+ [q(x) + λr(x)],
(15.2.114)
and B is the boundary condition operator
B =







α1 + α2
d
dx,
at x = a,
β1 + β2
d
dx,
at x = b.
(15.2.115)
We begin by seeking a Green’s function g(x|ξ), which satisﬁes
Lg = −δ(x −ξ),
Bg = 0.
(15.2.116)
To ﬁnd the Green’s function, we utilize the set of eigenfunctions ϕn(x) associated with the
regular Sturm-Liouville problem
d
dx

p(x)dϕn
dx

+ [q(x) + λnr(x)]ϕn = 0,
(15.2.117)

Green’s Functions
751
where ϕn(x) satisﬁes the same boundary conditions as y(x). If g exists and if the set {ϕn}
is complete, then g(x|ξ) can be represented by the series
g(x|ξ) =
∞
X
n=1
Gn(ξ)ϕn(x).
(15.2.118)
Applying L to Equation 15.2.118,
Lg(x|ξ) =
∞
X
n=1
Gn(ξ)L[ϕn(x)] =
∞
X
n=1
Gn(ξ)(λ −λn)r(x)ϕn(x) = −δ(x −ξ),
(15.2.119)
if λ does not equal any of the eigenvalues λn. Multiplying both sides of Equation 15.2.119
by ϕm(x) and integrating over x,
∞
X
n=1
Gn(ξ)(λ −λn)
Z b
a
r(x)ϕn(x)ϕm(x) dx = −ϕm(ξ).
(15.2.120)
If the eigenfunctions are orthonormal,
Z b
a
r(x)ϕn(x)ϕm(x) dx =
 1,
n = m,
0,
n ̸= m,
and
Gn(ξ) = ϕn(ξ)
λn −λ.
(15.2.121)
This leads directly to the bilinear formula:
g(x|ξ) =
∞
X
n=1
ϕn(ξ)ϕn(x)
λn −λ
,
(15.2.122)
which permits us to write the Green’s function at once if the eigenvalues and eigenfunctions
of L are known.
Problems
For the following initial-value problems, ﬁnd the transfer function, impulse response, Green’s
function, and step response. Assume that all of the necessary initial conditions are zero and
τ > 0. If you have MATLAB’s control toolbox, use MATLAB to check your work.
1. g′ + kg = δ(t −τ)
2. g′′ −2g′ −3g = δ(t −τ)
3. g′′ + 4g′ + 3g = δ(t −τ)
4. g′′ −2g′ + 5g = δ(t −τ)
5. g′′ −3g′ + 2g = δ(t −τ)
6. g′′ + 4g′ + 4g = δ(t −τ)
7. g′′ −9g = δ(t −τ)
8. g′′ + g = δ(t −τ)
9. g′′ −g′ = δ(t −τ)

752
Advanced Engineering Mathematics with MATLAB
Find the Green’s function and the corresponding bilinear expansion using eigenfunctions
from the regular Sturm-Liouville problem ϕ′′
n + k2
nϕn = 0 for
g′′ = −δ(x −ξ),
0 < x, ξ < L,
which satisfy the following boundary conditions:
10. g(0|ξ) −αg′(0|ξ) = 0, α ̸= 0, −L,
g(L|ξ) = 0,
11. g(0|ξ) −g′(0|ξ) = 0,
g(L|ξ) −g′(L|ξ) = 0,
12. g(0|ξ) −g′(0|ξ) = 0,
g(L|ξ) + g′(L|ξ) = 0.
Find the Green’s function11 and the corresponding bilinear expansion using eigenfunctions
from the regular Sturm-Liouville problem ϕ′′
n + k2
nϕn = 0 for
g′′ −k2g = −δ(x −ξ),
0 < x, ξ < L,
which satisfy the following boundary conditions:
13. g(0|ξ) = 0,
g(L|ξ) = 0,
14. g′(0|ξ) = 0,
g′(L|ξ) = 0,
15. g(0|ξ) = 0,
g(L|ξ) + g′(L|ξ) = 0,
16. g(0|ξ) = 0,
g(L|ξ) −g′(L|ξ) = 0,
17. a g(0|ξ) + g′(0|ξ) = 0,
g′(L|ξ) = 0,
18. g(0|ξ) + g′(0|ξ) = 0,
g(L|ξ) −g′(L|ξ) = 0.
15.3 JOINT TRANSFORM METHOD
In the previous section an important method for ﬁnding Green’s function involved either
Laplace or Fourier transforms. In the following sections we wish to ﬁnd Green’s functions
for partial diﬀerential equations. Again transform methods play an important role. We will
always use the Laplace transform to eliminate the temporal dependence. However, for the
spatial dimension we will use either a Fourier series or Fourier transform. Our choice will
be dictated by the domain: If it reaches to inﬁnity, then we will employ Fourier transforms.
On the other hand, a domain of ﬁnite length calls for an eigenfunction expansion. The
following two examples illustrate our solution technique for domains of inﬁnite and ﬁnite
extent.
11 Problem 18 was used by Chakrabarti, A., and T. Sahoo, 1996: Reﬂection of water waves by a nearly
vertical porous wall. J. Austral. Math. Soc., Ser. B, 37, 417–429.

Green’s Functions
753
• Example 15.3.1: One-dimensional Klein-Gordon equation
The Klein-Gordon equation is a form of the wave equation that arose in particle physics
as the relativistic scalar wave equation describing particles with nonzero rest mass. In this
example, we ﬁnd its Green’s function when there is only one spatial dimension:
∂2g
∂x2 −1
c2
∂2g
∂t2 + a2g

= −δ(x −ξ)δ(t −τ),
(15.3.1)
where −∞< x, ξ < ∞, 0 < t, τ, c is a real, positive constant (the wave speed), and a is a
real, nonnegative constant. The corresponding boundary conditions are
lim
|x|→∞g(x, t|ξ, τ) →0,
(15.3.2)
and the initial conditions are
g(x, 0|ξ, τ) = gt(x, 0|ξ, τ) = 0.
(15.3.3)
We begin by taking the Laplace transform of Equation 15.3.1 and ﬁnd that
d2G
dx2 −
s2 + a2
c2

G = −δ(x −ξ)e−sτ.
(15.3.4)
Applying Fourier transforms to Equation 15.3.4, we obtain
G(x, s|ξ, τ) = c2
2π e−sτ
Z ∞
−∞
eik(x−ξ)
s2 + a2 + k2c2 dk = c2
π e−sτ
Z ∞
0
cos[k(x −ξ)]
s2 + a2 + k2c2 dk.
(15.3.5)
Inverting the Laplace transform and employing the second shifting theorem,
g(x, t|ξ, τ) = c2
π H(t −τ)
Z ∞
0
sin

(t −τ)
√
a2 + k2c2 
cos[k(x −ξ)]
√
a2 + k2c2
dk.
(15.3.6)
Equation 15.3.6 represents a superposition of homogeneous solutions (normal modes) to
Equation 15.3.1. An intriguing aspect of Equation 15.3.6 is that this solution occurs every-
where after t > τ. If |x −ξ| > c(t −τ), these wave solutions destructively interfere so that
we have zero there while they constructively interfere at those times and places where the
physical waves are present.
Applying integral tables to Equation 15.3.6, the ﬁnal result is
g(x, t|ξ, τ) = c
2J0
h
a
p
(t −τ)2 −(x −ξ)2/c2
i
H[c(t −τ) −|x −ξ|].
(15.3.7)
This Green’s function is illustrated in Figure 15.3.1. Thus, the Green’s function for the
Klein-Gordon equation yields waves that propagate to the right and left from x = 0 with
the wave front located at x = ±ct. At a given point, after the passage of the wave front,

754
Advanced Engineering Mathematics with MATLAB
−10
−5
0
5
10
0
2
4
6
8
10
−0.4
−0.2
0
0.2
0.4
0.6
 a(x−ξ)/c
 a(t−τ)
 g(x,t|ξ,τ)/c
Figure 15.3.1: The free-space Green’s function g(x, t|ξ, τ)/c for the one-dimensional Klein-Gordon equa-
tion at diﬀerent distances a(x −ξ)/c and times a(t −τ).
the solution vibrates with an ever-decreasing amplitude and at a frequency that approaches
a - the so-called cutoﬀfrequency - at t →∞.
Why is a called a cutoﬀfrequency? From Equation 15.3.5, we see that, although the
spectral representation includes all of the wavenumbers k running from −∞to ∞, the
frequency ω =
√
c2k2 + a2 is restricted to the range ω ≥a from Equation 15.3.6. Thus, a is
the lowest possible frequency that a wave solution to the Klein-Gordon equation may have
for a real value of k.
⊓⊔
• Example 15.3.2: One-dimensional wave equation on the interval 0 < x < L
One of the classic problems of mathematical physics involves ﬁnding the displacement
of a taut string between two supports when an external force is applied. The governing
equation is
∂2u
∂t2 −c2 ∂2u
∂x2 = f(x, t),
0 < x < L,
0 < t,
(15.3.8)
where c is the constant phase speed.
In this example, we ﬁnd the Green’s function for this problem by considering the
following problem:
∂2g
∂t2 −c2 ∂2g
∂x2 = δ(x −ξ)δ(t −τ),
0 < x, ξ < L,
0 < t, τ,
(15.3.9)
with the boundary conditions
α1g(0, t|ξ, τ) + β1gx(0, t|ξ, τ) = 0,
0 < t,
(15.3.10)
and
α2g(L, t|ξ, τ) + β2gx(L, t|ξ, τ) = 0,
0 < t,
(15.3.11)
and the initial conditions
g(x, 0|ξ, τ) = gt(x, 0|ξ, τ) = 0,
0 < x < L.
(15.3.12)

Green’s Functions
755
We start by taking the Laplace transform of Equation 15.3.9 and ﬁnd that
d2G
dx2 −s2
c2 G = −δ(x −ξ)
c2
e−sτ,
0 < x < L,
(15.3.13)
with
α1G(0, s|ξ, τ) + β1G′(0, s|ξ, τ) = 0,
(15.3.14)
and
α2G(L, s|ξ, τ) + β2G′(L, s|ξ, τ) = 0.
(15.3.15)
Problems similar to Equation 15.3.13 through Equation 15.3.15 were considered in the
previous section. There, solutions were developed in terms of an eigenfunction expansion.
Applying the same technique here,
G(x, s|ξ, τ) = e−sτ
∞
X
n=1
ϕn(ξ)ϕn(x)
s2 + c2k2n
,
(15.3.16)
where ϕn(x) is the nth orthonormal eigenfunction to the regular Sturm-Liouville problem
ϕ
′′(x) + k2ϕ(x) = 0,
0 < x < L,
(15.3.17)
subject to the boundary conditions
α1ϕ(0) + β1ϕ′(0) = 0,
(15.3.18)
and
α2ϕ(L) + β2ϕ′(L) = 0.
(15.3.19)
Taking the inverse of Equation 15.3.16, we have that the Green’s function is
g(x, t|ξ, τ) =
( ∞
X
n=1
ϕn(ξ)ϕn(x)sin[knc(t −τ)]
knc
)
H(t −τ).
(15.3.20)
Let us illustrate our results to ﬁnd the Green’s function for
∂2g
∂t2 −c2 ∂2g
∂x2 = δ(x −ξ)δ(t −τ),
(15.3.21)
with the boundary conditions
g(0, t|ξ, τ) = g(L, t|ξ, τ) = 0,
0 < t,
(15.3.22)
and the initial conditions
g(x, 0|ξ, τ) = gt(x, 0|ξ, τ) = 0,
0 < x < L.
(15.3.23)

756
Advanced Engineering Mathematics with MATLAB
0
0.2
0.4
0.6
0.8
1
0
0.5
1
1.5
2
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
 x/L
 c(t−τ)/L
 c g(x,t|ξ,τ)
Figure 15.3.2: The Green’s function cg(x, t|ξ, τ) given by Equation 15.3.26 for the one-dimensional wave
equation over the interval 0 < x < L as a function of location x/L and time c(t −τ)/L with ξ/L = 0.2.
The boundary conditions are g(0, t|ξ, τ) = g(L, t|ξ, τ) = 0.
For this example, the Sturm-Liouville problem is
ϕ′′(x) + k2ϕ(x) = 0,
0 < x < L,
(15.3.24)
with the boundary conditions ϕ(0) = ϕ(L) = 0. The nth orthonormal eigenfunction for
this problem is
ϕn(x) =
r
2
L sin
nπx
L

.
(15.3.25)
Consequently, from Equation 15.3.20, the Green’s function is
g(x, t|ξ, τ) = 2
πc
( ∞
X
n=1
1
n sin
nπξ
L

sin
nπx
L

sin
nπc(t −τ)
L
)
H(t −τ).
(15.3.26)
See Figure 15.3.2.
15.4 WAVE EQUATION
In Section 15.2, we showed how Green’s functions could be used to solve initial- and
boundary-value problems involving ordinary diﬀerential equations. When we approach par-
tial diﬀerential equations, similar considerations hold, although the complexity increases.
In the next three sections, we work through the classic groupings of the wave, heat, and
Helmholtz’s equations in one spatial dimension. All of these results can be generalized to
three dimensions.
Of these three groups, we start with the wave equation
∂2u
∂x2 −1
c2
∂2u
∂t2 = −q(x, t),
(15.4.1)

Green’s Functions
757
where t denotes time, x is the position, c is the phase velocity of the wave, and q(x, t) is
the source density. In addition to Equation 15.4.1 it is necessary to state boundary and
initial conditions to obtain a unique solution. The condition on the boundary can be either
Dirichlet or Neumann or a linear combination of both (Robin condition). The conditions in
time must be Cauchy - that is, we must specify the value of u(x, t) and its time derivative
at t = t0 for each point of the region under consideration.
We begin by proving that we can express the solution to Equation 15.4.1 in terms of
boundary conditions, initial conditions, and the Green’s function, which is found by solving
∂2g
∂x2 −1
c2
∂2g
∂t2 = −δ(x −ξ)δ(t −τ),
(15.4.2)
where ξ denotes the position of a source that is excited at t = τ. Equation 15.4.2 expresses
the eﬀect of an impulse as it propagates from x = ξ as time increases from t = τ. For
t < τ, causality requires that g(x, t|ξ, τ) = gt(x, t|ξ, τ) = 0 if the impulse is the sole source
of the disturbance. We also require that g satisﬁes the homogeneous form of the boundary
condition satisﬁed by u.
Our derivation starts with the equations
∂2u(ξ, τ)
∂ξ2
−1
c2
∂2u(ξ, τ)
∂τ 2
= −q(ξ, τ),
(15.4.3)
and
∂2g(x, t|ξ, τ)
∂ξ2
−1
c2
∂2g(x, t|ξ, τ)
∂τ 2
= −δ(x −ξ)δ(t −τ),
(15.4.4)
where we obtain Equation 15.4.4 from a combination of Equation 15.4.2 plus reciprocity,
namely g(x, t|ξ, τ) = g(ξ, −τ|x, −t). Next we multiply Equation 15.4.3 by g(x, t|ξ, τ) and
Equation 15.4.4 by u(ξ, τ) and subtract. Integrating over ξ from a to b, where a and b are
the endpoints of the spatial domain, and over τ from 0 to t+, where t+ denotes a time
slightly later than t so that we avoid ending the integration exactly at the peak of the delta
function, we obtain
Z t+
0
Z b
a

g(x, t|ξ, τ)∂2u(ξ, τ)
∂ξ2
−u(ξ, τ)∂2g(x, t|ξ, τ)
∂ξ2
+ 1
c2

u(ξ, τ)∂2g(x, t|ξ, τ)
∂τ 2
−g(x, t|ξ, τ)∂2u(ξ, τ)
∂τ 2

dξ dτ
= u(x, t) −
Z t+
0
Z b
a
q(ξ, τ) g(x, t|ξ, τ) dξ dτ.
(15.4.5)
Because
g(x, t|ξ, τ)∂2u(ξ, τ)
∂ξ2
−u(ξ, τ)∂2g(x, t|ξ, τ)
∂ξ2
= ∂
∂ξ

g(x, t|ξ, τ)∂u(ξ, τ)
∂ξ

−∂
∂ξ

u(ξ, τ)∂g(x, t|ξ, τ)
∂ξ

,
(15.4.6)
and
g(x, t|ξ, τ)∂2u(ξ, τ)
∂τ 2
−u(ξ, τ)∂2g(x, t|ξ, τ)
∂τ 2
= ∂
∂τ

g(x, t|ξ, τ)∂u(ξ, τ)
∂τ

−∂
∂τ

u(ξ, τ)∂g(x, t|ξ, τ)
∂τ

,
(15.4.7)

758
Advanced Engineering Mathematics with MATLAB
we ﬁnd that
Z t+
0

g(x, t|ξ, τ)∂u(ξ, τ)
∂ξ
−u(ξ, τ)∂g(x, t|ξ, τ)
∂ξ
ξ=b
ξ=a
dτ
+ 1
c2
Z b
a

u(ξ, τ)∂g(x, t|ξ, τ)
∂τ
−g(x, t|ξ, τ)∂u(ξ, τ)
∂τ
τ=t+
τ=0
dξ
+
Z t+
0
Z b
a
q(ξ, τ) g(x, t|ξ, τ) dξ dτ = u(x, t).
(15.4.8)
The integrand in the ﬁrst integral is speciﬁed by the boundary conditions. In the second
integral, the integrand vanishes at t = t+ from the initial conditions on g(x, t|ξ, τ). The
limit at t = 0 is determined by the initial conditions. Hence,
u(x, t) =
Z t+
0
Z b
a
q(ξ, τ)g(x, t|ξ, τ) dξ dτ
+
Z t+
0

g(x, t|ξ, τ)∂u(ξ, τ)
∂ξ
−u(ξ, τ)∂g(x, t|ξ, τ)
∂ξ
ξ=b
ξ=a
dτ
−1
c2
Z b
a

u(ξ, 0)∂g(x, t|ξ, 0)
∂τ
−g(x, t|ξ, 0)∂u(ξ, 0)
∂τ

dξ.
(15.4.9)
Equation 15.4.9 gives the complete solution of the nonhomogeneous problem.
The ﬁrst
two integrals on the right side of this equation represent the eﬀect of the source and the
boundary conditions, respectively. The last term involves the initial conditions; it can be
interpreted as asking what sort of source is needed so that the function u(x, t) starts in the
desired manner.
• Example 15.4.1
Let us apply the Green’s function technique to solve
∂2u
∂t2 = ∂2u
∂x2 ,
0 < x < 1,
0 < t,
(15.4.10)
subject to the boundary conditions u(0, t) = 0 and u(1, t) = t, 0 < t, and the initial
conditions u(x, 0) = x and ut(x, 0) = 0, 0 < x < 1.
Because there is no source term and c = 1, Equation 15.4.9 becomes
u(x, t) =
Z t
0
[g(x, t|1, τ)uξ(1, τ) −u(1, τ)gξ(x, t|1, τ)] dτ
−
Z t
0
[g(x, t|0, τ)uξ(0, τ) −u(0, τ)gξ(x, t|0, τ)] dτ
−
Z 1
0
[u(ξ, 0)gτ(x, t|ξ, 0) −g(x, t|ξ, 0)uξ(ξ, 0)] dξ.
(15.4.11)
Therefore we must ﬁrst compute the Green’s function for this problem. However, we have
already done this in Example 15.3.2 and it is given by Equation 15.3.26 with c = L = 1.

Green’s Functions
759
Next, we note that g(x, t|1, τ) = g(x, t|0, τ) = 0 and u(0, τ) = uτ(ξ, 0) = 0. Consequently,
Equation 15.4.11 reduces to only two nonvanishing integrals:
u(x, t) = −
Z t
0
u(1, τ)gξ(x, t|1, τ) dτ −
Z 1
0
u(ξ, 0)gτ(x, t|ξ, 0) dξ.
(15.4.12)
If we now substitute for g(x, t|ξ, τ) and reverse the order of integration and summation,
Z t
0
u(1, τ)gξ(x, t|1, τ) dτ = 2
∞
X
n=1
(−1)n sin(nπx)
Z t
0
τ sin[nπ(t −τ)] dτ
(15.4.13)
= 2t
∞
X
n=1
(−1)n sin(nπx)
Z t
0
sin[nπ(t −τ)] d(t −τ)
−2
∞
X
n=1
(−1)n sin(nπx)
Z t
0
(t −τ) sin[nπ(t −τ)] d(t −τ)
(15.4.14)
= −2t
∞
X
n=1
(−1)n sin(nπx) cos[nπ(t −τ)]
nπ

t
0
(15.4.15)
−2
∞
X
n=1
(−1)n sin(nπx)
sin[nπ(t −τ)]
n2π2
−(t −τ)cos[nπ(t −τ)]
nπ

t
0
= −2t
π
∞
X
n=1
(−1)n
n
sin(nπx) + 2
π2
∞
X
n=1
(−1)n
n2
sin(nπx) sin(nπt),
(15.4.16)
and
Z 1
0
u(ξ, 0)gτ(x, t|ξ, 0) dξ = −2
∞
X
n=1
sin(nπx) cos(nπt)
Z 1
0
ξ sin(nπξ) dξ
(15.4.17)
= −2
∞
X
n=1
sin(nπx) cos(nπt)
sin(nπξ)
n2π2
−ξ cos(nπξ)
nπ

1
0
(15.4.18)
= 2
π
∞
X
n=1
(−1)n
n
sin(nπx) cos(nπt).
(15.4.19)
Substituting Equation 15.4.16 and Equation 15.4.19 into Equation 15.4.12, we ﬁnally obtain
u(x, t) = −2t
π
∞
X
n=1
(−1)n
n
sin(nπx) −2
π
∞
X
n=1
(−1)n
n
sin(nπx) cos(nπt)
+ 2
π2
∞
X
n=1
(−1)n
n2
sin(nπx) sin(nπt).
(15.4.20)
The ﬁrst summation in Equation 15.4.20 is the Fourier sine expansion for f(x) = x over the
interval 0 < x < 1. Indeed, a quick check shows that the particular solution up(x, t) = xt
satisﬁes the partial diﬀerential equation and boundary conditions.
The remaining two
summations are necessary so that u(x, 0) = x and ut(x, 0) = 0.
⊓⊔
To apply Equation 15.4.9 to other problems, we must now ﬁnd the Green’s function
for a speciﬁc domain. In the following examples we illustrate how this is done using the

760
Advanced Engineering Mathematics with MATLAB
joint transform method introduced in the previous section. Note that both examples given
there were for the wave equation.
• Example 15.4.2: One-dimensional wave equation in an unlimited domain
The simplest possible example of Green’s functions for the wave equation is the one-
dimensional vibrating string problem.12 In this problem the Green’s function is given by
the equation
∂2g
∂t2 −c2 ∂2g
∂x2 = c2δ(x −ξ)δ(t −τ),
(15.4.21)
where −∞< x, ξ < ∞, and 0 < t, τ.
If the initial conditions equal zero, the Laplace
transform of Equation 15.4.21 is
d2G
dx2 −s2
c2 G = −δ(x −ξ)e−sτ,
(15.4.22)
where G(x, s|ξ, τ) is the Laplace transform of g(x, t|ξ, τ). To solve Equation 15.4.22 we take
its Fourier transform and obtain the algebraic equation
G(k, s|ξ, τ) = exp(−ikξ −sτ)
k2 + s2/c2
.
(15.4.23)
Having found the joint Laplace-Fourier transform of g(x, t|ξ, τ), we must work our way
back to the Green’s function. From the deﬁnition of the Fourier transform, we have that
G(x, s|ξ, τ) = e−sτ
2π
Z ∞
−∞
eik(x−ξ)
k2 + s2/c2 dk.
(15.4.24)
To evaluate the Fourier-type integral, Equation 15.4.24, we apply the residue theorem. See
Section 11.4. Performing the calculation,
G(x, s|ξ, τ) = c exp(−sτ −s|x −ξ|/c)
2s
.
(15.4.25)
Finally, taking the inverse Laplace transform of Equation 15.4.25,
g(x, t|ξ, τ) = c
2H (t −τ −|x −ξ|/c) ,
(15.4.26)
or
g(x, t|ξ, τ) = c
2H [c(t −τ) + (x −ξ)] H [c(t −τ) −(x −ξ)] .
(15.4.27)
We can use Equation 15.4.26 and the method of images to obtain the Green’s function
for
∂2g
∂x2 −1
c2
∂2g
∂t2 = δ(x −ξ)δ(t −τ),
0 < x, t, ξ, τ,
(15.4.28)
12 See also Graﬀ, K. F., 1991: Wave Motion in Elastic Solids. Dover Publications, Inc., Section 1.1.8.

Green’s Functions
761
0
2
4
6
8
10
0
2
4
6
8
10
0
0.1
0.2
0.3
0.4
0.5
 x/ξ
 c(t−τ)/ξ
 g(x,t|ξ,τ)/c
Figure 15.4.1:
The Green’s function g(x, t|ξ, τ)/c given by Equation 15.4.30 for the one-dimensional
wave equation for x > 0 at diﬀerent distances x/ξ and times c(t −τ) subject to the boundary condition
g(0, t|ξ, τ) = 0.
subject to the boundary condition g(0, t|ξ, τ) = 0.
We begin by noting that the free-space Green’s function,13 Equation 15.4.26, is the par-
ticular solution to Equation 15.4.28. Therefore, we need only ﬁnd a homogeneous solution
f(x, t|ξ, τ) so that
g(x, t|ξ, τ) = c
2H (t −τ −|x −ξ|/c) + f(x, t|ξ, τ)
(15.4.29)
satisﬁes the boundary condition at x = 0.
To ﬁnd f(x, t|ξ, τ), let us introduce a source at x = −ξ at t = τ. The corresponding
free-space Green’s function is H(t −τ −|x + ξ|/c). If, along the boundary x = 0 for any
time t, this Green’s function destructively interferes with the free-space Green’s function
associated with the source at x = ξ, then we have our solution. This will occur if our new
source has a negative sign, resulting in the combined Green’s function
g(x, t|ξ, τ) = c
2 [H(t −τ −|x −ξ|/c) −H(t −τ −|x + ξ|/c)] .
(15.4.30)
See Figure 15.4.1. Because Equation 15.4.30 satisﬁes the boundary condition, we need no
further sources.
In a similar manner, we can use Equation 15.4.26 and the method of images to ﬁnd
the Green’s function for
∂2g
∂x2 −1
c2
∂2g
∂t2 = δ(x −ξ)δ(t −τ),
0 < x, t, ξ, τ,
(15.4.31)
subject to the boundary condition gx(0, t|ξ, τ) = 0.
13 In electromagnetic theory, a free-space Green’s function is the particular solution of the diﬀerential
equation valid over a domain of inﬁnite extent, where the Green’s function remains bounded as we approach
inﬁnity, or satisﬁes a radiation condition there.

762
Advanced Engineering Mathematics with MATLAB
We begin by examining the related problem
∂2g
∂x2 −1
c2
∂2g
∂t2 = δ(x −ξ)δ(t −τ) + δ(x + ξ)δ(t −τ),
(15.4.32)
where −∞< x, ξ < ∞, and 0 < t, τ. In this particular case, we have chosen an image that
is the mirror reﬂection of δ(x −ξ). This was dictated by the fact that the Green’s function
must be an even function of x along x = 0 for any time t. In line with this argument,
g(x, t|ξ, τ) = c
2 [H (t −τ −|x −ξ|/c) + H (t −τ −|x + ξ|/c)] .
(15.4.33)
⊓⊔
• Example 15.4.3: Equation of telegraphy
When the vibrating string problem includes the eﬀect of air resistance, Equation 15.4.21
becomes
∂2g
∂t2 + 2γ ∂g
∂t −c2 ∂2g
∂x2 = c2δ(x −ξ)δ(t −τ),
(15.4.34)
where −∞< x, ξ < ∞, and 0 < t, τ, with the boundary conditions
lim
|x|→∞g(x, t|ξ, τ) →0
(15.4.35)
and the initial conditions
g(x, 0|ξ, τ) = gt(x, 0|ξ, τ) = 0.
(15.4.36)
Let us ﬁnd the Green’s function.
Our analysis begins by introducing an intermediate dependent variable w(x, t|ξ, τ),
where g(x, t|ξ, τ) = e−γtw(x, t|ξ, τ). Substituting for g(x, t|ξ, τ), we now have
∂2w
∂t2 −γ2w −c2 ∂2w
∂x2 = c2δ(x −ξ)δ(t −τ)eγτ.
(15.4.37)
Taking the Laplace transform of Equation 15.4.37, we obtain
d2W
dx2 −
s2 −γ2
c2

W = −δ(x −ξ)eγτ−sτ.
(15.4.38)
Using Fourier transforms as in Example 15.3.1, the solution to Equation 15.4.38 is
W(x, s|ξ, τ) = exp[−|x −ξ|
p
(s2 −γ2)/c2 + γτ −sτ]
2
p
(s2 −γ2)/c2
.
(15.4.39)
Employing tables to invert the Laplace transform and the second shifting theorem, we have
that
w(x, t|ξ, τ) = c
2eγτI0
h
γ
p
(t −τ)2 −(x −ξ)2/c2
i
H[c(t −τ) −|x −ξ|],
(15.4.40)
or
g(x, t|ξ, τ) = c
2e−γ(t−τ)I0
h
γ
p
(t −τ)2 −(x −ξ)2/c2
i
H[c(t −τ) −|x −ξ|].
(15.4.41)

Green’s Functions
763
−10
−5
0
5
10
0
2
4
6
8
10
0
0.1
0.2
0.3
0.4
0.5
0.6
 (x−ξ)/c
 t−τ
 g(x,t|ξ,τ)/c
Figure 15.4.2: The free-space Green’s function g(x, t|ξ, τ)/c for the one-dimensional equation of telegraphy
with γ = 1 at diﬀerent distances (x −ξ)/c and times t −τ.
Figure 15.4.2 illustrates Equation 15.4.41 when γ = 1.
⊓⊔
• Example 15.4.4
Let us solve14 the one-dimensional wave equation on an inﬁnite domain:
∂2u
∂t2 −∂2u
∂x2 = cos(ωt)δ[x −X(t)],
(15.4.42)
subject to the boundary conditions
lim
|x|→∞u(x, t) →0,
0 < t,
(15.4.43)
and initial conditions
u(x, 0) = ut(x, 0) = 0,
−∞< x < ∞.
(15.4.44)
Here ω is a constant and X(t) is some function of time.
With the given boundary and initial conditions, only the ﬁrst integral in Equation
15.4.9 does not vanish. Substituting the source term q(x, t) = cos(ωt)δ[x −X(t)] and the
Green’s function given by Equation 15.4.26, we have that
u(x, t) =
Z t
0
Z ∞
−∞
q(ξ, τ)g(x, t|ξ, τ) dξ dτ
(15.4.45)
= 1
2
Z t
0
Z ∞
−∞
cos(ωτ)δ[ξ −X(τ)]H(t −τ) −|x −ξ|) dξ dτ
(15.4.46)
= 1
2
Z t
0
H[t −τ −|X(τ) −x|] cos(ωτ) dτ,
(15.4.47)
14 See Knowles, J. K., 1968: Propagation of one-dimensional waves from a source in random motion. J.
Acoust. Soc. Am., 43, 948–957.

764
Advanced Engineering Mathematics with MATLAB
since c = 1.
Problems
1. By direct substitution, show15 that
g(x, t|0, 0) = J0(
√
xt )H(x)H(t)
is the free-space Green’s function governed by
∂2g
∂x∂t + 1
4g = δ(x)δ(t),
−∞< x, t < ∞.
2. Use Equation 15.3.20 to construct the Green’s function for the one-dimensional wave
equation
∂2g
∂t2 −∂2g
∂x2 = δ(x −ξ)δ(t −τ),
0 < x, ξ < L,
0 < t, τ,
subject to the boundary conditions g(0, t|ξ, τ) = gx(L, t|ξ, τ) = 0, 0 < t, and the initial
conditions that g(x, 0|ξ, τ) = gt(x, 0|ξ, τ) = 0, 0 < x < L.
3. Use Equation 15.3.20 to construct the Green’s function for the one-dimensional wave
equation
∂2g
∂t2 −∂2g
∂x2 = δ(x −ξ)δ(t −τ),
0 < x, ξ < L,
0 < t, τ,
subject to the boundary conditions gx(0, t|ξ, τ) = gx(L, t|ξ, τ) = 0, 0 < t, and the initial
conditions that g(x, 0|ξ, τ) = gt(x, 0|ξ, τ) = 0, 0 < x < L.
4.
Use the Green’s function given by Equation 15.3.26 to write down the solution to
the wave equation utt = uxx on the interval 0 < x < L with the boundary conditions
u(0, t) = u(L, t) = 0, 0 < t, and the initial conditions u(x, 0) = cos(πx/L) and ut(x, 0) = 0,
0 < x < L.
5. Use the Green’s function given by Equation 15.3.26 to write down the solution to the wave
equation utt = uxx on the interval 0 < x < L with the boundary conditions u(0, t) = e−t
and u(L, t) = 0, 0 < t, and the initial conditions u(x, 0) = sin(πx/L) and ut(x, 0) = 1,
0 < x < L.
6. Use the Green’s function that you found in Problem 2 to write down the solution to the
wave equation utt = uxx on the interval 0 < x < L with the boundary conditions u(0, t) = 0
and ux(L, t) = 1, 0 < t, and the initial conditions u(x, 0) = x and ut(x, 0) = 1, 0 < x < L.
7. Use the Green’s function that you found in Problem 3 to write down the solution to
the wave equation utt = uxx on the interval 0 < x < L with the boundary conditions
ux(0, t) = 1 and ux(L, t) = 0, 0 < t, and the initial conditions u(x, 0) = 1 and ut(x, 0) = 0,
0 < x < L.
15 First proven by Picard, ´E., 1894: Sur une ´equation aux d´eriv´ees partielles de la th´eorie de la propa-
gation de l’´electricit´e. Bull. Soc. Math., 22, 2–8.

Green’s Functions
765
8. Find the Green’s function16 governed by
∂2g
∂t2 + 2∂g
∂t −∂2g
∂x2 = δ(x −ξ)δ(t −τ),
0 < x, ξ < L,
0 < t, τ,
subject to the boundary conditions
gx(0, t|ξ, τ) = gx(L, t|ξ, τ) = 0,
0 < t,
and the initial conditions
g(x, 0|ξ, τ) = gt(x, 0|ξ, τ) = 0,
0 < x < L.
Step 1: If the Green’s function can be written as the Fourier half-range cosine series
g(x, t|ξ, τ) = 1
LG0(t|τ) + 2
L
∞
X
n=1
Gn(t|τ) cos
nπx
L

,
so that it satisﬁes the boundary conditions, show that Gn(t|τ) is governed by
G′′
n + 2G′
n + n2π2
L2 Gn = cos
nπξ
L

δ(t −τ),
0 ≤n.
Step 2: Show that
G0(t|τ) = e−(t−τ) sinh(t −τ)H(t −τ),
and
Gn(t|τ) = cos
nπξ
L

e−(t−τ) sin[βn(t −τ)]
βn
H(t −τ),
1 ≤n,
where βn =
p
(nπ/L)2 −1.
Step 3: Combine the results from Steps 1 and 2 and show that
g(x, t|ξ, τ) = e−(t−τ) sinh(t −τ)H(t −τ)/L
+ 2e−(t−τ)H(t −τ)/L
×
∞
X
n=1
sin[βn(t −τ)]
βn
cos
nπξ
L

cos
nπx
L

.
16 ¨Ozi¸sik, M. N., and B. Vick, 1984: Propagation and reﬂection of thermal waves in a ﬁnite medium.
Int.
J. Heat Mass Transfer, 27, 1845–1854; Tang, D.-W., and N. Araki, 1996:
Propagation of non-
Fourier temperature wave in ﬁnite medium under laser-pulse heating (in Japanese). Nihon Kikai Gakkai
Rombumshu (Trans. Japan Soc. Mech. Engrs.), Ser. B, 62, 1136–1141.

766
Advanced Engineering Mathematics with MATLAB
15.5 HEAT EQUATION
In this section we present the Green’s function17 for the heat equation
∂u
∂t −a2 ∂2u
∂x2 = q(x, t),
(15.5.1)
where t denotes time, x is the position, a2 is the diﬀusivity, and q(x, t) is the source den-
sity. In addition to Equation 15.5.1, boundary conditions must be speciﬁed to ensure the
uniqueness of solution; the most common ones are Dirichlet, Neumann, and Robin (a linear
combination of the ﬁrst two). An initial condition u(x, t = t0) is also needed.
The heat equation diﬀers in many ways from the wave equation and the Green’s function
must, of course, manifest these diﬀerences. The most notable one is the asymmetry of the
heat equation with respect to time. This merely reﬂects the fact that the heat equation
diﬀerentiates between past and future as entropy continually increases.
We begin by proving that we can express the solution to Equation 15.5.1 in terms
of boundary conditions, the initial condition, and the Green’s function, which is found by
solving
∂g
∂t −a2 ∂2g
∂x2 = δ(x −ξ)δ(t −τ),
(15.5.2)
where ξ denotes the position of the source. From causality18 we know that g(x, t|ξ, τ) = 0
if t < τ. We again require that the Green’s function g(x, t|ξ, τ) satisﬁes the homogeneous
form of the boundary condition on u(x, t). For example, if u satisﬁes a homogeneous or
nonhomogeneous Dirichlet condition, then the Green’s function will satisfy the correspond-
ing homogeneous Dirichlet condition. Although we will focus on the mathematical aspects
of the problem, Equation 15.5.2 can be given the physical interpretation of the temperature
distribution within a medium when a unit of heat is introduced at ξ at time τ.
We now establish that the solution to the nonhomogeneous heat equation can be ex-
pressed in terms of the Green’s function, boundary conditions, and the initial condition.
We begin with the equations
a2 ∂2u(ξ, τ)
∂ξ2
−∂u(ξ, τ)
∂τ
= −q(ξ, τ),
(15.5.3)
and
a2 ∂2g(x, t|ξ, τ)
∂ξ2
+ ∂g(x, t|ξ, τ)
∂τ
= −δ(x −ξ)δ(t −τ).
(15.5.4)
As we did in the previous section, we multiply Equation 15.5.3 by g(x, t|ξ, τ) and Equation
15.5.4 by u(ξ, τ) and subtract.
Integrating over ξ from a to b, where a and b are the
endpoints of the spatial domain, and over τ from 0 to t+, where t+ denotes a time slightly
later than t so that we avoid ending the integration exactly at the peak of the delta function,
we ﬁnd
a2
Z t+
0
Z b
a

u(ξ, τ)∂2g(x, t|ξ, τ)
∂ξ2
−g(x, t|ξ, τ)∂2u(ξ, τ)
∂ξ2

dξ dτ
17 See also Carslaw, H. S., and J. C. Jaeger, 1959: Conduction of Heat in Solids.
Clarendon Press,
Chapter 14; Beck, J. V., K. D. Cole, A. Haji-Sheikh, and B. Litkouhi, 1992: Heat Conduction Using
Green’s Functions. Hemisphere Publishing Corp., 523 pp.; ¨Ozi¸sik, M. N., 1993: Heat Conduction. John
Wiley & Sons, Inc., Chapter 6.
18 The principle stating that an event cannot precede its cause.

Green’s Functions
767
+
Z t+
0
Z b
a

u(ξ, τ)∂g(x, t|ξ, τ)
∂τ
+ g(x, t|ξ, τ)∂u(ξ, τ)
∂τ

dξ dτ
=
Z t+
0
Z b
a
q(ξ, τ)g(x, t|ξ, τ) dξ dτ −u(x, t).
(15.5.5)
Applying Equation 15.4.6 and performing the time integration in the second integral, we
ﬁnally obtain
u(x, t) =
Z t+
0
Z b
a
q(ξ, τ)g(x, t|ξ, τ) dξ dτ
+ a2
Z t+
0

g(x, t|ξ, τ)∂u(ξ, τ)
∂ξ
−u(ξ, τ)∂g(x, t|ξ, τ)
∂ξ
ξ=b
ξ=a
dτ
+
Z b
a
u(ξ, 0)g(x, t|ξ, 0) dξ,
(15.5.6)
where we used g(x, t|ξ, t+) = 0. The ﬁrst two terms in Equation 15.5.6 represent the familiar
eﬀects of volume sources and boundary conditions, while the third term includes the eﬀects
of the initial data.
• Example 15.5.1: One-dimensional heat equation in an unlimited domain
The Green’s function for the one-dimensional heat equation is governed by
∂g
∂t −a2 ∂2g
∂x2 = δ(x −ξ)δ(t −τ),
−∞< x, ξ < ∞,
0 < t, τ,
(15.5.7)
subject to the boundary conditions lim|x|→∞g(x, t|ξ, τ) →0, and the initial condition
g(x, 0|ξ, τ) = 0. Let us ﬁnd g(x, t|ξ, τ).
We begin by taking the Laplace transform of Equation 15.5.7 and ﬁnd that
d2G
dx2 −s
a2 G = −δ(x −ξ)
a2
e−sτ.
(15.5.8)
Next, we take the Fourier transform of Equation 15.5.8 so that
(k2 + b2)G(k, s|ξ, τ) = e−ikξe−sτ
a2
,
(15.5.9)
where G(k, s|ξ, τ) is the Fourier transform of G(x, s|ξ, τ) and b2 = s/a2.
To ﬁnd G(x, s|ξ, τ), we use the inversion integral
G(x, s|ξ, τ) = e−sτ
2πa2
Z ∞
−∞
ei(x−ξ)k
k2 + b2 dk.
(15.5.10)
Transforming Equation 15.5.10 into a closed contour via Jordan’s lemma, we evaluate it by
the residue theorem and ﬁnd that
G(x, s|ξ, τ) = e−|x−ξ|√s/a−sτ
2a √s
.
(15.5.11)

768
Advanced Engineering Mathematics with MATLAB
From a table of Laplace transforms we ﬁnally obtain
g(x, t|ξ, τ) =
H(t −τ)
p
4πa2(t −τ)
exp

−(x −ξ)2
4a2(t −τ)

,
(15.5.12)
after applying the second shifting theorem.
⊓⊔
The primary use of the fundamental or free-space Green’s function19 is as a particular
solution to the Green’s function problem. For this reason, it is often called the fundamental
heat conduction solution. Consequently, we usually must ﬁnd a homogeneous solution so
that the sum of the free-space Green’s function plus the homogeneous solution satisﬁes any
boundary conditions. The following examples show some commonly employed techniques.
• Example 15.5.2
Let us ﬁnd the Green’s function for the following problem:
∂g
∂t −a2 ∂2g
∂x2 = δ(x −ξ)δ(t −τ),
0 < x, ξ < ∞,
0 < t, τ,
(15.5.13)
subject to the boundary conditions g(0, t|ξ, τ) = 0, limx→∞g(x, t|ξ, τ) →0, and the initial
condition g(x, 0|ξ, τ) = 0. From the boundary condition g(0, t|ξ, τ) = 0, we deduce that
g(x, t|ξ, τ) must be an odd function in x over the open interval (−∞, ∞). We ﬁnd this
Green’s function by introducing an image source of −δ(x+ξ) and resolving Equation 15.5.7
with the source δ(x −ξ)δ(t −τ) −δ(x + ξ)δ(t −τ). Because Equation 15.5.7 is linear,
Equation 15.5.12 gives the solution for each delta function and the Green’s function for
Equation 15.5.13 is
g(x, t|ξ, τ) =
H(t −τ)
p
4πa2(t −τ)

exp

−(x −ξ)2
4a2(t −τ)

−exp

−(x + ξ)2
4a2(t −τ)

(15.5.14)
=
H(t −τ)
p
πa2(t −τ)
exp

−x2 + ξ2
4a2(t −τ)

sinh

xξ
2a2(t −τ)

.
(15.5.15)
In a similar manner, if the boundary condition at x = 0 changes to gx(0, t|ξ, τ) = 0,
then Equation 15.5.14 through Equation 15.5.15 become
g(x, t|ξ, τ) =
H(t −τ)
p
4πa2(t −τ)

exp

−(x −ξ)2
4a2(t −τ)

+ exp

−(x + ξ)2
4a2(t −τ)

(15.5.16)
=
H(t −τ)
p
πa2(t −τ)
exp

−x2 + ξ2
4a2(t −τ)

cosh

xξ
2a2(t −τ)

.
(15.5.17)
19 In electromagnetic theory, a free-space Green’s function is the particular solution of the diﬀerential
equation valid over a domain of inﬁnite extent, where the Green’s function remains bounded as we approach
inﬁnity, or satisﬁes a radiation condition there.

Green’s Functions
769
0
0.5
1
1.5
2
0
0.5
1
1.5
2
0
0.1
0.2
0.3
0.4
0.5
0.6
 x
 a2(t−τ)
 [a2(t−τ)]1/2 g(x,t|ξ,τ)
Figure 15.5.1: The Green’s function, Equation 15.5.17, for the one-dimensional heat equation on the
semi-inﬁnite domain 0 < x < ∞, and 0 ≤t −τ, when the left boundary condition is gx(0, t|ξ, τ) = 0 and
ξ = 0.5.
Figure 15.5.1 illustrates Equation 15.5.17 for the special case when ξ = 0.5.
⊓⊔
• Example 15.5.3: One-dimensional heat equation on the interval 0 < x < L
Here we ﬁnd the Green’s function for the one-dimensional heat equation over the in-
terval 0 < x < L associated with the problem
∂u
∂t −a2 ∂2u
∂x2 = f(x, t),
0 < x < L,
0 < t,
(15.5.18)
where a2 is the diﬀusivity constant.
To ﬁnd the Green’s function for this problem, consider the following problem:
∂g
∂t −a2 ∂2g
∂x2 = δ(x −ξ)δ(t −τ),
0 < x, ξ < L,
0 < t, τ,
(15.5.19)
with the boundary conditions
α1g(0, t|ξ, τ) + β1gx(0, t|ξ, τ) = 0,
0 < t,
(15.5.20)
and
α2g(L, t|ξ, τ) + β2gx(L, t|ξ, τ) = 0,
0 < t,
(15.5.21)
and the initial condition
g(x, 0|ξ, τ) = 0,
0 < x < L.
(15.5.22)
We begin by taking the Laplace transform of Equation 15.5.19 and ﬁnd that
d2G
dx2 −s
a2 G = −δ(x −ξ)
a2
e−sτ,
0 < x < L,
(15.5.23)
with
α1G(0, s|ξ, τ) + β1G′(0, s|ξ, τ) = 0,
(15.5.24)

770
Advanced Engineering Mathematics with MATLAB
and
α2G(L, s|ξ, τ) + β2G′(L, s|ξ, τ) = 0.
(15.5.25)
Problems similar to Equation 15.5.23 through Equation 15.5.25 were considered in Section
15.2. Applying this technique of eigenfunction expansions, we have that
G(x, s|ξ, τ) = e−sτ
∞
X
n=1
ϕn(ξ)ϕn(x)
s + a2k2n
,
(15.5.26)
where ϕn(x) is the nth orthonormal eigenfunction to the regular Sturm-Liouville problem
ϕ
′′(x) + k2ϕ(x) = 0,
0 < x < L,
(15.5.27)
subject to the boundary conditions
α1ϕ(0) + β1ϕ′(0) = 0,
(15.5.28)
and
α2ϕ(L) + β2ϕ′(L) = 0.
(15.5.29)
Taking the inverse of Equation 15.5.26, we have that
g(x, t|ξ, τ) =
" ∞
X
n=1
ϕn(ξ)ϕn(x)e−k2
na2(t−τ)
#
H(t −τ).
(15.5.30)
For example, let us ﬁnd the Green’s function for the heat equation on a ﬁnite domain
∂g
∂t −a2 ∂2g
∂x2 = δ(x −ξ)δ(t −τ),
0 < x, ξ < L,
0 < t, τ,
(15.5.31)
with the boundary conditions g(0, t|ξ, τ) = g(L, t|ξ, τ) = 0, 0 < t, and the initial condition
g(x, 0|ξ, τ) = 0, 0 < x < L.
The Sturm-Liouville problem is
ϕ′′(x) + k2ϕ(x) = 0,
0 < x < L,
(15.5.32)
with the boundary conditions ϕ(0) = ϕ(L) = 0. The nth orthonormal eigenfunction to
Equation 15.5.32 is
ϕn(x) =
r
2
L sin
nπx
L

.
(15.5.33)
Substituting Equation 15.5.33 into Equation 15.5.30, we ﬁnd that
g(x, t|ξ, τ) = 2
L
( ∞
X
n=1
sin
nπξ
L

sin
nπx
L

e−a2n2π2(t−τ)/L2
)
H(t −τ).
(15.5.34)

Green’s Functions
771
On the other hand, the Green’s function for the heat equation on a ﬁnite domain
governed by
∂g
∂t −a2 ∂2g
∂x2 = δ(x −ξ)δ(t −τ),
0 < x, ξ < L,
0 < t, τ,
(15.5.35)
with the boundary conditions
gx(0, t|ξ, τ) = 0,
gx(L, t|ξ, τ) + hg(L, t|ξ, τ) = 0,
0 < t,
(15.5.36)
and the initial condition g(x, 0|ξ, τ) = 0, 0 < x < L, yields the Sturm-Liouville problem
that we must now solve:
ϕ′′(x) + λϕ(x) = 0,
ϕ′(0) = 0,
ϕ′(L) + hϕ(L) = 0.
(15.5.37)
The nth orthonormal eigenfunction for Equation 15.5.37 is
ϕn(x) =
s
2(k2n + h2)
L(k2n + h2) + h cos(knx),
(15.5.38)
where kn is the nth root of k tan(kL) = h. We also used the identity that (k2
n+h2) sin2(knh)
= h2. Substituting Equation 15.5.38 into Equation 15.5.30, we ﬁnally obtain
g(x, t|ξ, τ) = 2
L
( ∞
X
n=1
[(knL)2 + (hL)2] cos(knξ) cos(knx)
(knL)2 + (hL)2 + hL
e−a2k2
n(t−τ)
)
H(t −τ). (15.5.39)
⊓⊔
• Example 15.5.4
Let us use Green’s functions to solve the heat equation
∂u
∂t = a2 ∂2u
∂x2 ,
0 < x < L,
0 < t,
(15.5.40)
subject to the boundary conditions
u(0, t) = 0,
u(L, t) = t,
0 < t,
(15.5.41)
and the initial condition
u(x, 0) = 0,
0 < x < L.
(15.5.42)
Because there is no source term, Equation 15.5.6 simpliﬁes to
u(x, t) = a2
Z t
0
[g(x, t|L, τ)uξ(L, τ) −u(L, τ)gξ(x, t|L, τ)] dτ
(15.5.43)
−a2
Z t
0
[g(x, t|0, τ)uξ(0, τ) −u(0, τ)gξ(x, t|0, τ)] dτ +
Z L
0
u(ξ, 0)g(x, t|ξ, 0) dξ.
The Green’s function that should be used here is the one given by Equation 15.5.34. Further
simpliﬁcation occurs by noting that g(x, t|0, τ) = g(x, t|L, τ) = 0 as well as u(0, τ) =
u(ξ, 0) = 0. Therefore we are left with the single integral
u(x, t) = −a2
Z t
0
u(L, τ)gξ(x, t|L, τ) dτ.
(15.5.44)

772
Advanced Engineering Mathematics with MATLAB
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
0
0.5
1
 x/L
 a2t/L2
 a2u(x,t)/L2
Figure 15.5.2: The temperature distribution within a bar when the temperature is initially at zero and
then the ends are held at zero at x = 0 and t at x = L.
Upon substituting for g(x, t|L, τ) and reversing the order of integration and summation,
u(x, t) = −2πa2
L2
∞
X
n=1
(−1)nn sin
nπx
L
 Z t
0
τ exp
a2n2π2
L2
(τ −t)

dτ
(15.5.45)
= −2L2
a2π3
∞
X
n=1
(−1)n
n3
sin
nπx
L

exp
a2n2π2
L2
(τ −t)
 a2n2π2τ
L2
−1

t
0
(15.5.46)
= −2L2
a2π3
∞
X
n=1
(−1)n
n3
sin
nπx
L
 a2n2π2t
L2
−1 + exp

−a2n2π2t
L2

.
(15.5.47)
Figure 15.5.2 illustrates Equation 15.5.47. This solution is equivalent to Equation 8.6.16
that we found by Duhamel’s integral.
⊓⊔
• Example 15.5.5: Heat equation within a cylinder
In this example, we ﬁnd the Green’s function for the heat equation in cylindrical
coordinates
∂g
∂t −a2
r
∂
∂r

r∂g
∂r

= δ(r −ρ)δ(t −τ)
2πr
,
0 < r, ρ < b,
0 < t, τ,
(15.5.48)
subject to the boundary conditions limr→0 |g(r, t|ρ, τ)| < ∞, g(b, t|ρ, τ) = 0, and the initial
condition g(r, 0|ρ, τ) = 0.
As usual, we begin by taking the Laplace transform of Equation 15.5.48, or
1
r
d
dr

rdG
dr

−s
a2 G = −e−sτ
2πa2rδ(r −ρ).
(15.5.49)

Green’s Functions
773
0
0.5
1
0
0.05
0.1
0.15
0.2
0
1
2
3
4
5
 r/b
 a2(t−τ)/b2
 b2 g(r,t|ρ,τ)
Figure 15.5.3: The Green’s function, Equation 15.5.54, for the axisymmetric heat equation, Equation
15.5.48, with a Dirichlet boundary condition at r = b. Here ρ/b = 0.3 and the graph starts at a2(t−τ)/b2 =
0.001 to avoid the delta function at t −τ = 0.
Next we re-express δ(r −ρ)/r as the Fourier-Bessel expansion
δ(r −ρ)
2πr
=
∞
X
n=1
AnJ0(knr/b),
(15.5.50)
where kn is the nth root of J0(k) = 0, and
An =
2
b2J2
1(kn)
Z b
0
δ(r −ρ)
2πr
J0(knr/b) r dr = J0(knρ/b)
πb2J2
1(kn)
(15.5.51)
so that
1
r
d
dr

rdG
dr

−s
a2 G = −e−sτ
πa2b2
∞
X
n=1
J0(knρ/b)J0(knr/b)
J2
1(kn)
.
(15.5.52)
The solution to Equation 15.5.52 is
G(r, s|ρ, τ) = e−sτ
π
∞
X
n=1
J0(knρ/b)J0(knr/b)
(sb2 + a2k2n)J2
1(kn) .
(15.5.53)
Taking the inverse of Equation 15.5.53 and applying the second shifting theorem,
g(r, t|ρ, τ) = H(t −τ)
πb2
∞
X
n=1
J0(knρ/b)J0(knr/b)
J2
1(kn)
e−a2k2
n(t−τ)/b2.
(15.5.54)
See Figure 15.5.3.
If we modify the boundary condition at r = b so that it now reads
gr(b, t|ρ, τ) + hg(b, t|ρ, τ) = 0,
(15.5.55)
where h ≥0, our analysis now leads to
g(r, t|ρ, τ) = H(t −τ)
πb2
∞
X
n=1
J0(knρ/b)J0(knr/b)
J2
0(kn) + J2
1(kn)
e−a2k2
n(t−τ)/b2,
(15.5.56)
where kn are the positive roots of k J1(k) −hb J0(k) = 0. If h = 0, we must add 1/(πb2) to
Equation 15.5.56.

774
Advanced Engineering Mathematics with MATLAB
Problems
1. Find the free-space Green’s function for the linearized Ginzburg-Landau equation20
∂g
∂t + v ∂g
∂x −ag −b∂2g
∂x2 = δ(x −ξ)δ(t −τ), −∞< x, ξ < ∞, 0 < t, τ,
with b > 0.
Step 1: Taking the Laplace transform of the partial diﬀerential equation, show that it
reduces to the ordinary diﬀerential equation
bd2G
dx2 −v dG
dx + aG −sG = −δ(x −ξ)e−sτ.
Step 2: Using Fourier transforms, show that
G(x, s|ξ, τ) = e−sτ
2π
Z ∞
−∞
eik(x−ξ)
s + ikv + bk2 −a dk,
or
g(x, t|ξ, τ) = ea(t−τ)
π
H(t −τ)
Z ∞
0
e−b(t−τ)k2 cos{k[x −ξ −v(t −τ)]} dk.
Step 3: Evaluate the second integral and show that
g(x, t|ξ, τ) = ea(t−τ)H(t −τ)
2
p
πb(t −τ)
exp

−[x −ξ −v(t −τ)]2
4b(t −τ)

.
2. Use Green’s functions to show that the solution21 to
∂u
∂t = a2 ∂2u
∂x2 ,
0 < x, t,
subject to the boundary conditions
u(0, t) = 0,
lim
x→∞u(x, t) →0,
0 < t,
and the initial condition
u(x, 0) = f(x),
0 < x < ∞,
is
u(x, t) = e−x2/(4a2t)
a
√
πt
Z ∞
0
f(τ) sinh
 xτ
2a2t

e−τ 2/(4a2t) dτ.
20 See Deissler, R. J., 1985: Noise-sustained structure, intermittency, and the Ginzburg-Landau equation.
J. Stat. Phys., 40, 371–395.
21 See Gilev, S. D., and T. Yu. Mikha˘ılova, 1996: Current wave in shock compression of matter in a
magnetic ﬁeld. Tech. Phys., 41, 407–411.

Green’s Functions
775
3. Use Equation 15.5.30 to construct the Green’s function for the one-dimensional heat
equation gt −gxx = δ(x −ξ)δ(t −τ) for 0 < x < L, 0 < t, with the initial condition that
g(x, 0|ξ, τ) = 0, 0 < x < L, and the boundary conditions that g(0, t|ξ, τ) = gx(L, t|ξ, τ) = 0
for 0 < t. Assume that L ̸= π.
4. Use Equation 15.5.30 to construct the Green’s function for the one-dimensional heat
equation gt −gxx = δ(x −ξ)δ(t −τ) for 0 < x < L, 0 < t, with the initial condition that
g(x, 0|ξ, τ) = 0, 0 < x < L, and the boundary conditions that gx(0, t|ξ, τ) = gx(L, t|ξ, τ) = 0
for 0 < t.
5. Use Equation 15.5.43 and the Green’s function given by Equation 15.5.34 to ﬁnd the
solution to the heat equation ut = uxx for 0 < x < L, 0 < t, with the initial data u(x, 0) = 1,
0 < x < L, and the boundary conditions u(0, t) = e−t and u(L, t) = 0 when 0 < t.
6. Use Equation 15.5.43 and the Green’s function that you found in Problem 3 to ﬁnd
the solution to the heat equation ut = uxx for 0 < x < L, 0 < t, with the initial data
u(x, 0) = 1, 0 < x < L, and the boundary conditions u(0, t) = sin(t) and ux(L, t) = 0 when
0 < t.
7. Use Equation 15.5.43 and the Green’s function that you found in Problem 4 to ﬁnd
the solution to the heat equation ut = uxx for 0 < x < L, 0 < t, with the initial data
u(x, 0) = 1, 0 < x < L, and the boundary conditions ux(0, t) = 1 and ux(L, t) = 0 when
0 < t.
8. Find the Green’s function for
∂g
∂t −a2 ∂2g
∂x2 + a2k2g = δ(x −ξ)δ(t −τ),
0 < x, ξ < L,
0 < t, τ,
subject to the boundary conditions
g(0, t|ξ, τ) = gx(L, t|ξ, τ) = 0,
0 < t,
and the initial condition
g(x, 0|ξ, τ) = 0,
0 < x < L,
where a and k are real constants.
15.6 HELMHOLTZ’S EQUATION
In the previous sections, we sought solutions to the heat and wave equations via Green’s
functions. In this section, we turn to the reduced wave equation
∂2u
∂x2 + ∂2u
∂y2 + λu = −f(x, y).
(15.6.1)
Equation 15.6.1, generally known as Helmholtz’s equation, includes the special case of Pois-
son’s equation when λ = 0. Poisson’s equation has a special place in the theory of Green’s
functions because George Green (1793–1841) invented his technique for its solution.

776
Advanced Engineering Mathematics with MATLAB
The reduced wave equation arises during the solution of the harmonically forced wave
equation22 by separation of variables. In one spatial dimension, the problem is
∂2u
∂x2 −1
c2
∂2u
∂t2 = −f(x)e−iωt.
(15.6.2)
Equation 15.6.2 occurs, for example, in the mathematical analysis of a stretched string over
some interval subject to an external, harmonic forcing. Assuming that u(x, t) is bounded
everywhere, we seek solutions of the form u(x, t) = y(x)e−iωt.
Upon substituting this
solution into Equation 15.6.2 we obtain the ordinary diﬀerential equation
y′′ + k2
0y = −f(x),
(15.6.3)
where k2
0 = ω2/c2. This is an example of the one-dimensional Helmholtz equation.
Let us now use Green’s functions to solve the Helmholtz equation, Equation 15.6.1,
where the Green’s function is given by the Helmholtz equation
∂2g
∂x2 + ∂2g
∂y2 + λg = −δ(x −ξ)δ(y −η).
(15.6.4)
The most commonly encountered boundary conditions are
• the Dirichlet boundary condition, where g vanishes on the boundary,
• the Neumann boundary condition, where the normal gradient of g vanishes on the bound-
ary, and
• the Robin boundary condition, which is the linear combination of the Dirichlet and Neu-
mann conditions.
We begin by multiplying Equation 15.6.1 by g(x, y|ξ, η) and Equation 15.6.4 by u(x, y),
subtract and integrate over the region a < x < b, c < y < d. We ﬁnd that
u(ξ, η) =
Z d
c
Z b
a

g(x, y|ξ, η)
∂2u(x, y)
∂x2
+ ∂2u(x, y)
∂y2

−u(x, y)
∂2g(x, y|ξ, η)
∂x2
+ ∂2g(x, y|ξ, η)
∂y2

dx dy
+
Z d
c
Z b
a
f(x, y)g(x, y|ξ, η) dx dy
(15.6.5)
=
Z d
c
Z b
a
 ∂
∂x

g(x, y|ξ, η)∂u(x, y)
∂x

−∂
∂x

u(x, y)∂g(x, y|ξ, η)
∂x

dx dy
+
Z d
c
Z b
a
 ∂
∂y

g(x, y|ξ, η)∂u(x, y)
∂y

−∂
∂y

u(x, y)∂g(x, y|ξ, η)
∂y

dx dy
+
Z d
c
Z b
a
f(x, y)g(x, y|ξ, η) dx dy
(15.6.6)
=
Z d
c

g(x, y|ξ, η)∂u(x, y)
∂x
−u(x, y)∂g(x, y|ξ, η)
∂x
x=b
x=a
dy
+
Z b
a

g(x, y|ξ, η)∂u(x, y)
∂y
−u(x, y)∂g(x, y|ξ, η)
∂y
y=d
y=c
dx
+
Z d
c
Z b
a
f(x, y)g(x, y|ξ, η) dx dy.
(15.6.7)
22 See, for example, Graﬀ, K. F., 1991: Wave Motion in Elastic Solids. Dover Publications, Inc., Section
1.4.

Green’s Functions
777
Because (ξ, η) is an arbitrary point inside the rectangle, we denote it in general by (x, y).
Furthermore, the variable (x, y) is now merely a dummy integration variable that we now
denote by (ξ, η).
Upon making these substitutions and using the symmetry condition
g(x, y|ξ, η) = g(ξ, η|x, y), we have that
u(x, y) =
Z d
c

g(x, y|ξ, η)∂u(ξ, η)
∂ξ
−u(ξ, η)∂g(x, y|ξ, η)
∂ξ
ξ=b
ξ=a
dη
+
Z b
a

g(x, y|ξ, η)∂u(ξ, η)
∂η
−u(ξ, η)∂g(x, y|ξ, η)
∂η
η=d
η=c
dξ
+
Z d
c
Z b
a
f(ξ, η)g(x, y|ξ, η) dξ dη.
(15.6.8)
Equation 15.6.8 shows that the solution of Helmholtz’s equation depends upon the sources
inside the rectangle and values of u(x, y) and (∂u/∂x, ∂u/∂y) along the boundary. On the
other hand, we must still ﬁnd the particular Green’s function for a given problem; this
Green’s function depends directly upon the boundary conditions. At this point, we work
out several special cases.
1. Nonhomogeneous Helmholtz equation
and homogeneous Dirichlet boundary conditions
In this case, let us assume that we can ﬁnd a Green’s function that also satisﬁes the
same Dirichlet boundary conditions as u(x, y). Once the Green’s function is found, then
Equation 15.6.8 reduces to
u(x, y) =
Z d
c
Z b
a
f(ξ, η)g(x, y|ξ, η) dξdη.
(15.6.9)
A possible source of diﬃculty would be the nonexistence of the Green’s function. From
our experience in Section 15.2, we know that this will occur if λ equals one of the eigenvalues
of the corresponding homogeneous problem. An example of this occurs in acoustics when
the Green’s function for the Helmholtz equation does not exist at resonance.
2. Homogeneous Helmholtz equation
and nonhomogeneous Dirichlet boundary conditions
In this particular case, f(x, y) = 0. For convenience, let us use the Green’s function
from the previous example so that g(x, y|ξ, η) = 0 along all of the boundaries. Under these
conditions, Equation 15.6.8 becomes
u(x, y) = −
Z b
a
u(ξ, η)∂g(x, y|ξ, η)
∂η

η=d
η=c
dξ −
Z d
c
u(ξ, η)∂g(x, y|ξ, η)
∂ξ

ξ=b
ξ=a
dη.
(15.6.10)
Consequently, the solution is determined once we compute the normal gradient of the
Green’s function along the boundary.
3. Nonhomogeneous Helmholtz equation
and homogeneous Neumann boundary conditions

778
Advanced Engineering Mathematics with MATLAB
If we require that u(x, y) satisﬁes the nonhomogeneous Helmholtz equation with homo-
geneous Neumann boundary conditions, then the governing equations are Equation 15.6.1
and the boundary conditions ux = 0 along x = a and x = b, and uy = 0 along y = c and
y = d. Integrating Equation 15.6.1, we have that
Z d
c
∂u(b, y)
∂x
−∂u(a, y)
∂x

dy +
Z b
a
∂u(x, d)
∂y
−∂u(x, c)
∂y

dx
+ λ
Z d
c
Z b
a
u(x, y) dx dy = −
Z d
c
Z b
a
f(x, y) dx dy.
(15.6.11)
Because the ﬁrst two integrals in Equation 15.6.11 must vanish in the case of homogeneous
Neumann boundary conditions, this equation cannot be satisﬁed if λ = 0 unless
Z d
c
Z b
a
f(x, y) dx dy = 0.
(15.6.12)
A physical interpretation of Equation 15.6.12 is as follows: Consider the physical pro-
cess of steady-state heat conduction within a rectangular region. The temperature u(x, y)
is given by Poisson’s equation
∂2u
∂x2 + ∂2u
∂y2 = −f(x, y),
(15.6.13)
where f(x, y) is proportional to the density of the heat sources and sinks. The boundary
conditions ux(a, y) = ux(b, y) = 0 and uy(x, c) = uy(x, d) = 0 imply that there is no heat
exchange across the boundary. Consequently, no steady-state temperature distribution can
exist unless the heat sources are balanced by heat sinks. This balance of heat sources and
sinks is given by Equation 15.6.12.
Having provided an overview of how Green’s functions can be used to solve Poisson
and Helmholtz equations, let us now determine several of them for commonly encountered
domains.
• Example 15.6.1: Free-space Green’s function for the one-dimensional Helmholtz equation
Let us ﬁnd the Green’s function for the one-dimensional Helmholtz equation
g′′ + k2
0g = −δ(x −ξ),
−∞< x, ξ < ∞.
(15.6.14)
If we solve Equation 15.6.14 by piecing together homogeneous solutions, then
g(x|ξ) = Ae−ik0(x−ξ) + Beik0(x−ξ),
(15.6.15)
for x < ξ, while
g(x|ξ) = Ce−ik0(x−ξ) + Deik0(x−ξ),
(15.6.16)
for ξ < x.
Let us examine Equation 15.6.15 more closely. The solution represents two propagating
waves. Because x < ξ, the ﬁrst term is a wave propagating out to inﬁnity, while the second
term gives a wave propagating in from inﬁnity. This is seen most clearly by including the
e−iωt term into Equation 15.6.15, or
g(x|ξ)e−iωt = Ae−ik0(x−ξ)−iωt + Beik0(x−ξ)−iωt.
(15.6.17)

Green’s Functions
779
0
x
x
iy
k
-k
-k
k
iy
(a) Contour for x >
(b) Contour for x < 
0
0
ξ
ξ
0
Figure 15.6.1: Contour used to evaluate Equation 15.6.21.
Because we have a source only at x = ξ, solutions that represent waves originating at inﬁnity
are nonphysical and we must discard them. This requirement that there are only outwardly
propagating wave solutions is commonly called Sommerfeld’s radiation condition.23 Similar
considerations hold for Equation 15.6.16 and we must take C = 0.
To evaluate A and D, we use the continuity conditions on the Green’s function:
g(ξ+|ξ) = g(ξ−|ξ),
and
g′(ξ+|ξ) −g′(ξ−|ξ) = −1,
(15.6.18)
or
A = D,
and
ik0D + ik0A = −1.
(15.6.19)
Therefore,
g(x|ξ) =
i
2k0
eik0|x−ξ|.
(15.6.20)
We can also solve Equation 15.6.14 by Fourier transforms. Assuming that the Fourier
transform of g(x|ξ) exists and denoting it by G(k|ξ), we ﬁnd that
G(k|ξ) =
e−ikξ
k2 −k2
0
,
and
g(x|ξ) = 1
2π
Z ∞
−∞
eik(x−ξ)
k2 −k2
0
dk.
(15.6.21)
Immediately we see that there is a problem with the singularities lying on the path of
integration at k = ±k0. How do we avoid them?
There are four possible ways that we might circumvent the singularities. One of them
is shown in Figure 15.6.1. Applying Jordan’s lemma to close the line integral along the real
23 Sommerfeld, A., 1912: Die Greensche Funktion der Schwingungsgleichung.
Jahresber.
Deutschen
Math.- Vereinung, 21, 309–353.

780
Advanced Engineering Mathematics with MATLAB
Free-Space Green’s Function for the Poisson and Helmholtz Equations
Dimension
Poisson Equation
Helmholtz Equation
One
no solution
g(x|ξ) =
i
2k0
eik0|x−ξ|
Two
g(x, y|ξ, η) = −ln(r)
2π
g(x, y|ξ, η) = i
4H(1)
0 (k0r)
r =
p
(x −ξ)2 + (y −η)2
Note: For the Helmholtz equation, we have taken the temporal forcing to be e−iωt and k0 = ω/c.
axis (as shown in Figure 15.6.1),
g(x|ξ) = 1
2π
I
C
eiz(x−ξ)
z2 −k2
0
dz.
(15.6.22)
For x < ξ,
g(x|ξ) = −i Res
eiz(x−ξ)
z2 −k2
0
; −k0

=
i
2k0
e−ik0(x−ξ),
(15.6.23)
while
g(x|ξ) = i Res
eiz(x−ξ)
z2 −k2
0
; k0

=
i
2k0
eik0(x−ξ),
(15.6.24)
for x > ξ. A quick check shows that these solutions agree with Equation 15.6.20. If we try
the three other possible paths around the singularities, we obtain incorrect solutions.
⊓⊔
• Example 15.6.2: Free-space Green’s function for the two-dimensional Helmholtz equation
At this point, we have found two forms of the free-space Green’s function for the one-
dimensional Helmholtz equation. The ﬁrst form is the analytic solution, Equation 15.6.20,
while the second is the integral representation, Equation 15.6.21, where the line integration
along the real axis is shown in Figure 15.6.1.
In the case of two dimensions, the Green’s function24 for the Helmholtz equation sym-
metric about the point (ξ, η) is the solution of the equation
d2g
dr2 + 1
r
dg
dr + k2
0g = −δ(r)
2πr ,
(15.6.25)
where r =
p
(x −ξ)2 + (y −η)2. The homogeneous form of Equation 15.6.25 is Bessel’s
diﬀerential equation of order zero. Consequently, the general solution in terms of Hankel
functions is
g(r|r0) = A H(1)
0 (k0r) + B H(2)
0 (k0r).
(15.6.26)
24 For an alternative derivation, see Graﬀ, K. F., 1991: Wave Motion in Elastic Solids. Dover Publica-
tions, Inc., pp. 284–285.

Green’s Functions
781
Why have we chosen to use Hankel functions rather than J0(·) and Y0(·)? As we argued
earlier, solutions to the Helmholtz equation must represent outwardly propagating waves
(the Sommerfeld radiation condition).
If we again assume that the temporal behavior
is e−iωt and use the asymptotic expressions for Hankel functions, we see that H(1)
0 (k0r)
represents outwardly propagating waves and B = 0.
What is the value of A? Integrating Equation 15.6.26 over a small circle around the
point r = 0 and taking the limit as the radius of the circle vanishes, A = i/4 and
g(r|r0) = i
4H(1)
0 (k0r).
(15.6.27)
If a real function is needed, then the free-space Green’s function equals the Neumann
function Y0(k0r) divided by −4.
⊓⊔
• Example 15.6.3: Free-space Green’s function for the two-dimensional Laplace equation
In this subsection, we ﬁnd the free-space Green’s function for Poisson’s equation in two
dimensions. This Green’s function is governed by
1
r
∂
∂r

r∂g
∂r

+ 1
r2
∂2g
∂θ2 = −δ(r −ρ)δ(θ −θ′)
r
.
(15.6.28)
If we now choose our coordinate system so that the origin is located at the point source,
r =
p
(x −ξ)2 + (y −η)2 and ρ = 0. Multiplying both sides of this simpliﬁed Equation
15.6.28 by r dr dθ and integrating over a circle of radius ǫ, we obtain −1 on the right side
from the surface integration over the delta functions. On the left side,
Z 2π
0
r∂g
∂r

r=ǫ
dθ = −1.
(15.6.29)
The Green’s function g(r, θ|0, θ′) = −ln(r)/(2π) satisﬁes Equation 15.6.29.
To ﬁnd an alternative form of the free-space Green’s function when the point of exci-
tation and the origin of the coordinate system do not coincide, we ﬁrst note that
δ(θ −θ′) = 1
2π
∞
X
n=−∞
ein(θ−θ′).
(15.6.30)
This suggests that the Green’s function should be of the form
g(r, θ|ρ, θ′) =
∞
X
n=−∞
gn(r|ρ)ein(θ−θ′).
(15.6.31)
Substituting Equation 15.6.30 and Equation 15.6.31 into Equation 15.6.29, we obtain the
ordinary diﬀerential equation
1
r
d
dr

rdgn
dr

−n2
r2 gn = −δ(r −ρ)
2πr
.
(15.6.32)

782
Advanced Engineering Mathematics with MATLAB
The homogeneous solution to Equation 15.6.32 is
g0(r|ρ) =

a,
0 ≤r ≤ρ ,
b ln(r),
ρ ≤r < ∞.
(15.6.33)
and
gn(r|ρ) =

c (r/ρ)n,
0 ≤r ≤ρ ,
d (ρ/r)n,
ρ ≤r < ∞,
(15.6.34)
if n ̸= 0.
At r = ρ, the gn’s must be continuous, in which case,
a = b ln(ρ),
and
c = d.
(15.6.35)
On the other hand,
ρdgn
dr

r=ρ+
r=ρ−= −1
2π ,
(15.6.36)
or
a = −ln(ρ)
2π ,
b = −1
2π ,
and
c = d =
1
4πn.
(15.6.37)
Therefore,
g(r, θ|ρ, θ′) = −ln(r>)
2π
+ 1
2π
∞
X
n=1
1
n
r<
r>
n
cos[n(θ −θ′)],
(15.6.38)
where r> = max(r, ρ) and r< = min(r, ρ).
We can simplify Equation 15.6.38 by noting that
ln

1 + ρ2 −2ρ cos(θ −θ′)

= −2
∞
X
n=1
ρn cos[n(θ −θ′)]
n
,
(15.6.39)
if |ρ| < 1. Applying this relationship to Equation 15.6.38, we ﬁnd that
g(r, θ|ρ, θ′) = −1
4π ln

r2 + ρ2 −2rρ cos(θ −θ′)

.
(15.6.40)
Note that when ρ = 0 we recover g(r, θ|0, θ′) = −ln(r)/(2π).
⊓⊔
• Example 15.6.4: Two-dimensional Poisson equation over a rectangular domain
Consider the two-dimensional Poisson equation
∂2u
∂x2 + ∂2u
∂y2 = −f(x, y).
(15.6.41)
This equation arises in equilibrium problems, such as the static deﬂection of a rectangular
membrane. In that case, f(x, y) represents the external load per unit area, divided by the
tension in the membrane. The solution u(x, y) must satisfy certain boundary conditions.
For the present, let us choose u(0, y) = u(a, y) = 0, and u(x, 0) = u(x, b) = 0.

Green’s Functions
783
To ﬁnd the Green’s function for Equation 15.6.41 we must solve the partial diﬀerential
equation
∂2g
∂x2 + ∂2g
∂y2 = −δ(x −ξ)δ(y −η),
0 < x, ξ < a,
0 < y, η < b,
(15.6.42)
subject to the boundary conditions
g(0, y|ξ, η) = g(a, y|ξ, η) = g(x, 0|ξ, η) = g(x, b|ξ, η) = 0.
(15.6.43)
From Equation 15.6.9,
u(x, y) =
Z a
0
Z b
0
g(x, y|ξ, η)f(ξ, η) dη dξ.
(15.6.44)
One approach to ﬁnding the Green’s function is to expand it in terms of the eigenfunc-
tions ϕ(x, y) of the diﬀerential equation
∂2ϕ
∂x2 + ∂2ϕ
∂y2 = −λϕ,
(15.6.45)
and the boundary conditions, Equation 15.6.43. The eigenvalues are
λnm = n2π2
a2
+ m2π2
b2
,
(15.6.46)
where n = 1, 2, 3, . . ., m = 1, 2, 3, . . ., and the corresponding eigenfunctions are
ϕnm(x, y) = sin
nπx
a

sin
mπy
b

.
(15.6.47)
Therefore, we seek g(x, y|ξ, η) in the form
g(x, y|ξ, η) =
∞
X
n=1
∞
X
m=1
Anm sin
nπx
a

sin
mπy
b

.
(15.6.48)
Because the delta functions can be written
δ(x −ξ)δ(y −η) = 4
ab
∞
X
n=1
∞
X
m=1
sin
nπξ
a

sin
mπη
b

sin
nπx
a

sin
mπy
b

,
(15.6.49)
we ﬁnd that
n2π2
a2
+ m2π2
b2

Anm = 4
ab sin
nπξ
a

sin
mπη
b

,
(15.6.50)
after substituting Equations 15.6.48 and 15.6.49 into Equation 15.6.42, and setting the
corresponding harmonics equal to each other. Therefore, the bilinear formula for the Green’s
function of Poisson’s equation is
g(x, y|ξ, η) = 4
ab
∞
X
n=1
∞
X
m=1
sin
nπx
a

sin
nπξ
a

sin
mπy
b

sin
mπη
b

n2π2/a2 + m2π2/b2
.
(15.6.51)

784
Advanced Engineering Mathematics with MATLAB
Thus, solutions to Poisson’s equation can now be written as
u(x, y) =
∞
X
n=1
∞
X
m=1
anm
n2π2/a2 + m2π2/b2 sin
nπx
a

sin
mπy
b

,
(15.6.52)
where anm are the Fourier coeﬃcients for the function f(x, y):
anm = 4
ab
Z a
0
Z b
0
f(x, y) sin
nπx
a

sin
mπy
b

dy dx.
(15.6.53)
Another form of the Green’s function can be obtained by considering each direction
separately. To satisfy the boundary conditions along the edges y = 0 and y = b, we write
the Green’s function as the Fourier series
g(x, y|ξ, η) =
∞
X
m=1
Gm(x|ξ) sin
mπy
b

,
(15.6.54)
where the coeﬃcients Gm(x|ξ) are left as undetermined functions of x, ξ, and m. Substi-
tuting this series into the partial diﬀerential equation for g, multiplying by 2 sin(nπy/b)/b,
and integrating over y, we ﬁnd that
d2Gn
dx2 −n2π2
b2 Gn = −2
b sin
nπη
b

δ(x −ξ).
(15.6.55)
This diﬀerential equation shows that the expansion coeﬃcients Gn(x|ξ) are one-dimensional
Green’s functions; we can ﬁnd them, as we did in Section 15.2, by piecing together homo-
geneous solutions to Equation 15.6.55 that are valid over various intervals. For the region
0 ≤x ≤ξ, the solution to this equation that vanishes at x = 0 is
Gn(x|ξ) = An sinh
nπx
b

,
(15.6.56)
where An is presently arbitrary. The corresponding solution for ξ ≤x ≤a is
Gn(x|ξ) = Bn sinh
nπ(a −x)
b

.
(15.6.57)
Note that this solution vanishes at x = a. Because the Green’s function must be continuous
at x = ξ,
An sinh
nπξ
b

= Bn sinh
nπ(a −ξ)
b

.
(15.6.58)
On the other hand, the appropriate jump discontinuity of G′
n(x|ξ) yields
−nπ
b Bn cosh
nπ(a −ξ)
b

−nπ
b An cosh
nπξ
b

= −2
b sin
nπη
b

.
(15.6.59)
Solving for An and Bn,
An = 2
nπ sin
nπη
b
 sinh[nπ(a −ξ)/b]
sinh(nπa/b)
,
(15.6.60)

Green’s Functions
785
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
0.5
 x/b
 y/b
 g(x,y|ξ,η)
Figure 15.6.2: The Green’s function, Equation 15.6.62 or Equation 15.6.63, for the planar Poisson equation
over a rectangular area with Dirichlet boundary conditions on all sides when a = b and ξ/b = η/b = 0.3.
and
Bn = 2
nπ sin
nπη
b
 sinh(nπξ/b)
sinh(nπa/b).
(15.6.61)
This yields the Green’s function
g(x, y|ξ, η) = 2
π
∞
X
n=1
sinh[nπ(a −x>)/b] sinh(nπx</b)
n sinh(nπa/b)
sin
nπη
b

sin
nπy
b

,
(15.6.62)
where x> = max(x, ξ) and x< = min(x, ξ). Figure 15.6.2 illustrates Equation 15.6.62 in
the case of a square domain with ξ/b = η/b = 0.3.
If we began with a Fourier expansion in the y-direction, we would have obtained
g(x, y|ξ, η) = 2
π
∞
X
m=1
sinh[mπ(b −y>)/a] sinh(mπy</a)
m sinh(mπb/a)
sin
mπξ
a

sin
mπx
a

, (15.6.63)
where y> = max(y, η) and y< = min(y, η).
⊓⊔
• Example 15.6.5: Two-dimensional Helmholtz equation over a rectangular domain
The problem to be solved is
∂2g
∂x2 + ∂2g
∂y2 + k2
0g = −δ(x −ξ)δ(y −η),
(15.6.64)
where 0 < x, ξ < a, and 0 < y, η < b, subject to the boundary conditions that
g(0, y|ξ, η) = g(a, y|ξ, η) = g(x, 0|ξ, η) = g(x, b|ξ, η) = 0.
(15.6.65)

786
Advanced Engineering Mathematics with MATLAB
We use the same technique to solve Equation 15.6.64 as we did in the previous example
by assuming that the Green’s function has the form
g(x, y|ξ, η) =
∞
X
m=1
Gm(x|ξ) sin
mπy
b

,
(15.6.66)
where the coeﬃcients Gm(x|ξ) are undetermined functions of x, ξ, and η. Substituting this
series into Equation 15.6.64, multiplying by 2 sin(nπy/b)/b, and integrating over y, we ﬁnd
that
d2Gn
dx2 −
n2π2
b2
−k2
0

Gn = −2
b sin
nπη
b

δ(x −ξ).
(15.6.67)
The ﬁrst method for solving Equation 15.6.67 involves writing
δ(x −ξ) = 2
a
∞
X
m=1
sin
mπξ
a

sin
mπx
a

,
(15.6.68)
and
Gn(x|ξ) = 2
a
∞
X
m=1
anm sin
mπx
a

.
(15.6.69)
Upon substituting Equations 15.6.68 and 15.6.69 into Equation 15.6.67, we obtain
∞
X
m=1

k2
0−m2π2
a2
−n2π2
b2

anm sin
mπx
a

= −4
ab
∞
X
m=1
sin
nπη
b

sin
mπξ
a

sin
mπx
a

.
(15.6.70)
Matching similar harmonics,
anm =
4 sin(mπξ/a) sin(nπη/b)
ab(m2π2/a2 + n2π2/b2 −k2
0),
(15.6.71)
and the bilinear form of the Green’s function is
g(x, y|ξ, η)= 4
ab
∞
X
n=1
∞
X
m=1
sin(mπξ/a) sin(nπη/b) sin(mπx/a) sin(nπy/b)
m2π2/a2 + n2π2/b2 −k2
0
.
(15.6.72)
See Figure 15.6.3. The bilinear form of the Green’s function for the two-dimensional Helm-
holtz equation with Neumann boundary conditions is left as Problem 15.
As in the previous example, we can construct an alternative to the bilinear form of the
Green’s function, Equation 15.6.72, by writing Equation 15.6.67 as
d2Gn
dx2 −k2
nGn = −2
b sin
nπη
b

δ(x −ξ),
(15.6.73)

Green’s Functions
787
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
−1
−0.5
0
0.5
1
 x/a
 y/a
 g(x,y|ξ,η)
Figure 15.6.3: The Green’s function, Equation 15.6.72, for Helmholtz’s equation over a rectangular region
with a Dirichlet boundary condition on the sides when a = b, k0a = 10, and ξ/a = η/a = 0.35.
where k2
n = n2π2/b2 −k2
0. The homogeneous solution to Equation 15.6.73 is now
Gn(x|ξ) =

An sinh(knx),
0 ≤x ≤ξ,
Bn sinh[kn(a −x)],
ξ ≤x ≤a.
(15.6.74)
This solution satisﬁes the boundary conditions at both endpoints.
Because Gn(x|ξ) must be continuous at x = ξ,
An sinh(knξ) = Bn sinh[kn(a −ξ)].
(15.6.75)
On the other hand, the jump discontinuity involving G′
n(x|ξ) yields
−knBn cosh[kn(a −ξ)] −knAn cosh(knξ) = −2
b sin
nπη
b

.
(15.6.76)
Solving for An and Bn,
An =
2
bkn
sin
nπη
b
 sinh[kn(a −ξ)]
sinh(kna)
,
(15.6.77)
and
Bn =
2
bkn
sin
nπη
b
 sinh(knξ)
sinh(kna).
(15.6.78)
This yields the Green’s function
g(x, y|ξ, η) = 2
b
N
X
n=1
sin[κn(a −x>)] sin(κnx<)
κn sin(κna)
sin
nπη
b

sin
nπy
b

+ 2
b
∞
X
n=N+1
sinh[kn(a −x>)] sinh(knx<)
kn sinh(kna)
sin
nπη
b

sin
nπy
b

,
(15.6.79)

788
Advanced Engineering Mathematics with MATLAB
where x> = max(x, ξ) and x< = min(x, ξ). Here N denotes the largest value of n such that
k2
n < 0, and κ2
n = k2
0 −n2π2/b2. If we began with a Fourier expansion in the y direction,
we would have obtained
g(x, y|ξ, η) = 2
a
M
X
m=1
sin[κm(b −y>)] sin(κmy<)
κm sin(κmb)
sin
mπξ
a

sin
mπx
a

+ 2
a
∞
X
m=M+1
sinh[km(b −y>)] sinh(kmy<)
km sinh(kmb)
sin
mπξ
a

sin
mπx
a

,
(15.6.80)
where M denotes the largest value of m such that k2
m < 0, k2
m = m2π2/a2 −k2
0, κ2
m =
k2
0 −m2π2/a2, y< = min(y, η), and y> = max(y, η).
⊓⊔
• Example 15.6.6: Two-dimensional Helmholtz equation over a circular disk
In this example, we ﬁnd the Green’s function for the Helmholtz equation when the
domain consists of the circular region 0 < r < a. The Green’s function is governed by the
partial diﬀerential equation
1
r
∂
∂r

r∂g
∂r

+ 1
r2
∂2g
∂θ2 + k2
0g = −δ(r −ρ)δ(θ −θ′)
r
,
(15.6.81)
where 0 < r, ρ < a, and 0 ≤θ, θ′ ≤2π, with the boundary conditions
lim
r→0 |g(r, θ|ρ, θ′)| < ∞,
g(a, θ|ρ, θ′) = 0,
0 ≤θ, θ′ ≤2π.
(15.6.82)
The Green’s function must be periodic in θ.
We begin by noting that
δ(θ −θ′) = 1
2π + 1
π
∞
X
n=1
cos[n(θ −θ′)] = 1
2π
∞
X
n=−∞
cos[n(θ −θ′)].
(15.6.83)
Therefore, the solution has the form
g(r, θ|ρ, θ′) =
∞
X
n=−∞
gn(r|ρ) cos[n(θ −θ′)].
(15.6.84)
Substituting Equation 15.6.83 and Equation 15.6.84 into Equation 15.6.81 and simplifying,
we ﬁnd that
1
r
d
dr

rdgn
dr

−n2
r2 gn + k2
0gn = −δ(r −ρ)
2πr
.
(15.6.85)
The solution to Equation 15.6.85 is the Fourier-Bessel series
gn(r|ρ) =
∞
X
m=1
AnmJn
knmr
a

,
(15.6.86)
where knm is the mth root of Jn(k) = 0. Upon substituting Equation 15.6.86 into Equation
15.6.85 and solving for Anm, we have that
(k2
0 −k2
nm/a2)Anm = −
1
πa2J′2
n(knm)
Z a
0
δ(r −ρ)Jn
knmr
a

dr,
(15.6.87)

Green’s Functions
789
−1
−0.5
0
0.5
1
−1
−0.5
0
0.5
1
−1
−0.5
0
0.5
1
 x/a
 y/a
 g(r,θ|ρ,θ′)
Figure 15.6.4: The Green’s function, Equation 15.6.89, for Helmholtz’s equation within a circular disk
with a Dirichlet boundary condition on the rim when k0a = 10, ρ/a = 0.35
√
2, and θ′ = π/4.
or
Anm =
Jn(knmρ/a)
π(k2nm −k2
0a2)J′2
n(knm).
(15.6.88)
Thus, the Green’s function25 is
g(r, θ|ρ, θ′) = 1
π
∞
X
n=−∞
∞
X
m=1
Jn(knmρ/a)Jn(knmr/a)
(k2nm −k2
0a2)J′2
n(knm) cos[n(θ −θ′)].
(15.6.89)
See Figure 15.6.4.
Problems
1. Using a Fourier sine expansion in the x-direction, construct the Green’s function governed
by the planar Poisson equation
∂2g
∂x2 + ∂2g
∂y2 = −δ(x −ξ)δ(y −η),
0 < x, ξ < a,
−∞< y, η < ∞,
with the Dirichlet boundary conditions
g(0, y|ξ, η) = g(a, y|ξ, η) = 0,
−∞< y < ∞,
25 For an example of its use, see Zhang, D. R., and C. F. Foo, 1999: Fields analysis in a solid magnetic
toroidal core with circular cross section based on Green’s function. IEEE Trans. Magnetics, 35, 3760–3762.

790
Advanced Engineering Mathematics with MATLAB
and the conditions at inﬁnity that
lim
|y|→∞g(x, y|ξ, η) →0,
0 < x < a.
2. Using a generalized Fourier expansion in the x-direction, construct the Green’s function
governed by the planar Poisson equation
∂2g
∂x2 + ∂2g
∂y2 = −δ(x −ξ)δ(y −η),
0 < x, ξ < a,
−∞< y, η < ∞,
with the Neumann and Dirichlet boundary conditions
gx(0, y|ξ, η) = g(a, y|ξ, η) = 0,
−∞< y < ∞,
and the conditions at inﬁnity that
lim
|y|→∞g(x, y|ξ, η) →0,
0 < x < a.
3. Using a Fourier sine expansion in the y-direction, show that the Green’s function governed
by the planar Poisson equation
∂2g
∂x2 + ∂2g
∂y2 = −δ(x −ξ)δ(y −η),
0 < x, ξ < a,
0 < y, η < b,
with the boundary conditions
g(x, 0|ξ, η) = g(x, b|ξ, η) = 0,
and
g(0, y|ξ, η) = gx(a, y|ξ, η) + β g(a, y|ξ, η) = 0,
β ≥0,
is
g(x, y|ξ, η) =
∞
X
n=1
sinh(νx<) {ν cosh [ν(a −x>)] + β sinh [ν(a −x>)]}
ν2 cosh(νa) + βν sinh(νa)
sin
nπη
b

sin
nπy
b

,
where ν = nπ/b, x> = max(x, ξ), and x< = min(x, ξ).
4. Using the Fourier series representation of the delta function in a circular domain:
δ(θ −θ′) = 1
2π + 1
π
∞
X
n=1
cos[n(θ −θ′)],
0 ≤θ, θ′ ≤2π,
construct the Green’s function governed by the planar Poisson equation
1
r
∂
∂r

r∂g
∂r

+ 1
r2
∂2g
∂θ2 = −δ(r −ρ)δ(θ −θ′)
r
,

Green’s Functions
791
where a < r, ρ < b, and 0 ≤θ, θ′ ≤2π, subject to the boundary conditions g(a, θ|ρ, θ′) =
g(b, θ|ρ, θ′) = 0 and periodicity in θ. You may want to review how to solve the equidimen-
sional equation, Section 2.7.
5. Construct the Green’s function governed by the planar Poisson equation
1
r
∂
∂r

r∂g
∂r

+ 1
r2
∂2g
∂θ2 = −δ(r −ρ)δ(θ −θ′)
r
,
where 0 < r, ρ < ∞, and 0 < θ, θ′ < β, subject to the boundary conditions that g(r, 0|ρ, θ′)
= g(r, β|ρ, θ′) = 0 for all r. Hint:
δ(θ −θ′) = 2
β
∞
X
n=1
sin
nπθ′
β

sin
nπθ
β

.
You may want to review how to solve the equidimensional equation, Section 2.7.
6. Construct the Green’s function governed by the planar Poisson equation
1
r
∂
∂r

r∂g
∂r

+ 1
r2
∂2g
∂θ2 = −δ(r −ρ)δ(θ −θ′)
r
,
where 0 < r, ρ < a, and 0 < θ, θ′ < β, subject to the boundary conditions g(r, 0|ρ, θ′) =
g(r, β|ρ, θ′) = g(a, θ|ρ, θ′) = 0. Hint:
δ(θ −θ′) = 2
β
∞
X
n=1
sin
nπθ′
β

sin
nπθ
β

.
You may want to review how to solve the equidimensional equation, Section 2.7.
7. Using a Fourier sine series in the z-direction and the results from Problem 31 at the end
of Section 6.5, ﬁnd the Green’s function governed by the axisymmetric Poisson equation
∂2g
∂r2 + 1
r
∂g
∂r + ∂2g
∂z2 = −δ(r −ρ)δ(z −ζ)
2πr
,
where 0 < r, ρ < a, and 0 < z, ζ < L, subject to the boundary conditions
g(r, 0|ρ, ζ) = g(r, L|ρ, ζ) = 0,
0 < r < a,
and
lim
r→0 |g(r, z|ρ, ζ)| < ∞,
g(a, z|ρ, ζ) = 0,
0 < z < L.
8. Following Example 15.6.5 except for using Fourier cosine series, construct the Green’s
function26 governed by the planar Helmholtz equation
∂2g
∂x2 + ∂2g
∂y2 + k2
0g = −δ(x −ξ)δ(y −η),
0 < x, ξ < a,
0 < y, η < b,
26 Kulkarni et al. (Kulkarni, S., F. G. Leppington, and E. G. Broadbent, 2001: Vibrations in several
interconnected regions: A comparison of SEA, ray theory and numerical results. Wave Motion, 33, 79–96)
solved this problem when the domain has two diﬀerent, constant k2
0’s.

792
Advanced Engineering Mathematics with MATLAB
subject to the Neumann boundary conditions
gx(0, y|ξ, η) = gx(a, y|ξ, η) = 0,
0 < y < b,
and
gy(x, 0|ξ, η) = gy(x, b|ξ, η) = 0,
0 < x < a.
9. Using Fourier sine transforms,
g(x, y|ξ, η) = 2
π
Z ∞
0
G(k, y|ξ, η) sin(kx) dk,
where
G(k, y|ξ, η) =
Z ∞
0
g(x, y|ξ, η) sin(kx) dx,
ﬁnd the Green’s function governed by
∂2g
∂x2 + ∂2g
∂y2 = −δ(x −ξ)δ(y −η),
for the quarter space 0 < x, y, with the boundary conditions
g(0, y|ξ, η) = g(x, 0|ξ, η) = 0,
and
lim
x,y→∞g(x, y|ξ, η) →0.
Step 1: Taking the Fourier sine transform in the x direction, show that the partial diﬀer-
ential equation reduces to the ordinary diﬀerential equation
d2G
dy2 −k2G = −sin(kξ)δ(y −η),
with the boundary conditions
G(k, 0|ξ, η) = 0,
and
lim
y→∞G(k, y|ξ, η) →0.
Step 2: Show that the particular solution to the ordinary diﬀerential equation in Step 1 is
Gp(k, y|ξ, η) = sin(kξ)
2k
e−k|y−η|.
You may want to review Example 15.2.8.
Step 3: Find the homogeneous solution to the ordinary diﬀerential equation in Step 1 so
that the general solution satisﬁes the boundary conditions. Show that the general solution
is
G(k, y|ξ, η) = sin(kξ)
2k
h
e−k|y−η| −e−k(y+η)i
.

Green’s Functions
793
Step 4: Taking the inverse, show that
g(x, y|ξ, η) = 1
π
Z ∞
0
h
e−k|y−η| −e−k(y+η)i
sin(kξ) sin(kx) dk
k .
Step 5: Performing the integration,27 show that
g(x, y|ξ, η) = −1
4π ln
[(x −ξ)2 + (y −η)2][(x + ξ)2 + (y + η)2]
[(x −ξ)2 + (y + η)2][(x + ξ)2 + (y −η)2]

.
10. Find the free-space Green’s function28 governed by
∂2g
∂x2 + ∂2g
∂y2 −g = −δ(x −ξ)δ(y −η),
−∞< x, y, ξ, η < ∞.
Step 1: Introducing the Fourier transform
g(x, y|ξ, η) = 1
2π
Z ∞
−∞
G(k, y|ξ, η)eikx dk,
where
G(k, y|ξ, η) =
Z ∞
−∞
g(x, y|ξ, η)e−ikx dx,
show that the governing partial diﬀerential equation can be transformed into the ordinary
diﬀerential equation
d2G
dy2 −
 k2 + 1

G = −e−ikξδ(y −η).
Step 2: Introducing the Fourier transform in the y-direction,
G(k, y|ξ, η) = 1
2π
Z ∞
−∞
G(k, ℓ|ξ, η)eiℓy dℓ,
where
G(k, ℓ|ξ, η) =
Z ∞
−∞
G(k, y|ξ, η)e−iℓy dy,
solve the ordinary diﬀerential equation in Step 1 and show that
G(k, y|ξ, η) = e−ikξ
2π
Z ∞
−∞
eiℓ(y−η)
k2 + ℓ2 + 1 dℓ.
27 Gradshteyn, I. S., and I. M. Ryzhik, 1965: Table of Integrals, Series, and Products. Academic Press,
Section 3.947, Formula 1.
28 For its use, see Geisler, J. E., 1970: Linear theory of the response of a two layer ocean to a moving
hurricane. Geophys. Fluid Dyn., 1, 249–272.

794
Advanced Engineering Mathematics with MATLAB
Step 3: Complete the problem by showing that
g(x, y|ξ, η) =
1
4π2
Z ∞
−∞
Z ∞
−∞
eik(x−ξ)eiℓ(y−η)
k2 + ℓ2 + 1
dℓdk
=
1
4π2
Z ∞
0
Z 2π
0
eirκ cos(θ−ϕ)
κ2 + 1
κ dθ dκ
= 1
2π
Z ∞
0
J0(rκ)
κ2 + 1 κ dκ = K0(r)
2π
,
where r =
p
(x −ξ)2 + (y −η)2, k = κ cos(θ), ℓ= κ sin(θ), x −ξ = r cos(ϕ), and y −η =
r sin(ϕ). You may want to review the material around Equation 9.3.73 through Equation
9.3.75. You will need to use integral tables29 to obtain the ﬁnal result.
11. Find the free-space Green’s function governed by
∂2g
∂x2 + ∂2g
∂y2 −∂g
∂x = −δ(x −ξ)δ(y −η),
−∞< x, y, ξ, η < ∞.
Step 1: By introducing ϕ(x, y|ξ, η) such that
g(x, y|ξ, η) = ex/2ϕ(x, y|ξ, η),
show that the partial diﬀerential equation for g(x, y|ξ, η) becomes
∂2ϕ
∂x2 + ∂2ϕ
∂y2 −ϕ
4 = −e−ξ/2δ(x −ξ)δ(y −η).
Step 2: After taking the Fourier transform with respect to x of the partial diﬀerential
equation in Step 1, show that it becomes the ordinary diﬀerential equation
d2Φ
dy2 −
 k2 + 1
4

Φ = −e−ξ/2−ikξδ(y −η).
Step 3: Introducing the same transformation as in Step 3 of the previous problem, show
that
Φ(k, y|ξ, η) = e−ξ/2−ikξ
2π
Z ∞
−∞
eiℓ(y−η)
k2 + ℓ2 + 1
4
dℓ,
and
ϕ(x, y|ξ, η) = e−ξ/2
2π K0( 1
2r),
where r =
p
(x −ξ)2 + (y −η)2.
Step 4: Using the transformation introduced in Step 1, show that
g(x, y|ξ, η) = e(x−ξ)/2
2π
K0( 1
2r).
29 Gradshteyn and Ryzhik, op. cit., Section 6.532, Formula 6.

Green’s Functions
795
15.7 GALERKIN METHOD
In the previous sections we developed various analytic expressions for Green’s functions.
We close this chapter by showing how to construct a numerical approximation.
In Sections 6.9 and 9.8 we showed how ﬁnite elements can be used to solve diﬀerential
equations by introducing subdomains known as ﬁnite elements rather than a grid of nodal
points. The solution is then represented within each element by an interpolating polynomial.
Unlike ﬁnite diﬀerence schemes that are constructed from Taylor expansions, the theory
behind ﬁnite elements introduces concepts from functional analysis and variational methods
to formulate the algebraic equations.
There are several paths that lead to the same ﬁnite element formulation. The two most
common techniques are the Galerkin and collocation methods. In this section we focus on
the Galerkin method. This method employs a rational polynomial, called a basis function,
that satisﬁes the boundary conditions.
We begin by considering the Sturm-Liouville problem governed by
d2ψn
dx2 + λnψn = 0,
0 < x < L,
(15.7.1)
subject to the boundary conditions ψn(0) = ψn(L) = 0.
Although we could solve this
problem exactly, we will pretend that we cannot.
Rather, we will assume that we can
express it by
ψn(x) =
N
X
j=1
αnjfj(x),
(15.7.2)
where fj(x) is our basis function. Clearly, it is desirable that fj(0) = fj(L) = 0.
How do we compute αnj?
We begin by multiplying Equation 15.7.1 by fi(x) and
integrating the resulting equation from 0 and L. This yields
Z L
0
fi(x)d2ψn
dx2 dx + λn
Z L
0
fi(x)ψn(x) dx = 0,
(15.7.3)
where i = 1, 2, 3, . . . , N. Next, we substitute Equation 15.7.2 and ﬁnd that
N
X
j=1
"Z L
0
fi(x)f ′′
j (x) dx + λn
Z L
0
fi(x)fj(x) dx
#
αnj = 0.
(15.7.4)
We can write Equation 15.7.4 as
(A + λnB)d = 0,
(15.7.5)
where
aij =
Z L
0
fi(x)f ′′
j (x) dx = −
Z L
0
f ′
i(x)f ′
j(x) dx,
(15.7.6)
bij =
Z L
0
fi(x)fj(x) dx,
(15.7.7)
and the vector d contains the elements αnj.
There are several obvious choices for fj(x):

796
Advanced Engineering Mathematics with MATLAB
• Example 15.7.1
The simplest choice for fj(x) = sin(jπx/L).
If we select N = 2, Equation 15.7.2
becomes
ψn(x) = αn1 sin
πx
L

+ αn2 sin
2πx
L

.
(15.7.8)
From Equation 15.7.6 and Equation 15.7.7,
aij = −
jπ
L
2 Z L
0
sin
iπx
L

sin
jπx
L

dx,
i = 1, 2, j = 1, 2;
(15.7.9)
and
bij =
Z L
0
sin
iπx
L

sin
jπx
L

dx,
i = 1, 2, j = 1, 2.
(15.7.10)
Performing the integrations, a12 = a21 = b12 = b21 = 0, a11 = −π2/(2L), a22 = −2π2/L,
and b11 = b22 = L/2.
Returning to Equation 15.7.5, it becomes

−π2/2 + λnL2/2
0
0
−2π2 + λnL2/2
 
αn1
αn2

=

0
0

.
(15.7.11)
In order for Equation 15.7.11 to have a unique solution,

−π2/2 + λnL2/2
0
0
−2π2 + λnL2/2
 = 0.
(15.7.12)
Equation 15.7.12 yields 4λ1 = λ2 = 4π2/L2.
In summary,
ψ1(x) = sin(πx/L),
λ1 = π2/L2;
(15.7.13)
and
ψ2(x) = sin(2πx/L),
λ2 = 4π2/L2,
(15.7.14)
with α12 = α21 = 0. Here we have chosen that α11 = α22 = 1.
⊓⊔
• Example 15.7.2
Another possible choice for fj(x) involves polynomials of the form (1 −x/L)(x/L)j
with j = 1, 2. Unlike the previous example, we have nonorthogonal basis functions here.
Note that fj(0) = fj(L) = 0. Therefore, Equation 15.7.2 becomes
ψn(x) = αn1(1 −x/L)(x/L) + αn2(1 −x/L)(x/L)2.
(15.7.15)
From Equation 15.7.6 and Equation 15.7.7,
aij = −1
L2
Z L
0

1 −x
L
  x
L
i 
j(j −1)
 x
L
j−2
−j(j + 1)
 x
L
j−1
dx
(15.7.16)
= 1
L
 j(j −1)
i + j −1 −j(j −1)
i + j
−j(j + 1)
i + j
+ j(j + 1)
i + j + 1

,
(15.7.17)

Green’s Functions
797
with i = 1, 2 and j = 1, 2. Similarly,
bij =
Z L
0

1 −x
L
  x
L
i 
1 −x
L
  x
L
j
dx
(15.7.18)
= L

1
i + j + 1 −
2
i + j + 2 +
1
i + j + 3

.
(15.7.19)
Performing the computations, a11 = −1/(3L), a12 = a21 = −1/(6L), a22 = −2/(15L),
b11 = L/30, b12 = b21 = L/60, and b22 = L/105.
Returning to Equation 15.7.5, it becomes

−1/3 + λnL2/30
−1/6 + λnL2/60
−1/6 + λnL2/60
−2/15 + λnL2/105
 
αn1
αn2

=

0
0

.
(15.7.20)
In order for Equation 15.7.20 to have a unique solution,

−1/3 + λnL2/30
−1/6 + λnL2/60
−1/6 + λnL2/60
−2/15 + λnL2/105
 = 0.
(15.7.21)
Equation 15.7.21 yields λ1L2 = 10 and λ2L2 = 42. Note how close these values of λ are to
those found in the previous example. Returning to Equation 15.7.20, we ﬁnd that α11 = 1,
α12 = 0, α22 = 1, and α21 = −1/2.
In summary,
ψ1(x) =

1 −x
L
 x
L,
λ1 = 10
L2 ;
(15.7.22)
and
ψ2(x) = −1
2

1 −x
L
 x
L +

1 −x
L
  x
L
2
,
λ2 = 42
L2 .
(15.7.23)
Because fj(x) are linearly independent, their use in the Galerkin expansion is quite ac-
ceptable. However, because these functions are not particularly orthogonal, their usefulness
will become more diﬃcult as N increases. Consequently, the choice of orthogonal functions
is often best.
⊓⊔
How do we employ the Galerkin technique to approximate Green’s functions? We begin
by considering the inhomogeneous heat conduction problem:
∂u
∂t −∂2u
∂x2 = F(x, t),
0 < x < L,
0 < t,
(15.7.24)
with the boundary conditions
u(0, t) = u(L, t) = 0,
0 < t,
(15.7.25)
and the initial condition u(x, 0) = 0, 0 < x < L.
Let us write the solution to this problem as
u(x, t) =
N
X
n=1
cn(t)ψn(x)e−λnt.
(15.7.26)

798
Advanced Engineering Mathematics with MATLAB
Direct substitution of Equation 15.7.26 into Equation 15.7.24, followed by multiplying the
resulting equation by fi(x) and integrating from 0 to L, gives
N
X
n=1
cn(t)e−λnt
Z L
0
fi(x)d2ψn
dx2 dx −
N
X
n=1
dcn
dt −λncn

e−λnt
Z L
0
fi(x)ψn(x) dx
= −
Z L
0
fi(x)F(x, t) dx.
(15.7.27)
Because
d2ψn
dx2 + λnψn = 0,
(15.7.28)
Equation 15.7.27 simpliﬁes to
N
X
n=1
dcn
dt e−λnt
Z L
0
fi(x)ψn(x) dx =
Z L
0
fi(x)F(x, t) dx = F ∗
i (t),
(15.7.29)
where i = 1, 2, . . . , N.
We must now ﬁnd cn. We can write Equation 15.7.29 as
N
X
n=1
eine−λnt dcn
dt dx = F ∗
i (t),
(15.7.30)
where
ein =
N
X
j=1
αnjbji.
(15.7.31)
Using linear algebra, we ﬁnd that
e−λnt dcn
dt =
N
X
i=1
pniF ∗
i (t),
(15.7.32)
where pni are the elements of an array P = E−1 and E = (DB)T . The arrays D and B
consist of elements αij and bij, respectively. Solving Equation 15.7.32, we ﬁnd that
cn(t) = An +
N
X
i=1
pni
Z t
0
F ∗
i (η)eλnη dη.
(15.7.33)
Because u(x, 0) = 0, cn(0) = 0 and An = 0.
We are now ready to ﬁnd our Green’s function. Let us set F(x, t) = δ(x −ξ)δ(t −τ).
Then F ∗
i (t) = fi(ξ)δ(t −τ) and
cn(t) = H(t −τ)
N
X
i=1
pnifi(ξ)eλnτ.
(15.7.34)
From Equation 15.7.2, Equation 15.7.26, and Equation 15.7.34, we obtain the ﬁnal result
that
g(x, t|ξ, τ) = H(t −τ)
N
X
n=1
N
X
j=1
N
X
i=1
αnjpnifi(ξ)fj(x)e−λn(t−τ).
(15.7.35)

Green’s Functions
799
⊓⊔
• Example 15.7.3
In Example 15.5.2, we solved the Green’s function problem:
∂g
∂t −∂2g
∂x2 = δ(x −ξ)δ(t −τ),
(15.7.36)
with the boundary condition
g(0, t|ξ, τ) = g(L, t|ξ, τ) = 0,
(15.7.37)
and the initial condition g(x, 0|ξ, τ) = 0. There we found the solution (Equation 15.5.34):
g(x, t|ξ, τ) = H(t −τ)
∞
X
n=1
ψn(ξ)ψn(x)e−k2
n(t−τ),
(15.7.38)
where we have the orthonormal eigenfunctions
ψn(x) =
p
2/L sin(knx),
kn = nπ/L.
(15.7.39)
Let us use the basis function fj(x) = (1 −x/L)(x/L)j to ﬁnd the approximate Green’s
function to Equation 15.7.36. Here j = 1, 2, 3, . . . , N,
For N = 2, we showed in Example 15.7.2 that
B = L

1/30
1/60
1/60
1/105

,
D =

1
0
−1/2
1

.
(15.7.40)
Consequently,
BD =
L
840

28
14
0
1

,
E =
L
840

28
0
14
1

.
(15.7.41)
Using Gaussian elimination,
P = E−1 = 1
L

30
0
−420
840

.
(15.7.42)
Therefore, the two-term approximation to the Green’s function, Equation 15.7.38, is
g(x, t|ξ, τ) = 30
L
x
L

1 −x
L
 ξ
L

1 −ξ
L

exp

−10(t −τ)
L2

H(t −τ)
+
210
L
x
L

1 −x
L
 ξ
L

1 −ξ
L

−420
L
x
L

1 −x
L
  ξ
L
2 
1 −ξ
L

−420
L
 x
L
2 
1 −x
L
 ξ
L

1 −ξ
L

+ 840
L
 x
L
2 
1 −x
L
  ξ
L
2 
1 −ξ
L

× exp

−42(t −τ)
L2

H(t −τ).
(15.7.43)
For N > 2, hand computations are very cumbersome and numerical computations are
necessary. For a speciﬁc N, we ﬁrst compute the arrays A and B via Equation 15.7.17 and
Equation 15.7.19.

800
Advanced Engineering Mathematics with MATLAB
Table 15.7.1: The Value of L2λn for n = 1, 2, . . . , N as a Function of N.
n
Exact
N = 2
N = 3
N = 4
N = 6
N = 8
N = 10
1
9.87
10.00
9.87
9.87
9.87
9.87
9.87
2
39.48
42.00
42.00
39.50
39.48
39.48
39.48
3
88.83
102.13
102.13
89.17
88.83
88.83
4
157.91
200.50
159.99
157.96
157.91
5
246.74
350.96
254.42
247.04
6
355.31
570.53
376.47
356.65
7
483.61
878.88
531.55
8
631.65
1298.03
725.34
9
799.44
1850.98
10
986.96
2548.73
for j = 1:N
for i = 1:N
A(i,j) = j*(j-1)/(i+j-1) - j*(j-1)/(i+j) ...
+ j*(j+1)/(i+j+1) - j*(j+1)/(i+j) ;
B(i,j) = 1/(i+j+1) - 2/(i+j+2) + 1/(i+j+3);
end; end
Next we compute the λn’s and corresponding eigenfunctions: [v,d] = eig(A,-B).
Table 15.7.1 gives L2λn for several values of N.
Once we found the eigenvalues and eigenvectors, we now compute the matrices D, E,
and P. For convenience we have reordered the eigenvalues so that their numerical value
increases with n. Furthermore, we have set αnn equal to one for n = 1, 2, . . . , N.
[lambda,ix] = sort(temp);
for i = 1:N
for j = 1:N
D(i,j) = v(j,ix(i));
end; end
for i = 1:N
denom = D(i,i);
for j = 1:N
D(i,j) = D(i,j) / denom;
end; end
E = transpose(D*B);
P = inv(E);
Having computed the matrices D and P, our ﬁnal task is the computation of the
Green’s function using Equation 15.7.35. The MATLAB code is:
phi i(1) = (1-xi)*xi;
for i = 2:N
phi i(i) = xi*phi i(i-1);
end
for ii = 1:idim
x = (ii-1)*dx;
phi j(1) = (1-x)*x;

Green’s Functions
801
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
−2
0
2
4
6
8
10
x/L
L g(x,t|ξ,τ)
exact
N = 3
N = 6
N = 9
N = 12
Figure 15.7.1: Comparison of the exact Green’s function Lg(x, t|ξ, τ) for a one-dimensional heat equation
given by Equation 15.7.38 (solid line) and approximate Green’s functions found by the Galerkin method for
diﬀerent values of N. Here (t −τ)/L2 = 0.001 and ξ = 0.4.
for j = 2:N
phi j(j) = x*phi j(j-1);
end
for n = 1:N
for j = 1:N
for i = 1:N
g(ii) = g(ii) + D(n,j).*P(n,i).*phi j(j).*phi i(i) ...
.*exp(-lambda(n)*time);
end; end; end
end
In this code the parameter time denotes the quantity (t−τ)/L2. Figure 15.7.1 compares
this approximate Green’s function for various N against the exact solution. One of the
problems with this method is ﬁnding the inverse of the array E.
As N increases, the
accuracy of the inverse becomes poorer.
Further Readings
Beck, J. V., K. D. Cole, A. Haji-Sheikh, and B. Litkouhi, 1992: Heat Conduction Using
Green’s Functions. Hemisphere Publishing Corp., 523 pp. Detailed study of solving heat
conduction problems via Green’s functions.
Carslaw, H. S., and J. C. Jaeger, 1959: Conduction of Heat in Solids. Oxford University
Press, Chapter 14. An early classic for ﬁnding the Green’s function for the heat equation.

802
Advanced Engineering Mathematics with MATLAB
Duﬀy, D. G., 2015: Green’s Functions with Applications. Chapman & Hall/ CRC, 464 pp.
A source book.
¨Ozi¸sik, M. N., 1993: Heat Conduction. John Wiley & Sons, Chapter 6. A book of how to
solve partial diﬀerential equations of heat conduction.
Stakgold, I., 1997: Green’s Functions and Boundary Value Problems. Wiley-Interscience,
720 pp. A systematic approach to boundary-value problems.

Chapter 16
Probability
So far in this book we presented mathematical techniques that are used to solve deter-
ministic problems - problems in which the underlying physical processes are known exactly.
In this and the next chapter we turn to problems in which uncertainty is key.
Although probability theory was ﬁrst developed to explain the behavior of games of
chance,1 its usefulness in the physical sciences and engineering became apparent by the late
nineteenth century. Consider, for example, the biological process of birth and death that
we treated in Example 1.2.9. If b denotes the birth rate and d is the death rate, the size of
the population P(t) at time t is
P(t) = P(0)e(b−d)t.
(16.0.1)
Let us examine the situation when P(0) = 1 and b = 2d so that a birth is twice as likely
to occur as a death. Then, Equation 16.0.1 predicts exponential growth with P(t) = edt.
But the ﬁrst event may be a death, a one-in-three chance since d/(b + d) = 1/3, and this
would result in the population immediately becoming extinct. Consequently we see that
for small populations, chance ﬂuctuations become important and a deterministic model is
inadequate.
The purpose of this and the next chapter is to introduce mathematical techniques that
will lead to realistic models where chance plays an important role, and show under what
conditions deterministic models will work. In this chapter we present those concepts that
we will need in the next chapter to explain random processes.
1 Todhunter, I., 1949: A History of the Mathematical Theory of Probability From the Time of Pascal
to That of Laplace. Chelsea, 624 pp.; Hald, A., 1990: A History of Probability and Statistics and Their
Applications before 1750. John Wiley & Sons, 586 pp.
803

804
Advanced Engineering Mathematics with MATLAB
16.1 REVIEW OF SET THEORY
Often we must count various objects in order to compute a probability. Sets provide a
formal method to aid in these computations. Here we review important concepts from set
theory.
Sets are collections of objects, such as the number of undergraduate students at a
college. We deﬁne a set A either by naming the objects or describing the objects. For
example, the set of natural numbers can be either enumerated:
A = {1, 2, 3, 4, . . .},
(16.1.1)
or described:
A = {I : I is an integer and I ≥1}.
(16.1.2)
Each object in set A is called an element and each element is distinct. Furthermore, the
ordering of the elements within the set is not important.
Two sets are said to be equal if they contain the same elements and are written A = B.
An element x of a set A is denoted by x ∈A. A set with no elements is called a empty
or null set and denoted by ∅. On the other hand, a universal set is the set of all elements
under consideration.
A set B is subset of a set A, written B ⊂A, if every element in B is also an element
of A. For example, if A = {x : 0 ≤x < ∞} and S = {x : −∞< x < ∞}, then A ⊂S.
We can also use this concept to deﬁne the equality of sets A and B. Equality occurs when
A ⊂B and B ⊂A.
The complement of A, written A, is the set of elements in S but not in A. For example,
if A = {x : 0 ≤x < ∞} and S = {x : −∞< x < ∞}, then A = {x : −∞< x < 0}.
Two sets can be combined together to form a new set. This union of A and B, written
A ∪B, creates a new set that contains elements that belong to A and/or B. This deﬁnition
can be extended to multiple sets A1, A2, . . . , AN so that the union is the set of elements for
which each element belongs to at least one of these sets. It is written
A1 ∪A2 ∪A3 ∪· · · ∪AN =
N
[
i=1
Ai.
(16.1.3)
The intersection of sets A and B, written A ∩B, is deﬁned as the set of elements that
belong to both A and B. This deﬁnition can also be extended to multiple sets A1, A2, . . . , AN
so that the intersection is the set of elements for which each element belongs to all of these
sets. It is written
A1 ∩A2 ∩A3 ∩· · · ∩AN =
N
\
i=1
Ai.
(16.1.4)
If two sets A and B have no elements in common, they are said to be disjoint and A∩B = ∅.
A popular tool for visualizing set operations is the Venn diagram.2 For sets A and B
Figure 16.1.1 pictorially illustrates A ∪B, A ∩B, A, and A ∩B.
With these deﬁnitions a number of results follow: A = A, A ∪A = S, A ∩A = ∅,
A ∪∅= A, A ∩∅= ∅, A ∪S = S, A ∩S = A, S = ∅, and ∅= S. Here S denotes the
universal set.
Sets obey various rules similar to those encountered in algebra. They include:
2 Venn, J., 2008: Symbolic Logic. Kessinger, 492 pp.

Probability
805
                                                                                                                                                         
















                                                                                                                                















                                                                                                                                                                                              


















                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                























                        











S
S
S
S
A
B
A
B
A
B
Shaded area:
Shaded area:
B
U
A
Shaded area:
B
A
Shaded area:
A
B
U
U
A
A
Figure 16.1.1: Examples of Venn diagrams for various conﬁgurations of sets A and B. Note that in the
case of the lower right diagram, B ⊂A.
1. Commutative properties: A ∪B = B ∪A,
A ∩B = B ∩A.
2. Associate properties: A ∪(B ∪C) = (A ∪B) ∪C,
A ∩(B ∩C) = (A ∩B) ∩C.
3. Distributive properties: A∩(B∪C) = (A∩B)∪(A∩C),
A∪(B∩C) = (A∪B)∩(A∪C).
4. De Morgan’s law: A ∪B = A ∩B.
Finally we deﬁne the size of a set.
Discrete sets may have a ﬁnite number of el-
ements or countably inﬁnite number of elements.
By countably inﬁnite we mean that
we could in theory count the number of elements in the sets. Two simple examples are
A = {1, 2, 3, 4, 5, 6} and A = {1, 4, 16, 64, . . .}. Discrete sets lie in opposition to continuous
sets where the elements are inﬁnite in number and cannot be counted. A simple example
is A = {x : 0 ≤x ≤2}.
Problems
1. If B ⊂A, use Venn diagrams to show that A = B ∪(B ∩A) and B ∩(B ∩A) = ∅. Hint:
Use the Venn diagram in the lower right frame of Figure 16.1.1.
2. Using Venn diagrams, show that A ∪B = A ∪(A ∩B) and B = (A ∩B) ∪(A ∩B). Hint:
For A ∩B, use the upper right frame from Figure 16.1.1.
16.2 CLASSIC PROBABILITY
All questions of probability begin with the concept of an experiment where the governing
principle is chance. The set of all possible outcomes of a random experiment is called the
sample space (or universal set); we shall denote it by S. An element of S is called a sample
point. The number of elements in S can be ﬁnite as in the ﬂipping of a coin twice, inﬁnite
but countable such as repeatedly tossing a coin and counting the number of heads, or inﬁnite
and uncountable, as measuring the lifetime of a light bulb.

806
Advanced Engineering Mathematics with MATLAB
Any subset of the sample set S is called an event. If this event contains a single point,
then the event is elementary or simple.
• Example 16.2.1
Consider an experiment that consists of two steps. In the ﬁrst step, a die is tossed. If
the number of dots on the top of the die is even, a coin is ﬂipped; if the number of dots on
the die is odd, a ball is selected from a box containing blue and green balls. The sample
space is S = {1B, 1G, 2H, 2T, 3B, 3G, 4H, 4T, 5B, 5G, 6H, 6T}. The event A of obtaining a
blue ball is A = {1B, 3B, 5B}, of obtaining a green ball is B = {1G, 3G, 5G}, and obtaining
an even number of dots when the die is tossed is C = {2H, 2T, 4H, 4T, 6H, 6T}. The simple
event of obtaining a 1 on the die and a blue ball is D = {1B}.
⊓⊔
Equally likely outcomes
An important class of probability problems consists of those whose outcomes are equally
likely. This expression “equally likely” is essentially an intuitive one. For example, if a coin
is tossed it seems reasonable that the coin is just as likely to fall “heads” as to fall “tails.”
Probability seeks to quantify this common sense.
Consider a sample space S of an experiment that consists of ﬁnitely many outcomes
that are equally likely. Then the probability of an event A is
P(A) = Number of points in A
Number of points in S .
(16.2.1)
With this simple deﬁnition we are ready to do some simple problems. An important aid
in our counting is whether we can count a particular sample only once (sampling without
replacement) or repeatedly (sampling with replacement). The following examples illustrate
both cases.
• Example 16.2.2: Balls drawn from urns with replacement
Imagine the situation where we have an urn that has k red balls and N −k black balls.
A classic problem asks: What is the chance of two balls being drawn, one after another
with replacement, where the ﬁrst ball is red and the second one is black?
We begin by labeling the k red balls with 1, 2, 3, . . . , k and black balls are numbered
k + 1, k + 2, . . . , N. The possible outcomes of the experiment can be written as a 2-tuple
(z1, z2), where z1 ∈1, 2, 3, . . . , N and z2 ∈1, 2, 3, . . . , N. A successful outcome is a red ball
followed by a black one; we can express this case by E = {(z1, z2) : z1 = 1, 2, . . . , k; z2 =
k + 1, k + 2, . . . , N}. Now the total number of 2-tuples in the sample space is N 2 while the
total number of 2-tuples in E is k(N −k). Therefore, the probability is
P(E) = k(N −k)
N 2
= p(1 −p),
(16.2.2)
where p = k/N.
⊓⊔

Probability
807
• Example 16.2.3: Balls drawn from urns without replacement
Let us redo the previous example where the same ball now cannot be chosen twice. We
can express this mathematically by the condition z1 ̸= z2. The sample space has N(N −1)
balls and the number of successful 2-tuples is again k(N −k). The probability is therefore
given by
P(E) = k(N −k)
N(N −1) = k
N
N −k
N
N
N −1 = p(1 −p)
N
N −1.
(16.2.3)
The restriction that we cannot replace the original ball has resulted in a higher probability.
Why? We have reduced the number of red balls and thereby reduced the chance that we
again selected another red ball while the situation with the black balls remains unchanged.
⊓⊔
• Example 16.2.4: The birthday problem3
A classic problem in probability is: What is the chance that at least two individuals
share the same birthday in a crowd of n people? Actually it is easier to solve the comple-
mentary problem: What is the chance that no one in a crowd of n individuals shares the
same birthday?
For simplicity let us assume that there are only 365 days in the year. Each individual
then has a birthday on one of these 365 days. Therefore, there are a total of (365)n possible
outcomes in a given crowd.
Consider now each individual separately. The ﬁrst person has a birthday on one of 365
days. The second person, who cannot have the same birthday, has one of the remaining
364 days. Therefore, if A denotes the event that no two people have the same birthday and
each outcome is equally likely, then
P(A) = n(A)
n(S) = (365)(364) · · · (365 −n + 1)
(365)n
.
(16.2.4)
To solve the original question, we note that P(A) = 1 −P(A) where P(A) denotes the
probability that at least two individuals share the same birthday.
If n = 50, P(A) ≈0.03 and P(A) ≈0.97. On the other hand, if n = 23, P(A) ≈0.493
and P(A) ≈0.507. Figure 16.2.1 illustrates P(A) as a function of n. Nymann4 computed
the probability that in a group of n people, at least one pair will have the same birthday
with at least one such pair among the ﬁrst k people.
⊓⊔
In the previous examples we counted the objects in sets A and S. Sometimes we can
deﬁne these sets only as areas on a graph. This graphical deﬁnition of probability is
P(A) = Area covered by set A
Area covered by set S .
(16.2.5)
The following example illustrates this deﬁnition.
3 First posed by von Mises, R., 1939: ¨Uber Aufteilungs- und Besetzungswahrscheinlichkeiten. Rev. Fac.
Sci. Istambul, 4, 145–163.
4 Nymann, J. E., 1975: Another generalization of the birthday problem. Math. Mag., 53, 111–125.

808
Advanced Engineering Mathematics with MATLAB
0
10
20
30
40
50
60
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Number of people in crowd
Probability of shared birthdays
Figure 16.2.1: The probability that a pair of individuals in a crowd of n people share the same birthday.
t
t
T
T
t
τ
2
1
Figure 16.2.2: The graphical solution of whether two fellows can chat online between noon and T minutes
after noon. The shaded area denotes the cases when the two will both be online whereas the rectangle gives
the sample space.
• Example 16.2.5
Two friends, Joe and Dave, want to chat online but they will log on independently
between noon and T minutes after noon. Because of their schedules Joe can only wait
t minutes after his log-on while Dave can only spare τ minutes. Neither fellow can stay
beyond T minutes after noon. What is the chance that they will chat?
Let us denote Joe’s log-on time by t1 and Dave’s log-on time by t2. Joe and Dave will
chat if 0 < t2 −t1 < t and 0 < t1 −t2 < τ. In Figure 16.2.2 we show the situation where
these inequalities are both satisﬁed. The area of the sample space is T 2. Therefore, from
the geometrical deﬁnition of probability, the probability P(A) that they will chat is
P(A) = T 2 −(T −t)2/2 −(T −τ)2/2
T 2
.
(16.2.6)
⊓⊔

Probability
809
                                                                                                                                















                                    











S
B
A
B
S
B
A
Shaded area:
B
A
Shaded area:
U
U
A
Figure 16.2.3: The Venn diagram used in the derivation of Property 5.
So far there has been a single event that interests us and we have only had to compute
P(A). Suppose we now have two events that we wish to follow. How are the probabilities
P(A) and P(B) related?
Consider the case of ﬂipping a coin. We could deﬁne event A as obtaining a head, A =
{head}. Event B could be obtaining a tail, B = {tail}. Clearly A ∪B = {head, tail} = S,
the sample space. Furthermore, A∩B = ∅and A and B are mutually exclusive. We already
know that P(A) = P(B) = 1
2. But what happens if A ∩B is not an empty set?
From our deﬁnition of probability and previous examples, we introduce the following
three basic axions:
Axion 1: P(A), P(B) ≥0,
Axion 2: P(S) = 1,
Axion 3: P(A ∪B) = P(A) + P(B) if A ∩B = ∅.
The ﬁrst two axions are clearly true from the deﬁnition of probability and sample space.
It is the third axion that needs some attention. Here we have two mutually exclusive events
A and B in the sample space S. Because the number of points in A ∪B equals the number
of points in A plus the number of points in B, n(A∪B) = n(A)+n(B). Dividing both sides
of this equation by the number of sample points and applying Equation 16.2.1, we obtain
Axion 3 when A ∩B = ∅.
From these three axioms, the following properties can be written down:

810
Advanced Engineering Mathematics with MATLAB
                                                                                                                                                                                                                                                                                                                                                                                                                                    





























S
A
B
A
B
U
U
A
B
Figure 16.2.4: The Venn diagram that shows that A = (A ∩B) ∪(A ∩B).
1. P(A) = 1 −P(A)
2. P(∅) = 0
3. P(A) ≤P(B) if A ⊂B
4. P(A) ≤1
5. P(A ∪B) + P(A ∩B) = P(A) + P(B).
All of these properties follow readily from our deﬁnition of probability except for Prop-
erty 5 and this is an important one. To prove this property from Axion 3, consider the
Venn diagram shown in Figure 16.2.3. From this ﬁgure we see that
A ∪B = A ∪(A ∩B)
and
B = (A ∩B) ∪(A ∩B).
(16.2.7)
From Axion 3, we have that
P(A ∪B) = P(A) + P(A ∩B),
(16.2.8)
and
P(B) = P(A ∩B) + P(A ∩B).
(16.2.9)
Eliminating P(A ∩B) between Equation 16.2.8 and Equation 16.2.9, we obtain Property 5.
The following example illustrates a probability problem with two events A and B.
• Example 16.2.6
Consider Figure 16.2.4. From this ﬁgure, we see that A = (A ∩B) ∪(A ∩B). Because
A ∩B and A ∩B are mutually exclusive, then from Axion 3 we have that
P(A) = P(A ∩B) + P(A ∩B).
(16.2.10)
⊓⊔
• Example 16.2.7
A company has 400 employees. Every quarter, 100 of them are tested for drugs. The
company’s policy is to test everyone at random, whether they have been previously tested
or not. What is the chance that someone is not tested?
The chance that someone will be tested is 1/4. Therefore, the chance that someone
will not be tested is 1 −1/4 = 3/4.
⊓⊔

Probability
811
Permutations and combinations
By now it should be evident that your success at computing probabilities lies in correctly
counting the objects in a given set. Here we examine two important concepts for systemic
counting: permutations and combinations.
A permutation consists of ordering n objects without any regard to their order. For
example, the six permutations of the three letters a, b, and c are abc, acb, bac, bca, cab, and
cba. The number of permutations equals n!.
In a combination of given objects we select one or more objects without regard to their
order. There are two types of combinations: (1) n diﬀerent objects, taken k at a time,
without repetition, and (2) n diﬀerent objects, taken k at a time, with repetitions. In the
ﬁrst case, the number of sets that can be made up from n objects, each set containing k
diﬀerent objects and no two sets containing exactly the same k things, equals
number of diﬀerent combinations =

n
k

≡
n!
k!(n −k)!.
(16.2.11)
Using the three letters a, b, and c, there are three combinations, taken two letters at a time,
without repetition: ab, ac, and bc.
In the second case, the number of sets, consisting of k objects chosen from the n objects
and each being used as often as desired, is
number of diﬀerent combinations =

n + k −1
k

.
(16.2.12)
Returning to our example using three letters, there are six combinations with repetitions:
ab, ac, bc, aa, bb, and cc.
• Example 16.2.8
An urn contains r red balls and b blue balls. If a random sample of size m is chosen,
what is the probability that it contains exactly k red balls?
If we choose a random sample of size m, we obtain

r + b
m

possible outcomes. The
number of samples that includes k red balls and m−k blue balls is

r
k
 
b
m −k

. There-
fore, the probability that a sample of size m contains exactly k red balls is

r
k
 
b
m −k


r + b
m

.
⊓⊔
• Example 16.2.9
A dog kennel has 50 dogs, including 5 German shepherds. (a) What is the probability of
choosing 3 German shepherds if 10 dogs are randomly selected? (b) What is the probability
of choosing all of the German shepherds in a group of 10 dogs that is chosen at random?

812
Advanced Engineering Mathematics with MATLAB
Let S denote the sample space of groups of 10 dogs. The number of those groups
is n(S) = 50!/(10!40!).
Let Ai denote the set of 10 dogs that contain i German shep-
herds. Then the number of groups of 10 dogs that contain i German shepherds is n(Ai) =
10!/[i!(10 −i)!]. Therefore, the probability that out of 50 dogs, we can select at random 10
dogs that include i German shepherds is
P(Ai) = n(Ai)
n(S) =
10!10!40!
i!(10 −i)!50!.
(16.2.13)
Thus, P(A3) = 1.1682 × 10−8 and P(A5) = 2.453 × 10−8.
⊓⊔
• Example 16.2.10
Consider an urn with n red balls and n blue balls inside. Let R = {r1, r2, . . . , rn} and
B = {b1, b2, . . . , bn}. Then the number of subsets of R ∪B with n elements is

2n
n

. On
the other hand, any subset of R∪B with n elements can be written as the union of a subset
of R with i elements and a subset of B with n −i elements for some 0 ≤i ≤n. Because,
for each i, there are

n
i
 
n
n −i

such subsets, the total number of subsets of red and
blue balls with n elements equals Pn
i=0

n
i
 
n
n −i

. Since both approaches must be
equivalent,

2n
n

=
n
X
i=0

n
i
 
n
n −i

=
n
X
i=0

n
i
2
(16.2.14)
because

n
n −i

=

n
i

.
⊓⊔
Conditional probability
Often we are interested in the probability of an event A provided event B occurs.
Denoting this conditional probability by P(A|B), its probability is given by
P(A|B) = P(A ∩B)
P(B)
,
P(B) > 0,
(16.2.15)
where P(A ∩B) is the joint probability of A and B. Similarly,
P(B|A) = P(A ∩B)
P(A)
,
P(A) > 0.
(16.2.16)
Therefore,
P(A ∩B) = P(A|B)P(B) = P(B|A)P(A),
(16.2.17)
and we obtain the famous Bayes’ rule
P(A|B) = P(B|A)P(A)
P(B)
.
(16.2.18)

Probability
813
• Example 16.2.11
Consider a box containing 10 pencils. Three of the pencils are defective with broken
lead. If we draw 2 pencils out at random, what is the chance that we will have selected
nondefective pencils?
There are two possible ways of selecting our two pencils: with and without replacement.
Let Event A be that the ﬁrst pencil is not defective and Event B be that the second pencil
is not defective. Regardless of whether we replace the ﬁrst pencil or not, P(A) =
7
10 because
each pencil is equally likely to be picked. If we then replace the ﬁrst pencil, we have the
same situation before any selection was made and P(B|A) = P(A) =
7
10. Therefore,
P(A ∩B) = P(A)P(B|A) = 0.49.
(16.2.19)
On the other hand, if we do not replace the ﬁrst selected pencil, P(B|A) = 6
9 because
there is one fewer nondefective pencil. Consequently,
P(A ∩B) = P(A)P(B|A) = 7
10 × 6
9 = 14
30 < 0.49.
(16.2.20)
Why do we have a better chance of obtaining defective pencils if we don’t replace the
ﬁrst one? Our removal of that ﬁrst, nondefective pencil has reduced the uncertainty because
we know that there are relatively more defective pencils in the remaining 9 pencils. This
reduction in uncertainty must be reﬂected in a reduction in the chances that both selected
pencils will be nondefective.
⊓⊔
Law of total probability
Conditional probabilities are useful because they allow us to simplify probability cal-
culations. Suppose we have n mutually exclusive events A1, A2, . . . , An whose probabilities
sum to unity, then
P(B) = P(B|A1)P(A1) + P(B|A2)P(A2) + · · · + P(B|An)P(An),
(16.2.21)
where B is an arbitrary event, and P(B|Ai) is the conditional probability of B assuming
Ai. In other words, the law (or formula) of total probability expresses the total probability
of an outcome that can be realized via several distinct events.
• Example 16.2.12
There are three boxes, each containing a diﬀerent number of light bulbs. The ﬁrst box
has 10 bulbs, of which 4 are dead. The second has 6 bulbs, of which one is dead. Finally,
there is a third box of eight bulbs, of which 3 bulbs are dead. What is the probability of
choosing a dead bulb if a bulb is randomly chosen from one of the three boxes?
The probability of choosing a dead bulb is
P(D) = P(D|B1)P(B1) + P(D|B2)P(B2) + P(D|B3)P(B3)
(16.2.22)
=
1
3
  4
10

+
1
3
 1
6

+
1
3
 3
8

= 113
360.
(16.2.23)

814
Advanced Engineering Mathematics with MATLAB
If we had only one box with a total 24 bulbs, of which 8 were dead, then our chance of
choosing a dead bulb would be 1/3 > 113/360.
⊓⊔
Independent events
If events A and B satisfy the equation
P(A ∩B) = P(A)P(B),
(16.2.24)
they are called independent events. From Equation 16.2.15 and Equation 16.2.16, we see
that if Equation 16.2.24 holds, then
P(A|B) = P(A),
P(B|A) = P(B),
(16.2.25)
assuming that P(A) ̸= 0 and P(B) ̸= 0. Therefore, the term “independent” refers to the
fact that the probability of A does not depend on the occurrence or non-occurrence of B,
and vice versa.
• Example 16.2.13
Imagine some activity where you get two chances to be successful (for example, jumping
for fruit still on a tree or shooting basketballs). If each attempt is independent and the
probability of success 0.6 is the same for each trial, what is the probability of success after
(at most) two tries?
There are two ways of achieving success. We can be successful in the ﬁrst attempt
with P(S1) = 0.6 or we can fail and then be successful on the second attempt: P(F1 ∩
S2) = P(F1)P(S2) = (0.4)(0.6) = 0.24, since each attempt is independent.
Therefore,
the probability of achieving success in two tries is 0.6 + 0.24 = 0.84. Alternatively, we
can compute the probability of failure in two attempts: P(F1 ∩F2) = 0.16.
Then the
probability of success with two tries would be the complement of the probability of two
failures: 1 −0.16 = 0.84.
⊓⊔
• Example 16.2.14
Consider the tossing of a fair die. Let event A denote the tossing of a 2 or 3. Then
P(A) = P({2, 3}) = 1
3. Let event B denote tossing an odd number, B = {1, 3, 5}. Then
P(B) = 1
2.
Now A ∩B = {3} and P(A ∩B) = 1
6. Because P(A ∩B) = P(A)P(B), events A and
B are independent.
⊓⊔
Often we can characterize each outcome of an experiment consisting of n experiments
as either a “success” or a “failure.”
If the probability of each individual success is p,
then the probability of k successes and n −k failures is pk(1 −p)n−k. Because there are
n!/[k!(n −k)!] ways of achieving these k successes, the probability of an event having k
successes in n independent trials is
Pn(k) =
n!
k!(n −k)!pk(1 −p)n−k,
(16.2.26)

Probability
815
where p is the probability of a success during one of the independent trials.
• Example 16.2.15
What is the probability of having two boys in a four-child family?
Let us assume that the probability of having a male is 0.5. Taking the birth of one
child as a single trial,
P4(2) = 4!
2!2!
1
2
4
= 3
8.
(16.2.27)
Note that this is not 0.5, as one might initially guess.
Problems
1. For the following experiments, describe the sample space:
(a) ﬂipping a coin twice.
(b) selecting two items out of three items {a, b, c} without replacement.
(c) selecting two items out of three items {a, b, c} with replacement.
(d) selecting three balls, one by one, from a box that contains four blue balls and ﬁve green
balls without replacement.
(e) selecting three balls, one by one, from a box that contains four blue balls and ﬁve green
balls with replacement.
2. Consider two fair dice. What is the probability of throwing them so that the dots sum
to seven?
3. In throwing a fair die, what is the probability of obtaining a one or two on the top side
of the cube?
4. What is the probability of getting heads exactly (a) twice or (b) thrice if you ﬂip a fair
coin 6 times?
5.
An urn contains six red balls, three blue balls, and two green balls.
Two balls are
randomly selected.
What is the sample space for this experiment?
Let X denote the
number of green balls selected. What are the possible values of X? Calculate P(X = 1).
6. Consider an urn with 30 blue balls and 50 red balls in it. These balls are identical except
for their color. If they are well mixed and you draw 3 balls without replacement, what is
the probability that the balls are all of the same color?
7. A deck of cards has 52 cards, including 4 jacks and 4 ten’s. What is the probability of
selecting a jack or ten?
8. Two boys and two girls take their place on a stage to receive an award. What is the
probability that the boys take the two end seats?

816
Advanced Engineering Mathematics with MATLAB
9. A lottery consists of posting a 3-digit number given by selecting 3 balls from 10 balls,
each ball having the number from 1 to 10. The balls are not replaced after they are drawn.
What are your chances of winning the lottery if the order does not matter? What are your
chances of winning the lottery if the order does matter? Write a short MATLAB code and
verify your results. You may want to read about the MATLAB intrinsic function randperm.
10. A circle of radius 1 is inscribed in a square with sides of length 2. A point is selected
at random in the square in such a manner that all the subsets of equal area of the square
are equally likely to contain the point. What is the probability that it is inside the circle?
11. In a rural high school, 20% of the students play football and 10% of them play football
and wrestle. If Ed, a randomly selected student of this high school, played football, what
is the probability that he also wrestles for his high school?
12. You have a well-shuﬄed card deck. What is the probability the second card in the deck
is an ace?
13. We have two urns: One has 4 red balls and 6 green balls, the other has 6 red and 4
green. We toss a fair coin. If heads, we pick a random ball from the ﬁrst urn, if tails from
the second. What is the probability of getting a red ball? How do your results compare
with the probability of getting a red ball if all of the red and green balls had been placed
into a single urn?
14. A customer decides between two dinners: a “cheap” one and an “expensive” one. The
probability that the customer chooses the expensive meal is P(E) = 0.2. A customer who
chooses the expensive meal likes it with a 80% probability P(L|E) = 0.8. A customer who
chooses the cheap meal dislikes it with 70% probability P(D|C) = 0.7.
(a) Compute the probability that a customer (1) will choose a cheap meal, (2) will be
disappointed with an expensive meal, and (3) will like the the cheap meal.
(b) Use the law of total probability to compute the probability that a customer will be
disappointed.
(c) If a customer found his dinner to his liking, what is the probability that he or she chose
the expensive meal? Hint: Use Bayes’ theorem.
15. Suppose that two points are randomly and independently selected from the interval
(0, 1). What is the probability the ﬁrst one is greater than 1/4, and the second one is less
than 3/4? Check your result using rand in MATLAB.
16. A certain brand of electronics chip is found to fail prematurely in 1% of all cases. If
three of these chips are used in three independent sets of equipment, what is the probability
that (a) all three will fail prematurely, (b) that two will fail prematurely, (c) that one will
fail prematurely, and (d) that none will fail?
Project: Experimenting with MATLAB’s Intrinsic Function rand
The MATLAB function rand can be used in simulations where sampling occurs with
replacement. If we write X = rand(1,100), the vector X contains 100 elements whose values
vary between 0 and 1. Therefore, if you wish to simulate a fair die, then we can set up the
following table:

Probability
817
0 < X < 1/6
die with one dot showing
1/6 < X < 1/3
die with two dots showing
1/3 < X < 1/2
die with three dots showing
1/2 < X < 2/3
die with four dots showing
2/3 < X < 5/6
die with ﬁve dots showing
5/6 < X < 1
die with six dots showing.
We can then write MATLAB code that counts the number of times that we obtain a one or
two. Call this number n. Then the probability that we would obtain one or two dots on a
fair die is n/100. Carry out this experiment and compare your answer with the result from
Problem 2. What occurs as you do more and more experiments?
Project: Experimenting with
MATLAB’s Intrinsic Function randperm
MATLAB’s intrinsic function randperm(m) creates a random ordering of the numbers
from 1 to m. If you execute perm = randperm(365), this would produce a vector of length
365 and each element has a value lying between 1 and 365. If you repeat the process, you
would obtain another list of 365 numbers but they would be in a diﬀerent order.
Let us simulate the birthday problem. Invoking the randperm command, use the ﬁrst
element to simulate the birthday of student 1 in a class of N students. Repeatedly invoking
this command, create vector birthdays that contains the birthdays of the N students. Then
ﬁnd out if any of the days are duplicates of another. (Hint: You might want to explore the
MATLAB command unique.) Repeating this experiment many times, compute the chance
that a class of size N has at least two students that have the same birthday. Compare your
results with Equation 16.2.4. What occurs as the number of experiments increases?
16.3 DISCRETE RANDOM VARIABLES
In the previous section we presented the basic concepts of probability. In high school
algebra you were introduced to the concept of a variable - a quantity that could vary unlike
constants and parameters. Here we extend this idea to situations where the variations are
due to randomness.
A random variable is a single-valued real function that assigns a real number, the value,
to each sample point t of S. The variable can be discrete, such as the ﬂipping of a coin, or
continuous, such as the lifetime of a light bulb. The sample space S is the domain of the
random variable X(t), and the collection of all numbers X(t) is the range. Two or more
sample points can give the same value of X(t) but we will never allow two diﬀerent numbers
in the range of X(t) for a given t.
The term “random variable” is probably a poor one. Consider the simple example of
tossing a coin. A random variable that describes this experiment is
X[si] =

1,
s1 = head,
0,
s2 = tail.
(16.3.1)
An obvious question is: What is random about Equation 16.3.1? If a head is tossed, we
obtain the answer one; if a tail is tossed, we obtain a zero. Everything is well deﬁned;
there is no element of chance here. The randomness arises from the tossing of the coin.
Until the experiment (tossing of the coin) is performed, we do not know the outcome of
the experiment and the value of the random variable. Therefore, a random variable is a

818
Advanced Engineering Mathematics with MATLAB
1
2
3
4
5
6
1
2
3
4
5
6
x
x
F  (x)
X
X
1/6
1/6
1/3
1/2
2/3
5/6
1
p  [x]
Figure 16.3.1: The probability mass function for a fair die.
variable that may take diﬀerent values if a random experiment is conducted and its value is
not known in advance.
We begin our study of random variables by focusing on those arising from discrete
events. If X is discrete, X assumes only ﬁnitely many or countably many values: x1, x2, x3,
. . .. For each possible value of xi, there is a corresponding positive probability pX[x1] =
P(X = x1), pX[x2] = P(X = x2), . . . given by the probability mass function. For values of
x diﬀerent from xi, say x1 < x < x2, the probability mass function equals zero. Therefore,
we have that
pX[xi] =
n pi,
x = xi,
0,
otherwise,
(16.3.2)
where i = 1, 2, 3, . . .. A family of discrete random variables having the same probability
mass family is called identically distributed. ‘
• Example 16.3.1
Consider a fair die. We can describe the results from rolling this fair die via the discrete
random variable X, which has the possible values xi = 1, 2, 3, 4, 5, 6 with the probability
pX[xi] = 1
6 each. Note that 0 ≤pX[xi] < 1 here. Furthermore,
6
X
i=1
pX[xi] = 1.
(16.3.3)
Figure 16.3.1 illustrates the probability mass function.
⊓⊔
• Example 16.3.2
Let us now modify Example 16.3.1 so that
X[si] =
( 1,
si = 1, 2,
2,
si = 3, 4,
3,
si = 5, 6.
(16.3.4)
The probability mass function becomes
pX[1] = pX[2] = pX[3] = 1
3.
(16.3.5)
⊓⊔

Probability
819
Some Properties of the Probability Mass Function pX[xi]
0 ≤pX[xk] < 1,
pX[x] = 0
if
x ̸= xk,
k = 1, 2, . . .
X
n
pX[xn] = 1
FX(x) = P(X ≤x) =
X
xk≤x
pX[xk]
P(a < x ≤b) =
X
a<xk≤b
pX[xk]
• Example 16.3.3
Consider the probability mass function:
pX[xn] =

k(1/2)n,
n = 0, 1, 2, . . . ,
0,
otherwise.
(16.3.6)
Let us (a) ﬁnd the value of k, (b) ﬁnd P(X = 2), (c) ﬁnd P(X ≤2), and (d) P(X ≥1).
From the properties of probability mass function,
k
∞
X
n=0
1
2
n
= k
1
1 −1
2
= 2k = 1.
(16.3.7)
Therefore, k = 1
2. Note that 0 ≤pX[xn] ≤1.
Having found k, we immediately have
P(X = 2) = pX[x2] = 1
8,
(16.3.8)
P(X ≤2) = pX[x0] + pX[x1] + pX[x2] = 7
8,
(16.3.9)
and
P(X ≥1) = 1 −P(X = 0) = 1
2.
(16.3.10)
⊓⊔
Having introduced the probability mass function, an alternative means of describing the
probabilities of a discrete random variable is the cumulative distribution function. It is
deﬁned as
FX(x) = P(X ≤x),
−∞< x < ∞.
(16.3.11)
It is computed via
FX(x) =
X
xi≤x
pX[xi] =
X
xi≤x
pi.
(16.3.12)
Consequently, combining Equation 16.3.11 and Equation 16.3.12, we obtain
P(a < x ≤b) =
X
a<xi≤b
pi.
(16.3.13)
Equation 16.3.13 gives the probability over the interval (a, b].

820
Advanced Engineering Mathematics with MATLAB
• Example 16.3.4
A Bernoulli experiment is a random experiment, the outcome of which is a success
or failure. Consider now a sequence of independent Bernoulli trials with probability p of
success from trial to trial. This sequence is observed until the ﬁrst success occurs. Let X
denote a random variable that equals the trial number on which the ﬁrst success occurs.
The probability mass function is then
pX[xn] = (1 −p)n−1p,
n = 1, 2, 3, . . . .
(16.3.14)
Let us compute the cumulative distribution function.
For geometric series, we begin by noting that
∞
X
n=0
arn =
∞
X
n=1
arn−1 =
a
1 −r,
|r| < 1.
(16.3.15)
Next we check Equation 16.3.14 and determine whether it is a valid probability mass func-
tion. It is because
∞
X
n=1
pX[xn] =
∞
X
n=1
(1 −p)n−1p =
p
1 −(1 −p) = 1,
(16.3.16)
where we used Equation 16.3.15. Next, we note that
P(X > m) =
∞
X
n=m+1
(1 −p)n−1p = (1 −p)mp
1 −(1 −p) = (1 −p)m.
(16.3.17)
Therefore,
FX(x) = P(X ≤m) = 1 −P(X > m) = 1 −(1 −p)m,
(16.3.18)
where m = 1, 2, 3, . . . .
⊓⊔
• Example 16.3.5: Generating discrete random variables via MATLAB
In this example we show how to generate a discrete random variable using MATLAB’s
intrinsic function rand. This MATLAB command produces random, uniformly distributed
(equally probable) reals over the interval (0, 1). How can we use this function when in the
case of discrete random variables we have only integer values, such as k = 1, 2, 3, 4, 5, 6, in
the case of tossing a die?5
Consider the Bernoulli random variable X = k, k = 0, 1. As you will show in your
homework, it has the cumulative distribution function of
FX(x) =
( 0,
x < 0,
1 −p,
0 ≤x < 1,
1,
1 ≤x.
(16.3.19)
5 This technique is known as the inverse transform sampling method. See pages 85–102 in Devroye, L.,
1986: Non-Uniform Random Variable Generation. Springer-Verlag, 843 pp.

Probability
821
1
F  (x)
1−p
x
p
X
1
Figure 16.3.2: The cumulative distribution function for a Bernoulli random variable.
See Figure 16.3.2.
Imagine now a program that includes the MATLAB function rand, which yields the
value t. Then, if 0 < t ≤1 −p, Figure 16.3.2 gives us that X = 0. On the other hand, if
1 −p < t < 1, then X = 1. Thus, to obtain M realizations of the Bernoulli random variable
X, the MATLAB code would read for a given p:
clear;
for i = 1:M
t = rand(1,1);
if (t <= 1-p) X(i,1) = 0;
else
X(i,1) = 1;
end; end
The end product of this code creates a vector X of length M consisting of a random variable
with either zeros or ones. This is shown in Figure 16.3.3(a) when p = 0.4.
Once we have generated this random variable, we can use its relative frequency to
compute its probability mass function and cumulative distribution function from
ˆpX[xk] = Number of outcomes equal to k
M
,
(16.3.20)
and
ˆFX(x) = Number of outcomes ≤x
M
.
(16.3.21)
In Figure 16.3.3(b) we have computed the value of ˆpX[1]. Clearly it should equal p. As this
ﬁgure shows, we obtain poor results when M is small, with ˆpX[1] moving randomly above
and below the correct answer. As M becomes larger, our estimate improves.
Problems
1. The Bernoulli distribution has the probability mass function
pX[xk] = P(X = k) = pk(1 −p)1−k,
k = 0, 1,

822
Advanced Engineering Mathematics with MATLAB
0
5
10
15
20
25
30
35
40
45
50
−0.5
0
0.5
1
1.5
 k
 xk
(a)
0
20
40
60
80
100
120
140
160
180
200
0
0.2
0.4
0.6
0.8
1
 M
 est. pX[1]
(b)
Figure 16.3.3: (a) Outcomes of the Bernoulli random variable generated by the MATLAB function rand.
(b) The computed value of the probability mass function pX[1] as a function of M realization of the Bernoulli
random variable. The dashed line is the line for the exact answer p = 0.4.
where 0 ≤p ≤1. (a) Show that this distribution is a valid probability mass function. (b)
Find its cumulative distribution function.
2.
An experiment is performed where a digit, ranging from 0 to 9, is repeatedly and
randomly chosen. If X denotes the times that this experiment must be repeated until the
digit 0 is selected, ﬁnd P(X).
3. A scientiﬁc company needs a programmer who knows an unusual programming language.
If only 5% of programmers know this language, how many programmers should the company
interview to have a 75% chance of ﬁnding such a programmer?
16.4 CONTINUOUS RANDOM VARIABLES
In the previous section we examined random variables that can assume only certain
discrete values. Here we extend the concept of random variables so that they can take on
values over a continuous interval. Typical examples of continuous random variables include
the noisy portion of the voltage within an ampliﬁer, the phase of a propagating wave, and
the amount of precipitation.
An important quantity that we introduced in the previous section was the probability
mass function. What is the corresponding function for continuous random variables? From
the fundamental concepts of probability, we know that the probability of a continuous
variable assuming one speciﬁc value out of its possible range values equals zero; it is merely
one point out of an inﬁnite number of points in the sample space. On the other hand, there
is a ﬁnite probability that the value assumed by the random variable X will lie within an
arbitrarily small interval dx and this probability will depend on the length of the interval.
Another factor that should inﬂuence the probability is the value of x. There is no
reason why the probability of X should be independent of x. Consequently, an equation
for probability in the interval x < X ≤x + dx requires a function pX(x), which acts as a

Probability
823
x
x
p  (x)
X
dx
Figure 16.4.1: A probability density function.
weighting function and models the relative frequency behavior of X. For these reasons, the
probability that a continuous random variable X will assume a value lying between x and
x + dx is given by
P(x < X ≤x + dx) = pX(x) dx.
(16.4.1)
Figure 16.4.1 illustrates a possible example of pX(x) where the shaded area equals the
probability P(x < X ≤x + dx). Clearly the function pX(x) = P(x < X ≤x + dx)/dx
has the dimension of probability per inﬁnitesimal interval dx and is called, for that reason,
the probability density.
Furthermore, although pX(x) dx ≤1, this does not mean that
pX(x) ≤1. A family of random variables having the same probability density is identically
distributed.
The function pX(x) must also satisfy several additional conditions. Because probability
cannot be negative, pX(x) ≥0 of all x. Furthermore, as Figure 16.4.1 suggests, if we add
up all of the possible values of x, then we have a certain event.
We can express this
mathematically by
Z ∞
−∞
pX(x) dx = 1.
(16.4.2)
Thus, a probability density has the properties given by Equation 16.4.1 and Equation 16.4.2.
It must also be a single-valued function of x. Note that these conditions do not require that
pX(x) is a continuous function of x.
Let us now consider the probability P(a < X ≤b) where a and b are constants. If
we subdivide the range of x between a and b into inﬁnitesimal intervals (x, x + dx), the
probability that the random variable will assume a value from one such interval is given by
Equation 16.4.1. The probability that the variable will assume a value in the interval (a, b)
equals the sum of the probabilities from each subinterval between a and b and is given by
the area under the curve p(x) between x = a and x = b. Therefore,
P(a < X ≤b) =
Z b
a
pX(x) dx.
(16.4.3)
If a = −∞, we have that
P(X ≤b) =
Z b
−∞
pX(x) dx.
(16.4.4)
Alternatively, setting b = ∞,
P(a < X) =
Z ∞
a
pX(x) dx.
(16.4.5)

824
Advanced Engineering Mathematics with MATLAB
Some Properties of the Probability Density Function pX(x)
pX(x) ≥0,
Z ∞
−∞
pX(x) dx = 1
P(a < X ≤b) =
Z b
a
pX(x) dx
From Equation 16.4.3 we also have
P(X > a) = 1 −P(X < a) = 1 −
Z a
−∞
pX(x) dx =
Z ∞
a
pX(x) dx.
(16.4.6)
From Equation 16.4.4 we now deﬁne
FX(x) = P(X ≤x) =
Z x
−∞
pX(ξ) dξ.
(16.4.7)
This function FX(x) is called the cumulative distribution function, or simply the distribution
function, of the random variable X. Clearly,
pX(x) = F ′
X(x).
(16.4.8)
Therefore, from the properties of pX(x), we have that (1) FX(x) is a nondecreasing function
of x, (2) FX(−∞) = 0, (3) FX(∞) = 1, and (4) P(a < X ≤b) = FX(b) −FX(a).
• Example 16.4.1
The continuous random variable X has the probability density function
pX(x) =

k
 x −x2
,
0 < x < 1,
0,
otherwise.
(16.4.9)
What must be the value of k? What is the cumulative distribution function? What is
P(X < 1/2)?
From Equation 16.4.2, we have that
Z ∞
−∞
pX(x) dx = k
Z 1
0
 x −x2
dx = k x2
2 −x3
3

1
0
= k
6.
(16.4.10)
Therefore, k must equal 6.
Next, we note that
FX(x) = P(X ≤x) =
Z x
−∞
pX(ξ) dξ.
(16.4.11)
If x < 0, FX(x) = 0. For 0 < x < 1, then
FX(x) = 6
Z x
0
 ξ −ξ2
dξ = 6
ξ2
2 −ξ3
3

x
0
= 3x2 −2x3.
(16.4.12)

Probability
825
F  (x)
X
1
2
1
x
3
Figure 16.4.2: The cumulative distribution function for an exponential random variable.
Finally, if x > 1,
FX(x) = 6
Z 1
0
 ξ −ξ2
dξ = 1.
(16.4.13)
In summary,
FX(x) =
(
0,
0 ≤x,
3x2 −2x3,
0 < x ≤1,
1,
1 < x.
(16.4.14)
Because P(X ≤x) = FX(x), we have that P(X < 1
2) = 1
2 and P(X > 1
2) = 1 −P(X <
1
2) = 1
2.
⊓⊔
• Example 16.4.2: Generating continuous random variables via MATLAB6
In the previous section we showed how the MATLAB function rand can be used to gen-
erate outcomes for a discrete random variable. Similar considerations hold for a continuous
random variable.
Consider the exponential random variable X. Its probability density function is
pX(x) =

0,
x < 0,
λe−λx,
0 < x,
(16.4.15)
where λ > 0. For homework you will show that the corresponding cumulative distribution
function is
FX(x) =

0,
x ≤0,
1 −e−λx,
0 < x.
(16.4.16)
Figure 16.4.2 illustrates this cumulative density function when λ = 1. How can we use these
results to generate a MATLAB code that produces an exponential random variable?
Recall that both MATLAB function rand and the cumulative distribution function pro-
duce values that vary between 0 and 1. Given a value from rand, we can compute the
corresponding X = x, which would give the same value from the cumulative distribution
function. In short, we are creating random values for the cumulative distribution function
and using those values to give the exponential random variable via
X = x = −ln (1 −rand) /λ,
(16.4.17)
6 This technique is known as the inverse transform sampling method. See pages 27–39 in Devroye, L.,
1986: Non-Uniform Random Variable Generation. Springer-Verlag, 843 pp.

826
Advanced Engineering Mathematics with MATLAB
0
5
10
15
20
25
30
35
40
45
50
0
1
2
3
4
5
6
 k
 xk
(a)
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
0
0.2
0.4
0.6
0.8
1
 x
 est. pX(x)
(b)
Figure 16.4.3: (a) Outcomes of a numerical experiment to generate an exponential random variable using
the MATLAB function rand.
(b) The function ˆpX(x) given by Equation 16.4.18 as a function of x for
an exponential random variable with M = 1000. The dashed black line is the exact probability density
function.
where we have set FX(x) = rand. Therefore, the MATLAB code to generate exponential
random variables for a particular lambda is
clear;
for i = 1:M
t = rand(1,1);
X(i,1) = -log(1-t) / lambda;
end
where M is the number of experiments that we run. In Figure 16.4.3(a) we illustrates the ﬁrst
200 outcomes from our numerical experiment to generate an exponential random variable.
To compute the probability density function we use the ﬁnite diﬀerence approximation
of Equation 16.4.1, or
ˆp(x0) = Number of outcomes in [x0 −∆x/2, x0 + ∆x/2]
M∆x
,
(16.4.18)
where ∆x is the size of the bins into which we collect the various outcomes. Figure 16.4.3(b)
illustrates this numerical estimation of the probability density function in the case of an
exponential random variable. The function ˆpX(x) was created from the MATLAB code:
clear;
delta x = 0.2; lambda = 1; M = 1000; % Initialize ∆x, λ and M
% sample M outcomes from the uniformly distributed distribution

Probability
827
t = rand(M,1);
% generate the exponential random variable
x = - log(1-t)/lambda;
% create the various bins [x0 −∆x/2, x0 + ∆x/2]
bincenters=[delta x/2:delta x:5];
bins=length(bincenters); % count the number of bins
% now bin the M outcomes into the various bins
[n,x out] = hist(x,bincenters);
n = n / (delta x*M); % compute the probability per bin
bar h = bar(x out,n); % create the bar graph
bar child = get(bar h,’Children’);
set(bar child,’CData’,n);
colormap(Autumn);
Problems
1. The probability density function for the exponential random variable is
pX(x) =

0,
x < 0,
λe−λx,
0 < x,
with λ > 0. Find its cumulative distribution function.
2. Given the probability density function
pX(x) =

kx,
0 < x < 2,
0,
otherwise,
where k is a constant, (a) compute the value of k, (b) ﬁnd the cumulative density function
FX(x), and (c) ﬁnd the P(1 < X ≤2).
3. Given the probability density function
pX(x) =

k (1 −|x|) ,
|x| < 1,
0,
|x| > 1,
where k is a constant, (a) compute the value of k and (b) ﬁnd the cumulative density
function FX(x).
Project: Central Limit Theorem
Consider the sum S = (X1 + X2 + X3 + · · · + X100)/100, where Xi is the ith sample
from a uniform distribution.
Step 1: Write a MATLAB program to compute the probability density function of S. See
Figure 16.4.4.
Step 2: The central limit theorem states the distribution of the sum (or average) of a
large number of independent, identically distributed random variables will be approximately
normal, regardless of the underlying distribution. Do your numerical results agree with this
theorem?

828
Advanced Engineering Mathematics with MATLAB
S
0.35
0.4
0.45
0.5
0.55
0.6
0.65
probability density
0
2
4
6
8
10
12
14
Figure 16.4.4: Computed probability density function for the sum S = (X1 + X2 + X3 + · · · + X100)/100,
where Xi is the ith sample from a uniform distribution.
16.5 MEAN AND VARIANCE
In the previous two sections we explored the concepts of random variable and distribu-
tion. Here we introduce two parameters, mean and variance, that are useful in characterizing
a distribution.
The mean µX is deﬁned by
µX = E(X) =







X
k
xk pX[xk],
X discrete,
Z ∞
−∞
x pX(x) dx,
X continuous.
(16.5.1)
The mean provides the position of the center of the distribution. The operator E(X), which
is called the expectation of X, gives the average value of X that one should expect after many
trials.
Two important properties involve the expectation of the sum and product of two ran-
dom variables X and Y . The ﬁrst one is
E(X + Y ) = E(X) + E(Y ).
(16.5.2)
Second, if X and Y are independent random variables, then
E(XY ) = E(X)E(Y ).
(16.5.3)
The proofs can be found elsewhere.7
The variance provides the spread of a distribution. It is computed via
σ2
X = Var(X) = E{[X −E(X)]2},
(16.5.4)
7 For example, Kay, S. M., 2006: Intuitive Probability and Random Processes Using MATLAB. Springer,
833 pp. See Sections 7.7 and 12.7.

Probability
829
or
σ2
X =







X
k
(xk −µX)2pX[xk],
X discrete,
Z ∞
−∞
(x −µX)2pX(x) dx,
X continuous.
(16.5.5)
If we expand the right side of Equation 16.5.4, an alternative method for ﬁnding the variance
is
σ2
X = Var(X) = E(X2) −[E(X)]2,
(16.5.6)
where
E(Xn) =







X
k
xn
k pX[xk],
X discrete,
Z ∞
−∞
xnpX(x) dx,
X continuous.
(16.5.7)
• Example 16.5.1: Mean and variance of M equally likely outcomes
Consider the random variable X = k where k = 1, 2, . . . , M. If each event has an
equally likely outcome, pX[xk] = 1/M. Then the expected or average or mean value is
µX = 1
M
M
X
k=1
xk = M(M + 1)
2M
= M + 1
2
.
(16.5.8)
Note that the mean does not equal any of the possible values of X. Therefore, the expected
value need not equal a value that will be actually observed.
Turning to the variance,
Var(X) = (M + 1) [(2M + 1)/6 −(M + 1)/4]
(16.5.9)
= (M + 1) [4M + 2 −3M −3] /12
(16.5.10)
= (M + 1)(M −1)/12 = (M 2 −1)/12,
(16.5.11)
because
E(X2) = 1
M
M
X
k=1
x2
k = M(M + 1)(2M + 1)
6M
= (M + 1)(2M + 1)
6
.
(16.5.12)
We used Equation 16.5.6 to compute the variance.
⊓⊔
• Example 16.5.2
Let us ﬁnd the mean and variance of the random variable X whose probability density
function is
pX(x) =

kx,
0 < x < 1,
0,
otherwise.
(16.5.13)
From Equation 16.5.1, we have that
µX = E(X) =
Z 1
0
x(kx) dx = kx3
3

1
0
= k
3.
(16.5.14)

830
Advanced Engineering Mathematics with MATLAB
From Equation 16.5.6, the variance of X is
σ2
X = Var(X) = E(X2)−[E(X)]2 =
Z 1
0
x2(kx) dx−k2
9 = kx4
4

1
0
−k2
9 = k
4 −k2
9 . (16.5.15)
⊓⊔
• Example 16.5.3: Characteristic functions
The characteristic function of a random variable is deﬁned by
φX(ω) = E[exp(iωX)].
(16.5.16)
If X is a discrete random variable, then
φX(ω) =
∞
X
k=−∞
pX[xk]eikω.
(16.5.17)
On the other hand, if X is a continuous random variable,
φX(ω) =
Z ∞
−∞
pX(x)eiωx dx,
(16.5.18)
the inverse Fourier transform (times 2π) of the Fourier transform, pX(x).
Characteristic functions are useful for computing various moments of a random variable
via
E(Xn) = 1
in
dnϕX(ω)
dωn

ω=0
.
(16.5.19)
This follows by taking repeated diﬀerentiation of Equation 16.5.16 and then evaluating the
diﬀerentiation at ω = 0.
Consider, for example, the exponential probability density function pX(x) = λe−λx
with x, λ > 0. A straightforward calculation gives
φX(ω) =
λ
λ −ωi.
(16.5.20)
Substituting Equation 16.5.20 into Equation 16.5.19 yields
E(Xn) = n!
λn .
(16.5.21)
In particular,
E(X) = 1
λ
and
E(X2) = 2
λ2 .
(16.5.22)
Consequently, µX = 1/λ and Var(X) = E(X2) −µ2
X = 1/λ2.
⊓⊔
• Example 16.5.4: Characteristic function for a Gaussian distribution
Let us ﬁnd the characteristic function for the Gaussian distribution and then use that
characteristic function to compute the mean and variance.

Probability
831
Because
pX(x) =
1
√
2π σ e−(x−µ)2/(2σ2),
(16.5.23)
the characteristic function equals
φX(ω) =
1
√
2π σ
Z ∞
−∞
e−(x−µ)2/(2σ2)+iωx dx
(16.5.24)
= eiωµ−σ2ω2/2

1
√
2π σ
Z ∞
−∞
exp

−(x −µ −iωσ2)2
2σ2

dx

(16.5.25)
= eiωµ−σ2ω2/2
(16.5.26)
because the quantity within the wavy brackets equals one.
Given this characteristic function, Equation 16.5.26, we have that
φ′
X(ω) = (iµ −σ2ω)eiωµ−σ2ω2/2.
(16.5.27)
Therefore, φ′
X(0) = iµ and from Equation 16.5.19, µX = E(X) = µ. Furthermore,
φ′′
X(ω) = (iµ −σ2ω)2eiωµ−σ2ω2/2 −σ2eiωµ−σ2ω2/2.
(16.5.28)
Consequently, φ′′
X(0) = −µ2 −σ2 and Var(X) = E(X2) −µ2
X = σ2.
Problems
1. Let X(s) denote a discrete random variable associated with a fair coin toss. Then
X(s) =

0,
s = tail,
1,
s = head.
Find the expected value and variance of this random variable.
2. The geometric random variable X has the probability mass function:
pX[xk] = P(X = k) = p(1 −p)k−1,
k = 1, 2, 3, . . . .
Find its mean and variance. Hint:
∞
X
k=1
krk−1 =
1
(1 −r)2 ,
∞
X
k=2
k(k −1)rk−2 =
2
(1 −r)3 ,
|r| < 1,
and E(X2) = E[X(X −1)] + E(X).
3. Given
pX(x) =

kx(2 −x)
0 < x < 2,
0,
otherwise,
(a) ﬁnd k and (b) its mean and variance.
4. Given the probability density
pX(x) = (a2 −x2)ν−1
2 ,
ν > −1
2,

832
Advanced Engineering Mathematics with MATLAB
ﬁnd its characteristic function using integral tables.
For the following distributions, ﬁrst ﬁnd their characteristic functions. Then compute the
mean and variance using Equation 16.5.19.
5. Binomial distribution:
pX[xk] =

n
k

pkqn−k,
0 < p < 1,
where q = 1 −p. Hint: Use the binomial theorem to simplify Equation 16.5.17.
6. Poisson distribution:
pX[xk] = e−λ λk
k! ,
0 < λ.
7. Geometric distribution:
pX[xk] = qkp,
0 < p < 1,
where q = 1 −p.
8. Uniform distribution:
pX(x) = H(x −a) −H(x −b)
b −a
,
b > a > 0.
Project: MATLAB’s Intrinsic Function mean and var
MATLAB has the special commands mean and var to compute the mean and variance,
respectively, of the random variable X.
Use the MATLAB command randn to create a
random variable X(n) of length N. Then, ﬁnd the mean and variance of X(n). How do these
parameters vary with N?
Project: Monte Carlo Integration and Importance Sampling
Consider the integral I =
R 1
0
√
1 −x2 dx = π/4. If we were to compute it numerically
by the conventional midpoint rule, the approximate value is given by
IN = 1
N
N
X
n=1
f(xn),
(1)
where f(x) =
√
1 −x2 and xn = (n −1/2)/N. For N = 10, 50, 100, and 500, the absolute
value of the relative error is 2.7 × 10−3, 2.4 × 10−4, 8.6 × 10−5, and 7.7 × 10−6, respectively.
Monte Carlo integration is a simple alternative method for doing the numerical inte-
gration using random sampling. It is a particularly powerful technique for approximating
complicated integrals. Here you will explore a simple one-dimensional version of this scheme.
Consider the random variable:
IM = 1
M
M
X
m=1
f(xm),
(2)

Probability
833
−0.3
−0.2
−0.1
0
0.1
0.2
0
1
2
3
4
5
6
M = 10
probability density
−0.1
−0.05
0
0.05
0.1
0
2
4
6
8
10
12
14
M = 50
−0.08
−0.06
−0.04
−0.02
0
0.02
0.04
0.06
0.08
0
5
10
15
20
M = 100
approximate − exact value of the integral
probability density
−0.04
−0.03
−0.02
−0.01
0
0.01
0.02
0.03
0.04
0
10
20
30
40
50
M = 500
approximate − exact value of the integral
Figure 16.5.1: The probability density function arising from using Monto Carlo integration to compute
R 1
0
√
1 −x2 dx for various values of M.
where xm is the mth sample point taken from the uniform distribution. IM is a random
variable because it is a function of the random variable xm. Therefore,
E(IM) = 1
M
M
X
m=1
E[f(xm)] = 1
M
M
X
m=1
Z 1
0
f(x)p(x) dx
= 1
M
M
X
m=1
Z 1
0
f(x) dx =
Z 1
0
f(x) dx = I,
because p(x), the probability of the uniform distribution, equals 1. Furthermore, as we
increase the number of samples M, IM approaches I. By the strong law of large numbers,
this limit is guaranteed to converge to the exact solution: P(limM→∞IM −I) = 1. Equation
(2) is not the midpoint rule because the uniform grid xn has been replaced by randomly
spaced grid points.
Step 1: Write a MATLAB program that computes IM for various values of M when xm is
selected from a uniform distribution. By running your code thousands of times, ﬁnd the
probability density as a function of the diﬀerence between IM and I. Compute the mean
and variance of IM. How does the variance vary with M? See Figure 16.5.1.
The reason why standard Monte Carlo integration is not particularly good is the fact
that we used a uniform distribution. A better idea would be to sample from regions where
the integrand is larger. This is the essence of the concept of importance sampling: That
certain values of the input random variable xm in a simulation have more impact on the
parameters being estimated than others.
We begin by noting that
I =
Z 1
0
f(x) dx =
Z 1
0
f(x)
p1(x)p1(x) dx,

834
Advanced Engineering Mathematics with MATLAB
where p1(x) is a new probability density function that replaces the uniform probability
distribution and is relatively larger when f(x) is larger and relatively smaller when f(x) is
smaller.
The question now becomes how to compute p1(x). We shall use the VEGAS algo-
rithm, which constructs p1(x) by sampling f(x) K times, where K < M. Within each kth
subinterval we assume that there are M/K uniformly distributed points. Therefore,
p1(xm) =
K f(sm)
PK
k=1 f(sk)
,
where sk is the center point of the kth subinterval within which the mth point is located.
For each m, we must ﬁnd xm. This is done in two steps: First we randomly choose the kth
subinterval using a uniform distribution. Then we randomly choose the point xm within
that subinterval using a uniform distribution. Therefore, our modiﬁed integration scheme
becomes
IM = 1
M
M
X
m=1
f(xm)
p1(xm).
(3)
Now,
E(IM) = 1
M
M
X
m=1
E
 f(xm)
p1(xm)

= 1
M
M
X
m=1
Z 1
0
f(x)
p1(x)p1(x)p2(x) dx
= 1
M
M
X
m=1
Z 1
0
f(x) dx =
Z 1
0
f(x) dx = I,
because p2(x) = 1.
Step 2: Write a MATLAB program that computes IM for various values of K for a ﬁxed value
of M. Recall that you must ﬁrst select the subdivision using the MATLAB function rand
and then the value of xm within the subdivision using a uniform distribution. By running
your code thousands of times, ﬁnd the probability density as a function of the diﬀerence
between IM and I. Compute the mean and variance of IM. How does the variance vary
with M? See Figure 16.5.2.
16.6 SOME COMMONLY USED DISTRIBUTIONS
In the previous sections we introduced the concept of probability distributions and their
description via mean and variance. In this section we focus on some special distributions,
both discrete and continuous, that appear often in engineering.
Bernoulli distribution
Consider an experiment where the outcome can be classiﬁed as either a success or
failure. The probability of a success is p and the probability of a failure is 1−p. Then these
“Bernoulli trials” have a random variable X associated with them where the probability
mass function is given by
pX[xk] = P(X = k) = pk(1 −p)1−k,
k = 0, 1,
(16.6.1)

Probability
835
−0.04
−0.03
−0.02
−0.01
0
0.01
0.02
0.03
0
10
20
30
40
50
K = 5
probability density
−0.03
−0.02
−0.01
0
0.01
0.02
0
10
20
30
40
50
60
70
80
K = 10
−0.02 −0.015 −0.01 −0.005
0
0.005
0.01
0.015
0
20
40
60
80
100
120
140
K = 20
approximate − exact value of the integral
probability density
−0.015
−0.01
−0.005
0
0.005
0.01
0
50
100
150
200
250
300
350
K = 50
approximate − exact value of the integral
Figure 16.5.2: The probability density function arising from using importance sampling with Monto Carlo
integration to compute R 1
0
√
1 −x2 dx for various values of K and M = 100.
where 0 ≤p ≤1. From Equation 16.3.12 the cumulative density function of the Bernoulli
random variable X is
FX(x) =
(
0,
x < 0,
1 −p,
0 ≤x < 1,
1,
1 ≤x.
(16.6.2)
The mean and variance of the Bernoulli random variable X are
µX = E(X) = p,
and
σ2
X = Var(X) = p(1 −p).
(16.6.3)
• Example 16.6.1
A simple pass and fail process is taking a ﬁnal exam, which can be modeled by a
Bernoulli distribution. Suppose a class passed a ﬁnal exam with the probability of 0.75. If
X denotes the random variable that someone passed the exam, then
E(X) = p = 0.75,
and
Var(X) = p(1 −p) = (0.75)(0.25) = 0.1875.
(16.6.4)
⊓⊔
Geometric distribution
Consider again an experiment where we either have success with probability p or failure
with probability 1−p. This experiment is repeated until the ﬁrst success occurs. Let random
variable X denote the trial number on which this ﬁrst success occurs. Its probability mass
function is
pX[xk] = P(X = k) = p(1 −p)k−1,
k = 1, 2, 3, . . . .
(16.6.5)
From Equation 16.3.12 the cumulative density function of this geometric random variable
X is
FX(x) = P(X ≤x) = 1 −(1 −p)k.
(16.6.6)

836
Advanced Engineering Mathematics with MATLAB
The mean and variance of the geometric random variable X are
µX = E(X) = 1
p,
and
σ2
X = Var(X) = 1 −p
p2
.
(16.6.7)
• Example 16.6.2
A particle within an accelerator has the probability 0.01 of hitting a target material.
(a) What is the probability that the ﬁrst particle to hit the target is the 50th? (b) What is
the probability that the target will be hit by any particle?
P(ﬁrst particle to hit is the 50th) = 0.01(0.99)49 = 0.0061.
(16.6.8)
P(target hit by any of ﬁrst 50th particles) =
50
X
n=1
0.01(0.99)n−1 = 0.3950.
(16.6.9)
⊓⊔
• Example 16.6.3
The police ticket 5% of parked cars. Assuming that the cars are ticketed independently,
ﬁnd the probability of 1 ticket on a block with 7 parked cars.
Each car is a Bernoulli trial with P(ticket) = 0.05. Therefore,
P(1 ticket on block) = P(1 ticket in 7 trials) =

7
1

(0.95)6(0.05) = 0.2573.
(16.6.10)
⊓⊔
Binomial distribution
Consider now an experiment in which n independent Bernoulli trials are performed and
X represents the number of successes that occur in the n trials. In this case the random
variable X is called binomial with parameters (n, p) with a probability mass function given
by
pX[xk] = P(X = k) =

n
k

pk(1 −p)n−k,
k = 0, 1, . . . , n,
(16.6.11)
where 0 ≤p ≤1, and

n
k

=
n!
k!(n −k)!,
(16.6.12)
the binomial coeﬃcient. The term pk arises from the k successes while (1 −p)n−k is due
to the failures. The binomial coeﬃcient gives the number of ways that we pick those k
successes from the n trials.
The corresponding cumulative density function of X is
FX(x) =
n
X
k=0

n
k

pk(1 −p)n−k,
n ≤x < n + 1.
(16.6.13)

Probability
837
The mean and variance of the binomial random variable X are
µX = E(X) = np,
and
σ2
X = Var(X) = np(1 −p).
(16.6.14)
A Bernoulli random variable is the same as a binomial random variable when the parameters
are (1, n).
• Example 16.6.4
Let us ﬁnd the probability of rolling the same side of a die (say, the side with N dots
on it) at least 3 times when a fair die is rolled 4 times.
During our 4 tosses, we could obtain no rolls with N dots on the side (k = 0), one roll
with N dots (k = 1), two rolls with N dots (k = 2), three rolls with N dots (k = 3), or
four rolls with N dots (k = 4). If we deﬁne A as the event of rolling a die so that the side
with N dots appears at least three times, then we must add the probabilities for k = 3 and
k = 4. Therefore,
P(A) = pX[x3] + pX[x4] =

4
3

p3(1 −p)1 +

4
4

p4(1 −p)0
(16.6.15)
= 4!
3!1!p3(1 −p)1 + 4!
4!0!p4(1 −p)0 = 0.0162
(16.6.16)
because p = 1
6.
⊓⊔
• Example 16.6.5
If 10 random binary digits are transmitted, what is the probability that more than
seven 1’s are included among them?
Let X denote the number of 1’s among the 10 digits. Then
P(X > 7) = P(X = 8) + P(X = 9) + P(X = 10) = pX[x8] + pX[x9] + pX[x10] (16.6.17)
=

10
8
 1
2
8 1
2
2
+

10
9
 1
2
9 1
2
1
+

10
10
 1
2
10 1
2
0
(16.6.18)
= (45 + 10 + 1)
1
2
10
=
56
1024.
(16.6.19)
⊓⊔
Poisson distribution
The Poisson probability distribution arises as an approximation for the binomial dis-
tribution as n →∞and p →0 such that np remains ﬁnite. To see this, let us rewrite the
binomial distribution as follows:
P(X = k) =
n!
k!(n −k)!
λ
n
k 
1 −λ
n
n−k
= n(n −1)(n −2) · · · (n −k + 1)
nk
λn
n!
(1 −λ/n)n
(1 −λ/n)k ,
(16.6.20)

838
Advanced Engineering Mathematics with MATLAB
if λ = np. For ﬁnite λ,
lim
n→∞

1 −λ
n
k
→1,
lim
n→∞

1 −λ
n
n
→e−λ,
(16.6.21)
and
lim
n→∞
n(n −1)(n −2) · · · (n −k + 1)
nk
→1.
(16.6.22)
Therefore, for large n, small p and moderate λ, we can approximate the binomial distribution
by the Poisson distribution:
pX[xk] = P(X = k) = e−λ λk
k! ,
k = 0, 1, . . . .
(16.6.23)
The corresponding cumulative density function of X is
FX(x) = e−λ
n
X
k=0
λk
k! ,
n ≤x < n + 1.
(16.6.24)
The mean and variance of the Poisson random variable X are
µX = E(X) = λ,
and
σ2
X = Var(X) = λ.
(16.6.25)
In addition to this approximation, the Poisson distribution is the probability distribution
for a Poisson process. But that has to wait for the next chapter.
• Example 16.6.6
Consider a student union on a campus. On average 3 persons enter the union per
minute. What is the probability that, during any given minute, 3 or more persons will
enter the union?
To make use of Poisson’s distribution to solve this problem, we must have both a large
n and a small p with the average λ = np = 3. Therefore, we divide time into a large number
of small intervals so that n is large while the probability that someone will enter the union
is small. Assuming independence of events, we have a binomial distribution with large n.
Let A denote the event that 3 or more persons will enter the union, then
P(A) = pX[0] + pX[1] + pX[2] = e−3
30
0! + 31
1! + 32
2!

= 0.423.
(16.6.26)
Therefore, P(A) = 1 −P(A) = 0.577.
⊓⊔
Uniform distribution
The continuous random variable X is called uniform if its probability density function
is
pX(x) =

1/(b −a),
a < x < b,
0,
otherwise.
(16.6.27)

Probability
839
The corresponding cumulative density function of X is
FX(x) =
(
0,
x ≤a,
(x −a)/(b −a),
a < x < b,
1,
b ≤x.
(16.6.28)
The mean and variance of a uniform random variable X are
µX = E(X) = 1
2(a + b),
and
σ2
X = Var(X) = (b −a)2
12
.
(16.6.29)
Uniform distributions are used when we have no prior knowledge of the actual probability
density function and all continuous values in some range appear equally likely.
Exponential distribution
The continuous random variable X is called exponential with parameter λ > 0 if its
probability density function is
pX(x) =

λe−λx,
x > 0,
0,
x < 0.
(16.6.30)
The corresponding cumulative density function of X is
FX(x) =

1 −e−λx,
x ≥0,
0,
x < 0.
(16.6.31)
The mean and variance of an exponential random variable X are
µX = E(X) = 1/λ,
and
σ2
X = Var(X) = 1/λ2.
(16.6.32)
This distribution has the interesting property that is “memoryless.” By memoryless,
we mean that for a nonnegative random variable X, then
P(X > s + t|X > t) = P(X > s),
(16.6.33)
where x, t ≥0. For example, if the lifetime of a light bulb is exponentially distributed, then
the light bulb that has been in use for some hours is as good as a new light bulb with regard
to the amount of time remaining until it fails.
To prove this, from Equation 16.2.4, Equation 16.6.33 becomes
P(X > s + t and X > t)
P(X > t)
= P(X > s),
(16.6.34)
or
P(X > s + t and X > t) = P(X > t)P(X > s),
(16.6.35)
since P(X > s + t and X > t) = P(X > s + t). Now, because
P(X > s + t) = 1 −
h
1 −e−λ(s+t)i
= e−λ(s+t),
(16.6.36)

840
Advanced Engineering Mathematics with MATLAB
P(X > s) = 1 −
 1 −e−λs
= e−λs,
(16.6.37)
and
P(X > t) = 1 −
 1 −e−λt
= e−λt.
(16.6.38)
Therefore, Equation 16.6.35 is satisﬁed and X is memoryless.
• Example 16.6.7
A component in an electrical circuit has an exponentially distributed failure time with
a mean of 1000 hours. Calculate the time so that the probability of the time to failure is
less than 10−3.
Let the exponential random variable X = k have the units of hours. Then λ = 10−3.
From the deﬁnition of the cumulative density function,
FX(xt) = P(X ≤xt) = 0.001,
and
1 −exp(−λxt) = 0.001.
(16.6.39)
Solving for xt,
xt = −ln(0.999)/λ = 1.
(16.6.40)
⊓⊔
• Example 16.6.8
A computer contains a certain component whose time (in years) to failure is given by
the random variable T distributed exponentially with λ = 1/5. If 5 of these components
are installed in diﬀerent computers, what is the probability that at least 2 of them will still
work at the end of 8 years?
The probability that a component will last 8 years or longer is
P(T > 8) = e−8/5 = 0.2019,
(16.6.41)
because λ = 1/5.
Let X denote the number of components functioning after 8 years. Then,
P(X ≥2) = 1 −P(X = 0) −P(X = 1)
(16.6.42)
= 1 −

5
0

(0.2019)0(0.7981)5 −

5
1

(0.2019)1(0.7981)4
(16.6.43)
= 0.2666.
(16.6.44)
⊓⊔
Normal (or Gaussian) distribution
The normal distribution is the most important continuous distribution. It occurs in
many applications and plays a key role in the study of random phenomena in nature.
A random variable X is called a normal random variable if its probability density
function is
pX(x) = e−(x−µ)2/(2σ2)
√
2π σ
,
(16.6.45)

Probability
841
where the mean and variance of a normal random variable X are
µX = E(X) = µ,
and
σ2
X = Var(X) = σ2.
(16.6.46)
The distribution is symmetric with respect to x = µ and its shape is sometimes called
“bell shaped.” For small σ2 we obtain a high peak and steep slope while with increasing σ2
the curve becomes ﬂatter and ﬂatter.
The corresponding cumulative density function of X is
FX(x) =
1
√
2π σ
Z x
−∞
e−(ξ−µ)2/(2σ2) dξ =
1
√
2π
Z (x−µ)/σ
−∞
e−ξ2/2 dξ.
(16.6.47)
The integral in Equation 16.6.46 must be evaluated numerically. It is convenient to introduce
the probability integral:
Φ(z) =
1
√
2π
Z z
−∞
e−ξ2/2 dξ.
(16.6.48)
Note that Φ(−z) = 1 −Φ(z). Therefore,
FX(x) = Φ
x −µ
σ

.
(16.6.49)
and
P(a < X ≤b) = FX(b) −FX(a).
(16.6.50)
Consider now the intervals consisting of one σ, two σ, and three σ around the mean µ.
Then, from Equation 16.6.50,
P(µ −σ < X ≤µ + σ) = 0.68,
(16.6.51)
P(µ −2σ < X ≤µ + 2σ) = 0.955,
(16.6.52)
and
P(µ −3σ < X ≤µ + 3σ) = 0.997.
(16.6.53)
Therefore, approximately
2
3 of the values will be distributed between µ −σ and µ + σ,
approximately 95% of the values will be distributed between µ−2σ and µ+2σ, and almost
all values will be distributed between µ −3σ and µ + 3σ. For most uses, then, all values
will lie between µ −3σ and µ + 3σ, the so-called “three-sigma limits.”
As stated earlier, the mean and variance of a normal random variable X are
µX = E(X) = µ,
and
σ2
X = Var(X) = σ2.
(16.6.54)
The notation N(µ; σ) commonly denotes that X is normal with mean µ and variance
σ2. The special case of a normal random variable Z with zero mean and unit variance,
N(0, 1), is called a standard normal random variable.
Problems
1.
Four coins are tossed simultaneously.
Find the probability function for the random
variable X that gives the number of heads. Then compute the probabilities of (a) obtaining
no heads, (b) exactly one head, (c) at least one head, and (d) not less than four heads.

842
Advanced Engineering Mathematics with MATLAB
2. A binary source generates the digits 1 and 0 randomly with equal probability. (a) What
is the probability that three 1’s and three 0’s will occur in a six-digit sequence? (b) What
is the probability that at least three 1’s will occur in a six-digit sequence?
3. Show that the probability of exactly n heads in 2n tosses of a fair coin is
pX[xn] = 1 · 3 · 5 · · · 2n −1
2 · 4 · 6 · · · 2n
.
4. If your cell phone rings, on average, 3 times between noon and 3 P.M., what is the
probability that during that time period you will receive (a) no calls, (b) 6 or more calls, and
(c) not more than 2 calls? Assume that the probability is given by a Poisson distribution.
5. A company sells blank DVDs in packages of 10. If the probability of a defective DVD is
0.001, (a) what is the probability that a package contains a defective DVD? (b) what is the
probability that a package has two or more defective DVDs?
6. A school plans to oﬀer a course on probability in a classroom that contains 20 seats.
From experience they know that 95% of the students who enroll actually show up. If the
school allows 22 students to enroll before the session is closed, what is the probability of
the class being oversubscribed?
7. The lifetime (in hours) of a certain electronic device is a random variable T having a
probability density function pT (t) = 100H(t−100)/t2. What is the probability that exactly
3 of 5 such devices must be replaced within the ﬁrst 150 hours of operation? Assume that
the events that the ith device must be replaced within this time are independent.
16.7 JOINT DISTRIBUTIONS
In the previous sections we introduced distributions that depended upon a single ran-
dom variable. Here we generalize these techniques for two random variables. The range of
the two-dimensional random variable (X, Y ) is RXY = {(x, y); ξ ∈S and X(ξ) = x, Y (ξ) =
y}.
Discrete joint distribution
Let X and Y denote two discrete random variables deﬁned on the same sample space
(jointly distributed). The function pXY [xi, yj] = P[X = xi, Y = yj] is the joint probability
mass function of X and Y . As one might expect, pXY [xi, yj] ≥0.
Let the sets of possible values of X and Y be A and B. If xi ̸∈A or yj ̸∈B, then
pXY [xi, yj] = 0. Furthermore,
X
xi∈A,yj∈B
pXY [xi, yj] = 1.
(16.7.1)
The marginal probability functions of X and Y are deﬁned by
pX[xi] =
X
yj∈B
pXY [xi, yj],
(16.7.2)

Probability
843
and
pY [yj] =
X
xi∈A
pXY [xi, yj].
(16.7.3)
If X and Y are independent random variables, then pXY [xi, yj] = pX[xi]· pY [yj].
• Example 16.7.1
A joint probability mass function is given by
pXY [xi, yj] =

k(xi + 2yj),
xi = 1, 2, 3, yj = 1, 2;
0,
otherwise.
(16.7.4)
Let us ﬁnd the value of k, pX[xi], and pY [yj].
From Equation 16.7.1, we have that
k
3
X
xi=1
2
X
yj=1
(xi + 2yj) = 1,
(16.7.5)
or
k

(1 + 2) + (1 + 4) + (2 + 2) + (2 + 4) + (3 + 2) + (3 + 4)

= 1.
(16.7.6)
Therefore, k = 1/30.
Turning to pX[xi] and pY [yj],
pX[xi] = k
2
X
yj=1
(xi + 2yj) = k(xi + 2) + k(xi + 4) = k(2xi + 6) = (xi + 3)/15,
(16.7.7)
where xi = 1, 2, 3, and
pY [yj] = k
3
X
xi=1
(xi + 2yj) = k(1 + 2yj) + k(2 + 2yj) + k(3 + 2yj) = k(6 + 6yj) = (1 + yj)/5,
(16.7.8)
where yj = 1, 2.
⊓⊔
• Example 16.7.2
Consider an urn that contains 1 red ball, 2 blue balls, and 2 green balls. Let (X, Y )
be a bivariate random variable where X and Y denote the number of red and blue balls,
respectively, chosen from the urn. There are 18 possible ways that three balls can be drawn
from the urn: rbb, rbg, rgb, rgg, brb, brg, bbr, bbg, bgr, bgb, bgg, grb, grg, gbr, gbb, gbg, ggr,
and ggb.
The range of X and Y in the present problem is RXY ={(0, 1), (0, 2), (1, 0), (1, 1), (1, 2)}.
The joint probability mass function of (X, Y ) is given by pXY [xi, yj] = P(X = i, Y = j),
where xi = 0, 1 and yj = 0, 1, 2. From our list of possible drawings, we ﬁnd that pXY [0, 0] =
0, pXY [0, 1] = 1/6, pXY [0, 2] = 1/6, pXY [1, 0] = 1/6, pXY [1, 1] = 1/3, and pXY [1, 2] = 1/6.
Note that all of these probabilities sum to one.
Given these probabilities, the marginal probabilities are pX[0] = 1/3, pX[1] = 2/3,
pY [0] = 1/3, pY [1] = 1/2, and pY [2] = 1/3. Because pXY [0, 0] ̸= pX[0]pY [0], X and Y are
not independent variables.
⊓⊔

844
Advanced Engineering Mathematics with MATLAB
• Example 16.7.3
Consider a community where 50% of the families have a pet. Of these families, 60%
have one pet, 30% have 2 pets, and 10% have 3 pets. Furthermore, each pet is equally
likely (and independently) to be a male or female. If a family is chosen at random from
the community, then we want to compute the joint probability that his family has M male
pets and F female pets.
These probabilities are as follows:
P{F = 0, M = 0} = P{no pets} = 0.5,
(16.7.9)
P{F = 1, M = 0} = P{1 female and total of 1 pet}
(16.7.10)
= P{1 pet}P{1 female|1 pet}
(16.7.11)
= (0.5)(0.6) × 1
2 = 0.15,
(16.7.12)
P{F = 2, M = 0} = P{2 females and total of 2 pets}
(16.7.13)
= P{2 pets}P{2 females|2 pets}
(16.7.14)
= (0.5)(0.3) ×
1
2
2
= 0.0375,
(16.7.15)
and
P{F = 3, M = 0} = P{3 females and total of 3 pets}
(16.7.16)
= P{3 pets}P{3 females|3 pets}
(16.7.17)
= (0.5)(0.1) ×
1
2
3
= 0.00625.
(16.7.18)
The remaining probabilities can be obtained in a similar manner.
⊓⊔
Continuous joint distribution
Let us now turn to the case when we have two continuous random variables. In analog
with the deﬁnition given in Section 16.4, we deﬁne the two-dimensional probability density
pXY (x, y) by
P(x < X ≤x + dx, y < Y ≤y + dy) = pXY (x, y) dx dy.
(16.7.19)
Here, the comma in the probability parentheses means “and also.”
Repeating the same analysis as in Section 16.4, we ﬁnd that pXY (x, y) must be a
single-valued function with pXY (x, y) ≥0, and
Z ∞
−∞
Z ∞
−∞
pXY (x, y) dx dy = 1.
(16.7.20)

Probability
845
The joint distribution function of X and Y is
FXY (x, y) = P(X ≤x, Y ≤y) =
Z x
−∞
Z y
−∞
pXY (ξ, η) dξ dη.
(16.7.21)
Therefore,
P(a < X ≤b, c < Y ≤d) =
Z b
a
Z d
c
pXY (ξ, η) dξ dη.
(16.7.22)
The marginal probability density functions are deﬁned by
pX(x) =
Z ∞
−∞
pXY (x, y) dy,
and
pY (y) =
Z ∞
−∞
pXY (x, y) dx.
(16.7.23)
An important distinction exists upon whether the random variables are independent or not.
Two variables X and Y are independent if and only if
pXY (x, y) = pX(x)pY (y),
(16.7.24)
and conversely.
• Example 16.7.4
The joint probability density function of bivariate random variables (X, Y ) is
pXY (x, y) =

kxy,
0 < y < x < 1,
0,
otherwise,
(16.7.25)
where k is a constant. (a) Find the value of k. (b) Are X and Y independent?
The range RXY for this problem is a right triangle with its sides given by x = 1, y = 0,
and y = x. From Equation 16.7.20,
Z ∞
−∞
Z ∞
−∞
pXY (x, y) dx dy = k
Z 1
0
x
Z x
0
y dy

dx = k
Z 1
0
x y2
2

x
0
dx
(16.7.26)
= k
2
Z 1
0
x3 dx = k
8 x41
0 = k
8.
(16.7.27)
Therefore, k = 8.
To check for independence we must ﬁrst compute pX(x) and pY (y). From Equation
16.7.23 and holding x constant,
pX(x) = 8x
Z x
0
y dy = 4x3,
0 < x < 1;
(16.7.28)
pX(x) = 0 otherwise. From Equation 16.7.23 and holding y constant,
pY (y) = 8y
Z 1
y
x dx = 4y(1 −y2),
0 < y < 1.
(16.7.29)
Because pXY (x, y) ̸= pX(x)pY (y), X and Y are not independent.
⊓⊔

846
Advanced Engineering Mathematics with MATLAB
L
cos
Θ
L 
(θ)
(b) no intersection
Θ
LL cos(θ)
O
X
X
O
(a) intersection
Figure 16.7.1: Schematic of Buﬀon’s needle problem showing the random variables X and Θ.
• Example 16.7.5: Buﬀon’s needle problem
A classic application of joint probability distributions is the solution of Buﬀon’s needle
problem:8 Consider an inﬁnite plane with an inﬁnite series of parallel lines spaced a unit
distance apart. A needle of length L < 1 is thrown upward and we want to compute the
probability that the stick will land so that it intersects one of these lines. See Figure 16.7.1.
There are two random variables that determine the needle’s orientation: X, the distance
from the lower end O of the needle to the nearest line above and Θ, the angle from the
vertical to the needle. Of course, we assume that the position where the needle lands is
random; otherwise, it would not be a probability problem.
Let us deﬁne X ﬁrst. Its possible values lie between 0 and 1. Second, X is uniformly
distributed on (0, 1) with the probability density
pX(x) =
 1,
0 ≤x ≤1,
0,
otherwise.
(16.7.30)
Turning to Θ, its value lies between −π/2 to π/2 and is uniformly distributed between these
values. Therefore, the probability density is
pΘ(θ) =

1/π,
−π/2 < θ < π/2,
0,
otherwise.
(16.7.31)
The probability p that we seek is
p = P{needle intersects line} = P{X < L cos(Θ)}.
(16.7.32)
Because X and Θ are independent, their joint density equals the product of the densities
for X and Θ: pXΘ(x, θ) = pX(x)pΘ(θ).
The ﬁnal challenge is to use pXΘ(x, θ) to compute p. In Section 16.2 we gave a geometric
deﬁnition of probability. The area of the sample space is π because it consists of a rectangle
in (X, Θ) space with 0 < x < 1 and −π/2 < θ < π/2.
The values of X and Θ that
8 First posed in 1733, its solution is given on pages 100–104 of Buﬀon, G., 1777: Essai d’arithm´etique
morale. Histoire naturelle, g´en´erale et particuli`ere, Suppl´ement, 4, 46–123.

Probability
847
lead to the intersection with a parallel line is 0 < x < L cos(θ) where −π/2 < θ < π/2.
Consequently, from Equation 16.2.5,
p =
Z π/2
−π/2
Z L cos(θ)
0
pXΘ(x, θ) dx dθ =
Z π/2
−π/2
Z L cos(θ)
0
pX(x)pΘ(θ) dx dθ
(16.7.33)
= 1
π
Z π/2
−π/2
Z L cos(θ)
0
dx dθ = 1
π
Z π/2
−π/2
L cos(θ) dθ = 2L
π .
(16.7.34)
Consequently, given L, we can perform the tossing either physically or numerically, measure
p, and compute the value of π.
⊓⊔
Convolution
It is often important to calculate the distribution of X + Y from the distribution of
X and Y when X and Y are independent. We shall derive the relationship for continuous
random variables and then state the result for X and Y discrete.
Let X have a probability density function pX(x) and Y has the probability density
pY (y). Then the cumulative distribution function of X + Y is
GX+Y (a) = P(x + y ≤a) =
Z Z
x+y≤a
pX(x)pY (y) dx dy
(16.7.35)
=
Z ∞
−∞
Z a−y
−∞
pX(x)pY (y) dx dy =
Z ∞
−∞
Z a−y
−∞
pX(x) dx

pY (y) dy
(16.7.36)
=
Z ∞
−∞
FX(a −y)pY (y) dx.
(16.7.37)
Therefore,
pX+Y (a) = d
da
Z ∞
−∞
FX(a −y)pY (y) dy

=
Z ∞
−∞
pX(a −y)pY (y) dy.
(16.7.38)
In the case when X and Y are discrete,
pX+Y [ak] =
∞
X
i=−∞
pX[xi]pY [ak −xi].
(16.7.39)
Covariance
In Section 16.5 we introduced the concept of variance of a random variable X. There
we showed that this quantity measures the dispersion, or spread, of the distribution of X
about its expectation. What about the case of two jointly distributed random numbers?
Our ﬁrst attempt might be to look at Var(X) and Var(Y ). But this would simply
display the dispersions of X and Y independently rather than jointly.
Indeed, Var(X)
would give the spread along the x-direction while Var(Y ) would measure the dispersion
along the y-direction.

848
Advanced Engineering Mathematics with MATLAB
Consider now Var(aX +bY ), the joint spread of X and Y along the (ax+by)-direction
for two arbitrary real numbers a and b. Then
Var(aX + bY ) = E[(aX + bY ) −E(aX + bY )]2
(16.7.40)
= E[(aX + bY ) −E(aX) −E(bY )]2
(16.7.41)
= E{a[X −E(X)] + b[Y −E(Y )]}2
(16.7.42)
= E{a2[X −E(X)]2 + b2[Y −E(Y )]2 + 2ab[X −E(X)][Y −E(Y )]}
(16.7.43)
= a2Var(X) + b2Var(Y ) + 2abE{[X −E(X)][Y −E(Y )]}.
(16.7.44)
Thus, the joint spread or dispersion of X and Y in any arbitrary direction ax + by depends
upon three parameters: Var(X), Var(Y ), and E{[X −E(X)][Y −E(Y )]}. Because Var(X)
and Var(Y ) give the dispersion of X and Y separately, it is the quantity E{[X −E(X)][Y −
E(Y )]} that measures the joint spread of X and Y . This last quantity,
Cov(X, Y ) = E{[X −E(X)][Y −E(Y )]},
(16.7.45)
is called the covariance and is usually denoted by Cov(X, Y ) because it determines how X
and Y covary jointly. It only makes sense when we have two diﬀerent random variables
because in the case of a single random variable, Cov(X, X) = σ2
X = Var(X). Furthermore,
Cov(X, Y ) ≤σXσY . In summary,
Var(aX + bY ) = a2 Var(X) + b2 Var(Y ) + 2ab Cov(X, Y ).
(16.7.46)
An alternative method for computing the covariance occurs if we recall that µX = E(X)
and µY = E(Y ). Then
Cov(X, Y ) = E[(X −µX)(Y −µY )] = E(XY −µXY −µY X + µXµY )
(16.7.47)
= E(XY ) −µXE(Y ) −µY E(X) + µXµY
(16.7.48)
= E(XY ) −µXµY −µY µX + µXµY
(16.7.49)
= E(XY ) −µXµY = E(XY ) −E(X)E(Y ),
(16.7.50)
where
E(XY ) =







X
xi∈A,yj∈B
xiyj pXY [xi, yj],
X discrete,
Z ∞
−∞
Z ∞
−∞
xy pXY (x, y) dx dy,
X continuous.
(16.7.51)
Therefore,
Cov(X, Y ) = E(XY ) −E(X)E(Y ).
(16.7.52)
It is left as a homework assignment to show that
Cov(aX + b, cY + d) = ac Cov(X, Y ).
(16.7.53)
In general, Cov(X, Y ) can be positive, negative, or zero.
For it to be positive, X
and Y decrease together or increase together.
For a negative value, X would increase
while Y decreases, or vice versa. If Cov(X, Y ) > 0, X and Y are positively correlated. If

Probability
849
Cov(X, Y ) < 0, X and Y are negatively correlated. Finally, if Cov(X, Y ) = 0, X and Y are
uncorrelated.
• Example 16.7.6
The following table gives a discrete joint density function:
xi
pXY [xi, yj]
0
1
2
pY [yj]
0
3
28
9
28
3
28
15
28
yj
1
3
14
3
14
0
3
7
2
1
28
0
0
1
28
pX[xi]
5
14
15
28
3
28
Because
E(XY ) =
2
X
i=0
2
X
j=0
xi yj pXY [xi, yj] = 3
14,
(16.7.54)
µX = E(X) =
2
X
i=0
xi pX[xi] = 3
4,
and
µY = E(Y ) =
2
X
j=0
yj pY [yj] = 1
2, (16.7.55)
then
Cov(X, Y ) = E(XY ) −E(X)E(Y ) = 3
14 −3
4 · 1
2 = −9
56.
(16.7.56)
Therefore, X and Y are negatively correlated.
⊓⊔
• Example 16.7.7
The random variables X and Y have the joint probability density function
pXY (x, y) =
 x + y,
0 < x < 1, 0 < y < 1,
0,
otherwise.
(16.7.57)
Let us compute the covariance.
First, we must compute pX(x) and pY (y). We ﬁnd that
pX(x) =
Z 1
0
pXY (x, y) dy =
Z 1
0
(x + y) dy = x + 1
2
(16.7.58)
for 0 < x < 1, and
pY (y) =
Z 1
0
pXY (x, y) dx =
Z 1
0
(x + y) dx = y + 1
2
(16.7.59)

850
Advanced Engineering Mathematics with MATLAB
for 0 < y < 1.
Because
E(XY ) =
Z 1
0
Z 1
0
xy(x + y) dx dy =
Z 1
0
 
y x3
3

1
0
+ y2 x2
2

1
0
!
dy
(16.7.60)
=
Z 1
0
y
3 + y2
2

dy = y2
6 + y2
6

1
0
= 1
3,
(16.7.61)
µX = E(X) =
Z 1
0
x pX(x) dx =
Z 1
0

x2 + x
2

dx = 7
12,
(16.7.62)
µY = E(Y ) =
Z 1
0
y pY (y) dy =
Z 1
0

y2 + y
2

dy = 7
12,
(16.7.63)
then
Cov(X, Y ) = E(XY ) −E(X)E(Y ) = 1
3 −49
144 = −1
144.
(16.7.64)
Therefore, X and Y are negatively correlated.
⊓⊔
Correlation
Although the covariance tells us how X and Y vary jointly, it depends upon the same
units in which X and Y are measured. It is often better if we free ourselves of this nuisance,
and we now introduce the concept of correlation.
Let X and Y be two random variables with 0 < σ2
X < ∞and 0 < σ2
Y < ∞. The
correlation coeﬃcient ρ(X, Y ) between X and Y is given by
ρ(X, Y ) = Cov
X −E(X)
σX
, Y −E(Y )
σY

= Cov(X, Y )
σXσY
.
(16.7.65)
It is noteworthy that |ρ(X, Y )| ≤1.
Random Vectors
It is often useful to express our two random variables X and Y as a two-dimensional
random vector V = (X Y )T . Then, the covariance can be written as 2 × 2 covariance
matrix, given by

cov(X, X)
cov(X, Y )
cov(Y, X)
cov(Y, Y )

.
These considerations can be generalized into the n-dimensional random vector consisting of
n random variables that are all associated with the same events.
• Example 16.7.7
Using MATLAB, let us create two random variables by invoking X = randn(N,1) and Y
= randn(N,2), where N is the sample size. If N = 10, we would ﬁnd that using the MATLAB
command cov(X,Y) would yield

Probability
851
X
-4
-2
0
2
4
Y
-4
-2
0
2
4
Figure 16.7.2: Scatter plot of points (Xi, Yi) given by the random vector V in Example 16.7.7 when N =
1000.
>> ans =
3.1325
0.9748
0.9748
1.4862
.
(If you do this experiment, you will also obtain a symmetric matrix but with diﬀerent
elements.) On the other hand, if N = 1000, we ﬁnd that cov(X,Y) equals
>> ans =
0.9793
−0.0100
−0.0100
0.9927 .
The interpretation of the covariance matrix is as follows: The variance (or spread)
of data given by X and Y is (essentially) unity.
The correlation between X and Y is
(essentially) zero. These results are conﬁrmed in Figure 16.7.2 where we have plotted X
and Y as the data points (Xi, Yi) when N = 1000. We can see the symmetric distribution
of data points.
Problems
1. A search committee of 5 is selected from a science department that has 7 mathematics
professors, 8 physics professors, and 5 chemistry professors. If X and Y denote the number
of mathematics and physics professors, respectively, that are selected, calculate the joint
probability function.
2. In an experiment of rolling a fair die twice, let Z denote a random variable that equals
the sum of the results. What is pZ[zi]? Hint: Let X denote the result from the ﬁrst toss
and Y denote the result from the second toss. What you must ﬁnd is Z = X + Y .
3. Show that Cov(aX + b, cY + d) = ac Cov(X, Y ).

852
Advanced Engineering Mathematics with MATLAB
−0.5
0
0.5
1
1.5
2
2.5
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
 z
Estimated  pZ(z)
Convolution Project
Project: Convolution
Consider two independent, uniformly distributed random variables (X, Y ) that are summed
to give Z = X + Y with
pX(x) =
 1,
0 < x < 1,
0,
otherwise,
and
pY (y) =
 1,
0 < y < 1,
0,
otherwise.
Show that
pZ(z) =
(
z,
0 < z ≤1,
2 −z,
1 < z ≤2,
0,
otherwise.
Then conﬁrm your results using MATLAB’s intrinsic function rand to generate {xi} and
{yj} and computing pZ(z). You may want to review Example 11.5.1.
Further Readings
Beckmann, P., 1967: Probability in Communication Engineering. Harcourt, Brace & World,
511 pp. A presentation of probability as it applies to problems in communication engineer-
ing.
Ghahramani, S., 2000: Fundamentals of Probability. Prentice Hall, 511 pp. Nice introduc-
tory text on probability with a wealth of examples.
Hsu, H., 1997: Probability, Random Variables, & Random Processes. McGraw-Hill, 306 pp.
Summary of results plus many worked problems.
Kay, S. M., 2006: Intuitive Probability and Random Processes Using MATLAB. Springer,
833 pp. A well-paced book designed for the electrical engineering crowd.
Ross, S. M., 2007: Introduction to Probability Models. Academic Press, 782 pp. An intro-
ductory undergraduate book in applied probability and stochastic processes.

Probability
853
Tuckwell, H. C., 1995: Elementary Applications of Probability Theory. Chapman & Hall,
292 pp. This book presents applications using probability theory, primarily from biology.

Chapter 17
Random Processes
In the previous chapter we introduced the concept of a random variable X. There X
assumed various values of x according to a probability mass function pX[k] or probability
density function pX(x). In this chapter we generalize the random variable so that it is also
a function of time t. As before, the values of x assumed by the random variable X(t) at a
certain time is still unknown beforehand and unpredictable.
Our random, time-varying variable X(t; ξ) is often used to describe a stochastic or
random process. In that case, X(t) is the state of the process at time t. The process can
be either discrete or continuous in t.
A random process is not one function but a collection or family of functions, called
sample functions, with some probability assigned to each. When we perform an experiment,
we observe only one of these functions that is called a realization or sample path
of the
process. To observe more than a single function, we must repeat the experiment.
The state space of a random process is the set of all possible values that the random
variable X(t) can assume.
We can view random processes from many perspectives. First, it is a random function of
time. This perspective is useful when we wish to relate an evolutionary physical phenomenon
to its probabilistic model. Second, we can focus on its aspect as a random variable. This is
useful in developing mathematical methods and tools to analyze random processes.
Another method for characterizing a random process examines its behavior as t and ξ
vary or are kept constant. For example, if we allow t and ξ to vary, we obtain a family or
ensemble of X(t). If we allow t to vary while ξ is ﬁxed, then X(t) is simply a function of
time and gives a sample function or realization for this particular random process. On the
other hand, if we ﬁx t and allow ξ to vary, X(t) is a random variable equal to the state of
the random process at time t. Finally, if we ﬁx both t and ξ, then X(t) is a number.
855

856
Advanced Engineering Mathematics with MATLAB
0
20
40
60
80
100
−1
−0.5
0
0.5
1
 t
 X(t)/a
Figure 17.0.1: A realization of the random telegraph signal.
• Example 17.0.1
Consider a random process X(t) = A, where A is uniformly distributed in the interval
[0, 1]. A plot of sample functions of X(t) (a plot of X(t) as a function of t) consists of
horizontal straight lines that would cross the ordinate somewhere between 0 and 1.
⊓⊔
• Example 17.0.2
Consider the coin tossing experiment where the outcomes are either heads H or tails
T. We can introduce the random process deﬁned by
X(t; H) = sin(t),
and
X(t; T) = cos(t).
(17.0.1)
Note that the sample functions here are continuous functions of time.
⊓⊔
• Example 17.0.3: Random telegraph signal
Consider a signal that switches between −a and +a at random times. Suppose the
process starts (at time t = 0) in the −a state. It then remains in that state for a time
interval T1 at which point it switches to the state X(t) = a. The process remains in that
state until t = T2, then switches back to X(t) = −a. The switching time is given by a
Poisson process, a random process that we discuss in Section 17.6. Figure 17.0.1 illustrates
the random telegraph signal.
⊓⊔
Of all the possible random processes, a few are so useful in engineering and the physical
sciences that they warrant special names. Some of them are:
• Bernoulli process
Imagine an electronics ﬁrm that produces electronic devices that either work (a success
denoted by “S” ) or do not work (a failure or denoted “F”). We can model the production
line as a series of independent, repeated events where p denotes the probability of producing
a working device and q = 1 −p is the probability of producing a faulty device. Thus, the
production line can be modeled as random process, called a Bernoulli process, which has
discrete states and parameter space.

Random Processes
857
0
5
10
15
20
25
30
−0.5
0
0.5
1
1.5
 x[k,s]
Realization 1
0
5
10
15
20
25
30
−0.5
0
0.5
1
1.5
 x[k,s]
Realization 2
0
5
10
15
20
25
30
−0.5
0
0.5
1
1.5
 k
 x[k,s]
Realization 3
Figure 17.0.2: Three realization or sample functions of a Bernoulli random process with p = 0.4. The
realization starts at k = 0 and continues forever.
The dashed box highlights the values of the random
variable X[21, s].
If we denote each discrete trial by the integer k, a Bernoulli process generates successive
outcomes at times k = 0, 1, 2, . . .. Mathematically we can express this discrete random
process by X[k, s] where k denotes the time and s denotes the number of the realization
or sample function.
Furthermore, this random process maps the original experimental
sample space {(F, F, S, . . .), (S, F, F, . . .), (F, F, F, . . .), . . .} to the numerical sample space
{(0, 0, 1, . . .), (1, 0, 0, . . .), (0, 0, 0, . . .), . . .}. Unlike the Bernoulli trial that we examined in
the previous chapter, each simple event now becomes an inﬁnite sequence of S’s and F’s.
Figure 17.0.2 illustrates three realizations or sample functions for a Bernoulli random
variable when p = 0.4. In each realizations s = 1, 2, . . ., the abscissa denotes time where
each successive trial occurs at times k = 0, 1, 2, . . .. When we ﬁx the value of k, the quantity
X[k, s] is a random variable with a probability mass function of a Bernoulli random variable.
• Markov process
Communication systems transmit either the digits 0 or 1. Each transmitted digit often
must pass through several stages. At each stage there is a chance that the digit that enters
one stage will be changed by the time when it leaves.
A Markov process is a stochastic process that describes the probability that the digit
will or will not be changed. It does this by computing the conditional distribution of any
future state Xn+1 by considering only the past states X0, X1, . . . , Xn−1 and the present
state Xn.
In Section 17.4 we examine the simplest possible discrete Markov process, a
Markov chain, when only the present and previous stages are involved. An example is the
probabilistic description of birth and death, which is given in Section 17.5.
• Poisson process
The prediction of the total number of “events” that occur by time t is important to
such diverse ﬁelds as telecommunications and banking. The most popular of these counting
processes is the Poisson process. It occurs when:

858
Advanced Engineering Mathematics with MATLAB
1. The events occur “rarely.”
2. The events occur in nonoverlapping intervals of time that are independent of each other.
3. The events occur at a constant rate λ.
In Section 17.6 we explore this random process.
• Wiener process
A Wiener process Wt is a random process that is continuous in time and possesses the
following three properties:
1. W0 = 0,
2. Wt is almost surely continuous, and
3. Wt has independent increments with a distribution Wt−Ws ∼N(0, t−s) for 0 ≤s ≤t.
As a result of these properties, we have that
1. the expectation is zero, E(Wt) = 0,
2. the variance is E(W 2
t ) −E2(Wt) = t, and
3. the covariance is cov(Ws, Wt) = min(s, t).
Norbert Wiener (1894–1964) developed this process to rigorously describe the physical
phenomena of Brownian motion - the apparent random motion of particles suspended in
a ﬂuid. In a Wiener process the distances traveled in Brownian motion are distributed
according to a Gaussian distribution and the path is continuous but consists entirely of
sharp corners.
Project: Gambler’s Ruin Problem
Pete and John decide to play a coin-tossing game. Pete agrees to pay John 10 cents
whenever the coin yields a “head” and John agrees to pay Pete 10 cents whenever it
is a “tail.”
Let Sn denote the amount that John earns in n tosses of a coin.
This
game is a stochastic process with discrete time (number of tosses).
The state space is
{0, ±10, ±20, · · ·} cents. A realization occurs each time that they play a new game.
Step 1: Create a MATLAB code to compute a realization of Sn. Plot several realizations
(sample functions) of this random process. See Figure 17.0.3.
Step 2: Suppose Pete has 10 dimes. Therefore, there is a chance he will run out of dimes at
some n = N. Modify your MATLAB code to construct a probability density function that
gives the probability Pete will run out of money at time n = N. See Figure 17.0.3. This is
an example of the famous gambler’s ruin problem.
17.1 FUNDAMENTAL CONCEPTS
In Section 16.5 we introduced the concepts of mean (or expectation) and variance as
it applies to discrete and continuous random variables. These parameters provide useful
characterizations of a probability mass function or probability density function. Similar
considerations hold in the case of random processes and we introduce them here.
Mean and variance
We deﬁne the mean of the random process X(t) as the expected value of the process
- that is, the expected value of the random variable deﬁned by X(t) for a ﬁxed instant of

Random Processes
859
0
200
400
600
800
1000
−50
0
50
100
number of tosses
gain/loss (in dimes)
0
200
400
600
800
1000
0
1
2
3
4x 10
−3
N
Estimated PDF
Figure 17.0.3: (a) Top frame: John’s gains or losses as the result of the three diﬀerent coin tossing games.
(b) The probability density function for John’s winning 10 dimes as a function of the number of tosses that
are necessary to win 10 dimes.
time. Note that when we take the expectation, we hold the time as a nonrandom parameter
and average only over the random quantities. We denote this mean of the random process
by µX(t), since, in general, it may depend on time. The deﬁnition of the mean is just the
expectation of X(t):
µX(t) = E[X(t)] =
Z ∞
−∞
x pX(t)(t; x) dx.
(17.1.1)
In a similar vein, we can generalize the concept of variance so that it applies to random
processes. Here variance also becomes a time-dependent function deﬁned by
σ2
X(t) = Var[X(t)] = E
n
[X(t) −µX(t)]2o
.
(17.1.2)
• Example 17.1.1: Random linear trajectories
Consider the random process deﬁned by
X(t) = A + Bt,
(17.1.3)
where A and B are uncorrelated random variables with means µA and µB. Let us ﬁnd the
mean of this random process.
From the linearity property of expectation, we have that
µX(t) = E[X(t)] = E(A + Bt) = E(A) + E(B)t = µA + µBt.
(17.1.4)
⊓⊔

860
Advanced Engineering Mathematics with MATLAB
• Example 17.1.2: Random sinusoidal signal
A random sinusoidal signal is one governed by X(t) = A cos(ω0t + Θ), where A and
Θ are independent random variables, A has a mean µA and variance σ2
A, and Θ has the
probability density function pΘ(x) that is nonzero only over the interval (0, 2π).
The mean of X(t) is given by
µX(t) = E[X(t)] = E[A cos(ω0t + Θ)] = E[A]E[cos(ω0t + Θ)].
(17.1.5)
We have used the property that the expectation of two independent random variables equals
the product of the expectation of each of the random variables. Simplifying Equation 17.1.5,
µX(t) = µA
Z 2π
0
cos(ω0t + x)pΘ(x) dx.
(17.1.6)
A common assumption is that pΘ(x) is uniformly distributed in the interval (0, 2π), namely
pΘ(x) = 1
2π ,
0 < x < 2π.
(17.1.7)
Substituting Equation 17.1.7 into Equation 17.1.6, we ﬁnd that
µX(t) = µA
2π
Z 2π
0
cos(ω0t + x) dx = 0.
(17.1.8)
⊓⊔
• Example 17.1.3: Wiener random process or Brownian motion
A Wiener (random) process is deﬁned by
X(t) =
Z t
0
U(ξ) dξ,
t ≥0,
(17.1.9)
where U(t) denotes white Gaussian noise. It is often used to model Brownian motion. To
ﬁnd its mean, we have that
E[X(t)] = E
Z t
0
U(ξ) dξ

=
Z t
0
E[U(ξ)] dξ = 0,
(17.1.10)
because the mean of white Gaussian noise equals zero.
⊓⊔
Autocorrelation function
When a random process is examined at two time instants t = t1 and t = t2, we obtain
two random variables X(t1) and X(t2). A useful relationship between these two random
variables is found by computing their correlation as a function of time instants t1 and t2.
Because it is a correlation between the values of the same process sampled at two diﬀerent

Random Processes
861
instants of time, we shall call it the autocorrelation function of the process X(t) and denote
it by RX(t1, t2). It is deﬁned in the usual way for expectations by
RX(t1, t2) = E[X(t1)X(t2)].
(17.1.11)
Just as in the two random variables case, we can deﬁne the covariance and correlation
coeﬃcient, but here the name is slightly diﬀerent. We deﬁne the autocovariance function
as
CX(t1, t2) = E{[X(t1) −µX(t1)][X(t2) −µX(t2)]}
(17.1.12)
= RX(t1, t2) −µX(t1)µX(t2).
(17.1.13)
Note that the variance of the process and its average power (the names used for the average
of [X(t)−µX(t)]2 and [X(t)]2, respectively) can be directly obtained for the autocorrelation
and the autocovariance functions, by simply using the same time instants for both t1 and
t2:
E{[X(t)]2} = RX(t, t),
(17.1.14)
and
σ2
X(t) = E{[X(t) −µX(t)]2} = CX(t, t) = RX(t, t) −µ2
X(t).
(17.1.15)
Therefore, the average power, Equation 17.1.14, and the variance, Equation 17.1.15, of
the process follows directly from the deﬁnition of the autocorrelation and autocovariance
functions.
• Example 17.1.4: Random linear trajectories
Let us continue Example 17.1.1 and ﬁnd the autocorrelation of a random linear trajec-
tory given by X(t) = A + Bt. From the deﬁnition of the autocorrelation,
RX(t1, t2) = E[X(t1)X(t2)] = E{[A + Bt1][A + Bt2]}
(17.1.16)
= E(A2) + E(AB)(t1 + t2) + E(B2)t1t2
(17.1.17)
= (σ2
A + µ2
A) + µAµB(t1 + t2) + (σ2
B + µ2
B)t1t2,
(17.1.18)
where σ2
A and σ2
B are the variances of the random variables A and B. We can easily ﬁnd
the autocovariance by
CX(t1, t2) = RX(t1, t2) −µX(t1)µX(t2) = σ2
A + σ2
Bt1t2.
(17.1.19)
⊓⊔
• Example 17.1.5: Random sinusoidal signal
We continue to examine the random sinusoidal signal given by X(t) = A cos(ω0t + Θ).
The autocorrelation function is
RX(t1, t2) = E[X(t1)X(t2)] = E[A cos(ω0t1 + Θ)A cos(ω0t2 + Θ)]
(17.1.20)
= 1
2E(A2)E[cos(ω0t2 −ω0t1) + cos(ω0t2 + ω0t1 + 2Θ)]
(17.1.21)
= 1
2(σ2
A + µ2
A)

cos[ω0(t2 −t1)] +
Z 2π
0
cos[ω0(t2 + t1) + 2x]pΘ(x) dx

.(17.1.22)

862
Advanced Engineering Mathematics with MATLAB
In our derivation we used (1) the property that the expectation of A2 equals the sum of
the variance and the square of the mean, and (2) the ﬁrst term involving the cosine is
not random because it is a function of only the time instants and the frequency. From
Equation 17.1.22 we see that autocorrelation function may depend on both time instants
if the probability density function of the phase angle is arbitrary. On the other hand, if
pΘ(x) is uniformly distributed, then the last term in Equation 17.1.22 vanishes because
integrating the cosine function over the interval of one period is zero. In this case we can
write the autocorrelation function as a function of only the time diﬀerence. The process
also becomes wide-sense stationary with
RX(τ) = E[X(t)X(t + τ)] = 1
2(σ2
A + µ2
A) cos(ω0τ).
(17.1.23)
⊓⊔
Wide-sense stationary processes
A process is strictly stationary if its distribution and density functions do not depend
on the absolute values of the time instants t1 and t2 but only on the diﬀerence of the time
instants, |t1 −t2|. However, this is a very rigorous condition. If we are concerned only with
the mean and autocorrelation function, then we can soften our deﬁnition of a stationary
process to a limited form, and we call such processes wide-sense stationary processes. A
wide-sense stationary process has a constant mean, and its autocorrelation function depends
only on the time diﬀerence:
µX(t) = E[X(t)] = µX,
(17.1.24)
and
RX(t1, t2) = E[X(t1)X(t2)] = RX(t2 −t1).
(17.1.25)
Because time does not appear in the mean, we simply write it as a constant mean value µX.
Similarly, because the autocorrelation function is a function only of the time diﬀerence, we
can write it as a function of a single variable, the time diﬀerence τ:
RX(τ) = E[X(t)X(t + τ)].
(17.1.26)
We can obtain similar expressions for the autocovariance function, which in this case de-
pends only on the time diﬀerence as well:
CX(τ) = E{[X(t) −µX][X(t + τ) −µX]} = RX(τ) −µ2
X.
(17.1.27)
Finally, the average power and variance for a wide-sense stationary process are
E{[X(t)]2} = RX(0),
(17.1.28)
and
σ2
X = CX(0) = RX(0) −µ2
X,
(17.1.29)
respectively. Therefore, a wide-sense stationary process has a constant average power and
constant variance.

Random Processes
863
Problems
1. Find µX(t) and σ2
X(t) for the random process given by X(t) = A cos(ωt), where ω is
a constant and A is a random variable with the Gaussian (or normal) probability density
function
pX(x) =
1
√
2π e−x2/2.
2. Consider a sine-wave random process X(t) = A cos(ωt+Θ), where A and ω are constants
with A > 0. The phase function Θ is a random, uniform variable on the interval [−π, π].
Find the mean and autocorrelation for this random function.
3.
Consider a countably inﬁnite sequence {Xn, n = 0, 1, 2, 3, . . .} of a random variable
deﬁned by
Xn =

1,
for success in the nth trial,
0,
for failure in the nth trial,
with the probabilities P(Xn = 0) = 1 −p and P(Xn = 1) = p. Thus, Xn is a Bernoulli
process. For this process, E(Xn) = p and Var(Xn) = p(1−p). Show that the autocorrelation
is
RX(t1, t2) =
 p,
t1 = t2,
p2,
t1 ̸= t2;
and the autocovariance is
CX(t1, t2) =

p(1 −p),
t1 = t2,
0,
t1 ̸= t2.
Project: Computing the Autocorrelation Function
In most instances you must compute the autocorrelation function numerically. The
purpose of this project is to explore this computation using the random telegraph signal.
The exact solution is given by Equation 17.2.24. You will compute the autocorrelation two
ways:
Step 1: Using Example 17.6.1, create MATLAB code that generates 500 realizations of the
random telegraph signal.
Step 2: Choosing an arbitrary time tS, compute Xk(tS)Xk(tS + τ) for 0 ≤0 ≤τmax and
k = 1, 2, 3, . . . , 500. Then ﬁnd the average value of Xk(tS)Xk(tS + τ). Plot RX(τ) as a
function of τ and include the exact answer for comparison. Does it matter how many sample
functions you use?
Step 3: Now introduce a number of times tm = m∆t, where m = 0, 1, 2, . . . , M. Using only
a single realization k = K of your choice, compute XK(m∆t) × XK(m∆t + τ). Then ﬁnd
the average value of XK(m∆t)XK(m∆t + τ) and plot this result as a function of τ. On the
same plot, include the exact solution. Does the value of ∆t matter? See Figure 17.1.1

864
Advanced Engineering Mathematics with MATLAB
0
0.2
0.4
0.6
0.8
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
τ
 RX
0
0.2
0.4
0.6
0.8
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
τ
(a)
(b)
Figure 17.1.1: The autocorrelation function RX(τ) for the random telegraph signal as a function of τ
when λ = 2. The dashed line gives the exact solution. In frame (a) Xk(tS)Xk(tS +τ) has been averaged over
500 realizations when tS = 2. In frame (b) X200(m∆t)X200(m∆t + τ) has been averaged with M = 1200
and ∆t = 0.01.
17.2 POWER SPECTRUM
In earlier chapters we provided two alternative descriptions of signals, either in the
time domain, which provides information on the shape of the waveform, or in the frequency
domain, which provides information on the frequency content. Because random signals do
not behave in any predictable fashion nor are they represented by a single function, it is
unlikely that we can deﬁne the spectrum of a random signal by taking its Fourier transform.
On the other hand, the autocorrelation of random signals describes in some sense whether
the signal changes rapidly or slowly. In this section we explain and illustrate the concept
of power spectrum of random signals.
For a wide-sense stationary random signal X(t) with autocorrelation function RX(τ),
the power spectrum SX(ω) of the random signal is the Fourier transform of the autocorre-
lation function:
SX(ω) =
Z ∞
−∞
RX(τ)e−iωτ dτ.
(17.2.1)
Consequently, the autocorrelation can be obtained from inverse Fourier transform of the
power spectrum, or
RX(τ) = 1
2π
Z ∞
−∞
SX(ω)eiωτ dω.
(17.2.2)
As with any Fourier transform, it enjoys certain properties. They are:
1. The power spectrum is real and even: SX(−ω) = SX(ω) and S∗
X(ω) = SX(ω), where
S∗
X(ω) denotes the complex conjugate value of SX(ω).
2. The power spectrum is nonnegative: SX(ω) ≥0.
3. The average power of the random signal is equal to the integral of the power spectrum:
E{[X(t)]2} = RX(0) = 1
π
Z ∞
0
SX(ω) dω.
(17.2.3)

Random Processes
865
4. If the random signal has nonzero mean µX, then its power spectrum contains an impulse
at zero frequency of magnitude 2πµ2
X.
5. The Fourier transform of the autocovariance function of the random process is itself
also a power spectrum and usually does not contain an impulse component in zero
frequency.
Consider the following examples of the power spectrum:
• Example 17.2.1: Random sinusoidal signal
The sinusoidal signal is deﬁned by
X(t) = A cos(ω0t + Θ),
(17.2.4)
where the phase is uniformly distributed in the interval [0, 2π]. If the amplitude A has a
mean of zero and a variance of σ2, then the autocorrelation function is
RX(τ) = 1
2σ2 cos(ω0τ) = RX(0) cos(ω0τ).
(17.2.5)
The power spectrum of this signal is then
SX(ω) =
Z ∞
−∞
RX(0) cos(ω0τ)e−iωτ dτ = RX(0)π [δ(ω −ω0) + δ(ω + ω0)] .
(17.2.6)
Because this signal contains only one frequency ω0, its power spectrum is just two impulses,
one at ω0 and one at −ω0. Since the negative frequency appears due only to the even
property of the power spectrum, it is clear that all power is concentrated at the frequency
of the sinusoidal signal. While this is a very simple example, it does illustrate that the
power spectrum indeed represents the way the power in the random signal is distributed
among the various frequencies.
We shall see later that if we also use linear systems in
order to amplify or attenuate certain frequencies, the results mirror what we expect in the
deterministic case.
⊓⊔
• Example 17.2.2: Modulated signal
Let us now examine a sinusoidal signal modulated by another random signal that
contains low frequencies. This random process is described by
Y (t) = X(t) cos(ω0t + Θ),
(17.2.7)
where the phase angle in Equation 17.2.7 is a random variable that is uniformly distributed
in the interval [0, 2π] and is independent of X(t). Then the autocorrelation function of Y (t)
is given by
RY (τ) = E[Y (t)Y (t + τ)] = E{X(t) cos(ω0t + Θ)X(t + τ) cos[ω0(t + τ) + Θ]}
(17.2.8)
= E[X(t)X(t + τ)]E{cos(ω0t + Θ) cos[ω0(t + τ) + Θ]} = 1
2RX(τ) cos(ω0t). (17.2.9)
Let us take RX(τ) = RX(0)e−2λ|τ|, the autocorrelation function for a random telegraph
signal (see Equation 17.2.22). In this case,
RY (τ) = 1
2RX(0)e−2λ|τ| cos(ω0t).
(17.2.10)

866
Advanced Engineering Mathematics with MATLAB
Turning to the power spectrum, the deﬁnition gives
SY (ω) =
Z ∞
−∞
1
2RX(τ) cos(ω0t)e−iωτ dτ
(17.2.11)
= 1
4
Z ∞
−∞
RX(τ)
 eiω0τ + e−iω0τ
e−iωτ dτ
(17.2.12)
= 1
4 [SX(ω −ω0) + SX(ω + ω0)] .
(17.2.13)
Thus, the resulting power spectrum is shifted to the modulating frequency ω0 and its
negative value, with peak values located at both ω = ω0 and ω = −ω0.
⊓⊔
• Example 17.2.3: White noise
There are instances when we want to approximate random signals where the autocor-
relation function is very narrow and very large about τ = 0. In those cases we construct an
idealization of the autocorrelation function by using the impulse or delta function δ(τ).
In the present case when RX(τ) = C δ(τ), the power spectrum is
SX(ω) =
Z ∞
−∞
C δ(τ)e−iωτ dτ = C.
(17.2.14)
Thus, the power spectrum here is a ﬂat spectrum whose value is equal to C. Because the
power spectrum is a ﬂat for all frequencies, it is often called “white noise” since it contains
all frequencies with equal weight.
An alternative derivation involves the random telegraph that we introduced in Example
17.0.3. As the switching rate becomes large and the rate λ approaches inﬁnity, its amplitude
increases as
√
λ.
Because RX(0) increases linearly with λ, the autocorrelation function
becomes
RX(τ) = Cλ exp(−2λ|τ|).
(17.2.15)
The resulting power spectrum equals
SX(ω) = lim
λ→∞
4Cλ2
ω2 + 4λ2 = lim
λ→∞
C
1 + [ω/(2λ)]2 = C.
(17.2.16)
The power spectrum is again ﬂat for all frequencies.
The autocorrelation for white noise is an idealization because it has inﬁnite average
power. Obviously no real signal has inﬁnite power since in practice the power spectrum
decays eventually.
Nevertheless, white noise is still quite useful because the decay usu-
ally occurs at such high frequencies that we can tolerate the errors of introducing a ﬂat
spectrum.
⊓⊔
• Example 17.2.4: Random telegraph signal
In Example 17.0.3 we introduced the random telegraph signal: X(t) equals either +h
or −h, changing its value from one to the other in Poisson-distributed moments of time.
The probability of n changes in a time interval τ is
Pτ(n) = (λτ)n
n!
e−λτ,
(17.2.17)

Random Processes
867
where λ denotes the average frequency of changes.
To compute the power spectrum we must ﬁrst compute the correlation function via
the product X(t)X(t + τ). This product equals h2 or −h2, depending on whether X(t) =
X(t + τ) or X(t) = −X(t + τ), respectively.
These latter relationships depend on the
number of changes during the time interval. Now,
P[X(t) = X(t + τ)] = Pτ(n even) = e−λτ
∞
X
n=1
(λτ)2n
(2n)! = e−λτ cosh(λτ),
(17.2.18)
and
P[X(t) = −X(t + τ)] = Pτ(n odd) = e−λτ
∞
X
n=1
(λτ)2n+1
(2n + 1)! = e−λτ sinh(λτ).
(17.2.19)
Therefore,
E[X(t)X(t + τ)] = h2Pτ(n even) −h2Pτ(n odd)
(17.2.20)
= h2e−λτ[cosh(λτ) −sinh(λτ)]
(17.2.21)
= h2e−2λ|τ|.
(17.2.22)
We have introduced the absolute value sign in Equation 17.2.24 because our derivation was
based on t2 > t1 and the absolute value sign takes care of the case t2 < t1.
Using Problem 1, we have that
SX(ω) = 2h2
Z ∞
0
e−2λτ cos(λτ) dτ =
4h2λ
ω2 + 4λ2 .
(17.2.23)
Problems
1. Show that
SX(ω) = 2
Z ∞
0
RX(τ) cos(ωτ) dτ.
17.3 TWO-STATE MARKOV CHAINS
A Markov chain is a probabilistic model in which the outcomes of successive trials
depend only on its immediate predecessors. The mathematical description of a Markov
chain involves the concepts of states and state transition. If Xn = i, then we have a process
with state i and time n. Given a process in state i, there is a ﬁxed probability Pij that state
i will transition into state j. In this section we focus on the situation of just two states.
Imagine that you want to predict the chance of rainfall tomorrow.1 From close obser-
vation you note that the chance of rain tomorrow depends only on whether it is raining
today and not on past weather conditions. From your observations you ﬁnd that if it rains
today, then it will rain tomorrow with probability α, and if it does not rain today, then
the chance it will rain tomorrow is β. Assuming that these probabilities of changes are
stationary (unchanging), you would like to answer the following questions:
1 See, for example, Gabriel, K. R., and J. Neumann, 1962: A Markov chain model for daily rainfall
occurrence at Tel Aviv. Quart. J. R. Met. Soc., 88, 90–95.

868
Advanced Engineering Mathematics with MATLAB
1. Given that is raining (or not raining), what are the chances of it raining in eight days?
2. Suppose the day is rainy (or dry), how long will the current weather remain before it
changes for the ﬁrst time?
3. Suppose it begins to rain during the week, how long does it take before it stops?
If the weather observation takes place at noon, we have a discrete parameter process;
the two possible states of the process are rain and no rain. Let these be denoted by 0 for no
rain and 1 for rain. The four possible transitions are (0 →0), (0 →1), (1 →0), and (1 →1).
Let Xn be the state of the process at the nth time point. We have Xn = 0, 1. Clearly,
{Xn, n = 0, 1, 2, . . .} is a two-state Markov chain. Therefore questions about precipitation
can be answered if all the properties of the two-state Markov chains are known. Let
P (m,n)
i,j
= P(Xn = j|Xm = i),
i, j = 0, 1;
m ≤n.
(17.3.1)
P (m,n)
i,j
denotes the probability that the state of the process at the nth time point is j given
that it was at state i at the mth time point. Furthermore, if this probability is larger for
i = j than when i ̸= j, the system prefers to stay or persist in whatever state it is. When
n = m + 1, we have that
P (m,m+1)
i,j
= P(Xm+1 = j|Xm = i).
(17.3.2)
This is known as the one-step transition probability, given that the process is at i at time
m.
There are two possibilities: either P (m,m+1)
ij
depends on m or P (m,m+1)
ij
is independent
of m, where m is the initial value of the time parameter. Our precipitation model is an
example of a second type of process in which the one-step transition probabilities do not
change with time.
Such processes are known as time homogeneous.
Presently we shall
restrict ourselves only to these processes. Consequently, without loss of generality we can
use the following notation for the probabilities:
Pij = P(Xm+1 = j|Xm = i)
for all m,
(17.3.3)
and
P (n)
ij
= P(Xm+n = j|Xm = i)
for all m.
(17.3.4)
Chapman-Kolmogorov equation
The Chapman2-Kolmogorov3 equations provide a mechanism for computing the tran-
sition probabilities after n steps. The n-step transition probabilities P (n)
ij
denote the prob-
ability that a process in state i will be in state j after n transitions, or
P (n)
ij
= P[Xn+k = j|Xk = i],
n ≥0,
i, j ≥0.
(17.3.5)
2 Chapman, S., 1928: On the Brownian displacements and thermal diﬀusion of grains suspended via
non-uniform ﬂuid. Proc. R. Soc. London, Ser. A, 119, 34–54.
3 Kolmogorov, A. N., 1931: ¨Uber die analytischen Methoden in der Wahrscheinlichkeitsrechnung. Math.
Ann., 104, 415–458.

Random Processes
869
Therefore, P (1)
ij
= Pij. The Chapman-Kolmogorov equations give a method for computing
these n-step transition probabilities via
P (n+m)
ij
=
∞
X
k=0
P (n)
ik P (m)
kj ,
n, m ≥0,
(17.3.6)
for all i and j. Here P (n)
ik P (m)
kj
represents the probability that the ith starting process will
go to state j in n + m transitions via a path that takes it into state k at the nth transition.
Equation 17.3.6 follows from
P (n+m)
ij
= P[Xn+m = j|X0 = i] =
∞
X
k=0
P[Xn+m = j, Xn = k|X0 = i]
(17.3.7)
=
∞
X
k=0
P[Xn+m = j|Xn = k, X0 = i]P[Xn = k|X0 = i] =
∞
X
k=0
P (n)
ik P (m)
kj .
(17.3.8)
Transmission probability matrix
Returning to the task at hand, we have that
P (2) = P (1+1) = P · P = P 2,
(17.3.9)
and by induction
P (n) = P (n−1+1) = P (n−1) · P = P n,
(17.3.10)
where P (n) denotes the transition matrix after n steps.
From our derivation, we see that: (1) The one-step transition probability matrix com-
pletely deﬁnes the time-homogeneous two-state Markov chain. (2) All transition probability
matrices show the important property that the elements in any of their rows add up to one.
This follows from the fact that the elements of a row represent the probabilities of mutually
exclusive and exhaustive events on a sample space.
For two-state Markov processes, this means that
P (n)
00 + P (n)
01 = 1,
and
P (n)
10 + P (n)
11 = 1.
(17.3.11)
Furthermore, with the one-step transmission probability matrix:
P =

1 −a
a
b
1 −b

,
0 ≤a, b ≤1,
|1 −a −b| < 1,
(17.3.12)
then the n-step transmission probability matrix is

P (n)
00
P (n)
01
P (n)
10
P (n)
11

=
 
b
a+b + a (1−a−b)n
a+b
a
a+b −a (1−a−b)n
a+b
b
a+b −b (1−a−b)n
a+b
a
a+b + b (1−a−b)n
a+b
!
.
(17.3.13)
This follows from the Chapman-Kolmogorov equation that
P (1)
00 = 1 −a,
(17.3.14)

870
Advanced Engineering Mathematics with MATLAB
Table 17.3.1: The Probability of Rain on the nth Day.
n
P00
P10
P01
P11
1
0.7000
0.2000
0.3000
0.8000
2
0.5500
0.3000
0.4500
0.7000
3
0.4750
0.3500
0.5250
0.6500
4
0.4375
0.3750
0.5625
0.6250
5
0.4187
0.3875
0.5813
0.6125
6
0.4094
0.3938
0.5906
0.6063
7
0.4047
0.3969
0.5953
0.6031
8
0.4023
0.3984
0.5977
0.6016
9
0.4012
0.3992
0.5988
0.6008
10
0.4006
0.3996
0.5994
0.6004
∞
0.4000
0.4000
0.6000
0.6000
and
P (n)
00 = (1 −a)P (n−1)
00
+ bP (n−1)
01
,
n > 1,
(17.3.15)
= b + (1 −a −b)P (n−1)
00
,
(17.3.16)
since P (n)
01 = 1−P (n)
00 . Solving these equations recursively for n = 1, 2, 3, . . . and simplifying,
we obtain Equation 17.3.13 as long as both a and b do not equal zero.
• Example 17.3.1
Consider a precipitation model where the chance for rain depends only on whether it
rained yesterday. If we denote the occurrence of rain by state 0 and state 1 denotes no rain,
then observations might give you a transition probability that looks like:
P =

0.7
0.3
0.2
0.8

.
(17.3.17)
Given that the atmosphere starts today with any one of these states, the probability of
ﬁnding that it is raining on the nth day is given by P n. Table 17.3.1 illustrates the results
as a function of n. Thus, regardless of whether it rains today or not, in ten days the chance
for rain is 0.4 while the chance for no rain is 0.6.
⊓⊔
Limiting behavior
As Table 17.3.1 suggests, as our Markov chain evolves, it reaches some steady-state.
Let us explore this limit of n →∞because it often provides a simple and insightful repre-
sentation of a Markov process.
For large values of n it is possible to show that the limiting probability distribution of
states is independent of the initial value. In particular, for |1 −a −b| < 1, we have that
lim
n→∞P (n) =

b
a+b
a
a+b
b
a+b
a
a+b

.
(17.3.18)

Random Processes
871
This follows from limn→∞(1 −a −b)n →0 since |1 −a −b| < 1. From Equation 17.3.13 the
second term in each of the elements of the matrix tends to zero as n →∞.
Let us denote these limiting probabilities by πj = limn→∞P (n)
ij . Then, from Equation
17.3.18,
π00 = π10 =
b
a + b = π0,
and
π01 = π11 =
a
a + b = π1,
(17.3.19)
and these limiting distributions are independent of the initial state.
Number of visits to a certain state
When a random process visits several states we would like to know the number of visits
to a certain state. Let N (n)
ij
denote the number of visits the two-state Markov chain {Xn}
makes to state j, starting initially at state i, in n time periods. If µ(n)
ij
denotes the expected
number of visits that the process makes to state j in n steps after it originally started at
state i, and the transition probability matrix P of the two-state Markov chain is
P =

1 −a
a
b
1 −b

(17.3.20)
with |1 −a −b| < 1, then
||µ(n)
ij || =
 
nb
a+b + a(1−a−b)[1−(1−a−b)n]
(a+b)2
na
a+b −a(1−a−b)[1−(1−a−b)n]
(a+b)2
nb
a+b −b(1−a−b)[1−(1−a−b)n]
(a+b)2
na
a+b + b(1−a−b)[1−(1−a−b)n]
(a+b)2
!
(17.3.21)
To prove Equation 17.3.21, we introduce a random variable Y (k)
ij , where
Y (n)
ij
=

1,
if Xk = j and X0 = i,
0,
otherwise,
(17.3.22)
for i, j = 0, 1. This random variable Y (n)
ij
gives the time at which the process visits state j.
The probability distribution of Y (n)
ij
for ﬁxed k is
Y (n)
ij
0
1
Probability
1 −P (n)
ij
P (n)
ij
Thus, we have that
E[Y (k)
ij ] = P (k)
ij ,
i, j = 0, 1;
k = 1, 2, . . . , n.
(17.3.23)
Because Y (k)
ij
equals 1 whenever the process is in state j and 0 when it is not in j, the
number of visits to j, starting originally from i, in n steps is
N (n)
ij
= Y (1)
ij
+ Y (2)
ij
+ · · · + Y (n)
ij .
(17.3.24)

872
Advanced Engineering Mathematics with MATLAB
Taking the expected values and using the property that the expectation of a sum is the sum
of expectations,
µ(n)
ij
= E
h
N (n)
ij
i
= P (1)
ij
+ P (2)
ij
+ · · · + P (n)
ij
=
n
X
k=1
P (k)
ij .
(17.3.25)
From Equation 17.3.13, we substitute for each P (k)
ij
and ﬁnd
µ(n)
00 =
n
X
k=1
P (k)
00 =
n
X
k=1

b
a + b + a(1 −a −b)k
a + b

,
(17.3.26)
µ(n)
01 =
n
X
k=1
P (k)
01 =
n
X
k=1

a
a + b −a(1 −a −b)k
a + b

,
(17.3.27)
µ(n)
10 =
n
X
k=1
P (k)
10 =
n
X
k=1

b
a + b −b(1 −a −b)k
a + b

,
(17.3.28)
and
µ(n)
11 =
n
X
k=1
P (k)
11 =
n
X
k=1

a
a + b + b(1 −a −b)k
a + b

,
(17.3.29)
ﬁnally, noting that
n
X
k=1
b
a + b =
nb
a + b,
(17.3.30)
and
n
X
k=1
a(1 −a −b)k
a + b
=
a
a + b
n
X
k=1
(1 −a −b)k
(17.3.31)
=
a
a + b

(1 −a −b) + (1 −a −b)2 + · · · + (1 −a −b)n
(17.3.32)
= a(1 −a −b)
a + b

1 + (1 −a −b) + · · · + (1 −a −b)n−1
(17.3.33)
= a(1 −a −b) [1 −(1 −a −b)n]
(a + b) [1 −(1 −a −b)]
.
(17.3.34)
Here we used the property of a geometric series that
n−1
X
k=0
xk = 1 −xn
1 −x ,
|x| < 1.
(17.3.35)
• Example 17.3.2
Let us continue with our precipitation model that we introduced in Example 17.3.1. If
we wish to know the expected number of days within a week that the atmosphere will be
in a given state, we have from Equation 17.3.21 that
µ(7)
00 =
7b
a + b + a(1 −a −b)[1 −(1 −a −b)7]
(a + b)2
= 3.3953,
(17.3.36)

Random Processes
873
µ(7)
10 =
7b
a + b −b(1 −a −b)[1 −(1 −a −b)7]
(a + b)2
= 2.4031,
(17.3.37)
µ(7)
01 =
7a
a + b −a(1 −a −b)[1 −(1 −a −b)7]
(a + b)2
= 3.6047,
(17.3.38)
and
µ(7)
11 =
7a
a + b + b(1 −a −b)[1 −(1 −a −b)7]
(a + b)2
= 4.5969,
(17.3.39)
since a = 0.3 and b = 0.2.
⊓⊔
Duration of stay
In addition to computing the number of visits to a certain state, it would also be useful
to know the fraction of the discrete time that a process stays in state j out of n when the
process started in state i. These fractions are:
lim
n→∞
µ(n)
00
n
= lim
n→∞
µ(n)
10
n
= π0,
(17.3.40)
and
lim
n→∞
µ(n)
01
n
= lim
n→∞
µ(n)
11
n
= π1.
(17.3.41)
Thus, the limiting probabilities also give the fraction of time that the process spends in the
two states in the long run.
If the process is in state i (i = 0, 1) at some time, let us compute the number of
additional time periods it stays in state i until it moves out of that state. We now want to
show that this probability distribution αi, i = 0, 1, is
P(α0 = n) = a(1 −a)n,
(17.3.42)
and
P(α1 = n) = b(1 −b)n,
(17.3.43)
where n = 1, 2, 3, . . .. Furthermore,
E(α0) = (1 −a)/a,
E(α1) = (1 −b)/b,
(17.3.44)
and
Var(α0) = (1 −a)/a2,
Var(α1) = (1 −b)/b2,
(17.3.45)
where the transition probability matrix P of the Markov chain {Xn} equals
P =

1 −a
a
b
1 −b

(17.3.46)
with |1 −a −b| < 1. Clearly a or b cannot equal to zero.
To prove this we note that at every step the process has two choices: either to stay in
the same state or to move to the other state. Suppose the process is in state 0 at some time.
The probability of a sequence of outcomes of the type {0 0 · · · 0
| {z }
n
1} is required. Because of the

874
Advanced Engineering Mathematics with MATLAB
property of Markov-dependence, we therefore have the realization of a Bernoulli process with
n consecutive outcomes of one type followed by an outcome of the other type. Therefore,
the probability distribution of α0 is geometric with (1 −a) as the probability of “failure,”
and the distribution of α1 is geometric with (1−b) as the probability of failure. Thus, from
Equation 16.6.5, we have that
P(α0 = n) = a(1 −a)n,
(17.3.47)
and
P(α1 = n) = b(1 −b)n,
(17.3.48)
where n = 0, 1, 2, . . .. The expression for the mathematical expectation and variance of α0
and α1 easily follow from the corresponding expressions for the geometric distribution.
• Example 17.3.3
Let us illustrate our expectation and variance expressions for our precipitation model.
From Equation 17.3.44 and Equation 17.3.45, we have that
E(α0) = (1 −a)/a = 2.3333,
E(α1) = (1 −b)/b = 4,
(17.3.49)
and
Var(α0) = (1 −a)/a2 = 7.7777,
Var(α1) = (1 −b)/b2 = 20,
(17.3.50)
since a = 0.3 and b = 0.2.
Problems
1. Given
P =

3/4
1/4
1/2
1/2

,
(a) compute P n and (b) ﬁnd limn→∞P n.
2. Suppose you want to model how your dog learns a new trick. Let Fido be in state 0 if
he learns the new trick and in state 1 if he fails to learn the trick. Suppose that if he learns
the trick, he will retain the trick. If he has yet to learn the trick, there is a probability α
of him learning it with each training session. (a) Write down the transition matrix. (b)
Compute P (n) where n is the number of training sessions. (c) What is the steady-state
solution? Interpret your result. (d) Compute the expected amount of time that Fido will
spend in each state during n training sessions.
17.4 BIRTH AND DEATH PROCESSES
In the previous section we considered two-state Markov chains that undergo n steps. As
the time interval between each step tends to zero, the Markov process becomes continuous
in time. In this section and the next, we consider two independent examples of continuous
Markov processes.
We began Chapter 16 by showing that the deterministic description of birth and death
is inadequate to explain the extinction of species. Here we will ﬁll out the details of our
analysis and extend them to population dynamics and chemical kinetics. As Section 1.2

Random Processes
875
showed, deterministic models lead to ﬁrst-order ordinary diﬀerential equations, and this
description fails when the system initially contains a small number of particles.
Consider a population of organisms that multiply by the following rules:
1. The sub-populations generated by two co-existing individuals develop completely in-
dependently of one another;
2. an individual existing at time t has a chance λ dt+o(dt) of multiplying by binary ﬁssion
during the following time interval of length dt;
3. the “birth rate” λ is the same for all individuals in the population at any time t;
4. an individual existing at time t has a chance µ dt + o(dt) of dying in the following time
interval of length dt; and
5. the “death rate” µ is the same for all individuals at any time t.
Rule 3 is usually interpreted in the sense that in each birth just one new member is added
to the population, but of course mathematically (and because the age structure of the
population is being ignored) it is not possible to distinguish between this and an alternative
interpretation in which one of the parents dies when the birth occurs and is replaced by
two children.
Let n0 be the number of individuals at the initial time t = 0 and let pn(t) denote the
probability that the population size N(t) has the value n at the time t. Then
dpn
dt = (n −1)λpn−1 −n(λ + µ)pn + µ(n + 1)pn+1,
n ≥1,
(17.4.1)
and
dp0(t)
dt
= µp1(t),
(17.4.2)
subject to the initial condition that
pn(0) =
 1,
n = n0,
0,
n ̸= n0.
(17.4.3)
Equation 17.4.1 through Equation 17.4.3 constitute a system of linear ordinary equa-
tions.
The question now turns on how to solve them most eﬃciently.
To this end we
introduce a probability-generating function:
φ(z, t) =
∞
X
n=0
znpn(t).
(17.4.4)
Summing Equation 17.4.1 from n = 1 to ∞after we multiplied it by zn and using Equation
17.4.2, we obtain
∞
X
n=0
zn dpn
dt = λ
∞
X
n=1
(n−1)znpn−1(t)−(λ+µ)
∞
X
n=1
nznpn(t)+µ
∞
X
n=0
(n+1)znpn+1(t). (17.4.5)
Because
∞
X
n=0
zn dpn
dt = ∂φ
∂t ,
(17.4.6)
∞
X
n=1
nznpn(t) = z
∞
X
n=0
nzn−1pn(t) = z ∂φ
∂z ,
(17.4.7)

876
Advanced Engineering Mathematics with MATLAB
∞
X
n=1
(n −1)znpn−1(t) =
∞
X
k=0
kzk+1pk(t) = z2
∞
X
k=0
kzk−1pk(t) = z2 ∂φ
∂z ,
(17.4.8)
and
∞
X
n=0
(n + 1)znpn+1(t) =
∞
X
k=1
kzk−1pk(t) =
∞
X
k=0
kzk−1pk(t) = ∂φ
∂z ,
(17.4.9)
Equation 17.4.5 becomes the ﬁrst-order partial diﬀerential equation
∂φ
∂t = (λz −µ)(z −1)∂φ
∂z ,
(17.4.10)
subject to the initial condition
φ(z, 0) = zn0.
(17.4.11)
Equation 17.4.10 is an example of a ﬁrst-order partial diﬀerential equation of the general
form
P(x, y)∂u
∂x + Q(x, y)∂u
∂y = 0.
(17.4.12)
This equation has solutions4 of the form u(x, y) = f(ξ) where f(·) is an arbitrary function
that is diﬀerentiable and ξ(x, y) = constant are solutions to
dx
P(x, y) =
dy
Q(x, y).
(17.4.13)
In the present case,
dt
1 = −
dz
(λz −µ)(z −1) = −
dz
(λ −µ)(z −1) +
dz
(λ −µ)(z −µ/λ).
(17.4.14)
Integrating Equation 17.4.14,
−(λ −µ)t + ln[ψ(z)] = ln(ξ),
(17.4.15)
or
ξ(z, t) = ψ(z)e−(λ−µ)t,
(17.4.16)
where
ψ(z) = λz −µ
z −1 .
(17.4.17)
Therefore, the general solution is
φ(z, t) = f
h
ψ(z)e−(λ−µ)ti
.
(17.4.18)
Our remaining task is to ﬁnd f(·). From the initial condition, Equation 17.4.11, we
have that
φ(z, 0) = f[ψ(z)] = zn0.
(17.4.19)
4 See Webster, A. G., 1966: Partial Diﬀerential Equations of Mathematical Physics. Dover, 446 pp.
See Section 22.

Random Processes
877
Because z = [µ −ψ(z)]/[λ −ψ(z)], then
f(ψ) =
µ −ψ
λ −ψ
n0
.
(17.4.20)
Therefore,
φ(z, t) =
µ −ψ(z)e−(λ−µ)t
λ −ψ(z)e−(λ−µ)t
n0
.
(17.4.21)
Once we ﬁnd φ(z, t), we can compute the probabilities of each of the species from the
probability generating function. For example,
P{N(t) = 0|N(0) = n0} = p0(t) = φ(0, t).
(17.4.22)
From Equation 17.4.17 we have ψ(0) = µ and
φ(0, t) =
(
µ

1 −e−(λ−µ)t
λ −µe−(λ−µ)t
)n0
,
λ ̸= µ,
(17.4.23)
and
φ(0, t) =

λt
1 + λt
n0
,
λ = µ.
(17.4.24)
An important observation from Equation 17.4.23 and Equation 17.4.24 is that
lim
t→∞p0(t) = 1,
λ ≤µ,
(17.4.25)
and
lim
t→∞p0(t) =
µ
λ
n0
,
λ > µ.
(17.4.26)
This limit can be interpreted as the probability of extinction of the population in a ﬁnite
time.
Consequently there will be “almost certain” extinction whenever λ ≤µ.
These
results, which are true whatever the initial number of individuals may be, show very clearly
the inadequacy of the deterministic description of population dynamics.
Finally, let us compute the mean and variance for the birth and death process. The
expected number of individuals at time t is
m(t) = E[N(t)] =
∞
X
n=0
n pn(t) =
∞
X
n=1
n pn(t).
(17.4.27)
Now
dm
dt =
∞
X
n=1
ndpn
dt =
∞
X
n=1
n [(n −1)λpn−1 −n(λ + µ)pn + µ(n + 1)pn+1]
(17.4.28)
= λ
∞
X
n=1
(n −1)2pn−1 + λ
∞
X
n=1
(n −1)pn−1 −(λ + µ)
∞
X
n=1
n2pn + µ
∞
X
n=1
(n + 1)2pn+1
−µ
∞
X
n=1
(n + 1)pn+1
(17.4.29)
= −(λ + µ)
∞
X
n=1
n2pn + λ
∞
X
i=0
i2pm + µ
∞
X
k=2
k2pk + λ
∞
X
i=0
i pi −µ
∞
X
k=2
k pk.
(17.4.30)

878
Advanced Engineering Mathematics with MATLAB
In the ﬁrst three sums in Equation 17.4.30, terms from i, k, n = 2, and onward cancel and
leave −(λ + µ)p1 + λp1 = −µp1. Therefore,
dm
dt = −µp1 + λ
∞
X
i=0
i pi −µ
∞
X
k=2
k pk = (λ −µ)
∞
X
n=0
n pn, = (λ −µ)m.
(17.4.31)
If we choose the initial condition m(0) = n0, the solution is
m(t) = n0e(λ−µ)t.
(17.4.32)
This is the same as the deterministic result, Equation 1.2.9, with the birth rate b replaced
by λ and the death rate d replaced by µ. Furthermore, if λ = µ, the mean size of the
population is constant.
The second moment of N(t) is
M(t) =
∞
X
n=0
n2pn(t).
(17.4.33)
Proceeding as before, we have that
dM
dt =
∞
X
n=1
n2 dpn
dt =
∞
X
n=1
n2 [λ(n −1)pn−1 −(λ + µ)n pn + µ(n + 1)pn+1]
(17.4.34)
= λ
∞
X
n=1
(n −1)3pn−1 + 2λ
∞
X
n=1
(n −1)2pn−1 + λ
∞
X
n=1
(n −1)pn−1 −(λ + µ)
∞
X
n=1
n3pn
+ µ
∞
X
n=1
(n + 1)3pn+1 −2µ
∞
X
n=1
(n + 1)2pn+1 + µ
∞
X
n=1
(n + 1)pn+1
(17.4.35)
= λ
∞
X
k=1
k3pk + 2λ
∞
X
k=1
k2pk + λ
∞
X
k=1
k pk −(λ + µ)
∞
X
n=1
n3pn
+ µ
∞
X
i=2
i3pi −2µ
∞
X
i=2
i2pi + µ
∞
X
i=2
i pi.
(17.4.36)
The three sums, which contain either i3 or k3 or n3 in them, cancel when i, k, n = 2 and
onward; these three sums reduce to −µp1. The sums that involve i2 or k2 can be written
in terms of M(t). Finally, the sums involving i and k can be expressed in terms of m(t).
Therefore, Equation 17.4.36 becomes the ﬁrst-order ordinary diﬀerential equation
dM
dt −2(λ −µ)M = (λ + µ)m(t) = (λ + µ)n0e(λ−µ)t,
(17.4.37)
with M(0) = n2
0.
Equation 17.4.37 can be solved exactly using the technique of integrating factors from
Section 1.5. Its solution is
M(t) = n2
0e2(λ−µ)t + λ + µ
λ −µn0e(λ−µ)t h
e(λ−µ)t −1
i
.
(17.4.38)
From the deﬁnition of variance, Equation 16.6.5, the variance of the population in the birth
and death process equals
Var[N(t)] = n0
(λ + µ)
(λ −µ)e(λ−µ)t h
e(λ−µ)t −1
i
,
λ ̸= µ,
(17.4.39)

Random Processes
879
or
Var[N(t)] = 2λn0t,
λ = µ.
(17.4.40)
• Example 17.4.1: Chemical kinetics
The use of Markov processes to describe birth and death has become quite popular.
Indeed, it can be applied to any phenomena where something is being created or destroyed.
Here we illustrate its application in chemical kinetics.
Let the random variable X(t) be the number of A molecules in a unimolecular reaction
A →B (such as radioactive decay) at time t. A stochastic model that describes the decrease
of A can be constructed from the following assumptions:
1. The probability of transition from n to n −1 in the time interval (t, t + ∆t) is nλ∆t +
o(∆t) where λ is a constant and o(∆t) denotes that o(∆t)/∆t →0 as ∆t →0.
2. The probability of a transition from n to n −j, j > 1, in the time interval (t, t + ∆t) is
at least o(∆t) because the time interval is so small that only one molecule undergoes
a transition.
3. The reverse reaction occurs with probability zero.
The equation that governs the probability that X(t) = n is
pn(t + ∆t) = (n + 1)λ∆tpn+1(t) + (1 −λn∆t)pn(t) + o(∆t).
(17.4.41)
Transposing pn(t) from the right side, dividing by ∆t, and taking the limit ∆t →0, we
obtain the diﬀerential-diﬀerence equation5
dpn
dt = (n + 1)λpn+1(t) −nλpn(t).
(17.4.42)
Equation 17.4.42 is frequently called the stochastic master equation. The ﬁrst term on the
right side of this equation vanishes when n = n0.
The solution of Equation 17.4.42 once again involves introducing a generating function
for pn(t), namely
F(z, t) =
n0
X
n=0
pn(t)zn,
|z| < 1.
(17.4.43)
Summing Equation 17.4.42 from n = 0 to n0 after multiplying it by zn, we ﬁnd
n0
X
n=0
zn dpn
dt = λ
n0−1
X
n=0
(n + 1)znpn+1(t) −λ
n0
X
n=1
nznpn(t).
(17.4.44)
Because
n0
X
n=0
zn dpn
dt = ∂F
∂t ,
(17.4.45)
n0
X
n=0
nznpn(t) = z
n0
X
n=0
nzn−1pn(t) = z ∂F
∂z ,
(17.4.46)
5 McQuarrie, D. A., 1963: Kinetics of small systems. I. J. Chem. Phys., 38, 433–436.

880
Advanced Engineering Mathematics with MATLAB
and
n0−1
X
n=0
(n + 1)znpn+1(t) =
n0
X
k=1
kzk−1pk(t) =
n0
X
k=0
kzk−1pk(t) = ∂F
∂z ,
(17.4.47)
Equation 17.4.44 becomes the ﬁrst-order partial diﬀerential equation
∂F
∂t = λ(1 −z)∂F
∂z .
(17.4.48)
The solution of Equation 17.4.48 follows the method used to solve Equation 17.4.10.
Here we ﬁnd ξ(z, t) via
dt
1 =
dz
λ(z −1),
(17.4.49)
or
ξ(z, t) = (z −1)e−λt.
(17.4.50)
Therefore,
F(z, t) = f

(z −1)e−λt
.
(17.4.51)
To ﬁnd f(·), we use the initial condition that F(z, 0) = zn0. This yields f(y) = (1+y)n0
and
F(z, t) =

1 + (z −1)e−λtn0 .
(17.4.52)
Once again, we can compute the mean and variance of this process. Because
∂F
∂z

z=1
=
n0
X
n=0
npn(t),
(17.4.53)
the mean is given by
E[X(t)] = ∂F(1, t)
∂z
.
(17.4.54)
To compute the variance, we ﬁrst compute the second moment. Since
z ∂F
∂z =
n0
X
n=0
nznpn(t),
(17.4.55)
and
∂
∂z

z ∂F
∂z

=
n0
X
n=0
n2zn−1pn(t),
(17.4.56)
we have that
n0
X
n=0
n2pn(t) = ∂2F(1, t)
∂z2
+ ∂F(1, t)
∂z
.
(17.4.57)
From Equation 16.6.5, the ﬁnal result is
Var[X(t)] = ∂2F(1, t)
∂z2
+ ∂F(1, t)
∂z
−
∂F(1, t)
∂z
2
.
(17.4.58)
Upon substituting Equation 17.4.52 into Equations 17.4.54 and 17.4.58, the mean and
variance for this process are
E[X(t)] = n0e−λt,
and
Var[X(t)] = n0e−λt  1 −e−λt
.
(17.4.59)

Random Processes
881
Because the expected value of the stochastic representation also equals the deterministic
result, the two representations are “consistent in the mean.” Further study shows that this
is true only for unimolecular reactions. Upon expanding Equation 17.4.52, we ﬁnd that
pn(t) =

n0
n

e−nλt  1 −e−λtn0−n .
(17.4.60)
An alternative method to the generating function involves Laplace transforms.6 To
illustrate this method, we again examine the reaction A →B.
The stochastic master
equation is
dpn
dt = (n −1)λpn−1(t) −nλpn(t),
n0 ≤n < ∞,
(17.4.61)
pn(t) = 0 for 0 < n < n0, where pn(t) denotes the probability that we have n particles of
B at time t. The initial condition is that pn0(0) = 1 and pm(0) = 0 for m ̸= n0 where n0
denotes the initial number of molecules of B.
Taking the Laplace transform of Equation 17.4.61, we ﬁnd that
sPn(s) = (n −1)λPn−1(s) −nλPn(s),
n0 < n < ∞,
(17.4.62)
and
sPn0(s) −1 = −nλPn0(s).
(17.4.63)
Therefore, solving for Pn(s),
Pn(s) = (n −1)λ
s + nλ Pn−1(s) = λn−n0(n −1)!
(n0 −1)!
n
Y
k=n0
(s + kλ)−1.
(17.4.64)
From partial fractions,
Pn(s) = (n −1)!
(n0 −1)!
n
X
k=n0
(−1)k−n0
(k −n0)!(n −k)!(s + kλ).
(17.4.65)
Taking the inverse Laplace transform,
pn(t) =
(n −1)!
(n0 −1)!(n −n0)!
n
X
k=n0
(−1)k−n0(n −n0)!
(k −n0)!(n −k)! e−λkt
(17.4.66)
=
(n −1)!e−λn0t
(n0 −1)!(n −n0)!
n−n0
X
j=0
(−1)j(n −n0)!
j!(n −n0 −j)!e−λjt
(17.4.67)
=
(n −1)!e−λn0t
(n0 −1)!(n −n0)!
 1 −e−λtn−n0 ,
(17.4.68)
where we introduced j = k −n0 and eliminated the summation via the binomial theorem.
Equation 17.4.68 is identical to results7 given by Delbr¨uck using another technique.
⊓⊔
6 Ishida, K., 1969: Stochastic model for autocatalytic reaction. Bull. Chem. Soc. Japan, 42, 564–565.
7 Delbr¨uck, M., 1940: Statistical ﬂuctuations in autocatalytic reactions. J. Chem. Phys., 8, 120–124.
See his Equation 7.

882
Advanced Engineering Mathematics with MATLAB
• Example 17.4.2
In the chemical reaction rA
λ
→
←
µ B, r molecules of A combine to form one molecule of B.
If X(t) = n is the number of B molecules, then the probability pn(t) = P{X(t) = n} of
having n molecules of B is given by
dpn
dt = −[nµ + (N −n)λ] pn + (N −n + 1)λpn−1 + (n + 1)µpn+1,
(17.4.69)
where 0 ≤n ≤N, rN is the total number of molecules of A, λ is the rate at which r
molecules of A combine to produce B, and µ is the rate at which B decomposes into A.
Multiplying Equation 17.4.69 by zn and summing from n = −1 to N + 1,
N+1
X
n=−1
zn dpn
dt = −Nλ
N+1
X
n=−1
znpn + (λ −µ)
N+1
X
n=−1
nznpn + Nλ
N+1
X
n=−1
znpn−1
−λ
N+1
X
n=−1
(n −1)znpn−1 + µ
N+1
X
n=−1
(n + 1)znpn+1.
(17.4.70)
Deﬁning
F(z, t) =
N+1
X
n=−1
pn(t)zn,
|z| < 1,
(17.4.71)
with p−1 = pN+1 = 0, we have that
∂F
∂t =
N+1
X
n=−1
zn dpn
dt ,
(17.4.72)
∂F
∂z =
N+1
X
n=−1
nzn−1pn =
N
X
i=−2
(i + 1)zipi+1 =
N+1
X
i=−1
(i + 1)zipi+1,
(17.4.73)
z ∂F
∂z =
N+1
X
n=−1
nznpn,
(17.4.74)
z2 ∂F
∂z =
N+1
X
n=−1
nzn+1pn =
N+2
X
i=0
(i −1)zipi−1 =
N+1
X
i=−1
(i −1)zipi−1,
(17.4.75)
and
F =
N+1
X
n=−1
zn+1pn =
N+2
X
i=0
zipi−1 =
N+1
X
i=−1
zipi−1.
(17.4.76)
Therefore, the diﬀerential-diﬀerence equation, Equation 17.4.70, can be replaced by
∂F
∂t = Nλ(z −1)F +

µ −(µ −λ)z −λz2 ∂F
∂z .
(17.4.77)
Using the same technique as above, this partial diﬀerential equation can be written as
dt
−1 =
dz
(1 −z)(µ + λz) =
dF
−Nλ(z −1).
(17.4.78)

Random Processes
883
Equation 17.4.78 yields the independent solutions
1 −z
µ + λz e−(µ+λ)t = ξ(z, t) = constant,
(17.4.79)
and
(µ + λ)−NF(z, t) = η(z, t) = another constant,
(17.4.80)
where f(·) is an arbitrary, diﬀerentiable function.
If there are m units of B at t = 0,
0 ≤m ≤N, the initial condition is F(z, 0) = zm. Then,
f
 1 −z
µ + λz

=
zm
(µ + λz)N ,
(17.4.81)
or
f(x) = (1 −µx)m
(µ + λ)N (1 + λx)N−m.
(17.4.82)
After some algebra, we ﬁnally ﬁnd that
F(z, t) =
1
(µ + λ)N
n
µ
h
1 −e−(µ+λ)ti
+ z
h
λ + µe−(µ+λ)tiom
×
n
µ + λe−(µ+λ)t + λz
h
1 −e−(µ+λ)tioN−m
.
(17.4.83)
Computing the mean and variance, we obtain
E(X) =
m
µ + λ
h
λ + µe−(µ+λ)ti
+ (N −m)λ
µ + λ
h
1 −e−(µ+λ)ti
,
(17.4.84)
and
Var(X) =
mµ
(µ + λ)2
h
λ + µe−(µ+λ)ti h
1 −e−(µ+λ)ti
+ (N −m)λ
(µ + λ)2
h
µ + λe−(µ+λ)ti h
1 −e−(µ+λ)ti
.
(17.4.85)
Problems
1. During their study of growing cancerous cells (with growth rate α), Bartoszy´nski et
al.8 developed a probabilistic model of a tumor that has not yet metastasized. In their
mathematical derivation a predictive model gives the probability pn(t) that certain nth
type of cells (out of N) will develop. This probability can change in two ways: (1) Each of
the existing cells has the probability λn∆t + o(∆t) of mutating to another type between t
and t+∆t. (2) The probability that cells in state n at time t will shed a metastasis between
t and t + ∆t is µncet/α∆t + o(∆t), where µ is a constant and c is the size of a single cell.
Setting ρ = λc/N and ν = µc, the governing equations for pn(t) is
dpn
dt = −(ρ + ν)net/αpn + ρ(n + 1)et/αpn+1,
n = 0, 1, 2, . . . , N −1,
(1)
8 Bartoszy´nski, R., B. F. Jones, and J. P. Klein, 1985: Some stochastic models of cancer metastases.
Commun. Statist.-Stochastic Models, 1, 317–339.

884
Advanced Engineering Mathematics with MATLAB
and
dpN
dt
= −(ρ + ν)Net/αpN,
(2)
with the initial conditions pN(0) = 1 and pn(0) = 0 if n ̸= N.
Step 1: Introducing the generating function
φ(z, t) =
N
X
n=0
znpn(t),
0 ≤z ≤1,
(3)
show that our system of linear diﬀerential-diﬀerence equations can be written as the ﬁrst-
order partial diﬀerential equation
∂φ
∂t = [ρ −(ρ + ν)z]et/α ∂φ
∂z
(4)
with φ(z, 0) = zN.
Step 2: Solve the partial diﬀerential equation in Step 1 and show that
φ(z, t) =

ρ
ρ + ν
N 
1 −

1 −ρ + ν
ρ
z

exp
h
−α(ρ + ν)

et/a −1
iN
.
(5)
Project: Stochastic Simulation of Chemical Reactions
Most stochastic descriptions of chemical reactions cannot be attacked analytically and
numerical simulation is necessary. The purpose of this project is to familiarize you with
some methods used in the stochastic simulation of chemical reactions. In particular, we will
use the Lokta reactions given by the reaction equations:
A + X
k1
−→2X,
(1)
X + Y
k2
−→2Y,
(2)
Y
k3
−→Z.
(3)
Surprisingly, simple numerical integration of the master equation is not fruitful. This occurs
because of the number and nature of the independent variables; there is only one master
equation but N reactants and time for independent variables.
An alternative to integrating the master equation is a direct stochastic simulation. In
this approach, the (transition) probability for each reaction is computed: p1 = k1ax∆t,
p2 = k2xy∆t, and p3 = k3y∆t, where ∆t is the time between each consecutive state and
a is the constant number of molecules of A.
The obvious question is: Which of these
probabilities should we use?
Our ﬁrst attempt follows Nakanishi:9 Assume that ∆t is suﬃciently small so that
p1 + p2 + p3 < 1.
Using a normalized uniform distribution, such as MATLAB’s rand,
compute a random variable r for each time step. Then march forward in time. At each
time step, there are four possibilities. If 0 < r ≤p1, then the ﬁrst reaction occurs and
9 This is the technique used by Nakanishi, T., 1972: Stochastic analysis of an oscillating chemical
reaction. J. Phys. Soc. Japan, 32, 1313–1322.

Random Processes
885
0
5
10
15
20
25
30
0
500
1000
1500
2000
2500
3000
 time
 number of x molecules
0
5
10
15
20
25
30
0
500
1000
1500
2000
2500
3000
 time
 number of y molecules
Figure 17.4.1: The temporal variation of the molecules in a Lokta reaction when ∆t = 10−5, k1a = 10,
k2 = 0.01, k3 = 10, and x(0) = y(0) = 1000.
x(t + ∆t) = x(t) + 1, y(t + ∆t) = y(t). If p1 < r ≤p1 + p2, then the second reaction occurs
and x(t + ∆t) = x(t) −1, y(t + ∆t) = y(t) + 1. If p1 + p2 < r ≤p1 + p2 + p3, then the third
reaction occurs and x(t + ∆t) = x(t), y(t + ∆t) = y(t) −1. Finally, if p1 + p2 + p3 < r ≤1,
then no reaction occurs and x(t + ∆t) = x(t), y(t + ∆t) = y(t).
For the ﬁrst portion of this project, create MATLAB code to simulate our chemical
reaction using this simulation technique. Explore how your results behave as you vary x(0),
y(0) and especially ∆t. See Figure 17.4.1.
One of the diﬃculties in using Nakanishi’s method is the introduction of ∆t. What
value should we choose to ensure that p1 + p2 + p3 < 1? Several years later, Gillespie10
developed a similar algorithm. He introduced three parameters, a1 = k1ax, a2 = k2xy, and
a3 = k3y, along with a0 = a1 + a2 + a3. These parameters a1, a2, and a3 are similar to the
probabilities p1, p2, and p3. Similarly, he introduced a random number r2 that is chosen
from a normalized uniform distribution. Then, if 0 < r2a0 ≤a1, the ﬁrst reaction occurs
and x(t + ∆t) = x(t) + 1, y(t + ∆t) = y(t). If a1 < r2a0 ≤a1 + a2, then the second reaction
occurs and x(t + ∆t) = x(t) −1, y(t + ∆t) = y(t) + 1. If a1 + a2 < r2a0 ≤a0, then the third
reaction occurs and x(t + ∆t) = x(t), y(t + ∆t) = y(t) −1. Because of his selection criteria
for the reaction that occurs during a time step, one of the three reactions must take place.
See Figure 17.4.2.
The most radical diﬀerence between the Nakanishi and Gillespie schemes involves the
time step. It is no longer constant but varies with time and equals ∆t = ln(1/r1)/a0, where
r1 is a random variable selected from a normalized uniform distribution. The theoretical
justiﬁcation for this choice is given in Section III of his paper.
10 Gillespie, D. T., 1976: A general method for numerically simulating the stochastic time evolution
of coupled chemical reactions. J. Comput. Phys., 22, 403–434; Gillespie, D. T., 1977: Exact stochastic
simulation of coupled chemical reactions. J. Phys. Chem., 81, 2340–2361

886
Advanced Engineering Mathematics with MATLAB
0
5
10
15
20
25
30
0
1000
2000
3000
4000
5000
 time
 number of x molecules
0
5
10
15
20
25
30
0
1000
2000
3000
4000
5000
 time
 number of y molecules
Figure 17.4.2: Same as Figure 17.4.1 except that Gillespie’s method has been used.
For the second portion of this project, create MATLAB code to simulate our chemical
reaction using Gillespie’s technique. You might like to plot x(t) vs y(t) and observe the
patterns that you obtain.
Finally, for a speciﬁc time, compute the probability density function that gives the
probability that x and y molecules exist. See Figure 17.4.3.
17.5 POISSON PROCESSES
The Poisson random process is a counting process that counts the number of occur-
rences of some particular event as time increases. In other words, for each value of t, there
is a number N(t), which gives the number of events that occurred during the interval [0, t].
For this reason N(t) is a discrete random variable with the set of possible values {0, 1, 2, . . .}.
Figure 17.5.1 illustrates a sample function. We can express this process mathematically by
N(t) =
∞
X
n=0
H(t −T[n]),
(17.5.1)
where T[n] is the time to the nth arrival, a random sequence of times. The question now
becomes how to determine the values of T[n]. The answer involves three rather physical
assumptions. They are:
1. N(0) = 0.
2. N(t) has independent and stationary increments. By stationary we mean that for any
two equal time intervals ∆t1 and ∆t2, the probability of n events in ∆t1 equals the
probability of n events in ∆t2. By independent we mean that for any time interval

Random Processes
887
0
1000
2000
3000
0
0.2
0.4
0.6
0.8
1
1.2x 10
−3
number of  x  molecules
Estimated PDF
0
1000
2000
3000
0
0.2
0.4
0.6
0.8
1
1.2x 10
−3
number of  y  molecules
Figure 17.4.3: The estimated probability density function for the chemical reactions given by Equations
(1) through (3) (for X on the left, Y on the right) at time t = 10. Five thousand realizations were used in
these computations.
(t, t + ∆t) the probability of n events in (t, t + ∆t) is independent of how many events
have occurred earlier or how they have occurred.
3.
P[N(t + ∆t) −N(t) = k ] =
( 1 −λ∆t,
k = 0,
λ∆t,
k = 1,
0,
k > 1,
(17.5.2)
for all t. Here λ equals the expected number of events in an interval of unit length of
time. Because E[N(t)] = λ, it is the average number of events that occur in one unit
of time and in practice it can be measured experimentally.
We begin our analysis of Poisson processes by ﬁnding P[N(t) = 0 ] for any t > 0. If
there are no arrivals in [0, t], then there must be no arrivals in [0, t−∆t] and also no arrivals
in (t −∆t, t]. Therefore,
P[N(t) = 0 ] = P[N(t −∆t) = 0, N(t) −N(t −∆t) = 0 ].
(17.5.3)
Because N(t) is independent,
P[N(t) = 0 ] = P[N(t −∆t) = 0 ]P[N(t) −N(t −∆t) = 0 ].
(17.5.4)
Furthermore, since N(t) is stationary,
P[N(t) = 0 ] = P[N(t −∆t) = 0 ]P[N(t + ∆t) −N(t) = 0 ].
(17.5.5)
Finally, from Equation 17.5.2,
P[N(t) = 0 ] = P[N(t −∆t) = 0 ](1 −λ∆t).
(17.5.6)

888
Advanced Engineering Mathematics with MATLAB
4
3
2
1
N(t)
t
t
t
t
t
t
1
2
4
5
3
Figure 17.5.1: Schematic of a Poisson process.
Let us denote P[N(t) = 0 ] by P0(t). Then,
P0(t) = P0(t −∆t)(1 −λ∆t),
(17.5.7)
or
P0(t) −P0(t −∆t)
∆t
= −λP0(t −∆t).
(17.5.8)
Taking the limit as ∆t →0, we obtain the (linear) diﬀerential equation
dP0(t)
dt
= −λP0(t).
(17.5.9)
The solution of Equation 17.5.9 is
P0(t) = Ce−λt,
(17.5.10)
where C is an arbitrary constant. To evaluate C, we have the initial condition P0(0) =
P[N(0) = 0 ] = 1 from Axion 1. Therefore,
P[N(t) = 0 ] = P0(t) = e−λt.
(17.5.11)
Next, let us ﬁnd P1(t) = P[N(t) = 1 ]. We either have no arrivals in [0, t −∆t] and one
arrival in (t −∆t, t] or one arrival in [0, t −∆t] and no arrivals in (t −∆t, t]. These are the
only two possibilities because there can be at most one arrival in a time interval ∆t. The
two events are mutually exclusive. Therefore,
P[N(t) = 1 ] = P[N(t −∆t) = 0, N(t) −N(t −∆t) = 1 ]
+ P[N(t −∆t) = 0, N(t) −N(t −∆t) = 0 ]
(17.5.12)
= P[N(t −∆t) = 0 ]P[N(t) −N(t −∆t) = 1 ]
+ P[N(t −∆t) = 1 ]P[N(t) −N(t −∆t) = 0 ]
(17.5.13)
= P[N(t −∆t) = 0 ]P[N(t + ∆t) −N(t) = 1 ]
+ P[N(t −∆t) = 1 ]P[N(t + ∆t) −N(t) = 0 ].
(17.5.14)

Random Processes
889
Equation 17.5.13 follows from independence while Equation 17.5.14 follows from stationar-
ity. Introducing P1(t) in Equation 17.5.14 and using Axion 3,
P1(t) = P0(t −∆t)λ∆t + P1(t −∆t)(1 −λ∆t),
(17.5.15)
or
P1(t) −P1(t −∆t)
∆t
= −λP1(t −∆t) + λP0(t −∆t).
(17.5.16)
Taking the limit as ∆t →0, we obtain
dP1(t)
dt
+ λP1(t) = λP0(t).
(17.5.17)
In a similar manner, we can prove that
dPk(t)
dt
+ λPk(t) = λPk−1(t),
(17.5.18)
where k = 1, 2, 3, . . . and Pk(t) = P[N(t) = k].
This set of simultaneous linear equations can be solved recursively. Its solution is
Pk(t) = exp(−λt)(λt)k
k!
,
k = 0, 1, 2, . . . ,
(17.5.19)
which is the Poisson probability mass function. Here λ is the average number of arrivals
per second.
In the realization of a Poisson process, one of the important quantities is the arrival
time, tn, shown in Figure 17.5.1. Of course, the arrival time is also a random process and
will change with each new realization. A related quantity Zi = ti −ti−1, the time intervals
between two successive occurrences (interoccurrence times) of Poisson events. We will now
show that the random variables Z1, Z2, etc., are independent and identically distributed
with
P(Zn ≤x) = 1 −e−λx,
x ≥0,
n = 1, 2, 3, . . .
(17.5.20)
We begin by noting that
P(Z1 > t) = P[N(t) = 0] = e−λt
(17.5.21)
from Equation 17.5.19. Therefore, Z1 has an exponential distribution.
Let us denote its probability density by pZ1(z1). From the joint conditional density
function,
P(Z2 > t) =
Z ξ1
0
P(Z2 > t|Z1 = z1)pZ1(z1) dz1,
(17.5.22)
where 0 < ξ1 < t. If Z1 = z1, then Z2 > t if and only if N(t + z1) −N(z1) = 0. Therefore,
using the independence and stationary properties,
P{Z2 > t|Z1 = P[N(t + z1) −N(z1) = 0]} = P[N(t) = 0] = e−λt.
(17.5.23)
Consequently,
P(Z2 > t) = e−λt,
(17.5.24)

890
Advanced Engineering Mathematics with MATLAB
showing that Z2 is also exponential. Also, Z2 is independent of Z1. Now, let us introduce
pZ2(z2) as the probability density of Z1 + Z2. By similar arguments we can show that Z3
is also exponential. The ﬁnal result follows by induction.
• Example 17.5.1: Random telegraph signal
We can use the fact that interoccurrence times are independent and identically dis-
tributed to realize the Poisson process. An important application of this is in the generation
of the random telegraph signal: X(t) = (−1)N(t). However, no one uses this deﬁnition to
compute the signal; they use the arrival times to change the signal from +1 to −1 or vice
versa.
We begin by noting that Ti = Ti−1 + Zi, with i = 1, 2, . . ., T0 = 0, and Ti is the ith
arrival time. Each Zi has the same exponent probability density function. From Equation
16.4.17,
Zi = 1
λ ln

1
1 −Ui

,
(17.5.25)
where the Ui’s are from a uniform distribution. The realization of a random telegraphic
signal is given by the MATLAB code:
clear
N = 100; % number of switches in realization
lambda = 0.15; % switching rate
X = [ ];
% generate N uniformly distributed random variables
S = rand(1,N);
% transform S into an exponential random variable
T = - log(S)/lambda;
V = cumsum(T); % compute switching times
t = [0.01:0.01:100]; % create time array
icount = 1; amplitude = -1; % initialize X(t)
for k = 1:10000
if ( t(k) >= V(icount) ) % at each switching point
icount = icount + 1;
amplitude = - amplitude; % switch sign
end
X(k) = amplitude; % generate X(t)
end
plot(t,X) % plot results
xlabel(’\it t’,’FontSize’,25);
ylabel(’\it X(t)/a’,’FontSize’,25);
axis([0 max(t) -1.1 1.1])
This was the MATLAB code that was used to generate Figure 17.5.2.
⊓⊔
• Example 17.0.2
It takes a workman an average of one hour to put a widget together. Assuming that
the task can be modeled as a Poisson process, what is the probability that a workman can
build 12 widgets during an eight-hour shift?

Random Processes
891
The probability that n widgets can be constructed by time t is
P[N(t) = n] = e−λt (λt)n
n!
.
(17.5.26)
Therefore, the probability that 12 or more widgets can be constructed in eight hours is
P[N(t) ≥12] = e−8
∞
X
n=12
8n
n! = 0.1119,
(17.5.27)
since λ = 1.
We could have also obtained our results by creating 12 exponentially distributed time
periods and summed them together using MATLAB:
t uniform = rand(1,12);
T = - log(1-t uniform);
total time = sum(T);
Then, by executing this code a large number N of times and counting the number icount
of times that total time <= 8, the probability equals icount / N.
Problems
1. Use the generating function
F(z, t) =
∞
X
n=0
pn(t)zn,
|z| < 1,
with F(z, 0) = 1 to solve Equation 17.5.18 by showing that F(z, t) = eλt(z−1). Then, by
expanding F(z, t), recover Equation 17.5.19.
Project: Output from a Filter
When the Input Is a Random Telegraphic Signal 11
In the study of many systems, such as linear ﬁlters, the output y(·) can be written as
y(t) =
Z t
−∞
W(t −τ)x(τ) dτ,
where W(·) is the weight function and x(·) is the input. The purpose of this project is
to explore the probability density P(y) of the output when x(t) is the random telegraphic
signal, a Poisson random process. You will ﬁlter this input two ways: (1) ideal integrator
with ﬁnite memory: W(t) = H(t) −H(t −τ1), τ1 > 0, and (2) simple RC = 1 low-pass
ﬁlter W(t) = e−tH(t).
Step 1: Use MATLAB to code x(t) where the expected time between the zeros is λ.
Step 2: Develop MATLAB code to compute y(t) for each of the weight functions W(t).
Step 3: Compute P(y) for both ﬁlters. How do your results vary as λ varies?
11 Suggested by a paper by McFadden, J. A., 1959: The probability density of the output of a ﬁlter when
the input is a random telegraphic signal: Diﬀerential-equation approach. IRE Trans. Circuit Theory, 6,
228–233.

892
Advanced Engineering Mathematics with MATLAB
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
 y
 P(y)
Figure 17.5.1: The probability density P(y) of the output from an ideal integrator with ﬁnite memory
when the input is a random telegraphic signal when ∆t = 0.01, λ = 2, and τ1 = 10.
−1
−0.5
0
0.5
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
 y
 P(y)
Figure 17.5.2: The probability density P(y) of the output from a simple RC = 1 ﬁlter, when the input is
a random telegraphic signal, when λ = 1, and ∆t = 0.05.
Further Readings
Beckmann, P., 1967: Probability in Communication Engineering. Harcourt, Brace & World,
511 pp. A presentation of probability as it applies to problems in communication engineer-
ing.
Gillespie, D. T., 1991: Markov Processes: An Introduction for Physical Scientists. Academic
Press, 592 pp. For the scientist who needs an introduction to the details of the subject.
Hsu, H., 1997: Probability, Random Variables, & Random Processes. McGraw-Hill, 306 pp.

Random Processes
893
Summary of results plus many worked problems.
Kay, S. M., 2006: Intuitive Probability and Random Processes Using MATLAB. Springer,
833 pp. A well-paced book designed for the electrical engineering crowd.
Ross, S. M., 2007: Introduction to Probability Models. Academic Press, 782 pp. An intro-
ductory undergraduate book in applied probability and stochastic processes.
Tuckwell, H. C., 1995: Elementary Applications of Probability Theory. Chapman & Hall,
292 pp. This book presents applications using probability theory, primarily from biology.

Chapter 18
Itˆo’s Stochastic Calculus
In Chapter 1 we studied the solution to ﬁrst-order ordinary diﬀerential equations
dx
dt = a(t, x),
x(0) = x0.
(18.0.1)
There we showed that Equation 18.0.1 has the solution
x(t) = x(0) +
Z t
0
a[η, x(η)] dη.
(18.0.2)
Consider now the analogous stochastic diﬀerential equation:
dX(t) = a[t, X(t)] dt,
X(0) = X0.
(18.0.3)
Although Equations 18.0.1 and 18.0.3 formally appear the same, an immediate question is
what is meant by dX(t). In elementary calculus the concept of the inﬁnitesimal involves
limits, continuity, and so forth. As we shall see in Section 18.2, Brownian motion, a very
common stochastic process, is nowhere diﬀerentiable. Here we can merely say that dX(t) =
X(t + dt) −X(t).
Consider now a modiﬁcation of Equation 18.0.3 where we introduce a random forcing:
dX(t) = a[t, X(t)] dt + b[t, X(t)] dB(t),
X(0) = X0.
(18.0.4)
Here dB(t) = B(t + dt) −B(t), B(t) denotes Brownian motion and a[t, X(t)] and b[t, X(t)]
are deterministic functions. Consequently, changes to X(t) result from (1) the eﬀects of the
895

896
Advanced Engineering Mathematics with MATLAB
initial conditions and (2) noise generated by Brownian motion (the driving force). Stochastic
processes governed by Equation 18.0.4 are referred to as Itˆo processes.
Following the methods used to derive 18.0.2 we can formally write the solution to
Equation 18.0.4 as
X(t) = X0 +
Z t
0
a[η, X(η)] dη +
Z t
0
b[η, X(η)] dB(η).
(18.0.5)
The ﬁrst integral in Equation 18.0.5 is the conventional Riemann integral from elementary
calculus and is well understood. The second integral, however, is new and must be treated
with care. It is called Itˆo’s stochastic integral and treated in Section 18.3.
In summary, a simple analog to ﬁrst-order ordinary diﬀerential equations for a single
random variable X(t) raises several important questions. What is meant by the inﬁnitismal
and the integral in stochastic calculus? In this chapter we will focus on Itˆo processes and
the associated calculus. Although Itˆo’s calculus is an important discipline, it is not the only
form of stochastic calculus. The interested student is referred elsewhere for further study.
Problems
1. The Poisson random process N(t) is deﬁned by
N(t) =
∞
X
n=1
H(t −tn),
where tn is a sequence of independent and identically distributed inter-arrival times tn.
A graphical representation of N(t) would consist of ever-increasing steps with the edges
located at t = tn. Use the deﬁnition of dN(t) = N(t + dt) −N(t) to show that
dN(t) =

1,
for t = tn,
0,
otherwise.
2. The telegraph signal is deﬁned by X(t) = (−1)N(t), where N(t) is given by the Poisson
random distribution in Problem 1. Show1 that
dX(t) = X(t + dt) −X(t) = (−1)N(t) h
(−1)dN(t) −1
i
= −2X(t) dN(t).
Hint: Consider dN(t) at various times.
3. If X(t) and Y (t) denote two stochastic processes, use the deﬁnition of the derivative to
show that (a) d[cX(t)] = c dX(t), where c is a constant, (b) d[X(t)±Y (t)] = dX(t)±dY (t),
and (c) d[X(t)Y (t)] = X(t) dY (t) + Y (t) dX(t) + dX(t) dY (t).
18.1 RANDOM DIFFERENTIAL EQUATIONS
A large portion of this book has been devoted to solving diﬀerential equations. Here
we examine the response of diﬀerential equations to random forcing where the diﬀerential
1 Taken from Janaswamy, R., 2013: On random time and on the relation between wave and telegraph
equation. IEEE Trans. Antennas Propag., 61, 2735–2744.

Itˆo’s Stochastic Calculus
897
equation describes a nonrandom process. This is an important question in the sciences and
engineering because noise, a random phenomenon, is ubiquitous in nature.
Because the solution to random diﬀerential equations can be found by conventional
techniques, we can use them to study the eﬀect of randomness on the robustness of a
solution to a diﬀerential equation subject to small changes of the initial condition. Although
this may be of considerable engineering interest, it is really too simple to develop a deep
understanding of stochastic diﬀerential equations.
• Example 18.1.1: LR circuit
One of the simplest diﬀerential equations that we encountered in Chapter 1 involves
the mathematical model for an LR electrical circuit:
LdI
dt + RI = E(t),
(18.1.1)
where I(t) denotes the current within an electrical circuit with inductance L and resistance
R, and E(t) is the mean electromotive force. If we solve this ﬁrst-order ordinary diﬀerential
equation using an integrating factor, its solution is
I(t) = I(0) exp

−Rt
L

+ 1
L exp

−Rt
L
 Z t
0
F(τ) exp
Rτ
L

dτ.
(18.1.2)
Clearly, if the electromotive forcing is random, so is the current.
In the previous chapter we showed that the mean and variance were useful parameters
in characterizing a random variable. This will also be true here. If we ﬁnd the mean of the
solution,
E[I(t)] = I(0) exp

−Rt
L

(18.1.3)
provided E[F(t)] = 0. Thus, the mean of the current is the same as that for an ideal LR
circuit.
Turning to the variance,
σ2
I(t) = E[I2(t)] −{E[I(t)]}2
(18.1.4)
= E

I2(0) exp

−2Rt
L

+ 2I(0)
L
exp

−2Rt
L
 Z t
0
E[F(τ)] exp
Rτ
L

dτ
+ 1
L2 exp

−2Rt
L
 Z t
0
Z t
0
E[F(τ)F(τ ′)] exp
R(τ + τ ′)
L

dτ ′ dτ
(18.1.5)
−I2(0) exp

−2Rt
L

= 1
L2 exp

−2Rt
L
 Z t
0
Z t
0
E[F(τ)F(τ ′)] exp
R(τ + ξ)
L

dτ ′ dτ.
(18.1.6)
To proceed further we need the autocorrelation E[F(τ)F(τ ′)]. In papers by Ornstein
et al.2 and Jones and McCombie,3 they adopted a random process with the autocorrelation
2 Ornstein, L. S., H. C. Burger, J. Taylor, and W. Clarkson, 1927: The Brownian movement of a
galvanometer and the inﬂuence of the temperature of the outer circuit. Proc. Roy. Soc. London, Ser. A,
115, 391–406.
3 Jones, R. V., and C. W. McCombie, 1952: Brownian ﬂuctuations in galvanometer and galvanometer
ampliﬁers. Phil. Trans. Roy. Soc. London, Ser. A, 244, 205–230.

898
Advanced Engineering Mathematics with MATLAB
function
E[F(τ)F(τ ′)] = 2Dδ(τ −τ ′).
(18.1.7)
The advantage of this process is that it is mathematically the simplest because it possesses a
white power spectrum. Unfortunately this random process can never be physically realized
because it would possess inﬁnite mean square power. All physically realizable processes
involve a power spectrum that tends to zero at suﬃciently high frequencies. If Φ(ω) denotes
the power spectrum, this condition can be expressed as
Z ∞
0
Φ(ω) dω < ∞.
(18.1.8)
In view of these considerations, let us adopt the autocorrelation
RX(τ −τ ′) =
Z ∞
0
Φ(ω) cos[ω(τ −τ ′)] dω,
(18.1.9)
where Φ(ω) is the power spectrum of F(τ). Therefore, the variance becomes
σ2
I(t) = 1
L2
Z t
0
Z t
0
Z ∞
0
Φ(ω) exp

−R(t −τ)
L

exp

−R(t −τ ′)
L

cos[ω(τ −τ ′)] dω dτ dτ ′.
(18.1.10)
Reversing the ordering of integration,
σ2
I(t) = 1
L2
Z ∞
0
Φ(ω)
Z t
0
Z t
0
exp

−R(2t −τ −τ ′)
L

cos[ω(τ −τ ′)] dτ dτ ′ dω.
(18.1.11)
We can evaluate the integrals involving τ and τ ′ exactly. Equation 18.1.11 then becomes
σ2
I(t) =
Z ∞
0
Φ(ω)
ω2 + R2/L2
h
1 + e−2Rt/L −2e−Rt/L cos(ωt)
i
dω.
(18.1.12)
Let us now consider some special cases. As t →0, σ2
I(t) →0 and the variance is
initially small. On the other hand, as t →∞,
σ2
I(t) =
Z ∞
0
Φ(ω)
ω2 + R2/L2 dω.
(18.1.13)
Thus, the variance grows to a constant value, which we would have found by using Fourier
transforms to solve the diﬀerential equation.
Consider now the special case Φ(ω) = 2D/π, a forcing by white noise. Ignoring the
defects in this model, we can evaluate the integrals in Equation 18.1.13 exactly and ﬁnd
that
σ2
I(t) = DL
R

1 −e−2Rt/L
.
(18.1.14)
These results are identical to those found by Uhlenbeck and Ornstein4 in their study of a
free particle in Brownian motion.
⊓⊔
4 Uhlenbeck, G. E., and L. S. Ornstein, 1930: On the theory of the Brownian motion. Phys. Review,
36, 823–841. See the top of their page 828.

Itˆo’s Stochastic Calculus
899
• Example 18.1.2: Damped harmonic motion
Another classic diﬀerential equation that we can excite with a random process is the
damped harmonic oscillator:
y′′ + 2ξω0y′ + ω2
0y = F(t),
(18.1.15)
where 0 ≤ξ < 1, y denotes the displacement, t is time, ω2
0 = k/m, 2ξω0 = β/m, m is
the mass of the oscillator, k is the linear spring constant, and β denotes the constant of a
viscous damper. In Chapter 2 we showed how to solve this second-order ordinary diﬀerential
equation. Its solution is
y(t) = y(0)e−ξω0t

cos(ω1t) + ξω0
ω1
sin(ω1t)

+ y′(0)
ω1
e−ξωt sin(ω1t) +
Z t
0
h(t −τ)F(τ) dτ,
(18.1.16)
where ω1 = ω0
p
1 −ξ2, and
h(t) = e−ξω0t
ω1
sin(ω1t)H(t).
(18.1.17)
Again we begin by ﬁnding the mean of Equation 18.1.16. It is
E[y(t)] = y(0)e−ξω0t

cos(ω1t) + ξω0
ω1
sin(ω1t)

+y′(0)
ω1
e−ξωt sin(ω1t)+
Z t
0
h(t−τ)E[F(τ)] dτ.
(18.1.18)
If we again choose a random process where E[F(t)] = 0, the integral vanishes and the
stochastic mean of the motion only depends on the initial conditions.
Turning to the variance,
σ2
I(t) = E[y2(t)] −{E[y(t)]}2 =
Z t
0
Z t
0
h(t −τ)h(t −τ ′)E[F(τ)F(τ ′)] dτ dτ ′.
(18.1.19)
If we again adopt the autocorrelation function
RX(τ −τ ′) =
Z ∞
0
Φ(ω) cos[ω(τ −τ ′)] dω,
(18.1.20)
where Φ(ω) is the power spectrum of F(τ), then
σ2
I(t) =
Z ∞
0
Φ(ω)
ω2
1
Z t
0
Z t
0
e−ξω0(2t−τ−τ ′) sin[ω1(t −τ)] sin[ω1(t −τ ′)] cos[ω(τ −τ ′)] dτ dτ ′ dω.
(18.1.21)
Carrying out the integrations in τ and τ ′, we ﬁnally obtain
σ2
I(t) =
Z ∞
0
Φ(ω)
|Ω(ω)|2

1 + e−2ξω0t

1 + 2ξω0
ω1
sin(ω1t) cos(ω1t)
−eω0ξt

2 cos(ω1t) + 2ξω0
ω1
sin(ω1t)

cos(ωt) −eξω0t 2ω
ω1
sin(ω1t) sin(ωt)
+ ξ2ω2
0 −ω2
1 + ω2
ω2
1
sin2(ω1t)

dω,
(18.1.22)

900
Advanced Engineering Mathematics with MATLAB
0
1
2
3
4
−0.02
−0.01
0
0.01
0.02
0.03
mean of forcing
0
1
2
3
4
0
0.2
0.4
0.6
0.8
1
mean of response
0
1
2
3
4
0.95
1
1.05
t
variance of forcing
0
1
2
3
4
0
2
4
6x 10
−3
t
variance of response
Figure 18.1.1: The mean and variance of the response for the diﬀerential equation y′ + y = f(t) when
forced by Gaussian random noise. The parameters used are y(0) = 1 and ∆τ = 0.01.
where |Ω(ω)|2 = (ω2
0 −ω2)2 + 4ω2ω2
0ξ2.
As in the previous example, σ2
I(t) →0 as t →0 and the variance is initially small. The
steady-state variance now becomes
σ2
I(t) =
Z ∞
0
Φ(ω)
|Ω(ω)|2 dω.
(18.1.23)
Finally, for the special case Φ(ω) = 2D/π, the variance is
σ2
I(t) =
D
2ξω2
0

1 −e−2ξω0t
ω2
1

ω2
1 + ω0ω1ξ sin(2ω1t) + 2ξ2ω2
0 sin2(ω1t)

.
(18.1.24)
These results are identical to those found by Uhlenbeck and Ornstein5 in their study of a
harmonically bound particle in Brownian motion.
Project: Low-Pass Filter with Random Input
Consider the initial-value problem
y′ + y = f(t),
y(0) = y0.
It has the solution
y(t) = y0e−t + e−t
Z t
0
eτf(τ) dτ.
This diﬀerential equation is identical to that governing an RC electrical circuit. This circuit
has the property that it ﬁlters out high frequency disturbances. Here we explore the case
when f(t) is a random process.
5 Ibid. See their pages 834 and 835.

Itˆo’s Stochastic Calculus
901
−0.2 −0.1
0
0.1
0.2
0
5
10
15
 t = 0.1
Estimated PDF
−0.2 −0.1
0
0.1
0.2
0
2
4
6
8
 t = 0.5
Estimated PDF
−0.2 −0.1
0
0.1
0.2
0
2
4
6
8
 t = 1.5
 y
Estimated PDF
−0.2 −0.1
0
0.1
0.2
0
2
4
6
 t = 3
Estimated PDF
y
Figure 18.1.2: The probability density function for the response to the diﬀerential equation y′ + y = f(t)
when f(t) is a Gaussian distribution.
Twenty thousand realizations were used to compute the density
function. Here the parameters used are y(0) = 0 and ∆τ = 0.01.
Step 1: Using the MATLAB intrinsic function randn, generate a stationary white noise
excitation of length N. Let deltat denote the time interval ∆t between each new forcing so
that n = 1 corresponds to t = 0 and n = N corresponds to the end of the record t = T.
Step 2: Using the Gaussian random forcing that you created in Step 1, develop a MATLAB
code to compute y(t) given y(0) and f(t).
Step 3: Once you have conﬁdence in your code, modify it so that you can generate many
realizations of y(t). Save your solution as a function of t and realization. Use MATLAB’s
intrinsic functions mean and var to compute the mean and variance as a function of time.
Figure 18.1.1 shows the results when 2000 realizations were used. For comparison the mean
and variance of the forcing have also been included. Ideally this mean and variance should
be zero and one, respectively. We have also included the exact mean and variance, given
by Equation 18.1.3 and Equation 18.1.14, when we set L = R = 1 and D = ∆t/2.
Step 4: Now generalize your MATLAB code so that you can compute the probability density
function of ﬁnding y(t) lying between y and y+dy at various times. Figure 18.1.2 illustrates
four times when y(0) = 0 and ∆τ = 0.01.
Step 5: Modify your MATLAB code so that you can compute the autocovariance. See Figure
18.1.3.
Project: First-Passage Problem with Random Vibrations 6
In the design of devices, it is often important to know the chance that the device will
exceed its design criteria. In this project you will examine how often the amplitude of a
6 Based on a paper by Crandall, S. H., K. L. Chandiramani, and R. G. Cook, 1966: Some ﬁrst-passage
problems in random vibration. J. Appl. Mech., 33, 532–538.

902
Advanced Engineering Mathematics with MATLAB
0
1
2
3
0
1
2
3
0
2
4
6
x 10
−3
 t1
 t2
autocovariance
Figure 18.1.3: The autocovariance function for the diﬀerential equation y′ + y = f(t) when f(t) is a
Gaussian distribution. Twenty thousand realizations were used. The parameters used here are y(0) = 0
and ∆τ = 0.01.
simple, slightly damped harmonic oscillator
y′′ + 2ζω0y′ + ω2
0y = f(t),
0 < ζ ≪1,
(1)
will exceed a certain magnitude when forced by white noise. In the physical world this
transcending of a barrier or passage level leads to “bottoming” or “short circuiting.”
Step 1: Using the MATLAB command randn, generate a stationary white noise excitation
of length N. Let deltat denote the time interval ∆t between each new forcing so that n =
1 corresponds to t = 0 and n = N corresponds to the end of the record t = T.
Step 2: The exact solution to Equation (1) is
y(t) = y(0)e−ζω0t
"
cos
p
1 −ζ2 ω0t

+
ζ
p
1 −ζ2 sin
p
1 −ζ2 ω0t
#
+
y′(0)
ω0
p
1 −ζ2 e−ζω0t sin
p
1 −ζ2 ω0t

(2)
+
Z t
0
e−ζω0(t−τ) sin
hp
1 −ζ2 ω0(t −τ)
i
p
1 −ζ2
f(τ)
ω2
0
d(ω0τ)
= y(0)e−ζω0t
"
cos
p
1 −ζ2 ω0t

+
ζ
p
1 −ζ2 sin
p
1 −ζ2 ω0t
#
+
y′(0)
ω0
p
1 −ζ2 e−ζω0t sin
p
1 −ζ2 ω0t

(3)
+ e−ζω0t sin
p
1 −ζ2 ω0t

p
1 −ζ2
Z t
0
eζω0τ cos
p
1 −ζ2 ω0τ
 f(τ)
ω2
0
d(ω0τ)

Itˆo’s Stochastic Calculus
903
0
20
40
60
80
100
−4
−2
0
2
4
forcing
0
20
40
60
80
100
−2
−1
0
1
2
ω0t
y(t)
Figure 18.1.4: A realization of the random function y(t) governed by Equation (1) when forced by the
Gaussian random forcing shown in the top frame. The parameters used here are y(0) = 1, y′(0) = 0.5,
ζ = 0.1, and ω0∆τ = 0.02.
−e−ζω0t cos
p
1 −ζ2 ω0t

p
1 −ζ2
Z t
0
eζω0τ sin
p
1 −ζ2 ω0τ
 f(τ)
ω2
0
d(ω0τ).
Because you will be computing numerous realizations of y(t) for diﬀerent f(t)’s, an eﬃcient
method for evaluating the integrals must be employed. Equation (3) is more eﬃcient than
Equation (2).
Using the Gaussian random forcing that you created in Step 1, develop a MATLAB code
to compute y(t) given y(0), y′(0), ζ and f(t). Figure 18.1.4 illustrates a realization where
the trapezoidal rule was used to evaluate the integrals in Equation (3).
Step 3: Now that you can compute y(t) or y(n) for a given Gaussian random forcing,
generalize your code so that you can compute irun realizations and store them in y(n,m)
where m = 1:irun. For a speciﬁc n or ω0t, you can use MATLAB’s commands mean and var
to compute the mean µX(t) and the variance σ2
X(t). Figure 18.1.5 shows the results when
1000 realizations were used. For comparison the mean and variance of the forcing have also
been included. Ideally this mean and variance should be zero and one, respectively. The
crosses give the exact results that
µX(t) = y(0)e−ζω0t
"
cos
p
1 −ζ2 ω0t

+
ζ
p
1 −ζ2 sin
p
1 −ζ2 ω0t
#
+
y′(0)
ω0
p
1 −ζ2 e−ζω0t sin
p
1 −ζ2 ω0t

(4)
and Equation 18.1.25 when D = ω0∆t/2.
Step 4: Finally generalize your MATLAB code so that you store the time T(m) that the
solution y(n) exceeds a certain amplitude b > 0 for the ﬁrst time during the realization m.

904
Advanced Engineering Mathematics with MATLAB
0
10
20
30
40
50
−0.15
−0.1
−0.05
0
0.05
0.1
0.15
mean of forcing
0
10
20
30
40
50
−1
−0.5
0
0.5
1
1.5
mean of response
0
10
20
30
40
50
0.8
0.9
1
1.1
1.2
ω0t
variance of forcing
0
10
20
30
40
50
0
0.02
0.04
0.06
0.08
0.1
0.12
ω0t
variance of response
Figure 18.1.5: The mean µX(t) and variance σ2
X(t) of a slightly damped simple harmonic oscillator when
forced by the Gaussian random noise. The parameters used here are y(0) = 1, y′(0) = 0.5, ζ = 0.1, and
ω0∆τ = 0.02.
Of course, you can do this for several diﬀerent b’s during a particular realization. Once you
have this data you can estimate the probability density function using histc. Figure 18.1.6
illustrates four probability density functions for b = 0.4, b = 0.8, b = 1.2, and b = 1.6.
Project: Wave Motion Generated by Random Forcing 7
In the previous projects we examined ordinary diﬀerential equations that we forced
with a random process. Here we wish to extend our investigation to the one-dimensional
wave equation
∂2u
∂t2 −∂2u
∂x2 = cos(ωt)δ[x −X(t)],
subject to the boundary conditions
lim
|x|→∞u(x, t) →0,
0 < t,
and initial conditions
u(x, 0) = ut(x, 0) = 0,
−∞< x < ∞.
Here ω is a constant and X(t) is a stochastic process.
In Example 15.4.4 we show that the solution to this problem is
u(x, t) = 1
2
Z t
0
H[t −τ −|X(τ) −x|] cos(ωτ) dτ.
7 Based on a paper by Knowles, J. K., 1968: Propagation of one-dimensional waves from a source in
random motion. J. Acoust. Soc. Am., 43, 948–957.

Itˆo’s Stochastic Calculus
905
0
10
20
30
40
50
0
0.02
0.04
0.06
0.08
0.1
 b = 0.4
Estimated PDF
0  
50
100
150
200
0
0.005
0.01
0.015
0.02
0.025
 b = 0.8
Estimated PDF
0   
250
500 
750
1000
0
1
2
3
4
5x 10
−3
 b = 1.2
ω0T
Estimated PDF
0   
500
1000
1500
2000
0
2
4
6
8x 10
−4
 b = 1.6
ω0T
Estimated PDF
Figure 18.1.6: The probability density function that a slightly damped oscillator exceeds b at the time
ω0T. Fifty thousand realizations were used to compute the density function. The parameters used here are
y(0) = 0, y′(0) = 0, ζ = 0.05, and ω0∆τ = 0.05. The mean value of ω0T is 10.7 when b = 0.4, 41.93 when
b = 0.8, 188.19 when b = 1.2, and 1406.8 when b = 1.6.
When the stochastic forcing is absent X(t) = 0, we can evaluate the integral and ﬁnd that
u(x, t) = 1
2ω H(t −|x|) sin[ω(t −|x|)].
Step 1: Invoking the MATLAB command randn, use this Gaussian distribution to numeri-
cally generate an excitation X(t).
Step 2: Using the Gaussian distribution from Step 1, develop a MATLAB code to compute
u(x, t).
Figure 18.1.7 illustrates one realization where the trapezoidal rule was used to
evaluate the integral.
Step 3: Now that you can compute u(x, t) for a particular random forcing, generalize your
code so that you can compute irun realizations. Then, for particular values of x and t,
you can compute the corresponding mean and variance from the irun realizations. Figure
18.1.8 shows the results when 10,000 realizations were used.
Step 4: Redo your calculations but use a sine wave with random phase: X(t) = A sin(Ωt+ξ),
where A and Ωare constants and ξ is a random variable with a uniform distribution on
[0, 2π].
18.2: RANDOM WALK AND BROWNIAN MOTION
In 1827 the Scottish botanist Robert Brown (1773–1858) investigated the fertilization
process in a newly discovered species of ﬂower. Brown observed under the microscope that
when the pollen grains from the ﬂower were suspended in water, they performed a “rapid

906
Advanced Engineering Mathematics with MATLAB
−6
−4
−2
0
2
4
6
0
1
2
3
4
5
−0.25
−0.2
−0.15
−0.1
−0.05
0
0.05
0.1
0.15
0.2
0.25
 t
 x
 u(x,t)
−6
−4
−2
0
2
4
6
0
1
2
3
4
5
−0.25
−0.2
−0.15
−0.1
−0.05
0
0.05
0.1
0.15
0.2
0.25
 t
 x
 u(x,t)
(a)
(b)
Figure 18.1.7: The solution (realization) of the wave equation when forced by a Gaussian distribution
and ω = 2. In frame (a), there is no stochastic forcing X(t) = 0. Frame (b) shows one realization.
−6
−4
−2
0
2
4
60
1
2
3
4
5
−0.2
−0.15
−0.1
−0.05
0
0.05
0.1
0.15
0.2
 t
 x
 mean
−6
−4
−2
0
2
4
60
1
2
3
4
5
0
0.2
0.4
0.6
0.8
1
x 10
−3
 t
 x
 variance
Figure 18.1.8:
The mean and variance when the wave equation is forced by the stochastic forcing
cos(ωt)δ[x −X(t)], where ω = 2 and X(t) is a Gaussian distribution.
oscillation motion.” This motion, now known as Brownian motion, results from the random
kinetic strikes on the pollen grain by water molecules. Brownian motion is an example of
a random process known as random walk. This process has now been discovered in such
diverse disciplines, from biology8 to ﬁnance. In this section we examine its nature.
Consider a particle that moves along a straight line in a series of steps of equal length.
Each step is taken, either forwards or backwards, with equal probability 1
2. After taking
N steps the particle could be at any one (let us denote it m) of the following points:
8 Codling, E. A., M. J. Plank, and S. Benhamou, 2008: Random walk models in biology. J. R. Soc.
Interface, 5, 813–834.

Itˆo’s Stochastic Calculus
907
0
10
20
30
40
50
−10
−5
0
5
10
15
 N
 m
Figure 18.2.1: Three realizations of a one-dimensional random walk where N = 50.
−N, −N + 1, . . . , −1, 0, 1, . . . , N −1 and N. Here m is a random variable.
We can generate realizations of one-dimensional Brownian motion using the MATLAB
code:
clear
NN = 50; % select the number of steps for the particle to take
t = (0:1:NN); % create ‘‘time’’ as the particle moves
% create an array to give the position at each time step
m = zeros(size(t));
m(1) = 0; % initialize the position of particle
for N = 1:NN % now move the particle
x = rand(1); % generate a random variable lying between [0, 1]
if (x <= 0.5) step = 1; % if less then 0.5, make it a ‘‘head’’
else step = -1; end % otherwise it is a ‘‘tail’’
% move the particle one step to the right or left
m(N+1) = m(N) + step;
end
%
plot the results
hold on
plot(t,m,’--ko’,’LineWidth’,2,’MarkerSize’,8)
xlabel(’N’,’FontSize’,25); ylabel(’m’,’FontSize’,25)
grid on % add a grid to axes
Figure 18.2.1 illustrates three such realizations.
A natural question would now be: What are the quantitative properties of random
walk? In particular, what is the probability P(m, N) that the particle is at point m after N
displacements? We begin by noting the probability of any given sequence of N steps is
  1
2
N.
The desired probability P(m, N) equals
  1
2
N times the number of distinct sequences of steps

908
Advanced Engineering Mathematics with MATLAB
that will lead to the point m after N steps. To reach m, we must take (N +m)/2 steps in the
positive direction and (N −m)/2 in the negative direction since (N +m)/2−(N −m)/2 = m.
(Note both m and N must be even or odd.) The number of these distinct sequences is
N!
 1
2(N + m)

!
 1
2(N −m)

!.
(18.2.1)
Therefore,
P(m, N) =
N!
 1
2(N + m)

!
 1
2(N −m)

!
1
2
N
.
(18.2.2)
Comparing these results with Equation 16.6.14, we see that P(m, N) is simply a binomial
distribution. For this reason, we immediately know E(m) = 0 and Var(m) = N. That
is, the average position is the origin and the spread of the Brownian motion occurs as the
square root of steps taken increases.
The case of greatest interest arises when N is large and m ≪N. Then we can approx-
imate P(m, N) by the Poisson distribution,
P(m, N) ≈
r
2
πN exp

−m2
2N

.
(18.2.3)
Let us reexpress Equation 18.2.3 in terms of x and t where x = m∆x and t = N∆t. Using
these deﬁnitions, our equation becomes
P(x, t) =
1
2
√
πDt
exp

−x2
4Dt

,
(18.2.4)
if we deﬁne D = (∆x)2/(2∆t). The attentive student will note that P(x, t) is the Green’s
function for the heat function, Example 15.5.1.
An alternative approach to this problem would be to compute many random walks and
then calculate the probability density function from these computations. We can construct
a MATLAB code to do this. First we would realize many random walks (here 2000) and
count the number of times that they end at position m:
clear
NN = 100; % set the end point of the random walks
% introduce intermediate positions along the random walk
t = (0:1:NN);
% initialize array ‘‘m’’ which gives the position at any time
m = zeros(size(t));
for icount = 1:2000 % now perform many random walks
m(1) = 0; % initial position of particle in each walk
for N = 1:NN
x = rand(1); % create a random variable between [0, 1]
% if ’’x’’ less than 0.5, we have a ’’heads’’
if (x <= 0.5) step = 1;
else step = -1; end % otherwise we have a ’’tail’’

Itˆo’s Stochastic Calculus
909
−40
−30
−20
−10
0
10
20
30
40
0
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
0.09
 m
Estimated  P(m,100)
Figure 18.2.2: Numerical computation of P(m, 100) using 2000 random walks.
The black line gives
Equation 18.2.3.
m(N+1) = m(N) + step; % now take a step forward or backward
end
% set up array that tracks of the final position of the particle
location(icount) = m(N+1);
end
xx = -40:1:40;
% now count the particles that ended somewhere
%
between -40 and 40
[n,xout] = hist(location,xx)
% for comparison, compute Equation 18.2.3
w exact = sqrt(2/(pi*NN))*exp(-xout.*xout/(2*NN));
n = n / 2000; % now compute the mass probability function
%
plot the results
bar h = bar(xout,n)
bar child = get(bar h,’Children’)
set(bar child,’CData’,n)
colormap(Autumn)
hold on
plot(xout,w exact,’-k’,’LineWidth’,3)
xlabel(’\it m’,’FontSize’,25)
ylabel(’Estimated \it P(m,100)’,’FontSize’,25)
Figure 18.2.2 illustrates the results of simulating random walk.
• Example 18.2.1: On the probability of striking a barrier
An important question in engineering is what is the probability that a given random sys-
tem will exceed its design constraints. Here we ask a similar question about one-dimensional

910
Advanced Engineering Mathematics with MATLAB
t
ξ
N
m
Figure 18.2.3: Several random walks from the origin to point (ξ, N). All of these walks would be excluded
from our calculations because they either cross or touch the line m = ξ before the ﬁnal step.
Brownian motion: What is the probability that after taking N steps the particle arrives at
ξ without ever having touched or crossed the line m = ξ at any earlier step? We will do it
exactly and then conﬁrm our results using MATLAB.
The arrival of the particle at ξ after N steps implies that its position after N −1 steps
must have been either ξ −1 or ξ + 1. However, a trajectory from (ξ + 1, N −1) to (ξ, N) is
not allowed because it must have crossed the line m = ξ earlier. On the other hand, not all
trajectories arriving at (ξ, N) from (ξ −1, N −1) are acceptable because a certain number
will have touched or crossed the line m = ξ earlier than its last step. See Figure 18.2.3.
Thus the number of permitted ways of arriving at ξ for the ﬁrst time after N steps equals
all possible ways of arriving at ξ minus any arrivals from (ξ −1, N −1) and any arrivals
that crossed or touched the line m = ξ earlier than the N −1.
From our previous work, the number of possible ways from the origin to (ξ, N) is
N!
 1
2(N + ξ)

!
 1
2(N −ξ)

!.
(18.2.5)
The number of possible ways from the origin to (ξ + 1, N −1) is
(N −1)!
 1
2(N + ξ)

!
 1
2(N −ξ −2)

!.
(18.2.6)
Finally, the number of trajectories arriving at (ξ −1, N −1) but having an earlier contact
with, or a crossing of, the line m = ξ is also
(N −1)!
 1
2(N + ξ)

!
 1
2(N −ξ −2)

!,
(18.2.7)
since it equals the number of trajectories that arrive at (ξ + 1, N −1). From Figure 18.2.3
we see that, due to symmetry, the trajectory that leads to (ξ + 1, N −1) also leads to

Itˆo’s Stochastic Calculus
911
One of the great mathematicians of the twentieth century, Norbert Wiener (1894–1964) graduated
from high school at the age of 11 and Tufts at 14. Obtaining a doctorate in mathematical logic
at 18, he repeatedly traveled to Europe for further education. His work extends over an extremely
wide range from stochastic processes to harmonic analysis to cybernetics. (Photo courtesy of the
MIT Museum with permission.)
(ξ −1, N −1). Consequently the number of trajectories from the origin to (ξ, N) that have
never touched or crossed m = ξ is
N!
 1
2(N + ξ)

!
 1
2(N −ξ)

! −2
(N −1)!
 1
2(N + ξ)

!
 1
2(N −ξ −2)

!,
(18.2.8)
or
ξ
N
N!
 1
2(N + ξ)

!
 1
2(N −ξ)

!.
(18.2.9)
The probability P(ξ, N) that we are seeking is
P(ξ, N) = ξ
N
N!
 1
2(N + ξ)

!
 1
2(N −ξ)

!
1
2
N
.
(18.2.10)
For large N, P(ξ, N) is approximately given by
P(ξ, N) = ξ
N
r
2
πN exp

−ξ2
2N

.
(18.2.11)
We can also compute this probability using the MATLAB code given above. In this
code we replace the counting process location(icount) = m(N+1); by
b = sort(m);
if ( (m(NN+1) == b(NN+1)) & (b(NN+1)>b(NN)) )
jcount = jcount + 1;
location(jcount) = m(NN+1);
end
where we initialize jcount = 0 at the beginning. The idea behind this code is as follows:
For each of the icount trajectories, we use the MATLAB routine sort to arrange them from

912
Advanced Engineering Mathematics with MATLAB
−5
0
5
10
15
20
25
30
35
40
45
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5x 10
−3
ξ
Estimated  P(ξ,100)
Figure 18.2.4: The probability P(ξ, N) that a particle will reach the point m = ξ without the particle
ever crossing or touching the line m = ξ earlier than N = 100. The solid line is the theoretical probability
given by Equation 18.2.11. Here 50, 000 random walks were taken.
the left-most to the right-most position. To be included in the count of particles reaching
m = ξ at step N, the last position of the particle must be (ξ, N) and it may never have
reached or crossed m = ξ.
The if condition ensures that both conditions are met.
If
they are, that particular walk is accepted. Once again the various right-most positions are
binned and the probability is computed. Figure 18.2.4 illustrates this process using 5000
random walks and this result is compared with the probability given by Equation 18.2.11.
⊓⊔
• Example 18.2.2: Wiener process
Consider the time interval (0, t] and let us subdivide it into subintervals of length ∆t
so that there are t/∆t subintervals. Suppose now that a particle, initially at x = 0, takes a
step (in one space dimension) at the times ∆t, 2∆t, . . . and that the size of the step is either
∆x or −∆x, with a probability of 1
2 that the step is to the left or right. The position of
the particle X(t) at time t is a random walk, which has executed t/∆t steps. Because the
position depends on the choice of ∆t and ∆x, X(t) depends upon t, ∆t and ∆x.
Mathematically we can describe this random process by
X(t) =
t/∆t
X
n=1
Zi,
(18.2.12)
where the Zi’s are independent and identically distributed with
P(Zi = ∆x) = P(Zi = −∆x) = 1
2,
(18.2.13)
and n = 1, 2, . . .. For each Zi,
E(Zi) = 0,
and
Var(Zi) = E(Z2
i ) = (∆x)2.
(18.2.14)
From Equation 18.2.12, we see that
E[X(t)] = 0,
and
Var[X(t)] = E(Z2
i ) =
t
∆tVar(Zi) = t(∆x)2
∆t
.
(18.2.15)

Itˆo’s Stochastic Calculus
913
Presently we have said nothing about the relationship between ∆t and ∆x except
that both are small. However, we cannot have just any relationship between them because
the variance would be either zero or inﬁnite. The only reasonable choice is ∆x =
√
∆t,
which makes Var[X(t)] = t for all values of ∆t. In the limit ∆t →0 the random variable
X(t) converges into a random variable, hereafter denoted by B(t), with the properties that
E[B(t)] = 0 and Var[B(t)] = t.
The collection of random variables {B(t), t > 0} is a
continuous process in time and called a Wiener process.
⊓⊔
Our previous example shows that Brownian motion and the Wiener process are very
closely linked. Because Brownian motion occurs in so many physical and biological processes
we shall focus on that motion (and the corresponding Wiener process) exclusively from now
on.
We deﬁne the standard Brownian motion (or Wiener process) B(t) as a stochastic
process that has the following properties:
1. It starts at zero: B(0) = 0.
2. Noting that B(t)−B(s) ∼N(0, t−s), E{[B(t)−B(s)]2} = t−s and Var{[B(t)−
B(s)]2} = 2(t −s)2.
Replacing t with t + dt and s with t, we ﬁnd that
E{[dB(t)]2} = dt.
3. It has stationary and independent increments.
Stationary increments means
that B(t + h) −B(η + h) = B(t) −B(η) for all h. An independent increment
means B(t2) −B(t1), . . . , B(tn) −B(tn−1) are independent random variables.
4. Because increments of Brownian motion on adjacent intervals are independent
regardless of the length of the interval, the derivative will oscillate wildly as
∆x →0 and never converge. Consequently, Brownian motion is nowhere diﬀer-
entiable.
5. It has continuous sample paths, i.e., “no jumps.”
6. The expectation values for the moments are given by
E[B2n(t)] = (2n)!tn
n!2n ,
and
E[B2n−1(t)] = 0,
(18.2.16)
where n > 0. See Problem 1 at the end of Section 18.4.
Problems
1. Show that E{sin[aB(t)]} = 0, where a is a real.
2. Show that
E{cos[aB(t)]} =
∞
X
n=0
(−1)n
2nn! (a2t)n,
where a is a real.

914
Advanced Engineering Mathematics with MATLAB
3. Show that E{exp[aB(t)]} = exp(a2t/2), where a is a real.
Project: Probabilistic Solutions of Laplace’s Equation
In Section 9.7 and Section 9.8 we showed that we could solve Laplace’s equation using
ﬁnite diﬀerence or ﬁnite element methods, respectively. During the 1940s, the apparently
unrelated ﬁelds of random processes and potential theory were shown to be in some sense
mathematically equivalent.9 As a result, it is possible to use Brownian motion to solve La-
place’s equation, as you will discover in this project. The present numerical method is useful
for the following reasons: (1) the entire region need not be solved in order to determine
potentials at relatively few points, (2) computation time is not lengthened by complex ge-
ometries, and (3) a probabilistic potential theory computation is more topologically eﬃcient
than matrix manipulations for problems in two and three spatial dimensions.
To understand this technique,10 consider the following potential problem:
∂2u
∂x2 + ∂2u
∂y2 = 0,
0 < x < 1,
0 < y < 1,
(1)
subject to the boundary conditions
u(x, 0) = 0,
u(x, 1) = x,
0 < x < 1,
(2)
and
u(0, y) = u(1, y) = 0,
0 < y < 1.
(3)
If we introduce a uniform grid with ∆x = ∆y = ∆s, then the ﬁnite diﬀerence method yields
the diﬀerence equation:
4u(i, j) = u(i + 1, j) + u(i −i, j) + u(i, j + 1) + u(i, j −1),
(4)
with i, j = 1, N −1 and ∆s = 1/N.
Consider now a random process of the Markov type in which a large number N1 of non-
interacting particles are released at some point (x1, y1) and subsequently perform Brownian
motion in steps of length ∆s each unit of time. At some later time, when a few arrive at
point (x, y), we deﬁne a probability P(i, j) of any of them reaching the boundary y = 1
with potential uk at any subsequent time in the future. Whenever one of these particles
does (later) arrive on y = 1, it is counted and removed from the system. Because P(i, j) is
deﬁned over an inﬁnite time interval of the diﬀusion process, the probability of any parti-
cles leaving (x, y) and arriving along some other boundary (where the potential equals 0)
at some future time is 1 −P(i, j). Whenever a particle arrives along these boundaries it is
also removed from the square.
Having deﬁned P(i, j) for an arbitrary (x, y), we now compute it in terms of the proba-
bilities of the neighboring points. Because the process is Markovian, where a particle jumps
from a point to a neighbor with no memory of the past,
P(i, j) = p(i + 1, j|i, j)P(i + 1, j) + p(i −1, j|i, j)P(i −1, j)
+ p(i, j + 1|i, j)P(i, j + 1) + p(i, j −1|i, j)P(i, j −1),
(5)
9 See Hersh, R., and R. J. Griego, 1969: Brownian motion and potential theory. Sci. Amer., 220,
67–74.
10 For the general case, see Bevensee, R. M., 1973: Probabilistic potential theory applied to electrical
engineering problems. Proc. IEEE, 61, 423–437.

Itˆo’s Stochastic Calculus
915
0
2
4
6
8
10
0
1
2
3
4
5
6
7
8
9
10
 i
 j
Figure 18.2.5: Four Brownian motions within a square domain with ∆x = ∆y. All of the random walks
begin at grid point i = 4 and j = 6.
where p(i + 1, j|i, j) is the conditional probability of jumping to (x + ∆s, y), given that
the particle is at (x, y). Equation (5) evaluates P(i, j) as the sum of the probabilities of
reaching y = 1 at some future time by various routes through the four neighboring points
around (x, y). The sum of all the p’s is exactly one because a particle at (x, y) must jump
to a neighboring point during the next time interval.
Let us now compare Equation (4) and Equation (5). The potential u(i, j) in Equation
(4) and P(i, j) becomes an identity if we take the conditional probabilities as
p(i + 1, j|i, j) = p(i −1, j|i, j) = p(i, j + 1|i, j) = p(i, j −1|i, j) = 1
4,
(6)
and if we also force u(i, N) = P(i, N) = i, u(i, 0) = P(i, 0) = 0, u(0, j) = P(0, j) = 0,
and u(N, j) = P(N, j) = 0. Both the potential u and the probability P become continuous
functions in the space as ∆s →0, and both are well behaved as (x, y) approaches a boundary
point. A particle starting along y = 1, where the potential is uk, has a probability uk of
arriving there; a particle starting on the remaining boundaries, where the potential is zero,
is immediately removed with no chance of arriving along y = 1. From these considerations,
we have
u(i, j) ≡P(i, j) = lim
N→∞
1
N
X
k
Nkuk,
(7)
where N is the number of particles starting at (x, y) and Nk equals the number of particles
that eventually - after inﬁnite time - arrive along the entire boundary at potential uk. This
sum includes the boundary y = 1 and (trivially) the remaining boundaries.
Step 1: Develop a MATLAB code to perform two-dimensional Brownian motion. Let U
be a uniformly distributed random variable lying between 0 and 1. You can use rand. If
0 < U ≤1
4, take one step to the right; 1
4 < U ≤1
2, take one step to the left; if 1
2 < U ≤3
4,
take one step downward; and if 3
4 < U ≤1, take one step upward. For the arbitrary point
i,j located on a grid of N ×N points with 2 ≤i, j ≤N −1, repeatedly take a random step

916
Advanced Engineering Mathematics with MATLAB
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
 x
 50 realizations 
 y
 u(x,y)
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
 x
 200 realizations 
 y
 u(x,y)
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
 x
 800 realizations 
 y
 u(x,y)
0
0.5
1
0
0.5
1
0
0.2
0.4
0.6
0.8
1
 x
 3200 realizations 
 y
 u(x,y)
Figure 18.2.6: Solution to Equation (1) through Equation (3) using the probabilistic solution method.
until you reach one of the boundaries. Record the value of the potential at the boundary
point. Let us call this result u k(1). Figure 18.2.5 illustrates four of these two-dimensional
Brownian motions.
Step 2: Once you have conﬁdence in your two-dimensional Brownian motion code, generalize
it to solve Equation (1) through Equation (3) using runs realizations at some interior grid
point. Then the solution u(i,j) is given by
u(i, j) =
1
runs
runs
X
n=1
u k(n).
(8)
Step 3: Finally, plot your results. Figure 18.2.6 illustrates the potential ﬁeld for diﬀerent
values of runs. What are the possible sources of error in using this method?
18.3: ITˆO’S STOCHASTIC INTEGRAL
In the previous section we noted that Brownian motion (the Wiener process) is nowhere
diﬀerentiable. An obvious question is what is meant by the integral of a stochastic variable.
Consider the interval [a, b], which we subdivide so that a = t0 < t1 < t2 < · · · < tn = b.
The earliest and simplest deﬁnition of the integral is
Z b
a
f(t) dt = lim
∆t→0
n
X
i=1
f(τi) ∆ti,
(18.3.1)

Itˆo’s Stochastic Calculus
917
where ti−1 ≤τi ≤ti and ∆ti = ti −ti−1. In the case of the classic integral, the integration
is with regards to the increment dt.
Itˆo’s integral is an integral where the inﬁnitesimal increment involves Brownian motion
dB(t), which is a random variable. Before we can deﬁne this integral, we must introduce
two important concepts. The ﬁrst one is nonanticipating processes: A process F(t) is a
nonanticipating process if F(t) is independent of any future increment B(s) −B(t) for any
s and t where s > t. Nonanticipating processes are important because Itˆo’s integral applies
only to them.
The second important concept is convergence in the mean square sense. It is deﬁned
by
lim
n→∞E



"
Sn −
Z b
a
F(t) dB(t)
#2

= 0,
(18.3.2)
where Sn is the partial sum
Sn =
n
X
i=1
F(ti−1) [B(ti) −B(ti−1)] .
(18.3.3)
We are now ready to deﬁne the Itˆo integral: It is the limit of the partial sum Sn:
ms−lim
n→∞
Sn =
Z b
a
F(t) dB(t),
(18.3.4)
where we denoted the limit in the mean square sense by ms−lim. Combining Equation
18.3.3 and Equation 18.3.4 together, we ﬁnd that
Z b
a
f[t, B(t)] dB(t) = lim
∆t→0
n
X
i=1
f[ti−1, B(ti−1)] [B(ti) −B(ti−1)] ,
(18.3.5)
where ti = i∆t and ∆t = (b −a)/N. As one might suspect,
Z b
a
dB(t) = B(b) −B(a).
(18.3.6)
Because F(t) and dB(t) are random variables, so is Itˆo’s integral.
The results from Equation 18.3.6 would be misunderstood if we think about them as
we do in conventional calculus. We cannot evaluate the right side of Equation 18.3.6 by
looking up B(t) in some book entitled “Tables of Brownian Motion.” This equation only
holds true for a particular realization (sample path).
• Example 18.3.1
Let us use the deﬁnition of the Itˆo integral to evaluate Itˆo integral
R t
0 B(x) dB(x). In
the present case,
Sn =
n
X
i=1
B(xi−1) [B(xi) −B(xi−1)] ,
(18.3.7)

918
Advanced Engineering Mathematics with MATLAB
where xi = it/n. Because 2a(b −a) = b2 −a2 −(b −a)2,
Sn = 1
2
n
X
i=1
B2(xi) −1
2
n
X
i=1
B2(xi−1) −1
2
n
X
i=1
[B(xi) −B(xi−1)]2
(18.3.8)
= 1
2B2(t) −1
2
n
X
i=1
[B(xi) −B(xi−1)]2 .
(18.3.9)
Therefore,
ms−lim
n→∞
Sn = 1
2B2(t) −1
2 ms−lim
n→∞
n
X
i=1
[B(xi) −B(xi−1)]2
(18.3.10)
= 1
2B2(t) −t
2.
(18.3.11)
As a consequence,
Z t
0
B(η) dB(η) = 1
2B2(t) −t
2,
(18.3.12)
or
Z b
a
B(t) dB(t) = 1
2[B2(b) −B2(a)] −b −a
2
.
(18.3.13)
Consider now the derivative of B2(t),
d[B2(t)] = [B(t + dt) −B(t)]2 = 2B(t) dB(t) + dB(t) dB(t).
(18.3.14)
In order for Equation 18.3.12 and Equation 18.3.14 to be consistent, we arrive at the very
important result that
[dB(t)]2 = dt
(18.3.15)
in the mean square sense. We will repeatedly use this result in the remaining portions of
the chapter.
⊓⊔
Because the Itˆo integral is a random variable, two important quantities are its mean
and variance. Let us turn ﬁrst to the computation of the expectation of
R b
a f[t, B(t)] dB(t).
From Equation 18.3.5 we ﬁnd that
E
(Z b
a
f[t, B(t)] dB(t)
)
= lim
∆t→0 E
( n
X
i=1
f[ti−1, B(ti−1)]∆Bi
)
(18.3.16)
= lim
∆t→0
n
X
i=1
E{f[ti−1, B(ti−1)]}E[∆Bi] = 0.
(18.3.17)
Therefore
E
(Z b
a
f[t, B(t)] dB(t)
)
= 0.
(18.3.18)

Itˆo’s Stochastic Calculus
919
To compute the variance, we begin by noting that
(Z b
a
f[t, B(t)] dB(t)
)2
= lim
∆t→0
( n
X
i=1
f[ti−1, B(ti−1)]∆Bi
)2
(18.3.19)
= lim
∆t→0
n
X
i=1
f 2[ti−1, B(ti−1)](∆Bi)2
(18.3.20)
+ 2
n
X
i=1
n
X
j=1
i̸=j
f[ti−1, B(ti−1)]∆Bi f[tj−1, B(tj−1)]∆Bj.
Taking the expectation of both sides of Equation 18.3.20, we have that
E
Z b
a
f[t, B(t)] dB(t)
2
= lim
∆t→0
n
X
i=1
E{f 2[ti−1, B(ti−1)]}E[(∆Bi)2]
(18.3.21)
+ 2 lim
∆t→0
n
X
i=1
n
X
j=1
i̸=j
E{f(ti−1, B(ti−1)]}E[∆Bi] E{f(tj−1, B(tj−1)]}E[∆Bj]
= lim
∆t→0
n
X
i=1
E{f 2[ti−1, B(ti−1)]}(ti+1 −ti).
(18.3.22)
The double summation vanishes because of the independence of Brownian motion. There-
fore, the ﬁnal result is
E
(Z b
a
f[t, B(t)] dB(t)
)2
=
Z b
a
E{f 2[t, B(t)]} dt.
(18.3.23)
⊓⊔
• Example 18.3.2
Consider the random number X =
R b
a
√
t sin[B(t)] dB(t). Let us ﬁnd E(X) and E(X2).
From Equation 18.3.18, we have that E(X) = 0. For that reason, var(X) = E(X2)
and
Var(X) = E(X2) =
Z b
a
E
n√
t sin[B(t)]
2o
dt =
Z b
a
t E

sin2[B(t)]
	
dt
(18.3.24)
=
Z b
a
(t/2)E {1 −cos[2B(t)]} dt =
Z b
a
t
2
"
1 −
∞
X
n=0
(−1)n22ntn
2nn!
#
dt
(18.3.25)
= −1
2
Z b
a
∞
X
n=1
(−1)n2n
n!
tn+1 dt = 1
2
∞
X
n=1
(−1)n+12n
(n + 2)n!
 bn+2 −an+2
.
(18.3.26)
The value of E{cos[2B(t)]} follows from Problem 2 at the end of the last section.
⊓⊔

920
Advanced Engineering Mathematics with MATLAB
Table 18.3.1 gives a list of Itˆo stochastic integrals.
Most of these results were not
derived from the deﬁnition of the Itˆo stochastic integral but from Itˆo lemma, to which we
now turn.
Problems
Consider the random variable X =
R b
a f[t, B(t)] dB. Find E(X) and Var(X) for the follow-
ing f[t, B(t)]:
1. f[t, B(t)] = t
2. f[t, B(t)] = tB(t)
3. f[t, B(t)] = |B(t)|
4. f[f, B(t)] =
√
t exp[B(t)]
5. If X =
R b
a f(t){sin[B(t)] + cos[B(t)]} dB(t), show that var(X) =
R b
a f 2(t) dt, if f(t) is a
real function.
Project: Numerical Integration of Itˆo’s Integral
Equation 18.3.5 is useful for numerically integrating the Itˆo integral
Z t
0
f[x, B(x)] dB(x).
Write a MATLAB script to check Example 18.3.1 for various values of n when t = 1. How
does the error vary with n?
Project: Numerical Check of Equations 18.3.18 and 18.3.23
Using the script from the previous project, develop MATLAB code to compute Equation
18.3.18 and Equation 18.3.23. Using a million realizations (sample paths), compare your
numerical results with the exact answer when a = 1, b = 1, and f[t, B(t)] =
√
t sin[B(t)].
18.4: ITˆO’S LEMMA
Before we can solve stochastic diﬀerential equations, we must derive a key result in
stochastic calculus: Itˆo’s formula or lemma. This is stochastic calculus’s version of the
chain rule.
Consider a function f(t) that is twice diﬀerentiable. Using Taylor’s expansion,
df(B) = f(B + dB) −f(B) = f ′(B) dB + 1
2f ′′(B) (dB)2 + · · · ,
(18.4.1)
where B(t) denotes Brownian motion. Integrating Equation 18.4.1 from s to t, we ﬁnd that
Z t
s
df(B) = f[B(t)] −f[B(s)] =
Z t
s
f ′(B) dB + 1
2
Z t
s
f ′′(B) dx + · · · ,
(18.4.2)
because [dB(x)]2 = dx. The ﬁrst integral on the right side of Equation 18.4.2 is an Itˆo’s
stochastic integral while the second one can be interpreted as the Riemann integral of f ′′(B).
Therefore, Itˆo’s lemma or formula is
f[B(t)] −f[B(s)] =
Z t
s
f ′(B) dB + 1
2
Z t
s
f ′′(B) dx
(18.4.3)

Itˆo’s Stochastic Calculus
921
Table 18.3.1: A Table of Itˆo Stochastic Integrals with t > 0 and b > a > 0
1.
Z b
a
dB(t) = B(b) −B(a)
2.
Z t
0
B(η) dB(η) = 1
2[B2(t) −t]
3.
Z t
0
[B2(η) −η] dB(η) = 1
3B2(t) −tB(t)
4.
Z t
0
η dB(η) = tB(t) −
Z t
0
B(η) dη
5.
Z t
0
B2(η) dB(η) = 1
3B3(t) −
Z t
0
B(η) dη
6.
Z t
0
eλ2η/2 cos[λB(η)] dB(η) = 1
λeλ2t/2 sin[λB(t)]
7.
Z t
0
eλ2η/2 sin[λB(η)] dB(η) = 1
λ
n
1 −eλ2t/2 cos[λB(t)]
o
8.
Z t
0
exp

−1
2λ2η ± λB(η)

dB(η) = ± 1
λ

exp

−1
2λ2t ± λB(t)

−1
	
9.
Z b
a
B(η) exp
B2(η)
2η
 dB(η)
η3/2
= b−1/2 exp
B2(b)
2b

−a−1/2 exp
B2(a)
2a

10.
Z b
a
f(η) dB(η) = f(t)B(t)

b
a
−
Z b
a
f ′(η)B(η) dη
11.
Z b
a
g′[B(η)] dB(η) = g[B(t)]

b
a
−1
2
Z b
a
g′′[B(η)] dη

922
Advanced Engineering Mathematics with MATLAB
for t > s.
• Example 18.4.1
Consider the case when f(t) = t2 and s = 0. Then, Itˆo’s formula yields
B2(t) −B2(0) = 2
Z t
0
B(x) dB(x) −
Z t
0
dx.
(18.4.4)
Evaluating the second integral and noting that B(0) = 0, we again obtain Equation 18.3.12,
that
Z t
0
B(x) dB(x) = 1
2[B2(t) −t].
(18.4.5)
⊓⊔
• Example 18.4.2
Consider the case when f(t) = eat and s = 0. Then, Itˆo’s formula yields
eaB(t) −1 = a
Z t
0
eaB(x) dB(x) + a2
2
Z t
0
eaB(x) dx.
(18.4.6)
Computing the expectation of both sides,
E
h
eaB(t)i
−1 = a2
2
Z t
0
E
h
eaB(x)i
dx.
(18.4.7)
Solving this integral equation, we ﬁnd that E[eaB(t)] = ea2t/2, a result that we found earlier
in Problem 2, Section 18.2.
⊓⊔
• Example 18.4.3
If f(t) = sin(λt), λ > 0, then Itˆo’s formula gives
sin[λB(t)] = λ
Z t
0
cos[λB(η)] dB(η) −1
2λ2
Z t
0
sin[λB(η)] dη.
(18.4.8)
Taking the expectation of both sides of Equation 18.4.8, we ﬁnd that
E{sin[λB(t)]} = −1
2λ2
Z t
0
E{sin[λB(η)]} dη.
(18.4.9)
Setting g(t) = E{sin[λB(t)]}, then
g(t) = −1
2λ2
Z t
0
g(η) dη.
(18.4.10)
The solution to this integral equation is g(t) = 0. Therefore, E{sin[λB(t)]} = 0.
⊓⊔

Itˆo’s Stochastic Calculus
923
Educated at the Imperial University of Tokyo, Kiyoshi Itˆo (1915–2008) applied the techniques of
diﬀerential and integral to stochastic processes. Much of Itˆo’s original work from 1938 to 1945 was
done while he worked for the Japanese National Statistical Bureau. After receiving his doctorate,
Itˆo became a professor at the University of Kyoto from 1952 to 1979. (Author: Konrad Jacobs,
Source: Archives of the Mathematisches Forschungsinstitut Oberwolfach.)
The second version of Itˆo’s lemma begins with the second-order Taylor expansion of
the function f(t, x):
f[t + dt, B(t + dt)] −f[t, B(t)] = ft[t, B(t)] dt + fx[t, B(t)] dB(t)
+ 1
2

ftt[t, B(t)] (dt)2 + fxt[t, B(t)] dt dB(t)
(18.4.11)
+ fxx[t, B(t)] [dB(t)]2	
+ · · · .
Here we assume that f[t, B(t)] has continuous partial derivatives of at least second order.
Neglecting higher-order terms in Equation 18.4.11, which include the terms with factors
such as (dt)2 and dt dB(t) but not [dB(t)]2 because [dB(t)]2 = dt, our second version of
Itˆo’s lemma is
f[t, B(t)] −f[s, B(s)] =
Z t
s

ft[η, B(η)] + 1
2fxx[η, B(η)]
	
dη +
Z t
s
fx[η, B(η)] dB(η)
(18.4.12)
if t > s.

924
Advanced Engineering Mathematics with MATLAB
• Example 18.4.4
Consider the function f(t, x) = ex−t/2. Then,
ft(t, x) = −1
2ex−t/2,
fx(t, x) = ex−t/2,
and
fxx(t, x) = ex−t/2.
(18.4.13)
Therefore, from Itˆo’s lemma, we have that
eB(t)−t/2 −eB(s)−s/2 =
Z t
s
e−η/2eB(η) dB(η).
(18.4.14)
⊓⊔
• Example 18.4.5: Integration by parts
Consider the case when F(t, x) = f(t)g(x). The Itˆo formula gives
d[f(t)g(x)] =

f ′(t)g[B(t)] + 1
2f(t)g′′[B(t)]
	
dt + f(t)g′[B(t)] dB(t).
(18.4.15)
Integrating both sides of Equation 18.4.15, we ﬁnd that
Z b
a
f(t)g′[B(t)] dB(t) = f(t)g[B(t)]

b
a
−
Z b
a
f ′(t)g[B(t)] dt −1
2
Z b
a
f(t)g′′[B(t)] dt, (18.4.16)
which is the stochastic version of integration by parts.
For example, let us choose f(t) = eαt and g(x) = sin(x). Equation 18.4.16 yields
Z t
0
eαη cos[B(η)] dB(η) = eαη sin[B(η)]

t
0
−α
Z t
0
eαη sin[B(η)] dη + 1
2
Z t
0
eαη sin[B(η)] dη
(18.4.17)
= eαt sin[B(t)] −
 α −1
2
 Z t
0
eαη sin[B(η)] dη.
(18.4.18)
In the special case of α = 1
2, Equation 18.4.18 simpliﬁes to
Z t
0
eαη cos[B(η)] dB(η) = et/2 sin[B(t)].
(18.4.19)
⊓⊔
An important extension of Itˆo’s lemma involves the function f[t, X(t)] where X(t) is no
longer simply Brownian motion but is given by the ﬁrst-order stochastic diﬀerential equation
dX(t) = cX(t) dt + σX(t) dB(t),
(18.4.20)
where c and σ are real. The second-order Taylor expansion of the function f[t, X(t)] becomes
f[t + dt,X(t + dt)] −f[t, X(t)] = ft[t, X(t)] dt + fx[t, X(t)] dX(t)
(18.4.21)
+ 1
2

ftt[t, X(t)] (dt)2 + fxt[t, X(t)] dt dX(t) + fxx[t, X(t)] [dX(t)]2	
+ · · · .

Itˆo’s Stochastic Calculus
925
Next, we substitute for dX(t) using Equation 18.4.20, neglect terms involving (dt)2 and
dt dB(t), and substitute [dB(t)]2 = dt. Consequently,
df = f[t + dt, X(t + dt)] −f[t, X(t)]
(18.4.22)
= σX(t)fx[t, X(t)] dB(t) +

ft[t, X(t)] + cX(t)fx[t, X(t)] + 1
2σ2X2(t)fxx[t, X(t)]

dt.
(18.4.23)
The present extension of Itˆo’s lemma reads
f[t, X(t)] −f[s, X(s)] =
Z t
s

ft[η, X(η)] + cX(η)fx[η, X(η)] + 1
2σ2X2(η)fxx[η, X(η)]

dη
+
Z t
s
σX(η)fx[η, X(η)] dB(η)
(18.4.24)
=
Z t
s

ft[η, X(η)] + 1
2σ2X2(η)fxx[η, X(η)]

dη
+
Z t
s
fx[η, X(η)] dX(η),
(18.4.25)
where
dX(η) = cX(η) dη + σX(η) dB(η)
(18.4.26)
and t > s.
We can ﬁnally generalize Itˆo’s formula to the case of several Itˆo processes with respect
to the same Brownian motion. For example, let X(t) and Y (t) denote two Itˆo processes
governed by
dX(t) = A(1,1)(t) dt + A(2,1)(t) dB(t),
(18.4.27)
and
dY (t) = A(1,2)(t) dt + A(2,2)(t) dB(t).
(18.4.28)
For stochastic process f[t, X(t), Y (t)], the Taylor expansion is
df[t, X(t),Y (t)] = ft[t, X(t), Y (t)] dt + fx[t, X(t), Y (t)] dX(t)
+ fy[t, X(t), Y (t)] dY (t)
(18.4.29)
+ 1
2fxx[t, X(t), Y (t)]A(2,1)(t)A(2,1)(t) dt + 1
2fxy[t, X(t), Y (t)]A(2,1)(t)A(2,2)(t) dt
+ 1
2fyx]t, X(t), Y (t)]A(2,2)(t)A(2,1)(t) dt + 1
2fyy[t, X(t), Y (t)]A(2,2)(t)A(2,2)(t) dt.
• Example 18.4.6: Product rule
Consider the special case f(t, x, y) = xy. Then ft = 0, fx = y, fy = x, fxx = fyy = 0,
and fxy = fyx = 1. In this case, Equation 18.4.29 simpliﬁes to
d[X(t)Y (t)] = Y (t) dX(t) + X(t) dY (t) + A(2,1)[t, X(t), Y (t)]A(2,2)[t, X(t), Y (t)] dt.
(18.4.30)
A very important case occurs when A(2,1)[t, X(t), Y (t)] = 0 and X(t) = g(t) is purely
deterministic. In this case,
d[g(t)Y (t)] = Y (t) dg(t) + g(t) dY (t).
(18.4.31)

926
Advanced Engineering Mathematics with MATLAB
This is exactly the product rule from calculus.
Problems
1. (a) Use Equation 18.4.3 and f(t) = tn to show that
Bn(t) = n
Z t
0
Bn−1(x) dB(x) + n(n −1)
2
Z t
0
Bn−2(x) dx.
(b) Show that
E[Bn(t)] = n(n −1)
2
Z t
0
E[Bn−2(x)] dx.
(c) Because E[B(t)] = 0 and E[B2(t)] = t, show that
E

B2k+1(t)

= 0,
and
E

B2k(t)

= (2k)!
2kk! tk.
2. Let f(t, x) = x3/3 −tx and use Itˆo’s formula to show that
Z t
0
[B2(η) −η] dB(η) = 1
3B3(t) −t B(t).
3. If f(x) is any continuously diﬀerentiable function, use Equation 18.4.29 to show that
Z t
0
f(η) dB(η) = f(t)B(t) −
Z t
0
f ′(η)B(η) dη.
4. If f(t) = et, use the previous problem to show that
Z t
0
eη dB(η) = etB(t) −
Z t
0
eηB(η) dη.
5. Let G(x) denote the antiderivative of g(x). Use Equation 18.4.3 to show that
Z b
a
g[B(t)] dB(t) = G[B(t)]

b
a
−1
2
Z b
a
g′[B(t)] dt.
6. (a) If g(x) = xex, use Problem 5 to show that
Z t
0
B(η)eB(η) dB(η) = [B(t) −1]eB(t) + 1 −1
2
Z t
0
[B(η) + 1]eB(η) dη.

Itˆo’s Stochastic Calculus
927
(b) Use Equation 18.3.18 to show that
E
h
B(t)eB(t)i
= E
h
eB(t)i
−1 + 1
2
Z t
0
n
E
h
B(η)eB(η)i
+ E
h
eB(η)io
dη
= et/2 −1 + 1
2
Z t
0
n
eη/2 + E
h
B(η)eB(η)io
dη.
(c) Setting g(t) = E

B(t)eB(t)
, use Laplace transforms to show that
E
h
B(t)eB(t)i
= tet/2.
7. (a) If g(x) = 1/(1 + x2), use Problem 5 to show that
Z t
0
dB(η)
1 + B2(η) = arctan[B(t)] +
Z t
0
B(η)
[1 + B2(η)]2 dη.
(b) Use Equation 18.3.18 to show that
Z t
0
E

B(η)
[1 + B2(η)]2

dη = −E {arctan[B(t)]} .
(c) Because
−3
√
3
16
≤
x
(1 + x2)2 ≤3
√
3
16 ,
or
−3
√
3
16 t ≤
Z t
0
B(η)
[1 + B2(η)]2 dη ≤3
√
3
16 t,
show that
−3
√
3
16 t ≤E {arctan[B(t)]} ≤3
√
3
16 t.
8. If g(x) = x/(1 + x2), use Problem 5 to show that
Z t
0
B(η)
1 + B2(η) dB(η) = 1
2 log[1 + B2(t)] −1
2
Z t
0
1 −B2(η)
[1 + B2(η)]2 dη.
9. Use integration by parts with f(t) = eβt and g(x) = −cos(x) to show that
Z t
0
eβη sin[B(η)] dB(η) = 1 −eβt cos[B(t)] +
 β −1
2
 Z t
0
eβη cos[B(η)] dη.
Then, take β = 1
2 and show that
Z t
0
eη/2 sin[B(η)] dB(η) = 1 −et/2 cos[B(t)].

928
Advanced Engineering Mathematics with MATLAB
10. Redo Example 18.4.3 and show that E{cos[λB(t)]} = e−λ2t/2, λ > 0.
11. Use trigonometric double angle formulas to show that
(a)
E{sin[t + λB(t)]} = e−λ2t/2 sin(t),
and
(b)
E{cos[t + λB(t)]} = e−λ2t/2 cos(t),
when λ > 0.
12. Following Example 18.4.4 with f(t, x) = ±λ exp
 ±λx −λ2t/2

, λ > 0, show that
Z t
0
exp

±λB(η) −λ2η
2

dB(η) = ± 1
λ

exp

±λB(t) −λ2t
2

−1

.
13. Following Example 18.4.4 with f(t, x) = exp(λ2t/2) sin(λx), λ > 0, show that
Z t
0
exp
λ2η
2

cos[λB(η)] dB(η) = 1
λ exp
λ2t
2

sin[λB(t)].
14. Following Example 18.4.4 with f(t, x) = −exp(λ2t/2) cos(λx), λ > 0, show that
Z t
0
exp
λ2η
2

sin[λB(η)] dB(η) = 1
λ

1 −exp
λ2t
2

cos[λB(t)]

.
15. Following Example 18.4.4 with f(t, x) = t−1/2 exp[x2/(2t)], show that
Z b
a
B(t) exp
B2(t)
2t
 dB(t)
t3/2
= b−1/2 exp
B2(b)
2b

−a−1/2 exp
B2(a)
2a

.
16. The average of geometric Brownian motion on [0, t] is deﬁned by
G(t) = 1
t
Z t
0
eB(η) dη.
Use the product rule to ﬁnd dG(t). Hint: Take the time derivative of tG(t) =
R t
0 eB(η) dη.
18.5: STOCHASTIC DIFFERENTIAL EQUATIONS
We have reached the point where we can examine stochastic diﬀerential equations. Of
all the possible stochastic diﬀerential equations, we will focus on Langevin’s equation11 - a
11 Langevin, P., 1908: Sur la th´eorie du mouvement brownien. C. R. Acad. Sci. Paris, 146, 530–530.
English translation: Langevin, P., 1997: On the theory of Brownian motion. Am. J. Phys., 65, 1079–1081.

Itˆo’s Stochastic Calculus
929
model of the velocity of Brownian particles. We will employ this model in a manner similar
to that played by simple harmonic motion in the study of ordinary diﬀerential equations.
It illustrates many of the aspects of stochastic diﬀerential equations without being overly
complicated.
• Example 18.5.1
Before we consider the general stochastic diﬀerential equation, consider the following
cases where we can make clever use of the product rule. For example, let us solve
dX(t) = [t + B2(t)] dt + 2tB(t) dB(t),
X(0) = X0.
(18.5.1)
In the present case, we can ﬁnd the solution by noting that
dX(t) = B2(t) dt + t[2B(t) dB(t) + dt] = B2(t) dt + t d[B2(t)] = d[tB2(t)].
(18.5.2)
Integrating both sides of Equation 18.5.2, we ﬁnd that the solution to Equation 18.5.1 is
X(t) = tB2(t) + X0.
(18.5.3)
Similarly, let us solve the stochastic diﬀerential equation
dX(t) = b −X(t)
1 −t
dt + dB(t),
0 ≤t < 1,
(18.5.4)
with X(0) = X0.
We begin by writing Equation 18.5.4 as
d[b −X(t)]
1 −t
+ b −X(t)
(1 −t)2 dt = −dB(t)
1 −t .
(18.5.5)
Running the product rule backwards,
d
b −X(t)
1 −t

= −dB(t)
1 −t .
(18.5.6)
Integrating both sides of Equation 18.5.6 from 0 to t, we ﬁnd that
b −X(t)
1 −t
= b −X(0) −
Z t
0
dB(η)
1 −η .
(18.5.7)
Solving for X(t), we obtain the ﬁnal result that
X(t) = b −[b −X(0)](1 −t) + (1 −t)
Z t
0
dB(η)
1 −η .
(18.5.8)
In the present case we cannot simplify the integral in Equation 18.5.8 and must apply
numerical quadrature if we wish to have numerical values.
⊓⊔
In the introduction we showed that the solution to Langevin’s equation:
dX(t) = cX(t) dt + σ dB(t),
X(0) = X0,
(18.5.9)

930
Advanced Engineering Mathematics with MATLAB
is
X(t) = X0 + c
Z t
0
X(η) dη + σ
Z t
0
dB(η).
(18.5.10)
An obvious diﬃculty in understanding this solution is the presence of X(s) in the ﬁrst
integral on the right side of Equation 18.5.21.
Let us approach its solution by considering the function f(t, x) = e−ctx. Then, by Itˆo’s
lemma, Equation 18.4.16,
f[t, X(t)] −X(0) =
Z t
0

ft[η, X(η)] + cX(η)fx[η, X(η)] + 1
2σ2fxx[η, X(η)]
	
dη
+
Z t
0
σfx[η, X(η)] dB(η),
(18.5.11)
because f[0, X(0)] = X(0). Direct substitution of f(t, x) into Equation 18.5.11 yields
e−ctX(t) −X0 = σ
Z t
0
e−cη dB(η).
(18.5.12)
Finally, solving for X(t), we obtain
X(t) = X(0)ect + σect
Z t
0
e−cη dB(η),
(18.5.13)
an explicit expression for X(t). For the special case when X0 is constant, X(t) is known as
an Ornstein-Uhlenbeck process.12
An alternative derivation begins by multiplying Equation 18.5.9 by the integrating
factor e−ct so that the equation now reads
e−ct dX(t) −ce−ctX(t) dt = σe−ct dB(t).
(18.5.14)
Running the product rule, Equation 18.4.23, backwards, we have that
d

e−ctX(t)

= σe−ct dB(t).
(18.5.15)
Integrating both sides of Equation 18.5.15, we obtain Equation 18.5.12.
• Example 18.5.2: Exact stochastic diﬀerential equation
Consider the stochastic diﬀerential equation
X(t) = X(0) + c
Z t
0
X(s) ds + σ
Z t
0
X(s) dB(s),
(18.5.16)
with c, σ > 0.
If X(t) = f[t, B(t)], then by Itˆo’s lemma, Equation 18.4.9,
X(t) = X(0) +
Z t
0

ft[s, B(s)] + 1
2fxx[s, B(s)]
	
ds +
Z t
0
fx[s, B(s)] dB(s).
(18.5.17)
12 Uhlenbeck and Ornstein, op. cit.

Itˆo’s Stochastic Calculus
931
time
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
X(t)
0.5
1
1.5
2
2.5
3
3.5
Figure 18.5.1: Ten realizations (sample paths) of geometric Brownian motion when c = 0.1, σ = 0.5, and
X(0) = 1. The heavy line is the mean of X(t).
Comparing Equation 18.5.16 and Equation 18.5.17, we ﬁnd that
cf(t, x) = ft(t, x) + 1
2fxx(t, x),
(18.5.18)
and
σf(t, x) = fx(t, x).
(18.5.19)
From Equation 18.5.19,
fxx(t, x) = σfx(t, x) = σ2f(t, x).
(18.5.20)
Therefore, Equation 18.5.18 can be replaced by
 c −1
2σ2
f(t, x) = ft(t, x).
(18.5.21)
Equation 18.5.19 and Equation 18.5.21 can be solved using separation of variables, which
yields
f(t, x) = f(0, 0) exp
 c −1
2σ2
t + σx

,
(18.5.22)
or
X(t) = f[t, B(t)] = X(0) exp
 c −1
2σ2
t + σB(t)

.
(18.5.23)
Thus, a stochastic diﬀerential equation can sometimes be solved as the solution of a deter-
ministic partial diﬀerential equation. In the present case, this solution is called geometric
Brownian motion. For its solution numerically, see Example 18.6.1. See Figure 18.5.1.
⊓⊔
• Example 18.5.3: Homogeneous linear equation
Consider the homogeneous linear stochastic diﬀerential equation
dX(t) = c1(t)X(t) dt + σ1(t)X(t) dB(t).
(18.5.24)
Let us introduce f(t, x) = ln(x). Then by Itˆo’s lemma, Equation 18.4.21,
df = d[ln(X)] =

c1(t) −1
2σ2
1(t)

dt + σ1(t) dB(t),
(18.5.25)

932
Advanced Engineering Mathematics with MATLAB
because ft = 0, fx = 1/x and fxx = −1/x2. Integrating both sides of Equation 18.5.25 and
exponentiating the resulting expression, we obtain
X(t) = X(0) exp
Z t
0

c1(η) −1
2σ2
1(η)

dη +
Z t
0
σ1(η) dB(η)

.
(18.5.26)
⊓⊔
• Example 18.5.4: General case
Consider the homogeneous linear stochastic diﬀerential equation
dX(t) = [c1(t)X(t) + c2(t)] dt + [σ1(t)X(t) + σ2(t)] dB(t).
(18.5.27)
Our analysis begins by considering the homogeneous linear stochastic diﬀerential equa-
tion
dY (t) = c1(t)Y (t) dt + σ1(t)Y (t) dB(t),
Y (0) = 1.
(18.5.28)
From the previous example,
Y (t) = exp
Z t
0

c1(η) −1
2σ2
1(η)

dη +
Z t
0
σ1(η) dB(η)

.
(18.5.29)
Next, let us introduce two random variables, X1 = 1/Y and X2 = X. Using Itˆo lemma
f(t, x) = 1/x, then
dX1 = df(t, Y ) = d
 1
Y

=

σ2
1(t) −c1(t)
 dt
Y −σ1(t)dB(t)
Y
(18.5.30)
=

σ2
1(t) −c1(t)

X1(t) dt −σ1(t)X1(t) dB(t),
(18.5.31)
since ft = 0, fx = −1/x2 and fxx = 2/x3.
Using Equation 18.4.30, where X1 is governed by Equation 18.5.31 and X2 is governed
by 18.5.27 because X2 = X,
d(X1X2) = [c2(t) −σ1(t)σ2(t)] X1(t) dt + σ2(t)X1(t) dB(t).
(18.5.32)
Upon integrating both sides of Equation 18.5.32, we have
X1X2 −X1(0) =
Z t
0
[c2(η) −σ1(η)σ2(η)]
dη
Y (η) +
Z t
0
σ2(η) dB(η)
Y (η) .
(18.5.33)
Consequently, our ﬁnal result is
X(t) = Y (t)

X(0) +
Z t
0
[c2(η) −σ1(η)σ2(η)]
dη
Y (η) +
Z t
0
σ2(η) dB(η)
Y (η)

,
(18.5.34)
where Y (t) is given by Equation 18.5.29.
⊓⊔

Itˆo’s Stochastic Calculus
933
• Example 18.5.5: Stochastic Verhulst equation
The stochastic Verhulst equation is
dX(t) = aX(t)[M −X(t)] dt + bX(t) dB(t),
X(0) = X0.
(18.5.35)
We begin its solution by introducing Φ(t) = 1/X(t). Then by Itˆo’s lemma, Equation
18.4.21 with f(x) = 1/x,
dΦ(t) = −Φ(t)[(aM −b2) dt + b dB(t)] + a dt,
Φ(0) = 1/X0.
(18.5.36)
To solve Equation 18.5.36, we use the results from Example 18.5.4 with c1(t) = b2−aM,
c2(t) = a, σ1(t) = −b, and σ2(t) = 0. Denoting ǫ(t) = (aM −b2/2)t + bB(t), we can write
Equation 18.5.34 as
Φ(t)eξ(t) −Φ(0) = a
Z t
0
eξ(η) dη,
(18.5.37)
or
eξ(t)
X(t) −1
X0
= a
Z t
0
eξ(η) dη.
(18.5.38)
Solving for X(t), we obtain the ﬁnal result that
X(t) =
X0 exp[ξ(t)]
1 + aX0
R t
0 exp[ξ(η)] dη
.
(18.5.39)
Problems
1. Solve the stochastic diﬀerential equation
dX(t) = 1
2et/2B(t) dt + et/2 dB(t),
X(0) = X0,
by running the product rule backwards.
2. Solve the stochastic diﬀerential equation
dX(t) = e2t[1 + 2B2(t)] dt + 2e2tB(t) dB(t),
X(0) = X0,
by running the product rule backwards. Hint: Rewrite the diﬀerential equation dX(t) =
e2t[2B(t) dB(t) + dt] + (2e2t dt)B2(t).
3. Solve the stochastic diﬀerential equation
dX(t) = [1 + B(t)] dt + [t + 2B(t)] dB(t),
X(0) = X0,
by running the product rule backwards. Hint: Rewrite the diﬀerential equation dX(t) =
2B(t) dB(t) + dt + B(t) dt + t dB(t).
4. Solve the stochastic diﬀerential equation
dX(t) = [3t2 + B(t)] dt + t dB(t),
X(0) = X0,

934
Advanced Engineering Mathematics with MATLAB
by running the product rule backwards. Hint: Rewrite the diﬀerential equation dX(t) =
3t2 dt + [B(t) dt + t dB(t)].
5. Solve the stochastic diﬀerential equation
dX(t) = B2(t) dt + 2tB(t) dB(t),
X(0) = X0,
by running the product rule backwards. Hint: Rewrite the diﬀerential equation dX(t) =
t[2B(t) dB(t) + dt] + B2(t) dt −t dt.
6. Find the integrating factor and solution to the stochastic diﬀerential equation
dX(t) = [1 + 2X(t)] dt + e2t dB(t),
X(0) = X0,
where B(t) is Brownian motion.
7. Find the integrating factor and solution to the stochastic diﬀerential equation
dQ(t) + Q(t)
RC dt = V (t)
R
dt + α(t)
R
dB(t),
Q(0) = Q0,
where R and C are real, positive constants, and B(t) is Brownian motion.
8. Find the integrating factor and solution to the stochastic diﬀerential equation13
dX(t) = 2tX(t) dt + e−t dt + dB(t),
t ∈[0, 1],
with X(0) = X0, and B(t) is Brownian motion.
9. Find the integration factor and solution to the stochastic diﬀerential equation
dX(t) = [4X(t) −1] dt + 2 dB(t),
X(0) = X0,
where B(t) is Brownian motion.
10. Find the integration factor and solution to the stochastic diﬀerential equation
dX(t) = [2 −X(t)] dt + e−tB(t) dB(t),
X(0) = X0,
where B(t) is Brownian motion.
11. Find the integration factor and solution to the stochastic diﬀerential equation
dX(t) = [1 + X(t)] dt + etB(t) dB(t),
X(0) = X0,
where B(t) is Brownian motion.
13 Khodabin, M., and M. Rostami, 2015: Mean square numerical solution of stochastic diﬀerential equa-
tions by fourth order Runge-Kutta method and its applications in the electric circuits with noise. Adv.
Diﬀ. Eq., 2015, 62.

Itˆo’s Stochastic Calculus
935
12. Find the integration factor and solution to the stochastic diﬀerential equation
dX(t) =
 1
2X(t) + 1

dt + et cos[B(t)] dB(t),
X(0) = X0,
where B(t) is Brownian motion.
13. Find the integration factor and solution to the stochastic diﬀerential equation
dX(t) =

t + 1
2X(t)

dt + et sin[B(t)] dB(t),
X(0) = X0,
where B(t) is Brownian motion.
14. Following Example 18.5.2, solve the exact stochastic diﬀerential equation:
dX(t) = et 
1 + B2(t)

dt +

1 + 2etB(t)

dB(t),
X(0) = X0.
Step 1: Show that ft + 1
2fxx = et(1 + x2), and fx = 1 + 2etx.
Step 2: Show that f(t, x) = x + etx2 + g(t).
Step 3: Show that g(t) = X0 and X(t) = B(t) + etB2(t) + X0.
15. Following Example 18.5.2, solve the exact stochastic diﬀerential equation:
dX(t) =

2tB2(t) + 3t2 [1 + B(t)]
	
dt +

1 + 3t2B2(t)

dB,
X(0) = X0.
Step 1: Show that ft + 1
2fxx = 2tx3 + 3t2(1 + x), and fx = 3t2x2 + 1.
Step 2: Show that f(t, x) = t2x3 + x + g(t).
Step 3: Show that g′(t) = 3t2.
Step 4: Show that X(t) = t2[B3(t) + t] + B(t) + X0.
Using Equation 18.5.26, solve the following stochastic diﬀerential equations:
16. dX(t) = t2X(t) dt + tX(t) dB(t),
X(0) = X0
17. dX(t) = cos(t)X(t) dt + sin(t)X(t) dB(t),
X(0) = X0
18. dX(t) = ln(t + 1)X(t) dt +
p
ln(t + 1) X(t) dB(t),
X(0) = X0
19. dX(t) = ln(t + 1)X(t) dt + tX(t) dB(t),
X(0) = X0
20. Following Example 18.5.5, solve the stochastic diﬀerential equation
dX(t) = [aXn(t) + bX(t)] dt + cX(t) dB(t),
X(0) = X0,
where n > 1.
Step 1: Setting Φ(t) = X1−n(t), use Itˆo’s lemma Equation 18.4.21 with f(x) = 1/xn−1 to
show that
dΦ(t) = (1 −n)Φ(t)
 b −1
2nc2
dt + c dB(t)

+ (1 −n)a dt.

936
Advanced Engineering Mathematics with MATLAB
Step 2: Setting c1(t) = (1 −n)b −n(1 −n)c2/2, c2(t) = (1 −n)a, σ1(t) = (1 −n)c, and
σ2(t) = 0, show that
exp[(n −1)ξ(t)]
Xn−1(t)
−
1
Xn−1
0
= (1 −n)a
Z t
0
exp[(n −1)ξ(η)] dη,
or
exp[(n −1)ξ(t)]
Xn−1(t)
=
1
Xn−1
0
+ (1 −n)a
Z t
0
exp[(n −1)ξ(η)] dη,
where ξ(t) = (b −c2/2)t + cB(t).
21. Following Example 18.5.5, solve the stochastic Ginzburg-Landau equation:
dX(t) =
h
aecX(t) + b
i
dt + σ dB(t),
X(0) = X0.
Step 1: Setting Φ(t) = exp[−cX(t)], use Itˆo’s lemma Equation 18.4.21 with f(x) = e−cx to
show that
dΦ(t) = −
 bc −1
2σ2c2
Φ(t) dt −σcΦ(t) dB(t) −ac dt.
Step 2: Setting c1(t) = σ2c2/2 −bc, c2(t) = −ac, σ1(t) = −σc, and σ2(t) = 0, show that
X(t) = X0 + bt + σB(t) −1
c ln

1 −ac
Z t
0
exp [cX0 + bcξ + σcB(ξ)] dξ

.
22. Following Example 18.5.5, solve the stochastic diﬀerential equation:
dX(t) =

[1 + X(t)][1 + X2(t)]

dt + [1 + X2(t)] dB(t),
X(0) = X0.
Step 1: Setting Φ(t) = tan−1[X(t)], use Itˆo’s lemma Equation 18.4.21 with f(x) = tan−1(x)
to show that dΦ(t) = dt + dB(t).
Step 2: Solving the stochastic diﬀerential equation in Step 1, show that
X(t) = tan[tan−1(X0) + t + B(t)].
18.6: NUMERICAL SOLUTION OF STOCHASTIC DIFFERENTIAL EQUATIONS
In this section we construct numerical schemes for integrating the stochastic diﬀerential
equation
dX(t) = a[X(t), t] dt + b[X(t), t] dB(t)
(18.6.1)
on t0 ≤t ≤T with the initial-value X(t0) = X0.
Our derivation begins by introducing the grid t0 < t1 < t2 < · · · < tn < · · · < tN = T.
For simplicity we assume that all of the time increments are the same and equal to 0 <
∆t < 1 although our results can be easily generalized when this is not true. Now
Xn+1 = Xn +
Z tn+1
tn
a[X(η), η] dη +
Z tn+1
tn
b[X(η), η] dB(η).
(18.6.2)

Itˆo’s Stochastic Calculus
937
The crudest approximation to the integrals in Equation 18.6.2 is
Z tn+1
tn
a[X(η), η] dη ≈a[X(tn), tn]∆tn,
(18.6.3)
and
Z tn+1
tn
b[X(η), η] dB(η) ≈b[X(tn), tn]∆Bn.
(18.6.4)
Substituting these approximations into Equation 18.6.2 yields the Euler-Marugama ap-
proximation.14 For the Itˆo process X(t) = {X(t), t0 ≤t ≤T}:
Xn+1 = Xn + a(tn, Xn) (tn+1 −tn) + b(tn, Xn)
 Btn+1 −Btn

(18.6.5)
for n = 0, 1, 2, . . . , N −1 with the initial value X0.
When b = 0, the stochastic iterative scheme reduces to the conventional Euler scheme
for ordinary diﬀerential equations. See Section 1.7. When b ̸= 0, we have an extra term
generated by the random increment ∆Bn = B(tn+1)−B(tn) where n = 0, 1, 2, . . . , N −1 for
Brownian motion (the Wiener process) B(t) = B(t), t ≥0. Because these increments are
independent Gaussian random variables, the mean equals E(∆Bn) = 0 while the variance
is E[(∆Bn)2] = ∆t. We can generate ∆Bn using the MATLAB function randn.
An important consideration in the use of any numerical scheme is the rate of conver-
gence. During the numerical simulation of a realization, at time t there will be a diﬀerence
between the exact solution X(t) and the numerical approximation Y (t). This diﬀerence
e(t) = X(t)−Y (t) will also be a random variable. A stochastic diﬀerential equation scheme
converges strongly with order m, if for any time t, E(|e(t)|) = O[(∆t)m] for suﬃciently small
time step ∆t. The strong order for the Euler-Marugama method can be proven to be 1
2.
To construct a strong order 1 approximation to Equation 18.6.1, we return to Equation
18.6.2. Using Equation 18.4.12, we have
Xn+1 −Xn =
Z tn+1
tn

a[Xn(η), η] +
Z η
tn
 aax + 1
2b2axx

dξ +
Z η
tn
bax dB(ξ)

dη
+
Z tn+1
tn

b[Xn(η), η] +
Z η
tn
 abx + 1
2b2bxx

dξ +
Z η
tn
bbx dB(ξ)

dη
(18.6.6)
= a[X(tn), tn]∆t + b[X(tn), tn)∆Bn + Rn,
(18.6.7)
where
Rn =
Z tn+1
tn
Z η
tn
bbx dB(ξ)

dB(η) + higher −/order terms.
(18.6.8)
Dropping the higher-order terms,
Rn ≈b[X(tn), tn]bx[X(tn), tn]
Z tn+1
tn
Z η
tn
dB(ξ)

dB(η).
(18.6.9)
Consider now the double integrals
(∆Bn)2 =
Z tn+1
tn
dB(η)
 Z tn+1
tn
dB(η)

=
Z tn+1
tn
Z tn+1
tn
dB(ξ)

dB(η).
(18.6.10)
14 Maruyama, G., 1955: Continuous Markov processes and stochastic equations. Rend. Circ. Math.
Palermo, Ser. 2,, 4, 48–90.

938
Advanced Engineering Mathematics with MATLAB
Now,
Z tn+1
tn
Z tn+1
tn
dB(ξ)

dB(η) =
Z tn+1
tn
Z η
tn
dB(ξ)

dB(η) +
Z tn+1
tn
Z tn+1
η
dB(ξ)

dB(η)
+
Z tn+1
tn
[dB(η)]2
(18.6.11)
= 2
Z tn+1
tn
Z η
tn
dB(ξ)

dB(η) +
Z tn+1
tn
[dB(η)]2
(18.6.12)
= 2
Z tn+1
tn
Z η
tn
dB(ξ)

dB(η) + ∆t,
(18.6.13)
because
Z tn+1
tn
[dB(η)]2 =
Z tn+1
tn
dη = ∆t.
(18.6.14)
Combining Equation 18.6.9, Equation 18.6.10, and Equation 18.6.13 yields
Rn ≈b[X(tn), tn]bx[X(tn), tn]

(∆Bn)2 −∆t

.
(18.6.15)
Finally, substituting Equation 18.6.15 into Equation 18.6.7 gives the ﬁnal result, the Milstein
method:15
Xn+1 = Xn + a(Xn, tn) ∆tn + b(Xn, tn) ∆Bn + 1
2b(Xn, tn)∂b(Xn, tn)
∂x

(∆Bn)2 −∆t

.
(18.6.16)
• Example 18.6.1
Consider the Itˆo process X(t) deﬁned by the linear stochastic diﬀerential equation
dX(t) = aX(t) dt + bX(t) dB(t),
(18.6.17)
for t ∈[0, T]. If this Itˆo process has the drift a(x, t) = ax and the diﬀusion coeﬃcient
b(x, t) = bx, the exact solution (see Equation 18.5.16) is
X(t) = X0 exp

a −b2
2

t + bB(t)

(18.6.18)
for t ∈[0, T]. Figure 18.6.1 compares the numerical solution of this stochastic diﬀerential
equation using the Euler-Marugama and Milstein method against the exact solution. Note
that each frame has a diﬀerent solution because the Brownian forcing changes with each
realization.
⊓⊔
Although a plot of various realizations can give an idea of how the stochastic processes
aﬀect the solution, two more useful parameters are the sample mean and standard deviation
at time tn:
X(tn) = 1
J
J
X
j=1
Xj(tn),
(18.6.19)
15 Milstein, G., 1974: Approximate integration of stochastic diﬀerential equations. Theory Prob. Applic.,
19, 557–562.

Itˆo’s Stochastic Calculus
939
0
0.25
0.5
0.75
1
X(t n),Yn
0
1
2
3
4
5
6
h = 0.2
0
0.25
0.5
0.75
1
0
5
10
15
20
25
30
h = 0.1
t
0
0.25
0.5
0.75
1
X(t n),Yn
0
2.5
5
7.5
10
12.5
15
h = 0.05
t
0
0.25
0.5
0.75
1
0
1
2
3
4
5
6
h = 0.02
Figure 18.6.1: The numerical solution of the stochastic diﬀerential equation, Equation 18.6.17, using the
Euler-Marugama (crosses) and the Milstein (circles) methods for various time steps h. The dashed line
gives the exact solution.
and
σ2(tn) =
1
J −1
J
X
j=1

Xj(tn) −X(tn)
2 ,
(18.6.20)
where J are the number of realizations and Xj(tn) is the value of the random variable at
time tn of the jth realization.
In many physical problems, “noise” is the origin of the stochastic process and we suspect
that we have a normal distribution N(µ, σ2) where µ and σ are the population mean and
standard deviation, respectively. Then, using the sample statistics, Equations 18.6.20 and
18.6.21, a two-sided conﬁdence interval can be determined as

X(tn) −τstudent
σ(tn)
√
J
, X(tn) + τstudent
σ(tn)
√
J

based on the student-τ distribution with J −1 degrees of freedom.
Project: RL Electrical Circuit with Noise
An important component of contemporary modelling is the mixture of deterministic
and stochastic aspects of a physical system. In this project you will see how this is done
using a simple electrical system.16
Consider a simple electrical circuit consisting of a resistor with resistance R and an
inductor with inductance L. If the circuit is driven by a voltage source v(t), the current
I(t) at a given time t is given by the ﬁrst-order ordinary diﬀerential equation
LdI
dt + RI = v(t),
I(0) = I0.
(1)
16 See Kol´aˇrov´a, E., 2005: Modeling RL electrical circuits by stochastic diﬀerential equations. Proc. Int.
Conf. Computers as Tool, Belgrade (Serbia and Montenegro), IEEE R8, 1236–1238.

940
Advanced Engineering Mathematics with MATLAB
Rt/L
0
0.5
1
1.5
2
2.5
3
3.5
4
I(t)
-2
-1
0
1
2
3
4
5
Figure 18.6.2: Eleven realizations as a function of the nondimensional time Rt/L of the numerical solution
of Equation (4) using the Euler-Marugama method when h = 0.02, α/L = 1, β/L = 0, I0 = 0, and v(t) = R.
The mean and 95% conﬁdence interval (here tstudent = 2.228) are given by the heavy solid and dashed
lines, respectively. Finally, the crosses (+) give the deterministic solution.
Step 1: Using classical methods, show that the deterministic solution to Equation (1) is
I(t) = I0e−Rt/L + 1
L
Z t
0
exp
R
L (τ −t)

v(τ) dτ.
(2)
There are two possible ways that randomness can enter this problem. First, the power
supply could introduce some randomness so that the right side of Equation (1) could read
v(t)+α dB2(t)/dt. Second, some physical process within the resistor could cause randomness
so that the resistance would now equal R + β dB1(t)/dt. Here B1(t) and B2(t) denote two
independent white noise processes and α, β are nonnegative constants. In this case the
governing diﬀerential equation would now read
dI
dt + 1
L

R + αdB1
dt

= 1
L

v(t) + β dB2
dt

,
I(0) = I0.
(3)
Converting Equation (3) into the standard form of a stochastic ordinary diﬀerential equa-
tion, we have that
dI = 1
L [v(t) −RI(t)] dt −α
LI(t) dB1(t) + β
L dB2(t),
I(0) = I0.
(4)
Step 2: Using MATLAB, create a script to numerically integrate Equation (4) for a given
set of α, β, I0 = 0, R, L, and v(t). Plot I(t) as a function of the nondimensional time Rt/L
for many realizations (say 20). See Figure 18.6.2.
Step 3: Although some idea of the eﬀect of randomness is achieved by plotting several
realizations, a better way would be to compute the mean and standard deviation at a given
time. On the plot from the previous step, plot the mean and standard deviation of your

Itˆo’s Stochastic Calculus
941
time
0
100
200
300
400
500
600
700
800
900
1000
E[x(t)]
-1.5
-1
-0.5
0
0.5
1
σ = 0
σ = 0.01
σ = 0.1
Figure 18.6.3: Plot of E[x(t)] versus time for the FitzHugh-Nagamo model for three values of σ. The
value of the parameters are a = 0.8, m = 1.2, and τ = 100. The Euler method was used with a time step
of 0.1.
solution as a function of nondimensional time. How does it compare to the deterministic
solution?
Project: Relaxation Oscillator with Brownian Motion Forcing
The FitzHugh-Nagamo17 model describes excitable systems such as a neuron. We will
modify it so that the forcing is due to Brown motion. The governing equations are
dx = −x(x2 −a2) dt −y dt + σ dB1(t),
and
dy = (x −my) dt/τ + σ dB2(t),
where a, m, σ, and τ are parameters.
Write a MATLAB script to numerically integrate this modiﬁed FitzHugh-Nagamo model
for various values of σ. Using many simulations, compute E[x(t)] as a function of time t.
See Figure 18.6.3. What is the eﬀect of the Brownian motion forcing?
Project: Stochastic Damped Harmonic Oscillator
The damped stochastic harmonic oscillator is governed by the stochastic diﬀerential
equations:
dv(t) = −γv(t) dt −k2x(t) dt −αx(t) dB(t),
and
dx(t) = v(t) dt,
(1)
where k, α and γ are real constants. This system of equations is of interest for two reasons:
(1) The system is forced by Brownian motion. (2) The noise is multiplicative rather than
additive because the forcing term is x(t) dB(t) rather than just dB(t).
17 FitzHugh, R., 1961:
Impulses and physiological states in theoretical models of nerve membrane.
Biophys. J., 1, 445-466; Nagumo, J., S. Arimoto, and S. Yoshizawa, 1962: An active pulse transmission
line simulating nerve axon. Proc. IRE, 50, 2061–2070.

942
Advanced Engineering Mathematics with MATLAB
time
0
5
10
15
20
25
30
E[x(t)]
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
Euler method
Heun method
leapfrog method
Figure 18.6.4: Plot of E[x(t)] versus time for the damped harmonic oscillator forced by Brownian motion.
The value of the parameters are k = 1, γ = 0.25, and alpha = ∆t = 0.1. Five thousand realization were
performed.
We could solve both equations numerically using Euler’s method.18 The purpose of
this project is to introduce you to the Heun method. In the Heun method we ﬁrst compute
an estimate of the solution x∗and v∗by taking an Euler-like time step:
x∗= xi + vi∆t,
and
v∗= vi −γvi∆t −k2xi∆t −αxi∆Bi,
(2)
where xi and vi denote the displacement and velocity at time ti = i∆t, ∆t is the time step,
and i = 0, 1, 2, . . .. With these estimates we compute the value for xi+1 and vi+1 using
xi+1 = xi+ 1
2(vi+v∗)∆t,
and
vi+1 = vi−1
2γ(vi+v∗)∆t−1
2k2(xi+x∗)∆t−αxi∆Bi.
(3)
Qiang and Habib19 developed a leapfrog algorithm to solve this problem. Because the
algorithm is rather complicated, the interested student is referred to their paper.
Write a MATLAB script to use the Euler and Huen methods to numerically integrate the
stochastic harmonic oscillator when 10α = 4γ = k = 1 and x(0) = v(0) = 0. Using many
simulations, compute E[x(t)] as a function of time t. See Figure 18.6.4. What happens to
the accuracy of the solution for larger values of ∆t?
Project: Mean First Passage Time
The stochastic diﬀerential equation
dX(t) = [X(t) −X3(t)] dt +
4
X2(t) + 1 dB(t)
describes the motion of a particle in a double-well potential V (x) = x4/4 −x2/2, subject
to a spacially dependent random forcing when the acceleration X′′(t) can be neglected.
18 For further details, see Greiner, A., W. Strittmatter, and J. Honerkamp, 1988: Numerical integration
of stochastic diﬀerential equations. J. Stat. Phys., 51, 95–108.
19 Qiang, J., and S. Habib, 2000: Second-order stochastic leapfrog algorithm for multiplicative noise
Brownian motion. Phys. Review, 62, 7430–7437.

Itˆo’s Stochastic Calculus
943
h1/2
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
mean time
0.7
0.8
0.9
1
1.1
1.2
1.3
Figure 18.6.5: The mean time that it takes a particle to travel from X(0) = −1 to X = 0 in the double-
well potential stated in the text. Sixty thousand realizations were used with a time step h. Two diﬀerential
numerical schemes were used: the Euler-Marugama (crosses) and the Milstein (circles) methods. The curves
are linear least-squares ﬁts through the results.
An important question is what is the average (mean) time that it takes a particle initially
located at a minimum X(0) = −1 to reach the local maximum X(t) = 0.
Write MATLAB code that computes X(t) as a function of time t.
Using this code
and creating N realizations, compute the length of time that it takes the particle to reach
X(t) = 0 in each realization. Then compute the mean from those times and plot the results
as a function
√
h, the square root of the time step. See Figure 18.6.5. We used
√
t rather
than h following the suggestions of Seeßelberg and Petruccione.20
Project: Bankruptcy of a Company
The stochastic diﬀerential equation21
dX(t) = [µX(t) −iD] dt + σX(t) dB(t),
0 < t < T,
with X(0) = X0, describes the evolution with time t of the wealth X(t) of a ﬁrm. Here µ
and σ denote the deterministic and stochastic evolution of the ﬁrm’s wealth, respectively,
X0 is the initial wealth of the ﬁrm, and iD gives the amount of payment to a ﬁnancier (bank)
who initially loaned the ﬁrm the amount D at the interested rate i. Write a MATLAB code
to simulate the wealth of a ﬁrm during its lifetime T given a known D, i and X0 with
µ = 1.001/year, and various values of σ.
During the simulation there is a chance that the ﬁrm goes bankrupt at time t = τ <
T. This occurs when the stochastic process hits the barrier X(τ) = 0. If n denotes the
number of times that bankruptcy occurs in N simulations, the probability of bankruptcy
is P[X(τ) = 0] = n/N.
Using your code for simulating a ﬁrm’s wealth, compute the
probability of bankruptcy as a function of interest rate for a small (D = 20, X0 = 100),
20 Seeßelberg, M., and F. Petruccione, 1993: An improved algorithm for the estimation of the mean ﬁrst
passage of ordinary stochastic diﬀerential equations. Comput. Phys. Commun., 74, 247–255.
21 See Cerqueti, R., and A. G. Quaranta, 2012:
The perspective of a bank in granting credit:
An
optimization model. Optim. Lett., 6, 867–882.

944
Advanced Engineering Mathematics with MATLAB
interest (%/yr)
0
1
2
3
4
5
6
7
8
9
10
probability of bankruptcy
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
σ = 1.5
σ = 2.0
σ = 2.5
Figure 18.6.6: The probability of bankruptcy over a three-year period as a function of interest rate of a
ﬁrm with initial wealth X0 = 500 and debt D = 100. Other parameters are h = 0.01 yr and µ = 1.001/year.
The units on σ is year−1/2. Five hundred thousand realizations were used to compute the probability.
medium (D = 100, X0 = 500), and large (D = 200, X0 = 1000) ﬁrm. See Figure 18.6.6.
How does the average value of τ vary with interest rate?
Further Readings
Kloeden, P. E., and E. Platen, 1992: Numerical Solution of Stochastic Diﬀerential Equa-
tions. Springer-Verlag, 632 pp. A solid book covering numerical schemes for solving stochas-
tic diﬀerential equations.
Mikosch, T., 1998: Elementary Stochastic Calculus with Finance in View. World Scientiﬁc,
212 pp. Very well-crafted book on stochastic calculus.

Answers
To the Odd-Numbered Problems
Section 1.1
1. ﬁrst-order, linear
3. ﬁrst-order, nonlinear
5. second-order, linear
7. third-order, nonlinear
9. second-order, nonlinear
11. ﬁrst-order, nonlinear
13. ﬁrst-order, nonlinear
15. second-order, nonlinear
Section 1.2
1. y(x) = −ln(C −x2/2)
3. y2(x) −ln2(x) = 2C
5. 2 + y2(x) = C(1 + x2)
7. y(x) = −ln(C −ex)
9. ay3(t) −b
ay3
0 −b
= e−3at
13. V (t) =
V0S e−t/(RC)
S + RV0

1 −e−t/(RC)
15. N(t) = N(0) exp

ln[K/N(0)]
 1 −e−bt	
17.
1
([A]0 −[B]0) ([A]0 −[C]0) ln

[A]0
[A]0 −[X]

+
1
([B]0 −[A]0) ([B]0 −[C]0) ln

[B]0
[B]0 −[X]

+
1
([C]0 −[A]0) ([C]0 −[B]0) ln

[C]0
[C]0 −[X]

= kt
Section 1.3
1. ln |y| −x/y = C
3. |x|(x2 + 3y2) = C
5. y = x (ln |x| + C)2 7. sin(y/x) −ln |x| = C

946
Advanced Engineering Mathematics with MATLAB
Section 1.4
1. xy2 −1
3x3 = C
3. xy2 −x + cos(y) = C
5. y/x + ln(y) = C
7. cos(xy) = C
9. x2y3 + x5y + y = C
11. xy ln(y) + ex −e−y = C
13. y −x + 1
2 sin(2x + 2y) = C
Section 1.5
1. y(x) = 1
2ex + Ce−x,
x ∈(−∞, ∞)
3. y(x) = ln(x)/x + Cx−1,
x ̸= 0
5. y(x) = 2x3 ln(x) + Cx3,
x ∈(−∞, ∞)
7. esin(2x)y(x) = C,
nπ + ϕ < 2x < (n + 1)π + ϕ, where ϕ is any real and n is any integer.
9. y(x) = 4
3 + 11
3 e−3x,
x ∈(−∞, ∞)
11. y(x) = (x + C) csc(x)
13. y(x) =
cosa(x) y(0)
[sec(x) + tan(x)]b +
c cosa(x)
[sec(x) + tan(x)]b
Z x
0
[sec(ξ) + tan(ξ)]b
cosa+1(ξ)
dξ
15. y(x) = 2ax −1
8a2
+
ω2e−2ax
8a2(a2 + ω2) −a sin(2ωx) −ω cos(2ωx)
8ω(a2 + ω2)
17. y2(x) = 2(x −x2/k)/(2 −k)
if
k ̸= 2;
y2(x) = x ln(1/x)
if
k = 2
19. [A](t) = [A]0e−k1t,
[B](t) = k1[A]0
k2 −k1

e−k1t −e−k2t
,
[C](t) = [A]0

1 + k1e−k2t −k2e−k1t
k2 −k1

21. y(x) = [Cx + x ln(x)]−1
23. y(x) =

Cx2 + 1
2x2 ln(x)
2
25. y(x) = [Cx −x ln(x)]1/2
Section 1.6
5. The equilibrium points are x = 0, 1
2, and 1. The equilibrium at x = 1
2 is unstable while
the equilibriums at x = 0 and 1 are stable.
7. The equilibrium point for this diﬀerential equation is x = 0, which is stable.
Section 1.7
1. x(t) = et + t + 1
3. x(t) = [1 −ln(t + 1)]−1
Section 2.0
1. y2(x) = A/x
3. y2(x) = Ax−4
5. y2(x) = A(x2 −x + 1)
7. y2(x) = A sin(x)/√x
9. y(x) = C2eC1x o
11. y(x) =
 1 + C2eC1x
/C1
13. y(x) = −ln |1 −x|
15. y(x) = C1 −2 ln(x2 + C2)

Answers to the Odd-Numbered Problems
947
Section 2.1
1. y(x) = C1e−x + C2e−5x
3. y(x) = C1ex + C2xex
5. y(x) = C1e2x cos(2x) + C2e2x sin(2x)
7. y(x) = C1e−10x + C2e4x
9. y(x) = e−4x [C1 cos(3x) + C2 sin(3x)]
11. y(x) = C1e−4x + C2xe−4x
13. y(x) = C1 + C2x + C3 cos(2x) + C4 sin(2x)
15. y(x) = C1e2x + C2e−x cos(
√
3 x) + C3e−x sin(
√
3 x)
17. y(t) = e−t/(2τ) 
A exp

t
√
1 −2Aτ/(2τ)

+ B exp

−t
√
1 −2Aτ/(2τ)
	
Section 2.2
1. x(t) = 2
√
26 sin(5t + 1.7682)
3. x(t) = 2 cos(πt −π/3)
5. x(t) = s0 cos(ωt)+ v0
ω sin(ωt) and v(t) = v0 cos(ωt)−ωs0 sin(ωt), where ω2 = Mg/(mL).
Section 2.3
1. x(t) = 4e−2t −2e−4t
3. x(t) = e−5t/2 
4 cos(6t) + 13
3 sin(6t)

5. The roots are equal when c = 4 when m = −2.
Section 2.4
1. y(x) = Ae−3x + Be−x + 1
3x −1
9
3. y(x) = e−x[A cos(x) + B sin(x)] + x2 −x + 2
5. y(x) = A + Be−2x + 1
2x2 + 2x + 1
2e−2x
7. y(x) = (A + Bx)e−2x +
  1
9x −2
27

ex
9. y(x) = A cos(3x) + B sin(3x) + 1
12x2 sin(3x) + 1
36x cos(3x)
11. y(x) = 2ax −1
8a2
+
ω2e−2ax
8a2(a2 + ω2) −a sin(2ωx) −ω cos(2ωx)
8ω(a2 + ω2)
Section 2.5
1. γ = 3,
5. x(t) = e−ct/(2m) [A cos(ω0t) + B sin(ω0t)] +
F0 sin(ωt −ϕ)
p
c2ω2 + (k −mω2)2
Section 2.6
1. y(x) = Aex + Be3x + 1
8e−x
3. y(x) = Ae2x + Be−2x −(3x + 2)ex/9
5. y(x) = (A + Bx)e−2x + x3e−2x/6
7. y(x) = Ae2x + Bxe2x +
  1
2x2 + 1
6x3
e2x
9. y(x) = Aex + Bxex + x ln(x)ex
Section 2.7
1. y(x) = C1x + C2x−1
3. y(x) = C1x2 + C2/x
5. y(x) = C1/x + C2 ln(x)/x
7. y(x) = C1x cos[2 ln(x)] + C2x sin[ln(x)]

948
Advanced Engineering Mathematics with MATLAB
9. y(x) = C1 cos[ln(x)] + C2 sin[ln(x)]
11. y(x) = C1x2 + C2x4 + C3/x
Section 2.8
1. The trajectories spiral outward from (0, 0).
3. The equilibrium points are (x, 0); they are unstable.
5. The equilibrium points are v = 0 and |x| < 2; they are unstable.
Section 3.1
1. A + B =

4
5
3
4

= B + A
3. 3A −2B =

7
10
−1
2

,
3(2A −B) =

15
21
0
6

5. (A + B)T =

4
3
5
4

,
AT + BT =

4
3
5
4

7. AB =

11
11
5
5

, AT B =

5
5
8
8

, BA =

4
6
8
12

, BT A =

5
8
5
8

9. BBT =

2
4
4
8

,
BT B =

5
5
5
5

11. A3 + 2A =

65
100
25
40

13. yes

27
11
2
5

15. yes


11
8
8
4
5
3


17. no
19. 5(2A) =


10
10
10
20
30
10

= 10A
21. (A + B) + C =

4
0
8
2

= A + (B + C)
23. A(B + C) =

9
−1
11
−2

= AB + AC
27.

1
−2
3
1
 
x1
x2

=

5
1

29.



0
1
2
3
3
0
−4
−4
1
1
1
1
2
−3
1
−3






x1
x2
x3
x4


=



2
5
−3
7



Section 3.2
1. 7
3. 1
5. −24
7. 3

Answers to the Odd-Numbered Problems
949
Section 3.3
1. x1 = 9
5, x2 = 3
5
3. x1 = 0, x2 = 0, x3 = −2
Section 3.4
1. x1 = 1, x2 = 2
3. x1 = x3 = α, x2 = −α
5. x1 = −1, x2 = 2α, x3 = α
7. x1 = 1, x2 = 2.6, x3 = 2.2
Section 3.5
1. λ = 4,
x0 = α

2
1

;
λ = −3
x0 = β

1
−3

3. λ = 1
x0 = α


−1
0
1

+ β


3
1
0

;
λ = 0,
x0 = γ


1
1
1


5. λ = 1,
x0 = α


1
0
0

+ β


0
1
−1

;
λ = 2,
x0 = γ


1
1
0


7. λ = 0,
x0 = α


1
1
1

; λ = 1,
x0 = β


3
2
1

; λ = 2,
x0 = γ


7
3
1


Section 3.6
1. x = c1

1
−1

e−t + c2

1
1

e3t
3. x = c1

1
2

e3t + c2

1
−2

e−t
5. x = c1

1
−1

et/2 + c2

t
−1/2 −t

et/2
7. x = c1

1
−1

e2t + c2

−1 + t
−t

e2t
9. x = c3

−3 cos(2t) −2 sin(2t)
cos(2t)

et + c4

2 cos(2t) −3 sin(2t)
sin(2t)

et
11. x = c3

2 cos(t)
7 cos(t) + sin(t)

e−3t + c4

2 sin(t)
7 sin(t) −cos(t)

e−3t
13. x = c3

−cos(2t) + sin(2t)
cos(2t)

et + c4

−cos(2t) −sin(2t)
sin(2t)

et
15. x = c1

−1
2

e3t + c2

−3
2

e−t
17. x = c1


0
1
0

+ c2


0
2
1

et + c3


2
1
0

e2t
19. x = c1


3
−2
12

e−t + c2


1
0
2

et + c3


0
1
0

e2t

950
Advanced Engineering Mathematics with MATLAB
Section 3.7
1.

et
3tet
0
et

3.


et
tet
1
2t2et
0
et
tet
0
0
et


5.


et
2tet
2t2et
0
et
2tet
0
0
et


7.
x1(t) = 1
2
 3et −e−t
x1(0) + 1
2
 e−t −et
x2(0) + 3tet −3 sinh(t) + 2t
x2(t) = 1
2
 3et −3e−t
x1(0) + 1
2
 3e−t −et
x2(0) + 3tet + 2e−t −5 sinh(t) + 4t −2
9.
x1(t) = [cos(t) + 2 sin(t)]x1(0) −5 sin(t)x2(0) + 2t cos(t) −t sin(t) −3 sin(t)
x2(t) = sin(t)x1(0) + [cos(t) −2 sin(t)]x2(0) + t cos(t) −sin(t)
11.
x1(t) = 1
3

e4t + 2et
x1(0) + 1
3

e4t −et
x2(0) + 1
3

e4t −et
x3(0)
−t2
6 et −4t
9 et + 4
27e4t −4
27et
x2(t) = 1
3

e4t −et
x1(0) + 1
3

e4t + 2et
x2(0) + 1
3

e4t −et
x3(0)
+ t2
3 et −4t
9 et + 4
27e4t −4
27et
x3(t) = 1
3

e4t −et
x1(0) + 1
3

e4t −et
x2(0) + 1
3

e4t + 2et
x3(0)
−t2
6 et + 5t
6 et + 4
27e4t −4
27et
13.
x1(t) =
  1
2e3t + 1
2e−t
x1(0) +
  1
4e3t −1
4e−t
x3(0) + 5
4
 et −e3t
+ 1
4
 e−t −et
x2(t) = e−2tx2(0) + 2
 et −e−2t
x3(t) =
 e3t −e−t
x1(0) +
  1
2e3t + 1
2e−t
x3(0) + 5
2
 et −e3t
+ 1
2
 et −e−t
15.
x1(t) = (1 −t)e2tx1(0) + te2tx2(0) + (2t + t2)e2tx3(0) +
 t2 + 1
4t + 1
4

e2t −3
4t −1
4
x2(t) = −te2tx1(0) + (1 + t)e2tx2(0) + (4t + t2)e2tx3(0)
+
 t2 + 9
4t −3
2

e2t + 2et −1
4t −1
2
x3(t) = e2tx3(0) + e2t −et
Section 4.1
1. a × b = −3i + 19j + 10k
3. a × b = i −8j + 7k
5. a × b = −3i −2j −5k
9. ∇f = y cos(yz)i + [x cos(yz) −xyz sin(yz)]j −xy2 sin(yz)k

Answers to the Odd-Numbered Problems
951
11. ∇f = 2xy2(2z + 1)2i + 2x2y(2z + 1)2j + 4x2y2(2z + 1)k
13. Plane parallel to the xy plane at height of z = 3, n = k
15. Paraboloid,
n = −
2x i
p
1 + 4x2 + 4y2 −
2y j
p
1 + 4x2 + 4y2 +
k
p
1 + 4x2 + 4y2
17. A plane, n = j/
√
2 −k/
√
2
19. A parabola of inﬁnite extent along the y-axis,
n = −2xi/
√
1 + 4x2 + k/
√
1 + 4x2
21. y = 2/(x + 1);
z = exp[(y −1)/y]
23. y = x;
z2 = y/(3y −2)
Section 4.2
1. ∇· F = 2xz + z2,
∇× F = (2xy −2yz)i + (x2 −y2)j,
∇(∇· F) = 2zi + (2x + 2z)k
3. ∇· F = 2(x −y) −xe−xy + xe2y,
∇× F = 2xze2yi −ze2yj + [2(x −y) −ye−xy] k,
∇(∇· F) =
 2 −e−xy + xye−xy + e2y
i +
 x2e−xy + 2xe2y −2

j
5. ∇· F = 0,
∇× F = −x2i + (5y −9x2)j + (2xz −5z)k,
∇(∇· F) = 0
7. ∇· F = e−y + z2 −3e−z, ∇× F = −2yzi + xe−yk, ∇(∇· F) = −e−yj + (2z + 3e−z)k
9. ∇· F = yz + x3zez + xyez,
∇× F = (xez −x3yez −x3yzez)i + (xy −yez)j + (3x2yzez −xz)k,
∇(∇· F) =
 3x2zez + yez
i +
 z + xez
j +
 y + x3ez + x3zez + xyez
k,
11. ∇· F = y2 + xz2 −xy sin(z),
∇× F = [x cos(z) −2xyz]i −y cos(z)j + (yz2 −2xy)k,
∇(∇· F) = [z2 −y sin(z)]i +

2y −x sin(z)

j +

2xz −xy cos(z)

k
13. ∇· F = y2 + xz −xy sin(z),
∇× F = [x cos(z) −xy]i −y cos(z)j + (yz −2xy)k,
∇(∇· F) = [z −y sin(z)]i +

2y −x sin(z)

j +

x −xy cos(z)

k
Section 4.3
1. 16/7 + 2/(3π)
3. e2 + 2e8/3 + e64/2 −13/6
5.−4π
7. 0
9. 2π
Section 4.4
1. ϕ(x, y, z) = x2y + y2z + 4z + constant
3. ϕ(x, y, z) = xyz + constant
5. ϕ(x, y, z) = x2 sin(y) + xe3z + 4z + constant
7. ϕ(x, y, z) = xe2z + y3 + constant
9. ϕ(x, y, z) = xy + xz + constant
Section 4.5
1. 1/2
3. 0
5. 27/2
7. 5
9. 0
11. 40/3
13. 86/3
15. 96π

952
Advanced Engineering Mathematics with MATLAB
Section 4.6
1. −5
3. 1
5. 0
7. 0
9. −16π
11. −2
Section 4.7
1. −10
3. 2
5. π
7. 45/2
Section 4.8
1. 3
3. −16
5. 4π
7. 5/12
Section 5.1
1. f(t) = 1
2 −2
π
∞
X
m=1
sin[(2m −1)t]
2m −1
3. f(t) = −π
4 +
∞
X
n=1
(−1)n −1
n2π
cos(nt) + 1 −2(−1)n
n
sin(nt),
5. f(t) = π
8 + 2
π
∞
X
n=1
2 cos(nπ/2) sin2(nπ/4)
n2
cos(nt) + sin(nπ/2)
n2
sin(nt)
7. f(t) = sinh(aL)
aL
+ 2aL sinh(aL)
∞
X
n=1
(−1)n
a2L2 + n2π2 cos
nπt
L

−2π sinh(aL)
∞
X
n=1
n(−1)n
a2L2 + n2π2 sin
nπt
L

9. f(t) = 1
π + 1
2 sin(t) −2
π
∞
X
m=1
cos(2mt)
4m2 −1
11. f(t) = a
2 −4a
π2
∞
X
m=1
1
(2m −1)2 cos
(2m −1)πt
a

−2a
π
∞
X
n=1
(−1)n
n
sin
nπt
a

13. f(t) = π −1
2
+ 1
π
∞
X
n=1
sin(nπt)
n
,
15. f(t) = 4a cosh(aπ/2)
π
∞
X
m=1
cos[(2m −1)t]
a2 + (2m −1)2
Section 5.3
1. f(x) = π
2 −4
π
∞
X
m=1
cos[(2m −1)x]
(2m −1)2
,
f(x) = 2
π
∞
X
n=1
(−1)n+1 sin(nx)
n
3. f(x) = a3
6 −a2
π2
∞
X
m=1
1
m2 cos
2mπx
a

,
f(x) = 8a2
π3
∞
X
m=1
1
(2m −1)3 sin
(2m −1)πx
a

5. f(x) = 1
4 −2
π2
∞
X
m=1
cos[2(2m −1)πx]
(2m −1)2
,
f(x) = 4
π2
∞
X
m=1
(−1)m+1 sin[(2m −1)πx]
(2m −1)2
7. f(x) = 2π2
3
−4
∞
X
n=1
(−1)n
n2
cos(nx),
f(x) = 2π
∞
X
n=1
sin(nx)
n
+ 8
π
∞
X
m=1
sin[(2m −1)x]
(2m −1)3

Answers to the Odd-Numbered Problems
953
9. f(x) = a
6 + 4a
π2
∞
X
m=1
(−1)m sin[(2m −1)π/6]
(2m −1)2
cos
(2m −1)πx
a

f(x) = a
π2
∞
X
m=1
(−1)m sin(mπ/3)
m2
sin
2mπx
a

−2a
3π
∞
X
n=1
(−1)n
n
sin
nπx
a

11. f(x) = 3
4 + 1
π
∞
X
m=1
(−1)m
2m −1 cos
(2m −1)πx
a

f(x) = 1
π
∞
X
n=1
1 + cos(nπ/2) −2(−1)n
n
sin
nπx
a

13. f(x) = 3a
8 + 2a
π2
∞
X
n=1
cos(nπ/2) −1
n2
cos
nπx
a

,
f(x) = a
π
∞
X
n=1
 2
n2π sin
nπ
2

−(−1)n
n

sin
nπx
a

Section 5.4
1. f(t) = 1
2 + 2
π
∞
X
n=1
sin[(2n −1)t]
2n −1
, f(t) = 1
2 + 2
π
∞
X
n=1
cos[(2n −1)t −π/2]
2n −1
3. f(t) = 2
∞
X
n=1
1
n cos
h
nt + (−1)n π
2
i
, f(t) = 2
∞
X
n=1
1
n sin
n
nt + [1 + (−1)n]π
2
o
Section 5.5
1. f(t) = π
2 −2
π
∞
X
m=−∞
ei(2m−1)t
(2m −1)2
3. f(t) = 1 + i
π
∞
X
n=−∞
n̸=0
enπit
n
5. f(t) = 1
2 −i
π
∞
X
m=−∞
e2(2m−1)it
2m −1
Section 5.6
1. y(t) = A cosh(t) + B sinh(t) −1
2 −2
π
∞
X
n=1
sin[(2n −1)t]
(2n −1) + (2n −1)3
3. y(t) = Ae2t + Bet + 1
4 + 6
π
∞
X
n=1
cos[(2n −1)t]
[2 −(2n −1)2]2 + 9(2n −1)2
+ 2
π
∞
X
n=1
[2 −(2n −1)2] sin[(2n −1)t]
(2n −1){[2 −(2n −1)2]2 + 9(2n −1)2}
5. yp(t) = π
8 −2
π
∞
X
n=−∞
ei(2n−1)t
(2n −1)2[4 −(2n −1)2]
7. q(t) =
∞
X
n=−∞
ω2ϕn
(inω0)2 + 2iαnω0 + ω2 einω0t

954
Advanced Engineering Mathematics with MATLAB
Section 5.7
1. f(t) = 3
2 −cos(πx/2) −sin(πx/2) −1
2 cos(πx)
Section 6.1
1. λn = (2n −1)2π2/(4L2), yn(x) = cos[(2n −1)πx/(2L)]
3. λ0 = −1, y0(x) = e−x and λn = n2, yn(x) = sin(nx) −n cos(nx)
5. λn = −n4π4/L4, yn(x) = sin(nπx/L)
7. λn = k2
n, yn(x) = sin(knx) with kn = −tan(kn)
9.
λ0 = −m2
0, y0(x) = sinh(m0x) −m0 cosh(m0x) with coth(m0π) = m0; λn = k2
n,
yn(x) = sin(knx) −kn cos(knx) with kn = −cot(knπ)
11.
(a)
λn = n2π2,
yn(x) = sin[nπ ln(x)]
(b)
λn = (2n −1)2π2/4,
yn(x) = sin[(2n −1)π ln(x)/2]
(c)
λ0 = 0,
y0(x) = 1;
λn = n2π2,
yn(x) = cos[nπ ln(x)]
13. λn = n2 + 1, yn(x) = sin[n ln(x)]/x
15. λ = 0, y0(x) = 1; yn(x) = cosh(λnx) + cos(λnx) −tanh(λn)[sinh(λnx) + sin(λnx)],
where n = 1, 2, 3, . . ., and λn is the nth root of tanh(λ) = −tan(λ).
Section 6.3
1. f(x) = 2
π
∞
X
n=1
(−1)n+1
n
sin
nπx
L

3. f(x) = 8L
π2
∞
X
n=1
(−1)n+1
(2n −1)2 sin
(2n −1)πx
2L

Section 6.4
1. f(x) = 1
4P0(x) + 1
2P1(x) + 5
16P2(x) + · · ·
3. f(x) = 1
2P0(x) + 5
8P2(x) −3
16P4(x) + · · ·
5. f(x) = 3
2P1(x) −7
8P3(x) + 11
16P5(x) + · · ·
Section 7.3
1. u(x, t) = 4L
cπ2
∞
X
m=1
1
(2m −1)2 sin
(2m −1)πx
L

sin
(2m −1)πct
L

3. u(x, t) = 9h
π2
∞
X
n=1
1
n2 sin
2nπ
3

sin
nπx
L

cos
nπct
L

5. u(x, t) = sin
πx
L

cos
πct
L

+4aL
π2c
∞
X
n=1
(−1)n+1
(2n −1)2 sin
(2n −1)π
4

sin
(2n −1)πx
L

sin
(2n −1)πct
L

7. u(x, t) = 4L
π2
∞
X
n=1
(−1)n+1
(2n −1)2 sin
(2n −1)πx
L

cos
(2n −1)πct
L


Answers to the Odd-Numbered Problems
955
9. u(x, t) = √a
∞
X
n=1
J1(2kn
√a )J0(2kn
√x )
k2nJ2
1(2kn)
sin(knt),
where kn is the nth solution of J0(2k) = 0.
11. u(x, t) = 8Lcs0
π2
∞
X
n=1
(−1)n
(2n −1)2 cos
(2n −1)πx
2L

sin
(2n −1)πct
2L

Section 7.4
1. u(x, t) = sin(2x) cos(2ct) + cos(x) sin(ct)/c
3. u(x, t) =
1 + x2 + c2t2
(1 + x2 + c2t2)2 + 4x2c2t2 + ex sinh(ct)
c
5. u(x, t) = cos
πx
2

cos
πct
2

+ sinh(ax) sinh(act)
ac
Section 8.3
1. u(x, t) = 4A
π
∞
X
m=1
sin[(2m −1)x]
2m −1
e−a2(2m−1)2t
3. u(x, t) = −2
∞
X
n=1
(−1)n
n
sin(nx)e−a2n2t
5. u(x, t) = 4
π
∞
X
m=1
(−1)m+1
(2m −1)2 sin[(2m −1)x]e−a2(2m−1)2t
7. u(x, t) = π
2 −4
π
∞
X
m=1
cos[(2m −1)x]
(2m −1)2
e−a2(2m−1)2t
9. u(x, t) = π
2 −4
π
∞
X
n=1
cos[(2n −1)x]
(2n −1)2
e−a2(2n−1)2t
11. u(x, t) = 32
π
∞
X
n=1
(−1)n
(2n −1)3 cos
(2n −1)x
2

e−a2(2n−1)2t/4
13. u(x, t) = 4
π
∞
X
n=1
sin[(2n −1)x/2]
2n −1
e−a2(2n−1)2t/4
15. u(x, t) =
∞
X
n=1

4
2n −1 −8(−1)n+1
(2n −1)2π

sin
(2n −1)x
2

e−a2(2n−1)2t/4
17.u(x, t) = T0x
π
+ 2T0
π
∞
X
n=1
1
n sin(nx)e−a2n2t
19. u(x, t) = h1 + (h2 −h1)x
L
+ 2(h2 −h1)
π
∞
X
n=1
(−1)n
n
sin
nπx
L

exp

−a2n2π2
L2
t

21. u(x, t) = h0 −4h0
π
∞
X
n=1
1
2n −1 sin
(2n −1)πx
L

exp

−(2n −1)2π2a2t
L2


956
Advanced Engineering Mathematics with MATLAB
23. u(x, t) = 1
3 −t −2
π2
∞
X
n=1
(−1)n
n2
cos(nπx)e−a2n2π2t
25. u(x, t) = 4
π
∞
X
n=1
(−1)n+1
(2n −1)4 sin[(2n −1)x]
h
1 −e−(2n−1)2ti
27. u(x, t) = A0(L2 −x2)
2κ
+ A0L
h
−2L2A0
κ
∞
X
n=1
sin(βn)
β4n[1 + κ sin2(κ)/hL] cos
βnx
L

exp

−a2β2
nt
L2

,
where βn is the nth root of β tan(β) = hL/κ.
29. u(x, t) = 4u0
∞
X
n=1
sin(knL) cos(knx)
2knL + sin(2knL) cos(knx) exp

−(k1 + a2k2
n)t

,
where kn denotes the nth root of k tan(kL) = k2/a2
31. u(r, t) = 2
πr
∞
X
n=1
(−1)n+1
n
sin(nπr)e−a2n2π2t
33. u(r, t) = 4bu0
r
∞
X
n=1
sin(kn) −kn cos(kn)
kn[2kn −sin(2kn)] sin
knr
b

e−a2k2
nt/b2,
where kn is the nth root of k cot(k) = 1 −A, nπ < kn < (n + 1)π.
35. u(r, t) = θ + 2(1 −θ)
∞
X
n=1
J0(knr/b)
knJ1(kn) e−a2k2
nt/b2,
where kn is the nth root of J0(k) = 0.
37. u(r, t) = G
4ρν (b2 −r2) −2Gb2
ρν
∞
X
n=1
J0(knr/b)
k3nJ1(kn) e−νk2
nt/b2,
where kn is the nth root of J0(k) = 0.
39. u(r, t) = 2T0
L2 e−κt
∞
X
n=1
[LJ1(knL) −bJ1(knb)]J0(knr)
kn[J2
0(knL) + J2
1(knL)]
e−a2k2
nt,
where kn is the nth root of kJ1(kL) = hJ0(kL).
Section 9.3
1. u(x, y) = 4
π
∞
X
m=1
sinh[(2m −1)π(a −x)/b] sin[(2m −1)πy/b]
(2m −1) sinh[(2m −1)πa/b]
3. u(x, y) = −2a
π
∞
X
n=1
sinh(nπy/a) sin(nπx/a)
n sinh(nπb/a)
5. u(x, y) = 4
π
∞
X
n=1
(−1)n+1 sinh[(2n −1)πy/2a] cos[(2n −1)πx/2a]
(2n −1) sinh[(2n −1)πb/2a]
7. u(x, y) = 1
9. u(x, y) = 1 −4
π
∞
X
m=1
cosh[(2m −1)πy/a] sin[(2m −1)πx/a]
(2m −1) cosh[(2m −1)πb/a]

Answers to the Odd-Numbered Problems
957
11. u(x, y) = 1
13. u(x, y) = T0 + ∆T cos(2πx/λ)e−2πy/λ
15. u(x, y) = L −y −4γL
π2
∞
X
m=1
cosh[(2m −1)πx/L)
(2m −1)2 sinh[(2m −1)π/L] sin
nπy
L

17. u(r, z) = Aa2z
b2
+ 2Aa
b2
∞
X
n=1
sinh(knz) J1(kna) J0(knr)
k2n cosh(knL)J2
0(knb)
,
where kn is nth positive zero of J′
0(kb) = −J1(kb) = 0.
19. u(r, z) = (z −h)r2
0
a2
+ 2r0
∞
X
n=1
sinh[kn(z −h)/a]J1(knr0/a)J0(knr/a)
k2n cosh(knh/a)J2
0(kn)
,
where kn is nth positive zero of J1(k) = 0.
21. Case (a):
u(r, z) = 4
π
∞
X
n=1
I1[(2n −1)πr/2]
I1[(2n −1)π/2]
sin[(2n −1)π(z −1)/2]
2n −1
Case (b):
u(r, z) = −2
∞
X
n=1
cosh(knz)
cosh(kn)
J1(knr)
knJ0(kn)
where kn is the nth root of J1(k) = 0.
23. u(r, z) = −2
π
∞
X
n=1
(−1)nI1(nπr) sin(nπz)
n I1(nπa)
25. u(r, z) = 2
∞
X
n=1
sinh(knz)J1(knr)
k3n cosh(kna)J1(kn),
where kn is nth positive zero of kJ0(k) = J1(k).
27. u(r, z) = 2u0
∞
X
n=1
J1(µn)J0(µnr/a)
µn[J2
0(µn) + J2
1(µn)]
cosh[µn(L −z)/a]
cosh(µnL/a)
,
where µnJ1(µn) = βJ0(µn), β = aK/D and n = 1, 2, 3, . . ..
29. u(r, z) = −V
(
1 −2
∞
X
n=1
cosh(knz/a)
kn J1(kn)
exp

−knd
2a

J0
knr
a
)
if |z| < d/2, and
u(r, z) = −2V
∞
X
n=1
sinh[knd/(2a)]
kn J1(kn)
exp

−kn|z|
a

J0
knr
a

if |z| > d/2.
31. u(r, z) = 2B
∞
X
n=1
exp[z(1 −
p
1 + 4k2n )/2]J0(knr)
(k2n + B2)J0(kn)
,
where kn is nth positive zero of kJ1(k) = BJ0(k).
35. u(r, θ) = 400
 r
7aP1[cos(θ)] −1
9
r
a
3
P3[cos(θ)] −2
63
r
a
5
P5[cos(θ)]

37. u(r, θ) = 1
2T0
∞
X
n=0
{Pn−1[cos(α)] −Pn+1[cos(α)]}
r
a
n
Pn[cos(θ)]

958
Advanced Engineering Mathematics with MATLAB
Section 9.4
1. u(x, y) = 64 R
π4 T
∞
X
n=1
∞
X
m=1
(−1)n+1(−1)m+1
(2n −1)(2m −1)
×
cos[(2n −1)πx/2a] cos[(2m −1)πy/b]
(2n −1)(2m −1)[(2n −1)2/a2 + (2m −1)2/b2]
Section 10.1
1. 1 + 2i
3. −2/5
5. 2 + 2i
√
3
7. 4eπi
9. 5
√
2e3πi/4
11. 2e2πi/3
Section 10.2
1. ±
√
2,
±
√
2
 
1
2 +
√
3i
2
!
,
±
√
2
 
−1
2 +
√
3i
2
!
3. i,
±
√
3
2 −i
2
5. ± 1
√
2

−
qp
a2 + b2 + a + i
qp
a2 + b2 + a

7. ±(1 + i),
±2(1 −i)
Section 10.3
1. u = 2 −y, v = x
3. u = x3 −3xy2, v = 3x2y −y3
5. f ′(z) = 3z(1 + z2)1/2
7. f ′(z) = 2(1 + 4i)z −3
9. f ′(z) = −3i(iz −1)−4
11. 1/6
13. v(x, y) = 2xy + constant
15. v(x, y) = x sin(x)e−y + ye−y cos(x) + constant
Section 10.4
1. 0
3. 2i
5. 14/15 −i/3
Section 10.5
1. (e−2 −e−4)/2
3. π/2
Section 10.6
1. πi/32
3. πi/2
5. −2πi
7. 2πi
9. 6π
Section 10.7
1.
∞
X
n=0
(n + 1)zn
3. f(z) = z10 −z9 + z8
2 −z7
6 + · · · −
1
11!z + · · ·
We have an essential singularity and the residue equals −1/11!
5. f(z) = 1
2! + z2
4! + z4
6! + · · ·
We have a removable singularity where the value of the residue equals zero.

Answers to the Odd-Numbered Problems
959
7. f(z) = −2
z −2 −7z
6 −z2
2 −· · ·
We have a simple pole and the residue equals −2.
9. f(z) = 1
2
1
z −2 −1
4 + z −2
8
−· · ·
We have a simple pole and the residue equals 1/2.
Section 10.8
1. −3πi/4
3. −2πi.
5. 2πi
7. 2πi
Section 10.11
3. z = C√τ −π + π i
5. z = τ 7/4 or τ = z4/7
7. z = a
π cosh−1(τ),
0 ≤ℑ[cosh−1(τ)] ≤π
Section 11.3
1. πe−|ω/a|/|a|
Section 11.4
1. −t/(1 + t2)2
3. f(t) = 1
2e−tH(t) + 1
2etH(−t)
5. f(t) = e−tH(t) −e−t/2H(t) + 1
2te−t/2H(t)
7. f(t) = ie−atH(t)/2 −ieatH(−t)/2
9. f(t) = (1 −a|t|)e−a|t|/(4a)
11. f(t) = (−1)n+1t2n+1e−atH(t)/(2n + 1)!
13. f(t) = e2tH(−t) + e−tH(t)
15. f+(t) =
i e−at
R2 −e2a +
1
2Rt+2
∞
X
n=−∞
einπt
nπ + [ln(R) −a] i
f−(t) =
i e−at
R2e−2a −1H(t −2) + H(t −2)
2Rt
∞
X
n=−∞
einπt
nπ + [ln(R) −a] i
17.
f(t) = −2β
L H(t)
∞
X
n=1
(−1)ne−(2n−1)βγπt/2L
× {γ cos[(2n −1)βπt/2L] + sin[(2n −1)βπt/2L]}
Section 11.6
1. y(t) = [(t −1)e−t + e−2t]H(t)
3. y(t) = 1
9e−tH(t) +
 1
9e2t −1
3te2t
H(−t)
Section 11.7
1. u(x, y) = 1
π

tan−1
1 −x
y

+ tan−1
x
y

3. u(x, y) = T0
π
π
2 −tan−1
x
y


960
Advanced Engineering Mathematics with MATLAB
5. u(x, y) = T0
π

tan−1
1 −x
y

+ tan−1
1 + x
y

+ T1 −T0
2π
y ln
(x −1)2 + y2
x2 + y2

+T1 −T0
π
x

tan−1
1 −x
y

+ tan−1
x
y

Section 11.8
1. u(x, t) = 1
2 erf
 b −x
√
4a2t

+ 1
2 erf
 b + x
√
4a2t

3. u(x, t) = 1
2T0 erf
 b −x
√
4a2t

+ 1
2T0 erf

x
√
4a2t

Section 12.1
1. F(s) = s/(s2 −a2)
3. F(s) = 1/s + 2/s2 + 2/s3
5. F(s) =

1 −e−2(s−1)
/(s −1)
7. F(s) = 2/(s2 + 1) −s/(s2 + 4) + cos(3)/s −1/s2
9. f(t) = e−3t
11. f(t) = 1
3 sin(3t)
13. f(t) = 2 sin(t) −15
2 t2 + 2e−t −6 cos(2t)
17. F(s) = 1/(2s) −sT 2/[2(s2T 2 + π2)]
Section 12.2
1. f(t) = (t −2)H(t −2) −(t −2)H(t −3)
3. y′′ + 3y′ + 2y = H(t −1)
5. y′′ + 4y′ + 4y = tH(t −2)
7. y′′ −3y′ + 2y = e−tH(t −2)
9. y′′ + y = sin(t)[1 −H(t −π)]
Section 12.3
1. F(s) = 2/(s2 + 2s + 5)
3. F(s) = 2e−s/s3 + 2e−s/s2 + e−s/s
5. F(s) = 1/(s −1)2 + 3/(s2 −2s + 10) + (s −2)/(s2 −4s + 29)
7. F(s) = 2/(s + 1)3 + 2/(s2 −2s + 5) + (s + 3)/(s2 + 6s + 18)
9. F(s) = 2e−s/s3 + 2e−s/s2 + 3e−s/s + e−2s/s
11. F(s) = (1 + e−sπ)/(s2 + 1)
13. F(s) = 4(s + 3)/(s2 + 6s + 13)2
15. f(t) = 1
2t2e−2t −1
3t3e−2t
17. f(t) = e−t cos(t) + 2e−t sin(t)
19. f(t) = e−2t −2te−2t + cos(t)e−t + sin(t)e−t
21. f(t) = et−3H(t −3)
23. f(t) = e−(t−1)[cos(t −1) −sin(t −1)]H(t −1)
25. f(t) = cos[2(t −1)]H(t −1) + 1
6(t −3)3e2(t−3)H(t −3)
27. f(t) = {cos[2(t −1)] + 1
2 sin[2(t −1)]}H(t −1) + 1
6(t −3)3H(t −3)
29. f(t) = t[H(t) −H(t −a)];
F(s) = 1/s2 −e−as/s2 −ae−as/s
31. F(s) = 1/s2 −e−s/s2 −e−2s/s
33. F(s) = e−s/s2 −e−2s/s2 −e−3s/s

Answers to the Odd-Numbered Problems
961
35. Y (s) = s/(s2 + 4) + 3e−4s/[s(s2 + 4)]
37. Y (s) = e−(s−1)/[(s −1)(s + 1)(s + 2)]
39. Y (s) = 5/[(s −1)(s −2)] + e−s/[s3(s −1)(s −2)]
+2e−s/[s2(s −1)(s −2)] + e−s/[s(s −1)(s −2)]
41. Y (s) = 1/[s2(s + 2)(s + 1)] + ae−as/[(s + 1)2(s + 2)]
−e−as/[s2(s + 1)(s + 2)] −e−as/[s(s + 1)(s + 2)]
43. f(0) = 1
45. f(0) = 0
47. Yes
49. No
51. No
Section 12.4
1. F(s) = coth
sπ
2

(s2 + 1)
3. F(s) = 1 −(1 + as)e−as
s2(1 −e−2as)
Section 12.5
1. f(t) = e−t −e−2t
3. f(t) = 5
4e−t −6
5e−2t −1
20e3t
5. f(t) = e−2t cos
 t + 3π
2

7. f(t) = 2.3584 cos(4t + 0.5586)
9. f(t) = 1
2 +
√
2
2 cos
 2t + 5π
4

Section 12.6
11. f(t) = et −t −1
Section 12.7
1. f(t) = 1 + 2t
3. f(t) = t + t2/2
5. f(t) = t3 + t5/20
7. f(t) = t2 −t4/3
9. f(t) = 5e2t −4et −2tet
11. f(t) = (1 −t)2e−t
13. f(t) = a

1 −eπt erfc(
√
πt)

/2
15. f(t) = 1
2t2
17. x(t) =
n
ec2t 
1 + erf
 c
√
t

−c2t −1 −2c
p
t/π
o
/c2
19. f(t) = a + a2t + 1
2a erf(
√
at ) + a3t erf(
√
at ) + a2√
te−a2t/√π
Section 12.8
1. y(t) = 5
4e2t −1
4 + 1
2t
3. y(t) = e3t −e2t
5. y(t) = −3
4e−3t + 7
4e−t + 1
2te−t
7. y(t) = 3
4e−t + 1
8et −7
8e−3t
9. y(t) = (t −1)H(t −1)
11. y(t) = e2t −et +
 1
2 + 1
2e2(t−1) −et−1
H(t −1)
13. y(t) =

1 −e−2(t−2) −2(t −2)e−2(t−2)
H(t −2)
15. y(t) =
 1
3e2(t−2) −1
2et−2 + 1
6e−(t−2)
H(t −2)
17. y(t) = 1 −cos(t) −[1 −cos(t −T)] H(t −T)
19. y(t) = e−t −1
4e−2t −3
4 + 1
2t −

e−(t−a) −1
4e−2(t−a) −3
4 + 1
2(t −a)

H(t −a)
+a
 1
2e−2(t−a) + (t −a)e−(t−a) −1
2

H(t −a)

962
Advanced Engineering Mathematics with MATLAB
21. y(t) = tet + 3(t −2)et−2H(t −2)
23. y(t) = 3

e−2(t−2) −e−3(t−2)
H(t −2)
+ 4

e−3(t−5) −e−2(t−5)
H(t −5)
25. x(t) = cos(
√
2t)e3t −
1
√
2 sin(
√
2t)e3t;
y(t) =
3
√
2 sin(
√
2t)e3t
27. x(t) = t −1 + e−t cos(t),
y(t) = t2 −t + e−t sin(t)
29. x(t) = 3F1 −2F2 −F1 cosh(t) + F2et −2F1 cos(t) + F2 cos(t) −F2 sin(t)
y(t) = F2 −2F1 + F1e−t −F2 cos(t) + F1 cos(t) + F1 sin(t)
Section 12.9
1. f(t) = (2 −t)e−2t −2e−3t
3. f(t) =
  1
4t2 −1
4t + 1
8

e2t −1
8
5. f(t) =
 1
2(t −1) −1
4 + 1
4e−2(t−1)
H(t −1)
7. f(t) =
e−bt
cosh(ab) −8ab
∞
X
n=1
(−1)n sin[(2n −1)πt/(2a)]
4a2b2 + (2n −1)2π2
+ 4
∞
X
n=1
(−1)n (2n −1)π cos[(2n −1)πt/(2a)]
4a2b2 + (2n −1)2π2
Section 12.10
1. u(x, t) = 4
π2
∞
X
m=1
sin[(2m −1)πx] sin[(2m −1)πt]
(2m −1)2
3. u(x, t) = sin(πx) cos(πt) −sin(πx) sin(πt)/π
5. u(x, t) = c
∞
X
n=0
f(t −x/c −2nL/c)H(t −x/c −2nL/c)
+ c
∞
X
m=1
f(t + x/c −2mL/c)H(t + x/c −2mL/c)
7. u(x, t) = xt −te−x + sinh(t)e−x +

1 −e−(t−x) + t −x −sinh(t −x)

H(t −x)
9.
u(x, t) = gx
ω2 −2gω2
L
∞
X
n=1
sin(λnx) cos(λnt)
λ2n(ω4 + ω2/L + λ2n) sin(λnL), where λn is the nth root of
λ = ω2 cot(λL).
11. u(x, t) = E −4E
π
∞
X
n=1
1
2n −1 sin
(2n −1)πx
2ℓ

cos
(2n −1)cπt
2ℓ

, or
u(x, t)=E
∞
X
n=0
(−1)nH

t −x + 2nℓ
c

+ E
∞
X
n=0
(−1)nH

t −[(2n + 2)ℓ−x]
c

.
13. p(x, t) = p0 −4ρu0c
π
∞
X
n=1
(−1)n
2n −1 sin
(2n −1)πx
2L

sin
(2n −1)cπt
2L

15. u(r, t) =
ap0
ρr[(β/
√
2 −α)2 + β2]

e−βτ/
√
2
 1
√
2 −α
β

sin(βτ) + cos(βτ)


Answers to the Odd-Numbered Problems
963
−e−ατ

H(τ), where τ = t −(r −a)/c.
17. u(x, t) = 2t
3 + x2
2 −1
6 −2
∞
X
n=1
(−1)n cos(nπx)
cos(nπt)
n2π2
+ 2 sin(nπt)
n3π3

Section 12.11
1. u(x, t) = T0

1 −e−a2t
3. u(x, t) = x + 2
π
∞
X
n=1
(−1)n
n
sin(nπx)e−n2π2t
5. u(x, t) = x(1 −x)
2
−4
π3
∞
X
m=1
sin[(2m −1)πx]
(2m −1)3
e−(2m−1)2π2t
7. u(x, t) = x erfc
 x
2
√
t

−2
r
t
π exp

−x2
4t

9. u(x, t) = u0
2 e−δxerfc

x
2a
√
t + a(1 −δ)
√
t
2

+ u0
2 e−xerfc

x
2a
√
t −a(1 −δ)
√
t
2

11. u(x, t) = 1
2eσ2t−βt
 e−σx
ρ + σ erfc
 x
2
√
t −σ
√
t

+ eσx
ρ −σ erfc
 x
2
√
t + σ
√
t

−
ρ
ρ2 −σ2 eρx+ρ2t−βterfc
 x
2
√
t + ρ
√
t

13. u(x, t) = t(L −x)
L
+ Px(x −L)
2a2
−x(x −L)(x −2L)
6a2L
−2PL2
a2π3
∞
X
n=1
(−1)n
n3
sin
nπx
L

exp

−a2n2π2t
L2

+2(P + 1)L2
a2π3
∞
X
n=1
1
n3 sin
nπx
L

exp

−a2n2π2t
L2

15. u(x, t) = 4q
π
∞
X
n=1
(−1)n cos[(2n −1)πx/2L]
(2n −1)[αq −(2n −1)2π2a2/4L2]
×

1 −exp[αqt −(2n −1)2π2a2t/4L2]
	
17. u(r, t) = u0

1 −b −β
r
f(r, t)

+
Z t
0

1 −b −β
r
f(r, t −τ)

q(τ) dτ,
where f(r, t) = erfc
 r −b
2a
√
t

−exp
r −b
β
+ a2t
β2

erfc
a
√
t
β
+ r −b
2a
√
t

.
19.y(t) = 4µAω2
mL
∞
X
n=1
λneλnt
λ4n −( 2µ
mL)(1 + 2µL
mν )λ3n + 2ω2λ2n + 6ω2µ
mL λn + ω4 ,
where λn is the nth root of λ2 + 2µλ3/2 coth

L
p
λ/ν

/(m√ν ) + ω2 = 0.
21. u(x, t) =
x
a + 1 + 2
∞
X
n=1
sin(λnx) exp(−λ2
nt)
[3a + 3 + λ2n/(3a)] sin(λn),
where λn is the nth root of λ cot(λ) = (3a + λ2)/3a.

964
Advanced Engineering Mathematics with MATLAB
23. u(x, t) = 1 −e−bt
Z ax
0
e−ηI0

2
p
btη

dη
25. u(r, t) = a2 −r2
4
−2a2
∞
X
n=1
J0(knr/a)
k3n J1(kn) e−k2
nt/a2,
where kn is the nth root of J0(k) = 0.
27. u(r, t) = k
"
t −b2 −r2
4a2
+ 2
a2b
∞
X
n=1
J0(κnr)
κ3nJ1(κnb)
#
,
where kn is the nth root of J0(κb) = 0.
Section 12.13
1. u(x, y) = 4
π
∞
X
m=1
1
2m −1 exp

−(2m −1)πx
a

sin
(2m −1)πy
a

Section 13.1
1. F(z) = 2z/(2z −1) if |z| > 1/2
3. F(z) = (z6 −1)/(z6 −z5) if |z| > 0
5. F(z) = (a2 + a −z)/[z(z −a)] if |z| > a.
Section 13.2
1. F(z) = zTeaT /(zeaT −1)2
3. F(z) = z(z + a)/(z −a)3
5. F(z) = [z −cos(1)]/{z[z2 −2z cos(1) + 1]}
7. F(z) = z[z sin(θ) + sin(ω0T −θ)]/[z2 −2z cos(ω0T) + 1]
9. F(z) = z/(z + 1)
11. fn ∗gn = n + 1
13. fn ∗gn = 2n/n!
Section 13.3
1. f0 = 0.007143, f1 = 0.08503, f2 = 0.1626, f3 = 0.2328
3. f0 = 0.09836, f1 = 0.3345, f2 = 0.6099, f3 = 0.7935
5. fn = 8 −8
  1
2
n −6n
  1
2
n
7. fn = (1 −αn+1)/(1 −α)
9. fn =
  1
2
n−10 Hn−10 +
  1
2
n−11 Hn−11
11. fn = 1
9(6n −4)(−1)n + 4
9
  1
2
n
13. fn = an/n!
Section 13.4
1. yn = 1 + 1
6n(n −1)(2n −1)
3. yn = 1
2n(n −1)
5. yn = 1
6 [5n −(−1)n]
7. yn = (2n −1)
  1
2
n +
 −1
2
n
9. yn = 2n −n −1
11. xn = 2 + (−1)n; yn = 1 + (−1)n
13. xn = 1 −2(−6)n; yn = −7(−6)n

Answers to the Odd-Numbered Problems
965
Section 13.5
1. marginally stable
3. unstable
Section 14.1
7. bx(t) = 1
π ln

t + a
t −a

Section 14.2
5. w(t) = u(t) ∗v(t) = πe−1 sin(t)
Section 14.3
1. z(t) = eiωt
Section 14.4
3. x(t) =
1 −t2
(1 + t2)2 ;
bx(t) =
2t
(1 + t2)2
Section 15.2
1. G(s) = 1/(s + k)
g(t|0) = e−kt
g(t|τ) = e−k(t−τ)H(t −τ)
a(t) =
 1 −e−kt
/k
3. G(s) = 1/(s2 + 4s + 3)
g(t|0) = 1
2(e−t −e−3t)
g(t|τ) = 1
2

e−(t−τ) −e−3(t−τ)
H(t −τ)
a(t) = 1
6e−3t −1
2e−t + 1
3
5. G(s) = 1/[(s −2)(s −1)]
g(t|0) = e2t −et
g(t|τ) =

e2(t−τ) −et−τ
H(t −τ)
a(t) = 1
2 + 1
2e2t −et
7. G(s) = 1/(s −9)2
g(t|0) = 1
3 sinh(3t)
g(t|τ) = 1
3 sinh[3(t −τ)]H(t −τ)
a(t) = 1
9 [cosh(3t) −1]
9. G(s) = 1/[s(s −1)]
g(t|0) = et −1
g(t|τ) = [et−τ −1] H(t −τ)
a(t) = et −t −1
11.
g(x|ξ) = (1 + x<)(L −1 −x>)
L
,
and
g(x|ξ) = −2ex+ξ
e2L −1 + 2L3
π2
∞
X
n=1
ϕn(ξ)ϕn(x)
n2(n2π2 + L2),
where ϕn(x) = sin(nπx/L) + nπ cos(nπx/L)/L.
13.
g(x|ξ) = sinh(kx<) sinh[k(L −x>)]
k sinh(kL)
,

966
Advanced Engineering Mathematics with MATLAB
and
g(x|ξ) = 2L
∞
X
n=1
sin(nπξ/L) sin(nπx/L)
n2π2 + k2L2
.
15.
g(x|ξ) = sinh(kx<){k cosh[k(x> −L)] −sinh[k(x> −L)]}
k sinh(kL) + k2 cosh(kL)
,
and
g(x|ξ) = 2
∞
X
n=1
(1 + k2
n) sin(knξ) sin(knx)
[1 + (1 + k2n)L](k2n + k2) ,
where kn is the nth root of tan(kL) = −k.
17.
g(x|ξ) = [a sinh(kx<) −k cosh(kx<)] cosh[k(L −x>)]
k[a cosh(kL) −k sinh(kL)]
,
and
g(x|ξ) = 2
∞
X
n=1
(a2 + k2
n) cos[kn(ξ −L)] cos[kn(x −L)]
[(a2 + k2n)L −a](k2n + k2)
,
where kn is the nth root of k tan(kL) = −a.
Section 15.4
3.
g(x, t|ξ, τ) = t −τ
L
H(t −τ) + 2
π H(t −τ)
∞
X
n=1
1
n cos
nπξ
L

cos
nπx
L

sin
nπ(t −τ)
L

5.
u(x, t) = 2
∞
X
n=1
sin
nπx
L
 
nπ
L2 + n2π2

e−t −cos
nπt
L

+
L
L2 + n2π2 sin
nπt
L

+ 2 sin
πx
L

cos
πt
L

+ 4L
π2
∞
X
m=1
1
(2m −1)2 sin
(2m −1)πx
L

sin
(2m −1)πt
L

7.
u(x, t) = 1 −t2
2L −2L
π2
∞
X
n=1
1
n2 cos
nπx
L
 
1 −cos
nπt
L

Section 15.5
3.
g(x, t|ξ, τ) = 2
L
 ∞
X
n=1
sin
(2n −1)πξ
2L

sin
(2n −1)πx
2L

exp

−(2n −1)2π2(t −τ)
4L2

× H(t −τ)

Answers to the Odd-Numbered Problems
967
5.
u(x, t) = 2π
∞
X
n=1
n
n2π2 −L2 sin
nπx
L
 
e−t −exp

−n2π2t
L2

+ 4
π
∞
X
m=1
1
2m −1 sin
(2m −1)πx
L

exp

−(2m −1)2π2t
L2

7.
u(x, t) = 1 −t
L −2L
π2
∞
X
n=1
1
n2 cos
nπx
L
 
1 −exp

−n2π2t
L2

Section 15.6
1.
g(x, y|ξ, η) = 1
π
∞
X
n=1
1
n exp

−nπ
a |y −η|

sin
nπξ
a

sin
nπx
a

5.
g(r, θ|ρ, θ′) = 1
π
∞
X
n=1
1
nrnπ/β
<
r−nπ/β
>
sin
nπθ′
β

sin
nπθ
β

7.
g(r, z|ρ, ζ) =
2
πa2L
∞
X
n=1
∞
X
m=1
J0(kmρ/a)J0(kmr/a)
πa2LJ2
1(km)(k2m/a2 + n2π2/L2) sin
nπζ
L

sin
nπz
L

Section 16.2
1. (a) S = {HH, HT, TH, TT}
(b) S = {ab, ac, ba, bc, ca, cb}
(c) S = {aa, ab, ac, ba, bb, bc, ca, cb, cc}
(d) S = {bbb, bbg, bgb, bgg, ggb, ggg, gbb, gbg}
(e) S = {bbb, bbg, bgb, bgg, ggb, ggg, gbb, gbg}
3. 1/3
5. 1/3
7. 2/13
9. 1/720, 1/120
11. 1/2
13. 1/2
15. 9/16
Section 16.3
1.
FX(x) =
( 0,
x < 0,
1 −p,
0 ≤x < 1,
1,
1 ≤x.
3.
27

968
Advanced Engineering Mathematics with MATLAB
Section 16.4
1. FX(x) =

0,
x ≤0,
1 −e−λx,
0 < x.
3. FX(x) =





0,
x < −1,
(1 + x)2/2,
−1 ≤x < 0,
1 −(x −1)2/2,
0 ≤x < 1,
1,
1 ≤x.
Section 16.5
1. E(X) = 1
2, and Var(X) = 1
4
3. k = 3/4, E(X) = 1, and Var(X) = 1
5
5. φX(ω) =
 peiω + q
n, µX = np, Var(X) = npq
7. φX(ω) = p/(1 −qeωi), µX = q/p, Var(X) = q/p2
Section 16.6
1. (a) 1/16, (b) 1/4, (c) 15/16, (d) 1/16
5. P(X > 0) = 0.01, and P(X > 1) = 9 × 10−5
7. P(T < 150) = 1
3, and P(X = 3) = 0.1646
Section 16.7
1.
pXY [xi, yj] =

7
xi
 
8
yj
 
5
5 −xi −yj


20
5

,
where xi = 0, 1, 2, 3, 4, 5, yj = 0, 1, 2, 3, 4, 5 and 0 ≤xi + yj ≤5.
Section 17.1
1. µX(t) = 0, and σ2
X(t) = cos(ωt)
3. For t1 = t2, RX(t1, t2) = p; for t1 ̸= t2, RX(t1, t2) = p2. For t1 = t2, CX(t1, t2) = p(1−p);
for t1 ̸= t2, CX(t1, t2) = 0.
Section 17.4
1.
P n =

2/3 + (1/3)(1/4)n
1/3 −(1/3)(1/4)n
2/3 −(2/3)(1/4)n
1/3 + (2/3)(1/4)n

.
P ∞=

2/3
1/3
2/3
1/3

.
Section 18.3
1. E(X) = 0,
Var(X) = E(X2) = (b3 −a3)/3
3. E(X) = 0,
Var(X) = E(X2) = (b2 −a2)/2
Section 18.5
1. X(t) = et/2B(t) + X0
3. X(t) = B2(t) + tB(t) + X0
5. X(t) = tB2(t) −t2/2 + X0
7. et/(RC)Q(t) −Q(0) = 1
R
R t
0 eη/(RC)V (η) dη + 1
R
R t
0 eη/(RC)α(η) dη

Answers to the Odd-Numbered Problems
969
9. X(t) = X(0)e4t + 1
4
 1 −e−4t
+ 2
R t
0 e4(t−η) dB(η)
11. X(t) = X0et + et −1 + 1
2et[B2(t) −t]
13. X(t) = et/2X0 −2t −4 + 5et/2 −et cos[B(t)]
17.
X(t) = X0 exp

1
8 sin(2t) + sin(t) −1
4t +
Z t
0
sin(η) dB(η)

19.
X(t) = X0 exp

(t + 1) ln(t + 1) −t −1
6t3 +
Z t
0
η dB(η)


Index
abscissa of convergence, 560
absolute value of a complex number, 442
Adams-Bashforth method, 40
addition
of a complex numbers, 441
of matrices, 99
of vectors, 145
age of the earth, 553–554
aliasing, 231–233
amplitude
of a complex number, 442
spectrum, 511
analytic complex function, 449
derivative of, 450
analytic signals, 718–720
Archimedes’ principle, 184–185
argument of a complex number, 442
autonomous ordinary diﬀerential
equation, 4, 48
auxiliary equation, 50
back substitution, 102, 113
band-pass functions, 717
basis function, 795
Bayes’ rule, 812
Bernoulli equation, 28–29
Bessel
equation of order n, 271–275
function of the ﬁrst kind, 273
expansion in, 277–285
function of the second kind, 273
function, modiﬁed, 275
recurrence formulas, 276–277
Bessel, Friedrich Wilhelm, 272
Biot number, 352
boundary condition
Cauchy, 300
Dirichlet, 339
Neumann, 339
Robin, 340
boundary-value problems, 46
branches
of a complex function, 449
principal, 443
Bromwich contour, 613
Bromwich integral, 613
Bromwich, Thomas John I’Anson, 614
Buﬀon’s needle problem, 846–847
carrier frequency, 524
Cauchy
boundary condition, 300
data, 300
integral formula, 464–466
principal value, 485–488
problem, 300
residue theorem, 473–476
Cauchy, Augustin-Louis, 451

972
Advanced Engineering Mathematics with MATLAB
Cauchy-Goursat theorem, 460
Cauchy-Riemann eqns, 451
centered ﬁnite diﬀerences, 326
central limit theorem, 827
Chapman-Kolmogorov equation, 868–869
characteristic
polynomial, 124
equation, 50
value, 124, 240
vector, 124
characteristic function, 240, 830–831
characteristics, 318
chemical reaction, 12–13, 882–883
circular frequency, 58
circulation, 159
closed
contour integral, 157, 459
surface integral, 163
coeﬃcient matrix, 112
cofactor, 105
column of a matrix, 98
column vector, 98
combinations, 811
complementary error function, 565
complementary solution of an
ordinary diﬀerential equation, 66
complex-valued
function, 448–450
conjugate, 441
number, 441
plane, 442
variable, 441
complex matrix, 98
components of a vector, 145
compound interest, 9, 694–695
conformable
for addition of matrices, 99
for multiplication of matrices, 99
conformal mapping, 491–507
conservative ﬁeld, 159
consistency in ﬁnite diﬀerencing
for the heat equation, 378
for the wave equation, 329
consistent system of linear eqns, 111
contour integrals, 456–460
convergence
of a Fourier integral, 512
of ﬁnite diﬀerence solution
for heat equation, 379
for wave equation, 330
of Fourier series, 189
convolution theorem
for Fourier transforms, 544–547
for Hilbert transforms, 715–717
for Laplace transforms, 588–591
for z-transforms, 678
Coriolis force, 147
Cramer’s rule, 108
Crank-Nicholson method, 382
critical points, 33, 88
stable, 33, 89
stable node, 90
unstable, 33, 89
cross product, 146
curl, 154
curve,
simply closed, 460
space, 146
cutoﬀfrequency, 754
d’Alembert’s formula, 320
d’Alembert’s solution, 318–324
d’Alembert, Jean Le Rond, 319
damped harmonic motion, 61, 899–900
damping constant, 61
de Moivre’s theorem, 443
deformation principle, 462
degenerate eigenvalue problem, 247
del operator, 148
delay diﬀerential equation, 608–609
delta function, 512–513, 568–570
design of ﬁlm projectors, 585–587
design of wind vane, 64–65
determinant, 104–108
diagonal, principal, 98
diﬀerence eqns, 667
diﬀerential eqns
nth order, 45–95
ﬁrst-order, 1–43
nonlinear, 1
order, 1
ordinary, 1–97
partial, 1, 297–336,
337–384, 385–440
stochastic, 929–932
type, 1
diﬀerentiation of a Fourier series, 199
diﬀusivity, 338

Index
973
dimension of a vector space, 125
direction ﬁelds, 31
Dirichlet conditions, 189
Dirichlet problem, 339
Dirichlet, Peter Gustav Lejeune, 191
dispersion, 306
divergence
of a vector, 153
theorem, 179–185
division of complex numbers, 441
dot product, 146
double Fourier series, 427
dual Fourier-Bessel series, 404
dual integral eqns, 401
Duhamel’s theorem
for ordinary diﬀerential equation, 741
for the heat equation, 651–659
eigenfunctions, 239–256
expansion in, 251
orthogonality of, 249
eigenvalue(s)
of a matrix, 124
of a Sturm-Liouville problem, 239–247
eigenvalue problem, 124–129
for ordinary diﬀerential eqns, 239–247
singular, 240
eigenvectors, 124–129
orthogonality of, 132
electrical circuits, 24, 76, 604–609
electrostatic potential, 392
element of a matrix, 98
elementary row operations, 111
elliptic partial diﬀerential equation, 385
entire complex function, 449
equilibrium points, 33, 88
equilibrium systems of linear eqns, 111
error function, 565
essential singularity, 469
Euler’s formula, 442
Euler’s method, 34–36
Euler-Cauchy equation, 83–86
evaluation of partial sums
using z-transform, 688
exact ordinary diﬀerential equation, 17
existence of ordinary diﬀerential eqns
nth-order, 46
ﬁrst-order, 8
explicit numerical methods
for the heat equation, 377
for the wave equation, 326
exponential order, 560
fast Fourier transform (FFT), 231
ﬁlter, 234
ﬁnal-value theorem
for Laplace transforms, 575
for z-transform, 676
ﬁnite diﬀerence approximation
to derivatives, 326
ﬁnite element, 795
ﬁnite Fourier series, 225–234
ﬁrst-order ordinary diﬀerential eqns, 1–43
linear, 20–31
ﬁrst-passage problem, 901–903
ﬂux lines, 150
folding frequency, 233
forced harmonic motion, 71–76
Fourier
coeﬃcients, 188
cosine series, 194
cosine transform, 555
Joseph, 190
number, 347
series for a multivalued function, 217
series for an even function, 194
series for an odd function, 194
series in amplitude/phase form, 211–213
series on [−L, L], 187–198
sine series, 194
sine transform, 555
Fourier coeﬃcients, 253
Fourier cosine series, 194
Fourier transform, 509–549, 736–740
basic properties of, 520–530
convolution, 544–547
inverse of, 510, 532–542
method of solving the heat eqn, 551–556
of a constant, 518
of a derivative, 524
of a multivariable function, 514
of a sign function, 519
of a step function, 520
Fourier-Bessel
coeﬃcients, 279
expansions, 277
Fourier-Legendre
coeﬃcients, 264
expansion, 263
Fredholm integral eqn, 121

974
Advanced Engineering Mathematics with MATLAB
free umderdamped motion, 58
frequency convolution, 546
frequency modulation, 526
frequency response, 735
frequency spectrum, 511
for a damped harmonic
oscillator, 736–737
for low-frequency ﬁlter, 738–739
function
even extension of, 206
generalized, 570
multiplied complex, 448
odd extension of, 206
single-valued complex, 448
vector-valued, 148
fundamental of a Fourier series, 188
Galerkin method, 795–801
gambler’s ruin problem, 858
Gauss’s divergence theorem, 179–185
Gauss, Carl Friedrich, 180
Gauss-Seidel method, 429
Gaussian elimination, 114
general solution to an
ordinary diﬀerential equation, 4
generalized Fourier series, 252
generalized functions, 570
generating function
for Legendre polynomials, 260
Gibbs phenomenon, 202–205, 267
gradient, 148
graphical stability analysis, 33
Green’s function, 725–742
for a damped harmonic oscillator, 737
for low-frequency ﬁlter, 738
Green’s lemma, 169–172
grid point, 325
groundwater ﬂow, 388–392
half-range expansions, 206–209
Hankel transform, 399
harmonic functions, 386, 455
complex, 455
harmonics of a Fourier series, 188
heat conduction
in a rotating satellite, 220–224
within a metallic sphere, 409–414
heat dissipation in disc brakes, 640–642
heat equation, 337–383, 551–556, 637–662
for a semi-inﬁnite bar, 551–553
for an inﬁnite cylinder, 357–360
nonhomogeneous, 339
one-dimensional, 340–343
within a solid sphere, 355–357
Heaviside
expansion theorem, 581–587
step function, 563–565
Heaviside, Oliver, 564
Hilbert pair, 704
Hilbert transform, 703–723
and convolution, 715–716
and derivatives, 714–715
and shifting, 714
and time scaling, 714
discrete, 711–712
linearity of, 713
product theorem, 716–717
Hilbert, David, 705
holomorphic complex function, 449
homogeneous
ordinary diﬀerential eqns, 16–17, 45
solution to ordinary diﬀerential eqn, 66
system of linear eqns, 101
hydraulic potential, 338
hydrostatic equation, 8
hyperbolic partial diﬀerential equation, 297
ideal Hilbert transformer, 703
ideal sampler, 668
imaginary part of a complex number, 441
importance sampling, 833
impulse function
see (Dirac) delta function.
impulse response, 732
inconsistent system of linear eqns, 111
indicial admittance for ordinary
diﬀerential eqns, 733–734
of heat equation, 654
inertia supercharging, 208
initial
-value problem, 45, 597–610
conditions, 300
initial-boundary-value problem, 339
initial-value theorem
for Laplace transforms, 574
for z-transforms, 676
inner product, 99
integral curves, 87

Index
975
integral equation, 731
of convolution type, 592–594
integrals
complex contour, 456–460
Fourier type, evaluation of, 536–537
line, 156–159
real, evaluation of, 477–482
integrating factor, 19
integration of a Fourier series, 200–201
interest rate, 9, 694
inverse
discrete Fourier transform, 226
Fourier transform, 510, 532–542
Hilbert transform, 704
Laplace transform, 581–588, 613–617
z-transform, 681–689
inversion formula
for the Fourier transform, 510
for the Hilbert transform, 704
for the Laplace transform, 613–617
for the z-transform, 681–689
inversion of Fourier transform
by contour integration, 533–542
by direct integration, 532
by partial fraction, 532–533
inversion of Laplace transform
by contour integration, 614–617
by convolution, 588
by partial fractions, 581–583
in amplitude/phase form, 583–587
inversion of z-transform
by contour integration, 685–689
by partial fractions, 683–685
by power series, 681–683
by recursion, 682–683
irrotational, 154
isoclines, 31
isolated singularities, 452
iterative methods
Gauss-Seidel, 429
successive over-relaxation, 432
iterative solution of the radiative
transfer equation, 267–269
Itˆo process, 896
Itˆo’s integral, 916–921
Itˆo’s lemma, 920–928
Itˆo, Kiyhosi, 923
joint transform method, 752
Jordan curve, 460
Jordan’s lemma, 533
Kirchhoﬀ’s law, 24
Klein-Gordon equation, 307
Kramers-Kronig relationship, 721–223
Lagrange’s trigonometric identities, 445
Laguerre polynomial, 596
Laplace integral, 559
Laplace transform, 559–619
basic properties of, 571–577
convolution for, 588–591
deﬁnition of, 559
derivative of, 573
in solving
delay diﬀerential equation, 608–609
heat equation, 637–644
integral eqns, 592–594
Laplace equation, 662–664
wave equation, 619–629
integration of, 574
inverse of, 581–587, 613–617
of derivatives, 562
of periodic functions, 579–581
of the delta function, 568–570
of the step function, 563–565
Schouten-van der Pol theorem for, 619
solving of ordinary
diﬀerential eqns, 597–610
Laplace’s eqn, 385–433, 550–551, 662–664
ﬁnite element solution of, 433
in cylindrical coordinates, 386
in spherical coordinates, 387
numerical solution of, 428–433
solution by Laplace transforms, 662–664
solution by separation
of variables, 388–415
solution on the half-plane, 549–551
Laplace’s expansion in cofactors, 105
Laplace, Pierre-Simon, 387
Laplacian, 153
Laurent expansion, 469
Lax-Wendroﬀscheme, 334
Legendre polynomial, 259
expansion in, 263
generating function for, 260–261
orthogonality of, 263
recurrence formulas, 261
Legendre’s diﬀerential equation, 257
Legendre, Adrien-Marie, 257

976
Advanced Engineering Mathematics with MATLAB
length of a vector, 145
line integral, 156–159, 456–460
line spectrum, 215
linear dependence
of eigenvectors, 124
of functions, 53
linear transformation, 103
linearity
of Fourier transform, 520
of Hilbert transform, 713
of Laplace transform, 561
of z-transform, 674
lines of force, 150
Liouville, Joseph, 241
logistic equation, 12
low-frequency ﬁlter, 738–739
low-pass ﬁlter, 900–902
LU decomposition, 122
magnitude of a vector, 145
Markov chain
state, 867
state transition, 867
time homogeneous, 868
matrices
addition of, 99
equal, 98
multiplication, 99
matrix, 97
algebra, 97
ampliﬁcation, 129
augmented, 112
banded, 102
coeﬃcient, 112
complex, 98
diagonalization, 138
exponential, 139
identity, 98
inverse, 100
invertible, 100
method of stability
of a numerical scheme, 128
nonsingular, 100
null, 98
orthogonal, 123
real, 98
rectangular, 98
square, 98
symmetric, 98
tridiagonal, 102
unit, 98
upper triangular, 102
zero, 98
matrix exponential, 139
maximum principle, 386
Maxwell’s ﬁeld eqns, 156
mean, 828–830
mechanical ﬁlter, 587
meromorphic function, 452
method of partial fractions
for Fourier transform, 532–533
for Laplace transform, 581–587
for z-transform, 683–685
method of undetermined coeﬃcients, 67-70
minor, 105
mixed boundary-value problems, 400–405
modiﬁed Bessel function,
ﬁrst kind, 275
second kind, 275
Euler method, 34–36
modiﬁed Euler method, 34
modulation, 524–527
modulus of a complex number, 442
Monte Carlo integration, 833
multiplication
of complex numbers, 441
of matrices, 99
multivalued complex function, 448
nabla operator, 148
natural vibrations, 306
Neumann problem, 339
Neumann’s Bessel function of order n, 274
Newton’s law of cooling, 351
nonanticipating process, 917
nondivergent, 153
nonhomogeneous
heat equation, 339
ordinary diﬀerential equation, 45
system of linear eqns, 101
norm of a vector, 98, 145
normal diﬀerential equation, 45
normal mode, 306
normal to a surface, 148
not simply connected, 460
numerical solution
of heat equation, 377–383
of Laplace’s equation, 428–433
of stochastic diﬀerential eqn, 936–943
of the wave equation, 326–334

Index
977
Nyquist frequency, 233
Nyquist sampling criteria, 231
one-sided ﬁnite diﬀerence, 326
order
of a matrix, 98
of a pole, 470
orthogonal matrix, 123
orthogonality, 249
of eigenfunctions, 249–251
of eigenvectors, 132
orthonormal eigenfunction, 251
overdamped ordinary diﬀerential eqn, 62
overdetermined system of linear eqns, 116
parabolic partial diﬀerential eqn, 338
Parseval’s equality, 201–202
Parseval’s identity
for Fourier series, 201
for Fourier transform, 527–529
for z-transform, 688
partial fraction expansion
for Fourier transform, 532
for Laplace transform, 581–587
for z-transform, 683–685
particular solution to ordinary
diﬀerential equation, 3, 66
path
in complex integrals, 457
in line integrals, 157
path independence
in complex integrals, 462
in line integrals, 159
permutation, 811
phase, 442
angle in Fourier series, 211–213
diagram, 87
line, 33
path, 87
spectrum, 511
phase of the complex number, 442
phasor amplitude, 721
pivot, 112
pivotal row, 112
Poisson process, 886–891
arrival time, 889
Poisson’s equation, 425–427
integral formula
for a circular disk, 414–415
for upper half-plane, 551
summation formula, 529–532
Poisson’s summation formula, 529
Poisson, Sim´eon-Denis, 426
polar form of a complex number, 442
pole of order n, 470
population growth and decay, 11, 874–883
position vector, 145
positive oriented curve, 463
potential ﬂow theory, 155
potential function, 161–162
power content, 201
power spectrum, 528, 864–867
principal branch, 443
principal diagonal, 98
principle of linear superposition, 50, 303
probability
Bernoulli distribution, 834
Bernoulli trials, 820
binomial distribution, 836
characteristic function, 830
combinations, 811
conditional, 812
continuous joint distribution, 844
correlation, 850
covariance, 848
cumulative distribution, 824
distribution function, 824
event, 806
elementary, 806
simple, 806
expectation, 828
experiment, 805
exponential distribution, 839
Gaussian distribution, 840
geometric distribution, 835
independent events, 814
joint probability mass function, 842
law of total probability, 813
marginal probability functions, 842
mean, 828
normal distribution, 840
permutation, 811
Poisson distribution, 837
probability integral, 841
probability mass function, 818
random variable, 817–818
sample point, 805
sample space, 805
standard normal distribution, 841
uniform distribution, 838

978
Advanced Engineering Mathematics with MATLAB
probability (continued)
variance, 828
QR decomposition, 123
quadrature phase shifting, 703
quieting snow tires, 195–198
radiation condition, 300, 351
radius of convergence, 467
random diﬀerential equation, 897–898
random process, 855–891
autocorrelation function, 860
Bernoulli process, 856
Brownian motion, 905–913
chemical kinetics, 879
counting process, 857
mean, 858
power spectrum, 864
realization, 855
sample function, 855
sample path, 855
state, 855
state space, 855
variance, 858
wide-sense stationary processes, 862
Wiener process, 912–913
random variable, 817
discrete, 818
domain, 817
range, 817
rank of a matrix, 114
real deﬁnite integrals
evaluation of, 477–482
real matrix, 98
real part of a complex number, 441
rectangular matrix, 98
recurrence relation
for Bessel functions, 276–277
for Legendre polynomial, 261–263
in ﬁnite diﬀerencing, 92
reduction in order, 47
regular complex function, 449
regular Sturm-Liouville problem, 240
relaxation methods, 429–433
removable singularity, 470
residue, 469
residue theorem, 472–476
resonance, 75, 219, 600
rest points, 33
Riemann, Georg Friedrich Bernhard, 452
Robin problem, 340
Rodrigues’ formula, 260
root locus method, 737
roots of a complex number, 445–447
row echelon form, 113
row vector, 98
rows of a matrix, 98
Runge, Carl, 38
Runge-Kutta method, 37–40, 93–97
scalar, 145
Schouten-Van der Pol theorem, 619
Schwarz-Christoﬀel transformation, 496–507
Schwarz’ integral formula, 551
second shifting theorem, 565
secular term, 219
separation of variables
for heat equation, 340–366
for Laplace’s equation, 388–415
for ordinary diﬀerential eqns, 4-14
for Poisson’s equation, 425–427
for wave equation, 300–314
set, 804
complement, 804
disjoint, 804
element, 804
empty, 804
intersection, 804
null, 804
subset, 804
union, 804
universal, 804
shifting
in the ω variable, 525
in the s variable, 571
in the t variable, 521, 572
sifting property, 513
simple
eigenvalue, 242
pole, 470
simple harmonic motion, 58, 600
simple harmonic oscillator, 57–61
simply closed curve, 460
sinc function, 511
single side-band signal, 720
single-valued complex function, 448
singular
solutions to ordinary diﬀerential
eqns, 6
Sturm-Liouville problem, 240

Index
979
singular Sturm-Liouville problem, 240
singular value decomposition, 132
singularity
essential, 469
isolated, 469
pole of order n, 470
removable, 470
slope ﬁeld, 31
solenoidal, 153
solution curve, 31
solution of ordinary diﬀerential eqns
by Fourier series, 217–224
by Fourier transform, 547–549, 735–740
space curve, 146
spectral radius, 124
spectrum of a matrix, 124
square matrix, 98
stability of numerical methods
by Fourier method for heat eqn, 379
by Fourier method for wave eqn, 329
by matrix method
for wave equation, 128
steady-state heat equation, 10, 347
steady-state output, 33
steady-state solution to ordinary
diﬀerential eqns, 73
steady-state transfer function, 735
step function, 563–565
step response, 733
stochastic calculus, 895–941
Brownian motion, 906–913
damped harmonic motion, 899–900
derivative, 895
diﬀerential eqns, 928–932
ﬁrst-passage problem, 901–903
integrating factor, 930
Itˆo process, 896
Itˆo’s integral, 916–921
Itˆo’s lemma, 920–928
low-pass ﬁlter, 900–902
nonlinear oscillator, 941
numerical solution, 936–939
Euler-Marugama method, 937
Milstein method, 938
product rule, 926, 929
random diﬀerential eqns, 897–898
RL electrical circuit with noise, 939
wave motion due to random
forcing, 904–906
Wiener process, 913
stochastic process, 855
Stokes’ theorem, 173–178
Stokes, Sir George Gabriel, 174
streamlines, 150
Sturm, Charles-Fran¸cois, 240
Sturm-Liouville
equation, 240
problem, 239–247
subtraction
of complex numbers, 441
of matrices, 99
of vectors, 145
successive over-relaxation, 429
superposition integral, 727
for ordinary diﬀerential eqns, 741
of heat equation, 651–659
superposition principle, 303
surface conductance, 351
surface integral, 162–166
system of linear
diﬀerential eqns, 133–137
homogeneous eqns, 101
nonhomogeneous eqns, 101
tangent vector, 146
Taylor expansion, 467
telegraph equation, 309, 620–629
telegraph signal, 856, 863
terminal velocity, 9, 27
thermal conductivity, 338
threadline equation, 299–300
time shifting, 521, 571
trajectories, 87
transfer function, 732
transform
Fourier, 509–549, 736–740
Hilbert, 703–723
Laplace, 559–619
z-, 667–702
transient solution to ordinary
diﬀerential eqns, 73
transmission line, 620–629
transmission probability matrix, 869
transpose of a matrix, 101
tridiagonal matrix, solution of, 101–102
underdamped, 62
underdetermined system of linear eqns, 113

980
Advanced Engineering Mathematics with MATLAB
uniformitarism, 554
uniqueness of ordinary diﬀerential eqns
nth-order, 46
ﬁrst-order, 3
unit
normal, 149
step function, 563–565
vector, 145
Vandermonde’s determinant, 108
variance, 828–830
variation of parameters, 78–83
vector, 98, 145
vector element of area, 165
vector space, 125
Venn diagram, 804
vibrating string, 297–299
vibrating threadline, 299–300
vibration of ﬂoating body, 60
Volterra equation of the second kind, 592
volume integral, 179–185
wave equation, 297–334, 619–635
damped, 308–311
for a circular membrane, 312–314
for an inﬁnite domain, 318–324
one-dimensional, 299
wave motion due
to random forcing, 904–906
weight function, 249
Wiener process, 860, 913
Wiener, Norbert, 911
Wronskian, 54
z-transform, 667–702
basic properties of, 674–680
convolution for, 678
ﬁnal-value theorem for, 676–677
for solving diﬀerence eqns, 691–697
initial-value theorem for, 676
inverse of, 681–689
linearity of, 674
multiplication by n, 677
of a sequence multiplied by an
exponential sequence, 674
of a shifted sequence, 674–676
of periodic sequences, 677–678
their use in determining
stability, 697–702
zero vector, 145

