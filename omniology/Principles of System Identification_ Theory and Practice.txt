
Using the VitalSource® ebook
Access to the VitalBookTM ebook accompanying this book is 
via VitalSource® Bookshelf – an ebook reader which allows 
you to make and share notes and highlights on your ebooks 
and search across all of the ebooks that you hold on your 
VitalSource Bookshelf. You can access the ebook online or 
offline on your smartphone, tablet or PC/Mac and your notes 
and highlights will automatically stay in sync no matter where 
you make them.
1.	 Create a VitalSource Bookshelf account at  
https://online.vitalsource.com/user/new or log into 
your existing account if you already have one.
2.	 Redeem the code provided in the panel below 
to get online access to the ebook. Log in to 
Bookshelf and click the Account menu at the top right 
of the screen. Select Redeem and enter the redemption 
code shown on the scratch-off panel below in the Code 
To Redeem box. Press Redeem. Once the code has 
been redeemed your ebook will download and appear in 
your library.
DOWNLOAD AND READ OFFLINE 
To use your ebook offline, download BookShelf to your PC, 
Mac, iOS device, Android device or Kindle Fire, and log in to 
your Bookshelf account to access your ebook:
On your PC/Mac
Go to http://bookshelf.vitalsource.com/ and follow the 
instructions to download the free VitalSource Bookshelf  
app to your PC or Mac and log into your Bookshelf account.
On your iPhone/iPod Touch/iPad 
Download the free VitalSource Bookshelf App available 
via the iTunes App Store and log into your Bookshelf 
account. You can find more information at https://support.
vitalsource.com/hc/en-us/categories/200134217-
Bookshelf-for-iOS
On your Android™ smartphone or tablet
Download the free VitalSource Bookshelf App available 
via Google Play and log into your Bookshelf account. You can 
find more information at https://support.vitalsource.com/
hc/en-us/categories/200139976-Bookshelf-for-Android-
and-Kindle-Fire
On your Kindle Fire
Download the free VitalSource Bookshelf App available 
from Amazon and log into your Bookshelf account. You can 
find more information at https://support.vitalsource.com/
hc/en-us/categories/200139976-Bookshelf-for-Android-
and-Kindle-Fire
N.B. The code in the scratch-off panel can only be used once. 
When you have created a Bookshelf account and redeemed 
the code you will be able to access the ebook online or offline 
on your smartphone, tablet or PC/Mac.
SUPPORT
If you have any questions about downloading Bookshelf, 
creating your account, or accessing and using your ebook 
edition, please visit http://support.vitalsource.com/
Accessing the E-book edition  

PRINCIPLES OF 
SYSTEM IDENTIFICATION
Theory and Practice

This page intentionally left blank
This page intentionally left blank

PRINCIPLES OF 
SYSTEM IDENTIFICATION
Arun K. Tangirala
Theory and Practice

MATLAB® is a trademark of The MathWorks, Inc. and is used with permission. The MathWorks does not warrant the 
accuracy of the text or exercises in this book. This book’s use or discussion of MATLAB® software or related products 
does not constitute endorsement or sponsorship by The MathWorks of a particular pedagogical approach or particular 
use of the MATLAB® software.
CRC Press
Taylor & Francis Group
6000 Broken Sound Parkway NW, Suite 300
Boca Raton, FL 33487-2742
© 2015 by Taylor & Francis Group, LLC
CRC Press is an imprint of Taylor & Francis Group, an Informa business
No claim to original U.S. Government works
Version Date: 20141118
International Standard Book Number-13: 978-1-4398-9602-0 (eBook - PDF)
This book contains information obtained from authentic and highly regarded sources. Reasonable efforts have been 
made to publish reliable data and information, but the author and publisher cannot assume responsibility for the valid-
ity of all materials or the consequences of their use. The authors and publishers have attempted to trace the copyright 
holders of all material reproduced in this publication and apologize to copyright holders if permission to publish in this 
form has not been obtained. If any copyright material has not been acknowledged please write and let us know so we may 
rectify in any future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, transmitted, or uti-
lized in any form by any electronic, mechanical, or other means, now known or hereafter invented, including photocopy-
ing, microfilming, and recording, or in any information storage or retrieval system, without written permission from the 
publishers.
For permission to photocopy or use material electronically from this work, please access www.copyright.com (http://
www.copyright.com/) or contact the Copyright Clearance Center, Inc. (CCC), 222 Rosewood Drive, Danvers, MA 01923, 
978-750-8400. CCC is a not-for-profit organization that provides licenses and registration for a variety of users. For 
organizations that have been granted a photocopy license by the CCC, a separate system of payment has been arranged.
Trademark Notice: Product or corporate names may be trademarks or registered trademarks, and are used only for 
identification and explanation without intent to infringe.
Visit the Taylor & Francis Web site at
http://www.taylorandfrancis.com
and the CRC Press Web site at
http://www.crcpress.com

Dedication
To
My Parents
Smt. T. Rajyalakshmi and (the Late) Sri T. Subrahmanyam

vi
अ"ान तi म
िरा*ध,य "ान.जन शलाकया |
च4u6*मील
ित8 9न त,: ;ी गuर= नम: ||
I oﬀer my respectful obeisances unto my Guru, who
has opened my eyes that were blinded by the
darkness of ignorance, with an instrument coated in
the ointment of knowledge.
- From the Vedas
ॐ सह ना ववतu  |
सह नाै भuन+तu  |
सह वी-य करवाव1 |
2ज4व
ि
 नावध
i तम4तu मा व
i
9i षi व1 |
ॐ श< तi : श< तi : श< तi : ||
Om, May God Protect us Both
(the Teacher and the Student),
May God Nourish us Both,
May we Work Together with Energy and Vigour,
May our Study be Enlightening and not give rise to Hostility,
Om, Peace, Peace, Peace.
- From the Upanishads

Contents
Foreword .........................................................................................................................................xix
Preface.............................................................................................................................................xxi
List of Figures..............................................................................................................................xxvii
List of Tables...............................................................................................................................xxxiii
PART I
INTRODUCTION TO IDENTIFICATION AND MODELS FOR LINEAR
DETERMINISTIC SYSTEMS
Chapter 1
Introduction ..................................................................................................................2
1.1
Motivation..........................................................................................................................2
1.2
Historical developments ....................................................................................................8
1.3
System Identiﬁcation.......................................................................................................13
1.3.1
Three Facts of Identiﬁcation..............................................................................14
1.3.2
Notion of a Model .............................................................................................15
1.3.3
Quantitative vs. Qualitative Models ..................................................................17
1.3.3.1
Deterministic vs. Stochastic Models ................................................18
1.3.3.2
Non-Parametric vs. Parametric Models............................................18
1.4
Systematic identiﬁcation .................................................................................................19
1.4.1
Data Generation and Acquisition ......................................................................19
1.4.2
Data Pre-Processing...........................................................................................21
1.4.3
Data Visualization .............................................................................................22
1.4.4
Model Development ..........................................................................................22
1.4.5
Model Assessment and Validation.....................................................................24
1.4.6
Prior Process Knowledge...................................................................................24
1.4.7
Suggestions for Obtaining a Good Model.........................................................25
1.5
Flow of learning material ................................................................................................26
1.6
Software...........................................................................................................................29
Chapter 2
A Journey into Identiﬁcation......................................................................................31
2.1
Identiﬁability ...................................................................................................................31
2.2
Signal-to-Noise ratio .......................................................................................................34
2.3
Overﬁtting........................................................................................................................35
2.4
A modeling example: liquid level system .......................................................................38
2.4.1
The Physical Process .........................................................................................38
2.4.2
Data Generation.................................................................................................38
2.4.3
Data Visualization and Preliminary Analysis....................................................40
vii

viii
Contents
2.4.4
Building Non-Parametric Models......................................................................41
2.4.5
Building Parametric Models..............................................................................43
2.4.6
Goodness of the Model......................................................................................45
2.4.7
Developing a State-Space Model ......................................................................50
2.5
Reﬂections and summary ................................................................................................53
Chapter 3
Mathematical Descriptions of Processes: Models......................................................56
3.1
Deﬁnition of a model.......................................................................................................56
3.2
Classiﬁcation of models ..................................................................................................57
3.2.1
Types of Models ................................................................................................58
3.2.2
Models for Identiﬁcation ...................................................................................66
Chapter 4
Models for Discrete-Time LTI Systems.....................................................................68
4.1
Convolution model ..........................................................................................................68
4.1.1
Impulse Response..............................................................................................69
4.2
Response models .............................................................................................................72
4.2.1
Finite Impulse Response (FIR) Model ..............................................................72
4.2.2
Step Response Model ........................................................................................73
4.2.3
Frequency Response Model ..............................................................................75
4.3
Diﬀerence equation form ................................................................................................79
4.3.1
Motivating Remarks ..........................................................................................79
4.3.2
Parametrization of Impulse Response ...............................................................80
4.3.3
Transfer Function Operator ...............................................................................81
4.3.4
Stability and Poles.............................................................................................84
4.4
State-space descriptions...................................................................................................86
4.4.1
Background........................................................................................................86
4.4.2
State Variable.....................................................................................................87
4.4.3
State-Space Models ...........................................................................................90
4.4.3.1
Forms of State-Space Representations.............................................92
4.4.4
State-space ↔Transfer Function Operator Form..............................................98
4.5
Illustrative example in MATLAB: estimating LTI models............................................101
4.5.1
Data Generation...............................................................................................101
4.5.2
Estimation of FIR Model.................................................................................102
4.5.3
Estimation of Step-Response Model ...............................................................102
4.5.4
Estimation of Diﬀerence Equation Model.......................................................103
4.5.5
Estimation of a State-Space Model .................................................................104
4.6
Summary........................................................................................................................107
Chapter 5
Transform-Domain Models for Linear TIme-Invariant Systems .............................109
5.1
Frequency response function.........................................................................................109
5.1.1
Characteristics of FRF.....................................................................................109
5.2
Transfer function form...................................................................................................112
5.2.1
Response to Damped Oscillatory Signals........................................................112
5.2.2
z-Transforms....................................................................................................113

Contents
ix
5.2.2.1
Properties of z-Transforms.............................................................115
5.2.3
Transfer Functions...........................................................................................117
5.2.3.1
FRF: Special Case of Transfer Function ........................................121
5.3
Empirical transfer function (ETF).................................................................................123
5.4
Closure...........................................................................................................................125
Chapter 6
Sampling and Discretization ....................................................................................129
6.1
Discretization.................................................................................................................129
6.1.1
Sampled-Data System .....................................................................................131
6.1.2
Zero-Order Hold..............................................................................................131
6.1.3
Sampler............................................................................................................132
6.1.4
State-Space Approach .....................................................................................133
6.1.5
Transfer Function Approach............................................................................136
6.2
Sampling........................................................................................................................141
6.2.1
Choice of Sampling Rate.................................................................................142
6.2.2
Sampling Theorem ..........................................................................................144
6.2.3
Practical Guidelines for Sampling...................................................................146
6.3
Summary........................................................................................................................147
PART II
MODELS FOR RANDOM PROCESSES
Chapter 7
Random Processes....................................................................................................151
7.1
Introductory remarks .....................................................................................................151
7.2
Random variables and probability.................................................................................152
7.3
Probability theory..........................................................................................................153
7.3.1
Probability Distribution Functions ..................................................................154
7.4
Statistical properties of random variables .....................................................................158
7.4.1
Mean and Variance ..........................................................................................158
7.4.2
Multivariate Case.............................................................................................163
7.4.2.1
Covariance and Correlation............................................................165
7.4.3
Partial Correlation ...........................................................................................169
7.5
Random signals and processes .....................................................................................171
7.5.1
Deﬁnitions .......................................................................................................171
7.5.2
Notion of Realization ......................................................................................173
7.5.3
Statistical Properties........................................................................................175
7.5.4
Stationarity ......................................................................................................176
7.5.5
Non-Stationarities............................................................................................178
7.5.6
Ergodicity ........................................................................................................181
7.6
Time-series analysis ......................................................................................................182
7.7
Summary........................................................................................................................184
Chapter 8
Time-Domain Analysis: Correlation Functions .......................................................186
8.1
Motivation......................................................................................................................186
8.2
Auto-covariance function .............................................................................................187

x
Contents
8.2.1
Auto-Correlation Function (ACF)...................................................................187
8.3
White-noise process.......................................................................................................190
8.3.1
Theoretical ACFs of Elementary Processes ....................................................192
8.4
Cross-covariance function ............................................................................................195
8.4.1
Properties and Uses of CCF ............................................................................196
8.5
Partial correlation functions ..........................................................................................198
8.5.1
Partial ACF......................................................................................................198
8.5.2
Partial CCF ......................................................................................................201
8.6
Summary........................................................................................................................202
Chapter 9
Models for Linear Stationary Processes...................................................................204
9.1
Motivation......................................................................................................................204
9.2
Basic ideas.....................................................................................................................205
9.3
Linear stationary processes............................................................................................207
9.3.1
Non-Uniqueness of Time-Series Models ........................................................209
9.4
Moving average models.................................................................................................210
9.4.1
ACVF Signature of an MA Process ................................................................210
9.4.2
Invertibility of an MA Process ........................................................................212
9.5
Auto-regressive models .................................................................................................215
9.5.1
Stationary Representations ..............................................................................216
9.5.2
ACF of AR Processes......................................................................................217
9.5.3
Order Determination and PACF ......................................................................220
9.5.4
Alternative Representations of the AR Process...............................................222
9.5.5
Equivalence Between AR and MA Representations .......................................224
9.6
Auto-regressive moving average models ......................................................................226
9.7
Auto-regressive integrated moving average models......................................................227
9.8
Summary........................................................................................................................234
Chapter 10 Fourier Analysis and Spectral Analysis of Deterministic Signals ...........................238
10.1
Motivation......................................................................................................................238
10.2
Deﬁnitions .....................................................................................................................242
10.2.1
Periodic and Aperiodic signals........................................................................242
10.2.2
Energy and Power Signals...............................................................................243
10.2.3
Cross-Covariance Functions for Deterministic Signals...................................244
10.3
Fourier representations of deterministic processes........................................................248
10.3.1
Fourier Series...................................................................................................249
10.3.2
Power Spectrum...............................................................................................250
10.3.3
Fourier Transform............................................................................................251
10.3.4
Discrete-Time Fourier Series...........................................................................253
10.3.5
Discrete-Time Fourier Transform....................................................................255
10.3.6
Properties of DTFT..........................................................................................258
10.4
Discrete Fourier Transform (DFT)................................................................................262
10.4.1
Spectrum and Spectral Density .......................................................................266
10.5
Summary........................................................................................................................267

Contents
xi
Chapter 11 Spectral Representations of Random Processes.......................................................270
11.1
Introduction ...................................................................................................................270
11.2
Power spectral density of a random process..................................................................271
11.2.1
PSD from Ensemble Averaging.......................................................................272
11.2.2
PSD from Auto-Covariance Function .............................................................274
11.2.2.1
Random Periodic Process...............................................................277
11.2.3
Wiener Representations and PSD....................................................................281
11.3
Spectral characteristics of standard processes...............................................................282
11.3.1
White Noise Process........................................................................................282
11.3.2
Spectral Density of ARMA Process: Colored Noise.......................................283
11.4
Cross-spectral density and coherence............................................................................287
11.5
Partial coherence............................................................................................................293
11.6
Spectral factorization.....................................................................................................295
11.7
Summary........................................................................................................................301
PART III
ESTIMATION METHODS
Chapter 12 Introduction to Estimation........................................................................................305
12.1
Motivation......................................................................................................................305
12.2
A simple example: constant embedded in noise............................................................305
12.3
Deﬁnitions and terminology..........................................................................................307
12.3.1
Goodness of Estimators...................................................................................309
12.4
Types of estimation problems........................................................................................310
12.4.1
Signal Estimation.............................................................................................310
12.4.2
Parameter Estimation.......................................................................................312
12.4.3
State Estimation...............................................................................................313
12.4.4
Other Classiﬁcations........................................................................................313
12.5
Estimation methods .......................................................................................................314
12.6
Historical notes..............................................................................................................315
Chapter 13 Goodness of Estimators............................................................................................317
13.1
Introduction ...................................................................................................................317
13.2
Fisher information .........................................................................................................318
13.3
Bias................................................................................................................................322
13.4
Variance .........................................................................................................................322
13.4.1
Minimum Variance Unbiased Estimator .........................................................325
13.5
Eﬃciency ......................................................................................................................325
13.6
Suﬃciency .....................................................................................................................326
13.7
Cramer-Rao’s inequality................................................................................................326
13.7.1
Best Linear Unbiased Estimator......................................................................331
13.8
Asymptotic bias.............................................................................................................332
13.9
Mean square error..........................................................................................................333
13.9.1
Minimum Mean-Square Estimator..................................................................334
13.10 Consistency....................................................................................................................334

xii
Contents
13.11 Distribution of estimates................................................................................................336
13.11.1 Central Limit Theorem....................................................................................337
13.12 Hypothesis testing and conﬁdence intervals..................................................................338
13.12.1 Hypothesis Testing ..........................................................................................339
13.12.2 Conﬁdence Regions.........................................................................................342
13.13 Empirical methods for hypothesis testing .....................................................................345
13.14 Summary........................................................................................................................346
13.A Appendix .......................................................................................................................347
13.A.1
Proof of Cramer-Rao Inequality......................................................................347
Chapter 14 Estimation Methods: Part I.......................................................................................350
14.1
Introduction ...................................................................................................................350
14.2
Method of moments estimators .....................................................................................351
14.2.1
Basic Idea ........................................................................................................351
14.3
Least squares estimators................................................................................................355
14.3.1
Ordinary Least Squares ...................................................................................355
14.3.2
Goodness of LS Fits ........................................................................................362
14.3.3
Properties of the LS Estimator ........................................................................365
14.3.4
Computing the Linear LS Estimate.................................................................373
14.3.5
Weighted Least Squares...................................................................................376
14.3.6
Other Variants of Linear LS ............................................................................381
14.4
Non-linear least squares ................................................................................................382
14.4.1
Numerical Methods for Optimization .............................................................384
14.4.2
Special Cases...................................................................................................386
14.4.2.1
Linear in Parameters.......................................................................387
14.4.2.2
Linear via Transformation..............................................................387
14.4.2.3
Pseudo-Linear Regression..............................................................388
14.4.2.4
Algorithmic Aspects of NLS Methods...........................................388
14.4.3
Asymptotic Properties of the NLS Estimator..................................................389
14.5
Summary........................................................................................................................393
14.A Appendix .......................................................................................................................394
14.A.1
Projection Theorem .........................................................................................394
14.A.2
Decomposition Theorem .................................................................................394
14.A.3
QR Factorization .............................................................................................395
14.A.4
Singular Value Decomposition........................................................................396
Chapter 15 Estimation Methods: Part II .....................................................................................400
15.1
Maximum likelihood estimators ...................................................................................400
15.1.1
Estimation of Mean and Variance: GWN........................................................403
15.1.2
Estimation of an ARX Model..........................................................................405
15.1.3
Computing the MLE........................................................................................409
15.1.4
Properties of the ML Estimator .......................................................................410
15.2
Bayesian estimators.......................................................................................................411
15.2.1
Linear Bayesian MMSE ..................................................................................416
15.3
Summary........................................................................................................................417

Contents
xiii
Chapter 16 Estimation of Signal Properties................................................................................419
16.1
Introduction ...................................................................................................................419
16.2
Estimation of mean and variance ..................................................................................419
16.2.1
Estimators of Mean..........................................................................................420
16.2.2
Estimation of Variance ....................................................................................422
16.3
Estimators of correlation ...............................................................................................424
16.3.1
Estimators of Partial Correlation.....................................................................425
16.4
Estimation of correlation functions ...............................................................................426
16.5
Estimation of auto-power Spectra .................................................................................433
16.5.1
Periodogram ....................................................................................................434
16.5.2
Finite-Length Eﬀects in Direct DFT Methods ................................................434
16.5.2.1
Spectral Leakage ............................................................................434
16.5.3
Remedies: Window Functions.........................................................................438
16.5.4
Estimation of Spectra for Stochastic Signals...................................................445
16.5.5
Periodogram Estimator....................................................................................445
16.5.5.1
Properties of Periodogram as a PSD Estimator for Stochastic
Signals ............................................................................................445
16.5.6
Averaged (Smoothed) Periodogram Estimators ..............................................451
16.5.7
Parametric Methods ........................................................................................461
16.5.8
Subspace Decomposition-Based Methods ......................................................464
16.6
Estimation of cross-spectral density..............................................................................466
16.7
Estimation of coherence ................................................................................................468
16.8
Summary........................................................................................................................473
PART IV
IDENTIFICATION OF DYNAMIC MODELS - CONCEPTS AND
PRINCIPLES
Chapter 17 Non-Parametric and Parametric Models for Identiﬁcation ......................................479
17.1
Introduction ...................................................................................................................479
17.2
The overall model..........................................................................................................479
17.3
Quasi-stationarity ..........................................................................................................480
17.4
Non-parametric descriptions ........................................................................................484
17.4.1
Time-Domain Descriptions .............................................................................484
17.4.1.1
FIR Models.....................................................................................485
17.4.1.2
Step Response Models ...................................................................485
17.4.2
Frequency-Domain Descriptions.....................................................................486
17.5
Parametric descriptions .................................................................................................486
17.5.1
Equation-Error Models....................................................................................488
17.5.1.1
ARX Family ...................................................................................488
17.5.1.2
ARMAX Family.............................................................................489
17.5.1.3
ARIMAX Models...........................................................................491
17.5.2
Output-Error Family........................................................................................492
17.5.3
Box-Jenkins Family.........................................................................................494
17.5.4
Selecting an Appropriate Model Structure......................................................496
17.6
Summary........................................................................................................................497

xiv
Contents
Chapter 18 Predictions ...............................................................................................................499
18.1
Introduction ...................................................................................................................499
18.2
Conditional expectation and linear predictors...............................................................500
18.2.1
Best Linear Predictor.......................................................................................502
18.3
One-step ahead prediction and innovations...................................................................505
18.3.1
Predictions of the Stochastic Process ..............................................................505
18.3.2
Predictions of the Overall LTI System ............................................................506
18.4
Multi-step and inﬁnite-step ahead predictions ..............................................................507
18.5
Predictor model: An alternative LTI description...........................................................512
18.5.1
Model Sets and Structures...............................................................................513
18.6
Identiﬁability .................................................................................................................514
18.6.1
Model Identiﬁability........................................................................................514
18.6.2
Identiﬁable LTI Black-Box Structures ............................................................514
18.6.3
System Identiﬁability.......................................................................................517
18.7
Summary........................................................................................................................518
Chapter 19 Identiﬁcation of Parametric Time-Series Models.....................................................520
19.1
Introduction ...................................................................................................................520
19.2
Estimation of AR models ..............................................................................................520
19.2.1
Y-W Method ....................................................................................................521
19.2.2
Least Squares / Covariance Method ................................................................524
19.2.3
Modiﬁed Covariance Method..........................................................................525
19.2.4
Burg’s Method.................................................................................................526
19.2.5
ML Estimator...................................................................................................529
19.3
Estimation of MA models .............................................................................................529
19.4
Estimation of ARMA models........................................................................................531
19.4.1
Non-linear LS Estimation................................................................................531
19.4.2
Maximum Likelihood Estimation....................................................................533
19.4.3
Properties of the NLS and ML estimators.......................................................536
19.4.4
Estimation of ARIMA Models........................................................................539
19.5
Summary........................................................................................................................539
Chapter 20 Identiﬁcation of Non-Parametric Input-Output Models...........................................542
20.1
Recap .............................................................................................................................542
20.2
Impulse response estimation .........................................................................................542
20.2.1
Direct Estimation using Impulse Inputs ..........................................................543
20.2.2
Estimation from Response to Arbitrary inputs................................................543
20.2.2.1
Diagonalization: Pre-Whitening the Input .....................................545
20.2.3
Regularization and Including Prior Knowledge ..............................................548
20.2.4
Estimation of IR Coeﬃcients from Frequency Response Data.......................552
20.2.5
Indirect Estimation from Parametric Models ..................................................552
20.3
Step response estimation ...............................................................................................553
20.4
Estimation of frequency response function ..................................................................554
20.4.1
Sinusoidal Input-Based Estimation .................................................................554

Contents
xv
20.4.2
ETFE................................................................................................................556
20.4.3
Estimation from Spectral Densities: Spectral Analysis (SPA) ........................558
20.4.4
Smoothed Estimates ........................................................................................560
20.4.4.1
Smoothing the ETFE......................................................................561
20.4.4.2
From Smoothed PSD Estimates .....................................................561
20.4.4.3
Welch’s Averaged Approach ..........................................................563
20.5
Estimating the disturbance spectrum.............................................................................563
20.6
Summary........................................................................................................................565
Chapter 21 Identiﬁcation of Parametric Input-Output Models...................................................568
21.1
Recap .............................................................................................................................568
21.2
Prediction-error minimization (PEM) methods.............................................................569
21.3
Properties of the PEM estimator....................................................................................573
21.3.1
Consistency of PEM Estimators......................................................................575
21.4
Variance and distribution of PEM-QC estimators.........................................................581
21.5
Accuracy of parametrized FRF estimates using PEM...................................................585
21.6
Algorithms for estimating speciﬁc parametric models..................................................589
21.6.1
Estimating ARX Models .................................................................................590
21.6.1.1
AUDI: Estimating Several ARX Models Simultaneously..............591
21.6.2
Estimating ARMAX Models...........................................................................593
21.6.2.1
Pseudo-Linear Regression Method for ARMAX...........................596
21.6.3
Estimating OE Models ....................................................................................597
21.6.3.1
Stieglitz-McBride Algorithm .........................................................599
21.6.4
Estimating BJ Models......................................................................................601
21.7
Correlation methods ......................................................................................................603
21.7.1
Instrumental Variable (IV) Methods................................................................604
21.7.2
Properties of the IV Estimator.........................................................................606
21.7.3
Multistage IV (IV4) Method ...........................................................................607
21.8
Summary........................................................................................................................608
Chapter 22 Statistical and Practical Elements of Model Building..............................................611
22.1
Introduction ...................................................................................................................611
22.2
Informative Data............................................................................................................612
22.2.1
Persistent Excitation........................................................................................613
22.3
Input design for identiﬁcation .......................................................................................614
22.3.1
Pseudo-Random Binary Sequences.................................................................615
22.3.2
Preliminary Tests for Input Design..................................................................618
22.4
Data pre-processing.......................................................................................................618
22.4.1
Oﬀsets, Drifts and Trends................................................................................619
22.4.2
Outliers and Missing Data...............................................................................621
22.4.3
Pre-Filtering.....................................................................................................633
22.4.4
Partitioning the Data........................................................................................635
22.5
Time-delay estimation ...................................................................................................635
22.5.1
Deﬁnitions .......................................................................................................635
22.5.2
Impulse Response Estimation Method............................................................636
22.5.3
Frequency-Domain Estimation Method ..........................................................637

xvi
Contents
22.5.4
Model-based Estimation Method ....................................................................641
22.6
Model development .......................................................................................................642
22.6.1
Model Structure Selection ...............................................................................643
22.6.2
Options in Parametric Modeling .....................................................................644
22.6.3
Order Determination........................................................................................646
22.6.4
Model Quality Assessment and Validation......................................................648
22.7
Summary........................................................................................................................653
Chapter 23 Identiﬁcation of State-Space Models .......................................................................656
23.1
Introduction ..................................................................................................................656
23.2
Mathematical essentials and basic ideas........................................................................660
23.2.1
Basic Approach ...............................................................................................661
23.2.2
Observability and Controllability....................................................................661
23.3
Kalman ﬁlter..................................................................................................................663
23.3.1
Extended Kalman Filter and the Unscented KF..............................................671
23.3.2
Innovations Form.............................................................................................673
23.4
Foundations for subspace identiﬁcation ........................................................................674
23.4.1
Extended Observability Matrix .......................................................................675
23.4.2
Realization Methods........................................................................................676
23.4.2.1
Estimation from IR: Ho and Kalman Method................................676
23.4.2.2
Kung’s Method...............................................................................679
23.5
Preliminaries for subspace identiﬁcation methods........................................................681
23.5.1
Subspaces, Projections and Implementations..................................................682
23.6
Subspace identiﬁcation algorithms................................................................................685
23.6.1
Deterministic Systems.....................................................................................685
23.6.1.1
MOESP Method .............................................................................687
23.6.1.2
N4SID Method ...............................................................................690
23.6.2
Deterministic-plus-Stochastic Systems ...........................................................693
23.6.2.1
Numerical Kalman State Estimates................................................694
23.6.2.2
Statistical Interpretations of Projections ........................................695
23.6.2.3
MOESP and N4SID Methods for the Full Case.............................697
23.6.2.4
CVA Method...................................................................................700
23.6.2.5
Uniﬁed Algorithm ..........................................................................701
23.6.2.6
Estimation of System Matrices, Noise Covariance and Kalman
Gain ................................................................................................702
23.6.2.7
Interpreting SSID Methods in the PE Framework .........................706
23.7
Structured state-space models .......................................................................................708
23.7.1
Parametrized Linear Black-Box Models .........................................................709
23.7.2
Grey-Box Identiﬁcation...................................................................................712
23.7.2.1
Grey-Box Modeling of a Two-Tank System ..................................712
23.8
Summary........................................................................................................................715
Chapter 24 Case Studies .............................................................................................................718
24.1
ARIMA model of industrial dryer temperature.............................................................718
24.1.1
Process Data ....................................................................................................718
24.1.2
Building the Time-Series Model .....................................................................718

Contents
xvii
24.2
Simulated process: developing an input-output model..................................................723
24.2.1
Data Generation...............................................................................................724
24.2.2
Data Pre-Processing.........................................................................................724
24.2.3
Non-Parametric Analysis.................................................................................725
24.2.4
Parametric Model Development......................................................................727
24.2.5
Model Quality Assessment..............................................................................729
24.2.6
Parametric Model along the OE Route............................................................731
24.3
Process with random walk noise ...................................................................................733
24.3.1
Visual Analysis................................................................................................733
24.3.2
Non-Parametric Estimates...............................................................................733
24.3.3
Parametric Input-Output Model ......................................................................735
24.4
Multivariable modeling of a four-tank system ..............................................................740
24.4.1
Process Description .........................................................................................740
24.4.2
Data Acquisition..............................................................................................742
24.4.3
Data Pre-Processing and Non-Parametric Analysis ........................................742
24.4.4
Development of a State-Space Model .............................................................743
24.4.5
Transfer Function Models for the MIMO system ...........................................747
24.4.5.1
Approach I: Using the Full SS Model............................................747
24.4.5.2
Approach II: Using the MOESP Model .........................................748
24.5
Summary........................................................................................................................752
PART V
ADVANCED CONCEPTS
Chapter 25 Advanced Topics in SISO Identiﬁcation ..................................................................755
25.1
Identiﬁcation of linear time-varying systems................................................................755
25.1.1
WLS Methods with Forgetting Factor.............................................................757
25.1.2
Recursive Methods ..........................................................................................757
25.1.3
Recursive Weighted Least Squares..................................................................761
25.1.4
Recursive PEM Algorithm ..............................................................................764
25.1.5
Wavelet-Based Approaches ............................................................................766
25.1.5.1
Wavelet Transforms........................................................................767
25.1.5.2
Identiﬁcation of LTV Systems Using Wavelets..............................774
25.2
Non-linear identiﬁcation................................................................................................776
25.2.1
Neural Network Models .................................................................................778
25.2.2
Fuzzy Models ..................................................................................................779
25.2.3
Dynamic Non-Linear Models: NARX ...........................................................780
25.2.4
Simpliﬁed Non-linear Models.........................................................................780
25.2.4.1
Volterra Models..............................................................................781
25.2.4.2
Hammerstein and Wiener Models..................................................781
25.3
Closed-loop identiﬁcation .............................................................................................783
25.3.1
Closed-Loop Identiﬁcation Techniques...........................................................785
25.4
Summary........................................................................................................................787
Chapter 26 Linear Multivariable Identiﬁcation...........................................................................790
26.1
Motivation......................................................................................................................790
26.2
Estimation of time delays in MIMO systems................................................................791

xviii
Contents
26.3
Principal component analysis (PCA).............................................................................795
26.3.1
Motivating Example: Linear Algebra Perspective...........................................795
26.3.2
Statistical Approach.........................................................................................800
26.3.2.1
Population Version .........................................................................800
26.3.2.2
Sample Version Formulation of PCA.............................................802
26.3.3
Rank Determination and Modeling using Iterative PCA.................................804
26.3.3.1
Iterative PCA..................................................................................804
26.3.3.2
Example 1: Flow Mixing................................................................808
26.3.3.3
Example 2: Continuously Stirred Tank Heater...............................810
26.4
Summary........................................................................................................................812
References......................................................................................................................................814
Index ..............................................................................................................................................829

Foreword
System Identiﬁcation is an ever-present interface between the real world and the mathematical world
of models for signals and systems used in control, signal processing and systems theory. It has its
early historic roots in the work of Gauss and Bayes in the eighteenth and nineteenth century and
became an established research area in Automatic Control in the mid-1960s. The 1960s and 1970s
was a bursting time of inventing new algorithms in the area. One can notice a dip in activities in the
late 1980s when it was even suggested then to discontinue the IFAC series on symposia on System
Identiﬁcation. Since then, we have seen a remarkable revival of interest in the subject. Scopus lists
over 20,000 publications in 2013 with the term “System Identiﬁcation” either in the title or in
the abstract. It is natural to trace this renewed interest to the exploding access to sensor and data
information as well as to computing power.
So it is important to welcome the comprehensive and up-to-date treatment of the area in the
present book by Professor Arun K. Tangirala. The text is extensive, but the division into clear parts
will make it easy both for course work and self-studies to structure the material appropriately. The
author has in his Preface discussed how this can be done eﬃciently.
Mastering System Identiﬁcation techniques has an element of experience, creativity and inspira-
tion, in addition to the knowledge and understanding of available techniques. In this sense, System
Identiﬁcation is as much an art as a science. Therefore, I am very pleased to see that the book
contains ample reference to code, such as the MATLAB System Identiﬁcation Toolbox, for illus-
tration and training. There is no better way to master the area than getting hands-on experience on
the methods applied to real data. So I encourage the readers to take these opportunities to deeper
understanding and experience and wish them an interesting and enjoyable journey with this book.
Lennart Ljung
xix

This page intentionally left blank
This page intentionally left blank

Preface
System Identiﬁcation is concerned with developing mathematical models from observed data, and
therefore a subject based on observational (data) science. It is at the heart of all data-driven or
measurement-based process operations, namely, design, control and monitoring where models play
a critical role. The idea of learning from observations is timeless. The technicalities of this subject as
we see today, however, have its seeds in some of the eighteenth and nineteenth century mathematics
and probability theory. It has now grown into a remarkably vast tree with several branches and sub-
branches. This text is designed to provide a knowledge of the grassroots and a bird’s eye view of the
tree while mostly dwelling on one branch called the linear system identiﬁcation. A quick tour of a
few far oﬀ(advanced) branches is presented in the ﬁnal part of the text.
The prime motivation for authoring this book comes from my own experience and initial ex-
posure to this subject during my graduate days at the University of Alberta, Canada, when I felt
the need for a classroom textbook on this subject that is both self-contained and illustrative. Iden-
tiﬁcation is fascinating because one could discover working mathematical relationships (models)
between variables purely (well, largely) from data! However, the sea of terminology that one has to
swim through and the need for foundations in probability, estimation and systems theory makes the
learning curve quite steep. In order to build models from data it is necessary to understand what class
of models are suited for a given process and be equipped to handle uncertainties in data. Addition-
ally, and importantly, a sound knowledge of estimation theory is required to obtain an eﬃcient and
consistent estimate of the model. Finally, when the theory is put into practice, the user’s intuition
and creativity plays an important role in arriving at a good working model. Thus, as it is popularly
known, System Identiﬁcation is both a science and an art.
Over the last fourteen years of teaching this subject, or rather learning, I have had a wonderful
opportunity to make my way to the foundations of this subject as a learner; and equally importantly,
as a teacher to fathom the level at which an average student of a course on System Identiﬁcation is
positioned. There was a strong case for developing a one-stop resource for identiﬁcation. A reader,
especially a beginner, should not have the need to hop, skip and jump across texts for foundations
and eventually get entangled in the notational conﬂicts, to say the least.
The primary audience for this book is therefore that student who has had a minimal or zero
exposure to any of the founding subjects, but is still keen on learning how to systematically build
models from data using a single resource. As a learned friend and former colleague of mine once
advised me, “write the text for students and not necessarily for teachers” I have tried to faithfully
follow this advice while still keeping the instructor’s expectations in mind. This partly explains why
the book is organized the way it is and why half of it is devoted to foundations, namely, systems
theory, modeling of stochastic processes and estimation theory. These topics do add to the volume
of text, but one cannot ignore the pillars in the process of constructing the dome!
Engineering curricula in general are rarely designed to oﬀer even near suﬃcient knowledge or
the skill set required for understanding the subject of System Identiﬁcation. A key shortcoming is
the lack of training in handling randomness or uncertainties in data. Statistical and mathematical
courses are taken at early stages and promptly forgotten primarily because they are not necessarily
taught in a context. In my own interactions with students / participants of short-term courses and
workshops across the globe, I recognize that students rarely had opportunities to sit through the
founding courses or even if they did, it was necessary to re-visit those concepts in the context of
identiﬁcation. To give an example, the transition from convolution to FIR and diﬀerence equation
models would be presented quite diﬀerently in a signal processing context vis-a-vis identiﬁcation,
because the concern in the former is ﬁltering and its implementation whereas in the latter it is
estimation of parameters and model parametrization.
xxi

xxii
Preface
The focal subject of this text is discrete-time linear time-invariant open-loop identiﬁcation. The
book is arranged in ﬁve parts and has been organized in a way that suits beginners (starting from
scratch), intermediate (equipped with foundations), as well as advanced (familiar with input-output
identiﬁcation) readers.
Parts I to III present the essential concepts of identiﬁcation and lay down the foundations of
mathematical descriptions of systems, random processes and estimation in the context of identiﬁca-
tion. Students and instructors of this subject can budget their time to these parts in accordance with
their background in the respective areas. A reader familiar with these topics may also ﬁnd revisiting
these portions refreshing given that the presentation is in the context of identiﬁcation.
Part I
This part introduces the reader to the world of identiﬁcation. Chapter 2 deserves particular mention
since it aims to oﬀer the reader an illustrative tour of identiﬁcation. Subsequent chapters essentially
review models for linear systems theory in time- and transform (frequency) domain, however, in the
context of identiﬁcation. A condensed material on sampling and discretization is also included.
Part II
The biggest challenge in data-driven analysis is the presence of uncertainties or randomness. Often
this is one of the most demanding parts of learning System Identiﬁcation. Therefore it may be
necessary to pay more attention to this part of the subject.
All the salient topics pertaining to random processes, namely, correlation functions, ARIMA
modeling of stationary processes and spectral representations, are discussed in the related chapters.
An exclusive chapter on deterministic spectral analysis is included in order to give the necessary
background for understanding spectral representations.
Part III
This part serves as the most appropriate transition from the previous parts to the remainder portions
of this text because it connects theory to practice and models to data. The subject of estimation
is a very exciting and challenging one. The reader should spend considerable time in carefully
understanding the subtle and practical aspects of estimation in the constituent chapters. Founding
concepts such as goodness of estimators (bias, variance, etc.) and Fisher’s information are discussed.
The mainstay of this part are the traditional methods for estimation (method of moments and least
squares) and the more modern methods (Bayesian, which also includes MLE).
All System Identiﬁcation exercises involve use of signal properties such as mean, variance, auto-
covariance and spectral density. Therefore, it is inevitable that a chapter on this topic is included.
Part IV
Part IV forms the nucleus of this text. It constitutes the application of concepts and methods in the
previous parts to the problem of identiﬁcation. The theory pertaining to non-parametric and para-
metric models for deterministic-plus-stochastic LTI systems are discussed in detail. Concepts of
prediction theory pertaining to stationary random processes and input-output systems are discussed.
Subsequently, the theory of estimating non-parametric and parametric models is included. Regular-
ized estimation of impulse response coeﬃcients, smoothed estimates of FRFs, prediction-error and
instrumental variable methods are discussed in great detail. Chapters 17 to 21 contain the related
material.
Statistical and practical aspects of identiﬁcation including input design, outlier and missing data
treatment (with emphasis on robust identiﬁcation and EM algorithms), time-delay estimation (using

Preface
xxiii
classical and a powerful frequency-domain method) and model assessment tests are presented in
Chapter 22. Order determination and other options in parametric modeling are also brieﬂy reviewed.
Identiﬁcation of state-space models is the topic of Chapter 23. The focus is on subspace identiﬁ-
cation, which is concerned with identiﬁcation of unstructured (non-parametric) state-space models.
The material is developed in a step-wise manner, from the simple deterministic case with impulse
inputs to the full deterministic-plus-stochastic system with arbitrary inputs. A tutorial review of
Kalman ﬁlter and other related concepts are included. Identiﬁcation of structured state-space mod-
els and grey-box models are brieﬂy discussed in the second part of the chapter, mostly by way of
examples.
A set of simulation and industrial case studies are presented in Chapter 24 to illustrate the prac-
tical applications of identiﬁcation concepts. These case studies can also be used as motivating ex-
amples in an introductory session.
Part V
The ﬁnal part oﬀers an overview of advanced topics of identiﬁcation namely the linear time-varying
(LTV), non-linear and closed-loop identiﬁcation. A multivariable approach to identiﬁcation using
the method of iterative PCA as a potential tool is discussed. In addition, a delay estimation method
set in the frequency domain for MIMO systems is presented. The hope is that an interested reader
will pursue these topics in greater detail based on his/her needs and requirements.
Practicing aspects and software
No learning is complete without practice. In the modern era of data analytics, to be able to translate
theory into a computer (soft code) is an unwritten requirement. It is therefore important for a user
of System Identiﬁcation to put the relevant concepts into practice at each stage of learning. For this
purpose, snippets of computer code for all numerically illustrated examples are incorporated there
and then. Serious readers of this text are strongly encouraged to implement these codes by a com-
plete re-typing (as against the ineﬀective ”copy-paste” approach) so as to reinforce their learning.
This strategy, in my opinion, is potentially more eﬀective than referring the reader to a CD or a
Website.
The primary software platform for the illustration of examples in this text is MATLAB®1, a
powerful commercial computation, visualization and simulation software package developed by
The MathWorks, Inc. The System Identiﬁcation Toolbox, exclusively designed for the subject is
extensively used in this text. Beginners of MATLAB may be required to go through a few tutorials
on the basic usage of this software, many of which are easily and freely accessible on the web.
Who can use this text?
The text has been written mainly for classroom teaching and is meant as a one-stop reference for
an introductory to moderately advanced courses on System Identiﬁcation. That said, a researcher of
this subject will also ﬁnd the text a useful resource both for theory and practice; besides, it oﬀers
glimpses of some modern developments in this area. I have tried to achieve a healthy balance of the-
ory, conceptual explanations and of course most importantly examples. Mathematics is inevitable
1MATLAB is a registered trademark of The MathWorks, Inc. For product information, please contact
The MathWorks Inc.
3 Apple Hill Drive
Natick, MA 01760-2098 USA
Tel: 508-647-7000
Fax: 508-647-7001
Email: info@mathworks.com
Web: www.mathworks.com

xxiv
Preface
beyond a certain point, but understanding an equation is important, not necessarily remembering it.
The presentation is largely generic without aiming at a particular discipline, keeping in with the ver-
satility of the subject. The illustrative examples are mostly numerical and simulation-based with the
obvious intention of transparency. Moreover, what are considered elementary topics and typically
conﬁned to appendices have been included in the main body. In these respects, a hardcore researcher
may ﬁnd certain sections and examples somewhat simplistic, but will hopefully appreciate the main
motivation.
It must be mentioned that the text is also useful for introductory courses on stochastic signal
processing or time-series analysis (see suggestions below for relevant portions), which are usually
taught at a second- or third-year undergraduate level in engineering colleges.
What is not contained in this text?
The book does not discuss several specialized and emerging branches such as identiﬁcation of
continuous-time systems, multiscale identiﬁcation, control-relevant identiﬁcation, etc. Topics such
as non-linear, time-varying (recursive) and closed-loop identiﬁcation are discussed in a condensed
manner.
Suggestions for classroom teaching
The material can be taught selectively depending on the level of the course. In a beginner level
course, the student is assumed to have little or no background on the foundational concepts. While in
an intermediate / advanced level course, the student has good foundations in systems and estimation
theory with possibly some working knowledge of input-output identiﬁcation techniques.
• Beginner Course:
i. Part I (state-space descriptions optional). The case study of Chapter 2 is particularly useful
for a motivational overview.
ii. Part II (discussing only the main results in Chapters 10 and 11).
iii. All chapters of Part III with Chapter 15 optional.
iv. Part IV (excluding Chapter 23).
v. Brieﬂy discuss recursive algorithms.
For certain audience, it may be useful to give a working overview of subspace identiﬁcation
where the emphasis is on case studies rather than technical details.
• Intermediate / Advanced:
i. Quick review of Parts I and II.
ii. Review of Chapter 14 followed by a detailed coverage of Chapters 15 and spectral density
estimation IV.
iii. Part IV in detail with emphasis on subspace identiﬁcation.
iv. Time-varying identiﬁcation and other selected topics in Part V.
Of course, the above recommendations are largely guidelines; eventually it is the instructor’s call
since he/she is best aware of the students’ background and other constraints. Therefore, some
amount of tailoring to a given course is inevitable.
The end-of-chapter problems are divided into two categories: review questions and exercises. The
former category aids in self-assessment of the understanding, while the latter ﬁnds use in homework
problems / quizzes. MATLAB scripts used in this text and the data sets used in illustrations and
exercises are available at the publisher’s Website.
Selected portions of this text can be easily used to conduct a one-week or two-week-long work-
shop on System Identiﬁcation. In such situations, a strategy that has worked is to focus more on
salient concepts and spend time on case studies. Chapter 24 is useful for this purpose.

Preface
xxv
The material in this text is a culmination of several classroom and workshop lecture notes. The
notes are now available for free of cost thanks to the National Program on Technology Enhanced
Learning (NPTEL2), an initiative for distance education by the Ministry of Human Resources and
Development (MHRD), India. Under this program, educational material for hundreds of courses in
several disciplines are available in Web (text) and/or video formats. To procure the notes pertaining
to System Identiﬁcation, follow the link named Chemical Engineering on the NPTEL Website and
select the course with the subject name.
Although the book has been written for a full-semester course on System Identiﬁcation, it also
serves as a good text for teaching introductory semester courses on Modeling of Random Processes
(or Applied Time-Series Analysis), a prescription for which follows:
• Introductory Course on Stochastic Signal Processing:
i. Parts II and III.
ii. Chapters 18 and 19.
iii. Case study of Chapter 24.
Acknowledgments
I am indebted forever to my parents (the late) Sri T. Subrahmanyam and Smt. T. Rajyalakshmi for
their unconditional love, sacriﬁce, encouragement and constant support. I oﬀer my humble respects
to my spiritual teacher Mathaji for her invaluable guidance and strength over the past two decades.
I would like to thank the administration of IIT Madras for oﬀering enormous freedom to teach
electives and conduct unfettered research; my colleagues at the Department of Chemical Engineer-
ing, IIT Madras especially in the Process Systems Engineering group for their wonderful encour-
agement. Special thanks to Prof. Shankar Narasimhan for lending the IPCA code and enlightening
me on PCA. I owe a signiﬁcant part of my learning to the students of my courses on System Identi-
ﬁcation and Applied Time-Series Analysis and several other workshops.
I am highly grateful to Prof. Polifke, TUM and his research group for the support, encouragement
in writing this book as well as the opportunities to apply and teach this subject during my visits to
TUM in 2012-14. I would also like to thank Prof. Babatunde Ogunnaike, University of Delaware
for hosting me on my sabbatical visit during which much of this book was developed. Due thanks
to my former colleague and a good friend, Prof. Rajanikanth Vadigepalli, Thomas Jeﬀerson Univer-
sity for making our stay at Delaware smooth and homely. Several former and present students and
colleagues have helped me in critically reviewing early to near-ﬁnished versions of this manuscript.
I would like to specially thank Prof. Sachin Patwardhan, IIT Bombay for sharing his wonderful in-
sights into the subject and critical feedback on certain chapters in this text, in addition to providing
the data set for the quadruple tank system of Chapter 24.
Among several graduate student researchers, I would like to particularly thank Ralf, Devesh
and Senthil for their timely and meticulous reviews that have helped me signiﬁcantly reﬁne the
text. Also special thanks to Satheesh for patiently working on a variety of simulations and the
interesting discussions that I had with him on the models. I am very grateful to my good friends at
IIT Madras, IIT Bombay, University of Alberta, University of British Columbia and Madras Institute
of Technology, Chennai for their kind understanding, words of encouragement and tolerating my
pre-occupations with this book. Among several others I would like to particularly place on record
my gratitude to all the numerous anonymous teachers on the Web for their wonderful learning
resources.
This text is also a part of the The MathWorks book program whose software support through
MATLAB® and the System Identiﬁcation Toolbox is gratefully acknowledged. I would like to spe-
cially place on record my thanks to Prof. Lennart Ljung, an exponent in the ﬁeld, for patiently
2http://nptel.iitm.ac.in.

xxvi
Preface
responding to my questions / queries over emails and kindly agreeing to write a Foreword to this
text.
The critical comments oﬀered by the anonymous reviewers of the book proposal have markedly
helped in shaping the material of this text; I would like to sincerely thank them for the same. I would
also like to place on record my gratefulness to the Senior Editor, Dr. Gagandeep Singh, the Project
Editor, Michele Dimont, the editorial team and the project coordinators, Laurie Schlags and Hayley
Ruggieri, for their enormous patience, understanding and kindness throughout this project.
A book of this volume cannot materialize without the excellent and untiring support of family
members. I am ever grateful to my brothers Murali, Prasad and Shashidhar and their families for the
wonderful support and encouragement. I am also indebted to my parents-in-law for their immense
support, aﬀection and understanding. My heartfelt thanks to my wonderful wife, Kalyani, for her
tremendous, unfailing support and putting up with extended periods of my absence from home; our
son, Hariganesh, whose curiosity and enthusiasm for the completion of the book exceeded mine at
times; and our daughter, Vishnuvilasini, for the endless joy and energy she brings into our lives.
Finally, but most importantly, my grateful and humble salutations to the Almighty in whose eyes
the entire world is deterministic!
In preparing this material, unnoticed errors must have occurred at random locations despite the
best eﬀorts. Any inconvenience caused as a result is sincerely regretted. Therefore, I humbly request
the reader to notify me of such instances. In addition, any suggestions for improvements to the book
are wholeheartedly welcome. I would like to sign oﬀwith the hope that this book will persistently
excite the reader’s thinking and interests in this subject!
Arun K. Tangirala

List of Figures
1.1
(SEE COLOR INSERT) Identiﬁcation is the task of using input-output data to
build a model: a mathematical abstraction of the process...............................................2
1.2
Applications of models in process systems engineering. ...............................................4
1.3
Temperature response of a reactor to changes in coolant ﬂow rate is used in iden-
tiﬁcation of the reactor system........................................................................................4
1.4
Plot of RH and Temperature ...........................................................................................6
1.5
Two approaches to modeling: ﬁrst-principles vs. experimental (empirical). .................8
1.6
(SEE COLOR INSERT) The system being identiﬁed consists of the true process
and additional elements.................................................................................................13
1.7
(SEE COLOR INSERT) A generic iterative procedure for System Identiﬁcation. ...20
1.8
A standard sampled-data system. .................................................................................20
1.9
System Identiﬁcation involves application of concepts from four broad ﬁelds in
engineering, mathematics and statistics........................................................................26
2.1
The best ﬁt and the error in the parameter estimates depend on the SNR. ..................34
2.2
Training data and order determination in Example 2.4. ...............................................36
2.3
Cross-validation of polynomial models in Example 2.4. .............................................36
2.4
Schematic of the liquid level system discussed in Section 2.4. ....................................38
2.5
Time-trends and spectra of ﬂow and level measurements in the identiﬁcation of
the liquid level system. .................................................................................................39
2.6
Impulse response estimates of the liquid level system. ................................................42
2.7
Step response estimates of the liquid level system. .....................................................43
2.8
Comparing one-step ahead predictions (deviations from steady-state) of the iden-
tiﬁed models on the training data. ................................................................................46
2.9
Correlation between residuals and lagged inputs for the output-error (bottom) and
equation-error (top) models. ........................................................................................47
2.10
Correlation analysis of residuals obtained from the best equation-error model. .........48
2.11
Auto-correlation function of the residuals from the output-error model. ....................49
2.12
Inﬁnite-step ahead predictions from the output-error model on the test data set..........49
2.13
Plot of (log) Hankel singular values and correlation functions from the state-space
model. ...........................................................................................................................51
3.1
The inputs and outputs of a model are in general diﬀerent from the physical inputs
and outputs of a process. ..............................................................................................57
3.2
(SEE COLOR INSERT) Types of models. ................................................................58
3.3
(SEE COLOR INSERT) Four broad categories of empirical models. ......................59
3.4
(SEE COLOR INSERT) Composite model from identiﬁcation. ...............................66
4.1
Impulse response of an LTI system. .............................................................................69
4.2
Schematic depicting the derivation of a convolution operation. ..................................69
4.3
Impulse responses of diﬀerent systems. .......................................................................70
4.4
Typical step response of a ﬁrst-order LTI system. .......................................................74
4.5
Bode plots for the ﬁrst-order system in Example 4.5. .................................................78
4.6
Bode plot for the pure delay system of Example 4.6 with D = 2. ...............................78
4.7
Two diﬀerent ways of realizing a state-space representation. ......................................89
4.8
Snapshot of the input-output data. .............................................................................102
xxvii

xxviii
List of Figures
4.9
Impulse response estimates - dashed lines denote the signiﬁcance levels. ................103
4.10
Estimates of step-response coeﬃcients ......................................................................103
4.11
Snapshot of predictions of the SS model (4.75) (measurements shown as dashed
line). ...........................................................................................................................105
5.1
Location of the corner frequency on a Bode plot .......................................................111
5.2
True (solid curve) and estimated (dashed curve) FRFs for the system in (5.28). ......125
6.1
A typical sampled-data system. ..................................................................................131
6.2
Schematic showing the operations of a ZOH and sampler, respectively. ...................132
6.3
Mapping of the stability region under step-invariant discretization. ..........................140
6.4
(SEE COLOR INSERT) Incorrect sampling rates can result in ambiguous
discrete-time signals. ..................................................................................................145
7.1
Commonly encountered cumulative (probability) distribution functions. .................155
7.2
Density functions: shaded regions correspond to Pr(1 ≤X ≤2) and Pr(6 ≤X ≤
8), respectively. ..........................................................................................................157
7.3
(SEE COLOR INSERT) Schematic illustrating confounding and conditioning. ....169
7.4
Examples of univariate random signals. ....................................................................172
7.5
Diﬀerent realizations of a ﬁxed liquid level. ..............................................................174
7.6
(SEE COLOR INSERT) Examples of stationary and non-stationary time-series. ..177
7.7
Linear trend type non-stationarity (top) and the residuals (bottom). .........................180
7.8
Snapshot of an integrating process (top) and the diﬀerenced series (bottom). ..........181
7.9
Schematic illustrating ergodicity. ...............................................................................182
7.10
Broad application areas of time-series analysis. ........................................................183
8.1
ACF of the measurements in Figure 7.4. ...................................................................188
8.2
ACF of a white-noise process. ...................................................................................191
8.3
ACF of an MA(1) process. .........................................................................................193
8.4
ACF of an AR(1) process. ..........................................................................................195
8.5
CCF plots for Example 8.4. .......................................................................................197
8.6
Graphical representation of the auto-regressive process: ACF detects presence
of both the direct and indirect pathways, whereas PACF detects only the direct
pathways .....................................................................................................................199
8.7
Theoretical PACFs of a few representative processes. ...............................................201
8.8
PACF of the measurements in Figure 7.4. ..................................................................201
9.1
Snapshot of the series in Example 9.5 and its ACF. ...................................................214
9.2
ACF of the residuals from the estimated model in (9.26). .........................................215
9.3
Theoretical ACF of AR(2) process with d1 = −1.2,d2 = 0.35. .................................219
9.4
ACF and PACF of the series in Example 9.9. ............................................................223
9.5
ACF of the prediction errors from the estimated model in (9.48). .............................223
9.6
ACF and PACF plots of an unknown process. ...........................................................224
9.7
LTI representation of AR and MA models. ................................................................226
9.8
Integrating series, its ACF and PACF estimates. ........................................................228
9.9
ACF, PACF of the series and ACF of the diﬀerenced series of Example 9.12. .........229
9.10
Simulated series, its ACF and PACF estimates pertaining to Example 9.13. ............231
9.11
ACF of residuals from models estimated in Example 9.13. .......................................232
9.12
Diﬀerenced series, its ACF and PACF. ......................................................................232
10.1
Series of Example 10.1 and its power spectral density. .............................................240

List of Figures
xxix
10.2
(SEE COLOR INSERT) Comparing the signal estimate using the inverse FT
method with the true signal in Example 10.1. ............................................................240
10.3
Power spectral densities of two ﬂow loop outputs, a temperature loop measure-
ment and wind speed. .................................................................................................242
10.4
Signals and their covariance functions with reference to Examples 10.3 and 10.4. ..247
10.5
(SEE COLOR INSERT) Power spectral and Fourier decomposition of the
square wave in Example 10.5. ....................................................................................250
10.6
Energy densities in time and frequency of the rectangular signal in Example 10.6. .253
10.7
Finite-length pulse of Example 10.8 and its energy spectral density when A =
1, L = 10. ....................................................................................................................256
10.8
Finite-length pulse of Example 10.9 and its energy spectral density when A =
1, L = 10. ....................................................................................................................257
10.9
Computing the energy spectral density through three diﬀerent ways for a deter-
ministic signal. ...........................................................................................................261
11.1
Three diﬀerent methods of arriving at the spectral density of a stationary stochas-
tic process. ..................................................................................................................272
11.2
PSD of WN process generated by ensemble average. ...............................................273
11.3
Power spectral density of white noise process. ..........................................................282
11.4
Power spectral density and distribution of the MA(1) process in Example 11.3. ......284
11.5
Power spectral density and distribution of the AR(1) process in Example 11.4. .......284
11.6
Power spectral density of the ARMA(1,1) process in Example 11.5. .......................286
11.7
Time-delay estimation from the phase spectrum. ......................................................289
11.8
Estimate of FRF using spectral densities. ..................................................................291
11.9
Squared input-output coherence and SNR for the process of Example 11.8. ............293
12.1
(SEE COLOR INSERT) Schematic illustrating generic estimation. .......................308
13.1
Pictorial illustration of bias and variance of an estimator. .........................................323
13.2
Plot to illustrate variability and the (Gaussian) distribution of the sample mean. .....325
13.3
Sketch depicting (p.d.f.s of) two unbiased estimators with diﬀerent variances. ........326
13.4
Cross-correlation function of the series in Example 13.12. .......................................341
13.5
Plot of 95% conﬁdence intervals (for mean) from 1000 realizations; 51 of these
intervals do not contain the true mean µ0 = 0. ..........................................................344
14.1
Snapshot of the input-output data used in estimation of the ARX model. .................353
14.2
Input-output data and parameter estimates of the FIR model of Example 14.2. .......360
14.3
CCF σεu[l] and ACF σεε[l] plots associated with the model estimated in Exam-
ple 14.2. ......................................................................................................................362
14.4
Predictions vs. measurements. ...................................................................................364
14.5
Distribution of the OLS estimates of the FIR model in Example 14.5, obtained
from 200 realizations. ................................................................................................371
14.6
ACF of the residuals from the OLS estimation of the FIR model in Example 14.7. .380
15.1
(SEE COLOR INSERT) Prior and posterior p.d.f.s of mean in Example 15.2. ......414
16.1
Testing CCF with the signiﬁcance levels for the series of Example 16.1. .................429
16.2
Testing the series of Example 16.2 for whiteness. .....................................................432
16.3
Rectangular window function and its Fourier transform magnitude. .........................437
16.4
Illustration of spectral leakage of sine wave. .............................................................438

xxx
List of Figures
16.5
(SEE COLOR INSERT) Window functions and the magnitudes of their Fourier
transforms. ..................................................................................................................439
16.6
Reduction in spectral leakage by use of window functions. ......................................442
16.7
Trade-oﬀin using windows for reducing spectral leakage. .......................................443
16.8
(SEE COLOR INSERT) (Top panel) Periodograms from a single realization
with N = 250 and N = 2000 observations; (Middle panel) Averaged peri-
odograms from 1000 realizations; (Bottom panel) Distribution of ˆγ(0)/γ(0) and
2 ˆγ(0.4π)/γ(0.4π) obtained from 1000 realizations. .................................................449
16.9
Estimation of PSD of a GWN process using non-parametric methods. ....................460
16.10
PSD estimates of a colored noise process using parametric methods. .......................463
16.11
CPSD and squared coherence estimates for the liquid level system using data
generated in Chapter 2. ..............................................................................................471
17.1
(SEE COLOR INSERT) Input-output representation of a deterministic-plus-
stochastic LTI system. ................................................................................................480
17.2
Schematic representation of an ARX structure. .........................................................488
17.3
Schematic representation of an ARMAX structure. ..................................................490
17.4
Schematic representation of a OE structure. ..............................................................492
17.5
Schematic representation of a BJ structure. ...............................................................495
18.1
Schematic illustrating one-step ahead prediction of the LTI system. ........................507
18.2
Predictions of the estimated OE and ARX models for the liquid level system of
Chapter 2. ...................................................................................................................511
19.1
ACF of the residuals from the ARMA(1,1) model. ...................................................538
20.1
Comparison of FIR model estimates with and without the pre-whitening step. ........547
20.2
(SEE COLOR INSERT) Estimates of IR coeﬃcients with regularization for the
process in Example 20.2. ...........................................................................................551
20.3
Estimate of FRF using the ETFE. ..............................................................................559
20.4
Estimate of FRF using smoothed spectral densities obtained with Hann window
of widths L = 200,100,50. True responses shown as solid line. ...............................564
20.5
Non-parametric estimates of disturbance spectrum using smoothed spectral den-
sities obtained with Hann window of widths L = 200,100,50. True spectrum
shown as solid line. ....................................................................................................564
21.1
FRF ﬁts and the weighting functions by PEM for two diﬀerent structures in Ex-
ample 21.6. .................................................................................................................587
21.2
IR estimates and residual analysis plots for Example 21.7. .......................................591
21.3
IR estimates and the residual analysis plots for Example 21.9. .................................595
21.4
IR estimates (for delay estimation) and the residual analysis plots for Example
21.10. ..........................................................................................................................598
21.5
Residual analysis plots for the model estimated in Example 21.11. ..........................599
21.6
IR estimates (for delay estimation) and residual analysis plots for Example 21.13. .602
21.7
Bias (and its absence) in the OLS estimates of an ARX model of Example 21.14. ..605
22.1
ACF of the output and IR estimates for (G1, H1) both conﬁrm the presence of
very slow dynamics in G. ...........................................................................................621
22.2
ACF of the output and model residuals for (G2, H2) conﬁrm the presence of very
slow dynamics in H only. ...........................................................................................621
22.3
Uncorrupted and outlier contaminated outputs of Example 22.2. .............................629

List of Figures
xxxi
22.4
Output proﬁle after reconstruction of missing data (outliers). ...................................629
22.5
Time delay estimation in open-loop SISO systems (TFM) at SNRout = 10 and
SNRout = 1, respectively............................................................................................640
22.6
Time delay estimation in liquid level system with SNRout = 10 and SNRout = 1,
respectively. ................................................................................................................641
22.7
(SEE COLOR INSERT) Residual analysis of the model and ACF of the inputs
used in Example 22.5. ................................................................................................650
22.8
Residual analysis of the model and ACF of the inputs after pre-whitening. .............651
22.9
Impulse response of the model-error model corresponding to the FIR(2) model
estimated in Example 22.5. ........................................................................................652
23.1
Prediction-correction algorithm in a Kalman ﬁlter state estimator. ...........................667
23.2
Kalman ﬁlter estimates of a constant signal with choices Q = 0.0001 and R =
0.01. ............................................................................................................................669
23.3
Kalman ﬁlter estimates of a constant signal with choices Q = 0.0001 and R = 1. ...670
23.4
IR coeﬃcients and singular values of the Hankel matrix for Example 23.6. .............680
23.5
(SEE COLOR INSERT) Plot of Hankel singular values for the system in Exam-
ple 23.7. ......................................................................................................................705
24.1
Series, ACF, PACF and spectral density of the temperature series. ...........................719
24.2
Diﬀerenced series and its properties - signal appears to be stationary. ......................720
24.3
ACF and Box-Ljung Q-stat of residuals from ARMA(2,1) model. ...........................721
24.4
Residual ACF and Box-Ljung statistics for the constrained ARMA(2,1) model. .....721
24.5
Residual ACF and Box-Ljung statistics for the constrained ARMA(5,1) model. .....722
24.6
Comparing predictions with observations. .................................................................722
24.7
Input-output proﬁle and their spectral densities. ........................................................725
24.8
Non-parametric estimates of time responses. ............................................................726
24.9
Smoothed estimate of the FRF. ..................................................................................726
24.10
(SEE COLOR INSERT) Plot of Hankel singular values. ........................................728
24.11
(SEE COLOR INSERT) Loss functions for ARX models with diﬀerent numer-
ator and denominator polynomial orders. ..................................................................728
24.12
Residual analysis of the ARX model in (24.9). .........................................................729
24.13
Cross-validating the model (24.9) with the test data resulted in ﬁts of 80.6% and
69%, respectively. ......................................................................................................731
24.14
Comparing elementary responses obtained from non-parametric and parametric
models. .......................................................................................................................731
24.15
Correlation analysis and PACF of residuals from OE model, (24.10). ......................732
24.16
Snapshot of the input-output data. .............................................................................734
24.17
Impulse and step response estimates for the process in §24.3. ..................................734
24.18
Auto-correlation function of the output and frequency domain analysis of the pro-
cess in §24.3. ..............................................................................................................735
24.19
(SEE COLOR INSERT) Hankel singular values. ....................................................735
24.20
Cross- and auto-correlation analysis of the residuals from ARMAX models. ..........736
24.21
Cross- and auto-correlation analysis of the residuals from OE models. ....................737
24.22
PACF of the residuals from the OE(1,2) model and whiteness test for the noise
model. .........................................................................................................................738
24.23
Residual analysis and cross-validation of the BJ model in (24.18). ..........................738
24.24
Residual analysis and cross-validation of the BJ model in (24.20). ..........................739
24.25
Schematic of a typical quadruple tank system. ..........................................................740
24.26
Schematic diagram (Detroja, 2006) of the quadruple tank system used in §24.4. .....741

xxxii
List of Figures
24.27
Input-output proﬁles and input-input coherence plot for the identiﬁcation experi-
ment on the four-tank system. ....................................................................................742
24.28
Auto-correlation functions of the level responses. .....................................................743
24.29
Singular values and residual analysis of the initial (third-order) state-space model. .744
24.30
Residual analysis of the fourth-order state-space model and its reﬁned version. ......745
24.31
Cross-validating the (reﬁned) fourth-order model and comparing it with the (re-
ﬁned) third-order and ﬁfth-order models. ..................................................................745
24.32
Comparing the predictive performance of the BJ and SS(4) models on the test
data set. .......................................................................................................................748
24.33
Cross-correlation analysis of the residuals from the third-order MOESS model. .....749
24.34
ACF and PACF of the residuals from the third-order MOESS model. ......................750
24.35
ACFs of the residuals from the ARMA(1,1) noise models. .......................................751
25.1
Casting the time-varying parameter estimation as a control problem. .......................759
25.2
Time-varying identiﬁcation of the system in Example 25.2. .....................................764
25.3
Diﬀerent wavelet functions possessing diﬀerent properties. ......................................768
25.4
(SEE COLOR INSERT) Normalized scalograms of two diﬀerent signals. ............769
25.5
Scales s > 1 generate low (band)-pass ﬁlter wavelets while scales s < 1 gen-
erate high (band)-pass ﬁlter wavelets. Generated for Morlet wavelet with center
frequency ω0 = 6 rad/sec. ..........................................................................................770
25.6
Fast pyramidal algorithm for orthogonal wavelet decomposition (analysis). ............772
25.7
Fast algorithm for reconstruction (synthesis) from decomposed sequences. .............772
25.8
Wavelet decomposition and reconstructions of the respective bands for the piece-
wise regular polynomial signal of Mallat (1999). ......................................................773
25.9
Schematic of a single-layer neural network. ..............................................................778
25.10
Hammerstein model. ..................................................................................................781
25.11
Wiener model. ............................................................................................................782
25.12
Wiener-Hammerstein model. .....................................................................................782
25.13
(SEE COLOR INSERT) A typical closed-loop setup with the signals of interest
in identiﬁcation. .........................................................................................................784
26.1
Schematic illustrating the technique of decoupling a MIMO system in the fre-
quency domain using partial coherence. ....................................................................792
26.2
Time-delay estimation in the MIMO system (TFM). ................................................794
26.3
Scatter plot of the data. ..............................................................................................796
26.4
Data in the variable space and in the new basis space. ..............................................797
26.5
Scatter plot of the data ...............................................................................................798
26.6
Data in the variable space and in the new basis space. ..............................................799
26.7
Snapshot of input-output data for the CSTH example. ..............................................811

List of Tables
2.1
Parameter estimates (errors) of the best equation-error model for the liquid-level system ...48
4.1
Comparison of diﬀerence and convolution forms .................................................................83
5.1
Pole locations (p) of X(z) and time-domain characteristics ...............................................114
5.2
Non-parametric (response-based) descriptions of deterministic LTI systems .....................127
5.3
Parametric descriptions of deterministic LTI systems .........................................................128
9.1
Durbin-Levinson’s algorithm ...............................................................................................221
10.1 Fourier Transforms and corresponding energy/power decompositions (expressed in
cyclic frequency) ..................................................................................................................259
16.1 Table of common window functions (w[k], k = 0,· · · , N −1 ) and their characteristics ..475
16.2 Lag window, their spectral equivalents and variance of B-T estimators .............................476
16.3 Comparison of non-parametric and parametric estimators of p.s.d. ....................................476
16.4 Comparison of popular methods for spectral estimation .....................................................477
17.1 Classes of parametric models as special cases of the PEM family (17.25) .........................496
19.1 Procedure to estimate an ARMA model ..............................................................................537
19.2 Steps for building an ARIMA model ...................................................................................540
22.1 Indices of non-zero coeﬃcients in the generating polynomial of full-length PRBS ...........616
23.1 Settings for the two-tank system simulation ........................................................................713
26.1 Results from IPCA and PCA of ﬂow mixing data ...............................................................809
xxxiii

This page intentionally left blank
This page intentionally left blank

PART I
INTRODUCTION TO IDENTIFICATION AND
MODELS FOR LINEAR DETERMINISTIC
SYSTEMS

1
Introduction
This chapter introduces the basic concepts of identiﬁcation and provides an overview of the
subject. The notion of model, its deﬁnition and applications are discussed with suitable exam-
ples. The main objective of this chapter is to provide foundations of identiﬁcation, introduce
certain basic terminology, oﬀer a historical overview and describe a systematic procedure for
building empirical models from data.
1.1
MOTIVATION
Analysis of process characteristics and inter-variable relationships is of paramount importance in
prediction, control, monitoring, design and innovation of process systems. A key step in these anal-
yses is the development of a (mathematical) description of the process under study, known as the
model. Two contrasting approaches are generally followed for model development: (i) a theoretical
(ﬁrst-principles) approach that is based on fundamental laws of matter and energy, and (ii) an empir-
ical approach that is based on analysis of observations (experimental or operating data). The latter
approach is a highly practical alternative to the former and widely followed since most processes
are too complex to be understood at a fundamental level. Observations potentially carry a wealth
of information that remains otherwise obscure in a ﬁrst-principles approach. The subject of System
Identiﬁcation is concerned with the means and techniques for studying a process system through
observed / experimental data, primarily for developing a suitable (mathematical) description of that
system.
Process
(Unknown)
Input 
u[k]
(Probe 
signal)
Output 
y[k]
(Observed 
response)
Identification
Model
FIGURE 1.1
(SEE COLOR INSERT) Identiﬁcation is the task of using input-output data to build a model: a
mathematical abstraction of the process.
Figure 1.1 schematically portrays a typical exercise in System Identiﬁcation. The prime objective
is to develop a model from input-output1 data. The resulting model is said to be empirical in con-
trast to being a ﬁrst-principles model. A simple analogy to identiﬁcation is that of taking a vehicle
(process) on a test drive.
1Alternative terminologies for input and output signals are also prevalent; for example, cause and eﬀect, probe signal and
response, independent and dependent, explanatory and predicted variables, and so on.
2

Introduction
3
Example 1.1: Vehicle Test Drive
In the test drive of a vehicle, the user develops a mental model of the vehicle’s performance
by examining its response to changes in various inputs such as fuel supply, pressure on the
brake pedal, rotations of steering vehicle and so on. The end use of the model is in decision
making; additionally, the exercise can provide insights into how to operate the vehicle in a
safe and eﬃcient manner.
Another analogy that is useful to relate to is the interview process.
Example 1.2: Interview
In a recruitment interview, the interviewer attempts to “identify” the candidate by asking
questions related to the skills required for the advertised position. The end use of this model
is once again in decision making.
The identiﬁed model in Figure 1.1 consists of two components (i) a mathematical description of
the cause-eﬀect relationships, usually known as the deterministic model and (ii) a statistical-plus-
mathematical description of the uncertainties, known as the stochastic model. The latter component
comes into play due to the presence of observation errors, process uncertainties and modeling errors
(unaccounted dynamics) (further explained in §1.3). On the other hand, the main object of interest
to the user is the deterministic (input-output) component of the model because it captures the dy-
namics of the physical process. An important fact is that the accuracy and precision of the estimated
deterministic model depends on the assumptions constituting the stochastic model. This fact is of-
ten undermined or even ignored in several modeling exercises partly because it is not immediately
obvious to a beginner in identiﬁcation as to why such a connection exists. Only a careful study and
practice of the subject establishes this point clearly.
The concepts and techniques of identiﬁcation have largely originated from the domains of statis-
tics, engineering and econometrics. The task of identiﬁcation, however, appears in almost every
walk of life. Shortly we shall come across examples that are illustrative of the versatility of this sub-
ject. In order to set up and solve these diverse problems, it is necessary to understand the principles
governing identiﬁcation concepts and techniques, which is the purpose of this text.
What factors motivate the need for identiﬁcation? The two primary motivating factors are (i) the
need for models in process analysis and automation and (ii) the practical limitations of the ﬁrst-
principles approach in developing models. These factors are discussed in that order below.
Incentives in model development
The beneﬁts of developing models are enormous. Figure 1.2 depicts the applications of models to
four major branches of process systems engineering, namely, design, estimation (prediction), control
and monitoring.
Central to all these applications is the use of models in simulations and predictions, which con-
stitute the key incentives of model development. Simulations, by their computational nature, oﬀer
a cost and time-eﬀective, safe alternative to experiments that are usually time-consuming, expen-
sive and marked with safety issues. Signiﬁcant advances in the ﬁelds of computational science and
technology have rendered simulations as powerful ways of understanding processes, bringing about
innovations and testing new designs and strategies. The enormous beneﬁts gained through the sim-
ulation route usually come at the cost of inaccuracies in simulations. In order to minimize these
losses, high accuracy requirements are imposed on a model whose end use is in simulation.
On the other hand, predictions are on-line exercises where the model is used to forecast the pro-
cess response for the prevailing operating conditions over a ﬁnite time-step horizon. Conceptually
predictions are not much diﬀerent from simulations; however, technically simulation is reserved for

4
Principles of System Identiﬁcation: Theory and Practice
Models
Design
Estimation
Control
Monitoring
Stability Analysis
Controller Design
Performance 
Assessment
...
Predictions
Advanced Process 
Control
Soft Sensors
Filtering 
...
Statistical Quality 
Control
Fault Detection & 
Diagnosis
...
Simulations 
Optimization
Planning/
Scheduling
...
FIGURE 1.2
Applications of models in process systems engineering.
predictions under special conditions - the case of inﬁnite-step prediction horizon. Chapter 18 oﬀers
technical deﬁnitions of predictions, how to compute them from models and explains this distinction
in detail. Predictions are vital to design, control, fault detection, testing new schemes, etc. However,
the accuracy requirements of the models are lower than in simulation-based applications.
Speciﬁc examples below highlight the role of identiﬁcation in process operations and its multi-
disciplinary facets.
Example 1.3: Reactor Control
Reactions between two or more chemical species are often accompanied by the release of heat.
0
500
1000
1500
2000
420
430
440
450
Temperature
0
500
1000
1500
2000
90
100
110
120
Coolant Flow
Time 
FIGURE 1.3
Temperature response of a reactor to changes in coolant ﬂow rate is used in identiﬁcation of the
reactor system (source: DAISY (Moor et al., 1997)).
For stable and an eﬃcient operation of a reactor, engineers are always confronted with the
design of a suitable controller that adjusts the ﬂow of the coolant in the jacket to regulate the
reactor temperature. An engineer conducts experimental studies on the reactor by varying
the coolant ﬂow and measuring the temperature response, a typical snapshot of which is
displayed in Figure 1.3 (data source Moor et al. (1997)). This data is used to identify a
model between the manipulated variable and the controlled variable.
Identiﬁcation is frequently used to build models for monitoring processes.

Introduction
5
Example 1.4: Process Monitoring
Monitoring an industrial plant consists of ﬁrst building a model of the plant under normal op-
erating conditions followed by a projection of the fresh data onto this model online. Industrial
processes can be too complex for the development of a ﬁrst-principles model. The natural
recourse is to identify a model relating process variables from routine normal operating data.
This is the case of multivariable identiﬁcation. The challenges are the multivariable nature,
non-linearities and importantly the closed-loop conditions.
Models can be used to understand relationships between variables so as to be able to detect errors
in fresh data and correct those errors.
Example 1.5: Data Reconciliation
Measurements from sensors are always not reliable in the sense that they are not necessarily
consistent with the physics of the process. In a mixing process for example, the ﬂow and
temperature measurements may not satisfy the mass and energy balances. Data reconciliation
consists of ﬁrst detecting the presence of signiﬁcant errors (above tolerable noise levels) and
then rectifying the erroneous data. The ﬁrst step requires a model that is consistent with
the physical laws. For several processes, the form of the model equations is not known well
enough. Identiﬁcation comes to the rescue of setting up the simultaneous problem of model
estimation and gross error detection from data.
The next example is concerned with the development of a model of an aircraft.
Example 1.6: Flight Control
One of the key problems in ﬂight control is the attitude control, i.e., the control of the aircraft’s
orientation. Attitude control is carried out by exerting forces on the aircraft in the appropriate
direction thereby generating the appropriate moment about its center of gravity. A model
that predicts the orientation for a given direction of force is central to the design of this
controller. A typical procedure is to apply pilot-generated or computer-generated frequency
sweeps (inputs) and record dynamic responses using appropriate sensors. The challenges are
the presence of highly coupled and unstable dynamics.
The problem of identiﬁcation assumes an interesting form in the task of inferential sensing.
Example 1.7: Soft Sensing
There exist several physical variables for which sensing hardware does not exist or it is
that they cannot be measured on-line. Examples include composition of product stream in a
distillation column or a gasiﬁer, molecular weight of a polymer, ﬁneness of cement and so on.
In situations such as these, an attractive alternative is to ”soft” sense these variables (primary
variables) using measurements of other variables (explanatory variables). The identiﬁcation
problem is that of building a model between the scarce oﬄine (laboratory) measurements
of the primary variable and the frequently available on-line measurements of explanatory
variables.
System Identiﬁcation principles are useful in building an approximate simpliﬁed empirical model
of a ﬁrst-principles high-order non-linear model.
Example 1.8: Model Approximation
High-order rigorous ﬁrst-principles models allow process engineers to safely test new designs,
control strategies and monitoring schemes. However, it may be often required to work with

6
Principles of System Identiﬁcation: Theory and Practice
a simpliﬁed model of a process, e.g., in controller design. These ideas ﬁnd routine place in
process control and aircraft system design. System Identiﬁcation principles guide the user in
designing the appropriate input signal, setting realistic simulation parameters and ﬁnally in
building the desired model.
The following example presents an identiﬁcation exercise in the context of weather forecasting.
Example 1.9: Prediction of Relative Humidity
Plots of trends for June 01-27, 2010
Date
Relative Humidity
0
5
10
15
20
25
40
60
80
100
Date
Temperature
0
5
10
15
20
25
25
30
35
FIGURE 1.4
Plot of relative humidity and temperature at IIT Madras, Chennai, India from June 01 to 27, 2010.
Data is missing at random.
In a statistical approach to weather forecasting, the relative humidity (RH) of air can be
predicted using historical data. Additionally, past temperature measurements can be used
to improve predictions. In the former case, we build what is known as a time-series model,
whereas in the latter case we build a model typical of identiﬁcation. The challenge here is
that the user does not have the privilege to provide test inputs, i.e., changes in temperature.
Besides, the input itself is a measurement (corrupted with observation errors) rather than a
known quantity. Figure 1.4 shows a plot of RH and temperature recorded by an automated
weather station (AWS) located at IIT Madras, Chennai, India for the period June 01-27,
2010. The missing segments in the plot correspond to missing data segments.
Modern applications of identiﬁcation ﬁnd increasing use in energy systems and biomedical en-
gineering, a rapidly evolving ﬁeld of engineering in medicine and biology.
Example 1.10: Optimization
A fuel cell system generates electrical energy by electrochemically combusting hydrogen with
oxygen. For an eﬃcient operation of a fuel cell system, the operating conditions (e.g., stack
temperature and pressure) have to be set at their optimum. A dynamic model of the fuel cell
system allows the designer to determine the optimum operating conditions.

Introduction
7
Example 1.11: Insulin Delivery Control
A classical biomedical application of engineering principles is the development of an auto-
mated insulin delivery system for diabetic patients. To ensure eﬃcient control, the biomedical
engineer will ﬁrst require a mathematical model relating the insulin delivery rate to the glu-
cose levels in the body. Data from several patients are collated to identify a suitable model.
One of the challenges is the presence of feedback naturally present in the metabolic pathways.
In recent times, models have been used to understand the causal (directional) relationships between
variables.
Example 1.12: Network Reconstruction
In neurosciences, one of the prime interests is to uncover how certain active parts of the brain
are connected to each other. Neuroscientists can build the underlying network connectivity
by ﬁrst collecting measurements from select regions (e.g., electroencephalogram (EEG) data)
and then building causal models between such measurements. The coeﬃcients of the model
can be further examined in time- or in frequency-domain to detect the presence of directed
connectivities between measurements in those regions.
In general, the modeling objectives and the type of model naturally vary with each layer. In
process design, for instance, the usual aim is to identify the steady-state relationships between mea-
surements, whereas in control and monitoring the aim is to identify the dynamic behavior of the
plant. On the other hand, it may be necessary to develop a rigorous simulator of the process where
conducting experiments on the actual plant is often neither safe nor cost- or time-eﬀective. The end
use of the model clearly governs the accuracy requirements of the model. As an example, a model
used in the feedback control of a process is acceptable even if it is a low-order approximation of the
process whereas the model used for optimizing or simulating the same process is acceptable only if
it is able to deliver excellent predictions.
From the foregoing discussion, it is evident that the role and impact of identiﬁcation in process
operations and making innovative changes to processes is immense. While this being true, the qual-
ity of identiﬁed models depend on the level of sophistication in instrumentation and data acquisition.
Thus, while identiﬁcation helps in making innovative changes to systems, these enhancements, in
turn, facilitate better ground for identiﬁcation.
We discuss the second motivating factor for identiﬁcation, namely, the limitations faced by the
ﬁrst-principles approach in developing models.
Beneﬁts of empirical approaches
Identiﬁcation oﬀers a powerful and pragmatic alternative to ﬁrst-principles modeling, which uses
basic laws of material, momentum and energy balances combined with some constitutive (empiri-
cal) relationships. In the early days of control and automation, models were largely developed using
the ﬁrst-principles approach. These models primarily related continuous-time variables. A good un-
derstanding of the physics of the process is critical to the development of ﬁrst-principles models.
Most modern processes of interest are complex to the extent that precludes a fundamental approach.
The natural recourse has been towards data-driven approaches since they assume minimal prior
knowledge and largely depend on input-output observations for developing models. With advances
in measurement technology and the dawn of the digital era in the early 1960s, data-based approaches
gained large momentum. Rapid developments in estimation theory, advances in computational sci-
ences combined with the beneﬁts of digital technology over analog counterparts strongly nourished
data-driven approaches.

8
Principles of System Identiﬁcation: Theory and Practice
Models
First-principles
(Fundamentals)
Empirical
(Data,driven)
Write conservation 
equations
Constitutive laws
...
Perform experiments
Propose models
Estimate parameters
...
FIGURE 1.5
Two approaches to modeling: ﬁrst-principles vs. experimental (empirical).
Figure 1.5 oﬀers a simplistic comparison of the ﬁrst-principles and empirical approaches to mod-
eling. In addition to being natural alternatives, empirical approaches oﬀer several practical beneﬁts,
salient among them being (i) the ability to build models with minimal process knowledge and (ii)
the ﬂexibility in selecting the model structure and (iii) the convenience of implementing them in a
soft form, i.e., in the form of a computer-interpretable code. Not surprisingly, identiﬁcation is today
an integral part of modern industrial control and automation schemes.
There exist several distinguishing and contrasting features of ﬁrst-principles and empirical mod-
els. These are discussed in §3.2.1. At this point of discussion, two important points merit attention.
The ﬁrst point is concerned with the transparency (physical meaning) of the models. First-principles
models by their way of construction are transparent whereas the empirical models are generally
opaque with respect to the physics of the process because they are developed largely using mathe-
matical methods rather than physical laws. For this reason, models obtained from identiﬁcation are
termed as black-box models. The opacity of empirical models can be reduced by incorporating a
priori process knowledge, for example, by imposing known structural constraints on the model, re-
sulting in what are known as grey-box models. These ideas are relatively modern and usually treated
as advanced topics in identiﬁcation (§23.7.2 presents some preliminary ideas). The second point is
related to the extrapolation capabilities of these models. Data-driven models have, in general, good
predictive abilities only over the operating regime spanned by the data whereas ﬁrst-principles mod-
els are superior in this respect.
As with any matured ﬁeld, a brief study of history of its evolution and developments is bene-
ﬁcial in appreciating the depths and breadths of the subject, treading previously unexplored paths,
avoiding accidental re-invention of wheels and in several other ways. With this motive, a historical
account of System Identiﬁcation follows.
1.2
HISTORICAL DEVELOPMENTS
The idea of identifying models from data is perhaps as old as the art of learning through experi-
mentation. In today’s era of automation, engineers increasingly turn to data-driven approaches for
building approximate dynamic models. Empirical relationships are commonplace in thermodynam-
ics and transport phenomena. There is hardly an application today where data-driven knowledge
is not used. The formalization of concepts and techniques of identiﬁcation as we learn today has
evolved primarily through a variety of contributions from engineers and statisticians. Much of the
presentation below is inspired from the surveys of Åström and Eykhoﬀ(1971), Gevers (2006), and
Ninness (2009a).
Modern System Identiﬁcation has its roots in the eighteenth and nineteenth century developments
of mathematics and probability theory (read Ninness (2009a) for a good account of developments).
Some milestone results in this direction include the conditional probability due to Bayes (Bayes,

Introduction
9
1763), the method of least squares (LS) due to Gauss and Legendre (Gauss, 1809), emergence of
the illustrious Fourier transforms (Fourier, 1822; Proakis and Manolakis, 2005), Schuster’s peri-
odogram measure (Schuster, 1897). Of these the least squares method and the ideas therein have
possibly had the maximum impact on data-based modeling and parameter estimation. It is expected
to do so for many decades to come. Gauss’s conception of the LS method itself originated from his
proposition to determine planetary orbits from astronomical data instead of using physical laws such
as Kepler’s laws of motion. This was a classical example of system identiﬁcation. The LS method
is, in fact, regarded as a precursor to and the core engine of several present-age sophisticated esti-
mation methods including the celebrated Kalman ﬁlter for state estimation (read Sorenson (1970)
for a technical treatment).
Early decades of the twentieth century witnessed a surge of developments largely tilted towards
modeling of stochastic processes. Fisher’s concept of likelihood and the celebrated maximum likeli-
hood estimation (MLE) method (Fisher, 1912, 1922), contributions by Yule and Walker in modeling
auto-regressive processes (Walker, 1931; Yule, 1927) and more importantly, the landmark works of
Khinchin, Kolmogorov, Wiener, Cramer and the likes laid solid foundations for modeling random
processes in time and frequency (spectral) domains (see Priestley (1981) for a good historical ac-
count). Applying these concepts to real data gave birth to the ﬁeld of time-series analysis (TSA, also
known as statistical signal processing), whose main focus was prediction of phenomena driven by
unknown or unmeasurable causes. The auto-regressive moving average (ARMA) model was theo-
retically shown to be capable of representing a wide range of linear stationary processes with the
support of the spectral factorization theorem and the conception of white-noise stochastic process.
Gradually TSA matured into a solid ﬁeld with widespread applications in engineering, sciences and
econometrics. A signiﬁcantly distinct body of work started to emerge with the inclusion of known
(deterministic) eXogenous causes into ARMA models, culminating into methods for identiﬁcation
such as ARX and ARMAX. These models are essentially parametrized diﬀerence equation descrip-
tions with the input and the white-noise signal as the forcing functions for the deterministic and
stochastic subsystems, respectively (read Box, Jenkins and Reinsel (2008)). The stochastic parts of
these models, as remarked earlier, accounted for the eﬀects of unmeasured disturbances and mea-
surement noise. An interesting account of the connections between time-series analysis and system
identiﬁcation is chronicled in Deistler (2002) .
In a world of parallel developments, the ﬁeld of control and systems theory was being en-
riched with contributions from leading engineers (particularly during the post Second World War
era) resulting in formalization of systems concepts and systemic methods for tuning classical PID
(proportional-integral-derivative) algorithms. Control engineers began to use simpliﬁed continuous-
time impulse- and step-response models for controller design. The step response was found to be
particularly convenient because of its plant-friendliness (step changes are easier to introduce than
impulses) and the ease with which the three key pieces of information required for control, namely,
time-delay, time-constant and steady-state gain, could be extracted. Numerous empirical methods to
optimally estimate these parameters from the step response were developed. These models remain
the backbone of several methods for tuning lower-level industrial control loops even today. Step re-
sponse models have also been used successfully in several model predictive control (MPC) schemes
(reference), known under the name dynamic matrix control (DMC). However, step-type signals are
weak in frequency content and not suited to modeling of high-order systems. Consequently they
also have limited predictive abilities. Adding to these limitations was the rising need for methods
that can use observed input-output data rather than merely experimental data.
With the dawn of digital era in the 1950s, computer-based control schemes began to be foreseen
as platforms for powerful next-generation industrial control strategies. Advances in measurement
and instrumentation technology helped in materializing these ideas in practice. The much acclaimed
sampling theorem due to Shannon (1948) and Whittaker (1935) opened up doors to the world of dig-
ital analysis of continuous-time systems. Engineers were able to introduce custom-designed inputs

10
Principles of System Identiﬁcation: Theory and Practice
with richer excitation instead of a simple step-type signal and also store large volumes of experi-
mental / operating data. Emergence of novel eﬃcient computational algorithms for signal processing
tools introduced a paradigm shift in digital signal processing. A landmark invention was the Fast
Fourier Transform (FFT) algorithm for spectral analysis of signals due to Cooley and Tukey (1965).
The digital systems revolution was aptly supported by a rapid formalization of discrete-time systems
theory. Data-driven discrete-time models began to emerge as natural and preferred alternatives. A
paradigm shift in control and estimation theory occurred with the arrival of the celebrated Kalman
ﬁlter (Kalman, 1960; Kalman and Bucy, 1961) which not only provided optimal algorithms for
state estimation but also propelled the theory of optimal control. Combined with the new methods
of identiﬁcation, the notion of approximate as opposed to true models gained increasing empha-
sis within the control community. This is because optimal controller design based on simpliﬁed
reduced-order models was computationally lighter. State-space descriptions gradually grew to be
the natural choices for joint identiﬁcation and signal estimation, as well as for multivariable control.
By mid-1960s, two distinct classes of methods precipitated: one class drawn on the techniques
of time-series analysis (predominantly using parametrized input-output representations) and an-
other built on the state-space descriptions. The seminal papers by Åström and Bohlin (1965) and
Ho and Kalman (1966) can be treated as the foundational works for the two streams of identiﬁca-
tion methods. With the topic gaining the status of a ﬁeld of its own, formalizations of deﬁnitions
and estimations began to emerge. Zadeh (1962) gave a formal deﬁnition of identiﬁcation as “the
determination on the basis of input and output, of a system within a speciﬁed class of systems, to
which the system under test is equivalent.” The work by Åström and Bohlin (1965) solved the pa-
rameter estimation methods for ARMAX models in the MLE framework, which was then extended
to the general family of Box-Jenkins models (Box, Jenkins and Reinsel, 2008). On the other hand,
the work of Ho and Kalman (1966) established a method for determination of state-space models
from impulse response coeﬃcients.
The ﬁeld of System Identiﬁcation experienced a transformation in theory and practice starting in
the mid-1970s with the introduction of prediction-error (PE) identiﬁcation methods due to Ljung
(1976a,b, 1978). A signiﬁcant change of approach to empirical modeling came about due to a
marked shift in the problem formulation, wherein the restrictive search for true model structures
was replaced by a broader and practical search for the best approximate models. The PE minimiza-
tion (PEM)2 approaches, which were devised for estimating parametrized models (both input-output
and state-space), were shown to contain several well-known methods including the likes of LS and
ML estimation. In fact, it is believed to have drawn inspiration from the ML estimation method. Ex-
pectantly, the PE methods resulted in almost always non-linear optimization problems (with unique
solutions only for special model structures and quadratic objective functions).
Ljung (1976a,b) showed that the PEM estimates asymptotically (large sample conditions) con-
verge to the true parameters under some mild assumptions on the data generating process (also see
Caines (1976)). Establishment of the asymptotic Gaussian distributional properties of these meth-
ods under fairly general conditions (Ljung, 1999; Ljung and Caines, 1979) provided the necessary
support for their practical use. The study of how error characteristics in parameter estimates trans-
late to errors in transfer functions (frequency response functions) (Ljung, 1985b; Wahlberg and
Ljung, 1981) solidiﬁed the position of prediction-error methods in the ﬁeld of control. Expressions
for bias (accuracy) and variance (precision) highlighted the tunable elements of identiﬁcation and
their impact on the ﬁnal model quality. A number of other properties and implementation aspects of
prediction-error methods were subsequently established, reﬁned and reviewed in the years to follow.
Several excellent articles, textbooks and innumerable conferences on identiﬁcation have since been
organized, especially on linear time-invariant (LTI) dynamic systems. Over the years, signiﬁcant
developments occurred in the areas of non-linear, time-varying and other branches of identiﬁcation
2The acronym PEM is also used to abbreviate other related phrases in System Identiﬁcation, e.g., prediction-error models.

Introduction
11
as well. The PE minimization methods are today at the heart of many state-of-the-art identiﬁcation
algorithms (for parametrized models). Various other branches of identiﬁcation oriented towards spe-
ciﬁc end use of models (e.g., control relevant identiﬁcation) have also evolved over the years.
A limitation of the prediction-error approach is that it is not equipped to handle the joint prob-
lem of identiﬁcation and signal (state) estimation that arises when the observed variable is diﬀerent
from the physical output of interest, but is related to it. Such situations are not uncommon in process
systems. The state-space descriptions are apt choices for these classes of problems. An added ad-
vantage of state-space models is that they can represent multi-input, multi-output (MIMO) systems
with elegance and simplicity. Two broad classes of state-space models exist (as with the input-
output models), namely, the non-parametrized (unstructured) class that make minimal assumptions
on the process and parametrized class that results as a consequence of assuming a certain structure
on the state-space matrices. Estimating non-parametrized state-space models with PEM methods
involve diﬃculties that are mitigated only through parametrizations. However, parametrization of
multivariable models usually requires prior insights into process characteristics; further, a single
scheme of parametrization does not suit all applications. Motivated by these considerations and
equipped with the tools of linear algebra, statistics and optimization, algorithms for numerical (non-
parametric) state-space identiﬁcation were sought. The work of Ho and Kalman (1966) marked the
beginning of such methods, wherein an elegant method for estimating a state-space model from
the impulse-response coeﬃcients using what are known as Hankel matrices was presented. Subse-
quently, two signiﬁcant works by Akaike (1974b) and Kung (1978) laid the foundations for a set of
novel methods, collectively known as the subspace identiﬁcation (SSID) algorithms for estimation
of non-parametric state-space models from measured data (Overschee and Moor, 1996; Qin, 2006).
The principal beneﬁts of subspace methods are that they are non-iterative (unlike PEM), and
based on eﬃcient numerical methods such as singular-value decomposition (SVD) and QR factor-
ization methods. Further, they contain an implicit implementation of the numerical Kalman ﬁlter.
The classical Kalman ﬁlter assumes that a model is readily available whereas the numerical ﬁl-
ter presents the optimal estimates directly from data through a series of orthogonal projections.
Thus, vis-a-vis PEM approaches, subspace methods have an edge with respect to parametrization,
convergence, numerical eﬃciency and also model-order reduction (Overschee and Moor, 1996).
A highlight of the subspace methods is that it can “automatically” estimate the order of the state-
space model unlike the classical non-parametric input-output identiﬁcation methods. Thus, it re-
quires minimal intervention of the user. Notwithstanding the numerous beneﬁts, subspace methods
often come in for two standard criticisms, at least in the early years of development: ﬁrst, that they
generate sub-optimal estimates (unlike PEM) and second, application to closed-loop identiﬁcation
is marked with challenges. While the gravity of the ﬁrst point has been considerably reduced by a
formal interpretation of subspace methods in the PEM framework, the second limitation has been
overcome with considerable success in a number of works (Huang, Ding and Qin, 2005; Katayama
and Tanaka, 2007; Larimore, 1996; Ljung and McKelvey, 1996; Verhaegen, 1993)
To summarize, there exist two broad classes of algorithms, namely, the prediction-error and
the subspace identiﬁcation algorithms for developing empirical dynamic models from input-output
data. The PE methods ﬁnd wide usage in estimation of parametric models and can be used in
both open- and closed-loop conditions. They possess good large sample properties and result in
Gaussian distributed estimates. Subspace identiﬁcation on the other hand is suited for estimation of
non-parametrized state-space models under open-loop and closed-loop conditions. While the PEM
estimates are theoretically guaranteed to be optimal, subspace methods do not necessarily guarantee
optimality. Since the latter deal with non-parametric models, it has been a recent practice to run the
data through SSID methods prior to estimating a parametric model using the PE algorithms.
In closing, special mention should be made of a relatively less used, but powerful, method known
as the instrumental variable (IV) method. The IV technique is primarily devised to produce consis-
tent (convergent) and eﬃcient (minimum error) estimates in situations where the LS method fails to

12
Principles of System Identiﬁcation: Theory and Practice
do so. It replaces the regressors in a LS method with what are known as instruments. The idea of the
IV method was originally devised for identiﬁcation problems in econometrics where the causes (ex-
planatory variables) are known with error unlike in the classical identiﬁcation of most engineering
problems where the inputs are deterministic (known) variables (read Angrist and Krueger (2001)
and Stock and Trebbi (2003) for an analysis of the historical origins). Gradually they were adopted
to the engineering arena (Soderstrom and Stoica, 1994), sometimes grouped under the banner of
correlation methods (Ljung, 1999).
Remarks:
The historical account above is by no means exhaustive and has been intentionally restricted to
the mainstay of this text, which is the sub-ﬁeld of dynamic, linear time-invariant systems. There exist other
branches of identiﬁcation that have attracted considerable attention over the last two decades, such as black-box
identiﬁcation of continuous-time / non-linear / time-varying / multiscale systems and grey-box identiﬁcation,
to name a few. An interested reader is referred to articles of the likes of Bohlin (2006), Kerschen et al. (2006),
Rao and Unbehauen (2006), Sjöberg et al. (1995), and Tangirala, Mukhopadhyay and Tiwari (2013) and the
classical book of Ljung (1999), in addition to the previously referenced survey papers for a broad overview of
developments in this ﬁeld.
Through the foregoing sections it is hoped that the reader has garnered a bird’s eye view of
System Identiﬁcation, recognized the key motivating factors and gained an overview of the prime
developments and conceptions in this ﬁeld. In the descriptions above, a number of terms such as
parametrization, bias, variance, consistency, etc. have been used. Technical deﬁnitions and explana-
tion of these terms are provided later at appropriate points in the text.
From a layman’s perspective, identiﬁcation appears synonymous to the ﬁt of curves to data
(curve-ﬁtting). This is indeed true. However, it is also important to recognize that identiﬁcation
is much more than merely curve ﬁtting. Identiﬁcation exercises are challenged primarily by exper-
imental factors (input design), process complexities, and measurement uncertainties and require a
sound knowledge of models and their estimation. These challenges and limitations can be dealt
deftly only through a holistic, careful and a step-by-step understanding of the theory. A systematic
approach to identiﬁcation will overcome or in the least minimize the challenges in empirical model-
building by a careful design of experiments for identiﬁcation, judicious choice of models and an
appropriate deployment of estimation algorithms. A fact to remember is that the task of identiﬁca-
tion is almost always an iterative exercise. To rightly interpret the results at each iteration and to
incorporate the end-of-iteration learning back into the identiﬁcation exercise requires a good un-
derstanding of how diﬀerent elements of identiﬁcation impact the model that is being developed. A
methodical approach will not only result in a high-ﬁdelity model but will also guide us on how we
should conduct our experiments or make improvements at diﬀerent stages to improve model quality.
The ability to attribute the success or failure of a model at the end of an identiﬁcation exercise to
the right factors can only rest with a learned practitioner.
Aims and objectives of this text
The grand objective of this text is to present a self-contained learning material on developing dy-
namic empirical discrete-time models, predominantly, linear system identiﬁcation, aimed at be-
ginners, instructors/researchers and practitioners of this subject. Speciﬁcally the objective is to ex-
plain and illustrate the following:
i. systematic procedure for identiﬁcation
ii. diﬀerent deterministic-plus-stochastic descriptions used in identiﬁcation of LTI systems
iii. technical concepts such as parametrization, bias, variance, consistency, etc.
iv. classical and modern estimators, namely, method of moments, LS, MLE and Bayesian methods
v. estimation of signal properties such as auto- and cross-correlation, spectral density, coherence

Introduction
13
vi. prediction-error and subspace-identiﬁcation methods
vii. estimation of time-delays and non-parametric models
viii. practical aspects of model development: how to assess the goodness of models, how to reﬁne an
estimated model using statistical and practical guidelines, etc.
ix. concepts of design of inputs and experiments for identiﬁcation
The emphasis is on the interpretations and practical aspects of identiﬁcation with some aﬀordable
sacriﬁce of rigor. The underlying principles are explained with suitable demonstrations and illus-
trative examples while attention is also paid to the development of key theoretical expressions. It is
hoped that a healthy balance of theory and practice is achieved in this process.
An overview of selected advanced topics is provided towards the end of this text. These con-
cepts, although more challenging and complex than their linear counterparts, are still based on the
principles of linear system identiﬁcation.
1.3
SYSTEM IDENTIFICATION
Identiﬁcation is the exercise of developing a mathematical relationship (model) between the
causes (inputs) and the eﬀects (outputs) of a system (process) based on observed or measured
data. Stated otherwise, identiﬁcation establishes a mathematical map between the input and
output spaces as determined by the data.
Terminology and notation
The terms input and output in identiﬁcation have generic meanings in identiﬁcation. Outputs con-
stitute all those signals that are measured and which one wishes to predict. They are also known
as responses or predicted variables. Inputs collectively refer to all variables that are considered to
inﬂuence the outputs. The input set consists of both that which can be manipulated by the user
(probe signals, and that which cannot be adjusted but can be measured. The former subset of sig-
nals are frequently referred to as inputs and the latter subset as measured disturbances. This is the
terminology that is followed in the present text.
Process
Input
signals
Output
Disturbances 
Sensors
Measurable 
Measurements 
of responses &
disturbances
Sensor Noise
!"#$%&'$()$'*#')+$,)--"'*.%/$*0%.'1"'$(%',#%2
Actuators
FIGURE 1.6
(SEE COLOR INSERT) The system being identiﬁed consists of the true process and additional
elements.
Figure 1.6 depicts the participating elements in an identiﬁcation exercise, namely, the actuators,
process (which we wish to identify), sensors and disturbances in addition to the probe signal and
the response. Disturbances themselves are categorized into two classes - those which can be mea-
sured (e.g., temperature ﬂuctuations in a hot and cold ﬂuid mixing process) and those which are
unmeasured (e.g., wind disturbances experienced by an aircraft).

14
Principles of System Identiﬁcation: Theory and Practice
An important observation merits attention - the discrete-time model built by the user is that of
the system appearing in the shaded region and not that of the process alone. In other words, the
identiﬁed model not only explains the (continuous-time) process dynamics, but also the actuators,
sensors and as already stated, eﬀects of the disturbances. Extracting the model of the continuous-
time process from the identiﬁed discrete-time model is certainly a non-trivial task (see also remark
below).
The following notation is used in the text. Discrete-time physical input (adjustable) is denoted
by u[k], measured response by y[k], unmeasured and measured disturbances by d[k] and dm[k]
respectively, where the index k stands for the kth observation (sampling) instant. States and deter-
ministic variables as the case may be are represented by x[k]. Continuous-time signals and functions
are denoted by parentheses, for example, u(t) and y(t), where t is a continuous-time quantity. We
shall for most portions of the text, turn oﬀthe measured disturbances; to include them in the analysis
whenever necessary is fairly straightforward (at least for linear systems). The eﬀect of the unmea-
sured disturbance d[k] is represented by v[k]; it is assumed to additively corrupt yt[k], the true
response of the process to the input. Vectors shall be indicated by boldfaced notation, e.g., u[k] for
a vector of inputs. Matrices are denoted by (boldfaced) uppercase characters, as in A or Γ.
1.3.1
THREE FACTS OF IDENTIFICATION
There are three universal facts of identiﬁcation concerning the accuracy and precision of identiﬁed
models, which also provide the guiding paths for identiﬁcation:
1. It is generally not possible to build an accurate model from ﬁnite-sample data. Any model es-
timated from data contaminated with errors can never be accurate. A more important factor is
the possibility of a model-process mismatch (any process is typically more complex than a pre-
sumed mathematical model). Mis-speciﬁcation of the model structure (see §18.5.1 for a formal
deﬁnition) usually lead to systematic errors in model estimates and predictions. Technically, such
estimates (of models, parameters or signals) and predictions are termed as biased. The general
eﬀort in estimation is to produce unbiased estimates, but this can be achieved only with the “cor-
rect” speciﬁcation of model structure, proper choice of estimation method and in many situations
only with inﬁnite (very large) observations. When the latter is achieved, the model is said to be
asymptotically unbiased. Technical deﬁnitions of (ﬁnite-sample, statistical) bias and asymptotic
bias are provided in §13.3.
2. It is generally not possible to estimate a precise model from ﬁnite-sample data. This stems from
the fact that a single record of data is only one of the several possible data records for the same
experiment. Repeating an experiment (while holding all the controllable factors at the ﬁxed val-
ues) produces numerically a diﬀerent set of readings. The cause for this variability in data across
diﬀerent runs of experiments is the randomness in disturbances and measurement noise. In prac-
tice, one usually works only with a single experimental ﬁnite-length record, the estimated model
is only one among many models that could have been estimated from other possible realizations.
Thus, the variability in data manifests as impreciseness in estimates (of models, parameters or
signals). The statistical measure of variability is the variance. Every estimation method strives
to drive the variance in estimates to zero. The fact is that it is never possible to precisely estimate
any parameter (model or signal) from ﬁnite-length data. However, it may be achievable under
asymptotic (large sample) conditions. This is a highly desirable property of every estimator. See
§13.4 and 13.10 for technical deﬁnitions and explanations.
3. The accuracy and precision of the optimally identiﬁed model, among other factors, is critically
dependent on the (i) input type (excitation and shape, with the latter holding for non-linear sys-
tems) and the (ii) signal-to-noise ratio achieved in the experiment. A generalized term capturing
both of these aspects is information. The quality of the ﬁnal model depends on how informative
the data is. Fisher’s information metric (Fisher, 1925) plays a fundamental role in this respect

Introduction
15
(see §13.2).
To understand the role of information intuitively, recall Example 1.2 pertaining to an interview
process. The success of selecting the “best” candidate depends on the “information” obtained by
the interviewer through a set of suitable questions (number and nature) as well as the relative
uncertainties for that candidate.
Therefore, an important task in identiﬁcation is input design. The challenge is that a proper
design of input requires suﬃcient knowledge of the system and the level of uncertainties, which
is the purpose of input design itself! Identiﬁcation is therefore inevitably an iterative exercise.
Section 2.1 illustrates the role of input in identiﬁcation on a simple example. Theoretical details
are discussed in §22.3.
Whenever one speaks of accuracy and precision, technically one requires to have a reference
point. typically the truth (Section 13.3 and 13.4 presents technical deﬁnitions of these terms). In
the statements above as well, the description of a “true” system is tacitly assumed to be available.
Practically, however, the complexity of the system that is being identiﬁed is beyond the reach of a
mathematical description. Then, the reference point is the “best” approximation that can be realized
for the chosen model structure and the given experimental data, especially, inputs. Nevertheless,
for theoretical analysis, i.e., for academic purposes, one often assumes a “true” system primarily
to study accuracy and precision properties (of a model structure) resulting from an identiﬁcation
exercise with a chosen estimation algorithm and the input design for a given system.
Given an input-output data set, there exist many approximate models that can numerically explain
the input-output data with reasonable accuracy and precision. The main tools for realizing the “best”
model are built on concepts of linear algebra, estimation (optimization), probability theory and
stochastic signal processing. A point of practical importance is that the optimal estimation algorithm
delivers the best model conditioned on a user-speciﬁed set of parameters (e.g., model class, order,
time-delay, etc.). The user is required to further optimize these free parameters, which can be done
eﬃciently only through a formal study of identiﬁcation.
Remarks:
The identiﬁed model is usually discrete-time in nature since it is based on sampled data. When
the data is generated through sampling a continuous-time process3 with the aid of sampler and hold devices
(see Figure 1.8 and the associated discussion), there are certain merits in identifying the inherent continuous-
time process. Justiﬁably, there has been a renewed interest in recent times to directly identify the continuous-
time process from input-output data. Historically, methods for developing lower-order continuous-time models
from step response data existed even before the emergence of modern identiﬁcation (recall §1.2), but were
overshadowed by the surge of discrete-time identiﬁcation methods. The last two decades have seen the active
development of eﬃcient methods for directly identifying or indirectly recovering continuous-time models from
sampled data. The theory related to these topics is outside the scope of this text. An interested reader is referred
to the rich literature available on this topic (Garnier and Wang, 2008; Rao and Unbehauen, 2006)
We now turn our attention to the model, which is the centerpiece of identiﬁcation. In the follow-
ing section, only a brief overview of the models and certain important classiﬁcations is provided.
Chapter 3 treats the topic of modeling in greater detail and presents the necessary technical details
and terminology.
1.3.2
NOTION OF A MODEL
A model of a process is broadly deﬁned as that entity which can emulate the characteristics of
that process for a given set of operating conditions and parameters.
3A large class of processes naturally occur in discrete-time for which this discussion does not apply. Examples include
population growth, average rainfall, etc.

16
Principles of System Identiﬁcation: Theory and Practice
It is the lens through which the observer analyzes the process. The usages of the term model
in real-life phrases such as a model apartment, a model design also have a similar connotation:
a substitute or a prototype for the original process. A few examples below oﬀer glimpses of the
diﬀerent forms of models that are encountered in engineering and other scientiﬁc applications.
Example 1.13: Spring-Mass System
The steady-state displacement of a spring x under the application of a force F, under some
mild assumptions is nicely modeled by Hooke’s law
F = −kx
where k is the spring constant. The model is an example of a static model, relating instan-
taneous quantities.
Example 1.14: Liquid Level System
A liquid level system, commonly used as a buﬀer in many industrial processes, consists of
a cylindrical tank with in and out ﬂows. The transient relationship between the liquid level
h(t) and the inlet ﬂow rate Fi (t) can be modeled as
Ac
dh(t)
dt
= Fi (t) −Cv
p
h(t)
where Ac is the cross-sectional area of the tank and Cv is the valve coeﬃcient of the valve at
the outlet. This is an example of a dynamic, non-linear, ordinary diﬀerential equation model.
Example 1.15: RLC Circuit
The dynamic behavior of the output voltage y(t) of an RLC circuit is observed at Ts time
interval for a change in input current u(t). The resulting discrete-time system is described by
the set of equations
"x1[k + 1]
x2[k + 1]
#
=
"a11
a12
a21
a22
# "x1[k]
x2[k]
#
+
"b11
b21
#
u[k]
y[k] =
f
0
R
g "x1[k]
x2[k]
#
where R is the resistance and the elements {ai j}, {bi j} depend on the values of inductance L,
capacitance C and the sampling interval Ts. The discrete-time quantities are denoted by the
integer index k.
A model such as this one is known as a discrete-time linear state-space model (of second
order).
Example 1.16: Plug-Flow Reactor
A plug-ﬂow reactor is a tubular reactor which is continuously fed with a reactant at one
end of the reactor to produce a desired product at the other end. For a reactor carrying out
ﬁrst-order reaction A −→B under isothermal conditions, the unsteady-state description of
the composition of the reactant cA(t, z) and product cB(t, z) can be modeled as
∂cA
∂t
= −v ∂cA
∂z −k0cA exp
 
−EA
RT
!
∂cB
∂t
= −v ∂cB
∂z + k0cA exp
 
−EA
RT
!

Introduction
17
where v is the ﬂuid velocity, T is the temperature of the reactor and the partial derivatives
are along time t and length of the reactor z ∈[0, L], respectively.
This is an example of a distributed parameter model, which is used to describe a process
that evolves in time as well as along another dimension (in this case, space).
Example 1.17: Spring-Mass Dampener
The spring-mass-dampener systems are representative of the shock-absorber systems and
hydraulic systems that have second-order dynamics. When sinusoidal forcing functions are
applied to these systems, the response at steady-state is obtained by means of the complex
frequency response function
G(jω) =
Kω2n
(ω2n −ω2) + 2jζωnω
where ωn and ω are the natural frequency of the system and the input, respectively, while ζ is
the damping factor of the system. A model such as this is an example of a frequency-domain
description of a system.
As discussed in the previous sections, a realistic identiﬁcation exercise always results in a com-
posite model consisting of deterministic (which explains eﬀects of known inputs) and stochastic
(describing impact of unknown causes) terms. The example below pertains to a widely used model
class for identiﬁcation.
Example 1.18: Auto-Regressive Exogenous (ARX) Model
A second-order empirical auto-regressive model with exogenous input has the following
mathematical form:
y[k] = −a1y[k −1] −a2y[k −2] + b1u[k −1] + e[k]
(1.1)
where y[k] is the measured output, u[k] is the physical (exogenous) input and e[k] is a purely
random signal that is absolutely unpredictable. The latter can also be thought of as a ﬁctitious
input, whose statistical properties are partly known, but never known in amplitude. When
written in transfer function form (introduced in Chapter 4), it is easy to see the measurement
as actually a sum of two eﬀects,
y[k] =
b1q−1
1 + a1q−1 + a2q−2 u[k] +
1
1 + a1q−1 + a2q−2 e[k]
(1.2)
where q−1 is the backward shift operator such that q−1u[k] = u[k −1] (see Chapter 4).
The model in the foregoing example is a parametric model (characterized by parameters a1, a2 and
b1), diﬀerent types of which are presented in Chapter 17.
Chapter 3 presents a rigorous deﬁnition of the model with a detailed presentation of the diﬀerent
classes of models. At this point we discuss two very broad classes of models, namely, qualitative
(descriptive) and quantitative (numerical) models and two sub-classes in the latter category.
1.3.3
QUANTITATIVE VS. QUALITATIVE MODELS
Qualitative models, as the name suggests, merely describe the response of a system on a categorical
basis with little or no involvement of numerical values. For example, when the heat input to a ﬂuid
heating system is increased, the temperature of the ﬂuid increases; or when the product draw in
a distillation column is increased, the purity of the top product decreases and so on. Quantitative

18
Principles of System Identiﬁcation: Theory and Practice
models, on the other hand, describe the relationship between quantiﬁed changes in input and output
in terms of mathematical expressions.
Among these two classes, quantitative models prove to be, clearly, more useful in process con-
trol, optimization, monitoring as compared to qualitative models whose use is mostly restricted to
making qualitative analysis of and improvements to process operations. The major advantage of the
quantitative models is that they allow us to draw inferences and make decisions based on quantiﬁed
criteria. Besides they can be easily programmed by means of a computer, which greatly reduces the
need for human intervention in process operations.
Quantitative models can be further categorized into diﬀerent pairs of classes depending on the
nature of the processes they describe, the assumptions made about the underlying phenomena and
the approach taken to develop them. We have already encountered two contrasting classes, namely,
the ﬁrst-principles vs. empirical models in Section 1.1. Two additional classiﬁcations that are fre-
quently encountered in the identiﬁcation literature are discussed below. A detailed description of
diﬀerent types of models and the basis for classiﬁcation is provided in Chapter 3.
1.3.3.1
Deterministic vs. Stochastic Models
In Section 1.3, we made an important observation. The measured response not only contains eﬀects
of the known inputs, but also the eﬀects of disturbances and measurement errors. The model that ex-
plains the eﬀects of inputs is usually termed as a deterministic model, while the model that explains
the eﬀects of disturbances and sensor noise is termed as a stochastic model. In general, deterministic
models accurately relate variables that are free of error, i.e., those which are known accurately while
stochastic models describe the uncertain characteristics of the process using probability theory and
time-series models. In an identiﬁcation exercise, the developed model is a composite one, contain-
ing both the deterministic and stochastic components. Chapters 2 and 3 discuss the related aspects
in detail.
1.3.3.2
Non-Parametric vs. Parametric Models
This forms a very important classiﬁcation in the modeling arena. The term non-parametric should
not be misunderstood as to be devoid of any unknowns or parameters. In fact, the term parametric
refers to the parametrization of the model. As a simple example, consider the step response model
of a system, which is simply the set of step response coeﬃcients at the sampling instants (from
start to steady state). This is a non-parametric model. However, if the system is assumed to have
ﬁrst-order characteristics, then the response can be characterized by three parameters, namely, gain,
time-constant and time-delay. When the response coeﬃcients are directly estimated, it is termed as
non-parametric identiﬁcation. Instead if the parameters are estimated, it is the case of parametric
identiﬁcation. Clearly, in the latter, the number of unknowns, are fewer than the former. However,
this advantage of parametric models only sets in when prior knowledge is available.
Parametric models possess a speciﬁc structure and order and are characterized by fewer parame-
ters while non-parametric models do not possess any speciﬁc structure or order but are characterized
by a large number of unknowns. Diﬀerence equation descriptions are common examples of the for-
mer class while convolution models (impulse response models) are examples of the latter. From an
identiﬁcation viewpoint, non-parametric models can be estimated with minimal a priori knowledge
while the estimation of parametric models demands some a priori knowledge on the user’s part.
This prior knowledge can be acquired by ﬁrst estimating a non-parametric model. A more detailed
presentation of these aspects is contained in Chapter 3.
Until this point we have studied the basic concepts of identiﬁcation and obtained a preview of
the diﬀerent types of models. Now we address the most important topic, which is the identiﬁcation
procedure itself.

Introduction
19
Essentials of Identiﬁcation
Model development is the primary goal in identiﬁcation. To ensure that the identiﬁcation method
delivers models with a desired accuracy and precision level, it is imperative that the user has a clear
understanding of:
i. What are the possible model structures for a deterministic process? (Chapters 3 to 5)
ii. How does one represent uncertainties and randomness in processes / data? (Chapters 7 to 11)
iii. Which is the most appropriate model structure to begin with? (Chapter 17)
iv. What are the qualities of a good estimator? (Chapter 13)
v. What methods are available for estimating optimal models? (Chapters 14, 15, 19, 20, 21 and 23)
vi. How does one assess the goodness of estimated models and construct conﬁdence regions? (Chap-
ters 13 and 22 )
vii. How to compute predictions given a model structure? (Chapter 18)
viii. What are the optimal inputs for a given identiﬁcation problem and how to design them? (Chapter
22)
Answers to the above questions are provided by a formal study of the subject indeed as indicated
by the respective chapters in the text. However, it is equally important to implement identiﬁcation
in a step-wise manner. The systematic procedure presented in the following section describes these
steps starting with data acquisition. This procedure is revisited in greater detail later in Chapter 22.
1.4
SYSTEMATIC IDENTIFICATION
The procedure for identiﬁcation can be divided into ﬁve salient steps, namely,
S1. Data Generation and Acquisition
S2. Data Pre-Processing
S3. Data Visualization
S4. Model Development
S5. Model Assessment and Validation
A ﬂowchart delineating the salient steps in identiﬁcation is shown in Figure 1.7. The ﬂowchart
highlights two important facets of identiﬁcation. Firstly, that identiﬁcation is an iterative exercise
and secondly, that prior process knowledge can be factored into every stage of identiﬁcation. In
fact, it is recommended to incorporate as much prior knowledge as possible. The diﬀerent steps are
discussed below in detail.
1.4.1
DATA GENERATION AND ACQUISITION
This ﬁrst step can be said to be the most inﬂuencing step in identiﬁcation, rightly so since the success
of every stage of identiﬁcation and the conﬁdence on the ﬁnal model depends on the information
quality (and quantity) of data. It is the food for identiﬁcation.
Figure 1.8 portrays the schematic of a typical sampled-data system. Discrete-time input designed
by the user is converted to an approximate continuous-signal by a hold device (also termed as the
digital-to-analog converter), which then excites the process with the help of an actuator (also known
as the ﬁnal control element). The resulting response is then observed with the aid of sensing device
that consists of a sampler and quantizer. The sensor is often known as the analog-to-digital (A/D)
converter. Sampled data is passed on to a data storage device.
There are three key decision variables in this operation, namely, the type of discrete-time input,
the type of hold device and the sampling rate. Input design is an identiﬁcation-speciﬁc issue and has

20
Principles of System Identiﬁcation: Theory and Practice
Model Development
Data Generation and Acquisition
Sensors
PROCESS
Inputs
Disturbances
Measurable
DATA
Select Candidate 
Models
VISUALIZATION
PRE-PROCESSING
NON-PARAMETRIC 
ANALYSIS
MODEL 
ESTIMATION
Estimation
Criteria
MODEL QUALITY 
ASSESSMENT
Satisfactory?
Prior 
Knowledge
No
Yes
MODEL
Residual Analysis
Estimation Error Analysis
Cross-Validation
... 
Actuators
Outputs
FIGURE 1.7
(SEE COLOR INSERT) A generic iterative procedure for System Identiﬁcation.
Process
User-designed input 
u[k]
D/A 
Converter
Sensor
Measured output
y[k]
Actuator
A/D 
Converter
y(t)
x(t)
u(t)
ua(t)
FIGURE 1.8
A standard sampled-data system.

Introduction
21
been reasonably well studied but with plenty of open-ended problems. The basic question of interest
is - what kind of excitation is best for a given identiﬁcation problem? Once again, this is analogous
to framing the right set of questions to be asked in an interview process or in an examination. Just
as the number, type and complexity level of questions depends on the purpose of the examination,
the number of candidates that take part and that have to be selected, the nature of the input is also
tied to the end use of the model, i.e., whether it is eventually used for control, fault detection or in
simulation and the accuracy plus precision requirements of the model.
The basic tenet is that the excitation in the input should be such that its eﬀect in the measured
output is larger than those caused by sensor noise / unmeasured disturbances. In closed-loop situa-
tions, the input moves are decided by the controller; in such situations, the user has no direct way
of adjusting the input excitation. However, indirect access is available through the set-point or a
dither signal (an external signal) that is introduced at the input or at the set-point. The central result
in design of experiments for identiﬁcation is strongly tied to the notion of identiﬁability, or more
appropriately the concept of “informative” data. The basic idea is illustrated later in §2.1. Formal-
ization of related concepts, as presented in §22.2 and §22.3, not only facilitates solutions to the input
design problem, but also allows us to obtain a preliminary idea of the model complexity that can be
built for a given data set. The concept of informative data stems from a central concept in identiﬁ-
cation, known as the identiﬁability, whose basic idea is illustrated in §2.1. A formal discussion of
the same appears in §18.6.
Obtaining informative data is critically dependent on the sampling rate. The issue of choosing a
suitable sampling rate has been at the roots of several ﬁelds, particularly in the ﬁeld of communi-
cations and signal processing where it all began six decades ago (Lüke, 1999; Unser, 2000). As in
the case of the input design problem, the major results in sampling theory are best formulated and
presented in frequency-domain. The celebrated sampling theorem due to Whittaker, Shannon and
Nyquist is a standing example of this fact. Despite the remarkable progress in the subject (of sam-
pling), certain open issues still remain. One such open-ended problem is in the context of choosing
a suitable sampling rate for multiscale systems, which are characterized by phenomena occurring
at time-scales diﬀering by at least an order (e.g., a fuel cell system that generates energy through
electrochemical reactions).
Finally, the hold device plays an important role in identiﬁcation because it alters the spectral char-
acteristics of the designed discrete-time input as a consequence of approximating the continuous-
time signal from the digital signal. Mathematically, this approximation can be carried out in in-
ﬁnitely diﬀerent ways. A widely used method is the zero-order hold (ZOH) approximation. It holds
the signal constant between two sampling instants. Essentially the interpolating curve is a zeroth
order polynomial. ZOH devices are popular due to their ease of implementation. All higher-order
devices are non-causal and therefore not realizable (causal versions exist, but also introduce addi-
tional complexities - they ﬁnd use only in very specialized applications).
Chapter 6 explains the basics of sampling and hold operations, and reviews discretization - which
is the procedure to derive the discrete-time equivalent of a continuous-time system.
1.4.2
DATA PRE-PROCESSING
The acquired data in its raw form is usually not ready to be used for model development. Often
the data has to be subjected to quality checks and a pre-processing step before presenting it to the
model estimation algorithm. There are many factors that aﬀect data quality (in addition to noise),
two among which are discussed below.
i. Outliers: Outliers are data which do not conform to other parts of the data largely due to sensor
malfunctions and/or abrupt and brief process excursions. Detecting and handling outliers in data
can be very complicated and challenging primarily due to the fact that there is no universal

22
Principles of System Identiﬁcation: Theory and Practice
deﬁnition of an outlier. Notwithstanding this fact, a few reasonably good statistical methods are
available for this purpose.
ii. Missing data: The issue of missing data is prevalent in several applications. Intermittent sensor
malfunctioning, power disruptions, non-uniform sampling and data transfer losses are some of
the common reasons for missing data. In Figure 1.4 we observed missing observations (at ran-
dom) of relative humidity and temperature. A few popular methods for handling missing data
include the ML-based expectation maximization and the multiple imputation methods.
Section 22.4.2 gives an overview of some well-known methods for handling missing data and
outliers.
Pre-processing of data may also be motivated by the assumptions, limitations and requirements
of model development. For instance, data may contain drifts, trends and other non-stationarities,
whereas most identiﬁcation methods assume stationarity of data, a condition requiring the statis-
tical properties of data to remain invariant with time. To bring such measurements into the realm
of stationary signals, two approaches are commonly implemented: (i) explicit ﬁtting of polynomi-
als and working with residuals and (ii) diﬀerence the series and work with the diﬀerenced series.
Sections 7.5.5, 9.7 and 22.4.1 discuss these approaches.
Pre-ﬁltering data is an elegant way of encompassing methods for handling a variety of data
characteristics such as drifts and noise. Further, it can be used to obtain preferentially accurate ﬁts
in select frequency ranges and to establish theoretical equivalences of diﬀerent parametric model
structures (see §17.5).
Data pre-processing can consume a signiﬁcant amount of the overall time and eﬀort in an identi-
ﬁcation exercise. The situation can be alleviated considerably by choosing a reliable instrumentation
and data acquisition system, and a careful experimental design.
1.4.3
DATA VISUALIZATION
Visualizing data is a key step in information extraction and signal analysis. The value of information
obtained from visual inspection of data at each stage of identiﬁcation is immense. Prior to the pre-
processing stage, visual examination assists in manually identifying presence of drifts, outliers and
other peculiarities. It also provides an opportunity for the user to qualitatively verify the quality of
data from an identiﬁcation viewpoint (e.g., suﬃcient excitation). A careful examination can also
provide preliminary information on the delay, dynamics and gain of the process. The information
obtained at this stage can be used at the model quality assessment stage. For instance, if the user
observes an underdamped behavior as a salient characteristic, any model that does not capture this
behavior can be rejected.
Powerful methods exist for visualizing multi-dimensional or multivariable data. The user can
exploit the eﬀectiveness of these methods in selecting the right candidate models. Post model devel-
opment, a visual comparison of the predictions vs. the observed values should be strongly preferred
to a single index such as correlation or similarity factor for assessing the quality of the model.
Finally, visualization of data in a transform domain (e.g., Fourier domain) can prove very ben-
eﬁcial. Examination of the input and output in frequency domain can throw light on the spectral
content and presence of periodicities. It is useful in obtaining a ﬁrst-hand feel of the level of (in-
put) excitation and the ﬁltering nature of the system. Time-frequency analysis tools such as wavelet
transforms (Mallat, 1999; Tangirala, Mukhopadhyay and Tiwari, 2013) can further provide valuable
information on the time-varying characteristics of the process.
1.4.4
MODEL DEVELOPMENT
Development of a model is the central goal of identiﬁcation, as we have already learned. As ex-
plained in §1.1, the general objective is to build a deterministic-plus-stochastic model. This part of

Introduction
23
identiﬁcation involves two steps: (i) specifying a model structure and order, and (ii) estimating the
parameters of that model by solving the associated optimization problem.
Choice of candidate models
Choosing the candidate models is perhaps the most challenging and time consuming part of iden-
tiﬁcation. The approach is usually iterative and governed by the following guidelines. Only a brief
overview is provided. The illustrative example of §2.4 highlights a few of these aspects, while a
detailed discussion with case studies is presented in Chapter 22.
1. Accuracy (bias) and precision (variance) requirements: For a given data set, the bias and variance
of the estimated model are determined by its structure and the estimation algorithm. An important
aspect is the interplay between the stochastic and deterministic parts of the model.
2. Prediction accuracy and horizon: The primary considerations here are the range (of time steps)
over which prediction is sought and the accuracy (over a frequency range). Unless otherwise
explicitly demanded by the application, the one-step ahead prediction is of interest.
3. End-use of the model: In addition to the predictive abilities, the end-application might impose
other requirements. For instance, if the intended use is in control, the model should be as simple
(low-order) as possible and should not have underestimated the delay. Further, the characteristics
of the process over its bandwidth should have been well captured. The branch of control-relevant
identiﬁcation is an oﬀshoot of these ideas.
4. Estimation aspects: The ease of estimation can be an important factor of consideration. Models
that yield linear-in-parameter predictors are typically preferred to those that are non-linear due
to convenience of computation and the existence of a unique solution. The price that is paid is
the prediction ability of the model. A trade-oﬀis therefore sought. These facts are theoretically
elucidated and illustrated in Chapters 18, 17, 21 and 22.
5. Prior knowledge: The choice of model may be motivated by some prior information known on
the type of models such as linear / non-linear, low- / high-order, etc. or on the structure of the
parametric model. As mentioned earlier, this facet of identiﬁcation falls under the purview of
grey-box modeling (see §1.4.6 for more discussion and §23.7.2 for illustrations).
Notwithstanding the inﬂuence of the above factors, in almost all situations, the user begins with an
initial guess of the structure and iteratively makes reﬁnements using the results from the assessment
of model quality.
Remarks:
One of the biggest beneﬁts of empirical modeling is the ﬂexibility in selecting the model structure.
As much as it equips the user with tremendous freedom, it also brings with it the risks of overﬁtting (see
Example 2.4 for an illustration and also §2.4). Moreover, a “correct” model is beyond the reach of any modeling
exercise. So to speak, no process can be accurately described by any mathematical description.
Therefore, the goal of identiﬁcation is not necessarily to develop a correct model, but is rather to build a
good and useful working model.
Estimation method
Once a candidate model is selected, what remains is its estimation, which is essentially an opti-
mization problem. Section 1.2 gave an overview of the methods available for estimation, namely,
the prediction-error minimization, instrumental variable and the subspace identiﬁcation methods.
A typical estimation criterion typically has a form of minimization of a function of the prediction
errors. The function is usually based on a distance metric. For example, least squares methods min-
imize the Euclidean distance between the predicted and observed values (squared 2-norm of the
prediction errors). Other factors such as quality of parameter estimates, number of parameters can
be factored into the objective function. Methods based on the maximum likelihood principle, on the
other hand, construct the objective function from probabilistic considerations.

24
Principles of System Identiﬁcation: Theory and Practice
In choosing an estimation algorithm, the prime factors for consideration are the goodness of
estimates and the ease of computation. Usually these are conﬂicting factors. However, without sac-
riﬁcing the key properties (e.g. precision) of an estimator, wherever possible a computationally
simpler algorithm may be chosen. The ﬁnal decision should be driven by a judicious, practical and
informed choice of algorithms.
1.4.5
MODEL ASSESSMENT AND VALIDATION
The model quality assessment and validation step is an integral part of any model development
exercise, be it identiﬁcation or a ﬁrst-principles approach. The focal points of analysis are
1. How eﬀectively has the model explained the output variations in the training data? The overall
goal is certainly to achieve as “small” a prediction error (minimum bias) as possible, but not at
the cost of low precision (variance in model or parameter estimates). With this objective in mind,
three tests are performed (Chapter 22 explains these points in detail with illustrations)
i. Statistical analysis of prediction errors or residuals: The key requirement is that there is no
residual information left for the model to capture.
ii. Error analysis of estimates: The (standard) errors should be small relative to the estimated
values.
iii. Analysis of model ﬁt: Metrics such as adjusted R2 and its variants are typically used for
determining the degree of ﬁt (of predictions).
2. How accurately does the model predict the response on a test (fresh) data set? This is the test
of cross-validation. The primary purpose of this test is to determine whether the model has
been trained to capture the global characteristics of the process as evidenced in the training
data set or has specialized to the local features of the training data. When the latter occurs, its
predictive capabilities for a fresh data set deteriorates and model is deemed to have been overﬁt.
The performance itself is evaluated based on certain metrics of ﬁt and prediction horizons.
The outcomes of the above diagnostic tests provide the necessary feedback for reﬁning the de-
cisions made in previous stages. If a model does not meet any of the aforementioned requirements,
it inevitably calls for improvements at one or more of the previous steps. When the user has con-
ﬁdence in data quality, eﬀorts should be directed towards reﬁning the structure and/or order of the
model. Naturally, a review of decisions in other stages may also be required. To achieve best results,
the user should have a sound knowledge of the impact of choices and decisions in the preceding
steps on the ﬁnal quality of the model.
1.4.6
PRIOR PROCESS KNOWLEDGE
As remarked above quite often some a priori knowledge concerning the (i) structure of the model,
(ii) order of the model, (iii) values of a subset of parameters and (iv) bounds on parameter values may
be available. For instance, in developing a model for a two-tank (in series) system it is known that
the process has second-order overdamped characteristics. It is certainly beneﬁcial to incorporate this
additional knowledge into model estimation in anticipation that (i) the resulting model will reﬂect
the physics of the process in a more transparent manner than a classical black-box model and (ii)
the resulting model will have better prediction capabilities than an unconstrained model.
Naturally, the degree of transparency increases with the available a priori information. The most
transparent case is that of the known mathematical form of the model usually through a ﬁrst-
principles analysis of the process and only the parameters remain to be determined. This may be
termed for lack of a better term, a white-box model.
Grey-box modeling arises prominently in development of state-space models with known struc-
ture. For a given input-output system, there exist inﬁnite state-space realizations that produce the
same input-output relationship. However, a particular structure may be desirable from an estimation

Introduction
25
viewpoint or by the application of interest. Constrained optimization of parametric models provides
the necessary framework for estimation of grey-box models.
Quite often it is the case that the prior knowledge is not known with certainty. For instance, the
analyst knows that the parameters of interest fall within a range or that impulse response has a par-
ticular shape. Bayesian approaches oﬀer a powerful framework for handling prior knowledge mixed
with uncertainty. These methods are now being widely applied in several ﬁelds because they directly
produce the uncertainty regions for the estimates unlike classical point estimators such as LS and
MLE. A major limitation of the Bayesian estimators until recently was the high computational cost
involved in implementing them. However, with the recently introduced Markov chain Monte Carlo
(MCMC) simulations, the barrier has been signiﬁcantly reduced. The mathematical paraphernalia
of Bayesian approaches can be quite complex and is usually covered in advanced texts. In this text,
nevertheless, some preliminary material is presented in §15.2 and §20.2.3.
Remarks:
Black-box models are usually in for criticism because they do not explicitly take into account the
physics of the process. Notwithstanding the technical correctness of these criticisms, a point in counter is that
a careful analysis of the data and a systematic identiﬁcation can produce good working black-box models that
have predictive capabilities similar to or sometimes better than that of a ﬁrst-principles model. Undoubtedly,
the success of building these models is crucially anchored to the data quality.
1.4.7
SUGGESTIONS FOR OBTAINING A GOOD MODEL
It is appropriate to conclude this section by prescribing the ingredients for obtaining a good working
model:
• Good quality data: Design and conduct experiments to generate informative data. The data
should be rich enough to distinguish between two competing candidate models.
• Data visualization: Often this step is undermined. Visual analysis of data can extract valuable
information with such ease that would otherwise require elaborate mathematical analysis. The
information obtained by a qualitative analysis at this stage is useful in making decisions in model
selection as well as in model validation.
• Suitable model structure and domain: Model structure should be based on end use, predictability
and physical insights. The right choice of domain (e.g., frequency) for data pre-processing and
modeling can signiﬁcantly enhance the quality of the model.
• Simplicity of the model: Simple models can be good approximations of complicated systems. A
complex model that produces marginal improvement in predictions at the price of large errors in
parameter estimates should be discarded in favor of a simpler model.
• Time-scale for modeling: Identifying the appropriate time-scale for the phenomenon of interest
is crucial. Slow sampling leads to loss of observability whereas excessively fast sampling pro-
duces large amounts of noise relative to the signal and can also push the system to the verge of
instability (see Chapter 6).
• Model validation: Right interpretation of model validation and model quality assessment is es-
sential to building a good model. The model diagnostic checks reveal considerable information
on the model suﬃciency and can contain clues to directions for model reﬁnement.
• Finally, there is no substitute for thinking, insight and intuition.
Clearly, identiﬁcation is both a science and an art since it is brought about by a careful blend of
knowledge (of both the subject and process), design (of the experiment), experience and intuition
(of the user).
The next section concludes this chapter with a description of the organization and ﬂow of learning
material in this text.

26
Principles of System Identiﬁcation: Theory and Practice
1.5
FLOW OF LEARNING MATERIAL
The subject of identiﬁcation is essentially a conﬂuence of the four broad subjects of theory of ran-
dom processes, estimation theory, signal processing and systems theory.
Figure 1.9 schematically illustrates this fact. A mastery of the subject of identiﬁcation invariably
demands a strong foundation in these respective areas. From a pedagogical perspective, a contextual
and a need-based learning is pragmatic. With this perspective, the ﬁrst three parts of this text is
devoted to an exposition of the requisite fundamentals in the founding areas.
Theory'of'
Random'
Processes
Signal'
Processing
System'
Identiﬁcation
Parts I, IV & V
Chapters
1, 2, 17-26
Estimation'
Theory
Estimation)
methods
Properties)of)
estimators
...
Disturbance)
modeling
Random)
Processes
...
Correlation)
&)Spectral))
Analysis
Signal)
Transforms...
Systems'&'
Sampling'
Theory
System)
Descriptions
LTI)Systems)
Theory
Sampling)...
Part III
Chapters
12 - 15
Parts II & III 
Chapters
8, 10, 11, 
16
Part II 
Chapters
7-9, 11
Part I 
Chapters
3-6
FIGURE 1.9
System Identiﬁcation involves application of concepts from four broad ﬁelds in engineering,
mathematics and statistics.
ORGANIZATION OF THIS BOOK
The book is divided into ﬁve parts. Part I provides the introductory material on identiﬁcation, math-
ematical models and the various descriptions of deterministic linear time-invariant systems. In Part
II, the focus is entirely on the theory of random processes, models for linear stationary processes and
spectral (frequency-domain) representations. Part III provides the crucial foundations on estimation
theory, methods for estimating statistical properties, techniques for (model) parameter estimation
and most importantly on metrics for assessing the quality of estimates. The subject matter of Part
IV is the culmination of the concepts and principles presented in the preceding parts, in the context
of identiﬁcation. Expectantly, it is the largest among all the parts and constitutes the core of this text.
The topics in Part IV can be fully understood with a good comprehension of the preceding portions.
Part V oﬀers glimpses of advanced concepts in identiﬁcation.
The content of each part is described below in greater detail.

Introduction
27
Part I
Chapter 1 introduced the basic principles of identiﬁcation and notions of modeling with an expo-
sition of a systematic procedure for identiﬁcation. Chapter 2 is a curtain raiser for the subject. It
takes the reader through the inner world of identiﬁcation by illustrating the procedure outlined in
Section 1.4 on a simple case study. The main aim of Chapter 2 is to allow the user to absorb the
tenets and ideas of identiﬁcation (of LTI systems) with a qualitative understanding of the theory. A
general introduction to mathematical descriptions and model classiﬁcation is the subject of Chapter
3. Through this chapter, the reader obtains an overview of the library of models that one can choose
from for a given process. Chapters 4 and 5 are exclusively devoted to the models of discrete-time LTI
systems, which are the primary representations of interest. In addition to providing a standard re-
view, the pros and cons of each of these descriptions from an identiﬁcation standpoint are discussed.
The connections between continuous-time and discretized systems under a sampling-and-hold op-
eration are presented in Chapter 6. The material therein also reviews basic sampling theory in the
context of signals and systems. A beginner should not be surprised to ﬁnd a recurring need to revisit
Chapters 4 and 6 during the course of reading this text.
Part II
In Section 1.3 we observed that the response of a system contains eﬀects of both deterministic and
stochastic quantities, thus the need for building a composite model. Chapter 7 introduces the reader
to the founding concepts of random processes. A brief review of the theory of random variables
and the founding concepts of stationarity and ergodicity constitutes the chapter. Predictability of
random processes is tested by means of correlation functions, which are treated in Chapter 8. The
chapter also introduces the building block for time-series modeling and analysis, the white-noise
process, which is an ideal unpredictable random process. Time-domain models for linear station-
ary processes, namely, the auto-regressive moving average (ARMA) representations and ARIMA
models are treated in Chapter 9. Theoretical correlation function properties of these models and
Yule-Walker equations are the focal topics. Chapter 10 presents a review of Fourier transforms
and the concepts of spectrum and spectral density, for deterministic signals. It oﬀers the requisite
foundations for the frequency-domain analysis and spectral representations of random processes
presented in Chapter 11, which provide a complementary (to that of time-domain) and an excellent
viewpoint of random processes. Frequency-domain equivalents of correlation functions, namely,
the cross-power spectrum and coherence are described in this chapter. Further, the milestone result
of spectral factorization theorem is reviewed. In each chapter, the concepts are illustrated through
suitable examples in MATLAB®.
Part III
Parts I and II provide the theoretical foundations. In Part III, the focus shifts to the ﬁeld of estima-
tion, which connects the world of theory to the ﬁeld of practice with a blend of optimization and
statistics. Therefore this part serves as the most appropriate transition from the previous parts to the
remainder portions of this text. The subject of estimation is a very exciting and challenging one. The
reader should spend considerable time in carefully understanding the subtle and practical aspects of
estimation in the constituent chapters. Chapter 12 presents an introduction to the ﬁeld of estimation
and brieﬂy discusses the three estimation problems, namely, prediction, ﬁltering and smoothing.
Any estimation problem is only half-complete with the computation of an estimate. The remainder,
an important one, constitutes the accuracy and precision analysis of the estimate (or the estimator).
Chapter 13 deals with the topic of the “goodness” of the estimators. Key properties such as bias,
variance and consistency are discussed in great detail with suitable examples. Expressions for these
properties throw light on how experiments should be conducted for obtaining eﬃcient (minimum
variance) estimates.

28
Principles of System Identiﬁcation: Theory and Practice
There exist an innumerable set of algorithms for parameter estimation. However, it suﬃces to
focus on four widely used classes of algorithms, namely, the method of moments, least squares
methods, maximum likelihood methods and Bayes estimation algorithms. Chapter 14 describes
the ﬁrst two classes while Chapter 15 presents the remaining two classes. Part III concludes with
Chapter 16, which is concerned with estimation of statistical properties (e.g., mean, correlation) and
spectral densities. The estimators of signal properties presented in this chapter are vital to estimation
of model parameters. As with previous parts, the concepts in each chapter are adequately illustrated
by way of examples in MATLAB.
Part IV
Part IV forms the nucleus of this text. It constitutes the application of concepts and methods in
the previous parts to the problem of identiﬁcation. To begin with, the reader is introduced to non-
parametric and parametric models for LTI systems in Chapter 17. The general class of parametric
descriptions, i.e., the prediction-error model structures form the central subject of discussion in
the chapter. A knowledge of prediction theory is vital to the practice of identiﬁcation. Chapter
18 enunciates the basics of prediction theory, where concepts of one-step and inﬁnite-step ahead
predictions are elucidated. Predictor-based model descriptions are also introduced in this chapter.
The central concept of identiﬁability and related notions such as equality of models are explained
in the concluding part of this chapter. Conditions for (model) identiﬁability of linear time-invariant
black box model structures are discussed. The notion of system identiﬁability and the requirements
to guarantee the same are also presented.
Chapter 20 treats the identiﬁcation of non-parametric models, namely, the (impulse, step and
frequency response models. Classical and modern methods for estimation of IR coeﬃcients are
included. Standard estimators of frequency response functions are discussed.
Chapter 21 is concerned with the identiﬁcation of parametric model structures that are described
in Chapter 17 using the PEM methods, correlation approaches and IV methods. Techniques for
estimating speciﬁc model structures (e.g., ARX, ARMAX, OE) are presented. Frequency-domain
interpretations of quadratic PEM methods are also discussed. This chapter constitutes an integral
part of the text.
Chapter 22 discusses the statistical and practical aspects of identiﬁcation, beginning with the
theory governing input design for identiﬁcation of LTI systems. The ideas of informative data and
persistent excitation are formally discussed. This is followed by a treatment of the input design in the
classical sense. Popularly used class of input signals, with special attention to pseudo-random binary
signals (PRBS), are discussed. Methods for handling outliers and missing data, namely, the robust
identiﬁcation and the EM algorithm are explained in detail with suitable examples. Subsequently,
the time-delay estimation problem is discussed in good detail where an eﬃcient frequency-domain
method based on Hilbert transform relation along with the classical correlation and model-based
methods are presented. In the second part of this chapter, model order determination and other
options such as pre-ﬁltering are reviewed. Finally, statistical tests for model quality assessment and
validation are described with MATLAB-based illustrations.
Identiﬁcation of state-space models is taken up in Chapter 23. A majority of this chapter is de-
voted to the subspace identiﬁcation, the ideas and algorithms therein. A basic understanding of
the Kalman ﬁlter is integral to comprehending subspace algorithms. A tutorial review of the same
is therefore included. The core of this chapter is the general class of subspace identiﬁcation al-
gorithms with specializations such as N4SID, MOESP and CVA. This topic is usually counted
among advanced topics in identiﬁcation due to the underlying mathematical complexities. In view
of this fact, the presentation begins with the simple deterministic case and gradually builds up to the
deterministic-plus-stochastic scenario. Parametrized state-space models and their identiﬁcation are
described subsequently. The chapter concludes with an outline of grey-box identiﬁcation, mainly by
way of illustrations on a few simulated processes.

Introduction
29
Finally, Chapter 24 presents a set of simulation and industrial case studies to illustrate the prac-
tical applications of the concepts learned in this text. These can also serve as motivating examples
in a classroom session.
Part V
The ﬁnal part consisting of Chapters 25 and 26 oﬀers glimpses of the advanced topics in identiﬁ-
cation. The objective is to provide an overview of these topics, highlight the main challenges and
discuss the principles of a few common methods. Therefore, the presentation is kept crisp and il-
lustrative. Chapter 25 contains a collection of topics related to linear time-varying, non-linear and
closed-loop identiﬁcation of single-input, single-output (SISO) systems. Illustrative examples are
presented for each of these classes. The book concludes in Chapter 26 with a cursory introduction
to multivariable identiﬁcation. A frequency-domain method for time-delay estimation in multivari-
able systems, as an extension of the technique described for SISO systems in Chapter 22, using
partial coherence is introduced. Finally, a method for multivariable identiﬁcation, when both inputs
are outputs are known with errors, using the well-known principal component analysis (PCA) is put
forth.
1.6
SOFTWARE
The primary software platform for the illustration of examples in this text is MATLAB® (Release
2014a), a powerful commercial computation, visualization and simulation software package de-
veloped by The MathWorks, Inc. The System Identiﬁcation Toolbox (Ljung, 2014), a companion
software exclusively designed for this subject, contains all the necessary tools for the analysis, simu-
lation and identiﬁcation of process systems from data. Simulations of continuous-time and complex
process systems are facilitated by MATLAB and its companion software SIMULINK. The best
way to learn MATLAB and SIMULINK is by going through some of the popular tutorials ﬁrst and
reproducing the results therein.
EXERCISES
E1.1. Deﬁne the term “System Identiﬁcation.”
E1.2. Explain the need for identiﬁcation in process automation.
E1.3. Identify two key diﬀerences between the ﬁrst-principles and empirical approaches to model de-
velopment.
E1.4. What are the diﬀerences between deterministic and stochastic eﬀects in a measured process
response?
E1.5. A liquid buﬀer system is a commonly encountered unit in industrial processes. It consists of a
vessel with an inﬂow Fin, an outﬂow Fout due to gravity and a liquid buﬀer maintained at a height
h. Assuming a cylindrical geometry for the vessel, answer the following:
a. Write a ﬁrst-principles model for the liquid level dynamics using the conservation of mass
principle. Assume incompressible ﬂow (constant density) and that the outﬂow ∝to the square
root of liquid level.
b. What kind of a model do you obtain in part (a)? (e.g., non-linear / linear)
c. Do you need any experimental data for developing your ﬁrst-principles model? If yes, what kind
of data do you require?
E1.6. Suppose you are completely unaware of the form of the ﬁrst-principles model and you intend to
empirically obtain the dynamic, discrete-time model (that relates the input-output observations) of
interest in E1.5.. What would be your approach? Describe in detail the following
a. How would you choose a suitable sampling interval?

30
Principles of System Identiﬁcation: Theory and Practice
b. What input would you consider appropriate?
c. What would be a suitable model to begin with? Would a linear dynamic model be a good
starting point?
d. Can you list some ideas of how to estimate the model that you postulate?
e. How do you propose to handle the measurement errors (assume no unmeasured disturbances
are present)?
f. List the major challenges (if any) in this exercise.
E1.7. Give two examples of quantitative and qualitative models for a (i) mechanical system, (ii) elec-
trical system, (iii) aerospace system and (iv) a chemical engineering system.
E1.8. Describe three uses of model in the context of diﬀerent applications.
E1.9. Give two examples of identiﬁcation problems in any ﬁeld (engineering, medicine, humanities,
etc.) of your choice.
E1.10. Explain the salient steps in identiﬁcation.
E1.11. What role does model validation play in the development of a good model?

2
A Journey into Identiﬁcation
An overview of identiﬁcation is provided by means of examples and a simulation case study.
The objective is to take the reader through an illustrative tour of identiﬁcation while giving
glimpses of the technical aspects. The main topics of interest are identiﬁability, quality of
parameter estimates and model development.
In Chapter 1, we learned that the measured response usually consists of both the eﬀects of the
input as well as that of the unmeasured disturbances and/or measurement errors, known as the
deterministic and stochastic eﬀects, respectively (recall Figure 1.6). Further, from §1.3.1, recall
that the ability to identify a model (of a speciﬁed structure) uniquely and precisely depends on
two factors: (i) the input characteristics and (ii) the relative proportions of the deterministic and
stochastic eﬀects in the measurement, quantiﬁed by the signal-to-noise ratio (SNR). In a broader
sense, the uniqueness of identiﬁed models and is not only connected to the input design but also
with the estimation algorithm and the model structure itself. Collectively, these factors are formally
analyzed using the concept of identiﬁability.
In the following section, we oﬀer brief glimpses of the aforementioned technical concepts, es-
pecially the roles of model and input in identiﬁcation, primarily through illustrations on simple
examples1. In addition, the phenomenon of overﬁtting, a technical term for “excessive” mathemat-
ical modeling, is also elucidated through the example of a polynomial ﬁt. The centerpiece of this
chapter is a complete case study on the identiﬁcation of a liquid level system using the systematic
procedure presented in §1.4.
2.1
IDENTIFIABILITY
As remarked earlier, the ability to identify a unique model for a given system depends on three
critical aspects:
1. Model: This is solely a property of the model and is concerned with whether there exists a unique
(one-to-one) mapping between the model and the parameters being estimated2.
2. Experimental conditions: Speciﬁcally we refer to the type of input and sampling rate, among
which the ﬁrst factor is the most inﬂuential and is a signiﬁcant design factor. The question is then
whether the input has generated the requisite information required to distinguish between two
candidate models.
3. Estimation method: A number of methods are available for parameter estimation as discussed
in §1.4.4. The question is whether the estimation method is capable of estimating the “true”
parameters if inﬁnite samples are available, which is termed as an asymptotic property of the
estimator. The technical term is consistency.
Furthermore, it is necessary to know whether the estimated model, in principle, converges to the
“true” system. This aspect depends on the true system description itself. The three factors above
1Formal discussions on identiﬁability appear in §18.6 and §22.3.
2An additional concern that remains is if the model is complex enough to explain the underlying system, but we shall
defer a discussion on this issue until Chapter 21.
31

32
Principles of System Identiﬁcation: Theory and Practice
and the system’s characteristics together determine the ability to discover the true system from
observations, which is formally termed as system identiﬁability.
Model identiﬁability (or sometimes parameter identiﬁability) is the term that is used to formally
describe the ability to obtain a unique model. In analyzing model identiﬁability, the analysis is
carried out at a theoretical level, where the characteristics of the input and estimation algorithms are
assumed to be ideal. Thus, we are primarily concerned with the model itself.
The role of input in system identiﬁability is studied through the concept of informative experi-
ments. Example 2.2 below is aimed at illustrating the underlying ideas. The third property, which is
solely known as consistency, will be taken up for illustration at a later stage, in Chapters 12 and 13.
System identiﬁability is formally studied
For simplicity we shall consider only deterministic systems. The ﬁrst example below illustrates
the notion of model identiﬁability, speciﬁcally for so-called parametrized models.
Example 2.1: Model or Parameter Identiﬁability
Consider ﬁtting the model y[k,θ] = θ1θ2u[k] to a given data, where u[k] and y[k] are the
input and output of a system, while θ =
f
θ1
θ2
gT is the parameter vector to be identiﬁed.
The prediction (denoted by a hat) of this model to a given input is
ˆy[k,θ] = θ1θ2u[k]
(2.1)
Regardless of the input, two diﬀerent parameter values θ1 and θ2 produce identical predic-
tions. Stated mathematically,
ˆy[k,θ1] = ˆy[k,θ2]
̸=⇒θ1 = θ2
(2.2)
Therefore, the mapping from the parameter space to the model (predictor) space is not one-
to-one. Formally, the model is said to be not (globally) identiﬁable. Consequently, it is not
possible to arrive at a unique estimate of θ.
On the other hand, if the model is re-parametrized in terms of a single parameter β = θ1θ2,
then the model is identiﬁable at all points in the β space.
The above example suggests that re-parametrization of a model, in this case from a higher-
dimensional to a lower-dimensional parameter space, can improve identiﬁability for that model.
Further, a model can be rendered locally identiﬁable by adding suitable constraints on the param-
eters (see Exercise E2.2.). A formal treatment of these concepts, particularly for linear dynamical
systems, is presented in §18.6. It must be also mentioned that, on several occasions, models may not
be in the parametrized forms, known as non-parametric models; the concept of identiﬁability even
applies to such models.
We now turn our attention to the second aspect of identiﬁability, which is concerned with re-
covery of the true system from the data and is largely governed by how the experiment has been
performed.
The basic principle in identiﬁcation is that good models can only be obtained from “good” data.
If the data is generated by a poor excitation, then there is very little scope for building a good model
simply because the data lacks information (recall the analogy of an interview process).
The model realized by the user heavily depends on the experimental conditions that prevailed
at the data acquisition stage. The process may not have been excited over the entire input-output
range. As a result, the model does not “see” all aspects of the relationship. In the case of high-order
linear systems, the input may have only excited the lower-order dynamics or for non-linear systems
it is that the input has excited only a subset of non-linearities.
The following example illustrates how an improper choice of input can lead to loss of identiﬁa-
bility. Once again, the illustration is in a deterministic setting.

A Journey into Identiﬁcation
33
Example 2.2: Role of Input in Identiﬁability
Consider a linear time-invariant (LTI) system governed by the following input-output rela-
tionship (3rd-order ﬁnite impulse response system):
y[k] = b1u[k −1] + b2u[k −2] + b3u[k −3]
(2.3)
with b1 = 1, b2 = 0.6 and b3 = 0.3. Suppose a sinusoidal input of the form u[k] = sin(2π(0.1)k) =
sin(ω0k) is applied to the system.
Under the input, the output in (2.3) is
y[k] = b1 sin(ω0k −φ) + b2 sin(ω0k −2φ) + b3 sin(ω0 −3φ)
which can be re-written as
y[k] =
 
b1 +
b2
2 cos φ
!
sin(ω0k −φ) +
 
b3 +
b2
2 cos φ
!
sin(ω0k −3φ)
= b′
1 sin(ω0k −φ) + b′
3 sin(ω0k −3φ)
(2.4)
Thus, a 3-parameter model manifests as a 2-parameter model when viewed through the lens
of a mono-frequency input. Unfortunately, it is not possible to uniquely recover b1,b2 and b3
from b′
1 and b′
3.
Observe that one can re-write (2.4) in terms of the pair (sin(ω0k −φ),sin(ω0k −2φ)) or
(sin(ω0k −2φ),sin(ω0k −3φ))3.
Regardless of the way (2.4) is written, with a sinusoid of single frequency, only two of the
three explanatory variables u[k −1], u[k −2] and u[k −3] are unique. Consequently, only two
of the three parameters b1, b2 and b3, can be uniquely estimated.
The situation encountered in the above example is formally termed as loss of identiﬁability due
to insuﬃcient information, which here is due to lack of suﬃcient input excitation. From a statisti-
cal viewpoint, the data does not have suﬃcient information or evidence to discriminate between a
second-order and higher-order ﬁnite impulse response models.
The observations above oﬀer a preview of an important fact in identiﬁcation that we shall learn
in §22.3 - identiﬁability is guaranteed (at least for linear time-invariant systems) when the input
is persistently exciting, which roughly translates to an input containing sinusoids of almost all fre-
quencies. These concepts are foundational to input design (see §22.3).
Observe that in Example 2.2 the input generates enough information in the data to estimate a
two-parameter model. Further, it may be veriﬁed that if the input contains additional frequency
components, for e.g., u[k] = sin(ω0k) +sin(ω1k), then it is possible to estimate all three parameters
uniquely (see Exercise E2.5.).
Identiﬁability can also be at loss due to improper choice of sampling rates. At the scale of obser-
vation, only those time constants can be identiﬁed that are commensurate with the sampling interval
Ts. For instance, it is not possible to detect modes of the process (or even delays) that have set-
tling times less than Ts. Collectively, poor input design and sampling rate lead to lack of suﬃcient
information.
The following section addresses the role of SNR in the precision of model estimates, i.e., it is
not suﬃcient to have good excitation in the input but it is also important to have a signiﬁcant input
strength relative to noise for obtaining reliable models.
3Equation (2.4) is due to the trigonometric relationship sin(ω0k −2φ) =
1
2 cos ω0 (sin(ω0k −φ) + sin(ω0k −3φ)).

34
Principles of System Identiﬁcation: Theory and Practice
2.2
SIGNAL-TO-NOISE RATIO
Even with good excitation, the stochastic eﬀects in the measurements can be high enough to be
detrimental to model quality. For example, choosing sampling rates much faster than the pace at
which outputs change can bring in more noise than actual process variation.
The relative contributions of deterministic excitation and random variations are quantiﬁed by a
measure known as the signal-to-noise ratio (SNR) .
SNR = Variance of signal
Variance of noise
(2.5)
The term signal here refers to the true response of the system. Having a good SNR is critical to
obtaining reliable parameter estimates, regardless of the estimation method. This is qualitatively
understood as follows. Fitting a model intuitively amounts to explaining variations in the output. If
a signiﬁcant portion of the variations in the measurement is due to noise, then the contribution of the
input weakens and hence the ability to precisely estimate the model as well. An alternative viewpoint
is that the SNR represents the ratio of eﬀects due to known variable versus the uncertainties. Thus,
the lower the SNR, the more ambiguous is the estimate of the input-output model.
The following example aids in understanding the above concepts.
Example 2.3: Effect of SNR on Parameter Estimation
The relationship between the output y[k] and the input u[k] of a system is known to be
y[k] = b1u[k] + b0
with b1 = 5 and b0 = 2. Relationships such as the one above are common in linear calibration
sensors, proportional controllers and so on. Assume that the input and the measured output
ym[k] = y[k] + v[k] is available, where the measurement error v[k] is assumed to be random.
0
0.2
0.4
0.6
0.8
1
1
2
3
4
5
6
7
8
Input
Output
Output vs. Input (SNR = 100)
 
 
 
y = 5.009*x + 1.989
Data
Best Fit
(a) σ ˆb1 = 0.036, σ ˆb0 = 0.02
0
0.2
0.4
0.6
0.8
1
1
2
3
4
5
6
7
8
Input
Output
Output vs. Input (SNR = 10)
 
 
 
y = 5.027*x + 1.965
Data
Best Fit
(b) σ ˆb1 = 0.114, σ ˆb0 = 0.064
FIGURE 2.1
The best ﬁt and the error in the parameter estimates depend on the SNR.
The best linear ﬁt and the parameter estimates for two diﬀerent settings of SNR =
σ2
y
σ2v , namely
(i) SNR = 100 and (ii) SNR = 10 obtained from N = 200 samples of (ym[k],u[k]) data are
shown in Figures 2.1(a) and 2.1(b), respectively. The quantities ˆbi and σ ˆbi are the estimates
and standard errors in the estimates of bi, i = 0,1, respectively. While the estimates do not
vary signiﬁcantly with the change in SNR, the errors in ˆbi, i.e., σ ˆbi in the estimates increase
roughly by a factor of three. The increase in fact, is theoretically given by
q
100
10 = 3.162. The
lower the SNR, the lower the reliability (conﬁdence) of the resulting parameter estimate.
□

A Journey into Identiﬁcation
35
Listing 2.1
MATLAB code for Example 2.3
% Create input-output data
uk = rand(200,1); yk = 5*uk + 2;
% Add noise to get the measurement
ek = randn(200,1);
ykm1 = yk + ek*sqrt(var(yk)/100);
% SNR 100
ykm2 = yk + ek*sqrt(var(yk)/10);
% SNR 10
% Plot data and use curve fitting to obtain the best fits
figure; plot(uk,ykm1,’x’,’linewidth’,1);
figure; plot(uk,ykm2,’x’,’linewidth’,1);
% Compute LS estimates and their standard errors
Phi = [uk ones(200,1)]
thetah1 = Phi \ ykm1;
err1 = ykm1 - Phi*thetah1;
errth1 = sqrt(diag(inv(Phi’*Phi)*sum(err1.^2)/198));
thetah2 = Phi \ ykm2;
err2 = ykm2 - Phi*thetah2;
errth2 = sqrt(diag(inv(Phi’*Phi)*sum(err2.^2)/198));
In practice, the SNR is not known a priori. However, in several applications, the noise variance
can be estimated from steady-state data and the input amplitude can be adjusted to achieve a desired
SNR in an identiﬁcation experiment.
The signal-to-noise ratio has a signiﬁcant role to play in all estimation exercises. For instance, in
signal estimation, it quantiﬁes the separability of the signal and noise components of a measurement.
2.3
OVERFITTING
Overﬁtting occurs when the model is trained to capture the “local” features of the data rather than the
“global” characteristics. In identiﬁcation, this situation arises when one misconstrues the stochastic
eﬀects in the data as a part of the deterministic (input-output) eﬀects, i.e., when the chance varia-
tions in the response are attributed to the changes in the input variables. This situation occurs when
the user “over-speciﬁes” the complexity of the deterministic portion in a bid to explain the output
as accurately as possible. The extreme case is when the entire variability in the output is attributed
solely to the variations in the input. An obvious beneﬁt from increasing the complexity of the de-
terministic model is the improved ﬁt on the training data, i.e., lower prediction error. However, the
reduction in the bias (of the prediction) comes with the risk of high standard errors (variance) in the
model (parameter) estimates. Further, with such models we are led to poor predictions on a fresh
data set, on some occasions even unstable (unbounded) ones.
The following example illustrates the risks associated with overﬁtting on a simple static system.
Section 2.4 demonstrates this phenomenon on a dynamic system.
Example 2.4: Overﬁtting
The input-output data of a system is shown in Figure 2.2(a). A visual inspection reveals
that a polynomial ﬁt can capture the relationship reasonably well. In order to choose the
appropriate order of the polynomial, the sum squared error of residual is drafted against the
order of the polynomial, shown in Figure 2.2(b). A good choice of the order is three, since
the improvement in the residual norm at higher orders is minuscule.
It would be useful to know if the third order is indeed the optimal choice. This cannot

36
Principles of System Identiﬁcation: Theory and Practice
0
0.5
1
1.5
2
2.5
3
3.5
4
0
5
10
15
20
25
Input
Output
(a) Input-output data of Example 2.4
1
2
3
4
5
6
7
0
5
10
15
20
25
30
Order
Residual norm
(b) Norm of residuals vs. order of polynomial ﬁt
FIGURE 2.2
Training data and order determination in Example 2.4.
be determined using the training data alone; a test data set is also required to assess its
predictive abilities (the procedure of cross-validation). Polynomials of order three to ﬁve are
ﬁt and tested on a fresh data set. Figure 2.3 shows the predictions of the respective models.
It is clear that the third-order polynomial model oﬀers the best compromise between the
predictions on the training and test data. The ﬁtted polynomial (predictor) is
ˆy[k] = 1.183
(±0.03) + 0.384
(±0.07)u[k] + 0.314
(±0.04)u2[k] + 0.198
(±0.007)u3[k]
where the values in brackets are the standard errors in the coeﬃcient estimates (§14.3.3
derives the necessary expressions).
4
4.5
5
5.5
6
6.5
7
7.5
8
20
40
60
80
100
120
140
160
Input
Output
Comparison of predictions on test data
 
 
Actual
3rd order
4th order
5th order
FIGURE 2.3
Cross-validation of polynomial models in Example 2.4.
It is useful to compare the estimated model with the true model used for data generation
y[k] = 1.2 + 0.4u[k] + 0.3u2[k] + 0.2u3[k] + v[k]
where v[k] is an ideal random noise (unpredictable stochastic signal) such that the SNR is
set to 10. The chosen order and the coeﬃcient estimates agree very well with the true ones.
Note that we have discovered the true model without any prior knowledge.
The fourth and ﬁfth order models negligibly lower residual norms on the training data
and therefore fail miserably on the test data. In fact the ﬁfth-order model produces unstable

A Journey into Identiﬁcation
37
predictions4. The reason for the poor performance of the higher-order models is that they
have attempted to explain the chance variations using the input. All empirical modeling
exercises potentially run into this risk, but as the example shows, it can be avoided by a
careful cross-validation.
The instability of predictions is one of the perils in overﬁtting, which can be avoided by
examining the errors in parameter estimates of these models in conjunction with plot in
Figure 2.2(b); the errors in parameters of 4th order ﬁt are quite high as shown below,
ˆy[k] = 1.23
(±0.04) + 0.14
(±0.13)u[k] + 0.14
(±0.6)u2[k] + 0.085
(±0.054)u3[k] + 0.015
(±0.007)u4[k]
re-aﬃrming that this model is not suited to the given data.
It must be noted that the parameter estimates and the error values change with each run
of the data (due to the use of a diﬀerent noise realization) - but the message remains the
same.
An important remark is in order here. Over-parametrization has to be viewed not with reference
to the “true” model, but with respect to the model that can be identiﬁable. There are two reasons for
this. Firstly, the process is usually much more complicated than the model that is being ﬁt. Therefore
a comparison of the model with the process has little meaning. Secondly, as we have seen in Section
2.1, the number of parameters and the order of the model that can be estimated is largely governed
by the input excitation.
Listing 2.2
MATLAB code for Example 2.4
% Generate training data
xvec = (0:0.02:4)’;
yvec = 1.2 + 0.4*xvec + 0.3*xvec.^2 + 0.2*xvec.^3;
% Add measurement noise
ymeas = yvec + 0.4*randn(length(yvec),1);
for i = 1:7,
eval([’[pvechat’ num2str(i) ’,S’ num2str(i) ’]=␣polyfit(xvec,ymeas ,1);’]);
end
% Calculation of standard error in estimates
Rinv3 = inv(S3.R);
covmat3 = (Rinv3*Rinv3 ’)*S3.normr/S3.df;
errvec3 = sqrt(diag(covmat3));
Rinv4 = inv(S4.R);
covmat4 = (Rinv4*Rinv4 ’)*S4.normr/S4.df;
errvec4 = sqrt(diag(covmat4))’;
% Test data for model validation
xtest = (4:0.02:8)’;
ytest = 1.2 + 0.4*xtest + 0.3*xtest.^2 + 0.2*xtest.^3;
ytmeas = ytest + 0.4*randn(length(ytest),1);
% Predictions of the model on test data
[yhat3,delta3] = polyval(pvechat3 ,xtest,S3);
[yhat4,delta4] = polyval(pvechat4 ,xtest,S4);
[yhat5,delta5] = polyval(pvechat5 ,xtest,S5);
% Plot training data
figure; plot(xvec,ymeas)
4Not all higher-order models necessarily produce unstable predictions, but this example points to one such possibility.

38
Principles of System Identiﬁcation: Theory and Practice
% Plot the residual norm vs. order
errnorm = [S1.normr S2.normr S3.normr S4.normr S5.normr S6.normr S7.normr]’;
figure; plot((1:7),errnorm ,’-o’,’Markerface’,’blue’)
% Plot test results
figure; plot(xtest ,[ytmeas yhat3 yhat4 yhat5])
legend({’Actual’ ; ’3^{rd}␣order’ ; ’4^{th}␣order’ ; ’5^{th}␣order’})
To summarize, overﬁtting arises when the proposed model contains parameters in excess of what
are identiﬁable. The appropriate level of model complexity is determined by ensuring an acceptable
trade-oﬀbetween predictions on the training and test data.
A systematic model estimation exercise can greatly aid in preventing the model from running into
the risks of overﬁtting. While there exist no strict rules that can completely prevent this phenomenon,
identiﬁcation theory oﬀers useful guidelines based on an approximate analysis. The method adopted
for determining the optimal order in the previous example, although heuristic, is representative of the
rigorous information-theoretic approaches that are widely used for order selection (Section 22.6.3).
The polynomial ﬁts and the errors in estimates have been computed using the LS method and the
associated expressions provided in §14.3.
Next, we turn to the focal example of this chapter. An empirical model of a simple dynamic ﬁrst-
order buﬀer process is developed. It is shown how one can systematically build input-output and
state-space models from data with as little knowledge of the process as possible. The main objective
is to provide the precursory experience of the options and challenges in a typical identiﬁcation
problem.
2.4
A MODELING EXAMPLE: LIQUID LEVEL SYSTEM
2.4.1
THE PHYSICAL PROCESS
The process of interest is a buﬀer system as shown in Figure 2.4 consisting of a cylindrical tank,
with inlet and outlet ﬂow rates of Fi m3/hr and Fo m3/hr, respectively.
Fi
Fo
h
FIGURE 2.4
Schematic of the liquid level system discussed in Section 2.4.
The objective is to build a model that explains changes in level h(t) with respect to changes in
inlet ﬂow rate Fi(t). The end-use of this model could be in simulation, control and/or monitoring of
the liquid level system.
2.4.2
DATA GENERATION
In a realistic situation, one would perform real-time experiments on the liquid level process with a
custom-designed input. The input design would be usually preceded by a preliminary experiment
to obtain essential process characteristics for determining the appropriate sampling rate and the
frequency content of the input. Keeping in view the main objective of the example, the experiment is

A Journey into Identiﬁcation
39
replaced by the simulation of a ﬁrst-principles model with an appropriate input design and sampling
interval in place.
Model for simulation
The deterministic ﬁrst-principles model of the liquid level system (based on conservation of mass)
is
dh(t)
dt
+ 1
Ac
Cv
p
h(t)
=
1
Ac
Fi(t)
(2.6)
with the usual assumptions of (i) incompressible ﬂuid and (ii) the outlet ﬂow rate being proportional
to the square root of the pressure head (valve equation)
Fo(t) = Cv
p
h(t)
(2.7)
where Cv is the valve coeﬃcient at the outlet. The quantity Ac in (2.6) is the cross-sectional area
of the cylindrical tank. The system is brought to a steady state before exciting it with the designed
input. With the operating conditions set to Fi(t) = 4.5 cu. ft. / min., Cv = 1.5 and Ac = 0.5 ft2, the
nominal level is 9 ft.
Input used for data generation
The input used for simulation is a discrete-time pseudo-random binary signal (PRBS), which con-
sists of short- and long-duration pulses switching between two levels around the nominal operating
value. The PRBS input has certain advantages over other inputs as we shall learn later (in §22.3).
Figure 2.5(a) (bottom panel) shows the input proﬁle. The long duration pulses (low frequency) se-
cure the gain information while the not-so-long ones are useful in capturing the dynamics of the
process.
0
50
100
150
200
250
300
350
400
8
8.5
9
9.5
10
Snapshot of input−output profile
Level
0
50
100
150
200
250
300
350
400
4.2
4.4
4.6
4.8
5
Samples
Flow
(a) Snapshot of the ﬂow rate and level data for
the liquid level system example
0
0.5
1
1.5
2
2.5
3
3.5
0
0.1
0.2
0.3
0.4
Output and input spectra
Power
0
0.5
1
1.5
2
2.5
3
3.5
0
0.005
0.01
0.015
0.02
Frequency (rad/sample)
Power
(b) Power spectra of the input and output signals
FIGURE 2.5
Time-trends and spectra of ﬂow and level measurements in the identiﬁcation of the liquid level
system.
The response of the sampled-data (ZOH-process-sampler) system is obtained by numerically
integrating the non-linear ODE in (2.6) from time t = 0 to t = 2045 and observing at Ts = 1 min.
sampling intervals (in the MATLAB / SIMULINK environment). To render the simulation realistic,
a measurement error in the form of an ideal random (unpredictable) noise sequence is added to the
true response such that the output SNR is set to a value of 10. A snapshot of the liquid level response
is shown in the top panel of Figure 2.5(a).

40
Principles of System Identiﬁcation: Theory and Practice
% Perform experiment , collect input-output data
sim(’liqlevel_exch01.mdl’);
dataset = iddata(yk,uk,1);
dataset.OutputName = ’Level’; dataset.InputName = ’Flow’;
dataset.TimeUnit = ’minutes’;
The rest of the section exempliﬁes the development of a linear, time-invariant discrete-time nu-
merical model that can explain the dynamics of the sampled output (level measurement) to changes
in discrete-time input (ﬂow) following the steps outlined in Section 1.4 and Figure 1.7.
2.4.3
DATA VISUALIZATION AND PRELIMINARY ANALYSIS
As a ﬁrst step, the input-output data is visually examined for the presence of any drifts, outliers,
etc. Figure 2.5(a) shows the absence of any polynomial trends and other anomalies of concern
(such as outliers, missing data). Some minimal pre-processing is still necessary, however, to fulﬁll
the assumption of linearity, which holds only for deviations of variables around a nominal operating
point (typically steady-state) and not absolute values themselves (essentially zero intercept models).
Steady-state can be determined experimentally before introducing changes to the input. When
such experiments have not been performed (we shall assume this to be the case here), an alternative
is to use the average of the readings as a nominal operating point. Consequently, a simple mean-
centering operation of the input-output data is used to generate the required deviation variables.
Therefore, for the rest of the analysis we shall work with
y[k] = ˜y[k] −¯y; u[k] = ˜u[k] −¯u
where the variables with ˜. are absolute-valued and the quantities under the bar are simple averages
of the respective variables.
figure
subplot(211)
plot(dataset.y(1:400),’linewidth’,1.5);
subplot(212)
stairs(dataset.u(1:400),’linewidth’,1.5);
figure
subplot(211)
[Pyy,wvec] = periodogram(yk - mean(yk),[],length(yk),’twosided’);
plot(wvec(2:end/2),Pyy(2:end/2),’linewidth’,2);
subplot(212)
[Puu,wvec] = periodogram(uk - mean(uk),[],length(uk),’twosided’);
plot(wvec(2:end/2),Puu(2:end/2),’linewidth’,2);
Spectral analysis
It is useful to examine the frequency content of the output signal so as to obtain insights into the
ﬁltering nature of the process. A spectral plot consisting of a plot of power vs. frequency (on the x-
axis) is widely used for this purpose. High power in a frequency band implies the strong presence of
those frequency components. Figure 2.5(b) shows the spectra of the input and output signals where
the power on the vertical axis is a measure of its strength. Most of the input power has been packed
in the low- to mid-frequency band. This is in fact a part of the input design strategy because liquid
level systems are low-pass ﬁlters, meaning that any high frequency ﬂuctuations in the input will
yield poor response. The output spectrum shown in the top panel of Figure 2.5(b) bears testimony
to this fact. All input components with frequencies greater than approximately 0.7 rad/sample have
been signiﬁcantly attenuated by the system.

A Journey into Identiﬁcation
41
Partitioning the data
For modeling purposes, the data is partitioned into two sets: one partition consisting of the ﬁrst
N = 1500 samples for training the model, while the second set consisting of the remainder of
the data, used in cross-validation of the model. Both data sets are expressed in terms of deviation
variables with the nominal operating point determined from the training data.
% Partition data into training and test data
% Use means of training data as the reference point
datatrain = dataset(1:1500); datatest = dataset(1501:end);
[Ztrain,Tr] = detrend(datatrain ,0);
Ztest = detrend(datatest ,Tr);
Following the systematic procedure outlined in Figure 1.7, we begin the model development with
the estimation of elementary response or non-parametric models (e.g., impulse and step responses).
2.4.4
BUILDING NON-PARAMETRIC MODELS
Non-parametric models provide insights into several important (deterministic) process characteris-
tics with minimal assumptions:
i. Time-delay: The impulse response (cross-correlation) method is the classical approach for delay
estimation and we shall follow it here. At a later stage in the text, (in §22.5) we shall learn the
use of frequency-domain methods to obtain eﬃcient estimates of time-delay.
ii. Gain: It is the ﬁnal change in the output to a unit change in the input. Step response coeﬃcients
are ideally suited for estimating gain.
iii. Time-constant: When the process is approximated to have ﬁrst-order dynamics, the time constant
is roughly the time taken for the response to reach 63% of the ﬁnal value to a step change in the
input. Once again the step response is naturally suited for estimating this parameter.
The step response coeﬃcients can also be used to detect what is known as an integrating eﬀect,
a term used to characterize unusually very long settling times (very large time constants). This
situation does not apply to the present case study. One can also infer the disturbance characteristics
using non-parametric methods, but that is reserved for a later discussion.
Impulse Response estimates
The IR estimates are obtained by ﬁtting a ﬁnite-length impulse response (FIR) model:
y[k] ≈
M
X
l=0
g[l]u[k −l]
(2.8)
to the data using the least squares method. The coeﬃcients {g[.]} form the (M + 1) long impulse
response sequence that is of interest. When the system has a delay of D samples, then the ﬁrst D IR
coeﬃcients are identically zero. The corresponding estimated coeﬃcients will be however “small”
non-zero values. In practice, a test of signiﬁcance is performed wherein the estimated coeﬃcients
lower than a statistically determined threshold are termed as insigniﬁcant.
% Estimate impulse response and plot it
irestoptions = impulseestOptions;
irestoptions.Advanced.AROrder = 0;
firmod_liql = impulseest(Ztrain ,irestoptions);

42
Principles of System Identiﬁcation: Theory and Practice
FIGURE 2.6
Impulse response estimates of the liquid level system.
[ircoeff ,kvec,~,ir_sd] = impulse(firmod_liql ,30);
stem(kvec,ircoeff ,’Markerfacecolor’,’blue’);
ir_3sd = 2.58*ir_sd;
fillxvec = [kvec(1) kvec(1) kvec(2:end)’ kvec(end:-1:2)’]’;
fillyvec = [-ir_3sd(1) ir_3sd(1) ir_3sd(2:end)’ -ir_3sd(end:-1:2)’]’;
hold
fill(fillxvec ,fillyvec ,[0.5 0.58 1],’FaceAlpha’,0.4,’Linestyle’,’none’);
Impulse response estimates obtained from the training data are shown in Figure 2.6. Any estimate
falling within the shaded region is treated as statistically insigniﬁcant. The discrete-time liquid level
system thus has a unit sample delay (delays in discrete-time systems are expressed in terms of
samples). Physically there is no delay between ﬂow and level, i.e., the continuous-time system has
zero delay. However, the unit delay in the sampled-data system is due to the presence of zero-order
hold. This is explained later in Chapter 6.
The decaying nature of the IR estimates is a clear indication that the sampled-data system is
stable, which agrees very well with our physical knowledge of the process.
Step response model
Estimates of unit step response coeﬃcients are obtained from the IR coeﬃcients using a simple
relationship
ys[k] =
k
X
n=0
g[n]
(2.9)
The resulting estimates are shown in Figure 2.7, which is strongly suggestive of a ﬁrst-order (or
an overdamped higher-order) dynamics with a gain of approximately 3.7 units. If the system is
approximated as a ﬁrst-order process, the time-constant is about 7 samples (minutes). The fact that
the step response steadies out is an indicator of the absence of any instabilities and non-stationarities
in the process.
% Estimate step response and plot it
[srcoeff ,kvec,~,sr_sd] = step(firmod_liql ,40);
figure; stairs(kvec,srcoeff);

A Journey into Identiﬁcation
43
0
5
10
15
20
25
30
35
40
0
0.5
1
1.5
2
2.5
3
3.5
4
Time (Sampled)
Amplitude
Step response estimates
FIGURE 2.7
Step response estimates of the liquid level system.
A third elementary response that is also of interest is the frequency response function, which
shall be taken up for estimation at a later point in the text (in Chapter 20).
Identiﬁcation of response models is aﬄicted by the estimation of a large number of unknowns,
which is not preferred in any estimation exercise. Parametrizing, these responses, meaning ﬁtting
mathematical expressions to the curves, aids in considerably reducing the size of the unknowns
because one estimates the “parameters” instead of the response coeﬃcients. An important point
is that parametrization of response models leads to diﬀerence equation form of descriptions. The
following section demonstrates the development of a parametric model for the liquid level system.
2.4.5
BUILDING PARAMETRIC MODELS
The objective is to identify a diﬀerence equation (DE) model for the deterministic process from the
given data. The key information that is to be provided by the user is a suitable “guess” of the delay
and order of the DE form.
From the previous section, it is meaningful to premise a ﬁrst-order diﬀerence equation with a
delay of 1 unit sample for the deterministic process.
x[k] + a1x[k −1] = b1u[k −1]
(2.10)
where x[k] denotes the unobserved true discrete-time (deterministic) response of the process.
The parameters θ =
f
a1
b1
gT are estimated such that the sum squared one-step ahead predic-
tion errors is minimized,
min
θ
N−1
X
k=0
(x[k] −ˆx[k|k −1])2
(2.11)
where
ˆx[k|k −1] = −a1x[k −1] + b1u[k −1]
(2.12)
is the “prediction of x[k] given the knowledge of x[.] and u[.] until the (k −1)th instant.”
However, this is only possible when the true response is known. In reality, only a measurement
of x[k] is available. Therefore, it is natural re-write the minimization in (2.11) in terms of the

44
Principles of System Identiﬁcation: Theory and Practice
measurement prediction error:
min
θ
N−1
X
k=0
(y[k] −ˆy[k|k −1])2
(2.13)
where now ˆy[k|k −1] is the “prediction of the measurement y[k] given the knowledge of measure-
ments and inputs until the (k −1)th instant. For the rest of the presentation, ˆy[k] is used to denote
ˆy[k|k −1].
Clearly, an expression for the predictor ˆy[k] is required. Since we are dealing with measurements
here, it is intuitive that models for both deterministic and stochastic eﬀects are required.
To construct the overall model for y[k], we ﬁrst assume that stochastic eﬀects, collectively de-
noted by v[k], are additive
y[k] = x[k] + v[k]
(2.14)
Naturally, the (one-step ahead) prediction of the measurement is
ˆy[k] = ˆx[k] + ˆv[k]
(2.15)
where ˆv[k] is the (one-step ahead) prediction of the disturbances and noise.
The deterministic signal x[k] is modeled by the diﬀerence equation (2.10). A model for v[k]
is required to complete the picture. Diﬀerent models exist depending on the assumptions made on
the predictability of v[k], leading to diﬀerent descriptions for y[k]. Two common models, namely,
the output-error and the equation-error models are explored in this case study. We shall see that
these methods make somewhat contrasting assumptions about v[k] and that they can signiﬁcantly
inﬂuence the choice of the ﬁnal input-output model.
Output-error model
A simple assumption is that the error in the measurement is absolutely unpredictable given any
amount of past. For zero-mean noise this means,
ˆv[k] = 0
(2.16)
Such a stochastic signal is termed as the white-noise signal, denoted by e[k] hereafter. Plugging
(2.16) into (2.15), we have
ˆy[k] = ˆx[k] = −a1x[k −1] + b1u[k −1]
(2.17)
The unknowns on the RHS of the equation are a1, b1 and x[k −1]. It is clear that the predictor in
(2.17) is non-linear in unknowns. Since the white-noise error directly enters the output, the model
producing the predictor above is termed as the output-error model.
Applying the non-linear least squares method to solve (2.13) using the predictor in (2.17) on the
training data produces,
ˆa1 = −0.8826(±0.002), ˆb1 = 0.4621(±0.006)
(Output-Error Model)
(2.18)
where the hat on the parameters ˆ[.] denotes the respective estimates and the values in the bracket
are the standard errors in those estimates.
% Estimate output-error model of specified order and delay
mod_oe = oe(Ztrain ,[1 1 1]);
present(mod_oe)
The goodness of this model will be assessed shortly. Now, we explore an alternative model struc-
ture that arises out of relaxing the unpredictable assumption on the stochastic component v[k].

A Journey into Identiﬁcation
45
Equation-error model
For these class of models, the assumption is that v[k] is predictable, but with the additional require-
ment of a linear predictor for the measurement, unlike the one in (2.17).
To understand the basic idea, ﬁrst rewrite the DE for the true response x[k] (2.12) in terms of the
measurement using (2.15) to obtain
y[k] = −a1y[k −1] + b1u[k −1] +
z                   }|                   {
(v[k] + a1v[k −1])
w[k]
=⇒ˆy[k|k −1] = −a1y[k −1] + b1u[k −1] + ˆw[k|k −1]
In order to have a linear predictor for the measurement y[k −1], we require
ˆw[k|k −1] = 0
(2.19)
meaning w[k] is the white-noise signal e[k]. It follows that
ˆy[k] = −a1y[k −1] + b1u[k −1]
(2.20)
ˆv[k] = −a1v[k −1]
(2.21)
leading to a ﬁrst-order auto-regressive predictor for v[k]. Since the error in the diﬀerence equation
for the measurement is white (in contrast to the OE case), the description in (2.21) is known as the
equation-error model, speciﬁcally the auto-regressive eXogenous (ARX) model.
Notice that the model for the measurement error in (2.21) has a coeﬃcient identical to the one
for the deterministic response in (2.12). A major implication of (2.21) is that the deterministic and
noise process share the same dynamics.
From an estimation viewpoint, the ARX model oﬀers a signiﬁcant beneﬁt over the OE model
counterpart in that unique estimates of the ARX model parameters can be obtained. However, this
luxury comes at a sacriﬁce that may be fairly serious as we shall shortly learn.
The linear least-squares estimates of the equation-error model using the training data are ob-
tained as
ˆa1 = −0.7788(±0.012), ˆb1 = 0.472(±0.016)
(Equation-Error Model)
(2.22)
% Estimate equation -error model of specified order and delay
mod_arx = arx(datatrain ,[1 1 1]);
present(mod_arx)
% Verify using the LS method described in Chapters 14 and 22
Both the estimated models must now be tested for their “goodness” to make improvements (if
necessary) and to eventually select the “better” model.
2.4.6
GOODNESS OF THE MODEL
The prediction error, technically termed as residual, serves as the key quantity of interest in assess-
ing the goodness of the model. It is formally deﬁned as
ε[k] = y[k] −ˆy[k]
(2.23)
A “good” model should not leave behind residuals (from training) that oﬀer further scope for pre-
dictions, while avoiding overﬁtting (recall Example 2.4). Consequently, the following have to be
fulﬁlled:
i. the residuals cannot be explained (predicted) by the input (test for the deterministic model),
ii. the residuals cannot be predicted using its own past, i.e., it is is truly unpredictable (test for the
stochastic model), and
iii. the errors in parameter estimates are small or negligible relative to the estimates themselves (test
for over-parametrization).

46
Principles of System Identiﬁcation: Theory and Practice
Predictions
The one-step ahead predictions from the estimated models are computed on the training data. The
scatter plots comparing predictions vs. observed values are shown in Figure 2.8.
−1
−0.5
0
0.5
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Output−error model on the training data
Observed value
Predicted value
Correlation: 94%
(a) Output-error model
−1
−0.5
0
0.5
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Observed value
Predicted value
Equation−error model on the training data
Correlation: 89%
(b) Equation-error model
FIGURE 2.8
Comparing one-step ahead predictions (deviations from steady-state) of the identiﬁed models on
the training data.
The output-error model fares better than its equation-error counterpart in this respect as evident
from the correlation coeﬃcient between the predictions ˆy[k], and the observed response y[k]. A
visual examination of Figure 2.8 also conﬁrms this fact because the predictions of the output-error
model have a relatively lower scatter around the unity line5.
% Predictions on training data
yhat_oe = predict(mod_oe,datatrain);
yhat_arx = predict(mod_arx ,datatrain);
% Predictions vs. observations
figure;
plot(yhat_oe ,datatrain.y,’x’,datatrain.y,datatrain.y,’r-’)
figure;
plot(yhat_arx ,datatrain.y,’x’,datatrain.y,datatrain.y,’r-’)
Test for deterministic model: Correlating residuals with inputs
The foregoing prediction analysis puts the models in close contest. However, to test whether these
models leave behind any unexplained input eﬀects, the correlation between the residuals and the
lagged (time-shifted) inputs are computed for each of these models. This is also known as the cross-
correlation function. Figure 2.9 shows the cross-correlation between the residuals and lagged inputs.
A signiﬁcant correlation between ε[k] and input u[k] at positive lags directly implies that the eﬀects
of input on the process response have not been completely explained. From Figure 2.9, it is clear
that there exists no signiﬁcant correlation between the residuals of the OE model and the inputs
at any lag. Thus, the estimated OE model in (2.18) has satisfactorily captured the dynamics of the
deterministic process.
On the other hand, the residuals from the ARX model are signiﬁcantly correlated with inputs im-
plying that it has not managed to adequately capture the deterministic eﬀects. Therefore, it becomes
5An alternative plot superposing the predicted and observed outputs can also be used.

A Journey into Identiﬁcation
47
−30
−20
−10
0
10
20
30
−0.1
−0.05
0
0.05
0.1
Lags
Correlation
Correlation between residuals and lagged inputs
−30
−20
−10
0
10
20
30
−0.1
0
0.1
0.2
0.3
Lags
Correlation
FIGURE 2.9
Correlation between residuals and lagged inputs for the output-error (bottom) and equation-error
(top) models.
necessary to consider higher-order ARX models as possible candidates. A few iterations of model
ﬁtting followed by correlation analysis of the residuals result in a ﬁfth-order ARX model as being
satisfactory. Figure 2.10 displays the correlation between the residuals and inputs for this model.
The prediction errors do not contain any signiﬁcant eﬀects of the inputs. The parameter estimates
for this model are reported in Table 2.1. Observe that one of the corresponding parameter estimates
( ˆa1) is marked by a signiﬁcant error, thereby reducing the reliability of the model. This should be
expected since we have overparametrized the model (keep in mind that the deterministic process is
a ﬁrst-order).
The OE model is clearly the winner here in two respects, namely, parameter estimation error
and parsimony (parameter dimensionality).
% Compute one-step ahead prediction errors
err_oe = pe(mod_oe,datatrain); % Returned as an iddata object
err_arx = pe(mod_arx ,datatrain);
% Correlation between residuals and inputs
corrye_oe = xcov(err_oe.y,datatrain.u,24,’coeff’);
corrye_arx = xcov(err_arx.y,datatrain.u,24,’coeff’);
% 99 % significance levels
clim = 2.58/sqrt(length(datatrain.y));
% Plot
figure
subplot(211); stem(-24:24,corrye_oe); hold on
plot([-24 24],[1 1]*clim,’r--’,[-24 24],[-1 -1]*clim,’r--’)
subplot(212); stem(-24:24,corrye_arx); hold on
plot([-24 24],[1 1]*clim,’r--’,[-24 24],[-1 -1]*clim,’r--’)
% Fit the best equation -error model
mod_arxb = arx(datatrain ,[5 5 1]);
present(mod_arxb)
% Compute residuals
err_arxb = pe(mod_arxb ,datatrain); % Compute prediction errors
% ACF of residuals and CCF with inputs
[acf_errb ,lags] = xcov(err_arxb.y,20,’coeff’);
ccf_errbu = xcov(err_arxb.y,datatrain.u,20,’coeff’);
figure
subplot(211); stem(lags(21:end),acf_errb(21:end))
subplot(212); stem(lags,ccf_errbu)

48
Principles of System Identiﬁcation: Theory and Practice
0
5
10
15
20
25
−0.5
0
0.5
1
Lag
Correlation
Auto−correlation function of residuals
−30
−20
−10
0
10
20
30
−0.1
−0.05
0
0.05
0.1
Lag
Correlation
Correlation between residuals and lagged inputs
FIGURE 2.10
Correlation analysis of residuals obtained from the best equation-error model.
TABLE 2.1
Parameter estimates (errors) of the best equation-error model for the liquid-level system
Parameter
a1
a2
a3
a4
a5
Estimate
0.067
(±0.03)
0.112
(±0.03)
0.102
(±0.03)
0.14
(±0.02)
0.19
(±0.02)
Parameter
b1
b2
b3
b4
b5
Estimate
0.451
(±0.02)
0.377
(±0.02)
0.311
(±0.03)
0.17
(±0.02)
0.136
(±0.02)
Test for noise model: Predictability in residuals
Given that the output-error model has captured the deterministic eﬀects adequately well, a natural
step is to assess if the stochastic part of the model has satisfactorily explained the random eﬀects.
A plot of the auto-correlation function of residuals is used for this purpose. It is essentially the
correlation between any two samples separated in time by a lag l. Any predictability in the sequence
manifests as non-zero correlation at a non-zero lag l. The ACF of the residuals from the OE model
is shown in Figure 2.11. The absence of any statistically signiﬁcant correlation at any non-zero lag
indicates no scope for predictability within the residuals. Note that by deﬁnition, the ACF is unity
at lag zero, i.e., any sample is best correlated with itself.
The stochastic model assumed in (2.16), thus suﬃciently explains the noise characteristics of the
measured output.
For completeness of analysis, the auto-correlation function of the residuals from the ﬁfth-order
% Plot the ACF of residuals
acf_err = xcov(err_oe.y,20,’coeff’);
figure; stem((0:20),acf_err(21:end)); hold on
% 99 % significance levels
clim = 2.58/sqrt(length(err_oe.y));
plot([0 20],[1 1]*clim,’r--’,[0 20],[-1 -1]*clim,’g--’)

A Journey into Identiﬁcation
49
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Auto−correlation function of the residuals
ACF
Lags
FIGURE 2.11
Auto-correlation function of the residuals from the output-error model.
ARX model is also evaluated. The top panel of Figure 2.10 display the ACF. Some signiﬁcant
correlation exists at non-zero lags implying that the stochastic terms are not adequately modeled.
The results of the assessment tests are convincingly in favor of the OE model in all respects.
Thus, solving a non-linear optimization problem was worth the eﬀort.
Cross-validation
A good model is one which yields good predictions on a fresh data set. The predictions of the output
error model on a fresh data are shown in Figure 2.12. The acid test for a model is its ability to make
good long-range predictions. The predictions (deviations from steady-state) shown in Figure 2.12
are the inﬁnite-step ahead predictions. The one-step ahead predictions of the output at kth instant
are computed with the knowledge of the observations until the previous instant, i.e., the (k −1)th
instant whereas the inﬁnite-step ahead predictions are calculated based on the observations provided
at inﬁnite time in the past, i.e., practically without any information about the observations, but only
based on the input proﬁle.
−1
−0.5
0
0.5
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Predictions of the OE model on the test data
Observed
Predicted
(a) Scatter plot
1500
1520
1540
1560
1580
1600
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
Samples
Output
 
 
Observed
Prediction
(b) Snapshot of predictions
FIGURE 2.12
Inﬁnite-step ahead predictions from the output-error model on the test data set.
As mentioned earlier, the test data set constitutes samples N = 1501 onwards. Figure 2.12(a)
shows that the output-error model is able to predict very well on a fresh data set. A common measure
of goodness-of-predictions is the normalized root mean square (NRMS) measure of ﬁt (see also
§14.3.2):
Rf = 1 −||y −ˆy||2
||y −¯y||2

50
Principles of System Identiﬁcation: Theory and Practice
where y and ˆy are vectors of measurements and predictions, respectively, and ¯y is the mean value of
y. The notation ||.||2 stands for the 2-norm of the vector. The NRMS value for predictions calculates
to about 72%. A snapshot of the predictions superimposed on the observed values is shown in Figure
2.12(b). The graph visually conﬁrms the goodness of predictions.
% Infinite -step ahead predictions
yhat_inf = predict(mod_oe,datatest ,Inf);
yhat = yhat_inf.y;
% Compare against measurements
figure
plot(yhat,datatest.y,’x’,datatest.y,datatest.y,’r-’)
figure
plot((1501:1600),datatest.y(1:100) ,(1501:1600),yhat(1:100),’gx’)
Final model
Based on the results of the model assessment tests, namely, the residual analysis, analysis of errors
in estimates and cross-validation, the ﬁrst-order OE model with a delay of unit sample is deemed as
the most appropriate:
y[k] = x[k] + e[k]
x[k] = −ˆa1x[k −1] + ˆb1u[k −1]
ˆa1 = −0.8826(±0.0019), ˆb1 = 0.4621(±0.0052)
(2.24a)
(2.24b)
(2.24c)
It is also a common practice to express the diﬀerence equation in what is known as a transfer
function (TF) operator form:
y[k] = G(q−1)u[k] + H(q−1)e[k]
(2.25)
where G(q−1) and H(q−1) are known as plant and noise models, respectively. The quantity q−1 is
known as the backward shift operator, meaning q−1x[k] = x[k −1].
The OE model in (2.24) in the TF form is written as:
y[k] =
(±0.005)
0.4621q−1
1 −0.8826
(±0.002)q−1 u[k] + e[k]
(2.26)
The transfer function representation has certain nice features, which are discussed in Chapter 4.
The presentation until this point illustrated the procedure to develop an empirical input-output
model from data. Now we turn to show how a state-space description can be identiﬁed. Identiﬁcation
of state-space models, as remarked in §1.2, has certain advantages over the input-output forms,
speciﬁcally in terms of numerical eﬃciency and order determination.
2.4.7
DEVELOPING A STATE-SPACE MODEL
A generic state-space model that is typically used in identiﬁcation has the form
x[k + 1] = Ax[k] + Bu[k] + Ke[k]
(State equation)
(2.27a)
y[k] = Cx[k] + Du[k] + e[k]
(Output equation)
(2.27b)
where x[k] is the vector of states, or hidden or unobserved variables. The variable e[k] is the vector
of unpredictable random errors (as in the output-error model). The state-space form in (2.27) is

A Journey into Identiﬁcation
51
0
1
2
3
4
5
6
−1
−0.5
0
0.5
1
1.5
2
2.5
3
3.5
Log of Singular values
Model order
(a) log Hankel singular values
0
5
10
15
20
25
−0.5
0
0.5
1
Auto−correlation function of residuals
−30
−20
−10
0
10
20
30
−0.1
0
0.1
CCF between residuals and inputs
lag
(b) Residual analysis of the ﬁrst-order model
FIGURE 2.13
Plot of (log) Hankel singular values and correlation functions from the state-space model.
also known as the innovations form. When the structures of state-space matrices in (2.27) are not
constrained in any manner, we have a non-parametrized state-space form.
The state-space and input-output descriptions are interconvertible. With a suitable parametriza-
tion (constraints on state-space matrices) of the innovations form followed by conversion into input-
output form, one can arrive at the OE and ARX models in (2.24) and (2.20), respectively. For
instance, with a single-state and setting K = 0 in i.e., by only letting the error enter the output
only, leads to the OE model form in (2.24). It is also possible to do the reverse, i.e., write a state-
space model from the identiﬁed input-output OE model. Such state-space models are then known
as parametrized state-space models. However, we shall reserve that discussion for Chapter 23. Be-
low we demonstrate a widely used approach for state-space identiﬁcation which directly estimates
a state-space model from data.
In order to directly estimate the state-space model of the form (2.27), we use a popular subspace
method known as the N4SID algorithm, where the user is not required to key in any guess of the
order. As mentioned earlier, the algorithm automatically determines this parameter using what are
known as Hankel singular values. In practice, the user can restrict the order to a range, say from
ﬁrst to ﬁfth order. The subspace algorithm is supplied with the delay information that we estimated
earlier.
Setting the range of orders as one to ﬁve and the delay to unity, the algorithm estimates a ﬁrst-
order discrete-time state-space model.
ˆA = 0.881(±0.002);
ˆB = 0.043(±5 × 10−4)
(2.28a)
ˆK = −8.0552 × 10−4(± −1.2 × 10−3)
(2.28b)
ˆC = 10.71(±4.4 × 10−6);
D = 0
(2.28c)
where the values in brackets are (numerically computed) errors in the respective estimates. The ﬁrst-
order choice is arrived at by examining the (logarithm of) Hankel singular values for the speciﬁed
range of orders, as shown in Figure 2.13(a). States that have signiﬁcant Hankel singular values are
retained in the model.
Residual analysis plots shown in Figure 2.13(b) shows that the ﬁrst-order model has satisfactorily
explained the input-output relationship as well as the stochastic terms.
Identifying a structured state-space model
Barring ˆK, all the estimates in (2.28) appear to be signiﬁcant6. The high error in ˆK relative to its
estimate indicates that the true K is most likely to be zero, i.e., the disturbance term in the state
6The matrix D represents the instantaneous eﬀect of input on output. A non-zero delay automatically implies that D = 0.

52
Principles of System Identiﬁcation: Theory and Practice
Listing 2.3
MATLAB code for estimating the state-space models.
% Load the input-output data
load liqleveldata
% Create IDDATA object and training / test objects
Z = iddata(yk,uk,1);
[datatrain ,Tr] = detrend(Z(1:1500),’constant’);
datatest = detrend(Z(1501:end),Tr);
% Fit a state-space model and analyse the residuals
mod_ss = ssest(datatrain ,1:5,’Ts’,1);
resid(datatrain ,mod_ss)
present(mod_ss)
% Re-estimate the SS model w/o the state disturbance
mod_ss2 = ssest(datatrain ,1,’Ts’,1,’disturbancemodel’,’none’);
present(mod_ss2)
% Estimate a structured SS model corresponding to OE model
mod_ss3 = ssest(datatrain ,1,’Ts’,1,’disturbancemodel’,’none’,’form’,’canonical...
’);
present(mod_ss3)
is absent7. Thus, we could omit that term in the state equation and ﬁt the model once again. The
resulting estimate is:
x[k + 1] = 0.8826(±0.001375)x[k] + 0.04152(±2.4 × 10−4)u[k]
(2.29a)
y[k] = 11.13(±9.126 × 10−7)x[k] + e[k]
(2.29b)
The estimates have clearly improved, as evident from the lowering of errors relative to the model in
(2.28).
One could further force the state-space model to have a structure similar to (2.24) so that it is
possible to compare the estimates. Forcing C = 1 (in addition to K = 0) produces the estimate
x[k + 1] = 0.8826(±0.00188)x[k] + 0.04621(±0.0052)u[k]
(2.30a)
y[k] = x[k] + e[k]
(2.30b)
resulting in almost congruent models because state-space models with structural constraints (a.k.a.
structured state-space models) are identiﬁed using the same method (prediction-error minimization)
as that for input-output models. The only diﬀerence is in the initial guess of these estimates.
Identiﬁed model vs. true model
In closing, it is instructive to compare the identiﬁed models in (2.18) and (2.30) with the “true”
linearized discrete-time model. This is only for the purpose of illustration. In a practical situation
it is obvious that such a privilege does not exist.
The linearized, discretized model of the non-linear continuous-time liquid-level system is:
x[k] = −0.8825x[k −1] + 0.47u[k −1]
(2.31)
7The errors reported for the state-space model are computed using a numerical sensitivity analysis, unlike for the OE and
ARX models. Therefore, in general, a great deal of caution is required in using these error estimates.

A Journey into Identiﬁcation
53
at a sampling interval of Ts = 1 min. The estimated output-error models in (2.18) and (2.30) are
a very close match to the discretized model of the process in (2.31) in structure and parameters,
reproduced below for convenience,
ˆa1 = −0.8826(±0.002), ˆb1 = 0.4621(±0.006)
(2.18 revisited)
It is interesting to compare (2.31) with the ﬁrst-order ARX model of (2.22). The input coeﬃcient is
estimated with reasonable accuracy but the regression parameter estimate is signiﬁcantly diﬀerent
from the true value. In other words, a systematic error (bias) is incurred in the estimation of a1. This
is true for all ARX model estimates whenever a mismatch exists between the noise model of ARX
structure and that of the true process (a demonstration of this fact is given in Chapter 21).
In the simulation of the system, a stationary unpredictable noise (white-noise) was added to
the response with the variance adjusted to obtain a SNR of 10. In retrospect, the deterministic
parts of the ﬁrst-order OE and ARX model matched with the process (in structure), while only the
stochastic part of the OE model agreed with that of the data generating process. The latter factor
is the reason why a ﬁrst-order ARX model failed to deliver. A higher-order model was satisfactory
in some respects, but then the deterministic part was over-modeled. The message to carry forth is
that the characterization of the stochastic terms is important in rightly modeling the deterministic
sub-systems of the process.
2.5
REFLECTIONS AND SUMMARY
It is appropriate to conclude this chapter with an introspective summary of the important lessons
learned herein. In these reﬂections, we take the opportunity to raise generic questions that are en-
countered in identiﬁcation and provide answers as pointers to the appropriate portions in this text.
1. In Example 2.1, a model, which was linear in input, but non-linear in parameters, was found to
be non-identiﬁable. Is this true of all models (strictly speaking, predictors) that are non-linear in
parameters? The answer is not necessarily yes. For linear dynamical systems, we shall study in
§18.6 identiﬁability of diﬀerent model structures.
2. Example 2.2 of a FIR system showed the role of input design in identiﬁability, which is the ability
to identify a model uniquely. In general also, does this hold good? The answer is, yes. Section
22.3 discusses these concepts in the context of input design.
3. The relation between variability in parameter estimates and SNR was illustrated in Example 2.3.
What is the exact relation in general? The fundamental Cramer-Rao’s inequality provides bounds
on lowest achievable error in parameter estimates. It involves the Fisher’s information metric.
These theoretical concepts are deﬁned and illustrated in Chapter 13. Speciﬁc expressions for
errors in parameter estimates can be derived under large-sample conditions for certain estimators
such as LS and MLE (see §14.3.1 and §15.1.4).
4. In generating the data for the liquid level system, we have used a PRBS input. Naturally, we
could have interrogated the system with a diﬀerent input sequence, e.g., a step or a mixture of
sine waves. Once again, the key governing factors are identiﬁability and SNR. Section 22.3, as
mentioned earlier, is devoted to the topic of input design.
5. The sampling interval of 1 min. for the level measurement was based on the general guidelines
given in Chapter 6, which discusses fundamental results on how should one choose the sampling
rate? While the general answer is based on the maximum frequency contained in the signal, in
identiﬁcation and control, the connection is with the pace of the dynamics or the bandwidth (both
related to time-constants) of the system.
6. Pre-processing and apportioning of data for training and cross-validation purposes can involve
more generic approaches than the ones used in the case study. See Chapter 22 for related discus-
sions.

54
Principles of System Identiﬁcation: Theory and Practice
7. Models for the liquid level system were selected from the LTI family. A non-linear model would
have certainly been a better choice given the physics of the process, but would have opened up
a number of challenges in the estimation stage. A general recommendation is to begin with a
LTI family because they can be estimated relatively easily, unless there are compelling reasons
to select otherwise.
8. Is it possible to determine whether an LTI model suits a given process? The answer to this ques-
tion is provided by coherence (see §11.4), which not only examines the suitability of an LTI
relationship but also suggests the frequency range over which such a model can be built. The
results from this analysis can be used in other stages of identiﬁcation, such as delay estimation
and pre-ﬁltering the data.
9. Non-parametric descriptions provide a wealth of information. While impulse and step response
models oﬀer good insights, frequency-domain descriptions present a broader and deeper pic-
ture of the system dynamics. These aspects are discussed in Chapters 5, 11 and 17. The non-
parametric models in §2.4.4 were estimated using the methods described in Chapter 20.
10. We considered two forms of parametric model structures, namely the OE and the EE model struc-
tures, since they are the two widely used starting points in identiﬁcation of parametric models.
See §17.5 for a comprehensive description of the gamut of parametric models used in identiﬁ-
cation. Non-linear least squares and the linear version used for parameter estimation are special
cases of the more versatile and powerful prediction-error minimization methods discussed in
Chapter 21.
11. The primary reason for the poor performance of ARX model is that the parametrization of the
noise model in (2.21) is completely tied to that of the deterministic part. This kind of parametriza-
tion does not suit the case study, but may suit several other processes. A converse argument can
also be made for the OE models. See the ensuing point.
12. The output-error model structure turned out to be an appropriate one for the liquid level sys-
tem. In general is this true? If the measurement noise possessed some predictability, would the
output-error model structure still produce good results? The answer is yes, only under open-loop
conditions and for the deterministic part. See Chapter 21 for a theoretical proof.
13. If the stochastic part of the output has some predictability, auto-correlation analysis of the resid-
uals from the best OE model would clearly indicate those characteristics. In such a case, a time-
series model for the residuals is also constructed. Subsequently, the deterministic and time-series
models are used as initial guesses for estimating the more general Box-Jenkins model. See Chap-
ter 21 for a case study.
14. When the parametrization is such that it results in a linear predictor (e.g., ARX), there are cer-
tain advantages. On the other hand, having independent “tunable” parameters in the noise and
deterministic models (as in Box-Jenkins structures) always results in non-linear predictors, but a
broader class of processes can be modeled. Which one is a better approach? The example shows
that mathematical convenience need not always be given the top priority. Notwithstanding this
fact, a common practice is to ﬁrst develop the “best possible” ARX model for the given data and
then seek other model structures lest they fail.
15. The residual analysis is the key to model reﬁnement. What information does the correlation
between residuals and inputs contain? How can we use this information to improve the model?
These aspects are discussed at length in Chapter 22. The auto-correlation and cross-correlation
functions are the main tools, as was evident from the case study. These concepts are theoretically
deﬁned in Chapter 8 while estimators of these functions are provided in §16.4.
16. Order determination for input-output models is traditionally done using information-theoretic
measures such as AIC, BIC, etc. (see §22.6.3). State-space models oﬀered a clear advantage in
that it replaced the lengthy trial-and-error approach to order determination. It also obviates the
need for the use of aforementioned measures. Do these advantages always exist? In general,
state-space models almost always oﬀer valuable preliminary insights into the order and structure

A Journey into Identiﬁcation
55
of input-output models. One of the disadvantages, among a few others (e.g., non-uniqueness of
representation) of state-space models is that a non-parametric state-space model has more param-
eters to estimate than an identiﬁable input-output model of the same order. Thus, do we run into
identiﬁability issues with these models? Chapter 4 presents a vivid comparison of deterministic
state-space vs. input-output models. See also Chapter 23.
17. Constraining the state-space matrices structurally reduces the number of unknowns to be esti-
mated, thereby improving identiﬁability. In the case study, we were able to discover the under-
lying structure of the process by a systematic analysis of the freely parametrized model. (2.28).
Generalizing these ideas leads us into the expanses of grey box modeling. See §23.7.2 for expan-
sions and illustrations of these ideas.
For many of the questions above, generally speaking, no deﬁnitive answers exist. Only guiding
principles for building good quality models can be given. The responsibility rests with the user
in making “appropriate” choices using a pragmatic blend of theory and intuition at all stages of
identiﬁcation; from a careful design of experiments to a systematic analysis of data.
EXERCISES
E2.1. Highlight the two fundamental challenges in identiﬁcation.
E2.2. Give two examples of a model that is not identiﬁable in the entire parameter space, i.e., is not
globally identiﬁable, but is locally identiﬁable.
E2.3. Explain the two diﬀerent model structures, namely, output-error model and equation-error model
structures.
E2.4. Describe the iterative procedure for identiﬁcation.
E2.5. Show that for Example 2.2, using the input u[k] = sin(ω0k) + sin(ω1k) does not result in loss of
identiﬁability.
E2.6. Re-estimate the parameters of the OE model with diﬀerent sample sizes of training data N = 100
and N = 500. Compare the errors in the estimated parameters with those reported in (2.24). What
do you conclude?
E2.7. Re-work the entire liquid level case study for two diﬀerent signal-to-noise ratios, 5 and 1 respec-
tively. What do you conclude on the accuracy and precision of the resulting parameter estimates?
E2.8. In the exercise above, does the subspace algorithm still rightly identify the model order when a
state-space model is being identiﬁed?
E2.9. Generate a fresh ﬂow-level response data by changing the measurement noise from white to
ﬁltered noise by placing a discrete-time ﬁlter block in the disturbance channel path, in the SIMULINK
block diagram. Use the ﬁlter coeﬃcients num = 1, den = [1 -0.5] and set the SNR to 10. For this
purpose, switch oﬀthe noise, simulate and compute the variance of the true response. Subsequently,
turn the white-block noise on and adjust the variance parameter in the block such that the desired
SNR is achieved.
E2.10. Using the data from the above simulation, determine the best OE model (remember the only
tests are correlation between inputs and residuals, as well as good parameter estimates) still manages
to explain the deterministic process correctly.
E2.11. How does the ARX model (of a suitably high-order) fare in the above situation, i.e., data generated
with colored noise?
E2.12. Develop a state-space model for the process using the above data. Compare it with the model
in (2.29) and comment on the diﬀerences, if any.

3
Mathematical Descriptions of Processes:
Models
This chapter presents the reader with the basic deﬁnition of a model and the diﬀerent classes of
models that can be developed. The material in this chapter will enable the user to understand
the various factors that characterize a model and the criteria that govern its choice.
A fact that stands out distinctly in Chapters 1 and 2 is that the model is both the end-product and
the centerpiece of every identiﬁcation exercise. A good model necessarily requires “good” quality
data and the choice of a good starting model. While generating quality data is achieved by a proper
input design, the choice of the initial model structure depends on the a priori knowledge of the
suitable model type and structure. Usually the situation is that we begin with a good guess and
improve upon the initial choice if necessary (as in the case study of Chapter 2). The ﬁnal decision
is governed by how well the model suits the purpose, cost (of estimation) considerations, the merits
and limitations of a given model and other constraints.
The speciﬁcation of a model is usually in terms of its type, structure and order. Any blind guess
of these speciﬁcations will obviously take us through a circuitous path and at times not even con-
verge to a working model. A good guess should be based on any a priori knowledge of the process
complexity, a preliminary examination of the data, ease of estimation, end-use and physical mean-
ingfulness of the model. A systematic approach can be expected to converge to a useful working
model in a minimum number of steps.
The ﬁrst step in this process is to obtain an overview of the diﬀerent model classes available to
the user. This chapter is devoted to this cause.
We begin with the formal deﬁnition of a model.
3.1
DEFINITION OF A MODEL
A model is a set of linear/non-linear (ordinary or partial) diﬀerential (or diﬀerence), algebraic
equations in terms of the process variables / states, inputs, and parameters, built on a set of
assumptions.
The model is essentially a mathematical abstraction of the physical process. Later in this text, in
Chapter 18, we shall observe that an alternative way of specifying a model is to specify the predictor
(prediction expression) and characterize the prediction error.
Terminology
In modeling literature, inputs to a model need not correspond to the physical inputs to a system.
Similarly, outputs need not correspond to the physical outputs of the system. They have a broader
connotation. Outputs of a model constitute those variables that we wish to predict or explain, while
inputs to a model include all those variables that participate in the prediction. For this reason, model
inputs are more appropriately known as explanatory variables.
Figure 3.1 schematically shows the diﬀerence in the workings of a process and a model. It high-
lights the fact that the inputs to the model are not merely the physical inputs to the process. The
56

Mathematical Descriptions of Processes: Models
57
Process
!"#$%&
'()*$&%+,-.
/+01+,-.&2
3$%#$%&
'4.+&$0.)5
/+01+,-.&2
61&%$0,+"7.&
'8%97:+&%17
.;.7%&2
(a) Process generates outputs
Model
!"#$%&%'()*
+%),%-$./
0).1).//()/2
34'#4'/
0#).5,6'.5
+%),%-$./2
7*/'.89#%)%8.'.)/
:;*/,6%$9#)(#.)',./
(b) Model predicts outputs
FIGURE 3.1
The inputs and outputs of a model are in general diﬀerent from the physical inputs and outputs of
a process.
model input is a broader set. It consists of the past and present inputs to the process and all other
variables that participate in the prediction of the outputs of interest. An important part of any model
that should never be forgotten is the set of underlying assumptions. A popular class of descriptions
known as state-space models use an additional set of variables known as states (see Chapter 4)
to describe the process. These states are usually internal dynamical variables of a system. Section
4.4.3.1 discusses the related concepts in great detail.
A model is thus a map between the set of explanatory variables and the set of predicted
variables.
Example 3.1: Explanatory Variables
Auto-regressive time-series models (see Section 9.5) have the form
v[k] = −d1v[k −1] −d2v[k −2] −· · · −dpv[k −p] + e[k]
di ∈R
(3.1)
where v[k] and e[k] are the output and stochastic (endogenous) input of the random process,
respectively. The explanatory variables in these models are the past outputs whereas in
moving average models (see Section 9.4), the inputs are endogenous white-noise (shock-wave
like) signals. On the other hand, where the model is used as a soft-sensor the inputs are all
those variables that can aid in inference of the infrequently measured variables.
Notation: The text employs the conventional notation. Outputs and inputs are denoted by y and
u, respectively, while the states are denoted by x.
3.2
CLASSIFICATION OF MODELS
The primary classiﬁcation of models is based on the approach to modeling itself, i.e., ﬁrst-
principles models vs. empirical models. Within these two classes, further categorizations are pos-
sible based on several considerations, such as
• Do we wish to model the steady-state behavior or the transient (dynamic) behaviour?
• Are the important process variables dependent on process directions other than time? (e.g., is the
concentration in a reactor varying with the location or can be assumed to be uniform?)
• Does the process of interest possess purely random behavior or does it exhibit a mix of determin-
istic and random behavior?
• What kind of input-output relationships are desirable? (e.g., linear, non-linear, time-varying, etc.)
• What is the end-use of the model? Do we wish to use the model for control, monitoring, opti-
mization or prediction?

58
Principles of System Identiﬁcation: Theory and Practice
MODELS
First-Principles
Empirical
Single-Scale
Multiscale
Static
Dynamic
Time-varying
Time-invariant
Lumped
Distributed
Linear
Non-linear
Continuous
Discrete
Deterministic
Stochastic
FIGURE 3.2
(SEE COLOR INSERT) Types of models.
• Should the model be physically meaningful or interpretable? Model structure may be required to
follow a form known from prior knowledge, for example, from a ﬁrst-principles description.
Following the line of thought above, models can be classiﬁed based on
i. Approach to modeling (e.g., ﬁrst-principles vs. empirical)
ii. System characteristics (e.g., linear/non-linear, time-varying/time-invariant)
iii. Knowledge available to the user (e.g., deterministic/stochastic, black-box/grey-box)
iv. Domain of modeling (e.g., continuous-time/discrete-time, time-/frequency-domain)
v. Response characteristics (e.g., static/dynamic, lumped/distributed)
3.2.1
TYPES OF MODELS
The diﬀerent types of models are shown in Figure 3.2. This classiﬁcation is by no means hierarchical
and exhaustive. We could begin with any class shown in Figure 3.2 and further sub-divide into
remaining classes. For example, one can have a discrete-time, ﬁrst-principles, non-linear model or a
discrete-time, empirical, linear model. In addition to the types shown, we have input-output models
and state-space models. However, this classiﬁcation is based on the mathematical abstraction of the
process.
We shall now brieﬂy understand the nomenclature of the model classes shown in Figure 3.2.
In Section 1.1, a brief discussion concerning ﬁrst-principles and empirical models was outlined.
The section below oﬀers more insights into this comparison while taking the opportunity to highlight
a few important aspects.
First-principles vs. empirical models
This classiﬁcation is based on the diﬀerence in the approach taken towards modeling. First-
principles models are developed from fundamentals using basic laws and constitutive relationships.
The approach generally results in causal, continuous, non-linear diﬀerential-algebraic equations.
The equation in (2.6) is a simple example of a ﬁrst-principles model. While these models are very ef-
fective and reliable, simulations of these models require good numerical ODE and algebraic solvers.
The latter fact occludes ﬁrst-principles models from being used in several on-line applications, for
example, in control. Equally important is the fact that most processes do not oﬀer the luxury of even

Mathematical Descriptions of Processes: Models
59
Empirical Models
Non-parametric
Parametric
Black-box
Grey-box
Models'do'not'possess'
any'speciﬁc'structure'but'
usually'described'by'
responses'(responses'are'
not'parametrized)
Models'possess'a'speciﬁc'
structure'and'are'
characterized'by'delay,'
order'and'a'set'of'
parameters'
Models'are'developed'using'
minimal'process'
knowledge.'Parameters'
cannot'be'(easily)'related'
to'physical'properties.
A'priori'knowledge'is'used'
in'model'development.'
Model'parameters'(full'/'
partial'set)'have'physical'
meaning.
FIGURE 3.3
(SEE COLOR INSERT) Four broad categories of empirical models.
developing a ﬁrst-principles model. The two foregoing facts are perhaps the most signiﬁcant factors
that have strongly impeded the popularity of this approach.
On the other hand, owing to their reliability, ﬁrst-principles models are widely used in commer-
cial simulators and in root-cause diagnosis. An important point to note is that no model is truly
ﬁrst-principles. All ﬁrst-principles models possess some amount of empirical characteristics, with
varying degrees, either in the form of simplifying assumptions or experimentally determined pa-
rameters.
Empirical models are built using measured data. Naturally, identiﬁed models are in discrete-time.
Exceptions to this observation are where continuous-time models are directly identiﬁed from sam-
pled data. One of the biggest beneﬁts that empirical models hold over their ﬁrst-principles coun-
terparts is that only a minimal knowledge of process is required in developing them. The second
advantage they oﬀer is the ﬂexibility in model structure, which is highly useful in several applica-
tions.
These beneﬁts leverage on a few factors. Prime among them is the data quality, a factor that is
not easy to control. While noise is eﬀectively handled by the estimation methods available today,
the main requirement is the presence of suﬃcient excitation in the inputs. Further, empirical models
usually do not have good extrapolation capabilities. The model structure is chosen to best explain
variations witnessed in the training data, which is usually a small subset of the entire range of
possible process changes. The example of empirical modeling of the liquid level system in §2.4
may be recalled in this context. Another shortcoming of an empirical model is the inability to use
it in understanding the eﬀect of changing a process design parameter. For instance, the empirical
model developed in §2.4 does not reveal how a change in cross-sectional area of the tank inﬂuences
the liquid level. In contrast, ﬁrst-principles models are naturally equipped to answer questions of
this kind.
Notwithstanding the disadvantages, empirical models are very popular because of the ease with
which they can be developed and the requirement of minimal process knowledge. For processes
with complex behavior, empirical modeling is the natural alternative. Moreover, empirical models
are usually built only in the post-design stage, i.e., these models are usually used only to capture
process behavior for the chosen design conditions.
Classiﬁcation of empirical models
The class of empirical models can be further subdivided into four broad categories, namely, para-
metric / non-parametric models (recall §1.3.3.2) and black-box / grey-box (recall §1.4.6). Figure 3.3
depicts these four categories along with their descriptions.

60
Principles of System Identiﬁcation: Theory and Practice
Non-parametric vs. parametric models
The distinction between a non-parametric and parametric model is based on whether the model
possesses a speciﬁc “structure” chosen by the user or not.
Example 3.2: Non-Parametric Model: Impulse Response Model
Any discrete-time linear time-invariant system with input u[k] and output y[k] is described
by the convolution equation
y[k] =
∞
X
n=−∞
g[n]u[k −n]
(3.2)
where g[.] is known as the impulse response of the discrete-time system. Also known as the
impulse response model, this is an example of a non-parametric model since the user makes
no assumption about the “structure” of the model but rather only assumes linearity and
time-invariance.
Chapters 4 and 17 discuss this model at length in the context of identiﬁcation.
A common misconception is that non-parametric models are “free” of parameters or unknowns,
which is obviously not true. The coeﬃcients {g[k]} are the parameters of the model, but bear a direct
connection with the physical characteristics of the system.
The term parameter, in fact, stems from the parametrization of the system’s response, typically
to elementary inputs, for example, impulse, step and sinusoidal signals. As a consequence of this
parametrization, the non-parametric response models can be re-expressed in terms of these parame-
ters, resulting in what are known as parametric models. In the example below, the parametric model
results when the impulse response sequence {g[k]} of the convolution model (3.2) is parametrized
(see Chapter 4 for details).
Example 3.3: Parametric Model: Difference Equation Model
Any discrete-time linear time-invariant system with input u[k] and output y[k] can be de-
scribed by the diﬀerence equation
y[k] +
na
X
m=1
amy[k −m] =
nb
X
n=0
bnu[k −n]
(3.3)
where {am} and {bm} are the parameters of the diﬀerence equation model.
In identiﬁcation, the number of past inputs and outputs to be included become decision
variables, which are usually determined by a mix of statistical tools and experience. Further,
the parameters {am} and {bm} do not directly reveal the characteristics of the system unlike
g[.], which directly reveals the impulse response of the system.
A formal deﬁnition of the term structure is presented in Chapters 17 and 18. For now it suﬃces to
consider it as a term that refers to the speciﬁc mathematical form of the model and its parametriza-
tion. In the absence of any process knowledge, non-parametric models serve as good starting points
in identiﬁcation. The insight obtained from this exercise is used in the identiﬁcation of a suitable
parametric model. Chapters 4 and 17 contrast these two classes of models in greater detail.
Black-box vs. grey-box models
Traditionally empirical models have always been black-box models, meaning neither the structure
nor the parameters have a one-to-one correspondence with the physical properties of the process.
When the purpose of a model is only prediction, black-box models make a good choice. Where

Mathematical Descriptions of Processes: Models
61
physical interpretability is required, it becomes necessary to impose constraints on the structure
(functional form) of the model and the nature of model, which is usually done before and/or during
the estimation stage. The resulting models are then grey-box models, whose level of transparency
depends on the a priori information available to the user.
For example, it is known that the displacement of a mass-spring-dampener system has second-
order dynamics with respect to the external force applied. Imposing this requirement on the model
order brings it closer to the underlying process and also allows a direct interpretation of the param-
eters of the model. Grey-box models, thus, oﬀset certain disadvantages of an empirical model but
at the expense of a more complicated and costly estimation exercise. Grey-box identiﬁcation is an
advanced and emerging topic in identiﬁcation. In systems biology, grey-box models are often pre-
ferred to black-box models since scientists would like to use these mathematical models as means
of understanding and making innovations to biological processes.
Linear vs. non-linear models
The classiﬁcation is based on the mathematical nature of the assumption made about the system.
A system is said to be linear if and only if it satisﬁes the principles of homogeneity (scaling) and
superposition (addition of inputs). A formal deﬁnition follows.
Deﬁnition 3.1. (Linear System) A system with input u[k] and output y[k]
y[k] = T {u[k]}
is linear if and only if
i. T {αu[k]} = αT {u[k]} = αy[k]
ii. T {α1u1[k] + α2u2[k]} = α1y1[k] + α2y2[k]
where T is the transformation operator.
Example 3.4: Linear System
y = bu + a is linear only if a = 0; however, (y −y0) = b(u −u0) is linear.
All systems that do not satisfy the linearity conditions are non-linear. No system in reality is
exactly linear. However, for “small” changes in process conditions, the input-output relationship
can be expected to exhibit linear behavior. The range over which this approximation holds good
depends on the system in hand. Despite their obvious limitations, linear models are a natural choice
in modeling; at least they serve as good starting points for a wide variety of processes. The linear
approximation can be justiﬁed for several systems and applications where the approximation er-
rors are eﬃciently handled by either a feedback strategy or an adaptive mechanism to account for
changing operation conditions.
A major advantage of working with linear models is that the associated mathematics (of identiﬁ-
cation, control and estimation) is convenient and tractable. Moreover, they are transparent and easy
to comprehend. Moreover, the theory for linear systems oﬀers several insights into identiﬁcation as-
pects that carry forward to non-linear systems. Another beneﬁt is that several non-linear processes
can be described by linear models built on transformed data.
As remarked in Chapter 1, this text is concerned with the development of linear models. Non-
linear identiﬁcation is a mathematically intricate area with relatively fewer applications. Section
25.2 describes a few popular methods used for identifying non-linear models.

62
Principles of System Identiﬁcation: Theory and Practice
Time-varying vs. time-invariant models
A system is said to be time-invariant if it produces the same output for the same input regardless of
when the input was provided.
Mathematically,
If u[k]
T
−→y[k]
then
u[k −L]
T
−→y[k −L] ∀L ∈Z
Practically, it means that the characteristics of the system do not change with time.
Example 3.5: Time-Invariant System
The diﬀerence equation model in (3.3) is an example of a time-invariant system. Observe that
it is also linear.
Example 3.6: Time-Varying System
The system described by
y[k] + a1[k]y[k −1] = b0u[k −1]
(3.4)
is an example of a time-varying system, where the time-varying nature is introduced by the
time-dependence of the parameter a1.
Observe that this is a linear time-varying system.
Remark: No system is truly time-invariant. However, several systems can be approximately
thought of locally time-invariant, i.e., at the scale of observation / operation. Interestingly, the time-
varying behavior can be sometimes lumped into random eﬀects in the measurement or in the system.
As with the case of linear / non-linear models, time-invariant models are favorable starting points
vis-a-vis time-varying models once again due to mathematical convenience and tractability. Simi-
larly, several time-varying systems can be described as either time-invariant models in a transform
domain or by a set of locally time-invariant models.
Deterministic vs. stochastic models
As we noted in §1.3.3.1, the measured response of any (physical) process can be split into two
components:
1. A component associated with an external cause (designed or known). This is the deterministic
component.
2. A component associated with disturbances, noise, unmeasured inputs, and modeling errors. This
is the stochastic component.
A deterministic model predicts the response of a process accurately. These models are used to
explain processes whose physics are accurately known. Furthermore, inputs to deterministic models
are also deterministic, meaning their proﬁles are accurately known.
In contrast, a stochastic model is deployed to describe the response of a process which can never
be accurately predicted. These models are built on the foundations of statistics and probability. The
key challenge is that the observed response is one of the several possible responses due to which the
optimal model is ﬁt in a statistical sense as opposed to the optimal deterministic model which is ﬁt
in a functional sense. The resulting model is traditionally known as a time-series model. The theory
of stochastic modeling is generally applied to forecast changes in any process for which no external
cause could be associated or the cause itself is not measured or known.

Mathematical Descriptions of Processes: Models
63
The inputs to stochastic models, unlike in the case of deterministic models, are random signals,
which assume values from a probability distribution. An encouraging aspect is that their statistical
properties are ﬁxed, which may have to be determined from data.
Example 3.7: Stochastic Model
A wide range of disturbances can be described by a ﬁrst-order auto-regressive model
v[k] = −d1v[k −1] + e[k]
(3.5)
where v[k] is the disturbance and e[k] is the ﬁctitious ideal random signal known as the
white-noise signal (see Chapter 9).
The white-noise signal e[k] is characterized by its statistical property known as the auto-
correlation function (refer to Chapter 7).
Remark: No system is truly deterministic. An element of uncertainty always exists. However,
from an engineering viewpoint systems are deterministic if the degree of predictability is very high.
In identiﬁcation, we usually build a composite model, i.e., a deterministic plus stochastic model.
This discussion is continued in §3.2.2.
Single-scale vs. multiscale models
Several processes comprise phenomena that evolve over diﬀerent time (or spatial) scales. A fuel cell
system, atmospheric process, human system, and an integrated chemical process are all examples
of such processes. In chemical engineering, the two time-constant (time-scale) process is a classical
example of a multiscale system. Measurements of process variables contain contributions from sub-
systems and (instrumentation) devices with signiﬁcantly diﬀerent time-constants. A fuel cell system
exhibits multiscale behavior due to the large diﬀerences in the time-scales of the electrochemical
sub-system (order of 10−5 s), the fuel ﬂow sub-system (order of 10−1 s) and the thermal sub-system
(order of 102 to 103 s). The atmospheric system is a complex, large, multiscale system consisting of
micro-physical and chemical processes (order of 10−1s) to temperature variations (order of hours)
to seasonal variations (order of months). Modeling such systems presents huge challenges primarily
because there is no single scale of observation that suits all the phenomena.
Models that are built over a single scale of observation (in time or space) are known as single-
scale models. Multiscale models on the other hand model the system at diﬀerent scales or layers. The
subject of multiscale empirical modeling has gathered momentum only in the last decade. Majority
of the literature focuses on single-scale models, which pose suﬃcient challenges in themselves.
When not speciﬁed otherwise, any model is a single-scale model. Empirical models are built at
a scale which is determined by the sampling interval. The text is limited to the development of
single-scale empirical models only.
Continuous time vs. discrete-time models
As the names suggest, the classiﬁcation is based on the nature of domain in which the models are
developed. The inputs, outputs (and states) are all discrete-time quantities. Empirical models are
usually developed in discrete-time since measurements are available in the form of sampled-data.
Most of the applications are tailored to directly deploy these discrete-time models without having
to estimate the continuous-time model of the process.
Nevertheless, there may arise situations where estimating the continuous-time models become
necessary. To address these needs, various methods that can estimate the continuous-time models
from discrete-time data have evolved. Continuous-time identiﬁcation belongs to the category of
modern identiﬁcation areas, which is beyond the scope of this text.

64
Principles of System Identiﬁcation: Theory and Practice
Static vs. dynamic models
The categorization of models into static and dynamic models is a response-based one. Static models,
also known as steady-state models relate instantaneous quantities, or at best describe the eﬀects of
delayed inputs.
Example 3.8: Static Model
The liquid level in a buﬀer system is related to the outlet ﬂow rate through the valve equation
at steady-state
Fout(t) = Cv
p
h(t)
(3.6)
The coeﬃcient Cv is also known as the valve sizing coeﬃcient.
Steady-state models do not have a “memory” associated with them.
Dynamic models are a more general class of models which describe the transient behavior of
a process. These models are required in a wide range of applications whereas steady-state models
have limited applicability. All the foregoing models that we have come across are examples of
dynamic models. Continuous-time dynamic models necessarily involve derivatives to explain the
rate of evolution. A ﬁrst-principles (continuous) dynamic model was encountered in (2.6). Discrete-
time dynamic models on the other hand are in the form of diﬀerence equations. Consequently, they
rely on past outputs (and inputs) to capture the transients. Dynamic models thus have a memory. An
empirical dynamic model was constructed for the liquid level system in Chapter 2. First-principles
dynamic models are obtained by a suitable discretization of the continuous-time model. Note that
steady-state models are a special case of dynamic models.
The focus of this text is to develop empirical dynamic models.
Lumped vs. distributed parameter models
In explaining the output variations, one could treat the output to be only a function of time or
also address output variations in other dimensions. Lumped parameter models are based on the
former assumption. The variations of output in other dimensions are neglected, rather lumped into
a single quantity. Distributed parameter model, as the name suggests also examines the variations
along other dimensions. The continuously stirred-tank reactor (CSTR) is usually given a lumped
model treatment since it is safe to assume uniform concentration in the tank by virtue of the stirrer.
A plug ﬂow reactor (PFR) on the other hand calls for a distributed parameter model because the
concentration of the product (and the unreacted component) varies along the length of the reactor in
addition to time.
Lumped parameter models are easier to estimate because they are characterized by much fewer
parameters compared to the distributed parameter model. Consequently, the data length and excita-
tion requirements for estimation of these models are signiﬁcantly diﬀerent. Analogous to the case
of time-invariant vs. time-varying systems, distributed parameter systems can also be modelled with
the help of multiple (locally) lumped parameter models. Once again therefore it suﬃces to learn the
theory of developing lumped parameter models.
Domain-based models
Finally, models can also be constructed in speciﬁc domains. The continuous-time and discrete-time
are speciﬁc examples of this philosophy. In a broader sense, models are divided into those built in
the raw domain and transform domain. The raw domain is the domain in which measurements are
available to the user (typically the time domain). The transform domain model relates variables in a
transformed space. The Fourier domain is a common domain in which transform models are built.

Mathematical Descriptions of Processes: Models
65
Example 3.9: Frequency Response Function
The output and input of the system described in (3.2) are related in the Fourier domain as
Y (ω) = G(ejω)U(ω)
(3.7)
where Y (ω) and U(ω) are the Fourier transforms of the output y[k] and input u[k], respec-
tively. The function G(ejω) is known as the frequency response function or more commonly
as the transfer function (see Section 17.4.2).
The frequency response function is also the Fourier transform of the impulse response
function g[k].
Chapter 5 reviews the concepts of frequency-domain models for linear time-invariant systems. In
several applications, measurements are directly available as a function of frequency. In such cases,
the raw domain is the frequency domain itself.
Models can also be in mixed domains. An emerging example of this approach is model devel-
opment in the wavelet domain, which allows the user to model the variations as a joint function of
time and frequency (scale). Wavelet domain models have shown to be potentially elegant tools for
modeling of multiscale and time-varying systems. Section 25.1.5 discusses models described in the
wavelet domain for the purpose of modeling linear time-varying systems. In general, the choice of
transform depends on the nature of the process characteristics under study.
Choosing the “correct” model
A key challenge in identiﬁcation is to select the “correct” type of model. The fact is that the notion
of a “right” model is only idealistic. We are practically interested in obtaining a useful and working
model. Four primary factors govern its choice and development, namely,
i. End-use: This is a signiﬁcant factor in determining the nature, structure and accuracy of the
model to be developed. The entire identiﬁcation exercise may be tailored to suit a particular
application. Control-relevant identiﬁcation is a paradigm based on this philosophy. Models meant
to be used in control are expected to have good predictive abilities in only frequency regimes
where control is eﬀective. Moreover, the controller design and model development can be jointly
performed.
ii. Estimation considerations: When two or more structures are equally likely candidates, the ease
of estimation is a deciding factor. Auto-regressive models, for instance, result in linear predictors
whereas moving average models produce non-linear predictors (see Chapters 9 and 18). There-
fore, in time-series modeling, auto-regressive models are favored from an estimation complexity
viewpoint. Linear predictors with least squares criteria produce unique parameter estimates. We
had discussed this somewhat in detail in Chapter 2.
iii. Model simplicity: Given that any model is only an abstraction of the process, models that are
simpler are always preferable. This is also the principle of parsimony. Parsimonious and simpler
models are convenient from both estimation and implementation viewpoints.
iv. Physical meaningfulness: Several applications demand that models are physically meaningful,
particularly that the model structure has some correspondence to the physics or biology of the
process. Grey-box modeling places maximum importance to this criterion.
It would not be an overemphasis to reiterate the role of data quality in selecting the “correct” model.
The ﬁnal model is heavily leveraged on the inputs that are used to excite the system and the noise
present in the system. Therefore, a preliminary examination of the data is always useful in obtaining
an idea of the “best” model that one may be able to ﬁt. For example, step response data cannot be
expected to be used to develop highly accurate models.

66
Principles of System Identiﬁcation: Theory and Practice
Deterministic
Contains(the(physics(or(
explicable(part(of(the(process
Physical)inputs
(Exogenous)
Stochastic
Shock)wave
(ﬁctitious,0random)
Contains(eﬀects(of(noise,(
unmeasured(disturbances,(etc.
Time:series(modelling(concepts(
are(used(to(build(these(models
Process)response
(Observed)
+
+
FIGURE 3.4
(SEE COLOR INSERT) Composite model from identiﬁcation.
3.2.2
MODELS FOR IDENTIFICATION
From the preceding discussion, it is clear that a plethora of models are possible for a given system
depending on the assumptions and characteristics we wish to describe. In this text, however, we shall
focus on the development of discrete-time, linear, time-invariant, dynamic, single-scale models. To
keep the description short, we refer to these models as linear time-invariant (LTI) models. At this
point it is also clear that the overall model of interest is a deterministic-plus-stochastic model. Figure
3.4 shows a schematic of the overall model that we aim to develop.
An important advantage of choosing LTI descriptions is that a large class of stochastic eﬀects can
be also modeled as response of an LTI system driven by a ﬁctitious random signal. This ﬁctitious
signal can be treated as a shock wave like signal as illustrated in Figure 3.4. Chapter 9 presents the
theoretical details and derivations pertaining to the stochastic modeling.
The forthcoming Chapter 4 lays the foundations for mathematical descriptions of discrete-time
LTI deterministic processes.
REVIEW QUESTIONS
R3.1. Deﬁne the term model.
R3.2. What is the basis for model classiﬁcation?
R3.3. Identify three key merits of ﬁrst-principles and empirical models.
R3.4. What classes of models does system identiﬁcation generally result in?
R3.5. Describe the diﬀerences between a deterministic and a stochastic model.
R3.6. What are lumped parameter models? For what class of processes are they suited?
R3.7. What are the considerations for selecting a model class?
R3.8. Explain the justiﬁcation for assuming linearity and time-invariance. Does this hold for all pro-
cesses?
R3.9. Where does grey-box model get its name from?
R3.10. Identify the key diﬀerence between non-parametric and parametric models.
R3.11. What are transform domain models and how can they be useful?

Mathematical Descriptions of Processes: Models
67
EXERCISES
E3.1. Give two examples of distributed parameter models.
E3.2. Classify the systems (i) y[k] = u[k2] and (ii) y[k] = sign(u[n −2]) and (iii) y[k] = sin(u[k]) as
one of causal/non-causal, time-varying/time-invariant, static/dynamic and linear/non-linear.
E3.3. Processes are, in general, non-linear. Quite often we work with models that are linear approxi-
mations using a technique known as linearization, which constructs a ﬁrst-order Taylor’s series ap-
proximation of the non-linear model around a steady-state. A non-linear dynamic conical liquid-level
system is governed by the diﬀerential equation,
dV (t)
dt
= Fi (t) −Cv
p
h(t)
(3.8)
where V (t) = 1
3 πr2(t)h(t) is the volume of the liquid in the conical tank, Cv is the valve coeﬃcient,
h(t) and Fi (t) are the liquid level and inlet ﬂow rate, respectively. Given the semi-angle θ = 30deg,
steady-state inlet ﬂow Fi,s = 2 l/min and Cv = 0.8 units, do the following:
a. Determine the steady-state level hs.
b. Construct an approximate linear ODE for the deviation variable ˜h(t) = h(t) −hs in terms of
˜F(t) = Fi (t) −Fs through the linearization of the non-linear ODE.
c. Using the approximate linear model, discuss how Cv and θ inﬂuence the liquid level response
to a perturbation in the steady-state when Fi (t) is held ﬁxed at its steady-state.
E3.4. The linear ODE obtained in E3.3. is continuous-time in nature. Develop two diﬀerent approximate
discretized models, i.e., diﬀerence equation models, for the linear system using the techniques of
numerical integration, namely, the Euler’s backward and forward diﬀerencing methods.

4
Models for Discrete-Time LTI Systems
This chapter presents a self-contained review of the models for discrete-time, linear time-
invariant systems. The reader is recommended to pay particular attention to the identiﬁcation
viewpoints of each model structure. The material in this chapter is essential for understanding
the remainder of this textbook.
In Chapter 3, we learnt the deﬁnition of a linear time-invariant (LTI) system. To recap, an LTI
system satisﬁes two important properties:
i. Superposition: A linear combination of inputs produce the same linear combination of the re-
spective outputs.
ii. Time-invariance: Input delayed (or shifted) by a time T produces the same output as the original
input, but shifted by the same amount of time.
These two properties are central to the derivation of the diﬀerent model forms that one can write
for an LTI system. Fundamental to all these forms is the convolution equation model.
4.1
CONVOLUTION MODEL
The discrete-time convolution equation is given by
y[k] =
∞
X
n=−∞
g[n]u[k −n] =
∞
X
n=−∞
g[k −n]u[n]
(4.1)
Interpretation: The output of an LTI system at any instant is a inﬁnite sum of weighted past,
present and future inputs.
The weights {g[n]} are known as the impulse response (IR) coeﬃcients of the system
We ﬁrst discuss how the convolution equation results as a fundamental description. Any arbi-
trary discrete-time signal u[k] can be expressed as a weighted combination of shifted discrete-time
impulses
u[k] =
∞
X
n=−∞
u[n]δ[k −n]
(4.2)
where δ[k] is the Kronecker delta function,
δ[k] =
( 1,
k = 0
0,
k , 0
k
δ[k]
1
0
1
2
3
4
-1
-2
-3
-4
-5
5
68

Models for Discrete-Time LTI Systems
69
G
δ[k]
g[k]
FIGURE 4.1
Impulse response of an LTI system.
Denote the response of the LTI system to the impulse input δ[k] by g[k] as shown in Figure 4.1.
The LTI system is denoted by G. Each term of Equation (4.2) produces an output u[n]g[k −n] by
virtue of the linearity and time-invariance properties of an LTI system.
Invoking the linearity property, the output is a superposition of the individual outputs as illus-
trated in Figure 4.2. Equation (4.1) then follows.
u[k]
u[-­‐2]δ[k	  +	  2]
u[-­‐1]δ[k	  +	  1]
u[0]δ[k	  -­‐	  0]
u[1]δ[k	  -­‐	  1]
u[2]δ[k	  -­‐	  2]
...
...
G
G
G
G
G
u[-­‐2]g[k	  +	  2]
u[-­‐1]g[k	  +	  1]
u[0]g[k	  +	  0]
u[1]g[k	  -­‐	  1]
u[2]g[k	  -­‐	  2]
y[k]
FIGURE 4.2
Schematic depicting the derivation of a convolution operation.
4.1.1
IMPULSE RESPONSE
The name impulse response model is used synonymously with the convolution equation model.
An important observation is that for an LTI system, merely knowing the impulse response g[k] is
suﬃcient to predict the response of the system G to an arbitrary input. Additionally, several key
properties of the LTI system (e.g., stability, causality) can be easily inferred by an analysis of its IR
coeﬃcients. A few useful facts are discussed below in this context.
A few useful facts
a. Knowing the IR coeﬃcients, one can compute the response of a system to an arbitrary input.
Example 4.1: Compute Response to an Arbitrary Input Using the IR
Compute the response of a system whose impulse response is
g[k] =

(0.5)k−1
k ≥0
0
k ≤0
(4.3)
to a unit step input u[k] = 1,k ≥0.
Solution: Denoting the response by ys[k] and using Equation (4.1),
ys[k] =
∞
X
n=−∞
g[n]u[k −n] =
k
X
n=1
(0.5)n−1
(4.4)
= 1 −0.5k−
k ≥1
(4.5)

70
Principles of System Identiﬁcation: Theory and Practice
−4
−2
0
2
4
6
8
10
12
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
Samples
Amplitude
(a) MA(3) ﬁlter in Example 4.2
−4
−2
0
2
4
6
8
10
12
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Samples
Amplitude
(b) First-order system in Example 4.4
FIGURE 4.3
Impulse responses of diﬀerent systems.
The response ys[k] is also known as the step response of the system, which is discussed in
§4.2.2.
b. The IR determines the causality and stability properties of the system.
Deﬁnition 4.1. An input-output system is said to be causal if and only if the output at the present
instant does not depend on a future input. A strictly causal system excludes the possibility of the
instantaneous eﬀect of the input.
From the deﬁnition of impulse response and (4.1), it follows that
A system is said to be causal if and only if
g[k] = 0,
∀k < 0
(4.6)
Strict causality additionally requires g[0] = 0. Essentially, a causal system only responds earliest
when the impulse has been applied.
Most of the real world systems generally obey the causality principle. In identiﬁcation and data
analysis, physical engineering systems are causal. However, the mathematical operations on data
can be non-causal. A large class of ﬁltering methods belong to this category.
Example 4.2: Moving Average Filter
A moving average (MA) ﬁlter of the form
yf [k] = α−1y[k −1] + α0y[k] + α1y[k + 1]
is often used to smooth measurements {y[k]} (alleviate noisy content) prior to any identi-
ﬁcation or control exercise.
This MA ﬁlter is non-causal because the output of the ﬁlter depends on a future value of
the measurement. Smoothing ﬁlters are often implemented oﬀ-line for this reason.
The impulse response of the MA ﬁlter with α−1 = 0.3,α0 = 0.4,α1 = 0.3 is shown in Figure
4.3(a). Observe that the non-zero impulse responses are the coeﬃcients {αi}s themselves.
Models developed from data should be causal for them to be physically meaningful and to be
able to use them in real-time for online predictions. To reﬂect this requirement, the convolution
model in (4.1) is modiﬁed to
y[k] =
∞
X
n=0
g[n]u[k −n] =
k
X
n=−∞
g[k −n]u[n]
(4.7)

Models for Discrete-Time LTI Systems
71
c. The nature of process dynamics, i.e., “slow” or “fast” dynamics can be inferred by an exam-
ination of the plot of IR coeﬃcients.
The decay of the IR coeﬃcients is a reﬂection of the dynamics of the process.
Example 4.3: A Causal First-Order Process
A causal ﬁrst-order process has an impulse response of the form
g[k] =

b(−a)k,
k ≥0
0,
k < 0
b,a ∈R, |a| < 1
When |a| ≪1 (pole closer to the origin), the process has fast dynamics and settles quickly.
In which case, the IR coeﬃcients have a fast decay. On the other hand, when |a| ≈1,
the process takes much larger times to settle and is said to exhibit integrating eﬀects.
Integrating processes essentially act like storage devices (e.g., capacitors) and exhibit very
slow to marginally unstable dynamics. The impulse response of such a process has a very
slow decay.
An important fallout of the foregoing discussion is that the IR coeﬃcients oﬀer insights into the
stability of a system, which is one of its most important characteristics.
Two notions of stability exist: (i) asymptotic (a.k.a internal) stability and (ii) bounded-input,
bounded-output (BIBO) (a.k.a external) stability. While the former corresponds to the free re-
sponse (zero-input) case and concerned with the response of internal variables, i.e., states, the
latter corresponds to the forced response case, where the output behavior is of concern. Ex-
cept under some special conditions (unstable pole-zero cancellations), both forms of stability are
identical (see Exercise E4.3.).
For LTI systems, BIBO stability is deﬁned as follows:
An LTI system is said to be BIBO stable if all bounded-inputs yield bounded-outputs
|y[k]| ≤My,
My < ∞
∀|u[k]| ≤Mu,
Mu < ∞
(4.8)
The IR of an unstable process essentially runs away with time (unbounded). The standard result
relating BIBO stability to the IR follows from the convolution model (4.1).
Any LTI system is BIBO stable if and only if the impulse response is absolutely conver-
gent (see Franklin, Powell and Workman (1998) for a proof)
∞
X
k=−∞
|g[k]| < ∞
(4.9)
Remarks:
- Absolute convergence of g[k] implies that impulse response should decay at large times, i.e., g[k] −→
0 as k −→∞.
- Condition (4.9) is same for continuous-time systems with the summation replaced by an integral.
- When the system is marginally stable, the impulse response does not decay to zero, but either settles
to a non-zero, bounded value or oscillates perennially.
Example 4.4: A Strictly Causal and Stable First-Order Process
The system described by
g[k] =

b(−a)k−1,
k ≥1
0,
k ≤0
(4.10)

72
Principles of System Identiﬁcation: Theory and Practice
where a,b ∈R, is stable for all values of |a| < 1.
Figure 4.3(b) shows the impulse response of this system.
Models for stable systems should also possess stability. To ensure that an empirical model satis-
ﬁes this requirement, it is necessary to explicitly impose this constraint. Several classical iden-
tiﬁcation algorithms do not, however, impose such a constraint. In such cases, it is important to
test the predictions of the model for stability.
d. Delay in the input-output produces a shift in the impulse response.
This is a widely applied properties of the IR sequence in the estimation of input-output delay. For
a system with time-delay D samples, the IR shifts to the right by the same amount; consequently,
the ﬁrst D IR coeﬃcients are identically zero, i.e., g[k] = 0,k ≤D. The strictly causal ﬁrst-order
process of Example 4.4 has a delay of D = 1 sample, while the causal process of Example 4.3
has D = 0, i.e., no input-output delay.
Estimation of delay is a critical step in model development, design of robustly stable control sys-
tems and accuracy of fault diagnostic schemes. In the non-ideal world, the measured / estimated
D impulse response coeﬃcients take on “small” values due to the presence of noise. In prac-
tice, IR coeﬃcients are estimated from input-output data using a cross-correlation analysis (see
Chapter 20) and tested for statistical signiﬁcance. The relevant technical details are presented in
Chapter 20.
4.2
RESPONSE MODELS
Convolution equation models oﬀer a very good framework for theoretical analysis of LTI systems.
From a practical viewpoint, however, it is convenient to work with a response-based description.
These models have two main advantages: (i) process characteristics can be easily extracted and (ii)
they are nicely amenable to estimation from experiments.
Theoretically, one could develop a myriad of response models corresponding to diﬀerent inputs
and still be able to predict the response to other inputs. However, it is suﬃcient to restrict the set
to three elementary inputs, namely, (i) impulse, (ii) step and (iii) sinusoidal inputs. This section is
devoted to a review of these widely used elementary response models while oﬀering identiﬁcation
viewpoints.
The ﬁrst among these, the impulse response model was presented in §4.1.1. Below we study a
practically implementable and useful modiﬁcation of the IR model for stable systems, wherein the
inﬁnite summation is truncated to a ﬁnite one. This modiﬁcation is motivated by the fact that it is
impractical to identify inﬁnite IR coeﬃcients of the convolution model (4.1) from data.
4.2.1
FINITE IMPULSE RESPONSE (FIR) MODEL
For stable systems, g[k] →0 as k →∞. Practically, it is safe therefore to assume
g[k] ≈0, ∀k > M
M ∈Z+
(4.11)
i.e., the impulse response to be negligible after M sampling instants. Consequently, the inﬁnitely
long convolution in (4.7) can be restricted to contain ﬁnite terms,
y[k] =
M
X
n=0
g[n]u[k −n]
M ∈Z+
(4.12)
The description in (4.12) is known as the ﬁnite-impulse reponse (FIR) model since the output is
described by a ﬁnite set of IR coeﬃcients. The length of the FIR model, M, is a user-speciﬁed pa-

Models for Discrete-Time LTI Systems
73
rameter since it varies with the system and the sampling rate. At a ﬁxed sampling interval, processes
with shorter settling times require smaller values of M.
FIR models are very popular in industrial applications for the following reasons:
i. They have a simple structure and are easy to estimate (see Chapter 20). FIR models are non-
parametric in nature (at a later stage we shall show that they also belong to the class of parametric
models). Consequently, the FIR model requires minimal speciﬁcations from the user’s side.
ii. These models can be used even in situations where the output is infrequently available relative
to the model inputs (explanatory variables). This is the case of multirate sampling, which arises
whenever certain variables are sampled slower or non-uniformly relative to other variables. Com-
mon examples are compositions in distillation columns, molecular weight of polymers, ﬁneness
of cement.
iii. If the model inputs u[.] are user-designed inputs, then they are free of error. This gives an added
advantage from an estimation viewpoint. Computation of theoretical properties and standard
errors of estimates of g[.] is much simpler than otherwise (see Chapter 13).
iv. The parameters of the model are physically meaningful. Directly one obtains the IR characteris-
tics of the system.
v. Delay estimate is easily obtained from a plot of g[.] (estimate thereof). This is a classical and
widely used method for delay estimation (detailed in §22.5).
FIR models also have their limitations. They cannot eﬀectively model systems that have long-
memory or integrating processes. These systems are characterized by very slowly decaying co-
eﬃcients, thereby leaning towards an inﬁnite (large number of) impulse response coeﬃcient de-
scription.
4.2.2
STEP RESPONSE MODEL
The FIR model directly reveals the response of the process to impulse-like inputs. However, more
commonly, variations in process variables inputs and disturbances exhibit step-like changes. Fur-
thermore, as we shall see shortly, it is much easier to read-oﬀseveral vital process characteristics
such as gain and time-constant from step response rather than from impulse response coeﬃcients.
Owing to this fact, it is preferable to work with step response models than impulse response models
in several control applications.
It should be noted that both step and impulse response representations theoretically contain the
same information and are inter-convertible. The preference for one model over the other essentially
depends on the convenience with which a set of desirable process characteristics can be read-oﬀor
inferred from the model.
The step response description is obtained by ﬁrst striking a relationship with the impulse response
description. Beginning with the convolution equation in (4.1) or (4.7) and noting that the unit step
is
u[k] =

1,
k ≥0
0,
k < 0
(4.13)
we obtain
ys[k] =
k
X
n=0
g[n]
(4.14)
Thus, the step response at any instant is the cumulative (running) sum of the IR coeﬃcients up to
that instant. Problem 4.1 may be recalled in this context. The unit step and the typical response of a
ﬁrst-order system is sketched in Figure 4.4. Response to step of a diﬀerent magnitude is simply the

74
Principles of System Identiﬁcation: Theory and Practice
FIGURE 4.4
Typical step response of a ﬁrst-order LTI system.
scaled response of the unit step response.
An alternative way of writing (4.14) is
g[k] = ys[k] −ys[k −1]
(4.15)
The IR coeﬃcient is the diﬀerence between two successive step response coeﬃcients.
Relationships (4.14) and (4.15) are not surprising given that the inputs themselves enjoy similar
relations.
Characteristics of step response
The step response displays key process characteristics that are useful in several applications. Intro-
ductory texts on control and linear systems theory elaborate this aspect in great detail. Here we only
review the salient ones.
i. Gain (Kp): It is deﬁned as the total change achieved in the output per change in the input when
the input moves from one steady-state condition to another steady-state. This is also known as
the D.C. Gain.
(D.C.) Gain = △y
△u
steady-state
(4.16)
The preﬁx D.C. is used to distinguish it from the A.C. Gain that stems from the frequency re-
sponse function of an LTI system. Knowledge of the magnitude and sign of gain is critical to
controller design and several other applications.
ii. Time-constant (τp): The deﬁnition is based on the step response of a continuous-time ﬁrst-order
process. The time-constant is deﬁned as the time taken for the response of a continuous ﬁrst-
order system to reach 63.2% of its steady-state value, based on the fact that the step-response of
a ﬁrst-order continuous-time system is,
ys(t) = Kp(1 −e−t/τp )
(4.17)
Similar deﬁnitions for discrete-time systems can also be provided. A time-constant also deter-
mines the so-called bandwidth of a system, which plays a critical role in signal processing and
identiﬁcation.
Higher-order continuous-time systems are characterized by multiple time-constants with as many
as the order. Several scenarios are possible for theese system. A second-order system, for in-
stance, can have two repeated time-constants. For systems with underdamped behavior (complex
poles), the notion of natural frequency (which is the inverse of time-constant) is used. Multiscale
systems are characterized by time-constants that diﬀer by at least an order. For overdamped sys-
tems, i.e., systems with real poles, the time-constants are the absolute inverse of the poles or the
eigenvalues (see transfer function and state-space descriptions below). Regardless of the nature
of the system, the largest time-constant governs the settling time of the system.
To determine the time-constant (of the c.t. process) from the discrete-time response, it is neces-
sary to know the sampling interval of the system (read Chapter 6 for details). On the other hand,
the sampling rate itself is governed by the time-constant of the process.

Models for Discrete-Time LTI Systems
75
iii. Delay: We came across this quantity earlier as well. Delays are of diﬀerent types, input-output
delay, input-state delay (encountered in state-space descriptions), measurement delay, apparent
delay and so on. The most commonly encountered one is the input-output delay, which is deﬁned
as the time taken for the system to respond to an input change for the ﬁrst time. In a strict sense,
the delay characteristics of a system are not related to its dynamics. However, apparent delays,
which result due to approximations of higher-order systems by lower-order models, depend on
the system dynamics. Section 22.5 elaborates on these points and also presents a few widely used
methods of delay estimation.
To summarize, the delay captures the initial characteristics of the response, time-constant charac-
terizes the transient portion while the gain quantiﬁes the overall change at steady-state. For under-
damped systems, a few other characterizing quantities such as overshoot, decay ratio, etc. are used.
Classical texts on process control discuss these characteristics in greater detail. See Stephanopoulos
(1984) and Seborg, Edgar and Mellichamp (2003) for example.
Next, we study a more generalized and widely used response function, namely, the frequency
response function.
4.2.3
FREQUENCY RESPONSE MODEL
The frequency response description is perhaps the most versatile and useful representation of an
LTI system. It is based on the response to a sinusoidal input thereby giving it the name frequency
response function (FRF).
The theoretical FRF is constructed by evaluating the response of an LTI system to a sine wave of
frequency ω.
For mathematical convenience, we will instead consider a complex exponential u[k] = Auejωk.
Using the convolution equation in (4.7), the response of the LTI system can be computed as:
y[k] =
∞
X
n=0
g[n]u[k −n] = A
∞
X
n=0
g[n]ejω(k−n)
= Au
∞
X
n=0
g[n]e−jωnejωk
= AuG(ejω)ejωk
(4.18)
where
G(ejω) =
∞
X
n=0
g[n]e−jωn
(4.19)
is the frequency response function of the LTI system.
From (4.19), the FRF is the discrete-time Fourier transform (refer to Chapter 10) of the impulse
response function. Thus, the frequency response function is a representation of the LTI system in
the transform domain. Observe the distinction that unlike the impulse and step response, the FRF
is complex.
FRF quantiﬁes how an LTI system responds to inputs of diﬀerent frequencies. The utility of
FRF in identiﬁcation is immense in both experimental design and theoretical analysis of model
estimation algorithms as we shall discuss shortly and in relevant sections of the text.
By re-writing (4.18) using the polar representation of G(ejω), we obtain a fundamental result in
linear systems theory:
y[k] = Au|G(ejω)|e(jωk+∠G(jω))
(4.20)
which can be summarized as

76
Principles of System Identiﬁcation: Theory and Practice
The (steady-state) response of an LTI system to a sinusoidal input is also sinusoidal with
the same frequency (as the input), but with a diﬀerent amplitude and phase.
Steady-state (stability) requirement
The steady-state requirement is necessary in the deﬁnition of FRF because during the transient pe-
riod the system’s characteristics ride on the sinusoidal input and therefore has a diﬀerent frequency
content. The mathematical viewpoint is that the result in (4.18) takes into account the entire duration
of the impulse response from start to steady-state (if it exists).
Existence of steady-state implicitly assumes that the system is stable. This condition coincides
with that for the Fourier transform in (4.19) to exist, which is that the impulse response should have
a ﬁnite 1-norm (see Chapter 10). The 1-norm convergence is identical to the absolute convergence
requirement for a system to be BIBO stable.
Bode plots
The amplitude ratio (AR) and phase shift can be deﬁned from (4.19) and (4.20), as
AR(ω) = Ay
Au
= |G(ejω)|;
φ(ω) = φy −φu = ∠G(ejω)
Both the AR and phase shift are functions of the input frequency ω. A collective plot of magnitude
ratio and phase shift (vs. frequency) are known as Bode plots1.
The AR is usually expressed in decibel2 (dB) using the conversion
dB = 20 log10 AR
Thus, a drop/jump in the AR by a factor of 10 corresponds to a drop/jump of 20 in dB.
Phase, on the other hand, could be expressed in radians or degrees. Units of frequency are either
in angular frequency (rad/time) or in cyclic frequency, (cycles/time, 2π rad. = 1 cycle). Traditionally
Bode plots are drawn with the frequency axis on a log-scale so as to highlight the low-frequency
characteristics, which is the regime of interest for many processes.
Properties of FRF
In the analysis of FRF, three properties of FRF are useful:
i. Periodicity: The FRF is periodic with fundamental period 2π, meaning
G(ej(ω+2πl)) = G(ejω),
l ∈Z
(4.21)
The periodicity property follows from the deﬁnition (4.19). Note that this fact does not hold for
continuous-time systems. The property (4.21) of the discrete-time FRFs is due to the periodicity
of discrete-time complex exponentials appearing in (4.19). It can also be attributed to sampling
(see Chapter 6).
ii. Conjugate symmetry: The FRF satisﬁes
G(ejω) = G⋆(e−jω)
The property can be veriﬁed from (4.19).
1Named after Hendrik Alfred Bode who popularized their use.
2In honor of Alexander Graham Bell.

Models for Discrete-Time LTI Systems
77
iii. Magnitude symmetry: This property follows from the conjugate symmetry property.
|G(ejω)| = |G(e−jω)|
(4.22)
iv. Phase anti-symmetry: Again, this is a corollary of conjugate symmetry.
∠G(ejω) = −∠G(e−jω)
(4.23)
v. Sum-of-series property: The dB value and phase of a system comprising two linear sub-systems
in series are respectively the sum of the individual dB values and phases. Mathematically, if
G(ejω) = G1(ejω)G2(ejω)
then,
dBG = dBG1 + dBG2
(4.24)
φG = φG1 + φG2
(4.25)
Consequent to the ﬁrst four properties discussed above, Bode plots for discrete-time FRFs are re-
stricted to ω ∈[0,π], one half of the fundamental frequency range.
Example 4.5: FRF of a First-Order System
Compute the FRF of the ﬁrst-order system in Problem 4.1 and draw the Bode plot.
Solution: The FRF of the system is obtained using (4.19)
G(ejω) =
∞
X
n=0
g[n]e−jωn =
∞
X
n=1
b(−a)n−1e−jωn = b
e−jω
1 + ae−jω
Thus an input of frequency ω is ampliﬁed/attenuated and phase shifted according to
|G(ejω)| =
|b|
√
1 + a2 + 2a cos ω
;
φ(ω) = −ω −arctan
 −a sin ω
1 + a cos ω
!
The Bode plot for the system with b = 1,a = −0.5 is shown in Figure 4.5. Observe how
the AR drops oﬀat higher frequencies. When a broad-frequency input is used, the system
predominantly allows only low-frequency components to go through. Systems like these are
known as low-pass ﬁlters.
It is instructive to study the Bode diagram of a pure delay system since delays are commonly
encountered in several processes. Moreover, it aids in understanding the approximations that result
when higher-order systems are approximated as lower-order plus delay models (refer to §22.5).
Example 4.6: FRF of a Pure-Delay System
Compute the FRF of a pure-delay system
y[k] = u[k −D]
D ∈Z+
and sketch its Bode plot.
Solution: Observe that the pure-delay system has a unit impulse response
g[k] =

0,
k < D
1,
k = D
0,
k > D
(4.26)

78
Principles of System Identiﬁcation: Theory and Practice
10
−2
10
−1
10
0
10
1
−4
−2
0
2
4
6
8
Frequency (rad/sample)
Magnitude (dB)
Magnitude plot of a first−order system
(a) Magnitude (Amplitude Ratio) response
10
−2
10
−1
10
0
10
1
−180
−160
−140
−120
−100
−80
−60
−40
−20
0
Phase plot of a first−order d.t. system
Frequency (rad/sample)
Phase (deg.)
(b) Phase response
FIGURE 4.5
Bode plots for the ﬁrst-order system in Example 4.5.
−1
−0.5
0
0.5
1
Magnitude (dB)
0.5
1
1.5
2
2.5
3
3.5
4
−8
−6
−4
−2
0
Phase (rad)
Bode diagram of a pure−delay system
Frequency  (rad/sec)
FIGURE 4.6
Bode plot for the pure delay system of Example 4.6 with D = 2.
By deﬁnition then, the FRF of the pure-delay system is
G(ejω) =
∞
X
n=0
g[n]e−jωn = e−jDω
Thus an input of frequency ω will only experience a phase shift (lag) of Dω without any
change in its amplitude.
|G(ejω)| = 1;
φ(ω) = −Dω
(4.27)
Systems with these characteristics are known as all-pass ﬁlters since all frequency compo-
nents are allowed to go through with equal preference.
The Bode plot for the pure delay system in Problem 4.6 is shown in Figure 4.6. For easy reference
to the theoretical answers, the frequency axis is drawn on a linear scale. The reader can easily verify
that the magnitude of slope of the phase is indeed the delay, D = 2.
Bode plots for higher-order systems
Bode diagrams for higher-order systems are constructed by ﬁrst breaking the higher-order system
into elementary sub-systems (ﬁrst-order system, second-order system and pure delay system) and
using properties (4.24) together with (4.25) (Dorf and Bishop, 2010; Stephanopoulos, 1984).

Models for Discrete-Time LTI Systems
79
Use of FRF in identiﬁcation
Knowing the ﬁltering characteristics is vital to identiﬁcation in at least three diﬀerent respects:
i. Input design: The knowledge of FRF tells us what type of inputs should be used for exciting
the system in identiﬁcation experiments. Inputs should contain frequencies in the bandwidth of
the system and such that the SNR is high. Recall Problem 2.2 which illustrated the connections
between identiﬁability and the frequency content of the input.
Undoubtedly the input design is a tricky problem since it would not be possible to estimate the
FRF without performing the experiment, which itself cannot be optimally conducted without a
good knowledge of FRF. To break this imbroglio, an iterative procedure is usually adopted. A
preliminary set of experiments with step-type inputs are conducted to obtain a rough estimate
of the bandwidth, which is then used to reﬁne the frequency content of the input. Chapter 22
discusses these ideas in greater detail.
ii. Model selection: Analysis in the frequency domain reveals how models of diﬀerent structures
and/or estimation algorithms approximate the transfer function of a system. The connections and
contrasts between estimates of diﬀerent parametric model structures are nicely brought out by
a frequency-domain interpretation of the estimation problem. Section 21.5 presents the familiar
result on how diﬀerent parametric models estimate the same transfer function with diﬀerent
accuracies with a least-squares method.
iii. Pre-ﬁltering: The frequency-domain characterization also assists us in designing appropriate
pre-ﬁlters for achieving a certain bias (modelling error) distribution. Pre-ﬁlters essentially aid
in noise reduction and in placing importance to speciﬁc frequency ranges during identiﬁcation.
Section 22.4.3 elucidates the relevant ideas.
The remainder of the material on the characteristics of FRF and its ﬁnite-sample version (known
as empirical transfer function) are discussed separately in Chapter 5. The same chapter also presents
the generalized z-transform based transfer function.
We now study an alternative, modern and a powerful time-domain representation of the LTI
system.
4.3
DIFFERENCE EQUATION FORM
Continuous-time dynamic systems are governed by diﬀerential equations. It is natural that discrete-
time dynamics are governed by diﬀerence equations or recursive relations. In contrast to the convo-
lution form (4.1) where the output is purely a function of past input changes, the diﬀerence equation
attributes the changes in the present output to past outputs as well.
4.3.1
MOTIVATING REMARKS
The convolution equation is considered as a suitable starting point for describing LTI systems in
one school of thought; on the other hand, the diﬀerence equation form is also considered to be an
equally suitable and natural starting point in another school of thought. Rightfully so, because dy-
namics and diﬀerence (diﬀerential) equations are somewhat synonymous. Several growth (or decay)
models in population studies, economics and other ﬁelds are naturally described by recursive rela-
tions. Furthermore, mathematical analysis of sampled-data systems (see Chapter 6), i.e., discretized
continuous-time systems result in diﬀerence equations as the natural approximations of diﬀerential
equations. Notwithstanding these facts, the freedom available in an identiﬁcation exercise calls for
a critical understanding and comparison of the convolution and diﬀerence equation choices.
In this section, we ﬁrst study diﬀerence equation forms for discrete-time LTI systems, their con-
nections with the convolution form followed by a contrast of these forms in the identiﬁcation con-
text.

80
Principles of System Identiﬁcation: Theory and Practice
Although the forms have contrasting philosophies, interestingly they share a strong connection.
Diﬀerence equations naturally arise when impulse response (or for that matter other responses)
is parametrized, i.e., a functional form is imposed on the IR sequence. Consequently, diﬀerence
equations forms are also known as parametric models of LTI systems.
Several standard texts on sampled-data systems and digital control present diﬀerence equation
forms as approximations of diﬀerential equations. We deviate from this approach here and show that
diﬀerence equations arise naturally when discrete-time responses are parametrized. One of the prime
objectives is to highlight the connections between convolution and diﬀerence forms. This is useful
for identiﬁcation because it enables the reader to discern the diﬀerences between non-parametric
and parametric forms which ultimately prove to be useful in model selection and development. In
fact, these connections are valid for continuous-time systems as well. We shall, however, also review
the standard approach in the context of sampled-data systems (in Chapter 6) to show how diﬀerence
equations result as a consequence of discretization.
4.3.2
PARAMETRIZATION OF IMPULSE RESPONSE
Consider the situation of ﬁtting the convolution model (4.1) or (4.7) to a given input-output data.
A solution is the FIR approximation (4.12). An alternative is to assume a functional form for the
impulse response such as the one in Example 4.4,
g[k] =

b(−a)k−1,
k > 0
0,
k ≤0
(4.28)
where a,b ∈R.
The knowledge (known or assumed) of the structure (parametrization) of the IR coeﬃcients can
be incorporated at the estimation stage by solving a constrained optimization problem. An easier
approach is to re-write the input-output relationship in terms of the parameters of interest with
the basic objective of optimizing the parameters instead of the response coeﬃcients (as in non-
parametric models).
Following the latter approach, the convolution equation in (4.7) can be procedurally simpliﬁed
as follows:
kth instant:
y[k] =
k
X
n=0
g[k −n]u[n] =
k−1
X
n=0
b(−a)k−n−1u[n]
(4.29)
(k −1)th instant:
y[k −1] =
k−2
X
n=0
b(−a)k−n−2u[n]
(4.30)
Multiplying (4.30) with (−a) and subtracting it from (4.29) yields
y[k] + ay[k −1] = bu[k −1], k ≥1,
y[0] = 0
(4.31)
where the initial condition is the consequence of strict causality. Equation (4.31) is termed as a
diﬀerence equation of ﬁrst-order.
Thus, the convolution relationship translates to the diﬀerence equation (in (4.31)) under the
parametrization (4.28).
Remarks:
From an identiﬁcation and modeling viewpoint, parametrization is attractive because (i) it signiﬁ-
cantly reduces the burden of estimation relative to the M unknowns that have to be estimated in an FIR model,
and (ii) there is no need to truncate the model as we did in the FIR model. These beneﬁts come at a cost, which
shall be discussed shortly.
Extending the idea of ﬁtting a parametrized model to a general LTI system leads to the following
result:

Models for Discrete-Time LTI Systems
81
Any causal LTI system, in general, can be described by the diﬀerence equation:
y[k] + a1y[k −1] + · · · + ana y[k −na] = b0u[k] + b1u[k −1] + · · · + bnbu[k −nb]
(4.32)
The result can be of course extended to include non-causal systems as well. The qualitative statement
is that
The output of any LTI system can be expressed as weighted sum of ﬁnite number of
past inputs and outputs.
The diﬀerence equation in (4.32) is said to be of order na and input memory length nb. When an
input-output delay of D samples exists, the ﬁrst term of the RHS in (4.32) is bDu[k −D].
Order
The term order above refers to the extent to which the output is directly inﬂuenced by its own past
while allowing for any input eﬀects.
For the motivating example above, the output at any instant is directly dependent only on the
immediate past output in addition to the input at previous instant. Thus, it is a ﬁrst-order system.
In essence, the term order describes the (natural) characteristics of the system just as it does for
continuous-time dynamic systems.
Observe that to set up the diﬀerence equation form for an LTI system, the user must specify:
i. Order (na): Number of past outputs (system’s memory).
ii. Delay (D): The ﬁrst input in the past that aﬀects the output.
iii. Input memory (nb): No. of past inputs that aﬀect the output.
Remarks:
Other elementary responses (e.g., step and frequency) can also be parametrized in a similar manner
as above. Even in such cases, one can simplify the respective models with a parametric model.
In the following section, we learn a compact way of writing the diﬀerence equation using the
shift operator.
4.3.3
TRANSFER FUNCTION OPERATOR
We ﬁrst introduce the shift operator.
Shift operator
The backward shift operator, denoted by q−1, when applied to a sample or a sequence results in the
sample or sequence shifted by one sampling interval.
q−1y[k] = y[k −1] =⇒q−Ly[k] = y[k −L]
(4.33)
A forward shift operator naturally acts in the reverse way. Note that the shift operator is not a
multiplier! (the order of operation cannot be changed).
The diﬀerence equation in (4.32) can be now re-written in terms of q−1,
(1 + a1q−1 + · · · + anaq−na )y[k] = (b0 + b1q−1 + · · · + bnb q−nb )u[k]
Introducing the operator,
G(q−1) = b0 + b1q−1 + · · · + bnb q−nb
1 + a1q−1 + · · · + anaq−na = B(q−1)
A(q−1)
(4.34)

82
Principles of System Identiﬁcation: Theory and Practice
the diﬀerence equation can be compactly written as
y[k] = G(q−1)u[k]
(4.35)
Since G(q−1) governs how the input is “transferred” to the output it acquires the name transfer
function operator. It should not be confused with the more popular transfer function G(z−1), which
is a function of complex variable z, although both play similar roles.
Remarks:
As with q−1, G(q−1) is an operator and not a multiplier. The transfer function operator is a ratio
of two polynomial operators. Further, G(q−1) can be written in terms of forward shift operator as well.
Example 4.7: Difference Equation to Transfer Function Operator Form
Consider the diﬀerence equation
y[k] −1.2y[k −1] + 0.32y[k −2] = u[k −1] + 0.8u[k −2]
The transfer operator representation for this system is given by
G(q−1) =
1 + 0.8q−1
1 −1.2q−1 + 0.32q−2
In terms of the forward-shift operator, the transfer function is
G(q) =
q + 0.8
q2 −1.2q + 0.32
Remarks:
The transfer function in terms of q−1 is useful for reverting to the diﬀerence equation form while
that in terms of the forward shift q is useful for analyzing the system’s characteristics.
Parametrization
The mapping of convolution form to diﬀerence equation form is unique for a given parametrization.
Speciﬁcally,
a. Corresponding to a diﬀerence equation, there always exists a parametrization of the impulse
response
b. A parametrization of the IR always produces a single diﬀerence equation.
To determine the corresponding parametrization for a given diﬀerence equation, three methods can
be used: (i) the classical method of solving diﬀerence equation using characteristic roots (see below),
(ii) the shift-operator method (to be described shortly) or (iii) the z-transform method (see Chapter
5). These are indeed also the methods that are widely used to solve diﬀerence equations.
Having established the connections between these two forms, we contrast their merits and de-
merits.
Difference equation vs. convolution forms
Table 4.1 summarizes the contrasting aspects. The two most distinguishing aspects that deserve
special attention are: (i) the necessity of specifying a structure a priori (or not) (ii) the physical
meaning of the parameters (or the lack thereof) between the two forms. The last point of Table
4.1 is subtly placed in favor of diﬀerence equations since non-zero initial conditions are usually
speciﬁed in terms of response rather than in terms of the input. If the case is the latter, then both
forms are evenly placed.

Models for Discrete-Time LTI Systems
83
TABLE 4.1
Comparison of difference and convolution forms
Diﬀerence equation form
Convolution form
Output
is
expressed
as
a
weighted sum of past outputs and
inputs
Output
is
expressed
as
a
weighted sum of past inputs only
Model has a speciﬁc structure -
order, delay and input memory
Only the assumption of LTI is
suﬃcient.
Parameters do not directly reﬂect
the system’s characteristics
Coeﬃcients directly reﬂect sys-
tem’s characteristics
Model is usually characterized
by a few parameters
Model usually requires a larger
set of coeﬃcients
Initial conditions of a system can
be easily incorporated
No explicit provision for accom-
modating non-zero initial condi-
tions
In comparing these two forms, an important point to keep in mind is that convolution equation
forms arise purely in the context of describing forced responses whereas diﬀerence equations de-
scribe the dynamics without any speciﬁc reference to the source of dynamics, i.e., whether it is
forced or natural or a mix of both.
The question is then, what is a good starting point in identiﬁcation? In the absence of any a priori
knowledge and when the system prior to the experiment was at steady-state, usually one begins with
the convolution form (since it requires least a priori user speciﬁcations). Subsequently the diﬀerence
equation form is constructed due to its parsimonious and closer-to-reality representation. Moreover,
an advantage of starting with the convolution form is that it provides a reasonably accurate estimate
of delay and good process insights that prove to be very useful in ﬁtting a diﬀerence equation form. If
the system is at unsteady-state even at the beginning of the identiﬁcation experiment, then it becomes
necessary to estimate the non-zero initial conditions along with the model. In such situations, the
diﬀerence equation and the state-space forms (see §4.4) are strongly recommended.
In closing, two interesting facts may be noted:
i. The diﬀerence equation form of ﬁnite order always corresponds to an inﬁnite impulse response
(IIR) representation
ii. The FIR model is a special case of the diﬀerence equation form involving only past inputs,
i.e., {ai} = 0
iii. Where it is required to consider non-zero initial conditions, the diﬀerence equation description
is preferable to the FIR model.
For reasons obvious now, (inﬁnite IR) convolution models are termed as non-parametric models,
whereas diﬀerence equations are treated as parametric models. The FIR model belongs to both
classes.
By a long division of G(q−1) we can derive the corresponding convolution form for a given
diﬀerence equation, from where one can possibly determine the underlying parametrization.
Example 4.8: Difference to Convolution Form
Consider a ﬁrst-order system: y[k] −0.6y[k −1] = 2u[k −1]
k ≥0.

84
Principles of System Identiﬁcation: Theory and Practice
Then,
y[k] =
2q−1
1 −0.6q−1 u[k] = 2q−1(1 −0.6q−1)−1u[k]
= 2(q−1 + 0.6q−2 + 0.36q−3 + 0.216q−3 + · · · )u[k]
=⇒y[k] =
∞
X
n=1
2(−0.6)n−1u[k −n]
Thus,
g[k] =

2(−0.6)k−1,
k ≥1
0,
k = 0
Example 4.8 above illustrates the point made earlier, diﬀerence equations correspond to systems
with inﬁnitely long impulse response.
Now, let’s use the idea to solve an exercise concerning a second-order system.
Example 4.9: Computing IR from DE Form
An LTI system is described by the diﬀerence equation
y[k] −1.2y[k −1] + 0.35y[k −2] = 2u[k −1],
k ≥0
Determine the impulse response of the system.
Solution: First construct the transfer function operator for this system
G(q−1) =
2q−1
1 −1.2q−1 + 0.35q−2
Collecting the coeﬃcients of increasing powers of q−1 from the long division of G(q−1), one
obtains the IR sequence
g[0] = 0; g[1] = 2; g[2] = 2.4; g[3] = 2.18; · · ·
Observe that the ﬁrst IR coeﬃcient is zero due to unit input-output delay.
4.3.4
STABILITY AND POLES
In §4.1.1 we deﬁned BIBO stability. The deﬁnition was in the context of forced response. For linear
systems, stability is a property of the system, i.e., not dependent on the operating conditions. There-
fore linear stability is usually discussed with respect to free response. Termed as the asymptotic
stability, it basically examines the response to non-zero initial conditions (revisited in §4.4).
Deﬁnition 4.2. A linear system is asymptotically stable if and only if
lim
k→∞y[k] →0
∀y[0] , 0
(4.36)
As remarked earlier, asymptotic stability and BIBO stability requirements are identical for linear
systems, unless under some peculiar conditions apply3.
3We shall at a later stage, in Deﬁnition 4.5, review a more widely used deﬁnition based on state-space models.

Models for Discrete-Time LTI Systems
85
The free response of systems described by the diﬀerence equation in (4.32) is given by its homo-
geneous solution, which is governed by the characteristic equation.
The characteristic polynomial for a general diﬀerence equation is obtained by ﬁrst plugging in
y[k] = λk into (4.32) while setting the input u[k] = 0,
λk + a1λk−1 + · · · + ana λk−na = 0
λk−na (λna + a1λna−1 + a2λna−2 + · · · + ana ) = 0
The C.E. is then
λna + a1λna−1 + a2λna−2 + · · · + ana = 0
(4.37)
The LHS is also the denominator of G(q) with the forward shift operator replaced by λ. It is also
said to be the C.E. of G(q) or G(q−1). The roots of (4.37) are also known as poles of the system
(see Chapter 5).
Depending on the nature of roots, the homogeneous solution takes diﬀerent forms. The roots
could be real or complex and/or repeated. For the simplest case of distinct real roots, the form of the
solution is
yfree[k] =
na
X
i=1
αipk
i
(4.38)
where pi are the roots of (4.37) and constants {αi}na
i=1 are determined using initial conditions.
For repeated roots the form of the solution diﬀers from above but still involves the powers of
roots, pk
i . Thus the roots of the characteristic equation or poles play a critical role in the free re-
sponse.
Stability requires y[k] →0, which in turn requires all poles to be of less than unity in magnitude
|pi| < 1, ∀i
(Stability requirement)
(4.39)
The system of Problem 4.9 has two poles located at p1,2 = 0.7,0.5 implying that the system is
stable.
The continuous-time counterpart is that the real part of all poles of the continuous-time system
should be strictly negative.
For the sake of completeness, we brieﬂy discuss the total response. The total response of a linear
system can be expressed as a sum of free (natural) and forced response.
y[k] = yfree[k] + yf orced[k]
= Homogeneous solution + Particular solution
Standard texts on linear systems theory cover this material extensively. We highlight only the
principal points here.
The particular solution depends on the input type. In general. for overdamped systems, the cur-
vature of the response is largely inﬂuenced by that of the input. For example, if the input is an
impulse, the particular solution is in the form of an impulse or a pulse, a step input produces a step
shape in the output and so on. A generalized method of determining the response of an LTI system
consists of using z-transforms, which is taken up in the next chapter. We shall observe there that the
particular solution is also largely governed by the roots of the characteristic equation. In fact, the
impulse response has a form similar to (4.38) thereby facilitating connections between asymptotic
stability and BIBO stability requirements. For the system of Problem 4.9, the IR turns out to be
(using the method of z-transforms),
g[k] =

7(0.7)k−1 −5(0.5)k−1,
k ≥1
0,
k = 0

86
Principles of System Identiﬁcation: Theory and Practice
The reader may obtain the impulse response by solving the diﬀerence equation by hand and verify
the same with the results above.
To summarize the key points made in this section, diﬀerence equations oﬀer a realistic way of
representing LTI systems and are also appealing from an estimation viewpoint due to their parsi-
mony. However, to build empirical models of these forms the user is required to specify or make
suitable guesses of delay, order and input memory length which is by no means a trivial task. In this
respect convolution models are the natural initial candidates and also provide the necessary insights
and knowledge for seeding the diﬀerence equation models. Not only does this discussion apply to
continuous-time systems but also to a large class of stochastic processes as we shall learn in Chapter
9.
In the following section, we discuss a more versatile and powerful time-domain representation
of the LTI system known as the state-space representation.
4.4
STATE-SPACE DESCRIPTIONS
The state-space representation is based on a radically diﬀerent approach to modeling. The approach
rests on the notion of states, which could be thought as either tangible or abstract (artiﬁcial or ﬁcti-
tious) or as unobserved variables, but they are essentially those set of variables that characterize the
dynamics of a system. The state-space framework is considered modern and has several advantages
over the classical input-output framework. However, it also comes with its own set of liabilities as
we shall learn.
4.4.1
BACKGROUND
Although branded as “modern,” the use of the term “state” in mathematics and systems theory has
been long in practice. In calculus, introducing artiﬁcial variables (which are also states) to break up
higher-order diﬀerential equations is a standard trick. The term state is also used frequently with
its implicit meaning when referring to the steady-state of a process. On informal terms, day-to-day
life phrases such as “state of mind,” “physical state” also connote state as something that character-
izes the associated system. However, for mathematical modeling one requires a more precise and
quantitative deﬁnition of a state.
First-principles modeling naturally gives rise to state-space representations. In data-driven anal-
ysis these models gained momentum with the landmark work of Kalman and co-workers (Kalman,
1960; Kalman and Bucy, 1961) that introduced the Kalman ﬁlter. Today, it is is one of the most
widely used ﬁlters in data-driven applications. The results also propelled the growth of (i) optimal
(or modern) control theory, a branch of control theory that advocates state-feedback (or state esti-
mation) algorithms to optimally control processes and (ii) state estimation, an important branch of
estimation with far-reaching applications. Numerous applications of state-space representations in
control and state estimation have since been reported (references).
The progress in the area of state estimation, in turn, motivated the development of state-space
models of physical systems from data. Identiﬁcation of state-space models involves an additional
degree of complexity in that (as we shall learn in Chapter 23) it requires both the estimates of the
states as well as the state-space model. The subspace identiﬁcation algorithms are a collection of
excellent algorithms based on linear algebra that estimate states and model parameters simultane-
ously (Overschee and Moor, 1996). These algorithms opened doors to novel ways of implementing
Kalman ﬁlters and provided the powerhouse to model multivariable systems.
Kalman’s seminal ideas and several modern control algorithms are mainly developed on (approx-
imate) linear state-space models. Linear state-space models of suﬃciently high-order are known to
be capable of modeling a large class of industrial processes (see Favoreel, Moor and Overschee
(2000) for instance). Linear subspace identiﬁcation algorithms by themselves present considerable
learning challenges. Non-linear subspace identiﬁcation is yet to mature both theoretically as well as

Models for Discrete-Time LTI Systems
87
in practice. With this justiﬁcation, we shall, as with the case of linear input-output models, conﬁne
ourselves in this text to linear state-space models.
Several excellent texts and articles on state-space models in identiﬁcation have been written to-
date (see Qin (2006) and the references therein, Overschee and Moor (1996), Katayama (2005)).
The objective of this section is to enlighten the reader on the fundamental concepts, study diﬀerent
deterministic discrete-time state-space forms and highlight features relevant to identiﬁcation. In
Chapter 5 we review the connections between state-space and transfer-function forms. State-space
models that incorporate stochastic eﬀects and the actual know-how of subspace identiﬁcation are
detailed in Chapter 23. The reader may ﬁnd it also beneﬁcial to read some well-known texts on
deterministic state-space models (e.g., Brogan (1991)) .
4.4.2
STATE VARIABLE
Pivotal to the development of a state-space representation is a proper understanding of the term
state, for which no rigorous or single deﬁnition exists. A widely prevalent description of the term
state is provided below (Kailath, 1980).
A state at a given instant is that minimally suﬃcient variable or “statistic,” which quantiﬁes the
consolidated eﬀect of the past inputs / conditions of the system and contains all the necessary
information to compute the future response of a system.
It literally quantiﬁes the state of the process at that given time. When the transients of the system
have vanished, it is said to be at a steady-state, i.e., the states no longer change with time.
Mathematical deﬁnitions vary with the context in which they are introduced. In the discussions to
follow, an attempt is made to capture and condense the prevalent deﬁnitions with a uniﬁed deﬁnition
and supplement it with a few qualifying statements. Three motivational examples are presented ﬁrst.
State-space models have been traditionally introduced in the context of ﬁrst-principles modeling.
The ﬁrst example is therefore justiﬁably along these lines.
Example 4.10: States of a First-Principles Model
Consider a continuous-stirred tank reactor (CSTR) of ﬁxed volume V carrying out a ﬁrst-
order4 irreversible reaction
A
k1
→B
where k1 is the associated kinetic rate constant.
Assuming the inlet ﬂow stream contains only the reactant A, the equations describing the
concentration of the product B (in continuous-time) are given by
dcA
dt
= F
V cAi −(k1cA)
(4.40a)
dcB
dt
= −F
V cB + (k1cA)
(4.40b)
where cAi is the inlet concentration of reactant A.
Thus, to describe variations in cB (due to changes in cAi), two diﬀerential equations
corresponding to cA and cB are required. Then, we say that the system with input cAi and
output cB is characterized by two states,
x = [cA
cB]T
Observe that only (4.40a), i.e., a single state x = cA is suﬃcient to describe if only cA is the
variable of interest.
4The term order in reaction kinetics should be distinguished from the order in systems theory.

88
Principles of System Identiﬁcation: Theory and Practice
From a ﬁrst-principles modeling viewpoint therefore, states are dynamic physical variables that
characterize the system (subsystem) of interest.
Next, we illustrate an example that represents the prime application of state-space models in
estimation problems. This is the classic problem of estimating unobserved variables from measure-
ments, which appears in diﬀerent contexts: (i) the variable of interest is diﬃcult to measure online
and therefore a secondary variable is measured or (ii) a sensor has to be calibrated or (iii) a soft
sensor has to be developed and so on. The ﬁrst situation is quite common; in distillation columns
where composition cannot be measured directly on-line (at least as frequent as other measurements)
but temperature is used to estimate the composition, while in the cement industry, the cement ﬁne-
ness is inferred from other measurements. Numerous other examples can be found in other ﬁelds of
engineering and sciences.
Example 4.11: Unobserved or Hidden Variables
A ﬁrst-order discrete-time deterministic LTI system is described by
x[k] = −a1x[k −1] + b1u[k −1]
Suppose that x[k] (say, composition) cannot be measured, but instead a related variable y[k]
(say, temperature) can be measured.
Taking the measurement errors (stochastic) into account and assuming a linear algebraic
relationship between the measured variable and the unobserved variable, we can write
y[k] = c1x[k] + wy[k]
where wy[k] is the random measurement error in y[k].
The unobserved variable(s) x[k] are termed as states in this context.
The dynamics of the measurement y[k] are then governed by
x[k + 1] = −a1x[k] + b1u[k]
(4.41a)
y[k] = c1x[k] + wy[k]
(4.41b)
which are called the state and output equations, respectively.
Note that the states can be eliminated from the above equations to produce the usual
input-output equation. The purpose of retaining them is to be able to estimate them from
error-corrupted known(s) given the knowledge of a1, b1, c1 and the statistical properties of
wy[.] (state estimation problem).
Identiﬁcation of state-space models is concerned with estimating both the states as well as the model
parameters a1, b1 and c1, which is obviously more intriguing than a regular state estimation problem.
A main challenge faced in this context is that it is a non-linear estimation problem. Consequently,
there are multiple combinations of states and model parameters that can describe the same system.
We learn two facts from the preceding example: (i) states are unobserved or hidden variables in
an estimation problem and (ii) in empirical modelling, the choice of states is not unique.
The concept of states can also be generalized to include parameters in a general estimation prob-
lem. After all, parameters are also hidden quantities and estimated from measurements.
It should be noted that non-uniqueness of states is not merely limited to the realms of empirical
modelling. In general, mathematically no state-space model is unique unless restrictions exist on
model parameters.
Now we turn to the classical example of a state-space model that emerges from breaking up
a higher-order diﬀerence equation into a set of ﬁrst-order diﬀerence equations. This example also
serves as a means of illustrating converting diﬀerence equation forms and transfer function operator
forms to state-space forms.

Models for Discrete-Time LTI Systems
89
Example 4.12: Decomposition of a Higher-Order System
A second-order discrete-time LTI system is described by
y[k] = −a1y[k −1] −a2y[k −2] + b1u[k −1]
(4.42a)
=⇒G(q−1) =
q−1
1 + a1q−1 + a2q−2 =
q−1
(1 −p1q−1)(1 −p2q−2)
(4.42b)
Using the standard trick from calculus of assigning “internal” variables, we can decompose
(4.42a) into two ﬁrst-order diﬀerence equations. There are several possible ways of realizing
this task. One possible way is by assigning internal variables as shown in the block diagram
of Figure 4.7(a).
!"#
y[k]
!
u[k]
$#
"%#
"%&
!"#
x1[k]
x2[k]
(a) States are outputs of shift operators
u[k]
y[k]
!
x1[k]
x2[k]
k2q−1
1 −p2q−1
k1q−1
1 −p1q−1
(b) States are outputs of ﬁrst-order subsystems
FIGURE 4.7
Two diﬀerent ways of realizing a state-space representation.
Thus,
x1[k] = y[k]; x2[k] = y[k −1]
This gives rise to the following state-space representation:
"x1[k + 1]
x2[k + 1]
#
=
"−a1
−a2
1
0
# "x1[k]
x2[k]
#
+
"b1
0
#
u[k]
(4.43a)
y[k] =
f
1
0
g "x1[k]
x2[k]
#
(4.43b)
Another possible decomposition is the parallel one as shown in Figure 4.7(b), realized by a
suitable partial fraction expansion of G(q−1) in (4.42b).
G1(q−1) =
k1q−1
1 −p1q−1 ; G2(q−1) =
k2q−1
1 −p2q−1
k1,k2 ∈R
G(q−1) = G1(q−1) + G2(q−1)
Assigning the outputs of G1 and G2 as states,
x1[k] = y1[k]; x2[k] = y2[k]
we obtain a diﬀerent state-space representation:
"x1[k + 1]
x2[k + 1]
#
=
"p1
0
0
p2
# "x1[k]
x2[k]
#
+
"k1
k2
#
u[k]
(4.44a)
y[k] =
f
1
1
g "x1[k]
x2[k]
#
(4.44b)
where k1, k2 are the constants of partial fraction expansion and p1,p2 are the roots of de-
nominator of G(q−1).

90
Principles of System Identiﬁcation: Theory and Practice
In the preceding example, states are artiﬁcial variables introduced in the realization of a higher-
order system as imagined to be ﬁrst-order sub-systems either in series or parallel or in any other
combination.
Observe that in all the examples, states are outputs of ﬁrst-order systems that are possibly coupled
with each other.
Based on these examples and prior discussions, a state variable can be deﬁned as follows:
Deﬁnition 4.3. The states of a system are the outputs of a minimal set of (coupled or decou-
pled) ﬁrst-order elementary sub-systems (physical or virtual) that are required to describe the
dynamics of the system.
A few important remarks follow.
Remarks:
i. Depending on the method adopted for realizing the ﬁrst-order sub-systems, the states are either physical or
virtual variables.
ii. Mathematically, there are inﬁnitely diﬀerent ways of choosing the states just as they are inﬁnitely diﬀerent
ways of breaking up a higher-order system into a set of ﬁrst-order subsystems.
iii. Continuous-time state equations are ﬁrst-order diﬀerential equations, while discrete-time state equations
are ﬁrst-order diﬀerence equations.
iv. The output equations in both domains are always algebraic equations.
4.4.3
STATE-SPACE MODELS
We now study general discrete-time state-space representations and their features.
A general state-space model has the form
x[k + 1] = Adx[k] + Bdu[k]
(state equations)
y[k] = Cx[k] + Du[k]
(output equations)
(4.45a)
(4.45b)
where the subscripts on matrices A and B point to the discrete-time nature of the model
It is also customary to denote the LTI system in state-space form as
Gd =
" Ad
Bd
C
D
#
(4.46)
once again with the subscript on G referring to the discrete-time nature.
The continuous-time state space model is also similar to (4.45a)-(4.45b), but with ﬁrst-order
ordinary diﬀerential equations for the state:
˙x(t) = Acx(t) + Bcu(t)
(state equations)
(4.47)
˙y(t) = Cx(t) + Du(t)
(output equations)
(4.48)
Observe that the output equations remain identical in both domains since they are algebraic equa-
tions.
We shall soon drop the subscripts on the matrices and G with an understanding based on context.
This is also justiﬁed since most concepts apply to both discrete- and continuous-time forms.

Models for Discrete-Time LTI Systems
91
Interpreting the state-space model
The state equation describes the dynamic part of the process. It tells us how the input aﬀects the
internal quantities of a system. A few important observations to note:
- Each state equation is a ﬁrst-order strictly causal diﬀerence equation.
- State equations for systems at steady-state are purely algebraic.
- The number of states (in a minimal realization, see Deﬁnition 4.4 below) is the order of the
system.
- In control applications, the matrix A together with A determines the controllability, i.e., the
ability to take the process from the present state to a desired state.
The output equation is an algebraic equation. It could stand for a calibration equation or a primary-
secondary variable relationship. Regardless of the context, it is the key equation for inferring (ob-
serving) states from measurements.
- It quantiﬁes how the states aﬀect measurements y.
- The matrix C together with A determines the observability of states (see discussion on observ-
ability below).
- The matrix D quantiﬁes the direct eﬀect of the input (e.g., bypass or recycle) and is also known
as the feedthrough term.
- For input-output systems that are strictly causal, D = 0. This is usually the case for sampled-data
systems with a zero-order hold (read Chapter 6).
Only the matrix A is a square, while the remaining matrices are in general rectangular with appro-
priate dimensions.
Beneﬁts of a state-space model
A state-space representation has a few important modeling beneﬁts to oﬀer vis-a-vis a pure input-
output representation.
i. A state-space model oﬀers more physical insights into the process dynamics than the input-
output form. This is primarily because it explains the “internal” behavior of a process. Contrast
this with the input-output form which describes the process in a relatively “peripheral” manner.
The following example illustrates this point.
Example 4.13: Continuous-Tank Heater System (CSTH)
A CSTH consists of a continuous inlet (and outlet) ﬂow with a variable power heater coil
as the heat source. Temperature variations with respect to changes in inlet ﬂow (Fi) and
heat rate input ( ˙Q) are described by second-order dynamics, with the liquid level (h) and
temperature (To) as the states. The state-space representation would symbolically have
the following structure
˙x(t) =
"a11
0
a21
a22
#
x(t) +
"b11
0
b21
b22
#
u(t)
(4.49a)
y(t) =
f
0
1
g
x(t)
(4.49b)
where x = [h
To]T and y ≡T and u ≡[Fi
˙Q]T . Entries a22 and b22 are zero simply
because level changes are unaﬀected by changes in temperature and heat rate (unless
operating at ﬂash conditions). The same structure would apply to the discrete-time SS
model as well.

92
Principles of System Identiﬁcation: Theory and Practice
The input-output form is a second-order (non-linear) diﬀerential equation,
d2To
dt2 + a1
dTo
dt + a2To = f (To,Fi, ˙Q,t)
(4.50)
where f (.) is a non-linear function.
The SS model oﬀers deeper insights into the physics of the process. It describes two
facts: (i) changes in inlet ﬂow aﬀect the level and temperature simultaneously and (ii)
temperature variations occur due to changes in both the level (volume) and the input
heat (enthalpy). In comparison, the DE form merely enunciates second-order dynamics
for the temperature.
ii. A state-space model can reveal unstable mode cancellations with the inputs while the input-
output system is still stable. Again this a consequence of the preceding point. For unstable sys-
tems, the SS model can reveal the states that are internally unstable. These points extend to
control applications as well.
iii. The ability of state-space representations to handle multivariable systems is perhaps one of its
biggest positives. The prime consideration is that applications built on state-space representations
naturally accommodate both multivariable and single-input, single-output systems. Much of the
algebra involved assumes generic dimensions for the matrices A, B, C and D. With the input-
output models the situation is to the contrary. A signiﬁcant challenge is involved in extending
the controller design, identiﬁcation techniques for SISO to multivariable systems. Adding to this
point is the fact that the dynamics of a ny × nu multivariable process is collectively described by
a single matrix A, whereas the transfer function format requires mn transfer functions to express
the same dynamics. In this sense, state-space models provide technical elegance and convenience.
iv. From an identiﬁcation viewpoint, SS descriptions score over the input-output counterparts in two
respects, as mentioned in §1.2. The ﬁrst is that the algorithms employed for subspace identiﬁ-
cation are numerically more well-behaved than the iterative algorithms employed for estimating
transfer function models. Secondly, and perhaps more importantly, the SS framework facilitates
joint estimation and identiﬁcation problem, whereas the input-output framework can only allow
one to build a model between known variables but cannot estimate the “hidden” variables.
4.4.3.1
Forms of State-Space Representations
In Example 4.12 we observed how a given input-output system can possess two state-space descrip-
tions. The reality is that one can build inﬁnite state-space representations since states are internal
quantities and we can choose them in mathematically inﬁnitely diﬀerent ways as shown below.
Physically, of course, the possible choices for states are ﬁnite and determined by the governing rate
equations.
Consider the general state-space representation (4.46)
G =
" A
B
C
D
#
(4.51)
where we have dropped the subscripts for convenience.
Suppose it is desired to represent G in a new state space w,
x = Tw
(4.52)
where T is a non-singular similarity transformation matrix. Choosing a diﬀerent set of states essen-
tially amounts to rotating the existing set of states (or the coordinate space).
The state-space realization in the w space is obtained by combining (4.51) and (4.52),
G =
" ˜A
˜B
˜C
˜D
#
=
" T−1AT
T−1B
CT
D
#
(4.53)

Models for Discrete-Time LTI Systems
93
Observe that the feedthrough matrix remains invariant to choice of states, as is expected. The re-
alizations (A,B,C,D) and ( ˜A, ˜B, ˜C, ˜D) are similar since they are connected through a similarity
transformation T. Under this transformation, matrix properties such as eigenvalues are preserved.
There exist inﬁnite choices for T, leading to inﬁnite possible state-space representations for the
same system. This is both beneﬁcial and disadvantageous as discussed shortly.
Although there exist innumerable SS forms, we are usually interested in a few special canonical
forms (Kailath, 1980) such as the ones given below (for SISO systems):
i. Diagonal canonical form: The matrix A is diagonal meaning the state equations are decoupled.
A =

p1
0
· · ·
0
0
p2
· · ·
0
...
...
...
...
0
0
· · ·
pnx

(4.54)
where nx is the state-dimension of the system.
The diagonal entries of A in this form are the poles of the system.
ii. Observer canonical form: The matrices A and C have special structures.
A =

−a1
1
0
· · ·
0
...
...
...
...
−an−1
0
0
· · ·
1
−an
0
0
· · ·
0

;
C =
f
1
0
· · ·
0
g
whence B =

b1 −a1b0
...
bn−1 −an−1b0
bn −anb0

;
D = b0
(4.55)
where ais and bis are the coeﬃcients of DE (4.32) (or a diﬀerential equation).
For systems with ny > 1, the matrix C contains one non-zero entry per row and column.
This special form is useful for determining observability (by a joint examination of A and C). The
ability to re-write a given state-space realization into an observer canonical form is guaranteed
only if the corresponding similarity transformation matrix T exists. The existence of such a
transformation is, in turn, guaranteed only if the observability matrix (deﬁned later in (4.59)) is
of full rank. The canonical form derives its name hence.
iii. Observability canonical form: The state-space matrices of this form are given by
A =

0
1
· · ·
0
...
· · ·
...
...
0
0
· · ·
1
−an
−an−1
· · ·
−a1

;
C =
f
1
0
· · ·
0
g
B =

β1
β2
...
βn

=

1
0
· · ·
0
a1
1
· · ·
0
...
...
· · ·
...
an−1
an−2
· · ·
1

−1 
b1 −a1b0
...
bn−1 −an−1b0
bn −anb0

;
D = b0
(4.56)
iv. Controller canonical form: In this canonical form, the restrictions are on the structures of A

94
Principles of System Identiﬁcation: Theory and Practice
and B.
A =

−a1
· · ·
−an−1
−an
1
...
0
0
...
...
...
0
· · ·
1
0

;
B =

1
0
...
0
0

(4.57a)
whence C =
f
b1 −a1b0
· · ·
bn−1 −an−1b0
bn −anb0
g
;
D = b0
(4.57b)
where the symbols have their same meanings as before. For systems with nu > 1, matrix B has
one non-zero entry per input.
This form is useful for determining controllability (by a joint examination of A and B). As
in the case of observability, the feasibility of ﬁnding a non-singular transformation matrix T
that produces a controllable canonical form is connected to the rank of what is known as a
controllability matrix (see below). This also explains the name given to this form.
v. Controllability canonical form: The state-space matrices of this form are given by
A =

0
0
· · ·
−an
1
· · ·
0
−an−1
...
...
...
0
· · ·
1
−a1

;
B =

1
0
...
0
0

C =
f
β1
β2
· · ·
βn
g
=
f
b1 −a1b0
· · ·
bn −anb0
g

1
a1
a2
· · ·
an
0
1
a1
· · ·
an−1
...
...
...
...
...
0
0
0
· · ·
1

−1
;
D = b0
(4.58)
Remarks:
The observer and controller canonical forms, observability and controllability canonical
forms are dual pairs (transposes). In fact, the observability and controllability conditions as well as the
design of observer and controller problems are also, respectively, duals, of each other.
vi. Jordan canonical form: This canonical form is a generalization of the diagonal form to accom-
modate the repeated poles case. The result is that A has a block diagonal form.
Note: All state-space realizations have a permutation ambiguity about them, i.e., the rows and columns of the
matrices depend on the ordering of states.
Despite the multitude of possible realizations, all state-space models for a given system corre-
spond to the same input-output relationship.
Liabilities of state-space descriptions
Earlier we discussed the merits of using a SS form. But the SS descriptions are not without their
impediments as discussed below.
a. The most important criticism of state-space representations is that they are not unique. As we
observed above, inﬁnitely many choices of states exist for a single input-output system. This
is both a boon and a bane. In process simulation, one could choose diagonal form to simplify
computational matters. The controllable and observable canonical forms are advantageous in
control and estimation applications and so on.

Models for Discrete-Time LTI Systems
95
b. In identiﬁcation, however, the non-uniqueness of SS descriptions places certain limitations on
identiﬁed SS models. Empirical state-space models are identiﬁable only up to a state transforma-
tion, meaning the states are some arbitrary transformations of the underlying physical states that
describe the process. Thus, the states of identiﬁed SS models usually do not carry any physical
meaning. This is not desirable in many applications. A natural remedy to this diﬃculty is to in-
corporate constraints on the structures of state-space models in the identiﬁcation algorithm. This
is the idea underneath grey-box modeling approaches. Section 23.7.2 builds on this point.
c. The number of unknown to be estimated in an unstructured state-space model is usually much
larger than that of a corresponding input-output model. Suppose a third-order SISO system is to
be identiﬁed. A SS description consists of a total of 9 (of A) + 3 (of B) + 3 (of C) + 1 (of D) =
16 parameters, whereas a transfer function description would at most be characterized by 4 (3 in
the denominator plus 1 in the numerator) parameters. In fact this leads to loss of identiﬁability
issues in the state-space model which is the reason for the preceding point.
d. The issues in (b.) and (c.) can be alleviated by bringing in a priori knowledge of process dynam-
ics. Essentially the idea is to solve a grey-box identiﬁcation problem instead of a pure black-box
identiﬁcation problem. For instance, if a SS model of the CSTH in Example 4.13 is desired. The
state-space matrices of the empirical model can be constrained to exactly adhere to the known
structure. This idea not only brings in physical meaning to the states but also aids in parsimony
of parameters. In fact, the grey-box state-space model can be used to estimate certain physico-
chemical properties of the system when the functional relationship of the non-zero entries with
the physical parameters is known a priori.
e. A risk associated with state-space descriptions is the inclusion of more states than what is ac-
tually necessary causing loss of observability (and controllability). Therefore, it is important to
work with minimal realization descriptions without involving any cancellation of internally and
physically unstable modes.
f. Continuous-time SS models suﬀer from a shortcoming when describing systems with delays. De-
lays in continuous-time are inﬁnite-order systems resulting in inﬁnite-dimensional (state) repre-
sentations, which present mathematical challenges. On the contrary, discrete-time delay systems
are always of ﬁnite-order thus possessing ﬁnite-dimensional state-space descriptions.
The risks / shortcomings associated with state-space descriptions are generally far outweighed by
the beneﬁts they oﬀer, particularly in (i) multivariable identiﬁcation and (ii) joint estimation and
identiﬁcation. Owing to these reasons, state-space models have been increasingly used in several ap-
plications of systems engineering, historically in optimal control (Brogan, 1991; Dorf and Bishop,
2010) and more recently in identiﬁcation Favoreel, Moor and Overschee (2000) and Qin (2006).
These applications rely on the crucial concepts of observability and controllability. Among these,
the ﬁrst concept bears stronger relevance to identiﬁcation. It suﬃces to discuss the former consider-
ing the fact that the two concepts are duals of each other.
Observability
When the state variables x are physical variables, but not measured with a sensor, they are said to
be unobserved. Whether it is possible to estimate these unobserved variables or not from known
information (measurements and process model) is the problem of observability. Observability does
not refer the ability to measure, but to observe.
Observability is an important desirable property of the system to be identiﬁed. When a system
is partially observable, only that part of the system can be identiﬁed. For linear systems, the rank
of the observability matrix is the order of the system. This is one of the key properties on which all
subspace identiﬁcation and multivariable dynamic identiﬁcation methods are built.

96
Principles of System Identiﬁcation: Theory and Practice
The observability matrix Ono for a system of order no is deﬁned as
Ono =

C
CA
...
CAno−1

(4.59)
The observability matrix plays a vital role in state estimation and identiﬁcation. It basically de-
termines the ability to estimate (reconstruct) the initial conditions of a system x[0] (or x(0)) from
measurements and inputs over the duration k ≥0 (or t ≥0).
A fundamental result is that the rank of Ono is the order of a minimal realization state-space
description. In other words, a LTI system with representation (A, B,C, D) is called observable if the
associated observability matrix is of full rank. A sketchy proof of this result is outlined in Chapter
23 where the notion of extended observability matrix is also presented.
A state-controllable system is one for which one can always ﬁnd an input sequence that can drive
the states to a desired ﬁnal value. The controllability matrix determines whether a system possesses
this property. Based on the dual relationship, the controllability matrix Cnc is the transpose of Ono
and replacing C →B, AT →A. Thus, a system is controllable if its dual is observable.
Minimal realization and order
In the previous sections we used the terms realization and order frequently. Here we formally deﬁne
these terms. Although the deﬁnitions are provided for discrete-time systems, as with the rest of the
material, they equally apply to the continuous-time case.
Deﬁnition 4.4. The set of matrices (A,B,C,D) is said to be a realization of an input-output system
whose transfer function is G(z).
In Example 4.12, we derived two diﬀerent realizations (4.43a) and (4.43b) of a second-order
system.
In principle, one can construct inﬁnitely diﬀerent realizations for a given system. Furthermore,
the order of the state-space model can be greater than that of the input-output system if a proper
methodology is not adopted to convert from a TF to SS representation. From the viewpoint of
identiﬁcation (and control), only a minimal realization state-space model can be developed from
data.
A minimal realization of a system is that description of the system with states that can be both
observed and controlled. The following theorem due to Kalman formalizes the same.
Theorem 4.1
A realization (A,B,C,D) is minimal if and only if it is both observable and controllable.
The term minimal essentially refers to the minimum number of states that are required to describe
the input-output relationship after all the pole-zero cancellations. Systematic procedures are avail-
able for reducing non-minimal realizations to minimal ones (Brogan, 1991). A good understanding
of minimal realizations is necessary because of its importance in all state-space based applications.
Otherwise, one always runs into the risk of redundant states leading to unobservable and/or uncon-
trollable descriptions.
For a good overview of this topic and its relevance to systems theory, the reader is directed to
Schutter (2000).

Models for Discrete-Time LTI Systems
97
Representation of delays in state-space forms
Delays have a signiﬁcant impact on the order of the system. As mentioned earlier, time-delays
in continuous-time systems result in inﬁnite-order systems. For discrete-time systems, presence of
pure delays in the worst case manifest as additional states thereby causing only a ﬁnite increase in
the overall order of the system. The augmentation method is a standard trick to develop a standard
state-space model for a system augmented with pure delays.
Example 4.14: Augmentation Method to Incorporate Pure Delays
A second-order system is described by the state-space representation
x[k + 1] =
"
0
1
−0.24
1.1
#
x[k] +
" 2
−0.8
#
u[k];
y[k] =
f
1
0
g
x[k]
The transfer function operator of this system is given by
G(q−1) =
2q−1 −0.8q−2
1 −1.1q−1 + 0.24q−2
Suppose an additional pure delay of 2 samples is introduced in the input-output channel.
The SS representation of the new system is then obtained as follows.
First write the state-equation for the system with additional delay
x[k + 1] =
"
0
1
−0.24
1.1
#
x[k] +
" 2
−0.8
#
u[k −2]
Then, introduce two additional states, namely,
˜x1[k] = u[k −2];
˜x2[k] = u[k −1]
Now augment the old states with these additional states to obtain the SS model for the
delayed system:
"x[k + 1]
˜x[k + 1]
#
=

0
1
2
0
−0.24
1.1
−0.8
0
0
0
0
1
0
0
0
0

"x[k]
˜x[k]
#
+

0
0
0
1

u[k]
y[k] =
f
0
1
0
0
g "x[k]
˜x[k]
#
The reader may verify that this new representation is a minimal realization. Thus, the new system is
a fourth-order system.
The augmentation method in Example 4.14 should be used with care. Additional states should be
augmented to accommodate pure delays only when the additional delay truly results in an increase
in the number of poles. The need to augment is veriﬁed by writing the transfer function form of the
new system, as illustrated below with an example.
Example 4.15: Delays and Relative Degree of TF
Consider the transfer function
G(q−1) =
2q−1
1 −1.1q−1 + 0.24q−2

98
Principles of System Identiﬁcation: Theory and Practice
which has two poles located at p1,2 = 0.8,0.3.
A state-space model for this system is
x[k + 1] =
" 1.1
1
−0.24
0
#
x[k] +
"2
0
#
u[k]
y[k] =
f
1
0
g
x[k]
An additional pure delay in the input-output channel changes the TF operator to
G(q−1) =
2q−2
1 −1.1q−1 + 0.24q−2
The new system is still characterized by two poles. Therefore, additional states should not
be introduced to obtain an SS description for the new system.
In fact, by a direct inspection of the transfer function, we can write a state-space descrip-
tion for the new system:
x[k + 1] =
" 1.1
1
−0.24
0
#
x[k] +
"0
2
#
u[k]
y[k] =
f
1
0
g
x[k]
A blind implementation of the augmentation method would have resulted in a three-state
model, but one which is not a minimum realization.
Note: The reader should verify that indeed by applying the state augmentation method of Example 4.14 to
Example 4.15 one would obtain a non-minimal realization of the system.
Until this point we have learnt the concepts of state-space representations, merits, demerits and
certain technical concepts built on these representations. We shall now learn how to represent a
state-space representation in the transfer function operator (or the diﬀerence equation) form. This
exercise is useful in reinforcing certain concepts discussed in this section and in other ways that will
become clear in the later portions of the text.
4.4.4
STATE-SPACE ↔TRANSFER FUNCTION OPERATOR FORM
To convert a state-space representation to the transfer function operator form, we ﬁrst re-write the
state equations using the shift operator and subsequently substitute the states in the output equation.
The state equation can be written as:
qx[k] = Ax[k] + Bu[k]
=⇒x[k] = (qI −A)−1Bu[k]
(4.60)
Substituting the last equation into the output equation yields
y[k] = [C(qI −A)−1B + D]u[k]
(4.61)
Therefore the mapping from SS to transfer function operator is
G(q) = C(qI −A)−1B + D
(4.62)
A few important remarks are in order.

Models for Discrete-Time LTI Systems
99
Remarks:
i. The input-output relationship is invariant to transformation of states (as expected).
G(q) = CT(qI −T−1AT)−1T−1B + D
= C(qI −A)−1B + D
ii. Equation (4.62) also shows that a state-space representation for a given G(q) is non-linear in unknowns.
Thus, multiple solutions (for the matrices) exist; but in all those solutions, the feedthrough matrix D is
unique.
iii. For a given A and C, the choice of B and D is unique. This fact is exploited by most subspace identiﬁcation
algorithms.
The following example illustrates these concepts.
Example 4.16: SS to TF Representation
Find the transfer function operator equivalent representation of the d.t. system:
A =
" 1
−0.42
0.5
0
#
;
B =
"2
0
#
;
C =
f
1
−0.6
g
;
D = 0
(4.63)
Solution: Using (4.62), we obtain
G(q) =
(2q −0.6)
q2 −q + 0.21 =
2(q −0.3)
(q −0.7)(q −0.3)
Remarks:
Observe that the zero at z1 = 0.3 is exactly located at one of the poles p1 = 0.3 causing a zero-pole
cancellation. A loss of observability should therefore occur indeed as veriﬁed by the rank of the observability
matrix,
rank(O) = rank
 " 1
−0.6
0.7
−0.42
#!
= 1
Thus the observer realizes the system only as a ﬁrst-order,
G(q) =
2
z −0.7
OR
x[k + 1]
=
0.7x[k] + 2u[k]
y[k]
=
x[k]
which is a minimal realization of the SS model in (4.63).
Transfer function operator to state-space form
The reverse problem of representing an input-output form was illustrated in the motivational ex-
ample at the beginning of this section. Another example is taken up for reinforcing the underlying
ideas.
Example 4.17: TF to SS Representation
Find a SS realization of G(q−1) =
2 −0.8q−1
1 −1.1q−1 + 0.24q−2 .
Solution: First re-write the TF form as a diﬀerence equation form
y[k] −1.1y[k −1] + 0.24y[k −2] = 2u[k] −0.8u[k −1]

100
Principles of System Identiﬁcation: Theory and Practice
and then re-write the equation in a nested form using the q−1 operator
y[k] =
x1[k]
z                                                   }|                                                   {
q−1((1.1y[k] −0.8u[k]) −q−1(0.24y[k])
|            {z            }
x2[k]
) +2u[k]
Assigning the states as indicated above, we obtain the SS model
x[k + 1] =
"−1.1
0
0.24
1
#
x[k] +
" −3
−0.48
#
u[k]
(observer canonical form)
y[k] =
f
1
0
g
x[k] + 2u[k]
where x[k] =
f
x1[k]
x2[k]
gT
One could, of course, have written the above or other canonical forms by a direct inspection of
the diﬀerence equation based on the structures given in §4.4.3.1.
Solutions to state equations
The state-space model can be used to simulate the free response as well as the forced response of a
system. Given the initial conditions and the input proﬁle, one can compute the state at any instant
k > 0 as follows:
x[1] = Ax[0] + Bu[0]
x[2] = Ax[1] + Bu[1]
= A2x[0] + ABu[0] + Bu[1]
...
x[k] = Ak x[0] +
k−1
X
l=0
Ak−l−1Bu[l]
(4.64)
The output at any instant is therefore
y[k] = CAk x[0] + C
k−1
X
l=0
Ak−l−1Bu[l] + Du[k]
(4.65)
The matrix exponential in (4.64) can be computed by hand using the z-transform method:
Ak = Z−1{(I −Az−1)−1}
(4.66)
Equation (4.65) is useful in at least two diﬀerent ways. It suggests that the stability of the system
is related to the behavior of Ak, which is in turn dependent on the eigenvalues of A according
to (4.66). The result below corroborates our observations. Secondly, this is the starting point for
deriving observability conditions and a class of state-space identiﬁcation algorithms.
Stability
The deﬁnition of stability (asymptotic stability) in the state-space framework is based on the re-
sponse of states to non-zero initial conditions. Only the salient results are stated here. See Brogan
(1991) for a more detailed and rigorous analysis of stability.
Deﬁnition 4.5. A system represented by state-space matrices (A,B,C,D) is asymptotically stable if
and only if
x[k] →0 ∀x[0] , 0
(4.67)

Models for Discrete-Time LTI Systems
101
The stability requirement earlier in terms of poles of G(q) can be related to the eigenvalues of A
using (4.62).
The denominator of G(q) is the characteristic equation of A, for
G(q) = Cadj(qI −A)
det(qI −A) B + D
Consequently,
The poles of the system G are the eigenvalues of the state matrix A
Thus, the matrix A characterizes the stability and dynamics of the system. The standard result, that
is identical to the condition on the poles stated earlier for transfer function models, now follows.
A discrete-time LTI system represented by the state-space model (4.46) is stable if and only if
|λi(A)| < 1
∀i
(4.68)
Other characteristics such as time-constants, delay and gain can be also inferred from the SS de-
scription by converting them into the TF form.
4.5
ILLUSTRATIVE EXAMPLE IN MATLAB: ESTIMATING LTI MODELS
In this section, we oﬀer a quick preview of estimating diﬀerent time-domain models from input-
output data, while the full technical details associated with the estimation are presented in Chapters
20 through 23.
The main purpose is to demonstrate the use of the System Identiﬁcation Toolbox (MATLAB) for
estimating IR, step response and state-space models. Frequency response estimation is illustrated in
Chapter 5.
4.5.1
DATA GENERATION
The deterministic process used for demonstration in the transfer function form is:
G(q−1) = 0.6 −0.2q−1
1 −0.5q−1 q−1
(4.69)
which can also be written in the diﬀerence equation and the observability canonical forms as
yd[k] −0.5yd[k −1] = 0.6u[k −1] −0.2u[k −2]
(4.70)
and
x[k + 1] =
"0
1
0
0.5
#
x[k] +
"0.6
0.1
#
u[k]
(4.71a)
yd[k] =
f
1
0
g
x[k]
(4.71b)
where yd is the output of the deterministic process.
Observe that the diﬀerence equation in (4.70) is ﬁrst-order and yet two states are required to
describe the system. The extra state is required to model the eﬀects of the additional lagged input
u[k −2].

102
Principles of System Identiﬁcation: Theory and Practice
0
50
100
150
200
−2
−1
0
1
2
Output
0
50
100
150
200
−1
−0.5
0
0.5
1
Input
Samples
FIGURE 4.8
Snapshot of the input-output data.
Input signal and measurement noise
The process is excited with a pseudo-random binary signal of length N = 2555 (described later
in §22.3 while the measurement of the output is corrupted with a zero-mean, unit-variance, pure
random noise (white-noise) e[k] (similar to the one in Chapter 2). Thus, the input-output relationship
in the diﬀerence equation form is
y[k] = 0.6 −0.2q−1
1 −0.5q−1 q−1 + e[k]
(4.72)
In the state-space form, only the output equation in (4.71b) is modiﬁed to
y[k] = yd[k] + e[k]
(4.73)
The objective is to only estimate the deterministic part, i.e., G(q−1) in diﬀerent forms from the
input-output data. A snapshot of the input and measurement is shown in Figure 4.8.
In the estimation exercise below we shall assume that the delay is unknown. It is rather obtained
from the FIR model estimates, as is the common practice.
4.5.2
ESTIMATION OF FIR MODEL
FIR models can be estimated in two ways: (i) by the direct, but rudimentary, method of exciting
the system with an impulse input, (ii) by way of estimation from experimental data where a user-
designed input sequence is used. The latter method produces superior estimates because it is much
better equipped to handle measurement errors.
Figure 4.9 displays the ﬁrst nine coeﬃcients of a M = 20 coeﬃcient FIR model estimated
from the input-output data. The classical correlation analysis-based approach is used to estimate the
coeﬃcients. Observe that the estimates are fairly accurate (true values are shown as solid circles).
The dashed lines essentially serve as thresholds below which the estimate at any lag can be treated
as insigniﬁcant with a 1% risk.
In reality the true IR values are never known. The goodness of estimated FIR model is rather
tested using model assessment and evaluation methods.
4.5.3
ESTIMATION OF STEP-RESPONSE MODEL
As with impulse response models, empirical step-response models can be developed through two
diﬀerent routes: (i) collecting the response of the system to a step input or (ii) by way of estimation
from (user-designed) input-output data. We follow the latter approach.
The step response estimate is shown in Figure 4.10, from which the following information can
be extracted:

Models for Discrete-Time LTI Systems
103
0
1
2
3
4
5
6
7
8
9
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
Time (samples)
IR coefficient
 
 
Estimates
True
FIGURE 4.9
Impulse response estimates - dashed lines denote the signiﬁcance levels.
0
2
4
6
8
10
12
14
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Samples
Amplitude
 
 
Estimates
True
FIGURE 4.10
Estimates of step-response coeﬃcients
i. The gain of the system is approximately 0.8 units (theoretical value is 0.8)
ii. The delay of the system is 1 sample (true value is also 1 sample)
iii. System under study is stable and can be approximated as a ﬁrst-order behavior with time-constant
of 0.8 time units (sampling interval is 1 unit).
4.5.4
ESTIMATION OF DIFFERENCE EQUATION MODEL
Diﬀerence equation deterministic models can be estimated (or ﬁt) in diﬀerent ways. Least-squares
based regression techniques are standard in this regard. However, the problem becomes quite in-
tricate in the presence of stochastic eﬀects. Chapter 14 presents the widely used least squares and
maximum likelihood methods for parameter estimation. Applications of these techniques to the
diﬀerent parametric descriptions of Chapter 17 are presented in Chapter 21.
Estimated model
The steps outlined below are used to arrive at a suitable diﬀerence equation model.
i. The FIR model estimated in §4.2.1 suggests the delay as D = 1 sample.
ii. The step response estimate obtained in §4.2.2 does not indicate underdamped characteristics - so
it is safe to begin with a ﬁrst-order approximation.

104
Principles of System Identiﬁcation: Theory and Practice
Listing 4.1
MATLAB code for IR and SR estimation Figures 4.9 and 4.10
%% Create an IDPOLY object for the process
mod_p = idpoly(1,[0 0.6 -0.2], 1, 1, [1 -0.5],’Noisevariance’,1);
% Generate input and simulate the process
uk = idinput(1275,’prbs’,[0 1/5],[-1 1]);
xk = sim(mod_p,uk); mod_p.Noisevariance = var(xk)/10;
yk = sim(mod_p,uk,simOptions(’AddNoise’,true));
%% Collect the input-output data
Z = iddata(yk,uk,1); Ztrain = detrend(Z,0);
%% Estimate the impulse response
mod_fir = impulseest(detrend(Ztrain ,0));
[irest,kvec,~,sd_ir] = impulse(mod_fir ,10);
figure; stem(kvec,irest); hold on
plot(kvec,sd_ir,’k--’,kvec,-sd_ir,’g--’);
% Compute the true values and plot them
ir_act = filter([0 0.6 -0.2],[1 -0.5],[1 zeros(1,9)]);
stem((0:9),ir_act,’ro’,’filled’);
%% Compute step response estimates
[stepres ,kvec] = step(mod_fir ,15);
figure; plot(kvec,stepres ,’b-’); hold on
% Compute the true values and plot them
sr_act = filter([0 0.6 -0.2],[1 -0.5],ones(15,1));
plot((0:14),sr_act,’r--’);
plot((0:14),sr_act,’ro’,’MarkerFaceColor’,’red’);
iii. Starting with a ﬁrst-order, and input memory M = 1 and following the procedures outlined in
Chapters 21 and 22 (refer to the case study in Chapter 22), the following model results for the
deterministic part of the process:
x[k] −0.5368
(±0.028)x[k −1] = 0.5958
(±0.008)u[k −1] −0.2246
(±0.025)u[k −2]
(4.74)
The values reported underneath the estimated coeﬃcients are the standard errors in the estimates
(see Chapter 13). A comparison of the estimated model (4.74) with the true model (4.70) clearly
indicates that the method has not only delivered the correct structure but also good parameter esti-
mates. As mentioned previously, in practice, the goodness can only be assessed by a comparison of
predictions with the measurements, which is not shown here.
Finally, we demonstrate how to estimate a state-space model.
4.5.5
ESTIMATION OF A STATE-SPACE MODEL
The measurement y[k] is as before, constructed by corrupting the response with white noise of
variance adjusted to achieve SNR 10.
y[k] = yd[k] + e[k]
σ2
e ≈0.1σ2
yd
The task in hand is to estimate a state-space model from N = 2555 samples of input-output data.
Running the data through the systematic procedure outlined in Chapter 1 and using the subspace
identiﬁcation algorithm yields the following optimal state-space model for the deterministic part:
x[k + 1] =
"0.196
0.411
0.108
0.319
#
x[k] +
"0.023
0
#
u[k]
yd[k] =
f
25.582
−2.369
g
x[k]
(4.75)

Models for Discrete-Time LTI Systems
105
Listing 4.2
MATLAB code for DE model estimation example
% Create an IDPOLY object for the process
mod_p = idpoly(1,[0 0.6 -0.2],1,1,[1 -0.5],’Noisevariance’,1);
% Generate input and simulate the process
uk = idinput(2555,’prbs’,[0 0.2],[-1 1]);
xk = sim(mod_p,uk); mod_p.Noisevariance = var(xk)/10;
yk = sim(mod_p,uk,’Noise’);
% Collect the input-output data
dataset = iddata(yk,uk,1);
% Estimate the DE model of a specified order and delay
de_mod = oe(datatrain ,[2 1 1]);
present(de_mod)
20
40
60
80
100
120
140
160
180
200
−1
−0.5
0
0.5
1
1.5
Predictions of the free parametrized s.s. model
Samples
Amplitude
 
 
Measured
Gsshat; fit: 71.57%
FIGURE 4.11
Snapshot of predictions of the SS model (4.75) (measurements shown as dashed line).
The order estimate comes out correct, but the state-space matrices are signiﬁcantly diﬀerent from
the true ones (with the exception of D) in (4.71). This should be expected since the subspace iden-
tiﬁcation algorithm can only identify one of the innumerable possible second-order state-space re-
alizations.
The matrices identiﬁed in (4.75) are said to follow a free parametrization, meaning no con-
straints are imposed on the structure. In Chapter 23 it will become clear that for the case of free
parametrization, error bounds cannot be provided on the elements of the SS matrices due to identi-
ﬁability constraints. Thus, the acceptability of the model is only decided by comparing predictions
of (4.75) with the observations. Figure 4.11 shows a snapshot of the inﬁnite-step ahead predictions
(Chapter 18) from this model. The model has produced fairly good quality predictions. Further, the
realization of (4.75) is both observable and controllable. Thus, the model provides an acceptable
minimal realization description of the process.
Note: The goodness of ﬁt reported in the ﬁgure is the NRMS value deﬁned in (2.24a).
Estimating structured state-space models
In practice it is not possible to know the “true” structure of the matrices, however, a pre-determined
structure can be imposed. For illustration purposes, we impose the observability canonical structure.

106
Principles of System Identiﬁcation: Theory and Practice
The algorithm produces the estimates
A =

0
1
−0.02
(±0.046)
0.521
(±0.17)

;
B =

0.598
(±0.008)
0.108
(±0.01)

C =
f
1
0
g
D = 0
(4.76)
where the standard error of estimate in each entry is reported underneath each estimate. The standard
errors are useful in constructing conﬁdence intervals for the true values (see §13.12.2).
Observe that the nominal values of the identiﬁed matrices are in close agreement with the true
values in (4.71).
Both realizations (4.75) and (4.76) are equally acceptable models for the process. However, the
free parametrization requires estimation of 4 + 2 + 2 = 8 parameters whereas the canonical form
involved only 2 + 2 = 4 parameters. From an estimation viewpoint, clearly the latter is preferable.
Parsimonious representations of the same structure produce estimates with lower error.
One could further reduce the parameters to be estimated by considering the fact that the error in
the A(2,1) element of (4.76) is statistically insigniﬁcant (error is much larger than the estimate).
Thus, eﬀectively this parameter can be treated as zero. Re-estimating the matrices with this addi-
tional constraint produces:
A =

0
1
0
0.45
(±0.03)

;
B =

0.598
(±0.008)
0.106
(±0.01)

C =
f
1
0
g
D = 0
(4.77)
Comparison of (4.77) with (4.71) suggests that the estimates are fairly accurate. Further, observe
that the error in A(2,2) element is signiﬁcantly lower than that of (4.76). The reader may verify that
the estimated model is both observable and controllable. Thus, this is a minimal realization of the
underlying process.
The subspace algorithms employed for identifying free parametrized forms are presented in
Chapter 23. On the other hand, estimating the structured state-space models as in (4.76) and (4.77)
belongs to the category of grey-box modelling (discussed in §23.7.2).
Listing 4.3
MATLAB code for the estimation of SS model
% Create an IDPOLY object for the process
mod_p = idpoly(1,[0 0.6 -0.2],1,1,[1 -0.5],’Noisevariance’,1);
% Generate input and simulate the process
uk = idinput(2555,’prbs’,[0 0.2],[-1 1]);
xk = sim(mod_p,uk); mod_p.Noisevariance = var(xk)/10;
yk = sim(mod_p,uk,’Noise’);
% Collect the input-output data
dataset = iddata(yk,uk,1);
datatilde = detrend(dataset ,0);
% Estimate a freely parametrized state-space model
Gss_hat = pem(datatilde);
% Print the state-space model
present(Gss_hat)
% Compare predictions
figure; compare(datatilde ,Gss_hat);
% Fit an observability canonical form

Models for Discrete-Time LTI Systems
107
Gss_can = pem(datatilde ,’ssparameterization’,’canonical’);
present(Gss_can);
% Fit a structured state-space model
% Initialization
A = [0 1; 0 0.4]; B = [0.4 ; 0.3];
C = [1 0]; D = 0; K = [0 ; 0];
M = idss(A,B,C,D,K);
% Providing structural information
M.As = [0 1; 0 NaN]; M.Bs = [NaN ; NaN];
M.Cs = [1 0]; M.Ds = 0; M.Ks = [0 ; 0];
M.x0s = [0 ; 0];
% Estimating the structured model
Mhat = pem(datatilde ,M);
present(Mhat)
4.6
SUMMARY
In this chapter, we studied diﬀerent time-domain descriptions of linear time-invariant systems. The
convolution model and the response-based descriptions belong to the category of non-parametric
models, whereas the diﬀerence equation forms, transfer function operator and the state-space forms
belong to the class of parametric models. We also studied and critically compared the diﬀerent fea-
tures of these forms in the context of identiﬁcation. Non-parametric models hold signiﬁcant beneﬁts
over the parametric counterparts, but the latter provide parsimonious representations, which makes
them a preferred choice in several applications. Among the parametric models, the state-space de-
scriptions hold signiﬁcant advantages over the input-output counterparts, particularly for MIMO
systems and joint estimation-identiﬁcation problems. However, they are also liable to identiﬁability
and non-uniqueness issues.
The central message is as follows. While the diversity of descriptions brings enormous ﬂexibility
to the identiﬁcation problem, it also calls for a careful selection of model family given the trade-oﬀs
involved between the ease of estimation, user interventions and end-use requirements.
REVIEW QUESTIONS
R4.1. Explain why the convolution equation is a fundamental description of the LTI system.
R4.2. What is the motivation and justiﬁcation for an FIR model?
R4.3. Under what conditions on the LTI system’s response do we obtain a diﬀerence equation descrip-
tion?
R4.4. Explain the key diﬀerences between a diﬀerence equation and convolution form? When is each
of these forms preferred in identiﬁcation?
R4.5. Deﬁne the frequency response function and list a few of its possible uses. Under what conditions
(on the system) does it exist?
R4.6. Deﬁne asymptotic and BIBO stability. Are they diﬀerent conceptually?
R4.7. Describe what is meant by ’state” of a system?
R4.8. What are the prime advantages of state-space descriptions over transfer function models?
R4.9. Explain what is meant by minimal realization and the order of a system.
R4.10. Describe the popular canonical forms for state-space models and discuss their advantages.

108
Principles of System Identiﬁcation: Theory and Practice
R4.11. Describe the augmentation procedure for expressing state-space models with delays as standard
state-space forms.
EXERCISES
E4.1. A system is described by the following diﬀerence equation
y[n] = 1
2 (u[n] −u[n −2])
a. Write the transfer function representation of the above system.
b. Determine the zeros, poles and D.C. gain of the system.
c. Compute the steady-state response to the input signal,
u[n] = 5 + 3 cos( π
2 n + 60◦) + 4 sin(πn + 45◦).
d. What kind of a ﬁlter is the above system?
e. Write a state-space model for the above system.
f. Verify your answers in MATLAB.
E4.2. The state-space model of an LTI system is known to be
x[k + 1] =
"
1
−0.48
0.5
0
#
x[k] +
" 2
0
#
u[k]
y[k] =
f
0.5
1
g
x[k]
a. Determine the transfer function of the system by hand. Verify your answer using MATLAB.
b. Find the gain, poles, and zeros of the system. Is it a stable system?
c. Sketch the step response of the system.
E4.3. Determine if the following systems are asymptotically and BIBO stable
(i) G1(z) =
z −0.2
z2 −1.1z + 0.18,
(ii) G2(z) = z2 −0.36z + 0.9
z2 −0.5z −3
(iii) G2(z) =
z + 1.5
z2 −3z + 2.61
E4.4. An LTI system is described by the diﬀerence equation: y[k] −y[k −1] + 0.24y[k −2] = 2u[k −1].
a. Sketch the frequency response of the system G(ejω).
b. Find the ﬁrst 4 impulse response coeﬃcients.
E4.5. Given the following state-space model
" x1[k + 1]
x2[k + 1]
#
=
" −1
2
0
−0.6
# " x1[k]
x2[k]
#
+
"
1
0.7
#
u[k]
y[k]
=
f
1
2
g
x[k]
a. Derive the system transfer function.
b. Determine the zeros, poles and the DC gain of the system.
c. Determine the impulse and frequency response of the system.
d. Verify your answers using MATLAB.
E4.6. The impulse response of a discrete-time system is given by
g[k] = (0.4)k−1 + 2(0.6)k−1, k ≥1
(4.78)
a) Plot the impulse and step responses of the system. Is the system causal and stable?
b) Arrive at the frequency response function G(ejω) of the system. Plot the magnitude and phase
response of the system.
c) Write the corresponding input-output diﬀerence equation and the transfer function represen-
tation that describes the system.
d) Compute an appropriate FIR approximation of the system by hand.
e) Use a PRBS input (frequencies in the band f ∈[0 0.2] cycles/sample) to excite the system.
Obtain measurements by adding random noise (white), while adjusting its variance such that
SNR sets to 10.
f) Now estimate an FIR model from the above input-output data using impulseest. How close
are the estimates to the theoretical values? Is the length of the estimated FIR model the same
as the approximate FIR model you built by hand?

5
Transform-Domain Models for Linear
TIme-Invariant Systems
This chapter presents models of the LTI system in a transform (frequency) domain. A review of
the frequency-domain descriptions of discrete-time, LTI systems is presented. The objectives
are to provide insights into FRFs and their characteristics, introduce and review transfer func-
tion (z-domain) representations. The chapter also connects time-domain models of Chapter 4
with their frequency- and z-domain counterparts.
In the previous chapter, speciﬁcally in §4.2.3, we studied the frequency response function (FRF)
as one of the elementary response models for an LTI system.
The purpose of this chapter is review certain useful facets of the FRF, again with relevance to
identiﬁcation. Subsequently, we advance to the subject of complex-frequency (damped sine waves)
representations of LTI systems, also known as the transfer functions, through the use of what are
known as z-transforms. We shall in due course observe an interesting resemblance between the
transfer function and the transfer function operator representation presented earlier in §4.3.
5.1
FREQUENCY RESPONSE FUNCTION
To recall, the FRF is the discrete-time Fourier transform of the IR sequence
G(ejω) =
∞
X
k=0
g[k]e−jωk
(5.1)
It characterizes the response of an LTI system to sinusoidal (oscillatory) inputs. A point to reckon is
that it is complex-valued unlike the step and impulse response sequences. One of the most important
uses of FRF, recall, is that it characterizes the ﬁltering nature of an LTI system1.
Filters play tremendous roles in communications, signal processing, control, estimation, identiﬁ-
cation and other allied ﬁelds. Understanding the characteristics of ﬁlters from the FRF is essential to
their proper use in these applications. Numerous texts discuss this topic in great detail. The purpose
of the following discussion is only to spotlight aspects relevant to identiﬁcation.
5.1.1
CHARACTERISTICS OF FRF
The main characteristics of FRF are discussed below.
i. A.C. Gain (|G(ejω)|): This is an alternative term for AR(ω), which quantiﬁes the amplitude
change in the output to an input of unit amplitude at a given frequency. The D.C. Gain Gp
deﬁned earlier in the context of a step response is simply the A.C. Gain evaluated at ω = 0,
naturally since at steady-state the step is a zero frequency signal. The A.C. Gain is one of the
most useful characteristics of a ﬁlter since it governs the ﬁltering nature of the system.
1Any LTI system is technically identical to a linear ﬁlter and vice versa. The diﬀerence is that a system is one which is
already in place, whereas a ﬁlter is usually designed.
109

110
Principles of System Identiﬁcation: Theory and Practice
Note that the gain is independent of the input-output delay merely because
|G(ejω)e−jDw| = |G(ejω)|
The above result is exploited in conjunction with the phase information for time-delay estimation
(see §22.5.3). This property is also used in control loop performance monitoring to diagnose the
source of model-plant mismatch in advanced control schemes (see for instance Selvanathan and
Tangirala (2010a)).
Filters
Since |G(ω)| is a function of the input frequency, every LTI system acts as a ﬁlter, meaning it
preferentially “allows” only a range of frequencies to manifest in the output, unless |G(ejω)| =
1 ∀ω.
Depending on the nature of |G(ω)|, an LTI system is categorized as one among the following:
a. Low-pass ﬁlters: Low-frequency inputs are preferentially allowed to go through while
high-frequency inputs are signiﬁcantly attenuated. Note that the terms “low” and “high”
are subjective because they vary with the system. The time-constants (see corner frequency
below) can be used to determine the demarcation of low- and high-frequency regimes. Most
chemical processes (and other engineering systems) possess low-pass ﬁltering characteris-
tics. Integrators (storage tanks, capacitors) are ideal low-pass ﬁlters.
Several numerical ﬁlters designed for noise removal from measurements have low-pass
characteristics since noise usually has high-frequency content.
b. High-pass ﬁlters: These ﬁlters have characteristics contrasting to that of low-pass ﬁlters.
High-pass ﬁlters ﬁnd uses in radio frequency applications, to eliminate non-zero DC com-
ponents and in conjunction with low-pass ﬁlters to construct band-pass ﬁlters.
c. Band-pass / Band-reject ﬁlters: These ﬁlters, as their name suggests, either allow or reject
a band of frequencies. They are used in communication systems and in signal processing
where one may be interested in only extracting components in a select band of frequencies.
d. All-pass ﬁlter: These are LTI systems that do not alter the amplitude of the input signal but
only change the phase, i.e., |G(ejω)| = 1 ∀ω. A pure-delay system is an example of an
all-pass ﬁlter. These ﬁlters ﬁnd uses in signal processing applications.
ii. Corner frequency (Ωco): The corner frequency2, also known as cutoﬀfrequency, is usually
deﬁned w.r.t. continuous-time ﬁrst-order systems. It is the point on the frequency axis where the
low- and high-frequency asymptotes of the |G(ejω)| virtually meet. An alternative deﬁnition is
that it is the frequency where the AR falls oﬀby a factor of 1/
√
2 or a fall of dB by 3 units
relative to the AR at Ω= 0.
For a continuous-time ﬁrst-order system, the corner frequency is
Ωco = 1
τp
(5.2)
where τp is the time-constant of the continuous-time system.
Figure 5.1 shows the location of corner frequency for a ﬁrst-order continuous-time system with
Kp = 2 and time-constant τp = 2 time units. The corner frequency for this system is Ωco =
1/2 = 0.5 rad/time. Note that this system has low-pass ﬁlter characteristics.
The knowledge of corner frequency is useful in computing the bandwidth of the system,which is
vital to input design and a host of other applications.
Similar deﬁnitions exist for systems with band-pass and high-pass ﬁlter characteristics. The rela-
tionship between the corner frequency for the continuous-time and discrete-time system can be
obtained using the discretization concepts presented later in Chapter 6.
2The upper case symbol is used to distinguish the corner frequency for the c.t. system from the d.t. system.

Transform-Domain Models for Linear TIme-Invariant Systems
111
10
−2
10
−1
10
0
10
1
−20
−15
−10
−5
0
5
10
Magnitude (dB)
Frequency  (rad/s)
Low frequency asymptote
High frequency asymptote
ΩCO
FIGURE 5.1
Location of the corner frequency on a Bode plot
iii. Bandwidth (BW): There is no universal deﬁnition of bandwidth because it appeals to diﬀerent
ﬁelds in diﬀerent ways; however, in all deﬁnitions it denotes a frequency range relevant to the
process under study. In systems theory and signal processing, the frequency range of interest is
that over which the system produces a “signiﬁcant” response with the reference point usually
being the peak magnitude response. The 3dB bandwidth deﬁnition, which is widely followed,
deﬁnes BW to be the frequency range over which the AR lies within 3dB of the peak response3.
For low-pass ﬁlters, BW = [0,Ωco].
In communication and information theory, it denotes the amount of data in bits/sec or bytes/sec
that can be transmitted in a ﬁxed amount of time. While in optics it denotes the width of an
individual spectral line. Elsewhere bandwidth is simply the support of a function in frequency
domain.
In identiﬁcation, the bandwidth is essentially the range of input frequencies over which the sys-
tem will actively respond. This is clearly useful in input design. The inputs are typically designed
to contain frequencies in the range of 3 to 4 times the bandwidth (see §22.3).
iv. Phase shift (φ): The phase shift is solely due to the system dynamics (time-constants) and time-
delay. It is independent of the D.C. gain. One of the key features of the phase shift is that the
contributions of time-constants (dynamics) saturate at high-frequencies. Consequently, the phase
in this regime is predominantly due to delay. This feature has been considerably exploited to es-
timate delays in LTI systems. However, in the presence of noise and unknown dynamics, optimal
estimates of delay are best obtained using the phase over full frequency range. The contribution
of the dynamics is then indirectly computed from the amplitude ratio (Lindemann et al., 2001;
Selvanathan and Tangirala, 2010b). Section 22.5 describes this approach for delay estimation.
The phase of a system (ﬁlter) also denotes how much distortion the inputs, particularly the sharp
features, experience as they go through the system. Systems with linear phase do not cause any
distortion to the input waveform. A pure-delay system is a simple example of a linear phase
system. FIR ﬁlters with symmetric impulse response coeﬃcients have linear phase.
Minimum and non-minimum phase systems
Any system described by a diﬀerence equation, speciﬁcally with IIR characteristics or an FIR
with asymmetric IR is bound to exhibit non-linear phase characteristics. Two types of systems
3In another deﬁnition, the reference dB is the horizontal low-frequency asymptote.

112
Principles of System Identiﬁcation: Theory and Practice
are encountered among these, namely, the minimum phase and the non-minimum phase. The
nomenclature is relative. A system is non-minimum phase if another system with identical am-
plitude ratio characteristics but with a smaller phase exists. This distinction is important in con-
trol because non-minimum phase characteristics can tremendously limit achievable control loop
performance and robustness. In time-series modeling, non-minimum phase stochastic systems
are relatively more diﬃcult to estimate because they involve use of higher-order statistics (see
Giannakis and Mendel (1989) for instance). Closed-loop identiﬁcation with non-minimum phase
controllers result in stability issues for the identiﬁed model (Codrons, Anderson and Gevers,
2002).
All of the preceding ﬁltering characteristics can be related to the zero and pole locations of the
LTI system. Section 5.2 oﬀers details on these connections.
Towards the end of this chapter we shall study a practically useful deﬁnition of FRF known as
the empirical transfer function estimate (ETFE).
Next, we study a second class of transform-domain descriptions based on the z-transform, known
as the transfer function representation.
5.2
TRANSFER FUNCTION FORM
The transfer function form is a generalization of the FRF to the complex frequency (z)-domain. This
generalization oﬀers signiﬁcant advantages over the time-domain representations as we shall learn
in this section.
A useful, but less emphasized, viewpoint is that the transfer function is also a response-based
description for inputs that are exponentially amplitude modulated (damped) oscillatory signals
eαkejωk, α ∈R for this purpose.
5.2.1
RESPONSE TO DAMPED OSCILLATORY SIGNALS
Setting the input u[k] = eα0kejω0k, the response of the LTI system is
y[k] =
∞
X
n=0
g[n]eα0(k−n)ejω0(k−n)
= *
,
∞
X
n=0
g[n]e−α0ne−jω0n+
-
eα0kejω0k
(5.3)
The result is, not surprisingly, similar to the case of oscillatory signals.
Introducing z0 = eα0ejω0, (5.3) can be re-written as
y[k] = *
,
∞
X
n=0
g[n]z−n
0 +
-
eα0kejω0k
(5.4)
The quantity in brackets is the so-called one-sided z-transform of the IR sequence,
G(z) =
∞
X
n=0
g[n]z−n
(5.5)
evaluated at z = z0.
Thus, G(z) measures, in general, the extent to which a damped complex exponential is “trans-
ferred” to the output and acquires the name transfer function. It is a function of the complex fre-
quency z.
The classical reason for motivating the transfer function is that diﬀerence equations transform to
algebraic equations in the z-domain. An elementary understanding of the one-sided z-transform is
necessary.

Transform-Domain Models for Linear TIme-Invariant Systems
113
5.2.2
Z-TRANSFORMS
Forward transform
The one-sided z-transform of a discrete sequence x[.], denoted by X(z), is given by
X(z) ≜Z{x[k]} =
∞
X
k=0
x[k]z−k
(5.6)
By virtue of the transform, the signal acquires a new representation. The entire sequence x[.] is now
represented by a single complex function X(z). Information content in the signal is neither lost nor
newly generated.
The z-transform is unique. For a given signal there exists only one z-transform (if it exists) and
vice versa.
A few illustrative examples follow:
1. Unit impulse:
x[k] = δ[k] =
( 1,
k = 0
0,
k , 0
: X(z) = 1;
ROC :
Entire z-plane
2. Unit step:
x[k] =
( 1,
k ≥0
0,
k < 0
: X(z) =
∞
X
k=0
z−k =
1
1 −z−1 ;
ROC :
|z−1| < 1
3. Exponential signal:
x[k] = ak, |a| < 1, k ≥0 : X(z) =
∞
X
k=0
ak z−k =
1
1 −az−1 ;
ROC |az−1| < 1
4. Sinusoid:
x[k] = sin(ω0k) : X(z) =
∞
X
k=0
sin(ω0k)z−k =
z sin(ω0)
z2 −2z cos(ω0) + 1;
ROC |z−1| < 1
5. Modulated sinusoid:
x[k] = eαk sin(ω0k) : X(z) =
zeα sin(ω0)
z2 −2zeα cos(ω0) + e2α ;
ROC |z−1| < eα
The ROC stands for region of convergence in the z-plane, in which X(z) exists and is analytic. It
depends on whether the given sequence is causal (x[k] = 0, k < 0) or anti-causal (x[k] = 0,k ≥0).
Without the speciﬁcation of ROC, a given X(z) could correspond to a causal or an anti-causal
sequence. In the remainder of this text, the ROC speciﬁcation is dropped assuming that we are
dealing with causal sequences only, i.e., they are zero-valued at negative indices.
Zeros and poles of the transformed signal
A large class of signals have rational z-transforms, i.e.,
X(z) = N(z)
D(z)
Then the roots of the numerator and denominator contain crucial information about the time-domain
characteristics of the associated signal x[k].

114
Principles of System Identiﬁcation: Theory and Practice
TABLE 5.1
Pole locations (p) of X(z) and time-domain characteristics
p = 1
One-sided constant signal (step). Two poles corre-
spond to a ramp signal.
p = 0
Delayed (shifted) signal. Each pole corresponds to a
single shift.
|p| < 1
Decaying signal, x[k] →0 k →∞
|p| = 1
Purely oscillatory signal
ℑ(p) , 0
Oscillatory characteristics
|p| > 1
Signal grows without bounds
The poles are the roots of D(z) = 0 while the zeros are the roots of N(z) = 0. Of these, the poles
are most useful in revealing the time-domain characteristics of the signal.
In the examples above, the step signal has a pole at z = 1, the exponential signal has a pole at z =
a while the sinusoid produces a pair of poles at z = ±ejω0. The damped sinusoid has expectantly,
poles at z = eαejω, i.e., a mixture of both the exponential and sinusoids. The pole locations signify
the nature of the waveform, i.e., whether it is constant, decaying, growing, oscillatory or shifted
with respect to origin.
Table 5.1 contains the mapping between pole locations and signal characteristics. The knowledge
of this mapping is also useful in LTI system analysis using transfer functions.
Inverse transform
The time-domain sequence can be uniquely recovered using the contour-integral based inverse trans-
form
x[k] =
1
2πj
I
X(z)zk−1 dz
(5.7)
However, expression (5.7) is seldom used in practice. Two alternative methods are employed instead.
i. Power series expansion: A long division of X(z) is performed to express it as a series expansion
in terms of z−1. The coeﬃcients of this expansion are the time-samples of x[k].
ii. Partial fraction expansion: X(z) is broken up into simpler terms using the partial fraction
expansion of X(z) into simpler terms. A table of standard z-transforms is then used to determine
the inverse transform of the individual terms. The overall sequence is the sum of the individual
sequences.
Two exercises below demonstrate the above ideas.
Example 5.1: Inverse z-Transform
Problem: Find the inverse z-transform of:
(i) X1(z) =
1
(1 −0.5z−1)(1 −0.3z−1) and (ii) X2(z) =
2z−3
(1 −z−1)2
Solution: Use the partial fraction expansion and standard table of z-transforms
i.
X1(z) =
2.5
1 −0.5z−1 −
1.5
1 −0.3z−1
=⇒x[k] = 2.5(0.5)k −1.5(0.3)k, k ≥0

Transform-Domain Models for Linear TIme-Invariant Systems
115
ii.
X2(z) = 2z−2
z−1
(1 −z−1)2
=⇒x[k] = 2(k −2), k ≥2
The z-transform possesses several useful properties. A few among these that are relevant to the
analysis of LTI systems are discussed below.
5.2.2.1
Properties of z-Transforms
i. Linearity: The z-transform of a superposition of signals is the same superposition of the indi-
vidual transforms
Z{α1x1 + α2x2} = α1X1(z) + α2X2(z) ∀α1,α2 ∈C
(5.8)
ii. Delay:
Z{x[k −D]} = z−D(X(z) +
−1
X
k=−D
x[k]z−k)
∀D ≥0
(5.9)
Most of the sequences that we encounter are zero for negative times, i.e., x[k] = 0, k < 0,
therefore
Z{x[k −D]} = z−DX(z)
(5.10)
iii. Positive shift:
Z{x[k + D]} = zD(X(z) −
D−1
X
n=0
x[n]z−n)
∀D ≥0
(5.11)
Notice the asymmetry between the properties for delayed and positive shifts. This is expected
due to the one-sided nature of the z-transform.
iv. Convolution: This is the most important property of the transform where its application to LTI
systems is concerned.
Z

∞
X
n=−∞
x1[n]x2[k −n]

= Z

∞
X
n=−∞
x1[k −n]x2[n]

= X1(z)X2(z)
(5.12)
where X1(z) and X2(z) are the z-transforms of x[.] and x2[.], respectively. Thus, convolution
operation transforms to a product in the z-domain.
Note: The result is applicable to causal sequences as well. In the continuous-time case, the Laplace trans-
forms play the role of z-transforms.
In addition to the above properties, two theorems ﬁnd frequent use. These theorems are stated
below, proofs of which are readily available in several standard texts.
Initial and ﬁnal value theorems
The ﬁrst theorem oﬀers means of computing the initial value of the signal, x[0] merely from X(z).

116
Principles of System Identiﬁcation: Theory and Practice
Theorem 5.1: Initial Value Theorem
If x[k]
Z
←→X(z), then
lim
k→0 x[k] = lim
z→∞X(z)
(5.13)
provided x[k] is causal, i.e., x[k] = 0, k < 0.
The ﬁnal value theorem, which ﬁnds more utility than the IVT is stated below.
Theorem 5.2: Final Value Theorem
If x[k]
Z
←→X(z), then
lim
k→∞x[k] = lim
z→1(z −1)X(z)
(5.14)
provided (z −1)X(z) has no poles on or outside the unit circle.
The ﬁnal value theorem is used in computing the D.C. gain from the transfer function of a system.
The knowledge of z-transforms and properties is now applied to the analysis of LTI systems.
Use of z-transforms in LTI systems theory
There are two advantages of using z-transforms in the analysis of linear time-invariant systems:
a. The diﬀerence / convolution equation description transforms into an algebraic equation in the
z-domain.
b. A single complex function (transfer function) characterizes the system behavior.
The use of z-transforms in solving diﬀerence equations consists of transforming the diﬀerence
equation into an algebraic equation followed by the inverse z-transform of the resulting expression.
Note: Only one-sided z-transforms are useful in solving diﬀerence equations.
The idea is illustrated by way of an example.
Example 5.2: Computing Responses Using z-Transforms
Determine (i) the free response (u[k] = 0, y[0] = 0, y[1] = 1) and (ii) the forced response to a
unit-step input u[k] (with zero initial conditions) of the system:
y[k + 2] −0.7y[k + 1] + 0.1y[k] = u[k],k ≥0
Solution:
i. First transform the diﬀerence equation into the z-domain
z2Y (z) −z2y[0] −zy[1] −0.7(zY (z) −zy[0]) + 0.1Y (z) = 0
=⇒Y (z) =
z
z2 −0.7z + 0.1 = c1
z
z −0.5 + c2
z
z −0.2
∴y[k] = c1(0.5)k + c2(0.2)k
k ≥0
where c1 = 10/3,c2 = −10/3

Transform-Domain Models for Linear TIme-Invariant Systems
117
ii. Transform the diﬀerence equation into the z-domain
z2Y (z) −z2y[0] −zy[1] −0.7(zY (z) −zy[0]) + 0.1Y (z) =
1
z −1
=⇒Y (z) =
z
(z −1)(z2 −0.7z + 0.1) = c1
z
z −0.5 + c2
z
z −0.2 + c3
z
z −1
∴y[k] = c1(0.5)k−2 + c2(0.2)k−2 + c3,
k ≥0
where the constants are obtained as c1 = −20/3,c2 = 25/6,c3 = 5/2 using the fact that y[0] = 0
and y[1] = 0 due to two sample input-output delay.
The reader may verify that this solution satisﬁes the initial conditions.
The following section introduces the concept of transfer function, the generalization of FRF.
5.2.3
TRANSFER FUNCTIONS
Section 5.2.1 introduced the transfer function as the z-transform of the IR function (Equation (5.5)).
The deﬁnition is re-established below starting once again from the convolution equation.
y[k] =
∞
X
n=0
g[n]u[k −n]
Taking z-transform on both sides of the equation
Z {y[k]} = Z

k
X
n=0
g[n]u[k −n]

(5.15)
and using the convolution property of the z-transform produces
Y (z) = G(z)U(z)
(5.16)
where once again
G(z) =
∞
X
n=0
g[n]z−n
(5.17)
Since quantity G(z) quantiﬁes “how much” of the input is transferred to the output in the z-domain,
it acquires the name transfer function.
From Equations (5.16) and (5.17), we can arrive at two deﬁnitions of transfer functions4.
Deﬁnition 5.1. The transfer function (of a LTI) system is deﬁned in two diﬀerent ways:
i. The ratio of the z-transforms of output and input (with zero initial conditions)
G(z) = Y (z)
U(z)
(5.18)
ii. The z-transform of the impulse response of the LTI system
G(z) =
∞
X
n=0
g[n]z−n
(5.19)
4Strictly speaking, the transfer function should be written as G(z−1) since the r.h.s. are functions of z−1. However, the
convention is to denote it as G(z).

118
Principles of System Identiﬁcation: Theory and Practice
The ﬁrst deﬁnition is useful in deriving the discrete-time t.f. of a sampled-data system, which is
discussed in Chapter 6.
Remarks:
Observe a strong similarity between the deﬁnitions of transfer function operator G(q−1) in (4.34).
Shortly, we shall make a close comparison of these two forms.
Example 5.3: First-Order System
Recall the impulse response of a ﬁrst-order system in (4.4),
g[k] =

b(−a)k−1,
k ≥1
0,
k ≤0
The transfer function of this system is therefore
G(z) = z−1
b
1 + az−1 =
b
z + a
The solved exercise below shows how to obtain transfer function from the diﬀerence equation.
Example 5.4: Transfer Function from DE
Problem: Determine the transfer function of a system described by the diﬀerence equation
form.
y[k] −y[k −1] + 0.24y[k −2] = u[k −1] + 2u[k −2]
Solution: The transfer function of this system is obtained by taking the z-transforms on both
sides of the equation and setting the initial conditions to zero,
G(z) =
1 + 2z−1
1 −z−1 + 0.24z−2 =
2z + 1
z2 −z + 0.24
Uses of transfer function
The transfer function is useful in many ways:
i. To compute the response of a system for a given input proﬁle. The procedure involves computa-
tion of Y (z) followed by computation of the time-response using the inverse z-transform.
ii. In inferring stability, oscillatory characteristics, damping, inverse response, etc. of the system by
an analysis of G(z).
The most important parameters of a transfer function are:
i. Poles: These are roots of the characteristic equation den(G(z)) = 0. The poles govern the stabil-
ity of the system, shape/speed of response and the natural response of the system. They are solely
a property of the system. The mapping between poles and system characteristics is identical to
that for signals given in Table 5.1.
The number of poles at the origin is the number of pure delays present in the system.
ii. Zeros: Zeros are the roots of num(G(z)) = 0. The zero locations dictate what class of inputs
are completely blocked by the system. These parameters are a consequence of how the system
interacts with the input. They have no eﬀect on the stability of the system.

Transform-Domain Models for Linear TIme-Invariant Systems
119
iii. Gain: This is the D.C. gain deﬁned earlier in (4.16). The gain can be computed from the transfer
function using the ﬁnal value theorem,
D.C. Gain = lim
k→∞y[k]u[k]:unit step
= lim
z→1(z −1)Y (z)
= lim
z→1(z −1)G(z)
1
1 −z−1
= lim
z→1 G(z)
(5.20)
provided the steady-state exists. Recall that the FVT is applicable only when (z −1)Y (z) or
zG(z) has no poles outside or on the unit circle.
iv. Delay: The input-output delay is the relative degree of the transfer function written in forward
form G(q) or G(z),
Delay = Relative degree(G(z)) = Degree(Den(G(z))) −Degree(Num(G(z)))
(5.21)
When the backward form G(q−1) (or G(z−1)) is used, delay is the exponent of the q−1 (or z−1)
in the leading term of the numerator.
v. Order: Two deﬁnitions are possible with some subtle diﬀerences.
Deﬁnition 5.2. The order of a system is the degree of the denominator polynomial of G(q) or
G(z).
Alternatively, it is the number of poles of G(z).
This deﬁnition of the order coincides with the deﬁnition of order for a state-space representation,
because the deﬁnition includes the contribution of delays as well.
Deﬁnition 5.3. The order of the system is the degree of the denominator polynomial of G(q−1)
or G(z−1).
The second deﬁnition is purely based on the dynamics of the system. It excludes the contribution
of pure delays. The equivalent order of a state-space representation has to be then carefully
calculated (see Examples 4.14 and 4.15).
Example 5.5: Poles, Zeros, Order and Delay
Problem: A system has a transfer function
G(z) =
z−2 + 2z−3
1 −1.3z−1 + 0.4z−2
Determine the order and delay. Locate the poles and zeros and compute the gain of the
system.
Solution:
i. Order: Re-write the given transfer function as,
G(z) =
z + 2
z3 −1.3z2 + 0.4z
The denominator polynomial is of degree 3. Hence it is a third-order system.
A minimal state-space realization will require three states to describe the system.

120
Principles of System Identiﬁcation: Theory and Practice
ii. Delay: The relative degree of G(z) is 3 −1 = 2. Therefore, the discrete-time system has a delay
of 2 units. One of these delays is a pure delay as conﬁrmed by the pole locations below.
iii. Poles: The characteristic equation is
λ3 −1.3λ2 + 0.4λ = 0
The poles are therefore at p1,2,3 = 0,0.8,0.5.
iv. Zeros: The system has a single zero located at z = −2.
v. Gain: The gain is calculated using (5.20),
lim
z→1 G(z) = lim
z→1
z−2 + 2z−3
1 −1.3z−1 + 0.4z−2 = 30
Stability analysis using G(z)
As we have learnt earlier, stability is related to the pole locations of G(z).
The formal result is stated below.
Theorem 5.3
A causal LTI system is asymptotically stable if and only if all the poles of its transfer function G(z)
are strictly inside the unit circle |z| < 1.
Remarks:
i. A simple proof of the stability theorem may be constructed by recalling the absolute convergence require-
ment of g[k] for stability and Equation (5.17).
ii. BIBO stability implies asymptotic stability unless G(z) experiences a pole-zero cancellation.
iii. Systems with a single pole (or a pair of complex poles) on the unit circle are marginally stable. This is
because the impulse response of these systems neither grows nor decays. However, responses to other inputs
can become unbounded.
iv. An LTI system with a single (real) pole on the unit circle, i.e.,
G(z) =
1
z −1
and/or
1
1 −z−1
is known as an integrator.
The following example brings out the distinction between BIBO stability and asymptotic stabil-
ity.
Example 5.6: BIBO Stability and Asymptotic Stability
The system
G1(z) =
z−1
1 −0.8z−1 + 0.12z−2
is both BIBO and asymptotically stable since both the poles p1,2 = 0.6,0.2 reside in the unit
circle.
On the other hand, the system
G2(z) =
z−1(1 −1.2z−1)
1 + 0.7z−1 −0.6z−2

Transform-Domain Models for Linear TIme-Invariant Systems
121
is asymptotically unstable since one of the poles of G2(z), p1,2 = 1.2,−0.5 lies outside the unit
circle. However, since the zero at z = 1.2 exactly cancels out the pole, G2 is still BIBO stable.
For all practical purposes though, the system is unstable.
Remarks:
The preceding example also provides an important cautionary message. Unstable pole-zero cancel-
lations in transfer function representations gives a grossly incorrect picture of system characteristics, particu-
larly that of stability. However, stable poles may be cancelled without obtaining misleading responses. Strictly
speaking, zeros and poles (even if they are stable) should not be canceled in any situation since zeros arise
when the system is forced with an input, while the poles are purely a property of the system and govern the
natural response.
In the next example, we illustrate how transfer function can be used to compute the system
response without having to explicitly solve the diﬀerence equation.
Example 5.7: Computing Response from TF
Problem: A system is known to have transfer function G(z) =
z−2
1 −0.5z−1 . Compute the
response of the system to a step-input.
Solution: Firstly, since u[k] is a step, U(z) = 1/(1 −z−1). Now,
Y (z) = G(z)U(z)
=
z−2
1 −0.5z−1
1
1 −z−1
= z−2
 
c1
1 −z−1 +
c2
1 −0.5z−1
!
=⇒y[k] = Z−1 {Y (z)} = c1 + c2(0.5)k−2
k ≥2
where c1 = 2,c2 = −1.
Note that we have factored out the delay contribution to facilitate computation of the response.
The transfer function, expectantly, shares a close relationship with the FRF given that the former
is a generalization of the latter.
5.2.3.1
FRF: Special Case of Transfer Function
Reckoning the motivation for transfer functions, and a comparison of the deﬁnitions in (4.19) and
(5.17), it is clear that the frequency response is G(z) evaluated on the unit circle z = ejω
Thus,
G(ejω) =
∞
X
k=0
g[k]e−jωk = G(z)|z=e jω
(5.22)
Evidently, the system cannot have poles on the unit circle for the RHS of (5.22) to exist, which is
also the requirement of stability for the existence of FRF.
In view of (5.22), the FRF is also referred to as transfer function in the identiﬁcation literature.
Equation 5.22 also gives rise to an alternative deﬁnition of FRF.
Deﬁnition 5.4. The frequency response function is the ratio of (discrete-time) Fourier transforms

122
Principles of System Identiﬁcation: Theory and Practice
of the output and input, respectively (with the system starting from rest)
G(ejω) =
∞
X
n=0
y[k]e−jωk
∞
X
n=0
u[k]e−jωk
= Y (ω)
U(ω)
(5.23)
In passing, it is useful to distinguish the subtle diﬀerences between the transfer function operator
G(q−1) and the transfer function G(z).
Transfer function operator and transfer function
The transfer function operator, G(q−1) and the transfer function, G(z−1) have identical forms bar-
ring two, but marked diﬀerences:
i. q is a forward-shift operator, whereas z is a complex variable. Therefore, G(q−1) is an operator,
whereas G(z−1) is a multiplier.
ii. The transfer function is derived assuming zero initial conditions, whereas the operator version of
it does not make any assumptions.
Consequent to the points above, it is possible to uniquely recover the diﬀerence equation from
G(q−1), whereas an ambiguity is associated with the diﬀerence equation recovered from G(z−1).
The following example highlights this point (also see Astrom reference).
Example 5.8: G(q−1) and G(z−1)
Consider a system described by diﬀerence equation
y[k] −0.6y[k −1] = u[k] −0.6u[k −1]
The transfer function operator for this system is
G(q−1) = 1 −0.6q−1
1 −0.6q−1 , 1
whereas the transfer function is
G(z−1) = 1 −0.6z−1
1 −0.6z−1 = 1
Recovering the diﬀerence form from G(z−1) yields y[k] = u[k], which is correct only when
the initial conditions are zero.
In the remainder of the text, we shall not observe the speciﬁc distinction between G(q−1) and G(z−1)
unless required otherwise.
Relationship to other forms
The transfer function form can be converted to state-space form using the same approach as for
G(q−1) presented in §4.4.4. All the arguments and concepts therein carry forward to the TF case as
well.
Recovering the diﬀerence equation is straightforward by noting the correspondence between
coeﬃcients of the numerator and denominator polynomials and the RHS and LHS of the diﬀerence

Transform-Domain Models for Linear TIme-Invariant Systems
123
equation, respectively. The recovery of the DE form is unique only in the absence of any zero-pole
cancellation.
Finally, the impulse response is obtained from G(z−1) in the same way as from G(q−1) (the power
series expansion method). Alternatively standard tables can be used for this purpose. Responses to
step and other inputs are computed by the method outlined in Example 5.7.
Outlook
The transfer function being a representation in the transform domain can be also viewed as a
representation in a diﬀerent basis space. This perspective has resulted in development of other
representations of LTI systems in other basis spaces such as polynomial basis (e.g., Laguerre
polynomials, generalized orthonormal basis functions), wavelet basis, etc. The choice of basis
is motivated by the features that the new representation can oﬀer; Hof and Ninness (2005) and
Tangirala, Mukhopadhyay and Tiwari (2013) are two representative resources for related ideas
and developments.
The last topic in this chapter is concerned with an approximation of the frequency response
function for identiﬁcation in the same way as the inﬁnite impulse response (convolution) model
(4.7) was approximated to obtain the FIR model (4.12).
5.3
EMPIRICAL TRANSFER FUNCTION (ETF)
The theoretical deﬁnition of FRF (5.23) is based on inﬁnite samples of input and output. Evidently,
this form is not suitable for identiﬁcation because in dealing with experimental data, two factors
demand consideration, (i) only ﬁnite samples of output and input are available and (ii) computation
of DTFT can only be performed on a frequency grid, i.e., at ﬁnite frequencies. In other words, the
unknown G(ejω), ω ∈[−π,π) can only be estimated at ﬁnite points from ﬁnite samples.
The impediment essentially stems from the diﬃculty associated with computing the discrete-time
Fourier transform (DTFT) of ﬁnite-length signals. This issue is well-known in signal processing
for which the well-established solution is the Discrete Fourier Transform (DFT) (read §10.4 for
details).
The unitary DFT of a ﬁnite-length signal {x[k]}N−1
k=0 is
X[n] ≜X(ωn) =
1
√
N
N−1
X
k=0
x[k]e−jωnk;
ωn = 2π n
N ,
n = 0,· · · , N −1
(5.24)
Observe that the number of frequencies at which the DFT is computed equals N, the length of the
signal. This is necessary to guarantee reconstruction of the continuous-frequency DTFT (see §10.4).
Note: In the conventional deﬁnition of DFT, the multiplication factor is unity in place of 1/
√
N so that the
2-norm is preserved, ||x[k]||2
2 = ||X[n]||2
2. The form of DFT used in (5.24) is known as the unitary DFT. See
§10.4 for more details.
Replacing the DTFTs of the output and input in (5.23) by the respective DFTs
YN[n] ≜YN (ωn) =
1
√
N
N−1
X
k=0
y[k]e−jωnk
UN[n] ≜UN (ωn) =
1
√
N
N−1
X
k=0
u[k]e−jωnk

124
Principles of System Identiﬁcation: Theory and Practice
one obtains
GN (ejω) = YN (ω)
UN (ω)
(5.25)
where the subscripts on ω have been dropped for generic reasons.
The modiﬁed FRF in (5.25) is known as the empirical transfer function. It is in fact only an
estimate of the theoretical FRF (5.23). To emphasize this fact, the ETF will be termed as ETF
estimate (ETFE) and denoted as ˆGN (ejω) in all its subsequent appearances.
The ETFE addresses the previously mentioned practical diﬃculties very well. However, it no
longer enjoys the exact relationship of Equation (5.23), i.e.,
YN (ωn)
UN (ωn) , G(ejωn )
(5.26)
unless the input is periodic and when N is a multiple of that period.
The error term is bounded whenever the input is bounded as stated below:
YN (ωn)
=
G(ejωn )UN (ωn) + RN (ωn)
(5.27a)
|RN (ωn)|
≤
2Cu
CG
√
N
(5.27b)
where |u[k]| ≤Cu,
and
CG =
∞
X
k=−∞
k|g[k]|
(5.27c)
For a proof of this result, see Ljung (1999). As N →∞, the error term vanishes making ˆGN (ejω)
exact with G(ejω).
Estimation of FRF
We once again take up the system used for illustration in the previous chapter.
The deterministic process was given by (4.70). It has the FRF,
G(ejω) = 0.6e−jω −0.2e−2jω
1 −0.5e−jω
(5.28)
As before, the measurement obtained is the true output corrupted with noise at an SNR level set to
10. The goal is to estimate the FRF from N = 2555 samples of input-output data.
Figure 5.2 displays the ETFE obtained using (5.25). The magnitude and phase response estimates
(dashed line) are compared with the true values (solid line). MATLAB codes for simulating the
process and estimating the FRF are provided at the end of the chapter.
Two contrasting observations emanate from Figure 5.2. The ﬁrst one is that ETFE has captured
the trend of the FRF fairly well, particularly in the low-frequency regime. This is a desirable trait of
an estimator. The second one though is undesirable; the estimate has an erratic behavior, whereas
the true FRF is a smooth function of frequency. The ﬂuctuations as well as the error magnitude are
highly pronounced in the high-frequency regime. While the overall erratic behavior is due to the
presence of stochastic eﬀects, the large error in the high-frequency regime is due to the input. The
input has been designed to contain only low frequencies.
Listing 5.1
MATLAB code for the estimation of FRF in (5.28)
% Create an IDPOLY object for the process
mod_p = idpoly(1,[0 0.6 -0.2],1,1,[1 -0.5],’Noisevariance’,1);
% Generate input and simulate the process
uk = idinput(2555,’prbs’,[0 0.2],[-1 1]);

Transform-Domain Models for Linear TIme-Invariant Systems
125
True
ETFE
10
−2
10
−1
10
0
10
1
−400
−200
0
200
400
Phase (degrees)
Frequency (rad/s)
 
 
10
−2
10
−1
10
0
10
1
10
−2
10
0
10
2
Amplitude
True FRF and ETFE (Bode plots)
FIGURE 5.2
True (solid curve) and estimated (dashed curve) FRFs for the system in (5.28).
xk = sim(mod_p,uk); mod_p.Noisevariance = var(xk)/10;
yk = sim(mod_p,uk,’Noise’);
% Collect the input-output data
dataset = iddata(yk,uk,1);
datatilde = detrend(dataset ,0);
% Estimate the empirical transfer function estimate
Gwhhat = etfe(datatilde);
% Draw a Bode plot of the estimates and the true values
figure; bode(mod_p,’b-’,Gwhhat,’r--’);
legend({’True’ ; ’ETFE’});
Noise has a detrimental eﬀect on the quality of ETFE estimates. Chapter 20 describes in detail
the associated issues and the methods for improving the estimates.
5.4
CLOSURE
The chapter presented a review of the LTI representations in the transform domains, namely, the
frequency (Fourier) and the z-domain. These descriptions oﬀer insights and ease of representations
that nicely complement the time-domain counterparts. In Chapter 25, we shall brieﬂy study another
transform-domain representation, in the wavelet domain, but for linear time-varying systems.
With this chapter, we conclude our review of the mathematical descriptions of deterministic LTI
systems. Tables 5.2 and 5.3, respectively, summarize the non-parametric and parametric descriptions
presented in the preceding and the present chapters. Note that state-space models also belong to the
family of parametric descriptions since they originate from DE models.
Notwithstanding the diversity of the descriptions, their features and forms, all these models carry
identical information and are inter-convertible. However, estimation theory places each form on a
separate platform. One of the main goals of these chapters has been to oﬀer insights into these
aspects. In identiﬁcation, the choice of a particular form by the user depends on (i) end-use (ii) ease
of estimation and (iii) prior knowledge.
Although each model form can be theoretically re-written in another form, it is strongly recom-
mended to directly estimate the desired model form. For example, if it is desired to estimate the FRF,
then it is advisable to obtain ˆGN (ejω) “directly” rather than taking the DFT of estimated impulse
response ˆg[k]. Reasons for this recommendation are outlined in Chapter 20.

126
Principles of System Identiﬁcation: Theory and Practice
REVIEW QUESTIONS
R5.1. What are transform domain models and how could they be useful?
R5.2. Give two diﬀerent deﬁnitions of frequency response functions. Are they both suitable for identi-
ﬁcation?
R5.3. Does the FRF exist for every class of LTI systems?
R5.4. Can a transfer function be deﬁned for all LTI systems? What is the connection between the
transfer function and the FRF?
R5.5. Explain two key uses of z-transforms in the analysis of LTI systems.
R5.6. What is the diﬀerence between G(z−1) and G(q−1)?
R5.7. Deﬁne the order of a input-output system.
R5.8. Describe the physical signiﬁcance of poles and zeros of a transfer function.
R5.9. Deﬁne empirical transfer function and explain the motivation behind its deﬁnition.
R5.10. When is the empirical FRF an exact approximation of the inﬁnite-sample based FRF?
R5.11. Explain the generalization from FRF to transfer functions (using z-transforms).
EXERCISES
E5.1. Compute the z-transform of y[k] = k2T2s .
E5.2. Given the z transform: X(z) =
z−1
(1 −z−1)(1 + 1.3z−1 + 0.4z−2) , determine the initial and ﬁnal
values of x[k]. Also ﬁnd x[k] for any general k.
E5.3. Find the z-transform of x[k] = ak. What are the poles of X(z)?
E5.4. Consider the diﬀerence equation y[k + 2] −1.5y[k + 1] + 0.5y[k] = u[k + 1].
a. Compute the output sequence when u[k] is a step at k = 0 and y[0] = 0.5 and y[−1] = 1.
b. Using the z-transform method verify your result for y[k].
E5.5. A system is designed to process the input as: y[n] = 1
3 (u[n] + u[n −1] + u[n −2]).
a. Discuss its frequency response analytically.
b. What kind of ﬁlter does this system represent?
c. Verify your analysis using the bode command in MATLAB.
d. What input signals are completely eliminated by this ﬁlter?
E5.6. With reference to the discrete-time system obtained in E6.9. at Ts = 1, answer the following:
a. Write the frequency response function G(ejω). Draw the Bodé plot using MATLAB.
b. Estimate the FRF of this system using the Empirical Transfer Function with four diﬀerent
inputs (i) full-length PRBS of lengths N = 63, (ii) full-length PRBS of length N = 2047, (iii)
coloured PRBS (use band [0 1/4] in the idinput command) and (iv) a mixed sine in the
frequency range ω ∈[0, 0.4].
c. Compare the estimate among the four above with the true one and consolidate your ﬁndings.
E5.7. Given the z transform: X(z) =
z−1
(1 −z−1)(1 + 1.3z−1 + 0.4z−2) , determine the initial and ﬁnal
values of x[k]. Also ﬁnd x[k] for any general k.

Transform-Domain Models for Linear TIme-Invariant Systems
127
TABLE 5.2
Non-parametric (response-based) descriptions of deterministic LTI systems
Name
Model
Features
Convolution
(IIR)
y[k] =
∞
X
n=−∞
g[n]u[k −n]
Fundamental equation; model
parameters are the response to
unit impulse input; inﬁnite co-
eﬃcients
Causal FIR
y[k] =
M−1
X
n=0
g[n]u[k −n]
Approximation of IIR; good
starting model; ﬁnite parame-
ters; useful for delay estima-
tion
(Causal)
Finite
Step
response
y[k] =
M−1
X
n=0
(s[n] −s[n −1])u[k −n]
Easier to estimate; easy to
read-oﬀprocess characteris-
tics; model parameters are step
response
coeﬃcients;
good
starting model
Frequency
response
function
(FRF)
G(ejω) = Y (ω)
U(ω)
=
∞
X
k=0
g[k]e−jωk
Fundamental model; only for
stable
systems;
transform-
domain
model;
complex
representation
of
sinusoidal
response;
very
valuable
for identiﬁcation and delay
estimation
Empirical
Transfer
Function
Estimate
(ETFE)
ˆGN (ejω) = YN (ωn)
UN (ωn)
=
1
√
N
N−1
X
k=0
y[k]e−jωnk
1
√
N
N−1
X
k=0
u[k]e−jωnk
Finite sample approximation
of FRF; ﬁnite parameters; low
approximation error but high
variability

128
Principles of System Identiﬁcation: Theory and Practice
TABLE 5.3
Parametric descriptions of deterministic LTI systems
Name
Model
Features
Diﬀerence
equation
model
y[k] + a1y[k −1] + · · · + ana y[k −na]
= b0u[k −D] + · · · + bnbu[k −D −nb]
Finite-parameter, most
general
description;
structure
character-
ized by delay, order
and
input
memory;
parsimonious represen-
tations
Transfer
function
operator
y[k] = G(q−1)u[k]
Operator form of DE;
unique for a given DE
Transfer
function
G(z−1) = Y (z−1)
U(z−1)
zero i.c.
=
∞
X
k=0
g[k]z−k
Transform-domain rep-
resentation of DE form;
gain,
poles
and
ze-
ros completely charac-
terize the system; zero-
initial
conditions
as-
sumption;
non-unique
for a given DE
State-
space
model
x[k + 1] = Adx[k] + Bdu[k]
y[k] = Cx[k] + Du[k]
G =
" Ad
Bd
C
D
#
Most general paramet-
ric
description;
non-
unique representation;
powerful
models
for
MIMO systems; suit-
able for joint estima-
tion and identiﬁcation

6
Sampling and Discretization
Foundations on sampled-data systems, sampling and discretization are provided. Key learn-
ing elements of this chapter are the connections between discrete-time and continuous-time
systems in presence of a zero-order hold, the sampling theorem and guidelines for choosing
sampling rates.
Experimental data is the vital ingredient for identiﬁcation. The introductory chapter taught us
that an identiﬁcation experiment consists of three basic steps, (1) designing the discrete-time input,
(2) exciting the process with an approximate continuous-time input and (3) sampling (measuring)
the resulting output. This chapter discusses the mathematical concepts related to the latter two steps,
while reserving the ﬁrst one for §22.3.
This chapter begins by presenting concepts of discretization in order to establish the mapping
between a sampled-data system and the underlying continuous-time process. Understanding this
mapping crucially aids in formulating practical guidelines for selecting sampling rates in identiﬁca-
tion experiments and discovering the model for the underlying continuous-time process. We shall,
however, only discuss the former problem. Developing continuous-time models from sampled data
is beyond the purview of this text.
6.1
DISCRETIZATION
We begin with the deﬁnition of discretization.
Discretization is the act of obtaining a discrete-time system (or a model) from a
continuous-time system (or a model), under a suitable sampling-and-hold scheme.
Discretized models are usually derived from continuous-time, ﬁrst principles models. Consequently,
the structure and parameters of these models can be related to the geometrical and physico-chemical
properties of the underlying process. These models are therefore naturally useful in grey-box mod-
elling, where the model structure is governed by a discretized version of the continuous-time model.
It should be remarked that discretization as such has a wider appeal. For instance, in digital con-
trol, it is used to arrive at equivalent digital controllers from analog controllers. Other applications
include numerical diﬀerentiation and integration that are at the heart of all modern simulators and
numerical solvers.
Remarks:
A large class of processes naturally operate in discrete domain, for which, there are no correspond-
ing continuous-time counterparts. Monthly wages, rainfall, population growth are prominent examples of such
processes.
Methods for discretization can be classiﬁed into two categories:
i. Approximate discretization: These methods derive discrete-time models using approximations
of continuous-time functions. Arriving at approximate diﬀerence equations from diﬀerential
equations is a classical example of this approach.
Example 6.1: Approximation of First-Order System
A ﬁrst-order continuous-time dynamic system is described by the ODE:
τp
dy
dt + y(t) = Kpu(t)
(6.1)
129

130
Principles of System Identiﬁcation: Theory and Practice
An approximate discrete-time model can be obtained using a backward or a forward
diﬀerence approximation of the derivative.
Backward diﬀerence approximation yields
τp
y(t) −y(t −Ts)
Ts
+ y(t) ≈Kpu(t)
where Ts is the sampling step.
Setting t := kTs, y[k] ≡y(kTs) and α = Ts/τp, we obtain
y[k] +
1
1 + α y[k −1] = Kpα
1 + α u[k]
(6.2)
While the forward diﬀerence approximation produces
y[k] −(1 + α)y[k −1] = Kpαu[k −1]
(6.3)
Observe the diﬀerences in the two approximate diﬀerence equations.
The second approximation produces a strictly causal, but a less stable model than its
backward diﬀerencing counterpart (reference).
ii. Exact discretization: These methods produce discretized models that are exact, i.e., they match
the analytical solution of the diﬀerential equations, but under a given set of conditions. The tax-
onomy can be misleading since these models are also approximations of the continuous-time
system when the conditions for exactness are not met. This aspect becomes clearer in the discus-
sions to follow. The underlying idea is explained with an example below.
Example 6.2: Exact Discretization of a First-Order System
Consider the same ﬁrst-order system as discussed above:
τp
dy
dt + y(t) = Kpu(t)
(6.4)
From calculus, the analytical solution to this equation is
y(t2) = y(t1)e−(t2−t1)/τp + Kp
τp
et2/τp
Z t2
t1
e−t′/τpu(t′) dt′
The particular solution (second term on the RHS) depends on the input u(t′) during the
time interval (t1,t2).
The simplest of cases is when u(t) is a piecewise constant signal, changing only at the
sampling instants
u(t) = u((k −1)Ts), (k −1)Ts ≤t < kTs
Selecting t2 := (k + 1)Ts and t1 := kTs, we obtain the diﬀerence equation
y[k] = e−α y[k −1] + Kp(1 −e−α)u[k −1]
(6.5)
where α = Ts/τp as before.
Observe that there is no approximation involved in this approach other than the piecewise
constant approximation of the input. This discretization is exact, meaning the solutions to
the diﬀerence equation and the diﬀerential equation are identical as long as the continuous-
time and discrete-time inputs are identical.
It is interesting to note that the approximate model obtained by forward diﬀerencing in (6.3) is in
fact a ﬁrst-order approximation of the model in (6.5).

Sampling and Discretization
131
The principle of exact discretization can be applied to any input approximation in general. How-
ever, the case of interest is usually the one as demonstrated above because the standard digital-
to-analog converter used in industrial applications produces a piecewise approximation of the
continuous-time signal.
The remainder of this section expands the ideas outlined above and shows how discretized models
can be obtained from state-space and transfer function representations. In order to understand the
related methodologies, a basic understanding of the sampled-data system is necessary.
6.1.1
SAMPLED-DATA SYSTEM
A sampled-data (SD) system is a typical system constructed for the purposes of conducting exper-
iments using a digital device (such as a computer). Recall Figure 1.8 of the introductory chapter,
which is reproduced here in Figure 6.1 for convenience.
Process
User-designed input 
u[k]
D/A 
Converter
Sensor
Measured output
y[k]
Actuator
A/D 
Converter
y(t)
x(t)
u(t)
ua(t)
FIGURE 6.1
A typical sampled-data system.
The SD system is constructed by appending in series a D/A converter and an actuator at the input
side, and a sensor plus A/D converter at the output.
The role of the D/A converter is to produce an approximate continuous-time signal from a
discrete-time signal. The continuous-time input is further realized by an actuator which is respon-
sible for exciting the process. Process response is converted to an electrical signal (sometimes a
pneumatic signal) using a sensor, which is then sampled at a pre-speciﬁed sampling rate by the A/D
converter. The ideal A/D converter is the ideal sampler, which produces the instantaneous values of
the continuous-time sensor output at speciﬁed sampling instants. The A/D converter also consists
of a quantizer whose role is to digitize or quantize the sensor output for storage in a digital device,
usually a hard disk.
In the derivations below, we neglect the actuator dynamics as well as any non-idealized charac-
teristics of a realistic A/D converter (e.g., quantization errors). The stochastic part of the model can
account for some of these errors, most signiﬁcant among them being the measurement noise. The
derivation oﬀers provision for including actuator dynamics whenever it becomes necessary to do so.
The task in sight is to obtain a mapping between the continuous-time process and discrete-time
system. We denote the continuous-time process by Gc or by its TF representation Gc(s) (s being
the Laplace variable) and the discrete-time system by Gd or by Gd(z).
The mapping, or the discretization, naturally depends on the type of D/A converter, i.e., the
type of approximation introduced at the input side of the system. We are particularly interested, as
mentioned previously, in the case of piecewise constant approximations. A device that realizes this
approximation is known as the zero-order hold, whose characteristics are reviewed below.
6.1.2
ZERO-ORDER HOLD
Several D/A converters exist depending on the approximating function that is employed. The sim-
plest among these is the zero-order approximation realized by a device known as the Zero-Order
Hold (ZOH).

132
Principles of System Identiﬁcation: Theory and Practice
ZOH
!!""
"
!##$
#
$%
(a) Interpolation by a Zero-Order Hold
!"
#!$"
$
##%$
%
!"
(b) Sampling operation
FIGURE 6.2
Schematic showing the operations of a ZOH and sampler, respectively.
The approximation produced by a ZOH is given by:
u(t) = u(kTh) = u[k]
kTh ≤t < (k + 1)Th
(6.6)
where Th is the hold duration. In essence, the ZOH holds on to the old value until the new sample
arrives. This is a zero-order polynomial interpolation, hence the name.
Figure 6.2(a) illustrates the piecewise constant interpolation performed by a ZOH. It is easy to
imagine the case of u[k] being a discrete-time step. The resulting output u(t) is also a step signal.
The ZOH approximation is exact for signals that are piecewise constant over the sampling
interval (such as step and staircase signals). For this reason, the discretization with a ZOH device
is also known as step-invariant discretization.
For all other signals, there is a certain reconstruction error involved. The largest value of the error
is given by (see also Proakis and Manolakis (2005)):
ϵ ZOH = max
k
|u(tk+1) −u(tk)| ≤h max
t

du0(t)
dt

where u0(t) is the true continuous-time signal.
Needless to say, there are inﬁnite possible interpolations of u(t) for a given u[k]. The ﬁrst-order
hold, for instance, produces a piecewise linear approximation of u(t). However, it is non-causal. It
is necessary to know a future sample u[k + 1] to reconstruct u(t) during t ∈(k,k + 1]. Practically,
the ZOH is the simplest among all the hold devices.
6.1.3
SAMPLER
The sampler produces a discrete-time signal from a continuous-time signal. Mathematically it is a
mapping of signals in continuous-time domain to the mapping in discrete-time domain.
Figure 6.2(b) schematically shows the operation of an ideal sampler. The sampler is characterized
by its sampling interval Ts or the sampling frequency Fs = 1/Ts, which quantiﬁes the rate at which
the samples are obtained. The resulting discrete-time signal is simply the continuous-time signal at
the sampling instants,
x[k] ≡x(kTs) = x(t)|t=kTs
t ∈R, k ∈Z
(6.7)

Sampling and Discretization
133
Note: The discrete-time signal u[k] is not deﬁned between sampling instants.
The opening and closing times of the switch are assumed negligible (usually true) compared to
the duration of the sampling period Ts.
Sampling need not be uniform in time; it may be irregular depending on the limitations of the
physical sampling operation and the signal under analysis. Note that the sampler is a generic term
used to denote the device or a living being that samples a continuous-time signal. Uniform (or
periodic) sampling is mathematically and practically the simplest mode of sampling.
The choice of sampling interval is a challenging subject in itself and of interest to several ﬁelds -
communications, signal processing and control to name a few. Milestone works on sampling theory
date back to at least seven decades, popular among them being the celebrated Whittaker-Shannon
sampling theorem (Mallat, 1999). The sampling theorem dictates the minimum sampling rate (as-
suming uniform sampling) to guarantee a lossless recovery of the continuous-time signal from its
sampled version. Section 6.2 presents the main results of the sampling theorem as well as practical
guidelines for choosing sampling rates based on the discretization theory presented below.
Single rate vs. Multirate systems
The ZOH is characterized by its hold duration Th. Typically the hold duration is set to the same value
as the sampling period of the sampler. A sampled-data system with this setting is known as a single-
rate system. Systems for which Th , Ts are known as multirate systems. Single-rate systems are
more common and preferred to multirate systems because theoretically and practically single-rate
systems are much more convenient to handle when compared to multirate systems. Notwithstanding
this fact, multirate systems are many a times inevitable due to physical limitations on sensing de-
vices (e.g., molecular weight of a polymer, composition of a chemical product, ﬁneness of cement).
Identiﬁcation of multirate systems is much more challenging than that of single-rate systems for a
simple reason that the user has much less information to build a model. A few interesting methods
have been developed in the last decade or more for multirate identiﬁcation (see Li, Shah and Chen
(2001) and Wang, Chen and Huang (2004) for example). The main challenge in any multirate iden-
tiﬁcation problem is to build a discrete-time model at the faster rate from a mix of slow-rate (output)
measurements and fast-rate inputs.
This text is concerned only with single-rate system identiﬁcation, which by itself presents nu-
merous challenging and exciting problems.
Having understood the characteristics of the ZOH and the sampler we are now set to develop
the main result, i.e., discretizing a continuous-time system. Two methods are discussed: the ﬁrst
one is based on a state-space representation, while the second one is based on a transfer function
representation.
6.1.4
STATE-SPACE APPROACH
We begin with the state-space representation in the c.t. domain.
˙x(t) = Ax(t) + Bu(t)
y(t) = Cx(t) + Du(t)
The goal is to derive a diﬀerence equation of the form (4.46), i.e., the relationship between states at
two successive sampling instants. Recall the state evolution equation (solution) from §4.4
x(t2) = eA(t2−t1)x(t1) + eAt2
Z t2
t1
e−AτBu(τ) dτ
(6.8)

134
Principles of System Identiﬁcation: Theory and Practice
Choosing t1 ≜kTs and t2 ≜(k + 1)Ts we obtain,
x((k + 1)Ts) = eATsx(kTs) + eA(k+1)Ts
Z (k+1)Ts
kTs
e−AτBu(τ) dτ
(6.9)
Equation (6.9) is the key to discretization. The discrete-time model depends on how the input
changes during the sampling interval, which in turn is determined by the interpolating or the hold
device.
The ZOH discretization is governed by (6.6),
u(τ) = u(kTs) = u[k],
kTs < τ ≤(k + 1)Ts
Using this fact in (6.9), we obtain the discrete-time state equation,
x[k + 1] = eATsx[k] + eA(k+1)Ts
Z (k+1)Ts
kTs
e−Aτ dτBu[k]
= eATs
|{z}
Ad
x[k] + (eATs −I)A−1B
|              {z              }
Bd
u[k]
The output equation being algebraic, is unaﬀected by the ZOH approximation,
y[k] = Cx]k] + Du[k]
Putting together the results, the discretized-time state space model
˙x(t) = Ax(t) + Bu(t)
y(t) = Cx(t) + Du(t)
ZOH
−−−−→
Ts
x[k + 1] = Adx[k] + Bdu[k]
y[k] = Cx[k] + Du[k]
(6.10)
is governed by the mapping
Ad = eATs;
Bd = (eATs −I)A−1B
(6.11)
Observe that the discretization involves computing the exponential of a matrix.
The matrix exponential is deﬁned using the inﬁnite-order Taylor’s series expansion of the expo-
nential,
eAt = I + At + A2 t2
2! + · · ·
(6.12)
Note: The matrix exponential is not the exponential of its elements.
Computation of eAt
Equation (6.12) is only suitable for theoretical analysis. A variety of algorithms exist for compu-
tational purposes. Moler and Loan (2003) present an excellent review of nineteen diﬀerent ways
of computing eAt. With very low-dimensional matrices, the computation can be done by hand for
which two methods are widely used.
1. Eigenvalue decomposition method: The exponential is computed as
eAt = VeΛtV−1
(6.13)
where V and Λ are the eigenvector and eigenvalue (diagonal) matrices of A.

Sampling and Discretization
135
Proof. The identity in (6.13) can be proved using the standard result from matrix algebra,
A = VΛV−1
An = VΛnV−1
in the power series expansion of (6.12)
eAt = VV−1 + VΛV−1t + VΛV−1 t2
2! + · · ·
= V(I + Λt + Λt2
2! + · · · )V−1
= VeΛtV−1
This completes the proof.
□
The second method is based on the Laplace transform.
2. Laplace transform method: The exponential computes the Laplace transform ﬁrst followed by
an inverse Laplace transform.
eAt = L−1 (
(sI −A)−1)
(6.14)
The inverse Laplace transform of a matrix is the matrix of the inverse transform of the individual
elements.
The expression in (6.14) is based on a simple fact that
L
(
eAt)
= sI −A
In fact, the second method, illustrated in the following example, is preferable and more elegant
than the eigenvalue decomposition method.
Example 6.3: Discretization of a Second-Order System
Problem: Construct the discretized model of a sampled-data system consisting of a second-
order continuous-time system
A =
"−3
0
2
−5
#
;
B =
"1
4
#
;
C =
f
0
1
g
;
D = 0
a ZOH and sampler at Ts = 0.02 time units.
Solution: The state-space matrices for the discrete-time system are obtained by invoking
(6.11) and (6.14),
eAt = L−1 (
(sI −A)−1)
= L−1 
"s + 3
0
−2
s + 5
#−1
= L−1
(
1
s2 + 8s + 15
"s + 5
0
2
s + 3
#)
=
"
e−3t
0
e−3t −e−5t
e−5t
#
Using the given sampling period Ts = 0.02,
Ad =
"0.9418
0
0.0369
0.9048
#
;
Bd =
"0.0194
0.0765
#
C =
f
0
1
g
;
D = 0

136
Principles of System Identiﬁcation: Theory and Practice
The reader may verify these results using the eigenvalue decomposition method.
Listing 6.1
MATLAB code for Example 6.3
% C.T. SS model
A = [-3 0; 2 -5]; B = [1 4]’; C = [0 1]; D = 0;
Gs = ss(A,B,C,D);
Gd = c2d(Gs,0.02);
[Ad,Bd,C,D] = ssdata(Gd)
The mapping of state-space models given by (6.11) provides us some useful insights, speciﬁcally
with respect to mapping of eigenvalues and gain preservation. Eigenvalue mapping is useful in
making decisions on appropriate sampling rates for a given continuous-time system.
Theorem 6.1: Eigenvalue (Spectral) Mapping
The eigenvalues λci(A)
i = 1,· · · ,n of a continuous-time LTI system map to the discrete-time
domain under ZOH discretization as
λdi(Ad) = eλciTs
∀i
(6.15)
The proof of this result is based on the Cayley-Hamilton theorem and can be found in standard
texts on digital control. See Åström and Wittenmark, 1997, Appendix B, for example.
Theorem 6.2: Gain Preservation
The D.C. gain of the sampled-data system obtained by single-rate ZOH and sampling operation is
identical to the D.C. gain of the continuous-time system.
Proof. The transfer function of the d.t. system is: Gd(z) = C(zI −Ad)−1Bd + D
Gain(Gd(z)) = lim
z→1 Gd(z) = C(I −Ad)−1Bd + D
= C(I −Ad)−1(Ad −I)A−1B + D
= −CA−1B + D = Gain(Gc(s))
□
It is easy to verify these two facts for the problem in Example 6.3.
We discuss the transfer function approach next.
6.1.5
TRANSFER FUNCTION APPROACH
For an LTI system with transfer function form Gc(s) the state-space method can be used by convert
the TF to a SS form. The resulting discrete-time SS model can be then again converted to Gd(z),
the t.f. form for the discrete-time system. This is a circuitous route though.

Sampling and Discretization
137
Fortunately, a direct method to obtain Gd(z) exists. The procedure described below is based on
the deﬁnition of the transfer function appearing in (5.18)
G(z) = Y (z)
U(z)
1. Select the discrete-time input u[k]
2. Determine the equivalent c.t. input u(t), i.e., the output of ZOH
3. Compute the response of the c.t. system Gc(s). Denote it by y(t).
4. Arrive at an expression for y(kTs) from y(t).
5. Determine Gd(z) = Y (z)
U(z) =
∞
X
k=0
y[k]z−k
∞
X
k=0
u[k]z−k
The method is unaﬀected by the choice of u[k] in the ﬁrst step. However, a clever choice can
simplify hand calculations. Among all the inputs, the discrete-time step serves as the best choice
because then the associated continuous-time input is also a step, as demonstrated below.
Step-invariant discretization
When u[k] is set to a step signal, the ZOH results in a step input u(t) to the process. Thus, the
corresponding y(t) is the step response of Gc(s). Consequently,
Gd(z−1) =
Z

L−1
(Gc(s)
s
)t=kTs

1
1 −z−1
= (1 −z−1)Z

L−1
(Gc(s)
s
)t=kTs

(6.16)
The approach is illustrated on (i) a ﬁrst-order system and (ii) the second-order system of Example
6.3.
Example 6.4: Step-Invariant Discretization
Problem: Obtain the step-invariant discretized model of a ﬁrst-order continuous-time process
Gp(s) =
Kp
τps + 1
Solution: Using the method outlined earlier, introduce a discrete-time step so that u(t) is also
a step. Then, y(t) is the step response of Gp(s)
ys(t) = Kp(1 −e−t/τp )
The z-transform of the sampled output is
Y (z) =
∞
X
k=0
Kp(1 −e−kTs/τp )z−k
= Kp
 
1
1 −z−1 −
1
1 −e−Ts/τp z−1
!

138
Principles of System Identiﬁcation: Theory and Practice
Noting that for a d.t. step, U(z−1) = 1/(1 −z−1), the discrete-time transfer function is
Gd(z−1) = Y (z−1)
U(z−1)
= z−1 Kp(1 −e−Ts/τp )
1 −e−Ts/τp z−1
Thus, we can conclude that the step-invariant discretization of the ODE
τp
dy
dt + y(t) = Kpu(t)
is
y[k] + ay[k −1] = Kp(1 + a)u[k −1]
which agrees with the result in Example 6.2.
Three important points may be observed from the above exercise:
1. A unit sample input-output delay arises due to discretization. The source of this delay is the ZOH
and sampling operation, which continues to hold the input u(t) at u[k −1] even as t = kTs. The
input is updated only at t = kT+
s , whose eﬀect is only observed in the next instant t = (k + 1)Ts.
2. The pole of the continuous-time system p = −1/τp maps to p = −Ts/τp for the discrete-time
system. This is also in agreement with the eigenvalue mapping theorem.
3. The gains of Gc(s) and Gd(z−1) are identical. Again this conﬁrms the gain preservation result.
The model of a ﬁrst-order discretized system is a standard result that may be easily memorized.
Discretization of a second-order system oﬀers additional insights into the eﬀects of sampling on the
mapping of zero-pole locations.
Example 6.5: Discretization of a Second-Order System
Problem: A second-order continuous-time system has the t.f.
Gc (s) =
4s + 14
s2 + 8s + 15
Determine the t.f. of the discrete-time system obtained by sampling the continuous-time
system with a ZOH and a sampler at Ts = 0.02 time units.
Solution: Following the steps outlined earlier,
Gd(z) = (1 −z−1)Z

L−1
( Gc (s)
s
)t=kTs

= (1 −z−1)Z
(
L−1  c1
s +
c2
s + 3 +
c3
s + 5
t=kTs
)
= 14/15 + (1 −z−1)
 
−5/15
1 −e−3Ts z−1 +
−9/15
1 −e−5Ts z−1
!
= z−1
0.07651 −0.07134z−1
1 −1.847z−1 + 0.8521z−2
(verify this with the earlier result)
An alternative method, that is perhaps simpler, is to break up the second-order Gc (s) into
two ﬁrst-order systems followed by adding up the individual discretized ﬁrst-order systems:
Gc (s) =
1
s + 3 +
3
s + 5
∴Gd(z−1) = (1/3)(1 −e−3Ts )z−1
1 −e−3Ts z−1
+ (3/5)(1 −e−5Ts )z−1
1 −e−5Ts z−1
= z−1
0.07651 −0.07134z−1
1 −1.847z−1 + 0.8521z−2

Sampling and Discretization
139
The insights gained from the foregoing exercise are as follows:
1. The order of the system is preserved. A second-order c.t. system manifests as a second-order
discrete-time system. Thus, the number of poles of both these systems is identical (excluding the
additional pole at the origin introduced by the delay due to ZOH-sampling).
2. No mapping relation can be provided for zero locations. In fact, the c.t. system and the discretized
system need not have the same number of zeros. This is primarily because discretization inﬂu-
ences the mode in which the input interacts with the system. See Åström and Wittenmark, 1997,
Chapter 2 for details.
Listing 6.2
MATLAB code for Example 6.5
Gs = tf([4 14],[1 8 15]);
% C.T. TF model
Gd = c2d(Gs,0.02);
% D.T. TF model
ss(Gd)
% Verify with the earlier result
Delays in the continuous-time input-output channel introduce additional factors into the discrete-
time transfer function. A procedure to account for delays is described below.
Discretization in presence of process delays
Suppose that a delay of D time units exists between u(t) and y(t). For SISO systems, the delay in
the input-output channel can be “transferred” to the input side. Two possibilities arise, as discussed
below:
1. Integer Delay: D = dTs where d ∈Z+: This case is simple and has already been addressed. The
transfer function of the delayed system is z−dGd(z); alternatively, the s.s. model is augmented
with d additional states such that the new s.s. model has d additional eigenvalues at the origin.
2. Fractional Delay: D = (d + γ)Ts, where 0 < γ < 1. The fractional delay case is handled by
modifying the discretization of the state-equation as follows:
x[k + 1] = eATsx[k] + eA(k+1)Ts
Z (k+γ)Ts
kTs
e−Aτ dτBu[k −d −1]
+ eA(k+1)Ts
Z (k+1)Ts
(k+γ)Ts
e−Aτ dτBu[k −d]
= Adx[k] + Bd1u[k −d −1] + Bd2u[k −d]
The ﬁrst equation is due to the fact that the continuous input to the process remains at u[k −d −1]
for the ﬁrst part of the sampling interval and then shifts to u[k −d] for the remaining part.
Consequently, the transfer function of the delayed system is (β1z−m−1+ β2z−m)Gd(z). The same
result can be arrived at by using what are known as modiﬁed z-transforms (see Franklin, Powell
and Workman (1998, Chapter 4)).
From the theory of discretization, it is clear that the manifestation of the continuous-time system
as a sampled-data system depends on several factors, namely, the interpolation function of the hold
device, the sampling rate and the input-output delay.
Summary highlights of ZOH discretization
The key points pertaining to ZOH-discretization are enumerated below for easy reference. A few
additional remarks are also included.
1. The order of the system, i.e., the degree of the characteristic equation polynomial is unchanged.

140
Principles of System Identiﬁcation: Theory and Practice
!"!#"
$%!#"
1
-1
j
-j
!"!&"
$%!&"
z = esTs
FIGURE 6.3
Mapping of the stability region under step-invariant discretization.
2. Both systems have identical number of poles. A continuous-time system containing D = dTs
process delays, discretization introduces d poles at the origin in the d.t. system.
3. Fractional delays introduce zeros in the numerator of the discretized transfer function.
4. A step-invariant (ZOH) discretization guarantees that the step responses of the d.t. and c.t. sys-
tems are identical at the sampling instants. Responses of the systems to other inputs in general
do not enjoy this relationship. For example, the IR of Gd(z−1) is not identical to the IR of Gc(s)
at the sampling instants (see Exercise E6.2.).
ys[k] = ys(kTs) = ys(t)|t=kTs
(6.17)
g[k] = g(kTs) , g(t)|t=kTs
(6.18)
5. The poles are mapped according to (6.15),
p(z)
i
= ep(s)
i
Ts
(6.19)
No particular expression exists for the mapping of zeros. At very low sampling rates, however,
zeros approximately map according to (6.19). Moreover, discretized system may possess zeros
even as the c.t. system does not have any zeros (recall Problem 6.5 and the case of fractional
delays).
6. By virtue of (6.19), real parts of poles of discretized systems are always positive (regardless of
the sign of p(s)
i ).
7. The D.C. gains of both systems are identical. The gains are conserved because the gain of the
sampler, Ts, is compensated by the gain of ZOH, equal to 1/Ts. Note that the A.C. gains (the
magnitude of FRF) at non-zero frequencies do not match.
8. The mapping of Gc(s) to Gd(z) is not unique. All continuous-time systems with diﬀerent (patho-
logical sampling) poles p(s) = α+ j(2πm/Ts), m ∈Z map to the same discrete-time system with
pole location p(z) = eα. Thus, the recovery of the continuous-time system from a given discrete-
time system is marked with ambiguity.
Stability map
Under the ZOH discretization the stability region for continuous-time systems, which is the left-half
plane (LHP) ℜ(s) < 0 maps to the unit circle |z| < 1. Marginally stable systems characterized by
a single pair of poles on the imaginary axis of the s-plane map to the boundary of the unit circle in
the z-plane. The RHP in the s-plane maps to the exterior of the unit circle (unstable regions).
Figure 6.3 displays a sketch of this mapping. Shaded regions indicate stability regions in the
respective domains.
Before proceeding to review the sampling concepts in the next section, we brieﬂy mention other
forms of discretization that are used in controller design and other applications.

Sampling and Discretization
141
Other forms of discretization
At the beginning of this chapter we learnt how diﬀerence equations could be arrived by approximat-
ing derivatives in time. Other discretization methods are also possible. There are methods that aim
to achieve invariance with respect to a select class of signals. Impulse invariant method is an exam-
ple of this category. Another set of methods discretize the transfer functions by directly mapping
points on the s-plane to the z-plane. The bilinear or Tustin’s approximation is a widely used method
based on this idea. A short list of popular methods (including the impulse invariant and Tustin’s
approximation) is provided below.
i. Bilinear (Tustin) approximation: The mapping is governed by
z = 1 + sTs/2
1 −sTs/2OR
s = 2
Ts
z −1
z + 1
(6.20)
The Tustin’s approximation oﬀers good frequency domain matching between continuous-time
and discrete-time domain systems.
Delays of the form D = (d + γ)Ts, d ∈Z+, 0 ≤γ ≤1 are mapped to include only the integral
part as z−d.
ii. Zero-pole-gain matching: Under this mapping, the zeros and poles are mapped according to
ϝ(
iz) = eϝ(
i s)Ts
(6.21)
p(
i z) = ep(
i s)Ts
(6.22)
where ϝ(
i.) and pi(.) are the zeros and poles in the respective domains. The constant in the
discrete-time transfer function is adjusted so that the gains are preserved.
iii. Impulse-invariant discretization: The discretized system is obtained such that the continuous-
time and the discrete-time impulse response signals match at sampling instants. Evidently the
method is not invariant with respect to step and other class of inputs.
iv. First-order hold (FOH) approximation: As remarked in §6.1.2, the ﬁrst-order hold constructs
u(t) by a linear interpolation between sampling instants,
u(t) = u[k] + t −kTs
kTs
(u[k + 1] −u[k])
kTs ≤t < (k + 1)Ts
(6.23)
This is a non-causal interpolation. Note that the FOH results in a ramp-invariant discretization.
In the following section, we review the key concepts pertaining to sampling and suggest guide-
lines for the same in identiﬁcation.
6.2
SAMPLING
Sampling is the act of obtaining the values of a continuous-time signal x(t) at a set of discrete
points. Deﬁne tk, k ∈Z as the kth sampling instant. Then the discrete-time signal is the sequence
{x(tk)} or {x[k]}.
If tk = kTs, where Ts is the sampling interval (period), the operation refers to periodic sampling.
Then Fs = 1/Ts is known as the sampling rate or sampling frequency.
The units of Ts are time units/sample. Likewise, the units of Fs are samples/time and usually
expressed in Hertz (Hz). A value of Fs = 50 Hz means 50 samples are obtained in one second.
Sampling frequency can also be expressed in radians/time as ωs = 2πFs.

142
Principles of System Identiﬁcation: Theory and Practice
6.2.1
CHOICE OF SAMPLING RATE
A critical decision variable in a sampling operation is the choice of sampling rate.
A key consideration in selecting a sampling rate is that sampling should not result in loss of
information, i.e., it should be possible to reconstruct the continuous-time signal (if necessary) from
its sampled counterpart.
It is intuitive that the sampling frequency depends on the frequency of the signal. The number of
samples that have to be collected in a time interval depends on the number of cycles completed by
the signal in that time interval. In the worst case, at least two samples should be available per every
cycle of the c.t. signal.
The celebrated sampling theorem provides a concrete answer to this question by formally set-
ting up the problem in frequency domain. In order to follow the main ideas underlying the sam-
pling theorem it is necessary to learn a few important properties of discrete-time signals and how
continuous-time signals are recovered from their discrete-time counterparts.
Frequency / periodicity of sampled signals
A continuous-time sinusoid of frequency F cycles/time (or Ωrad/time) is sampled at a sampling
frequency Fs Hz produces the discrete-time signal
x[k] ≡x(kTs) = Asin(2πFkTs) = Asin(2πFk 1
Fs
t)
Comparing with the expression for a d.t. sine wave x[k] = Asin(2π f k), the frequency of the
sampled signal is
f = F
Fs
(6.24)
Observe that the units of f are cycles/sample whereas that of F are cycles/time.
Thus, a continuous-time sinusoid of frequency F = 50 Hz sampled at Fs = 150 samples/sec
produces a discrete-time signal with a frequency f = F/Fs = 50/150 = 0.3 cycles/sample.
Two important properties
The discrete-time signals possess two unique properties that have far-reaching consequences in
digital signal processing.
i. Only discrete-time signals with rational frequencies are periodic. In contrast, continuous-time
signals with irrational frequencies can also be periodic. This is attributed to the fact that the
fundamental period of a d.t. signal is a positive integer (units of samples), whereas the period of
a c.t. signal belongs to the space of real numbers (having units of time).
Periodic d.t. signal:
x[k + Np] = x[k]
k ∈Z+
Periodic c.t. signal:
x(t + Tp) = x(t)
t ∈R+
The point in case is that the fundamental period of a discrete-time signal of frequency f is not
merely Np = 1/ f unlike for continuous-time signals.
To determine the period of a d.t. signal x[k] with a rational frequency, the frequency f is ex-
pressed as in irreducible fraction (numerator and denominator are coprimes). The denominator
is then the period of the signal.

Sampling and Discretization
143
Example 6.6: Period of a Discrete-Time Signal
Problem: Determine the period of (i) x1[k] = 2 sin(0.8πk) and (ii) x2[k] = cos( √πk).
Solution:
i. The given signal has a frequency of f = 0.4 cycles/sample. Expressing f in its simplest
form,
f = 4
10 = 2
5 cycles/sample
On that account, the fundamental period of x1[k] is 5 samples. Although 2 cycles are
completed in 5 samples, the ﬁrst repetition visible to the observer is only after 5 samples.
A spectral analysis (see Chapter 10) will, however, reveal the true frequency of the signal.
ii. The frequency of x2[k] is f = 0.5/ √π cycles/sample. This is an irrational number. There-
fore, x2[k] is not periodic.
ii. Two discrete-time signals with frequencies s.t. f2 −f1 = M, M ∈Z are identical to each other,
sin(2π f2k) = sin(2π( f1 + M)k) = sin(2π f1k)
Thus, the fundamental frequency range for d.t. signals is f ∈[0,1) or f ∈[−0.5,0.5). This prop-
erty does not apply to continuous-time signals. Discrete-time signals possess this characteristic
due to sampling and the periodicity of sinusoids. These signals reside in the domain of integers
whereas continuous-time signals reside in the domain of real numbers.
Reconstructing the continuous-time signal
The inversion of the sampling operation, i.e., converting the sequence of numbers x[k] to a
continuous-time signal x(t) is known as reconstruction. In many applications, reconstruction may
not be necessary since the digital signals are processed directly. However, the theory of recon-
struction is necessary to decide the ideal sampling rate. Moreover, in computer-controlled (digital
control) systems, it becomes necessary to convert the control actions into continuous-time signals
that can be sent to the actuators. Diﬀerent types of reconstruction exist depending on the device that
is used.
A device that recovers the continuous-time signal from its sampled version is called a reconstruc-
tor or an interpolator.
An ideal reconstruction is one in which the continuous-time signal has been recovered correctly.
The ability to realize a perfect reconstruction depends on (i) the sampling frequency that was used
to obtain the sampled signal (see aliasing below) and (ii) the mathematics of the device being used
for reconstruction.
Given a discrete-time signal of frequency f obtained at a sampling frequency Fs, the frequency
of the ideally recoverable continuous-time signal is
F = f Fs
An ideal reconstruction is achieved by Shannon’s reconstruction. The ZOH obtains an approxi-
mate reconstruction.
• Shannon Reconstruction: In this type of reconstruction, x(t) is given by the expression (Proakis
and Manolakis, 2005):
x(t) =
k=∞
X
k=−∞
x(kh) sin cωs(t −kh)
2
This is an ideal reconstructor. It requires past and future samples and is therefore non-causal. It
introduces a delay in the reconstruction. Although not useful for control applications, it is used
in communications and signal processing with modiﬁcations.

144
Principles of System Identiﬁcation: Theory and Practice
• Zero-Order Hold (ZOH): This is one of the most commonly used reconstruction devices. The
reconstruction follows: x(t) = x(kh) tk ≤t < tk+1. The ZOH has several advantages over the
Shannon’s reconstructor. Also, it can be used for non-periodic sampling.
As we learnt earlier, the ZOH is exact for signals that are piecewise constant over the sampling
interval. For all other signals, there is a certain reconstruction error involved.
Example 6.7: Ideal Reconstruction
A discrete-time sinusoid x[k] = sin(0.8πk) is obtained by sampling a continuous-time sinusoid
at Fs = 50 Hz. To determine The frequency of the discrete-time signal is f = 0.8/2 = 0.4
cycles/sample at a sampling frequency of Fs = 50 samples/sec. Therefore, F = 0.4(50) = 20
Hz.
Aliasing
A consequence of the second property of d.t. signals in reconstruction is that a discrete-time sinusoid
of frequency | f | > 0.5 manifests as a sinusoid of a lower frequency. This phenomenon is known as
aliasing.
A sinusoid of frequency f2 s.t. f2 = f1 + M, M ∈Z where f1 ∈[0,1) is said to be an alias of
the sine wave of frequency f1.
For example, x2[k] = sin(2.5πk) is an alias of x1[k] = sin(0.5πk).
Aliasing results in loss of information. The following example is illustrative of this point.
Example 6.8: Aliasing
Suppose x(t) = sin(20πt) is sampled at Fs = 50 Hz, then the sample signal has a frequency
f = F/Fs = 10/50 = 0.2 cycles/sample.
On the other hand, if Fs = 8 Hz instead, then f = F/Fs = 10/8 = 1.25 samples/cycle.
However, the resulting signal manifests as x[k] = sin(2π(1.25)k) = sin(0.25πk) to an observer.
The consequence is that the observer can only recover a continuous-time signal of lower
frequency F = 0.125(50) = 6.25 Hz, but not the original continuous-time signal of frequency
F = 10 Hz.
Therefore, slow sampling rate causes aliasing, which leads to loss of information.
6.2.2
SAMPLING THEOREM
We are now equipped to answer the question: how fast should a continuous-time signal be sam-
pled so that there is no loss of information?
The answer is somewhat evident from the foregoing discussion. The sampling rate should be cho-
sen such that it does not produce aliases, i.e., the frequency of the d.t. signal falls in the fundamental
range [0,1)
| f | =

F
Fs

< 1
2
A continuous-time sinusoid of frequency F should be sampled at least as fast as twice its
frequency so that there is no loss of information.

Sampling and Discretization
145
0
0.5
1
1.5
2
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time
Amplitude
(a) Two continuous-time signals with F1 = 1 Hz
and F2 = 5 Hz
0
0.5
1
1.5
2
−1
0
1
Amplitude
Sampled signals at Fs = 4 Hz
0
0.5
1
1.5
2
−1
0
1
Time
Amplitude
(b) Sampled versions at Fs = 4 Hz
FIGURE 6.4
(SEE COLOR INSERT) Incorrect sampling rates can result in ambiguous discrete-time signals.
For example, the minimum sampling rate for x(t) = 2 sin(60πt) is Fs,min = 2F = 2 × 30 = 60
Hz.
Although the minimum sampling rate is 2F, practical situations involve sampling rates that are
much higher than the minimum sampling rate.
The general statement of the sampling theorem assumes the continuous-time signal to be band-
limited. It dictates the minimum sampling rate based on the maximum frequency component. The
following theorem is due to Whittaker (1935) and Shannon (1948) who independently arrived at the
result.
Theorem 6.3: Sampling Theorem
A continuous-time signal x(t) band-limited in the interval [−Fmax,Fmax], should be sampled at
least as fast as 2Fmax for perfect recovery of x(t) from x[k].
Proof. The proof for the above theorem can be qualitatively built from the foregoing results. A
formal proof can be found in standard digital control and signal processing texts (Åström and Wit-
tenmark (1997), for example).
□
Example 6.9: Minimum Sampling Frequency
Problem: Determine the minimum sampling rate for a continuous-time signal x(t)
=
2 sin(60πt) + 0.5 sin(100πt) + 10 sin(20πt).
Solution: The maximum frequency present in the signal is Fmax = 50 Hz. Therefore,
Fs,min = 2Fmax = 2 × 50 = 100 Hz
Another example on the consequences of choosing an inappropriate sampling frequency is illus-
trated in Figure 6.4. The left panel shows the two components of frequencies 1 and 5 Hz, respec-
tively, present in a signal. At Fs = 4 Hz, both components map to the same discrete-time component
(shown on the right panel). Thus, recovery of the continuous-time signal can only produce the low-
frequency component of 1 Hz but not the higher frequency component (5 Hz). The term “high” here
is with respect to sampling frequency.

146
Principles of System Identiﬁcation: Theory and Practice
A corollary of the sampling theorem with regards to reconstruction of the continuous-time signal
is stated below.
The maximum frequency component of a continuous-time signal that can be detected unam-
biguously from its discrete-time counterpart is Fs/2.
The frequency Fs/2 is known as Nyquist frequency.
Example 6.10: Nyquist Frequency
If the sampling frequency is chosen as Fs = 50 Hz, then the maximum frequency that a c.t.
signal can contain so that it is reconstructed without ambiguity is 50/2 = 25 Hz.
Any component of x(t) above the Nyquist frequency will appear as a slow signal due to
aliasing.
The sampling theorem places theoretical restrictions on the sampling rates to ensure zero loss
of information. Practically, sampling rates are set to (much) higher values than the minimum rates.
The chapter concludes with guidelines for choosing sampling rates in practice.
6.2.3
PRACTICAL GUIDELINES FOR SAMPLING
Intuitively it appears that the higher the sampling rate, the better is the situation. However, this is
not the case as argued below.
i. The eigenvalue mapping result in (6.15) tells us that as Ts →0, λi(Ad) →1. In other words,
faster sampling rates push the discrete-time system to the boundaries of stability. Very fast
systems result in integrating eﬀects since the poles are situated very close to the perimeter of the
unit circle. Identiﬁcation (and control) of systems with integrating eﬀects is more involved than
otherwise.
ii. Choosing a higher sampling rate than what is actually “appropriate” can drastically increase the
“amount” of noise in the measurement. The third point below elaborates this fact in greater detail.
iii. Sampling rates have to be commensurate with the time-scale of the evolution of the process.
Imagine a situation where the output changes very slowly relative to the sampling interval. Then,
a major risk of sampling very fast is that most of the observed variations in the measurement
would be due to noise thus signiﬁcantly lowering the SNR. Low SNRs have detrimental eﬀects
on parameter estimation and model development (recall Example 2.3).
Therefore, a general guideline is to choose the sampling interval Ts in the range
Ts ∈
 τ
5, τ
10

(about 20 to 40 samples in one settling time)
where τ is the dominant time-constant or the time-constant of a ﬁrst-order approximation of the
system (Åström and Wittenmark, 1997, Chapter 2).
In terms of the bandwidth of the system, a recommendation is to ensure (Franklin, Powell and
Workman, 1998, Chapter 11)
20 < ωs
ωb
< 40
(6.25)
where ωs = 2π/Ts is the sampling frequency and ωb is the 3dB bandwidth of the continuous-
time system.
In practice, special (analog) ﬁlters are installed to ensure that any frequencies higher than half the
sampling frequency are cut oﬀfrom the continuous-time signal to avoid aliasing eﬀects. Such ﬁlters
are known as “anti-aliasing” ﬁlters.

Sampling and Discretization
147
Remarks:
Multiscale systems, i.e., systems with multiple time-scale pose considerable challenge in the choice
of sampling rates. If the sampling rate is chosen with respect to the fastest time constant, the relatively slow
phenomena manifest as integrating eﬀects, whereas a sampling rate based on the slowest time constant loses the
information on the faster phenomena. This continues to be a challenge in the analysis of multiscale systems.
It is appropriate to close the section by observing an important point. Sampling rates fundamen-
tally govern the limitations of any data-driven analysis. The data obtained at a chosen sampling rate
can only contain unambiguous information of signals up to the Nyquist frequency. Thus, the models
built on sampled data will only be able to explain those phenomena that are commensurate at that
sampling frequency and not anything beyond.
6.3
SUMMARY
In this chapter, we learnt the concepts of discretizing a continuous-time system. Discretization is
the act of converting a continuous-time system to a discrete-time system by the use of a sampler and
a hold device. The ZOH device provides a very practical solution to construction of approximate
continuous-time signals from the d.t. signals. It is step-invariant, meaning it is an exact discretization
for inputs that are step type.
This chapter reviewed the theoretical procedure for discretization and the properties of step-
invariant discretization in detail. Speciﬁcally, the pole-zero mapping and gain preservation may be
recalled in this context.
Sampling rates (for periodic sampling) are governed by sampling theorem. Violation of sam-
pling theorem produces aliasing. Very fast sampling rates can pose risks to the stability and estima-
tion of d.t. systems. The sampling interval should be chosen such that it is commensurate with the
time-constants of the c.t. system. An alternative viewpoint is that sampling aﬀects observability of
processes, which plays a vital role in identiﬁability.
This brings us to the closure of Part I, in particular the review of models for deterministic LTI
systems. In Part II, we shall learn the fundamentals of random variables, linear random processes
and their model descriptions. The concepts pertaining to models of linear random process bear a
strong resemblance to those that we learnt in Chapters 3 through Chapter 6. A solid understanding
of this part makes the journey in the following part a smooth and enjoyable sail.
REVIEW QUESTIONS
R6.1. Describe the elements of a sampled-data system.
R6.2. What is the role of hold device in sampling?
R6.3. Describe the diﬀerence between a ZOH and an FOH. For what class of signals does the ZOH
result in zero approximation error?
R6.4. What does the term discretization mean?
R6.5. Explain the diﬀerent ways of discretizing a continous-time system.
R6.6. What does step-invariant discretization mean? Where does it get its name from?
R6.7. How do poles map from the c.t. to the d.t. system in a ZOH discretization?
R6.8. What diﬀerence does a fractional delay make to the discretization vis-a-vis integer delay?
R6.9. Why cannot discretized systems have poles with negative real parts?
R6.10. Explain Shannon’s sampling theorem.
R6.11. What are the considerations for choosing sampling frequency for a system?

148
Principles of System Identiﬁcation: Theory and Practice
EXERCISES
E6.1. Show that the backward discretization is more stable than the forward discretization in numerical
integration.
E6.2. Show that the step-invariant discretization is not impulse invariant, i.e.,
g[k] ≡g(kTs) , g(t)|t=kTs
E6.3. The relation between the inlet ﬂow rate Fi and the liquid level in the second tank of a two
non-interacting tank process can be modelled as:
G(s) = H2(s)
Fi (s) =
2
(s + 1)(s + 2)
For this process, answer/do the following:
a. Identify the time constants and gain of this system. The units of time are min.
b. Find a state-space representation of this system.
c. If the level and the ﬂow rate are sampled every Ts = 0.1 min., obtain the discrete-transfer
function using
i. State-space approach (i.e., convert the c.t. s.s. model to d.t. s.s. model and then ﬁnd G(z))
ii. Input-output or the z-transform approach
d. Are the transfer functions obtained in (i) and (ii) identical?
e. Use MATLAB to compute the transfer function of the d.t. system and verify your results in
parts (c) and (d).
E6.4. Compute the state-space model for the above system when there is a process delay of τd = 9
sec.
E6.5. A continuous-time system behaves like a second-order system with the transfer function:
G(s) =
2(s + 1)
(5s + 1)(10s + 1)
a. Choose an appropriate Ts for the system.
b. If a discrete-time system Gd = SGH is formed by the inclusion of a sampler and ZOH, arrive
at Gd(z) using the direct input-output approach.
c. Compute the D.C. gain, poles and zeros of the discrete-time system.
d. Obtain the theoretical frequency response of the discrete-time system.
e. Carry out the tasks above using MATLAB. For part (e), obtain a plot of the frequency response
and verify your theoretical analysis.
f. Discuss the inﬂuence of choosing diﬀerent Ts on the discretized system.
E6.6. Find the d.t. transfer function G(z) that is a result of discretizing G(s) =
1
(s + 1)(s + 2) with a
ZOH. Choose an appropriate Ts. Also, identify the poles and zeros of G(z).
E6.7. With reference to the G(s) in the previous questions,
a. Write a continuous-time state-space model corresponding to G(s) in the above question.
b. Obtain the corresponding discrete-time state-space model.
c. Compute the eigenvalues of Ad. Do they match with the poles of G(z) in the previous question?
E6.8. A continuous-time system is described by the transfer function
G(s) = e−2s
s + 2 −e−s
s + 4
(6.26)
a. Find the discrete-time ZOH equivalent of the above system with Ts = 1 units.
b. Qualitatively sketch the step response of the resulting discrete-time system.
c. Is the proposed sampling interval appropriate for the above system? If not, suggest a suitable
Ts.

Sampling and Discretization
149
E6.9. A continuous-time LTI system is known to possess the transfer function
G(s) =
2
(10s + 1)(4s + 1)
a. Obtain the discretized transfer function G(z) in MATLAB assuming a ZOH.
b. Verify that the discretization is not impulse-invariant, i.e., g[k] , g(t)|t=kTs both by hand and
in MATLAB.
E6.10. A discrete-time signal x[n] = cos2( 2π
3 n) is obtained by sampling a continuous-time signal x(t)
at a sampling rate of 60 Hz. What is the fundamental period of x[n]? Identify x(t).
E6.11. Determine whether or not each of the following signals is periodic. In case a signal is periodic,
specify its fundamental period:
(a) x[n] = 3 cos(4n + π/6)
(b) x[n] = cos(n/10) cos(πn/10)
(c) x[n] = cos(πn/2) + 2 sin(πn/8) + 3 cos(πn/6 + π/3)

PART II
MODELS FOR RANDOM PROCESSES

7
Random Processes
This is an introductory and foundational chapter for the theory of random processes. The
objective is to review concepts and deﬁnitions pertaining to random variables and random
processes. It is recommended to pay special attention to the concepts of expectation operator,
correlation, stationarity and ergodicity. Interpretations of these concepts in the context of
prediction are provided.
7.1
INTRODUCTORY REMARKS
Chapters 1 and 2 taught us that models developed in identiﬁcation should ideally explain both the
deterministic and stochastic parts of a process. The theory for modeling deterministic processes was
expounded in Part I. Our journey into the modeling of random processes gets underway with this
chapter. The remaining chapters of this part (Part II) describe the measures, models and representa-
tions of random processes.
Throughout this part, we shall assume that the exogenous inputs are switched oﬀwith the ob-
jective of solely focusing on the stochastic eﬀects. In Part IV, which is exclusively concerned with
system identiﬁcation, we shall superimpose the deterministic and stochastic models under the addi-
tivity assumption.
Recall the early discussions in Chapter 1. Uncertainty is one of the inescapable truths in the
analysis of processes and measurements. The sources of uncertainty in data-driven modeling are
primarily (i) insuﬃcient understanding of the process (modeling errors), (ii) measurement errors
and (iii) eﬀects of unmeasured causes. The second source, is in fact, a manifestation of our inability
to perfectly design and understand the instrumentation and its characteristics. All sources of uncer-
tainty in a process lead to the same repercussion - that it is not possible to accurately predict that
process. Then we have what is known as a random process. To complement this deﬁnition, it is
useful to deﬁne, a perfectly predictable process (within the walls of theoretical analysis), known as
the deterministic process that generates a deterministic signal. Strictly such processes are never en-
countered in practice. However, the conception is useful in handling situations where the measured
response is due to a mix of known and unknown causes, such as in system identiﬁcation.
The goal of probability theory and random process modeling is essentially to exploit the pre-
dictability of a random process to the maximum extent possible. With uncertainty reining the
workhorses of prediction, the simplest recourse is to list all possible predictions (outcomes) and
postulate the chance of each of those outcomes.
Example 7.1: Rainfall Prediction
It is a well-known fact that the occurrence of rainfall in any geographical location can never
be accurately predicted. The natural solution is to list both possibilities (“yes” or “no”) and
associate each outcome with their respective chances (probabilities).
Naturally, for events described by continuous-valued variables (e.g., reactor temperature, wind
speed), it is not possible to specify the chance associated with each outcome. Instead we work
with inﬁnitesimal intervals of outcomes and what are known as probability density functions. The
cornerstones of theory of random processes are the concepts of probability and random variables. It
is ﬁtting therefore that we begin this chapter with a review of the same.
151

152
Principles of System Identiﬁcation: Theory and Practice
7.2
RANDOM VARIABLES AND PROBABILITY
The prime characteristic of a probabilistic phenomenon is that a speciﬁc outcome cannot be pre-
dicted because the underlying process is not properly understood. Thus, we treat the associated
variable to be random, meaning many possible outcomes exist of which the variable assumes one
value. This gives birth to the notion of a random variable, a rudimentary deﬁnition of which is given
below.
Deﬁnition 7.1. A random variable (RV) is one whose value set contains at least two elements.
The space of possible values is known as the outcome space or sample space.
The value set could be continuous (e.g., temperature of an inlet ﬂow, sensor errors) or discrete
(e.g., occurrence of rainfall, face value of a die). Accordingly, one obtains a continuous or discrete
RV respectively.
When the number of possible outcomes shrinks to unity, the variable ceases to be random and is
termed as deterministic. Note that when the actual event occurs, the RV assumes only one value
among the possible outcomes. The associated probability law gives us the chance that RV can
take one of these outcomes or within a certain interval depending on whether it is a discrete- or
continuous-valued variable respectively.
In dealing with uncertain events, the nature of the outcomes can be qualitative (e.g., good / bad),
or quantitative (e.g., sensor reading). In order to have a uniﬁed setup, the random variable is deﬁned
to take on only numeric values. This leads to the following formal deﬁnition.
Deﬁnition 7.2 (Random Variable, Priestley (1981)). A random variable X is a mapping (or point
function) from the sample space S onto the real line such that to each element s ⊂S there corre-
sponds a unique real number.
Example 7.2: Random Variable
In a game of sport, three possibilities arise for the player - victory, loss and a draw. These
descriptive outcomes are assigned numbers so as to use the probability theory for numeric-
valued variables. Among the many diﬀerent choices, a popular mapping is to assign the
random variable 1 for victory, -1 for loss and 0 for a draw.
Conventionally, the RV is denoted by an uppercase variable X. The value that it takes on is
denoted by a lowercase variable x.
Remarks:
a. In constructing a random variable, we eﬀectively replace our original (abstract) sample space by a new
(concrete) sample space.
Examples: outcomes of a game, head and tail of a toss are mapped to [1,0].
b. If the experiment itself yields some physical quantity that is real valued, then no further mapping is required.
c. In practice, the term random variable is restricted to measurable functions only, i.e., those for which the
probabilities in the sample space are deﬁned.
d. A diﬀerence between the random and a deterministic variable is that the former always has the additional
dimension of outcomes.
Does a random variable actually exist?
This is a philosophical question requiring profound discussions, which of course we shall not
dwell deep into. The essence of which, however, is worth noting. The term randomness, in signal
analysis, is associated with any variable or a signal that is not accurately predictable. In principle,
there is no reason to believe that the true process behaves in a “random” manner. It is merely that

Random Processes
153
since we are unable to predict its course, i.e., due to lack of suﬃcient understanding or knowledge
that any process qualiﬁes to be random.
Randomness is, therefore, not a characteristic of a process, but is rather a reﬂection of our lack
of knowledge and understanding of that process.
As remarked earlier, when it is not possible to predict accurately, we take recluse in probability
theory.
7.3
PROBABILITY THEORY
The theory of probability is a formalization of intuitive ways of describing uncertainties. Three
examples are presented below to illustrate the underlying ideas.
Example 7.3: Roll of a Die
This is the classic example of predicting the face value of a die in a single roll. The random
variable is the face value. An accurate ﬁrst-principles model that takes into account the
geometry of the die, ﬂoor surface, the speed with which it is rolled, etc. is highly inconceivable.
Instead we list the six possibilities and postulate that all outcomes are equally likely
(unless the die has a geometrical imperfection).
Xi :
1,2,· · · ,6
Pr(Xi) := 1/6 ∀i
This postulation can be veriﬁed by experimental means as well.
Example 7.4: Level Measurement
Consider the case of measuring ﬂuid level in a closed tank. Neglecting any evaporation losses
between two readings, the sensor should produce a constant reading. However, in reality the
measurement ﬂuctuates due to sensor characteristics. The level measurement at each instant
in time is treated as a random variable because the sensor noise is not accurately predictable.
Notice that here we have a continuous-valued RV.
Thus, the observed reading at any instant in time is one among the myriad of possible
readings that could have been obtained. Theoretically, the set of possible values is inﬁnite
(even if the sensor values were quantized). This example is representative of all measurement-
related randomness.
Example 7.5: Estimation of Averages
One of the most routine tasks in statistical data analysis is to estimate the mean (average)
of a random variable. Given N observations (in time) of a RV X and assuming that the mean
of the RV has not changed with time, its sample mean ¯x is often used as an estimate of the
mean
¯x = 1
N (x[1] + x[2] + · · · + x[N])
(7.1)
where x[k] is the kth sample. Since the measurements are themselves random, the sample
mean is also a random variable. What this means is that repeated experiments, (all other
conditions held), each consisting of N samples, produce diﬀerent values of ¯x.
The possible values and particularly the spread of ¯x determines the goodness of ¯x as an
estimator of the true mean. It is possible to theoretically determine the distribution of ¯x by
knowing the probability distribution of x[k] (cf. Chapter 13).

154
Principles of System Identiﬁcation: Theory and Practice
Example 7.5 is representative of all estimation exercises. Any estimate inherits the randomness
(uncertainty) present in the measurements. Evaluating how the uncertainty in measurements propa-
gates to the estimates allows us to determine the probabilistic characteristics of estimates, which is
crucial to the construction of conﬁdence intervals for the associated parameters (cf. Chapter 13).
The speciﬁcation of the outcomes and the associated probabilities completely characterizes the
random variable. For this purpose, a probability distribution function is introduced.
7.3.1
PROBABILITY DISTRIBUTION FUNCTIONS
The probability distribution function F(x) of any random variable X gives us the probability of X
taking on any value lower than a speciﬁed value x. It is known more appropriately as the cumulative
distribution function (c.d.f.).
F(x) = Pr(X ≤x)
(7.2)
The c.d.f. can be given a cumulative “mass distribution function” interpretation.
Probability distributions (functions) are either theoretically known or are determined through
experiments. Theoretical, or ﬁrst-principles approaches require a fair amount of process knowledge
Ogunnaike (2010).
Experimental determination of c.d.f.s, on the other hand, involves operating the process under
the same controlled conditions over several hundreds of trials and recording the outcome in each
trial. With the obtained experimental data the probabilities are empirically estimated using
Pr(Outcome) = No. of trials producing favorable outcome
Total no. of trials
(7.3)
This is also known as the frequentist’s deﬁnition of probability, which replaced the long-held classi-
cal thought of uniform (equally likely) probability for phenomena that had natural symmetry in them
(e.g., six-faced die without any imperfections). An inherent assumption is that the trials above have
covered the entire outcome space, also known as the ensemble, without introducing any deliberate
prejudice (systematic error) towards one or more outcomes.
The c.d.f.s may be described by theoretical (or closed-form) expressions, while many others are
only known empirically in the form of tables.
For any function to qualify as the probability distribution function, it has to satisfy the following
properties (implications provided in parentheses):
1. 0 ≤F(x) ≤1, ∀x
2.
lim
x→−∞F(x) = 0,, lim
x→∞F(x) = 1,
(Probability of no and any occurrence is 0 and 1, respectively)
3. F(x) is a non-decreasing function in the sense that, for any h ≥0 and all x,
F(x + h) ≥F(x)
(Probability cannot be negative)
4. F(x) is right-continuous for all x, i.e.,
lim
h→0+ F(x + h) = F(x)
(F(x) can have “jumps” )
Continuous and Discrete-valued RVs
In general, there exist many diﬀerent types of distribution functions, each characterizing a class of
phenomena (see Ogunnaike (2010) for an excellent exposition). These functions can be classiﬁed
into two diﬀerent types depending on the nature of the RV, i.e., whether it is continuous-valued or
discrete-valued. When the distribution functions exist, the continuous-valued RV possesses a con-
tinuous c.d.f. while the discrete-valued RV has a c.d.f. that is discontinuous, speciﬁcally a staircase

Random Processes
155
−5
0
5
0
0.5
1
x
F(x)
Gaussian PDF (µ = 0,σ = 1)
0
20
40
0
0.5
1
x
F(x)
Chi−square PDF with 10 d.o.f.
0
5
10
0
0.5
1
x
F(x)
Binomial PDF (n = 10,p=0.5)
−5
0
5
0
0.5
1
x
F(x)
Uniform PDF
FIGURE 7.1
Commonly encountered cumulative (probability) distribution functions.
form. Consequently, for the latter case, there exists no density function. The salient diﬀerences be-
tween these distributions are listed below. It is useful to understand these diﬀerences in analogies
with mass distributions and density functions in solid mechanics.
Continuous c.d.f.s:
i. F(x) is continuous and diﬀerentiable for almost all x (e.g., Gaussian).
ii. For these distributions, a “density” function (like in mechanics) exists.
Discrete c.d.f.s:
i. F(x) is a simple step function with jumps at points (e.g., Binomial).
ii. No density function exists for this case. Instead a probability mass function that determines
Pr(X = x) is deﬁned (e.g., counts of number of heads in a coin toss, face value on a die).
iii. The probability of taking on a value between jump points is zero.
One could also encounter phenomena with mixed or hybrid distributions. The Lebesgue’s decom-
position theorem (Priestley, 1981) states that any distribution function can be decomposed into a
sum of continuous and discrete distributions, and a third term which is singular in nature. The third
type arises only in pathological situations and is largely of academic interest.
Figure 7.1 sketches four diﬀerent distributions, three of which are smooth (continuous) while the
fourth (binomial) distribution function is a discrete distribution. These four distributions have their
respective applications as brieﬂy described below:
i. Gaussian (Normal) distribution: This is one of the most prominent and versatile distributions.
It is suited for continuous-valued random variables that are a result of a large number of small
(in magnitude), additive and independent eﬀects. This distribution also characterizes phenomena
with random, symmetric, independent deviations from a target value. Measurement errors are
very often assumed to follow a Gaussian distribution.
ii. Chi-square distribution: The χ2-distribution is a member of the larger family of distributions
known as Γ (Gamma) distributions, which are meant to characterize continuous, non-negative
valued random phenomena. Consequently, this distribution ﬁnds applications in characterizing
estimates of variance, spectral density and other quadratic non-negative variables.

156
Principles of System Identiﬁcation: Theory and Practice
iii. Uniform distribution: Capable of describing both continuous and discrete-valued random vari-
ables, it is used to describe phenomena that do involve any particular inclination towards a spe-
ciﬁc outcome. It is generally used to describe selection or sampling processes that are a result of
picking an item at random from a ﬁnite size population.
iv. Binomial distribution: A very prominent one, describes the probabilistic characteristics of the
success/failure distribution of n independent trials, with each trial possessing only two outcomes
(Bernoulli random variable). The distribution has numerous applications in reliability engineer-
ing, safety and hazard tests, fertilization of cells, etc.
For a comprehensive treatment of distribution functions and their applications, the reader is referred
to Ogunnaike (2010).
In the remainder of the text, we work with only continuous distributions since most physical vari-
ables of interest are continuous-valued. Given that continuous distributions possess density func-
tions (the analogue of density functions in mechanics), it is convenient to work with probability
density functions (p.d.f.).
Probability density function
The probability density function (p.d.f.) f (x) can be deﬁned in two diﬀerent ways:
1. It is the function such that the area under the curve gives the probability of X taking on values in
the abscissa space,
Pr(a ≤x ≤b) =
Z b
a
f (x) dx
(7.4)
Thus,
Z
E
f (x) dx = 1
(Probability of any outcome is unity)
where E is the ensemble of X.
2. It is the derivative (w.r.t. x) of the distribution function
f (x) = dF(x)
dx
(7.5)
Combining (7.4) and (7.5), we observe
Pr(a ≤x ≤b) = F(b) −F(a)
Note:
i. Integration over the ensemble is commonly written as
Z ∞
−∞
f (x) dx where the lower and upper limits indi-
cate the extreme possible values.
ii. The density function should never be thought of as the probability of X = x, since this is always zero for
continuous-valued RVs.
Gaussian density function
One of the most frequently encountered and widely used distribution functions is the Gaussian
(Normal) distribution. It has the probability density function
f (x) =
1
σ
√
2π
exp
 
−1
2
(x −µ)2
σ2
!
(7.6)

Random Processes
157
−4
−3
−2
−1
0
1
2
3
4
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
x
f(x)
Gaussian density function (µ = 0,σ = 1)
(a) Gaussian density function
0
5
10
15
20
25
30
35
40
0
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
0.09
0.1
x
f(x)
χ2 density function (10 d.o.f.)
(b) χ2-density function
FIGURE 7.2
Density functions: shaded regions correspond to Pr(1 ≤X ≤2) and Pr(6 ≤X ≤8), respectively.
Figure 7.2(a) shows the plot of a standard Gaussian density function, i.e., with µ = 0 and σ = 1.
The parameters µ and σ govern the center and spread of the bell-shaped curve.
The Gaussian p.d.f. enjoys the following properties:
i. It is completely characterized by the two parameters µ and σ.
ii. The parameters µ and σ are related to the ﬁrst two moments of the pdf, which can be easily
estimated in practice.
iii. The density function is symmetric meaning all the higher-order moments are zero.
iv. It is the density of the average of a large number of independent RVs drawn from the same
distribution, regardless of the original distribution (central limit theorem, see Section 7.4)
Furthermore, as described earlier, this distribution function is versatile and prominently used in a
diverse range of applications.
Note: The higher-order moments of a Gaussian distribution are not truly zero, but the higher-order moments
of other distributions are referenced w.r.t. that of the Gaussian p.d.f.. Thus, the higher-order moments of a
Gaussain p.d.f. can be treated as the origin.
χ2 density function
Another widely encountered density function of interest is the χ2 p.d.f.:
fn(x) =
1
2n/2Γ(n/2) xn/2−1e−x/2
(7.7)
where n is the degrees-of-freedom (d.o.f.) parameter and Γ(.) is the Gamma function.
The d.o.f. can be understood by examining an alternative deﬁnition of the density function. A RV
constructed as the sum-square of n independent, standard Gaussian distributed random variables,
Zi’s
X =
n
X
i=1
Z2
i
is said to possess a Chi-square distribution with n degrees of freedom, conventionally denoted by
X ∼χ2
n.
Figure 7.2(b) shows a plot of the χ2 p.d.f. with n = 10 d.o.f. As n →∞, by the central limit
theorem (see Theorem 13.4), the distribution converges to a Gaussian distribution.

158
Principles of System Identiﬁcation: Theory and Practice
The χ2 density function is used to assess goodness of ﬁts, estimates of variance and other non-
negative quantities such as spectral densities.
There exist several other density functions which ﬁnd an important place in their respective
application areas. Standard texts on statistics and probability list these distributions and discuss
their properties at great lengths (see for example Ogunnaike (2010) and Johnson (2011)).
Practical aspects
In practice, knowing the form of the p.d.f. a priori is not a trivial task by any means. In some
situations it may be possible to derive the theoretical p.d.f. based on the physics of the process
(Ogunnaike, 2010). However, even if the form is known, it is seldom possible to theoretically know
the parameters of the density function. This situation is much alike to, or perhaps even more com-
plicated than, developing models for deterministic processes. As in those processes, here too the
practical approach is to conduct experiments and determine the p.d.f. (when the form is not known)
and/or estimate the parameter values (when the form is known) that best explain the randomness in
the data.
Determining the p.d.f. empirically is also, unfortunately, a task marked by several challenges,
particularly due to the lack of an eﬃcient estimation method. The diﬃculty becomes manifold for
multivariable cases, where joint p.d.f.s have to be estimated. Fortunately, in the realm of linear ran-
dom processes, it is not necessary to know the p.d.f. but rather it suﬃces to know two statistics,
namely, the mean, which is a measure of the center of the possible outcomes and covariance, which
measures the linear relation between the outcomes of a pair of random variables. These two statis-
tics are in fact related to the ﬁrst two moments of the joint density function. Another encouraging
aspect is that these two statistics can be estimated with reasonable accuracy in practice.
The expressions for model parameter estimates, errors in estimates and bounds on predictions in
the linear case are all dependent on the ﬁrst- and second-order statistical properties of the random
characteristics in data. It should be added, however, that any attempt to venture into the non-linear
realm requires the use of higher-order properties.
The suﬃciency of merely knowing mean and variance in dealing with linear random processes
is strongly linked to the assumption of Gaussian distribution for the random eﬀects in data. This is
also related to the fact that a complete description of uncertainty for a Gaussian distributed random
variable is available through its mean and variance.
Given that our focus is largely on linear processes in this text, it is important to gain an in-depth
theoretical knowledge of ﬁrst- and second-order statistics. Equally important is to interpret them
in the identiﬁcation context. A good appreciation of these concepts can be gained as one traverses
through the rest of the text, particularly, in estimation problems. The following section provides the
theory pertaining to the vital statistics of density functions.
7.4
STATISTICAL PROPERTIES OF RANDOM VARIABLES
We begin with the analysis of a single random variable and gradually extend our discussion to the
bivariate (multivariate) case.
7.4.1
MEAN AND VARIANCE
Mean
The ﬁrst property of interest is the mean or average, conventionally denoted by µX.
It is theoretically deﬁned as the weighted average of all the outcomes. The formal deﬁnition is

Random Processes
159
given by
µX =
Z
E
x f (x) dx
Z
E
f (x) dx
=
Z
E
x f (x) dx
(7.8)
It is clear that the weighting is the probability of occurrence (in a small neighbourhood). In the
discrete RV case, the integral is replaced by a summation and f (x)dx replaced by the probability
Pr(Xi).
Remarks:
i. The mean is the ﬁrst moment of the p.d.f. f (x) (analogous to the center of mass). It is the ensemble average
of X.
ii. It is the most fundamental concept in the analysis of random variables because all other properties of the
p.d.f. are expressed as averages of functions of X.
iii. The mean serves as a good representative of the center of outcomes. In other words, it is a statistical center
of the outcome space. However, it is not necessarily the geometric center.
iv. For Gaussian and uniform distributions, the outcomes are symmetrically distributed around the mean; thus,
the mean is also the geometric center.
Note: Another popular measure of center is the median, which is useful for distributions that are asymmet-
ric about the mean.
v. As we shall show shortly, mean is the best prediction of a random variable in the absence of any other
information.
Expectation operator
To facilitate computation of averages of functions of random variables, it is convenient to introduce
an operator, known as the expectation operator. By virtue of the third remark above, the mean is
said to be the expected value of X.
E(X) = µX =
Z
E
x f (x) dx
(7.9)
Several real-world examples serve to illustrate (7.9).
Example 7.6: Average Temperature
A simple example is that of predicting temperature at a certain time of the day. Without
taking into account any other inﬂuencing variables or any trends in the temperature, the
daily average is the “expected” temperature. As we shall see shortly, it is the best prediction
in the absence of other information.
Needless to say, the mean is an elementary prediction. The time-series analysis approach exploits
the trends and correlations in time samples to improve upon this simple forecast using conditional
means.
Returning to our discussion on the expectation operator, we study a few of its useful properties.

160
Principles of System Identiﬁcation: Theory and Practice
Properties of the expectation operator
i. From (7.9), expectation is always in the space of outcomes, i.e., the ensemble.
ii. Expectation operator is a linear operator
E *
,
M
X
i=1
αi Xi+
-
=
M
X
i=1
αiE(Xi)
(7.10)
iii. The expectation of a function of X is,
E(g(X)) =
Z
E
g(x) f (x) dx
(7.11)
Essentially, the average of g(X) is the average of function of each outcome weighed by the
probability of occurrence of X itself. Also, note that g(.) is a deterministic function.
iv. Functions of RVs and expectation operators do not commute,
E(g(X)) , g(E(X))
(7.12)
v. The expectation of a RV X is the solution to
min
c
E((X −c)2)
(7.13)
This is merely a reiteration of the fact that we have discussed earlier. The mean is the best
(minimum mean square error) prediction of X. If all the possible outcomes of X were to be
represented by a single constant that is at a minimum distance from those outcomes, then that
constant is E(X).
vi. Finally, expectation is non-commutative to multiplication in general (unless under some special
conditions).
E(XY) , E(X)E(Y)
Two solved exercises below illustrate the workings of the expectation operator.
Example 7.7: Mean of a Sinusoid at an Instant
Find the expectation of a random variable y[k] = sin(ωk + φ) where φ is uniformly distributed
in [−π,π].
Solution: E(y[k]) = E(sin(ωk + φ)) = 1
2π
Z π
−π
sin(ωk + φ) dφ
= 1
2π ( −cos(ωk + φ)|π
−π)
= 1
2π (cos(ωk −π) −cos(ωk + π)) = 0
Observe that the expectation is not an averaging across time.
Example 7.8: Average Power in a Current Wire
The ﬂuctuation of current in a constant resistance wire has random characteristics and is
known to follow a uniform distribution in [a,b] at a given time. Determine the average power

Random Processes
161
dissipated by the wire at any given instant.
Solution: E(P) = E(i2R) = R
1
b −a
Z b
a
i2 di
=
R
b −a
*
,
i3
3

b
a
+
-
= R(b2 + a2 + ab)/3
It is left as an exercise to the reader to show that the expectation of a RV following a Gaussian
distribution is indeed the parameter µX.
We now study the second, but perhaps the most important property of a random variable.
Variance
The mean is one of the best estimates of the center of possible values. However, what is equally
(and sometimes more) important is to know the spread or dispersion of outcomes.
The variance of a random variable, denoted by σ2
X is the average spread of outcomes around its
mean,
σ2
X = E((X −µX)2) =
Z
E
(x −µX)2 f (x) dx
(7.14)
Variance is also a good measure of the range of possible values of a RV. In the temperature pre-
diction example, it is not enough to merely know the best prediction at a certain time of the day/year,
but it is also important to know the “range” of temperatures for various purposes. The variance mea-
sure, and its extension to the multivariate case, known as covariance, are indispensable to several
applications - statistical process control, error analysis of parameter estimates / predictions, input
design and so on. In measurement and estimation theory, variance is a measure of sensor precision
and the goodness of an estimator.
Remarks:
• From (7.14), variance is the second central moment of f (x). Further, it can be rewritten as
σ2
X = E(X2) −µ2
X
(7.15)
• The variance deﬁnition is in the space of outcomes. It should not be confused with the widely used variance
deﬁnition for a series or a signal (time samples).
• Large variance indicates far spread of outcomes around its statistical center. Naturally, in the limit as σ2
X →
0, X becomes a deterministic variable.
• The positive square root of variance is known as the standard deviation, σX.
The variance of a Gaussian distributed RV is given by the parameter of the p.d.f., σ2
X. Approxi-
mately 64% of the outcomes are contained in the 2σ interval, [µ−σ, µ+σ], 95% in the 4σ interval,
[µ −2σ, µ + 2σ] and 99% in the 6σ interval, [µ −3σ, µ + 3σ].
Example 7.9: Variance of a Laplace Distributed RV
Determine the variance of a RV that follows a Laplace distribution, the pdf given by
f (x) = 1
2b exp
 
−|x −µ|
b
!
Solution: σ2
X = E((X −µX )2) =
Z ∞
−∞
(x −µX )2 1
2b exp
 
−|x −µ|
b
!
dx
= 2b2

162
Principles of System Identiﬁcation: Theory and Practice
In statistical data analysis including estimation, identiﬁcation and prediction, we encounter
scaled random variables. It is useful to know how the mean and variance of the scaled variables
are related to those of the original ones.
Property of a scaled random variable
In various applications and theoretical analysis of random processes, it is necessary to deal with
random variables that arise from linear combinations of other RVs. For this purpose, consider a RV
Y = a +
M
X
i=1
bi Xi = a + bTX
(7.16)
where
b =
f
b1
b2
· · ·
bM
gT
X =
f
X1
X2
· · ·
XM
gT
Then, the ﬁrst- and second-order properties of Y can be expressed in terms of the properties of the
originating RVs as follows (see Exercise):
µY = a + bT µX
var(Y) = σ2
Y = bT ΣXb
(7.17a)
(7.17b)
where ΣX known as the covariance matrix is the multivariate analogue of the variance (to be deﬁned
in the following section).
In closing this section, it is useful to learn the reasons for the special place and the ubiquity that
Gaussian distribution occupies in time-series analysis and identiﬁcation.
Properties of Gaussian distributed variables
There are three important reasons that give the distribution its special place:
1. The Gaussian distribution is completed characterized by the ﬁrst two moments (mean and vari-
ance).
2. A linear combination of Gaussian random variables also possesses a Gaussian distribution,
If X1, X2,· · · , XM are uncorrelated normal variables, then a linear combination of these variables
also has a Gaussian distribution,
Y = b1X1 + b2X2 + · · · + bM XM ∼N (µY,σ2
Y )
where
µy = b1µ1 + b2µ2 + · · · + bM µM
σ2
y = b2
1σ2
1 + b2
2σ2
2 + · · · + b2
Mσ2
n
Generalizing the above result, we have for a M × 1 vector RV X possessing a joint normal
distribution with mean µX and covariance matrix ΣX, the linear transformation Y = A + BX has
a joint Gaussian distribution with mean and variance (see Exercise (E7.16.)):
µY = A + BµX;
ΣY = BΣXBT
(7.18)
where A and B are matrices of appropriate dimensions, while µX and ΣX are the mean and
covariance matrix of the random variable vector X (see the next section for deﬁnitions).

Random Processes
163
3. Central Limit Theorem: The theorem is a further generalization of the result above. A full state-
ment of this theorem is given in §13.11. Summarily it states that a linear combination of a large
number of independent random variables X1,· · · , XM tends to have a Gaussian distribution as
M →∞. This is one of the classical results in statistics. It is widely used to derive distributions
of parameter estimates. One of the popular applications of the CLT is in deriving the distribution
of sample mean, which is simply the average of series data. See §13.11 for a formal statement.
The statistical descriptions of scaled random variables and the central limit theorem above involve
multivariate versions of mean and variance. The following section provides deﬁnitions and interpre-
tations of these quantities, however, in a broader context.
7.4.2
MULTIVARIATE CASE
In the analysis of several statistical events and random signals we will be required to analyze two
or more variables simultaneously. Of particular interest would be to examine the presence of linear
dependencies, develop linear models and predict one RV using another set of random variables. It
is instructive to begin with the bivariate case, i.e., analysis of a pair of random variables.
Where analysis of more than one variable is concerned, the notion of joint probability density
functions sets in. The joint p.d.f. governs the probability of two RVs taking on values within a
rectangular cell in the 2-D real space (e.g., height and weight of an individual, temperature and
pressure of a gas).
Joint probability density function
Consider two continuous-valued random variables X and Y. The probability that these variables
take on values in a rectangular cell is given by
Pr(x1 ≤x ≤x2, y1 ≤y ≤y2) =
Z y2
y1
Z
x2
x1
f (x, y) dx dy
The joint bivariate Gaussian distribution of Z =
f
X
Y
gT is given by
f (x, y) =
1
(
√
2π)2|ΣZ|−1/2 exp
 
−1
2 (Z −µZ)T Σ−1
Z (Z −µZ)
!
(7.19)
where µZ and ΣZ are the mean and covariance matrix of Z, respectively. For deﬁnition of covariance
and covariance matrix, see Section 7.4.2.1.
In the probabilistic analysis of two variables, two questions frequently arise:
1. What is the probability Pr(x1 ≤X ≤x2) regardless of the outcome of Y and vice versa?
(marginal density)
2. What is the probability Pr(x1 ≤X ≤x2) for a given outcome of the other variable Y = y2?
(conditional density)
Answers to these questions, as explained below, provide a valuable set of tools for multivariate data
analysis.
Marginal density and independence
The marginal density is arrived at by evaluating the probability of the variable of interest over the
ensemble space of the “free” variable.

164
Principles of System Identiﬁcation: Theory and Practice
Deﬁnition 7.3. The marginal density of a RV X in the context of another RV Y is given by
f X (x) =
Z
EY
f (x, y) dy
(7.20)
where EY is the ensemble space of variable Y.
Likewise,
fY (y) =
Z
EX
f (x, y) dx
(7.21)
The marginal densities can be used to compute probabilities associated with individual RVs and
conditional probabilities.
Two random variables are said to be independent if the probability of joint occurrence is the
product of individual probabilities. Mathematically this is possible if and only if the joint density is
product separable.
f (x, y) = f (x) f (y)
(Independence)
(7.22)
Conditional density
The conditional density is used to evaluate the conditional probability, i.e., the probability of one
event given the occurrence of another event. For example, what is the probability that a tourist will
carry an umbrella given that it will rain?
The conditional density function of Y given X = x is
fY |X=x(y) = f (x, y)
f (x)
(7.23)
If X and Y are independent, the conditional density is the marginal density of Y (independent of X).
The reverse is also true.
Conditional expectation
The conditional expectation of Y given X = x is
E(Y |X = x) =
Z
EY
y fY |X=x(y) dy = φ(x)
(7.24)
with a slight abuse of notation X = x (inappropriate for a continuous-valued RV). However, this
is done to merely indicate that the conditional expectation E(Y |X) is purely a function of the con-
strained variable X. A more appropriate way of reading X = x is that X is within very close vicinity
of x.
When X and Y follow a joint Gaussian distribution, it can be shown that the function φ(x) is a
linear function of x (see Exercise).
The conditional density and conditional expectation are invaluable tools in prediction theory
because in making predictions, we are always interested in determining the value of Y given another
RV X. A cornerstone result in prediction theory (to be established in Chapter 18) is that
The conditional expectation is the best predictor of Y given X among all the (non-linear) pre-
dictors that minimize the mean square prediction error.

Random Processes
165
A useful result involving conditional expectations is that of iterative expectation,
EX (EY (Y |X)) = E(Y);
EY (EX (X|Y)) = E(X)
(7.25)
Note that in evaluating the inner expectation, the quantity that is ﬁxed is treated as deterministic.
The outer expectation essentially averages the inner one over the outcome space of the ﬁxed inner
variable.
In the following section, we examine the most fundamental tool in linear multivariable data
analysis, namely, covariance (and correlation). A careful study of these topics is critical to under-
standing the subject of identiﬁcation.
7.4.2.1
Covariance and Correlation
One of the most intriguing and useful questions in bivariate analysis and prediction theory is if (the
outcomes of) two random variables inﬂuence each other. In particular, we would like to know if the
variability in X is connected to the variability in Y and vice versa.
The statistic that measures the co-variance between two RVs is given by
σXY = E((X −µX)(Y −µY )) =
Z +∞
−∞
Z +∞
−∞
(x −µX)(y −µY ) f (x, y) dx dy
(7.26)
Covariance is the second-order property of the joint p.d.f. It can be further re-written as,
σXY = E((X −µX)(Y −µY )) = E(XY) −E(X)E(Y)
(7.27)
Clearly, if Y = X, we obtain variance of X, the spread of outcomes of X. Thus, covariance is a
measure of joint spread of X and Y.
Covariance in parameter estimation
Covariance is central to all linear model parameter estimation problems. It has a strong connection
with the least squares estimation of a linear model as illustrated below.
Example 7.10: Covariance and Least Squares Estimation
Consider ﬁtting a linear model (predictor) ˆY = αX + β with the following criterion of ﬁt
min
α,β J(α, β) = min
α,β E((Y −ˆY)2)
(7.28)
Assume E(X) = 0 for simplicity. The solution is obtained by the standard procedure
∂J
∂α = −2E(Y X) + 2αE(X2) = 0
∂J
∂β = −2E(Y) + 2β = 0
The optimal parameter estimates are
ˆα⋆= σY X
σX X
;
ˆβ⋆= E(Y)
(7.29)
The same result can be obtained using the projection theorem (see Chapter 14). Note that when
σ2
X = 1, ˆα⋆= σY X.

166
Principles of System Identiﬁcation: Theory and Practice
Covariance of vector quantities
The measure can be extended to a vector of random variables in a straightforward manner to obtain
a variance-covariance (or simply covariance) matrix.
For a vector of random variables,
X =
f
X1
X2
· · ·
XN
gT
the covariance matrix is given by
ΣX = E((X −µX)(X −µX)T )
(7.30)
=

σ2
X1
σX1X2
· · ·
σX1XN
σX2X1
σ2
X2
· · ·
σX2XN
...
· · ·
· · ·
...
σXN X1
σXN X2
· · ·
σ2
XN

(7.31)
The diagonal of ΣX contains variance of individual RVs while the oﬀ-diagonals contain covariance
between a pair of RVs.
The variance-covariance matrix is one of the most widely encountered quantities in identiﬁca-
tion. In parameter estimation, the variance-covariance matrix of parameter estimates is useful for
constructing conﬁdence intervals of parameters. The computation of this matrix uses the residual
(prediction error) covariance matrix. The variance-covariance matrix of the regressors plays a cru-
cial role in parameter estimation and input design.
Below, we mention some useful properties of covariance:
i. Covariance is a symmetric measure: σXY = σY X, i.e., it is not a directional measure. Conse-
quently it cannot be used to sense causality (cause-eﬀect relation).
ii. The covariance matrix ΣX is a symmetric, positive semi-deﬁnite matrix =⇒λi(ΣX) ≥0 ∀i.
iii. Linear transformation of the random variables Z = AX produces
ΣZ = E((Z −µZ)(Z −µZ)T ) = AΣXAT
(7.32)
iv. Most importantly, covariance is only a measure of linear relationship between two RVs:
When σXY = σY X = 0, there is no linear relationship between X and Y.
v. Covariance is sensitive to the choice of units for the random variables under investigation (not
scale-invariant).
vi. It is not a bounded measure, meaning it is not possible to infer the degree of the strength of the
linear relationship from the value of σXY.
To overcome the last two issues mentioned above, a normalized version of covariance known as
correlation is introduced.
Correlation
Correlation is the normalized covariance:
ρXY = σXY
σXσY
(7.33)
It is one of the most widely used measures in signal (data) analysis1.
1Other correlation measures namely, Spearman’s rank correlation and Kendall’s tau-rank correlation, also exist, but this
is most popular.

Random Processes
167
Note: In signal processing, the term correlation is used to refer to covariance in statistics but computed without
removal of mean whereas normalized correlation refers to the correlation (w/o removal of mean) in statistics.
Correlation inherits all the properties of covariance, i.e., invariant to direction of analysis, sym-
metricity and ability to detect linear relationships. A correlation matrix similar to the covariance
matrix in (7.31) can also be deﬁned. The boundedness of correlation is supported by the following
result.
Theorem 7.1
For all bivariate distributions with ﬁnite second-order moments, correlation is a bounded measure
|ρXY | ≤1
(7.34)
When the equality holds, it implies that with probability 1, Y = αX + β.
Proof. The result can be proved using Chebyshev’s inequality (Priestley, 1981).
□
When σXY = 0 = ρXY, X and Y have no linear relationship (non-linear relationship cannot be
detected). The variables are then said to be uncorrelated.
Alternatively, since σXY = E(XY) −E(X)E(Y), the condition also implies
E(XY) = E(X)E(Y)
(Uncorrelated)
(7.35)
The average of product of random variables is the product of averages.
Uncorrelated condition merely rules out the presence of linear relationship between X and Y.
Determining the absence of non-linear dependencies requires the test of independence.
Independence vs. uncorrelatedness
Compare Equation (7.22) with (7.35). Independence requires the separability of joint density
whereas uncorrelated condition requires separability of “joint” expectation (expectation of product
of variables). The ﬁrst implies the second and not vice versa (see an important exception below).
Naturally so, since absence of non-linear relationships implies absence of linear dependence as well
but not the reverse. Thus, independence is a stronger requirement.
Two uncorrelated random variables X and Y are also independent only when they jointly fol-
low a Gaussian distribution. In other words, when f (x, y) is bivariate Gaussian, independence and
uncorrelated conditions are equivalent (see Exercise E7.13.). This result once again reiterates the
advantages of assuming a Gaussian distribution.
We now establish a connection between conditional expectation and covariance.
Conditional expectation and uncorrelatedness
From (7.24), the conditional expectation E(Y |X) is a function of x. Intuitively, if there is a rela-
tionship between Y and X, the conditional expectation should be expected to be diﬀerent from the
unconditional expectation.
The following result is relevant to the discussion.
Theorem 7.2
Two variables are uncorrelated if and only if E(Y |X) = E(Y).

168
Principles of System Identiﬁcation: Theory and Practice
Proof. The forward result can be proved using iterative expectation,
σXY = E(XY) −E(X)E(Y)
= EX (EY (XY |X)) −E(X)E(Y)
= EX (XEY (Y |X)) −E(X)E(Y)
= E(X)E(Y |X) −E(X)E(Y)
= 0
□
Remarks:
The result is similar to that for independence: f (y|x) = f (y).
Having understood the full implications of ρXY = 0 and |ρXY | = 1, we study the implications
of |ρXY | < 1. This is perhaps the most important one to know since no process is truly linear.
Implications of |ρXY | < 1
For the purposes of discussion, consider a RV
Y = αX + ϵ
Assume that (i) µϵ = 0 =⇒µY = αµX and (ii) ϵ and X are uncorrelated, i.e., there is nothing in ϵ
that can be explained by a linear function of X.
Then,
σ2
Y = α2σ2
X + σ2
ϵ
The variability in Y is due to variability in X as well as in ϵ.
Evaluating the correlation between X and Y gives
ρXY = E(XY) −E(X)E(Y)
σXσY
= α(E(X2) −E(X)2)
|α|σ2
X
r
1 +
σ2ϵ
α2σ2
X
= ±
1
s
1 +
σ2
ϵ
α2σ2
X
(7.36)
Thus, whenever Y contains an additional component that X cannot explain (linearly), the correlation
falls below unity. The factor γ2 = (α2σ2
X)/σ2
ϵ completely determines |ρXY |, i.e., to what extent a
linear model (in terms of X) can explain Y.
Two diﬀerent scenarios arise depending on the source of ϵ:
i. When ϵ represents merely the measurement error in Y, the factor γ2 is known as the signal-to-
noise ratio (SNR). Thus, even when the true relationship is linear, SNR can cause a signiﬁcant
drop in the correlation. In fact, as SNR →0, ρY X →0. The linear relationship is then completely
drowned in noise.
ii. When ϵ represents the non-linearities and other factors that are uncorrelated with X, the factor
γ2 is the ratio of variance-explained to the variance of prediction-error. Once again when σ2
ϵ ≫
α2σ2
X, ρY X ≈0.
In practice, ϵ contains both unexplained eﬀects (modeling errors) and noise. It is not trivial to
distinguish the individual contributions, but the net eﬀect is a drop in the correlation. The point in
case is that correlations should be interpreted with great care.

Random Processes
169
Limitations and pitfalls of correlation
Correlation is the most widely used tool in data analysis; at the same time, it is also vulnerable to
abuse if not interpreted properly. The following points may always be remembered to avoid any
unwarranted inferences using this measure:
Remarks:
a. Correlation is only a mathematical measure. It does not take into account any physics of the process that
relates X to Y.
b. High values of correlation only mean that a linear model can be constructed between X and Y. It does not
necessarily mean that in reality there exists a linear process that relates X and Y. The high correlation could
also be because the experimental conditions only triggered the linear characteristics of the process.
c. Correlation cannot detect the direction of relationships (due to its symmetricity).
d. Absence of correlation only implies that no linear model can be ﬁt. Even if the true relationship is linear,
the measurement noise can be high, thus limiting the ability of correlation to detect the underlying linearity.
7.4.3
PARTIAL CORRELATION
Covariance or correlation, as we have learnt, is a very useful tool in highlighting the linear de-
pendences between a pair of variables. An important fact that calls for attention in interpreting
correlation is confounding, which is essentially the manifestation of spurious relationship between
two variables due to the inﬂuence of a common third variable(s). Figure 7.3 depicts the situation
that leads to confounding and also the one that emerges after what is known as conditioning. Cor-
relation measures the total (direct and indirect) dependence between X and Y along all pathways.
The problem of interest is to determine the correlation along the direct pathway.
Z
X
Y
direct link
confounding 
variable
Z
X.Z
Y.Z
conditioning
FIGURE 7.3
(SEE COLOR INSERT) Schematic illustrating confounding and conditioning.
The following example theoretically demonstrates the concept of confounding.
Example 7.11: Confounding
Consider two random variables X = 2Z +3W and Y = Z +V where V, W and Z are zero-mean
RVs. Further, it is known that W and V are uncorrelated with Z as well as among themselves,
i.e., σVW = 0.
Evaluating the covariance between X and Y yields
σY X = E((2Z + 3W)(Z + V))
= 2E(Z2) = 2σ2
Z , 0
It is clear, on the other hand, that in the absence of Z, Y and X are uncorrelated (since W
and V are uncorrelated).
Thus, Y and X “appear” to be correlated purely because of the common eﬀect of another
variable Z. Essentially, Z is tying together Y and X.

170
Principles of System Identiﬁcation: Theory and Practice
To resolve confounding, one needs to compute the direct correlation between Y and X. In other
words, the eﬀects of Z have to be discounted in both Y and X. The correlation between discounted
variables is termed as partial correlation. This process of discounting for the eﬀects of confounding
variables is known as conditioning. With respect to the example above, the conditioned variables
denoted by X.Z and Y.Z thus no longer contain the eﬀects of Z, as shown in Figure 7.3. It is
instructive to imagine partial and total correlation as analogues of partial and ordinary derivatives,
respectively, in calculus.
Partial correlation diﬀers from ordinary correlation in only one respect, which is that it computes
correlation between discounted or conditioned variables whereas the latter computes correlation
among “raw” variables.
Mathematically, partial covariance is denoted by σY X.Z
σY X.Z = cov(Y, X|Z) = E((Y −µY )(X −µX)|Z)
(7.37)
Remarks:
The concept of conditioning or partial measures is not merely restricted to the world of correlation.
It can be equally applied to non-linear measures of dependence such as mutual information, transfer entropy,
etc. and frequency domain measures such as spectra and coherency as well.
Computation of partial correlation
The partial correlation is computed using the following procedure:
i. Obtain the optimal predictions of Y and X using Z. Denote them by ˆY⋆(Z) and ˆX⋆(Z), respec-
tively.
ii. Construct the conditioned variables, which are the residuals
ϵY .Z = Y −ˆY⋆(Z);
ϵ X.Z = X −ˆX⋆(Z)
(7.38)
An important requirement is that the residuals should be completely devoid of any linear eﬀects
of Z. Mathematically,
cov(ϵY .Z, Z) = 0;
cov(ϵ X.Z, Z) = 0
(7.39)
It turns out that predictions using least squares method produce residuals that satisfy the above
requirements (see Chapter 14, LS methods produce residuals that are orthogonal to the space of
explanatory or regressor variables). Thus, the predictors in (7.38) are the least squares predic-
tions.
iii. Compute the partial covariance and partial correlation as
σY X.Z = cov(ϵY .Z,ϵ X.Z)
(7.40)
ρY X.Z =
σY X.Z
√var(ϵY .Z)var(ϵ X.Z)
(7.41)
Following the procedure above and using the result from Example 7.10, a general expression for the
partial correlation can be provided (see Exercise E7.15.)
ρY X.Z =
ρY X −ρY Z ρZ X
q
(1 −ρ2
Y Z)
q
(1 −ρ2
Z X)
(7.42)
Observe that when ρY Z = 0 = ρZ X, partial correlation reduces to ordinary correlation as ex-
pected. The deﬁnition in (7.42) can be easily extended to the case of vector Z as well (see Priestley
(1981) for example).

Random Processes
171
Example 7.12: Partial Correlation
Compute the partial correlation between Y and X in Example 7.11.
Solution: First use (7.36) to compute
ρY X =
σ2
Z
(σ2
Z + σ2
Y )(4σ2
Z + σ2
W )
;
ρY Z =
1
v
t
1 +
σ2
V
σ2
Z
;
ρX Z =
1
v
t
1 +
σ2
V
4σ2
Z
;
Next, applying (7.42), it is easy to see that
ρY X.Z = 0
which agrees with our observation. Having removed the eﬀects of Z from X and Y, there is
nothing in X and Y that correlates them directly.
Uses of partial correlation
Partial correlation ﬁnds several applications in multivariable data analysis. In time-series analysis,
partial auto-correlation functions built on these concepts are used in determining the order of auto-
regressive models (cf. Chapter 8). The partial cross-correlation function and its frequency-domain
counterpart, known as partial coherency function, ﬁnd good use in time-delay estimation (see Chap-
ter 20). In model-based control applications, partial correlations are used to quantify the impact of
model-plant mismatch in model-predictive control applications (see Badwe et al. (2009, 2010) for
example).
This brings us to the conclusion of the requisite review of the random variables. An interested
reader is referred to texts purely devoted to the theory of random variables.
7.5
RANDOM SIGNALS AND PROCESSES
This section is devoted to the concepts of discrete-time random signals and processes, particularly
the notions of realization, stationarity and ergodicity.
As a motivational example, consider the measurements of four diﬀerent physical variables,
namely, temperature measurement from an industrial control loop, wind speed in a particular ge-
ographical region, daily closing prices of Switzerland stock market index during the years 1991-
19982 and the electrocardiogram (ECG) of a patient, shown in Figure 7.4. The variations in these
signals cannot be completely or accurately explained by any known mathematical function nor can
one identify causes that can accurately explain the variations. As in the case of random variables,
we take recourse to probability theory. The probabilistic approach is to predict possible evolution
trajectories and then associate chances for each of those outcomes. This constitutes the basic idea
in random signal analysis.
The development begins with the deﬁnition of a random signal.
7.5.1
DEFINITIONS
Deﬁnition 7.4. A (discrete-time) random signal is a function x[k] whose characteristics cannot be
accurately described by any existing mathematical function. At each point, it is characterized by a
probability distribution.
2Source: Dataset EuStockMarket in the software package R, a freely available language and environment for statistical
computing and graphics.

172
Principles of System Identiﬁcation: Theory and Practice
500
1000
1500
2000
2500
12
14
16
18
20
22
24
Time
Temperature
(a) Temperature measurement
0
5
10
15
20
25
30
0
1
2
3
4
5
6
7
8
9
10
Time (days)
Amplitude
(b) Wind speed readings
0
2
4
6
8
10
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
Time (sec)
Amplitude
(c) ECG recordings
1991
1992
1993
1994
1995
1996
1997
1998
1999
1000
2000
3000
4000
5000
6000
7000
8000
9000
Time (years)
Swiss Market Index
(d) Swiss stock market index
FIGURE 7.4
Examples of univariate random signals.
An alternative deﬁnition that is more amenable for analysis follows.
Deﬁnition 7.5. A (discrete-time) random signal
x = {x[1], x[2],· · · , x[k], x[k + 1],· · · }
is an index-ordered sequence of random variables in the temporal and/or spatial and/or frequency
domain. Its characteristics can only be described by probabilistic laws and not merely by mathemat-
ical models.
The essence is that we cannot predict the evolution of a random signal accurately and that at any
instant the observed value is one of the many possible values.
In a similar way, a continuous-time random signal can be deﬁned. The values themselves could
be continuous or discrete. We are concerned with continuous-valued, discrete-time signals.
The signals shown in Figure 7.4 are only representatives of the numerous types of random signals
encountered in every ﬁeld. These signals can be even two-dimensional (e.g., electron microscopy
images, satellite images) or three-dimensional (e.g. computed tomography) in nature.
Practically any signal can be treated as random because of measurement uncertainties or / and
incomplete process knowledge.
Implication of randomness in signals
In using the term “randomness,” it is important to pay attention to two key facts. The ﬁrst one is that
a random signal cannot be accurately predicted. This does not completely rule out the possibility of
prediction; rather it implies that it is possible to predict a random signal, but always with < 100%
conﬁdence. Indeed the signals in Figure 7.4 have certain predictable patterns that can be discerned
even by visual inspection. However, these measurements also contain variations that are beyond
the reach of mathematical functions, which is the reason for their random nature. The second fact is
about comprehending the source of randomness. The origins of “randomness” are not in the process,

Random Processes
173
rather it is in our ignorance of the underlying physics and the associated causes. Furthermore, even
when the causes are identiﬁed, it is highly likely that we are unable to measure them (e.g., change
in administrative policies). There are also those situations where we are able to measure the causes
but the measurements are not accurate (due to measurement uncertainties).
Two examples below highlight these facts.
Example 7.13: Steam Heated Fluid
In an energy recycling scheme, the steam generated upstream is used to heat a reactant
entering a downstream reactor. To improve the eﬃciency, a process engineer sets out to de-
termine the relationship between the temperature and pressure ﬂuctuations of the steam
ﬂow and the reactant temperature from their measurements. The temperature observations
constitute a random signal due to the sensor noise, random variations in the heat transfer
coeﬃcients across the pipeline, etc. Further the major causes of changes in reactant temper-
ature are also random once again due to sensor noise, uncontrollable random variations in
the upstream process and so on.
Example 7.14: Stock Market Price
Consider the problem of predicting the stock market price of a certain stock. The ﬁrst dif-
ﬁculty in predicting this variable is the lack of a complete knowledge of the factors that
inﬂuence the stock price. Even if we were able to enlist all the factors, one or more of them
may not be measurable (for example, political situation, market competition).
In Example 7.13, note that even if the causal variables are deterministic (accurately known),
measurement and modeling errors lead to inaccurate predictions. In system identiﬁcation, these
errors are collectively lumped into a single random signal.
Time-series
The term time-series is traditionally used to denote a ﬁnite collection of ordered observations.
x =
f
x[1]
x[2]
· · ·
x[N]
gT
These observations could be originating from a random or a deterministic process or a mix of both.
The subject of analysis of random signals (and the random processes) has been traditionally
termed as time-series analysis or random (stochastic) signal processing. The central problem of
interest in time-series analysis is time-series modeling.
7.5.2
NOTION OF REALIZATION
The notion of realization is central to the theory of random signals and also explains one of the key
challenges in time-series analysis.
A single time-series, as remarked above, is an ordered collection of observations. However, each
observation is only one of the many possibilities; as a result, a single record is only one of the
numerous possible sets of observations. For this reason, a ﬁnite length record of a random process
is said to be a realization of the process.
Example 7.15: Liquid Level Measurement
Consider a simple experiment of measuring liquid level in a storage tank. Neglecting all other
losses, the level is constant. A single time-series (record) is a consequence of using one sensor

174
Principles of System Identiﬁcation: Theory and Practice
to observe a process. Readings from three diﬀerent sensors are shown (the physical value
shown as dashed line).
FIGURE 7.5
Diﬀerent realizations of a ﬁxed liquid level.
Each sensor realizes the ﬁxed physical variable (level) in a diﬀerent manner. This is the
case with all measurements in practice.
As in the case of random variables, all possible realizations of a random signal constitute the
ensemble of that signal or process.
The typical situation is that only a single realization is available to the analyst. A key challenge
in analysis of random signals is to be able to infer the properties of the random process and build
models for the same from a single realization.
Two questions of paramount importance are:
1. How reliable are the estimates (of model parameters, statistical properties, etc.) from a single
realization?
2. Is a single estimate of the concerned statistic suﬃcient? The average of the readings from the
ﬁrst sensor is 13.972 cm. Measurements from the third sensor average to 13.975 cm. What can
be said about the true level?
Similar questions equally arise in non-engineering situations as well.
Example 7.16: News Report
The news report of an event includes the reporter’s own perception (realization). A reader of
diﬀerent newspapers should be able to obtain a good estimate of the truth from the reports
contained in the respective newspapers.
The central issue is thus to determine the conditions under which inferences drawn from a single
record of data are meaningful and useful? It turns out two conditions, namely, stationarity and
ergodicity, are fundamental to the usability of any inference / model built on a single realization.
These concepts are discussed in Sections 7.5.4 and 7.5.6.
Random process
The conventional deﬁnition of a random process is as follows:
Deﬁnition 7.6. The random process is the ensemble of the random signal x[k]. It is the collection
of all possible realizations of x[k].

Random Processes
175
A random process is thus a function of both the time and realization. We shall, however, for the
sake of convenience refer only to the time function part of it.
A simpler deﬁnition can be provided.
Deﬁnition 7.7. The process (or a subsystem) that generates a random signal is termed as the ran-
dom process.
The randomness is due to the lack of an accurate mathematical relationship that can describe
its evolution. Further, a random process is assumed to exist at all times (for mathematical conve-
nience) - the existence is not random. The phrases “random signal” and “random process” are used
interchangeably (no signal can exist without a generating process!).
A deterministic process on the other hand generates signals whose values are accurately known
(no uncertainty) and accurately predictable (completely understood). A deterministic signal there-
fore has only a single possible value at each instant, but that value can change with time though.
7.5.3
STATISTICAL PROPERTIES
In the statistical analysis of random signals (time-series), we are concerned with the statistical prop-
erty of each observation in the signal as well as the time-series (ﬁnite collection of observations).
The former depends on the p.d.f. of x[k], while the latter depends on the joint probability density
function of the set of observations.
For instance, the mean and variance of a random signal {x[k]} are deﬁned as
µk = E(x[k])
(7.43)
σ2
k = E((x[k] −µk)2)
(7.44)
while the covariance of a pair of observations is given by
σxx[k1,k2] = E((x[k1] −µk1)(x[k2] −µk2))
(7.45)
A key point to note is that both the statistical property of each observation as well as the series can
change with time(s) (or the domain) of observation. When all the statistical properties of a signal
remain invariant with time, the signal is said to be stationary (see Section 7.5.4 below).
A common misconception
A common perception is that the mean of a random signal is the average of the ﬁnite-length obser-
vations, i.e., the sample mean,
¯x = 1
N
N
X
k=1
x[k]
(7.46)
It would be a grave mistake to believe so. The sample mean above is only an estimator of the
theoretical mean of the signal, even so under the assumption that the true mean in (7.43) is invariant
with time. There exist several other estimators of the true mean, for example, the median.
The above remark applies to every property of the random signal. Statistical properties of signals
are, in general, functions of time, but not deﬁned across time. Their deﬁnitions are always in the
ensemble space. Thus, the mean of a signal is deﬁned with respect to all possible values at a single
instant but not along all possible values across time.
By the same token, it should not be construed that deterministic signals do not possess properties
such as mean, variance and so on. As a matter of fact, for these class of signals, the properties are

176
Principles of System Identiﬁcation: Theory and Practice
deﬁned in terms of observations for the entire duration of their existence. For example, the mean
and variance of a deterministic signal u[k] (if it exists) are deﬁned as
¯u = lim
N→∞
1
N
N
X
k=1
u[k]
(7.47a)
s2
u = lim
N→∞
1
N
N
X
k=1
(u[k] −¯u)2
(7.47b)
Section 10.2 extends deﬁnitions of other properties such as covariance to the class of deterministic
signals.
Returning to the world of random signals, an important requirement in data analysis is that es-
timates from data observed over a time period should be useful and applicable to the analysis of
the process at a diﬀerent time period. Intuitively, a model built from a given set of observations is
useful only if the probability structure remains invariant with time. In the deterministic case as well
a similar condition is implicitly required. An empirical model is valid at all times if the operating
conditions are “similar” and the process is time-invariant. These ideas motivate the requirement of
stationarity.
7.5.4
STATIONARITY
Deﬁnition 7.8. A random process is said to be strictly stationary if all of its statistical properties
remain invariant to shifts in time. This is to say that the joint p.d.f.
f (x[1], x[2]. · · · , x[N]) = f (x[T + 1], x[T + 2],· · · , x[T + N])
for all T, N ∈Z+.
Signals that do not satisfy the stationarity condition are said to be non-stationary.
The stationarity condition essentially requires that the p.d.f. of every sample remains invariant
with time (by setting N = 1 in the deﬁnition). It is equivalent to the requirement of a “steady-
state” on the statistical properties.
.
In reality, rarely does a process exist that satisﬁes the strict requirements of stationarity deﬁned
above. Equally diﬃcult it is to verify if a process satisﬁes this requirement. Observe that to verify
stationarity one needs to know the statistical moments (ensemble averages) at every instant in time.
This is an extremely impractical task to carry out. A feasible alternative is to compute time-averages
over “short” segments of the signal and test for their invariance with respect to time. An assumption
implicit to this approach is that the time-average is a suitable representative of the ensemble average.
This is the condition of ergodicity (see below).
Figure 7.6 shows plots of three real-life series from three diﬀerent domains. The ﬁrst one corre-
sponds to the tree-ring counts (an indicator of environmental changes). The second series is associ-
ated with the manipulated variable of an industrial ﬂow loop, while the third series corresponds to
the number of airline passengers over the period 1949-19603. A visual inspection clearly dismisses
the third time-series as being stationary. The second series is stationary, but has an inherent peri-
odicity. Finally, the tree-ring series “appears” to be stationary. These are crude conclusions based
on visual examinations. Rigorous statistical tests are available to test the hypothesis of stationarity.
However, all these approaches rely only on a single record and therefore do not test stationarity in
the true sense.
3Source: The dataset AirPassengers from the software package R (R Core Team, 2014)

Random Processes
177
100
150
200
250
300
350
0.0
0.5
1.0
1.5
Years
Treering
(a) Stationary
0
500
1000
1500
2000
-100
-50
0
50
100
Time
Flow
(b) Stationary, Periodic
Time
AirPassengers
1950
1952
1954
1956
1958
1960
100
200
300
400
500
600
(c) Non-stationary
FIGURE 7.6
(SEE COLOR INSERT) Examples of stationary and non-stationary time-series.
Weak stationarity
The requirement of strict stationarity is similar to the strict requirement of time-invariance or lin-
earity for deterministic processes, which are also academically convenient assumptions but rarely
satisﬁed in practice.
Although no process in reality remains the same with the passage of time, we assume that the
forecasting or the analysis time-scales are short enough to deem the changes insigniﬁcant.
Earlier we had noted that for linear processes the ﬁrst two moments (of the joint p.d.f.) are of
prime interest. With this motivation, we can settle for a relaxed requirement as stated below.
Deﬁnition 7.9. (Weakly Stationary Process) A random process x[k] is said to be weakly stationary
or wide-sense stationarity if it satisﬁes the following:
C1. µk = E(x[k]) = µ ∀k. The mean is invariant with time.
C2. σ2
k = E((x[k] −µ)2) = σ2 < ∞. The process should have ﬁnite variance.
C3. The covariance between any pair of observations (known as the auto-covariance function
(ACVF), see Chapter 8 for deﬁnition)
σxx[k,l] = E((x[k] −µ)(x[k −l] −µ)) = σxx[l]
of the process is only dependent on the time distance (lag) betwen samples, l, but not on time.
Since the deﬁnition is based on second-order properties, a weakly stationary process is also
referred to as a second-order stationary process. It is possible of course to deﬁne third- and higher-
order stationary processes by requiring the appropriate statistical properties to be invariant with
time.
To illustrate the fact that only second-order properties participate in linear modeling, consider
the following example of ﬁtting an auto-regressive model.
Example 7.17: Second-Order Properties in Modeling
The auto-regressive (AR) model is a popular linear model for predicting the course of a
random process (time-series). It is desired to ﬁt a ﬁrst-order AR model to a zero-mean series
x[k]. An AR(1) model forecasts the series as a linear function of its immediate past,
ˆv[k] = −a1x[k −1]
(7.48)
where the parameter a1 is adjusted to obtain as close a ﬁt as possible. A popular choice is to
minimize the variance of prediction errors,
min
a1 J(ak ) = min
a1 E((x[k] −ˆx[k])2) = min
a1 E((x[k] + a1x[k −1])2)

178
Principles of System Identiﬁcation: Theory and Practice
The optimal estimate is obtained by solving dJ
dak
= 0
2E(x[k]x[k −1]) + 2a1E(x2[k −1]) = 0
(7.49)
=⇒a⋆
1 = −σxx[1]
σ2x
(7.50)
Thus, as long as only the covariance at lag 1 and the variance of the series are invariant with
time, the model parameter needs no update.
The requirement of second-order stationarity is not only theoretically suﬃcient for linear pro-
cesses, but is also a practically meaningful condition in general. Several decision making tasks
largely make use of second-order statistical properties since they can be easily estimated.
The concept of weak stationarity can be extended to the class of composite (random plus de-
terministic) signals. Termed as quasi-stationarity and deﬁned in Section 17.3, it is a very useful
concept in system identiﬁcation and in general analysis of signals consisting of both deterministic
and random eﬀects.
Strict stationarity implies weak stationarity but not vice versa, evidently from the deﬁnitions.
However, second-order stationarity guarantees strict stationarity in the special case of random pro-
cess following a joint Gaussian distribution. This claim is easily supported by the fact that joint
Gaussian p.d.f. (7.19) requires only the knowledge of ﬁrst- and second-order moments.
Models built on the assumptions of weak stationarity and Gaussianity are idealistic and are often
criticized for not capturing the realistic behavior of the actual process. However, literature and re-
search have shown that these “simple” models suﬃce in several cases and with some modiﬁcations,
the scope of their applicability can be enhanced. Moreover, understanding the theory built on these
assumptions and the type of models that describe such processes are greatly useful in modeling real
world processes.
7.5.5
NON-STATIONARITIES
As we remarked earlier, stationarity is largely an idealization of the reality just as the way linearity
is an idealization of the non-linear world. No process exists whose statistical properties remain
invariant with time. However, the theory built on stationarity assumption makes the mathematics of
modeling convenient and also allows us to describe a large class of non-stationary processes with
stationary models on transformed variables (just as non-linear systems can be described by linear
models built on transformed data).
A simple example of non-stationary process is that of a sinusoid with random phase.
Example 7.18: A Non-Stationary Process
Consider the random signal
x[k] = Acos(ωk + φ)
(7.51)
where φ is a random variable with uniform distribution in [0,π].

Random Processes
179
The mean of this signal (process) is
E(x[k]) = E(Acos(ωk + φ))
= A
Z π
0
cos(ωk + φ) f (φ) dφ
= A
π
Z π
0
cos(ωk + φ) dφ
= A
π

sin(ωk + φ)|π
0

= −2A
π sin(ωk)
which is a function of time.
Thus, the process is non-stationary.
It is of interest to note that when the range of φ is [−π,π], the process is wide-sense stationary, i.e.,
it satisﬁes all the conditions outlined in Deﬁnition 7.9.
Example 7.18 above presents a mean non-stationary process. Variance non-stationarities are com-
monly encountered in econometrics and ﬁnancial systems. In general, a process can be time-varying
(non-stationary) with respect to one or more moments, the most inclusive case being that of time-
varying p.d.f.. Therefore, we could have a process which is stationary in mean, but non-stationary
in variance and so on. The SMI series of Figure 7.4(d) is both mean and variance non-stationary as
will be discussed shortly. The ECG data in Figure 7.4(c), on the other hand, is known to contain
periodicities and are aptly described by non-linear time-series models.
Non-stationarities are broadly classiﬁed into two categories, namely, deterministic and stochastic
non-stationarities depending on whether the changes in statistical properties are deterministic or
stochastic functions of time, respectively. Examples of the deterministic class include trend-type,
periodic (both corresponding to mean shifts) and variance non-stationary signals. In the stochastic
class we have the integrating (random walk), stochastic periodicity and conditional variance as
prominent examples.
The purpose of this section is to highlight two commonly encountered types of non-stationarities,
namely, (i) trend type and (ii) integrating type (random walk), and to give an outline of the ideas
to deal with them. Periodic types of non-stationarities are either handled as sinusoids embedded
in noise or as harmonic processes. Section 11.2.2.1 discusses the technicalities of this topic. Engi-
neering systems often present integrating type non-stationarities when compared to the other types.
Econometric, climatic and ﬁnancial processes, on the other hand, present both trend and integrat-
ing types on a similar footage. Development of time-series models that incorporate the integrating
eﬀects appears in Chapter 9.
Trend-type non-stationarities
When the changing mean can be modeled as trends, for example, a linear or a parabolic trend, we
have trend-type non-stationarities. Recall Figure 7.6(c) that displayed the airline passenger series.
From a visual inspection, it is clear that the series is dominated by a trend type pattern. Upon removal
of trend if the residual exhibits stationarity, the random process is known as a trend stationary
process. Models of these processes consist of a polynomial (time trend) component plus a stationary
model of the residuals. A suitable mathematical model for these processes is,
x[k] = µk + w[k]
(7.52)
where µk is a polynomial function of time and w[k] is a stationary signal. For example, a linear
trend is modeled as µk = a + bk.

180
Principles of System Identiﬁcation: Theory and Practice
In general, trends can be ﬁt by an explicit polynomial model or can be removed by the use of ap-
propriate smoothing ﬁlters on the series, the latter being a non-parametric approach. See Brockwell
(2002) for technical details on the diﬀerent types of ﬁlters available for this purpose. Removal of
trends from a series is known as detrending.
1949
1951
1953
1955
1957
1959
1961
−200
−100
0
100
200
Year
Residuals
1949
1951
1953
1955
1957
1959
1961
0
200
400
600
800
Airline passengers
Airline passenger series
 
 
FIGURE 7.7
Linear trend type non-stationarity (top) and the residuals (bottom).
Figure 7.7 shows the monthly airline passenger series shown earlier and the linear ﬁt to the
same. The residual series obtained from a linear polynomial ﬁt is shown in the bottom plot. It still
contains a non-stationarity of the “growth” type, which is usually handled by a log-transformation.
Stationarities of these types are nicely handled by a generalization of the stationary models known
as GARCH (generalized auto-regressive conditional heteroskedastic) models. These models fall
outside the purview of this text. The reader is encouraged to refer to texts purely devoted to this
subject matter (Shumway and Stoﬀer, 2006).
In general, the approaches that handle trend-type non-stationarities require the user to choose the
appropriate order of the polynomial or the smoothing ﬁlter by a trial-and-error approach. Addition-
ally, the ﬁlter parameters may have to be tuned to suit the application. An alternative approach is to
diﬀerence the time-series, which is primarily meant to handle the integrating-type non-stationarities.
Integrating-type non-stationarities
One of the most commonly encountered non-stationary processes is the random walk process (spe-
cial case of Brownian motion). The simplest random walk process is an integrating process,
x[k] =
k
X
n=0
e[k]
(7.53)
where e[k] is the (unpredictable) shock-wave or the (white-noise) aﬀecting the process at the kth
instant. The qualiﬁer integrating is a consequence of (7.53). At any instant the signal is the accu-
mulation of all shock-wave like changes from the beginning.
Observe that the random walk in (7.53) can also be written as
x[k] −x[k −1] = e[k]
(7.54)
indicating that the diﬀerenced series possesses a stationary behavior. For this reason, an integrating
process is also known as diﬀerence stationary process. A generalization of the random walk model
is
x[k] = x[k −1] + w[k]
(7.55)
where w[k] is a stationary signal.

Random Processes
181
0
50
100
150
200
−30
−20
−10
0
10
Amplitude
Original Series
0
50
100
150
200
−4
−2
0
2
4
Differenced Series
Time
Amplitude
FIGURE 7.8
Snapshot of an integrating process (top) and the diﬀerenced series (bottom).
An alternative description of this process is one that is characterized by stochastic trends, partic-
ularly of the drift with random walk type,
x[k] = µk + w[k]
(7.56a)
µk = δ + µk−1 + v[k]
(7.56b)
where both w[k] and v[k] are stationary signals and δ is a constant.
Figure 7.8 displays N = 200 samples of a random walk series in the top panel. The non-
stationarity can be easily discerned by a visual inspection. The plot at the bottom shows the dif-
ferenced series, which appears to be stationary.
It can be shown that a single degree of diﬀerencing eliminates a linear trend, second degree re-
moves a quadratic trend and so on. On the one hand, thus, this approach incorporates the polynomial
ﬁt approach. On the other hand, diﬀerencing the series is equivalent to subjecting the series through
a high-pass ﬁlter. Therefore, despite its capability in handling a wide range of stationarities, dif-
ferencing also has potentially detrimental eﬀects. In identiﬁcation, diﬀerencing can eliminate the
useful low-frequency content and highlight the noise content. The SNR of the resulting series is
thus, usually lower than that of the original one. Chapter 9 discusses the merits and demerits of the
diﬀerencing approach in greater detail.
In passing, it is worthwhile to note processes could be also characterized by what is known
as seasonality, which essentially introduces changes at the seasonal scale. The hourly wind speed
series in Figure 7.4(b) is an example of such a process. The series contains seasonality eﬀects at the
24 and 48 hour scales in addition to the hourly variations. Seasonality is easily detected by a spectral
analysis of the data. It is usually handled by an appropriate pre-processing or by explicitly including
the seasonal terms in the model. In the engineering arena. these characteristics are encountered in
multiscale systems, which are usually discussed in advanced texts. The reader is directed Brockwell
(2002) and Shumway and Stoﬀer (2006) for an exposition of this topic in the context of time-series
analysis.
We turn our attention to the second requirement on the process, namely, ergodicity.
7.5.6
ERGODICITY
For stationary processes, the second requirement on the time-series again stems from the fact that
in practice we work with only a single record of data. Essentially, data is obtained in time (or space
/ frequency), whereas the statistical properties are deﬁned in the space of outcomes (at any time).
The basic stipulation is that estimates computed from averages of time (or other domain) samples
should serve as suitable representatives of the theoretical statistical properties, which are deﬁned
as averages in the outcome space (ensemble). A formal deﬁnition follows.

182
Principles of System Identiﬁcation: Theory and Practice
Deﬁnition 7.10. A process is said to be ergodic if the (time averaged) estimate serves as a repre-
sentative of the true value (statistical average) when the number of observations N →∞.
Time
Realization
Time
Realization
!"#$%&'$()*$+),$
-.%$()*$+),$
t0
FIGURE 7.9
Schematic illustrating ergodicity.
Figure 7.9 illustrates the idea. Freezing the time of observation at t0, the ensemble average is the
average of all possibilities (realizations) at t0. On the other hand, if we freeze the realization and
compute the average of all observations from that particular realization, we obtain the time average.
Then, the process is ergodic if the time average serves as a suitable representative of the ensemble
average.
A few clarifying remarks (w.r.t. ergodicity and stationarity) are in place:
Remarks:
• Ergodicity is often confused with stationarity. They are two diﬀerent concepts. Stationarity warrants the
invariance of models and inferences with respect to time, whereas ergodicity authorizes the analyst to work
with a single data record.
• With respect to Figure 7.9, stationarity guarantees that the ensemble average is invariant to the choice of
t0. Only when this is guaranteed the question of whether a single record oﬀers a suitable estimate of the
ensemble average at t0 arises. Thus, the notion of ergodicity comes into picture only when the process is
stationary.
• A qualitative interpretation of an ergodic process is that given suﬃcient time, the process would have un-
ravelled nearly all possibilities that exist at any time instant (regardless of the starting point).
• Most importantly, ergodicity is usually more a characteristic of the experimentation procedure and less of
the underlying process. For example, a malfunctioning or poorly designed sensor cannot produce measure-
ments that are representative of the readings with all bias-free and high-precision sensors. Stationarity on
the other hand is largely a characteristic of the process, and less on the choice of experimental parameters.
Theoretical conditions for ergodicity can be provided. However, in the context of this subject,
these conditions would be of limited use. Ergodicity is diﬃcult to verify in practice; however, can
be ensured by a careful experimentation, particularly through a proper selection and conﬁguration
of sensors and instrumentation.
We conclude this chapter with a brief discussion on the subject of time-series analysis, an an-
tecedent and an integral part of system identiﬁcation.
7.6
TIME-SERIES ANALYSIS
Traditionally, time-series analysis (TSA) refers to the analysis of random signals and processes that
may or may not be inﬂuenced by exogenous (external) factors. The focus was largely on modeling
linear univariate random processes. Gradually the subject has evolved to include multivariate and

Random Processes
183
!"#$%&##'(%)'*$%(%+&'
,-+.%./&01$+#2
!"#$%&'()*&+#'),)-."/"0'
12"/,+""'3$*+%)"#/,45
3&.#+$&%+&#'4'5&0&.1.6.78
!6+)#7+*'3$*+%)"#/,40'%-/()#/%'
#*+,8"0'"+)"$,)-'+9+%#"5
Time-Series 
Analysis / Random 
signal processing
(prediction, filtering, 
estimation theories, 
communication 
theory)
9:8#$+#;'
<&/.71(=:8;'
>:&/./&01$+#'),8'
"+:+*)-'$#7+*')*+)"
-%7$%&&1$%7'
(==6$+(0$.%#
!8/"#2*1),%+'($8+--/,40'
*$12"#'%$,#*$-0'"."#+('
/8+,#/;%)#/$,5
5&)$+$%&
!($,/#$*/,4'$3'-)1'
:)*/)1-+"0'+</8+(/%'
),)-."/"0'%-/,/%)-'
8+%/"/$,"5
FIGURE 7.10
Broad application areas of time-series analysis.
non-linear random processes; not merely in the modeling context, but also in the tasks of classiﬁca-
tion, pattern recognition and so on.
Figure 7.10 shows the broad areas of applications of random signal processing. With measure-
ment technology making entry into every ﬁeld, the scope of applications can only expand further.
Central to all these applications is the problem of prediction, a problem that received signiﬁcant
attention in the early 1930s. The period then later witnessed milestone developments in the ﬁeld of
random signal processing among which the spectral factorization result deserves a special mention.
Traditional time-series modeling addresses the prediction of a random process either using its
own past or by imagining the process to be driven by ﬁctitious inputs. System identiﬁcation is essen-
tially time-series modeling with the inclusion of exogenous (deterministic or stochastic) variables.
Rightfully therefore, a majority of the theory (prediction and estimation theory) and modeling ter-
minology in system identiﬁcation derives from time-series analysis. Therefore, a strong foundation
in random signal processing is necessary to obtain mastery over the subject of identiﬁcation.
Listing 7.1
Useful MATLAB commands for concepts in Chapter 7
% Many specialized functionalities from Statistics Toolbox
% Random variables and p.d.f.
rand, randn, hist,
normrnd , unifrnd , normcdf , unifcdf ,
binornd , binocdf , chi2rnd , chi2cdf
% Distribution fitting tool and tests
dfittool , kstest
% Statistical properties
mean, median , mode, var, std, corrcoef , xcov, xcorr

184
Principles of System Identiﬁcation: Theory and Practice
7.7
SUMMARY
This chapter provided the basic foundations on two important topics, namely, random variables/sig-
nals and their statistical properties. The emphasis has been on linear random processes, which rely
on second-order statistical properties. Gaussian distributions are popular because of their second-
order suﬃciency and central limit theorem. Covariance / correlation as measures of linear relation-
ship were reviewed. It may be particularly recalled that uncorrelated condition merely corresponds
to absence of linear relationships whereas independence rules out any possible relationship between
two RVs. Partial covariance and correlation, which are essentially conditioned covariance / corre-
lation, are useful in resolving issues related to confounding. All statistical properties of a RV can
be evaluated using the expectation operator, which plays a central role in the analysis of random
variables. Together with the conditional expectation, it forms the basic pillar in prediction theory.
Stationarity and ergodicity are the two cornerstones on which the time-series analysis rests.
While the former requires statistical properties to remain invariant with time, the latter highlights
the requirement of estimates from a single record to stand representatives of the process. Both these
conditions are not guaranteed in reality nor is it easy to verify them in practice. Instead, the user
should remember these conditions as the bounding walls of the framework in which models are de-
veloped. When models fail, it is also likely that these conditions are violated, calling for appropriate
remedial measures that are taken at the experimentation stage or in the selection of models.
REVIEW QUESTIONS
R7.1. Deﬁne a random variable and the primary motivation for working with random variables.
R7.2. Give two diﬀerent deﬁnitions of a random process.
R7.3. Describe and deﬁne strict stationarity.
R7.4. What is the motivation for deﬁning weak stationarity?
R7.5. What are the diﬀerent types of non-stationarities that are commonly encountered?
R7.6. Explain how trend-type non-stationarities are usually handled.
R7.7. What is a random walk process? Why is it known as an integrating process?
R7.8. What is ergodicity? What role does it play in time-series analysis?
R7.9. Propose an example of a non-ergodic process.
EXERCISES
E7.1. The average thickness of a silicon wafer in a manufacturing process is 334 µm, while the variance
is known to be 10.2 µm. Assuming a normal distribution for the thickness, approximately how many
samples from a lot of 90 wafers will possess thickness less than 320 mm? Re-work your answer if a
uniform distribution is assumed.
E7.2. Probability distributions are often used in describing several real-life phenomena or quantities that
arise in estimation. Identify two real situations that can be described by (i) Gaussian, (ii) Poisson
and (iii) Chi-square distributions.
E7.3. In this chapter we learned that probability distribution functions could be either continuous or
step-like. Can you think of a phenomenon described by a mixed distribution function, i.e., partly
discrete and partly continuous?
E7.4. Given that the marks scored by a student in two diﬀerent subjects have the joint density,
F(x, y) =
( K(1 −x)(1 −y)
for
0 < x < 1, 0 < y < 1
0
elsewhere

Random Processes
185
ﬁnd (i) the value of K, (ii) marginal densities in x and y, (iii) the probability Pr(0.4 < X < 0.8,
0.2 < Y < 0.4), (iv) conditional densities fY (y|X = x) and f X (x|Y = y).
E7.5. Given the variance-covariance matrix of three random variables X1, X2 and X3, Σ
=

4
1
2
1
9
−3
2
−3
25

,
a. Find the correlation matrix ρ.
b. Compute the correlation between X1 and 1
2 X2 + 1
2 X3.
E7.6. Show that
cov(c11X1 + c12X2 + · · · + c1n Xn,c21X1 + c22X2 + · · · + c2n Xn) = cT
1 ΣXc2
where c1 =
f
c11
c12
· · ·
c1n
gT and c2 =
f
c21
c22
· · ·
c2n
gT and ΣX is the variance-
covariance matrix of X.
Verify the above result by computing the covariance between two variables Z1 = X1 + X2 + X3 and
Z2 = X1 + 2X2 −X3 with ΣX given in E7.5..
E7.7. The joint cumulative distribution function of two continuous random variables is given by
F(x, y) = 1
16 xy(x + y),
0 ≤x ≤2, 0 ≤y ≤2
Determine (i) the c.d.f. of x and (ii) the joint p.d.f. of x and y. Plot the three functions using MATLAB.
E7.8. If two random variables have joint density
f (x, y) =
(
K(x + y2)
for
0 < x < 2, 0 < y < 2
0
elsewhere
determine (i) the value of K, (ii) marginal densities in x and y, (iii) the probability Pr(0.6 < X < 1.2,
0.4 < Y < 0.8), (iv) conditional expectation E(Y |X = 1).
E7.9. The covariance between two RVs is estimated from their samples x[n] and y[n] as
ˆσyx = 1
N
N
X
n=1
(y[n] −¯y)(x[n] −¯x)
where ¯x and ¯y are the sample means of X and Y, respectively, and N is the sample size. Write a
function in MATLAB to calculate this sample covariance matrix for two random variables, X ∼N (1,3)
and Y = X2 +5X (use the randn routine to generate N = 1000 samples of X). Compare the resulting
covariance matrix with the theoretical one and the values obtained from xcov routine in MATLAB.
E7.10. Verify the Central Limit Theorem in MATLAB by ﬁrst generating N random variables of a non-
Gaussian distribution and then examining the distribution of a linear combination of these N RVs
for N = 5 and N = 100.
E7.11. Show that the third-order moment of a Gaussian-distributed RV is zero.
E7.12. Two zero-mean random variables X and Y have σ2
X = 1 and σ2
Y = 4. Further, σXY = 3.
Determine
a. E(XY).
b. The correlation between Z1 = 2X + 3Y and Z2 = X −3Y.
E7.13. Show that two uncorrelated random variables that have a joint Gaussian distribution are also
independent.
E7.14. The random walk process evolves as w[k] =
k
X
n=0
x[k] where x[k] is an i.i.d. process with mean
zero and further w[0] = 0. Prove that w[k] is a non-stationary process.
E7.15. Derive the expression for partial correlation in (7.42).
E7.16. Show that (7.18) holds.
E7.17. Determine if x[k] = e[k] sin(c1k) + e[k −1] cos(c1k), c1,c2 ∈R is stationary.

8
Time-Domain Analysis: Correlation
Functions
Three important statistical properties of a random process, namely, the auto-correlation,
cross-correlation and partial correlation function, and a fundamental random process, known
as the white-noise process are introduced in this chapter. These are central to the analysis
and model development of linear random processes. The emphasis is largely on the theoret-
ical aspects, but with interpretations for practice. The objective is to provide the theoretical
foundations necessary for building stochastic models.
8.1
MOTIVATION
One of the most intriguing and interesting problems in time-series analysis is that of prediction. The
theoretical problem setting is as follows:
Given observations of the random process up to the kth instant1,
{· · · ,v[k −2],v[k −1],v[k]}
predict v[k + 1],v[k + 2],· · · .
Notation: Random signal and the generating process are being denoted by v[k] (or sometimes by {v[k]}).
This change in notation (with respect to the previous chapter) is applicable throughout this chapter and in the
remainder of this text as well.
The eﬀort in modeling random processes is to build causal mathematical descriptions for the
process from observations. Predictions are then obtained by implementing the model equations on-
line.
The basic premise for model development, or even prediction is that the history (past) of the
process contains some useful information about the future. If a process does not possess this
characteristic, then there is no scope for prediction; and the series is said to be unpredictable
or an ideal random process.
Remarks:
Predictability depends on the model that is being used for prediction. Shortly, we shall distinguish
between unpredictable linear and non-linear random processes.
A ﬁrst step in prediction is, therefore, to develop a measure of predictability in a series. For
linear random processes the natural measure is correlation because of its excellent ability to detect
linear relationships. The idea is to compute correlation between an observation, say v[k], and each
of the past observations v[k −1],v[k −2],· · · . If there is at least one observation in the past that
is correlated with v[k], then we can exploit this correlation to predict v[k + l],l > 0. These ideas
motivate the deﬁnition of an auto-covariance (or auto-correlation) function.
1In practice, only ﬁnite length data is available. The focus here is on the theoretical problem. The ﬁnite length problem is
taken up in subsequent chapters.
186

Time-Domain Analysis: Correlation Functions
187
8.2
AUTO-COVARIANCE FUNCTION
The auto-covariance function (ACVF) is deﬁned as the covariance between two samples of a
series, v[k1] and v[k2]
σvv[k1,k2] = E((v[k1] −µk1)(v[k2] −µk2))
(8.1)
where µki is the mean of the process at ki instant.
For stationary processes, the mean remains invariant and the ACVF is only a function of the
distance between the sampling instants l = k1 −k2.
The auto-covariance function of a stationary process is only a function of the lag l between
two samples,
σvv[l] = E((v[k] −µv)(v[k −l] −µv))
(8.2)
where µx = E(v[k]) is the mean of the stationary process.
Stationarity implies that v[k] inﬂuences a future observation v[k + l] in the same way as v[k −l]
inﬂuences v[k].
Properties of ACVF
Given that ACVF is a covariance-based measure, it inherits all properties of the covariance. Some
of the useful properties are listed below.
i. ACVF measures (only) the linear dependence between v[k] and v[k −l]. This means σvv[l] = 0
merely rules out linear relationships.
ii. It is a symmetric measure, i.e.,
σvv[l] = σvv[−l]
(8.3)
iii. Like covariance, ACVF is also aﬀected by confounding, i.e., σvv[l] includes the eﬀects of other
variables (and observations) that commonly inﬂuence both v[k] and v[k −l]. In other words,
ACVF cannot tell whether two observations are directly and indirectly correlated. It measures
the total correlation.
iv. The value of ACVF is unbounded and depends on the units of v[k].
The last property above calls for a normalized measure, very much akin to the need for normalizing
covariance, which resulted in correlation.
8.2.1
AUTO-CORRELATION FUNCTION (ACF)
Drawing parallels with the deﬁnition of correlation, the auto-correlation function (ACF) is intro-
duced:
ρxx[l] = σvv[l]
σvv[0]
(8.4)
The ACF inherits all the characteristics of correlation.
i. The maximum value of ACF is unity, at lag l = 0. Essentially, any sample is best correlated with
itself.

188
Principles of System Identiﬁcation: Theory and Practice
0
50
100
150
200
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
(a) ACF of temperature measurement
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
(b) ACF of wind speed readings
0
5
10
15
20
25
30
35
40
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
(c) ACF of ECG recordings
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
(d) ACF of Swiss stock market index
FIGURE 8.1
ACF of the measurements in Figure 7.4.
ii. It is bounded:
−1 ≤ρxx[l] ≤1
(8.5)
with the equality occurring if and only if x[k] = αx]k −l],
α ∈R, i.e., for a perfectly linear
predictable process
iii. It is invariant to the choice of units of v[k].
Figure 8.1 shows the ACF estimates of the four example random signals that were presented in
Figure 7.4. Note that the distance between two lags is equal to the duration of one sampling interval.
Thus, in Figure 8.1(a), one lag corresponds to one second while in Figure 8.1(b), one lag amounts
to one hour. For the ECG series, a lag corresponds to 0.001 of a second while for the stock market
index, each lag represents one business day.
The maximum lag until which the ACF remains signiﬁcant is said to be the memory of the
process. Stationary processes have a ﬁnite memory in the sense that the eﬀect of process conditions
at v[k] or v[0] vanishes after ﬁnite lags whereas non-stationary processes have inﬁnite memory -
the eﬀect of initial conditions is felt even at much later times.
The estimator used for obtaining the ACF estimates in Figure 8.1 is discussed in Section 16.4. It
suﬃces to say at this point that the estimator assumes the process to be stationary; however, when
it is applied to a non-stationary (particularly integrating type) process such as the Swiss market
stock index series, the estimates decay very slowly. This feature is useful in detecting integrating
type non-stationarities. Note that the theoretical ACF for a general non-stationary process does not
necessarily exhibit this feature.
Interpreting ACF in predictions
The motivation for introducing ACVF and ACF has been from a prediction viewpoint. Therefore, it
is useful to interpret the measure in the prediction context. Consider the following example for this
purpose.

Time-Domain Analysis: Correlation Functions
189
Example 8.1: Role of ACF in Forecasts
Consider the forecast of a series v[k] at k2 = k + l given information only at k1 = k using a
linear model,
ˆv[k + l|v[k]] = αv[k]
(8.6)
where the [ˆ.] denotes the prediction of that variable. The notation ˆv[k +l|v[k]] should be read
as “prediction of v[k + 1] given v[k]”.
A popular method of choosing the optimal value of α is by minimization of sum-square
prediction-errors (least squares approach),
min
α E

(x[k + l] −ˆx[k + l|x[k]])2
= min
α E

(x[k + l] −αx[k])2
The optimal solution is
α⋆= ρvv[l]
which is the ACF of the process at lag l.
Thus, the ACF at any lag l is the optimal coeﬃcient of the linear model or the l-step ahead predictor
(8.6). A corollary is that the samples corresponding to the lags at which ρvv[l] = 0 do not contain
any predictable information about v[k].
The following example further highlights the role of ACF in estimation of linear time-series
models that is due to appear in Chapter 19.
Example 8.2: Best Linear Predictor of an AR(2) Process
Determine the optimal (minimum mean-square error) linear predictor for to a second-order
auto-regressive process
ˆv[k] = φ11v[k −1] + φ12v[k −2]
(8.7)
Solution: The solution to this problem is obtained by minimizing J(φ11,φ12) = E((v[k]−ˆv[k])2)
w.r.t. the parameters.
The resulting equations are
∂J
∂φ11
= −2E(v[k]v[k −1]) + 2φ11E(v2[k −1]) + 2φ12E(v[k −1]v[k −2]) = 0
∂J
∂φ12
= −2E(v[k]v[k −2]) + 2φ12E(v2[k −2]) + 2φ11E(v[k −1]v[k −2]) = 0
Re-writing in terms of auto-covariances, we have
φ11σvv[0] + φ12σvv[1] = σvv[1]
φ11σvv[1] + φ12σvv[0] = σvv[2]
=⇒
"σvv[0]
σvv[1]
σvv[1]
σvv[0]
# "φ11
φ12
#
=
"σvv[1]
σvv[2]
#
The optimal values of coeﬃcients are thus functions of the auto-covariances at lags l =
0,1,2. Thus, the ACVFs up to lag l = L govern the optimal predictor of Lth order.
The exercise oﬀers an interesting observation to carry forward. The model parameters are deter-
mined not by the values of the random signal, but instead by its statistical properties. In fact, the set
of equations for optimal estimates of the coeﬃcients in the exercise are a special case of the general
set of equations known as the Yule-Walker equations (see Chapter 14). The Y-W equations are one
of the ﬁrst methods that were developed to estimate coeﬃcients of auto-regressive models.

190
Principles of System Identiﬁcation: Theory and Practice
Non-negativity of ACVF
From the foregoing discussion and examples, it is clear that ACVF plays a critical role in prediction
and model estimation. In general, methods for development / estimating time-series models implic-
itly or explicitly involve inverse mapping of the estimated ACF to the model parameters. Therefore,
it is important to ensure that this inverse mapping produces mathematically meaningful and correct
models. Therefore, it is important to know if any symmetric function qualiﬁes to be the ACF of a
stationary random process? The answer is in the negative.
The main result is that only symmetric functions that are non-negative deﬁnite qualify to be the
ACVF of a stationary process. A formal statement and proof follow.
Deﬁnition 8.1. A sequence γ[.] is said to be non-negative deﬁnite if it satisﬁes
n
X
i=1
n
X
j=1
aiγ[|i −j|]aj ≥0
∀ai,aj ∈R , n > 0.
Theorem 8.1
The ACVF of a stationary process is non-negative deﬁnite.
Proof. Consider a process y[k] =
n
X
i=1
ai x[k −i −1] = aTx, where x[.] is an observation of a ran-
dom stationary process and ai ∈R. Then
var(y[k]) = E

(y[k] −µy)(y[k] −µy)T 
= E

aT (x −µx)(x −µx)Ta

= E

aT Σna

=
n
X
i=1
n
X
j=1
aiσ[i −j]aj ≥0
where
Σn =

σxx[0]
· · ·
σxx[n −1]
...
· · ·
...
σxx[1 −n]
· · ·
σxx[0]

(8.8)
□
The matrix Σn in (8.8) is known as the variance-autocovariance matrix.
From the discussion thus far, ACVF is used in testing predictability as well as in model esti-
mation. In order to formalize the test of predictability, it is useful to construct a process which is
unpredictable (in a linear sense). By deﬁnition, the ACVF of such a process should be zero at all
lags l , 0, i.e., no two observations should be correlated. This process is the well-known white-noise
process. A formal discussion follows.
8.3
WHITE-NOISE PROCESS
The white-noise (WN) process denoted by e[k] is an ideal random unpredictable process.

Time-Domain Analysis: Correlation Functions
191
ρ[l]
1
0
l
FIGURE 8.2
ACF of a white-noise process.
Deﬁnition 8.2 (White-noise process). The WN process {e[k]} is an uncorrelated random pro-
cess whose auto-correlation function is,
ρee[l] =
( 1
l = 0
0
l , 0
(8.9)
with ﬁnite variance, i.e., σ2
e < ∞
The name “white” stems from it spectral characteristics, as elucidated in §11.3.1. Observe that the
WN process is stationary and characterized purely by its ACF. Further, the deﬁnition does not place
any constraints on the probability distribution. Thus, one could think of a Gaussian WN (GWN),
uniform WN (UWN) process and so on. The Gaussian WN process is commonly used since it is
characterized only by its second-order characteristics and owing to the consequences of the central
limit theorem.
Note: A variety of random number generators can generate GWN and UWN processes. These are pseudo-
random number generators in the sense that they lose their randomness when the initial condition (seed) is
known. On the other end, they are random because no known mathematical function can accurately predict
their evolution.
Remarks and interpretation
The WN process can be thought of like a shock wave that is unpredictable. Its ACF has an impulse-
like shape as shown in Figure 8.2. Although an idealization, there are several real-life processes that
possess the characteristics of a white-noise process.
For any process that has an element of predictability, the ACF deviates from the impulse shape.
A useful interpretation of a WN process is that no amount of past observations can improve the
prediction of the WN process beyond its unconditional mean, which is the best prediction in the
minimum mean square error sense. Recall from Chapter 7 the fact that the conditional and uncon-
ditional expectations are identical for an uncorrelated process. For a WN process, thus,
E(e[k]|{e[k −1],e[k −2],· · · ,}) = E(e[k]) = µe
(8.10)
Remarks:
An important reason for deﬁning a WN process is not merely for benchmarking predictability
but also to use it as a basic building block in models of random processes. We shall dwell on these aspects
in Chapter 9. In identiﬁcation / time-series analysis, the WN sequence is used to denote the unpredictable
component of a signal and is also the ideal residual.

192
Principles of System Identiﬁcation: Theory and Practice
I.I.D. process
The WN deﬁnition can be generalized to arrive at the notion of an independent process, which
demands that all higher-order moments of the joint pdf to be zero. This is an extension of the notion
of independence in the random variable case to the realm of random signals.
Deﬁnition 8.3. An identical, independently distributed (i.i.d.) process is that process which is ab-
solutely unpredictable (using any non-linear model).
All moments of the joint pdf of an i.i.d. process are zero.
Remarks:
A Gaussian white-noise process is an i.i.d process as well. In practice, it is very diﬃcult to test for
independence, whereas it is quite easy to test for the absence of correlation.
8.3.1
THEORETICAL ACFS OF ELEMENTARY PROCESSES
Recall Figure 8.1 that displayed the ACFs of four diﬀerent random signals. It is clear that all four
series are predictable, i.e., none of them have white-noise like characteristics. The next step is to
“guess” the mathematical model that can capture the linear dependence between samples. A sys-
tematic procedure is preferable to a blind guess game. Therefore, we study the reverse problem ﬁrst.
Formulate elementary model structures for linear stationary random processes and evaluate the the-
oretical ACF signatures of those models. The hope is that the map between the ACF and random
processes will enable us to make an intelligent guess of the suitable predictor for a given series.
Prima facie, it appears that we may have to scan through various model structures. Fortunately it
turns out that it is suﬃcient to study only two diﬀerent structures, namely, the moving average and
auto-regressive models. The following sections are meant only to provide preliminary insights into
the ACF characteristics of these processes. A detailed treatment is presented in Chapter 9.
We begin with the moving average representations.
ACF of a Moving Average (MA) process
The MA process of ﬁrst-order is governed by the following diﬀerence equation:
v[k] = e[k] + c1e[k −1]
(8.11)
where e[k] is the zero-mean GWN process of variance σ2
e and c1 is a ﬁnite constant.
Observe that an MA process is such that its current state is a superposition of the previous shock
wave plus an unpredictable part e[k].
The theoretical ACF is obtained using the deﬁnition in (8.2)
σvv[l]
=
E((v[k] −µv)(v[k −l] −µvs))
=
E((e[k] + c1e[k −1])(e[k −l] + c1e[k −l −1]))
=
E(e[k]e[k −l]) + c1E(e[k]e[k −l −1])
+ c1E(e[k −1]e[k −l]) + c2
1E(e[k −1]e[k −l −1])
=
σee[l] + c1σee[l + 1] + c1σee[l −1] + c2
1σee[l]
Using the deﬁnition of WN process in (8.9), the ACVF of the MA(1) process is
σvv[l] =

(1 + c2
1)σ2
e
l = 0
c1σ2
e
l = ±1
0
l = ±2,±3,· · ·
(8.12)

Time-Domain Analysis: Correlation Functions
193
ACF of a Moving Average (1) process
Lags
1
-20
-10
0
10
20
FIGURE 8.3
ACF of an MA(1) process.
From the foregoing result, the ACF of an MA(1) process can be written as
ρvv[l] =

1
l = 0
c1
(1 + c2
1)
l = ±1
0
|l| ≥2
(8.13)
Figure 8.3 shows a sketch of the ACF of an MA(1) process. Three interesting observations follow
from the foregoing results:
1. The ACF of an MA(1) process has a sharp cut-oﬀafter lag l = 1 (the order of the MA(1) process).
2. The ACF is independent of the variance of the WN process.
3. Since ρvv[l] = 0,|l| ≥2, one cannot predict the process beyond one time-step.
It is appropriate to revisit the requirement of non-negative deﬁniteness on the ACF with an illustra-
tive example.
Example 8.3: Non-Negative Deﬁniteness
Consider a sequence (function)
f [l] =

1,
l = 0
c,
l = ±1
0,
otherwise
We wish to determine the range of values of c for which the symmetric sequence f [l] qualiﬁes
to be the ACF of a real-valued stationary process.
The given function resembles the ACF of an MA(1) process. By comparison with (8.13),
an MA(1) process with real coeﬃcient exists only when |c| ≥1/2. Thus, the sequence f [l]
can be the ACF of a stationary process if and only if |c| ≤1/2. It turns out that violating
the condition |c| > 1/2 results in an f [l] that is non-negative deﬁnite (see Exercise E8.3).
The foregoing example suggests that non-negative deﬁniteness of the ACVF is related to the abil-
ity to ﬁnd a real-valued random process for a given time-series. In general, estimators of time-series

194
Principles of System Identiﬁcation: Theory and Practice
models involve estimates of ACFs, as we shall learn in Chapter 19. In order to obtain models with
real-valued coeﬃcients, it is necessary to have non-negative deﬁnite estimates of ACF. Thus, only
those estimators of ACVF that produce non-negative deﬁnite estimates of ACVF are admissible.
Further for the MA(1) process, observe that two diﬀerent random processes with coeﬃcients (c1
and 1/c1) have the same ACF. This is an important fact that needs to be addressed in modeling. As
we shall learn in Chapter 9, we shall require the model to be invertible to resolve this dilemma.
It will be shown in §9.4.1 that the ACF of a general MA(M) process has a sharp cut-oﬀafter
|l| = M lags.
ACF of an auto-regressive (AR) process
Next, we examine the ACF characteristics of a ﬁrst-order AR process,
v[k] = −d1v[k −1] + e[k]
(8.14)
where e[k] is the zero-mean GWN process of variance σ2
e and d1 is a ﬁnite constant.
In contrast to the MA(1) process, an AR(1) process is such that its current state is a linear
function of the past state plus the unpredictable e[k]. Assume |d1| < 1 (a condition required for
stationarity of v[k]). With the stationarity condition satisﬁed, µe = 0 implies µv = 0.
The theoretical ACF can be then obtained using its deﬁnition in (8.2)
σvv[l] = E(v[k]v[k −l])
= −d1E(v[k −1]v[k −l]) + E(e[k]v[k −l])
= φ1σvv[l −1] + σev[l]
where σev[l] is the cross-covariance function, i.e., the covariance between e[k] and v[k −l] (deﬁned
in Section 8.4). A careful examination of (8.14) reveals that v[k −l] contains eﬀects of only past
e[k]. By deﬁnition of WN, therefore, σev[l] = 0,l > 0.
Due to the symmetry property of σvv[l], it is suﬃcient to work out the derivation for l ≥0. To
complete the derivation, we ﬁrst evaluate σev[l] for l ≥0.
To obtain σev[0], multiply both sides of (8.14) with e[k] and take expectations on both sides to
yield,
E(e[k]v[k]) = −d1E(e[k]v[k −1]) + E(e[k]e[k]) = σ2
e
using the same arguments as above.
Thus, we have the following set of equations
σvv[0] = −d1σvv[−1] + σev[0]
= −d1σvv[1] + σ2
e
σvv[1] = −d1σvv[0]
Solving equations for σvv[0] and σvv[1] simultaneously gives
σvv[0]
=
σ2
e
1 −d2
1
ρvv[l]
=
(−d1) |l | ∀|l| ≥1
(8.15)
A sketch of the ACF is shown in Figure 8.4 for the case when d1 = 0.5. Observe the exponential
decay of the ACF in stark contrast to that of the MA process.
In general, the ACF of any stationary auto-regressive processes exhibits exponential decay. We
shall prove this result formally in Chapter 9.
Before we move on to the next section, it is useful to recap our observations of the auto-
correlation function.

Time-Domain Analysis: Correlation Functions
195
ACF of an Auto-Regressive (1) process
Lags
1
-20
-10
0
10
20
FIGURE 8.4
ACF of an AR(1) process.
Quick recap
a. The ACF measures linear dependencies between samples of a time-series.
b. For a stationary process, the ACF is a symmetric non-negative deﬁnite function.
c. The ACF coeﬃcients at any lag determine the parameters of a model that produces minimum
mean-square forecasts of x[k + l] given x[k] and its past.
d. For an MA(1) process, the ACF abruptly vanishes after lags |l| > 1.
e. For an AR(1) process, the ACF dies down only exponentially.
In system identiﬁcation, a fundamental step is to correlate two or more series, be it the input-output
pair for model estimation or the input-residual pair for model validation. The cross-covariance func-
tion, it turns out, is a natural tool for both these purposes.
8.4
CROSS-COVARIANCE FUNCTION
The cross-covariance function (CCVF) is a generalization of the ACVF to two series. It measures
the linear dependence between the series at two time instants.
Deﬁnition 8.4. The CCVF between two random processes y[k] and v[k] is deﬁned as
σyv[k,l] = cov(y[k],w[k −l]) = E((y[k] −µy[k])(v[k −l] −µv[k−l]))
(8.16)
For stationary processes, the CCVF is only a function of the distance between samples (lag).
σyv[l] = E((y[k] −µy)(v[k −l] −µv))
(8.17)
Similar to the covariance and ACF, the CCVF is sensitive to the choice of units for v[k] and y[k].
Therefore, a normalized version known as the cross-correlation function (CCF) is used,
ρyv[l] =
σyv[l]
pσyy[0]σvv[0]
(8.18)
It follows immediately from the property of correlation tha,t
|ρxy[l]| ≤1 ∀l
(8.19)

196
Principles of System Identiﬁcation: Theory and Practice
A major distinction between the CCF and ACF is that it is non-symmetric,
ρyv[l] , ρyv[−l]
ρyv[l] = ρvy[−l]
(8.20)
Note: Certain texts and software deﬁne CCVF as ˜σyv[l] = E((y[k + l] −µy)(v[k] −µv)). This alternative
deﬁnition has no impact on the theoretical properties but inﬂuences the interpretation since the two deﬁnitions
are mirror images of each other, i.e., ˜σyv[−l] = σyv[l].
8.4.1
PROPERTIES AND USES OF CCF
The CCF has a few useful properties that makes it a very valuable tool in identiﬁcation, and in
general, data analysis.
i. It is asymmetric. In other words, we cannot expect the past of v[k] to inﬂuence y[k] the same
way as the future of v[k]. For example, if v[k] and y[k] are the input and output of a causal
process, then the v[k + l] has no inﬂuence on y[k] for all l > 0.
ii. The asymmetric property is useful in delay estimation in a linear time-invariant system. Section
22.5 discusses related concepts. An example below oﬀers a preview.
Example 8.4: Using CCF to Estimate Delays
Consider the measurement from a pure gain-plus-delay system
y[k] = Au[k −D] + v[k]
(8.21)
where v[k] represents the measurement noise. Without loss of generality assume both
u[k] and v[k] to be zero-mean random signals. Further assume that u[k] and v[k] are
uncorrelated (reasonable under open-loop conditions).
A visual examination of the input-output plot cannot reveal the delay due to the presence
of noise v[k]. Instead, a correlation-based method is very eﬀective as described below.
σyu[l] = E(y[k]u[k −l]) = AE(u[k −D]u[k −l]) + E(v[k]u[k −l])
= Aσuu[l −D] + σvu[l]
= Aσuu[l −D]
(8.22)
Re-writing the result in terms of correlation, one obtains
ρyu[l] =
Aσuu[l −D]
q
(A2σ2u + σ2v)σ2u
= ρuu[l −D]
1 +
σ2v
A2σ2u
Since ρuu[l −D] attains max. at l = D, delay is the lag at which ρyu[l] attains a peak
value.
Figures 8.5(a) and 8.5(b) show the cross-correlation plots for Example 8.4 with two diﬀerent
inputs, a GWN input and an input from an AR(1) process u[k] = −0.5u[k −1] + e[k]. In both
cases, the CCF peaks at lag l = 4, which is the true delay in the system.
Note: The input-output pair need not be random in nature. One can also use the idea above for deterministic
signals using the deﬁnitions of covariance functions in Chapter 10.
iii. Another useful property is the relationship between the CCVF and ACVF of the input for a linear
time-invariant system.

Time-Domain Analysis: Correlation Functions
197
−20
−15
−10
−5
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Lags
CCF
ρyu[l] for the pure delay system example
(a) Case of white-noise input
−20
−15
−10
−5
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Lags
CCF
ρyu[l] for the pure delay system (correlated input)
(b) Case of AR(1) input
FIGURE 8.5
CCF plots for Example 8.4.
The CCVF between the output and input of a random process is the ACVF of the input ﬁltered
by the same ﬁlter ˜H(q−1) that generates the output.
Mathematically,
σyw[l] =
∞
X
n=0
˜h[n]σww[l −n] = ˜H(q−1)σww[l]
(8.23)
The result is fairly straightforward to derive (see Exercise ) but requires the use of the general
linear model representation (9.13) of Chapter 9.
The result ﬁnds several applications. Two among these are in the estimation of impulse response
(see Chapter 20) and in the theoretical analysis of spectral densities (Chapters 10 and 11). An
example below illustrates the ﬁrst application.
Example 8.5: Estimation of Impulse Response Using CCVF
It is desired to estimate the IR coeﬃcients from the response of a LTI system driven by
an input w[k] having the properties of a white-noise signal.
Using Equation (8.23), we obtain
σyw[l] =
∞
X
n=0
˜h[n]σww[l −n]
Since w[k] has white-noise like properties,
σww[l −n] =

σ2w,
l = n
0,
l , n
Consequently,
˜h[l] = σyw[l]
σ2w
(8.24)
When σ2w = 1, ˜h[l] = σvw[l], which is merely the CCVF between the output and input.
When the input w[k] is non-white (colored), the impulse response estimates are obtained by
solving a set of simultaneous equations.

198
Principles of System Identiﬁcation: Theory and Practice
iv. The cross-covariance between the residuals and regressors forms the optimality conditions in
classical parameter estimation methods such as least squares and the instrumental variable meth-
ods (see Chapter 14). It is also used as a key measure to determine the adequacy of a model
(Chapter 22).
v. Cross-correlation is also the basic measure in several multivariable identiﬁcation methods. Prin-
cipal component analysis, a powerful multivariate data analysis tool (described in §26.3), per-
forms an eigenvalue decomposition of the cross-covariance matrix to extract the multivariable
model.
In utilizing the nice properties of CCVF, an important fact may always be taken into considera-
tion, which is that it suﬀers from confounding. Recall the discussion of §7.4.3 in this context.
Confounding occurs in both ACF and CCF because the confounding variable could be either
intermediate observations or common variables inﬂuencing the two samples of interest. A remedy
for confounding was presented in the form of partial correlation in §7.4.3. We extend that idea to
the time-series case.
8.5
PARTIAL CORRELATION FUNCTIONS
The partial correlation function is essentially the partial correlation between lagged variables, lead-
ing to partial versions of ACF and CCF.
8.5.1
PARTIAL ACF
As a motivational example, consider the AR(1) process
v[k] = −d1v[k −1] + e[k]
whose ACF is given by (8.15),
ρvv[l] = (−d1) |l |
The ACF suggests that v[k] and v[k −l] are correlated whereas the governing diﬀerence equation
for the process clearly shows that only two successive samples v[k] and v[k −1] directly inﬂuence
each other.
The cause for this apparent correlation can be understood by re-writing the diﬀerence equation
of the process as
v[k] = −d1(−d1v[k −2] + e[k −1]) + e[k] = d2
1v[k −2] −d1e[k −1] + e[k]
Thus v[k −2] appears to inﬂuence v[k −2] indirectly through v[k −1]. The same argument can be
extended to explain correlation at other lags as well. In ﬁtting diﬀerence equation (auto-regressive)
models to time-series data, an important piece of information that is required is the number of
past terms that directly participate in the diﬀerence equation. ACF fails to provide this information.
To obtain this information, one needs to compute the direct auto-correlation known as the partial
auto-correlation function (PACF).
The deﬁnition of PACF directly follows from §7.4.3 by using a vector set of confounding vari-
ables. Since ACF is symmetric, it suﬃces to examine only for l > 1. The confounding variables
are
z = {v[k −l + 1],· · · ,v[k −2],v[k −1]}
.
Figure 8.6 oﬀers a graphical representation of the auto-regressive process. The observation at
(k −2), v[k −2], inﬂuences v[k] along two diﬀerent pathways, namely, the direct and indirect
pathways. At each instant, the white-noise contributes to the unpredictable uncertainty in v[k]. ACF
measures correlation along both the pathways, whereas PACF computes correlation only along the
direct pathway. This explains the essential diﬀerence between these two measures.

Time-Domain Analysis: Correlation Functions
199
v[k-2]
e[k-2]
v[k-1]
e[k-1]
v[k]
e[k]
…
…
Direct pathway
Indirect pathway
FIGURE 8.6
Graphical representation of the auto-regressive process: ACF detects presence of both the direct
and indirect pathways, whereas PACF detects only the direct pathways
Deﬁnition of PACF
The PACF at any lag l, denoted by φvv[l], is deﬁned as
φvv[l] =

corr(v[k],v[k −l]|z),
|l| > 1
ρvv[l],
|l| = 1
(8.25)
where z is as given above. The PACF coeﬃcient at lag l = 1 is the ACF at lag l = 1 itself since
there is no intermediate variable. Stated another way, the direct correlation at lag l = 1 is the same
as total correlation.
It follows that whenever φvv[l] = 0 for some lag l = l0, v[k −l0] does not directly inﬂuence v[k].
The converse is also true. Example 8.6 illustrates this point on an AR(1) process.
Computation of PACF
The computational procedure follows from Section 7.4.3.
1. Obtain the best predictors for v[k] and v[k −l] using z. Denote the associated residuals by ϵ v[k]
and ϵ v[k −l], respectively.
ϵ v[k] = v[k] −ˆv⋆[k|z];
ϵ v[k −l] = v[k −l] −ˆv⋆[k −l|z];
where
ˆv⋆[k|z] =
l−1
X
i=1
α⋆
i v[k −i];
ˆv⋆[k −l|z] =
l−1
X
i=1
β⋆
i v[k −i]
where α⋆
1 and β⋆
1 are the optimal (least squares) estimates of αi and βi, respectively.
2. Compute the PACF at lag |l| > 1 as
φvv[l] = corr(ϵ v[k],ϵ v[k −l])
(8.26)
The computational procedure is demonstrated on an AR(1) process below.
Example 8.6: Computing the PACF of an AR(1) Process
Find the PACF of an AR(1) process: v[k] = −d1v[k −1] + e[k] at lags l = 1,2
Solution: From deﬁnition,
φvv[1] = ρvv[1] = −d1
φvv[2] = corr(v[k] −α⋆
1 v[k −1],v[k −2] −β⋆
1 v[k −1])

200
Principles of System Identiﬁcation: Theory and Practice
where α⋆
1 and β⋆
1 are the LS estimates. To compute them, note that ˆv[k|v[k −1]] = α1v[k −1]
and ˆv[k −1|v[k]] = β1v[k]. Comparing notes with Example 7.10,
α⋆
1 = σvv[1]
σvv[0] = ρvv[1];
β⋆
1 = σvv[−1]
σvv[0] = ρvv[1]
Then,
φvv[2] =
cov(v[k] −ρvv[1]v[k −1],v[k −2] −ρvv[1]v[k −1])
p
var(v[k] −ρvv[1]v[k −1])var(v[k −2] −ρvv[1]v[k −1])
= ρ[2] −ρ[1]
1 −ρ[1]2
where ρ[l] is the ACF of the process. This is a generic result.
The process under study is an AR(1). Therefore, ρ[l] = (−d1)|l |, thereby φvv[2] = 0. At a
later stage, it will be shown that φvv[l] = 0 for all lags l ≥2.
An interesting observation emerges. The PACF for an AR(1) process falls oﬀabruptly to zero
from lag l = 2 onwards. Contrast this behavior with the exponential decay of ACF for an AR(1)
process.
Intuitively one can expect the vice versa behavior of PACF for MA process. Indeed this is true.
It can be shown that for an MA(1) process (see Exercise E8.6),
φvv[l] = −
−c|l |
1 (1 −c2
1)
1 −c2(|l |+1)
1
(MA(1) process)
(8.27)
A few interesting remarks follow from the foregoing discussion.
Remarks:
i. The computation of conditioned v[k −l] using z involves its “prediction” using future values. For this
reason, this is known as backcasting. The apparent awkwardness of backcasting can be eased by viewing
it as conditioning, i.e., removing common eﬀects of the intermediate variables from v[k −l].
ii. Further to the remark above, backcasting is not merely a mathematical exercise, but is also practically
useful; for instance, in estimating missing observations of a process from future samples.
iii. The PACF of a WN process is zero at all lags (like the ACF).
iv. The PACF at lag l = 0 is not deﬁned. However, for visualization purposes, PACF at lag l = 0 is sometimes
set to unity.
v. The PACF coeﬃcient at any lag p, φvv[p] is the last coeﬃcient of an AR(p) model ﬁt to the series v[k]. This
is formally established in Section 9.5.3.
vi. In practice, a recursive algorithm due to Durbin (1960) and Levinson (1947) that uses the coeﬃcients at
l = p −1 and the ACF coeﬃcients (see Table 9.1 in Section 9.5.3) is used to compute the PACF.
vii. The PACF and ACF exhibit dual characteristics with respect to auto-regressive and moving average pro-
cesses. Chapter 9 elucidates this point in greater detail.
Figure 8.7 shows the theoretical PACF of a few representative processes, namely, the GWN
process, an AR(1) process, an MA(1) process and an AR(2) process. Observe the exponential decay
of the PACF of the MA(1) process.
The PACFs of the four example real-life signals considered previously in Figure 7.6 are plotted
in Figure 8.8. The reader may recall that the SMI series is non-stationary and therefore theoretically
the PACF is not just dependent on the lag alone. However, the estimates have been computed by
treating it as a stationary process. The PACF estimates of this series indicate that the process may
be represented by an AR(1) process with a pole very close to the unit circle, i.e., an integrating

Time-Domain Analysis: Correlation Functions
201
0
10
20
0
0.5
1
Lags
PACF
PACF of a GWN process
0
10
20
0
0.5
1
Lags
PACF
PACF of an AR(1) process
0
10
20
−0.5
0
0.5
1
Lags
PACF
PACF of an MA(1) process
0
10
20
0
0.5
1
Lags
PACF
PACF of an AR(2) process
FIGURE 8.7
Theoretical PACFs of a few representative processes.
process (§9.7 expands this point). The PACF of ECG series has alternating signs and high-order AR
characteristics, which is typical of non-linear processes (we do not pursue this line of discussion in
this text). For the remaining two series, pure AR models may be insuﬃcient due to the absence of a
sharp cut-oﬀin the PACF; ARMA models may be required for the purpose.
0
5
10
15
20
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
PACF
Lags
(a) PACF of temperature measurement
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
PACF
Lags
(b) PACF of wind speed readings
0
5
10
15
20
25
30
35
40
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
PACF
Lags
(c) PACF of ECG recordings
0
5
10
15
20
25
30
35
40
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
PACF
Lags
(d) PACF of Swiss stock market index
FIGURE 8.8
PACF of the measurements in Figure 7.4.
8.5.2
PARTIAL CCF
The partial cross-correlation function can be deﬁned in a similar way as the PACF. One of the main
purposes of deﬁning a partial CCF is to discount for the eﬀects of a third (or more) variable z[k]
when evaluating the correlation between two variables y[k] and u[k −l].

202
Principles of System Identiﬁcation: Theory and Practice
The deﬁnitions and interpretations of PACF carry forward to PCCF as well with the exception of
the symmetric property. At a later stage we shall study the frequency-domain counterparts of these
measures and their applications to time-delay estimation.
Listing 8.1
Useful MATLAB commands for concepts in Chapter 8
% Generating white-noise and coloured noise
randn, rand
% GWN and UWN respectively
filter , sim, tf, idpoly % To construct MA, AR objects and perform filtering
% Covariance and Correlation functions
xcov, xcorr % Removes mean and w/o mean removal , respectively
8.6
SUMMARY
In this chapter we studied the key concepts of correlation functions (of lags), namely the auto-
correlation and cross-correlation functions. These are useful in studying the characteristics of ran-
dom signals. The related measures are essentially obtained by applying the correlation deﬁnition to
two diﬀerent observations of a random signal or of two diﬀerent signals. The ACF is a measure of
(linear) predictability within a series. For a stationary process, it is purely a function of the lag. The
ACF is not only useful in detecting predictability, but also in deﬁning an ideal random process. The
white-noise process is that ideal unpredictable stationary random process. Processes that are pre-
dictable have a non-impulse like ACF. Moving average processes exhibit a sharp cut-oﬀin the ACF,
whereas auto-regressive processes are characterized by an exponential decay. The cross-correlation
function is a generalization of ACF to characterize predictability of one series using another series.
Due to its asymmetric property, it is useful in delay estimation. It is a valuable tool in system iden-
tiﬁcation for impulse response estimation, model validation and diagnosis. The partial correlation
functions are useful in computing direct correlations. The partial ACF is a valuable tool in deter-
mining the order of auto-regressive processes, while the partial CCF is used in estimating delays of
sub-channels in multivariable systems.
REVIEW QUESTIONS
R8.1 Deﬁne auto-correlation function and its uses.
R8.2 Discuss the non-negative deﬁniteness property of the ACF.
R8.3 Deﬁne a white-noise process and explain its role in modeling.
R8.4 How is CCF useful for delay estimation?
R8.5 What are the ACF characteristics of MA(1) and AR(1) processes?
R8.6 Discuss the motivation for partial ACF.
R8.7 What are the PACF characteristics of AR(1) and MA(1) processes?
R8.8 Explain the term “conditioning” in signal analysis, speciﬁcally in correlation.
R8.9 Describe the theoretical procedure for computing PACF.
R8.10 Suggest one use of the partial cross-correlation function.
EXERCISES
E8.1 Show that x[k] = a0 sin(2π f0k) + b0 cos(2π f0k) is weakly stationary, i.e., has (i) ﬁnite mean and
is time-invariant, (ii) ﬁnite variance and (iii) ACVF is only a function of the lag.

Time-Domain Analysis: Correlation Functions
203
E8.2 Compute the theoretical ACF of the following processes:
(i) v[k] = e[k] + 0.8e[k −1] + 0.15e[k −2]
(ii) v[k] = 0.95v[k −1] + e[k]
(iii) v[k] = 0.4v[k −1] + e[k] + 0.6e[k −2]
(iv) v[k] = −0.7v[k −2] + e[k]
E8.3 Show that for the MA(1) process v[k] = e[k] + c1e[k −1], the ACVF sequence σvv[l] is non-
negative deﬁnite whenever |c1| > 1/2.
E8.4 It turns out that at a certain stage in an identiﬁcation exercise, the CCF between the inputs
and residuals is negligible, but the ACF of residuals shows colored (non-white) residuals. How do
you propose to modify the model structure at that stage? What can you say of the original process?
Justify your answers.
E8.5 Obtain the theoretical expressions for the PACF coeﬃcients of an AR(2) process at lags l = 1,2.
E8.6 Show that the PACF of an MA(1) process is given by (8.27).
E8.7 For an AR process, the PACF coeﬃcients have been obtained as φ[l] = 0.8,0.5
l = 1,2, and
zero at all other lags, estimate the order and coeﬃcients of the AR process.
E8.8 Consider a random process
v[k] = 1 + 0.4q−1
1 −0.6q−1 e[k]
(8.28)
where e[k] is zero-mean, unit variance GWN.
a. Find the theoretical ACVF σvv[l].
b. Generate 2000 samples of this sequence and use the acf.m routine to compute the sample
ACVF.
c. Do you ﬁnd close agreement between the theoretical and sample ACVF?
E8.9 Periodicities are a common phenomena. A process generates a sinusoidal wave, which is observed
with error,
y[k] = Asin(2π f0k) + e[k]
where e[k] is the usual zero-mean unit-variance WN sequence and A, f0 are suitable constants.
a. Is the process stationary? Support your answer suitably.
b. Prove that the time-averaged ACVF2 of y[k],
Ryy[l] = 1
N
N
X
k=l+1
(y[k] −¯y)(y[k −l] −¯y)
(8.29)
where ¯y is the sample mean, is asymptotically (large samples, N →∞) also a sinusoidal
sequence with frequency f0.
c. Is there any advantage of detecting periodicity of the sine wave from its ACF rather than
examining y[k] directly?
d. Verify results in part (b) using MATLAB from 1000 samples of a sine wave with frequency
f0 = 0.2 cycles/sample with SNR maintained at 10.
2You may assume that the white-noise process is ergodic, i.e., the time- and ensemble-averages coincide in the limiting
case.

9
Models for Linear Stationary Processes
The chapter presents the theory of time-domain models for linear stationary processes. Two
contrasting and powerful classes of models, namely, the auto-regressive and moving average
models are reviewed. Following which, the general class of ARIMA models are discussed.
The main objective is to provide theoretical foundations for modeling stochastic variations in
signals. Parallels to models for deterministic LTI systems are highlighted so that the reader
can conveniently recognize the present chapter as a stochastic analogue of Chapter 4.
9.1
MOTIVATION
The previous chapter introduced two important measures, namely, ACF and CCF (and their partial
versions) to detect predictability within and across series. A formal use of these measures is carried
out through appropriate statistical tests. For instance, to test the predictability within a series, a
whiteness test for the signal is conducted, wherein the observed (estimated) ACF is subjected to a
test of hypothesis that the series falls out of a white-noise process, i.e., the ACF is zero at non-zero
lags. These procedures are detailed in Chapter 16.
The present chapter is concerned with the important step of modeling that follows the tests of
predictability. We shall speciﬁcally study two important topics: (1) the possible class of models for
linear stationary processes and (2) properties of these theoretical models. Estimation of models is
presented in Chapter 14.
At the outset we reiterate a point made earlier in Chapter 7. It is not possible to predict a random
process accurately by its very deﬁnition. The most basic prediction of any random signal is its
mean, i.e., the unconditional expectation E(v[k]). Time-series models oﬀer the maximum possible
improvement over this basic prediction by exploiting the temporal correlations within and across
variables. Associated with this prediction is always a degree of uncertainty (inaccuracy).
A vast body of literature on time-series modeling is centered on linear random processes because
they oﬀer mathematical convenience. Moreover a large class of random processes can be adequately
described by linear models. Development of these models is evidently based on the linear measures
presented in previous chapters. When it is required to build non-linear models, it is necessary to use
measures that test non-linear inter-sample dependencies. Such measures are based on higher-order
statistical moments.
The historical approach to time-series modeling involved breaking up the series as
y[k] = m[k]
Trend
+ s[k]
Seasonal
+
v[k]
Stationary
(9.1)
followed by a separate modeling of each component. These models are known as additive models.
The trend usually contains a polynomial type of trend while the seasonal component captures pe-
riodic behavior (if any) and seasonal eﬀects. Both of these components could be combined into a
single deterministic component. Several eﬃcient non-parametric and semi-parametric methods that
make use of suitable smoothing and ﬁltering operations are available to facilitate such a decompo-
sition (see Brockwell (2002), Priestley (1981), and Shumway and Stoﬀer (2006)).
The main challenge is to model the stationary component, which was studied extensively by sev-
eral researchers in the late 1940s. Among these were the pioneering works of Wiener, Kolmogorov,
Cramer, Wold and other contemporaries (Priestley, 1981), whose eﬀorts were aimed at developing
204

Models for Linear Stationary Processes
205
predictors for linear stationary processes. The resulting prediction theory led to the formal frame-
work for stochastic modeling that we see today. Linear predictors have been thus studied for long.
Although these works largely focused on modeling linear and stationary processes, they gradually
paved the way for modeling non-stationary (random walk type) processes as well.
Signiﬁcant developments in non-linear time-series models have taken place in the last two
decades. These models hold promise as powerful modeling solutions to several applications where
linear models fail to perform. However, keeping in view the scope of the text and for pedagogical
reasons, the presentation in this chapter is limited to linear random processes. A good foundation on
linear modeling theory is an essential stepping stone for understanding and developing non-linear
models.
The concepts of linearity and linear models are clearly understood in the context of determinis-
tic processes (recall Deﬁnition 3.1). The associated deﬁnition rests on an input-output relationship.
Adopting the same deﬁnition for random processes is somewhat tricky because there are no vis-
ible or tangible inputs to a random process. This is apparently a diﬃcult situation and presents
formidable challenges. Fortunately, a solution exists to this problem under certain conditions. That
is, it is possible to still deﬁne linearity and build linear models for random processes provided they
possess certain properties. A basic requirement is that the random process should be stationary. The
more essential requirement and the complete solution revolves around a milestone result in the the-
ory of random processes known as the spectral factorization result, which is discussed in Chapter
10.
In the following sections we shall review the essential concepts of stochastic process modeling
and discuss two important classes of models. For a rigorous treatment of the subject, the reader is
referred to the rich expositions and texts on the same (Brockwell, 2002; Hamilton, 1994; Priestley,
1981; Shumway and Stoﬀer, 2006).
9.2
BASIC IDEAS
The basic idea in modeling is as follows: any (stationary) random process can be thought of as
consisting of a predictable portion plus an unpredictable component.
v[k] = ˆv[k] + e[k]
(9.2)
where ˆv[k] represents the predictable portion and e[k] the unpredictable ideal random process, i.e.,
the white-noise process or in general the i.i.d. process. The second term in (9.2) is an indispens-
able component of any random process because when it is absent, v[k] condenses to a deterministic
process. On the other hand, the ﬁrst term can be absent, in which case, v[k] has white-noise charac-
teristics.
Given P past observations of the process, the modeling objective is to develop a predictor ˆv⋆[k]
that leaves nothing predictable in the prediction error. In other words, the prediction error
ϵ[k] = v[k] −ˆv⋆[k]
(9.3)
should have either white-noise or i.i.d. characteristics.
Recalling a key result from Section 7.4.2 (see also Chapter 18) involving conditional expecta-
tions, we note that the best predictor of v[k] is its conditional expectation given its past,
ˆv⋆[k] = E(v[k]|{v[k −1],v[k −2],· · · ,v[k −P]})
(9.4)
As appealing the result in (9.4) is, it is practically very diﬃcult to use since conditional expecta-
tion calculations require the knowledge of conditional p.d.f.s, which are very diﬃcult to obtain. A
simpler alternative is to assume that the observations follow a joint Gaussian distribution with the

206
Principles of System Identiﬁcation: Theory and Practice
result that the conditional expectation of (9.4) is a linear function of the past observations1,
ˆv⋆[k] =
P
X
i=1
(−di)v[k −i]
(9.5)
When the true process does not satisfy the (joint) Gaussianity assumption, the linear predictor is
sub-optimal, but is at least mathematically tractable and implementable.
Plugging in the linear predictor (9.5) into (9.2) gives rise to a diﬀerence equation form for v[k],
v[k] +
P
X
i=1
div[k −i] = e[k]
(9.6)
which exhibits a strong correspondence with the diﬀerence equation description (4.32) for deter-
ministic LTI systems in Chapter 4.
It is easy to observe that (9.6) can be cast into the convolution form and other forms that we have
seen in Chapters 4 and 5. The following example is illustrative of this point.
Example 9.1: LTI Representation
Suppose that a stationary random process v[k] has an exponentially decaying ACF and a
sharp cut-oﬀin the PACF at lag l = 1. Then from Section 8.5.1, we know that v[k] can be
modeled as an auto-regressive process of ﬁrst-order, i.e., v[k] can be described by (9.6) with
P = 1,
v[k] + d1v[k −1] = e[k]
(9.7)
Bringing in the shift-operator, we can express (9.7) using the transfer function operator
v[k] = H(q−1)e[k]
where
H(q−1) =
1
1 + d1q−1
(9.8)
Chapter 10 shows how spectral representations for stochastic processes can be constructed using
Wiener’s representations and the powerful Wiener-Khinchine theorem.
White noise (ideal prediction error) acts as an input
Now we turn to an important observation. A comparison of the results from the foregoing example
and the diﬀerence equation (9.6) with the corresponding deterministic counterparts (recall Equation
(4.32)) suggests that we may treat the white-noise signal e[k] as a forcing function for the diﬀerence
equation in (9.6), i.e. as an “input” that drives the stochastic process v[k]. Thus, the uncertainty in
the process is also its driving force. An important point to remember though is that this white-noise
input is ﬁctitious and random, unlike the input of the deterministic process.
The spectral factorization result essentially establishes the conditions under which it is possible to
represent a given random process in the diﬀerence equation form (9.6). Assuming these conditions
hold good for the processes of our interest, it is now possible to import concepts of linearity, stability,
etc. to the random process domain.
1The negative sign on the coeﬃcients is introduced to have a positive sign on the coeﬃcients of the diﬀerence equation
for v[k].

Models for Linear Stationary Processes
207
Linear random process is a ﬁlter
The most valuable implication of the preceding discussion is that
(Almost all) Stationary random processes can be represented as outputs of linear time-
invariant ﬁlters driven by white-noise inputs.
v[k] = H(q−1)e[k]
(9.9)
The representation in (9.9) is highly beneﬁcial in system identiﬁcation because with it both the
deterministic and stochastic eﬀects can be modeled in the single framework of LTI systems.
Further, the concepts of linear systems theory for deterministic processes can be transported (al-
beit with some caution and modiﬁcations) to random processes as well. We begin with the important
deﬁnition of linearity for a stationary random process.
9.3
LINEAR STATIONARY PROCESSES
Deﬁnition 9.1. Any stationary process is said to be linear if and only if it can be represented as
v[k] =
∞
X
n=−∞
hne[k −n]
∀k
where e[k] ∼WN(0,σ2
e)
(9.10a)
and
∞
X
n=−∞
|hn| < ∞
(9.10b)
Thus, a stationary process is linear if and only if it can be represented as the weighted sum of the
past, present and future (white noise) shock waves, with the weights fulﬁlling (9.10b).
Remarks:
1. The summation in (9.10a) includes past and future shock waves, which is not congenial for practical use.
Hence, the summation is usually restricted to causal processes, i.e., series with n ≥0.
2. The WN process driving force for the linear process is replaced by an I.I.D. process in certain schools of
thought, especially, in non-linear time-series analysis. In this text, however, it suﬃces to adopt the WN
assumption.
3. Further to the point above, no restriction on the distribution of the source WN process is placed. We shall,
nevertheless, deploy the Gaussian WN process unless otherwise explicitly stated. This choice is for two
reasons that are already known to us: (i) it is suﬃcient to examine the ﬁrst- and second-order moments of
v[k] and (ii) a Gaussian WN process is also an I.I.D. process.
4. A more general representation under relaxed conditions (only requiring covariance stationarity of v[k])
was given by Wold (1938) and is known popularly as Wold’s decomposition. The representation essen-
tially breaks up a covariance stationary process into deterministic (completely predictable) and stochastic
components. See Hamilton (1994, Chapter 4) for further discussion.
Stationarity and Stability
The absolute convergence requirement of the weights (IR coeﬃcients) {hn} in (9.10a) is both a
necessary and suﬃcient condition for stationarity. A formal proof of this is available in several

208
Principles of System Identiﬁcation: Theory and Practice
classical texts on time-series analysis (Brockwell and Davis, 1991). The requirement stems from
the condition of the absolute convergence of the series (with probability 1)
E(|v[k]|) = E(|
∞
X
n=−∞
hne[k −n]|) <
∞
X
n=−∞
|hn|E|e[k −n]|
< σe
∞
X
n=−∞
|hn| < ∞=⇒
∞
X
n=−∞
|hn| < ∞
which is reminiscent of the stability condition (4.9) for the deterministic LTI system.
Consequent to the observations above, an alternative deﬁnition of a linear random process can be
provided.
A stationary process is linear if and only if it is the output of a stable LTI system driven by a
Gaussian white-noise signal.
To reiterate a point made earlier, the spectral factorization result establishes the conditions under
which it is possible to represent a stationary process in the form (9.10a).
Role of time-series models in identiﬁcation
It is useful to emphasize the role of the linear random process model (9.10a) in identiﬁcation. It is
useful in two diﬀerent ways:
1. To build a linear model for the stochastic part of y[k]: The objective is to be able to predict that
component of the output which the input cannot explain (residuals). The beneﬁt of having (9.10a)
is that both the deterministic and noise models have the same LTI representation. However, note
that the estimation of noise model is more challenging due to the additional burden of estimating
the properties of e[k].
2. To develop a joint stationary representation for the input-output system: This is one of the stan-
dard approaches in closed-loop identiﬁcation where y[k] and u[k] are each given a linear station-
ary representation. Section 25.3 presents details of this approach.
In addition, the general model (9.13) is useful in deriving certain theoretical results in estimation
of impulse response coeﬃcients (recall Example 8.5).
The linear stationary process in (9.10a) can be given diﬀerent representations exactly in the same
way as we can for a deterministic LTI process. These forms are brieﬂy discussed below. The ensuing
sections, §9.4, §9.5 and §9.6, speciﬁcally focus on the convolution, diﬀerence equation and transfer
function forms.
Convolution form
Equation (9.10a) shares a strong similarity with the convolution equation in (4.1),
y[k] =
∞
X
n=−∞
g[n]u[k −n]
(4.1 revisited)
The sequence {hn} can be thus thought of as the impulse response sequence of the random process
generating v[k]. This convolution form leads to the moving average representation discussed in
§9.4.

Models for Linear Stationary Processes
209
Remarks:
Observe an important distinction between (9.10a) and (4.1). The forcing function is a Gaussian
white-noise process, which is random and unknown whereas the input is deterministic in (4.1). Only the ACF
of the random input e[k] is known (not the ACVF) with certainty, whereas in the deterministic case, the input
sequence u[k] itself is known with certainty.
Transfer function representation
Using the backshift operator notation, (9.10a) can be re-written as
v[k] = H(q−1)e[k]
where
H(q−1) =
∞
X
n=−∞
hnq−n
(9.11)
A transfer function can be deﬁned in a similar way
H(z−1) =
∞
X
n=−∞
hnz−n
(9.12)
The transfer function can be used in the same way as it is done for deterministic processes. It can
be used to represent two general stationary processes y[k] and w[k] related through a linear system.
y[k] = ˜H(q−1)w[k]
(9.13)
The representation in (9.13) is useful in several identiﬁcation problems, particularly when the input
itself is a random signal or has the properties of a random signal.
Frequency response function
Further to the above deﬁnitions, a frequency response function of the random process can be con-
structed as the DTFT of the impulse response sequence h[.],
H(e−jω) =
∞
X
n=0
h[n]e−jωn
(9.14)
Later in Chapter 11, we shall learn that the FRF in (9.14) has the same interpretation of a linear
ﬁlter as for deterministic processes. In other words, v[k] is a ﬁltered version of the white noise e[k].
Remarks:
The FRF cannot be given the interpretation of Equation (5.23) derived for deterministic processes,
i.e., as the ratio of Fourier transforms of v[k] and e[k] because the corresponding transforms do not exist. The
reason is that random signals are neither ﬁnite-energy signals nor necessarily periodic signals.
In the analysis of random processes, a more useful and interpretable quantity is |H(e−jω)|2,
whose role will be established in Chapter 10. For now it suﬃces to say that it relates the spectral
densities (to be deﬁned in Chapter 10) of input and output of a linear random process. This also
holds good for deterministic processes. Thus, |H(e−jω)|2 is a more unifying quantity.
Note: Fourier transforms only exist for ﬁnite-energy (deterministic) signals, whereas spectral densities can be
deﬁned for both deterministic and stationary stochastic signals.
9.3.1
NON-UNIQUENESS OF TIME-SERIES MODELS
Time-series modeling is concerned with estimating (or ﬁtting) the coeﬃcients h[.] given a ﬁnite-
length realization of v[k]. The fact that the inputs to the model (9.10a) are unknown and random
makes it challenging. Recall that the additional goal in time-series modeling is to estimate the vari-
ance of e[k]. However, any estimate of σ2
e is not unique because the pair (αH(q−1),σ2
e/α2, α ∈R)

210
Principles of System Identiﬁcation: Theory and Practice
is an equally qualifying solution to (9.10a). Thus, we run into an identiﬁability issue. The solution
is unique only up to a scaling factor.
An easy way to resolve the non-uniqueness is to ﬁx the leading coeﬃcient of the polynomial
H(q−1) to unity,
h0 = 1
(9.15a)
Thus, the transfer function operator is now
H(q−1) = 1 + h1q−1 + h2q−2 + · · ·
(9.15b)
Furthermore, the concept of delay does not arise in univariate time-series modeling since e[k −
D] and e[k] have the same variance (by virtue of stationarity) thereby making it impossible to
estimate D. The spectral factorization result formalizes this observation by stating that H(e−jω)
can be identiﬁed uniquely only up to a phase term. Thus, both H(e−jω) and H(e−jω)e−Dω are
equally possible solutions for a given series.
Continuing our discussion on models for linear random processes, we now study in detail the
ﬁnite-length convolution (moving average) form, the diﬀerence equation (auto-regressive) repre-
sentation and the transfer function (auto-regressive moving average) form in the following sections.
The correspondence of these sections in the deterministic domain are the FIR, the diﬀerence equa-
tion and the transfer function models of §4.2.1, §4.3 and §5.2, respectively.
9.4
MOVING AVERAGE MODELS
The moving average representation of order M has the following form
v[k] =
M
X
n=1
hne[k −n] + e[k]
(9.16)
which has a striking resemblance to the FIR representation in (4.12). The MA(M) representation
assumes that the process evolves as a linear combination of M past shock waves plus an inevitable
uncertainty.
The corresponding transfer function (operator) representation is
H(MA)(q−1) = 1 +
M
X
n=1
hnq−n;
H(MA)(z−1) = 1 +
M
X
n=1
hnz−n
(9.17)
Just as FIR models represent stable processes as long as the coeﬃcients of representation are
ﬁnite, ﬁnite-order MA models always represent stationary processes as long as |hn| < ∞, ∀n.
On the other hand, the inﬁnite-order MA process is stationary only when the sequence {h[n]} is
absolutely convergent.
A key question in modeling is whether a moving average or an auto-regressive or some other
form is suitable for a given series. It turns out that the auto-covariance function and its partial cousin
provide valuable answers to this question. With this motivation, we study the ACVF signature of
an MA process. The study shall also facilitate certain classical methods of estimating parameters of
time-series models.
9.4.1
ACVF SIGNATURE OF AN MA PROCESS
Moving average processes are characterized by a unique signature in the ACF. This fact was il-
lustrated in 8.3.1, where it was shown that the ACF of an MA(1) process exhibits a sharp cut-oﬀ
beyond the lag l = 1. A generalization of this observation follows.

Models for Linear Stationary Processes
211
To establish the general result, an auto-covariance generating function for a linear random pro-
cess is introduced.
Auto-covariance generating function
The idea behind deﬁning the ACVF generating function is to collect all the ACVF coeﬃcients in a
single polynomial.
Deﬁnition 9.2. The auto-covariance generating function is deﬁned as the two-sided z-transform of
the ACVF sequence
gσ(z) =
∞
X
l=−∞
σvv[l]z−l
(9.18)
The key result is that the ACVF generating function can be computed directly from the linear
representation (9.10a).
gσ(z) = σ2
eH(z−1)H(z)
(9.19)
where H(z−1) is the transfer function (9.12).
The result in (9.19) can be derived by substituting the deﬁnition of ACVF (8.2) into (9.18) and
then bringing in the transfer function deﬁnition (9.12). A detailed derivation is found in standard
texts on time-series (see Box, Jenkins and Reinsel (2008) for instance).
The exercise below demonstrates the utility of ACVGF.
Example 9.2: Auto-Covariance Generating Function of an MA(2) Process
Compute the ACVF of an MA(2) process
v[k] = e[k] + h1e[k −1] + h2e[k −2]
Solution: First observe that
H(q−1) = 1 + h1q−1 + h2q−2
To compute the ACVF, construct the ACVGF by computing the product
gσ(z) = σ2
eH(z−1)H(z) = σ2
e(1 + h1z−1 + h2z−2)(1 + h1z + h2z2)
= σ2
e(h2z−2 + (h1 + h1h2)z−1 + (1 + h2
1 + h2
2) + (h1 + h1h2)z + h2z2)
Comparing with Equation (9.18) and reading oﬀthe coeﬃcients of z−l, we obtain
σvv[l] =

(1 + h2
1 + h2
2)σ2e,
l = 0
(h1 + h1h2)σ2e,
|l| = 1
h2σ2e,
|l| = 2
0,
|l| ≥3
(9.20)
Thus, as expected, the ACVF of an MA(2) process vanishes at all lags |l| > 2.
It is not diﬃcult to extend the foregoing observation to the general case. Combining the gen-
eral MA(M) representation (9.16) and the ACVGF deﬁnition (9.19), the following general result
emerges:

212
Principles of System Identiﬁcation: Theory and Practice
The ACVF (and ACF) of a general MA(M) process is zero at all lags |l| > M, i.e.,
σvv[l] = 0
∀|l| > M
(9.21)
As a result, the ﬁnite-order MA(M) process is also known as M-correlated process. The result in
(9.21) is used in determining the appropriate order of an MA model for a given series.
Having established the signature of a moving average process, the next question of relevance is
whether one can recover the time-series model uniquely from the ACVF of a series. Recall Example
8.3 in this context, where we observed that two processes can have the same ACVF. The following
section discusses an important consequence of this non-unique mapping in time-series modeling.
9.4.2
INVERTIBILITY OF AN MA PROCESS
Building a time-series model involves both the estimation of the parameters of H(q−1) as well as
σ2
e. The ACF is useful in estimating the model coeﬃcients since it is independent of the variance of
the driving force, as exempliﬁed below.
Example 9.3: Invertibility
Recall the ACF of an MA(1) process v[k] = e[k] + h1v[k −1]:
ρvv[l] =

1
l = 0
h1
(1 + h2
1)
l = ±1
0
|l| ≥2
Given ACF, what is the estimate of h1? Solving the quadratic equation above for h1 given
ρ[1] results in two roots that are reciprocals of each other. By a visual inspection, it is easy
to observe that both h1 and 1/h1 produce the same ACF.
The corresponding models are
Model 1:
h1 = c1;
σ2
e =
σ2v
1 + c2
1
(9.22a)
Model 2: h1 = 1/c1;
σ2
e =
c2
1σ2v
1 + c2
1
(9.22b)
where
c1 = −
1
2ρ[1] +
q
1 −4ρ2[1]
2ρ[1]
(9.22c)
Both models, in principle, qualify to describe the given MA(1) process. However, the question
that arises is if one model has a particular advantage over the other.
In general, for a given ACF there will always exist two MA models, one with zeros outside
the unit circle and another with zeros inside the unit circle. The root cause for this imbroglio can
once again be traced back to the spectral factorization result, which is described later in §11.6. At
present, the question of interest is whether both models or only one among the two are acceptable.
This question can be answered by taking into account the end-use of the model, which is typically
prediction. The requirement is that the chosen model should produce stable predictions. The follow-
up example below oﬀers insights.
Example 9.4: Prediction Using an MA(1) Model
Consider the prediction of an MA(1) process using the model v[k] = e[k] + h1e[k −1] and
measurements up to k.

Models for Linear Stationary Processes
213
Denoting the predictions with a hat, we can write
ˆv[k + 1|k] = h1e[k]
since e[k + 1] is unpredictable given any amount of information in the past. The white-noise
signal e[k] is not available, but can be in principle, recovered from the observations v[k]. To
recognize this, re-write the model equation,
e[k] = v[k] −h1e[k −1]
= v[k] −h1v[k −1] + h2
1e[k −2]
= v[k] +
∞
X
n=1
(−h1)nv[k −n]
(9.23)
For the inﬁnite sum on the RHS to converge, |h1| < 1.
Thus, to produce stable predictions, it is important to select the model with |h1| < 1.
In general, observe that we could write (9.23) as
e[k] = H−1(q−1)v[k]
provided the inverse exists, which is guaranteed if the condition |h1| < 1 is satisﬁed.
A general expression for prediction of noise models is derived in Chapter 18,
ˆv[k + 1|k] = (1 −H−1(q−1))v[k + 1]
(9.24)
Remarks:
Equation (9.24) looks a bit unusual in the sense it appears as if v[k + 1] is required to compute
ˆv[k + 1]. However, since the leading coeﬃcient of H(q−1) is unity, the fact is that v[k + 1] is not required for
computing ˆv[k + 1].
Thus, only those MA models that are invertible are admissible (so as to guarantee stable predic-
tions).
Invertibility is related to the zeros of the transfer function H(z−1) as stated below.
Theorem 9.1
An MA(M) process is invertible if and only if all the roots (in terms of z−1) of the characteristic
equation
H(z−1) = 1 +
M
X
n=1
hnz−n
(9.25)
reside outside the unit circle.
Alternatively, all the zeros of H(z−1) are required to be located inside the unit circle (the con-
vention is to compute zeros and poles in terms of z).
Proof. The proof is straightforward by requiring that the inverse of the model be stationary (stable).
The poles of the inverse are the zeros of the original transfer function.
□
To summarize, MA models are characterized by ﬁnite coeﬃcients and ﬁnite-length ACVFs. The
mapping between the model parameters and ACVF is not unique. The uniqueness is brought about
by requiring the MA models to be invertible.

214
Principles of System Identiﬁcation: Theory and Practice
We close this section with an example of estimating a moving average model for a simulated
series. The idea is to illustrate the basic procedure. The working details of the underlying estimation
algorithms are provided in Chapter 19.
Example 9.5: Fitting an MA Model to a Simulated Series
Data consisting of N = 2000 samples of a simulated process is available. A snapshot of the
series is shown in Figure 9.1(a). The goal is to ﬁt an MA model of appropriate order. The
0
50
100
150
200
250
−4
−3
−2
−1
0
1
2
3
4
5
Samples
Amplitude
(a) Snapshot of the simulated series
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Auto−correlation function
ACF
Lags
(b) ACF of the series
FIGURE 9.1
Snapshot of the series in Example 9.5 and its ACF.
ﬁrst step is to examine the ACF of the series shown in Figure 9.1(b). The dashed lines are
the 99% signiﬁcance levels for the estimates. They aid in testing the signal for whiteness,
i.e., for lack of predictability. If the hypothesis that the signal is white holds, the estimates
of ACF at all lags should lie within these bands with 99% probability. For the case under
study, this requirement is violated at lags l = 1,2. Therefore we reject the hypothesis that
the signal is white. Further, since the ACF at lags l > 2 are insigniﬁcant, we premise that the
series can be modeled as an MA(2) process (a more appropriate way of order determination
is done through rigorous statistical analysis or using information criteria methods).
Choosing the order as two and estimating the MA(2) model with a non-linear least squares
algorithm (see Chapter 14 and §19.3) produces
ˆH(q−1) = 1 + 1.31
(±0.02)q−1 + 0.42
(±0.02)q−2
(9.26)
where as usual the values in parentheses are the standard errors in the estimates of the
respective coeﬃcients. The relatively negligible values of the errors reveal that the parameter
estimates are highly reliable.
The residuals of the model are subjected to a whiteness test to determine the adequacy
of the model. Figure 9.2 displaying the ACF estimates and the associated 99% signiﬁcance
levels shows that we cannot reject the hypothesis that the residuals are white. Therefore, the
estimated model is satisfactory in all critical aspects.
For instructional purposes, it is worth noting that the actual model used in the generation
of the series is
H(q−1) = 1 + 1.3q−1 + 0.4q−2
(9.27)

Models for Linear Stationary Processes
215
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Auto−correlation function
ACF
Lags
FIGURE 9.2
ACF of the residuals from the estimated model in (9.26).
Listing 9.1
MATLAB code for Example 9.5
% Generate the white-noise input
ek = randn(2000,1);
% Set up the MA(2) model coefficients
cvec = [1 1.3 0.4];
% Filter the white-noise with the MA model
vk = filter(cvec,1,ek);
% Plot the ACF
vk_acf = acf(vk,20,1);
% Create the iddata object
vkdata = iddata(vk,[],1);
% Estimate the MA(2) parameters
mod_ma = armax(vkdata,’na’,0,’nc’,2);
Now we turn our attention to the class of representations that attempt to describe processes using
the concept of “regression.” These representations are essentially diﬀerence equation descriptions
analogues of deterministic processes.
9.5
AUTO-REGRESSIVE MODELS
The term regression is borrowed from health sciences where it is usually used to describe the inﬂu-
ence of the past experiences on the present behavior (of a patient). We have earlier seen regression-
based descriptions in this text as diﬀerence equation models for deterministic LTI systems in §4.3.
The AR representation emerges whenever the best predictor for a process is a linear combination
of its past (recall (9.6)).
v[k] =
P
X
j=1
(−d j)v[k −j] + e[k]
or
(1 +
P
X
j=1
d jq−j)v[k] = e[k]
(9.28)
Observe that the uncertainty term represented by the white-noise signal e[k] is indispensable to the
model.
Supported by the theoretical arguments in Section 4.3, it is easy to show that any AR description
is essentially the equivalent of (9.10a) under a parametrization of the IR coeﬃcients {h[.]}.
The transfer function operator and the transfer function are given by
H(AR)(q−1) =
1
1 +
P
X
j=1
d jq−j
;
H(AR)(z−1) =
1
1 +
P
X
j=1
d j z−j
(9.29)

216
Principles of System Identiﬁcation: Theory and Practice
9.5.1
STATIONARY REPRESENTATIONS
The AR representation in (9.29) does not necessarily satisfy the stationarity requirement in (9.10b).
Earlier in Section 9.3 we observed that the stationarity requirement of linear random models is
equivalent to the stability condition of LTI deterministic processes. Based on this equivalence, we
admit only those AR models that are stable, i.e., those which have poles of H(z−1) inside the unit
circle.
Theorem 9.2
The AR(P) model in (9.29) produces a stationary series if and only if H(z−1) represents a stable
transfer function, i.e., all the poles of H(z−1) reside in the unit circle.
Proof. The result can be proved by constructing an equivalent inﬁnite-order MA model (see Section
9.5.5) followed by an invocation of (9.10b). Alternative methods also exist. Relevant details are
found in classical texts (see Shumway and Stoﬀer (2006, Chapter 3)).
□
Note: Recall that the poles are computed as roots of the denominator of H(z−1) in terms of z. If the roots
are expressed in terms of z−1, the requirement is that they should reside outside the unit circle.
Causality of AR models
Notwithstanding the result above, an AR model with poles outside the unit circle can still represent
a stationary process, but the resulting model is not causal as shown below with an example inspired
from Shumway and Stoﬀer (2006).
Example 9.6: Causality
Consider an AR(1) process v[k] + d1v[k −1] = e[k] with pole outside the unit circle, i.e.,
|d1| > 1. Then, introducing α1 = 1/d1 and using the shift-operator notation, we could re-
write the AR(1) process as
q + d1
q
v[k] = e[k]
(9.30)
=⇒v[k] =
q
q + d1
e[k]
(9.31)
= α1(1 + α1q)−1qe[k]
(9.32)
= −
−1
X
n=−∞
(−α1)−ne[k −n]
(9.33)
providing a linear stationary model for v[k] in terms of future values of shock waves. The rep-
resentation is stationary because the coeﬃcient sequence is absolutely convergent. However,
we have a non-causal model.
Explosive (unstable) models therefore possess a stationary representation but those which are non-
causal in nature. These models are however of little use in forecasting; hence, we exclude them from
all subsequent discussions.
In the remainder of the text, the phrases stationary AR models and causal AR models shall be
used interchangeably.

Models for Linear Stationary Processes
217
9.5.2
ACF OF AR PROCESSES
In the previous section, it was shown that an MA model is appropriate if the ACF falls oﬀfor lags
|l| > M. The goal of this section is to determine if a similar characteristic signature of AR processes
exists.
Recall the example of Section 8.3.1 where it was shown that ACF of an AR(1) process has an
exponential decay. The extension of the result to the general case below shows that the ACF of
an AR(P) process is a sum of exponentials. This is not a useful signature for modeling purposes.
Nonetheless, it paves the way for an interesting set of equations known as the Yule-Walker equa-
tions. Later in this section, it is established that the PACF is the characterizing statistical property of
an AR process (recall the example in Section 8.5.1) and plays a remarkably similar role as the ACF
does for the MA process.
ACF of a general AR(P) process
A general AR(P) process is described by,
v[k] =
P
X
j=1
(−d j)v[k −j] + e[k]
Using the standard procedure to compute the theoretical ACF, we obtain
σvv[l] = E(v[k]v[k −l]) =
P
X
j=1
−d jσvv[l −j] + σev[l]
Alternatively, in the diﬀerence equation form
σvv[l] +
P
X
j=1
d jσvv[l −j] = σev[l]
(9.34)
with
σev[l] =
(
σ2
e
l = 0
0
l > 0
Note that it suﬃces to be concerned with l > 0 due to the symmetric nature of the ACF.
The LHS of (9.34) has a form that is identical to that of the AR representation; the only distinction
being that the forcing function of (9.34) is a deterministic sequence. This leads to an interesting
observation.
The ACVF of an AR process has the same characteristic equation as that of the original
process.
To arrive at the general expression for the ACF, one could use any of the techniques that are used to
solve diﬀerence equations. The solution depends on the nature of roots. The case of distinct roots is
suﬃcient for the purpose of discussion.
If the roots of the characteristic equation are distinct, the solution takes the form
σvv[l] = α1λl
1 + α2λl
2 + · · · + αPλl
P ∀l > 0
(9.35)

218
Principles of System Identiﬁcation: Theory and Practice
where {λ−1
j }P
j=1 are the roots of the AR polynomial
D(q−1) = 1 +
P
X
j=1
d jq−j = ΠP
j=1(1 −ξjq−1) = 0
Thus, the ACVF is a sum of mixed exponentials. When the roots are repeated, the ACVF involves
lag-multiplied exponentials while complex roots would induce oscillatory characteristics. Regard-
less of the nature of roots, the ACVF is a convergent sequence as long as the generating process is
stationary.
Yule-Walker equations
A closer look at Equation (9.34) reveals that it is suﬃcient to solve the ACVF coeﬃcients from lags
l = 0,· · · ,P for an AR(P) process
σvv[0] +
P
X
j=1
d jσvv[j] = σ2
e
(9.36a)
σvv[l] +
P
X
j=1
d jσvv[l −j] = 0
l = 1,· · · ,P
(9.36b)
The auto-covariance coeﬃcients at subsequent lags |l| > P can be obtained by recursively solving
(9.34). Thus, it is suﬃcient to solve a set of P + 1 simultaneous equations. Equations (9.36a) to
(9.36b) are named Yule-Walker equations after their proponents Yule and Walker (Walker, 1931;
Yule, 1927).
The following example demonstrates the use of Y-W equations on an AR(2) process.
Example 9.7: ACVF of an AR(2) Process
Obtain the ACVF of an AR(2) process:
v[k] = −d1v[k −1] −d2v[k −2] + e[k]
Solution: When P = 2, the equations are (dropping the subscripts on σ)
σ[0] + d1σ[1] + d2σ[2] = σ2
e
σ[1] + d1σ[0] + d2σ[1] = 0
σ[2] + d1σ[1] + d2σ[0] = 0
=⇒

1
d1
d2
d1
(1 + d2)
0
d2
d1
1


σ[0]
σ[1]
σ[2]

=

σ2e
0
0

The solution is given by
σ[0] = σ2
v =
(1 + d2)σ2e
(1 + d2)(1 −d2
2) −d2
1 + d2
1d2
;
ρ[1] = −
d1
1 + d2
ρ[2] = −d2 +
d2
1
1 + d2
At lags |l| > 2, the ACVF is obtained by recursively solving
σ[l] = −d1σ[l −1] −d2σ[l −2]
Figure 9.3 plots the theoretical ACF of the AR(2) process in Problem 9.7 with d1 = −1.2,d2 =
0.35. The exponential decay is vividly seen.

Models for Linear Stationary Processes
219
0
5
10
15
20
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Lags
ACF
Theoretical ACF of an AR(2) process
FIGURE 9.3
Theoretical ACF of AR(2) process with d1 = −1.2,d2 = 0.35.
The Y-W equations for a general AR(P) process are set up as

1
d1
· · ·
dP−1
dP
d1
1 + d2
· · ·
dP
0
...
...
...
...
...
dP−1
dP
· · ·
1 + dP
0
dP
dP−1
· · ·
d1
1

|                                          {z                                          }
ΘP

σ[0]
σ[1]
...
σ[P −1]
σ[P]

|       {z       }
σ0:P
=

σ2
e
0
...
0
0

|{z}
ς
(9.37)
from where the ACVF is obtained as
σ0:P = Θ−1
P ς
(9.38)
Use of Y-W equations
The Y-W equations are useful in
1. Computing the theoretical ACF for a given AR process (model)
2. Estimating the AR model parameters (and σ2
e) for a known ACF
3. Determining the P constants αj (j = 1,· · · ,P) of the general solution (9.35)
Of the above three uses, the second is the most valuable one. Note that the ﬁrst use was demonstrated
in Problem 9.7.
The second point can be realized by treating the parameters as unknowns and re-writing the
equations

σ[0]
σ[1]
· · ·
σ[P −1]
σ[1]
σ[0]
· · ·
σ[P −2]
...
...
· · ·
...
σ[P −1]
σ[P −2]
· · ·
σ[0]

|                                               {z                                               }
ΣP

d1
d2
...
dP

|{z}
θP
=
−

σ[1]
σ[2]
...
σ[P]

|  {z  }
σP
The solution to the Y-W equations is then
θP = Σ−1
P σP
(9.39)
Equation 9.39 oﬀers a good means of estimating parameters of an AR(P) model for a given series.
To use it in practice the theoretical ACVFs are replaced by the corresponding estimates. This method

220
Principles of System Identiﬁcation: Theory and Practice
of estimating parameters belongs to the so-called method of moments. This topic is further discussed
in Chapter 14.
The question of interest is naturally, how to choose an appropriate value of P? This takes us back
to the problem of ﬁnding the signature characteristic of an AR process for order determination; in a
similar way as the ACF indicates the order of an MA process.
At this juncture, we can conceive two alternatives to determine the order:
1. Fit AR models of successively increasing orders (guesses) until we stumble upon the “true” order,
or
2. Discount for the propagative eﬀects to uncover the true order
It turns out both of these options are identical to using PACF to determine the order. The following
section is devoted to this issue.
9.5.3
ORDER DETERMINATION AND PACF
Recall from Section 8.5.1 that the PACF measures direct correlation. It is capable of “seeing
through” the propagated eﬀects in an AR process and correctly detecting the order of a regres-
sive process. This property of PACF makes it a suitable tool for determining the order of a general
AR process.
The main result is stated below.
Theorem 9.3
The PACF of an AR(P) process vanishes for all lags l > P,
φvv[l] = 0
∀l > P
(9.40)
Proof. A proof of the above result is constructed through the successively increasing order method
as described below.
1. Fit AR(p) models
v[k] =
p
X
j=1
φp jv[k −j] + e[k]
(9.41)
of successively increasing orders p = 1,· · · ,Pmax. where the maximum order Pmax is a user-
deﬁned parameter.
2. Collect the last coeﬃcient φpp, ; j = 1,· · · ,P0 of each model that is ﬁt.
3. Determine P0, the value of p after which φpp persistently remains at zero.
Then P0 is the true order of the AR process. This claim is based on the fact that when an AR(p)
model is ﬁt to an AR(P0) process,
φpp = 0
∀p > P0
(9.42)
The proof is completed by showing that the last coeﬃcient of any AR(p) model is indeed the
PACF at lag p (see Exercise E9.4.),
φ[p] = φpp
(9.43)
□

Models for Linear Stationary Processes
221
A useful outcome of Theorem 9.3 is an alternative method for computing the PACF at any lag l,
which is by ﬁtting AR(l) model and extracting its last coeﬃcient.
A recursive algorithm due to Durbin and Levinson (Durbin, 1960; Levinson, 1947) is available
for estimating AR models of successively increasing orders in a computationally eﬃcient manner.
TABLE 9.1
Durbin-Levinson’s algorithm
1. Fit the best AR model of ﬁrst order. The optimal estimate is φ11 = ρ[1]
2. The coeﬃcients of AR(p) models of orders p ≥2 can be recursively computed as
φp+1, p+1
=
ρ[p + 1] −
p
X
j=1
φp j ρ[p + 1 −j]
1 −
p
X
j=1
φp j ρ[j]
(9.44a)
φp+1, j
=
φp j −φp+1, p+1φp, p−j+1
j = 1,· · · ,p
(9.44b)
With the alternate deﬁnition of PACF as above, the D-L algorithm in Table 9.1 can be used for
recursively computing the PACF coeﬃcients as well.
The example below elucidates this idea.
Example 9.8: D-L Algorithm for Computation of PACF
Compute the PACF of a stationary process at lags l = 1,2
Solution: The PACF at lag l = 1 is the coeﬃcient of the AR(1) model
φ11 = ρ[1]
which coincides with the value obtained by deﬁnition
At lag l = 2, using the D-L algorithm,
φ22 = ρ[2] −φ11ρ[1]
1 −φ11ρ[1]
= ρ[2] −ρ[1]2
1 −ρ[1]2
When the underlying process is AR(1), φ22 = 0, corroborating Theorem 9.3 and Equation
(9.43).
Once the “true” order is determined using PACF, the algorithm can be used for computing the
remaining coeﬃcients φjP0, j = 1,· · · ,P0 −1.
Remarks:
A certain method of determining the order computes by overﬁtting a very high-order AR model
to the series followed by an inspection of the largest index of the signiﬁcant coeﬃcients. This method is not
recommended because, ﬁrst, the errors in estimates depend on the number of parameters being estimated and
secondly, the theoretical interpretation is missing.
Reﬂection coefﬁcients
In statistical signal processing and time-series literature, it is common to use the term reﬂection
coeﬃcient, which is deﬁned as the negative of the PACF coeﬃcient at a lag l = p. Thus,
κp ≜−φpp
(9.45)

222
Principles of System Identiﬁcation: Theory and Practice
Further, using the D-L equations (9.44), a recursive relation between the parameters of models of
orders p and p −1 can be written in terms of the reﬂection coeﬃcient κp as follows:
θ(p) =
"
θ(p−1) + κp ¯θ(p−1)
κp
#
(9.46)
where
¯θ(p−1) =
f
dp−1
dp−2
· · ·
d1
gT
(9.47)
is merely the reﬂection of the parameter vector θ(p−1) =
f
d1
d2
· · ·
dp−1
gT. Equation (9.46)
also explains the name given to κp.
The notion of reﬂection coeﬃcient is central to a popular method of estimating AR models,
known as the Burg’s method (see §19.2.4).
9.5.4
ALTERNATIVE REPRESENTATIONS OF THE AR PROCESS
The Y-W equations, i.e., the recursive relations for the ACVF and the concept of PACF coeﬃ-
cients give way to alternative representations for an AR process. Thus, in addition to the standard
parameter-based representation in (9.28), we have two other representations for an AR(P) process:
1. The ACFs at lags l = 1,· · · ,P and the innovations variance σ2
e.
2. The reﬂection (or the PACF) coeﬃcients at lags l = 1,· · · ,P and the innovations variance.
In principle both the above representations are theoretically equivalent to the parametric represen-
tation in (9.28). For instance, the parameters corresponding to an ACF-based description can be
recovered theoretically using the Y-W equations. Similarly, the D-L recursion can be used to obtain
the ACF from the reﬂection coeﬃcient-based description. The distinction between these representa-
tions arises once again in the context of estimation just as we argued for deterministic LTI systems.
One form of representation may be more suited than the other for a given application. A classic ex-
ample is that of using the reﬂection coeﬃcient-based representation over the parametric one because
of an interesting result:
An AR(P) process is stationary if and only if |κp| < 1, p = 1,· · · ,P.
In other words, all reﬂection coeﬃcients of a stationary process take on values between -1 and 1.
In Burg’s method of estimating an AR model, the estimates of these coeﬃcients are constrained to
satisfy this requirement so that the resulting model estimate is stationary. It would be very diﬃcult
to achieve the same with the parametric representation of (9.28).
There exist other representations, most of which are suited to specialized applications. All
these representations are equivalent, but essentially describe the AR models in diﬀerent ways. See
Broersen (2006, Section 5.3) for related discussion.
We now demonstrate the foregoing results in the estimation of a parametric AR model to a
simulated series.
Example 9.9: Fitting an AR Model to a Simulated Series
Data consisting of N = 2000 samples of a simulated process is available. The goal is to
ﬁt an AR model of appropriate order. The ﬁrst step is to subject the ACF of the series
to a whiteness test as explained in Example 9.5. Figure 9.4(a) oﬀers visible evidence for
predictability. The exponentially decaying nature of ACF is indicative of an AR-like process.

Models for Linear Stationary Processes
223
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
(a) ACF of the series
0
5
10
15
20
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
PACF
Lags
(b) PACF of the series
FIGURE 9.4
ACF and PACF of the series in Example 9.9.
To determine the appropriate order, we turn to the PACF, which is shown in Figure 9.4(b).
The dashed lines carry the same interpretation as they did in the ACF.
Choosing the order as two and estimating the AR(2) model with the linear least squares
algorithm (see Chapter 14) produces
ˆH(q−1) = 1/(1 −1.251(±0.021)q−1 + 0.3932(±0.021)q−2)
(9.48)
The estimates are highly reliable, as indicated by the standard errors in the coeﬃcient
estimates. Next, we subject the model residuals to a whiteness test as per the standard
procedure. The ACF of the residuals and the signiﬁcance levels in Figure 9.5 amply indicate
that the model has good predictive abilities.
Thus, the obtained model is satisfactory in both respects, reliability of parameter estimates
as well as white prediction errors.
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
FIGURE 9.5
ACF of the prediction errors from the estimated model in (9.48).
The model used in generating the AR series is
H(q−1) = 1/(1 + 1.2q−1 + 0.35q−2)
(9.49)
In a complete AR identiﬁcation exercise, the variance of the white-noise source σ2e is also
estimated. For this example, the estimate is obtained as ˆσ2e = 0.9926 against the true value
of σ2e = 1 used in simulation.
Auto-regressive models hold a strong leverage over the moving average representations in an im-
portant respect, which is that of estimation. Linear estimators can be used to optimally estimate AR
models while this does not hold for MA representations (read Chapters 18 and 19 for details). The

224
Principles of System Identiﬁcation: Theory and Practice
reason is that auto-regressive models result in linear-in-parameter predictors, whereas MA models
produce predictors that are non-linear in parameters. Linear estimators are advantageous because
they lead to unique solutions (especially when combined with least squares methods, see Chapter
14) and are computationally simple, whereas non-linear estimators require numerical optimization
algorithms, which most often deliver locally optimal solutions.
Listing 9.2
MATLAB code for Example 9.9
% Generate the random signal
ek = randn(2000,1);
dvec = [1 -1.2 0.35];
vk = filter(1,dvec,ek);
% Plot the ACF and PACF
vk_acf = acf(vk,20,1);
vk_pacf = pacf(vk,20,1);
% Create the iddata object
vkdata = iddata(vk,[],1);
% Estimate the AR(2) parameters
mod_ar = armax(vkdata,’na’,2,’nc’,0);
% Predictions and residuals
vkhat = predict(mod_ar,vk,1);
We conclude this section by observing an important fact, which in some sense is a re-visit of
the facts delineated in Chapter 4 for deterministic processes. This is concerning the equivalence
between AR and MA representations.
9.5.5
EQUIVALENCE BETWEEN AR AND MA REPRESENTATIONS
The focal point of this section is that stationary AR and invertible MA representations are equivalent.
Consider the following motivational example.
Example 9.10: Fitting AR and MA Models
The ACF and PACF plots of a series are shown in Figures 9.6(a) and 9.6(b).
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Auto−correlation function
ACF
Lags
(a) ACF plot
0
5
10
15
20
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Partial auto−correlation function
PACF
Lags
(b) PACF plot
FIGURE 9.6
ACF and PACF plots of an unknown process.
From the plots, we can make two diﬀerent observations leading to two alternative repre-
sentations for the same process. Figure 9.6(a) shows that the ACF coeﬃcients are statistically
insigniﬁcant after lags l = 8 and hence an MA(8) representation seems appropriate. On the
other hand, Figure 9.6(b) suggests an AR(3) (or perhaps an AR(5)) representation.

Models for Linear Stationary Processes
225
Estimating both the model forms, we obtain:
MA model:
c1 = 1.058
(±0.02)
c2 =
0.69
(±0.033);
c3 = 0.411
(±0.036);
c4 = 0.183
(±0.04)
c5 = 0.092
(±0.037);
c6 = 0.084
(±0.036);
c7 = 0.062
(±0.033);
c8 = 0.045
(±0.022)
AR model:
d1 = −1.054
(±0.022)
d2 = 0.415
(±0.031);
d3 = −0.0937
(±0.022) ;
with noise variance estimates as ˆσ2e = 0.994 and ˆσ2e = 0.9912, respectively. It is left as a simple
exercise to the reader to verify that this estimated AR model is stationary.
The residuals of both models pass the whiteness test. However, some of the parameter
estimates of the MA model suﬀer from large errors (c5,c6,c7 and c8). Thus, the MA model
has been over-parametrized. A reduced-order MA(4) model is estimated, whose parameter
estimates are
MA model:
c1 = 1.059
(±0.02)
c2 = 0.683
(±0.031);
c3 = 0.382
(±0.031);
c4 = 0.126
(±0.02)
which produces white residuals. The noise variance estimate is ˆσ2e = 0.9965. The reader may
verify that this model is indeed invertible.
In summary, both AR(3) and MA(4) models serve as good representations of the under-
lying process. The parameter dimensions of both models are not signiﬁcantly diﬀerent.
The results of the example above are not surprising since, in general, any stationary AR model
has an invertible MA representation and vice versa, similar to the equivalent representations that
diﬀerence equation and convolution models enjoy.
In general, the following result is true (the proof is left to the reader as an exercise).
Any stationary AR(P) model has an inﬁnite-order MA representation; on the same hand, any
invertible MA(M) model possesses a stationary (causal) inﬁnite-order AR representation.
An example below demonstrates the procedure for obtaining an AR representation for an MA
process.
Example 9.11: AR Representation of an MA Process
Find a stationary AR representation of an MA process:
v[k] = e[k] + 0.6e[k −1]
Solution: The AR representation can be found by either recursively substituting for past
values of e[k] in terms of v[k] or by a long division of the MA polynomial (provided the
inverse converges). We shall use the latter method. Existence of inverse is guaranteed by the
invertibility of the MA model.
v[k] = (1 + 0.6q−1)e[k]
=⇒(1 + 0.6q−1)−1v[k] = e[k]
(1 −0.6q−1 + 0.36q−2 −...)v[k] = e[k]
Thus, the ﬁnite-order MA process has an inﬁnite-order AR description:
v[k] =
∞
X
j=1
(−0.6) jv[k −j] + e[k]

226
Principles of System Identiﬁcation: Theory and Practice
A compelling question to ask in this context is: which model is more appropriate? There is no
deﬁnitive answer to this question. Instead we turn to the guidelines described in Section 3.2.1. The
considering factors are: (i) end-use of the model, (ii) ease of estimation and (iii) model complexity
(number of parameters, model form, etc.). Based on these considerations, the AR model is favorable
in Example 9.10 because it can be estimated using a linear least squares algorithm and has fewer
parameters.
On the other hand, it is likely that for a diﬀerent process, the MA model is preferable despite
the need for a numerical optimization algorithm, because the AR representation of the process may
require a much larger number of parameters.
Notwithstanding the above observations, it is possible to build a representation with even fewer
parameters when models with both MA and AR eﬀects are considered, giving rise to a general class
of models.
9.6
AUTO-REGRESSIVE MOVING AVERAGE MODELS
No stationary process can be expected to be purely either AR or MA type.
A more general representation is one that contains mixed eﬀects, which is the auto-regressive
moving-average, or an ARMA(P, M) representation
H(q−1) = C(q−1)
D(q−1) =
1 +
M
X
i=1
ciq−i
1 +
P
X
j=1
d jq−j
(9.50)
The ARMA representation is the analogue of the general diﬀerence equation description of a
deterministic LTI system given in (4.32). Thus, it combines both MA and AR representations under
the umbrella of LTI systems as depicted in Figure 9.7.
e[k]
H(q−1)
v[k]
FIGURE 9.7
LTI representation of AR and MA models.
Observe that the white-noise e[k] is both the unpredictable component of v[k] and a ﬁctitious
input that generates v[k]. Only those ARMA models that are both invertible and stationary are
allowable representations for causal, stationary processes.
Note that any (invertible and stationary) ARMA process can always be given an equivalent (sta-
tionary) AR or (invertible) MA representation. However, the resulting models are of inﬁnite-order.
Neither the ACF nor PACF can provide a practically useful distinct signature to determine the
order of the numerator and denominator polynomials. ARMA model orders are usually determined
iteratively and using information theoretic considerations.
For the sake of completeness, we brieﬂy discuss the procedure to obtain the theoretical ACF of
an ARMA process. There are primarily two diﬀerent ways in which one can calculate the theoretical
ACF of a ARMA(P, M) process:
Method I: Convert the given ARMA model to an MA representation and use the auto-covariance gener-
ating function. The equivalent MA model is of inﬁnite-order. Therefore, a generic expression for
H(q−1) may be required for the purpose.

Models for Linear Stationary Processes
227
Method II: Set up the diﬀerence equation in terms of ACVF coeﬃcients.
Solve the ﬁrst K set of equations for lags l = 0,· · · ,K −1 where K = max(P + 1, M + 1).
Subsequently, obtain the ACVFs at larger lags l > K recursively as in the case of an AR process.
Regardless of the method, it is a fact that the eﬀect of MA component of the process on the ACVF
prevails only up to lag l = M; thereafter, the AR eﬀects persist. The MA component essentially
results in a diﬀerent forcing function for the diﬀerence equation that generates the ACVF of an AR
process.
The PACF of an ARMA process has a complicated behavior and is primarily of academic interest.
For this reason, we avoid the discussion on the same. The interested reader is referred to texts that
discuss this topic in detail (Box, Jenkins and Reinsel, 2008).
A numerical example on the estimation of ARMA models is illustrated in §19.4.
We conclude this chapter with the representations of a class of non-stationary processes, known
as the auto-regressive integrated moving average (ARIMA) representations.
9.7
AUTO-REGRESSIVE INTEGRATED MOVING AVERAGE MODELS
Non-stationarities are of various kinds as discussed in Section 7.5.5. The mean non-stationarities,
particularly trends, are handled by polynomial ﬁts to the series followed by ﬁtting stationarity mod-
els to the residuals. Integrating type non-stationarities are commonly encountered in engineering
systems. As explained in §7.5.5, the method of diﬀerencing the series followed by a stationary
ARMA ﬁt is a widely used approach for describing these processes. The resulting representation is
known as the ARIMA model. These representations were largely popularized through the works of
Box and Jenkins (Box, Jenkins and Reinsel, 2008).
The idea underlying ARIMA representations is to pre-incorporate or enforce an integrator into
the model by writing a stationary ARMA representation for the diﬀerenced series. The degree of
diﬀerencing, i.e., the number of times the series has to be diﬀerenced depends on the application.
In order to describe an ARIMA process, it is convenient to introduce a diﬀerencing operator,
∇= 1 −q−1
so that
∇v[k] = v[k] −v[k −1]
(9.51)
When the series is diﬀerenced d times in succession, the operation is represented by
∇dv[k] = (1 −q−1)dv[k]
(9.52)
Note: The operator in (9.52) should not be confused with the lag-d diﬀerencing operator ∇d = 1 −q−d.
The ARIMA(P,d, M) representation is then the stationary ARMA(P, M) model for the diﬀer-
enced series ∇dv[k]:
∇dv[k] = C(q−1)
D(q−1) e[k]
(9.53)
For the original series, the transfer function is therefore
H(q−1) =
1 +
M
X
i=1
ciq−i
(1 −q−1)d(1 +
P
X
j=1
d jq−j)
(9.54)

228
Principles of System Identiﬁcation: Theory and Practice
0
200
400
600
800
1000
−15
−10
−5
0
5
10
15
20
Samples
Amplitude
(a) Integrating series
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
(b) ACF of I(1) series
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
PACF
Lags
(c) PACf of I(1) series
FIGURE 9.8
Integrating series, its ACF and PACF estimates.
Note that the pure integrator is a ﬁrst-order auto-regressive process with the pole on the unit circle.
It is conventionally represented as an I(1) process in many texts.
The quantities P and M have their usual meaning as in ARMA models. By diﬀerencing the
series d times, we are essentially forcing d poles of the ARIMA model (for the original series) to
be located on the unit circle.
A more general ARIMA representation is
∇dv[k] = µd + C(q−1)
D(q−1) e[k]
(9.55)
where the constant αd originates from the presence of a polynomial trend of the form Pd
i=0 µiki in
v[k]. Thus, when an ARIMA model with a constant is ﬁt to a given series, implicitly it is understood
that v[k] has a polynomial trend of degree d with or without integrating eﬀects. We shall mostly
work with (9.53).
ACF and PACF characteristics of an integrating process
Integrating eﬀects can be visually determined by examining the ACF of a given series. A rigorous
approach is to perform unit root tests on the series (discussion to follow). In Section 8.2.1, it was
remarked that ACF estimates exhibit a very slow decay for integrating type process. This fact can
be understood by examining the theoretical ACF of an AR(1) process,
ρ[l] = (−d1) |l |
(9.56)
As d1 approaches unity, the decay is very slow. In the limiting case d1 →1, i.e., as the process
tends to an integrator, the ACF remains a constant. The exact behavior of the estimates is more
complicated, but it tends to have that of the theoretical ACF for large samples. It follows that the
PACF of this process has a single non-zero coeﬃcient at lag l = 1 with a value tending to unity.
Figure 9.8 shows N = 1000 samples of an integrating process, the ACF and PACF estimates
from the data. The ACF and PACF estimates agree with the theoretical observations made earlier.
The slow decay in the ACF estimate is also the characteristic of a trend stationary process. Recall
the SMI series of Figure 7.4(d) and its ACF in Figure 8.1(d). The series is approximately charac-
terized by a linear trend as was demonstrated in Section 7.5.5. Observe how the ACF estimates
remain close to unity up to a large lag. A similar observation can also be made regarding the ECG
series of Figure 7.4(c) whose ACF was shown in Figure 8.1(c). The ACF exhibits a very slow decay.
Thus, the ECG can also be speculated to contain integrating or a trend type non-stationarity. These
speculations are further strengthened by the PACF plots in Figures 8.8(d) and 8.8(c), respectively.
The diﬀerencing operation truly serves its purpose only when the process has a pole location
exactly at unity. This requirement cannot be expected to hold for a general process. The natural
question is whether diﬀerencing a series is worth the risk. A point in favor of the diﬀerencing

Models for Linear Stationary Processes
229
approach is that the estimation of “stationary” poles, but close to unit circle, can result in models
with conﬁdence regions containing non-stationary models. By forcing the pole to the unit circle
a priori, this situation is avoided. The side eﬀect is however that a stationary process with slowly
decaying process acquires a non-stationary representation.
The following example demonstrates this point.
Example 9.12: A Case for Differencing
Consider N = 400 samples of a stationary process
H(q−1) =
1
1 −0.96q−1
The ACF and PACF of the series are shown in Figures 9.9(a) and 9.9(b), respectively. The
ACF shows a slow decay indicating possible random walk behavior, as conﬁrmed by the
PACF.
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
(a) ACF of series
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
PACF
Lags
(b) PACF of series
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
(c) PACF of diﬀerenced series
FIGURE 9.9
ACF, PACF of the series and ACF of the diﬀerenced series of Example 9.12.
For the purpose of illustration, we discount the possibility of integrating eﬀects and esti-
mate an AR(1) model,
ˆH(q−1) =
1
1 −0.9745
0.011 q−1
(9.57)
The pole location of the estimated (nominal) model is at 0.97, which is close to but within
the unit circle.
However, the 99% conﬁdence interval for the parameter d1 is given by −0.9745 ± 0.03 (see
Chapter 13 for computing conﬁdence intervals). Thus, one of the possible models in the model
set has a pole location outside the unit circle. This is not acceptable since an explosive model
cannot be considered in the possible model set for a process that is stationary or at worst
random walk.
On the other hand, the I(1) model is better suited for the series since at least it is not
explosive, if not stationary. The suitability of this model is supported by the ACF of the
diﬀerenced series in Figure 9.9(c).
In principle, diﬀerencing a series can eliminate both integrating (random walk) and drift types of
non-stationarities. However, ARIMA models require the diﬀerenced series to be stationary, which
does not necessarily hold for series that have drifts. Therefore, it is necessary to ascertain the type of
non-stationarity through an appropriate statistical test. Furthermore, for any stationary series, diﬀer-
encing operation introduces an artiﬁcial MA component with a root on the unit circle (non-invertible
MA term). This is a common risk associated with diﬀerencing approaches and is termed as overdif-
ferencing. It can arise in one of the following situations: (i) the series is trend-nonstationary, (ii)
the series is stationary and (iii) the series has been diﬀerenced more than necessary. The following
discussion throws light on the ﬁrst aspect.

230
Principles of System Identiﬁcation: Theory and Practice
Differencing operation for detrending and overdifferencing
Consider a process
v[k] = α0 + α1k + w[k]
α0,α1 ∈R
(9.58)
where w[k] is a stationary process.
First-diﬀerencing v[k] produces
vd[k] = ∇v[k] = α1 + ∇w[k]
(9.59)
which is a stationary process with non-zero mean. To this series one can ﬁt an ARMA (or a pure
AR or MA) model of appropriate order. It is easy to see that a d-degree diﬀerencing eliminates
polynomial trends of dth order.
Note that however ∇forces an MA component in vd[k] with a root on the unit circle (or d roots
introduced with ∇d), which is non-invertible. The estimated model need not necessarily have such
a feature.
Removal of linear or polynomial trends by curve ﬁtting seems to be the preferable way of de-
trending. However, it is not without its shortcomings. A major diﬃculty is the inability to distin-
guish between trends and incomplete cycles of very low frequencies Granger (1966) and Granger
and Hatanaka (1964). There exists no formal way of resolving this ambiguity. Only a few heuristic
guidelines are available. Another artefact is the introduction of spurious correlations at smaller lags.
The merits and demerits of ﬁrst-diﬀerencing versus curve ﬁtting approaches was brieﬂy discussed
in §7.5.5. An alternative approach for handling trends is through an appropriate ﬁltering of the series,
as described in Section 7.5.5. The idea is to estimate trends ﬁrst by means of the ﬁlter followed by
the development of an ARMA model for the stationary part. Simple moving average ﬁlters provide
crude estimates of trends. The weighted moving average ﬁlters and exponential ﬁlters are widely
used instead. Several classical texts on time-series analysis discuss this topic in greater detail (see
for example (Brockwell, 2002; Chatﬁeld, 2004)).
Identiﬁcation presents an additional concern, which is the possibility (or lack thereof) of the
deterministic process resulting in trends and integrating eﬀects. In the frequency-domain, integra-
tors are ideal low-pass ﬁlters while the diﬀerencing operation is equivalent to passing the series
through a high-pass ﬁlter. When the deterministic component contains the integrating eﬀects and
the stochastic term is stationary, diﬀerencing the measurement eliminates the non-stationary deter-
ministic term but enhances the noise content (relative to the eﬀects of input). Other scenarios are
also possible, for example, non-stationarities in both deterministic and stochastic parts. The diﬀer-
ent possibilities and consequences of removal of trends and diﬀerencing of the series on the quality
of the identiﬁed models for each of these scenarios are discussed in §22.4.1.
An example of the second and third type, i.e., inadvertently diﬀerencing a stationary series or
overdiﬀerencing can be easily constructed. Suppose the given series or that a diﬀerenced signal is
white, v[k] = e[k]. Diﬀerencing v[k] yields,
∇v[k] = vd[k] = e[k] −e[k −1] = (1 −q−1)e[k]
(9.60)
A spurious correlation is thus observed in vd[k] at lag l = 1. Once again, we have that an artiﬁcial
non-invertible zero is introduced in the diﬀerenced series.
The above points clearly call for exercising caution in adopting the diﬀerencing approach and
the use of appropriate tests before developing an ARIMA model.

Models for Linear Stationary Processes
231
Tests for overdifferencing, unit roots and trends
A simple test that is used to determine whether a series has been overdiﬀerenced is to compare the
variances of the series prior to and post diﬀerencing. Theoretically, the point of overdiﬀerencing is
when the variance of ∇dv[k] is greater than v[k]. In the preceding example of diﬀerencing a white-
noise series, it is easy to verify that σ2
vd > σ2
v. However, this result does not necessarily hold for
correlated processes, i.e., if v[k] is not white. For such processes, this test overestimates the required
degree of diﬀerencing.
Rigorous statistical tests known as unit root tests are usually employed to test the presence of a
pole on the unit circle. This is a common practice in the analysis of econometrics and ﬁnancial time-
series analysis. Two conventional tests are the augmented Dickey-Fuller (ADF) (Said and Dickey,
1984) and the Phillips-Perron tests (Phillips and Perron, 1988). In addition, there exist methods to
test the presence of deterministic trends in a series, for example, Kwiatkowski, Phillips, Schmidt
and Shin (KPSS) test (Kwiatkowski et al., 1992). These tests can be used to determine whether
diﬀerencing or ﬁtting a polynomial trend is more appropriate.
The unit root tests are based on an important observation we made earlier. When the process
is stationary, diﬀerencing introduces a unit root MA factor in the ARMA representation of the
diﬀerenced series. The statistics of these tests follow a non-standard and non-normal asymptotic
distributions. Furthermore, the limiting distributions can be quite sensitive to the presence of deter-
ministic trends in the series. Consequently, eﬃcient unit root tests (Elliot, Rothenberg and Stock,
1996; Ng and Perron, 2001) were developed to address these drawbacks. However, the critical val-
ues for the unit root tests cannot be determined in the conventional way (reading oﬀstandard tables).
Simulation techniques are used to tabulate these critical values.
Keeping in with the overall scope of the book and the application domain of these tests, technical
details of these tests are avoided here. The interested reader is referred to classical texts on this
topic; see Hatanaka (1996) and Patterson (2012).
Estimating an ARIMA Model
We conclude this section with an example demonstrating the estimation of an ARIMA model on
a simulated series. Another aim of this example is to show the beneﬁt of ﬁtting an ARIMA model
rather than a traditional ARMA model of higher order.
Example 9.13: Fitting an ARIMA Model
Consider the simulated series shown in Figure 9.10(a). The goal is to develop a time-series
model for the process from these N = 1000 observations.
The ACF and PACF shown in Figures 9.10(b) and 9.10(c) strongly hint at the presence
of integrating eﬀects. The plots suggest at least two diﬀerent possible models.
0
100
200
300
400
500
600
700
800
900
1000
−25
−20
−15
−10
−5
0
5
10
15
20
Samples
Amplitude
(a) Simulated series
0
2
4
6
8
10
12
14
16
18
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
(b) ACF of the series
0
2
4
6
8
10
12
14
16
18
20
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
PACF
Lags
(c) PACF of the series
FIGURE 9.10
Simulated series, its ACF and PACF estimates pertaining to Example 9.13.
The ﬁrst possibility is to build a model for the series as is (ignoring any possible integrating
eﬀects), based on the signatures shown by the PACF plot. It suggests an AR(3) model as a

232
Principles of System Identiﬁcation: Theory and Practice
0
2
4
6
8
10
12
14
16
18
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
(a) ACF of AR(3) (original se-
ries) residuals
0
2
4
6
8
10
12
14
16
18
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
(b) ACF of ARMA(1,1) (diﬀer-
enced series) residuals
0
2
4
6
8
10
12
14
16
18
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
(c) ACF of AR(2) (diﬀerenced
series) residuals
FIGURE 9.11
ACF of residuals from models estimated in Example 9.13.
0
100
200
300
400
500
600
700
800
900
1000
−25
−20
−15
−10
−5
0
5
10
15
20
Samples
Amplitude
(a) Diﬀerenced series
0
2
4
6
8
10
12
14
16
18
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
(b) ACF of diﬀerenced series
0
2
4
6
8
10
12
14
16
18
20
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
PACF
Lags
(c) PACF of diﬀerenced series
FIGURE 9.12
Diﬀerenced series, its ACF and PACF.
suitable candidate. The estimates of AR(3) model are obtained as:
ˆH1(q−1) =
1
1 −1.844
(±0.03)q−1 + 1.082
(±0.06)q−2 −0.2249
(±0.03)q−3 ;
ˆσ2
e = 0.9617
(9.61)
The parameter estimates are reliable. The ACF of the residuals shown in Figure 9.11(a)
suggest that the model has captured all the predictable variations. Thus, this model qualiﬁes
to be acceptable.
Now we explore the second option, which is to build an ARIMA model recognizing the
integrating eﬀects. The diﬀerenced series vd[k] = ∇v[k] and its ACF as well as PACF are
shown in Figure 9.12. The PACF suggests an AR(2) model for vd[k]. For comparison purposes,
we estimate an ARMA(1,1) model which is also characterized by two parameters.
The estimated AR(2) model is
ˆH(q−1) =
1
1 −0.821
(±0.03)q−1 + 0.243
(±0.03)q−2 ;
ˆσ2
e = 0.9769
while the ARMA(1,1) estimate is obtained as
ˆH(q−1) = 1 +
(±0.04)
0.364 q−1
1 −0.467
(±0.04)q−1
ˆσ2
e = 0.9814
Both these models pass the residual whiteness test as shown in Figures 9.11(c) and 9.11(b)
respectively. Thus, the two models are equally acceptable. The estimated variance of the
white-noise inputs are comparable. However note that the estimates of the AR(2) model
are optimal and unique whereas the parameter estimates of the ARMA(1,1) model are only
locally optimum. From an estimation viewpoint, therefore, the AR(2) model is favorable.
Thus, a working ARIMA model for the series v[k] is
ˆH2(q−1) =
1
(1 −q−1)(1 −0.821
(±0.03)q−1 + 0.243
(±0.03)q−2)
(9.62)

Models for Linear Stationary Processes
233
Incidentally the model in (9.61) for the original (un-diﬀerenced) series (9.61) and the one in
(9.62) for the diﬀerenced series are of the same order. The distinguishing feature is the pole
locations of these two models, as given below
Poles( ˆH1) :
0.9625,0.4185 ± j0.2344
Poles( ˆH2) :
1,0.4104 ± j0.2732
The nominal poles of ˆH1 are all stable, thus corresponding to a stationary model whereas one
of the nominal poles of ˆH2 is on the unit circle, making it a non-stationary representation.
The issue is which model is preferable?
A decisive factor is the pole locations of the family of models in the conﬁdence region
(computed from the standard errors in parameter estimates). One of the possible models in
the model set of ˆH1 has poles located at 1.0324,0.4283 ± j0.3438 (the model with coeﬃcients
ˆdi +3ˆσdi ). Thus, the possible model set includes an explosive model, which is not acceptable.
because the conﬁdence intervals for predictions are unbounded. It is not diﬃcult to see that
the model set associated with ˆH2 does not possess this shortcoming.
In light of these arguments, ˆH2(q−1) is selected as a suitable model for the given series.
It is of interest to note that the actual process model used in generating the series is:
H(q−1) =
1 + 0.3q−1
(1 −0.97q−1)(1 −0.54q−1)
Listing 9.3
MATLAB code for Example 9.13
% Generate the random signal
ek = randn(1000,1);
vk_arima = filter([1 0.3],[1 -1.51 0.97*0.54],ek);
% Plot the series
plot(vk_arima);
% Plot the ACF & PACF
acf(vk_arima ,20,1);
pacf(vk_arima ,20,1);
% Estimate an AR(3) model for the original series
modar_vk = ar(vk_arima ,3,’ls’);
err_ar = pe(modar_vk ,vk_arima);
acf(err_ar ,20,1);
% ACF of
residuals
% Difference the series, plot its ACF and PACF
vkd = diff(vk_arima);
plot(vkd);
acf(vkd,20,1);
pacf(vkd,20,1);
% Estimate an ARMA(1,1) model for the differenced series
modarma_vkd = armax(vkd,[1 1]); present(modarma_vkd)
err_arma = pe(modarma_vkd ,vkd);
acf(err_arma , 20,1);
% Estimate an AR(2) model for the differenced series
modar_vkd = ar(vkd,2); present(modar_vkd)
err_ar2 = pe(modar_vkd ,vkd);
acf(err_ar2 ,20,1);
The time-series models developed in this chapter form the basis for noise modeling in linear
system identiﬁcation. In fact, most models in identiﬁcation emerge as extensions of these structures
to the case of including eXogenous inputs, thus acquiring the names ARX, ARMAX and ARIMAX
models. These structures are presented in Chapter 17.
We close this chapter with a remark on the examples provided in this chapter, speciﬁcally those
concerned with estimation of models. These examples were primarily meant to illustrate concepts in

234
Principles of System Identiﬁcation: Theory and Practice
the context. The technical details of estimation algorithms and a systematic procedure for estimating
these models appear in subsequent chapters.
9.8
SUMMARY
This chapter presented the foundational concepts of time-series modeling. In particular, three
classes of models for linear stationary processes were discussed, namely, the moving average, auto-
regressive, and the ARMA models. A strong parallel exists between the theory of linear, stable
deterministic processes and the linear stationary processes. Under the conditions of the spectral fac-
torization result, most linear stationary processes acquire LTI representations with white-noise as
the driving input.
On the modeling front, theoretically ACF and PACF serve as suitable tools for determining the
order of the MA and AR models, respectively. Yule-Walker equations oﬀered new interpretation of
the PACF coeﬃcients. The recursive algorithm due to Durbin and Levinson facilitates easy compu-
tation of PACF as well as AR model coeﬃcients. An important highlight of this chapter is that AR,
MA and ARMA models enjoy an equivalence. Therefore, the user has to exercise judgement and
use modeling guidelines to select the appropriate model for a given series.
ARIMA models, which are ARMA models on diﬀerenced series, are eﬀective descriptions of
a broad class of non-stationary processes. Diﬀerencing a series is a powerful way of removing
integrating type eﬀects and trends, but is also plagued with some risks. Therefore, it is important to
exercise caution in adopting this approach.
REVIEW QUESTIONS
R9.1. Describe a moving average representation and its underlying philosophy.
R9.2. Write the general auto-regressive model and conceptually explain the representation.
R9.3. What is a linear random stationary process?
R9.4. Identify the parallels between linear stationary processes and LTI deterministic processes.
R9.5. How is theoretical ACF useful in modeling random processes?
R9.6. Give the deﬁnition and uses of the ACVF generating function.
R9.7. Why is the ACF not suitable for determining the order of an AR process?
R9.8. Describe the connections between PACF at lag l and the last coeﬃcient of an AR(l) model for
a stationary process.
R9.9. What are Yule-Walker equations?
R9.10. Explain how Y-W equations are useful in estimating parameters of an auto-regressive model.
R9.11. Describe the ARIMA representation.
R9.12. What are the modeling risks of a diﬀerencing operation on a given series?
EXERCISES
E9.1. Prove the fundamental relationship (8.23) between the CCVF and ACVF of the input for a linear
stationary process.
E9.2. Write a MATLAB code to reproduce the results of Example 9.12.

Models for Linear Stationary Processes
235
E9.3. Consider the process
x[k + 1] =
"−a
0
0
−b
#
x[k] + v[k]
y[k] =
f
1
1
g
x[k]
where v[k] is zero-mean white-noise process with covariance matrix Rv =
"σ2
1
0
0
σ2
2
#
.
Show that y[k] can be represented as
y[k] = λ
q + c
(q + a)(q + b) e[k]
where e[k] is a zero-mean, unit variance white-noise sequence. Provide expressions for c and λ.
E9.4. Show that the last coeﬃcient of an AR(p) model for a stationary process v[k] is indeed the
PACF of v[k] at lag l = p.
E9.5. The AR(1) process is given by x[k] = φ1x[k −1] + e[k] where e[k] ∼N (0,σ2e) and |φ1| < 1. For
this process,
a. Show that the process is not stationary for arbitrary initial conditions. (Hint: Write the
generic solution as a sum of two terms, particular and complementary solution).
b. Further show that corr(x[k], x[k −l]) = φl
1
" var(x[k −l])
var(x[k])
#1/2
c. Show that the solution to x[k] at large times is given by
x[k] =
∞
X
r=0
(φ1)r e[k −r]
d. Consequently, argue that the process is only asymptotically (at large times) stationary for
arbitrary initial conditions.
e. How should the initial condition, i.e., the value of x[0] be chosen so that the process is also
stationary and not merely asymptotically stationary?
E9.6. The MA(2) process is represented by H(q−1) = 1 + c1q−1 + c2q−2. Use the ACVF generating
function to arrive at the theoretical expressions for the ACVF of the MA(2) process.
E9.7. For the MA(2) process above, ﬁnd the constraints (regions) on c1 and c2 so as to produce
admissible ACF.
E9.8. Write the general expression for the ACF of an AR(2) process H(q−1) =
1
1 −1.3q−1 + 0.4q−2 .
Compare your answer with estimates obtained using the supplied routine acf.m.
E9.9. A process is known to be AR(1): (x[k] −µx) = φ1(x[k −1] −µx) + e[k], where e[k] is the usual
uncorrelated N (0,σ2e)
a. Derive the conditional mean ˜µ = E(x[k]|x[k −1]) and conditional variance E((x[k] −˜µ)2).
b. What is the auto-covariance function of the conditioned series {x[k]|x[k −1]}? Give a suitable
interpretation to your answer.
E9.10. Consider two discrete-time random processes given by
(i) v1[k] = 1.2v1[k −1] −0.27v1[k −2] + e[k] and (ii) v2[k] = e[k] + 0.8e[k −1] + 0.15e[k −2] where
e[k] ∼GWN (0,σ2e = 1). Answer the following:
a. Write the transfer functions H1(q−1) and H2(q−1), respectively. Comment on whether they are
(i) stationary and (ii) invertible.
b. Calculate the theoretical ACF of each of these processes at lags l = 0,1,2,3,4. Sketch the same.
c. Compute the cross-covariance function σv1v2[l] at lags l = −2,−1,0,1,2.
d. Generate N = 2000 samples of v1[k] and v2[k]. Verify answers to parts E9.10.b and E9.10.c.

236
Principles of System Identiﬁcation: Theory and Practice
E9.11. A random process v[k] = H(q−1)e[k] has the transfer function operator H(q−1) = 1 + c1q−1
1 + d2q−2 ,
where e[k] is the usual zero-mean GWN.
a. Given ρ[2] = 0.6, which of the parameters (including σ2e ) can be estimated? Give their esti-
mates.
b. Additionally, if it is given that the PACF coeﬃcient at lag 2 is φ22 = 0.425, complete the
estimation exercise as much as possible.
c. Suppose SamayaKumara ﬁts an AR model for the above process, what order do you expect
him to ﬁt into? In practice, will it depend on the number of samples available?
Listing 9.4
MATLAB routine for computing ACF
function acfval = acf(x,L,plotopt);
% COMPUTES THE ONE-SIDED ACF AND PLOTS THE ACF (OPTIONAL)
%
% INPUTS:
%
x: Sequence whose ACF needs to be calculated
%
L: Number of lags upto which ACF needs to be calculated
%
plotopt: Option = 1 (YES, Default), 0 (NO Plot)
%
Error limits for a white-noise hypothesis are also
%
plotted
%
% OUTPUTS:
%
acfval: (L+1) Values of ACF (first value at lag zero is unity);
%
% Usage:
acfval = acf(x,lags,plotopt);
%
if (nargin == 2)
plotopt = 1;
end
x = x(:);
% Compute the ACF
[c,lags] = xcov(x,L,’coeff’);
% Assign the values of ACF
acfval = c(L+1:end);
% Plot the ACF depending on the option
if (plotopt == 1),
figure
stem((0:L),acfval,’linewidth’,1);
hold on
plot((0:L),acfval,’o’,’markerfacecolor’,’red’);
% Plot the error limits for a white-noise assumption
errlim = 2.58/sqrt(length(x));
plot((0:L),ones(L+1,1)*errlim ,’r--’);
plot((0:L),-ones(L+1,1)*errlim ,’g--’);
box off
%title(’Auto-correlation function ’,’fontsize ’,14,’fontweight ’,’bold ’);
ylabel(’ACF’,’fontsize’,12,’fontweight’,’bold’);
xlabel(’Lags’,’fontsize’,12,’fontweight’,’bold’);
set(gca,’Fontsize’,12,’Fontweight’,’bold’);
set(gcf,’Color’,[1 1 1]);
end
Listing 9.5
MATLAB routine for computing PACF

Models for Linear Stationary Processes
237
function pacfval = pacf(x,L,plotopt);
% COMPUTES THE PACF AND PLOTS THE PACF (OPTIONAL)
%
% INPUTS:
%
x: Sequence whose PACF needs to be calculated
%
L: Number of lags upto which PACF needs to be calculated
%
plotopt: Option = 1 (YES, Default), 0 (NO Plot)
%
Error limits for a WN hypothesis are also plotted
% OUTPUTS:
%
pacfval: (L+1) Values of PACF (value at lag zero set to unity);
%
% Usage:
pacfval = pacf(x,lags,plotopt);
% Set the default options
switch nargin
case 2
plotopt = 1;
case 1
L = 20;
plotopt = 1;
end
x = x(:);
% Compute the acf values upto L
acfval = acf(x,L,0);
acfval = acfval(2:end);
% Initialize the Phi matrix and set the values at lag l=1
phix = acfval(1);
tempphi = phix(1);
% Compute PACF recursively using Durbin -Levinson ’s equations
for k = 2:L,
tempvar1 = sum(tempphi(k-1,1:k-1).*acfval(k-1:-1:1)’);
tempvar2 = sum(tempphi(k-1,1:k-1).*acfval(1:k-1)’);
tempphi(k,k) =
(acfval(k) - tempvar1)/(1 - tempvar2);
for j = 1:k-1,
tempphi(k,j) = tempphi(k-1,j) - tempphi(k,k)*tempphi(k-1,k-j);
end
end
pacfval = [1 ; diag(tempphi)];
% Plot the PACF depending on the option
if (plotopt == 1),
figure
stem((0:L),pacfval ,’linewidth’,1);
hold on
plot((0:L),pacfval ,’o’,’markerfacecolor’,’red’);
% Plot the error limits for a white-noise assumption
errlim = 2/sqrt(length(x));
plot((0:L),ones(L+1,1)*errlim ,’r--’);
plot((0:L),-ones(L+1,1)*errlim ,’g--’);
box off
%title(’Partial auto-correlation function ’,’fontsize ’,14,’fontweight ’,’...
bold’);
ylabel(’PACF’,’fontsize’,12,’fontweight’,’bold’);
xlabel(’Lags’,’fontsize’,12,’fontweight’,’bold’);
set(gca,’Fontsize’,12,’Fontweight’,’bold’);
set(gcf,’Color’,[1 1 1]);
end

10
Fourier Transforms and Spectral
Analysis of Deterministic Signals
The chapter is devoted to the frequency-domain analysis of signals with the main objective
of introducing the concept of power spectrum. The focus topics of this chapter are Fourier
representations, power spectral density and the correlation theorem, all of these set up in the
context of deterministic signals. We shall also brieﬂy introduce the notions of cross power
spectrum and coherence. The concepts learnt in this chapter lay the foundations for Chapter
11 concerning stochastic processes.
10.1
MOTIVATION
In Chapter 8 we learnt how to characterize random signals (processes) in terms of their time-domain
statistical properties, speciﬁcally, using correlation functions. Subsequently, Chapter 9 oﬀered time-
domain parametric descriptions of linear stationary and integrating type processes.
A radically diﬀerent route of describing and analyzing these signals takes us through the fre-
quency domain using the Fourier transform, popularly known as spectral representations. Compre-
hending the associated theory becomes considerably easier once we understand the machinery in the
framework of deterministic signals. With this idea, we devote this chapter to the Fourier transforms
and spectral analysis of deterministic processes. Spectral representations of random signals are then
taken up in Chapter 11.
Transforms are essentially change of basis of representation. The Fourier transform is based on
the use of sinusoidal basis functions, which are pure tone waveforms. A natural question is whether
this new representation of signals oﬀers any theoretical and/or practical beneﬁts over the regular
time-domain counterpart?
Fourier transform of signals brings with it several beneﬁts to the ﬁelds of signal processing
and identiﬁcation. Central to these applications are the concepts of spectral density function and
phase spectrum. The notion of spectral density is also vital to the milestone spectral factorization
result. For this reason, analysis in the Fourier domain is also known as spectral or frequency-domain
analysis.
We highlight the salient applications of frequency-domain analysis below.
1. Detection of oscillatory or periodic components in measurements: Determining the presence
of periodicities in a measurement is highly infeasible using a pure time-domain analysis due
to the presence of noise and multiple frequency components. This is one of the most widely
encountered problems in all spheres of engineering and science. In climatology, we are inter-
ested in knowing the periodicity of climatic phenomena; in health monitoring of control loops,
the ﬁrst step is to detect loops with oscillatory outputs (Tangirala, Shah and Thornhill, 2005);
fault detection and diagnosis of vibration machinery and several other mechanical equipments
rely on monitoring of frequency content of measurements (Randall, 2011); biomedical signals
such as EEG and ECG are primarily characterized by their frequency content (Blinowska and
Zygierewicz, 2012) and so on. Among the diﬀerent tools used in these applications, Fourier
transform occupies the most prominent and indispensable place.
238

Fourier Analysis and Spectral Analysis of Deterministic Signals
239
2. Estimation of frequency response functions: The FRF is a valuable tool in the analysis of LTI
systems as we learnt in Chapters 4 and 5. It is deﬁned as the Fourier transform of the impulse
response function, as we learnt in Section 4.2.3. Estimation of the FRF involves the use of ETF
deﬁned in Section 5.3, which is the ratio of discrete Fourier transforms of the output and input.
Methods for estimation of FRF are presented in 20. An eﬃcient method uses the cross-spectral
and the auto-spectral densities for this purpose (see §20.4). The spectral densities are also used
in estimating the frequency content of the disturbances (cf. §20.5).
3. Delay estimation using cross-spectral density: One of the main advantages of frequency-
domain analysis is that the eﬀects of dynamics and delay are decoupled in the FRF, which
are otherwise entangled in the time-domain response. Theoretically, the phase of LTI systems
at high frequencies is only a linear function of the delay. This fact is suitably exploited in es-
timation of delays. A generalized method that takes into account the phase spectrum over the
entire frequency range using a weighted least squares formulation is presented in §22.5. The re-
sulting estimator is more eﬃcient and versatile than the classical time-domain approach using
cross-correlation functions (Hamon and Hannan, 1974).
4. Input design: The theoretical conditions for suﬃcient excitation in inputs guaranteeing identiﬁa-
bility turns out to be a set of conditions on the input spectrum. The condition known as persistent
excitation requires that the input contains almost all frequencies (cf. §22.3). Consequently, most
input design problems are formulated using the power spectrum and phase properties of the input.
5. Filtering and estimation: It is a widely known fact that the natural domain of ﬁlter characteri-
zation is the frequency-domain. Chapters 4 and 5 brieﬂy highlighted this fact. In identiﬁcation,
pre-ﬁlters are designed to shape the model bias and variance (model accuracy and eﬃciency)
in the frequency domain. Pre-ﬁlters are widely used for estimating suitable models in control
relevant identiﬁcation, continuous-time identiﬁcation, etc. The variability of model parameter
estimates are signiﬁcantly aﬀected by the ratio of spectral densities of signal and noise. This is
true even for signal estimation. A signal is separable from noise if their spectral distributions do
not signiﬁcantly confound with each other. The lesser the overlap, the better the estimation (see
Example 10.1 below). In a broader sense, ﬁlters are indispensable to all applications of commu-
nication and signal processing both in theory and in practice.
6. Theoretical analysis of processes: The role of Fourier transforms in the theoretical analysis
of linear deterministic and random processes can rarely be overemphasized. The most powerful
conditions for stability of LTI deterministic processes are available in frequency domain (the
celebrated Nyquist’s stability criterion). Moreover, important results on performance limitations
and robustness of a control system are predominantly in terms of frequency-domain behavior of
the closed-loop system.
In the theory of linear random processes, the correlation structure of a stationary process is fun-
damentally characterized by its power spectral density. The white-noise signal acquires its name
from its spectral distribution as we shall learn in Chapter 11. More importantly, the conditions
under which a linear model can be developed for a stationary process are governed by the factor-
izability of its power spectral density (see Section 11.6).
In addition to the aforementioned list of applications, spectral analysis ﬁnds wide use in control
system design, closed-loop performance monitoring, non-linearity detection, estimation of auto-
covariance functions, image analysis, solutions to ODEs and so on. Fourier transform is also the
basis and inspiration for a host of other transforms and spectral analysis tools, particularly methods
for time-frequency analysis.
An emerging fact from the discussion thus far is that the primary arm of Fourier analysis is
the spectral density function, or more generally, the spectral distribution function. It measures the
contributions of the diﬀerent frequency components to the overall energy / power of the signal. In
most applications, the spectral density is the center of attention rather than the transform itself. In
the case of random processes, this is a fact because Fourier transforms of random signals do not

240
Principles of System Identiﬁcation: Theory and Practice
0
100
200
300
400
500
−6
−4
−2
0
2
4
6
Samples
Amplitude
(a) Series
0
0.1
0.2
0.3
0.4
0.5
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
Frequency (cycles/sample)
Spectral density
(b) Power spectral density
FIGURE 10.1
Series of Example 10.1 and its power spectral density.
exist. The concept of spectrum provides a uniﬁed framework for analyzing both deterministic and
stochastic signals.
Two illustrative examples are presented below to develop an intuitive feel and an appreciation
for the use of spectral density in identiﬁcation.
Example 10.1: Spectral Density, Periodicity Detection and Signal Estimation
The series of interest consists of N = 500 samples of a simulated process
v[k] = sin(0.2πk) + sin(0.5πk) + e[k]
(10.1)
where e[k] is the GWN process with variance σ2e = 2.25.
The series v[k] is shown in Figure 10.1(a). Its Fourier transform results in a complex
series V ( f ) where f is the frequency. Figure 10.1(b) shows the (normalized) spectral den-
sity, |V ( f )|2/N, also known as the periodogram. Observe that the frequency is expressed in
cycles/sample.
The periodogram shows distinct peaks at frequencies f1 = 0.1 and f2 = 0.15 cycles/sam-
ple, respectively, implying that the series predominantly contains two periodic components.
Detecting these two oscillatory components by a visual examination of the series is evidently
not a feasible task.
0
20
40
60
80
−2.5
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
2.5
Samples
Amplitude
 
 
True
Estimated
FIGURE 10.2
(SEE COLOR INSERT) Comparing the signal estimate using the inverse FT method with the
true signal in Example 10.1.
Suppose now that the objective is to extract the periodic components from the mea-
surement. A simple, but somewhat rudimentary, approach is to ﬁrst zero-out |V ( f )| at all

Fourier Analysis and Spectral Analysis of Deterministic Signals
241
Listing 10.1
MATLAB code for Example 10.1
% Generate the measurement
kvec = (0:499)’;
vk = sin(2*pi*0.1*kvec) + sin(2*pi*0.25*kvec) + randn(500,2.25);
% Compute periodogram
N = length(vk);
[Pxx,wvec] = periodogram(vk-mean(vk),[],N,1);
figure; plot(wvec,Pxx/sum(Pxx));
% Take Fourier Transform
vkf = fft(vk);
magvkf = abs(vkf(1:end/2)); phasevk = phase(vkf(1:end/2));
% Zero out the contributions (assumed to be) due to noise
magvkf2 = zeros(length(magvkf),1);
magvkf2(50:52) = magvkf(50:52);
magvkf2(125:127) = magvkf(125:127);
vkfmod = magvkf2.*exp(i*phvkf);
vkfmod2 = [vkfmod ; 0 ; flipud(conj(vkfmod(2:end)))];
% Estimate the signal
vkhat = ifft(vkfmod2);
% Plot against the true deterministic signal
xk = sin(2*pi*0.1*kvec) + sin(2*pi*0.25*kvec);
figure; plot((0:99),xk(1:100),’r-’,(0:99),vkhat(1:100),’b--’);
frequencies except at those very close to and including f1 and f2. The assumption is that the
spectrum at all other frequencies is primarily due to noise. Then, using the phase informa-
tion ∠V ( f ), we perform the inverse Fourier transform to obtain an estimate of the underlying
signal.
A snapshot of the resulting estimate with a superimposition on the true one is shown in
Figure 10.2.
It is clear from the plot that the estimated signal is very close in amplitude and phase to
the true one. The sum square error is about 3% of the original signal. Thus, it would be fair
to say that the spectral analysis has separated the signals from noise very eﬃciently.
In a related application of periodicity detection, the periodograms of four real-life measurements
are shown in Figure 10.3. Figures 10.3(a) and 10.3(b) correspond to two ﬂow loops in a reﬁnery
process (Tangirala, Shah and Thornhill, 2005) while Figures 10.3(c) and 10.3(d) correspond to
the temperature and wind speed measurements of Figure 7.4(a) and 7.4(b), respectively. The key
signatures of interest are the distinct peaks (if any) in these plots.
It is interesting to note that the ﬂow loop of Figure 10.3(a) is devoid of any periodic component.
This is a good sign for the performance of the associated controller. An ideal controller should re-
sult in an output with a ﬂat spectrum. Contrary to this expectation, the spectral density of the ﬂow
loop in Figure 10.3(b) shows a very distinct peak at F = 0.06 cycles/min., indicating poor loop per-
formance. Oscillations in controlled variables are potential causes of reduced product quality and
safety hazards. The spectral density plot of the temperature in Figure 10.3(c) shows the presence of
several low-frequency components. There is thus a large scope for improving the controller perfor-
mance. Finally, the periodogram of the wind speed series shows the presence of a distinct frequency
at F = 1 cycle/day, which is in agreement with the nature of atmospheric phenomena. The plots
once again demonstrate the eﬃciency of spectral analysis in revealing the presence (or absence) of
oscillatory components in each of these series.
In general, the success of the spectral analysis in detecting the oscillatory components and their

242
Principles of System Identiﬁcation: Theory and Practice
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
Frequency (cycles/min.)
Spectral density
(a) Flow loop 1
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
Frequency (cycles/min.)
Spectral density
(b) Flow loop 2
0
0.2
0.4
0.6
0.8
1
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
Frequency (cycles/sec)
Spectral density
(c) Temperature loop
0
1
2
3
4
5
6
7
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
Frequency (cycles/day)
Spectral density
(d) Wind speed
FIGURE 10.3
Power spectral densities of two ﬂow loop outputs, a temperature loop measurement and wind
speed.
frequencies relies on the energy/power distributions of the signals and the measurement noise in the
frequency-domain.
Not all signals possess Fourier transforms. Deterministic signals with ﬁnite energy have a Fourier
representation. On the contrary, Fourier transforms of random signals do not exist. This makes it
practically diﬃcult to apply these transforms to analyze measurements since they usually contain
both eﬀects. Fortunately, spectral densities of both random (stationary) and deterministic signals
theoretically exist and can be constructed by transforming the signal properties, obviating the need
to transform the signals themselves. This key result is celebrated in the form of Wiener-Khinchin
theorem (see §11.2). The theorem also establishes connections between the statistical properties of
random signals in time and frequency domains.
The developments in this chapter rest on a formal understanding of concepts such as energy,
power, periodic signals and energy/power densities. A review of these concepts is provided in the
following section.
10.2
DEFINITIONS
10.2.1
PERIODIC AND APERIODIC SIGNALS
Deﬁnition 10.1. A continuous-time signal x(t) is said to be periodic if and only if there exists a
Tp , 0,Tp ∈R such that
x(t + Tp) = x(t)
(10.2)
The smallest value of Tp for which the signal is periodic is said to be the fundamental period of
x(t). The fundamental frequency of the signal is F0 = 1/Tp.

Fourier Analysis and Spectral Analysis of Deterministic Signals
243
Deﬁnition 10.2. A discrete-time signal x[k] is said to be periodic if and only if there exists a
Np , 0, Np ∈Z+ such that
x[k + Np] = x[k]
(10.3)
Observe that the period of a discrete-time signal is an integer and is expressed in samples (taken
to complete one or an integer number of cycles). The smallest value of Np that satisﬁes (10.3) is
said to be the fundamental period of x[k].
The most important distinction between a continuous-time periodic and discrete-time periodic
signal is that discrete-time signals with irrational frequencies are not periodic.
Theorem 10.1
A discrete-time signal x[k] = Asin(2π f k) is periodic if and only if the frequency f can be ex-
pressed as a rational number
f = N
M
(10.4)
where N and M are co-prime. Then M is the period of the signal.
Proof. The proof is evident from the deﬁnition of f . If f is irrational, the signal takes an irrational
number of samples to complete integer number of cycles. The result then follows from deﬁnition
10.2.
□
Example 10.2: Periodicity
The period of a discrete-time signal x[k] = 2 sin(0.6πk) is found by ﬁrst noting that it has a
frequency f = 0.3 cycles/sample.
Expressing f in the co-prime rational form, we obtain f = 3/10. Thus the period of x[k]
is Np = 10. Observe that the signal would have completed three cycles in one fundamental
period, unlike in the case of continuous-time signals.
10.2.2
ENERGY AND POWER SIGNALS
The deﬁnitions are based on the concepts of energy and power in signal analysis.
Deﬁnition 10.3. The energy of a continuous-time signal x(t) and a discrete-time signal x[k] are
respectively deﬁned as (Cohen, 1994),
Exx =
Z ∞
−∞
|x(t)|2 dt ;
Exx =
∞
X
−∞
|x[k]|2
(10.5)
A signal with ﬁnite energy, i.e., 0 < Exx < ∞is said to be an energy signal1.
An exponentially decaying signal and a short-lived disturbance are examples of energy signal. In
fact, any signal of ﬁnite amplitude and duration is an energy signal.
The energy of a signal can be loosely interpreted to be the energy “expended” by the system to
generate the signal over the duration t ∈(−∞,∞).
1The squared modulus instead of a simple square is introduced to accommodate complex-valued signals.

244
Principles of System Identiﬁcation: Theory and Practice
Random signals are conventionally assumed to exist throughout in time and therefore do not
qualify as energy signals. On the other hand, ﬁnite-length realizations have ﬁnite energy. Another
classical example of a “non-energy signal” is a periodic signal.
Deﬁnition 10.4. The average power of a continuous-time signal x(t) and a discrete-time signal
x[k] are respectively deﬁned as (Cohen, 1994)
Pxx = lim
T→∞
1
2T
Z T
−T
|x(t)|2 dt ;
Pxx = lim
N→∞
1
2N
k=N
X
k=−N
|x[k]|2
(10.6)
A signal with ﬁnite power, i.e., 0 < Pxx < ∞is said to be a power signal.
All periodic signals are power signals. In general, all inﬁnitely long, ﬁnite-amplitude signals are
power signals. Therefore, a stationary random signal is a power signal.
On the contrary, all ﬁnite-duration (and amplitude) signals have Pxx = 0. In general, any energy
signal is not a power signal and vice versa. However, it is possible that a signal is neither an energy
nor a power signal.
Similar to the case of energy, the power of a signal can be interpreted as the average rate at which
the system “expends” energy to generate the signal over the duration t ∈[−T,T], T →∞.
Energy and power densities
Equation (10.5) gives rise to the idea of an energy density in time. Drawing analogies with proba-
bility density function and densities in mechanics, the quantity
Sxx(t) = |x(t)|2
(10.7)
is termed as the energy density per unit time. The energy density per time can also be thought of as
an “instantaneous” power.
Similarly, the power density in time can be deﬁned as
γxx(t) = |x(t)|2
T
(10.8)
For the discrete-time case, the energy and power density in time are not deﬁned since the domain
is not a continuum (much alike to the case of discrete-valued random variables). The distribution
functions exist nevertheless. On the other hand, we can think of energy and power densities of these
signals in a transform domain, provided that the new domain is continuous and that the transform
is energy / power preserving. This concept forms the basis for deﬁning spectral densities of c.t. and
d.t. signals in the Fourier (frequency) domain as we shall shortly learn.
The energy densities in frequency domain share a strong connection with the time-domain char-
acteristics (properties) of the signal, speciﬁcally the covariance functions. This is one of the most
founding results in the spectral analysis of signals (deterministic version of the well-known Wiener-
Khinchin theorem, see Theorem 10.3).
10.2.3
CROSS-COVARIANCE FUNCTIONS FOR DETERMINISTIC SIGNALS
Section 8.4 introduced the cross-correlation function for random signals. The measure detects linear
relationship between two random signals that are separated by l instants (lags) apart in time. A
similar measure can be constructed for deterministic signals as well. Recall that we have already
deﬁned mean and variance for deterministic signals in Section 7.5.3.

Fourier Analysis and Spectral Analysis of Deterministic Signals
245
CCVF of Periodic signals
Deﬁnition 10.5. The cross-covariance function between two zero-mean, periodic deterministic sig-
nals xp[k] and yp[k] with a (least) common period Np is deﬁned as
σxp yp[l] = 1
Np
Np−1
X
k=0
xp[k]yp[k −l]
(10.9)
A normalized version of (10.9) results in the cross-correlation function for periodic signals
ρxp yp[l] =
σxp yp[l]
q
σxp xp[0]σyp yp[0]
(10.10)
The deﬁnitions in (10.9) and (10.10) specialize to the auto-covariance and auto-correlation functions
of the periodic signal, respectively, when xp[k] = yp[k].
It is easy to observe that the average power of the periodic signal is its ACVF at lag l = 0,
Pxp xp = σxp xp[0]
(10.11)
ACVF of a periodic signal is also periodic
A useful property of the ACVF of a periodic signal
σxp xp[l] = 1
Np
Np−1
X
k=0
xp[k]xp[k −l]
(10.12)
is that it is periodic with the same fundamental period as the signal, i.e.,
σxp xp[l + Np] = σxp xp[l]
Example 10.3: ACVF of a Cosine
Consider the periodic signal xp[k] = Acos(2π f k) given that f = m/N where gcf(m, Np) = 1,
i.e., m and Np are coprime.
The auto-covariance function of the signal is given by
σxx[l] =
1
Np
Np−1
X
k=0
cos(2π f k) cos(2π f (k −l))
=
1
2Np
Np−1
X
k=0
(cos(2π f (2k −l)) + cos(2π f l))
= 1
2 cos(2π f l)
where the ﬁrst term in the summation of the penultimate equation vanishes because the
average of a (phase-shifted) cosine in a single cycle is zero.
Thus, the ACVF of the signal is also periodic with the same period Np.
When the signal contains more than one periodic component, the ACF also inherits those char-
acteristics. The periodicity feature of the ACVF is widely used to detect periodicities in several
engineering processes and natural phenomena.

246
Principles of System Identiﬁcation: Theory and Practice
CCVF of aperiodic signals
Deﬁnition 10.6. The cross-covariance function between two aperiodic deterministic, energy signals
x[k] and y[k] is deﬁned as
σxy[l] =
∞
X
k=−∞
x[k]y[k −l]
(10.13)
As before, normalization of CCVF results in the cross-correlation function2
ρxy[l] =
σxy[l]
pσxx[0]σyy[0]
(10.14)
The ﬁnite energy requirement is akin to the ﬁnite variance requirement of a wide-sense stationary
signal.
By setting x[k] = y[k] in (10.13) and (10.14) we obtain the auto-covariance and auto-correlation
functions, respectively. It is easy to observe that the energy of the deterministic signal is the auto-
covariance of the signal at lag l = 0.
Exx = σxx[0]
(10.15)
Example 10.4: ACVF of an Exponentially Decaying Signal
The ACVF of an exponential signal
x[k] =

eαk,
k ≥0 ,α < 0
0,
k < 0
is given by
σxx[l] =
∞
X
k=−∞
x[k]x[k −l] =
∞
X
k=l
eαkeα(k−l) = eαl
∞
X
k′=0
e2αk′ =
eαl
1 −e2α
Thus, the ACVF of the exponentially decaying signal has the same decay rate as that of the
signal.
Figure 10.4 shows the signals of Examples 10.3 and 10.4 and their estimated ACVFs for Np = 20
and α = −0.05, respectively. From Figures 10.4(a) and 10.4(b), it is easy to verify that the period of
ACVF is the same as that of the signal, Np = 20 samples. For the case of exponentially decaying
signal, Figure 10.4(d) reads the value of ACVF at lag l = 0 as 10.5083, which agrees with our
theoretical calculation σxx[0] = 1/(1 −e−1) = 10.5083.
Listing 10.2
MATLAB code for Figure 10.4
% Generate the sine wave
k1 = (0:200)’;
xk1 = cos(2*pi*0.05*k1);
% Plot the signal
figure; stem(k1(1:41),xk1(1:41))
% Compute the ACVF and plot it
[xk_acf ,lags] = xcorr(xk1,40,’biased’);
figure; stem(lags(L1+1:end),xk_acf(L1+1:end))
2An alternative usage is to term (10.13) (or (10.9)) as cross-correlation and (10.14) (or (10.10)) as normalized correlation.

Fourier Analysis and Spectral Analysis of Deterministic Signals
247
0
5
10
15
20
25
30
35
40
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Samples
Amplitude
(a) Snapshot of the cosine
0
5
10
15
20
25
30
35
40
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
Lags
ACVF
(b) ACVF of the cosine
0
20
40
60
80
100
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Samples
Amplitude
(c) Exponentially decaying signal
0
20
40
60
80
100
0
2
4
6
8
10
12
Lags
ACVF
(d) ACVF of exponential signal
FIGURE 10.4
Signals and their covariance functions with reference to Examples 10.3 and 10.4.
% Generate the exponentially decaying signal
k2 = (0:200)’; alpha = -0.05;
xk2 = exp(alpha*k2);
% Plot the signal
figure; stem(k2(1:100),xk2(1:100))
% Compute the ACVF and plot it
[xk_acf ,lags] = xcorr(xk2,40);
figure; stem(lags(L2+1:end),xk_acf(L2+1:end))
An interesting observation regarding the ACVF of a deterministic signal emerges from Examples
10.3 and 10.4, which is that it fully inherits the characteristics of the original signal. This is useful in
recovering signal characteristics from their measurements, which are usually corrupted with noise.
When the measurement noise is white or has a rapidly decaying correlation, analysis in the ACF
domain oﬀers a signiﬁcant advantage over a pure time-domain analysis since the eﬀect of noise on
the ACF is conﬁned, in general, to only the ﬁrst few lags. Contrast this with the eﬀect of noise on the
signal, which is felt at each instant in the time-domain. Thus, it is easier to detect the periodic com-
ponent using the ACF. Several periodicity detection applications exploit this feature for detecting
oscillatory components embedded in noise (see for example, Thornhill, Huang and Zhang (2003)).
Remarks:
Observe two distinctions between the deﬁnitions of the correlation functions for random (in Chap-
ter 8) and deterministic signals here:
a. Deﬁnition (8.17) is given by the average of products across the ensemble space, whereas (10.13) is a simple
summation (not an average) over the time-sample space.
b. The expression in (10.13) and (10.9) do not involve subtraction of means of the respective signals. This
distinction vanishes when we work with zero-mean (mean-centered) signals.
Note: Certain texts on statistical signal processing deﬁne (8.17), the correlation function for random sig-
nals, in terms of the absolute variables (rather than deviations from mean) to bring about a uniformity in the
deﬁnitions for deterministic and stochastic signals.

248
Principles of System Identiﬁcation: Theory and Practice
The interpretations of these properties for both classes of signals are however identical. In Chapter 16 we shall
further observe that the expressions for estimates of these functions closely resemble each other.
Chapter 17 (speciﬁcally §17.3) presents a uniﬁed deﬁnition of ACF for mixed signals based on
time averages assuming ergodicity and quasi-stationarity. The time-average deﬁnition is also able to
handle bounded-amplitude deterministic signals that exist forever, but are not necessarily periodic.
10.3
FOURIER REPRESENTATIONS OF DETERMINISTIC PROCESSES
In the Fourier transform literature, two phrases, namely, Fourier series and Fourier transform, are
used to distinguish between the case of periodic and aperiodic signals. A further classiﬁcation is
based on whether the original domain (usually time domain) of signal is continuous or discrete.
Regardless of the nature and domain of signal, the fundamental idea is to imagine the signal to be
made up of a weighted combination of sinusoids with diﬀerent frequencies. The periodic nature or
lack thereof, and the continuous or discrete domain only governs the family of sinusoids considered
for analysis. The weights or the coeﬃcients of combination also carry similar interpretations across
the board. Table 10.1 summarizes the four diﬀerent ﬂavors of Fourier representations of determin-
istic signals. In the following sections, we dwell on the theoretical and practical aspects of each of
these transforms, while converging to the well-known discrete Fourier transform (DFT).
Remarks:
1. Every signal transform is described by a synthesis equation, which deﬁnes how the signal is imagined to
be constructed from a family of building blocks (atoms), and an analysis equation, which oﬀers means
of determining “which” members of the family have actually participated in the signal synthesis. When
the building blocks are ﬁxed a priori and independent of the signal, the transform is said to be built on
ﬁxed basis; on the other hand, when these building blocks are derived from data, the transform is said to
work with adaptive basis. Fourier transform belongs to the former category. On the other hand, principal
component analysis (see §26.3), which also performs an orthogonal decomposition, falls into the latter
category. A main advantage of the ﬁxed basis is that since the properties of the building blocks are known a
priori, it is easy to infer the signal’s properties. A demerit is, of course, that the analysis may not physically
tally with the signal’s evolving mechanism because the actual building blocks used in the synthesis may be
quite diﬀerent from the postulated ones.
2. In data analysis, it is natural to begin with the analysis equation since one is interested in knowing the signal
properties from the given signal. However, pedagogically it is instructive to present the synthesis equation
ﬁrst since it explains the fundamental idea underneath the transform and is also responsible for the birth of
the analysis equation.
3. To give an analogy of Fourier transform in the musical world, a music conductor ﬁrst sets the tune to a
given lyrical composition and then determines which of the instruments in the orchestra will participate
in realizing that tune. Not all instruments in the composer’s repertoire are needed to play a musical piece.
Each instrument is characterized by a certain frequency, amplitude (sound level) and phase (when to be-
gin); similarly, Fourier transform ﬁrst imagines the signal to be made of sinusoids of diﬀerent frequencies
(synthesis) and subsequently analyzes which of these diﬀerent frequencies actually make up the signal and
also determines their amplitudes and phases. Not all sinusoids necessarily contribute to the signal under
analysis; usually it is a small subset.
4. In signal analysis, it is useful to interpret the transformation from a correlation viewpoint. Every transform
of a signal can be viewed as a correlation of that signal with the transforming basis function. The coeﬃcient
of transform is the “amount” of correlation or similarity of that signal with the basis function. Thus, the
Fourier transform measures the similarity of the signal with sine waves of diﬀerent frequencies.
5. Finally, the primary goal of any signal transform to postulate a model for signal representation in a new
domain such that the analysis in this new domain highlights makes it very convenient to analyze signal
features, ﬁlter, etc. as highlighted in §16.5.7. However, on an equal footing, or perhaps more, often one is
equally interested in the power or energy decomposition of the signal in the frequency domain. In Fourier
domain, these tools are facilitated by Parseval and Plancherel’s results in functional analysis. They assume

Fourier Analysis and Spectral Analysis of Deterministic Signals
249
more prominence than signal decomposition especially because, as we shall learn in Chapter 11, random
stationary signals do not enjoy Fourier representations unlike deterministic signals, but certainly possess
spectral densities (under some mild conditions).
For this reason, Table 10.1 presents both signal and energy / power decompositions for each class of deter-
ministic signals in the second and third columns, respectively. While the second column is applicable only
to deterministic signals, the third column, especially the power spectral decomposition carries forward with
some mild alterations to the world of random signals.
We begin our journey with the Fourier series, which was historically the ﬁrst one to arrive on the
sets of frequency domain representations.
10.3.1
FOURIER SERIES
A continuous-time periodic signal (function) with fundamental period Tp = 1/F0 is expressed as a
(linear) weighted combination of (positive and negative) harmonics.
x(t) =
∞
X
n=−∞
cnej2πnF0t
(Synthesis equation)
(10.16)
Equation (10.16) is the Fourier series expansion of x(t) in terms of complex sinusoids that have the
same period (not fundamental).
The coeﬃcient cn in (10.16) is calculated as
cn = 1
Tp
Z
Tp
x(t)e−j2πnF0t dt
(Analysis equation)
(10.17)
The result is predominantly useful in theoretical analysis of signals and systems.
Remarks:
i. The coeﬃcients cn are in general complex-valued. For real-valued signals, cn = −c⋆n (complex conjugates).
ii. Inclusion of negative frequencies in (10.16) is purely for mathematical reasons. By virtue of the property of
cn above, in reality the series is a real-valued weighted summation of sines and cosines.
iii. The coeﬃcients cn exist if and only if the signal x(t) is absolutely convergent in [0,Tp], i.e., x(t) ∈
L1(0,Tp). On the other hand, the series converges to x(t) if it is continuous and of bounded variation
in [0,Tp]. For discontinuous signals with ﬁnite extrema and ﬁnite number of discontinuities, the series
converges to the average value of the left and right limits (Priestley, 1981). This is termed as the Gibbs phe-
nomenon (Bloomﬁeld, 2000). The suﬃciency conditions for any function f (t) to possess a Fourier series
expansion was established by Dirichlet and are popularly known as Dirichlet conditions (Priestley, 1981).
iv. A weaker requirement is that x(t) has a ﬁnite 2-norm in the interval (0,Tp). Then, the summation
xM (t) =
M
X
n=−M
cne−j2πnF0t
(10.18)
converges to x(t) in the mean square sense, i.e., the integral
R
(x(t) −xM (t))2 dt vanishes in the limit as
M −→∞. The requirements for other forms of convergence are available in classical texts (see Priestley
(1981) for instance).
v. The squared magnitude of cn gives the power of the nth harmonic in the signal (power spectral decompo-
sition, see Section 10.3.2).
vi. The phase angle of coeﬃcients is a measure of how much each sinusoid has to be shifted in time to synthe-
size the signal. This is useful in time-delay or lag estimation.
vii. Finally, the Fourier series / transform represents any signal as addition and subtraction of cosines / sines.
This representation is largely mathematical and may not have any resemblance to the actual physics of the
generating process.

250
Principles of System Identiﬁcation: Theory and Practice
10.3.2
POWER SPECTRUM
The series expansion is useful in many ﬁelds of applied and theoretical mathematics. An equally
important and useful result is that of the power spectral decomposition of the signal (Parseval and
Plancherel result, see Table 10.1).
The average power of the signal can be decomposed in the frequency domain as
Pxx = 1
Tp
Z Tp
0
|x(t)|2 dt =
∞
X
n=−∞
|cn|2
(Power decomposition)
(10.19)
The power spectral decomposition result can be interpreted as follows:
1. Pn = |cn|2 is the contribution by the nth harmonic and hence {|cn|2} is known as power spectrum,
denoted by P(Fn).
2. P(Fn) is deﬁned only at discrete frequencies, thereby giving it the name line spectrum.
3. The power spectrum is invariant (blind) to phase shifts. Two signals having diﬀerent phases but
same amplitudes will have identical power spectra.
4. For a real-valued signal, c∗
n = c−n. Consequently, the spectrum is a symmetric quantity.
Example 10.5: Square Wave
The Fourier series representation of the periodic square wave
x(t) =

1,
0 ≤t ≤1/2
−1,
1/2 < t ≤1
(10.20)
with period Tp = 1 is given by the coeﬃcients
cn = 1
Tp
Z 1
0
x(t)e−j2πnt dt
=
Z 1/2
0
e−j2πnt dt −
Z 1
1/2
e−j2πnt dt
= j sin
 nπ
2

sin c
 nπ
2

e−jnπ
−20
−15
−10
−5
0
5
10
15
20
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
Harmonic index
Power
Line spectral decomposition of a square wave
(a) Power spectral plot
0
0.2
0.4
0.6
0.8
−1
−0.5
0
0.5
1
Time
Amplitude
Fourier decomposition of a square wave
 
 
Original
Fundamental
3rd harmonic
5th harmonic
(b) Fourier decomposition
FIGURE 10.5
(SEE COLOR INSERT) Power spectral and Fourier decomposition of the square wave in
Example 10.5.

Fourier Analysis and Spectral Analysis of Deterministic Signals
251
Figure 10.5(a) shows the power spectral decomposition of the square wave. The line spec-
trum is plotted as a function of the harmonic index. By convention, the ﬁrst harmonic is the
fundamental frequency. Observe that it is symmetric and that only odd harmonics participate
in the synthesis of the signal.
The signal decomposition (over one period) is shown in Figure 10.5(b). The decomposition
is purely mathematical.
It is left to the reader as an exercise (see E10.3) to illustrate the Gibbs phenomenon for the example
above. A recovery of the original signal (square wave) by successively including harmonics at higher
frequencies produces the form of the square wave well, but fails to recover the sharp corners.
Listing 10.3
MATLAB code for Example 10.5
% Generate the coefficients
cn = inline(’j*sin(pi*n/2)*sinc(n/2)*exp(-j*pi*n)’,’n’);
nvec = (-20:20)’;
% Compute the coefficients
cnvec = [];
for n = -20:20,
cnvec = [cnvec ; cn(n)];
end
% Plot the line spectrum
figure; bar(nvec,abs(cnvec).^2,0.15)
% Plot the sinusoidal components
t = (0:.005:1-0.005)’; xt = square(2*pi*t);
c1 = -2*imag(cnvec(22))*sin(2*pi*t);
c3 = -2*imag(cnvec(24))*sin(2*pi*3*t);
c5 = -2*imag(cnvec(26))*sin(2*pi*5*t);
c7 = -2*imag(cnvec(28))*sin(2*pi*7*t);
figure; plot(t,xt); hold on
plot(t,c1,’r--’); plot(t,c3,’g-.’); plot(t,c5,’k.’);
We turn our attention to a relatively more practical situation is the case of aperiodic signals, in
which case the Fourier series takes the shape of Fourier transform.
10.3.3
FOURIER TRANSFORM
Aperiodic signals can be treated as a limiting case of periodic signal with period Tp →∞. Then,
the spacing of harmonics on the frequency axis △F = 1/Tp →0. The family of basis functions then
belongs to the continuous-domain.
The synthesis equation in (10.16) takes the integral form,
x(t) =
Z ∞
∞
X(F)ej2πFt dF
(Fourier Synthesis)
(10.21)
Its dual, the analysis equation is now evaluated over the entire time axis,
X(F) ≜F{x(t)} =
Z ∞
∞
x(t)e−j2πFt dt
(Fourier Transform)
(10.22)
The quantity X(F) has a similar interpretation as that of cn in (10.17). It is a complex-valued
continuous function of the frequency F.

252
Principles of System Identiﬁcation: Theory and Practice
Conditions for existence of Fourier transform
The Fourier transform is guaranteed to exist if the signal x(t) is absolutely integrable,
Z ∞
−∞
|x(t)| dt < ∞
For the signal to be recovered uniquely (or the average value at points of discontinuity), x(t) should
have bounded variation at all points.
A weaker and a mathematically useful requirement is that the 2-norm of the signal be ﬁnite, i.e.,
x(t) ∈L2. Almost all ﬁnite energy signals have a Fourier transform.
The theory of generalized functions relaxes some of the above restrictions and also allows us to
compute Fourier transforms of idealized functions such as impulse and sine wave (Antoniou, 2006;
Lighthill, 1958).
Energy spectral density
A Parseval relation similar to (10.19) exists.
Exx =
Z ∞
−∞
|x(t)|2 dt =
Z ∞
−∞
|X(F)|2 dF
(Energy decomposition)
(10.23)
Thus, energy is preserved by the transform3.
Equation (10.23) facilitates decomposition of the energy in the frequency domain. The quantity
|X(F)|2 is a continuous function of the frequency and can be given the interpretation of an energy
spectral density by virtue of (10.23). In other words, |X(F)|2dF measures the energy contributions
of the frequency components within the band (F,F + dF) to the total energy of the signal.
Example 10.6: Finite Duration Rectangular Pulse
The Fourier transform of the ﬁnite duration rectangular pulse signal
x(t) = AΠ
 t
T

=

A
|t| < T/2
0
otherwise
is given by
X(F) =
Z T/2
−T/2
Ae−j2πFt dt = A*
,
e−j2πFt
−j2πF

T/2
−T/2
+
-
= AT sin(πFT)
πFT
= ATsinc(πFT)
Thus, the ﬁnite-duration pulse has an inﬁnitely long Fourier transform.
The observation in the foregoing example can be generalized to all ﬁnite-length signals.
All ﬁnite-duration signals have Fourier transforms that are inﬁnitely long and vice versa. The
fundamental duration-bandwidth principle places a lower bound on the product of the energy
spreads in both domains
σ2
t σ2
F ≥1/4
(10.24)
3A more general result is the preservation of inner products

Fourier Analysis and Spectral Analysis of Deterministic Signals
253
−3
−2
−1
0
1
2
3
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Time
Energy density
(a) Energy density in time
−4
−3
−2
−1
0
1
2
3
4
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Frequency (cycles/time)
Energy density
(b) Energy spectral density
FIGURE 10.6
Energy densities in time and frequency of the rectangular signal in Example 10.6.
where the spreads σ2
t and σ2
F are the second-order central moments of the energy densities in time
and frequency, respectively (Cohen, 1994)4. The quantities σt and σF are known as the dura-
tion and bandwidth, respectively. This result has profound implications in the simultaneous time-
frequency analysis of signals and multiscale identiﬁcation.
Fourier-Stieltjes transform
The Fourier-Stieltjes transform fuses the Fourier series and transform into a single integral.
Introduce dX(F) = X(F)dF so that (10.21) can be re-written as
x(t) =
Z ∞
−∞
ej2πFtdX(F)
(10.25)
In order to accommodate periodic functions, i.e., the Fourier series, we allow dX(F) to be piecewise
continuous, speciﬁcally, a step-like function so that
dX(F) =

cn,
F = Fn, n ∈Z
0,
elsewhere
very much akin to the probability distribution function for discrete-valued random variables. Equa-
tion 10.25 then represents what is known as Fourier-Stieltjes transform.
The advantage of (10.25) is that it enables us to give frequency-domain representations for sig-
nals (functions) that are neither periodic nor absolutely integrable, but have bounded amplitudes.
Random signals are classical examples in this category. These concepts form the cornerstone of
Wiener’s generalized harmonic analysis (Wiener, 1930) presented in Section 11.2.3.
Next we review the foregoing results for discrete-time signals. The forms of Fourier series and
transform are similar to that for the continuous-time signals, but the family of basis functions are
diﬀerent.
10.3.4
DISCRETE-TIME FOURIER SERIES
Discrete-time signals are unique only over the frequency range f ∈[−0.5,0.5) or ω ∈[−π,π) (or
any interval of the same length). Furthermore, the period of a discrete-time signal is expressed in
4A rigorous lower bound is derived in Cohen (1994).

254
Principles of System Identiﬁcation: Theory and Practice
samples. The family of basis functions now consists of all (complex) sinusoids with period N,
ej2πkn/N
n = 0,1,· · · , N −1
Any basis function with frequency f ≥N/N is already included in the basis set above.
The discrete-time Fourier series expansion of a periodic sequence x[k] of period N is given by
x[k] =
N−1
X
n=0
cnej2πkn/N
(Discrete-time Fourier series)
(10.26)
The coeﬃcients {ck} of this expansion are given by:
cn = 1
N
N−1
X
k=0
x[k]e−j2πkn/N
(Discrete-time Fourier coeﬃcients)
(10.27)
Observe that the coeﬃcients are also periodic with the same period N, i.e., cN+n = cN.
Notice the strong similarity of (10.27) with (10.17). Consequently, the coeﬃcients have a similar
interpretation as well. The conjugate symmetry of coeﬃcients exists for real-valued discrete-time
signals as well,
cn = c⋆
N−n−1
n , 0, N/2
(10.28)
assuming N is even.
Power spectrum
Parseval’s result for discrete-time signals provides the decomposition of power in the frequency
domain,
Pxx = 1
N
N−1
X
k=0
|x[k]|2 =
N−1
X
n=0
|cn|2
(10.29)
giving rise to a line spectrum in frequency domain, as in the continuous-time case.
Pxx[n] ≜Pxx( fn) = |cn|2
n = 0,1,· · · , N −1
(10.30)
The diﬀerence between the results in (10.19) and (10.29) is only in the restriction on the number of
basis functions in the expansion.
By virtue of the periodicity of Fourier coeﬃcients in (10.27), the power spectrum of a discrete-
time periodic signal is also periodic with period N, i.e.,
Pxx[n + N] = Pxx[n]
(10.31)
Combined with the conjugate symmetry property (10.28), it deems suﬃcient to analyze the power
spectrum in the range 0 ≤n ≤N/2 −1, i.e., 0 ≤fn = n/N ≤0.5 −1/N.
Example 10.7: Periodic Pulse
The discrete-time Fourier representation of a periodic signal x[k] = {1,1,0,0} with period
N = 4 is given by,
cn = 1
4
3
X
k=0
x[k]e−j2πkn/4
= 1
4 (1 + e−j2πn/4)
n = 0,1,2,3

Fourier Analysis and Spectral Analysis of Deterministic Signals
255
This gives the coeﬃcients
c0 = 1
2;
c1 = 1
4 (1 −j);
c2 = 0;
c3 = 1
4 (1 + j)
Observe that c1 = c⋆
3 .
In §10.3.6 we shall learn an interesting result, which states that the auto-covariance function of
the discrete-time periodic signal and its spectrum form a Fourier series pair.
We turn to the analysis of discrete-time aperiodic signals next.
10.3.5
DISCRETE-TIME FOURIER TRANSFORM
The discrete-time aperiodic signal is treated in the same way as the continuous-time case, i.e., as an
extension of the DTFS to the case of periodic signal as N →∞. The frequency axis is no longer
discrete since the spacing 1/N →0.
The synthesis equation is now an integral, but still restricted to f ∈[−1/2,1/2) or ω ∈[−π,π)
x[k] =
Z 1/2
−1/2
X( f )ej2π f k df = 1
2π
Z π
−π
X(ω)ejωk dω
(Synthesis)
(10.32)
Equation (10.32) is also known as the inverse discrete-time Fourier transform.
The analysis equation is the Discrete-Time Fourier Transform (DTFT).
X( f ) =
∞
X
k=−∞
x[k]e−j2π f k
(DTFT)
(10.33)
Not surprisingly, DTFT is obtained by evaluating the z-transform of a signal on the unit circle
z = ejω = ej2π f (in as much as the FRF is the transfer function evaluated on the unit circle).
The DTFT X( f ) is periodic with a period of one cycle/sample (Hz) as in the case of DTFS.
Convergence is guaranteed provided the signal x[k] is absolutely summable (ﬁnite 1-norm) or is of
ﬁnite energy (weaker condition).
Energy spectral density
Energy is preserved under this transformation once again due to Parseval’s relation:
Exx =
∞
X
k=−∞
|x[k]|2 =
Z 1/2
−1/2
|X( f )|2 df = 1
2π
Z π
−π
|X(ω)|2 dω
(10.34)
Consequently, the quantity
Sxx(ω) = |X( f )|2 = |X(ω)|2
2π
(10.35)
qualiﬁes to be a density function, speciﬁcally as the energy spectral density of x[k].
Given that X( f ) is periodic (for real-valued signals), the spectral density of a discrete-time (real-
valued) signal is also periodic with the same period.
Example 10.8: DTFT of a Discrete-Time Impulse
The Fourier transform of a discrete-time impulse x[k] = δ[n] (Kronecker delta) is
X( f ) = F{δ[n]} =
∞
X
k=−∞
δ[k]e−j2π f k = 1
∀f
(10.36)

256
Principles of System Identiﬁcation: Theory and Practice
The energy spectral density is given by
Sxx ( f ) = |X( f )|2 = 1
∀f
(10.37)
thus giving rise to a uniform energy density.
−10
−5
0
5
10
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Time
Amplitude
(a) Finite-duration pulse
−0.4
−0.2
0
0.2
0.4
0.6
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
Frequency (cycles/sample)
Energy spectral density
(b) Energy spectral density
FIGURE 10.7
Finite-length pulse of Example 10.8 and its energy spectral density when A = 1, L = 10.
Figure 10.7 shows a sketch of the unit impulse and its energy spectral density (shown only
over the fundamental range).
This result is used later in computing the power spectral density of a white-noise signal
through its ACVF.
On the other hand, there exist special discrete-time signals for which the DTFT cannot be computed,
but whose Fourier transform is evaluated using the theory of generalized functions (Antoniou, 2006,
Chapter 6). For example, the Fourier transform of a discrete-time complex exponential x[k] =
ej2π f0k cannot be computed using the DTFT, but using the generalized function theory, is
F{ej2π f0k} = δ( f −f0)
(10.38)
Strictly speaking the complex exponential is a periodic signal and only a Fourier series is appropri-
ate. Another example is that of the Dirac delta function.
Next, consider the case of a ﬁnite length pulse.
Example 10.9: Energy Density Spectrum of a Finite-Duration Pulse
Compute the Fourier transform and the energy density spectrum of a ﬁnite-duration rectan-
gular pulse
x[k] =
( A,
0 ≤k ≤L −1
0
otherwise
Solution: The DTFT of the given signal is
X( f ) =
∞
X
k=−∞
x[k]e−j2π f k =
L−1
X
k=0
Ae−j2π f k = A1 −e−j2π f L
1 −e−j2π f
Sxx ( f ) = A2 1 −cos(2π f L)
1 −cos 2π f
Plots of the signal and its spectral density are shown in Figure 10.8(a) and 10.8(b), respec-
tively. The spectral density is shown only over f ∈[−1/2,1/2).

Fourier Analysis and Spectral Analysis of Deterministic Signals
257
−10
−5
0
5
10
15
20
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Time
Amplitude
(a) Finite-duration pulse
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0
10
20
30
40
50
60
70
80
90
100
Frequency (cycles/sample)
Energy spectral density
(b) Energy spectral density
FIGURE 10.8
Finite-length pulse of Example 10.9 and its energy spectral density when A = 1, L = 10.
Tables containing the list of Fourier transforms for frequently encountered signals are available
in standard texts on signal processing (Proakis and Manolakis, 2005).
Cross-energy spectral density
In the analysis of multivariable signals, it is useful to deﬁne a quantity known as cross-energy
spectral density,
Sx2x1( f ) = X2( f )X⋆
1 ( f )
(10.39)
It is readily seen that upon setting x2[k] = x1[k], (10.39) specializes to the (auto) energy spec-
trum in (10.35).
The cross-spectral density measures the linear relationship between two signals, whereas the
auto-energy spectral density measures linear dependencies within the observations of a signal, in
the frequency domain. When x2[k] and x1[k] are the output and input of a linear time-invariant
system respectively, i.e.,
x2[k] = G(q−1)x1[k] =
n=∞
X
n=−∞
g[k]x1[k −n] = g1[k] ⋆x1[k]
(10.40)
then, using the results of Chapters 4 and 5 as well as the properties of Fourier transform (Theorem
10.2)
X2( f ) = G1(ej2π f )X1( f )
(10.41)
from where two important results emerge,
Sx2x1( f ) = G1(e−j2π f )Sx1x1(f )
Sx2x2( f ) = |G1(e−j2π f )|2Sx1x1(f )
(10.42)
(10.43)
Equation (10.42) is widely used in empirical estimation of transfer function given input-output data
(see Example 11.7) while (10.43) is used in parametric estimation of spectra (see Sections 11.3.2
and 16.5.7).

258
Principles of System Identiﬁcation: Theory and Practice
Coherency
It will be shown later that cross-spectral density is closely related to the cross-covariance function
(Wiener-Khinchin theorem). Thus, the cross-spectral density is a frequency-domain measure for
detecting linear relationships between two variables. As with correlation, a normalized version of
cross-spectral density known as coherency is used.
κx2x1( f ) =
Sx2x1( f )
pSx2x2( f )Sx1x1( f )
(10.44)
In practice, the magnitude squared coherence |κx2x1( f )|2 is used.
When (10.40) holds, it is easy to show that
κx2x1( f ) = 1, ∀f
(10.45)
The condition (10.45) is widely used as a test for linearity between two signals.
Further discussion on cross-spectral density and coherence is deferred until Section 11.4.
Summary
It is useful to summarize our observations on the spectral characteristics of diﬀerent classes of
signals.
i. Continuous-time signals have aperiodic spectra
ii. Discrete-time signals have periodic spectra
iii. Periodic signals have discrete power spectra
iv. Aperiodic (ﬁnite energy) signals have continuous energy spectra
Discrete spectra are also referred to as line spectra, whereas continuous spectra are qualiﬁed by a
spectral density function.
As remarked earlier, Table 10.1 summarizes the four diﬀerent variants of the transform that we
have learnt. The ﬁrst column carries the name associated with the variant, second column provides
expression for forward (analysis) and inverse (synthesis) transforms. while the third column contains
the power / energy equivalence result along with the binding requirements of the signal. Note that
the transforms are listed in terms of cyclic frequency instead of angular frequency, for the sake of
convenience.
An interesting inference can be drawn from the above observations. Sampling in time introduces
periodicity in frequency. The converse of this fact, i.e., sampling in frequency corresponds to peri-
odicity in time is also true. This fact is established later in Section 10.4.
Next we review certain useful properties of the DTFT. Proofs of these statements and an elab-
orate treatment is available in standard texts (see Proakis and Manolakis (2005)). Although these
properties are listed for the discrete-time case, they apply equally to continuous-time signals as well.
Further, these properties enjoy a dual relationship between the time and frequency domains.
10.3.6
PROPERTIES OF DTFT
i. Linearity: If x1[n]
F
−→X1(ω) and x2[n]
F
−→X2(ω) then
a1x1[n] + a2x2[n]
F
−→a1X1( f ) + a2X2( f )
ii. Time shifting: If x1[n]
F
−→X1(ω) then x1[n −k]
F
−→e−j2π f k X1( f )
Note that the energy spectrum of the shifted signal remains unchanged while the phase spectrum
shifts by −ωk at each frequency.
Dual: A shift in frequency X( f −f0) corresponds to modulation in time, ej2π f0nx[n].

Fourier Analysis and Spectral Analysis of Deterministic Signals
259
TABLE 10.1
Fourier Transforms and corresponding energy/power decompositions (expressed in cyclic frequency)
Variant
Synthesis
and
analysis
equations
Parseval’s relation and signal require-
ments
Fourier Series
x(t) =
∞
X
n=−∞
cnej2πnF0t
Pxx = 1
Tp
Z Tp
0
|x(t)|2 dt =
∞
X
n=−∞
|cn|2
cn ≜1
Tp
Z
Tp
x(t)e−j2πnF0t dt
x(t) is periodic with fundamental period
Tp = 1/F0
Fourier Transform
x(t) =
Z ∞
−∞
X(F)ej2πFt dF
Exx =
Z ∞
−∞
|x(t)|2 dt =
Z ∞
−∞
|X(F)|2 dF
X(F) ≜
Z ∞
−∞
x(t)e−j2πFt dt
x(t) is aperiodic;
Z ∞
−∞
|x(t)| dt < ∞
or
Z ∞
−∞
|x(t)|2 dt < ∞(ﬁnite energy,
weaker requirement)
Discrete-Time Fourier
Series
x[k] =
N−1
X
n=0
cnej2πkn/N
Pxx = 1
N
N−1
X
k=0
|x[k]|2 =
N−1
X
n=0
|cn|2
cn ≜1
N
N−1
X
k=0
x[k]e−j2πkn/N
x[k] is periodic with fundamental period
N
Discrete-Time Fourier
Transform
x[k] =
Z 1/2
−1/2
X( f )ej2π f k df
Exx =
∞
X
k=−∞
|x[k]|2 =
Z 1/2
−1/2
|X( f )|2 df
X( f ) ≜
∞
X
k=−∞
x[k]e−j2π f k
x[k] is aperiodic;
∞
X
k=−∞
|x[k]| < ∞or
∞
X
k=−∞
|x[k]|2 < ∞(ﬁnite energy, weaker
requirement)
iii. Time reversal: If x[n]
F
−→X(ω), then x[−n]
F
←→X(−f ) = X⋆( f ) where the star denotes
complex conjugate.
If a signal is folded in time, then its power spectrum remains unchanged; however, the phase
spectrum undergoes a sign reversal.
Dual: The dual is contained in the statement above.
iv. Convolution Theorem: Convolution in time-domain transforms into a product in the frequency
domain.

260
Principles of System Identiﬁcation: Theory and Practice
Theorem 10.2
If x1[n]
F
−→X1(ω) and x2[n]
F
−→X2(ω) and
x[k] = (x1 ⋆x2)[k] =
∞
X
n=−∞
x1[n]x2[k −n]
then,
X( f ) ≜F{x[k]} = X1( f )X2( f )
(10.46)
Proof. See Proakis and Manolakis (2005) for example.
□
This is an extremely useful result in the analysis of signals and LTI systems. The deﬁnition of
FRF in (4.19) is an example application, where the convolution equation above is replaced by
the one that governs an LTI system. Then,
Y ( f ) = G( f )U( f )
or
Y (ω) = G(ω)U(ω)
(10.47)
The above result is familiar to us from Chapter 5 in the form of Equation 5.23, where the quan-
tities Y ( f ), G( f ) and U( f ) have been deﬁned.
Remarks:
i. We have used G(ω) to be consistent with the notation used in (10.47), whereas strictly it should read
G(ejω), as used in Chapter 5.
ii. The above relation does not apply to random signals since their Fourier transforms do not exist.
However, the spectral relations in (10.42) and (10.43) carry forward in a nice way, but with replacing
the energy spectral densities by power spectral densities. Chapter 11 discusses these points in greater
detail.
Dual: Multiplication in time corresponds to convolution in frequency domain.
x[k] = x1[k]x2[k]
F
−→
Z 1/2
−1/2
X1(λ)X2( f −λ) dλ
(10.48)
The dual is useful in analyzing other transforms (for example, wavelet transforms, see §25.1.5.1).
v. Correlation Theorem (Wiener-Khinchin theorem for deterministic signals)
Theorem 10.3
The Fourier transform of the cross-covariance function σx1x2[l] (recall Deﬁnition 10.6) is the
cross-energy spectral density (10.39)
F{σx1x2[l]} =
∞
X
l=∞
σx1x2[l]e−j2π f l = Sx1x2( f ) = 2πSx1x2(ω)
(10.49)

Fourier Analysis and Spectral Analysis of Deterministic Signals
261
x[k]
Sxx(f)
σxx[l]
X(f)
x[k] ? x[−k]
X(f)X?(f)
Deterministic
Energy Signal
Spectral
Density
Fourier 
Transform
ACVF
F
F
Wiener-Khinchin
Theorem
|XN(fn)|2
lim
N!1
Magnitude-squared DFT
FIGURE 10.9
Computing the energy spectral density through three diﬀerent ways for a deterministic signal.
Proof. Firstly, recognize that the cross-covariance function in (10.13) is the convolution between
x1[k] and ˜x[k] = x2[−k]
x1 ⋆˜x2[l] =
∞
X
n=−∞
x1[n] ˜x2[l −n] =
∞
X
n=−∞
x1[n]x2[n −l] = σxx[l]
(10.50)
From the convolution and time reversal properties, it follows that
F{σxx[l]} = F{x1 ⋆˜x2[l]} = X1( f ) ˜X2( f ) = X1( f )X⋆
2 ( f ) = Sx1x2( f )
(10.51)
□
The result, originally due to Wiener (1930) and Khintchine (1934) for stationary random signals,
is a fundamental result in the spectral analysis of signals (see Theorem 11.4).
An alternative way of stating the foregoing result is that the auto-covariance function of a signal
and its energy spectral density form a Fourier transform pair.
σxx[l]
F
−→Sxx( f )
(10.52)
Figure 10.9 shows three diﬀerent ways of computing the theoretical energy spectral density:
(i) the Fourier transform method (also known as the direct method), (ii) the Wiener-Khinchin
method based on the Fourier transform of ACVF (a.k.a. direct method) and (iii) the discrete
Fourier transform-based (to be deﬁned shortly in §10.4) method. The last method is listed pri-
marily to strike an analogy with the random signal case, where |XN ( f )|2 would be replaced by
what is known as a periodogram (see §10.4.1).
Remarks:
In the analysis of random signals, as we shall learn in Chapter 11, the l.h.s. of (10.52) is replaced
by the ACVF of the random signal, while the r.h.s. is replaced by the power spectral density of the signal.
In other words, the second of the three methods is useful in arriving at the spectral density. In Chapter 11,
we shall also study the conditions under which this result holds.
The foregoing theorem can also be applied to the case of discrete-time periodic signals (with
period N), but now to the power spectrum (distribution) since the spectral density does not exist.
Using the deﬁnitions of spectrum in (10.30) and the ACVF in (10.12), we have, for periodic

262
Principles of System Identiﬁcation: Theory and Practice
signals
Pxx[n] = 1
N
N−1
X
l=0
σxx[l]e−j2πln/N
σxx[l] =
N−1
X
l=0
Pxx[n]ej2πln/N
(10.53a)
(10.53b)
vi. Plancherel-Parseval’s theorem:
Inner products are preserved in time and Fourier domains.
Theorem 10.4
Consider two discrete sequences x1[k] and x2[k] whose inner products exist.
If x1[k]
F
−→X1(ω) and x2[k]
F
−→X2(ω) then
∞
X
k=−∞
x1[k]x∗
2[k] =
Z 1/2
−1/2
X1( f )X∗
2( f ) df
(10.54)
Proof. Available in standard texts. See Oppenheim and Schafer (1987), for example.
□
The limits on the integral in the RHS of (10.54) are due to the periodic nature of the continuous
functions X1( f ) and X2( f ).
Setting x2[k] = x1[k] in (10.54) produces the Parseval’s identity (10.34). A similar result exists
for other cases including periodic discrete-time and aperiodic / periodic continuous-time signals.
In the study of the Fourier transform and its properties thus far we have assumed that the signals
are available for an inﬁnite length of time, which is an impractical assumption. It is therefore ap-
propriate to study perhaps the practically most important version of the Fourier transform, known
as the DFT.
10.4
DISCRETE FOURIER TRANSFORM (DFT)
The development of DFT is motivated by three facts concerning the Fourier representation of
discrete-time signals:
1. Only ﬁnite-length measurements are available.
2. Signals encountered in reality are not necessarily periodic.
3. DTFT can only be computed at a discrete set of frequencies.
Therefore, it is necessary to make the DTFT in (10.33) amenable to ﬁnite-length series and
computation on a grid of frequencies. In other words, it is required to sample X( f ) in frequency.
However, since X( f ) is periodic with a period of one cycle/sample, it is suﬃcient to sample the
frequency axis in the fundamental range f ∈[−0.5,0.5).
The sampled and truncated version of DTFT is known as Discrete Fourier Transform (DFT),
X( fn) =
N−1
X
k=0
x[k]e−j2π fnk
(10.55)

Fourier Analysis and Spectral Analysis of Deterministic Signals
263
where N is the length of the signal x[k]. The transform derives its name from the fact that it is now
discrete in both time and frequency.
A key decision factor is the choice of grid spacing in the frequency axis, △f ≜fn −fn−1, i.e.,
the sampling interval in the frequency domain. The governing criterion for △f is that we should be
able to recover X( f ) from its sampled version X( fn). This is reminiscent of the criterion to be met
in sampling continuous-time signals (Chapter 6).
The main result that addresses the above concern is given below.
Main result
For signal x[k] of length Nl, its DTFT X( f ) is perfectly recoverable from its sampled version
X( fn) if and only if the frequency axis is sampled uniformly at Nl points in [−1/2,1/2), i.e.,
if
△f = 1
Nl
or
△ω = 2π
Nl
(10.56)
A proof of the above result is available in standard texts on signal processing. See Proakis and
Manolakis (2005) for instance.
The resulting DFT is known as the N-point DFT with N = Nl. The associated analysis and
synthesis equations are given by
X[n] ≜X( fn) =
N−1
X
k=0
x[k]e−j 2π
N nk
n = 0,1,· · · , N −1
x[k] = 1
N
N−1
X
n=0
X[n]ej 2π
N kn
k = 0,1,· · · , N −1
(10.57a)
(10.57b)
The above relationships are also sometimes written as
X[k] =
N−1
X
n=0
x[n]W−kn
N
;
x[n] = 1
N
N−1
X
k=0
X[k]W kn
N
where WN = ej2π/N.
Unitary DFT
It is also a common practice to use a factor 1/
√
N on both (10.57a) and (10.57b) to achieve sym-
metry of expressions.
X[n] =
1
√
N
N−1
X
k=0
x[k]e−j2π fnk
fn = n
N , n = 0,1,· · · , N −1
x[k] =
1
√
N
N−1
X
n=0
X[n]ej2π fnk
k = 0,1,· · · , N −1
(10.58a)
(10.58b)
The resulting transforms are known as unitary transforms since they are norm-preserving, i.e.,
||x[k]||2
2 = ||X[n]||2
2.

264
Principles of System Identiﬁcation: Theory and Practice
Reconstruction
The reconstruction of X(ω) from its N-point DFT is facilitated by the following expression (Proakis
and Manolakis, 2005):
X( f ) =
N−1
X
n=0
X
 2πn
N
!
P
 
2π f −2πn
N
!
N ≥Nl
(10.59)
where P( f ) = sin(π f N)
N sin(π f ) e−jπ f (N−1)
The above reconstruction expression is strikingly similar to that for a continuous-time signal x(t)
from its samples x[k]. Further, the condition N ≥Nl is similar to the requirement for avoiding
aliasing.
Consequences of sampling the frequency axis
Recall a key observation in Section 10.3.5 on how sampling in time introduces periodicity in fre-
quency domain. On the same note we also postulated that sampling in frequency should imply
periodicity in time-domain. It is appropriate that we analyze DFT in this light.
When the DTFT is evaluated at N equidistant points (also known as bins) in [−π,π], one obtains
X
 2π
N n
!
=
∞
X
k=−∞
x[k]e−j2πnk/N
n = 0,1,· · · , N −1
=
∞
X
l=−∞
l N+N−1
X
k=l N
x[k]e−j2πnk/N
=
N−1
X
k=0
∞
X
l=−∞
x[k −lN]e−j2πnk/N
The last equation above appears structurally very similar to the expression for the coeﬃcients of a
discrete-time Fourier series in (10.27). To realize this similarity, we re-write (10.27),
Npcn =
Np−1
X
k=0
xp[k]e−j2πnk/Np
(10.60)
where xp[k] is a periodic signal with period Np.
It is clear that X
 2π
N n

and Ncn have identical forms when we choose the inner summation of
X
 2π
N n

as the periodic signal with a period N in (10.60)
xp[k] =
∞
X
l=−∞
x[k −lN]
Np = N
The signal xp[k] =
∞
X
l=−∞
x[k −lN] is indeed periodic with period N, thereby justifying the compar-
ison. On the same note, this periodic signal is also a periodic extension of the ﬁnite-length signal
{x[0], x[1],· · · , x[N −1]}.
Putting together our observations above, we can make the following inference:

Fourier Analysis and Spectral Analysis of Deterministic Signals
265
The N-point DFT X[n] of a sequence xN = {x[0], x[1],· · · , x[N −1]} is equivalent to the
coeﬃcient cn of the DTFS of the periodic extension of xN. Mathematically,
X[n] = Ncn,
cn = 1
N
N−1
X
k=0
x[k]e−j 2π
N kn
(10.61)
Stated alternatively, an N-point DFT implicitly assumes the given ﬁnite-length signal to be peri-
odic with a period equal to N regardless of the nature of the original signal.
These observations also throw light on the reconstruction equation in (10.57b).
Energy spectral density
The energy spectral density of x[k] at fn can be computed from the DFT as
Sxx( fn) = |X( fn)|2
(10.62)
In the limit as N →∞, DFT goes back to DTFT, and therefore,
lim
N→∞|X( fn)|2 = Sxx( f )
(10.63)
This result is indicated in the diagonal of the spectral density diagram in Figure 10.9.
Properties of DFT
The DFT inherits all of the properties of DTFT discussed earlier with the only diﬀerence that the
convolution property now involves what is known as circular convolution (see Porat (1997) and
Proakis and Manolakis (2005)) due to the fact that DFT deals with ﬁnite-length sequences.
i. Circular convolution property:The DFT of the circular convolution (denoted by ⊛) of two
ﬁnite-length sequences x1[k] and x2[k] is the product of their respective DFTs.
x1 ⊛x2[k]
DFT
=⇒X1[n]X2[n]
(10.64)
The dual of this relationship is simply its converse.
ii. Parseval’s identity: The identity is derived from that of the DTFS in (10.29) and using the
relationship between the DFT coeﬃcients and those of the DTFS,
N−1
X
k=0
|x[k]|2 = N
N−1
X
n=0
|cn|2
Knowing X[n] = Ncn,
N−1
X
k=0
|x[k]|2 = 1
N
N−1
X
n=0
|X[n]|2
(10.65)
With a unitary DFT,
X[n] =
1
√
N
N−1
X
k=0
x[k]e−j2πnk/N;
x[k] =
1
√
N
N−1
X
n=0
X[n]ej2πnk/N
the identity is simpler
N−1
X
k=0
|x[k]|2 =
N−1
X
n=0
|X[n]|2
(10.66)

266
Principles of System Identiﬁcation: Theory and Practice
iii. Periodicity: The DFT is periodic with a period N,
X[n + N] = X[n]
(10.67)
iv. Circular conjugate symmetricity: The coeﬃcients of a DFT satisfy
X[n] = X⋆[N −n]
n , 0, N/2 + 1(even N)
(10.68)
v. Frequency resolution: The spacing on the frequency axis in an N-point DFT is equal to △f =
1/N or △ω = 2π/N.
Computation of DFT: FFT
It is useful to view DFT and Inverse DFT as linear transformations
XN = WNxN
xN = 1
N W∗
NXN
where the quantities xN, XN and WN are stacked up as
xN =

x[0]
x[1]
...
x[N −1]

;
XN =

X[0]
X[1]
...
X[N −1]

WN =

1
1
1
· · ·
1
1
WN
W2
N
· · ·
W N−1
N
1
W2
N
W4
N
· · ·
W2(N−1)
N
...
...
...
...
...
1
W N−1
N
W2(N−1)
N
· · ·
W (N−1)(N−1)
N

The linear transformation relationships are useful for hand calculations. Practically these imple-
mentations have to be carried out at a machine level. Eﬀorts in this direction existed since the middle
of the nineteenth century. However, it was only in the mid 1960s that a breakthrough algorithm due
to Cooley and Tukey (1965) emerged for fast computation of DFT. The algorithm known as the Fast
Fourier transform revolutionized the world of spectral analysis. It is based on a divide and conquer
concept that was originally conceived for a dyadic length signal, i.e., Nl = 2m, m ∈Z. Subse-
quently, several variants of the algorithm have come into existence and the requirement of dyadic
length is no longer binding. FFT is available today in almost every numerical computation package.
The major computational improvement in the FFT algorithm is the reduction in the number of
(machine) operations from O(N2) in the regular DFT to O(N log(N)) (Proakis and Manolakis,
2005; Smith, 1997). Note that the Fast Fourier Transform is merely an algorithm, but not a new
transform in itself!
For an in-depth presentation of these algorithms, the reader is referred to standard signal pro-
cessing texts (Oppenheim and Schafer, 1987; Porat, 1997; Proakis and Manolakis, 2005; Smith,
1997).
We close this chapter with an important concept that sets up the launch pad for the topic of the
next chapter, which is that of power spectral density for random signals.
10.4.1
SPECTRUM AND SPECTRAL DENSITY
A vast variety of signals that we encounter are either ﬁnite-energy aperiodic or stochastic (or mixed)
signals, which are characterized by energy and power spectral density, respectively. However, the

Fourier Analysis and Spectral Analysis of Deterministic Signals
267
practical situation is that we have a ﬁnite-length signal xN = {x[0], x[1],· · · , x[N −1]}. Computing
the N-point DFT, as we know from the previous section, amounts to treating the underlying inﬁnitely
long signal ˜x[k] as periodic with period N. Thus, strictly speaking we obtain a power spectrum (line
spectrum) regardless of the nature of underlying signal.
In order to be able to use the spectrum as a tool for estimating spectral density of ﬁnite-length
observations of random signals and to bring the deterministic and stochastic signals into a single
framework of estimation, an artiﬁcial spectral density known as the periodogram (Schuster, 1897)
is constructed as follows.
The power spectrum Pxx( fn) for the ﬁnite-length signal {x[k]}N−1
k=0 is obtained by recalling the
deﬁnition of power for a periodic signal (10.6) and using (10.65)
=⇒Pxx( fn) = |cn|2 = |X[n]|2
N2
(10.69)
Subsequently, an empirical power spectral density (power per unit cyclic frequency) for the
ﬁnite-length sequence is introduced as,
Pxx( fn) ≜PSD( fn) = Pxx( fn)
△f
= N|cn|2 = |X[n]|2
N
(10.70)
where the units of frequency is, as usual, in cycles/sample. In Chapter 16, we shall learn how to
apply the above deﬁnition to estimate the spectral density of random signals from a a ﬁnite-length
realization. The PSD in (10.70) is also useful in handling mixed signals, e.g., measurements of
sinusoids.
The quantity Pxx( fn) in (10.70) is known as the periodogram, ﬁrst introduced by Schuster
(1897). Chapter 16 discusses the applications and properties of the periodogram in greater detail.
Note: To express density in power per radians/sample, multiply Pxx ( fn) in (10.70) by a factor of 1/2π. When
it is desired to express density in power per (frequency of continuous-time signal), Pxx ( fn) is multiplied by
1/Fs, where Fs is the sampling frequency in samples/time.
10.5
SUMMARY
In this chapter, we learnt the concepts of Fourier series and transforms for periodic and aperiodic
signals, respectively. Fourier transforms exist in diﬀerent forms depending on the nature of the
signal. Despite the apparent diﬀerences in these variants, all of them are based on the single principle
of representing signals using sinusoidal basis functions.
Although the main motive of Fourier representation is to provide signal decomposition, practi-
cally the energy / power spectral decomposition due to Parseval-Plancherel’s theorem is the more
useful result. Frequency-domain representations provide valuable tools for analysis of signals and
systems. Power spectrum / spectral density is a valuable tool in detecting periodicities, estimation
of frequency response functions and ﬁlter design.
Periodic signals have discrete (line) spectral distribution, whereas aperiodic signals (with ﬁnite
energy) have continuous spectral distributions. Consequently, aperiodic signals can be characterized
by spectral densities.
The correlation theorem or the Wiener-Khinchin theorem connects the correlation (second-
order) structure characterized by the auto-covariance function to the power decomposition in the
frequency-domain characterized by the spectral density. This is a unifying result for deterministic
and stochastic signals as we shall learn in Chapter 11. It is worth noting that while Fourier represen-
tations oﬀer very powerful means of signal analysis, the results should be interpreted with great care
since the underlying mathematics may not have any relevance to the physics of the process under
analysis.

268
Principles of System Identiﬁcation: Theory and Practice
REVIEW QUESTIONS
R10.1 Distinguish between a periodic and an aperiodic signal.
R10.2 Identify the key diﬀerences between an energy signal and a power signal
R10.3 What is the basic diﬀerence between a Fourier series and a Fourier transform?
R10.4 Identify the conditions on a continuous-time signal under which its Fourier transform exists.
R10.5 Highlight the salient diﬀerences between the continuous-time and discrete-time Fourier series.
R10.6 List the important properties of the DTFT.
R10.7 Does the DTFT of a stationary random signal exist? Give reasons.
R10.8 Why is DFT necessary? How diﬀerent is it from DTFT?
R10.9 How is the Fourier transform useful in arriving at the frequency response functions for LTI
systems?
R10.10 Describe the connection between cross-correlation and cross-energy density.
R10.11 Sampling in time introduces periodicity in frequency and vice versa. Explain this fact.
R10.12 Deﬁne periodogram and explain the reasons for introducing it.
EXERCISES
E10.1 Determine if the following signals are periodic:
(i) x[k] = cos(0.4πk), (ii) x[k] = sin(0.8πk + π/3), (iii) x[k] = cos(
√
0.5πk)
E10.2 For the signals that are periodic in the exercise above, write a Fourier series expansion.
E10.3 Illustrate the Gibbs phenomenon for the square wave of Example 10.5.
E10.4 Consider a continuous-time sinusoidal signal x(t) = sin(2πF0t). Suppose that F0 = 10 kHz and
that this signal is sampled at sampling frequency of Fs = 45 kHz to produce x[k]. Then
a. Plot the signal x[k] (stem plot), 0 ≤k ≤45. Can you determine both the period and frequency
f0 of x[n] by visual inspection? Theoretically compute the frequency f0 of the signal x[k]?
b. Assume you were measuring x[k]. For this purpose, generate 1000 samples of the measurement
y[k] = x[k] + e[k] where e[k] is a Gaussian distributed random sequence (noise) with mean
zero and unit variance. Plot the ﬁrst 50 (or 100) samples of y[k]. Are you able to detect the
d.t. sine wave without ambiguity?
c. Now compute the FFT of X( f ) using the fft routine in MATLAB. Compute the power spec-
trum of y[k], given by |Y ( f )|2. Plot |Y ( f )|2 vs. f . Can you now detect the frequency of the
d.t. sine wave? Compare this with your experience in part (b) and explain.
E10.5 Consider the signal x[k] = {−1,2,−3,2,−1} for k = −2,−1,0,1,2 whose Fourier Transform is
X(ω). Compute the following quantities, without explicitly computing X(ω):
(a) X(0) (b) ∠X(ω) (c)
Z ∞
−∞
X(ω) dω (d) X(π) (e)
Z ∞
−∞
|X(ω)|2 dω.
E10.6 Consider the periodic signal x[k] = 1,0,1,2,3,2 starting from k = 0. Verify Parseval’s theorem
for this case.
E10.7 A signal x[k] has the Fourier Transform:
X(ω) =
1
1 −ae−jω
Determine the Fourier Transform of the following signals:
(i) x[2k + 1] (ii) eπk/2x[k + 2] (iii) x[k] cos[0.3πk] and (iv) x[k] ⋆x[k −1].

Fourier Analysis and Spectral Analysis of Deterministic Signals
269
E10.8 Determine the sequence h[n] whose DTFT is H(ω) = 1 + 2 cos ω + 3 cos(2ω).
G(ω) =

0
|ω| ≤π/8
1
π/8 < |ω| < 3π/8
0
3π/8 ≤|ω| ≤π
(10.71)
Determine the impulse response of the ﬁlter.
E10.9 Consider a continuous-time sine wave x(t) = sin(2πF0t) + sin(2πF1t) with F0 = 5 and F1 = 10
kHz. Generate N = 200 observations of the sampled signal x[k] at a sampling frequency of Fs = 40
kHz.
a. Theoretically compute the frequencies and period of x[k]. Plot the signal x[k] (stem plot),
0 ≤k ≤40. Can you determine both the period and frequencies of x[k] by visual inspection?
If yes/no, provide answers.
b. Assume you were measuring x[k]. For this purpose, generate the measurement y[k] = x[k]+e[k]
where e[k] is a Gaussian distributed random sequence (white noise) with mean zero and unit
variance. Plot the ﬁrst 50 (or 100) samples of y[k]. Are you able to detect the period of the
underlying signal x[k] without ambiguity?
c. Detect the frequencies by computing the power spectral density of y[k], i.e., the periodogram
given by |Y[n]|2/N where N is the number of observations and Y[n] is the DFT of y[k]. For
this purpose, use the fft routine in MATLAB. Compare your results with those obtained from
periodogram routine.
d. Explain or analyze what you would expect to observe in the periodogram if x[k] was generated
at Fs = 15 Hz instead.
E10.10 A set of 100 samples of a continuous-time signal x(t) is obtained by sampling at interval
T = 1.28 milliseconds. Suppose that x(t) has a frequency F = 300 Hz and the 100-point DFT, X d[k]
is computed. At what values of k will the DFT exhibit a peak? What is the minimum number of
zeros with which we need to pad x[n] to identify the frequency exactly?
E10.11 Given two signals,
x1[n] =
(
sin(0.6πn),
0 ≤n < N
sin(0.44πn),
N ≤n < 2N
x2[n] =
( sin(0.6πn) + sin(0.44πn)
0 ≤n < 2N
a. Compute the power spectra of these two signals for N = 2000 and plot them.
b. From the plots, can you distinguish these two signals? If yes/no, elaborate.
c. If your answer to the above question is a NO, how would you tailor the use of Fourier Transform
to distinguish two such signals through power spectral plots?

11
Spectral Representations of Random
Processes
In this chapter, we study the spectral representations of random processes. Speciﬁcally, the
focus is on the deﬁnitions of power spectral density for random signals, the Wiener-Khinchin
theorem and the important spectral factorization result. Bivariate frequency-domain mea-
sures, namely, cross-power spectrum, coherence and partial coherence are also discussed. A
study of this chapter reinforces concepts in previous chapters and oﬀers a strong foundation
for estimation of frequency-domain models, time-delay estimation and input design.
11.1
INTRODUCTION
Spectral distributions and densities for random signals cannot be constructed using the same line
of approach as that for deterministic signals owing to an important fact: the Fourier transform of
a random signal does not exist. The reason is that a random signal neither satisﬁes the ﬁnite 1-
norm requirement nor the ﬁnite 2-norm requirement. Nevertheless, the theoretical developments for
deterministic signals in the previous section, speciﬁcally the concept of Fourier transforms and the
Wiener-Khinchin theorem are foundational in developing a similar theory for random processes.
Random signals (with bounded amplitude) are in general, aperiodic power signals, for which
no Fourier transform or series deﬁnitions exist. At a later stage, we shall study a special class of
random processes known as harmonic processes, which are mean-square periodic.
The aperiodic nature of random signals encourages us to postulate the existence of a spectral
density. In the following sections, we shall learn how spectral densities are deﬁned for stationary
random processes, the conditions under which they exist and their theoretical aspects. These sec-
tions summarize an encouraging and important fact - spectral densities also exist for (a large class
of) stationary random processes and they are related to the auto-covariance functions through the
Fourier transforms, thereby exactly resembling the case for deterministic signals.
Historical note
The theory pertaining to spectral representations of random processes is largely due to a culmination
of pioneering works in the ﬁelds of mathematics and signal processing during the years 1920-1950
(due to Wiener, Khinchin, Wold, Herglotz, Bochner, Kolmogorov, Cramer and Wintner).
Wiener’s generalized harmonic analysis (GHA) is one of the foundational results in this context
(Benedetto, 1997; Wiener, 1930). Another fundamental result known as the Wiener-Khinchin the-
orem1 (also available as Herglotz or Bochner theorem in functional analysis) for continuous-time
stochastic processes along with the associated Wold’s theorem for discrete-time processes constitute
the milestone results in spectral representations of stochastic processes.
1Certain historical critiques term this as a misnomer with a note that Khinchin established the result ﬁrst, which Wiener
used later in 1950.
270

Spectral Representations of Random Processes
271
Three main results
Before dwelling into the theoretical details of the aforementioned results, it is useful to obtain a
summary overview of the contributions and their parallels with those for deterministic processes.
The three main results are:
1. Spectral representation of (stationary) random processes: It is possible to represent random pro-
cesses in a similar way as the Fourier transform-based description of deterministic processes. The
diﬀerence is that for the case of stochastic process, the coeﬃcients of representation are random
and uncorrelated, with the requirement that the random signal does not explode in amplitude at
large times. Wiener termed this as generalized harmonic analysis of signals. The problem was
originally treated in the continuous-time domain, but was in due course extended to accommo-
date discrete-time signals as well. The GHA facilitates the deﬁnition of a spectral density for a
stationary random process in a strikingly similar way as (10.35).
2. Spectral representation of the auto-covariance function: The more useful and mathematically
elegant result is the connection between the auto-covariance function and the spectral density of
a stationary process. The spectral distribution / density and the auto-covariance function of a class
of random processes form a Fourier pair. This is the essence of Wiener-Khinchin (Herglotz and
Bochner) theorem, which brought the deterministic and (restricted class of) stochastic processes
into a uniﬁed framework (recall (10.49)).
In several texts, this result is presented as a deﬁnition of power spectrum for random process.
However, it is more of a result rather than a deﬁnition. The Fourier transform of the ACVF as it
stands cannot be immediately interpreted as spectral density. Support for this interpretation stems
from Wiener’s GHA or a less formal approach discussed below (see Percival and Walden (1993)
and Priestley (1981)). The most important contributions of the W-K theorem are that (i) it throws
light on the conditions under which a spectral density exists and (ii) oﬀers means of computing
spectral densities from time-series.
3. Spectral density as an ensemble average: An intuitive but a practically very useful deﬁnition
of power spectrum is obtained by an ensemble averaging of the power spectral density of a
ﬁnite-length realization evaluated in the asymptotic time limit, N →∞. An advantage with this
deﬁnition is that one can begin with the classical Fourier transform of the ﬁnite-length realiza-
tion. Further, it also provides the starting point for a wide class of spectral density estimation
methods. The theoretical conditions under which the existence of the spectral density, when it
is constructed using this approach, is provided by the Wiener-Khinchin (Herglotz and Bochner)
theorem.
Figure 11.1 summarizes the three diﬀerent methods discussed above where the power spectral
density is denoted by γ(ω). As highlighted above, the GHA path gives the rigorous theoretical
deﬁnition, whereas the ensemble method aids in an intuitive understanding and estimation of the
spectral density. The W-K theorem path is perhaps the most widely used relation for both the theo-
retical computation and estimation of the power spectral density.
Remarks:
Note that we have switched over from cyclic frequency f to angular frequency ω = 2π f , which
has the units of radians / sample.
The following section presents the technical details pertaining to the three results above.
11.2
POWER SPECTRAL DENSITY OF A RANDOM PROCESS
For pedagogical reasons, we shall begin with the least rigorous, but intuitively appealing deﬁnition
of power spectrum and gradually arrive at Wiener’s representation through the generalized harmonic
analysis. This is somewhat in an order reverse to the developments in Section 10.3, but the reader
will shortly appreciate the justiﬁcation for this choice.

272
Principles of System Identiﬁcation: Theory and Practice
v[k]
γvv(!)
σvv[l]
dZ(!)
E(v[k]v[k −l])
dZ(!)dZ?(!)
d!
Stationary
Signal
Spectral
Density
ACVF
Wiener-Khinchin
Theorem
E
✓|VN(!n)|2
2⇡N
◆
Periodogram
Averaging
lim
N!1
F
Generalized Harmonic Analysis
FIGURE 11.1
Three diﬀerent methods of arriving at the spectral density of a stationary stochastic process.
11.2.1
PSD FROM ENSEMBLE AVERAGING
Consider N observations constituting the ith realization of a random signal v[k]. The ﬁnite-length
realization vN = {v(i)[k]}N−1
k=0 has ﬁnite energy, whereas the inﬁnitely long random signal has in-
ﬁnite energy, but ﬁnite power (assuming the random signal to be of bounded amplitude). In con-
structing the power spectral density of the random process {v[k]}, it is natural to ﬁrst construct the
p.s.d. of the ﬁnite-length realization.
In Chapter 10, we introduced the notion of power spectral density for ﬁnite-length sequences
through the use of DFT and (10.70). Applying those ideas, the p.s.d. of vN in (radians/sample) is
given by
γ(i,N)
vv
(ω) =
1
2πN

N−1
X
k=0
v(i)[k]e−jωk

2
(11.1)
Since (11.1) is the density for a single realization, the next step is to take the ensemble average of
the densities of all realizations, E(γ(i,N)
vv
(ω)), as with any other statistical property. Finally, remem-
bering that the random process theoretically exists forever, we evaluate the average in the limiting
case of N →∞. Thus, a deﬁnition of PSD for the random process arises.
Deﬁnition 11.1. The PSD of a random process is the asymptotic ensemble average of the power
spectral density of a ﬁnite-length realization
γvv(ω) = lim
N→∞E(γ(i,N)
vv
(ω)) = lim
N→∞E
 |VN (ω)|2
2πN
!
(11.2)
where we have dropped the realization superscript on VN since it is implicitly understood in an
expectation operation. In (11.2), VN (ω) is the DFT of vN.
Observe that the density in (11.2) satisﬁes four necessary properties listed below.
Deﬁnition 11.2. (Properties of a spectral density function) The spectral density function of a
discrete-time stationary process necessarily satisﬁes the following properties:
i. γvv(ω) ≥0,
∀ω
ii. γvv(ω) = γvv(−ω)
∀ω ∈[−π,π]
iii. γvv(ω + 2π) = γvv(ω)
iv.
1
2π
Z π
−π
γ(ω) dω < ∞

Spectral Representations of Random Processes
273
The last property of bounded integral is established later, see discussion post equation (11.15).
An example illustrating the above ideas brings in more insights.
Example 11.1: Spectral Density of a White-Noise Process
We ﬁrst generate N samples of a white-noise process
v[k] = e[k]
e[k] ∼N (0,1)
(11.3)
Following the ideas outlined above, we ﬁrst compute the power spectral density according
to (11.1). The resulting PSD is averaged across Ni realizations. Figure 11.2(a) shows the
PSD obtained for a single record of data containing N = 500 samples. Ensemble averaging
using Ni = 1000 realization produces the spectral density in Figure 11.2(b). As the number
of samples per realization is increased to N = 2000, we obtain the density in 11.2(c). Finally,
averaging across a much larger number of realizations produces the PSD in Figure 11.2(d).
Among the three densities, this estimate can be expected to be the closest to the theoretical
deﬁnition (11.2).
0
0.5
1
1.5
2
2.5
3
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
5.5
Frequency (rad/sec)
PSD
(a) Finite-length realization N = 500
0
0.5
1
1.5
2
2.5
3
0.8
0.85
0.9
0.95
1
1.05
1.1
1.15
1.2
Frequency (rad/sec)
PSD
(b) Ensemble average Ni = 1000; N = 500
0
0.5
1
1.5
2
2.5
3
0.8
0.85
0.9
0.95
1
1.05
1.1
1.15
1.2
Frequency (rad/sec)
PSD
(c) Ensemble average Ni = 1000; N = 2000
0
0.5
1
1.5
2
2.5
3
0.8
0.85
0.9
0.95
1
1.05
1.1
1.15
1.2
Frequency (rad/sec)
PSD
(d) Ensemble average Ni = 10000; N = 10000
FIGURE 11.2
PSD of WN process generated by ensemble average.
Observe the vast diﬀerence in the spectral density obtained from a single realization in
Figure 11.2(a) and the ensemble-averaged densities in Figures 11.2(b), 11.2(c) and 11.2(d).
On the other hand, increasing the sample size from N = 500 to N = 2000 does not have any
signiﬁcant impact on the range (or ﬂuctuations) in PSD estimates (see discussion below).
The PSD in Figure 11.2(d) appears dense because of the ﬁne spacing in frequency △f2 =
1/10000.
Two interesting observations can be made from the densities in Figures 11.2(b), 11.2(c) and 11.2(d).

274
Principles of System Identiﬁcation: Theory and Practice
Listing 11.1
MATLAB code for Example 11.1
% Data parameters
Nsamp = 2000; Nreal = 1000;
vk_psd = zeros(Nsamp/2,1);
% Compute PSD for all realizations
for i = 1:Nreal,
vki = randn(Nsamp ,1);
vkif = fft(vki);
vki_psd = abs(vkif(1:end/2)).^2/Nsamp;
vk_psd = vk_psd + vki_psd;
end
vk_psd = vk_psd/Nreal;
% Plot the PSD
fvec = (0:1/Nsamp:0.5-1/Nsamp)’;
figure; plot(fvec*2*pi,vk_psd);
i. The ﬁrst interesting observation is that the PSD has more or less uniform contributions from all
frequencies. It turns out that this is a fact for any WN process in general. We shall establish this
fact shortly with the help of the W-K theorem. This result is of immense consequence in the anal-
ysis of stochastic processes. Indeed the WN process acquires its name due to this characteristic.
ii. The second one, which has a strong bearing on the estimation of PSD, is that an increase in the
samples does not have any discernible impact on the “ﬂuctuations” or the smoothness of the PSD.
This is not surprising since at each frequency, the averaging is across realizations but not along
samples. However, an increase in the number of realizations reduces the range of PSD estimate
at each frequency considerably. These observations constitute the basic idea in non-parametric
methods for estimating spectral densities (see Chapter 16).
Deﬁnition (11.2) is used widely in identiﬁcation and signal analysis. Knowing the theoretical
support for this deﬁnition is essential for a correct interpretation. We turn to W-K theorem for this
purpose.
11.2.2
PSD FROM AUTO-COVARIANCE FUNCTION
The ﬁrst result of interest is that the PSD in (11.2) is the Fourier transform of the auto-covariance
function. Essentially we are referring to the stochastic version of (10.49), the Wiener-Khinchin
theorem for deterministic processes. In establishing this relationship, we will also discover the con-
ditions under which (11.2) is valid.
The derivation largely follows the development in Priestley (1981). It is built around two facts
(i) |V (ω)|2 = V (ω)V⋆(−ω) and (ii) the product of Fourier transforms of two signals is equivalent
to their convolution in time.
Theorem 11.1
Let v[k] be a zero-mean discrete-time stochastic process with an auto-covariance function σvv[l]
and power spectral density γvv(ω) as deﬁned in (11.2).

Spectral Representations of Random Processes
275
Then, γvv(ω) and σvv[l] form a Fourier pair,
γvv(ω) = 1
2π
∞
X
l=−∞
σvv[l]e−jωl;
σvv[l] =
Z π
−π
γ(ω)ejωl dω
(11.4)
Proof. The squared Fourier transform of the ﬁnite-length record {v[k]}N−1
k=0 can be written as
|VN (ω)|2 = VN (ω)VN (−ω) =
N−1
X
n=0
N−1
X
m=0
v[n]v[m]e−jω(n−m)
(11.5)
Taking expectation on both sides
E

|VN (ω)|2
= E *
,
N−1
X
n=0
N−1
X
m=0
v[n]v[m]e−jω(n−m)+
-
=
N−1
X
n=0
N−1
X
m=0
σvv[n −m]e−jω(n−m)
(11.6)
Introduce l = n −m and observe that the summand repeats N −|l| times for a given value of n.
Further, (−N −1) ≤l ≤(N −1).
Thus, the double summation (11.6) can be replaced with a single summation over l to obtain
1
2πN E

|VN (ω)|2
=
1
2πN
N−1
X
l=−(N−1)
(N −|l|)σvv[l]e−jωl
= 1
2π
N−1
X
l=−(N−1)
 
1 −|l|
N
!
σvv[l]e−jωl
(11.7)
Introduce
f N[l] =

1 −|l|/N,
|l| ≤N −1,
0,
|l| > N −1
to write the PSD in (11.2) as
γvv(ω) = lim
N→∞
1
2π
N−1
X
l=−(N−1)
f N[l]σvv[l]e−jωl = 1
2π
N−1
X
l=−(N−1)
lim
N→∞f N[l]σvv[l]e−jωl
(11.8)
Note that f [l] →1 in the limit as N →∞. Therefore, for the limit on the RHS to exist, σvv[l]
should decay suﬃciently fast.
Formally, for the summation to converge, we require

N−1
X
l=−(N−1)
f N[l]σvv[l]e−jωl

≤
N−1
X
l=−(N−1)
f N[l]|σvv[l]|
≤
N−1
X
l=−(N−1)
|σvv[l]| < ∞
since f N[l] ≤1∀N

276
Principles of System Identiﬁcation: Theory and Practice
Thus, the power spectral density is the Fourier transform of the ACVF
γvv(ω) = 1
2π
l=∞
X
l=−∞
σvv[l]e−jωl
(11.9)
provided
∞
X
l=−∞
|σvv[l]| < ∞
(11.10)
The second result simply follows from the inverse Fourier transform
σvv[l] =
Z π
−π
γ(ω)ejωl dω
(11.11)
□
The requirement (11.10) is not surprising; it is indeed the condition for the DTFT of σvv[l] to
exist!
Theorem 11.1 along with the requirement (11.10) constitutes the popular spectral representation
theorem (of the ACVF). This is also known as the Wiener-Khinchin theorem, as succinctly stated
below.
Theorem 11.2
Any stationary process with ACVF σvv[l] satisfying
∞
X
l=−∞
|σvv[l]| < ∞
(absolutely summable)
has the spectral representation
σvv[l] =
Z π
−π
γvv(ω)ejωl dω
(11.12)
where γxx is the spectral density and has the representation
γvv(ω) = 1
2π
∞
X
l=−∞
σvv[l]e−jωl
−π ≤ω < π
(11.13)
Proof. See proof for Theorem 11.1.
□
Note that by dividing both sides of (11.12) with σ2
v gives
ρvv[l] =
Z π
−π
γvv(ω)
σ2v
ejωl dω
(11.14)
The factor γvv(ω) is known as the normalized spectral density. We shall shortly come across a
generalization of the result in (11.14) in the form of Theorem 11.4, also known as the Wiener-
Khinchin-Wold theorem.

Spectral Representations of Random Processes
277
A useful fallout of Theorems 11.1 and 11.2 is that the area under the spectral density is the
variance of the random signal
σ2
v = σvv[0] =
Z π
−π
γ(ω) dω
(11.15)
Alternatively, (11.15) oﬀers a spectral decomposition of the variance. For stationary processes σ2 <
∞, therefore the spectral density deﬁned in (11.2) also satisﬁes the bounded integral requirement.
The PSD in (11.2) exists only when the ACVF of a random process is absolutely convergent,
a condition satisﬁed by a large class of stationary random processes. On the same note, not all
stationary processes satisfy (11.10). The classic case is that of a random periodic process, which
appears in several ﬁelds of interest.
11.2.2.1
Random Periodic Process
On a ﬁrst thought, randomness and periodicity appear to be contradictory terms since the latter
means perfect predictability. The deﬁnition of a random periodic process is, however, not exactly
along the lines of (10.2) for deterministic processes, but rather in a mean square sense.
Deﬁnition 11.3. A discrete-time (wide-sense) stationary process {v[k]} is said to be periodic with
period Np if
E((v[k + Np] −v[k])2) = 0
(11.16)
or equivalently,
a. σvv[l + Np] = σvv[l], ∀l ∈Z
(Periodic ACVF)
b. σvv[Np] = σvv[0]
c. Pr(v[k + Np] = v[k]) = 1 ∀k ∈Z
The proof of equivalence of (11.16) with the three alternative conditions is left as an exercise to
the reader (see Exercise E11.4).
Remarks:
It is instructive to connect the periodicity of ACVF of a random process with an identical property
of a periodic deterministic process in (10.12). Thus, once again the ACVF uniﬁes the framework of determin-
istic and stochastic signals.
There exist several practical examples of random periodic processes. Arrival of trains at a railway
station on a daily schedule can be termed as periodic by modeling the deviations from the scheduled
times as randomness in phase. Oscillations in the controlled variables of poorly performing loops
can be modeled as the output of a random periodic process.
Harmonic process
A widely used model of a random periodic process is that of a harmonic process.
Deﬁnition 11.4. The linear weighted sum of cosines
v[k] =
M
X
i=1
Ai cos(ωik + φi)
(11.17)
where Ai, ωi are constants (deterministic quantities) and {φi}M
i=1 are independent random variables
with φi ∈U[−π,π], is known as the harmonic process.

278
Principles of System Identiﬁcation: Theory and Practice
Observe that (11.17) may also be written as
v[k] =
M
X
i=1
(A′
i cos ωik + B′
i sin ωik)
(11.18)
where A′
i = Ai cos φi, B′
i = Ai sin φi are random, zero-mean, normally distributed, uncorrelated
variables (see Exercise)2. That is,
E(A′
i) = 0 = E(B′
i);
E(A′
iB′
i) = 0;
(11.19)
E(A
′2
i ) = σ2
i = E(B
′2
i )
(11.20)
It is easy to show that the process in (11.17) under the speciﬁed assumptions on phase is wide-
sense stationary and random periodic.
Firstly, from (11.18) and (11.20) it follows that the harmonic process is mean stationary
E(v[k]) = E(
M
X
i=1
(A′
i cos ωik + B′
i sin ωik)) =
M
X
i=1
E(A′
i) cos ωik + E(B′
i) sin ωik = 0
Secondly, taking note of (11.20) the ACVF of v[k] contains only the squared terms,
σvv[l] = E(v[k]v[k −l]) =
M
X
i=1
E(A′2
i ) cos ωk cos ω(k −l) + E(B′2
i ) sin ωk sin ω(k −l)
=
M
X
i=1
σ2
i cos ωil
(11.21)
Thus, the harmonic process is stationary and periodic. The variance of v[k] is the aggregate of
the variance of the individual components.
σ2
v =
M
X
i=1
σ2
i
(11.22)
Observe the similarity of (11.22) with (11.15) for the aperiodic case.
Returning to the main point of our discussion, the ACVF of a harmonic process is not absolutely
convergent since it never decays to zero at large lags. In general, this is true for any random peri-
odic process by virtue of Deﬁnition 11.3. As in the case of deterministic periodic signals, random
periodic signals therefore do not possess a density function. Nevertheless, they possess a spectral
distribution function, deﬁned along similar lines as the probability distribution function,
Γvv(ω) = Cumulative power in v[k] over (−π,ω)
(11.23)
Drawing upon the analogy of probability distribution further, a spectral distribution function Γ(ω)
that suits both class of signals, i.e., periodic as well as aperiodic stationary signals can be con-
structed.
For the latter class, a density function exists (as already established)
Aperiodic, stationary:
Γvv(ω) =
Z ω
−π
γvv(ω) dω ;
or, γ(ω) = dΓ(ω)
dω
(11.24)
For periodic signals, the spectral distribution function has a step-like form with spikes at ωi similar
to the probability distribution function for discrete-valued random variables.
2It is possible to relax the deterministic assumption on Ai by letting A2
i to be χ2 distributed variable with 2-degrees of
freedom.

Spectral Representations of Random Processes
279
Spectral representation of general random processes
A general version of Theorem 11.1 that takes into account both stationary non-periodic and periodic
processes due to Wiener, Khinchin and later Wold is given below. The result is based on another
closely related theorem due to Herglotz and Bochner who established the spectral equivalent of
Theorem 8.1 concerning the non-negative deﬁniteness of the ACVF for a stationary process. The
discrete-time case is presented. For the continuous-time stochastic process, the reader is referred to
Brockwell and Davis (1991) and Priestley (1981).
Theorem 11.3: Bochner and Herglotz
A complex-valued sequence ρ[l], l ∈Z is non-negative deﬁnite if and only if it can be expressed
as a Fourier-Stieltjes integral
ρ[l] =
Z π
−π
ejωl dF(ω)
∀l ∈Z
(11.25)
where F(ω) is a distribution function on the interval (−π,π), i.e., F(ω) is right-continuous, non-
decreasing, bounded on [−π,π] and F(−π) = 0, F(π) = 1.
Proof. See Brockwell and Davis (1991).
□
Combining the non-negative deﬁniteness requirement of the ACVF and the above theorem, we
have the well-known Wiener-Khinchin theorem.
Theorem 11.4: Khintchine (1934), Wiener (1930) and Wold (1938)
A discrete sequence ρ[l] is the auto-correlation function of a discrete-time stochastic process v[k]
if and only if there exists a function F(ω), such that
ρ[l] =
Z π
−π
ejωldF(ω)
l ∈Z
(11.26)
where F(ω) has the properties of a (normalized) distribution function on the interval (−π,π), i.e.,
F(ω) is right-continuous, non-decreasing, bounded on [−π,π] and F(−π) = 0, F(π) = 1.
Proof. Proof is found in standard texts. See Brockwell and Davis (1991) and Priestley (1981).
□
The function F(.) in (11.26) is called the normalized spectral distribution function. Comparing
with (11.14),
F(ω) = Γ(ω)/σ2
such that
F(π) = 1
(11.27)
Remarks:
1. When F(ω) (or Γ(ω)) is continuous, dF(ω) = f (ω)dω, where f (ω) is the (normalized) spectral density
function exists, which is obtained by recalling (11.24)
γvv(ω) = dΓ(ω)
dω
= σ2 dF(ω)
dω
=⇒
f (ω) = γ(ω)
σ2
(11.28)

280
Principles of System Identiﬁcation: Theory and Practice
Consequently
Z π
−π
γ(ω)
σ2
dω = 1
(11.29)
giving us a normalized version of (11.15).
2. Further, under the above conditions, i.e., continuous F(ω), it is easy to recover (11.12) and (11.13) of
Theorem 11.2) by substituting dF(ω) = f (ω)dω = σ2vγ(ω) dω and recognizing that (σvv[l],γvv(ω))
form a Fourier pair.
The results above provide an alternative means of determining the conditions under which a given
sequence qualiﬁes to be the ACVF of an aperiodic stationary process in a much simpler manner than
what Theorem 8.1 provides. The idea is to compute the Fourier transform of the given sequence (if
it exists) and examine if the resulting quantity has the properties of a density function, as listed in
Deﬁnition 11.2. This point is elucidated by a revisit of Example 8.3.
Example 11.2: Non-Negative Deﬁniteness of ACVF
The sequence
f [l] =

1,
l = 0
c,
l = ±1
0,
otherwise
is the ACF of a stationary process if and only if its Fourier transform
γ(ω) =
∞
X
l=−∞
f [l]e−jωl = 1 + 2c cos ω
(11.30)
is non-negative for all ω. The requirement is that
|c| ≤1/2
(11.31)
which is identical to the result obtained in Example 8.3 by imposing the requirement in
Theorem 8.1.
A running summary of the discussion thus far is given below.
1. The ACF σvv[l] of every stationary process possesses a spectral distribution function Γ(ω).
2. Random stationary (aperiodic) processes are characterized by continuous Γ(ω); hence, a spectral
density function γ(ω) can be used to describe such processes.
3. Harmonic processes (random periodic processes) are characterized by periodic ACVFs and spec-
tra that are deﬁned only at discrete frequencies; consequently, {ωr } is a step-like Γ(ω) and no
spectral density function exists.
4. Non-negative functions necessarily have a corresponding distribution function in the Fourier
domain, related through a Fourier-Stieltjes integral.
5. It is also useful to observe a strong analogy between the existence of spectral density and dis-
tributions for aperiodic and harmonic stationary processes with that of probability density and
distribution functions for random variables. Both discrete and continuous RVs possess probabil-
ity distributions, whereas it is only the latter that possess probability densities.

Spectral Representations of Random Processes
281
11.2.3
WIENER REPRESENTATIONS AND PSD
As a culmination of the ideas presented in §11.2 and §11.2.2, we shall brieﬂy review the generalized
harmonic analysis ideas due to Wiener (1930). While Theorems 11.2 and 11.4 oﬀered spectral
representations of the ACVF, Wiener’s GHA presents spectral representations of the process. It is
pointed out, however, that this is largely of theoretical interest. The results presented in Sections
11.2.1 and 11.2.2 have the maximum relevance in practice.
GHA is essentially built on two concepts: (i) the Fourier-Stieltjes transform and (ii) the repre-
sentation of random periodic process in (11.18). Wiener’s ideas, however, stemmed from his eﬀorts
to provide a generalized representation of signals in Fourier domain to handle (continuous-time)
signals that are neither periodic nor that decay in time (e.g. cos(
√
2k)).
The main idea is to write a Fourier-Stieltjes transform for the ith realization,
v(i)[k] =
Z ∞
−∞
ejωk dF(i)(ω)
(11.32)
Wiener showed that for random signals, dF(i)(ω) is neither a step function nor is it diﬀerentiable
(since v(i)(k) is not absolutely integrable), but rather
dF(i)(ω) = O(
√
dω)
so that the order of magnitude of the increment of F(i)(ω) over for an inﬁnitesimal increase in
frequency dω is much larger than dω.
However, the quantity |dF(i)(ω)|2 increments by dω (in a similar way as |X(ω)|2 dω for deter-
ministic energy signals) so that
h(i)(ω) = |dF(i)(ω)|2/dω
can be thought of as a spectral density for that realization. The spectral density of the random process
is then the ensemble average of h(i)(ω),
γxx(ω) = E(h(i)(ω))
The formal result on the spectral representation of a discrete-time process is given below without
proof (see Priestley (1981) for full details).
Theorem 11.5: Spectral Representation of Discrete-Time Stochastic Processes
Given a discrete-time zero-mean stochastic process {v[k]}, there exists an orthogonal process,
{Z(ω)}, such that,
v[k] =
Z π
−π
ejωk dZ(ω)
(11.33)
with the integral deﬁned in the mean-square sense. The orthogonal process dZ(ω) has the following
properties
(i) E(dZ(ω)) = 0
∀ω
(ii) E(|dZ(ω)|2) = dΓ(ω) ∀ω
(iii) E(dZ⋆(ω),dZ(ω′)) = cov(dZ(ω),dZ(ω′)) = 0
∀ω = ω′

282
Principles of System Identiﬁcation: Theory and Practice
Proof. For proof, see Priestley (1981).
□
Wiener’s GHA is essentially the extension of (10.25) to the stochastic case; thus, the integral in
(11.33) is a stochastic integral (see Priestley (1981) for formal deﬁnition).
The variable dZ(ω) has a similar interpretation as of that encountered in the Fourier-Steiltjes
transform (10.25) in the sense that the derivative of dZ(ω)/dω is the Fourier transform of v[k] (al-
ternatively, Z(ω) can be thought of as “integral” of the Fourier transform). A loose interpretation is
that for a random periodic process, {dZ(ω)} is similar to the random-valued coeﬃcients in (11.18).
However, the quantity of interest is not dZ(ω) so much as |dZ(ω)|2 is, which provides the
spectral distribution function. In fact, from Theorems 11.1 and 11.2,
E(|dZ(ω)|2) = σ2
vdF(ω) = Γvv(ω)
(11.34)
Starting with the GHA, it is possible to arrive at the spectral representation theorem for the ACVF
(Theorem 11.9) but we omit that derivation here. The reader is referred to Priestley (1981, Chapter
4) for related details and a good exposition of this topic.
In closing, it is interesting to note the similarity of Equations (11.9) and (11.33), albeit with
one striking diﬀerence. The variable dF(ω) is a deterministic function whereas dZ(ω) is a random
variable. Thus, (11.9) is a regular Lebesgue integral, whereas (11.33) is a stochastic integral.
In the following section, we show how the spectral representation (of ACVF) Theorem 11.2, i.e.,
the Wiener-Khinchin relations, are useful in developing expressions for spectral representations of
stationary (ARMA) processes described in Chapter 9.
11.3
SPECTRAL CHARACTERISTICS OF STANDARD PROCESSES
The main tool for computing the spectral densities of the processes below is the relation in (11.9).
We begin by constructing the frequency-domain description of the white-noise process, the central
building block of time-series models.
11.3.1
WHITE NOISE PROCESS
Recalling that the ACVF of WN is an impulse centered at lag l = 0, we obtain an alternative
description of the WN process in the spectral domain.
Deﬁnition 11.5. The WN process is a stationary process with a constant p.s.d.
γee(ω) = 1
2π
∞
X
l=−∞
σee[l]e−jωl = σ2
e
2π , −π ≤ω ≤π
(11.35)
0
!
σ2
e
2π
γ(ω)
ω
FIGURE 11.3
Power spectral density of white noise process.

Spectral Representations of Random Processes
283
The normalized spectral density 2πγ(ω)/σ2
e is unity at all ω.
The average power of a white-noise process contains uniform contributions from all of its
frequency components.
By analogy white light contains all colors uniformly, from where the process derives its name.
The ﬂatness of spectral density is used as a test for whiteness of a process. For any other non-white,
i.e., correlated or colored process, the spectral density is non-ﬂat.
It is worthwhile reiterating a point made in Section 8.3. The deﬁnition above does not constrain
the distribution function of the white noise to be Gaussian. Therefore, one can think of Gaussian
WN, Uniform WN and so on.
11.3.2
SPECTRAL DENSITY OF ARMA PROCESS: COLORED NOISE
In the following examples, spectral densities of MA(1) and AR(1) processes are studied.
Example 11.3: Spectral Density of an MA(1) Process
Compute the spectral density of an MA(1) process:
v[k] = e[k] + 0.6e[k −1]
where e[k] ∼N (0,1), i.e., the GWN process.
Solution: The ACVF of the given process using the tools of Chapter 8 is
σxx[l] =

1.36
l = 0
0.6
|l| = 1
0
|l| ≥2
Using (11.9), the spectral density and the distribution function are
γ(ω) = 1
2π
∞
X
l=−∞
σ[l]e−jωl = 1
2π (1.36 + 2(0.6) cos ω)
∀ω ∈[−π,π]
Γ(ω) =
Z ω
−π
γ(ω) dω = 1
2π (1.36(ω + π) + 1.2 sin ω)
∀ω ∈[−π,π]
Figure 11.4 shows the plots of spectral density and distribution for the given process.
The spectral density has a non-ﬂat shape with larger concentration in the lower frequency
range. The shape and value depends on the coeﬃcients of the MA(1) process. A sign reversal
of c1 would cause the spectral density to have larger values in the higher-frequency range
(closer to π).
Observe that the spectral density is symmetric in ω. In practice, therefore it suﬃces to
examine over ω ∈[0,π].
For a general MA(M) process, the spectral density can be computed by ﬁrst computing the ACVF
using the auto-covariance generating function (9.18) followed by the use of the W-K theorem. A
simpler method using the transfer function representation is presented shortly.
Example 11.4: PSD of an AR(1) Process
Compute the spectral density of an AR(1) process
v[k] −0.5v[k −1] = e[k]

284
Principles of System Identiﬁcation: Theory and Practice
−4
−3
−2
−1
0
1
2
3
4
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
Frequency (rad/sec)
PSD
(a) Power spectral density
−4
−3
−2
−1
0
1
2
3
4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
1.4
Frequency (rad/sec)
Power spectral distribution
(b) Spectral distribution
FIGURE 11.4
Power spectral density and distribution of the MA(1) process in Example 11.3.
where e[k] ∼N (0,1)
Solution: From Chapter 8, the ACVF of the given AR(1) process is
σxx[l] = 4
3 (0.5)|l | ∀l
Once again using the W-K theorem, we obtain
γ(ω) = 1
2π
∞
X
l=−∞
σ[l]e−jωl = 1
2π
 
1
1.25 −cos ω
!
∀ω ∈[−π,π]
The spectral density and distribution functions are shown in Figures 11.5(a) and 11.5(b),
,respectively. Once again, as in the case of MA(1) process, the spectral density is non-uniform
and shows that the power in v[k] is made up of larger contributions from lower frequencies.
−4
−3
−2
−1
0
1
2
3
4
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Frequency (rad/sec)
PSD
(a) Power spectral density
−4
−3
−2
−1
0
1
2
3
4
0
1
2
3
4
5
6
7
8
9
Frequency (rad/sec)
Power spectral distribution
(b) Spectral distribution
FIGURE 11.5
Power spectral density and distribution of the AR(1) process in Example 11.4.
In both examples, the contributions of each frequency component to the overall power varies
with the frequency, unlike the case of “white” noise. Correlated processes therefore are given the
name colored noise since a color is essentially produced by light waves in a frequency band of the
visible spectrum. From this viewpoint, a random process acquires a ﬁltering interpretation, which is
of course not surprising.

Spectral Representations of Random Processes
285
Computing power spectral density from ACVF can become challenging for higher-order AR
or even a lower-order ARMA process. Fortunately, it is possible to compute the spectral density
directly from the transfer function without having to explicitly compute the ACVF as shown below.
This method also forms the basis for parametric spectral estimation (see Section 16.5.7).
Power spectral density from transfer function
The main result is as follows. Given the transfer function of an ARMA process, v[k] = H(q−1)e[k],
its spectral density is given by
γvv(ω) = |H(e−jω)|2γee(ω) = |H(e−jω)|2 σ2
e
2π
(11.36)
where
H(e−jω) = DTFT(h[k]) =
∞
X
k=−∞
h[k]e−jωk
The result is easy to establish by starting with the general deﬁnition of a linear random process
v[k] =
∞
X
m=−∞
h[m]e[k −m]
and observing that
=⇒σvv[l] =
∞
X
m=−∞
h[m]h[l −m]σ2
ee
Taking DTFT on both sides and using the convolution-product property of the Fourier transform we
obtain equation (11.36).
The expression for spectral density in (11.36) is a re-statement of the expression (10.43), for
linear stochastic processes. Drawing parallels, we can thus treat h[.] as the impulse response of the
random process and H(ejω) as the frequency response function of the process.
Furthermore, for a linear stochastic process that has an ARMA representation, the power spectral
density of a linear random process is proportional to the squared magnitude of its FRF.
The following theorem formalizes the foregoing results.
Theorem 11.6
Let v[k] be an ARMA(P, M) process (not necessary causal or invertible) described by
D(q−1)v[k] = C(q−1)e[k],
e[k] ∼WN(0,σ2
e)
(11.37)
where D(z−1) = 1 + d1z−1 + · · · + dPz−P and C(z−1) = 1 + c1z−1 + · · · + cM z−M have no common
zeros and D(z−1) has no zeros on the unit circle |z| = 1. Then, v[k] has the spectral density
γvv(ω) = σ2
e
2π
|C(e−jω)|2
|D(e−jω)|2 ,
−π ≤ω ≤π
(11.38)
Proof. Develop a stationary solution of the ARMA process in the form of (9.10a) with coeﬃcients
satisfying (9.10b). Subsequently, follow the proof for (11.36).
□

286
Principles of System Identiﬁcation: Theory and Practice
The example below demonstrates the use of (11.36) (or (11.38)) in computing the p.s.d. of an
ARMA(1,1) process.
Example 11.5: PSD of an ARMA(1,1)
Compute the power spectral density of an ARMA (1,1) process:
H(q−1) = 1 + 0.7q−1
1 −0.4q−1
driven by a zero-mean Gaussian white-noise process with σ2e = 1.
Solution: Using (11.36), the power spectral density is
γ(ω) = |H(ejω)|2 σ2e
2π = 1
2π
 1.49 + 1.4 cos ω
1.16 −0.8 cos ω
!
Figure 11.6 carries the plot of power spectral density over the positive frequency range. This
ARMA process has the characteristics of a low-pass ﬁlter.
0
0.5
1
1.5
2
2.5
3
3.5
0
0.2
0.4
0.6
0.8
1
1.2
1.4
Frequency (rad/sec)
PSD
FIGURE 11.6
Power spectral density of the ARMA(1,1) process in Example 11.5.
Remarks:
1. In the examples discussed until now, the power spectral density does not appear to provide any evidence
of the order of the auto-regressive or the moving average aspects of the transfer function in contrast to the
ACF or PACF. In general, this is true as well.
2. Notwithstanding the remark above, both ACVF and spectral density oﬀer means of testing the whiteness of
a series.
3. The prime use of spectral density is however in detection of periodicities, transfer function and delay esti-
mation. In this respect, it is superior to its time-domain counterpart (covariance functions).
Listing 11.2
MATLAB code for Figures 11.4, 11.5 and 11.6
% Frequency vector
deltaf = 1/1000; fvec = (-0.5:deltaf:0.5-deltaf);
% PSD of MA(1)
psi_ma1 = inline(’abs(1␣+␣0.6*exp(-sqrt(-1)*w)).^2’,’w’);

Spectral Representations of Random Processes
287
% Plot PSD
plot(2*pi*fvec,psi_ma1(2*pi*fvec)/(2*pi))
% Spectral distribution function
Psi_ma1 = inline(’1.36*(w+pi)␣+␣1.2*sin(w)’,’w’);
% Plot spectral distribution
figure; plot(2*pi*fvec,Psi_ma1(2*pi*fvec)/(2*pi))
% PSD of AR(1) process
psi_ar1 = inline(’abs(1./(1␣-␣0.5*exp(-sqrt(-1)*w))).^2’,’w’);
% Plot the PSD
figure; plot(2*pi*fvec2,psi_ar1(2*pi*fvec2)/(2*pi))
% Spectral distribution and its plot
psd_ar1 = psi_ar1(2*pi*fvec2)/(2*pi);
figure; plot(2*pi*fvec2,cumsum(psd_ar1)*2*pi/1000)
% PSD of ARMA(1,1) process
Hq = tf([1 0.7],[1 -0.4],1);
fvec = (0:deltaf:0.5-deltaf)’;
magHq = squeeze(bode(Hq,2*pi*fvec));
% Plot the PSD
figure; plot(2*pi*fvec,magHq.^2/(2*pi));
A natural extension of the concept of the power spectral density is the cross-spectral density anal-
ogous to the extension of auto-covariance function to the cross-covariance function. Together with
the cross-spectral density, the power spectral density is used in estimation of frequency response
function, delay estimation and periodicity detection.
11.4
CROSS-SPECTRAL DENSITY AND COHERENCE
The cross-power spectral density (CPSD) between two stochastic signals v1[k] and v2[k] is essen-
tially an extension of (16.63) and (11.9) to the stochastic case.
Deﬁnition 1:
γv2v1[ω] = ¯E(V⋆
2,N (ω)V⋆
1,N (ω)) = lim
N→∞E *
,
V2,N (ω)V⋆
1,N (ω)
2πN
+
-
(11.39a)
The deﬁnition in (11.39a) is deﬁned directly in the ensemble space. It is a generalization of the PSD
(11.2) to the bivariate case.
Deﬁnition 2:
γv2v1(ω) = 1
2π DTFT(σv2v1[l]) = 1
2π
∞
X
l=−∞
σv2v1[l]e−jωl
(11.39b)
Just as it was remarked in §11.1 (in the context of auto-spectral densities) (11.39b) is more of a
theorem rather than a deﬁnition since it follows from Wiener-Khinchin theorem. It is, in fact, a
generalization of Theorem 11.4.
Deﬁnition 3:
γv2v1(ω) = E(dZv2(ω)dZ⋆
v1(ω))
(11.39c)
where dZvi (ω) is the spectral representation of v1[k] in Wiener’s GHA sense and the star denoting
complex conjugate as usual. Computing this expectation involves stochastic integrals, which falls
outside the scope of this text. It is interesting to note that (11.39c) is the stochastic version of the
deﬁnition in (10.39) for deterministic signals.

288
Principles of System Identiﬁcation: Theory and Practice
Among the three deﬁnitions above, (11.39a) and (11.39b) are the ones that are useful in practice,
while (11.39c) is largely amenable to theoretical analysis.
As in the case of auto-spectral density, for the CPSD to exist, the cross-covariance function
should be absolutely convergent,
∞
X
l=−∞
|σv2v1[l]| < ∞
(11.40)
CPSD from transfer function representation
In a manner similar to the computation of power spectral density from the transfer function of the
stochastic process, the cross-spectral density between two stationary signals can be computed as
γv2v1(ω) = H(e−jω)γv1v1(ω)
(11.41)
where H(q−1) is the transfer function between v1 and v2 considering them as input and output
signals respectively, i.e.,
v2[k] = H(q−1)v1(q−1)
(11.42)
Properties of cross-spectral density
The cross-spectral density has properties that are, however, distinct from those of the auto-spectral
density.
1. It is complex-valued unlike the power spectral density. Further,
γv2v1(ω) = γ⋆
v1v2(ω) = γv1v2(−ω)
(11.43)
resembling the behavior of cross-covariance function.
2. The magnitude, |γv2v1(ω)| gives the strength of common power between v2 and v1 at that fre-
quency.
3. The angle, φv2v1(ω) =≜∠γv2v1(ω), also known as the phase, is useful in estimating delays in
the system.
4. When v1 and v2 are uncorrelated at all lags, i.e., σv2v1[l] = 0, ∀l, the cross-spectral density
vanishes to zero, γyu(ω) = 0, ∀ω. Thus,
γyu(ω) = 0, ∀ω
⇐⇒
No linear relationship between y and u
(11.44)
We illustrate two important applications of the cross-spectral density below. The ﬁrst example is
a revisit of Example 8.4 where we showed how to estimate delay by locating the peak in the CCF.
Example 11.6: Estimation of Delay Using Cross-Spectral Density
Recall the process (8.21)
y[k] = Au[k −D] + v[k]
((8.21) revisited)
where u[k] is the input (with random signal-like properties) to the process and v[k] is the
measurement noise possessing stationary random process characteristics. The objective is to
estimate the time-delay D.
Under open-loop conditions, i.e., when the input and disturbance v[k] are uncorrelated,
from (8.22) we know
σyu[l] = Aσuu[l −D]

Spectral Representations of Random Processes
289
The cross-spectral density using (11.39b) is
γyu(ω) =
∞
X
l=−∞
σyu[l]e−jωl =
∞
X
l=−∞
Aσuu[l −D]e−jωl
= Ae−jωD
∞
X
l=−∞
Aσuu[l′]e−jωl′
= Ae−jωDγuu(ω)
(11.45)
Thus,
|γyu(ω)| = Aγuu(ω);
φyu(ω) = ∠γyu(ω) = −Dω
(11.46)
The phase of the cross-spectrum is therefore a straight line with slope equal to −D. In practice,
the slope of a linear ﬁt to the phase provides us with an estimate of the magnitude of delay.
0
0.5
1
1.5
2
2.5
3
3.5
−14
−12
−10
−8
−6
−4
−2
0
Frequency (rad/sample)
Phase
 
 
 
y = − 4*x − 0.0067
Estimated phase
Linear fit
(a) White-noise input
0
0.5
1
1.5
2
2.5
3
3.5
−16
−14
−12
−10
−8
−6
−4
−2
0
2
Frequency (rad/sample)
Phase
 
 
 
y = − 4*x + 0.031
Estimated phase
Linear fit
(b) Colored noise input
FIGURE 11.7
Time-delay estimation from the phase spectrum.
Figures 11.7(a) and 11.7(b) illustrate the idea on a system with A = 2 and D = 4 when a
Gaussian white-noise u[k] = e[k] ∼N (0,1) and colored noise u[k] = −0.5u[k −1]+e[k] are used
as inputs, respectively. The slope of the linear ﬁts in both cases correctly point to the actual
delay in the system. Phase estimates were obtained by ﬁrst estimating the cross-spectral
density using what are known as smoothed estimators (see §16.6) followed by computing the
argument of the result.
In both cases, v[k] was chosen as white noise (uncorrelated with the input) with variance
adjusted such that SNR is set to 4.
Listing 11.3
MATLAB code for Example 11.6
% Generate white-noise input
N = 1000; D = 4;
uk_in = randn(N+D,1);
% Generate output
yk = 2*uk_in(1:N,1) + randn(N,1);
uk = uk_in(D+1:end,1);
% FFT of input and output
ukf = fft(uk); ykf = fft(yk);
% Estimating cross-spectral density
[gamma_yu ,w] = cpsd(yk,uk);
% Plot the phase sepctrum

290
Principles of System Identiﬁcation: Theory and Practice
fvec = (0:1/N:0.5-1/N);
figure; plot(fvec*2*pi,phase(gamma_yu));
% Filtered white-noise as input: AR(1)
uk_in2 = filter(1,[1 -0.5],uk_in);
% Generate output
yk2 = 2*uk_in2(1:N,1) + randn(N,1);
uk2 = uk_in2(D+1:end,1);
% Cross-spectral density
[gamma_yu2 ,w2] = cpsd(yk2,uk2)
% Plot the phase spectrum
figure; plot(w2,phase(gamma_yu2));
The phase expressions above can also be derived, and in a simpler manner, using the relation in
(11.41). A generalization of the foregoing example is obtained by letting the delay be a function of
the frequency. The derivative of the phase
D(ω) = dφyu(ω)
dω
then acquires the interpretation of a “group delay” or an “envelope delay” (Bendat and Piersol,
2010; Priestley, 1981).
When the process contains dynamics in addition to pure delays, the phase consists of contribu-
tions from both dynamics and delay. For continuous-time systems, the contributions of the dynamics
to the phase saturates at high-frequencies with only the eﬀects of delay prevailing. However, this
is not necessarily true for discrete-time systems. An eﬃcient time-delay estimation method can be
devised even under these conditions without the explicit knowledge of time-constants or dynamics.
Section 22.5.3 elucidates this idea in the context of delay estimation.
The second example illustrates the use of cross-spectral density in estimation of frequency re-
sponse functions.
Example 11.7: Estimation of FRF
The output measurement of an LTI system can be represented as
y[k] = G(q−1)u[k] + v[k]
(11.47)
where u[k] and v[k] are the input and disturbance, respectively.
Given input-output data, the frequency response function of the deterministic part of the
process can be estimated using the spectral densities as follows.
From (11.41),
γyu(ω) = G(e−jω)γuu(ω)
=⇒G⋆(e−jω) = γyu(ω)
γuu(ω)
(11.48)
assuming that input and disturbance are uncorrelated at all lags.
Thus, an estimate of the FRF can be obtained by replacing the cross-spectral and auto-
spectral densities with their respective estimates
ˆG(e−jω) = ˆγyu(ω)
ˆγuu(ω)
(11.49)
By working in the cross-spectral domain we are able to eﬀectively alleviate the eﬀects of
noise on the estimate of FRF. Observe that when the input is white with unity variance, the
estimate of cross-spectral density is the estimate of FRF itself.

Spectral Representations of Random Processes
291
Listing 11.4
MATLAB code for Example 11.7
% Generate input-data
N = 1000; uk = randn(N,1);
% Simulate process
Gd = tf([2 0],[1 -0.5],1);
yk = lsim(Gd,uk,(0:N-1)) + 0.5*randn(N,1);
% Estimate FRF
[gamma_yu ,w] = cpsd(yk,uk);
[gamma_uu ,w] = cpsd(uk,uk);
Gwhat = gamma_yu./gamma_uu;
% Compare estimated and true FRFs
Gw = squeeze(freqresp(Gd,w));
figure; plot(w,[abs(Gw) abs(Gwhat)]);
Figure 11.8 shows the estimate of FRF using the above idea on a process with
G(q−1) =
2q−1
1 −0.5q−1 ;
v[k] = e[k] ∼N (0,1)
0
0.5
1
1.5
2
2.5
3
3.5
1
1.5
2
2.5
3
3.5
4
4.5
Frequency (rad/sec)
FRF
 
 
True
Estimated
FIGURE 11.8
Estimate of FRF using spectral densities.
Notice that the estimates of FRF exhibit wild ﬂuctuations whereas the true one is smooth.
However, the estimate does capture the underlying trend of the FRF.
The idea presented in the foregoing example forms the basis for estimating FRF non-
parametrically from input-output data. See §20.4.4 for related methods.
Interestingly, (11.48) is also the solution to the least squares approximation of y[k] using {u[k]}
in the frequency domain (see Priestley (1981)). The mathematical statement is as follows.
Denote
g⋆= min
g
E((y[k] −
∞
X
n=−∞
g[n]u[k −n])2)
where g is the inﬁnitely long vector of the impulse response coeﬃcients {g[k]}. Then,
g⋆= F−1(G⋆(e−jω)) = F−1
 γyu(ω)
γuu(ω)
!
(11.50)

292
Principles of System Identiﬁcation: Theory and Practice
Coherency
In (10.44), we introduced coherency as a measure of linearity between two deterministic signals.
The same deﬁnition is extended below to the case of random signals,
κv2v1(ω) =
γv2v1(ω)
pγv2v2(ω)γv1v1(ω)
(11.51)
The magnitude of coherency is coherence. As stated in (10.45), squared coherence |κ(ω)|2 is used
to test linearity between two random variables. Observe the similarity of (11.51) with the deﬁnition
of CCF in (8.18). Coherency is a measure of correlation between two signals in frequency domain.
However, two points may be noted:
i. Coherency is not the Fourier transform of cross-correlation function.
ii. Correlation at lag l has a normalization involving product of ACVFs of the signals at lag l = 0,
whereas coherency at frequency ω has a normalization involving products of PSD of the signals
at that frequency ω.
The property of coherence in (10.45) for detecting linear relationships carries forward to the stochas-
tic case as well,
Coherence between two random signals y[k] and u[k] is unity if and only if they are
related through an LTI system,
|κyu(ω)|2 = 1
⇐⇒
{y[k],u[k]} are related through an LTI
(11.52)
Whenever κyu(ω) , 1, conclusions similar to the case of ρyu < 1 can be drawn, (i) the two
series are probably non-linearly related at that frequency and/or (ii) the “original” series are linearly
related, but noise in the data could be masking the linear relationship. The following discussion
elucidates these facts.
Consider a fairly general scenario
y[k] = G(q−1)u[k]
|        {z        }
x[k]
+v[k]
(11.53)
where v[k] represents the collective eﬀects of noise and disturbances. Assuming v[k] to be station-
ary and possessing an ARMA representation
v[k] = H(q−1)e[k]
it is possible to show by following a procedure similar to that in Section 7.4.2.1, that the squared
coherence at each frequency is inversely dependent on the noise-to-signal ratio at that frequency,
|κyu(ω)|2 =
1
1 + γvv(ω)
γxx(ω)
=
1
1 +
|H(e−jω)|2σ2
e
|G(e−jω)|2γuu(ω)
=
1
1 +
1
SNR(ω)
(11.54)
where the signal-to-noise ratio at each frequency is deﬁned as
SNR(ω) = γxx(ω)
γvv(ω) = |G(e−jω)|2γuu(ω)
|H(e−jω)|2σ2e
(11.55)

Spectral Representations of Random Processes
293
Thus, we have an interesting result. Measuring coherence between input and output of a linear
system oﬀers means of estimating the output signal-to-noise ratio in the frequency domain. The
following example illustrates this idea.
Example 11.8: Coherence of an LTI System
Consider the following process
G(q−1) =
2q−1
1 −0.5q−1 ;
H(q−1) = 1
(11.56)
An 1024-long input sequence u[k] with ﬁltered white-noise characteristics and a cut-oﬀfre-
quency at ω0 = 1.2566 rad/sec (see §22.3) is used to excite the process. The variance of the
WN is adjusted to σ2e = 0.25 so that the SNR = σ2x/σ2e ≈16.
Squared coherence is computed from N = 1024 samples. Theoretically, |κyu(ω)|2 ≈1 at
low frequencies, where SNR is very high and |κyu(ω)|2 ≈0 at high frequencies, regions of
very low SNR.
0
0.5
1
1.5
2
2.5
3
3.5
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Frequency (rad/sec)
Squared coherence
(a) Squared coherence |κ(ω)|2
0
0.5
1
1.5
2
2.5
3
3.5
0
50
100
150
200
250
300
Frequency (rad/sec)
SNR
(b) SNR(ω)
FIGURE 11.9
Squared input-output coherence and SNR for the process of Example 11.8.
Figure 11.9(a) displays the estimated squared coherence as a function of frequency for
the given process. An important step prior to applying (11.51) is segmentation and windowing
of the input-output data. Without this step, one would obtain misleading values of coherence. For
further details, see §16.7.
The estimated squared coherence agrees with the theoretical expectations. To corroborate
its dependence on SNR(ω), i.e., (11.54), the SNR as a function of frequency is shown in Figure
11.9(b). In regions of very low SNR, the squared coherence goes to zero and in regions of
high SNR, coherence touches unity.
This example also illustrates the beneﬁcial insights that can be obtained through
frequency-domain measures.
In identiﬁcation, squared coherence is useful not only in testing the feasibility of linear models
but also in computing the errors incurred in the estimation of delay and FRF using frequency-domain
methods (recall Examples 11.6 and 11.8). These errors are then incorporated into the identiﬁcation
problem using a weighted least squares approach.
11.5
PARTIAL COHERENCE
Coherence as deﬁned above suﬀers from confounding when more than two variables are involved.
This is to be expected since it is the frequency-domain analogue of correlation. Just as the way
partial correlation in (7.42) was devised to address the issue, a measure known as partial coherence

294
Principles of System Identiﬁcation: Theory and Practice
Listing 11.5
MATLAB code for Example 11.8
% Generate input-data
N = 1024;
uk = idinput(N,’rgs’,[0 0.4],[-1 1]);
% Simulate process
Gd = tf([2 0],[1 -0.5],1);
xk = lsim(Gd,uk,(0:N-1)); vk = 0.5*randn(N,1);
yk = xk + vk;
% Compute squared coherence and plot it
Nfreq = 128;
[Cyu,wvec] = mscohere(yk,uk,hanning(Nfreq),[],Nfreq);
figure; plot(wvec,Cyu)
% Compute SNR and plot it
Pxx = cpsd(xk,xk,hanning(Nfreq),[],Nfreq);
Pvv = cpsd(vk,vk,hanning(Nfreq),[],Nfreq);
snr_xv = Pxx./Pvv;
figure; plot(wvec,snr_xv)
can be devised in frequency-domain so as to test for direct relationships between two variables. In
this context, the coherence in (11.51) (and (10.44)) is known as ordinary coherence.
The partial correlation (7.42) relies on the concept of partial covariance (7.37). Similarly, the par-
tial coherence rests on the notion of partial cross-spectrum, which is the frequency-domain equiva-
lent of partial covariance (7.37).
The procedure to construct partial coherency between two variables v1 and v2 given a third vari-
able v3 then follows from the construction of partial covariance:
i. Condition both v1 and v2 on the third variable v3. In other words, construct residuals from best
linear predictors of v1 and v2 as in (7.38)
ε1.3[k] = v1[k] −ˆv⋆
1 [k|v3];
ε2.3[k] = v2[k] −ˆv2⋆[k|v3]
(11.57)
where ˆv⋆
i [k|vj] denotes the best prediction of vi given vj as before.
The best predictors for v1 and v2 using v3 are obtained as
ˆv⋆
1 [k] =
∞
X
n=−∞
g⋆
13[n]v3[k −n]
ˆv⋆
2 [k] =
∞
X
n=−∞
g⋆
23[n]v3[k −n]
(11.58)
where from (11.50),
G⋆
13(ω) =
∞
X
n=−∞
g⋆
13(ω)e−jωn = γv1v3(ω)
γv3v3(ω)
(11.59)
G⋆
23(ω) =
∞
X
n=−∞
g⋆
23(ω)e−jωn = γv2v3(ω)
γv3v3(ω)
(11.60)
ii. Compute the cross-spectrum between the residuals ε2[k] and ε1[k] to obtain the partial cross-
spectral density.
Following the notation in Wiener’s GHA, we denote the spectral representations of ε1.3 and ε2.3
by dZε1(ω) and dZε2(ω), respectively. Then,
dZε1(ω) = dZv1(ω) −G⋆
13(ω)dZv3(ω)
(11.61)
dZε2(ω) = dZv2(ω) −G⋆
23(ω)dZv3(ω)
(11.62)

Spectral Representations of Random Processes
295
with the additional notation being self-evident. Substituting expressions for G⋆
13(ω) and G⋆
23(ω)
and using the deﬁnition of cross-spectrum in (11.39c), we have
γv2v1.v3(ω) = E(dZε2(ω)dZ⋆
ε1(ω)
(11.63)
Substituting the expressions for (11.61) and (11.62) and using the deﬁnition of cross-spectra for
the respective variables, we can obtain the following simpliﬁed expression for the partial cross-
spectral density (see Exercise E11.10),
γε2ε1(ω) = γv2v1.v3(ω) = γv2v1(ω) −γv2v3(ω)γv3v1(ω)
γv3v3(ω)
(11.64)
iii. Finally, partial coherency is constructed from partial cross-spectral density
ηv2v1(ω) ≜κv2v1.v3(ω) =
γε2ε1(ω)
pγε2ε2(ω)γε1ε1(ω)
(11.65)
An interesting result useful in multivariable analysis follows.
Partial coh. ηv j vi (ω) = 0
⇐⇒
No direct linear link between vj and vi
(11.66)
Multivariate case
The multivariate versions of the spectral density, coherence for an m × 1-dimensional process are
essentially matrices of the form
S(ω) =

γv1v1(ω)
γv1v2(ω)
· · ·
γv1vm (ω)
γv2v1(ω)
γv2v2(ω)
· · ·
γv2vm (ω)
...
...
...
...
γvmv1(ω)
γvmv2(ω)
· · ·
γvmvm (ω)

(11.67)
C(ω) =

1
κv1v2(ω)
· · ·
κv1vm (ω)
κv2v1(ω)
1
· · ·
1
...
...
...
...
κvmv1(ω)
κvmv2(ω)
· · ·
1

(11.68)
Remarks:
All three measures, namely, spectral density, ordinary coherence and partial coherence are symmet-
ric measures, meaning they do not have directionality or cause-eﬀect information in them. Directed versions
of these measures with applications to network connectivity reconstruction have appeared in the last decade
or more in neurosciences, systems biology and process engineering (Baccala and Sameshima, 2001; Faes and
Nollo, 2011; Gigi and Tangirala, 2010).
We conclude this chapter with one of the most fundamental results in time-series modeling (pre-
diction): the spectral factorization result.
11.6
SPECTRAL FACTORIZATION
In Chapter 9 we learnt how to develop time-series models for random stationary processes. Given
a process described by a time-series model, Sections 9.4 and 9.5 discussed the theoretical ACVFs
while the previous section showed how to arrive at the theoretical spectral density from a linear
representation of the random process (recall (11.36)). The grander question is whether for a process
with a given spectral density, is it always possible to construct a linear description of the form
(9.10a)?, speciﬁcally a causal version. This problem was addressed by several researchers in late

296
Principles of System Identiﬁcation: Theory and Practice
1940s (prominently by Wiener, Kolmogorov, Wold, Cauchy and Doob; see Priestley (1981) for
a good historical account) in their eﬀorts to develop linear predictors for stationary processes. The
culmination of all the concerted eﬀorts is the celebrated spectral factorization result, which is brieﬂy
discussed below.
To understand the problem description, begin with the causal linear time-series model
v[k] =
∞
X
n=0
h[n]e[k −n] = H(q−1)e[k]
∞
X
n=0
|h[n]| < ∞
(11.69)
where, as usual
H(q−1) =
∞
X
n=0
h[n]q−n
e[k] ∼WN(0,σ2
e)
Then, using (11.36), we know
γ(ω) = σ2
e
2π |H(e−jω)|2 = σ2
e
2π H(e−jω)H⋆(e−jω) = σ2
e
2π H(e−jω)H(ejω)
(11.70)
Spectral factorization is the inverse problem, as stated below.
Given a time-series with continuous, symmetric, non-negative spectral density γ(ω) that is in-
tegrable over [−π,π] ﬁnd a factorization of the form (11.70). From this viewpoint, H(e−jω) is
known as the spectral factor.
Factorization of the spectral density can be formally shown to be a crucial step in the development
of a (linear) predictor for a stationary random process v[k] using the model (9.10a). This fact can
be realized by starting with Wiener’s representation of a stationary process (11.33) and invoking
Theorem 11.1, i.e., the spectral representation of the ACVF (11.4) (refer to Priestley (1981) for a
formal development). This problem was independently studied by Kolmogorov (1941) and Wiener
Wiener (1949) using two diﬀerent models (predictors). While Kolmogorov used an inﬁnite-order,
causal, moving average version for prediction, Wiener used an inﬁnite-order causal auto-regressive
model. Despite the diﬀerences in the predictor forms, the requirement still turns out to be (11.70).
This should not be surprising, since MA and AR models share an equivalence. On a side note, these
two approaches lead to two diﬀerent viewpoints of the white-noise process. In the former case,
white-noise process serves as the “basis” or the building block for representing a stationary process;
while in the latter case the white-noise is essentially the “unpredictable” portion of any stationary
process, also known as the innovations (see Chapter 18).
Returning to the problem of factorization, a few important questions arise. Under what conditions
is it possible to obtain the factorization (11.70)? Are there any restrictions on γ(ω) or the spectral
factor H(ejω)? A prime concern is also the uniqueness of the factorization. We do not formally
dwell on these issues, but rather state the results and provide interpretations with suitable examples.
To state the general result, it is necessary to introduce the z-transform of the ACVF,
γ(z) =
∞
X
l=−∞
σ[l]z−l
(11.71)
whereupon it is evident that γ(ω) = γ(z)|z=e−jω. The function γ(z) is also called the spectral
density.

Spectral Representations of Random Processes
297
Now a more general version of the spectral factorization problem can be stated. Find σ2 and
H(z) such that the spectral density γ(z) in (11.71) can be factorized as3
γ(z) = σ2
2π H(z−1)H(z)
(11.72)
where
H(z) =
∞
X
n=0
h[n]z−n;
H(z−1) =
∞
X
n=0
h[n]zn
(11.73)
Essentially, H(z−1) is obtained by replacing every appearance of z in H(z) with z−1.
Next we discuss a few important facts pertaining to the spectral factorization.
i. The ﬁrst fact to note is that in both forms (11.70) and (11.72), the factorization is not unique. If
(σ2
e, H) is a solution, then (α2σ2, H/α),
α ∈R is also a solution. This issue was discussed in
Section 9.3.1. There we ﬁxed the non-uniqueness by requiring (recall (9.15a))
h[0] = 1 =⇒
H(0) = 1
(11.74)
We impose an identical requirement here as well.
ii. The second fact is that spectral factors can only be identiﬁed correctly up to a phase. If H(z) is
a solution, then so is H(z)e−Dω. The phases cancel out in the products of (11.70) and (11.72).
This is not surprising since spectral densities are blind to phase shifts in signals. Unfortunately,
this issue is not resolvable. Nevertheless, spectral factorization guarantees the identiﬁcation of a
minimum-phase ﬁlter H(z).
iii. Thirdly, if H(z) is a solution, then H(z−1) is an equally likely solution. This is in fact a fallout
of the ﬁrst issue above. The following example illustrates this point.
Example 11.9: Two Processes with Identical Spectral Density
Consider the ARMA process
v[k] = 1 + 3q−1
1 −2q−1 e[k]
e[k] ∼WN(0,σ2
e)
(11.75)
Observe that this process is neither causal (poles outside the unit circle) nor invertible
(zeros outside the unit circle).
From Theorem 11.6, it has the spectral density
γvv(ω) = σ2e
2π
|1 + 3e−jω|2
|1 −2e−jω|2
(11.76)
The spectral density can be re-written as
γvv(ω) = σ2e
2π
|1 + 3e−jω|2
|1 −2e−jω|2 = σ2e
2π
|1 + 3ejω|2
|1 −2ejω|2 = 9σ2e
8π
|(1/3)e−jω + 1|2
|(−1/2)e−jω + 1|2
(11.77)
Thus, from the spectral density viewpoint, the process in (11.75) and
˜v[k] = 1 + (1/3)q−1
1 −(1/2)q−1 ˜e[k]
˜e[k] ∼WN(0, 9
4σ2
e)
(11.78)
are indistinguishable.
3It is also a common practice to write the RHS of (11.72) as σ2H(z)H⋆(1/z⋆) for complex-valued processes.

298
Principles of System Identiﬁcation: Theory and Practice
The main message is that if the time-series of interest is generated by a process that is neither
causal (poles outside the unit circle) nor invertible (zeros outside the unit circle), then there exists
an equivalent process that is invertible and causal which has the same spectral density. The latter
process is however driven by a white-noise with a diﬀerent variance. The opposite is also true.
An identical issue was encountered earlier in Section 9.4.2 where the task was to build a time-
series model from a given ACVF. Since ACVF and spectral density are merely transforms of each
other, the issue and remedy can also be expected to be alike. The non-uniqueness was remedied
by restricting to invertible models only. We apply the same restriction here.
Now, we state the conditions under which the spectral factorization exists.
1. The ﬁrst condition is that non-causal (two-sided), inﬁnite-order, MA model of (9.10a) exists for
all stationary processes that have continuous spectral densities. For proof, see Priestley (1981).
2. The foregoing result is of little practical signiﬁcance since we are interested in causal (one-
sided) representations of the form (11.69). Essentially we are seeking a H(z−1) such that the IR
sequence {h[.]} is one-sided. It turns out that this is guaranteed if the spectral density, which is
integrable by deﬁnition, satisﬁes the following Paley-Wiener condition:
Z π
−π
log γ(ω) dω > −∞
(11.79)
This condition is satisﬁed by most stationary processes with continuous PSD unless γ(ω) is zero
over a continuous interval in frequency. Then, we say that γ(ω) is regular.
Interestingly, the condition in (11.79) does not guarantee invertibility of the factor or an AR
representation of the process.
3. To guarantee the existence of an invertible spectral factor, a necessary and suﬃcient condition is
as follows:
The logarithm of the spectral density log γ(z) is analytic in the annulus β < |z| < 1/β, β < 1.
Analytic essentially means that the function does not assume indeterminate values. This condi-
tion is a generalization of (11.79). It ensures that an AR representation of the process exists (see
Priestley (1981, Chapter 10)). Furthermore, it also leads to h[0] = 1, ﬁxing the uniqueness issue
discussed earlier.
We are now ready to state the general result (see Kailath, Sayed and Hassibi (2000) and Priestley
(1981) for a detailed account).
Theorem 11.7: Spectral factorization
Given a (discrete-time) stationary process whose spectral density is,
C1. Symmetric: γ(ω) = γ(−ω), ω ∈[−π,π]
C2. Non-negative: γ(ω) ≥0, (cannot be zero over an interval of frequencies)
C3. Integrable: 0 <
Z π
−π
γ(ω) dω < ∞(ﬁnite variance)
C4. Log-Analytic: log(γ(z)) possesses derivatives of all orders in the annulus β < |z| <
1/β, β < 1
its spectral density function is factorizable as
γ(z) = ec0H(z−1)H(z) = σ2
2π H(z−1)H⋆(z−1)
(11.80)

Spectral Representations of Random Processes
299
with H(z−1) and H(z) as deﬁned in (11.73). Further,
c0 = 1
2π
Z π
−π
log(γ(ω)) dω
(11.81a)
h[0] = 1
(11.81b)
|zeros(H(z))| < 1 (inside the unit circle, invertible)
(11.81c)
Proof. See Priestley (1981).
□
If H(z) has a rational form,
H(z) = C(z)
D(z)
(11.82)
then spectral factorization is such that both the poles and roots are guaranteed to be within the unit
circle. Thus, H(z) is both causal and invertible. Consequently, the driving white-noise process also
possesses a linear representation in terms of the random process v[k].
e[k] =
∞
X
n=0
˜h[n]v[k −n]
∞
X
n=0
| ˜h[n]| < ∞
(11.83)
where ˜h[n] are the impulse response coeﬃcients of the inverse ﬁlter 1/H(z). The inverse ﬁlter is
also known as the whitening ﬁlter.
Multivariable case
The multivariate version of (11.80) is
S(ω) = H(ω)ΣeHH (ω)
(11.84)
where S(ω) is the cross-spectral density matrix deﬁned in (11.67), Σe is the variance-covariance
matrix (7.31) of the innovations vector e[k] and {.}H denotes the Hermitian. Typically Σe is forced
to have a diagonal structure.
Discussion
When a random process is such that its spectral density can be factorized according to (11.72), then
it is said to be a regular process.
Several algorithms are available for realizing the factorization (Kailath, Sayed and Hassibi,
2000). In linear algebra, spectral factorization has a very close semblance to the spectral or eigen
decomposition of a matrix in terms of its eigenvalues and eigenvectors. The factorization assumes
diﬀerent names in diﬀerent ﬁelds (for example, Wiener-Hopf factorization, Riesz-Fejer theorem). It
is also possible to develop spectral factorization result for operators.
In time-series modeling, the factorization is not directly used for obtaining a model since the gen-
eral form of γ(ω) is not known. Rather we force ﬁt one of the models discussed in Chapter 9 to a
suitable degree of approximation. Examples 9.5, 9.9 and 19.6 are representative of those approaches.
See also discussion on rational spectral densities below. The spectral factorization is important nev-
ertheless since it provides the necessary theoretical support and establishes the conditions for the
existence of a time-series model.

300
Principles of System Identiﬁcation: Theory and Practice
Geometric interpretation
A geometric interpretation to the spectral factorization result can be provided by deﬁning a Hilbert
space for random variables, where the inner products and norms are deﬁned using covariances and
variances, respectively (see Priestley (1981)). The main point is that the white-noise sequence {e[k]}
can be thought of as an orthogonal (uncorrelated) basis for the observed random process v[k]. This
is the time-domain equivalent of the spectral representation (11.33) due to Wiener.
Rational spectral densities
When the spectral density γ(ω) is a rational function of trigonometric polynomials,
γ(ω) =
α0 +
M
X
r=1
αr cos(rω)
β0 +
N
X
s=1
βs cos(sω)
(11.85)
it is known as a rational spectral density.
The solution to the factorization simpliﬁes considerably whenever γ(ω) has the form in (11.85)
because all ARMA(P, M) processes possess rational spectral densities. Recall the process of Prob-
lem 11.5, for example, which is an ARMA(1,1) process. The spectral density of this process is a
rational polynomial with both the numerator and denominator being polynomials in cos ω.
An illustrative example below reinforces the point made above.
Example 11.10: ARMA Model from Rational Spectral Density
Suppose a random process v[k] is known to possess the spectral density
γvv(ω) = 4 1.09 + 0.6 cos ω
1.64 −1.16 cos ω
By visual inspection, γvv(ω) can be factorized as
γvv(ω) = 4
 1 + 0.3e−jω
1 −0.8e−jω
!  1 + 0.3ejω
1 −0.8ejω
!
There are two solutions to the ﬁlter that generate v[k], one which has zeros and poles inside
the unit circle and the other which has them outside the unit circle.
We choose the one that is both causal and invertible.
v[k] = 1 + 0.3q−1
1 −0.8q−1 e[k]
e[k] ∼WN(0,8π)
(11.86)
What if the true process does not possess a rational spectral density, but still satisﬁes the condi-
tions of Theorem 11.7? Then, building an AR(P) or an MA(M) model amounts to approximating
the spectral density of the given process with a rational function of trigonometric polynomials.
The following theorem (Brockwell and Davis, 1991) provides the necessary support to the suit-
ability of such an approximation for a real-valued stationary process with a continuous, symmetric
and integrable spectral density γ(ω).
Theorem 11.8
If γ is a symmetric, non-negative, continuous spectral density on [−π,π], then for every ϵ > 0, there

Spectral Representations of Random Processes
301
exists a non-negative integer M and a polynomial
A(z) =
M
Y
i=1
(1 −η−1
i z) = 1 + a1z + a2z2 + · · · + apzM
|η j | > 1, ∀j = 1,· · · , M
(11.87)
with real-valued coeﬃcients such that
|K|A(e−jω)|2 −γ(ω)| < ϵ
∀ω ∈[−π,π]
(11.88)
where
K =
1
(1 + a2
1 + a2
2 + · · · + a2
M)
Z π
−π
γ(ω) dω
Proof. See Brockwell and Davis (1991).
□
It can also be shown, as corollaries of the above theorem that MA and AR models of ﬁnite-order
provide suitable approximations to the spectral density of a given process (Brockwell and Davis,
1991).
To reiterate the points made in this section, the spectral factorization theorem provides the nec-
essary theoretical support for ﬁtting models to time-series data. When a random process is known
to satisfy the conditions stipulated by Theorem 11.7, any suitable estimation method may be used
to ﬁt a time-series model.
11.7
SUMMARY
In this chapter, we learned the concepts of spectral density and distribution function for random
processes. Unlike for deterministic processes, the Fourier transform of random signals does not
exist. The spectral density is directly derived from the ACVF of the process, a deﬁnition that also
holds for deterministic signals. Theoretically the spectral density, if it exists, can be derived in three
diﬀerent ways. Spectral density does not exist for harmonic processes, which are periodic in a mean
square sense. On the other hand, spectral distribution function always exists for any random process
whose ACVF is non-negative deﬁnite.
Wiener’s GHA provides the generalized framework for representing random signals in a way
similar to the Fourier representation for deterministic signals. The Wiener-Khinchin theorem uniﬁes
the spectral density deﬁnition for both random and deterministic signals.
For multivariable systems, the cross-spectral density is useful in estimating the delay and the
frequency response function. It is once again derived from the cross-covariance function. Coherency,
the normalized version of the cross-spectrum oﬀers a useful test for linearity. As with correlation,
it suﬀers from confounding, which is remedied through the construction of the partial coherence
function (PCF). The PCF is a very useful tool in detecting direct relationships between a pair of
variables in a multivariable process.
Finally, we learnt the importance of spectral factorization as a theoretical requirement for the ex-
istence of a time-series model. In the linear modeling of a stationary random process, two candidate
models exist, one that is both causal and invertible and the other that is not. With the aim of making
stable predictions, we select the one that is causal and invertible.
REVIEW QUESTIONS
R11.1 Explain why a random signal cannot be given a Fourier representation.

302
Principles of System Identiﬁcation: Theory and Practice
R11.2 What are the necessary conditions for a random process to possess a spectral density?
R11.3 Give the deﬁnition of a random periodic signal.
R11.4 Explain the three diﬀerent ways of “deﬁning” power spectral density of a signal.
R11.5 What is Wiener’s generalized harmonic analysis?
R11.6 State the spectral factorization theorem. What is its contribution to time-series modeling?
R11.7 Deﬁne coherency and its role in determining the LTI characteristic of a system.
R11.8 Identify two key uses of the cross-spectral density function.
R11.9 State the Wiener-Khinchin theorem and the conditions under which it applies.
R11.10 What is theoretical spectral density of a white-noise process? How do the colored noise pro-
cesses diﬀer in this respect?
R11.11 Deﬁne partial cross-spectral density and partial coherency. What are their uses?
EXERCISES
E11.1 Determine if the signal v[k] = Asin2(ωk + φ) is harmonic given that φ is uniformly distributed
in [−π,π] and A is a constant.
E11.2 Derive the expression for the spectral density of an AR(2) process
v[k] =
1
1 −1.1q−1 + 0.28q−2 e[k]
e[k] ∼WN(0,2)
using deﬁnition (11.38).
E11.3 Verify the result in the previous question by ﬁrst constructing the ACVF and then using deﬁnition
(11.9).
E11.4 Show that the three conditions stated in Deﬁnition 11.3 for a random periodic signal are equiv-
alent to the condition given in (11.16).
E11.5 A random signal w[k] is obtained as a superposition of two random signals v1[k] and v2[k], i.e.,
w[k] = v1[k]+v2[k]. Given that v1[k] ∼WN(0,2) and v2[k] is an AR(1) process v2[k]−0.6v2[k −1] =
e[k], e[k] ∼WN(0,1),
a. Find the spectral density of w[k].
b. Determine an appropriate ARMA representation for w[k].
E11.6 Find the theoretical autocorrelation function and the power spectral density function for the
following random processes:
(i) v[k] = α0 + e[k] + 2e[k −1] + e[k −2] and (ii) v[k] = α0 + e[k] −2e[k −1] + e[k −2]
where e[k] is a zero-mean GWN sequence and α0 is a constant.
Plot the theoretical auto-correlation function (use stem plot) and the theoretical p.s.d. function for
each of the above processes. What inferences can you make from these plots?
E11.7 The power spectrum for a random stationary process {v[k]} is given by
H(q) = 1 + 0.6q−1
1 + 0.4q−1
(11.89)
a. Compute the power spectrum γvv(ω).
b. Determine the ACF of v[k] from your result in part (a) for lags upto l = 2.
E11.8 With reference to E9.10., compute the theoretical (auto)-spectral density Φvv(ω) of each of
these processes by two methods, (i) using Wiener-Khinchin theorem and (ii) from the frequency
response function H(ejω).

Spectral Representations of Random Processes
303
E11.9 The p.s.d. of a stationary process is known to be γvv( f ) =
1.44
1.16 −0.8 cos(2π f ) .
a. Find the ACVF of the stationary process.
b. Sketch the ACVF and the p.s.d.
c. Determine the time-series model H(q−1) that generates v[k] = H(q−1)e[k].
E11.10 Derive the expression for partial cross-spectral density in Equation (11.64).
E11.11 Consider the random signal y[k] generated as the measurement,
y[k] = G1(q−1)u1[k] + G2(q−1)u2[k] + e[k]
(11.90)
where G1(q−1) = 2q−3, G2(q−1) = 3q−2 are the transfer functions of the two sub-systems excited by
stationary inputs u1[k] ∼GWN(0,σ2
1), u2[k] ∼GWN(0,σ2
2), and e[k] is the zero-mean white-noise
measurement error with variance σ2e. Given that u1 and u2 are correlated, i.e., σu1u2[l] , 0 for some
lag l, but are individually uncorrelated with e[k]:
a. Derive the expression for the cross-spectral density γyu1 (ω).
b. Argue that the phase of γyu1 (ω) cannot be used to determine the delay of G1(q−1).
c. Determine the expression for partial cross-spectral density γyu1.u2 (ω).
d. Show that the phase of partial cross-spectral density γyu1.u2 (ω) indeed oﬀers means for esti-
mating the delay in G1(q−1).

PART III
ESTIMATION METHODS

12
Introduction to Estimation
The purpose of this chapter is to introduce the reader to the basics of estimation theory. Three
fundamental estimation problems, namely, prediction, ﬁltering and smoothing are reviewed.
Two popularly encountered generic estimation problems, namely, parameter and signal esti-
mation are highlighted. This chapter serves as a stepping stone for the rest of the chapters
devoted to estimation.
12.1
MOTIVATION
Parts I and II laid the theoretical foundations for developing data-driven models for deterministic and
random processes. Diﬀerent forms of linear time-invariant models that can be possibly built were
studied. We also obtained glimpses of a few tools that can be used for estimating these models. These
tools required the characterization and estimation of a signal’s properties such as auto-covariance
function, spectral density, etc. Having learnt the theoretical deﬁnitions and characterizations of the
signal’s properties, the next natural step in identiﬁcation is to learn how to estimate these signal
properties and model parameters.
From the illustrative examples of the previous chapters, it is clear that the presence of noise
can signiﬁcantly alter the course of a modeling exercise. It may be required, in many situations,
therefore to ﬁlter out the undesirable components of a measurement prior to taking it through the
model estimation exercise. Lastly, but most importantly, is the task of prediction, a fundamental
goal of modeling. Depending on what we wish to predict, the model and the (future) time horizon
of prediction, the mathematics of the model estimation can change signiﬁcantly.
The full gamut of problems discussed above falls under a single, but the very broad umbrella of
estimation theory. It provides the necessary paraphernalia for estimating the unknown from known
information. The unknown could be a signal, parameter or a state. A secondary, but an important
objective of estimation is to provide (at least under simplistic assumptions) bounds on the errors
incurred in an estimation exercise.
Estimation theory hardly requires any motivating exposition. The problem of estimation arises
in every ﬁeld of data analysis without any exception. It is only that the forms are diﬀerent - it could
be in the context of inferring an unknown parameter, or estimating a signal from its measurement,
or predicting the course of a process. All of these problems share a common objective - to discover
or infer the “unobserved truth” from observed data.
The basic concepts of estimation are illustrated by means of an illustrative example. This is the
classic case of estimating a constant (signal) embedded in noise.
12.2
A SIMPLE EXAMPLE: CONSTANT EMBEDDED IN NOISE
Assume that we are interested in knowing the (constant) level x[k] of ﬂuid in a storage tank (no in
and out ﬂow). The level sensor that is being used for this purpose is known to provide an erroneous
measurement y[k]. The true quantity of interest is therefore “hidden” or “unobserved” and has to be
estimated from y[k].
Observation at a single instant in fact does oﬀer an estimate of c. But, as we shall show later, this
is too crude an estimate. Intuitively, using a set of observations {y[0],· · · , y[N −1]} we may obtain
a better estimate (under certain conditions). The estimation problem thus follows.
305

306
Principles of System Identiﬁcation: Theory and Practice
Problem statement: Given N observations {y[k]}N−1
k=0 of a constant signal c, obtain the “best” estimate
of c.
The ﬁrst step is to quantify what we mean by “best.” Denoting the estimate by ˆc and the true value
by c0, a natural requirement is that ˆc be as “close” as possible to the true value c0. A popular choice
is the squared Euclidean distance measure. However, since c0 is unknown, we have to take a slightly
diﬀerent approach.
The objective function should take into account known information, y[k]. For this purpose, a relationship
between the known and the parameter to be estimated, i.e., a model is presupposed.
Assuming the error to be zero-mean GWN and additive, a simple model is
y[k] = c + e[k]
e[k] ∼WN(0,σ2
e)
(12.1)
Observe that we have (N+1) unknowns, c and {e[k]}N−1
k=0
and N knowns, {y[k]}N−1
k=0 . The problem
is clearly underdetermined. Fortunately, since e[k] is random, its statistical properties deserve more
attention than its value at each instant. Thus, only p = 2 unknowns have to be estimated,
θ =
f
c
σ2e
gT
(12.2)
At this point, there are several ways of formulating the estimation criterion. For the present, we take
the prediction-error route1.
The prediction-error route involves ﬁrst setting up the predictor for the known measurements, momen-
tarily assuming the parameters in (12.2) to be given. Intuitively, the best predictor under the model
(12.1) and given θ is
ˆy[k|θ] = c
(12.3)
since e[k] is zero-mean2.
Introducing
ε[k|θ] = y[k] −ˆy[k|θ];
y =
f
y[0]
· · ·
y[N −1]
gT ;
ˆy =
f
ˆy[0]
· · ·
ˆy[N −1]
gT
(12.4)
we set up the optimization problem
min
θ ||y −ˆy||2
2 = min
θ
N−1
X
k=0
(y[k] −ˆy[k|θ])2 = min
θ
N−1
X
k=0
ε2[k|θ]
(12.5a)
subject to ˆy[k|θ] = c
(12.5b)
This is also the well-known least squares estimation approach.
The solution to the above optimization problem (see Chapter 14) is
ˆc⋆= 1
N
N−1
X
k=0
y[k]
(12.6)
which is, interestingly, the sample mean of the series y[k].
Obtaining the estimate of σ2e is slightly more complicated. However, it suﬃces for now to state that a
“good” estimate of σ2e can be obtained by evaluating the variance of the prediction errors ε[k|θ] at the
optimum.
ˆσ2
e = ˆε2[k|c⋆] =
1
N −1
N−1
X
k=0
(y[k] −ˆc⋆)2
(12.7)
In Chapter 14 we formally discuss the “goodness” of this estimate.
The expressions in (12.6) and (12.7) are said to be the estimators of c and σ2
e, respectively.
1In Chapter 14, we revisit this problem using the MLE approach.
2We shall later prove that this is indeed the best prediction of y[k] under (12.1) using the concept of conditional expec-
tation.

Introduction to Estimation
307
Remarks:
• The result in (12.6) is not surprising since c is, in fact, the mean of the process y[k]. Thus the estimation of
c amounts to estimating the mean of a random stationary process y[k].
• The sample mean is the best estimator of the mean in the least-squares sense.
• Observe that the estimator in (12.6) is a linear function of the knowns. Thus, it belongs to the class of linear
estimators.
• Estimation theory oﬀers tremendous freedom in postulating the estimation problem. In exploring this free-
dom, the user should note that the model and objective function are the vital elements of any estimation
exercise. While the model provides the estimator with the search space for the estimates, the objective func-
tion characterizes the point of optimum in the search space. The optimization algorithm essentially guides
the estimator towards this optimum.
Any change in the form of model or objective function can signiﬁcantly alter the solution. To recognize
this fact, consider the choice of 1-norm as a distance measure in place of the squared 2-norm for the signal
estimation problem above. With the new objective, the optimization problem is
min
θ ||y −ˆy||1 = min
θ
N−1
X
k=0
|ε[k|θ]|
(12.8a)
subject to ˆy[k|θ] = c
(12.8b)
It turns out (see Exercise E12.1.) that the solution to the optimization problem is the median,
ˆc⋆= Median(y)
(12.9)
Computing the median is a non-linear operation. Therefore, the estimator in (12.9) is non-linear. It is
thus clear that a change of estimation criterion produces a completely diﬀerent estimator. It may be noted
that under the assumption that the errors in y[k] are GWN, both estimators produce identical estimates.
However, the “quality” of the estimates are quite diﬀerent. Median oﬀers a robust estimate of c while mean
is very sensitive to the presence of outliers.
• The value of the estimate changes with the realization of the series. Thus, the estimate in (12.6) is a random
variable. If R data records (each of length N) are used, we obtain R diﬀerent estimates ˆc⋆r , r = 1,· · · , R
of c. It is desirable to keep the variation among these R estimates as low as possible. These facts apply to
the general case as well.
With these preliminary insights, we are prepared to formally deﬁne estimation and study the
generic setup of an estimation problem.
12.3
DEFINITIONS AND TERMINOLOGY
In a linguistic sense, estimation refers to the exercise of inferring the unknown using (i) known
information and (ii) a method or a formula for the same. A formal deﬁnition is oﬀered below.
Estimation is the exercise of methodically inferring the unobserved or hidden variable from
a given information set using a mathematical map between the space of unknowns and
knowns and a criterion for estimation. The device that performs the estimation is said to
be the estimator.
Figure 12.1 depicts the general setup of an estimation problem. We can identify ﬁve important
elements of this framework.
1. Information set Z: This is obviously the key ingredient. The information is available in diﬀerent
forms depending on the application. It could be in the form of a time-series data, an image,
qualitative data, or initial conditions, etc. In identiﬁcation Z is typically the input-output data.

308
Principles of System Identiﬁcation: Theory and Practice
Known 
information set
Z
ESTIMATOR
Objective 
(Loss) Function
ˆ✓
Model / 
Constraints
Confidence region
•✓0
True value
Estimate
FIGURE 12.1
(SEE COLOR INSERT) Schematic illustrating generic estimation.
2. Model (Constraints) M: It is a set of mathematical relationships between the knowns and un-
observed. The model could be a deterministic or a stochastic or a mixed function. It could also
be in the form of a predictor or a probability density function. Further, it may also include any
known constraints (such as bounds) on the variables / parameters to be estimated.
3. Objective function J : This is a mathematical statement by which the user deﬁnes what is meant
by “best.” It may include a number of terms depending on the objective. The typical objective
is to minimize (or a maximize) a function of the knowns and unknowns. Additional terms that
reﬂect the cost of estimation, computational eﬀort, penalty for violating certain constraints, etc.
may also be included. One may also have a vector of objective functions that are typical of multi-
objective estimation problems. An alternative name given to this function is the loss function,
since it reﬂects the loss in making an incorrect estimation.
It is important to choose the objective function carefully since it has a strong bearing on the
complexity of the optimization problem and the nature of the solution. Complicated forms of J
may provide better solutions but typically at the cost of increased computational burden.
4. Estimator: It is essentially the mathematical device or expression that computes the estimate
taking in all the three inputs above.
It is useful to view the estimator as a ﬁlter. For example, the estimator in (12.6) ﬁlters the signal
(or the parameter) c from the given observations. In fact, all ﬁltering problems constitute a subset
of estimation problems (see discussion in Section 12.4.1). The celebrated Wiener and Kalman
ﬁlters are classical estimators of signals or states. With this interpretation, we can apply several
concepts related to ﬁltering theory. As in the case of ﬁlters, estimators can be of various types
- causal / non-causal, linear / non-linear, time-invariant / adaptive and so on. Linear estimators
are preferred to non-linear ones because of ease of implementation. However, the price that may
have to be paid is the loss of eﬃciency and/or lack of robustness to uncertainties in data.
The form of the estimator is dictated by the optimization problem. The ﬁnal expression could
be in a closed-form solution or as a numerical algorithm depending on the complexity of the
optimization problem. This being true, it is also possible to specify a priori the form of estimator
and then use a criterion of estimation to obtain the exact expression.
5. Estimate vector: It is the output of the estimator and a systematic inference of the parameters of
interest. To denote the estimator, we shall adopt the standard notation. The parameter / variable
to be estimated is denoted by θ (could be a scalar or a vector), while the estimate itself is denoted
with a hat, ˆθ.
ˆθ = g(Z)
(12.10)

Introduction to Estimation
309
where the function g(Z) is known as the estimator function. Needless to state, g(Z) implicitly
depends on J and M.
On several occasions, the unknown set is larger than the set of parameters of interest θ. The
unknowns that we are not interested particularly in, but whose knowledge is required to estimate
θ are known as nuisance parameters.
Note: It is also conventional to have the same notation for the estimate and the estimator, i.e., ˆθ. The actual
reference is understood based on the context.
The concepts of true value and conﬁdence region are discussed shortly.
12.3.1
GOODNESS OF ESTIMATORS
The goal of any estimation exercise is to obtain the “best” estimate, with the term “best” qualiﬁed by
the model and the objective function. On the same note, the task of estimation is complete only when
(i) a qualifying statement of how close the estimate is to the true value (goodness or performance of
the estimator) can be made and (ii) a conﬁdence region for the true value is provided.
The above discussion assumes the existence of a true value. However, in several situations the
notion of a true value itself is ﬁctitious because the true model between Z and θ may be completely
diﬀerent from the assumed model (recall the motivational case study of Chapter 2). Irrespective of
whether a true value exists or not, we would like to know, at least when the model holds, how good
the estimate is. Therefore, for the purpose of evaluating an estimator, we introduce two quantities.
1. True value θ0: This is the true value of the parameter vector θ.
2. Data generating process (DGP): This is the process that generates the observations. The concept
is necessary in the estimation of model parameters. Typically the DGP is a set of governing equa-
tions for the measurements. In estimating parameters of a linear regression model, for example,
the DGP is:
y[k] =
P
X
i=1
zi[k]θi0 + v[k]
(12.11)
where zi, i = 1,· · · ,P are the known regressors and v[k] is the net eﬀect of uncertainties in y[k].
Where the DGP is unknown or structurally diﬀerent from the assumed model, it becomes nec-
essary to prove that the estimated model is the best approximation of the function that generates
y[k].
Further, we formulate certain tests to assess the performance of the estimator. There are essentially
six performance measures of an estimator, as discussed below.
i. Bias: It is a measure of the accuracy of the estimator by examining the statistical average of all
possible estimates in the space of uncertainties.
ii. Variance: This measure evaluates the precision (repeatability) of the estimator by examining the
statistical spread of estimates around their average.
iii. Minimum squared error: (MSE) The MSE is a measure of the precision as well, but the refer-
ence point is the true value θ0.
iv. Consistency: It is a measure of the large sample behavior of the MSE. Diﬀerent forms of con-
sistency can be deﬁned. This is a practically useful measure because it throws light on whether
larger sample size can actually improve the quality of the estimate.
v. Eﬃciency: This is used to compare two diﬀerent (unbiased) estimators. The estimator with lower
variance is said to be more eﬃcient.

310
Principles of System Identiﬁcation: Theory and Practice
vi. Suﬃciency: It determines the “suitability” of an estimator for a given estimation problem. This
property is concerned with whether the estimator is able to extract the maximum possible in-
formation present in the data about the parameter. A ballpark understanding is that it examines
whether the estimator leaves out something in the data that still contains some information about
the parameter being estimated.
The above measures are also known as the properties of an estimator, which can be further divided
into two categories, namely, statistical properties and asymptotic properties. While the former cat-
egory is concerned with the ensemble behavior of the estimator, the latter is concerned with the
large sample behavior. The technical deﬁnitions and interpretations of these measures are detailed
in Chapter 13. Of these six properties, the variance, consistency and eﬃciency are by far the most
important ones.
Conﬁdence intervals and hypothesis testing
No estimator can produce an estimate that is identical to the true value for obvious reasons: (i) un-
certainties in data (ii) modeling errors or inaccuracies and (iii) inability to ﬁnd the global optimum
(numerical optimizers usually return local optima). However, we would like to provide regions or
intervals in which the true value is expected to be contained, with as high degree of conﬁdence
as possible. The resulting interval is known as the conﬁdence interval (read Section 13.12.2). Con-
struction of a conﬁdence interval requires the knowledge of the distribution of estimates (recall from
12.2 that estimates are random variables). In fact, the problem is a subset of the larger branch of
hypothesis testing, which involves statistically testing a user-speciﬁed hypothesis on the true value
of the parameter. Hypothesis testing is perhaps one of the most important purposes of statistical
inferencing (estimation).
A good estimator produces conﬁdence regions that have narrow width (radius) and also one that
contains the true value. As mentioned above, it is not possible to provide 100% conﬁdence intervals
of ﬁnite width.
12.4
TYPES OF ESTIMATION PROBLEMS
The problem of estimation assumes diﬀerent names depending on the context in which it is formu-
lated. The subject itself is known alternatively as statistical decision theory or statistical inferencing.
Estimation problems can be classiﬁed into two broad categories: (1) signal estimation and (2)
parameter estimation. In a uniﬁed framework, both can be shown to be equivalent. However, keep-
ing in view the pedagogical reasons and the origins of these problems, we shall maintain a clear
distinction between them.
In the last three decades or so, a new class of problems known as the state estimation has attracted
widespread attention in the signal processing and statistical community. On a related note, since the
state sequence is essentially another signal, justiﬁably the state estimation problem can be treated
as one of signal estimation.
12.4.1
SIGNAL ESTIMATION
Signals are usually available in the form of measurements that are contaminated by noise. The
signal could be a regular 1-D signal, or a higher-dimensional variable such as an image. The goal is
to estimate the signal(s) from the measurements.
The generic problem in (discrete-time) signal estimation is as follows.
Given measurement set
{Z[0],Z[1],· · · ,Z[N −1]},
Z[.] ∈Rm
(12.12)

Introduction to Estimation
311
and a dynamical model,
Z[k + 1] = Φ(x[k],Z[k],v[k])
(12.13)
estimate the signal x[k] ∈Rp and the statistical properties of the stochastic signal v[k] ∈Rm.
The problem statement is incomplete without an assumption on the joint probability distribution
(density function) of v[k]
v[k] ∼f (v; ξ)
(12.14)
where ξ is the vector of parameters characterizing the probability density f (.).
The information set could also include possible input actions u[k] (see state estimation below).
Needless to say, the steady-state signal estimation problem (related to the celebrated Wiener ﬁlter)
is a special case of the dynamical one.
Popular applications concerned with this problem are radar and sonar signal processing, commu-
nications of audio / video signals, biomedical signal detection, etc. The problem of signal estimation
is usually accompanied by signal detection, although sometimes a distinction is not observed be-
tween the two.
Signal estimation is a classic problem with over two centuries of contributions. In this course
of time, the topic has lent itself to three sub-classes, namely, prediction, ﬁltering and smoothing
depending on the relative position of the sampling instant at which the estimate is desired with
respect to the time horizon over which the data is available.
Prediction
The prediction problem, as the term implies, refers to the case when the information is available up
to k and we are interested in estimating future values of the signal x[k + 1], x[k + 2],· · · .
Estimate x[k + 1], x[k + 2],· · ·
given {Z[0],Z[1],· · · ,Z[k]}
(12.15)
The estimates of future values are naturally referred to as predictions. It is customary to denote the
prediction (and the predictor) as
ˆx[k + 1|k] (One-step ahead predictor);
ˆx[k + p|k] (p-step ahead predictor)
On many occasions, the signal that we wish to predict may be the measurement itself.
Prediction is a prime problem of interest in all areas of analysis. In identiﬁcation, the role of
prediction is critical to model estimation so as to obtain the best model. Prediction-error methods
use the predictor as the basic vehicle to minimize the prediction errors.
In Chapter 18 we show how prediction expressions are derived given a LTI model. It is appropriate
to remind ourselves of the fundamental result in prediction theory, which is that the conditional
expectation E(x[k]|Z) is the best predictor in the minimum mean-square error sense.
Filtering
Filtering is concerned with the estimation of the signal at the kth (present) instant given information
up to the kth (present) instant.
Given Zk = {Z[0],Z[1],· · · ,Z[k]} estimate x[k]
(12.16)
The ﬁltered estimate is denoted by ˆx[k|Zk] or simply ˆx[k|k].
This problem holds an indispensable place in communications, control and several on-line ap-
plications. The Wiener ﬁlter, Kalman ﬁlter and particle ﬁlter are some of the celebrated ﬁlters that

312
Principles of System Identiﬁcation: Theory and Practice
provide optimal solutions to the related estimation problem under diﬀerent assumptions. These ﬁl-
ters and their design diﬀer considerably from the classical ﬁlters such as Chebyshev, Butterworth
ﬁlters in that the latter are designed oﬀ-line and without taking into any explicit consideration of the
signal and/or noise dynamics.
In system identiﬁcation, ﬁlters are used to eliminate or alleviate noise prior to model estimation.
Several identiﬁcation problems embed the ﬁlter into the model estimation problem. These topics are
treated under the banner of pre-ﬁltering.
When compared to prediction, ﬁltering essentially looks at the estimation problem in the present
time.
Smoothing
Finally, smoothing is that estimation problem which relies on both past and future data to make an
inference of the signal at the present instant.
Estimate x[k]
given ZN = {Z[0],· · · ,Z[k −1],Z[k],Z[k + 1],· · · ,Z[N −1]}
(12.17)
The resulting estimate is denoted as ˆx[k|ZN], 0 ≤k ≤N −2.
It is clearly a non-causal operation. Smoothing has to be therefore implemented oﬄine unlike
prediction and ﬁltering, which can be carried out online.
The estimator that performs smoothing is usually referred to as the smoothing ﬁlter or simply
smoother.
An intelligent estimation method uses all the three operations in the right sequence. For instance,
the popular Kalman ﬁlter ﬁrst makes an optimal one-step (or a p-step) ahead prediction of the signal,
then optimally ﬁlters (updating the prediction) the estimate with the arrival of the new measurement,
and optionally smooths the ﬁltered estimates.
All the three estimation problems invariably make certain assumptions on the signal dynamics
(e.g., steady-state or dynamic, LTI or LTV), noise characteristics (e.g., white or colored, stationary
or non-stationary) and the signal-noise relationship (e.g., uncorrelated or correlated).
Chapter 23 presents the theoretical development of Kalman ﬁlter in the context of state-space
model identiﬁcation.
12.4.2
PARAMETER ESTIMATION
This term parameter may either refer to a regression model parameter or the parameter of a proba-
bility distribution (density) function.
In model parameter estimation, the form of the regression model is known and the user is inter-
ested in estimating the parameters of the model from the given data. This is the standard case in
identiﬁcation - a problem that we shall extensively study. Recall the case study of Chapter 2 in this
context, where we used the least squares method to estimate the parameters of the output-error and
the equation-error models. These problems have the generic form
min
θ
||yN −ˆy(θ)||2
2
(12.18)
where yN is the vector of stacked measurements, ˆy(θ) is the predictor expression resulting from a
model and θ are the vector of model parameters.
Statistical parameter estimation, on the other hand, is concerned with estimating the parameters
of a density (or a distribution) function, the form of which is either pre-supposed by the user or
empirically “guessed” from the given data. This is an extensively studied problem and ﬁnds wide
applications in identiﬁcation. Methods based on the concept of likelihood function introduced by

Introduction to Estimation
313
Fisher (1922) are very powerful and popular estimation methods in this context. The (log)-likelihood
function problems are of the form
min
θ
−ln l(θ|yN )
(12.19)
where l is the likelihood function (constructed from the density function), yN is the vector of obser-
vations as above and θ is the vector of statistical parameters.
The model parameter estimation problem can be solved using likelihood functions and vice versa.
These methods are discussed in greater detail in Chapter 14.
12.4.3
STATE ESTIMATION
As the name suggests, state estimation is concerned with the inference of states from given observa-
tions. The problem is naturally portrayed in the state-space framework and was largely popularized
by Kalman (1960) in his seminar paper on Kalman ﬁlter. The Kalman ﬁlter (see §23.3) is a linear
estimator and provides optimal estimates of states under the assumptions of GWN disturbances and
measurement noise. An important requirement is that the state-space model is known a priori. Post-
publication of Kalman’s work, there has been an explosion of activity in the state estimation arena,
giving it a prominent place in the estimation literature. Numerous extensions and generalizations of
these estimators have appeared over the last four decades. Kalman ﬁlter also motivated the develop-
ment of alternative ﬁlters, using somewhat similar ideas. Non-linear state estimation using extended
Kalman ﬁlters (EKF) and particle ﬁlters are some of the state-of-art state estimators (Grewal and
Andrews, 2008; Zarchan and Musoﬀ, 2008).
The generic (discrete-time) state estimation problem is described below.
Given measurements y[k] ∈Rm and input actions u[k] ∈Rn and a state-space model
x[k + 1] = Φ(x[k],u[k],w[k])
(12.20a)
y[k] = Γ(x[k],u[k],v[k])
(12.20b)
w[k] ∼fw(w; ξw)
(12.20c)
v[k] ∼fv(v; ξv)
(12.20d)
estimate the signal x[k] ∈Rp and the statistical properties of the state noise, w[k] ∈Rp and process
noise, v[k] ∈Rm. The case of Gaussian density functions for the state and process noise and
linear model is the most popular one due to mathematical convenience and ease of implementation.
Methods that can handle non-linear models and non-Gaussian distributions are also available, but
are naturally mathematically more complicated.
One of the main reasons for the popularity of state estimation problems is because every signal
estimation problem in dynamic systems can be cast into this form. Since the state essentially charac-
terizes a hidden or unobserved quantity, the signal of interest can be treated as a state. An important
requirement is, however, that the state-space model is available beforehand. This may not be the
case in several situations. Eﬀorts to estimate the state-space model and the states jointly led to the
theory of subspace identiﬁcation (Chapter 23). Interestingly, several parameter estimation problems
involving parameters that vary with time can also be cast as state-estimation problems. The recursive
estimation methods exemplify this fact (see §25.1).
12.4.4
OTHER CLASSIFICATIONS
There exist other classiﬁcations based on the nature of the estimators. A type of classiﬁcation is
based on the estimates that the estimators produce. These are point estimators and interval estima-
tors. Point estimators are those that produce single-valued estimates, whereas interval estimators

314
Principles of System Identiﬁcation: Theory and Practice
deliver estimates within a certain range. The former class of estimators are a commonplace in prac-
tice. Another classiﬁcation takes into account the model or the density function that is used in
estimation. The broad classes are
i. Non-parametric: The exact form model or density function is unknown, but the space to which
it belongs is known.
ii. Semi-parametric: The predictor form is known but the probability density function is known.
These are popular in econometrics.
iii. Parametric: Both the predictor and the density function forms are known. Only the parameters
are, of course, unknown.
As one moves from non-parametric to parametric estimators, the beneﬁts and losses are similar
to those witnessed in moving from non-parametric to parametric models. The prime advantage of a
non-parametric estimator is that there is no prejudice towards a class of estimators, thereby avoiding
any errors due to misspeciﬁcation. However, the computational and the mathematical burden spikes
up signiﬁcantly. Thus, as usual, the issue is that of a trade-oﬀbetween the two.
Most of the identiﬁcation literature are parametric estimation problems and we shall only deal
with these classes of problems in this text.
This chapter closes with a short overview of the estimation methods. The technical details of these
methods are expounded in Chapter 14.
12.5
ESTIMATION METHODS
In the large breadth and depth of estimation literature, one comes across numerous methods for
estimation. Fortuitously, most of these techniques can be classiﬁed as variants of a handful of fun-
damental methods. Therefore, it suﬃces, at least for most times, to study these basic methods in
depth. An overview of the founding ideas is presented below.
1. Method of moments: The idea behind these methods is straightforward. Derive the theoretical
expression for the moments of the distribution in terms of the parameters that are being estimated.
Replace the theoretical moments by their estimates assuming the original relationship holds good
for the estimated moments as well. The resulting estimator does not possess the same degree of
elegance and eﬃciency as those from LS and MLE methods, but provides reasonable estimates
that are handy in several applications. In the least, the estimates serve as good initial conditions
for other methods.
2. Least-squares (LS) method: The idea, largely credited to Gauss (also attributed to Legendre),
is to minimize the squared Euclidean distance between the observations y[k] and a function
f (θ,YN ). This method belongs to a larger class of methods that minimize some form of distance
between the known and a function of the unknowns. Other distance measures such as 1-norm
(a.k.a. Manhattan distance), Kullback-Leibler measure, Mahalanobis distance (weighted least
squares), can also be potentially used.
The biggest advantage of using the squared 2-norm distance measure is that, with linear models
it produces a linear and unique estimator. The resulting estimator is also known as the linear LS
estimator to distinguish it from its non-linear LS counterpart. Several variants of LS techniques
exist - weighted LS (WLS), generalized LS (GLS), total LS (TLS), partial LS (PLS) and so on.
A vast majority of the methods used in practice are based on this basic LS method. A method
that uses a variation of the LS idea for dynamic systems is the instrumental variable (IV) method
(see §21.7.1).
3. Maximum-likelihood estimation (MLE) method: The method, historically younger than the
LS method, at least by a century, was originally conceived by Fisher (1912) in his pivotal paper.
The technique directly attacks the joint probability density function of the measurements taking

Introduction to Estimation
315
into account both deterministic and probabilistic models for the components of the measurement.
The chief assumption is that the observations have a stochastic component. This is in contrast
to LS methods which can be cast as a pure functional approximation problem and the stochastic
nature of the data need be brought in when the properties of the estimator are evaluated.
MLE is a powerful method of estimation that produces eﬃcient estimators when the sample size
is large. Computationally it is more demanding than the LS methods because almost all MLE
methods are non-linear optimization problems. A vast portion of the literature available on this
method assumes a Gaussian density function for the observations. A few variants that assume
Poisson distribution, uniform distribution are also available but are used sparingly (Garthwaite,
Jolliﬀe and Jones, 2002).
It can be shown that the MLE and LS methods are equivalent when the stochastic terms in the
observation follow a Gaussian distribution. A stronger equivalence exists between the MLE and
WLS methods.
4. Bayes estimation method: The fourth class of methods are based on a radically diﬀerent as-
sumption on the unknowns of interest. While the classical approaches assume the parameters to
be deterministic, a Bayesian method assumes the parameter to be random possessing a known
prior probability distribution P(θ). The knowledge of this prior probability distribution is not
easily available, thus reducing its practical appeal. However, it is a very powerful framework for
incorporating prior knowledge to produce eﬃcient estimates. It incorporates the other popular ap-
proaches. For instance, the MLE method falls out of the Bayes estimation approach when P(θ)
is assumed be uniform. Application of Bayesian estimation methods to system identiﬁcation is a
growing area of interest with some exciting challenges and results.
12.6
HISTORICAL NOTES
The subject of estimation is one among the oldest and at the same time stimulating with fresh chal-
lenges thrown in by complex applications. The theory is enriched with very well-developed ideas
that have matured over the last two centuries. Consequently, the literature in this ﬁeld is abundant
with numerous contributions and a diverse set of methods. A strong reason for the richness of this
subject is the immense practical value it holds in all areas of engineering, sciences and humanities.
The majority of the ideas that exist today have originated largely from the ﬁelds of statistics and sig-
nal processing. Notable among those who have made contributions to the subject are Gauss, Legen-
dre, Fisher, Cramer, Rao, Wiener, Kolmogorov and Kalman. This list is by no means exhaustive, but
merely represents the turning points in the journey of estimation. Applications of estimation theory
to engineering discipline are innumerable and have been collected in several textbooks and review
/ survey articles. An excellent article by Sorenson (1970) gives a detailed and insightful account of
the historical and anecdotal developments during the Gauss-Legendre and the Wiener-Kolmogorov
eras followed by an interesting perspective on the Kalman ﬁlter.
It would be a futile attempt to present the full range of estimation methods and issues in a single
textbook, let alone a few chapters of this text. With this fact in mind, the aim of Chapters 12 to
16 is to present the reader with the basic foundations and expand on methods relevant to system
identiﬁcation. An in-depth understanding of these chapters will place the reader in a good position
from where it would not be diﬃcult to dwell further into advanced material found elsewhere.
In the following chapter, we shall study the means and methods of assessing the performance of
estimators, an overview of which was brieﬂy given in Section 12.3.1.
REVIEW QUESTIONS
R12.1. Explain the basic goals in an estimation problem.
R12.2. What are the basic diﬀerences between prediction, ﬁltering and smoothing?

316
Principles of System Identiﬁcation: Theory and Practice
R12.3. Describe the diﬀerent elements of an estimation exercise.
R12.4. What are the various types of estimation problems?
R12.5. Explain, with at least one example, the equivalence between parameter, signal and state estima-
tion problems.
R12.6. What are the six performance measures used in characterizing an estimator?
R12.7. Brieﬂy describe the four broad methods available for estimation.
EXERCISES
E12.1. Show that the solution to the 1-norm minimization in (12.8b) is the sample median of observa-
tions.
E12.2. Suppose the estimator for c in Section 12.2 is pre-speciﬁed to have a form
ˆc =
N−1
X
k=0
αy[k]
(12.21)
Then derive the optimal value of α such that
J = E( ˆc −E( ˆc))2
(12.22)
is minimized. Compare the solution with the optimal solution in (12.6).
E12.3. With reference to the estimation problem in §12.2, let y[k] fall out of a Gaussian white-noise
process with µ = 2 and σ2 = 1. Generate least squares estimates of c σ2e for diﬀerent sample sizes
N = 10,100,500,10000. Determine if the estimates of c and σ2e converge to the true value as N
increases.
E12.4. Repeat the above exercise with the sample median estimator, but only examine the convergence
of ˆc.
E12.5. Use the setting in E12.3. to obtain estimates of c and σ2e for two diﬀerent sample sizes N1 =
10 and N2 = 1000. Repeat this exercise for several realizations R = 500. Plot histograms of the
respective estimates for each sample size. What distributions do you deem appropriate for each of
those estimates?

13
Goodness of Estimators
This chapter presents the performance measures of estimators discussed in Chapter 12 - their
deﬁnitions and interpretations. In addition, it presents the Fisher information matrix, an im-
portant quantity in estimation and identiﬁcation. Although somewhat theoretical and mathe-
matical in nature, the material presented in this chapter forms the backbone of identiﬁability,
computing errors in (model and statistical) parameter estimates, constructing conﬁdence in-
tervals for parameters and arriving at distributions of estimates.
13.1
INTRODUCTION
From Section 12.3.1 recall an important fact - obtaining an estimate is not necessarily the only
end goal of an estimation exercise. An equally important goal is to quantify the errors incurred
in estimation and provide a conﬁdence region for the “truth.” We have previously discussed the
sources of estimation errors in Chapter 12. A realistic experimental design can at best only minimize
some sources of errors, but not eliminating them. Zero error occurs only in an idealistic setting, since
even the most careful experiment is not impervious to factors beyond our control.
A natural recourse is to design the estimator in such a way that despite the inevitable uncertain-
ties, it should deliver an estimate as accurate and precise as possible. Such an estimator can only
be developed by understanding the inﬂuence of two contrasting aspects, namely, (i) experimental
factors within our control (e.g., sample size, sampling rate) and (ii) random variations in the pro-
cess and data on the quality of the estimate. Furthermore, we require quantitative deﬁnitions of
qualiﬁers such as accuracy, precision and so on. The theory presented in this chapter is exactly for
this purpose. Another useful application of this theory is that it will equip us with the knowledge of
selecting the “right” estimator from a competing set of estimators in a principled manner.
As mentioned in Section 12.3.1, there are six major qualifying characteristics of any estimator.
The developments to follow are devoted to a study of these properties. Foremost, however, is the
review of an important concept known as Fisher information (matrix), which is central to the
evaluation of variance bounds of estimators and the concept of identiﬁability.
Notation
The notation ˆθ is used to denote the estimator and the estimate. Sometimes to emphasize the depen-
dence of the estimate (estimator) on the observed data, the functional form ˆθ(.) may be used. On
other occasions the notation ˆθN may be used to explicitly denote its dependence on the sample size.
The true value is denoted by θ0. Also recall that any estimate in general is a random variable since
it is a function of observed data, which themselves contain random eﬀects.
All the results stated in this chapter (and in general estimation theory) assume that the observed
data is stochastic. It shall be further assumed that we have a vector of observations y and that it
is characterized by a joint probability density function f (y; θ) or f (y|θ), where θ is the vector of
parameters as usual. Note that the assumption of randomness on y does not limit its applicability to
identiﬁcation since measurements contain random eﬀects as well. When required (in later chapters),
the results are applied by replacing the density functions of observed data with their conditional
densities (or with density functions of prediction errors).
317

318
Principles of System Identiﬁcation: Theory and Practice
13.2
FISHER INFORMATION
The central goal in estimation is to estimate parameter(s) θ from a set of observed data y. Related
to this problem is the burning question, “how much” information on the parameter of interest is
contained in the given data? The Fisher information Fisher (1925) oﬀers valuable insights in this
direction. For the sake of brevity, only the salient aspects are presented.
First, introduce the following quantities
l(θ,y) = f (y; θ) (or f (y|θ))
(likelihood function)
(13.1a)
L(θ,y) = ln l(θ,y)
(log-likelihood function)
(13.1b)
The likelihood function in (13.1a) is a function of the parameter θ for a given series y. Mathe-
matically, it is identical to the p.d.f.; however, its role and interpretation are diﬀerent. The p.d.f.
facilitates computation of probabilities given θ, whereas the likelihood is a function of θ and fa-
cilitates computation of optimal parameter estimates that would have most likely (with maximum
probability) resulted in the given series. To explicitly indicate the random nature of the observed
data, sometimes the likelihood is written as l(θ,YN ), where YN is the vector of random variables
corresponding to the N observations in y.
A few additional insights and the use of likelihood in parameter estimation is the subject of Section
15.1.
Next, introduce the score,
S(θ; y) = ∂
∂θ ln f (y; θ) = ∂
∂θ L(θ,y)
(13.2)
Assume that the p.d.f. f (y; θ) is regular:
i. ∂L
∂θ exists and is ﬁnite
ii. The operations of integration with respect to y and diﬀerentiation with respect to θ can be inter-
changed.
∂
∂θ
"Z
ˆθ(y) f (y; θ)dy
#
=
Z
ˆθ(y)
" ∂
∂θ f (y; θ)
#
dy
i.e., the range of y does not depend on θ1. The integrals above are in reality acting in the RN
space since y is a N-dimensional vector.
Then,
µS = E(S|θ) = 0
(see Appendix 13.A.1)
(13.3)
var(S|θ) = E(S2) = E *
,
 ∂L(y,θ)
∂θ
!2
+
-
(13.4)
The Fisher information is deﬁned as
I(θ) = var(S) = E *
,
 ∂L
∂θ
!2
+
-
(13.5)
1A p.d.f. that does not meet this requirement is the uniform density, f (x) = (1/θ)I0,θ (x) whose support depends on the
unknown parameter θ.

Goodness of Estimators
319
Also, since
E *
,
 ∂L
∂θ
!2
+
-
= −E
 ∂2L
∂θ2
!
(see Appendix 13.A.1)
(13.6)
the information is
I(θ) = −E
 ∂2L
∂θ2
!
= −E
 ∂S
∂θ
!
(13.7)
The deﬁnition in (13.7) is usually the most convenient to work with.
Example 13.1: Information about Mean, Variance and Standard Deviation in a Single Observation
Suppose that we have a single observation of a random process following a Gaussian distri-
bution. Then Y ∼N (µ,σ2).
i. Assume that we are interested in knowing θ = µ when σ2 is given. The log-likelihood function is
L(µ;Y) = ln f (y|µ) = −1
2 ln(2πσ2) −1
2
(y −µ)2
σ2
(13.8)
The Fisher information on θ = µ using (13.7) is then
I(µ) = −E
 ∂2L
∂θ2
!
= 1
σ2
(13.9)
The information contained in a single sample about its average increases as the variance (spread
of possible values) decreases. The limiting case is that of a deterministic variable.
ii. When the variance is unknown, θ = σ2 then a single observation has the information
I(σ2) = −E
 ∂2L
∂θ2
!
= −E( 1
2σ4 −(y −µ)2
σ6
) =
1
2σ4
(13.10)
iii. On the other hand, if the parameter of interest is the standard deviation θ = σ, the information
contained is
I(σ) = −E
 ∂2L
∂θ2
!
= −E( 1
σ2 −3 (y −µ)2
σ4
) = 2
σ2
(13.11)
Thus, I(σ2) , (I(σ))2. In general, the information is not commutative with respect to a functional
of the parameter φ(θ). The following result provides the expression for I(φ(θ)).
I(θ) =
 dφ
dθ
!2
I(φ(θ))
(13.12)
where I(φ(θ)) is the information of φ(θ) in Y.
When (13.12) is evaluated for the case of θ = σ and φ(θ) = σ2, we obtain
I(σ) = (2σ)2I(σ2)
=⇒I(σ2) =
1
2σ4
(13.13)
agreeing with (13.10) in Example 13.1.
Note: Some authors use I1(θ) to denote the information contained in a single observation.

320
Principles of System Identiﬁcation: Theory and Practice
Generalizing (13.5) to the information on a p × 1 parameter vector θ contained in N samples, we
obtain the information matrix
Ii j (θ) = cov(Si,Sj) = E(Si(YN )Sj (YN )) = −E
 
∂2
∂θi∂θ j
L(θ; yN )
!
i, j = 1,· · · ,p
(13.14)
where Si is the ith score statistic,
Si =
∂
∂θi
ln f (YN |θ)
(13.15)
where f (Yn|θ) is the joint p.d.f. of the N observations y.
Further, the information on a function of parameters φ(θ) is given by
I(θ) = Jθ(φ(θ))TI(φ(θ))Jθ(φ)
(13.16)
where Jθ(φ(θ)) is the Jacobian of φ(θ) w.r.t. θ.
The calculation of Fisher information matrix (13.14) is demonstrated on a simple parameter esti-
mation problem.
Example 13.2: Fisher’s Information on Mean and Variance of a GWN Process
Compute the information contained in N samples of a GWN process y[k] ∼N (µ,σ2) under
three diﬀerent situations:
(i) θ = µ and σ2 is known
(ii) θ = σ2 and µ is unknown
(iii) θ =
f
µ
σ2gT
Solution: For all three cases,
f (YN |(µ,σ2)) =
N−1
Y
k=0
1
σ
√
2π
exp
 
−(y[k] −µ)2
2σ2
!
(i) Constructing the log-likelihood from L(θ; yN ) gives
S(θ; yN ) =
N−1
X
k=0
(y[k] −µ)
σ2
Applying (13.14),
I(µ) = −E
 ∂S
∂θ
!
= N
σ2
(13.17)
(ii) For this case,
S(θ; yN ) = −N
2σ2 +
1
2σ2
N−1
X
k=0
(y[k] −µ)2
Applying (13.14),
I(σ2) = −E
 ∂S
∂θ
!
=
N
2σ4
(13.18)

Goodness of Estimators
321
(iii) Denote θ1 = µ and θ2 = σ2, θ =
f
θ1
θ2
gT The log-likelihood function is
L(θ; yN ) = c −N
2 ln θ2 −
1
2θ2
N−1
X
k=0
(y[k] −θ1)2
(13.19)
The information matrix is thus
I(θ) = −E
*.....
,

∂2L
∂θ2
1
∂2L
∂θ1∂θ2
∂2L
∂θ2∂θ1
∂2L
∂θ2
2

+/////
-
=

N
σ2
0
0
N
2σ4

(13.20)
Thus, the estimates of mean and variance of a white-noise process do not aﬀect each other, i.e.,
they are uncorrelated. In other words, these parameters can be estimated individually.
Remarks:
i. The Fisher information is a localized version (in the parameter space) of the more general Kullback-Leibler
information (KLI, Kullback and Leibler (1951)) in the vicinity of the true parameters. The KLI measures
the information loss incurred in approximating a true probability distribution with a hypothesized (model)
distribution.
ii. In MLE, the score S has a nice interpretation. It is the sensitivity of the objective function to the parameters.
The information measure I(θ) is therefore the average (negative) second derivative of the objective function
w.r.t. the decision variables.
iii. The term information by itself may have little technical meaning in data analysis. It is meaningful only in
the context of (i) the unknown(s) that have to be estimated and (ii) how these unknown(s) are related to the
observations, i.e., the model. The implications of these results are ubiquitous in model estimation and input
design. The former aspect is discussed in Section 13.7 and while the latter is presented in §22.3.
iv. From Problem 13.2 and Example 13.1, it is easy to observe that the information contained in N samples
is N times that contained in a single observation. This is an expected result since we have N uncorrelated
observations. Thus, by increasing the sample size, we indeed obtain more information. That being said, the
increase in information is not proportional to the sample size when the observations are correlated, because
then IN (θ) < NI1(θ).
The Fisher information matrix is a useful metric in experimental (input) design, model
parametrization, constructing conﬁdence intervals and determining the minimum expected errors
in parameter estimates. Two such applications are demonstrated in Section 13.7 which presents one
of the most important results in estimation theory, known as the Cramer-Rao’s inequality.
In the following sections, we study the six important properties of an estimator that were listed
in §12.3.1. It is instructive to classify these properties into two classes, namely, the statistical prop-
erties and asymptotic properties. In the former case, we study the ensemble characteristics of the
estimator, i.e., the average properties of the estimate across all realizations of the data, but for a
ﬁxed sample size. In the latter case, we study the ensemble properties of the estimator under large
sample conditions, i.e., how the statistical properties change when large number of observations are
provided. Bias, variance, mean square error belong to the former class, while asymptotic versions
of these belong to the latter class.
Finally in §13.11, we shall also study the distributional properties of an estimator, primarily only
in the large sample scenario. The main purpose of studying the distributional properties is to con-
struct conﬁdence intervals for the true parameters and conduct hypothesis tests.

322
Principles of System Identiﬁcation: Theory and Practice
13.3
BIAS
One of the ideal “expectations” of an estimator is that it provides us with accurate estimates. Ob-
viously running the estimator through a single, ﬁnite-length realization (record) of data will never
produce the true estimate. However, if the error in the estimate can be zeroed out by an averaging
of the estimates across all possible realizations (records of data), then the estimator may be deemed
as accurate. A formal deﬁnition follows.
Deﬁnition 13.1. An estimator ˆθ is said to be accurate or unbiased if and only if
µ ˆθ = E( ˆθ) = θ0
(13.21)
The diﬀerence △ˆθ = E( ˆθ) −θ0 is said to be the bias of that estimator.
Example 13.3: Sample Mean Estimator
The sample mean estimator for a stationary process,
¯y = 1
N
N−1
X
k=0
y[k]
(13.22)
is unbiased since
E( ¯y) = E *.
,
1
N
N−1
X
k=0
y[k]+/
-
= 1
N
N−1
X
k=0
E(y[k]) = µ
(13.23)
Note that the estimation and the result are meaningful only when the process is stationary.
Thus, the estimator (12.6) gives an unbiased estimate of c.
A point of emphasis is that the averaging in (13.21) is across all possible records of data and not
along time. From this viewpoint, the deﬁnition has limited practical value since it is extremely rare
to obtain multiple records of data. Unbiasedness is nevertheless a useful requirement for comparing
performance of two estimators (see Cramer-Rao’s bound in Section 13.7).
For practical applications, what would be more interesting is to examine the large sample behavior
of an estimator, i.e., whether the estimate will converge to the true value (in a probabilistic sense) as
N →∞. Two such properties are the asymptotic bias and consistency (see Sections 13.8 and 13.10).
While bias (statistical or asymptotic) is an important property of interest, a crucial property is the
variability of the estimate for diﬀerent realizations of data, which we study next. In general, it is
easier to handle bias in estimators than variability in the estimates for diﬀerent realizations.
13.4
VARIANCE
As discussed above, a more important requirement of an estimator is that it is able to deliver esti-
mates with as less variability as possible when diﬀerent records of data are supplied to it. Essentially
we are interested in addressing repeatability or reproducibility.
Deﬁnition 13.2. The variance of an estimator (estimate) is deﬁned as
σ2
ˆθ = E(( ˆθ −µ ˆθ)2)
(13.24)
Observe that the deﬁnition is with reference to the average of the estimator, µ ˆθ and not with
respect to its true value, θ0. In the latter case, one obtains the mean square error measure, discussed
in §13.9. When the estimator is unbiased, the variance and mean square error measures coincide.

Goodness of Estimators
323
µˆθ
•θ0
!"#$%&'(#$
)*'"+$*,
x
x
x
x
x
x
x
x
●
!"#$
ˆθ(i)
FIGURE 13.1
Pictorial illustration of bias and variance of an estimator.
Note: It is a fact that in practice we work with single record of data and rarely is there an opportunity to
compute the variability as in (13.24). However, the reason for studying the variance of an estimator is to know
how much faith one can place in a single estimate as a representative of the true value.
Figure 13.1 oﬀers a pictorial illustration of bias and variance as deﬁned above. Each cross mark
represents the estimate obtained from the ith realization and is denoted by ˆθ(i).
In the previous section, we noted that the sample mean is an unbiased estimator of the mean.
Assuming that the model (12.1) holds, we can derive an analytical expression for the variability in
sample mean, as shown below.
Example 13.4: Variance of Sample Mean for a GWN Process
Using Deﬁnition 13.2,
σ2
¯y = E(( ¯y −E( ¯y))2)
= E *..
,
*.
,
1
N
N−1
X
k=0
y[k] −µy+/
-
2
+//
-
= E *..
,
*.
,
1
N
N
X
k=1
(y[k] −µy)+/
-
2
+//
-
= 1
N2 E *.
,
N
X
k=1
(y[k] −µy)2+/
-
+ 1
N2 E *.
,
N
X
n=1
N
X
m=1,m,n
(y[n] −µy)(y[m] −µy)+/
-
= 1
N2
*.
,
N
X
k=1
E(y[k] −µy)2+/
-
+ 1
N2
*.
,
N
X
n=1
N
X
m=1,m,n
E(y[n] −µy,n)(y[m] −µy,n)+/
-
The summand in the second term can be easily recognized as the auto-covariance of y[k].
With the white-noise model for y[k],
y[k] = c + e[k]
e[k] ∼GWN(0,σ2
e)
the variability of sample mean is
σ2
¯y =
σ2y
N = σ2e
N
(13.25)
Remarks:
i. The variance of the sample mean is directly proportional to the variance of the random signal. Intuitively
this is a meaningful result. However, we have no control over σ2e.

324
Principles of System Identiﬁcation: Theory and Practice
ii. It is inversely proportional to the number of observations N. This is an interesting result and also a good
feature of the estimator because
σ2
¯y →0
as
N →∞
(13.26)
Thus, we are able to shrink the variability in the estimate by collecting more samples. This is certainly a
very desirable property for an estimator. As we shall shortly learn, (unbiased) estimators that possess this
feature are known to be consistent.
iii. The true mean has no bearing on the variability (of the sample mean), which is again a sensible result.
iv. The positive square root of σ2
ˆθ is known as the standard error of the estimate.
v. When ˆθ is a p × 1 vector, we have a variance-covariance matrix (as in the case of a multivariate RV),
Var( ˆθ) = Σ ˆθ = E(( ˆθ −E( ˆθ))( ˆθ −E( ˆθ))T )
=

σ2
ˆθ1
σ ˆθ1 ˆθ2
· · ·
σ ˆθ1 ˆθp
σ ˆθ2 ˆθ1
σ2
ˆθ2
· · ·
σ ˆθ2 ˆθp
...
...
...
...
σ ˆθp ˆθ1
σ ˆθp ˆθ2
...
σ2
ˆθp

(13.27)
It is a symmetric matrix with the oﬀ-diagonal elements reﬂecting the error incurred in estimating a pair of
parameters jointly. A diagonal Σ ˆθ implies that the parameters can be estimated on an individual basis. In
practice, the trace(Σ ˆθ) and the diagonal elements of Σ ˆθ ﬁnd wider utility.
Note that the variance expression in (13.25) is diﬀerent for colored noise and involves the auto-
covariance function of the signal (see Exercise E13.1). Even in that case, however, the dependency
on 1/N prevails.
Example 13.5: Variability and Zero-Bias of Sample Mean
In order to illustrate the foregoing results, R = 1000 realizations of a unit-variance, zero-
mean white-noise process, each containing N = 1000 samples were generated. Sample mean
for each of these realizations was computed using (13.22). A plot of these values versus the
realization index is shown in Figure 13.2(a).
The average of sample means is calculated to be µ ¯y = −2.9876 × 10−5, very close to the
true value. The estimated variance from the sample means of diﬀerent realizations is 0.00102,
which is practically in perfect agreement with the theoretical variability of ¯y, σ2y/N = 1/1000 =
0.001.
The two-sigma limits, ±2σ ¯y are shown to indicate that most of the data is contained
with these limits. In fact, about 95% of the sample means reside in this band since the
sample mean follows a Gaussian distribution as empirically conﬁrmed in Figure 13.2(b). The
Gaussian density ﬁt shown by a solid curve explains the histogram of sample means very
well.
The fact that the sample mean follows a Gaussian distribution (regardless of the distribution of the
data) is formally established through the central limit theorem, reviewed in Section 13.11.1.
The variance of an estimator is a measure of its precision, i.e., how close repeated estimates are
to each other. The lower the variance, the more precise is the estimate. For this reason, estimators
with minimum variance are desirable.

Goodness of Estimators
325
0
200
400
600
800
1000
−0.2
−0.15
−0.1
−0.05
0
0.05
0.1
0.15
Realizations
Statistics
 
 
Sample means
Average of means
Two S.E. limits
(a) Sample means of 1000 realizations
−0.1
−0.05
0
0.05
0.1
0
2
4
6
8
10
12
Data
Density
 
 
Data
Fit
(b) Distribution of the sample mean
FIGURE 13.2
Plot to illustrate variability and the (Gaussian) distribution of the sample mean.
13.4.1
MINIMUM VARIANCE UNBIASED ESTIMATOR
An estimator is said to possess minimum variance if among all unbiased estimators it has the least
variance.
Deﬁnition 13.3. An estimator ˆθ(Z) is said to be minimum variance unbiased estimator (MVUE) if
and only if
C1. E( ˆθ) = θ0 (Unbiased)
C2. Var( ˆθ) ≤Var( ˆθi) ∀i satisfying C1.
13.5
EFFICIENCY
The eﬃciency of an estimator is a measure of how well it performs relative to an unbiased estimator
that has the least variance. The unbiasedness is a requirement since biased estimators can be easily
tuned to have lower variance than an unbiased estimator. Then, the comparison is not a fair one.
Formally, the eﬃciency of an estimator ˆθ is deﬁned as
Eﬃciency( ˆθ) = η ˆθ = var( ˆθ⋆)
var( ˆθ)
(13.28)
where ˆθ⋆is the estimator that has theoretically the lowest variance among all estimators. The
Cramer-Rao’s inequality (or bound) in Section 13.7 dictates the bound and also stipulates the con-
dition under which an estimator exists. An estimator that achieves this lower bound is said to be the
most eﬃcient or fully eﬃcient. For example, the sample mean is the most eﬃcient estimator of the
mean of a white-noise process. We shall prove this fact shortly. When it is not possible to ﬁnd an
eﬃcient estimator, we need a measure of relative eﬃciency.
Relative efﬁciency
The relative eﬃciency of an unbiased estimator ˆθ2 with respect to another unbiased estimator ˆθ1 is
deﬁned as
Relative eﬃciency (%) = 100 ×
σ2
ˆθ1
σ2
ˆθ2
(13.29)
When ˆθ1 is the most eﬃcient estimator, i.e., that achieves the Cramer-Rao bound, the relative eﬃ-
ciency simpliﬁes to the standard eﬃciency in (13.28).

326
Principles of System Identiﬁcation: Theory and Practice
f(ˆθ1)
f(ˆθ2)
✓0
FIGURE 13.3
Sketch depicting (p.d.f.s of) two unbiased estimators with diﬀerent variances.
Figure 13.3 oﬀers a pictorial representation of two unbiased estimators with diﬀerent variances.
Estimator ˆθ1 is relatively more eﬃcient than ˆθ2. The more eﬃcient estimator is preferable since it
has a larger proportion of estimates close to the true value than the less eﬃcient one.
13.6
SUFFICIENCY
The suﬃciency of an estimator is a measure of how well an estimator captures the available infor-
mation about a parameter from the given series. It is formally deﬁned as follows.
Deﬁnition 13.4. An estimator ˆθ(y) is said to be suﬃcient if the conditional distribution of y given
the value of ˆθ does not involve the parameter θ.
The above condition can be expressed in the familiar factorization requirement.
An estimator is termed suﬃcient if the joint p.d.f. of y can be factorized into a product of two
functions
f (y; θ) = g( ˆθ,θ)h(y)
(13.30)
where h(y) is completely devoid of the parameter θ.
The sample mean for observations of a GWN process is a suﬃcient statistic for µ, i.e., the joint
p.d.f. of N samples of a GWN process can be split into two functions as in (13.30) (see Exercise
E13.5).
We now return to the most important property of an estimator, its variability or precision.
13.7
CRAMER-RAO’S INEQUALITY
The Cramer-Rao’s inequality (Cramer, 1946; Rao, 1945) provides the lowest achievable variance by
an unbiased estimator in terms of the Fisher information matrix introduced in Section 13.2. Further,
it also states the condition under which such an estimator exists and a method to ﬁnd that estimator
as well.
Theorem 13.1: Cramer-Rao Lower Bound
Suppose ˆθ(y) is an unbiased estimator of a single parameter θ. Then, if the p.d.f. f (y; θ) is regular,
the variance of any unbiased estimator is bounded below
var( ˆθ(y)) ≥(I(θ))−1
(13.31)

Goodness of Estimators
327
where I(θ) is the information measure in (13.5) (or (13.7)).
Further, an estimator ˆθ⋆(y) that can achieve this lower bound exists if and only if
S(YN,θ) = I(θ)( ˆθ⋆(y) −θ)
(13.32)
Then, ˆθ⋆(y) is said to be suﬃcient and most eﬃcient estimator of θ.
Proof. See Appendix 13.A.1.
□
The inequality in (13.31) is one of the fundamental results in estimation theory.
Remarks:
i. The C-R bound gives us the achievable theoretical lower bound and states the condition for the existence of
an estimator that can achieve this lower bound.
An alternative form of (13.32) can be given. The MVUE estimator that achieves the C-R bound exists if
and only if
S(YN ,θ)
I(θ)
+ θ
(13.33)
is independent of θ (suﬃciency) and only dependent on the observations y.
Example 13.6: Estimating the Mean of a GWN
Consider the standard problem of estimating the mean of a GWN process y[k] ∼N (µ,σ2)
from N observations. Given σ2, the information on µ in y was calculated in (13.17).
The minimum variability that any unbiased estimator will exhibit is
(I(µ))−1 = σ2
N
(13.34)
To determine the existence of an estimator that achieves this minimum, construct (13.33)
S(YN ,θ)
I(θ)
+ θ =
N−1
X
k=0
(y[k] −µ)
N
+ µ = 1
N
N−1
X
k=0
y[k]
(13.35)
which is only dependent on y. In fact, it is none other than the sample mean! The variance
of this estimator was indeed shown to be σ2/N in Example 13.4.
Thus, we conclude that the sample mean is the most eﬃcient and also a suﬃcient estimator
of the mean of a GWN.
A situation where the most eﬃcient unbiased estimator does not exist arises in estimating the parameter λ
of a white-noise with an exponential distribution, f (y) = λe−λy (see Exercise E13.3).
Existence of an efﬁcient estimator
The existence of the most eﬃcient estimator depends on two factors:
a. The parameter θ, or in general, its function g(θ). For instance, in the case of exponentially distributed
WN, it turns out that there exists an eﬃcient estimator if 1/λ is estimated instead of λ (see Exercise
E13.4).
In identiﬁcation, this means that the form of the model that is being estimated should be chosen
with care. It may turn out that the parameters of the same model, written in one form, can be
estimated eﬃciently than in another form. Or it is that a particular model can be estimated more
eﬃciently than another one for a given process. At the root of these recommendations is the
fact that the information contained in the data on a set of parameters is diﬀerent from that on a
transform of the parameters.

328
Principles of System Identiﬁcation: Theory and Practice
b. The probabilistic characteristics of the observed data, speciﬁcally the density function. In reality, it
is diﬃcult to know the p.d.f. a priori. Then, the existence of an eﬃcient estimator depends on the
assumed density function.
ii. From (13.31), the larger the information on θ, the lower is the bound, i.e., higher the precision of the most
eﬃcient unbiased estimator.
iii. The C-R bound is used to deﬁne eﬃciency and also compare two unbiased estimators (see Section 13.5).
iv. For the multi-parameter case, i.e., when the parameter vector θ is p × 1, the result generalizes to
Σ ˆθ −I−1(θ) ≥0
(positive semi-deﬁnite)
(13.36)
where the information matrix I(θ) is as deﬁned in (13.14).
An optimal estimator that achieves the bound in (13.36) exists if and only if
I−1(θ)S(θ,y) + θ
(13.37)
is independent of the parameter vector θ and dependent on the observations y.
The proof of the above result is a generalization of that given in Appendix 13.A.1 and can be found in
several texts (see Priestley (1981) and Rao (1973)).
Furthermore, for all unbiased estimators ˆθi (y) of a speciﬁc parameter θi,
var( ˆθi (y)) ≥Jii (θ)
(13.38)
where Jii (θ) is the ith diagonal element of (I(θ))−1.
Note that, in general, the bound in (13.38) would be diﬀerent for the case of estimating θi when all or some
of the other parameters are given. An exception is the case when I(θ) is diagonal as in Problem 13.2.
v. The calculation of the bound, in general, requires the knowledge of the true parameter θ0. See Example
13.7.
vi. Cramer-Rao’s bound can also be derived for biased estimators using a more general form of (13.31) (see
Exercise E13.6), but the bound depends on the bias. Therefore, it has relatively little use.
Role of Cramer-Rao inequality in identiﬁcation
The Cramer-Rao inequality result oﬀers valuable guidance in identiﬁcation because it quantiﬁes the
(theoretical) impact of experimental factors such as sample size, input excitation and noise levels
on the errors in parameter estimates. Two representative examples are presented to demonstrate the
underlying ideas.
Example 13.7: Estimation of Sinusoid in Noise
Consider the problem of estimating the frequency θ = f0 of a sine wave from its measurement,
y[k] = Asin(2π f0k) + e[k]
e[k] ∼N (0,σ2
e)
(13.39)
for a known amplitude A and noise variance σ2.
Given that the noise follows a Gaussian distribution, it is easy to derive the joint density
of N observations as,
f (y; θ) =
1
(2πσ2e)N/2 exp
*........
,
−1
2
N−1
X
k=0
(y[k] −Asin(2π f0k))2
σ2e
+////////
-
(13.40)

Goodness of Estimators
329
Consequently, the log-likelihood function and the score statistic are
L(θ; y) = −N
2 ln(2πσ2
e) −1
2
N−1
X
k=0
(y[k] −Asin(2π f0k))2
σ2e
(13.41)
S(θ; y) = ∂L
∂θ = 2πA
σ2e
N−1
X
k=0
(y[k] −Asin(2π f0k))(k cos(2π f0k))
(13.42)
The information on θ contained in the N observations is then,
I(θ) = −E
 ∂S
∂θ
!
= 4π2A2
σ2e
N−1
X
k=0
k2 cos2(2π f0k)
(13.43)
Thus, the Cramer-Rao inequality is
var( ˆf0) ≥
σ2e
4π2A2
N−1
X
k=0
k2 cos2(2π f0k)
(13.44)
For a given frequency, as the SNR A2/σ2e becomes larger, the information in the observations
increases, thereby increasing the hope of obtaining a more precise estimate.
However, the actual bound depends on the frequency of the sinusoid. Therefore, the ability
to precisely estimate varies with the frequency itself.
The second example pertains to the estimation of parameters of a linear model from input-output
data.
Example 13.8: Estimating Parameters of an FIR Model
Suppose it is desired to estimate the impulse response coeﬃcients {g[n]} of a process from
input-output data using the FIR model (4.12).
Assume the true process also has an FIR description and that the observations are corrupted
with white-noise. Then,
y[k] =
M
X
n=0
g[n]u[k −n] + e[k],
e[k] ∼N (0,σ2
e)
(13.45)
The parameters of interest are θ =
f
g[0]
g[1]
· · ·
g[N −1]
gT . Assume that u[k] is deter-
ministic and for illustration purposes, that σ2e is known.
Introduce the vector of regressors,
ϕ[k] =
f
u[k]
u[k −1]
· · ·
u[k −M]
gT
(13.46)
As in Example 13.7, the joint p.d.f. of y can be written as
f (y; θ) =
1
(2πσ2e)N/2 exp
*........
,
−1
2
N−1
X
k=0
(y[k] −ϕT [k]θ)2
σ2e
+////////
-
(13.47)

330
Principles of System Identiﬁcation: Theory and Practice
from where the log-likelihood is
L(θ,y) = −N
2 ln(2πσ2) −1
2
N−1
X
k=0
(y[k] −ϕT [k]θ)2
σ2e
(13.48)
The ijth element of the information matrix I(θ) is then
Ii j (θ) = −E
 
∂2
∂θi∂θ j
L(θ,YN )
!
=
N−1
X
k=0
ϕi[k]ϕj[k]
σ2e
Introducing the N × (M + 1) regressor matrix,
ΦN =
f
ϕ[0]
ϕ[1]
· · ·
ϕ[N −1]
gT
from where the information matrix and the C-R inequality are
I(θ) = N
1
N ΦT
N ΦN
σ2e
;
Σ ˆθ ≥σ2e
N
 1
N ΦT
N ΦN
!−1
(13.49)
The quantity 1
N ΦT
N ΦN in the numerator of I(θ) is the covariance matrix (rather an estimate of
it, see (16.26)) of the regressors (inputs) while the denominator represents the noise excitation.
Thus, once again we are presented with the fact that the errors in the parameter estimates are
inversely dependent on the SNR and the data size N. To obtain reliable parameter estimates,
therefore we should maintain a high SNR and acquire as large number of observations as
possible.
In deriving (13.49) we have assumed that the regressors ΦN are given or deterministic.
MVU estimator of an FIR model
Having discovered the bound for the most eﬃcient estimator of the parameters of an FIR model
(with the Gaussian noise assumption), it would be obviously of interest to know whether such an
estimator exists. For this purpose, we invoke (13.37).
First construct the score vector
S(θ,y) =
" ∂L
∂θ1
· · ·
∂L
∂θp
#T
=

N−1
X
k=0
ϕ1[k] (y[k] −ϕT[k]θ)
σ2e
· · ·
N−1
X
k=0
ϕp[k] (y[k] −ϕT[k]θ)
σ2e

T
= 1
σ2e
ΦT
Ny −(ΦT
NΦT
N )θ
(13.50)
Using (13.49) and (13.50),
I−1(θ)S(θ,y) + θ = (ΦT
NΦT
N )−1ΦT
Ny
(13.51)
which satisﬁes the requirements of an estimator of θ.
Thus, the most eﬃcient estimator of the parameters of an FIR model in presence of GWN is
ˆθ⋆(y) = (ΦT
NΦT
N )−1ΦT
Ny
(13.52)

Goodness of Estimators
331
which is a linear estimator. In Chapters 14 and 20, we shall prove that this is also the linear least
squares estimator of the FIR model. Linear estimators have certain obvious beneﬁts vis-a-vis the
non-linear ones. We shall discuss the linear estimators in more detail shortly.
From the examples above, it is apparent that the bound requires the knowledge of the true pa-
rameter value when we have a non-linear model, whereas the bound with a linear model for the
observations with a Gaussian noise density is independent of the true values.
13.7.1
BEST LINEAR UNBIASED ESTIMATOR
An eﬃcient estimator may not always exist; in fact, even a MVUE estimator may not also always
exist. Furthermore, it may be that the p.d.f. is not known impeding the search for a MVU estimator.
In such situations, a practical alternative is therefore to sacriﬁce the minimum variance requirement
and instead search for the best linear unbiased estimator (BLUE). The existence of a BLUE is not
guaranteed, but it requires at most the knowledge of the second-order statistics and not the p.d.f.
as we shall see below. Intuitively, therefore, BLUE may be related to an estimator that assumes a
Gaussian distribution for the noise (or the data).
The requirements of a best linear unbiased estimator are
i. The estimator should be linear
ˆθ(y) = Ay
(13.53)
where A is a matrix of weights that needs to be determined, subject to the conditions below.
ii. The estimator is unbiased, E( ˆθ) = θ0. This constraint translates to a constraint on the weights
AE(y) = θ0
(13.54)
This condition essentially means
E(y) = Lθ0
(13.55)
where L is a matrix such that
AL = I
(13.56)
As an example, in the simple case of estimating the mean of a random process, A is a vector,
θ ∼µ, L is a vector of ones; then
N−1
X
k=0
a1k = 1
(13.57)
Recall that the sample mean satisﬁes this requirement.
iii. It should have the minimum variance (among all linear estimators), i.e., E(( ˆθ −θ0)2) should be
a minimum.
With the third requirement, the optimization (estimation) problem is
min
A trace(E((Ay −θ0)(Ay −θ0)T ))
Using the unbiased requirement (13.54) and the properties of trace, we can re-write the optimization
problem as
min
A trace((AT ΣyA))
s.t.
AL = I
(13.58)

332
Principles of System Identiﬁcation: Theory and Practice
The solution to this optimization problem is (Exercise E13.10)
ˆA⋆= (LT Σ−1
y L)−1LT Σ−1
y =⇒ˆθBLUE = (LT Σ−1
y L)−1LT Σ−1
y y
(13.59)
Example 13.9: BLUE of FIR Model Parameters
Consider the FIR model of Example 13.8. Instead of assuming the p.d.f. of the noise corrupting
the observations y, assume its ﬁrst- and second-order statistics.
E(e) = 0
=⇒E(y) = Φθ
(L = Φ)
Σe = σ2
eIN×N
=⇒Σy = σ2
eIN×N
(uncorrelated errors)
Then, the best linear unbiased estimator of the FIR model parameters are
ˆθBLUE = (ΦT Φ)−1ΦT y
(13.60)
which is the MVUE estimator (and the linear least squares estimator) as well. This coinci-
dence is not surprising since we have assumed a linear model for the observation vector y.
The only diﬀerence is that a distribution of the noise was not required to be known.
A standard generalization of this result is when the errors in the observation have a non-
identity, non-diagonal covariance matrix. Denoting W = Σ−1
e , the estimator is
ˆθBLUE = (ΦT WΦ)−1ΦT Wy
which we shall show later to be the weighted least squares estimator.
From the foregoing example, it is apparent that the BLUE and MVUE coincide whenever the ob-
servations y are governed by a linear model with Gaussian noise. The Gauss-Markov theorem for-
malizes this fact.
13.8
ASYMPTOTIC BIAS
Statistical unbiasedness is a desirable property; however, it is not necessarily the most desirable
property. A biased estimator is also considered acceptable provided the bias vanishes for very large
samples. For this purpose, asymptotic unbiasedness is deﬁned.
Deﬁnition 13.5. An estimator is said to be asymptotically unbiased if
lim
N→∞△ˆθ = 0
i.e.,
lim
N→∞E( ˆθ) = θ0
(13.61)
Remarks:
Asymptotic bias is a large sample property. Therefore it is of little interest in situations concerning
small samples.
A standard estimator of variance
ˆσ2
y = 1
N
N−1
X
k=0
(y[k] −¯y)2
(13.62)
where ¯y is the sample mean, is a biased estimator of σ2
y (see Chapter 16), but is asymptotically
unbiased.
An advantage with using a (statistically) biased estimator is that we can achieve variance lower
than that of a MVU estimator. Estimators encountered in practice fall into two categories: (i) those
that are unbiased but aim to achieve minimum variance (governed by the C-R bound) and (ii) those
that are biased but have lower than the minimum variance. However, for the latter class of estimators,

Goodness of Estimators
333
the variance is no longer a measure for comparing the performance of such estimators since in
principle one can shrink the variance to an arbitrarily low (non-zero) value by increasing the bias to
a very large value. To compare these classes of estimators and recognize this trade-oﬀ, the variance
of the estimator with respect to the true value, known as the mean square error (MSE), is a more
suitable measure. Thus, the best estimator is not necessarily the MVUE, but rather the minimum
mean square estimator (MMSE).
13.9
MEAN SQUARE ERROR
The mean square error (MSE) of an estimator is its variance with reference to its true value θ0.
Deﬁnition 13.6. The MSE of an estimator is deﬁned as
MSE( ˆθ) = E(|| ˆθ −θ0||2
2) = E(
p
X
i=1
( ˆθi −θi0)2)
(13.63)
We now derive a classical result in estimation.
Theorem 13.2
For any estimator ˆθ, the following identity holds
MSE( ˆθ) = trace(Σ ˆθ) + ||△ˆθ||2
2
(13.64)
Proof.
E(|| ˆθ −θ0||2
2) = E(tr(( ˆθ −θ0)( ˆθ −θ0)T ))
= tr(E(( ˆθ −θ0)( ˆθ −θ0)T ))
= tr(E(( ˆθ −E( ˆθ))( ˆθ −E( ˆθ)T )) + tr(E((E( ˆθ) −θ0)(E( ˆθ) −θ0)T ))
+ 2tr(E(( ˆθ −E( ˆθ))(E( ˆθ) −θ0)T ))
= trace(Σ ˆθ) + ||△ˆθ||2
2
The last identity comes about by recognizing the ﬁrst term as the trace of Var( ˆθ) and that E( ˆθ −θ0)
is a deterministic quantity. Consequently the expectation on the second term disappears
tr(E((E( ˆθ) −θ0)(E( ˆθ) −θ0)T )) = tr(△ˆθ△ˆθT ) = tr(△ˆθT △ˆθ) = ||△ˆθ||2
2
and the third term vanishes to zero.
□
Remarks:
1. For unbiased estimators, △ˆθ = 0, therefore MSE and Σ ˆθ are identical.
2. Since both terms on the RHS of (13.64) are positive-valued, estimators that have small MSE naturally
require good accuracy and precision.
3. When MSE( ˆθ) →0 as N →∞, the estimator is said to be consistent (see Section 13.10 below).

334
Principles of System Identiﬁcation: Theory and Practice
13.9.1
MINIMUM MEAN-SQUARE ESTIMATOR
It is ideally desirable to build an estimator ˆθ with minimum mean square error. The MMSE problem
can be set up by assuming the parameter θ to be a random variable. Therefore, this is useful in a
Bayesian estimation framework. The resulting estimator, as it turns out, is the conditional expecta-
tion E(θ|y).
Theorem 13.3
The MMSE of θ given y is the conditional expectation
ˆθMMSE(Y) = E(θ|Y)
(13.65)
We shall prove this result in the prediction theory context in Chapter 18. As in the case of MVUE,
the form of MMSE could be non-linear or linear. For practical reasons, linear MMSE estimators are
more popular. In fact, when θ and y follow a joint Gaussian distribution, the linear MMSE is also
the optimal MMSE. This point is discussed in greater detail in Chapter 18.
We now move on to study an important property of an estimator that is based on MSE.
13.10
CONSISTENCY
One of the expectations of an estimator is that the estimate should “converge” to the true value as
the number of observations increases, i.e., as N →∞. When this is satisﬁed, the estimator is termed
as consistent. Thus, consistency is an asymptotic property of an estimator.
For easy understanding, it is useful to imagine the estimates { ˆθN, N = 1,2,· · · } as an inﬁnite
sequence of random variables. Consistency is concerned with the convergence of this sequence of
random variables to θ0, which is a deterministic quantity. In order to study the consistency properties
therefore, a theory for the convergence of a sequence of random variables is required2. There exists,
at least, three diﬀerent types of convergence of random variables. The type of consistency depends
on the deﬁnition of convergence used.
Regardless of the deﬁnition in use, the main issue is the distance of ˆθ with respect to θ0 for large
sample sizes. Three forms of consistency are popularly used (Kobayashi, Mark and Turin, 2012).
1. Weak consistency: This form is based on the notion of convergence in probability
Deﬁnition 13.7. The estimator ˆθN is said to be consistent if,
lim
N→∞Pr(| ˆθN −θ0| ≥ϵ) = 0
∀ϵ > 0
(13.66)
This is often written as
ˆθN
p
−→θ0
or
plim
N→∞
ˆθN = θ0
(13.67)
The interpretation is that the probability of an estimate far away from the true value shrinks as
the sample size increases.
2Convergence of sequence of random numbers is diﬀerent from that of deterministic numbers

Goodness of Estimators
335
A standard result is the Chebyshev’s weak law of large numbers, which is concerned with the
convergence of the sample mean ¯y to the true (population) mean µy as the sample size increases
(Kobayashi, Mark and Turin, 2012).
This form of consistency is considered weak since convergence in probability does not guarantee
convergence of moments (Kobayashi, Mark and Turin, 2012).
2. Mean-square consistency: The expected distance of the estimate from the true value vanishes
to zero asymptotically.
Deﬁnition 13.8. An estimator ˆθN is said to be mean-square consistent if
lim
N→∞E(( ˆθN −θ0)2) = 0, written as
ˆθN
m.s.
−→θ0
(13.68)
In other words, MSE( ˆθN ) →0 as N →∞.
A mean-square consistent estimate is desirable since it not only implies consistency in probabil-
ity, but also results in
lim
N→∞△θ = 0
lim
N→∞var( ˆθN ) = 0
(13.69)
i.e., asymptotically unbiased and variance-consistent estimate by virtue of (13.64). A (mean-
square) consistent estimator thus need not be unbiased, but is certainly asymptotically unbiased.
On the same note, if an estimate is not asymptotically unbiased, it cannot be mean-square consis-
tent. Unless otherwise explicitly mentioned, by consistency, we shall mean in the mean-square
sense.
Example 13.10: Consistent Estimates of Mean and Variance
The sample mean estimator for a white-noise process e[k] discussed in previous examples
has an MSE
MSE( ¯y) = var( ¯y) = σ2e
N
(13.70)
This is obviously a mean-square consistent estimator since its MSE →0 as N →∞.
The biased estimator of the variance of a random process was shown to be earlier asymp-
totically unbiased. For a GWN process with variance σ2e, the estimator is known to have
a variance
var( ˆσ2
N ) = 2(N −1)σ4e
N2
(13.71)
indicating that the variance goes to zero for large samples. By deﬁnition, therefore it is
mean-square consistent.
Note: In several estimation problems, the mean-square consistency may not apply since the ﬁrst or the
second-order moments of the estimators may not exist. In such situations, the weaker form of consistency
or the following deﬁnition is used.
3. Almost sure (strong) consistency: This deﬁnition stems from the notion of almost sure conver-
gence of sequence of random variables. In probability theory, an almost sure event is that which
has a probability 1, written as w.p.1 (Kobayashi, Mark and Turin, 2012).
Deﬁnition 13.9. An estimator is said to be strongly consistent if it converges almost surely to
the parameter θ0.
ˆθN
a.s.
−→θ0
or
ˆθN −→θ0 w.p.1
(13.72)

336
Principles of System Identiﬁcation: Theory and Practice
This consistency form implies weak consistency (consistency in probability), but not the con-
verse. The strong consistency version of the weak law of large numbers is the Kolmogorov’s
strong law of large numbers, again with respect to sample mean Kobayashi, Mark and Turin
(2012).
There exists another form of convergence, namely, convergence in distribution, which is used in
deriving the asymptotic distribution of estimates. The following section dwells on this topic.
13.11
DISTRIBUTION OF ESTIMATES
Until now we have studied how to quantify the goodness of estimates (estimators) both in a statistical
and in an asymptotic sense. This only constitutes half of the journey though. An equally important
part of the post-estimation exercise is to construct regions containing the true value, of course with
a tinge of uncertainty. The concepts learnt in the previous sections along with the knowledge of
the distribution of estimates comprise the complete set of tools required for this purpose. In this
section, we discuss the concepts pertaining to distribution of estimators in a generic sense. The
actual application to constructing conﬁdence regions is presented in Section 13.12.2.
Knowing the distribution of estimates amounts to deriving the p.d.f. of ˆθN, which is not trivial in
most situations. The distribution of estimate generally depends on three factors:
i. Randomness in observations: This pertains to the joint distribution or density function of the
observation vector y. It is a crucial factor since it is the “feed” to the estimator.
ii. Form of estimator: When the estimator is linear (e.g., sample mean, BLUE estimator) the trans-
formation of the f (y; θ) can be easily studied. Non-linear estimators naturally pose a challenge,
except under very special conditions.
iii. Sample size: The length of the data N has a signiﬁcant impact on the resultant distribution. A
large body of identiﬁcation (and estimation) literature is built on the large sample size assump-
tion. Small sample sizes not only aﬀect the distribution but also the consistency property of an
estimator.
In general, it is possible to derive the theoretical p.d.f. of the estimates for ﬁnite sample sizes only
in a handful of situations. As mentioned above, widely available results are through an asymptotic
analysis.
Multiplication by
√
N
Distributions are quite often stated for
√
N( ˆθ −θ0) (or at times
√
N ˆθN) instead of ˆθN itself. The
reason for this is because asymptotically ( ˆθN −θ0) converges to a constant (mostly zero), whereas
√
N( ˆθ −θ0) converges to a random variable with a meaningful distribution. The sample mean esti-
mator is a classical example in this context. From the previous sections, we know it is a consistent
estimator of the mean, at least for a white-noise process. This means ¯yN −µy converges to zero as
N →∞. On the other hand,
√
N( ¯yN −µy) converges to a random variable with mean zero and
ﬁnite variance.
E( ˆθN ) = µy;
var( ¯y) =
σ2
y
N
=⇒
( ¯y −µy)
m.s.
−→0
(13.73)
but,
√
N( ¯y −µy)
m.s.
−→σ2
y
(13.74)
This is the general situation in parameter estimation problems as we shall learn later. Popular tech-
niques such as least-squares and MLE methods yield parameter estimates that behave in a similar
manner.
One of the most celebrated results in the distribution theory of estimates is the central limit theo-
rem, which is itself based on the general concept of convergence of distribution, as stated below.

Goodness of Estimators
337
Deﬁnition 13.10. A sequence of random variables {XN }, each possessing a distribution function
F(xN ) converges in distribution if the sequence of those distributions {F(xN )} (sometimes written
as FN (x)) converges to a distribution function F(x). The random variable X associated with F(x)
is said to be the limit in distribution of the sequence, indicated as
Xn
d
−→X
(13.75)
Note that the theorem speaks of convergence of distributions, not the random variables them-
selves. Furthermore, this convergence does not guarantee convergence in probability in general,
unless the limiting random variable is a constant (a pathological case).
Now we state the central limit theorem, which was historically ﬁrst studied by the French math-
ematician de Moivre and progressively improved by reputed mathematicians/scientists, namely,
Laplace, Chebyshev, Markov, Lyapunov, Lindeberg and Levy, in that order. The historical devel-
opment essentially resulted in the reﬁnement of restrictions under which the theorem applies, but
the general form of result remained the same.
13.11.1
CENTRAL LIMIT THEOREM
Before stating the formal result, it is important to understand its essence. The theorem essentially
states how the weighted sum of N random variables (not necessarily independent and possessing
identical distributions) converge in distribution as N →∞. Its applicability in identiﬁcation or in
general parameter estimation is useful when we are able to express the estimator in a (approxi-
mately) linear form, either in terms of original observations or transformed observations.
The basic version of the theorem due to Lindeberg and Levy is as follows.
Theorem 13.4: Central Limit Theorem
The uniformly weighted sum of N independent and identically distributed (i.i.d.) random variables
{Xn, n = 1,· · · , N}
¯X =
N
X
n=1
Xn
N
(13.76)
converges in distribution as
√
N
 ¯X −µ
σ
!
d
−→N (0,1)
(13.77)
where
E[Xn] = µ < ∞, var(Xn) = σ2 < ∞,
∀n = 1,· · · , N
(13.78)
Proof. Available in standard texts on statistics. See Kobayashi, Mark and Turin (2012) for instance.
□
Note that the sum is none other than the sample mean of the N random variables.
Remarks:
The conditions of independence and identical distributions are not heavily restrictive. Versions
of CLT that relax these conditions but instead place some minor additional requirements on the moments or
the autocorrelation functions are available (Kobayashi, Mark and Turin, 2012). Thus, the theorem has wider
applicability than what appears to be from its original version.

338
Principles of System Identiﬁcation: Theory and Practice
The multivariate version of this result is stated below without proof.
Theorem 13.5: CLT (Multivariate Version)
Suppose that X1,X2,· · · ,XN are i.i.d. random vectors with mean µ and variance-covariance matrix
Σ. Deﬁne,
¯X = 1
N
N
X
i=1
Xi
(13.79)
Then,
√
NΣ−1/2( ¯X −µ)
d
−→N (0,I)
or
√
N( ¯X −µ)
d
−→N (0,Σ)
(13.80)
Remarks:
1. The CLT is one of the landmark results in statistics, speciﬁcally in inferencing. Given its history and di-
versity of applications, numerous studies have been carried out to investigate its behavior under a variety
of conditions. Generalizations and extensions to other random objects such as matrices and polytopes are
available.
2. In estimation theory, it is extremely useful to derive the distribution of parameter or signal estimates. On
the other hand, the CLT constitutes the standard technique to generate Gaussian distributed variables from
a set of uniformly distributed random numbers.
3. The theorem throws light on why a Gaussian distribution assumption is sometimes justiﬁed for events
whose distributional behavior is completely unknown. If it is assumed that the random variable of interest
is a linear mixture of several other random variables, then a normal distribution is a reasonable choice.
4. It is also conventional to state that the distribution of ¯X is asymptotically normal or simply write as
√
N( ¯X −µ) ∼AN (0,σ2)
(13.81)
5. CLT lends itself to an approximation result in the sense that it provides an idea of how fast the sum converges
in distribution to a Gaussian. It can be shown that the approximation error depends on the skewness and
kurtosis of the random variables {Xi}. Thus for example, the sums of uniformly distributed RVs converge
faster than those of exponentially distributed variables.
6. In light of the previous remark, sums of transformed RVs that have more symmetric distributions and have
lighter tails converge to normal distributions faster than the raw variables.
The CLT provides us with a tool for deriving distributions of parameter estimates from linear
estimators. When the estimator is a complicated function of the observations, further simplifying
approximations or the use of modern (Monte-Carlo) methods such as bootstrapping or surrogate data
analysis have to be employed. For linear system identiﬁcation and the methods used for parameter
estimation, the theory learnt until this point suﬃces. For completeness sake, however, we review the
basic ideas of Monte-Carlo methods in Section 13.13.
13.12
HYPOTHESIS TESTING AND CONFIDENCE INTERVALS
Constructing conﬁdence regions for the true parameters is usually the last, but perhaps the most
important, step in an estimation exercise. The task of developing conﬁdence intervals falls under

Goodness of Estimators
339
the purview of a broader topic in statistics known as hypothesis testing. As the name suggests, it is
concerned with a (statistical) procedure for testing a claim made by the analyst with regards to the
properties of the process of interest or the model parameters using the observations as an evidence.
In order to make a decision to reject or not to reject (“accept”) a hypothesis, a good knowledge of
the theory of Section 13.11 is vital.
13.12.1
HYPOTHESIS TESTING
Hypothesis in statistics is a conjecture or a proposition made by the analyst regarding a statistical
property or a model parameter or any other quantity of interest. The role of hypothesis testing is
to help the analyst in statistically rejecting or not rejecting the hypothesis using the observations.
Clearly, these observations should contain information on the parameter(s) under investigation.
In system identiﬁcation, the hypothesis that we would be often interested in is that a set of model
parameters are actually zero valued, i.e., the model is of a lower complexity than the chosen one.
Another hypothesis of interest is that two models are equal, which is usually tested using their
respective sum-square prediction errors. In time-series analysis, a common hypothesis is that the
given series is white, i.e., the ACF is zero-valued at all non-zero lags or that the spectral density is
ﬂat. These hypotheses give birth to what are known as signiﬁcance levels for parameter estimates. A
generalization of the signiﬁcance level calculation leads to the problem of constructing conﬁdence
regions.
Note: The phrase “accepting the hypothesis” is technically not used due to the manner in which these tests are
carried out.
A hypothesis test typically consists of the following steps:
1. Formulate the null hypothesis H0. Choose an appropriate alternate hypothesis Ha.
2. Choose an appropriate statistic ζ for the test. The statistic is generally a linear or non-linear
function of the parameter(s) involved in the hypothesis.
3. Compute the test statistic from the given observations. Denote this by ζo.
4. Make a decision. Reject or do not reject the null hypothesis depending on whether the observed
statistic falls in a “critical” region or not.
The determination of critical region depends on (i) the distribution of the statistic (under the null
hypothesis) (ii) the error that we wish to minimize and (iii) the alternate hypothesis. An important
input required for hypothesis test is the true or the hypothesized value of the parameter, which is
supplied by the analyst.
The error that is typically minimized is the so-called Type 1 error, which corresponds to the
probability of wrongly rejecting H0 even when it is true. Conventionally this error is termed as the
signiﬁcance level, α (should not be confused with the signiﬁcance levels of estimates). The critical
regions are the upper tail, lower tail or both the lower and upper (two) tails of the distribution
depending on whether the alternative hypothesis corresponds to very large, very small or both very
small and large values of the statistic, respectively. The small and large qualiﬁers are relative to the
critical value ζc as determined by α and the distribution as described below.
Upper tail test : Pr(ζ ≤ζc) = 1 −α
(13.82)
Lower tail test : Pr(ζ ≤ζc) = α
(13.83)
Two-tail test : Pr(ζ ≤ζc1) = α/2; and Pr(ζ ≤ζc2) = 1 −α/2
(13.84)
where the probabilities are computed under the null hypothesis being true.

340
Principles of System Identiﬁcation: Theory and Practice
p-value based test
An alternative way of performing the hypothesis test is based on the p-value, which is the proba-
bility of observing a more extreme value of the statistic than the observed value. The probability is
computed under the null hypothesis being held to be true. The sign or the direction of the extreme
value depends on the alternate hypothesis just as the way the critical value does. The p-value com-
putation is fairly straightforward. For example, in an upper tail test, the p-value is the Pr(ζ ≥ζo).
If the p-value ≤α, then H0 is rejected.
Regardless of the method adopted, the basic goal in a hypothesis test is to determine if the obser-
vations carry evidence that refute the null hypothesis.
The test statistic acts like the magnifying lens through which we search for evidence, while the
critical value serves in decision making. By default, H0 is assumed to be true, which also explains
why distributions of test statistics and critical values are constructed under the same assumption.
Hypothesis testing is often compared and explained in the context of a jury’s decision in a court-
room, where H0 is that the accused is innocent. It is the responsibility of the prosecutor to provide
ample evidence that can refute H0. Literature is abundant with numerous semi-formal articles and
textbooks that oﬀer illuminating insights into this topic (Johnson, 2011; Montgomery and Runger,
2011; Ogunnaike, 2010).
We shall use two numerical examples to understand the concepts explained above.
Example 13.11: Testing Average Temperature
An engineer measures the (controlled) temperature of a reactor over a period of 3 hours at
a sampling interval of Ts = 15 sec. The sample average of the N = 720 readings is calculated
to be ¯y = 90.1826◦C. Based on this observation, the engineer claims that the temperature is
at its set-point T0 = 90◦C on the average. Suppose we wish to test this claim.
Then, the formal hypothesis test is set up as follows.
H0 : µy = 90
Ha : µy , 90
In this situation, the procedure calls for a two-tailed test.
Assume that the temperature series has white-noise characteristics (we shall learn later
how to test this assumption as well). Then we know that for the large sample case,
√
N
 ¯Y −µ
σ
!
d
−→N (0,1)
Thus, an appropriate test statistic suited for the purpose is
ζ = ¯y −µ0
σ/
√
N
(13.85)
where µ0 is the true value assumed in H0. For the example, µ0 = T0 = 90◦C. For illustration
purposes, we shall assume that σ is known to be 2◦C (see note following the example).
The observed value of the statistic is then ζo = 2.45. The critical value of this statistic
at a signiﬁcance level α = 0.05 is ζc = 1.96. The interpretation is that the probability of
obtaining |ζ| greater than 1.96 is less than 0.05 if the temperature was truly at its set-
point on the average. Since ζo > ζc, the null hypothesis, i.e., the engineer’s claim that the
reactor temperature is at the set-point on the average stands rejected in favor of the alternate
hypothesis.
Note: The assumption of known σ can be relaxed. We can instead estimate σ from data, in which case the
statistic follows a Student’s t-distribution with ν = N −1 degrees of freedom. When the d.o.f. is large ν > 30,
however, the t−distribution manifests as a Gaussian distribution.

Goodness of Estimators
341
The next example is concerned with testing for correlation between two signals.
Example 13.12: Testing Zero-Correlation for Delay Estimation
In an eﬀort to determine the delay D of a pure-delay system, an input u[k] with white-noise
characteristics was injected. N = 500 samples of the resulting response y[k] were collected.
From Example 8.4, we know that under white-noise inputs, the correlation between the
lagged input u[k −l] and output is theoretically zero at all lags except at lag l = D. With
this background, the user computes the correlation ρyu[l] between u[k −l] and y[k] at lags
l ∈[−10,10] using the following expression,
ˆρyu[l] =
ˆσyu[l]
p ˆσyy[0]ˆσuu[0]
(13.86)
where ˆσyu[l] = 1
N
N−1
X
k=l
(y[k] −¯y)(u[k −l] −¯u), l ≥0
(13.87)
The resulting estimates are shown in Figure 13.4. The dashed lines are the consequence of
hypothesis testing as explained below. It is now required to test for zero correlation at each
−10
−5
0
5
10
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Lags
Cross−correlation
FIGURE 13.4
Cross-correlation function of the series in Example 13.12.
of these lags (visually it is easy to spot the delay, but the purpose is to show the formal way
of testing correlations).
Correlation estimate between two jointly Gaussian distributed RVs X and Y is known to
be asymptotically distributed as (see §16.3)
√
N( ˆρ −ρ)
d
−→
N (0,(1 −ρ2)2)
(13.88)
where ρ is the true correlation. Applying this result at each lag and setting the true correlation
to ρ = 0, the estimate at each lag is distributed as
p
N −|l| ˆρ ∼N (0,1)
(13.89)
At small lags |l| << N, √N −|l| ≈
√
N. The distribution under the assumptions can then be
written in the more conventional form,
ˆρ ∼N (0,1/N)
(13.90)
The task at hand is to test the hypothesis,
H0 : ρyu[l] = 0
Ha : ρyu[l] , 0

342
Principles of System Identiﬁcation: Theory and Practice
This is a two-tailed test. From (13.89), the critical value for the statistic ζ = ˆρ at α = 0.05
signiﬁcance is ζc = 1.96/
√
N = 1.96/
√
500 = 0.0877. If the correlation coeﬃcient at any lag
is greater than this critical value in magnitude, then that coeﬃcient is termed as signiﬁcant.
The critical limits are shown as dashed lines in Figure 13.4. For the delay estimation problem
since we are given that the input is white, the search is for a single signiﬁcant coeﬃcient.
The estimate at lag l = 4 is the only signiﬁcant correlation coeﬃcient, thus allowing us to
conclude beyond any reasonable doubt that the delay is D = 4.
Remarks:
i. If the input was colored noise, then the search would be for the peak value.
ii. More importantly, colored inputs produce colored outputs. Consequently, the limits on the correlation co-
eﬃcient at each lag changes and depends on the auto-correlation structure at each lag.
iii. When the objective is to test only the correlation coeﬃcient (i.e., cross-correlation at lag l = 0), the distri-
bution in (13.88) is traditionally re-written using Fisher’s transformation,
ˆγ = 1
2 log
 1 + ˆρ
1 −ˆρ
!
√
N( ˆγ −γ) ∼N (0,1)
(13.91)
which is commonly used to conduct the hypothesis test.
Signiﬁcance tests
The tests of hypothesis similar to that in the foregoing example, i.e., H0 : θ = 0 are also known as
signiﬁcance tests since they amount to testing whether the obtained estimate should be considered
signiﬁcant or not. The phrase has also been used in general to denote a hypothesis test. When a null
hypothesis is rejected, the estimate is (statistically) signiﬁcant, and the converse - when H0 is not
rejected, the estimate is not signiﬁcant.
The signiﬁcance level α also acquires its name for a similar reason. It can be also interpreted as
the critical p-value or the threshold on the probability of obtaining a statistic more extreme than the
observed. In the Example 13.11, the p-value is 0.0071, which is lesser than the chosen threshold
α = 0.05. Even at a signiﬁcance level of α = 0.01, the null hypothesis would be rejected.
In general, the result of a hypothesis tests can be quite sensitive to the choice of signiﬁcance
level. For this reason, it is important to specify the signiﬁcance level along with the outcome of a
hypothesis test. Finally, statistical signiﬁcance of an estimate should not be confused with the actual
physical signiﬁcance of that parameter, which is a completely diﬀerent concept.
13.12.2
CONFIDENCE REGIONS
We return to the problem of making conﬁdence statements about the true parameter, albeit in sta-
tistical terms. Technically, we would like to obtain set estimates rather than merely point estimates.
These sets are usually in terms of intervals or regions associated with a certain degree of conﬁdence.
Therefore they acquire the name conﬁdence regions.
Note: Note that the notion of a true parameter is usually a ﬁction since the original process is typically more
complex than the assumed model that the parameters of the model may have no appearance in the actual process
descriptions. Nevertheless, for the purposes of testing an estimation algorithm, we introduce the notion of a
true parameter.
The procedure for constructing a conﬁdence interval is a two-step process. First, construct a prob-
abilistic interval for the error ˆθN −θ0 using the knowledge of the distribution (or density) of ˆθN, the
bias and variance properties. In the second step, convert this probabilistic interval into a conﬁdence
region for θ0. The procedure is illustrated on the standard mean estimation problem below. Deriva-
tions of conﬁdence regions for other parameter estimation problems appear at their respective points
of discussion.

Goodness of Estimators
343
Conﬁdence interval for mean
Assume that the sample mean ¯y is used as an estimator of the mean µy. Our goal is to obtain a
conﬁdence region for µy given a single record of data.
For the present we shall assume that the true variance σ2
y is known. This is not binding on the
result in any signiﬁcant way. From Section 13.11 we know that
√
N
 ¯y −µy
σy
!
∼N (0,1)
(13.92)
Using the properties of a Gaussian distribution,
−1.96 ≤
√
N ¯y −µy
σy
≤1.96
(with 95% probability)
=⇒µy ∈[¯y −1.96
√
N
σy, ¯y + 1.96
√
N
σy]
(with 95% conﬁdence)
(13.93)
Notice that we use the term conﬁdence instead of probability as soon as we talk of µy. The reason
is that the true parameter is deterministic and hence to talk of probability is not meaningful.
The 100(1 −α)% CI for the mean is
µy ∈[¯y −ζc
σy
√
N
, ¯y + ζc
σy
√
N
]
(13.94)
where ζc is the critical value such that the standardized Gaussian distributed variable ζ has a Pr(ζ >
ζc) = α/2.
Interpretation
The conﬁdence interval (CI) should be interpreted with care. Consider the case of a 95% CI for
mean.
Suppose that we have 1000 records of data, from each of which we can obtain an estimate
¯y(i),
i = 1,· · · ,1000. For each such estimate we could construct the interval in (13.93). Then,
out of 1000 such CIs, roughly 950 intervals would have correctly captured the true mean. In other
words, there is a 5% chance that the interval in (13.94) does not contain the true mean. The same
explanation applies to a general 100(1 −α)% CI as well.
Figure 13.5(a) shows the conﬁdence intervals for the mean of a zero-mean white-noise process
obtained from 1000 realizations. Each realization gives rise to a conﬁdence interval. A plot of the
lower limit vs. upper limit of the interval reveals the number of intervals that do not capture the
true mean, µ0 = 0. For the case study, it turns out that 51 intervals (22 in the ﬁrst and 29 in the
third quadrant) do not contain zero. These intervals with the corresponding realization indices on
the vertical axis are shown in Figure 13.5(b).
With reference to (13.94), a few useful remarks follow.
Remarks:
i. The width of the CI is only dependent on the standard error in the estimate σy/
√
N, which is, in turn
dependent on the variability of the process and 1/
√
N.
ii. The narrower the width of the interval at a ﬁxed α, the better is the estimator. A consistent estimator
produces zero-width CI asymptotically. Therefore as we collect more samples, our ability to conﬁne the
true parameter to a smaller interval increases.
iii. When the variance of the process has to be estimated from the data, the (normalized) sample mean follows
a t-distribution.
¯y −µy
ˆσy/
√
N
∼t −distribution with (N −1) d.o.f.
(13.95)

344
Principles of System Identiﬁcation: Theory and Practice
−0.2
−0.15
−0.1
−0.05
0
0.05
−0.05
0
0.05
0.1
0.15
0.2
Lower limit of the CI
Upper limit of the CI
(a) 95% CIs from 1000 realizations
−0.2
−0.15
−0.1
−0.05
0
0.05
0.1
0.15
0.2
0
100
200
300
400
500
600
700
800
900
1000
Interval
Realization index
(b) Intervals that miss the true mean
FIGURE 13.5
Plot of 95% conﬁdence intervals (for mean) from 1000 realizations; 51 of these intervals do not
contain the true mean µ0 = 0.
The C.I. should be then constructed accordingly. However, when N is relatively large, the t-distribution
behaves like a Gaussian distribution. Therefore (13.94) still applies, but by replacing σ with ˆσ.
iv. For correlated processes, the CI has to be re-derived because var( ¯y) is inﬂuenced by the correlation struc-
ture.
In any estimation problem, the degree or level of conﬁdence in the CI and the width of the interval
have a direct relationship. Increasing the conﬁdence also results in a larger width. A 100% CI will
have ideally an inﬁnite width (or the maximum width as dictated by the p.d.f. of the statistic), which
is of little or no use. For the vector of parameters case, the width is characterized by the volume of
the conﬁdence region or set.
Using CIs for signiﬁcance or hypothesis tests
The conﬁdence interval is commonly used for conducting signiﬁcance tests, i.e., hypothesis of the
form H0 : θ = θ0, Ha : θ , θ0. The idea is to construct the CI at the same signiﬁcance level and
then to check whether θ0 is contained in the interval.
Applying this idea to Example 13.11, we obtain the CI for µ as [90.0365,90.3827]. The CI does
not contain the test value µ0 = 90 and therefore the null hypothesis stands rejected, a conclusion
identical to that of the example.
In closing, it should be noted that we have used the mean estimation case as an example to high-
light the diﬀerent facets of conﬁdence intervals. Construction of conﬁdence regions in general de-
pends on the parameter(s) of interest, the estimator and the knowledge of the distribution of the
associated statistic. These aspects will become clearer in due course of the text as we discuss diﬀer-
ent parameter estimation problems associated with a variety of models and signals using the popular
estimation algorithms.
It is appropriate to conclude this chapter with an overview of empirical methods for determining
the distribution of parameter estimates and hypothesis testing.
Listing 13.1
MATLAB code for generating Figures 13.5(a) and 13.5(b)
% Initialize variables
ybar = []; var_y = []; ci_low = []; ci_up = [];
% Generate data and compute CIs
for i = 1:1000,
yi = randn(1000,1);
ybar = [ybar; mean(yi)];
var_y = [var_y; var(yi)];

Goodness of Estimators
345
ci_low = [ci_low ; ybar(i) - 1.96*std(yi)/sqrt(1000)];
ci_up = [ci_up ; ybar(i) + 1.96*std(yi)/sqrt(1000)];
end
% Plot the CIs in 2-D space
figure; plot(ci_low,ci_up,’x’)
hold on
plot([-0.2 0.05],[0 0],’r--’)
plot([0 0],[-0.05 0.2],’g--’)
% Plot the CIs
figure
ind_neg = find(ci_up < 0); ind_pos = find(ci_low > 0);
ind_tot = [ind_neg ; ind_pos];
plot([ci_low(ind_tot) ci_up(ind_tot)]’,[ind_tot ind_tot]’,’-o’)
hold on; plot([0 0],[0 1000],’k--’);
13.13
EMPIRICAL METHODS FOR HYPOTHESIS TESTING
In Section 13.11, we learnt the traditional means of deriving distributions. However, there exist nu-
merous situations where the form of the estimator is too complex to be handled by conventional
methods. This also complicates the subsequent problems of hypothesis testing and construction of
conﬁdence regions. In all those cases, a natural alternative is to empirically determine the distri-
bution from the given data by generating artiﬁcial or pseudo-realizations. The generated data are
commonly known as surrogate data or pseudo-population.
Generation of surrogate data can be done in two diﬀerent ways:
1. Monte-Carlo method: Simulate the model that is believed to represent the population to which
the observed data belongs. Choose a diﬀerent realization of the randomness in each run. They
are typically parametric in nature, meaning the stochastic part of the data is parametrized using
a p.d.f. and a time-domain model. For example, an moving-average model is ﬁt to a time-series
data. Using this model and the estimated variance of the WN, one can artiﬁcially generate several
data sets to study the variability in parameter estimates.
The term Monte-Carlo was ﬁrst coined by Metropolis and Ulam (1949) in their work on simula-
tions using random walks (also see Eckhardt (1987)). Since then, the ideas have been extended
to other applications, statistical inferencing being one of them.
2. Bootstrap method: This method is non-parametric in nature. The basic idea is to generate the
data using the concept of resampling with replacement. The pool of possibilities is provided by
the data. A new data set is created by randomly drawing an observation from the readings. Sam-
pling without replacement essentially means that the set of possibilities for the next observation
includes the same set of samples each time. Thus, the surrogate data could contain groups of
identical observations.
As an example, if
y = {0.1450,0.8492,0.3575,0.4822,0.6107}
is the single record of data, two possible bootstraps with replacement are
y(1) = {0.8492,0.8492,0.4822,0.4822,0.6107}
y(2) = {0.6107,0.1450,0.3575,0.4822,0.3575}
In practice, hundreds of such surrogate data sets are generated. Variants of this basic idea are
deployed to suit particular applications and hypotheses. One of these variants is the parametric
bootstrap method, which ﬁrst ﬁts the parameters of a distribution and then uses the ﬁt to generate
data. This has of course a strong semblance to the Monte-Carlo method.

346
Principles of System Identiﬁcation: Theory and Practice
For each of the generated data set, data statistics and model estimates are obtained. These quanti-
ties are then subject to study the probability distributions of the statistics as well as model parame-
ters. For instance, if the 1000 realizations of Example 13.5 were generated using one of the above
methods, the sample mean obtained from each pseudo-record could be subject to a histogram analy-
sis to determine its distribution and variability. The theoretical expressions in Sections 13.3 and 13.4
would be no longer required. The critical values required for hypothesis tests are also determined
from the empirical distributions.
Empirical methods present numerous challenges in data generation as well as empirical determi-
nation of the required statistics. A major concern is their high sensitivity to the method in which
the surrogates are generated. In this respect, it is important to take into account the hypothesis that
is being tested. A useful guideline is that the surrogate data should preserve certain properties of
the original time-series while lacking the property that is being investigated, which is in turn dic-
tated by the null hypothesis. The number of trials and a good discriminatory statistic also play a
critical role. Finally, the computational burden of these methods can become a serious factor for
high-dimensional data sets and parameters. Despite these challenges, several interesting advances
and applications of these methods have emerged in the last decade. Read Baldacchino, Anderson
and Kadirkamanathan (2013), Garatti and Bitmead (2010), and Ninness and Henriksen (2010) for
some recent developments and applications of resampling techniques and MCMC simulations in
system identiﬁcation.
13.14
SUMMARY
Knowing how well an estimator performs is perhaps as important as the task of estimation itself.
Without a knowledge of the properties of the estimator, it is hard to place much faith in the estimate.
For this purpose, we studied key properties such as bias, variance, mean square error and large-
sample properties such as asymptotic bias and consistency. Among these the variability of estimates
and the consistency of an estimator are the key properties. In this context, the C-R bound provides
a lower bound on the variability of the most eﬃcient estimator. The inequality also provides con-
ditions for the existence of the most eﬃcient estimator and a method for deriving the same (if it
exists).
The Fisher’s information matrix addresses a fundamental question on the information content
available in the observations with respect to the parameter(s) of interest. The model form and the
number of parameters can signiﬁcantly aﬀect the information available for each parameter, which
in turn inﬂuences the quality of the estimates.
Hypothesis testing and conﬁdence region constructions, two essential tasks of statistical infer-
encing, require the knowledge of the distribution of parameter estimates. These distributions can
be analytically derived for certain simple estimators using the fundamental central limit theorem.
However, the problem can be complicated in numerous other situations. Empirical methods based
on surrogate data generation using Monte-Carlo and bootstrap techniques can be used to arrive at
empirical distributions. These methods should be used with care because of a lack of clear under-
standing in how the settings and user’s choices in these algorithms leverage the ﬁnal inference.

Goodness of Estimators
347
13.A
APPENDIX
13.A.1
PROOF OF CRAMER-RAO INEQUALITY
Starting from the unbiased assumption,
Z
( ˆθ −θ0) f (y; θ) dy = 0
=⇒∂
∂θ
Z
( ˆθ −θ0) f (y; θ) dy = 0
=⇒−
Z
f (y; θ) dy +
Z
( ˆθ −θ0) ∂f (y; θ)
∂θ
dy = 0
−→
Z
( ˆθ −θ0) ∂ln f (y; θ)
∂θ
f (y; θ) dy = 1
−→
Z
( ˆθ −θ0)
p
f (y; θ) ∂ln f (y; θ)
∂θ
p
f (y; θ) dy = 1
(13.A.1)
Using Cauchy-Schwartz inequality for two functions g1(y) and g2(y),
Z
g2
1(y) dx
Z
g2
2(y) dy ≥
 Z
g1(y)g2(y) dy
!2
Setting g1(y) = ( ˆθ −θ0)
p
f (y; θ) and g2(y) = ∂ln f (y; θ)
∂θ
p
f (y; θ), the desired result is obtained
Z
( ˆθ −θ0)2 f (y; θ)
Z  ∂L(y; θ)
∂θ
!2
f (y; θ) dy ≥1
=⇒var( ˆθ(y)) ≥
1
E *
,
 ∂L
∂θ
!2
+
-
(13.A.2)
The remaining part of the result
−E
 ∂2L
∂θ2
!
= E *
,
 ∂L
∂θ
!2
+
-
is proved below.
Using the fact that the pdf is regular,
E
 ∂
∂θ ln f (y; θ) dθ
!
=
Z  ∂f (y; θ)
∂θ
1
f (y; θ)
!
f (y; θ) dθ = 0
The last identity is obtained by interchanging the order of integration and diﬀerentiation.
REVIEW QUESTIONS
R13.1 Describe the notions of bias and variance.
R13.2 Explain the basic diﬀerences between the variance and mean-square error of an estimator.
R13.3 Deﬁne Fisher’s information matrix and explain the underlying philosophy.

348
Principles of System Identiﬁcation: Theory and Practice
R13.4 What is Cramer-Rao’s bound and its role in estimation theory?
R13.5 Explain the term consistency in estimation. How many types of consistency are normally studied
and what are the diﬀerences between them?
R13.6 Is consistency an asymptotic or a statistical property?
R13.7 Why is eﬃciency important in estimation?
R13.8 Can an eﬃcient estimator always be determined?
R13.9 Explain what is meant by best unbiased linear estimator.
R13.10 Discuss suﬃciency of an estimator with an example.
R13.11 What is meant by “distribution of an estimate?” Why is it important to know this quantity?
R13.12 Discuss the role of Central Limit Theorem in deriving the distribution of linear estimators.
R13.13 What makes it diﬃcult to derive the distribution of non-linear estimators?
R13.14 Explain the central idea in bootstrapping methods for determining the distribution of estimators.
R13.15 Describe the basic steps in hypothesis testing.
R13.16 What is meant by “conﬁdence region” or “conﬁdence interval” in the context of estimation?
R13.17 Explain the connections between conﬁdence interval determination and hypothesis testing.
EXERCISES
E13.1 Derive the expression for the variance of the sample mean ¯v = 1
N
PN−1
k=0 v[k] when v[k] is generated
by an MA(M) correlated stationary process. Verify that your answer simpliﬁes to (13.25) when v[k]
is a WN process.
E13.2 Verify your result in E13.1 by means of Monte Carlo simulations for an MA(1) process: x[k] =
e[k] + 0.4e[k −1].
E13.3 Show that there exists no eﬃcient estimator for estimating the parameter λ of a WN process
with exponential distribution f (λ) = λe−λy.
E13.4 Following the above problem, show that the inverse of the parameter 1/λ can be estimated
eﬃciently.
E13.5 Prove that for a GWN process, the sample mean is a suﬃcient estimator of the mean.
E13.6 Derive the C-R bound for a biased estimator. Show that the result simpliﬁes to that of an unbiased
estimator.
E13.7 Using simulations verify that the sample mean is a consistent estimator of the mean. For simplicity,
choose the WN process as the reference process.
E13.8 Show that a single sample of N observations of a white-noise process is an unbiased estimator of
the mean, but is not a consistent estimator.
E13.9 Given N observations of a stationary process {v[k]}, two diﬀerent estimators of mean are proposed:
(i) a random observation, ˆµv = v[k],k ∈[0, N −1]
(ii) weighted average of any two observations, ˆµv = w1v[k1] + w2v[k2], k1,k2 ∈[0, N −1],w1 , w2
(iii) weighted average of all observations: ˆµv =
N−1
X
k=0
wkv[k], wi , wj
Answer the following:
a. Are these estimators unbiased? If not, suggest additional requirements/modiﬁcations on the
estimators such that they are unbiased.
b. For each of the above estimators (with the unbiased conditions in part (a)), which assess their
goodness w.r.t. the sample mean in the sense of var( ˆµ) (or the width of conﬁdence interval),
given that v[k] is white-noise.

Goodness of Estimators
349
E13.10 Derive the best linear unbiased estimator in (13.59).
E13.11 Obtain the best linear unbiased estimator of the mean. Does it coincide with the sample mean?
What inferences can you draw from the comparison?
E13.12 Repeat the above exercise for estimating the variance. Does it exist? If no, ﬁnd a suitable
transformation of data and determine the BLUE of variance with the transformed data.
E13.13 A quality inspector was responsible for testing the claim made by a car tire manufacturer that
the outer diameter of the tire is µ = 21.5 cm. For this purpose, 76 sample tires were collected at
random to note that the sample mean is ¯x = 22.22 cm with a sample variance s2 = 0.26 cm2. Can
the quality inspector refute the manufacturer’s claim?
E13.14 In an air-pollution study, the following amount of benzene-soluble organic matter (in micrograms
per cubic meter) were obtained for eight diﬀerent samples of air:
conc.
2.2
1.8
3.1
2
2.4
2
2.1
1.2
Assuming that the population sampled is normal, construct a 95% conﬁdence interval for the corre-
sponding true mean.
E13.15 Siddhu wishes to estimate the parameter α in x[k] = αy[k], but instead he ﬁts y[k] = βx[k]
and then uses ˆα = 1/ ˆβ to solve the problem. Is this a correct way of estimating α? Support your
answer suitably.

14
Estimation Methods: Part I
This chapter is the ﬁrst of the two chapters that review four powerful estimation philosophies.
Two among these, namely, least squares and the maximum likelihood estimation methods,
attract more attention than the rest. The present chapter is devoted mainly to the presentation
of the least squares class of methods with a brief review of the method of moments and its
generalized class. The subsequent chapter reviews the principles of maximum likelihood and
Bayesian estimation techniques. The main objective is to present the foundational ideas with
illustrative examples. Properties of these estimators are discussed in detail. The presentation
is mainly generic; applications to dynamics models are presented in Part IV. A thorough
understanding of these methods is necessary in choosing the appropriate estimator for a given
model and application.
14.1
INTRODUCTION
In the previous two chapters (Chapters 12 and 13) we learnt the general concepts of estimators
and the means to analyze their goodness. An important message from those chapters is that there
exists more than one way to estimate the parameters (unknowns). Each estimator diﬀers in the
objective function and the assumptions that it makes on the data, which in turn have a direct impact
on the quality of the estimates. The C-R inequality states the conditions under which an eﬃcient
estimator can be found. In the least, we should be using a best linear unbiased estimator. Chapter 12
showed how diﬀerent objectives or estimation cost functions lead to diﬀerent forms of estimators
with varying solutions and properties. In principle, there exist innumerable methods for estimation.
However, it suﬃces to study four classes of methods considering their wide usage, universal appeal
and that most of the existing methods can be cast into one of these forms.
The four classes of methods are the method of moments (MoM) or its generalized version (GMM),
least squares (LS), maximum likelihood estimation (MLE) and Bayesian methods. The ﬁrst three
classes of estimators belong to the family of extremum estimators, i.e., estimators that maximize or
minimize a cost criterion. Among these, of particular interest are the LS and MLE methods because
of their wide applicability and their versatility. The method of moments is less sophisticated than
these two approaches, but can oﬀer good starting solutions for initializing the non-linear algorithms
such as non-linear LS and MLE. Bayesian methods on the other hand are relatively recent and yet to
gain the same intensity of applicability as the LS and MLE methods. Nevertheless they are futuristic.
Keeping in view the vastness and the depth of these techniques, for instructional purposes, the
presentation is divided into two chapters. In the ﬁrst part, i.e., this chapter, the focus is on the least
squares methods with a brief tour of the MoM, while the second part contained in Chapter 15 is
devoted to MLE and Bayesian estimation techniques. The division of the material is also justiﬁed
from the viewpoint that both LS and MoM do not demand the knowledge of the p.d.f. for estimation
purposes, whereas MLE and Bayesian methods are entirely set up in the probabilistic framework.
In both chapters, the purpose is to lay down the basic ideas governing these methods, derive the
generic solutions and illuminate upon the overall performance of these estimators.
The chapters to follow present application of these methods to estimation of signal properties
(Chapter 16), time-series models (Chapter 19) and input-output models (Chapters 20 and 21). In
the application to parameter estimation of dynamic models, speciﬁc issues arise. These aspects are
discussed in the respective chapters of Part IV. An interesting fact as we shall learn later is that
350

Estimation Methods: Part I
351
the LS and MLE methods can be uniﬁed under a single banner of prediction-error methods. The
prediction-error approaches also accommodate other estimation techniques such as the instrumental
variable and error-in-variable methods.
The presentation of the estimation methods in these twin chapters is restricted to the multiple-
input single-output class of processes. Extensions to multivariable systems is not diﬃcult, but are
more eﬀectively handled in the state-space domain. Identiﬁcation of state-space models is based
on the projection approaches, known as the subspace methods in Chapter 23. At the heart of these
approaches once again we ﬁnd the permeation of the LS and MLE concepts. Multivariate input-
output modeling techniques using principal component analysis and partial least squares ﬁnds a
signiﬁcant place in identiﬁcation. The former technique is discussed in §26.3. Needless to say, these
techniques are also built on the basic ideas of least squares. Thus, a clear comprehension of the
estimation methods in Chapters 14 and 15 is essential to the understanding of all the subsequent
chapters in this text.
We begin our journey with the method of moments estimation approach.
14.2
METHOD OF MOMENTS ESTIMATORS
The method of moments (MoM), as the name suggests, is based on the moments of the joint density
function of the observations.
14.2.1
BASIC IDEA
The basic premise is that the theoretical relationships between the moments (of pdf) and the param-
eters of interest are also satisﬁed by the sample moments and estimates. If p parameters have to be
estimated, then we develop expressions for p moments and solve for the unknowns by replacing the
theoretical quantities with their estimated versions.
It is based on the more general idea of equating functions of distributions to functions of parame-
ters. Given N observations {y[1],· · · , y[N]}, where y[k] is described by a distribution F(y[k]), we
set up the equations
hi(F(y[k])) = gi(θ)
i = 1,· · · ,p
(14.1a)
or in general, ηi(F(y[k]),θ) = 0,
i = 1,· · · ,p
(14.1b)
where gi(.), hi(.) and ηi(.) are the ith user-chosen functions of the parameters θ and the distribu-
tion F(.), respectively. The method of moments emerges by choosing hi(.)’s (or ηi(.)’s) to be the
moments,
hi(F) = Mi( f ) ≜E(Y i) =
Z
yi dF =
Z
yi f (y) dy
(Ensemble average)
(14.2)
Using what is known as substitution principle, we replace the ensemble averages with their time-
domain averages and solve p equations
ˆMi( f ) = 1
N
N−1
X
k=0
yi[k]
(Time average)
(14.3)
gi( ˆθ) = ˆMi( f ) = 1
N
N−1
X
k=0
yi[k]
(14.4)
An advantage of the method of moments is that it does not require the knowledge of the distribution
of data as in MLE.

352
Principles of System Identiﬁcation: Theory and Practice
Estimating mean and variance using MoM
The simplest among the estimation problem is that of the mean, θ = µy, which is also the ﬁrst
moment. Choosing g(θ) = θ, we have
θ = µ = M1(F)
ˆθ = ˆµ = ˆM1 = 1
N
N−1
X
k=0
y[k]
(14.5)
which is none other than the sample mean ¯y.
Properties: In the previous chapter, we learnt that the sample mean is an unbiased estimator of the
mean. It is also consistent and eﬃcient when y[k] is GWN. For correlated processes, it is consistent
but not an eﬃcient estimator.
The variance of a white-noise process can be estimated in a similar way. Start by noting
σ2
y + µ2 = M2
Replacing the theoretical values with their estimates, we have thus
ˆσ2
y = ˆM2 −ˆM2
1
= 1
N
N−1
X
k=0
y2[k] −*
,
1
N
N−1
X
k=0
y[k]+
-
2
yielding
ˆσ2
y = 1
N
N−1
X
k=0
(y[k] −¯y)2
(14.6)
Properties: The estimator in (14.6) is asymptotically unbiased and consistent. It shall be shown later
that this is also the maximum likelihood estimate.
MoM for estimating a linear model
Given N input-output observations, consider ﬁtting an auto-regressive exogenous (ARX) model
using the method of moments. The model is described by the diﬀerence equation (see Chapter 17)
y[k] + a1y[k −1] = b1u[k −1] + e[k]
(14.7)
where {e[k]} is a zero-mean, white-noise process.
Assume that the input u[k] has the characteristics of a random signal. The technique for parameter
estimation remains the same, that is, to match the theoretical moments with the sample moments.
The choices of appropriate moments hold the key. We need at least two equations to estimate the two
unknowns θ = [a1 b1]T. Among the many diﬀerent ways of setting up these equations, a common
way is based on the requirement that the one-step ahead prediction errors, ε(k,θ) = y[k] −ˆy[k|k −
1,θ] be free of any linear eﬀects of the “regressors”, y[k −1] and u[k −1]. In other words, the second
moment (covariance) of the joint distributions of (y[k −1],ε(k,θ)) and (u[k −1],ε(k,θ)) be both
zero. The one-step ahead prediction errors for the ARX model are derived in §18.3. Assuming
innovations to be zero-mean, the theoretical requirements are thus,
E(y[k −1]ε(k,θ)) = 0
=⇒E(y[k −1](y[k] + a1y[k −1] −b1u[k −1])) = 0
(14.8)
E(u[k −1]ε(k,θ)) = 0
=⇒E(u[k −1](y[k] + a1y[k −1] −b1u[k −1])) = 0
(14.9)

Estimation Methods: Part I
353
which can be re-arranged as
" σyy[0]
−σyu[0]
−σyu[0]
σuu[0]
# "a1
b1
#
=
"−σyy[1]
σyu[1]
#
(14.10)
Replacing the theoretical ones with their sample versions, we obtain the MoM estimates of a1 and
b1,
ˆθ⋆
MoM =
" ˆσyy[0]
−ˆσyu[0]
−ˆσyu[0]
ˆσuu[0]
#−1 "−ˆσyy[1]
ˆσyu[1]
#
(14.11)
where the estimates of the covariance functions are obtained using
ˆσx1x2[l] = 1
N
N−1
X
k=l
(x1[k] −¯x1)(x2[k −l] −¯x2),
l ≥0
(14.12)
A numerical example follows.
Example 14.1: Estimating an ARX Model with MoM
Input-output data consisting of N = 2046 observations are obtained through the simulation
of an ARX process. A snapshot of the data is shown in Figure 14.1.
Assume that the input-output delay is known to be d = 1 sampling interval (alternatively
an FIR model estimate can fetch this information). The goal is to ﬁt an ARX model of
the form (14.7) using MoM. Computing the necessary covariances in (14.11), we obtain the
0
100
200
300
400
500
−10
0
10
Output
0
100
200
300
400
500
−1
0
1
Input
Time (sec)
FIGURE 14.1
Snapshot of the input-output data used in estimation of the ARX model.
estimates as,
ˆa1 = −0.6933; ˆb1 = 2.0133
which are very close to the true values used in the simulation.
a1,0 = −0.7; b1,0 = 2
An appropriate way of verifying the goodness of these estimates is to perform a residual
analysis. This is left as an exercise to the reader.
Remarks:
The zero-correlation conditions used in arriving at the estimates, as we shall observe later, are
identical to those used in least squares methods. These are also the optimality conditions for obtaining best
approximations of functions in a lower-dimensional basis space (projection theorem).

354
Principles of System Identiﬁcation: Theory and Practice
Listing 14.1
MATLAB code used in Example 14.1
% Generate data
proc_mod = idpoly([1 -0.7],[0 2],1,1,1,’Noisevariance’,1);
% Input design
uk = idinput(2046,’prbs’,[0 0.4],[-1 1]);
% Measurement with SNR approx 10
ykstar = sim(proc_mod ,uk);
proc_mod.Noisevariance = (1 - 0.49)*var(ykstar)/10;
yk = sim(proc_mod ,uk,’Noise’);
% Estimate using MoM
[sigma_mat ,lags] = xcov([-yk uk],1,’biased’);
cov_mat = reshape(sigma_mat(2,:),2,2);
cov_rhs = sigma_mat(3,1:2)’;
% Use pseudo-inverse or backslash
theta_mom = pinv(cov_mat)*cov_rhs;
In the identiﬁcation literature, MoM leads to the so-called correlation methods. Refer to §20.2.2
for an application of this method to estimation of impulse response coeﬃcients and §21.7 for a
generic theory of correlation methods in identiﬁcation. One of the early applications is in the esti-
mation of time-series models, especially auto-regressive models. The resulting method leads to what
are popularly known as Yule-Walker equations (recall §9.5.2). Section 19.2.1 presents the technical
details of the Y-W method.
Generalized method of moments
The method of solving an exact set of equations given in (14.4) can be generalized to a minimization
problem by (i) relaxing the requirements that the sample moments exactly satisfy the relations as
theoretical moments and (ii) incorporating more moments than necessary. This is the idea underlying
Hansen’s pioneering work on generalized method of moments (GMM) estimators (Hansen, 1982).
θ⋆
GMM = arg min
θ
|| ˆηηη(Z,θ)||2
W
(14.13)
where || ˆηηη||2
W = ˆηηηTW ˆηηη is a weighted-norm (or a distance measure), Z is the set of observed data and
ˆηηη is the vector of functions constructed using the moment conditions as
ηi(Z[k],θ0) ≜E(gi(Z[k],θ0)) = 0
(14.14)
=⇒ˆηi(Z,θ) = 1
N
N−1
X
k=0
gi(Z[k],θ)
i = 1,· · · ,P > p
(14.15)
For instance, in the estimation of parameters of the ARX model presented earlier, Z is the input-
output data, θ = [a1 b1]T and
g1(Z[k],θ) = y[k −1](y[k] + a1y[k −1] −b1u[k −1])
(14.16a)
g2(Z[k],θ) = u[k −1](y[k] + a1y[k −1] −b1u[k −1])
(14.16b)
with P = 2 (exact set of equations) and setting the norm to a regular 2-norm, i.e., W = I2×2.
A more general formulation involves the use of ηηη(Z,ζζζ,θ), where ζζζ are auxiliary variables known
as instruments (see §21.7.1). One of the main advantages of the GMM estimators over the MLE is

Estimation Methods: Part I
355
that they can accommodate more moment conditions than necessary, i.e., the over-identiﬁed case.
Furthermore, where the distribution of the data is known, GMM can be computationally lighter than
the MLE counterparts. In general, these estimators yield asymptotically normal, consistent, but not
necessarily eﬃcient estimates. Eﬃciency (asymptotic) is achieved only with an appropriate choice
of the weighting matrix W. These characteristics are similar to that of a weighted least-squares
method as shall learn shortly. The optimal choice of the weighting matrix will also be detailed at
that point of discussion. Interestingly, GMM also contains the methods of generalized least squares
and maximum likelihood estimation, which precede GMM historically by at least a century or two
(Hamilton, 1994).
The GMM estimator is widely applied in the ﬁelds of economics and ﬁnance, its birthplace, where
the regressors or the explanatory variables are all prone to uncertainties. Applications of GMM to
system identiﬁcation have been very scarce partly because well-established and rigorous methods
based on LS and MLE concepts were already in place. Furthermore, the instrumental variables (IV)
method, conceived about at least ﬁfty years before GMM, was already in vogue to address the case
of explanatory variables contaminated with errors. One of the advantages that GMMs are known
to possess is that they can handle partially speciﬁed models, which potentially ﬁnds applications in
grey-box modeling. The reader is referred to the rich literature on the use of generalized method of
moments in empirical modeling as a direction of exploration and uniﬁcation of several ideas (see
Hamilton (1994) for an excellent exposition).
We study next the most widely used method of estimation, the least squares method, based on the
principle of minimizing the sum-square distance between the target function and its approximation.
14.3
LEAST SQUARES ESTIMATORS
The idea underlying the method of least squares, as intuitive as it appears today, was formally in-
troduced at least two centuries ago. Largely credited to Gauss (1795), it was ﬁrst published by Leg-
endre. The grass roots of this method are in the ﬁelds of astronomy, where a data-driven approach
using the least-squares principle was used to predict the trajectory of an asteroid (Gauss, 1809). In
what followed, every ﬁeld of theoretical analysis and empirical approximation witnessed an explo-
sion of its applications. Numerous variants and generalizations of the least-squares approach have
been proposed, studied and applied (Abdulle and Wanner, 2002). Today it is an indispensable tool
in all data-driven approaches to prediction, modeling, control, monitoring, etc.
The governing principles of LS method can be introduced in diﬀerent ways depending on the con-
text. In functional (data) analysis, it is introduced with the idea of a (squared) distance-minimizing
approximation, while in statistical analysis it is presented as an variance-of-errors minimizing pre-
dictor. Both these versions are reviewed in this text. In addition, the diﬀerent variants of least squares
are also studied. The presentation is fairly generic in nature, but adorned with a few illustrative ex-
amples. Speciﬁc applications to estimating dynamic models are discussed in subsequent chapters.
14.3.1
ORDINARY LEAST SQUARES
The plain version of least squares with no frills or rather minimal assumptions is termed as ordinary
least squares (OLS). An important point to note is that the core problem addressed by the OLS can
be completely described in a functional approximation setting, without invoking any randomness
in the data. This is unlike the method of moments or the MLE which primarily assume that the
observations contain random eﬀects. Nevertheless, to assess the properties or the quality of the
OLS estimator, it becomes necessary to make assumptions about the random nature of the errors of
approximation or in the data.
The sample least squares version of OLS directly formulates the problem in terms of N observa-
tions. It possesses a higher practical appeal than the theoretical version that we shall study shortly.
Justiﬁably our journey begins at this point.

356
Principles of System Identiﬁcation: Theory and Practice
Sample LS problem
The problem statement is as follows.
Given N observations of a variable y =
f
y[0]
· · ·
y[N −1]
gT, obtain the best prediction
(or approximation) of y using p explanatory variables (or regressors) ϕi[k], i = 1,· · · ,p
such that the predictions ˆy =
f
ˆy[0]
ˆy[1]
· · ·
ˆy[N −1]
gT are collectively at a minimum
(vectorial) distance from y.
Observe that we require the entire observation vector to be at a minimum distance from its ap-
proximation, and not each observation from its respective prediction. The explanatory variables ϕ’s
could be any known variable that is believed to contain information on y. The problem of selecting
appropriate regressors has been studied quite extensively and continues to be a problem of interest.
In identiﬁcation, the regressors are usually the past outputs and / or the lagged inputs. While in
inferential (soft) sensing, the explanatory set consists of the physical variables whose measurements
are available and presumably contain information about the variable of interest. We shall study a
standard problem known as the regression, where the regressors are treated in a generic manner.
The statement of the LS problem is complete with a speciﬁcation of “how” y[k] is being predicted,
i.e., when a model is speciﬁed. Depending on whether a linear or a non-linear model is used, the
problem acquires the name linear / non-linear least squares or linear / non-linear regression. A
major advantage of the linear LS over the non-linear counterpart is that the ﬁnal solution is unique,
a global optimum and has a closed-form expression, which is established below. The linear LS is
presented ﬁrst.
Linear model
Assume that the approximation of y[k] is through a linear model,
ˆy[k] =
p
X
i=1
θiϕi[k] = ϕT[k]θ
(14.17)
where θ is the unknown set of free parameters that have to be optimized to achieve the least squares
objective.
Introduce
Φ =
f
ϕ[0]
ϕ[1]
· · ·
ϕ[N −1]
gT
(14.18)
Z = y ∪Φ
(14.19)
Since each ϕ[k] is a p×1 vector, Φ is a N × p matrix. The matrix Z simply consists of all the known
data.
The optimization problem can thus be written
min
θ
JN (Z,θ) = ||y −ˆy||2
2 = (y −ˆy)T (y −ˆy)
s.t. ˆy = Φθ
which can be solved in diﬀerent ways, (i) standard method of setting gradients dJ/dθ = 0, (ii) com-
pleting sum of squares and (iii) the projection theorem, also known as the orthogonality principle.
We shall adopt the third approach while leaving the ﬁrst two as exercises to the reader (see Exercise
E14.4).

Estimation Methods: Part I
357
The projection theorem is stated in Appendix 14.A.1. Its essence is that the optimal (2-norm sense)
approximation of y is that one whose residual is orthogonal to the approximation. In particular, it is
orthogonal to every basis that spans the approximation. In other words, the optimal predictor does
not leave anything in the residuals that can be predicted using the regressors.
In the present context, the basis vectors are the regressors. Thus, the solution is realized by requir-
ing
⟨ϕi,ε⟩= 0
=⇒ϕT
i (y −Φθ) = 0
i = 1,· · · ,p
(14.20)
All the p equations can be jointly written as
ΦT (y −Φθ) = 0
yielding the familiar solution
ˆθ⋆
LS = (ΦTΦ)−1ΦTy
(14.21)
which is identical to the estimator (13.52) of Example 13.8 that was derived by imposing eﬃciency
conditions on the parameter estimates of an FIR model. Comparing terms, the regressors of the
FIR model are essentially the present and past inputs and the parameters are the impulse response
coeﬃcients. Moreover, Example 13.52 was derived in a stochastic setting, whereas (14.21) is in a
functional approximation setting.
With a minor manipulation of terms, (14.21) is also identical to the MoM estimator derived earlier
for an ARX model, as will be shown shortly.
Remarks:
i. In the problem setting and solution derived above, the index k has been assumed to denote time stamps of
measurements. However, this is in no way binding since k could be treated in a more generic fashion. It
could denote a point on the frequency or the spatial grid. In several other situations, k could also represent
the index of diﬀerent sensors measuring the same variable at a ﬁxed spatial location or frequency.
ii. Further to the remark above, even when k stands for time, it could be that it denotes readings of y at diﬀerent
steady states.
Projections / predictions and residuals
The optimal prediction of y is
ˆyLS = Φ ˆθ⋆
LS = Φ(ΦTΦ)−1ΦTy = Py
(14.22)
and the associated residuals are
εLS = y −ˆyLS = (I −Φ(ΦTΦ)−1ΦT )y = P⊥y
(14.23)
where
P = Φ(ΦTΦ)−1ΦT
and P⊥= I −P
(14.24)
are said to be the projection matrix and its orthogonal complement, respectively. The latter name is
due to the fact that
PP⊥= P⊥P = 0
(14.25)
The notions of projection and its orthogonal complement are critical to the development of subspace
identiﬁcation algorithms for modeling state-space models (see Chapter 23).

358
Principles of System Identiﬁcation: Theory and Practice
Matrix inversion perspective
The LS estimator can be thought of as a solution to a set of linear overdetermined equations since p
unknowns are being estimated from N equations while forcing the prediction ˆy to match y
y ≈Φθ
(14.26)
Pre-multiplying both sides by ΦT yields
ΦTy = (ΦTΦ)θ
(14.27)
which are also known as the normal equations.
Note: Strictly speaking, we are solving y = Φθ + ε. Imposing ΦT ε = 0 eliminates the errors and also sets up
the exact set of equations in (14.27).
Now introduce the pseudo-inverse
Φ† = (ΦTΦ)−1ΦT
(14.28)
so that the LS solution can be written as
ˆθ⋆
LS = Φ†y
(14.29)
The reason for terming Φ† as the pseudo-inverse is apparent from a comparison with the standard
solution to an exact set of equations. The quantity Φ† is also known as the Moore-Penrose inverse
of Φ.
Based on the discussion up to this point, a fact stands out clearly.
The minimization of sum-square (quadratic) prediction errors with a predictor that is linear in
the unknowns results in a linear estimator.
This is perhaps the strongest reason for the popularity of the LS estimators.
Population or theoretical LS: linear case
The population or the theoretical LS problem is concerned with the best (variance-minimizing)
(inear) approximation of a random variable Y using p random variables ϕi. Connections with sample
version can be established by imagining the observation vector y to represent N samples of Y and
similarly for the regressors.
The statement of the problem follows.
min
θ
J(Z,θ) = E((Y −ˆY)2)
s.t. ˆY =
p
X
i=1
θiϕi
The stochastic equivalent of the projection theorem, known as the decomposition theorem (see Ap-
pendix 14.A.2) can be used to solve the optimization problem. The main ramiﬁcation of this theorem
is that the conditional expectation E(Y |X) is the optimal predictor of Y (given X) in the mean-square
error sense and that the associated residual is uncorrelated to the (function) of regressors.
Collecting all the p regressors into ϕ =
f
ϕ1
· · ·
ϕp
gT and applying the uncorrelated condition,
we obtain the well-known normal equations
cov(ϕ,ε) = cov(ϕ,Y −ϕTθ) = 0
=⇒Σϕϕθ = ΣϕY
(14.30)

Estimation Methods: Part I
359
from which the theoretical solution emerges
θ⋆
LS = Σ−1
ϕϕΣϕY
(14.31)
An interesting point to note from the results is that the set of overdetermined equations in the sample
domain transforms to a set of exact equations in the covariance domain.
% MATLAB commands (routines) to implement LS estimator
pinv, \, qr
regress
% Statistics Toolbox
Equivalence of OLS with MoM
Consider y and Φ to be N samples of Y and ϕ, respectively. Then, replacing the theoretical covari-
ances (moments) with their respective sample versions (estimates) produces
ˆΣϕϕ = 1
N ΦTΦ;
ˆΣϕY = 1
N ΦTY
(14.32)
which then yields the LS solution for the sample version
ˆθ⋆
LS =
 1
N ΦTΦ
!−1  1
N ΦTy
!
(14.33)
Thus, (14.21) is the MoM solution obtained by using the moments condition in (14.30). The major
diﬀerence is that the LS solution falls out of a nicely formulated optimization problem, whereas
the MoM estimator falls out of a pre-speciﬁed moments condition. However, the equivalence shows
that with an appropriate choice of moments, the MoM estimate can yield minimum mean square
prediction error estimates.
The following example illustrates the use of LS method in estimating an FIR model from input-
output data.
Example 14.2: Estimating the IR Coefﬁcients Using the LS Method
Input-output data comprising N = 510 samples of a process excited with a PRBS input
switching between -1 and 1 is available. A snapshot of the data is shown in Figure 14.2(a).
An FIR model is chosen as a suitable representation of the process. For this purpose, a
p = M = 11 coeﬃcient FIR model
ˆy[k] =
M−1
X
n=0
g[n]u[k −n]
is ﬁt to the data using the least-squares method. The output vector and the regression matrix
are constructed (in MATLAB® notation) as follows (keeping in mind that the predictor can
only be written for k = M −1,· · · , N −1):
y =
f
y[M]
y[M + 1]
· · ·
y[N −1]
gT
Φ =
f
u[M : N]
u[M −1 : N −1]
· · ·
u[1 : N −M]
g
where the notation u[M : N −1] denotes the input vector spanning samples from k = M −1
to k = N −1 instants. Thus, eﬀectively only (N −M) observations are available for estimation.
The LS estimates are plotted in Figure 14.2(b). From the estimates, we can safely infer that
the generating process is stable and has a delay of 2 samples. At a later stage (post §14.3.3),
we shall use a statistically sound approach to determine the ﬁrst signiﬁcant IR coeﬃcient.

360
Principles of System Identiﬁcation: Theory and Practice
50
100
150
200
250
−2
−1
0
1
2
Time
Output
50
100
150
200
250
−1
−0.5
0
0.5
1
Time
Input
(a) Input-output data
0
2
4
6
8
10
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Lags
IR coefficients
(b) Estimates of IR coeﬃcients
FIGURE 14.2
Input-output data and parameter estimates of the FIR model of Example 14.2.
The process used for simulation is also described by an FIR representation
y[k] = 0.3u[k −2] + u[k −3] + 0.5u[k −4] + 0.2u[k −5] + e[k]
(14.34)
where e[k] ∼N (0,σ2e) and σ2e = 0.2277 (so that SNR is set to 10). Observe that the delay of
2 samples is correctly detected by the estimated FIR model.
It is encouraging to know that we are able to discover the structure of the governing model
and the coeﬃcient values merely from the data through a systematic identiﬁcation approach.
Listing 14.2
MATLAB Code for Example 14.2
% Process
Gp = idpoly(1,[0 0 0.3 1 0.5 0.2],1,1,1,’Noisevariance’,1,’Ts’,1);
% Generate input
uk = idinput(510,’prbs’,[0 0.4],[-1 1]);
N = length(uk);
% Simulate the process
xk = sim(Gp,uk);
Gp.Noisevariance = var(xk)/10;
yk = sim(Gp,uk,’Noise’);
% Plot the input-output data
zk = iddata(yk,uk,1);
% Estimate 11 IR coefficients of a FIR model
% Construct output vector
M = 11;
Y = yk(M:end);
% Construct regressors
Phimat = [];
for k1 = 0:M-1,
Phimat
= [Phimat uk(M-k1:end-k1)];
end
% OLS estimates of IR models
ir_est = pinv(Phimat)*Y;
% Predictions
Yhat = Phimat*ir_est;
% ACF of residuals and CCF between residuals and inputs

Estimation Methods: Part I
361
[acfval,lags] = xcov(Y-Yhat,20,’coeff’);
[ccfval,lags] = xcov(Y-Yhat,uk(M:end),20,’coeff’);
Diagonal covariance matrix
A special case arises when the regressors are uncorrelated, i.e., when the covariance matrix Σϕϕ
is diagonal, resulting in decoupled normal equations. The advantage is that the parameters can be
estimated individually:
ˆθi = σϕiY
σ2ϕi
(14.35)
Further, it avoids the ills associated with matrix inversions. This is the scenario in the LS estimation
of impulse response coeﬃcients from data generated using white-noise inputs. See §20.2.2.1 for
details.
Including the constant term
The problem setting thus far has ignored the possibility of having an intercept term or a constant β
in the regression model. Including such a term in the model can be done by merely appending the
regressor with a vector of ones as seen below.
y[k] = ϕT[k]θ + β =
f
ϕ[k]
1
gT "θ
β
#
(14.36)
On the other hand, the LS estimate of β can be obtained sequentially by ﬁrst obtaining ˆθLS followed
by,
ˆβLS = ¯y −¯ϕT ˆθLS
(14.37)
where ¯y and ¯ϕ are the sample means of y[k] and the regressors, respectively. When ¯y = 0 and
¯ϕ = 0, ˆβLS = 0. Consequently, when regression is carried out with deviation variables, the need for
including a constant term is obviated. This is usually the procedure that is followed in practice.
The estimate in (14.37) follows a more general result from partial (linear) regression due to Frisch
and Waugh (1933), known as the Frisch-Waugh-Lovell theorem.
Theorem 14.1: Partial Regression, Frisch and Waugh (1933) and Lovell (1963)
In the linear least squares regression of y on two sets of variables ϕi and ϕj,
ˆy[k] = ϕT
i [k]θi + ϕT
J [k]θj
(14.38)
the LS estimates of parameters θj can be determined given the LS estimates of other parameters θi
as follows
ˆθj,LS = (ΦT
j Φj)−1ΦT
j y −(ΦT
j Φj)−1ΦT
j Φi ˆθi,LS
= (ΦT
j Φj)−1ΦT
j (y −Φi ˆθi,LS)
(14.39)
Proof. See Greene (2012).
□

362
Principles of System Identiﬁcation: Theory and Practice
Some useful remarks follow.
Remarks:
i. The parameter estimates corresponding to ϕj are the result of regressing the residuals εi (from the regres-
sion of y on the other subset i) onto ϕj.
ii. Equation (14.37) can be easily derived from (14.39) by setting ϕj[k] = 1. Then (ΦT
j Φj)−1 = 1/N, ΦT
j y =
PN−1
k=0 y[k] and ΦT
j Φi = PN−1
k=0 ϕT [k].
iii. From the result, it follows that when the regressor subsets are orthogonal (uncorrelated), i.e., ΦT
j Φi = 0,
the corresponding parameters can be estimated separately.
iv. Finally, the theorem is useful in step-wise regression where the regressors are included one-by-one and the
associated parameters have to be estimated.
14.3.2
GOODNESS OF LS FITS
An important step in modeling is to assess the model for its “goodness” post-estimation. This step
reveals any model deﬁciencies or shortcomings and also provides directions for improvements, if
necessary. In general, there are two questions associated with the estimation of any model:
1. How well has the model (of the speciﬁed structure) explained (predicted) the output? For a given
structure and data, the quality of prediction solely depends on the estimation algorithm. This is
the focal topic of this section, speciﬁcally for the LS method.
2. Is there a need to reﬁne the chosen model structure? This is a broader question, which requires the
use of model diagnostic measures, speciﬁcally pertaining to residual analysis. The primary tools
are cross-correlation of residuals with inputs, auto-correlation of residuals, and cross-validation.
For the model in Example 14.2, the correlation plots are shown in Figures 14.3(a), 14.3(b) and
14.4, respectively. The basic requirements are that no signiﬁcant correlation exists between the
−20
−15
−10
−5
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
Lags
CCF
(a) CCF between ε and u
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
(b) ACF of residuals
FIGURE 14.3
CCF σεu[l] and ACF σεε[l] plots associated with the model estimated in Example 14.2.
residual and inputs, and that the residuals possess white-noise characteristics. Both plots conclu-
sively indicate that there is no further need for making improvements to the model. Expressions
for computing the signiﬁcance levels are provided in Chapter 16, while the measures themselves
are discussed in Chapter 22.
We now return to the ﬁrst point of interest above and review the widely used R2 measure, also
known as the mean square (MS) measure of ﬁt.

Estimation Methods: Part I
363
R2 Measures
To derive the measure, we begin with the basic decomposition of the measurement
y[k] = ˆy[k] + ε[k]
(14.40)
Evaluating the variance on both sides and using the key fact that predictions and residuals from LS
estimated models are orthogonal to each other, we have
var(y[k]) = var( ˆy[k] + ε[k]) = var( ˆy[k]) + var(ε[k])
(∵cov( ˆy,ε) = 0)
(14.41)
The sample version of the above identity is also true,
N−1
X
k=0
(y[k] −¯y)2
|             {z             }
sum square total (SST)
=
N−1
X
k=0
( ˆy[k] −¯y)2
|             {z             }
sum square predictions (SSP)
+
N−1
X
k=0
ε2[k]
|     {z     }
sum square errors (SSE)
(14.42)
where ¯y is the sample mean of the predicted variable.
The term on the LHS is independent of the choice of parameters and ﬁxed for a given data. On
the other hand, the goal in LS term is to minimize the SSE. The identity in (14.42) thus gives rise to
an interesting viewpoint:
In an eﬀort to minimize the squared distance between the prediction and observation vectors,
the LS method attempts to maximize the variance of output explained by the regressors.
Therefore, it is natural to deﬁne a goodness measure, traditionally known as the coeﬃcient of deter-
mination and denoted by R2, as follows
R2 ≜SSP
SST = 1 −
N
X
k=0
ε2[k]
N−1
X
k=0
(y[k] −¯y)2
= 1 −
||ˆy −y||2
2
||y −¯y||2
2
(14.43)
Remarks:
i. From (14.43) and (14.42) it follows that
0 ≤R2 ≤1
(14.44)
ii. Equation 14.42 is the basis for the analysis of variance (ANOVA) in regression exercises.
iii. Although introduced in the context of least squares, the concept of R2 can also be used with other model
ﬁtting methods. However, if the applied method does not fulﬁll (14.42), then R2 value can be greater than
unity.
iv. The measure can also be shown to be as the squared correlation between the predictions and observations
(see Exercise E14.5).
v. It is necessary to include a constant term in model (one in the regression vectors) to correctly compute R2
as a measure of ﬁt. However, if the constant term turns out to be statistically insigniﬁcant, then there is no
eﬀect on the computed value.
vi. R2 has a poor sensitivity with respect to inclusion (or exclusion) of additional regressors. Thus, it cannot be
used to determine the suﬃciency or suitability of a variable in explaining the output.

364
Principles of System Identiﬁcation: Theory and Practice
vii. In order to address the above issue, an adjusted R2 based on the mean square rather than sum squares is
used,
¯R2 = 1 −SSE/(N −p)
SST/N −1
= 1 −N −1
N −p (1 −R2)
(14.45)
where the factors (N −1) and (N −p) denote the degrees of freedom associated with the SST and SSE
respectively. The adjusted R2 can assume negative values unlike the classical R2.
With the incorporation of average version, the adjusted R2 essentially measures the balance achieved be-
tween the loss of degrees of freedom due to the inclusion of additional regressors (increased variability of
estimates) and the improvement achieved in the ﬁt (decreased prediction bias).
viii. The adjusted R2 is only an elementary metric for evaluating the balance between reduction in bias (predic-
tion error) and increase in variance (of parameter estimates). In practice, sophisticated measures based on
information theory such as AIC and SIC (see §22.6.3) are employed.
The R2 value for the 11-coeﬃcient FIR model of Example 14.2 is computed as 0.9094, while the
adjusted R2 value is 0.9074.
Alternative measure of ﬁt: NRMS
A drawback of the R2 measure is that its value does not necessarily reﬂect the visually observed
“ﬁt,” mostly depicting an inﬂated picture. Therefore an alternative measure of ﬁt based on the non-
squared (regular) norm is sometimes used
Rf = 1 −||ˆy −y||2
||y −¯y||2
(14.46)
This is termed as the normalized root mean square (NRMS) goodness of ﬁt. For the model of
Example 14.2, the value of Rf is 0.7, which gives a better (than R2 or ¯R2) picture of the ﬁt as shown
in Figure 14.4.
0
50
100
150
200
250
300
350
−3
−2
−1
0
1
2
3
4
Samples
Prediction
 
 
Predicted
Observed
FIGURE 14.4
Predictions vs. measurements.
In practice, the “suﬃciency” and “reliability” of a model is measured using indices such as Akaike
information criterion (AIC) and Mallows Cp statistic (Rao, 1973). See also §22.6.3. Any goodness
of ﬁt metric can only provide a bird’s eye view of the model quality but cannot provide ﬁner details
such as accuracy, precision, conﬁdence regions for parameters, etc. The following section caters to
these issues.

Estimation Methods: Part I
365
14.3.3
PROPERTIES OF THE LS ESTIMATOR
Assume that the data generating process (DGP, recall §12.3.1) is:
DGP:
y[k] = ϕT[k]θ0 + ξ[k]
(14.47)
where θ0 is the true parameter vector, ϕT[k] is the regressor and ξ[k] contains the unobserved
stochastic term that collectively represents the eﬀects of unmeasured disturbances and noise. It is
also conventional to call ξ[k] as the equation error1. As we shall see shortly, the properties of ˆθ
depend on the nature of ξ[k] and its correlation with the regressor, ϕ[k].
The prediction error or the residual incurred in using a LS estimate of θ is
ε[k] = y[k] −ˆy[k] = y[k] −ϕT[k] ˆθ = ϕT[k] ˜θ + ξ[k]
(14.48)
where ˜θ is the parameter estimation error, given by
˜θ = θ0 −ˆθ = θ0 −(ΦTΦ)−1ΦT (Φθ0 + ξξξ) = −(ΦTΦ)−1ΦTξξξ
(14.49)
Observe that the prediction error for a given data is never equal to the equation error ξ[k] but addi-
tionally contains contributions from the “diﬀerence” between the true and the estimated parameter.
Consequently, the properties of the residual depends on the characteristics of these two terms.
Note: Sometimes, a distinction is observed between prediction error and residual. The former is used in the
context of fresh data, while the latter with the training data. In this text, these terms are used interchangeably. In
most situations, the analysis of residuals or prediction errors is with respect to the training data except during
cross-validation, where the evaluation of the model’s performance is on a fresh data set.
We are now set to discuss the properties of the LS estimator.
1. Bias: This is concerned with the accuracy of the LS estimator. For the estimator to be accurate
(unbiased), it is required that E( ˜θ) = 0. Two separate cases arise, depending on the nature of Φ.
Deterministic Φ (e.g., FIR models with deterministic inputs): The estimator is unbiased if
E(ξ[k]) = 0. This fact is easily realized by taking expectations on both sides of (14.49).
Stochastic Φ (e.g., ARX or ARMAX models): The LS estimator is unbiased whenever the equa-
tion error ξ[k] in the process is uncorrelated with the regressor vector, ϕ[k].
To establish this result, ﬁrst recall from iterative expectation
E( ˜θ) = EΦ(E( ˜θ|Φ))
(14.50)
Evaluating the inner expectation,
E( ˜θ|Φ) = E((ΦTΦ)−1ΦTξξξ|Φ) = (ΦTΦ)−1ΦT E(ξξξ|Φ)
It follows that whenever E(ξξξ|Φ) = 0, i.e., equation error and regressor are uncorrelated,
E( ˜θ|Φ) = 0. The stronger requirement is that the regressor ϕ[k] be independent2 of ξ[k] and
E(ξ[k]) = 0. Then,
E( ˜θ) = E(−(ΦTΦ)−1ΦTξξξ) = −E((ΦTΦ)−1ΦT )E(ξξξ) = 0
1A generalization of this notion is the observation error, that shall be introduced in Chapter 17.
2When two RVs X1 and X2 are independent, E(g1(X1)g2(X2)) = E(g1(X1))E(g2(X2)).

366
Principles of System Identiﬁcation: Theory and Practice
Example 14.3: Accuracy of FIR Model Estimates
In Example 14.2 the LS method was applied to the estimation of impulse response coeﬃ-
cients of an FIR model. Then, according to the above result, estimates are guaranteed to
be accurate whenever the data generating process is
y[k] =
M−1
X
n=0
g0[n]u[k −n] + ξ[k]
and (i) it is under open-loop conditions and (ii) the input does not inﬂuence the error ξ[k]
(and vice versa), regardless of whether ξ[k] is colored or white.
Under closed-loop conditions, the input is correlated to ξ[k] due to feedback and hence
biased estimates result. This is one of the challenges in closed-loop identiﬁcation.
The next example is representative of a typical scenario in identiﬁcation where biased estimates
result even under open-loop conditions.
Example 14.4: Bias in the Estimation of ARX Model
Suppose that the generating process is governed by an auto-regressive, moving average,
eXogenous (ARMAX) description, (see Section 17.5):
y[k] = −a10y[k −1] + b10u[k −1] + e0[k] + c10e0[k −1]
(14.51)
Comparing with (14.47), the equation error ξ[k] is colored.
ξ[k] = e0[k] + c10e[k −1]
Now consider the scenario that the user chooses to ﬁt an ARX model (these models are
commonly used)
y[k] = −a1y[k −1] + b1u[k −1] + e[k]
(14.52)
to the data, i.e., essentially assumes that the regressor set is
ϕ[k] =
f
−y[k −1]
u[k −1]
gT
(14.53)
and that the equation error is white. Then the regressor and equation error of the process,
ξ[k], are correlated because y[k −1] carries eﬀects of e0[k −1]. Thus, the LS estimates of
a1 and b1 are biased (inaccurate).
In Section 21.7.1, we shall come across a technique known as instrumental variable method
that produces unbiased estimates of the parameters, while still enjoying other properties
of the LS estimator.
Whenever the estimates are biased, the value of the bias depends on the extent of correlation
between ϕ[k] and ξ[k].
2. Variance: From the study of the material in previous chapter, this is one of the most deﬁning
properties of an estimator.
It is useful to ﬁrst derive the conditional variance, i.e., var(θ|Φ) because the result can handle
both deterministic and stochastic cases (of Φ). Further, recall that since θ is a vector, its variance
is a matrix Σ ˆθ with the variance of the individual parameters along the diagonal,
var( ˆθ|Φ) = E(( ˆθ −θ0)( ˆθ −θ0)T |Φ)
= E((ΦTΦ)−1ΦTξξξξξξTΦ(ΦTΦ)−1|Φ)
= (ΦTΦ)−1ΦT ΣξξξΦ(ΦTΦ)−1

Estimation Methods: Part I
367
where Σξξξ is the N × N variance-covariance matrix of ξξξ, the equation error vector. When ξ[k] is
stationary,
Σξξξ =

σ2
ξ
σξξ[1]
· · ·
σξξ[N −1]
σξξ[1]
σ2
ξ
· · ·
σξξ[N −2]
...
...
...
...
σξξ[N −1]
σξξ[N −2]
· · ·
σ2
ξ

(14.54)
Returning to the variance of ˆθ, the expression is obtained by the standard result involving condi-
tional variance,
Σ ˆθ = EΦ(var( ˆθ|Φ)) + varΦ(E( ˆθ|Φ)) = EΦ(var( ˆθ|Φ))
(14.55)
where the last identity is due to the unbiased nature of the LS estimator. Thus, the variance of LS
estimator depends on Σξξξ, i.e., the correlation structure of ξξξ and the randomness in Φ.
Deterministic Φ and white errors
Of particular interest is the case when Φ is free of errors and Σξξξ = σ2
eIN×N: This is the case of
uncorrelated or white errors. Then,
Σ ˆθ = σ2
e(ΦTΦ)−1
(14.56)
The expression is identical to the C-R lower bound (13.49) on the variance of all unbiased esti-
mators of a linear regression model. Thus,
The LS method delivers the most eﬃcient estimator of a linear regression model when
the errors underlying the observations are temporally uncorrelated and stationary.
To be able to use (14.56), we need an estimate of σ2
e.
Estimation of error variance
In order to estimate the variance of the errors in observations, a representative series of e[k] is
required. A good choice is the prediction error or the residual in (14.48),
ε[k] = ϕT[k] ˜θ + e[k]
(14.57)
which contains both e[k] as well as the eﬀects of the error in the point estimate of θ. On the
other hand, given that E( ˜θ) = 0, it may not be unreasonable to expect that the average proper-
ties of ε[k] can serve as suitable estimates for the statistical properties of e[k]. The following
relationship supports this insight. From (14.23)
ε = P⊥y = P⊥(Φθ0 + e) = P⊥e
(14.58)
where we have used the deﬁnition of the projection matrix in (14.24).
Using the relationship above, it can be shown that the statistic
ˆσ2
e =
N−1
X
k=0
ε2[k]
N −p
= SSE
N −p
(14.59)
is unbiased estimator of the innovations variance σ2
e. The proof is left as an exercise to the reader
(see Exercise E14.6).

368
Principles of System Identiﬁcation: Theory and Practice
Remarks:
The N −p factor in the denominator instead of N is due to the fact that p degrees of freedom
have been used up to estimate the p parameters. In other words, eﬀectively only N −p terms in the SSE are
linearly independent.
The estimate of variance in (14.59) has a χ2 distribution with N −p degrees of freedom (under
the assumption of GWN errors) according to the following result.
Theorem 14.2
In the linear regression of y corrupted with Gaussian white-noise errors e[k] using OLS, the
estimate of σ2
e given by (14.59) has the following properties
E( ˆσ2
e) = σ2
e
(Unbiased)
(14.60a)
E(( ˆσ2
e −σ2
e)2) = 2σ2
e
N −p
(Consistent)
(14.60b)
(N −p) ˆσ2
e
σ2e
d→χ2
N−p
(14.60c)
Proof. Available in standard statistical texts. See Greene (2012).
□
3. Eﬃciency: As remarked earlier, the OLS estimator achieves the lowest variance of estimates
among all estimators of the linear regression model when the equation error ξ[k] of the generat-
ing process is GWN. Under these conditions, it is therefore the MVUE and also the BLUE (recall
related discussion from Section 13.7.1).
When the equation error is colored, the OLS estimator is however not eﬃcient. In Section 14.3.5,
we shall learn a variant of the LS technique known as the weighted least squares (WLS), which
produces eﬃcient estimates even when ξ[k] is colored.
4. Consistency: The OLS estimator is consistent in the sense of probability provided (i) the covari-
ance of regressors is E(ϕ[k]ϕT[k]) = Σϕϕ is invertible and (ii) the regressors are uncorrelated
with the equation errors, E(ϕ[k]ξ[k]) = 0.
To recognize this fact, recall
ˆθ = θ0 + lim
N→∞
 1
N ΦTΦ
!−1
lim
N→∞
 1
N ΦTξξξ
!
(14.61)
By law of large numbers,
1
N ΦTΦ
p
−→Σϕϕ;
1
N ΦTξξξ
p
−→0
(14.62)
Thus,
ˆθ
p
−→θ0
(14.63)
Mean-square consistency is guaranteed when the errors are white and the regressors are deter-
ministic.
lim
N→∞MSE( ˆθ) = 0
(14.64)

Estimation Methods: Part I
369
5. Asymptotic bias: Given that the LS estimator is consistent, it follows that it is also asymptotically
unbiased.
6. Distribution: As we learnt in Chapter 13, the distribution of the estimates are critical to the con-
struction of conﬁdence intervals for θ0. These distributions are studied under diﬀerent scenarios,
as presented below. Note that the ﬁnal results are similar in nature.
i. Gaussian errors: The conditional distribution of the estimates is Gaussian. This is easy to
establish.
ˆθ = Φ†y
ξ[k] ∼N (0,Σξξξ)
=⇒ˆθ|Φ ∼N (θ0,σ2
e(ΦTΦ)−1)
(14.65)
The result follows from the fact that a linear combination of Gaussian distributed RVs
produces a RV with Gaussian distribution.
ii. Non-Gaussian errors: In this case too, the estimates follow a Gaussian distribution by virtue
of the CLT. This holds even when the equation error is colored and the result is uncondi-
tional, i.e., whether the regressors are stochastic or ﬁxed. However, this is an asymptotic
property unlike the ﬁnite-sample result above.
Theorem 14.3
If ξ[k] are independent and identically distributed (i.i.d.) with mean zero and variance σ2
and the regressors are “well-behaved,” then
ˆθ
d
−→N
 
θ0, σ2
N Σ−1
ϕϕ
!
(14.66)
Proof. Available in standard texts. See Greene (2012) for instance.
□
Observe that the assumption on the equation error is independence rather than being uncor-
related. Furthermore, by well-behaved regressors it is meant that (i) ΦTΦ is of full rank as
N →∞and (ii) no single observation shall dominate the data.
In practice, (14.66) is used by replacing the theoretical variance of the regressor with its
corresponding estimate.
ˆθ
d
−→N

θ0, ˆσ2(ΦTΦ)−1
(14.67)
Distribution of a function of estimates
In certain parameter estimation problems, the estimates may be computed as the (non-linear)
transform of another set of related parameter estimates. In identiﬁcation, for example, the step
response estimates may be computed by ﬁrst estimating the IR coeﬃcients followed by an inte-
gration of the same. In such situations, it is necessary to know the distribution of the function of
parameter estimates. The following result is useful in the context.
Theorem 14.4
If g( ˆθ) is a set of continuous and continuously diﬀerentiable functions of ˆθ, then under the

370
Principles of System Identiﬁcation: Theory and Practice
conditions of Theorem 14.3,
g( ˆθ)
d
−→N

g(θ0),Ω

Σ ˆθ

ΩT 
(14.68)
where Ω= dg/dθ is the Jacobian of the functions g w.r.t. the parameter vector and Σ ˆθ is the
covariance of parameter estimates ˆθ (such as the one given in (14.56)).
Proof. See Greene (2012) for instance.
□
In practice, the theoretical variance is replaced by the asymptotic covariance matrix
ˆΩ( ˆσ2(ΦTΦ)−1) ˆΩ
T.
7. Conﬁdence intervals for θ0: Using the distribution of the estimates, we can construct the conﬁ-
dence intervals for θ0 as illustrated in Section 13.12.2.
From Theorem 14.3, the OLS estimates of the linear regression model follow a multivariate
Gaussian distribution, under the restricted conditions of GWN errors. Then, the (standardized)
individual parameters have a normal distribution,
ˆθi −θi0
q
σ2eSii
∼N (0,1)
(14.69)
where Sii is the ith diagonal element of (ΦTΦ)−1. When σ2
e is replaced by its estimator in (14.59),
the Student’s t-distribution results for ˆθi,
ˆθi −θi0
q
ˆσ2eSii
∼tN−p
(14.70)
The 100(1 −α)% conﬁdence interval for θi0 is therefore,
ˆθi −t1−α/2,N−p
q
ˆσ2eSii ≤θi0 ≤ˆθi + t1−α/2,N−p
q
ˆσ2eSii
(14.71)
where t1−α/2,N−p is the critical value of the t-distribution with N −p degrees of freedom. When
N is very large (N ≫30), the t-distribution tends to a normal distribution. The 99% conﬁdence
interval for θi0 is approximately
ˆθi −2.58
q
ˆσ2eSii ≤θi0 ≤ˆθi + 2.58
q
ˆσ2eSii
(14.72)
The 99% signiﬁcance levels for the estimates are therefore ±2.58
q
ˆσ2eSii.
We revisit Example 14.2 to examine the properties of the FIR model parameter estimates.
Example 14.5: Properties of LS estimates of a FIR model
In Example 14.2, we obtained the estimates of the 11-coeﬃcient FIR model. Using (14.67),
we compute the standard error for each of these estimates, as tabulated below.
ˆg[0]
ˆg[1]
ˆg[2]
ˆg[3]
ˆg[4]
ˆg[5]
0.0215
(±0.0733)
−0.0387
(±0.0985)
0.2943
(±0.1147)
0.9688
(±0.1247)
0.5030
(±0.1307)
0.2073
(±0.1327)
ˆg[6]
ˆg[7]
ˆg[8]
ˆg[9]
ˆg[10]
ˆσ2e
−0.0408
(±0.1307)
0.0564
(±0.1247)
−0.0808
(±0.1149)
0.0368
(±0.0994)
0.0170
(±0.0736)
0.2215

Estimation Methods: Part I
371
The numbers reported below the estimates are the 3σ errors in the respective estimates.
These are also the 99% signiﬁcance values. Thus, we can statistically conclude that (i) the
process has a delay of 2 units because the ﬁrst signiﬁcant IR coeﬃcient occurs at lag l = 2,
and (ii) the underlying description has a FIR representation with 4 coeﬃcients (incidentally
tallying with the actual process representation in (14.34)).
To verify the distributional properties of OLS estimators, Nr = 200 realizations of data are
generated. Estimates from each realization are collected and analyzed. Figure 14.5 shows the
histograms of the IR estimates at lags l = 0,2,3,8. It is fairly apparent that the estimates
follow a Gaussian distribution (a density function could be ﬁt to verify this claim).
−0.1
0
0.1
0
10
20
30
40
IR Estimate g[0]
Count
0
0.5
1
0
20
40
60
IR Estimate g[2]
Count
0.8
1
1.2
1.4
0
20
40
60
IR Estimate g[3]
Count
−0.2
0
0.2
0
20
40
60
IR Estimate g[8]
Count
FIGURE 14.5
Distribution of the OLS estimates of the FIR model in Example 14.5, obtained from 200 real-
izations.
The error analysis revealed that the IR estimates are signiﬁcant only at lags l = 2,3,4,5.
A natural step forward is to re-estimate the FIR model containing only these terms. The
re-estimated model is,
ˆg[2]
ˆg[3]
ˆg[4]
ˆg[5]
ˆσ2e
0.272
(±0.0692)
0.9756
(±0.0836)
0.5136
(±0.0838)
0.2073
(±0.0695)
0.2213
Observe that the 3σ errors are considerably lower than those of the previously estimated
11-coeﬃcient model. This is also true of ˆσ2e. The improvement owes itself to the decrease in
dim(θ), which causes an increase in the degrees of freedom for estimation.
Remarks:
a. In deriving the properties of the LS estimator above, we have assumed that the functional form of the
process has been “rightly” speciﬁed. In practice, this is never satisﬁed since the real process is far more
complex than the DGP model (14.47). A similar assumption is also necessary in deriving the properties of
the non-linear LS estimator (see §14.4.3)3.
Therefore, the expressions for the properties and distributions above (as well as for the CIs) should be used
only when the user is convinced that these requirements have been met at least for the given data. This
conviction is facilitated by residual analysis.
b. The number of observations N in all the above expressions should be treated as the size of the eﬀective ob-
servations participating in estimation. Recall Example 14.2 in this context, where the estimation eﬀectively
used N −M + 1 = 510 −10 = 500 observations as against 510 samples.
3The equivalent of this in the more general PEM methods is to assume that the system is contained in the model set. See
§21.4.

372
Principles of System Identiﬁcation: Theory and Practice
Listing 14.3
MATLAB code for estimating the parameters of Example 14.5
% Filename firest_ls.m
% Create process object
Gp = idpoly(1,[0 0 0.3 1 0.5 0.2],1,1,1,’Noisevariance’,1);
% Generate input
uk = idinput(510,’prbs’,[0 0.4],[-1 1]);
N = length(uk);
% Simulate the process and adjust noise variance
xk = sim(Gp,uk); Gp.Noisevariance = var(xk)/10;
yk = sim(Gp,uk,’Noise’);
% Collect the input-output data
zk = iddata(yk,uk,1);
% Estimate 11 IR coefficients of a FIR model
% Construct output vector
M = 11;
Y = yk(M:end);
% Construct regressors
Phimat = [];
for k1 = 0:M-1,
Phimat
= [Phimat uk(M-k1:end-k1)];
end
% OLS estimates of IR models
ir_est = pinv(Phimat)*Y;
Listing 14.4
MATLAB code for standard error and residual analysis in Example 14.5
% Predictions
Yhat = Phimat*ir_est;
% CCF between residuals and inputs
[ccfval,lags] = xcov(Y-Yhat,uk(M:end),20,’coeff’);
% Compute standard errors
varek_hat = sum((Y - Yhat).^2)/(length(Y)-length(ir_est));
ir_errmat = varek_hat*inv(Phimat ’*Phimat);
ir_errvec = sqrt(diag(ir_errmat));
% Residual analysis
figure; plot((11:310),Yhat(1:300),’b-’,(11:310),Y(1:300),’r--’)
% ACF of residuals
acf(Y - Yhat ,20);
% CCF between residuals and inputs
figure; stem(lags,ccfval,’markerfacecolor’,’red’)
hold on; plot([-20 20],ones(1,2)*2.58/sqrt(N-M),’r--’);
plot([-20 20],-ones(1,2)*2.58/sqrt(N-M),’g--’);

Estimation Methods: Part I
373
Listing 14.5
MATLAB code for distribution of estimates in Example 14.5
Nreal = 200; gkvec = zeros(Nreal ,4);
for i = 1:Nreal,
firest_ls
gkvec(i,:) = ir_est([1 3 4 9]);
end
% Plot the histogram of estimates
figure
subplot(221); hist(gkvec(:,1));
subplot(222); hist(gkvec(:,2));
subplot(223); hist(gkvec(:,3));
subplot(224); hist(gkvec(:,4));
Listing 14.6
MATLAB code for Example 21.14
% ARMAX Process
proc_mod1 = idpoly([1 -0.5],[0 0 1.4],[1 0.6],1,1,’Noisevariance’,1);
proc_mod2 = idpoly([1 -0.5],[0 0 1.4],1,1,1,’Noisevariance’,1);
% Generate input
uk = idinput(510,’prbs’,[0 0.4],[-1 1]);
N = length(uk);
% Simulate the process
xk1 = sim(proc_mod1 ,uk); xk2 = sim(proc_mod2 ,uk);
proc_mod1.Noisevariance = var(xk1)/10;
proc_mod2.Noisevariance = var(xk2)/10;
yk1 = sim(proc_mod1 ,uk,’Noise’);
yk2 = sim(proc_mod2 ,uk,’Noise’);
% Collect the input-output data
zk1 = iddata(yk1,uk,1); zk2 = iddata(yk2,uk,1);
% Estimate the ARX models
mod_arx1 = arx(zk1,[1 1 2]);
mod_arx2 = arx(zk2,[1 1 2]);
% Present the models
present(mod_arx1)
present(mod_arx2)
14.3.4
COMPUTING THE LINEAR LS ESTIMATE
The LS solution in (14.21) does not lend itself to eﬃcient computation since an inversion is involved.
In fact, the condition number of the matrix ΦTΦ is the square of that of the original matrix Φ. Thus,
solving the normal equations is even more badly conditioned. Further, problems may occur when Φ
is rank deﬁcient either due to numerical precision or due to linear dependence among the columns
of Φ. Therefore, a verbatim implementation of (14.21) is to be avoided.
The QR factorization oﬀers a computationally eﬃcient way of solving the normal equations for
full rank matrices without matrix inversion. When Φ is rank deﬁcient, a relatively more powerful,
but also computationally more expensive algorithm known as the singular value decomposition
(SVD) is used.
1. QR factorization: The basics of this factorization is provided in Appendix 14.A.3.
The main beneﬁt of using (14.A.11) is that the LS solution can be obtained by simple back
substitution since R is upper triangular. The salient steps in using this factorization for obtaining
the LS estimate are described below.

374
Principles of System Identiﬁcation: Theory and Practice
Assume Φ is of full rank and that N > p. Then from a full QR factorization
ΦP = Q
 R1
0
!
(14.73)
where the orthogonal permutation matrix P is p × p, orthogonal factor Q is N × N and the upper
triangular matrix R1 is p × p. Since Φ is full rank, R1 is non-singular.
Using the property QQT = I = PPT, we have through (14.73)
||y −Φθ||2
2 = ||QT (y −Φθ)||2
2 = ||QTy −
 R1
0
!
PTθ||2
2
Partition QTy as QTy =
 z1
z2
!
, where z1 : Rp×p and z2 : RN−p×p. Then, introducing ¯θ = PTθ,
the cost function can be re-written as
||y −Φθ||2
2 =

 z1
z2
!
−
 R1
0
!
PTθ

2
2
= ||z1 −R1 ¯θ||2
2 + ||z2||2
2
(14.74)
The second term is independent of θ and hence the solution is
¯θ = R−1
1 z1
(14.75)
The solution is actually obtained by back substitution. Note that ¯θ is only diﬀerent from θ in
terms of a permutation, i.e., it is merely a re-ordered parameter vector. The cost function at the
optimum is
J( ˆθ⋆) = ||z2||2
2
(14.76)
Connotatively, z2 is the residual of the model at the optimum. Thus, the QR factorization simul-
taneously provides the parameter estimate and the residuals.
Rank deﬁcient Φ
When the matrix Φ has a rank r < p (rank deﬁcient), only r parameters can be estimated uniquely.
The remaining (p −r) cannot be estimated and have to be chosen arbitrarily. Keeping this fact in
view, the matrices are partitioned diﬀerently.
R =
 R1
R2
0
0
!
;
QTy = *.
,
z11
z12
z2
+/
-
;
¯θ =
 ¯θ1
¯θ2
!
(14.77)
where R1 : Rr×r (non-singular) is upper triangular, R2 : Rr×(p−r), z11 : Rr×1, z12 : R(p−r)×1,
z2 : R(N−p)×1, ¯θ1 : Rr×1 and ¯θ is as before the permuted vector of the p parameters.
In terms of the newly introduced matrices and vectors, the LS problem is then that of minimizing,
||R1 ¯θ1 + R2 ¯θ2 −z11||2
2 + ||z12||2
2 + ||z2||2
2
(14.78)
which achieves optimum when
¯θ1 = R−1
1 (z11 −R2 ¯θ2)
∀arbitrary ¯θ2 ∈R(p−r)
(14.79)
A trivial choice of ¯θ2 = 0, which is a sparse solution. This is the option exercised by the familiar
“backslash \” operation in many software packages. The underlying principle of this operation
is QR factorization. In general the choice of ¯θ2 can be cast as another optimization problem.

Estimation Methods: Part I
375
Listing 14.7
MATLAB commands to perform QR factorization for LS estimation
p = size(Phi,2);
% size of parameter vector
[Q,R,P] = qr(Phi);
% full factorization
zvec = Q’*Y;
Theta = inv(R(1:p,1:p))*zvec(1:p,:)
pred_err = zvec(p+1:end,:);
% residuals
[Q,R,P] = qr(Phi,0); % economy factorization
Theta = inv(R)*Q’*Y
% only parameters can be obtained
[Ps,indP] = sort(P); % Arrange the theta vector
Theta = Theta(indP);
A numerically more eﬃcient way of handling rank deﬁcient regressors is through the use of
SVD, which is equivalent to applying the pseudo-inverse.
2. Pseudo-inverse or the SVD: A working overview of SVD is provided in Appendix 14.A.4. Ap-
plying the SVD to the LS problem is equivalent to using the pseudo-inverse, as we shall see
shortly.
Using the SVD of Φ,
Φ = USVT
the linear LS objective function can be written as
(y −Φθ)T (y −Φθ) = (y −Φθ)TUUT (y −Φθ) = ||UTy −SVTθ||2
2
=
rX
i=1
(σi βi −uT
i y)2 +
N
X
i=r+1
(uT
i y)2
(14.80)
where β ≜VTθ.
The solution for the transformed parameters thus follows,
βi =

uT
i y
σi
,
i = 1,· · · ,r
arbitrary,
i = r + 1,· · · ,p
(14.81)
with the objective function at the optimum achieving
min
θ
||y −Φθ||2
2 =
N
X
i=r+1
(uT
i y)2
(14.82)
A (1-norm minimizing) solution (for β) is to set the “free” βi = 0, i = r + 1,· · · ,p. The optimal
parameter estimates ˆθ with this choice of free βis are therefore,
θ = Vβ =
rX
i=1
uT
i y
σi
βi
(14.83)
This is indeed the solution rendered by the pseudo-inverse because
Φ† = (ΦTΦ)−1ΦT = (VSTSVT )−1VSUT = VS†UT
(14.84)
It is easy to verify that
S† =
f
S−1
1
0p×(N−p)
g
;
S1 = diag(σ1,· · · ,σp)
(14.85)
The equivalence between the LS solutions using SVD and pseudo-inverse then follows.

376
Principles of System Identiﬁcation: Theory and Practice
Listing 14.8
MATLAB commands to carry out SVD for LS estimation
[N,p] = size(Phi);
[U,S,V] = svd(Phi);
% full factorization
Phiplus = V*pinv(S)*U’
Phiplus = pinv(Phi); % both give pseudo -inverse
Theta = Phiplus*Y;
pred_err = sum(U(:,p+1:end).*repmat(Y,1,N-p),1);
pred_err = Y - Phi*Theta; % both give residuals
[U,S,V] = svd(Phi,0);
[U,S,V] = svd(Phi,’econ’); % try with economy factorization
In the following two sections we study a few useful extensions of the least squares method.
14.3.5
WEIGHTED LEAST SQUARES
A widely used generalization of the OLS treats each observation at a diﬀerent level of “impor-
tance” by incorporating weights on the samples (strictly on the prediction errors). There are several
compelling reasons to consider such a formulation.
i. Error in each observation has a diﬀerent variance - this is the case of heteroskedastic errors. Each
sample therefore is not equally reliable. Samples with “more” errors are less reliable than those
with “less” errors. This situation can arise when the error levels vary with the operating condition
(inputs) or when the data is contaminated by outliers.
ii. Observation errors are stationary, but colored (recall that OLS is eﬃcient only when ξ[k] is
GWN).
iii. Recent samples to be given more importance than the past for model adaptation. The weights
are then termed as forgetting factors. This is one of the strategies used in identiﬁcation of linear
time-varying systems. See §25.1 for related discussion.
iv. In smoothing and sensor fusion problems, it is common to give diﬀerent weighting to each ob-
servation to account for either diﬀerent signal-to-noise ratio at each sample or for varying sensor
reliabilities. An example application is in the computation of smoothed FRF from its raw estimate
(see Section 20.4).
The general statement of the problem is as follows.
min
θ
(y −Φθ)TW(y −Φθ)
(14.86)
where W is a positive deﬁnite weighting matrix. By deﬁnition therefore, W is symmetric. When
W = IN×N, we recover the OLS formulation.
Remarks:
i. The cost function in (14.86) is also known as the Mahalanobis distance, named after Mahalanobis (1936)
and is conventionally written as a weighted squared-norm ||y −Φθ||W.
ii. The WLS formulation as given above is also known as the generalized least squares (GLS). Related litera-
ture treats the case of diagonal W as the weighted least-squares problem.
The solution to the WLS estimation in (14.86) can be easily derived by casting it as an OLS
problem on scaled data. For this purpose, we exploit the positive-deﬁniteness of W and perform a
Cholesky factorization
W = CTC
(14.87)

Estimation Methods: Part I
377
With this decomposition the objective function in (14.86) can be re-written as
(y −Φθ)TCTC(y −Φθ)
(14.88)
As a second and ﬁnal step, introduce scaled observations and regressors,
yS = Cy; ΦS = CΦ
(14.89)
so that the WLS problem can be cast into an OLS formulation
min
θ
(yS −ΦSθ)T (yS −ΦSθ)
(14.90)
From the OLS solution (14.21), we thus have the WLS estimator
ˆθWLS = (ΦT
SΦS)−1ΦT
SyS = (ΦTWΦ)−1ΦTWy
(14.91)
Remarks:
i. Scaling the data amounts to scaling the observation errors as well, ξξξS = Cξξξ. The scaled errors have the co-
variance matrix ΣξξξS = CΣξξξCT . For a special choice of C (see below), ΣξξξS = I, oﬀering certain advantages.
ii. The diagonal elements of W are easy to interpret - they represent the importance given to each observation
(prediction error). On the other hand, the oﬀ-diagonal elements account for the importance given to cross-
terms in the summation. This is understood by writing the cost function as
(y −ΦT θ)T W(y −ΦT θ) = trace((y −ΦT θ)T W(y −ΦT θ))
The need for including cross-terms in W arises when the equation errors possess temporal correlation (in
general, correlation along the k dimension).
iii. The WLS method is a special case of the GMM and the MLE. Section 15.1 throws light on the latter
equivalence.
Choice of weights
The problem setting above obviously assumes that W is known to the user. In model adaptation,
W is a diagonal matrix of forgetting factors, typically parametrized by a single parameter λ. The
objective function for this case is
J(θ, N) =
N−1
X
k=0
λk−N+1ε2[k]
(14.92)
where the weighting is w[k] = λk−(N−1), 0 < λ ≤1. The most recent sample acquires the maxi-
mum importance. Clearly, λ = 1 fetches the OLS formulation.
In all other situations, the choice is guided by a user-deﬁned criterion. A common criterion is the
eﬃciency of the estimator.
The variance of the linear WLS estimator under the standard assumptions made in the OLS case
is a function of the weights
Σ ˆθ(W) = var( ˆθWLS) = (ΦTWΦ)−1ΦTWΣvWΦ(ΦTWΦ)−1
(14.93)
The search is for W that minimizes the variance in (14.93), i.e.,
Find a positive semi-deﬁnite Wopt s.t. Σ ˆθ(Wopt) −Σ ˆθ(W) ≤0, ∀W

378
Principles of System Identiﬁcation: Theory and Practice
Fortunately the solution is simple despite the formidableness of (14.93). The optimal weighting
matrix is the inverse of the covariance of observation errors,
Wopt = Σ−1
ξξξ
(14.94)
The variance of the estimator with the optimal choice of weights is
Σ ˆθ(Wopt) = (ΦTWoptΦ)−1 = (ΦT ΣξξξΦ)−1
(14.95)
A proof of the above result can be found in several standard texts (Yan and Su, 2009). An intuitive
insight can be, nevertheless, obtained by considering the case of heteroskedastic errors, i.e., when
the equation error is uncorrelated, but its variance changes with the observation index. In other
words, each sample has a diﬀerent level of reliability.
Heteroskedastic errors: diagonal weighting
When the equation errors are heteroskedastic, the variance-covariance matrix of ξ[k] is
Σξξξ = E(ξξξξξξT ) =

σ2
1
0
· · ·
0
0
σ2
2
· · ·
0
...
...
...
...
0
0
· · ·
σ2
N

(14.96)
In such cases, we already know that OLS yields ineﬃcient estimates.
On the other hand, with the optimal weighting according to (14.94)
W = Σ−1
ξξξ =

1/σ2
1
0
· · ·
0
0
1/σ2
2
· · ·
0
...
...
...
...
0
0
· · ·
1/σ2
N

(14.97)
the WLS is guaranteed to produce eﬃcient estimates of θ. This choice of W seems natural when we
re-write the objective function for the WLS as
(y −Φθ)TW(y −Φθ) =
N
X
k=1
(y[k] −ϕT[k]θ)2/σ2
k
(14.98)
Each (squared) residual is weighted with the inverse of the variability of the associated observation.
Higher the error variance, lower the reliability of that sample and lesser the importance given to that
observation. Thus, the optimal weighting is intuitively meaningful.
Further, recall that WLS is eﬀectively OLS on scaled data. The optimal choice of W in (14.94)
leads to a scaling factor of C = Σ−1/2
ξξξ
. Thus, the covariance matrix of the scaled equation errors ξξξS
is E(CξξξξξξTC) = IN×N. Consequently, by virtue of the property of OLS, the estimates are eﬃcient
(for Gaussian errors).
A simple example below illustrates the main ideas underlying WLS.
Example 14.6: Sensor Fusion: Steady-State Estimation
Temperature measurements of a reactor at steady-state from 10 thermocouples that have
diﬀerent, but known error characteristics (variability).
Sensor
1
2
3
4
5
6
7
8
9
10
Meas. (◦C)
61.2
64.3
59.1
64.1
63.8
62.9
58.2
60.7
61.5
63.7
Variance
0.36
2.25
1.69
0.25
0.49
2.89
3.2
1.4
1.2
2.7

Estimation Methods: Part I
379
where the readings have already been adjusted for calibration.
The goal is to estimate the steady-state temperature from these ten diﬀerent measurements.
Assume that the error across sensors are uncorrelated. Then using (14.94) and noting that
ϕ[k] = 1 for this example, we obtain the WLS estimate of the average and its error variance
as
ˆµW LS = (ΦT WΦ)−1ΦT Wy =
N
X
k=1
y[k]
σ2
k
N
X
k=1
1
σ2
k
= 62.6086
var( ˆµ) = (ΦT WΦ)−1 =
1
N
X
k=1
1
σ2
k
= 0.0805
where k indicates the sensor index for this example.
Compare the estimate and its variance from the OLS
ˆµOLS = 1
N
N
X
k=1
y[k] = 61.95; var( ˆµ) = (ΦT Φ)−1ΦT ΣξξξΦ(ΦT Φ)−1 =
N
X
k=1
σ2
k
N2
= 0.1643
The widths of conﬁdence intervals for the average correspondingly would be proportional to
2σ ˆµ, i.e., 0.2835 and 0.4053, respectively.
Determining the weights
The optimal result is of limited use unless the variances are known. This knowledge typically comes
out of an estimation method. To break this impasse, a few methods have been proposed, mostly for
the heteroskedastic case.
1. Group the data manually or use grouped data to estimate variance for each of these groups. Then
scale each group (both the output and regressors) accordingly.
2. Apply OLS and compute the residuals from the resulting model. From here, two routes exist.
The ﬁrst one uses the ACVF of the residuals to construct an estimate of Σξξξ. In the second route, a
model is ﬁt between either absolute or squared residuals and some or all regressors. Subsequently
this model is used to express Σξξξ.
3. In general, propose a model for the errors or its variance and jointly estimate the parameters of
this model as well as the regression equation using a likelihood-based method.
For technical details pertaining to the methods listed above, see Carroll and Rupert (1988) and Yan
and Su (2009). Some additional illustrations are found in Greene (2012).
Tests for heteroskedasticity are available. Common among these are the White’s test, and the Park,
Glesjer, and Breusch-Pagan-Godfrey tests (Yan and Su, 2009).
The following example serves to illustrate the beneﬁt of WLS. It uses the estimated covariance
matrix of the residuals to determine the matrix of weights W.
Example 14.7: Estimation of FIR Model: Correlated Errors and WLS Estimator
Data is generated by exciting the process of Example 14.2 with the same input sequence,
but with colored noise, i.e., correlated errors. Assuming that we have gone through the steps
of Examples 14.2 and 14.5 using OLS technique, the ﬁnal model of interest is a 4-coeﬃcient
model with a delay of 2 units.

380
Principles of System Identiﬁcation: Theory and Practice
The ACF of residuals shown in Figure 14.6 clearly establish that the assumption of white-
noise observation errors does not apply to this case study. Consequently, the expressions given
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
FIGURE 14.6
ACF of the residuals from the OLS estimation of the FIR model in Example 14.7.
in (14.56) for computing the errors in parameter estimates does not hold for this case study.
More importantly, from the properties of OLS estimators discussed in §14.3.3, we know that
the OLS estimator is not eﬃcient in the presence of correlated errors.
The WLS estimator with the optimal choice of weighting matrix W = Σ−1
ξξξ
can be used to
obtain eﬃcient estimates of the regression parameters. Since Σξξξ is unavailable, we use the
prediction errors from the OLS model to obtain an estimate as follows. Figure 14.6 points to
a MA(1) correlation structure in ξ[k]. Therefore, a reasonable estimate of Σξξξ is
ˆΣξξξ =

ˆσ2ε
ˆσεε[1]
0
· · ·
0
ˆσεε[1]
ˆσ2ε
ˆσεε[1]
· · ·
0
0
ˆσεε[1]
ˆσ2ε
...
0
...
...
...
...
ˆσεε[1]
0
0
· · ·
ˆσεε[1]
ˆσ2ε

(14.99)
where we have made use of the fact that the ACF of a MA(1) process is theoretically zero
beyond lags l = 1.
Setting W = ˆΣ−1
v , we obtain the WLS estimates as follows.
WLS estimates
ˆg[2]
ˆg[3]
ˆg[4]
ˆg[5]
0.3357
(±0.0275)
0.9865
(±0.0294)
0.4926
(±0.0295)
0.1844
(±0.0276)
Clearly the errors in the estimates are smaller than in those from the OLS. The decrease may
not be dramatic for this case, but the example serves to illustrate the concept. In general,
the improvement in the estimates depends on the correlation structure of the noise.
An important point to note is that the residuals associated with the WLS estimated model
would still be correlated. It is only in the scaled domain that the residuals would remain
uncorrelated.
Remarks:
A more elegant method for the foregoing example would consist of absorbing the noise model into
the predictor ˆy[k|θ] so that the parameter of the MA(1) model, c1, is jointly estimated with the parameters
of the regression model. Subsequently, an OLS estimator or an MLE technique may be applied. This is the
general approach that is adopted in system identiﬁcation, the details of which will be learnt in Chapter 21.
Before we draw the curtains on the concepts of LS methods, it is useful to know that there exist
several other variants of the LS method. Obviously it is not possible to dwell into each of them. The
following section provides a brief overview of a few popular variants.

Estimation Methods: Part I
381
Listing 14.9
MATLAB code for Example 14.7
proc_mod = idpoly(1,[0 0 0.3 1 0.5 0.2],[1 0.4],1,1,’Noisevariance’,1);
% Generate input
uk = idinput(510,’prbs’,[0 0.4],[-1 1]); N = length(uk);
% Simulate the process
xk = sim(proc_mod ,uk);
proc_mod.Noisevariance = var(xk)/10;
yk = sim(proc_mod ,uk,’Noise’);
% Plot the input-output data
zk = iddata(yk,uk,1); plot(zk)
zkd = detrend(zk,0);
% Estimate 4 coefficients of a FIR model using ARX routine (LS)
mod_fir = arx(zkd,[0 4 2]);
% Compute errors and ACF
err_mod = pe(zkd,mod_fir);
acf_err = acf(err_mod.y,20);
% Construct output variables and regressors
Y = zkd.y(6:end); Neff = length(Y); ukd = zkd.u;
Phimat = [];
for k1 = 2:5,
Phimat
= [Phimat ukd(6-k1:end-k1)];
end
% Scale the data using auto-covariances (not just ACFs)
Sigma_v = eye(Neff) + acf_err(2)*diag(ones(Neff -1,1),-1) + acf_err(2)*diag(...
ones(Neff -1,1),1);
Sigma_v = var(err_mod.y)*Sigma_v;
% Construct W and scale data using Cholesky factor
W = inv(Sigma_v); Cw = chol(W);
Ys = Cw*Y; Phimat_S = Cw*Phimat;
% WLS estimates of IR models
irest_wls = pinv(Phimat_S)*Ys;
% Variance of estimates
var_irwls = inv(Phimat_S ’*Phimat_S);
err_irwls = sqrt(diag(var_irwls));
14.3.6
OTHER VARIANTS OF LINEAR LS
Each variant either addresses a shortcoming or extends the least squares to a larger class of problems.
i. Recursive least squares (RLS): The problem is motivated by the need for updating the model
in time, either because process is time-varying or due to a change of operating conditions. A
computationally eﬃcient recursive algorithm of the form
ˆθN+1 = ˆθN + △θ
(14.100)
can be devised to update the model parameters with the arrival of (N+1)th observation. Technical
details related to this method are presented in §25.1.
ii. Constrained least squares: This variant handles constraints on the parameters (if any) of the
forms
Aθ(≤) = b
((In)Equality constraint)
(14.101a)
θL ≤θ ≤θU
(Interval constraint)
(14.101b)
||Aθ −b||2
2 ≤γ2
(Quadratic constraint)
(14.101c)

382
Principles of System Identiﬁcation: Theory and Practice
These problems often arise in grey-box modeling where some prior information on the parame-
ters or model structure is known. Another common application of this variant is in the so-called
ridge regression problems, where the constraint is to obtain sparse solutions, i.e., models with
low complexity.
The solution to the constrained LS problem can be determined using any of the following meth-
ods: (i) method of Lagrangian multipliers (ii) generalized SVD method. Solutions to each of the
above cases and the implementation details are available in Golub and Loan (1996).
iii. Total least squares (TLS): This is considered a generalization of the OLS and is a rigorous way
of taking into account the errors in both predicted and explanatory variables. The approach to
TLS is related to, but not identical to that of errors-in-variables (EIV) problem. An excellent his-
torical and technical account of the TLS is given in Huﬀel and Vandewalle (1991) and Markovsky
and Huﬀel (2007). A solution to the multivariable version of the TLS problem is oﬀered by the
principal component analysis (PCA) (see §26.3.3).
iv. Partial least squares (PLS): The phrase partial least squares was ﬁrst coined by Wold (1972)
in an eﬀort to develop multivariable regression models for situations where the regressors are
linearly dependent. The basic idea is to build the regression model in a transformed space by
transforming (or projecting) the explanatory and the dependent variables into a new space. Only
a subset of these projections, known as the latent vectors are used for regression. The subset of
regressors is selected in such a way that they capture as much possible covariance between Φ
and Y. The reader is directed to Wold, Sjöström and Eriksson (2001) and Abdi (2010) for a nice
exposition on the methodology and concepts of PLS.
PLS is often compared and contrasted with principal component regression (PCR), which builds
models using principal components from PCA (see §26.3), which is also a least-squares based
approach. The main contrasting factor between the two is the requirement for choosing the latent
vectors of Φ in PLS is not variance maximization as in PCR, but is the covariance (between
Φ and Y) maximization. Several works have studied the relationship between PLS, PCR and
other multivariable regression philosophies (see Rosipal and Krämer (2006) and the references
therein).
A generalization of the least-squares principle is naturally the non-linear LS method, where the
predicted variables are allowed to be non-linear functions of the unknowns and the explanatory
variables.
14.4
NON-LINEAR LEAST SQUARES
The non-linear least squares problem handles the more general case of non-linear predictor models,
min
θ
JN (θ,y,ϕ) = 1
N ||y −ˆy(θ,ϕ)||2
2
s.t. ˆy(θ,ϕ) = s(θ,ϕ)
(14.102)
where s(.) is a known non-linear function, y is the N × 1 observation vector and ϕ is the set of
explanatory variables as usual. For simplicity, we shall simply use ˆy in place of ˆy(θ,ϕ) remembering
its dependence on the parameters and regressors.
The optimal solution is once again obtained by setting the gradient of the objective function to
zero:
θ⋆= arg
"
g(θ) ≜∇θJ = −1
N
∂ˆy
∂θ
T
(y −ˆy) = 0
#
(14.103)
Thus, as in the linear case, here too we are presented with an orthogonality requirement at the
optimal point. An obvious diﬃculty however, is that, unlike in the case of linear LS, we have a
set of non-linear equations. Another contrasting feature is that the number of parameters does not
necessarily equal the number of explanatory variables.

Estimation Methods: Part I
383
The non-linearity of the orthogonality conditions is the key challenge and gives rise to two dif-
ﬁculties: (i) non-availability of a closed-form solution and (ii) existence of multiple solutions. A
natural recourse is to turn to numerical optimization algorithms, which generally return local op-
tima. These solvers iteratively improve upon an initial guess using an update rule that search in the
direction of the gradient of J(θ,Z). We review two commonly used algorithms below followed by
a family of generic solutions.
Newton-Raphson method
The N-R method is a well-known method for solving non-linear equations. It attempts to solve
(14.103) using a ﬁrst-order Taylor’s series expansion of the gradient of the objective function ∇θ J
around the true point θ⋆, where ∇θ J(θ⋆) = 0.
The resulting iterative equation for updating θ is
θ(i+1) = θ(i) −(∇θg)−1 g(θ)θ=θ(i)
(14.104)
Gauss-Newton method
In contrast to the N-R method above, the approach here is based on a ﬁrst-order approximation for
the non-linear predictor s(θ).
At the ith iteration, the ﬁrst-order approximation of the predictor is
ˆy(θ) ≈ˆy(θ(i)) + Ψ(θ)|θ=θ(i) (θ −θ(i))
(14.105)
where Ψ is made up of the gradients of the predictor
ψ(k,θ) ≜∇θ ˆy(k,θ) = ∂ˆy(k,θ)
∂θ
=
" ∂ˆy[k]
∂θ1
· · ·
∂ˆy[k]
∂θp
#T
Ψ(θ) = ∇θ ˆy =
f
ψ(0,θ)
ψ(1,θ)
· · ·
ψ(N −1,θ)
gT
(14.106a)
(14.106b)
In some sections of literature, the quantity ψT (k,θ) evaluated at a ﬁxed value θ = θ0 is known
as the pseudo-regressor. The justiﬁcation stems from the linear approximation (14.105). When the
predictor is a linear in the unknowns, ψ(k,θ) is the regressor itself
ˆy[k] = ϕT[k]θ =⇒ψ(k,θ) = ϕ
(14.107)
Thus, the matrix Ψ(k,θ) takes the role of the regressor matrix Φ in the linear LS formulation.
Plugging in the approximation (14.105) into the objective function (14.102) produces a locally
linear LS problem. To see this introduce
εi = y −ˆy(θ(i)); △θ(i) = θ −θ(i)
Then, the objective function in (14.102) at the ith iteration is
Ji(θ) = (εi −Ψ(θ(i))△θ)T (εi −Ψ(θ(i))△θ)
(14.108)
An iterative rule can be now written using the LS solution of (14.108),
θ(i+1) = θ(i) + (Ψ(θ(i))T Ψ(θ(i)))−1Ψ(θ(i))Tεi
(14.109)
The Gauss-Newton method is known to be advantageous over the Newton-Raphson method in a few
respects, as discussed shortly.

384
Principles of System Identiﬁcation: Theory and Practice
14.4.1
NUMERICAL METHODS FOR OPTIMIZATION
The two approaches discussed above belong to a more general family of methods, which prescribe
update rules of the form
θ(i+1) = θ(i) + ηid(i)
(14.110)
where d(i) is the direction of change in the parameter space, and ηi, known as the step length is
responsible for controlling the amount of change. The latter is ideally chosen such that the objective
function decreases with every iteration. A set of diﬀerent possibilities that give rise to well-known
methods are brieﬂy listed below. For convenience, deﬁne g(θ) ≜∇θ J and gi ≜g(θ(i)).
1. Steepest-descent algorithm: The direction of search is chosen as
d(i) = −(∇θ J)(i) = −gi
(14.111)
while the step length is chosen such that the objective function reaches the minimum in a single-
step,
ηi = arg min
ηi J(θ(i+1))
(14.112)
To determine the optimal step length, ﬁrst-order approximations of J(θ) are used
J(θ(i+1)) ≈J(θ(i)) −ηi(gT
i gi)
(14.113)
Together with (14.110), the optimal step size (by requiring that ∂J((i+1))/∂η(i) = 0) turns out to
be
η⋆
i =
gT
i gi
gT
i H(i)g
where
H(i) = (∇θg)|θ=θ(i) (Hessian)
(14.114)
Clearly, the step length is non-negative whenever the Hessian H(i) is positive-deﬁnite, which
cannot be unfortunately guaranteed.
The steepest descent algorithm (Bazaraa, Sherali and Shetty, 2006) is very popular because of
its simplicity. It has a linear convergence rate and switches back and forth between iterations in a
zig-zag fashion. A major drawback, however, is that its convergence is too slow as it approaches
the solution, particularly when J(θ) is ﬂat around the optimum. On the other hand, it forms the
basis for the development of a variety of other sophisticated numerical optimization algorithms.
2. Newton-Raphson method: This method improves upon the steepest descent algorithm by choos-
ing
d(i) = −gi
ηi = (H(i))−1
(14.115)
where H(i) is the p× p Hessian of the objective function deﬁned earlier. The shortcomings of this
method are that the computation of a matrix inverse and the Hessian is involved at each iteration.
The Gauss-Newton method overcomes these shortcomings by only using the ﬁrst derivatives.
Further, the positive-deﬁniteness of Hessian is not guaranteed, implying that the objective func-
tion is not bound to decrease after every iteration. The modiﬁed Newton-Raphson method incor-
porates an additional factor in the step length, so that the update rule
θ(i+1) = θ(i) −αi(H(i))−1gi
(14.116)
overcomes the aforesaid drawback.

Estimation Methods: Part I
385
3. Gauss-Newton method: From a comparison of (14.109) and (14.110), the choices of step length
and search direction are:
d(i) = Ψ(θ(i))T (y −ˆy(θ(i)))
ηi = (Ψ(θ(i))T Ψ(θ(i)))−1
(14.117)
Although a matrix inverse appears, the adjustment ηid(i) is merely the OLS estimates resulting
from regressing the prediction errors at the ith iteration, εi[k] on ψ(k,θ(i)), which we know can
be eﬃciently computed.
It can be shown that this approach is equivalent to a Newton-Raphson method with a suitable
approximation of the Hessian in (14.114).
H(θ) = 1
N (Ψ(θ)T Ψ(θ)) −1
N ((∇θΨ)Tε(θ) ≈1
N (Ψ(θ)T Ψ(θ)) =⇒η = 1
N H−1
(14.118)
The approximation is justiﬁed as follows. Observe that the second term on the exact expression
in (14.118) is the covariance between the second-derivative of the non-linear predictor and the
residuals. At the optimum, it is reasonable to neglect this term since the errors form an indepen-
dent series. Further, note that from the deﬁnition in (14.103)
g(θ) = −1
N Ψ(θ)Tε(θ) =⇒
d(i) = −Ng(θ)
(14.119)
Putting together (14.118) and (14.119), the connection between G-N and N-R methods is estab-
lished.
The approximation in (14.118) is only good at the optimum. Therefore, it comes at the cost of
very slow to zero convergence rate when the residuals are large. To circumvent this problem, a
damped Gauss-Newton method is often employed:
θ(i+1) = θ(i) −µi(Ψ(θ(i))T Ψ(θ(i)))−1Ψ(θ(i))Tεi
(14.120)
where the damping factor µi is adjusted such that JN decreases with every iteration.
Gauss-Newton algorithms run into diﬃculties when Ψ(θ(i))T Ψ(θ(i)) is rank deﬁcient. A modi-
ﬁcation of the method addresses this issue (see below).
4. Levenberg-Marquardt algorithm: This method belongs to the class of approaches that attempt to
ensure positive deﬁniteness of the Hessian in the steepest descent, Newton-Raphson and Gauss-
Newton methods by adding a suitable matrix. The L-M algorithm has a simple approach
H(i)
c
= H(i) + λIp×p
(14.121)
where λ is the so-called regularization parameter. In addition to handling anomalies in H, it is
used to control the convergence rate of the scheme.
In applying the algorithm to G-N methods, the approximate Hessian (14.118) is used as the
Hessian in (14.121).
5. Quasi-Newton methods: The quasi-Newton schemes essentially are a generalization of the L-M
algorithm (Bazaraa, Sherali and Shetty, 2006). They use a symmetric correction matrix to the
inverse of the Hessian, ¯H ≜H−1 after every iteration.
¯H(i+1) = ¯H(i) + C(i)
(14.122)
where C is a symmetric matrix. At the ﬁrst iteration, the inverse is initialized to identity, ¯H(0) = I.
Two popular algorithms in this category are the Davison-Fletcher-Powell (DFP) and the
Broydon-Fletcher-Goldfarb-Shanno (BFGS) algorithms (Bazaraa, Sherali and Shetty, 2006).

386
Principles of System Identiﬁcation: Theory and Practice
6. Trust-region methods: The previously described algorithms can be collectively classiﬁed as line-
search methods where the solution is searched in the direction of the decreasing gradient using
adaptive steps.
A fundamentally diﬀerent approach is taken in the trust-region methods, where the objective
function is approximated in the neighbourhood of θ(i) using a model m(i)(θ(i+1)−θ(i)) (typically
a quadratic). At each iteration the objective is to ﬁnd that change in the parameter vector that
secures the minimum of this model in a “trust” region, i.e., where the model approximation
is good. This change is accepted provided an acceptable decrease in the objective function is
noticed. The model as well as the trust-region are updated after each iteration.
The iterative algorithm is summarized below.
1. Specify initial guess θ(0), maximum search step size ¯△, initial trust region size △0 ∈(0, ¯△)
and acceptance constant β ∈
f
0, 1
4 ).
2. Deﬁne δi ≜θ(i+1) −θ(i). Solve
min
δi mi(δi) = J(θ(i)) + δT
i gi + 1
2δT
i H(i)δi
(14.123)
s.t. ||δi|| ≤△i
(14.124)
3. Compute the reduction ratio at the optimum δ⋆
i .
ζi = J(θ(i)) −J(θ(i) + δ⋆
i )
mi(0) −mi(δ⋆
i )
(14.125)
4. Update the parameters and the trust region as follows:
θ(i+1) =

θ(i) + δ⋆
i ,
ζi > β
θ(i),
otherwise
(14.126)
△i+1 =

1
4△i,
ηi < 1
4,
min(2△i, ¯△),
ηi > 3
4 and ||δi|| = △i
△i,
otherwise
(14.127)
Despite the diﬀerence in the underlying philosophies, the Levenberg-Marquardt algorithm can
also be cast into a trust-region method. For a good exposition of the trust-region algorithms, see
Bazaraa, Sherali and Shetty (2006).
For a detailed description of the foregoing algorithms and rigorous discussion on nonlinear regres-
sion, the reader is referred to related texts (Amemiya, 1985; Bazaraa, Sherali and Shetty, 2006;
Dennis and Schnabel, 1996; Seber and Wild, 1989).
14.4.2
SPECIAL CASES
The non-linear regression problem takes special forms depending on the form of s(.). When si(.) =
exp(θiϕi), it is known as an exponential regression problem; logistic functions si(.) = θ1/(1 +
θ2 exp(θ3ϕi)) give rise to logistic regression - these are commonly used in growth studies or when
the response variable is qualitative. A general class of non-linear regression models that is popularly
and sometimes imprudently employed in the non-linear system identiﬁcation is the neural network
model. These models can potentially model a very diverse set of processes, which is the reason for
their popularity. Section 25.2.1 presents the technical details of the diﬀerent types of neural network
models. The related chapter also discusses two other common non-linear modeling paradigms in
identiﬁcation, namely the Hammerstein-Wiener models and nonlinear ARX (NARX) models.
We make a special mention of two common situations pertaining to the predictor being (i) linear
and (ii) pseudo-linear in parameters. Of the two, the former is simpler since no iterative algorithms
are required. These models can be estimated using linear LS methods.

Estimation Methods: Part I
387
14.4.2.1
Linear in Parameters
A predictor function is linear in the unknowns when it has the form
ˆy(k,θ) =
p
X
i=1
θi fi(ϕ[k])
(14.128)
where fi(ϕ) is a known non-linear function of the regressor set ϕ. Thus, the NLS formulation
reduces to a linear LS problem for the predicted and the functions of explanatory variables. The
limitation is that the knowledge of these functions should be known to the user either through
process knowledge or from prior experience. Polynomial regression is a classical example of the
linear-in-parameters case.
Example 14.8: Linear in Parameters
Consider ﬁtting a model between the power drawn P and the ﬂow of current ϕ = I through
a wire. We know from Ohm’s law that an approximate relationship exists:
P ∝I2 =⇒
P = θI2
Thus, a linear regression problem to determine θ can be set up by choosing ϕ = I2.
14.4.2.2
Linear via Transformation
The non-linear regression problem may be transformed to a linear by a suitable transformation of
variables.
fy(y[k]) = fϕ(ϕ[k])θ
(14.129)
where fy(.) and fϕ are the functions for the respective variables.
Example 14.9: Estimation of Activation Energy
In physical chemistry, a classic non-linear regression problem is that of determining the
activation energy Ea from the Arrhenius equation given the rate constant k and temperature
T data,
k = e−Ea/RT
(14.130)
where R is the universal gas constant. A standard approach is to transform both sides of the
equation
ln k = −Ea
1
RT
(14.131)
and use the OLS estimator for Ea by setting y ≡ln k and ϕ = 1/RT.
An extension of these ideas leads to estimation using projections of the response and explanatory
variables on to a chosen basis set (for example, Fourier, wavelet basis).
Remarks:
In transforming a non-linear regression problem to a linear in parameters formulation, it is im-
portant to understand that the error characteristics are also transformed. In Example 14.9 for instance, the
reaction rate constants and temperatures were transformed. But these variables contain measurement errors.
The characteristics of the transformed randomness can have a serious inﬂuence on the standard errors of the re-
sulting parameter estimates. Quite often it is not trivial to determine the probabilistic nature of the transformed
errors.

388
Principles of System Identiﬁcation: Theory and Practice
14.4.2.3
Pseudo-Linear Regression
Identiﬁcation of linear time-invariant systems using parametric prediction-error models involves
non-linear regression problems that can be re-cast into the form.
y[k] = ϕT (k,θ)θ + ξ[k]
(14.132)
where ϕT (k,θ) is an implicit function of the parameter vector θ. Due to its strong semblance with
the linear regression, the problem is known by the name pseudo-linear regression (PLR). Also ob-
serve that ϕ(k,θ) in the PLR is identical to the pseudo-regressor ψ(k,θ) in (14.106a). The class of
models belonging to ARMAX, OE and Box-Jenkins structures can all be cast in the pseudo-linear
regression form.
Example 14.10: PLR Form of an OE Model
Recall the output-error model (2.17) for the liquid level system in Chapter 2:
ˆy[k] = −a1x[k −1] + b1u[k −1]
(14.133)
where x[k] is the unknown noise-free response of the model and ˆy[k] is the prediction of
observed response. The non-linear LS estimation of parameters can be cast as a PLR problem
by observing
θ =
f
−a1
b1
gT
ϕ(k,θ) =
f
−x[k −1]
u[k −1]
gT
(14.134)
The noise-free response of the model, using (2.12), can be written as a ﬁltered input4,
x[k] = −a1x[k −1] + b1u[k −1] =⇒x[k] =
b1q−1
1 + a1q−1 u[k]
Thus, given θ, one can compute x[k] (of course with a speciﬁcation of the initial values).
Chapter 17 provides the PLR form for all the parametric model structures mentioned above.
The estimation algorithm for PLR is also iterative in nature. However, a nice feature is that at each
iteration only a least squares problem need be solved as seen below.
i. Initialize the regressors. A common choice is to use estimates from a regular linear regression
model.
ii. Obtain an estimate of θ with the initial regressor. Given the regressor, it is a linear estimation
problem and hence a LS method is applied.
iii. Update the regressors and estimates iteratively until convergence.
The exact implementation details and the convergence properties are presented in §21.6.2.1 in the
context of estimating parametric models.
14.4.2.4
Algorithmic Aspects of NLS Methods
In the implementation of non-linear solvers, three issues call for attention: (i) gradient computation
(ii) initial guess for the parameters and (iii) stopping criterion.
4Note that the true response of the system is independent of the parameter θ.

Estimation Methods: Part I
389
Computing the gradients
The gradients involved in the NLS algorithms can be computed only numerically. Generic expres-
sions for carrying out these calculations exist only for select model structures. In identiﬁcation, the
parametric prediction-error models fortunately fall into this basket. The gradient computations for
these structures take the shape of ﬁltering operations. The exact ﬁlter that is to be used depends on
the model structure. Chapter 21 presents related expressions for ARMAX, OE and other structures.
The PLR form of these structures are useful in deriving the ﬁltering equivalents of the gradients.
Initial guess and Convergence criteria
Any non-linear optimization solver relies on two inputs from the user:
i. Initial guess: The starting points can have a signiﬁcant impact on the convergence of the solver.
Regardless of the algorithm, it is always recommended to take any prior information and phys-
ical knowledge of the process into account while feeding the initial guess. General practices
include using the estimates of a linear least squares algorithm, random number generator, etc.
The sensitivity of the algorithms to initial values can considerably diﬀer from each other. In
system identiﬁcation, initial parameter guesses are generated using linear or other non-iterative
algorithms (see §22.6.2).
ii. Termination criteria: The inﬂuence of these criteria on the optimizer is not as drastic as the initial
guess, but still determines the ﬁnal quality of solution. The stopping conditions are typically of
the form:
a. No signiﬁcant decrease in the objective function: |J(θ(i+1)) −J(θ(i))| < δJ
b. Gradient has decreased to a tolerably small value: ||g(θ(i))||2 < δg
c. No signiﬁcant improvement in the parameters: ||θ(i) −θ(i−1)||2 < δθ where each δ is a
user-deﬁned tolerance.
Several software packages also consider a limit on the maximum number of iterations as a
practical termination criterion.
14.4.3
ASYMPTOTIC PROPERTIES OF THE NLS ESTIMATOR
The complexity of NLS algorithms makes it very diﬃcult to analyze the properties of the estimators
in a transparent manner. Under mild conditions stated below, the NLS estimators are known to
be consistent and result in asymptotically normally distributed estimates. Without dwelling on the
complicated derivations, only the ﬁnal results are stated. The reader is referred to Amemiya (1985)
and Seber and Wild (1989) for technical details.
The data generating process is assumed to be
y[k] = s(θ,ϕ[k]) + ξ[k]
(14.135)
where ξ[k] is the usual stochastic term representing noise, disturbances, etc.
The following conditions are standard assumptions in non-linear regression problems although
they are not necessary for consistency.
i. Identiﬁability: This is a standard requirement even for linear models, for which the simple con-
dition of full rank was suﬃcient. For non-linear models, the requirement is that s(θ1,ϕ) =
s(θ2,ϕ) ⇔θ1 = θ2.
ii. Diﬀerentiable functional form: This requirement is necessary for the existence of gradients, and
even for a solution to exist.
iii. Correlation between gradient and disturbance converges to zero at the optimum. In the presence
of feedback this assumption does not hold.

390
Principles of System Identiﬁcation: Theory and Practice
iv. Stochastic nature of ξ[k]: The disturbance is conditionally zero-mean, homoscedastic, zero tem-
poral correlation and has ﬁnite second-order moments:
E(ξ[k]|s(ϕi[k],θ)) = 0 ∀i = 1,· · · ,pr
(conditionally uncorrelated)
(14.136a)
E(ξ[k]ξ[k −l]|s(ϕ[k],θ)) = 0
(zero conditional auto-correlation)
(14.136b)
E(ξ2[k]|s(ϕ[k],θ)) = σ2
e < ∞
(ﬁnite conditional variance)
(14.136c)
Observe that we do not appeal to a particular probability distribution for ξ[k]. However, where
eﬃciency is claimed, the Gaussian distribution assumption is necessary.
v. Exogeneity of explanatory variables: This roughly translates to no correlation between the re-
gressors and the noise term.
The reader is encouraged to recall and compare similar requirements in the linear regression case.
Consistency
The following assumptions are assumed in establishing weak consistency (Amemiya, 1985).
A-1 Compact parameter space: Essentially this implies that the space Θ to which θ belongs is
closed and bounded.
A-2 Convergence of the objective function:
JN (θ,Φ)
p
−→
J(θ)
∀θ
(should be continuous and diﬀerentiable)
A-3 Continuity of J(θ): The objective function is continuous and diﬀerentiable on the parameter
space Θ.
A-4 Unique minimum of J(θ): The objective function J(θ) has a unique minimum at θ0.
Theorem 14.5: Consistency of NLS Estimators
Under the conditions (A-1)-(A-4), the LS estimator of the parameters θ ∈Θ of the non-linear
regression model is weakly consistent
ˆθ⋆
NLS
p
−→θ0
(14.137)
Proof. See Amemiya (1985) and Seber and Wild (1989).
□
Remarks:
a. Strong consistency can be established by making additional assumptions on the function s(θ,ϕ) (see
Amemiya (1985)).
b. It is often the case that the model guessed by the user is not identical to the “true” model of the process.
Then, the algorithm will converge to the values that yield the best approximation under the user-speciﬁed
function (this result carries forward to the prediction-error methods for identiﬁcation, see Chapter 21).
c. In most literature, the assumption (A-1) is replaced by a zero-mean and i.i.d. requirement.
In the identiﬁcation of non-linear dynamic models, the stipulations are similar. The requirements
are spelt out in Chapter 21 where the more generic prediction-error method is discussed.

Estimation Methods: Part I
391
Asymptotic Normality
The NLS estimates asymptotically follow a Gaussian distribution regardless of the actual distribu-
tion of the noise term ξ[k], provided the following conditions are met:
N-1. The covariance of pseudo-regressors at the true value θ0 converges in probability to a positive
deﬁnite covariance matrix:
1
N Ψ(θ0)T Ψ(θ0)
p
−→Σ0
Ψ
(14.138)
N-2. The covariance between regressors at the true value and the noise term converges in distribution
to a Gaussian:
1
√
N
Ψ(θ0)Tξξξ
d
−→N (0,σ2
eΣ0
Ψ)
(14.139)
Theorem 14.6
Under the assumptions (N-1) to (N-2) and consistency, the least squares estimates of the non-linear
model in (14.135) have the property
√
N( ˆθNLS −θ0)
d
−→N

0,σ2
e(Σ0
Ψ)−1
(14.140)
where the asymptotic covariance matrix Σ0
Ψ is given by (14.138),
Proof. See Amemiya (1985) and Seber and Wild (1989).
□
As in the case of linear LS methods, we need an estimator of the noise variance σ2
e to be able to
estimate Σ ˆθ.
A consistent estimator of σ2
e is given by
ˆσ2
e = 1
N ||y −ˆy( ˆθ,ϕ)||2
2
(14.141)
analogous to the linear LS case (14.59).
The theoretical covariance matrix in (14.140) is replaced by its estimate so that,
ˆΣθ = ˆσ2
e(Ψ(θ0)T Ψ(θ0))−1 = σ2
e
N (Σψ)−1
(14.142)
Observe the strong similarity between the expressions for variance of NLS and linear LS estimate
in (14.56). The result should be expected given the analogy between the regressor matrices Φ of the
LLS and the pseudo-regressor Ψ(θ0) of the NLS. It is important to point out that in neither problem,
the normality assumption on ξ[k] is necessary (except when claiming eﬃciency).
In a nutshell, the large sample properties of linear least squares estimates, with appropriate ana-
logues, apply to the non-linear least squares estimates as well. The analogy extends to the weighted
non-linear least squares formulation as well.
With the distribution and the estimate of parameter-error variance in hand, hypothesis testing
on the parameters (or their functions) can be carried out in a manner similar to the linear case. The
Wald statistic and the Lagrange multiplier test are commonly used for this purpose (Seber and Wild,
1989).

392
Principles of System Identiﬁcation: Theory and Practice
The asymptotic analysis presented above is obviously valid only when the number of observa-
tions is large. Furthermore, the model should satisfy the standard requirements of residual analysis
in order to be able to apply these results. Small sample behavior of these estimates are diﬃcult to
analyse. Bootstrapping methods (recall Section 13.13) oﬀer a good alternative in this context. They
can be applied to a larger class of non-linear estimators including GMM and MLE. An added advan-
tage is that these methods do not make any binding assumptions on the model or the data. Refer to
Davison and Hinkley (1997) and Zoubir and Iskander (2004) for a broad application of these ideas.
NLS in identiﬁcation
Non-linear least squares estimator is at the heart of several identiﬁcation algorithms. The NLS is
in fact a special form of the more general prediction error methods. Chapter 21 presents the NLS
formulation for the estimation of diﬀerent discrete-time LTI model structures. Therefore, we refer
the reader to the appropriate sections for illustrative examples on such applications.
Quite often one is interested in a continuous-time process model. Numerous classical methods
are available for this purpose. Over the last two decades, the NLS or prediction-error methods have
been systematically applied for building continuous-time process models as well by parametrizing
the discrete-time model in terms of the continuous-time process parameters. The example below
illustrates one such application.
Example 14.11: Estimating a Continuous-Time Process Model
Revisit the liquid level process of Chapter 2, where a suitable discrete-time model was
identiﬁed. Suppose instead we choose to identify the underlying continuous-time process.
From the physics of the process, we postulate a ﬁrst-order-plus-dead-time (FOPTD) model:
G(s) =
Kp
τps + 1e−Td s
(14.143)
where the parameters have their usual meanings. Note that Td is the process delay and should
not be confused with the delay due to ZOH. Truly speaking the process has no delay in it.
However, we let the estimation algorithm speak for itself.
From Chapter 6, the discrete-time model for the liquid level x[k] in terms of the parameters
θ =
f
Kp
τp
Td
gT is
x[k] = e−(t−Td)/τp x[k −1] + Kp(1 −e−(t−Td)/τp )u[k −1]
(14.144)
From our experience with discrete-time empirical modeling for this process, we shall assume
the measurement to be described by an output-error model
ˆy[k] = x[k] = e−(t−Td)/τp x[k −1] + Kp(1 −e−(t−Td)/τp )u[k −1]
(14.145)
The predictor is obviously a non-linear function of the unknowns. Setting up the NLS problem
min
θ
N−1
X
k=0
(y[k] −ˆy[k])2
and running the estimator (in MATLAB) produces:
ˆτp = 8.0162(±0.1351);
ˆKp = 3.9928(±0.0412)
ˆTd = 0.049(±0.0262)
(14.146)
where the values in parentheses are 1σ-standard errors as usual. The 95% conﬁdence interval
for the delay parameter includes a zero. Thus, the hypothesis H0 : Td = 0 cannot be rejected.

Estimation Methods: Part I
393
Listing 14.10
MATLAB code for Example 14.11
% Load liquid level data
load liqleveldata.mat
% Collect data
Z = iddata(yk,uk,1);
datatrain = detrend(Z,0);
% Estimate FOPTD process model
Gp1 = pem(datatrain ,’p1d’);
present(Gp1)
% Delay = 0; Now estimate first-order model
Gp2 = pem(datatrain ,’p1’);
present(Gp2)
% Residual analysis
resid(Gp2,datatrain);
Re-estimating the process model excluding the delay term marginally improves the estimates
of the gain and time-constant:
ˆτp = 8.1416(±0.1246);
ˆKp = 4.0109(±0.0404)
(14.147)
The true values (based on the linearized model) for this process are τp = 8 min. and Kp = 4.
The initial guess for the estimates are obtained by an indirect computation of θ from the
identiﬁed discrete-time OE model in (2.18)
ˆτ(0)
p
= −
Ts
ln(0.8826) = 8.0075;
ˆK(0)
p
=
0.4621
1 −0.8812 = 3.9361
(14.148)
while the gradients are computed using the ideas outlined in Section 21.6.3.
The ideas in the foregoing example can be extended to accommodate other possible noise models
by choosing an appropriate model structure (e.g., Box-Jenkins). Identiﬁcation of continuous-time
models is an exciting area ﬁlled with challenges. Several interesting methods have appeared on the
forefront in the last two decades (Garnier and Wang, 2008; Rao and Unbehauen, 2006; Unbehauen
and Rao, 1990).
In closure, the task of estimating parameters of a non-linear model is challenging, but is also
well-countered by sophisticated methods. When applying these techniques, the reader should make
an eﬀort to provide a good initial guess and choose an optimization algorithm that has a good mix
of properties such as convergence, robustness to initial conditions, etc. Eventually, the solution is
practically a local minimum.
14.5
SUMMARY
This chapter presented two methods of estimation, namely, the method of moments and the least
squares methods. MoM rests on a simple idea, but does not necessarily produce eﬃcient estimates.
GMM estimators, however, can be tuned to produce eﬃcient estimates with an appropriate choice of
weights. They also enhance the scope of applicability of the MoM estimator. Least squares methods
have their origins in functional approximation problems and produce unique estimates when the
predictor (or the approximating function) is linear in unknowns.
Ordinary least squares produces optimal (eﬃcient) estimates when the equation errors are white.
The weighted least squares extends its applicability and can handle a variety of situations. Non-
linear least squares takes this one step further by incorporating non-linear predictors. However,

394
Principles of System Identiﬁcation: Theory and Practice
the price that is paid is the lack of a closed-form solution and the local optima discovered by the
numerical solvers.
The asymptotic properties of OLS, WLS and NLS have been presented. There exist other special-
ized variants of these methods with their trademark applications.
The presentation in this chapter has been largely oriented for the static problem while providing
glimpses of their applications to dynamic processes through illustrative examples. Part IV is an
expansion of these ideas to modeling of dynamic systems.
14.A
APPENDIX
14.A.1
PROJECTION THEOREM
The projection theorem provides a result that is central to parameter estimation as well as prediction.
Theorem 14.7: Projection Theorem
Let C be a closed subspace of the Hilbert space H and let y be an element in H. Then, y can be
uniquely decomposed into two parts
y = ˆy + ε
(14.A.1)
where ˆy belongs to C and ε is orthogonal to ˆy, i.e., ε ⊥ˆy or ⟨ε, ˆy⟩= 0. This decomposition is unique
in the sense that it minimizes the distance between y and any other vector w in C,
||y −ˆy||2 ≤||y −w||2
∀w ∈C
(14.A.2)
with the equality holding only when w = ˆy.
Proof. See Shumway and Stoﬀer (2006).
□
The vector ˆy is said to be the projection of y onto the C (or the bases spanning C) and is denoted
by PCy.
A corollary of the projection theorem is that the residual ε is orthogonal to every basis vector of
the subspace C.
The closed subspace of H is generated by a closed span of a ﬁnite set of elements {x1, x2,· · · , xp}
of H. In other words, every w ∈C can be written as
w =
p
X
i=1
αi xi
(14.A.3)
The optimal projection (or approximation) of y onto C can be determined by solving the p orthog-
onality conditions
⟨y −PCy, xi⟩= 0,
i = 1,· · · ,p
(14.A.4)
14.A.2
DECOMPOSITION THEOREM
The decomposition theorem is in essence identical to the projection theorem, but is set in the stochas-
tic framework. It oﬀers a fundamental result in estimation theory, which is that the conditional ex-
pectation is the best approximation or prediction in the mean-square sense.

Estimation Methods: Part I
395
Theorem 14.8: Decomposition Theorem
Any random variable Y can be decomposed into two terms
y = E(Y |X) + ε
(14.A.5)
such that
C1. E(ε|X) = 0 (error is uncorrelated with the regressor)
C2. E(h(X)ε) = 0, where h(.) is any function of X (error is uncorrelated with any function of the
regressor)
This decomposition is also the minimum mean square approximation of Y using X, denoted by
g(X).
E(Y |X) = min
g(X) E((Y −g(X))2)
(14.A.6)
Proof.
i. Proof of zero conditional mean.
E(ε|X) = E((Y −E(Y |X))|X) = E(Y |X) −E(Y |X) = 0
ii. E(h(X)ε) = E(E(h(X)ε|X)) = E(h(X)E(ε|X)) = 0
The proof for the conditional expectation being the MMSE estimator of Y is left as an exercise (see
Exercise E14.11).
□
Recall that E(Y |X = x) is a function of X, but not necessarily linear. However, if X and Y have a
joint Gaussian distribution, then E(Y |X) is a linear function of X.
The connection between the projection and decomposition theorems is established by treating
random variables in the Hilbert space.
14.A.3
QR FACTORIZATION
The QR factorization of any N × p rectangular matrix X is given by
XP = QR
(14.A.7)
where Q is either a N × N square matrix (full factorization) or rectangular of size N × p (economy
factorization) and R is correspondingly a N × p rectangular or a p × p square matrix. The quantity
P is a permutation matrix meant to permute columns of R so that it can be partitioned as
R =
 R1
0
!
(14.A.8)
such that the diagonal elements of R are non-increasing.
Importantly, in the full factorization
QTQ = I = QQT
PTP = I = PPT
(orthogonal)
(14.A.9)
Q =

Q1
Q2

(14.A.10)

396
Principles of System Identiﬁcation: Theory and Practice
where Q1 : RN×p stems from X while Q2 : RN×(N−p) is arbitrarily chosen such that it is orthogonal.
Further, R1 is a non-singular, right or an upper triangular matrix.
In an economy factorization, only Q1 and R1 are returned. Note that Q1 only satisﬁes QT
1 Q1 =
Ip×p
The QR factorization can also be used to determine the rank of X, known under the name of rank-
revealing QR (RRQR) factorization. Rank is essentially the size of non-zero diagonal elements of
R1. A related fact is that det(X) = Qp
i=1 rii.
The set of linear equations can be re-written using the QR factorization as follows
Xθ = y =⇒Rθ = QTy
(14.A.11)
where we have made use of the properties of Q and R.
The advantage of using a QR factorization in solving linear equations is that the solution can be
computed without explicitly computing Q. This is due to the fact that R can be computed by a series
of Householder reﬂections
Hp · · · H2H1X = R
(14.A.12)
Putting together (14.A.11) and (14.A.12), we obtain
Hp · · · H2H1 = QT
(14.A.13)
The Gram-Schmidt normalization procedure can also be used to obtain the factors.
Implementation details and technicalities of these methods can be found in the classic text by
Golub and Loan (1996).
14.A.4
SINGULAR VALUE DECOMPOSITION
The full SVD of a rectangular matrix X : RN×p is its factorization as
X = UN×NSN×pVT
p×p
(14.A.14)
such that the factors satisfy
UT U = IN×N ;
VT V = Ip×p
(orthonormal)
(14.A.15)
S :
"
S1
0p×(N−p)
0(N−p)×p
0(N−p)×(N−p)
#
(p −diagonal)
(14.A.16)
where S = diag(σ1,· · · ,σp), σ1 ≥σ2 ≥· · · ≥σp is a diagonal matrix of singular values of X.
The columns of U and V are said to contain the left and right singular vectors of X, respectively
The matrix V and S2
1 (diagonal matrix of squared singular values) are the eigenvectors and eigen-
values of XTX, respectively, as seen below
XTX = (USVT )T (USV) = VΛVT =⇒(XTX)V = VΛ
(14.A.17)
where Λ = STS is a p × p diagonal matrix of eigenvalues. Similarly, U contains the eigenvectors of
XXT.
Further, (14.A.14) can be written as
XV = US
(14.A.18)
telling us that the orthonormal vectors in V are mapped to the orthonormal columns of U through a
scaling matrix S.

Estimation Methods: Part I
397
In an economy SVD, as in the case of QR factorization, the matrices U, S are restricted to N × p,
p × p, respectively.
SVD is considered as an extension of the eigenvector decomposition of square matrices to rect-
angular matrices. A useful interpretation is that SVD expresses the matrix X as a series of rotation,
scaling and rotation operations. It is one of the most powerful tools in data analysis and has a number
of applications.
The two most important properties of SVD are
1. When X is rank r < p (assuming N < p), i.e., rank deﬁcient, then (p −r) singular values are
identically zero
2. Reconstructing X using only the ﬁrst r singular values (and the corresponding rows and columns
in VT and U) provides the best rank r approximation in the 2-norm sense. That is, for any
rectangular matrix X,
ˆXr =
rX
i=1
σi(uivT
i ) = arg
min
Y,rank(Y)=r||X −Y||2
2
(14.A.19)
When X is exactly of rank r, then the above approximation is exact.
A standard application of SVD is to solve a set of linear equations involving p parameters with a
rank deﬁcient matrix X,rank(X) = r < p, as brieﬂy illustrated below.
Xθ = y =⇒S VTθ
|{z}
β
= UTy
|{z}
˜y
;
Thus, βi = ˜yi/σi,
i = 1,· · · ,r
Then, the solution is
θ = Vβ
(14.A.20)
where the “free” βi, i = r + 1,· · · ,p are arbitrarily chosen.
SVD is also closely related to the popular principal component analysis method, as delineated in
§26.3.
REVIEW QUESTIONS
R14.1 Describe the basic principle in the method of moments.
R14.2 What are the advantages and disadvantages of a MoM estimator?
R14.3 Discuss the sample and population versions of a least squares estimator.
R14.4 When does the LS method yield a unique estimate?
R14.5 Explain the diﬀerences between the regular R2 and the adjusted R2.
R14.6 List the main assumptions that are made in studying the properties of LS estimators.
R14.7 Under what conditions (on the data) are linear LS estimators eﬃcient?
R14.8 When are linear LS estimators consistent?
R14.9 Do linear LS estimates always follow Gaussian distribution? If yes/no, why?
R14.10 Explain how you would derive the distributional properties of function of linear LS parameter
estimates.
R14.11 Describe the numerically eﬃcient ways of implementing the LS solution.
R14.12 List a few popular variants of least squares estimators.
R14.13 What is the prime diﬀerence between weighted LS and ordinary LS estimators?

398
Principles of System Identiﬁcation: Theory and Practice
R14.14 The optimal weighting in WLS methods is the inverse of noise covariance matrix. Explain this
statement.
R14.15 Explain the main challenges of non-linear LS problems.
R14.16 Describe the methods used in solving the non-linear LS optimization problem. Speciﬁcally discuss
the merits and demerits of each of those methods.
R14.17 What is pseudo-linear regression and for what classes of problems is it suited?
EXERCISES
E14.1 Show that the median is the best 1-norm estimator of the mean.
E14.2 Evaluate the sensitivity of mean and median to the presence of a single outlier in the data, present
at random, and of magnitude A.
E14.3 Show that the method of moments does not necessarily give rise to a unique estimator. Consider
the estimation of the parameter of an exponential distribution function to illustrate this fact.
E14.4 Derive the LS solution (14.21) using the (i) standard optimization approach, i.e., by solving
dJ/dθ = 0 and (ii) completion of sum squares.
E14.5 Prove that the R2 measure deﬁned in (14.43) is the squared correlation between the observations
and predictions from a LS estimator.
E14.6 Show that the estimator of error variance in (14.59) is unbiased.
E14.7 Consider the process
y[k] = b1u[k −1] + b2u[k −2] + b3u[k −3] + w[k]
where b1 = 2, b2 = 1.2, b3 = 0.4. Assume w[k] to be a zero-mean Gaussian WN sequence.
E14.8 The following experiment has been made to determine the acceleration constant g. A steel ball
has been dropped without initial velocity from a rooftop. The position of the ball h (relative to the
rooftop) versus time t is recorded as:
Time (s) t
1
2
3
4
5
6
Position (m) h
8.49
20.05
50.65
72.19
129.85
171.56
The times of the measurement are exact, but there is an error in the measurement of the position.
a. Determine g using the least squares method.
b. Can you compute the errors in ˆg from the given data? Why/why not?
E14.9 A chemical company, wishing to study the eﬀect of extraction time x in minutes on the eﬃciency
of extraction operation y (in %), obtained the data shown below
x
27
45
41
19
35
39
19
49
15
31
y
57
64
80
46
62
72
52
77
57
68
a. Visually inspect the data and judge whether a linear model is justiﬁed.
b. Compute the correlation to conﬁrm your ﬁndings in the previous part.
c. Obtain the LS estimates of the parameters of the linear model y = αx + β.
d. Provide the 95% conﬁdence interval on α.
a. Generate 2046 samples of the output using a PRBS input (containing two levels -1 and 1 and
frequency content [0 0.2]). Adjust the variance of w[k] such that the output SNRout is set to
10.
b. Assuming full knowledge of the deterministic portion of the process, construct the regressor
matrix Φ, the stacked observation vector Y and estimate the parameter vector θ using the LS
method.
c. Compute the predictions, residuals and estimate the variance of w[k] from the residuals. Esti-
mate the co-variance as ˆΣ ˆθ = (ΦT Φ)−1 ˆσ2w. Construct the 95% conﬁdence intervals for each of
the parameters using the estimated co-variance. Are the conﬁdence intervals narrow?

Estimation Methods: Part I
399
d. Repeat parts (a) and (b) for 200 diﬀerent realizations of w[k]. Estimate the mean and co-
variance of ˆθ from the resulting parameter estimates. Is the average close to θ0, the true
value?
e. Compute the 95% conﬁdence intervals for the 200 realizations by repeating part (c) and the
covariance of parameter estimates for each realization that you computed in part (d). How
many times does the 95% conﬁdence interval not contain the true value?
f. In constructing the conﬁdence intervals for the parameters, we assume a normal distribution
of the parameter estimates. Can you verify this assumption? Does this distribution hold even
if w[k] were to be uniformly distributed with the same mean and variance?
E14.10 We learned the theory of distribution of parameter estimates obtained from the OLS method.
You are required to verify this in practice. For this purpose, generate 4000 samples of data of a
process described by:
y[k] = 0.8u[k −1] + 0.6u[k −2] + 0.25u[k −3] + 0.1u[k −4] + e[k]
where u[k] is a random noise ﬁltered through F(q) = 1/(1 −0.5q−1) and e[k] is a zero-mean white-
noise sequence such that the SNR (with respect to input) is 10.
Carry out the following tasks to get an experience of the related theory:
a. Remove the mean from the input-output data.
b. Fit an FIR model of order 4 (assuming the correct knowledge of delay).
c. Repeat (a)-(b) for 200 diﬀerent realizations of e[k].
d. Verify with any randomly chosen 5 data sets the results obtained in the text on the orthogonality
of residuals with ϕ[k].
e. Verify the theoretical results on unbiasedness of parameter estimates using data from all real-
izations.
E14.11 Show that the function g(X) that minimizes E((Y −g(X))2), where Y and X are two random
variables, is the conditional expectation E(Y |X).

15
Estimation Methods: Part II
This chapter is a sequel to Chapter 14. Two powerful classes of estimators, namely, maximum
likelihood and Bayesian estimators are reviewed. Both methods are based in the probabilistic
framework.
15.1
MAXIMUM LIKELIHOOD ESTIMATORS
The maximum likelihood estimation (MLE) is one of the most powerful estimation methods avail-
able today. It is based in the probabilistic framework unlike the least squares methods above, whose
original formulation was cast as a functional approximation. Despite their distinctive philosophies,
we can establish a strong equivalence between these approaches by casting the LS method in a
probabilistic framework.
As with several other classical topics in this text, numerous scholarly and instructive articles,
textbooks and expositions on MLE have been written. The purpose of the following presentation is
of course largely pedagogical. Accordingly, the aim is to instill the basic concepts underlying MLE
without any frills. Technical details are presented to the necessary level and established results are
stated without dwelling into the proofs. It is hoped that this presentation will equip the reader with
the necessary skill to formulate an estimation problem in the MLE form.
The MLE, as it was originally formulated, was primarily meant for estimating the parameters of
probability density (distribution) functions. However, without much extra eﬀort it can be extended
to estimate parameters of dynamic models from measurements containing stochastic inﬂuences.
The foundation of this method is on the notion of likelihood. Therefore, it is necessary to clearly
understand this concept.
Notion of likelihood
The concept of likelihood is closely related to that of conditional probability or inverse probability
(Bayesian ideas), but is not identical to it (see Fisher (1922)).
For any probabilistic event associated with a RV Y, we can compute the probability Pr(y1 < Y <
y2) given its probability density function f (y|θ), where θ is the parameter vector characterizing the
density function. However, in data analysis, the situation is that we are given a set of observations
yN = {y[0], y[1],· · · , y[N −1]}, meaning that the event has occurred and we are interested in
“guessing” or estimating (i) the form of the density function (model) and (ii) the parameters of that
function. Obviously there exist inﬁnite possibilities for f (y). This problem is not much diﬀerent
from selecting the best function that approximates a response-explanatory variable relationship.
The only distinguishing aspect is that the unknowns are the parameters of a p.d.f. rather than that of
a model.
Returning to the main point, a criterion for selecting the “best” parameter is that it should maxi-
mize the probability of occurrence of y in the range yN to yN + dy. The resulting optimal parameter
estimate is then termed as the one that most likely produces this event among all choices of θ. In his
seminal paper, Fisher (1922) coined the term likelihood to describe this approach1. Since y is ﬁxed
1This paper dismisses the notion of inverse probability principle on which Fisher arrived at the criterion in his 1912 paper
(Fisher, 1912).
400

Estimation Methods: Part II
401
and the optimizing variable is θ, the function to be optimized is denoted diﬀerently as l(θ|y) and
termed as the likelihood function. It originates from the p.d.f. since the probability of obtaining the
data yN is proportional to the p.d.f. f (yN |θ). That is to say,
l(θ|yN ) ∝f (y|θ)
(15.1)
Despite sharing the same ground, the fundamental diﬀerence between l(θ|y) and f (y|θ) is that the
former is a function of a deterministic vector θ, while the latter is a function of the random vector
y.
Conditional probability perspective
From another (Bayesian) perspective, the likelihood function has a strong connection to the condi-
tional probability density f (θ|yN ) as seen below. The reason it is not identical to f (θ|y) is that we
have restricted the parameter vector to be deterministic.
If θ were random, from the basics of conditional probability,
f (θ|yN ) f (yN ) = f (yN |θ) f (θ)
=⇒f (θ|yN ) = f (y|θ) f (θ)
f (y)
(15.2)
The density function f (θ) is known as prior distribution in Bayesian language (see Section 15.2).
When the parameter vector is deterministic, f (θ) disappears from (15.2). Consequently, the condi-
tional density can be thought of as an ordinary function of θ for a ﬁxed set of observations. Given
that yN is ﬁxed, the denominator is simply a constant, thereby giving us (15.1).
Remarks:
The above perspective of MLE was put forth by Fisher’s contemporaries who were using Bayes’
ideas to derive parameter estimates by maximizing the probability of θ given y (maximum a posteriori esti-
mates). However, Fisher argued in his paper (Fisher, 1922) that this is not the scheme in which the MLE was
proposed. Fisher’s key point was that MLE stands instead on maximizing the likelihood function while treating
θ as a deterministic parameter. For an excellent historical account of related developments and perspectives,
read (Aldrich, 1997).
For all practical purposes, we shall ignore the proportionality constant in (15.1) and write
l(θ|yN ) = f (yN |θ)
(15.3)
Procedure for MLE
The objective in MLE is to maximize the likelihood function. However, the mathematics of the
problem is much simpliﬁed if the logarithm of the likelihood is maximized instead. To bring matters
in line with the MoM, LS and other conventional techniques, the optimization problem is framed as
a minimization problem:
ˆθM L = arg min
θ
- ln l(θ|yN )
or
ˆθM L = arg min
θ
-L(θ|ZN )
(15.4)
where ZN = {yN,uN } (or a general information set) and we have used the notation introduced in
Chapter 13, L(.) ≜ln l(.).
Using the terminology introduced in Chapter 13, the ML estimate is the roots of the score function
S(θ)
ˆθM L = arg [S(θ) = 0]
(15.5)

402
Principles of System Identiﬁcation: Theory and Practice
Evidently, we have a non-linear optimization problem in hand, calling for the use of numerical
algorithms described in Section 14.4.1. There exist two additional algorithms speciﬁcally meant for
computing the ML estimates. Section 15.1.3 brieﬂy describes these algorithms.
Note: In the formulation of the MLE above, we have assumed the random variables to be continuous. A similar
formulation exists for discrete-valued random variables as well.
A three-step procedure for the formulation and solution to a general ML estimation from N ob-
servations of a process y[k] is given below. It is useful to imagine the observations to be made up
of a stochastic term v[k] and/or a deterministic component x[k].
1. Assume a density function: Assume a suitable density function f (v) for the stochastic component
(typically a Gaussian).
2. Construct the likelihood function: Postulate a model (mostly dynamic) for the deterministic com-
ponent (wherever applicable). In certain texts, this is also said to be the conditional mean since
E(y[k]|x[k]) = x[k] whenever v[k] is zero-mean. Putting together the models for x[k] and v[k],
construct the density function of y and hence the likelihood for θ.
3. Solve the optimization problem: Set up the optimization problem with any additional constraints
that may have to be placed. Solve it using a suitable algorithm (typically a numerical solver).
Note that in order to carry out the last step, the density function should satisfy the regularity
conditions prescribed in Section 13.2. In the event this is not satisﬁed, the derivative of the
likelihood does not exist and the optimum has to be determined by inspection. An example of
this case is the estimation of parameters of a uniform density function.
Further, since MLE is a non-linear optimization problem, multiple solutions may exist. It is then
necessary to verify that the solution indeed corresponds to the minimum by evaluating the second
derivative.
Lastly, as with any estimation technique, compute the errors in the resulting estimates.
Remarks:
The MLE formulation is also contained in the larger family of prediction-error methods as pre-
sented later in Chapter 21. In that case we postulate a predictor by assuming a suitable model for the determin-
istic component as well as the predictable stochastic portion (e.g., an ARMA model). The likelihood function
is then constructed from the density function of the prediction errors.
Form of density function
In order to solve an MLE problem, it is necessary to specify the density function for the observations
(or for the prediction errors as the case may be). Three options are available: (i) density function is
known a priori or derived from a physical understanding of the process (see Ogunnaike (2010) for a
good treatment of this topic) (ii) empirical density determined from the data and (iii) user’s choice.
The ﬁrst two options are witnessed in a limited number of applications due to lack of suﬃcient
process insights or lack of methods to correctly estimate the density. In most situations, the user
exercises a mix of all options, i.e., the choice is driven by process insights, knowledge gathered
from the data and mathematical convenience.
A vast body of MLE literature is built on the Gaussian density assumption mostly due to the con-
venience and ubiquity of a Gaussian density in data analysis (recall the discussion in Section 7.3.1).
There are, of course, a signiﬁcant number of formulations and solutions based on non-Gaussian
densities as well (see Garthwaite, Jolliﬀe and Jones (2002) for instance), which are again driven by
the fact that the processes under study demand the use of a non-Gaussian density.
We shall, for the most part in this text, deal with MLE formulations based on the Gaussian distri-
bution.
The MLE methodology is illustrated on two classical representative problems pertaining to statis-
tical inferencing and identiﬁcation, respectively.

Estimation Methods: Part II
403
15.1.1
ESTIMATION OF MEAN AND VARIANCE: GWN
Problem statement
Consider the illustrative problem of Chapter 12. Given N observations of a constant signal corrupted
with noise,
y[k] = c + e[k]
(15.6)
estimate the steady-state value c and the variance of the measurement noise σ2
e. In Chapter 12 we
attacked this problem using the LS technique. Here we shall deploy the MLE method.
Constructing the likelihood function
Following the procedure outlined earlier, ﬁrst assume a density for the WN source in y[k]. Keeping
matters consistent with the illustration in Chapter 12, let e[k] ∼GWN(0,σ2
e). Thus, we have two
unknowns to estimate:
θ =
f
c
σ2
e
gT
(15.7)
The second step involves construction of the likelihood function
l(θ|yN ) = f (yN |θ)
(15.8)
Given that e[k] is Gaussian, y[k] also follows a Gaussian distribution with
E(y[k]|θ) = c; σ2
y = σ2
e
=⇒f (y[k]) =
1
q
2πσ2e
exp
 
−1
2
(y[k] −c)2
σ2e
!
(15.9)
Further, since e[k] is WN and Gaussian, the joint p.d.f. of yN is the product of the marginal p.d.f.s
(recall that uncorrelated Gaussian RVs are also independent). Thus,
f (y[0], y[1],· · · , y[N −1]|θ) =
N−1
Y
k=0
f (y[k]|θ)
=⇒l(θ|yN ) =
1
(2πσ2e)N/2 exp *
,
−1
2
N−1
X
k=0
(y[k] −c)2
σ2e
+
-
(15.10)
The objective function to be minimized is then
L(θ,yN) = - ln l(.) = - N
2 ln(2π) −N
2 ln σ2
e −1
2
N−1
X
k=0
(y[k] −c)2
σ2e
|                 {z                 }
LS obj. fun.
(15.11)
The last term of the objective function can be easily recognized as the sum square (prediction)
errors in the LS formulation. On the other hand, unlike the LS problem, MLE gives rise to a set of
non-linear normal equations. Fortunately, in this case, a closed-form solution exists as shown below.
Setting the gradients of the objective w.r.t. c and σ2
e to zero, we obtain:
∂L
∂c = 0 =⇒−
N−1
X
k=0
(y[k] −c)
σ2e
= 0
(15.12)
∂L
∂σ2e
= 0 =⇒−N
2σ2e
+
N−1
X
k=0
(y[k] −c)
σ4e
= 0
(15.13)

404
Principles of System Identiﬁcation: Theory and Practice
Listing 15.1
MATLAB code for ML estimation of mean and variance
% Requires Statistics toolbox
% Generate time-series
yk = randn(200,1);
% Estimate mean and variance using ML
[p_hat,p_ci] = mle(yk,’distribution’,’normal’); % Or mle(’data ’)
% Compute standard errors
cov_phat = mlecov(p_hat,yk,’pdf’,@normpdf);
err_phat = sqrt(diag(cov_phat));
Solving both equations simultaneously, we obtain the ML estimates of c and σ2
e,
ˆcML = 1
N
N−1
X
k=0
y[k] = ¯y; ˆσ2
e,ML = 1
N
N−1
X
k=0
(y[k] −¯y)2
(15.14)
Numerical example
A time-series consisting of N = 200 observations generated by a GWN process of mean µ = 1 and
variance σ = 2 is obtained. The ML estimates of these parameters are
Estimates:
ˆµML = 1.0467(±0.1287);
ˆσML = 1.8203(±0.0910)
95% C.I.s:
µ ∈(0.7923,1.3012);
σ ∈(1.6619,2.0237)
where the values in parentheses are standard errors in the respective estimates.
Remarks:
i. The ML and LS estimates of c coincide. In general, the ML and LS estimates of linear models coincide
when the observation errors are Gaussian white noise.
ii. Estimate of variance diﬀers slightly from the unbiased estimator given by LS in (12.7). The factor of 1/N in
place of 1/(N −1) in (15.14) makes it statistically biased, but asymptotically unbiased. On the same note,
the ML estimate of variance is relatively more eﬃcient than the LS estimate.
iii. The estimates of c and σ2e are mean-square consistent. This fact follows from
var( ˆcML) = var( ¯y) = σ2e
N ;
var( ˆσ2
e,ML) = 2(N −1)
N2
σ4
e
(15.15)
iv. ML estimator, although being biased, achieves the Cramer-Rao bound asymptotically. To realize this for
the problem studied above, observe from (15.15)
var( ˆσ2
e,ML) ≈2
N σ4
e
(for large N)
(15.16)
which coincides with the Cramer-Rao bound (I(σ2))−1 for a Gaussian white-noise (recall Example 13.2).
v. Suppose we wish to obtain the ML estimate of standard deviation σe. Then, we solve for c and σe simul-
taneously. Since the MLE of c is independent of σe, it suﬃces to only estimate σe. For this purpose,
∂L
∂σe
= 0 =⇒−N
σe
+
N−1
X
k=0
(y[k] −¯y)2
σ3e
= 0
yielding
ˆσe,ML =
v
u
t
1
N
N−1
X
k=0
(y[k] −¯y)2
(15.17)

Estimation Methods: Part II
405
giving us an interesting observation
MLE(σe) =
q
ˆσ2
e,ML
(15.18)
which is not necessarily a property of any general estimator.
vi. The asymptotic distribution of the ML estimates are
√
N( ˆc −c0) ∼AsN (0,σ2
e);
√
N( ˆσ2
e −σ2
e) ∼AsN (0,2σ4)
(15.19)
It should be noted that the ﬁnite sample distribution of ˆσ2e is a χ2 with N degrees of freedom.
vii. The ML estimator for the white-noise case can be shown to be contained in the family of GMM estimators
(Greene, 2012).
viii. One of the advantages of ML formulation is that heteroskedastic errors, i.e., var(e[k]) = σ2
k can be naturally
accommodated. For the example of interest, the log-likelihood modiﬁes to
L(θ|y) = const. −1
2
N−1
X
k=0
σ2
k −1
2
N−1
X
k=0
(y[k] −c)2
σ2
k
|                  {z                  }
WLS obj. fun.
(15.20)
Thus, the ML formulation also encompasses the weighted least squares problem. Assuming the knowledge
of σ2
k, we obtain the WLS estimate of θ = c,
ˆcMLE = ˆcWLS =
N−1
X
k=0
y[k]
σ2
k
N−1
X
k=0
1
σ2
k
(15.21)
To summarize, the ML estimator of mean and variance has some very nice and attractive proper-
ties, notable among those being asymptotic eﬃciency, consistency and invariance to transforms of
parameters. What makes MLE popular and a powerful estimator is that almost all the above proper-
ties carry forward to the estimation of any other parameter as well, provided some mild conditions
are satisﬁed.
The reader is cautioned, however, that most of the optimal properties of MLE are under the large
sample assumption. The small sample properties of MLE are quite diﬀerent, bias being one such
glaring example. There are certain pathological situations for which MLE does not exist or if it ex-
ists, it is not unique. These discouraging situations are fortunately relatively less often encountered
than those where the use of MLE is theoretically sound and optimal.
In the next section, an application of MLE in estimating the parameters of a popular model struc-
ture in identiﬁcation, known as the auto-regressive exogenous model, is illustrated. It is an equation-
error model with white equation errors. The development is along the lines of the MLE of an AR(1)
model in Shumway and Stoﬀer (2006).
15.1.2
ESTIMATION OF AN ARX MODEL
Problem statement
Given N input-output samples ZN = {yN,uN } of a process, it is desired to ﬁt a ﬁrst-order ARX
model described in (14.7),
y[k] + a1y[k −1] = b1u[k −1] + e[k]

406
Principles of System Identiﬁcation: Theory and Practice
Constructing the likelihood
The MLE problem is set up by ﬁrst assuming a density function for the WN process. Assume, as
usual, e[k] ∼N (0,σ2
e). Thus, the parameters to be estimated are
θ =
f
a1
b1
σ2
e
gT
The case of non-zero mean GWN can be easily incorporated.
Next, we construct the likelihood function for the observations yN.
l(θ|ZN ) = f (ZN |θ) = f (yN |θ,uN ) f (uN |θ) = f (yN |θ,uN )
(15.22)
where we have used the familiar Bayes’ rule for two random variables X1 and X2
f (X1, X2) = f (X1) f (X2|X1)
(15.23)
and the fact that u is a deterministic or a known sequence.
The likelihood can be derived by writing the joint p.d.f. of N Gaussian variables as an extension
of (7.19)to the multivariate case, which would involve the covariance matrix of yN (and its determi-
nant). However, the mathematics of maximizing the resulting expression is quite complicated. An
alternative method is based on the trick of factorizing the joint p.d.f. by recursively applying (15.23)
to (15.22). In the ﬁrst stage of factorization,
f (yN |θ,uN ) = f (yN−1|θ,uN ) f (y[N −1]|θ,yN−1,uN )
(15.24)
where yN−1 = {y[0], y[1],· · · , y[N −2]}.
The key idea is then to recognize that, under the ﬁrst-order ARX model (14.7), the present sample
is only dependent on the immediately preceding observation and input
f (y[N −1]|θ,yN−1,uN ) = f (y[N −1]|θ, y[N −2],u[N −2])
(15.25)
Substituting the above relation into (15.24), assuming the input u[k] = 0, k < 0 and expanding the
resulting expression recursively results in the likelihood
l(θ|ZN ) = f (y[0]|θ)
N−1
Y
k=1
f (y[k]|{θ, y[k −1],u[k −1]})
(15.26)
To complete the expression, once again the regression model (14.7) is invoked while observing that
both y[0] and the conditioned y[k]|{y[k −1],u[k −1]} follow a Gaussian distribution. Evaluating
the statistics of the ﬁrst observation, under the assumption that u[0] = 0, we obtain
µy[0] = 0;
σ2
y[0] =
σ2
e
1 −a2
1
=⇒f (y[0]|θ) =
1
q
2πσ2e
exp *
,
−1
2
y2[0](1 −a2
1)
σ2e
+
-
(15.27)
and of the conditioned observations,
E(y[k]|{y[k −1],u[k −1]}) = −a1y[k −1] + b1u[k −1] = ˆy[k|k −1]
var(y[k]|{y[k −1],u[k −1]}) = σ2
e
=⇒f (y[k]|{θ, y[k −1],u[k −1]}) =
1
q
2πσ2e
exp
 
−1
2
(y[k] −ˆy[k|k −1])2
σ2e
!
(15.28)

Estimation Methods: Part II
407
Putting together the foregoing expressions and (15.26), we ﬁnally have the log-likelihood function
L(θ|ZN ) = const. −N
2 ln σ2
e −1
2
y2[0](1 −a2
1)
σ2e
−1
2
N−1
X
k=1
(y[k] −ˆy[k])2
σ2e
(15.29a)
= const. −N
2 ln σ2
e −1
2
y2[0](1 −a2
1)
σ2e
−
1
2σ2e
N−1
X
k=1
ϵ2[k]
|     {z     }
LS obj. fun.
(15.29b)
Once again, not surprisingly, the LS objective function is embedded in the MLE formulation. The
main diﬀerence is that in MLE we take into account the randomness of the ﬁrst observation, while
in the least squares method we assume it to be ﬁxed or given. cric
ML estimates
Introduce as in Shumway and Stoﬀer (2006),
Sc(a1,b1) =
N−1
X
k=1
(y[k] −ˆy[k])2
(conditional sum squares, CSS)
(15.30)
Su(a1,b1) = y2[0](1 −a2
1) +
N−1
X
k=1
(y[k] −ˆy[k])2
(unconditional sum squares, USS)
(15.31)
so that (15.29) can be written as
L(a1,b1,σ2
e) = const. −N
2 ln σ2
e −Su(a1,b1,σ2
e)
(15.32)
where the names are self-explanatory. The conditional sum is minimized by the OLS estimator,
whereas the unconditional sum is minimized by the WLS estimator. In the latter case, the sum is
justiﬁed by virtue of the fact that y[0] has a variance of (1 −a2
1)/σ2
e, while the prediction errors
from ε[k], k = 1,· · · , N −1 have a theoretical variance of σ2
e.
The log-likelihood is obviously non-linear in the unknowns. No closed-form expression is avail-
able for the optimal estimates of a1 and b1. A comforting fact is that the optimal estimate of inno-
vations variance can be computed explicitly from (15.32) as follows:
∂L(a1,b1,σ2
e)
∂σ2e
= 0 =⇒
ˆσ2
e,ML = Su( ˆa1,ML, ˆb1,ML)
N
(15.33)
where ˆa1, M L, ˆb1,M L have their obvious meanings.
The model parameter estimates are themselves obtained using the numerical algorithms of Sec-
tion 14.4.1. It is interesting to note that the CSS, USS and MLE are progressively in the order of
sophistication (of estimation) as well as computational burden.
Remarks:
Frequently one works with the conditional likelihood, i.e., ignoring the randomness in the ﬁrst
observation (or p observations as the case may be). The advantage is that it is computationally lighter. In fact,
it yields the same solution as the CSS above, with the only diﬀerence being in the estimate of σ2e.
ˆσ2
e,CML = Sc ( ˆa1,CSS, ˆb1,CSS)
N −1
(15.34)

408
Principles of System Identiﬁcation: Theory and Practice
Example 15.1: MLE of ARX Model Parameters
For the input-output data in Example 14.1, let us estimate the parameters using MLE.
Setting up the negative log-likelihood in (15.29b) and minimization of the same with an
initial guess ˆa(0)
1
= −0.4, ˆb(0)
1
= 1,( ˆσ2e)(0) = 0.4 produces the ML estimates:
ˆa1
ˆb1
ˆσ2e
−0.703
1.995
0.703
Compare this with the LS estimates ˆa1 = −0.703, ˆb1 = 1.995, ˆσ2e = 0.7032. The parameter
estimates are almost identical. This is expected since the predictor is linear in parameters and
the noise is Gaussian. Having said thus, we may also remind ourselves that the ML estimates
are local optima whereas the linear LS estimates are unique.
In Section 15.1.4, we shall learn how to compute errors in these estimates.
The data generated for this example comes from the process
y[k] −0.7y[k −1] = 2u[k −1] + e[k]
e[k] ∼N (0,6796)
excited by a PRBS input.
Remarks:
i. The variance of the innovations estimated by ML approach is theoretically lower than that by the OLS,
but it is a biased estimate. However, as in Section 15.1.1, the estimate is asymptotically unbiased. The
reason for higher variability of the OLS estimate is that the variance is estimated after estimating p model
parameters. Thus eﬀectively only N −p degrees of freedom are available. On the other hand, the ML
approach estimates the model parameters and innovations variance jointly, which eventually leads to lower
variance. An intuitive explanation of the ML estimators in this respect is given in Section 15.1.4.
ii. The ML estimates of the model parameters and the innovations variance are consistent and asymptotically
eﬃcient under some fairly mild conditions (see Section 15.1.4).
iii. It is useful to re-write the likelihood in (15.26) in terms of the one-step ahead prediction errors ε[k|k −1]
as,
l(θ|ZN ) = f (y[0]|θ)
N−1
Y
k=1
f (ε(k|k −1,θ))
(15.35)
which is used later for setting up the likelihood for ARMA(X) models. See §19.4.
Listing 15.2
MATLAB code for Example 15.1
% Generate data
proc_mod = idpoly([1 -0.7],[0 2],1,1,1,’Noisevariance’,1);
uk = idinput(2046,’prbs’,[0 0.4],[-1 1]);
% Measurement with SNR approx 10
ykstar = sim(proc_mod ,uk);
proc_mod.Noisevariance = (1 - 0.49)*var(ykstar)/10;
yk = sim(proc_mod ,uk,’Noise’);
Z = [yk uk];
% Assuming delay and order, obtain MLE
th_mle = fminsearch(@(pars) neglogl_arx(Z,pars),[-0.4 1 0.4]’);
% LS estimates
Phi = [-yk(1:end-1) uk(1:end-1)]; yvec = yk(2:end);
th_ls = pinv(Phi)*yvec;

Estimation Methods: Part II
409
Listing 15.3
MATLAB function for Example 15.1
function arx_nll = neglogl_arx(Z,params)
% RETURNS LOG-LIKELIHOOD FOR MLE OF ARX
% TO BE USED IN CONJUNCTION WITH arxest_mle.m
% Parse the parameters
yvec = Z(:,1); uvec = Z(:,2); N = length(yvec);
a1 = params(1); b1 = params(2); sigma_e = params(3);
% Predictions and prediction errors
Phi = [-yvec(1:end-1) uvec(1:end-1)];
yhat = Phi*[a1 ; b1];
err_vec = yvec(2:end) - yhat;
% Compute negative log-likelihood and return it
term1 = -(N/2)*log(sigma_e^2);
term2 = -(1/2)*yvec(1)^2*(1 - a1^2)/sigma_e^2;
term3 = -(1/2)*sum(err_vec.^2)/sigma_e^2;
arx_nll =
-(term1 + term2 + term3);
Application of MLE to estimating time-series models and in general, dynamic models are for-
mulated in terms of one-step ahead prediction errors (innovations). Chapters 19 and 21 present the
associated details.
15.1.3
COMPUTING THE MLE
The non-linear optimization problem resulting from the ML formulation can be solved using
Newton-Raphson and Gauss-Newton methods. In addition, three other algorithms are widely used,
as brieﬂy discussed below.
i. Fisher’s scoring method: Originally proposed by Fisher (1922), it is a variant of the Newton-
Raphson method, which updates the parameter as
θ(i+1) = θ(i) +
f
H(θ(i))
g−1 S(θ(i))
(N-R update)
(15.36)
Fisher’s scoring algorithm replaces the computationally intensive Hessian calculations of the
N-R method by their expected values.
Hi j (θ) = −∂2L(θ)
∂θi∂θ j
−→Hi j (θ) = −E
 ∂2L(θ)
∂θi∂θ j
!
(Fisher’s scoring)
(15.37)
The Hessian in (15.36) and the expected Hessian in (15.37) are the observed and the expected
information matrices, respectively.
In (15.36), S(θ(i)) denotes the score vector evaluated at the ith iteration. An advantage of using
(15.37) is that only ﬁrst-order derivatives are suﬃcient to compute the expected Hessian.
E
 ∂2L(θ)
∂θi∂θ j
!
= −E
 ∂L
∂θi
∂L
∂θ j
!
(15.38)
Also, the expected Hessian is guaranteed to be positive deﬁnite, avoiding the typical non-
convergence issues associated with a N-R method. Further, the scoring algorithm is less sensitive
to the choice of an initial estimate. It is often recommended to implement a mix of methods, i.e.,
initially run the scoring algorithm until a few iterations followed by the N-R method as the so-
lutions gets closer to convergence. See Osborne (1992) for an enlightening discussion on related
aspects.

410
Principles of System Identiﬁcation: Theory and Practice
ii. Polytope method: Unlike the gradient search approach of the N-R or the Fisher’s scoring meth-
ods, the idea here is to use a heuristic direct-search method for parameter updates (Nelder and
Mead, 1965). This is also know as the simplex method (not to be confused with the one in linear
programming).
At each stage of the algorithm, a polytope or a simplex of p + 1 (p = dim(θ)) set of parameter
vectors (points in parameter space) is formed using pre-speciﬁed step sizes. The objective func-
tion is evaluated at each of these points and the point that has the worst-valued objective function
is replaced by another point with a lower value of the objective function. Update rules are then
applied to the parameter vector depending on the value of the objective function at the newly
formed point (Garthwaite, Jolliﬀe and Jones, 2002). This technique is recommended in situa-
tions where evaluating the derivatives is prohibitively diﬃcult (e.g., large scale problems). The
method suﬀers from lack of convergence proofs that are available for gradient-search methods.
iii. EM algorithm: The Expectation-Maximization algorithm due to Dempster, Laird and Rubin
(1977) is a powerful technique that is widely used for obtaining ML estimates, particularly with
incomplete or missing data sets. Strictly speaking, it is not a numerical algorithm but a method-
ology for setting up the complete data likelihood from incomplete data. Although devised for the
missing data case, it is also used to handle intractable ML problems which do not truly miss any
data, but those that become tractable by imagining the observed data to be generated by some
unobserved variables.
The EM algorithm uses an iterative approach consisting of two steps known as the expectation
E and maximization M steps. When the complete data is available, the parameter vector θ, can
be estimated by minimizing the complete log-likelihood. The missing data is the main obstacle
in the construction of complete log-likelihood. The EM algorithm circumvents the missing data
estimation sub-problem in an elegant manner. It computes the average log-likelihood of the com-
plete data over the space of missing values using an estimate of θ(i) and the given observed data.
The average likelihood is used in revising the estimate to θ(i+1) and this iteration is continued
until convergence.
Q(θ,θ(i)) =
Z
ln f (x,θ) f (x|y,θ(i)) dx
(Expectation step)
(15.39)
θ(i+1) = arg max
θ Q(θ,θ(k))
(Maximization step)
(15.40)
Section 22.4.2 presents the technical details of this algorithm.
A known problem with the EM algorithm is that it does not necessarily converge to the ML
estimate; see Little and Rubin (2002). However, its advantages usually outweigh the drawbacks,
evident from its widespread use. For further discussion, refer to §22.4.2.
15.1.4
PROPERTIES OF THE ML ESTIMATOR
Suppose that the observation vector constitutes a random sample (GWN or i.i.d.) y and that the true
joint p.d.f. f (y; θ0) satisﬁes the regularity conditions. Then the ML estimator has certain attractive
asymptotic properties (see Cox and Hinkley (1974) and Rao (1973) for proofs.)
i. Consistency: The ML estimate converges in probability to the true parameter,
ˆθML
p
−→θ0
(15.41)
ii. Asymptotic normality:
( ˆθML −θ0)
d
−→N (0,I0(θ)−1)
(15.42)
where I0(θ) is the Fisher’s information matrix (13.14) or the inverse of the Cramer-Rao’s lower
bound (13.36) evaluated at the true point θ = θ0.

Estimation Methods: Part II
411
iii. Asymptotic eﬃciency: A corollary of the above property is that the covariance of the ML estima-
tor asymptotically converges to the Cramer-Rao’s lower bound.
lim
N→∞Σ ˆθ = I0(θ)−1
(15.43)
iv. Asymptotically unbiased: ML estimators can in general produce biased estimates (with the ex-
ception of a few cases). A general reason given for this behavior is that the ML estimator overﬁts
the given series. However, the bias can in general be evaluated and a correction factor can be
applied (see Firth (1993) and Mardia, Southworth and Taylor (1999)). When the sample size
becomes large, this is no longer an issue since these estimators are asymptotically unbiased.
v. Invariance: Suppose φ = g(θ) for some appropriate one-to-one function g(.), then a remarkable
property of the ML estimator is that
ˆφML = g( ˆθML)
(15.44)
vi. Suﬃciency: If ˆθM L exists, then it is a suﬃcient estimator of θ.
Although the properties above are listed under restrictive conditions, they hold in general for dy-
namic systems as well (Ljung, 1999).
Several extensions and modiﬁcations of MLE method are found in literature. See Garthwaite,
Jolliﬀe and Jones (2002) for a related presentation of these algorithms. We are particularly interested
in its extensions to dynamic systems described by probabilistic models. This aspect is discussed in
the broader framework of prediction-error methods in Chapter 21.
The ﬁnal topic of interest in this chapter is that of Bayesian estimation methods. The presentation
is kept at an introductory level since it is usually considered as an advanced topic in identiﬁcation.
However, as the reader will note, it is a fairly general method, encompassing the ML estimator as a
special case.
15.2
BAYESIAN ESTIMATORS
The Bayesian estimators, named in honor of Rev. Bayes Bayes (1763) exploit the “full” potential of
conditional probability unlike the MLE approach. A fundamental diﬀerence between the Bayesian
approach and the ones discussed until now is that it assumes the parameters of interest θ to be
random with some a priori knowledge of f (θ). Since deterministic variables are limiting cases of
random variables, the ML approach is naturally contained in these methods. Strictly speaking, it is
not the parameter that is random. It is the uncertainty in our knowledge of the parameter that gives
the random characteristic to it.
The starting point for this class of methods is the conditional p.d.f. written using Bayes’ rule:
f (θ|yN ) f (yN ) = f (yN |θ) f (θ)
=⇒f (θ|yN ) = f (yN |θ) f (θ)
f (yN )
(15.45)
The quantity f (θ|yN ) is also known as the posterior distribution of θ since it is being computed
after the observations have been obtained. Its companion is f (θ) which we refer to as the prior
distribution or density. This constitutes the user’s knowledge of the parameter vector prior to using
the data. The role of observed data y is to reduce the uncertainty in the prior information or improve
our knowledge of the parameter θ.
For a given observation set yN (evidence), the denominator is a ﬁxed quantity, allowing us to write
f (θ|yN )
(Posterior)
= C f (yN |θ)
(Likelihood)
f (θ)
(Prior)
(15.46)

412
Principles of System Identiﬁcation: Theory and Practice
The constant C is usually adjusted such that f (θ|y) is a legitimate p.d.f.
Once f (θ|y) is obtained, the “full” information of θ is available, which can be used in whichever
way required. Thus, we do not have a single estimate unlike with LS or MLE, but a range of esti-
mates described by the posterior.
Interestingly, it is possible to obtain point estimates by evaluating diﬀerent properties of the p.d.f.
f (θ|y). These point estimates are optimal in the sense that they minimize a risk function R(ϵθ) =
E(C(ϵθ)), which is the averaged user-deﬁned cost function.
ˆθ = arg min
θ R(ϵ) = arg min
θ E(C(ϵθ))
(15.47)
Three popular choices of cost functions associated with three related properties of the p.d.f. are
discussed below:
1. Bayesian estimate, E(θ|y): This is the estimate that minimizes the cost function
C(ϵθ) = ||θ −θ0||2
2
(15.48)
In other words, it is the MMSE of θ and also the mean of f (θ|y).
ˆθBA = E(θ|y) = arg min
θ
E(tr(θ −θ0)(θ −θ0)T )
(15.49)
The support comes from the classical result in prediction theory discussed in Chapter 7. Given
a random variable Y, the best prediction of an unknown X is its conditional expectation in the
minimum mean square-error sense.
The estimate is computed using the deﬁnition of conditional expectation (7.24) and the posterior
density function (15.46),
E(θ|y) =
Z
θ f (θ|y) dθ
(15.50)
2. MAP estimate: The associated cost function is
C(ϵθ) =

0,
|ϵθ| < δ
1,
|ϵθ| > δ
(15.51)
which can be shown to specialize to the maximum a posteriori estimate (Kay, 1993). The MAP
is essentially the mode of f (θ|y):
ˆθMAP = arg max
θ
f (θ|y) = arg max
θ
f (y|θ) f (θ)
(15.52a)
or ˆθMAP = arg max
θ
(ln f (y|θ) + ln f (θ))
(15.52b)
The estimate is also known a the hit-or-miss estimate.
It is easy to discern that when all values of θ are equally likely a priori, i.e., when f (θ) = α,α ∈
R+, the Bayesian estimate specializes to MLE. This estimator is also known as the Bayesian
ML estimator to distinguish the philosophies involved in deriving the classical MLE and this
one. The Bayesian (classical) MLE is, in general, sub-optimal to the MAP, because it has a non-
informative prior, but is computationally less demanding.
The general MAP is sometimes also termed as a penalized ML estimator because the objec-
tive function in (15.52b) contains an additional term, which can be interpreted as a regularizing
term. For instance, choosing the prior as Gaussian with mean θ = 0 and variance
1
2Nα Ip leads
to an MLE objective with classical regularization (see Exercise E15.6). An application of this
equivalence for regularized estimation of FIR models is discussed in §20.2.3.

Estimation Methods: Part II
413
3. Median estimate: As the name suggests, it is the median of the posterior.
ˆθMedian = Median( f (θ|y))
(15.53)
The associated cost function is the absolute value of the error.
C(ϵθ) = |ϵθ|
(15.54)
For a Gaussian posterior, the mean, median and mode coincide. Among the three estimators, the
MMSE is the most preferred because of its quadratic objective function; however, it is one of the
most diﬃcult to compute.
In the next section, we illustrate the application of Bayesian estimation on two example processes
that appeared in the context of previously discussed estimators.
Example 15.2: Estimation of Constant with Prior Knowledge
We revisit the case of estimating a constant in noise from its measurement (estimation of
mean and variance) that was discussed in Sections 12.2 and 15.1.1. Unlike in those cases,
here we assume some prior knowledge of θ ≡c, the uncertainty in which is described by a
Gaussian p.d.f.:
f (θ) =
1
q
2πσ2c
exp
 
−(θ −µc)2
2σ2c
!
(15.55)
As in 15.1.1, we shall assume e[k] ∼N (0,σ2e).
Then the posterior is
f (θ|y) = C
1
(2πσ2c)1/2(2πσ2e)N/2 exp
*........
,
−(θ −µc)2
2σ2c
−
N−1
X
k=0
(y[k] −θ)2
2σ2e
+////////
-
(15.56)
where the constant C is adjusted such that
R
f (θ|y) dθ = 1.
Determination of C and re-arrangement of terms leads to a Gaussian-like form for f (θ|y)
as follows.
The exponent of the posterior p.d.f. can be re-written as:
−(θ −µc)2
2σ2c
−
N−1
X
k=0
(y[k] −θ)2
2σ2c
= −θ2
2
 1
σ2c
+ N
σ2e
!
+ 2θ
 µc
σ2c
+ N ¯y
2σ2e
!
−*
,
µ2c
2σ2c
+
PN−1
k=0 y2[k]
2σ2e
+
-
We shall work our way backwards. Assume that it is true that the posterior p.d.f. is Gaussian
and show that a solution exists.
f (θ|y) ∝N ( ¯µ, ¯σ2) =
1
√
2π ¯σ2 exp
 
−1
2
(θ −¯µ)2
¯σ2
!
(15.57)
where ¯µ ≜µθ |y, ¯σ2 ≜σ2
θ |y.
Then, comparing coeﬃcients of powers of θ in the exponents, we have
1
¯σ2 = 1
σ2c
+ N
σ2e
;
¯µ
¯σ2 = µc
σ2c
+ N ¯y
σ2e

414
Principles of System Identiﬁcation: Theory and Practice
Thus, we have
¯σ2 =
1
1
σ2c
+ N
σ2e
;
¯µ =
 µc
σ2c
+ N ¯y
σ2e
!
¯σ2
(15.58)
The quantity ¯µ is the Bayesian estimate of c, deﬁned in (15.50) and the ¯σ is the standard
error in this estimate.
It is left as an exercise to the reader to verify that the constant terms in both exponents
are identical under (15.58).
−10
−5
0
5
10
0
0.005
0.01
0.015
0.02
0.025
0.03
θ
f(θ|y)
Prior and posterior p.d.f.s
 
 
Prior
After N = 1
N = 10
N = 100
FIGURE 15.1
(SEE COLOR INSERT) Prior and posterior p.d.f.s of mean in Example 15.2.
To illustrate the results numerically, suppose that N = 100 samples of observations are
available. Assume for the prior, µc = 0,σ2c = 4 and that the variance of the GWN is known to
be σ2e = 2. The prior and the posterior p.d.f.s resulting from taking into account N = 1,10,100
observations are shown in Figure 15.1.
The plots show how the data improves the largely uncertain prior knowledge to a much
more precise estimate. The computed variance of the resulting estimate is 0.02, which is
identical to the theoretical value in (15.58).
Remarks:
i. The Bayes estimate of c is E(c|y) = ¯µ. Expressing this estimate in a weighted form provides valuable
insights into the workings of the Bayesian method.
¯µ = αµc + (1 −α) ¯y
where
α = ¯σ2
σ2c
=
σ2e
σ2e + Nσ2c
(15.59)
Thus, the approach gives us a weighted estimate of the prior mean (i.e., no data) and sample mean (i.e., no
prior).
ii. The Bayesian estimate is statistically biased, but asymptotically unbiased.
E( ¯µ) , µ;
lim
N→∞E( ¯µ) = lim
N→∞
µc
σ2c
¯σ2 + lim
N→∞
N ¯σ2
σ2e
E( ¯y) = µ
(15.60)
iii. The variance of the Bayesian estimate is a harmonic average of the variances in the estimates from two
sources, σ2c and σ2e/N, from prior and data, respectively. Introducing
β =
σ2c
(σ2e/N)
=
Uncertainty in ˆθ a priori
Uncertainty in ˆθ from data
(15.61)

Estimation Methods: Part II
415
we have
¯σ2
σ2c
=
1
β + 1 = α
(15.62)
The core philosophy of Bayesian estimation is that the data improves the prior estimate or knowledge of θ.
This fact is established clearly in (15.62). Since β ≥0 for ﬁnite N, ¯σ2 ≤σ2c.
iv. The Bayesian estimate has a lower variance than that with a non-informative prior such as MLE or LSE:
¯σ2 < σ2e
N
(15.63)
Moreover, it is a consistent estimator
lim
N→∞¯σ2 = 0
(15.64)
v. Further, it is instructive to consider two extreme cases built on (15.59) and (15.62).
Case 1: no prior knowledge of θ, i.e., σ2c →∞or that α →0.
lim
σ2c→∞
¯µ = ¯y
lim
σ2c→∞
¯σ2 = σ2
N
(15.65)
thereby simplifying to ML and LS estimates. In this case, the information on c solely comes from data. This
is also the case when β >> 1, i.e., when the data is much more informative than the prior w.r.t. θ.
Case 2: perfect knowledge of θ, i.e., σ2c →0 or that α →1.
lim
σ2c→∞
¯µ = µc
lim
σ2c→0
¯σ2 = 0
(15.66)
Thus, the data has no role to play. As in the previous case, this result also corresponds to when β ≪1, i.e.,
when the prior p.d.f. is much more informative than the data w.r.t. θ.
Listing 15.4
MATLAB code for Example 15.2
% Generate measurement
ymeas = sqrt(2)*randn(100,1) + 3;
% Create inline functions for prior and likelihood
sigma_pr = 2; mu_pr = 0;
prior_pdf = inline(’(1/sqrt(2*pi*P2^2))*exp(-(1/2)*((theta␣-␣␣P1).^2/P2^2))’,’...
theta’,’P1’,’P2’);
sigma_wn = sqrt(2);
like_ymeas = inline(’(1/sqrt(2*pi*2))*exp(-(1/2)*(y␣-␣theta).^2/2)’,’y’,’theta...
’);
% Compute posterior with increasing no. of observations
theta_vec = (-10:0.01:10)’;
post_pdf = prior_pdf(theta_vec ,mu_pr,sigma_pr);
post_pdf = post_pdf/sum(post_pdf);
for k = 1:100,
like_y = 1;
for i = 1:k,
temp_like = like_ymeas(ymeas(i),theta_vec);
like_y = temp_like.*like_y;
end
post_pdf(:,k+1) = prior_pdf(theta_vec ,mu_pr,sigma_pr).*like_y;
post_pdf(:,k+1) = post_pdf(:,k+1)/sum(post_pdf(:,k+1));
end

416
Principles of System Identiﬁcation: Theory and Practice
Likelihood and prior distributions: conjugate pairs
Computation of the posterior can present some serious challenges depending on the choice of the
(likelihood) density f (y|θ) and the prior. It turns out that the burden is signiﬁcantly reduced if the
likelihood and prior form a combination such that the posterior also falls in the family of prior
distributions. Then, the combination (of the likelihood and prior) is said to form a conjugate prior.
In addition to the pair noted above, some well-known conjugate pairs include (Gaussian, Gamma),
(Gaussian, Wishart), (Multinomial, Dirichlet), etc. (Kay, 1993; Ogunnaike, 2010).
Having stated thus, it is important to choose the prior that is appropriate for the situation rather
than going by mathematical or computational convenience.
15.2.1
LINEAR BAYESIAN MMSE
The Bayes estimate E(θ|y) was shown to be the MMSE in Section 15.2. From a practical standpoint,
its utility is limited since it requires the knowledge of p.d.f. and the form of the estimator may
be complicated. Similar issues were encountered with the MVUE (recall Section 13.7.1), where a
practical remedy was to use the BLUE. Analogously here, we propose a linear Bayesian MMSE. As
with BLUE, it does not require the knowledge of prior and the likelihood p.d.f., but only the mean
and covariance. The only diﬀerence is that we do not impose the unbiased condition, but instead
demand minimum mean-square error.
Restricting the estimator to a linear form:
ˆθ = c + Ay
(15.67)
where µθ is the vector of prior means, we determine the constant c and matrix A by imposing the
MMSE requirement.
{c⋆,A⋆} = arg min
A
E(||θ −θ0||2
2)
(15.68)
The optimal solution turns out to be (see Exercise E15.8)
A⋆= ΣθyΣ−1
yy (y −µy);
c⋆= µθ −A⋆E(y)
(15.69a)
leading us to
ˆθLMMSE = µθ + A⋆(y −E(y))
(15.69b)
Σ ˆθ ˆθ = Σθθ −ΣθyΣ−1
yy Σyθ
(covariance of estimates)
(15.69c)
where Σθy is the p × N cross-covariance matrix, Σyy is the N × N covariance matrix and Σθθ is the
prior covariance of parameters.
Once again, drawing parallels with BLUE, the LMMSE is also the MMSE only when the data
generating process is linear in parameters and the observations are corrupted by Gaussian white
errors. A Bayesian Gauss-Markov theorem exists to this eﬀect (Kay, 1993).
Application to a linear model
Consider the application of LMMSE to the case of parameters and the observations related through
a linear model (as in FIR and ARX models),
y = Φθ + ξξξ
(15.70)
where ξξξ ∼N (0,Σξξξξξξ) and θ ∼N (µθ,Σθθ).
The following standard results in probability theory are useful before applying (15.69).

Estimation Methods: Part II
417
Under the model (15.70),
E(y) = Φµθ
(15.71a)
Σyy = E((y −E(y)(y −E(y))T ) = ΦΣθθΦT + Σξξξξξξ
(15.71b)
Σθy = E((θ −µθ)(y −E(y))T ) = ΣθθΦT
(15.71c)
Putting together (15.69) and (15.71), we have
ˆθLMMSE = µθ + (Σ−1
θθ + ΦT ΣξξξξξξΦ)−1ΦT Σ−1
ξξξξξξ(y −Φµθ)
(15.72)
It is easy to see that by setting µθ = 0 and letting Σθθ →∞(no information on θ a priori), we
recover the minimum variance weighted least squares estimator.
Discussion
It is apparent now that the Bayesian approach is one of the most natural approaches for estimation
since in many situations the user has some knowledge of θ a priori (even if it means a range of values
or some properties) and the data serves as means of reﬁning that knowledge. The more information
the data contains on θ, the better is the reﬁnement. An important point that can be garnered from the
Bayesian method is that classical methods such as MLE (and hence least squares) also implicitly
assume prior knowledge of θ, but a trivial one - that all values are equally likely. From a practical
and computational viewpoint, it is therefore clear why the classical methods are more prevalent.
On the other hand, ML can produce erroneous estimates with its trivial choice of prior. It is known
that even a “simple” prior (from a computational viewpoint) such as a Gaussian can produce better
estimates than MLE.
A distinguishing feature of Bayesian estimators is that they naturally provide interval estimates
instead of point estimates delivered by the previously discussed methods. Consequently, the step of
computing any error bounds on ˆθ or its distribution is completely obviated. This information is a
part and parcel of the Bayesian estimation.
An interesting exposition of some the foregoing points appears in the work by Meng and Xie
(2014). See Ogunnaike (2010) for some critical arguments. Notwithstanding the strengths and weak-
nesses, the Bayesian framework remains possibly the only known uniﬁed and coherent framework
for incorporating prior uncertainties in parameters.
One of the theoretical stumbling blocks that limits the utility of Bayesian theory (and hence its
popularity) is the requirement of knowing the prior p.d.f. f (θ), which may not be easily available.
Furthermore, the involvement of p.d.f.s makes it a very computationally demanding approach. Nev-
ertheless, the attractive properties of a Bayesian framework and the recent developments in this
area, particularly that of Markov chain Monte Carlo (MCMC) simulations, oﬀer remedies that can
signiﬁcantly overcome these obstacles.
15.3
SUMMARY
This chapter, companion to Chapter 14, reviewed the principles of maximum likelihood and
Bayesian estimation methods. Both these estimators are cast in a stochastic framework. They are
characterized by very attractive asymptotic properties, largely at the expense of sacriﬁcing bias.
Computationally, MLE methods can only yield to numerical algorithms since the associated op-
timization problems are non-linear, which is also the case with non-linear least squares methods.
Thus, one has to be content in practice with locally optimal estimates.
MLE and LS methods are equivalent when the observational errors are Gaussian and white, which
is fairly restrictive. Similarly, under certain conditions, MLE can be formulated as a GMM estimator.

418
Principles of System Identiﬁcation: Theory and Practice
In general, MLE has been the preferred estimator whenever large samples are available. The prob-
lem is simpliﬁed when the observations follow a Gaussian distribution. Results on non-Gaussian
distribution have also been reported in literature, but are expectantly more involved. The small sam-
ple behavior of MLE has been a subject of debate and critical study. In several situations, it becomes
very diﬃcult to evaluate the p.d.f. or it is unknown. Then non-linear least squares are powerful al-
ternatives, or sometimes even a preferred estimator.
The Bayesian approach sets up the most generic framework for parameter estimation but also re-
sults in computationally intensive problems. The latter has been a subject of intense research with
some promising techniques coming to the forefront. Bayesian methods encompass all the classical
(frequentist) estimators and constitute perhaps the only best known way of systematically incorpo-
rating prior knowledge of parameters.
The presentation in this chapter has been largely oriented for the static problem while providing
glimpses of their applications to dynamic processes through illustrative examples. Part IV is an
expansion of these ideas to modeling of dynamic systems.
REVIEW QUESTIONS
R15.1 Explain the concept of likelihood. How diﬀerent is it from conditional probability?
R15.2 Describe mathematically the equivalence between MLE and LS method for estimation of mean.
R15.3 List the steps in maximum likelihood estimation procedure.
R15.4 Explain how the MLE is contained in the Bayesian estimation method.
R15.5 What is the diﬀerence between a prior and a posterior p.d.f.?
R15.6 Describe the maximum a posteriori (MAP) estimate.
R15.7 Deﬁne Bayes estimate.
R15.8 Compare the philosophies underlying MLE and Bayesian estimation principles.
R15.9 Describe at least two speciﬁc merits and demerits of the Bayesian estimation versus the maximum
likelihood estimation techniques.
EXERCISES
E15.1 Verify the asymptotic distribution results for the ML estimate of mean through Monte Carlo
simulations.
E15.2 Given observations from a Gaussian random process with mean and variance identical, µ = σ2 = λ,
obtain the ML estimate of λ.
E15.3 With reference to Exercise E15.2, determine the variance of the ML estimate. Is this lower or
higher than the case when the constraint on the mean and variance is ignored?
E15.4 Suppose an AR(2) model (set exogenous inputs to zero) is estimated using MLE from N obser-
vations of the series y[k]. Set up the MLE for the same.
E15.5 Simulate N = 500 observations of an AR(2) process: v[k] −1.2v[k −1] + 0.32v[k −2] = e[k]. With
the formulation in Exercise E15.4, estimate the parameters of the AR(2) model using MATLAB (or
your favorite software).
E15.6 Show that the MAP estimator with a zero-mean Gaussian prior whose variance is
1
2Nα Ip (where
p = dim θ) is identical to the regularized ML estimator with the classical penalty term α||θ||2
2.
E15.7 Carry out a Bayesian estimation of the parameter of an AR(1) model: v[k] = 0.7v[k −1] + e[k]
assuming σ2e is known and a Gaussian prior for the AR coeﬃcient.
E15.8 Derive the linear MMSE estimator in (15.69).

16
Estimation of Signal Properties
This chapter serves as a useful reference for estimators of the signal’s properties, both sta-
tistical and deterministic. In the ﬁrst part of this chapter, we shall study expressions for esti-
mating time-domain properties. The second part of this chapter is devoted to the estimation
of frequency-domain characteristics, particularly, the spectral densities. The objective is not
merely to provide expressions for the estimators but also to highlight their properties so that
the user is aware of the appropriateness of a particular estimator for a given application.
16.1
INTRODUCTION
Preceding chapters have highlighted the need for estimating the signal properties and also discussed
in detail the methods to obtain the same. Estimation of the properties of signals, be it output or input,
is important at diﬀerent stages of identiﬁcation. In Chapter 2 we observed that the ﬁrst step towards
building a (linear) data-driven model is the construction of deviation quantities. A generalization of
this step is the removal of trends. In all estimation exercises, an important post-estimation step is the
computation of standard errors, which requires the know-how of computing variance of observation
noise. The Fisher’s information metric gives us the extent of information available in a data given
a theoretical model. In practice, we need an empirical version of the same. On the other side of the
story is the need to compute spectral densities for the estimation of frequency response functions
and input-output delays.
This chapter is solely devoted to address the aforementioned needs. First we present estimators of
key statistical properties, namely, mean, variance and correlation (functions). Subsequently two em-
pirical methods for computing Fisher’s information are reviewed. Estimation of frequency-domain
properties, namely the auto- and the cross-power spectral densities constitute the second-half of this
chapter. Suitable illustrations using the support software are provided to assist the reader in taking
the estimators from theory to practice.
A cautionary note is in place here. It is a good practice to distinguish theoretical deﬁnitions from
the expressions (formulae) used to obtain the corresponding estimates. For instance, quite often the
sample mean is confused with the true deﬁnition of mean of a signal. In principle they are diﬀerent
and coincide only for a class of signals or under special conditions. For any property of a signal,
there exists only one theoretical deﬁnition, but many estimators. The presentation to follow does not
recommend a particular estimator, but rather discusses the properties and highlights certain known
aspects. It is the user’s call to make the “right” choice of estimator, which is largely governed by its
properties, as discussed in Chapter 13 and any other application-speciﬁc criteria (e.g., ease of online
implementation).
16.2
ESTIMATION OF MEAN AND VARIANCE
We examine the estimators of two fundamental properties of a signal, namely, mean and variance.
The theoretical deﬁnitions for these quantities for stochastic signals were provided in (7.8) and
(7.14), respectively.
419

420
Principles of System Identiﬁcation: Theory and Practice
16.2.1
ESTIMATORS OF MEAN
Several estimators of mean exist, of which we discuss two widely used estimators. In the dis-
cussions to follow, the vector of N observations are denoted by a boldfaced vector, for e.g.,
y = {y[0], y[1], y[N −1]}.
Sample mean
The sample mean, encountered in several discussions earlier, is given by:
¯y =
N−1
X
k=0
αk y[k]
where αk = 1
N , ∀k
(16.1)
Properties of sample mean
i. The sample mean is the MoM and OLS estimator of the mean. It is also the MLE with y[k] ∼
GWN(µ,σ2) assumption.
ii. Unbiasedness: The estimator is unbiased as long as the generating process is stationary.
iii. Variance: Under the stationarity assumption for {y[k]} its variability is given by:
σ2
¯y = 1
N
N−1
X
l=−(N−1)
 
1 −|l|
N
!
σyy[l]
(16.2)
where σyy[l] is the ACVF of {y[k]}.
iv. Consistency: The estimator converges in the mean square sense (and consequently in probabil-
ity). In other words, it is consistent. The stationarity requirement on y[k] is implicitly understood.
v. Eﬃciency: The sample mean is the most eﬃcient estimator when {y[k]} is Gaussian white. For
correlated processes, a weighted least squares estimate or MLE with the appropriate correlation
function should be used.
vi. Distribution: The CLT establishes the asymptotic distribution of ¯y under fairly general condi-
tions. A more precise statement is, however, necessary when the process is correlated.
Theorem 16.1
If {y[k]} has a linear stationary representation
y[k] = µy +
∞
X
n=−∞
h[n]w[k −n]
under
w[k] ∼i.i.d.(0,σ2
w)
(16.3)
then,
¯y ∼AsN (µ, λ
N )
where
λ =
∞
X
l=−∞
 
1 −|l|
N
!
σyy[l]
(16.4)
Proof. See Shumway and Stoﬀer (2006).
□

Estimation of Signal Properties
421
The distribution result is useful in constructing conﬁdence intervals and conducting hypothe-
sis tests. Recall §13.12.2 in this context. For example, when y[k] is WN, (16.4) specializes to
¯y ∼AsN (µ,σ2/N), a known result, from where the large sample 100(1 −α)% C.I. can be
constructed:
¯y −zα/2
σ
√
N
< µ < ¯y + zα/2
σ
√
N
(16.5)
where zα/2 is the critical value satisfying Pr(Z > zα/2 = α/2) and Z ∼N (0,1). When σ is
unknown, the sample standard deviation may be used.
In the small sample case (N ≤50), the standardized sample mean t = ( ¯y −µ)/( ˆσ/
√
N) is
known to follow a Student’s t-distribution only when y[k] ∼GWN. The critical values in the C.I.
are then replaced with those from t-distribution.
vii. Robustness: The sample mean has very poor robustness characteristics. It has a breakdown point
(a common measure of robustness in robust statistics) of one, since a single abnormal observation
can cause the sample mean to shift by an arbitrary value. The higher the breakdown point, the
more robust is the estimator. For further details, refer to Huber and Ronchetti (2009).
Now we turn our attention to an alternative and a highly robust estimator.
Sample median
The sample median is the middle (or a pseudo-middle) value of the ordered observations,
ys = sort(y);
ys[0] ≥ys[2] ≥· · · ≥ys[N −1]
˘y ≜Sample Median(y) =
N−1
X
i=0
αi ys[i]
(16.6)
where αi =

1,
i = N+1
2
(odd N);
f 1
2
1
2
g
,
i = N
2 , N
2 + 1 (even N)
0,
otherwise
(16.7)
Properties of sample median
i. It is the optimal estimate of mean in the 1-norm sense,
˘y = arg

min
c
N−1
X
k=0
|y[k] −c|

Statistically it minimizes E(|Y −c|) (when this expectation exists).
ii. Unbiasedness: The sample median is an unbiased estimator of the mean whenever the density
f (y) is symmetric. It is also an unbiased estimator of the median, but without any restrictive
assumptions.
iii. Consistency: The sample median is a strongly consistent estimator of the population median
whenever {y[k]} is i.i.d.
iv. Eﬃciency: This property depends on the distribution of the data generating process. For Gaussian
distributed processes, sample median is a relatively less eﬃcient estimator of µ than the sample
mean. The asymptotic relative eﬃciency is about 2/π = 0.6366. On the other hand, for the case
of Laplace distribution, the sample median is fully eﬃcient.

422
Principles of System Identiﬁcation: Theory and Practice
v. Distribution: The sample median is asymptotically normal
˘y ∼AsN (µ,
1
4N f 2(m) )
(16.8)
where m is the true median and f (.) is the density function.
vi. Robustness: The lower eﬃciency of the sample median is balanced by its high robustness. It has
a maximum breakdown point of 0.5, making it ideally suitable for estimating mean from data
corrupted by outliers (see §22.4.2).
16.2.2
ESTIMATION OF VARIANCE
There exist several estimators of variance among which we discuss four of them.
Sample variance
Two popular versions of sample variance are
ˆσ2
N−1 =
1
N −1
N−1
X
k=0
(y[k] −¯y)2;
ˆσ2
N = 1
N
N−1
X
k=0
(y[k] −¯y)2
(16.9)
where ¯y is the sample mean deﬁned in (16.1).
Properties of sample variance
i. The estimators ˆσ2
N−1 and ˆσ2
N are the OLS and ML (as well as MoM) estimators of the true
variance σ2, respectively.
ii. Unbiasedness: The ML estimator is biased, while the OLS estimator is unbiased. On the other
hand, both are asymptotically unbiased.
iii. Consistency: The variance of each of these estimators when {y[k]} is white-noise have been given
in previous chapters:
var( ˆσ2
N−1) =
2σ4
(N −1)2 ;
var( ˆσ2
N ) = 2(N −1)σ4
N2
(16.10)
Thus, both estimators are consistent, but the ML estimate has a lower standard error and is eﬃ-
cient. Asymptotically they are equally eﬃcient. However, the MLE enjoys the functional invari-
ance property, i.e., the ML estimate of σ is merely the square root of MLE of σ2.
We shall for most occasions use the ML estimator which is also compatible with the estimator
for ACVF that is due to appear shortly in Section 16.4, where the variance expression for the
case of correlated signal is also presented.
iv. Distribution: When {y[k]} is Gaussian white, the normalized estimate has a chi-square distribu-
tion with N −1 degrees of freedom:
N ˆσ2
N
σ2
∼χ2
N−1
(16.11)
A 100(1 −α) C.I. for σ2 can thus be derived,
N ˆσ2
χ2
N−1,1−α/2
< σ2 <
N ˆσ2
χ2
N−1,α/2
(16.12)

Estimation of Signal Properties
423
Due to the nature of the χ2 distribution, the C.I. is not symmetric unlike the case for mean in
(16.5).
When the distribution of {y[k]} is non-normal, the above results approximately hold good pro-
vided the deviation from Gaussianity is not too serious.
v. Robustness: The sample standard deviation is expectantly sensitive to the presence of outliers.
Three alternative measures, known as the interquartile range, mean absolute deviation and me-
dian absolute deviation are often used where robustness is a necessity.
Other estimators
Three other estimators of spread (standard deviation) are:
1. Range: The range is merely,
R = | max y −min y|
(16.13)
For a normal distribution, R ≈6 when N is large. The interquartile range (IQR), deﬁned as the
diﬀerence between the upper and lower quartiles is a fairly robust estimator of σ. For a normal
distribution, the estimate of ˆσ = IQR/1.34898, where the correction factor is applied to obtain
an unbiased estimate of σ.
2. Mean absolute deviation (µAD): The theoretical deﬁnition is
δ1 ≜µAD = E(|Y −µ)|
(16.14)
It is considered as a more “natural” way of expressing the spread of a random variable than the
standard deviation. Closed-form expressions for δ1 do not generally exist, but expressions for the
ratio δ1/σ do exist.
A commonly used estimator is
ˆδ1,y = 1
N
N−1
X
k=0
|y[k] −¯y|
(16.15)
A correction factor is usually necessary to obtain an unbiased estimate of the regular scale pa-
rameter σ. For normally distributed data, (see Exercise E16.5).
ˆσ1 = 1.253 ˆδ1
(16.16)
The resulting estimator is more robust than the standard sample variance.
3. Median absolute deviation: (MAD): The deﬁnition of MAD is same as µAD, with the mean
replaced by median in theory as well as in estimation.
ˆδ2,y ≜MAD(y) = 1
N
N−1
X
k=0
|y[k] −˘y|
(16.17)
As with µAD, a correction factor is usually necessary. Once again, for normally distributed data,
we have that
ˆσ2 = 1.4826 ˆδ2
(16.18)
This estimate is more robust than the µAD, naturally so since it is based on the median, a robust
estimator of the location. Further, ˆσ2
p
−→σ with an asymptotic distribution N (µ,σ2).
The eﬃciency of MAD is low for data falling out of a Gaussian distribution, standing at 37%.
An alternative measure by Rousseeuw and Croux (1993) uses the ﬁrst quartile of all interpoint
distances to give 82% eﬃciency at normal distribution, which is more than a notch higher than
that of MAD.

424
Principles of System Identiﬁcation: Theory and Practice
For a detailed exposition of the sampling distributions of µAD and MAD along with a comprehen-
sive comparison with the sample standard deviation, the reader is referred to Pham-Gia and Hung
(2001).
Listing 16.1
MATLAB commands for estimating mean and variance
% Some commands require Statistics toolbox
% Computing mean
mean, median
% Computing variance and standard deviation
var, std, range, mad(y,0), mad(y,1)
16.3
ESTIMATORS OF CORRELATION
Computation of correlation (7.33) requires covariance estimates. A standard way of estimating co-
variance between two signals y[k] and u[k] is through
ˆσyu = 1
N
N−1
X
k=0
(y[k] −¯y)(u[k] −¯u)
(16.19)
The correlation estimate (a.k.a. Pearson’s correlation coeﬃcient) is then obtained as
ˆρyu =
ˆσyu
ˆσy ˆσu
(16.20)
The covariance and correlation matrices are constructed accordingly:
ˆΣ =
" ˆσ2
y
ˆσyu
ˆσuy
ˆσ2
u
#
;
Ξ =
" 1
ˆσyu
ˆρuy
1
#
(16.21)
Properties of sample correlation coefﬁcient
i. The sample correlation coeﬃcient is an asymptotically unbiased and consistent estimator of the
correlation ρyu (see below for related expressions).
ii. Distribution: The distribution of ˆρ is a rather complicated problem to handle. When y[k] and
u[k] have a joint Gaussian distribution, an exact expression involving beta and hypergeometric
functions is available (Pearson, 2011). However, given the complicated nature of the result, typ-
ically approximate expressions for the ﬁrst four moments are computed. Among these we are
interested in the ﬁrst two:
E( ˆρyu) ≈ρ −ρ(1 −ρ2)
2(N + 6) ;
var( ˆρyu) ≈(1 −ρ2)2
N + 6
(16.22)
Observe that the variance of the estimate is dependent on the actual correlation with the maxi-
mum occurring at ρ = 0, i.e., when the variables are actually uncorrelated.
Under the bivariate Gaussian assumption, when the true correlation between the signals is ρ = 0,
the estimate is known to have a near normal distribution.
ˆρyu
d
−→N (0,1/N)
(16.23)
Thus, the 95% and 99% signiﬁcance levels for correlation are ±1.96/
√
N and ±2.58/
√
N, re-
spectively.

Estimation of Signal Properties
425
When the true ρyu , 0, a common approach is to use the Fisher’s transformation which pro-
duces a transformed coeﬃcient with approximately normal distribution, under the large sample
approximation and bivariate Gaussian assumption.
Fˆρ = 1
2 ln
 1 + ˆρ
1 −ˆρ
!
∼N (µF,σ2
F)
(16.24)
where µF = 1
2 ln
 1 + ρ
1 −ρ
!
;
σ2
F =
1
N −3
(16.25)
iii. Robustness: The Pearson’s correlation coeﬃcient is in general very sensitive to the presence of
outliers in data (see Pearson (2011)). Moreover, it is also not invariant to transformation of data.
For example, correlation between transformed variables can be zero even though the original
variables may be highly correlated. In statistical data analysis, other measures such as Spearman’s
rank-correlation coeﬃcient is highly preferred where these properties (robustness and invariance
to transformations) are desirable.
Generalizing to a vector of random signals, we have
z =
f
y1
· · ·
ym
u1
· · ·
um
gT ;
Σz = E((z −µz)(z −µz)T )
and its estimate
ˆΣz = 1
N
˜ZT ˜Z
ˆΞi j =
ˆΣi j
pΣiiΣj j
(16.26)
where
˜ZN×2m =
f
˜y1[0 : N −1]
· · ·
˜ym[0 : N −1]
˜u1[0 : N −1]
· · ·
˜um[0 : N −1]
g
(16.27)
and the notation ˜[.] denotes mean-centered variables, e.g., ˜yi = yi −¯yi.
The distribution of the sample covariance matrix is not available in a closed-form expression in
general. The situation is somewhat simpliﬁed if the random variables are uncorrelated and that they
follow a multivariate normal distribution. Then the sample covariance follows a Wishart distribution
(Ogunnaike, 2010).
ˆΣz ∼W2m,N−1(Σ)
(16.28)
where W2m, N−1 is the 2m-dimensional Wishart distribution with (N −1) degrees of freedom. The
Wishart distribution can be thought of as an extension of the univariate χ2 distribution to the multi-
variate case.
Results on distribution of the sample correlation matrix for uncorrelated multivariate normally
distributed signals have been provided by several researchers (see Neudecker and Wesselman (1990)
for instance).
In a general situation, resampling techniques such as the boostrapping methods may have to be
employed to arrive at the empirical distribution.
16.3.1
ESTIMATORS OF PARTIAL CORRELATION
In Section 7.4.3, we learnt the notion of partial correlation and its use in detecting the direct corre-
lation between two signals y and u in the presence of a confounding variable w (a.k.a. controlling
variable). The deﬁnition is based on the correlation between conditioned variables. Conditioning
here refers to the removal of linear eﬀects of the confounding variable w on each of y and u in an

426
Principles of System Identiﬁcation: Theory and Practice
optimal manner (typically using least squares). Recall that this procedure leads to the theoretical
expression for the partial correlation as
ρyu.w =
ρyu −ρyw ρwu
q
(1 −ρ2yw)
q
(1 −ρ2wu)
((7.42) revisited)
The estimate itself is obtained by replacing the theoretical values on the RHS by their respective
estimates.
Test for conditional linear independence: To test the hypothesis ρyu.w = 0, Fisher’s transforma-
tion of the partial correlation can be used in a similar way as for the ordinary correlation.
When both the signal sets are vectors, the partial correlation is computed in two steps:
1. Denote the signals of interest by z and the confounding signals by w. Construct the sample
covariance matrix:
ˆΣ =
" ˆΣzz
ˆΣzw
ˆΣwz
ˆΣww
#
j
(16.29)
2. Compute the partial covariance (between the signals in z) as:
ˆΣz.w = ˆΣzz −ˆΣzw ˆΣ−1
ww ˆΣwz
(16.30)
from which the partial correlation estimate is obtained as
ˆΞz.w = Σ−1/2
d
ˆΣz.wΣ−1/2
d
(16.31)
In the expression above, Σd is a diagonal matrix consisting of the diagonal elements of ˆΣz.w.
Listing 16.2
MATLAB commands for computing correlation
% Some commands require Statistics Toolbox
% Computing covariance and correlation
corrcoef , cov, corr, xcov, xcorr
% xcorr does not remove mean
% Computing partial correlation
partialcorr
We now turn to the estimation of correlation functions, ideas for which emanate from this section.
16.4
ESTIMATION OF CORRELATION FUNCTIONS
The material presented in this section has its roots in the expositions of Shumway and Stoﬀer (2006),
Priestley (1981) and Box, Jenkins and Reinsel (2008).
Estimates of cross-correlation function
The cross-covariance function σyu[l] (recall (8.17)) between two signals y and u is the cross-
covariance between y[k] and u[k −l]. Accordingly,
ˆσyu[l] = 1
N
N−1
X
k=l
(y[k] −¯y)(u[k −l] −¯u)
l ≥0
(16.32)
To obtain the estimates at negative lags, use the fact that σyu[l] = σuy[−l]. The maximum lag up to
which ˆσyu[l] in (16.32) can be evaluated is |lmax| = N −1. It is easy to see that (16.32) simpliﬁes
to the ML estimator of variance in (16.9).

Estimation of Signal Properties
427
An estimate of the CCF is obtained by simply normalizing the CCVF estimate in (16.32).
ˆρyu[l] =
ˆσyu[l]
p ˆσyy[0]ˆσuu[0]
(16.33)
Properties of CCF estimator
The estimator in (16.33) is asymptotically unbiased and consistent. This is expected since under-
neath (16.33) resides a correlation estimate.
In identiﬁcation (and time-series analysis) we are primarily concerned with (i) whiteness of resid-
uals (or a given series) and (ii) lack of correlation between residuals and (lagged) inputs for model
assessment and diagnosis. In order to set up formal tests, we require the knowledge of
1. Fluctuations (or standard error) in ˆρyu[l] when the true correlation is ρyu[l] = 0, ∀l. This is
useful in drawing the signiﬁcance levels for CCF (ACF) estimates.
2. Correlation between estimates at two diﬀerent lags, again when the true correlation function is
zero. This becomes useful in interpreting the CCF (ACF) plots.
The results are similar to that for correlation, with additional restrictions on the driving white-
noise sources and the nature of processes. The main result is given below (Brockwell and Davis
(1991) and Shumway and Stoﬀer (2006)).
Theorem 16.2
If y[k] and u[k] have both linear stationary (not necessarily causal) representations as in (9.10) and
the driving white-noise sources are IID and are independent of each other, then
ˆρyu[l] ∼As.N *.
,
0, 1
N
∞
X
j=−∞
ρyy[j]ρuu[j]+/
-
,
l ≥0
(16.34)
Further, the joint distribution of the estimates at two diﬀerent lags l = l1,l2 is asymptotically normal:
cov( ˆρyu[l1], ˆρyu[l2])
d
−→1
N
∞
X
j=−∞
ρyu[j]ρuu[j + l1 −l2]
(16.35)
Proof. See Shumway and Stoﬀer (2006).
□
Remarks:
i. It is clear that the error in the estimates depends on the auto-correlation of the individual series.
ii. The result leads us to a useful formula for the signiﬁcance levels for correlation estimates when one of the
signals is hypothesized to be white:
ˆρyu[l] ∼As.N (0,1/N)
(16.36)
=⇒100(1 −α)% sig. level for ˆρyu[l] = ± zα/2
√
N
(16.37)

428
Principles of System Identiﬁcation: Theory and Practice
iii. If neither signal is known to be white, then one or both have to be pre-whitened to be able to use the results.
When correlations are tested by pre-whitening both series, it is said to be based on an “equal-footing”
approach, while the test based on a pre-whitening only a single series is known as a “systems” approach
(Chatﬁeld, 2004). The latter is used in the estimation of IR coeﬃcients in identiﬁcation of FIR models,
explained in §20.2.2.1, and statistical assessment of model quality, illustrated in §22.6.4. An illustration of
the “equal footing” approach is shown in Example 16.1 below.
Note that the CCF of the pre-whitened series in both approaches is diﬀerent from the CCF of the original
series. However, the purpose of pre-whitening is to test for correlations; more importantly, to be able to use
the signiﬁcance level given in (16.37).
Pre-whitening: Given any series, the process ﬁrst involves ﬁtting a suﬃciently high-order time-series
model (preferably AR because of the ease of estimation) using MLE or LS methods to the given series.
Then, the residual series of the resulting model is the pre-whitened series. See Example 16.1 below and
20.1 in §20.2.2.1 for more details.
iv. The large-sample expression for covariance of correlation estimates without the restriction that y and u are
independent, due to Bartlett is given below (Brockwell and Davis, 1991).
If y[k] and u[k] have a bivariate Gaussian distribution and further that the individual ACVFs are absolutely
convergent (i.e., a spectral density exists), then
lim
N→∞Ncov( ˆρyu[l1], ˆρyu[l2]) =
∞
X
j=−∞
f
ρyy[j]ρuu[j + l2 −l1] + ρyu[j + l2]ρuy[j −l1]
−ρyu[l1](ρyy[j]ρyu[j + l2] + ρuu[j]ρuy[j −l2])
−ρyu[l2](ρyy[j]ρyu[j + l1] + ρuu[j]ρuy[j −l1])
+ ρyu[l1]ρyu[l2]
 1
2 ρ2
yy[j] + ρyu[j] + 1
2 ρuu[j]
! g
(16.38)
It follows that if either y[k] or u[k] is white and ρyu[l] = 0, then a result similar to (16.36) emerges,
lim
N→∞var( ˆρyu[l]) = 1
N
(16.39)
These results are illustrated through a numerical example.
Example 16.1: Signiﬁcance Levels for CCF
Consider two signals with zero cross-correlation, but are individually auto-correlated:
y[k] =
1
1 −1.1q−1 + 0.28q−1 e1[k] (AR(2));
u[k] =
1
1 −0.8q−1 e2[k] (AR(1))
e1[k] ∼N (0,1); e2[k] ∼N (0,1);
σe1e2[l] = 0, ∀l
Computing ρyu[l] from N = 512 observations produces the CCF plot shown in the bottom
panel of Figure 16.1(a). Although the series are truly uncorrelated, blindly applying the
signiﬁcance levels without considering the auto-correlation structure of the individual series
can lead to erroneous conclusions. The dashed lines in the ﬁgures denote the 95% signiﬁcance
levels.
Pre-whitening both the series followed by a CCF testing reveals the correct underlying
relationship between the two signals y[k] and u[k].
It is left as an exercise to the reader to show that pre-whitening even one series can lead to correct
conclusions. The example above is representative of the correlation analysis between the residuals
and inputs in an identiﬁcation exercise.

Estimation of Signal Properties
429
−10
−5
0
5
10
−0.1
0
0.1
0.2
CCF
Lags
With original series
−10
0
10
−0.5
0
0.5
1
ACF
Lags
−10
0
10
−0.5
0
0.5
1
ACF
Lags
(a) Using original series
−10
−5
0
5
10
−0.1
0
0.1
CCF
Lags
With pre−whitened series
−10
0
10
−0.5
0
0.5
1
ACF
Lags
−10
0
10
−0.5
0
0.5
1
CCF
Lags
(b) Using pre-whitened series
FIGURE 16.1
Testing CCF with the signiﬁcance levels for the series of Example 16.1.
Listing 16.3
MATLAB code for illustrating Example 16.1
% Generate two series AR(1) and MA(1)
uk = filter(1,[1 -0.8],randn(512,1));
yk = filter(1,[1 -1.1 0.28],randn(512,1));
N = length(yk);
% Compute the CCF and draw the significance levels
Lmax = 10;
[ccfacf_mat ,lags] = xcov([yk uk],Lmax,’coeff’);
% Plot the CCF and the significance levels
figure; h1 = subplot(2,1,2);
stem(h1,lags,ccfacf_mat(:,2),’Markerfacecolor’,’blue’);
hold on
plot([-Lmax Lmax]’,[ones(2,1) -ones(2,1)]*1.96/sqrt(N),’r--’);
% Plot the ACFs
h2 = subplot(2,2,1);
stem(h2,lags,ccfacf_mat(:,1),’Markerfacecolor’,’blue’);
hold on
plot([-Lmax Lmax]’,[ones(2,1) -ones(2,1)]*1.96/sqrt(N),’r--’);
h3 = subplot(2,2,2);
stem(h3,lags,ccfacf_mat(:,4),’Markerfacecolor’,’blue’);
hold on
plot([-Lmax Lmax]’,[ones(2,1) -ones(2,1)]*1.96/sqrt(N),’r--’);
% Pre-whiten and compute the CCF
mod_aryk = ar(yk,2);
yk_resid = pe(mod_aryk ,yk);
mod_aruk = ar(uk,2);
uk_resid = pe(mod_aruk ,uk);
[ccfacf_eps ,lags] = xcov([yk_resid uk_resid],Lmax,’coeff’);
% Plot the CCF and the significance levels
figure; h12 = subplot(2,1,2);
stem(h12,lags,ccfacf_eps(:,2),’Markerfacecolor’,’blue’);
hold on
plot([-Lmax Lmax]’,[ones(2,1) -ones(2,1)]*1.96/sqrt(N),’r--’);
% Plot the ACFs
h22 = subplot(2,2,1);
stem(h22,lags,ccfacf_eps(:,1),’Markerfacecolor’,’blue’);
hold on
plot([-Lmax Lmax]’,[ones(2,1) -ones(2,1)]*1.96/sqrt(N),’r--’);

430
Principles of System Identiﬁcation: Theory and Practice
h32 = subplot(2,2,2);
stem(h32,lags,ccfacf_eps(:,4),’Markerfacecolor’,’blue’);
hold on
plot([-Lmax Lmax]’,[ones(2,1) -ones(2,1)]*1.96/sqrt(N),’r--’);
Estimates of auto-correlation function
The ACF is a special case of the CCF and hence all the previous results apply in a straightforward
manner. Nevertheless, it deserves special attention because of its importance in modeling (residual
analysis tests, see §22.6.4). From (16.33),
ˆρyy[l] = ˆσyy[l]
ˆσyy[0] ;
ˆσyy[l] = 1
N
N−1
X
k=l
(y[k] −¯y)(y[k −l] −¯y),
l ≥0
(16.40)
As in the case of CCF, the maximum lag up to which the ACF can be computed is |lmax| = N −1.
Remarks:
i. The ACF estimator in (16.40) is consistent.
ii. Bartlett’s expression for the covariance of the ACF estimates can be applied by setting y[k] = u[k] in
(16.38) and simplifying to give
lim
N→∞Ncov( ˆρyy[l1], ˆρyy[l2]) =
∞
X
j=−∞
(ρ[j + l1] + ρ[j −l1] −2ρ[l1]ρ[j])
×(ρ[j + l2] + ρ[j −l2] −2ρ[l2]ρ[j])
(16.41)
where the subscripts on ρ in the RHS have been dropped for convenience.
iii. When y[k] follows a Gaussian distribution,
√
N ˆρyy ∼As.N (ρyy,Σ ˆρ)
(16.42)
where ˆρyy =
f
ˆρ[1]
ˆρ[2]
· · ·
ˆρ[l]
g
and Σ ˆρ is the covariance matrix whose elements are given by
(16.41).
The distribution of ACF estimates in (16.42) is used to construct conﬁdence intervals for ACFs, wherever
required.
iv. By virtue of the result above, we have that, for a Gaussian white-noise signal,
ˆρyy[l] ∼AsN (0,1/N)
(16.43)
=⇒100(1 −α)% sig. level for ˆρyy[l] = ± zα/2
√
N
(16.44)
v. Expression (16.44) forms the basis for a test of whiteness (see the ensuing section for an illustration and
additional tests).
vi. The ACVF in (16.40) can be computed in an eﬃcient manner through the Fourier transform route. By
Wiener-Khinchin theorem, the power spectral density and ACVF are Fourier pairs. It can be shown that the
periodogram and the biased sample ACVF in (16.40) also form a Fourier pair (see §16.5.1). For large data
sets, computing the ACVF via the IFFT of periodogram oﬀers signiﬁcant computational advantages over a
straightforward implementation of (16.40).
As remarked earlier, testing the whiteness of a series is an important part of the residual analysis
during model assessment. In time-series modeling, this test is also applied in the initial stages of
model development, in order to examine whether the given series is predictable. Several time- and
frequency-domain methods are available for this purpose (Brockwell, 2002; Shumway and Stoﬀer,
2006). We discuss two popular time-domain (or lag-domain) methods below.

Estimation of Signal Properties
431
Tests for whiteness
The problem is of testing the hypothesis
H0 : ρ[l] = 0, ∀l
against
Ha : ρ[l] , 0, at least for one l ∈{Z −0}
1. Sample auto-correlation test: The setup for this test directly follows from (16.44). For a given
series, compute the ACF estimates up to a maximum lag, say l = 20. Then, reject H0 if at the
ACF exceeds the 100(1 −α)% signiﬁcance level in (16.44). For instance, the 95% signiﬁcance
levels are ±1.96/
√
N.
A matter of concern in implementing this test is that the probability of | ˆρ[l]| > 1.96/
√
N at a
given lag depends on ˆρ[l] at other lags since these estimates are correlated with each other, as
dictated by Theorem 16.2.
2. Box-Ljung-Pierce test: It is also known by the name portmanteau test. The method overcomes
the aforementioned drawback of the sample ACF-based method by collectively examining the
ACF estimates over a range of lags. Under H0, the sample ACF coeﬃcients possess a Gaussian
distribution; therefore the sum-squared estimates follow a χ2 distribution. With this basic idea,
the Box-Ljung statistic (Ljung and Box, 1978)
Q = N(N + 2)
L
X
l=1
ˆρ2
yy[l]
N −l
(16.45)
is constructed. When H0 holds, Q ∼χ2
L. If the observed Q exceeds the prescribed critical value,
H0 is rejected at the level α. The value of L is a user-speciﬁed value and chosen somewhat
arbitrarily, say L = 20 or 40. A modiﬁed statistic due to McLeod and Li (1983)
Q = N(N + 2)
L
X
l=1
ˆρ2
ww[l]
N −l
(16.46)
where the use of squared series w[k] = y2[k] is also common.
Other tests such as the Durbin-Watson test (for testing residuals from a linear regression), turning
point test, diﬀerence sign test, rank tests or even a parametric test such as ﬁtting a time-series model
and testing for the adequacy of a zero-order model are also commonly used. See Brockwell (2002)
for a description of some of these methods.
To illustrate the two tests above, we make use of a simulated series as discussed below.
Example 16.2: Whiteness Test of a Series
Given N = 512 observations of a series, whose snapshot if displayed in Figure 16.2(a), we
would like to test for its whiteness. The sample ACF and the signiﬁcance levels are shown
in Figure 16.2(b). Based on the sample ACF test, the null hypothesis that the given series is
white is rejected at α = 0.05 signiﬁcance level since the ACF at lags l = 1,2 exceed the 95%
bounds. The BLP Q statistic for the given series is 250.6922, a value much higher than the
critical value of 31.41 obtained from the χ2
20,α/2 distribution where α = 0.05. Thus, the null
hypothesis that the series is white is rejected at α = 0.05 signiﬁcance level.
The ACF plot is in fact suggestive of a MA(2) model for the series. However, such guesses
should be conﬁrmed with a more rigorous analysis either by re-computing the bounds for
ACF post-ﬁtting an MA(2) model and using (16.41).
At a later stage, we shall describe a frequency-domain whiteness test based on spectral density of
the series.

432
Principles of System Identiﬁcation: Theory and Practice
20
40
60
80
100
120
−3
−2
−1
0
1
2
3
4
Time
Amplitude
(a) Snapshot of the series
0
5
10
15
20
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
ACF
Lags
(b) Sample ACF
FIGURE 16.2
Testing the series of Example 16.2 for whiteness.
Estimation of PACF
The partial ACF estimates, useful in determining the order of AR models, are computed using the
classical recursive Durbin-Levinson’s algorithm described in Table 9.1. Note that the method re-
quires the computation of ACF estimates up to the lag at which the PACF is desired. The underlying
principle is that of a Yule-Walker estimator of the coeﬃcients of an AR(p) model. Recall that the
PACF at a lag l = p, φvv[p] is the last coeﬃcient of an AR(p) model for v[k]. Thus, the distribu-
tion of PACF estimates depends on the sampling distribution of the model coeﬃcients. Chapter 19
presents the large sample properties of the Y-W estimates of an AR(p) model. Using those results,
two important properties of the PACF estimates (obtained by the Y-W or the D-L algorithm) can be
stated:
i. The PACF estimator consistently estimates the PACF values.
ii. If the data is assumed to be generated by an AR(P) process,
√
N ˆφvv[l]
d
−→N (0,1), ∀l > P
=⇒95% signiﬁcance levels for ˆφvv[l] = ±1.96
√
N
, ∀l > P
(16.47)
Biased vs. unbiased estimators of ACVF
In closing, an important aspect related to the estimation of ACVF merits discussion (which equally
applies to the estimation of CCVF as well). The estimator in (16.40) is known to be biased (but
asymptotically unbiased). One could have alternatively considered an intuitively unbiased estimator
instead,
ˆσ(u)
yy [l] =
1
N −|l|
N−1
X
k=l
(y[k] −¯y)(y[k −l] −¯y)
(16.48)
However, this estimator is seldom used for reasons mentioned below. See Percival and Walden
(1993) and Priestley (1981) for a thorough treatment of the issues and the necessary proofs / deriva-
tions.
i. The “unbiased” estimator has a larger mean square error (recall it as an important metric of
estimator’s goodness) than the biased estimator in (16.40) (see Percival and Walden (1993, p.
191-194) for example)
ii. Non-negative deﬁniteness, a critical property of any ACVF sequence of a stationary process, is
not guaranteed by ˆσ(u)[l]. In contrast, the estimator in (16.40) guarantees a non-negative se-
quence. This is perhaps the more important reason for the biased estimator to be the standard
choice.

Estimation of Signal Properties
433
iii. By virtue of the second property, the use of ˆσ(u)[.] in spectral estimation is not guaranteed to
produce non-negative valued spectral densities, whereas the biased estimator always produces
non-negative spectral density estimates.
iv. Finally, as a matter of academic interest, the “unbiased” estimator is only unbiased if the sample
mean is replaced by the true mean. Else, even ˆσ(u)[.] stands to be biased.
16.5
ESTIMATION OF AUTO-POWER SPECTRA
Spectral estimation has been a subject of great value and interest for more than a century (Bloom-
ﬁeld, 2000; Broersen, 2006; Priestley, 1981). There exist today several well-established and time-
tested techniques owing to the concerted eﬀorts of several researchers. The classical spectral esti-
mation problem and most of the relevant literature are in the context of stochastic signals because
of the underlying challenges.
Historically, estimation of spectra was associated with the detection of periodicities in measured
data. One of the classical approaches has been to formulate the problem as that of regression with
the cosines and sines of diﬀerent frequencies as regressors. It turns out that the OLS estimates of
the regression coeﬃcients are proportional to the DFT of the ﬁnite-length data (see for example,
Priestley (1981)).
In Chapters 10 and 11, we learnt that the primary instrument for spectral analysis detection is the
Fourier transform, speciﬁcally the energy / power spectral densities and the DFT. Deterministic sig-
nals are characterized by either energy spectral density (inﬁnite-length aperiodic signals) or power
spectrum (periodic case), while stochastic signals of general interest are characterized by their power
spectral densities (recall deﬁnitions (11.2) and (11.4)). However, in §10.4.1, we were able to deﬁne
a power spectral density for deterministic signals as well, based on DFT of ﬁnite-length records.
Thus, it suﬃces to compute the power spectral density in practice.
The p.s.d. obtained from ﬁnite-length data was given the name periodogram by Schuster (1897).
The periodogram can always be computed irrespective of the nature of the underlying signals. His-
torically, the periodogram was one of the ﬁrst spectral estimators to be developed.
It is useful to ﬁrst study an important eﬀect of ﬁnite-length data on the use of periodogram known
as spectral leakage (see §16.5.2.1) since it applies to both deterministic and stochastic signals.
Remedial measures for mitigating spectral leakage involve the use of what are known as window
functions.
In the stochastic case, the use of periodogram as an estimator presents an additional issue, which
is that it lacks the required property of consistency. Consequently, several modiﬁed periodogram
methods have come to the forefront. Recognizing the two potential risks of using these techniques,
eﬀorts were directed towards model-based methods for spectral estimation by ﬁrst building time-
series models (typically the AR class) followed by the construction of spectral density using the
FRF route (recall (11.36)). These techniques fall under parametric methods as against the non-
parametric methods that the periodogram and other DFT-of-signal based techniques belong to. One
of the major advantages of the parametric methods is that they are rid of the spectral leakage and
consistency issues mentioned above. Potentially they can construct spectral density at higher reso-
lution. Naturally, these methods come with their bag of risks (see §16.5.7).
We shall focus, for the most part, on the estimation of auto-spectral densities since it is fairly
straightforward to apply these ideas to the cross-spectral density estimation problem. Spectral esti-
mation for measurements containing mixed spectra (pure tones and broadband noise) call for greater
care when using non-parametric methods. Although not directly related to identiﬁcation, for com-
pleteness sake we shall brieﬂy review these so-called high resolution spectral estimation methods
(also known as principal component methods) in §16.5.8.
In the developments to follow, all discrete-time deterministic signals are denoted by x[k], while
the stochastic signals by v[k].
We begin by ﬁrst deﬁning the periodogram.

434
Principles of System Identiﬁcation: Theory and Practice
16.5.1
PERIODOGRAM
Given a ﬁnite record of data, yN = {y[0], y[1],· · · , y[N −1]}, the periodogram is deﬁned as (Schus-
ter, 1897),
Pyy(ωn) =
1
2πN |YN (ωn)|2
(16.49)
where YN (ωn) =
N−1
X
k=0
y[k]e−jωnk, ωn = 2π n
N , n = 0,1,· · · , N −1.
Interestingly, the concept of periodogram existed at least four decades prior to the concept of the
power spectral density for random processes.
If the unitary DFT,
YN (ωn) =
1
√
N
N−1
X
k=0
y[k]e−jωnk, ωn = 2π n
N ,n = 0,· · · , N −1
(16.50)
is used instead, the periodogram has a simpler form.
ˆγvv(ω) = 1
2π |YN (ω)|2
(16.51)
This version is frequently used in the theoretical analysis of identiﬁcation problems.
Note: If it is desired to express P(.) in cyclic frequency f , use N instead of 2πN and unity in the denominators
of (16.49) and (16.51), respectively.
An important property that the periodogram enjoys is the symmetricity owing to the circular
conjugate symmetry property of DFT. The periodogram is unique only over frequencies n =
0,· · · , ⌊N/2⌋. Hence, in practice the periodogram is computed only up to these frequencies. Fol-
lowing which, several signal processing tools elect to report a one-sided spectral density (Bendat
and Piersol, 2010),
P(o)
vv [n] =

Pvv[0],
n = 0, N
2 (N even only)
2Pvv[n],
n = 1,· · · , ⌊N−1
2 ⌋
(16.52)
where ⌊.⌋is the usual ﬂoor operator.
In principle, the periodogram can be computed for any ﬁnite-length data. However, its use as an
estimator of the p.s.d. for a random signal, as mentioned above, attracts modiﬁcations. As mentioned
earlier, all spectral estimation methods based on DFT of signals (periodogram being one among
them) suﬀer from the ﬁnite-length eﬀects.
16.5.2
FINITE-LENGTH EFFECTS IN DIRECT DFT METHODS
We shall study the issue of spectral leakage and the associated remedial measures. In studying the
ﬁnite-length eﬀects, we shall largely use deterministic signals to illustrate the underlying concepts.
However, these apply to stochastic signals as well.
16.5.2.1
Spectral Leakage
Recall that performing the DFT of a given observation record (of length Nl) implicitly amounts to
assuming that the original (presumably) inﬁnitely-long signal is periodic. In other words, even the
given signal contains a periodic component of period Np, the DFT is capable of correctly identifying

Estimation of Signal Properties
435
the periodicity if and only if the length of the signal is Nl = mNp,
m ∈Z, i.e., the length is an
integer multiple of the period. When only fractional cycles are completed in a single record, we run
into a phenomenon known as spectral leakage due to the ﬁnite sample size eﬀects.
An alternative viewpoint is that a component of the signal with frequency f0 is correctly identiﬁed
by DFT if and only if f0 is a member of the basis set, i.e.,
f0 ∈{ fn = 1
N ; n = 0,1,· · · , N −1}
else the single tone is explained by a subset of basis frequencies that are diﬀerent from f0.
This is understood by studying the simple case of a complex exponential.
Example 16.3: DFT of a Complex Sinusoid
Consider a (complex-valued) periodic signal x[k] = ej2π f0k where f0 = m/Np, m, Np ∈Z+ and
as usual, m and Np are coprime. Suppose N samples of such a signal are available. Then, its
DFT is,
X[n] =
N−1
X
k=0
x[k]e−j2π n
N k =
N−1
X
k=0
e
j2πk

m
Np −n
N

= 1 −r N
1 −r
where
r = e
j2π*
,
m
Np
−n
N
+
-
When N = lNp, l ∈Z+, the DFT is
X[n] = 1 −ej2π(lm−n)
1 −ej 2π
N (lm−n) =

N,
n = lm
0,
n , lm
(16.53)
Thus, DFT identiﬁes the correct frequency with the power spectrum showing a single peak
at n = lm. For real-valued mono-frequency sine (or cosine), the peak value1 is N/2.
When N = (l +γ)Np, 0 < γ < 1, i.e., when only fractional cycles are completed in the given
data record,
X[n] = 1 −ej2π(lm−n+γm)
1 −ej 2π
N (lm−n+γm) =
1 −ej2πγm)
1 −ej 2π
N (lm−n)ej 2πγm
N
(16.54)
The peak value still occurs at n = lm, but there X[n] , N. More importantly, when n , lm,
X[n] , 0. Thus, the amplitude of DFT is not concentrated at a single frequency, but rather
spread around it. The extent of spread or leakage diminishes as n becomes larger than lm.
It follows that the power spectrum also exhibits a peak around n = lm unlike just a single
peak when N = lNp.
Spectral leakage is encountered in the DFT of any general ﬁnite-length signal. One of the most
important consequences of spectral leakage is that these artefacts interfere with the contributions of
other signal and/or noise components in x[k]. A formal treatment of these eﬀects and remedies is
facilitated by the introduction of window functions.
1By virtue of the Euler’s identity (for e jθ) and the linearity property of DFT.

436
Principles of System Identiﬁcation: Theory and Practice
Windowing perspective
A ﬁnite-length signal x[k], 0 ≤k ≤N −1 can be thought of as its corresponding inﬁnite-length
signal x0[k] being viewed through a rectangular (or a boxcar) “window” wR[k] (naturally of width
N). Mathematically, this is written as
x[k] = wR[k]x0[k]
(16.55a)
where wR[k] =

1,
0 ≤k ≤N −1
0,
elsewhere
(16.55b)
From the property of the Fourier transforms, we recall that the DTFT of the ﬁnite-length signal is
X(ω) = W R(ω) ⊛X(ω) = 1
2π
Z π
−π
W R(ω′)X0(ω −ω′) dω′
(16.56)
In other words, the Fourier transform of the ﬁnite-length signal X(ω) at each frequency is a con-
voluted or a distorted version of the true value X0(ω). The extent of distortion depends on the
characteristics of the window in the frequency domain, W R(ω). As previously mentioned, a major
repercussion of this distortion is that it clouds the ability of the analyst in discriminating between
the signal’s inherent components and the leakage caused by the window. In the discussion to follow,
we derive the expression for W R(ω).
Fourier transform of rectangular window
From Example 10.9, we know that the DTFT of a pulse with width N
W R(ω) = 1 −e−jωN
1 −e−jω
= e−jω N−1
2 sin(ωN/2)
sin(ω/2) , ω , 0
Observe that
W R(ω)/N = 1,
at ω = 0,2πM, M ∈Z+
W R(ω)/N = 0,
at ω = 2π d
N = d△ω, d ∈Z −{0}
The time-domain proﬁle of the rectangular window and the magnitude of its Fourier transform
are shown in Figure 16.3. Notice that the x-axis of Figure 16.3(b) is in terms of frequency oﬀset fO,
expressed in bins. It is calculated with respect to the frequencies at which |W(ω)| = 0,
fO =
ω
(2πd/N) =
ω
d△ω
(16.57)
The lobe in the nearest vicinity of frequency ω = 0 is called the main or the central lobe and
the lobes associated with the side peaks as side lobes. The eﬀect of (16.56) is that the spectral
estimate from the DFT at any frequency bin contains contributions of the signal and the noise from
neighboring bins as measured by the window. In this sense, the window function acts as a sensor
for the true spectrum.
We revisit Example 10.1 in light of the above discussion.
Example 16.4: DFT of a Complex Sinusoid Revisited
Revisiting Example 16.3, choose x[k] = ejω0k,
∈[−π,π]. Recall ω0 = 2πm/Np. The DTFT
of the corresponding inﬁnite-length signal is
X0(ω) = δ(ω −ω0).

Estimation of Signal Properties
437
0
10
20
30
40
50
60
0
0.2
0.4
0.6
0.8
1
Samples
w[k]
(a) Time-domain proﬁle
−8
−6
−4
−2
0
2
4
6
8
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Frequency offset (bins)
|W(fO)|/N
(b) Magnitude of W (ω)
FIGURE 16.3
Rectangular window function and its Fourier transform magnitude.
Then,
X(ω) = 1
2π
Z π
−π
W R(ω′)δ(ω −ω0 −ω′) dω′ = W R(ω −ω0)
Thus, the shape of X(ω) depends on the behavior of W R(ω) in the vicinity of ω0. Proceeding
to its DFT,
X[n] = X(ω)|ωn=n△ω = W R(n△ω −ω0);
△ω = 2π/N
From the analysis of the rectangular window above, spectral leakage is absent whenever
n△ω −ω0 = d△ω, d , 0
=⇒ω0 = (n −d)△ω or N = lNp, l ∈Z+
(16.58)
and a single peak is observed at that bin n⋆where W R(ω)/N = 1, i.e., at
n⋆△ω −ω0 = 0
=⇒n⋆= lm
When N = (l + γ)Np, 0 < γ < 1, i.e., ω0 = (l + γ)△ω
|X(ωn)| = |X[n]| =

sin(γm)
sin(2π(r −γm)/N)

;
r = n −lm
The peak in |X[n]| no longer occurs at n = lm, but to its left or right depending on the values
of γ and m, which also govern the spread to the neighboring frequencies.
Figure 16.4 illustrates these points on a sinusoid of ω0 = 2π(0.04), i.e., Np = 25 for two
diﬀerent sample sizes2, N = 100 and N = 109.
The periodogram for N = 100 is shown in Figure 16.4(a). Since N = 200 is an integer
multiple of Np, a single spectral peak is observed and rightly at f = 0.04 cycles/sample
corresponding to n⋆= 8 (9th bin). Spectral leakage due to fractional cycles in the record of
N = 109 samples is shown in Figure 16.4(b).
Observe that the peak does not occur any more at f0 = 0.04 since f0 < { fn = n/N; n =
0,1,· · · , N −1}. Consequently, the power contained in the original signal at a single frequency
f0 is now explained by sinusoids at neighboring frequencies.
2Note that the cyclic frequency is chosen over the angular frequency in this example for convenience.

438
Principles of System Identiﬁcation: Theory and Practice
0
0.02
0.04
0.06
0.08
0.1
0
5
10
15
20
25
Frequency (cycles/sample)
Periodogram
(a) N = 100 (integer cycles)
0
0.02
0.04
0.06
0.08
0.1
0
2
4
6
8
10
12
14
16
18
Frequency (cycles/sample)
Periodogram
(b) N = 109 (fractional cycles)
FIGURE 16.4
Illustration of spectral leakage of sine wave.
Listing 16.4
MATLAB code for Example 16.4
% Generate a sine of length equal to integer cycles
kvec1 = (0:99)’; f0 = 0.04; f_lim = [0 0.1];
xk1 = sin(2*pi*f0*kvec1);
% DFT and Line spectrum
xk1f = fft(xk1-mean(xk1));
N1 = length(xk1); fvec1 = (0:1/N1:0.5-1/N1);
figure; stem(fvec1,abs(xk1f(1:end/2)).^2/N1);
% Repeat for fractional cycle case
kvec2 = (0:108)’;
xk2 = sin(2*pi*f0*kvec2);
% DFT and Line spectrum
xk2f = fft(xk2-mean(xk2));
N2 = length(xk2); fvec2 = (0:1/N2:0.5-1/N2);
figure; stem(fvec2,abs(xk2f(1:floor(end/2))).^2/N2);
16.5.3
REMEDIES: WINDOW FUNCTIONS
Remedial measures for leakage are devised based on two equivalent standpoints, one in the time
and the other in the frequency domain.
The time-domain standpoint is based on the fact that DFT inherently treats the original signal as
a periodic extension of the ﬁnite-length signal. Thus, unless the ﬁrst and last values of the signal co-
incide, a very rare occurrence, discontinuities occur at the boundaries. The spectral eﬀects of these
discontinuities interfere with the power spectrum of the actual signal. If the sharp changes at the
boundaries can be replaced by smooth transitions using appropriate weighting at the endpoints, the
leakage could be signiﬁcantly alleviated, if not eliminated. Diﬀerent degrees of smoothing require-
ments at the endpoints give rise to window functions with diﬀerent characteristics.
The frequency-domain viewpoint is that the non-localized (spread out) nature of the rectangular
window |W(ω)| is the cause for leakage and any remedial measure should be aimed at reducing the
side lobes (recall Figure 16.3(b)). However, any eﬀort to suppress the side lobes inevitably results
in the widening of the main lobe (once again due to the duration-bandwidth principles)! Wider main
lobes are not desirable either since they accumulate more amounts of noise and signal components
within the vicinity of a frequency of interest. This is the essential compromise involved in the design
of alternative window functions.

Estimation of Signal Properties
439
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
Normalized length
w[k]
 
 
Hanning
Bartlett
Blackman
Flat Top
Rectangular
(a) Time-domain proﬁles
−10
−8
−6
−4
−2
0
2
4
6
8
10
−120
−100
−80
−60
−40
−20
0
Frequency offset (bins)
dB (normalized)
 
 
Hanning
Bartlett
Blackman
Flat Top
Rectangular
(b) Normalized magnitude (in dB), |W (ω)|/N
FIGURE 16.5
(SEE COLOR INSERT) Window functions and the magnitudes of their Fourier transforms.
Consequent to the above discussion, a modiﬁed periodogram is introduced,
˜Pyy(ω) =
1
2πN

N−1
X
k=0
w[k]y[k]e−jωnk

2
(16.59)
where w[k] is the window function with the primary role of tapering the data in a smooth manner
at its boundaries. For this reason, w[k] is frequently referred to as the tapering window.
The following fact places limitations on the ability to improve the spectral leakage characteristics
using the modiﬁed periodogram.
Ideally, for zero leakage, it is necessary to have a window such that W(ω) = δ(ω). Unfortu-
nately this cannot be satisﬁed by any window function of ﬁnite length. The duration-bandwidth
principle is the underlying cause for this fact. A function that is perfectly localized in fre-
quency is spread inﬁnitely in time. This is in conﬂict with the ﬁnite-length requirement of a
window function.
A variety of window functions (also known as tapering functions) have been studied in literature.
Table 16.1, at the end of the chapter, presents a list of popular window functions (named after their
proponents) and their frequency-domain characteristics (see below for a description). Each window
diﬀers from the other in the trade-oﬀthat it oﬀers between two important requirements of harmonic
analysis, namely, detectability and resolvability (others include sensitivity and dynamic range). The
former is concerned with the ability to detect periodic components buried in broadband noise, while
the latter is concerned with the ability to ﬁnely segregate two closely spaced signal components. In
this respect, any window is best understood by its frequency-domain characteristics. From a ﬁltering
viewpoint, W(ω) is the FRF of the ﬁlter (window) that essentially ﬁlters the original signal in the
frequency domain as evidenced in (16.56).
Figure 16.5(a) displays the time and frequency-domain proﬁles of a few popular window func-
tions. Note that the case of rectangular window defaults to not applying any window function since
it is inherent to any ﬁnite-length signal. Observe the smooth transitions at boundaries in most non-
rectangular functions. The eﬀects are felt in |W(ω)| as shown in Figure 16.5(b).
Listing 16.5
MATLAB code for generating Figure 16.5
% Frequency vector
Nfreq = 2000; winlen = 64;
wvec = (0:1/Nfreq:1-1/Nfreq)*2*pi - pi;

440
Principles of System Identiﬁcation: Theory and Practice
% Windows and magnitudes of FRF
% Rectangular , Hann, Bartlett , Blackman , Flat top
w_rect = window(@rectwin ,winlen); cg_rect = sum(w_rect);
w_hann = window(@hann,winlen); cg_hann = sum(w_hann);
w_bart = window(@bartlett ,winlen); cg_bart = sum(w_bart);
w_black = window(@blackman ,winlen); cg_black = sum(w_black);
w_flatt = window(@flattopwin ,winlen); cg_flatt = sum(w_flatt);
figure;
plot((0:winlen -1)/winlen ,[w_hann w_bart w_black w_flatt])
hold on; plot((0:winlen -1)/winlen ,w_rect ,’k--’)
% Frequency -domain characteristics
Rectw_f = fft(w_rect/cg_rect ,Nfreq);
Rectw_mag = abs(fftshift(Rectw_f));
dB_rect = 20*log10(Rectw_mag);
Hannw_f = fft(w_hann/cg_hann ,Nfreq);
Hannw_mag = abs(fftshift(Hannw_f));
dB_Hann = 20*log10(Hannw_mag);
Bartw_f = fft(w_bart/cg_bart ,Nfreq);
Bartw_mag = abs(fftshift(Bartw_f));
dB_Bart = 20*log10(Bartw_mag);
Blackw_f = fft(w_black/cg_black ,Nfreq);
Blackw_mag = abs(fftshift(Blackw_f));
dB_Black = 20*log10(Blackw_mag);
Flattw_f = fft(w_flatt/cg_flatt ,Nfreq);
Flattw_mag = abs(fftshift(Flattw_f));
dB_Flatt = 20*log10(Flattw_mag);
figure
plot(wvec/(2*pi/winlen),[dB_Hann dB_Bart dB_Black dB_Flatt])
hold on; plot(wvec/(2*pi/winlen),dB_rect ,’k--’);
As with any ﬁlter, the FRF of the window W(ω) (speciﬁcally its magnitude), is characterized
by several factors that inﬂuence the detectability and resolvability. We discuss only ﬁve important
factors and their relation to detection, resolution and spectral distortion of signals.
Characteristics of window functions
i. 6 dB BW This is the frequency interval in which |W(0) −|W(ω)| ≤6 dB. It is responsible for
resolving two closely spaced frequencies of similar amplitudes. The window with the narrowest
6 dB BW has the maximum resolving capability, which is the rectangular window. Notice that
the 6 dB BW is larger than theoretical resolution of the DFT, which is △f = 1/N = 1 bin.
ii. Peak side lobe (PSL): This is the peak value of the ﬁrst side lobe in |W(ω)|. It should be a mini-
mum to minimize leakage. Reducing PSL and minimizing 6 dB BW are conﬂicting requirements.
The rectangular window has the maximum PSL and therefore the maximum leakage.
iii. Side-lobe roll oﬀ(SLR): It measures the rate at which |W(ω)| falls oﬀfrom the central to the
side lobes. It inﬂuences the extent of spread or distortion - highest SLR causes the least leakage.
The decay in frequency is related to the diﬀerentiability of the window function at its boundaries
(Mallat, 1999). A sharp discontinuity such as that of a rectangular window has a decay rate of
1/ f while for a Hanning window, the decay is 1/ f 3 since both the function and its ﬁrst derivative
are continuous at the boundaries.
iv. Coherent gain (CG): This is the normalized DC gain of the ﬁlter (window), W(ω)|ω=0. From
the properties of the DFT,
CG = 1
N W(ω)|ω=0 = 1
N
N
X
k=1
w[k]
(16.60)

Estimation of Signal Properties
441
It is the factor by which the signal’s amplitude is altered due to windowing. The power spectrum
of a signal computed from its windowed version is calculated according to a modiﬁed deﬁnition
of (10.69) using the CG,
˜Pxx( fn) = |cn|2
CG2
(16.61)
The square of the CG value is also known as the coherent power gain (CPG). When a rectangular
window is applied (i.e., eﬀectively no windowing), ˜Pxx(.) simpliﬁes to Pxx( fn) in (10.69) since
the rectangular window has a unity CG.
v. Equivalent or eﬀective noise bandwidth (ENBW): This is the (normalized) width of a rect-
angular shaped W(ω) with the same gain and eﬀectively passes the same amount of broadband
noise as the given window. With this deﬁnition, a mathematical expression can be derived Harris
(1978)
ENBW =
N−1
X
k=0
w2[k]
(
N−1
X
k=0
w[k])2
=
||w||2
2
N2CG2
(16.62)
The ENBW can be interpreted as the eﬀective frequency resolution. It has two uses. Firstly, it
is used to obtain a deﬁnition of power spectral density for deterministic signals when window
functions are applied. Using the modiﬁed deﬁnition of power spectrum in (16.61),
˜γxx( fn) =
˜Pxx( fn)
ENBW =
N2|cn|2
N−1
X
k=0
w2[k]
(16.63)
Observe once again that when a rectangular window is used, ˜γxx(.) specializes to the regular
PSD in (10.70).
Secondly, ENBW serves as a measure of a window’s noise performance, speciﬁcally, its ability
to detect a signal component buried in noise. The rectangular window is the least sensitive to the
presence of broadband noise but has high leakage eﬀects. The Hanning window, for example,
oﬀers a suitable compromise.
Other window characteristics include processing gain, scalloping loss, worst case performance loss
and overlap correlation. For a comprehensive analysis of the characteristics of window functions,
the reader is referred to Harris (1978) and Poularikas (2010).
The rectangular window has the narrowest main lobe width but all other factors such as highest
peak side lobe and a low SLR are against its use. All other windows have a higher 6 dB BW than
the rectangular window, but other factors related to leakage are in their favor. These observations
are corroborated by Figure 16.5(b). Non-rectangular windows reduce the leakage signiﬁcantly and
better discrimination of signal components with disparate amplitudes but result in a loss of accuracy
in estimating the power at each frequency. The rectangular window on the other hand oﬀers the best
spectral resolution.
Figure 16.6 shows the spectrum of the signal in Example 16.4 when Hanning and Blackman
windows are applied to the N = 109 samples long signal of Example 16.4. On comparison with
the spectrum in Figure 16.4(b), the spectral leakage has clearly diminished with the use of window
function. However, the power has been re-distributed among the two frequencies nearest to f0 =
0.04 with a lowering of the power at frequency closer to f0. The Hanning window demonstrates
better characteristics than the Blackman window in this example.

442
Principles of System Identiﬁcation: Theory and Practice
0
0.02
0.04
0.06
0.08
0.1
0
2
4
6
8
10
12
Frequency (cycles/sample)
Periodogram
(a) Hanning window, N = 109; Np = 25
0
0.02
0.04
0.06
0.08
0.1
0
2
4
6
8
10
12
Frequency (cycles/sample)
Periodogram
(b) Blackman window, N = 109; Np = 25
0
20
40
60
80
100
120
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time
Amplitude
(c) Hanning windowed signal
0
20
40
60
80
100
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time
Amplitude
(d) Blackman windowed signal
FIGURE 16.6
Reduction in spectral leakage by use of window functions.
Listing 16.6
MATLAB code for Figure 16.6
% Generate signal
kvec2 = (0:108)’; f0 = 0.04;
xk2 = sin(2*pi*f0*kvec2);
N2 = length(xk2); fvec2 = (0:1/N2:0.5-1/N2);
% Apply Hann and Blackman windows
win_fun1 = window(@hanning ,N2); xk2w1 = win_fun1.*xk2;
cg_win1 = sum(win_fun1); ssqwin1 = sum(win_fun1.^2);
win_fun2 = window(@blackman ,N2); xk2w2 = win_fun2.*xk2;
cg_win2 = sum(win_fun2); ssqwin2 = sum(win_fun2.^2);
% DFT
xk2w1f = fft(xk2w1-mean(xk2w1));
xk2w2f = fft(xk2w2-mean(xk2w2));
% Plot spectrum
figure; stem(fvec2,abs(xk2w1f(1:floor(end/2))).^2/ssqwin1);
figure; stem(fvec2,abs(xk2w2f(1:floor(end/2))).^2/ssqwin2);
A second example demonstrates the trade-oﬀinvolved in windowing.
Example 16.5: Mixed Sines Embedded in Noise
The measurement y[k] under analysis is N = 240 samples of a mixed sinusoid embedded in
noise
y[k] = x[k] + v[k];
x[k] = A1 sin(2π f0k) + A2 sin(2π f1k)
with A1 = 1, A2 = 0.27, f0 = 0.1, f1 = 0.16, v[k] ∼GW N(0,σ2v) and σ2v/σ2x = 0.5 (SNR 2).
The time proﬁle of the measurement is shown in Figure 16.7(a).

Estimation of Signal Properties
443
0
50
100
150
200
250
−2.5
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
2.5
Time
Amplitude
(a) Measurement
0
0.1
0.2
0.3
0.4
0.5
0
10
20
30
40
50
60
70
Frequency (cycles/sample)
Periodogram
(b) PSD w/o windowing
0
0.1
0.2
0.3
0.4
0.5
0
5
10
15
20
25
30
35
40
Frequency (cycles/sample)
Periodogram
(c) PSD with Hann windowing
0
0.1
0.2
0.3
0.4
0.5
0
5
10
15
20
25
30
35
Frequency (cycles/sample)
Periodogram
(d) PSD with Blackman windowing
FIGURE 16.7
Trade-oﬀin using windows for reducing spectral leakage.
Ordinary power spectral density of y[k] (with no windowing) is displayed in Figure 16.7(b).
The frequency component f0 is correctly detected by a single peak since N/Np1 = 240/10 = 24,
an integer. However, the component with frequency f1 has a very weak presence in the spectral
density due to low amplitude and spectral leakage. Its contribution to the PSD is comparable
to that of noise at that frequency.
Windowing reduces the spectral leakage and highlights the presence of the second compo-
nent as seen in Figures 16.7(c) and 16.7(d). The price that is paid is the smearing (loss of
resolution) of the spectral density at the ﬁrst component f1.
A spectral peak detection algorithm based on a weighted average can nevertheless be
applied to identify the peak frequency from the spectral densities (see Porat (1997)).
In general, the choice of window is governed by the application of interest. The Hann window is
widely used by default in several applications since it oﬀers a reasonable trade-oﬀbetween leak-
age, resolution and detection. However, when suﬃciently large number of samples are available, a
rectangular window is recommended. Flat-top windows are best suited for applications that demand
ﬁne determination of periodic signals buried in small amounts of noise.
An extensive treatment of window functions is found in several texts and articles. See Harris
(1978), Heinzel, Rüdiger and Schilling (2002), Percival and Walden (1993), and Poularikas (2010)
for an excellent treatment of this topic.
Listing 16.7
MATLAB code for Example 16.5
f0 = 0.1; f1 = 0.16; N = 240; kvec = (0:N-1)’;
xk = sin(2*pi*f0*kvec) + 0.27*sin(2*pi*f1*kvec);
% Add measurement noise s.t. SNR = 2
yk = xk + randn(N,1)*std(xk)/sqrt(2);
yk = yk - mean(yk);

444
Principles of System Identiﬁcation: Theory and Practice
% Compute power spectral density
ykf = fft(yk); yk_psd = abs(ykf(1:end/2)).^2;
% Plot the PSD of measurement
fvec = (0:1/N:0.5-1/N);
figure; stem(fvec,yk_psd/N,’Markersize’,0);
% Window the measurement and plot the PSD
% Hann
win_hann = hanning(N); ykw1 = win_hann.*yk;
ykw1f = fft(ykw1); ykw1_psd = abs(ykw1f(1:end/2)).^2;
figure; stem(fvec,ykw1_psd/sum(win_hann.^2),’Markersize’,0);
% Blackman
win_black = blackman(N); ykw3 = win_black.*yk;
ykw3f = fft(ykw3); ykw3_psd = abs(ykw3f(1:end/2)).^2;
figure; stem(fvec,ykw3_psd/sum(win_black.^2),’Markersize’,0);
Practical considerations
In a practical situation, it would be diﬃcult to know if the signal contains a single frequency or mul-
tiple frequencies. Moreover, it would be unrealistic to expect the record to contain integer cycles.
Therefore, when dealing with short-length signals, applying a window function is always recom-
mended. Notwithstanding this recommendation is the fact that when the data length N becomes
large, the spectral leakage is negligible. Then the beneﬁts of windowing turn into drawbacks in the
form of spurious features.
In the computation of an N-point DFT, it is necessary that N ≥Nl for perfect recovery of X(ω).
However, seldom is there a need to recover X(ω). Most computations directly involve X(ωn) at a
desired resolution. Therefore, for computational and practical reasons it may not be necessary to
select N = Nl particularly when N is large. In this respect, several computational algorithms based
on DFT may use default values of N that provide adequate frequency resolution (e.g., N = 128 or
N = 256) regardless of the length of the signal. When a higher resolution is desired, the user is
provided with that ﬂexibility too. The maximum resolution available to the user in all cases is
(△ω)max = 2π
Nl
(16.64)
Thus, it is not possible to achieve a resolution higher than that dictated by the length of the signal.
To improve visualization of the spectrum, we can artiﬁcially increase the length of the signal by a
suitable extension of the ﬁnite-length record beyond the measurement period. A standard approach
is to pad x[k] with (N −L) zeros (distributed evenly towards the start and end of the signal) prior
to taking the DFT. However, this should be done with great caution and its consequences should be
understood very well. Introduction of zeros at the boundaries of the signal amounts to introducing
discontinuities at those points, which has its repercussions in the overall spectrum (Proakis and
Manolakis, 2005). A key point to note is that by choosing N ′ > N, no new information is generated,
but only provides an improved visualization of the DFT. In other words, the padding of (N −L)
zeros does not provide any new information about the spectrum but only provides a better display.
In passing, it is remarked that it is a good practice to remove the DC component of the signal
(average of the series) and any polynomial trends prior to computing its DFT.

Estimation of Signal Properties
445
16.5.4
ESTIMATION OF SPECTRA FOR STOCHASTIC SIGNALS
At the outset, it is useful to recall the deﬁnitions of power spectral density of a random signal v[k]
from Chapter 11.
γvv(ω) = lim
N→∞E(γ(i,N)
vv
(ω)) = lim
N→∞E
 |VN (ω)|2
2πN
!
(From Signal)
(16.65)
γvv(ω) = 1
2π
∞
X
l=−∞
σvv[l]e−jωl
(From ACVF)
(16.66)
γvv(ω) = |H(e−jω)|2γee(ω) = |H(e−jω)|2 σ2
e
2π
(From Model)
(16.67)
Non-parametric methods make use of the ﬁrst two deﬁnitions, while the parametric methods rely on
the last one.
16.5.5
PERIODOGRAM ESTIMATOR
The periodogram estimator was one of the ﬁrst to be proposed for the estimation of p.s.d. of
stochastic signals, when originally it was used for estimation of periodicities by Schuster (1897).
As remarked earlier, it was discovered that the estimator lacked a critical property, that of consis-
tency. Subsequently, several estimators were proposed, all based on certain modiﬁcations of the
periodogram. Therefore, it is important to study the properties of periodogram in detail.
The main basis for using the periodogram as an estimator is that a ﬁnite-length record vN of a
stochastic signal v[k] is square-summable and therefore a Fourier transform exists. Thus, we have
ˆγvv(ωn) = Pvv(ωn) =
1
2πN |VN (ωn)|2
(16.68)
where VN is the DFT of vN.
In order to obtain clearer insights into the properties of periodogram, it is useful to express it in the
form (16.66) based on ACVF. Starting with (16.68) and invoking the estimator of ACVF in (16.40),
the periodogram can also be shown as the Fourier transform of the estimated ACVF (see Exercise
E16.7)
ˆγvv(ωn) = Pvv(ωn) = 1
2π
N−1
X
l=−(N−1)
ˆσvv[l]e−jωnl
(16.69)
bringing it directly in line with (16.66).
Remarks:
Equation (16.69) also oﬀers a computationally eﬃcient way of estimating the ACVF of a given
sequence. The eﬃciency stems from the highly optimized FFT algorithm. First compute the periodogram using
(16.49) and then inverse FFT to obtain an estimate of σvv[l].
16.5.5.1
Properties of Periodogram as a PSD Estimator for Stochastic Signals
i. Bias: The periodogram in (16.68) (or (16.69)) is a biased estimator of the spectral density. This
is to be expected since the ˆσyy[l] in (16.69) is itself a biased estimator of the ACVF.
E(Pvv(ωn)) = 1
2π
N−1
X
l=−(N−1)
E( ˆσyy[l])e−jωnl = 1
2π
N−1
X
l=−(N−1)
 N −|l|
N
!
σyy[l]e−jωnl
(16.70)

446
Principles of System Identiﬁcation: Theory and Practice
To realize the bias in the estimate, introduce the sequence
a[l] =

1 −|l|
N ,
|l| ≤(N −1)
0,
otherwise
(16.71)
Then, (16.69) can be re-written as
Pvv(ωn) = 1
2π
∞
X
l=−∞)
a[l]σyy[l]e−jωnl = 1
2π
Z π
−π
A(ωn)γvv(ωn −λ) dλ
(16.72)
where
A(ω) = F{a[l]} = 1
N
 sin(Nω/2)
sin(ω/2)
!2
(16.73)
is the Fejer kernel. The last identity in (16.72) comes about by recognizing that the summation is
a DTFT of the product of a[l] and σyy[l]/(2π). From (10.48), we know that Fourier transform
of a product is convolution in frequency. Convolution (in any domain) introduces distortions as
we know from Chapter 4.
Thus, the periodogram is a biased version of the spectral density γvv(ω).
E(P(ωn)) , γ(ωn)
(16.74)
Remarks:
a. Spectral leakage is another manifestation of the bias. For deterministic signals, leakage vanishes when
the signal completes integer cycles in the data record. However, for random signals, the bias vanishes
whenever v[k] is WN, for which σvv[l] = 0, ∀l , 0.
b. Theoretically, the bias is zero whenever A(.) has perfect localization in frequency, i.e., A(ω) = δ(ω).
From (16.73), this can never be true for ﬁnite N. The multi-taper method (to be discussed shortly)
imposes a constraint of this nature to reduce the bias.
c. The bias in the periodogram can also be reduced by windowing the signal prior to applying the DFT.
Estimators of this type are known as modiﬁed periodogram estimators. However, they too suﬀer from
lack of consistency like the raw periodogram.
d. From the result in (16.72), it is tempting to replace the biased estimator of the ACVF with the unbiased
version (that has a factor of 1/(N −|l|) in the denominator), but it leads to the possibility of obtaining
negative-valued spectral estimates (see Exercise E16.8), which is not acceptable. On the other hand,
the biased estimator of ACVF is always guaranteed to produce non-negative spectral estimates since
A(λ) ≥0, ∀λ from (16.73).
ii. Asymptotic bias: In the limiting case N →∞, the convolving function A(ω) tends to an impulse
lim
N→∞A(ω) = 2πδ(ωn)
(16.75)
Applying this to (16.72), we see that
lim
N→∞E(Pvv(ω)) = γvv(ω)
(16.76)
Note: The foregoing fact can also be directly inferred by comparing the deﬁnitions of the estimator in
(16.49) with the deﬁnition of p.s.d. in (16.65).
iii. Variance: Arriving at the expression for variance of a periodogram is quite tedious in general,
but somewhat simpliﬁed for Gaussian random signals. For GWN processes, the result is that

Estimation of Signal Properties
447
(Priestley, 1981; Proakis and Manolakis, 2005):
var(Pvv(ωn)) = γ2
vv(ωn)

1 +
 sin(ωN)
N sin ω
!2
=⇒lim
N→∞var(Pvv(ωn)) = γ2
vv(ωn)
(16.77)
The foregoing result also approximately holds for correlated processes.
The variance expression in (16.77) should be rightly interpreted. It is a measure of how the esti-
mates of p.s.d. are dispersed at each frequency over all experimental records and not the variation
in estimates across frequencies. See Figure 16.8 and the associated explanation in Example 16.6.
iv. Consistency: From (16.77) it is evident that the periodogram is not a consistent estimator of
the power spectral density γ(ω). Increasing the number of samples does not decrease the variance
or the error in the estimates. Three diﬀerent explanations are usually oﬀered to explain the lack of
consistency (see §16.5.6). An excellent exposition of this topic is given by Priestley (1981). It is
argued that the main reason for the inconsistency of the periodogram despite being derived from
a consistent ACVF estimator is that when N sample ACVFs with variance O(1/N) are added
up, the result is a quantity with variance O(1). The averaged and the smoothed periodogram
methods, as we shall soon learn, address this concern suitably well.
v. Distribution: Suppose that v[k] is a zero-mean GWN, v[k] = e[k], e[k] ∼N (0,σ2
e).
From (11.35), γvv(ω) = σ2
e/(2π). Assume N is even for the purpose of discussion5.
The DFT of the ﬁnite-length realization vN at each frequency, VN (ω), also has a complex-
valued Gaussian distribution. To establish the sampling distribution of ˆγ(ωn), we ﬁrst examine
|VN (ωn)|2.
VN (ωn) =
N−1
X
k=0
y[k]e−jkωn =
N−1
X
k=0
v[k] cos(kωn)
|                  {z                  }
VN,c (ωn)
+j
N−1
X
k=0
v[k] sin(kωn)
|                 {z                 }
VN,s (ωn)
=⇒1
N |VN (ωn)|2 = 1
N V 2
N,c(ωn) + 1
N V 2
N,s(ωn)
Thus, ˆγvv(ωn) is a sum of two squared (normalized) Gaussian random variables. Now, it is easy
to establish under v[k] = e[k] that,
var(YN,c(ωn)/
√
N) = σ2
e
N
N−1
X
k=0
cos2(kωn) =

σ2
e/2,
ωn = 2πn/N, n , 0, N/2
σ2
e,
ωn = 0,π
(16.78a)
var(YN,s(ωn)/
√
N) = σ2
e
N
N−1
X
k=0
sin2(kωn) =

σ2
e/2,
ωn = 2πn/N, n , 0, N/2
σ2
e,
ωn = 0,π
(16.78b)
In writing the above relations, we have made use of certain trigonometric identities concerning
the products of cosines and sines.
Thus,
VN,c(ωn)/
√
N ∼

N (0,σ2
e/2),
ωn = 2πn/N, n , 0, N/2
N (0,σ2
e),
ωn = 0,π
(16.79)
VN,s(ωn)/
√
N ∼

N (0,σ2
e/2),
ωn = 2πn/N, n , 0, N/2
N (0,σ2
e),
ωn = 0,π
(16.80)
5Results are valid for odd N as well.

448
Principles of System Identiﬁcation: Theory and Practice
The distinction for ωn = 0,π occurs because VN,s(.) = 0 at these frequencies. Further,
cov(VN,c(ωn),VN,c(ωm)) = 0 = cov(VN,s(ωn),VN,s(ωm))
m , n
(16.81)
cov(VN,c(ωn),VN,s(ωm)) = 0
∀m,n
(16.82)
Therefore, 2 ˆγvv(ωn)/(σ2
e/(2π)) is a sum of two squared uncorrelated Gaussian variables with
N (0,1). The formal result on the distribution of ˆγvv(ωn) thus follows.
Theorem 16.3
If e[k] is a zero-mean GWN (independent process) and variance σ2
e, then the spectral density
(periodogram) estimates ˆγ(ωn) = P(ωn), ωn = 2πn/N, n = 0,1,· · · ,[N/2] are independently
distributed with, for each n,
2Pvv(ωn)
σ2e/(2π) ∼χ2(2)
n = 1,· · · , ⌊N −1
2
⌋
(16.83)
∼2χ2(1)
n = 0, N
2 (N even only)
(16.84)
Further, the mean and variance of the estimates are
E(P(ωn)) = σ2
e
2π = γee(ωn),
∀n = 0,1,· · · ,[N/2]
(16.85)
var(P(ωn)) =

 σ2
e
2π
!2
= γ2
ee(ωn),
n = 1,· · · , ⌊N−1
2 ⌋
2
 σ2
e
2π
!2
= 2γ2
ee(ωn),
n = 0, N
2 (N even only)
(16.86)
Finally, the periodogram estimates at two frequencies P(ωm), P(ωn), m , n are independent
(uncorrelated).
Proof. The result on distribution follows by ﬁrst observing that
2
σ2e
2πPvv(ωn) = 2
σ2e
*
,
Y 2
N,c(ωn)
N
+
Y 2
N,c(ωn)
N
+
-
and then using (16.80).
The mean and variance of Pvv(ωn) follows from the properties of a random variable Z with
χ2(ν) distribution, E(Z) = ν and var(Z) = 2ν.
Finally, the independence of estimates at two distinct frequencies result is a consequence of the
independence of (16.82).
□
Theorem 16.3 conﬁrms our previous ﬁndings with regards to the mean and variance of the
periodogram-based density estimates of a GWN process.
A numerical example on a zero-mean unit variance GWN is used to illustrate the implications of
Theorem 16.3.
Example 16.6: Distribution and Inconsistency of the Periodogram: GWN
It is desired to estimate the p.s.d. of a (zero-mean, unit-variance) GWN using a data set
containing N = 250 observations of the process. The periodogram is computed according
to (16.49).

Estimation of Signal Properties
449
A plot of the two-sided periodogram is shown in the top-left panel of Figure 16.8. Theo-
retically the WN has a ﬂat spectral density according to (11.35). The estimates, however,
ﬂuctuate randomly (erratically) around this true value. Increasing the sample size to
0
1
2
3
0.2
0.4
0.6
0.8
Single realization: N = 250
ω
PSD
0
1
2
3
0.2
0.4
0.6
0.8
1
1.2
Single realization: N = 2000
ω
PSD
0
1
2
3
0.1
0.15
0.2
ω
PSD
 
 
0
1
2
3
0.1
0.15
0.2
ω
PSD
 
 
0
5
10
15
20
0
200
400
600
800
PSD(ω=0)
Count
0
5
10
15
20
0
200
400
600
800
PSD(ω=0.4π)
Count
Averaged
True
Averaged
True
FIGURE 16.8
(SEE COLOR INSERT) (Top panel) Periodograms from a single realization with N = 250
and N = 2000 observations; (Middle panel) Averaged periodograms from 1000 realizations; (Bottom panel)
Distribution of ˆγ(0)/γ(0) and 2 ˆγ(0.4π)/γ(0.4π) obtained from 1000 realizations.
N = 2000 has no visible eﬀect on the ﬂuctuations as observed in the top-right panel. It
only increases the resolution △ω. Averaging the estimates across 2000 realizations for each
of these cases tremendously improves the estimate, as evident from the reduced ﬂuctu-
ations in the middle panels of Figure 16.8. Observe that averaging with N = 2000 only
results in increased resolution (recall △ω = 2π) but does not bring about any reduction
in the ﬂuctuations. In all the four panels, the dashed line shows the true PSD, which is
γ(ω) = 1/(2π) = 0.1592 units.
The distribution of the normalized estimates, ˆγ(0)/γ(0) at ω0 = 0 and 2 ˆγ(0.4π)/γ(0.4π)
at ω0 = 0.8π are shown in the bottom row panels of the ﬁgure. The histograms are in
accordance with the results dictated by Theorem 16.3. To conﬁrm that these estimates
indeed follow a chi-square distribution with the 1-d.o.f. and 2-do.f., respectively, a gamma
distribution (since a χ2(ν) is a special case of the Γ(a,b) distribution with a = ν/2 and
b = 2) was ﬁt to these estimates.
The estimated parameters of the Γ(a,b) distribution were
ω0
ˆa
ˆb
ˆ
var( ˆγ(.))
0
0.495
2.142
0.0571
0.4π
0.962
2.148
0.0288
in close agreement with the theoretical expectations a(0) = 0.5,b(0) = 2,var( ˆγ(0)) = 0.0507
and a(0.4π) = 1,b(0.4π) = 2,var( ˆγ(0.4π)) = 0.0253, respectively.
Finally, the correlation coeﬃcient between the PSD estimates at two diﬀerent frequencies
ω1 = 0.15π and ω2 = 0.4π is found to be 0.015, a negligibly low value, conﬁrming the third
assertion of Theorem 16.3.

450
Principles of System Identiﬁcation: Theory and Practice
Listing 16.8
MATLAB code for Example 16.6
% Generate realizations and their psds
Nreal = 1000; Nobs2 = 2000; Nobs1 = Nobs2/8;
vk_psd1 = zeros(Nobs1/2,Nreal);
vk_psd2 = zeros(Nobs2/2,Nreal);
for i = 1:Nreal
vk = randn(Nobs2 ,1);
[t_psd1,wvec1] = periodogram(vk(1:Nobs1),rectwin(Nobs1),Nobs1,’twosided’...
);
[t_psd2,wvec2] = periodogram(vk,rectwin(Nobs2),Nobs2,’twosided’);
vk_psd1(:,i) = t_psd1(1:end/2);
vk_psd2(:,i) = t_psd2(1:end/2);
end
% Plot the results
true_psd = 1/(2*pi);
figure
h1 = subplot(321);
plot(h1,wvec1(1:end/2),vk_psd1(:,34)); hold on
plot([wvec1(1) wvec1(end/2)],[1 1]/(2*pi),’r--’,’linewidth’,2);
h2 = subplot(322);
plot(h2,wvec2(1:end/2),vk_psd2(:,34)); hold on
plot([wvec2(1) wvec2(end/2)],[1 1]/(2*pi),’r--’,’linewidth’,2);
h3 = subplot(323);
plot(h3,wvec1(1:end/2),mean(vk_psd1 ,2)); hold on
plot([wvec1(1) wvec1(end/2)],[1 1]/(2*pi),’r--’,’linewidth’,2);
axis tight
set(gca,’ylim’,[0.1 0.2])
h4 = subplot(324);
plot(h4,wvec2(1:end/2),mean(vk_psd2 ,2)); hold on
plot([wvec2(1) wvec2(end/2)],[1 1]/(2*pi),’r--’,’linewidth’,2);
% Plot distributions of PSD estimates
h5 = subplot(325);
psdhat0 = vk_psd2(1,:)/true_psd;
hist(h5,psdhat0)
h6 = subplot(326);
psdhat1 = 2*vk_psd2(401,:)/true_psd;
hist(h6,psdhat1)
% Fit chi-square distributions to two select estimates
psdfit0 = fitdist(psdhat0 ’,’gamma’)
psdfit1 = fitdist(psdhat1 ’,’gamma’)
The results of Theorem 16.3 can be extended to a general linear stationary process
v[k] =
∞
X
j=−∞
h[j]w[k −j]
satisfying:
i. IID driving source: w[k] ∼i.i.d.(0,σ2
w)
ii. Stationarity:
∞
X
j=−∞
|h[j]| < ∞
iii. Rapidly decaying ACVF:
∞
X
l=−∞
l|σvv[l]| < ∞
using the central limit theorem (Brockwell and Davis, 1991; Shumway and Stoﬀer, 2006). Fur-
ther the periodogram can be evaluated on any set of distinct frequencies, n = m/N provided that

Estimation of Signal Properties
451
ωn is closest to a frequency of interest ω0. In other words, ω0 is not necessarily on the regular
DFT frequency grid but is closest to one of the grid points such that as N →∞, ωn →ω0.
For a general linear stationary process with i.i.d. driving source and rapidly decaying ACVF,
the following asymptotic results hold:
a.
lim
N→∞E(P(ωn)) = γ(ω0)
b. 2P(ωn)
γ(ω0)
d→χ2(2)
c. The approximate 100(1 −α)% conﬁdence intervals for γ(ω0) are
2 P(ωn)
χ2
α
2 (2) < γ(ω0) < 2 P(ωn)
χ2
1−α
2 (2)
(16.87)
d. Estimates at two diﬀerent frequencies are independent.
Now, we turn our attention to ﬁnding remedies that address the primary weakness of the peri-
odogram estimator.
16.5.6
AVERAGED (SMOOTHED) PERIODOGRAM ESTIMATORS
It is clear from the previous section that the periodogram as an estimator of the p.s.d. of stochastic
signals has certain nice properties, except for one crucial drawback, which is that of lack of consis-
tency. Several methods have been developed to induce consistency into the periodogram estimator
by suitable modiﬁcations. The diﬀerences in these methods are primarily in the way they view the
root-cause of inconsistency6.
As mentioned earlier, three viewpoints are usually oﬀered to explain the lack of consistency in
the periodogram:
i. Deﬁnition (16.65) demands averaging across realizations in addition to having large samples. The
periodogram estimator (16.49), however, does not involve any ensemble averaging and therefore
lacks the desired property. Averaged periodogram estimators due to Bartlett and Welch take this
perspective.
ii. From the perspective of the ACVF-based deﬁnition in (16.66) requires inclusion of ACVF across
the entire lag domain. However, the periodogram includes lags only in the range |l| ≥(N −1)
as evident from (16.69). The Blackman-Tukey and the maximum entropy methods oﬀer remedies
based on these standpoints.
iii. A third viewpoint is that the periodogram ﬂuctuates wildly across frequencies (estimates at two
frequencies are uncorrelated with each other) whereas the true spectral density is a smooth one.
The smoothness of the underlying density is not incorporated into the estimator and hence the
result. The Daniell smoother takes this stance.
Remarks:
In this respect, an excellent observation made by Priestley (1981) merits mention. Originally,
the periodogram was devised to estimate spectra of periodic signals, which only possess line (discrete)
spectra. Its adaptation to estimating spectral densities (continuous spectra) should naturally lead to some
diﬃculties. Thus, the standard criticism of lack of consistency requires a much fairer consideration. Fur-
thermore, this line of observation also conﬁrms the need for incorporating the smoothness requirement into
the periodogram-based estimator. Traditionally this has been implemented as a post-operative step, i.e., ﬁrst
compute the periodogram “as is” and follow it up with a smoothing operation.
6Note that we do not use the term modiﬁed periodogram, but rather we use averaged periodogram because the former is
usually reserved to denote methods that merely taper or window the data prior to the computation of periodogram.

452
Principles of System Identiﬁcation: Theory and Practice
Historical developments
Consequent to the aforementioned developments and facts, smoothing the periodogram (averaging
the PSD estimates over a band of frequencies) was one of the ﬁrst remedies to come to the forefront.
Largely popularized as Daniell’s smoother (Daniell, 1946), it is also believed to have been con-
ceived much earlier by Einstein (see Bloomﬁeld (2000)). In due course of time, Blackman-Tukey
(Blackman and Tukey, 1959) reasoned the use of truncated ACVF in (16.69) as the main factor
and proposed the use of a windowed or lagged estimated ACVF. The idea was to have a tapered
or smoothed ACVF rather than a truncated version. This approach oﬀered certain computational
advantages over the smoothed periodogram methods.
Somewhat contemporaneously, there emerged another set of methods which took the viewpoint
of ensemble-averaged deﬁnition (16.65) and proposed segmentation of data (dividing the data into
smaller chunks) to generate artiﬁcial realizations. These works were largely due to Bartlett (1948)
and Welch (1967), the latter’s method being one of the most popular methods today. An added ben-
eﬁt is that the segmentation step also facilitates computational eﬃciency. The works in the decades
to follow witnessed emergence of other sophisticated techniques, some specializing to a class of
signals. Notable among these is the multi-tapering method (MTM) due to Thomson (1982).
It is worthwhile pointing out that despite the diﬀerences in the underlying philosophies of the
above-mentioned approaches, eﬀectively all methods aim to directly or indirectly improve the de-
grees of freedom. Recall from Theorem 16.3 that the raw periodogram has only 2 degrees of free-
dom. Smoothed periodogram method of Daniell, for example, increases the equivalent or eﬀective
d.o.f. (EDOF) (Emery and Thomson, 2004; Priestley, 1981) by a factor of L when L frequencies are
averaged to produce the smoothed estimate. Similarly Bartlett’s method of averaging periodograms
of K data segments increases the EDOF by a factor of K and so on. The increase in EDOF brings
about a decrease in variance of the estimates. Of course, a price has to be paid and that is the loss in
frequency resolution △F. For instance, segmenting the data of length N into K segments of L data
points each reduces the frequency resolution by a factor of K.
A useful way of viewing these methods is to put each of them into the perspective of bias and
variance trade-oﬀ. The periodogram is biased, but asymptotically goes to zero and has a variance that
does not shrink to zero as N →∞. On the other hand, the modiﬁed / smoothed estimators decrease
the variance but at the expense of increasing the bias. The asymptotic bias, nevertheless, still goes to
zero. The following sections present the algorithmic details of each of the aforementioned methods.
Daniell Smoother
Basic idea: At each frequency ωi, estimate the true density by smoothing the periodogram ˆγ(.) in
the vicinity of ωi.
The underlying philosophy is that the true p.s.d. is constant over a small band of frequencies. In
the case of WN, as in Example 16.6, the true p.s.d. γee(ω) is constant throughout.
The approach is reminiscent of estimating a constant from measurements, which in this case, are
the raw periodogram estimates ˆγvv[n] (or P(ωn)). The OLS estimate of the constant is the simple
average. For the more practical case where γ(ω) is non-constant (over the small band), a weighted
average is employed. The Daniell’s method belongs to the category of frequency-averaging methods.
Assuming that the spectral density is constant over a band of L = 2M + 1 frequencies (bandwidth
of Bw ≃L/N), the optimal estimate is the simple average,
ˆγD
vv(ωn) = 1
L
M
X
m=−M
Pvv(ωn −ωm) = 1
L
M
X
m=−M
Pvv[n −m]
(16.88)
Asymptotic properties of the smoothed periodogram can be theoretically constructed under two
important assumptions (Shumway and Stoﬀer, 2006), namely, (i) the bandwidth B is small, i.e.,

Estimation of Signal Properties
453
L ≪N and (ii) the underlying spectral density is roughly constant over this bandwidth. The key
large sample properties are:
i. E( ˆγD(ωn)) ≈γ(ωn)
(asymptotically unbiased)
ii. var( ˆγD(ωn)) ≈1
L γ2(ωn)
(consistency)
iii. cov( ˆγD(ωn), ˆγD(ωm) ≈

L −|n −m|
L2
γD(ωn)γD(ωm),
|n −m| ≤L
0,
otherwise
(smoothness within the bandwidth)
iv. 2L ˆγD(ωn)
γ(ωn) ∼χ2(2L)
(increase in d.o.f.)
The decrease in variance comes at the price of increase in bias due to ﬂattening of the spectral
density, as remarked earlier. The loss in bias is reﬂected in the smearing of any pure-tone or very
narrowband spectra. Larger bandwidth results in estimates with lower error but with a larger bias.
The last property mentioned above is useful in constructing conﬁdence intervals for the spectral
density.
The foregoing ideas can be generalized to the weighted-averaged smoother.
ˆγD
vv(ωn) =
M
X
m=−M
W(ωm)Pvv(ωn −ωm) =
M
X
m=−M
W[m]Pvv[n −m]
s.t.
X
m
W[m] = 1 (16.89)
The window has to satisfy the requirements of being symmetric, non-increasing and unity sum
of coeﬃcients. The asymptotic properties of the simple-averaged estimator apply to the modiﬁed
Daniell smoother as well, provided M, N →∞but M/N →0 (data length increases at a faster
rate than the window width) (Shumway and Stoﬀer, 2006). Furthermore two minor diﬀerences arise
w.r.t. the distributional properties of the estimate as listed below.
Deﬁning LM = *
,
M
X
m=−M
W2[m]+
-
−1
, we have
i. Variance:
L−1
Mcov( ˆγD(ωn), ˆγD(ωm)) =

γ2(ω),
ωn = ωm = ω , 0,1/2
2γ2(ω),
ωn = ωm = 0,1/2
0,
|n −m| > L
(16.90a)
ii. Distribution:
2LM ˆγD(ω)
γ(ω)
∼As χ2(2LM)
(16.90b)
It is easy to verify that the distribution simpliﬁes to that for the simple averaged smoother since then
Wm = 1/(2M + 1), ∀m implying LM = 2M + 1 = L. The bandwidth of the spectral window, i.e.,
the band of frequencies over which the window shapes the periodogram can be deﬁned as
Bw = LM
N
(16.91)
Thus, the Daniell smoother has ν = 2NBw degrees of freedom.
There exist diﬀerent ways of choosing the weights. The modifed Daniell-kernel places half
weights at the end points, while the remaining are distributed uniformly. For example, when M = 1,
the weights are
W[1] = 1
4 = W[3];
W[2] = 1
2
(16.92)

454
Principles of System Identiﬁcation: Theory and Practice
The modiﬁed Daniell-kernel has less spectral leakage compared to the regular rectangular kernel
(simple averaging). Alternatively, a weighted average can be formed by applying the kernel repeat-
edly to obtain smoother estimates. Expectantly, this is equivalent to smoothing the raw periodogram
with a single ﬁlter that results from the convolution of the individual kernels (Bloomﬁeld, 2000;
Shumway and Stoﬀer, 2006).
The length of the window L = 2M + 1 is usually chosen such that L ≪N/2. The exact choice
of L and the number of repetitions of smoothing (in weighted average Daniell-kernel) naturally
depends on the application. The guiding light is that one should produce a good trade-oﬀbetween
smoothing of narrow peaks (good resolution of sinusoidal frequencies) and smoothness of the noisy
component.
Algorithm 16.1
Estimation of p.s.d. using Daniell’s smoothed periodogram
1. Mean-center the given series vN
2. Compute the raw periodogram of the mean-centered series according to (16.49)
3. Obtain the estimate of the p.s.d. by either a simple or weighted running average of the resulting
periodogram using (16.88)
In closing, we make an important observation that connects the upcoming discussion on the
Blackman-Tukey method. The smoothed averaging in (16.89) is a (discrete-time) convolution op-
eration between the smoothing window and the periodogram. Therefore, it should correspond to a
product of the time-domain counterparts of the smoothing window and the periodogram, respec-
tively.
Blackman-Tukey method
Baisc idea: Window the sample ACVF before applying the Fourier transform in (16.69) (Blackman
and Tukey, 1959).
The method takes the viewpoint of deﬁnition (16.69). It attributes the poor performance of the
periodogram due to large errors in the estimates of ACVF at large lags. For instance, only a single
sample is available to obtain ˆσvv[l] at lag |l| = (N −1). Therefore, it is meaningful to give low
importance or even disregard estimates at larger lags.
Formally the idea is implemented by weighing or windowing the ACVF in (16.69)
ˆγ(BT)
vv
(ωn) = 1
2π
N−1
X
l=−(N−1)
w[l]ˆσvv[l]e−ωnl
(16.93)
where w[l] is the window function studied in §16.5.3. The window function equips the user with
the ﬂexibility to not only disregard or give more importance to estimates at smaller lags, but also to
place emphasis on lags that are of interest in a given application.
In spectral estimation literature, w[k] is also known as the lag window and the B-T estimator
as the lag window spectral estimator (Percival and Walden, 1993). The lag window is the inverse
Fourier transform of the smoothing window used in Daniell smoothers, as shown below7. This fact
is recognized by observing
ˆγ(BT )(ω) =
N−1
X
l=−(N−1)
w[l]ˆσvv[l]e−ωnl =
Z π
−π
P(ξ)W(ω −ξ) dξ
(16.94)
7The lag window in (16.93) is not exactly the IDFT of W (ωn) in (16.89), but truncated to zero outside the interval
|l | > M. See Percival and Walden (1993, p. 237-238).

Estimation of Signal Properties
455
where W(.) is the Fourier transform of the lag window w[l]
W(ω) =
M
X
l=−M
w[l]e−j2πlω
and P(.) is the periodogram estimate.
The r.h.s. of (16.94) is a continuous version of the Daniell smoother in (16.89). It implies that the
B-T estimate essentially smooths the periodogram (in the frequency domain), essentially conﬁrming
our observation at the close of the previous section, i.e., the B-T estimator is equivalent (and at times
identical to) the Daniell smoother (see Percival and Walden (1993) for a rigorous proof). While the
former modiﬁes the (estimated) ACVF prior to transformation, the latter operates on the spectral
density obtained from the raw ACVF estimate. The conditions that have to be met by the window
function are also similar in both estimators as seen below.
In practice, window functions that are zero outside an interval 2M + 1, M ≪N are used. The
result is that the estimated ACVF is zeroed for all lags |l| > M and possibly tapered inside the
interval |l| ≤M.
The lag window w[l] is required to satisfy a set of conditions for the power spectral estimate to
be real and non-negative valued (Djuric and Kay, 1999; Percival and Walden, 1993).
C1. Symmetric: w[−l] = w[l]. This is necessary for obtaining real-valued p.s.d. estimate.
C2. Non-increasing with |l|: 0 ≤w[l] ≤w[0].
C3. Unity at center: w[0] = 1. From its relationship to the smoothing window, this is akin to the unity
sum requirement on W(ω) stated in (16.89).
C4. Non-negative DTFT: W(ω) ≥0, |ω| ≤π.
The fourth requirement is only a suﬃcient, but not a necessary condition. It stems from (16.94)
and the requirement that ˆγ(BT)(ω) ≥0. Violation of this condition does not necessarily result in a
negative power spectral density.
A rectangular window, for example,
wR[l] =

1,
|l| ≤M
0,
|l| > M
(16.95)
satisﬁes all the three conditions but violates the fourth one.
On the other hand, a Bartlett (triangular) window
wB[l] =

1 −|l|
M ,
|l| ≤M,
0,
otherwise
(16.96)
satisﬁes all the four requirements.
The equivalence also implies that a ﬁnite-window B-T estimator does not have a ﬁnite-window
Daniell smoother owing to the duration-bandwidth principle of Fourier transforms (recall (10.24)).
Finite-duration windows have asymptotically decaying Fourier transforms, speciﬁcally, the sinc
functions. Table 16.2 lists some of the popular lag windows and their smoothed window coun-
terparts.
With the equivalence, one should expect the asymptotic properties of the B-T estimator to be
similar to those of the Daniell smoother. Independent derivations of the asymptotic properties of the
B-T estimator are presented in several classical signal processing texts (see Proakis and Manolakis
(2005) for example).

456
Principles of System Identiﬁcation: Theory and Practice
For a generic lag window w[m], deﬁne as in the case of Daniell smoother, a measure of bandwidth
(Percival and Walden, 1993),
˜Bw = *
,
M
X
m=−M
w2[m]+
-
−1
(16.97)
Then, under the conditions M →∞as N →∞and M/N →0, we have the following:
i. Asymptotically unbiased estimator,
E( ˆγ(BT)(ω)) ≈γ(ω)
(16.98)
ii. Variance of the estimator ∝1/N,
cov( ˆγBT(ωn), ˆγnD(ωp)) =

γ2(ω)
N ˜Bw
,
ωn = ωp = ω , 0,1/2
2γ2(ω)
N ˜Bw
,
ωn = ωp = 0,1/2
0,
|n −p| > L
iii. The B-T estimates are asymptotically distributed (under the conditions on M and N stated above)
in the same way as Daniell smoothed estimates.
ν ˆγ(BT)(ω)
γ(ω)
∼As χ2(ν)
(16.99a)
where ν = 2N/ *
,
M
X
m=−M
w2[m]+
-
= 2N ˜Bw
(16.99b)
It is instructive to compare the properties of the B-T estimator with those of the Daniell smoother
in (16.90).
The B-T estimator is consistent under the above-said conditions since as N →∞, the variance
shrinks to zero and it is asymptotically unbiased. Variance expressions for use with some pop-
ular windows are listed in Table 16.2. A more inclusive list is available in classical texts on time-
series analysis (Brockwell and Davis (1991), Percival and Walden (1993), and Shumway and Stoﬀer
(2006) are good references for this purpose.).
Regardless of the nature of the window, the eﬀect of M is on the resolution of estimator. The
exact resolution, however, depends on the nature of the window used. With a rectangular win-
dow, the frequency resolution is △ω = 2π/2M whereas the Bartlett window yields eﬀectively
△f = 2π(1.28)/2M. Thus, as M decreases, the variance is lowered but the resolution is wors-
ened. Therefore, a trade-oﬀis involved. See Percival and Walden (1993, Chapter 6) for an excellent
set of guidelines on the choice of windows and their parameters, and their impact on the spectral
estimates.
Algorithm 16.2
Estimation of auto-spectral density using Blackman-Tukey method
1. Estimate ACVF of the process from the given series vN using (16.40).
2. Apply a suitable lag window to the estimated ACVF sequence. The chosen window function should
satisfy the conditions (C1.)-(C4.).
3. Estimate the p.s.d. by computing the FFT of the windowed ACVF as in (16.93).

Estimation of Signal Properties
457
Bartlett’s method
Basic idea: Divide the data record of length N into K non-overlapping segments of length L, i.e.,
N = KL, and take the simple average of the periodograms estimates from these K segments.
ˆγB(ωn) = 1
K
K
X
i=1
P(i)(ωn)
(16.100)
where P(i)(ω) is the periodogram estimate in the ith segment.
The segmentation is motivated by the need for generating artiﬁcial realizations keeping in view
the requirement of the p.s.d. deﬁnition in (11.2).
It is straightforward to show that the variance is reduced by a factor of K for white-noise sequences
(see Exercise E16.11). The reduction comes at the cost of decrease in frequency resolution from
△f = 1/N to △f = 1/L.
Welch’s averaged modiﬁed periodogram
Basic idea: Same as that of Bartlett’s approach, but with two changes: (i) taper the segmented data
(to improve the basic periodogram estimate) and (ii) allow overlapping of segments (to increase the
degrees of freedom).
The estimate is still computed as a simple average as in (16.100).
ˆγW (ωn) = 1
K
K
X
i=1
ˆγ(i)(ωn)
(16.101)
where ˆγ(i)(ωn) is the modiﬁed periodogram estimate of the ith segment,
ˆγ(i)(ωn) = PSD(w[k]v(i)[k]) =
1
CwL

L−1
X
k=0
w[k]v(i)[k]e−jωnk

2
(16.102)
where C is a normalization factor to account for loss in power that occurs due to tapering
Cw = 1
L
L−1
X
k=0
w2[k]
(16.103)
The number of segments obtained with an overlap of O samples is K = (N −O)/(L −O). Welch’s
method is also known as weighted overlapped-segmented averaging or the Welch’s overlapped seg-
mented averaging method, both abbreviated by WOSA. The Bartlett and WOSA estimators belong
to the category of ensemble averaging methods because they work with averages across (artiﬁcially
generated) realizations.
Overlapping of segments provides two advantages over Bartlett method: (i) for a ﬁxed length L,
more segments can be obtained, (ii) for a ﬁxed number of segments K, we can have longer segments.
Thus, one can achieve both reduction in variance and increased resolution compared to Bartlett’s
method, depending on the extent of overlap. In principle, O can take on values between 0 (Bartlett
method) to (L −1). Welch (1967) recommends a 50% overlap, O = L/2, for which K = 2N/L −1.
With these choices for segmentation and a Bartlett’s window for tapering the data in each segment
and starting with the modiﬁed power spectral density expression due to windowing (16.63), the
variance of the estimator can be asymptotically derived as (Proakis and Manolakis, 2005; Welch,
1967)
var( ˆγW(ωn)) ≃9
8K γ2(ωn) = 16N
9L γ2(ωn)
(16.104)

458
Principles of System Identiﬁcation: Theory and Practice
For a ﬁxed segment length, overlapping results in roughly twice as the number of segments with
Bartlett’s non-overlapping method (exactly 2K −1). Unlike in the Bartlett approach, the reduction
in variance is not proportional to the number of segments due to the overlap, which causes each
successive segment to be correlated with the previous one. Therefore, the variance reduction is
approximately 9/16 of that of Bartlett’s method. For results with other window types, see Percival
and Walden (1993) and Welch (1967).
A step-wise procedure for implementing the WOSA estimator is given below. Computational as-
pects of the estimation methods discussed above are nicely elucidated in Bendat and Piersol (2010).
Algorithm 16.3
Estimation of auto-spectral density using Welch’s averaged periodogram
1. Divide the data into K segments of length L each with an overlap of O (typically 50%).
2. For each segment, perform the following:
a. Mean-center and apply a tapering window.
b. Compute the FFT at the desired resolution (typicaly △f = 1/L).
c. Compute the periodogram of each segment according to (16.102).
3. Obtain the estimate of power spectral density by averaging the modiﬁed periodogram estimates as
in (16.101).
A general guideline for choosing the window type and width is that it should achieve an acceptable
trade-oﬀbetween identifying pure tones and smoothening of noise. Too small a block size increases
the degrees of freedom thereby lowering the variance, but results in large bias and spectral leakage.
Welch in his original work recommends the use of a Welch window (similar to the Hann window)
or a Parzen window (Welch, 1967). It is further shown that the method can be computationally more
eﬃcient than the smoothed periodogram technique if the window length L <
√
N.
The WOSA estimator can be shown as equivalent to the B-T estimator with an appropriate choice
of (i) covariance estimator and the (ii) lag window function (read Stoica and Moses (2005, Chapter
2) and Bendat and Piersol (2010, p. 401)). The equivalent lag window is in fact the convolution of
the data tapering window used in the WOSA with itself.
Multiple window (multi-taper) method
Basic idea: Same as in averaged periodogram methods, but with two diﬀerences: (i) design windows
or tapers explicitly to minimize bias (spectral leakage) by solving an optimization problem and (ii)
use orthogonal windows.
Introduced by Thomson (1982), the method minimizes the spectral leakage by requiring the win-
dows to possess ﬁne localization of energy in frequency (narrow bandwidth). This is one of the main
advantages of the MTM compared to the classical averaging methods discussed above. Further, it is
naturally equipped to handle mixed spectra, i.e., both line (pure tones) and continuous (broadband
noise) spectra. The estimate is given by a similar expression as the classical methods:
ˆγ(MW)
vv
(ωn) = 1
K
K
X
i=1
ˆγ(i)
vv (ωn)
(16.105)
and the spectrum over each segment (also known as the eigenspectrum) also has a similar expres-
sion:
ˆγ(i)
vv (ωn) = 1
λi

N−1
X
k=0
x[k]wi[k]e−jωnk

2
(16.106)

Estimation of Signal Properties
459
The width and type of the window function wi[k], known as the Slepian sequence, are derived
from an optimization problem aimed at minimizing the spectral leakage as well as variance (of the
estimate). The solution turns out to be the same as that of the eigenvalue problem,
Awi = λiwi
(16.107)
where the eigenvector wi is the vectorized window and the matrix A is made up of:
ai j = sin(2πW(i −j))
i −j
(16.108)
where W is a user-supplied parameter known as the frequency half-bandwidth. The resulting win-
dows belong to a family of functions known as discrete prolate spheroidal sequences (DPSS), orig-
inally studied by Slepian and Pollak (1961). See Percival and Walden (1993, Chapters 7-8) for a
detailed derivation of these sequences and an insightful exposition of the multitaper spectral estima-
tion method.
Typical choices of W range from 1.5/N to 20/N. The exact solution and the number of tapers K
depend on W, but is limited by K = ⌊2NW⌋, owing to the duration-bandwidth principle. Once the
tapers are computed for a speciﬁed bandwidth, the spectral estimate is obtained as
ˆγvv(ωn) =
K
X
i=1
λk | ˆγvv(i)(ωn)
K
X
i=1
λk
(16.109)
An exact expression for the variance depends on the bandwidth W. However, the MT method is
known to be consistent.
Example 16.7: Estimation of Power Spectral Density of a WN Process
In order to visually demonstrate and compare the performance of the diﬀerent non-
parametric spectral estimation methods, N = 1024 samples of a zero-mean, unit-variance
GWN process are generated.
The raw periodogram and the estimates from Welch’s averaged periodogram method, B-T
weighted ACVF and the MTM with the following settings are shown in Figure 16.9.
i. Welch’s method: L = 128, O = L/2; Hann window; 256-point FFT.
ii. B-T estimator: ACVF truncated to |l| = 127, Bartlett window; 256-point FFT.
iii. Multi-tapering method: NW = 4; 256-point FFT.
The dashed line, as previously, represents the theoretical p.s.d. of a unit variance GWN: The
modiﬁed / averaged periodogram estimators oﬀer a clear improvement over the periodogram
estimator.
A visual inspection shows that the performance of the Welch and the B-T estimators are
comparable. Incidentally these estimates are better than those oﬀered by MTM. However, no
general conclusions should be drawn from this example. Any of these methods can be tuned
to perform better / worse than the other. The purpose of this example is mainly to give the
reader a feel for the improvements that each of these methods oﬀer.
The methods discussed in this section range from the raw periodogram to the sophisticated MTM.
A performance indicator known as the ﬁgure of merit, deﬁned as M = var( ˆγ(.)) × △ω is usually
charted for each of the methods discussed above. Lower the ﬁgure of merit, the better is the method.
The MTM, B-T and the Welch methods usually have some of the lowest ﬁgures of merit. A common
alternative measure of performance is the quality factor deﬁned as Q = (E( ˆγ(ω)))2/var( ˆγ(ω)) is

460
Principles of System Identiﬁcation: Theory and Practice
0
1
2
3
0.2
0.4
0.6
0.8
1
Periodogram
ω
PSD
0
1
2
3
0
0.1
0.2
0.3
0.4
0.5
Welch Method
ω
PSD
0
1
2
3
0
0.1
0.2
0.3
0.4
0.5
B−T Method
ω
PSD
0
1
2
3
0
0.1
0.2
0.3
0.4
0.5
Multi−taper Method
ω
PSD
FIGURE 16.9
Estimation of PSD of a GWN process using non-parametric methods.
also used (Proakis and Manolakis, 2005). With this measure, higher the quality factor, the better is
the estimator. The periodogram, for instance, has unity Qper = 1, while the B-T estimator has one of
the best values (minimum variance estimates), QBT = 2.34N△f where △f is the resolution of the
window measured at the 3-dB bandwidth. The WOSA estimates have, in general, a higher variance
than the B-T estimates; but the adjustable parameters of a WOSA estimator can be tuned to obtain
the same number of eﬀective DOF as the B-T estimator with a proper choice of overlap for the same
frequency resolution (Nuttall, 1971). On the other hand, the computational burden associated with
the WOSA estimator can be signiﬁcantly lower than that with the smoothed periodogram methods
Bendat and Piersol (2010, Chapter 11). For this reason, the Welch’s averaged estimator has acquired
more prominence than the other classical estimators.
A fact, however, remains with all non-parametric methods - they suﬀer from spectral leakage,
resolution limited by data length and lack of smoothness in spectral estimates. In the next section,
we study parametric methods, which do not suﬀer from these drawbacks.
Listing 16.9
MATLAB code for Example 16.7
% Generate WN sequence and compute theoretical PSD
N = 1024;
ek = randn(N,1); ekd = ek - mean(ek);
th_psd = 1/(2*pi);
% Periodogram
[psd_hat ,wv] = periodogram(ekd,rectwin(N),N,’twosided’);
psd_per = psd_hat(1:end/2);
% Welch’s averaged periodogram
[psd_hatw ,wv2] = pwelch(ekd,hanning(128) ,64,[],’twosided’);
psd_welch = psd_hatw(1:end/2);
% B-T method
L = 127;
[acf_vv,lags] = xcov(ekd,L,’biased’);
win_fn = bartlett(length(lags));
wacf_vv = win_fn.*acf_vv;
psd_bt = fft(wacf_vv(128:end),256) + 256*ifft(wacf_vv(128:-1:1) ,256) - wacf_vv...
(128);

Estimation of Signal Properties
461
% Neglect imaginary parts due to rounding errors
psd_bt = real(psd_bt(1:end/2))/(2*pi);
% MTM
[psd_hatm ,wv3] = pmtm(ekd,[],[],’twosided’);
psd_mtm = psd_hatm(1:end/2);
figure
subplot(2,2,1)
plot(wv(1:end/2),psd_per ,wv([1 end/2]),th_psd*[1 1],’r--’);
subplot(2,2,2)
plot(wv2(1:end/2),psd_welch ,wv2([1 end/2]),th_psd*[1 1],’r--’)
subplot(2,2,3)
plot(wv2(1:end/2),psd_bt,wv2([1 end/2]),th_psd*[1 1],’r--’)
subplot(2,2,4)
plot(wv3(1:end/2),psd_mtm ,wv3([1 end/2]),th_psd*[1 1],’r--’)
16.5.7
PARAMETRIC METHODS
The parametric methods take a completely diﬀerent route to spectral estimation by assuming
a generating or a parametric model for the given time series. Thus, eﬀectively the spectrum
is parametrized (recall from Chapter 4 that time-domain parametric models are equivalent to
parametrization of the time responses of a process). Parametrization of the model also tantamounts
to parametrizing the ACVF. The parametrization aids in the extrapolation of the ACVF beyond lags
|l| ≥N, thereby achieving higher resolution than the non-parametric methods which are limited by
the assumption of σvv[l] = 0, ∀|l| ≥N.
Time-series model-based methods
Denote the estimated time-series model by ˆH(q−1) and the variance of the WN by ˆσ2
e. Using equa-
tion (11.36), we have the spectral estimate,
ˆγvv(ω) = | ˆH(e−jω)|2 ˆσ2
e
2π
(16.110)
Naturally, the quality of the resulting spectrum is conditioned on the goodness of the estimated
model. On the other hand, since the model is only an intermediary in this method, the actual structure
of the model is not a major issue of concern as long as the dynamics of the process have been well
captured. The choice of model structure is usually guided by the ease of estimation unless there is
a strong preference towards a particular model owing to some priori knowledge of the generating
process. In the absence of any a priori information, AR models are preferred since they give rise to
linear predictors (see §18.3.1 and §19.2.2). An additional point in favor of the parametric approach
is that any continuous p.s.d. can be reasonably well approximated by AR models of suﬃciently high
order (Anderson, 1971; Shumway and Stoﬀer, 2006, p. 229).
Methods for estimating time-series models are described in Chapter 19. Below we note a few
important remarks concerning the use of parametric methods.
Remarks:
i. Estimates obtained by ﬁtting an AR model are identical to maximum entropy estimates (to follow shortly).
ii. The quality of the AR model depends on the method that is used. In principle, there exist several choices
(see Chapter 19). Popular ones include Yule-Walker, Burg’s method, MLE and the covariance method. The
(modiﬁed) covariance method and the Burg’s method are usually preferred because they generally produce
estimates with lower variance. The Y-W method, as we note in Chapter 19 can provide poor estimates when
the true poles are close to the unit circle. When N is very large, the diﬀerences in the methods may not be
signiﬁcant.

462
Principles of System Identiﬁcation: Theory and Practice
iii. If the underlying process is MA, and an MA(M) model is used for estimation, one obtains a B-T estimate
with a rectangular window (see Exercise E16.13).
iv. Regardless of the model structure, it is important to choose an appropriate order to avoid both overﬁtting
and large modeling errors. Information criteria measures such as AIC, BIC and MDL are widely used for
this purpose (see Chapter 22).
v. The AR-based parametric estimation is ideally suited for processes characterized by narrowband spectra or
have spectral peaks. In contrast, MA models are useful for processes with broadband spectra.
vi. For processes with mixed spectra (sinusoids embedded in noise), an ARMA model may be used. If the
series contains p pure tones, then an AR model of order P = 2p is required (because a single pure tone can
be explained by an AR model with two (purely imaginary) poles). This approach has close relation to the
Pisarenko harmonic decomposition method.
vii. Computing errors in parametric spectral estimates and construction of associated conﬁdence intervals is
a complicated task since it is diﬃcult to determine the propagation of uncertainties in model parameters
through the squared magnitude of the FRF. A method to derive the conﬁdence bands was provided by Berk
(1974) and is described in Percival and Walden (1993). The asymptotic autoregressive spectral estimator
using an inﬁnitely large order AR model, i.e., N →∞,P →∞,P3/N →0 results in conﬁdence intervals
of the form (Shumway and Stoﬀer, 2006),
ˆγ(AR)(ω)
1 + Czα/2
≤γ(ω) ≤
ˆγ(AR)(ω)
1 + Czα/2
(16.111)
where C = √2P/N and zα/2 is the ordinate corresponding to the upper α/2 of the standard normal distri-
bution. Alternatively, bootstrapping methods may be used for this purpose.
A step-wise procedure outlining the parametric method is given below.
Algorithm 16.4
Obtaining estimates of auto-spectral density using parametric methods
1. Remove means from the data sequence vN .
2. Fit a suitable parametric time-series model H(q−1) to the mean-centered series using the procedure
of Table 19.1 (including checks for stationarity, etc.).
3. Estimate the noise variance σ2e using the obtained time-series model.
4. Evaluate the FRF of the estimated time-series model.
5. Compute the estimate of power spectral density by inserting the FRF and the innovations variance
estimates in (16.110).
Maximum entropy based estimation
The maximum entropy spectral estimator also extrapolates the ACVF at lags |l| ≥N by maximizing
the entropy of the given series expressed in terms of its spectral density. The underlying principle
is that the ACVF at lags |l| ≥N is the same as that of a random process whose auto-covariance
sequence over lags |l| < N coincide with the estimated sequence. Thus, it implicitly exploits the
structure of the ACVF indicated by the observations and does not make any further assumptions.
The entropy of a Gaussian signal in terms of its spectral density function is deﬁned as
E(v[k]) = 1
4π
Z π
−π
ln γvv(ω) dω
(16.112)

Estimation of Signal Properties
463
Maximizing this entropy w.r.t. the unknown ACVFs σvv[l] and imposing that P ACVFs of the
process match the estimated ACVFs, yields a solution that is identical to ﬁtting an AR model of
order P. This result was discovered by Burg and is available as Burg’s maximum entropy theorem
(Burg, 1975; Stoica and Moses, 2005). Thus, an AR model-based p.s.d. estimator is a maximum
entropy spectral estimator.
Parametric vs. non-parametric methods
The two classes of methods diﬀer in a similar way as they do in system identiﬁcation. A comparison
of characteristics in the context of spectral estimation is summarized in Table 16.3 at the end of the
chapter.
As in identiﬁcation, in the absence of any speciﬁc a priori information, a non-parametric method
(such as the Welch’s method) is highly recommended as a starting point.
An illustrative example concerning the estimation of a colored noise is shown below.
Example 16.8: PSD Estimation of a Correlated Process
It is desired to estimate the power spectral density of a colored noise process from N = 2048
observations. Three methods are considered: (i) Welch’s method, (ii) Parametric MCOV method
and (iii) Burg’s method. The latter two ﬁt AR models of appropriate order (determined by
an information criterion measure such as AIC) using two diﬀerent methods, the modiﬁed
covariance and Burg’s method, respectively (see Chapter 19).
0
0.5
1
1.5
2
2.5
3
1
2
3
4
5
ω (rad/sample)
PSD
 
 
Parametric (MCOV)
Theoretical
Welch
0
0.5
1
1.5
2
2.5
3
1
2
3
ω (rad/sample)
PSD
 
 
Parametric (Burg)
Theoretical
FIGURE 16.10
PSD estimates of a colored noise process using parametric methods.
Figure 16.10 shows the PSD estimates from the aforementioned methods. Of particular
interest are those obtained from parametric estimators. The order has been determined using
the AIC which measures the trade-oﬀbetween the bias (model complexity) and variance
(errors in parameter estimates) of the model.
The dashed line in both panels once again represents the theoretical spectral density for
this process. The data-generating process is an ARMA(1,1):
v[k] = H(q−1)e[k]; H(q−1) = (1 + 0.4q−1)/(1 −0.7q−1),
e[k] ∼N (0,1)
In the top panel of the ﬁgure, Welch’s estimates are also shown for comparison purposes.
It is evident that the AR estimator produces high quality estimates. Moreover, the PSD has
a smooth nature unlike that of the non-parametric method.

464
Principles of System Identiﬁcation: Theory and Practice
Listing 16.10
MATLAB code for Example 16.8
% Generate the process
vk = filter([1 0.4],[1 -0.7],randn(2048,1));
vkd = vk - mean(vk);
% Use pwelch to estimate
[Pvv,wvec] = pwelch(vk,[],[],[],’twosided’);
psdvk_welch = Pvv(1:end/2);
% Estimate the p.s.d. using the AR model (MCOV)
aic_mod = [];
for k1 = 1:20,
modvk_ar = ar(vk,k1);
aic_mod(k1) = aic(modvk_ar);
end
[min_aic ,min_ord] = min(aic_mod);
modvk_ar = ar(vk,min_ord);
Hw_hat = freqz(1,modvk_ar.a,wvec(1:end/2));
psdvk_ar = abs(Hw_hat).^2*modvk_ar.Noisevariance/(2*pi);
% Burg’s method
Pvv = pburg(vk,min_ord ,wvec);
psdvk_burg = Pvv(1:end/2);
% Theoretical spectral density
Hw0 = freqz([1 0.4],[1 -0.7],wvec(1:end/2));
th_psdvv = abs(Hw0).^2/(2*pi);
figure
subplot(211)
plot(wvec(1:end/2),psdvk_ar ,’b-’); hold on
plot(wvec(1:end/2),th_psdvv ,’k--’);
plot(wvec(1:end/2),psdvk_welch ,’r-.’);
subplot(212)
plot(wvec(1:end/2),psdvk_burg ,’c-’); hold on
plot(wvec(1:end/2),th_psdvv ,’k--’);
16.5.8
SUBSPACE DECOMPOSITION-BASED METHODS
We close the discussion with a presentation on what are known as high-resolution or subspace de-
composition methods, speciﬁcally designed for the case of sinusoids embedded in (Gaussian white)
noise. These methods largely began with Pisarenko’s work on harmonic decomposition method
(Pisarenko, 1973).
y[k] =
p
X
i=1
Aieωik + e[k]
e[k] ∼N (0,σ2
e)
(16.113a)
Based on the above model, the auto-covariance matrix Σyy (up to lag L) and the power spectrum
γyy can be expressed as
Σyy =
p
X
i=1
|Ai|2s(ωi)s(ωi)H
|                      {z                      }
Σxx
+σ2IL×L
(16.113b)
γyy(ω) =
p
X
i=1
|Ai|2δ(ω −ωi) + γee(ω)
(16.113c)

Estimation of Signal Properties
465
where si is the vector s(ωi) ≜
f
1
ejωi
ej2ωi
· · ·
ejLωi gT. In practice, the lag L can take on
a maximum value of (N −1).
The goal is to estimate the frequencies and their associated strengths (ωi,|Ai|2),
i = 1,· · · ,p
and the noise variance σ2 through an eigenvalue analysis of the ACVF matrix Σyy. The rank of the
ACVF matrices of y and x are L and p < L, respectively. Thus, (L −p) eigenvalues of Σxx are
identically zero. Using matrix algebra fundamentals, the eigenvalue decomposition of Σyy can be
written as,
Σyy =
p
X
i=1
(λi + σ2
e)vivH
i +
L
X
i=p+1
σ2
evivH
i
(16.114)
where vi is the ith eigenvector, {λi, i = 1,· · · ,p} are the p non-zero eigenvalues of Σxx. Note
that the ACVF matrix of y is positive deﬁnite and symmetric. Hence, it is guaranteed that we can
construct orthonormal eigenvectors, i.e.,
vivj =

1,
i = j
0,
i , j
Without loss of generality, assume that the eigenvalues of Σyy are arranged in descending order
(as in SVD). The resulting decomposition then approximately breaks up the ACVF matrix into
two subspaces, namely the signal and noise subspace, each spanned by the eigenvectors {vi, i =
1,· · · ,p} and {vi, i = p + 1,· · · , L}, respectively. The break-up would have been exact had the
corresponding eigenvalues been solely dependent on the signal and noise characteristics.
Below we present three methods based on the above idea for separating the signal and noise
spectrum. These methods essentially diﬀer in the way they estimate the signal and noise power
spectrum from this decomposition. Readers who are familiar with principal component analysis
(PCA) (Section 26.3) may recognize the close resemblance of these methods with the PCA-based
method for signal and noise separation.
1. Pisarenko’s harmonic decomposition: The approach that Pisarenko takes eﬀectively amounts to
computing the noise variance by examining the last ordered eigenvalue of Σyy set up with L =
p + 1. The method hinges on an AR(2p) model (with symmetric coeﬃcients) for the sinusoidal
signal x[k]. The roots of the associated diﬀerence equation are purely imaginary of the form
λi = ±jωi. Combining this model with the additive noise model for the measurement, we have
y[k] = −
2p
X
m=1
amx[k −m] + e[k]
(16.115)
Substituting for x[k −m] in terms of the measurement and noise, we obtain an ARMA model for
y[k] which has the same coeﬃcients for the AR and MA parts.
−
2p
X
m=0
amy[k −m] = −
2p
X
m=1
ame[k −m]
a0 = 1; a2p−i = ai
(16.116)
The auto-covariance of the measurement can then be expressed as
Σyya = σ2a
where a =
f
1
a1
· · ·
a2p
gT
(16.117)
The eigenvalue associated with that eigenvector that is symmetric and whose ﬁrst and last values
are unity, provides an estimate of the noise variance. Compare the above equation with the one
resulting from multiplying both sides of (16.114) with one of the noise eigenvectors
Σyyvp+1 = σ2
evp+1
(16.118)

466
Principles of System Identiﬁcation: Theory and Practice
Thus, the last eigenvector contains the model coeﬃcients, which is a known result in PCA.
Solving for the roots of the polynomial with the coeﬃcients from this eigenvector provides esti-
mates of the frequencies of the sinusoids. With these pieces of information, the power associated
with these frequency components |Ai|2 are obtained by setting up L = p linear equations using
(16.113c).
Pisarenko’s method produces poor estimates mainly due to the way it estimates the noise vari-
ance. Furthermore, it relies on a model for the signal and assumes that the number of sinusoids
p is known a priori. Nevertheless, it generates ideas for other advanced approaches.
2. Multiple Signal Classiﬁcation (MUSIC): This technique is essentially an improvement on the
PHD method. It estimates the noise variance by taking the average of the (L −p) minimum
eigenvalues of the ACVF of Σyy, once again very much alike, to PCA:
ˆσ2
e =
1
L −p
L
X
i=p+1
λi
(16.119)
The frequencies are also estimated in a slightly diﬀerent manner by deﬁning an average pseudo-
spectrum:
ˆγMUSIC(ω) =
1
L
X
i=p+1
|s(ω)Hvi|2
(16.120)
At frequencies ωi of the sinusoids, the correlation between the signal and the noise eigenvectors
vi, i = p + 1,· · · , L is very small, producing peaks in the pseudo-spectrum.
3. Eigenvector method: The method oﬀers a further improvement over the MUSIC technique by
constructing the pseudo-spectrum
ˆγeig(ω) =
1
L
X
i=p+1
1
λi
|s(ω)Hvi|2
(16.121)
In the methods described above, the theoretical auto-covariance matrix is replaced by the sample
auto-covariance matrix.
Note: In the spectral estimation literature, it is common to use the term correlation matrix to mean covari-
ance matrix. The diﬀerences in terminology is once again due to the diﬀerent usage of terms in statistics
and signal processing community to mean the same quantity.
The main points of the foregoing methods and their uses are summarized in Table 16.4 at the end
of the chapter. Each method is suited to a class of applications, speciﬁcally on the nature of signal
and noise spectra and their relative proportions in the measurements. A particular method should be
selected based on the prior knowledge and the information that is being sought.
There exist several other estimators of spectral densities such as minimum variance, ESPRIT,
Bayesian estimators, etc. Most of these are specialized for a class of applications or possibly require
high computational power. An interested reader is referred to Djuric and Kay (1999) and Marple
(1987) for an insightful discussion of these methods.
16.6
ESTIMATION OF CROSS-SPECTRAL DENSITY
The methods, ideas and issues that we learnt for estimating auto-spectral densities in the foregoing
section, with minor and obvious modiﬁcations, carry forward to the estimation of cross-spectral

Estimation of Signal Properties
467
densities as well. For instance, the raw estimate of c.p.s.d. between two stationary signals y[k] and
u[k] given by,
ˆγyu(ω) = Pyu(ω) = 1
2πYN (ω)U⋆
N (ω)
(16.122)
where YN (ω) and UN (ω) are the N-point DFTs of y[k] and u[k], respectively, is asymptotically
unbiased, but not consistent. The asymptotic variance is Priestley (1981)
var( ˆγyu(ω)) ≊

γyy(ω)γuu(ω),
ω , 0,π
2γyy(ω)γuu(ω),
ω = 0,π
(16.123)
Then, the ideas of smoothed periodogram using any of the previously discussed non-parametric
approaches can be used to obtain a consistent estimator.
CPSD estimates from smoothed periodogram
In this approach, the B-T estimator or the equivalent Daniell’s method is used as outlined in the
algorithm below.
Algorithm 16.5
Obtaining smoothed estimates of cross-spectral density
1. Remove means from the data sequences yN and uN .
2. Compute the raw cross-spectral density estimate using (16.122) (alternatively the raw CCVF estimate
using (16.32)).
3. Smooth the raw CPSD estimate using an appropriate spectral window (alternatively compute the
FFT of windowed CCVF using an appropriate lag window).
The smoothed estimator is asymptotically unbiased and consistent (all the previously assumed
asymptotic conditions and properties of the lag window holding):
var( ˆγ(BT )
yu
(ω)) ≊

˜Bw
N γyy(ω)γuu(ω),
ω , 0,π
2 ˜Bw
N γyy(ω)γuu(ω),
ω = 0,π
(16.124)
where ˜Bw is the bandwidth of the lag window as deﬁned in (16.97).
The usual quantities of interest are the amplitude and phase spectra (for example, in delay estima-
tion). Priestley (1981) derives the necessary distributional properties of these estimators. Denoting
the amplitude and the phase by ˆζyu(ω) = | ˆγyu(ω)| and ˆφyu(ω) = arg ˆγyu(ω), respectively, we have
for ω , 0,π,
var( ˆζyu(ω)) ≊Bw
2N ζ2
yu(ω)
 
1
|κyu(ω)|2 + 1
!
var( ˆφyu(ω)) ≊Bw
2N ζ2
yu(ω)
 
1
|κyu(ω)|2 −1
!
(16.125a)
(16.125b)
where it is assumed that the magnitude of the true coherence deﬁned in (11.51) is non-zero, i.e.,
κyu(ω) > 0.
Recall that coherence (magnitude of coherency) is always bounded above by unity. Furthermore,
coherence is also a measure of linear dependence between two variables. Therefore, the error in
amplitude and phase estimates is high at all those frequencies where the linear dependency is weak.

468
Principles of System Identiﬁcation: Theory and Practice
The phase estimates are accurate (at any ω) whenever the signals are perfectly correlated, which
occurs only in an ideal situation. In practice, we use estimated values of squared coherence in
(16.125a) and (16.125b).
Distributional properties of amplitude and phase spectra are provided in Brockwell and Davis
(1991, Chapter 11).
Welch’s approach to estimation of CPSD is similar to that for the auto-spectral density. Divide
the two-time series into K overlapping (typically 50%) segments, compute the raw modiﬁed cross-
spectral density for each segment followed by an averaging of the raw estimates:
ˆγW
yu(ωn) = 1
K
K
X
i=1
ˆγ(i)
yu(ωn)
where ˆγ(i)
yu(ωn) = 1
L
˜Y (i)
L (ωn) ˜U(i),⋆
L
(ωn)
= 1
L
*
,
L−1
X
k=0
w[k]y(i)[k]e−jωnk+
-
*
,
L−1
X
k=0
w[k]u(i)[k]ejωnk+
-
(16.126a)
(16.126b)
where the ˜[.] on Y and U denotes DFT of tapered segments, L is the number of data points in each
segment and w[k] is the tapering window applied to each segment. A step-by-step procedure is
outlined below.
Algorithm 16.6
Obtaining WOSA estimates of cross-spectral density
1. Remove means from the data sequences yN and uN .
2. Divide each of these sequences into K segments of L data points each with overlapping (typically
50%).
3. Compute the raw modiﬁed CPSD estimate using (16.126b).
4. Average the raw estimates as in (16.126a) to obtain the WOSA estimate of CPSD.
Remarks:
It is a common practice to report the one-sided auto- and cross-spectral density instead of the
regular two-sided spectral densities (see Bendat and Piersol (2010) for instance). The former form is motivated
by the symmetry property of the magnitudes of the density functions. However, caution should be exercised in
using these quantities since the one-sided is adjusted such that
Area(One-sided p.s.d.) = Area(Two-sided p.s.d.)
Consequently, the one-sided density function is doubled at all frequencies except at ω , 0.
16.7
ESTIMATION OF COHERENCE
Coherency between two random stationary signals was deﬁned in (11.51). Recalling and applying
it two stationary signals y[k] and u[k] gives,
κyu(ω) =
γyu(ω)
pγyy(ω)γuu(ω)
((11.51) revisited)
A raw estimate of coherency using the periodogram estimator yields a completely worthless result
because using (16.68) and (16.122) we have,
ˆκyu(ω) =
Pyu(ω)
pPyy(ω)Puu(ω)
= 1, ∀ω

Estimation of Signal Properties
469
which has very little meaning.
Therefore it is necessary to use smoothed or averaged spectral densities:
ˆκyu(ωn) =
ˆγ(S)
yu (ωn)
q
ˆγ(S)
yy (ωn) ˆγ(S)uu (ωn)
(16.127)
where ˆγ(S)(ω) denotes one of Daniell, B-T or the WOSA estimators. Other alternative non-
parametric estimators also exist. For a good review of non-parametric methods for estimation of
coherence read Carter (1987).
The important quantities of interest is the magnitude coherence | ˆκyu(ω)| and its squared version
(MSC), not only in the analysis of data but also in deriving error bounds on CPSD estimates.
Coherence estimates from smoothed periodograms
The asymptotic properties of the magnitude coherence estimate and its squared version computed
from smoothed estimator are given in several classical texts (Brockwell and Davis, 1991; Priestley,
1981), as reported below. One can notice close similarities of these results with that of the squared
correlation coeﬃcient presented in 16.3.
i. Variance: The magnitude coherence estimate has the property under the conditions |κyu(ω)|2 >
0,
var(| ˆκyu(ω)|) ≊1 −|κyu(ω)|2
2NBw
(16.128)
where Bw is the bandwidth of the window used in smoothing the periodogram.
ii. When a simple averaging smoother (16.88) is used, the asymptotic variance of the squared co-
herence estimate is given by:
var(| ˆκyu(ω)|2) ≊= 4|κyu(ω)|2(1 −|κyu(ω)|2)2
2NBw
(16.129)
once again under the assumption that |κyu(ω)| > 0.
In addition to being consistent, an important point to note is that the error in the coherence
estimate depends on the true coherence and that it is a function of the frequency. The lowest
error, 0, is achieved when the true coherence is unity.
iii. Distribution: The magnitude coherence has an asymptotically normal distribution
| ˆκyu(ω)| ∼AsN (|κyu(ω)|,(1 −|κyu(ω)|2)/2NBw)
(16.130)
The above result can be used to derive the distribution for MSC estimate and particularly set up
the test for the null hypothesis of zero coherence in order to test the absence of linear relation-
ships.
iv. Under the null hypothesis H0 : |κyu(ω)|2 = 0, the following holds:
| ˆκyu(ω)|2
1 −| ˆκyu(ω)|2 (L −1) ∼As F(2,2L −2)
(16.131)
where ˆκyu(ω) is the simple smoothed estimate of coherence and L = 2M + 1 is the width of the
spectral window.

470
Principles of System Identiﬁcation: Theory and Practice
Coherence estimates from WOSA estimator
The squared coherence estimates obtained from the Welch’s method have been rigorously ana-
lyzed in several works. Carter (1987) presents these results in great detail. Closed-form expres-
sions for bias, variance and distribution, both exact and approximate, are available only for the
non-overlapping segmented approach. The approximate case assumes that the number of non-
overlapping segments KN is large. Only these results are recalled here. For all other cases and
expressions, the reader is referred to Carter (1987).
i. Bias:
E(| ˆκyu(ω)|2) −|κyu(ω)|2 ≊
1
KN

1 −|κyu(ω)|2
≤
1
KN

1 −|κyu(ω)|

(16.132)
Thus, the estimator is asymptotically unbiased. It has a zero bias whenever the true MSC is unity.
ii. Variance:
var

| ˆκyu(ω)|2
≊

1
K2
N
,
|κyu(ω)|2 = 0
2|κyu(ω)|2(1 −|κyu(ω)|2)2
KN
,
0 < |κyu(ω)|2 ≤1
(16.133)
The estimator is thus consistent. Further, the expression for non-zero coherence is almost iden-
tical to that for the smoothed estimator given in (16.129). Accordingly, the lowest error of 0,
occurs at unity coherence. The worst error is incurred when the MSC is one-third (see Exercise
E16.14).
When the segments are overlapped, arriving at analytical expressions is quite complicated. Besides,
the errors depend on the extent of overlap in a complicated fashion. The reader is directed to Carter
(1987) and Wang and Tang (2004). In closing, it may also be noted that bootstrapping techniques
always exist as a reliable alternative for determining the statistical properties of the MSC estimate.
A case study of estimating c.p.s.d. and coherence for the input-output data from the liquid level
case study of Chapter 2 is presented.
Example 16.9: CPSD and Squared Coherence of Liquid Level Data
Recall the liquid level case study of Chapter 2. The spectral content of the input and output,
cross-spectral density as well as coherence are computed for the given data.
Figure 16.11(a) shows the power spectral density and c.p.s.d estimates. The diagonal plots
show the power spectral densities (estimates) of the output and input, respectively. It is clear
that we have used a low-frequency input and therefore we should expect only “information”
about the system in this regime. The output spectral density clearly suggests that the process
has strong low-pass ﬁlter characteristics, largely justifying the choice of input spectral con-
tent. The oﬀ-diagonal plots show the magnitude of c.p.s.d. (recall it is a complex quantity)
estimates. Both plots are identical since γyu = γ⋆uy.
The squared coherence is shown in Figure 16.11(b). A conclusion that clearly follows is
that the data useful for linear model identiﬁcation is only in a selected frequency region. The
lack of coherence in mid- and high-frequencies is due to: (i) low-frequency excitation in the
input (ii) non-linearities in the process and (iii) noise content in the measurements. These
observations are either directly or indirectly incorporated in diﬀerent aspects of identiﬁcation
- estimation of FRF, delays, bias-adjustment in models, etc. We shall learn these aspects in
subsequent chapters of the text.

Estimation of Signal Properties
471
0
2
4
0
0.1
0.2
0.3
0.4
PSDy
ω (rad/sample)
0
2
4
0
0.02
0.04
0.06
0.08
|CPSDyu|
ω (rad/sample)
0
2
4
0
0.02
0.04
0.06
0.08
|CPSDuy|
ω (rad/sample)
0
2
4
0
0.005
0.01
0.015
0.02
PSDu
ω (rad/sample)
(a) CPSD estimates
0
0.5
1
1.5
2
2.5
3
3.5
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
ω (rad/sample)
|Cohyu|2
(b) Squared coherence estimate
FIGURE 16.11
CPSD and squared coherence estimates for the liquid level system using data generated in
Chapter 2.
Listing 16.11
MATLAB code for Example 16.9
% Load the liquid level data
load liqleveldata
% Remove the mean
ukd = uk - mean(uk); ykd = yk - mean(yk);
% Compute the auto- and cross-spectral density
[Puu,w1] = cpsd(ukd,ukd,[],[],’twosided’);
[Pyy,w2] = cpsd(ykd,ykd,[],[],’twosided’);
[Pyu,w3] = cpsd(ykd,ukd,[],[],’twosided’);
figure
subplot(221); plot(w2(1:end/2),Pyy(1:end/2))
subplot(222); plot(w3(1:end/2),abs(Pyu(1:end/2)))
subplot(223); plot(w1(1:end/2),abs(Pyu(1:end/2)))
subplot(224); plot(w2(1:end/2),Puu(1:end/2))
% Squared coherence
[sqcohyu ,w4] = mscohere(ykd,ukd,hanning(128) ,[],[],’twosided’);
figure
plot(w4(1:end/2),sqcohyu(1:end/2));
Non-parametric estimation of cross-spectral density is also useful in estimation of disturbance
spectrum, without actually ﬁtting a model (see Chapter 20).
In using the estimators, we have assumed stationarity (or quasi-stationarity). When the measure-
ments contain non-stationary trends, it is important to eliminate them (for example, through poly-
nomial ﬁtting) before employing these techniques.
Parametric estimators of coherence
Just as there exist parametric methods for estimating auto-spectral density, there are also ways of
parametrically estimating cross-spectral density and coherence. These methods are built on ideas for
vector time-series modeling, speciﬁcally, multivariate auto-regressive (MVAR) models. The founda-
tional result is once again the multivariate version of spectral factorization (11.84) that was presented
in §11.6. For an m × 1 vector process v[k],
S(ω) = H(ω)ΣeHH (ω)
((11.84) revisited)

472
Principles of System Identiﬁcation: Theory and Practice
where H(ω) (more appropriately H(ejω) is the vector MA model of the vector process v[k], Σe is
the m × m innovations (noise) covariance matrix (typically diagonal) and S(ω) is the cross-spectral
density matrix of v[k],
S(ω) =

γv1v1(ω)
γv1v2(ω)
· · ·
γv1vm (ω)
γv2v1(ω)
γv2v2(ω)
· · ·
γv2vm (ω)
...
...
...
...
γvmv1(ω)
γvmv2(ω)
· · ·
γvmvm (ω)

((11.67) revisited)
The prime step is the estimation of the VMA model, for which several methods exist. A predomi-
nantly used method is via the VAR model route (Lutkepohl, 2005),
H(ω) = A−1(ω)
(16.134)
where A(q−1) is the matrix equivalent of the univariate auto-regressive model
A(q−1)v[k] = e[k],
A = I +
P
X
r=1
Arq−r
(16.135)
The reason for the popularity of the VAR descriptions in parametric multivariate spectral analy-
sis is identical to the use of AR models for the univariate case. Extensions of standard techniques
such as least-squares, Y-W and Burg methods are available for the multivariate case as well (Lutke-
pohl, 2005). These techniques, as in the univariate case, also produce estimates of the innovations
variance-covariance matrix Σe.
For a SISO input-output process, the vector series is v[k] =
f
y[k]
u[k]
gT, Σe is a 2 × 2 diagonal
matrix and the spectral matrix is
S(ω) =
"γyy(ω)
γyu(ω)
γuy(ω)
γuu(ω)
#
(16.136)
The matrices H(ω) and A(ω) for this case are each 2 × 2 dimensional at each frequency. Given
time-series of y[k] and u[k], one can estimate these matrices as well as the cross-spectral density
matrix S(ω) using (11.84). The estimate of coherence matrix then follows.
Further discussion on this subject is beyond the scope of the current text. Vector time-series mod-
els ﬁnd widespread use in the ﬁeld of econometrics (Galbraith, Ullah and Zinde-Walsh, 2002; Lutke-
pohl, 2005) and in recently in neurosciences for causality analysis; see Baccala and Sameshima
(2001) and Gigi and Tangirala (2010). The idea of using these models for parametric estimation is
discussed in Faes and Nollo (2011) and Kay (1988) with a toolbox for the same available electroni-
cally at eMVAR (2012).
Estimation of partial cross-spectral density and partial coherence
We close this chapter with a brief discussion on the estimation of partial cross-spectral density
(PCPSD) and partial coherence (PCOH) that were introduced in §11.5. These quantities are very
useful in estimation of time-delays, channel transfer functions and connectivities in multivariable
processes (read §26.2).
Theoretical expressions for PCPSD and PCOH for a trivariate process were derived in (11.64) and
(11.65), respectively. These expressions involve the theoretical unconditional or the ordinary cross-
spectral densities of pairs of variables. Estimates of PCPSD and PCOH are obtained by replacing
the theoretical values of the unconditioned quantities with their respective estimates, which can be
obtained either using non-parametric and parametric ways as discussed in the foregoing sections.
The parametric methods are more popular in this respect due to their ease of use and the quality
of estimates that they produce (see Faes and Nollo (2011) for a summary demonstration of related
ideas).

Estimation of Signal Properties
473
16.8
SUMMARY
Through this chapter we have learnt various estimation methods for the statistical properties of
signals, speciﬁcally the ﬁrst- and second-order moments. There exist many estimators for a given
property, but what is desired in practice is an (asymptotically) unbiased, minimum variance and ef-
ﬁcient estimator. Closed-form expressions for distribution and conﬁdence intervals of the estimates
can be constructed only for a few estimators. Fortunately this is true for several commonly used
ones. In general, one would have to adopt resampling techniques to derive the conﬁdence intervals
or carry out hypothesis testing.
It is important to pay attention to the assumptions under which the signiﬁcance levels of estimates
are computed before using them. Otherwise, we are led to erroneous conclusions, which can have a
critical impact on the application of interest.
A signiﬁcant portion of this chapter has been devoted to spectral estimators of two classes -
non-parametric and parametric. Each has its own merits and demerits. In the absence of any a
priori information or as a good starting point, the non-parametric methods are always a safe option.
Parametric estimators produce good quality estimates, but have to be used carefully. Wrong choice
of model order can lead to highly misleading results. In the detection of sinusoids, where medium
resolution is desired, non-parametric methods are recommended. The information gathered from
these estimates can then be used in high-resolution subspace methods.
This chapter also concludes Part III of this text equipping us to move into the core part of this text
on identiﬁcation.
REVIEW QUESTIONS
R16.1 Identify two key diﬀerences between the sample mean and sample median in the estimation
context.
R16.2 Describe the procedure for estimating partial correlation.
R16.3 Explain the diﬀerences in the estimators of variance of a signal.
R16.4 Describe the diﬀerent tests of whiteness.
R16.5 What is spectral leakage and how can it be mitigated?
R16.6 Why is pre-whitening necessary for computing signiﬁcance levels in CCF estimation?
R16.7 Describe the major weakness of periodogram as an estimator of spectral density for a random
signal.
R16.8 Explain the working principle of Blackman-Tukey method.
R16.9 What is the main idea underneath Bartlett’s and Welch’s averaged periodogram method?
R16.10 Highlight the key diﬀerences between parametric and non-parametric estimators of spectral
density.
R16.11 For what class of signals is the subspace algorithm suited as a spectral estimator?
R16.12 Describe two diﬀerent ways of estimating the cross-spectral density.
R16.13 Why is it necessary to adopt the averaged or smoothed estimates of cross-spectral densities in
the computation of squared coherence?
R16.14 Describe the method for parametric estimation of coherence.
EXERCISES
E16.1 Verify by way of simulation, the distribution of sample mean for the case when the observations
fall out of a non-Gaussian distribution.

474
Principles of System Identiﬁcation: Theory and Practice
E16.2 A quality inspector was responsible for testing the claim made by a paper manufacturer that the
thickness of the paper is µ = 0.1 mm. For this purpose, 20 sample sheets were collected at random
to note that the sample mean is ¯x = 0.12 mm with a sample variance s2 = 0.0016 mm2. Can the
quality inspector refute the manufacturer’s claim?
E16.3 The variability in the temperature measurement of a reactor given in tmeasdata.mat is to be
estimated. From the estimate, construct 95% conﬁdence intervals for the variance.
E16.4 Prove that the sample mean calculated from N samples of a stationary process y[k] has a variance
var( ¯y) = 1
N

σyy[0] + 2
N−1
X
l=1
 
1 −|l|
N
!
σyy[l]

Verify your result by means of Monte Carlo simulations for an MA(1) process: y[k] = e[k]+0.4e[k−1].
E16.5 Derive the correction factor in (16.16) using Monte Carlo simulations.
E16.6 The time it takes for an administration department to process a ﬁle can be treated as a random
variable. To verify a claim by the administration department that it takes on the average µ = 10 days
to process a ﬁle, the processing times for N = 12 ﬁles, denoted by d[k] in days were recorded
k
1
2
3
4
5
6
7
8
9
10
11
12
d[k]
10.9
11.5
9.1
11.1
10.2
9.8
12.1
9.2
10.5
11.2
10.7
11.1
a. Calculate the sample mean and the sample variance of this random process.
b. Is the claim acceptable at 5% signiﬁcance level?
E16.7 Show that the periodogram in (16.49) can be re-written as the ACVF-based form (16.69).
E16.8 Show that the use of unbiased estimator of ACVF can produce negative-valued spectral densities.
E16.9 Determine the theoretical power spectral density of the series formed by
v[k] = e[k −2] + 2e[k −1] + 4e[k]
e[k] ∼N (0,1)
E16.10 Generate 2000 samples of v[k] in E16.9. Estimate the power spectrum using diﬀerent estimators,
namely, (i) periodogram, (ii) smoothed periodogram using Daniell’s smoother, (iii) Welch’s averaged
periodogram method and (iv) parametric method. Compare the estimates with the theoretical density
obtained in part E16.9 above.
E16.11 Show that the variance of the Bartlett’s estimator in (16.100) reduces that of the periodogram
estimator of spectral density by a factor K.
E16.12 Let a series consist of a periodic component embedded in noise y[k] = α1 cos(2π f0k) +
β1 sin(2π f0k) + e[k] where e[k] ∼N (0,σ2e).
a. Assuming that integer number of cycles have been completed in N samples, provide LS esti-
mates of α1, β1 and σ2e.
b. Do you ﬁnd a close relation between the expressions for optimal parameter estimates and the
DFT (of y[k]) coeﬃcients? If yes, explain it.
c. Verify your results by simulation. Choose α1 = 2, β1 = 3 and σ2e = 1.
E16.13 In parametric estimation of spectral density, show that if the underlying process is MA and an
MA(M) model is used, it is equivalent to using a B-T estimator with a rectangular window.
E16.14 Using the expression for the variance of squared coherence estimator in (16.133), show that the
worst error is incurred when the true mean squared coherence is 1/3.

Estimation of Signal Properties
475
TABLE 16.1
Table of common window functions (w[k], k = 0,· · · , N −1 ) and their characteristics
Window
Function, w[k]
6dB
BW
[bins]
PSL
[dB]
SLR
[dB/oct]
CG
ENBW
[bins]
Rectangular
1
1.21
-13.3
-6
1
1
Bartlett

2k/N −1,
k ≤N/2
2 −2k/N −1,
k > N/2
1.78
-26.5
-12
0.5
1.33
Hanning3
1
2
"
1 ± cos
 2πk
N −1
!#
2
-31.5
-18
0.5
1.5
Hamming4
0.54 ± 0.46 cos
 2πk
N −1
!
1.81
-42.7
-6
0.5328 1.36
Blackman
2
X
m=0
cm cos
 2πm
N −1
!
c0 = 0.42; c1 = −0.5; c2 = 0.08
2.35
-57
-18
0.42
1.73
Minimum
4-
term Blackman-
Harris
4
X
m=0
cm cos
 2πm
N −1
!
c0 = 0.35875; c1 = −0.48829;
c2 = 0.14128; c3 = 0.01168
1.64
-92
-6
0.3587 2
Nuttall4c
3
X
m=0
cm cos
 2πm
N −1
!
c0 = 0.3635819; c1 = −0.4891775;
c2 = 0.1365995; c3 = 0.0106411
2.63
-98.1
-6
0.3636 1.9761
Kaiser (α = 3)
J0 *.
,
πα
s
1 −
 
2k
N −1 −1
!2+/
-
J0(πα)
2.39
-69.6
-6
0.4
1.8
Flat-top
win-
dow
4
X
m=0
cm cos
 2πm
N −1
!
c0 = 0.21557895; c1 = −0.41663158;
c2 = 0.277263158; c3 = −0.083578947;
c4 = 0.006947368
4.6528
-89.65
-6
0.2122 3.83

476
Principles of System Identiﬁcation: Theory and Practice
TABLE 16.2
Lag window, their spectral equivalents and variance of B-T estimators
Lag window,w(x = l/M)
Spectral window, W(ω)
var( ˆ
γBT(ω))
γ2(ω)
Rectangular : 1,|x| ≤1
Dr (ω) ≜sin(2πM + π)ω
sin(πω)
2M
N
Bartlett : 1 −|x|,|x| ≤1
sin2(πMω)
M sin2(πω)
2M
3N
Tukey-Hanning : 1
2 (1 + cos x),|x| ≤1
1
X
m=−1
ci Dr (2πω + πm/M)
c−1 = 1
4,c0 = 1
2,c1 = 1
4
3M
4N
Parzen :

1 −6x + 6|x|3,
|x| < 1/2,
2(1 −|x|)3,
−1/2 ≤x ≤1
0,
otherwise
6
πM3
sin4(Mω/4)
sin4(ω/2)
0.539M
N
Sinc (Daniell) : sin(πx)
πx
,|x| ≤1

M,
|ω| ≤1/2M
0,
otherwise
M
N
TABLE 16.3
Comparison of non-parametric and parametric estimators of p.s.d.
Non-parametric
Parametric
No model is required. It can be esti-
mated with minimum a priori informa-
tion.
A generating model is assumed. Some
a priori information or user interven-
tion is usually required.
Assumes σvv[l] = 0, ∀|l| > N.
No such assumption. Model is eﬀec-
tively used for extrapolation.
Assumes periodicity, v[k + L] = v[k].
No such assumption.
Spectral leakage due to ﬁnite-length
data.
Finite length not an issue, unless N is
comparable to number of parameters in
the model.
Resolution is limited to 1/N.
Theoretically, no limitations on resolu-
tion. Quality of the model limited by
N.
Consistency achieved by sacriﬁcing
resolution.
Consistency of spectral estimates de-
pend on estimated parameters.
Do not generally give misleading re-
sults, but may mask features if exces-
sive smoothing is used.
Can yield misleading results with an
overﬁt model. Quality of the estimate
can vary with the method used for
model estimation.

Estimation of Signal Properties
477
TABLE 16.4
Comparison of popular methods for spectral estimation
Method
Suitability
Remarks
Periodogram
Deterministic
signals
or
measurements with very
high SNR. Good for esti-
mating line spectra.
Resolution limited by data
length. Spectral leakage is
an issue. Computationally
eﬃcient.
Modiﬁed/Averaged
periodogram
Measurements with mod-
erate to low SNR. Should
not be applied to determin-
istic signals. More suited to
broadband spectra.
Resolution
even
fur-
ther limited due to data
segmentation.
Good
for
obtaining
preliminary
spectral signatures. Extent
of smoothing determined
by trial and error.
Multi-taper method
Same as above. Better han-
dling of mixed (line and
broadband) spectra.
Improved spectral leakage
characteristics and reduced
variance.
Parametric estimator
Suited to a variety of spec-
tra except for line spec-
tra.
Narrowband
spectra
are better handled by AR
models while broadband
by MA models.
Oﬀers ﬁne resolution of
spectra. Should be used
carefully
since
wrong
model
orders
can
give
misleading results.
Subspace methods
Specialized
for
multiple
sines embedded in noise.
Not suitable for other ap-
plications.
Number of frequency com-
ponents to be determined
by
trial
and
error
(not
trivial).
Non-parametric
method
with
very
high
resolution.

PART IV
IDENTIFICATION OF DYNAMIC MODELS -
CONCEPTS AND PRINCIPLES

17
Non-Parametric and Parametric Models
for Identiﬁcation
The objective of this chapter to provide mathematical descriptions of the models used in linear
identiﬁcation. Foundations for the material were provided in Chapters 4 and 9. We shall study
both non-parametric (response-based) and parametric (prediction-error) models. Estimation
of each of these model types is discussed in Chapters 20 and 21.
17.1
INTRODUCTION
The chapters in Parts I and II laid down the foundations on models of discrete-time deterministic
and stochastic processes, respectively, while Part III provided the paraphernalia for estimating these
models. In Part IV (this part), beginning with this chapter, our goal is to collectively apply the
concepts from the previous chapters to frame and solve identiﬁcation problems. We shall begin by
studying the diﬀerent model types amenable for linear identiﬁcation. Essentially we shall weave the
descriptions of Chapters 4 and 5 with those of Chapters 9 to 11. The end result is a composite model
that aims to describe both the deterministic and stochastic eﬀects of the sampled-data system.
As usual, we shall observe two broad distinctions: (i) non-parametric and (ii) parametric descrip-
tions, each with their standard merits and demerits. In addition, these models may be cast either in
time-domain or in frequency-domain. Estimation of these models is discussed in a later chapter be-
cause it requires familiarity with certain additional concepts as well as insights into some practical
aspects of identiﬁcation upfront.
17.2
THE OVERALL MODEL
The idea here is to fuse the deterministic and stochastic eﬀects to arrive at a composite model for the
measurement y[k]. An important assumption that we shall make is that the output measurement y[k]
is a superposition of the “true” response (of the deterministic process) ytrue[k], and the disturbances
/ noise v[k].
y[k] = ytrue[k] + v[k]
(17.1)
Giving an LTI treatment to the deterministic and stochastic processes, and denoting these systems
by G and H, respectively, we symbolically have that
y[k] = Gu[k] + He[k]
G, H : LTI, e[k] : WN
(17.2)
where the notation Gu should be read as G operating on u (likewise for He) and not as multi-
plication. It is a common practice to refer to G as the plant model and H as the noise model in
identiﬁcation literature.
Figure 17.1 portrays the foregoing ideas. It is useful to explicitly list the assumptions in writing
(17.2):
i. Additive noise: The stochastic term superposes on the true response.
479

480
Principles of System Identiﬁcation: Theory and Practice
G
H
u[k]
e[k]
y[k]
+
+
v[k]
White-noise
(fictitious)
Input
Observed
output
Process 
Model
Noise 
Model 
Stochastic
effect
FIGURE 17.1
(SEE COLOR INSERT) Input-output representation of a deterministic-plus-stochastic LTI sys-
tem.
ii. Linearity and time-invariance of G: The deterministic process is LTI. No restrictions on stability
of G are necessary at this point.
iii. Stationarity of v[k]: The stochastic signal v[k] is stationary (Deﬁnition 7.8). Further it satisﬁes
the spectral factorization result (recall Theorem 11.7), i.e., it can be expressed as the output of
an LTI system driven by white-noise (Deﬁnition 8.2).
Thus, we have in eﬀect a deterministic-plus-probabilistic description for the input-output pair
{u[k], y[k]}.
Identiﬁcation problem
The problem of system identiﬁcation is as follows:
Given N observations of input-output data ZN = {y[k],u[k]}N−1
k=0 , obtain optimal estimates of
G, H and the statistical properties of e[k] (usually µe and σ2
e).
In order to be able to apply the estimation techniques of Chapters 14 and 16 for identiﬁcation, the
stationarity assumption for purely stochastic processes has to be extended to the class of signals with
composite, i.e., deterministic plus stochastic eﬀects. Essentially a uniﬁed deﬁnition of stationarity
for deterministic and stochastic signals is required. The following section is devoted to this aspect.
17.3
QUASI-STATIONARITY
To appreciate the need for a uniﬁed deﬁnition of stationarity, consider the mean of the output in
(17.2),
E(y[k]) = G(q−1)u[k] + E(v[k])
(17.3)
Thus, even with a stationary v[k] the ensemble average of the output changes with time. However,
given that u[k] is generally deterministic and that we work with a single realization of the output, the
time-average property is also a crucial one. Therefore, the question arises whether one could still use
the theory of stationary stochastic processes to identify models for the stochastic and deterministic
sub-systems, i.e., to identify G and a time-series model for v[k], given that y[k] is not even weakly
stationary?
It turns out that if the applied input is “well-behaved,” then the output can be expected to have
bounded time averages. Further, even though the ACVF of y[k] as well as the CCVF between the
output and input may change with time for short samples, they become independent of time for

Non-Parametric and Parametric Models for Identiﬁcation
481
large samples. The “well-behaved” nature of the inputs essentially translates to the requirement of
quasi-stationarity (see Ljung (1999) and the description below).
Generalized expectation
In order to deﬁne quasi-stationarity it is ﬁrst important to re-deﬁne the covariance function since
neither the deﬁnition for purely stochastic signals in §8.2 (or §8.4) nor for the deterministic signals
in §10.2.3 apply to the output in (17.2). With this requirement in view, it is useful to introduce a
generalized expectation operator ¯E, deﬁned as
¯E( f (s[k])) = lim
N→∞
1
N
N
X
k=1
E( f (s[k]))
(17.4)
The new expectation operator facilitates both time and ensemble averaging of the signal. Observe
that when x[k] is purely stochastic and stationary, ¯E yields the regular expectation E( f (x[k])).
Likewise if x[k] is deterministic, the expectation operation disappears and a time-averaging results.
Therefore, the stationary stochastic part of y[k] is only subject to an ensemble averaging, while the
deterministic part is subject to a time averaging. It follows that the generalized expectation is suited
for both random and deterministic signals.
Deﬁnitions
The next step is to introduce a modiﬁed deﬁnition of (limiting) auto-covariance function that is
suited for a mixed signal s[k]. We introduce this in two stages.
First, the regular auto-covariance function using the classical expectation, but without mean cen-
tering1, is introduced:
Rss[k,m] ≜E(s[k]s[m])
(17.5)
The covariance function above is clearly non-stationary whenever s[k] contains a deterministic
component or / and non-stationary stochastic component.
Secondly, the large sample ACVF using the generalized expectation, once again without mean
centering, is deﬁned:
¯Rss[k,m] ≜¯E(s[k]s[m]) = lim
N→∞
1
N
N
X
k=0
Rss(k,m)
(17.6)
If this covariance is bounded for all values of k and m and in the limit is only a function of l = k −m,
as for stationary random signals, i.e.,
¯Rss[k,m] = ¯Rss[k −m] = ¯Rss[l]
(17.7)
then s[k] is said to be quasi-stationary. A formal deﬁnition follows.
1The mean centering is not performed so as to be able to accommodate the deﬁnition for deterministic signals.

482
Principles of System Identiﬁcation: Theory and Practice
A signal s[k] is said to be quasi-stationary if it satisﬁes the following:
R1. Bounded average: E(s[k]) = µs[k],
|µs[k]| < ∞,∀k
R2. Boundedness of the classical ACVF: The classical ACVF E(s[k]s[m]) can be a function
of both k and m (i.e., not necessarily k −m) as long as it is bounded.
R3. Large-sample ACVF stationarity: As the number of observations increases, the ACVF
deﬁned by
¯Rss[l] ≜¯E(s[k]s[k −l])
(17.8)
is only dependent on the lag l. Note that treating ¯Rss[n −k] as the ACVF in a strict sense is
only valid when the signal s[k] is zero-mean.
Remarks:
1. The ﬁrst two conditions above essentially require that the output and its ﬁnite-sample ACVF should remain
bounded in order to obtain meaningful (model) parameter estimates.
2. The third requirement is useful for deriving asymptotic results using weak stationarity principles.
3. A prime purpose of deﬁning quasi-stationarity is to formalize the conditions and the framework under which
identiﬁcation can be practically performed. For example, if experimental data is generated with a ramp-type
input, the classical techniques of identiﬁcation cannot be applied. The data has to be pre-processed to bring
it into the quasi-stationarity framework.
From the deﬁnition above, it is evident that a stationary stochastic signal is also quasi-stationary.
The converse is not true. Thus, quasi-stationarity is a diluted version of weak stationarity, but one
that is more practically congenial.
Examples of quasi-stationary signals
There exist several practical signals that are quasi-stationary, and hence qualify as inputs in identi-
ﬁcation. We list a two popular classes below:
1. Periodic deterministic signals: All periodic deterministic signals are quasi-stationary. Examples
include sinusoids, a train of equal width pulses and full-length pseudo-random binary sequences.
For these signals, the deﬁnition of ACVF in for quasi-stationary signals simpliﬁes to the expres-
sions for periodic deterministic signals in Chapter 10,
σxp xp[l] = 1
Np
Np−1
X
k=0
xp[k]xp[k −l]
((10.12) revisited)
where Np is the period of the periodic signal. It is not diﬃcult to show that the ACVF deﬁnition
in (17.8) for simpliﬁes to that for periodic signals in (10.12) (see Exercise E17.3). Thus, periodic
signals are quasi-stationary.
On the other hand, ﬁnite-duration aperiodic signals are not quasi-stationary since the time-
averaged auto-covariances go to zero, as per the deﬁnition in (10.13).
2. Realizations of stationary random signals: Examples in this class include the ﬁnite-length real-
ization of white-noise, its colored variant and random binary sequences. An important require-
ment, however, is that these signals should have zero mean.

Non-Parametric and Parametric Models for Identiﬁcation
483
Spectral density deﬁnition for quasi-stationary signals
Just as a stationary signal is characterized by power spectral density, a quasi-stationary signal can
also be characterized by a p.s.d., deﬁned by the Wiener-Khinchin theorem
γss(ω) = 1
2π
l=−∞
X
l=∞
¯Rss[l]e−jωl
(17.9)
On the basis of (17.9) it is possible to show that the periodogram of y[k] is an asympotically unbi-
ased estimator of γss(ω) (Ljung, 1999).
lim
N→∞E
 
1
2πN |YN (ω)|2
!
= γss(ω)
(17.10)
Furthermore, as elucidated in Chapter 16, only smoothed periodograms are consistent estimators of
γss(ω).
Quasi-stationarity in identiﬁcation
We have up to this point, studied quasi-stationarity of univariate signals. However, it is important
to extend this concept to bivariate signals and guarantee that the output of an LTI system, when
excited, by a quasi-stationary signal is also quasi-stationary.
Accordingly, we ﬁrst extend the concept of quasi-stationarity to a pair of signals. Two signals y
and u are jointly quasi-stationary if the cross-covariance, as deﬁned below, exists.
¯Ryu(τ) ≜¯E(y[k]u[k −τ])
(17.11)
As in (17.9), a cross-spectral density can also be deﬁned for jointly quasi-stationary signals:
γyu(ω) = 1
2π
∞
X
l=−∞
¯Ryu[l]e−jωl
(17.12)
Secondly, we study an important result, which is that the output of an LTI system excited by a
quasi-stationary input is also quasi-stationary. A formal statement follows.
Theorem 17.1
Let G(q−1) be a stable transfer function and u[k] be a discrete-time quasi-stationary signal with
spectral density γuu(ω). Then the signal
s[k] = G(q−1)u[k]
(17.13)
is also quasi-stationary with
γss(ω) = |G(e−jω)|2γuu(ω)
(17.14a)
γsu(ω) = G(e−ω)γuu(ω)
(17.14b)
Proof. See (Ljung, 1999).
□

484
Principles of System Identiﬁcation: Theory and Practice
It follows that the output of the general LTI system (17.2),
y[k] = Gu[k] + He[k]
is quasi-stationary provided (i) the ﬁlters G and H are stable, (ii) the input {u[k]} is quasi-stationary
(deterministic) and (iii) {e[k]} is zero-mean white-noise process with variance σ2
e. Further, under
open-loop conditions
γyy(ω) = |G(e−jω)|2γuu(ω) + σ2
e
2π |H(e−jω)|2
(17.15a)
γyu(ω) = G(e−jω)γuu(ω)
(17.15b)
Returning to the problem of identiﬁcation, the LTI assumptions on G and H imply that we have
access to a repertoire of descriptions, non-parametric as well as parametric (refer to the respective
chapters of Parts I and II). Note that it is also possible to have state-space descriptions for G and
H. For the white-noise driving force, in principle, we are free to select the distribution function.
However, for reasons already known to us, we shall often specialize to zero-mean Gaussian white-
noise, e[k] ∼N (0,σ2
e).
In the following sections, we shall study the various descriptions for the overall model that arise as
a result of diﬀerent choices for G and H. The purpose of this study is not merely to know a particular
description but also to understand the implications of choosing a certain model in identiﬁcation.
The focus now is only on input-output representations. State-space descriptions appear exclusively
in Chapter 23. We begin with the non-parametric descriptions.
17.4
NON-PARAMETRIC DESCRIPTIONS
The non-parametric models arise when G and H are represented in a non-parametric form, for ex-
ample, as convolution model or using spectral representations. The connotations of a non-parametric
form in identiﬁcation have been studied earlier in Chapters 3 and 4. As before, models can be built
in (i) time-domain and (ii) frequency-domain.
17.4.1
TIME-DOMAIN DESCRIPTIONS
The most common non-parametric time-domain description corresponds to the convolution form
for G and H,
y[k] =
∞
X
n=−∞
g[n]u[k −n] +
∞
X
m=−∞
h[n]e[k −n]
(17.16)
Using the backward shift-operator q−1 notation, (17.16) is re-written as
y[k] = G(q−1)u[k] + H(q−1)e[k]

G(q−1) =
∞
X
n=−∞
g[n]q−n
H(q−1) =
∞
X
n=−∞
h[n]q−n
(17.17)
Bringing in the usual restrictions of causality, g[n] = 0, h[n] = 0, n < 0 and uniqueness of noise
model, h[0] = 1, we have
y[k] =
∞
X
n=0
g[n]u[k −n] +
∞
X
m=1
h[m]e[k −m]
|                                           {z                                           }
predictable portion
+e[k]
(17.18)

Non-Parametric and Parametric Models for Identiﬁcation
485
Separating the instantaneous white-noise term as in (17.18) aids in recognizing the predictable por-
tion of y[k] (giving us glimpses of Chapter 18) and also serves as a reminder of the fact that the
measurement always contains an unpredictable portion.
Note: One can further restrict the summation in G by assuming zero inputs at negative times, i.e., u[l] = 0,l <
0.
17.4.1.1
FIR Models
As in Chapter 4, we argue that (17.18) is not amenable for identiﬁcation because an inﬁnite number
of unknowns have to be estimated. As a ﬁrst step, we include only M past inputs as in §4.2.1. This
gives rise to the popular FIR model structure
y[k] =

k
X
n=0
g[n]u[k −n] + v[k],
k ≤M −1
M
X
n=0
g[n]u[k −n] + v[k],
k ≥M
(17.19)
It is one of the most widely used non-parametric models and is also a good starting point in identiﬁ-
cation since it makes minimal assumptions about the plant model. The merits of an FIR model from
an identiﬁcation viewpoint were discussed in Chapter 4. There is no particular attempt to estimate
the noise model H(q−1) since it is not the object of interest.
The FIR model also belongs to the family of parametric models, as we shall shortly learn.
Estimation: FIR models are estimated using (i) correlation analysis with input-prewhitening, (ii)
the least squares methods (same as correlation analysis), or (iii) subspace methods.
17.4.1.2
Step Response Models
The step-response model can be developed by using the relationship between the IR coeﬃcients
g[k] and s[k],
g[k] = s[k] −s[k −1]
(17.20)
in (17.16). Also, assuming the inputs to be zero at negative times,
y[k] =
k
X
n=0
(s[n] −s[n −1])u[k −n] + v[k]
(17.21)
We can further restrict the number of coeﬃcients (at large k) by assuming the existence of a steady-
state (stability of G), essentially requiring s[n] = s[M] , 0,n ≥M.
y[k] =

k
X
n=0
(s[n] −s[n −1])u[k −n] + v[k],
0 ≤k < M
M−1
X
n=0
(s[n] −s[n −1])u[k −n] + s[M]
k
X
n=M
u[k −n] + v[k],
k ≥M
(17.22)
The beneﬁts of a step-response representation in modeling an LTI system were discussed in Chapter
4.
Estimation: The standard LS method or the correlation analysis can be used to estimate the
step-response coeﬃcients. Alternatively, they can be computed indirectly from the estimated IR
coeﬃcients via (17.20).

486
Principles of System Identiﬁcation: Theory and Practice
17.4.2
FREQUENCY-DOMAIN DESCRIPTIONS
Adopting the frequency-response description for G gives us a frequency-domain or the transfer-
function representation for the plant model. Since the disturbance term v[k] does not possess a
Fourier transform, the frequency-domain description is strictly only available for the true response
Ytrue(ω) = G(ejω)U(ω)
However, this is of little use. Noting that the ﬁnite-length disturbance has a Fourier transform, a
natural recourse is to adopt a frequency-domain description involving ﬁnite observations, leading to
the ETFE form studied in Chapter 5. Recalling (5.27), we have
(Signal Description)
YN (ωn) = G(ejωn )UN (ωn) + VN (ωn) + RN (ωn)
(17.23)
where the Fourier transforms are the respective (unitary) DFTs of the ﬁnite-length signals, while
RN (ω) is a bounded error introduced in using the ﬁnite-length Fourier transforms.
Alternatively, recalling that a stationary process has a spectral density, we could develop a model
relating the spectra.
(Spectral Description)
γyy(ω) = |G(ejω)|2γuu(ω) + γvv(ω)
(17.24)
We shall learn in Chapter 20 that (17.24) facilitates a method for estimating the disturbance spectrum
from the input-output data and an estimate of the plant FRF.
Estimation: The FRF is estimated using as the ETF presented in Chapter 5. However, the ETFE
suﬀers from the same shortcomings as that of a periodogram. The estimate is improved using
smoothing ideas in spectral density estimation. Refer to Chapter 20 for details.
Remarks:
Representations (17.19), (17.22), (17.23) and (17.24) constitute the non-parametric descriptions of
the LTI system, speciﬁcally the plant. The noise model is characterized by the disturbance spectrum γvv(ω)
in (17.24). As discussed in Chapters 4 and 5, these are good starting points in identiﬁcation since they make
minimal assumptions about the systems and also oﬀer valuable information on delay, stability, dynamics and
the order of the system. These pieces of information are then useful in identifying parametric models which
are usually parsimonious and structured representations of the LTI system.
17.5
PARAMETRIC DESCRIPTIONS
Parametric descriptions of the input-output system in (17.16) arise by parametrizing the plant and
noise models, G(q−1) and H(q−1). As shown in Chapter 4, this is equivalent to parametrizing the
responses of the respective sub-systems. While there exist numerous ways of parametrizing G and
H, the rational polynomial transfer function representations are widely used:
G(q−1,θ) =
B(q−1)
A(q−1)F(q−1) ;
H(q−1,θ) =
C(q−1)
A(q−1)D(q−1)
(17.25)
where it is assumed that all polynomials above are co-prime (no zero-pole cancellations), and
A(q−1) :
1 + a1q−1 + · · · + anaq−na
B(q−1) :
bnk q−nk + bnk+1q−nk−1 + · · · + bnk+nb−1q−(nb−1−nk )
nk ∈{Z+ ∪0} :
Input-output delay (in samples)
C(q−1) :
1 + c1q−1 + · · · + cnc q−nc
D(q−1) :
1 + d1q−1 + · · · + dnd q−nd
θ :
[ a1
· · ·
ana
b0
· · ·
bnb−1
c1
· · ·
cnc
d1
· · ·
dnd
f1
· · ·
fn f ]T
(17.26)

Non-Parametric and Parametric Models for Identiﬁcation
487
Identiﬁcation of (17.25) involves estimation of the parameter vector θ for speciﬁed values of delay
nk and polynomial orders.
The representation in (17.25) existed in specialized forms (to be discussed shortly) for several
decades in the time-series literature before the generalized form was introduced by Box and Jenkins
in 1970s; see Box, Jenkins and Reinsel (2008). The model was further popularized by the works of
Ljung (1976b, 1978) and Ljung and Caines (1979) in the prediction-error framework, subsequent to
which the model structure came to be known about as the prediction-error model.
Understanding the model
i. Observe that all denominator polynomials have their leading coeﬃcients ﬁxed to unity. The rea-
son for this setting was discussed in Chapters 4 and 11 in the context of deterministic and stochas-
tic models, respectively. Essentially, these coeﬃcients translate to the coeﬃcient of y[k] when
(17.25) is written as a diﬀerence equation. This coeﬃcient is non-identiﬁable. Hence the choice.
ii. The A(.) polynomial characterizes the common dynamics present in the plant and noise subsys-
tems. If there is none, then A(q−1) = 1. In such a case, the plant and noise models are said to be
independently parametrized.
iii. The input-output delay represented by nk is, in general, at least one sample due to the presence
of ZOH. However, whenever there is a feedthrough path, instantaneous eﬀects are present, i.e.,
nk = 0.
iv. Polynomial B(.) represents the numerator dynamics, i.e., how the input interacts with the system.
The leading coeﬃcient, which is determined by the input-output delay, has to be identiﬁed from
data. Characteristics such as inverse response, or non-minimum phase behavior, are explained
by the B polynomial. Observe that it contains nb coeﬃcients. For convenience, introduce n′
b =
nk + nb −1 so that the last coeﬃcient is bn′
b.
v. Complementary to B, the factor F() in the denominator of the plant model accounts for the
dynamics of the plant that are unique to it.
vi. The numerator polynomial C(q−1) of the noise model, as we know from Chapter 9, accounts for
the moving average characteristics of the random process v[k]. Similarly, D(q−1) characterizes
the auto-regressive behavior of v[k].
vii. In practice, the parametric model is written in a diﬀerence equation form for the purposes of
prediction (of y[k]) and estimation (of θ).
Predictions, prediction errors and simulation
One of the main purposes of developing models is prediction. Predictions are computed numerically
during and after model training, and symbolically while setting up the estimation problem to develop
expressions for prediction errors. Therefore, it is necessary to know how to derive a predictor form
for a given model structure. Chapter 18 presents the theory and procedure for developing predictor
expressions from a model described by (17.2). With a little sacriﬁce on the pedagogical ﬂow of this
text, the ﬁnal expression is provided below in advance.
Denoting the one-step ahead prediction by ˆy[k|k −1], we have
ˆy[k|k −1] = H−1(q−1)G(q−1)u[k] + (1 −H−1(q−1))y[k]
(17.27)
Observe that the predictor is built purely from the input-output data and the model (G, H). Further-
more, the inverse of the noise model has a signiﬁcant role to play in the prediction. From (17.27),
we can also obtain an expression for the one-step ahead prediction error,
ε[k|k −1] ≜y[k] −ˆy[k|k −1] = H−1(q−1)(y[k] −G(q−1)u[k])
(17.28)

488
Principles of System Identiﬁcation: Theory and Practice
B
A
1
A
u[k]
e[k]
y[k]
+
+
v[k]
FIGURE 17.2
Schematic representation of an ARX structure.
An important fallout of (17.28) is that the white-noise driving force in (17.2) is also the theoretical
one-step ahead prediction error.
e[k] = ε[k|k −1]
(17.29)
For this reason, the general model structure in (17.2) or (17.25) is known as the prediction-error
model. In addition, the white-noise process is also known as the innovations.
Associated with the notion of prediction is the concept of simulation, which is essentially inﬁnite-
step ahead prediction. As we shall show in §18.4, the simulated response of any LTI parametric
model is given by
ˆysim[k] = ˆy[k| −∞] = G(q−1)u[k]
(17.30)
The main diﬀerence between p-step ahead (p < ∞) and the inﬁnite-step ahead prediction, i.e.,
simulation is that the latter does not take any process measurement into account in its computation.
Remarks:
Equation (17.30) essentially implies that simulation completely ignores the noise characteristics;
in fact, it is simply the response of the deterministic sub-system.
In the sections to follow, we shall study the diﬀerent model structures that the prediction-error
model of (17.25) begets for diﬀerent choices of the polynomials. The main purpose is to understand
the implications of choosing each structure on modeling and estimation.
17.5.1
EQUATION-ERROR MODELS
The ﬁrst set of models of interest is the equation-error model family. This structure arises when
F(q−1) = 1 = D(q−1). Further specializations emerge depending on whether C = 1 or not.
17.5.1.1
ARX Family
The parametric description known as the Auto-Regressive eXogenous (ARX) model is obtained by
setting C = D = 1 = F.
y[k] = B(q−1)
A(q−1) u[k] +
1
A(q−1) e[k]
(17.31)
Figure 17.2 shows a pictorial representation of this structure. The noise corrupting the output is a
ﬁltered white-noise, where the ﬁlter has the same characteristics as the process. The reason for its
name is understood by examining its diﬀerence equation form.

Non-Parametric and Parametric Models for Identiﬁcation
489
Features of ARX model
i. Diﬀerence equation form: Using the shift-operator deﬁnition and expanding the polynomials, we
obtain
y[k] + a1y[k −1] + · · · + ana y[k −na] = bdu[k −nk] + · · · + bn′
bu[k −n′
b] + e[k]
(17.32)
where n′
b = nb −1+nk. Since the white-noise enters the diﬀerence equation for the measurement,
it is also known as the equation-error model. A total of na + nb parameters have to be estimated.
Referring to the orders and delay of the diﬀerence equation form, we shall denote the structure
in (17.32) as ARX(na,nb) model with a delay nk.
Observe that the FIR model is also a member of the ARX family when na = 0, i.e., when no
regressive terms are included. Thus, the FIR model can be viewed as both a non-parametric and
a parametric model.
ii. Predictor: The one-step ahead predictor for the ARX model, using (17.27), is
ˆy[k|k −1] = B(q−1)u[k] + (1 −A(q−1))y[k]
= bdu[k −nk] + · · · + bn′
bu[k −n′
b] −a1y[k −1] −· · · −ana y[k −na]
(17.33)
The one-step ahead prediction error is given by (17.28)
ε[k|k −1] = A(q−1)y[k] −B(q−1)u[k]
(17.34)
iii. Regression form: Writing the predictor in linear regression form is useful for estimation.
Prediction-error methods (such as LS) make use of this regression form extensively. The pre-
dictor in (17.33) can be cast as
ˆy[k] = ϕT[k]θ
ϕ[k] =
f
−y[k −1]
· · ·
−y[k −na]
u[k −nk]
· · ·
u[k −n′
b]
gT
θ =
f
a1
· · ·
ana
bnk
· · ·
bn′
b
gT
(17.35)
In constructing the regressor or using the predictor (17.33), past values of outputs and inputs are
required. This situation can be handled in diﬀerent ways. Section 22.6.2 reviews these options.
iv. Estimation: Observe that the predictor is linear in unknowns. This is attractive since from Chap-
ter 14 we know that LS estimation produces a unique estimate of θ with a closed-form expression
available. ARX models can be therefore estimated using OLS methods. Moreover, one can esti-
mate ARX models of diﬀerent orders simultaneously (see §21.6.1.1). These are the reasons for
its widespread popularity in identiﬁcation. See §21.6.1 for details.
v. Plant and noise model coupling: A major shortcoming of the ARX model is that the noise model
has no independent parametrization. It is completely tied to the plant model. In reality, it is rare
to ﬁnd systems that have these characteristics. Moreover, the scope of processes that it can pos-
sibly explain is also limited since C = 1. However, the convenience of estimating this structure
signiﬁcantly outweighs these shortcomings in practice.
Next we study an enhancement of the ARX model by the inclusion of a moving average term in
the model, i.e., by letting C , 1.
17.5.1.2
ARMAX Family
This model family is an extension of the ARX family of models to incorporate a moving average
term (in the noise model).
y[k] = B(q−1)
A(q−1) u[k] + C(q−1)
A(q−1) e[k]
(17.36)

490
Principles of System Identiﬁcation: Theory and Practice
It can also be viewed as an extension of the ARMA model to include the eﬀects of exogenous
inputs. Naturally it acquires the name Auto-Regressive Moving Average eXogeneous (ARMAX)
model. Figure 17.3 depicts the working of this model. The noise is modelled as an ARMA process
with the same auto-regressive characteristics as that of the plant.
B
A
C
A
u[k]
e[k]
y[k]
+
+
v[k]
FIGURE 17.3
Schematic representation of an ARMAX structure.
Features of ARMAX model
i. Diﬀerence equation form: Using the same procedure as in ARX, we have
y[k] + a1y[k −1] + · · · + ana y[k −na] = bnku[k −nk] + · · · + bn′
bu[k −n′
b]
+ c1e[k −1] + · · · + cnc e[k −nc] + e[k]
(17.37)
where n′
b = nb −1 + nk. The equation-error is now colored unlike in ARX model. Thus, an
ARMAX model is an equation-error structure with a moving average model for the equation
error. It is characterized by a total of na + nb + nc parameters. As in the case of ARX, we shall
denote (17.37) as ARMAX(na,nb,nc) with a delay of nk samples.
ii. Predictor: The one-step ahead predictor using (17.27) is
ˆy[k|k −1] = B(q−1)
C(q−1)u[k] +
 
1 −A(q−1)
C(q−1)
!
y[k]
which can then be re-arranged to give,
ˆy[k|k −1] = bnku[k −nk] + · · · + bn′
bu[k −n′
b] −a1y[k −1] −· · · −ana y[k −na]
+ c1ε[k −1] + · · · + cnc ε[k −nc]
(17.38)
Notice that now the predictor is non-linear in unknowns. The prediction error is itself a function
of θ. It is given by
ε[k|k −1] =
1
C(q−1) (A(q−1)y[k] −B(q−1)u[k])
(17.39)
Introducing
yf [k] =
1
C(q−1) y[k]; uf [k] =
1
C(q−1)u[k]
(17.40)
allows us to obtain a diﬀerent perspective of (17.39)
ε[k|k −1] = A(q−1)yf [k] −B(q−1)uf [k]
(17.41)

Non-Parametric and Parametric Models for Identiﬁcation
491
Thus, the ARMAX model is equivalent to an ARX model on pre-ﬁltered data with the pre-ﬁlter
being L(q−1) = 1/C(q−1).
yf [k] = B(q−1)
A(q−1) uf [k] +
1
A(q−1) e[k]
(17.42)
This is a very useful result for theoretical analysis as well as in estimation (see below).
iii. Regression form: Given that the predictor (17.38) is non-linear in unknowns, we can only think
of a pseudo-linear regression (PLR, recall §14.4.2) form:
ˆy[k] = ϕT[k,θ]θ
ϕ(k,θ) = [−y[k −1]
· · ·
−y[k −na]
u[k −nk]
· · ·
u[k −n′
b]
ε[k −1]
· · ·
ε[k −nc]]T
θ =
f
a1
· · ·
ana
bnk
· · ·
bn′
b
c1
· · ·
cnc
gT
(17.43)
(17.44)
The dependence of the regressor on θ stems from the fact the prediction errors have to be known
to construct it. A common method is to ﬁrst build an ARX model and then initialize the regressors
with the prediction errors of the ARX model. As in the case of ARX, the initial conditions have
to be known, which are discussed in §22.6.2.
iv. Estimation: We had earlier noticed that predictor is non-linear in unknowns. Thus, a non-linear
LS estimator has to be used. Consequently, only local optima (for the parameter estimates) are
obtained. Alternatively, an iterative OLS method with pre-ﬁltering of data can also be used. The
ARMAX model is a linear regression model with colored error. Therefore, an iterative weighted
least squares method with an appropriate weighting can also be used (recall Example 14.7). See
Chapter 21 for more details.
v. Plant and noise model coupling: The ARMAX model enhances the scope of ARX modeling with
its moving average term. It brings in some ﬂexibility to the noise model. For this reason, it is a
popular model in industrial processes. The beneﬁts of an ARMAX structure is also accompanied
by an increased estimation complexity (more parameters, non-linear predictor).
17.5.1.3
ARIMAX Models
The ARMAX structure can be tailored to incorporate non-stationarities by incorporating integrating
eﬀects much as like an ARMA model was extended to an ARIMA model (recall §9.7). Here we
obtain an ARIMAX model
y[k] = B(q−1)
A(q−1) u[k] +
C(q−1)
(1 −q−1)dD(q−1) e[k]
(17.45)
where d represents the number of poles at unity circle. For a large range of process, d is typically at
most 2. As discussed in §9.7, it also represents the degree of diﬀerencing.
An alternative viewpoint is that it is an ARMAX model on diﬀerenced data:
∇dy[k] = B(q−1)
A(q−1) ∇du[k] + C(q−1)
D(q−1) e[k]
(17.46)
where ∇= 1 −q−1 is the diﬀerencing operator.
Models (17.45) and (17.46) can describe integrating eﬀects in the noise model. However, the plant
model can also contain integrating eﬀects. Two possibilities arise:

492
Principles of System Identiﬁcation: Theory and Practice
Plant and noise sub-systems have integrating eﬀects of the same order:
∇dy[k] = B(q−1)
A(q−1) u[k] + C(q−1)
D(q−1) e[k]
(17.47)
Only the plant sub-system contains integrating eﬀects:
∇dy[k] = B(q−1)
A(q−1) u[k] + ∇dC(q−1)
D(q−1) e[k]
(17.48)
Remarks:
ARIMAX models have to be used only when really necessary since they involve diﬀerencing of
measured data, which is equivalent to high-pass ﬁltering of data. Consequently, the noise eﬀects relative to
those of the input are enhanced, eﬀectively decreasing the SNR. Chapter 22 explains these aspects with an
example.
There exist other variants of equation-error models such as ARARX models suited for specialized
processes (see Ljung (1999, Chapter 4)).
We now turn to a contrasting and powerful model structure, glimpses of which were given in
Chapter 2.
17.5.2
OUTPUT-ERROR FAMILY
The output-error (OE) model, as the name suggests, assumes that the white-noise directly aﬀects
the output. Stated diﬀerently, H = 1. There is no attempt to model the noise characteristics:
y[k] = B(q−1)
F(q−1)u[k] + e[k]
(17.49)
Figure 17.4 illustrates this representation. The assumption on the noise model may seem too re-
strictive, but a major beneﬁt is that we obtain the best estimate of the transfer function G. We shall
establish this fact theoretically in Chapter 21.
B
F
u[k]
e[k]
y[k]
+
+
v[k]
FIGURE 17.4
Schematic representation of a OE structure.
Features of OE models
i. Diﬀerence equation form: The OE structure can be described by
y[k] + f1y[k −1] + · · · + fn f y[k −nf ] = bnku[k −nk] + · · · + bn′
bu[k −n′
b]
+ f1e[k −1] + · · · + fn f e[k −nf ] + e[k]
(17.50)
where n′
b = nb −1 + nk. A total of nb + nf parameters have to be estimated. The model shall be
denoted as OE(nb,nf ) with a delay of nk samples.
It is easy to see that the OE model is a special case of ARMAX model with C = A = F.
Fundamentally, of course, the philosophies underlying these two structures are diﬀerent.

Non-Parametric and Parametric Models for Identiﬁcation
493
ii. Predictor: The one-step ahead predictor using (17.27) is
ˆy[k|k −1] = B(q−1)
F(q−1)u[k]
(17.51)
The prediction is solely based on inputs. There is no feedback from measurements to the predictor
unlike in (17.33) and (17.38). We shall learn in Chapter 18 that (17.51) is the inﬁnite-step ahead
prediction for any parametric model. In other words, the one-step and the inﬁnite-step ahead
predictions coincide for an OE model. This is the unique characteristic of OE models. Since
the predictor solely focuses on the deterministic portion, this structure has an advantage under
open-loop conditions in that it yields best estimates of the plant transfer function (see §21.5).
Technically, the inﬁnite-step ahead prediction is also known as simulation (see Chapter 18).
The recursive equation for the predictor is
ˆy[k|k −1] = bnku[k −nk] + · · · + bn′
bu[k −n′
b] −f1 ˆy[k −1] −· · · −fn f ˆy[k −nf ]
(17.52)
In order to implement the predictor, initial values of the predictions are required. These can
be generated initially from an ARX model for instance. A slightly diﬀerent viewpoint can be
achieved by introducing an intermediate variable ξ[k] ≜(B(q−1)/F(q−1))u[k], so that
ξ[k] = bnku[k −nk] + · · · + bn′
bu[k −n′
b] −f1ξ[k −1] −· · · −fn f ξ[k −nf ]
(17.53a)
ˆy[k] = ξ[k]
(17.53b)
The ξs are also known as the instrumental variables. The prediction error for the OE model is
ε[k|k −1] = y[k] −B(q−1)
F(q−1)u[k]
(17.54)
As in the case of ARMAX model, the OE model can be viewed from a pre-ﬁltering viewpoint.
Introducing
yf [k] =
1
F(q−1) y[k]; uf [k] =
1
F(q−1)u[k]
(17.55)
allows us to write (17.54)
ε[k|k −1] = F(q−1)yf [k] −B(q−1)uf [k]
(17.56)
Thus, the OE model is equivalent to an ARX model on pre-ﬁltered data with the pre-ﬁlter being
L(q−1) = 1/F(q−1).
yf [k] = B(q−1)
F(q−1)uf [k] +
1
F(q−1) e[k]
(17.57)
Alternatively, the ARX model in (17.31) can be written as
A(q)y[k] = B(q−1)
A(q−1) (A(q−1)u[k]) + e[k]
(17.58)
Thus, the ARX model may be viewed as an OE model on pre-ﬁltered data with the pre-ﬁlter being
L(q−1) = A(q−1).
Once again, these are useful results in theoretical analysis as well as in estimation (see below and
in Chapter 21).

494
Principles of System Identiﬁcation: Theory and Practice
iii. Regression form: A pseudo-linear regression form for the OE model is:
ˆy[k] = ϕT[k,θ]θ
ϕ[k,θ] =
f
u[k −nk]
· · ·
u[k −n′
b]
−ξ[k −1]
· · ·
−ξ[k −nf ]
g
]T
θ =
f
bnk
· · ·
bn′
b
f1
· · ·
fn f
gT
where the ξs are the instrumental variables. A common approach is to initialize the regressors
with predictions from a model such as the ARX.
iv. Estimation: The OE model can be estimated in a number of diﬀerent ways. A non-linear least
squares method using analytical expressions for the predictor derivatives is generally used. The
pre-ﬁltering viewpoint is used to derive an iterative method by solving an OLS at each step. This
is known as the Stieglitz-McBride method. On the other hand, the OE model is a special case
of the ARMAX model, thereby giving it the ﬂavor of a linear regression model with colored
equation error. Thus, an iterative weighted least-squares method can be used. See Chapter 21 for
technical details of these algorithms.
v. Plant and noise model coupling: The OE model makes no attempt to describe the noise charac-
teristics. Instead it is tuned to explain the input eﬀects alone. Therefore, under open-loop condi-
tions, we can expect the optimally trained OE model to result in an unbiased estimate of the plant
model. All other models bias themselves to a certain frequency region determined by the inverse
of the noise model H−1(q−1). This fact is technically established in §21.5.
Realistically, a large class of processes lend themselves to the OE model. An advantage of the OE
structure is that for non-OE type processes, one obtains unbiased estimate of the plant model. The
noise characteristics can then be analyzed from the residuals using time-series approaches. These
two pieces of information can then be used to initialize a more general model structure such as the
Box-Jenkins model.
17.5.3
BOX-JENKINS FAMILY
The Box-Jenkins (BJ) structure introduced by Box, Jenkins and Reinsel (2008) resorts to an inde-
pendent parametrization of the plant and noise models. It is one of the most general structures.
y[k] = B(q−1)
F(q−1)u[k] + C(q−1)
D(q−1) e[k]
(17.59)
The BJ model is illustrated in Figure 17.5. An obvious advantage of this structure is that it is
equipped to handle a wide variety of LTI processes. However, the modeling complexity is also
increased. The user is required to guess orders of four diﬀerent polynomials, for which the usual
approach is a trial-and-error method combined with information theoretic criteria.
Features of BJ models
i. Diﬀerence equation form: The BJ structure is described easier by introducing ξ[k]
=
B(q−1)/F(q−1)u[k],
ξ[k] + f1ξ[k −1] + · · · + fn f ξ[k −nf ] = bnku[k −nk] + · · · + bn′
bu[k −n′
b]
v[k] + d1v[k −1] + · · · + vndv[k −nd] = c1e[k −1] + · · · + cnc e[k −nc] + e[k]
y[k] = ξ[k] + v[k]
(17.60)
where n′
b = nb −1 + nk. The form in (17.60) is reminiscent of a state-space representation. The
BJ model is parametrized by a total of nb + nc + nd + nf parameters. As with other structures,
the BJ model in (17.60) shall be denoted as BJ(nb,nc,nd,nf ) with a delay of nk samples.

Non-Parametric and Parametric Models for Identiﬁcation
495
B
F
C
D
u[k]
e[k]
y[k]
+
+
v[k]
FIGURE 17.5
Schematic representation of a BJ structure.
ii. Predictor: The one-step ahead predictor using (17.27) is
ˆy[k|k −1] = D(q−1)
C(q−1)
B(q−1)
F(q−1)u[k] +
 
1 −D(q−1)
C(q−1)
!
y[k]
(17.61)
while the one-step ahead prediction error is
ε[k|k −1] = D(q−1)
C(q−1)
 
y[k] −B(q−1)
F(q−1)u[k]
!
(17.62)
As with other models, the BJ model can be viewed from a pre-ﬁltering viewpoint. Introducing
yf [k] = D(q−1)
C(q−1) y[k]; uf [k] = D(q−1)
C(q−1) u[k]
(17.63)
allows us to re-write (17.62) as
ε[k|k −1] = yf [k] −B(q−1)
F(q−1)uf [k]
(17.64)
Thus, the BJ model is equivalent to an OE model on pre-ﬁltered data with the pre-ﬁlter being
L(q−1) = D(q−1)/C(q−1).
yf [k] = B(q−1)
F(q−1)uf [k] + e[k]
(17.65)
This is a useful result for theoretical analysis, while not as much in estimation.
iii. Regression form: A pseudo-linear regression form for the BJ model based on (17.60) is realized
as (by writing ˆy[k] = ˆξ[k] + ˆv[k]),
ˆy[k] = ϕT[k,θ]θ
ϕ[k,θ] = [ u[k −nk]
· · ·
u[k −n′
b]
ε[k −1]
· · ·
ε[k −nc]
v[k −1]
· · ·
v[k −nd]
−ξ[k −1]
· · ·
−ξ[k −nf ] ]T
θ = [ bnk
· · ·
bn′
b
c1
· · ·
cnc
d1
· · ·
dnd
f1
· · ·
fn f ]T
where the ξ[k]’s are the artiﬁcial variables introduced in (17.60) and v[k]’s are the disturbances.
As before, the pseudo-linear regressor is initialized using an initial guess of the polynomials.

496
Principles of System Identiﬁcation: Theory and Practice
TABLE 17.1
Classes of parametric models as special cases of the PEM family (17.25)
Model
Polynomial values
FIR
A(q) = 1; F(q) = 1; C(q) = 1; D(q) = 1
ARX
F(q) = D(q) = A(q); C(q) = 1
ARMAX
F(q) = D(q) = A(q)
OE
A(q) = 1; C(q) = D(q) = 1
BJ
A(q) = 1
iv. Estimation: The BJ model is estimated using a non-linear least squares method. Analytical ex-
pressions for the predictor derivatives are given in Chapter 21. A PLR approach can also be used
to estimate the parameters.
v. Plant and noise model coupling: From the description (17.59), this is perhaps the best possible
way to model the plant and noise sub-systems. But the price paid is the modeling complexity.
As mentioned earlier, there is an increased burden on the number of parameters and orders to be
determined. The BJ model is usually not the ﬁrst choice in identiﬁcation. See some guidelines
below.
Table 17.1 summarizes the special cases of the PEM family that have been studied in Sections
17.5.1 through 17.5.3.
17.5.4
SELECTING AN APPROPRIATE MODEL STRUCTURE
Parametrization of G and H facilitates a parsimonious representation of the system (when compared
with the non-parametric description). However, the user is confronted with the challenge of selecting
the “right” model structure for a given application. There exists no deﬁnitive formula or answer to
this question. Nevertheless, understanding the implications of choosing a particular structure from
the (i) data-ﬁtting and (ii) process modeling perspectives greatly aids the user in making an informed
decision.
i. Coupling between G and H: Selecting a particular structure implicitly amounts to assuming
certain interplay between the plant and noise dynamics. The polynomials are vehicles through
which the model explains the plant and noise characteristics to achieve the overall data ﬁtting
objective (typically of minimizing prediction errors). For example, with the setting A = 1, the
(BJ) model has the freedom to independently explain the input and noise eﬀects, but the price
paid is the complexity of the resulting optimization problem. On the other end is the ARX model
which severely constrains the parametrization but oﬀers mathematical convenience.
ii. Bias distribution: Consequent to the facts stated above, we can show that choosing a
model structure essentially amounts to a compromise between minimizing the weighted bias,
W(ejω)|G0(ejω) −G(ejω)|2 and explaining the output-error spectrum (see Chapter 21). The
weighting function W(ejω) =
γuu(ω)
|Hθ⋆(ejω)|2 where θ⋆is the optimum. For output-error mod-
els, the bias is shaped completely by the input alone, which is typically chosen based on system
bandwidth considerations. All other model structures result in an emphasis of diﬀerent frequency
range than that considered by the input design. Therefore, an output-error model may be the pre-
ferred estimator for the transfer function G.

Non-Parametric and Parametric Models for Identiﬁcation
497
iii. Ease of estimation: From our earlier discussions, it is easy to observe that certain model structures
are easier to estimate than the other. The ARX (and hence the FIR) structure is particularly noted
for its ease of estimation because the associated predictor is linear. This aspect makes these
models as favorable structures, at least, as initial choices.
In view of the above factors, the following recommendations can be made.
Typically the user has limited knowledge of the process dynamics a priori and relies on the data
to discover the same. Therefore, a good starting point is the ARX structure. However, where the
highly restrictive parametrization of ARX is a concern, a strongly recommended initial choice is the
OE structure since it facilitates the best estimate of the plant model. Subsequently, if the residuals
show evidence to reject the hypothesis of H = 1, a time-series approach can be used to build a
noise model. The resulting estimates of G and H can be jointly improved by ﬁtting a BJ structure.
An alternative approach for determining an appropriate parametric model is to begin with a state-
space model as was illustrated in Chapter 2. An added advantage is that the order can be determined
systematically without the need for a trial-and-error approach. In all these approaches, the guiding
light is always the set of model diagnostics.
Chapter 22 oﬀers further guidelines on this topic with illustrative examples and the review of a
method known as AUDI for simultaneous estimation of ARX model structures.
17.6
SUMMARY
In this chapter we learnt the various input-output model structures that are popularly used in identiﬁ-
cation. We studied two classes, namely, the non-parametric and parametric models. The former set
of models oﬀer a typical starting point in identiﬁcation since they can be built with minimal process
knowledge while providing valuable information for developing parametric models. Parametriza-
tion of (17.2) leads to diﬀerent families of parametric descriptions, the various features of which we
studied in detail. These diﬀerent families can be brought under a larger umbrella of the prediction-
error models. The choice of a particular family or structure is driven by three factors, namely, the
coupling of plant and noise parametrizations, ease of estimation and bias considerations. In one
school of thought, the ARX model is the preferred initial choice while in another, the OE model is
preferable. However, an interesting result is that these diﬀerent model structures are equivalent to
each other under the umbrella of pre-ﬁltering. This equivalence is useful for theoretical analysis as
well as in devising estimation algorithms. State-space descriptions (discussed in Chapter 23) oﬀer a
third alternative in guiding the user to a suitable parametric model.
Finally, it is also possible to consider other input-output parametric models by representing
the data in a diﬀerent basis space. The case of orthonormal basis functions (e.g., Laguerre and
wavelets) has attracted considerable attention in the identiﬁcation community. These representa-
tions are brieﬂy discussed in Part V.
REVIEW QUESTIONS
R17.1 Describe the general LTI representation of a deterministic-plus-stochastic system. List the as-
sumptions made.
R17.2 Deﬁne the generalized expectation operator. In what sense is it generalized?
R17.3 Deﬁne quasi-stationarity. What is the primary motivation for introducing it?
R17.4 Give examples of quasi-stationary signals.
R17.5 What are the diﬀerent non-parametric descriptions of an LTI system? Compare and contrast their
uses.
R17.6 Why are parametric models given that name?

498
Principles of System Identiﬁcation: Theory and Practice
R17.7 Discuss the ARX structure and its features.
R17.8 How are the diﬀerent parametric models related through pre-ﬁltering?
R17.9 Compare and contrast the OE model with the ARX structure. Which is a preferable model in
identiﬁcation?
R17.10 What is the pseudo-linear regression form? Which class of models can be casted into this form?
R17.11 Describe the ARIMAX family of models. Where are they used?
R17.12 Discuss the BJ family of models and their merits/demerits.
R17.13 List and discuss the salient considerations for model selection.
EXERCISES
E17.1 Determine the pseudo-linear regression form for the general PEM structure in (17.25).
E17.2 The ARARX structure assumes an auto-regressive model for the standard equation-error model.
Write the resulting description and discuss its features.
E17.3 Show that (deterministic) periodic signals are quasi-stationary.
E17.4 A process behaves according to the following relationship
y[k]
=
b0
1u[k −1] + b0
2u[k −2] +
1 + c0
1q−1
1 + d0
1q−1 w[k]
where w[k] is a zero-mean, white-noise sequence of variance σ2w. Input-output data is collected with
white-noise input of variance σ2u.
If it is decided to ﬁt an FIR model such that the predictor is ˆy[k|k −1] = b1u[k −1] + b2u[k −2] to
the above process,
a. Derive the expression for the least squares estimates of b1 and b2 in terms of the original
parameters, σ2u and σ2w.
b. What can you say about the bias of the estimates ˆb1 and ˆb2?
c. Would you have been able to answer part (b) without answering part (a)?

18
Predictions
In this short chapter, we shall study the basic results in prediction theory. Of particular interest
are (i) the general expressions for one-step and p-step ahead predictions of the parametric
model discussed in Chapter 17 and (ii) the predictor model description for an LTI system.
18.1
INTRODUCTION
One of the central aims of modeling is prediction. To this eﬀect, models are trained to achieve as
good predictions as possible by choosing the decision variables (model parameters) so that a chosen
norm of prediction errors (typically the squared 2-norm) is minimized. Therefore, it is important to
formally study the concept of prediction and learn the mathematics of developing predictor expres-
sions for a given model structure. This chapter is devoted to this purpose.
The fundamental prediction problem is stated as follows.
Given an information set, known as the data set, Z, ﬁnd the best prediction of a (random)
variable Y.
The data set Z comprises measurements of all variables that are potentially informative about Y. In
time-series forecasting for instance, Z consists of N past measurements of Y, while Y itself is y[k].
The prediction problem assumes diﬀerent forms depending on the application:
i. Identiﬁcation: Z consists of past observations of input-output data and y[k] is the output at the
present instant.
ii. Smoothing: Z consists of past as well as future data and y[k] is the signal at the present instant.
This is of course suited only for oﬄine applications.
iii. Static regression: Z is the set of regressors or explanatory variables at the same instant as y[k],
which is the predicted variable.
The main challenge in prediction is, usually, the presence of stochasticity or uncertainty in Z and
/ or Y. Deterministic signals, especially in deterministic chaotic systems, also present considerable
challenges.
Prediction theory is a subject with rich history. The concepts have their roots in the milestone
results of the early twentieth century due to the concerted eﬀorts of several researchers (Wiener,
Kolmogorov, Wold and Cramer to name a few). Gauss’s method of predicting planetary motions us-
ing the LS approach can also be considered as one of the ﬁrst documented eﬀorts for prediction. In
time-series analysis, forecasting is the technical term for prediction. A cornerstone result in predic-
tion theory is that the conditional expectation is the best predictor in the mean square error sense.
However, this result holds more theoretical importance and less practical utility since the knowledge
of joint p.d.f.s is essential for computations of conditional expectations. Moreover E(Y |Z) can be a
complicated non-linear function of Z. Consequently, a large body of literature is built around deter-
mining the best linear predictors. In the modern era, there has been an emerging growth of theory
of non-linear predictors based on concepts from learning theory (machine, inductive and iterative
learning), Bayesian methods, etc. However, it is far from reaching the maturity of linear prediction
theory.
499

500
Principles of System Identiﬁcation: Theory and Practice
The following sections outline the classical results in prediction theory and illustrate their use in
identiﬁcation. We shall mostly restrict our study to linear predictors. For the sake of completeness
and to gain a better appreciation of the subject, we shall ﬁrst introduce the conditional expectation
result.
The focal point of this chapter is the development of the one-step and p-step ahead prediction
error expressions for the LTI models described in Chapter 17. An important point that we shall learn
is that predictors are alternative forms of model descriptions. The concluding section of this chapter
expands on this point.
In passing, it is useful to recall that prediction belongs to the larger problem of estimation. Thus,
the concepts of bias, variance, best unbiased linear predictor, and MMSE prediction apply to pre-
dictors as well.
18.2
CONDITIONAL EXPECTATION AND LINEAR PREDICTORS
A remarkable result in prediction (or estimation) theory is concerning the best approximation of Y
given another random variable Z. The result is a direct consequence of the decomposition theorem
14.8.
Among all the predictors of a random variable Y given another random variable Z, the predictor
ˆY⋆= g(Z) = E(Y |Z)
(18.1)
provides the optimal prediction of Y in the mean square error sense.
In other words, the conditional expectation is the minimum mean square error predictor (recall
Exercise E14.11). The result also applies to the multivariate case as well. It is useful to recall the
unconditional expectation, µY = E(Y), which is the minimum mean square error predictor of Y
when no additional information is available.
Note that E(Y |Z) is a (non-linear) function of the explanatory variable(s) Z. Thus, among all the
non-linear functions, the one in (18.1) is the best predictor in the MMSE sense.
Two important aspects
There are two aspects to the prediction of a time series as discussed below.
1. Sample size N: This is the number of observations available for prediction, typically containing
past data. Certain predictors require inﬁnite past, while others can work with ﬁnite past. For the
former class of predictors, using ﬁnite data introduces additional errors. However, for station-
ary processes, these errors are guaranteed to vanish whenever the time-series model H(q−1) is
invertible.
2. Prediction horizon l: We are interested usually in two diﬀerent types of forecasts, namely, the
short-term and the long-term forecasts. The one-step ahead prediction, belonging to the former,
is widely used in model estimation, where the parameters are optimized to minimize the one-step
ahead prediction errors. On the other extreme is the inﬁnite-step ahead prediction. We shall ob-
serve later that this is equivalent to simulation, meaning the actual past information is never used
but the predictions themselves are used recursively to generate the long-range forecasts. Models
may also be optimized to minimize l-step or inﬁnite-step ahead prediction errors depending on
the application in hand (e.g., in model predictive control).
The following examples illustrate the foregoing points.

Predictions
501
Example 18.1: Prediction of an AR(1) Process
Problem: Suppose that the stochastic signal v[k] is generated by an AR(1) process:
v[k] = −d1v[k −1] + e[k]
e[k] ∼GWN(0,σ2
e)
Find the best (i) one-step ahead and (ii) l-step ahead predictions.
Solution: In a one-step ahead prediction, given information up to (k −1), we are interested
in predicting v[k]. Denoting the prediction by ˆv[k|k −1] and using (18.1), we have
ˆv[k|k −1] = E(v[k]|k −1) = E(−d1v[k −1]|k −1) + E(e[k]|k −1) = −d1v[k −1]
(18.2)
where the second term is zero by deﬁnition. Thus, the one-step ahead prediction in this case
requires only the observation at k −1 and not of the inﬁnite past.
The l-step ahead prediction on the other hand is given by
ˆv[k + l|k −1] = E(v[k + l]|k −1) = −d1E(v[k −1]|k −l)
which upon recursive substitution of the AR(1) model equation yields
ˆv[k|k −l] = (−d1)lv[k −l]
(18.3)
If the given model is stable, so is the prediction. Observe that the inﬁnite-step ahead predic-
tion of this model is zero.
Now consider a contrasting case, the MA(1) process.
Example 18.2: Predictions of an MA(1) Process
Problem: Find the best (i) one-step and (ii) l-step ahead predictions of an MA(1) process:
v[k] = e[k] + c1e[k −1]
Solution: Applying the conditional expectation result we have
ˆv[k|k −1] = E(v[k]|k −1) = E(e[k] + c1e[k −1]|k −1) = c1E(e[k −1]|k −1)
(18.4)
The information available is the past of the series {v[k −1],v[k −2],· · · } from which it is
required to recover e[k −1] in the best possible manner. For this purpose, re-write the MA
model as
e[k] = v[k] −c1e[k −1]
= v[k] −c1(v[k −1] −c1e[k −2]) = · · · =
∞
X
j=0
(−c1) jv[k −j]
(18.5)
Thus, the recovery of e[k −1] requires inﬁnite past of v[k] and therefore the one-step ahead
prediction of the MA(1) process.
ˆv[k|k −1] = c1
∞
X
j=0
(−c1) jv[k −j]
(18.6)
The l-step (l > 1) ahead prediction of the MA(1) process is zero since
ˆv[k|k −1] = E(e[k] + c1e[k −1]|k −l) = 0
(18.7)
by deﬁnition of the white-noise process.

502
Principles of System Identiﬁcation: Theory and Practice
From the two examples above, we realize that an AR(P) process can be predicted using only ﬁnite
past whereas an MA(M) process requires inﬁnite past. Section 18.3 presents a formal approach to
the prediction of these models.
Observe that the prediction expression for an AR process is easier to implement whereas it is rela-
tively complicated for the MA case (since the source white-noise is unknown). The MA predictor is
best implemented using the innovations algorithm discussed later in this chapter. Predictions of an
MA model at initial times are prone to large errors since very few data is available, but, as remarked
earlier, with progress in time, these errors subside if the model is invertible.
Continuing with our discussion on the conditional expectation, its evaluation requires the knowl-
edge of p.d.f., f (y, z), since
E(Y |Z) =
Z
y f (y|z) dy
(18.8)
Unfortunately, the knowledge of the joint p.d.f. is seldom available and even diﬃcult to estimate
in practice. If the p.d.f. is unavailable, a stochastic model between y and z can be used to compute
the prediction E(Y |Z). Any such attempt, however, would lead to a sub-optimal solution because it
amounts to pre-supposing the form of E(Y |Z). Fortuitously, when Y and Z have a joint Gaussian
distribution, the prediction of Y using the best linear model (that which minimizes the mean square
prediction errors) is the same as the one given by conditional expectation. This is the support on
which the popularity of best linear predictors (BLP) rests.
The situation above is similar to the one we encountered in estimation theory. Finding an MMSE
or a MVUE estimator may be diﬃcult, but one can always devise the best unbiased linear estimator.
According to the Gauss-Markov theorem, the BLUE is MVUE when the data generating process is
linear and the observation errors are Gaussian.
To summarize, the conditional expectation of Y is the best predictor given Z. It can be evalu-
ated only when the joint p.d.f. or a model (probabilistic-plus-functional) relating Y to Z is known.
When neither is given, the best linear predictor can be constructed. The BLP coincides with the
conditional expectation when Y and Z have a jointly Gaussian distribution. The classical method
to determine the BLP for a stationary process is outlined in several texts (see Brockwell and Davis
(1991) and Shumway and Stoﬀer (2006) for example). We review below certain related concepts
that are particularly useful for constructing the likelihood function of ARMA models in §19.4.2.
18.2.1
BEST LINEAR PREDICTOR
The problem of ﬁnding the BLP is stated as follows.
Given n random variables W =
f
W1
W2
· · ·
Wn
gT, determine the best linear approxima-
tion function or predictor
PWY ≜ˆY (W1,· · · ,Wn) =
n
X
i=1
φniWi
(18.9)
which minimizes
E(Y −PWY)2
(18.10)
It is easy to recognize the above problem as the OLS formulation for the linear regression of Y
on W with the parameters φn =
f
φn1
· · ·
φnn
gT. Using the OLS solution in (14.31) (or the
projection theorem in Appendix 14.A.1), we have the BLP of Y
PWY = ˆφT
nW
where
ˆφn = Σ−1
WWΣYW
(18.11)

Predictions
503
where as usual ΣWW is the covariance matrix of W.
Applying (18.11) to arrive at the best one-step linear prediction of a time-series by choosing
v[n] ≡Y, and v[i −1] ≡Wi, i = n,· · · ,1 (notice the reverse order), we have
ˆφn = Σnσ(1)
n
(18.12a)
Pn
n−1v = ˆφnvn
(18.12b)
where Σn is the autocovariance matrix and σ(1)
n
=
f
σvv[1]
· · ·
σvv[n]
gT as in the Y-W solution
(9.39) and vn =
f
v[0]
v[1]
· · ·
v[n −1]
gT. Further, we have used the notation Pn
n−1v to denote
Pvnv[n].
The similarity of the solution to ﬁnding the best linear one-step prediction in (18.12a) to the Y-W
solution (9.39) is not surprising since the problem of ﬁnding the BLP is identical to determining an
AR(n) model for v[n]. Generally speaking,
Finding the one-step ahead BLP of v[k] from (n −1) past observations is equivalent to
determining the best AR(n) process for v[k].
The error in the one-step ahead prediction is given by
εn
n−1 = v[n] −Pn
n−1v
(18.13)
The variance of this prediction error is given by
λn
n−1 ≜var(εn
n−1) = σ2
v −σ(1)T
n
Σ−1
n σ(1)
n
(18.14)
Thus, λ1
0 is the variance of error in predicting v[1] using v[0], λ2
1 associated with predicting v[2]
using {v[0],v[1]}, and so on. Note that the best prediction of v[0] given no past is its expectation
itself, P0v[k] = E(v[k]). For a zero-mean series, therefore ε0 = v[k] =⇒λ0 = σ2
v.
Two useful results (in constructing the likelihood for ARMA models) in the context are:
1. The one-step ahead prediction errors associated with the BLPs of v[n1] and v[n2], n1 , n2 are
uncorrelated.
2. If v[k] is an ARMA process, i.e., v[k] = H(q−1)e[k], then the variance of the one-step ahead
prediction error can be expressed as
λn
n−1 = σ2
ern
n−1
(18.15)
where rn
n−1 is independent of σ2
e. This fact can be veriﬁed by evaluating the variance of the
prediction of v[0] given zero past. This is the variance of v[0] itself and equal to σ2
e
P∞
j=0 h2[j].
The BLP is illustrated by means of two examples, where for the purpose of illustration we assume
that the process generating v[k] is known. In reality this is not the case.
Example 18.3: BLP of an AR(1) Process
Given the ﬁrst two observations of a series, {v[1],v[0]} and that v[k] is generated by an
AR(1) process:
v[k] = −d1v[k −1] + e[k]
determine the BLP of (i) v[2] (one-step ahead) and (ii) v[3] (two-step ahead).

504
Principles of System Identiﬁcation: Theory and Practice
Using (18.12a), the optimal coeﬃcients of the one-step ahead BLP are given by
ˆφ2 = Σ−1
2 σ(1)
2
(18.16)
The supplied model is used to compute the factors on the RHS. For an AR(1) process, we
know that σvv[l] = −d1σvv[l −1], |l| ≥1 and σvv[0] = σ2e/(1 −d2
1).
Therefore,
Σ2 =
"σvv[0]
σvv[1]
σvv[1]
σvv[0]
#
= σvv[0]
" 1
−d1
−d1
1
#
;
σ(1)
2
= σvv[0]
"−d1
d2
1
#
(18.17)
yielding
ˆφ2 = Σ−1
2 σ(1)
2
=
"−d1
0
#
(18.18)
Thus, the coeﬃcients of the best one-step ahead BLP are that of the AR(1) model itself and
the BLP itself is
P2
1v = −d1v[1]
(18.19)
coinciding with the conditional expectation result of Example (18.1).
Proceeding in a similar way for the coeﬃcients of the two-step ahead BLP ˆv[3] = φ21v[1] +
φ22v[0] , we obtain
ˆφ2 = Σ−1
2 σ(2)
2
=
1
1 −d2
1
" 1
d1
d1
1
# " d2
1
−d3
1
#
=
"d2
1
0
#
(18.20)
giving the best two-step ahead linear predictor as
P3
1v = d2
1v[1]
(18.21)
which once again coincides with the prediction E(v[3]|{v[1],v[0]}) given in Example 18.1.
Consider now the case of making a one-step ahead prediction of an MA(1) process.
Example 18.4: BLP of an MA(1) Process
Given the ﬁrst two observations of a series, {v[1],v[0]} and that v[k] is generated by an
MA(1) process:
v[k] = e[k] + c1e[k −1]
determine the BLP of (i) v[2] (one-step ahead) and (ii) v[3] (two-step ahead).
Proceeding along similar lines as in Example 18.3, we obtain the coeﬃcients for the one-step
ahead BLP,
ˆφ2 = Σ−1
2 σ(1)
2
=
"1 + c2
1
c1
c1
1 + c2
1
#−1 "c1
0
#
=
1
1 + c2
1 + c4
1
"c1(1 + c2
1)
−c2
1
#
(18.22)
and the BLP is
ˆv[2|{v[1],v[0]}] = ˆφ21v[1] + ˆφ22v[0]
(18.23)
which is diﬀerent from the conditional expectation predictor (18.6) in Example 18.2. The
diﬀerence is expected since the predictor from conditional expectation is non-linear whereas
the one under study is linear.
Note that the BLP of v[2] is better than a truncation of (18.6) (see Exercise E18.1).
The ideas described above can be extended to the m-step ahead prediction algorithm (see
(Shumway and Stoﬀer, 2006)). It is convenient to re-write the predictor for v[n] in terms of the
one-step ahead prediction error made at v[n −1]. This is known as the innovations algorithm, the
basic ideas of which are presented in the following section.

Predictions
505
18.3
ONE-STEP AHEAD PREDICTION AND INNOVATIONS
In the ﬁrst part we shall learn the formal expressions for the one-step prediction of a process with no
exogenous eﬀects, i.e., the time-series case. Subsequently in the second part, this predictor is used
to arrive at the prediction expression for a general LTI system with input eﬀects.
18.3.1
PREDICTIONS OF THE STOCHASTIC PROCESS
Given a stationary (causal), invertible process
v[k] =
∞
X
j=1
h[n]e[k −n] + e[k] = H(q−1)e[k];
H(q−1) = 1 +
∞
X
n=1
h[n]q−n
(18.24)
we are interested in a formal expression for the one-step ahead prediction of v[k].
Following the procedure outlined in Example 18.2
ˆv[k|k −1] =
∞
X
1
h[n]e[k −n] = (H(q−1) −1)e[k]
(18.25)
The task is therefore to obtain a formal expression for the driving force e[k] in terms of the observed
series v[k]. At this point we invoke the invertibility property of H(q−1) so that we can write
e[k] = H−1(q−1)v[k] =
∞
X
j=0
˜h[j]v[k −j]
(18.26)
where {˜h[.]} is the IR sequence of the inverse model.
H−1(q−1) =
∞
X
j=0
˜h[j]q−j
(18.27)
Remarks:
It is not straightforward to arrive at (18.26) without invoking the invertibility property of H(q−1).
For formal proof, see Brockwell and Davis (1991). For an intuitive understanding, refer to the MA(1) process
of Example 18.2. The estimate of e[k] would become unbounded if |c1| > 1.
Substituting (18.26) into (18.25), we obtain
ˆv[k|k −1] = (1 −H−1(q−1))v[k]
(18.28)
On a ﬁrst glance, (18.28) may seem to require v[k] for predicting v[k]. But expanding H−1(q−1)
shows that this is not the case since the leading coeﬃcient of H−1(q−1) is unity.
Innovations
An interesting interpretation of the WN process e[k] is obtained by constructing the theoretical
prediction error using (18.24) and (18.25),
ε[k|k −1] = v[k] −ˆv[k|k −1] = e[k]
(18.29)
Thus, the white-noise sequence is the theoretical one-step ahead prediction error. For this reason,
e[k] is also referred to as innovations. It is the new unpredictable change contained in v[k] at each
instant.

506
Principles of System Identiﬁcation: Theory and Practice
Innovations algorithm
When v[k] is a causal AR(P) process, (18.28) yields
ˆv[k|k −1] =
P
X
n=1
(−d j)v[k −j]
(18.30)
Full-ﬂedged predictions can be made only from k = P onwards. Predictions at k = 0,· · · ,P −1 are
made with suitable initializations of v[k] (Brockwell and Davis, 1991).
For MA(M) processes, the predictor in (18.28) is more useful for theoretical analysis than for
practical implementation. This is because H−1(q−1) has inﬁnite-terms in its expansion and therefore
requires inﬁnite past of v[k]. Moreover, even with a truncated version (ﬁnite observations), the
number of terms on the RHS grows with time.
An elegant solution that is followed in practice is to replace the innovations e[k] in (18.25) with
the the one-step ahead prediction errors ε[k] based on the equivalence in (18.29). The prediction
errors are set to zero at negative times, ε[k] = 0,k < 0. For the MA(1) process.
ˆv[k|k −1] = c1e[k −1] = c1ε[k −1]
ε[k] = v[k] −ˆv[k|k −1]
(18.31)
Starting at k = 0 and initializing ε[−1] = 0, the one-step ahead predictions are
ˆv[0| −1] = c1ε[−1] = 0;
ε[0] = v[0] −0
ˆv[1|0] = c1ε[0];
ε[1] = v[1] −ˆv[1|0]
......
...
The generalization of the basic idea illustrated above leads to the well-known innovations algorithm
for the one-step ahead prediction of a stationary process, particularly suited for a MA process.
Classical texts on time-series analysis discuss this algorithm in great detail (see Brockwell and
Davis (1991) and Shumway and Stoﬀer (2006)).
We now turn to the main problem, which is that of the one-step ahead prediction of an LTI system
described by the model in (17.17).
18.3.2
PREDICTIONS OF THE OVERALL LTI SYSTEM
The starting point is the overall model in (17.17)
y[k] = G(q−1)u[k] + v[k]; v[k] = H(q−1)e[k]
(18.32)
Noting that the prediction of deterministic portion is simply G(q−1)u[k], we have from (18.28),
ˆy[k|k −1] = G(q−1)u[k] + ˆv[k|k −1] = G(q−1)u[k] + (1 −H−1(q−1))v[k]
(18.33)
However, v[k] is an unmeasured variable. To arrive at a practically useful expression, insert v[k] =
y[k] −G(q−1)u[k] into (18.33) and re-arrange to obtain
ˆy[k|k −1] = H−1(q−1)G(q−1)u[k] + (1 −H−1(q−1))y[k]
(18.34)
Once again, as in (18.28), y[k] is not really required to compute ˆy[k] since the leading coeﬃcient
of H−1(q−1) is unity. This is clearly seen in the convolution form of the predictor:
ˆy[k|k −1] =
∞
X
j=0
˜g[n]u[k −n] +
∞
X
j=1
˜h[n]y[k −n]
(18.35)

Predictions
507
where we have introduced
H−1(q−1)G(q−1) =
∞
X
j=0
˜g[n]q−n
(18.36)
For discrete-time systems with ZOH and no feedthrough, the summation in the ﬁrst term of (18.35)
begins from j = 1.
H−1G
1 −H−1
+
+
ˆy[k|k −1]
y[k]
u[k]
FIGURE 18.1
Schematic illustrating one-step ahead prediction of the LTI system.
Figure 18.1 illustrates the predictor in (18.34). The prediction can be thus viewed as a result of
applying suitable ﬁlters to the input and output. We shall elaborate on this aspect in §18.5.
The theoretical one-step ahead prediction error is, as before, the innovations
ε[k|k −1] = y[k] −ˆy[k|k −1] = −H−1(q−1)G(q−1)u[k] + H−1(q−1)y[k] = e[k]
(18.37)
In Chapter 17 expressions for predictions and prediction errors for speciﬁc structures were pro-
vided. These were obtained using (18.34) and (18.37). Estimation of G and H is usually carried
out by minimization of a norm of the prediction-error. This is the central idea in prediction-error
methods.
While the one-step prediction-error is useful in estimation, the acid test for a model is its ability to
make long-range predictions. Having said that, it is in some sense unreasonable to expect the model
to provide good long-range predictions when it has been optimized for one-step predictions. Nev-
ertheless, there exists one parametric model family whose long-range (inﬁnite-step) and one-step
predictions are theoretically identical. This is the family of output-error models. We shall establish
this fact in the following section, whose purpose is also to provide formal expressions for l-step
ahead predictions.
18.4
MULTI-STEP AND INFINITE-STEP AHEAD PREDICTIONS
The l-step ahead prediction of y[k] is
ˆy[k|k −l] = G(q−1)u[k] + ˆv[k|k −l]
(18.38)
where it is always understood that the input proﬁle for a future time is known, a reasonable assump-
tion under open-loop conditions.
The l-step ahead prediction for the disturbance is obtained by examining (18.24) and ignoring the
terms involving e[k −l + 1] to e[k]. Thus,
ˆv[k|k −l] =
∞
X
n=l
h[n]e[k −n]
(18.39)

508
Principles of System Identiﬁcation: Theory and Practice
Introduce
¯Hl (q−1) ≜
l−1
X
n=0
h[n]q−n; H′
l (q−1) ≜
∞
X
n=l
h[n]q−n
(18.40)
so that
H(q−1) = ¯Hl (q−1) + H′
l (q−1)
(18.41)
Then, the prediction in (18.39) can be re-written as
ˆv[k|k −l] = H′(q−1)e[k]
(18.42)
Once again appealing to the invertibility property of H(q−1), we have
ˆv[k|k −l] = H′
l (q−1)H−1(q−1)v[k]
(18.43)
Using (18.41), we have thus
ˆv[k|k −l] = (1 −¯Hl (q−1)H−1(q−1))v[k]
(18.44)
It is easy to see that (18.44) produces the one-step ahead prediction in (18.28) when l = 1.
Inserting (18.44) into (18.38) and replacing v[k] with its theoretical estimate y[k] −G(q−1)u[k]
produces the l-step ahead predictor for y[k],
ˆy[k|k −l] = Wl (q−1)G(q−1)u[k] + (1 −Wl (q−1))y[k]
(18.45)
where we have introduced a predictor ﬁlter (Ljung, 1999)
Wl (q−1) ≜¯Hl (q−1)H−1(q−1)
(18.46)
Two important ramiﬁcations follow.
i. Inﬁnite-step ahead prediction: As l →∞, ¯Hl (q−1) →H(q−1). Therefore, we have from
(18.45) and (18.46),
ˆy[k| −∞] = G(q−1)u[k]
(18.47)
The result is expected since the inﬁnite-step ahead prediction of noise is zero. Equation (18.47)
does not involve any measurement in the past, thereby constructing it solely from the inputs
and the deterministic model. The inﬁnite-step ahead prediction is therefore also referred to as
simulation.
Notice that (18.47) is exactly the one-step ahead prediction of the output-error model given
by (17.52). Thus, the one-step and the inﬁnite-step ahead predictions of an OE model are iden-
tical. Consequently any method that estimates the OE model by minimizing its one-step ahead
prediction error will also minimize its inﬁnite-step ahead prediction error.
ii. One-step ahead viewpoint: Observe that the l-step ahead prediction in (18.47) can be viewed
as the one-step ahead prediction of y[k] with a noise model W−1
l , i.e., suppose
y[k,G,W−1
l ] = G(q−1)u[k] + W−1
l (q−1)e[k]
(18.48)
then,
ˆy[k|(k −1,G,W−1
l )] = ˆy[k|(k −l,G, H)]
(18.49)

Predictions
509
Thus, changing the prediction horizon is equivalent to altering the noise model. This also implies
that it is suﬃcient to know how to estimate models that minimize one-step ahead prediction
errors.
Example 18.5: Two-Step Predictor for an AR Process
Consider a random process v[k] with a known AR(1) description
H(q−1) = 1/(1 + d1q−1) = 1 −d1q−1 + d2
1q−2 −· · ·
The one-step ahead prediction using (18.28) is
ˆv[k|k −1] = −d1v[k −1]
For the two-step ahead prediction we use (18.44). Note that
¯H2(q−1) = 1 −d1q−1 and
H−1(q−1) = 1 + d1q−1.
ˆv[k|k −2] = (1 −¯H2(q−1)H−1(q−1))v[k] = d2
1v[k −2]
The result in (18.49) essentially implies that if we change the noise model for v[k] to
Hnew(q−1) = W−1
2 (q−1) = ( ¯H2(q−1)H−1(q−1))−1 =
1
1 −d2
1q−2
then the one-step ahead prediction with this new noise model
ˆv[k|k −1] = (1 −H−1
new(q−1))v[k] = d2
1v[k −2]
(18.50)
is the same as the two-step ahead prediction with the old noise model, which is indeed
the case.
Returning to (18.45), as in the case of one-step ahead prediction, it can be written in a non-
parametric form as well,
ˆy[k|k −l] =
∞
X
j=0
˜gl[j]u[k −j] +
∞
X
j=l
˜hl[j]y[k −j]
(18.51)
where ˜gl[.] and ˜h[.] are the IR sequences of Wl (q−1)G(q−1) and 1 −Wl (q−1), respectively. Notice
the diﬀerent starting indices for the two terms in the summation.
Example 18.6: One-Step and Inﬁnite-Step Ahead Predictions of ARX(1,1) and OE(1,1) Models
Develop one-step, two-step and inﬁnite-step ahead predictions of the following models:
ARX(1,1) : y[k] =
3q−1
1 −0.5q−1 u[k] +
1
1 −0.5q−1 e[k]
(18.52a)
OE(1,1) : y[k] =
3q−1
1 −0.5q−1 u[k] + e[k]
(18.52b)
where e[k] ∼GWN(0,σ2e).
Solution: Applying (18.34) to the ARX model yields,
ARX(1,1) : ˆy[k|k −1] = 3q−1u[k] + 0.5q−1y[k] = 3u[k −1] + 0.5y[k −1]
(18.53a)

510
Principles of System Identiﬁcation: Theory and Practice
For the OE model, we have
OE(1,1) : ˆy[k|k −1] =
3q−1
1 −0.5q−1 u[k]
=⇒ˆy[k|k −1] = 0.5ˆy[k −1|k −2] + 3u[k −1]
(18.53b)
which is quite diﬀerent from that of the ARX model in the sense that it uses the past
prediction in place of the past measurement. It is clear that therefore, an initial guess of the
prediction has to be supplied to compute the predictions of the OE model1.
Rewriting the predictor of the OE model in terms of a prediction at k = M, we have
OE(1,1) : ˆy[k|k −1] =
M
X
n=1
3(0.5)n−1u[k −n] + (0.5)M ˆy[k −M|k −M −1]
(18.53c)
Thus, at large times (relative to the initialization instant M), i.e., beyond the system’s natural
settling time, the eﬀect of the initial guess vanishes and we are left with only the ﬁrst term.
OE(1,1) : ˆy[k|k −1] ≈
M
X
n=1
3(0.5)n−1u[k −n],
(large times)
(18.53d)
The inﬁnite-step ahead predictions of the ARX and OE models are identical as per the
result in (18.47)
ˆy[k| −∞] = ysim[k] = G(q−1)u[k]
(18.54)
where ysim[k] is the simulated response. Using similar steps as above, one can re-write the
inﬁnite-step ahead prediction purely as a weighted (and truncated) sum of past inputs.
Observe that, as expected, the one-step and the inﬁnite-step ahead predictions of the OE
model are identical owing to its structure (H = 1); recall the discussion in §18.3 and §18.4 in
this respect.
We next demonstrate the use of MATLAB in computing predictions of the OE and ARX models
developed for the liquid level system in Chapter 2.
Example 18.7: Computing Predictions in MATLAB
For the purpose of illustration, recall the liquid level case study of Chapter 2. The predictions
of two diﬀerent estimated models, namely, the OE(1,1) and ARX(5,5) models, are compared.
While the one-step ahead prediction is computed for the training data (used for estimation).
the inﬁnite-step ahead predictions are computed on a fresh data set (test data set).
Figures 18.2(a) and 18.2(b) show snapshots of these predictions. On both data sets, the two
models give predictions of similar quality. However, the reader may recall that the output-
error model was found to oﬀer the best description of the input-output relationship, while
the high-order ARX model was discarded because it was not satisfactory based on model
quality checks.
Listing 18.1
MATLAB code for generating Figure 18.7
% Load data
load liqleveldata
zk = iddata(yk,uk,1);
1This is natural, since the OE model is also an ARMAX model and we have studied earlier that predictors from MA
models require an initial guess.

Predictions
511
0
50
100
150
200
250
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time
Amplitude
Comparison of one−step predictions
 
 
OE model
ARX model
Observed data
(a) One-step predictions on training data
1500
1550
1600
1650
1700
1750
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time
Amplitude
Comparison of infinite−step predictions
 
 
OE model
ARX model
Observed data
(b) Inﬁnite-step predictions on test data
FIGURE 18.2
Predictions of the estimated OE and ARX models for the liquid level system of Chapter 2.
datatrain = zk(1:1500);
% Remove trends
[dataset ,Tr] = detrend(datatrain ,0);
% Build OE and ARX models
mod_oe = oe(dataset ,[1 1 1]);
mod_arx = arx(dataset ,[5 5 1]);
% Compare one-step ahead predictions
predone_oe = predict(mod_oe,dataset ,1);
predone_arx = predict(mod_arx ,dataset ,1);
plot((1:250),predone_oe.y(1:250),’-’,(1:250),predone_arx.y(1:250),’k--’...
,(1:250),dataset.y(1:250),’r.’);
% Or use ’compare ’
% Compute infinite -step ahead predictions on a fresh data
datatest = detrend(zk(1501:end),Tr)
compare(datatest(1:250),mod_oe,mod_arx ,inf)
Unknown initial conditions
The predictors in (18.34) and (18.45) (and their convolution forms) assume that an inﬁnite past is at
our disposal. In practice, only ﬁnite length data is available. This creates the need for extending the
input and output to times k < 0. Diﬀerent solutions exist for this purpose. The simplest approach is
to assume the initial values to be zero. Another option is to include them as a part of the parameter
estimation exercise and determine them in an optimal fashion. A Kalman ﬁlter approach can also be
employed to estimate the initial conditions.
Predictor ﬁlter
The predictor ﬁlter Wl (q−1) in (18.45) can also be constructed starting with the deterministic model
alone (i.e., ignoring the noise model) and by imposing requirements on the sensitivity of the predic-
tions to errors in (i) in the guess of initial conditions and (ii) measurements. See Ljung (1999) for
an elucidation of this fact.
Further to the above point, the non-parametric (convolution) form of the predictors in (18.35) and
(18.51) suggest that we could directly work with the predictor ﬁlter coeﬃcients instead of deriving
them from a given G and H. Moreover, these ﬁlter coeﬃcients could be optimized to yield minimum
prediction errors. This is the basis for the so-called predictor model description of the LTI system.
The next section is devoted to this idea.

512
Principles of System Identiﬁcation: Theory and Practice
18.5
PREDICTOR MODEL: AN ALTERNATIVE LTI DESCRIPTION
Placing the results of the previous sections in perspective, an interesting picture emerges. The pre-
diction is essentially a weighted combination of the ﬁltered input and output. Thus, the one-step
ahead prediction in (18.34) can be re-written in terms of input and output predictor ﬁlters
ˆy[k|k −1] = Wu(q−1)u[k] + Wy(q−1)y[k] = W(q−1)z[k]
(18.55)
where
W(q−1) =
f
Wu(q−1)
Wy(q−1)
gT
z[k] =
f
u[k]
y[k]
gT
(18.56)
Comparing with (18.34), we have the general expression for one-step ahead predictor ﬁlters,
Wu(q−1) = H−1(q−1)G(q−1), Wy(q−1) = (1 −H−1(q−1))
(18.57)
Further, there exists a one-to-one link between T =
f
G(q−1)
H(q−1)
gT and the predictor ﬁlters
W =
f
Wu(q−1)
Wy(q−1)
gT.
The main point is as stated in the close of the previous section. While the LTI system and the
predictor expressions can be fully described by specifying (G, H) and the p.d.f. of the innovations
fe(.), the same could be achieved by specifying the predictor ﬁlters Wu(q−1) and Wy(q−1) and the
p.d.f. of the prediction errors. In other words, we need not concern ourselves with the connections
between T and W, but rather directly work with W. This new description based on W is known
as the predictor model. Compared to the standard model-based description, the predictor-model
form has a larger practical appeal in identiﬁcation because of its implementability in prediction
computations.
The following deﬁnitions follow from Ljung (1999). They are useful in understanding the key
concept of identiﬁability, to be discussed in §22.3.
Deﬁnition 18.1. A predictor model of a LTI system is a stable ﬁlter W(q−1), deﬁning the one-step
ahead prediction as in (18.55).
Note the stability requirement. The original system may be unstable, but the predictor is required
to be stable.
Deﬁnition 18.2. A complete probabilistic model of a LTI system is the predictor model and the
p.d.f. of the associated prediction errors (W(q−1), f (e[k])).
A model is said to be a l-step ahead predictor model if its predictions use measurements only up
to y[k −l]. Thus, the output predictor-ﬁlter should have the form
Wy(q−1) =
∞
X
n=l
wy[n]q−n
(18.58)
An output error model is clearly one for which Wy(q−1) = 0.
Just as the way (G, H) could be parametrized, the predictor model W could also have a para-
metric form. The only requirement is that the parametrized form W(z,θ) be diﬀerentiable since the
gradients Ψ of these predictor models have to exist (for parameter estimation).

Predictions
513
Equality of models
Finally, it is appropriate to speak of equality of two (predictor) models, which is useful later for
deﬁning identiﬁability and informative experiments.
Deﬁnition 18.3. Equality of models Two models W1 and W2 are said to be equal if the frequency
responses of the predictor ﬁlters are identical at almost all frequencies (Ljung, 1999).
W1(e−jω) = W2(e−jω)
for almost all ω
(18.59)
This brings us to the close of the prediction-related concepts necessary for identiﬁcation.
18.5.1
MODEL SETS AND STRUCTURES
In identiﬁcation, the prime task is to select a suitable model among a collection of postulated candi-
date models. When the search is among a family of parametric models, the focus is on models with
structures. Until this point we have used the phrases “model set” and “model structure” somewhat
loosely without a clear deﬁnition. In order to formalize concepts such as convergence of estimators
and identiﬁability (of models), the following formal deﬁnitions are necessary (Ljung, 1999).
Deﬁnition 18.4. (Model set) A model set is a collection of predictor models,
M = {Wi(q−1),i ∈I}
(18.60)
where I is an index set.
Examples of model sets are (i) models with Wy(q−1) = 0 (output error models) and (ii) all models
whose Wy(q−1) are second-order polynomials and Wu(q−1) are ﬁrst-order.
Note that model sets include both non-parametric as well as parametric models. When the focus
is on the latter class, parametrized by the p × 1 parameter vector θ, we have what are known as
model structures.
Deﬁnition 18.5. A model structure is a diﬀerentiable mapping from the parameter space θ ∈Rp to
the model set M such that the predictor gradients are stable.
Formally a model structure is denoted by M(θ). Notice the requirement of existence and stability
of predictor gradients, required for estimation.
Example 18.8: Model Structure
The predictor model
ˆy[k] = B(q−1,θ)u[k] + (1 −A(q−1,θ))y[k]
(ARX model)
θ =
f
a1
· · ·
ana
bnk
· · ·
bn′
b
gT
is a model structure because the predictor as well as its gradient Ψ = d
dθ W(q−1,θ) are both
stable. Also observe that the noise and plant models are not independently parametrized.
In general any of the predictor forms for parametric models that we have studied in Chapter 17
with appropriate stability requirements are model structures. The state-space descriptions due to
appear in Chapter 23 also qualify as model structures.
The ﬁnal topic of interest and that works silently in the background of every identiﬁcation exer-
cise is the concept of identiﬁability. It is appropriate to place the discussion at this juncture since
identiﬁability is concerned with the structure of the model and the mapping from the parameter
space to the model space.

514
Principles of System Identiﬁcation: Theory and Practice
18.6
IDENTIFIABILITY
As remarked in §2.1, the concept of identiﬁability has three arms: (i) uniqueness and invertibility
of the model structure M(θ) at every point in the θ space, (ii) “information” present in the data
to resolve between two models (largely depends on the inputs) and (iii) consistency property of the
estimator.
In this section, we ﬁrst discuss the concepts of model identiﬁability, speciﬁcally of linear time-
invariant, black-box model structures, followed by the broader practically important concept of
system identiﬁability. Only the important terminology, main results and their interpretations are
provided. For full technical details, the reader is referred to Ljung (1999, Chapter 4).
18.6.1
MODEL IDENTIFIABILITY
First, we deﬁne the notion of global identiﬁability, which is concerned with the uniqueness of a
model structure at any point in the entire parameter space, denoted by DM.
Deﬁnition 18.6. (Global Identiﬁability) A model structure is globally identiﬁable at θ⋆if the equal-
ity of models implies equality of parameters,
M(θ) = M(θ⋆), θ ∈DM =⇒θ = θ⋆
(18.61)
Essentially, there should not be more than one set of parameter values that produce the same
model. Recall once again that by equality of models, we mean here equality of predictor ﬁlters, as
explained earlier.
It is naturally very diﬃcult to ﬁnd models that meet the global identiﬁability condition, unless
under very simplistic conditions (e.g., pure linear static models). Therefore, a weaker condition is
often demanded, which is that the model should be identiﬁable at almost all points in the parameter
space. An alternative way of stating the same is that if a model is equal at two diﬀerent points θ and
θ⋆should imply that θ is within an ϵ-neighborhood of θ⋆, for “suﬃciently” small values of ϵ.
Example 18.9: Locally Identiﬁable Model
A simple example of a locally identiﬁable model is y[k] = θ2u[k],θ ≥0. It is identiﬁable at all
points in the region θ ≥0.
However, the model is not globally identiﬁable, i.e., at all points in the θ space since two
values of θ produce the same predictor.
It is also possible that the model is not identiﬁable in the entire parameter space, but may be
locally identiﬁable in a region of interest. This region is usually dictated by the constraints placed
on the parameters. Within that region, once again, the model should be identiﬁable at all points.
Then we have the notion of strict local identiﬁability. Further, we can deﬁne a weaker form of this
concept in the same way as we did for global identiﬁability.
Applying Deﬁnition 18.6 to test model identiﬁability is not a trivial task in general, especially for
non-linear systems. In this text, the primary interest is on the identiﬁability of SISO LTI black-box
structures, both the input-output and state-space models. We shall only state the main result con-
cerning the identiﬁability of these structures and use a few examples to describe their implications.
For a full technical discussion, the reader is referred to Ljung (1999, Chapter 4).
18.6.2
IDENTIFIABLE LTI BLACK-BOX STRUCTURES
The conditions for identiﬁability are diﬀerent for input-output and state-space model structures.
This is due to the inherent diﬀerences in their forms, i.e., parameter to model mappings.

Predictions
515
Input-output models
Applying Deﬁnitions 18.3 and 18.6, the identiﬁability of a SISO input-output LTI model structure
requires that two diﬀerent parameters should not produce the same predictor ﬁlter corresponding to
that structure. Consider the following examples.
Example 18.10: Identiﬁability of an ARX(1,1) Model
Determine if the ARX model
G(q−1,θ) = b1q−1 + b2q−2
1 + a1q−1
, H(q−1,θ) =
1
1 + a1q−1
(18.62)
where θ =
f
a1
b1
b2
gT , is identiﬁable.
The predictor ﬁlters for this model structure can be written using (18.57) as
Wu(q−1,θ) = B(q−1); Wy (q−1,θ) = 1 −A(q−1)
(18.63)
For global identiﬁability, two models at two diﬀerent values of the parameter vector should
never be equal. Using Deﬁnitions 18.3 and 18.6, it is easy to check that the model is identi-
ﬁable.
Wu(q−1,θ) = Wu(q−1,θ⋆) ⇐⇒θ = θ⋆
Wy (q−1,θ) = Wy (q−1,θ⋆) ⇐⇒θ = θ⋆
In general all ARX model structures are identiﬁable.
The issue is a bit more involved with other types such as ARMAX and Box-Jenkins structures.
The main requirement is that no zero-pole cancellation should occur in the plant and noise models.
Consider the following example, followed by a formal statement of the general result.
Example 18.11: Identiﬁability of an OE(1,2) Model
Consider the hypothetical OE(1,2) model
G(q−1,θ) =
q−1 + b1q−1
(1 + b1q−1)(1 + f1q−1) , H(q−1) = 1
(18.64)
where θ =
f
b1
f1
gT .
The above model is clearly not identiﬁable since the predictor ﬁlter Wu(q−1,θ) = G(q−1) is
identical at two diﬀerent points in the θ space. In other words, identical predictions are ob-
tained for two diﬀerent values of b1. This occurs due to the common factors in the numerator
and denominator of G(q−1).
The main result now follows (see Ljung (1999)).
Theorem 18.1: Identiﬁability of LTI Model Structure
Consider the general model structure, M(θ) of (17.25) given by
G(q−1,θ) =
B(q−1)
A(q−1)F(q−1) ;
H(q−1,θ) =
C(q−1)
A(q−1)D(q−1)
((17.25) revisited)
with θ given by (17.26). This model structure is globally identiﬁable at any point θ⋆if and only if
the following are satisﬁed:

516
Principles of System Identiﬁcation: Theory and Practice
i. zna A(z,θ⋆), znb B(z),θ⋆and zncC(z,θ⋆) are co-prime.
ii. znb B(z),θ⋆and zn f F(z,θ⋆) are co-prime.
iii. zncC(z),θ⋆and znd D(z,θ⋆) are co-prime.
iv. If na ≥1, zn f F(z,θ⋆) and znd D(z,θ⋆) should be co-prime, i.e., all factors common to D and F
should be contained in A.
v. If nd ≥1, and znd D(z,θ⋆) zna A(z,θ⋆) and znb B(z),θ⋆should be co-prime.
vi. If nf ≥1, and znd D(z,θ⋆) zna A(z,θ⋆) and zncC(z),θ⋆should be co-prime.
If all the parametric model structures discussed in §17.5, as special cases of (17.25), satisfy the
above requirements, they are identiﬁable. Note that not all requirements have to be invoked for each
specialized structure.
State-space models
A parametrized state-space model structure of an innovations form (refer to §23.3.2) is represented
as
x[k + 1] = A(θ)x[k] + B(θ)u[k] + K(θ)e[k]
(18.65)
y[k] = C(θ)x[k] + D(θ)u[k] + e[k]
(18.66)
where K is the Kalman gain.
The question is then on how the elements of the parameter vectors θ should be seated in the
elements of the matrices A, B, C, D and K so that the resulting structure is identiﬁable.
For this purpose, recall that a general state-space representation is not unique (recollect the dis-
cussion in §4.4) unless the matrices have zero-valued and non-zero entries in speciﬁc locations.
Therefore, a state-space model structure cannot be parametrized arbitrarily and expected to be iden-
tiﬁable. Canonical forms of §4.4.3.1 meet these requirements and therefore qualify as identiﬁable
structures. Identiﬁability of state-space structures require the model to be both observable and con-
trollable, as explained below.
A commonly used realization is the observer canonical form presented in (4.55),
A(θ) =

×
×
In−1
...
×
0
· · ·
0

, B =

×
×
...
×

K =

×
×
...
×

(18.67)
C =
f
1
0
· · ·
0
g
(18.68)
where the entry ‘×’ denotes a parameter and n is the order of the system.
Remarks:
1. In the parametric form of (18.68), we have omitted D assuming a unit delay in the input-output channel,
i.e., strict causality.
2. In total we have n + n + n = 3n parameters to be estimated. The innovations form in (18.68) corresponds
to an ARMAX model of nth order (for all polynomials). On the other hand, ARMAX model structures
are identiﬁable as per Theorem 18.1 if and only if there is no pole-zero cancellation. In other words, it is
required that the observer canonical form in (18.68) be of minimal realization (recall deﬁnition 4.1). Thus,
it should also be controllable for being identiﬁable.

Predictions
517
Following the second remark, the general result is stated below:
The observer canonical structure of the innovations form in (18.68) is globally identiﬁable at
any point θ⋆if and only if it is controllable with respect to both inputs u[k] and e[k], i.e., the
controllability matrix constructed from {A(θ⋆),
f
B(θ⋆)
K(θ⋆)
g
} is of full ranka.
aRead §23.2.2 for a formal deﬁnition of controllability
Remarks:
An nth-order unstructured (fully parametrized) SISO state-space model in the innovations form has
n2 + n + n + n = n2 + 3n unknowns, whereas the identiﬁable form in (18.68) has only 3n parameters to be
estimated. Thus, canonical forms improve the identiﬁability by choosing a minimal parametrization, but the
algorithms to estimate them are more complex than those for the unstructured models. See §23.7.
For MIMO systems, the situation is somewhat more complicated and challenging to arrive at an
identiﬁable canonical form. An important result in this connection is the existence of a globally
identiﬁable canonical form for any ﬁnite-order linear multivariable system. This is the observability
canonical form (4.56) in which the C matrix has ones (one per output row) and zeros at appropriate
locations, while B and K are fully parametrized. The matrix A consists of ones along the super-
diagonals and speciﬁc rows that are entirely parametrized (total number of such rows equal to ny).
The remaining entries of A are all zeros. This speciﬁc canonical form in fact corresponds to an
ARMAX structure. See Ljung (1999, Chapter 4) for a technical elucidation of this point.
We close this section with a brief discussion on a practically important and relevant concept,
which is concerned with the ability to identify a system uniquely.
18.6.3
SYSTEM IDENTIFIABILITY
A natural question that follows is: if the model is identiﬁable, will the identiﬁed parameters equal
the “true” values? This question is valid, of course, assuming that a “true” description of the system
exists.
As remarked above, three factors determine the answer to this question:
1. The true system contained in the model structure: Denoting the true system by S, we are asking
if S ∈M(θ)? For example, if the true system is second-order, with a third-order model contains
S ∈M, while with a ﬁrst-order model, S < M. This aspect is detailed in §21.3 with examples,
where the convergence properties of PEM estimators are studied.
2. Consistency of the estimator: This aspect has been studied in detail in diﬀerent sections earlier,
in §13.10, §14.3.3 and §15.1.4. For identiﬁcation of parametric models using PEM methods,
consistency of PEM estimators is necessary. This aspect is studied in §21.3.
3. Resolvability between two model structures: Resolvability is the ability to discriminate between
two competing model structures and to be able to conclude that one is better suited than the other
for a given process. The input is the key to achieving this discriminatory ability. In a broader
sense, it depends on the information contained in the data, which is usually generated by the
probe signals. Recall Example 2.2 in this regard. A formal study of this point lays the foundations
of input design. Section 22.2 is devoted to this purpose.
When all the three requirements above are met, the system can be identiﬁed uniquely; this is the
condition of system identiﬁability.
With the expressions developed for predictions and other formalizations, we are now ready to take
up the problem of estimating models, which is the key step in identiﬁcation. The chapters (19 to 23)
to follow are devoted to this topic, beginning with the estimation of time-series models.

518
Principles of System Identiﬁcation: Theory and Practice
18.7
SUMMARY
Prediction theory is a vast subject with a very rich set of applications. In this chapter we have studied
prediction concepts pertaining to identiﬁcation. The cornerstone result is the conditional expectation
providing the best prediction (in the MSE sense). A Bayesian framework for prediction naturally
exists (as in the parameter estimation case). The conditional expectation is then simply the Bayes
prediction, i.e., the mean of the posteriori p.d.f. of the predicted variable. However, the conditional
expectation result is useful only when the joint p.d.f. of the predicted variable and the regressors
are known. In the absence of this knowledge, a best linear predictor can be constructed. The BLP
only requires the knowledge of ﬁrst- and second-order moments. As in estimation theory, the BLP
coincides with the conditional expectation for the Gaussian case.
In identiﬁcation, the prediction problem typically begins by assuming that the model is given (or
postulated by the user). Using the plant and noise model description of the LTI system we learnt how
to develop the one-step and l-step ahead forecasts. The theoretical one-step ahead prediction error
is the white-noise source, which also gives an alternative name to the WN process, the innovations.
Among the parametric models, the output-error model has a unique characteristic - its one-step
and inﬁnite-step ahead predictions are identical. Computing the l-step ahead prediction with a noise
model is identical to generating a one-step ahead prediction with an alternative equivalent noise
model.
One of the interesting outcomes of the predictor expressions is the alternative description of the
LTI system known as predictor models, which are based on predictor ﬁlters. The description is based
on the fact that predictions (of an LTI system) are in general a linear combination of the ﬁltered
inputs and outputs. The predictor model along with a probabilistic description of the prediction
errors oﬀers a useful and practical alternative representation of the LTI system.
Finally, this chapter introduced the formal concepts and deﬁnitions of model sets, structures and
identiﬁability. Model sets are essentially collection of a particular type of models, whereas model
structures are parametrized forms with stable predictors of the same. These concepts are useful in
studying the convergence properties of PEM estimators and also understanding the notions of iden-
tiﬁability. Identiﬁability is an important concept that works in the background of every identiﬁcation
exercise. Model identiﬁability examines whether the chosen model structure is indeed unique in the
parameter space, while the system identiﬁability studies the conditions under which the “true” sys-
tem parameters can be obtained from data using the selected model and estimation algorithm. A
follow-up topic on that of informative data is presented in §22.2 in the context of input design.
REVIEW QUESTIONS
R18.1 What is the role of conditional expectation in prediction?
R18.2 Describe what you understand by a best linear predictor.
R18.3 Identify the diﬀerences between a one-step ahead prediction and an inﬁnite-step ahead prediction.
R18.4 Why does the OE model produce identical one-step and inﬁnite-step ahead predictions?
R18.5 Describe the term predictor ﬁlter and its role in prediction.
R18.6 Explain the predictor model description of an LTI system.
R18.7 What is a model set?
R18.8 Deﬁne a model structure.
R18.9 When are two models said to be equal?
R18.10 Explain the concepts of global and local identiﬁability.
R18.11 What are the conditions under which the parametric LTI input-output black box models are
globally identiﬁable?

Predictions
519
R18.12 Give one example of a non-identiﬁable input-output model structure.
R18.13 Why are general state-space structures not necessarily identiﬁable?
R18.14 State the conditions under which a state-space structure is identiﬁable.
EXERCISES
E18.1 Show that the best linear predictor of v[2] given {v[1],v[0]} obtained in Example 18.4 is better
than a truncation of the inﬁnitely long predictor in Example 18.2, when v[k] is generated by an
MA(1) process.
E18.2 Derive the expression for the l-step ahead prediction error of an LTI system described by the
usual description (G, H).
E18.3 Give a suitable interpretation of the l-step ahead prediction error.
E18.4 Show using the equivalence of the l-step and one-step ahead predictions that the (M + 1)-step
(and greater) ahead prediction of a MA(M) process is zero.
E18.5 Determine the three-step ahead prediction for a process v[k] =
1
1 + c1q−1 e[k]. Compute the
variance of the associated prediction error.
E18.6 Given the one-step ahead predictor ˆy[k|k−1] = L1(q)u[k]+L2(q)y[k], determine the corresponding
plant- and noise-models.
E18.7 Usually we minimize the (squared) prediction error based on “output error,” i.e., y[k]−G(q)u[k].
What interpretation (of the plant and noise model) can we provide if we minimize the prediction
error based on “input error”, i.e., u[k] −G−1(q)y[k]?
E18.8 It is known to us that the theoretical one-step ahead prediction error from an LTI description
y[k] = G(q)u[k] + H(q)v[k] is white-noise. What kind of a noise description H(q) will additionally
ensure the theoretical prediction errors up to 2-steps (only) are also white?
E18.9 Show that the variance of the forecasting error in the m-step ahead prediction error of a time-
series is σ[0] −γ(p)T
n
Γ−1
n γ(p)
n
. Use this result to derive the variance of the forecasting error for an
AR(1) process: x[k] = φx[k −1] + e[k]

19
Identiﬁcation of Parametric Time-Series
Models
Estimators of time-series models are discussed. The primary objectives are to provide the
working principles of these methods and their implementation. Concepts learnt from this
chapter are useful for disturbance (noise) modeling and estimation of spectral densities.
19.1
INTRODUCTION
In Chapter 9 we studied diﬀerent time-series models for linear stationary random processes. A
general description is given by the ARMA model (or ARIMA for integrating processes). In this
chapter, we shall learn how to estimate these models using the methods of Chapters 14 and 15.
Historically, time-series modeling precluded identiﬁcation by a few decades. Furthermore recall
from our discussions on previous chapters that estimating models for identiﬁcation is essentially
identical to developing a time-series model with exogenous eﬀects. Therefore, it is natural that we
familiarize ourselves with the methods and procedures for estimation of time-series models ﬁrst.
The resulting model is useful in (i) explaining the eﬀects of disturbances (noise modeling) and (ii)
estimation of power spectral densities (recall §16.5.7).
A variety of methods are available for estimating ARMA models, almost all of which emerge
from systematically applying the techniques and estimators in Chapters 13 through 15. However,
the diﬀerences in the properties of the AR, MA and the ARMA model structures attract diﬀerent
estimation methods. For instance, auto-regressive models result in linear predictors; therefore, a
linear OLS method delivers the goods. On the other end, MA models are described by non-linear
predictors calling for a non-linear LS method, which is computationally more intense and results in
local optima. The linear nature of the AR predictors also attracts a few other specialized methods.
The historical nature and the applicability of this topic is such that numerous texts and survey/tu-
torial articles dedicated to this topic have been written (Box, Jenkins and Reinsel, 2008; Brockwell,
2002; Chatﬁeld, 2004; Priestley, 1981; Shumway and Stoﬀer, 2006). Therefore, it is neither the ob-
jective of this short chapter nor is it feasible to give an in-depth treatment of the subject. The primary
aims of this chapter are to (i) highlight the working principles of popular methods, (ii) discuss the
properties of the resulting estimators and (iii) demonstrate their implementation (in MATLAB). The
chapter begins with the estimation of AR models in §19.2 and gradually develops into the estimation
of ARMA models in §19.4. In the concluding part, we discuss the estimation of ARIMA models.
19.2
ESTIMATION OF AR MODELS
The AR estimation problem is stated as follows. Given N observations of a stationary process {v[k]},
k = 0,· · · , N −1, ﬁt an AR(P) model (recall (9.28)).
v[k] =
P
X
j=1
(−d j)v[k −j] + e[k]
(9.28 revisited)
One of the ﬁrst methods that were developed to estimate AR models was the Yule-Walker method
based on the Yule-Walker equations (recall §9.5.2). The Y-W method belongs to the class of method
520

Identiﬁcation of Parametric Time-Series Models
521
of moments and is one of the simplest to use. However, it is known to suﬀer from certain shortcom-
ings as we shall learn shortly. Gradually more powerful and sophisticated methods appeared on the
arena. Among these we shall particularly discuss (i) modiﬁed covariance method, (ii) LS method,
(iii) Burg’s method and the (iv) MLE method.
19.2.1
Y-W METHOD
The Y-W method of Yule (1927) and Walker (1931) is an MoM approach as outlined in §9.5.2 and
§14.2. The second-order moments of the bivariate p.d.f. f (v[k],v[k −l]), i.e., the ACVFs of an
AR(P) process are related to the parameters of the model through §9.5.2,

σvv[0]
σvv[1]
· · ·
σvv[P −1]
σvv[1]
σvv[0]
· · ·
σvv[P −2]
...
...
· · ·
...
σvv[P −1]
σvv[P −2]
· · ·
σvv[0]

|                                                        {z                                                        }
ΣP

d1
d2
...
dP

|{z}
θP
= −

σvv[1]
σvv[2]
...
σvv[P]

|     {z     }
σP
σ2
v + σT
PθP = σ2
e
Thus, the Y-W estimates of the AR(P) model and the innovations variance σ2
e are
ˆθ = −ˆΣ−1
P ˆσP
ˆσ2
e = ˆσ2
v + ˆσT
P ˆθ = ˆσ2
v −ˆσT
P ˆΣ−1
P ˆσP
(19.1a)
(19.1b)
provided ˆΣP is invertible, which is guaranteed so long as σ[0] > 0. The matrix ˆΣP itself is con-
structed using the biased estimator of the ACVF (read Chapter 16)
ˆσ[l] = 1
N
N−1
X
k=l
(v[k] −¯v)(v[k −l] −¯v)
(19.2)
Prediction error minimization viewpoint
The Y-W estimates can be shown as the solution to the OLS minimization of the prediction error
(see Exercise E19.1)
ˆθYW = arg min
θ
N+P−1
X
k=0
ε2[k]
(19.3)
where
ε[k] = v[k] −ˆv[k|k −1] = v[k] −
P
X
i=1
(−di)v[k −i]
(19.4)
Notice that the summation in (19.3) starts from k = 0 and runs up to k = N + P −1, whereas the
predictions can be actually computed only from k = P to k = N−1 without making any assumptions
on the series at both ends of the data. In order to compute the prediction errors from k = 0,· · · ,P−1
and k = N,· · · , N + P −1 an extended sequence of v[k] is required. The Y-W method pads p zeros
to both ends of the series to construct the extended sequence (Orfanidis, 2007). This approach is
frequently referred to as pre- and post-windowing of data.
In statistical signal processing applications, the prediction error is viewed as running the series
v[k] through a moving average or a FIR ﬁlter with the coeﬃcients {1,d1,· · · ,dP}. This is also
known as the prediction error ﬁlter.

522
Principles of System Identiﬁcation: Theory and Practice
The minimization formulation in (19.3) also directly fetches us the Y-W estimates from the OLS
solution to the linear regression problem in (14.21):
ˆθYW = (ΦTΦ)−1ΦT ˜v
(19.5)
with
Φ =
f
ϕ[0]
ϕ[1]
· · ·
ϕ[N + p −1]
gT
ϕ[k] =
f
−v[k −1]
· · ·
−v[k −P]
gT
˜v =
f
v[0]
v[1]
· · ·
v[N + p −1]
gT
(19.6a)
(19.6b)
(19.6c)
keeping in mind v[k] = 0, ∀{k = −P,· · · ,−1} ∪{k = N,· · · , N + p −1}.
Further, an unbiased estimate of the innovations variance can be directly obtained from (14.59),
ˆσ2
e =
N+p−1
X
k=0
ε2[k]/N
(19.7)
where the d.o.f. is Neﬀ= N + p −p = N.
Other properties of the Y-W estimator also thus follows from those of the OLS estimator. Specif-
ically, it can be now asserted that the Y-W estimates asymptotically tend to have a Gaussian distri-
bution.
Properties of the Y-W estimator
1. For a model of order P, if the process {v[k]} is also AR(P), the parameter estimates asymptoti-
cally follow a multivariate Gaussian distribution,
√
N(θ −θ0)
d
−→N

0,σ2
eΓ−1
P

(19.8)
In practice, the theoretical variance and covariance matrix are replaced by their respective esti-
mates.
2. From the above property, the 100(1 - α)% conﬁdence region for θ0 is the ellipsoid:
{θ0 ∈RP : ( ˆθ −θ0)T ˆΓP( ˆθP −θ0) ≤ˆσ2
e
N χ2
1−α(P)}
(19.9)
where χ2
1−α(P) is the (1 −α) quantile of the χ2-distribution with P degrees of freedom.
3. Of more practical utility is the 95% CI for the individual parameter θi0, which is approximately
constructed using the diagonals of ˆΣ−1
P
ˆθi ± 1.96ˆσe
√
N
(ˆΣ−1
P )1/2
ii
(19.10)
4. Using the ﬁrst property, if {v[k]} is an AR(P0) process and an AR model of order P > P0 is ﬁt
to the series, then the coeﬃcients in excess of the true order are distributed as
√
Nθl ∼AN(0,1)
∀l > P0
(19.11)
To verify this fact, consider ﬁtting an AR(P) model to a white-noise process, i.e., when P0 = 0.
Then ΣP = σ2
eI. The result in (19.11) then follows.

Identiﬁcation of Parametric Time-Series Models
523
5. Recall that the last coeﬃcient of an AR(P) model is the PACF coeﬃcient φPP of the series by
virtue of (9.43). Equation (19.11) is therefore useful in establishing the 100(1−α)% signiﬁcance
levels for the PACF estimates. By the present notation,
φll = −dl = −θl
(19.12)
It follows that if the true process is AR(P0), the 95% signiﬁcance levels for PACF estimates at
lags l > P0 are
−1.96
√
N
≤ˆφll ≤1.96
√
N
(19.13)
6. From (19.8) it follows the Y-W estimates of an AR model are consistent.
7. In as much as with all its attractive properties, the Y-W estimator suﬀers from a drawback. It may
produce poor (high variability) estimates when the generating auto-regressive process has poles
close to unit circle. The cause for this behavior is the poor conditioning of the auto-covariance
matrix ˆΣP for such processes combined with the bias in the ACVF estimator (19.2) (Hoon et
al., 1996). The eﬀects of the latter (bias) always prevail, but are magniﬁed when ˆΣP is poorly
conditioned. Thus, it is useful to test the singularity of ˆΣP before proceeding to use the Y-W
estimator.
8. The Durbin-Levinson’s algorithm outlined earlier in Table 9.1 is used to compute the parameter
estimates in a recursive manner without having to explicitly invert ˆΣP. The recursion is facilitated
by the Toeplitz structure of ˆΣP, which in combination with the biased ACVF estimator guarantees
that the resulting model is stable and minimum phase. Recall from the discussion in §16.5.7 that
unbiased ACVF estimator does not guarantee positive deﬁniteness of ˆΣP.
A numerical example is illustrated below.
Example 19.1: Y-W Estimation of an AR Model
Fit an AR model of second order using the Y-W method to a series consisting of N = 500
observations from an AR(2) process.
Solution: The variance and ACF estimates at lags l = 1,2 are computed to be ˆσ[0] = 7.1113,
ˆρ[1] = 0.9155, ˆρ[2] = 0.7776, respectively. Plugging in these estimates into (19.1a) produces
ˆθ =
" ˆd1
ˆd2
#
= −
"
1
0.9155
0.9155
1
#−1 "0.9155
0.7776
#
=
"−1.258
0.374
#
(19.14)
The estimate of the innovations variance can be computed using (19.1b)
ˆσ2
e = 7.1113 +
f
0.9155
0.7776
g "−1.258
0.374
#
= 0.9899
(19.15)
The errors in the estimates can be computed from (19.8) by replacing the theoretical values
with their estimated counterparts.
Σ ˆθ = 0.9899
"
1
0.9155
0.9155
1
#−1
=
" 0.0017
−0.0016
−0.0016
0.0017
#
(19.16)
Consequently, approximate 95% C.I.s for d1 and d2 are [−1.3393,−1.1767] and [0.2928,0.4554],
respectively.
Comparing the estimates with the true values used for simulation
d1,0 = −1.2; d20 = 0.32
(19.17)

524
Principles of System Identiﬁcation: Theory and Practice
we observe that the method has produced reasonably good estimates and that the C.I.s
contain the true values.
The reader may verify that the alternative solutions in (19.5) and (19.7) yield the same
solution.
The Y-W estimator is generally not the preferred method for time-series modeling unless the data
length is large and it is known a priori that the generating process has poles well within the unit
circle. However, it serves as very good method for initializing non-linear estimators such as NLS
and MLE (see §19.4.1 and §19.4.2).
19.2.2
LEAST SQUARES / COVARIANCE METHOD
The least squares method, as we learnt in §14.3 minimizes the sum square prediction (approxima-
tion) errors.
ˆθLS = arg min
θ
N−1
X
k=p
ε2[k]
(19.18)
Comparing with the standard linear regression form (14.17), we have
ϕ[k] =
f
−v[k −1]
· · ·
−v[k −P]
gT ;
θ = d =
f
d1
· · ·
dP
gT
(19.19)
Observe that the regressor vector ϕ[k] and the prediction error are constructed from k = P to
k = N −1 unlike in the Y-W method. Thus, the LS method does not pad or window the data. This is
also the conditional least squares (recall §15.1.2) because the randomness in the ﬁrst P observations
is ignored.
Using the LS solution (14.21), one obtains
ˆθLS = ˆdLS = (ΦTΦ)−1ΦTv =
 
1
N −PΦTΦ
!−1  
1
N −PΦTv
!
(19.20)
where
Φ =
f
ϕ[P]
ϕ[P + 1]
· · ·
ϕ[N −1]
gT ;
v =
f
v[P]
v[P + 1]
· · ·
v[N −1]
gT
(19.21)
Thus, we have a unique solution as in the Y-W method. Note that Φ and v have dimensions (N −
P) × P and (N −P) × 1, respectively.
A careful examination of (19.20) suggests that it can be written as a MoM estimate
ˆθ = −ˆΣ−1
P ˆσP
(19.22)
by introducing (see Exercise E19.2)
ˆΣP ≜
1
N −PΦTΦ =

ˆσvv[1,1]
ˆσvv[1,2]
· · ·
ˆσvv[1,P]
...
...
· · ·
...
ˆσvv[P,1]
ˆσvv[P,2]
· · ·
ˆσP[P,P]

(19.23)
ˆσP ≜
1
N −PΦTv =

ˆσvv[1,1]
...
ˆσvv[P,1]

(19.24)

Identiﬁcation of Parametric Time-Series Models
525
where the estimate of the ACVF is given by
ˆσvv[l1,l2] =
1
N −P
N−1
X
n=P
v[n −l1]v[n −l2]
(19.25)
Observe that ˆΣP is a symmetric matrix by virtue of (19.25).
With this equivalence, the method of LS estimation also acquires the name covariance method.
It is advantageous to use the LS / covariance method rather than the Y-W method for short data
records.
19.2.3
MODIFIED COVARIANCE METHOD
The modiﬁed covariance (MCOV) method stems from a modiﬁcation of the objective function in the
LS approach described above. In (19.18), the goal was to minimize the sum square forward predic-
tion errors. The MCOV method instead minimizes the sum squares of both forward and backward
prediction errors, εF and εB, respectively.
ˆθLS = arg min
θ
*.
,
N−1
X
k=p
ε2
F[k] +
N−p−1
X
k=0
ε2
B[k]+/
-
(19.26)
By a change of summation index, the objective function can also be written as
N−1
X
k=p
ε2
F[k] +
N−p−1
X
k=0
ε2
B[k] =
N−1
X
k=p
(ε2
F[k] + ε2
B[k −P])
(19.27)
To understand the notion of backward prediction error, recall the concept of PACF in §8.5.1 where
the notion of backcasting was introduced. It is concerned with predicting v[k] using a set of future
samples.
ˆv[k|{v[k + 1],· · · ,v[k + P]}] =
P
X
i=1
(−βi)v[k + i]
(19.28)
The backward prediction error is then deﬁned in a similar way as the forward case:
εB[k] = v[k] −ˆv[k|{v[k + 1],· · · ,v[k + P]}]
(19.29)
We showed in §8.5.1 speciﬁcally for an AR(1) process that the optimal coeﬃcients (in a LS sense)
are identical to the optimal coeﬃcients of the forecasting model. In the general case also this holds,
β⋆
i,LS = d⋆
i,LS, i = 1,· · · ,P
(19.30)
Thus, the objective of the MCOV method is to minimize
N−1
X
k=p

*
,
v[k] +
P
X
i=1
div[k −i]+
-
2
+ *
,
v[k −P] +
P
X
i=1
div[k −P + i]+
-
2
(19.31)
It is left as an exercise to the reader (see Exercise E19.3) to show that the solution to the above
optimization problem is of the same form as from the LS or the covariance method, but with the
auto-covariance estimate replaced by the one given below.
ˆθMCOV = −ˆΣ−1
P ˆσP
ˆσvv[l1,l2] =
N−1
X
k=p
(v[k −l1]v[k −l2] + v[k −P + l1]v[k −P + l2])
ˆΣP,i j = ˆσ[i, j];
ˆσP,i = ˆσ[i,1],
i = 1,· · · ,P; j = 1,· · · ,P
(19.32a)
(19.32b)
(19.32c)

526
Principles of System Identiﬁcation: Theory and Practice
The covariance matrix ˆΣP is no longer Toeplitz and therefore a recursion algorithm such as the D-L
method cannot be applied.
Properties of the covariance methods
1. The asymptotic properties of the covariance (LS) and the MCOV estimators in (19.20) and
(19.32), respectively, are identical to that of the Y-W estimator (Marple, 1987).
2. Application of these methods to the estimation of line spectra (sinusoids embedded in noise)
produces better results than the Y-W method, especially for short data records. The modiﬁed
covariance estimator fares better than the OLS in this respect.
3. On the other hand, stability of the resulting models is not guaranteed while using the covariance-
based estimators. Moreover, the variance-covariance matrix does not possess a Toeplitz structure,
which is disadvantageous from a computational viewpoint.
Example 19.2: Estimating AR(2) Using LS and MCOV
For the series of Example 19.1, estimating the parameters using the LS method produces
ˆd1 = −1.269;
ˆd2 = 0.3833
The MCOV method yields
ˆd1 = −1.268;
ˆd2 = 0.3827
which only slightly diﬀer among each other and the Y-W estimates.
The standard errors in both estimates are identical to those computed in the Y-W case by
virtue of the properties discussed above.
19.2.4
BURG’S METHOD
Burg’s method minimizes the same objective as the MCOV method, but with the aims of incorpo-
rating two desirable features: (i) stability of the estimated AR model and (ii) a D-L like recursion
algorithm for parameter estimation (Burg, 1975). The key idea is to employ the reﬂection coeﬃ-
cient (negative PACF coeﬃcient)-based AR representation (recall §9.5.4). That is, it estimates the
reﬂection coeﬃcients κp, p = 1,· · · ,P instead of the model parameters.
Further, given the connection between the reﬂection coeﬃcients and the stationarity of the associ-
ated AR process, stability of the estimated model is guaranteed by requiring the magnitudes of the
estimated reﬂection coeﬃcients to be each less than unity.
The optimization problem remains the same as in the MCOV method. For an AR(p) model, solve
min
κp
N−1
X
k=p
(ε2
F[k] + ε2
B[k −P])
(19.33)
Consequent to the requirement that a D-L like recursive solution be obtained, Burg’s method solves
the above optimization problem using the optimal solution at order (p −1). In order to arrive at
the solution, a recursive relationship for the prediction errors associated with two successive orders
is required. Additionally, this recursive relation should involve the decision variable, which is the
reﬂection coeﬃcient κp.
The forward and backward prediction errors associated with a model of order p can be re-written

Identiﬁcation of Parametric Time-Series Models
527
as follows:
ε(p)
F [k] = v[k] +
p
X
i=1
div[k −i] =
f
v[k]
· · ·
v[k −p]
g " 1
θ(p)
#
(19.34)
ε(p)
B [k −p] = v[k −p] +
p
X
i=1
div[k −p + i] =
f
v[k]
· · ·
v[k −p]
g " ¯θ(p)
1
#
(19.35)
Recalling (9.46) and combining it with (19.34) and (19.35), the following recursive relation between
the forward and backward prediction errors from models of two successive orders can be obtained:
ε(p)
F [k] = ε(p−1)
F
[k] + κpε(p−1)
B
[k −p]
(19.36)
ε(p)
B [k −p] = ε(p−1)
B
[k −p] + κpε(p−1)
F
[k]
(19.37)
Inserting the recursive relations into the objective function and solving the optimization problem
yields
ˆκ⋆
p = −2
N−1
X
n=p
ε(p−1)
F
[n]ε(p−1)
B
[n −p]
N−1
X
n=p

(ε(p−1)
F
[n])2 + (ε(p−1)
B
[n −p])2
(19.38)
Stability of the estimated model can be veriﬁed by showing that the optimal reﬂection coeﬃcient in
(19.38) satisﬁes |κp| ≤1, ∀p (see Exercise E19.4).
The estimates of the innovations variance are also recursively updated as:
ˆσ2(p)
e
= ˆσ2(p−1)
e
(1 −ˆκ2
p)
(19.39)
Given that the reﬂection coeﬃcients are always less than unity in magnitude, the innovations vari-
ance is guaranteed to decrease with increase in order. Equation (19.39) also serves in selecting the
appropriate order, which is not discussed here.
A basic procedure for Burg’s algorithm thus follows:
1. Set p = 0 and θ(0) = 0 so that the forward and backward prediction errors are initialized to
ε(0)
F [k] = v[k] = ε(0)
F [k].
2. Increment the order p by one and compute κp+1 using (19.38).
3. Update the parameter vector θ(p+1) using (9.46).
4. Update the prediction errors for the incremented order using (19.34) and (19.35).
5. Repeat steps 2-4 until a desired order p = P.
It is easy to see that the optimal estimate of κ1 with the initialization above is ˆκ⋆
1 = ρvv[1], which is
also the optimal LS estimate of an AR(1) model. A computationally eﬃcient version of the above
algorithm updates the denominator of (19.38) recursively. This is known as Burg’s recursion. See
Marple (1987) for details.
Properties of Burg’s estimator
Asymptotic properties of the optimal estimates of κp are not straightforward to come by particularly
when the postulated model order is lower than the true order P0. It is even more diﬃcult to analyze
the properties of parameter estimates since they are not explicitly optimized. In a work by Kay

528
Principles of System Identiﬁcation: Theory and Practice
and Makhoul (1983), Burg’s method is shown to share an asymptotic equivalence with the Y-W
estimator when p ≥P0, i.e., when the postulated order is at least equal to the true order (see also
Hainz (1994)). The bias properties were studied by Lysne and Tjostheim (1987) using extensive
simulations (see also Hainz (1994)). The key facts are summarized below:
i. The bias of Burg’s estimates are as large as those of the LS estimates, but lower than those of the
Yule-Walker, especially when the underlying process is auto-regressive with roots near the unit
circle.
ii. The variance of reﬂection coeﬃcient estimates for models with orders p ≥P0 are given by
var( ˆκp) =

1 −κ2
p
N
,
p = P0
1
N ,
p > P0
(19.40)
The case of p > P0 is consistent with the result for the variance of the PACF coeﬃcient estimates
at lags l > P0 given by (16.47) and (19.11).
iii. The innovations variance estimate is asymptotically unbiased (Akaike reference), again when the
postulated order is at least equal to the true order
E( ˆσ2
e) = σ2
e

1 −p
N

, p ≥P0
=⇒lim
N→∞E( ˆσ2
e) = σ2
e
(19.41)
iv. All reﬂection coeﬃcients for orders p ≥P0 are independent of the lower order estimates.
v. By the asymptotic equivalence of Burg’s method with the Y-W estimator, the distribution and
covariance of resulting parameter estimates are identical to that given in (19.8). The diﬀerence is
in the point estimate of θ and the estimate of the innovations variance.
vi. Finally, a distinct property of Burg’s estimator is that it guarantees stability of AR models.
Uses in modeling and spectral estimation
In parametric spectral density estimation, speciﬁcally, the detection of sines in noise, the Y-W
method is known to produce inaccurate estimates because it eﬀectively assumes the signal to be
zero outside the data interval in estimating the ACVF. This is frequently referred to as windowing
of the data. Further it produces poor results with short data records and introduces a bias in the fre-
quency estimation. An advantage, however, is that it always results in stable estimate of the model.
The large bias (inaccuracy) in the model estimate when the true process has poles close to unit
circle, however, makes it a less preferred estimator.
The covariance and the MCOV estimators possess better small sample properties than the Y-W,
but lose out on guaranteeing stability. They result in high-resolution spectral estimates and do not
suﬀer from frequency biases of the Yule-Walker method. These improvements are accomplished due
to the modiﬁed ACVF estimators in (16.41) and (19.32b), respectively. The lack of a stable model
assurance requires the user to manually examine the stability of the resulting estimate. Between the
two estimators, the MCOV method has an edge over the covariance estimator due to the diﬀerences
in the objective function and hence the ACVF estimator. Further, among all the four estimators the
MCOV method produces spectral estimates with least variance (see Narasimhan and Veena (2010)).
Burg’s estimator oﬀers a compromise between the MCOV and the Y-W estimators in the sense
that the stability of the latter is preserved while achieving the high resolution spectral estimate fea-
ture of the former. However, it does suﬀer from certain disadvantages, particularly, when used in
parametric spectral estimation. Bias in estimation of frequencies of sinusoids in noise is a promi-
nent shortcoming. Others include spectral line splitting, i.e., a single sine wave manifesting as two
sine waves with closely spaced frequencies, and sensitivity of peaks (in spectra) to initial phase.
Modiﬁcations addressing some of these shortcomings are available (see Kay (1988, Chapter 7) and

Identiﬁcation of Parametric Time-Series Models
529
the references therein). In time-series modeling, Burg’s method is preferred because it guarantees
stability of the resulting estimate. The MCOV estimator with a manual check on the stability is also
recommended. Note that none of these guarantee stability of the models in the conﬁdence region.
For further discussion on the comparison of these methods, the reader is referred to Broersen
(2006), Kay (1988), Marple (1987), and Narasimhan and Veena (2010).
Example 19.3: Simulated AR(2) Series
For the simulated series considered in 19.1 and 19.2, the Burg’s method produces estimates
ˆd1 = −1.267;
ˆd2 = 0.3827
which are almost identical to the MCOV estimates.
Once again given the large sample size, the asymptotic properties can be expected to be
identical to that of previous methods.
19.2.5
ML ESTIMATOR
Application of the maximum likelihood method to estimation of AR models was presented in
§15.1.2 with exogenous inputs included. The procedure and the features of the estimator there-
fore apply identically to the pure AR case as well. Invoking the results from §15.1.2, MLE gives
rise to a non-linear estimator for the AR model. The innovations estimate in (15.44) applies to the
AR case with the inputs excluded from the unconditional sum squares.
Comparing the ML estimator with the previously discussed estimators, the ML method is com-
putationally more expensive. The cost of computation increases considerably with the order. An
attractive feature of the ML estimator is its asymptotic properties, namely, consistency and eﬃ-
ciency. However, these large sample properties are achieved by the Y-W, OLS and Burg’s method
estimators as well (Shumway and Stoﬀer, 2006). Therefore there is usually little incentive in adopt-
ing the maximum likelihood method for estimating AR models. In line with this recommendation
are a few other minor practical aspects that are discussed in Broersen (2006).
19.3
ESTIMATION OF MA MODELS
The problem of estimating an MA model is more involved than that of the AR parameters for one
prime reason that the predictor is non-linear in the unknowns. With an MA(M) model the predictor
is
ˆv[k|k −1] = c1e[k −1] + · · · + cMe[k −M],
k ≥M
(19.42)
wherein both the parameters and the past innovations are unknown. Thus, the non-linear least
squares estimation method and the MLE are popularly used. Both these methods require a proper
initialization so as to not get lost in local minima. A few popular methods for obtaining preliminary
estimates are listed below.
i. Method of moments: From the principles discussed in §14.2, the method works on equating
theoretical with sample moments. For example, an MA(1) model results in the simple equation
(recall §9.4.1)
ˆρvv[1] =
c1
1 + c2
1
(19.43)
giving rise to two solutions from which we select the invertible solution.
Clearly, the method results in a set of non-linear equations, which is not quite attractive for a
preliminary estimator. Moreover, it produces highly ineﬃcient estimates. Therefore, it is also a
poor candidate for a standalone estimator.

530
Principles of System Identiﬁcation: Theory and Practice
ii. Durbin’s method: The idea underlying Durbin’s estimator is to ﬁrst generate the innovation se-
quence through a high-order AR model, which can be estimated using the OLS technique. Sub-
sequently, the MA(M) model is re-written as
v[k] −ˆe[k] =
M
X
i=1
ci ˆe[k −i]
(19.44)
where ˆe[k] = ˆD(q−1)v[k] is the estimate obtained from the AR model. Observe that the expres-
sion above diﬀers from (19.42) in that here e[k] is estimated using v[k] whereas e[k] is estimated
from past of v[k] and hence is set to zero. The order of the AR model used above can be selected
in diﬀerent ways, for example, using AIC or BIC (see §22.6.3). A simple guideline recommends
P = 2M.
Durbin’s estimator is known to produce good estimates in situations where the true process does
not have zeros close to the unit circle in a similar way as Y-W method for estimating AR models.
For a more detailed reading, see Broersen (2006).
iii. Innovations algorithm: The technique essentially estimates the MA parameters iteratively in a
way similar to the D-L algorithm for AR models. The key idea is to use the innovations repre-
sentation of the MA model by recalling that the white-noise sequences are also theoretically the
one-step ahead predictions (see §18.3). Deﬁning c0 ≡1
v[k] =
M
X
i=0
cie[k −i] =
M
X
i=0
ci(v[k] −ˆv[k|k −1])
(19.45)
Denoting the vector of coeﬃcients of MA(m) model by {cmi, i = 1,· · · ,m} and ˆσ2
e,m to repre-
sent the associated innovations variance, we have the recursive algorithm (Brockwell and Davis,
1991),
1. Set m = 0 and ˆσ2
e,0 = ˆσ2
v.
2. Compute
ˆcm,m−j = ( ˆσ2
e,m)−1 *.
,
σvv[m −j] −
j−1
X
i=0
ˆcj, j−i ˆcm,m−i ˆσ2
e,i+/
-
,
0 ≤j < m
(19.46)
3. Update the innovations variance
ˆσ2
e,m = ˆσ2
v −
M−1
X
j=0
ˆc2
m,m−j ˆσ2
e, j
(19.47)
4. Repeat steps 2 and 3 until a desired order m = M.
The procedure described above is based on the innovations algorithm form of the one-step ahead
prediction presented in §18.3. For exact details, see Brockwell and Davis (1991).
Although the innovations algorithm has a strong resemblance to the D-L algorithm for AR(p)
models, an important factor distinguishes them. The Durbin-Levinson algorithm is guaranteed
to produce consistent estimates of the parameters of an AR(p) model whenever p = P0, the true
order of the AR process whereas this is not true of the innovations algorithm. Consistency is only
guaranteed when the selected order m = M is “suﬃciently” large, which is not necessarily equal
to the true order M0. A rigorous condition is given in Brockwell and Davis (1991). For practical
purposes, it suﬃces to choose an order at which the estimates “stabilize,” i.e., no signiﬁcant
change in the parameter estimates is observed or to use information criterion-based methods. The
ACF estimate plot along with the 95% conﬁdence bands is also a valuable source of information
on the requisite order.
Owing to the properties of the estimates from the innovations algorithm, these are primarily used
to seed the ML or NLS algorithms.

Identiﬁcation of Parametric Time-Series Models
531
iv. Hannan-Rissanen algorithm: The approach is similar to that of Durbin’s estimator in the sense
that the innovations are replaced by their estimates from an AR model. However, the diﬀerence
is that the parameters are estimated from a linear least-squares regression of v[k] on estimated
past innovations:
ˆv[k] =
M
X
i=1
ci ˆe[k −i],
k ≥M
(19.48)
The past terms of ˆe[k] are obtained as the residuals of a suﬃciently high AR (p) model. The
parameter estimates can be further updated using an additional step, but it can be usually avoided.
The maximum likelihood and the non-linear least squares estimators are presented in the following
section concerning estimation of ARMA models. By setting the AR terms to zero, these approaches
specialize to the estimation of MA models.
In passing, it should be remarked that the Durbin’s estimator and the innovations algorithm fare
much better than the MoM estimator in terms of eﬃciency. In certain schools of thought, the
Durbin’s estimator is preferred to the MLE due to the convergence and invertibility issues asso-
ciated with the latter (see Broersen (2006)).
19.4
ESTIMATION OF ARMA MODELS
Given a set of N observations {v[0],v[1],· · · ,v[N −1]} of a process, we set out to estimate the
P′ = P + M parameters θ =
f
d1
· · ·
dP
c1
· · ·
cM
gT of the ARMA(P, M) model
v[k] +
P
X
j=1
d jv[k −j] =
M
X
i=1
cie[k −i] + e[k]
(19.49)
and the innovations variance σ2
e. It is assumed without loss of generality that the generating process
is zero-mean.
The predictor of the ARMA model is clearly non-linear in unknowns due to the presence of the
MA term, as a result of which the NLS algorithm is employed. A Gauss-Newton or the Levenberg-
Marquardt method (recall §14.4.1) is used to determine the numerical optimum. In the MLE ap-
proach, the likelihood function is not as straightforward to construct as was the case with AR
models. However, the experience in §15.1.2 hints at the use of prediction errors (innovations) for
constructing the likelihood function, which is indeed the approach used in practice.
19.4.1
NON-LINEAR LS ESTIMATION
The objective function to minimize is
J(θ,σ2
e) =
N−1
X
k=max(P, M)
(v[k] −ˆv[k|k −1])2
(19.50)
where
ˆv[k|k −1] = −
P
X
j=1
d jv[k −j] +
M
X
i=1
cie[k −i]
(19.51)
The objective function in (19.50) refers to the conditional NLS since it takes the ﬁrst k =
0,· · · ,max(P, M) observations to be ﬁxed. The unconditional version, in contrast, takes into ac-
count the randomness in those observations as well (recall §15.1.2). However, when the sample size
is large, the diﬀerences between these two versions vanish.

532
Principles of System Identiﬁcation: Theory and Practice
Applying a numerical method to determine the optimum requires evaluation of gradients of the
objective function, speciﬁcally those of the predictor ˆv[k]. For instance when using the Gauss-
Newton method of iteration, (14.109), we have
θ(i+1) = θ(i) + (Ψ(θ(i))T Ψ(θ(i)))−1Ψ(θ(i))Tεi
(19.52)
where for the problem under study,
Ψ(θ) = ∇θ ˆv =
f
ψ(0,θ)
ψ(1,θ)
· · ·
ψ(N −1,θ)
gT
(19.53)
and the gradient is
ψ(k,θ) = ∂ˆv(k,θ)
∂θ
= −∂ε(k,θ)
∂θ
=
" ∂ˆv[k]
∂θ1
· · ·
∂ˆv[k]
∂θP′
#T
(19.54)
where ε(k,θ) = v[k] −ˆv(k,θ) is the prediction error. The gradients are evaluated using the notion
of innovations, i.e., by replacing the white-noise terms in ˆv[k] with the one-step ahead prediction
errors (residuals) of the model.
The procedure is illustrated on an ARMA(1,1) model.
Example 19.4: Gradients for ARMA(1,1)
For an ARMA(1,1) model, θ =
f
d1
c1
gT . The predictions and prediction errors are given
by,
ˆv[k] = −d1v[k −1] + c1e[k −1] = −d1v[k −1] + c1ε(k −1,θ)
(19.55)
=⇒ε(k,θ) = v[k] + d1v[k −1] −c1ε(k −1,θ)
(19.56)
where the residuals of the model (at each iteration) are used as substitutes for the innovations
e[k].
Equation (19.56) can be further re-written as
(1 + c1q−1)ε(k,θ) = v[k] + d1v[k −1]
(19.57)
Thus, the gradient of the predictor at the ith iteration is obtained by ﬁrst noting that
(1 + c1q−1) ∂ε(k,θ)
∂d1
= −v[k −1]
(1 + c1q−1) ∂ε(k,θ)
∂c1
+ ε(k −1,θ) = 0 =⇒(1 + c1q−1) ∂ε(k,θ)
∂c1
= −ε(k −1,θ)
where we have used the chain (or the product) rule to evaluate the derivative w.r.t. c1.
Using ∂ˆv/∂θ = −∂ε/∂θ, the gradients are the outputs of an AR(1) process with two diﬀerent
inputs
ψ(k,θ(i)) =
1
1 + c1q−1
f
v[k −1]
ε(k −1,θ(i))
gT
(19.58)
Alternatively, they are the outputs of two diﬀerent AR(1) processes with the same input,
ψ(k,θ(i)) =
"
1
1 + d1q−1 ε(k −1,θ(i))
1
1 + c1q−1 ε(k −1,θ(i))
#T
(19.59)
where in deriving (19.59) we have applied the model (1 + d1q−1)v[k] = (1 + c1q−1)e[k] to the
residuals and replacing e[k] with ε[k].

Identiﬁcation of Parametric Time-Series Models
533
The form of the gradients obtained above for an ARMA(1,1) process extends to the general ARMA
and the ARMAX models as well.
The unconditional NLS formulation also employs an identical procedure with the only diﬀerence
that the summation in the objective function (19.50) begins from k = 0 or sometimes even at nega-
tive values with backcasting for generating the series at k < 0 (see Brockwell and Davis (1991) and
Shumway and Stoﬀer (2006)). A discomfort with using the unconditional NLS is that the problem
remains non-linear even for the estimation of AR models, as was noted in §15.1.2.
Next we turn to the MLE method.
19.4.2
MAXIMUM LIKELIHOOD ESTIMATION
The ML estimation as usual begins by setting up the likelihood function of the observations. Making
the standard assumption of GWN, the likelihood of the series v = {v[k]}N−1
k=0 is
l(θ,σ2
e) = f (v[0],· · · ,v[N −1]|θ) =
1
(2π)N/2|ΣN |1/2 exp
 
−1
2vT
N Σ−1
N vN
!
(19.60)
where ΣN = E(vNvT
N ) is the true variance-autocovariance matrix of the observations and |.| denotes
the determinant.
The approach used is essentially an extension of (15.35), presented for the ARX model estima-
tion. Factorize the joint p.d.f. by conditioning the present observation on the previous observations
and rope in the prediction errors. However, the presence of the MA component makes it more com-
plicated because the past innovations are also required for predictions. To understand this point,
consider the ARMA(1,1) model. The conditioned observation and prediction at k = 1 are, respec-
tively,
v[1]|v[0] = e[1] + c1e[0] −d1v[0],
ˆv[1|v[0]] = E(v[1]|v[0]) = c1E(e[0]|v[0]) −d1v[0] (19.61)
The conditional p.d.f. f (v[1]|v[0]) requires the knowledge of e[0] or the one-step ahead prediction
errors ε[0] = v[0] −ˆv[0| −1], which, in turn, requires the knowledge of v[−1] and ε[−1] (or e[−1]).
Thus, the factorization of the joint p.d.f. is not as straightforward as in the AR case. Three strategies
are followed to address this issue, for a general ARMA(P, M) model, leading to the conditional, un-
conditional and exact likelihood functions. These are in the order of increasing rigour and naturally,
the computational burden.
The conditional likelihood is obtained by ﬁxing the past M observations and innovations, typically
by their means (usually zero), v[k] = 0, ε[k] = 0,k < 0. The innovations at non-negative times are
then computed as
ε[k] = v[k] −ˆv[k|k −1] = v[k] +
k−1
X
j=0
d jv[k −j] −
k−1
X
i=0
cie[k −i],
k = 0,· · · , N −2
(19.62)
The conditional log-likelihood is then
L(θ) = −N
2 ln 2π −N
2 ln σ2
e −
N−1
X
k=0
ε2[k]
2σ2e
(19.63)
Another strategy recommended by Box, Jenkins and Reinsel (2008) is to start the computation of
predictions at k = P and set all innovations up to k = P −1 to zero, i.e., ε[P −1] = · · · =
ε[P −M + 1] = 0. Then, the log-likelihood is given by
L(θ) = −N −P
2
ln 2π −N −P
2
ln σ2
e −
N−1
X
k=P
ε2[k]
2σ2e
(19.64)

534
Principles of System Identiﬁcation: Theory and Practice
Example 19.5 illustrates how to set up the conditional MLE for an MA(1) model.
Example 19.5: Conditional Likelihood for an MA(1) Model
Given an MA(1) model v[k] = e[k]+c1e[k −1], and the innovations are zero at negative time,
i.e., ε[k] = 0, k < 0, we have
v[0]|{ε[−1] = 0} = e[0] =⇒v[0]|ε[−1] ∼N (0,σ2
e)
v[1]|{v[0],ε[0]} = e[1] + c1ε[0] =⇒v[1]|{v[0],ε[0]} ∼N (c1ε[0],σ2
e)
Extending this approach to the general k we have
v[k]|{v[k −1],ε[k −1]} ∼N (c1ε[k −1],σ2
e)
(or ˆv[k|k −1] = −
k−1
X
j=0
(−c1)k−jv[j])
(19.65)
The log-likelihood is, as stated earlier,
l(c1,σ2
e) = −N
2 ln 2π −N
2 ln σ2
e −
N−1
X
k=0
ε2[k]
2σ2e
(19.66)
where
ε[k] = v[k] −c1ε[k −1],k ≥1; ε[0] = v[0]
(19.67)
which is evidently a complicated non-linear function of the parameters. Methods such as
Gauss-Newton or the Fisher’s scoring algorithm discussed in §15.1.3 are used to determine
the optimal parameters that maximize (19.66).
Example 19.5 can be modiﬁed in a straightforward way to write the likelihood for an ARMA(1,1).
The predictor would then additionally include the regressive term −d1v[k−1] (see Exercise E19.10).
The unconditional likelihood is set up by replacing the past innovations and observations with
their backcasts, which are obtained by writing the ARMA(P, M) model backwards. See Box, Jenkins
and Reinsel (2008, Chapter 7) for an illustration of this approach. The conditional and unconditional
likelihood yield estimates with similar properties for large samples, but the latter are more eﬃcient
for smaller sample size and processes with poles close to unit circle.
Finally, the exact likelihood is set up directly from (19.60) using the innovations algorithm, as
described brieﬂy below. The main idea is to re-write the joint density in terms of the innovations
using the BLP discussed in §18.2.1 so that we move from a full covariance matrix to a diagonal
covariance matrix. Only the main ideas are outlined. For a full description, refer to Brockwell and
Davis (1991).
Innovations-based MLE
To understand the basic principle, refer to Equation (19.65) of Example 19.5, where the predictor
ˆv[k|k −1] has the form of best linear predictor at each instant. The key idea is to expresseach
observation v[k], k = 0,· · · , N −1 in terms of their BLPs and innovations as

v[0]
v[1]
...
v[N −1]

= C

v[0] −P0v
v[1] −P1
0v
...
v[N −1] −P N
N−1v

= C

ε0
ε1
0...
εN
N−1

|  {z  }
ε
(19.68)

Identiﬁcation of Parametric Time-Series Models
535
where C is a lower triangular matrix with ones on its diagonal. In writing the above relation we
have used the notation of §18.2.1. The advantage of writing the observations in the form (19.68) is
that the innovations at two diﬀerent instants are uncorrelated. Consequently, the covariance of the
observations can be expressed as
Σ−1
N = CDCT
(19.69)
where D is a diagonal matrix containing conditional variance of the innovations,
D = diag(λ0,λ1
0,· · · ,λN
N−1)
(19.70)
Furthermore, from (19.69) the determinant of ΣN is
|ΣN | = |C|2
N−1
Y
k=0
λk
k−1 =
N−1
Y
k=0
λk
k−1
(19.71)
vT Σ−1
N v = εTD−1ε
(19.72)
With these relations and recalling (18.15) for the conditional variance of innovations, i.e., λk
k−1 =
σ2
erk
k−1 (in Example 19.5, we had λk
k−1 = var(ε[k|k −1]) = σ2
e(1 + c2k
1 )), the likelihood in (19.60)
can be re-written in terms of the innovations:
l(θ,σ2
e) =
1
((2πσ2e)N QN−1
k=0 rk
k−1(θ))1/2 exp
 
−S(θ)
2σ2e
!
(19.73)
where rk
k−1(θ) is independent of σ2
e and S(θ,σ2
e) is the unconditional sum squares
S(θ) =
N−1
X
k=0
(εk
k−1(θ))2
rk
k−1(θ)
(19.74)
The log-likelihood is therefore
L(θ,σ2
e) = const. −N
2 ln σ2
e −N
2
N−1
X
k=0
ln rk
k−1 −1
2
S(θ,σ2
e)
σ2e
(19.75)
solution to which can be obtained only numerically. However, a closed-form expression can be given
for the estimate of σ2
e as
ˆσ2
e,ML = S( ˆθML)
N
(19.76)
As in the MLE of AR models, an unconditional least squares can be solved by dropping the second
ln rk
k−1, k = 0,· · · , N −1 terms in (19.66). The conditional NLS objective is obtained by only
considering the last term.
Initialization
Both the NLS and ML estimators have to be initialized with appropriate guesses, which are typically
generated by one of the four methods discussed earlier in §19.3. Although those methods were
presented for the MA case, it is straightforward to extend the ideas to include the auto-regressive
terms as well. The MoM would, for instance, have to be set up to write equations for ACVF in
terms of model parameters (recall the discussion in §9.6). In a similar way, the Hannan-Rissanen
algorithm can be extended to include additional regressive terms in the predictor for v[k].

536
Principles of System Identiﬁcation: Theory and Practice
19.4.3
PROPERTIES OF THE NLS AND ML ESTIMATORS
Deriving the asymptotic properties of the NLS (i.e., the conditional/unconditional ML) and ML
estimators is beyond the scope of this text. It suﬃces to only state the main result (for details, see
Brockwell and Davis (1991) and Shumway and Stoﬀer (2006)).
Theorem 19.1
The parameter estimates of an ARMA(P, M) model obtained from the unconditional, conditional
least squares and the ML estimators initialized with the method of moments are asymptotically
consistent. Further,
√
N( ˆθ −θ0) ∼AsN

0,σ2
eS(θ0)−1
(19.77)
The (P + M) × (P + M) covariance matrix S is given by
S =
" E(xPxT
P)
E(xPwT
M)
E(wMxT
P)
E(wMwT
M)
#
(19.78)
where xP and wM are constructed from two auto-regressive processes
xP =
f
x[k −1]
x[k −2]
· · ·
x[k −P]
gT ;
x[k] =
1
D(q−1) e[k]
(19.79)
wM =
f
w[k −1]
w[k −2]
· · ·
w[k −M]
gT ;
w[k] =
1
C(q−1) e[k]
(19.80)
Proof. See Brockwell and Davis (1991).
□
Remarks:
i. The block diagonals S11 (P × P) and S22 (M × M) are essentially the auto-covariance matrices of x[k] and
w[k], respectively, while the oﬀ-diagonals are the matrices of cross-covariance functions between x[k] and
w[k]. Intuitively this result can be understood as follows.
Recall that a Gauss-Newton method solves an OLS problem at each iteration with the vector of regressors
ϕ being the vector of predictor gradient ψ. For an ARMA(P, M) process, ψ is a (P + M) × 1 vector (recall
Example 19.4). The OLS estimation theory in §14.3.1 tells us that the covariance of θ is σ2eE(ϕϕT ). From
Example 19.4, speciﬁcally from (19.59), we recognize that the gradient vector ψ can be expressed as the
outputs of P and M AR processes with transfer functions q−i/D(q−1), i = 1,· · · ,P and q−j/C(q−1), j =
1,· · · , M, respectively. Connecting these two facts explains the result in Theorem 19.1.
ii. A few special cases aid in a better understanding of Theorem 19.1.
a. AR(1): For this case, S is a scalar. Using (19.78),
S = E(x[k −1]x[k −1]) = σ2
e/(1 −d2
1) =⇒var( ˆd1) = (1 −d2
1)/N
(19.81)
b. MA(1): Using (19.78),
S = E(w[k −1]w[k −1]) = σ2/(1 −c2
1) =⇒var( ˆc1) = (1 −c2
1)/N
(19.82)
The similarity of (19.82) with (19.81) is due to the fact that the gradient of the predictor for MA(1) is
similar to that for the AR(1) case.

Identiﬁcation of Parametric Time-Series Models
537
c. ARMA(1,1): For this case, S is a matrix. It is left as an exercise to the reader to show that
S =
"σxx[0]
σxw[0]
σwx[0]
σww[0]
#
= σ2
e

1
(1 −d2
1)
1
1 −c1d1
1
1 −c1d1
1
(1 −c2
1)

(19.83)
As a reiteration of the basic point that we made in Chapter 13, one of the purposes of deriving the
theoretical variance estimates is to obtain insights into selecting an appropriate model dimensionality
(number of parameters) and a suﬃcient sample size for a given precision. For instance, ﬁtting higher
order-models to lower-order processes can result in loss of eﬃciency.
iii. Theorem 19.1 is valid only when the sample size is large. For small samples, no expression for the variance
or the distribution exists. In such cases, the bootstrapping method is an eﬀective alternative.
Notwithstanding the nice properties of ML estimators, they are also marked by certain criticisms.
Some of these include diﬃculties in convergence and lack of guarantee of invertibility. See Broersen
(2006) for an insightful discussion.
TABLE 19.1
Procedure to estimate an ARMA model
1. Carry out a visual examination of the series. Inspect the data for “outliers,” drifts, signiﬁcantly
diﬀering variances, etc.
2. Perform the necessary pre-processing of data (e.g., removal of trends, transformation) to obtain
a stationary series.
3. Compute the ACF and PACF to make a preliminary guess of the AR and MA parts. For develop-
ing a pure AR model, PACF gives a good estimate of the requisite order and likewise ACF for a
pure MA model.
4.
a. For AR models, use the MCOV or Burg’s method with the chosen order. If the purpose is
spectral estimation, then prefer the MCOV method.
b. For MA and ARMA models, generate preliminary estimates (typically using the Y-W or
the H-R method) with the chosen orders. Use these preliminary estimates with an MLE or
NLS algorithm to obtain “optimal” estimates.
5. Subject the model to a quality (diagnostic) check. If the model passes all the checks, then accept
this model. Otherwise, work towards an appropriate model order until satisfactory results are
obtained.
Estimation of ARMA models is a problem of importance in many ﬁelds with a host of methods.
The eﬀectiveness of each approach depends on various factors such as sample size, process char-
acteristics, a priori knowledge and so on, thereby making it near impossible to suggest a universal
method. Having said thus, in a fairly general scenario, NLS and MLE methods have been observed
to deliver reasonably good estimates when the generating process is “well-behaved” and the sample
size is large. On the same note, there exists no decisive method for order determination. Among
the several methods, two information-theoretic criteria namely the Akaike’s information criterion
(AIC) and the Schwartz-Bayesian information criterion (SIC or BIC) are widely used. A general
procedure for time-series modeling is outlined in Table 19.1.
Over the last two decades, state-space methods for estimating ARMA models have gained signif-
icant momentum. Estimation algorithms for these models employ the celebrated Kalman ﬁlter for

538
Principles of System Identiﬁcation: Theory and Practice
generating the one-step ahead predictions. An advantage with the SS representations is the avail-
ability of an automatic method for order determination. Several modern texts discuss this topic (see
Shumway and Stoﬀer (2006) for instance). Chapter 23 on subspace identiﬁcation describes these
ideas in the context of identiﬁcation.
An illustrative example of estimating an ARMA model for the simulated series of Example 9.10
is presented below.
Example 19.6: Estimating an ARMA Model
The objective of this exercise is to build an ARMA representation for the process of Exam-
ple 9.10. We had earlier examined the ACF and PACF plots in Figures 9.6(a) and 9.6(b),
respectively.
Beginning with an ARMA(1,1) representation, the estimated model is
ˆH(q−1) = 1 +
(±0.025)
0.418 q−1
1 −0.629
(±0.02)q−1
(19.84)
where once again the standard errors in the estimates are reported below each coeﬃcient
estimate. Undoubtedly, the obtained estimates have a good precision (low variability). Addi-
tionally, the model is both stationary and invertible.
The ACF of residuals from the estimated model is shown in Figure 19.1. The model is thus
satisfactory in both respects.
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
FIGURE 19.1
ACF of the residuals from the ARMA(1,1) model.
Compare the obtained model with the estimated MA and AR models in 9.10. The ARMA
model thus oﬀers a parsimonious representation without compromising on the accuracy and
reliability.
It is of interest to note that the true process is also an ARMA(1,1) representation:
H(q−1) = 1 + 0.4q−1
1 −0.6q−1
It is a coincidence thus that the orders of the estimated model and the generating process
match each other.
When the residual whiteness test indicates the need for increasing the model order, there is no
deﬁnitive way of determining whether the numerator or denominator order or both should be in-
creased. The solution has to be determined by trial and error, but in a systematic manner. In general,

Identiﬁcation of Parametric Time-Series Models
539
when competing models are available, the decision on the ﬁnal model is based on information cri-
teria measures (see §22.6.3).
Listing 19.1
MATLAB code for Example 19.6
% Generate data
Hq = idpoly(1,[],[1 0.4],[1 -0.6],[],’Noisevariance’,1);
ek = randn(1000,1);
vk = sim(Hq,ek);
% Fit an ARMA(1,1) model
mod_arma = armax(vk,[1 1]);
present(mod_arma)
% ACF of residuals
err_arma = pe(mod_arma ,vk); % Notice err_arma is not iddata object
acf(err_arma ,20,1);
19.4.4
ESTIMATION OF ARIMA MODELS
In §9.7 we learnt that non-stationarities are of two types, deterministic (e.g., trend type non-
stationarity) and stochastic (e.g., mean, variance and integrating type non-stationarity). The focus of
this text is on the latter type. In particular, we target diﬀerence stationary processes which are nicely
represented by ARIMA models. It may also be recalled from §7.5.5 and §9.7 that ARIMA repre-
sentations are capable of handling trend-type non-stationarities as well. Here we outline a general
procedure for estimating an ARIMA model and note some cautionary points.
Section 9.7 provides the general form of an ARIMA model:
∇dv[k] = C(q−1)
D(q−1) e[k],
∇= 1 −q−1
(19.85)
In the estimation of an ARIMA model, we are interested in determining the degree of diﬀerencing
d, the orders of the ARMA components P and M and the parameters of the C and D polynomials.
Given that ARIMA models are primarily meant for diﬀerence stationary processes and that un-
necessary diﬀerencing can cause more harm than good, it is ﬁrst important to examine the data for
the presence of non-stationarities and also determine their type before arriving at a decision to ﬁt
an ARIMA model. This forms the preliminary steps in a general procedure for building ARIMA
models as outlined in Table 19.2.
Chapter 24 presents an application of time-series modeling to the temperature series from an
industrial process.
19.5
SUMMARY
In this chapter we studied the estimation of time-series models. Auto-regressive models are sim-
pler to estimate than moving average models since they are characterized by linear predictors.
Consequently, these models have received more attention in the estimation literature. Among the
known techniques, four methods are popular: Yule-Walker, least squares (covariance), forward-
backward method (modiﬁed covariance) and Burg’s estimator (based on reﬂection coeﬃcients and
the forward-backward prediction error method). The Y-W method guarantees stability but performs
poorly for integrating or long-memory processes. The covariance and MCOV methods do not suﬀer
from the latter but cannot guarantee stability. Burg’s estimator guarantees stability and also per-
forms well for long-memory processes. However, for spectral estimation, particularly detection of
sinusoids in noise, the MCOV method is better suited than Burg’s estimator. Notwithstanding these
diﬀerences, the large sample behavior of all these estimators is similar.

540
Principles of System Identiﬁcation: Theory and Practice
TABLE 19.2
Steps for building an ARIMA model
1. Examine/test the series for integrating type non-stationarity using visual inspection of the series
and/or the ACF plots and the unit root tests (e.g., Dickey-Fuller, Phillips-Perron tests). If the
series exhibits strong evidence for unit roots, then an ARIMA model can be ﬁt after following
steps 2 and 3 below.
Note: Conducting unit root tests can be challenging and involved. They have to be performed with care
and should be corroborated with visual observations of the series as well as the ACF/PACF plots.
2. If there is a strong evidence (additionally) for trend type non-stationarities, remove them by
ﬁtting polynomial functions to the series (using OLS method for example) and work with the
residuals of this ﬁt. Denote these by w[k].
Note: Polynomial trends of degree d can also be handled by ARIMA with constant models.
3. If the residuals (or the series in the absence of trends) is additionally known to contain growth
eﬀects, then a logarithmic transformation is recommended. Call the resulting series as ˜w[k] or
˜v[k] as the case maybe.
4. Determine the appropriate degree of diﬀerencing d (by a visual or statistical testing of the diﬀer-
enced series).
5. Fit an ARMA model to ∇d ˜w[k] or ∇d ˜v[k] (or to the respective untransformed series if step 3 is
skipped).
Estimation of MA models gives rise to non-linear optimization problems. The non-linear least
squares and MLE methods are widely used. To seed these algorithms, a few important methods
are used, namely, Y-W method, innovations algorithm, Durbin’s estimator and Hannan-Rissanen’s
algorithm.
There exists no decisive rule or method for estimating ARMA or ARIMA models. Following a
systematic procedure and the use of AIC and BIC for order determination in general produces a
working model. An industrial case study is presented in §24.1. It carries the characteristics of a
typical time-series modeling exercise and demonstrates the success of a systematic approach.
REVIEW QUESTIONS
R19.1 Derive the Y-W equations and explain how it can be used for estimating an AR model.
R19.2 Explain the basic diﬀerences between the four diﬀerent methods for AR model estimation dis-
cussed in §19.2.
R19.3 What is the main challenge in MLE formulation for the estimation of an ARMA model?
R19.4 Describe the main features of Burg’s method.
R19.5 Would you prefer an MA or an AR model when estimation eﬀort is the criterion?
R19.6 Describe the general method for modeling non-stationary series.
R19.7 Explain why ARIMA models are equipped to handle trend and polynomial type non-stationarities.

Identiﬁcation of Parametric Time-Series Models
541
EXERCISES
E19.1 Show that the Y-W estimator is the result of minimizing (19.3).
E19.2 Show that (19.20) can be written as a method of moments estimator.
E19.3 Prove that the MCOV method is identical to the method of moments using the auto-covariance
estimator in (19.32b).
E19.4 Show that the optimal reﬂection coeﬃcient in (19.38) satisﬁes |κp| ≤1, ∀p.
E19.5 A time-series is provided in the data ﬁle time_series1.mat.
a. Using the ACF and PACF, comment on the type of model (AR, MA or ARMA) that is suitable
for the given series.
b. Fit a suitable model for the given series (use ar or arma routines in MATLAB). The ﬁnal
model should be best in terms of predictability as well as parsimony of parameters. Present
your choice of model with suitable justiﬁcations.
E19.6 The LS estimator and the Y-W estimator produce almost identical estimates of an AR(P) model,
with a subtle diﬀerence. The subtle diﬀerence lies in the way each of these methods handle non-zero
mean of a series. Show that this diﬀerence vanishes for large N.
E19.7 Verify the fact in E19.6 on a series generated by an AR(2) model with d1 = −1.1, d2 = 0.28.
E19.8 Develop the expressions for the likelihood function for the AR(1) directly using the joint density
function
f (vN ,θ) =
1
(2π)N/2|ΣN |1/2 exp
 
−1
2vT Σ−1
N v
!
and compare it with the expression obtained in (15.29).
E19.9 Repeat the exercise in E19.8 for an MA(1) model.
E19.10 Write the likelihood function for an ARMA(1,1) model using Example 19.5 as a starting point.
E19.11 Do the following:
a. Write a MATLAB function to implement the H-R algorithm for the estimation of ARMA model
parameters. The user is expected to supply the orders of the respective components.
b. Test your code on three diﬀerent processes: (i) AR(2) process with d1 = −1.3, d2 = 0.4, (ii)
MA(2) process with c1 = 1, c2 = 0.21 and (iii) ARMA(1,2) process with d1 = 0.4, c1 = 0.7, c2 =
0.12.
E19.12 For the series v[k] given in time_series2.mat, do/answer the following:
a. Is the series stationary?
b. Fit the least parsimonious and best AR model of an appropriate order to the given series.
Provide 95% C.I. for the parameters.
c. Suppose the order of the AR model is known a priori with certainty but the parameters only
with some uncertainty. Describe how you would set up the estimation problem.
E19.13 For the data given in nottem.mat, check for periodicities from the PSD. Build a model for the
series by ﬁrst ﬁtting the periodicities and then an ARMA model for the residuals.
E19.14 A random process is known to be described by the following time-series model
v[k] =
1 + 0.5q−1
1 −1.7q−1 + 0.7q−2 e[k],
σ2
e ∼GWN(0,1)
Do/answer the following:
a. Is the process stationary and invertible? Explain
b. If your answer to part (E19.14a) is a NO, transform v[k] suitably to obtain a stationary and
invertible process. Call this transformed process w[k]
c. Compute and sketch the spectral density of v[k] or w[k] (if you found v[k] non-stationary).
d. Suppose it is desired to approximate v[k] or w[k] (whichever is applicable) with an optimal
AR(2) model. For this purpose, KaalaNipuna proposes equating the ACVFs at lags l = 0,1,2
while SamayaBhushana suggests equating the spectral densities of the process and the model.
Who do you think has a better proposition and why? Elucidate your points clearly.

20
Identiﬁcation of Non-Parametric
Input-Output Models
This chapter is devoted to the methods for estimating non-parametric models presented in
Chapter 17. Estimation of response models, namely, impulse, step and frequency responses,
is discussed.
20.1
RECAP
Before we set out to estimate non-parametric models, it is useful to recap certain relevant points
concerning their uses from previous chapters.
Non-parametric models are usually the preferred starting points in identiﬁcation for reasons dis-
cussed previously (recall §17.4). They make minimal assumptions about the process and do not
require any signiﬁcant intervention from the user. In Chapter 17 we studied three important descrip-
tions, namely, impulse, step and frequency response models. The focus is primarily on estimation of
these models, speciﬁcally in Sections 20.2, 20.3 and 20.4, respectively.
Chapters 11 and 16 described approaches for construction and estimation of non-parametric noise
models based on spectral representations. In §20.5 we shall study a non-parametric method for
estimating the disturbance spectrum from input-output data, which is essentially an extension of the
non-parametric techniques of §16.5.5 that were developed for estimating the spectral density of a
random process.
One of the reasons for non-parametric descriptions being strong contenders as starter models is
that they provide valuable knowledge on time-delay (dead time), order and process characteristics
that are required for estimating parametric models. The impulse and frequency response estimates
have been the traditional tools for this purpose. Chapter 22, speciﬁcally §22.5, is devoted to a pre-
sentation of techniques for delay estimation. The use of IR estimates in order estimation through
Hankel matrices is discussed in Chapter 23.
As with previous chapters, wherever applicable, theory is supported with demonstration on case
studies using the System Identiﬁcation toolbox of MATLAB. Throughout this chapter the following
are assumed - open-loop conditions, inputs are quasi-stationary and unmeasured disturbances are
stationary.
20.2
IMPULSE RESPONSE ESTIMATION
As was discussed in §17.4.1.1, the FIR model representation is the suitable version of the IIR model
for non-parametric identiﬁcation. The problem statement is as follows. Estimate the M unknown
coeﬃcients
θ =
f
g[0]
g[1]
· · ·
g[M −1]
gT
of the FIR model
y[k] =
M−1
X
n=0
g[n]u[k −n] + v[k]
(20.1)
from input-output data.
542

Identiﬁcation of Non-Parametric Input-Output Models
543
Two methods, namely, the covariance (MoM) method (leading to the well-known Wiener-Hopf
equations) and least squares method, are widely used for estimating IR coeﬃcients from time-
domain data. Both methods theoretically give rise to identical solutions as we have observed previ-
ously in other modeling contexts. However, the scope and quality of the estimates in practice diﬀer
signiﬁcantly. For instance, the method of moments lends itself to the well-known instrumental vari-
able (IV) method upon the use of a diﬀerent set of moment conditions and correlating instruments,
which outperforms the LS method when v[k] has internal correlation, i.e., when it is colored. On the
other hand, adding a regularization term to the LS objective function produces estimates of much
better quality than those from the regular MoM.
Before we delve into a more detailed study, it is instructive to study a simpler, but a rudimentary
method.
20.2.1
DIRECT ESTIMATION USING IMPULSE INPUTS
A simple method of determining the IR coeﬃcients is by a direct injection of impulse input of
magnitude A into the system. The measured response in presence of unmeasured disturbances /
noise v[k] is then,
y[k] = Ag[k] + v[k] =⇒ˆg[k] = y[k]
A
(20.2)
The error in the estimate is v[k]/A which can be made small by choosing a large A. However,
then we run into the risk of pushing the process into non-linear regimes. In practice therefore, this
method has little utility but allows us to develop an appreciation for estimating IR coeﬃcients from
custom-designed or arbitrary inputs.
20.2.2
ESTIMATION FROM RESPONSE TO ARBITRARY INPUTS
From the foregoing discussion, an important message emerges - the best estimate of the elementary
response of a system is not necessarily generated by using the elementary input, but rather from
a “richer” input. Typical inputs include a pseudo-random binary signal (PRBS), (band-limited)
white-noise and multisine signals. While the PRBS has certain advantages in a general identiﬁcation
problem, the white-noise input brings a speciﬁc beneﬁt to the estimation of IR coeﬃcients. This
aspect is discussed shortly.
A major impediment in the estimation of FIR model parameters is the stochastic term v[k]. Two
standard estimators, as mentioned previously, based on the covariance (MoM) and the LS methods
are widely used. Both approaches address the stochastic term v[k] in their own right (recall Chapter
14). The resulting theoretical solutions are, as discussed below, identical.
1. MoM or covariance method: As explained in Chapter 14, the idea is to ﬁrst set up equations
relating parameters to the theoretical moments and then use the sample versions in place of the
actual moments. A common approach is to use the second-order moments (covariance) condition,
which is that the observation error v[k] is uncorrelated with the (lagged) inputs u[k −l], l ≥0,
cov(u[k −l],v[k]) = E(u[k −l],v[k]) = 0,
l ≥0
which is a reasonable assumption under open-loop conditions. Feedback can result in complica-
tions (see Chapter 25.3).
Applying the moment condition to the FIR model (20.1), we obtain
E(y[k]u[k −l]) =
M−1
X
n=0
g[n]E(u[k −n]u[k −l])
(20.3)

544
Principles of System Identiﬁcation: Theory and Practice
This is also the familiar Wiener-Hopf equation
σyu[l] =
M−1
X
n=0
g[n]σuu[n −l]
(20.4)
Setting up for l = 0,· · · , M −1 to solve for M coeﬃcients gives us M equations in M unknowns.
Using matrix notation, we have thus,
Σϕϕθ = ΣYϕ =⇒
ˆθ = Σ−1
ϕϕΣYϕ
(20.5)
where
Y ≡y[k];
ϕ =
f
u[k]
u[k −1]
· · ·
u[k −(M −1)]
gT
Equations (20.4) and (20.5) are familiar to us from previous chapters. Example 8.5 produced this
result using the CCVF-ACVF relationship in (8.23) while §14.3.1 derived the same using the
theoretical solution to the OLS problem with the past inputs as regressors and the IR coeﬃcients
as unknown parameters.
In order to apply (20.5) in practice, the theoretical quantities are replaced by their sample versions
using the biased estimators in (14.32), giving rise to
ˆθ =
 1
N ΦTΦ
!−1  1
N ΦTy
!
(20.6)
where
Φ =
f
ϕ[M −1]
ϕ[M]
· · ·
ϕ[N −1]
gT
(20.7a)
ϕ[k] =
f
u[k]
u[k −1]
· · ·
u[k −(M −1)]
gT
(20.7b)
y =
f
y[M −1]
y[M]
· · ·
y[N −1]
gT
(20.7c)
From the solution above and the discussion in Chapter 14, the covariance estimator is identical
to the least squares estimator, which is discussed below.
2. Least squares method: The theoretical solution to the FIR model estimation is obtained by
directly applying (14.31) and setting the regressors and output as in the covariance method above.
The result is the same as (20.6).
The sample estimator is obtained by applying the generic LS estimator (14.21) with the regressor
matrix Φ and the observation vector y set up as in (20.7),
ˆθ = (ΦTΦ)−1ΦTy
(20.8)
which is identical to the estimator in (20.6).
For an illustration of the LS estimation of a FIR model, the reader is referred to the previously
presented Example 14.2.
Prior to a study of the properties of these estimators, it is worthwhile studying certain implemen-
tation aspects. The implementation of the FIR estimator is done along the same lines as a general
LS estimator (for example, via QR factorization). Two speciﬁc variants, the classical pre-whitening
and the modern regularization using a Bayesian approach are presented below.

Identiﬁcation of Non-Parametric Input-Output Models
545
20.2.2.1
Diagonalization: Pre-Whitening the Input
When the input has white-noise characteristics (e.g., white-noise, PRBS, multi-sine input), the auto-
covariance matrix Σϕϕ is a diagonal
Σϕϕ = σ2
uIM×M
(20.9)
the solution procedure is greatly simpliﬁed. The inversion of the matrix is avoided and the IR coef-
ﬁcients can be estimated individually. From (20.5)
ˆθl = ˆg[l] = σyu[l]
σ2u
,
l = 0,· · · , M −1
(20.10)
However, white-noise inputs are seldom used in identiﬁcation experiments because they are not
preferable from an input design viewpoint (read §22.3 for a related discussion). Nevertheless, we can
still exploit (20.10) by pre-whitening the input used in the identiﬁcation experiment. Pre-whitening
was brieﬂy discussed in §16.4. It is the process of ﬁnding a white-noise like signal eu[k] and an
associated invertible ﬁlter such that eu[k] ﬁltered by Fq(q−1) produces the input of interest u[k],
u[k] = F−1
p (q−1)eu[k] =⇒Fp(q−1)u[k] = eu[k]
(20.11)
The pre-whitening ﬁlter Fp(q−1) and the variance σ2
eu can be determined using the time-series
modeling methods of Chapter 19. Since the goal is only to obtain some ﬁlter which achieves pre-
whitening, the accuracy of the model is not a prime concern. Therefore, it is convenient to choose
an AR ﬁlter of suﬃciently high-order.
As remarked in §16.4, pre-whitening, when used for correlation testing, is of two types. The one
used in IR estimation is the “systems” approach as explained below. For the sake of illustration,
initially neglect the stochastic term of the observed response to an arbitrary input
y[k] = G(q−1)u[k]
(20.12)
Inserting (20.11), we have
y[k] = G(q−1)F−1
p (q−1)eu[k]
(20.13)
For a SISO system, the order of ﬁlters can be reversed on the RHS. With a minor rearrangement of
terms we obtain
yf [k] = G(q−1)uf [k]
where
yf [k] = Fp(q−1)y[k]
(20.14)
In other words, the LTI system that relates the original input and output also connects the ﬁltered
versions. The advantage in using (20.14) is that the input uf [k] has WN characteristics so that
ˆg[l] =
σy f u f [l]
σ2u f
=
σy f u f [l]
σ2eu
,
∀l
(20.15)
Bringing back the observation error in y[k], we have
yf [k] = G(q−1)uf [k] + vf [k]
(20.16)
where vf [k] = Fp(q−1)v[k] is the ﬁltered error.
Thus, the pre-whitening approach, while keeping the deterministic process intact, alters the noise
model. This should be expected since pre-ﬁltering signals is equivalent to changing the noise model

546
Principles of System Identiﬁcation: Theory and Practice
(recall related sections in Chapter 17). Although the point estimation of the IR coeﬃcients is greatly
simpliﬁed, pre-whitening results in ineﬃcient estimates since the ﬁltered errors vf [k] are in general
colored. The ineﬃciency property follows from the properties of OLS in §14.3.1.
Approximate signiﬁcance levels for the resulting IR estimates can be derived from the expressions
for the CCF estimates in §16.4 by re-writing (20.15)
ˆg[l] =
σy f u f [l]
q
σ2y f σ2u f
q
σ2y f σ2u f
σ2u f
=⇒ˆg[l]
σ2
u f
q
σ2y f σ2u f
= ρy f u f [l]
Since uf is white, we can use (16.37) in conjunction with the preceding result to develop 100(1 −
α)% signiﬁcance band for ˆg[l], under the hypothesis g[l] = 0, ∀l. The 99% band, for example, is
| ˆg[l]| ≤2.58
√
N
q
σ2y f σ2u f
σ2u f
under H0 : g[l] = 0
(20.17)
If even a single estimate of g[l] resides outsides this band, the hypothesis is rejected at 99% signiﬁ-
cance level. Moreover, the ﬁrst lag at which this occurs is deemed as the time-delay of the system.
The foregoing estimation procedure is known as correlation analysis (CRA) and is summarized
in Algorithm 20.1.
Algorithm 20.1
Estimation of IR using CRA
1. Collect input-output data u[k] and y[k], k = 0,1,· · · , N −1.
2. Subtract means ¯u and ¯y from the respective series (if necessary remove any trends).
3. Fit an AR(P) ﬁlter Fp(q−1) to the input. A typical choice is P = 10.
4. Apply the ﬁlter Fp(q−1) to u[k] and y[k] to obtain pre-whitened input uf [k] and ﬁltered measurement
yf [k].
5. Compute (20.15) at desired lags (l = 0,1,· · · , M −1) to procure IR estimates.
6. Evaluate (20.17) to obtain 99% signiﬁcance levels for the IR estimates.
7. Plot the resulting IR coeﬃcients to determine the adequacy of M, estimate time-delay and stability
characteristics of the process.
Note: The covariance matrix of the pre-whitened inputs is strictly diagonal only in a theoretical sense. Practi-
cally, the oﬀ-diagonal elements of ΦT Φ constructed using pre-whitened inputs are non-zero values. Therefore,
an additional error is introduced by using (20.15) as is with samples.
In order to demonstrate the CRA algorithm, we revisit Example 14.2.
Example 20.1: FIR Estimates Using Pre-Whitened Inputs
We shall revisit the FIR model estimation of Example 14.2, using the pre-whitening approach.
Applying the CRA algorithm, the estimates are obtained as
ˆg[0]
ˆg[1]
ˆg[2]
ˆg[3]
ˆg[4]
ˆg[5]
−0.0353
0.0173
0.2618
0.9947
0.4909
0.2060
ˆg[6]
ˆg[7]
ˆg[8]
ˆg[9]
ˆg[10]
−0.0071
0.0248
−0.0317
−0.0151
0.0873

Identiﬁcation of Non-Parametric Input-Output Models
547
(a) LS estimates after pre-whitening
(b) LS estimates on original data
FIGURE 20.1
Comparison of FIR model estimates with and without the pre-whitening step.
The 99% signiﬁcance level is computed to be 0.1932 using (20.17). Thus the 1σ standard
error in the estimate is 0.075 and the 99% conﬁdence interval for the true coeﬃcients is
ˆg[l] ± 0.1932.
To assess the error incurred by directly using (20.15), i.e., assuming ΦT Φ to be diagonal,
the full ΦT Φ (constructed after pre-whitening) is used in conjunction with (20.8). The results
are tabulated below.
ˆg[0]
ˆg[1]
ˆg[2]
ˆg[3]
ˆg[4]
ˆg[5]
−0.0564
(±0.0546)
0.0242
(±0.056)
0.251
(±0.057)
0.9978
±0.058
0.4810
(±0.058)
0.2139
(±0.059)
ˆg[6]
ˆg[7]
ˆg[8]
ˆg[9]
ˆg[10]
ˆσ2e
−0.0287
(±0.0585)
0.0329
(±0.058)
−0.0573
(±0.0564)
0.0066
(±0.0563)
0.0526
(±0.0547)
where the value in brackets is the 1σ standard error. Thus, the diﬀerences in the estimates
and their standard errors are somewhat signiﬁcant. Thus, assuming the sample covariance
matrix to be diagonal after pre-whitening can introduce additional errors.
Finally, a comparison of the LS estimates with and without pre-whitening reveals the
ineﬃciency that pre-whitening can cause. Graphical illustration of the LS estimates and
their errors with and without the pre-whitening step are given in Figures 20.1(a) and 20.1(b),
respectively. A comparison of these ﬁgures reveals that estimates obtained post pre-whitening
are relatively ineﬃcient.
Listing 20.1
MATLAB code for Example 20.1
% Load data
load firest_data
N = length(yk);
% Fit a filter to the detrended data
zkd = detrend(zk,0);
Fp = ar(zkd.u,10,’ls’);
% Apply the filter to input and output
ukf = filter(Fp.a,1,zkd.u); ykf = filter(Fp.a,1,zkd.y);
zkf = iddata(ykf,ukf,1);
% Compute covariance and IR estimates
M = 11;
cov_yfuf = xcorr([ykf ukf],M-1,’biased’);
ir_craest = cov_yfuf(M:end,2)/cov_yfuf(M,4);

548
Principles of System Identiﬁcation: Theory and Practice
% Compute significance level
ir_signif = (2.58/sqrt(N))*(sqrt(cov_yfuf(M,1)/cov_yfuf(M,4)));
% Compute without diagonal approximation
firmod_lspw = arx(zkf,[0 M 0]);
ir_lspw = firmod_lspw.b;
ir_lspwerr = firmod_lspw.db;
% Plot the IR estimates
figure; stem((0:(M-1)),ir_lspw ,’markerfacecolor’,’blue’); hold on
fill_vecx = [-0.2 (0:M-1) M-1+0.2]’; fill_vecy = 2.58*[ir_lspwerr(1) ...
ir_lspwerr ir_lspwerr(end)]’;
fill([fill_vecx ; flipud(fill_vecx)],[fill_vecy ; -flipud(fill_vecy)]’,[0.08 ...
0.17 0.55],’facealpha’,0.25,’linestyle’,’none’);
% Estimates from LS method
firmod_ls = arx(zkd,[0 11 0]);
ir_ls = firmod_ls.b;
ir_lserr = firmod_ls.db;
figure; stem((0:(M-1)),ir_ls,’markerfacecolor’,’blue’); hold on
fill_x = [-0.2 (0:M-1) M-1+0.2]’; fill_y = 2.58*[ir_lserr(1) ir_lserr ir_lserr...
(end)]’;
fill([fill_x ; flipud(fill_x)],[fill_y ; -flipud(fill_y)]’,[0.08 0.17 0.55],’...
facealpha’,0.25,’linestyle’,’none’);
Remarks:
Pre-whitening is suitable predominantly for SISO systems. Moreover, if u[k] is narrow band, then
the order of the pre-whitening may be exceedingly high. In such cases pre-whitening may be more detrimental
than being advantageous. Furthermore, ineﬃciency of the estimates post pre-whitening is a cause for concern.
In view of these facts, a LS algorithm is almost always favored over the CRA algorithm with pre-whitening.
20.2.3
REGULARIZATION AND INCLUDING PRIOR KNOWLEDGE
Non-parametric IR estimates do not necessarily exhibit the characteristics of the true IR coeﬃcients
due to measurement errors and insuﬃcient information from the user. For instance, most systems
have smooth responses, whereas the estimates exhibit an erratic behavior. In certain applications,
the decay nature of the IR coeﬃcients is possibly known a priori and can be included into the
estimation. Factors such as these motivated a fresh analysis of the non-parametric approach to the
IR estimation problem, but now with certain regularization conditions or constraints. Note that the
standard approach to obtaining smoothed IR estimates is to ﬁrst estimate the optimal parametric
model (using the prediction-error approach) followed by simulating the impulse response of the
obtained model. However, the objective here is to obtain smoothed estimates via the non-parametric
route.
In an interesting work, Pillonetto and Nicolao (2010) propose the use of kernel methods in the
non-parametric IR estimation problem to obtain regularized or smoothed estimates. Their approach
involves application of what is known as a Gaussian process regression (GPR) Rasmussen and
Williams (2006) to the IR estimation problem. In a recent work, Chen, Ohlsson and Ljung (2012)
summarize related ideas and also highlight the connections between various approaches to the prob-
lem. Keeping matters within the scope of this text, only the salient results are presented. A complete
technical account of these developments is found in the respective references.
The classical approach in the LS framework is to add a penalty term, typically a weighted norm
of the parameter vector (recall §14.3.6)
JN (θ,D) =
N−1
X
k=p
(y[k] −ϕT[k]θ)2 + θTDθ
(20.18)

Identiﬁcation of Non-Parametric Input-Output Models
549
where D is a positive semi-deﬁnite p × p matrix. The regularized estimate is given by
ˆθr
N = (ΦTΦ + D)−1(ΦTΦ)y = (ΦTΦ + D)−1(ΦTΦ)−1 ˆθLS
N
(20.19)
The basic question is then: how do we choose the matrix D? A standard consideration is to minimize
mean square error of the parameter vector. For the purpose of obtaining insights, it is convenient
to consider a simpliﬁed situation corresponding to an input with white-noise characteristics with
σ2
u = γu, white equation error v[k] ∼N (0,σ2
e) in (20.1) and a diagonal D. Then, the diagonal
element of the MSE( ˆθr
N) is approximately,
MSE( ˆgr
k) =
σ2
eλu N + d2
k+1(g0
k)2
(λu N + dk+1)2
,
k = 0,1,· · · , M −1
(20.20)
where g0
k ≜g0[k] is the true impulse response coeﬃcient and d j is the jth diagonal element of D.
The
The MSE is minimized by choosing
d2
j =
σ2
(g0
j−1)2 ,
j = 0,· · · , M
(20.21)
It is usually suﬃcient to know the form of D rather than the exact expression. For instance, if the
system is stable, then the impulse response coeﬃcients have a general form g[l] = bαk, |α| < 1.
Chen, Ohlsson and Ljung (2012) show that the regularized estimate is equivalent to a few other
approaches, namely (i) the parametric approach using the impulse response of the best ﬁt model
chosen by cross-validation, (ii) the Bayesian approach of incorporating prior knowledge (typically
as a Gaussian p.d.f.) and (iii) the Gaussian process regression (Pillonetto, Chiuso and Nicolao, 2011;
Pillonetto and Nicolao, 2010). The equivalence is not surprising in light of the fact that the Bayesian
(MAP) estimate with a Gaussian prior is equivalent to an MLE (PEM) with regularization (recall
the discussion in §15.2). Among these diﬀerent approaches, the Bayesian approach with a Gaussian
prior and the covariance matrix as a tuning parameter is considered best suited due to its natural
appeal and versatility.
Following the above discussion, we now assume the IR estimates g =
f
g[0],g[1],· · · ,g[M −1]
gT
have a Gaussian prior with mean zero (input and output are uncorrelated)
g ∼N (0,PM)
(20.22)
where PM is the covariance matrix. With a Gaussian prior and Gaussian observation error, the
posterior can be constructed in the same way as in Example 15.2.
The covariance matrix in (20.22) can be chosen in diﬀerent ways. A recommended approach is
to parametrize it so that only the form has to be speciﬁed while the parameters are optimized along
with the IR coeﬃcients. Some choices for PM (Chen, Ohlsson and Ljung, 2012; Pillonetto and
Nicolao, 2010) are:
i. Diagonal: P(DI)
mn
=

cλn,
m = n
0,
else
, where c,λ ≥0 are parameters to be optimized. The IR
coeﬃcients are assumed to be uncorrelated.
ii. Diagonal Correlated: A correlation structure for the IR estimates is assumed, with ρ|m−n| denot-
ing the correlation.
P(DC)
mn
= cρ|m−n|λ(m+n)/2
(20.23)
The implication is that the impulse response is smooth.

550
Principles of System Identiﬁcation: Theory and Practice
iii. Tuned Correlated: This is a variant of the DC kernel above obtained by tuning the correlation as
ρ =
√
λ,
P(TC)
mn
= c min(λm,λn)
(20.24)
Note that λ now has a restricted range λ ∈[0,1]. With the parametrization of the correlation, the
computation load is relatively lower than in using the DC kernel. Of course, the class of processes
that the TC kernel can handle is relatively smaller.
iv. Cubic Spline:
P(CS)
mn
=

c m2
2 (n −m
3 ),
m ≤n
c n2
2 (m −n
3 ),
(20.25)
A variant of the cubic spline, known as the stable spline, is obtained by replacing m and n with
λm and λn, 0 ≤λ ≤1, respectively in (20.25).
The Bayesian approach is similar to performing a regularization with the choice D = σ2
eP−1
M.
Remarks:
a. As is true of a typical Bayesian estimator, the approach above results in biased estimates, but with a lower
variance.
b. The performance of regularization algorithm depends on the choice of the regularization matrix D or the
prior covariance matrix (kernel) PM.
c. Chen, Ohlsson and Ljung (2012) observe that in general, for a high-order process, a model approximation
of desired order is better estimated by a regularized model followed by the application of a model-order
reduction technique with the desired order.
The distribution of the resulting estimates is given by the posterior p.d.f., i.e., the conditional
p.d.f. of the IR coeﬃcients. With a Gaussian prior and equation error, from §15.2 we know that the
posterior also has a Gaussian distribution
g|Z ∼N (µpost
g
,Ppost
M )
(20.26)
where Z is the input-output data as usual while the estimates of statistical properties are given by
(Chen, Ohlsson and Ljung, 2012)
ˆµpost
g
=

(σ2
eΦT
NΦN )−1 + P−1
M
−1 (σ2
eΦT
NΦN )−1 ˆθ(LS)
N
(20.27)
ˆPpost
M
=

(σ2
eΦT
NΦN )−1 + P−1
M
−1
(20.28)
where ΦN is the usual N × p regressor matrix that we have encountered before and ˆθ(LS)
N
is the OLS
estimate of the IR coeﬃcients.
Example 20.2: Regularized Estimation of IR Coefﬁcients
The process under consideration is
y[k] =
2q−2
1 −1.48q−1 + 0.54q−2 u[k] + e[k],
e[k] ∼GWN(0,σ2
e)
(20.29)
where u[k] is a PRBS of variance σ2u = 1 and σ2e is adjusted such that SNR is 10.

Identiﬁcation of Non-Parametric Input-Output Models
551
(a) Regularized and ordinary estimates
(b) Regularized estimates and true coeﬃcients
FIGURE 20.2
(SEE COLOR INSERT) Estimates of IR coeﬃcients with regularization for the process in
Example 20.2.
The regularized estimates obtained from the algorithm above are compared with those
from the ordinary LS method in Figure 20.2(a). The shaded areas correspond to the signiﬁ-
cance regions for the respective estimates. Clearly, the regularized estimates are signiﬁcantly
smoother than the ordinary counterparts. Moreover, the variability is lower as indicated by
the shaded areas, particularly conspicuous at larger lags.
It is instructive to compare the regularized estimates with the true coeﬃcients computed
from (20.29). Figure 20.2(b) depicts this comparison. The estimates are in close agreement
with the true values.
% Data generating process
dgp_mod = idpoly(1,[0 0 2],1,1,[1 -1.48 0.54]);
uk = idinput(2046,’prbs’,[0 0.4],[-1 1]); % Full-length PRBS
yktrue = sim(dgp_mod ,uk); % Noise-free simulation
% Adjust the noise variance
dgp_mod.Noisevariance = var(yktrue)/10;
% Simulate with noise
yk = sim(dgp_mod ,uk,simOptions(’Addnoise’,true));
% Detrend and prepare the data
dataset = iddata(yk,uk,1); Ztrain = detrend(dataset ,0);
% Estimate the IR coefficients with regularization
% Turn off regressive modeling (modeling of noise)
options = impulseestOptions; options.Advanced.AROrder = 0;
ir_regulmod = impulseest(Ztrain ,options);
% Without regularization
ir_lsmod = arx(Ztrain ,[0 51 0]);
% Compute IR coefficients
[ir_true ,kvec] = impulse(dgp_mod ,50);
[ir_regulest ,kvec,~,ir_sdreg] = impulse(ir_regulmod ,50);
[ir_lsest ,kvec,~,ir_sdls] = impulse(ir_lsmod ,50);
figure;
stem(kvec,ir_regulest ,’r’,’Markerfacecolor’,’red’); hold on
stem(kvec,ir_lsest ,’bd’);
% Plot significance regions for regularized estimates
ir_3sdreg = 2.58*ir_sdreg;
fillxvec = [kvec(1) kvec(1) kvec(2:end)’ kvec(end:-1:2)’]’;
fillyvec = [-ir_3sdreg(1) ir_3sdreg(1) ir_3sdreg(2:end)’ -ir_3sdreg(end:-1:2)...
’]’;

552
Principles of System Identiﬁcation: Theory and Practice
fill(fillxvec ,fillyvec ,[0.9 0.1 0],’FaceAlpha’,0.4,’Linestyle’,’none’);
% Plot significance regions for the LS estimates
ir_3sdls = 2.58*ir_sdls;
fillyvec2 = [-ir_3sdls(1) ir_3sdls(1) ir_3sdls(2:end)’ -ir_3sdls(end:-1:2)’]’;
fill(fillxvec ,fillyvec2 ,[0.5 0.58 1],’FaceAlpha’,0.2,’Linestyle’,’none’);
% Plot the true IR
figure
stem(kvec,ir_regulest ,’r’,’Markerfacecolor’,’red’); hold on
stem(kvec,ir_true ,’ks’);
fill(fillxvec ,fillyvec ,[0.9 0.1 0],’FaceAlpha’,0.4,’Linestyle’,’none’);
For a more detailed presentation of the regularization approach, the reader is referred to Chen,
Ohlsson and Ljung (2012).
20.2.4
ESTIMATION OF IR COEFFICIENTS FROM FREQUENCY RESPONSE DATA
When frequency response data in the form of magnitude |G(ejωn )| and phase ∠G(ejωn ) at n =
0,1,· · · , N frequencies, the impulse response model can be estimated by ﬁtting the theoretical FRF
of the FIR model to the given data.
Denoting the measured complex frequency response by G(e−jω) and the prediction by
ˆG(e−jω,θ), the optimal estimates of the IR coeﬃcients θ = gM are given by
ˆg⋆
M = min
θ
N−1
X
n=0
|G(e−jωn ) −ˆG(e−jωn,θ)|2
(20.30)
where the prediction of the FRF by the FIR model is given by the Fourier transform of the IR
coeﬃcients (Chapter 5)
ˆG(e−jωn,θ) =
M−1
X
k=0
g[k]e−jωn
(20.31)
Two minor modiﬁcations can be introduced into the objective function of (20.30). The ﬁrst one is
to restrict the summation to a desired frequency range (as demanded by the application) while the
second one is to have a weighting function in the norm (weighted LS).
It is easy to recognize (20.30) as a non-linear least squares problem. Therefore, numerical solvers
discussed in Chapter 14 can be employed.
20.2.5
INDIRECT ESTIMATION FROM PARAMETRIC MODELS
An alternative route to estimating response models is the method based on parametric approach.
Although being in contrast to the general line of (non-parametric) approach in this chapter, the
method merits discussion due to its relevance and versatility. The non-parametric way of estimating
FIR models does not take into account the noise structure. As a result, one obtains biased estimates.
Parametric models on the other hand are capable of modeling a variety of noise dynamics. The
idea is therefore to ﬁrst ﬁt a parametric model using the methods of Chapter 21 to the given time-
domain or frequency response data followed by an analytical computation of the impulse response.
ARX models, despite their restrictive structure, serve as good candidates for this purpose due to the
computational ease. However, other model structures are equally viable candidates and should be
considered whenever the ARX model fails to model the process.
It is worth re-iterating here that the parametric approach essentially amounts to a parametrization
of the IR sequence and therefore leads to a signiﬁcantly parsimonious representation. From an

Identiﬁcation of Non-Parametric Input-Output Models
553
estimation viewpoint, therefore, there is a high incentive in adopting this approach in addition to
overcoming the biased nature of non-parametric estimates.
Remarks:
There are at least two ways to estimate IR coeﬃcients in MATLAB (version 2013b).
The ﬁrst method is to use the routine impulseest, which estimates IR coeﬃcients with the regularization
option as a default. In addition, also by default, the option of obtaining parametric estimate of the IR coeﬃcients
by ﬁtting an ARX model to the data is available:
y[k] = B(q−1)
A(q−1) u[k] +
1
A(q−1) e[k]
(20.32)
where
M−1
X
n=0
g[n]q−n and A(q−1) = 1 + a1q−1 + · · · + ana q−na. The impulse response of B(q−1)/A(q−1) is
returned as the estimate by default. The parametric estimation is useful for handling colored noise and feedback
(if any). A default value of na = 5 is used. Also note that if the regularization option is turned oﬀ, the pre-
whitening option is switched on.
The second method is use to the arx routine with na = 0 as in Example 20.1. This approach allows the user
to obtain LS estimates of IR coeﬃcients with the option of turning on/oﬀregularization (by default turned oﬀ).
In addition, one can still generate parametric estimates by setting na to the desired value. No pre-whitening,
however, is performed in any situation.
See MATLAB documentation for additional information and options.
20.3
STEP RESPONSE ESTIMATION
In classical controller design problems, the traditional approach has been to generate step responses
of the continuous-time process by applying a step input to the process. Estimation of step response
of a sampled-data system can be also determined by applying a discrete-time step. However, as we
argued in the impulse response case, the resulting estimates are rather crude. Continuing this line
of argument further, the step response coeﬃcients are better estimated using the input-output data
acquired by applying richer inputs.
The estimation problem can be set up in a similar fashion as the IR estimation problem in §20.2.
On the other hand, using the invariance property of MLE methods, the step response estimates can
be constructed from the ML estimates of the IR coeﬃcients. This is the common practice.
To arrive at the distribution of step response coeﬃcients, note that the IR estimates follow a
normal distribution. It follows that the sum of these estimates also follow a Gaussian distribution.
The mean and variance of the resulting estimates can be easily computed from either the properties
of Gaussian random variables using (7.18) or the result from Theorem 14.4.
The procedure is summarized below.
Algorithm 20.2
Estimation of step response coeﬃcients
1. Estimate the IR model using the LS method with or without regularization.
2. Compute the step response from the resulting LTI model using the result
ˆystep[k] =
k
X
n=0
ˆg[n] = 1T
k ˆgk
(20.33)
where 1k and gk are k × 1 vector of ones and IR coeﬃcients, respectively.
3. Compute conﬁdence regions using (7.18) or (14.68).
We now turn to the non-parametric estimation of frequency response function, also known as the
transfer function estimation problem.

554
Principles of System Identiﬁcation: Theory and Practice
20.4
ESTIMATION OF FREQUENCY RESPONSE FUNCTION
The theoretical FRF given by (4.19) and (5.23) assume either that inﬁnite IR coeﬃcients or inﬁnite
input and output data are available. In order to handle practicalities, an empirical transfer function
was introduced in §5.3. This is the usual starting point for FRF estimation from a general input-
output data. However, before we deliberate further it is useful, as previously, to study certain other
elementary methods based on applying sinusoidal inputs to the process. These approaches, unlike
in the impulse and step response case, produce estimates of good quality as discussed below.
20.4.1
SINUSOIDAL INPUT-BASED ESTIMATION
The idea is intuitive and is based on the deﬁnition of FRF. Apply a cosine (or a sine) input wave of
amplitude Au and frequency ωi.
u[k] = Au cos ωik
Acquire the steady-state response,
y[k] = Au|G0(ejωi )| cos(ωik + φ) + v[k]
k = 0,1,· · · , N −1
(20.34)
At this point, there exist two approaches to estimation of FRF as discussed below:
1. Direct sinusoidal excitation: Record the amplitude of the output and its phase (usually by visual
inspection). Then, knowing the input amplitude and phase, compute the amplitude ratio and
phase shift as follows.
| ˆG(ejωi )| = Ay
Au
;
∠ˆG(ejωi ) = φ
(20.35)
The analysis is repeated for each frequency in the desired range. While this method is simple,
the quality of the resulting estimate is signiﬁcantly aﬀected by the presence of noise and the
procedure that is used to compute Ay and φu (e.g., by direct visual inspection or from spectral
analysis of the output). Moreover, the experiment is usually laborious, unless the FRF is desired
at a handful of frequencies. The following approach handles the issue of noise eﬀects in a more
sophisticated manner.
2. Correlation analysis: In this approach, the standard trick of correlation (as in IR estimation)
is used. The response is correlated with a cosine and sine wave of the same frequency with
the premise that the noise and the sinusoids are uncorrelated. From the knowledge of Fourier
transforms in Chapter 10, the correlation coeﬃcients must be related to the real and imaginary
parts of the corresponding DFT coeﬃcients. The following analysis illustrates the procedure and
the connections with DFT.
The sample correlations of the output with the cosine and sine are evaluated by constructing the
sums
Ic(ωi) = 1
N
N−1
X
k=0
y[k] cos ωik,
Is(ωi) = 1
N
N−1
X
k=0
y[k] sin ωik
(20.36)
Evaluating the ﬁrst sum by inserting (20.34), we have
Ic(ωi) = 1
N
N−1
X
k=0
Au|G0(ejωi )| cos(ωik + φ) cos ωik + 1
N
N−1
X
k=0
v[k] cos ωik
= Au
2 |G0(ejωi )| cos φ + Au|G0(ejωi )| 1
2N
N−1
X
k=0
cos(2ωik + φ) + 1
N
N−1
X
k=0
v[k] cos ωik
(20.37)

Identiﬁcation of Non-Parametric Input-Output Models
555
where G0(ejω) is the true FRF.
The third term on the r.h.s. of (20.37) vanishes for large N unless v[k] has a periodic component,
while the second term also disappears for large N by virtue of property of trigonometric func-
tions. Applying the same argument to the second sum (see Exercise E20.1), we have thus, for
large N,
Ic(ωi) = Au
2 |G0(ejωi )| cos φ,
Is(ωi) = −Au
2 |G0(ejωi )| sin φ
(20.38)
giving us the correlation estimate of FRF,
| ˆG(ejωi )| = 2
Au
q
Ic(ωi)2 + Is(ωi)2,
∠ˆG(ejωi ) = −arctan
 Is(ωi)
Ic(ωi)
!
(20.39)
To recognize the connections with the DFT-based procedure, recall the unitary DFTs of the output
and input from Chapters 5 and 10,
YN (ωi) =
1
√
N
N−1
X
k=0
y[k]e−jωik =
√
N(Ic(ωi) −jIs(ωi))
UN (ωi) =
1
√
N
N−1
X
k=0
u[k]e−jωik =
√
N Au
2
(for u[k] = Au sin ωik)
It can be easily veriﬁed that the correlation estimate in (20.39) can be written as (see Exercise
E20.2),
ˆG(ejωi ) = YN (ωi)
UN (ωi)
(20.40)
where ωi is the frequency of the input sinusoid. This is also the empirical transfer function
estimator deﬁned in (5.25) evaluated at the input frequencies. As we shall show shortly, ETFE is
capable of handling a broader class of inputs.
Properties of correlation estimate
The correlation estimate obtained with sinusoidal inputs has the following properties (see Ljung
(1999))
a. The estimate is unbiased, i.e,, E( ˆG(ejωi )) = G0(ejωi ).
b. It is a consistent estimator of the FRF. This is based on the fact that the variance of the
stochastic term in Ic(ωi) and Is(ωi) decays like 1/N so as long as v[k] is stationary and
has an ACF that absolutely decays fast enough, speciﬁcally:
∞
X
l=−∞
l|σvv[l]| < ∞
(20.41)
The properties and the connection of the correlation estimator with ETFE hold good for general
periodic inputs so long as the sample size N is an integer multiple of the period.
Despite the nice properties of the correlation estimator, its applicability is limited since most in-
dustrial processes do not admit sinusoidal inputs. Moreover performing this experiment for each
frequency is quite tedious.
In order to overcome the practical limitations of the foregoing estimator, a more general input
that contains a mix of sines can be applied. Broadening this idea further, one can even admit ape-
riodic inputs that have a continuous spectrum. Such signals are typically the outputs of a stationary

556
Principles of System Identiﬁcation: Theory and Practice
stochastic process (ﬁlter). As shown in the next section, with the use of a aperiodic broadband in-
puts, while there are signiﬁcant gains on the experimental aspects, the consistency property is lost.
Algorithm 20.3
Algorithm for correlation estimate with periodic inputs
1. Design a sinusoidal sequence of frequency ω.
2. Collect the steady-state response of the system to the sinusoidal input.
3. Form correlations between the response and (cos ωk,sin ωk) using (20.36).
4. Compute the magnitude and phase of FRF using (20.39).
20.4.2
ETFE
Consider the general case of a quasi-stationary input u[k] with a spectral density γu. Denote the
response as usual by y[k], k = 0,1,· · · , N −1.
Then the estimate of FRF through the ETFE is,
ˆˆGN (ejω) = YN (ω)
UN (ω)
(20.42)
where the numerator and denominator are as before, the unitary DFTs of output and input, respec-
tively. Customarily the ETFE is evaluated on a uniform grid of frequencies {ωn = 2πn/N, n =
0,1,· · · , N −1}.
Note: It is not mandatory to use the unitary transform in (20.42) since the factors cancel out in any case.
The ETFE in (20.42) carries a double hat to indicate that even in the absence of noise, it remains
only an estimate of the true FRF G0(ejω). This is in contrast to the version in (20.40), rightly so
because the ETFE is an accurate estimator of the FRF under noise-free conditions when the input is
periodic. Recall §5.3 which discussed the properties of the ETF in the deterministic case.
Algorithm 20.4
Algorithm for computing the ETFE
1. Collect input-output data by exciting the process with a pre-designed input.
2. Mean center the data and remove any possible trends.
3. Compute DFT of the output and input applying (10.58a).
4. Estimate the FRF using (20.42).
In §5.3 we studied the properties of ETFE as an estimator of the FRF under noise-free conditions.
The question of interest now is, how good is ETFE as an estimator under noisy conditions? This
topic is extensively discussed in Ljung (1999). A summary of those ﬁndings is presented below.
Intuitively, we can expect the ETFE not to be necessarily a consistent estimator by drawing anal-
ogy with the periodogram estimator, i.e., ETFE serves as an estimator of FRF in the same way as
the periodogram serves to estimate the spectral density of a signal. Continuing on this analogy, for
periodic signals, ETFE can be expected to be consistent, which is the case indeed.

Identiﬁcation of Non-Parametric Input-Output Models
557
Properties of ETFE
Assume the data generating process to be,
y[k] = G0(q−1)u[k] + v[k]
(20.43)
=⇒YN (ω) = G0(ejω)UN (ω) + RN (ω) + VN (ω)
(20.44)
where v[k] is a zero-mean stationary stochastic process, possibly correlated and satisﬁes the absolute
decay requirement stated in (20.41). The quantity RN (ω), previously appearing in (5.27), is the error
incurred in approximating the exact FRF with a ﬁnite-sample version and decays like 1/
√
N (with
a unitary transform for DFT).
Then, the ETFE has the following properties:
1. Asymptotically unbiased: It is statistically biased, but an asymptotically unbiased estimator of
the FRF. Dividing both sides of (20.44) by UN (ω) and taking expectations yields,
E( ˆˆGN (ejω)) = G0(ejω) + RN (ω)
UN (ω)
(20.45)
since E(VN (ω) = 0 whenever E(v[k]) = 0.
By virtue of the result in (5.27), RN (ω) decays as 1/
√
N (or 1/N for a non-unitary transform),
while UN (ω) tends to U(ω). Therefore, the bias vanishes as N →∞.
2. Unbiased for periodic inputs: The bias of ETFE vanishes for ﬁnite samples provided inputs of
period Np are used and that the sample size is N = mNp, m ∈Z+. This is once again due to
the property of ETFE discussed in §5.3. When periodic inputs are used and integer cycles are
completed in the data length, the remainder term RN (ω) is zero.
3. Not consistent: The variance of ETFE does not fall oﬀas N increases, but rather is the inverse of
SNR at that frequency. The covariance of ETFE at two frequencies ω and ξ is given by (Ljung,
1999),
E

[ ˆˆGN (ejω) −G0(ejω)][ ˆˆGN (e−jξ) −G0(e−jξ)]

=

1
|UN (ω)|2 [γv(ω) + ρ2(N)],
ξ = ω
ρ2(N)
UN (ω)UN (−ξ) ,
|ξ −ω| = 2πn
N , n = 1,2,· · · , N −1
(20.46)
where γvv(ω) is the spectral density of v[k].
|ρ2(N)| ≤C2
√
N
(20.47)
The exact expression for C2 is given in Ljung (1999). It suﬃces to know that it is ﬁnite so long
as (20.41) is satisﬁed.
It follows that when N →∞,
var( ˆˆGN (ejω)) =
γvv(ω)
|UN (ω)|2
(20.48)
with a reminder that UN (ω) is the unitary transform.
Observe that the denominator in (20.48) is the periodogram (barring a constant) of the input.
From §16.5.4, we know that the periodogram is an erratic function of ω, ﬂuctuating around
γuu(ω).

558
Principles of System Identiﬁcation: Theory and Practice
When the input is periodic, we know from §16.5.2.1 that the periodogram1 ∝N. Consequently,
the variance of ETFE goes to zero, making it a consistent estimator. However, observe that the
ETFE is then deﬁned only at the frequencies contained in the output.
4. Asymptotically uncorrelated: By virtue of the result in (20.48) and the boundedness of ρ2(N),
it follows that the estimates at two diﬀerent frequencies are uncorrelated. This means that the
ETFE ﬂuctuates erratically around G0(ejω) in a similar manner as the periodogram around the
spectral density.
The lack of consistency of ETFE can be reasoned in the same way as was done in §16.5.6 for the
periodogram. For the purpose of reﬁning the ETFE, it is worth highlighting two viewpoints:
i. When the input is a ﬁltered stochastic signal (or has such properties), it is merely one of the
inﬁnite realizations. Expectantly therefore the ETFE is bound to face the same consequence as
the periodogram since the true ﬁnite-length transform of the input is an ensemble average of
UN (ω). A remedy is, as in smoothed periodogram methods, to compute the ETFE over segments
and average them. This route leads to a Welch-averaged periodogram-like estimator.
ii. The second viewpoint is that ETFE, like the periodogram, produces erratic estimates whereas
the true FRF is a smooth function of ω. Thus, averaging or smoothing the raw estimate over
an interval of frequencies (as in the Daniell’s smoothed periodogram approach) can bring about
consistency.
Both lead to the same suggestion - use smoothed estimates of the ETFE. Before we explore the
remedy, it is useful to examine a standard approach familiar to the signal processing community to
estimate the FRF, which is through the use of spectral densities. Through the development, we shall
not only observe the connections with ETFE and be able to devise the necessary remediation, but
will also obtain a convenient way of implementing the ETFE.
20.4.3
ESTIMATION FROM SPECTRAL DENSITIES: SPECTRAL ANALYSIS (SPA)
A classical approach to estimating FRF is via spectral analysis. In identiﬁcation, we appeal to the
relation (17.14b) given by Theorem 17.1 for quasi-stationary signals. To recall the result, for any
LTI system G, when the input and output are quasi-stationary and the input is uncorrelated with
v[k],
γyu(ω) = G(ejω)γuu(ω)
=⇒G(ejω) = γyu(ω)
γuu(ω)
(20.49)
(20.50)
where the spectral densities in (20.49) now follow the deﬁnitions introduced for quasi-stationary
signals in §17.3.
The relation in (20.49) leads to a natural estimator for the FRF from ﬁnite-length observations of
input and output (Brillinger, 2001, Chapter 6),
ˆˆG(ejω) = ˆγyu(ω)
ˆγuu(ω)
(20.51)
where raw estimators of the spectral densities are used.
1The periodogram here is the one based on unitary DFT given in (16.51). However, its proportionality with N for periodic
signals is true even for the regular deﬁnition in (16.49).

Identiﬁcation of Non-Parametric Input-Output Models
559
When the spectral density estimates in (20.51) are computed in the standard way,
ˆγyu(ω) = 1
2π
N−1
X
l=−(N−1)
ˆσyu[l]e−jωl,
ˆγuu(ω) = 1
2π
N−1
X
l=−(N−1)
ˆσuu[l]e−jωl
(20.52)
the resulting estimator is identical to the ETFE in (20.42) (see Exercise E20.4). For the computation
of p.s.d.’s through (20.52), the covariance function estimates are obtained from the biased estimator
in (16.32).
Algorithm 20.5
Algorithm for estimating FRF using spectral densities
1. Collect input-output data by exciting the process with a pre-designed input.
2. Compute estimates of cross-spectral (between y and u) and auto-spectral densities (of the input)
using (20.52).
3. Estimate the FRF using (20.50).
Example 20.3: Estimating the FRF Using ETFE
Measurements from an ARMAX process
y[k] =
2q−2
1 −1.2q−1 + 0.35q−2 u[k] +
1
1 −0.5q−1 σ2
e,
e[k] ∼GWN(0,0.69)
are generated using a PRBS input with cut-oﬀfrequency 0.2 cycles/sample. The innovations
variance has been set to the given value so that the output SNR is set to 10. The objective
is to estimate the FRF from N = 2046 observations of this process,
10
−2
10
−1
10
0
10
1
0
10
20
30
40
50
60
70
80
Frequency
Magnitude
 
 
Estimated
True
(a) Magnitude estimates
10
−2
10
−1
10
0
10
1
−400
−300
−200
−100
0
100
200
Frequency
Phase
 
 
Estimated
True
(b) Phase estimates
FIGURE 20.3
Estimate of FRF using the ETFE.
After the usual steps of mean-centering the input and output, the FRF is estimated using
the ETFE. The resulting magnitude and phase estimates are shown in Figures 20.3(a) and
20.3(b), respectively. While the general trends in both quantities are well captured by the
ETFE, the erratic variations across frequencies make it unattractive as an estimator. The
reason for this erratic behavior has been discussed in §20.4.2. Furthermore, the phase esti-
mates are quite poor in the high frequency region, mostly due to the fact that the excitation
in that frequency is negligible.

560
Principles of System Identiﬁcation: Theory and Practice
Listing 20.2
Estimating FRF via ETFE in Example 20.3
% Generating an IDPOLY object of type ARMAX
proc_armax = idpoly([1 -1.2 0.35],[0 0 2],[1 0.3],’Noisevariance’,1);
% Simulate the process with a PRBS input
uk = idinput(2046,’prbs’,[0 0.4],[-1 1]); % Full-length PRBS
yktrue = sim(proc_armax ,uk); % Noise-free simulation
% Adjusting the noise variance s.t. SNR = 10
mult_fact = (1 + 0.3^2)*(1 + 0.35)/((1 + 0.35)*(1 - 0.35^2) - 1.2^2 + ...
0.35*1.2^2);
proc_armax.Noisevar = 0.1*var(yktrue)/mult_fact;
% Simulate with noise
yk = sim(proc_armax ,uk,simOptions(’Addnoise’,true));
% Processing the data
dataset = iddata(yk,uk,1);
datatrain = detrend(dataset ,0);
% Estimating the FRF with ETFE
Gwhat = etfe(datatrain);
wvec = Gwhat.Frequency;
[mag_act ,phase_act] = bode(proc_armax ,wvec);
% Plot the estimated vs. true magnitude and phase response
figure
semilogx(wvec,squeeze(abs(Gwhat.Response)),’b-’,wvec,squeeze(mag_act),’r--’);
figure
semilogx(wvec,phase(squeeze(Gwhat.Response))*180/pi,’b-’,wvec,squeeze(...
phase_act),’r--’);
It is emphasized that the erratic variation in the ETFE across frequencies is not the same
as the variance of ETFE. The latter is the variability in ETFE across diﬀerent realizations of
the output data at any given frequency, whereas the former is the ﬂuctuation in the estimate
across frequencies.
20.4.4
SMOOTHED ESTIMATES
The previous section clearly highlights the need for smoothing the ETFE requires in order to produce
consistent estimates of the FRF (whenever aperiodic inputs are used). This fact is also reinforced by
the viewpoint oﬀered by the spectral analysis method in (20.50) - consistent estimates are obtained
using smoothed instead of the raw estimators of spectral density. As a matter of fact, regardless of
the viewpoint, one obtains the same remedy (Ljung, 1999). In other words, estimating FRF with
smoothed spectral densities and smoothing the raw ETFE both give rise to the same estimates. A
technical proof of the equivalence is given in Ljung (1999). The result should be more or less a
foregone conclusion by analogy with the consistent estimation of spectral densities using smoothed
and averaged periodogram estimators. By a straightforward comparison with the methods of §16.5.6
for p.s.d. estimation, we can intuitively propose three strategies to build a consistent estimator of
FRF:
1. Daniell’s smoother: This idea leads to smoothing the ETFE (computing the weighted average).
2. Blackman-Tukey method: This approach suggests use of using B-T (or smoothed) estimates of
cross-spectral densities in (20.51).
3. Welch’s averaged method: This line of thought leads to segmenting the input-output data fol-
lowed by an averaging of ETFE. Alternatively, one could use Welch’s estimates of spectral den-
sities in (20.51).

Identiﬁcation of Non-Parametric Input-Output Models
561
The above approaches indeed constitute the set of methods that are used in practice. Among these,
the B-T estimate based approach is recommended for computational ease (Ljung, 1999). We shall
study all three approaches nevertheless for pedagogical reasons.
20.4.4.1
Smoothing the ETFE
As remarked earlier, the arguments and strategy are along the same lines as was for Daniell’s
smoother. The diﬀerence here is that the weighted average is constructed from a weighted least
squares approach. Suppose the true FRF G0(ejωn ), ωn = 2πn/N is constant in a small neighbor-
hood of ωn and over the interval [2πn1/N,2πn2/N] (a reasonable assumption to begin with). The
trick is then to view the ETFE as a measurement of G0(ejωn ) with an error εG(ωn) whose variance
is given by (20.48). That is,
ˆˆG(ejωn ) = G0(ejωn ) + εG(ωn)
(20.53)
with σ2
εG,ωn ≜var(εG(ωn)) ≈
γvv(ωn)
|UN (ωn)|2
(20.54)
Then, using the WLS principle in §14.3.5, the optimal estimate of G0(ejωn ) is given by the weighted
average
ˆGN (ejωn ) =
n2
X
n=n1
αn ˆˆG(ejωn )
n2
X
n=n1
αn
,
αn =
1
σ2
EG,ωn
= |UN (ωn)|2
γvv(ωn)
(20.55)
where the optimal weights are chosen in accordance with (14.94). Notice that these weights require
the knowledge of the disturbance spectrum, which for simplicity, may be assumed also to be constant
within that interval. Then the result is that they cancel out in the numerator and denominator
Extending the above idea to large N and letting G0(ejωn ) have a smooth variation, a weighted
ETFE results (Ljung, 1999)
ˆGN (ejωn ) =
Z π
−π
W(ξ −ωn)|UN (ξ)|2 ˆˆG(ejξ) dξ
Z π
−π
W(ξ −ωn)|UN (ξ)|2 dξ
(20.56)
where W(ξ) is one of the window functions (in the frequency domain) discussed in §16.5.3. The
assumption of constant disturbance spectrum over the width of the window function still holds. This
basic idea can be extended to accommodate non-constant disturbance spectrum over the smoothing
band by choosing a weighting as in (20.55), if the disturbance spectrum is known beforehand. A
recommended procedure is to estimate the disturbance spectrum as outlined in §20.5.
20.4.4.2
From Smoothed PSD Estimates
The smoothed SPA approach, as remarked earlier, consists of using the smoothed spectral estimates
for the theoretical densities in (20.50)
ˆG(ejω) =
ˆγS
yu(ω)
ˆγSuu(ω)
(20.57)

562
Principles of System Identiﬁcation: Theory and Practice
where the superscript S on the estimates of densities in the numerator and denominator indicates that
they are smoothed versions. These estimates can be obtained using the methods described in §16.5.6,
for example, the Daniell’s smoothed periodogram or the Blackman-Tukey method of computing the
Fourier transform of windowed ACVF.
Both these methods were discussed at length in §16.5.6 and §16.6. The reader may refer to these
sections for the respective estimators and also recall that technically smoothed estimates of spectral
densities are identical to the B-T estimates.
Algorithm 20.6
Algorithm for estimating FRF using smoothed SPA
1. Collect input-output data by exciting the process with a pre-designed input.
2. Compute smoothed estimates of cross-spectral (between y and u) and auto-spectral densities (of the
input) using the Blackman-Tukey estimator.
3. Estimate the FRF using (20.57).
Remarks:
i. Covariance estimator: Ljung (1999) recommends the use of B-T estimator for computational elegance.
Moreover, the covariance estimate is constructed in a slightly diﬀerent manner from the regular biased
estimator in (16.32), as follows:
ˆσyu[l] = 1
N
N−1
X
k=0
y[k]u[k −l]
(20.58)
with a periodic extension of u[k] outside the interval 0 ≤k ≤N −1, i.e., u[k] = u[k −(N −1)], k > N −1
and u[k] = u[N −1 + k],k > 0. Evidently, the diﬀerence between (20.58) and (16.32) is in the limits of
summation.
ii. Equivalence with smoothed ETFE: The numerator and denominator of the smoothed estimate in (20.56) can
be interpreted in an asymptotic sense as the smoothed estimates of the cross-spectrum and input spectrum
respectively (see Exercise E20.5). Consequently, the equivalence between the smoothed ETFE and the
spectral analysis estimate of the FRF is established.
iii. Window type and width: The inﬂuence of the user parameters, namely, lag window type and width L =
2M + 1 on the (variance of) spectral estimates were discussed in §16.5.6. A similar set of recommendations
and guidelines apply to the FRF estimation as well. For instance, the larger the width of the frequency
window in (20.56), the lower is the variance of ˆG(ejωn ) since more frequencies are averaged. However,
the bias increases since the true FRF can diﬀer signiﬁcantly over a broad frequency band.
Ljung (1999) derives an expression for the optimal width of the lag window. However this expression re-
quires the knowledge of quantities that are unknown a priori. The trial-and-error approach is more realistic,
but time consuming. A recommended value for the window width is L = N/20.
iv. Consistency of the smoothed estimate: The smoothed estimate is asymptotically biased and consistent as
expected. The asymptotic expression for the variance is given by (the conditions of asymptotic result of B-T
estimates holding)
var( ˆGN (ejω)) ≊
1
N ˜Bw
γvv(ω)
γuu(ω)
(20.59)
where ˜Bw is the bandwidth of the lag window introduced in (16.97). In terms of the spectral window W(ω),
it is
˜Bw =
 
2π
Z π
−π
W2(ω) dω
!−1
(20.60)
Thus the estimator is consistent.

Identiﬁcation of Non-Parametric Input-Output Models
563
20.4.4.3
Welch’s Averaged Approach
Recalling the Welch’s averaged periodogram method in §16.5.6 and applying it to the present sce-
nario, the ﬁrst step is to divide the output and input series into K segments (usually with a 50%
overlap) followed by the application of (20.50) to obtain the ETFE for each segment. Subsequently,
one could form a simple or weighted average of these estimates as follows
ˆGN (ejωn ) = 1
M
K
X
i=1
ˆˆG(i)
L (ejωn )
(20.61)
where L is the length of each segment and ˆˆG(i)
L (ejωn ) is the ETFE from the ith segment. A more
eﬃcient estimate is obtained by constructing a weighted average:
ˆGN (ejωn ) = 1
M
M
X
i=1
ˆˆG(i)
L (ejωn )|UL(ωn)|2
M
X
i=1
|UL(ωn)|2
(20.62)
because the variance of the ETFE of each segment at each frequency is ∝1/|UL(ωn)|2 (assuming
the same disturbance spectrum at each frequency across segments).
Remarks:
Another possible way of implementing Welch’s idea is to use the WOSA estimates of cross- and
auto-spectral densities in (20.51). This approach leads us to the smoothed estimate discussed earlier.
20.5
ESTIMATING THE DISTURBANCE SPECTRUM
The disturbance spectrum γvv(ω) (under open-loop conditions) can be obtained by evaluating the
covariances on both sides of (17.17) and applying the Wiener-Khinchin theorem
γyy(ω) = G(ejω)γuu(ω) + γvv(ω)
(20.63)
From this theoretical expression, a natural estimator of the disturbance spectrum follows (Brillinger,
2001):
ˆγvv(ω) = ˆγyy(ω) −ˆGN (ejω) ˆγuu(ω)
= ˆγyy(ω) −| ˆγyu(ω)|2
ˆγuu(ω)
(20.64a)
(20.64b)
Remarks:
i. Asymptotic properties of the estimator in (20.64) are derived in Brillinger (2001, Chapter 6). The main
property of interest is that it is consistent.
ii. Non-parametric estimates of disturbance spectrum are useful in determining a priori whether an OE model
would suﬃce or otherwise. An example illustrating this point is shown below.
We conclude this chapter with an illustrated example on estimating the FRF using smoothed
estimators.
Example 20.4: Smoothed Estimates of FRF
Consider the ARMAX process and the input of Example 20.3, where we had obtained a “raw”
estimate of FRF using the ETFE. Here we turn to the smoothed estimator of (20.57) using
the B-T estimator with Hann lag window of three diﬀerent widths L = 200,100,50. In the

564
Principles of System Identiﬁcation: Theory and Practice
10
−2
10
−1
10
0
10
1
0
5
10
15
Frequency
Magnitude
 
 
True
Estimated L = 200
Estimated L = 100
Estimated L = 50
(a) Magnitude estimates
10
−2
10
−1
10
0
10
1
−400
−350
−300
−250
−200
−150
−100
−50
0
Frequency
Phase
 
 
True
Estimated L = 200
Estimated L = 100
Estimated L = 50
(b) Phase estimates
FIGURE 20.4
Estimate of FRF using smoothed spectral densities obtained with Hann window of widths L =
200,100,50. True responses shown as solid line.
10
−2
10
−1
10
0
10
1
−30
−20
−10
0
10
20
30
40
Frequency
Spectral Density
 
 
True
Estimated L = 200
Estimated L = 100
Estimated L = 50
FIGURE 20.5
Non-parametric estimates of disturbance spectrum using smoothed spectral densities obtained
with Hann window of widths L = 200,100,50. True spectrum shown as solid line.
frequency domain, these windows corresponds to frequency smoothing windows of increasing
widths. Thus, one should expect a decrease in variance and an increase in bias up this order.
Figures 20.4(a) and 20.4(b) show the magnitude and phase responses, conﬁrming our ex-
pectations. The widest lag window (L = 200), i.e., the narrowest frequency window, retains
the erratic behavior of the ETFE since the smoothing is insuﬃcient while the narrowest lag
window (L = 50), i.e., the widest frequency window results in low variance (smoothed) esti-
mates with larger bias. For this example, the width L = 100 appears to be an appropriate
choice.
The disturbance spectrum is estimated using (20.64) with the same set of windows used in
estimation of FRF. These estimates, shown in Figure 20.5, exhibit the same behavior as that
of the FRF as the lag window width is varied.

Identiﬁcation of Non-Parametric Input-Output Models
565
20.6
SUMMARY
In this chapter we learnt how to estimate time-domain non-parametric models. Impulse response
(FIR) models are estimated using correlation analysis and least squares methods. Pre-whitening of
signals prior to the application of these methods is a classical method, but is marred with certain
disadvantages. Two of these being that they produce ineﬃcient estimates and their scope of appli-
cability is restricted to SISO systems. Least squares techniques are advantageous mainly because
one can incorporate regularization into the estimation problem and also can be applied to multivari-
able systems. Regularization produces smoothed estimates, which is particularly useful for systems
described by a large number of IR coeﬃcients (e.g., systems with integrating eﬀects or large time-
constants). Further, the approach has conceptually strong connections with a Bayesian estimator
using a Gaussian prior.
Frequency response functions can be estimated in diﬀerent ways depending on how the data
has been generated. If periodic signals have been used, the ETFE is an asymptotically biased and
consistent estimator of the FRF. For the arbitrary inputs case, the ETFE is a poor estimator - the
error cannot be brought down with any number of observations - in an exactly similar way as the
periodogram as an estimator of the spectral density of stochastic signals. Smoothed ETFE, like
the smoothed periodogram, oﬀers consistent estimates of the FRF. Theoretically this estimator is
identical to using the spectral analysis (SPA) estimator, which uses the ratio of smoothed cross- and
auto-spectral densities. Computationally this is the approach followed to estimate FRF. Finally, we
also learnt how to estimate the disturbance spectrum in a non-parametric manner. These estimates
are useful in gaining insights into the type of noise model that may be required.
In general, the non-parametric estimates are useful in determining the delays and obtaining valu-
able insights into the orders and process dynamics - all of which are crucial to building parametric
models, as discussed in the next chapter.
REVIEW QUESTIONS
R20.1 What are the two diﬀerent ways in which FIR models can be estimated?
R20.2 Explain why the theoretical expressions for both estimators of FIR models are identical.
R20.3 Describe the idea of pre-whitening and its role on IR estimation.
R20.4 Identify two possible disadvantages of using the pre-whitening method.
R20.5 Why is regularization of impulse response needed and when is it really eﬀective?
R20.6 Deﬁne ETFE and describe its properties.
R20.7 Under what conditions is ETFE a good estimator of the FRF of a system?
R20.8 What is the diﬀerence between the spectral analysis and the ETFE approaches to estimating the FRF of
a system?
R20.9 Explain the similarities between the problems and solutions to the estimation of spectral densities of
stochastic signals and the FRFs in identiﬁcation.
R20.10 Describe a method to estimate FIR models from frequency response data.
EXERCISES
E20.1 Show that the second term of (20.37) vanishes for large N.
E20.2 Prove that the correlation estimator of FRF in (20.39) can be written as the ETFE-like estimator in
(20.40).

566
Principles of System Identiﬁcation: Theory and Practice
E20.3 Consider a data-generating process
y[k] = a1y[k −1] + b1u[k −3] + b2u[k −4] + e[k]
where e[k] is the Gaussian white noise with mean zero. Generate data with a1 = −0.5,b1 = 2,b2 = 1.2 and
adjust σ2e such that SNR is 10.
a. Estimate an FIR model of suitable length using the LS method (without regularization).
b. Test the coeﬃcients for their signiﬁcance and estimate the delay. Does it agree with the generating
process?
c. Do you expect biased estimates for this process? Verify your answer with Monte-Carlo simulations.
E20.4 Prove that when raw estimates of cross- and auto-spectral densities as given in (20.52) are used in the
PSD-based estimator of FRF, as given by (20.51), the resulting estimator is none other than ETFE.
E20.5 Show that the numerator and denominator of (20.56) asymptotically converge to the smoothed estimates
of the respective spectral densities.
E20.6 A process output evolves as: y[k] = b1u[k −1]+b2u[k −2]+e[k] where e[k] is a zero-mean white-noise
sequence. Further, u[k] has white-noise like properties and that open-loop conditions prevail.
a. Assume that b1 is known, and the problem is only of estimating b2. Derive a theoretical expression
for the LS-optimal estimate of b2 in such a case.
b. What do you theoretically expect of the estimate of b2 above (both its value and variance) in compar-
ison to the estimate of b2 obtained in case you had estimated both coeﬃcients? Justify your answers
appropriately.
E20.7 Simulate the liquid level system of Chapter 2 with the settings used in the illustration. From the generated
input-output data, do the following:
a. Estimate an FIR model of suitable length with and without regularization. Do you observe any diﬀer-
ences in the estimates? Explain.
b. Compare the estimated impulse response coeﬃcients with that of the true system (by injecting a unit
impulse in the input and turning oﬀthe noise).
c. Obtain an estimate of the FRF using the ETFE and smoothed estimator (SPA). Do the estimates
conform to the theory described in Sections 20.4.2 and 20.4.4?
d. From the obtained FRF estimate, comment on the ﬁltering nature of the liquid level system. Do your
observations agree with the physical nature of the system?
E20.8 Repeat E20.7 with a white-noise input of the same variance as the PRBS input that was used in the
simulation. Do you observe any distinct diﬀerences in your answers? Clearly state and explain your obser-
vations.

Identiﬁcation of Non-Parametric Input-Output Models
567
Listing 20.3
MATLAB code for Example 20.4
% Generating an IDPOLY object of type ARMAX
proc_armax = idpoly([1 -1.2 0.35],[0 0 2],[1 0.3],’Noisevariance’,1);
% Simulate the process with a PRBS input
uk = idinput(2046,’prbs’,[0 0.4],[-1 1]); % Full-length PRBS
yktrue = sim(proc_armax ,uk); % Noise-free simulation
% Adjusting the noise variance s.t. SNR = 10
mult_fact = (1 + 0.3^2)*(1 + 0.35)/((1 + 0.35)*(1 - 0.35^2) - 1.2^2 + ...
0.35*1.2^2);
proc_armax.Noisevar = 0.1*var(yktrue)/mult_fact;
% Simulate with noise
yk = sim(proc_armax ,uk,simOptions(’Addnoise’,true));
% Processing the data
dataset = iddata(yk,uk,1);
datatrain = detrend(dataset ,0);
% Estimating the FRF with ETFE
L1 = 200; Gwhat1 = spa(datatrain ,L1);
L2 = 100; Gwhat2 = spa(datatrain ,L2);
L3 = 50; Gwhat3 = spa(datatrain ,L3);
wvec = Gwhat1.Frequency;
[mag_act ,phase_act] = bode(proc_armax ,wvec);
% Plot the magnitude response
figure
semilogx(wvec,squeeze(mag_act),’b-’,wvec,abs(squeeze(Gwhat1.Response)),’r--’);
hold on
semilogx(wvec,abs(squeeze(Gwhat2.Response)),’k-.’,wvec,abs(squeeze(Gwhat3....
Response)),’g:’);
% Plot the phase response
figure
semilogx(wvec,squeeze(phase_act),’b-’,wvec,phase(squeeze(Gwhat1.Response))...
*180/pi,’r--’);
hold on
semilogx(wvec,phase(squeeze(Gwhat2.Response))*180/pi,’k-.’,wvec,phase(squeeze(...
Gwhat3.Response))*180/pi,’g:’);
% Plot the disturbance spectrum
figure
distpsd_true = 20*log10(spectrum(proc_armax(’noi’),wvec));
semilogx(wvec,squeeze(distpsd_true),’b-’,wvec,squeeze(20*log10(spectrum(Gwhat1...
(’noi’)))),’r--’);
hold on
semilogx(wvec ,20*log10(squeeze(spectrum(Gwhat2(’noi’)))),’k-.’,wvec ,20*log10(...
squeeze((spectrum(Gwhat3(’noi’))))),’g:’);

21
Identiﬁcation of Parametric
Input-Output Models
This chapter presents methods for identiﬁcation of parametric models. Two broad classes
of approaches, namely, the prediction-error minimization and correlation methods are dis-
cussed. The focus is largely on the prediction-error methods (PEM) due to their attractive
convergence properties. Certain specialized methods for speciﬁc parametric models are also
discussed. Among the correlation methods, particular attention is given to the instrumental
variable (IV) method.
21.1
RECAP
In the preceding chapter we learnt how to develop non-parametric models, i.e., models that do not
assume any speciﬁc mathematical “structure” (equation of curves) for the response of the system.
Here we study methods for estimating parametric models, which as we learnt in Chapter 4, are
a result of parametrizing the responses of the plant and noise models. The basic idea here is to
estimate the parameters instead of response coeﬃcients. As we studied in Chapters 4 and 17, there
are signiﬁcant advantages to this approach, especially that of parsimony. In frequency domain, an
added advantage is the ﬁne resolution at which the FRF can be estimated using parametrized models
- exactly along the lines on which parametric methods score over non-parametric counterparts for
spectral density estimation. These advantages come at a price paid by the analyst in providing the
information on delay, orders, etc. which is usually obtained through non-parametric identiﬁcation.
From Chapter 17 recall that primarily three broad classes of parametric model families exist,
namely, the equation-error (e.g., ARX, ARMAX), output-error and the Box-Jenkins family.
Of the three, the BJ family is the larger one containing the other two families as its members and
is described by (17.59)
y[k] = G(q−1,θ)u[k] + H(q−1,θ)e[k] = B(q−1)
F(q−1)u[k] + C(q−1)
D(q−1) e[k]
(21.1)
where e[k] ∼GWN(0,σ2
e) and the parameter vector θ is the set of coeﬃcients of the ﬁnite-order
polynomials, B, C, D and F.
The prediction-error family is a generalized representation of the BJ model in which the dynamics
common to noise and plant models are exclusively highlighted
G(q−1,θ) =
B(q−1)
A(q−1)F(q−1) ; H(q−1,θ) =
C(q−1)
A(q−1)D(q−1)
(21.2)
such that F(q−1) and D(q−1) are co-prime polynomials.
Note that A(.), C(.), D(.) and F(.) are all monic polynomials, i.e., have unity as the leading
coeﬃcient.
The one-step prediction and the prediction-error of the PE model were obtained in §18.3 and
568

Identiﬁcation of Parametric Input-Output Models
569
§18.4, respectively.
ˆy[k|k −1,θ] = H−1(q−1,θ)G(q−1,θ)u[k] + (1 −H−1(q−1,θ))y[k]
(21.3)
=
∞
X
j=0
˜g[n]u[k −n] +
∞
X
j=1
˜h[n]y[k −n]
(21.4)
ε[k|k −1,θ] = y[k] −ˆy[k|k −1,θ] = H−1(q−1)(y[k] −G(q−1,θ)u[k])
(21.5)
where ˜g[.] and ˜h[.] are the IR coeﬃcients of the input and output predictor ﬁlters. In this respect, it
is useful to re-iterate a point made earlier in Chapter 18. Parametric models can also be viewed as a
parametrization of the impulse response of the predictor ﬁlters, { ˜g[.]} and {˜h[.]}, respectively.
Note: In the presentations to follow, for convenience, the explicit dependence of the predictions, prediction errors and
transfer functions on θ is suppressed unless otherwise required.
Parametric identiﬁcation problem
Given ZN = {y[k],u[k]}N−1
k=0 identify the (parametrized) polynomials (A, B,C, D,F) and
variance σ2
e
The parameter estimation problem can be suitably handled using the methods of Chapters 14
and 15. A hallmark of the parametric identiﬁcation methods is that the LS, MLE and Bayesian ap-
proaches to identiﬁcation can be uniﬁed under the single umbrella of what are known as prediction-
error minimization (PEM) methods. On the other hand, the MoM approach gives rise to the so-called
correlation methods. Thus, one ﬁnds two broad classes of techniques for estimation of parametric
models.
1. PEM methods: The central object of interest in this approach is the (one-step ahead) prediction-
error. A natural expectation of a good model is that it should result in a “small” prediction error.
The objective in this method is to minimize the prediction errors using the model parameters and
noise variance as vehicles. The exact form of the objective function depends on the mathematical
measure that is used to quantify the smallness of the prediction error and whether the data is
being pre-ﬁltered.
2. Correlation methods: This is a second-order method of moments approach (recall §14.2). The
central idea is to drive the prediction errors such that they are uncorrelated with past data. As
with PEM methods, the exact set of equations depend on whether the data is pre-ﬁltered prior
to forming the correlations. The idea can also be generalized to consider correlations between
functions of prediction errors and functions of historical data.
The rest of this chapter is devoted to a detailed study of these methods with illustrations on suitable
examples.
21.2
PREDICTION-ERROR MINIMIZATION (PEM) METHODS
The generic problem of parameter estimation in a PEM approach is formulated as follows (Ljung,
1999).
ˆθ⋆
N = arg min
θ
V(θ,ZN )
(21.6a)
where
V(θ,ZN ) = 1
N
N−1
X
k=0
ˇl(ε(k,θ))
(21.6b)

570
Principles of System Identiﬁcation: Theory and Practice
The function ˇl(.) is a positive-valued monotonically increasing scalar function with the provision
to accommodate several known approaches such as LS and MLE as special cases (to be discussed
shortly). Alternatively, it could be a norm of the prediction error vector. A standard choice is the
quadratic function (norm), ˇl(ε) = 1
2ϵ2, translating to the non-linear / linear LS problem.
Generalizations
The objective function in (21.6b) can be generalized to encompass a broader class of methods:
1. Pre-ﬁltering: In many situations, data may be pre-ﬁltered prior to parameter estimation with
a pre-ﬁlter L(q−1). Recall from §1.4.2 that this step may be motivated for various reasons, for
example, emphasizing the model ﬁt over a select frequency range. Then, (21.6b) generalizes to
ˆθ⋆
N = arg min
θ
1
N
N−1
X
k=0
ˇl(ε f (k,θ))
(21.7)
where
ε f [k] = L(q−1)ε[k] = H−1(q−1)(yf [k] −G(q−1)uf [k])
(21.8)
is the ﬁltered prediction error constructed from pre-ﬁltered data.
2. Weighting: The idea and motivation is quite identical to that of the WLS problem. Allow ˇl(.) to
be explicitly a function of the sample
V(θ,ZN ) = 1
N
N−1
X
k=0
ˇl(ε f (k,θ),k)
Often the explicit dependence is factored out in the form of a time-varying weighting factor
w(k, N) as in the WLS, so that
V(θ,ZN ) = 1
N
N−1
X
k=0
w(k, N)ˇl(ε f (k,θ))
(21.9)
3. Parametrization of the function: In certain situations, the function ˇl(.) itself may be parameter-
ized by a parameter vector η (e.g., for bringing about robustness to outliers). Thus ˇl(ε f (k,θ),θ)
is now ˇl(ε f (k,θ),[θ η]T ). In a way similar to that of regularized estimation of FIR models, here
too the parameter vector η is optimized along with the model parameters θ.
4. Regularization: In order to impose penalty on overparametrization, an additional θ dependent
term may be introduced.
V R
N (θ,ZN ) = 1
N
N−1
X
k=0
ˇl(ε f (k,θ),k,θ) + R(θ)
(21.10)
Setting R(θ) = δ||θ||2
2 results in the standard Tikhonov-regularization formulation with δ as the
regularization parameter. As remarked in §15.2, setting ˇl(.) to be the log-likelihood function,
this approach is equivalent to Bayesian estimation with a Gaussian prior for the parameters. In
some recent developments, a sum-of-norms regularization has been used in place of the l2-norm
penalty for applications involving sparse parameters; see Ohlsson and Ljung (2013), for instance.

Identiﬁcation of Parametric Input-Output Models
571
For the multivariable case with nu inputs and ny outputs, the prediction error is a ny × 1 vector.
Then it is common to set up the objective function as a function of the sample covariance matrix of
prediction errors:
VN (θ,ZN ) = ˇl (R(θ)) ,
where
R(θ) = 1
N
N−1
X
k=0
ε(k,θ)WεT (k,θ)
(21.11)
where W is a matrix of weights accounting for relative importances and possible cross-correlations
between errors. Standard choices of ˇl(.) include trace and determinant.
Special cases of PEM
PEM specializes to several well-known methods depending on the choice of (i) pre-ﬁlter L(q−1), (ii)
the function ˇl(.) and (iii) the model structure. These specializations are easier to follow by setting
the pre-ﬁlter to unity, L(q−1) = 1 (no ﬁltering).
1. LSE: Choosing ˇl(ε,k,θ) = |ε(k,θ)|2, we obtain the least-squares estimator. The exact expres-
sion for the prediction error, of course, as we have seen earlier depends on the model structure.
This quadratic norm is usually the default choice in most applications.
2. MLE: When ˇl(ε,θ,k) = −ln fe(ε,k|θ) = −ln l(θ,ε,k) = L(θ,ε,k), where fe(.) is the p.d.f.
of e[k] and l(.) is the likelihood function, the maximum likelihood criterion is obtained.
When the innovations follow a Gaussian distribution, the log-likelihood function, as we know, is
ln l(θ,σ2
e,k) = const. + 1
2 ln σ2
e + 1
2
ε2
σ2e
Depending on the model structure, the variance of the innovations may or may not be an ex-
plicit function of the model parameters. For instance, recall from §15.1.2 that it is possible to
estimate σ2
e and the parameter vector θ independently for the case of ARX models. On the other
hand, where the estimation of ARMA(X) models using MLE is concerned, recall from §19.4.2
how the innovations variance is an implicit function of θ and that both have to be estimated
simultaneously.
For the multivariable case with Gaussian innovations, from (7.19), the log-likelihood and the
objective function are given by
L(θ,ε,k) = const. + 1
2 ln det Σe + 1
2εT Σ−1
e ε
(21.12a)
VN (θ,ZN ) = 1
N
N−1
X
k=0
L(θ,ε,k) = const. + 1
2 ln det Σe + 1
2
N−1
X
k=0
εT Σ−1
e ε
(21.12b)
If the noise covariance matrix is unknown and not parametrized through θ, then it is possible to
show that the PEM estimate is the solution to minimizing the determinant of the sample covari-
ance matrix of prediction errors (see Exercise E21.3)
VN (θ,ZN ) = det

1
N
N−1
X
k=0
ε(k,θ)εT (k,θ)

(21.13)
The equivalence of (21.13) with (21.11) is not surprising given that MLE with Gaussian innova-
tions is identical to the LS estimate.
3. MAP estimate: From §15.2, this Bayesian estimator is an MLE with a penalization term. With
this equivalence and the foregoing discussion, it should not be diﬃcult to see MAP as a special
case of PEM. Choosing ˇl(ε,θ,k) = −ln fe(ε,k|θ)−ln fθ(θ) gives rise to maximum a posteriori
estimate.

572
Principles of System Identiﬁcation: Theory and Practice
4. AIC estimate: Akaike in a series of works (Akaike, 1973, 1974a) proposed estimation of model
from an information theoretic perspective. The idea was to arrive at a model that is at a minimum
Kullback-Leibler information distance (Kullback, 1959) from the true system. It is possible to
show (for details refer to Ljung (1999)) that this approach is equivalent to minimizing the log-
likelihood with an additional term that measures the “size” of the model.
ˆθAIC = arg min
θ
*
,
1
N

N−1
X
k=0
−L(ε(k,θ),θ) + dim θ

+
-
(21.14)
Thus, for a ﬁxed model structure the PEM estimate with ˇl(.) = −L(.) and AIC estimate coin-
cide (since the second term is ﬁxed for a given model structure). Evaluating the estimate across
diﬀerent model structures aids in arriving at a model with an optimal trade-oﬀbetween model
complexity (variance of estimates) and model ﬁt (bias in predictions). Chapter 22 discusses this
aspect in detail.
There exists a fair amount of freedom in choosing the function (or norm) ˇl(.). The choice, of course
depending on the application, is also usually guided by certain general factors such as bias and
variance of the transfer function (see §21.5), robustness and ease of estimation (Ljung, 1999). For
instance, where eﬃciency ranks high in the priority list, the log-likelihood (MLE) is a natural choice.
However, as we had learned in Chapter 15, MLE is computationally demanding. Therefore, a com-
mon practice is to use the quadratic norm, which is equivalent to a conditional MLE with Gaussian
distributed errors (recall Example 15.1).
Choice of pre-ﬁlter
It is clear now that the PEM estimator accommodates various well-known estimators for diﬀerent
choices of objective functions. Variants of these specializations can be realized by selecting diﬀerent
pre-ﬁlters. The guiding principle is provided by the fact that pre-ﬁltering the data amounts to choos-
ing a particular noise model. Recall §17.5 in this context. The best choice of pre-ﬁlter is the noise
model itself. Chapter 22 discusses the salient aspects of the pre-ﬁlter’s impact in identiﬁcation for
the removal of drifts, trends and noise. For an elaborate treatment of this topic, see Ljung (1999).
Obtaining parameter estimates
The formulation of the PEM estimation in (21.6b) clearly leads to a non-linear optimization problem
in general (with the exception of quadratic ˇl and ARX structure). Therefore a non-linear solver such
as the Gauss-Newton method has to be employed.
As mentioned earlier, the standard choice for the norm is a quadratic one. A widely employed
method to estimate the resulting non-linear optimization problem is the (modiﬁed) Gauss-Newton
procedure, which is recalled below from Section §14.4.1 for easy reference:
Algorithm 21.1
General algorithm for obtaining quadratic PEM estimates
1. Initialize the model structure with a suitable guess of parameters (choose a stable guess). In several
situations, these guesses are the estimates of sub-optimal methods or from models estimated in
parts1.
2. Update the estimates using a modiﬁed Gauss-Newton algorithm until convergence
ˆθ(i+1) = ˆθ(i) −µiR−1
i ˆgi
(21.15)
1Refer to the case study in §24.2 for a demonstration.

Identiﬁcation of Parametric Input-Output Models
573
where
ˆgi = VN (θ)
dθ
θ=θ(i) = −1
N
N−1
X
k=0
ε(θ)ψ(θ)
θ=θ(i)
ψ(k,θ) = ∂
∂θ ˆy(k|θ); Ri = V′′
N ≈1
N
N−1
X
k=0
ψ(k, ˆθ(i))ψ(k, ˆθ(i))T
The exact expressions for the gradient of the predictor ψ(k,θ) depend on the model structure. The
section on ARMAX model estimation in §21.6.2 and the example 21.8 therein illustrate the com-
putation of these expressions for an ARMAX model. These ideas carry forward to other structures
such as OE and BJ models as well.
Notwithstanding the generic estimation algorithm discussed above, there exist specialized algo-
rithms for each family of models. The Stieglitz-McBride algorithm for OE model estimation (see
§21.6.3) is an example of this kind. These methods do not necessarily produce optimal estimates,
but provide suitable starting points for the general algorithm.
The next natural topic of attention is the goodness of PEM estimates. Given that LS and ML es-
timators are special cases of PEM and that they possess nice properties, one can expect the PEM
estimator also to be equipped with good asymptotic properties. As we shall shortly learn, this is
indeed the case. We shall only study the key large sample properties, namely, asymptotic conver-
gence (whether the estimates converge to a limit as N →∞) and consistency (whether the limit is
the true value itself). In addition, we shall also, naturally, review the distributional properties of the
estimator. For a detailed account, the reader is directed to Ljung (1999).
21.3
PROPERTIES OF THE PEM ESTIMATOR
The discussion to follow is largely in the context of quadratic-criteria PEM estimators, denoted
by the acronym PEM-QC:
VN (θ,ZN ) = 1
N
N−1
X
k=0
1
2ϵ2(k,θ)
(21.16)
Further, open-loop conditions are assumed. Closed-loop scenario is discussed in §25.3. Convergence
properties of general norm PEM estimators are also available, but of lesser interest here. See Ljung
(1999) for details.
Two governing factors
The properties of PEM estimator, as with a general estimation problem, depend on two key govern-
ing factors:
1. Model mis-speciﬁcation: This factor appeals to the diﬀerence between the model structure ﬁnally
identiﬁed by the user and the data generating process (DGP). How is this diﬀerence quantiﬁed?
In terms of the transfer function or the FRF. Recall from §18.5 that two models are equal only if
their FRFs are identical.
Denote the model structure (recall its deﬁnition from §18.5.1) by M(θ) and the true system by
S. Formally,
S :y[k] = G0(q−1)u[k] + H0(q−1)e0[k]
(21.17)
M :y[k] = G(q−1,θ)u[k] + H(q−1,θ)e[k] ≡{G(q−1,θ), H(q−1,θ)|θ ∈DM}
(21.18)
where DM is a compact set2.
2Compactness of the set essentially means that the set is bounded, closed and that all sequences converge to a limit point
in the set.

574
Principles of System Identiﬁcation: Theory and Practice
The true system could be either in a non-parametric or parametric form. If the latter applies,
then S is a ﬁxed point in the parameter space. When the model structure contains the true system,
we write S ∈M(θ). In terms of the FRF, this is written as
∃θ ∈DM s.t.
G0(ejω) = G(ejω,θ),
H0(ejω) = H(ejω,θ)
(21.19)
Essentially,
The true system is said to be contained in the model set if and only if there exists a value of θ for
which the FRF calculated from the parametrized plant and noise models exactly matches with
that of the true plant and noise models, respectively. When the system has a parametric form as
in (21.2), the model structure contains the system only if the orders of the polynomials of the
model are at least the same as that of the system and the delay has not been overestimated.
In principle, there are four diﬀerent possibilities of model-system mismatch, of which three are
of prime interest:
i. (G0, H0) ∈(G(q−1,θ), H(q−1,θ)): System plant and noise models are contained in the model
set.
ii. G0 ∈G(q−1,θ), H0 < H(q−1,θ): Only the true plant model is contained.
iii. (G0, H0) < (G(q−1,θ), H(q−1,θ)): None of the plant and noise models are captured.
The remaining case, namely, G0 < G(q−1,θ), H0 ∈H(q−1,θ) is of little practical interest.
2. Parametrization of G and H: The convergence property of the estimator depends on how the
plant and noise models are parametrized because the nature of parametrization determines the
ﬂexibility available in tuning the plant and noise models independently to explain the data. It is
useful to imagine the parameters as tuning knobs to minimize the prediction errors.
As an example, recall the parametric identiﬁcation of the liquid level system in §2.4.5, where
the generating process approximately had a ﬁrst-order OE structure. Estimates of the ﬁrst-order
ARX model, i.e., G0 ∈G(q−1,θ), H0 < H(q−1,θ) turned out to be biased (recall (2.20) and
2.31). The general result that we shall shortly learn, is that when there is a mismatch between the
model and DGP, consistency of the PEM-QC estimator is guaranteed only when the plant and
noise models are independently parametrized.
The following example illustrate the notions of model structure and true system.
Example 21.1: Model Structure and True System
Suppose the data generating process has an ARMAX description
S :
y[k] =
b0
1q−1
1 + a0
1q−1 + a0
2q−2 u[k] +
1 + c0
1q−1
1 + a0
1q−1 + a0
2q−2 e0[k],
e0[k] ∼GWN(0,σ2,0
e )
and four diﬀerent candidate model structures are chosen (assume that the delay has been
correctly estimated):
i. ARX(1,1): G(q−1,θ) =
b1q−1
1 + a1q−1 ; H(q−1,θ) =
1
1 + a1q−1 .
This is the case of S < M, i.e., G0 < G(q−1,θ), H0 < H(q−1,θ).

Identiﬁcation of Parametric Input-Output Models
575
ii. ARX(2,1): G(q−1,θ) =
b1q−1
1 + a1q−1 + a2q−2 ; H(q−1,θ) =
1
1 + a1q−1 + a2q−2 .
Then, we have that G0 ∈G(q−1,θ), H0 < H(q−1,θ). In both ARX structures, the noise and plant
models are jointly parametrized.
iii. OE(2,1): G(q−1,θ) =
b1q−1
1 + a1q−1 + a2q−2 ; H(q−1,θ) = 1.
As in the previous case, we have that G0 ∈G(q−1,θ), H0 < H(q−1,θ). However, there is a striking
diﬀerence. The plant and noise models are parametrized independently (strictly speaking the noise
model has not been parametrized), whereas the ARX model has a fully joint parametrization
for G and H. As remarked earlier, we should expect the PEM-QC estimates of G to converge to
G0.
iv. BJ(2,1,1,2): G(q−1,θ) =
b1q−1 + b2q2
1 + f1q−1 + f2q−2 ; H(q−1,θ) =
1 + c1q−1
1 + d1q−1 + d2q−2 .
In this case as well the true system is contained in the model structure S ∈M(θ) (with b2 = 0)
despite the fact that B(q−1) has been overparametrized. In this model, the plant and noise
models are parametrized independently.
v. ARMAX(2,1,1): G(q−1,θ) =
b1q−1
1 + a1q−1 + a2q−2 ; H(q−1,θ) =
1 + c1q−1
1 + a1q−1 + a2q−2 .
This is evidently the case of S ∈M(θ)
In the example above, notice the distinction between e0[k] and e[k]. The former is the true GWN
disturbance acting on the process, with variance σ2
e0, whereas the latter emerges from the model
and its variance is estimated along with θ.
Other requirements and assumptions
Among other requirements for consistency to be achieved, the prime one is that of identiﬁability,
which was succinctly introduced in §2.1 and an important facet of which was formally treated in
§18.6. The other facet pertaining to the role of input in guaranteeing parameter identiﬁability, is
discussed in Section 22.3. Note that if the input is not “suﬃciently" excited, the estimator may
converge, but not necessarily to the true one if S ∈M holds. Additional assumptions include
quasi-stationarity, stability of predictor ﬁlters and that gradients of predictors exist. These are listed
below.
(A-1) data is informative (input has the “necessary” excitation)
(A-2) inputs and outputs are quasi-stationary
(A-3) both the inputs and outputs can be expressed as outputs of linear ﬁlters driven by white noise,
e0[k]
(A-4) predictor ﬁlters are stable, i.e., model predictions are bounded
(A-5) gradients of predictors w.r.t. θ exist and are ﬁnite
Under closed-loop conditions, an additional requirement is needed on the input, which is that it
should have an external source of excitation (e.g., via set-point or through a dither). This is discussed
in §25.3.
21.3.1
CONSISTENCY OF PEM ESTIMATORS
With all the foregoing assumptions and identiﬁability requirements satisﬁed, the consistency of
PEM estimators depends on whether a mis-speciﬁcation has occurred, the nature of the mismatch
and the parametrization of plant and noise models.

576
Principles of System Identiﬁcation: Theory and Practice
Case of S ∈M
Theorem 21.1
Conditions (A-1)-(A-5) holding and S ∈M, the PEM-QC estimates converge to the true value,
G(ejω, ˆθN ) −→G0(ejω),
H(ejω, ˆθN ) −→H0(ejω)
(21.20)
If the true system has a parametric representation, characterized by the parameter vector θ0, then
Theorem 21.1 implies
ˆθN −→θ0
w.p.1
(21.21)
In Example 21.1, this case corresponds to ﬁtting an BJ(2,1,1,2) or an ARMAX(2,1,1) model to the
data generated from an ARMAX(2,1,1) process. From Theorem 21.1, the parameter estimates of
these two diﬀerent model structures will both converge to that of the true process.
Case of S < M, G0 ∈G(q−1,θ) and independent parametrization
This is the case where only the plant structure is speciﬁed correctly and G(q−1,θ) and H(q−1,θ)
are independently parametrized.
Theorem 21.2
Under open-loop conditions, (A-1)-(A-5) holding, S < M,G0 ∈G(θ) and that the parametrization
of G(q−1,θ) and H(q−1,θ) are independent, the PEM-QC estimate of the plant model converges to
the true value,
G(ejω, ˆθN ) −→G0(ejω)
(21.22)
Again, if the true system has a parametric representation and the parameter is partitioned as
θ0 =
f
θ0,G
θ0,H
gT
(21.23)
where θ0,G and θ0,H only parametrize G0 and H0, respectively, then Theorem 21.2 implies
ˆθG N −→θ0,G
w.p. 1
(21.24)
Referring to Example 21.1, this situation corresponds to ﬁtting an OE(2,1) model to the data gen-
erated from an ARMAX(2,1,1) process. Theorem 21.2 dictates that the plant model of the OE(2,1)
structure will converge to that of the ARMAX(2,1,1) process despite the disparity in the noise mod-
els.

Identiﬁcation of Parametric Input-Output Models
577
General case: (i) S < M and (ii) G0 ∈G(θ) with common parametrization
Historically, until 1970s, researchers were mostly concerned with the estimation of the “true” model.
However, the reality is that the process is more complex than what can be conceived of, and therefore
it is unlikely to be contained in the user-speciﬁed model set. Two relevant questions of interest are
therefore: (i) under what conditions do the parameter estimates converge in this case? and (ii) when
they do, to what value do they converge?
To answer the questions above, it is important to establish ﬁrst that the objective function itself
converges to a realizable limit. A theoretical result to this eﬀect exists (see Ljung (1999)). Without
delving into the derivations, the ﬁnal result is stated
¯V(θ) ≜lim
N→∞
1
N
N−1
X
k=0
1
2ϵ2(k,θ) = ¯E
 1
2ε2[k,θ]
!
(21.25)
where ¯E is the time- and ensemble-average operator deﬁned earlier in (17.4).
Remarks:
The consequence of the limit result above is that for a purely stochastic process, the limit simpliﬁes
to the variance of prediction errors. In the general case, under the quasi-stationarity assumption, the determin-
istic input has the properties of a random signal. Therefore, for all practical purposes, one can replace the time-
and ensemble-average operator ¯E with the regular ensemble expectation E(.)
Now we turn to the following interesting result.
Theorem 21.3
Conditions (A-1) - (A-5) holding, the PEM-QC converges to the optimum realized by the limit
objective function ¯V (θ). That is, for any model parameterization,
ˆθN −→θ⋆w.p. 1
(21.26)
where
θ⋆= min
θ
¯V (θ) = min
θ
¯E
 1
2ε2[k,θ]
!
(21.27)
In essence, we obtain the best possible approximation asymptotically realized by the chosen
model structure. Theorem 21.3 is useful in answering the question on what is theoretically the best
approximation obtained by the chosen model structure, asymptotically. An example below illustrates
this point.
Example 21.2: Fitting an ARX Model to an OE Process
Problem: Consider data generated by an OE process
y[k] + f 0
1 y[k −1] = b0
1u[k −1] + e0[k] + f 0
1 e0[k −1]
e0[k] ∼N (0,σ2
e0)
(21.28)
excited by a zero-mean WN input, i.e., σuu[l] = 0, ∀l , 0 with variance σ2u.
Suppose an ARX(1,1) model
y[k] + a1y[k −1] = b1u[k −1] + e[k]
(21.29)

578
Principles of System Identiﬁcation: Theory and Practice
is ﬁt to the data. Then, what values do the PEM-QC estimates of a1 and b1 converge to as
N →∞?
Solution: From Theorem 21.2, it is clear that the parameter estimates ˆa1 and ˆb1 do not
necessarily converge to f 0
1 and b0
1, respectively.
On the other hand, Theorem 21.3 allows us to compute the theoretical values of the ARX
model estimates under the given conditions as follows.
1. Compute predictor: ˆy[k|k −1] = −a1y[k −1] + b1u[k −1]
2. Compute the limiting objective function:
¯V(θ) = ¯E(ε2(k,θ)) = ¯E((y[k] + a1y[k −1] −b1u[k −1])2)
= (1 + a2
1)σ2
y + 2a1σyy[1] −2b1σyu[1] + b2
1σ2
u
where we have used the strict causality condition, σyu[l] = 0, l ≥0 (which is theoretically true
only when input has white-noise characteristics).
3. Estimate the optimal limiting parameters that minimize ¯V(θ) by setting the concerned partial
derivatives to zero
∂¯V(θ)
∂a1
= 0 =⇒a⋆
1 = −σyy[1]
σ2y
;
∂¯V(θ)
∂b1
= 0 =⇒b⋆
1 = σyu[1]
σ2u
(21.30)
To complete the calculations, we need to ﬁnd the true auto- and cross-covariance quantities.
From the process description in (21.28) and noting that µu = 0, µy = 0, we have
σ2
y = E(y[k]y[k]) = −f 0
1 σyy[1] + b0
1σyu[1] + σye[0] + f1σye[1]
σyy[1] = E(y[k]y[k −1]) = −f 0
1 σ2
y + b0
1
:0
σyu[0] +
:0
σye[−1] + f 0
1 σye[0]
σye[0] = E(y[k]e[k]) = −f 0
1
:0
σye[−1] + b0
1
:0
σue[−1] + σ2
e + f 0
1

:0
σee[1] = σ2
e
σye[1] = E(y[k]e[k −1]) = −f 0
1 σ2
e + b0
1
:0
σue[0] +

:0
σee[1] + f 0
1 σ2
e = 0
σyu[1] = E(y[k]u[k −1]) = −f 0
1
:0
σyu[0] + b0
1σ2
u +
:0
σeu[1] + f 0
1
:0
σue[0] = b0
1σ2
u
=⇒σ2
y =
(b0
1)2
1 −( f 0
1 )2 σ2
u + σ2
e;
σyy[1] = −f 0
1 σ2
y + f 0
1 σ2
e
Therefore, the optimal parameter estimates of the ARX(1,1) model for the OE(1,1) process
are
a⋆
1 = f 0
1 *
,
1 −σ2e
σ2y
+
-
;
b⋆
1 = b0
1
(21.31)
where σ2y is as computed before. Thus, we have biased estimates (hence the lack of consis-
tency) of the plant model G(q−1). Note that the estimate of the numerator coeﬃcient happens
to be unbiased though.
This example also largely explains the inability of the ﬁrst-order ARX model to suﬃciently
explain the dynamics of the liquid-level system in the case study of Chapter 2 (the only
diﬀerence is that a PRBS input was used in the case study as against the white-noise input
in the present example).
Remarks:
i. It is important to recognize that the cause of this bias is the method and not necessarily the model mis-
speciﬁcation. From Chapter 14 we know that LS estimates of linear regression models are biased whenever

Identiﬁcation of Parametric Input-Output Models
579
the equation error is colored. ARX models are linear regression models and the given process has a colored
equation error,
y[k] = −f 0
1 y[k −1] + b0
1u[k −1] +
colored eqn. error
z                }|                {
e[k] + f 0
1 e[k −1]
Hence, the bias. In §21.7.1, we shall learn a technique known as the instrumental variable method that can
produce unbiased estimates of the ARX model despite the colored equation error.
ii. The PEM estimate of a1 in (21.31) clearly indicates that the bias diminishes for very high SNR. Thus, the
signal-to-noise ratio has a larger role to play in parameter estimation.
Theorem 21.3 is more generic in nature. It can be applied even under conditions of Theorem 21.2,
i.e., even when G0 ∈G(θ). To illustrate this application, consider a situation that is the reverse of
that in Example 21.2.
Example 21.3: Fitting an OE Model to an ARX Process
Given that the input-output data is generated by an ARX(1,1) process:
y[k] = −a0
1y[k −1] + b0
1u[k −1] + e0[k]
with a zero mean GWN input of variance σ2u, and an OE(1,1) model
y[k] =
b1q−1
1 + f1q−1 u[k] + e[k]
is sought. Determine if the PEM-QC estimates of the plant model converge to that of the
process.
Solution: Naturally, one can right away invoke Theorem 21.2 to conclude that indeed the
estimates of plant model parameters converge to the respective true ones. Since the purpose
of this example is to illustrate the use of Theorem 21.3, we follow a procedure similar to that
in Example 21.2.
As a ﬁrst step, re-write the OE model in an IIR form so that it is convenient to compute
the expression for ¯V (θ):
y[k] = b1
∞
X
i=1
(−f1)i−1u[k −i] + e[k]
so that the one-step ahead predictor and the prediction error are
ˆy[k|k −1] = b1
∞
X
i=1
(−f1)i−1u[k −i]
=⇒ε[k|k −1] = y[k] −b1
∞
X
i=1
(−f1)i−1u[k −i]
Now, the limit objective function is
¯V(θ) = ¯E((y[k] −b1
∞
X
i=1
(−f1)i−1u[k −i])2)
= E(y2[k]) + E(b2
1
*.
,
∞
X
i=1
(−f1)i−1u[k −i]+/
-
2
−2E(b1
∞
X
i=1
(−f1)i−1y[k]u[k −i])
= σ2
y + b2
1
∞
X
i=1
( f 2
1 )i−1σ2
u −2b1
∞
X
i=1
(−f1)i−1σyu[i]
= σ2
y +
b2
1
1 −f 2
1
σ2
u −2
b1b0
1
1 + a0
1 f1
σ2
u
(21.32)

580
Principles of System Identiﬁcation: Theory and Practice
The last expression follows from the ARX process description and the fact that the input is
WN, implying
σyu[i] = E(y[k]u[k −i]) = b0
1(−a0
1)i−1σ2
u
Setting the derivatives of (21.32) with respect to b1 and f1 to zero and solving the resulting
equations yields
f ⋆
1 = a0
1;
b⋆
1 = b0
1
(21.33)
Thus, we obtain unbiased estimates of the plant model.
Inﬂuence of input on PEM estimates
In general, the best approximation (and the bias) not only depends on the user-speciﬁed model
structure but also on the input signal and input-output delay. Example 2.2 gave us some insights
into the role of input where a third-order FIR model could only be best approximated by a second-
order FIR model when the input is poorly excited. To further comprehend the inﬂuence exerted by
the input signal in shaping the best approximation, revisit Example 21.2 with the input generated
from an MA(1) process.
Example 21.4: Revisiting Example 21.2 with Correlated Input
Consider the process and model of Example 21.2 under the input
u[k] = eu[k] + α1eu[k −1],
eu[k] ∼GWN(0,σ2
eu )
Then, following the same line of procedure as in Example 21.2, the estimates of a1 and b1
are biased (see Exercise E21.7):
a⋆
1 = f 0
1
*...
,
1 −
1
σ2y
σ2e −
(b0
1)2α2
1
1+α2
1
σ2e
σ2eu
+///
-
(21.34a)
b⋆
1 = b0
1
*...
,
1 −
α1 f 0
1
(1+α2
1)σ2y
σ2e
−
α2
1σ2eu
σ2e
+///
-
(21.34b)
This situation is closer to the liquid level identiﬁcation case study of Chapter 2 since the
designed PRBS exhibits a temporal correlation similar to that of the MA(1) input in this
example.
In the foregoing example, observe that the bias in each of the parameter estimates depends on the
true values of the parameters, SNR and the correlation in the input. Shortly, we shall learn how the
input spectrum shapes both the bias and variance of the estimates of transfer functions in frequency
domain.
Inﬂuence of user-speciﬁed delay
The eﬀect of user-speciﬁed delay on the identiﬁed models, particularly when over-speciﬁed (user-
speciﬁed delay is greater than the true one), can be signiﬁcant. Under these conditions, the model
set will not contain the true system even though the numerator and denominator orders of the indi-
vidual polynomials have been correctly speciﬁed. For example, a 20-coeﬃcient FIR model with a
delay of 2 samples cannot model a process that is also a 20-coeﬃcient FIR but with a delay of 1
sample. On the other hand, under-specifying does not result in these issues but introduces unneces-
sary parameters into a model. Fortunately, the cross-correlation between residuals and inputs, and
the error analysis of parameter estimates reveal the mis-speciﬁcation of the delay.

Identiﬁcation of Parametric Input-Output Models
581
Practical aspects
A standard question that comes to mind is: of what use are Theorems 21.1, 21.2 and 21.3 in prac-
tice?, because one would not know whether the true system description is contained in the model set
or not. The direct practical utility of these theorems is low, but they lend strong theoretical support
to the identiﬁed models, particularly that (i) the estimator fetches the best possible approximation,
when the user-speciﬁed model set does not encompass the true system and (ii) the output-error
model of “suﬃciently” high-order can rightly estimate the plant transfer function despite the mis-
match in the noise models. Observe that ARX model structures do not necessarily enjoy such a
property. In a general identiﬁcation exercise, the goal is to realize the conditions of Theorem 21.1,
at least on the basis of the training data. This is achieved by carefully adhering to the systematic
procedure in Figure 1.7, in particular the model quality assessment checks described in §22.6.4.
Correlation analysis of residuals and conﬁdence intervals of parameters are the key indicators.
In closing this section, it should be remarked that all the results presented above have assumed
that the true system possesses a LTI description. However, the reality is to the contrary, i.e., all
real-life systems are non-linear and/or of time-varying nature, albeit of diﬀerent degrees. In this
light, the “true” system in reality is a linearized, time-invariant approximation in the vicinity of
the experimental conditions. Recall the case study of §2.4, where the system under study has a
continuous-time, non-linear and time-invariant description in (2.6). In such a case, the linearized
and discretized version (2.31) along with the noise description serves as the true system reference.
Finally, the convergence properties of the PEM-QC estimators, especially that of Theorem 21.1,
are equally applicable to those with other norms, but with an important additional requirement that
these norms be convex (see Ljung (1999, Chapter 8)).
21.4
VARIANCE AND DISTRIBUTION OF PEM-QC ESTIMATORS
Finite sample properties of PEM estimators are quite complicated and diﬃcult to analyze. Therefore,
only large sample properties are available.
The asymptotic variance and distributional properties of PEM-QC estimators are, expectantly,
quite similar to those of the NLS estimators discussed in §14.4.3. Just as the way we studied the
convergence results for three diﬀerent conditions, the variance of PEM-QC estimators are also avail-
able for the cases of:
i. The model set M contains the true system S.
ii. G0 ∈G(θ), H0 < H(θ), the plant and noise models are independently parametrized.
iii. System is not contained in the model set, S < M.
Among these three, the ﬁrst one is of utmost interest. The expressions for the remaining two cases
are complicated and largely useful for theoretical analysis. Only the ﬁnal statement of the result is
discussed below. For a formal treatment and proofs of the results, refer to Ljung (1999, Chapter 9).
Covariance of parameter estimates
Under conditions identical to those for convergence, PEM estimates obtained with a quadratic
norm asymptotically follow a Gaussian distribution.
i. True system contained in the model set, S ∈M:
2The asymptotic properties of PEM estimators ﬁrst appeared in the works of Ljung and Caines (1979) and later in Ljung
(1985a).

582
Principles of System Identiﬁcation: Theory and Practice
The variance depends on the sensitivity of the predictor to θ and σ2
e
√
N( ˆθN −θ⋆) ∼AsN (0,Pθ)
Pθ = σ2
e
f ¯E(ψ(k,θ0)ψT (k,θ0))
g−1
where ψ(k,θ0) =
d
dθ ˆy(k,θ)
θ=θ0
(21.35a)
(21.35b)
(21.35c)
The assumptions here are similar to those made in deriving the variance of NLS estimators where
it was assumed that the model captured the structure of the data generating process exactly.
• Observe the similarity of (21.35) with those of NLS estimators given in (14.140) and
(14.142). The only diﬀerence is that the gradients are explicitly treated for their stochastic
content. As in non-linear regression, the prediction gradients take the role of regressors in
a linear regression model.
• Notice that once again, the error in ˆθ is inversely ∝how sensitive is the predictor w.r.t. θ
and directly ∝the noise variance (noise-to-prediction-gradient ratio). Therefore, the values
of these quantities depend on the model structure. Sections 21.6.2 and 21.6.3 provide the
expressions for the gradient of the predictor for ARMAX and OE models, respectively.
• When the predictors are linear in unknowns (e.g., ARX models), the gradients do not de-
pend on the true values. The PEM-QC estimator is then identical to the linear least squares
method and has the properties of an OLS estimator.
• For linear regression models, the covariance of ˆθ can be computed purely from data without
the knowledge of the true values (recall similar expression for LSEs of linear models).
The asymptotic variance expressions are useful in theoretical as well as practical analysis (to be
discussed shortly). An example below demonstrates its theoretical application.
Example 21.5: Variance of ARX Parameter Estimates
Consider ﬁtting an ARX(1,1) model
y[k] =
b1q−1
1 + a1q−1 u[k] +
1
1 + a1q−1 e[k] = yd[k] + v[k]
(21.36)
to the data generated by a process having the same structure, but with the true parameters
a10, b10 and variance σ2
e0. The input is a zero-mean WN process with variance σ2u and is
uncorrelated with the noise e0[k].
The ﬁrst step is to derive an expression for the predictor gradient
ψ(k,θ) = d
dθ ˆy(k,θ) = −d
dθ ˆε(k,θ) =
f
−y[k −1]
u[k −1]
gT
(using (17.34))
Subsequently, using (21.35), we have
Pθ = σ2
e0
f ¯E(ψ(k,θ0)ψT (k,θ0))
g−1
= σ2
e0
"
σ2y
−σyu[0]
−σuy[0]
σ2u
#−1
where, as before, ¯E has been replaced by the regular expectation operator (i.e., the process
is assumed to be ergodic)
Thus, we have
Σ ˆθ =
σ2
e0
N
"
σ2y
−σyu[0]
−σuy[0]
σ2u
#−1
(21.37)

Identiﬁcation of Parametric Input-Output Models
583
In a practical use of (21.37), the theoretical (co-)variances and the innovations variance
would be replaced by their sample versions.
To obtain more insights into the errors in ˆθ, we compute the theoretical expressions for
the (co-)variances using the system description:
y[k] + a10y[k −1] = b10u[k −1] + e0[k]
Proceeding in a similar way as in Example 21.2, we have
σ2
y =
b2
10σ2u + σ2
e0
1 −a2
10
; σyu[0] = 0
(21.38)
Substituting these into (21.37), we obtain
Σ ˆθ =
σ2
e0
N
"σ2y
0
0
σ2u
#
Thus,
var( ˆa1) =
σ2
e0
Nσ2y
=
1 −a2
10
N
1
1 + b2
10
σ2u
σ2
e0
=
1 −a2
10
N
1
1 + SNRout
var(ˆb1) =
σ2
e0
Nσ2u
=
1
N × SNRin
;
cov( ˆa1, ˆb1) = 0
(21.39a)
(21.39b)
where
SNRout = var(yd[k])
var(v[k]) =
b2
10σ2u/(1 −a2
10)
σ2
e0/(1 −a2
10)
=
b2
10σ2u
σ2
e0
;
SNRin = var(u[k])
var(e[k]) = σ2u
σ2
e0
(21.40)
are the output and input SNR, respectively, for the ARX(1,1) process.
The expressions in (21.39) once again emphasize the role of signal-to-noise ratio in the
errors in parameter estimates. The dependence on SNR is also intuitively meaningful -
precision of input coeﬃcient estimate is governed by input-SNR and that of output by the
output-SNR.
Comparing notes with the NLS estimator, it is of interest to note that the variance expression for
ˆa1 in (21.39) simpliﬁes to that for the NLS estimate of the AR(1) model, given by (19.81).
ii. Plant model description in the model set, G0 ∈G(θ), G and H independently parametrized:
Under the assumptions (A-1) - (A-5) and the conditions of Theorem 21.2, the parameter estimates
follow an asymptotic Gaussian distribution with
√
N( ˆθN −θ0) ∼N (0,Pθ)
where
Pθ = σ2
e
f ¯EψG[k]ψT
G[k]
g−1 f ¯E ˜ψ[k] ˜ψT k
g f ¯EψH[k]ψT
H[k]
g−1
ψG[k] =
∂
∂θG
ˆy[k] = H−1(q−1,θ⋆
H )
∂
∂θG
G(q−1,θG)
θG=θ0,G
u[k]
˜ψ[k] =
∞
X
l=0
˜f [l]ψθG[k + l],
˜F(z) =
H0(z)
H(z,θ⋆
H ) =
∞
X
l=0
˜fl z−l
(21.41a)
(21.41b)
(21.41c)
(21.41d)
This case corresponds to situations that solely focus on the deterministic eﬀects, i.e., where
inaccuracies in noise modeling are not of concern. Fitting an OE model to a process is a classic
instance of this case. An example from Ljung (1999, p. 289) where an OE(1,1) model is ﬁt to an
ARX(1,1) process demonstrates the use of (21.41b).

584
Principles of System Identiﬁcation: Theory and Practice
iii.
General case, S < M, plant and noise models are independently parametrized: As we have
learnt earlier, for this case, the model converges to the best approximation in the model set.
Therefore, the error in parameter estimates is computed with respect to the “best estimate” θ⋆and
not the true parameters, where θ⋆is the optimum determined by the limiting objective function,
given by (21.27).
This case is of less interest to a practitioner since the eﬀort in general is to model the plant and/or
noise models adequately well enough, i.e., to fulﬁll S ∈M or G0 ∈G(θ). Nevertheless, for
the sake of completeness, expressions for covariance are provided below. For further details and
derivations, the reader is referred to Ljung (1999, Chapter 9).
Under the conditions of Theorem 21.3, the following results hold:
√
N( ˆθN −θ⋆) ∼N (0,Pθ)
(21.42a)
where
Pθ =

V ′′(θ⋆)
−1 Q

V ′′(θ⋆)
−1
Q = lim
N→∞E
(
[V ′
N (θ⋆,ZN )][V ′
N (θ⋆,ZN )]T )
(21.42b)
(21.42c)
where the quantities V ′(.) and V ′′(.) are the ﬁrst and second derivatives of the objective functions
w.r.t. θ, evaluated at the limit optimum. These expressions are useful in theoretical analysis of
PEM estimates.
The asymptotic expressions are, as with other estimators, useful in three diﬀerent ways:
i. computing the large sample errors in parameter estimates,
ii. constructing conﬁdence intervals for the true parameters, and
iii. theoretically analyzing PEM estimators under diﬀerent input conditions.
Among the three diﬀerent possibilities for the model sets discussed earlier, the simplest and per-
haps the most practical one is the ﬁrst case, i.e., S ∈M. The practical utility of this case is high
since the goal in identiﬁcation is to build a model that captures the underlying system description
(barring the case of output-error model identiﬁcation). It can be shown (see (Ljung, 1999)) that
these estimates are asymptotically eﬃcient, i.e., as N →∞it achieves the variance dictated by the
Cramer-Rao’s lower bound. The expressions in (21.35) require the knowledge of the true parameter
values! In practice, we replace the true ones with their sample versions, with the aim of obtaining
consistent estimators of the parameters covariance matrix and innovations variance:
ˆPθ = ˆσ2
e
1
N

N−1
X
k=0
ψ(k, ˆθ)ψT (k, ˆθ)

−1
;
ˆσ2
e = 1
N
N−1
X
k=0
ε2(k, ˆθ)
(21.43)
where ˆθ is the obtained parameter estimate.
Until this point we have studied the convergence properties of PEM estimators in the domain of
parameters. This constituted an indirect way of evaluating the accuracy of the resulting estimate
of the transfer function or the frequency response function of the system. It is important, however,
to directly examine the convergence of (parametrized) FRFs since the true (LTI) system is always
characterized by an FRF, but not necessarily by a parametric representation. With this motivation,
we step into the following section.

Identiﬁcation of Parametric Input-Output Models
585
21.5
ACCURACY OF PARAMETRIZED FRF ESTIMATES USING PEM
The founding results on the goodness of transfer function (or the FRF) estimates using the PEM
estimators were provided by Ljung (1985b) and Wahlberg and Ljung (1981).
The two questions of interest with respect to the FRFs constructed from the optimal parametric
models (estimated by PEM) are as follows.
i. In the general case of S < M, Theorem 21.3 states that the PEM method results in the best
approximate model for the chosen structure. Then, we wish to determine how the prediction
error (in time) manifests as error in the FRF (bias in FRF) at each frequency.
ii. How does the variability in parameter estimates propagate to variability in the FRF? That is, we
would like to obtain expressions for var( ˆG(ejω,θ)).
Answers to these questions above will not only allow us to compute the bias and variance in para-
metric transfer function ﬁts but more importantly, determine the design factors in an identiﬁcation
exercise that can be changed to shape the bias and minimize the variance.
In order to arrive at an answer for the ﬁrst question, we need a frequency-domain equivalent of
the time-domain (quadratic) PEM objective function. Asymptotic expressions for the frequency-
domain equivalents were presented by Ljung (1985b) and Wahlberg and Ljung (1981), and later in
(Ljung, 1999). These results are established under the usual assumption of quasi-stationarity. Only
the main results are given below. For details on the intermediate steps, see Ljung (1999). The basic
expression for deriving the frequency-domain equivalent is due to Parseval’s identity:
¯V(θ) = ¯E 1
2ε2(k,θ) = 1
4π
Z π
−π
γεε(ω,θ) dω
(21.44)
where the quantity γεε(ω,θ) is the spectrum of prediction errors and a function of the parameter
vector. The goal is to derive an expression for the spectral density γεε(ω,θ) in terms of the “true”
system and the model transfer functions.
Assuming that the data generating process is
y[k] = G0(q−1)u[k] + H0(q−1)e0[k],
e0[k] ∼GWN(0,σ2
e0)
Substituting the generating equation into the generic expression for the one-step ahead prediction
error (18.37) and a minor algebraic manipulation yields
ε[k] = H−1(q−1,θ)[(G0(q−1) −G(q−1,θ))u[k]
(21.45)
+ (H0(q−1) −H(q−1,θ))e0[k] + H(q−1,θ)e0[k])]
= H−1(q−1)[△G(q−1,θ)u[k] + △H(q−1,θ)e0[k]] + e0[k]
(21.46)
where
△G(q−1,θ) = G0(q−1) −G(q−1,θ),
△H(q−1,θ) = H0(q−1) −H(q−1,θ)
(21.47)
Finally, applying the relation (17.14a) for quasi-stationary signals to obtain the spectral density
γεε(ω) and plugging the same into (21.44) yields the required expression under open-loop condi-
tions (input u[k] is uncorrelated with noise e0[k])
γεε(ω,θ) = |△G(ejω,θ)|2
γuu(ω)
|H(ejω,θ)|2 + |△H(ejω,θ)|2
|H(ejω,θ)|2 σ2
e,0 + σ2
e,0
(21.48)
where △G(ejω,θ) = G0(ejω) −G(ejω,θ) and likewise for △H(ejω,θ).

586
Principles of System Identiﬁcation: Theory and Practice
Examining (21.48) in combination with (21.44), we write the limiting estimate as
θ⋆= arg min
θ∈D
1
4π
Z π
−π
|△G(ejω,θ)|2
γuu(ω)
|H(ejω,θ)|2 + |△H(ejω,θ)|2
|H(ejω,θ)|2 σ2
e,0 dω
(21.49)
where we have ignored σ2
e,0 because it does not participate in the minimization.
Some interesting remarks with respect to the ﬁt provided by PEM in the frequency domain follow:
1. When the true system is not contained in the model set, we know from Theorem 21.3 that the
estimated model is only the best approximation of the true system but not identical to it. Equation
(21.49) throws light on how the PEM methods “shape” the misﬁt or the error in frequency do-
main. Assume that the plant and noise models are independently parametrized, i.e., the parameter
vector can be partitioned as θ =
f
θG
θH
gT. Then,
θ⋆
G = arg min
θG ∈D
1
4π
Z π
−π
|△G(ejω,θG)|2
γuu(ω)
|H(ejω,θ⋆
H )|2
(21.50)
Thus,
The bias in the PEM ﬁt of FRF is shaped by W(ω) = γuu(ω)/|H(ejω,θ)|2.
2. The weighting function W(ω) = γuu(ω)/|H(ejω,θ)|2 can be termed as the input signal to model
noise ratio. This interpretation follows from the fact that |H(ejω,θ)|2 is a measure of the noise
power in the model. When a pre-ﬁlter is applied to the data, the weighting is
W(ω) = |L(ejω,θ)|2γuu(ω)/|H(ejω,θ)|2
(21.51)
3. From an identiﬁcation viewpoint, there are therefore three design factors, namely, (i) input spec-
trum, (ii) noise model and the (iii) pre-ﬁlter. The optimal values of these factors are usually de-
termined by trial and error. However, certain insights are helpful in understanding their inﬂuence
on the estimate, as discussed below.
4. From (21.50), it follows that for a given input-output data, the noise model determines the ﬁt
of FRF G(ejω). For example, consider the case where the input has white-noise like properties
γuu(ω) = 1. Then ﬁtting an OE model, i.e., H(.) = 1, produces a ﬁt with equal weights at all
frequencies.
5. Interpretations for model structures with common parametrizations (e.g., ARX models) are not
as straightforward for the independently parametrized case. However, the weighting function is
only known at the optimum. For example, in estimating an ARX model the PEM-QC method
would skew the ﬁt towards the frequency range determined by H−1(ejω,θG⋆) = A(ejω,θ⋆
G),
which usually has large magnitudes at high-frequencies. In other words, in ARX model estima-
tion, the usual emphasis is on FRF ﬁts at higher frequency ranges.
6. The foregoing point throws light on why OE models deliver good estimates of the plant model
despite ignoring the noise dynamics under open-loop conditions. Further, it oﬀers a new insight
into the role of the stochastic model in the identiﬁcation of deterministic models.
7. For a ﬁxed noise model, say H(q−1,θ) = H⋆(q−1), the bias is completely shaped by the input
spectrum. For colored inputs (non-ﬂat spectrum), the ﬁt is naturally good wherever the input
power is large. This makes sense since information about the system can be obtained only at
those frequencies where it has been excited.
8. The pre-ﬁlter can be chosen to nullify the eﬀects of the noise dynamics so as to shape the ﬁt
solely with the input spectrum, by setting L(q−1) = H⋆(q−1) where H⋆(q−1) is either a known
or an estimated noise model. This is the basis of Stieglitz-McBride algorithm for estimating OE
models by ﬁtting ARX structures on pre-ﬁltered data (see Algorithm 21.7).

Identiﬁcation of Parametric Input-Output Models
587
9. For an arbitrary non-linear and/or time-varying system, the expression developed in (21.50) does
not apply since the true system does not have a LTI description. However, a reference LTI system
that yields the optimal predictor-ﬁlter of the form (18.55) under the experimental conditions can
be used.
An example is provided below so as to illustrate the foregoing points.
Example 21.6: Frequency-Domain Approximations of PEM Estimates
Consider the following system
G(q−1) = q−2
0.3457 −0.2968q−1 + 0.03203q−2 −0.01249q−3
1 −2.029q−1 + 1.433q−2 −0.2371q−3 −0.09834q−4 ; H(q−1) = 1
(21.52)
where e[k] ∼GWN(0,0.05) and the input used is a PRBS with full-band spectrum, i.e.,
γuu(ω) ≈const., ∀ω.
Two diﬀerent model structures, but having identical orders for the deterministic portions,
(i) OE(2,2) model:
G(q−1) =
b2q−2 + b3q−3
1 + a1q−1 + a2q−2 ;
H(q−1) = 1;
(21.53)
(ii) ARX(2,2) model:
G(q−1) =
b2q−2 + b3q−3
1 + a1q−1 + a2q−2 ;
H(q−1) =
1
1 + a1q−1 + a2q−2
(21.54)
are ﬁt. In both models, there is no mis-speciﬁcation of the delay.
The FRFs of the resulting parametric plant model ﬁts are shown in Figure 21.1(a). The
OE(2,2) model achieves a good ﬁt over the entire frequency range excepting at very high
frequencies. This is due to the inability of the second-order model to correctly capture the
roll oﬀof the deterministic model. The ARX(2,2) model on the other hand fails to capture
10
−2
10
−1
10
0
10
1
10
−0.9
10
−0.7
10
−0.5
10
−0.3
10
−0.1
10
0.1
Frequency (rad/sec)
Magnitude
Comparison of parametric FRF fits by PEM
 
 
True
OE(2,2) fit
ARX(2,2) fit
(a) Fits achieved by PEM
10
−2
10
−1
10
0
10
1
10
−0.4
10
−0.2
10
0
10
0.2
Frequency (rad/sec)
Magnitude
Weighting function for OE(2,2) and ARX(2,2) fits
 
 
OE(2,2) Weights
ARX(2,2) Weights
(b) Weighting functions
FIGURE 21.1
FRF ﬁts and the weighting functions by PEM for two diﬀerent structures in Example 21.6.
the low-frequency characteristics and also misses out on the peak value. However, the ﬁt in
the high-frequency has much lower error. This is solely due to the reasons elucidated earlier.
PEM estimates of parametric models concentrate on frequency regions highlighted by the
input spectra and the inverse of noise model spectra.
For the ARX model and the input used in this case study, the weighting function is
1/|H(e−jω)|2 (since the input has WN characteristics) where H(ejω,θ⋆
H ) = 1 + a⋆
1 e−jω +
a⋆
2 e−jω. The weighting functions used by PEM for estimating the ARX and the OE models
are shown in Figure 21.1(b). It clearly explains the nature of misﬁts (or lack of) observed in
Figure 21.1(a).

588
Principles of System Identiﬁcation: Theory and Practice
Insights into noise model ﬁt
We conclude this subsection with an insight into the noise model ﬁt. Intuitively and by analogy with
the deterministic part, the PEM estimate of the noise model is expected to provide a weighted ﬁt
of the disturbance spectrum. It turns out that this is the fact when the plant and noise models are
independently parametrized.
Recalling that the disturbance is v[k] = y[k] −G(q−1,θ⋆
G)u[k], the spectral density of v[k] can
be expressed as (see Exercise E21.11)
γvv(ω) = |G0(ejω) −G(ejω,θ⋆
G)|2γuu(ω) + σ2
e0|H0(ejω)|2
(21.55)
only under open-loop conditions. From the spectral factorization result of Theorem 11.7 and the
quasi-stationarity assumption, we know that the disturbance spectrum can be factorized as
γvv(ω) = α|S(ejω)|2
(21.56)
where all three quantities γvv(ω), α and S(ejω) are dependent on the optimal plant model parame-
ters θ⋆
G.
Using the above expressions, the following result can be derived
θ⋆
H = arg min
θH
1
4π
Z π
−π
γεε(ω) dω
= arg min
θH
1
4π
Z π
−π

1
H(ejω,θH ) −
1
S(ejω,θ⋆
G)

2
γvv(ω,θ⋆
G) dω
(21.57)
Thus, the optimal estimate of noise model parameters amounts to ﬁtting a time-series model to the
disturbance (output-error) spectrum. Strictly speaking the inverse of the noise model is ﬁt to that of
the output-error spectrum.
Next we turn to the second question of errors in the estimates of parametric FRFs.
Covariance of FRF estimates
Expressions for covariance of parametrically estimated FRFs were provided by Ljung (1985b) for
the large sample and high-order systems. These results are generally useful in designing experi-
ments for identiﬁcation. Under open-loop conditions and high-order (n) systems, the covariance
expressions for the plant and noise FRFs, even when they have common parameters, are:
var( ˆGN (ejω, ˆθ)) ≈n
N
γvv(ω)
γuu(ω) ;
var( ˆHN (ejω, ˆθ)) ≈n
N |H0(ejω)|2
(21.58)
For a given model order, the error in plant FRF at each frequency is inversely proportional to the
SNR at that ω and the sample size N, whereas the error in noise FRF is inﬂuenced, not surprisingly,
solely the sample size N. These expressions oﬀer valuable guidance in input design. The reader is
referred to Ljung (1999) for derivations and insightful examples.
Running summary
Prediction-error methods contain in them several well-known estimation methods. Depending on
whether the “true” system is contained in the model set, the parameter estimates will converge to
the true values or the best approximation respectively under fairly relaxed assumptions. Under open-
loop conditions, the PEM-QC estimates the OE model such that the TF (FRF) estimate is shaped by
the input spectrum alone; whereas for non-OE models the FRF ﬁt is shaped by the model signal-to-
noise ratio γuu(.)/|H(.,θ)|2. From this viewpoint, ﬁtting an OE model therefore is perhaps the best
way of estimating the deterministic part of the process, under open-loop conditions.

Identiﬁcation of Parametric Input-Output Models
589
Under closed-loop conditions, PEM methods produce unbiased estimates of the FRF if and only
if the noise model has been “correctly” speciﬁed. Thus, OE models produce biased estimates under
closed-loop conditions. We shall elaborate on this point in §25.3.
With all the advantages of PEM methods highlighted until now, it is also time for reﬂecting on
some possible demerits of PEM methods.
Drawbacks of PEM methods
Despite their highly desirable properties, prediction-error methods suﬀer from the standard ills of
iterative numerical search algorithms, primarily (i) local minima traps and (ii) sensitivity to initial
guesses. These become even more pronounced when applied to multivariable identiﬁcation.
In order to minimize the pitfalls of numerical convergence and the sensitivity to initial guesses,
a standard recommendation is to use estimates obtained from subspace methods (Chapter 23) to
initialize PEM algorithms. A major advantage of the subspace methods is that they are non-iterative
in nature.
Notwithstanding the facts above, prediction-error methods are by far the best known and popular
methods for identiﬁcation from large samples owing to their attractive asymptotic properties. Fur-
thermore, they are also equipped to incorporate any constraints on model parameters, in general, for
grey-box modeling.
The complexity and gradients of the generic PEM-QC methods presented in this section depend
on the model structure in hand. In the following section, we shall discuss these aspects and also
take the opportunity to learn certain specialized algorithms for each model structure. They do not
necessarily enjoy the same optimality or convergence properties as the PEM methods, but certainly
oﬀer means of obtaining good starting models.
In passing, it is important to highlight the data pre-processing and delay estimation steps that are
necessary for obtaining satisfactory parametric models. The procedure is outlined below.
Algorithm 21.2
Common data pre-processing procedure for estimating models:
1. Carry out visual analysis of the data. Check for trends, outliers and anomalies. Process the data
appropriately to handle outliers and anomalies (if detected).
2. Partition data into training and test data sets. Call this Ztrain and Ztest, respectively.
3. Remove means (or drifts if necessary) from Ztrain. Subtract these means from Ztest.
4. Estimate I/O delay nk (in samples) using non-parametric analysis of training data.
Note: Visual inspection of trends, outliers and anomalies may be replaced by formal statistical
tests. In addition, data may be tested for non-linearities whenever necessary.
21.6
ALGORITHMS FOR ESTIMATING SPECIFIC PARAMETRIC MODELS
We begin with one of the simplest (in the sense of predictor expressions) model structures, namely,
the ARX model. From §18.3.2, it may be recalled that models of the ARX family are characterized
by linear predictors. Therefore, the PEM-QC estimator is also linear, producing unique estimates.

590
Principles of System Identiﬁcation: Theory and Practice
21.6.1
ESTIMATING ARX MODELS
From §17.5.1.1, the ARX model is characterized by:
θ =
f
a1
a2
· · ·
ana
bnk
· · ·
bn′
b
gT
ϕ[k] =
f
−y[k −1]
· · ·
−y[k −na]
u[k −nk]
· · ·
u[k −n′
b]
g
ˆy[k|k −1] = B(q−1)u[k] + (1 −A(q−1))y[k] = ϕT [k]θ
ε[k|k −1] = y[k] −ˆy[k|k −1]
Since the predictor is linear in parameters, gradients are independent of parameters and hence
PEM-QC specializes to OLS formulation. The computational burden is negligible and a global
minimum is obtained. Furthermore, ARX models oﬀer the luxury of being able to estimate models
of diﬀerent orders simultaneously (see §21.6.1.1). Notwithstanding these advantages, recall that
ARX models are suited to only a restrictive class of processes. A ﬂowchart illustrating the ARX
procedure is provided below.
Algorithm 21.3
LS method for estimating ARX models:
1. Prepare data and estimate I/O delay nk (samples) as outlined in Algorithm 21.2.
2. Guess polynomial orders na and nb using insights from non-parametric analysis.
3. Construct regressor matrix and measurement vector3
Φ =
f
−y[k −1]
· · ·
−y[k −na]
u[k −nk]
· · ·
u[k −n′
b]
g
;
y = {y[k]}
k = nk : (N −1)
where n′
b = nb + nk −1.
4. Obtain LS estimates of θARX (using QR factorization)
MATLAB: arx(Ztrain,[na nb nk])
5. Perform model diagnostic checks (residual analysis, estimation errors and cross-validation). If model
fails any of the tests, reﬁne model orders and repeat 3-4 until a satisfactory model is obtained.
Example 21.7: Fitting an ARX Model
A process with description:
y[k] = 0.6q−2 −0.2q−3
1 −0.5q−1
u[k] +
1
1 −0.5q−1 e[k]
(21.59)
is simulated with a N = 2055 samples long PRBS input containing frequencies in the range
[0,0.1]. The noise variance is set to 0.1.
An ARX model is developed from the resulting input-output data following the standard
identiﬁcation procedure. The IR estimates shown in Figure 21.2(a) are used for estimating
the input-output delay.
The estimated model is:
A(q−1) = 1 −0.5343
(±0.016)q−1; B(q−1) = 0.6158
(±0.01)q−2 −0.234
(±0.016)q−3;
ˆσ2
e = 0.0972
Residual analysis of this model shows that it has satisfactorily captured the predictable
portions of the data. Parameter estimates are signiﬁcant (standard errors are relatively very

Identiﬁcation of Parametric Input-Output Models
591
(a) Impulse response estimates
0
5
10
15
20
25
−0.5
0
0.5
1
Residual auto−correlation
Lag
ACF
−30
−20
−10
0
10
20
30
−0.1
0
0.1
Residual−input Cross−correlation
Lag
CCF
(b) Residual analysis plots
FIGURE 21.2
IR estimates and residual analysis plots for Example 21.7.
low). The estimated model agrees very well with the DGP and the noise variance estimate is
also close to that of the process.
Remarks:
i. The linear predictor of the ARX model oﬀers another advantage - models of diﬀerent orders can be esti-
mated simultaneously. An algorithm for this purpose is discussed below in §21.6.1.1. The loss functions
associated with each of these models are also estimated simultaneously. These results can be used to select
the “best” ARX model order suited for a given process. However, the selected model should be tested for
parameter reliability, i.e., errors in parameter estimates.
ii. When the equation errors in the data generating process, i.e., the errors w[k] in the expression of the output
y[k] = ϕT [k]θ + w[k]
are colored, from the properties of the OLS estimator in §14.3.3 we know that the resulting estimates are
biased (even asymptotically). As a result, the estimates are not consistent (but they converge). Example 14.4
numerically illustrates this fact in the context of a technique known as the instrumental variable method
that produces unbiased estimates of ARX models.
iii. A computationally eﬃcient and an exact recursive algorithm to update the model online, whenever required
(in identiﬁcation of linear time-varying systems, for example,) can be developed. See §25.1.3 for related
details.
21.6.1.1
AUDI: Estimating Several ARX Models Simultaneously
The linear predictor of the ARX model lends itself to an elegant algorithm for simultaneous esti-
mation of ARX model structures of orders 1 to P. Proposed by Niu, Fisher and Xiao (1992) and
Niu, Xiao and Fisher (1990), it is known as the Augmented UD Identiﬁcation (AUDI) algorithm.
The key idea is to construct an augmented regressor matrix Φa as shown below followed by what is
known as a UDUT factorization of (ΦT
a Φa)−1.
1. Construct an augmented regressor matrix Φa
Φa[N] =
f
ϕ[0]
ϕ[1]
· · ·
ϕ[N −1]
gT
ϕ[k] =
f
−y[k −P]
u[k −P]
· · ·
−y[k −1]
u[k −1]
−y[k]
gT
3Most software packages index the ﬁrst element as one. Then k would run from nk + 1 to N.

592
Principles of System Identiﬁcation: Theory and Practice
Listing 21.1
Sample code to estimate an ARX model
% Create the plant and noise model objects
proc_arx = idpoly([1 -0.5],[0 0 0.6 -0.2],1,1,1,’Noisevariance’,0.05);
% Create input sequence
uk = idinput(2555,’prbs’,[0 0.2],[-1 1]);
% Simulate the process
yk = sim(proc_arx ,uk,simOptions(’Addnoise’,true));
% Build iddata objects and remove means
z = iddata(yk,uk,1); zd = detrend(z,0);
% Compute IR for time-delay estimation
mod_fir = impulseest(zd);
figure; impulseplot(mod_fir ,’sd’,3)
% Time-delay = 2 samples
% Estimate ARX model (assume known orders )
na = 1; nb = 2; nk = 2;
mod_arx = arx(zd,[na nb nk])
% Check the residual plot
figure ; resid(zd, mod_arx);
% Analyze model errors
present(mod_arx)
Observe the inclusion of the y[k] term in the regressor vector ϕ[k] and that Φa is a (N −1) ×
(2P + 1) matrix.
2. Perform a UDUT factorization of the Augmented Information Matrix (AIM) CP[N] =
(ΦT
a [N]Φa[N])−1
CP[N] = UP[N]DP[N]UT
P[N]
The factor U is a (2P + 1) × (2P + 1) upper triangular matrix with 1’s on the principal diagonal.
The elements of every alternate column above the principal diagonal, starting from the third column,
i.e., U[1 : 2i,2i + 1], i = 1,· · · ,P contains the parameter estimates of the ith order ARX model.
Speciﬁcally,
ˆθi[N −P + i] = U[1 : 2i,2i + 1]
θi =
f
a1
b1
· · ·
ai
bi
gT ,
i = 1,· · · ,P
On the other hand, the matrix D is a (2P + 1) × (2P + 1) diagonal matrix containing the values of
the loss function associated with ARX models from orders 1 to P.
J ( ˆθi[N −P + i]) = 1/d j j
Note: The notation ˆθi[M] stands for the estimate of θ for the ith order ARX model using M samples.
A recursive version of the AUDI algorithm is available due to Niu, Fisher and Xiao (1992). It is
usually considered to have better numerical performance than the RLS algorithm due to the use of
UDUT factorization (see Bierman (2006) and Ljung and Ljung (1985)).
Remarks:
1. The role of AUDI or similar algorithms is in only computing models of varying orders simultaneously.
Selection of the “best” model still follows the general guidelines given previously.
2. It is not possible to have a similar algorithm for simultaneous estimation of non-ARX structures since a
NLS algorithm is involved.
We next study the estimation of ARMAX models.

Identiﬁcation of Parametric Input-Output Models
593
21.6.2
ESTIMATING ARMAX MODELS
From §17.5.1.2, the ARMAX model is characterized by:
θ =
f
a1
a2
· · ·
ana
b1
· · ·
bnb
c1
· · ·
cnc
gT
ϕ(k,θ) =
f
−y[k −1]
· · ·
−y[k −na]
· · ·
u[k −nk]
· · ·
u[k −n′
b]
· · ·
ε[k −1,θ]
· · ·
ε[k −nc,θ]
gT
ˆy[k] = ϕT (k,θ)θ
ε(k,θ) = y[k] −ˆy(k|θ)
The predictor is non-linear in parameters. Therefore, PEM-QC specializes to a NLS formulation,
resulting in locally optimal estimates. Evidently, it is computationally more demanding than esti-
mation of ARX models. A beneﬁt is, however, that ARMAX models are suited to a wider class of
processes than their ARX counterparts.
Gradient computations for ARMAX model
In solving the non-linear optimization problem resulting from PEM, recall that gradient (of the
objective function) computations are required at each iteration. These gradients in turn call for gra-
dients of the predictors, ψ[k]. For parametric model structures, we can derive analytical expressions
for these gradients. Below we illustrate the derivation for an ARMAX(1,1,1) model.
Example 21.8: Gradients for an ARMAX(1,1,1) Model
In the estimation of ARMAX(1,1,1) model
y[k] = −a1y[k −1] + b1u[k −1] + e[k] + c1e[k −1]
the parameters of interest are θ =
f
a1
b1
c1
gT .
The one-step ahead predictor for this model is (recall Chapter 18)
ˆy[k|θ] = −a1y[k −1] + b1u[k −1] + c1e[k −1]
The regression problem is non-linear since e[k −1] is unknown and is implicitly a function of
θ.
In order to obtain the gradients of the predictor w.r.t. parameters, we need to know the
dependence of e[k] on θ. This is implicitly evaluated by replacing it with the theoretical
deﬁnition
e[k] = y[k] −ˆy[k|k −1]
=⇒(1 + c1q−1) ˆy[k] = (c1 −a1)y[k −1] + b1u[k −1]
(21.60)
Now diﬀerentiate both sides w.r.t. each of the parameters to obtain the required gradients
∂ˆy
∂a1
= −
1
1 + c1q−1 y[k −1];
∂ˆy
∂b1
=
1
1 + c1q−1 u[k −1]; ∂ˆy
∂c1
=
1
1 + c1q−1 ε[k −1]
(21.61)
where we have replaced the theoretical innovations e[k] with the one-step prediction errors
ε[k].
Given initial guess of θ, the gradient for updating the parameter estimates is thus obtained
by ﬁltering the regressor with 1/C(q−1). This procedure is repeated at each iteration using
the regressor and parameter at that stage.

594
Principles of System Identiﬁcation: Theory and Practice
From the foregoing example, it is easy to show that for the general case the predictor gradients of
an ARMAX model at the ith iteration can be written as (see Exercise E21.9)
ψ(i)[k] = ∂ˆy
∂θ
θ= ˆθ(i) =
1
C(i)(q−1) ϕ(i)[k]
(21.62)
The quantity ϕ(i)[k] is the vector of regressors at the ith iteration,
ϕ(i)[k] =
f
−y[k −1]
· · ·
−y[k −na]
u[k −1]
· · ·
u[k −n′
b]
ε(i)[k −1]
· · ·
ε(i)[k −nc]
gT
(21.63)
where n′
b = nb + nk −1.
The foregoing example is in fact an extension of Example 19.4 studied earlier in the context of
estimating ARMA models using NLS methods. It is instructive to compare the gradient vector in
(21.62) with that for the ARX structure and connect it with the viewpoint of ARMAX models as
ARX models on pre-ﬁltered data (as shown in §17.5.1.3).
A general procedure to estimate ARMAX models is outlined below.
Algorithm 21.4
NLS method for estimating ARMAX models:
1. Prepare data and estimate I/O delay nk (samples) as outlined in Algorithm 21.2.
2. Guess polynomial orders na, nb and nc using insights from non-parametric analysis.
3. Provide initial estimates of polynomial coeﬃcients (see §22.6.2). Set iteration count i = 1.
4. Construct regression vector as in (21.63) using residuals from the initial model.
5. Solve the PEM-QC optimization problem using methods of §14.4.1 (typically G-N method) until
convergence. Use (21.62) and (21.63) to compute necessary gradients and update the regression
vector.
MATLAB: armax(Ztrain,[na nb nc nk]) OR armax(Ztrain,initsys)
6. Perform model diagnostic checks (residual analysis, estimation errors and cross-validation). If model
fails any of the tests, reﬁne model orders and repeat steps 3-5 until a satisfactory model is obtained.
Now we turn to an illustrative example of ﬁtting ARMAX model using MATLAB.
Example 21.9: Fitting an ARMAX Model
The ARX data generating process of Example 21.7 is modiﬁed to include a moving average
component in the stochastic part:
y[k] = 0.6q−2 −0.2q−3
1 −0.5q−1
u[k] + 1 −0.3q−1
1 −0.5q−1 e[k]
(21.64)
As was done earlier, it is simulated with a N = 2055 samples long PRBS input containing
frequencies in the range [0,0.1]. The noise variance is set to 0.1.
The resulting input-output data is mean-centered, subject to delay estimation (using the
IR estimates shown in Figure 21.3(a)), followed by the identiﬁcation of a suitable ARMAX
model. Using the procedure outlined in Algorithm 21.4, we obtain the following estimate:
A(q−1) = 1 −0.4875
(±0.038)q−1; B(q−1) = 0.5937
(±0.01)q−2 −0.1824
(±0.032)q−3;
C(q−1) = 1 −0.2961
(±0.044)q−1;
ˆσ2
e = 0.0986

Identiﬁcation of Parametric Input-Output Models
595
(a) Impulse response estimates
0
5
10
15
20
25
−0.5
0
0.5
1
Residual auto−correlation
Lag
ACF
−30
−20
−10
0
10
20
30
−0.1
0
0.1
Residual−input Cross−correlation
Lag
CCF
(b) Residual ACF and residual-input CCF
FIGURE 21.3
IR estimates and the residual analysis plots for Example 21.9.
Once again the residual analysis, i.e., correlation plots, displayed in Figure 21.3(b), show
that the model has satisfactorily captured the predictable portions of the data. Parameter
estimates are signiﬁcant (standard errors are relatively very low). Estimates agree very well
with the values used in simulation.
Listing 21.2
Sample code to estimate an ARMAX model
% Create the plant and noise model objects
p_armax = idpoly([1 -0.5],[0 0 0.6 -0.2],[1 -0.3],1,1,’Noisevariance’,0.1);
% Create input sequence
uk = idinput(2555,’prbs’,[0 0.2],[-1 1]);
% Simulate the process
yk = sim(p_armax ,uk,simOptions(’Addnoise’,true));
% Build iddata objects and remove means
ZN = iddata(yk,uk,1); Ztrain = detrend(ZN,0);
% Compute IR for time-delay estimation
mod_fir = impulseest(Ztrain);
figure; impulseplot(mod_fir ,’sd’,3);
% Time-delay = 2 samples
% Estimate ARMAX model
na = 1; nb = 2; nc = 1; nk = 2;
mod_armax = armax(Ztrain ,[na nb nc nk])
% Check the residual plot
figure ; resid(Ztrain, mod_armax);
% Analyze the model
present(mod_armax)
Apart from PEM methods, there exist other ways for estimating ARMAX models. Two popular
methods being (i) the pseudo-linear regression method (recall §14.4.2.3) and (ii) the multi-stage
instrumental variable (IV4) approach. The latter approach is presented in §21.7.1. The following
section presents the PLR method.

596
Principles of System Identiﬁcation: Theory and Practice
21.6.2.1
Pseudo-Linear Regression Method for ARMAX
The algorithm relies on the pseudo-linear regression (PLR) form of the ARMAX model (17.44)
ϕ(k,θ) =
f
−y[k −1]
· · ·
−y[k −na]
u[k −nk]
· · ·
u[k −n′
b]
ε[k −1,θ]
· · ·
ε[k −nc,θ]
gT
ˆy[k] = ϕT (k,θ)θ
(21.65a)
(21.65b)
The regressor in (21.65b) is an implicit function of θ, preventing us from using linear LS methods.
However, recall from §14.4.2.3 that non-linear problems of this type can be handled by the pseudo-
linear regression (PLR) approach. The methodology also consists of an iterative approach like the
NLS method, but involves a linear regression at each iteration. Therefore, it enjoys computational
superiority over the PEM methods.
A model that aids in setting up the regressor (21.65b) in the ﬁrst iteration is required to trigger the
algorithm. The algorithm therefore consists of the following iterations:
ϕ(i+1)[k] =
f
−y[k −1]
· · ·
−y[k −na]
u[k −nk]
· · ·
u[k −n′
b]
ε(i)[k −1,θ(i)]
· · ·
ε(i)[k −nc,θ(i)]
gT
ˆy[k] = ϕ(i+1)[k]θ(i+1)
(21.66a)
(21.66b)
Equation (21.66b) resembles the prediction expression from a standard linear regression. Therefore
θ(i+1) can be estimated using a LS method. At i = 0, the prediction error is supplied by model
that can be estimated in a non-iterative manner (such as the ARX or a subspace model). A standard
approach is to use the prediction errors from an optimal (high-order) ARX model.
Algorithm 21.5
PLR method for ARMAX model estimation:
1. Estimate an ARX model (M0) of suitably high-order.
2. At the ﬁrst iteration i = 0, generate prediction errors using the model M0 to construct ϕ(i+1)[k] in
(21.66a).
3. Obtain LS estimates of θ(i+1)
ARMAX using the regression form in (21.66b).
4. Compute the prediction errors and update the regression vector in (21.66a) using θ(i+1).
5. Repeat steps 3-4 until convergence.
MATLAB: rplr
Remarks:
i. The PLR method described above for ARMAX model estimation is also known as the extended least
squares method (Yeredor, 2000).
ii. The MATLAB routine rplr implements a recursive version of Algorithm 21.5, which incrementally up-
dates the parameter vector as and when a new sample arrives (see §25.1.2). This is the widely practiced and
studied version of the PLR algorithm. Section 25.1.4 provides details on the RPLR scheme.
Convergence properties of (R)PLR (for ARMAX structures) are studied in Soderstrom and Stoica
(1994, Chapter 9) and Ljung (1999, Chapter 11). The convergence depends on the real part of
1/C0(ejω) where C0(ejω) is the true moving average polynomial of the system description. There
exist situations where the algorithm does not converge. In this respect, the PLR method fares low
against the PEM methods.
We now turn to the study of estimating output-error models.

Identiﬁcation of Parametric Input-Output Models
597
21.6.3
ESTIMATING OE MODELS
The OE model, recall from §17.5.2, is characterized by:
θ =
f
bnk
· · ·
bn′
b
f1
· · ·
fn f
gT
ϕOE(k,θ) =
f
u[k −nk]
· · ·
u[k −n′
b]
−ξ(k −1,θ)
· · ·
−ξ(k −nf ,θ)
gT
ξ[k] = ˆy[k] = −
n f
X
i=1
fiξ[k −i] +
n′
b
X
l=nk
blu[k −l]
ˆy(k|θ) = ϕT (k,θ)θ
The OE model is a special case of the ARMAX model with C(q−1) = A(q−1). Therefore most of
the discussion for ARMAX models applies in a straightforward way to the OE structure as well.
The predictor is non-linear in parameters resulting in a NLS criterion for the PEM-QC method. The
predictor gradients are computed in a manner similar to that of ARMAX models. Following the
procedure of Example 21.8, it is straightforward to derive a general expression as in (21.62)
ψOE[k] =
1
F(q−1) ϕOE[k]
(21.67)
where the regression vector ϕ[k] is as noted above. The algorithm is therefore on the same lines as
that for the ARMAX model.
First deﬁne
ϕ(i)[k] =
f
u[k −nk]
· · ·
u[k −n′
b]
−ξ(i)[k −1]
· · ·
−ξ(i)[k −nf ]
gT
(21.68)
where n′
b = nb + nk −1.
Algorithm 21.6
NLS method for estimating OE models:
1. Prepare data and estimate I/O delay nk (samples) as outlined in Algorithm 21.2.
2. Guess polynomial orders nb and nf using insights from non-parametric analysis.
3. Provide initial estimates of polynomial coeﬃcients (see §22.6.2). Set iteration count i = 0.
4. Construct regression vector as in (21.68) using predictions from the initial plant model.
5. Solve the PEM-QC optimization problem using methods of §14.4.1 (typically G-N method) until
convergence. Use (21.67) and (21.68) to compute necessary gradients and update the regression
vector.
MATLAB: oe(Ztrain,[nb nf nk]) OR oe(Ztrain,initsys)
6. Perform model diagnostic checks (residual analysis, estimation errors and cross-validation). If model
fails any of the tests, reﬁne model orders and repeat steps 3-5 until a satisfactory model is obtained.
An illustrative example in MATLAB follows.
Example 21.10: Fitting an OE Model in MATLAB
Consider the deterministic process of Example 21.7 with a white-noise output error:
y[k] = 0.6q−2 −0.2q−3
1 −0.5q−1
u[k] + e[k]
(21.69)

598
Principles of System Identiﬁcation: Theory and Practice
Listing 21.3
Sample code to estimate an OE model
% Create the plant and noise model objects
p_oe = idpoly(1,[0 0 0.6 -0.2],1,1,[1 -0.5],’Noisevariance’,0.1);
% Create input sequence
uk = idinput(2555,’prbs’,[0 0.2],[-1 1]);
% Simulate the process
yk = sim(p_oe,uk,simOptions(’Addnoise’,true));
% Build iddata objects and remove means
ZN = iddata(yk,uk,1); Ztrain = detrend(ZN,0);
% Compute IR for time-delay estimation
mod_fir = impulseest(Ztrain);
figure; impulseplot(mod_fir ,’sd’,3);
% Time-delay = 2 samples
% Estimate OE model
nb = 2; nf = 1; nk = 2;
mod_oe = oe(Ztrain ,[nb nf nk])
% Check the residual plot
figure ; resid(Ztrain, mod_oe);
% Analyze the model
present(mod_oe)
This process is simulated with a N = 2055 samples long PRBS input containing frequencies
in the range [0,0.1]. The noise variance is set to 0.1.
Following the procedure outlined in Algorithm 21.6, we obtain the following estimate:
B(q−1) = 0.6126
(±0.01)q−2 −0.2087
(±0.038)q−3;
F(q−1) = 1 −0.4985
(±0.042)q−1;
ˆσ2
e = 0.0973
(a) Impulse response estimates
0
5
10
15
20
25
−0.5
0
0.5
1
Residual auto−correlation
Lag
ACF
−30
−20
−10
0
10
20
30
−0.1
0
0.1
Residual−input Cross−correlation
Lag
CCF
(b) Residual ACF and residual-input CCF
FIGURE 21.4
IR estimates (for delay estimation) and the residual analysis plots for Example 21.10.
Both necessary model diagnostics, namely, residual analysis (shown in Figure 21.4) and
errors in parameter estimates point to a satisfactory model.
As an illustration of the theoretical result in Theorem 21.2, we show that ﬁtting an OE model
to the ARX process of Example 21.7 (when the plant structure is speciﬁed correctly) results in an
unbiased estimate of the plant model despite the mismatch in the noise dynamics.

Identiﬁcation of Parametric Input-Output Models
599
Example 21.11: Fitting an OE Model to an ARX Process
For the system of Example 21.7, N = 2046 samples of input-output data is generated using a
PRBS input in the frequency range [0, 0.2].
0
5
10
15
20
25
−0.5
0
0.5
1
Residual auto−correlation
Lag
ACF
−30
−20
−10
0
10
20
30
−0.1
0
0.1
Residual−input Cross−correlation
Lag
CCF
FIGURE 21.5
Residual analysis plots for the model estimated in Example 21.11.
An OE(2,1) model results from implementing the procedure outlined in Algorithm 21.6.
The CCF and ACF plots in Figure 21.5 suggest that the deterministic model is satisfactory
while, expectedly, the noise model is inadequate.
The estimate of the OE(2,1) model is as follows:
B(q−1) = 0.6087
(±0.01)q−2 −0.1891
(±0.041)q−3;
F(q−1) = 1 −0.4855
(±0.058)q−1;
ˆσ2
e = 0.1349
where the estimate of innovations variance is naturally incorrect due to mis-speciﬁcation in
the noise model.
A time-series model (an AR/MA/ARMA) can be ﬁt to the residuals, following which a BJ
model may be ﬁt using the plant and noise models as initial estimates.
As with ARMAX models, alternative estimation schema exist. Among these four methods merit
attention. These are based on the concepts of (i) pseudo-linear regression, (ii) viewing OE structures
as ARX models on pre-ﬁltered data (Stieglitz-McBride method), (iii) the weighted least-squares and
the (iv) instrumental variables, respectively. The ﬁrst among these follows similar lines as that for
the ARMAX model (see Exercise E21.13), while the fourth method becomes clear with a study of
the instrumental variables in §21.7.1. The remaining two methods are described below.
21.6.3.1
Stieglitz-McBride Algorithm
The algorithm is based on the fact that the OE model is an ARX model on ﬁltered data. Recall from
§17.5.2 that the OE model may also be expressed as,
y f [k]
z         }|         {
1
F(q−1) y[k] = B(q−1)
F(q−1)
*.....
,
u f [k]
z         }|         {
1
F(q−1)u[k]
+/////
-
+
1
F(q−1) e[k]
yf [k] = B(q−1)
F(q−1)uf [k] +
1
F(q−1) e[k]
This observation naturally gives rise to an elegant algorithm for estimating B(q−1) and F(q−1) as
originally proposed by Steiglitz and McBride (1965).

600
Principles of System Identiﬁcation: Theory and Practice
Algorithm 21.7
Stieglitz-McBride algorithm:
1. Prepare data and estimate I/O delay nk (samples) as outlined in Algorithm 21.2.
2. Guess polynomial orders nb and nf using insights from non-parametric analysis.
3. At iteration i = 0, estimate an ARX model with orders na = nf , nb and delay nk.
4. Filter input and output with 1/A(i)(q−1) to obtain u(i)
f [k] and y(i)
f [k].
5. Estimate the ARX model with ﬁltered data to obtain updated models. Increment iteration to i + 1.
6. Repeat steps 4-5 until convergence.
Convergence properties of the Stieglitz-McBride (STMB) algorithm were studied in Stoica and
Soderstrom (1981). Global convergence is guaranteed only if v[k] is white. When this holds, fur-
ther, the estimates are asymptotically Gaussian distributed. Nevertheless, in practice, the STMB
algorithm can produce good initial estimates for the PEM method.
WLS approach to estimating OE models
The idea underlying this approach is fairly straightforward. The following example serves to illus-
trate the method.
Example 21.12: Estimating an OE(1,1) Model Using WLS
Consider the estimation of OE(1,1) model:
y[k] =
b1q−1
1 + f1q−1 u[k] + e[k]
(21.70a)
The diﬀerence equation form of the model is:
y[k] = −f1y[k −1] + b1u[k −1] + e[k] + f1e[k −1]
(21.70b)
Essentially, we have a linear regression equation with colored equation error w[k] = e[k] +
f1e[k −1], which is also correlated with one of the regressors y[k −1]. Thus, a WLS method
is ideally suited for estimating the parameters b1 and f1. From §14.3.5 we know that the
optimal weighting matrix is the inverse of Σww where w is the N × 1 vector of errors:
Σww =

σ2w
σww[1]
σww[2]
· · ·
σww[N −1]
σww[1]
σww[0]
σww[1]
· · ·
σww[N −1]
...
...
...
...
...
σww[N −2]
· · ·
σww[1]
σww[0]
σww[1]
σww[N −1]
· · ·
· · ·
σww[1]
σww[0]

=

(1 + f 2
1 )
f1
0
· · ·
0
f1
(1 + f 2
1 )
f1
· · ·
0
...
...
...
...
...
0
· · ·
f1
(1 + f 2
1 )
f1
0
0
· · ·
f1
(1 + f 2
1 )

σ2
e
However, this matrix cannot be known a priori since both f1 and σ2e are unknown. To
overcome this impediment, we adopt an iterative approach.
First obtain LS estimates of b1, f1 and σ2e (ﬁt an ARX model using OLS). Next, construct
an initial estimate of Σww to compute the WLS estimates of b1 and f1 using (14.91). From
this step, reﬁne the estimate of Σww. Now iterate between these two steps until convergence.

Identiﬁcation of Parametric Input-Output Models
601
Based on the foregoing example, we are now in a position to provide the recipe for a general
iterative weighted least squares (IWLS) algorithm.
Algorithm 21.8
IWLS (Generalized LS) Algorithm for estimating OE models
1. Prepare data and estimate I/O delay nk (samples) as outlined in Algorithm 21.2.
2. Guess polynomial orders nb and nf using insights from non-parametric analysis.
3. At iteration i = 0, estimate an ARX model with orders na = nf , nb and delay nk. Also compute σ2,i
e .
4. Construct an estimate of the noise covariance matrix Σ(i)
ww using the fact that w[k] = (1 + f (i)
1 q−1 +
· · · + f (i)
n f q−n f )e[k].
5. Compute WLS estimates of the ARX model parameters with Wopt = Σ−1
ww and (14.91). Increment
iteration to i + 1.
6. Repeat steps 4-5 until convergence.
Theoretical studies on the convergence properties of the above algorithm have been studied in
numerous regression problems. This method, known as the iteratively re-weighted least squares, is
theoretically equivalent to the MLE estimator with a Gaussian distribution. From a computational
viewpoint, at each stage of this algorithm, inversion of a sparse tridiagonal matrix is involved. There-
fore, for large data, the computational burden could be potentially higher than a regular PEM-QC
algorithm.
We now turn to the last class of models in this category.
21.6.4
ESTIMATING BJ MODELS
From §17.5.3, it may be recalled that the BJ model is characterized by
θ =
f
bnk
· · ·
bn′
b
c1
· · ·
cnc
d1
· · ·
dnd
f1
· · ·
fn f
gT
ˆy[k|θ] = D(q)B(q)
C(q)F(q) u[k] +
 
1 −D(q)
C(q)
!
y[k]
ε[k|k −1] = y[k] −ˆy[k|k −1]
The PEM-QC criterion results in an NLS formulation evidently since the predictor is non-linear
in parameters. Gradient (of the predictor) expressions can be derived in a similar manner as for the
ARMAX model. A pseudo-linear regression form of the predictor was provided in §17.5.3, but is
not ideally congenial for estimation. BJ models are capable of modeling a broad class of processes,
however, at the cost of more computation eﬀort and inputs from the user. Gradient computations
once again follow similar lines as in the previous model structures (see Exercise E21.14).
A good way of initializing the BJ model is through a two-stage approach (OE modeling followed
by a time-series model of the residuals) or a subspace method (see §22.6.2 and the case study).
A general procedure for estimating BJ models using the PEM-QC method is outlined below.
Algorithm 21.9
NLS method for estimating BJ models
1. Prepare data and estimate I/O delay nk (samples) as outlined in Algorithm 21.2.
2. Obtain initial estimates of the plant and noise models (say using the OE-plus-time-series or the
subspace identiﬁcation method).

602
Principles of System Identiﬁcation: Theory and Practice
3. Specify orders nb, nf , nc and nd (based on the initial model).
4. Set iteration count i = 0. Compute gradients using the initial model.
5. Solve the PEM-QC optimization problem using methods of §14.4.1 (typically G-N method) until
convergence. At each iteration, increment i by one and update the gradients.
MATLAB: bj(Ztrain,[nb nc nd nf nk]) OR bj(Ztrain,initsys)
6. Perform model diagnostic checks (residual analysis, estimation errors and cross-validation). If the
model fails any of the tests, reﬁne model orders and repeat steps 4-5 until a satisfactory model is
obtained.
A MATLAB-based illustration of estimating a BJ model follows.
Example 21.13: A MATLAB Example
A system possessing a BJ description
y[k] = 0.6q−2 −0.2q−3
1 −0.5q−1
u[k] + 1 + 0.2q−1
1 −0.3q−1 e[k]
(21.71)
is excited by a N = 2046 samples long PRBS input containing frequencies in the range [0,0.2].
The noise variance is set to 0.1.
Following the procedure outlined in Algorithm 21.9, we converge to a BJ(2,1,1,1) model,
whose residual correlation plots are shown in Figure 21.6.
(a) Impulse response estimates
−30
−20
−10
0
10
20
30
−0.1
−0.05
0
0.05
0.1
CCF btween residuals and input
lag
CCF
0
5
10
15
20
25
−0.5
0
0.5
1
Residual analysis plots for the BJ(2,1,1,1) model 
ACF
(b) Residual ACF and residual-input CCF
FIGURE 21.6
IR estimates (for delay estimation) and residual analysis plots for Example 21.13.
The respective correlations clearly point to a satisfactory model. The estimates of the
coeﬃcients given below
B(q−1) = 0.5873
(±0.009)q−2 −0.1884
(±0.04)q−3
C(q−1) = 1 + 0.2551
(±0.045)q−1
D(q−1) = 1 −0.256
(±0.045)q−1
F(q−1) = 1 −0.4788
(±0.06)q−1
further conﬁrm the reliability of the model. Thus, a BJ(2,1,1,1) model is deemed acceptable
for the process, which is also incidentally of the same structure and order.
Listing 21.4
MATLAB script for Example 21.13
% Create the plant and noise model objects
p_bj = idpoly(1,[0 0 0.6 -0.2],[1 0.2],[1 -0.4],[1 -0.5],’Noisevariance’,0.1);

Identiﬁcation of Parametric Input-Output Models
603
% Create input sequence
uk = idinput(2046,’prbs’,[0 0.4],[-1 1]);
% Simulate the process
yk = sim(p_bj,uk,simOptions(’Addnoise’,true));
% Build iddata objects and remove means
Zk = iddata(yk,uk,1); Ztrain = detrend(z,0);
% Compute IR for time-delay estimation
mod_fir = impulseest(Ztrain);
figure; impulseplot(mod_fir ,’sd’,3);
% Time-delay = 2 samples
% Estimate BJ model (assume known orders )
nb = 2; nc = 1; nd = 1; nf = 1; nk = 2;
mod_bj = bj(zd,[nb nc nd nf nk])
% Present the model
present(mod_bj)
% Check the residual plot
figure ; resid(Ztrain, mod_bj);
With this example, the discussion on the theory and illustration of PEM methods for estimating
parametric models comes to a close. Although we have primarily focused on the quadratic criterion,
the main results, especially Theorem 21.3, apply to the case of other norms of prediction errors (or
their functions) as well (provided some important criteria are met). For a more detailed and rigorous
theoretical treatment of these aspects, read Ljung (1999). Another point that merits attention is the
fact that we have only discussed the unconstrained (parameter) version of the PEM formulation.
Constraints on parameters are, on the other hand, not uncommon (for example, bounds on parame-
ters). Then, the optimization problem has to be solved in presence of such constraints and naturally
the complexity of the associated algorithm is higher than the unconstrained case.
The next and ﬁnal topic of presentation is, as mentioned earlier in §21.1, on an alternative class
of techniques based on correlation methods (analogous to generalized method of moments).
21.7
CORRELATION METHODS
The principal concepts governing the correlation methods are those that govern the MoM and
its generalized versions (recall §14.2). The requisite moment condition is natural - the residuals
should be uncorrelated with past data. As usual, we replace the theoretical moments with their
sample versions.
Let z[k −l] =
f
y[k −l]
u[k −l]
gT denote the vector of data at the (k −l)th instant. Then the
basic correlation estimate is obtained as
ˆθN = sol
θ

1
N
N−1
X
k=l
z[k −l]ε(k,θ) = 0
∀l 1 ≤l ≤(N −1)

(21.72)
The number of lags involved in the computation of correlation depends on the model in hand, specif-
ically the size of θ. Recall Example 14.1 and the preceding theoretical discussion of an application
of (21.72) to the parameter estimation of an ARX(1,1) model. From §14.2 and §14.3 recall that the
LS method also leads to (21.72). As a natural extension of this point, the (unconstrained) PEM-QC
formulation also belongs to the family of correlation methods.
Generalizing the above idea to requiring zero correlation between functions of past data ζ[k] =
f (Zk−1), where Zk−1 denotes the past data up to (k −1), and functions h(.) of ﬁltered prediction

604
Principles of System Identiﬁcation: Theory and Practice
errors, one obtains the generalized correlation estimate of θ as given below (Ljung, 1999).
ˆθN = sol
θ

1
N
N−1
X
k=0
ζ(k,θ)h(ε f (k,θ)) = 0

(21.73)
where ε f [k] is the ﬁltered prediction error and ζ(.) has been allowed to be a function of θ to indicate
its dependence on the model as well (for example, it may consist of past prediction errors).
The variable ζ is generally chosen as a p×1 vector to arrive at p independent equations. However,
as in the GMM, this is not mandatory. One can set up more equations than parameters and solve a
minimization problem instead as in (14.13).
ˆθN = arg min
θ

1
N
N−1
X
k=0
ζζζ(k,θ)h(ε f (k,θ))
W
(21.74)
where ||.||W is norm weighted in the sense of a weighting matrix W.
Correlation estimator specializes to a few previously studied estimators, namely the pseudo-linear
regression and PEM-QC methods depending on the choice of ζ and the pre-ﬁlter. For instance,
choosing ζζζ(k,θ) = ψ(k,θ) (gradient of ˆy(k,θ)) and h(ε) = ε results in the PEM-QC estimate.
One of the most widely studied and used correlation-based method is the instrumental variable
method that is designed to produce consistent estimates of linear regression in presence of errors
that are correlated with regressors. Recall that OLS produces inconsistent or biased estimates under
these conditions. The following section describes this method in detail.
21.7.1
INSTRUMENTAL VARIABLE (IV) METHODS
As remarked above, the primary motivation for IV estimator is the fact that the LS method results
in biased estimates of θ for systems described by linear regression
y[k] = ϕT (k)θ + v[k]
whenever the equation errors v[k] and ϕ[k] are correlated. The following example illustrates this
fact. It is also a numerical illustration of Example 14.4, which theoretically demonstrated that when
ARX models are ﬁt to data generated by ARMAX processes (with the same functional form), biased
estimates result.
Example 21.14: Bias in LS Estimates of ARX Models
Consider data from two diﬀerent processes, both having the same functional form, but
corrupted by diﬀerent types of equation error.
y1[k] = 0.5y1[k −1] + 1.4u[k −1] + e[k] + 0.6e[k −1]
(Correlated error)
y2[k] = 0.5y2[k −1] + 1.4u[k −1] + e[k]
(Uncorrelated error)
The input used in Example 14.5 is applied to generate N = 510 samples.
To each data set, suppose that the user ﬁts a ﬁrst-order ARX model
y[k] = −a1y[k −1] + b1u[k −1] + e[k]
(21.75)
using the LS method, where for the purpose of illustration we have assumed that the delay
and order are known.
Then, according to the discussion in Example 14.4, the estimates of a1 and b1 should be
biased for the ﬁrst process and unbiased for the second. In order to demonstrate this fact

Identiﬁcation of Parametric Input-Output Models
605
−0.6
−0.5
−0.4
0
50
100
Estimate of a1
Count
1.2
1.4
1.6
0
20
40
60
80
Estimate of b1
Count
−0.6
−0.5
−0.4
0
50
100
150
Estimate of a1
Count
1.2
1.4
1.6
0
50
100
Estimate of b1
Count
ARMAX process
ARX process
ARX process
ARMAX process
FIGURE 21.7
Bias (and its absence) in the OLS estimates of an ARX model of Example 21.14.
numerically, Nr = 400 realizations of data sets are generated and ARX models are estimated
from each data set using the OLS algorithm. Histograms of the parameter estimates ˆa1 and
ˆb1 from these models are shown in Figure 21.7.
The mean values of each of these parameters, calculated as the average across realizations
are
E( ˆa(1)
1 ) ≈−0.5520
E(ˆb(1)
1 ) ≈1.3640
E( ˆa(2)
1 ) ≈−0.5001
E(ˆb(2)
1 ) ≈1.4027
Evidently, the estimates corresponding to the process with colored noise are biased.
In closing, observe that the correlation between the regressors and the equation errors does
not aﬀect the form of the distribution.
The reason for the bias in the LS estimates is understood as follows. From the perspective of
(21.73), the LS estimator solves p correlation equations
1
N ϕ[k](y[k] −ϕT[k]θ) = 0
(21.76)
whereas, the r.h.s. is not zero in general; rather it is the correlation between ϕ[k] and v0[k]. Since
the LS estimator assumes the r.h.s. of (21.76) to be zero, it is free of bias only when the correlation
is zero. Furthermore, the magnitude of bias is dependent on the extent of correlation.
The IV estimator, on the other hand, also solves p correlation (normal) equations
1
N
N−1
X
k=0
ζζζ[k](y[k] −ϕT[k]θ) = 0
(21.77)
but by “cleverly” replacing the regressors in (21.76) with what are known as instruments, denoted
by ζζζ[k], which play the role of ϕ[k] but satisfy two key conditions:
1. 1
N
N−1
X
k=0
ζζζ[k]ϕT[k] should be non-singular. This requirement is to ensure identiﬁability, i.e.,
uniqueness of estimates.
2. 1
N
N−1
X
k=0
ζζζ[k]v0[k] = 0 (uncorrelated with disturbances in the process). This is the key, but a
diﬃcult requirement to strictly fulﬁll since one never knows the true correlation structure of the
disturbance. Usually this is addressed by ensuring that ζζζ[k] is noise-free.

606
Principles of System Identiﬁcation: Theory and Practice
Remarks:
Note that the ζζζ[k] is an instrument, but not a regressor, which continues to be ϕ[k].
When a GMM approach as in (21.74) is employed, one obtains an extended-iV method (see
(Soderstrom and Stoica, 1994, Chapter 8)).
Choice of instruments
A natural choice of instrument is to use noise-free simulated outputs. A standard way of generating
these instruments with minimal computation eﬀort is to estimate an ARX model of the necessary
order and simulate it in noise-free conditions
ζζζ(k,θ) ≡
f
x[k −1]
· · ·
x[k −na]
u[k −nk]
· · ·
u[k −n′
b]
gT ;
x[k] =
ˆB(q−1)
ˆA(q−1)
u[k]
(21.78)
These instruments can be expected to satisfy both requirements under open-loop conditions. This
idea can be generalized further to generate instruments by passing u[k] through suitable pre-ﬁlters
ζζζ(k,θ) = Ku(q−1,θ)u[k]
(21.79)
21.7.2
PROPERTIES OF THE IV ESTIMATOR
In the preceding example, one observes that the errors in parameter estimates from the IV method
have been reported. These errors are computed using the expressions for asymptotic covariance of
the IV estimates under certain assumptions. A key assumption is that the system is contained in the
model description (as with PEM estimators in §21.4). Consistency properties are also studied under
similar and additional assumptions. An excellent presentation of the related theoretical aspects is
given in (Soderstrom and Stoica, 1994). Below we present only a summary of these ﬁndings.
Assumptions
(IV-1) The system is strictly causal and stable.
(IV-2) Input has a persistent excitation of “suﬃciently” high order.
(IV-3) Disturbance is stationary with rational spectral density.
(IV-4) The process is under open-loop conditions (not a strict requirement).
(IV-5) Plant description G0 is contained in the model plant set G, and the model is identiﬁable.
(IV-6) Cross-correlation between instruments and equation errors is zero at all lags.
Under the above assumptions, the IV estimator is consistent and produces asymptotically Gaus-
sian distributed estimates.
√
N(θIV −θ0) ∼AsN (0,PIV)
(21.80)
Expressions for the asymptotic covariance matrix PIV are given in Soderstrom and Stoica (1994).
Remarks:
When the true plant description is not contained in the model set, the method results in the best
approximation of the system among all models of the speciﬁed order. This is a limiting result as in the PEM
estimator case.
Finally, eﬃciency is guaranteed when the instruments are chosen in an “optimal” manner. How-
ever, this requires the knowledge of the “true” instruments which can be practically determined only
through an iterative approach. The multistage IV method described in the following section is based
on the above idea. However, it does not iterate until convergence of the instruments. Instead it strikes
a balance between the desired optimality and practicality of the method.

Identiﬁcation of Parametric Input-Output Models
607
21.7.3
MULTISTAGE IV (IV4) METHOD
As the name suggests, the method consists of four stages constituting the core of the algorithm
below. An important feature of this method is that it reﬁnes the instruments using a combination of
the IV and pre-ﬁltering (Stieglitz-McBride) approach.
Algorithm 21.10
Algorithm for multistage IV (IV4) method:
1. Prepare data and estimate I/O delay nk (samples) as outlined in Algorithm 21.2.
2. Specify the orders na and nb of the ARX polynomials to be estimated.
3. Estimate an ARX model of the desired order using the LS method to obtain ˆA(1)(q−1) and ˆB(1)(q−1).
4. Construct instruments from the estimated ARX model as ζζζ (1)[k] =
ˆB(1)(q−1)
ˆA(1)(q−1)
u[k].
5. Compute the IV estimate using the instruments ζζζ (1)[k] and the residuals from the resulting model.
6. Build a time-series model for the residuals and pre-ﬁlter the input output data with the inverse of
the noise model.
7. Re-compute the IV estimate of the ARX model parameters using the ﬁltered data and the same
instrument ﬁlters as in Step 2.
MATLAB: iv4, iv
Example 21.15: Estimating ARX model in Presence of Colored Error
Consider N = 2555 samples from an ARMAX process
y[k] = 0.6q−2 −0.2q−3
1 −0.5q−1
u[k] + 1 + 0.6q−1
1 −0.5q−1 e[k]
excited by a PRBS input containing frequencies in the band [0 0.2]. The innovations variance
is set to 0.1.
For illustration purposes, we shall assume that the knowledge of true orders is available.
The OLS estimates of the ARX model parameters are reported below.
B(q−1) = 0.6093
(±0.008)q−2 −
0.08
(±0.016)q−3;
B0(q−1) = 0.6q−2 −0.2q−3
A(q−1) = 1 −0.3029
(±0.02)q−1;
A0(q−1) = 1 −0.5q−1
On comparison with the parameters of the true polynomials A0 and B0 polynomials, it is
apparent that the OLS estimator has delivered biased estimates.
In contrast, the IV4 estimator produces unbiased estimates as reported below.
B(q−1) = 0.6154
(±0.008)q−2 −0.2308
(±0.032)q−3;
B0(q−1) = 0.6q−2 −0.2q−3
A(q−1) = 1 −0.5281
(±0.045)q−1;
A0(q−1) = 1 −0.5q−1
% Create the plant and noise model objects
p_armax = idpoly([1 -0.5],[0 0 0.6 -0.2],[1 -0.3],1,1,’Noisevariance’,0.05);
% Create input sequence
uk = idinput(2555,’prbs’,[0 0.2],[-1 1]);
% Simulate the process

608
Principles of System Identiﬁcation: Theory and Practice
yk = sim(p_armax ,uk,simOptions(’Addnoise’,true));
% Build iddata objects and remove means
z = iddata(yk,uk,1); zd = detrend(z,0);
% Estimate ARX model using arx (assume known orders and delay)
na = 1; nb = 2; nk = 2;
mod_arx = arx(zd,[na nb nk])
% Estimate ARX model using IV (assume known orders and delay)
mod_iv = iv4(zd,[na nb nk]);
% Present the models and compare estimates
M = stack(mod_arx ,mod_iv)
present(M)
21.8
SUMMARY
In this chapter we studied two broad classes of methods, namely, the prediction-error and corre-
lation methods for estimation of parametric models. the former class of estimators specialize to
several well-known ones such as LS and MLE methods. The main attention of this chapter was on
PEM methods with quadratic criterion (PEM-QC) leading to NLS formulations. Numerical algo-
rithms such as the modiﬁed Gauss-Newton method are used to compute the estimates. In general,
PEM methods have very attractive asymptotic properties. Consistency of these methods depends on
whether the system description S is contained in the model set M and the noise parametrization.
The general result is that when the noise and plant are independently parametrized, the PEM esti-
mate converges to the true description when S ∈M, and to the best approximation when S < M.
A drawback of PEM methods is that they can be computationally demanding. The complexity of
these methods depend on the model structure in use. ARX models are the best in this respect since
their estimation involves linear least squares type methods. For other model structures, numerical
gradients can be computed through appropriate pre-ﬁlters of the algorithms. Furthermore, several
sub-optimal algorithms for these model structures exist, which can be used to initialize the nu-
merical algorithms for PEM methods. The prediction-error minimization formulations are perhaps
the most known eﬀective means of estimating input-output models because they are equipped to
estimate both plant and noise models in the presence / absence of parameter constraints.
Correlation methods do not necessarily involve an optimization problem like PEM methods. They
are based on the requirement that the residuals be orthogonal to past input-output data. The PEM-
QC method can be shown to be a subset of these methods. However, the standard OLS method
gives inconsistent estimates of ARX models when the equation errors are colored. On the other
hand, the instrumental variable method produces consistent estimates by solving correlation equa-
tions between residuals and instruments, which are essentially noise-free versions of the outputs.
These variables can be constructed in several ways. A standard choice is to estimate a linear regres-
sion model followed by a noise-free simulation. Correlation estimators also enjoy good asymptotic
properties, but are usually employed for plant model estimation. Extended correlation methods such
as the extended-IV method determine the estimates by solving a minimization problem, as in the
GMM estimation, instead of an exact set of equations. These techniques are beyond the scope of the
present text.
REVIEW QUESTIONS
R21.1 Describe the basic philosophy of prediction error methods in model estimation.
R21.2 Under what conditions are the PEM estimates consistent?
R21.3 What can be expected of the PEM parameter estimates when there is a mismatch between the
assumed model and the data generating process?

Identiﬁcation of Parametric Input-Output Models
609
R21.4 Explain the frequency-domain interpretation of PEM-QC estimation method.
R21.5 Identify the factors aﬀecting the bias of transfer functions estimates obtained via PEM.
R21.6 What is the principle of correlation methods in identiﬁcation?
R21.7 Describe the motivation for IV method from a least squares estimation viewpoint.
R21.8 When do IV and OLS estimates coincide?
R21.9 Describe three diﬀerent ways of generating instruments in IV methods.
R21.10 Explain the multistage IV4 method.
R21.11 What advantages does the multistage IV4 technique oﬀer over the regular IV method?
EXERCISES
E21.1 Consider the data generating process
y[k] = a1y[k −1] + b1u[k −3] + b2u[k −4] + e[k]
where e[k] is the Gaussian white noise with mean zero. Generate data with a1 = −0.8,b1 = 2,b2 = 1.2
and adjust σ2e such that SNR is 10.
a. Set up the Φ matrix and estimate the parameters a1,b1,b2 using the least squares criterion.
b. What is the standard deviation of each of these parameters? Do the residuals satisfy the
assumptions of the least-squares method?
E21.2 Write a MATLAB code implementing the PLR method for estimating ARMAX models and test
it on a ﬁrst-order ARMAX process.
E21.3 Show that the PEM-MLE estimator in (21.12) simpliﬁes to (21.13) when the noise covariance
matrix is unknown and not a function of θ.
E21.4 A process has a ﬁrst-order OE structure
y[k] =
b20q−2
1 + a10q−1 u[k] + w[k]
where w[k] is a zero-mean white-noise sequence with variance σ2w. Suppose an input, which is ﬁltered
white-noise u[k] = 1/(1−α1q−1)eu[k] is used to excite this process, where eu[k] is a zero-mean white-
noise sequence with variance σ2eu . Then,
a. Find out what estimate of delay can be expected to be obtained from the impulse response
estimates.
b. If an ARX model of a ﬁrst-order with the correct plant delay is used to ﬁt the input-output
data
y[k] =
b2q−2
1 + a1q−1 u[k] +
1
1 + a1q−1 e[k]
ﬁnd the expressions for the LS estimates of b2 and a1. Comment on your obtained results.
E21.5 Write a MATLAB code implementing the Stieglitz-McBride algorithm and test it on a ﬁrst-order
OE process.
E21.6 A process evolves according to the OE(1,1,2) structure y[k] =
b0
2q−2
1 + f 0
1 q−1 u[k] + e[k] where e[k]
is the usual zero-mean, white-noise sequence of variance σ2e.
a. Develop expressions for σ2y, σyy[1], σuy[1], and σuy[2] in terms of the variances of the input
and the white-noise sequences, i.e., σ2u and σ2e, respectively.

610
Principles of System Identiﬁcation: Theory and Practice
b. Consider ﬁtting an ARX model y[k] =
b2q−2
1 + a1q−1 u[k]+
1
1 + a1q−1 ˜e[k] to this process. Assuming
that a WN input sequence with variance σ2u is used, determine the LS estimates of a1 and b2
in terms of the process parameters b0
2 and f 0
1 and the variances σ2u and σ2e.
c. Simulate the process with a white-noise input such that the SNR is set to 10. Obtain 2000
samples of input-output data. Verify your answers in parts (a) and (b).
d. Is this the best ARX model for the given OE process? If not, obtain the “best” ARX model for
the generated input-output data.
E21.7 Derive the expressions for the optimal parameter estimates of an OE model as given in (21.34)
when the data generating process is ARX type.
E21.8 Generate 1000 samples of a process possessing an ARMAX structure with
G(q−1) =
2q−2
1 −1.1q−1 + 0.2q−2 ;
H(q−1) =
1 + 0.4q−1
1 −1.1q−1 + 0.2q−2
(choose H(q−1) accordingly). Use a PRBS sequence (frequencies in the [0 0.4] band) and ﬁx SNR
at 10. We are interested in investigating the estimates of (the ﬁrst 8) impulse response coeﬃcients
using diﬀerent methods.
a. Least squares method.
b. Least squares method, but by ﬁrst pre-whitening the input.
c. Obtaining the best ARX model and calculating the IR coeﬃcients.
d. Obtaining the best OE model and calculating the IR coeﬃcients.
e. Estimating the FRF and subsequently taking the inverse Fourier Transform.
f. Which method do you feel is the “best” one for the purpose? Justify.
E21.9 Derive the gradient (of the regressor) expression given in (21.62) for ARMAX models.
E21.10 It is known that a process has a second-order ARX structure
y[k] =
βq−2
1 + 2αq−1 + α2q−2 u[k] +
1
1 + 2αq−1 + α2q−2 e[k]
where e[k] is a zero-mean white-noise sequence with variance σ2e.
Develop a method to estimate the parameters α and β using a second-order ARX model (assume
delay is known) so that the relationship between the coeﬃcients is satisﬁed. Comment on the possible
advantages/disadvantages of the above method versus simply estimating a second-order ARX model
(i.e., with three parameters to be estimated).
E21.11 Derive the expression given in (21.55) for the spectral density of the disturbance v[k] = y[k] −
G(q−1)u[k] under open-loop conditions.
E21.12 A process is described by y[k] = a0
1y[k −1] + b0
1u[k −1] + e[k] where e[k] is the usual zero-mean
GWN sequence with variance σ2e. Input-output data is generated using a WN input of variance σ2u.
a. Suppose an AR(1) model: y[k] = α1y[k −1] + e1[k] is used to describe this process. Obtain the
LS estimate of the AR(1) coeﬃcient in terms of the true parameters, σ2e and σ2u.
b. Would it be possible that the estimate ˆa1 is an unbiased estimate of the true value a0
1?
E21.13 Develop a pseudo-linear regression algorithm for estimating an OE model. Write a MATLAB
code for the same and test it on estimating an OE model for the data generated in E21.6.
E21.14 Derive the gradient (of the predictor) expressions for the non-linear least squares estimation of
a BJ model.

22
Statistical and Practical Elements of
Model Building
This chapter revisits the systematic procedure for identiﬁcation that was outlined in Chapter
1, with speciﬁc attention to model development. Input and experimental design for identiﬁca-
tion are presented. Statistical principles and certain pragmatic guidelines for choosing model
structures, the estimation algorithm and model quality assessment are presented. Information
theoretic methods for order determination are also discussed.
22.1
INTRODUCTION
Until this point in the text, we have studied the diﬀerent theory and principles of identiﬁcation, in
particular, the various deterministic-plus-probabilistic model structures, important estimation prin-
ciples and methodologies, and the mathematics of computing predictions for a given model. Ap-
plication of these principles to model development, as we have observed, also requires inputs and
decision making from the user’s end.
The objective of this chapter is to address the ﬁner issues and aspects of model development that
constitute the gap between theory and practice.These issues are described below:
i. Input design concerned with generating informative data, which in turn ensures identiﬁability.
ii. Data pre-processing including removal of means, trends and drifts; handling outliers and missing
data, and pre-ﬁltering.
iii. Estimating input-output delay from data using non-parametric and parametric methods.
iv. Guidelines for shortlisting candidate models from the repertoire of models in Chapter 17.
v. Initial conditions for constructing regressors and executing the numerical non-linear PEM algo-
rithms for model estimation.
vi. Statistical measures of testing model adequacy, i.e., model accuracy, reliability and predictive
abilities.
vii. Methods and guidelines for model structure selection and order determination.
Input design is a very important step in identiﬁcation since it is responsible for generating infor-
mative data. When this stage fails, the identiﬁcation exercise results in poor models regardless of
the rigor in the remaining steps. Solutions to the remaining issues are based on a combination of
statistics, intuition and insight. Time-delay estimation can be formulated as a rigorous optimization
problem in time or frequency domains, with the latter yielding eﬃcient estimates. On the other hand,
there exists no automated procedure for model development, and rightfully so since the experience
and domain knowledge of the user can barely be replaced by a set of rules or formulae. An approach
that works well in most cases is to start with a simple model ﬁrst and gradually sophisticate it using
the feedback from model diagnostic checks. Statistical analysis of the model estimates, predictions
and prediction errors play a vital role in model diagnosis and making any necessary improvements
to models. Needless to say, the user’s intuition and experience is also invaluable in this respect.
The methods and guidelines presented in this chapter are demonstrated on case studies in Chap-
ter 24. It is also useful to place the various aspects addressed in the chapter in the context of the
systematic identiﬁcation procedure outlined in Chapter 1, reproduced here for convenience:
611

612
Principles of System Identiﬁcation: Theory and Practice
1. Generate informative data: Design inputs such that measurements contain information about
the parameters of interest.
2. Visualize the data: Obtain a feel for the delay and dynamics by zooming into portions corre-
sponding to step changes in the inputs. Inspecting the data visually is also useful for detecting
the presence of outliers and/or abnormalities in the data.
3. Pre-process data: Remove non-zero means, trends / drifts, outliers and missing data. Pre-
processing may also typically include pre-ﬁltering and/or transformations of the data because
modeling requirements (e.g., frequency-domain models) may demand so to obtain consistent or
eﬃcient estimates (e.g., stationarity or white-noise).
4. Build non-parametric descriptions: Estimate response-based models (e.g., impulse, step, FRF)
using the methods of Chapter 20. These models give reasonably good estimates of time-delay and
gain in addition to providing insights into the dynamics (and hence model order) of the process.
5. Develop parametric descriptions: Estimate polynomial input-output models using the PEM
or IV methods. Preliminary guesses of requisite user inputs, namely, delay and order have to be
provided. Non-parametric methods provide reasonably accurate estimates of the true delay, while
only a crude estimate of the order. The latter is reﬁned iteratively using model quality checks and
information criteria measures (e.g., AIC).
6. Assess model quality: Estimated model should pass all performance checks: (i) zero residual-
input cross-correlations, (ii) zero temporal correlation in residuals, (iii) C.I.s for parameters
should not contain zeros and (iv) cross-validation. There may be other checks dictated by the
process and/or the application such as physical meaningfulness of the model, etc.
We shall begin with the topic of informative data, which is a necessary condition for system
identiﬁability (recall §18.6.3) and provides foundations for the key problem of input design. Only
important ideas are outlined. The topic of input design is one of the evolving branches of identiﬁca-
tion with a blend of ideas from optimization, spectral analysis and statistics.
22.2
INFORMATIVE DATA
In §2.1, speciﬁcally in Example 2.2, we illustrated the role of input in guaranteeing (system) identi-
ﬁability, to be speciﬁc, resolvability. The frequency-domain interpretation of PEM-QC estimators in
(21.49) also highlighted the importance of inputs. We can thus summarize certain important points
on the role of input in identiﬁcation:
i. The input governs the information content in the data with respect to the unknowns of interest.
ii. It determines the way the process appears to the observer and the estimation algorithm.
iii. The frequency content of the input governs the number of parameters that are identiﬁable or the
dimensionality of the identiﬁable model.
iv. The strength of the input relative to noise signiﬁcantly inﬂuences the precision of parameter
estimates.
The above observations lead to concepts of informative experiments (see Ljung (1999)) and con-
stitute the theoretical as well as practical guidelines for input design.
Intuitively, inputs should contain as many frequencies as possible to maximize the “information”
thereby theoretically assuring identiﬁability. An experiment is “informative” if it allows us to resolve
between two candidate models.
Think of each frequency as a “knife” that cuts the big pie of candidate models into two portions.
At the end of the identiﬁcation exercise, we would like to have the smallest portion of the pie that
contains the true model.

Statistical and Practical Elements of Model Building
613
Remarks:
It may be recalled from §2.2 that the signal-to-noise ratio also aﬀects our ability to identify a
model. Despite the use of an optimal input, a high SNR can result in large uncertainties for the parameters.
In order to derive the input properties that guarantee identiﬁability, we need to ﬁrst deﬁne what is
meant by informative data. The data is said to be informative enough when predictions with a given
data are identical (on the average), which occurs only when the corresponding predictor ﬁlters are
equal.
Deﬁnition 22.1. A quasi-stationary data set is informative enough with respect to a model set
if for any two models W1 and W2,
¯E[(W1(q−1) −W2(q−1))z[k]]2 = 0
(22.1)
The expectation operator is the generalized one that we introduced in Chapter 17 in the context
of quasi-stationarity.
The diﬀerence (W1(q−1) −W2(q−1))z[k] is also the one-step ahead prediction error. That is, if
θ1 and θ2 are the associated model parameters
△ε[k] = ε1[k] −ε2[k] = ˆy(θ1) −ˆy(θ2) = (W1(q−1) −W2(q−1))z[k]
Suppose (G1, H1) and (G2, H2) are the corresponding plant-noise model pairs, then the condition
for informative data can be written as
¯E((△ε[k])2) = 0
which can be then shown (Ljung, 1999) to be equivalent to
|△G(ejω)|2γuu(ω) = 0,
under
△H(ejω) = 0
(22.2)
If the input spectrum is zero at some frequency, then there is no way of distinguishing between
the two plant models at that frequency.
This leads to the concept of persistent excitation.
22.2.1
PERSISTENT EXCITATION
It is clear that if a ﬁne distinction between models is desired, the inputs should have as many fre-
quencies as possible. Of course it is not possible to inject a continuum of frequencies and therefore
models can only be resolved within a small region.
When the input, speciﬁcally its spectral density, contains almost all frequencies, it is said to be
persistently exciting.
Any quasi-stationary input u[k] is persistently exciting if (Ljung, 1999)
γuu(ω) > 0,
for almost all ω
In practice, however, we may use inputs that contain only a set of frequencies over a band. Con-
sequently, we can only distinguish between models of certain orders. An input of single frequency
(ω , 0) can estimate two parameters. Recall Example 2.2, which showed that an input with a single
frequency is suﬃcient to estimate a two-parameter FIR model, provided the delay is known.
Extending this idea, a quasi-stationary signal that is persistently exciting of order n = nb + nf
is informative with respect to all models of orders nb and nf in the numerator and denominator,
respectively. As the number of frequencies in the input increases, the ability to discriminate or
resolve between models of higher-orders increases.

614
Principles of System Identiﬁcation: Theory and Practice
Deﬁnition 22.2. A quasi-stationary signal {u[k]} is said to be persistently exciting of order n if, for
all ﬁlters of the form
Mn(q) = m1q−1 + · · · + mnq−n
the relation
|Mn(ejω)|2γuu(ω) = 0
implies that
Mn(ejω) = 0
(22.3)
The condition of persistent excitation of order n can be translated to a requirement on the covari-
ance matrix of the input.
A quasi-stationary input is persistently exciting of order n if and only if its covariance matrix
Rn
uu =

Ruu[0]
Ruu[1]
· · ·
Ruu[n −1]
Ruu[1]
Ruu[2]
· · ·
Ruu[n −2]
...
...
...
Ruu[n −1]
Ruu[n −2]
· · ·
Ruu[0]

is non-singular.
The question that now remains is how to design inputs that satisfy the excitation requirements
above.
22.3
INPUT DESIGN FOR IDENTIFICATION
The topic of input design has been an active and challenging area of interest for several decades.
Although the general result of persistent excitation gives a fair idea of what is a desirable input, there
still remain plenty of open-ended problems. One of the prime challenges is that an input that has
optimized for a class of identiﬁcation problems need not be optimum for another. For example, an
input signal optimized for LTI system is not the best for linear time-varying or non-linear systems.
Persistent excitation is necessary for input design but not suﬃcient. It does not take into account the
identiﬁcation eﬀort or the cost. The latter could be deﬁned in terms of input amplitudes (wear and
tear on the actuator), rate of change of inputs, bias and variance considerations, etc. An input that
meets the practical requirements of a process operation is said to be plant friendly, a term that has
been coined recently. See Narasimhan et al. (2011) and Rivera et al. (2003).
Some primary considerations (apart from persistent excitation) are:
• The asymptotic properties of the estimate (bias and variance) depend only on the input spectrum
- not on the actual waveform. This is evident from (21.49).
• The input must have limited amplitude: umin ≤u(t) ≤umax taking into account physical
constraints on the actuators. This is also important to ensure that the process does not enter the
non-linear regime.
• Periodic inputs may be useful, particularly in modal identiﬁcation (common in structural me-
chanics and vibration machinery).
• The parameter estimate covariance matrix is typically inversely proportional to the input power
(variance). Therefore, we would like to inject as much power as possible into the input. This is
of course conﬂicting with the second requirement above.
A property that strikes a balance between the amplitude and the variance requirements is the crest
factor
C2
r =
maxt u2(t)
lim
N→∞
1
N
N
X
t=1
u2(t)
(22.4)

Statistical and Practical Elements of Model Building
615
A good signal waveform is one that has a small crest factor (minimum amplitude in the numerator
for a maximum variance contained in the denominator). The theoretic lower bound of Cr is 1, which
is achieved for binary symmetric signals.
Remarks:
Input design, in general, is formulated as an optimization problem with the objective of minimizing
a cost function subject to certain constraints. Some interesting and rigorous formulations have been proposed
over the last decade including that of plant-friendly input design. A large class of input design problems aim at
maximizing the Fisher’s information (13.5) so as to obtain eﬃcient estimates (by virtue of C-R bound (13.31))
We have however discussed the problem under simplistic, but essential, considerations.
Types of inputs
There are diﬀerent kinds of inputs available for identiﬁcation. To each its merits and demerits.
1. White noise: It contains all frequencies uniformly. Theoretically a preferable input signal. De-
couples the IR parameter estimation problem. Provides uniform ﬁt at all frequencies. However,
possesses a high crest factor.
2. Random binary: Generated by starting with a Gaussian sequence and then passing it through a
ﬁlter depending on the input spectrum requirements. The sign of the ﬁltered signal is the RBS.
No proper control over the spectrum. The “sign” operation distorts the spectrum of the input
sequence. The RBS has the lowest crest factor.
3. Pseudo-RBS: As the name suggests, it is not strictly a random signal. It is a deterministic signal
with the properties of a random signal. Generated using a Linear Feedback Shift Register (LFSR)
of n bits, a maximum length PRBS is 2n −1 sequences long. A full-band PRBS possesses white
noise-like properties. The frequency content can be changed by altering the clock sampling rate
(see §22.3.1 below). It has the lowest crest factor. A disadvantage is that only maximum length
PRBS possess the desired properties.
4. Multisine: Multisines are a combination of sinusoids of diﬀerent frequencies, which are gener-
ally known beforehand.
u[k] =
M
X
i=1
aj sin(ωik + φi),
0 ≤ω1 < ω2 < · · · < ωM ≤π
(22.5)
These signals provide very good estimates of the transfer function at the respective frequencies.
While both amplitudes and phases are design parameters, the latter have a signiﬁcant inﬂuence
on the amplitude, and hence the crest factor (see Exercise E22.7). A useful guideline is to keep
the sines as much as “out of phase” as possible so as to keep the crest factor low. Note that the
spectrum is not continuous. Therefore, the estimates at other frequencies are not available.
Of the above the PRBS sequence is the most widely used for linear systems since binary signals
have the lowest crest factor for a given variance.
22.3.1
PSEUDO-RANDOM BINARY SEQUENCES
Binary signals with a desired spectral shape can be generated in two ways:
1. Random Binary signal: Generated by passing a random Gaussian signal through a sign function.
The disadvantage is that there is little control over the spectrum
2. Pseudo-Random Binary signal: These are deterministic binary signals that have white noise-
like properties (and hence the name pseudo-random)
PRBS:
u[k] = rem(a1u[k −1] + · · · + anu[k −n],2)
(modulo 2)
• With n-coeﬃcients, one can generate a 2n −1 full length sequence (zero is excluded).

616
Principles of System Identiﬁcation: Theory and Practice
TABLE 22.1
Indices of non-zero coefﬁcients in the generating polynomial of full-length PRBS
Order
M = 2n −1
Non-zero indices of {an}
2
3
1,2
3
7
2, 3
4
15
1, 4
5
31
2, 5
6
63
1, 6
7
127
3, 7
8
255
1, 2, 7, 8
9
511
4, 9
10
1023
7, 10
11
2047
9, 11
• The choice of coeﬃcients (which are zero / non-zero) determines if a full length or partial
length sequence is generated.
• The signal resulting from the modulo operation above switches between 0 and 1. To obtain
a PRBS that switches between -1 and 1, a linear transformation of the form au + b, a =
2,b = −1 is applied.
A PRBS generating device (made of registers and ﬂip-ﬂops) has two periods - one for the shift
register and the other for the clock, which determines the minimum number of sampling intervals
after which the sequence is allowed to shift. When both these periods are identical and a full-length
PRBS (see below) is generated, a PRBS with white-noise properties is obtained.
Full-length PRBS
For a n-coeﬃcient PRBS, the maximum length sequence that can be generated without repetition is
M = 2n −1. The table lists those {an}s that have to be non-zero; see Ljung (1999) and Soderstrom
and Stoica (1994). There exist other combinations of non-zero coeﬃcients as well (see Exercise
E22.5).
Observe that the last coeﬃcient has to be non-zero. Full-length pseudo-random binary sequences
are periodic with period M, and therefore quasi-stationary. Further, only full-length PRBS have
white noise-like properties as corroborated by the result below.
Theorem 22.1
Any maximum length or full-length PRBS switching between ±U has the ﬁrst- and second-order
properties
¯u = 1
M
M−1
X
k=0
u[k] = ±U
M
(22.6a)
σuu[l] = 1
M
M−1
X
k=0
u[k]u[k −l] =

U2,
l = 0,
−U2
M ,
otherwise
(22.6b)

Statistical and Practical Elements of Model Building
617
In deriving the properties above, we have used the deﬁnitions of mean of a deterministic signal
in (7.47a) and the auto-covariance of a periodic signal in (10.12), respectively (see also Exercise
E22.4). Note that the expression in (22.6b) is truly the ACVF only when M is very large, since the
mean is not exactly zero for ﬁnite and small values of M.
The spectral property of the PRBS (note that it is a periodic signal and hence does not possess
a spectral density) can be derived using the Wiener-Khinchin theorem-like relations for periodic
signals in (10.53). Using (10.53a), the spectrum of a full-length PRBS is
Pxx( fn = n
M ) = 1
M
M−1
X
l=0
σuu[l]e−j2π fnl
=

U2
M2 ,
n = 0
U2
M
 
1 + 1
M
!
,
n = 1
M ,· · · , M −1
M
(22.7)
As M becomes large, the spectrum is uniform at all frequencies, essentially achieving “white noise-
like” spectral characteristics.
Band-limited PRBS
To generate band-limited, for example, low-frequency content PRBS, the full-length sequence is
subjected to a simple operation. First the full-length PRBS is generated, followed by an elongation
or stretching of the constant portions of full-length PRBS, while keeping the overall length ﬁxed.
Technically, the full-length PRBS is re-sampled P times faster than the frequency at which it is gen-
erated. The resulting signal has the same properties as passing the PRBS through a simple moving
average ﬁlter of order P.
˜u[k] = 1
P (u[k] + u[k −1] + · · · u[k −P])
Listing 22.1
MATLAB commands for input design
uk = idinput(2047,’prbs’,[0 1],[-1 1]); % full-length PRBS
uk = idinput(2555,’prbs’,[0 1/5],[-1 1]); % band-limited PRBS
Notice that we specify the upper limit on the band as 1/P where P is the clock period. As remarked
earlier setting P = 1 produces a PRBS with full spectrum.
We could generate a band-limited PRBS by passing it through a low-pass ﬁlter, but the control
over the resulting spectrum is limited (Soderstrom and Stoica, 1994).
Remarks:
1. For a given amplitude range, PRBS packs the maximum variance or energy.
2. It is ideally suited only for linear systems. Since it switches between two states, it cannot detect non-
linearities.
3. Change in the initialization only produces a shift in PRBS. This is due to the periodicity property of PRBS.
Therefore, PRBS is not directly suited for design of uncorrelated inputs for multivariable systems.
4. For time-varying and non-linear systems, some modiﬁcations exist such as Multi-valued PRBS and
Amplitude-Modulated PRBS (Nelles, 2001).

618
Principles of System Identiﬁcation: Theory and Practice
22.3.2
PRELIMINARY TESTS FOR INPUT DESIGN
Deciding the frequency content of the input prior to identiﬁcation is akin to knowing the questions
to be asked to the candidate in an interview where it is the “best response” zone of the candidate
is not known a priori (the interviewer’s enigma). Just as in an interview, questions are determined
iteratively and based on the end-purpose of the interview as well as the candidate in question, some
preliminary tests have to be conducted to arrive at the optimal input design unless of course this
information is known a priori.
1. Perform a step test (3% - 10% magnitude) on the system. The step response throws light on the
gain, time constant, delay, inverse response, etc.
2. A step in one direction is insuﬃcient. Perform a step at least test in two directions or best apply
a staircase signal so as to check for the eﬀects of non-linearities and the range of linearization.
3. From the step response, identify the eﬀective time-constant τ of the c.t. process.
4. Compute the eﬀective bandwidth ΩBW = 1/τ.
5. Use sampling frequency Fs = 1/Ts anywhere between 10 −20 times ΩBW.
6. Set the maximum frequency (w.r.t. continuous time) in the input to be about 2−3 times the ΩBW.
7. Design an input sequence of the appropriate type (white, rbs, multisine, prbs) accord-
ingly.
With the above recommendations, reasonable suggestions for the input frequencies, in terms of
the discrete-time (or normalized) frequency range, vary from [0, 2ΩBW/20ΩBW] = [0, 0.1] to
[0, 3ΩBW/10ΩBW] = [0, 0.3] cycles/sample. These correspond to clock periods between P = 10
and P = 3. Typical choices in practice (for systems with low-pass ﬁlter characteristics) are P = 4
and P = 5. For systems with special frequency response characteristics, extra care is required.
Guidelines for experimental design
Ljung (1999) provides useful guidelines for experimental design so as to generate informative data.
Speciﬁc conditions vary with the application.
• Choose experimental conditions and inputs such that the predictor becomes sensitive to parame-
ters of interest and importance.
• Choose excitation frequencies and use the input energy in those bands where a good model is
intended and/or where the disturbance activity is insigniﬁcant.
• Under open-loop conditions and for linear systems, apply binary, periodic inputs with full control
over the excitation energies.
• Recall from Chapter 21 that the error in transfer function estimate is inversely proportional to the
sample size and SNR.
Cov ˆGN (eiω) ≈n
N
Φvv(ω)
Φuu(ω)
• Sample 10-20 times the bandwidth frequency.
For further reading and the latest developments on input design, the reader is referred to Barenthin
(2006) and Soderstrom and Stoica (1994). With the inputs designed for generating informative data,
the next step of concern is pre-processing of data that may be aﬀected by drifts, outliers, etc.
22.4
DATA PRE-PROCESSING
Input-output data, in general, can contain various characteristics / anomalies that are in viola-
tion of the assumptions made in the theoretical construction and estimation of models. Common

Statistical and Practical Elements of Model Building
619
among these characteristics are drifts and/or trends, outliers, missing data which violate the quasi-
stationarity, “well-behaved” nature (no one value shall dominate the data) and uniform sampling
assumptions. In order to prepare the data for identiﬁcation, therefore, it is important to either pre-
process / transform the data or cleverly model the features separately followed by a fusion with the
identiﬁed model. Usually the need for the ﬁrst approach arises, i.e., data cleaning. The “cleaned”
or pre-processed data is then subjected to identiﬁcation. It may be noted that even when the data
is clean, it may be necessary to perform minimal operations on the data such as removal of oﬀsets
(means) and partitioning the data set into training and test data sets.
22.4.1
OFFSETS, DRIFTS AND TRENDS
Linear models, recall, satisfy superposition and homogeneity principles. For non-linear processes,
linear models relate deviation variables, i.e., deviations from a nominal operating point, which
is typically chosen as the steady state condition. Therefore, it is important to construct deviation
variables from the data (w.r.t. steady state) as a ﬁrst step in identiﬁcation. Quite often, however, the
steady state values or the nominal point may not be available to the user. In such situations, these
quantities have to be either estimated along with model parameters or separately. In the latter case,
experimental data from a steady state operation can be used. When such data is not available, it is a
common practice to replace it with sample mean of the training data.
Remarks:
The sample mean is, as we know, not a robust estimator of the mean. Therefore, in presence of
outliers or heavy-tailed data, one may replace it with the sample median or estimate the oﬀsets along with
model parameters (both give diﬀerent results). Of course, a third alternative is to use outlier replacement /
handling methods (see §22.4.2 below).
To summarize, for linear system identiﬁcation only, we shall work with deviation variables,
y[k] = yabs[k] −ˆyss, u[k] = uabs[k] −ˆuss
(22.8)
where the subscript on y and u denote the absolute values and ˆuss and ˆyss are the estimates of
steady-states. Also see §22.4.4 below on performing the same operation to the test data.
Measurements can often exhibit slow drifts and trends due to inherent non-stationarities in pro-
cesses and/or disturbances. Integrating (or like) type disturbances or presence of integrators in pro-
cesses are a common cause of these characteristics. In order to meet the quasi-stationarity assump-
tion of the (classical) identiﬁcation theory, it is necessary to account for these characteristics explic-
itly. We have earlier discussed similar issues in the context of time-series modeling in §7.5.5 and
§9.7. Two solutions emerged from those discussions:
1. If data contains only trends, model them using polynomial ﬁts of appropriate order, which is
determined by assessing the stationarity of the residual component.
Removal of periodic and seasonal eﬀects due to disturbances can be capably handled by well-
established methods in time-series analysis (see (Brockwell, 2002; Shumway and Stoﬀer, 2006)
for instance).
2. When a random walk or a very slow decay is observed, incorporate suﬃcient number of inte-
grators, i.e., by diﬀerencing the output suitably. From §9.7 we know that this approach can also
handle trends. The merits and demerits of this approach in the context of time-series analysis
were also discussed in detail in §7.5.5 and §9.7.
We shall further elaborate below on the use of the second approach in identiﬁcation.
Integrating effects
Integrating (due to poles on or very close to unit circle) eﬀects can be present in the disturbance
and/or the input channel. In the parametric representations of §17.5, we run into the following three
possibilities:

620
Principles of System Identiﬁcation: Theory and Practice
1. Integrator in the noise model:
y[k] = G(q−1,θ)u[k] + H(q−1,θ)
(1 −q−1) e[k]
(22.9a)
=⇒∇y[k] = G(q−1,θ)∇u[k] + H(q−1,θ)e[k]
(22.9b)
where ∇= 1 −q−1 is the usual diﬀerencing operator introduced in (9.52) and H(q−1,θ) has all
poles within the unit circle.
Thus, both input and output are diﬀerenced prior to identiﬁcation.
2. Integrator in the plant model: As before, but with a minor variation, we have
y[k] = G(q−1,θ)
1 −q−1 u[k] + H(q−1,θ)e[k]
(22.10a)
=⇒∇y[k] = G(q−1,θ)u[k] + H(q−1,θ)∇e[k]
(22.10b)
In this case, a model is developed between input and diﬀerenced output. However, the noise
model is forced to have a zero on the unit circle, i.e., a MA term with a zero at z = 1 is enforced
on the identiﬁed model.
3. Finally, we have the case of integrator in both plant and noise model,
∇y[k] = G(q−1,θ)u[k] + H(q−1,θ)e[k]
(22.10c)
where once again the input and diﬀerenced output are considered for identiﬁcation. However, the
diﬀerence here is that no constraints on noise model are placed.
A question that naturally arises is - how does one detect which one of the above cases applies to a
given identiﬁcation problem? The auto-correlation function of the output, as in classical time-series
analysis is of signiﬁcant help in this respect. If the ACF of the output shows a slow decay, then
the plant model is highly likely to have integrating eﬀects (or slow dynamics). The non-parametric
estimates, namely the impulse and step response models, can also oﬀer considerable insights into the
presence of integrating eﬀects in the deterministic sub-system. In order to detect these characteristics
in the noise sub-system, the ACF of residuals from the best OE model can be analyzed in the same
way as the time-series case. Unit root tests can also be conducted on these residuals as described in
§9.7.
The example below illustrates the above guidelines.
Example 22.1: Detecting Integrating Effects in Systems
Consider two systems, one which has slow dynamics in deterministic and the other in the
stochastic sub-system:
G1(q−1) =
2q−2
(1 −0.97q−1)(1 −0.5q−1) ; H1(q−1) =
1
1 −0.4q−1 ;
(22.11a)
G2(q−1) =
2q−2
(1 −0.7q−1)(1 −0.5q−1) ; H2(q−1) =
1
1 −0.95q−1 ;
(22.11b)
The ACF and non-parametric regularized impulse response estimates for (G1, H1) are shown
in Figures 22.1(a) and 22.1(b), respectively. Both conﬁrm the presence of (near) integrating
eﬀects in the deterministic sub-system.
For the second sub-system, the ACF of the output shown in Figure 22.2(a) does not detect
the near unit circle pole characteristics of the noise sub-system. An OE(1,2) model with delay
nk = 2 is ﬁt to the input-output data generated from this system. Auto-correlation estimates
of the residuals from this model are shown in Figure 22.2(b), which convincingly indicate the
presence of random walk-like eﬀects in the stochastic sub-system. Unit root tests, described
in §9.7, may be carried out on the residuals to formally test for integrating eﬀects.

Statistical and Practical Elements of Model Building
621
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
Plant contains integrating effect
(a) ACF estimates of the output
0
50
100
150
200
−0.5
0
0.5
1
1.5
2
2.5
3
3.5
4
IR estimates for plant containing integrating effects
Time
Amplitude
(b) IR estimates
FIGURE 22.1
ACF of the output and IR estimates for (G1, H1) both conﬁrm the presence of very slow dynam-
ics in G.
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
Stochastic subsystem contains integrating effect
(a) ACF estimates of the output
0
5
10
15
20
25
30
35
40
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
Stochastic subsystem contains integrating effect
(b) ACF estimates of the residuals
FIGURE 22.2
ACF of the output and model residuals for (G2, H2) conﬁrm the presence of very slow dynamics
in H only.
Remarks:
i. Enforcing integrators in the plant / noise models must be done only when really necessary. The general
motivation is that identiﬁcation of systems with poles on or very near to the unit circle typically results in
models with unstable conﬁdence regions. When the true system does not exhibit any integrating eﬀects,
diﬀerencing introduces spurious high-frequency variations, resulting in a lower SNR. Section 9.7 discussed
this aspect and the general risks associated with unnecessary diﬀerencing.
ii. A natural generalization of this discussion takes us towards identiﬁcation of systems with poles outside the
unit circle, i.e., unstable systems. A natural framework for handling these systems is closed-loop identiﬁca-
tion. The idea is to stabilize the system by feedback prior to identiﬁcation. See Forssell and Ljung (2000)
for an extension of the traditional PEM methods to unstable systems.
The case study in §24.3 presents a step-by-step identiﬁcation of a process consisting of random
walk type disturbances.
We next turn to the more challenging and frequently encountered case of brief bursts, outliers and
irregularly available data.
22.4.2
OUTLIERS AND MISSING DATA
Outliers and missing data are two common problems encountered in every sphere of data analysis.
As we shall see below, the deﬁnitions and causes of these anomalies and discrepancies are diﬀerent.

622
Principles of System Identiﬁcation: Theory and Practice
i. Outlier: There exists no formal deﬁnition of this term, but is broadly understood as that data
point which stands out distinctly from the bulk of the data. A widely cited deﬁnition is due to
Hawkins (1980):
An outlier is an observation which deviates so much from the other observations as to
arouse suspicions that it was generated by a diﬀerent mechanism.
The cause for an outlier could be either an abnormal sensor characteristic or an unusually abrupt
process excursion. Thus, not all outliers arise as a consequence of the measuring mechanism. A
single data set can consist of more than one outlier with diﬀerent patterns of occurrence, i.e., in
groups or scattered. Outliers can signiﬁcantly inﬂuence the estimates of signal properties such as
mean, covariance, spectral density, etc. in turn, aﬀecting the estimates of model parameters.
ii. Missing data: Sensors can intermittently (missing at random) or systematically undergo fail-
ures leading to blank or missing data. In many other situations, the measuring mechanism of
continuous-time processes itself may be irregular or non-uniform, e.g., astronomical data, lab
measurements from manually collected samples, etc. Such type of data is collectively treated
under the missing data umbrella. The major challenge faced in identiﬁcation with missing obser-
vations is that the regularity in the series is lost and thus all the classical methods fail to work
unless some estimate of the missing data is obtained.
The most important diﬀerence between the two data characteristics is that the presence and loca-
tions of outliers are usually not known a priori (only in a few situations they are known a priori),
whereas the locations of missing data are always known a priori. Thus, the problem of handling
outliers has an additional dimension to it - that of detection. Interestingly, despite being distinct en-
tities with diﬀerent causes, the remedies for handling missing data can be used to address the issue
of outliers (once they are detected) as remarked below.
Handling outliers
The main motivation for devising methods for handling outliers is, as remarked above, classical
estimators such as sample mean and variance are highly sensitive to the presence of outliers. A
measure of the sensitivity of an estimator (to unusual data) is the breakdown point (BP), which
essentially quantiﬁes how well an estimate can withstand “bad” data before it breaks down. For
ﬁnite-samples, deﬁnition is the smallest fraction of contamination that can cause the estimator to
produce estimates arbitrarily larger (in magnitude) than those obtained from the uncontaminated
data Z0
BP( ˆθ(Z)) = min
 m
N ,| ˆθ(Z) −ˆθ(Z0)| →∞

(22.12)
The lower the breakdown point of an estimator, the poorer is its robustness. Usually the BP is
mentioned in percentages under asymptotic (N →∞) conditions. This deﬁnition is applicable not
merely to estimators of statistical parameters, but also to those of model parameters. The sample
mean, for instance, has a breakdown point of 1/N, or 0%. Not coincidentally, this is also that of the
LS estimator. The sample median has a BP of 50%, making it a robust estimator of the mean (at the
cost of eﬃciency, recall §16.2). But, surprisingly the 1-norm estimator (absolute sum minimizer)
for linear regression has 0% BP, meaning it has the same poor sensitivity as that of the LS estimator
of regression parameters.
In the context of regression, the question of interest is not so much of whether a data point is
an outlier, but more of if the unusual data point impacts the regression model. For example, there
may be outliers in a regressor (w.r.t. its own set of values) but they do not inﬂuence the regression
model (parameters) while there may be some other unusual data in the regressor that are not outliers
but they can signiﬁcantly inﬂuence the regression model. For this reason, a ﬁner classiﬁcation of
outliers is necessary.

Statistical and Practical Elements of Model Building
623
i. Univariate outlier: It is an observation that is unusual unconditionally in either the response or
the regressor.
ii. Leverage point: This is a data point that has an unusual value for the regressor (far from its
average), but possibly still in line with pattern of the remaining data. In other words, it has the
potential to inﬂuence the regression model but does not always necessarily do so. Only “bad
leverage” points can aﬀect the regression model coeﬃcient.
iii. Regression outlier: This is that observation point where the response variable is unusual con-
ditional on the value of the regressor. On its own the regressor or the response variable is not
necessarily unusual. A key characteristic of the regressor outlier is that it produces a large resid-
ual but does not inﬂuence the regression slope coeﬃcient. Therefore, regression outliers aﬀect
the precision of the estimates.
iv. Inﬂuential observations: When an observation has high leverage and is also a regression outlier,
it will strongly inﬂuence the regression model. These observations are of maximum concern.
We are primarily interested in regression outliers and inﬂuential observations.
Two broad and somewhat contrasting approaches for handling (data and regression) outliers are
listed below:
1. Two-step approach: Identify outliers ﬁrst combined by an appropriate treatment and apply clas-
sical procedures to the cleaned data. This approach rests on the use of methods that detect and
treat the outliers appropriately. This approach is a traditional one for which several techniques
are available. However, there are a few, but important, risks associated with this approach (to be
listed shortly).
2. Single-step approach: Do not attempt to clean the data but rather work with statistical properties
and modeling procedures that are invariant or robust to the presence of outliers. The idea paves
way for the subject of robust statistics (for example, use sample median in place of sample mean,
recall §16.2) or robust regression. This is, relatively, an emerging area with some proven results.
The single-step approaches, in fact, are deemed to be superior to the two-step approaches for
a few important reasons (Huber and Ronchetti, 2009). In fact, they are used in turn for outlier
detection. The premise is that since robust regression methods are largely insensitive to (regression)
outliers and therefore the residuals associated with those observations should be large (Rousseeuw
and Leroy, 2004).
A select set of statistical and robust regression-based methods for detecting outliers.
Detection of and remedies for outliers
Detection of outliers is essentially governed by what is assumed about the characteristics of the
“normal” and/or “abnormal” data. These descriptions could be non-parametric or parametric. Prior
knowledge is also factored into deﬁning normal data / outliers, wherever applicable. Another key
tool that is required is a metric for deviation (distance measures) from normalcy.
Several among the existing and classical techniques for detecting data outliers can be divided
into diﬀerent approaches, namely, those that make use of statistical models, those based on spatial
proximity models and specialized approaches. There exist other categorizations such as univariate /
multivariate, non-parametric / parametric, etc. As remarked above, an important set of methods that
have emerged in the two to three decades are based on the robust regression diagnostics. Most of
the methods discussed below are meant for detecting regression outliers or inﬂuential observations.
1. Statistical tests: Assume a distribution for the normal data and test each point x[k] for distance
from the mean. A widely used distance measure is that Mahalanobis distance (Johnson, 2011).
MD(x[k]) = (x[k] −µx)T Σ−1
x (x[k] −µx)
(22.13)

624
Principles of System Identiﬁcation: Theory and Practice
In practice, the distributional properties are unknown and have to be estimated from data. For
this reason in the computation of (22.13), robust statistics such as sample median and median
absolute deviation (for the univariate case) are used to estimate the mean and standard devia-
tion, respectively. In the multivariate case, a robust estimator such as the minimum covariance
determinant (MCD) estimator is used to obtain an estimate of Σ (Rousseeuw and Leroy, 2004).
2. Regression diagnostics: The following are some of the popular measures built on the residuals
of regression.
a. Hat matrix: This is none other than the projection matrix P = Φ(ΦTΦ)−1ΦT from the OLS
estimator (recall (14.24)), which also explains its name. The diagonals of this matrix Pi j
denote the sensitivity of the predictor to the ith observation. This measure is useful in detect-
ing leverage points only since it completely ignores the response variables. An observation
for which Pii > 2p/N is considered a high leverage point. It is useful in detecting only a
small number of leverage points.
b. Studentized residuals: This is a measure stemming from the LS ﬁts and one that takes into
account both the dependent and the independent variables. Two diﬀerent constructions are
available in the literature:
¯εi =
ε[i]
ˆσ √1 −Pii
;
ε⋆
i =
ε[i]
ˆσi
√1 −Pii
(22.14)
where ε[i] = y[i] −ˆy[i].
The ﬁrst standardized residual, ¯εi, known as the internally studentized residual, is con-
structed a model estimated from the full data set (including the suspected outliers). On the
other hand, the second residual ε⋆
i is obtained from a model ﬁt by excluding the ith obser-
vation. Accordingly, ˆσ is the estimate of standard deviation of measurement errors in y and
ˆσi is the estimate of standard deviation with the suspected variable omitted.
c. Cook’s distance: Useful in detecting an inﬂuential observation (a data point that is both
high leverage and regression outlier). It is based on the diﬀerence between predicted and
observed responses.
Di =
¯ε2
i
pˆσ2
hii
1 −hii
(22.15)
where ¯εi is the standardized residual deﬁned in (22.14) and p is the number of parameters
as before. The ﬁrst factor measures discrepancy, i.e., goodness of model ﬁt for y[j] (eﬀect
of regression outlier) while the second one measures how far x[i] from the rest of the
regressors (a measure of leverage). A heuristic rule for the signiﬁcance test is Di >
4
N −p.
There exists no statistically rigorous means for this purpose. This metric can be used for
detection of multiple outliers.
d. DFFITS: A variant of Cook’s distance metric above, it was introduced by Belsley, Kuh and
Welch (1980) where the idea was to replace the internalized residual with the externalized
residual and to use the square-root distance,
DFFITSi = ε⋆
i
 
hii
1 −hii
!1/2
(22.16)
An observation for which |DFFITSi| > 2
p
p/N is potentially a highly inﬂuential observa-
tion.
e. DFBETAS: A natural way of determining if a given observation is inﬂuential is to study its

Statistical and Practical Elements of Model Building
625
inﬂuence on the regression coeﬃcient. This approach leads to the deﬁnition of DFBETA1
DFBETAi j = θ j −θ j(−i)
(22.17)
where θ j(−i) is the parameter estimate obtained by excluding the ith observation.
The measure DFBETAS is merely the standardized version of DFBETA,
DFBETASi j = DFBETAi j
σ ˆβ j (−i)
(22.18)
where σ ˆβ j (−i) is the error in the estimate of βj with the ith observation excluded. A thresh-
old for detecting inﬂuential observations is 2/
√
N.
f. LMS diagnostic: This measure is constructed from the standardized residuals of a least me-
dian squares (LMS)2 regression, i.e., one which minimizes the median of squared prediction
errors introduced by Rousseeuw (1984),
wi = |ri|/s0
where s0 = 1.4826
 
1 +
5
n −p
p
Mr
!
(22.19)
(22.20)
The quantity Mr is the median of the squared residual errors, i.e., Mr ≜median
k
(y[k] −
ˆy[k])2 and p = dim θ,. A data point for which wi > 2.5 is considered an inﬂuential obser-
vation.
g. Wavelet-based detection: The signal is decomposed in the time-frequency (scale) plane,
meaning into diﬀerent time-frequency bands using the discrete wavelet transform (DWT)
(see §25.1.5.1). Outliers are generally characterized by time-localized high-frequency phe-
nomena. A majority of the existing methods detect the outliers by determining the threshold
for the wavelet coeﬃcients (projections of the signal onto the wavelet basis) and then ﬁnd-
ing the index of the coeﬃcient that exceeds this threshold. Diﬀerent statistical ways of
determining this threshold are available, a popular one being the universal threshold sug-
gested by Donoho and Johnstone (1994). It is important to know that the success of this
method depends on the type of wavelet chosen and the threshold determination method.
A Haar wavelet with its discontinuity is ideally suited for outlier detection. See Bilen and
Huzurbazar (2002) and Grane and Velga (2010) for related reading.
h. Graphical methods: Outliers can also be detected by using certain specialized plots. A few
popular ones include normalized QQ plots of studentized residuals, standardized residu-
als vs. ﬁtted values, regression diagnostic plot (a plot of the standardized residuals of ro-
bust regression such as LMS or LTS, see below) versus the robust distances proposed by
Rousseeuw and Zomeren (1990), partial regression plots, etc. For details, refer to Rao et al.
(2008) and Yan and Su (2009).
The methods discussed above are by no means exhaustive. Cateni, Colla and Vannucci (2008),
Hodge and Austin (2004), and Zhang (2013) oﬀer good reviews on this topic.
Once the outliers are detected, there are diﬀerent ways of handling them such as deletion, replace-
ment, etc. A uniﬁed approach emerges by considering outliers as missing observations (although
1The nomenclature DFBETA stems from the notation used in the original work which used β j to denote the jth param-
eter.
2Not to be confused with least mean squares algorithm - popularly used in adaptive signal processing.

626
Principles of System Identiﬁcation: Theory and Practice
philosophically and technically the sources of these anomalies are diﬀerent). The merits and demer-
its of outlier handling (post detection) methods are thus similar to those for missing data treatment.
See the section on missing data for a discussion. It must be mentioned, however, that wavelet-based
techniques are superior to several others for univariate signals in that they are equipped to both deal
with detection and replacement of the outliers.
Huber and Ronchetti (2009) give excellent insights into a comparison of most of the above de-
scribed methods for outlier detection and replacement with the robust identiﬁcation approach out-
lined earlier. One of the main challenges of the two-step approach, as seen above, is that the methods
for detection and replacement are separate and mostly an iterative approach is required. The wavelet-
based method is of course an exception to this remark. Furthermore, several classical methods have
diﬃculties when multiple outliers are present in the data. In view of these challenges, Huber and
Ronchetti (2009) strongly advocate the second approach to handling outliers - that of robust regres-
sion. These methods have the advantage that they not only yield models that are not signiﬁcantly
aﬀected by outliers but they also aid in detecting outliers.
The LMS-based method for outlier detection above is an example of a robust regression formu-
lation. It has a breakdown point of 50%. However, the LMS has a very slow rate of asymptotic
eﬃciency (Rousseeuw and Leroy, 2004), i.e., it takes relatively (to LS) very large observations to
achieve small estimation errors. The least trimmed squares (LTS) formulation due to Rousseeuw
and Leroy (2004),
ˆθLTS = min
θ
T
X
l=1
˜ε2[l]
where { ˜ε[.]} = sort({ε})
descending order
(22.21a)
(22.21b)
on the other hand is not only robust but also asymptotically eﬃcient with the usual rate (as other
well-established estimators). In the formulation above, T is the trim factor, which is roughly based
on the fraction of outliers (or missing data) in the observations.
Other popular ideas for robust identiﬁcation are:
1. Replace the 2-norm (of errors) with p−norms (1 < p < 2) because the latter are robust to outliers.
2. Use the weighted least squares idea (if the outlier locations) - give, relatively, as low impor-
tance as possible to anomalous observations. Of course this assumes that the outlier locations are
known a priori.
Ljung (1999) (Chapter 9) provides asymptotic expressions that quantify the inﬂuence of norms on
the covariance matrices of parameter estimates. Based on these considerations, an optimal norm
that minimizes the sensitivity of parameter estimates to outliers can be devised. See Ljung (1999,
Chapter 15) for further details. A full technical discussion of the associated literature is beyond the
scope of this text. See Huber and Ronchetti (2009) and Rousseeuw and Leroy (2004) for a detailed
exposition of this subject.
Missing data
One of the main challenges presented by missing observations (and outliers) is the irregularity in
data which hampers the use of traditional techniques that are built on regularly spaced observa-
tions. Missing data are also commonplace in other ﬁelds such as social and behavioral sciences.
An example is the case of incomplete data due to respondents not answering all the questions in a
survey.
Irregularities in data, i.e., the distribution of time stamps, in general, are of diﬀerent kinds, de-
pending on the mechanism that generates the missing observations. To classify these mechanisms,

Statistical and Practical Elements of Model Building
627
it is useful to introduce the following taxonomy, mainly credited to Rubin (1976), who considered
the missingness as a probabilistic phenomenon.
M : Indicator matrix of missing observations
(22.22a)
f (M) : Distribution of M
(22.22b)
Zobs : Matrix of observed data
(22.22c)
Zmis : Matrix of missing data
(22.22d)
Three broad classes of missing data-generating mechanisms or scenarios are usually encountered:
i. Missing completely at random (MCAR): There is no predictability or pattern in the time stamps
of the missing observations. The conditional distribution of M is identical to the unconditional
one.
f (M|Z) = f (M)
(22.23)
ii. Missing at random (MAR): The missing observations are at random, but is dependent and only
solely on the distribution of the observed data,
f (M|Z) = f (M|Zobs)
(22.24)
iii. Missing data not at random (MNAR): Also known as missing data with a pattern, the probability
of missing data locations depends on the value of the unobserved data itself. In missing data
literature, this is also known as the case of nonignorable nonresponse.
In the context of regression, we have the additional case of missing data in the response where inputs
U1,U2,· · · ,Um are known but the measurement of output Y is missing. This problem has been well
studied. When the missingness of Y does not depend on any of the inputs and its own observations,
we have the MCAR; where the Ymis depends on the observed inputs, but not on Yobs, we have the
MAR case. Otherwise the MNAR applies. Finally, there is also the case of missing inputs when the
latter are also measured variables.
The methods available to handle missing data usually depend on which category the problem
belongs to. In reality, it may be diﬃcult to know the type of generating mechanism. A few statistical
tests are available to determine, for instance, if the missing data meets the MCAR assumption (see
Rao et al. (2008, Chapter 8)). It should also be added here that the terminology introduced by Rubin
(1976) itself suﬀers from certain ambiguities, but continues to be used in literature for practical
reasons (see Schafer and Graham (2002) for a critical exposition).
Methods for handling missing data
Methods for handling missing observations can be broadly divided into four categories:
1. Deletion methods: The strategy is to discard the locations corresponding to missing data and
only work with available observations. This is also known as the complete-case analysis in the
regression context. The technique works for steady-state model development, but has a very
limited role in developing dynamic models primarily because deleting data points ruins the serial
nature of data. Another disadvantage is that if the percentage of missing data is high, only a few
complete cases may be left to work with. Furthermore, estimates may be biased / ineﬃcient if
the distribution of missing data is not MCAR.
2. Imputation methods: The term impute in statistical language means “to ﬁll” or essentially to re-
place. The idea therefore is straightforward - replace the missing data appropriately and apply the
methods developed for complete data sets. The variety of techniques in this category essentially

628
Principles of System Identiﬁcation: Theory and Practice
diﬀer in the way they approximate the missing data. A general advantage of these class of meth-
ods is that they use existing data (thus no new information may be created) and well-established
full data set methods. However, the methods can be quite sensitive to the replacement strategy
and can lead to biased estimates. One ﬁnds two sub-categories in this class:
a. Single imputation: Methods based on this idea essentially replace each missing observa-
tion with one possible value leading to a single complete data set. In this category are the
mean imputation (replacement with the mean of observations), hot / cold deck imputation
(imputed value is drawn from a distribution, mostly derived from available observations)
and regression imputation (a model is used to predict the missing values). Among these the
mean imputation is the simplest but has perhaps the poorest performance. The regression
imputation is a popular approach and has a substantial literature Rao et al. (2008, Chapter
8).
b. Multiple imputation (MI): As an extension of the ideas in single imputation techniques,
the idea, originally introduced by Rubin (1987) here is to construct multiple possibilities
for a single missing observation, thus leading to more than one possible complete data set.
Parameter estimates are obtained for each of these completed data sets and then optimally
combined (usually a simple average is constructed) to obtain a single parameter estimate.
The MI is a modern approach and oﬀers several advantages over the traditional single imputation
approach. The resulting estimates are guaranteed to be asymptotically consistent and eﬃcient
under certain conditions (MAR assumption, ). Further, it can be applied to any data set with any
kind of analysis. However, expectedly, the computational burden is higher with MI methods.
3. Model-based approaches: Methods in this category assume a model for the observed data as well
for the missing mechanism. The maximum likelihood approach, in particular the Expectation-
Maximization (EM) algorithm due to Dempster, Laird and Rubin (1977) is a well-established
method in this context. It is based on the premise that the marginal distribution of the observed
data provides the correct likelihood for the unknown parameters under the MAR assumption.
4. Missing data as unknown parameters (MDUP): Finally, a statistically sub-optimal and a less
rigorous approach has been to treat the missing data also as unknown parameters and estimate
them along with the model parameters (Little and Rubin, 2002). This strategy oﬀers a working
solution but theoretically not sound for the prime fact that the missing measurements belong to
the random variable space whereas the model parameters are usually deterministic. On the other
hand, this approach is perhaps more appropriate in a Bayesian setting since it treats the model
parameters also as random variables.
We shall illustrate ﬁrst an example using two somewhat contrasting approaches - the robust identi-
ﬁcation based on the least trimmed squares technique described earlier and an iterative approach that
iterates between estimation of model parameters and missing data. Both methods are implemented
in MATLAB. The illustration is followed by a theoretical discussion of the more sophisticated and
rigorous MI and EM algorithms with focus on the latter.
It must be remarked that the LTS method does not require the knowledge of outlier locations,
whereas the iterative method requires one to specify the missing data / outlier locations.
Example 22.2: Identiﬁcation in Presence of Outliers (Missing Data)
Consider the following OE process:
y[k] =
2q−1 −q−2
1 −1.1q−1 + 0.24q−2 u[k] + e[k]
(22.25)
excited by a full-length (N = 2044) PRBS input in the band [0 1/4] variance of the zero-mean
GWN e[k] adjusted such that SNR is 10.
For the purpose of illustration, about 1.5% of data (30 observations) is corrupted with
outliers at random locations (the MAR case) with randomly taking on (integer) values in the

Statistical and Practical Elements of Model Building
629
range [−2ymax, 2ymax]. The uncorrupted and the outlier-ridden output proﬁles are shown in
Figure 22.3.
0
500
1000
1500
2000
−40
−20
0
20
40
Time (samples)
Outlier corrupted output
0
500
1000
1500
2000
−20
−10
0
10
20
Time (samples)
Measured output
FIGURE 22.3
Uncorrupted and outlier contaminated outputs of Example 22.2.
Only the outlier-contaminated output shown in the bottom panel of Figure 22.3 is available
for identiﬁcation. From the time proﬁle, a few outliers are visually discernible but most of
them are hidden to the eye. Estimating an OE(2,2) model without paying attention to the
outliers results in the following:
ˆB(q−1) =
2.12
(±0.072)q−2 −0.809
(±0.206)q−3;
ˆF(q−1) = 1 −0.907
(±0.144)q−1 + 0.091
(±0.11)q−2
(22.26)
The most aﬀected coeﬃcient is f2, whose true value is f2,0 = 0.24.
We shall ﬁrst implement the iterative approach based misdata routine in the System Iden-
tiﬁcation Toolbox of MATLAB. It requires the knowledge of missing data (outlier) locations.
Furnishing this information and the input-output data to the routine results in the “cleaned”
output signal, shown in Figure 22.4(a). For instructional purposes, the reconstructed output
is compared with the un-contaminated measurement in Figure 22.4(b). The NRMS metric of
ﬁt (deﬁned in (14.46)) is Rf = 0.9342. Re-estimating the OE(2,2) model but with the cleaned
0
500
1000
1500
2000
−15
−10
−5
0
5
10
15
Time (samples)
Cleaned output
(a) Cleaned (reconstructed) output
−15
−10
−5
0
5
10
15
−15
−10
−5
0
5
10
15
Un−contaminated output
Cleaned output
(b) Cleaned vs. original output
FIGURE 22.4
Output proﬁle after reconstruction of missing data (outliers).
data results in:
ˆB(q−1) =
2.056
(±0.0466)q−2 −0.905
(±0.141)q−3;
ˆF(q−1) = 1 −1.009
(±0.099)q−1 + 0.171
(±0.075)q−2
(22.27)
which oﬀers a signiﬁcant improvement over the estimates in (22.26).
Next, we run the LTS method of (22.21), which does not require the knowledge of outlier
locations, but only requires the speciﬁcaton of trim factor. Running the algorithm with T =

630
Principles of System Identiﬁcation: Theory and Practice
0.97N (rounded oﬀto the nearest integer), we obtain the model
ˆB(q−1) = 2.05q−2 −0.89q−3;
ˆF(q−1) = 1 −1.101q−1 + 0.175q−3
(22.28)
which produces nearly the same estimates as the iterative method above. The advantage is
that it was not necessary to specify the missing data locations with the LTS algorithm.
The errors in LTS estimates are not reported here. An interested reader may compute these
errors through bootstrapping methods.
Listing 22.2
MATLAB code for Example 22.2
%% Data generating process
mod_dgp = idpoly(1,[0 0 2 -1],1,1,[1 -1.1 0.24],’Ts’,1);
uk = idinput(2044,’prbs’,[0 1/4],[-1 1]);
ykdet = sim(mod_dgp ,uk);
mod_dgp.Noisevariance = var(ykdet)/10;
yk = sim(mod_dgp ,uk,simOptions(’AddNoise’,true));
%% Generate outliers
% Range of values for outlier
max_outl = round(2*max(abs(yk))); min_outl = -round(2*max(abs(yk)));
N_outl = 30;
yk_outl = randi([min_outl max_outl],N_outl ,1);
% Add outliers at random locations
outl_loc = randperm(length(yk),N_outl);
ykc = yk; ykc(outl_loc) = yk(outl_loc) + yk_outl;
ykc2 = ykc; ykc2(outl_loc) = NaN;
%% Estimate model without treatment
dataset = iddata(ykc,uk,1);
Ztrain = detrend(dataset ,0);
% Assume model orders and delays are known
nb = 2; nf = 2; nk = 2;
mod_oe = oe(Ztrain ,[nb nf nk]);
%% Estimate missing data and re-estimate model
datae = misdata(iddata(ykc2,uk,1));
Ztrain_clean = detrend(datae ,0);
mod_oe2 = oe(Ztrain_clean ,[nb nf nk]);
%% Estimate model using least trimmed squares
% Initial guess
mod_oe = oe(Ztrain ,[nb nf nk]);
theta0 = [mod_oe.b(nk+1:end) mod_oe.f(2:end)]’;
% Optimization using LTS
T = round(0.97*length(yk));
thetahat = fminsearch(@(theta) trimsq(theta,Ztrain ,[nb nf nk]’,T),theta0);
mod_oe3 = idpoly(1,[zeros(1,nk) thetahat(1:nb)’],1,1,[1 thetahat(nb+1:end)’],’...
Ts’,1);
Listing 22.3
Function returning the objective function for LTS in Example 22.2
function V_ts = trimsq(theta,Z,mod_ord ,T)
% Function to compute trimmed squares for OE models
% Read nb and nf
nb = mod_ord(1); nf = mod_ord(2); nk = mod_ord(3);

Statistical and Practical Elements of Model Building
631
% Construct the model
Bpol = [zeros(1,nk) theta(1:nb)’]; Fpol = [1 theta(nb+1:end)’];
mod_oe = idpoly(1,Bpol,1,1,Fpol,’Ts’,1);
% Compute one-step ahead prediction errors
pred_err = pe(mod_oe,Z,1);
% Return the objective function
sort_errsq = sort((pred_err.y).^2);
V_ts = sum(sort_errsq(1:T));
Among the well-established and widely applied methods for identiﬁcation of missing data, the
MI and EM algorithms are the most preferred because of their eﬃciency and versatility. The dif-
ference between these algorithms is that the former is non-iterative whereas the latter is iterative in
nature. However, a common feature is that both algorithms assume the missing data to be random
and perform averaging of some sorts over the possible values. In MI, the possibilities are generated
manually (using a Markov Chain Monte Carlo (MCMC) approach) and averaging is done on the
parameters post-estimation, whereas in EM (or ML algorithms) the averaging of likelihood is per-
formed and over all possibilities without the need to generate them. We brieﬂy present the workings
of EM algorithm below. For detailed derivations and a more formal account of the method, read
Dempster, Laird and Rubin (1977) and Little and Rubin (2002).
EM algorithm
The data set Z is partitioned into two sets, the observed data Zobs and missing data Zmis. Denote
the parameters of interest by θ. The EM algorithm is based on the maximum likelihood estimation
philosophy (discussed in §15.1).
The basic goal is to estimate the parameters from the likelihood function (which is proportional
to the p.d.f.) for the observed (available) data l(θ|Zobs). A key step in the EM algorithm is to relate
the estimation of θ from the likelihood of observed data to that from the full data as follows:
f (Z|θ) = f (Zobs|θ) f (Zmis|Zobs,θ)
(22.29)
=⇒L(θ|Zobs) = L(θ|Z) −ln f (Zmis|Zobs,θ)
(22.30)
where L(θ|.) is the log-likelihood function.
Taking the expectation on both sides of (22.30) in the conditioned missing data space, i.e., aver-
aging both sides for all possible values of missing data for a ﬁxed observation data and at a current
estimate of ˆθ(i), we obtain
l(θ|Zobs) = Q(θ| ˆθ(i)) −H(θ| ˆθ(i))
(22.31)
where
Q(θ| ˆθ(i)) = E ¯Zmis [L(θ|Z)] ,
H(θ| ˆθ(i)) = E ¯Zmis
ln f (Zmis|Zobs,θ)
(22.32)
with E ¯Zmis[X] =
Z
x f (Zmis|Zobs, ˆθ(i)) dZmis
(22.33)
The notation E ¯Zmis[.] essentially indicates expectation over all possible missing data for a ﬁxed set
of observations and the present parameter estimate. This is known as the expectation step in the
EM algorithm.
At the ith iteration, the likelihood is maximized to obtain the estimate ˆθ(i+1). This is the maximiza-
tion step. Hence the algorithm acquires its name. Note importantly that by Jensen’s inequality3,
H(θ| ˆθ(i)) ≤H( ˆθ(i)| ˆθ(i))
(22.34)
3For any convex function f and a random variable X, E(f (X)) ≥f (E(X)).

632
Principles of System Identiﬁcation: Theory and Practice
Therefore, it suﬃces to maximize Q(θ| ˆθ(i)) (also known as the auxiliary function). As a conse-
quence of the maximization of Q(.) at each iteration, one obtains the following key result in an EM
algorithm (Dempster, Laird and Rubin, 1977)
L( ˆθ(i+1)|Zobs) ≥L( ˆθ(i)|Zobs)
(22.35)
with equality occurring only when the estimates at two iterations are identical.
Remarks:
1. From the description above, it is clear that the basic philosophy of EM algorithm has an imputation ﬂa-
vor (and hence also shares similarities with the MI method as mentioned above). The main ideas are (i)
replace missing values by their estimates, (ii) estimate θ, (iii) update the estimates of missing observations
and iterate until convergence. However, the two key features of the algorithm that distinguish it from the
imputation-based algorithms are that the missing data itself is never reconstructed and that an iterative
approach is used.
2. Estimating model parameters with the likelihood function for the observed data in the EM algorithm
amounts to invoking the MAR assumption as explained below. The likelihood for observed data as used
in the EM algorithm is in fact the marginalized p.d.f. (likelihood) for the full data in the space of missing
observations
l(θ|Zobs) ∝f (Zobs|θ) =
Z
f (Z|θ) dZmis
(22.36)
Suppose the missing data mechanism, characterized by treating the indicator matrix M (consisting of ones
and zeros) is treated as a random variable (call this as M). In other words, it is assumed that the entries of
the matrix could take a one or a zero randomly. And further let β denote the parameters of the associated
distribution. Then, both the model and missing data mechanism distributional parameters θ and β are jointly
estimated by maximizing
f (Zobs, M|θ,β) =
Z
f (Z|θ) f (M|Zobs, Zmis,β) dZmis
(22.37)
Under the MAR conditions, i.e.,
f (M|Zobs, Zmis,β) = f (M|Zobs,β)
(22.38)
the likelihood in (22.37) can be factorized as
f (Zobs, M|θ,β) = f (M|Zobs,β) f (Zobs,θ)
(22.39)
With the MAR assumption, the parameters of the model and the missing data mechanism are distinct and
therefore the likelihood of observed data with and without including the missing data mechanism only diﬀer
by a proportionality constant. The main point thus follows.
3. The algorithm is applicable to a diverse range of problems, but works well only when the fraction of missing
data is small. Moreover, it converges to saddle points, i.e., local maxima and can suﬀer from slow rates of
convergence.
4. A generalized EM (GEM) algorithm attempts to ﬁnd some ˆθ(i+1) such that Q( ˆθ(i+1), ˆθ(i)) > Q( ˆθ(i), ˆθ(i))
instead of ﬁnding a maximum.
5. The EM algorithm has been used in several applications where the variables or parameters of interest are
unobserved, for example, in classiﬁcation and pattern recognition. Furthermore, as discussed in §15.1.3, the
EM algorithm is used in solving the MLE for the fully observed case as well.
6. In general, the EM algorithm is known to be sensitive to the initial guess. A few diﬀerent methods have
been studied in the context of classiﬁcation (see Biernacki, Celeux and Govaert (2003) and Melnykov and
Melnykov (2012)).

Statistical and Practical Elements of Model Building
633
The EM algorithm has been applied successfully to several identiﬁcation problems. A procedure
for applying the EM algorithm to ML estimation of state-space models in time-series modeling is
provided in Shumway and Stoﬀer (2006, Chapter 6) where the states are considered as missing
data based on the work in Shumway and Stoﬀer (1982). The auxiliary function at each stage is
constructed through the implementation of a Kalman ﬁlter by noting the connections between con-
ditional expectations and Kalman estimators. A robust algorithm is presented in Ninness and Gibson
(2005). Raghavan et al. (2005, 2006) take this a step further by applying it to the identiﬁcation of
state-space models from irregularly sampled data. Isaksson (1993) studies the parameter estimation
of ARX models from missing (output) data using the EM algorithm while giving an excellent ac-
count of other methods. A robust identiﬁcation method in presence of missing data and outliers is
presented in Tanaka and Katayama (1990). Recently, Wallin and Hansson (2014) present an exact
maximum likelihood method for estimating SISO input-output models when missing observations
occur in both input and output. An interested reader may also refer to the body of literature cited
within the aforementioned works.
The missing data problem in the prediction-error framework is treated in a similar manner above,
i.e., in the state-space models framework and using Kalman ﬁlters. See Ljung (1999, Chapter 14)
for additional details.
For a comprehensive reading on missing data literature, the reader is referred to Little and Rubin
(2002), Rao et al. (2008), and Schafer and Graham (2002). A few working tutorials on the use
of EM algorithm for identiﬁcation are available on the World Wide Web (see Holmes (2006) and
Schön (2009)). There exist also free toolboxes for robust and general identiﬁcation in MATLAB,
known as LIBRA, available for free at Brys et al. (2011) and the System Identiﬁcation Toolbox at
Ninness (2009b). An interesting discussion on missing data treatment with a somewhat catchy title
is available in Meng (2012). It must be remarked that frequency-domain methods have also been
successfully employed for identiﬁcation in presence of missing data (see Pintelton and Schoukens
(2000) for instance).
22.4.3
PRE-FILTERING
In several applications it may be desirable to emphasize ﬁts over a speciﬁc frequency range either
due to the needs of that application and/or it is known that the noise dominates the measurement
outside this band. Filtering the measurements prior to identiﬁcation is a natural strategy in this
regard. Pre-ﬁlters are also used to pre-whiten inputs (recall the pre-whitening approach for impulse
response estimation in §20.2.2.1). In the following section, we shall denote the pre-ﬁlter by L(q−1)
and the pre-ﬁltered data by
uf [k] = L(q−1)u[k],
yf [k] = L(q−1)y[k]
(22.40)
Note that, as we shall see shortly, to preserve the original deterministic input-output relationship in
the ﬁltered domain, it is necessary to use the same pre-ﬁlter for both the input and output. This was
also demonstrated in §20.2.2.1.
The main question of interest is: if a model (G, H) is ﬁt to the pre-ﬁltered data, what model is
being ﬁt to the original series? To answer this question, begin with the model for pre-ﬁltered data
yf [k] = G(q−1)uf [k] + H(q−1)e[k]
(22.41)
and bring in (22.40). Then we have the parametric model for the original inputs-outputs as (for SISO
systems)
y[k] = G(q−1,θ)u[k] + L−1(q−1)H(q−1,θ)e[k]
(22.42)

634
Principles of System Identiﬁcation: Theory and Practice
Equation (22.42) conveys an important message - pre-ﬁltering preserves the input-output relation-
ship but amounts to altering the noise model (for the original data) by a factor L−1(q−1). In fact,
this is a re-aﬃrmation of what was shown in §17.5 where one model structure for y and u could be
re-written as another model structure for the pre-ﬁltered data.
In view of the above result, it is also appropriate to study the eﬀect of pre-ﬁlters on two key
estimation properties, namely, the bias and variance.
Recall from §21.5 that the PEM-QC method for a model (G, H) results in a bias (in FRF) shaped
by γuu(ω)/|H(ejω,θ)|2 (for independently parametrized models). Replacing H(q−1,θ) with the
L−1H(q−1,θ) we obtain an important result:
The PEM estimate of the plant (deterministic) model using pre-ﬁltered data corresponds to
shaping the bias in FRF by a factor
Q(ejω,θ) = γuu(ω)|L(ejω)|2
|H(ejω,θ)|2
(22.43)
Thus, the pre-ﬁlter lends itself as another design factor in identiﬁcation (besides the input). It can
be used to emphasize good ﬁts in a certain frequency range. The choice of pre-ﬁlter depends on the
weighting function (in the criterion of ﬁt) speciﬁed by the end user.
Denoting the desired weighting by a non-negative valued function W(ω), we have (under open-
loop conditions)
|L(ejω)|2 = W(ω)|H(ejω,θH )|2
γuu(ω)
(22.44)
where θH is the vector of parameters in the noise model as before. Notice that the above result does
not oﬀer any insights into choosing the phase of the pre-ﬁlter.
Since the noise model is not known a priori, in practice it is required to iteratively determine the
pre-ﬁlter for a given weighting function with the exception of OE model structures, where the noise
model is ﬁxed to H(ejω,θH ) = 1. For the OE case therefore, the pre-ﬁlter can be determined a
priori by setting H(ejω) = 1 in (22.44).
The arguments above may also be applied in a somewhat approximate manner to the identiﬁcation
of jointly parametrized models, at least at the optimum. From the discussion surrounding (21.49)
we know that ARX models emphasize ﬁts in the high frequency range. To shift the emphasis to
frequencies excited by the input alone one could pre-ﬁlter the data (after a ﬁrst round of modeling)
with the inverse of noise model. Iterating this procedure leads to the Stieglitz-McBride algorithm
outlined in §21.6.3 (Algorithm 21.7).
Bias-variance trade-off consideration
Although pre-ﬁltering oﬀers the freedom to emphasize model ﬁts in select frequency ranges, it also
alters the noise characteristics. For instance, if y[k] is directly aﬀected by e[k] (OE process), then
yf [k] is aﬀected by ef [k] = L(q−1)e[k]. Thus, if a low-pass pre-ﬁlter such as L(q−1) = 1 + l1q−1
is used (to improve the low-frequency ﬁts), the ﬁltered data would be corrupted by low-frequency
noise. Of particular concern is that ef [k] has a higher variance (equal to σ2
e/(1 −l2
1)) than that of
e[k], which is not good news for the variance of parameter estimates. This is once again a reﬂection
of the inevitable bias-variance trade-oﬀin all identiﬁcation problems. It also calls for exercise of
caution in the use of pre-ﬁlters in identiﬁcation. See Ljung (1999, Chapter 14) for a formal design
of pre-ﬁlter with the objective of minimizing the mean-square error if ﬁt. The ﬁnal solution oﬀers
an optimal trade-oﬀbetween the bias and variance (since the mean square error is a sum of bias and
variance, recall (13.64) in this regard).

Statistical and Practical Elements of Model Building
635
22.4.4
PARTITIONING THE DATA
One of the main goals in identiﬁcation is to obtain a model with good predictive abilities. Therefore,
it is important to evaluate the estimated model in this respect. For this purpose, it becomes necessary
to partition the data into two sets - a test data set and a training data set. The test data is expected
to have primarily some “unique” characteristics with respect to the training data but also shares
some common features. Note that what is unique and common is quite subjective / qualitative and
varies with the application. An appropriate analogy is the task of partitioning the question bank for
a course into two sets - one for the homework assignments and the other for evaluation. We call
this problem as the instructor’s dilemma. Just as there is no readymade recipe for this situation, in
identiﬁcation as well there exists no formal solution to this problem.
A practical guideline is to ﬁrst construct the training data set by selecting those features that the
model should be presented with. In most applications, it is required to preserve the (time) contiguity
of observations. The test data may then be the remnant set of observations or the full data itself.
A consideration is that the test set contains at least some “new” characteristics (for example, input
frequencies not contained in the training data). Remember that the primary purpose is to test the
model’s interpolation and to a lesser extent the extrapolation abilities.
It is important to note that the same nominal point that was used in training should be used to
oﬀset the test data. It is a common mistake not to do so. This rule also applies to any other operation
performed on the data set including removal of trends, pre-ﬁltering, etc.
This concludes the presentation of tasks and methods constituting the ﬁrst step of data pre-
processing. In the following section, we discuss the problem of time-delay estimation and three
eﬀective solutions to the same.
22.5
TIME-DELAY ESTIMATION
Estimating the input-output delay as accurately as possible is crucial in several applications. In iden-
tiﬁcation, the accuracy of the delay estimate can have a signiﬁcant impact on the model estimates.
It is important therefore to study this problem at a fundamental level. We begin by studying the
deﬁnition of time delay.
22.5.1
DEFINITIONS
The true deﬁnition of delay is the time interval between the ﬁrst change in the input and the ﬁrst
(signiﬁcant) change in the response. It is independent of process dynamics. For continuous-time
systems, the delay is continuous-valued. However, in identiﬁcation of discrete-time models, delays
are expressed in samples. Moreover, there exist two deﬁnitions of delays (discrete-time), one corre-
sponding to the true one and the other arising out of approximating high-order dynamics.
1. True delay: This is the delay present in the actual physical process. The delay is best estimated
in a non-parametric manner, i.e., by making as minimal assumptions as possible on process
dynamics, (e.g., using impulse or frequency response methods).
2. Apparent delay: This is a consequence of approximating high-order processes by low-order-
plus-delay models. The original process may even have no delay in it. Therefore, this is generally
a model-induced delay and not necessarily equal to the true delay. The delay estimate is naturally
tied to the parametric model in use, and is jointly estimated along with the model parameters.
Typically an ARX model is used for ease of estimation.
Several methods exist for estimating time delays in linear systems. These techniques can be
broadly classiﬁed into (i) time domain, (ii) frequency domain and (iii) time-frequency domain-based
approaches. The focus of this text is only on the ﬁrst two classes of methods. An extensive com-
parison of techniques for delay estimation for linear systems is documented in Björklund (2003).

636
Principles of System Identiﬁcation: Theory and Practice
The survey compares several known time- and frequency-domain methods, but is not necessarily
exhaustive. Both continuous- and discrete-time delays are studied. While the thesis compares sev-
eral non-parametric and parametric (model-based) methods, the recommendation is for the latter, at
least under open-loop conditions.
We shall below describe among these many, two methods - one based on the impulse response
estimation and the other being the model-based method. In addition, a frequency-domain technique
based on the Hilbert transform relation is presented. This estimator outperforms the impulse re-
sponse estimation method and is also superior to the model-based method since it is non-parametric
in nature. The focus is on estimate of discrete-time delays.
22.5.2
IMPULSE RESPONSE ESTIMATION METHOD
The idea is straightforward and has already been applied in several illustrative examples in the fore-
going chapters of this text. Obtain the impulse response coeﬃcients from the FIR model estimates
either by LS (or WLS) techniques as described in §20.2.2. Compute the signiﬁcance levels (or the
conﬁdence intervals) using the standard expressions for LS estimators. The lag corresponding to the
ﬁrst signiﬁcant IR coeﬃcient is the time delay of the system.
ˆD = sol min
l
(g[l] > 0), l > 0
(22.45)
Alternatively, parametric estimates of the IR coeﬃcients may be obtained (using a LS or IV method)
for this purpose.
Delay estimation using impulse response estimates is similar to the cross-correlation methods
prevalent in signal processing literature (recall Example 8.4). From an estimation viewpoint, this
method of delay estimation is implicit or indirect, meaning the parameter of interest does not appear
explicitly in the estimation problem. This is evident from the problem statement above. There are
two disadvantages with this indirect approach. Firstly, it is very diﬃcult to derive expressions for
the variance of the resulting delay estimate. Secondly, which is in fact a consequence, it is hard to
determine the experimental factors that can be adjusted to minimize the error in delay estimate.
In an interesting work, Hamon and Hannan (1974) showed that this method of delay estimation is
approximately equivalent to minimizing a frequency-domain objective function explicitly involving
the delay parameter (technical details of this approximation are provided in §22.5.3). Based on
this result, Hamon and Hannan (1974) derive an approximate expression for the variance of the
cross-correlation estimator ˆDcorr when the true system is a pure delay. The expression, given below,
involves the (smoothed) auto- and cross-spectral densities as well as coherence:
var( ˆDcorr) = 1
N
1
M
M−1
X
n=0
ω2
n(1 −| ˆκ2(ωn)|) ˆγuu(ωn) ˆγyy(ωn)
*
,
1
M
M−1
X
n=0
ω2
n| ˆγyu(ωn)|+
-
2
(22.46)
where ωn = 2πn/M, n = 0,1,· · · ,(M −1)/M is the nth frequency in the Daniell window, ˆκ(.)
and ˆγyu(.) are the estimates of coherence and cross-spectral densities and M is the width of the
Daniell smoother (recall §16.5.6). The result itself is not conﬁned to Daniell’s estimates - any other
smoothed / averaged periodogram estimator may be used.
The key point is that the eﬃciency of this estimator (for the pure delay case) can be never be
higher than the frequency-domain estimator presented next. In fact, for systems with broad-band
colored input-output spectra, the relative eﬃciency can be as low as 0.3.
The arguments presented above can be extended, with additional eﬀort, to systems with dynamics
(in addition to the delay) as well. The following section presents the frequency domain method that

Statistical and Practical Elements of Model Building
637
has its origins in the work of Hamon and Hannan (1974) and later extended to SISO systems with
dynamics by Lindemann et al. (2001) and for multivariable processes by Selvanathan and Tangirala
(2010b).
22.5.3
FREQUENCY-DOMAIN ESTIMATION METHOD
The primary tools used in this method are the phase of the non-parametric estimate of FRF, speciﬁ-
cally, the cross-spectral density, and the Hilbert transform relation for causal LTI systems. The phase
of the cross-spectral density, as we know from §11.4, contains contributions from both dynamics
(numerator and denominator time constants) as well as delays at almost all frequencies. One cannot
therefore merely estimate the delay by evaluating the slope of the phase (ﬁtting a straight line) as in
Example 11.6 without discounting the eﬀects of time constants. Even in the pure delay case, where
G(z) = z−D, the method of ﬁtting a straight line to the phase produces a rudimentary estimate be-
cause the error characteristics in phase estimates change with frequency. Further, phase estimates
always have 2πm, m ∈Z ambiguities in them.
With the above motivation, Hamon and Hannan (1974) proposed a weighted non-linear optimiza-
tion that systematically takes into account the errors in phase estimate at each frequency and is
invariant to the 2π ambiguities in phase estimates,
D⋆
HH = sol max
D

J(D) = 1
M
X
ωn ∈B
W(ωn) cos( ˆφ(ω) −ˆφ(D,ω))

(22.47)
where ˆφ(D,ωn) is a predictor for the phase, in fact a known function of the delay D and frequency
ωn, while ˆφ(ωn) is the phase estimate (obtained from data). Typically it is the phase or the argument
of the cross-spectral density function. For the pure delay case, ˆφ(D,ωn) = −Dωn. The summation
can be restricted to a sub-band B or performed over the full-band of M frequencies depending on
the application and any a priori knowledge. This provision is useful, for instance, to consider only
those frequencies where the input excitation is high. The cosine function is naturally invariant to the
2π ambiguities in the phase estimates. Observe that the maximum of J(D) is sought since cosine
function reaches a peak value when the error ε(ω) = ˆφ(D,ω) −ˆφ(ω) tends to zero.
The weighting function W(ω) is introduced in the same spirit as in the WLS method, because
the phase estimate at each frequency has a variance that depends on the squared coherence at that
frequency (Priestley, 1981).
var( ˆφ(ω)) = 1
ν
 
1
|κ(ω)|2 −1
!
(22.48)
where ν refers to the number of equivalent degrees of freedom (property of the window or the
tapering function; see Emery and Thomson (2004) for instance). The optimal weighting is therefore
set to the inverse of this variance, i.e.,
W(ω) = 1/σ2
ˆφ(ω) =
|κ(ω)|2
1 −|κ(ω)|2
(22.49)
where we have discarded the equivalent degree of freedom parameter for obvious reasons.
The optimization problem in (22.47) is an integer optimization problem since D is expressed in
samples. Therefore, the objective function, J(D) is evaluated over a user-speciﬁed range of values
of the time-delay, D and the value that maximizes J(D) is the desired solution. The phase and coher-
ence estimates required for computing ˆφ(ω) and W(ω) are obtained from the smoothed estimators
in (20.57) and (16.127).
Among many advantages of this method, an important one is that the eﬀect of signal-to-noise
ratio is naturally incorporated in the optimization problem since the squared coherence is a measure

638
Principles of System Identiﬁcation: Theory and Practice
of the SNR (recall (11.54)). In practice, the theoretical squared coherence in (22.49) is replaced by
its estimate.
The delay estimator in (22.47) is asymptotically unbiased and has a normal distribution as estab-
lished by Hamon and Hannan (1974),
√
N(D⋆
HH −D0) ∼AsN (0, MQ−1)
(22.50a)
Q =
X
ωn ∈B
W(ωn) *
,
d ˆφ(D,ω)
dω
D=D⋆,ω=ωn
+
-
2
(22.50b)
Pure delay case
For this scenario, φ(ω) = −Dω. Therefore, the variance of the delay estimator is given by
var(D⋆
HH) = M
N
*.
,
X
ωn ∈B
ω2
nW(ωn)+/
-
−1
(22.51)
From a comparison of (22.46) and (22.51), it is easy to show that the variance of the correlation
estimator can never be lesser than the HH delay estimator.
The Hamon-Hannon delay estimator in (22.47) can accommodate several other complicated func-
tions of delays, among which the case of LTI system with dynamics is of wide interest. We discuss
this case next.
Systems with dynamics-plus-delay
When the system has dynamics (in addition to delay), the phase predictor is
ˆφ(D,ω) = arg ¯G(ejω) −Dω
(22.52)
where ¯G(.) is the delay-free transfer function comprising only the dynamics. The contribution of
this factor to the phase can be known if the functional form of ¯G is known. However, that would
require a parametric model ﬁt. The question is whether we can determine the ﬁrst term without
explicitly knowing the functional form? The answer is yes, and is provided by the Hilbert trans-
form relation (Oppenheim and Schafer, 1987) , which establishes a connection between the phase
and the magnitude of the FRF of a minimum-phase causal LTI system. This idea was explored by
Lindemann et al. (2001) in the estimation of delays in cortical systems. Given that this method is
founded on the Hilbert transform relation, we brieﬂy review the associated theory below.
Hilbert transform relation
The discrete-time Hilbert transform relation relates the real and imaginary parts of the DTFT of a
real-valued, causal discrete-time sequence Oppenheim and Schafer (1987, Chapter 11), say x[k].
XR(ejω) = x(0) + 1
2π P
Z π
−π
XI (ejθ) cot
 w −θ
2
!
dθ
(22.53a)
XI (ejω) = −1
2π P
Z π
−π
XR(ejθ) cot
 w −θ
2
!
dθ
(22.53b)
Here, P stands for the Cauchy principal value of the integral and XI (.), XR(.) denote the real and
imaginary parts of the DTFT of x[n].
For instance, if x[k] is the (real-valued) impulse response of a causal LTI system ¯g[k], the real
and imaginary parts of the FRF are related through (22.53a) and (22.53b). However, this does not

Statistical and Practical Elements of Model Building
639
automatically lead to a relation between the magnitude and phase of the FRF of a LTI system, which
is the one of interest.
In order to develop the desired relation, we apply the Hilbert Transform relations, particularly
(22.53b) to a new causal sequence ¯g[k] derived from ¯g[k]. This new sequence ˜g[k] is constructed
such that its Fourier transform ˜X(ejω) is the logarithm of the Fourier transform of ¯g[k],
F( ˜g[k]) = ˜G(ejω) = log( ¯G(ejω) = log | ¯G(ejω)| + j arg[ ¯G(ejω)]
(22.54)
The next step is the imposition of causality on ˜g[n], i.e., ˜g[n] = 0, n < 0. It turns out this con-
straint amounts to requiring that the system ¯G(z) is of minimum phase (see Oppenheim and Schafer
(1987)).
The sequence ˜g[k] is commonly referred to as the complex cepstrum of ¯g[k]. Invoking the Hilbert
transform relation in (22.53b) for ˜g[k] yields the desired relationship between the phase and log-
magnitude of a LTI system,
arg [ ¯G(ω)] = 1
2π
Z π
0
log | ¯G(θ)|
 
cot
 ω −θ
2
!
+ cot
 (ω + θ)
2
!!
dθ
(22.55)
Thus, when the system is minimum phase, arg ¯G(ejω) is completely determined through (22.55)
by log | ¯G(ejω)|. Furthermore, if ¯G(.) is the delay-free transfer function,
| ¯G(ω)| = |G(ejω)|
(22.56)
Combining the above identity with the fact that the relation can be computed only at discrete fre-
quencies, we obtain a practically implementable version of (22.55)
arg ¯G(ωl) =
1
2M
M
X
k=1,k,l
log |G(ωk)|
 
cot
ωl −ωk
2

+ cot
 (ωl + ωk)
2
!!
(22.57)
where it is assumed that the [0, π] is discretized into M frequencies.
Equation (22.57) is used in conjunction with (22.52) to obtain the optimal delay estimate by
solving (22.47). As mentioned previously, estimates of G(ejω) and hence its modulus and phase are
obtained using the smoothed estimator of (20.62).
Putting together the Hamon-Hannan delay estimator and the Hilbert transform relation, we have
the following algorithm for delay estimation.
Algorithm 22.1
Algorithm for delay estimation using the HH-HT method:
1. Test the input-output data for any non-zero means, drifts and trends and remove them if necessary.
2. Obtain non-parametric estimates of FRF (using (20.62), for example) and coherence using (16.127)
from pre-processed data.
3. Compute the phase and modulus of the estimated FRF.
4. Estimate the contributions of the dynamics to the phase using the HT relation (22.57)
5. Solve the optimization problem in (22.47) by evaluating it over a range of D.
6. Determine the value of D that maximizes J(D). This is the optimal estimate.
Finally, it is interesting to note that the delay estimation technique presented above can be brought
into the prediction-error framework by introducing the prediction error in phase and re-writing the
optimization in (22.47) as
J(D) =
X
B
W(ω) cos ε(ω)
(22.58)
where ε(ω) = ˆφ(ω) −arg ¯G(ω) + Dw
(22.59)

640
Principles of System Identiﬁcation: Theory and Practice
Extension of the above method to multivariable systems using partial coherence functions is pre-
sented in §26.2.
We next illustrate the foregoing method on simulated systems.
ILLUSTRATIONS
Two systems are taken up for illustration, namely, a simple transfer function model and the (non-
linear) liquid level system of Chapter 2.
Transfer function model
The transfer function model (TFM) considered for illustration is as follows:
G(z−1) =
4z−d
1 −0.3z−1
(22.60)
where d refers to the time delay. Simulation is performed for two diﬀerent output SNR levels by
exciting the system with pseudo random binary sequence (PRBS) and pulse sequence. The delay
(d) is set to 8 samples. The proposed method is applied on the input-output data to obtain J(D) for
a range of values of D. The scaled objective function is plotted against the delay parameter, D, for
the output SNR levels of 10 and 1 and the plots are shown in Figure 22.5. Both the plots clearly
identify the delay as 8 samples which is in agreement with the true delay.
0
5
10
15
20
0
0.2
0.4
0.6
0.8
1
Open loop, TFM, SNRout = 1
Objective function (J)
0
5
10
15
20
0
0.2
0.4
0.6
0.8
1
Open loop, TFM, SNRout = 10
FIGURE 22.5
Time delay estimation in open-loop SISO systems (TFM) at SNRout = 10 and SNRout = 1,
respectively.
Liquid level system
A liquid level system similar to that of Chapter 2 is considered for illustration. The diﬀerence here
is that the outlet ﬂow is assumed to be due to gravity through an aperture with a cross-sectional area
AT. The ODE governing the level dynamics to changes in inlet ﬂow rate Fi is:
dh
dt = Fi
Ac
−AT
Ac
q
(2gh + v2
2)
(22.61)
where h(t) is the level at time t, AT is the cross-sectional area of the tube at the outlet of the tank and
Ac is the cross-sectional area of the tank, g is acceleration due to gravity and v2 is velocity of ﬂuid
at the tank outlet. The output measurement is assumed to be available with a delay of 8 samples.
Simulations are carried out at two diﬀerent levels of output SNR, namely, 10 and 1. The values
of parameters that are used in the simulation are AT = 2.827 × 10−5m2 and AP = 9.5 × 10−3m2.
The objective function J is evaluated up to D = 20 lags and it is found that the maximum value of
J(D) occurs exactly at D = 9 as shown in Figure 22.6. Notice that the estimated delay includes the
contribution due to ZOH in addition to the measurement delay.

Statistical and Practical Elements of Model Building
641
0
5
10
15
20
0
0.2
0.4
0.6
0.8
1
Open loop, SNRout = 1
Objective function (J)
0
5
10
15
20
0
0.2
0.4
0.6
0.8
1
Open loop, SNRout = 10
FIGURE 22.6
Time delay estimation in liquid level system with SNRout = 10 and SNRout = 1, respectively.
To summarize, the frequency-domain method presented in this section delivers an eﬃcient and
sophisticated non-parametric estimator of time-delay for minimum-phase systems, particularly rel-
ative to the classical IR-estimation method. It should be mentioned here that violation of the min-
imum phase assumption does not lead to serious repercussions. In such situations, it is observed
from simulation studies that for “mild” violations, the method still produces the right estimate, but
otherwise yields an upper bound on the delay, usually one more than the true delay. For further
insights, the reader is referred to Lindemann et al. (2001) and Selvanathan and Tangirala (2010b)
for additional details.
In the next section, we discuss the model-based estimation method.
22.5.4
MODEL-BASED ESTIMATION METHOD
The method is fairly straightforward in nature. A search is carried out among a user-speciﬁed range
of model orders and delays using the PEM optimization algorithm (or any other suitable algorithm).
The delay of the model with the minimum loss function is deemed as the optimal delay. An OE
model structure is ideally the best suited due to its properties. However, quite often ARX structures
are chosen for ease of computation.
Delay estimates obtained using this method do not necessarily correspond to the true delays but
can also contain the apparent part due to the approximation error of the assumed model structure.
Thus, the optimal delay estimate is tied to the corresponding parametric model. Consequently, it may
be sensitive to the error characteristics in the data, i.e., the noise model of the structure. Moreover,
there are no speciﬁc guidelines on the range of or the maximum order to be chosen. An advantage,
however, is that the delay and the parameter estimates are obtained simultaneously.
The procedure is outlined below.
Algorithm 22.2
Algorithm for model-based delay estimation:
1. Test the input-output data for any non-zero means, drifts and trends and remove them if necessary.
2. Specify the parametric model structure (typically ARX), orders of the corresponding polynomials and
a range of delays.
3. Estimate the parametric model for the speciﬁed order and the delay. Loop through for all delays.
4. Compute the loss functions for each estimated model.
5. Determine the value of delay at which the loss function is the minimum among the set. This is the
optimal estimate.
MATLAB: delayest

642
Principles of System Identiﬁcation: Theory and Practice
Example 22.3: Delay Estimation in an OE(1,2) Process
We illustrate the model-based estimation method on two diﬀerent output-error processes:
S1: y[k] =
0.2q−4
1 −1.1q−1 + 0.21q−2 u[k] + e[k]
S2: y[k] =
0.2q−4 + 0.4q−5
1 −1.1q−1 + 0.21q−2 u[k] + e[k]
where e[k] ∼GWN(0,0.2). Both systems, as seen above, have an I/O delay of 4 samples.
However, S2 diﬀers from S1 in that it has a zero outside the unit circle.
A full-band PRBS input sequence of N = 1023 samples is used. For each system, the
input-output data is run through the model-based delay estimation algorithm. The delayest
routine in MATLAB with the default ARX model of orders na = 2, nb = 2 was used for this
purpose. The corresponding delay estimates are 4 and 5 samples, respectively. In the latter
case, the delay has been overestimated, possibly due to inadequate modeling (see Exercise
E22.11). For comparative purposes, the HH-HT method is also used. The delay is estimated as
4 samples for both systems. Observe that system S2 has a non-minimum phase characteristic.
When the SNR is fairly high, all delay estimation methods generally give identical estimates for
LTI systems. Theoretically, the HH-HT estimator is superior to the remaining two methods. Further-
more, it is observed to work well even for “mildly” non-stationary inputs as well (see Selvanathan
and Tangirala (2010b)). On the other hand, the model-based PEM estimator in principle has attrac-
tive properties but it requires the speciﬁcation of the “right” model. Furthermore, there exists no
theoretically straightforward way to provide error bounds on the associated delay estimates.
We next discuss aspects related to the primary task of model development.
22.6
MODEL DEVELOPMENT
This is the primal objective of identiﬁcation. It consists of three main operations: (i) selecting a
model structure, (ii) estimating the chosen model and (iii) quality assessment of the model. Chapter
21 described in detail the second operation where the PEM and IV estimators were extensively
discussed. In this section, we shall study issues and guidelines associated with the ﬁrst and third
steps. It should be reiterated that model development is iterative, where the model assessment serves
as both checks for satisfactory models and also provides clues for reﬁnement in each iteration. As
indicated in the systematic procedure for Figure 1.7, an unsatisfactory model is not necessarily a
consequence of an improper choice of model structure or estimation algorithm but could also be due
to poor experiments (e.g., inputs with poor excitation, inadequate or low quality instrumentation,
etc.).
General guidelines and recommendations for model development rest on the following fact.
The goal of modeling is to obtain the most parsimonious model that has the best properties
and with the least modeling eﬀort!
Parsimony of the model usually refers to parameter dimensionality. Attractive properties include the
usual good predictive ability, high model accuracy and precision, while the modeling eﬀort mainly
appeals to the computational complexity of the estimation algorithm. As we have learnt through the
theoretical discussions and illustrative examples in this text, these requirements are usually conﬂict-
ing in nature. The ﬁnal model is therefore always governed by some trade-oﬀs determined by the
application.

Statistical and Practical Elements of Model Building
643
22.6.1
MODEL STRUCTURE SELECTION
Selecting a model structure involves making decisions on:
i. Model type: LTI / LTV / Non-linear, etc.
ii. Domain of modeling: Time, frequency, time-frequency or any other basis space
iii. Model family: ARX, ARMAX, OE, non-linear classes, etc.
iv. Model characteristics: Order and input memory
These factors are discussed shortly,
General guideline
Start with a simple model, preferably guided by non-parametric analysis and (possibly some)
a priori knowledge, and proceed towards more sophisticated model structures guided by data
and model diagnostics.
A bottoms-up approach, i.e., a simple to more sophisticated model structure, is always recom-
mended since it minimizes the chances of overﬁtting. Any prior knowledge and/or physics of the
process should always be taken into account at every stage of model reﬁnement. For example, with
underdamped systems, a second-order system is the natural starting point. In several situations, par-
tial knowledge of the model may be available. The Bayesian approach is the best known way of
accommodating any prior or partial information
Model type and family
LTI models are advantageous in several ways as highlighted in Chapters 1 and 3. Unless the process
is known to exhibit strong non-linearity (e.g., pH systems) and time-varying in the operating regime,
it is advisable to start with a LTI model.
Time-domain models are obviously best suited for predictions, but frequency-domain models are
very useful in capturing important process characteristics. The domain of the ﬁnal model is usually
driven by the application.
The typical end-use of modeling is prediction, in which case a parametric time-domain model is
ideally congenial. In §1.4.4 we discussed the diﬀerent factors that inﬂuence the choice of candidate
LTI parametric models. We continue that discussion here with additional remarks.
1. Accuracy (bias) and precision (variance) requirements: An important aspect is the interplay
between the stochastic and deterministic parts of the model. As remarked in §1.1, the structure
of the stochastic part can signiﬁcantly alter the bias (accuracy) and variance (precision) of the
deterministic part. Recall the frequency-domain interpretations of §21.5 in this context. The OE
model produces the best approximation of the plant model for a given input, whereas the linear-
predictor ARX model gives importance to approximation errors in frequency ranges outside the
bandwidth of the plant. Finally, if data is ﬁltered, the role of pre-ﬁlter as discussed in §22.4.3
should also be taken into account.
2. Prediction accuracy and horizon: The horizon over which the prediction is sought has a signif-
icant impact on the model quality. As we have learnt earlier, minimizing one-step and inﬁnite-
step ahead predictions (the case of OE model) produce models with diﬀerent predictive abilities.
Unless otherwise explicitly demanded by the application, the one-step ahead prediction is of
interest4.
4For OE structures, the one-step and the inﬁnite-step ahead predictions are identical, recall from §18.4.

644
Principles of System Identiﬁcation: Theory and Practice
3. End-use of the model: The end application usually inﬂuences the choice of candidate as well
as the ﬁnal model. Control applications are typically content with lower-order models whereas
simulation and design applications demand ﬁne grain models.
4. Estimation aspects: Models that yield linear-in-parameter predictors are naturally preferred to
those that result in non-linear predictors, unless there is a compelling reason to choose otherwise
(for example, end-use). Recall that LTI deterministic-plus-stochastic models do not necessarily
produce predictors that are linear in parameters unlike pure LTI deterministic models, with the
exception of ARX / FIR model structure.
5. Prior knowledge: As we have noted on several occasions, prior knowledge is useful in restricting
the search to a smaller class of models or in producing physically meaningful models.
The role of visual inspection and non-parametric models in selecting an initial model structure is
signiﬁcant. Chapters 2, 17 and 20, and §22.5 provided necessary insights into this aspect.
When there are no compelling reasons (e.g., process knowledge, end-use), the “best” model is
usually chosen based on statistical considerations such as loss function value, information-theoretic
metrics such as Akaike and Bayesian Information Criterion (to be taken into account) and parsimony
of the model. Any decision on the ﬁnal model should be supported by satisfactory results from the
model assessment stage.
At the heart of model development is the estimation. From the discussions and demonstrations in
several preceding chapters, there exist many diﬀerent ways of estimating a chosen model structure.
A few guidelines and factors for consideration are discussed below.
Modeling estimation and effort
In setting up the estimation problem, the following points should be given due consideration:
• End-use of the model: As remarked above, the general requirement is that the one-step ahead
prediction errors be minimum. However, the end-use of the model may require minimization of
p-step ahead predictions. The loss function should be formulated accordingly.
• Domain of estimation: It may be easier to estimate the parameters in a domain diﬀerent from that
of the measurements. Moreover, it may be easier to derive the theoretical bounds on the errors in a
diﬀerent domain. The time-delay estimation described in §22.5 stands as an appropriate example
of this fact. In many applications (e.g., vibration machinery, acoustics) processes are naturally
characterized in frequency-domain, making it therefore the natural choice for modeling.
• Estimator complexity vs. quality: Estimation methods are characterized by the errors in the esti-
mates they produce. Likelihood methods are generally known to be the best estimators with large
sample sizes. However, the associated optimization problem is non-linear and can be computa-
tionally demanding. When an estimator such as the LS estimator, which may produce estimates
with relatively larger theoretical error but is easier on the computation, is available, it may be the
preferred choice.
The foregoing recommendations assume availability of large samples for model estimation. Small
sample identiﬁcation, an area that has attracted growing attention, requires other considerations
mainly because they either lead to under-determined problem formulations or estimates with poor
error characteristics. Compressed sensing techniques based on sparse representations of signals and
1-norm minimization techniques are emerging as powerful tools for this purpose.
Further, it may be necessary to include terms for model regularization in the objective function.
22.6.2
OPTIONS IN PARAMETRIC MODELING
In estimating the parametric model, the user has the freedom to make decisions on a few factors,
namely, (i) initial structure and conditions (for output and input signals), (ii) data pre-ﬁltering (this

Statistical and Practical Elements of Model Building
645
step may apply to estimation of non-parametric models as well), (iii) initial guesses for model
parameters (with non-linear predictors), (iv) regularization and (v) model order. Pre-ﬁltering of data
was discussed in §22.4.3. The following sections discuss the remaining aspects.
Remarks:
There exists also some freedom in matters of choosing the norm (e.g., robust vs. non-robust),
instruments (in IV methods), etc. The matter of fact, however, is that most options are eventually decided by
the application and data characteristics.
Initial structure and conditions
What is a reasonable starting parametric model structure for a given process? While several choices
exist, two promiment ones are the equation-error (ARX) and the output-error (OE) structure as illus-
trated in the liquid level case study of Chapter 2. An advantage of the ARX model structure is that
one can easily search over diﬀerent orders in a computationally eﬃcient manner (see §21.6.1.1). OE
model structures, on the other hand, result in non-linear predictors increasing the computational bur-
den. However, they result in best estimates of plant models (under open-loop conditions). Moreover,
the latter approach can be applied to a broader class of problems whereas the ARX structures are
capable of modeling a restricted class. The case studies in Chapter 24 illustrate these two diﬀerent
approaches.
Recall from Chapter 21 that the regressor vector ϕ[k] involved in the estimation of parametric
models generally consists of past outputs, inputs and possibly prediction errors. This information is
unavailable for k < 0. In other words, the regressors cannot be constructed for k < max(na,nb+nk),
in the case of ARX models or for k < max(nb +nk,nf ) for OE models and so on. In general, denote
the critical instant at which the regressor vector to be fully available by kc. There are three possible
approaches that one could adopt:
1. Conditional approach: Evaluate the loss function for instants k ≥kc. The traditional implemen-
tation of the OLS method for estimating ARX models is an example of this approach (recall
Algorithm 21.3). This strategy amounts to assuming the outputs at k < kc to be ﬁxed at their
given values or that we sacriﬁce that many samples. Computationally this is the lightest among
the three approaches, but the sacriﬁce can be signiﬁcant when the N−p is small, where p = dim θ.
2. Unconditional approach: The strategy here is similar to that used in MLE or the unconditional
LS technique. Set the prediction errors to zero for k < kc, but take into account the randomness
in the initial values. Relative to the conditional case, this strategy is computationally heavy, but
the resulting estimates have better properties.
3. Prior ﬁxation/estimation: Here, the unknown initial conditions, i.e., at negative instants, are ei-
ther ﬁxed or estimated (for example, as unknown parameters using a PEM method or as initial
conditions of states using a Kalman ﬁlter).
Preliminary estimates of models
With the exception of ARX (and FIR models) PEM estimation of all other model structures call for
non-linear optimization techniques (recall §21.6). The goodness of the resulting estimates crucially
depends on the quality of initial guesses. The methods discussed in previous chapters can be used to
fetch good preliminary estimates. Given below are some common initialization methods for speciﬁc
model structures:
1. ARMAX models: Use the multistage IV4 method described in §21.7.1. Alternatively, the PLR
method summarized in Algorithm 21.5 may be used.
2. OE models: Since the OE structure is a special case of ARMAX, one can use the same initializa-
tion algorithms as for ARMAX structure. In addition, the Steiglitz-McBride method (Algorithm
21.7) or a subspace identiﬁcation method (discussed in Chapter 23, Algorithm 23.4) with the

646
Principles of System Identiﬁcation: Theory and Practice
user-speciﬁed order, delay and K = 0. The subspace identiﬁcation may be the most preferred
since it also facilitates “automatic” estimation of the order, when it is not speciﬁed.
3. BJ models: Once again the multistage IV method with the speciﬁed orders may be used here. An
alternative strategy consists of ﬁrst ﬁtting an OE model of the requisite order followed by a time-
series model ﬁt to the residuals also provides a good initial guess. This is a two-stage method.
However, the OE model estimation itself may require an initial guess as described above. This
procedure is illustrated in the case study.
22.6.3
ORDER DETERMINATION
An appropriate model order for an identiﬁcation problem can be determined in diﬀerent ways, but
information-theoretic measures are widely used for this purpose. It is also a good practice to choose
an initial order using methodical ways rather than an arbitrary guess.
Preliminary estimates of order
Depending on the situation and the type of model, diﬀerent methods can be employed:
1. Noise models: ACF and PACF provide good indications of orders for MA and AR models. They
also provide bounds on ARMA model orders.
2. Plant models: Examination of non-parametric model estimates can oﬀer some clues. For in-
stance, if the step response estimates show underdamped characteristics, clearly a second-order
model is a good starting point. The Bode plots also oﬀer some insights - for example, the phase
and roll-oﬀin the magnitude plots at high frequencies are indicative of the order. However, more
often than not, these are of limited help.
One of the best initial guesses of the overall plant and noise model orders are oﬀered by sub-
space identiﬁcation methods (described in Chapter 23). This implies they can be used for identi-
ﬁcation of time-series models as well.
The ﬁnal choice of order is guided by residual analysis, covariance of parameter estimates and
information-theoretic criteria such as Akaike Information Criterion (AIC), Bayesian Information
Criterion (BIC), etc. that are presented next.
Information-theoretic and machine-learning criteria
Determination of order, and in general, model complexity and structure has been a problem of in-
terest for nearly ﬁve decades. Traditional approaches include the use of R2 (and its adjusted version
discussed in §14.3.2), assess improvements in residual variances through appropriate statistical tests
(such as F-tests on the ratio of variances) and so on. However, any model selection criterion should
take into account the trade-oﬀbetween bias (in predictions) and variance (of parameters), i.e., should
implicitly evaluate the price that has been paid in obtaining a model with better predictive abilities.
Information-theoretic metrics that were formally developed in the early 1970s naturally incorpo-
rated this consideration. Two widely used metrics are the Akaike Information Criterion (AIC) and
the Bayesian (a.k.a. Schwarz-) Information Criteria (SIC or BIC).The basis of these metrics is the
powerful Kullback-Leibler’s Information (KLI)5 theoretic measure (Kullback and Leibler, 1951),
which examined the distance between two (probability density) functions:
I( f,g) =
Z
f (x) log
 f (x)
g(x)
!
dx
(22.62)
5The KLI measure was proposed as a generalization of Shannon’s entropic measure of information (Shannon, 1948).

Statistical and Practical Elements of Model Building
647
In model selection, f and g could be either the true and approximated p.d.f.s or two diﬀerent ap-
proximations of some true density function.
Akaike (1973) proposed the use of expected K-L distance and established its connections with
log-likelihood (recall the AIC estimate in §21.2). The result was AIC
AIC(p) = −2L( ˆθN ) + 2p
(22.63)
where L( ˆθN ) is the log-likelihood function and p = dim(θ). The interpretation is that the ﬁrst term
represents the goodness of ﬁt (bias in predictions) achieved by the model while the second term
quantiﬁes the price paid in terms of model complexity and increase in the variance of parameter
estimates (more the parameters, higher is the error in ˆθN).
When models are estimated using quadratic loss functions V, the AIC can be written as6,
AIC(p) = N lnVN + 2p,
VN = det *
,
1
N
N−1
X
k=0
ε(k, ˆθN )εT (k, ˆθN )+
-
(22.64)
In general, as the model order is increased, the decrease in error variance is signiﬁcant compared
to the second term. However, beyond a certain order (i.e., some p) the improvement in model ﬁt is
marginal compared to the increase in p. Thus, the ideal model corresponds to a minimum value of
AIC(p). In practice, a sharp minimum is rarely seen. The AIC curve is more or less ﬂat for a range
of p. Model selection is then based on parsimony.
A corrected or an improved AIC criterion when p/N was comparable to N was proposed by
Hurvich and Tsai (1989)
AICc(p) = −2L( ˆθN ) + 2p
 
N
N −p −1
!
= AIC(p) + 2p(p + 1)
N −p −1
(22.65)
When N is large compared to p (N/p > 40), the AIC should perform well.
In general AIC is known to be conservative, i.e., can result in model with higher orders than
necessary. An alternative and perhaps a more eﬀective criterion was developed by Schwarz (1978).
Known as the Schwarz’s Information Criterion, it was developed to select the “best” model from
a set of models based on maximization of posterior densities, i.e., in a Bayesian setting (therefore
also came to be known as BIC).
BIC(p) = −2L( ˆθN ) + p ln N
(22.66)
with a form similar to AIC but with a diﬀerent cost or penalty term. In the context of quadratic cost
function minimization, the BIC takes the form
BIC(p) = N lnVN + p ln N
(22.67)
where VN is as described in (22.64). Based on the earlier arguments for AIC, the desired model is
the one which has a minimum BIC.
In a contemporaneous work by Rissanen (1978) in the ﬁeld of machine learning (inductive in-
ferencing) theory, a metric termed as minimum description length (MDL) was introduced for
selecting the model that was the most “learned.” The basic assertion in Rissanen’s work was that
6The deﬁnition AIC(p) = lnV + 2p
N is also commonly used.

648
Principles of System Identiﬁcation: Theory and Practice
the “ability to learn” (to model) is related to the “ability to describe.” Therefore, the model with the
shortest description length is ideally desirable.
MDL(p) = −2L( ˆθ) + p ln N
(22.68)
Interestingly enough, MDL and BIC, although originating from diﬀerent approaches have identical
expressions.
Finally, another widely used index for model selection is the ﬁnal prediction error (FPE) crite-
rion once again due to Akaike (1969) but now in the context of ﬁtting auto-regressive models using
LS methods.
FPE(p) = JLS( ˆθ) 1 + p/N
1 −p/N ≈JLS( ˆθ) (1 + 2p/N)
(when N/p ≫1)
(22.69)
The reader is referred to Rao et al. (2008) and Ljung (1999) for technical presentations of the
above measures.
Remarks:
A model selected based on one of the above measures does not immediately qualify as the ﬁ-
nal choice. It has to still go through the gates of model quality assessment checks before being accepted as
satisfactory.
Regularization
Over-parametrization, as we have seen in a few illustrative examples in Chapters 2 and 14, leads to
models with poor predictive abilities. Traditional means of avoiding this involves a careful analysis
of parameter estimation errors and a step-wise increase of model complexity. Regularization al-
lows the user to over specify the model parameters with an appropriate penalty term. An important
consideration is the bias-variance trade-oﬀ. While regularization reduces model error variance, it
also introduces bias. Recall §20.2.3 where a method for IR estimation with regularization based on
Bayesian considerations was discussed. Several modern identiﬁcation practices now consider regu-
larization as a default choice, particularly where there are a large number of parameters to estimate
(for example, in subspace identiﬁcation). Read Johansen (1997), Ljung (2013), and Ljung and Chen
(2013) for discussion on classical techniques and new approaches.
We shall now discuss the ﬁnal, but a very important step, in model development.
22.6.4
MODEL QUALITY ASSESSMENT AND VALIDATION
The identiﬁed model is assessed in two phases, namely, (i) training and (ii) test phase (also known
as cross-validation).
Training phase
The objective is to determine if the model has captured the characteristics of training data with
reasonable accuracy and reliability, i.e., if the ﬁt is satisfactory (test for unbiasedness) and that the
errors in parameter estimates are low (test for variance and no over-parametrization has occurred).
It may be recalled that in several illustrative examples of previous chapters, models were tested for
this property through (residual) correlation plots and (parameter estimation) error analysis. A formal
discussion now follows.
The assessment consists of three components, in that order:
1. Tests for model bias via statistical analysis of residuals:
A good model is one which has rightly captured all input eﬀects and the predictable portions
of the residuals y −Gu. In view of these expectations, the key requirements for an acceptable

Statistical and Practical Elements of Model Building
649
model are that the residuals (a) should be uncorrelated with the input and (ii) should not exhibit
any temporal correlation. In other words, there is no residual information left for the model to
capture.
a. Test for bias in plant model G:
The ﬁrst requirement above translates to insigniﬁcant cross-correlation between residuals
and inputs, i.e.,
σεu[l] ≈0, ∀l
(22.70)
The insigniﬁcance of σεu[l] = 0 is tested statistically using the 100(1 −α)% (typically
α = 0.05 or 0.01) signiﬁcance levels for the CCF. For this purpose, the theory outlined
§16.4 is used. While this is a routine step in identiﬁcation, the technically correct way of
implementing the procedure is to pre-whiten either the residuals or the input prior to the
computation of cross-correlation and the signiﬁcance levels. Recall Example 16.1, which
showed how one is led to false inferences by not doing so. On the other hand, if the input or
residual ε[k] is white, then the pre-whitening step is not necessary. See also Example 22.4
below.
When the residuals pass the cross-correlation test, we conclude that the characteristics of
the plant G have been adequately identiﬁed.
Example 22.4: Residual-Input Cross-Correlation Test
Consider the open-loop measurement generating process (an FIR(4) model)
y[k] =
5
X
n=2
bn,0u[k −n] + e[k],
e[k] ∼GWN(0,σ2
e)
(22.71a)
where u[k] is zero-mean and has white-noise characteristics.
Suppose that an FIR(2) model is identiﬁed for the process:
ˆy[k] =
3
X
n=2
b⋆
nu[k −i]
(22.71b)
where b⋆n is the limiting estimate (N →∞) of the parameter7.
Then, the limiting prediction error is given by
ε[k] = y[k] −ˆy[k] =
3
X
n=2
(bn,0 −b⋆
n)u[k −n] +
5
X
n=4
bn,0u[k −n] + e[k]
(22.71c)
Thus, the residual-input cross-correlation is theoretically,
σεu[l] = E(ε[k]u[k −l])
=
3
X
n=2
(bn,0 −b⋆
n)σuu[l −n] +
5
X
n=4
bn,0σuu[l −n]
(22.71d)
For white inputs σuu[m] = 0, ∀m , 0. Thus we have,
ρεu[l] =

(bl,0 −b⋆
l )/α,
l = 2,3
bl,0/α,
l = 4,5
0,1
l ≥0,|l| > 5
(22.71e)
7In reality, we should use estimates obtained from ﬁnite observations. However, for ease of mathematical analysis we
have used the limiting estimates.

650
Principles of System Identiﬁcation: Theory and Practice
−30
−20
−10
0
10
20
30
−0.2
0
0.2
0.4
0.6
lag
ρε u[l]
0
5
10
15
20
25
−0.5
0
0.5
1
lag
ρε ε[l]
(a) Residual correlation plots
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF of input
Lags
(b) ACF of inputs
FIGURE 22.7
(SEE COLOR INSERT) Residual analysis of the model and ACF of the inputs used in Example
22.5.
where α =
qP3
n=2(bn,0 −b⋆n)2 + P5
n=4 b2
n,0.
If the limiting estimates are unbiased, i.e., under open-loop conditions, the correlation
is non-zero at lags l = 4,5, exactly indicating the missing terms in the model. If the
correct model structure is identiﬁed, the cross-correlation would be zero at all lags.
Need for pre-whitening
Here we demonstrate the need for pre-whitening ε or u[k] in using ρεu for model assess-
ment when the input has colored noise characteristics. In the previous example, suppose
u[k] was colored (which is the general case as well). Then the expressions derived for σεu
do not apply since the auto-correlation of u[k] comes into play. In fact, the parameter es-
timates are biased (by virtue of the properties of PEM methods). The exact expression for
σεu therefore depends on the bias and the ACF of u[k].
Two important consequences are that (ii) ρεu could be non-zero at lags other than those in
the true model (exact missing terms are not known) and that the correlation can be non-zero
at any lag. The latter is serious since non-zero correlation at zero lag can suggest no delay
while that at negative lags can implicate feedback, both of which are most likely spurious
artifacts introduced by the internal correlation of the input. Furthermore, the widely used
signiﬁcance level for cross-correlation given in (16.39) is only valid when one of the series
is white.
The following example numerically illustrates the foregoing points on the FIR(4) process
of Example 14.2.
Example 22.5: Residual Analysis with Pre-Whitening
Consider the FIR process of Example 14.2
y[k] =
5
X
n=2
bn,0u[k −n] + e[k],
e[k] ∼GWN(0,σ2
e)
(22.72)
with b2,0 = 0.3,b3,0 = 1,b4,0 = 0.2,b5,0 = 0.2, u[k] being a PRBS input containing
frequencies in the band [0 1/5] and σ2e adjusted to SNR 10.
An FIR(2) model is estimated using the LS method from N = 2555 observations. The
estimate of cross-correlation ρεu[l] (implemented by the resid routine in MATLAB’s
System Identiﬁcation toolbox, 2013b version) are shown in Figure 22.7(a). No pre-
whitening is performed in computing the cross-correlation. The cross-correlation is

Statistical and Practical Elements of Model Building
651
−20
−15
−10
−5
0
5
10
15
20
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
CCF
Lags
(a) Residual correlation plots
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF of pre−whitened input
Lags
(b) ACF of inputs
FIGURE 22.8
Residual analysis of the model and ACF of the inputs after pre-whitening.
signiﬁcant at several lags including l = 0,−1. A meaningful interpretation for model
reﬁnement cannot be made from this plot due to the colored nature of the input
(whose ACF is shown in Figure 22.7(b)) and the residuals (top panel of Figure
22.7(a)). For instance, correlation at negative lags cannot be interpreted as presence
of future input eﬀects, i.e., feedback.
The input is now pre-whitened using an MA(4) model (recall §16.4 and §20.2.2.1
for the pre-whitening procedure), and the CCF between residuals and pre-whitened
input was estimated. Figure 22.8(a) shows the CCF estimate. The signiﬁcant corre-
lations at lags can now be rightly interpreted as the residuals containing signiﬁcant
eﬀects of past inputs. Moreover, the spurious correlations at negative and zero lags
disappear.
It must be added, however,that the lags corresponding to signiﬁcant correlations do
not directly oﬀer any useful clues for model reﬁnement due to the complicated eﬀects
of bias in parameter estimates ˆb2 and ˆb3. Model reﬁnements should then be made
by ﬁtting successively higher order models and using the information criteria. The
ﬁnal model has to still pass the residual analysis tests.
It should be mentioned that when the “correct” plant and noise models have been identiﬁed,
the residuals are white and therefore no pre-whitening is necessary. However, this is diﬃcult
to know a priori (since this is what we seek to test) and therefore pre-whitening the input is
essential for cross-correlation computation.
Model-error model
An alternative and perhaps a more eﬀective way of testing for the adequacy of plant model
is to develop what is known as the model-error model, Gεu Ljung (1999, Chapter 16).
The IR estimates of the model-error model for the estimated FIR(2) model in the preceding
example are shown in Figure 22.9. If the model has adequately captured the deterministic
eﬀects, all the IR estimates would be statistically insigniﬁcant (within the band). Further-
more, as in the CCF with pre-whitening case, any signiﬁcant correlation at lags less than
the order can be interpreted as applying this criterion. Figure 22.9 reveals the shortcomings
of the FIR(2) model for the process in Example 22.5.
Qualitatively there is no diﬀerence between using cross-correlation with pre-whitening and
impulse response for assessing the model bias since both work with cross-covariances; they
only diﬀer in the normalization factors. From an estimation viewpoint, however, the IR
coeﬃcients are easier to generate since a LS method is used whereas for pre-whitening one
may have to ﬁt an ARMA model as was the case in the example.

652
Principles of System Identiﬁcation: Theory and Practice
FIGURE 22.9
Impulse response of the model-error model corresponding to the FIR(2) model estimated in
Example 22.5.
Remarks:
It is suﬃcient to check for remnant eﬀects of past inputs alone and not past outputs as
well in the residuals (even if G has regressive terms) since outputs are essentially linear functions of
past inputs, i.e., we can always re-write G in a convolution form.
Test for feedback / incorrect delays
The cross-correlation test with input pre-whitening and the impulse response of the model-
error model can be used to detect the presence of any intrinsic feedback or regulatory mech-
anism between the input and output. Theoretically, the feedback manifests as signiﬁcant
correlation in ρεu[l] at negative lags or as signiﬁcant IR coeﬃcients of Gεu(q−1) at nega-
tive times. Feedback eﬀects are also reﬂected in non-zero IR coeﬃcients of the input-output
model as well.
Incorrect delays in the input-output model can also be estimated using above methods. The
characterizing signature is that insuﬃcient delays manifest as signiﬁcant correlation at lags
less than the postulated delay.
b. Test for bias in noise model H:
The criterion for noise model to pass the bias test is straightforward - the residuals should
have white noise characteristics. Therefore, one needs to apply the whiteness tests dis-
cussed in §16.4. The Box-Ljung statistic or its modiﬁed version deﬁned in (16.45) and
(16.46), respectively, are widely used for this purpose.
Remarks:
When the model under analysis belongs to the OE class, it is suﬃcient to subject the
model to test for signiﬁcance in cross-correlation alone since there is no provision in the structure to
explain noise models.
To summarize, the goodness (unbiasedness) of plant and noise models are tested through
a proper correlation analysis of the residuals. If the estimated models are unbiased, the
CCF ρεu[l] (pre-whitened input) and the ACF ρεε[l] should be insigniﬁcant at all lags.
Impulse response analysis of model-error-model oﬀers an alternative way of testing for the
unbiasedness in plant models. In addition, the presence of feedback may also be tested by
the foregoing methods.
2. Test for variance of models via error analysis of estimates: While the previous step tests
for bias in the estimated models, it is important to examine whether the unbiasedness has been
achieved at the cost of variance. This constitutes the purpose of analyzing the errors in parameter
estimates. It is important that this second check is carried out only after the model has passed
the correlation analysis test above. This is necessary since the expressions for estimation error
computations in Chapters 14, 15 and 21, it may be recalled, assume that the functional form has
been adequately captured and that the residuals are white.

Statistical and Practical Elements of Model Building
653
The prime requirement for a model to pass this test is that the (standard) errors should be small
relative to the estimated values. In other words none of the conﬁdence intervals for the individ-
ual unknowns (parameters) should include a zero. As described in §13.12 this is equivalent to
a hypothesis test of H0 : θi = 0, ∀i = 1,· · · ,p. The reader may recall that in several illustra-
tive examples we have used this check for over-parametrization. Recall Example 14.5 on FIR
estimation using the least squares method in this context.
3. Evaluation of model responses: Once the model has passed the bias and variance tests above,
it is useful to simulate the model responses - both elementary (impulse, step and frequency) and
those to the inputs used in training. For the former, the model response may be compared with
the non-parametric estimates while the response to input may be compared to the observed out-
put. The ﬁts may be assessed both by visual examination and quantitative metrics (for example,
NRMS in (14.46)).
A model that has successfully passed the above-mentioned tests in the training phase is ready to be
examined on a test data.
Testing phase
As remarked earlier, the main objective of this test is to assess the model’s predictive abilities on a
fresh data set. The prime purpose of this test, known as cross-validation, is to evaluate the model’s
extrapolation capabilities. The performance can be tested in two diﬀerent ways:
• Finite-step prediction: Usually models are trained for delivering good one-step (or a ﬁnite-step)
ahead predictions. Therefore, in the least, an acceptable model should perform well in this re-
spect.
• Inﬁnite-step prediction: This is the case of simulation as was discussed in §18.4. In the absence
of any end-use requirements, this is a preferred test for any model. Since the inﬁnite step ahead
prediction of any stochastic model is zero, noise models should not be subjected to this test.
If a model performs satisfactorily on the training data but fails the cross-validation test, then there
could be two reasons:
1. Overﬁtting: the model has captured variations that are local to the training data than actually
capturing the global characteristics of the process.
2. Improper test data: the test data may have features that are distinctly diﬀerent from what the
model has seen in the training data.
While the ﬁrst cause requires a re-evaluation of model’s overparametrization, the second cause calls
for an appropriate fresh data.
The information criteria presented earlier in §22.6.3 evaluate the performance of the model in the
training and testing phases.
Chapter 24, which is also the ﬁnal chapter in Part IV, presents case studies implementing the
procedures and methods described in this chapter. Particular attention may be paid to case studies
in §24.2 and §24.3.
22.7
SUMMARY
In this chapter we studied certain statistical, mathematical and a few empirical methods for in-
put design, data pre-processing, time-delay estimation and model development. The material in
this chapter along with the theoretical developments of the previous chapters provide the complete
know-how for implementing the systematic identiﬁcation procedure outlined in Chapter 1.

654
Principles of System Identiﬁcation: Theory and Practice
To highlight the important lessons from this chapter - a single frequency allows estimation of
a two-parameter model. The frequency content of the input plays a critical role in the model that
can be identiﬁable, i.e., the ability to discriminate or resolve between two candidate models. Input
should be persistently exciting for maximum resolvability between models. Visual analysis and pre-
processing of data is an important preliminary step in identiﬁcation. Outliers and missing data can
present special challenges with the former one being more diﬃcult to handle. There exist special-
ized ways of treating both anomalies in a uniﬁed framework using robust identiﬁcation, imputation
(multiple and iterative) and the expectation-maximization methods.
Model development usually begins with a non-parametric model gradually developing into a para-
metric model through a careful choice of structure, order and estimation algorithms. Input-output
delays are estimated by time- and frequency-domain non-parametric or model-based methods. The
decisions involved at various stages of the parametric model development are guided by the insights
from non-parametric analysis, information criteria, prior knowledge (if any) and end-use require-
ments. The ﬁnal step of model quality assessment is critical to identiﬁcation since it not only eval-
uates the model bias and variance characteristics but also oﬀers clues for further reﬁnement. The
assessment consists of three distinct tests, residual analysis, error analysis of parameter estimates
and cross-validation.
Illustrative examples were presented as a demonstration of the systematic procedure and some of
the concepts outlined in this chapter.
REVIEW QUESTIONS
R22.1 Explain what is meant by informative data.
R22.2 Describe the primary role of input in identiﬁcation, particularly in the ﬁnal model that is identiﬁed.
R22.3 What is crest factor and why is it important in input design?
R22.4 List the diﬀerent classes of inputs that are widely used and their merits / demerits.
R22.5 Explain what a full-length PRBS means and the special properties that it holds.
R22.6 How does one generate a band-limited PRBS?
R22.7 Can you highlight some advantages and disadvantages of using periodic signals as inputs in
identiﬁcation?
R22.8 Describe the diﬀerent methods available for outlier detection.
R22.9 Explain the basic methodology of the EM algorithm.
R22.10 What is multiple imputation and how is it helpful in handling missing data?
R22.11 What are the elements of a model structure?
R22.12 How is time-delay deﬁned?
R22.13 List two methods for time-delay estimation.
R22.14 Describe the salient steps in model quality assessment.
R22.15 What are the tests available for testing bias in plant and noise models?
R22.16 Explain what is meant by model variability and its role in the ability of the model to predict on
a fresh data set.
R22.17 Describe the diﬀerent information criteria discussed in this chapter. What are their uses?
R22.18 Why should not the inﬁnite-step ahead prediction test be used to assess the goodness of a noise
model?
R22.19 Explain what is meant by cross-validation.

Statistical and Practical Elements of Model Building
655
EXERCISES
E22.1 Show that an input with n frequencies can identify a 2n parameter model.
E22.2 Suppose that we want to generate an input signal u[k] with the spectral density
Φuu(ω) =
1
1.36 + 1.2 cos ω
Then,
a. Determine a stable ﬁlter H(q) that will generate the desired sequence u[k] = H(q)e[k], the
zero-mean unit-variance white-noise sequence.
b. Determine the variance of u[k].
E22.3 Verify by simulations that a PRBS sequence with band limited to [0 1/P] is generated as a
white-noise passing through a MA(P −1) ﬁlter.
E22.4 Derive the ﬁrst- and second-order properties of a full-length PRBS sequence, as given in (22.6a)
and (22.6b).
E22.5 Determine combinations of non-zero coeﬃcients that are diﬀerent from those listed in Table 22.1
for the generating polynomial of full-length PRBS sequences for M = 9,10,11, respectively.
E22.6 Show that the presence of feedback is reﬂected as a signiﬁcant correlation between the residuals
and inputs at negative lags.
E22.7 Show that the crest factor of a multisine can be as high as
√
2M when all amplitudes are equal.
E22.8 Show that the step function is a persistently exciting signal of order one.
E22.9 The input and output of a process is observed to behave according to the following relationship:
y[k] = 0.5q−3 + 1.2q−4
1 −0.7q−1
u[k] +
1
1 −0.7q−1 e[k]
where e[k] is normally distributed i.i.d. noise with mean zero. Choose variance of e[k] such that the
SNR with respect to the output is 10. Do/answer the following:
a. Use MATLAB/SIMULINK to simulate this process. Generate a full length samples of prbs
input sequence in the band [0 1/5] for this purpose. Divide the data set into training and test
(validation) data sets.
b. Plot the data and approximately estimate time-delay and the order of the system.
c. Remove constant data trends using the detrend command.
d. Estimate the FIR model and ﬁnd the time-delay estimate. Can you say if there is a fractional
time-delay?
e. Fit an input-output model using the ARX structure. Starting from model order na = 1,nb = 1,
ﬁnd the model orders that ﬁt the data best. Justify the choice of ﬁnal model orders. Compare
the model predictions on the training and test data sets.
f. Compute the 95% conﬁdence intervals for the true estimates.
g. Find the best OE model that ﬁts the data. How does the plant model fare in comparison with
that obtained using the ARX structure?
h. Fit a noise model that ﬁts the residuals best.
i. Using the combined plant and noise models above as the initial guess, estimate a BJ model.
j. Compare the estimated BJ model with the ARX model. Select the appropriate one for the
process.
E22.10 With the model-based delay estimation method in Example 22.3, obtain the suitable ARX model
orders that produce the “correct” delay for the process.
E22.11 Investigate the cause for the failure of ARX models in estimating the correct delay for the OE
process used in Example 22.3.

23
Identiﬁcation of State-Space Models
This chapter presents the main ideas, philosophy and techniques constituting the identiﬁca-
tion of state-space models, especially subspace identiﬁcation methods. Linear algebra-based
projection and decomposition algorithms for optimal (Kalman) estimation of states are dis-
cussed in detail. A review of the ubiquitous Kalman ﬁlter is brieﬂy presented. The chapter
also discusses popular specialized algorithms such as N4SID, MOESP and CVA. Subspace
methods are equipped with a semi-automated technique for order determination, which is
also delineated. This chapter also introduces the ideas of grey-box identiﬁcation in the con-
text of developing structured state-space models. MATLAB-based examples are presented to
illustrate the ideas at each stage of the developments.
23.1
INTRODUCTION
A general state-space representation for a deterministic (MIMO) process was given in §4.4:
x[k + 1] = Ax[k] + Bu[k]
(23.1)
y[k] = Cx[k] + Du[k]
(23.2)
where x, y and u are nx × 1, ny × 1 and nu × 1 vectors, respectively; A, B, C and D are nx × nx,
nx × nu, ny × nx and ny × nu matrices, respectively.
For a deterministic plus stochastic process, the representation is
x[k + 1] = Ax[k] + Bu[k] + wx[k]
(23.3a)
y[k] = Cx[k] + Du[k] + wy[k]
(23.3b)
where wx[k] and wy[k] are (vector) random processes known as state noise and measurement noise
(or output noise), respectively. These are assumed to be stationary with the following statistical
properties
E(wx[k]wx[k]T ) = R1
(23.3c)
E(wy[k]wy[k]T ) = R2
(23.3d)
E(wx[k]wy[k]T ) = R12
(23.3e)
In §4.4, the advantages of state-space models over the traditional input-output representations
were discussed, among which the ease of identifying multivariable systems and their suitability
for joint identiﬁcation and state estimation stood out in particular. The numerical eﬃciency of the
associated identiﬁcation techniques known as the subspace identiﬁcation algorithms, as we shall
learn in this chapter, add to the beneﬁts of these model forms.
For ease of discussion, we shall in most of the technical developments assume the system to be
SISO, but that does not take away any of the aforementioned beneﬁts since generalizations to MIMO
systems are straightforward.
Equivalence of (23.3) to the general input-output deterministic-plus-stochastic model in (17.2) is
obtained through the standard techniques for converting SS to TF models presented in §4.4.4,
y[k] = G(q−1)u[k] + v[k] = G(q−1)u[k] + H(q−1)e[k]
(23.4)
656

Identiﬁcation of State-Space Models
657
where
G(q−1) = C(qI −A)−1B + D
v[k] = C(qI −A)−1Bwx[k] + wy[k]
(23.5a)
(23.5b)
An explicit expression for H(q−1) such that v[k] = H(q−1)e[k] depends on the nature of the state
and measurement noise sequences.
The (unconstrained) state-space identiﬁcation problem is stated below.
Given N observations of input u[k] and output y[k], determine the appropriate order n, identify
state-space matrices A, B, C, D, the initial state x[0] and the second-order statistical properties
of the noise, namely, R1, R2 and R12.
The branch of identiﬁcation that studies the problem above is popularly known as subspace iden-
tiﬁcation. The reason for the name subspace stems from the method itself, which is explained in
§23.6. Subspace identiﬁcation algorithms are not equipped with the ability to handle the imposition
of any constraints on the structure of state-space matrices, which may arise whenever a state-space
form corresponding to a transfer function form or a physical representation is desired.
On the other hand, when we are concerned with identifying a structured state-space model, i.e.,
matrices with speciﬁc structure, one usually gives up the subspace route and takes the help of PEM
or optimization methods. Section 23.7 is devoted to this topic.
A simple and natural solution to the problem of state-space identiﬁcation, is of course, to identify
an input-output model ﬁrst and then convert it into one of the canonical forms discussed in §4.4.3.1.
The example below illustrates this idea.
Example 23.1: State-space form of an ARMAX(2,1,2) model
Consider the symbolic ARMAX(2,1,2) process:
y[k] =
b1q−1 + b2q−2
1 + a1q−1 + a2q−2 u[k] +
1 + c1q−1
1 + a1q−1 + a2q−2 e[k]
(23.6)
Writing the diﬀerence equation form and introducing states
y[k] + a1y[k −1] + a2y[k −2] = b1u[k −1] + b2u[k −2] + e[k] + c1e[k −1] + c2e[k −2]
x1[k] = y[k] −e[k]; x2[k] = −a1y[k −1] + c1e[k −1]
yields the state-space form
x[k + 1] =
"−a1
1
−a2
0
#
x[k] +
"b1
b2
#
u[k] +
"(c1 −a1)
(c2 −a2)
#
e[k]
(23.7)
y[k] =
f
1
0
g
x[k] + e[k]
(23.8)
where, on comparison with the form in (23.3), we have
wx[k] = Ke[k]; K =
"(c1 −a1)
(c2 −a2)
#
wy = e[k]
The obtained SS model is in the observable canonical form.
Subspace identiﬁcation methods directly estimate the state-space model from input-output data
through a series of linear algebraic operations. Thus, a total of 4 + 2 + 2 + 2 = 10 unknowns
(excluding the variance of σ2
e) are estimated for the ARMAX(2,1,2) vis-a-vis 5 parameters in an
input-output method.
Then, a natural question that arises is: why is there a need to study the problem of state-space
identiﬁcation afresh? We shall learn a few important reasons below that warrant a fresh study.

658
Principles of System Identiﬁcation: Theory and Practice
Why and when subspace identiﬁcation?
One of the shortcomings of the TF to SS method is that the mapping from input-output to state-
space domain is not unique (recall §4.4.4). Thus, we run into identiﬁability issues in this approach,
i.e., the problem of estimating a unique SS model. Subspace identiﬁcation methods also suﬀer from
the identiﬁability issue since they do not explicitly impose identiﬁable structures on the state-space
models (recall §18.6.2). The fact is that we can only identify state-space models in some basis, over
which we may have little or no control. Formally we say that subspace algorithms identify state-
space models uniquely only up to a non-singular transformation, or that they construct a realization
of the system.
A major impediment with the use of classical input-output approaches for multivariable systems
is that, the delays and orders that have to be determined grow substantially with the dimensionality
of the system. Subspace methods, on the other hand, are equipped with, in principle, an automated
method for order determination. Recall the introductory liquid level example of §2.4, where we
determined the order of the system without the need for an explicit initial guess.
Another natural idea that can be used to estimate the state-space matrices, is to use the SS to
TF equivalence for state-space identiﬁcation, i.e., write the input-output relation in terms of the
state-space entries and subsequently deploy a PEM method to estimate the unknowns. However, a
complicated non-linear optimization problem would result. The following example elucidates this
point.
Example 23.2: Estimating a Second-Order SS Model
Consider a fully parametrized, unit-delay deterministic second-order SISO state-space model
x[k + 1] =
"a11
a12
a21
a22
#
x[k] +
"b11
b21
#
u[k]
y[k] =
f
c11
c12
g
x[k]
The transfer function equivalent of this system is
G(q−1) = C(qI −A)−1B + D =
b1q + b2
det(qI −A)
where b1 and b2 are complicated functions (involving products) of the elements of A, B and
C matrices. The parameter vector of interest is
θ =
f
vec(A)
vec(B)
vec(C)
gT
where vec(.) is the vectorization operation, i.e., stacking up columns of the matrix one below
the other.
Due to the complicated non-linear map between θ and the parameters of G(q−1), PEM
methods for estimating θ involve a non-linear optimization problem with complicated gradi-
ents, possible convergence in addition to identiﬁability issues.
The number of parameters to be estimated is also large. Of course, one could use the canoni-
cal forms as in the foregoing example to alleviate this problem. However, for multivariable sys-
tems, constructing an identiﬁable form is not a trivial task. There exist, what are known as pseudo-
canonical forms or overlapping parametrizations, which oﬀer identiﬁable structures. They reduce
the number of parameters considerably, but other technical complications arise in the implementa-
tion of the PEM algorithm, for example, the need to switch from one identiﬁable structure to another
during the course of optimization; see Katayama (2005).
When there is no speciﬁc information available on the “structure” of θ, and there is no com-
pelling reason to arrive at a unique state-space model, it may be advisable to turn to the subspace
identiﬁcation method.

Identiﬁcation of State-Space Models
659
To summarize, SSID algorithms are superior to PEM in terms of ease of estimation, numerical
eﬃciency, convergence and order determination. These advantages stem from the fact that they
are based on linear algebra and projection algorithms which are non-iterative in nature. It may
be reiterated here that these advantages hold good only when the user has no preference for a
particular structure for any or all of the state-space matrices or a speciﬁc basis for the states. These
descriptions can be termed as unstructured state-space models in contrast to structured descriptions.
These are often also known as the freely or fully parametrized vs. structured or parametrized state-
space models.
Innovations form
In the context of state-space identiﬁcation, quite often although one begins with the SS model in
(23.3), the identiﬁed state-space model is usually re-written in terms of what is known as the inno-
vations form
x[k + 1] = Ax[k] + Bu[k] + Ke[k]
y[k] = Cx[k] + e[k]
(23.9a)
(23.9b)
where K is the Kalman gain and e[k] is the usual zero-mean (Gaussian) white-noise process. That
this is a natural outcome of state-space identiﬁcation is justiﬁed by the argument that algorithms
that produce optimal state-space models are also expected to optimally estimate the states. Thus,
the primary diﬀerence between the description in (23.3) and (23.9) is that the states in (23.9) are
Kalman states, i.e., the optimal state estimates. It may be noted that the prime diﬀerence between
the state estimates produced by a Kalman ﬁlter (given a SS model and the noise statistics) and the
one delivered by SS identiﬁcation algorithms is that the basis of representation is ﬁxed and known
in the former, while in the latter, estimates of states are obtained in some basis, over which we
may have very little control. Thus, SSID algorithms also have Kalman ﬁlters built into them, but
numerical ﬁlters, i.e., purely based on data and those that do not require the explicit knowledge of
the model.
Structured state-space models
The foregoing discussion suggests that it may be wiser to impose some structure on the state-space
models in order to ensure identiﬁability. However, the challenge is to guarantee that the chosen
structure is identiﬁable. Structured state-space models are typically referred to as canonical forms.
Structural constraints on SS matrices may also be motivated by ﬁrst-principles considerations and
physical meaningfulness of the resulting states, essentially in a grey-box context. In general, sub-
space identiﬁcation methods are not equipped to handle these situations since projection algorithms
are generally not capable of incorporating constraints on unknowns.
Estimation of structured state-space models require the use of PEM optimization methods. A
generalization of identifying structured SS models is the grey-box modeling wherein the parameters
are allowed to “enter” the state-space matrices in an arbitrary manner. These aspects are discussed
in §23.7 and §23.7.2, respectively .
Outline of this chapter
The basic ideas and methods of subspace identiﬁcation algorithms for estimating the innovations
form of (23.9) constitute the bulk of this chapter. Emphasis is given to the approach and conceptual
understanding of the methods, while explaining the salient mathematical steps. A complete technical
derivation of these methods is beyond the scope of this text. These details are found in texts that
exclusively deal with subspace identiﬁcation. Two excellent resources are Overschee and Moor
(1996) and Katayama (2005).

660
Principles of System Identiﬁcation: Theory and Practice
In §23.2, the basic ideas and mathematical preliminaries are provided, wherein the necessary
linear algebra concepts pertaining to projections are also explained. A review of the traditional
Kalman ﬁlter is provided in §23.3 where the innovations form of state-space model is presented.
The main algorithm for subspace identiﬁcation is presented in §23.6. The deterministic case is
discussed ﬁrst to ﬁx the key ideas, followed by an overview of the methods for the real data, i.e., the
deterministic-plus-stochastic case.
Parametrization of state-space models, especially those leading to canonical forms and their es-
timation using PEM methods are presented in §23.7. Grey-box models, which are state-space de-
scriptions with their structures derived from ﬁrst-principles models, form the concluding topic of
this chapter. Much of the presentation to follow has its roots in Ljung (1999), Overschee and Moor
(1996) and Katayama (2005).
23.2
MATHEMATICAL ESSENTIALS AND BASIC IDEAS
Subspace identiﬁcation algorithms are built on four important concepts, as brieﬂy described below.
1. Observability: This concept was introduced in §4.4.3.1. The observability matrix O deﬁned in
(4.59) plays a critical role in subspace identiﬁcation. Firstly, it facilitates the determination of
the order n since it is the rank of an observable minimal realizable state-space system. Secondly,
its deﬁnition in (4.59) allows us to estimate A and C matrices. Further, it determines the ability
to reconstruct the initial state vector x[0] given output and input data. In subspace algorithms,
the basic idea is to construct what is known as an extended observability matrix, from which the
order, matrices A and C are determined.
2. State estimator: The subspace identiﬁcation problem is challenged by the fact that the states are
unknown variables. Therefore, any least squares formulation would result in an NLS problem.
Knowing the state-space matrices, of course, would permit us to use the Kalman ﬁlter for op-
timal estimation of states. Since this is not the case, subspace identiﬁcation methods deploy a
numerical Kalman ﬁlter to obtain states (without the knowledge of system matrices) followed by
a least squares algorithm on the state-space model to estimate the matrices.
3. Realization theory: This is concerned with building state-space representations of deterministic
and stochastic systems from either measurements (empirical) or input-output descriptions (theo-
retical). The latter was the topic of §4.4.3.1 in the context of deterministic systems. Development
of realizations from data, which is of prime interest here, was pursued by several researchers
decades ago. Notable among these contributions are those by Ho and Kalman (1966) for deter-
ministic processes, and Akaike (1974b) and Faurre (1976) for stochastic processes. The method
of Ho and Kalman constructs deterministic state-space models from Hankel matrices of impulse
responses (see §23.4.2.1). The subspace identiﬁcation methods essentially extend these ideas to
developing models from arbitrary input-output data for the deterministic-plus-stochastic case.
The key idea is to use Hankel matrices of input-output data combined with elimination of noise
eﬀects using suitable projections or instrumental variable ideas. Numerical implementation of
these methods is eﬃciently carried out using QR and SVD factorization.
Stochastic realization methods on the other hand construct state-space models for random pro-
cesses from time-series data. The resulting descriptions and methods are essentially state-space
counterparts of the classical time-series models of Chapters 9, 11 and 19. More recently, a uniﬁed
realization theory that constructs state-space models of stochastic signals in presence of exoge-
nous eﬀects has been developed (Katayama, 2005). This has once again analogy to the viewpoint
of developing input-output models by treating the outputs as stochastic signals in presence of
exogenous inputs. The mathematics of the associated methods is relatively more involved, but is
ﬁnally implemented once again using linear algebra methods such as SVD and QR factorization.
We shall not pursue these methods here and instead refer the reader to the pertinent chapters of
Katayama (2005).

Identiﬁcation of State-Space Models
661
4. Projections: As remarked above, subspace identiﬁcation methods largely work with orthogonal /
oblique projections of output measurements onto appropriate spaces. Therefore, a basic knowl-
edge of projections, orthogonal complements, etc. is indispensable to a proper understanding
of these methods. It may be noted that it is these projection-based approaches that gives them
the name and also the non-optimization ﬂavor to subspace methods. Notwithstanding this fact,
estimates obtained from subspace identiﬁcation methods can be shown as solutions to the mini-
mization of multi-step prediction-error criteria.
23.2.1
BASIC APPROACH
There exist two diﬀerent approaches in subspace identiﬁcation. Both methods are based on input-
output data and make identical assumptions on the data generating mechanism, namely,
• All the observable states have been suﬃciently excited.
• Input satisﬁes the persistent excitation condition.
• Open-loop conditions, implying states and inputs are not in feedback.
The two broad approaches are as follows:
1. Estimate the extended observability matrix (to be deﬁned shortly) through an SVD of the projec-
tions of the output onto appropriate spaces. From this estimate, construct the estimates of A and
C followed by estimates of matrices B, D and the initial state vector x[0]. The Kalman gain K
is then computed using the estimates of state-space matrices and noise covariances as described
later in §23.3. If required, optimal estimates of states can also be computed from the extended
observability matrix.
2. Estimate the optimal states using a numerical Kalman ﬁlter followed by estimation of state-space
matrices A,B,C,D using ideas of linear regression. The residuals of the resulting model serve in
estimating the statistical properties of the state and measurement noise. Finally, K is estimated
from the noise covariances.
The most widely practiced method follows the ﬁrst approach, although its superiority, if any, over
the latter remains to be theoretically studied. On the other hand, these seemingly distinct approaches
can be uniﬁed under a single scheme with diﬀerent user-deﬁned choices, as brieﬂy summarized in
§23.6.2.5.
The developments in the rest of this chapter are organized as follows. First, in §23.2.2, we shall
brieﬂy explain the concepts of observability and controllability, both of which are central to SS iden-
tiﬁcation. Following which, §23.3 presents the theory of the celebrated Kalman ﬁlter and develops
the innovations form. The foundational concepts for subspace identiﬁcation, namely, the realization
theory, speciﬁcally the Ho and Kalman’s method for deterministic systems, and projections (deﬁ-
nitions and numerical implementations) are presented in §23.4. The centerpiece of this chapter is
§23.6, which presents the three subspace identiﬁcation algorithms and the uniﬁed theory. We close
the chapter with a brief presentation on structured state-space models including the parametric and
grey-box models.
23.2.2
OBSERVABILITY AND CONTROLLABILITY
The deﬁnition of an observability matrix for a LTI system and its prime utility was provided in (4.59)
and the discussion surrounding it. The development below explains the origins of this concept. We
shall assume a SISO system for the rest of the discussion without loss of generality.

662
Principles of System Identiﬁcation: Theory and Practice
Observability
Suppose the free response of an n-dimensional (nth order) system with a known state-space de-
scription (A,B,C,D) is available and the problem is that of determining the state vector x[k] (or
equivalently the initial condition x[0]). Then, it is required to set up n equations for the n unknown
states in terms of the outputs at n instants:
y[k] = Cx[k]
y[k + 1] = CAx[k]
...
...
y[k + n −1] = CAn−1x[k]
where we have made use of the fact that u[k] = 0.
Stacking the observations and the coeﬃcient matrices we have
yn[k] = Onx[k]
(23.10)
where
yn[k] =

y[k]
y[k + 1]
...
y[k + n −1]

; On =

C
CA
...
CAn−1

(23.11)
A unique solution to the state estimation is guaranteed clearly if and only if the observability
matrix On is non-singular, i.e., of full rank (equal to the order n). This is also true even when
for the forced response case (when u[k] , 0).
When the observability matrix satisﬁes the above condition, the system is said to be observable (in
the deterministic sense). The estimate of the initial state is given by
x[0] = O−1
n y
(23.12)
Note that the observability matrix On has the dimensions n×n (or (n×ny) × (n×ny) for a MIMO
system with ny outputs). Further, a change of basis for the states x = Tw results in the observability
matrix OnT for the new states.
Devices that estimate states from observations of output are known as observers, sometimes used
to refer to deterministic systems. The Luenberger observer is a widely used state estimator for
such systems. In the presence of noise, evidently it is required to estimate the states in an optimal
manner. This problem was rigorously formulated and studied by Kalman, which culminated into the
celebrated Kalman ﬁlter (Kalman, 1960; Kalman and Bucy, 1961)
Controllability
Identiﬁcation of state-space models also requires the system to be controllable, because to be able
to identify the minimal realization, i.e., the observable part of the system, the user should also be
able to excite all the observable states by suitable inputs. This is the problem of controllability and
more precisely reachability.
Deﬁnition 23.1. An LTI system G = (A,B,C,D) is said to be reachable (in L, L < ∞steps) if there
exists an input sequence that takes the system from the origin to a desired state xd in L steps.

Identiﬁcation of State-Space Models
663
Strictly speaking, the system is reachable only if the set of reachable states is the entire state
space. Controllability is concerned with the ability to drive the system from a non-zero initial state
x[0] , 0 to its equilibrium (origin) x = 0 in ﬁnite steps.
It turns out that an input sequence (for reachability) exists if and only if the matrix
Cn =
f
B
AB
· · ·
An−1B
g
(23.13)
is of full row rank (n is the order of the system). Thus, the system is reachable if and only if the
matrix Cn is of full rank. This is also the condition for controllability (unless A is singular). We shall
use the term controllable for the rest of the discussion to mean both properties.
As with observability, controllability matrix also modiﬁes to T−1Cn under a state transforma-
tion. However, the properties themselves are invariant to similarity transformations. Associated with
these properties are those of detectability and stabilizability (see Åström and Wittenmark (1997) and
Chen (1998) for further details).
Remarks:
The roles of controllability and observability matrices in identiﬁcation are equally important; how-
ever the use of observability matrix in estimating state-space models is more pronounced due to its importance
in the pure stochastic case as well.
23.3
KALMAN FILTER
The technicalities of Kalman ﬁlter (KF) and its development are studded with some inevitable math-
ematics. Before we plunge into the related equations, it is therefore instructive to discuss a simple
example that we shall later use for a numerical illustration of KF as well.
Example 23.3: Recursive Estimation of Mean: KF Viewpoint
Recall the problem of estimating mean of a random signal discussed in a few of the earlier
chapters. In Chapter 12, for instance, we derived the least squares estimate of the mean,
which turned out to be the sample mean
ˆµN = ¯xN = 1
N
N−1
X
k=0
y[k]
(23.14)
The same problem can now be cast in the context of state estimation, by treating the mean
(unknown parameter) as a state, i.e., x[k] = µ and essentially estimating this state from the
given measurements. Now consider the following practically encountered situation.
Suppose we have ¯xN and we wish to estimate ¯xN+1 upon the arrival of the measurement
y[N + 1] in a recursive fashion, i.e., without re-evaluating (23.14) altogether. Then it is easy
to derive such a recursion,
ˆµN+1 =
1
N + 1
N
X
k=0
y[k] +
1
N + 1 y[N + 1]
=
N
N + 1 ˆµN +
1
N + 1 y[N + 1]
(23.15)
Thus, we have a recursive optimal estimate of the mean.
Introducing K ≜
1
N + 1, and ˆx[k] ≜ˆµk at the kth instant, we obtain a useful way of writing
the recursion,
ˆx[k + 1] = (1 −K) ˆx[k] + Ky[k + 1]
= ˆx[k] + K(y[k + 1] −ˆx[k])
(23.16)

664
Principles of System Identiﬁcation: Theory and Practice
Finally, recognize that
ε[k] = y[k + 1] −ˆx[k] = y[k + 1] −ˆy[k + 1|k]
(23.17)
is the optimal prediction error since the best prediction of y[k + 1] given all the observations
up to k is E(y[k +1|k]) = ˆµk itself. Moreover, prior to the arrival of y[k +1] (or in its absence)
our estimate of mean is ˆµk itself. We could also generalize the idea to have a time-varying
Kk, which is useful when the true mean changes with time.
Thus, we have the recursion as an update to the prior estimate by an amount proportional
to the prediction error:
ˆx[k + 1] = ˆx[k] + Kk (y[k + 1] −ˆy[k + 1|k])
(23.18)
This is the essential idea of a Kalman ﬁlter - predict the state estimate at k using all the
information up to k −1 and recursively update (or correct) it proportional to the prediction
error. The proportionality constant is known as the Kalman gain.
At a later stage, post-derivations of the KF equations, we shall numerically illustrate the above
idea in Example 23.4.
The problem setup for optimal state estimation as proposed by Kalman is as follows. Suppose
observations of input and output from the following generating process are available.
x[k + 1] = Ax[k] + Bu[k] + wx[k]
y[k] = Cx[k] + Du[k] + wy[k]
Σwxwx = Q,
Σwywy = R
wx[k] ∼GWN(0,Q);
wy[k] ∼GWN(0,R)
x[0] ∼N (µ0,P0);
corr(x[0],wx) = 0
(23.19a)
(23.19b)
(23.19c)
(23.19d)
(23.19e)
Notice that we have assumed the noise sequences to be stationary. However, the theory applies even
when the covariance matrices are functions of time.
Remarks:
1. The above set of assumptions are collectively referred to as the Gauss-Markov model. In fact, the noise
processes wx, wy and x[0] are jointly Gaussian. The tag Markov comes about since under the prevailing
assumptions, it can be shown that the state process x[k] is Markov, i.e., f (x[k + 1]|x[k],x[k −1],· · · ,) =
f (x[k + 1]|x[k]). In other words, it is a ﬁrst-order vector auto-regressive process.
2. The problem formulation can easily accommodate cross-correlation between state- and process-noise de-
ﬁned by
S = E(wxwT
y )
(23.20)
but we shall study the uncorrelated case ﬁrst.
3. A slightly more general version relaxes the Gaussianity assumption, accommodates correlation between
the state and observation noise and only speciﬁes the second-order statistics without alluding to a particular
distribution.
4. An important assumption on which the development of Kalman ﬁlter rests is that the system in (23.19) is
observable, i.e., all the states can be uniquely estimated from the measurements.
With the above setting, the optimal state estimation problem due to Kalman (1960) is stated as
follows.

Identiﬁcation of State-Space Models
665
Given
1. Measurements up to the kth instant,
Zk ≜{z[k],z[k −1],· · · ,z[0]}
where z[k] = {y[k],u[k]}.
and
2. An observable state-space model of the generating process A, B, C and D and the noise
covariance matrices Q and R
determine the optimal estimate of the state x[k].
The problem can be divided into two sub-problems by noting that Zk = {Zk−1,z[k]}, as stated
below.
1. Given Zk and the state-space model, determine the optimal (MMSE) prediction of the state
vector x[k]
ˆx[k|k −1] = arg min
g(.) tr
f
E((x[k] −g(Zk−1))(x[k] −g(Zk−1))T )
g
(23.21)
2. Given optimal prediction ˆx[k|k−1] and the observation z[k], determine the optimal (MMSE)
estimate (ﬁltered) of the state vector x[k],
x[k|k] = arg min
h(.) tr
f
E((x[k] −h( ˆx[k|k −1],zk))(x[k] −h( ˆx[k|k −1],zk))T )
g
(23.22)
The variables ˆx[k|k −1] and ˆx[k|k] are known by diﬀerent names such as a priori and a posteriori,
predicted and corrected estimates, respectively. In certain presentations, notations such as ˆx−[k] and
ˆx[k] are used to denote the predicted and ﬁltered estimates, respectively. Collectively, the estimator
is known as Kalman predictor-corrector ﬁlter.
Solution
From Chapter 18, we know that the MMSE prediction of a random variable X given Y is the condi-
tional expectation E(X|Y). In the context of optimal state estimation, we have thus
ˆx−[k] ≜ˆx[k|k −1] = E(x[k]|Zk−1)
ˆx[k] ≜ˆx[k|k] = E(x[k]|{ˆx[k −1], y[k]})
(23.23a)
(23.23b)
for the predicted and ﬁltered estimates, respectively.
Associated with these estimates are the errors (covariances)
P−
k ≜cov(ˆx−[k], ˆx−[k]) = E((x[k] −ˆx−[k])(x[k] −ˆx−[k])T )
(23.24)
Pk ≜cov(ˆx[k], ˆx[k]) = E((x[k] −ˆx[k])(x[k] −ˆx[k])T )
(23.25)
Optimal prior estimate (prediction)
The optimal one-step ahead prediction of x[k] is obtained by applying (23.23a) to the given state-
space model in (23.19),
ˆx−[k] = AE(x[k −1]|Zk−1) + Bu[k −1] = A ˆx[k −1] + Bu[k −1]
P−
k = E((x[k] −ˆx−[k])(x[k] −ˆx−[k])T ) = APk−1AT + Q
(23.26a)
(23.26b)

666
Principles of System Identiﬁcation: Theory and Practice
where ˆx[k −1] is the estimate of state at (k −1), and Pk−1 is the associated covariance matrix. Notice
that the input does not contribute to the error in the state estimates; it results in only a mean shift.
This optimal prior estimate of the state has a Gaussian distribution,
(x[k]|Zk−1) ∼N (ˆx−[k],P−
k )
(23.27)
Optimal posterior estimate
When the measurement arrives at the kth instant, the optimal a posteriori estimate at k is provided
by (23.23b). We shall also additionally require that this estimate be a linear combination of ˆx−[k]
and y[k]
ˆx[k] = Kx[k]ˆx−[k] + Ky[k]y[k]
(23.28)
where K1[k] and K2[k] are appropriate gains to be determined. One of the primary reasons for the
form in (23.28) is to achieve computational eﬃciency through recursion.
Remarks:
A natural question that arises here is whether the linear form of the estimator desired in (23.28)
will result in the optimality of the conditional expectation estimator in (23.23b). This question was answered
in §18.2. Optimality is guaranteed so long as x[k] and Zk are jointly Gaussian, which holds for the generating
process of (23.19).
The ﬁrst requirement of the estimator in (23.28) is that it should be unbiased. Imposing this
requirement in combination with (23.26a) and (23.19), it is possible to show with some algebraic
manipulations (see Exercise E23.1) that
Kx[k] = I −Ky[k]C
(23.29)
leading to a nice form for (23.28)
ˆx[k] = ˆx−[k] + Ky[k](y[k] −Cˆx−[k])
(23.30)
Remarks:
The diﬀerence ε[k|k−1] = y[k]−C ˆx−[k] is in fact the one-step ahead prediction error correspond-
ing to the prediction ˆy[k|k −1] of the measurement using the optimal state estimate in (23.26a). Therefore, the
form in (23.30) has a nice interpretation - update or correct the prediction proportional to the prediction error.
Consequently, the gain Ky[k] essentially takes the role of a time-varying proportional feedback controller.
What remains, of course, is the determination of the optimal value of Ky[k]. For this purpose, we
appeal to the minimization of the trace in (23.22). The solution to this optimization problem can be
derived in diﬀerent ways (see Chapter 6 of Rao et al. (2008) for a statistical perspective). We only
present the ﬁnal result due to Kalman and Bucy (1961).
Kopt
y [k] = P−
kCT (CP−
kCT + R)−1
(23.31)
This optimal gain Kopt
y [k] is widely known as the Kalman gain and shall be denoted simply as Kk
in all future references.
The error in the optimal ﬁltered or the posterior estimate turns out to be,
Pk = (I −KkC)P−
k
(23.32)
It is essentially an update equation to the covariance matrix of the prior.
Remarks:

Identiﬁcation of State-Space Models
667
Time Update (Predict)
Measurement Update (Correct)
1. Compute the Kalman gain
Kk = P−
k CT (CP−
k CT + R)−1
2. Calculate the posterior estimate
ˆx[k] = ˆx−[k] + Kk(y[k] −Cˆx−[k])
3. Compute the posterior covariance
Pk = (I −KkC)P−
k
1. Given ˆx[k−1] and its covariance Pk−1, com-
pute the prior estimate
ˆx−[k] = Aˆx[k −1] + Bu[k −1]
2. Compute the prior covariance
P−
k = APk−1AT + Q
Initial Guess
ˆx[0], P0
FIGURE 23.1
Prediction-correction algorithm in a Kalman ﬁlter state estimator.
1. Equations (23.26a) and (23.30) are known as the time update and measurement update equations, respec-
tively. They are implemented in succession over every two consecutive sampling instants. The Kalman
predictor-corrector ﬁlter is summarized in Figure 23.1. An initial guess of the state vector is naturally re-
quired to trigger the algorithm.
2. The Kalman gain, which determines the level of importance given to the prediction error, is naturally a
function of both the measurement error (signiﬁed by R) and the prior state estimation error (signiﬁed by
P−
k ). Both these factors have contrasting eﬀects on the gain and should be understood on a relative basis.
When the conﬁdence levels in the measurements are high / low, i.e., R is very small / high, the gain is
large / low, meaning the update should / should not trust the measurement. On the other hand, when the
prior estimates are reliable / not reliable, i.e., P−
k is small / large, Kk is small / large, meaning less / more
signiﬁcance should be attached to prediction errors.
3. Observe that the prior, posterior covariance matrices and the Kalman gain can be computed oﬄine without
the aid of measurements - a mere knowledge of the state-space matrices, in particular, A, C and the noise
covariance matrices is suﬃcient. Consequently, the standard errors in state estimates can be computed
without actually computing the estimates themselves!
4. The prediction error y[k] −C ˆx−[k] at the optimum is known as the innovation, typically denoted by e[k]
(recall the use of this term in §18.3 in the context of predictions using input-output data). Its variance is
given by
Σk ≜var(e[k]) = CP−
k CT + R
(23.33)
=⇒Kk = P−
k CΣ−1
k
(23.34)
where the second equation is a re-written form of (23.31) for the Kalman gain. The innovations form of
(23.9) is based on this concept. For further discussion, see §23.3.2 below.
5. In deriving the Kalman gain above, an LTI model was assumed. However, the results also apply to the case
of linear time-varying models as well, i.e., the state-space matrices and/or the noise covariance matrices are
allowed to be functions of time.
6. A combined expression for the projected covariance Pk |k−1 = P−
k in (23.32) can be provided in terms of
the covariance of state estimate at k −1 as follows:
Pk |k−1 = APk−1|k−2AT + Q −APk−1|k−2CT (CPk−1|k−2CT + R)−1CPk−1|k−2AT
(23.35)
by making use of (23.26b), (23.32) and (23.31). The expression above is also known as the discrete-time
matrix Riccati equation, which appears extensively in optimal control problems.

668
Principles of System Identiﬁcation: Theory and Practice
7. For LTI systems, the recursion for the prior covariance theoretically reaches a steady-state Pk |k−1 =
Pk−1|k−2 = P, resulting in what is known as the discrete-time algebraic Riccati equation (DARE).
P = APAT + Q −APCT (CPCT + R)−1CPAT
(23.36)
Consequently, the Kalman gain K[k] also steadies out to a ﬁxed value K.
8. In a real-time implementation, the ﬁlter is initialized with guesses of ˆx[0|0] and P0|0 (a positive deﬁnite
matrix). A time update is implemented, i.e., ˆx[1|0] and P−
1 are computed, using (23.26a) and (23.26b),
respectively. When the measurement y[1] becomes available, these estimates are updated using (23.30) and
(23.32), respectively, to obtain ˆx[1|1] and P[1|1]. This process is continued at each time step.
9. The idea of Kalman ﬁltering has a strong resemblance to Bayesian estimation since it is based on ﬁnding
the MMSE estimates of states. The prime diﬀerence is however that the KF is still a classical estimator in
the sense that it produces optimal point estimates of states along with a p.d.f. of the error, whereas Bayesian
estimators directly produce interval estimates in the form of p.d.f. of the state vector.
10. Finally, the optimal estimates produced by KF can be shown to be as orthogonal projections of the states
onto the space of measurements by setting up the problem in the Hilbert space framework where the inner
products are deﬁned as expectations of products in the space of zero-mean random variables. In such a setup,
the innovations are orthogonalized measurements. Recall a similar result for the least squares parameter
estimates where the optimal solution satisﬁes the projection theorem. These connections oﬀer an important
viewpoint that aids in developing numerical Kalman ﬁlters without the explicit knowledge of the model - a
core step of subspace identiﬁcation algorithms (see §23.6).
Knowledge of noise covariance matrices
Computation of Kalman gain, state estimates and the covariance matrices clearly require the knowl-
edge of state and measurement noise covariance matrices Q and R, respectively. This information
is usually not easily available in practice, especially the state noise covariance, because there is no
easy access to the states and it also depends on the choice of states. Estimates of the measurement
error R can, however, be obtained with relative ease from steady-state data. In this respect, sys-
tem identiﬁcation plays a useful role in yielding the requisite estimates of Q and R (along with the
state-space model).
In the absence of any knowledge of these matrices, one uses Q and R as tuning parameters in
Kalman ﬁlter implementations. The relative magnitudes of Q and R signify the trust that can be
placed on the prior estimate compared to the measurement.
We are now in a position to numerically illustrate the introductory Example 23.3 concerned with
the recursive estimation of mean.
Example 23.4: Recursive Estimation of Mean: Re-Visited
We revisit the familiar case of estimating the mean of a random signal, or alternatively, a
constant embedded in noise (recall §12.2 and §15.1.1):
y[k] = c + e[k],
e[k] ∼GWN(0,σ2
e)
A state-space model for this signal is
x[k + 1] = x[k](= c)
(23.37)
y[k] = x[k] + e[k]
(23.38)
where the input terms are absent for obvious reasons. To bring it up to the generating process
of (23.19), we shall introduce a state-noise term w[k] with the noise variance Q and use it as
a tuning parameter to control the noise levels. Note that R = σ2e and S = 0 for the example.

Identiﬁcation of State-Space Models
669
0
10
20
30
40
50
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
0.55
Time (samples)
Estimate
(a) State estimate with TVKF
0
10
20
30
40
50
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Time (samples)
Error variance
(b) Error variance with TVKF
0
10
20
30
40
50
0.05
0.1
0.15
0.2
0.25
0.3
Time (samples)
Estimate
(c) State estimate with SSKF
FIGURE 23.2
Kalman ﬁlter estimates of a constant signal with choices Q = 0.0001 and R = 0.01.
We choose the values c = c0 = 0.27 and σ2e = 0.01 for generating N = 50 data points.
The purpose of illustration is not merely to show the eﬀectiveness of Kalman ﬁlter but
to also show the inﬂuence of the tuning parameters in a relative sense. To demonstrate the
latter, we consider two choices for the measurement noise covariance in the ﬁlter, R = 0.01
(true value) and R = 1 (100 times less reliable than the previous case), while ﬁxing Q =
0.0001. Furthermore, the performances of time-varying and steady-state Kalman ﬁlters are also
compared.
Figure 23.2 shows the results for the ﬁrst setting. The time-varying KF converges to the
true value on the average much quicker than the steady-state, while the error covariance of
the TVKF converges to the steady-state value of P = 9.5125 × 10−4 very quickly. The initial
guesses in both versions of the ﬁlters are set to ˆx[0] = 0.1048, while P0 = 0.5 in the TVKF.
The dashed line in the plots stand for the true value of the constant.
In the second case, the ﬁlter is tuned with R = 1, i.e., increased by 100 times, essentially
indicating to the ﬁlter that the measurements are much less reliable than before. The results
are shown in Figure 23.3.
While the estimates are smoother (since measurements are given lower importance, i.e., not
allowing the randomness to inﬂuence quickly), the error covariance in the TVKF decreases
much slower and does not converge to steady state in the given time. This is unlike what was
observed for the previous case.
Listing 23.1
MATLAB function for KF implementation
function [xhatk,Pxk] = KalmanFilt(mod_ss ,noisecov ,xh_prev ,Px_prev ,zk)
% Function to compute time-varying Kalman filter estimates xhat[k|k] given
% the [state-space model, noise covariances], the [state estimates at ’k-1’
% xhat[k-1|k-1], the error covariance at ’k-1’] and the measurement at ’k’
%
% Note: For discrete -time systems only
% Read state-space and noise covariance matrices

670
Principles of System Identiﬁcation: Theory and Practice
0
10
20
30
40
50
0.05
0.1
0.15
0.2
0.25
0.3
Time (samples)
Estimate
(a) State estimate with TVKF
0
10
20
30
40
50
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Time (samples)
Error variance
(b) Error variance with TVKF
0
10
20
30
40
50
0.05
0.1
0.15
0.2
0.25
0.3
Time (samples)
Estimate
(c) State estimate with SSKF
FIGURE 23.3
Kalman ﬁlter estimates of a constant signal with choices Q = 0.0001 and R = 1.
A = mod_ss.A; B = mod_ss.B; C = mod_ss.C; D = mod_ss.D;
Q = noisecov.Q; R = noisecov.R; S = noisecov.S;
% Read I/O data
ny = size(C,1); nu = size(B,2);
yk = zk(1:ny); uk = zk(ny+1:end);
% Compute prior estimate (prediction) and error covariance
xhatk_prior = A*xh_prev + B*uk;
Pxk_prior = A*Px_prev*A’ + Q;
% Compute Kalman gain
Kalm_k = Pxk_prior*C’*inv(C*Pxk_prior*C’ + R);
% Compute correction (update) for the states and the error covariances
xhatk = xhatk_prior + Kalm_k*(yk - C*xhatk_prior);
Pxk = (eye(size(A)) - Kalm_k*C)*Pxk_prior;
Listing 23.2
MATLAB script for the Kalman ﬁlter Example 23.4
% SCRIPT TO DEMONSTRATE KALMAN FILTER
% ESTIMATING A CONSTANT SIGNAL IN NOISE
%% Generating process
A = 1; B = 0; C = 1; D = 0;
G = 1; H = 1; Ts = 1;
sys_const = ss(A,[B G],C,[D H],Ts);
sysdet_const = ss(A,B,C,D);
% Noise covariances
noisecov.Q = 0.0001; noisecov.R = 1; noisecov.S = 0;
% Generate data

Identiﬁcation of State-Space Models
671
N = 50; c0 = 0.27;
uk = zeros(N,1); yk = randn(N,1)*0.1 + c0;
kvec = (0:N-1)’;
%% Steady-state Kalman filter
[kest,L,P,M,Z] = kalman(sys_const ,0.0001,noisecov.R,0);
yxest = lsim(kest,[uk yk],kvec ,0.065);
% Plot the estimates
figure; plot(kvec,yxest(:,2)); hold on
plot(kvec,c0*ones(length(kvec),1),’r--’);
%% Time-varying Kalman filter
% Initialize state and error covariance vector
xhat = []; Px = {};
xhat(1) = yxest(1,2); Px{1} = 0.5;
zk = [yk uk];
for k = 2:length(yk),
[xhatk,Pxk] = KalmanFilt(sysdet_const ,noisecov ,xhat(k-1),Px{k-1},zk(k,:)’)...
;
xhat(k) = xhatk;
Px{k} = Pxk;
end
% Plot the estimates
figure; plot(kvec,xhat); hold on
plot(kvec,c0*ones(length(kvec),1),’r--’);
figure; plot(kvec,cell2mat(Px))
Several examples of Kalman ﬁlter implementation in the form of tutorials and applications are
available. The reader is strongly encouraged to refer to the rich literature in this regard (see Eubank
(2006), Grewal and Andrews (2008), and Zarchan and Musoﬀ(2008) for instance).
Below we brieﬂy discuss the extension to the non-linear case, only for the sake of completeness.
The reader is free to skip the following section and move on to §23.3.2 since a knowledge of this
topic is not required for linear subspace identiﬁcation.
23.3.1
EXTENDED KALMAN FILTER AND THE UNSCENTED KF
Suppose the dynamics are described by a non-linear model,
x[k + 1] = f(x[k],u[k]) + wx[k]
y[k] = h(x[k]) + wy[k]
(23.39a)
(23.39b)
where the initial state is a random vector with known (speciﬁed) mean and covariance, and the noise
processes have similar properties as in the linear case (23.19). In fact, the noise covariances can also
be time-varying as before. Observe that the non-linearity in (23.39) is only in the deterministic part
of the system.
The Kalman ﬁlter developed above evidently cannot be applied to this case since there exists no
ﬁxed linear model. However, as is done in the modeling arena, we describe the non-linear model
with approximate time-varying linearized model. Subsequently, the Kalman ﬁlter can be applied to
the process, however with a diﬀerent local linear state-space model at each instant. This is the basic
idea of the popular extended Kalman ﬁlter (EKF). The derivation of the EKF is somewhat elaborate,
but the ﬁnal form is, not surprisingly, similar to the ordinary Kalman ﬁlter. Given below are the ﬁnal

672
Principles of System Identiﬁcation: Theory and Practice
ﬁlter equations; for a detailed derivation the reader is referred to texts on this topic, for example,
Zarchan and Musoﬀ(2008).
Predictor: Linearize around ˆx[k −1|k −1]
ˆx−[k] = f(ˆx[k|k])
P−
k = Jf[k −1]Pk−1JT
f [k −1] + Qk−1
(23.40a)
(23.40b)
Corrector: Linearize around ˆx[k|k −1]
ˆx[k|k] = ˆx−[k] + Kk (y[k] −h(ˆx−[k]))
Kk = P−
kJT
h [k]
f
Jh[k]P−
kJT
h [k] + Rk
g−1
Pk = (I −KkJh[k])P−
k
(23.41a)
(23.41b)
(23.41c)
where
Jg[k −1] = ∂f
∂x
ˆx[k−1|k−1],u[k−1]
(23.42)
Jh[k] = ∂h
∂x
ˆx[k |k−1],u[k−1]
(23.43)
are the Jacobians of state and output non-linear functions evaluated at the previous update and the
current prediction points, respectively.
The algorithm is initialized in the same way as the ordinary KF. Comparing notes with the ordi-
nary Kalman ﬁlter, essentially we have replaced the matrices A, C by the respective local matrices
(Jacobians), respectively.
Remarks:
i. The EKF is not an optimal ﬁlter. It is based on practically useful approximations. Consequently the error
covariances are not accurate.
ii. Essentially the initial guess is propagated through a locally linearized approximation at each instant. The
heuristic nature of the approach does not guarantee convergence since the approximation error can be greatly
inﬂuenced by the severity of the non-linearity.
iii. Nevertheless the EKF oﬀers a practical extension of the KF to several non-linear applications - its use,
however, demands user experience and awareness of its limitations.
The unscented Kalman ﬁlter (UKF) Julier and Uhlmann (2004) is an advanced version of the KF
that attempts to address the major drawback of the EKF, which is in choosing the local reference
point and its propagation through the model. UKF chooses a set of sample points, also known as
the sigma points, around the mean and then determines an optimal way to derive the state estimates
from the propagation of the sigma points through the model. Further, the p.d.f. of the noise is
also propagated through the non-linearity unlike in the EKF. Derivations and the associated ﬁlter
equations are beyond the scope of this text, but the reader is referred to Crassidis and Junkins (2012)
and Julier and Uhlmann (2004).
We return to the discussion of the ordinary KF, particularly in the context of identiﬁcation. It
assumes the availability of a state-space model and the knowledge of the noise covariance matrices.
On the other hand, identiﬁcation of state-space models is the problem of joint identiﬁcation (of state-
space model) and state estimation. As remarked early on in this chapter, a key feature of subspace
identiﬁcation methods is that they determine the optimal (Kalman) state estimates numerically, i.e.,
purely from data and without the explicit knowledge of a state-space model. This is achieved by
re-writing the Kalman ﬁlter equations in such a way that the optimal estimates are recognized as a
linear combination of the past input-output data and the initial state estimate (guess). The related
matter is described later in §23.6.

Identiﬁcation of State-Space Models
673
23.3.2
INNOVATIONS FORM
The innovations form is a state-space model, whose states are the optimal estimates as delivered by
a Kalman ﬁlter. The description stems from the combination of a time, and measurement updates
in (23.26a) and (23.30), respectively. It relates the optimal predictions at two consecutive instants
ˆx[k + 1|k] and ˆx[k|k −1].
To construct the relationship, we combine (23.26a) and (23.30) to produce
ˆx−[k] = ˆx[k|k −1] = A(ˆx[k −1|k −2] + Kk (y[k] −Cˆx[k −1|k −2])) + Bu[k −1]
(23.44)
Re-introducing the innovations term e[k] = y[k] −Cˆx[k|k −1], and evaluating the resulting expres-
sion at k + 1, we have
ˆx[k + 1|k] = Aˆx[k|k −1] + Bu[k] + K′
ke[k]
y[k] = C ˆx[k|k −1] + e[k]
(23.45a)
(23.45b)
where K′
k = AKk is also known as the Kalman gain, but for the innovations form. Naturally Ly is a
function of the s.s. matrices and the noise covariance matrices Q and R. The combined covariance
update and the variance of innovations were given earlier in (23.35) and (23.33), respectively,
var(x[k + 1|k]) = Pk+1|k = A(Pk |k−1 −KkCPk |k−1)AT + Q
var(e[k]) = Σk = CPk |k−1CT + R
(23.46)
(23.47)
The case of correlated noise
The innovations form (and the Kalman ﬁlter) above can also be derived when the state and process
noise are correlated, i.e., S , 0. In such a case, the innovations form and the combined covariance
update equations are
ˆx[k + 1|k] = Aˆx[k] + Kke[k]
y[k] = C ˆx[k|k −1] + e[k]
(23.48a)
(23.48b)
where
Kk = (APk |k−1C + S)M−1
k
Mk = Σk = CPk |k−1CT + R
(23.49a)
(23.49b)
and
Pk+1|k = (A −KkC)Pk |k−1(A −KkC)T + Q + KkRKT
k −(SKT
k + KkST )
(23.49c)
It is easily veriﬁed that when S = 0, we obtain the model in (23.45).
Use of innovations form in identiﬁcation
The innovations form in (23.45) has a critical role to play in identiﬁcation of state-space systems.
The central argument is that any algorithm that identiﬁes state-space model from data is, in addi-
tion to optimally estimating the state-space matrices, also expected to produce optimal estimates of
states. Therefore optimally identiﬁed state-space models will invariably be based on Kalman states
(rather than the true states), at least, for linear systems with Gaussian distributed noise. Conse-
quently, it is a wise idea to identify the innovations form (23.45) instead of the general model (23.19)
(or (23.3)). We shall, for the rest of the developments, conﬁne ourselves to the ﬁxed (steady-state)
Kalman gain case.

674
Principles of System Identiﬁcation: Theory and Practice
The prime diﬀerence between estimating the general state-space model and the innovations form
is that instead of estimating the noise covariance matrices Q and R (and possibly a noise cross-
covariance matrix) in the former, we have in the innovation form, the estimation of the Kalman gain
K and the innovations covariance S. An important point to observe is that both these latter quantities
are functions of the state-space matrices. However, the nature of these functional relationships is
usually of high complexity to the eﬀect that is better to estimate the Kalman gain and covariance
matrices along with the state-space matrices. However, such an approach also causes an increase
in the number of unknowns to be estimated. Fortunately, parametrized state-space models do not
suﬀer from this drawback. Stated otherwise, when A, B, C and D are functions of a parameter vector
θ, the user can parametrize one or both of these matrices i.e., express them as K(θ) and S(θ) (the
prime on Kalman gain has been dropped for convenience). Example 23.8 in a later section illustrates
the point in case.
Predictor form
The optimal state estimates of the innovations form in (23.45) can be re-written purely in terms of
past states and input-output data
x[k] = Ax[k −1] + Bu[k] + K(y[k −1] −Cx[k −1] −Du[k −1])
leading to the so-called predictor form
x[k + 1] = AKx[k] + BKz[k]
y[k] = Cx[k] + Du[k] + e[k]
(23.50a)
(23.50b)
where AK ≜(A −KC),BK ≜
f
(B −KD)
K
g
and z[k] =
f
u[k]
y[k]
gT.
The state-space form above in (23.50) is used in a class of approaches to state-space identiﬁcation.
A prime advantage of using this form is that it can be used for unstable systems since AK is stable
even when A is unstable. On the other hand, the diﬀerence w.r.t. the other two forms, namely, the
process form of (23.3) and (23.45) is that the predictor form is time-varying in the ﬁnite sample
case. However, this is not much of a drawback since all subspace identiﬁcation methods assume
large sample size.
We shall now study the foundational concepts governing subspace identiﬁcation methods.
23.4
FOUNDATIONS FOR SUBSPACE IDENTIFICATION
The main objective in a state-space identiﬁcation is the development of the innovations form given
input-output data. The entire eﬀort consists of a smaller set of objectives, namely,
1. Determination of the order of the system, i.e., dimension of states nx
2. Estimation of (deterministic) system matrices or states of the innovations form
3. Estimation of states / system matrices (if states are estimated ﬁrst)
4. Determination of Kalman gain and noise covariance matrices (of the innovations form)
The main tools for this purpose are, as remarked in §23.2, the extended observability (controlla-
bility) matrix, SVD of Hankel matrices (built from input-output data), and suitable orthogonal /
oblique projections of data onto appropriate subspaces. The last tool is required to obtain optimal
(Kalman) estimates of states.
It is instructive to ﬁrst study the deterministic case, i.e., the noise-free case because it is rela-
tively easier to follow and also provides the necessary foundations for understanding the class of
algorithms for identifying deterministic-plus-stochastic SS models. This is also in line with the his-
torical scheme of developments.

Identiﬁcation of State-Space Models
675
In the following sections, we shall brieﬂy study the basic elements of state-space identiﬁcation
and subsequently show how they are applied together for achieving the grand purpose.
23.4.1
EXTENDED OBSERVABILITY MATRIX
The observability matrix introduced earlier is useful in the context of identiﬁcation in two diﬀerent
ways:
Estimating order from On
One of the ﬁrst steps in state-space identiﬁcation is the determination of the order. The answer to
this is given by the rank of the observability matrix of an observable system.
Order n = rank(On)
(23.51)
The foregoing results, speciﬁcally (23.52), (23.53) and (23.51) bring out the vital role of observabil-
ity matrix in identiﬁcation. The natural question that arises is how does one obtain the observability
matrix from data and of what dimension should it be? (since neither the order nor the system ma-
trices are known). The answer to this is given by the concepts of extended observability and Hankel
matrices. While the former facilitates determination of the system order, the latter provides esti-
mates of the extended observability matrix (as well as the order).
Estimating matrices given observability / controllability matrix
Another important use of the observability matrix in identiﬁcation is in determining A and C through
the following approach. The ﬁrst row (or ny rows) of the observability matrix gives us C
C = On(1,:)
(MATLAB notation)
(23.52)
while the state transition matrix A is determined from a useful shift property of the observability
matrix:
On(1 : (n −1),:)A = On(2 : n,:)
=⇒A = [On(1 : (n −1),:)]−1On(2 : n,:)
(23.53)
In a similar way, the controllability matrix Cn can be used to estimate B and A (for a SISO system)
B = Cn(:,1)
(23.54a)
A = Cn(:,2 : n)[Cn(:,1 : (n −1))]−1
(23.54b)
In practice, however, neither the order is known nor is the observability / controllability matrix.
Assume for now we have a method to estimate these matrices. Then the order n can be determined
by constructing the matrix beyond the requisite number of rows, i.e., by having rows in excess of a
guessed order n. Such a matrix is known as the extended observability matrix, denoted by Or.
Or =

C
CA
...
CAr−1

,
r ≫n
(23.55)
The rank of Or is the order of the system. In the absence of noise and for linear systems, the extended
observability matrix Or also satisﬁes the same property as the ordinary observability matrix On.
This concept can be identically applied to construct an extended controllability matrix Cr,
Cr =
f
B
AB
· · ·
Ar−1B
g
,
r ≫n
(23.56)

676
Principles of System Identiﬁcation: Theory and Practice
The central goal in state-space identiﬁcation is to obtain estimates of the observability and con-
trollability matrices. Two broad methods that we shall study in the rest of this chapter for this pur-
pose are the realization and direct methods. The ﬁrst class of methods construct state-space mod-
els from impulse response coeﬃcients mainly due to Ho and Kalman (1966) and Kung (1978),
while the second class of methods, which have a more general appeal, estimate SS models di-
rectly from arbitrary input-output data using projection methods. The latter class is also known
as subspace identiﬁcation methods.
23.4.2
REALIZATION METHODS
We ﬁrst discuss methods for the deterministic case studied by Ho and Kalman (1966) followed by
those for the noisy case by Kung (1978).
Consider the SISO deterministic nth order state-space model (A,B,C,D). The objective is to es-
timate this model (a realization) given (i) impulse response of the system and (ii) input-output data
(general case). Both methods, as we shall see, estimate the extended observability matrix through
SVD of a Hankel matrix.
23.4.2.1
Estimation from IR: Ho and Kalman Method
The impulse response of a deterministic system in terms of the SS matrices is given by (see Exercise
E23.5)
g[k] =

D,
k = 0
CAk−1B,
k ≥1
(23.57)
Equation (23.57) oﬀers an alternative deﬁnition for a state-space realization (recall Deﬁnition 4.4).
Deﬁnition 23.2. A state-space model (A,B,C,D) for a system G is said to be a realization of the
system if and only if it satisﬁes the impulse response relation in (23.57).
It is clear from (23.57) that multiple solutions exist. However, the solution to the feedthrough
matrix is unique,
D = g[0]
(or D = G[0])
(23.58)
The non-uniqueness of the remaining matrices is a foregone conclusion from our discussion in §4.4.
The implication is that we can construct a SS model that is correct only up to a similarity transform
T.
In order to get a clue on a way to estimate the SS matrices from the IR coeﬃcients (henceforth for
k ≥1), observe from (23.57) that a factorization of the impulse response is involved. Further, also
observe that the IR coeﬃcient can be factored as
g[k] = [CAl][AmB],
l + m = k −1
(23.59)
where the quantities in square brackets can be recognized as entries of the (extended) observability
and controllability matrices. This is the key idea underlying Ho and Kalman’s method.
Generalizing the idea above, we ﬁrst conceive a Hankel matrix1 of impulse response coeﬃcients
1A Hankel matrix is a matrix with identical entries along the anti-diagonals.

Identiﬁcation of State-Space Models
677
(or operators) of inﬁnite dimension as follows.
H =

g[1]
g[2]
g[3]
g[4]
· · ·
g[2]
g[3]
g[4]
g[5]
· · ·
g[3]
g[4]
g[5]
g[6]
· · ·
g[4]
g[5]
g[6]
g[7]
· · ·
...
...
...
...
...

(23.60)
When the impulse response of the system satisﬁes (23.57), we have the following:
i. rank(H) = n, the order of the system
ii. The Hankel matrix H can be factored as a product of the inﬁnitely extended observability and
controllability matrices
H = O∞C∞= O∞TT−1C∞
(23.61)
It is fairly straightforward to establish the above result by noting that g[1] = CB,g[2] = CAB
and so on (see Exercise E23.6). The second identity conveys the fact that this factorization is
unique only up to a similarity transformation.
iii. The Hankel matrices connect the past inputs u−to future outputs y+ through
y+ = Hu−
(23.62)
where
y+ =
f
y[0]
y[1]
· · ·
gT ; u−=
f
u[−1]
u[−2]
· · ·
gT
(23.63)
The relationship follows from the convolution equation in (4.1) for LTI systems.
Remarks:
A more appropriate term for H is the block Hankel matrix since for MIMO systems, only the
blocks are identical along anti-diagonals.
In practice, a ﬁnite dimensional Hankel matrix of IR coeﬃcients is constructed
Hl,m =

g[1]
g[2]
g[3]
· · ·
g[m]
g[2]
g[3]
g[4]
· · ·
g[m + 1]
g[3]
g[4]
g[5]
· · ·
g[m + 2]
...
...
...
...
...
g[l]
g[l + 1]
g[l + 2]
· · ·
g[l + m −1]

(23.64)
where n < l ≤m. The ﬁnite-dimensional Hankel matrix can be factorized in a similar way as its
inﬁnite version, i.e., as a product of extended observability and controllability matrices
Hl,m = OlCm
(23.65)
which is once again unique only up to a similarity transformation.
The method of Ho and Kalman now follows.
1. Construct the Hankel matrix Hl,m from the given impulse response coeﬃcients.
2. Compute the SVD2 of the Hankel matrix
Hl,m =
f
Ud
Us
g "Sd
0
0
0
# f
Vn
Vs
g
(23.66)
where Sd is a diagonal matrix of the sorted n non-zero singular values
σ1 ≥σ2 ≥· · · σn > 0 = σn+1 = σn+2 = · · · = σd+s
2The bold faced notation is sacriﬁced for the factors to avoid confusion with the input / disturbance matrices due to appear
later in subspace identiﬁcation.

678
Principles of System Identiﬁcation: Theory and Practice
3. Estimate the rank n extended observability and controllability matrices from the SVD factors:
Ol = UdS1/2
d T, Cm = T−1S1/2
d Vd
(23.67)
where T is a n × n non-singular matrix (default T = I).
4. Construct estimates of the state-space matrices using earlier results:
C = Ol (1,:)
A = O†
l Ol
B = Cm(:,1)
(23.68a)
(23.68b)
(23.68c)
where Ol = Ol (1 : (l −1),:), Ol = Ol (2 : l,:) and the † symbol denotes pseudo-inverse.
An alternative way of estimating A is through the controllability matrix in (23.54). Note that the
method can be easily modiﬁed to accommodate MIMO systems by appropriately modifying the
dimensions of the concerned matrices.
Example 23.5: Ho and Kalman’s Method
Consider the following LTI system:
x[k] =
"1.2
−0.7
0.5
0
#
x[k] +
"2
0
#
u[k]
(23.69)
y[k] =
f
1
1
g
x[k]
(23.70)
with the transfer function
G(z) =
0.5z + 1
z2 −1.2z + 0.35
(23.71)
A Hankel matrix of IR coeﬃcients with l = m = 11 in (23.64) is constructed from the generated
impulse response. SVD of the Hankel matrix gives two non-zero singular values σ1 = 12.5451,
σ2 = 2.3583 and σr = 0,r ≥3, straight away giving us the order of the system as n = 2.
Computing the extended observability and controllability matrices using (23.67), followed
by the estimation of SS matrices using (23.68), gives
A =
" 0.8663
0.2468
−0.2468
0.3337
#
; B =
"−1.236
−1.014
#
; C =
f
−1.236
1.014
g
; D = 0
which yields exactly the same transfer function as in (23.71).
Listing 23.3
MATLAB code for Example 23.5
%% Data generation
% DGP
Gz = tf([0.5 1],[1 -1.2 0.35],1); Gz_ss = ss(Gz);
% Generate IR
ircoeff = impulse(Gz,21);
%% Identification
% Hankel matrix
Hir = hankel(ircoeff(2:12),ircoeff(12:end));
% SVD of Hankel matrix
[Uh,Sh,Vh] = svd(Hir); nx = rank(Hir);
% Estimate obsrv and ctrb matrices
Obn = Uh(:,1:nx)*sqrt(Sh(1:nx,1:nx));

Identiﬁcation of State-Space Models
679
Cbn = sqrt(Sh(1:nx,1:nx))*Vh(:,1:nx)’;
% Estimate SS matrices
D = ircoeff(1);
C = Obn(1,:); B = Cbn(:,1);
A = pinv(Obn(1:end-1,:))*Obn(2:end,:);
Ghat_ss = ss(A,B,C,D,1); Ghat_tf = tf(Ghat_ss);
23.4.2.2
Kung’s Method
In practice, experimental IR coeﬃcients are known with errors due to the presence of noise, distur-
bances, etc. Kung (1978) extended the above method to address this situation. The basic idea is to
replace (23.53) with a least squares version, i.e., solve a set of overdetermined equations.
The main consequence of errors in IR coeﬃcients is that the Hankel matrix is of full rank. There-
fore, an exact determination of order is no longer possible. A truncated SVD of the Hankel matrix
has to be used and the responsibility of choosing the “most signiﬁcant” singular values, i.e., the order
of truncation rests with the user. This is certainly not a trivial task and only guidelines are available
at present. The SVD factors are partitioned heuristically into the “deterministic” and “stochastic”
parts by the user,
U =
f
Ud
Us
g
, S =
"Sd
0
0
Ss
#
, V =
f
Vd
Vs
g
(23.72)
where Us and Vs are the left and right singular vectors corresponding to the user-identiﬁed “insignif-
icant” or “noisy” singular values in Ss. Neglecting the contributions of these factors to the Hankel
matrix, we have the approximation (or cleaned matrix of IR coeﬃcients)
ˆHl,m ≜UdSdVT
d
(23.73)
where now l,m ≫n. Notice that we have used a [ˆ.] to indicate that we are working with an estimate
now, a notation to be used below as well.
Estimates of observability and controllability matrices is then performed as usual, but they are no
longer exact.
ˆOl = UdS1/2
d T,
ˆCm = T−1S1/2
d Vd
(23.74a)
with a default value of T = I.
Finally, the matrices C and B are read oﬀas the ﬁrst blocks of ˆOl and ˆCm as before but A is
obtained in a least squares sense,
ˆC = ˆOl (1,:)
ˆA = ˆO
†
l ˆOl
ˆB = ˆCm(:,1)
(23.75a)
(23.75b)
(23.75c)
where now truly the pseudo-inverse of ˆOl is required unlike in the Ho and Kalman’s case where an
exact inverse could be used.
Example 23.5 is now revisited in the present context.
Example 23.6: State-Space Realization from Noisy IR Coefﬁcients: Kung’s Method
The IR coeﬃcients of the system in Example 23.5 are now corrupted with a zero-mean
white-noise of variance 0.01. The noisy IR coeﬃcients, denoted by gm[n], are shown in Figure
23.4(a). Singular values of the Hankel matrix (with l = m = 11) are plotted in Figure 23.4(b).

680
Principles of System Identiﬁcation: Theory and Practice
0
5
10
15
20
25
−0.5
0
0.5
1
1.5
2
Time (samples)
Measured impulse response
(a) Noisy IR coeﬃcients
0
2
4
6
8
10
12
0
1
2
3
4
5
6
7
Index
Singular values
(b) Singular values
FIGURE 23.4
IR coeﬃcients and singular values of the Hankel matrix for Example 23.6.
All singular values are non-zero due to the presence of noise. Therefore, no clear evidence
of the system order emerges in this case. However, a signiﬁcant drop in the singular values
beyond n = 2 is observed. The singular values beyond the third one are negligible (n = 3 is
also a viable option). Truncating the SVD to n = 2 and following the estimation steps in
(23.74) and (23.75), we obtain
A =
" 0.8638
0.2572
−0.2551
0.3534
#
; B =
"−1.248
−1.038
#
; C =
f
−1.248
1.038
g
; D = 0
where we have set D = 0 by treating the ﬁrst IR coeﬃcient as negligible.
The state-space model estimate above expectedly yields an approximate transfer function
unlike in the deterministic case
ˆG(q−1) =
0.4812q−1 + 1.044q−2
1 −1.217q−1 + 0.3708q−2
(23.76)
when compared to the true transfer function (23.71).
Listing 23.4
MATLAB code for Kung’s method in Example 23.6
%% Data generation
% DGP
Gz = tf([0.5 1],[1 -1.2 0.35],1);
Gz_ss = ss(Gz);
% Generate IR
ircoeff = impulse(Gz,21);
% Add noise to IR coefficients
irmeas = ircoeff + randn(length(ircoeff),1)*0.1;
figure; stem((0:21),irmeas,’markerfacecolor’,’b’)
%% Identification
% Hankel matrix
Hir = hankel(irmeas(2:12),irmeas(12:end));
% SVD of Hankel matrix
[Uh,Sh,Vh] = svd(Hir,’econ’);
% Plot the resulting singular values to guess the order
figure; stem((1:11),diag(Sh),’markerfacecolor’,’b’)

Identiﬁcation of State-Space Models
681
nx = 2;
% Estimate obsrv and ctrb matrices
Obnhat = Uh(:,1:nx)*sqrt(Sh(1:nx,1:nx));
Cbnhat = sqrt(Sh(1:nx,1:nx))*Vh(:,1:nx)’;
% Estimate SS matrices
Dhat = 0;
Chat = Obnhat(1,:); Bhat = Cbnhat(:,1);
Ahat = pinv(Obnhat(1:end-1,:))*Obnhat(2:end,:);
% Reconstruct the TF
Ghat_ss = ss(Ahat,Bhat,Chat,Dhat ,1); Ghat_tf = tf(Ghat_ss);
Estimation from arbitrary I/O data
In a more practical scenario, input-output data are generated from arbitrary inputs. An intuitive
solution is to estimate the IR coeﬃcients from input-output data using methods of §20.2. However,
a more appropriate approach would be to devise a method that can directly work with the input-
output data in anticipation of the need for identifying the stochastic sub-system when dealing with
noisy measurements.
The associated methods, as mentioned earlier, are broadly known as the projection-based or the
subspace identiﬁcation methods. They stem from a natural extension of the ideas presented above,
where we consider the stacked response Equation (23.10) in place of the impulse response and
perform an SVD of the projected output to obtain estimates of the extended observability matrix
and/or the states. The exactness and the approximations involved in Ho and Kalman’s and Kung’s
methods, respectively, are also reﬂected in the development of subspace identiﬁcation methods.
It is useful to ﬁrst obtain some foundations and the overall idea in subspace identiﬁcation before
we study the methods.
23.5
PRELIMINARIES FOR SUBSPACE IDENTIFICATION METHODS
All subspace methods strive to arrive at a basic equation of the form
˜Y = ˜Or ˜X
(23.77)
where ˜Y is a matrix of outputs projected on to an appropriate subspace, ˜Or is the extended ob-
servability matrix and ˜X is a matrix of state sequence in some basis space (of states). Equation
(23.77) is obtained by eliminating the input terms and noise terms through a series of projec-
tion operations on the outputs. This is the main trick in subspace identiﬁcation. Once this is
achieved and the rank ˜Y is established to be n, the order of the system, the column spaces of
Or and ˜Y are equal. Thus, SVD of ˜Y (as in Ho and Kalman’s method) produces the desired
quantities, namely, the extended observability matrix and the state sequence.
It is reiterated that the extended observability matrix and the states therefore can only be identiﬁed
correctly up to a similarity transformation. In the language of linear algebra, only the column space
of extended observability matrix and the row space of states can be obtained through subspace
identiﬁcation methods. A suﬃcient, but not necessarily a user-desired, state-space working model
is thus obtained. When a particular structure is desired, we have to turn to the optimization-based
(prediction-error minimization) methods.
From (23.77) are born three broad classes of methods as remarked in §23.2.1. The ﬁrst one is
based on the estimates of extended observability matrix while the remaining two are based on esti-
mate of states, all three subsequently followed by estimation of state-space matrices. In the language

682
Principles of System Identiﬁcation: Theory and Practice
of projections, the former class known as the MOESP methods work with orthogonal projections
while the latter class of method contain the (direct) N4SID methods that work with oblique pro-
jections, and the CVA methods that make use of principal angles. The MOESP methods directly
work with the innovations form, while the N4SID and CVA methods work with the process form
of model, estimates of which are used to derive the innovations form. All these three algorithms
are presented in §23.6. It may be also mentioned that there exist linear regression approaches to
state-space identiﬁcation, which use the predictor form (see Qin (2006) for a good overview).
It must be mentioned that the apparently disparate aforementioned methods are collectively
known as N4SID methods and, more importantly, can be uniﬁed under a single algorithm with
diﬀerent weighting options3.
Next we present a short primer on the concept of projections and their numerical implementations,
which are critical to the understanding of subspace methods.
23.5.1
SUBSPACES, PROJECTIONS AND IMPLEMENTATIONS
The ﬁrst deﬁnition is that of a subspace.
Deﬁnition 23.3. A subspace of a vector space V is a subset H ⊂V that has three properties:
1. The zero vector is in H
2. For each u,w ∈H, u + w ∈H (closed under addition)
3. For each u ∈H, αu,α ∈R is also in H (closed under multiplication)
The following theorem states that a linear combination of vectors always generates a subspace.
Theorem 23.1
Consider a set of m × 1 vectors {v1,v2,· · · ,vn} ∈Rm. Then all linear combinations of these vectors
form a subspace of Rm.
V = span{v1,v2,· · · ,vn} =

n
X
i=1
αivi|αi ∈R

(23.78)
Next we deﬁne row and column spaces of a rectangular matrix.
Deﬁnition 23.4. The row space and column space of an m × n matrix A denoted by row(A) =
yTA, y ∈Rm×1 and column(A) = Ax, x ∈Rn×1, respectively, are the set of all linear combinations
of the row vectors and column vectors, respectively.
The column space of a matrix A is also referred to as the image (Im(A) or range of that matrix.
Further, the column space of A is the row space of AT.
Now we proceed to deﬁning projections and their implementations, which constitute the core of
subspace identiﬁcation.
3The acronym N4SID stands for Numerical algorithms for Subspace State-Space System IDentiﬁcation, MOESP for
Multivariable Output Error State-sPace identiﬁcation and CVA for Canonical Variate Analysis.

Identiﬁcation of State-Space Models
683
Orthogonal projections
Deﬁnition 23.5 (Orthogonal projection). The orthogonal projection of the row space of a matrix A
on to the row space of B is given by4
A/B = ABT (BBT )†B
(23.79)
where † denotes the Moore-Penrose or the pseudo-inverse.
It is convenient to introduce the projection operator5
ΠB ≜BT (BBT )†B
(23.80)
so that (23.79) can be re-written as
A/B = AΠB
(23.81)
The part of A that is not captured by the orthogonal projection in (23.81) is contained in its
projection onto the orthogonal complement of the row space of B.
Deﬁnition 23.6. The projection of the row space of A onto the orthogonal complement of the row
space of B is given by
A/B⊥= AΠ⊥
B
(23.82)
where
Π⊥
B = I −ΠB
(23.83)
The matrix A can thus be expressed as a sum of these two projections
A = AΠB + AΠ⊥
B
(23.84)
The decomposition above has close resemblance to the projection theorem given in 14.7.
Numerical implementation
A numerically robust and eﬃcient computation of the orthogonal projection AΠB is facilitated by
the LQ decomposition
"B
A
#
= LQT =
"L11
0
L21
L22
# "QT
1
QT
2
#
(23.85)
where L and Q are lower triangular and orthogonal matrices (QTQ = I), respectively. Note that
the LQ decomposition of a matrix X is essentially a QR factorization of XT. Hence the use of QT
in (23.85). This also implies that L is simply the transpose of R.
The orthogonal projection and its complement as a consequence of (23.85) can be written as
AΠB = L21QT
1
AΠ⊥
B = L22QT
2
(23.86)
(23.87)
4In certain texts, the deﬁnition A/B = AB(BT B)†BT is followed. However, the reader should then recognize such
operations as projections of the row space of A on to the column space of B.
5This projection operator is similar to P in (14.24) introduced in the context of least squares methods, which also produces
orthogonal projections, but in the column space of Φ.

684
Principles of System Identiﬁcation: Theory and Practice
Oblique projection
The idea here is to decompose a matrix A as linear combinations of two non-orthogonal matrices B
and C, and their complements. Thus, the notion of orthogonal projection is implicitly in play here.
Essentially, the matrix A is decomposed as linear combinations of the rows of B and C and of the
rows of a matrix that this orthogonal to both B and C.
Deﬁnition 23.7 (Oblique projection). The oblique projection of the row space of A ∈Rr×l along
the row space of B ∈Rs×l onto the row space of C ∈Rp×l is given by
A/BC ≜A
f
CT
BT g *
,
"CCT
CBT
BCT
BBT
#†
+
-ﬁrst r columns
C
(23.88)
A geometric interpretation of the oblique projection can be provided. It is such that the angle
between the residual vector (of the projection) and the projection of A onto C is identical to the
angle between B and C. In other words the residual vector and B are parallel to each other. Naturally
when row space of B is orthogonal to that of C, the oblique projection simpliﬁes to the orthogonal
projection in (23.79).
When BCT = 0, A/BC = AΠC
(23.89)
An alternative deﬁnition of oblique projection can also be provided, as follows.
Deﬁnition 23.8 (Second deﬁnition). The oblique projection in (23.88) can also be deﬁned as
A/BC = [AΠ⊥
B][CΠ⊥
B]†C
(23.90)
Numerical implementation
As in the case of orthogonal projection, the oblique projection in (23.88) can be eﬃciently and
robustly implemented using the LQ decomposition

B
C
A

=

L11
0
0
L21
L22
0
L31
L32
L33


QT
1
QT
2
QT
3

(23.91)
so that
A/BC = L32L−1
22C = L32L−1
22 (L21QT
1 + L22QT
2 )
(23.92)
Remarks:
From (23.90) it is clear that the oblique and orthogonal (complement) projections can be related
through post-multiplication of the latter through an appropriate matrix:
A/BC = [A/B⊥]W2
s.t. W2 = [CΠB]†C
A/B⊥= [A/BC]W2
s.t. W2 = Π⊥
B
(23.93)
(23.94)
These relations form the basis for expressing one subspace method based on orthogonal projection with another
one that uses oblique projections.
Principal angles and directions
The principal angles6 between two matrices A ∈Rl×j and B ∈Rm×j are a generalization of the
angle between two vectors in that they consist of p = min(l,m) angles between the p unit vectors
in A and B. A key point to consider is that these angles are arranged in ascending order so that each
angle corresponds to the smallest angle among the unit vectors under consideration. The directions
corresponding to these angles are known as principal directions. A formal deﬁnition is given below.
6The notion of canonical angles is usually traced back to Jordan’s seminal work in 1875.

Identiﬁcation of State-Space Models
685
Deﬁnition 23.9 (Principal angles and directions). The principal angles φ1 ≤φ2 ≤· · · ≤π/2
between the row spaces of two matrices A ∈Rl×j and B ∈Rm×j are deﬁned recursively as:
cos φp =
max
a∈A,b∈B aTb
= aT
pbp
(23.95)
s.t.
||a|| = ||b|| = 1
< a,ai >= 0,< b,bi >= 0
∀i = 1,· · · ,p −1
The resulting vectors ai,bi, i = 1,· · · ,p are known as the principal directions.
Numerical implementation
As in the case of orthogonal and oblique projections, there exist SVD-based deﬁnitions that compute
the principal angles and directions (Knyazev and Argentati, 2002). One deﬁnition is given below.
Deﬁnition 23.10 (Alternative deﬁnition). The principal angles and directions between the row
spaces of two matrices A ∈Rl×j and B ∈Rm×j s.t. p = min(m,l) can be computed via the
SVD of
(AAT )−1/2(ABT )(BBT )−1/2 = USVT
(23.96)
as
cos φi = σi, i = 1,· · · ,p
(23.97a)
[A∢B] ≜
f
a1
· · ·
ap
g
= UT (AAT )−1/2A
(23.97b)
[A∢B] ≜
f
b1
· · ·
bp
g
= VT (BBT )−1/2B
(23.97c)
Statistical interpretations of projections and principal angles are provided in §23.6.2.
23.6
SUBSPACE IDENTIFICATION ALGORITHMS
The section begins by discussing two popular methods for identiﬁcation of deterministic realizations
(from arbitrary I/O data), namely the N4SID and MOESP methods7. The underlying ideas are then
extended to the realistic case of deterministic-plus-stochastic systems in a manner similar to how
Ho and Kalman’s method was extended to the noisy case by Kung. Methods for the deterministic-
plus-stochastic case are described in §23.6.2.
23.6.1
DETERMINISTIC SYSTEMS
The problem of deterministic identiﬁcation is as follows. Given N observations of input-output data
of a deterministic process, identify the state-space matrices A, B, C and D.
Before we proceed to describing the two aforementioned methods, it is useful to introduce certain
equations and matrices that are commonly used by both approaches.
7The CVA method is more appropriate for the stochastic scenario.

686
Principles of System Identiﬁcation: Theory and Practice
Basic entities
The ﬁrst one is constructed by stacking the responses for all times over a window of r samples using
(23.10), but now taking into account the presence of inputs,

y[k]
y[k + 1]
...
y[k + r −1]

|            {z            }
yr [k]
=

C
CA
...
CAr−1

|    {z    }
Or
x[k] +

D
0
· · ·
0
CB
D
· · ·
0
...
...
...
...
CAr−2B
· · ·
CB
D

|                            {z                            }
Gr

u[k]
u[k + 1]
...
u[k + r −1]

|            {z            }
ur [k]
(23.98)
so as to write
yr[k] = Orx[k] + Grur[k]
(23.99)
Next we write (23.99) at all instants from k = 0 to k = s −1. For this purpose, introduce
U0|r−1 =
f
ur[0]
ur[1]
· · ·
ur[s −1]
g
=

u[0]
u[1]
· · ·
u[s −1]
u[1]
u[2]
· · ·
u[s]
...
...
...
...
u[r −1]
u[r]
· · ·
u[r + s −2]

∈Rr×s
(23.100a)
Y0|r−1 =
f
yr[0]
yr[1]
· · ·
yr[s −1]
g
=

y[0]
y[1]
· · ·
y[s −1]
y[1]
y[2]
· · ·
y[s]
...
...
...
...
y[r −1]
y[r]
· · ·
y[r + s −2]

∈Rr×s
(23.100b)
where the arguments in the subscripts indicate the starting and ending sample index of the ﬁrst
columns of the respective matrices. Thus, we have the following stacked response equation
Y0|r−1 = OrX0|s−1 + GrU0|r−1
(23.101)
where X0|s−1 =
f
x[0]
x[1]
· · ·
x[s −1]
g
∈Rn×s is the matrix of states.
In a similar way, we can develop response equations over the times k = r,r + 1,· · · ,r + s −1 as
Yr |2r−1 = OrXr |r+s−1 + GrUr |2r−1
(23.102)
where
Ur |2r−1 =
f
ur[r]
ur[r + 1]
· · ·
ur[r + s −1]
g
(23.103a)
Yr |2r−1 =
f
yr[r]
yr[r + 1]
· · ·
yr[r + s −1]
g
(23.103b)
Notice that the bottom right element in each of the above matrices is u[2r + s −1] and y[2r + s −
1], respectively. The matrices U0|r−1 and Ur |r+s−1 (likewise for outputs and states) are known as
past and future matrices, respectively, w.r.t. the time instant ‘r’ since the columns of each of these
respective matrices are in temporal order and do not have any elements in common. Accordingly,
we have the block-Hankel matrices,
Up ≜U0|r−1; Yp ≜Y0|r−1; Xp ≜X0|s−1
(23.104a)
Uf ≜Ur |2r−1; Yf ≜Yr |2r−1; Xf ≜Xr |r+s−1
(23.104b)
The key assumptions on the data are similar to those in input-output identiﬁcation:

Identiﬁcation of State-Space Models
687
A1 The system is reachable, meaning all states are excited. Mathematically,
rank(X0|r−1) = n
A2 Input is persistently exciting, at least of order r, meaning
rank(U0|r−1) = r
A3 The process is under open-loop condition. In linear algebra terms,
span(X0|r−1) ∩span(U0|r−1) = 0
In the developments to follow, we shall use what are known as the past and future data matrices,
Wp := W0|r−1 =
"U0|r−1
Y0|r−1
#
=
"Up
Yp
#
(23.105)
Wf := Wr |2r−1 =
"Ur |2r−1
Yr |2r−1
#
=
"Uf
Yf
#
(23.106)
This matrix Wp contains the Hankel matrix of IR coeﬃcients as a sub-matrix when it is constructed
from impulse response data.
Remarks:
Under the assumptions (A1) and (A2), the rank of Wp can be shown to be r + n (or rnu + n for
MIMO systems). See Katayama (2005) for proof.
As we shall see shortly, the LQ decomposition of Wp forms the basic step of subspace identiﬁca-
tion algorithm. On the other hand, the matrices Wp and Wf together provide estimates of the future
state sequence Xf .
23.6.1.1
MOESP Method
Developed by Verhaegen and Dewilde (1992a,b), the approach in this method consists of estimating
the extended observability matrix followed by the estimation of system matrices using the stacked
output equation (23.100). Observe that the unknowns are Or, Xp and Gr. The trick is to ﬁrst elimi-
nate the term involving Gr by projecting the output onto the orthogonal complement of Up.
YpΠ⊥
Up = OrXpΠ⊥
Up
(23.107)
The LHS of (23.107) can be computed entirely from data in a numerical eﬃcient manner from the
LQ decomposition of Wp (recall (23.87))
"Up
Yp
#
= Wp =
"L11
0
L21
L22
# "QT
1
QT
2
#
,
L11 ∈Rr×r,
Q1 ∈Rs×r,
L21 ∈Rr×r,L22 ∈Rr×r,
Q2 ∈Rs×r
(23.108)
as
YpΠ⊥
Up = L22QT
2
(23.109)
The derivation of (23.109) from the LQ decomposition in (23.108) is left as an exercise to the reader
(see Exercise E23.7).
Remarks:
The matrix L in (23.108) has a nice theoretical interpretation. Every top and bottom block column
of L constitutes an input-output pair. Consequently, each column of L22 is a free or natural response of the
system (since the upper right block of L is a matrix of zeros).

688
Principles of System Identiﬁcation: Theory and Practice
Equation (23.107) eﬀectively states that the column space of the extended observability matrix
Or and that of YpΠ⊥
Up are equal. Moreover, it can be established under the assumptions (A1) and
(A2) that
rank

YpΠ⊥
Up

= n
(23.110)
See Verhaegen and Verdult (2007, Chapter 9) for a proof.
In other words, SVD of the YpΠ⊥
Up recovers Or up to a similarity transformation, which is es-
sentially what we seek. Extending this idea, it can be said that the SVD of YpΠ⊥
UpT for any rank-n
T gives us an estimate of the extended observability matrix. The choice of T is driven by user-
preferences or numerical simplicity considerations.
Once the extended observability matrix is obtained, estimates of system matrices are constructed
using the shift property of Or explained earlier (refer to (23.52) and (23.53)) and an algebraic
workout of the L and Q factors, as explained below.
i. Estimates of extended observability matrix: As remarked earlier, SVD of YpΠ⊥
UpT yields an
estimate of Or in a basis space. A computationally eﬃcient choice of T is Q2 since the dimension
of YpΠ⊥
UpQ2 is much smaller than that of YpΠ⊥
Up.
Multiply both sides of (23.158) by Q2. The LHS of the resulting equation in consequence of
(23.109) simpliﬁes to
YpΠ⊥
UpQ2 = L22
(23.111)
due to the orthonormal property, QT
2 Q2 = Ir×r.
While the RHS of (23.158) multiplied by Q2 yields
OrXpΠ⊥
UpQ2 = OrXpQ2
(23.112)
The second identity is due to the fact Π⊥
UpQ2 = Q2, which follows from the LQ decomposition
of Wp in (23.108) and that Q1 is orthogonal to Q2.
Combining both results above and using (23.107), it follows that
OrXpQ2 = L22
(23.113)
Finally, it can be shown by virtue of assumption (A1) that (Katayama, 2005; Verhaegen and
Verdult, 2007),
rank(L22) = n
(23.114)
Thus, SVD(L22) recovers the extended observability matrix in a basis space,
Or = U1Σ1/2
1
(23.115)
where the RHS stems from SVD of L22
L22 =
f
U1
U2
g "Σ1
0
0
0
# f
V1
V2
g
= U1Σ1VT
1
(23.116)
analogous to the SVD of the Hankel matrix (23.66) in Ho and Kalman’s method.
Remarks:
The row space of the state sequence Xp lying in the row space of Q2 can also be recovered
from the SVD. Usually, this step is not implemented. The N4SID method is more suited to estimating the
state sequence.

Identiﬁcation of State-Space Models
689
ii. Determination of A and C: These estimates follow in a straightforward fashion from the proper-
ties of Or, as discussed earlier in (23.53) and (23.52). Recall also (23.68) from Ho and Kalman’s
method.
C = Ol (1,:)
A = O†
l Ol
(23.117a)
(23.117b)
iii. Determination of B and D: These matrices can be estimated in diﬀerent ways once A and C are
known. Note that one can set up exactly as many linearly independent equations as the number
of unknowns in B and D. However, a method that lends itself well to the noisy case is presented
below.
From the LQ decomposition of Wp in (23.108) and the past response equation in (23.101), we
have
Yp = OrXp + GrL11QT
1 = L21QT
1 + L22QT
2
(23.118)
Pre- and post-multiplying both sides of the above equation with UT
2 and Q1 yields
UT
2 Gr = U2L21L−1
11
(23.119)
Given the knowledge of Or one can set up linear equations with D and B as unknowns, as
follows.

P1
˜P2Or−1
P2
˜P3Or−2
...
...
Pr−1
PrO1
Pr
0

"D
B
#
=

M1
M2
...
Mr−1
Mr

(23.120)
where
UT
2 =
f
P1
· · ·
Pr
g
,
s.t. Pi ∈R(rny−n)×ny
(23.121a)
˜Pi =
f
Pi
· · ·
Pr
g
(23.121b)
U2L21L−1
11 =
f
M1
· · ·
Mr
g
,
Mi ∈R(rny−n)×nu
(23.121c)
which can be solved using least-squares methods8.
In summary, we have the following algorithm for the deterministic MOESP method.
Algorithm 23.1
Algorithm for deterministic SS identiﬁcation using MOESP
1. Given input-output data, construct Wp for a chosen r and s
2. Perform LQ decomposition as in (23.108).
3. Obtain estimate of extended observability matrix via SVD of L22 using (23.115).
4. Compute estimates of system matrices A and C using (23.117).
5. Compute least squares estimates of B and D using (23.120).
8For a purely deterministic system, it is suﬃcient to set up as many equations as the number of parameters in the system
matrices. The least squares approach is introduced here as a prelude to the noisy case.

690
Principles of System Identiﬁcation: Theory and Practice
Remarks:
An alternative way of estimating the matrices B and D along with the initial state vector x[0] is via
the output equation of a general ny × nu MIMO system:
y[k] = CAkx[0] + *.
,
k−1
X
n=0
uT [n] ⊗CAk−n−1+/
-
vec(B) + (u[k] ⊗Iny)
(23.122)
where vec(.) denotes the standard vectorization of a matrix and ⊗is the Kronecker product.
Knowing A and C, this is a linear equation in B and D with the parameter vector
θ =

x[0]
vec(B)
vec(D)

and therefore can be solved using linear regression techniques, such as the OLS methods of §14.3.1.
23.6.1.2
N4SID Method
The N4SID method, developed by Overschee and Moor (1994), identiﬁes the SS model by ﬁrst
estimating the states using the SVD of oblique projection of the future output onto past data and
future input spaces, followed by estimation of the state-space matrices.
An important relation that this method employs in addition to the stacked past and future response
equations in (23.101) and (23.102) is the following equation for Xf
Xf = ArXp + ¯Cd
r Up
(23.123)
where
¯Cd
r =
f
Ar−1B
· · ·
AB
B
g
(23.124)
is the reversed controllability matrix (the superscript is to denote the deterministic system). The
derivation of (23.123) is left as an exercise to the reader (see Exercise E23.9). We shall now learn
how (23.123) and the earlier equations (23.101) and (23.102) are collectively analyzed to yield an
estimate of the future states (as well as if desired the extended observability matrix).
The ﬁrst step is to recognize that Xf can be constructed entirely as a linear combination of the
past outputs and inputs using (23.101) as follows:
Xf = Ar (O†
rYp −O†
rCd
r Up) + ¯Cd
r Up = LpWp
where Lp ≜
f
( ¯Cd
r −O†
rCr )
ArO†
r
g
(23.125a)
(23.125b)
Substituting (23.125a) into the relation (23.102) for future outputs gives
Yf = OrLpWp + GrUf
(23.126)
In MOESP, the orthogonal projection was used to eliminate the term involving Up, which was then
followed by SVD to obtain an estimate of Or. In N4SID, the oblique projection of the future output
onto past data along the past inputs, followed by SVD is used to obtain an estimate of the future
states (as well as Or, if desired). The oblique projection not only eliminates the input term but as
we shall see in the noisy case, also removes the noise term (asymptotically).
Referring to (23.126), we have via oblique projection
Y/Uf Wp = [YΠ⊥
Uf ][WpΠ⊥
Uf ]†Wp
= OrLpWpΠ⊥
Uf [WpΠ⊥
Uf ]†Wp
= OrLpWp
(23.127)

Identiﬁcation of State-Space Models
691
The last relation is due to the fact that9
[WpΠ⊥
Uf ][WpΠ⊥
Uf ]†Wp = Wp
(23.128)
Thus, we have
Γr ≜Yf /Uf Wp = OrXf
(23.129)
It can be shown that Γr is of rank n under the assumptions of reachability and persistent excitation
(see Katayama (2005) for instance). SVD of Γr therefore gives us an estimate of the future states
and the observability matrix.
Once again, as in MOESP, the oblique projection is implemented via the LQ decomposition

Uf
Wp
Yf

=

L11
0
0
L21
L22
0
L31
L32
0


QT
1
QT
2
QT
3

(23.130)
We are now in a position to describe the main steps in the N4SID methodology:
i. Estimation of state sequence and observability matrix: As explained earlier, these are achieved
through the SVD of Γr in (23.129) or ΓrT,
rank(T) = n . The matrix Γr itself is computed
through the LQ decomposition in (23.130) and using the general result for oblique projection in
(23.92),
Γr = OrXf = L32L†
22Wp
(23.131)
The result of interest then follows.
Xf = T−1Σ1/2
1 VT
1
Or = U1Σ1/2
1
T,
T ∈Rn×n, det(T) , 0
(23.132a)
(23.132b)
where the matrices on the RHS are obtained from the SVD of Γr
Γr =
f
U1
U2
g "Σ1
0
0
0
# "V1
V2
#
(23.133)
ii. Estimation of system matrices: We have two possible routes for this purpose. The ﬁrst one is to
employ the same strategy as in the MOESP method, i.e., ﬁrst estimating A and C followed by
that of B and D, all from the estimate of the extended observability matrix.
An alternative approach is to simultaneously estimate the four matrices using the state sequence
estimates (Overschee and Moor, 1996) through a linear regression of the stacked state and output
equations
" ˜Xr+1
˜Yr
#
=
"A
B
C
D
# " ˜Xr
˜Ur
#
(23.134)
where
˜Xr+1 =
f
x[r + 1]
· · ·
x[r + N −1]
g
˜Xr =
f
x[r]
· · ·
x[r + N −2]
g
˜Yr =
f
y[r]
· · ·
y[r + N −2]
g
˜Ur =
f
u[r]
· · ·
u[r + N −2]
g
9The identity in (23.128) is not immediate / trivial since WpΠU⊥
f [WpΠU⊥
f ]† = I. However, under assumptions (A1) and
(A2), (23.128) can be proved. See Overschee and Moor (1996) for proof.

692
Principles of System Identiﬁcation: Theory and Practice
A step-by-step algorithm for N4SID is given below.
Algorithm 23.2
Algorithm for deterministic SS identiﬁcation using N4SID
1. Given input-output data, construct Wp, Uf and Yf for a chosen r and s.
2. Perform LQ decomposition of the big matrix as in (23.130).
3. Compute Γr using (23.131).
4. Perform SVD of Γr to obtain estimates of state sequence Xf and extended observability matrix Or.
5. Compute estimates of state-space matrices using either Or or the estimated state sequence as a
least squares solution10 to (23.134).
Remarks:
A key fact underlying the N4SID method described above is as follows: (Moonen et al., 1989;
Moor et al., 1988).
The matrix of future states Xf is at the intersection (space) of past and future output spaces for an LTI
system under the extended conditions of (A1) - (A3), i.e., with r replaced by 2r. Mathematically,
row space(Xf ) = row space(Wp)
[
row space(Wf )
(23.135)
A proof of this result is found in diﬀerent texts (see Katayama (2005) and Overschee and Moor (1996)). It is
based on a linear algebra perspective of (23.123) through the eyes of (23.102) and (23.101). Consequent to the
result in (23.135), the N4SID method described above belongs to the class of intersection methods (Overschee
and Moor, 1996).
In a later section for the deterministic-plus-stochastic case, we shall describe a third method
known as the canonical variate analysis (CVA) method. which is based on principal angles.
Remarks:
1. The two diﬀerent algorithms presented above share a similar platform, that of projections. As shown in
§23.5.1, the oblique and orthogonal projections are related to each other through a weighting matrix. There-
fore it is intuitive that all three algorithms can be brought under a single umbrella. Indeed so, a unifying
algorithm that encompasses all the three prominent subspace identiﬁcation methods discussed above is
available and can be found in Overschee and Moor (1996, Chapter 2). The main step in this uniﬁed approach
is the use of oblique projections followed by SVD of the suitably pre- and post-weighted projections. De-
tails of a more general version of this algorithm, i.e., for the deterministic-plus-stochastic case is presented
in §23.6.2.
2. For the deterministic linear case, the accuracy of the ﬁnal estimate is more or less independent of the method
used. The true diﬀerences only show in the presence of noise, which is the subject of the next section.
3. Most of the derivations above assumed a SISO system. Extension to the MIMO case is straightforward with
the diﬀerence that the input and output matrices of interest consist of block rows, each block consisting of
nu and ny rows, respectively.
4. The user deﬁned parameters r and s are typically chosen such that r is much greater than the guessed
maximal order and s ≫r, in fact nearly equal to the number of observations N in hand. On a somewhat
related note, it is also possible to have the past and future matrices to have a diﬀerent number of block rows.
10See the earlier footnote in the case of MOESP algorithm.

Identiﬁcation of State-Space Models
693
23.6.2
DETERMINISTIC-PLUS-STOCHASTIC SYSTEMS
The problem statement for the state-space identiﬁcation is as follows. Given N observations of
input-output data (input is free of errors, but output is corrupted with noise), obtain optimal estimate
of either the general state-space form in (23.3) or the innovations form in (23.45). For reasons
discussed in §23.3.2, usually the latter form is of interest.
Presence of stochastic component in the output does not alter the basic steps of subspace iden-
tiﬁcation, but certain additional steps and assumptions are required to identify the stochastic sub-
system, as enumerated below.
1. A prime diﬀerence between the deterministic and the noisy case is that the excess (w.r.t. the
system order) singular values of the extended observability matrix are no longer zero. Instead
these values now assume positive real numbers, the magnitude of which depend on the noise
levels. It is the relative magnitude of the singular values corresponding to the deterministic and
stochastic sub-system that facilitates the demarcation. High SNR results in relatively “small”
singular values in place of ideally zero ones.
2. Derivation of the stacked response equations with the inclusion of the stochastic sub-system
3. Statistical equivalents of the projection operations introduced in §23.5.1 are required to handle
the random components in the output. The ergodicity assumption is invoked for this purpose. See
§23.6.2.2.
4. Requirements on the statistical properties of the inputs have to be placed. The standard quasi-
stationarity assumption is invoked here.
5. Estimators now have to be assessed for their consistency / asymptotic unbiasedness property.
Below we study the extension of the response equations that we earlier derived for the determin-
istic case.
Basic response equations
All subspace identiﬁcation methods make use of the same equations, as in the deterministic case,
namely, the past and future output in (23.101) and (23.102), respectively, plus the future state equa-
tion (23.123) but with additional noise terms, as given below for the innovations form:
Yp = OrXp + GrUp + HrEp
Yf = OrXf + GrUf + HrEf
Xf = ArXp + ¯Cd
r Up + ¯Cs
r Ep
(23.136)
(23.137)
(23.138)
where Hr is essentially the stochastic counterpart of Gr, i.e., the matrix of impulse response coeﬃ-
cients for the stochastic model,
Hr =

I
0
0
· · ·
0
CK
I
0
· · ·
0
CAK
CK
I
· · ·
0
...
...
...
...
...
CAr−2K
CAr−3K
CAr−4K
· · ·
I

(23.139)
and ¯Cs
r is the reversed controllability matrix for the stochastic sub-system,
¯Cs
r =
f
Ar−1K
Ar−2K
· · ·
K
g
(23.140)

694
Principles of System Identiﬁcation: Theory and Practice
The quantities Ep and Ef are the stacked past and future vectors of innovations, respectively, in
analogy to the inputs and outputs. A similar set of equations can be developed for the general state-
space form (23.3), where the stochastic terms would essentially be past / future measurement / state
noise terms in the respective equations.
It may be recalled that one of the most important outcomes of subspace identiﬁcation is the devel-
opment of a numerical Kalman ﬁlter, i.e., estimation of optimal states purely from input-output data
without the need for a state-space model. This is at the heart of all subspace methods, and therefore
deserves a brief study, in the least.
23.6.2.1
Numerical Kalman State Estimates
We remarked towards the end of §23.3 that the optimal state estimates can be expressed as linear
combinations of past input-output data and the initial state. A consequence of this fact is that the
optimal state estimates can be directly obtained as orthogonal projections of future outputs Yf on
past input-output data Wp and future inputs. Thus, an explicit knowledge of the state-space model
is obviated. Both the foregoing points are captured in the formal statements below. We present only
the main results here. For more technical details and proofs, the reader is referred to Overschee and
Moor (1996, Chapter 4) and Verhaegen and Verdult (2007, Chapter 9).
Optimal states as linear combinations of past data
This is an extension of the result in (23.125a) that was derived for the deterministic case.
The future states in (23.138) can be re-written using (23.136) as
Xf = ArXp + ¯Cd
r Up + ¯Cs
r Ep
=
f
ArO†
r
( ¯Cd
r −ArO†
rGr )
( ¯Cs
r −ArO†
rHr )
g 
Yp
Up
Ep

Following which, the estimates of future states are obtained by replacing the past terms of the
innovations with their expected values
ˆXf =
f
ArO†
r
( ¯Cd
r −ArO†
rGr )
g "Yp
Up
#
(23.141)
where we have assumed past errors to be of zero-mean. The future Kalman states, can therefore
be expressed as
ˆXf = LpWp
(23.142)
where Lp is the same as deﬁned earlier in (23.125b) and ˆXf is constructed in the same way
as Xf for the deterministic case in (23.125a), but now in terms of extended observability and
controllability matrices.
The derivation above follows the concise development in Trnka (2005) and is valid under asymp-
totic (r →∞, N →∞) conditions.
An alternative approach to developing (23.142), also under asymptotic conditions, is presented by
Verhaegen and Verdult (2007, Chapter 9) in the context of linear regression.
Finally, a third way of arriving at (23.142) is by recursively evaluating the state equation (23.50a)
of the predictor form, upon which one obtains
Xf = LpWp + Ap
k Xr−p |r−p+s−1
(23.143)

Identiﬁcation of State-Space Models
695
where
Lp =
f
BK
AkBk
· · ·
Ap−1
K
Bk
g
(23.144)
is the controllability matrix of the predictor form.
If the estimated model is stable, i.e., all eigenvalues of AK are strictly inside the unit circle,
Ap ≈0 as p →∞. Thus,
ˆXf = LpWp
(23.145)
Although not explicitly obvious, the innovation state estimates in (23.142) and (23.145) are both
naturally a function of the initial guess x[0] and the covariance matrix P0 for the state. This fact
clearly comes out of a rigorous derivation using the non-steady Kalman ﬁlter such as the one given
in Overschee and Moor (1996).
The following theorem establishes a relation between the state estimates and the orthogonal pro-
jections of the future output on to the subspace of the past data and future inputs, thus setting up the
platform for numerically recovering the states from input-output data alone.
Theorem 23.2
Under open-loop conditions and the assumptions of persistent excitation, the optimal estimate
(prediction) of future outputs is asymptotically,
˜Yf = Yf /
"Wp
Uf
#
= Or ˆXf + GrUf
(23.146)
A proof of this result is given in Overschee and Moor (1996).
For an interpretation of this optimal prediction in the PEM framework, speciﬁcally the multi-step
ahead prediction error minimization, see §23.6.2.7.
The foregoing theorem gives birth to the idea of a numerical Kalman ﬁlter as follows. Through
a further orthogonal projection of ˜Yf onto the orthogonal complement of Uf , the second term of
involving Gr is eliminated. SVD of the resulting quantity recovers the optimal (Kalman) states
(and the observability matrix) in a basis space. This approach, in essence, amounts to an oblique
projection of Yf onto Wp along Uf , which is essentially the main idea of N4SID methods.
The projection operations have to be now interpreted in a statistical framework owing to the
presence of noise.
23.6.2.2
Statistical Interpretations of Projections
In order to transit from the geometric (projection) operations in the deterministic world to the sta-
tistical averaging in the stochastic domain, it is useful to know that projections in time domain are
equivalents of cross-covariance in the ensemble domain (recall for example the equivalence between
sample LS and the population LS solutions in §14.3.1 in this context).
Invoking the assumption of ergodicity (recall §7.5.6) we replace the statistical averaging by the
inﬁnite time-averaging. For this purpose, consider two zero-mean random vectors v ∈Rnv×1 and
w ∈Rnw×1 at any kth instant. Then, the covariance between these two vectors is replaced by its
asymptotic time averaged product
E(vwT ) →lim
N→∞
1
N
N−1
X
k=0
v[k]wT[k]
(23.147)

696
Principles of System Identiﬁcation: Theory and Practice
Now construct the matrices of observations
VN =
f
v[0]
· · ·
v[N −1]
g
WN =
f
w[0]
· · ·
w[N −1]
g
Then, the relation in (23.147) can be re-written as
Σv,w = lim
N→∞
1
N (VNWT
N )
(23.148)
When v and w are uncorrelated, the theoretical covariance is zero. Geometrically it means that the
orthogonal projection of (the row space) of VN on WN is zero asymptotically, i.e., as N →∞as
argued below.
lim
N→∞VN/WN = lim
N→∞(VNWN )(VNVT
N )†VN
=
 
lim
N→∞
1
N VNWN
!
lim
N→∞

 1
N VNVT
N
!†
VN

= Σ[v,w] lim
N→∞

 1
N VNVT
N
!†
VN

(23.149)
If v and w are uncorrelated, the RHS of (23.148) is zero, meaning the orthogonal projection of
VN on WN is zero but only asymptotically. It is primarily this reason that subspace identiﬁcation
methods work well for noisy data only when the available sample size is large.
Based on the foregoing discussion, we shall hereafter assume that the projections of ﬁnite-
dimensional matrices A ∈Rr×N onto B ∈Rj×Nand their products (A and BT) introduced earlier
for deterministic systems are to be evaluated now in a limiting sense, as follows:
ABT →Φ[A,B] ≜lim
N→∞
1
N ABT
A/B →[AΠB]l ≜lim
N→∞
1
N A/B = Φ[A,B]Φ†
[B,B]B
A/B⊥→[AΠ⊥
B]l ≜lim
N→∞
1
N A −[AΠB]l
A/BC →[A/BC]l ≜[AΠ⊥
B]l[CΠ⊥
B]†
l C
(23.150)
(23.151)
(23.152)
(23.153)
where the subscript l on [.] indicates that the quantity inside the square brackets is being evaluated
in a limiting sense.
The principal angles are also evaluated in a similar way, i.e., using limiting products:
[AAT]−1/2
l
[ABT]l[BBT]−1/2
l
= USVT
cos φi = σi, i = 1,· · · ,p
[A∢B] ≜
f
a1
· · ·
ap
g
= UT[AAT]−1/2
l
A
[A∢B] ≜
f
b1
· · ·
bp
g
= VT[BBT]−1/2
l
B
(23.154)
(23.155)
(23.156)
(23.157)
Remarks:
The evaluation of the limit is only done for theoretical purposes. In practice, we work with 1
N A/B

Identiﬁcation of State-Space Models
697
23.6.2.3
MOESP and N4SID Methods for the Full Case
In this section we shall primarily discuss extensions of the previously described three methods fol-
lowed by a description of the unifying algorithm that contains a family of numerical algorithms for
subspace identiﬁcation. The essential point in these extensions is that the methods for determinis-
tic scenario also practically carry forth to the deterministic-plus-stochastic case, albeit with some
theoretically important diﬀerences.
The three algorithms are presented under the assumption of quasi-stationary inputs.
1. MOESP algorithm: The ﬁrst step is similar to that in the deterministic case, i.e., as in (23.107),
but by applying it to (23.137). However the noise term does not correlate out to zero through this
operation as seen below.
[Yf Π⊥
Uf ]l = [OrXf Π⊥
Uf ]l +
:0
[GrUf Π⊥
Uf ]l + [HrEf Π⊥
Uf ]l
(23.158)
The aim now is to eliminate the term involving the noise, which can be done using the idea of
IV methods (recall §21.7.1). Use suitable instruments for this purpose. The requirements on the
instrument matrix, call it ΨI ∈Rp×s, are similar to those in the IV algorithms,
lim
N→∞
1
N HrEf Π⊥
Uf ΨT
I = 0
rank
 
lim
N→∞
1
N Xf Π⊥
Uf ΨT
I
!
= n
(23.159a)
(23.159b)
where n is the order of the system. A possible choice for the instruments is the set of past inputs,
i.e., ΨI = Up ∈Rr×s, which leads to the so-called PI-MOESP (past input MOESP) method.
However, this is only suitable when the process noise is absent.
In order to estimate the general innovations form (23.3), the instrument matrix should consist of
both past outputs and inputs as follows
ΨI =
"Up
Yp
#
= Wp ∈R2r×s
(23.160)
It can be shown that the instruments in (23.160) above satisfy both requirements in (23.159)
under open-loop conditions and persistently exciting (of order 2r + n) inputs (Verhaegen and
Verdult, 2007). This approach leads to the so-called PO-MOESP (past-outputs MOESP) method
(Verhaegen, 1994).
Multiplying both sides of (23.158) with ΨT
I = WT
p gives
lim
N→∞
1
N Yf Π⊥
Uf WT
p = lim
N→∞
1
N OrXf Π⊥
Uf WT
p
(23.161)
The RHS has rank n by virtue of the second property of the instruments and the assumptions
made earlier on the process and the inputs. Further, the LHS of (23.161) can also be shown
to have rank n. Consequently, one can perform SVD of the LHS to obtain an estimate of the
observability matrix Or.
However, as mentioned at the beginning of §23.6.2, it is no longer possible to clearly determine
the order as in the deterministic case. Only a heuristic approach can be employed. This is due to
the presence of noise, which produces non-zero values in place of the ideal zero singular values.
The matrix product on the LHS of (23.161) can be eﬃciently computed as
1
N Yf Π⊥
Uf WT
p = 1
N L32LT
22
(23.162)

698
Principles of System Identiﬁcation: Theory and Practice
where the matrices on the right-hand side stem from the LQ factorization as in (23.130) (Verhae-
gen and Verdult, 2007),
1
N

Uf
Wp
Yf

=
1
√
N

L11
0
0
L21
L22
0
L31
L32
0


QT
1 /
√
N
QT
2 /
√
N
QT
3 /
√
N

(23.163)
One can now perform a SVD of either 1
N L32LT
22 or
1
√
N
L32 to obtain a column space for the
extended observability matrix Or (see remark following (23.166)).
1
√
N
L32 = UdΣdVT
d + UsΣsVT
s
(23.164)
where the singular vectors Ud ∈Rr×n,Us and Vd,Vs are left and right singular vectors cor-
responding to the heuristically partitioned singular values into the “signiﬁcant” (non-zero)
Σd ∈Rn×n and “insigniﬁcant” (near-zero) Σs sets, respectively.
Neglecting the insigniﬁcant singular values and the corresponding vectors results in a truncated
SVD (in contrast to the deterministic case),
1
√
N
L32 ≈UdΣdVT
d
(23.165)
The extended observability matrix is then obtained from the truncated SVD as
Or = UdΣ1/2
d T,
det(T ∈Rn×n) , 0
(23.166)
where typically T = In×n.
With the estimate of extended observability matrix in hand, estimation of the system matrices
A, B, C and D follows the same procedure as in the deterministic diﬀerence, albeit with one
important diﬀerence. Equations (23.53) and (23.52) are no longer exact (due to the truncation of
the SVD) and therefore only least squares estimates can be obtained.
Remarks:
Computing SVD of
1
√
N
L32 in place of 1
N L32LT
22 to obtain Or is theoretically justiﬁed be-
cause of the following result:
rank
 1
√
N
L32
!
= n
(23.167)
Adopting this alternate route is identical to multiplying both sides of (23.161) on the right by

WpΠ⊥
Up WTp
−1/2
since
LT
22 =

WpΠ⊥
Up WT
p
1/2
(23.168)
Thus, eﬀectively PO-MOESP works with SVD of
Γ(M)
r
≜
 1
N Yf Π⊥
Uf WT
p
! 
WpΠ⊥
Up WT
p
−1/2
(23.169)
A step-wise summary of the MOESP method is presented below.

Identiﬁcation of State-Space Models
699
Algorithm 23.3
Algorithm for SS identiﬁcation using MOESP
1. Given input-output data, construct the block-Hankel matrices Uf , Yf and Wp for a chosen r
and s.
2. Perform LQ decomposition as in (23.163) (or (23.130)).
3. Compute SVD of
1
√
N
L32 (essentially of Γr in (23.169)).
4. Determine the order of the system by identifying the top n signiﬁcant singular values.
5. Estimate the extended observability matrix from the truncated SVD as in (23.166).
6. Compute estimates of system matrices A and C using (23.117), but now in a least squares
sense.
7. Compute B and D using (23.120), once again using the LS method.
The MOESP algorithm, in its original form, was devised at estimating the deterministic sub-
system. It does not in particular aim to estimate the states, and the stochastic sub-system, i.e.,
the Kalman gain K and the innovations covariance matrix. The truncated SVD in (23.165) can
be used to estimate the states, however, only in the row space of some matrix W , I. Verhaegen
and Verdult (2007) show a method of estimating states by ﬁrst establishing the equivalence of the
PO-MOESP method with the least squares method. The equivalence is achieved by showing that
the column spaces of matrices used in estimating the observability matrix in both methods are
identical, while the matrices themselves diﬀering by a weighting factor Verhaegen and Verdult
(2007). It turns out that the latter approach leads to the N4SID method, which deals with oblique
projections.
Remarks:
i. The equivalence of MOESP and N4SID method should not come as surprising for at least two dif-
ferent reasons. First, the MOESP method is based on IV-methods which have close relation to the LS
methods. Secondly, the LQ decomposition in (23.163) is identical to the LQ decomposition (23.130)
used for computing the oblique projection in the deterministic N4SID algorithm, with the only diﬀer-
ence being in how the factors are used.
ii. The foregoing reason, in fact, establishes that the oblique projection is potentially useful in eliminat-
ing both the input and the noise terms of the stacked output equation, a claim that was made at the
beginning of §23.6.1.2.
We are now well motivated to study the N4SID algorithm due to Overschee and Moor (1994).
2. N4SID algorithm: Applying ideas from the deterministic version and consequent to the closing
remarks of the MOESP method above, the approach here consists of using the (asymptotic)
oblique projection of the stacked response (23.137).
[Yf /Uf Wp]l = [OrXf /Uf Wp]l + [GrUf /Uf Wp]l + [HrEf /Uf Wp]l
(23.170)
We shall examine each term individually, starting with the ﬁrst term. It simpliﬁes to Or ˆXf
asymptotically, i.e., when both N →∞and r →∞by virtue of (23.142):
lim
r→∞, N→∞
1
N Xf /Uf Wp = ˆXf
(23.171)
The second term is zero by the property of the oblique projection, B/BC = 0.
[Uf /Uf Wp]l = 0
(23.172)

700
Principles of System Identiﬁcation: Theory and Practice
Finally, the last term vanishes to zero asymptotically,
[Ef /Uf Wp]l = lim
N→∞
1
N Ef Π⊥
Uf = 0
(23.173)
by virtue of the uncorrelated property of the future errors with past data and with the future inputs
under open-loop conditions.
Remarks:
The distinction between Xf and ˆXf is that the latter is the estimate of the innovations sequence,
while the former is the theoretical Kalman state sequence.
In summary, we have
Γ(N4)
r
≜lim
N→∞
1
N Yf /Uf Wp = lim
N→∞
1
N Or ˆXf
(23.174)
The above result can also be derived from an instrumental variable approach.
The state estimates are obtained using the estimated Or
ˆXf = ˆO†
r Γr
(23.175)
or alternatively from the SVD factorization itself.
Estimation of system matrices can be once again carried out in the same way as in MOESP.
The N4SID method, as was proposed in its original form, uses the state estimates and the lin-
ear regression approach (similar to the deterministic case) as follows. First estimate the state
sequences,
ˆXi ≜ˆXf = ˆO†
r Γr
(23.176)
ˆXi+1 ≜ˆO
†
r Γr+1
(23.177)
then, perform the linear regression
" ˆXi+1
Yi
#
=
"A
B
C
D
# " ˆXi
Ui
#
+
"εx
εy
#
(23.178)
to obtain the state-space matrices. This procedure also gives the noise covariance matrices, Q,
R and S, from which the Kalman gain and the innovations covariance can be estimated (recall
(23.48)).
There exist other options and more robust approaches to estimation of the state-space matrices
from the extended observability matrix. Two such algorithms will be outlined shortly.
23.6.2.4
CVA Method
The canonical variate analysis method due to Larimore (1990), as remarked earlier, estimates the
system matrices by ﬁrst estimating the state sequence. However, it diﬀers from N4SID in that the
CVA uses the principal angles and principal directions between the row space of projected past data
Wp/U⊥
p and that of projected future outputs Yf /U⊥
p. The basis of this approach is the method of
canonical correlation analysis in stochastic subspace identiﬁcation (Akaike, 1974b; Arun and Kung,
1990; Overschee and Moor, 1993b).
An important result is that the system order is identical to the number of principal angles (between
the above-mentioned subspaces) that are diﬀerent from π/2. A technical discussion of the CVA
method is beyond the scope of this text. The reader is referred to Larimore (1990) for related details.
A point that deserves to be highlighted is that the CVA method is insensitive to scaling of input
data, which is a key advantage that it holds over the N4SID and MOESP methods. In other words, the
state-space model estimates are invariant to choice of units. This characteristic of CVA is attributed

Identiﬁcation of State-Space Models
701
to the fact that it uses scale-invariant measures such as angles and normalized directions. However,
unlike the N4SID method, this technique only estimates the projections of the states ˆXf /U⊥
f (using
the principal directions) but not the states themselves.
As remarked previously, all algorithms above can be brought under a single umbrella as summa-
rized below.
23.6.2.5
Uniﬁed Algorithm
From the descriptions of the methods above, it is clear that the three diﬀerent approaches essentially
share the same core idea, which is that of computing an appropriate projection of the output onto
the space of past inputs and outputs, and the future inputs. The key requirements on this projection
are that it should
i. Have rank n
ii. Be devoid of any input and noise terms
iii. Have the same column space as that of the extended observability matrix
iv. Be entirely computable from data.
The diﬀerences in the three methods is then essentially a pre- and post-multiplication of this projec-
tion by suitable weights W1 and W2, respectively. As a matter of fact, we could use the projection
from any of the previously discussed methods as a reference and express the remaining two as a
weighted version of this reference. In this respect, each piece of literature on subspace identiﬁcation
uses a diﬀerent reference projection. Three such uniﬁcations are discussed below.
For each of the unifying approaches, we ﬁrst describe the core entity Γr and then present the
three previously described methods as W1ΓrW2 to obtaining Or and/or Xf via SVD. Regardless of
the unifying framework, the weights should satisfy two requirements, namely, W1 should be non-
singular and W2 should not reduce the rank of WpW2 (or that of OrLp).
1. Projection approach (Overschee and Moor, 1996): The basic engine is constructed from the
oblique projection algorithm of the N4SID method,
Γr = [Yf /Uf Wp]l = [Yf Π⊥
Uf ]l[WpΠ⊥
Uf ]†
l Wp
(23.179)
and the three algorithms are computed with the following weighting matrices:
a. N4SID: W1 = I,W2 = I
b. MOESP: W1 = I,W2 = Π⊥
Uf
c. CVA: W1 = (Yf Π⊥
Uf )(Yf Π⊥
Uf )T )−1/2,W2 = Π⊥
Uf
For detailed proofs of the above relations, the reader is referred to Overschee and Moor (1996).
2. Linear LS-plus-IV approach (Verhaegen and Verdult, 2007): Here, the core estimate of the ob-
servability matrix is derived in a linear regression setting using the stacked future response equa-
tion (23.137) and the expression for optimal states (23.142) as linear combination of past input-
output data as follows:
Yf = OrLp
|{z}
Hr p
Wp + GrUf + HrEr
(23.180)
Eliminating the input term through an orthogonal projection and the noise term using the instru-
ments ΨI results in a linear regression involving Hr p. Applying the LS solution produces the
core entity for this unifying framework:
Γr = ˆHr p = (Yf Π⊥
Uf ΨT
I )(WpΠ⊥
Uf ΨT
I )†
(23.181)
The weighting matrices for the three algorithms then follow (see Verhaegen and Verdult (2007)
for derivations):

702
Principles of System Identiﬁcation: Theory and Practice
a. N4SID: W1 = I,W2 =

ΨI ΨT
I
1/2
b. MOESP: W1 = I,W2 = (ΨIΠ⊥
Uf ΨT
I )1/2
c. CVA: W1 = (Yf Π⊥
Uf Yf )−1/2,W2 = (ΨIΠ⊥
Uf ΨT
I )1/2
where a standard choice of ΨI is Wp. For more insights into connections between SSID and
regression approaches, refer to §23.6.2.7.
3. Instrumental variable approach (Ljung, 1999): The IV approach, as derived in the MOESP
method, is used to construct the basic entity11
Γr = 1
N Yf Π⊥
Uf ΨT
I
(23.182)
where ΨI is the matrix of instruments satisfying the previously deﬁned conditions. The three
algorithms then specialize with the weights
a. N4SID: W1 = I,W2 =
 1
N ΨIΠ⊥
Uf ΨT
I
!−1
ΨI
b. MOESP: W1 = I,W2 =
 1
N ΨIΠ⊥
Uf ΨT
I
!−1
ΨIΠ⊥
Uf
c. CVA: W1 =
 1
N Yf Π⊥
Uf Yf
!−1/2
,W2 =
 1
N ΨIΠ⊥
Uf ΨT
I
!1/2
where once again a typical choice of instrument is ΨI = Wp.
We next discuss how to estimate the main quantities of interest, namely, the system matrices,
noise covariances and the Kalman gain.
23.6.2.6
Estimation of System Matrices, Noise Covariance and Kalman Gain
Having obtained an estimate of the extended observability matrix, there are diﬀerent ways in which
the system matrices can be obtained.
Estimating the deterministic sub-system
We discuss two diﬀerent ways which bear similarity to the methods in §23.6.1.
1. In this approach, ﬁrst estimate A and C using the shift property of the observability matrix -
essentially (23.117), but in a least squares sense for A
ˆC = ˆOr (:,1 : n)
A = O†
l Ol
(23.183)
(23.184)
Subsequently estimate B, D and x[0] via a linear regression approach of the MOESP-type ap-
proach. At this point, two diﬀerent options exist depending on whether one sets the Kalman gain
K = 0 or not. These are known as the simulation and prediction options, respectively.
a. Simulation12, K = 0: Minimize the inﬁnite-step ahead prediction-error:
ˆB, ˆD, ˆx[0] =
min
{B,D,x[0]}
N−1
X
k=0
*
,
y[k] −Du[k] −(
k−1
X
l=0
u[l]CAk−l−1)vec(B)+
-
2
(23.185)
11Note that Ljung (1999) uses Π⊥
UT
f
in place of Π⊥
Uf due to a slightly diﬀerent deﬁnition of the projection matrix.
12For this case, the extended observability matrix can be estimated using the PI-MOESP method, i.e., by choosing ΨI =
Up.

Identiﬁcation of State-Space Models
703
This is akin to ﬁtting an OE model, where noise dynamics are not modeled. The resulting
estimation amounts to shaping the transfer function bias by the input spectrum from the
frequency-domain interpretation of OE ﬁts described in §21.5.
b. Prediction, K , 0: The one-step ahead predictor, derived by recursively applying the output
equation of the predictor form (23.50) (see Exercise E23.10) is given by,
ˆy[k] = C(A −KC)kx[0] +
k−1
X
l=0
C(A −KC)k−r−1(B −KD)u[l] + Du[k]+
+
k−1
X
l=0
C(A −KC)k−l−1Ky[l]
(23.186)
Estimate B, D and ˆx[0] by minimization of one-step ahead prediction error
ˆB, ˆD, ˆx[0] =
min
{B,D,x[0]}
N−1
X
k=0
(y[k] −ˆy[k])2
(23.187)
This route is similar to ﬁtting a deterministic and a noise model, as is done for non-OE
structures.
2. The second approach is based on the N4SID approach of estimating states ﬁrst followed by a
linear regression to estimate the system and noise covariance matrices. This method is compu-
tationally light, but unfortunately produces biased estimates whenever the input is band-limited
(which is usually the case in practice). A reason for the bias is that it does not estimate the initial
state x[0] in contrast to the previously described approach. The reader is referred to Overschee
and Moor (1996, Chapter 4) for further details.
Estimating noise covariance matrices
There are at least two diﬀerent ways of estimating these quantities:
1. The ﬁrst method is to use the approach outlined in the N4SID technique earlier, i.e., solve the
linear regression equations of (23.178). However, it gives unbiased estimates only under certain
restrictive conditions (see Overschee and Moor (1996)). On the other hand, it is computationally
lighter than the robust algorithm outlined below.
2. The idea is to solve again a set of linear regression equations for estimated states
" ˆXr+1
Yr |r
#
=
"A
B
C
D
# " ˆXr
Ur |r
#
+
"εx
εy
#
(23.188)
but the state estimates are constructed diﬀerently from the way in (23.178). Equation (23.146)
and its shifted version are used for this purpose. We directly provide the ﬁnal expression that
comes about
"
O†
r−1Zr+1
Yr,r
#
=
"A
C
#
O†
rZr +
"εx
εy
#
KUf +
(23.189)
where
Zr ≜Yf /
"Wp
Uf
#
(23.190)
Zr ≜Y−
f /
"W+
p
Uf
#
(23.191)

704
Principles of System Identiﬁcation: Theory and Practice
The quantities Y−
f and W+
p are obtained by shifting the “past” and “future” one down, while the
matrix K is a linear function of B and D (not given here, see Overschee and Moor (1996, pg.
118)) once A and C are known.
Solving the regression equation thus gives the residuals from which the noise covariance matrices
Q, R and S can be estimated.
"Q
S
S
R
#
= 1
N
N−1
X
k=0
"εx[k]
εy[k]
# f
εx[k]
εy[k]
g
(23.192)
As a matter of fact, matrices B and D can also be recovered from the estimate of K obtained from
the regression. However, the method described earlier is followed in practice.
Estimating Kalman gain K
The Kalman gain can also be estimated in a few diﬀerent ways:
1. Estimate K only using A, C and the noise covariance matrices, an approach that is also widely
followed.
2. From the estimates of A,B,C,D and Q,R,S using the deﬁnition in (23.49). This is the classical
approach.
3. Perform the SVD of ˆHp = ˆOr ˆLp to obtain an estimate of ˆLp. Subsequently recover K noting
that Lp is the controllability matrix constructed from (AK,Bk).
Finally, we put together a widely followed algorithm for the complete SS model estimation of a
SISO system based on the considerations of asymptotic unbiasedness and robustness.
Algorithm 23.4
Estimating a deterministic-plus-stochastic SS model
1. Estimate the extended observability matrix as ˆOr (preferably using CVA weights).
2. Compute estimates of A and C using the shift property.
3. Arrive at estimates of noise covariance matrices Q, R and S and the Kalman gain (if the disturbance
model is desired) using (23.192) and the steady-state version of (23.49).
4. Estimate B, D and x[0] using either the simulation or prediction option as per requirements.
Remarks:
There is also an additional option of enforcing stability, as remarked earlier. This is realized through
an alteration in the estimation of A from two versions of the extended observability matrices. Overschee and
Moor (1996) discuss these details in depth.
The algorithms outlined above are illustrated next using the MATLAB System Identiﬁcation Tool-
box on the process of Example 23.5 with a stochastic term.
Example 23.7: Estimation of a State-Space Model Using Subspace ID Methods
The data generating process is an ARMAX process with the deterministic part identical
to that of Example 23.5
y[k] =
0.5q−1 + q−2
1 −1.2q−1 + 0.35q−2 u[k] +
1 + 0.4q−1
1 −1.2q−1 + 0.35q−2 e[k]
(23.193)
2046 samples of input-output data are generated using a PRBS input with frequencies in the
range [0 0.2] cycles/sample.

Identiﬁcation of State-Space Models
705
0
2
4
6
8
10
12
−1
0
1
2
3
4
5
6
Log of Singular values
Model order
Red: Default Choice (2)
Select model order in Command Window.
FIGURE 23.5
(SEE COLOR INSERT) Plot of Hankel singular values for the system in Example 23.7.
After the usual data pre-processing and partitioning, the delay is estimated to be unit
sample using the IR method.
The order is determined using the (Hankel) singular values of the matrix in (23.182). The
default choice made by the algorithm, as shown in Figure 23.5, is 2.
Running the MOESP algorithm, i.e., with K = 0 and choosing a large prediction horizon
(the “simulation” option in n4sid) gives us the following second-order SS model estimate:
ˆA =
" 0.8826
0.8347
−0.08225
0.3128
#
,
ˆB =
"−2.171
−1.08
#
,
ˆC =
f
−0.6129
0.7601
g
, D = 0
(23.194)
Setting the weighting corresponding to CVA algorithm and keeping other options the same
yields the deterministic model estimate:
ˆA =
" 0.8895
0.1606
−0.4523
0.3057
#
,
ˆB =
"0.007
0.021
#
,
ˆC =
f
179.6
−35.41
g
, D = 0
(23.195)
which has evidently a diﬀerent state-space basis from the one in (23.194). Additionally, it is
useful to know that the CVA choice of weights leads to much lower parameter sensitivities
(not reported above) than that of the MOESP, in agreement with the remarks made earlier.
However, both result in the same extent of ﬁt on the training data and auto-correlated
residuals (since the noise dynamics are not modeled).
Finally, we estimate the full state-space model using the CVA weighting,
ˆA =
" 0.9169
0.3758
−0.2406
0.2795
#
,
ˆB =
"−0.0007
0.022
#
,
ˆK =
"0.0082
0.0029
#
ˆC =
f
181.5
26.48
g
, D = 0
(23.196)
The residual analysis now conﬁrms white residuals (not shown here) as well as insigniﬁcant
cross-correlation between u and ε.
It is instructive to compare the transfer function obtained by converting the estimated
model in (23.196)
ˆG(q−1) =
0.4699q−1 + 1.016q−2
1 −1.196q−1 + 0.3467q−2 ,
ˆH(q−1) = 1 + 0.365q−1 + 0.0089q−2
1 −1.196q−1 + 0.3467q−2
(23.197)
with the data generating process in (23.193). Observe that an extra coeﬃcient (corresponding
to q−2) appears in the numerator of the noise model. We can choose to ignore this and also
further estimate a parametrized state-space model with a canonical form corresponding to the
ARMAX structure. This is taken up in Example 23.9 of §23.7.
The reader is encouraged to explore other estimation options in the n4sid routine of the
toolbox.

706
Principles of System Identiﬁcation: Theory and Practice
Until this point we have maintained a fact that SSID methods are non-iterative and do not explic-
itly involve an optimization formulation. However, that does not make these methods sub-optimal
in any way. In fact, they are as optimal as PEM methods with certain options and additional embel-
lishments. This aspect is outlined in the following section.
23.6.2.7
Interpreting SSID Methods in the PE Framework
The diﬀerent unifying methods presented above clearly suggest that subspace identiﬁcation ap-
proaches are equivalent to solving regression-type problems for estimating state-space models. The
main diﬀerence being the absence of an explicit optimization formulation in the 4SID methods and
the use of projections for obtaining the estimates. It can be shown that these estimates are essentially
solutions to multi-step ahead prediction error minimization problems in contrast to the standard one-
step ahead PE minimization of the PEM methods. To recognize this connection, consider the m-step
prediction, m = 1,· · · ,r −1 of the output using the innovations form in (23.45),
ˆy[k + m|k] = CAmx[k] + Du[k + m] +
m−1
X
n=0
CAm−n−1Bu[k + n]
(23.198)
Evaluating the above expression at m = 1,· · · ,r −1 and stacking the resulting predictors along with
ˆy[k] = E(y[k]) for a given starting point k yields

ˆy[k]
ˆy[k + 1]
...
ˆy[k + r −1]

= Γrx[k] + Gr

u[k]
u[k + 1]
...
u[k + r −1]

(23.199)
Collecting such stacked predictions (in columns) for diﬀerent starting points in time k = r,r +
1,· · · ,r + s −1 gives us a familiar looking equation
ˆYf = OrXf + GrUf
(23.200)
From (23.142), the states can be replaced as a linear combination of past data13. Consequently, the
predictor equation can be re-written as,
ˆYf = OrLwWp + GrUf = HpWp + GrUf
(23.201)
Setting up the prediction-error minimization problem
min
Hp,Gr ||Yf −ˆYf ||2
F = min
Hp,Gr

Yf −
f
Hw
Gr
g "Wp
Uf
#
2
F
(23.202)
where ∥.∥2
F is the squared Frobenius-norm.
Denote Z =
"Wp
Uf
#
. Using the standard LS solution (14.21) and the deﬁnition of orthogonal
projection, the optimal prediction is obtained as
ˆY⋆
f = Yf ZT (ZZT )Z = Yf /Z = Yf /
"Wp
Uf
#
(23.203)
13This relation is exact strictly only under asymptotic conditions, i.e., r, s →∞.

Identiﬁcation of State-Space Models
707
which is identical to the result stated earlier in Theorem 23.2.
Further, using (23.201) and the deﬁnition of oblique projection it can be shown that
OrLwWp = Or ˆXf = Yf /Uf Wp
(23.204)
which is none other than the N4SID solution.
In addition to the connections of the SSID solution with the multi-step PE estimate, a few other
important points are noteworthy:
1. The user-deﬁned parameter r is none other than the prediction horizon of the subspace iden-
tiﬁcation methods.
2. Choosing the size of Wp amounts to selecting the order of the model (number of past outputs)
in the predictor expression. In order to understand this fact, recognize that (23.201) is a
compact way of writing the diﬀerence equation form, speciﬁcally that from an ARX model.
In general, 4SID methods use as much past data as possible. Thus, the (23.201) corresponds
to a predictor from a very high-order ARX model.
3. From the discussion above, order selection through the truncation of SVD of the core matrix
Γr can be eﬀectively treated as the estimation of a reduced-order model for the given system.
4. Putting together the points above, it can be said that subspace identiﬁcation methods essen-
tially ﬁt high-order ARX models followed by a model-order reduction step. This also partly
explains the suitability of the projection approaches (which produce linear LS estimates)
used in the 4SID methods.
5. The weighting matrices W1 and W2 serve as suitable frequency-domain weights on the
model-order reduction step. Essentially, they shape the frequency domain characteristics of
the reduced-order model that is eventually identiﬁed. These concepts constitute the frequency
weighted balanced truncation technique for model reduction due to Enns (1984) applied to
SSID (Overschee and Moor, 1993a). A technical elaboration of this point is beyond the scope
of this text. The reader is referred to Overschee and Moor (1996, Chapter 5) for technical elu-
cidations of this point.
6. Consequent to the point above, each of the three methods, namely, N4SID, MOESP and
CVA, can be eﬀectively seen as adopting a diﬀerent model-order reduction strategy, thereby
resulting in models with diﬀering frequency-domain ﬁts.
Next we discuss the choices available to the user in subspace identiﬁcation.
Design choices in subspace identiﬁcation
From the developments in the previous section, it it clear that the subspace identiﬁcation algorithms
have essentially the following user choices:
1. Prediction horizon r: Determination of an appropriate value of this parameter is usually done
using AIC-like measures.
2. Number of past outputs and inputs: In the derivation of the 4SID algorithm previously we have
assumed Wp to be consisting of 2r rows. However, this is ﬂexible, meaning the user is free to
choose pu and py terms for the input and output, respectively. Flexibility also exists in the choice
of instruments. If no disturbance model is desired, that when K = 0, recall from §23.6.2 using
past inputs alone as instruments is suﬃcient.
3. Weighting matrices: As noted earlier, diﬀerent options exist. Ljung (2003) observes that the CVA
weights as per the unifying algorithm in (23.182) is the best choice from the consideration of
goodness of data ﬁt14. In Bauer and Ljung (2002), Gustafsson (2002) and related works, the
14The MATLAB System Identiﬁcation Toolbox implements this as the default choice.

708
Principles of System Identiﬁcation: Theory and Practice
statistical properties of ˆOr and the inﬂuence of the weighting matrices on the variance of the
estimates are studied. It is shown in Bauer and Ljung (2002) that the CVA weights theoreti-
cally result in minimum or low variance estimates in the white-noise input case. Ljung (2003)
corroborates these ﬁndings through simulation studies.
4. Model order: There exist no theoretical results yet to determine the true model order. In practice,
only heuristic approaches are followed and the ﬁnal order is determined by means of residual
analysis as outlined in §22.6.3. The problem of determining the true nx from the SVD of ˆOr
in the noisy case is strikingly similar to the determination of the correct number of linear re-
lationships among the deterministic variables from measured data in multivariable identiﬁcation
principal component analysis. In both cases, the problem is that of determining non-zero singular
values, but of diﬀerent matrices. See §26.3.3 for further discussion.
5. Method of estimating system matrices: The previous sections have established, albeit not exhaus-
tively, that there exist diﬀerent ways of the state-space matrices. Also see §23.6.2.6 below. In
selecting an appropriate approach, the factors to consider are (asymptotic) unbiasedness, eﬃ-
ciency and robustness. Stability (of the identiﬁed model) can also be another important factor
in certain applications. Section 23.6.2.6 outlines a few time-tested algorithms that have worked
well for several data. For more details, read among many references, Overschee and Moor (1996)
and Qin (2006).
6. Regularization: Subspace identiﬁcation approaches identify non-parametric or freely parametrized
models and as a result, almost always suﬀer from over-parametrization. Regularization, as in the
I/O identiﬁcation, is a natural way of dealing with this issue. It is also appealing since it does not
require any parametrization. Recently, a few methods have been proposed along these lines. It
may be noted that regularization can also aid in model-order reduction and imparting stability to
the estimated model.
23.7
STRUCTURED STATE-SPACE MODELS
In the previous section, we studied the estimation of unstructured state-space models using non-
iterative subspace identiﬁcation methods. As remarked at the beginning of this chapter, quite often
we are compelled to impose structural constraints on state-space models for at least three prominent
reasons:
(S1) To identify the state-space model corresponding to a speciﬁc input-output model form, e.g., AR-
MAX structure.
(S2) To obtain physically meaningful states, which is a natural requirement in state estimation prob-
lems. In other words, we are interested in estimating state-space models whose structures have
been derived from physical insights or ﬁrst-principles approaches.
(S3) To estimate physical / chemical parameters or properties of continuous-time dynamic systems;
for example, one may be interested in estimating the valve or reaction rate constants of a process.
Regardless of the situation, the consequence is that the matrices have non-zero entries only in spe-
ciﬁc locations unlike in the freely parametrized case. The natural advantage of working with struc-
tured state-space models is parsimony and identiﬁability, but these come with the price of added
computational cost because the associated estimation problem consists of a constrained optimiza-
tion problem.
Structured state-space models lead to parsimonious, identiﬁable and/or physically meaningful
representations, however, their estimation involves signiﬁcant additional computational costs
compared to their unstructured counterparts.

Identiﬁcation of State-Space Models
709
The non-zero entries are essentially treated as parameters θ and then we write the state-space
model as (also recall (18.68))
x[k + 1] = A(θ)x[k] + B(θ)u[k] + K(θ)e[k]
y[k] = C(θ)x[k] + D(θ)u[k] + e[k]
(23.205a)
(23.205b)
where we notice now that the Kalman gain has also been parametrized. The model in (23.205) is
often known as a parametrized state-space model.
At a ﬁner level of consideration, we distinguish between two scenarios:
(1) parameters of interest are directly the non-zero entries but generally lack a physical meaning,
(2) parameters of interest may have a one-to-one or implicit correspondence with the non-zero en-
tries, but more importantly are physically meaningful.
Thus, within the structured state-space models we have two sub-classes, namely, parametrized
black-box and grey-box state-space models depending on the prior knowledge that drives the struc-
ture. In order to distinguish between these two scenarios, we denote the parameter vector by β for
the ﬁrst class of situations (corresponding to (S1)) and θ to denote the parameters of the grey-box
models (corresponding to scenarios (S2) and (S3) above). The following sections brieﬂy discuss the
estimation of these two diﬀerent classes of models mainly using illustrative examples.
23.7.1
PARAMETRIZED LINEAR BLACK-BOX MODELS
We begin this section with an example of a parametrized linear black-box model that is motivated
by a transfer function form.
Example 23.8: Innovations Form of an ARMAX(2,1,2) Model
Consider the symbolic ARMAX(2,1,2) process of Example 23.1:
y[k] =
b1q−1 + b2q−2
1 + a1q−1 + a2q−2 u[k] +
1 + c1q−1
1 + a1q−1 + a2q−2 e[k]
(23.206)
Writing the diﬀerence equation form and introducing states
y[k] + a1y[k −1] + a2y[k −2] = b1u[k −1] + b2u[k −2] + e[k] + c1e[k −1] + c2e[k −2]
x1[k] = y[k] −e[k]; x2[k] = −a1y[k −1] + c1e[k −1]
yields the innovations form
x[k + 1] =
"−a1
1
−a2
0
#
x[k] +
"b1
b2
#
u[k] +
"(c1 −a1)
(c2 −a2)
#
e[k]
(23.207)
y[k] =
f
1
0
g
x[k] + e[k]
(23.208)
Comparing with the innovations form (23.45), it is clear that the Kalman gain is now
parametrized in terms of the plant and noise model parameters. The obtained SS model
is in the observer canonical form, and is therefore identiﬁable according to the result in
§18.6.2.
In a parametric state-space identiﬁcation, the user estimates either the non-zero entries of
the state-space matrices or even better the ﬁve-dimensional parameter vector
β =
f
a1
a2
b1
c1
c2
gT
instead of estimating 4 + 2 + 2 + 2 = 10 unknowns of a non-parametric form.
A similar parametrization can also be derived for a more general B-J model structure.

710
Principles of System Identiﬁcation: Theory and Practice
A class of parametrized black-box models, also known as canonical models, is commonly de-
ployed for identiﬁcation. Recall §4.4.3.1 in this context, where we discussed diﬀerent canonical
forms such as the modal form, controllable / controllability canonical form and the observable / ob-
servability canonical form of deterministic state-space descriptions. One may directly choose from
this basket of canonical forms or derive the required form as in Example 23.8 above.
From §18.6.2, for SISO systems, recall that any of the canonical forms discussed in §4.4.3.1 are
identiﬁable. The observer canonical form is a popular choice in this respect, as also remarked in
§18.6.2.
Estimation of parametrized SS models
Parametrized or canonical forms such as the one discussed in the example above are estimated
through the regular PEM methods of Chapter 21. The state-space representation is converted to the
input-output form
y[k] = C(qI −A)−1Bu[k] + [C(qI −A)−1K + I]e[k]
(23.209)
where each matrix is parametrized, i.e., A(θ), B(θ) and so on. Subsequently, the PEM method to
determine the optimal estimates. Additionally, any constraints on the parameters may also be added
to the optimization problem. The properties of the resulting estimates are essentially those of the
PEM, as discussed in §21.4.
Remarks:
Note that since the parametrized SS models are identiﬁable (provided they are in the canonical
forms), it is possible to compute errors in the entries of state-space matrices unlike in the unstructured case.
These error calculations are carried out on the same lines as those discussed for input-output models in §21.4.
The following example illustrates the estimation of a structured state-space model using the
MATLAB System Identiﬁcation toolbox.
Example 23.9: Estimation of a Structured State-Space Model
Consider the ARMAX data generating process (of Example 23.8 with c=0)
y[k] =
0.5q−1 + q−2
1 −1.2q−1 + 0.35q−2 u[k] +
1 + 0.4q−1
1 −1.2q−1 + 0.35q−2 e[k],
e[k] ∼GWN(0,0.2)
(23.210)
excited by a PRBS input containing frequencies in the range [0, 0.2] rad/sample and 2046
samples of the input-output data are generated.
The goal is to develop a state-space model with the following canonical forms.
(SS1)
A =
"0
1
×
×
#
, B =
"×
×
#
, K =
"×
×
#
, C =
f
1
0
g
(SS2)
A =
"×
1
×
0
#
, B =
"×
×
#
, K =
"×
×
#
, C =
f
1
0
g
For this purpose, the data is subjected to the usual pre-processing (removal of mean). The
delay is estimated to be 1 unit sample using the IR estimation method.
Recognize that the model in SS1 is the observability canonical form, while the one in SS2
is the observer canonical form (refer to §4.4.3.1).
The MATLAB script to estimate the above models is given below. In both cases, initial
guesses of the structures have to be generated. For SS1, the initial estimate is generated
by transforming the freely parametrized to the desired canonical form. The initial guess for
SS2 is constructed manually using the idss routine. Running these guesses through the pem

Identiﬁcation of State-Space Models
711
routine gives us the following optimal estimates (with D = 0) :
(SS1)
ˆA =

0
1
−0.348
(±0.01)
1.197
(±0.01)

,
ˆB =

0.495
(±0.014)
1.606
(±0.02)

,
ˆK =

1.653
(±0.026)
1.687
(±0.048)

, C =
f
1
0
g
(23.211a)
(SS2)
ˆA =

1.197
(±0.01)
1
−0.348
(±0.01)
0

,
ˆB =

0.495
(±0.014)
1.103
(±0.016)

,
ˆK =

1.653
(±0.026)
−0.2921
(±0.031)

, C =
f
1
0
g
(23.211b)
Residual analysis (not shown here) conﬁrms the adequacy of the model. The estimates, as
evident from the errors, are signiﬁcant. Thus, the estimated models are satisfactory in these
essential aspects. An interested reader may cross-validate these models on the test data.
Listing 23.5
Sample code to estimate structured SS models
%% Data generating process
mod_dgp = idpoly([1 -1.2 0.35],[0 0.5 1],[1 0.4],1,1,’Ts’,1);
uk = idinput(2046,’prbs’,[0 0.4],[-1 1]);
ykdet = sim(mod_dgp ,uk);
mod_dgp.Noisevariance = 0.2; % SNR 11
yk = sim(mod_dgp ,uk,simOptions(’AddNoise’,true));
%% Set up data objects
dataset = iddata(yk,uk,1);
datatrain = dataset(1:1500); datatest = dataset(1501:end);
[Ztrain,Tr] = detrend(datatrain ,0);
Ztest = detrend(datatest ,Tr);
%% Obtain an initial estimate of the observability canonical form
mod_ss10 = n4sid(Ztrain ,2,’Form’,’canon’);
%% Alternatively specify the structure manually
mod_ss = n4sid(Ztrain ,2);
% Observer canonical form
A = [1 1; -0.2 0]; B = mod_ss.b; C = [1 0]; D = 0;
K = mod_ss.K; x0 = 0.1*ones(2,1);
mod_ss20 = idss(A,B,C,D,K,x0,1);
mod_ss20.Structure.a.Free = [1 0; 1 0];
mod_ss20.Structure.c.Free = false;
%% Estimate structured SS models
mod_ss1 = pem(Ztrain,mod_ss10);
mod_ss2 = pem(Ztrain,mod_ss20);
mod_stack = stack(1,mod_ss1 ,mod_ss2);
present(mod_ss1)
In the previous illustrated example, we estimated a total of 6 parameters (six non-zero entries of
the matrices) whereas the true process is characterized by only ﬁve parameters (denote this vector by
β). Thus, we can further improve upon the parsimony by taking into account the mapping between
the non-zero entry parameters θ and the underlying system parameters β. It is because this was
not taken into consideration the estimate of K(2,1) (second element, theoretically −a2) in the SS2
model is signiﬁcantly diﬀerent from A(2,1) (theoretically −a2) in the above example.

712
Principles of System Identiﬁcation: Theory and Practice
23.7.2
GREY-BOX IDENTIFICATION
Grey-box models derive their structure from ﬁrst-principles or a priori physical insights, as remarked
in the earlier section. An added advantage of these models is that the non-zero entries of the matrices
are a function of (typically a) a fewer number of parameters than if they were treated as purely black-
box structured counterparts. Thus, they can be considered as the most parsimonious, but expectantly
their estimation involves more computational cost than the black-box parametrized models.
An important remark is in order here. The focus in grey-box identiﬁcation, as is evident from
the above discussion, moves away from model to parameters. Therefore, the exercise of building
grey-box models is largely parameter estimation of ﬁrst-principles (white-box) models.
There exist, as in black-box models, two classes of grey-box models, namely the linear and non-
linear models, based on whether a linear or non-linear state-space description is involved. The
parameters of interest, however, in both cases may share a linear / non-linear relation with the state-
space matrices depending on how they enter the models.
Identiﬁability and estimation aspects of grey-box models are essentially similar to those of
parametrized linear black-box models. The prediction equation is now a function of the parame-
ters of the grey-box model. However, maximum likelihood estimation, i.e., PEM-ML methods are
considered superior to the regular PEM-QC estimators for this purpose (Bohlin, 2006). A challenge
in grey-box identiﬁcation is that it is relatively more diﬃcult to verify upfront the identiﬁability
because of the non-linear dependencies between the state-space matrices and the parameters of
interest. On the other hand, a practical beneﬁt of working with grey-box models is that the prior
knowledge signiﬁcantly lowers the burden of persistent excitation or information requirements in
input-output data that is normally required for black-box identiﬁcation. This is particularly useful
in several practical identiﬁcation problems (see for example Raghavan et al. (2005) and Rehor and
Havlena (2011))
In the following section we illustrate an example of grey-box identiﬁcation of a two-tank system
with the MATLAB System Identiﬁcation toolbox.
23.7.2.1
Grey-Box Modeling of a Two-Tank System
The process of interest consists of two non-interacting (incompressible) liquid level systems (cylin-
drical tanks of cross-sectional areas A1 and A2) placed in series with the input being the inlet ﬂow
rate Fi to the ﬁrst tank. The dynamics of the liquid levels in the two tanks are governed by the
following diﬀerential equations:
dh1
dt = Fi
A1
−Cv1
A1
p
h1
(23.212a)
dh2
dt = Cv1
A2
p
h1 −Cv2
A2
p
h2
(23.212b)
where it has been assumed that the ﬂow out (controlled by a valve) of each tank is respectively
proportional to
√
hi, i = 1,2. In (23.212), Cv1 and Cv2 are the valve constants of the respective
outﬂow valves. We thus have a single-input, two-output system.
The process is simulated with the settings reported in Table 23.1 and using a PRBS input Fi
containing frequencies in the band [0 0.2] rad/sample. The sampling interval, based on the step
response, is set to Ts = 2 time units. Measurements of levels are generated by adding white noise of
appropriate variance (SNR = 10) to the respective true level responses. Further, the noise sequences
across the measurements are assumed to be uncorrelated.

Identiﬁcation of State-Space Models
713
TABLE 23.1
Settings for the two-tank system simulation
Parameter
A1
A2
Cv1
Cv2
Fi,s
Value
1.2
1.2
0.8
0.8
2
where Fi,s is the nominal (steady-state) inlet ﬂow rate. Setting the LHS of (23.212) to zero and
solving yields the levels at steady-state as h1s = h2s = 6.25.
The objective of grey-box modeling is to obtain estimates of parameters15
β =
f
Cv1
Cv2
A1
A2
gT
(23.213)
from input-output data and under two diﬀerent scenarios (i) a linearized (ODEs) version of (23.212)
is available and (ii) the non-linear ODEs in (23.212) is known. We shall illustrate only the former
case. The latter is left as an exercise to the reader (see Exercise E23.12).
For the linearized case, the state-space model is in terms of deviation variables with respect to a
nominal point, usually the steady-state:
˙˜x(t) =

−
Cv1
2A1
ph1,s
0
Cv1
2A2
ph1,s
−
Cv2
2A2
ph2,s

˜x(t) +
"−1/A1
0
#
˜u(t)
(23.214)
˜y(t) =
"1
0
0
1
#
˜x(t)
(23.215)
where ˜x(t) =
f
h1(t) −h1,s
h2(t) −h2,s
gT and likewise for the inputs and outputs as well. There-
fore, for estimation of parameters, a knowledge of the steady-state responses h1,s and h2,s are also
required. Alternatively, one can estimate these parameters as well (see Exercise E23.13). This situ-
ation does not arise in the non-linear grey-box identiﬁcation that uses the non-linear ﬁrst-principles
model.
The MATLAB script to perform the respective identiﬁcation tasks is given below.
Listing 23.6
Function ﬁle for linear grey-box modeling of two-tank system
function [A,B,C,D] = twotankfun(betap,Ts,h1s,h2s)
% FUNCTION FILE THAT RETURNS THE STATE-SPACE MODEL FOR THE TWO-TANK PROCESS
% USED IN GREY-BOX IDENTIFICATION
% Read parameters
Cv1 = betap(1); Cv2 = betap(2); A1 = betap(3); A2 = betap(4);
% Form the continuous -time SS model
Ac = [-Cv1/(2*A1*sqrt(h1s)) 0 ; Cv1/(2*A2*sqrt(h1s)) -Cv2/(2*A2*sqrt(h2s))];
Bc = [1/A1 ; 0];
Cc = eye(2);
Dc = zeros(2,1);
15Usually the problem is that of estimating valve constants, but the cross-sectional areas are included for the sake of
illustration.

714
Principles of System Identiﬁcation: Theory and Practice
sysc = ss(Ac,Bc,Cc,Dc);
% Discretize
sysd = c2d(sysc,Ts,’zoh’);
% Return the discrete -time model
[A,B,C,D] = ssdata(sysd);
Listing 23.7
MATLAB script for linear grey-box identiﬁcation of two-tank system
%% Data generation
% Run the simulink model
sim(’twotank_dee’);
hws = get_param(bdroot,’modelworkspace’);
eval(hws.MATLABcode)
% Add noise
yk1 = simout(:,1) + randn(length(simout),1)*sqrt(var(simout(:,1))/10);
yk2 = simout(:,2) + randn(length(simout),1)*sqrt(var(simout(:,2))/10);
%% Pre-processing and setting up the data
Tsamp = 2;
dataset = iddata([yk1 yk2],uk,Tsamp);
Ztrain = detrend(dataset ,0);
%% Estimating the parameters of grey-box model
% Initial structure
betap = [1 1 1 1]’;
Mi = idgrey(’twotankfun’,betap,’d’,{h1ss, h2ss},Tsamp);
% Estimation
Mss = greyest(Mi,Ztrain);
The obtained estimates of the parameters are:
ˆCv1 = 0.7925
(±0.007),
ˆCv2 = 0.7995
(±0.007),
ˆA1 = 1.192
(±0.013),
ˆA2 = 1.193
(±0.025)
(23.216)
The obtained estimates are in very good agreement with the true values in Table 23.1.
As a ﬁnal illustration, suppose the true cross-sectional areas are known. Then only the valve
constants are to be estimated. Setting A1 and A2 to their true values and only letting Cvs be the free
parameters (as shown in the MATLAB code below) results in the estimates
ˆCv1 = 0.8148
(±0.006),
ˆCv2 = 0.7958
(±0.006),
(23.217)
with the variability in the estimates, expectantly, lower (albeit marginal) than the previous case.
The estimated values match very well with the true parameters listed in Table 23.1.
Listing 23.8
Code to freeze a subset of parameters
% Restricting the free parameters
Mi.Par = [1 1 1.2 1.2];
Mi.Structure.Parameters.Free = [1 1 0 0];
Mss = greyest(Mi,Ztrain);
In closing, it should be remarked that grey-box identiﬁcation is an emerging topic with an in-
creasing number of applications. There exist several shades within the greyness depending on the

Identiﬁcation of State-Space Models
715
extent of prior knowledge available to the user. We have primarily discussed the case where the
model structure is known. However, grey-box modeling in general encompasses all those situations
where some prior knowledge is available on the parameters such as constraints, bounds, etc. The
purpose of this section is mainly to oﬀer a preview of this topic and trigger exciting ideas. An inter-
ested reader is strongly encouraged to refer to the large expanses of literature available on this topic
for further study. Finally, there also exists naturally a connection between grey-box modeling and
Bayesian identiﬁcation since both work with prior information (see Herbert and Tulleken (1993) for
a formal treatment).
23.8
SUMMARY
In this chapter, we learnt diﬀerent methods for linear state-space identiﬁcation belonging to two
broad classes, namely the realization methods, due to the seminal works by Ho and Kalman (1966)
and Kung (1978), and the direct methods, namely the N4SID, MOESP and the CVA techniques
due to Larimore (1996), Overschee and Moor (1994), and Verhaegen and Dewilde (1992a,b). The
former methods construct state-space realizations from IR coeﬃcients, whereas the latter class of
methods work with projections of future output and input data onto appropriate subspaces that
are spanned by past data, and therefore acquire the name subspace identiﬁcation methods. The
central ideas in these algorithms are based on the estimation of extended observability matrix and
the implicit implementation of a numerical Kalman ﬁlter. The former oﬀers an estimate of the order
of the system and, together with the latter, provides estimates of the state-space matrices. Two
main advantages of the subspace ID algorithms over the PEM methods is that they are non-iterative
(unlike PEM) and that they give an “automated” way of determining the system order. Morever,
they can be implemented by numerically eﬃcient SVD and QR factorization methods.
The three algorithms, seemingly dissimilar in their philosophies, in reality are members of a
single family of methods. Each method results in a state-space model in a diﬀerent basis space
using what are known as weighting functions. Among the three methods, the OE-MOESP method
is devised at identifying the deterministic state-space model while the remaining two, N4SID and
CVA, identify the full deterministic-plus-stochastic system. The CVA method, which works with
correlations, scores over the other two in that it is invariant to the choice of units for the input and
output.
We also studied the foundational concepts for 4SID methods, namely, the observability and con-
trollability, projections and importantly state estimation using the celebrated Kalman ﬁlter. A system
should be observable to ensure identiﬁability (state estimability) while controllability is necessary
to ensure all states are excited. Subspace methods not only produce optimal state-space models but
also deliver optimal estimates of states in the basis of the identiﬁed model. In this respect, the chap-
ter brieﬂy described the basics of Kalman ﬁlter and derived the optimal predictor-corrector ﬁlter
equations for state estimation. The dynamical Kalman state estimates can be re-written in a state-
space representation known as the innovations form. Subspace identiﬁcation methods essentially
identify this form of state-space models.
Finally, an important point to note is that the state-space models identiﬁed by subspace identi-
ﬁcation methods are obtained uniquely only up to a similarity transformation and furthermore, no
control exists on the structure of the state-space models. These are said to be freely parametrized
forms. On the other hand, in several applications, structured state-space models are desired where
the s.s. matrices have a much fewer number of non-zero entries than the unstructured case. The loca-
tions of these non-zero entries may be known a priori usually through physical insights. Estimation
of such parametrized state-space models constitutes grey-box modeling. The last section of this
chapter gave an introductory overview of the associated methods and demonstrated identiﬁcation of
grey-box models with a few examples.
Subspace identiﬁcation is an evolving subject with a number of open-ended problems and chal-
lenges. We have assumed open-loop conditions throughout this chapter. Extensions to closed-loop

716
Principles of System Identiﬁcation: Theory and Practice
situations have been recently developed (Huang, Ding and Qin, 2005; Katayama and Tanaka, 2007;
Ljung and McKelvey, 1996; Verhaegen, 1993). Robust subspace identiﬁcation has also been a topic
of recent interest. A growing number of applications to the identiﬁcation of multivariable systems is
found in the literature. The reader is encouraged to explore the vast expanses of this topic and build
suﬃcient expertise using the foundations gained from this chapter.
REVIEW QUESTIONS
R23.1 Describe at least two potential advantages of identifying state-space models over the classical
input-output forms.
R23.2 What are the major challenges in state-space identiﬁcation. Contrast them especially with the
input-output version.
R23.3 Explain the basic idea of subspace identiﬁcation.
R23.4 Why is it not possible to obtain a unique state-space model from data?
R23.5 What does “ﬁxing the basis” in subspace identiﬁcation mean?
R23.6 What is the role of the observability matrix in identiﬁcation of state-space models?
R23.7 Deﬁne the concept of extended observability matrix.
R23.8 Why does subspace identiﬁcation acquire its name?
R23.9 Explain the basic diﬀerences between the identiﬁcation of unstructured and structured state-space
models.
R23.10 What are the diﬀerent ways in which the user can have a prior knowledge of the structure of
state-space matrices?
R23.11 Highlight the key diﬀerence between the identiﬁcation of parametrized state-space models and
grey-box models.
R23.12 Can you describe the challenges in grey-box identiﬁcation method vis-a-vis the subspace iden-
tiﬁcation method?
EXERCISES
E23.1 Show that (23.29) holds starting with the requirement of unbiased property.
E23.2 Derive two alternative forms for the posterior covariance matrix in the KF algorithm, namely,
a. Pk = P−
k −KkSKT
k
b. Pk = (I −KkC)P−
k (I −KkC)T + KkRKT
k (Joseph form)
c. P−1
k
= (P−
k )−1 + CT RC (information form)
E23.3 Derive the combined update (23.35) for the posterior covariance matrix.
E23.4 Recall that when X and Y are jointly Gaussian, the conditional expectation is a linear function
of Y. Further, the conditioned X is also Gaussian with
X|Y ∼N (µx|y,Σx|y)
(23.218a)
µx|y = µx + ΣxyΣ−1
yy (y −µy)
(23.218b)
Σx|y = Σxx −ΣxyΣ−1
yyΣyx
(23.218c)
Use these results to derive the optimal posterior estimate of state and covariance matrix as given in
(23.30) and (23.32), respectively.
E23.5 Show that the impulse response of a LTI system has the state-space realization in (23.57).

Identiﬁcation of State-Space Models
717
E23.6 Show that the Hankel matrix of IR coeﬃcients in (23.60) can be factored as a product of con-
trollability and observability matrices as in (23.61).
E23.7 Derive the factorization in (23.109) using the LQ decomposition of Wp in (23.108).
E23.8 Develop a suitable state-space model for the CSTH process in §26.3.3.3 (do not introduce errors
in the ﬂow).
E23.9 Derive the expression for future states given by (23.123) in terms of past states and inputs.
E23.10 Derive the one-step ahead predictor expression in (23.186) for the innovations form of state-space
model.
E23.11 An isothermal CSTR carries the following irreversible reactions
A
k1
−→B
k2
−→C
2A
k3
−→D
where k1, k2 and k3 are rate constants. The reactor is operated around the s.s. conditions Fs
V
=
4/7 min−1 , cAf s = 10 mol/lit, cAs = 3 mol/lit, cBs = 1.117 mol/lit. Assume volume of the reactor
V is constant and that the feed stream contains only component A. An experiment is carried out on
this reactor to estimate the rate constants from the input-output data. For this purpose, the reactor
is excited with a PRBS in u[k] = (F/V)[k] around its nominal state. The output is observed every
Ts = 0.1 min. For a ﬁxed feed concentration, the input-output data is collected and provided in
greyboxrxtr_data.mat.
Do the following:
a. The continuous-time (linearized) state-space model with x =
f
cA
cB
gT for this reactor is:
A =

−Fs
V −k1 −2k3cAs
0
k1
−Fs
V −k2

, B =
"cAf s −cAs
−cBs
#
, C =
f
0
1
g
D = 0
Determine the structure (only) of the discretized state-space model.
b. Identify a structured (grey-box) state-space innovations form of model only using the knowledge
of structure of A, B, C and D in part (a).
c. Estimate β =
f
k1
k2
k3
gT from the non-zero entries and the fact that Ad = eATs . You may
use a non-linear solver such as fsolve.
d. Now estimate the rate constants k1, k2, k3 directly using the grey-box modeling approach
and the relations between these parameters and SS matrices above. Keep in mind that rate
constants are usually positive-valued quantities. Show all the detailed steps.
e. Which among (c) and (d) would you prefer as a method for estimating rate constants? Explain.
E23.12 Estimate the valve constants and cross-sectional areas for the two-tank system of §23.7.2.1.
E23.13 For the linearized model of the two-tank system of §23.7.2.1, re-work the grey-box identiﬁcation
to estimate the steady state values of levels along with remaining parameters, namely, the valve
constants and cross-sectional areas.

24
Case Studies
Selected case studies on time-series modeling, identiﬁcation of simulation and real-life pro-
cesses are presented. The objective is to demonstrate the principles and practical aspects of
identiﬁcation outlined in this text.
24.1
ARIMA MODEL OF INDUSTRIAL DRYER TEMPERATURE
24.1.1
PROCESS DATA
The case study is concerned with developing a pure time-series model for the outlet temperature
of a dryer in an industrial process. A cascade controller regulates this temperature at a set-point of
T = 134◦C with the help of PI controllers in both master and slave loops.
The time-series model that we develop here can be used for predicting the eﬀects of disturbance
and in assessing the performance of the temperature control loop.
24.1.2
BUILDING THE TIME-SERIES MODEL
In developing a time-series model for the series, we follow the general procedure outlined in Table
19.2.
Step 1: Figure 24.1(a) shows the time series obtained at Ts = 15 second intervals. The auto-
correlation function in Figure 24.1(b) shows a slow decay suggesting the presence of a long-
memory characteristic at the scale of observation. Further, the PACF in Figure 24.1(c) has a
near-unity value at lag l = 1 indicating the possibility of a unit root in the AR component.
The spectral density estimated by Welch’s smoothed periodogram is shown in Figure 24.1(d)
shows signiﬁcant power at ω = 0 and neighboring frequencies, corroborating the presence of
integrating eﬀects. Additionally, a peak in the p.s.d. at ω = 0.055 rad/sample (normalized fre-
quency) is a clear indication of a periodicity in the series. From a performance assessment view-
point this is an indication of poor performance.
Note that although the actual process may not strictly contain an integrating eﬀect, the statistics
clearly indicate the suitability of a model with a pole on the unit circle. To verify this claim, a
unit root test can be conducted on the series. Leaving this exercise to the reader, we adopt a less
rigorous route. For the purpose of modeling, we select the ﬁrst N = 2000 observations and mean
center it. There is no visible polynomial trend in the series (a unit root test can be conducted to
conﬁrm this hypothesis).
Fitting an AR(1) model to the training data results in the noise model
ˆH1(q−1) =
1
1 −0.9966
(±0.0019)q−1
(24.1)
where the number in the parentheses is the standard error in the estimate. Clearly the data presents
a case for diﬀerencing.
Step 2: Does not apply to the case study.
Step 3: Does not apply to the case study.
718

Case Studies
719
0
500
1000
1500
2000
2500
3000
128
130
132
134
136
138
140
142
144
146
Time
Temperature
(a) Temperature series
0
20
40
60
80
100
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
(b) Auto-correlation function
0
5
10
15
20
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
PACF
Lags
(c) Partial auto-correlation function
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0
5
10
15
20
25
30
35
40
Normalized frequency (rad/sample)
Spectral density
(d) Power spectral density
FIGURE 24.1
Series, ACF, PACF and spectral density of the temperature series.
Step 4: A ﬁrst-degree of diﬀerencing d = 1 is deemed appropriate. The diﬀerenced series and its
ACF are shown in Figures 24.2 and 24.1(b), respectively.
There is no visible evidence of non-stationarity (again one could conduct a unit root test here).
Further, it is insightful to note that the variance of the diﬀerenced series is σ2
∇v = 0.0336 whereas
the variance of the original series is σ2
v = 4.3794. Thus, a single diﬀerencing has explained about
99% of the variance. The predictability of the diﬀerenced series remains to be analyzed.
The power spectral density post-diﬀerencing shows zero to very low power at ω = 0 indicat-
ing absence of any integrating eﬀects. With the earlier dominant integrating eﬀect taken away,
additional peaks in the p.s.d. are now visible pointing to more than one periodic component. At
this juncture one could ﬁrst model the periodic components separately followed by a time-series
modeling of the residual. Alternatively one could directly model the diﬀerenced series expecting
the time-series model to capture both periodic and stochastic eﬀects. We shall adopt this route
for this case study. The ﬁnal model should have imaginary components in order to explain the
oscillatory characteristics.
Step 5: With the above arguments we begin with an ARMA(2,1) model. The NLS estimate of the
model is obtained as
ˆH21(q−1) =
1 −
(±0.0669)
0.5085 q−1
1 −1.017
(±0.0725)q−1 + 0.111
(±0.057)q−2 ,
ˆσ2e = 0.0174
(24.2)
However, this model is unsatisfactory for several reasons: (i) the parameter estimate ˆd2 is in-
signiﬁcant, (ii) the poles of the identiﬁed model are purely real and (iii) residuals have signiﬁcant
correlation in them as conﬁrmed by Figures 24.3(a) and 24.3(b) showing the residual-ACF and
the Box-Ljung Q statistics, respectively.

720
Principles of System Identiﬁcation: Theory and Practice
0
500
1000
1500
2000
2500
3000
−2
−1.5
−1
−0.5
0
0.5
1
Samples
Amplitude
(a) Diﬀerenced temperature series
0
20
40
60
80
100
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
(b) ACF
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
PACF
Lags
(c) PACF
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0
0.02
0.04
0.06
0.08
0.1
0.12
Normalized frequency (rad/sample)
Spectral density
(d) Spectral density
FIGURE 24.2
Diﬀerenced series and its properties - signal appears to be stationary.
As a reﬁnement to (24.2), we estimate an ARMA(2,1) model with the constraint d1 = 0 to obtain
ˆH21c(q−1) = 1 +
(±0.0205)
0.5789 q−1
1 −0.5537
(±0.021)q−2 ,
ˆσ2e = 0.0178
(24.3)
This model is unsatisfactory as well since the residuals exhibit signiﬁcant correlation as seen
in Figure 24.4(a). At this point we turn to AIC and estimate models of a range of AR and MA
orders. AIC suggests an ARMA(6,6) model.
Reﬁning further and proceeding as above, the ﬁnal model is a constrained ARMA(5,1) model by
requiring that d1 = d3 = 0.
ˆH51c(q−1) =
1 +
(±0.0215)
0.5234 q−1
1 −0.4441
(±0.0275)q−2 −0.1269
(±0.0223)q−4 −0.1371
(±0.019)q−5 ;
ˆσ2
e = 0.0171;
(24.4)
The residual analysis plots are shown in Figures 24.5(a) and 24.5(b).
The ARMA(5,1) model in (24.4) is satisfactory in both respects - parameter estimates are signif-
icant and residuals exhibit no correlation. Additionally, the model is stable and there is at least a
single pair of complex poles,
p1 = 0.8924;
p2,3 = 0.1744 ± 0.5827i;
p4,5 = −0.6206 ± 0.1736i
(24.5)
Therefore, this model can be accepted as a good working model for the diﬀerenced series.
The model for the original series is thus
ˆH(q−1) =
1
1 −q−1 ˆH51c(q−1)
(24.6)

Case Studies
721
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lag
(a) ACF of residuals
0
2
4
6
8
10
0
10
20
30
40
50
60
Lag
Q statistic
 
 
Q stat
Critical value
(b) Box-Ljung test statistics
FIGURE 24.3
ACF and Box-Ljung Q-stat of residuals from ARMA(2,1) model.
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lag
(a) ACF of residuals
0
2
4
6
8
10
0
10
20
30
40
50
60
70
80
90
100
Lag
Q statistic
 
 
Q stat
Critical value
(b) Box-Ljung test statistics
FIGURE 24.4
Residual ACF and Box-Ljung statistics for the constrained ARMA(2,1) model.
Finally, the model on the data set is used to predict the series from instants k = 1899 to k = 2640.
The predictions are compared with the observations in Figures 24.6(a) and 24.6(b). With an
NRMS value (14.46) of 90% the model has captured the salient parts of the series very well.
Remarks:
1. The ARMA model in (24.4) has managed to explain only 50% of the variance of the (diﬀerenced) series.
Two factors are possibly responsible for this moderate ﬁt, (i) presence of periodicities that a low-order
ARMA model cannot explain and (ii) non-linearities in the control loop. In an unpublished separate study,
the control valve was diagnosed to exhibit a signiﬁcant non-linearity due to what is known as stiction. The
second factor is more likely the cause since the strengths of the periodic components are weak (refer to
Figure 24.2(d)).
2. In continuation of the remark above, the dominance of the integrating eﬀect over the periodicities is over-
whelming. Therefore, a parametric model is best suited for the original series. Had the periodicities signif-
icantly contributed to the overall variance of the signal, then it may have been necessary to ﬁrst detect and
model the sinusoidal trends (e.g., using the high-resolution subspace methods of §16.5.8 or a regression
method) and then develop an ARMA model for the residuals.
3. The constraints imposed on the parameters in estimating the ARMA models (24.3) and (24.4) are fairly
simple to implement. All that is required is to exclude the corresponding past outputs from the regressor
vector.

722
Principles of System Identiﬁcation: Theory and Practice
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lag
(a) ACF of residuals
0
2
4
6
8
10
0
5
10
15
20
25
Lag
Q stats
 
 
Q stat
Critical value
(b) Box-Ljung test statistics
FIGURE 24.5
Residual ACF and Box-Ljung statistics for the constrained ARMA(5,1) model.
2000
2100
2200
2300
2400
2500
2600
136
138
140
142
Measurements
Temperature
2000
2100
2200
2300
2400
2500
2600
136
138
140
142
Samples
Predictions
Temperature
(a) Measurements and predictions
−4
−3
−2
−1
0
1
2
3
−4
−3
−2
−1
0
1
2
3
Observed value
Predictions
(b) Predictions vs. Measurements
FIGURE 24.6
Comparing predictions with observations.
Listing 24.1
MATLAB code for the model in Section 24.1 - PART I
% Load data
load tempdryer_data
vk = temp_dryer; N = length(vk);
% Mean center
vkd = detrend(vk,’constant’);
% Plot data
figure; plot(vk)
% Plot the ACF and PACF
acf(vk,100); pacf(vk,20);
% Plot the spectral density (periodogram)
[temper_psd ,wvec] = pwelch(vkd,[],[],[],’twosided’);
figure
plot(wvec(1:100),temper_psd(1:100))
Listing 24.2
MATLAB code for the model in Section 24.1 - PART II
% Estimate an ARMA(1,1) model
mod_arma21 = armax(vkdiff(1:2000) ,[2 1]);
present(mod_arma21)
% Residual analysis
err_mod21 = resid(mod_arma21 ,vkdiff(1:2000));

Case Studies
723
acf(err_mod21.y,20);
% LB Q-test
[h,p_vals,Qstat,crit] = lbqtest(err_mod21.y,’lags’,(1:10),’alpha’,0.01);
figure; stem(Qstat,’markerfacecolor’,’blue’);
hold on; plot(crit,’r--’)
% Try out several ARIMA models
aic_vals = [];
for P = 1:4
for M = 1:4
mod_armapm = armax(vkdiff(1:2000),[P M]);
aic_vals(P,M) = aic(mod_armapm);
end
end
% Pick the best model
[min_val ,min_ind] = min(aic);
% Estimating constrained ARMA(2,1) model
init_sys = mod_arma21;
init_sys.a(2) = 0;
init_sys.Structure.a.Free = [0 0 1];
init_sys.b = 0; init_sys.Structure.b.Free = 0;
vkdiff2 = vkdiff; vkdiff2.u = zeros(2640,1);
mod_arma21c =
armax(vkdiff2(1:2000),init_sys);
% Residual analysis
err_mod21c = resid(mod_arma21c ,vkdiff2(1:2000));
acf(err_mod21c.y,20);
% Using the ECONOMETRICS toolbox
[h,p_vals,Qstat,crit] = lbqtest(err_mod21c.y,’lags’,(1:10),’alpha’,0.01);
% Estimating constrained ARMA(5,1) model
init_sys = mod_arma21c; init_sys.a = [init_sys.a 0 0 0];
init_sys.Structure.a.Free = [0 0 1 0 1 1];
init_sys.b = 0;
mod_arma51c = armax(vkdiff2(1:2000),init_sys);
% Residual analysis
err_mod51c = resid(mod_arma51c ,vkdiff2(1:2000));
acf(err_mod51c.y,20);
[h,p_vals,Qstat,crit] = lbqtest(err_mod51c.y,’lags’,(1:10),’alpha’,0.01);
figure
stem(Qstat,’markerfacecolor’,’blue’); hold on
plot(crit,’r--’);
% Prediction
vk_data2 = iddata(detrend(vk,’constant’),zeros(2641,1) ,1);
mod_arima51c = armax(vk_data2 ,init_sys ,’Integratenoise’,true);
vk_pred = predict(mod_arima51c ,vk_data2(1950:end),1);
plot(vk_data2(1950:end).y,vk_pred.y,’x’); hold on
plot(vk_data2(1950:end).y,vk_data2(1950:end).y,’r-’);
24.2
SIMULATED PROCESS: DEVELOPING AN INPUT-OUTPUT MODEL
We shall ﬁrst describe the process under study, which is used only for the purpose of simulation.
The data generating process under study has an ARX structure as described below. In the subsequent
steps, the process is assumed to be unknown and a systematic identiﬁcation is used to discover a

724
Principles of System Identiﬁcation: Theory and Practice
suitable model. Two routes to parametric model development shall be demonstrated, one starting
with an ARX structure and the other with an OE structure.
24.2.1
DATA GENERATION
The process under consideration and inputs used for simulation are described below.
Data generating process
The DGP has an ARX structure:
y[k] =
0.3q−3 + 0.2q−4
1 −0.9q−1 + 0.2q−2 u[k] +
1
1 −0.9q−1 + 0.2q−2 e[k],
e[k] ∼GWN(0,σ2
e)
(24.7)
where the noise variance σ2
e is adjusted as usual to achieve a SNR of 10.
Listing 24.3
Data generating process
% Create process object
dgp_arx = idpoly([1 -0.9 0.2],[0.3 0.2],1,1,1);
dgp_arx.iodelay = 3;
Input design and simulation
A low-frequency pseudo-random binary sequence (PRBS) input to excite the process.
Listing 24.4
Input design and data generation
% Low-frequency input design
% Syntax is such that [0 1] is a full band input
uk = idinput(2044,’prbs’,[0 1/3],[-1 1]);
% Simulation
xk = sim(dgp_arx ,uk);
mult_fac = (1.2*(1 - 0.2^2) - 0.9^2 + 0.9^2*0.2)/(1 + 0.2);
dgp_arx.Noisevariance = mult_fac*var(xk)/10;
yk = sim(dgp_arx ,uk,simOptions(’AddNoise’,true));
The above calculations result in a white-noise variance of σ2
e = 0.0657.
Note: In practice the frequency content of the input is usually determined experimentally by performing a step
test. See §22.3.2 for related guidelines.
24.2.2
DATA PRE-PROCESSING
As a ﬁrst step, the input-output data is collated into a single data set, which is the central object of
use. A snapshot of the ﬁrst 250 observations is shown in Figure 24.7(a).
From a visual inspection of the trend plots, there are no noticeable drifts or linear trends / non-
stationarities. Therefore, it is safe to assume that the output is quasi-stationary. The spectral density
plots in Figure 24.7(b) reveal the frequency range of input ([0 0.25] cycles/sample) that was de-
signed. Further, comparing the spectral densities of the input and output, it is clear that the system
under study has low-pass ﬁlter characteristics.

Case Studies
725
0
50
100
150
200
250
−4
−2
0
2
4
Amplitude
Output
0
50
100
150
200
250
−1
−0.5
0
0.5
1
Input
Time
Amplitude
(a) Input-output data
0
0.1
0.2
0.3
0.4
0.5
0
5
10
15
20
Normalized Frequency (cycles/sample)
Output p.s.d.
0
0.1
0.2
0.3
0.4
0.5
0
2
4
6
Normalized Frequency (cycles/sample)
Input p.s.d.
(b) Spectral densities in power/cyclic frequency
FIGURE 24.7
Input-output proﬁle and their spectral densities.
Partitioning the data
The data is divided into two parts: the training data consisting of the ﬁrst 1500 samples and a test
data containing the remainder.
Remarks:
i. Deviation variables for the test data are constructed with reference to the training data.
ii. It is also a common practice to let the test data overlap with the training data so that the errors introduced
due to initialization die down as the model enters the fresh data zone.
Listing 24.5
Partitioning the data and constructing the deviation quantities
% Partition the data into training and test sets
Ztr = Zk(1:1500); Ztest = Zk(1501:end);
% Detrend data
[Ztrd,Tr] = detrend(Ztr,0);
% Align the test data w.r.t. the same mean and variance
Ztestd = detrend(Ztrd,Tr);
24.2.3
NON-PARAMETRIC ANALYSIS
Our next step is to estimate impulse, step and frequency response models because they reveal useful
information on delay and process dynamics. The only signiﬁcant assumption that we make here is
that the system is LTI.
i. Impulse / step response estimates: An FIR model with M = 20 coeﬃcients is ﬁt using the LS
method (with regularization) described in §20.2. A plot of the IR estimates with 99% signiﬁcance
band is shown in Figure 24.8(a). The step response computed from the IR estimates is shown in
Figure 24.8(b).
Inferences from IR and step responses:
• The ﬁrst signiﬁcant impulse response estimate is obtained at lag l = 3, implying that the
system has an input-output delay of 3 sampling intervals.
• Step response estimates reveal that the process has an overdamped behavior (all real poles).
• If the system is approximated as a ﬁrst-order-plus-delay continuous-time model, the dom-
inant time-constant of the system is nearly 2.8 s, implying that the bandwidth is BW =
1/τ = 0.36 cycles/sec (compare with the true BW ≈0.49 cycles/sec).

726
Principles of System Identiﬁcation: Theory and Practice
(a) IR estimates
0
5
10
15
20
25
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
From: u1  To: y1
Step response estimates
Time (seconds)
Amplitude
(b) Step response estimates
FIGURE 24.8
Non-parametric estimates of time responses.
10
−2
10
−1
10
0
10
1
−25
−20
−15
−10
−5
0
5
From: u1  To: y1
Magnitude (dB)
Bode Diagram
Frequency  (rad/s)
(a) Magnitude estimates
10
−2
10
−1
10
0
10
1
−540
−450
−360
−270
−180
−90
0
From: u1  To: y1
Phase (deg)
Bode Diagram
Frequency  (rad/s)
(b) Phase estimates
FIGURE 24.9
Smoothed estimate of the FRF.
• From the step response, the system has a gain of approximately 1.68 units (the true plant
has a DC gain of 1.67).
Listing 24.6
Estimating the impulse and step responses
% IR estimation
fir_mod = impulseest(Ztrd ,20);
figure; impulseplot(fir_mod ,’sd’,3)
% Step response estimation
figure; step(fir_mod);
ii. FRF estimate: The discrete-time FRF is estimated using the smoothing approach described in
§20.4 (and the default options in Matlab). The magnitude and phase plots from the resulting FRF
estimate are shown in Figure 24.9(a) and 24.9(b), respectively.
Note: Recall from Chapter 5 that the FRF is symmetric about the origin and also periodic with a period of
2π. Therefore, it suﬃces to show only the positive half.
Inferences:
• The low-pass ﬁltering nature of the process is clearly visible in the magnitude plot. It is
left as an exercise to the reader to estimate the bandwidth of the system from this plot and
compare it with the estimate from the step response.
• Phase of the system saturates at −540◦. For discrete-time systems, each real positive pole
or pole-zero excess or a real negative zero produces a phase shift of −180◦. Discounting for
the delay of three samples, the delay-free system therefore has no zero-pole excess, meaning
it has the same number of poles and zeros. This analysis gives us a reasonable preliminary

Case Studies
727
guess and the range of search for the orders of numerator and denominator polynomials of
G(q−1).
Listing 24.7
MATLAB commands for FRF estimation
% FRF
estimation
[Gwhat,wvec] = spa(Ztrd);
figure; bode(Gwhat);
24.2.4
PARAMETRIC MODEL DEVELOPMENT
Using the insights gained from non-parametric identiﬁcation, we develop a parametric model of
appropriate order. As remarked early on in the case study, we shall illustrate with the initial model
from the ARX family.
Approach I: ARX route
The model of interest is:
y[k] = B(q−1,θ)
A(q−1,θ) u[k] +
1
A(q−1,θ) e[k]
(24.8)
where the parameters θ and σ2
e have to be optimized such that the prediction errors are at a mini-
mum.
From the non-parametric analysis, the following can be said about the A and B polynomials:
i. The process has an input-output delay of three samples.
ii. The delay-free deterministic model has a pole-zero excess of zero. For the ARX model, this
implies that B(q−1) and A(q−1) polynomials have the same number of coeﬃcients.
One could start with na = 1 and nb = 1. Subspace identiﬁcation methods provide an initial guess
for the order as the number of signiﬁcant Hankel singular values of the system (§23.6). Figure 24.10
shows the plot of singular values, with the order evaluation also performed using AIC. The analysis
suggests a second-order model.
Listing 24.8
Order determination using SSID
% FRF
estimation
n4sid(Ztraind ,1:10);
The subspace method does not oﬀer a clear indication whether both B and A should be second
order or only the latter. We could of course start with na = 2,nb = 1 and systematically arrive
at the correct model. However, given that the model of interest is an ARX structure, we could
estimate models of several orders simultaneously, as described in §21.6.1.1 followed by the use of
information-theoretic criteria such as AIC or MDL (BIC).
Thus a search for the optimal orders of A and B polynomials in the range na = 1 : 4 and nb = 1 : 4
is carried out with the delay ﬁxed to nk = 3.
Note: We could also restrict our search to only combinations with na = nb (no pole-zero excess) as deemed
by the non-parametric analysis.
Running the algorithm for simultaneous estimation of ARX models using the test data as the
cross-validation set and the training data for estimation, one obtains the loss functions for each
combination as shown in Figure 24.11.
Both AIC and MDL suggest the second-order as the optimal one, while not surprisingly the best
ﬁt is given by the model that has more number of parameters in it. From the metrics, the optimal
choices of orders (with the ﬁxed delay) are
na = 2;
n′
b = 2;
nk = 3

728
Principles of System Identiﬁcation: Theory and Practice
0
2
4
6
8
10
12
−1
0
1
2
3
4
5
Log of Singular values
Model order
Red: Default Choice (2)
Select model order in Command Window.
FIGURE 24.10
(SEE COLOR INSERT) Plot of Hankel singular values.
FIGURE 24.11
(SEE COLOR INSERT) Loss functions for ARX models with diﬀerent numerator and de-
nominator polynomial orders.
Listing 24.9
MATLAB commands for estimating ARX models simultaneously
% Set the range for orders
nn_mod = struc([1:4],[1:4],3);
% Compute ARX models and the associated loss functions
V = arxstruc(Ztrd,Ztestd,nn_mod);
% Select the best model
best_ord = selstruc(V);
Model estimation
With the aid of the foregoing analysis, an ARX(2,2) model with delay nk = 3 using the LS method
is estimated, as reported below:
ˆG1(q−1) =
0.2998
(±0.01) q−3 + 0.1763
(±0.015)q−4
1 −0.9495
(±0.021)q−1 + 0.2432
(±0.017)q−2
ˆH1(q−1) =
1
1 −0.9495
(±0.021)q−1 + 0.2432
(±0.017)q−2
ˆσ2e = 0.0664
(24.9a)
(24.9b)
(24.9c)

Case Studies
729
Listing 24.10
Estimating ARX model
% Estimate the best ARX structure
modarx_best = arx(Ztrd,best_ord);
present(modarx_best)
The 1σ-standard errors are reported, as always, with the parameter estimates. Section 22.6.4 stip-
ulates that these errors should be taken in faith only after the model has passed the model assessment
tests, the results of which are discussed below.
24.2.5
MODEL QUALITY ASSESSMENT
The model in (24.9) is subject to the assessment tests described in §22.6.4.
i. Residual analysis: Cross-correlation of the prediction errors with the pre-whitened inputs and
the ACF of residuals are shown in Figure 24.12(a). The absence of any signiﬁcant correlation in
either plots suggests that the plant and noise models have been adequately captured.
0
5
10
15
20
−0.5
0
0.5
1
ACF of residuals
Lags
−20
−15
−10
−5
0
5
10
15
20
−0.1
−0.05
0
0.05
0.1
CCF(ε,u) with PW
Lags
(a) Residual correlation plots
−1
−0.5
0
0.5
1
0
50
100
150
200
250
300
350
400
Prediction errors
Count
(b) Histogram of residuals
FIGURE 24.12
Residual analysis of the ARX model in (24.9).
A central assumption in the identiﬁcation theory and models is that errors have a Gaussian distri-
bution. There exist several statistical methods to test this null hypothesis. We turn to a histogram
of the residuals shown in Figure 24.12(b), which shows no signiﬁcant visual evidence to believe
that the Gaussianity hypothesis should be rejected.
Listing 24.11
Residual analysis
% Residual analysis
figure; resid_pw(modarx_best ,Ztrd);
% Compute prediction errors
err_modarx = pe(modarx_best ,Ztrd ,1);
% Histogram
figure; hist(err_modarx.y);
Listing 24.12
Function for residual analysis with input pre-whitening
function pred_err = resid_pw(model_user ,data)
% Compute one-step ahead prediction errors
err_val = pe(model_user ,data); N = length(err_val.y);
% Compute the ACF of residuals
L = 20; [acf_err ,lags] = xcov(err_val.y,L,’coeff’);
% Assign the values of ACF
acf_e = acf_err(L+1:end);

730
Principles of System Identiﬁcation: Theory and Practice
% Pre-whiten the inputs
acf_uk = xcov(data.u,L,’coeff’);
% Prompt the user for order of ARMA model of pre-whitening
figure; stem((0:L),acf_uk(L+1:end))
arma_ord = input(’Enter␣the␣order␣of␣pre-whitening␣filter␣[na␣nc]:’);
% Pre-whiten input
pwfilt = armax(iddata(data.u,[],1),arma_ord);
pw_uk = pe(pwfilt,data.u);
% Compute cross-correlation
[ccf_epwu ,lags] = xcov([err_val.y pw_uk],L,’coeff’);
% Plot the ACF and CCF
figure; set(gcf,’Color’,[1 1 1])
% ACF of residuals
subplot(211)
stem((0:L),acf_e,’markerfacecolor’,’red’,’markersize’,6); hold on
% Plot the error limits for a white-noise assumption
errlim = 2/sqrt(N);
plot((0:L),ones(L+1,1)*errlim ,’r--’); plot((0:L),-ones(L+1,1)*errlim ,’g--’);
% CCF between residuals and pre-whitened input
subplot(212)
stem(lags,ccf_epwu(:,2),’markerfacecolor’,’red’,’markersize’,6);
hold on
plot([-L L],ones(1,2)*2.58/sqrt(N),’r--’); plot([-L L],-ones(1,2)*2.58/sqrt(...
N),’r--’);
ii. Standard errors in ˆθ: Given that the model has passed the assessment checks, the parameter es-
timate errors reported in (24.9) can be used to test for signiﬁcance of estimates. For this purpose,
the 99% C.I. for each parameter as ˆθi ± 2.58σi are constructed. Clearly, none of these C.I.s con-
tain zero and therefore all parameter estimates are signiﬁcant, i.e., the hypothesis H0 : θi = 0 is
rejected for all i = 1,· · · ,p.
iii. Cross-validation: The model is now presented with the test data set to evaluate its one-step and
inﬁnite-step ahead prediction capabilities. Figure 24.13 shows the associated plots; the top panel
carries the scatter plots and the bottom panel shows a snapshot of the predictions in comparison
with the observed data. A match of 81% w.r.t. the one-step and 69% for the inﬁnite-step ahead
predictions is observed. The lower ﬁt for the inﬁnite-step ahead prediction should be expected in
general for any model since it is solely based on inputs (for OE models, the ﬁt in both cases will
be identical owing to its predictive properties discussed in §18.4).
Note that the predictions are compared for deviation quantities due to the manner in which the
model was developed.
Listing 24.13
Cross-validation on a test data
% Compute the predictions and return the fits
[yhat_1step ,fit1] = compare(Ztestd ,modarx_best ,1);
[yhat_infstep ,fit_inf] = compare(Ztestd ,modarx_best ,inf);
figure; subplot(221)
plot(Ztestd.y,yhat_1step.y,’x’); hold on
plot(Ztestd.y,Ztestd.y,’r-’);
Tvec = 101:160;
subplot(223)
plot(Ztestd.SamplingInstants(Tvec),Ztestd.y(Tvec)); hold on
plot(Ztestd.SamplingInstants(Tvec),yhat_1step.y(Tvec),’r--’);
subplot(222)
plot(Ztestd.y,yhat_infstep.y,’x’); hold on
plot(Ztestd.y,Ztestd.y,’r-’);
subplot(224)

Case Studies
731
−2
0
2
−2
−1
0
1
2
Observed values
Predictions
1600
1620
1640
1660
−4
−2
0
2
4
Time
Amplitude
−2
0
2
−2
−1
0
1
2
Observed values
Predictions
1600
1620
1640
1660
−4
−2
0
2
4
Time
Amplitude
FIGURE 24.13
Cross-validating the model (24.9) with the test data resulted in ﬁts of 80.6% and 69%, respec-
tively.
plot(Ztestd.SamplingInstants(Tvec),Ztestd.y(Tvec)); hold on
plot(Ztestd.SamplingInstants(Tvec),yhat_infstep.y(Tvec),’r--’)
Comparing frequency responses
Finally, the elementary responses of the parametric model are compared with those obtained from
the non-parametric analysis. Figure 24.14(a) and 24.14(b) show the step and frequency responses
obtained from non-parametric and ARX models, respectively. The match between these responses
is very close. Notice that the phase plots diﬀer by 360◦, which is the ambiguity that always exists in
phase estimation.
0
5
10
15
20
25
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
 
 
Time (seconds)
Amplitude
Non−parametric model
Best ARX model
(a) Step responses
−30
−25
−20
−15
−10
−5
0
5
Magnitude (dB)
Frequency  (rad/s)
10
−2
10
−1
10
0
10
1
−720
−360
0
360
720
Phase (deg)
 
 
Non−parametric model
Best ARX model
(b) Frequency responses
FIGURE 24.14
Comparing elementary responses obtained from non-parametric and parametric models.
Thus the estimated ARX(2,2) model with nk = 3 is suitable for the process in all respects.
24.2.6
PARAMETRIC MODEL ALONG THE OE ROUTE
We could also discover a working model starting with an OE structure. A complete development
(beginning with a ﬁrst-order OE model) is not presented here, but the ﬁnal OE model of the same

732
Principles of System Identiﬁcation: Theory and Practice
0
5
10
15
20
−0.5
0
0.5
1
ACF of residuals
Lags
−20
−15
−10
−5
0
5
10
15
20
−0.1
−0.05
0
0.05
0.1
CCF(ε,u) with PW
Lags
(a) Residual analysis plots
0
5
10
15
20
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
PACF of residuals from OE model
Lags
(b) PACF of residuals
FIGURE 24.15
Correlation analysis and PACF of residuals from OE model, (24.10).
order in (24.9) is estimated for comparison. Running the data through the oe routine in MATLAB
with nb = nf = 2 yields,
ˆB(q−1) = 0.292
(±0.019)q−3 + 0.202
(±0.043)q−4
(24.10a)
ˆF(q−1) = 1 −0.9087
(±0.066)q−1 + 0.213
(±0.049)q−2
ˆσ2e = 0.174
(24.10b)
The residual analysis plots (with input pre-whitening for computing CCF) are shown in Figure
24.15. It is clear that a satisfactory plant model has been obtained despite the mismatch in noise
dynamics between the model and process, as highlighted by the ACF of residuals. The exponential
decay of the ACF and the PACF plot shown in Figure 24.15(b) suggests an AR(2) structure for the
noise model H.
Fitting an AR(2) model to the residuals using one of the methods in §19.2 (speciﬁcally the modi-
ﬁed covariance method described in §19.2.3) produces
ˆH(q−1) =
1
1 −0.966
(±0.025)q−1 + 0.254
(±0.025)q−2
(24.11)
The goodness of the obtained noise model is tested by subjecting the residuals of ˆH to a whiteness
test. Examining the ACF of residuals shows that we have obtained a satisfactory model.
Listing 24.14
Estimating OE model and noise model
% Estimate the OE model of the same order
mod_oe = oe(Ztraind ,[2 2 3]);
% Obtain residuals
err_oe = pe(mod_oe,Ztraind);
% Plot PACF
pacf(err_oe.y,20);
% Fit an AR(2) model to the residuals
mod_noi = ar(err_oe.y,2);
The plant and noise models in (24.10) and (24.11) have been estimated separately; therefore, they
are not optimal. In order to jointly estimate the optimal G and H, a BJ(2,0,2,2) model with the

Case Studies
733
estimated model as initial guess is developed.
ˆG2(q−1) =
(±0.01)
0.285q−3 +
(±0.021)
0.208 q−4
1 −0.911
(±0.038)q−1 + 0.215
(±0.03)q−2
ˆH2(q−1) =
1
1 −0.966
(±0.025)q−1 + 0.253
(±0.025)q−2
ˆσ2
e = 0.0662
(24.12a)
(24.12b)
(24.12c)
The model reported in (24.12) is satisfactory in all respects.
Listing 24.15
Estimating a BJ(2,0,2,2) model
% Fit a BJ model
ginitial = idpoly(1,mod_oe.b,1,mod_noi.a,mod_oe.f,’Ts’,1);
mod_bj = bj(Ztraind ,ginitial);
Which of the models in (24.9) and (24.12) is more suited to the given process? This is the problem
of selecting the model structure. We can evaluate the AIC for these models and select the one that
has the minimum.
AIC({ ˆG1, ˆH1}) = −2.714;
AIC({ ˆG2, ˆH2}) = −2.7064;
(24.13)
Expectedly, the ARX model has a lower AIC. The FPE measure can also be evaluated for both
models.
Thus, we select the ARX(2,2) model in (24.9) as the best suited model for the given process.
Remarks:
The ARX model is the winner and also it matches with the underlying process in its orders. How-
ever this is more of a coincidence rather than commonplace, speciﬁcally because the DGP also has an ARX
structure. In reality the underlying process may be non-ARX and BJ models may be the preferred ones; recall
the liquid level case study of Chapter 2. The following case study is also an example in point.
24.3
PROCESS WITH RANDOM WALK NOISE
Input-output data is generated by simulating the process model and a PRBS input with SNR set
to 10, starting from steady state. The necessary details including the data generating process are
provided at the end of the case study. The goal is to build a suitable model.
24.3.1
VISUAL ANALYSIS
A snapshot of the input-output data is shown in Figure 24.16. There are no visible deterministic
trends or non-stationarities in the data. However, an important observation can be made from the
initial portions (ﬁrst 20 samples) of the output series. The measurement shows considerable vari-
ation despite zero input change during that period. This is an indication of the measurement noise
being colored and possibly with drifts. In the subsequent portions of the data, it is clear that the
direction of change in the output is in line with that of the input, suggesting a positive gain. We shall
conﬁrm these inferences shortly through non-parametric analysis and subsequently with parametric
models.
24.3.2
NON-PARAMETRIC ESTIMATES
Impulse and step responses
Impulse response coeﬃcients are estimated using the methods described in §20.2. The resulting
estimates are shown in Figure 24.17(a). From the plot, we observe a unit sample delay between the
input and output.

734
Principles of System Identiﬁcation: Theory and Practice
0
50
100
150
200
−10
−5
0
5
10
Output
Snapshot of input−output data
0
50
100
150
200
−1
−0.5
0
0.5
1
Time
Input
FIGURE 24.16
Snapshot of the input-output data.
(a) Impulse response estimates
0
10
20
30
40
50
60
−1
0
1
2
3
4
5
6
Time (Sampled)
Amplitude
Step response estimates
(b) Step response estimates
FIGURE 24.17
Impulse and step response estimates for the process in §24.3.
Step response estimates shown in Figure 24.17(b) conﬁrm the inferences drawn earlier from the
visual analysis of data. The drift at steady state suggests a random walk like characteristic of the
stochastic part of the process. On the other hand, the deterministic component seems to be devoid
of any non-stationarity since the response settles down in ﬁnite time. Finally, it can also be observed
that the system has a positive gain as premised before.
In order to conﬁrm that the deterministic component is devoid of any integrating eﬀects, it is
useful to examine the ACF of the output, as shown in Figure 24.18(a). The rapid decay of the ACF
conﬁrms our postulate. Frequency domain analysis of the data oﬀers more insights into the system
as well as the inputs that were used in the experiment (simulation). The input and output spectral
densities in the left panel of Figure 24.18(b) reveal that the system has low-pass ﬁlter characteristics.
The low power at near zero frequencies also supports the earlier made proposition of absence of
any integrating type eﬀects in the deterministic portions. Coherence plot shown on the top right
of Figure 24.18(b) is highly supportive of a linear time-invariant model for the process. Finally,
the disturbance spectrum shown in the bottom right plot clearly indicates a colored noise process.
Further, the relatively high power in the zero frequencies and the rapid roll oﬀonce again suggests
the presence of a pole close to unit circle in the noise model. These plots were generated using the
estimation methods described in §16.5.4 and §20.5.
We shall use these insights into developing a parametric input-output as well as a structured state-
space model for the process.

Case Studies
735
0
5
10
15
20
25
30
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Lags
ACF
ACF plot of the output
(a) ACF of the output
1
2
3
2
4
6
8
10
12
14
ω (rad/sample)
Spectral density
Disturbance spectrum
0
1
2
3
0.1
0.2
0.3
0.4
ω (rad/sample)
γuu
Input PSD
0
1
2
3
0.2
0.4
0.6
0.8
Coherence
Squared Coherence
0
1
2
3
2
4
6
8
γyy
Output PSD
(b) Frequency domain analysis
FIGURE 24.18
Auto-correlation function of the output and frequency domain analysis of the process in §24.3.
24.3.3
PARAMETRIC INPUT-OUTPUT MODEL
As outlined in Chapter 22, there are at least two diﬀerent approaches to developing parametric
models. One beginning with an ARX structure, possibly leading to an ARMAX model and the
other beginning with an OE structure, ﬁnally leading to a BJ model.
We shall illustrate both approaches here. To obtain a reasonable initial guess of the order, we mo-
mentarily turn to the subspace identiﬁcation procedure which examines the Hankel singular values.
Figure 24.19 shows a plot of these singular values. In MATLAB, these are produced by running the
data through the N4SID routine. The algorithm suggests a second-order model. Note that, however,
this is not exact but only a heuristic. A third-order model can also be a likely candidate.
0
2
4
6
8
10
12
−1
0
1
2
3
4
5
6
Log of Singular values
Model order
Red: Default Choice (2)
FIGURE 24.19
(SEE COLOR INSERT) Hankel singular values.
Approach 1: ARMAX model
By virtue of the observations from non-parametric models, an ARX model is clearly ruled out (due
to the diﬀerences in the dynamics of the plant and noise models). Consequently, an ARMAX model
is postulated. To obtain a reasonable initial guess of the polynomial orders, we can use the transfer

736
Principles of System Identiﬁcation: Theory and Practice
−30
−20
−10
0
10
20
30
−0.1
−0.05
0
0.05
0.1
CCF between residuals and output
lag
0
5
10
15
20
25
−0.5
0
0.5
1
ACF of residuals from ARMAX(2,2,2) model
(a) From ARMAX(2,2,2) model
−30
−20
−10
0
10
20
30
−0.1
−0.05
0
0.05
0.1
CCF between residuals and input
lag
0
5
10
15
20
25
−0.5
0
0.5
1
ACF of residuals from ARMAX(3,2,2) model
(b) From ARMAX(3,2,2) model
FIGURE 24.20
Cross- and auto-correlation analysis of the residuals from ARMAX models.
function equivalent of the previously estimated second-order state-space model:
A(q−1) = 1 −1.64q−1 + 0.6687q−2;
B(q−1) = 1.346q−1 −1.164q−2
C(q−1) = 1 −0.9577q−1 + 0.2224q−2
Based on the model above, an ARMAX(2,2,2) model is postulated. Estimates of this model are
obtained using the quadratic PEM method of Chapter 21. Results from the correlation analysis of
the residuals from this model are shown in Figure 24.20(a). The model is clearly unsatisfactory,
calling for a further reﬁnement of both plant and noise models. Consequently, the plant model order
is raised while keeping other polynomial orders intact.
Residual analysis from the resulting ARMAX(3,2,2) model results in the correlation plots shown
in Figure 24.20(b). The estimated model has captured both plant and noise dynamics satisfactorily.
Parameter estimates of this model are reported below
A(q−1) = 1 −1.881
(±0.015)q−1 + 1.063
(±0.017)q−2 −0.1674
(±0.0064)q−3;
B(q−1) = 1.209
(±0.0082)q−1 −1.142
(±0.019)q−2
C(q−1) = 1 −0.9077
(±0.029)q−1 + 0.1298
(±0.028)q−2
(24.14a)
(24.14b)
(24.14c)
The standard errors in estimates, indicated underneath each estimate, clearly allow us to conclude
that all parameter estimates are statistically signiﬁcant. The reader may verify that the estimated
model is stable and invertible (noise model).
Approach 2: Developing a BJ model
The ARMAX(3,2,2) model in (24.14) is satisfactory in all respects. For illustration purposes, how-
ever, it is instructive to show how a BJ model is developed starting with the estimation of an OE
model. Taking cues from the singular values of Figure 24.19, we estimate an OE(2,2) model with
a unit delay. Cross-correlation of model residuals with the input is shown in the bottom panel of
Figure 24.21(a). The model has satisfactorily explained the deterministic eﬀects. Stochastic model
is, as expected, not commensurate with the assumption of the OE model.

Case Studies
737
−30
−20
−10
0
10
20
30
−0.1
−0.05
0
0.05
0.1
CCF between input and residuals
lag
0
5
10
15
20
25
−0.5
0
0.5
1
ACF of residuals from OE(2,2,1) model
(a) From OE(2,2) model
−30
−20
−10
0
10
20
30
−0.1
−0.05
0
0.05
0.1
CCF between input and residuals
lag
0
5
10
15
20
25
−0.5
0
0.5
1
ACF of residuals from OE(1,2,1) model
(b) From OE(1,2) model
FIGURE 24.21
Cross- and auto-correlation analysis of the residuals from OE models.
The estimates of the OE(2,2) model are reported below.
B(q−1) = 1.193
(±0.021)q−1 −0.061
(±0.116)q−2;
(24.15a)
F(q−1) = 1 −0.9884
(±0.085)q−1 + 0.221
(±0.067)q−2
(24.15b)
The error in one of the parameter estimates, namely, b2 is very high relative to the estimate with
the eﬀect that the 95% C.I. for the parameter includes zero. Therefore, this is an overﬁt model.
Eliminating this parameter and re-estimating results in the following model
B(q−1) = 1.186
(±0.024)q−1
F(q−1) = 1 −0.95
(±0.014)q−1 + 0.1934
(±0.017)q−2
(24.16a)
(24.16b)
Cross-correlation coeﬃcients of the residuals from this model with the inputs are shown in Figure
24.21(b). No signiﬁcant correlation is observed. Thus, the OE(1,2) model in (24.16) is a satisfactory
candidate for the deterministic model. Residuals of this model provide an estimate of the stochastic
portion v[k]. An AR(1) model is ﬁt to the residual series based on the PACF of the residuals shown
in Figure 24.22(a).
ˆH(q−1) =
1
1 −0.9355
±0.009 q−1
(24.17)
Whiteness test for the AR(1) model by way of ACF analysis of residuals of ˆH(q−1) shown in
Figure 24.22(b) yields satisfactory results. Thus, we have identiﬁed the OE(1,2) model in (24.16)
and AR(1) model in (24.17) as suitable models for G(q−1) and H(q−1), respectively. The ﬁnal step
is to estimate a BJ model for using the above models as initial guesses. The result of this step is the
following estimate:
ˆG(q−1) =
(±0.008)
1.208 q−1
1 −0.938
(±0.006)q−1 + 0.1789
(±0.006)q−2
ˆH(q−1) =
1
1 −0.9365
(±0.009)q−1 ;
ˆσ2
e = 0.0819
(24.18a)
(24.18b)
The residuals of this model pass the correlation tests as seen in Figure 24.23(a). A snapshot of
the cross-validation of the BJ and ARMAX models on the test set is shown in Figure 24.23(b).

738
Principles of System Identiﬁcation: Theory and Practice
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
PACF of residuals from OE(1,2,1) model
PACF
Lags
(a) PACF of residuals
0
5
10
15
20
25
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF of residuals from the noise model
lag
ACF
(b) ACF of residuals from the noise model
FIGURE 24.22
PACF of the residuals from the OE(1,2) model and whiteness test for the noise model.
−30
−20
−10
0
10
20
30
−0.1
−0.05
0
0.05
0.1
CCF between input and residuals
lag
0
5
10
15
20
25
−0.5
0
0.5
1
ACF of residuals from BJ(1,0,1,2) model
(a) From BJ(1,0,1,2) model
1550
1600
1650
1700
1750
1800
−6
−4
−2
0
2
4
6
8
Time
Amplitude
Comparison of predicted and measured outputs
 
 
Measured
BJ Model
ARMAX Model
(b) Cross-validation
FIGURE 24.23
Residual analysis and cross-validation of the BJ model in (24.18).
The degree of ﬁt as measured by NRMSE (recall (14.46)) is 72%. Thus, both the BJ and ARMAX
models in (24.18) and (24.14), respectively, satisfactorily explain the process dynamics. However,
note that the BJ model is parsimonious compared to the ARMAX model.
Next we illustrate an alternative approach to modeling the given process, based on the idea of
diﬀerencing the data.
Approach 3: Developing a model on differenced data
In the visual analysis of data as well as the step response estimates (Figures 24.16 and 24.17(b),
respectively) we observed the presence of random walk-like eﬀects in the stochastic part of the
process. This is also conﬁrmed by the noise model estimate in (24.18b), which shows a pole close
to unit circle.
An alternative approach is therefore pursued here. Postulating an integrator in the noise model,
we write
y[k] = G(q−1)u[k] + H′(q−1)
1 −q−1 e′[k]
where H′(q−1) is a stable LTI model.
Consequently, one can write
∇y[k] = G(q−1)∇u[k] + H′(q−1)e′[k]
(24.19)
where ∇= 1 −q−1 is the diﬀerencing operator introduced in earlier chapters.

Case Studies
739
−30
−20
−10
0
10
20
30
−0.1
−0.05
0
0.05
0.1
CCF between residuals and differenced inputs
lag
0
5
10
15
20
25
−0.5
0
0.5
1
ACF of residuals from OE(1,2) model
(a) OE(1,2) model on diﬀerenced data
1550
1600
1650
1700
1750
1800
−6
−4
−2
0
2
4
6
8
Comparison of measured and predicted outputs
Time
Amplitude
 
 
Measured
BJ Model
Model Diff
(b) Cross-validation
FIGURE 24.24
Residual analysis and cross-validation of the BJ model in (24.20).
The idea is to ﬁt a BJ model to the diﬀerenced input-output data. Following the above procedure
(as in Approach 2), an OE(1,2) model satisfactorily explains the diﬀerenced input-output relation-
ship (including the stochastic part). Correlation plots of the residuals shown in Figure 24.24(a)
show there is nothing left in the residuals to be modeled. Thus, the following BJ model explains the
original data.
ˆG(q−1) =
(±0.008)
1.209 q−1
1 −0.938
(±0.006)q−1 + 0.1783
(±0.006)q−2
ˆH(q−1) =
1
1 −q−1 ;
ˆσ2
e′ = 0.0868
(24.20a)
(24.20b)
Observe the similarity between the models in (24.18) and (24.20) including the noise variances
(with slightly larger variance for the latter). The diﬀerence is that in (24.20), the noise model is ﬁxed
a priori by the user. Nevertheless, there is no discernible diﬀerence between the inﬁnite-step ahead
prediction capabilities of the models as Figure 24.24(b) shows.
Data generating process: True process
The process used in this case study is a BJ structure with a random walk like (pole close to unit
circle) characteristic in the noise model
G0(q−1) =
1.2q−1 −0.1q−1
1 −q−1 + 0.2275q−2 ; H0(q−1) =
1
1 −0.94q−1 ;
σ2
e = 0.0819
(24.21)
Remarks:
i. In retrospection, the BJ models (24.18) and (24.20) rightly capture the plant dynamics whereas the ARMAX
model in (24.14) overparametrizes both the plant and noise models.
ii. Both models fail to estimate the additional term of −0.1q−2 in the numerator polynomial of G(q−1). An
intuitive reason for this is that the magnitude of this coeﬃcient is small relative to the other coeﬃcients,
particularly at the SNR in the data.
iii. The ARMAX model (24.14) contains additional terms in the numerator polynomials of the plant and noise
models relative to that of the BJ model in (24.18). These additional terms essentially result in zeros that
approximately cancel out the extra pole(s) in the denominator terms of the ARMAX model.
iv. The parsimony principle favors the BJ model in (24.20) as a suitable model for the process. However,
forcibly placing the pole on the unit circle is not preferable when it is really not necessary. Therefore, the
ﬁnal choice of model is (24.18).

740
Principles of System Identiﬁcation: Theory and Practice
24.4
MULTIVARIABLE MODELING OF A FOUR-TANK SYSTEM
The process of interest is a quadruple tank system, originally proposed by Johansson (2000), and
widely used by several researchers as a test bed for control and identiﬁcation algorithms. The
widespread use owes itself to the simplicity and ease of setting up the experimental system, the
important features such as non-linearities (with scope for adjusting the extent of non-linearity) and
non-minimum phase characteristics.
24.4.1
PROCESS DESCRIPTION
Tank 3
Tank 4
Tank 1
Tank 2
Reservoir
Pump 1
Pump 2
u1
u2
y1
y2
Current
signal
Current
signal
FIGURE 24.25
Schematic of a typical quadruple tank system.
Figure 24.25 shows a simpliﬁed schematic of a typical four-tank system. The experimental setup
consists of two tanks on the top and two on the bottom with the labels denoted in the schematic.
Water from a reservoir is pumped into diagonally opposite tanks with the aid of two ﬁxed speed
pumps1 and split valves at user-speciﬁed ﬂow ratios, γ1 and γ2, respectively. The bottom tanks
receive additional inﬂows from the top tanks by virtue of gravity. For a range of settings of the
split ratios on either side, it is possible to introduce non-minimum phase characteristics into the
multivariable system (Johansson, 2000). Non-linearities are naturally present in the system due to
the square root relationship between the exit ﬂows and the respective levels of the top two tanks.
The inputs to the system are the current signals to the control valves so as to adjust the ﬂows into
the diagonally opposite tanks, while the outputs are the level measurements in the bottom tanks, as
indicated in Figure 24.25.
A non-linear model governing the dynamics of the system can be derived from ﬁrst principles, as
1It is also possible to use variable-speed pumps, in which case the control valves at the pumps can be omitted.

Case Studies
741
given below:
dh1
dt = −a1
A1
p
2gh1 + a3
A1
p
2gh3 + γ1
A1
F1
(24.22a)
dh2
dt = −a2
A1
p
2gh2 + a3
A1
p
2gh4 + γ2
A2
F2
(24.22b)
dh3
dt = −a3
A3
p
2gh3 + 1 −γ2
A3
F2
(24.22c)
dh4
dt = −a4
A4
p
2gh4 + 1 −γ1
A4
F1
(24.22d)
where Ai and ai are the cross-sectional areas of the ith tank and the outlet holes, respectively, Fi is
the ﬂow out of the control valves, γi are the respective split ratios and Hi is the level in the ith tank.
Full details of the geometrical dimensions, calibration coeﬃcients, sensors, instrumentation spec-
iﬁcations and other pertinent system parameters are available in the thesis by Detroja (2006). A
schematic showing the complete set of connections and the geometrical dimensions is shown in
Figure 24.26. It is clear from the schematic that the setup, which is a scale-up and modiﬁed version
of the original one by Johansson (2000), has some additional features that can be useful for testing
diﬀerent identiﬁcation, control and diagnostic algorithms.
 
FIGURE 24.26
Schematic diagram (Detroja, 2006) of the quadruple tank system used in §24.4.
The identiﬁcation objective is to develop a multivariable model that relates the current signals
(inputs) to the levels in the bottom tanks (outputs). It is assumed that the remaining valves are fully
open for this purpose. Assuming no additional resistance along the pathway from the control valves
to the bottom tanks, the ﬂows from the pumps are directly proportional to the current signals that
are commanding the respective control valves. In the identiﬁcation terminology, the deterministic
signals sent out by the computer are ui, i = 1,2, while y1 and y2 are the measurements of h1 and
h2, respectively.

742
Principles of System Identiﬁcation: Theory and Practice
24.4.2
DATA ACQUISITION
For the process, the split ratios were adjusted in such a way that larger ﬂow was diverted to the top
tanks. This setting introduces a non-minimum phase behavior in the continuous-time system, i.e.,
the transfer function in the continuous time contains right-half plane zeros. For the discrete-time
system, these conditions correspond to zeros outside the unit circle for the transfer functions.
Two PRBS sequences for introducing changes in the current signals (around the steady-state val-
ues) to the control valves are designed using the idinput routine in MATLAB. It is ensured that the
input signals are not strongly correlated; this is important to ensure that we do not run into singular-
ity issues in model estimation. Further, the process is brought to a steady-state before introducing
the PRBS input changes. A set of 1000 observations at 3-second sampling interval is acquired for
identiﬁcation. Figure 24.27(a) shows the input and output proﬁles obtained from the experiment.
Listing 24.16
Load data and de-trend
%% Read data and assign inputs as well as output
load 4tank_data
Z = iddata(yk,uk,1); % Note actual sampling interval 3 seconds
figure
subplot(221); plot(yk(:,1)); box off
subplot(222); plot(yk(:,2)); box off
subplot(223); plot(uk(:,1)); box off
subplot(224); plot(uk(:,2)); box off
% Alternatively use plot(Z)
200 400 600 800 1000
11.5
12
12.5
13
u2
Samples
Amplitude
200 400 600 800 1000
11.5
12
12.5
13
u1
Samples
Amplitude
200 400 600 800 1000
14
16
18
20
y2
Amplitude
200 400 600 800 1000
12
14
16
18
20
y1
Amplitude
(a) Input-output proﬁles
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Normalized Frequency  (×π rad/sample)
Magnitude
Coherence Estimate via Welch
(b) Squared coherence between the inputs
FIGURE 24.27
Input-output proﬁles and input-input coherence plot for the identiﬁcation experiment on the
four-tank system.
24.4.3
DATA PRE-PROCESSING AND NON-PARAMETRIC ANALYSIS
In order to conﬁrm that the inputs used in the experiment are not linearly related, at least to a
high strength, the squared coherence between the inputs is computed. Figure 24.27(b) shows the
squared coherence estimates obtained via Welch’s method (recall the discussion in §16.7). Since
the coherence estimates are signiﬁcantly below unity at most frequencies and the peak value is far
from unity, it is safe to conclude that the inputs are not strongly correlated.

Case Studies
743
0
5
10
15
20
25
30
35
40
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF of y1
Lags
(a) ACF of y1
0
5
10
15
20
25
30
35
40
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF of y2
Lags
(b) ACF of y2
FIGURE 24.28
Auto-correlation functions of the level responses.
Listing 24.17
Compute the input-input squared coherence and pre-process data
% Input-Input Coherence
figure; mscohere(Ztrain.u(:,1),Ztrain.u(:,2))
%% Data pre-processing
Tr = getTrend(Z);
Tr.InputOffset = [12 12]; Tr.OutputOffset = [16 16];
Zd = detrend(Z,Tr);
Ztraind = Zd(1:900); Ztestd = Zd(901:end);
The obtained data is free of outliers and missing values. No linear or polynomial trends in the re-
sponses are observed. In order to check for integrating type of eﬀect, the ACF estimates of measured
outputs, as displayed in Figure 24.28, are examined. A slow decay in the ACF estimates is strongly
suggestive of integrating eﬀects or random walk-like drifts in the process. Therefore, the data may
have to be diﬀerenced prior to model development. Nevertheless, we proceed without taking this
step. The idea is that the model thus identiﬁed would naturally highlight the presence of integrating
eﬀects, if any; further, it can also provide means of making a judicious decision for diﬀerencing, as
was the case in other studies (e.g., in §9.12 and §24.1).
In light of the above discussion, the only pre-processing step is that of subtracting the steady-
state oﬀsets from input and output signals, respectively2. The steady state values for the inputs
(current signals) are known to be 12 mA, while those of the outputs are determined from the data
collected prior to introducing changes in the inputs (not shown here). The oﬀset-free data set is
partitioned into a training set consisting of 900 observations and a test set containing the remaining
100 observations.
Our next step is that of identifying delays and developing a parametric model in the input-output
model. However, given that the system under study is a multivariable process, it is natural to turn
to the state-space domain for modeling purposes. We shall, therefore, ﬁrst demonstrate the develop-
ment of a state-space model, following it up with that of an input-output model.
24.4.4
DEVELOPMENT OF A STATE-SPACE MODEL
The de-trended data is run through the subspace algorithms of Chapter 23 in order to identify a
suitable guess of the order and generate an initial estimate of the state-space model. Recall that the
result is an unstructured or a non-parametrized state-space model.
2If the oﬀsets are estimated from data, it is advisable to estimate them from the training data, and apply the same to the
test data.

744
Principles of System Identiﬁcation: Theory and Practice
(a) Hankel singular values
0
5
10
15
20
25
−0.5
0
0.5
1
SS(3) Model: ACF of residuals from y2
Lag
0
5
10
15
20
25
−0.5
0
0.5
1
SS(3) Model: ACF of residuals from y1
(b) ACF of residuals
FIGURE 24.29
Singular values and residual analysis of the initial (third-order) state-space model.
Listing 24.18
Estimate state-space models
% Initial guesses of the order and model
mod_ssi = n4sid(Ztraind ,1:10); % Refines it using PEM as well
% Residual analysis
figure; resid(Ztraind ,mod_ssi)
% Not satisfactory. Now fit a higher -order model
mod_ss4 = n4sid(Ztraind ,4);
% Test the model
figure; resid(Ztraind ,mod_ss4)
% Improve the 4th order model
mod_ss4b = pem(Ztrain,mod_ss4b)
figure; resid(Ztraind ,mod_ss4b);
% Also generate refined 3rd and 5th order models for comparison
mod_ss3 = n4sid(Ztrain ,3); mod_ss3b = pem(Ztrain ,mod_ss3b)
mod_ss5 = n4sid(Ztrain ,5); mod_ss5b = pem(Ztrain ,mod_ss5b)
The heuristic based on Hankel singular values suggests a third-order state-space model, as shown
in Figure 24.29(a). However, the corresponding SS model fails the residual analysis, results of which
are shown in Figure 24.29. The auto-correlations of residuals for both outputs indicate the need for
further modeling.
Turning to a fourth-order model, we obtain reasonably satisfactory results as conﬁrmed by the
residual analysis plots in Figures 24.30(a), 24.30(b) and 24.30(c). The last plot indicates that the
dynamics of (u2, y2) sub-system have not been adequately explained. At this stage, we could ﬁt
a higher-order model or reﬁne the fourth-order model with a PEM algorithm. The latter path is
adopted here keeping the principle of parsimony in mind. Figure 24.30(d) shows that the reﬁned
fourth-order model has satisfactorily captured the dynamics of the (u2, y2) channel.
Cross-validation with the test data (consisting of the last 100 observations of the experimental
data) is shown in Figure 24.31. The inﬁnite-step ahead predictions are in close agreement with the
observed data. Further, a comparison with the predictions from the lower and higher-order models
is made to conﬁrm the suitability of the chosen model. The NRMS values for the third, fourth and
ﬁfth-order models are 82.24%, 89.07% and 89.14%, respectively. The improvement obtained in
moving from the fourth to the ﬁfth-order model is negligible compared to the increase in parameter
dimensionality. Therefore, the fourth-order model is the favored model among the three.

Case Studies
745
0
5
10
15
20
25
−0.5
0
0.5
1
SS(4) Model: ACF of residuals from y2
Lag
0
5
10
15
20
25
−0.5
0
0.5
1
SS(4) Model: ACF of residuals from y1
(a) ACF of residuals
−30
−20
−10
0
10
20
30
−0.1
0
0.1
SS(4) Model: CCF between u2 and residuals from y1
Lag
−30
−20
−10
0
10
20
30
−0.1
0
0.1
SS(4) Model: CCF between u1 and residuals from y1
(b) CCF of residuals from y1
−30
−20
−10
0
10
20
30
−0.1
0
0.1
0.2
SS(4) Model: CCF between u2 and residuals from y2
Lag
−30
−20
−10
0
10
20
30
−0.1
0
0.1
SS(4) Model: CCF between u1 and residuals from y2
(c) CCF of residuals from y2
−30
−20
−10
0
10
20
30
−0.1
0
0.1
SS(4) Refined Model: CCF between u2 and residuals from y2
Lag
−30
−20
−10
0
10
20
30
−0.1
0
0.1
SS(4) Refined Model: CCF between u2 and residuals from y1
(d) CCF of residuals from y2
FIGURE 24.30
Residual analysis of the fourth-order state-space model and its reﬁned version.
Comparison of infinite step−ahead predictions
Sampling instants
−4
−2
0
2
y1
 
 
910
920
930
940
950
960
970
980
990 1000
−3
−2
−1
0
1
2
y2
 
 
Test data
mod_ss3b
mod_ss4b
mod_ss5b
FIGURE 24.31
Cross-validating the (reﬁned) fourth-order model and comparing it with the (reﬁned) third-
order and ﬁfth-order models.

746
Principles of System Identiﬁcation: Theory and Practice
Listing 24.19
Analyzing the estimated state-space models
% Examine the estimates of SS matrices
present(mod_ss4b)
% Cross validation
figure
compare(Ztestd,mod_ss3b ,’b.’,mod_ss4b ,’r--’,mod_ss5b ,’ko’);
The matrices of the identiﬁed innovations form of state-space model are reported below:
ˆA =

0.997
−0.0003
−0.0183
−0.0352
−0.0105
0.9918
0.0714
0.0029
0.0079
−0.0332
0.8995
−0.0037
0.0828
0.0137
−0.0079
0.8816

ˆB =

0.0012
0.0014
−0.0012
0.0023
0.0042
−0.0042
−0.0034
0.0007

ˆK =

0.0010
0.0018
−0.0012
0.0026
0.0029
−0.0012
−0.007
−0.0076

ˆΣe =
"0.0234
0.0002
0.0002
0.012
#
ˆC =
"55.1532
−23.7233
4.5169
2.1302
36.9680
17.5869
−3.3954
1.5783
#
D =
"0
0
0
0
#
(24.23)
Remarks:
1. The eigenvalues of the matrix, which are the poles of the system, are located at, are λ
=
0.9194,0.9562,0.9472 ± 0.016i. Note that the imaginary parts of the complex poles are ideally supposed to
be zero since the underlying process has no known sources of underdamped characteristics. The proximity
of the poles to the unit circle may be attributed to the fast sampling rate chosen in the experiment. Finally,
the transmission zeros of the model are located at z = 0.8326,1.0435; the second zero located marginally
outside the unit circle is indicative of the mild non-minimum phase behavior of the system during the
experiment.
2. The diagonal nature of the noise covariance matrix estimate suggests that the noise processes in outputs are
uncorrelated. Having stated this, it must be reiterated that what is termed as “noise” is a lumped variable
containing unmodeled (non-linear) dynamics, eﬀects of actuator noise in the top and bottom tanks and
measurement noise. Therefore, suﬃcient caution should be exercised in attaching a physical meaning to the
noise covariance matrix.
3. From §2.4, we know that each tank is characterized by ﬁrst-order dynamics. Therefore, the relation between
u1 (or u2) and y2 (or y1) should be described by second-order characteristics. Two reasons for the increased
order of the identiﬁed state-space model can be given: (i) presence of delays, which have been set to the
default values of unity in the model and (ii) consolidated dynamics could be of fourth order, i.e., lower-order
sub-systems with diﬀerent pole locations collectively manifest as higher order. The collection includes both
the deterministic and the stochastic sub-systems.
4. An important advantage of choosing the state-space route is that prior estimates of time-delays and model
orders were not required. Moreover, it oﬀers a quick and reliable means for obtaining valuable insights into
the process characteristics. However, certain notable demerits also exist, as discussed below.
5. The identiﬁed state-space model in (24.23) is unstructured and also not identiﬁable (unique) (recall the
discussion in §23.1). Therefore, it is not possible to theoretically speak of errors in the individual elements
of the matrix estimates. However, it is possible to compute approximately the uncertainties in the estimates
through a (numerical) sensitivity analysis3.
6. Further to the point above, the state-space model contains more parameters than necessary to describe the
system, i.e., it is over-parametrized. See Exercise E24.4 for instructions on how to verify this fact.
3As reported by the present routine in MATLAB for state-space models.

Case Studies
747
7. Observe from the bottom plot of Figure 24.31 that the chosen model falls short of explaining the dynamics
of y2 in the duration spanned by the 970 to 990 instants.
In light of the points above, the state-space model identiﬁed in (24.23) oﬀers scope for improve-
ment in two respects, one being the parsimony, and the other being the predictive ability. There are
at least two approaches that one could follow here: (i) build a 2×2 input-output TF model (possibly
of the BJ structure) taking cues from the identiﬁed SS model, or (ii) estimate a grey-box model. The
former route is taken here, while leaving the second route to the reader for exploration (see Exercise
E24.7).
24.4.5
TRANSFER FUNCTION MODELS FOR THE MIMO SYSTEM
We present two approaches to the development of multivariable input-output models starting from
subspace models. The ﬁrst approach uses the SS model in (24.23) as a starting point, while the
second one uses the SS-OE model, i.e., with K = 0, as a starting model.
24.4.5.1
Approach I: Using the Full SS Model
Starting with the identiﬁed SS model, one arrives at an ARMAX structure. After a systematic trial-
and-error method, it is discovered that an ARMAX structure fails to satisfactorily explain the model
dynamics without being over-parametrized. This is to be expected because from the physics of the
process it is clear that a common parametrization of the deterministic models for all channels (even
for an individual output) is not appropriate.
However, the experience obtained above can be combined with a systematic trial-and-error ap-
proach in estimating an appropriate BJ model (reported in (24.25) and (24.26) below) by breaking
up the MIMO system into two 2 × 1 MISO systems, with the delays estimated as:
nk =
u1
u2


y1
1
4
y2
4
1
(24.24)
The resulting model not only satisfactorily passes all the model checks (not shown here), but also
exhibits better performance than the SS model in (24.23) on the test data set. Figure 24.32 conﬁrms
the latter observation.
The estimated Box-Jenkins model is reported below.
Model for y1:
B11(q−1) = 0.1092
(±0.0022)q−1;
B12(q−1) = 0.0425
(±0.0039)q−4 −
0.03
(±0.0045)q−5
F11(q−1) = 1 −0.934
(±0.002)q−1;
F12(q−1) = 1 −1.891
(±0.008)q−1 + 0.8943
(±0.008)q−2
C1(q−1) = 1 −0.786
(±0.0023)q−1;
D1(q−1) = 1 −0.9872
(±0.005)q−1
(24.25)
Model for y2:
B21(q−1) = 0.031
(±0.0026)q−4 −0.0235
(±0.003)q−5
B22(q−1) = 0.1103
(±0.0016)q−1,
F21(q−1) = 1 −1.899
(±0.0086)q−1 + 0.9017
(±0.0084)q−2;
F22(q−1) = 1 −0.947
(±0.0014)q−1
C2(q−1) = 1 −0.7671
(±0.023)q−1;
D2(q−1) = 1 −0.9899
(±0.0045)q−1
(24.26)

748
Principles of System Identiﬁcation: Theory and Practice
Comparison of infinite step−ahead predictions
Sampling Instants
−6
−4
−2
0
2
4
y1
 
 
910
920
930
940
950
960
970
980
990 1000
−3
−2
−1
0
1
y2
 
 
Test data
mod_ss4b
mod_bj
FIGURE 24.32
Comparing the predictive performance of the BJ and SS(4) models on the test data set.
Listing 24.20
Estimating the input-output model
% Estimate a BJ model of appropriate orders and delays
mod_bj = bj(Ztraind ,’nb’,[1 2; 2 2],’nc’,[1;1],’nd’,[1;1],...
’nf’,[1 2; 2 1],’nk’,[1 4; 4 1]);
% Residual analysis
figure; resid(mod_bj,Ztraind);
% Cross validation
figure; compare(Ztest,mod_ss4b ,’--’,mod_bj ,’r.’)
Remarks:
1. Notice the symmetry in the model structure and the delays, which is consistent with the physical construc-
tion of the process.
2. In continuation of the point above, the delay estimates for the oﬀ-diagonal channels are 3 sample times
greater than those for the diagonal ones. This is partly attributed to the fact that each of the oﬀ-diagonal
pathways involves an additional ﬁrst-order system, which has “slow" dynamics with respect to the obser-
vation scale of three seconds. The other reason is the non-minimum phase behavior of the system, which is
“seen” as a delay by the data-driven model.
3. The input-output model clearly points to the presence of integrating eﬀects in the noise models as high-
lighted by the close proximity of the poles to the unit circle. Thus, there is merit to building a model on
diﬀerenced data. A critical comparison of both models, i.e., on diﬀerenced and non-diﬀerenced data, how-
ever, is necessary before making a ﬁnal choice (see Exercise E24.3).
24.4.5.2
Approach II: Using the MOESP Model
In this approach, we ﬁrst identify the deterministic sub-system, as was done in the OE-based ap-
proaches of §24.2 and §24.3. However, given the multivariable nature, it is natural to develop a
state-space representation for the deterministic part. The MOESP algorithm can be used for this
purpose. Noise models can be subsequently developed from the residuals of this model.
Following a similar line of approach in the full subspace model development, a third-order state-
space model is found to be satisfactory in explaining the deterministic sub-system. Figure 24.33
shows the cross-correlations between the two inputs and the residuals of the models corresponding

Case Studies
749
−30
−20
−10
0
10
20
30
−0.4
−0.2
0
0.2
MOE SS(3) Model: CCF of u2 and residuals from y1
Lag
−30
−20
−10
0
10
20
30
−0.4
−0.2
0
0.2
MOE SS(3) Model: CCF of u1 and residuals from y1
(a) CCF of residuals from y1
−30
−20
−10
0
10
20
30
−0.4
−0.2
0
0.2
MOE SS(3) Model: CCF of u2 and residuals from y2
Lag
−30
−20
−10
0
10
20
30
−0.4
−0.2
0
0.2
MOE SS(3) Model: CCF of u1 and residuals from y2
(b) CCF of residuals from y2
FIGURE 24.33
Cross-correlation analysis of the residuals from the third-order MOESS model.
to y1 and y2 respectively. These plots conﬁrm the suitability of the third-order SS model, reported
below.
ˆA =

0.9337
0.008
−0.0005
−0.0027
0.9764
0.0008
0.109
−0.0088
0.9526

;
ˆB =

−0.0025
0.0036
−0.002
−0.0015
0.0032
−0.0052

ˆC =
" 20
−49.642
24.906
1.28
−36.524
−13.966
#
;
D =
"0
0
0
0
#
(24.27)
Time-series modeling of the residuals from the MOESS (multivariable output-error state-space)
model is now carried out to obtain preliminary estimates of the noise model. It is assumed that the
noise processes in y1 and y2 are uncorrelated.
The ACF and PACF of the two residual series are shown in Figures 24.34(a), 24.34(b), 24.34(c)
and 24.34(d), respectively.
From the knowledge of ACF and PACF signatures of ARMA models in §9.6, it is clear that both
noise processes can be suitably modeled by ARMA descriptions. Following this line of thought, the
following ARMA(1,1) models are found to be suitable for both channels.
C1(q−1) = 1 −0.6982
(±0.026)q−1; D1(q−1) = 1 −0.9852
(±0.062)q−1
C2(q−1) = 1 −0.521
(±0.03)q−1; D2(q−1) = 1 −0.9831
(±0.065)q−1
(24.28)
The ACFs of residuals from the ARMA(1,1) model are shown in Figure 24.35.
The third-order deterministic SS model in (24.27) together with the ARMA(1,1) model in (24.28)
provide the preliminary estimates for the input-output model that we intend to develop.
Listing 24.21
Estimating a MOESS model and developing noise models
%% Estimate a MOESS model and develop noise models
mod_ssdet = n4sid(Ztraind ,3,’Disturbance’,’None’);
figure; resid(mod_ssdet ,Ztraind)
% Compute prediction errors
err_ssdet = pe(mod_ssdet ,Ztraind ,1);
% Plot ACF and PACF
acf(err_ssdet.y(:,1) ,20,1); pacf(err_ssdet.y(:,1) ,20,1);
acf(err_ssdet.y(:,2) ,20,1); pacf(err_ssdet.y(:,2) ,20,1);

750
Principles of System Identiﬁcation: Theory and Practice
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
ACF of residuals from y1
(a) ACF of residuals from y1
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF
Lags
ACF of residuals from y2
(b) ACF of residuals from y2
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
PACF
Lags
PACF of residuals from y1
(c) PACF of residuals from y1
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
PACF
Lags
PACF of residuals from y2
(d) PACF of residuals from y2
FIGURE 24.34
ACF and PACF of the residuals from the third-order MOESS model.
% Build ARMA(1,1) models
mod_arma11 = armax(err_ssdet ,’na’,[1 0; 0 1],’nc’,[1 1]’);
figure; resid(mod_arma11 ,err_ssdet)
present(mod_arma11)
Developing the input-output model
The ﬁrst step is to bring down the over-parametrization in the MOESS model of (24.27) to a minimal
parametrization. A simple way of doing this is to convert the MOESS model to an MOETF structure,
followed by discarding the parameters that have large errors in them. This step leads to a revision of
the orders and delays for the individual sub-systems. We repeat this exercise until we have arrived
at a minimally parametrized model that also passes the residual analysis, to be speciﬁc, the cross-
correlation test. Using this step-wise approach, we obtain the following sequence of revised orders

Case Studies
751
0
5
10
15
20
25
−0.5
0
0.5
1
Correlation function of residuals. Output e@y2
Lag
0
5
10
15
20
25
−0.5
0
0.5
1
Correlation function of residuals. Output e@y1
Lag
FIGURE 24.35
ACFs of the residuals from the ARMA(1,1) noise models.
and estimates:
nb =
"3
3
3
3
#
;
nf =
"3
3
3
3
#
;
nk =
"1
1
1
1
#
↓
nb =
"1
3
1
3
#
;
nf =
"3
3
3
3
#
;
nk =
"1
3
4
1
#
↓
nb =
"1
1
1
1
#
;
nf =
"2
3
3
1
#
;
nk =
"1
3
4
1
#
↓
nb =
"1
1
1
1
#
;
nf =
"1
3
3
1
#
;
nk =
"1
3
4
1
#
The ﬁnal choice of OE model has 4 + 8 = 12 parameters compared to the 24 parameter initial OE
model constructed from MOESS. Notice that we have also “improved” the delay estimates.
The ﬁnal step is to fuse the OE model of the above orders and delays and the noise models in
(24.28) to seed the BJ estimation algorithm, and subject the BJ model to further reﬁnements, if
necessary. Carrying out this approach yields, in its ﬁrst step, a BJ model that does not result in
satisfactory cross-correlations of the residuals with inputs, and also has parameters that are not
identiﬁable. Adopting the same strategy for reﬁning the OE model earlier, in a step-wise manner,
we arrive at, interestingly, the same model orders and delays as in (24.25) and (24.26). Therefore,
the ﬁnal models coincide in both approaches.
Remarks:
1. Although both approaches yield the same models, for a general system, this may not hold, since there may
be several local optima that can satisfy the terminating criteria.
2. It is always advisable in practice to use at least two diﬀerent approaches to develop a model so as to
corroborate certain key ﬁndings such as delays, orders and other process features. Real-life processes rarely
oﬀer the privilege of a “true” LTI description and hence there is no model to compare.
3. Notwithstanding the above point, the second approach has an edge over the ﬁrst one as follows. In arriving
at the ﬁnal model, in the second approach, it is usually suﬃcient to revise only the orders and delays of
the deterministic model, since the orders of the noise models are optimally modeled in the preliminary step
itself. That is, the deterministic and stochastic sub-systems are nicely separated. On the contrary, in the ﬁrst
approach, one has to also tune both the plant and noise models, which is certainly more tedious. These
arguments, of course, hold only under open-loop conditions.

752
Principles of System Identiﬁcation: Theory and Practice
In closing, it is a worthwhile exercise to compare the predictive ability of the linearized model
with that of the identiﬁed model (see Exercise E24.6).
Listing 24.22
Estimating a MOESS model and developing noise models
%% Develop an input-output model
mod_tf = idtf(mod_ssdet);
mod_oe1 = oe(Ztraind ,mod_ssdet);
present(mod_oe1)
mod_oe4 = oe(Ztraind ,’nb’,[1 1;1 1],’nf’,[1 3; 3 1],’nk’,[1 3; 4 1]);
% Fuse the OE and noise models
dpoly = {mod_arma11.a{1,1}; mod_arma11.a{2,2}};
gtotal = idpoly({1 0;0 1},mod_oe4.b,mod_arma11.c,dpoly,mod_oe4.f,’Ts’,1);
% Estimate the BJ model
mod_bj1 = bj(Ztraind ,gtotal);
mod_bj2 = bj(Ztraind ,’nb’,[1 1;1 1],’nc’,[1;1],’nd’,[1;1],...
’nf’,[1 3;2 1],’nk’,[1 3;4 1]);
mod_bj6 = bj(Ztraind ,’nb’,[1 2;2 1],’nc’,[1;1],’nd’,[1;1],...
’nf’,[1 2;2 1],’nk’,[1 4;4 1]);
% Analysis
figure; resid(mod_bj6)
present(mod_bj6)
24.5
SUMMARY
This chapter presented four case studies that highlighted diﬀerent aspects of identiﬁcation and also
oﬀered some ideas for further study (e.g., delay estimation in multivariable systems). The ﬁrst case
study was concerned with the time-series modeling of an industrial dryer that has integrating char-
acteristics as well as some periodicities. A constrained ARIMA model was developed for the series
using the systematic methods discussed in this text. The constraint was necessary to zero out certain
parameters in the denominator polynomial.
In the second case study, we demonstrated how one could develop parametric models starting
with either the ARX or the OE model. A systematic procedure and the use of information theoretic
measures discovered the “true” model for the system, which had an ARX description. The third
case study demonstrated a method of handling integrating or random walk-like disturbances based
on the theory in §22.4.1. With the help of suitable aids, it was determined that there was a case
for diﬀerencing the output series. A BJ model on the diﬀerenced data was found to be a suitable
working model for the process.
Finally, the fourth case study demonstrated features of a multivariable identiﬁcation problem and
the power of state-space models in modeling MIMO systems from experimental data. The pro-
cess under study was the four-tank system, a widely used test bed for identiﬁcation and control
algorithms. It presented an interesting case for highlighting the merits and demerits of identifying
(unstructured) subspace models vis-a-vis parametrized input-output models for multivariable sys-
tems. Further, we showed how subspace approaches provide good starting points for input-output
models. It is appropriate to close by saying that a wise practitioner uses an appropriate blend of both
these approaches in a regular identiﬁcation exercise.

Case Studies
753
EXERCISES
E24.1 Develop a state-space model for the case study in §24.3. Consider both the non-diﬀerenced,
i.e., the data as is and the diﬀerenced cases.
E24.2 The data used for the quadruple tank system in §24.4 is available on the publisher’s site.
a. Estimate the input-output delay using the classical impulse response estimation method
discussed in Chapter 20.
b. Are the obtained delay estimates physically meaningful?
E24.3 With reference to §24.4, we develop a state-space model and an input-output model on the
diﬀerenced series. Be clear on whether both the input and output should be diﬀerenced, or only
the latter.
E24.4 Verify that the model identiﬁed in (24.23) is over-parametrized as instructed below:
a. Convert the SS model in (24.23) to a TF form using the idpoly routine. Observe that the
resulting model has an ARMAX structure.
b. With the TF model above as initial estimate, re-estimate an ARMAX model of the same
orders using the PEM algorithm.
c. Conﬁrm that the model obtained in E24.4(b) passes the residual test satisfactorily, but the
parameter estimates have large errors. This is an indication that the model has more param-
eters than identiﬁable.
E24.5 Identify a multivariable model for the four tank system from the simulation of the ﬁrst-
principles model given in §24.4.1 with the settings given in Detroja (2006). For this purpose
a. Design two PRBS sequences that are as uncorrelated as possible.
b. Choose appropriate sampling interval by performing step tests on the ﬁrst-principles model.
c. Perform a noise-free simulation so as to determine suitable values for the noise variances
in the level measurements.
d. Assume white noise measurement errors in the level readings. Adjust noise variances such
that the SNR is close to 10.
e. Collect data and identify a suitable state-space as well as input-output model.
E24.6 With reference to the quadruple tank setup, do the following:
• Develop a linearized model of the system around the given steady-state conditions.
• Compare the predictions of the linearized model to changes in inputs with that of the iden-
tiﬁed model in (24.25) and (24.26). Which of these models, in your observation, performs
better?
E24.7 Develop a grey-box model for the quadruple tank setup using the settings described in §24.4.
Verify if it performs better than the BJ model presented in (24.25) and (24.26).

PART V
ADVANCED CONCEPTS

25
Advanced Topics in SISO Identiﬁcation
The objective of this chapter is to present a brief overview of certain advanced topics in
identiﬁcation of SISO systems. In particular, we review topics of identiﬁcation of linear time-
varying systems using recursive and wavelet-based methods, non-linear system identiﬁcation
(both under open-loop conditions) and closed-loop identiﬁcation.
The theory and practical guidelines for identiﬁcation laid down in the previous parts of this text
have been in the framework of open-loop linear time-invariant systems. The general situation is,
however, that the system is time-varying and/or non-linear and/or under closed-loop conditions. In
this respect, the set of open-loop LTI systems is certainly a restricted class. However, as we shall
shortly learn, the core principles and guidelines for the identiﬁcation of aforementioned systems
are similar to those of LTI systems. Moreover, many of the algorithms use the LTI system model
as the basic building block. Needless to add, the form of optimization problem, complexity and
dimensionality of the associated methods can be signiﬁcantly diﬀerent from those of LTI systems.
While acknowledging the numerous deviations from open-loop LTI scenario, we shall restrict
ourselves in this chapter to three prominent classes, namely, linear time-varying, non-linear and
closed-loop systems.
25.1
IDENTIFICATION OF LINEAR TIME-VARYING SYSTEMS
There are several compelling reasons in practice to respect the time-varying nature of a system, par-
ticularly when the time scales of changes in process become comparable to that of the observation
time scale. The time-varying nature is induced largely by “rapidly” changing physical properties of
the system and/or wear and tear of the actuators. For example, in continuous operation of heat ex-
changers, it is common to observe either a build-up or erosion of material leading to what is known
as fouling. This causes signiﬁcant changes in the heat transfer coeﬃcient of the material with the
passage of time. A time-invariant model built on initial operating data would obviously be unable
to capture the changing system characteristics.
In this chapter, we shall restrict ourselves, as earlier, to linear time-varying (LTV) systems. One
of the main diﬀerences between LTV and LTI systems is that the elementary responses (impulse,
step) change with time. Moreover, the FRF is also a function of time. The non-parametric model in
(17.18) for instance would now be
y[k] =
∞
X
n=0
g[n,k]u[k −n] +
∞
X
m=1
h[n,k]e[k −n] + e[k]
(25.1)
A class of parametric descriptions on the other hand make use of those of LTI systems but with
time-varying coeﬃcients. Thus, the parametric model in (17.25) would now take the form
y[k] = G(q−1,θG[k])u[k] + H(q−1,θH[k])e[k]
(25.2)
Systems that are described by (25.2) are also known as the linear parameter-varying (LPV) systems.
A popular one is the TVARX process, for instance
y[k] = −
na
X
i=1
ai[k]y[k −i] +
nb
X
j=1
bj[k]u[k −nj] + e[k]
(25.3)
755

756
Principles of System Identiﬁcation: Theory and Practice
where e[k] is the usual white-noise process.
An implicit assumption in the models above is that the system is locally (in time) invariant. Thus,
the model in (25.2), explains the local time-invariance using the LTI model while describing the
changing system properties with the time-varying coeﬃcients. Modelling LPV systems then is a
matter of updating the model parameters at a chosen update rate in a numerically eﬃcient (recursive)
manner. These local LTI models are quite popular in adaptive control and other applications.
The subject of modeling LTV systems has attracted widespread interest among the identiﬁcation
and control community for several decades and continues to do so with the development of increas-
ingly sophisticated methods. As a result, today there exist several classical to modern approaches
for modeling LTV systems, signiﬁcant among them being modeled as LPV systems. The main ob-
jective of this section is to oﬀer the reader glimpses of certain standard and modern approaches. A
comprehensive treatment of this subject is outside the scope of this text. The reader is referred to
some recent texts on this subject for this purpose (Niedzwlecki, 2000; Santos et al., 2012).
A major challenge in the identiﬁcation of LTI systems is that it is an overdetermined problem,
meaning there are many more parameters than the available observations. Existing approaches for
modeling LTV (mostly LPV) systems can be divided broadly into two categories, namely the classi-
cal and modern approaches. Both approaches inherently aim at addressing the overdetermined issue
in their own right. There is a signiﬁcant diﬀerence, however, in how they explain / represent the
time-varying nature of the system and the identiﬁcation procedures.
Classical approaches:
• Use LTI representations with time-varying parameters, i.e., LPV descriptions.
• Deploy LPV models but further parametrize the time-varying nature of the parameters, for ex-
ample, assume k to be polynomial functions of time.
Identiﬁcation is then carried out by updating the model parameters at regular time intervals (update
instants) using numerically and computationally eﬃcient algorithms. The well-known weighted es-
timators and the recursive methods are widely used in model tracking and adaptive control. Alter-
natively, if the parameter variations are parametrized, then the goal is to identify the coeﬃcients of
such parametrizations. The advantage with the latter strategy is that no on-line tracking is required
but its success is then limited by the correctness of the assumed model for parameter variations. In
the present text, we shall describe the WLS methods with forgetting factor and the recursive class
of algorithms with speciﬁc focus on the recursive least squares methods.
Modern approaches:
The modern approach is more sophisticated in the sense that it expands the time-varying param-
eters on to a set of basis functions such as wavelets (Doroslovacki and Fan, 1996; Tsatsanis and
Giannakis, 1993). Alternatively, the signals are themselves projected on to basis functions such
that both the temporal and frequency-domain characteristics of the responses are explained in the
transformed domain (Shan and Burl, 2011; Tangirala, Mukhopadhyay and Tiwari, 2013). This is an
extension of the idea of FRFs to the time-frequency plane. The premise in both strategies is that
the time-varying nature of the parameters / system translate to constant coeﬃcients of expansions /
time-invariant models in the new basis space. A third strategy consists of using repeated experiments
leading to what are known as ensemble methods for identiﬁcation (Keamey et al., 1991; Verhaegen
and Yu, 1995), where the problem setting is in the state-space framework1.
To summarize, the strategies are
• Expand parameters in terms of basis functions (e.g., Legendre, Chebyshev, wavelets)
1See also Liu (1997) for an alternate algorithm for identifying time-varying subspace models from free response data.

Advanced Topics in SISO Identiﬁcation
757
• Build models on data in a diﬀerent basis space that capture the time-varying nature of signals
(e.g., wavelets)
• Ensemble methods (popular in biomedical / mechanical engineering applications)
In this text we shall brieﬂy elucidate the ﬁrst two strategies that particularly work with wavelet
transforms and wavelet basis.
25.1.1
WLS METHODS WITH FORGETTING FACTOR
The popular weighted least squares algorithm of §14.3.5 with forgetting factors is ideally suited
for identiﬁcation of (linear) time-varying systems. A point to this eﬀect was brieﬂy mentioned in
§14.3.5. In this approach, the weighting matrix is diagonal with elements
wkk = λN−1−k,
0 < λ ≤1
(25.4)
so that
ˆθ⋆
N = min
θ
N−1
X
k=0
λN−1−kε2[k]
(25.5)
The name forgetting factor arises due to the way it governs the importance of observations at dif-
ferent time instants in parameter estimation. Recent samples are given relatively more importance
than the past ones. The speciﬁc name given to λ in (25.4) is the exponential forgetting factor.
A computationally eﬃcient implementation of (25.5) is via the recursive WLS algorithm. Section
§25.1.3 discusses the relevant details and also some useful guidelines for choosing the forgetting
factor.
25.1.2
RECURSIVE METHODS
The strategy of these methods, as described above, is to update the estimated model (parameters)
adaptively. An important concern in adaptive modeling is the computational burden involved.
Example 25.1: Updating FIR Models
Consider the estimation of an M-coeﬃcient FIR model using the OLS method.
The optimal estimates of these coeﬃcients from N observations at k = 0,1,· · · , N −1 are
given by (20.8)
ˆθN = (ΦT
N ΦN )−1ΦT
N yN
where ΦN is an N × p matrix and yN is an N × 1 vector.
When the observation at k = N arrives, the regressor matrix and the measurement vector
update to,
ΦN+1 =
f
ϕ[0]
ϕ[1]
· · ·
ϕ[N]
gT =
" ΦN
ϕT [N]
#
yN+1
=
" yN
y[N]
#
increasing their dimensions. Oﬄine estimation of θN+1 will thus involve an increased number
of computations and continues to grow with N.
A closer look at ΦT
N+1ΦN+1, however, reveals the possibility of computing the covariance
matrix ΦT Φ in an eﬃcient manner. From the above expressions for the regressor matrix and
the output vector, we have
ΦT
N+1ΦN+1 = ΦT
N ΦN + ϕ[N]ϕT [N]
(25.6)
ΦT
N+1yN+1 = ΦT
N yN + ϕ[N]y[N]
(25.7)

758
Principles of System Identiﬁcation: Theory and Practice
The ﬁrst terms on the RHS of each of the above equations are known at k = N −1. Thus,
only the second terms have to be computed at the new instant, thereby signiﬁcantly lowering
the computational burden.
This motivates the possibility of an algorithm that can recursively update the model parameters
using the existing estimate and the new measurements in an eﬃcient manner. In addition, Example
23.3 concerning the update of mean, but introduced in the context of Kalman ﬁlter also serves
as a motivating example for recursive estimation. In fact, as we shall shortly learn, there exists a
strong semblance between recursive parameter estimation and the Kalman ﬁlter designed for state
estimation.
Note that the subscript in ˆθN+1 corresponds to the estimate obtained at k = N (since the starting
index is k = 0 in this text) and similarly for the regressor matrix and the measurement vector. To
keep things commensurate therefore, we shall introduce
ˆθ[m] ≜ˆθm+1;
Φ[m] ≜Φm+1;
y[m] ≜ym+1
(25.8)
where ˆθ[k] implies the estimate obtained at the kth instant.
Recursive identiﬁcation aims at improving the eﬃciency by constructing an update rule for the
parameters of the form
ˆθ[N] = ˆθ[N −1] + △ˆθ[N]
(25.9)
Problem statement: Given the parameter estimate ˆθ[N−1] from N samples at k = 0,1,· · · , N−1,
derive an update expression for △ˆθ[N].
In writing (25.9), we have implicitly assumed that the oﬄine estimate of θ can be expressed in
the additive incremental form (25.9), the appropriateness of which depends on the estimator in use.
This aspect shall be discussed shortly. We have also assumed that update interval (time between
two updates), Tu is identical to the sampling interval Tu. In reality, Tu = MTs, M > 1. For systems
that change slowly, M ≫1.
Recursive methods are also useful in identiﬁcation of LTI systems because they aid in determining
the minimum number of samples required for the parameter estimates to converge.
The conceptual premise for any parameter update is that the model is “far” from the true system.
Intuitively therefore the update △ˆθ[N] depends on the prediction error at k = N, since the prediction
error
ε[N] = y[N] −ˆy[N| ˆθ[N −1]]
(25.10)
is a measure of distance between the model and the process.
For ease of online computations, often a linear update law of the form may be preferred:
△ˆθ[N] = K[N]ϵ[N]
(25.11)
where K[N] is the gain.
Remarks:
i. It is idealistic to expect ε[k] = 0 at any instant since every observation contains at least the innovation e[k].
Consequently, the gain K[N] denotes the importance or weighting given to the new measurement relative
to the prior estimate ˆθ[N −1].

Advanced Topics in SISO Identiﬁcation
759
ii. Any recursion whether in identiﬁcation or in numerical analysis should stand the test of convergence, i.e.,
as N →∞it should converge to a ﬁnite value. This property naturally depends on the estimator (of θ) in
use. These issues are discussed at length for diﬀerent estimators in several texts (Ljung, 1999; Soderstrom
and Stoica, 1994; Young, 2011). The text by Young (2011) oﬀers an excellent introduction to recursion
algorithms.
iii. A natural question that arises from the preceding point is:
Under what conditions does the linear update rule in (25.11) asymptotically (N →∞) converge to the
oﬀ-line parameter estimate?
The answer is: for linear estimators of ˆθ - for example, when θ is the parameter vector of a linear regression
model and is estimated using the OLS method. This is because with a linear predictor, the relation
ˆθ[N] = ˆθ[N −1] + K[N](y[N] −Φ[N] ˆθ[N −1])
(25.12)
turns out to be exact (as shall be established shortly). When the estimator is non-linear, (25.12) can be
thought of merely a ﬁrst-order approximation of ˆθ[N] around a nominal point ˆθ[N −1]. Thus, with PEM
estimators, the recursions can be expected to produce only approximate estimates.
The prime problem of interest is the computation of the optimal gain in the linear update rule
(25.11), which intuitively should be a function of three quantities, namely, the error in prior estimate
( ˆθ[N−1]), the error characteristics of the new measurement y[N] and the estimation algorithm itself.
Computing the optimal gain
Arriving at expressions for the optimal gain is heavily dependent on the estimator for θ. It turns out
that it is relatively easy and simple to derive these expressions for linear estimators. We shall focus
largely on this case. There are a few diﬀerent ways in which the ﬁnal expressions can be derived
depending on the viewpoint that one takes of the recursion, as explained below.
Feedback control viewpoint
The main purpose of recursion is parameter (model) tracking. From this viewpoint, the update rule
is similar to a control law used in a proportional feedback strategy where the goal is to drive the pre-
diction ˆy[k] (output of the model) close to y[k] (set-point) by adjusting the parameters (manipulated
variables) at each instant. Re-writing the linear update rule in terms of the shift-operator
ˆθ[k] =
K[k]
1 −q−1 ε[k]
(25.13)
we recognize that a time-varying integral controller is involved. Figure 25.1 depicts the time-varying
parameter estimation as a control problem.
Parameter
Update
Model
-
+
ˆy[k]
y[k]
"[k]
ˆ✓[k]
FIGURE 25.1
Casting the time-varying parameter estimation as a control problem.
The rich theory of stability and tracking of control systems can be used to study the convergence
properties of the parameter update (controllers). This viewpoint also can be used to postulate other
forms of recursions based on optimal control type strategies. Observe that if the update interval Tu
is diﬀerent from the sampling interval Ts, the parameter estimation problem is a multirate control

760
Principles of System Identiﬁcation: Theory and Practice
problem. We shall not pursue this line of thought here, although the reader is encouraged to put the
ﬁnal expressions (derived shortly) into this perspective.
Kalman ﬁlter viewpoint
This viewpoint is perhaps the most widely studied and applied in parameter estimation literature.
Only the basic ideas are explained below.
The recursion in (25.9) combined with the update rule (25.11)
ˆθ[N|N] = ˆθ[N −1|N −1] + K[N]ε[N]
(25.14)
has a strong resemblance to the Kalman ﬁlter update (23.30)
ˆx[k|k] = ˆx[k|k −1] + Kkϵ[k]
= A ˆx[k −1|k −1] + Bu[k] + Kkϵ[k]
To establish the connection, ﬁrst recognize the parameters as states (both are hidden variables), i.e.,
x[k] ≡θ[k]. Secondly, by comparison of recursions, A = I and B = 0.
A state-space model satisfying the above choices is
θ[k + 1] = θ[k]
(25.15a)
y[k] = ϕT[k]θ[k] + v[k]
(25.15b)
which corresponds to a constant parameter (LTI) system. The state and process noise covariance
matrices are, respectively, Q = 0 and R = Σv.
The recursion in (25.9) with the linear update rule (25.11) can be formulated as a time-varying
Kalman ﬁlter problem by treating the parameters (which are hidden) as state variables and the
gain K[N] as the time-varying Kalman gain.
In the above statement, it is implicit that we are working with a linear estimator for ˆθ (such as OLS
for the linear regression model). For non-linear estimators, the extended Kalman ﬁlter equivalence
is used (Ljung, 1979; Moore and Weiss, 1979).
Now directly invoking the Kalman ﬁlter in (23.31), we obtain the optimal gain
K[N] = Pθ[N −1]ϕ[N −1](ϕT[N −1]Pθ[N −1]ϕ[N −1] + Σv)−1
(25.16)
with a prior estimate ˆθ[N −1] and Pθ[N −1] as the covariance of the prior estimate. In §25.1.3, we
shall establish that this is indeed the optimal gain for the recursive least squares estimator.
The Kalman ﬁlter viewpoint can also be used to accommodate time-varying systems (parameters)
by modifying the state equation in (25.15) to
θ[k + 1] = θ[k] + w[k]
(25.17)
where w[k] could be a deterministic function or a stochastic term.
Types of recursive estimators
The exact expression for the optimal recursion and the name for the update rule depends on (i) the
algorithm (LS, PLR, PEM, etc.) and (ii) the model structure (ARX, ARMAX, etc.) that is being
used in estimating the parameter vector θ.
i. R(W)LS: Recursive (Weighted) Least Squares methods give rise to simple and intuitive expres-
sions for K[N]. The weighted versions are generally implemented with a forgetting factor for
the weights.

Advanced Topics in SISO Identiﬁcation
761
ii. RPLR: This is the recursive version of pseudo-linear regression algorithms.
iii. RIV: This recursive algorithm for IV method also has a simple form due to its similarity to the
IV and LS estimators.
iv. RPEM: The exact expression for the recursive version of prediction-error methods depends on
the model structure, but a general form can be provided.
The following sections present the development of the above algorithms with greater attention on
the R(W)LS algorithm due to its wide applicability.
25.1.3
RECURSIVE WEIGHTED LEAST SQUARES
We shall ﬁrst derive the recursive ordinary least squares.
Begin with the expression for the estimate using (N + 1) samples
ˆθ[N] = (ΦT[N]Φ[N])−1Φ[N]Ty[N]
(25.18)
Then, observe as in Example 25.1,
Φ[N] =
" ΦN
ϕT[N]
#
(25.19)
=⇒ΦT[N]Φ[N] = ΦT[N −1]Φ[N −1] + ϕ[N]ϕT[N]
(25.20)
ΦT[N]y[N] = ΦT[N −1]y[N] + ϕ[N]y[N]
(25.21)
At this point it is convenient to introduce,
R[N] ≜ΦT[N]Φ[N];
P[N] ≜R−1[N]
(25.22)
Now
ˆθ[N] = R−1[N](ΦT[N −1]y[N −1] + ϕT[N]y[N])
(25.23)
which can be further developed as
ˆθ[N] = R−1[N](R[N −1] ˆθ[N −1] + ϕ[N]y[N])
= R−1[N](R[N] ˆθ[N −1] −ϕ[N]ϕT[N] ˆθ[N −1] + ϕ[N]y[N])
= ˆθ[N −1] + R−1[N]ϕ[N](y[N] −ϕT[N] ˆθ[N −1])
Thus, we have the recursion,
ε[N] = y[N] −ˆy[N| ˆθ[N −1]]
ˆθ[N] = ˆθ[N −1] + R−1[N]ϕ[N]ϵ[N]
R[N] = R[N −1] + ϕ[N]ϕT[N]
(25.24a)
(25.24b)
(25.24c)
Avoiding the matrix inversion
The computation of inverse of R[N] can lead to numerical inaccuracies in the update equations. It
can be avoided by using the matrix inversion lemma
[A + BCD]−1 = A−1 −A−1B(DA−1B + C−1)−1DA−1
Since we need to invert
R[N] = ΦT[N −1]Φ[N −1] + ϕ[N]ϕT[N]

762
Principles of System Identiﬁcation: Theory and Practice
we set
A ≡R[N]; B ≡ϕ[N] = DT; C = 1
to obtain the update equations in a numerically eﬃcient form
ˆθ[N] = ˆθ[N −1] + K[N]ϵ[N]
K[N] =
P[N −1]ϕ[N]
1 + ϕT[N]P[N −1]ϕ[N]
P[N] = P[N −1] −P[N −1]ϕ[N]ϕT[N]P[N −1]
1 + ϕT[N]P[N −1]ϕ[N]
(25.25a)
(25.25b)
(25.25c)
The reader may verify that the simple recursive update rule for the estimation of mean in Example
23.3 can be derived using the RLS algorithm above.
Recursive WLS algorithm with a forgetting factor
The recursive OLS method can now be modiﬁed to include a forgetting factor, which gives more
importance to newer samples. The associated WLS formulation is
min
θ
N−1
X
k=0
λN−1−k (y[k] −ϕT[k]θ)2
(25.26)
where λN−1−k is the forgetting factor. Observe that the most recent sample is given the maximum
importance.
The solution is obtained using the standard WLS estimator studied in §14.3.5 by setting W =
diag(λN−i), i = 1,· · · , N. The recursive update for the resulting estimate can then be derived as
ˆθ[N] = ˆθ[N −1] + K[N]ϵ[N]
K[N] =
P[N −1]ϕ[N]
λ + ϕT[N]P[N −1]ϕ[N]
P[N] = 1
λ
"
P[N −1] −P[N −1]ϕ[N]ϕT[N]P[N −1]
λ + ϕT[N]P[N −1]ϕ[N]
#
=

I −K[N]ϕT[N]
 P[N −1]
λ
(25.27a)
(25.27b)
(25.27c)
Inﬂuence and choice of forgetting factor
The value of λ not only determines essentially the importance given to recent measurements, but
more importantly inﬂuences the variance of the resulting parameter estimates. If λ is close to unity,
more observations participate in the estimation problem and hence one can expect parameter esti-
mates with lower variance. This is because λ = 1, an increasing number of observations participate
with the passage of time, thus there is more averaging involved in ˆθ. As k →∞, the matrix R[k],
which inversely aﬀects the variance of ˆθ, grows to inﬁnity according to (25.24).
As λ is lowered, practically a ﬁnite number of measurements participate in producing ˆθ at each
instant. Therefore, the error in estimates remains ﬁnite at all times. However, the beneﬁt is that the
algorithm is able to adapt better to the system properties. Thus, the forgetting factor oﬀers a trade-
oﬀbetween the ability to track the changing properties of the system and the errors (inﬂuence of
noise) in ˆθ.
There exist diﬀerent ways of choosing an “appropriate” value of λ depending on the system
properties and the desired level of adaptability to noise characteristics. Three popular methods are
discussed brieﬂy:

Advanced Topics in SISO Identiﬁcation
763
i. Constant exponential forgetting factor: Choose a ﬁxed value of λ in the range 0.95 < λ < 0.995.
This strategy is suitable for slowly varying systems and when the input has persistent excitation.
The latter condition is required to ensure that there are no accumulation of noise eﬀects with
time (also known as covariance windup; see Stenlund and Gustafsson (2002) and the references
therein).
ii. A simple guideline for choosing λ is that it is dependent on the rate at which the system properties
change or parameter variations occur. Choosing a value of λ amounts to roughly assuming the
system’s characteristics to remain invariant over a time period T0, known as the memory length.
With this interpretation, λ can be chosen such that 1/(1 −λ) is the ratio between time constants
of process dynamics and those of the time-constant dynamics; see Ljung (1999).
iii. Use a variable or adaptive forgetting factor based on the levels of excitation and measurement
noise. The value of λ can also be based on detection of changes in the output, which suit abruptly
changing systems. See Fortesque, Kershenbaum and Ydstie (1981), Hagglund (1985), and Sri-
pada and Fisher (1987). An alternative is the vector-type forgetting, i.e., to choose diﬀerent for-
getting factors for each parameter because parameters may have signiﬁcantly diﬀering time-
scales of variations (Saelid, Egeland and Foss, 1985; Saelid and Foss, 1983).
For a good account of this topic, read Kulhavy and Zarrop (1993).
The recursive approach can be even used for computing LS estimates for LTI systems to determine
the minimum number of observations for the parameter estimates to converge. For this purpose,
initialize P[k0] = P0 (an invertible positive semi-deﬁnite matrix) and θ[k0] = 0. Typically, P0 =
αI, α >> 1 (high error in initial guess).
An example below illustrates the recursive ARX or the RLS algorithm.
Example 25.2: Time-Varying Model Identiﬁcation Using RARX
Consider the following time-varying ARX system
y[k] =
b2,0[k]q−2
1 + a1,0[k]q−1 + a2,0[k]q−2 u[k] +
1
1 + a1,0[k]q−1 + a2,0[k]q−2 e[k]
(25.28)
where the parameters jointly vary as follows:
{a1,0[k],a2,0[k],b2,0[k]} =

{−0.9,0.2,2},
0 ≤k ≤N1
{−1.1,0.35,2.5},
N1 < k ≤N2
{−0.9,0.2,2}
N2 < k ≤N −1
(25.29)
with N1 = 715, N2 = 1533, N = 2044 and e[k] ∼GWN(0,σ2e = 0.1).
The RWLS algorithm given by (25.27) is implemented on the data to estimate the time-
varying parameters using the rarx routine in MATLAB’s System Identiﬁcation toolbox. Two
diﬀerent values of forgetting factor, λ = 0.95,0.99 are chosen to illustrate its inﬂuence on the
convergence of estimates. The algorithm is initialized with 0 = 0, P[0] = 104I. Parameter
estimates corresponding to the two diﬀerent forgetting factors are shown in Figures 25.2(a)
and 25.2(b), respectively.
The inﬂuence of the forgetting factors on the parameter estimates is clear. The closer the
value of λ to unity, the smoother the estimates are (lower variability), but the larger the time
taken to track the parameters.
Note that the time axis on the plots begins from k = 25 for improved visualization.
Listing 25.1
MATLAB script for Example 25.2
%% Data generation
% DGPs

764
Principles of System Identiﬁcation: Theory and Practice
500
1000
1500
2000
1
2
3
Time
θ3
500
1000
1500
2000
−0.5
0
0.5
Time
θ2
500
1000
1500
2000
−1.5
−1
−0.5
Time
θ1
 
 
Estimated
True
(a) Parameter estimates with λ = 0.95
500
1000
1500
2000
1
2
3
Time
θ3
500
1000
1500
2000
−0.5
0
0.5
Time
θ2
500
1000
1500
2000
−1.5
−1
−0.5
Time
θ1
 
 
Estimated
True
(b) Parameter estimates with λ = 0.99
FIGURE 25.2
Time-varying identiﬁcation of the system in Example 25.2.
Gp1 = idpoly([1 -0.9 0.2],2,1,1,1,’Ts’,1,’nk’,2,’Noisevariance’,0.1);
Gp2 = idpoly([1 -1.2 0.35],2.5,1,1,1,’Ts’,1,’nk’,2,’Noisevariance’,0.1);
% Input
uk = idinput(2044,’prbs’,[0 1/4],[-1 1]); N = length(uk);
N1 = round(0.35*N); N2 = round(0.4*N); N3 = N-N1-N2;
% Simulation
yk1 = sim(Gp1,uk(1:N1),simOptions(’AddNoise’,true));
yk2 = sim(Gp2,uk(N1+1:N1+N2),simOptions(’AddNoise’,true));
yk3 = sim(Gp1,uk(N1+N2+1:end),simOptions(’AddNoise’,true));
yk = [yk1 ; yk2 ; yk3];
%% Data collection and preliminary analysis
Z = iddata(yk,uk,1); plot(Z)
%% Recursive estimation
lambda = 0.95;
[th_vec,noisevar] = rarx(Z,[2 1 2],’ff’,lambda);
a1vec = Gp1.a(2:end); b1vec = Gp1.b(Gp1.nk+1:end);
a2vec = Gp2.a(2:end); b2vec = Gp2.b(Gp2.nk+1:end);
th0_1 = [a1vec b1vec]; th0_2 = [a2vec b2vec];
th0_vec = [repmat(th0_1,N1,1) ; repmat(th0_2,N2,1) ; repmat(th0_1,N3,1)];
% Plot the parameter estimates
figure
for i = 1:3,
subplot(3,1,i)
plot((0:N-1),th_vec(:,i),’b-’,(0:N-1),th0_vec(:,i),’r--’)
xlabel(’Time’); ylabel([’\theta_’ num2str(i)]);
T0 = 25; set(gca,’Xlim’,[T0 N-1]);
end
25.1.4
RECURSIVE PEM ALGORITHM
The RLS idea can be extended to all other algorithms and model structures. Thus, one can conceive
of recursive MLE, IV and prediction-error methods.
• RLS and RIV algorithms produce the same estimates as those from oﬀ-line methods that use the
full data, because there are no approximations involved in deriving the recursive rules.
• RPEM, RMLE and RPLR methods on the other hand involve some approximations. Therefore
they do not necessarily result in the same estimates as their oﬀ-line versions.
• Asymptotic properties (error variance, distributions, etc.) of all recursive estimators under some
conditions coincide, however, with their corresponding versions.

Advanced Topics in SISO Identiﬁcation
765
We shall only outline the basic ideas for the RPEM algorithm and directly provide the expressions
(other recursions, except RIV, can be derived as special cases) and refer the reader to Ljung (1999)
and Young (2011) which discuss the above-mentioned recursive algorithms in detail.
The basic ideas for recursive PEM algorithm stem from the iteration used in solving the non-linear
objective function (21.6b) for parameter estimation.
V (θ,ZN ) = γ[N]1
2
N−1
X
k=0
w[k, N]ε2(k,θ)
(25.30)
where w[k, N] = λN−k−1 is the weight in terms of the forgetting factor and γ[N] is a weight
normalization s.t. γ[N] PN−1
k=0 w[k, N] = 1.
At each iteration of the PEM estimation using the Gauss-Newton algorithm in (21.15), the param-
eter udpate at k = N −1 based on N observations, Z[N −1] has the form:
ˆθ(i+1)[N −1] = ˆθ(i)[N −1] −µi[R(i)
N ]−1V ′( ˆθ(i−1)[N −1],Z[N −1])
(25.31)
where R(i)
N is the covariance of predictor gradients ψ(k,θ) =
d
dθ ˆy(k,θ), and V ′( ˆθ(i−1)[N−1],Z[N−
1]) is the gradient of the objective function as deﬁned in (21.15). The key idea for developing the
recursive form is to apply the iterative update across two successive times:
ˆθ[N] = ˆθ[N −1] −µN+1R−1
N+1V ′( ˆθ[N −1],Z[N])
(25.32)
where the numerical iteration index has been dropped and the time recursion has been retained. The
covariance matrix RN = 1
N
PN−1
k=0 ψ(k,θ)ψT (k,θ) can be updated in the same manner as in RWLS.
An approximate update expression for the gradient assuming that the optimum has been reached at
k = N −1 can be derived as (Ljung, 1999),
V ′( ˆθ[N −1],Z[N]) = −γ[N]ψ(N, ˆθ[N −1])ε(k, ˆθ[N −1])
(25.33)
It is diﬃcult to derive a recursive expression for the predictor gradients. Therefore, they have to be
evaluated at each step.
Setting µ = 1 and introducing R[N] = RN+1, we have the RPEM algorithm
ε[N] = y[N] −ˆy[N| ˆθ[N −1]]
ˆθ[N] = ˆθ[N −1] + γ[N]R−1[N]ψ[N]ε[N]
R[N] = R[N −1] + γ[N](ψ[N]ψT[N] −R[N −1])
(25.34a)
(25.34b)
(25.34c)
where ψ[N] = ψ(N, ˆθ[N −1]). Observe from above that the update rule is in the form
△θ = K[N]ε[N],
where K[N] = Q[N]ψ[N]
(Kalman gain)
(25.35)
The gradient expressions depend on the type of model in use and the RPEM algorithm specializes
to the recursive versions for those models. For instance, with an ARX model, the RPEM estimator
simpliﬁes to the RWLS algorithm (25.27) with the normalization γ included. The covariance matrix
R[N] for RPEM is initialized in a suitable manner as in the RWLS algorithm.
In closing, it must be mentioned that a diﬀerent choice of γ leads to the well-known least mean
square (LMS) algorithm in adaptive control due to Widrow-Hoﬀ(Widrow and Hoﬀ, 1960; Widrow
and Stearns, 1985).

766
Principles of System Identiﬁcation: Theory and Practice
25.1.5
WAVELET-BASED APPROACHES
One of the widely used and successful modern approaches is based on what are known as wavelet
transforms. A brief introduction to wavelets and wavelet transforms is given below. Ideas behind
their application to identiﬁcation of time-varying system are explained in the ensuing section.
The wavelet transform is perhaps the most versatile tool used today in signal processing next
to the Fourier transform. The concept itself has originated in diﬀerent ﬁelds, namely, physics, sig-
nal processing (engineering) and mathematics almost contemporaneously for the purposes of time-
frequency (T-F) analysis, multirate ﬁltering and multiscale approximations, respectively. In addition
there also exists a statistical treatment of this subject. As a result, what we study today of this topic
is a conﬂuence of all these diﬀerent oceans, so to speak. This also implies that wavelet and the trans-
form can be introduced in a number of diﬀerent ways, namely, as a tool for time-frequency analysis,
multirate ﬁlter bank, approximation theory and as a correlation analysis tool. There exist numerous
texts (Addison, 2002; Cohen, 1994; Mallat, 1999; Percival and Walden, 2000) and articles on this
concept (see Tangirala, Mukhopadhyay and Tiwari (2013) for a tutorial review on wavelets in mod-
eling). We shall use a mix of time-frequency and signal processing perspective since that is perhaps
best suited for a system identiﬁcation audience.
The basic motivation for wavelet transforms comes from the need for analysis of signals that
have time-varying frequency characteristics, typically in amplitude and/or frequency. Both of these
changes manifest as time-varying spectral densities. These non-stationary signals are produced by
what are known as multiscale systems, of which time-varying systems are a sub-class. Any system
that is characterized by phenomena occurring at diﬀerent time- (or spatial) scales is a multiscale
system. Examples include a fuel cell system, atmospheric process, processes with widely varying
time-constants, etc. In order to capture the local behavior of a signal in time and frequency, we need
a basis function that has these properties. The Fourier representation (and the transform) explains the
signals in terms of sinusoids that are perfectly localized in frequency (a sine wave is represented by
a spike on the frequency axis) but spread over the entire time axis. In other words, the Fourier basis
does not have a compact support in time, but an ideally localized support in frequency. Consequently
it is able to localize the energy / power of a signal perfectly in frequency but not its local temporal
features.
Wavelets on the other hand are designed to have compact support in both time and frequency,
thereby giving them the ability to represent the signal in the two-dimensional T-F plane. Conse-
quently, wavelets are equipped to model the time-varying systems just as the way Fourier trans-
forms are used in deﬁning FRFs for LTI systems. Extending this further, wavelet transforms also
facilitate computation of energy / power “spectral” densities in the T-F plane. An important limi-
tation, though, is that both the wavelet-based models and energy density computations can only be
constructed within a cell and not at a point in the T-F plane. This is because wavelets do not have
perfectly localized support in either of the time- and frequency-axis2.
Strictly speaking wavelet transforms work in the time-scale plane. The term scale in wavelet anal-
ysis can be understood as synonymous to resolution, as in a geographical map, while localization
implies extracting the features in a time-frequency cell. When a map is drawn to a high scale, fewer
details (or only an approximation) are available. Thus, the frequency of highlighted points on the
map decreases. The converse holds for maps at smaller scale. For all interpretation purposes, and
in some instances of wavelet transforms on exact terms as well, the scale can be understood as the
inverse of frequency (Torrence and Compo, 1998).
In understanding the introductory material below, it is useful to remember the following.
2This fact is governed by the popular duration-bandwidth principle in signal processing, which is otherwise infamously
known as the uncertainty principle for signals. See Cohen (1994) for a good presentation of this topic.

Advanced Topics in SISO Identiﬁcation
767
All transforms are ﬁltering operations, which in turn are correlations and projections. The un-
derlying mathematics is essentially the same, only the terminology and the interpretations vary
with the context. Further, low-pass ﬁltered signals are approximations, while high-pass ﬁltered
signals are details.
25.1.5.1
Wavelet Transforms
There exist several diﬀerent wavelet transforms in the literature, each with its own set of niche
applications. However, it is useful to know that there is only one original wavelet transform, namely,
the continuous wavelet transform (CWT) while the rest are merely its variants.
Continuous wavelet transform
The CWT of a function or a signal x(t) is deﬁned as (Grossmann and Morlet, 1984; Jaﬀard, Meyer
and Ryan, 2001; Mallat, 1999),
W x(τ,s) = ⟨x,ψτ,s⟩
||ψτ,s||2
2
=
Z +∞
−∞
x(t)ψ∗
τ,s(t)dt
(25.36)
It is essentially the coeﬃcient of projection onto the wavelet ψτ,s, which is generated by the scaling
and translation of a mother wave ψ(t),
ψτ,s =
1
√|s|
ψ
t −τ
s

,
τ, s ∈R s , 0
(25.37)
where the mother wave itself should satisfy a zero-average and unity-norm requirement.
Z ∞
−∞
ψ(t) dt = 0 = ˆψ(ω)|ω=0
||ψ(t)||2 = 1
(25.38)
The name wavelet for ψτ,s is now clearer.
Figure 25.3 shows some of the commonly used wavelets. There exist many types of wavelets -
real-valued, complex-valued, (bi)-orthogonal, non-orthogonal, etc. Within a class, one could have
wavelets with diﬀerent characteristics, i.e., mathematical properties. Note that some wavelets have
closed-form expressions, while others are only tabulated in terms of their ﬁlter coeﬃcients. The Haar
wavelet (Haar, 1910), which has a discontinuity, was among the ﬁrst one to be conceived. The Mor-
let wavelet3 is complex-valued and suitable for feature extraction using CWTs while Daubechies
wavelets, which are continuous, real-valued and have compact support are widely used in signal de-
noising and compression using discrete wavelet transform (to be deﬁned shortly) among the most
widely used ones. In general, the choice of a particular wavelet is usually driven by the application.
See Gao and Yan (2010) and Mallat (1999) for an extensive treatment of this topic.
Remarks:
i. The CWT can also be viewed as a correlation between x(t) and the wavelet dilated to a scale factor s but
centered at τ.
ii. Evaluating the CWT in(25.36) across a range of τ and s amounts to analyzing the signal by lenses of
diﬀerent magnifying properties and traversing along the length of the signal. The parameter s determines
the width while τ controls the location of each lens.
3The Morlet wavelet does not have compact support, meaning does not decay in ﬁnite time and therefore does not satisfy
the admissibility condition. Thus, it is not a wavelet in the strictest sense.

768
Principles of System Identiﬁcation: Theory and Practice
0
0.5
1
−2
0
2
Haar
t
ψ(t)
−5
0
5
−1
0
1
Mexican Hat
t
ψ(t)
−5
0
5
−1
0
1
Real part of Morlet
t
ψ(t)
0
5
−2
0
2
Daubechies (db4)
t
ψ(t)
0
5
−2
0
2
Symmlet (sym4)
t
ψ(t)
−5
0
5
−2
0
2
Meyer
t
ψ(t)
FIGURE 25.3
Diﬀerent wavelet functions possessing diﬀerent properties.
iii. Computation of CWT is eﬃciently carried out in the frequency domain (Addison, 2002; Gao and Yan,
2010; Torrence and Compo, 1998)
F[Wx (τ,s)] = √sX(ω) ˆψ⋆(sω)
(25.39)
=⇒Wx (τ,s) = 1
2π
Z ∞
−∞
√sX(ω) ˆψ⋆(sω)ejωτ dω
(25.40)
In practice, a discrete version of the above is implemented over a user-deﬁned grid of scales and translations.
The minimum scale and translation are governed by the sampling time used in acquiring data.
iv. As in FT, the original signal x(t) can be restored perfectly using,
x(t) = 1
Cψ
Z ∞
0
Z +∞
−∞
W x(τ,s)ψτ,s
1
s2 dsdτ = 1
Cψ
Z ∞
0
W x(.,s) ⋆ψs(t) ds
s2
(25.41)
if and only if the condition on admissibility constant
Cψ =
Z ∞
0
ˆψ∗(ω) ˆψ(ω)
ω
dω < ∞
(25.42)
is satisﬁed. This is guaranteed as long as the zero-average condition (25.38) is satisﬁed.
In (25.41), the star ⋆denotes convolution.
v. Parseval’s relation: Energy is conserved according to
Z ∞
−∞
|x(t)|2 dt = 1
Cψ
Z ∞
0
Z ∞
−∞
|W x(τ,s)|2dτ ds
s2
(25.43)
This relation is used to construct what are known as scalograms, which are energy density functions due to
CWT in the time-scale plane, in a manner analogous to energy spectral density due to FT. Read Addison
(2002), Mallat (1999), and Torrence and Compo (1998) for further details.
Figures 25.4(a) and 25.4(b) display the (normalized) scalogram4 of a synthetic signal consisting
of a sine wave corrupted by an impulse and an industrial control loop measurement, respectively. A
Morlet mother wave with center frequency ω0 = 6 is used for this purpose. The time-series for each
of these signals are shown on the top panel of the respective ﬁgures. Spectral plots shown on the left
panel of each of these ﬁgures display only the frequency content, but cannot capture the duration of
their existence.
4The CWT and scalograms for this example are computed using the wavelet coherence toolbox (Grinsted, Moore and
Jevrejeva, 2002).

Advanced Topics in SISO Identiﬁcation
769
(a) Sine wave corrupted by an impulse
(b) Industrial control loop measurement
FIGURE 25.4
(SEE COLOR INSERT) Normalized scalograms of two diﬀerent signals.
In contrast, the scalogram clearly brings out in each case the time- and frequency-localized fea-
tures of the spectral density. The ﬁrst signal contains two components, a sine wave with highly
frequency-localized energy and an impulse characterized by a full frequency spread, but a highly
time-localized energy density. Both these features are nicely captured by the scalogram. In the sec-
ond case, the scalogram reveals that the control loop measurement contains oscillations that are
intense, but present intermittently. These signatures, which are neither easily visible by a visual
inspection nor by spectral analysis, are useful in performance assessment of control loops.
In constructing these plots, the normalized scalogram deﬁned by
1
s P(τ,ω = ζ
s ) ≜1
s

W x(τ, ζ
s )

2
(25.44)
where the factor ζ is responsible for converting scale s to frequency ω, is used. For the chosen
Morlet wavelet, ζ ≈1. The cone-like region is known as the cone-of-inﬂuence (COI), outside of
which the values of scalogram can be at best trusted only subjectively due to ﬁnite-length eﬀects
and the widths of wavelets involved at those scales. An insightful and theoretical elaboration of the
COI can be found in Mallat (1999) and Torrence and Compo (1998).
Filtering perspective
The zero-mean constraint on the wavelet, from a ﬁltering perspective, amounts to requiring that the
corresponding ﬁlter is a band-pass ﬁlter. Further, scaling the wavelet amounts to shifting the center
frequency as well as the bandwidth of the wavelet ﬁlter. In eﬀect, computing the wavelet transform
for diﬀerent values of s amounts to passing the signal through a bank of band-pass ﬁlters. The
ﬁltering nature of CWT can also be realized by re-writing (25.36) as
W x(u,s) = x ⋆¯ψs(τ)
where ψs(t) =
1√sψ∗−t
s

(25.45)
where the ⋆denotes convolution as before.
The center frequency of the wavelet ﬁlter is determined by that of the mother wave and the scaling
parameter s, which also determines the compression or dilation of the mother wave. If s > 1, ψτ,s(t)
is in a dilated state, resulting in a wide window or equivalently a low-pass ﬁlter. On the other hand,
if 0 < s < 1, ψτ,s(t) is in a compressed state, producing narrow windows that are suitable for
analyzing the high-frequency components of the signal. Note that the terms low and high are only
relative to the center frequency of the mother wave.

770
Principles of System Identiﬁcation: Theory and Practice
Figure 25.5 illustrates the above facts on a Morlet wavelet with center frequency ω0 = 6 ≈2π. It
is useful to contrast the ﬁltering nature of wavelet basis with that of Fourier basis, which is an ideal
band-pass ﬁlter in frequency domain, however with zero time-localization.
Scale = 1
Scale = 2
Scale = 0.5
FIGURE 25.5
Scales s > 1 generate low (band)-pass ﬁlter wavelets while scales s < 1 generate high (band)-
pass ﬁlter wavelets. Generated for Morlet wavelet with center frequency ω0 = 6 rad/sec.
Scaling function
The wavelet ﬁlters span the entire frequency range as s runs from ∞to 0, but then inﬁnite ﬁlters are
required. Fixing s = 1 as a reference point, the band-pass ﬁlters corresponding to s > 1, i.e., the
low-frequency range including ω = 0 are replaced by a single low-pass ﬁlter, which is equivalent to
introducing a scaling function φ(t) (Mallat, 1999) such that
| ˆφ(ω)|2 =
Z ∞
1
| ˆψ(sω)|2 ds
s =
Z ∞
ω
| ˆψ(ξ)|2
ξ
dξ
(25.46)
From the admissibility condition (25.42),
lim
ω→0 | ˆφ(ω)|2 = Cψ
(25.47)
suggesting that φ(ω) is a candidate FRF of a low-pass ﬁlter.
With the introduction of the scaling function, we can (i) deﬁne a transform similar to (25.36)
Lx(τ,s) = ⟨x(t),φτ,s(t)⟩= x ⋆¯φs(τ)
(25.48)
and (ii) re-write the signal representation (25.41) , in general, as a sum of an approximation and
details at scale s0:
x(t) =
1
Cψs0
Lx(.,s) ⋆φs0(t)
|                      {z                      }
Approximation at scale s0
+ 1
Cψ
Z s0
0
W x(.,s) ⋆ψs(t) ds
s2
|                               {z                               }
Details missed out by the approximation
(25.49)

Advanced Topics in SISO Identiﬁcation
771
Thus, wavelets facilitate the decomposition of a signal into its low-pass and high-pass ﬁltered com-
ponents.
Discrete Wavelet Transform
The CWT evaluated on an arbitrarily and ﬁnely spaced grid results in a highly redundant represen-
tation of the signal, i.e., more wavelet coeﬃcients than necessary. Several applications require com-
pact (minimal) representations of signals for storage and computational reasons, which are achieved
by ensuring orthogonality within the family of wavelets generated at diﬀerent values of s and τ. The
key idea is to restrict the scales to octaves (powers of 2) and translations proportional to the length
of the wavelet at each scale. Thus, the discrete wavelet transform (DWT) is born.
The DWT is the CWT (25.36) evaluated at speciﬁc scales and translations, s = 2j, j ∈Z and
τ = m2j, m ∈Z.
W f (m, j) =
Z +∞
−∞
f (t)ψ∗
m2j,2j (t)dt
(25.50)
where
ψm2j,2j (t) =
1
2j/2 ψ
 t −m2j
2j
!
(25.51)
The theoretical support for DWT is provided by the frame theory (Daubechies, 1992; Duﬃn and
Schaeﬀer, 1952).
It is reiterated that DWT is not a new transform in itself - it is merely a CWT evaluated at speciﬁc
points in the translation-scale space. However, the resulting family of wavelets with a unity-norm
normalization of the wavelets, i.e., ||ψm, j ||2 = 1 constitutes an orthonormal basis for R2 space,
giving also the compactness to signal representations.
The signal decomposition in (25.49) using CWT naturally applies to the DWT as well
x(t) =
X
m
am, j0φm, j0(t) +
X
j ≥j0
X
m
dm, j0ψm, j (t) = AJ0 +
J0
X
j=1
Dj
(25.52)
where {am, j0} are the approximation coeﬃcients at the scale j0 and {dm, j0},
j = 1,· · · , j0 are the
detail coeﬃcients at that level j0 (scale s = 2j0) and all ﬁner scales. The quantities Aj0 and DJ0 are
approximations and detail components of the signals x(.) at the level J0.
The coeﬃcients themselves are computed using projections on to the respective bases,
aj[m] ≜am, j = ⟨x,φm, j⟩;
d j[m] ≜dm, j = ⟨x,ψm, j⟩
(25.53)
where ⟨,⟩denotes inner product. In practice, these coeﬃcients are computed using the corresponding
low- and high-pass ﬁlters, with impulse responses {gl[.]} and {gh[.]}, respectively. This will be
explained shortly.
The most important outcome of the signal decomposition using DWT is the fact that the ap-
proximation and the details at a given scale can be computed solely from the approximation at the
immediately ﬁner scale using the same low-pass and high-pass ﬁlters and a dyadic relation,
aj+1[m] =
∞
X
n=−∞
gl[n −2m]aj[n] = (aj ⋆¯gl)[2m]
d j+1[m] =
∞
X
n=−∞
gh[n −2m]aj[n] = (d j ⋆¯gh)[2m]
(25.54a)
(25.54b)
where ¯gl[n] = g[−n] (likewise for ¯gh[.]) is the reﬂection of the IR sequence and ⋆denotes convo-
lution.

772
Principles of System Identiﬁcation: Theory and Practice
FIGURE 25.6
Fast pyramidal algorithm for orthogonal wavelet decomposition (analysis).
FIGURE 25.7
Fast algorithm for reconstruction (synthesis) from decomposed sequences.
The coeﬃcients aj+1 and d j+1 at level j + 1 together provide a coarser representation of x(t)
relative to that at level j.
This process of obtaining nested approximations and details can be continued until the maximum
depth is achieved, which is governed by the length of the sequence.
Equation (25.54) is central to the world of multiresolution approximations (MRA), where the
approximations at two successive dyadic scales are related to each other through a scaling relation.
This is considered very attractive for computer vision, image processing and modeling multiscale
systems. A formal treatment of MRA is found in several texts, see Jaﬀard, Meyer and Ryan (2001)
and Mallat (1999) for instance.
Computation of DWT
The MRA in (25.54) lends itself to a very elegant and a computationally eﬃcient algorithm (similar
to that of FFT) for computing the DWT at all scales (Mallat, 1989). This was one of the most im-
portant breakthroughs in numerical implementations of wavelet transforms. Starting with the given
sampled-data sequence x[k] (considered to be at the ﬁnest scale), its full-scale decomposition gov-
erned by (25.54) is obtained from a repeated convolution followed by downsampling operations as
shown in Figure 25.6. The downsampling by a factor of 2 is due to the shifts proportional to dyadic
scales in the convolution of (25.54). It is not necessary to always perform a full-scale decomposition
- one could halt it at any desired scale. The maximum possible decomposition is governed by the
sequence length N.
Reconstruction
Reconstruction of x(.) from its approximation and detail coeﬃcients is done in an almost reversed
manner of decomposition. Downsampling is replaced by upsampling and decomposition ﬁlters by
reconstruction ﬁlters ˜gl[.] and ˜gh[.], respectively, At each stage, the reconstruction is governed by

Advanced Topics in SISO Identiﬁcation
773
0
50
100
150
200
250
−10
0
10
d1
Time instants
0
50
100
150
200
250
−20
−100
10
d2
0
50
100
150
200
−20
0
20
d3
0
50
100
150
200
−50
0
50
a3
0
50
100
150
200
250
0
20
40
Plot of original signal and wavelet coefficients
Signal
(a) Wavelet decomposition
50
100
150
200
250
−10
0
10
D1
Samples
50
100
150
200
250
−10
0
10
20
D2
50
100
150
200
250
−10
0
10
D3
50
100
150
200
250
−20
0
20
A3
50
100
150
200
250
0
20
40
Plot of original signal and the filtered components
Signal
(b) Wavelet reconstruction
FIGURE 25.8
Wavelet decomposition and reconstructions of the respective bands for the piecewise regular
polynomial signal of Mallat (1999).
aj[k] =
∞
X
n=−∞
˜gl[k −2n]aj+1[n] +
∞
X
n=−∞
˜gh[k −2n]d j+1[n]
= ˇaj+1 ⋆˜gl[p] + ˇd j+1 ⋆˜gh[p],
j = Jmax −1,· · · ,0
(25.55)
where ˇaj+1 and ˇd j+1 are the upsampled sequences obtained by inserting zeros at alternate locations
in ˇaj and ˇd j, respectively, as depicted in Figure 25.7].
For exact recovery of signal, the reconstruction ﬁlters are related to those of decomposition and
have to satisfy the conditions of perfect reconstruction (Vaidyanathan, 1987). Additionally, impos-
ing the orthogonality of DWT results in the following synthesis ﬁlters
˜gl[.] = gl[.],
˜gh[.] = gh[.]
(25.56)
Filters with these properties are known as conjugate mirror ﬁlters (Mallat, 1999).
The discrete wavelet transform is perhaps best understood by an example.
Example 25.3: DWT of a Piecewise Regular Polynomial
A 3-level wavelet decomposition, reconstruction and MRA of a 256-sample long piecewise
regular polynomial signal of Mallat (1999) using boundary corrected Daubechies ﬁlter of
length 4 (IR coeﬃcients) is carried out.
The time proﬁle of this signal is shown in the top panel of Figure 25.8(a). The remaining
panels show in that order the approximation coeﬃcients a3 of length 32 and the detail co-
eﬃcients d3, d2 and d1 of lengths 32, 64 and 128, respectively. Recall that d3 contains the
details not contained in a3 at the scale s = 23 = 8. As one progresses down the levels, the time
resolution falls oﬀby a factor of 2 but the frequency resolution improves by the same factor.
Therefore, the coeﬃcient set d3 corresponds to the highest half-frequency band, whereas a3
corresponds to the lowest one-eighth frequency band. The magnitude of the coeﬃcient at
that level is a measure of the energy present in that frequency band at that time instant.
Figure 25.8(b) shows the reconstructed components of the signal in the respective frequency
bands. For instance, the lowest frequency component A3 corresponding to a3 is obtained by
ﬁrst setting all di, i = 1,· · · ,3 to zero and implementing the reconstruction algorithm of
Figure 25.7. The same procedure is applied to obtain D1 to D3. Notice that A3 contains
the approximate features of the signal while D1 to D3 contain features corresponding to
discontinuities and other near abrupt changes.

774
Principles of System Identiﬁcation: Theory and Practice
The WAVELAB software (Department of Statistics, 2000) was used to generate the signals
and compute the necessary discrete wavelet transforms in this example.
Signal estimation: In the reconstruction process, the diﬀerent components of x(.) obtained
from decomposition can be selectively or partially or fully used to reconstruct the corresponding
frequency-band components or partial or full signal, respectively. The decision on which compo-
nents to retain / discard depends on a statistically determined threshold, which could be scale-
speciﬁc or a global one. This facilitates highly ﬂexible and powerful ways of cleaning or de-noising
the signal. Several excellent methods for signal estimation have been formulated based on this idea
(see Cai and Harrington (1998), Donoho and Johnstone (1994), and Percival and Walden (2000)).
Consistent estimation is a powerful and relatively new strategy based on the idea of requiring that
the signal and its estimate should have the same wavelet representation (Cvetkovic and Vetterli,
1995; Thao and Vetterli, 1994).
Another highly useful property of DWT is that most of the energy in the signal can be packed into
much fewer numbers of wavelet coeﬃcients. This is the basis for compression.
The design of wavelets is synonymous with the design of wavelet ﬁlters wherein the properties
of the corresponding scaling and wavelet functions such as orthogonality, compact support, regu-
larity of wavelets, etc. are translated to appropriate properties on the low-pass and high-pass ﬁlters,
respectively.
For further technical and historical details, the reader is referred to the rich literature on this topic
(Mallat, 1999).
Shift-invariant wavelet transforms
When the restrictions on translations alone are relaxed, a dyadic wavelet transform is generated,
which once again presents a complete and stable, but a redundant representation. However, a main
advantage of this transform is that it is invariant to temporal shifts of features in the signal, thereby
giving it the name shift-invariant transform. Alternative names are also popular - maximal overlap
DWT, stationary WT, undecimated WT and so on. The translation-invariance (to signal features) is a
highly desirable feature in signal de-noising and pattern recognition (see Percival and Walden (2000)
for an extensive set of applications of MODWT). A recent method (Tangirala, Mukhopadhyay and
Tiwari, 2013) for modeling linear time-varying systems using wavelets is based on this undecimated
transform.
25.1.5.2
Identiﬁcation of LTV Systems Using Wavelets
Several diﬀerent paradigms and approaches have been proposed for modeling multiscale systems in
the wavelet framework (Tangirala, Mukhopadhyay and Tiwari, 2013). With respect to identiﬁcation
of linear time-varying systems, one ﬁnds eﬀectively three broad approaches. These are discussed
below.
i. CWT-based approach: The basic model here is,
y[k] = G(q−1,θG,k)u[k] + v[k]
(25.57)
where G(q−1,θk) is the parametrized, locally invariant, time-varying deterministic model and
v[k] is a stationary stochastic disturbance that is not parametrized.
The invariance in G is now not local in time but instead in a local region of the time-scale plane,
determined by the support of the wavelet at that scale. This is more ﬂexible than the simple
locally time-invariant assumption because over a given time interval, the system can be still
time-varying (with invariance across frequency bands over that time interval). These ideas were
put forth by Shan and Burl (2011), who proposed to ﬁrst select these locally invariant regions

Advanced Topics in SISO Identiﬁcation
775
in the time-frequency plane using a metric based on the (time-scale) time-frequency response
(TFR), deﬁned as
TFR(τ,s) = W y(τ,s)
Wu(τ,s)
(25.58)
where W y(t,s) and Wu(t,s) are the CWTs of the output and input, respectively. Observe the
similarity of (25.58) with that of the FRF deﬁnition in (5.23).
Under the assumptions of white v[k] and using a Morlet wavelet, Shan and Burl (2011) develop
an algorithm for selecting scales that are most informative (w.r.t. parameters), compact (in rep-
resentation) and clean (high SNR). Under Gaussian white noise assumption, the estimated (or
“measured”) TFR in (25.58) can be written as
TFR(τ,si) = TFR(τ,si,θτ) + ϵi
(25.59)
where si refers to the ith scale in the grid of scales at which the TFR is being computed. The
parametrized TFR at a given time point τ is given by (Shan and Burl, 2011)
TFR(τ,s,θ(τ)) =
√siF−1[G(θτ, jω)U(jω)Ψ⋆(jsiω)]
√siF−1[U(jω)Ψ⋆(jsiω)]
(25.60)
where F−1 is the inverse Fourier transform and Ψ(jω) = F(ψ(t)) is the Fourier transform of the
(Morlet) wavelet.
The parameters at each time-point are then estimated by the standard sum squares error mini-
mization approach.
ˆθτ
⋆= min
θτ
X
i∈S
ϵ2
i (si,τ,θτ)
(25.61)
where S is the set of selected scales according to a metric.
For diﬀerent choices of metrics and their impact on the resulting parameter estimates along with
a few simulation studies, refer to Shan and Burl (2011).
ii. DWT-based approach: This is one of the most popularly followed approaches in the modeling of
LTV systems (Doroslovacki and Fan, 1996; Tsatsanis and Giannakis, 1993); the idea herein is
to express the time-varying coeﬃcients of the diﬀerence equation model in terms of the wavelet
basis functions of the DWT family. We shall only summarize the approach of Tsatsanis and
Giannakis (1993), where the stochastic model is also allowed to be time-varying in the diﬀerence
equation model
y[k] = −
P
X
n=1
an[k]y[k −n] +
M
X
l=0
bn[k]u[k −n] +
nc
X
p=1
cp[k]e[k −p] + e[k]
(25.62)
The coeﬃcients in each of the summation terms on the RHS are now expanded in terms of
the orthonormal basis arising in the DWT. Further, as in the previous method, a scale selection
procedure is adopted. The basic premise here is that once again the process is time-invariant in
a time-frequency region. Mathematically, the expansion of the regressive coeﬃcients has a form
similar to that of (25.52)5,
a[n,k] =
X
m
ζ ak
m,Jmax ¯g(Jmax)
l
[k −2Jmaxm] +
Jmax
X
j=Jmin
X
m
ξak
m, j ¯g(j)
h [k −2jm]
(25.63)
5The approximation coeﬃcients in (25.52) should not be notationally confused with the a’s of (25.62).

776
Principles of System Identiﬁcation: Theory and Practice
where ¯g j
l [.] and ¯g j
h[.] are the low-pass and high-pass ﬁlter coeﬃcients at the jth scale. The
parameters Jmax and Jmin are the maximum (coarsest) and minimum (ﬁnest) levels of scales
selected for identiﬁcation using one of the information-theoretic measures (e.g., AIC) discussed
in §22.6.3. In addition, an F-test is used to determine the number of regressors to be retained in
the model.
The key point to note here is that the identiﬁcation of time-varying parameters is translated
to the estimation of time-invariant coeﬃcients of expansion due to the local time-invariance
assumption. Parsimony of parameters is achieved by scale-selection and the F-test for regressor
selection. The coeﬃcients of expansion themselves are estimated by minimizing using a least
squares method on the linear regression model in (25.62).
iii. MODWT-based approach: Several modiﬁcations with respect to the DWT approach are intro-
duced. First, the DWT is replaced with MODWT giving it the shift-invariance property. Secondly,
the orthogonal family is replaced by the bi-orthogonal family (decomposition and reconstruction
ﬁlters are orthogonal to each other, but not within themselves) of wavelets. Further, the local
time-invariance assumption is relaxed and ﬁnally, the model parameters are estimated by solv-
ing a least squares problem in the wavelet space rather in the original measurement space. The
approach used for estimation in the wavelet space is based on what is known as consistent predic-
tion, where the predictions and the measurements are required to have the same representation in
the wavelet domain. For a complete description of this method and formalization of ideas, refer
to Tangirala, Mukhopadhyay and Tiwari (2013).
25.2
NON-LINEAR IDENTIFICATION
All real-life processes are non-linear in nature. Linear models have limited scope and many a times
fail to adequately capture the dynamics of non-linear processes. Nevertheless, the theory of linear
modeling provides us with good foundations and some useful models for non-linear identiﬁcation.
A natural generalization of the linear models that we have studied until now is to let the model be
an arbitrary non-linear function:
y[k] = g(ϕ[k],θ) + v[k]
(25.64)
where g(.) is a non-linear function and v[k] is a stochastic term. The regression vector as usual
consists of past outputs and inputs:
ϕ[k] =
f
y[k −1]
· · ·
y[k −ny]
u[k −1]
· · ·
u[k −nu]
gT
(25.65)
Remarks:
i. The regressor vector can also include just the past inputs - then (25.64) takes the form of non-linear FIR
(NFIR) models. The Volterra model paradigm belongs to this class.
ii. It is straightforward to incorporate pre-ﬁltering in (25.64) as was done in PEM models.
iii. The non-linearity can also prevail in the noise model. However, one of the popular class of models known
as NARX treat v[k] to be white (see §25.2.3).
iv. An interesting viewpoint of (25.64) is that the non-linear model is a static non-linear transformation of
a (linearly) ﬁltered input and output data. This perspective gives birth to the Wiener-Hammerstein model
paradigm. These models are discussed in §25.2.4.2.
v. When the function f (.) is expanded over some basis functions, then one obtains the popular network models.
Examples of these include the neural networks, wavelet network models, etc. See §25.2.1 below.
vi. A non-linear extension can be conceived for the linear state-space models as well (recall the SS description
(23.39) in the context of EKFs). These are also known as “internal dynamics” models as opposed to the
“external dynamics” nature of the input-output model in (25.64).

Advanced Topics in SISO Identiﬁcation
777
Non-linear least squares method as an estimator of the parameters in (25.64) was discussed at
length in §14.4. To highlight the main points therein, the main challenge in non-linear identiﬁcation,
is that no closed-form solution exists. Only numerical solvers have to be used. Therefore, one has
to be satisﬁed with local optima. The PEM algorithms of Chapter 21 are naturally equipped to
handle predictors arising from (25.64). Furthermore, the systematic procedure and the various steps
discussed in Chapter 22 also carry forward in a straightforward manner except for the fact that one
no longer necessarily works with deviation variables. Tests for goodness of model also applies to
the non-linear case; however, correlation may be replaced with mutual information since the former
only tests for linear dependencies. Two issues therefore that call for signiﬁcant attention are (i)
the class of functions g(ϕ[k],.θ) that are used to construct (25.64) and (ii) design of inputs for
identifying f (.) and θ. The latter problem is quite complicated and beyond the scope of this text.
We shall solely restrict ourselves, in this introductory section, on the former aspect.
Selecting a suitable non-linear mapping g(.) for a given process is much more diﬃcult than in
linear identiﬁcation simply because there are numerous types of non-linearities. Too rigorous a
choice of non-linearity can degrade its performance that is even worse than that of a linear model.
Finally, recursive identiﬁcation presents considerable diﬃculties.
Notwithstanding the foregoing challenges, tremendous inroads have been made in non-linear
identiﬁcation over the last four decades. Plenty of open-ended problems exist and the subject is
a continually growing area of research. In the sections below we brieﬂy describe the widely used
modeling paradigms in identiﬁcation of non-linear systems.
An excellent source of material on the subject of non-linear identiﬁcation is Nelles (2001). See
also Ljung (1999, Chapter 5) and Ikonen and Najim (2002, Chapters 4-5). The papers by Sjöberg
et al. (1995) and Kerschen et al. (2006) oﬀer good surveys of the topic.
Generalized basis functions and universal approximators
In principle there exist inﬁnite choices for the non-linear function g(.). The universal approximation
result provides existence of mathematical models that can approximate any non-linear system with
arbitrary accuracy (Cybenko, 1989; Funahashi, 1989; Hornik, Stinchcombe and White, 1990). Pop-
ular among these models are the generalized basis function networks, wherein the approximating
functions are of the form,
g(ϕ[k],β,θ) =
M
X
j=1
hj (ϕ[k],β) f j (ϕ[k],θ)
(25.66)
where f j (.) are the basis functions and the hj (.) are known as the weighting functions. The standard
practice is to only parametrize the basis functions while directly estimating the weights {hj}, i.e., the
parameters of interest are only θ. When the function f (.) is imagined as an input-output graphical
network with the regressors at input nodes, basis functions at the nodes of the intermediate layer
and the predicted output at the output node, the weighting functions characterize the links.
The basis functions gj (.) could be of any form that satisﬁes certain mild conditions necessary for
identiﬁcation. Cybenko (1989) established the result using sigmoid functions:
g(ϕ,βj,γj) =
1
1 + e−βT
j ϕ−γk
(25.67)
These functions are at the heart of what are known as sigmoid neural networks.
The type of basis functions determines their ability to capture the ﬁne details of the input-output
mapping.

778
Principles of System Identiﬁcation: Theory and Practice
• Global basis: The basis functions have their presence felt on the entire range of regressors or
operating conditions. Examples include Fourier basis (sinusoids) and Volterra expansions (power
series).
• Local basis: In here, the mapping is partitioned into several local mappings because the basis
functions are localized, i.e., each basis function exists only over a small region of the regressor
space. Examples of this class are sigmoid functions, wavelet basis.
We brieﬂy discuss next a very popular class of generalized basis function network paradigm known
as the neural network model.
25.2.1
NEURAL NETWORK MODELS
The basic model, known as a single hidden layer network, expresses the prediction as a weighted
sum of non-linearly transformed regressors:
ˆy[k] =
X
j
β1j f j (
X
i
wjiϕi[k])
(25.68)
where j = 1,· · · , H are the nodes in the hidden layer and ϕi,i = 1,· · · ,p are the p regressors.
The non-linear function f j (.) is known as the activation function. A typical choice is the sigmoidal
function. Figure 25.9 portrays the schematic of a single layer neural network with p input nodes and
H hidden nodes. The output node usually implements a linear transformation as in (25.68).
f1(.)
⋮
f2(.)
fH(.)
φ1[k]
φp[k]
⋮
φ2[k]
w11
wHp
Σ
ŷ[k]
β11
β12
β1H
w2p
Hidden 
Layer
Input
Layer
Output
Layer
Activation
Function
FIGURE 25.9
Schematic of a single-layer neural network.
These models acquire the name due to their apparently close resemblance to the neural systems
in biological systems. Technically they are no diﬀerent from (25.66). When the input to f j (.) is
not the regressors directly but the output of another network, we have a multi-layer neural network
(multiple hidden layer). Originally conceived for modeling static systems, the architecture can be
easily extended to dynamic systems by using the regressor in (25.65). The input layer can also
consist of past predictions as in the output-error model by including a feedback path from the output
layer. Such architectures are called recurrent neural networks. These dynamic models essentially are
equivalent to NARX and NOE models. See §25.2.3 below.
There exist diﬀerent forms of neural nets depending on the type of basis functions and/or the
algorithms used to estimate them.
1. Sigmoid neural network: This is one of the early networks to be postulated where the basis
function is the sigmoid in (25.67). It is also known as the multilayer perceptron (MLP) network.

Advanced Topics in SISO Identiﬁcation
779
2. Radial basis functions network: A Gaussian basis function is used. In the training of these net-
works, the centers and standard deviations of the Gaussian functions in the hidden neurons are
also optimized. RBFs are known to possess superior approximation or modeling capabilities
when compared to MLPs Nelles (2001, Chapter 11).
3. Wavelet networks: In this architecture, wavelets which are characterized by a dilation (expansion
or compression) and a translating parameter. These functions are not only localized in the space,
but are additionally characterized by a scale or a resolution factor. Thus, these models are
ideally suited for identifying multiscale systems. Recall the introductory Section 25.1.5.1 on
wavelets and multiscale systems. The wavelet networks and wavenets are extensively discussed
in Bakshi, Koulanis and Stephanopoulos (1994), Thuillard (2000), and Zhang and Benveniste
(1992). The wavenet for a single output has the form,
g(ϕ[k]) =
H
X
j=1
β1jψs,τ(wT
j (ϕ[k] −µϕ))
(25.69)
where wj is the vector of weights associated with the jth node and
ψs,τ(x) =
1√sψ
 x −τ
s

(25.70)
is the wavelet resulting by scaling and translating a mother wave with s and τ, respectively (recall
(25.37)).
Various learning algorithms, essentially non-linear optimization techniques for the purpose of
estimating the weights, are available. A popular method is the (error) backpropagation algorithm.
In general, since neural networks are characterized by a large number of unknowns (weights w and
β), pruning of these weights is an implicit feature of the learning algorithms.
The topic of neural networks has been discussed and presented in numerous texts and articles. See
Hassoun (1995) and Nelles (2001) for an excellent treatment of this modeling paradigm, the merits
and demerits and the learning algorithms.
25.2.2
FUZZY MODELS
In several situations, it may not be possible to provide a precise numerical input-output mapping.
A fuzzy model that consists of statements and rules is then perhaps more appropriate (Zadeh, 1965,
1975). The statements are in the form of fuzzy logic, which is an extension of the Boolean logic.
While the latter always partitions the mapping into two spaces (yes / no) based on a threshold,
fuzzy logic softens this hard partitioning into more than two spaces and allows overlapping between
spaces. Fuzzy models can also be viewed to be based on a basis function, known as the membership
function.
An important feature is the set of rules that assign the given regressor to a particular membership
function. Examples are:
• In a stirred tank heater, if the liquid level is high and the power supply is
low, then the fluid temperature is low.
• In mechanical structures, the strain is high when the load is high.
• In chemical systems, the reaction rate constant is low when the temperature is
low, and high when the temperature is high.
The success of fuzzy models largely depends on the number and type of rules (for all possible
attributes of regressors), and how the membership functions for each regressor are fused together.

780
Principles of System Identiﬁcation: Theory and Practice
When the fuzzy model is used as an activation function in the neural network of Figure 25.9, a
neuro-fuzzy model is born. A popular architecture of this class is known as the Takagi-Sugeno fuzzy
model named after their proponents (Takagi and Sugeno, 1985). As with a single fuzzy model, the
ability to ﬁt a good model depends on the learning algorithm. For a comprehensive treatment of
these models and optimization algorithms, refer to Nelles (2001).
We shall now discuss a popular class of parametric non-linear models that stem from an extension
of the linear parametric model structures in §17.5.
25.2.3
DYNAMIC NON-LINEAR MODELS: NARX
The main idea is to use the “ARX type” regressor (25.65) in (25.64) and set v[k] = e[k] to obtain
the non-linear ARX (NARX) predictor
ˆy[k] = g(y[k −1],· · · , y[k −na],u[k −n1],· · · ,u[k −nu],θ)
(25.71)
where the function g(.) is free to be chosen. The output-error counterpart, i.e., the NOE model has
the predictor
ˆy[k] = g( ˆy[k −1],· · · , ˆy[k −na],u[k −1],· · · ,u[k −nu],θ)
(25.72)
where now the outputs are replaced by the predictor. Thus, the predictor has a feedback from its
past unlike in the NARX model. The NARMAX structure would include now the past innovations
also in the regressors in a manner similar to the PLR form (21.65b). Given that past innovations are
replaced by past prediction errors, the NARMAX models also have a recurrent structure.
Note that the function g(.) could be any non-linear function such as sigmoidal, radial basis,
wavelet, etc. It could be parametrized (e.g., polynomial) or non-parametrized. It can even include
linear terms in addition to the non-linearity. It is clear that NARX and NOE are neural networks
without and with feedback.
All the distinguishing properties of ARX and OE models discussed in the previous chapters qual-
itatively apply to the non-linear version as well. NARX models are simpler to estimate but best
suited for minimizing one-step ahead prediction errors, whereas NOE models involve complicated
gradient computations due to the predictor-feedback (recurrent) conﬁguration. However, the NOE
structure is a good choice for obtaining models with good simulation capabilities.
Algorithms for optimizing parameters given an input-output data once again stem from the class
of non-linear optimization algorithms meant for ﬁtting neural networks.
In the following section, we brieﬂy discuss two classes of models that are widely used in describ-
ing dynamic systems that have either polynomial non-linearities or static type non-linearities. Such
systems are common in several engineering applications involving actuators (e.g., ﬂow systems with
valves, electromagnetic motors).
25.2.4
SIMPLIFIED NON-LINEAR MODELS
The two paradigms of interest are the Volterra and block-oriented (Hammerstein and Wiener) mod-
els.

Advanced Topics in SISO Identiﬁcation
781
25.2.4.1
Volterra Models
These are NFIR models with polynomial transformations such as bilinear, trilinear and higher-order
terms. A parametrized Volterra model has the form
ˆy[k] = α0 +
M
X
n=0
αnu[k −n] + · · ·
+
M
X
n1=0
M
X
n2=0
· · ·
M
X
nJ =0
αn1,n2, ···,nMu[k −n1]u[k −n2] · · · u[k −nM]
(25.73)
A major beneﬁt of this structure is that the predictor is still linear in parameters since it is a poly-
nomial regression on the vector of present and past inputs. However, it suﬀers from the curse of
dimensionality. Therefore, the expansion is limited to bilinear terms in practice.
From a modeling viewpoint, the model is always guaranteed to be stable since only past inputs
are involved. Estimation and subset selection is based on simulation, rather than one-step prediction
error as in NARX type models.
25.2.4.2
Hammerstein and Wiener Models
As explained earlier, these model structures explain the non-linearity with a static element and
describe the dynamics with the aid of a linear model. The simplicity of this representation may
seem restrictive, but has been successfully used in a variety of applications. Since the non-linear
and linear dynamic parts are captured in separate blocks, these are also known as block-oriented
models.
Hammerstein models
The Hammerstein model describes the process as a linear ﬁlter acting on a non-linearly transformed
input. From a state-space perspective, the non-linearity is in the state equation as shown below:
x[k] = f (u[k −d])
ˆy[k] = G(q−1,θ)x[k] = B(q−1,θ)
F(q−1,θ) x[k]
(25.74a)
(25.74b)
The model has a strong semblance to the linear OE structure with the input replaced by its transfor-
mation. Figure 25.10 shows a block diagram of this model.
!"#$%#&'()*+'+%,)
-!"##$%&'$().)
/$&0&#+
1%#&'()
23#'0%,))
4"5&$
u
x
y
FIGURE 25.10
Hammerstein model.
The problem is much simpliﬁed if polynomial functions, i.e., parametrized functions are used,
i.e.,
f (u,β) = β0 + β1u + · · · + βmum
Then, the Hammerstein model is equivalent to several linear OE models in parallel with inputs um.

782
Principles of System Identiﬁcation: Theory and Practice
In general, one could use the sigmoidal, saturation, piecewise linear or wavelet basis functions;
additionally physical insights can also be used to choose f (.). Regardless of the choice of f (.), the
ﬁnal predictor would be non-linear in the unknowns β and θ unless under very special situations.
See Ikonen and Najim (2002) and Nelles (2001) for further discussion. Also see Eskinat, Johnson
and Luyben (1991) for application of Hammerstein models to the modeling of distillation column
and a heat exchanger.
Wiener models
Wiener models switch the order of blocks in a Hammerstein model. The output is modeled as a
non-linear transformation of the linear dynamic block as shown in Figure 25.11.
ˆy[k] = f (G(q−1)u[k],η)
These models can be recursively estimated using what is known as a key-term separation principle
(Vörös, 2003). The method results in a linear-in-parameters model at each recursion. The choice of
functions follows similar prescriptions as Hammerstein models. It can be shown that Wiener models
are inverse Hammerstein systems and vice versa.
!"#$%&'
()#%*"+''
,-.$/
0-#/"#$%&'12%2"+'
3!"#$#%4'
5/$*$#2
u
y
x
FIGURE 25.11
Wiener model.
A wider class of non-linear processes can be modeled by combining both structures known as the
Wiener-Hammerstein model, shown in Figure 25.12.
Nonlinear)Static)
(Hammerstein))
Element
Linear)
Dynamic))
Model
u
x
Nonlinear)Static)
(Wiener))
Element
y
FIGURE 25.12
Wiener-Hammerstein model.
We conclude this section with an illustration of modeling the liquid levels of a two-tank system
(of §23.7.2.1) using the Wiener-Hammerstein paradigm.
Example 25.4: Modelling a Two-Tank System
Consider the two-tank liquid level system of §23.7.2.1. The goal is to build a model relating
the outlet ﬂows of the two tanks F1 and F2 to the inlet ﬂow Fi to the ﬁrst tank.
A more realistic scenario is simulated by introducing saturation characteristics in the outlet
ﬂow valve on F2 (the valve on F1 has wide limits - so no saturation occurs for the operating
conditions). The process is simulated with a PRBS input in the band [0 1/4] switching
between ±10% of the nominal inlet ﬂow rate Fi. Measurements of the liquid level are generated
by adding white-noise to the level responses.
The true relationships between the two ﬂows and Fi is non-linear with F1 related through
a square-root non-linearity (due to the valve) while F2 has both the square root as well as
saturation characteristics. However, with the small levels of input excitation, the relation
between F1 and Fi can be approximately linear, but F2 and Fi share a non-linear relationship

Advanced Topics in SISO Identiﬁcation
783
due to the saturation non-linearity in F2 valve. This is conﬁrmed by the OE models identiﬁed
for each of these output-input pairs.
As a ﬁrst step, linear OE models of appropriate orders are identiﬁed (using the systematic
procedure described in Chapter 22) as reported below:
ˆG11(q−1) =
(±0.002)
0.235 q−1
1 −0.762
(±0.003)q−1
ˆG21(q−1) =
(±0.004)
0.014 q−1 +
(±0.005)
0.037 q−2
1 −1.488
(±0.025)q−1 + 0.551
(±0.022)q−2
(25.75)
Residual analysis showed that the (Fi,F1) relationship is adequately captured by ˆG11 but the
second pair is undermodeled. Identifying a W-H model (in fact only a Weiner model) with a
saturation element at the output yields the following estimate for the limits
ˆSL = 1.8538,
ˆSU = 2.1035
(25.76)
which are very close to the true values SL = 1.85 and SU = 2.1 used in the simulation.
In the identiﬁcation exercise above, the input-output delay is the set to 1 sample in both
channels, obtained through IR estimates6.
Listing 25.2
MATLAB script for Example 25.4
%% Data generation
% Open the simulink model ’twotank_wvalve.slx’
twotank_wvalve
% Run the simulink model
set_param(’twotank_wvalve/Valve1’,’UpperLimit’,’6’);
set_param(’twotank_wvalve/Valve1’,’LowerLimit’,’1’);
set_param(’twotank_wvalve/Valve2’,’UpperLimit’,’2.1’);
set_param(’twotank_wvalve/Valve2’,’LowerLimit’,’1.85’);
sim(’twotank_wvalve’);
% Add noise
N = length(simout); var_x = var(simout);
vk1 = randn(N,1)*sqrt(var_x(1)/10); vk2 = randn(N,1)*sqrt(var_x(2)/10);
yk1 = simout(:,1) + vk1; yk2 = simout(:,2) + vk2;
%% Pre-processing and setting up the data for each tank
Tsamp = 2;
dataset1 = iddata(yk1,uk,Tsamp); Ztrain1 = detrend(dataset1 ,0);
dataset2 = iddata(yk2,uk,Tsamp); Ztrain2 = detrend(dataset2 ,0);
%% Build models for Tank 1 & Tank 2
mod_oe1 = oe(Ztrain1 ,[1 1 1]);
figure; resid(mod_oe1 ,Ztrain1);
mod_oe2 = oe(Ztrain2 ,[2 2 1]);
mod_hw2 = nlhw(dataset2 ,[2 2 1],[],saturation);
figure; resid(mod_hw2 ,dataset2)
Until this point in the text we have learnt methods for identiﬁcation assuming open-loop condi-
tions. However, several systems may have to be identiﬁed only under closed-loop conditions. The
next and ﬁnal section of this chapter brieﬂy discusses related methods and issues.
25.3
CLOSED-LOOP IDENTIFICATION
The aim of this section is to brieﬂy provide an overview of challenges in closed-loop identiﬁcation
(CLID), describe common approaches to CLID and discuss the properties of PEM estimators under
closed-loop conditions. A generic schematic of closed-loop system with the signals of interest is
shown in Figure 25.13.
6Note that this approach is ideally suited only for linear systems. Estimation of time-delays in non-linear systems is
carried out using measures such as mutual information; see Babji and Tangirala (2009), for example.

784
Principles of System Identiﬁcation: Theory and Practice
G
C
H
e[k]
v[k]
y[k]
r1[k]
r[k]
_
+
+
+
+
+
u[k]
Dither signal 
/ Input noise
Set-point
Controller
FIGURE 25.13
(SEE COLOR INSERT) A typical closed-loop setup with the signals of interest in identiﬁca-
tion.
There are several important reasons for identifying processes under closed-loop conditions,
namely:
1. The open-loop system is inherently unstable (such as the inverted pendulum, ﬂight dynamics,
exothermic reactors). Therefore experiments can be conducted only after feedback stabilization.
2. Several industrial processes are open-loop stable, but are under feedback during the routine op-
eration. Disrupting this operation puts the safety and economy of the plant at risk.
3. Non-linear processes are linearized through feedback. Therefore, it would be wise to take advan-
tage of the linearization eﬀects of the controller.
4. Closed-loop behavior of the system may be of interest than in open-loop. This is particularly true
when the end-use of the model is in control.
The last reason mentioned above leads to a separate branch of identiﬁcation known as the control
relevant identiﬁcation (Albertos and Sala, 2002).
Closed-loop identiﬁcation can present several challenges, importantly:
• Inputs and disturbances are correlated. Consequently, methods that give consistent estimates for
open-loop data may fail when applied to closed-loop data. This is particularly true for correlation
methods. For instance, in estimating FIR coeﬃcients we were able to correlate out the noise with
input. However, under feedback the correlation strategy produces biased estimates.
• Input is designed by the controller. Therefore, the user has no control over input excitation or can
only indirectly induce perturbations through set-point changes.
• Controller tries to keep process within bounds (opposes variability) and therefore the excitation
in output and other signals in the loop is limited.
• System cannot be identiﬁed from regulatory data, i.e., without any set-point changes (or any
external perturbation). This is because the input excitation is derived entirely from that of the
output. The input is said to be endogenous to the output.
When there is no external source of excitation to the closed-loop system, the forward and feed-
back input-output relationships are
y[k] = Gp(q−1)u[k]
u[k] = −Gc(q−1)y[k]
Consequently, it is not possible to distinguish between the process model and the inverse of the
controller. Thus, some additional excitation in the input, which is uncorrelated with the output,
is necessary.
Experiments for identiﬁcation
Under closed-loop conditions, excitation can be injected in three diﬀerent ways:

Advanced Topics in SISO Identiﬁcation
785
1. Set-point changes: In many closed-loop systems, set-point excitation may naturally be available
as a part of routine operation, while in several others, set-points are meant to be constant over
long periods of operation. Introducing changes in set-point for the purpose of identiﬁcation may
even be prohibitive due to operational constraints.
2. Dither signal: This is an external probe signal that is injected into the input directly (denoted
by r1 in Figure 25.13) such that it causes minimal interference with the closed-loop operation.
Design of dither signals usually requires the knowledge of the process itself.
Sometimes dithers are introduced in set-points as well. In any case, dithers should be used with
care as they result in oﬀ-spec outputs.
3. Unknown input noise: In many scenarios, there may be input noise entering the system, which
serves as an external source of excitation. However, it is important that the noisy input is available
(not just the calculated value by the controller).
There also exist techniques that can estimate the open-loop model from closed-loop conditions
without introducing external excitation. A popular and eﬀective technique is that of self-tuning reg-
ulator with relay (Åström and Wittenmark, 1989). It uses a non-invertible relay controller (similar
to an on-oﬀcontroller) to avoid the risk of identifying the negative inverse of the controller. Another
technique, but less followed method, is that of Ziegler-Nichols cycling. This is one of the standard
methods for controller tuning developed by Ziegler and Nichols (1942) where a time-varying feed-
back gain is used. Both methods can be seen as essentially inducing excitation into the input by
changing the controllers.
25.3.1
CLOSED-LOOP IDENTIFICATION TECHNIQUES
The methods available for closed-loop identiﬁcation can be distinguished based on whether we have
knowledge of the (i) the feedback mechanism, (ii) set-point and the (iii) controller. Accordingly, we
have three broad approaches:
1. Direct approach: Ignore the feedback and apply the open-loop methods on the input-output
data.
2. Indirect approach: First identify the closed-loop system relating set-point to output followed
by an inference of the open-loop process (knowing the regulator).
3. Joint input-output approach: Assume the set-point drives both the input and output. Perform a
multivariable identiﬁcation and subsequently construct the system transfer function.
In all three methods, an external source of excitation either in the form of set-point changes or a
dither signal is necessary. We shall brieﬂy describe each of these methods.
Direct approach
In the direct approach, the prediction-error method that we earlier studied for open-loop systems is
directly applied to closed-loop data.
One of the main advantages of this method is that the controller need not be known. It works
regardless of the nature of feedback. However, an important requirement is that the true system must
be contained in the model set. A slightly less restrictive requirement is that the noise description be
correctly captured. This is understood by the following asymptotic frequency-domain equivalence
for the PEM-QC estimator (extension of (21.49)) under closed-loop conditions (Ljung, 1999),
γεε(ω) = |△G(ejω,θ) + Bθ|2γuu(ω)
|H(ejω,θ)|2
+
|△H(ejω,θ)|2
 
σ2
e,0 −|γue(ω)|2
γuu(ω)
!
|H(ejω,θ)|2
θ⋆= arg min
θ∈D
1
4π
Z π
−π
γεε(ω) dω
(25.77)

786
Principles of System Identiﬁcation: Theory and Practice
where
Bθ = △H(ejω,θ)γue(ω)
γuu(ω)
(25.78)
Thus, unless the noise model is correctly speciﬁed, the plant model is always biased. For this pur-
pose, it is advisable to choose an independently parametrized noise model with suﬃcient ﬂexibility.
Clearly, OE models fail here. Equations (25.77) and (25.78) oﬀer another useful insight under which
we may obtain unbiased estimates. Suppose the input is generated through a linear controller, i.e.,
u[k] = Gcr (q)r[k] + Gce(q)e0[k]
(25.79)
Since γre0(ω) = 0, we can write γue0(ω) = |Gce(ejω)|2γe0e0(ω) = |Gce(ejω)|2σ2
e0/(2π), which
is also the contribution of e0[k] to the spectrum of u through feedback, call it γe
uu(ω). Therefore,
|Bθ(ejω)|2 =
σ2
0
γuu(ω)
γe
uu(ω)
γuu(ω) |△H(ejω,θ)|2
(25.80)
Thus, Bθ becomes negligible if one of the following is satisﬁed: (i) noise model is correctly speci-
ﬁed, (ii) input SNR is high and (iii) contribution of disturbance to input spectrum is low.
Consistency and accuracy of direct methods are guaranteed so long as the above conditions are
met, mainly that the plant and noise models are independently and suﬃciently parametrized.
An advantage of the direct approach is that unstable systems can be handled with ease as long as
the closed-loop system is stable and the predictor is stable. The latter is satisﬁed by equation-error
model structures such as ARX and ARMAX so that the unstable poles of G and H cancel out.
Indirect approach
In this approach, the closed-loop transfer function is estimated ﬁrst by considering the set point r[k]
as the input
Gcl (z−1) = Y (z)
R(z) =
CG
1 + CG
(25.81)
from which the process transfer function can be recovered, provided the controller is known.
The main advantage of this approach is that standard methods can be applied since r[k] and
y[k] are in open loop. No bias results if the true plant is contained in the model set (no structural
mismatch). Correct speciﬁcation of the noise model is not necessary with this approach. However,
any deviation from the linearity assumption of the loop is felt as errors in ˆG. Typically the regulators
or actuators have mild to severe non-linearities. Therefore, one should be careful in applying this
method. The identiﬁcation problem is simpliﬁed if a diﬀerent parametrization known as the Youla-
Kucera parametrization is used.
Joint input-output approach
The output and input are modeled jointly as outputs of a system driven by set-point, followed by a
recovery of the process transfer function from the respective models.
y[k] = G(q−1)C(q−1)S(q−1)r[k] + S(q−1)e[k] = Gcl (q−1)r[k] + S(q−1)e[k]
(25.82)
u[k] = C(q−1)S(q−1)r[k] + C(q−1)S(q−1)e[k] = Gur (q−1)
(25.83)
where S = 1/(1 + CG) is the sensitivity function of the closed-loop system.

Advanced Topics in SISO Identiﬁcation
787
There are two approaches here. Develop a multivariable model for y[k] and u[k] with r[k] as
the inputs either taking into account or disregarding the correlations between noises. Subsequently,
recover the system estimate as
ˆG =
ˆGcl
ˆGru
(25.84)
Cancellation of common factors is not necessarily guaranteed. In order to enforce cancellations
we may explicitly parametrize Gcl (q−1,β) = G(q−1,θ)S′(q−1,η) and likewise Gur (q−1,β) =
S′(q−1,η) where β = [ θ η ]T and S′ = CS.
A two-stage method (Hof and Schrama, 1983) may also be used wherein Gur = CS′ is estimated
ﬁrst (using an OE method for instance since r and v are in open loop). Next a noise-free input is
generated through simulation
ˆu[k] = ˆGur (q−1)r[k]
(25.85)
This estimate of input is uncorrelated with noise and suitable for classical identiﬁcation of G in
y[k] = G(q−1,θ) ˆu[k] + v[k]
(25.86)
The condition for consistently estimating G is persistent excitation of the noise-free input ˆu. It can
be shown that this method is applicable even when the regulator is non-linear.
25.4
SUMMARY
The chapter discussed three advanced aspects of identiﬁcation, namely the time-varying nature,
non-linearities and closed-loop conditions. Identiﬁcation of these respective systems is more chal-
lenging than the LTI counterparts, but the associated methods are built on the philosophy of LTI
identiﬁcation. Techniques and models developed for LTI systems constitute the core of many popu-
lar algorithms for these systems.
Linear time-varying systems can be modeled in diﬀerent ways. At the outset of this chapter we
studied the classical models consisting of diﬀerence equations with time-varying coeﬃcients, es-
sentially an adaptation of the PE models of Chapter 17 to the time-varying case. These models
are estimated using recursive approaches, with particular attention to the RLS and weighted ver-
sion, which is the simplest and popular (when applicable) among its class. The RLS algorithm was
shown as equivalent to the Kalman ﬁlter by treating the model parameters as states. We also brieﬂy
studied the recursive variant of the PEM algorithm and its Kalman ﬁlter viewpoint. Modern ap-
proaches, based on wavelet transforms, were presented in §25.1.5. Wavelets are natural tools for
modeling LTV systems since they are equipped to capture the time-varying features of signals and
can also eﬀectively separate signal and noise subspaces. There exist several exciting ideas in this
domain, of which we discussed the CWT, DWT and MODWT-based approaches.
Non-linear identiﬁcation is a continually evolving subject with a rich history. Several modeling
paradigms are available in the literature, of which the most popular ones are the generalized ba-
sis function networks, non-linear versions of the prediction-error models and fuzzy models. In this
chapter, we brieﬂy studied these paradigms with an illustration of the Wiener-Hammerstein mod-
els on a two-tank system. Regardless of the modeling paradigm, non-linear identiﬁcation presents
several challenges when compared to their linear counterparts, the main challenge being the lack of
a unique solution and the computational complexity. In this respect, linear models on non-linearly
transformed data are preferable. The Wiener-Hammerstein structures are popular in this category.
Needless to say, the reduction in the computational complexity comes at the expense of their limi-
tation in modeling fairly complex non-linear dynamics.

788
Principles of System Identiﬁcation: Theory and Practice
The last part of the chapter discussed methods for closed-loop identiﬁcation, which is a natural
setting for systems that are open-loop unstable or industrial processes that are rarely amenable to
open loop operations for reasons of safety and economy. Three broad approaches, namely, the direct,
indirect and the joint input-output approaches were reviewed. In the ﬁrst approach, the feedback is
ignored during identiﬁcation; however, the noise dynamics should be captured accurately in order to
guarantee an unbiased estimate of the plant model. In the indirect approach, the closed-loop model
is identiﬁed ﬁrst followed by a recovery of the plant model from the same. However, it can be quite
sensitive to presence of signiﬁcant non-linearities and is limited to linear controller scenarios. Fi-
nally, the joint input-output approach relies on a joint time-series modeling of the input and output.
An estimate of the plant model is constructed from a ratio of the respective models. This method
can be used in non-linear regulators as well; however, cancellation of common factors has to be
guaranteed. Two key challenges in closed-loop identiﬁcation are the non-zero correlation between
input and disturbance, and persistent excitation of the input / set-point, that are both necessary for
guaranteeing identiﬁability of models. A dither signal, which is an external signal introduced into
the closed-loop system either at the input or set-point node, is often used to address both these con-
ditions. The idea of control relevant identiﬁcation, not discussed in this text, constitutes an exciting
branch of identiﬁcation, where both the model and controller are jointly identiﬁed and designed,
respectively.
REVIEW QUESTIONS
R25.1. Describe the challenges in modeling LTV systems as compared to LTI systems.
R25.2. Explain the basic philosophy of recursive methods.
R25.3. What is the connection between feedback control methods and recursive estimation algorithms?
R25.4. Describe the semblance between Kalman ﬁlters and recursive methods.
R25.5. Can we develop exact recursive update rules for all estimation algorithms?
R25.6. How are wavelets useful in identifying linear time-varying systems?
R25.7. Deﬁne wavelet transform.
R25.8. What is the fundamental diﬀerence between CWT and DWT?
R25.9. Explain the terms scale and translation in a wavelet transform.
R25.10. Describe the speciﬁc challenges in non-linear identiﬁcation over the linear counterpart.
R25.11. What does the universal approximation result state?
R25.12. Describe radial basis function and wavelet networks.
R25.13. What are Wiener and Hammerstein model structures? For what class of processes are they
suited?
R25.14. Under what conditions would closed-loop identiﬁcation preferred to the open-loop situation?
R25.15. What are basic challenges in closed-loop identiﬁcation?
R25.16. State the main criterion (criteria) for obtaining unbiased estimate of the plant model G(.) using
the direct identiﬁcation approach for closed-loop ID?
R25.17. Explain the indirect method of identiﬁcation and the possible challenges.
EXERCISES
E25.1. It is intended to recursively update the estimate of variance ˆσ2 of a measurement x[k] online
with the arrival of every new sample. Assuming that the current estimates xN (sample mean) and
ˆσ2
N are based on N samples, using regular expressions for the estimates, derive an equation for the
update of ˆσ2
N .

Advanced Topics in SISO Identiﬁcation
789
E25.2. Suppose that a system has the model structure y[k] = ay[k −1] + bu[k −1] + e[k]. A set of
input/output data from the system is given below:
. N
1
2
3
4
5
6
7
8
9
10
u
0.06
0.34
-0.98
-0.23
-0.87
-0.17
0.37
0.18
0.86
0.69
y
0.52
0.22
0.46
-0.59
-0.43
-0.85
-0.54
-0.05
0.05
0.81
a. Estimate the model parameters using the least squares method and the whole data set.
b. Estimate the model parameters using the least squares method, but use only the three ﬁrst
measurements for y and only the two ﬁrst for u.
c. Estimate the model parameters using the recursive least squares method. Use the model that
you received in (b) as initial model. Use also the initial P-matrix from (b).
d. Redo (c), but use P(0) = αI as an initial value for P. Try diﬀerent values of α.
e. Estimate the model parameters using MATLAB’s arx command.
E25.3. Section 26.3.3 describes the linear identiﬁcation of a CSTH process.
a. Excite the non-linearities of this system by introducing input changes with larger amplitudes.
b. Introduce ﬁltered noise into the measurements such that the SNR is reasonably good.
c. Develop a non-linear ARX model for this system.
E25.4. In Example 25.4, impose saturation constraints on the outlet valve of the ﬁrst tank.
a. Modify the diﬀerential equation governing the second tank accordingly.
b. Simulate the system with a PRBS input and adjust noise variance as in the example.
c. Estimate Wiener-Hammerstein models for the two outputs with the inlet ﬂow as the input.
d. What non-linear elements did you ﬁnd the best suited for each system? Can you explain your
result in relation to the physics of the process?

26
Linear Multivariable Identiﬁcation
In this chapter we present a preview of multivariable identiﬁcation, speciﬁcally two aspects:
(i) a time delay estimation method as an extension of the frequency-domain techniques pre-
sented in §22.5, and (ii) a method for linear multivariable identiﬁcation using principal com-
ponent analysis (PCA). A tutorial introduction to multivariable data analysis using PCA is
provided ﬁrst. The presentation of this technique is in the context of model identiﬁcation. Il-
lustrative examples demonstrate the application of PCA to identiﬁcation of linear steady-state
and dynamic processes.
26.1
MOTIVATION
A large class of real-life processes present themselves as multiple-input, multiple-output (MIMO)
systems. These processes not only include chemical plants but also other ones such as manufacturing
processes, atmospheric process, etc. For the rest of the discussion in this chapter, we shall consider
a MIMO system with nu inputs and ny outputs under open-loop conditions and term it as a nu × ny
system. What is the main challenge in identiﬁcation of MIMO systems? It is the correlation among
inputs that precludes us from a direct application of the delay estimation techniques described in
Chapter 22 or the SISO input-output identiﬁcation methods in Chapters 20 and 21.
Example 26.1: A 2 × 1 system
Consider the following 2 × 1 process:
y1[k] = G11(q−1)u1[k] + G12(q−1)u2[k] =
n=∞
X
n=−∞
g11[n]u1[k −n] +
n=∞
X
n=−∞
g12[n]u2[k −n]
Treating the MISO system as two separate SISO systems for estimating the IR coeﬃcients
is marked with confounding since
σy1u1[l] =
n=∞
X
n=−∞
g11[n]σu1u1[l −n] +
n=∞
X
n=−∞
g12[n]σu2u1[l −n]
Therefore, the estimation of IR coeﬃcients for the individual sub-systems is decoupled only
when the inputs are uncorrelated, i.e., σu2u1[l] = 0, ∀l. This has a direct impact on the delay
estimation in the sub-systems.
In the frequency domain, one has
Y1(ω) = G11(ω)U1(ω) + G12(ω)U2(ω)
Once again estimating the individual FRFs is a coupled problem since the cross-spectral
density of the output with an individual input is aﬀected by the correlation between the two
inputs:
γy1u1 (ω) = G11(ω)γu1u1 (ω) + G12(ω)γu2u1 (ω)
The same situation applies to the identiﬁcation of parametric models as well.
Thus, in general, the response functions or the parameters of the individual sub-systems
have to be estimated simultaneously. More importantly, the determination of user-speciﬁed
parameters such as orders and delays can be fairly cumbersome.
790

Linear Multivariable Identiﬁcation
791
Most of the challenges highlighted by the above example are easily overcome by the subspace
identiﬁcation methods of Chapter 23. However, as we learnt therein, these methods are not neces-
sarily optimal, especially for delay estimation, and are formulated to handle the case of noise-free
inputs. Nevertheless, certain ideas in subspace identiﬁcation, particularly, that of order determina-
tion can be still used.
In this chapter, we shall outline ideas for handling multivariable system identiﬁcation using the
ideas of decoupling or de-correlation, however, in a transform space. At ﬁrst, a method for delay
estimation is presented as an extension of the frequency-domain technique described in §22.5.3
using partial coherence. The concept of partial coherence was described in §11.5 as a method
for discounting for the eﬀects of extraneous or confounding variables in assessing the correlations
between two variables in the frequency domain.
Subsequently, a method for identiﬁcation based on the principal component analysis (PCA) is
presented. PCA is a tool for multivariate statistical analysis that identiﬁes relations between vari-
ables by projections (transformations) of variables onto a basis space spanned by the eigenvectors
of the covariance (correlation) matrix1. These projections are constrained to be orthogonal to each
other and known as principal components, giving the technique its name.
Thus, the objectives of this chapter are two-fold, namely, to describe a
1. Method for time-delay estimation by numerically decoupling the multivariable system in the
frequency-domain using the partial coherence technique.
2. Method for identiﬁcation of input-output models using PCA, a multivariate data analysis tech-
nique that works in a transformed space.
PCA belongs to the class of methods for the so-called errors-in-variables (EIV) case where both
input and output measurements are corrupted with errors. An introduction to principal component
analysis from an identiﬁcation as well as a statistical perspective is presented in §26.3. The time-
delay estimation method, although expressly does not make any assumption on the inputs, is still
suited for the EIV case as well.
26.2
ESTIMATION OF TIME DELAYS IN MIMO SYSTEMS
Section 22.5 described the approach to the delay estimation problem for a SISO system. The method
involved the computation of the phase spectrum, discounting the contributions of time-constant
using the Hilbert transform relations followed by a minimization problem:
D⋆:= sol min
D
X
ω
W(ω) cos ϵ(ω)
(26.1a)
ϵ(ω) = φ(ω) −arg ¯G(ω) −Dω
(26.1b)
W(ω) =
|κ(ω)|2
1 −|κ(ω)|2
(26.1c)
where |κ2(ω)| is the squared coherence function. The quantities φ(ω) and arg ¯G(ω) are the phases of
the overall and delay-free transfer functions, respectively. Estimates of these quantities are obtained
1Traditionally, PCA is introduced in most parts of the literature as a method for dimensionality reduction by exploiting
inter-variable correlations.

792
Principles of System Identiﬁcation: Theory and Practice
Multivariable Process
u1[k]
unu[k]
y1[k]
yny[k]
⦙
⦙
G11(ω)
G1nu(ω)
Gnynu(ω)
Gny1(ω)


⦙
⦙
Yny.znu (!)
Unu.znu(!)
Yny.z1(!)
Yny.znu(!)
Y1.znu(!)
Y1.z1(!)
U1.z1(!)
U1.z1(!)
Y(!) = G(!)U(!)
y[k] = G(q−1)u[k]
FIGURE 26.1
Schematic illustrating the technique of decoupling a MIMO system in the frequency domain
using partial coherence.
from the smoothed estimate of the FRF (using (20.57) or (20.61)) and the HT relation (in (22.57))
ˆφ(ω) = arg ˆG(ω);
ˆG(ω) =
ˆγS
yu(ω)
ˆγSuu(ω)
(26.2a)
arg ¯G(ωl) =
1
2M
M
X
k=1,k,l
log |G(ωk)|
 
cot (ωl −ωk)
2
+ cot (ωl + ωk)
2
!
(26.2b)
Direct application of the above method to an input-output sub-system of a multivariable process
results in confounding, as illustrated in Example 26.1. However, the method can be applied to the
sub-system of interest by merely decoupling it from the rest of the process case using the partial
coherence function (Selvanathan and Tangirala, 2010b). This basic idea is described below.
For a given sub-system comprising the input-output pair uj and yi, there are essentially two pre-
processing steps before applying the SISO delay estimation method. Both of these steps are based
on the procedure outlined in §11.5.
i. Compute the conditioned smoothed estimates of cross-spectra and auto-spectra γyi.zj u j .zj (ω)
and γu j.zj u j.z(ω), respectively.
ii. Compute the estimate of partial coherence ηyi.zj ui.z(ω) using (11.65).
In both steps above, the variable z consists of the remaining inputs um, m = 1,· · · ,nu, m , j.
Finally, solve the SISO delay estimation problem in (26.1a) by replacing the ordinary (uncon-
ditioned) cross-spectra, auto-spectra in (26.2a) and coherence in (26.1a) with the corresponding
conditioned versions.
In essence, the above procedure amounts to breaking up an ny × nu system into nynu partial
coherence functions as illustrated schematically in Figure 26.1.
The proposed methodology is symbolically illustrated on a 2 × 2 system.
Example 26.2: 2 × 2 system
Consider a 2 × 2 MIMO system. Conditioning each input-output pair on the remaining
inputs decomposes this MIMO system into four decoupled SISO systems. Denote the condi-

Linear Multivariable Identiﬁcation
793
tioned signals in time domain by uj.zj [k] and yi.zj [k], i, j = 1,2 and their frequency-domain
counterparts by Uj.zj (ω) and Yi.zj (ω), respectively. Here zj consists of all inputs except the
input of interest uj.
We shall now walk through the computation involved in conditioning y1[k] and u1[k] on
u2[k] to ultimately obtain the partial coherency between these signals. The conditioned ver-
sions are obtained as follows.
u1.u2[k] = u1[k] −
∞
X
n=−∞
b1[k]u2[k −n]
(26.3a)
y1.u2[k] = y1[k] −
∞
X
k=−∞
b2[n]u2[k −n]
(26.3b)
The optimal estimates of the coeﬃcients in the frequency domain are obtained from the
procedure described in §11.5 as
B1(ω) = γu1u2 (ω)
γu2u2 (ω) ;
B2(ω) = γy1u2 (ω)
γu2u2 (ω)
where γ(.) is the cross-spectral density function. The Fourier transforms of the conditioned
signals are
Y1.u2 (ω) = Y1(ω) −B1(ω)U2(ω)
U1.u2 (ω) = U1(ω) −B2(ω)U2(ω)
respectively, from where the partial coherency between y1 and u1 is obtained as
ηy1u1.u2 (ω) =
γy1.u2u1.u2 (ω)
q
γy1.u2 y1.u2 (ω)γu1.u2u1.u2 (ω)
=
κy1u1 (ω) −κy1u2 (ω)κu2u1 (ω)
{(1 −|κy1u2 (ω)|1/2)(1 −|κu2u1 (ω)|1/2)}1/2
(26.4)
The quantity ηy1.u2u1.u2 (ω) is now used in place of κy1u1 (ω) in (26.1a) to compute the objective
function for estimating the time delay in G11(ω).
The key result on which the delay estimation method is based is that the transfer function
G11(ω) is related to the conditioned cross-spectral densities in the same way as for the SISO
case:
G11(ω) =
γy1.u2u1.u2 (ω)
γu1.u2u1.u2 (ω)
(26.5)
A natural estimator of G11(ω) is obtained by replacing the numerator and denominator with
the respective smoothed estimates, giving us a similar result as that of the smoothed ETFE
for the SISO case.
The conditioned signals, partial coherency and the transfer functions for the remaining
combination of input-outputs are estimated in a similar way.
Generalizing the result from the foregoing example, it is possible to show that (see Exercise
E26.1)
Gi j (ω) =
γyi.zj u j.zj (ω)
γu j.zj u j.zj (ω)
(26.6)

794
Principles of System Identiﬁcation: Theory and Practice
Remarks:
in the above development, it is assumed that the matrix of transfer functions G(q−1) is full. In the
event it is known a priori that an input-output pair (ym,ul) is not connected, i.e., Gml = 0, then it is naturally
not required to estimate delays for those channels. More importantly, such inputs should be excluded in the
confounding set when estimating transfer functions Gl j, j , m.
Algorithm 26.1
Estimation of time-delays in MIMO systems
1. Collect the input-output observations.
2. Check for stationarities and trends. Remove means from data.
3. Compute partial cross-spectra and partial coherence for each input-output pair.
4. For each input-output pair, compute the objective function Ji j (D), i = 1,· · · ,ny, j = 1,· · · ,nu in
(26.1a) by replacing ordinary cross-spectra and coherence with the partial versions computed in Step
3.
5. Determine the delay in each channel by locating the lag at which the peak in Ji j is observed.
The method is illustrated on a simple 2 × 2 transfer function model. For applications to experi-
mental / industrial systems, the reader is referred to Selvanathan and Tangirala (2010b).
Transfer function model
A system of two inputs and two outputs is simulated with known delays in all four transfer functions
under open-loop conditions.
The chosen system is described by the transfer function matrix
G(q−1) =

q−5
1 −0.5q−1 + 0.05q−2
0.3q−4
1 −0.9q−1 + 0.2q−2
0.8q−6
1 −0.5q−1
q−3
1 −0.7q−1

(26.7)
0
5
10
15
20
−0.5
0
0.5
1
MIMO, TFM, G11(z−1)
Objective function (J)
0
5
10
15
20
−0.5
0
0.5
1
MIMO, TFM, G12(z−1)
0
5
10
15
20
−0.5
0
0.5
1
MIMO, TFM, G21(z−1)
Lags (D)
Objective function (J)
0
5
10
15
20
0
0.2
0.4
0.6
0.8
1
MIMO, TFM, G22(z−1)
Lags (D)
FIGURE 26.2
Time-delay estimation in the MIMO system (TFM).
Simulation is carried out by exciting the system with pulse inputs and the SNR is set to unity. The
multivariate system is decoupled into four non-interacting SISO systems through the use of partial
coherence function, yielding four conditioned pairs (in the frequency domain). Subsequently, delays
are estimated in each channel by searching for the peak in the respective objective function J(D)
over a range of values of D. The objective functions for the four sub-systems at SNRout = 1 are

Linear Multivariable Identiﬁcation
795
shown in Figure 26.2. Reading oﬀthe values of D at which the maxima are obtained, we obtain the
estimate:
ˆDOL =
"5
4
6
3
#
(26.8)
in excellent agreement with the true time-delay matrix.
We next study the basic ideas of MIMO identiﬁcation using PCA.
26.3
PRINCIPAL COMPONENT ANALYSIS (PCA)
Principal component analysis is a century-old multivariate data analysis tool that was originally con-
ceived for ﬁtting lines to data but gained popularity largely as a dimensionality reduction technique.
A majority of the vast applications and the literature on PCA including classical texts and review ar-
ticles present PCA as a tool for multivariate compression and feature extraction. Relatively, a much
smaller set of applications deploy PCA as a method of empirical modeling.
An important fact remains that, regardless of the application, essentially in PCA one explores
linear relationships between variables of interest to achieve the end goal. The search for correlation
among variables is facilitated by an eigenvalue analysis of the covariance (correlation) matrix. The
eigenvectors thus obtained constitute a new basis space for the analysis of variables. It is this new
basis set derived from data that holds the key to several applications. Under ideal conditions, i.e.,
deterministic linear case, the eigenvectors corresponding to zero eigenvalues provide a basis for the
linear relations among the variables. Naturally identiﬁcation problems focus on this subset of basis
vectors. The approach of last principal component analysis (reference) for model identiﬁcation is
drafted on the same idea. In signal compression, the basis of interest is complementary to that of
identiﬁcation, i.e., the eigenvectors corresponding to non-zero eigenvalues. In essence, the end use
determines the subset of interest.
In the presence of noise, the situation is more complicated since one does not obtain identically
zero eigenvalues even when the underlying signals are linearly related; however, solutions, both
ad hoc and formal ones, exist. A formally well-established result is that PCA provides an optimal
solution to the total least squares problem. Recall from the brief discussion in §14.3.6 that TLS
consists of two joint problems, identiﬁcation and signal estimation.
It is clear from the foregoing discussion that the topic of PCA can be introduced from diﬀerent
viewpoints depending on the application of interest. In the following section, we present the main
theoretical development largely from a linear algebra, i.e., a projection-based perspective while
paying attention to its use in identiﬁcation.
Prior to a formal treatment, it is useful to walk through a simple example which conveys the basic
idea.
26.3.1
MOTIVATING EXAMPLE: LINEAR ALGEBRA PERSPECTIVE
The example is concerned with the analysis of a two-variable (2-D) data set. In order to bring out
the basic ideas and highlight the challenges that noise brings into the analysis, the deterministic and
the noisy versions are separately illustrated.
Case 1: Deterministic two-dimensional signals
Consider N = 100 observations of two variables x1 and x2[k] = 2x1[k].
For reasons to become clear shortly, it is useful to re-write the relation as
2x1[k] −x2[k] = 0 =⇒
f
x1[k]
x2[k]
g " 2
−1
#
= 0
(26.9)

796
Principles of System Identiﬁcation: Theory and Practice
−4
−3
−2
−1
0
1
2
3
−8
−6
−4
−2
0
2
4
6
x1
x2
FIGURE 26.3
Scatter plot of the data.
A scatter plot of the data is shown in Figure 26.3. Expectedly, all observations fall along a single
line.
With the data as the starting point the goal is to detect and discover the equation of line tying x1
and x2, i.e., the dashed line indicated in Figure 26.3. Alternatively, this amounts to identifying a
linear constraint between variables because,
x2 = mx1 =⇒−mx1 + x2 = 0
(26.10)
In a more general form, the above can be re-written as
a11x1[k] + a21x2[k] = 0
(26.11)
Thus, we seek a linear combination of the variables that yields null. Introducing
X =
f
x1
x2
g
=

x1[0]
x2[0]
x1[1]
x2[1]
· · ·
· · ·
x1[99]
x2[99]

a =
"a11
a21
#
(26.12)
we can re-write (26.11) as
Xa = 0
(26.13)
For the example, a =
f
2
−1
gT.
Essentially the identiﬁcation problem amounts to ﬁnding the null space of X, which can be de-
termined in many diﬀerent ways. A numerically robust solution is provided by the singular value
decomposition (SVD), the mathematics of which was brieﬂy described in Appendix 14.A.4.
The right singular vectors corresponding to zero singular values of a matrix X provide a basis for
the null space of X. For the example under study, SVD of X yields two singular values and the right
eigenvectors
S =
"σ1
0
0
σ2
#
=
"22.7469
0
0
0
#
;
V =
"−0.4472
0.8944
−0.8944
−0.4472
#
Thus, a solution to (26.11) is given by v2
0.8944x1[k] −0.4472x2[k] = 0
(26.14)
which may be re-written as (26.9), i.e., a basis for the true solution has been found. Notice that
v2 = 0.4472a for this example.

Linear Multivariable Identiﬁcation
797
−5
0
5
−4
−3
−2
−1
0
1
2
3
4
x1
x2
v1
v2
(a) Data with principal directions indicated
−6
−4
−2
0
2
4
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
PC 1
PC 2
(b) Plot of the principal components
FIGURE 26.4
Data in the variable space and in the new basis space.
In general, a fact remains that the true constraint can be recovered uniquely only up to a scaling
factor, i.e., if the true solution is a, then we can recover only αa,α ∈R,α , 0. In other words, if v2
is a solution then βv2, β ∈R is also a solution.
A natural question that arises is: what does the ﬁrst singular vector v1 corresponding to σ1 signify?
By the property of SVD, it is orthogonal or perpendicular to the second vector. However, more
importantly, v1 is the direction of maximum scatter of the data in contrast to v2 which is the direction
of zero scatter. In this example, v1 gives us the direction of the line itself, i.e., the linear combination
p1 = Xv1 = −0.4472x1 −0.8944x2
(26.15)
is the set of points along the dashed line in Figure 26.4(b).
Remarks:
1. The vectors v1 and v2 essentially give us the principal directions of the data. The direction of maximum
scatter is of interest in signal compression applications, while that of minimum (zero) spread is of interest
in identiﬁcation. Figure 26.4(a) indicates these directions on the data plot.
2. The linear combinations p1 and p2 are known as the principal components (a.k.a. scores for a speciﬁc data
set) and v1, v2 as loadings in the PCA literature. The latter are in fact also a new set of basis vectors b1 and
b2 for the variables (see the following point). By convention, they are necessarily labelled in the order of
decreasing scatter.
3. Linear combinations are also linear transformations, i.e., rotations of axes. Geometrically and algebraically
therefore PCA amounts to searching for a new orthogonal basis aligned along the directions of data spread.
In this example, we have moved from
("1
0
#
,
"0
1
#)
−→
("−0.4472
−0.8944
#
,
" 0.8944
−0.4472
#)
Data in the rotated axis is graphed in Figure 26.4(b). The spread in the direction of p2 (rather v2) is expec-
tantly zero.
4. The singular values σ1 and σ2 quantify the spread of data in the respective singular directions v1 and v2,
respectively. This explains the reason for obtaining a zero singular value in the second direction for the
given data.
5. In the example, it is suﬃcient to store only p1 and v1 to recover x1 and x2. This is the idea behind compres-
sion. Expressions to recover X from principal components are given in §26.3.2.
6. In general, when M variables are related through (M −r) constraints, (26.13) takes on the form
XA = 0,
A ∈RM×(M−r)
(26.16)
Then,

798
Principles of System Identiﬁcation: Theory and Practice
−6
−4
−2
0
2
4
6
−6
−5
−4
−3
−2
−1
0
1
2
3
4
z1
z2
FIGURE 26.5
Scatter plot of the data
SVD or PCA discovers an orthonormal basis for the null space of X, that is TA, where T is non-singular.
The implication of the above fact is that each row (constraint) of TA is, in general, a linear combination of
all rows of the true constraint matrix A.
7. Finally, observe that PCA does not require one to label a priori variables as dependent and independent,
i.e., it is not required to know which variables are error-free and which are not, in contrast to classical linear
regression. The price that is paid, however, is the ambiguity of similarity transformation in the model.
On the other hand, a major advantage of PCA is that it is capable of discovering multiple relationships
(constraints).
We next study the case where both variables are known with error, but the underlying relationship
between true variables holds.
Case II: Same as Case I but with measurement noise
Denote the measured variables (corrupted by white noise errors) by zi[k],
zi[k] = xi[k] + ei[k],
ei[k] ∼GWN(0,σ2
i ), i = 1,2
x2[k] = 2x1[k]
The above situation is an example of the EIV case.
For simulation purposes, the variances of the measurement errors are adjusted such that SNR is
maintained at 10. A scatter plot of the data is shown in Figure 26.5. It is clear that the data does not
fall on a single line. However, it can be said that most of the data is scattered around an imaginary
line with some minor scatter in a possibly perpendicular direction. As in the previous case, construct
the matrix
Z =
f
z1
z2
g
=

z1[0]
z2[0]
z1[1]
z2[1]
· · ·
· · ·
z1[99]
z2[99]

(26.17)
Ignoring the presence of noise suppose SVD is applied to the matrix Z as in the deterministic case.
Then intuitively, we would not run into zero singular values since Z is not rank deﬁcient. The SVD
results conﬁrm our expectations below.
S =
"σ1
0
0
σ2
#
=
"23.0957
0
0
3.3978
#
;
V =
"0.4299
−0.9029
0.9029
0.4299
#

Linear Multivariable Identiﬁcation
799
−4
−3
−2
−1
0
1
2
3
−4
−3
−2
−1
0
1
2
3
z1
z2
 
 
True 1st
direction
True 2nd
direction
v1
v2
(a) Data with principal directions indicated
−6
−4
−2
0
2
4
−4
−3
−2
−1
0
1
2
3
4
PC 1
PC 2
(b) Plot of the principal components
FIGURE 26.6
Data in the variable space and in the new basis space.
The results are best understood by plotting the resulting principal components, which are computed
in the same way as in the previous case.
Figure 26.6(a) shows the principal directions v1 and v2, while Figure 26.6(b) shows a plot of the
principal components (data in the new basis space).
Remarks:
1. The direction v1 corresponds to the direction of the maximum spread as quantiﬁed by σ1. This is also
conﬁrmed in Figure 26.4(b).
2. Compare the results with those in the noise-free case. Noise has caused some scatter of the data in the
second direction v2 as well. Once again the extent of spread is measured by σ2. Due to the high SNR, the
scatter along v2 is much smaller than that along v1.
3. The presence of noise has mainly caused the SVD to inaccurately capture the true principal directions as
indicated in Figure 26.6(a). However, the deviations (in angles) are very minor due to the high SNR. As the
noise levels increase, one can expect the angles to be also signiﬁcant.
4. Consequent to the point above, an approximate model can also be identiﬁed by the coeﬃcients of v2, by
“approximating” the second projection to zero.
p2 = Zv2 ≈0
(26.18)
=⇒−0.9029z1[k] + 0.4299z2[k] = 0
(26.19)
which can be re-written as z2[k] = 2.1z1[k].
5. A rigorous method of identifying the model between deterministic variables, i.e., between x1 and x2, from
measurements using PCA on an appropriately pre-processed data was recently presented in a nice treatment
of the problem by Narasimhan and Shah (2008).
6. As in case 1, if compression is the end use, typically one retains only those principal components (and basis
vectors) with “high” singular values. However, then we have a lossy compression unlike the lossless one in
the previous case. In other words, the reconstruction from a the retained PC recovers only an approximation
of X. See the discussions in §26.3.2.
To summarize, principal component analysis is essentially SVD of the observation matrix. From
this perspective of linear algebra therefore, PCA amounts to transformation of variables into an or-
thogonal basis determined by the directions of data spread. A statistical approach to PCA on the
other hand is also useful in order to formally deal with practicalities of noise and uncertainties in
data. In both these approaches the objective is to determine optimal linear combinations or transfor-
mations - the only diﬀerence is that the statistical approach determines the optimal transformation
from a variance (spread) maximization viewpoint. The following section presents this approach,
where its connection with the SVD-solution is also highlighted.

800
Principles of System Identiﬁcation: Theory and Practice
26.3.2
STATISTICAL APPROACH
There exist two versions of this approach, as in ordinary least squares, namely, the theoretical and
the sample version. In both versions the variables of concern are treated as random variables and
the goal is to construct optimal linear combinations. However, in the theoretical formulation, the
problem is directly cast for the population variables whereas in the sample version the formulation is
in terms of samples. As in the OLS, the solution to the sample version can be obtained by replacing
the theoretical properties with the respective estimates. Further, the statistical formulation can be
given a signal approximation perspective by viewing the second-order properties as squared 2-
norms.
26.3.2.1
Population Version
The development below is mainly inspired from the presentation in Joliﬀe (2002).
Given M random variables z =
f
z1
z2
· · ·
zM
gT with covariance matrix ΣX, the principal
component analysis is concerned with construction of i = 1,· · · , M linear combinations of these M
variables with two important requirements on the the ith linear combination:
i. it should capture maximum variance of the data ∀i = 1,· · · , M.
ii. it should be uncorrelated with the (i −1)th one ∀i = 2,· · · , M.
Denote each linear combination by pi and the coeﬃcient (of combination) vector by bi such that
pi =
M
X
j=1
bi j zj = bT
i z
(26.20)
Then, at most we can construct M uncorrelated combinations2.
Maximizing the linearly transformed variables without any bounds on the coeﬃcients evidently
leads to unbounded solutions. Therefore it is necessary to constrain the coeﬃcients. A typical con-
straint is that of unity 2-norm
||bi||2 = 1
(26.21)
The optimized linear combinations are termed as principal components (PCs). According to the
statement of the problem, the ﬁrst PC is obtained by solving the optimization problem:
max
b1
var(p1)
s.t. (i) p1 = bT
i z (ii) bT
1 b1 = 1
From (7.17b), we know var(p1) = bT
1 ΣXb. Using this result and that of the Lagrange multiplier
method, we essentially solve
max
b1
bT
1 ΣXb −α(bT
1 b1 −1)
(26.22)
where α is the Lagrange multiplier.
Solving the optimization problem yields a key result. The optimal solution satisﬁes the eigenvalue
equation of the covariance matrix ΣX corresponding to the maximum eigenvalue:
ΣZb⋆
1 = λ1b⋆
1
(26.23)
2Conventional notation uses p for coeﬃcients (loadings) and t for PCs or scores.

Linear Multivariable Identiﬁcation
801
where λ1 is the maximum eigenvalue.
Proceeding to the second linear combination, we now require maximization of variance along
with the uncorrelated requirement
max
b2
var(p2)
s.t. (i) p2 = bT
2 z (ii) bT
2 b2 = 1 (iii) cov(p2,p1) = 0
The ﬁnal constraint essentially amounts to orthogonality of the coeﬃcient vectors themselves
bT
2 b1 = 0.
As earlier, solving the optimization problem above using the Lagrange multiplier approach pro-
duces the solution
ΣZb⋆
2 = λ2b⋆
2
(26.24)
where λ2 is the second largest eigenvalue of the covariance matrix.
Continuing in this fashion, we obtain the remaining (M −2) basis vectors. An important feature
of PCA is that all the optimal basis vectors can be computed in a single step by a full eigenvalue
analysis of the covariance matrix followed by a sorted arrangement.
ΣZB = BΛ
(26.25)
where
B =
f
b1
b2
· · · bM
g
, Λ = diag(λ1,λ2,· · · ,λM)
such that λ1 > λ2 > · · · > λM.
The variance of the ith PC is none other than the ith eigenvalue itself,
var(pi) = λi, i = 1,2,· · · , M
(26.26)
Thus, the normalized eigenvalue represents the fraction of variance explained by each PC.
% variance explained by pi =
λi
M
X
i=1
λi
(26.27)
Interestingly, one could start with a minimization (of variance) problem and demand uncorrelated
PCs. Following this line of thought leads to an alternative formulation of the PCA based on the
approximation perspective, which is stated as follows.
Given a vector of M random variables z =
f
z1
z2
· · ·
zM
gT, determine r orthonormal basis
vectors bi,i = 1,· · · ,r for its approximation ˆz, such that the approximation error ε = z −ˆz is
minimized. The mathematical statement is as follows
min
bi,i=1,···,r E(||ϵ||2
2)
(26.28a)
whereε = z −ˆz =
M
X
i=r+1
pibi
(26.28b)
ˆz ≜
rX
i=1
pibi
(26.28c)
and ||bi||2
2 = 1,∀i = 1,· · · ,r
(26.28d)

802
Principles of System Identiﬁcation: Theory and Practice
Solving the optimization problem using the method of Lagrange multipliers produces,
Rb⋆
i = λib⋆
i , i = 1,· · · ,r
(26.29)
where R ≜E(zzT ) and the eigenvalues are arranged in decreasing order. In other words, the best
approximation is constructed using the ﬁrst r eigenvectors of R. The residual variance is then simply
the sum of the last (M −r) eigenvalues.
Note: When the variables have zero mean, the matrix E(zzT ) is also the covariance matrix making
the solutions (26.25) and (26.29) identical.
PCA based on correlation matrix
It is a common practice to standardize variables to zero mean and unit variance in order to account
for disparities in units of measurements,
˜zi = zi −µi
σi
=⇒
˜Z = M + DZ
(26.30)
where M and D are made up of means and standard deviations of variables.
An advantage of working with standardized variables is that PCA becomes invariant to the choice
of units and scaling of variables. Fortunately, it turns out that PCA of scaled variables simply trans-
lates to eigenvalue analysis of the correlation matrix. However, it may be noted that the PCs ob-
tained from correlation matrix are not necessarily related to those derived from the covariance
matrix in a simple way. This is due to the complicated relation between the eigenvalues and eigen-
vectors of the two matrices.
For a discussion on the merits and demerits of working with correlation vs. covariance matrices
in the context of PCA, read Joliﬀe (2002). The preference is generally for using correlations due to
a simple fact that the data matrix Z is usually made up of diﬀerent physical variables measured in
signiﬁcantly disparate units.
We now turn to the more practical case of PCA based on observations of variables.
26.3.2.2
Sample Version Formulation of PCA
Consider N observations of M variables, zj[k], i = 1,· · · , M, k = 0,· · · , N −1. These observations
may be measurements of signals from processes that are either purely stochastic or are a mix of
both deterministic and stochastic eﬀects, as is usually assumed in identiﬁcation. In either case,
the approach in PCA remains the same. Only the subsequent interpretations depend on the data
generating process.
To construct the PCs, ﬁrst construct the matrix of observations,
Z =

z1[0]
z2[0]
· · ·
zM[0]
z1[1]
z2[1]
· · ·
zM[1]
...
...
...
...
z1[N −1]
z2[N −1]
· · ·
zM[N −1]

(26.31)
One could then set up an optimization problem for minimizing approximation error in a manner
similar to that in the previous section, but by replacing expectations with squared norms of residual
matrices. The constraints on orthogonality of principal components and orthonormality of basis
vectors still prevail.
Given ZN×M, ﬁnd the best approximation (that minimizes squared Frobenius norm of the error
matrix)
ˆZ = p1bT
1 + p2bT
2 + · · · + prbT
r ,
r ≤M
(26.32)

Linear Multivariable Identiﬁcation
803
such that
⟨bi,bj⟩=

0,
i , j
1,
i = j ,
⟨pi,pj⟩= 0, i , j
and var(p1) > var(p2) > · · · > var(pr )
The solution has the same form as the theoretical one in (26.29), but with the true covariance matrix
replaced by its sample estimate
ˆR =
1
N −1ZZT
(26.33)
(for a direct solution to the sample problem see Ogunnaike (2010, Chapter 23), for instance)
(ZTZ)b⋆
i = λib⋆
i
pi = Zbi,
i = 1,· · · ,r
(26.34a)
(26.34b)
A full principal decomposition of the matrix would involve all the eigenvectors
(ZTZ)B = BΛ
(Eigenvalue Analysis)
P = ZB
(Analysis)
Z = PBT = p1bT
1 + · · · + pMbT
M
(Synthesis)
(26.35a)
(26.35b)
(26.35c)
where Λ −diag(λ1,λ2,· · · ,λM) as earlier.
Connections with SVD solution
The connection of (26.35) with that of SVD is easily recognized by noting
ZTZ = (USVT )T (USVT ) = VSTSVT
=⇒(ZTZ)V = VTΛ
(26.36)
where the last identity follows from the deﬁnition of singular values as the positive square roots of
the eigenvalues of ZTZ.
Thus, the right singular vectors are the eigenvectors of the “covariance matrix” ZTZ. Computa-
tionally, the SVD route is numerically more robust but the eigenvalue analysis of the covariance is
attractive for large data sets.
The procedure to perform PCA is outlined below.
Algorithm 26.2
Principal Component Analysis
1. Collect the observations into an N × M matrix Z.
2. Optionally mean-center and unit standardize the variables (recommended). Call the scaled matrix ˜Z.
3. Perform SVD of ˜Z = USVT to obtain basis vectors B = V.
4. Compute i = 1,· · · , M PCs, P = ˜ZB (or as P = US).
5. Determine r most signiﬁcant singular values (or PCs) using an “optimal” rule.
6. Compute approximation ˆ˜Z = Pr
i=1 pibT
i and residuals E = ˜Z −˜ZT .
Analyze the retained / discarded PCs and/or residuals depending on the application.

804
Principles of System Identiﬁcation: Theory and Practice
Remarks:
i. PCA is equivalent to diagonalization of the covariance matrix. The formal equivalent of PCA in the ﬁeld of
continuous-time stochastic processes is the Karhunen-Loève Transform. It is also known by other names.
ii. The matrix decomposition (factorization) into an orthogonal basis space due to PCA has similarities with
several other decompositions (e.g., Fourier expansion), but with an important diﬀerence. PCA derives its
basis from the data where as Fourier-like expansions use a ﬁxed known basis.
iii. Principal components are essentially projections of measurements on to a new basis space. PCA essentially
re-organizes the N × M matrix Z into a new N × M matrix P with certain desirable properties. It also
facilitates signal estimation due to improved signal and noise separation in the new space.
iv. When variables are linearly related by (M −r) constraints, (M −r) eigenvalues of ZT Z are identically zero.
However, in practice, presence of noise result in these zero eigenvalues taking “small” values. The latter
could be also due to the presence of mild non-linearities in the data.
v. No statistical assumptions on the data generating process are required to carry out PCA. It is only when
the optimality of signal estimates (in ﬁltering), or the eﬃciency / consistency of model coeﬃcients (in
identiﬁcation), or the statistical limits on process / noise variations (in fault detection and statistical process
control) is sought that such assumptions have to be invoked.
vi. In continuation of the point above, asymptotic distributions and conﬁdence intervals of the sample PCs
and eigenvalues can be derived under the assumptions of multivariate normality of data. Bootstrap meth-
ods can be used to handle noise with non-Gaussian distributions. See Joliﬀe (2002, Chapter 3) for related
expressions and a good overview.
vii. PCA (and SVD) gives the best rank r approximation of a matrix Xn×m. The situation arises in several
applications (e.g., multivariate ﬁltering) where we are motivated to discard directions of “small” variance
attributing them to noise. The partially reconstructed Z
ˆZ =
r
X
i=1
pibT
i
(26.37)
is then the best rank r approximation of Z in the squared Frobenius norm sense provided the errors in
variables are white, spatially uncorrelated and of equal variance.
viii. The residual matrix E = Z −ˆZ holds the key to several prominent applications, namely, identiﬁcation,
process monitoring and estimation of noise properties.
ix. If the neglected PCs only contain noise eﬀects, the basis matrix ˜B =
f
br+1
br+2
· · ·
bm
g
of the
negligibly small eigenvalues provides an approximate model for the variables in Z.
26.3.3
RANK DETERMINATION AND MODELING USING ITERATIVE PCA
Determination of r, the number of PCs to retain is usually done heuristically. Popular methods in-
clude fraction of variance explained, a Scree plot of eigenvalues and cross-validation. However, re-
cently Narasimhan and Shah (2008) proposed an iterative method for exactly determining r through
scaling of Z with the inverse square root of the noise covariance matrix prior to performing PCA.
Once the rank r is determined, the model is found from the linear combinations producing zero
principal components.
The basic ideas of the IPCA method are outlined below.
26.3.3.1
Iterative PCA
The iterative PCA is set up in the following framework:

Linear Multivariable Identiﬁcation
805
i. Model (Constraints): The deterministic sub-system is described by a linear (static or dynamic)
model:
xT[k]A = 0
(26.38)
where the dimensions of A and x[k] depend on whether the system is at steady-state or is in
dynamics, as explained below.
a. Steady-state: The matrix A is a d × M and x[k] is a vector of (physical or true) variables at
the kth instant.
b. Dynamics: The dimensions of A depend on the order of the system with respect to each
variable and how x[k] is constructed since the vector x[k] now consists of both instanta-
neous as well as lagged variables. For example, with M = 3 and suppose the process is
governed by a single constraint (model)
a11x1[k] + a12x2[k −1] + a13x3[k −1] = 0
(26.39)
Then if
x[k] =
f
x1[k]
x1[k −1]
x2[k]
x2[k −1]
x3[k]
x3[k −1]
gT
(26.40)
A =
f
a11
0
0
a12
0
a13
g
(26.41)
Narasimhan and Shah (2008) only discuss the steady-state formulation in their work; however, it
can be applied to the dynamic case provided the order is known (which is usually a critical piece
of information that is diﬃcult to come by).
ii. Output-error model: Measurements of x[k] are assumed to be corrupted by white noise
z[k] = x[k] + e[k]
(26.42)
where e[k] is the white noise process following a multivariate Gaussian distribution with zero-
mean and a diagonal covariance matrix Σe.
iii. Quasi-stationarity: The deterministic variables {xi[k]}M
i=1 are quasi-stationary (recall 17.3).
iv. Identiﬁability: The number of constraints (rows of A) and the number of variables should satisfy
the relation
d(d + 1)
2
> M
(26.43)
The LHS of (26.43) is the number of diagonal plus the oﬀ-diagonal elements of the Σe corre-
sponding to the dependent variables.
The stacked version of the model (26.38) can be written as
XA = 0
(26.44)
where X is a N × M matrix with rows representing time instants and columns denoting variables
and A.
The measurements, with the OE assumption, are
Z = X + E
(26.45)

806
Principles of System Identiﬁcation: Theory and Practice
where Z is the matrix of stacked measurements. In the steady-state scenario, for instance,
Z =

z1[0]
z2[0]
· · ·
zM[0]
z1[1]
z2[1]
· · ·
zM[1]
...
...
...
...
z1[N −1]
z2[N −1]
· · ·
zM[N −1]

(26.46)
and accordingly the X and E matrices.
The main diﬃculty, as we have seen in case B of the motivating example, is that Z is full rank
even though X is rank deﬁcient. In other words, none of the singular values of Z will zero out
and therefore no indication of the dimensionality of the model space (number of constraints) is
obtained from the SVD of Z (or the eigenvalue analysis of the sample covariance matrix of z). This
is theoretically shown below.
The theoretical covariance matrices in the original domain are related as,
Σz = Σx + Σe
(26.47)
under open-loop conditions3.
Consequent to the above relation,
λi(Σz) = λi(Σx) + λi(Σe),
∀i = 1,· · · , M
(26.48)
By virtue of (26.38), s eigenvalues of Σx are identically zero, which is also the key in determining the
size of A. Equation (26.48) highlights the main diﬃculty of determining the model dimensionality
from measurements; the non-zero eigenvalues (of Σz) occupy the position of zero eigenvalues (of
Σx) since Σe is of full rank.
The key idea of Narasimhan and Shah (2008) is to suitably scale Y with a pre-multiplying matrix
SZ = SX + SE
(26.49)
so that the eigenvalues of the scaled measurement and scaled deterministic covariance matrices
only diﬀer by unity, i.e., λi(SE) = I, ∀i = 1,· · · ,n. Additionally S should not reduce the rank of
Σx.
From (26.48), it is straightforward to see that the theoretical solution to the above problem is
S = Σ−1/2
e
(26.50)
In practice, we replace the theoretical covariance matrix with its estimate, which is usually not
known a priori. Narasimhan and Shah (2008) oﬀer an iterative algorithm to estimate the noise co-
variance matrix as well as the order under the assumptions stated earlier. The algorithm iterates
between the PCA step where the scaled data is used to estimate the constraint matrix and residuals
are generated, and the MLE step which estimates the noise covariance matrix from the estimated
residuals. These iterations are carried out for a user-speciﬁed model dimensionality (number of
constraints), which need not be the correct one and, in fact, is the parameter of interest. Therefore,
another layer of iteration is involved on top of this loop, which is implemented for diﬀerent guesses
of order until the number of unity eigenvalues and the hypothesized model dimensionality match.
Initialization of IPCA algorithm can be done in several ways. An intuitive strategy that is also
followed in Narasimhan and Shah (2008) is to use the A matrix from the PCA solution. This initial
estimate, denoted by ˆA(0), can be plugged into the following equation
ˆA(0)z[k] = ˆA(0)x[k] + ˆA(0)e[k] = ˆA(0)e[k]
(26.51)
3We have used the notation Σx even though x is deterministic, under the quasi-stationarity assumption as we have done
so in the input-output identiﬁcation.

Linear Multivariable Identiﬁcation
807
to generate constrained residuals r[k] = ˆA(0)r[k], provided ˆA(0) is the true constraint matrix, i.e.,
if the order has been rightly guessed. If this does not hold, an iterative approach is required (see
Algorithm 26.3 below).
The covariance of the constrained residuals is related to that of the noise covariance as
Σr = ˆA(0)Σe( ˆA(0))T
(26.52)
Under these conditions, a preliminary estimate of Σe can be generated by solving the following
MLE problem:
min
Σe N log det ˆA(0)Σe( ˆA(0))T +
N
X
k=1
(rT[k]( ˆA(0)Σe( ˆA(0))T )−1r[k])
(26.53)
This estimate gives us the sample covariance matrix of the noise.
The basic steps in the IPCA algorithm are outlined below.
Algorithm 26.3
Algorithm for the IPCA method
1. Stack the given N observations of M variables into a N × M matrix Z.
2. Set counter i = 0. Initialize with the estimate of constraint matrix. ˆA(k) from PCA of raw data and
the preliminary estimate of noise covariance matrix Σ(k)
e
from solving (26.53).
3. Scale the data using the inverse of square root of noise covariance matrix.
4. Perform PCA on the scaled data matrix, and extract the constraint matrix.
5. Increment i by one and repeat steps 2-4 until convergence (of constraint matrices).
6. If the number of unity eigenvalues of the covariance matrix after completion of step 5 is not identical
to the guessed dimensionality, repeat steps 2-5.
Remarks:
1. In implementing Algorithm 26.3, the user has the option of standardizing the data to zero mean and unity
variance by subtracting the sample mean and dividing the data with the sample standard deviation (of the
measurements). The IPCA algorithm instead removes the mean (usually necessary) but standardizes it with
the square root of the standard deviation of the errors.
2. It is beneﬁcial to implement IPCA over PCA even when the number of constraints is exactly known a priori
since it facilitates the correct computation of constraint matrix. Scaling the data with the standard deviation
of errors is the key to model identiﬁcation. Essentially it amounts to a suitable rotation of the data matrix.
3. The accuracy of the estimate of A with respect to the true constraint matrix or the solution of another
algorithm can be measured by the angle between the row subspaces of two matrices introduced in §23.5.1.
Alternatively, a distance measure may also be used as prescribed in Narasimhan and Shah (2008),
αi = ||A0,i −A0,i ˆAT ( ˆAT ˆA)−1 ˆA||2
(26.54a)
α =
X
i
αi
(26.54b)
4. Finally, if a linear regression model between two sub-sets of independent and dependent variables x1 and
x2 such that
x =
" xI
xD
#M −d
d
and xD = BxI

808
Principles of System Identiﬁcation: Theory and Practice
is sought, it can be recovered by partitioning the constraint matrix accordingly
ˆA =
" ˆAI
ˆAD
#
and then forming the expression
B = −A−1
D AI
(26.55)
Note that the regression matrix B is recovered exactly in the deterministic (noise-free) case, whereas only
approximately in the noisy case. For a speciﬁed choices of dependent and independent variables, there is
no rotational or scaling ambiguity in the estimation of the regression matrix, whereas these ambiguities will
always prevail in the estimate of the constraint matrix A.
5. Both the constraint and the regression matrices are recovered correctly only up to a permutation factor.
The following section illustrates the application of IPCA to two case studies, one a steady-state
process of ﬂow mixing and the other one consisting of a dynamic stirred-tank heater mixing process.
26.3.3.2
Example 1: Flow Mixing
The system under consideration consists of two ﬂows mixing at diﬀerent nodes of a ﬂow network
to produce three other ﬂows. This example is similar to the one illustrated in Narasimhan and Shah
(2008).
x3[k] = 2x1[k] + 3x2[k]
x4[k] = x1[k] + x2[k]
x5[k] = x1[k] −2x2[k]
(26.56a)
(26.56b)
(26.56c)
The negative coeﬃcient in the relation for x5[k] essentially implies that twice the amount of x2 is
being drawn out of x5.
Observe upfront that the problem satisﬁes the identiﬁability requirement in (26.43). There are
three constraints, hence the LHS evaluates to 3 × 4/2 = 6. Thus, the problem is identiﬁable for a
three (minimum) to ﬁve (maximum) variable process.
Data generation
The two free-to-vary ﬂows are generated as two independent realizations of random variables with
means 5 and 4 and unit variance. The remaining three ﬂows are generated according to (26.56).
Measurements of the ﬂows are generated by adding white noise to the true variables
zi[k] = xi[k] + ei[k],
ei[k] ∼GWN(0,σ2
i ), i = 1,· · · ,5
(26.57)
where σ2
i ,
i = 1,· · · ,5 are adjusted such that SNR is 10 for each measurement. The true noise
covariance matrix is thus,
Σe,0 = diag(0.1,0.1,1.3,2,0.5)
(26.58)
Setting up data matrices
The vector and matrix of data for (I)PCA are constructed as
z[k] =
f
z1[k]
z2[k]
z3[k]
z4[k]
z5[k]
gT ;
Z =

zT[0]
zT[1]
...
zT[N −1]

(26.59)

Linear Multivariable Identiﬁcation
809
TABLE 26.1
Results from IPCA and PCA of ﬂow mixing data
Quantity
Values
Singular values (σi)
6.0307, 4.2764, 1.0053, 0.9987, 0.9956 (IPCA)
55.5795, 40.5724, 9.5545, 9.2713, 9.0856 (PCA)
Constraint matrix ˆA0

0.9217
−1.5157
0.4334
−1.1246
−0.6706
−1.9351
−1.4441
0.4065
0.8119
0.2760
−0.4021
1.4974
0.4115
−1.2332
0.7663

Covariance matrix ˆΣe
0.1123, 0.0993, 1.3163, 0.1846, 0.4352 (diagonal)
Regressor matrix ˆB0

2.0627
2.9560
1.0012
0.9712
1.0283
−1.9785

Accordingly, the true constraint and regression matrices (for the deterministic variables) are given
by
A0 =

2
3
−1
0
0
1
2
0
−1
0
1
−2
0
0
−1

;
B0 =

2
3
1
1
1
−2

(26.60)
The goal of IPCA is to discover the model (constraint) A0 given in (26.60).
IPCA results
IPCA algorithm with three constraints (for the ﬁve variable case, this is the minimum number of
constraints required to satisfy the identiﬁability requirement) is implemented on the mean-centered
data. The resulting singular values and the constraint matrix are reported in Table 26.1.
Since the number of (almost) unity eigenvalues is identical to the speciﬁed number of constraints,
it is concluded that the deterministic system is governed by three constraints. It is clear that the IPCA
has rightly uncovered the requisite parameters, namely, the number of constraints, the constraint
matrix up to a basis and the regression matrix. The latter is recovered using (26.55) by treating
x3, x4 and x5 as independent variables. From Table 26.1, it is evident that the regression matrix has
been estimated with reasonably good accuracy. The same conclusion can be drawn with respect to
the estimate of noise covariance.
For the purpose of comparison, the singular values obtained from PCA (SVD) of zero-mean,
unit-variance standardized data are also reported. There is indeed no obvious way to determine the
insigniﬁcant singular values. The reader is encouraged to estimate the regression matrix from PCA
and compare it with the true matrix given in (26.60) as well as the one from IPCA.
As a second and ﬁnal example, we illustrate an extension of IPCA to a dynamic process by way
of illustration on a continuously stirred tank heater system.
Remarks:
Extensions of PCA to dynamic systems have been reported in literature. A widely cited work is
that of Ku, Storer and Georgakis (1995) who proposed the modiﬁcation of X to include lagged variables since
linear dynamic systems are described by diﬀerence equations. The method, popularly known as DPCA, was
proposed originally for fault detection. Several variants have appeared since then. However, two issues remain.

810
Principles of System Identiﬁcation: Theory and Practice
The ﬁrst one is similar to the static case; there is no clear evidence of the order in the eigenvalues. While the
second issue is that there is no suitable interpretation of the constraints that are identiﬁed based on “small”
eigenvalues. One of the main issues with matrix of lagged variables is that the number of constraints identiﬁed
is usually more than the actual number of diﬀerence equations.
26.3.3.3
Example 2: Continuously Stirred Tank Heater
The process consists of heating water in a vessel by a jacket through which a hot ﬂuid ﬂows with a
ﬂow rate of Fj and at a temperature Tj (Bequette, 1998). The goal of identiﬁcation is to develop a
model between u ≡Fj and y ≡
"
T
Tj
#T
, where T is the temperature of the ﬂuid inside the vessel.
An important use of such a model is in the control of ﬂuid temperature through a manipulation of
the jacket ﬂow. The governing equations for the continuous-time process are
dT
dt = F
V (Ti −T) +
U A
V ρCp
(Tj −T)
(26.61)
dTj
dt = Fj
Vj
(Tji −Tj) −
U A
Vj ρjCp j
(Tj −T)
(26.62)
with the following parameters and (nominal) operating conditions:
Fs = 2.832 × 10−2 m3/min, V = 0.2832 m3, ρCp = 2281.688 kJ/m3◦C,
Ti = 10◦C, Ts = 51.667◦C Tji = 93.33◦C, Tjs = 65.55◦C,
Vj = 2.832 × 10−2 m3, ρjCp j = 2281.688 kJ/m3◦C,
Fjs = 4.248 × 10−2 m3/min, U A = 6845.063 kJ/min◦C
(26.63)
The sampling interval is chosen to be 0.2 min (12 seconds) based on process characteristics. A
step test (by introducing 10% change) is carried out on the system. Steady-state gains for T and Tj
are found to be 15.3061 and 20.4082, respectively. We shall use these values to validate the dynamic
model estimated from IPCA.
Data generation
Data is generated by inducing PRBS changes with white noise characteristics into the hot ﬂuid ﬂow
rate around the nominal point. Temperature measurements T and Tj are generated by adding white
errors to the responses. For illustration purposes, we work with ﬂow measurements4 by adding white
noise to the ﬂow variable. All noise sequences are adjusted to SNR of 10.
Implementation of the IPCA
A preliminary idea of the order is obtained using the subspace approach and AIC, which suggests
second order5. Accordingly the matrix is constructed as
Z =
"
Tm[2 : N −1]
Tj,m[2 : N −1]
Fj,m[2 : N −1]
Tm[1 : N −2]
Tj,m[1 : N −2]
Fj,m[1 : N −2]
Tm[0 : N −3]
Tj,m[0 : N −3]
Fj,m[0 : N −3]
#
(26.64)
4It is also possible in general to work with noise-free measurements in PCA, but we shall work with errors-in-variables
case.
5Several works in literature note strong connections between the subspace method and PCA.

Linear Multivariable Identiﬁcation
811
0
50
100
150
200
1
1.5
2
Flow rate
Samples
0
50
100
150
200
145
150
155
Jacket Temp.
0
50
100
150
200
124
125
126
Vessel Temp.
FIGURE 26.7
Snapshot of input-output data for the CSTH example.
where the subscript m denotes measurement.
From the basic knowledge, T[k] and Tj[k] each satisﬁes approximately a ﬁrst-order linear ODE.
The same applies to T[k −1] and Tj[k −1]. Therefore, one should expect in the least 4 constraints to
be governing Z (there may be additional relations among lagged ﬂows if the ﬂow rate has colored
noise characteristics).
The IPCA Algorithm 26.3 is implemented with 4 constraints on the mean centered Z (verify that
the construction of Z satisﬁes the identiﬁability condition). The singular values of the scaled matrix
are estimated as
ˆσ =
"
33.0896
6.1941
4.6410
4.2477
2.7873
1.0108
1.0004
0.9996
0.9890
#T
The number of unity eigenvalues obtained match very closely with the postulated constraints and
hence the iterations are stopped. The corresponding 4 × 9 matrix A together with
ˆAw[k] = 0
w[k] =
"
T[k]
Tj[k]
Fj[k]
T[k −1]
Tj[k −1]
Fj[k −1]
T[k −1]
Tj[k −2]
Fj[k −2]
#
(26.65a)
(26.65b)
gives an approximate linear dynamic model for the system.
However, on most occasions the goal is to obtain transfer functions for T[k] and Tj[k] in terms
of Fj[k]. For this purpose, use the shift operator q−1 in both A and x[k]. Thus, the ﬁrst step is to
re-write
ˆ¯A(q−1)x[k] = 0,
(26.66)
where x[k] =
"
T[k]
Tj[k]
Fj[k]
#T
(26.67)
such that ˆ¯A(q−1) is a 4 × 3 matrix derived from ˆA. The ﬁrst element of ˆ¯A(q−1) is, for instance,
ˆ¯a11(q−1) = ˆa11 + ˆa14q−1 + ˆa17q−2
(26.68)
The second step is to partition x[k] into dependent variables T[k],Tj[k] and the independent variable
Fj[k]. Accordingly ˆ¯A(q−1) =
"
ˆ¯AD(q−1)
ˆ¯AI (q−1)
#
is partitioned in the same way as in the steady-

812
Principles of System Identiﬁcation: Theory and Practice
state case. The ﬁnal transfer function matrix is then with a slight abuse of notation,

T[k]
Tj[k]

= −ˆ¯A†
D(q−1) ˆ¯AI (q−1)Fj[k]
(26.69)
Notice that the product G(q−1) is a 2 × 1 matrix.
Remarks:
1. The resulting transfer function expressions in (26.69) are of high-order (as in subspace identiﬁcation).
For this reason, they are not reported here. An interested reader may arrive at these expressions using the
methodology described above. A simple check of goodness can be used to examine the model at steady-
state. For the identiﬁed model above, applying the deﬁnition of DC Gain for TF representations to (26.69),
the steady-state gain is found to be
G(1) = [ 16.0892 20.7441 ]T
(26.70)
which is in good agreement with those obtained from step tests conducted earlier.
2. The errors in Z do not necessarily conform to the assumptions made in the IPCA formulation, which is that
the errors across rows of Z should be uncorrelated. However, asymptotically the inﬂuence of this deviation
may be minimal.
3. The high-order transfer function identiﬁed above can be simpliﬁed to a lower-order model using model-
order reduction techniques.
In closing, mention should be made of subspace-EIV (Chou and Verhaegen, 1997) and consistent
dynamic PCA methods (Li and Qin, 2001) for modeling multivariable systems. There is no attempt
to review or compare the proposed dynamic IPCA method with those powerful methods. The goal is
rather to present an extension of a rigorous multivariable method (IPCA) to the dynamic case with
the hope that it (persistently) excites the reader! Note that an ample number of works have shown
the similarity of PCA and subspace approaches.
26.4
SUMMARY
This chapter presented methods for estimating time delays and developing dynamic models for mul-
tivariable systems. The main challenge in estimating delays in MIMO systems is the confounding or
interaction. Partial coherence function is used to decouple the system and apply the SISO frequency-
domain delay estimation method to the resulting SISO sub-systems. Identiﬁcation of multivariable
systems is more involved and challenging than that of SISO systems. Subspace identiﬁcation meth-
ods (SIM) are naturally equipped to handle MIMO systems but not when inputs are known with
error. Formal extensions of SIM to handle the EIV case are available. In this chapter we showed an
alternative way of developing a dynamic model using an iterative version of the familiar multivari-
able static identiﬁcation methodology, the IPCA. A few open-ended problems exist for exploration
in this regard, which the reader will hopefully ﬁnd exciting enough.
REVIEW QUESTIONS
R26.1 Describe the basic challenges in identiﬁcation of MIMO systems.
R26.2 What is confounding and how does it aﬀect the delay estimation in multivariable systems?
R26.3 When can one apply the SISO identiﬁcation methods to MIMO systems?
R26.4 Explain how SVD is useful in identifying multivariable models from data.

Linear Multivariable Identiﬁcation
813
R26.5 What is the fundamental diﬀerence in the algebraic and statistical approaches to PCA?
R26.6 Explain the relation between singular values and eigenvalues of a covariance matrix.
R26.7 How does noise in data aﬀect model identiﬁcation using PCA / SVD?
EXERCISES
E26.1 Show that the frequency response of the ij −th channel in an LTI multivariable system can be
expressed as the ratio of the partial cross- and auto-spectral densities, as given in (26.6).
E26.2 Simulate the CSTH process in §26.3.3.3 under the prescribed conditions and SNR. Use the MIMO
delay estimation method of §26.2 to identify the input-output delays. Do you get the expected result?
E26.3 From the data available for the quadruple tank system of §24.4, estimate the input-output delays
using the method described in §26.2. Are these estimates physically meaningful?
E26.4 Repeat the delay estimation exercise in E26.3 in a simulation setting, using the ﬁrst-principles
model in §24.4.
E26.5 Repeat the IPCA modeling exercise in §26.3.3.3 on your computer.
a. Perform model-order reduction on the resulting transfer function.
b. Compare the reduced-order model with the discretized version of the continuous-time transfer
functions given in Bequette (1998).
E26.6 For the CSTH process, using the PCA method develop a linear multivariable model relating T, Tj
and Hj where Hj = FjTj is the enthalpy of the heating ﬂuid.
a. How many constraints describe the system?
b. Can you give a physical signiﬁcance to the identiﬁed number of constraints?

References
Abdi, H. (2010). Partial least squares regression and projection on latent structure regression (PLS
Regression). Wiley Interdisciplinary Reviews: Computational Statistics, 2 (1), pp. 97–106.
Abdulle, A. and G. Wanner (2002). 200 years of the least squares method. Elemente der Mathematik,
57, pp. 45–60.
Addison, P. (2002). The Illustrated Wavelet Transform Handbook: Introductory Theory and Appli-
cations in Science, Engineering, Medicine and Finance. London, UK: Institute of Physics.
Akaike, H. (1969). Fitting autoregressive models for prediction. Annals of the Institute of Statistics
and Mathematics, 21, pp. 243–347.
– (1973). Information theory and an extension of the maximum likelihood principle. In: Second
International Symposium on Information Theory. Budapest, Hungary, pp. 267–281.
– (1974a). A new look at the statistical model identiﬁcation. IEEE Transactions on Automatic
Control, AC-19, pp. 716–723.
– (1974b). Stochastic theory of minimal realization. IEEE Transactions on Automatic Control, 19,
pp. 667–674.
Albertos, P. and A. Sala, eds. (2002). Iterative Identiﬁcation and Control. London, UK: Springer-
Verlag.
Aldrich, J. (1997). R. A. Fisher and the making of maximum likelihood: 1912-1922. Statistical
Science, 12 (3), pp. 162–176.
Amemiya, T. (1985). Advanced Econometrics. Harvard University Press.
Anderson, T. (1971). The Statistical Analysis of Time Series. John Wiley & Sons, Inc.
Angrist, J. D. and A. B. Krueger (2001). Instrumental variables and the search for identiﬁcation:
from supply and demand to natural experiments. Journal of Economic Perspectives, 15 (4),
pp. 69–85.
Antoniou, A. (2006). Digital Signal Processing: Signals Systems and Filters. USA: McGraw-Hill.
Arun, K. and S. Kung (1990). Balanced approximation of stochastic systems. SIAM Journal of
Matrix Analysis and Applications, 11, pp. 42–68.
Åström, K. J. and B. Wittenmark (1997). Computer-Controlled Systems: Theory and Design. 3rd
edition. Englewood Cliﬀs, NJ, USA: Prentice Hall.
Åström, K. and T. Bohlin (1965). Numerical identiﬁcation of linear dynamic systems from normal
operating records. In: IFAC Symposium on Self-Adaptive Systems. Teddington, UK, pp. 96–111.
Åström, K. and P. Eykhoﬀ(1971). System identiﬁcation - a survey. Automatica, 7, pp. 123–162.
Åström, K. and B. Wittenmark (1989). Adaptive Control. Reading, MA: Addison-Wesley.
Babji, S. and A. K. Tangirala (2009). Time-delay estimation in Closed-Loop Processes using Aver-
age Mutual Information Theory. Control and Intelligent Systems, 37 (3), pp. 176–182.
Baccala, L. and K. Sameshima (2001). Partial directed coherence: a new concept in neural structure
determination. Biological Cybernetics, 84, pp. 463–474.
Badwe, A., R. Gudi, R. Patwardhan, S. Shah and S. Patwardhan (2009). Detection of model-plant
mismatch in MPC applications. Journal of Process Control, 19, pp. 1305–1313.
Badwe, A., R. Patwardhan, S. Shah, S. Patwardhan and R. Gudi (2010). Quantifying the impact of
model-plant mismatch on controller performance. Journal of Process Control, 20, pp. 408–425.
Bakshi, A., A. Koulanis and G. Stephanopoulos (1994). Wave-nets: novel learning techniques, and
the induction of physically interpretable models. In: SPIE, pp. 637–648.
Baldacchino, T., S. R. Anderson and V. Kadirkamanathan (2013). Computational system identiﬁca-
tion for Bayesian NARMAX modelling. Automatica, 49 (9), pp. 2641–2651.
Barenthin, M. (2006). “On input design in system identiﬁcation for control”. PhD thesis. Stockholm,
Sweden: KTH School of Electrical Engineering.
814

References
815
Bartlett, M. (1948). Smoothed periodograms from time series with continuous spectra. Nature, 161,
pp. 686–687.
Bauer, D. and L. Ljung (2002). Some facts about the choice of the weighting matrices in Larimore
type of subspace algorithms. Automatica, 38 (5), pp. 763–774.
Bayes, T. (1763). An essay towards solving a problem in the doctrine of chances. Philosophical
Transactions of the Royal Society London, 53, p. 370.
Bazaraa, M. S., H. D. Sherali and C. Shetty (2006). Nonlinear Programming: Theory and Algo-
rithms. 3rd edition. Hoboken, New Jersey, USA: John Wiley & Sons, Inc.
Belsley, D., E. Kuh and R. Welch (1980). Regression Diagnostics. John Wiley & Sons, Inc.
Bendat, J. S. and A. G. Piersol (2010). Random Data: Analysis and Measurement Procedures. 4th
edition. New York, USA: John Wiley & Sons, Inc.
Benedetto, J. J. (1997). Generalized harmonic analysis and Gabor and wavelet systems. In: NWCC
’94 Proceedings of the Norbert Wiener centenary congress on Norbert Wiener centenary
congress, pp. 85–113.
Bequette, B. W. (1998). Process Dynamics: Modeling, Analysis and Simulation. Upper Saddle
River, NJ, USA: Prentice Hall.
Berk, K. (1974). Consistent autoregressive spectral estimates. Annals of Statistics, 2, pp. 489–502.
Bierman, G. (2006). Factorization Methods for Discrete Sequential Estimation. Reprinted. New
York, USA: Dover Publications, Inc.
Biernacki, C., G. Celeux and G. Govaert (2003). Choosing starting values for the EM algorithm for
getting the highest likelihood in multivariate Gaussian mixture models. Computational Statistics
and Data Analysis, 41 (3), pp. 561–575.
Bilen, C. and S. Huzurbazar (2002). Wavelet-based detection of outliers in time series. Journal of
Computational and Graphical Statistics, 11, pp. 311–327.
Björklund, S. (2003). “A survey and comparison of time-delay estimation methods in linear
systems”. PhD thesis. SE–581 83 Linköping, Sweden: Department of Electrical Engineering,
Linköpings universitet.
Blackman, R. and J. Tukey (1959). The Measurement of Power Spectra, from the Point of View of
Communications Engineering. New York, USA: Dover Publications, Inc.
Blinowska, K. and J. Zygierewicz (2012). Pracï¿Œï¿Œï¿Œtical Biomedical Signal Analysis Using
MATLAB. Medical Physics and Biomedical Engineering. Boca Raton, FL, USA: CRC Press,
Taylor & Francis Group.
Bloomﬁeld, P. (2000). Fourier Analysis of Time Series: An Introduction. 2nd edition. New York,
USA: John Wiley & Sons, Inc.
Bohlin, T. P. (2006). Practical Grey-box Process Identiﬁcation: Theory and Applications. Advances
in Industrial Control. London, UK: Springer-Verlag.
Box, G. E., G. M. Jenkins and G. C. Reinsel (2008). Time Series Analysis: Forecasting and Control.
New York, USA: John Wiley & Sons, Inc.
Brillinger, D. (2001). Time Series: Data Analysis and Theory. Philadelphia, PA, USAl: SIAM.
Brockwell, P. (2002). Introduction to Time-Series and Forecasting. New York, USA: Springer-
Verlag.
Brockwell, P. and R. Davis (1991). Time Series: Theory and Methods. New York, USA: Springer.
Broersen, P. M. (2006). Automatic Autocorrelation and Spectral Analysis. London, UK: Springer-
Verlag.
Brogan, W. L. (1991). Modern Control Theory. Upper Saddle River, NJ: Prentice Hall.
Brys, G., M. D.-. bruyne, S. Engelen, M. Hubert, W. Y. Kong, N. Smets, K. V. Branden, S. V. der
Veeken, E. Vandervieren, K. V. Driessen, S. Verboven and T. V. en Fabienne Verwerft (2011).
LIBRA: a MATLAB Library for Robust Analysis. url: http://wis.kuleuven.be/stat/
robust/LIBRA/LIBRA-home.

816
References
Burg, J. (1975). “Maximum Entropy Spectral Analysis”. PhD thesis. Stanford, California: Stanford
University. url: http://sepwww.stanford.edu/theses/sep06/.
Cai, C. and P. Harrington (1998). Diﬀerent discrete wavelet transforms applied to denoising analyt-
ical data. Journal of Chemical Information and Computer Sciences, 38, pp. 1161–1170.
Caines, P. (1976). Prediction error identiﬁcation methods for stationary stochastic processes. IEEE
Transactions on Automatic Control, 21 (4), pp. 500–505.
Carroll, R. and D. Rupert (1988). Transformation and Weighting in Regression. London, UK: Chap-
man & Hall.
Carter, G. C. (1987). Coherence and time delay estimation. Proceedings of the IEEE, 75 (2),
pp. 236–255.
Cateni, S., V. Colla and M. Vannucci (2008). Outlier detection methods for industrial applications.
In: Advances in Robotics, Automation and Control. Ed. by J. Aramburo and A. R. Trevino. In-
Tech.
Chatﬁeld, C. (2004). The Analysis of Time Series - An Introduction. 6th edition. New York, USA:
CRC Press, Taylor & Francis Group.
Chen, C. (1998). Linear System Theory and Design. 3rd edition. New York, USA: Oxford University
Press.
Chen, T., H. Ohlsson and L. Ljung (2012). On the estimation of transfer functions, regularizations
and Gaussian processes - Revisited. Automatica, 48 (8), pp. 1525–1535.
Chou, C. and M. Verhaegen (1997). Subspace algorithms for the identiﬁcation of multivariable
dynamic errors-in-variables models. Automatica, 33 (10), pp. 1857–1869.
Codrons, B., B. Anderson and M. Gevers (2002). Closed-loop identiﬁcation with an unstable or
nonminimum phase controller. Automatica, 38 (12), pp. 2127–2137.
Cohen, L. (1994). Time Frequency Analysis: Theory and Applications. Upper Saddle River, New
Jersey, USA: Prentice Hall.
Cooley, J. and J. Tukey (1965). An algorithm for the machine computation of complex Fourier
series. Mathematical Computing, 19, pp. 297–301.
Cox, D. and D. Hinkley (1974). Theoretical Statistics. New York, USA: John Wiley & Sons, Inc.
Cramer, H. (1946). Mathematical Methods of Statistics. Princeton, NJ, USA: Princeton University
Press.
Crassidis, J. L. and J. L. Junkins (2012). Optimal Estimation of Dynamic Systems. Boca Raton, FL,
USA: CRC Press, Taylor & Francis Group.
Cvetkovic, Z. and M. Vetterli (1995). Discrete time wavelet extrema representation: design and
consistent reconstruction. IEEE Transactions on Signal processing, 43 (3), pp. 681–693.
Cybenko, G. (1989). Approximation by superpositions of a sigmoidal function. Mathematics of
Control Signals Systems, 2, pp. 303–314.
Daniell, P. (1946). Discussion on the symposium on autocorrelation in time series. Supplement to
the Journal of the Royal Statistical Society, 8 (1), pp. 88–90.
Daubechies, I. (1992). Ten Lectures in Wavelets. Philadelphia, PA, USA: Society for Industrial and
Applied Mathematics.
Davison, A. and D. Hinkley (1997). Bootstrap Methods and Their Applications. Statistical and
Probabilistic Mathematics. Cambridge, UK: Cambridge University Press.
Deistler, M. (2002). System identiﬁcation and time Series analysis: past, present, and future. En-
glish. In: Stochastic Theory and Control. Ed. by B. Pasik-Duncan. Vol. 280. Lecture Notes in
Control and Information Sciences. Springer Berlin Heidelberg, pp. 97–109. isbn: 978-3-540-
43777-2.
Dempster, A., N. Laird and D. Rubin (1977). Maximum likelihood from incomplete data via the
EM algorithm. Journal of Royal Statistical Society B. 39, pp. 1–38.
Dennis, J. and R. B. Schnabel (1996). Numerical Methods for Unconstrained Optimization and
Nonlinear Equations. Philadelphia, PA, USA: SIAM.

References
817
Department of Statistics, S. U. (2000). WAVELAB. http://www-stat.stanford.edu/ wavelab.
Detroja, K. P. (2006). “Fault detection and diagnosis in large scale systems”. PhD thesis. Indian
Institute of Technology Bombay, Mumbai, India.
Djuric, P. and S. Kay (1999). Spectrum Estimation and Modeling. In: Digital Signal Processing
Handbook. Ed. by V. Madisetti and D. Williams. Boca Raton, FL, USA: CRC Press, Taylor &
Francis Group.
Donoho, D. and I. Johnstone (1994). Ideal spatial adaptation by wavelet shrinkage. Biometrika, 81,
pp. 425–455.
Dorf, R. C. and R. H. Bishop (2010). Modern Control Systems. 12th edition. Upper Saddle River,
NJ, USA: Prentice Hall.
Doroslovacki, M. and H. Fan (1996). Wavelet-based linear system modeling and adaptive ﬁltering.
IEEE Transactions on Signal processing, 44 (5), pp. 1156–1165.
Duﬃn, R. and A. Schaeﬀer (1952). A class of nonharmonic Fourier series. Transactions of the
American Mathematical Society, 72, pp. 341–366.
Durbin, J. (1960). Estimation of parameters in time series regression models. Journal of Royal
Statistical Society B. 22, pp. 139–153.
Eckhardt, R. (1987). Stan Ulam, John von Neumann, and the Monte Carlo method. Los Alamos
Science, Special Issue, pp. 131–137.
Elliot, G., T. Rothenberg and J. Stock (1996). Eﬃcient tests for an autoregressive unit root. Econo-
metrica, 64, pp. 813–836.
Emery, W. and R. Thomson (2004). Data Analysis Methods in Physical Oceanography. New York,
USA: Elsevier Science Publishers.
eMVAR (2012). eMVAR – MATLAB Toolbox for the parametric frequency domain analysis of mul-
tivariate time series. url: http://www.science.unitn.it/~nollo/research/sigpro/
eMVAR.html.
Enns, D. (1984). “Model reduction for control system design”. PhD thesis. Stanford, California,
USA: Stanford University.
Eskinat, E., S. H. Johnson and W. Luyben (1991). Use of Hammerstein models in identiﬁcation of
nonlinear systems. AIChE Journal, 37 (2), pp. 255–268.
Eubank, R. L. (2006). A Kalman Filter Primer. Boca Raton, FL, USA: CRC Press, Taylor & Francis
Group.
Faes, L. and G. Nollo (2011). Multivariate frequency domain analysis of causal interactions in
physiological time series. In: Biomedical Engineering, Trends in Electronics, Communications
and Software. Ed. by A. N. Laskovski. InTech.
Faurre, P. (1976). Stochastic realization algorithms. In: System Identiﬁcation: Advances and Case
Studies. Academic Press, pp. 1–25.
Favoreel, W., B. de Moor and P. V. Overschee (2000). Subspace state space system identiﬁcation
for industrial processes. Journal of Process Control, 10, pp. 149–155.
Firth, D. (1993). Bias reduction of maximum likelihood estimates. Biometrika, 80 (1), pp. 27–38.
Fisher, R. (1912). On an absolute criterion for ﬁtting frequency curves. Messenger of Mathematics,
41, pp. 155–160.
– (1922). On the mathematical foundations of theoretical statistics. Philosophical Transactions
Royal Society London A, 222, pp. 309–368.
– (1925). Theory of statistical estimation. Proceedings of the Cambridge Philosophical Society,
22, pp. 700–725.
Forssell, U. and L. Ljung (2000). Identiﬁcation of unstable systems using output error and Box-
Jenkins model structures. IEEE Transactions on Automatic Control, 45 (1), pp. 137–141.
Fortesque, T., L. Kershenbaum and B. Ydstie (1981). Implementation of self-tuning regulators with
variable forgetting factors. Automatica, 17 (6), pp. 831–835.

818
References
Fourier, J. (1822). The Analytical Theory of Heat (Trans: Freeman A). Cambridge, UK: Cambridge
University Press.
Franklin, G. F., J. D. Powell and M. L. Workman (1998). Digital Control of Dynamic Systems. 3rd
edition. California, USA: Addison-Wesley.
Frisch, R. and F. Waugh (1933). Partial time regressions as compared with individual trends. Econo-
metrica, 1 (4), pp. 387–401.
Funahashi, K. (1989). On the approximate realization of continuous mappings by neural networks.
Neural Networks, 2 (3), pp. 183–192.
Galbraith, J. W., A. Ullah and V. Zinde-Walsh (2002). Estimation of the vector moving average
model by vector autoregression. Econometric Reviews, 21 (2), pp. 205–219.
Gao, R. and R. Yan (2010). Wavelets: Theory and Applications for Manufacturing. New York, USA:
Springer.
Garatti, S. and R. R. Bitmead (2010). On resampling and uncertainty estimation in system identiﬁ-
cation. Automatica, 46 (5), pp. 785–795.
Garnier, H. and L. Wang, eds. (2008). Identiﬁcation of Continuous-time Models from Sampled Data.
Advances in Industrial Control. London, UK: Springer-Verlag.
Garthwaite, P., I. Jolliﬀe and B. Jones (2002). Statistical Inference. New York, USA: Oxford Uni-
versity Press.
Gauss, C. (1809). Theoria Motus Corporum Coelestium. New York, USA: Dover Publications, Inc.
Gevers, M. (2006). A personal view of the development of system identiﬁcation. IEEE Control
Systems Magazine, 26 (6), pp. 93–105.
Giannakis, G. B. and J. M. Mendel (1989). Identiﬁcation of non-minimum phase systems using
higher order statistics. IEEE Transactions on Acoustics, Speech and Signal Processing, 37 (3),
pp. 360–377.
Gigi, S. and A. K. Tangirala (2010). Quantitative analysis of directional strengths in jointly station-
ary linear multivariate processes. Biological Cybernetics, 103 (2), pp. 119–133.
Golub, G. H. and C. F. V. Loan (1996). Matrix Computations. 3rd edition. Johns Hopkins University
Press.
Grane, A. and H. Velga (2010). Wavelet-based detection of outliers in ﬁnancial time series. Compu-
tational Statistics and Data Analysis, 54, pp. 2580–2593.
Granger, C. (1966). On the typical shape of an econometric variable. Econometrics, 34, pp. 151–
160.
Granger, C. and M. Hatanaka (1964). Spectral analysis of economic time series. Princeton, NJ,
USA: Princeton University Press.
Greene, W. H. (2012). Econometric Analysis. Upper Saddle River, NJ, USA: Prentice Hall.
Grewal, M. S. and A. P. Andrews (2008). Kalman Filtering: Theory and Practice Using MATLAB.
3rd edition. New Jersey, USA: John Wiley & Sons, Inc.
Grinsted, A., J. Moore and S. Jevrejeva (2002). Crosswavelet and Wavecoherence. url: http :
//www.pol.ac.uk/home/research/waveletcoherence/.
Grossmann, A. and J. Morlet (1984). Decomposition of Hardy functions into square integrable
wavelets of constant shape. SIAM Journal of Mathematical Analysis, 15 (4), pp. 723–736.
Gustafsson, T. (2002). Subspace-based system identiﬁcation: weighting and pre-ﬁltering of instru-
ments. Automatica, 38 (3), pp. 433–443.
Haar, A. (1910). Zur Theorie der orthogonalen Funktionen-Systeme. Mathematische Annalen, 69,
pp. 331–371.
Hagglund, T. (1985). Recursive estimation of slowly time-varying parameters. In: 7th Proceedings
of IFAC on Identiﬁcation and System Parameter Estimation. Vol. 2. University of York, pp. 1137–
1142.
Hainz, G. (1994). The asymptotic properties of Burg estimators. Tech. rep. 18/January. Heidelberg,
Germany: Institut fur Angewandte Mathematik, Universitat Heidelberg.

References
819
Hamilton, J. D. (1994). Time Series Analysis. Princeton, NJ, USA: Princeton University Press.
Hamon, B. and E. Hannan (1974). Spectral estimation of time delay for dispersive and non-
dispersive systems. Journal of the Royal Statistical Society, Series C, 23 (2), pp. 134–142.
Hansen, L. (1982). Large sample properties of generalized method of moments estimators. Econo-
metrica, 50, pp. 1029–1054.
Harris, F. (1978). On the use of windows for harmonic analysis with the discrete Fourier transform.
Proceedings of the IEEE, 66 (1), pp. 51–83.
Hassoun, M. H. (1995). Fundamentals of Artiﬁcial Neural Networks. Cambridge, MA, USA: MIT
Press.
Hatanaka, M. (1996). Time-Series-Based Econometrics: Unit Roots and Co-Integration. New York,
USA: Oxford University Press.
Hawkins, D. (1980). Identiﬁcation of Outliers. London, UK: Chapman and Hall.
Heinzel, G., A. Rüdiger and R. Schilling (2002). Spectrum and spectral density estimation by
the Discrete Fourier transform (DFT), including a comprehensive list of window functions and
some new ﬂat-top windows. Tech. rep. Hannover, Germany: Max-Planck-Institut für Gravitation-
sphysik.
Herbert, J. and A. Tulleken (1993). Grey-box Modelling and Identiﬁcation Using Physical Knowl-
edge and Bayesian Techniques. Automatica, 29 (2), pp. 285–308.
Ho, B. and R. Kalman (1966). Eﬀective construction of state variables from input-output data. In: 3rd
Annual Allerton Conference on Circuit and System Theory. Ed. by M. V. Valkenburg. Monticello,
Illinois, pp. 449–459.
Hodge, V. J. and J. Austin (2004). A survey of outlier detection methodologies. Artiﬁcial Intelligence
Review, 22, pp. 85–126.
Hof, P. V. den and B. Ninness (2005). System identiﬁcation with generalized orthonormal basis
functions. In: Modelling and Identiﬁcation with Rational Orthogonal Basis Functions. Ed. by
P. S. Heuberger, P. M. den Hof and B. Wahlberg. London, UK: Springer, pp. 61–102.
Hof, P. V. and R. Schrama (1983). An indirect method for transfer function estimation from closed
loop data. Automatica, 29 (6), pp. 1523–1527.
Holmes, E. (2006). An EM algorithm for maximum likelihood estimation given corrupted obser-
vations. url: http://faculty.washington.edu/eeholmes/Files/An%5C_EM%5C_
algorithm.pdf.
Hoon, M. J. L. de, T. H. J. J. van der Hagen, H. Schoonewelle and H. van Dam (1996). Why Yule–
Walker should not be used for autoregressive modelling. Annals of Nuclear Energy, 23 (15),
pp. 1219–1228.
Hornik, K., M. Stinchcombe and H. White (1990). Universal approximation of an unknown mapping
and its derivatives using multilayer feedforward networks. Neural Networks, 3 (5), pp. 551–560.
Huang, B., S. Ding and S. J. Qin (2005). Closed-loop subspace identiﬁcation: an orthogonal projec-
tion approach. Journal of Process Control, 15, pp. 53–66.
Huber, P. J. and E. M. Ronchetti (2009). Robust Statistics. Probability and Statistics. New York,
USA: John Wiley & Sons, Inc.
Huﬀel, S. V. and J. Vandewalle (1991). The Total Least Squares Problem: Computational Aspects
and Analysis. Philadelphia, PA, USA: SIAM.
Hurvich, C. and C.-L. Tsai (1989). Regression and time series model selection in small samples.
Biometrika, 76, pp. 297–307.
Ikonen, E. and K. Najim (2002). Advanced Process Identiﬁcation and Control. Ed. by N. Munro.
Control Engineering. New York, USA: Marcel Dekker Inc.
Isaksson, A. (1993). Identiﬁcation of ARX-models subject to missing data. IEEE Transactions on
Automatic Control, 38, pp. 813–819.
Jaﬀard, S., Y. Meyer and R. Ryan (2001). Wavelets: Tools for Science and Technology. Philadelphia,
PA, USA: Society for Industrial and Applied Mathematics.

820
References
Johansen, T. A. (1997). Constrained and regularized system identiﬁcation. In: Preprints IFAC Sym-
posium on System Identiﬁcation. IFAC. Kityakushu, pp. 1467–1472.
Johansson, K. (2000). A Quadruple-tank process: A Multivariable laboratory process with an ad-
justable zero. IEEE transactions on Control Systems Technology, 8 (3), pp. 456–465.
Johnson, R. A. (2011). Miller and Freund’s: Probability and Statistics for Engineers. Upper Saddle
River, NJ, USA: Prentice Hall.
Joliﬀe, I. (2002). Principal component analysis. Statistics. New York, USA: Springer-Verlag.
Julier, S. J. and J. K. Uhlmann (2004). Unscented Filtering and Nonlinear Estimation. Proceedings
of the IEEE, 92 (3), pp. 401–422.
Kailath, T. (1980). Linear Systems. Information and System Sciences. Upper Saddle River, NJ,
USA: Prentice Hall.
Kailath, T., A. H. Sayed and B. Hassibi (2000). Linear Estimation. Information and System Sci-
ences. Upper Saddle River, NJ, USA: Prentice Hall.
Kalman, R. (1960). A new approach to linear ﬁltering and prediction problems. Journal of Basic
Engineering, 82D, pp. 35–45.
Kalman, R. and R. Bucy (1961). New results in linear ﬁltering and prediction theory. Journal of
Basic Engineering, 8D, pp. 95–108.
Katayama, T. and H. Tanaka (2007). An approach to closed-loop subspace identiﬁcation by orthog-
onal decomposition. Automatica, 43, pp. 1623–1630.
Katayama, T. (2005). Subspace methods for system identiﬁcation. London, UK: Springer-Verlag.
Kay, S. and J. Makhoul (1983). Statistics of the estimated reﬂection coeﬃcients of an autoregressive
process. IEEE Transactions on Acoustics, Speech and SIgnal Processing, 31, pp. 1447–1455.
Kay, S. (1988). Modern Spectral Estimation. Theory and Applications. Englewood Cliﬀs, NJ, USA:
Prentice Hall.
Kay, S. M. (1993). Fundamentals of statistical signal processing: Estimation theory. Upper Saddle
River, NJ, USA: Prentice Hall.
Keamey, R. E., R. E. Kirsch, J. B. MacNeil and I. W. Hunter (1991). An ensemble time-varying
identiﬁcation technique, theory and applications. In: Preprints of the 9th IFAC/FORS Symposium
on Identiﬁcation and System Parameter Estimation, pp. 191–196.
Kerschen, G., K. Worden, A. F. Vakakisc and J.-C. Golinval (2006). Past, present and future of non-
linear system identiﬁcation in structural dynamics. Mechanical Systems and Signal Processing,
20, pp. 505–592.
Khintchine, A. (1934). Korrelations theorie der stationären stochastischen Prozessen. Mathematis-
che Annalen, 109, pp. 604–615.
Knyazev, A. V. and M. E. Argentati (2002). Principal angles between subspaces in an A-based scalar
product: Algorithms and perturbation estimates. SIAM Journal of Scientiﬁc Computation, 23 (6),
pp. 2009–2041.
Kobayashi, H., B. L. Mark and W. Turin (2012). Probability, Random Processes and Statistical
Analysis. New York, USA: Cambridge University Press.
Kolmogorov, A. (1941). Interpolation and extrapolation of stationary random processes. Bulleting
of Academic Sciences, USSR, 5, pp. 3–14.
Ku, W., R. Storer and C. Georgakis (1995). Disturbance detection and isolation by dynamic principal
component analysis. Chemometrics and Intelligent Laboratory Systems, 30, pp. 179–196.
Kulhavy, R. and M. Zarrop (1993). On a general concept of forgetting. International Journal of
Control, 58 (4), pp. 905–924.
Kullback, S. and R. Leibler (1951). On information and suﬃciency. Annals of Mathematics and
Statistics, 22, pp. 79–86.
Kullback, S. (1959). Information Theory and Statistics. New York, USA: John Wiley & Sons, Inc.

References
821
Kung, S. (1978). A new identiﬁcation method and model reduction algorithm via singular value
decomposition. In: 12th Asilomar Conf. on Circuits, Systems and Computers. Asilomar, CA,
pp. 705–714.
Kwiatkowski, D., P. Phillips, P. Schmidt and Y. Shin (1992). Testing the null hypothesis of station-
arity against the alternative of a unit root. Journal of Econometrics, 54, pp. 159–178.
Larimore, W. (1990). Canonical variate analysis in identiﬁcation, ﬁltering, and adaptive control. In:
29th IEEE Conference on Decision and Control. Honolulu, pp. 596–604.
– (1996). Statistical optimality and canonical variate analysis system identiﬁcation. Signal process-
ing, 52, pp. 131–144.
Levinson, N. (1947). The Wiener (root mean square) error criterion in ﬁlter design and prediction.
Journal of Mathematical Physics, 25, pp. 262–278.
Li, D., S. Shah and T. Chen (2001). Identiﬁcation of fast-rate models from multirate data. Interna-
tional Journal of Control, 74 (7), pp. 680–689.
Li, W. and S. J. Qin (2001). Consistent dynamic PCA based on errors-in-variables subspace identi-
ﬁcation. Journal of Process Control, 11 (6), pp. 661–676.
Lighthill, M. (1958). Introduction to Fourier Analysis and Generalized Functions. Cambridge, UK:
Cambridge University Press.
Lindemann, M., J. Raethjen, J. Timmer, G. Deuschl and G. Pﬁster (2001). Delay estimation for
cortico-peripheral relations. Journal of Neuroscience Methods, 111 (127-139).
Little, R. A. and D. B. Rubin (2002). Statistical Analysis with Missing Data. 2nd edition. Hoboken,
NJ, USA: John Wiley & Sons, Inc.
Liu, K. (1997). Identiﬁcation of linear time-varying systems. Journal of Sound and Vibration,
206 (4), pp. 487–505.
Ljung, G. and G. Box (1978). On a measure of lack of ﬁt in time series models. Biometrika, 65,
pp. 297–303.
Ljung, L. and S. Ljung (1985). Error propagating properties of recursive least-squares adaptive
algorithms. Automatica, 21 (157-167).
Ljung, L. (1976a). On consistency and identiﬁability. Mathematical Programming, Study No. 5,
pp. 169–190.
– (1976b). On the consistency of prediction error identiﬁcation methods. In: System Identiﬁcation,
Advances and Case Studies. Ed. by R. Meher and D. Lainiotis. Academic Press, pp. 121–164.
– (1978). Convergence analysis of parametric identiﬁcation methods. IEEE Transactions on Auto-
matic Control, 23 (5), pp. 770–783.
– (1979). Asymptotic behavior of the extended Kalman ﬁlter as a parameter estimator for linear
systems. IEEE Transactions on Automatic Control, 24 (1), pp. 36–50.
– (1985a). Asymptotic variance expressions for identiﬁed black-box transfer function models.
IEEE Transactions on Automatic Control, AC-30, pp. 834–844.
– (1985b). On the estimation of transfer functions. Automatica, 21 (6), pp. 677–696.
– (1999). System Identiﬁcation - A Theory for the User. Upper Saddle River, NJ, USA: Prentice
Hall International.
– (2003). Aspects and experiences of user choices in subspace identiﬁcation Methods. In: Proceed-
ings of the 13th IFAC Symposium on System Identiﬁcation. IFAC, pp. 1802–1807.
– (2013). Some classical and some new ideas for identiﬁcation of linear systems. Journal of Con-
trol, Automation and Electrical Systems, 24 (1-2), pp. 3–10.
– (2014). The System Identiﬁcation Toolbox: The Manual. Natick, MA, USA: The MathWorks Inc.
1st edition 1986, 9th edition 2014.
Ljung, L. and P. Caines (1979). Asymptotic normality of prediction error estimators for approximate
system models. Stochastics, 3, pp. 29–46.

822
References
Ljung, L. and T. Chen (2013). What can regularization oﬀer for estimation of dynamical systems?
In: Proceedings of IFAC International Workshop on Adaptation and Learning in Control and
Signal Processing. IFAC. Caen, France, pp. 1–8.
Ljung, L. and T. McKelvey (1996). Subspace identiﬁcation from closed loop data. Signal process-
ing, 52, pp. 209–215.
Lovell, M. (1963). Seasonal adjustment of economic time series and multiple regression analysis.
Journal of the American Statistical Association, 58, pp. 993–1010.
Lüke, H. D. (1999). The origins of sampling theorem. IEEE Communications Magazine, 37 (4),
pp. 106–108.
Lutkepohl, H. (2005). New Introduction to Multiple Time Series Analysis. New York, USA:
Springer.
Lysne, D. and D. Tjostheim (1987). Loss of spectral peaks in autoregressive spectral estimation.
Biometrika, 74, pp. 200–206.
Mahalanobis, P. C. (1936). On the generalised distance in statistics. Proceedings of the National
Institute of Sciences of India, 2 (1), pp. 49–56.
Mallat, S. (1999). A Wavelet Tour of Signal Processing. 2nd edition. San Diego, CA, USA: Academic
Press.
Mallat, S. G. (1989). A theory for multiresolution signal decomposition : the wavelet representation.
IEEE Transactions on Pattern Analysis and Machine Intelligence, 11, pp. 674–693.
Mardia, K., H. Southworth and C. Taylor (1999). On bias in maximum likelihood estimators. Jour-
nal of Statistical Planning and Inference, 76 (1), pp. 31–39.
Markovsky, I. and S. V. Huﬀel (2007). Overview of total least squares methods. Signal processing,
87 (10), pp. 2283–2302.
Marple, S. L. (1987). Digital Spectral Analysis with Applications. Upper Saddle River, NJ, USA:
Prentice Hall.
McLeod, A. and W. Li (1983). Diagnostic checking ARMA time series models using squared-
residual autocorrelations, Journal of Time Series Analysis, 4, pp. 269–273.
Melnykov, V. and I. Melnykov (2012). Initializing the EM algorithm in Gaussian mixture models
with an unknown number of components. Computational Statistics and Data Analysis, 56 (6),
pp. 1381–1395.
Meng, X.-L. (2012). You want me to analyze data I don’t have? Are you insane? Shanghai Archives
of Psychiatry, 24 (5), pp. 297–301.
Meng, X. and X. Xie (2014). I got more data, my model is more reﬁned, but my estimator is getting
worse! Am I just dumb? Econometric Reviews, 33 (1-4), pp. 218–250.
Metropolis, N. and S. Ulam (1949). The Monte Carlo method. Journal of the American Statistical
Association, 44 (247), pp. 335–341.
Moler, C. and C. V. Loan (2003). Nineteen Dubious Ways to Compute the Exponential of a Matrix,
Twenty-Five Years Later. SIAM Review, 45 (1), pp. 3–49.
Montgomery, D. C. and G. C. Runger (2011). Applied Statistics and Probability for Engineers. 5th
edition. New York, USA: John Wiley & Sons, Inc.
Moonen, M., B. D. Moor, L. Vandenberghe and J. Vandewalle (1989). On- and oﬀ-line identiﬁcation
of linear state-space models. International Journal of Control, 49 (1), pp. 219–232.
Moor, B. D., P. D. Gersem, B. D. Schutter and W. Favoreel (1997). DAISY: Database for Identiﬁca-
tion of Systems. Journal A, 38 (3), pp. 4–5. url: http://homes.esat.kuleuven.be/~smc/
daisy/.
Moor, B. D., M. Moonen, L. Vandenberghe and J. Vandewalle (1988). Identiﬁcation of linear state
space models with singular value decomposition using canonical correlation concepts. In: SVD
and Signal Processing: Algorithms, Applications and Architectures. Ed. by E. Deprettere. Else-
vier Science Publishers, pp. 161–169.

References
823
Moore, J. B. and H. Weiss (1979). Recursive prediction error methods for adaptive estimation. IEEE
Transactions on Systems, Man, and Cybernetics, 9 (4), pp. 197–205.
Narasimhan, S. and S. Shah (2008). Model identiﬁcation and error covariance matrix estimation
from noisy data using PCA. Control Engineering Practice, 16, pp. 146–155.
Narasimhan, S., S. A. Srikanth, J. V. N. Sreeram and R. Rengaswamy (2011). Optimal plant friendly
input design for system identiﬁcation. Industrial & Engineering Chemistry Research, 50 (23),
pp. 13045–13055.
Narasimhan, S. and S. Veena (2010). Signal Processing: Principles and Implementation. Alpha
Science International Ltd.
Nelder, J. and R. Mead (1965). A simplex method for function minimization. Computer Journal, 7,
pp. 308–313.
Nelles, O. (2001). Nonlinear System Identiﬁcation. Heidelberg, Germany: Springer-Verlag Ltd.
Neudecker, H. and A. Wesselman (1990). The asymptotic variance matrix of the sample correlation
matrix. Linear Algebra Applications, 127, pp. 589–599.
Ng, S. and P. Perron (2001). Lag length selection and the construction of unit root tests with good
size and power. Econometrica, 69, pp. 1519–1554.
Niedzwlecki, M. (2000). Identiﬁcation of Time-Varying Processes. West Sussex, England: John Wi-
ley & Sons, Inc.
Ninness, B. and S. Gibson (2005). Robust and simple algorithms for maximum likelihood estimation
of multivariable dynamic systems. Automatica, 41 (10), pp. 1667–1682.
Ninness, B. (2009a). Some system identiﬁcation challenges and approaches. In: SYSID 2009, 15th
IFAC Symposium on System Identiﬁcation. Ed. by E. Walter. Vol. 15. Saint-Malo, France, pp. 1–
20.
– (2009b). System Identiﬁcation Toolbox. url: http://sigpromu.org/idtoolbox/index.
html.
Ninness, B. and S. Henriksen (2010). Bayesian system identiﬁcation via Markov Chain Monte Carlo
simulation. Automatica, 46 (1), pp. 40–51.
Niu, S., D. Fisher and D. Xiao (1992). An augmented UD identiﬁcation algorithm. International
Journal of Control, 56 (1), pp. 193–211.
Niu, S., D. Xiao and D. Fisher (1990). A recursive algorithm for simultaneous identiﬁcation of
model order and parameters. IEEE Transactions on Acoustics, Speech and SIgnal Processing,
38, pp. 884–886.
Nuttall, A. (1971). Spectral estimation by means of overlapped FFT processing of windowed data.
Tech. rep. 4169. New London, CT: Naval Underwater Systems Center.
Ogunnaike, B. A. (2010). Random Phenomena: Fundamentals of Probability and Statistics for En-
gineers. Boca Raton, FL, USA: CRC Press, Taylor & Francis Group.
Ohlsson, H. and L. Ljung (2013). Identiﬁcation of switched linear regression models using sum-of-
norms regularization. Automatica, 49 (4), pp. 1045–1050.
Oppenheim, A. and R. Schafer (1987). Discrete-Time Signal Processing. Englewood Cliﬀs, NJ:
Prentice Hall.
Orfanidis, S. (2007). Optimum Signal Processing. 2nd edition. New York, USA: McGraw Hill.
Osborne, M. (1992). Fisher’s method of scoring. International Statistical Review, 60 (1), pp. 99–
117.
Overschee, P. V. and B. D. Moor (1993a). Choice of state-space basis in combined deterministic-
stochastic subspace identiﬁcation. Automatica, 31 (12), pp. 1877–1883.
– (1993b). Subspace algorithms for the stochastic identiﬁcation problem. Automatica, 29 (3),
pp. 649–660.
– (1994). N4SID - Subspace algorithms for the identiﬁcation of combined deterministic - stochastic
systems. Automatica, 30 (1), pp. 75–93.

824
References
Overschee, P. V. and B. de Moor (1996). Subspace Identiﬁcation for Linear Systems: Theory, Im-
plementation and Applications. Netherlands: Kluwer Academic Publishers.
Patterson, K. (2012). Unit Root Tests in Time Series. Vol. 1 & 2. Hampshire, UK: Palgrave Macmil-
lan.
Pearson, R. K. (2011). Exploring Data: in Engineering, the Sciences and Medicine. Canada: Oxford
University Press.
Percival, D. and A. Walden (1993). Spectral Analysis for Physical Applications. Cambridge, UK:
Cambridge University Press.
– (2000). Wavelet Methods for Time Series Analysis. Cambridge Series in Statistical and Proba-
bilistic Mechanics. New York, USA: Cambridge University Press.
Pham-Gia, T. and T. Hung (2001). The mean and median absolute deviations. Mathematical and
Computer Modelling, 24, pp. 921–936.
Phillips, P. and P. Perron (1988). Testing for unit roots in time series regression. Biometrika, 75,
pp. 335–346.
Pillonetto, G., A. Chiuso and G. D. Nicolao (2011). Prediction error identiﬁcation of linear systems:
a nonparametric Gaussian regression approach. Automatica, 47 (2), pp. 291–305.
Pillonetto, G. and G. D. Nicolao (2010). A new kernel-based approach for linear system identiﬁca-
tion. Automatica, 46 (1), pp. 81–93.
Pintelton, R. and J. Schoukens (2000). Frequency domain identiﬁcation with missing data. IEEE
Transactions on Automatic Control, 45 (2), pp. 364–369.
Pisarenko, V. (1973). The retrieval of harmonics from a covariance function. Geophysical Journal
of the Royal Astronomical Society, 33, pp. 347–366.
Porat, B. (1997). A Course in Digital Signal Processing. New York, USA: John Wiley & Sons, Inc.
Poularikas, A. (2010). Handbook of Formulas and Tables for Signal Processing. Boca Raton, FL,
USA: CRC Press, Taylor & Francis Group.
Priestley, M. B. (1981). Spectral Analysis and Time Series. London, UK: Academic Press.
Proakis, J. and D. Manolakis (2005). Digital Signal Processing - Principles, Algorithms and Appli-
cations. New Jersey, USA: Prentice Hall.
Qin, S. J. (2006). An overview of subspace identiﬁcation. Computers and Chemical Engineering,
30, pp. 1502–1513.
R Core Team (2014). R: A Language and Environment for Statistical Computing. R Foundation for
Statistical Computing. Vienna, Austria. url: http://www.R-project.org/.
Raghavan, H., R. B. Gopaluni, S. Shah, J. Pakpahan, R. Patwardhan and C. Robson (2005). Gray-
box identiﬁcation of dynamic models for the bleaching operation in a pulp mill. Journal of Pro-
cess Control, 15 (4), pp. 451–468.
Raghavan, H., A. K. Tangirala, R. B. Gopaluni and S. L. Shah (2006). Identiﬁcation of chemical
processes with irregular output sampling. Control Engineering Practice, 14, pp. 467–480.
Randall, R. B. (2011). Vibration-based Condition Monitoring: Industrial, Aerospace and Automo-
tive Applications. London, UK: John Wiley & Sons, Inc.
Rao, C. R. (1945). Information and the accuracy attainable in the estimation of statistical parameters.
Bulletin of Calcutta Mathematical Society, 37, pp. 81–89.
– (1973). Linear Statistical Inferences and its Applications. New York, USA: John Wiley & Sons,
Inc.
Rao, C. R., H. Toutenburg, Shalabh and C. Heumann (2008). Linear Models and Generaliza-
tions Least Squares and Alternatives Linear Models Linear Models and Generalizations: Least
Squares and Alternatives. Springer Series in Statistics. Heidelberg, Germany: Springer-Verlag.
Rao, G. and H. Unbehauen (2006). Identiﬁcation of continuous-time systems. IEE Proceedings on
Control Theory Applications, 153 (2), pp. 185–220.
Rasmussen, C. and C. Williams (2006). Gaussian processes for machine learning. Cambridge, MA,
USA: MIT Press.

References
825
Rehor, J. and V. Havlena (2011). A Practical approach to grey-box model identiﬁcation. In: 18th
IFAC World Congress. Milano, Italy, pp. 10776–10781.
Rissanen, J. (1978). Modeling by the shortest data description. Automaticat, 14 (465-471).
Rivera, D., H. Lee, M. Braun and H. Mittelman (2003). Plant-friendly system identiﬁcation: a chal-
lenge for the process industries. In: 13th IFAC Symposium on System Identiﬁcation.
Rosipal, R. and N. Krämer (2006). Overview and recent advances in partial least squares. In: Sub-
space, Latent Structure and Feature Selection. Ed. by C. Saunders, M. Grobelnik, S. Gunn and
J. Shawe-Taylor. Vol. 3940. Lecture Notes in Computer Science. Springer Berlin Heidelberg,
pp. 34–51.
Rousseeuw, P. J. (1984). Least median of squares regression. Journal of American Statistical Asso-
ciation, 79, pp. 871–880.
Rousseeuw, P. J. and C. Croux (1993). Alternatives to the median absolute deviation. Journal of the
American Statistical Association, 88 (424), pp. 1273–1283.
Rousseeuw, P. J. and A. Leroy (2004). Robust Regression and Outlier Detection. Probability and
Mathematical Statistics. New York, USA: John Wiley & Sons, Inc.
Rousseeuw, P. J. and B. van Zomeren (1990). Unmasking multivariate outliers and leverage Points.
Journal of American Statistical Association, 85, pp. 633–639.
Rubin, D. B. (1976). Inference and missing data. Biometrika, 63, pp. 581–592.
– (1987). Multiple imputation for nonresponse in surveys. New York, USA: John Wiley & Sons,
Inc.
Saelid, S., O. Egeland and B. Foss (1985). A solution to the blow up problem in adaptive controllers.
Modeling, Identiﬁcation and Control, 6 (1), pp. 36–39.
Saelid, S. and B. Foss (1983). Adaptive controllers with a vector variable forgetting factor. In: 22nd
IEEE Conference on Decision and Control, pp. 1488–1494.
Said, S. and D. Dickey (1984). Testing for unit roots in autoregressive moving-average models with
unknown order. Biometrika, 71, pp. 599–607.
Santos, P. L. dos, T. P. A. Perdicoúlis, C. Novara, J. A. Ramos and D. E. Rivera (2012). Linear
Parameter-Varying System Identiﬁcation: New Developments and Trends. Vol. 14. Advanced
Series in Electrical and Computer Engineering. Singapore: World Scientiﬁc Publishing Co. Pvt.
Ltd.
Schafer, J. L. and J. W. Graham (2002). Missing data: Our view of the state of the art. Psychological
Methods, 7 (2), pp. 147–177.
Schön, T. B. (2009). An explanation of the expectation maximization algorithm. Tech. rep. LiTH-
ISY-R-2915. Department of Electrical Engineering, Linköpings universitet.
Schuster, A. (1897). On lunar and solar periodicities of earthquakes. Proceedings of the Royal So-
ciety, 61, pp. 455–465.
Schutter, B. D. (2000). Minimal state-space realization in linear system theory: An overview. Jour-
nal of Computational and Applied Mathematics, 121 (1-2). Special Issue on Numerical Analysis
in the 20th Century, pp. 331–354.
Schwarz, G. (1978). Estimating the dimension of a model. Annals of Statistics, 6, pp. 461–464.
Seber, G. and C. Wild (1989). Nonlinear Regression. New York, USA: John Wiley & Sons, Inc.
Seborg, D. E., T. F. Edgar and D. A. Mellichamp (2003). Process Dynamics and Control. 2nd edition.
New York, USA: John Wiley & Sons, Inc.
Selvanathan, S. and A. K. Tangirala (2010a). Diagnosis of poor control loop performance due to
model plant mismatch. Industrial & Engineering Chemistry Research, 49 (9), pp. 4210–4229.
Selvanathan, S. and A. K. Tangirala (2010b). Time-delay estimation in multivariate systems using
Hilbert transform relation and partial coherence functions. Chemical Engineering Sciences, 65,
pp. 660–674.
Shan, X. and J. Burl (2011). Continuous wavelet based time-varying system identiﬁcation. Signal
Processing, 91 (6), pp. 1476–1488.

826
References
Shannon, C. (1948). A mathematical theory of communication. Bell System Technical Journal, 27,
pp. 379–423, 623–656.
Shumway, R. and D. Stoﬀer (1982). An approach to time series smoothing and forecasting using
the EM algorithm. Journal of Time Series Analysis, 3 (4), pp. 253–264.
– (2006). Time Series Analysis and its Applications. New York, USA: Springer-Verlag.
Sjöberg, J., Q. Zhang, L. Ljung, A. Benveniste, B. Deylon, P.-Y. Glorennec, H. Hjalmarsson and
A. Juditsky (1995). Nonlinear black-box modeling in system identiﬁcation: a uniﬁed overview.
Automatica, 31, pp. 1691–1724.
Slepian, D. and H. Pollak (1961). Prolate spheroidal wave functions, Fourier analysis, and uncer-
tainty - I. Bell System Technical Journal, 40, pp. 43–64.
Smith, S. W. (1997). Scientist and Engineer’s Guide to Digital Signal Processing. San Diego, CA,
USA: California Technical publishing.
Soderstrom, T. and P. Stoica (1994). System Identiﬁcation. Upper Saddle River, NJ, USA: Prentice
Hall International.
Sorenson, H. (1970). Least squares estimation: from Gauss to Kalman. IEEE Spectrum, 7, pp. 63–
68.
Sripada, N. R. and D. G. Fisher (1987). Improved least squares identiﬁcation. International Journal
of Control, 46 (6), pp. 1889–1913.
Steiglitz, K. and L. McBride (1965). A technique for the identiﬁcation of linear systems. IEEE
Transactions on Automatic Control, AC-10, pp. 461–464.
Stenlund, B. and F. Gustafsson (2002). Avoiding windup in recursive parameter estimation. In:
Preprints of reglermöte 2002. Linkoping, Sweden.
Stephanopoulos, G. (1984). Chemical Process Control: An Introduction to Theory and Practice.
Upper Saddle River, NJ, USA: Prentice Hall.
Stock, J. H. and F. Trebbi (2003). Who invented instrumental variable regression? Journal of Eco-
nomic Perspectives, 17 (3), pp. 177–194.
Stoica, P. and R. L. Moses (2005). Spectral Analysis of Signals. Upper Saddle River, NJ, USA:
Prentice Hall. url: http://user.it.uu.se/~ps/SAS-new.pdf.
Stoica, P. and T. Soderstrom (1981). The Steiglitz-McBride identiﬁcation algorithm revisited-
convergence analysis and accuracy aspects. IEEE Transactions on Automatic Control, 26 (3),
pp. 712–717.
Takagi, T. and M. Sugeno (1985). Fuzzy identiﬁcation of systems and its application to modeling
and control. IEEE Transactions on Systems, Man, and Cybernetics, 15 (1), pp. 116–132.
Tanaka, M. and T. Katayama (1990). Robust identiﬁcation and smoothing for linear system with
outliers and missing data. In: 11th IFAC World Congress. Tallinn, Estonia, USSR, pp. 160–165.
Tangirala, A. K., S. Mukhopadhyay and A. P. Tiwari (2013). Wavelet applications in modeling and
control. In: Advances in Chemical Engineering. Ed. by S. Pushpavanam. Vol. 43. Burlington:
Academic Press, pp. 107–204.
Tangirala, A. K., S. L. Shah and N. F. Thornhill (2005). PSCMAP: A new tool for plant-wide
oscillation detection. Journal of Process Control, 15 (8), pp. 931–941.
Thao, N. and M. Vetterli (1994). Deterministic Analysis of Oversampled A/D Conversion and De-
coding Deterministic Analysis of Oversampled A/D Conversion and Decoding Improvement
Based on Consistent Estimates. IEEE Transactions on Signal processing, 42 (3), pp. 519–531.
Thomson, D. (1982). Spectrum estimation and harmonic analysis. Proceedings of the IEEE, 70,
pp. 1055–1096.
Thornhill, N., B. Huang and H. Zhang (2003). Detection of multiple oscillations in control loops.
Journal of Process Control, 13 (91-100).
Thuillard, M. (2000). A review of wavelet networks, wavenets, fuzzy wavenets and their applica-
tions. In: ESIT 2000.

References
827
Torrence, C. and G. Compo (1998). A practical guide to wavelet analysis. Bulleting of the American
Meteorological Society, 79 (1), pp. 61–78.
Trnka, P. (2005). Subspace Identiﬁcation Methods. Tech. rep. Department of Control Engineering,
Czech Technical University.
Tsatsanis, M. and G. Giannakis (1993). Time-varying system identiﬁcation and model validation
using wavelets. IEEE Transactions on Signal processing, 41 (12), pp. 3512–3523.
Unbehauen, H. and G. Rao (1990). Continuous-time approaches to system identiﬁcation—A survey.
Automatica, 26 (1), pp. 23–35.
Unser, M. (2000). Sampling - 50 years after Shannon. Proceedings of the IEEE, 88 (4), pp. 569–587.
Vaidyanathan, P. (1987). Quadrature mirror ﬁlter banks, M-band extensions and perfect reconstruc-
tion techniques. IEEE ASSP Magazine, 4 (3), pp. 4–20.
Verhaegen, M. (1993). Application of a subspace model identiﬁcation techniques to identify LTI
systems operating on closed-loop. Automatica, 29, pp. 1027–1040.
– (1994). Identiﬁcation of the deterministic part of MIMO state space models given in innovations
form from input–output data. Automatica, 30 (1), pp. 61–74.
Verhaegen, M. and P. Dewilde (1992a). Subspace model identiﬁcation, Part 1: The output-error
state-space model identiﬁcation class of algorithms. International Journal of Control, 56 (5),
pp. 1187–1210.
– (1992b). Subspace model identiﬁcation, Part 2: The output-error state-space model identiﬁcation
class of algorithms. International Journal of Control, 56 (5), pp. 1211–1241.
Verhaegen, M. and V. Verdult (2007). Filtering and System Identiﬁcation. Cambridge, UK: Cam-
bridge University Press.
Verhaegen, M. and X. Yu (1995). A class of subspace model identiﬁcation algorithms to identify
periodically and arbitrarily time-varying systems. Automatica, 31 (2), pp. 201–216.
Vörös, J. (2003). Modeling and identiﬁcation of Wiener systems with two-segment nonlinearities.
IEEE Transactions on Control Systems Technology, 11, pp. 253–257.
Wahlberg, B. and L. Ljung (1981). Design variables for bias distribution in transfer function esti-
mation. IEEE Transactions on Automatic Control, AC-31, pp. 134–144.
Walker, G. (1931). On periodicity in series of related terms. Proceedings of the Royal Society of
London. Series A, 131, pp. 518–532.
Wallin, R. and A. Hansson (2014). Maximum likelihood estimation of linear SISO models subject to
missing output data and missing input data. International Journal of Control, 87 (11), pp. 2354–
2364.
Wang, J., T. Chen and B. Huang (2004). Multirate sampled-data systems: computing fast-rate mod-
els. Journal of Process Control, 14, pp. 79–88.
Wang, S. and M. Tang (2004). Exact conﬁdence intervals for magnitude-squared coherence esti-
mates. IEEE Signal Processing Letters, 11 (3), pp. 326–329.
Welch, P. (1967). The use of fast Fourier transform for the estimation of power spectra: A method
based on time averaging over short, modiﬁed periodograms. IEEE Transactions on Audio Elec-
troacoustics, AU-15, pp. 70–73.
Whittaker, J. (1935). Interpolatory function theory. Vol. 33. Cambridge Tracts in Mathematics and
Mathematical Physics. Cambridge, UK: Cambridge University Press.
Widrow, B. and M. Hoﬀ(1960). Adaptive switching circuits. In: IRE Wescon Convention Record,
pp. 96–104.
Widrow, B. and S. Stearns (1985). Adaptive Signal Processing. Upper Saddle River, NJ, USA:
Prentice Hall.
Wiener, N. (1930). Generalised harmonic analysis. Acta Mathematica, 35, pp. 117–258.
– (1949). Extrapolation, Interpolation and Smoothing of Stationary Time Series. New York, USA:
Technology Press and Wiley.
Wold, H. (1938). A Study in the Analysis of Stationary Time Series. Sweden: Almqvist and Wiksell.

828
References
Wold, H. (1972). Nonlinear iterative partial least squares (NIPALS) modeling: some current devel-
opments. In: Multivariate Analysis II. Ed. by P. Krishnaiah. New York: Academic Press, pp. 383–
407.
Wold, S., M. Sjöström and L. Eriksson (2001). PLS-regression: a basic tool of chemometrics. Chem.
Intell. Lab. Sys, 58, pp. 109–130.
Yan, X. and X. G. Su (2009). Linear Regression Analysis: Theory and Computing. Singapore: World
Scientiﬁc Publishing Co. Pvt. Ltd.
Yeredor, A. (2000). The extended least squares criterion: minimization algorithms and applications.
IEEE Transactions on Signal processing, 49 (1), pp. 74–86.
Young, P. C. (2011). Recursive Estimation and Time-Series Analysis: An Introduction for the Student
and Practitioner. 2nd edition. London, UK: Springer.
Yule, G. (1927). On a method of investigating periodicities in disturbed series, with special reference
to Wolfer’s sunspot numbers. Philosophical Transactions of the Royal Society London, Series A,
227, pp. 267–298.
Zadeh, L. (1962). From circuit theory to system theory. IRE Proceedings, 50 (856-865).
– (1965). Fuzzy sets. Information and Control, 8, pp. 338–353.
– (1975). Fuzzy logic and approximate reasoning. Synthese, 30, pp. 407–428.
Zarchan, P. and H. Musoﬀ(2008). Fundamentals of Kalman Filter: A Practical approach. 3rd edi-
tion. Virginia, USA: American Institute of Aeronautics and Astronautics.
Zhang, J. (2013). Advancements of outlier detection: A survey. ICST Transactions on Scalable
Information Systems, 13 (01-03), pp. 1–26.
Zhang, Q. and A. Benveniste (1992). Wavelet networks. IEEE Transactions on Neural Networks,
3 (6), pp. 889–898.
Ziegler, J. and N. Nichols (1942). Optimum settings for automatic controllers. Transactions of the
ASME, 64, pp. 759–765.
Zoubir, A. M. and D. R. Iskander (2004). Bootstrap Techniques for Signal Processing. Cambridge,
UK: Cambridge University Press.

Process
(Unknown)
Input 
u[k]
(Probe 
signal)
Output 
y[k]
(Observed 
response)
Identification
Model
FIGURE 1.1
Identiﬁcation is the task of using input-output data to build a model: a mathematical
abstraction of the process.
Disturbances
Measurable
Process
Actuators
System that is actually identiﬁed by the user
Output
Input
signals
Sensors
Measurements
of responses &
disturbances
Sensor Noise
FIGURE 1.6
The system being identiﬁed consists of the true process and additional elements.

Model Development
Data Generation and Acquisition
Sensors
PROCESS
Inputs
Disturbances
Measurable
DATA
Select Candidate 
Models
VISUALIZATION
PRE-PROCESSING
NON-PARAMETRIC 
ANALYSIS
MODEL 
ESTIMATION
Estimation
Criteria
MODEL QUALITY 
ASSESSMENT
Satisfactory?
Prior 
Knowledge
No
Yes
MODEL
Residual Analysis
Estimation Error Analysis
Cross-Validation
...
Actuators
Outputs
FIGURE 1.7
A generic iterative procedure for system identiﬁcation.

Linear
Non-linear
Time-varying
Time-invariant
Deterministic
Stochastic
Multiscale
Single-Scale
Discrete
Continuous
Dynamic
Static
Distributed
Lumped
First-Principles
Models
Empirical
FIGURE 3.2
Types of models.
Empirical Models
Parametric
Non-parametric
Models do not possess
any speciﬁc structure
but usually described
by responses (responses
are not parametrized
Models possess a speciﬁc
 structure and are
characterized by delay,
order and a set of
parameters
Models are developed
using minimal process
knowledge. Parameters
cannot be (easily) related
to physical properties.
A priori knowledge is used
in model development.
Model Parameters (full/
partial set) have physical
Meaning.
Black-box
Grey-box
FIGURE 3.3
Four broad categories of empirical models.
+
Time-series modelling concepts
are used to build these models
Shock wave
(ﬁctitious, random)
Physical inputs
(Exogenous)
Process response
(Observed)
Stochastic
Deterministic
Contains eﬀects of noise,
unmeasured disturbances, etc.
Contains the physics or
explicable part of the process
+
FIGURE 3.4
Composite model from identiﬁcation.

0
0.5
1
1.5
2
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time
Amplitude
(a) Two continuous-time signals with F1 = 1 Hz and F2 = 5 Hz
0
0.5
1
1.5
2
−1
0
1
Amplitude
Sampled Signals at Fs = 4 Hz
0
0.5
1
1.5
2
−1
0
1
Time
Amplitude
(b) Sampled versions at Fs = 4 Hz
FIGURE 6.4
Incorrect sampling rates can result in ambiguous discrete-time signals.

Confounding
variable
Conditioning
Direct link
Y
X
Z
X.Z
Y.Z
Z
FIGURE 7.3
Schematic illustrating confounding and conditioning.

100
50
0
–50
–100
0
500
1000
Time
Flow
1500
2000
(b) Stationary, Periodic
600
500
400
300
200
100
1950
1952
1954
1956
Time
AirPassengers
1958
1960
(c) Non-stationary
FIGURE 7.6
Examples of stationary and non-stationary time-series.

0
20
40
60
80
−2.5
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
2.5
Samples
Amplitude
True
Estimated
FIGURE 10.2
Comparing the signal estimate using the inverse FT method and the true signal in Example
10.1.
0
0.2
0.4
0.6
0.8
−1
−0.5
0
0.5
1
Time
Amplitude
Fourier Decomposition of a Square Wave
Original
Fundamental
3rd harmonic
5th harmonic
(b) Fourier decomposition
FIGURE 10.5
Power spectral and Fourier decomposition of the square wave in Example 10.5.

ˆθ
θ0
Objective
(Loss) Function
True value
Estimate
Conﬁdence region
Model/
Constraints
Estimator
Known
information set
Z
FIGURE 12.1
Schematic illustrating generic estimation.
−10
−5
0
5
10
0
0.005
0.01
0.015
0.02
0.025
0.03
θ
f(θ|y)
Prior and Posterior p.d.f.s
Prior
After N = 1
N = 10
N = 100
FIGURE 15.1
Prior and posterior p.d.f.s of mean in Example 15.2.

0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
Normalized Length
w[k]
Hanning
Bartlett
Blackman
Flat top
Rectangular
(a) Time-domain proﬁles
−10
−8
−6
−4
−2
0
2
4
6
8
10
−120
−100
−80
−60
−40
−20
0
Frequency Oﬀset (bins)
dB (normalized)
Hanning
Bartlett
Blackman
Flat top
Rectangular
(b) Normalized magnitude (in dB), |W(ω)|/N
FIGURE 16.5
Window functions and the magnitudes of their Fourier transforms.

0
1
2
3
0.2
0.4
0.6
0.8
Single Realization: N = 250
ω
PSD
0
1
2
3
0.2
0.4
0.6
0.8
1
1.2
Single Realization: N = 2000
ω
PSD
0
1
2
3
0.1
0.15
0.2
ω
PSD
0
1
2
3
0.1
0.15
0.2
ω
PSD
0
5
10
15
20
0
200
400
600
800
PSD (ω = 0)
Count
0
5
10
15
20
0
200
400
600
800
PSD(ω = 0.4 π)
Count
Averaged
True
Averaged
True
FIGURE 16.8
(Top panel) Periodograms from a single realization with N = 250 and N = 2000 obser-
vations; (Middle panel) Averaged periodograms from 1000 realizations; (Bottom panel)
Distribution of ˆγ(0)/γ(0) and 2ˆγ(0.4π)/γ(0.4π) obtained from 1000 realizations.
Input
Procss
Model
Noise
Model
Stochastic
eﬀect
White-noise
(ﬁctitious)
Observed
output
u[k]
y[k]
e[k]
v[k]
+
+
FIGURE 17.1
Input-output representation of adeterministic-plus-stochastic LTI system.

3.5
3
2.5
2
1.5
1
0.5
0
–0.5
–1
–1.50
10
20
Time (Sampled)
Amplitude
Regularized
Impulse Response Estimates
Ordinary
30
40
50
(a) Regularized and ordinary estimates
3.5
3
2.5
2
1.5
1
0.5
0
–0.5
–1
–1.50
10
20
Time (Sampled)
Amplitude
Regularized
IR Estimates and True Values
True
30
40
50
(b) Regularized estimates and true coeﬃcients
FIGURE 20.2
Estimates of IR coeﬃcients with regularization for the process in Example 20.2.

−30
−20
−10
0
10
20
30
−0.2
0
0.2
0.4
0.6
lag
ρε u [l]
0
5
10
15
20
25
−0.5
0
0.5
1
lag
ρε ε [l]
(a) Residual correlation plots
0
5
10
15
20
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ACF of Input
Lags
(b) ACF of inputs
FIGURE 22.7
Residual analysis of the model and ACF of the inputs used in Example 22.5.

0
2
4
6
8
10
12
−1
0
1
2
3
4
5
6
Log of Singular Values
Model Order
Red: Default Choice (2)
Select Model Order in Command Window.
FIGURE 23.5
Plot of Hankel singular values for the system in Example 23.6.
0
2
4
6
8
10
12
−1
0
1
2
3
4
5
Log of Singular Values
Model Order
Red: Default Choice (2)
Select Model Order in Command Window.
FIGURE 24.10
Plot of Hankel singular values.

FIGURE 24.11
Loss functions for ARX models with diﬀerent numerator and denominator polynomial
orders.
0
2
4
6
8
10
12
−1
0
1
2
3
4
5
6
Log of Singular Values
Model Order
Red: Default Choice (2)
FIGURE 24.19
Hankel singular values.

1
Amplitude
Period
Spectral Density
4
8
16
32
64
0
0.2
50
100
150
200
250
1/8
1/4
1/2
1
2
4
4
8
16
32
64
8
0.4
0.5
0
–0.5
50
100
150
200
250
(a) Sine wave corrupted by an impulse
10
Amplitude
Period
Spectral Density
8
4
16
32
64
128
8
4
16
32
64
128
0
100
200
300
Time
400
500
1/16
1/8
1/4
1/2
1
2
4
8
16
5
0
–10
100
200
300
400
500
(b) Industrial control loop measurement
FIGURE 25.4
Normalized scalograms of two diﬀerent signals.

u[k]
r[k]
r1[k]
y[k]
e[k]
v[k]
+
+
Controller
Set-point
Dither signal/
Input noise
+
+
+
–
FIGURE 25.13
A typical closed-loop setup with the signals of interest in identiﬁcation.


