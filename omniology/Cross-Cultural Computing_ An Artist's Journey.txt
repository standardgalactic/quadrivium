Springer Series on Cultural Computing
Naoko Tosa
Cross-Cultural 
Computing: 
An Artist's 
Journey
www.allitebooks.com

 Springer Series on Cultural Computing
Editor-in-Chief
Ernest Edmonds, University of Technology, Sydney, Australia
Editorial Board
Frieder Nake, University of Bremen, Bremen, Germany
Nick Bryan-Kinns, Queen Mary University of London, London, UK
Linda Candy, University of Technology, Sydney, Australia
David England, Liverpool John Moores University, Liverpool, UK
Andrew Hugill, De Montfort University, Leicester, UK
Shigeki Amitani, Adobe Systems Inc., Tokyo, Japan
Doug Riecken, Columbia University, New York, USA
Jonas Lowgren, Linköping University, Norrköping, Sweden
www.allitebooks.com

 More information about this series at   http://www.springer.com/series/10481  
www.allitebooks.com

 Naoko  Tosa 
 Cross-Cultural Computing: 
An Artist’s Journey  
www.allitebooks.com

 ISSN 2195-9056 
    ISSN 2195-9064 (electronic) 
 Springer Series on Cultural Computing 
 ISBN 978-1-4471-6511-8    ISBN 978-1-4471-6512-5 (eBook) 
 DOI 10.1007/978-1-4471-6512-5 
 Library of Congress Control Number: 2015957194 
 Springer London Heidelberg New York Dordrecht 
 © Springer-Verlag London  2016 
 This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of 
the material is concerned, speciﬁ cally the rights of translation, reprinting, reuse of illustrations, recitation, 
broadcasting, reproduction on microﬁ lms or in any other physical way, and transmission or information 
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology 
now known or hereafter developed. 
 The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication 
does not imply, even in the absence of a speciﬁ c statement, that such names are exempt from the relevant 
protective laws and regulations and therefore free for general use. 
 The publisher, the authors and the editors are safe to assume that the advice and information in this book 
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the 
editors give a warranty, express or implied, with respect to the material contained herein or for any errors 
or omissions that may have been made. 
 Printed on acid-free paper 
 Springer-Verlag London Ltd. is part of Springer Science+Business Media (www.springer.com) 
 Naoko  Tosa 
 Kyoto University 
 Kyoto ,  Japan  
www.allitebooks.com

v
 Foreword 
 The Cultural Computing Series is showing how the centre of computing has moved 
away from the concerns of the technology itself, and the early technically oriented 
applications, into the much more signiﬁ cant domain of the very culture of our lives. 
For a long time now we have seen the importance of computing in every aspect of 
work, from the manufacturing plant to the ofﬁ ce and the corner shop. The tight 
coupling of computer developments with communications technologies has enabled 
the construction of the Internet and the Web, without which many people today feel 
completely lost. This all-pervasive presence of computing very naturally changes 
the cultural context of our lives. It changes our relationships, our understanding of 
others, our international perspectives and, more and more, the way that we make 
and relate to art and entertainment of almost every form. 
 To take one example, innovation in the products and systems that surround us 
comes from design. Innovation in design is frequently inspired by art. Art is where 
we can ﬁ nd signiﬁ cant pointers to the future of computing and its likely impact on 
the world around us. 
 Another example is that today, through the new technologies, we cross cultural 
boundaries with ease. On the day that I am writing this I am having physical meet-
ings with people in England and virtual ones with people in both Australia and 
China. This does not mean that cultural differences disappear, but it at least means 
that they become more obvious and important. Will there be one global culture in 
the future? Will new cultural patterns emerge? 
 This book tackles these issues from the perspective of a cross-cultural artist to 
whom technology is central. Her experience and knowledge place her in an ideal 
position to illuminate several key aspects of cultural computing. Although this is not 
the ﬁ rst book in the series, conversations with Naoko Tosa were important in form-
ing the idea of creating Springer’s Cultural Computing books. Her story is a special 
one today but one that may be a model of many stories of the future. 
 Peak District, UK 
 Ernest  Edmonds 
 November 2015 
www.allitebooks.com

                 
www.allitebooks.com

vii
 Acknowledgments 
 Art and technology research that began in the 1960s has, to this point, not been pres-
ent in the relatively disconnected culture of now. Indeed, as for culture and comput-
ing, this is perhaps the biggest challenge. However, for me, there is a working 
relationship between art and technology research, and it seems that now is the time 
when IT can be connected by the cloud network, for technology and culture link 
continents, creating a new digital cultural world. Through this book, it was my aim 
to express this idea to the world. However, the situation was complicated because 
this is a new concept, and therefore, it would not have been possible to publish a 
book in such a new genre. Under these circumstances, however, Springer has made 
the new genre possible via a new cultural computing genre. To achieve this endeavor, 
there were two people who made great efforts over the long run. Helen Desmond, 
editor of Springer, invited me to publish this kind of novel work. And, Professor 
Ernest Edmond, the editor of the  Cultural Computing series, was the ﬁ rst to recog-
nize the value of this book. First and foremost, I would like to express my sincere 
thanks to these two people – I am so grateful. Professor David J Dalsky, a colleague 
of mine at Kyoto University, did his best to brush up my English, and ﬁ nally, by my 
side, always, I wish to deeply thank Professor Ryohei Nakatsu, my partner in life. 
www.allitebooks.com

                 
www.allitebooks.com

ix
 Contents 
 1  Introduction – The Discovery of Cultural Computing ..........................  
 1 
 
 1.1 
 Media to Supplement Thinking and Memorization ...........................  
 1 
 
 1.1.1 
 The Transcendental (Cross-Cultural) Artist .........................  
 2 
 
 1.1.2 
 Cultural Poiesis ....................................................................  
 4 
 
 1.2 
 From Occidental Unconsciousness to the Eastern 
Shan Shui Paintings ...........................................................................  
 5 
 
 1.2.1 
 “Neuro-Baby” Connecting Here and There .........................  
 5 
 
 1.2.2 
 MIT Center for Advanced Visual Studies ............................  
 6 
 
 1.2.3 
 We Cannot Remove Our Culture..........................................  
 7 
 
 1.2.4 
 Technologies Combined with the Spirit ...............................  
 9 
 
 1.2.5 
 Meeting the Shan Shui Master .............................................  
 10 
 
 1.3 
 Cultural Structure Becomes a Communication Technology ..............  
 12 
 
 1.4 
 Characteristics of Japanese Language ...............................................  
 13 
 
 1.5 
 Japanese Design .................................................................................  
 14 
 
 1.6 
 Computers Do Not Have a Cultural Information Hierarchy 
that Is Indispensable for Symbiosis with Humans .............................  
 14 
 
References ...................................................................................................  
 15 
 2  Computing Feelings ..................................................................................  
 17 
 
 2.1 
 Media Art, Culture, and Feelings .......................................................  
 17 
 
 2.1.1 
 Mediation .............................................................................  
 17 
 
 2.1.2 
 The Deﬁ nition and Classiﬁ cation of Media Art ...................  
 18 
 
 2.1.3 
 Applications of Media Art to Culture...................................  
 20 
 
 2.1.4 
 Communication of Feelings Between Humans 
and Machines .......................................................................  
 23 
 
 2.1.5 
 Realizing Empathy ...............................................................  
 24 
 
 2.2 
 “Neuro-Baby”: Voice-Based Recognition/Generation of Feelings ....  
 25 
 
 2.2.1 
 Japanese Love the ‘Humanoid’ ............................................  
 25 
 
 2.2.2 
 Human Feeling Recognition and Generation .......................  
 26 
 
 2.2.3 
 A Cue to Birth ......................................................................  
 26 
 
 2.2.4 
 Predawn ................................................................................  
 27 
www.allitebooks.com

x
 
 2.2.5 
 Interactive Design of “Neuro-Baby” ....................................  
 28 
 
 2.2.6 
 Technology of “Neuro-Baby” ..............................................  
 29 
 
 2.2.7 
 Flow of the Entire System ....................................................  
 31 
 
 2.2.8 
 Phonetic Feature Extraction .................................................  
 31 
 
 2.2.9 
 Emotion Recognition ...........................................................  
 33 
 
 2.2.10  Emotion Recognition Engine Between 
Different Cultures ................................................................  
 34 
 
 2.3 
 Cross-Cultural E-mail Software with Emotion Translation ...............  
 35 
 
 2.3.1 
 Emotional Translation in E-mail ..........................................  
 35 
 
 2.3.2 
 Emotion Translation of E-mail Using “Neuro-Baby” ..........  
 36 
 
 2.3.3 
 Emotional Translation Character 
in a Computer Network .......................................................  
 38 
 
References ...................................................................................................  
 39 
 3  Computing Stories ....................................................................................  
 43 
 
 3.1 
 Transforming the Real World into the World of a Story ....................  
 43 
 
 3.2 
 Stories and Culture ............................................................................  
 45 
 
 3.3 
 A Computer Composes Renga (Japanese Interactive Poetry) 
with a Human .....................................................................................  
 46 
 
 3.3.1 
 Interactive Poem ...................................................................  
 47 
 
 3.3.2 
 Technology Used in This System .........................................  
 48 
 
 3.3.3 
 Debut of the Prototype of This Story System ......................  
 52 
 
 3.4 
 A Computer that Makes People Burst into Laughter .........................  
 52 
 
 3.4.1 
 Humor Is a Highly Internal Intelligence ..............................  
 52 
 
 3.4.2 
 Interactive Comic Dialogue .................................................  
 53 
 
 3.4.3 
 Technology Used in This System .........................................  
 54 
 
 3.4.4 
 “Interactive Comedy” Incident .............................................  
 58 
 
 3.4.5 
 Automatic Generation of Feelings and Stories: 
“Interactive Theatre” ............................................................  
 59 
 
 3.5 
 Interactive Theatre Generates Feelings and Stories ...........................  
 59 
 
 3.5.1 
 Story Generation ..................................................................  
 59 
 
 3.5.2 
 Story Interactivity .................................................................  
 60 
 
 3.5.3 
 System Features ...................................................................  
 61 
 
 3.5.4 
 Software Composition ..........................................................  
 62 
 
 3.5.5 
 The Future of Digital Storytelling ........................................  
 65 
 
References ...................................................................................................  
 65 
 4  Computing Culture ...................................................................................  
 67 
 
 4.1 
 Picking Up Cultural Information .......................................................  
 67 
 
 4.2 
 Visualizing Communication ..............................................................  
 70 
 
 4.2.1 
 System Conﬁ guration ...........................................................  
 70 
 
 4.2.2 
 Synchronization Interaction Model ......................................  
 71 
 
 4.2.3 
 Software Conﬁ guration ........................................................  
 74 
 
 4.2.4 
 Biofeedback from Heart Sounds ..........................................  
 74 
 
 4.2.5 
 The Staging of the Installation .............................................  
 76 
 
 4.2.6 
 From the Unconsciousness to Zen and Sansui .....................  
 76 
Contents

xi
 
 4.3 
 Sansui Zen Using Computers “Art of ZEN” ......................................  
 77 
 
 4.3.1 
 Cultural Differences and Taboos ..........................................  
 77 
 
 4.3.2 
 Japanese Culture Used in Cultural Computing ....................  
 79 
 
 4.3.3 
 Meeting the “Art of ZEN” ....................................................  
 80 
 
 4.3.4 
 ‘Ma’ Interaction ....................................................................  
 80 
 
 4.3.5 
 Drawing Up a Scenario of Sansui Experience 
in the Clouds ........................................................................  
 81 
 
 4.3.6 
 The Contexts Generated by the Sansui Symbols .................  
 83 
 
 4.4 
 Sansui Perspective Method—Sanen ..................................................  
 83 
 
 4.4.1 
 Playing with Sansui Paintings (Interactions 
with Allegories and Symbols) ..............................................  
 85 
 
 4.4.2 
 Eastern Human Recognition Model .....................................  
 86 
 
 4.4.3 
 Zen Dialogue Interactions ....................................................  
 87 
 
 4.4.4 
 Controlling Ma with the Chaos Engine ................................  
 90 
 
 4.4.5 
 Computing the Yuzen Kimono Patterns of Kisoi, 
Awase, and Soroe .................................................................  
 92 
 
 4.4.6 
 Interactive Ten Oxherding Pictures Story ............................  
 92 
 
 4.5 
 Opening, Traveling, and Living in Sansui Zen ..................................  
 94 
 
 4.5.1 
 The Death of Prof. Stephen Benton and the Exhibition .......  
 95 
 
 4.5.2 
 “Art of ZEN” at Ubiquitous House ......................................  
 96 
 
 4.5.3 
 Computing the Spirituality of Japanese Culture ..................  
 97 
 
 4.6 
 Computers Read the Situation ...........................................................  
 98 
 
 4.6.1 
 Generating Inspiration ..........................................................  
 99 
 
 4.6.2 
 The Forms of Thoughts ........................................................   100 
 
 4.6.3 
 Dictionary of Images ............................................................   101 
 
 4.6.4 
 Willful Chaos Search ...........................................................   102 
 
 4.6.5 
 “i.plot” – A Thought Space to Connect Images 
and Words ............................................................................   102 
 
 4.6.6 
 “i.plot” for Reading the Situation.........................................   103 
 
 4.7 
 “Hitch Haiku” of Tree Peony and Foo Dog .......................................   106 
 
 4.7.1 
 Hitching the Kanji ................................................................   106 
 
 4.7.2 
 “Hitch Haiku” Interactions ...................................................   107 
 
 4.7.3 
 Haiku Generation Process ....................................................   109 
 
 4.7.4 
 Database ...............................................................................   112 
 
 4.7.5 
 Discovery of Digital Haiku Aﬁ cionados ..............................   113 
 
 4.7.6 
 Haiku Generation with Lasting Impressions ........................   113 
 
 4.7.7 
 Appearance of Haiku Media ................................................   114 
 
References ...................................................................................................   115 
 5  Cultures, Subconscious and Creativity Software ...................................   117 
 
 5.1 
 Cultures from an Engineering Perspective ........................................   117 
 
 5.1.1 
 Interactive Digital Archives ..................................................   118 
 
 5.1.2 
 Media that Preserves Culture for Future Children ...............   118 
 
 5.1.3 
 Cultural Infrastructure ..........................................................   119 
Contents

xii
 
 5.2 
 What Computers Are Missing ...........................................................   121 
 
 5.2.1 
 Recognition of Computer Without Senses ...........................   121 
 
 5.2.2 
 Illiterate Computers ..............................................................   122 
 
 5.3 
 Why Computers Must Move Towards Culture ..................................   122 
 
 5.3.1 
 Cybernetics ...........................................................................   122 
 
 5.3.2 
 AI..........................................................................................   123 
 
 5.3.3 
 Artiﬁ cial Life ........................................................................   124 
 
 5.4 
 Computing Culture ............................................................................   124 
 
 5.4.1 
 Japanese Culture with Structures .........................................   124 
 
 5.4.2 
 A Deeply Asian View of the Uncovered World ....................   127 
 
 5.4.3 
 Western Visual Analogies .....................................................   128 
 
 5.4.4 
 Western View of Japan .........................................................   129 
 
 5.5 
 Visual Analogies of Kanji Connect the World ...................................   131 
 
References ...................................................................................................   133 
Contents

1
© Springer-Verlag London 2016 
N. Tosa, Cross-Cultural Computing: An Artist’s Journey, Springer 
Series on Cultural Computing, DOI 10.1007/978-1-4471-6512-5_1
 Chapter 1 
 Introduction – The Discovery of Cultural 
Computing  
1.1  Media to Supplement Thinking and Memorization 
 “The ethnic crisis, the urban crisis, and the education crisis are interrelated. If 
viewed comprehensively, all three can be seen as different facets of a larger crisis, a 
natural outgrowth of man having developed a new dimension – the cultural dimen-
sion – most of which is hidden from view. The question is, how long can man afford 
to consciously ignore his own dimension?” This phrase is from the book, “ The 
Hidden Dimension (Hall  1990 ),” by an American anthropologist and cross-cultural 
researcher, Edward T. Hall. 
 Nowadays, computers play many important roles in our lives. Smartphones, 
e-mail, Websites, games, and personal computers (PCs) are an integral part of our 
lives, and every facet is used as media (McLuhan  1994 ). While computers were 
initially simply high-grade calculators, media have developed their use into supple-
menting thinking and memorization. 
 Consider the relationship between traditional customs and computers. Computers 
are often used for calculations, to store data, or for historical simulation. Fading 
cultures can be archived using computer technology to supplement memorization, if 
only to a limited extent, but this is not an optimal application of computer capacity 
because these machines are fully-ﬂ edged multimedia devices with the beneﬁ t of 
being able to be networked together. Nowadays, as people often communicate with 
other people of different cultural backgrounds, they are expected to understand the 
histories of other cultures as well as their own. Because the typical methods for 
understanding a culture involve reading books about the culture or visiting relevant 
museums, it is not easy to understand another culture by merely ﬁ nding the appro-
priate information. Could the development of information technology help us 
understand a culture by using computers as media to supplement thinking and mem-
orization, which has become more suitable for networking, mobile connections, and 
two-way communication? 

2
 This book explores the topics of art and technology, culture and technology, and, 
based on the integration of these two different concepts, ﬁ nally discusses a new 
world where both creators and consumers can reach a deep mutual understanding. 
These topics are the ﬁ eld of cultural computing (Rauterberg et al.  2010 ); that is, 
using computing to explore the essence and inner lives of cultures, including sensi-
tivity, national traits, and folklore. The essence of cultural computing integrates 
verbal and nonverbal information, which proposes a prosperous ﬁ eld in which com-
puters can improve the exchange of cultural information by using cultural models. 
Cultural computing, which is essential for the communication abilities of future 
computers that are now being introduced, is a new ﬁ eld that utilizes the actions and 
mannerisms of humans in each culture and history to share common or peculiar 
aspects by demonstrating some concrete methodology and examples. 
1.1.1  The Transcendental (Cross-Cultural) Artist 
 What is the aim of art? This is a multi-faceted question, but if I dare to give a short 
answer, it is “the visualization of the status of someone’s heart (Tosa  2010 ).” I have 
been interested in this idea since I was very young. 
 I became interested in surrealism after being inﬂ uenced by my art teacher in both 
my junior and high school. I was inﬂ uenced by the techniques and perspectives of 
various surrealism artists, from Salvador Dali, Max Ernst, and Rene Magritte, to 
Pierre Molinier. I was particularly interested in the ‘automatic’ method that many 
surrealists used in their mind’s creative visualization process. Some examples of 
such methods are the following: frottage (taking a pencil or other drawing tool and 
making a rubbing over a textured surface), decalcomania (placing a paper on top of 
another painted paper, pressing the paper against the painted paper, and copying the 
drawing on the separate paper) and marbling (creating beautiful patterns similar to 
marble by dropping paper ink into water, taking out the paper, and copying the 
design and intricate pattern drawn on the surface of the water). 
 I was inspired by surrealism because of the following reasons. When creating an 
artwork using an automatic method such as decalcomania, the intention of the 
author is not explicitly expressed in the created artwork. However, we can say that 
these methods make it possible for his/her unconscious intention to be expressed to 
some extent. Additionally, as the appearance of the created pattern is not directly 
controlled by the author, but is indirectly or unconsciously controlled, the artwork 
would appeal to the unconsciousness of its audience effectively. I have also taken an 
interest in images that may produce dualistic abstract thoughts such as ‘good and 
evil,’ ‘negative and positive,’ and so on. I have looked for a way to express these 
indeﬁ nable thoughts as art. 
 After graduating from high school, I became involved in modern art and the idea 
that I could better visualize my feelings through physical expression such as paint-
ings, ﬁ lms, etc. I also took part in theatre. After that, my interests shifted to ﬁ lm; I 
have created experimental movies and video art pieces. Little by little, I began to use 
1 Introduction – The Discovery of Cultural Computing

3
technology for the purpose of expression. I began creating graphics using computer 
software, and began creating complete artworks using technology. To supplement 
this work, I started to create interactive artworks; expressed using computer graph-
ics, these artworks transform themselves based on user interactions. 
 What have I created through these works? Looking back at these works, which 
came from the heart, I think that I have expressed human emotions, memories, and 
the underlying signs and signiﬁ ers of communication. Of course, to realize my artis-
tic expressions, my working environment slowly changed. 
 I had studied at a university for the arts, but at the same time I aspired to study at 
some high-technology laboratory or university. I devoted myself to research and 
creating new art; I was always looking for the best way to express my art as time 
passed. During this process, I became determined to be a ‘cross-cultural’ artist and 
transcend the ﬁ eld of art itself, rather than to be simply an artist. 
 Artworks made with technology are called ‘media arts’ or ‘interactive arts’ t but 
if an artist relies exclusively on technology to create works of art, the resulting work 
is not interesting in itself. However, the expression of art in the context of technol-
ogy or pursuit of technology in the context of art is quite interesting. 
 The value of art contrasts with the value of technology. Great pieces of art have 
universal values that may possibly never fade. In contrast, old technology is often 
discarded and surpassed by new technology. Media art can transcend its parts and 
create a new relationship between art and technology, which inﬂ uences other ﬁ elds. 
In other words, art transcends technology as technology transcends art. 
 I was conscious of my journey to become a ‘cross-cultural’ artist, and I deter-
mined that my next step would be to obtain a global perspective, instead of merely 
communicating an ordinary Japanese perspective. I moved my base of research 
activity to the Massachusetts Institute of Technology (MIT) in Boston, MA. While 
there, I saw a true difference between cultures. I noticed differences not only in our 
daily life, but also in the feelings, memories, signs, and unconscious communica-
tions that were strongly related to American culture. I noticed that, although I had 
tried to express art generally, alongside my globalized artistic expressions there 
were some that were characterized as being extremely Japanese. 
 At ﬁ rst, I tried to assimilate myself into American culture, but I quickly realized 
that my strong Japanese heritage meant that becoming accustomed to American 
culture would be difﬁ cult. Regardless, I paid attention to the actions and manner-
isms that were considered as ‘Japanese culture’ in America, and then I tried to 
express the difference between American and Japanese actions and mannerisms in 
the arts. 
 At that time, I became acquainted with the Shan shui, 1 ‘mountain-water’ paint-
ings by Sesshū Tōyō, 2 a Japanese master of Shan shui. Shan shui paintings are 
1  Shan shui (山水 in Japanese) painting came from a style of Chinese painting. Shan shui, the 
translation of which is ink and wash painting, involves or depicts scenery or natural landscapes that 
are created using a brush and ink rather than more conventional paints. 
2  Sesshū Toyo (1420–8 August 1506) was the well-known Japanese master of Shan shui painting 
from the middle Muromachi period. After studying at Sokokuji Temple in Kyoto to become a Zen 
1.1 Media to Supplement Thinking and Memorization

4
 landscape paintings depicting imagined scenery. This is related to the psychology of 
the unconscious in Carl Gustav Jung’s analytical psychology (Jung  1968 ). I 
researched the way of unconscious communication to understand other cultures by 
exploring and using the components of unconsciousness in Shan shui paintings. 
 I succeeded in creating an interactive artwork, the “ZENetic Computer (Tosa and 
Matsuoka  2006 ),” by modeling the structures of Zen and Shan shui, which are 
thought to be strong representations of Japanese culture. After that, I created the 
kanji (Chinese characters)-inspired “i.plot (Tosa et al.  2005 ),” which displays rela-
tionships between psychological associations and graphical images as ideograms. 
Still later, I produced the “Hitch Haiku (Tosa et al.  2009 )” system, which allows the 
user to create a haiku poem from kanji input, using the standard haiku template of 
5–7–5 characters. 
 Surprisingly, when I published these works overseas, for example, at MIT, many 
Americans showed an understanding of them. For these artworks to have become 
media that people in other cultures can understand, they have transcended time in 
the form of history and culture, and transcended space in the form of geographic 
distance, by picking up the structure of traditional Japanese culture through 
computers. 
1.1.2  Cultural Poiesis 
 In continuing these studies, I discovered that I could surpass these methods of art 
and technology. Interactive works using computer models of Japanese culture can 
act as a new form of media that enables all people to understand other cultures by 
experiencing them. Thus, various speciﬁ c features within traditional Japanese cul-
ture that are thought to be peculiar by other cultures will cease to be a hindrance in 
cultural exchange. 
 Many people worldwide can now create their own haiku or experience Zen. 
Using computers and a traditional cultural model, we can show people the world of 
traditional Japan. Of course, computers can model not only Japanese cultural meta-
phors, but also, for example, the works of Shakespeare, or even Kabuki, composed 
as if in the Globe Theatre. I think that in this way, cultural computing may even be 
paving the way for new cultures to emerge. 
 I noticed that computers have an appropriate feature for creating these new cul-
tures. Computer processes are divided into thousands of complex algorithms to 
work with data, but the interface we are often presented with is so simple. Handling 
cultural exchanges using a computer is what will lead to the creation of new cul-
tures. The culture we will see in that context is a poiesis (meaning ‘creation’ in 
Greek) of communication between different cultures. 
Buddhist, he went to China at the time of Song Dynasty and studied landscape paintings. Although 
inﬂ uenced by the Chinese painting style, after coming back to Japan he established his own land-
scape painting style. 
1 Introduction – The Discovery of Cultural Computing

5
 Pride for my mother country made my perspective increasingly patriotic, and I 
became more cautious to avoid just going along with things abroad. I obtained two 
different perspectives; namely, what Japan should be as seen by the world, and what 
the world should be as seen by Japan. With those perspectives, I could look at every-
thing calmly and clearly. When I noticed this for the ﬁ rst time in my life, I had the 
impulse to write a book and teach this perspective to others. 
1.2  From Occidental Unconsciousness to the Eastern Shan 
Shui Paintings 
1.2.1  “Neuro-Baby” Connecting Here and There 
 I am from the postwar generation, when American culture was widely available in 
TV shows after I was born. This exposure was the reason behind my unconscious 
interest in surrealism during adolescence and eventually I learned about Jung’s psy-
choanalysis of unconsciousness. After that, I began to express something intangible 
in my art, such as consciousness or feelings. That is why I started to create computer 
characters—characters in virtual reality (VR) through which we, as humans, could 
communicate with each other. 
 At that time, computers were still in an evolutionary phase between workstations 
and PCs. When I saw a PC for the ﬁ rst time, my intuition told me that it had func-
tionality comparable to a human. I wanted to create a grown-up human and make 
him or her talk, by visualizing an internal consciousness, about his or her feelings. 
 In the ﬁ eld of artiﬁ cial intelligence (AI), many researchers worked on computers 
that could talk with humans. However, their conversations were almost conven-
tional verbal exchanges that were programmed in advance. We cannot help feeling 
that we are forced to talk along certain language or thought patterns. Conversations 
should be fresh, enjoyable, and ﬂ ow freely. 
 I created “Neuro-Baby (Tosa and Nakatsu  1996 )” based on these ideas. This 
baby computer character cries, laughs, and performs various other actions based on 
the user’s vocal expressions. When I announced it in an international conference, it 
became the center of attention of researchers in the ﬁ elds of AI and robotics. I did 
not know why at the time, but now I think it is because this was their blind spot; 
“Neuro-Baby” aimed to have the feeling of a conversation in any exchange, instead 
of their aim, which was to exchange or communicate information. 
 A festival called “Artiﬁ cial Life” took place at Ars Electronica in 1993. Studies 
and artworks used computers and robots aimed at simulating lifelike evolution or 
humanization by using theories behind biological and neural networks. There, I met 
an eccentric person who watched “Neuro-Baby” many times, and spoke to it in a 
funny tone. After a casual greeting, I realized that he was Rodney Brooks, a world-
wide authority from MIT in the ﬁ eld of AI and robotics. 
1.2 From Occidental Unconsciousness to the Eastern Shan Shui Paintings

6
 AI and robotic technologies meet in interactive art. I felt that technology was 
approaching art in a new way. I also met Thomas Ray, who was studying artiﬁ cial 
life in the biology department at Advanced Telecommunications Research Institute 
International (ATR). 3 At that time, few people were creating interactive art, and 
there was no concrete authority in this ﬁ eld. 
 I met Dr. Tokura Yoichi, who was the president of the Human Information 
Communication Research Laboratories at ATR [12]. I studied sound using babies at 
ATR, where I was employed as guest researcher at a new laboratory: Media 
Integration and Communications Research Laboratories. While there, among many 
technological researchers, I studied the mechanism of communication using feel-
ings from 1995 to 2001. 
 Is technology using art? Or is art using technology? Looking back at this period, 
I realize that I focused on the essential component of human communications, their 
art, rather than their technology. I think I spent more time visualizing art than using 
technology. Communication is a deeply instinctive action, and includes many inter-
esting phenomena. First, I focused on handling nonverbal information, such as feel-
ings, by starting with “Neuro-Baby,” and then I began to work on verbal 
information. 
 Typical examples of nonverbal information are feelings, but these contain much 
more information than they initially suggest, from simple feelings like happiness, 
anger, sadness, and comfort, to sensitivity and the unconscious. Therefore, tackling 
these problems can enable us to have interactive visualization of feelings, sensitiv-
ity, and the unconscious.  
1.2.2  MIT Center for Advanced Visual Studies 
 After I left the Media Integration and Communications Research Laboratories at 
ATR, I stayed in Boston as a fellow of the MIT Center for Advanced Visual Studies 
(CAVS) from 2002 to 2004. 
 The history of art and technology starts from the avant-garde art group, 
Experiments in Art and Technology (EAT), which acted in the latter half of the 
1960s. The main members of this group were engineers employed in the Bell 
Telephone Laboratory at AT&T. Famous contemporary artists, such as American 
pop artist Robert Rauschenberg, and American composer John Milton Cage Jr., set 
a foothold in New York and participated in and carried out activities that crossed the 
borders of art, dance, music, and video production, and pursued the borderline 
between art and technology. EAT is the original organization of CAVS established 
at MIT in 1967. A Hungarian painter György Kepes, who had defected to America 
3  ATR is a unique private company established in the Kansai region in Japan in March 1986, based 
on the broad support of industrial companies such as NTT, NEC, Hitachi, Fujitsu, etc. and the 
Japanese government. Its aim is to promote fundamental and innovative R&D activities as well as 
to contribute to society in a wide range of telecommunication ﬁ elds in Japan. 
1 Introduction – The Discovery of Cultural Computing

7
and become a professor of architecture, also joined EAT. He prompted large move-
ments in various ﬁ elds such as urban life, environment and life, the fusion of art and 
science, as well as architecture. Kepes founded CAVS and became its director. 
CAVS has the longest history as a laboratory of art and technology (and it is now on 
the third ﬂ oor of the MIT Museum, above the main gallery). It was a pioneer of 
performance and collaboration, and its inﬂ uence on the newer generations is quite 
profound. 
 One of the famous artists who once stayed at CAVS is Nam June Paik, a Korean- 
American artist. He used a variety of media in his artworks and is considered the 
ﬁ rst video artist. Another artist, Charlotte Moorman, was a cellist who collaborated 
with Paik. She performed in Paik’s “TV Bra for Living Sculpture (1969)” with two 
small television sets attached to her breasts. Scott Fisher was another member; he 
was an inventor of the head-mounted display, which is one of the key VR technolo-
gies. CAVS has been a source for unlocking human knowledge and explorative 
research about the art of the future. 
 Invited by Prof. Steve Benton, the fourth director of CAVS, I worked as a fellow 
at CAVS from 2002 to 2004. Prof. Benton is a recognized authority on the study of 
holography, and he invented the rainbow holograph. He is also one of the founders 
of the MIT Media Laboratory. He appointed me so that CAVS could change its 
direction from ‘art and science’ to ‘art and computers,’ which indicated a shift from 
analog to digital. My expected role was to bring in an Asian inﬂ uence of digital arts 
to CAVS, based on an idea that had been deeply rooted in European culture. Benton 
had a great appreciation of Japanese culture. In MIT, many people were interested 
in my work, but it was difﬁ cult for them to identify the fundamental value and/or 
meanings in my artworks. It seemed to me that only Prof. Benton understood my 
works. 
1.2.3  We Cannot Remove Our Culture 
 Have you ever been impatient in a conversation and thought, “why can’t the person 
I’m talking with understand what I’m trying to say?” The main issue is that we usu-
ally communicate with someone under the assumption that they should be able to 
understand us. However, communication is required to reach mutual understanding. 
If both sides understand this principle, then desirable communication can be 
achieved. 
 If everyone already understood each other, no one would need to communicate. 
Japanese people take strong pride in their homogeneous race, and are apt to have 
relatively similar feelings, impressions, and opinions about someone’s actions, phe-
nomena, and the direction of their society. It would be a direct communication from 
mind to mind, which is a common saying in Japan. They are prone to thinking 
something and expecting that someone should understand if it comes up in 
conversation. 
1.2 From Occidental Unconsciousness to the Eastern Shan Shui Paintings
www.allitebooks.com

8
 This Japanese characteristic becomes obvious when we go abroad. That is 
because we face a situation where we cannot make ourselves understood, even if we 
try to make ourselves easy to understand. Many other Japanese qualities do not 
appear normal while abroad, and it is like herbivores living with carnivorous 
animals. 
 In America, however, it seems that Anglo-Americans especially will often com-
municate while considering that a person cannot understand them. In fact, I found 
this behavior in colleagues with German, Greek, Lebanese, Japanese, Chinese, 
French, and Anglo-American backgrounds. Southern Europeans usually use non-
verbal communication similarly to the Japanese, which made me feel a sense of 
closeness. However, it is my experience that Americans keep their distance when 
they communicate. Somehow, they do not open their hearts, or they tend to hesitate 
to show their feelings. This fact shows that they communicate with a consideration 
that a person cannot understand them. The same situation sometimes occurs when 
we communicate with a computer. 
 In Boston, audio response systems often answer when we call to enter into con-
tracts with a telephone or a gas service. Computers speak, “My name is Alice (e.g.), 
please answer me to register.” “May I ask your name, please?” “May I ask your 
address?” These questions continue. However, speech recognition sometimes fails. 
Then the computer says, “I couldn’t recognize that. Please repeat it again.” 
Answering the computer about three times would be the limit of patience, but one 
of the better things about the American frontier spirit is a big-hearted disposition. 
 “Are people here really patient with computer operators?” I asked my friend. She 
told me, “Not really. They are rather annoying, and it is typically better to wait until 
a human operator gets on.” She said that such systems are meddlesome, and extend 
the time in which we decide something. This analysis also shows the difference 
between Japanese, who are accustomed to communicating tacitly, and Americans, 
who are accustomed to being verbose. 
 While I stayed in Boston, I realized from my experience that we should think of 
communication as occurring only when people cannot understand each other, while 
considering the differences of their cultures. Many times, I experienced the satisfac-
tion of empathy when I could communicate with someone with whom I thought 
communication was almost impossible. We cannot communicate vigorously with-
out this kind of experience. If we communicate not only through discovering our 
errors, differences, and empathies, but also by exchanging and amplifying our 
knowledge and feelings, communication will transcend cultures. 
 We have obtained global communication by adopting media technologies in 
face-to-face communication, which had previously been limited to small communi-
ties. E-mails, social networks, and blogs have enabled us to communicate more 
easily with people from around the world, overcoming the barriers of distance and 
culture. Conversely, many people feel communication has become increasingly 
shallow. Rather, these shallow communications have recently produced a typical 
face-to-face conversation, “Did you read my message?” Communications may be 
becoming extremely superﬁ cial because of the waning of individualized cultures. 
1 Introduction – The Discovery of Cultural Computing

9
 Ignoring this current trend will cause a decline in our ability to communicate, 
which has been a basic instinct since ancient times. We immediately need a new 
form of media for communication that can convey one’s depth of feeling across the 
borders between cultures. I could tell that this goal was possible during my 2 years 
in Boston. I wanted to create media with which we can communicate deep feelings 
that transcend cultures. I left Boston with this idea.  
1.2.4  Technologies Combined with the Spirit 
 In the latter part of July 2002, I visited western China for 10 days. The aim of this 
trip was to exchange information with Tibetan doctors and philosophers and to 
complete the ﬁ eldwork for my research theme by looking for communication prob-
lems among art, technology, and hearts. 
 First, I visited Xining, the capital of the Qinghai Province. The Gelug lineage 
and its founder, Je Tsongkhapa, along with the fourteenth Dalai Lama, originate 
from here. The religious precepts of the Gelug lineage are considered highly impor-
tant in this region. 
 Many tulkus, including the fourteenth Dalai Lama, practiced asceticism in the 
Kumbum Monastery (Ta’er), one of the six largest temples of the Gelug lineage. I 
inspected the temple in which 4000 monks practiced asceticism, and felt a great 
energy, or a sense of many people’s minds, ﬂ owing inside the temple, where many 
pagodas (stupas) were standing. 
 Tibetans believe that medicine and philosophy are the same. Doctors are philoso-
phers and Buddhist priests at the same time. I was impressed with the manner doc-
tors ﬁ rst used to see what was wrong with each patient’s inner heart. 
 Tibetan philosophy has a faith that gives freedom to all afﬂ icted lives. Their 
thoughts are deeply related to consciousness, feelings, space, and lives, centered on 
the bowels of mercy and wisdom. Their cosmic view has to do with our essential 
problems, the wheel of life, and existence. Many cultures in Tibet include Buddhist 
Tantra as the appreciation of the idea that life moves in cycles. 
 South of Xining is Kitoku, which is famous for its hot springs. A 3800 m high-
land is nearby. I visited a Tibetan tent (Yurt), and they offered us butter named 
Tsampa, yak milk, and dishes with barley in them. I remembered that I used to eat 
similar foods in my childhood and was impressed that Tibet and Japan share a lot of 
traditions. I returned to Xining and visited the Arura Tibetan Medical Center, where 
I discussed my work with ﬁ ve people, including the famous Dr. Denchi, the hierarch 
and Buddhist philosopher, and Dr. Tanjinja who is a Nyingma (spiritual exercise 
specialist in Tibetan Buddhism). When I referred to my spirituality of arts and the 
possibility of fusion between art and technology, they identiﬁ ed with my ideas and 
said, “It is a possible idea as a future ﬁ gure of religion.” This encouraged me greatly. 
 Tibetan Buddhists see the spirit of the bodhisattva as being very important. This 
means they must drop their tenacious desires and self-love and have altruistic love. 
I noticed that this spirit is deeply related to interactive art. 
1.2 From Occidental Unconsciousness to the Eastern Shan Shui Paintings

10
 Interactivity in art is shallow and the value is low if the purpose is self- 
assertiveness or communication of the artist’s feeling. What is important is the inter-
action between the spirit of the bodhisattva and altruistic love. That is, if computer 
systems succeed in interacting with the spirit of the bodhisattva, the interactivity of 
the system can deeply resonate with the spirit of other peoples’ cultures. 
 I knew from my visit to Tibet that their Buddhism, which was born in India, has 
been adjusting to the culture there and that the global consciousness remains. I was 
impressed with the fact that we Japanese and Tibetan Buddhists were able to under-
stand each other deeply within our spirits. I hoped to create something for Westerners 
so they could also understand Buddhism, using a technology-based expression in 
media. Then I came upon Sesshū, which critically affected my artwork after that. 
1.2.5  Meeting the Shan Shui Master 
 I encountered Sesshū, the most prominent Japanese master of the Shan shui paint-
ing who lived in the middle Muromachi period, at the exhibition “Sesshū – Special 
Exhibition at the 500th Anniversary of His Death” at Kyoto National Museum 
(Kyoto National Museum  1990 ) in 2002. I was fascinated by the world Sesshū had 
created. I had not had any particular special interest in Japanese culture before that. 
For some reason, the Shan shui world of Sesshū in that exhibition seemed to become 
a VR that fully expressed his heart in my eyes. 
 In ancient China, a Shan shui painting featured a landscape that we wanted to 
view forever, a place we wanted to go to play, a place we wanted to live, or a home-
town in our heart in which we wanted to pass away. Shan shui pictures are that type 
of imagined scenery. Its bleeding, cracked, feathering lines of ink draw the move-
ment of the heart. It makes us feel color even if it is in monochrome. 
 I had an inspiration to compute Shan shui pictures and the world of Zen Buddhism 
expressed in Shan shui pictures when I ﬁ rst saw the Shan shui pictures created by 
Sesshū. Zen makes us feel immersed in Japanese culture because of its absence of 
absolutes and beautiful sense of “Wabi-sabi. 4 ” Wabi-sabi is the aesthetic character-
istics speciﬁ c to Japanese culture that include asymmetry, simplicity, austerity, 
modesty, intimacy, and appreciation of the ingenuous integrity of objects and pro-
cesses. One good example of Wabi-sabi is a Japanese garden style that was ﬁ rst 
introduced from China, but became a new style by removing the water features from 
the original Chinese garden style. Many elements in Japanese culture are gathered 
in Shan shui, like the ume Shan shui (Shan shui with Japanese plums). I wanted to 
express these pictures and Zen culture, centered on Japanese Zen, in my art. 
4  Wabi-sabi is a Japanese aesthetic feeling that became apparent in the late Muromachi period and 
became shared by many Japanese throughout the Edo period. The thought such as “everything has 
to change” or “nothing is eternal” is the basis of Wabi-sabi. Based on such thoughts, Wabi-sabi 
emphasizes the beauty existing in something simple, old, small, and sometimes poor contrary to 
beauty in huge, gorgeous, new, and luxury objects. 
1 Introduction – The Discovery of Cultural Computing

11
 Culture is the integration of human behavior that includes attitudes, norms, val-
ues, beliefs, actions, communications and groups (ethnic, religious, social, etc.) 
(Kroeber and Kluckhohn  1952 ). Cultures have been created, changed, opposed, and 
fused with each other over time, and can be rational and irrational. Cultures that 
have both rationality and irrationality seem difﬁ cult to comprehend fully. 
 Almost all existing Japanese media artworks feature traditional contents like 
Noh 5 and Kabuki Theatre 6 with added interactive functions. These media artworks 
are seen as being superﬁ cial digital expressions, even though they are extensions of 
texts, images, videos, and combinational multimedia that explain traditional culture. 
The thing is that they are only an explanation and are not new art. What these media 
are doing is only to view the surface, instead of to approach the culture directly. 
 No research has been undertaken to make use of the hierarchy of Japanese cul-
ture within the computer for existing computer technology. This is the reason why 
there is no art expressing deep, historical ‘culture’ on a large scale yet. Another 
reason is that most artworks have paid attention to the uniqueness of Japanese cul-
ture and seen it as a sum of superﬁ cial expressions. 
 In contrast, engineering identiﬁ es the mechanisms behind phenomena, and ana-
lyzes their elements alongside the structural form. Engineering studies ﬁ nd new 
relationships between different things and their constructions, by reconstructing, 
trying some combinations, and comparing them. 
 In creating new media art, we can make use of the extraction of the basic struc-
ture or thoughts of Japanese culture, and modeling them or using them as tools to 
create new technology. Fresh media works or artworks are likely to be created that 
way. This method will bring about greater possibilities for advancing media art and 
interactive arts hereafter. 
 I had a little advantage in this difﬁ cult challenge, in which I reconstructed the 
world of Zen, which was expressed in Shan shui pictures on the computer. Although 
we needed 3 years, we ﬁ nally produced a unique system that we called the “ZENetic 
Computer” (see Chap.   3 for more details). 
 I succeeded in constructing this futuristic interactive system by projecting a part 
of allegory or symbols in Shan shui pictures, Yamato-e (Japanese traditional paint-
ings), haiku, and kimonos that reminded me of Japanese culture—the structure of 
the Oriental thought, the structure of Buddhist philosophy and the mechanism of 
Japanese traditional culture—which were rarely featured in computers previously. 
 This system uses various symbols and allegories that are included in Buddhism, 
Oriental thought, and the Japanese cultures. This is because they all include plenty 
5  Noh derived from the Japanese word for “skill” or “talent,” is a major form of classical Japanese 
musical drama. Noh was ﬁ rst introduced from China more than 1000 years ago during the Nara 
period. Although originally it was entertainment including dance, music, performance, etc., gradu-
ally the form was puriﬁ ed and minimalized and around the fourteenth century was established in 
its present form. Many characters are masked, with men playing male and female roles. 
6  Kabuki is a classical Japanese dance-drama. Kabuki theatre is known for the stylization of its 
drama and for the elaborate make-up (called “Kumadori”) worn by some of its performers. The 
expression Kabukimono referred originally to those who were bizarrely dressed and swaggered on 
a street. 
1.2 From Occidental Unconsciousness to the Eastern Shan Shui Paintings

12
of cultural implications, and they have extraordinary terms, ﬁ gures, or colors. There 
are many rules in Shan shui pictures and the world of Zen. I discovered that comput-
ers could handle these, if they are ﬁ rst selected and then extracted t. For example, 
there is “三遠 (San-En),” which is a special perspective found in Shan shui pictures; 
a combination of looking-up, parallel, and looking-down views. Another is “Go- 
Un,” which means ﬁ ve elements; “色 (Shiki)” is the superﬁ cial appearance of real-
ity, “受 (Jyu)” is intuitive impressions, “想 (So)” is perceived images, “行 (Gyo)” is 
activation of behavior, and “識 (Shiki)” is the deep mind behind all of the above, 
which functions in recognition of the human in Buddhism, and so on. 
 The ﬁ rst exhibition of this system was in the MIT Museum. I was concerned 
whether Westerners would understand it. Despite my initial worry, however, the 
system was accepted by many Westerners and won great popularity. Westerners felt 
that Shan shui pictures and Zen were extremely Oriental and hard to approach, but 
they gave me the impression that they could understand the concepts through inter-
action with this system. I, myself, felt that we could realize the initial goal of 
expressing culture through media when I saw an American child interacting joyfully 
with the system. 
 After that, the system was exhibited at ACM SIGGRAPH, a well-known interna-
tional conference on computer graphics, and Kodaiji, a Zen temple in Kyoto. Each 
exhibition won great popularity. The success of the experiment using this system 
made me feel certain that ‘cultural computing,’ which computes culture itself, was 
a reasonable research goal. 
1.3  Cultural Structure Becomes a Communication 
Technology 
 I was encouraged by the success of “ZENetic Computer,” and felt that the interac-
tion that reached deep racial memories was the very research I wanted to realize in 
the next stage of the development of cultural computing. From the dry, natural inter-
action of computers to a friendly and impressive interaction… How could I realize 
this challenge? 
 I tried to classify the types, structures, and relationships of what supports racial 
memories in Japanese culture. Below are the details of my ﬁ ndings:
 1.  Japanese natural climate 
 Japanese transient weather and nature, thoughts of transience such as “Mono 
no Aware, 7 ” a sense of beauty such as “Wabi-sabi,” and existential thoughts of 
love for the present situation. 
7  Mono no Aware is a Japanese aesthetic feeling that frequently appears in Japanese literature in the 
Heian period (794–1185). Direct translation of Mono no Aware is deep and sentimental feeling 
when looking at or listening to something. In the Heian period based on Buddhism’s teaching 
about the end of the world, such thoughts as “everything has to change” or “nothing is eternal” 
became common. The feeling of Mono no Aware is tightly connected to such a thought. 
1 Introduction – The Discovery of Cultural Computing

13
 2.  Relationships between Japanese culture and general Asian cultures (Japanese 
methods overriding the Asian culture within Japan) 
 3.  Transformation from Chinese Shan shui pictures to Japanese ones. And transfor-
mation from Chinese gardens and grove gardens to Japanese rock gardens called 
“Kare-Shan shui 8 ” in Japanese. 
1.4  Characteristics of Japanese Language 
 A Waka poem 9 is a classical Japanese verse form and has played a major role in 
Japanese literature. The oldest literature in the world, “Tale of Genji” 10 and “Pillow 
Book”, 11 provides such examples in the life of noble people. There are several appli-
cations of Waka poetry. One is ‘Honka-dori, 12 ’ which is an allusion within a poem, 
particularly a reference to older poems that are generally recognized by its potential 
readers. Another format of poem, Haiku, 13  is the shortest poem in the world. Haiku 
8  Kare-Shan shui or often called a Zen garden is the Japanese dry rock garden. Its characteristic is 
a miniature stylized landscape consisting of carefully composed arrangements of rocks, moss, 
pruned trees and bushes. Its most distinctive feature is to use gravel or sand to represent ripples in 
water. 
9   Waka (literally, “Japanese poem”) is a type of poetry in classical Japanese literature. In contrast 
to the Chinese style of poetry that is composed using only Chinese characters and are called 
Kanshi, Waka consists of 5 phrases each of which involves 5, 7, 5, 7, 7 Japanese syllables 
respectively. 
10  The Tale of Genji (called “Genji Monogatari” in Japanese) is a classic work of Japanese literature 
written by the Japanese noblewoman Murasaki Shikibu in the early years of the eleventh century, 
which were culturally the peak of the Heian period. It is sometimes called the world’s ﬁ rst novel. 
The novel also illustrates a unique depiction of the livelihoods of high courtiers during the Heian 
period. 
11  The Pillow Book (called “Makura no Sōshi” in Japanese) is a Japanese book the contents of 
which are observations and musings recorded by Sei Shonagon during her time as a court lady to 
the Empress Consort Teishi during the 1990s and early eleventh century in the Heian period in 
Japan. 
12  Honka-dori is one form of Waka composition in which an old famous Waka is treated as a refer-
ence and a part of the referred Waka is used in a newly composed Waka. By doing it, it is believed 
that the composed Waka would deepen its meaning and become more valuable by expanding the 
imagination of listeners. 
13  Haiku is a very short form of Japanese poetry. It consists of three phrases each of which contains 
5, 7, 5 Japanese syllables respectively. The origin of Haiku is Waka. which consists of ﬁ ve phrases 
containing 5, 7, 7, 7, 7 Japanese syllables respectively. Based on Waka in the late Heian period the 
new type of Waka composition (called Renga in Japanese) become popular where multiple con-
tinuous Waka are composed by multiple people. Then the ﬁ rst part of Renga consisting of 5, 7, 5 
syllables became treated as an independent form of poetry. The famous poet Basho Matso through 
his Haiku composition raised the position of Haiku to sophisticated minimalist poetry. 
1.4 Characteristics of Japanese Language

14
poems use the rule of “Uta-makura”, 14 which is a rhetorical concept in Japanese 
poetry. 
1.5  Japanese Design 
 Japanese design is one of the most popular forms of Japanese culture. Two- 
dimensional designs include Mon (Japanese family heraldic symbols), Ori (pattern 
of textiles), colors, paper patterns, or lines. One of the typical three-dimensional 
dynamic designs is the design of Noh Theatre, which is a major form of classical 
Japanese musical drama that has been performed since the fourteenth century. Many 
performers are masked, with male players playing both male and female roles. 
Another is the design of Kabuki Theatre, which is well known for its stylized drama 
and for the elaborate make-up worn by some of its performers. 
 On this basis, we can refer to various racial types and structures of Japanese 
culture and communication.  
1.6  Computers Do Not Have a Cultural Information 
Hierarchy that Is Indispensable for Symbiosis 
with Humans 
 Scientiﬁ c technologies have developed Web 2.0, such as Google, YouTube, 
Wikipedia, and SMS, through which we can send information with greater ease. 
Robotic technologies are also developing new basic techniques to realize the supe-
rior functions to which living things currently have exclusive access. More speciﬁ -
cally, these are abstract global communication technologies such as movement 
functionality, manipulation systems, and distributed autonomous systems for 
upgrading intelligence. 
 However, there is no cultural information hierarchy needed to live with humans. 
Adding the local cultural information here by cultural computing may contribute to 
creating higher-level communication systems. 
 These ‘cultural computing’ methods enable us to model and structure the inner 
essentials of culture, like sensitivity, intuition, racial characteristics, and narratives 
that we have not yet been able to quantify. I am setting my goal as the realization of 
expanding present computers’ communication abilities to be able to reﬂ ect differ-
ences in feelings, consciousness, and memories, based on each individual culture. If 
these systems are realized, social, practical, and cultural information expression 
14  Utamakura is a category of poetic words, often involving place names, which allow for greater 
allusions and intertextuality across Japanese poems. Utamakura includes locations familiar to the 
court of ancient Japan, such as particularly sacred Shinto and Buddhism sites. 
1 Introduction – The Discovery of Cultural Computing

15
systems through various languages, voices, and movies could be enabled in various 
ﬁ elds. 
 Now, I would like to introduce you to the methods of cultural computing. 
 References 
 Hall ET (1990) The hidden dimension. Anchor, New York 
 Jung CG (1968) Analytical psychology: its theory and practice. Pantheon, New York 
 Kroeber AL, Kluckhohn C (1952) Culture: a critical review of concepts and deﬁ nitions. Peabody 
Museum, Cambridge, MA  
 Kyoto National Museum (1990) Master pieces of Kyoto National Museum. Kyoto National 
Museum, Kyoto 
 McLuhan M (1994) Understanding media: the extensions of man. The MIT Press, Boston 
 Rauterberg M, Hu J, Langereis G (2010) Cultural computing – how to investigate a form of uncon-
scious user experiences in mixed realities. In: Cultural computing. IFIP advances in informa-
tion and communication technology, vol 333. Springer, Berlin/Heidelberg/New York, 
pp 190–197 
 Tosa N (2010) Cultural computing – creative power integrating culture, unconsciousness and soft-
ware. In: Cultural computing. IFIP advances in information and communication technology, 
vol 333. Springer, Berlin/Heidelberg/New York, pp 223–232 
 Tosa N, Matsuoka S (2006) ZENetic computer: exploring Japanese culture. LEONARADO 
39(3):205–211  
 Tosa N, Nakatsu R (1996) The esthetics of artiﬁ cial life characters. In: Artiﬁ cial life V. Proceedings 
of the ﬁ fth international workshop on the synthesis and simulation of living systems. MIT 
Press, Cambridge, MA, pp 122–129  
 Tosa N, Torroella AR, Ellis B, Matsuoka S, Nakatsu R (2005) Computing inspiration: i.plot. In: 
SIGGRAPH’05, ACM SIGGRAPH 2005 emerging technologies, Article No. 3. ACM, 
New York 
   Tosa N, Obara H, Minoh M (2009) Hitch Haiku: an interactive supporting system for composing 
Haiku poem. In: Entertainment computing – ICEC2008. Lecture note in computer science, 
vol 5309. Springer, Berlin/New York, pp 209–216    
References

17
© Springer-Verlag London 2016 
N. Tosa, Cross-Cultural Computing: An Artist’s Journey, Springer 
Series on Cultural Computing, DOI 10.1007/978-1-4471-6512-5_2
 Chapter 2 
 Computing Feelings 
2.1  Media Art, Culture, and Feelings 
 In this chapter, I will describe the concepts and speciﬁ cations of artworks I have 
created (we call them ‘systems,’ from a technical perspective). As discussed in the 
Introduction, I have created media artworks (Tribe et al.  2006 ; Schwarz  1997 ; 
Shanken  2009 ; Rush  2005 ) while approaching how to deal with feelings. Through 
this process, I gradually noticed the importance of stories, and I expanded my work 
to connect with people’s unconsciousness, as well as consciousness. Finally, I con-
ceptualized ‘cultural computing’ (Tosa et al.  2005 ; Hu et al.  2008 ; Rauterberg et al. 
 2010 ). In describing my works chronologically, I trace the path that I followed from 
the ﬁ elds of media arts to cultural computing. 
2.1.1  Mediation 
 “We should be more sensible and serious about the transcending information that 
exists beyond mere understandings, because we are in an information society. The 
meaning of ‘art’ that has strange powers to provide non-sensory information is 
especially emphasized there.” This is a statement by the famous Japanese artist, 
Taro Okamoto ( 1993 ). 
 From ancient times, humans have associated images with certain ﬁ xed things. 
Historically, we left evidence of our consciousness in images on cave walls (Curtis 
 2007 ; Whitley  2008 ). These days, we leave images on media like papers and 
computers. 
 At a basic level, media are externalized parts of human senses. Speech is the ﬁ rst 
externalization of our thoughts. We have sung, told, and drawn on walls to pass 
down memories. From such speech and pictures, written characters (Fenollosa et al. 

18
 2010 ; Houston  2008 ) and grammar have been developed, and we now have coherent 
sentences. 
 McLuhan, a media scholar, said that a medium is an extension of ourselves 
(McLuhan  2011 ; McLuhan and Lapham  1994 ). For example, a hand became a 
spoon as an extension of the human body. Writing extended into printing, cameras 
were developed as an extension for our eyes, and microphones and recorders became 
the extension of our voices (McLuhan  2011 ). 
 Media artworks form ‘senses’ or ‘images’ within people through media. That is, 
media art contains transcending information that reaches a human’s subjective view, 
sensibilities, and the information of his or her culture by using images and sounds 
to move the viewer’s heart. 
 This transcending information is mediated by computers as the externalization of 
human memories and thoughts. In ancient times, the mediations between humans 
and other things were considered spiritual channels (Arewa and Hale  1975 ; Roman 
and Packer  1993 ). Today, the mediation of expanded media is carried out by media 
technology. People who are working on media technology are like the shamans of 
today. 
2.1.2  The Deﬁ nition and Classiﬁ cation of Media Art 
 After the mid-twentieth century, there was an artistic movement to actively take up 
recent media technology in their artworks and create new artistic expressions using 
the innovative characteristics of new technology. 
 A style of experimental movie existed in the 1910s or 1920s (Lee and Rennert 
 2011 ), which never played commercially in general movie theatres, but they are one 
of the roots of media art. After that, video arts came into being with the spread of 
video-editing technology (Meigh-Andrews  2006 ). For example, experimental video 
arts by Nam June Paik (Hanhardt and Hakuta  2013 ; Lees  2011 ), multimedia works, 
and performance works by Fluxus were created. 
 In the latter half of the twentieth century, computer technology was developed, 
and people focused on computers that enabled them to use various software applica-
tions to create media. Many media artworks already began to use computers. 
Recently, PCs became very popular and many media artworks use computers for 
their expressions (Cousens  2013 ; Paul  2008 ). 
 Next, I will refer to the classiﬁ cations of media art. Media art has a rather shallow 
history, and the ﬁ eld is not fully established. Therefore, there is no well-established 
system for any of these classiﬁ cations. Here, I try to classify media art based on my 
experience as a media artist. 
2 Computing Feelings
www.allitebooks.com

19
2.1.2.1  Media Art that Corresponds to Communications: 
Telecommunication, Wireless, Net Art, Global Positioning System 
(GPS)/Locative Media 
 Art is originally a kind of communication in which an artist sends messages to artis-
tic appreciators. Also, media artworks have a stronger tendency to be interactive 
because they use computers (Kwastek  2013 ; Costello et al.  2005 ). In this case, they 
are even closer to communication media in that sense. For example, there are Web 
arts that fully utilize the World Wide Web (Bayraktar et al.  1998 ), or interactive 
virtual pets that play roles of middlemen in communications between people. 
Recently, a smartphone-based augmented reality (AR) artist group called Manifest.
AR was formed. 
2.1.2.2  Media Art Using Machines or Robots and Tangible Interfaces 
 As media artworks often use computer graphics, like the aforementioned Web arts 
or virtual pets (Eisenmenger  1997 ), they tend to realize communication through 
computer displays. By contrast, mechanized media artworks focus on human-like 
physical communication. Typically, they use robots (Moura  2013 ), or they set up 
their works to have physical movement capability. 
2.1.2.3  Media Art Using Narrativity 
 Communications with virtual pets or robots tend to be in the form of a chat. We can 
expand these chats to have narrativity in their communication (Audet et al.  2007 ). 
Present movies have linearly progressing stories, but narrative media art let users 
interactively create the story or play the roles of the characters. Video games 
(McGonigal  2011 ) are a primary example of this. 
2.1.2.4  Media Art Related to the Environment, Urban Design, 
and Architecture 
 Most of us live in an urban environment and, because of this setting, there is great 
potential for interactive arts in our urban environment and architecture. New tech-
nological possibilities can produce environments that can communicate and interact 
with us (Kastner  2010 ). Some media art has already been seen on signs that use 
LED billboards and which relate to the area they are placed in, and this may develop 
further in the future; for example, houses may become robots.  
2.1 Media Art, Culture, and Feelings

20
2.1.2.5  Media Art Using Nanotechnology and Biotechnology 
 Nanotechnology and biotechnology are now being developed at a very fast pace. 
Using these technologies, new art expressions may be born. For example, there is a 
nanomandala, which is an experimental work for visualizing the nanoscopic world. 
There is also a work in the ﬁ eld of biotechnology that sets an electric potential sen-
sor on a plant to generate a computer graphics-based virtual plant on the computer 1 
(Sommerer and Mignonneau  2006 ). 
2.1.2.6  Media Art that Fuses Information Technology and Traditional 
Culture 
 Common present-day approaches to culture from a technological perspective are, 
for example, high-quality archives of cultural heritage or interactive exhibitions of 
traditional cultures. Cultural computing (Rauterberg et al.  2010 ; Curtis  2007 ), as 
suggested in this book, is meant to advance this ﬁ eld. 
 The development of media art varies depending on the development of IT. A new 
possibility is being created by merging media art and IT. For example, it is now pos-
sible to create an artwork that interactively conveys the abstract thoughts of Eastern 
cultures to Western viewers (Hu et al.  2008 ). I would like to show these new possi-
bilities in this book.  
2.1.3  Applications of Media Art to Culture 
 Let us think about the applications of media art. I discuss the following features, 
which correspond to media art. It is not enough to digitize superﬁ cial thoughts or 
cultural information into a static digital archive as we have done previously. It is 
important to let any users understand these cultures by showing them through inter-
active artworks using the feelings and interactivity in media art. A large market will 
emerge there. Additionally, these works could become a very important part of soci-
ety in the future. 
2.1.3.1  Nonverbal Interface 
 Communication with words is called verbal communication. In contrast, communi-
cation using feelings or sensibilities is called nonverbal communication (Mehrabian 
 2007 ; Knapp et al.  2013 ). Let us think about the relationship between culture and 
1  The Interactive Plant Growing is the interactive installation created by two media artists; Christa 
Sommerer and Laurent Mignonneau. By using this installation users can create their own artiﬁ cial 
creatures and can then interact with the creatures they have developed. 
2 Computing Feelings

21
nonverbal communication using feelings and sensibilities as the central focus. I will 
explain my works as speciﬁ c examples on this basis. 
 When we talk about communication, we often use the word ‘interface.’ An inter-
face is what stands between two things with intermediate information. We need an 
interface when we communicate with computers (Dix et al.  2003 ; Lazar et al.  2010 ). 
 We use a nonverbal interface to communicate feelings. This is an interface in 
which we can interact with computers using nonverbal messages like ﬁ gures, col-
ors, motions, circumstances, music, or sensibilities. Nonverbal interfaces have been 
thought to be important since the 1960s (Esposito et al.  2007 ; Wachsmuth and Sowa 
 2002 ). They will increase their usefulness in multimedia and mobile media that 
send images and music throughout the world. 
 According to researchers investigating nonverbal communication, 65 % of all 
messages used in communication are nonverbal. Albert Mehrabian ( 1972 ), a social 
psychologist in the United States, found that only 7 % of knowledge about feelings, 
behavior, and personality are acquired from actual words, 55 % are acquired from 
motions, and 38 % from paralanguage (Key  1975 ; Nagamachi  2010 ). 
 We can pick up feelings without needing to ﬁ lter through the logistic content of 
words, and we can express our status, feelings, or sensibilities to others without 
words, as well. That enables us to experience a deeper collective communication, in 
other words, human communication. 
 I have focused a great deal on a subset of nonverbal information, feelings, and 
studied interfaces that recognize and generate feelings. Assuming that a nonverbal 
interface is based on technology to capture a human’s feelings or sensibilities, there 
has been various research related to both hardware and software that is said to be 
able to process various feelings and sensibilities, and available because of the 
advancement of computer technology such as VR (Rheingold  1992 ; Eisner  2002 ). 
They often aim to realize the functions of the ﬁ ve human senses used in daily life. 
 Our ﬁ ve senses are more real than the ones provided by present technologies, and 
in some cases, we are not satisﬁ ed by these technologies and feel uncomfortable. 
Moreover, we are now more accustomed to technology than we were in the past, so 
I think we tend to be less impressed by simple and shallow technologies. 
 To resolve these problems and obtain tastes and impressions, I call for using 
cultural approaches. Cultural activities are emerging as ways to boost our quality of 
life by letting spiritual works of art, morals, and religion make us ethnically con-
scious using our sensibilities I set my goal as using computer software based on 
cultures to produce a model to recognize the sensibilities of a culture that engages 
in nonverbal communication with users. 
2.1.3.2  Importance of a Feeling-Based Interface 
 Information on sensibilities is too complex to process at this time because they have 
many different interpretations depending on individual personalities. Therefore, it is 
reasonable to speciﬁ cally use feelings only when these are thought of as easier to 
treat because of their relative clarity in classiﬁ cations used by the interface. 
2.1 Media Art, Culture, and Feelings

22
 Present research on human interfaces are using engineering approaches (Lazar 
et al.  2010 ). In contrast, the approach described here is more of a cultural approach. 
In other words, my research is about investigating human senses and technology to 
expand the range with which computers can interact with humans through emer-
gence in art and culture. Artists rarely have a ﬁ nal image in mind when they start to 
create an artwork. The process of creating an artwork is not in reaching a goal, but 
looking for a goal (Eisner  2002 ; Zeder and Hancock  2005 ). The method of search-
ing is different from the technological objective quantiﬁ cation. It is based on the 
personal, subjective view of the artist. The artist’s depth of view and sense of values 
are represented in the resulting artwork. An artist creates artworks that reﬂ ect their 
inner world or consciousness; therefore, considering these features will let us think 
about new feeling-based interfaces. Nowadays, analog information is being replaced 
by digital, so feelings may not be exceptions in being digitized. These methods may 
be adopted as tools to develop deeper interfaces with human consciousness. I have 
worked on recognition and generation of feelings with this perspective in mind. 
 The description above may seem abstract, but this is an extremely down-to-earth 
approach. For example, Brenda Laurel used a drama metaphor as an interface 
between computers and users in her book “ Computers as Theatre ” (Laurel  1993 ). 
She divided a theatre into three elements: viewers, a stage, and effects. She claimed 
that the main role of a computer interface is to let the minds of viewers focus on the 
events on a stage and to give them the expected effect, like spotlights or sound 
effects. 
 This perspective can be applied to other ﬁ elds. For example, the Japanese Noh 
stage is a metaphor that has a dual nested structure of a corridor; one is a corridor 
connected to another world and the other is connected to the main Noh stage 
(Fenollosa and Pound  2011 ; Takahashi et al.  2010 ). Based on such structure, a 
nested Noh narrative called “Fukushiki Mugen Noh” is performed. Here Noh drama 
construction has two parts: a dream and the present. Shite (the main actor) wears a 
mask and has left something incomplete before he died. Waki (the supporting actor) 
is a man who completes what Shite has left. Connecting expressions of images that 
construct this theatre to information within computers will increase our thoughts or 
imagination. This is an example of merging engineering and cultural approaches. 
 As we can see, the emerging possibilities of research to process the information 
of feelings have initiated various studies about humans’ mental activities, such as 
empathy and sensibilities, in ﬁ elds like recognition technology (Gibson  2005 ), AI 
(Russel and Norvig  2009 ), neural network computers (Haykin  2008 ), and brain sci-
ence (Schwartz and Begley  2003 ). The results of these studies are capable of being 
applied to cultural interfaces in the future. I think a concrete cultural interface can 
be realized only by connecting the ethnic unconsciousness and technology to the 
processing of emotions.  
2 Computing Feelings

23
2.1.4  Communication of Feelings Between Humans 
and Machines 
 Nowadays, the work being done on interfaces between humans and computers is 
increasing, corresponding to the increase in people’s opportunities to interact with 
computers. The present recognition technology for speech and images for interac-
tion between humans and computers is precise enough in a logical sense (Jurafsky 
and Martin  2008 ), but these technologies make us feel that they can be used only in 
very limited situations. That is because there is no “information of sensibilities 
(Nagamachi  2010 )” that represents the level of culture that is always transferred in 
communication between humans. 
 While research about feeling recognition using facial expressions are being stud-
ied (Bhatia  2012 ), I think that it would take less work to produce cultural depth in 
technology. Several studies (Brabe and Nass  2009 ; Breese and Ball  1999 ) have 
made computers generate sensibilities as if they have feelings, but these computers 
lack the ability to communicate using cultural information. 
 More feelings than logic are used in human communication. However, engineer-
ing research has focused on communication of global logistic information. Local 
information, such as culturally dependent feelings, has been ignored. In these sys-
tems, humans should try to ﬁ t themselves to the computer, which makes it difﬁ cult 
for humans to communicate on a deep level. 
 One ability we want computers to have is the ability to process feelings. This 
does not mean programing the computer to do something empathetic with its users. 
By adding feeling recognition to a computer, it will work more effectively than 
before (Rao and Loolaqudi  2012 ). The easiest way is to recognize the status of the 
user’s feelings and run programs based on that. To accommodate unexpected inter-
actions from the user, we may need to apply the famous Three Laws of Robotics 
(harmlessness, obedience, and self-defense) proposed by Isaac Asimov (Asimov 
 1950 ) so that future computers act responsibly. 
 This engineering methodology of emotion generation is typically taken from 
ﬁ elds of psychology. For example, according to Prof. Paul Ekman, the leading psy-
chologist in the ﬁ elds of feeling and nonverbal communication, six basic feelings—
namely fear, surprise, anger, hate, sadness, and happiness—occur corresponding to 
speciﬁ c triggers (Ekman  2007 ). Each emotion has a facial expression and a pat-
terned bionomical symptom. In the process of evocation of the facial expression 
generated by the pattern, a speciﬁ c sense behind an impulse generates a speciﬁ c 
reﬂ ection in facial expression or physical pose, which triggers activities of speciﬁ c 
automatic nervous system reactions and feeling experiences. 
 The Affective Computing Group at the MIT Media Laboratory (Picard  2000 ) is 
famous for research in this area. They study the effect of feelings in our daily actions 
like determination, recognition, or sense. Based on these effects, they also research 
the whole concept of feeling recognition in systems design while constructing theo-
ries of basic emotional information. 
2.1 Media Art, Culture, and Feelings

24
 Concretely speaking, their research includes the following: wearable emotion 
sensors and the design of its learning algorithm, and multimodal channeled analysis 
of results from feeling recognition; methods to evaluate frustration, pressure, and 
mood in natural conversation; an intelligent system that alleviates humans’ negative 
feelings by detecting frustration; resolving autistic patients’ feelings using commu-
nication; evaluation of effects of feelings on human health; and searching for ethical 
issues of emotional computing.  
2.1.5  Realizing Empathy 
 We can analyze classiﬁ cations and deﬁ nitions of empathy from novels, poems, dra-
mas, colors, ﬁ gures, or tones. We can also analyze feeling expression and its dynam-
ics over a time axis from movies and theatres. André Bazin, a French ﬁ lm analyst, 
used the term “presence” in the historical work “Qu’est-ce que le cinéma? (Bazin 
et al.  2004 ).” 
 Presence is a term that represents the viewer’s feeling as if she or he is in the 
screen, and the word describes the phenomenon well. Movies instigate the viewers’ 
dreams, and viewers feel as if they are encountering them in a reality that is sup-
ported by technology and human imagination. Considering the methodology of 
ﬁ lms is expected to create deeper cultural interfacing by realizing empathy. 
 However great the virtual world is, it is only superﬁ cial if we cannot feel empa-
thy within it. People never spend a long time in the virtual world. Empathy means 
to understand and share the feeling of others. In other words, it is a pseudo- 
experience within another person’s mind (Lancoboni  2009 ). An idea I had was to 
use interactive computer characters to realize human empathy. 
 One of the basic design concepts of avatars is that they work with us, and they 
make us feel an afﬁ nity, as if they are our alter ego. It is like a baby who came from 
There (another world) to Here (this world). I started this research while wondering 
how we could express a communication using technology containing a state of 
mind, feeling expressions, characteristics, intelligence, and actions. 
 In this research, I set the virtual world as dreams we experience while we sleep. 
It shows a real expression of the world of a dream (Fagan  2011 ). When we dream, 
we are proactive in whatever we do. However, our empathy cannot reach within this 
dream because of the barrier between the real and unreal. In this research, I intro-
duced interactions to break that barrier. The user can enter the virtual world, have 
fun within the programmed circumstances, talk with the characters, and interact 
with the scene to dynamically change the context and the story. My methodology 
uses this communication to utilize the differences between our cultural sensibilities 
in systems design through feeling recognition and an interactive story. 
 An interaction cannot cause the desired result if the human is not positive 
(Nissenboim and Vroman  1998 ). People are positive when they are experiencing 
good feelings, so we should create a situation in which everyone can feel good. A 
common example of this situation is the relationship parents have with their babies. 
2 Computing Feelings

25
Babies have only two notable feelings: excitement (positive or negative) and inter-
est. However, they acquire other feelings as they grow. They do not learn directly 
from anyone, but the signs of their feelings are directly related to their growing 
maturity. 
2.2  “Neuro-Baby”: Voice-Based Recognition/Generation 
of Feelings 
2.2.1  Japanese Love the ‘Humanoid’ 
 Why do Japanese people like ‘humanoids,’ regardless of age and sex? The Japanese 
have created human-like ﬁ gures from clay dolls to robots, and have felt empathy for 
them (Pate  2008 ; Takahashi  1990 ). Recent ‘humanoid’ robots are being developed 
with the hope of creating something resembling humans (Clay  2014 ; Sakagami 
et al.  2002 ). These robots represent a ‘relationship’ between humans and machines. 
Robots are machine dolls, in a sense, and robots mean a similar thing as dolls are to 
humans. Nowadays, dolls or robots exist as virtual characters beyond the physical 
limitations of computers. They are like physical computer game characters. Our 
empathy with computer characters is expected because we can more easily interact 
with them (Betsz  1997 ). They play important roles in social events of culture as we 
can see in the example of the recent “yuru-kyara” (mascot characters). 
 We can see communication by feelings in the broad context of cultural commu-
nication. People express their feelings through various nonverbal outputs. These are 
sometimes complex, like “smiling with your face but crying with your heart,” and 
sometimes we talk as if something is favorable, but in a strained tone of voice (Kalat 
 2011 ). 
 There is some engineering research about feeling recognition, but none of their 
approaches consider differences in culture. Information about feelings includes sub-
jectivity, ambiguity, and situation cognition (Nagamachi  2010 ). We also need to 
research external factors that generate speciﬁ c feelings. I think that feeling informa-
tion is not universal but personal, and these systems should provide the ability to 
interpret differences across cultures. 
 Here, I aimed to design and implement an emotional dialogue system that recog-
nizes and generates voices with feeling, and enables us to communicate with vari-
ous speakers across different cultures. 
 Now, I introduce the communications by computer characters with an emotional 
voice. 
2.2 “Neuro-Baby”: Voice-Based Recognition/Generation of Feelings

26
2.2.2  Human Feeling Recognition and Generation 
 I needed to design the computer characters for this system to generate natural feel-
ing expression, and to easily feel empathy. 
 I considered both verbal and nonverbal action in the design of the feeling model. 
People sometimes show conﬂ icts in their nonverbal and verbal actions. Consistent 
actions make us feel honest and reliable, but conﬂ icting ones make us feel dishonest 
and misleading. 
 Larger conﬂ icts appear between verbal and nonverbal actions when someone lies 
than when they tell the truth, according to research from psychologist Mordechai 
Rotenberg. Real feelings are thought to “trickle out” through nonverbal actions 
(Rotenberg  2003 ). The subtle motion of hands or legs are easier to use to show real 
feelings than more consciously controlled parts, such as eyes or facial expressions. 
 In the concrete design of the feeling model, I have developed a feeling model that 
can involve any type of feeling expressions in any language. Computers can map the 
detected feeling expressions onto this model (Tosa  1993 ). I designed a feeling rec-
ognition/generation algorithm using this model.  
2.2.3  A Cue to Birth 
 In 1989 at an international conference for computer graphics, I met Dr. Koichi 
Murakami, who was studying human interfaces at a laboratory at Fujitsu. I was 
becoming tired of video arts and computer graphics that simply expressed con-
sciousness or feelings over time. I was more interested in computed consciousness 
or personiﬁ cation and was looking for new interactive expressions by computers. 
Dr. Murakami suggested that I should use a neural network (a model that applies the 
mechanisms of human brain). I felt that it might lead to an innovative result, so I 
started collaborative work with him. My main theme was to visualize intangible 
feelings or consciousness, but it was too hard to realize this at that time by using 
computers Therefore, I set my goal to visualize emotions that are visible right from 
the start. I wanted to prepare an adult character and realize subtle emotional dia-
logue like ‘hate, but love.’ However, this was impossible because of the technologi-
cal limitations. I wonder whether anyone can perfectly match their actions and the 
feelings expressed in their dialogue; I was always struggling with conﬂ icts in my 
actions and emotions. Regardless, I ﬁ rst needed to determine how to process feel-
ings in a neural network. The ﬁ rst things I had to decide were what to set as input, 
what to set as output, and what to ﬁ ll the gap with. This information is very 
important. 
2 Computing Feelings

27
2.2.4  Predawn 
 From 1990 to 1992, we carried out various trials. Kenichi Tanigawa, a jazz pianist, 
joined us. The ﬁ rst achievement based on this collaboration was ‘Neuro Drummer’. 2 
In this Fujitsu-sponsored Neuro-Drummer project, we succeeded in developing a 
neural network software called ‘self-modifying connection networks.’ This has a 
function of learning similar to the way ‘neural nets’ in the human brain learn about 
rhythms using a neural network. The interaction of this system works in the follow-
ing way: when a user strikes a drum, the computer-based Neuro Drummer answers 
with a drum rhythm. I created various facial expressions for the Neuro Drummer. 
Depending on the rhythm of the drum played by a user, the facial expression of the 
Neuro Drummer changes—but the concept was still fuzzy. 
 After the Neuro Drummer project, we tried to create various design concepts for 
an effective application of a neural network. Finally, we found a method that uses 
the position of a mouse as input, facial expressions as output, and a quantiﬁ ed 
change of feelings in the center. 
 We created the character’s facial parts with both eyebrows, both eyes, and a 
mouth with 20 vertices, to display facial expression on the two-dimensional (2D) 
screen of a workstation. It took about 3 days to calculate a neural network that had 
100 elements in its input layer and 100 elements in its output layer. It was far from 
real-time processing, but we found a ray of hope when we saw the wireframe image 
change its facial expression. Nonetheless, speed was a big issue. 
 We needed to drastically reduce the input and output layers so we mapped  x and 
 y in 2D coordinates onto input and output layers of a neural network. This method 
reduced input/output elements from 100 to 2 and lightened the calculation amount. 
The system acquired the ability to process data in real time. 
 The next problem was the computer graphics-based facial expression. Even if it 
was based on a wireframe model, drawing a number of cells by hand was hard work. 
As it was around 1990, no general computer graphics software was available, so I 
used the computer graphics modeling software developed by Mr. Masanori 
Kakimoto The ﬁ rst “Neuro-Baby” was developed by implementing various previ-
ous ideas. We mapped each 3D facial expression onto 2D coordinates. Interpolated 
3D images from the base elements were generated depending on any data in the  x–y 
coordinates (Tosa et al.  1994 ). 
 We had to create many things that had not existed in the world yet. We tried to 
realize them step by step. Because they were created by hand for this purpose, their 
accuracy was less than we hoped, but we felt the greatest R&D achievement was 
when we realized interactive functionality. 
 We made a baby character for the system because adults were difﬁ cult to create, 
as I mentioned previously. I consulted the human facial expressions of “ Man 
2  Neuro Drummer is a project by Fujitsu that started in 1991. Through this project a neural network 
software was developed that has the structure of self-modifying networks of connections, similar 
to the way some neural nets in the human brain process information. 
2.2 “Neuro-Baby”: Voice-Based Recognition/Generation of Feelings

28
Watching ” by Desmond Morris in creating the computer graphics of the facial 
expressions. 
 We changed the input from mouse position to voice input to make the system 
recognize the user’s feelings. Then the interpolation method also changed from neu-
ral interpolation of vertices to direct linear interpolation of free transformations. 
 Finally, we developed a system that had its own feeling model and facial expres-
sions to recognize the user’s feelings from an input voice. A computer character, 
“Neuro-Baby,” was born by combining these elements, and it can communicate 
with people through feelings (Tosa  1993 ,  1995 ; Tosa et al.  1994 ; Tosa and Nakatsu 
 1996 ). 
2.2.5  Interactive Design of “Neuro-Baby” 
 Here, I introduce the character design for “Neuro-Baby.” If the user talks to the 
character with empathy, the system judges which of eight feelings should be shown 
using the user’s voice inﬂ ection and replies accordingly. For example, if the user 
says nothing, he sleeps, or if the user says something, he replies “Hello” or “Bye,” 
depending on his mood. If the user shouts at him or tells him off in a low tone, he 
gets angry. If the user teases him in a high tone, he does a handstand. If the user 
whistles in a high tone, he cheers up. If the user speaks weakly, he gets sad and hides 
his face in his hands. Sometimes, he even loses interest in the user and complains. 
2.2.5.1  Emotion Model 
 The emotion model is expressed in 2D coordinates, as shown in Fig.  2.1 . The  x -axis 
shows comfort level, and the  y -axis shows the strength of emotion. The following 
are the eight concrete feelings and corresponding input voice tones:
 Joy (happy, satisﬁ ed, funny, comfortable, smiling)
 *High strong voice, whistling 
 Anger (angry, mad)
 * Low strong voice, scolding, etc. 
 Surprise (shocked, surprised)
 * Sudden strong voice 
 Sadness (sad, weeping, lonely)
 * Low weak voice, etc. 
 Disgust
 * Tired voice as though you lost interest in him 
2 Computing Feelings

29
 Teasing
 * High and light voice tone 
 Fear
 * Low and threatening voice 
 Neutral
 * Normal voice 
 Emotional voices are different in each language. Learning special emotional 
voices for the language in a given locale will help the system recognize emotions 
more precisely. In the future, the system will be able to transfer this emotional voice 
among different cultures. 
2.2.6  Technology of “Neuro-Baby” 
 We aimed to develop the basic technologies to realize smarter interactions between 
humans and characters. We realized the following: 
 Fig. 2.1   Emotion model of “Neuro Baby” 
 
2.2 “Neuro-Baby”: Voice-Based Recognition/Generation of Feelings

30
2.2.6.1  Real-Time Processing 
 To realize interactions between humans and virtual agents, the system needed to 
process feature extraction, emotion recognition, and responses in real time (Kuo 
et al.  2006 ). This system realized real-time processing through sound processing 
and system composition.  
2.2.6.2  Handling Various Feelings 
 How many and what kind of emotions to handle was a difﬁ cult and important prob-
lem. For example, some of the research on emotion recognition handled the follow-
ing emotions:
  (a)  Anger, sadness, happiness, joy (Tosa and Nakatsu  1996 ) 
 (b)  Neutral, joy, boredom, sorrow, anger, fear, teasing (Mozziconacci  1995 ) 
  (c)  Anger, fear, sadness, happiness, hatred (Schemer  1995 ) 
  (d)  Neutral, happiness, sadness, anger, fear, boredom, hatred (Klasmeyer and 
Sendlmeier  1995 ) 
  (e)  Fear, anger, sadness, happiness (McGilloway et al.  1995 ) 
 At ﬁ rst, I worked on the four emotions indicated in (a). However, as I absorbed 
the lessons from the experience of exhibiting the ﬁ rst “Neuro-Baby,” I added several 
types of emotions that the character could recognize and express. To enrich the 
interaction with the expression of subtle feelings, ﬁ nally we decided to use the eight 
emotions described in Sect.  2.2.6 (Fig.  2.1 ). 
2.2.6.3  Precise Voice Processing 
 It is important to consider what kind of features to use with the voice recognition. 
One idea is that the voice feature for emotion recognition should be different from 
the one for speech recognition. In the ﬁ eld of speech recognition, “phonological 
features” (King and Taylor  2000 ) are used, such as a frequency spectrum. In the 
ﬁ eld of emotion recognition, a general idea is that we should use “prosodic fea-
tures” (Shriberg et al.  2005 ) instead, such as tone, pitch, or rhythm. 
 However, there is another perspective. When we speak, the phonological and 
prosodic features are strongly combined, and it is hard to express emotion while 
only processing the prosodic features. Therefore, we decided to use both features at 
the same time. In this research, we used the latter idea to use two features (that is, 
phonological and prosodic), as parameters.  
2 Computing Feelings

31
2.2.6.4  Speaker-Independent, Context-Independent Feeling Recognition 
 Speaker-independent recognition is important in the ﬁ eld of speech recognition and 
emotion recognition (Lee  1998 ). We do not want the system to learn only the feature 
of one speaker because the speaker may change. From another point of view, 
humans can recognize content and emotions at the same time regardless of the 
speaker. 
 Context-independence is important, especially for emotion recognition. In daily 
conversation, we use the same word or sentence with various emotions attached to 
it. In this research, we used a neural network as a type of recognition architecture 
and learning process with a large amount of samples to support independent speak-
ers and independent contexts at the same time. 
2.2.7  Flow of the Entire System 
 Figure  2.2 shows the block diagram of this system. The entire process consists of 
three parts: voice feature extraction, emotion recognition, and response generation.
 In the voice feature extraction, voice feature parameters are extracted from the 
input voice. Considering the amplitude, the data is divided into sections. Voice fea-
ture quantities are determined corresponding to the input voice of each section. 
These quantities are sent to the emotion recognition section. 
 Next, in the emotion recognition, there are two levels of feeling recognition. The 
ﬁ rst level has eight neural networks that are taught to recognize each of the eight 
feelings. Output from the feature extraction is input to these eight neural networks 
at the same time. The next level has logical parts that process output from eight 
neural networks to map them on the 2D emotional plane. The eight feelings are 
mapped to this plane. The position and movement of recognized emotions in the 2D 
plane affects the response of “Neuro-Baby”; that is, the facial expressions and 
motions that are generated. Facial expressions and motions to output for each emo-
tion were considered by artists as ﬁ tting. The response generates computer graphics 
and appropriate voice and music are played. 
 Now, I will explain the real-time phonetic feature extraction and the structure of 
emotion recognition by a neural network. 
2.2.8  Phonetic Feature Extraction 
 There are two types of feature parameters for emotion recognition: phonological 
and prosodic feature parameters. 
2.2 “Neuro-Baby”: Voice-Based Recognition/Generation of Feelings

32
 We used linear predictive coding (LPC) 3 (Gray and Markel  1976 ) for the phono-
logical feature. This is one of the methods for coding voice signals; it is based on a 
human speech model. LPC is a typical parameter to express voice features and is 
popular for speech recognition. 
 Three parameters were used for the prosodic feature: energy, time changes in the 
phonological feature, and voice pitch. Energy is determined from the sound level 
3   Linear predictive coding (LPC) is a tool used mostly in speech signal processing. It is used to 
represent the spectral envelope of a digital speech signal in compressed form. LPC is one of the 
most useful methods for encoding good quality speech at a low bit rate and has been used in speech 
coding, speech recognition, speech synthesis, etc. 
Speech input
Speech feature calculation
Extraction of speech period
Speech feature extraction
Speech processing
Emotion recognition
Emotion recognition using 
neural network
Training of neural network
Mapping on emotion plane
Recognized emotion
Generation of reaction
Generation of output speech
Processing
 Fig. 2.2   Block diagram of “Neuro Baby” 
 
2 Computing Feelings

33
and voice pitch information from LPC parameters. We used the time changes in 
LPC parameters for the last parameter. 
2.2.9  Emotion Recognition 
 Emotion recognition (Nicholson et al.  2000 ) is hard to target in research. The major 
reason for this difﬁ culty is that babies act by recognizing other people’s emotions 
(they are said to start recognizing emotion before they understand any contexts), but 
adults mainly use contexts that are included in speech to communicate with each 
other. Therefore, researchers of speech recognition have regarded the emotional 
information in speech as a mere variation or noise. 
 What’s more, semantic content and feelings are combined mutually in our voice 
(in both cases they can be conscious or unconscious). Context especially plays an 
important role in that they often control the level of emotion that we emit or sense 
unconsciously. In other words, the amount of emotional expression in one’s voice is 
strongly dependent on circumstances. Of course, the best solution is to recognize 
the emotion even if the input data includes both unconscious emotions and semantic 
content. However, it is difﬁ cult to recognize unconscious emotions because of the 
reasons I referred to above. Therefore, this system fully processes only conscious 
emotions within voices. 
Sub-neural betwork 
(anger)
Configuration of emotion recognition
Output
Decision logic
Sub-neural network
(sadness)
Sub-neural network
(neutral)
Speech feature parameter
 Fig. 2.3   Structure of the neural network for feeling recognition 
 
2.2 “Neuro-Baby”: Voice-Based Recognition/Generation of Feelings

34
2.2.9.1  The Structure of the Neural Network 
 Figure  2.3 shows the structure of the neural network for feeling recognition. This 
network consists of eight subnetworks and a logic part that integrates the eight out-
puts. Each subnetwork is tuned for each feeling (anger, sadness, happiness, fear, 
surprise, hatred, teasing, and neutrality). The logic section decides output by extract-
ing the nearest supervisor data from the eight neural networks.
2.2.9.2  Supervised Learning of the Neural Network 
 To perform emotional recognition, we needed to make the neural networks learn 
patterns beforehand. We prepared the following voice samples 
that were considered to realize speaker independence and context 
independence. Words 
 100 phonologically balanced words 
 Speakers 
 100 people (50 males, 50 females) 
 Emotions 
 Neutral, angry, sad, happy, scared, surprised, hateful, or teasing 
 Sample voice 1 
 100 words in each emotion from each speaker 
 Sample voice 2 
 Vowel sounds with each emotion from each speaker 
 We conducted a preliminary experiment using this learning data. The results 
showed that it is better to prepare two independent networks for males and females 
rather than putting them together, for both learning and recognition.  
2.2.10  Emotion Recognition Engine Between Different 
Cultures 
 We should produce ‘supervisor data’ localized for each country for this type of 
dialogue system. Tuning is required to make the neural network learn emotional 
expressions for each country. If we talk to the Japanese emotional system in English, 
the feeling outputs from “Neuro-Baby” increase in randomness because of the 
quicker changes in intonation in English in contrast to Japanese. The transitions 
among emotions then become random, such as him getting angry soon after he 
cries, then suddenly becoming surprised, and so on. 
 To collect the relevant data, we used typical emotional words from each language 
for the supervisor data. They enabled us to extract the ‘structure’ of intonations in 
each country’s emotional expressions. It is very important to ﬁ t the phonetic emo-
tional expressions to the country’s culture. Software agents for emotion recognition 
software with voices like this will be developed and applied to the speech of robots 
in the future. 
2 Computing Feelings

35
2.3  Cross-Cultural E-mail Software with Emotion 
Translation 
2.3.1  Emotional Translation in E-mail 
 In the following section, I will introduce research that used “Neuro-Baby” as an 
agent of cross-cultural communication. 
 In cross-cultural communication, we often face collisions rooted in differences 
between cultures (Neogy  2012 ). Most people think that these depend on the conver-
sational ability in other languages, but in reality, there are many problems beyond 
language alone. Nonverbal messages from each culture highlight differences, espe-
cially in lifestyle (Neogy  2012 ). I focused on these points and tried to improve 
“Neuro-Baby” so that it could translate emotions that exist behind e-mails in other 
languages. 
 The common understanding of culture among cultural anthropologists, sociolo-
gists, and psychologists is that senses of value, beliefs, attitudes, and ideologies 
form the subjective side of a culture. We can see that different cultures have differ-
ent subjective sides, and these sides hold important roles in communication. 
 Mutual understanding through communication is never realized unless the two 
sides understand the behavioral differences of the other side based on cultural dif-
ference. In this sense, appropriate emotional expressions also play important roles 
in communicating with each other. 
 I will introduce a story of a communication misunderstanding that became the 
basis of this research. I exchanged some e-mails with Prof. Steve Benton before I 
joined MIT. Prof. Benton used elegant and learned English, so I used a dictionary to 
write back to him. However, he suddenly stopped replying to me. I felt that some-
thing was wrong because Prof. Benton was a kind person but he had not replied to 
me for almost 3 months, even though I was soon to go to MIT. I asked Ryohei 
Nakatsu, 4 then my boss at ATR, to inquire as to the reason why he did not reply. I 
ﬁ nally discovered that the reason was the mistranslation of my thoughts into English. 
My messages had made Prof. Benton angry, which was why he stopped replying to 
me. 
 This problem occurred because the expectation of the sender did not match with 
the interpretation of the receiver. As you know, once a relationship goes sour, it is 
difﬁ cult to repair by merely exchanging messages. Communication through e-mail 
is convenient, but in many ways, especially across cultures, it is difﬁ cult. 
4  Ryohei Nakatsu (born 19 October 1946) is a researcher who has been pursuing communication 
technologies, focusing on emotion extraction from speech and facial images, emotion recognition, 
nonverbal communications, and integration of multimodalities in communications. At the same 
time, he has been trying to cross the boundary between pure technology and other areas such as art/
design, cognitive science, social science, etc. Based on such trials, he has succeeded in developing 
new interdisciplinary research areas such as art and technology, entertainment computing, enter-
tainment robotics, cultural computing, etc. 
2.3 Cross-Cultural E-mail Software with Emotion Translation

36
 As you can see in this example, Japanese people sometimes fail to read subtle 
nuances in English e-mails because of the limits of their vocabulary. However, they 
can use “Neuro-Baby” to emotionally transform the expressions and, from the other 
end, understand the feelings behind them without words. This is the concept of 
e-mail software with emotion translation.  
2.3.2  Emotion Translation of E-mail Using “Neuro-Baby” 
2.3.2.1  The Process 
 The system picks out the words that represent emotional expressions from the con-
tents of an e-mail and outputs the feelings of each word with motion and sounds. 
This emotion translation of e-mail is a kind of mail client with read-out 
functionality. 
 The character used in this software is “Neuro-Baby.” Babies are good for express-
ing raw emotions because they are loved by everyone. “Neuro-Baby” can express 
eight emotions and also some greeting expressions. The emotions expressed in this 
system are happiness, fear, surprise, neutrality, sadness, anger, boredom, and teas-
ing. “Neuro-Baby” reads the e-mail aloud, showing motions corresponding to the 
emotion (Fig.  2.4 ).
2.3.2.2  To Send an E-mail 
 Emotion Translation Mail is developed based on Java software that works on Web 
browsers. The user must sign in to the special database server before starting. 
 An ‘emotional words database’ is stored on the Web database server, which is 
needed for emotional transformations. It has a list of emotional words correspond-
ing to eight emotions like happiness or anger, and it is used for picking out the 
emotional words from an e-mail. 
 The database is on the Web because it grows daily. The user can register new 
words to the database as emotional words. As the number of users grows, the trans-
lation becomes richer and richer. There is also a ‘behavior database’ that deﬁ nes the 
behavior of the computer graphics character corresponding to each emotional word. 
2.3.2.3  User Customization 
 After writing the e-mail, the user can access the database by clicking the ‘convert’ 
button. Emotional words in the text are listed and each behavior is played. Then the 
computer graphics character reads the text aloud by synthesizing its baby-like voice. 
 The user can customize the motion of the computer graphics character if it is 
inadequate. Customized data is stored in the user’s own database, so it can be used 
2 Computing Feelings

37
 Fig. 2.4   Procedure of creating and sending e-mail 
 
2.3 Cross-Cultural E-mail Software with Emotion Translation

38
repeatedly. E-mails sent from Emotion Translation Mail can be opened in widely 
used mail clients, so the receiver does not need to run this software to see this 
e-mail. However, if the e-mail is opened in another mail client, only text is dis-
played. If Emotion Translation Mail received the message, the text is read aloud 
with motions that the sender decided on. This system enables us to realize more 
reliable e-mail-based communication that can convey the writer’s feelings. 
2.3.2.4  Each E-mail Is Stored on the Server 
 You can receive e-mails from Emotion Translation Mail using general e-mail soft-
ware. In fact, Emotion Translation Mail sends only text to other e-mail addresses. 
Then, when this software sends data such as emotional words, voices, and motions 
of the character, how are they viewed? 
 This system gives an “E-mail ID” to each e-mail. Then the system automatically 
adds the E-mail ID, password, and URL of the Web server to the body of the e-mail. 
The receiver software accesses the server and automatically inputs the ID and pass-
word to get the “emotional mail” stored on the server. 
 Figure  2.4 shows the whole procedure of creating or sending e-mail. The Web 
server and the sound-processing server are kept separate in order to avoid concur-
rent access to these servers. 
 The user downloads the Java applet every time he or she writes or reads e-mails. 
This method enabled the system to exist across any Web browser and be free in 
constructing its environment. 
 The Web server requires “send-mail” to send and receive e-mail and access its 
database. These are open source and widely used. By using this software, we kept 
the development costs down, and the maintenance is easier. 
2.3.3  Emotional Translation Character in a Computer 
Network 
 This software can connect the world’s e-mail systems using Emotional Translation 
Software. Each country’s own emotional characters can convey a message using 
responses that correspond with the relevant nationality. By exchanging emotionally- 
translated content, we can achieve cross-cultural dialogue through emotions. 
 By factoring in the emotion types of each country, emotional expressions of a 
country can translate into other countries’ emotions. Then, communication through 
emotions while considering other cultures’ feelings is achieved. This system has the 
potential to be an emotional programming software that strengthens the mutual 
understanding between people from different cultures. 
 In the future, we will be able to understand more emotions by merging these 
emotional models into one and analyzing the emotions on a computer. We will be 
2 Computing Feelings
www.allitebooks.com

39
able to make collections of the emotional information of each culture through com-
puters. If it is possible, this technology will contribute to humanity as a rich media 
that conveys deeply felt images across the world. This could have a huge impact and 
change the structure of our social system. This may even change normal relation-
ships within the information structures of modern society. 
 References 
 Arewa EO, Hale EE (1975) Poro communications (West Africa): a spiritual channel where men are 
the means of transmission. Anthropos H.2/1:78–96  
 Asimov I (1950) I, robot. Gnome Press, New York 
 Audet R, Romano C, Therrien C, Marchal H, Dreyfus L, Riviere D (2007) Narrativity: how visual 
arts, cinema and literature are telling the world today. Dis Voir, Paris 
 Bayraktar M, Zhang C, Vadapalli B, Kipp NA, Fox EA (1998) A web art gallery. In: Proceedings 
of the third ACM conference on digital libraries, pp 277–278 
 Bazin A, Gray H, Renoir J, Andrew D (2004) What is cinema? University of California Press, 
Oakland  
 Betsz D (1997) Tamagotchi: the ofﬁ cial care guide and record book. Virgin Books Ltd., London 
 Bhatia M (2012) Facial expression recognition system: extracting expressions from facial images. 
LAP LAMBERT Academic Publishing, Saarbrucken 
 Brabe S, Nass C (2009) Emotion in human-computer interaction. In: Sears A, Jacko JA (eds) 
Human computer interaction. CRC Press, Boca-Raton  
 Breese JS, Ball JE (1999) Modeling a user’s emotion and personality in a computer user interface. 
US patent 5987415A  
 Clay K (2014) Humanoid robots: running into the future. Capstone Press Inc, Mankato 
 Costello B, Muller L, Amitani S, Edmonds E (2005) Understanding the experience of interactive 
art: iamascope in beta_space. In: Proceedings of the second Australasian conference on inter-
active entertainment, pp 49–56 
 Cousens D (2013) Digital art. Arcturus Publishing Limited, London 
 Curtis G (2007) The cave painters: probing the mysteries of the world’s ﬁ rst artists. Anchor, 
New York 
 Dix A, Finlay JE, Abowd GD, Beale R (2003) Human–computer interaction. Prentice Hall, 
Mahwah 
 Eisenmenger R (1997) Virtual pets (Bradygames Strategy Guide). Brady Games 
 Eisner EW (2002) The arts and the creation of mind. Yale University Press, New Haven 
 Ekman P (2007) Emotions revealed, second edition: recognizing faces and feelings to improve 
communications and emotional life. Holt Paperbacks, New York 
 Esposito A, Faundez-Zanuy M, Keller E, Marinaro M (eds) (2007) Verbal and nonverbal commu-
nication behaviors, Lecture notes in computer science/lecture notes in artiﬁ cial intelligence. 
Springer, Berlin  
    Fagan TP (2011) The brilliant virtual world of our dreams – the quest to crack the enigma of dream 
consciousness. Grosvenor House Publishing Limited, Guildford  
 Fenollosa E, Pound E (2011) The Noh theatre of Japan: with complete texts of 15 classic plays. 
Dover Publications, New York 
 Fenollosa E, Pound E, Stalling J, Klein L, Saussy H (2010) The Chinese written character as a 
medium for poetry: a critical edition. Fordham University Press, New York 
 Gibson W (2005) Pattern recognition. Berkley, New York 
 Gray JD, Markel AH (1976) Linear prediction of speech. Springer, Berlin 
 Hanhardt JG, Hakuta K (2013) Nam June Paik: global visionary. GILES 
 Haykin SO (2008) Neural networks and learning machines. Prentice Hall, Mahwah 
References

40
 Houston SD (2008) The ﬁ rst writing: script invention as history and process. Cambridge University 
Press, Cambridge  
 Hu J, Bartneck C, Salem B, Rauterberg M (2008) ALICE’s adventures in cultural computing. Int 
J Arts Technol 1(1/2008):102–118 
 Jurafsky D, Martin JH (2008) Speech and language processing. Pearson Prentice Hall, Mahwah 
 Kalat JW (2011) Emotion. Cengage Learning, Independence 
 Kastner J (2010) Land and environmental art. Phaidon Press, London 
 Key MR (1975) Paralanguage and kinesics: nonverbal communication. Scarecrow Press, Lanham 
 King S, Taylor P (2000) Detection of phonological features in continuous speech using neural 
networks. Comput Speech Lang 14(4):333–353  
 Klasmeyer G, Sendlmeier W E (1995) Objective voice parameters to characterize the emotional 
content in speech. In: ICPhS’95, vol 1, p 182  
 Knapp ML, Hall JA, Horgan TG (2013) Nonverbal communication in human interaction. Cengage 
Learning, Singapore  
 Kuo SM, Lee BH, Tian W (2006) Real-time digital signal processing: implementation and applica-
tions. Wiley, Hoboken 
 Kwastek K (2013) Aesthetics of interaction in digital art. The MIT Press, Boston 
 Lancoboni M (2009) Mirroring people: the science of empathy and how we connect with others. 
Picador, New York 
 Laurel B (1993) Computers as theatre. Addison-Wesley Professional, Reading 
 Lazar J, Feng JH, Hochheiser H (2010) Research methods in human–computer interaction. Wiley, 
Hoboken 
 Lee K-F (1998) Large-vocabulary speaker-independent continuous speech recognition: the 
SPHINX system. Carnegie Mellon University, Pittsburg 
 Lee S-K, Rennert S (eds) (2011) Nam June Paik. Tate Publishing, London 
 Lees AL (2011) A history of experimental ﬁ lm and video. British Film Institute, London 
 McGilloway S, Bowie R, Bowie E D (1995) Prosodic signs of emotion in speech: preliminary 
content in speech. In: ICPhS’95, vol 1, International Phonetic Association, Canterbury, p 250.  
 McGonigal J (2011) Reality is broken: why games make us better and how they can change the 
world. Penguin, New York 
 McLuhan M (2011) Mechanical bride: folklore of industrial man. Gerald Duckworth & Company, 
London 
 McLuhan M, Lapham LH (1994) Understanding media: the extensions of man. The MIT Press, 
Boston  
 Mehrabian A (1972) Silent messages: implicit communication of emotions and attitudes. 
Wadsworth Publishing Company, Belmont 
 Mehrabian A (2007) Nonverbal communication. Aldine Transaction, Chicago 
 Meigh-Andrews C (2006) A history of vide art: the development of form and function. Bloomsbury 
Academic, London  
 Moura L (2013) Robot art: a new kind of art. CreateSpace Independent Publishing Platform, 
Seattle  
 Mozziconacci S (1995) Pitch variations and emotions in speech. ICPhS’95, vol 1, p 178 
 Nagamachi M (2010) Kansei engineering. CRC Press, Boca Raton 
 Neogy I (2012) When culture matters: the 55-minute guide to better cross-cultural communica-
tions. Verb Publishing Ltd, Buckland 
 Nicholson J, Takahashi K, Nakatsu R (2000) Emotion recognition in speech using neural networks. 
Neural Comput Appl 11:290–296  
 Nissenboim S, Vroman C (1998) Positive interactions program of activities for persons with 
Alzheimer’s diseases. Health Professions Press, Towson 
 Okamoto T (1993) Jibun no naka ni doku o mote (in Japanese). Youth, Tokyo 
 Pate AS (2008) Japanese dolls: the fascinating world of Ningyo. Tuttle Publishing, Clarendon 
 Paul C (2008) Digital art. Thames & Hudson, London 
 Picard RW (2000) Affective computing. The MIT Press, Boston 
2 Computing Feelings

41
 Rao KS, Loolaqudi SG (2012) Emotion recognition using speech features. Springer, Berlin 
 Rauterberg M, Hu J, Langereis G (2010) Cultural computing – how to investigate a form of uncon-
scious user experiences in mixed realities. In: Cultural computing: IFIP advances in  information 
and communication technology, vol 333, Springer, Berlin/Heidelberg/New York, pp 190–197 
    Rheingold H (1992) Virtual reality: the revolutionary technology of computer-generated artiﬁ cial 
worlds – and how it promises to transform society. Simon & Schuster, New York 
 Roman S, Packer D (1993) Opening to channel: how to connect with your guide. HJ Kramer, 
Tibron 
 Rotenberg M (2003) Hasidic psychology: making space for others. Transaction Publishers, New 
Brunswick  
 Rush M (2005) New media in art. Thames & Hudson, London 
 Russel S, Norvig P (2009) Artiﬁ cial intelligence: a modern approach. Prentice Hall, Mahwah 
 Sakagami Y, Watanabe R, Aoyama C, Matsunaga S, Higaki N, Fujimura K (2002) Intelligent 
ASIMO: system overview and integration. In: IEEE/RSJ international conference on intelli-
gent robotics and systems, vol 3. IEEE, New York, pp 2478–2483 
 Schemer KR (1995) How emotion is expressed in speech and singing. ICPhS’95, Royal Institute 
of Technology, Stockholm. vol 3, p 90 
 Schwartz JM, Begley S (2003) The mind and the brain: neuroplasticity and the power of mental 
force. Regan Books, New York 
 Schwarz H-P (1997) Media-art-history: media museum, ZKM, center for art and media Karlsruhe. 
Prestel, München  
 Shanken E (2009) Art and electronic media (themes & movements). Phaidon Press, London 
 Shriberg E, Ferrer L, Kajarekar S, Venkataraman A, Stolcke A (2005) Modeling prosodic feature 
sequences for speaker recognition. Speech Commun 46(3–4):455–472  
 Sommerer C, Mignonneau L (2006) Art as a living system: interactive computer artworks. 
Leonardo 32(3):165–173  
 Takahashi S (1990) Karakuri ningyo no bunkashi (Japanese Edition). Gakugei Shorin, Tokyo 
 Takahashi M, Morita T, Takaoka K (2010) Noh: classical Japanese performing art. PIE Books, 
Tokyo 
 Tosa N (1993) Talking to NEURO BABY. In: Ars Electronica’93, “Genetic Art-Artiﬁ cial Life” 
proceedings. Ars Electronica, Linz, pp 353–356  
 Tosa N (1995) Network neuro-baby with robotics hand, symbiosis of human and artifact. Elsevier 
Science BV, Amsterdam, pp 77–82 
 Tosa N, Nakatsu R (1996) Life-like communication agent: emotion sensing character MIC and 801 
feeling sensing character MUSE. In: Proceedings of the third IEEE international conference on 
802 multimedia computing and systems. IEEE, New York, pp 17–23 
 Tosa N, Murakami K, Sato S (1994) Neuro-character. In: AAAI’94 workshop, AI and A-life and 
entertainment. AAAI Press, Seattle  
 Tosa N, Matsuoka S, Ellis B, Ueda H, Nakatsu R (2005) Cultural computing with context-aware 
application: ZENetic computer. In: Springer lecture notes in computer science, vol 3711, 807. 
Springer, Berlin/New York, pp 13–23 
 Tribe M, Jana R, Grosenick U (eds) (2006) New media art. Taschen Publisher, Amsterdam 
 Wachsmuth I, Sowa T (eds) (2002) Gesture and sign languages in human computer interaction. 
Springer, Berlin 
 Whitley DS (2008) Cave paintings and the human spirit: the origin of creativity and belief. 
Prometheus Books, New York 
 Zeder S, Hancock J (2005) Spaces of creation: the creative process of playwriting. Heinemann 
Drama, Portsmouth  
References

43
© Springer-Verlag London 2016 
N. Tosa, Cross-Cultural Computing: An Artist’s Journey, Springer 
Series on Cultural Computing, DOI 10.1007/978-1-4471-6512-5_3
 Chapter 3 
 Computing Stories 
3.1  Transforming the Real World into the World of a Story 
 Stories stay alive by being handed down for hundreds or thousands of years by those 
who remember them. Largely as a result of my experimental impressions, I noticed 
the importance of stories in communicating with others reﬂ ected the information 
produced by cultures. 
 In 2001, I was invited to a workshop held in the The Banff Center, Canada. 
There, I witnessed the great talent known as ‘storytelling’ for the ﬁ rst time in my 
life. In Canada and America, some people were employed as storytellers. The ﬁ rst 
storyteller I met was Louise Profeit-LeBlanc, a cultured Inuit woman from Yukon 
Territory, Canada. Profeit-LeBlanc was popular because she had appeared on TV or 
radio programs and worked as an adviser on the traditional culture of the Yukon 
Territory. When she started to tell a story, the world changed slowly into a world of 
her creation. I felt that our VR experience using computers looked cheap in 
comparison. 
 I was so impressed when I felt that the scenery of the real world transforms into 
the world of the story. Other adults around me were absorbed in the world of her 
story, like children. Profeit-LeBlanc, like the Pied Piper of Hamelin, seemed to 
enchant the audience with her story; everyone in the room felt a sense of together-
ness as they listened. Great empathy was cultivated in her audience and energy was 
fed back into our hearts. Noticing the inﬁ nite power of stories, I was very eager to 
create a superior virtual interaction that would immerse our minds into a story, 
while analyzing the narrative on a computer. 
 Based on this experience, I started to develop systems that could fascinate people 
based on stories: an interactive poem system (Tosa and Nakatsu  1997 ,  1998 ), a 
comedy system (Tosa  2002 ), and an interactive movie system (Tosa and Nakatsu 
 1996a , Nakatsu and Tosa  1997 ). 

44
 First, I created an “Interactive Poem,” which composes a Renga poem 1 with the 
user using “You,” a poem written by the Japanese poet Shuntarō Tanikawa, 2 as the 
basis for generating the poem. As a comedy system, I created an “Interactive 
Comedy” in which a user plays a Japanese two-person comedy on a PC, with the 
computer taking the role of the Tsukkomi 3  (offensive person) and a user the role of 
Boke 4 (defensive person). For the movie, I created a work named “Interactive 
Theatre”, which uses Shakespeare’s “ Romeo and Juliet ” (Shakespeare  2012 ) as the 
basis and enables users to adopt the roles of the main characters and interact with 
other computer-generated personas. 
 Although these works might not be able to reproduce the magnetism of Profeit- 
LeBlanc’s stories, I found that users of the “Interactive Comedy” sometimes retorted 
back at the computer with anger and users of “Interactive Theatre” hugged each 
other after they played their roles as Romeo or Juliet; frequently, users felt deeply 
moved. 
 Many technical systems are expected to convey information. By contrast, I think 
these systems that I created could convey feelings like laughter, assent, and impres-
sions. These systems could realize this by centering on important roles in our daily 
communication like feelings and stories and on communicative interaction between 
humans and computers. 
 I think stories and memories are very important pieces of information in a  culture. 
If there were no stories, people could not pass down their memories (Gottschall 
 2013 ; Simmons and Lipman  2006 ). The feeling of being approached by something 
intimidating remains in one’s memory and constitutes a story. It is important for the 
audience to have their own internal sense of personal narrative that recall their own 
memories. One example can be observed in the patterns of Jōmon 5 earthenware. 
The relationship between patterns A and B constitutes a story as a code described in 
1  Renga is a genre of Japanese collaborative poetry. The origin of Renga is Waka, Japanese poetry 
that consists of ﬁ ve phrases each of which includes 5, 7, 5, 7, 7 syllables respectively. The ﬁ rst 
form of Renga started as a collaborative Waka creation between two people; one person created a 
former part with 5, 7, 5 syllables and another a latter part with 7, 7 syllables. Then the longer 
Renga, which is based on the repetition of this collaborative Waka creation, appeared as a collab-
orative Waka created by multiple people became popular. 
2  Shuntaro Tanikawa (born 15 December, 1931 in Tokyo, Japan) is a Japanese poet, translator  and 
scriptwriter . He is one of the most widely read and highly regarded Japanese poets, both in Japan 
and abroad. Several of his collections, including his selected works, have been translated into 
English. In addition to his poetry creation he has actively been doing various activities such as 
scenario writing, essay writing, lyric writing, etc. 
3  Manzai is a traditional style of stand-up comedy in Japanese culture. Manzai usually involves two 
performers – a straight and offensive man (Tsukkomi) and funny and defensive man (Boke) – trad-
ing jokes at great speed. Most of the jokes revolve around misunderstandings, double-talk, puns 
and other verbal gags. 
4  See footnote 3. 
5  The prehistoric period in Japan is named Jomon (around 16,500 years ago – around 3000 years 
ago). The name Jomon (straw-rope shaped pattern) came from the fact that a straw-rope shaped 
pattern is typically seen on many pots excavated from the strata of this period. The Jomon period 
ﬁ nished when rice farming was introduced into Japan from the Eurasian continent. 
3 Computing Stories

45
 letters and pictures, which are compiled into works ranging from short haiku 
(Hirshﬁ eld  2011 ) to grand operas. 
 Joseph Campbell (Campbell  1991 ), a mythologist, discovered a basic structure 
in the story of a hero’s birth. There are three central plots that are common among 
the birth of heroes in myths: Separation, in which the hero begins a journey; 
Initiation; and the Return. Campbell also indicated that ﬁ ve factors are important in 
story construction: World Model – The World: this world or another world; Story—
Plot, Script; Scene; Character; and Narrator—Omniscience, Omnipresence. We 
should note that the perspective of the Narrator can change from macro to micro 
perspectives. 
 A story is the combination of its center and circumjacent parts and this is the 
basis of variations in a story. I think that a culture has a similar structure. In each 
country there are basically two types of cultures; culture in an urban area and cul-
ture in a rural area. As people move between urban and rural areas, these two types 
of cultures are combined and thus a culture tends to change.  
3.2  Stories and Culture 
 When we think about stories, we think ﬁ rst of myths and fairy tales. Children grow 
up listening to myths or fairy tales told by their parents or grandparents. Myths are 
records of information as old as our racial origins. Learning a myth means implic-
itly learning details of a culture. We can learn about original Japanese feelings or 
sensibilities, as well as ideas behind Japanese culture, by learning myths written in 
the Kojiki (Record of Ancient Matters) 6 (Ono et al.  2012 ) or the Nihon-Shoki 
(Chronicles of Japan) 7 (Ono  2013 ). Some tales are based on historical events, and 
others are fables meant to teach lessons to children. Stories that have been handed 
down for many years teach us basic morals or ways to identify good from evil. 
Listening to such tales is entertainment and moral education at the same time. 
 These days, fewer children listen to myths or fairy tales in the conventional 
sense, but fairy tales and fantasies still play important roles in animation and chil-
dren’s ﬁ lms. Role-playing games (RPGs) (Peterson  2012 ) are a subset of video 
games such as “Dragon Quest” (Hartwig  2008 ) and “Final Fantasy” (Amano  2009 ) 
that use these fantasies. Even though fewer people listen to myths or fairy tales from 
their family members, they can access them through other media and are almost as 
likely to hear the old tales. 
6  Kojiki (Record of Ancient Matters) is the oldest extant chronicle in Japan, dating from the early 
eighth century. The Kojiki was composed in 712 by Ono Yasumaro at the request of the Empress 
at that time. The Kojiki is a collection of myths concerning the origin of the islands of Japan, 
 various Japanese Gods, and the uniﬁ ed process of the nation. 
7  The Nihon Shoki (Chronicles of Japan) is the second oldest book of classical Japanese history 
completed in 720. It is more elaborate and detailed than the Kojiki, and has proven to be an impor-
tant tool for historians and archaeologists. At the same time it is sometimes criticized that the 
content of the book is to justify the ruling system of the Emperor in Japan. 
3.2 Stories and Culture

46
 Stories provide interesting themes in the sense of differences between cultures. 
Interestingly, even though the situations or scenes of the world’s fairy tales vary 
depending on culture, the rough contents are the same. For example, the basic out-
line of “Cinderella” (James  2013 ) is as follows: A bullied heroine, who often 
appears as a fallen ﬁ gure, calls for help from her late mother. As proxies of her 
mother, animals, trees, and a ‘wizard’ as a godfather or godmother help the heroine 
with their marvelous powers, leading her to a happy ending The oldest model of 
Cinderella is the Chinese story “Ye Xian” (Mah  2010 ) by Duan Chengshi published 
in “ Miscellaneous Morsels from Youyang ” (Reed  1995 ) in the ninth century. 
“ Rhodopis ” (Climo  1992 ) from ancient Egypt is another version of the Cinderella 
story. Depending on the culture, Cinderella’s glass shoes may be written poems or 
the wizard may actually be a ﬁ sh. 
 Taboos sometimes appear in myths or folk tales. In the story of “ Urashima 
Tarō ”, 8 in Japan, there is a treasure box that the hero should not open, similar to the 
Greek myth of Pandora’s Box (Marzollo  2006 ). The world’s stories have thus spread 
while transmuting through cultural translation. 
 Myths and fairy tales from all around the world convey ancient racial memories 
and at the same time teach us morals for our daily life. There are two aspects of 
myths: their commonality among different cultures or races, and the items, modes, 
and codes of the local ethnicity. These two aspects are deeply embedded within our 
ethnic memories. I hoped to recall these memories, which were originally previ-
ously realized using storytelling, books, ﬁ lms, or animations, using new media. In 
this chapter, I will introduce three story systems. These systems differ from the 
present methods—like those of books, ﬁ lms, or animations—in that they can inter-
act with the user; scenes can change depending on the user’s action, instead of 
complying with a purely linear story. Additionally, I tried to import cultural expres-
sions that I learned from puppeteers, engineers, scientists, poets, and comedians 
into the stories. Moreover, I will show you how people perceived the computed 
emotions I created. 
3.3  A Computer Composes Renga (Japanese Interactive 
Poetry) with a Human 
 In Chap.   1 , I introduced a computer-generated character called “Neuro-Baby (Tosa 
and Nakatsu  1996b ),” which can communicate with humans based on feelings and 
emotions. However, it could not recognize language. Because humans assign 
8  Urashima Tarō is one of the most well-known Japanese  legends. It is about a ﬁ sherman who res-
cues a turtle and is rewarded for this with a visit to “Ryūgū-jō,” the palace of the Dragon God, 
under the sea. He stays there for only 3 days and, upon his return to his village, ﬁ nds that 300 years 
have passed. Rip Van Winkle is a similar story in America authored by Washington Irving. 
3 Computing Stories

47
emotional meaning to dialogue, they always tried to speak in their own language 
with “Neuro-Baby,” even though the software could not interpret their language. 
Even a child has the ability to create meaning when they are talking with puppets or 
other inanimate objects. Therefore, as a next step, I designed a communication tool 
that could identify the emotions behind words for the computer character. 
 In Japan, we have several ways of verbally expressing our emotions such as 
haiku or Waka. In this work, because the interactive exchange of emotion between 
a computer and a user is the center of interest, I adopted the Renga style, 9 a tradi-
tional Japanese style of interactive poetry, as the basic ‘structure’ of the interaction. 
Based on this basic concept, I developed the “Interactive Poem (Tosa and Nakatsu 
 1996a ,  b ),” with which the user could interactively compose poems. 
 Using “Interactive Poem,” the user can not only receive, but also actively col-
laborate with the computer in creating a poem and producing an interactive story. 
The story varies depending on who creates it. In other words, we realized a collab-
orative story artwork controlled by an individual’s style using an interactive dia-
logue method. 
3.3.1  Interactive Poem 
 MUSE, a character based on the Greek musical goddesses with the same name, 
appears on a large screen. MUSE recites a poem while talking to the user, in a man-
ner akin to singing, and says a short poetic phrase full of emotions. The user listens 
to the phrase and replies with a short phrase, and so unknowingly becomes absorbed 
in the world of poetry. Through this exchange of poetic phrases, “Interactive Poem” 
can create a world of improvised poems that are full of inspirations, feelings, and 
sensibilities (Fig.  3.1 ).
9  See footnote 1. 
 Fig. 3.1   Interaction between “Interactive Poem” and a user 
 
3.3 A Computer Composes Renga (Japanese Interactive Poetry) with a Human

48
3.3.2  Technology Used in This System 
 The “Interactive Poem” system is comprised of four parts: System Controller, 
Speech Recognizer, Image Generator, and Speech Output (Fig.  3.2 ).
3.3.2.1  Interactive Poem Mechanism 
 The most important function of this system is to create an interactive poem. I will begin 
by describing the database of the “Interactive Poem” system. Conventional poems are 
considered as a set of conjoined static phrases. That is, the basic composition of a con-
ventional poem is expressed as a simple transitional network. In this network, each 
phrase corresponds to a state, and each status connects to other states (Fig.  3.3 ).
System Control Unit
Speech
Output
Computer
 Graphics
Generation
Facial expression 
  data for Muse
Background image
Speech 
Recognition System
Phrase 
recognition
Emotion
recognition
 Fig. 3.2   System structure of “Interactive Poem” 
Phrase 1
Phrase 2
Phrase 3
Phrase 4
 Fig. 3.3   Simple transition of poem production 
 
 
3 Computing Stories

49
 The basic form of the “Interactive Poem” has a small difference from the simple 
transitional network. The simplest dialogue system with which the computer and 
the user alternatively speak to compose phrases of a predetermined poem is illus-
trated in Fig.  3.4 . To realize higher-order dialogue, we prepared multiple phrases 
that connect to the computer’s phrases. These phrases are selected carefully to 
match with other phrases in both phonological and semantic senses (Fig.  3.5 ). This 
transitional network is saved in the database and used to control the entire process. 
By these mechanisms, the user can add his own feelings or sensibilities to the world 
of the poem by talking to the computer and selecting phrases that ﬁ t his feelings or 
sensibilities.
 The “Interactive Poem” uses the poem called “You,” composed by Shuntarō 
Tanikawa. Using this process, we changed “You” so that it could be implemented by 
the “Interactive Poem” system. 
 First, the system delimits the poem into phrases, and separates these phrases into 
two categories: phrases that the user speaks, and phrases that MUSE speaks. A part 
of the poem is shown in the following: 
MUSE,
Phrase 1
USER,
Phrase 1
MUSE,
Phrase 2
USER,
Phrase 2
 Fig. 3.4   Simple user and computer interaction network for poem production 
USER,
Phrase 1
USER,
Phrase 2
MUSE,
Phrase 1
MUSE,
Phrase 2
 Fig. 3.5   Transition network for multiple poem production 
 
 
3.3 A Computer Composes Renga (Japanese Interactive Poetry) with a Human

50
 (a: a user, b: a computer)
  0.  Who are you? (b) 
  1.  You are not me (b) 
  2.  You are not him (b) 
  3.  Another person (b) 
  4.  You have the same ears as mine (a) 
  5.  And you hear different sounds from me (b) 
  6.  You are like me (a) 
  7.  You have ten ﬁ ngers (b) 
  8.  Something I cannot grab (a) 
  9.  You try to grab it (b) 
 10.  You (b) 
 11.  You are standing (a) 
 12.  In the sunlight of midsummer (b) 
 13.  Toward the ocean (a) 
 14.  Turning your back on me (b) 
 15.  You are looking (a) 
 16.  To the far horizon (b) 
 17.  In your heart (a) 
 18.  To a town I have never seen (a) 
 19.  On it I have never walked (a) 
 20.  A path is continuing (b) 
 21.  On the path (a) 
 22.  The snow is calmly falling (b) 
 23.  Someone I have never met (a) 
 24.  Is running toward me (b) 
 Figure  3.6 shows a morphing animation that adapted the emotions from the com-
puter poet, MUSE.
 In the next stage, the system selects multiple phrases that the user can speak, 
which correspond to each phrase that MUSE speaks. Below is an example:
 You are like me (a) 
 Who are you? (b) 
 You have the same ears as mine (a) 
 You have ten ﬁ ngers (b) 
 In your heart (a) 
 Another person (b) 
 On it I have never walked (a) 
 Then, the system expresses these as the transitional network shown in Fig.  3.5 , 
and saves them in the System Controller database. 
3 Computing Stories

51
3.3.2.2  Other Processes 
 Speech Recognition has two recognition modes: semantic recognition and emotion 
recognition. The system uses speaker-independent speech recognition to recognize 
the user’s semantic speech (Lee  1988 ). Each phrase is expressed as a sequence of 
phonetic parameters and saved into the Speech Recognition database. At the same 
time, the system recognizes the user’s emotions (Davis and Oda  2006 , Nicholson et 
al.  2000 ). As the basic architecture for emotion recognition, I used the neural net-
work ﬁ rst introduced in “Neuro-Baby” as described in Chap.   1 . 
 MUSE’s response to the user’s speech is expressed by music and images. Speech 
Output has the voice data of each phrase that MUSE speaks and plays them if 
needed. Computer Graphics Generation controls image expression. The image is 
composed of MUSE’s facial expressions and the background scene. MUSE’s facial 
expressions express MUSE’s response to user emotions. These facial expressions 
are expressed in a 3D morphing computer graphics animation corresponding to 
each of eight emotions (Fig.  3.4 ). To express the circumstances of the world of the 
poem, various background scenes are prepared and displayed in the screen, depend-
ing on the state of the transitional network. 
Anger
Surprise
Joy
Sadness
Teasing
Greeting
Neutral
Disgust
Fear
Strong feeling
Negative feeling
Positive feeling
Weak feeling
Anger
Surprise
Joy
Greeting
Neutral
Disgust
 Fig. 3.6   Two dimensional plane showing various “Muse” reaction 
 
3.3 A Computer Composes Renga (Japanese Interactive Poetry) with a Human

52
3.3.2.3  System Processing Details 
 When MUSE starts to speak the ﬁ rst phrase, a Recognition Process starts up. When 
the user talks into the microphone, the phrase is recognized by the computer’s 
semantic recognizer. The recognition system uses a subset dictionary that corre-
sponds to the next state of the transitional network. At the same time, the emotion 
in the phrase is recognized by the emotion recognizer. 
 The system’s response is based on the results from the recognition process and 
transitional network. MUSE’s facial expression changes depending on the emotion 
recognition results, and the spoken phrase is determined by the semantic recogni-
tion and transitional network results. The background scene changes depending on 
the state of the transitional network. 
 In this way, the system realizes a poetic interaction between the user and MUSE. 
3.3.3  Debut of the Prototype of This Story System 
 Using the “Interactive Poem,” a user can create a new poetic world that takes in the 
user’s feelings or emotions with assistance from the computer. This shows that the 
computer can draw out the user’s emotions and allow him to enjoy expanding his 
world and help create a story. My work was greatly admired, and the “Interactive 
Poem” won the L’Oréal Grand Prize of a L’Oréal competition for the fusion of art 
and technology, headed by the chairman of the award, Dr. Ilya Prigogine (winner of 
the Nobel Prize for thermal dynamics). If we can create systems with a basic story 
and grow the story by allowing it to branch off by itself, the possibilities and interest 
in this system grow bigger than ever. 
3.4  A Computer that Makes People Burst into Laughter 
3.4.1  Humor Is a Highly Internal Intelligence 
 In my work “Interactive Poem,” I created the story through poetic dialogue with a 
computer in VR. The vitality of our daily life can often be found in sharing a 
moment of laughter with a witty friend. Therefore, as a next step I tried to model 
these information structures for humor to spark more emergent communication. 
 Humor is frequently based on regional culture. Even within Japan, Eastern and 
Western humor are completely different (Davis and Oda  2006 ). We cannot understand 
these differences in humor without understanding the relevant nation and culture. A 
typical example would be comedies in the United Kingdom (Hill  2013 ), which fre-
quently include many moments of humor where Japanese people cannot understand 
why anyone should laugh. 
3 Computing Stories

53
 I studied the defensive person (Boke) and offensive person (Tsukkomi) in 
Japanese comedy 10 and found that their interactions made people laugh because the 
user, acting as the funny person, is mocked in a form of comedy. 
 Computers help us to think or remember more than before by storing infor-
mation. With this artwork, we are trying to make computers instigate laughter for 
internal fulﬁ llment or for the happiness of living. It is difﬁ cult to use computers 
for a ﬁ eld like this because while humor is an important interface that connects our 
subjective lives, it is more of an internal intelligence than, say, the problems of 
analysis or logic. 
 In other words, humor is an intelligence that represents empathy (Lachmann 
 2007 ) and has a very strong power over humans. AI used to focus too much on the 
analysis and understanding of observable intelligence, but I wanted to develop com-
puters that have the ﬂ exibility to communicate with people in good humor. Now, I 
will introduce the system I created while considering this as a basic concept.  
3.4.2  Interactive Comic Dialogue 
 “Interactive Comedy” is a computer system that I developed with Yoshimoto 
Kogyo 11 as a joint research project. A computer plays the role of a straight person 
(offensive character) and the user plays the role of the funny person (defensive char-
acter). When the user talks to the computer, it detects the user’s feelings, meanings, 
speed of speech, and determines the phrases and the timing of its replies to the user. 
The conversation goes well through these interactions. The user can enjoy the dia-
logue like a game of catch. The user unconsciously plays the role of the funny per-
son, and is responded to by the computer (Fig.  3.7 ).
 An example of a conversation using various conversational scenarios provided 
by Yoshimoto Kogyo follows: 
 User 
 We’re happy that people come to see us when they’re doing busy research 
or work! 
 PC 
 That’s true. 
 User 
 But I think that people who are truly busy are not here. 
 PC 
 Don’t say unnecessary things! 
 User 
 But, everyone, do you know how long we’ve been tackling this research? 
It’s taken nearly 300 years! 
 PC 
 You’re kidding! 
 User 
 I got it. You are comfy because you are devotedly executing the operation. 
 PC 
 I can’t understand what you’re saying. 
10  See footnote 3. 
11  Yoshimoto Kogyo is a major Japanese entertainment conglomerate, with its headquarters based 
in Osaka. It was founded in 1912 as a traditional theatre, and since then has grown to be one of the 
most inﬂ uential entertainment companies in Japan. 
3.4 A Computer that Makes People Burst into Laughter

54
 User 
 You are replying to us by thinking for yourself, aren’t you? 
 PC 
 I’m sorry, but I couldn’t hear you. 
 User 
 You’re great! One and all, please give him your applause! 
 PC 
 I don’t need your clapping, but I need some money! 
3.4.3  Technology Used in This System 
 The system consists of ﬁ ve parts. The Speech Recognition system processes the 
meaning recognition of a phrase uttered by a user. Then, the Feeling Analyzer ana-
lyzes the tone of the user’s voice, the input timing, and the speed. Using these 
results, the system obtains the level of the user’s absorption. In Character 
Composition, the facial expression of the computer graphics comedy player is 
determined by using the results from meaning recognition and detection of absorp-
tion level, and generates the reply voice (Fig.  3.8 ).
3.4.3.1  The Feelings Model 
 The model consists of nine feelings: happiness, joy, teasing, fear, sadness, disgust, 
anger, surprise, and the static state; these are similar to those of “Neuro-Baby.” 
Various kinds of utterances corresponding to each of these feelings were collected 
and used as the supervisor data for the development of the neural network (Fig.  3.9 ).
 Fig. 3.7   A user interacting with “Interactive Comedy” 
 
3 Computing Stories

55
Voice Input
Voice recognition
Sound analysis
Timing analysis
Determination of enthusiasm 
Enthusiasm analysis
CG Manzai character control
Manzai dialogue
Database
Manzai dialogue
realtime 
CG animation
Character synthesis
Scheme 2 System Structure
Meaning 
recognition
 Fig. 3.8   Block diagram of “Interactive Comedy” 
[Anger]
I cannot take it 
anymore
Don’t lie!
[Suprise]
Oh,snap!
Are you serious?
「Joy」
Hurray!
Wonderful!
「disgust」
You’re telling me
Who cares!
Stop talking 
nonsense
「Neutral」
Say again?
「Greeting」
What’s new?
Hello!
「Sadness」
It’s all over
I feel lonly
「Fear」
Scarly 
I’m worried...
「Teasing」
So what?
Stupid!
Strong voice
High pitch
Low pitch
Weak voice
 Fig. 3.9  Emotion model of “Interactive Comedy” 
 
 
3.4 A Computer that Makes People Burst into Laughter

56
3.4.3.2  Mapping Feelings 
 The feeling recognition result is converted into a two-dimensional feeling map and 
is sent to the script manager. When the user’s identity changes, the system tunes the 
expected value to the voice of the new user. 
3.4.3.3  Speech Recognition 
 The speech recognition result is compared with the dictionary. If the result corre-
sponds with one of the words/phrases in the dictionary, the script manager decides 
the phrase to be sent by the system. If no words are recognized, it uses output from 
the feeling recognition result (Fig.  3.10 ).
3.4.3.4  Script Manager 
 The script manager determines the level of the user’s absorption from the feeling 
and speech recognition results, and determines the facial expression of the computer 
graphics-based agent as well as the speech output (Fig.  3.11 ).
Voice input
Voice recognition
Hidden Markov Model
decision
Result of recognition
 Fig. 3.10   Structure of voice recognition part 
 
3 Computing Stories

57
3.4.3.5  Real-Time Computer Graphics Generation and Speech Output 
 The script manager sends the results to the Computer Graphics Generation, which 
has 30 patterns of facial expressions that are complemented in real-time by the data 
to create a facial expression for output. At the same time, the script manager deter-
mines the speech output and the type of voice (a feeling-based voice or the result of 
speech recognition) (Fig.  3.12 ).
Result of Analyze of enthusiam
Analysis of tone
 Analysis of timing
Decision of enthusiam 
If (tone is A,timing is B)....
Neural Network
Voice input
 Fig. 3.11   Structure of absorption recognition part 
Result of meaning
Result of enthusiasm
Decision of enthusiasm
Voice detabase of 
Comedy interaction
Real time animarion of
Comedy interaction
Transition network
 Fig. 3.12   Structure of character response generation part 
 
 
3.4 A Computer that Makes People Burst into Laughter

58
3.4.4  “Interactive Comedy” Incident 
 I was invited to deliver a speech titled “Japanesque Interactive Arts” at a large 
Japanese cultural event named “Spring Fiesta” held by the Consulate-General of 
Japan in Boston to demonstrate “Interactive Comedy.” This system was originally 
developed to entertain Japanese people by enabling them to play Japanese comedy 
using a computer, as mentioned previously. I collaborated with Mr. Isao Takenaka, 
a producer colleague of Yoshimoto Kogyo. I developed the interactive function of 
the system, and Yoshimoto prepared the Japanese comedy script to be stored in the 
system. The developed system won greater popularity among the general popula-
tion in Kansai, Japan than I ever expected. 
 However, humor depends on the local culture and we were in Boston. To test the 
system before the cultural event, I showed the system to my supervisor, Prof. 
Benton, but he did not laugh at all. I thought that it was necessary to change the 
script for Bostonians, and I looked for comedians within Boston who could play 
similar comedy to Japanese comedy. But the two-person style Japanese comedy 
seems much more popular in Asia than in the United States. Later, I found that 
improvisational comedy has some similarity. In improvisational comedy, a leader 
proposes a theme, and the other members improvise jokes based on that theme. 
 I watched a live performance of a locally very popular improvisational comedy 
group called “Improv Asylum” 12  in Boston and decided that their comedy could be 
applied to our system. The group came to see the demonstration of “Interactive 
Comedy” and showed interest in the system. I then met with their director. Once our 
collaboration began, Improv Asylum members changed Yoshimoto’s Japanese text 
to one that was full of Bostonian slang and jokes. At that point, the scenario was no 
longer understandable to the Japanese, but Bostonians laughed! Humor is such a 
delicate aspect of local culture. 
 As a challenge, we should investigate the relationships between ‘stories’ and 
‘reactions’ that generate the internal side of humor. People say that a story ‘jumps’ 
when its center and fringes collide. A story’s humor is generated when people feel 
some abnormalities, forces, collisions, or backlashes among the story’s elements. 
For example, if we encounter a wild animal while walking in the woods or we sud-
denly receive an unexpected gift from our friends, this randomness sparks humor 
within our stories, and this jump or spark is a basis for comedy. Additionally, we 
would be surprised if, after using a certain doorknob every day, we discover that it 
is actually made of sweets. These elements of surprise arise when a daily event is 
transformed, and the user’s consciousness jumps from the elements of surprise.  
12  See footnote 8. 
3 Computing Stories

59
3.4.5  Automatic Generation of Feelings and Stories: 
“Interactive Theatre” 
 Here, I introduce a system that enables the user to be an actor or actress of a story 
and to have fun with the changes in the story. Nowadays, story contexts in which the 
users can play the roles of characters in ﬁ lms or video games are popular. However, 
it is very challenging to produce an automatic story generation based on interaction 
results. Most of the research in this ‘interactive story-telling’ (Cavazza et al.  2002 ; 
Glassner  2004 ) ﬁ eld focuses on automatic generation of interactive stories after 
presetting their theme. 
 In contrast with interactive stories, the stories of present novels or ﬁ lms are called 
‘linear stories.’ Interactive stories, relative to linear stories, have the following 
 beneﬁ ts (Riedl and Young  2006 ; Murray  1998 ). The user does not watch passively, 
but actively participates in the progress of the story (so the user is not only the 
viewer, but also the participant). In this case, the user can create his or her own ideal 
stories. The application of these interactive stories can vary from being mere enter-
tainment to having educational or training uses. 
 Current linear stories are based on the well-thought-out plans of authors and 
methods to fascinate readers in VR have been established, but interactive stories are 
relatively new, so there are many unknowns, especially for methods to construct 
these stories. Below, I will show the concept and features of the system I created, 
and show how to make the story progress within this system (Tosa and Nakatsu 
 1996a ,  b ; Nakatsu and Tosa  1997 ). 
3.5  Interactive Theatre Generates Feelings and Stories 
3.5.1  Story Generation 
 Here, I refer to methods of designing or creating a story on a system that processes 
interactive stories. The following methods can be considered when we think about 
the interactive generation of stories: 
3.5.1.1  Fixed Story Method 
 This method has been used in one-way transitional media like present novels or 
ﬁ lms. Non-interactive media naturally uses this method. The merit of this method is 
that successful methodologies for literature and ﬁ lms have been established based 
on their long history. Experienced authors or ﬁ lm directors know how to construct 
good stories (Mackendrick and Cronin  2005 ; Lumet  1996 ). 
3.5 Interactive Theatre Generates Feelings and Stories

60
3.5.1.2  Half-Fixed Story Method 
 This is a method in which the rough scheme of the story is already prepared. In this 
sense, it is the same as the ﬁ xed story method, like novels or ﬁ lms. However, the 
story has a little latitude to be changed (or it has multiple possibilities that can be 
chosen to progress the story). The user interacts to some extent and has fun within the 
freedom of the story. Many recent RPGs apply this method (Tychsen et al.  2006 ).  
3.5.1.3  Free Story Method 
 This is a method where the story is not prepared at all and depends on interaction 
with the user. The software’s creators construct only the world in which the story 
progresses, and lets the users create the story. Superﬁ cially, this method is the freest 
and it may give the user fulﬁ llment, but this is not always true for the following 
reasons: (a) We needed to create a system that considers all possibilities because we 
cannot predict user actions. This is equal to creating a whole world, so it is very 
difﬁ cult, if not impossible. The closest thing to this would probably be massively 
multiplayer online RPGs (MMORPGs) (Feng et al.  2007 ); (b) The same thing 
occurs with the user, that is, if the user is given true freedom, she or he may be 
bewildered as to how to do anything in the VR world. This reproduces a similar 
 situation as the ﬁ rst trip to culturally dissimilar countries, where the user cannot tell 
left from right. 
 Therefore, the free story method is currently difﬁ cult to realize, but it may be 
possible to fully realize it in the future. In designing the “Interactive Comedy” and 
“Interactive Poem” systems, I felt that the half-ﬁ xed method was the most realistic 
current approach (Tosa and Nakatsu  1997 ; Tosa  2002 ). 
3.5.2  Story Interactivity 
 When we think about the interaction between the user and characters, the following 
points are important. 
3.5.2.1  Multimodal Interaction 
 Humans communicate using multimodal interactions. Concretely speaking, we use 
our voice, facial expressions, and gestures in face-to-face communication. Therefore, 
multiple inputs are better than a single input (Norris  2004 ). This concept is impor-
tant in realizing more natural interactions, deeper absorption, or empathy. 
 Because “Interactive Theatre” is new media, we can use inputs other than the 
normal inputs in our interactions or communications. It is necessary to use more 
stable input methods when we consider that the voice and image recognition 
3 Computing Stories

61
technologies are not fully matured and that they produce results with more errors 
than human processes. We can use push buttons or use foot sensors and motion 
captures for these methods. 
3.5.2.2  Verbal/Nonverbal Interaction 
 Human communication contains both verbal and nonverbal information. Nonverbal 
information contains personality, feelings, and sensibilities (Mehrabian  2007 ). As I 
referred to in the previous chapter, information about feelings or sensibilities plays 
an important role in our communications. Therefore, our characters should have 
functions to recognize and express feelings to realize nonverbal communication 
with humans. But nonverbal communication is insufﬁ cient to convey all informa-
tion, which means that verbal communications are still required. We still need to use 
speech recognition to recognize the meaning of the user’s words. 
 These are the concepts that “Interactive Theatre” are based on. This is new media 
with a style that integrates previous ﬁ lms, novels, video games, and communica-
tions. In comparing this media with present media, the closest description could be 
‘a movie or theatre that the viewer can participate in.’ The name of “Interactive 
Theatre” is based on these basic concepts. 
3.5.3  System Features 
 In the following, I refer to example artworks that I constructed based on the con-
cepts of “Interactive Theatre.” 
 RPGs are the typical example of interactive stories (Fine  2002 ), a subset of video 
games. Users can have fun in the story by playing the role of the main characters. 
Most RPGs have complete stories that are a mixture of the growth of the hero and 
the standard adventure game story, such as where the hero ﬁ ghts against evil and 
wins, but develops strong motivations along the way. 
 While RPGs have succeeded commercially, they have some limitations because 
their R&D in interactive storytelling is limited. I designed this system to differenti-
ate from conventional RPGs, by providing new functions and considering future 
possibilities to be developed. The features of this system are below: 
3.5.3.1  Controlling the Story with Multiple Inputs 
 The basic input method of video games are buttons. Some currently designed con-
trollers have acceleration sensors that also allows them to detect movement. 
Interactions that progress the story should be closer to communication between 
humans. In this system, we aimed to realize natural voices and interactions with 
gestures using speech recognition and motion capture, which will enable the partici-
pant to feel as if she or he is an actor or actress in the movie or drama. 
3.5 Interactive Theatre Generates Feelings and Stories

62
3.5.3.2  Realizing a Natural Interaction at Any Time 
 In interactive stories, the story may be distributed to the user through media’s 
 interactions with the user. Therefore, RPGs limit the possibility of unfolding stories 
through interaction. For example, when the user talks to a character, she or he 
will ﬁ nd no important reaction from the character if the character is not key to 
progressing the story. Therefore, interactions that have no relation to the story are 
usually disabled. 
 To include more frequent user interactions, we can create a mechanism for the 
user to interact with the characters in the story any time, which will be dramatic 
when sentimental interaction largely affects a story (Nakatsu et al.  1998 ). 
3.5.4  Software Composition 
 We needed to control the story appropriately and improvise interactions by consid-
ering the unfolding story and ‘any-time interaction.’ Therefore, we created a 
displaced- control-like system. The system composition is shown in Fig.  3.13 . I shall 
explain each part of the system simply.
Script
Manager
Scene
Manager
Interaction
Manager
Image
Handler
Voice
Recognition
Handler
Emotion
Recognition
Handler
Gesture Recognition
Handler
Motion Capture
Handler
Voice
Handler
 Fig. 3.13   Block diagram of “Interactive Theatre” 
 
3 Computing Stories

63
3.5.4.1  Script Manager 
 The Script Manager controls the entire interactive story by generating the interac-
tive scenario using a prepared scenario that was written by an author. Concretely 
speaking, the Script Manager deﬁ nes the elements of each scene and controls the 
transition between scenes. The transitions between scenes are expressed in the tran-
sition diagram (Fig.  3.14 ).
3.5.4.2  Interaction Manager 
 The Interaction Manager is placed under Script Manager and Scene Manager, and 
controls the interactions of each scene. We used vocal information and observed 
actions for these interactions. We applied a combination of speech and action recog-
nition to realize this multimodal interaction (Fig.  3.15 ).
Scene
Scene 2
Scene 3
Scene 4
Scene 5
Scene 2-2
Scene 2-1
Scene 2-3
Scene 2-4
Scene 2-5
Scene 2-6
 Fig. 3.14   Transition network of the script manager 
 
3.5 Interactive Theatre Generates Feelings and Stories

64
3.5.4.3  Handlers 
 Handlers (Fig.  3.16 ) are placed under the Scene Manager’s Interaction Manager. 
They control the input and output devices. We prepared the following handlers: 
(a) Speech Recognition Handler, recognizes the words or sentences the user has 
voiced, and sends them to the Interaction Manager. (b) Feeling Recognition Handler, 
recognizes feelings and sends them to the Interaction Manager. The methods of 
feeling recognition are the same as that of “Neuro-Baby.” (c) Motion Recognition 
Scene 2
Background
Image
Background
Music
Computer
Graphics
(Character 1)
Computer
Graphics
(Character 2)
Dialogue
(Character 1)
Dialogue
(Character 2)
Interaction
(Gesture)
Activeness
 Fig. 3.15   Transition network of the interaction manager 
Sound Output System
Mixer
PC
Sound Output
human motion recognition
sub system
Motion Capture
PC
 Motion Capture
PC
Emotion and Voice recognition
Sub System
Emotion and 
Voice recognition
PC
Image Generation System 
Computer Graphics
PC
LAN
Hardwere System
Emotion and 
Voice recognition
PC
Computer Graphics
PC
PC
Sound Output
 Fig. 3.16   Various handlers used in “Interactive Theatre” 
 
 
3 Computing Stories

65
Handler, sends the input data from motion captures to the Interaction Manager. At 
the same time, this part recognizes simple gestures for input data. (d) Sound Handler, 
processes the characters’ speech and any BGM (background music). (e) Image 
Handler, outputs the Computer Graphics character and the background images.
3.5.5  The Future of Digital Storytelling 
 As I referred to above, a story has basic structures in it. The combination of these 
structures creates the backbone of a story. Myths and fairy tales have their own 
structures and have passed down through generations, spread out, and changed to ﬁ t 
the culture of each region. 
 Stanisław Lem, who wrote “ Solaris ,” visualized the intelligence of future genera-
tions as one that transcends the biological limits of current humans’ brains through 
works that set their concept as a “collection of introductions to virtual books,” a 
book of “bit literature,” which are impressive books written entirely by AI and not 
by humans. These could include “harlequin romance novels” written and updated 
by a future-predicting computer or the lectures of Lem’s “Golem XIV”, which is a 
future computer with an intelligence far transcending that of humans. In the future, 
like these works, we will be able to construct databases of worldwide stories by 
systematization and accumulation, to make computers generate scenarios, and to 
read stories by computers that humans have never imagined before. 
 References 
 Amano Y (2009) Dawn: the worlds of ﬁ nal fantasy. Dark Horse Comics, Milwaukie 
 Campbell J (1991) The power of myth. Anchor, New York 
 Cavazza M, Charles F, Mead SJ (2002) Character-based interactive storytelling. IEEE Intell Syst 
17(4):17–24  
 Climo S (1992) The Egyptian Cinderella. Harper Collins, New York 
 Davis JM, Oda S (2006) Understanding humor in Japan. Wayne State University Press, Detroit 
 Feng W, Brandt D, Saha D (2007) A long-term study of a popular MMORPG. In: Proceedings of 
the 6th ACM SIGCOMM workshop on network and system support for games. ACM, New 
York, pp 19–24 
 Fine GA (2002) Shared fantasy: role playing games as social worlds. University of Chicago Press, 
Chicago  
 Glassner A (2004) Interactive storytelling: techniques for 21st century ﬁ ction. A K Peters/CRC 
Press, Natick  
  Gottschall J (2013) The storytelling animal: how stories make us human. Mariner Books, New York 
 Hartwig K-D (2008) Dragon quest. Piggyback Interactive, London 
 Hill T (2013) The British: an awfully useful guide. Summersdale, Chichester 
 Hirshﬁ eld J (2011) The heart of Haiku. Amazon Digital Services, Seattle 
 James J (2013) Cinderella (Faerie tale collection). StoneHouse Ink, Edmonton 
 Lachmann FM (2007) Transforming narcissism: reﬂ ections on empathy, humor, and expectations. 
Routledge, London  
References

66
 Lee K (1988) Large-vocabulary speaker-independent continuous speech recognition: the SPHINX 
system. Carnegie Mellon University, Pittsburg 
 Lumet S (1996) Making movies. Vintage, New York 
 Mackendrick A, Cronin P (2005) On ﬁ lm-making: an introduction to the craft of the director. Faber 
& Faber, London  
 Mah AY (2010) Chinese Cinderella. Ember 
 Marzollo J (2006) Pandora’s box: a Greek myth about the constellations. Little, Brown Books for 
Young Readers, New York 
 Mehrabian A (2007) Nonverbal communication. Aldine Transaction, Chicago 
 Murray JH (1998) Hamlet on the holodeck: the future of narrative in cyberspace. The MIT Press, 
Boston 
 Nakatsu R, Tosa N (1997) Toward the realization of interactive movies – inter communication 
theatre: concept and system. In: Proceedings of IEEE international conference on multimedia 
computing and systems. IEEE, New York, pp 71–77  
 Nakatsu R, Tosa N, Ochi T (1998) Interactive movie system with multi-person participation and 
anytime interaction capabilities. In: Proceedings of the sixth ACM international conference on 
multimedia. ACM, New York, pp 2–10  
 Nicholson J, Takahashi K, Nakatu R (2000) Emotion recognition in speech using neural networks. 
Neural Comput Appl 9(4):290–296  
  Norris S (2004) Analyzing multimodal interaction: a methodological framework. Routledge, 
London 
 Ono Y (2013) The Nihongi: chronicles of Japan from the earliest times to A.D. 697. CreateSpace 
Independent Publishing Platform, North Charleston  
 Ono Y, Chamberlain BH, Struik A (2012) The Kojiki. CreateSpace Independent Publishing 
Platform, North Charleston  
 Peterson J (2012) Playing at the world. Unreason Press, San Diego 
 Reed CE (1995) Youyang Zazu: miscellaneous morsels from Youyang. University of Washington, 
Washington 
 Riedl MO, Young RM (2006) From linear story generation to branching story graphs. IEEE 
Comput Graph Appl 26(3):23–31  
 Shakespeare W (2012) Romeo and Juliet. Simon & Brown, Victoria 
 Simmons A, Lipman D (2006) The story factor. Basic Books, New York 
 Tosa N (2002) Interactive comedy: laughter as the next intelligence system. In: Proceedings of 
2002 international symposium on Micro-Nano Mechatronics and human science. IEEE, New 
York, pp 135–138 
 Tosa N, Nakatsu R (1996a) For interactive future movie: body communication actor MIC & feel-
ing improvisation actor MUSE. In: Proceedings of the 7th international symposium on 
Electronic Art’96. ISEA, Brighton, pp 126–129  
  Tosa N, Nakatsu R (1996b) The esthetics of artiﬁ cial life characters. In: Artiﬁ cial Life V, proceed-
ings of the ﬁ fth international workshop on the synthesis and simulation of living systems. A 
Brandford Book, Cambridge, MA, pp 122–129  
 Tosa N, Nakatsu R (1997) Interactive poem. In: Proceedings of the AIMI international workshop 
on Kansei: the technology of emotion, DIST, pp 54–59  
 Tosa N, Nakatsu R (1998) Interactive poem system. In: Proceedings of the 6th ACM international 
multimedia conference. ACM, New York, pp 115–118  
 Tychsen A, Hitchens M, Brolund T, Kawakli M (2006) Live action role-playing games: control, 
communication, storytelling, and MMORPG similarities. Games Cult 1(3):252–275  
3 Computing Stories

67
© Springer-Verlag London 2016 
N. Tosa, Cross-Cultural Computing: An Artist’s Journey, Springer 
Series on Cultural Computing, DOI 10.1007/978-1-4471-6512-5_4
 Chapter 4 
 Computing Culture 
4.1  Picking Up Cultural Information 
 The previous chapters illustrated how to compute feelings and stories, which are 
important elements of culture. Now it is time to show an example of cultural 
 computing that applies to culture itself. 
 Currently, many computing projects that contain cultural content have only 
 digitalized cultural information as data and archived them. Some have visualized 
cultural heritage like urban heritage using VR technology (Song  2009 ; Falser and 
Juneia  2013 ; Silberman  2005 ). Unfortunately, most of them do not show the depth 
of the culture, but only the surface. 
 As I mentioned in the ﬁ rst chapter, we have obtained a global communication 
sphere by introducing various media technologies into our daily life; however, we 
are also concerned that our communication is becoming shallower. We urgently 
need new communication media that can convey the depth of a person’s feelings. 
Originally, communications were fostered in the cultural environment created by a 
region, race, climate, and language. Cultures are rooted in their unique histories. 
 Communications by letters, music, and movies have been developed to mutually 
communicate the unique qualities of various cultures. Today, when computers are 
widespread, those computers should take up the challenge to promote communica-
tions among local and global cultures properly. Computer engineers are also needed 
to put the local characteristics of each culture to practical use on the computer. 
 Informatics has been developed separately from technology, but in order to 
 utilize the quantity of information, it has focused on the creation of an infrastructure 
to manage the quantity. However, there is another classiﬁ cation of this information 
called ‘information of meanings,’ which represents the quality of the information, 
such as feelings or culture. It is important to deal with the ‘information of meanings.’ 
Present technologies have used only the globally shared aspects of the world and 
ignored the local. However, locally produced technology has cultural information 
that is unique to each country. 

68
 To investigate cross-cultural communications (Neogy  2012 ; Cohen  1997 ), there 
have been several experiments that allowed a machine to engage in cultural interac-
tions with users. One experiment showed that machine translations seem to be 
effective in cooperative research and development between different cultures 
(Yamashita and Ishida  2006 ). Another study explored the role of computer agents in 
cross-cultural communications on the Internet and found that if the agent broke a 
cultural taboo, people tended to gather on the Internet, and communications among 
people tended to go smoothly (Ishida  2006 ). These results are interesting, because 
it shows that people do indeed want ‘depth’ in their communications. 
 This research is practical for studies of universal cross-cultural communication, 
but in identifying the universal aspect of communication, it must be related to its 
local aspect. The depth of individual communication is seen as being included 
in local cultures, but few studies have focused on this kind of experience and these 
unique ways of communication. 
 It is time to research systems that help us to experience the cultural stories buried 
inside our indigenous identity. Here, I present research on interactive expressions 
that synthesize the inner essentials of culture such as subjectivity, feelings, ethnic-
ity, and narrativity, which have never been quantiﬁ able before. I deﬁ ne ‘Cultural 
Computing’ (Rauterberg and Hu  2010 ; Tosa  2006 ) as the integration of these 
research topics with a method of storytelling that reﬂ ects differences in feelings, 
consciousness, and memories, which are essential for future communication using 
computers. 
 Let us consider the beneﬁ ts of cultural computing by comparing it with current 
computing culture. First, cultural computing expresses not only visualized cultural 
contents, but also the structure of each culture. Therefore, it enables us to under-
stand different cultures more easily. Cultures have complex structures, so museums 
often exhibit only some aspects of cultural contents. However, knowledge and inter-
est levels vary between visitors, and no system has been created that can reply to all 
potential questions. 
 This type of system would enable us to simulate a person with a given cultural 
model. We could interactively experience the spirit of a culture we are interested in 
by controlling the process (for example, the entry of Buddhism into Japan). 
Furthermore, it would become possible to create a brand-new popular culture that 
would integrate multiple existing cultures. 
 Needless to say, these are currently only a possibility. Cultures have layered 
structures, and quantifying them is not simple. What I discuss in this chapter are 
examples of the processes with which I approach the larger idea of ‘Cultural 
Computing.’ I hope that researchers and artists with the same interests would par-
ticipate and widen the foothold that cultural computing is gaining. 
 Now, I will show methodologies for cultural computing. What I want to show 
you at ﬁ rst is an interactive system named “Unconscious Flow” (Tosa  2006 ; Tosa 
and Nakatsu  2000 ) that was designed to visualize an afﬁ nity for communication. 
 Cultural information also exists behind communicative information in our daily 
communications. Everyone remembers cultural courtesies in face-to-face commu-
4 Computing Culture

69
nication. In Japan, even if we are angry, we will smile and thank someone as a 
 matter of courtesy (Nishiyama  1999 ). Every culture has its own social rules that 
people are expected to follow. 
 Edward T. Hall, a cultural anthropologist, spoke about the differences in ‘space’ 
between cultures; that is, that people in different cultures not only speak different 
languages but, in a sense, they also live in a different world. He called this “proxe-
mics” (cultural proxemics) (Hall  1973 ,  1990 ). 
 Hall divided the potential distances between humans into four: “intimate dis-
tance,” “personal distance,” “social distance,” and “public distance” (Hall  1973 , 
 1990 ). An “intimate distance” is a close distance characterized by not only love and 
protection, but also arguing and ﬁ ghting. A “personal distance” is the distance dur-
ing communication with another person. A “social distance” is the distance during 
business talk, and a “public distance” is the distance of a speech in a lecture meet-
ing. The differences of each culture’s characteristics are explained, to some extent, 
by using proxemics. This is because the human desire for close distances, and the 
actions related to those desires, are what form human relations. In other words, the 
distance between people is determined by the feelings they have about each other. 
 In thinking about signiﬁ ers of communication from a physical perspective, it is 
obvious that verbal lies are easy to speak, but physical lies are difﬁ cult to hide. In 
“Unconscious Flow,” I tried to visualize cultural codes as empathy within commu-
nication by using proxemics and physiological information. 
 The next thing I learnt was the experiential system of Sansui Zen called “Art of 
ZEN” (Tosa et al.  2005 ). The concept of cultural computing uses culture itself, so 
we needed to focus on a certain culture initially and I created a system based on 
Japanese culture. I tried to compute the spirit that represents this culture. In making 
the “Art of ZEN,” I researched the possibility of interactions based on inspiration 
included in Zen dialogue and interactions associated with Japanese symbols and 
allegories. The system was exhibited in a museum in Japan, in other countries, and 
in a Zen temple. 
 Next, I will discuss “i.plot” (Tosa et al.  2008 ), an association system for words 
and images that inspire the user. We can use various search engines to access large 
amounts of data on the Internet. However, the access method is limited to a simple 
search that uses only given key words. “i.plot” seeks to create an inspiration space 
that can be intuitively imagined using ‘forms of thought’ from the given search 
words. I describe new access methods (for example, the context of an inspiration, 
visualization of the atmosphere in a dialogue, and the association space of kanji and 
English). As an access method, they give inspiration to users to seek new hidden 
relationships between things. “i.plot” is a trial to connect words and the contexts of 
images, which are related to creating abstract contexts and association images using 
computers. 
 Finally, I will explain “Hitch Haiku” (Tosa et al.  2009 ), which focuses on haiku 
generation with structures that evoke many images using minimal syllables. 
4.1 Picking Up Cultural Information

70
 One example of research on haiku and computers is the creation of a system that 
would suggest a relevant Kigo 1 (season word) to users for their haiku and provides 
a space for users to submit and appreciate haiku among their user group. However, 
this system focuses on the analysis of haiku rather than the creation of new Haiku. 
In “Hitch Haiku,” I focused on the creation of haiku. Basically, “Hitch Haiku” sup-
ports the creation of haiku by using the Saijiki (the dictionary of Kigo, a glossary of 
seasonal terms for Haiku composers). In the process of creating haiku phrases, 
“Hitch Haiku” generates many associations from the singular input, with the use of 
a dynamic search method called “Kanji (Chinese character) Inspiration,” to create 
interesting haiku that directly reﬂ ect the power of the given idea. I will introduce the 
design and composition of the haiku-supporting system with which users can enjoy 
creating haiku, inspired by the combinations of witty haiku phrases.  
4.2  Visualizing Communication 
 This work was a collaborative project with a group of AI and image-processing 
specialists headed by Masamichi Asukai, who was a researcher at Sony Kihara 
Research Center at that time. This work is designed for the visualization of human 
empathy. 
 Computers analyze and express the empathetic levels behind face-to-face com-
munication. The computer graphics-based mermaids work as user agents. They 
express both stress and interest using the users’ heart rate and a sympathy model 
calculated from their physical distance. For example, the agents may ﬁ ght together 
even if the users are posing quietly. 
4.2.1  System Conﬁ guration 
 The two computer graphics-based mermaids function as agents of two viewers. 
Each mermaid moves in sync with a viewer’s heart rate, as detected by the electrode 
attached to their ﬁ ngers. The computer characters express nonverbal communica-
tions (that is, the distance and interest between the viewers), their mutual interest is 
calculated using the viewers’ heart rates and the interactive model, designed with 
proxemics in mind and their mental distance is calculated based on the distance of 
their hands. For example, consider that the viewers are interested in each other, but 
are posing as if they are disinterested. In this case, if their hearts are beating quickly, 
the hidden relationship is revealed by the behaviors of the two mermaids. 
1  Kigo (season word) is a word or phrase associated with a particular season, used in Japanese 
poetry. Kigo was ﬁ rst used in the collaborative linked-verse forms such as Renga and Renku. As 
Haiku was a sophisticated form of Renga and Renku, Kigo also became commonly used in Haiku 
to indicate the season referred to. 
4 Computing Culture

71
 The computer analyzes the images from a camera sitting on the top of the system 
to capture the movements of red and yellow sticks attached to the viewers’ hands 
and use them for the interactive model. With a high degree of synchronization, the 
agents mimic the hand gestures of their subjects, but with a low degree of synchro-
nization, the agents tend to run away from each other. By touching the agents, the 
agents will directly follow the pallets, or, if their empathetic level is low, the agents 
will give advice to the viewers. The users’ heartbeats are picked up by electrodes 
and output as biofeedback.  
4.2.2  Synchronization Interaction Model 
 The data from the relaxation–strain calculated from the heart rate (the X-axis) and 
the interest calculated from the distance between the viewers’ hands (the Y-axis) are 
mapped on a 2D model. The movement of two mapped points on this plane pro-
duces the interaction model. If the two points entered the same area, the viewers are 
considered empathetic. We created this interaction model with Prof. Gaku Tokita, 
who is a physiological psychologist at Nihon University, Tokyo and aimed to 
express the following communications in this hidden dimension that do not appear 
in our superﬁ cial communications (Figs.  4.1 ,  4.2 , and  4.3 ):
 1.  When both participants are highly relaxed and interested during the experiment, 
they are considered empathetic. Animation is generated in which, for example, 
their mermaid agents hold hands or display other friendly actions (Fig.  4.4 ).
 2.   When both participants are in a situation where they feel highly stressed and 
disinterested, they are considered unfriendly. Animation is generated in which, 
for example, their mermaid agents quarrel with each other. 
 Fig. 4.1   An example of the movement of two mapped points 
 
4.2 Visualizing Communication

72
Interested
Not Interested
Stress
Relaxed
 Fig. 4.2   Another example 
of the movement of two 
mapped points 
Interested
Not Interested
Stress
Relaxed
 Fig. 4.3   Hardware 
structure of “Unconscious 
Flow” 
Screen
Projector
Speakers
Frames
CCD
Camera
Heart Rate from
Blood Flow Sensor
PC
Mac
Wooden bucket
5.0m
1.0m
 Fig. 4.4   Animation of two mermaids showing friendly actions 
 
 
 
4 Computing Culture

73
 3.  When both participants are in a situation where they are highly relaxed, but dis-
interested, the agents stay away from each other. Animation is generated in 
which, for example, their mermaid agents play separately (Fig.  4.5 ).
 4.   When both participants are in a situation where they are highly stressed and 
interested, they are considered to have conﬂ icting feelings (that is, there are some 
differences between their characteristics). Animation is generated in which, for 
example, their mermaid agents look interested, but also embarrassed. 
 Through the animation of the mermaids, we can discover new codes of commu-
nication that we cannot ﬁ nd in superﬁ cial face-to-face communications (Fig.  4.6 ).
 Fig. 4.5   Animation of two mermaids relaxed but not interested in each other 
 Fig. 4.6   Animation of two mermaids highly stressed but interested in each other 
 
 
4.2 Visualizing Communication

74
4.2.3  Software Conﬁ guration 
4.2.3.1  Hand-Position Detection by Color Information 
 The camera recognizes the color of yellow and red sticks that the viewers have, and 
based on this the recognition program detects the position of their hands. The dis-
tance between red and yellow sticks is detected by the stereo image input from two 
cameras. This distance is mapped into the interaction model and reﬂ ected in the 
reaction of the computer graphic-based mermaid agents (Fig.  4.7 ).
4.2.3.2  Heart Rate Sensor 
 The viewer’s heart rate is measured by placing a heart rate sensor (Fig.  4.8 ) on his/
her ﬁ nger. The measured heart rate is sent to a PC connected to the sensor and is 
mapped on the synchronicity model.
4.2.4  Biofeedback from Heart Sounds 
 The viewer’s heart rate was used for biofeedback and played as background music to 
relax the users. The heart rate analyzer analyzes the input data and sends it to Event 
Control as event data. The heart rate information is also sent to the sound processor as 
a MIDI command. The sound processor processes the data into sound as output. 
 Event Control sends commands to the Computer Graphics Generator if computer 
graphics need to be changed based on the current heart rate. The Computer Graphics 
Generator creates graphics based on these commands and produces the new images. 
 Fig. 4.7   Recognition of red and yellow sticks 
 
4 Computing Culture

75
 Image Recognition analyzes the image data fed from the cameras and relational 
information of the two hands and displayed computer graphics, and sends them to 
Event Control. Event Control again sends commands to the Computer Graphics 
Generator if the graphics need to be changed depending on the new data. The sound 
data is also continually sent to the sound processor as MIDI commands depending 
on the observed changes in heart rate (Fig.  4.9 ).
 Fig. 4.8   Heart rate sensor 
Projector
Generation of
Computer
Graphics
Image
Recognition
Event
Control
Heartbeat
Analysis
Blood Flow
Sensor
(MAX/MSP)
Sound 
Processing
Camera
Software Configuration
 Fig. 4.9   Software conﬁ guration of “Unconscious Flow” 
 
 
4.2 Visualizing Communication

76
4.2.5  The Staging of the Installation 
 I secured the installation of the system for exhibition in the United States, Europe, 
and Asia (Korea). I often think about installation in parallel with designing the sys-
tem. This time, I decided to project the computer graphics of mermaids onto a 
Japanese wooden bucket ﬁ lled with water, viewed from above. The users stand with 
red and yellow sticks on their hands, and interact with each other. The camera 
detects the colors of their sticks from above and measures the distance between 
them. By projecting various star images onto the water, I created a mixed reality 
effect that includes both VR and the real world. The detected heart rates of the inter-
acting users are output as biofeedback. Sound designers from Sony did a great job 
on the sound, which calms us in a way similar to prenatal training. 
 I set the system in a covered area with a space of two Tatami 2 mats, like a teahouse 
in Japan. The viewers did not actually drink tea, but I wanted the stage of the inter-
action to be an important and satisfying place. A bamboo frame and a thin, golden 
cloth walled the space. 
4.2.6  From the Unconsciousness to Zen and Sansui 
 This system was exhibited in several international media arts centers such as Ars 
Electronica in Linz, Austria, and in the Art Center Nabi in Korea. Did the new com-
munication code that visualizes empathetic information of communications leave 
any impact on the world through this exhibition? 
 I had devoted myself to Jung in my teenage years and have always been greatly 
interested in the existence of the unconscious mind, and set that as the target of my 
artistic expression. This work is my ﬁ rst step in visualizing an ‘unconscious mind.’ 
How do we reach a deeper side of the unconsciousness? As you know, Jung 
described the ‘anima’ or ‘animus’ as Jungian archetypes. What validates these 
archetypes are their various sources of images and allegories, which change depend-
ing on the analogies generated by human desire. These changes in images become 
symbols of the unconsciousness, and can create new cultures, with the assumption 
that the unconsciousness is strongly related to culture. Day by day, I became more 
certain of this idea, but I could not challenge it directly. The problem was huge and 
I could not determine what to tackle ﬁ rst. 
 A culture is vast, and encompasses both the consciousness and unconsciousness 
of humanity. A sense of similarity arises when people live together, which develops 
into a culture of sorts. I wanted to express the unconsciousness aspects of culture 
hidden within ethnicities. How should I realize this goal? I brooded over how to 
2  A Tatami is a type of mat used as a ﬂ ooring material in traditional Japanese-style rooms made of 
rice straw to form the core, with a covering of woven soft rush straw. After the Second World War, 
along with the rapid introduction of Western culture, the usage of Tatami became less and less. And 
nowadays a Tatami room is not common in Japanese houses. 
4 Computing Culture

77
express unconsciousness in cultures. At that time, I was interested in Japanese 
 culture, especially the cultural structures of tearooms and Noh theatre, but I had no 
idea how to grapple with these structures. 
4.3  Sansui Zen Using Computers “Art of ZEN” 
 In April 2002, I visited a great exhibition in Kyoto. It was a retrospective exhibition 
of Sesshū’s work (Chiba  1989 ; Tanaka  1972 ). I visited this exhibition with technol-
ogy in mind. Sesshū’s work looked like a huge VR world and I had a strong desire 
to use technology to create this kind of perspective. 
 Then, something unexpected occurred suddenly in my life. After viewing the 
retrospective exhibition of Sesshū’s work, my brain became ﬁ lled with Sansui paint-
ings while awake or asleep. I was completely fascinated by the VR expressed in 
Sansui space, and I wanted to achieve that by myself as quickly as I could. I loved 
the strong feeling of Sesshū’s Sansui paintings. Even more so, I was fascinated by 
the Sansui paintings’ worldview. 
 I am drawn in by Sansui paintings as I view them. In the past, the Chinese put 
Sansui paintings on walls, and contemplated what it would be like to go there. The 
paintings represented the places in which they wanted to pass away. 
 Two or three months later, I received a letter that notiﬁ ed me of my acceptance 
as an artist fellow at the MIT CAVS, which I had applied to in the previous year. 
However, there was a rule that I could not go abroad and conduct research funded 
by national Japanese research grants; because of this, I almost had to give up my 
research. However, owing to the great generosity of Prof. Fumio Harashima, a 
research manager at the Japan Science Technology Agency (JST) and President of 
Tokyo Metropolitan University, and the advice from Prof. Toshio Fukuda of Nagoya 
University, I was permitted to research stories based on Sansui paintings at MIT in 
the United States. I went to the United States in April 2002. Even though this was a 
great opportunity to spread my research internationally, as I expected, things did not 
go smoothly at ﬁ rst. 
4.3.1  Cultural Differences and Taboos 
 A culture is rooted in the ‘climate’ generated by the combination of the unique 
physical national conditions and the sprits and thoughts of the people there (Wong 
 2011 ; Tetsuro  1971 ). I could not become accustomed to the Japanese dishes served 
in Boston, as they were affected by the climate differences. Food is the basic source 
of human energy and we Japanese cannot work well without eating rice daily and 
having the ﬂ avor of soy sauce in our food. 
 At MIT, there are many Asians and Jewish people. It seemed to me that as many 
as 60 % of MIT students were Asians, and many famous professors were Jewish 
4.3 Sansui Zen Using Computers “Art of ZEN”

78
such as Mavin Minsky or Noam Chomsky. I often felt that Japanese are like 
 herbivorous animals and Westerners are like carnivores. I felt that there was a huge 
difference in energy between Japanese people and Westerners. I worked as dili-
gently as an ant because, as a foreigner, I did not need to follow Westerners’ style of 
work. At the same time I wanted to explain to my Western colleagues Japanese 
culture through the works of great Japanese artists whose works are not well known 
in US, 
 I visited Andrew Gordon, the chief of the Reischauer Institute of Japanese 
Studies, to ask him to write pamphlets about my exhibition. That was the day that 
the Dalai Lama was to visit Boston, and he had a speech planned at Harvard. The 
popularity of the Dalai Lama there was amazing; he was like a super star. Even my 
taxi driver knew about his speeches at MIT and Harvard, and how the $100 tickets 
had sold out in one night. People who missed the chance to attend his speech 
watched it on a video projector. Harvard even dared to offer a church as the venue 
for the speech of the Dalai Lama. Mr. Gordon mischievously asked, “What would it 
be like if he was a Japanese Buddhist monk?” 
 Because Tenshin Okakura 3 was an attendant of the Boston Art Museum, and he 
was in good relations with the Gardner Museum, there are many Japanese art col-
lections and gardens in Boston. I was moved by many types of Netsuke carving 4 that 
I had not seen in Japan. These inspired the question: Why is it that the Japanese 
could not evaluate these Japanese great artworks in the past very well, but started to 
value them when foreign arbiters gave them value? This is a bad habit carried over 
from the ancient eras when Japan imported various cultures from China. 
 I collaborated on research with Prof. Ian Condry, who is a researcher of Japanese 
culture. We started a translation of the story I wrote for “Art of ZEN,” and discussed 
Japanese culture. Prof. Condry is currently studying Japanese hip-hop culture. 
 Japanese Otaku 5 culture and anime were well known there. The Berklee College 
of Music holds concerts every day. Jazz pianist Toshiko Akiyoshi often plays there. 
But, what if we want to see Japanese traditional culture? There is a Japanese garden 
at the Isabella Stewart Gardner Museum, but the rustic garden seemed to appeal 
more to me than to the Americans to whom it had been designed to appeal.  
3  Tenshin Okakura (26 December 1863–2 September 1913) was a Japanese scholar who contrib-
uted to the development of arts in Japan. Outside of Japan, he is chieﬂ y remembered as the author 
of “The Book of Tea.” Although his original name was Kakuzo Okakura, in Japan he is well known 
by his poet name: Tenshin Okakura. He was invited to the Museum of Fine Arts, Boston in 1904 
and became the ﬁ rst head of the Asian art division in 1910. He is also known as one of the founders 
of the Tokyo University of the Arts. 
4  Netsuke are miniature sculptures that were used as accessory pouches in Japan. Netsuke were 
invented in seventeenth-century (Edo era in Japan) and were used commonly among men at that 
time. Traditional Japanese clothes called Kimonos had no pockets. Therefore it was necessary for 
men to store their personal belongings, such as tobacco, money, or medicines in a Netsuke. 
5  Otaku is a Japanese term used to refer to people, usually the younger generation, with strong 
interests, particularly, in Japanese animation, Manga (comic) or video games. Otaku has had some 
negative meaning such as obsessive, monomaniac, etc. At the same time it should be recognized 
that new Japanese and pop cultures are being created by them. 
4 Computing Culture

79
4.3.2  Japanese Culture Used in Cultural Computing 
 Because cultural computing has a broad meaning, we needed to create a system 
with a focus on local ethnicity. Here, I will describe how I computed the structure 
of Japanese culture and Eastern thoughts, the structure of Buddhist psychology, and 
the mechanisms of Japanese traditional culture. I focused on the structures of Sansui 
paintings and Yamato-e, 6 and allegories or symbols of kimono. I also applied 
 communication methods that have been nurtured in Japanese culture for a long time. 
I researched and developed the interactive system called “Art of ZEN,” which makes 
us feel newly enveloped in Mother Earth. 
 I organized symbols and allegories in my cultural computing system, such as 
important key words from Buddhism, Eastern thought, and Japanese culture. I used 
these key words because they have plenty of good implications, and the impacts of 
their terms, ﬁ gures, and colors in our lives are extraordinary. 
 Sansui was originally developed by Zen 7 Buddhism, so we looked especially 
carefully at Zen culture. Zen Buddhism is a sect of Mahayana Buddhism that 
Bodhidharma had brought into China. The sitting meditation called Zazen 8 from the 
Soto Zen 9 sect and the practice of telling Kōans (Zen riddles) from the Rinzai Zen 10 
sect are examples of Japanese Zen. 
 I focused on a ﬂ uctuation caused by the conﬂ ict between peoples’ consciousness 
and unconsciousness. This kind of ﬂ uctuation is seen during the process of a Zen 
Buddhist answering Kōans while being led by his/her master. I aimed to create a 
computer that would give us the virtual experience of sitting in Zazen. I displayed 
these Oriental and Japanese sensitivities on a computer screen and tried to create an 
interface in which users can become absorbed in the Japanese world of Sansui ink 
paintings. 
6  Yamato-e, the translation of which is ‘Japanese painting,’ is classical Japanese painting estab-
lished in the late Heian period (ninth to twelfth century). In the Heian era Chinese style paintings 
were imported from China (at that time Tang Dynasty) and were a strong inﬂ uence to the develop-
ment of Yamato-e. Since the Muromachi period (ﬁ fteenth century), the term Yamato-e has been 
used to distinguish Japanese paintings from contemporary Chinese style paintings (Kara-e). 
7  Zen is a school of Buddhism that originated in China during the sixth century. From China, Zen 
spread to Vietnam, to Korea and to Japan. Zen emphasizes the attainment of enlightenment and the 
personal expression of direct insight into the Buddhist teachings. As such, it de-emphasizes mere 
knowledge of Buddhism principles and emphasizes the importance of reaching enlightenment 
through hard mental and physical exercises. 
8  In Zen Buddhism, Zazen, which means seated mediation, is a way of meditation. A Zazen practi-
tioner sits down, calms the body and the mind trying to dispel every unnecessary thought form his/
her mind. 
9   In Japan there are three Zen parties: Sōtō, Rinzai and Ōbaku. Sōtō Zen is the largest of these three 
parties and emphasizes the importance of sitting and meditation exercise (Zazen). 
10  The Rinzai school is one of three schools of Zen in Japanese Buddhism. Rinzai Zen emphasises 
the importance of Kensho (“seeing one’s true nature”) as the gateway to enlightenment. As for the 
exercise to attaining Kensho, instead of practising meditation, Rinzai Zen emphasizes the training 
to embody the free functioning of wisdom through the activities of daily life. 
4.3 Sansui Zen Using Computers “Art of ZEN”
www.allitebooks.com

80
4.3.3  Meeting the “Art of ZEN” 
 A rough outline of a user’s experience with “Art of ZEN” is described as follows. 
First, the user builds a 3D Sansui ink painting on the ‘scroll’ on display, using iconic 
Sansui elements that are attached to the top of the display. 
 The images used in this interface express the conceptions of nature and philoso-
phy that characterize the history of Japanese Zen Buddhism, and provide the user 
with a dramatic experience very different from the images of modern life. Thus, in 
the introduction, the system brings about a kind of awakening within the users and 
encourages their unconscious imagination. 
 Next, because the system classiﬁ es the state of the user’s consciousness based on 
the user’s design of the Sansui landscape, it generates a story appropriate for the 
users, drawing them through the display and into their alternate worlds. 
 I included mechanisms in the story that were meant to stimulate the user’s con-
sciousness by various haiku and Kōans generated by the system. The story built 
from these elements is not a complete linear story like those found in movies or 
novels, but is rather a nonlinear collection of short story fragments. A user 
 experiencing these inconclusive story fragments will feel uncertainty, and have the 
expectation and desire to connect these fragments to build a complete story. Because 
of this desire, while the users may feel that they are being asked questions without 
a ‘correct’ answer, they cannot help but attempt to answer these questions.  
4.3.4  ‘Ma’ Interaction 
 Using their hidden cultural triggers, users connect these stories and build their own 
unique narratives. Next, while the user uses a virtual brush, a rake for the rock gar-
den, and other tools in response to questions posed by the system via images and a 
voice, the door to the realization of consciousness begins to open further. As the 
users’ desire to connect the story fragments mixes with the system’s user interface, 
the distance between their everyday and hidden selves begins to shrink. 
 ‘Ma’ interaction plays an important role in the process of fusing those two selves. 
Ma 11 is a very Japanese concept that emphasizes ephemeral events such as the here- 
and- now within every experience. Having traveled through several stages and 
scenes, at the end of their trip, the users converse with an ox, which is an interaction 
used in Zen as a metaphor for expressing one’s true self. Through this dialogue, the 
11  Ma is a Japanese word which can be roughly translated as “gap”, “space” or “pause.” Ma means 
both special gap and also time interval depending on the situation. Japanese culture emphasizes the 
importance of a special gap and time interval. For example, the time interval between utterances of 
two people talking face-to-face is considered an important factor for communication. Also the 
special gap between these two people is considered, especially in more serious situations such as 
a theatrical play or a match between two Samurai. The time interval and special gap have been 
considered essential in Japanese culture. 
4 Computing Culture

81
user can experience a process through which the everyday self and the subconscious 
self, fuse together and bring about a uniﬁ ed self-awareness of consciousness. 
 Because the environment surrounding the system plays a very important role in 
the user experience, I decided to prepare an Eastern atmosphere for the “Art of 
ZEN” installation (Fig.  4.10 ).
4.3.5  Drawing Up a Scenario of Sansui Experience 
in the Clouds 
 I did not decide on the complete scenario from the beginning and so each story was 
created separately. As a result, the scenario was separated into six parts: the creation 
of a 3D Sansui painting; travel into the world of the Sansui painting; interactions 
based on Zen dialogues; interaction with the chaos engine; kimono interactions; and 
an interaction with the Ten Oxherding Pictures story. 12 
 Mr. Seigow Matsuoka designed the Zen dialogue interactions and wrote the sen-
tences voiced by the system when the user approaches the Sansui objects. I used to 
travel frequently between the United States and Japan, and on one airplane journey, 
I wrote the whole scenario for the user’s experience while using the individual inter-
action design and user-prepared sentences. Because I could concentrate on reading 
or writing on the airplane, the 12-h ﬂ ight gave me plenty of time to do what I 
12   The Ten Ox Herding Pictures (or Ten Bull Pictures) is, in the tradition of Zen Buddhism, a series of 
short phrases and accompanying pictures that are intended to illustrate ten stages of a Buddhism prac-
titioner’s progression towards enlightenment, as well as his or her subsequent perfection of wisdom. 
 Fig. 4.10   “Art of Zen” installation 
 
4.3 Sansui Zen Using Computers “Art of ZEN”

82
needed. I asked MIT students, colleague researchers, and Prof. Condry whether 
they could understand my scenario and changed my scenario when they could not 
make sense of it. 
 The entire interaction ﬂ ow is as follows, which has a total time of about 30 min. 
The complete story progression is shown in Fig.  4.11 .
 1.  Creation of a Sansui painting. 
 2.  Generation of haiku related to the Sansui icons. 
 3.  When the user approaches an object in the Sansui painting, related Zen dialogue 
appears. 
 4.  Depending on the result of the Zen dialogue interaction, a specially designed 
kimono appears with each of the following design concepts that vary corre-
sponding to the users’ personalities: Kisoi, a comparative design; Mitate, choice 
and metaphor; Awase, design in pairs; and Soroe, design based on sets. 
 5.  At the end, a Ten Oxherding Pictures story (a metaphor for the 10 steps leading 
to enlightenment) corresponding to the user’s interaction is displayed. 
 6.  The users create a Sansui ink painting using the “Art of ZEN” (Fig.  4.10 ). 
Composition of a Sansui picture on the basis
of interactive Sansui icons 
User
System
Walking through the Sansui picture using
the Navigation Tool
Haiku and Zen-Dialogues emerging at
distinct places everywhere during the
Sansui landscape stroll
User experiences fundamental connections
on the basis of decisions
Users underlying character is detected 
and contextualized according to the Buddhist
system of Goun 
Interaction generates Haiku and 
Zen-Dialogues
Interaction forms Goun-Personality and 
targets Chaos
Ten Ox Story (Zen Method of 
determining personality according to
Ox drawings)
Determination of user`s Mental Level 
according to the character revealt through
interactions 
Creation of an Interactive Story
 Fig. 4.11   Story progression ﬂ ow 
 
4 Computing Culture

83
4.3.6  The Contexts Generated by the Sansui Symbols 
 At ﬁ rst, I intended to make the user paint a Sansui painting using real-time 3D cal-
ligraphic effects like blur, feathering, and cracking. However, in the original system, 
some users gave up drawing a picture and explored the 3D objects because the Sansui 
painting process was difﬁ cult. Therefore, I decided to produce icons consisting of the 
12 elements of Sansui paintings: rocks, mountains, the moon, travelers, bridges, 
birds, trees, houses, ﬂ owers, clouds, water, and wise men. Each of the Sansui icons 
is expressed by a hieroglyph or a kanji script. Users can drag and drop the icons 
where they like, and compose their own 3D Sansui painting. Using this method, 
everyone can make their own Sansui pictures, regardless of their drawing skills. 
 Figure  4.12 shows an example of a Sansui painting composed by a user. The 
composed stones, mountains, the moon, wise man, and water represent associated 
contexts. The computer determines the value of ﬁ ve personality categories with the 
information from the selected icons and where the user placed them. By arranging 
the kanji scripts, users create the story they experience.
4.4  Sansui Perspective Method—Sanen 
 Please look at the painting by Sesshū carefully (Fig.  4.13 ). Unlike Western picture’s 
perspective methods, Eastern Sansui paintings have an Oriental ‘Sanen’ perspective 
scheme, which has three different types of perspectives: Koen, Heien, and Shinen. 
Koen is the view from far away and from below, Heien is the straight view and 
Shinen is the near view from above. A Sansui picture includes these three perspec-
tives within it.
 Fig. 4.12   An example of a Sansui painting 
 
4.4 Sansui Perspective Method—Sanen

84
 These panorama-like pictures include the prospects relative to one’s eyesight. I 
tried to include this Sanen perspective in the system. Figure  4.14 is a Sanen perspec-
tive from the computer’s point of view. Depending on the position of a placed icon, 
the computer calls a relevant graphic to display, which corresponds with each of the 
Sanen perspectives.
 Fig. 4.13   A Sansui painting that consists of three types of views 
 Fig. 4.14   Relation between 2D position and three types of views 
 
 
4 Computing Culture

85
4.4.1  Playing with Sansui Paintings (Interactions 
with Allegories and Symbols) 
 When the users ﬁ nish their painting, they operate a 3D compass whose interface 
imitates the pond of a ‘rock garden,’ as shown in Fig.  4.18 where a young Zen 
Buddhist and a MIT student are interacting with the system. The user enters into the 
created Sansui painting world, and begins a Zen training journey. When the user 
approaches the river in the Sansui space, the sound of the river will play. The user 
can also experience Zenki (phenomenon of the results of Zen training), such as 
jumping ﬁ sh. The associated allegories and symbols trigger the appearance of haiku 
or Zen dialogues related to the landscape. 
 Symbols and allegories advance our recognition, thought, expression, and action 
in large steps. For example, a mandala is a communication tool invented by ancient 
people which is full of symbols and allegories. Also the ancient ethnic world used 
symbols like tigers and condors that allegorically triggered people’s memories 
based on their long history. The combination of the symbols enabled ancient peo-
ples to communicate with each other. 
 If you approach a ‘bridge,’ for example, a haiku is read out, that translates to, “A 
grass matting makes me feel cool, smells like tea from the bridge.” The haiku 
 selection is the work of the staff of the Editorial Engineering Laboratory in Tokyo. 
When you approach a river, a Zen dialogue related to water, “The Catﬁ sh and the 
Gourd,” appears (Fig.  4.15 ).
Haiku Output
Icon Priority
The day passes slowly; 
A pheasant comes down onto the bridge.
The rift in the clouds, 
whence snow falls on the distant mountains.
Advancing through pebbles, 
there flows a rivulet running from a spring.
An old quiet pond; A frog jumps into the pond; 
Splash! Silence again.
The autumn moon; 
I wandered around the pond all night long.
Bird
Mountain
Cloud
Cloud
Rock
Water
Water
Bridge
Bridge
House
House
House
Moon
Moon
Traveler
 Fig. 4.15   Relationships between Sansui symbols expressed by hieroglyphic icons and Haiku 
 
4.4 Sansui Perspective Method—Sanen

86
4.4.2  Eastern Human Recognition Model 
 In “Art of ZEN,” I wanted to use an Asian unique psychological model instead of a 
Western one. I adopted the Goun model, 13 which is a model of interaction between 
Zen masters and disciples. Goun is a model to recognize human characters, which 
is also a style of Buddhism that has existed for over 2000 years. I designed the sys-
tem to use Goun and Tao’s four seasons (spring, summer, autumn, winter) and ﬁ ve 
directions (east, south, center, west, north) in the interactive models. 
 When I was at MIT, I asked American information science researchers if they 
had ever researched a recognition model based on the spirit of Buddhism. 
Unfortunately, they had never used a Buddhist recognition model because they only 
ever needed to use normal Western psychology models. However, they were greatly 
interested in the proposed Buddhist recognition model. These researchers said they 
wanted to use one, but they could not understand it because interactions based on 
Asian philosophies like Buddhism have not been studied in Western science. Based 
on this experience, I can imagine that perhaps Asian cultures will be better able to 
develop human recognition models to use in IT technologies. 
4.4.2.1  Expression of a Sansui World Based on the Taoist World Model 
 The basic concept of Sansui is rooted in Tao (Wong  2011 ; Simpkins and Simpkins 
 1999 ), which is a Chinese idea of cosmological principles that teaches us the life of 
Xian (an enlightened person). When we explore the Sansui world, the climate 
changes based on the four seasons and the ﬁ ve directions. For example, if we move 
to the north, the climate changes to a snowy winter; if we move to the south, the 
climate changes to a summer evening; if we move to the east, the climate changes 
to a misty spring day; and if we move to the west, the climate changes to a rainy 
autumn day. Connecting the elements of Sansui paintings and Sanen, haiku, and 
Zen dialogues as well as the direction of movement will enable us to create many 
contexts and generate various affordances. 
13  Goun is a philosophical principle in Buddhism to explain how humans are structured, and is 
based on the principle that humans consist of the ﬁ ve elements below: 
 1.  “form” or “matter”: external and internal matter. Usually this means human physical body and 
physical sense organs. 
 2.  “sensation” or “feeling”: sensing an object as either pleasant or unpleasant or neutral. 
  3.  “perception”, “conception”, “apperception”, “cognition”, or “discrimination”: registers 
whether an object is recognized or not (for instance, the sound of a bell or the shape of a tree). 
 4.  “mental formations”, “impulses”, “volition”, or “compositional factors”: all types of mental 
habits, thoughts, ideas, opinions, prejudices, compulsions, and decisions triggered by an object. 
 5.  “consciousness” or “discernment”: a series of rapidly changing interconnected discrete acts of 
cognizance. The base that supports all experience. 
4 Computing Culture

87
4.4.2.2  Classiﬁ cation of User Personalities Using the Goun Model 
 Buddhist thought holds that ﬁ ve basic physical and mental elements, called Goun, 
make up the world. In this interactive system, I applied these elements in the clas-
siﬁ cation of one’s personality. The ﬁ ve personality categories are as follows: Shiki 
(㢢), a personality that focuses on nature and materials that actually exist; Ju (ਇ), a 
personality that focuses on intuitive impressions; Sou (ᜣ), a personality that focuses 
on perceived visual images; Gyou (㹼), a process of mind that activates behavior; 
and Shiki (䆈), a deep spiritual function that reaches beyond the above processes. 
 When the users create a Sansui space they like, the computer uniﬁ es the Sanen 
categories (Fig.  4.16 ) and classiﬁ es the created Sansui painting. Then user 
 personalities are determined as one of the Goun, and the journey begins by assum-
ing this Goun as the users’ personality.
4.4.3  Zen Dialogue Interactions 
 When users approach a certain object within the Sansui painting, a Zen event occurs. 
Every event is constructed so that one can have an interactive virtual experience 
with a Zen Kōan. For example, the Kōan “ Dharma Anjin ” (Fig.  4.17 ) is a dialogue 
in which, when a pupil complained, “Even after training, my inner spirit is still 
troubled,” Dharma Anjin replied, “Then show me your troubled spirit.” In this inter-
action, users are asked to draw their spirit in the screen at the rock garden interface 
(Fig.  4.18 ).
 When users meet a ﬂ ower, a Zenki 14 occurs, and the ﬂ owers fall. A very young 
Buddhist monk appears and a Zen dialogue, “The Lotus Smiles,” starts. This Kōan 
explores telepathy. In his later life, the Buddha bent a lotus in the presence of his 
disciples and threw it to them with a smile. A disciple, Mahākāśyapa, understood 
the meaning and caught the ﬂ ower. This disciple started Zen Buddhism. 
14  Zenki is the moment for a Zen practitioner to be able to reach a higher level toward enlighten-
ment. In Zen Buddhism, enlightenment has been considered the ultimate target for a person to 
reach. To achieve this one has to go through a difﬁ cult exercise of Zazen (Zen meditation) and also 
questions and answers with a Zen teacher. And at some moment it is said that a Zen practitioner 
can suddenly reach a higher state and ﬁ nally he/she can reach the state of enlightenment. 
Icon
Koen
Rock
Mountain
Moon
Jyu
Jyu
Jyu
Siki
Siki
Siki
Shiki
Sou
Gyou
Heien
Shinen
 Fig. 4.16   Examples of 
relationships between 
symbols, Sanen perspective 
and Goun 
 
4.4 Sansui Perspective Method—Sanen

88
 Fig. 4.17   Zen Koan interaction called “Dharma Anjin” 
 Fig. 4.18   Zen Buddhist 
interacting with “Art of 
Zen”  
 The Buddhist monk tells users, “There is a face and a back in anything. Feel it. 
Touch the leaves.” When users touch one of the leaves on the screen, the monk says, 
“Yes, that is a face mask from Noh Theatre. Find the same mask as it.” Users have 
to match each mask displayed on the stone garden interface (Fig.  4.19 ).
 
 
4 Computing Culture

89
 When users approach a standing tree in the Sansui painting, a Zen dialogue “The 
Sound of One Hand Clapping,” related to the autumn leaves, appears. Autumn 
leaves fall on the screen, and the Zen master advises, “Clap your hand.” If users clap 
their hands, the falling leaves stop, and the master says, “This is the ﬁ gure of your 
feelings” (Fig.  4.20 ).
 When users approach the water, the sound of a river is played, and they ﬁ nd a 
catﬁ sh in the river. This is the Zen dialogue named “The Catﬁ sh and the Gourd.” 
The Zen master asks users to “Put the slimy catﬁ sh into the narrow-mouth gourd.” 
 Fig. 4.19   Zen Koan interaction called “The Lotus Smiles” 
 Fig. 4.20   Zen Koan interaction called “One Hand Clapping” 
 
 
4.4 Sansui Perspective Method—Sanen

90
The catﬁ sh looks at the users from the pond in the rock garden interface. Users can 
try as hard as they like, but as users pursue, the catﬁ sh ﬂ ees faster and faster. The 
Zen master says enigmatically, “The chaser and the ﬂ eer; I want both of them to be 
free from each other” (Fig.  4.21 ).
 In each interaction, a duplicative, synchronized chaos engine starts up. This 
chaos engine generates three types of chaos, each of which represents the behaviors 
of the User, the Zen Master, and the Target. Depending on the ways users interact 
with Zen, the User and the Zen Master are or are not considered to be synchronized. 
The contents of the interaction change as the User approaches the Target. 
4.4.4  Controlling Ma with the Chaos Engine 
 “Scientists think that human recognition is chaotic. We try to reﬂ ect the core process 
of the user’s recognition in an interaction, as well as to make it more varied and 
dynamic,” said Dr. Peter Davies, who is a chaotic complex system researcher at the 
Adaptive Communications Research Lab at ATR and who designed the chaos 
engine, told me when we started our collaboration. 
 Scientists have no way to describe ‘thoughts,’ ‘feelings,’ or ‘concepts.’ However, 
if we apply the laws of modern physics to the activity of neuron cells, we notice that 
the activity of our brain has the same characteristics as everyday chaotic physics 
(Gleick  2008 ), such as the movement of planets, the behavior of a wind or water 
vortex, or the explosive growth of tissue cells. 
 Taking note of these similarities, we can imagine that such a chaotic mechanism 
is an essential part of the spontaneous reactions of our bodies and brains. Assuming 
 Fig. 4.21   Zen Koan interaction called “The Catﬁ sh and the Gourd” 
 
4 Computing Culture

91
this, all the available processes are explained by complex combinations of each 
dynamic process—each reﬂ ects the interaction of our bodies with the outer world—
which can be thought of as an example of imports and exports. I designed a chaos 
engine based on these ideas and through discussion with Dr. Davies. 
 The Chaos Engine is composed of many dynamic elements that imitate multiple 
basic elements that our ‘self’ has. The ‘self’ is the combination of two conﬂ icting 
elements that sometimes synchronize and sometimes do not. These processes of 
synchronization and contradiction are called ‘chaotic synchronization.’ These can 
be likened to the synchronization of pure chords of music, but are more complex 
and subtle in their behavior. Sometimes they react passively to external pressure 
and suction. Other times, they lock onto each other and act as one. Sometimes they 
act instantly and independently based on their own mechanisms without any exter-
nal controls. By feeding the results back to themselves at the same time, they 
sometimes enter an unregulated mode in which controlling and controlled ele-
ments are not distinguishable. When the system is stable, the Chaos Engine acts 
like a control unit. However, the system has the possibility of entering the other 
modes I referred to above, so this chaos engine mechanism can be more dynamic, 
spontaneous, and creative. 
 Is the behavior of the chaos engine ‘creativity,’ ‘free will,’ ‘oppressiveness,’ ‘con-
fusion,’ or ‘loss of control’? I tried very hard to control the chaos. The chaos engine 
worked well conceptually, but I did not consider it to be effective, so I ﬁ ne- tuned 
parameters dozens of times and modiﬁ ed the engine. 
 I think of the Zen dialogue as being controlled by a combination of both coopera-
tive and oppositional interactions between three different states: the current state of 
the user (User), the goal the user should reach (Target), and the Zen master guiding 
the user (Zen Master). 
 To imitate this process, I used a model that relates these three elements, User, 
Target, and Zen Master (they are expressed as points within Goun space), and trig-
ger changes in the reactions of the system as the user interacts with it. Appropriate 
‘ﬂ uctuation’ is needed to make users experience as many of the various interactions 
as possible when they interact with the system. The system uses a method for a dual 
synchronization of chaos to realize this ﬂ uctuation. The method for this dual syn-
chronization of chaos is a model handling the synchronization of two or more chaos 
states. In this case, we employ a model containing three chaos states, corresponding 
to the User, Target, and Zen Master. Each chaos state corresponds to a point in Goun 
space. Using the method for dual synchronization of chaos, if one applies an initial 
value and appropriate input values, the three chaos states relate to one another and 
move through Goun space to generate output corresponding to the executed 
interactions. 
 As the chaos input, the system uses data obtained from the user’s interactions. 
When the user interacts actively, the Zen Master chaos helps the User chaos and 
leads it to the next Target. If the interaction is not as active, the Zen Master chaos 
corresponds with the User chaos, and returns it to the previous Target. 
 For example, in the Kōan “Dharma Anjin,” the position of the Target chaos 
changes depending on the curvature and density of the drawing that the user 
4.4 Sansui Perspective Method—Sanen

92
sketches. The higher the density and curvature of the drawn lines, the better the 
Goun state achieved. This status is best expressed in the expression of Zen as the 
completion of an Ensō (circle) in a single stroke. Additionally, in the Kōan “The 
Lotus Smiles,” the Goun state increases with increasing accuracy in matching 
images of Noh theatre masks and the Zen Master leads the User to the next Target 
step. 
 In the Kōan “The Sound of One Hand Clapping,” the Goun state increases with 
the stability of the speed of the clapping sound, which reﬂ ects the stability of one’s 
mind. However, if the clapping speed is not stable, the user is scolded, “What are 
you doing!” Figure  4.22 shows the rules used for the chaos model and how the sys-
tem is affected (that is, the chaos states are changed) by the output data.
4.4.5  Computing the Yuzen Kimono Patterns of Kisoi, Awase, 
and Soroe 
 After the journey through the Sansui space, the user returns home. The Zen Master 
says to the user, “Here is a kimono. This kimono represents your mind.” The user 
looks for a kimono pattern using the rock garden interface, and a kimono pattern 
from Miyazaki Yuzen 15 is selected from different designs such as Kisoi, Soroe, or 
Awase, depending on the user’s interactions. 
 Because the rules that exist behind these design principles of Kisoi, Soroe, and 
Awase are complicated, I could not compute this part effectively. I would like to try 
to compute it more effectively in the next version of “Art of ZEN” by studying the 
mechanisms and structure of Kisoi, Soroe, and Awase. 
4.4.6  Interactive Ten Oxherding Pictures Story 
 I set the Ten Oxherding Pictures story 16 as the ending of “Art of ZEN” following the 
Yuzen kimono interaction. The Ten Oxherding Pictures story is a Zen method that 
leads us to enlightenment using the following ten pictures of an ox. The ox is a 
symbol of our mind. I designed this story as an interactive story.
 Jingyu (ሻ⢋) – In search of the ox 
 An ox is an animal that appears in Shan Hai Jing, which does not have a ﬁ xed ﬁ gure. 
The user is told that it will die if he/she does not draw eyes, nose, and a mouth. 
The user has to interact with this ox.  
15  Mr. Miyazaki Yuzensai (1654–13 June 1736) is known as the founder of Yuzen dyeing. At ﬁ rst 
he focused on painting on Japanese fans, then as the fans painted by him became famous, he started 
designing Kimonos. It is believed that he invented a dyeing method to apply his design to Kimonos 
and nowadays usually Yuzen means a Kimono using a design similar to his. 
16  See footnote 12. 
4 Computing Culture

93
 Kenseki (㾻䐑) – Discovery of the footprints 
 The chaos engine asks the user to draw the eyes, nose, and mouth of the ox. The user 
draws them on the touch screen. 
 Kengyu (㾻⢋) – Perceiving the ox  
 When the user draws the eyes, nose, and mouth, the ﬁ gure of the ox becomes clearer 
gradually. 
Interaction
Haiku Output
Apply goun assigned to the Haiku
The goun changes
Goun Input to Target Chaos
Output from
User Agent Chaos
Dialogue:
“The Catfish 
and the Gourd”
Dialogue:
“The Lotus 
Smiles”
Change goun depending on part of catfish touched
Touch the head → rise (toward shiki+)
Touch the tail → fall (toward shiki−)
Catfish’s movement 
changes
Goun target changes based on clicks
Sample every time user selects 2 leaves
If the masks are the same, goun target rises
If the masks are different, goun target falls
Buddha’s movement 
changes
Output audio changes
Dialogue:
“Dharma Anjin”
Dialogue:
“The Sound of
One Hand 
Clapping”
Goun value changes based on drawn lines
Sample data every three seconds
X Axis: Curvature (0.0 ~ 1.0)
Y Axis: Density (0.0 ~ 1.0)
Output audio changes
Change goun value based on clap timing
and movement of fallen leaves
A: Sample deviation based on timing of first two claps
    Small deviation → rise (toward shiki+)
    Large deviation → fall (toward shiki−)
B: Goun value rises as the movement of fallen
    leaves increases
Speed of falling leaves 
animation changes
Output audio changes
Refer to the goun result of previous four interactions
and select a Japanese cultural form for each.
Mitate: shiki; Kisoi: sou; Soroe: gyou; Awase: jyu, 
siki
Kimono design is 
displayed based on 
Japanese cultural 
forms awase,
kisoi, soroe and mitate.
None
Change target based on the distance between 
first two points drawn (eyes)
   Far apart → rise (toward shiki+)
   Close together → fall (toward shiki−)
Bull animation changes
Bull sound changes
Yuzen kimono 
patterns
Ten Bulls Story
Finding the Bull
Ten Bulls Story
Catching the 
Bull
Change target based on how user pulls rope
Pull moderately → goun value rises
Pull strongly → goun value falls
 Fig. 4.22   Relationship between chaos engine input and output 
 
4.4 Sansui Perspective Method—Sanen

94
 Tokugyu (ᗇ⢋) – Catching the ox  
 The user tries to catch the ox, but only the footprints are visible. The ox says, “Catch 
me,” even though it cannot be seen. The user must consider how to pursue it. The 
ox comes to life when the Ensō (a complete circle) is drawn. If the user fails to 
draw the Ensō, the ox dies, and the story ends.  
 Hogyu (⢗⢋) – Taming the ox 
 If the user succeeds at catching the ox, the ﬁ gure of the ox becomes ﬁ xed and then 
the user has to tame the ox using a rope.  
 Kiyukika (倾⢋ᑠᇦ) – Riding the ox home  
 This is an interaction in which the user plays with the ox. The user caresses the ox 
with a feather and the story moves to the next scene if the ox sleeps. However, if 
the ox wakes up, the story will end. 
 Bogyuzonjin (ᘈ⢋ᆈӪ) – Returning home, forgetting the ox  
  When the user returns home, the ox has disappeared and he/she sees a Chagama (tea 
kettle) steaming. 
 Jingyugubou (Ӫ⢋٦ᘈ) – Both ox and self transcended  
 A scroll appears at home, and the sentence ‘㢢ণᱟオ’ (Every form in reality is 
empty) appears. 
 Henponkangen (䘄ᵜ䚴Ⓚ) – Ordinal scenery looks great 
 When the user gets out of the room, there is a great 3D Sansui space that has not 
been seen before. 
 Nittensuishu (入鄽垂手) – Return to society 
 As the ending scene, the screen projects the scenes of “Art of ZEN” and the user’s 
Goun states are shown through ﬂ ashbacks, and ﬁ nally the scroll is closed and the 
scene ends. 
 Figure  4.22 shows the relationship between user interactions and Goun space. 
4.5  Opening, Traveling, and Living in Sansui Zen 
 The sound for “Art of ZEN” is an important element that connects one scene to 
another. I asked Toshinori Kondo, a globally famous jazz trumpeter, to create the 
music for “Art of ZEN.” Kondo is a trumpeter who travels to rarely visited regions 
around the world to play the trumpet. The two mindsets of Kondo’s jazz and the 
Sansui paintings of “Art of ZEN” corresponded well, and the music harmonically 
matched with the world of “Art of ZEN.” 
 When the user creates a Sansui space on the scroll, human icons are selected to 
talk to him or her. When he or she is traveling in the Sansui world and walking 
toward the waterfall, the sound of a waterfall is played. When he or she approaches 
a mountain or bird, their sounds are also played. Thus, we staged the sounds of the 
Sansui space. 
 Many users appreciated the voice of Matsuoka reading the haiku. There are 
Japanese, English, and French versions of the “Art of ZEN.” I asked artists at MIT 
4 Computing Culture

95
CAVS for their opinions on relevant English voices, because the English version 
should contain English voice-overs of the haiku. Many of my friends at MIT CAVS 
including Hisham Bizri 17 said that as the Japanese voice is well-matched to the 
screen, it would be better to provide captions in English for the Japanese voice. 
 Now I will refer to the creation of different language versions of the “Art of 
ZEN.” I needed to translate Japanese phrases into English because it was to be 
exhibited at the MIT Museum. We asked Prof. Condry to cooperate with us. He had 
worked as a journalist at “Yomiuri Shinbun” (a Japanese newspaper) after he gradu-
ated from university, so he speaks Japanese ﬂ uently. He translated Japanese phrases 
that are rich in nuance to beautiful English phrases that people from other countries 
could easily understand. Bradford Ellis, who was a senior student at the Faculty of 
Technology at Harvard University, also assisted with the translation of the Japanese 
text. 
4.5.1  The Death of Prof. Stephen Benton and the Exhibition 
 In autumn 2003, my former advisor, Prof. Benton, gave me the opportunity to 
exhibit the result of our shared research in the main gallery of the MIT Museum, 
where several successful creations by MIT students were exhibited. 
 The exhibition was advertised on the MIT Web site and newspaper o, headed by 
the title “Zen and the Art of Computers,” which was a parody of “Zen and the Art 
of Motorcycle Maintenance,” a bestselling book in the 1970s by Robert Pirsig. The 
work was welcomed by the unique humor of Americans. I should say that the expe-
rience gave me great joy and moved me deeply, for the work was born through much 
difﬁ culty, and in reality, my mind was anxious and stressed. The exhibition at the 
MIT Museum enjoyed great success and was supported by the Japanese Consulate 
in Boston, the Boston Japan Society, the MIT–Japan Program, and members of the 
Reischauer Institute of Japanese Studies. There was also success during the com-
memoration of the 150th anniversary of Japan–America relations. 
 To my deepest sadness, my former advisor Prof. Benton, the inventor of rainbow 
holography, passed away because of a brain tumor around the time of the exhibition. 
I had wanted to show him the exhibition. Thus, I experienced both the birth of our 
artwork and the death of my former advisor at the same time. As they say, c’est la 
vie (that’s life). 
 It is important to experience Zen with a Zabuton, a square cushion, so we 
lowered the desk and made viewers experience the exhibition while kneeling on a 
cushion. We put the rock garden interface on the low desk, and embedded a 14-in. 
touch screen into it to let it resemble a pond in the garden. We tried to express the 
17  Hisham Bizri is a Lebanese-American ﬁ lmmaker. He has worked in the US and Hungary with 
ﬁ lmmakers Raúl Ruiz and Miklós Jancsó and has made short ﬁ lms in the US, Lebanon, Ireland, 
Korea, Italy, and France. As of 2014, Bizri was an Associate Professor of Film at the University of 
Minnesota, Minneapolis. 
4.5 Opening, Traveling, and Living in Sansui Zen

96
Zenki by the effect that the images jump from the 100-in. screen to the embedded 
pond on the desk. 
 We asked a calligrapher to draw four large calligraphic images 3 m in width, and 
put them on both sides of the main screen, which made the installation appear regal 
and tension-sensitive. One of the exhibitions was held in Kōdaiji, a Zen temple in 
Kyoto, as well as in America and Europe. 
 I read many English books about Zen for my explanation of the exhibition in 
English. Many of these books use difﬁ cult expressions, or easy, but misleading, 
expressions. One of the clearest books about Zen was written by Daisetsu Teitaro 
Suzuki. 18 Half of the book was written in English, and the other part was written in 
Japanese, so the book came in handy because I could look up each word. 
4.5.2  “Art of ZEN” at Ubiquitous House 
 The “Art of ZEN” exhibition was sponsored by two governmental research institutes 
(France Telecom and the National Institute of Information and Communications 
Technology (NICT) that study ubiquitous houses, which are the smart houses of the 
future. These research institutes seemed to think that this work would ﬁ t future 
houses. 
 To set the “Art of ZEN” exhibition up in the ubiquitous house at Lennes 
Laboratory by France Telecom, we needed to synchronize the system with the inte-
rior controllers of the house. I staged the mechanism so that the blinds were closed, 
the lighting dimmed, and incense was burned at the startup of the “Art of ZEN.” In 
every scene, the related movies were projected interactively by the projector on the 
wall. I staged the space like a theatre for the “Art of ZEN”—for example, wind 
blows in the scene of “The Sound of One Hand Clapping,” and the scent of ﬂ owers 
drifts in the scene of “The Lotus Smiles.” For a French translation of the text, I 
asked a French researcher who studied Japanese at Maison Franco-Japonaise. 
 I changed some haiku to the words of Montaigne and some Zen dialogues to the 
words of la Fontaine, based on French ideas. Thus, the system became an actual 
example of cultural computing in which the cultural contents were replaced and 
mixed with those that were regionally relevant. 
 In the ubiquitous room at NICT, we set a 30-in.-wide plasma display in the drawing 
room like an alcove in a traditional Japanese house, and projected “Art of ZEN” 
onto the display. Many RFID (Radio Frequency Identiﬁ er) tags were mounted in the 
room. The system was designed to draw the Sansui paintings on the display when 
18   Daisetsu Teitaro Suzuki (October 18, 1870–July 12, 1966) was a Japanese author of books and 
essays on Buddhism, especially, Zen Buddhism. Suzuki was also a proliﬁ c translator of Chinese, 
Japanese, and Sanskrit literature. Suzuki spent several lengthy stretches teaching or lecturing at 
Western universities, and devoted many years to a professorship at Otani University, a Japanese 
Buddhist school. 
4 Computing Culture

97
the family sat around the table. When the user walked, he/she could listen to the 
voice of the Zen Master and interact using the real room. 
4.5.3  Computing the Spirituality of Japanese Culture 
 The calculation ability of computers, the resolution of the display, and the ability of 
input device advances are advancing beyond human comprehension. I expect that 
future technology will be able to enter the spiritual region of humans. 
 As I referred to in the Introduction, Tibetan high priests believed in the fusion of 
sprits and technology, which I think is not so far away. If a computer system can 
realize a kind of Bodhisattva-like interface, the interactivity may be that of a system 
that can resonate with the spirituality deep within someone. 
 To Western society, Japanese Zen is a mysterious form of psychology from the 
past. While there are books like “Zen for Everyone,” there are still doubts about 
whether everyone can understand Zen as it is. We tried to make “Art of ZEN” some-
thing through which users can learn about Japanese spirituality by tackling Zen 
dialogues, hearing haiku, and stepping into kimono designs. 
 The research into Japanese spirituality sponsored by France Telecom may have 
been made possible by the deep understanding of the cabalas of Christian Baloquie, 
the general manager of France Telecom’s branch ofﬁ ce in Japan. Everyone had an 
interest in the computing of Japanese spirituality. At the end of the sponsored 
research, an evaluation committee was held in Paris. From Japan, I invited Prof. 
Makoto Nagao, 19 the director of NICT at that time, and Prof. Michihiko Mino 20 of 
Kyoto University, to come. A staff member of France Telecom concurrently had 
work as an ofﬁ cer in the Institute of Science and Technology for France’s govern-
ment. He asked us why we used chaos in “Art of ZEN.” 
 Prof. Nagao explained, “The understanding of scientists about the mechanisms 
of a human’s mind is strongly limited. However, we can make a prediction that our 
brains have chaotic dynamics. Running with this idea, we can think that chaotic 
mechanisms are the essential parts that support all the immediate movements our 
bodies and mind have.” This answer was conveyed with conviction. 
 From now on, thoughts and designs for this cultural computing that boldly cross 
cultures were strongly desired. Through the research discussions with many 
 common researchers, I found that from the ancient days, people used symbols and 
allegories to understand or convey the story of something. It was an easier way for 
19  Makoto Nagao (born October 4, 1936) is a Japanese computer scientist. He contributed to various 
ﬁ elds: machine translation, natural language processing, pattern recognition, image processing and 
library science. He was the 23rd President of Kyoto University and also the Director of the Japan 
National Diet Library. 
20   Michihiho Mino is a Professor at the Department of Digital Content Research Academic Center 
for Computing and Media Studies, Kyoto University. The mission of Minoh Laboratory is to 
research in both computation and multimedia communication. 
4.5 Opening, Traveling, and Living in Sansui Zen

98
people to remember a story. Therefore, our next object of research is interactive 
storytelling, which we should research after exploring the current interaction 
 technologies between computers and humans. 
 I considered these things and composed the entire system. To realize the system, 
I took advantage of the chaotic model that represents human minds, the rock garden 
interface, and the interactive 3D computer graphics technology. 
 I am very thankful that we could obtain worldwide empathy for “Art of ZEN,” 
that I had success developing new technology that connects traditional cultures with 
modern cultures using educational computers, and that our system should deepen 
the understanding between cultures. 
 “Art of ZEN” was sponsored by the “Interaction and Intelligence” area of JST, 
France Telecom, ATR, and MIT CAVS. This system was exhibited not only in the 
MIT Museum, but also in Kōdaiji temple, Kyoto in 2004 and in the emerging tech-
nology sector of ACM SIGGRAPH. This system won the prize in the UNESCO 
Digital Cultural Heritage Competition in 2005.  
4.6  Computers Read the Situation 
 I introduced a system in which the viewer can be inspired by Sansui pictures or 
dialogues from Zen culture. As a next step, I developed a search/generation system 
named “i.plot,” which extracted the essence of inspiration. The ‘i’ stands for all of 
inspiration, information, and interactivity. 
 Each culture has contexts for its structure-like style, mode, or code. For example, 
there are poems, tea cultures, Noh dramas, comic dramas, Kabuki. These ‘ structures’ 
of Japanese rules of behavior exist in order to convey tradition. In other words, they 
are the existence of Iemoto (grand master, for example of tea, calligraphy, ﬂ ower 
arrangement, etc. in Japan) and Ma that we physically remember. And in each of the 
process learning mastery in Japanese culture such as tea, calligraphy, etc. as well as 
Ma, there are always three levels called “Shuhari”: the fundamentals, breaking with 
tradition, parting with traditional wisdom. 
 The concept of “i.plot” was to construct what drives our ethnicity inspirationally, 
beyond general synonyms or associations, by creating a database of these ‘ structures’ 
that identiﬁ es culture. 
 When we think about new words, we classify and describe them by discovering 
the general idea that contains the words, or we think about the usage or the function. 
We collect related words, and make associations. In this way, we nurture our under-
standing of words. If we see them from the perspective of phenomena, all the words 
of the world have been named, described, systematized, and related like a complex 
web. We are also included in the world of words and framing it at a certain moment. 
All things are processes that may relate to each other, and they exist. Alfred 
N. Whitehead, an English mathematician and psychologist, says in his book 
“Process and Reality” that there are four hypotheses about creative power: (1) 
Physical association, (2) Conceptual imagination, (3) Propositional imagination, 
4 Computing Culture

99
and (4) Reserved judgment. We considered inspirations of contexts that are hidden 
between words for the database of cultural structures. 
 This was my ﬁ rst research project after I returned to Kyoto from Boston. Two 
young American researchers did excellent work for this research. Jordan Gilliland 
came to Japan through an internship for the MIT-Japan Program, when the research 
was at a brainstorming level. He had studied under Noam Chomsky, the famous 
philologist, who expanded the generative grammar model and grammatically 
resolved the letters by Shakespeare. 
 After him, Bradford Ellis, who had just graduated from Harvard University’s 
School of Engineering, came to my laboratory. He was interested in scientiﬁ c 
 technology, arts, and Japan. Japanese engineering students rarely take up non- 
engineering ﬁ elds as their research, especially when they have passed through grad-
uate school level education. However, I felt the two interns had a capacity to tackle 
ﬁ elds outside the range of pure technology ﬂ exibly, even though they had come 
from schools of engineering. 
 The contexts of daily and general dialogues with computers, for example, to 
make purchases from a vending machine or to reserve something, are what we call 
monotony. If computers can give inspiration with humor and creativity to their 
users, we will be stimulated, and the future relationship between humans and comput-
ers, or using computers in education and entertainment, will change dramatically. 
4.6.1  Generating Inspiration 
 Every time we try to do something, we try and fail dozens of times, like a patience 
test. Every path is ﬁ lled with difﬁ culties. One’s aptitude for science is determined 
by whether they can tolerate these situations for a long time. This is likely the reason 
why researchers are always patient. 
 People talk about many ideas, but usually no concrete conclusion is seen. One 
may think nothing is advancing then, but new thoughts were certainly spreading 
within our thought processes. 
 Originally, a word has its origin and a designated system. If it is a completely 
standalone word, it is just a sound, not a word. A word has choices and metaphors 
from association of its meanings. ‘Emergence’ means the appearance of a new para-
digm that we have not thought of before, which has discovered a new direction to 
move in and, in doing so, break down a large barrier. When the emergence of words 
occurs, elements such as ‘kind’ and ‘individual’ or ‘position’ and ‘ﬁ gure’ connect 
to each other in the ‘story.’ These phenomena lead to the discovery of new relations 
and the creation of brand-new images. To compute these verbal items, we considered 
mechanisms that have various rules. When I struggled to think of an ideal mecha-
nism to stimulate this inspiration, my cooperative researcher talked to me about the 
idea of editorial thought forms, which hit me like a bolt from the blue. I designed 
the system using the open source psychological association data from Edinburgh 
University, which contains about 20,000 words, synonyms, antonyms, and thesau-
4.6 Computers Read the Situation

100
rus dictionaries of word nets from Princeton University and about 5000 pieces of 
data on thought forms. These thought forms are not simple, so I will explain the 
concept in the next section. 
4.6.2  The Forms of Thoughts 
 The ‘editorial thought forms’ are forms of thoughts to edit information. These con-
sist of ﬁ ve types, as you can see below. I constructed a database for the relationships 
of these thought structures. 
4.6.2.1  Concatenation 
 This is information where three words are arranged in order of continuity and they 
specify the following conditions:
 1.  The three pieces of information, A, B, and C, are of the same rank. 
 2.  The order of A, B, and C specify the position. 
 3.  The differences between (A and B) and (B and C) are the same. 
 For example: Hop–Step–Jump. 
4.6.2.2  Balance 
 The information about balance speciﬁ es the following conditions:
 1.  The three pieces of information, A, B, and C, are of the same rank. 
 2.  A, B, and C pull each other with the same force. 
 3.  The relations between (A and B), (B and C), and (C and A) are the same. 
 For example: The Holy Trinity of Christianity (Father–Son–Holy Spirit). 
4.6.2.3  Division 
 This is the division of an idea and the information speciﬁ es the following 
conditions:
 1.  The parent information, A, can be divided into the child information, B and C. 
 2.  The child information, B and C, is balanced. 
 3.  The relationship between A and B is equal to the relationship between A and C. 
 For example: Computers can be divided into software and hardware. 
4 Computing Culture

101
4.6.2.4  Uniﬁ cation 
 This is the combination of two ideas to produce a new word or a paradigm. For 
example, radio and cassette combines to produce a ‘radio cassette’ player. 
4.6.2.5  Crisscross 
 There are two patterns of crisscross:
 1.  Parallel combinations of B, C, D, and E connect to A as the center. 
 * The information B, C, D, and E are of the same rank. 
 * The information B, C, D, and E pull each other with the same force. 
 For example: If we take four seasons to be A, and B–E to be spring, summer, 
autumn, and winter.
 2.  The combination of two axes B–C and D–E. 
 * Each relationship of B, C, D, and E to A is the same. 
 * Assume the orthogonal coordinates for simpliﬁ cation. Information B–C is set to 
axis Y, D–E is set to axis X. 
 For example: The information ‘young and old of both sexes’ sets two axes, 
‘young–old’ and ‘man–woman.’ We can multiply the information in each space 
divided by the axes. That is, we can have the extremes ‘old man,’ ‘old woman,’ 
‘young man,’ and ‘young woman.’ These may generate new images or ideas. 
4.6.3  Dictionary of Images 
4.6.3.1  Psychological Association Dictionary 
 I used an open source database, the Edinburgh Associative Thesaurus (EAT) of 
“psychological association data” of Edinburgh University (Kiss et al.  1973 ). The 
data of EAT was created in the following steps: 1. In the 1980s, Edinburgh University 
made their students give words that most associated to each of 100 randomly 
selected words as fast as they could. One hundred different answers were collected. 
2. They made the data the small core of an association network. If we input a word, 
all the associated words will be output. 3. They used the associated words generated 
described in the second step to generate more associated words. Repeating these 
steps three times, they created a huge association network in which a great many 
words were linked to many others. 
4.6 Computers Read the Situation

102
4.6.3.2  Conception Dictionary 
 I used a conception dictionary (a dictionary of meanings) named WordNet, which 
was created by the Cognitive Science Laboratory of Princeton University (Miller 
 1995 ). In WordNet, words are classiﬁ ed into sets of synonyms named synsets. A 
simple deﬁ nition and relationships to other synonym groups are described. The goal 
of WordNet is to realize a dictionary that we can use intuitively to support automatic 
document analysis systems and artiﬁ cial intelligence systems. The database and 
software are opened based on BSD (Berkley Software Distribution) license, one of 
the free software license mechanisms, so anyone can download and use them. We 
can even access the WordNet online database by visiting the Princeton University 
Web site (Princeton University  2015 ). 
4.6.4  Willful Chaos Search 
 If we perform a search using two words, most systems select many words as long as 
they have short distances with the words and simply return the search results. 
However, I used another way of searching. The data I used have a ‘structure’ called 
thought forms, which is a huge association structure like the psychological associa-
tion dictionary and the conceptual dictionary structure, which contains strong, 
weak, opposite, and similar connections to other words, such as ‘neurons’ and ‘syn-
apses’. The chaos system doesn’t simply connect the closest words, but connects 
two different words using a unique way of searching, which we usually do not 
notice. I used the dual synchronized chaos engine to determine the length through 
which to search for relationships. The system let the dual synchronized chaos engine 
determine the distance between the input words and even searches the newly 
inspired words by adding elements depending on their relationships. Using the 
‘thought forms,’ ‘psychological association dictionary,’ and ‘chaos search,’ I devel-
oped a type of inspiration computing, based on a database of 20,000 or more words. 
4.6.5  “i.plot” – A Thought Space to Connect Images 
and Words 
 I will introduce the system named “i.plot,” which forms associations to create inspi-
rations using a chaos search and generate an inspiration space. 
4.6.5.1  Inspiration Space 
 If a user selects two words, the system presents the hidden relations as an ‘inspira-
tion space’ to the user. The strong point of the system is to create a ‘thought space’ 
by connecting the thought forms and psychologically associated words from the 
4 Computing Culture

103
huge number of chaos searches like a spider’s web. Some chaos parameters may 
result in a distant relationship that enables us to discover even more unexpected 
relationships between words. The association abilities of computers are shown to be 
usually beyond the association abilities of humans. 
 Each word has its synonyms and antonyms and can be divided and uniﬁ ed, the 
results of the search using these word relationships generates the association space 
for any words. When we think about something, external and internal information is 
mixed a ‘thought space’ in the brain is generated. The system visualizes an inspira-
tion space that is similar to the internal one. 
 I researched the rules to connect images and words, and ﬁ rst tried to connect the 
image of the wall paintings of South America (Satumo and Taube  2009 ) to each 
word. The reason is that each painting is classiﬁ ed into some concept such as gods 
or animals in the text. However, the paintings were hard to connect because the clas-
siﬁ cation included much less variance than the data of 20,000 words and the differ-
ences between their ages and cultures, and I was unable to ﬁ nd adequate 
correspondence between these two types of classiﬁ cation. Next, I tried to create a 
database that used comic book frames and the words representing the contents. 
However, the comic book frames were already related to the context around the 
adjacent frames, so I could not ﬁ nd signiﬁ cant correspondence either. Then I 
attempted to use pictograms instead, but pictograms, like trafﬁ c signs and smart-
phone icons, could not be a common visual language, and the correspondence was 
often nonsensical. Finally, I considered hieroglyphs in wall paintings, and I decided 
to use Kanji (Chinese characters) because Chinese characters are pictographs, like 
hieroglyphs. Although there are various types of Kanji depending on age, I used the 
oracle bone scripts that were used in the eleventh to fourteenth century BC, as these 
old kanji are close to visual images. 
 If the user inputs two words, the software generates the translation in hieroglyphs 
associated with the input words, namely, the kanji of the words are expected to gen-
erate inspiration. We can observe the relationships between images and words by 
the inspiration created from the combination of kanji, as hierograms, and English 
words, as phonograms (Fig.  4.23 ).
4.6.6  “i.plot” for Reading the Situation 
 I designed software that shows various relationships of words through ‘inspira-
tional’ computing when the user inputs a sentence. The ﬁ rst step in designing this 
software was to create software that would help Japanese people understand English 
contexts, as Japanese people may misuse English vocabulary when they write 
English e-mails. However, the results were beyond my expectations. 
 With more and more reﬁ ned sentence input, this software can generate more 
words that reﬂ ect the rich vocabulary of the original sentence. I could feel the imagi-
nation and the extent of the sentence. Next, I tried to visualize the words related to 
both previous and next sentences. This means that the computer tried to ‘pick up the 
subtext’ of the sentences. 
4.6 Computers Read the Situation

104
 Fig. 4.23   “i.plot” showing the relationship between two words both English words and 
hierograms  
 Fig. 4.24   “i.plot” showing words related to the input “Love is blind” 
 
 
4 Computing Culture

105
 For example, we input three sentences: 1. “Love is blind,” 2. “To be or not to be,” and 
3. “That is the question,” from the most famous part of “ Hamlet ” by Shakespeare. Then the 
hidden backward words associated with sentence 1 are displayed in blue font (Fig.  4.24 ).
 After that, the computer carries out the search for 2. “To be or not to be,” and 
displays the associated words related to the context of sentence 1 as well as sentence 
2. Comparing the ﬁ rst result and the second result, we can see the movement of the 
context between these sentences (Fig.  4.25 ).
 Fig. 4.25   “i.plot” showing words related to the input “To be or not to be” 
 Fig. 4.26   “i.plot” showing words related to the input “That is the question” 
 
 
4.6 Computers Read the Situation

106
 Finally, if we input 3. “That is the question,” the computer displays the ﬂ ow of 
the context considering the two sentences input before. Let us compare these three 
results (Fig.  4.26 ). How did the context shift?
 You may have noticed that the ‘situation’ expressed by the context of the three 
sentences is visualized, and it can be read. In the ﬁ rst sentence “Love is blind,” the 
computer created an atmosphere of sweetness and with plenty of room, but if the 
sentence proceeds to “That is the question,” the words are replaced by more serious 
words. 
 Thus, computers can give humor, knowledge, and inspiration to the users by 
considering the clue to inspiration. “i.plot” was the result of my attempt to create an 
inspiration engine that can stimulate the images in our brains with plenty of 
 vocabulary, using the logical meanings of language, cultural structures, and original 
images of kanji. 
 You may have noticed that when I explained culture as existing between texts and 
images or between texts and texts, secondary meanings emerged around them. In the 
next section, I will discuss these meanings in the context of haiku poetry as a realiza-
tion of the “intertextuality (Kristeva  1980 ; Allen  2011 )” proposed by Julia Kristeva. 
 France Telecom sponsored this research and the system was developed with their 
funding. I exhibited and demonstrated this software in the emerging technology 
 sector of ACM SIGGRAPH. 
4.7  “Hitch Haiku” of Tree Peony and Foo Dog 
 Using the inspiration computer, I tried to connect words and images and to describe 
the situation between the lines from connections of sentences to visualize our inner 
images. As a next step, I set myself the challenge to generate haiku because it has 
unique Japanese rhythms and involves plenty of cultural concepts like Kireji, Uta- 
makura or Honka-dori, which are speciﬁ c to haiku. I will introduce my cultural 
computing project named “Hitch Haiku,” which takes (hitches) Kanji from books 
around the world and makes associations in the form of Haiku. 
4.7.1  Hitching the Kanji 
 Haiku is a form of old Japanese poetry that contains 5, 7, and 5 Japanese syllables; 
it is the world’s shortest style of poem. Haiku includes ‘Kigo,’ which speciﬁ es the 
season, be it the new year, spring, summer, autumn, or winter. Haiku also includes 
‘Kireji,” for example, “ya,” “kana,” or “keri,” that connect phrases. The original 
form of haiku is Renga, in which two parts are sung alternatively, which originated 
in the Muromachi era. 
 In the seventeenth century, Matsuo Basho ( 1967 ) picked up Hokku, the ﬁ rst part 
of Renga, and created haiku. When we make a haiku or a small composition, some-
4 Computing Culture

107
times we cannot ﬁ nd good words, because we are ﬁ xated on certain ideas. 
Professionals refer to the Saijiki and relevant associated words from it, but most of 
us cannot do that. However, “Hitch Haiku” takes phrases from the contexts of books, 
connects them to the associative Saijiki, and generates a haiku automatically. I tried 
to construct a haiku composition-supporting tool. 
 I will refer to the process of generating haiku in Sect.  4.7.3 , but before that I must 
give an overview of the system. A user selects relevant words from e-books to be 
used in the haiku. Then the computer takes phrases from a Kigo database that 
includes a large number of haiku from Saijiki and generates a haiku.  
4.7.2  “Hitch Haiku” Interactions 
4.7.2.1  Select Your Favorite Phrases 
 The user visits one of e-books stored for this project on the Internet and ﬁ nds favor-
ite phrases that are linked to each book. 
4.7.2.2  Select Words to Create Your Haiku 
 The user highlights several words he or she likes using the pen icon from the text 
(Fig.  4.27 ). The ﬁ rst marking color is green, which represents that the words are 
the temporary selection. If the user highlights one or two words among the green- 
colored words to use in their haiku then the words are marked in red, and deter-
mined to be used for the haiku generation. The system then generates a haiku by 
 Fig. 4.27   Several key 
words highlighted 
by a user  
 
4.7 “Hitch Haiku” of Tree Peony and Foo Dog

108
selecting related phrases using all the words marked in green or red. Note that the 
weight of red-colored words is greater than that of green-colored ones. The user can 
use the eraser function to cancel the highlighting of words and reselect words.
4.7.2.3  Connect the Kireji 
 To keep the format of Haiku, appropriate particles and auxiliary verbs (Kireji), like 
ya, kana, or keri, are inserted after words to act as word separators. 
4.7.2.4  Select a Kigo (Season Word) and Generate the Haiku 
 To obtain maximum quality, the computer searches for a Kigo (season word) associ-
ated with the input words in a Saijiki, a dictionary of haiku, and an example-based 
database of any haiku poets. After that, the computer selects words related to the 
Kigo from texts of the book the user selected in step 3. Then the system generates a 
haiku related to the book. The computer does not directly use the input words, but 
selects high-ranked words from a large number of words related to the input words. 
4.7.2.5  Display the Haiku Animation and Select Sound Effects 
 The created haiku is displayed with a design determined by the image of the selected 
book. The design of characters (Japanese/English, layout, and display animation), 
the background movie, and the music are selected from this design (Fig.  4.28 ). As a 
variation function of the Haiku display, the user can click [Next] at bottom-right to 
generate another haiku with the same input words. The user can also click [Enter] to 
view the haiku translated into English (Fig.  4.29 ).
 Fig. 4.28   An example of 
generated Haiku  
 
4 Computing Culture

109
4.7.2.6  Castigation 
 The user can overwrite the generated haiku to brush up the expression so that it 
looks better. 
4.7.3  Haiku Generation Process 
 In this section, I refer to the processes of the interaction system I described earlier 
(Fig.  4.30 ). The main processes like morphological analysis and searching for 
related words are performed in Japanese, and some processes are performed in 
English, if required. Here are my step-by-step instructions for the inner processes of 
my interaction system:
 1.  The user inputs several words by marking them. 
 2.  The system processes the input words for their syllable counts. Kireji like ‘zo’ 
and ‘ya’ and particles are inserted after the words, or before the words for adverbs 
like ‘geni.’ Depending on the conjugation of the words, additional modifying 
words are added before or after the input words. 
 3.   At the same time, the system picks out nouns, verbs, adjectives, or adverbs by 
dividing the input words to morphemes, using the morphological analyzer. 
  4.  The system searches related words to each morpheme from its seven databases of 
related words: Thesaurus DB, Haiku thesaurus DB, Kigo DB, Idiom DB, Case 
frame DB, Onomatopoeia DB, and Learning DB. Each database has multiple 
words with each classiﬁ cation name. Note that the ‘related words’ to the word ‘S’ 
is a set of all words with the same classiﬁ cation as ‘S,’ except ‘S,’ in a database.  
 5.  When the generating haiku phrase has a Kigo word, the system searches haiku 
phrase databases that do not contain the Kigo, and when not, the system searches 
from the Kigo phrase database. When two or more phrases are found, the system 
obtains one phrase by weighting them.  
 Fig. 4.29   English 
translation of the generated 
Haiku 
 
4.7 “Hitch Haiku” of Tree Peony and Foo Dog

110
 6.   The system selects the highest weighted phrase as the related phrase to the user 
input words. 
 7.   The system generates a haiku by connecting the modiﬁ ed phrases or related 
phrases to form sets of syllables as 5–7–5.  
 8.  When the language is English, the system translates the phrases. Phrases gener-
ated by this system include many old Japanese words, so this system includes a 
special 
‘Old 
Japanese–Modern 
Japanese 
Dictionary’ 
and 
‘Japanese 
Onomatopoeia–English Onomatopoeia Dictionary’ in order to translate old 
Japanese words into the current language before translating them to English. For 
example, the phrase ‘ᶕȁ’ must be translated into ‘has come,’ but an average 
translator translates it as ‘does not come.’ 
 9.  The system uses a learning function to upgrade the quality of haiku generation 
by learning the result of the user’s castigation to the generated phrase. At ﬁ rst, 
the castigated phrases are inserted into the haiku phrase database. Then, the sys-
tem assumes that the user input words are related to the castigated phrases and 
registers the relation between input words and the castigated phrases into the 
database of related words. Figure  4.31 shows an example of haiku generation 
using the input words, ‘heart’ and ‘light snow.’
1.
User Input
7.
Generate Haiku
by “hitching”
the phrases
2. Adapt Kire-ji to
the input words
in order to adjust
the length
3. Morpohological Analysis
4. Search words from DB
5. Search phrases including the
association words from phrase DB
and attach them with weights
6. Select one phrase with
highest weight
8. Translate into English, if needed
9. Touch up and learning
Association words
DB
 Haiku Phrase DB
without Kigo
Haiku Phrase DB
with Kigo
Hitch Haiku System
Example Flow of Haiku Generation
 Fig. 4.30   Haiku generation process 
 
4 Computing Culture

111
  (a)  By adding some modifying words to ‘heart’ and ‘light snow,’ the system adjusts 
the phrase to make the length of the line 5 or 7 syllables.  
 (b)  Then, the computer searches the related words ‘heart’ and ‘light snow.’ For 
example, in the haiku thesaurus database, the system ﬁ nds ‘mottled snow,’ 
‘melting snow,’ and so on. 
  (c)  Because they include ‘snow,’ a Kigo of winter, the system searches phrases that 
include related words from a haiku phrase database without any Kigo. 
 (d)  A phrase ‘my heart is now dancing’ includes two related phrases, ‘my heart’ and 
‘dancing,’ so the weighting of the phrase increases. As a result, the phrase is 
selected as the most related phrase to the input words and is used in the haiku.  
  (e)  A Haiku ‘Light snow falling/My heart is now dancing/Together’ is generated. 
Thesaurus
(3 point)
+
Input
“Heart”
“Light snow”
Thesaurus
(3 point)
“Falling”
“Sincerity”
“Heart”
Haiku 
Thesaurus
(5 point)
“Snowshoe”
“Spotted snow”
“Melting snow”
Season 
words
(5 point)
“Frost”
“Light snow”
“Soft rime”
Idiom 
thesaurus
(5 point)
Case frame
(3 point)
“Dance”
“Warm”
“Touch”
“Together”
Onomatopoeia
(3 point)
“Konkon”
“Sansaku”
“Shinshin”
5 point
“Bring up
light snow”
0 point
“Rustic
appearance”
0 point
“Doubtful
smile”
6 point
“My heart now
dancing”
My heart now
dancing
5 point
“Cough
Konkon”
Together
Light
snow
falling
Created Haiku
The most
related word
Database Phrases
・　・
Case frame
(3point)
Process Flow of Hitch Haiku System
 Fig. 4.31   An example of Haiku generation corresponding to the input “Heart” and “Light snow” 
 
4.7 “Hitch Haiku” of Tree Peony and Foo Dog

112
  (f)  If an English translation is required, the haiku is translated into English at this 
stage. 
  (g)    When the user corrected the phrase ‘dancing’ to ‘rising,’ the corrected phrase 
registered in the haiku phrase database. Then, the system morphologically ana-
lyzes the phrase and obtains ‘my heart’ and ‘rising.’ Finally, the system registers 
them in the learning database so that a classiﬁ cation named ‘heart’ relates to ‘my 
heart’ and ‘rising,’ and also, ‘light snow’ relates to ‘my heart’ and ‘rising.’  
4.7.4  Database 
 In constructing the system, I prepared several databases. There are seven databases 
for related words: Thesaurus, Haiku thesaurus, Kigo, Idiom, Case frame, 
Onomatopoeia, and Learning. There are two types of haiku phrase databases. The 
haiku phrase database with Kigo includes Kigo and phrases, and the haiku phrase 
database without Kigo includes only phrases. The Thesaurus is a set of words that 
have similar meanings, and the Thesaurus database includes classiﬁ cation names and 
words from the Thesaurus Dictionary of the National Language Laboratory. The 
Thesaurus database includes about 32,000 records. For example, a classiﬁ cation 
named ‘The amount, limit’ contains ‘extreme,’ ‘culminate,’ ‘climax,’ and ‘satisfy.’ 
 The Haiku thesaurus includes the relationships between haiku terms and the 
morphemes of the descriptions from a haiku dictionary. The Haiku thesaurus 
database is constructed with terms using the classiﬁ cation names and the mor-
phemes of the descriptions as the words. This database includes about 2500 words. 
For example, a classiﬁ cation name ‘love’ contains ‘courting,’ ‘tender love,’ ‘mature 
love,’ ‘smothering love,’ and ‘affection.’ 
 The Kigo determines the season of a phrase. The Kigo database includes Kigo as 
words and seasons as classiﬁ cation names. The Kigo database includes about 13,000 
records. For example, a classiﬁ cation ‘spring climate’ contains ‘spring rain,’ ‘the 
ﬁ rst thunder of the year,’ ‘mottled snow mountain,’ ‘east wind,’ and ‘heat haze.’ 
 Idioms are phrases that have ﬁ xed meanings. The idiom database has direction 
words from the Idiom dictionary as classiﬁ cation names, morphemes of the direction 
words as the words, and morphemes of the descriptions as columns. The Idiom 
database includes about 1300 records. For example, a classiﬁ cation named ‘cry’ con-
tains ‘nearly cry,’ ‘between tears,’ ‘burst into tears,’ and ‘inner corner of one’s eyes.’ 
 Case frames include words and related nouns or verbs. The Case frame database 
includes constructs of nouns and verbs in columns, using these words as the 
 classiﬁ cation names. The database includes about 31,000 records. For example, a 
classiﬁ cation named ‘smile’ includes ‘you,’ ‘man,’ ‘the apple of one’s eye,’ ‘face,’ 
and ‘goddess.’ 
 Onomatopoeia includes imitative words. The Onomatopoeia database uses direc-
tion words from the haiku imitative words dictionary as the classiﬁ cation names, 
with morphemes of the descriptions as the words. The Onomatopoeia database 
4 Computing Culture

113
includes about 8800 records. For example, a classiﬁ cation name ‘Uh-uh’ contains 
‘strain,’ ‘assent,’ ‘permit,’ ‘agree,’ and ‘a voice.’ 
 The Learning database contains the learning data from user’s castigation to the 
generated haiku. The Learning database has the input words as the classiﬁ cation 
names, and the morphemes of corrected phrases as the words. The number of 
records increases as the system learns. 
 The Haiku phrase database with Kigo includes about 13,000 records, and the data 
is from a Saijiki. The Haiku phrase database without Kigo includes about 25,000 
records from the haiku thesaurus, haiku idiom, and imitative words dictionaries.  
4.7.5  Discovery of Digital Haiku Aﬁ cionados 
 In the previous sections, I introduced a haiku composition supporting system that 
automatically generates a haiku from user input words by modeling the structure of 
Japanese haiku as an example of cultural computing. 
 “Hitch Haiku” was exhibited at ACM SIGGRAPH held in America in 2007. I 
investigated the feedback of viewers from around the world. Nowadays, blogs and 
media on smartphones are popular, and linguistic expressions on digital media are 
gathering attention. Therefore, many people were interested in the connection 
between haiku, as a traditional culture, and IT. I was surprised that many young 
people had an interest in this system, because I thought that elderly people cared 
more for haiku than did younger people. 
 Younger people were enjoying haiku not only as poems, but also with music and 
videos. From a different perspective, they viewed haiku as something with different 
grammar, structures, and relations than present blogs or e-mails. They may have felt 
the birth of something like “intertextuality” as described by Julia Kristeva in the 
combination of the text data. 
4.7.6  Haiku Generation with Lasting Impressions 
 I aimed to develop a system based on learning by imitation, (this is the basis of 
Japanese culture), in this Haiku system by assuming that the right way is to imitate 
the structure of human thought and association during the composition of haiku. 
However, the system did not achieve the capability for haiku generation. To ﬁ nd the 
haiku phrases, the system searches huge databases for existing associations. To generate 
tasteful haiku, the system uses some rules of haiku such as associations with Kigo, 
Kireji, Uta-makura, and Kakari-musubi.   21  The system is now at the stage of providing 
haiku using chosen words and phrases into a haiku model of 5–7–5 syllables. 
21  Kakari-musubi is a special way of connecting two Japanese phrases; usually a subject phrase and 
a verb phrase. When connecting these two phrases one of several simple postpositional particles 
are used. Sometimes, however, when the author wants to emphasize a subject phrase, he/she can 
4.7 “Hitch Haiku” of Tree Peony and Foo Dog

114
 We should research methods to remedy the fragility of human minds in composing 
haiku, for example, the feelings of ‘yearning,’ ‘involvement,’ ‘playful sprit,’ or ‘blushing’ 
from the perspective of cultural computing. In addition, unique Japanese feelings, 
language, and characteristics also need to be investigated. For example, we should 
research how people use words like ‘Wabi-sabi’, 22 ‘Utsuroi’ 23 or ‘Okashi’, 24 ” in 
Haiku and Waka. We should also compute the use of Honka-dori, 25  which is some-
thing like ‘cut and paste’ in haiku, or the use of Uta-makura or Makura- kotoba, 26 
which represent beauty spots, and the relation of the Kakari-musubi connection. 
 In its current stage, this system plays the role of an association dictionary that 
provides people with a more ﬂ uent vocabulary when they write. Therefore, making 
the usability of this system as one that widens the creativity of human vocabulary is 
reasonably adequate. 
4.7.7  Appearance of Haiku Media 
 While I was selecting relevant books from a huge amount of e-books for haiku 
generation, I realized something. At ﬁ rst, I thought that I could create a system that 
can generate haiku similar to those by Basho that I learned in school. But when I 
tried to generate haiku from a book by Kepler, Plato, Minsky (a researcher of AI), 
Giacometti (a sculptor), and a book of craftworks by a German electro-pop musi-
cian, the generated haiku, of course, would include text that represented concepts and 
use one of the speciﬁ c postpositional particles. In this case a succeeding verb phrase should be 
changed in speciﬁ c form according to the postpositional particle. In ancient Japan such as the 
Heian era (ninth to twelfth century) the use of Kakari-musubi was very popular but nowadays it has 
mostly disappeared. 
22  Wabi-sabi is a Japanese aesthetic feeling that became apparent in the late Muromachi period and 
became shared by many Japanese throughout the Edo period. The thought such as “everything has 
to change” or “nothing is eternal” is the basis of Wabi-sabi. Based on such thought, Wabi-sabi 
emphasizes the beauty existing in something simple, old, small, and sometimes poor contrary to 
beauty in huge, gorgeous, new, and luxury objects. 
23  In Buddhism there is a basic concept that everything is not eternal, and will change and pass 
away. Utsuroi means the process of things to change and pass away. The basic attitude to accept 
Utsuroi, even to appreciate it has been the core part of the aesthetics of Japanese people. 
24  Okashi is archaic Japanese, meaning that there is a taste which deeply appeals to one’s heart 
when one sees nature or people’s behaviors surrounding him/her. The word was mainly used by 
women in the high court in the Heian period. The word is considered one of the representative 
words expressing Japanese woman’s aesthetics in the old days. 
25  Honka-dori is one form of Waka composition in which an old famous Waka is treated as a refer-
ence and a part of the referred Waka is used in a newly composed Waka. By doing it, it is believed 
that the composed Waka would deepen its meaning and become more valuable by expanding the 
imagination of listeners. 
26  Makurakotoba, literally “pillow word”, are a set of words or phrases used in Japanese Waka 
poetry, where epithets are used in association with certain words. Their usage is akin to the “grey-
eyed Athena” in the Ancient Greek epics of Homer. The set phrase can be thought of as a “pillow” 
for the noun or verb it describes. 
4 Computing Culture

115
thoughts from these books. I was troubled over this phenomenon because these texts 
would prevent the generated haiku from being Japanese, or from even being senti-
mental, like the works of Basho. Suddenly, I noticed that it may be wrong to forcibly 
create haiku like the works of Basho for any book in all categories. For example, it 
is wrong to describe steamed egg hotchpotch molded in a pudding pan as a ‘pud-
ding.’ Like that, if we generate haiku from the texts of a book by Goethe, it would not 
be the same as a classical haiku. It would be a haiku created using Japanese cultural 
computing haiku media as a compromise between the East and West. 
 Research of haiku media should focus on the original concept of haiku and 
Renga. Then, we should understand that these media are the starting point of 
Chanoyu, 27 and notice that the target of these media was to realize Ichiza-konryu, 28 
the meaning of which is that they share several relaxed hours. Someone who is not 
satisﬁ ed with the current blog and Facebook interfaces may prefer new types of 
networked haiku-generation environments. Basho 29 is said to have liked ‘love haiku’ 
like a love letter; someone may start to compose love haiku using the love poems of 
Shakespeare as a source. 
 Research to generate movies or music that matches the generated haiku is needed 
for multimedia haiku research. The translation of Japanese haiku to English also 
needs to be more precise. Through such research, I would like to etherealize the 
system to generate haiku with impressive digital content that call to the depths of 
our memories, consciousness, and ethnicities.  
 References 
 Allen G (2011) Intertexuality. Routledge, London 
 Basho M (1967) The narrow road to the deep north and other travel sketches. Penguin Classics, 
New York 
 Chiba R (1989) Sesshū’s long scroll: a Zen landscape journey. Tuttle Publishing, Clarendon 
27  Chano-yu is the Japanese tea ceremony, also called the Way of Tea. Chano-yu is one of the core 
parts of Japanese cultural activity involving the ceremonial preparation and presentation of Macha, 
powdered green tea. The sophisticated manner in which it is performed was required for noble men 
or high-ranked people in the Edo period. Zen Buddhism was a great inﬂ uence in the development 
of the tea ceremony. 
28  In the tea ceremony, a master should do the best he/she can for the invited guests to enjoy and 
appreciate the ceremony. Also the invited guests are required to graciously enjoy the tea ceremony 
corresponding to the effort of the master. Then the group joining the tea ceremony can share an 
atmosphere that they are one united group even for a short time and can enjoy this one-time 
meeting in their life, which is called Ichiza-konryuu. Another well known phrase “Ichigoichie” has 
the same meaning. 
29  Matsuo Bashō (1644–28 November 1694) was the most famous Haiku poet of the Edo period in 
Japan. During his lifetime, Bashō was recognized for his works in Renga, collaboratively created 
continuous Waka. As Basho treated the ﬁ rst part of Renga independently and it became a new short 
poem form called Haiku, today he is recognized as the greatest master of Haiku. His poetry is 
internationally renowned, and in Japan many of his poems are reproduced on monuments and 
traditional sites. 
References

116
 Cohen R (1997) Negotiating across cultures: international communication in an interdependent 
world. United States Institute of Peace, Washington 
 Falser M, Juneia M (2013) Archaeologizing heritage?: transcultural entanglements between local 
social practices and global virtual realities. Springer, Berlin  
 Gleick J (2008) Chaos: making a new science. Penguin, New York 
 Hall ET (1973) The silent language. Anchor, New York 
 Hall ET (1990) The hidden dimension. Anchor, New York 
 Ishida T (2006) Language grid: an infrastructure for intercultural collaboration. In: International 
symposium on applications and the internet. IEEE, New York, pp 5–100 
  Kiss GR, Armstrong C, Milroy R, Piper J (1973) An associative thesaurus of English and its com-
puter analysis. In: The computer and literary studies. University Press, Edinburgh, pp 153–165  
 Kristeva J (1980) Desire in language: a semiotic approach to literature and art. Columbia University 
Press, New York 
 Miller GA (1995) WordNet: a lexical database for English. Commun ACM 38(11):39–41 
 Neogy I (2012) When culture matters: the 55-minute guide to better cross-cultural communication. 
Verb Publishing Ltd, Roystone 
 Nishiyama K (1999) Doing business with Japan: successful strategies for intercultural communi-
cations. University of Hawaii Press, Hawaii 
  Princeton University (2015) WordNet. [Online] Available from:   https://wordnet.princeton.edu  . 
Accessed 22 Sept 2015  
 Rauterberg M, Hu J, Langereis G (2010) Cultural computing – how to investigate a form of uncon-
scious user experiences in mixed realities. In: IFIP advances in information and communica-
tion technologies, vol 333. Springer, Berlin/Heidelberg/New York, pp 190–197 
 Satumo W, Taube K (2009) Maya archaeology 1: featuring the ancient Maya Murals of San 
Bartolo, Guatemala. Precolumbia Mesoweb Press, San Francisco  
 Silberman NA (2005) Beyond theme parks and digital data: what can cultural heritage technolo-
gies contribute to the public understanding of past? Selected Works of Silberman N A, 
University of Massachusetts, Amherst 
 Simpkins CA, Simpkins A (1999) Simple Taoism: a guide to living in balance. Tuttle Publishing, 
Clarendon  
 Song M (2009) Virtual reality for cultural heritage applications. VDM Verlag, Saarbrücken 
 Tanaka I (1972) Japanese ink painting: Shubun to Sessu. Weatherhill/Heibonsha, Boston/Tokyo 
 Tetsuro W (1971) Climate and culture: a philosophical study. Hokuseido, Tokyo 
 Tosa N (2006) Unconscious ﬂ ow. LEONARDO 33(5):442 
 Tosa N, Nakatsu R (2000) Interactive art for Zen: unconscious ﬂ ow. In: Proceedings of IEEE inter-
national conference on information visualization. IEEE, New York, pp 535–540 
 Tosa N, Matsuoka S, Ellis B, Ueda H, Nakatsu R (2005) Cultural computing with context-aware 
applications: ZENetic computer. In: Entertainment computing – ICEC2005. Lecture notes in 
computer science, vol 3711. Springer, Berlin/New York, pp 13–23 
  Tosa N, Matsuoka S, Nakatsu R (2008) Computing inspiration: i.plot. In: New frontiers for enter-
tainment computing, Springer, New York, pp 117–127 
 Tosa N, Obara H, Minoh M (2009) Hitch Haiku: an interactive supporting system for composing 
Haiku poem. In: Entertainment computing – ICEC2008, Lecture note in computer science, vol 
5309. Springer, Berlin/New York, pp 209–216 
 Wong E (2011) Taoism: an essential guide. Shambhala, Boston 
 Yamashita N, Ishida T (2006) Effects of machine translation on collaborative work. In: Proceedings 
of the 2006 20th anniversary conference on computer supported cooperative work. ACM, New 
York, pp 515–524 
4 Computing Culture

117
© Springer-Verlag London 2016 
N. Tosa, Cross-Cultural Computing: An Artist’s Journey, Springer 
Series on Cultural Computing, DOI 10.1007/978-1-4471-6512-5_5
 Chapter 5 
 Cultures, Subconscious and Creativity 
Software 
5.1  Cultures from an Engineering Perspective 
 “While ensuring the free ﬂ ow of ideas by word and image, care should be exercised 
that all cultures can express themselves and make themselves known. Freedom of 
expression, media pluralism, multilingualism, equal access to art and to scientiﬁ c 
and technological knowledge, including in digital form, and the possibility for all 
cultures to have access to the means of expression and dissemination are the 
 guarantees of cultural diversity (Hanania  2014 ).” 
 In a broad sense, but on a small scale, cultural computing has already begun in 
various ﬁ elds (Tosa et al.  2005 ; Tosa  2010 ; Rauterberg et al.  2010 ; Hu et al.  2008 ). 
Through VR technology, countries with long histories such as Italy and China have 
created various virtual walkthroughs of their architecture that showcase their tradi-
tional culture (Gaitatzes et al.  2001 ; Hu et al.  2003 ; Ronchi  2009 ). These countries 
are now discussing the possibilities of interactions with their historical cultures at 
museums and international conferences worldwide. 
 For example, in the opening of the Beijing Olympics in summer 2008, many 
 elements of traditional Chinese culture were exhibited at the Beijing 2008 Opening 
Ceremony (Cook and Miles  2010 ). Rendered by Zhang Yimou, the Chinese cine-
matographer, historical Chinese percussion instruments with 3000 year histories 
were played, and a huge picture scroll was projected on a special screen. Several 
things that represent Chinese culture were used—for example, paper used on fold-
ing fans, the stage of the Beijing opera, ink brushes, kites, and the clothes of the 
performers. Computers controlled the entire process. I was taken in and impressed 
by the power of Chinese culture created through a demonstration of their history. 

118
5.1.1  Interactive Digital Archives 
 Let us now explore how to connect culture and technology. Digital archive tech-
nologies digitalize and save physical and nonphysical cultural resources such as 
history exhibitions, and art museums, public records ofﬁ ces, or libraries. These are 
intended to preserve visual heritage, to record culture, and to create regional visual 
libraries or regional industrial archives. These are mostly expressed by text, sounds, 
pictures, and videos (Hu et al.  2003 ; Ronchi  2009 ). The Japanese Ministry of 
Education, Culture, Sports, Science, and Technology (MEXT) has budgeted for 
this, and the archive has grown enormously (Kaneko  2012 ). However, MEXT can-
not ﬁ nd an effective use for the archive, and because of this, the project has been 
viewed with suspicion (Digital Content Association  2012 ). 
 A problem is the potential attractiveness of the digital archive. The system pre-
serves documented information with explanations or voices and can be searched by 
computers. Showing an audience an archive in this way is considered not very inter-
esting by the IT society where people use various kinds of interactive media. 
Interactive cultural computing that adds cultural models or stories to cultural infor-
mation would increase the attractiveness of the digital archive as a system. 
5.1.2  Media that Preserves Culture for Future Children 
 World heritage and intangible cultural assets exist all around the world. Westerners 
often preserve them, validate them, and pass them on to future generations, even if 
such processes need a lot of effort and energy. We should note that the Japanese 
language is easily changed and therefore it could disappear within 100 years if we 
are not conscious of the need to preserve it (McMahon  1994 ; Aitchison  2000 ). 
 Can we pass these important cultural aspects on to our children? There are 
 computer works that feature these cultural aspects, but not many media can use the 
deep structures of Japanese culture in current computer technology. Many people 
have focused only on surface Japanese culture, and regarded the Japanese culture as 
a sum of superﬁ cial Japanese expressions. However, the basic structure and thought 
of Japanese culture is universal. By extracting this content of Japanese culture, 
modeling them, and making various kinds of interactive tools from them, the media 
content is expected to deepen, which would send the unique structure and architec-
ture of Japanese culture to the world (Tosa  2010 ). 
 It is possible to apply such methods to the constructs of local or global media 
arts. Additionally, new techniques that contain Japanese and Western methods can 
be discovered. Cultural computing is thus expected to greatly advance media con-
tent in the future. 
 I felt that “Art of Zen” (Tosa et al.  2005 ), which I developed, contributes some-
thing new to the ﬁ eld of media arts. During the development process of this system, 
I felt like I was stumbling around in the dark. When the system was nearly complete 
5 Cultures, Subconscious and Creativity Software

119
and I looked back at my research, I suddenly understood that this kind of system has 
never existed before. 
 When a user approaches objects like mountains or water that represent his or her 
own Sansui picture, icons like mountains, rivers, and the moon turned into a related 
vision (for example, a river is related to the Zen riddle, “Hyonen Zu”). When he or 
she approaches a ﬂ ower, a haiku related to the ﬂ ower is displayed and is read out. 
The associative interaction of allegories and symbols related to Sansui pictures and 
the trumpet played by Toshinori Kondo 1 made a deep impression on my heart, it had 
‘quite an impact.’ It was beyond self-aware feelings or consciousness. I was wrapped 
in something larger, which made me remember my hometown and recall many 
memories. This feeling was produced by the power of analogy. Racial and historical 
memories have constructed analogies in allegories and symbols. I understood that 
this interaction of allegory and symbols expanded the association between words 
and images and created a story. During the exhibition, many spectators commented, 
“Wow! I realized that each of the interactions had its own meaning,” after seeing the 
user’s interactions. 
 Richard Dawkins, a biologist, said that when we are talking about the evolution 
of modern people, characteristics of culture are conveyed through imitation. The 
meme proposed by Dawkins ( 2006 ), is a metaphorical gene that acts as a unit for 
carrying cultural ideas, symbols or practices. He thought that meme is inherited 
through the exchange of thoughts or ideas among humans, from brain to brain. 
Conversely, present computer technologies are becoming more interactive. The 
Internet connects the world. Robots are becoming humanoid, enabling them to 
interact with people. 
 However, there is no cultural layer in technology yet, which is the reason why we 
do not feel the depth of communication, even when we are interacting with such 
systems or media. One of the missions of cultural computing is to insert a layer of 
culture that adds depth to the communications between human and computer. This 
research ﬁ eld has only just begun. The area that cultural computers affect will 
expand, taking in many artists, engineers, sociologists, and folklorists. 
5.1.3  Cultural Infrastructure 
 To explore the traditional culture of a foreign country, there has been no other real 
way except by visiting the country and ‘seeing’ it as a tourist for a short time. There 
may be too much of a language barrier when we try to see other cultures by reading 
a book. At the same time, these books are written about a speciﬁ c cultural condition, 
so people from other cultures can ﬁ nd it difﬁ cult to understand the culture. People 
say that a culture is a global entity, but it is deeply related to the mechanism of each 
1  Toshinori Kondo (born 15 December 1948) is a world famous free electric trumpeter. In addition 
to solo trumpet performance, he is well known for doing collaboration with artists in different 
areas such as painters, video artists, etc. 
5.1 Cultures from an Engineering Perspective

120
country’s political system, so there is a national barrier, as well. Of course, this 
national barrier is important in preserving the uniqueness of each culture. A simplis-
tic globalization would destroy each culture’s uniqueness and, as a result, cover the 
entire world with a simple, ‘average’ culture. 
 Then, is it possible for each culture to be able to preserve its uniqueness, behind 
a national barrier, and at the same time for us to be able to truly touch these other 
cultures and understand them? Due to the complexity of the present age, using mod-
els of cultural anthropology and structure is not enough. Cultural computing, which 
views the culture from an engineering perspective, hints at the potential of new 
communication that will make a breakthrough towards this goal. 
 The engineering perspective of a culture enables us to analyze its structure and 
quantify it. We can dismantle what makes up the culture and see its elements. In 
doing this, we can discover new structures or models from the various allegories or 
symbols of the culture and its existing history. We can change our perspective and 
see new directionality by re-editing and changing the models. As this process con-
tinues, we notice that digital technologies could play an important role in creating 
new media. This experience allows us an easier understanding of other cultures, 
which were previously difﬁ cult to understand. To determine the common structures 
between different cultures, each culture becomes included in media that people in 
various cultures can access and note similarities and differences. By these methods, 
these media can enable us to cross national barriers and understand and appreciate 
other cultures, while still keeping each culture unique. 
 What is the purpose of this? I think that through this process we are creating a 
new infrastructure for a cultural layer in computer networks. This cultural layer 
infrastructure has the potential to perform cross-cultural translations among differ-
ent cultures worldwide, which used to have difﬁ culty in understanding each other, 
through cultural computing in each country. 
 For example, language translation software (Koehn  2010 ; Wilks  2009 ) is 
grammar- based, but it does not consider hidden cultural content. This is partly why 
computer language translation software sometimes outputs misleading text. A 
smoother translation would be possible by adding a cultural translation function. 
Not only verbal information, but also multimedia information will be able to be 
translated by this cultural translation method in the future. 
 The ways of recognition, thought, expression, and action will largely change by 
extracting the formats from a structure of a speciﬁ c culture and utilizing them in the 
form of a ‘model template.’ A new culture would be created by ﬁ rst using these 
‘formats,’ then breaking the ‘formats,’ and ﬁ nally leaving the ‘formats.’ For exam-
ple, the Japanese compromise between the East and West was created by the entry 
of American culture after World War II. However, as the Americans themselves 
gradually left Japan, this mixed culture remained and became a core of pop culture 
in present-day Japan. The exchange of different cultural information will create new 
cultural information using computer networks. Designing this new, culture-based 
media leads to cultural computing, which interactively exchanges cultural informa-
tion, beyond Web 2.0 (O’Reilly  2009 ; Shelly and Frydenberg  2010 ). 
5 Cultures, Subconscious and Creativity Software

121
5.2  What Computers Are Missing 
5.2.1  Recognition of Computer Without Senses 
 We can feel various stimuli from our eyes, ears, nose, tongue, somatic senses, and 
balance senses, and we create meanings from these inputs like ‘hot,’ ‘heavy,’ and 
‘hard.’ Above those, we can recognize and express feelings like ‘happy’ and ‘sad’ 
(Damasio  2005 ; Jenkins et al.  1996 ). Using these capabilities, we can also recognize 
external information. 
 Technology for recognition of the external world from input, especially voices, 
images, or videos, has been actively studied (Duda and Hart  1998 ; Rosenthal et al. 
 1995 ). As for voices, studies have advanced quickly, because the structure of a lan-
guage is relatively apparent, so voice-recognition technology is already mature. 
Now people can generate text using voice recognition or control a car navigation 
system by voice (Sadun and Sande  2013 ), however image or video recognition are 
not yet very common, because of the variations in the external world. Conversely, 
when we have a speciﬁ c application we desire to realize, many of these are estab-
lished as rather concrete technology (for example, facial recognition functions are 
now preinstalled in new digital cameras) (Costache et al.  2006 ). As for emotions, I 
studied feeling recognition when I produced “Neuro-Baby” (Tosa et al.  1994 ; Tosa 
 1993 ). Since computers do not have senses I let it learn using a logical method that 
humans would never use. Through this process, computers have learned voice feel-
ings as if they are symbols. However, humans need to speak by following what 
computers have learned to ascertain recognition rates. I spoke with the computer 
and felt it to be an odd conversation. I tried to understand that computers are like 
robots, and that I was talking to something alive. Talking with computers for a long 
time may be boring because the conversation does not ﬂ ow well. However, technical 
research into feeling recognition by computers is actively being pursued. There are 
currently no signiﬁ cant advances in the ﬁ eld because of the uncertainty of structure 
and the changing appearance of feelings that depends on the situation, such as rela-
tionships or time and place. 
 Feelings of ‘hotness’ or ‘heaviness’ are not confusing because there are appar-
ently corresponding information about them, such as temperature and weight. 
However, there has been little research about the relationship between these feelings 
and our basic attributes, such as our temperament. In reality, this basic information 
and these processes are deeply related to cultures. They have deep direct effects to 
our higher recognition functions. Past studies considered only higher information 
processing, without observing basic information processing (Pierce  1980 ; Stone 
 2015 ). 
 As basic and higher information processes are deeply related, studies of higher 
information alone may not be enough to clarify the mechanism of emotion of feel-
ing. To complement past research results and approaches to properly analyzing cul-
ture, the advancement of research in this ﬁ eld should be accelerated. 
5.2 What Computers Are Missing

122
5.2.2  Illiterate Computers 
 What is information literacy (Lanning  2012 )? In an information society, it is the 
ability to acquire, memorize, and process information and to determine social, cul-
tural, and philosophical situations or effects of information. In the ﬁ eld of acquiring 
information, we have made great advancements led by the development of huge 
clouds of knowledge databases on the Internet and progress in search technologies, 
like Google. In the ﬁ eld of memorization of information, most of our memory 
has been kept outside of our brain and stored in various types of computers. In real-
ity, little advancement has been made regarding the problem of how to process 
information. It is true that a few research ﬁ elds are developing technology like 
language processing, translating, or data mining, but these are only individual 
developments. 
 The main problem is that developers have explored or designed technology based 
on their interests without considering the ‘meanings’ of information (Ivers  2003 ). 
What is needed is research based on a deep consideration of human consciousness: 
how and why do we process information? The information that we process daily 
must have something to do with the common knowledge of our race and cultures. 
Now, let us explore how to process culture using computers. 
5.3  Why Computers Must Move Towards Culture 
 Much research has been undertaken in the history of computer information process-
ing, which I refer to from an engineering perspective. I want to show that computers 
will converge to processing cultural information. 
5.3.1  Cybernetics 
 In the ﬁ eld of cybernetics (Wiener  1965 ; Ashby  2012 ), Gregory Bateson, who was 
a cultural anthropologist in his early career scientiﬁ cally analyzed phenomena 
through relations and patterns. He propounded that we can analyze various systems 
in the form of messages, communications, information, and feedback (Bateson 
 2002 ). Cybernetics won great attention as a general science that included ﬁ elds like 
communication, controlling, systems, and bionomics. It was actively researched, 
and the discovery of the mechanism of feedback proved to be one of the basic sys-
tems of life and was included in many systems as a basic mechanism. 
 However, because of the abstract deﬁ nition of systems and the widened range of 
subjects, little advancement as an engineering study was taken after that, even 
though the concept was solid. Nevertheless, feedback functions were a great 
 discovery in that they gave a great push towards advancement in technology like 
information engineering and control engineering. 
5 Cultures, Subconscious and Creativity Software

123
 Cybernetics and cultural computing are in some ways alike in their positions. 
Cultural computing will be a general science that covers many ﬁ elds, including 
information processing. It has an attractive methodology in which computers can 
process cultures by importing the idea of a ‘structure’ of the culture. However, at the 
same time, researchers should constantly clarify the position of their research 
because cultures are a complicated phenomenon. They should not simply label it as 
part of the ﬁ eld of cultural computing. 
5.3.2  AI 
 Research into the computing of human-level intellectual processing abilities such as 
reasoning, analogical inference, and judgment have been actively carried out with 
the aim to give computers senses. To realize human-level intellectual processing 
with computers is, in some way, akin to realizing human brains with a computer. 
This research ﬁ eld is called ‘AI’ (Russell and Norvig  2009 ; Warwick  2011 ). Initially, 
it seemed that research into AI would go well because there was an optimistic idea 
that most parts of human intellectual processes are logical and, therefore, could be 
programed. 
 It is true that the AI ﬁ eld partly succeeded. For example, computer chess  programs 
have been developed and have even been able to beat a human chess grandmaster. A 
program named ‘Expert System (Joseph and Riley  2014 )’ that replaces a part of a 
doctor’s judgment with computer output by embedding the knowledge of experts 
was developed and put into practice. 
 However, AI research slowly approached its limit. Only extremely logical pro-
cesses of human-level intellectual processes are easily programmable because 
humans have intellectual processing such as ‘commonsensical judgments,’ ‘intu-
itions,’ and ‘emotional judgments’ and they are currently impossible to compute. 
We cannot clearly say what process is running and why we can obtain a result. 
 AI researchers tried a method in which computers learned based on a database 
of actual human judgments. What became clear, however, is that real situations 
have a great deal of variation, so it was difﬁ cult to collect enough data. Moreover, 
there is considerable knowledge like ‘commonsense’ or ‘culture’ hidden within 
these situations that support the mental processes. Ultimately, AI researchers had 
underestimated humans. They had not noticed that real human intelligence used, 
in practice, a number of illogical processes such as ‘intuitions,’ ‘commonsense,’ 
or ‘culture.’ Therefore, AI researchers should be taking two different directions. 
One of these is to further study logical processes and slowly try to introduce the 
illogical processes. The other direction is to approach illogical processes such as 
‘emotions,’ ‘commonsense,’ and ‘intuition’ directly. It is clear that these pro-
cesses have a close relationship with culture. That is, cultural computing has 
potential to be a new research area complementing traditional AI research 
(Copeland  1993 ; Shanahan  1997 ).  
5.3 Why Computers Must Move Towards Culture

124
5.3.3  Artiﬁ cial Life 
 In the 1990s, artiﬁ cial life was actively researched to simulate living phenomena 
with a computer. This research duplicates the evolutionary progress of life (Adami 
 1997 ; Levy  1993 ). Indeed, this ambitious research approached the ﬁ eld of biology 
from an information-processing perspective using computers. Parts of it, like the 
genetic program that duplicated the process of a genetic process, were greatly suc-
cessful. Some results were sensational; for example, the duplication of the evolution 
process from unicellular to multicellular lives, or the duplication of the process in 
which a child slowly learns speech. Nowadays, the numbers of researchers and top-
ics have decreased. What was the problem? I think the answer is again that research-
ers simpliﬁ ed living phenomena too much. 
 Living phenomena have great variety and complexity, as well as close relation-
ships with the environments where each organism lives. It might be reckless to 
tackle this huge problem with a single algorithm called the ‘genetic algorithm.’ It is 
not strange that a trial to treat living phenomena only by computer simulations with-
out more cooperation with related ﬁ elds like biology, genetics, and earth sciences, 
would become stuck. 
 However, the history of artiﬁ cial life suggests many points to consider when we 
challenge cultural computing, as in the case of cybernetics. A ‘culture’ is also an 
extremely complex phenomenon. At the same time, it is an extremely attractive area 
for the information-processing ﬁ eld. There are several research themes that remain 
undeveloped. ultural computing ais a growing ﬁ eld awith many research themes. It 
is important to remember that cultures are extremely complex phenomena and have 
close relationships with anthropology, history, and folklore. 
5.4  Computing Culture 
5.4.1  Japanese Culture with Structures 
 Japanese culture matches computing well because it has relatively quantiﬁ able 
‘structures’: models, types, templates, modes, and styles. As we can see in Gengo 2 
by Miura Baien, 3 ‘A pair (一対)’ is not contradistinctive like positive and negative. 
2  Gengo is Baien Miura’s key philosophical works. He believed that behind every natural object 
and natural phenomenon there is ‘Jori,’ that gives groundings for the existence of these objects and 
phenomena. The concept Jori is similar to the western concept of logic. Based on this he had some 
conscious method for philosophy like modern western philosophers, he called it ‘Hankan-gouitzu’. 
According to the Jori principle he thought that we should observe natural objects from the point of 
pair-relations. Every object can be considered to be one side of a pair-relation, for example [water-
ﬁ re] or [heaven-earth]. He insisted that we cannot recognize any essence of beings without under-
standing this pair-relation. 
3  Baien Miura (1 September 1723–9 April 1789) was a Japanese philosopher of the Tokugawa era. 
Most Japanese thinkers and philosophers tried to follow philosophies established by old Chinese 
5 Cultures, Subconscious and Creativity Software

125
What is characteristic of Gengo is that two things complement each other to be one, 
like yin and yang, or the ground and the ﬁ gure. Omote-senke (表千家) 4 and ura- 
senke (裏千家), 5 duty and sentiment are also examples of ‘a pair.’ 
 After two comparative values are formed, they are classiﬁ ed by types like 
‘method (式),’ ‘rating (格),’ ‘ﬂ ow (流),’ and ‘wind (風).’ Haiku has styles of Basho 
(芭蕉) 6 or Buson (蕪村), 7 and a template of 5, 7, and 5 ﬁ gures. Under the classiﬁ ca-
tion of ‘types,’ there are stereotype, prototype, archetype, and so on. The prototype 
of a haiku is bahu (芭風: Basho style), which was made by Basho. Renga (連歌) 8 is 
the archetype haiku. Similarly, models, templates, types, and styles bring great 
advancement to human recognition, thoughts, expressions, and actions. Humans 
remember important things associatively as forms of structures, and these have been 
traditionally passed down. 
 Models are similar to matrices. Templates are similar to molds, types to forms, 
modes to modalities, and styles are similar to tastes. According to Matsuoka Seigou, 
a Japanese cultural researcher, structures in Japan are derived from katashiro (形
代). 9 Seigou says they had been important for the Japanese as being something 
philosophers such as Confucius, Laozi, Zhuanguzi, etc., whose teachings focus on the way of liv-
ing, the way of thinking, etc. and had no interest in analyzing objects or phenomenon surrounding 
people. On the other hand Baien Miura was interested in the basic structure of the nature surround-
ing people. 
4  Omotesenke (表千家 “front Sen house/family”) is the name of one of the three houses or families 
(家) that count their family founder as Sen Rikyū and are dedicated to carrying forward the Way of 
Tea developed by him. The other two are Urasenke and Mushakōjisenke. As Sen Rikyū is highly 
respected as a founder of the Way of Tea in Japan, these three families still keep their strong inﬂ u-
ence in Japanese society today. 
5  See footnote 4. 
6  Matsuo Bashō (1644–28 November 1694) was the most famous Haiku poet of the Edo period in 
Japan. During his lifetime, Bashō was recognized for his works in Renga. As Basho treated the ﬁ rst 
part of Renga independently and it became a new short poem form called Haiku, today he is rec-
ognized as the greatest master of Haiku. His poetry is internationally renowned, and in Japan many 
of his poems are reproduced on monuments and traditional sites. 
7  Yosa Buson (1716–January 17, 1784) was a Japanese poet and painter of the Edo period. Along 
with Matsuo Bashō and Kobayashi Issa, Buson is considered among the greatest poets of the Edo 
Period. Buson was born in a village near Osaka. Around the age of 20, Buson moved to Edo (now 
Tokyo) and learned poetry under the Haikai master Hayano Hajin. After Hajin died, Buson moved 
to Shimōsa Province near Edo. Following in the footsteps of his idol, Matsuo Bashō, Buson trav-
eled through the wilds of northern Japan. He published his notes from the trip in 1744. 
8  Renga (collaborative poetry) is a genre of Japanese collaborative poetry. The origin of Renga is 
Waka which consists of ﬁ ve phrases containing 5, 7, 5, 7, 7 Japanese syllables respectively. Based 
on Waka in late Heian period new type of collaborative Waka composition (called Renga) became 
popular. First form of Renga is Waka composition by two persons; former 5, 7, 5 syllables by one 
person and latter 7, 7 syllables by another. Then the form was extended so that following a Waka 
another Waka was created by different two persons and so on. 
 The opening 5, 7, 5 syllables of a Renga, called the Hokku, became the basis for the modern Haiku 
form of poetry. 
9  Katashiro is a physical object used as an emblem of the presence of a spirit in the rites of worship. 
The term also refers to an object representing the human ﬁ gure, used in rites of puriﬁ cation to 
represent the subject of the rite, in which case the subject rubs the object on his body or blows 
5.4 Computing Culture

126
 synonymous with the gods. Aratama (荒魂) and nigitama (和魂) 10 is a paired con-
cept that gods in Shinto Buddhism share. In Japan, there are some paired concepts 
that represent separate worlds. For example, this world and the other world (彼岸 
此岸), time and space, heaven and hell, ten’en chi’hou (the round sky and the square 
earth), utsu and utsutsu (absence and existence), godai (the ﬁ ve elements) and 
gogyo (Wu Xing), the spiritual and physical views of the world, and so on. 
 The are some pairs of concepts about places, for example, achi (there) and kochi 
(here), shime (しめ) and yui (ゆい), daigoku (大極) and choudou (朝堂), East and 
West jodo (浄土), yamato (大和) and kawachi (河内), a bad place (that is, hell) and 
a good place (heaven), omoya (main house) and hanare (guest house), azumaya 
(kiosk) and yorozuya (general store), etc. 
 For spirits, some pairs are material and ghost, miare (royal birth) and iware (rea-
son), raigyuo (reception by Amitabha) and Kangyo (God’s return to the shrine), 
yugen (spiritual beauty) and meihaku (clarity), kibutsuchinshi (writing feelings in 
comparison with something) and seijutsushinsho (writing feelings directly), suki 
(tasteful spirit) and mujo (absence of absolutes), marriage and divorce (縁結 and 縁
切り), yuso and mujo (有惜 and 無常), sacred and profane (ハレ and ケ: sacred–
profane dichotomy), asobi (play) and susabi (abandon), and so on. 
 For symbols, there are Iemoto (master) and ryuha (team), sights and magniﬁ cent 
scenes, kamon (family emblem) and monsho (coat of arms), katado-ru (assuming 
the ﬁ gure of something) and kizasu (to show signs of), nari (appearance) and furi 
(action), vairocana and acala, and so on. 
 Regarding trinities, there are motenasi (hospitality), shitsurai (room condition-
ing), and furumai (action), sin-gyo-so (regular, semicursive, and cursive scripts), 
jo-ha-kyu (slow, break and fast), Gautama Buddha, Amitabha, and Maitreya, yo 
(look) and shiki (method), and fu (like), yorishiro (God’s spirit) and katashiro (the 
replacement of God) and yashiro (shrine), and so on. 
 These ‘structures’ strongly affect one’s sense of recognition, literacy, and expres-
sions. Application of these structures may enable us to create a ‘media of Japanese 
culture’ on the computer, beyond superﬁ cial Japanese-content media art. 
 It is possible to create an interface with the media of Japanese culture, extracting 
the ‘structures’—the basic elements like art structure, the ﬁ gure of a spirit, the style 
of beauty—in Japanese culture with computers. By making the interface a tool for 
digital expression, editing or constructing the interactive system will be supported. 
breath upon it, thus transferring transgressions and pollutions to the object, which is later cast into 
a river or another body of water. Katashiro were also used when casting spells or curses. Most 
Katashiro seen today are made of paper, but in the past they were also made of gold, silver, iron, 
wood, rice straw or miscanthus reeds. 
10  In Japanese Shinto, Kami (god or spirit) has two faces. The aratama is the rough and violent side 
of a spirit. A Kami’s ﬁ rst appearance is as an Aratama, which must be paciﬁ ed with appropriate 
paciﬁ cation rites and worship so that the Nigitama can appear. The Nigitama is the normal state of 
the Kami, its functional side, while the Aratama appears in times of war or natural disasters. 
5 Cultures, Subconscious and Creativity Software

127
Fragile Japanese feelings, like aware (あはれ), 11 wabi-sabi, 12 and utsuroi (うつろ
い), 13 will be modeled and turned into interfaces. 
 By extracting and computing basic structures that comprise Noh or Kabuki cul-
ture, we can create an interactive system that has reasonable plots to be used in 
stories. These ‘media of Japanese culture’ are expected to be used in media-creation 
abroad and in museum events, movies, and international expositions, as well as 
inside the Japanese cultural region. They enable us to create Japanese culture mod-
els that affect the world. 
5.4.2  A Deeply Asian View of the Uncovered World 
 A foundation of Japanese culture resides in Japanese poems, also known as Waka. 14 
Japanese poems starting at Man’yoshu (万葉集) 15 were written in kanji. Though 
they have the appearance of classical Chinese, they were written with a Japanese 
word order. There are various Waka styles: Waka written in ideographical Kanji; 
Waka written in phonographic Kanji; Waka with both ideographical and phono-
graphic kanji; and Waka with no character expression. 
 However, kana characters had not yet been invented when these Waka were 
edited, so the poems used their unique notation, called Manyo-kana (万葉仮名). 16 
Poets tried to write Japanese poetry using phonographic kanji, without using any 
11  Mono no Aware is a Japanese aesthetic feeling that frequently appears in Japanese literature in 
the Heian period (794–1185). Direct translation of Mono no Aware is deep and sentimental feeling 
when looking at or listening to something. In the Heian period based on Buddhism’s teaching 
about the end of the world, such thoughts as “everything has to change” or “nothing is eternal” 
became common. The feeling of Mono no Aware is tightly connected to such a thought. 
12  Wabi-sabi is a Japanese aesthetic feeling that became apparent in the late Muromachi period and 
became shared by many Japanese throughout the Edo period. The thought such as “everything has 
to change” or “nothing is eternal” is the basis of Wabi-sabi. Based on such thought, Wabi-sabi 
emphasizes the beauty existing in something simple, old, small, and sometimes poor contrary to 
beauty in huge, gorgeous, new, and luxury objects. 
13  In Buddhism there is a basic concept that everything is not eternal, and will change and pass 
away. Utsuroi means the process of things to change and pass away. The basic attitude to accept 
Utsuroi, even to appreciate it has been core part of aesthetics of Japanese people. 
14   Waka (literally, “Japanese poem”) is a type of poetry in classical Japanese literature. In contrast 
to the Chinese style of poetry that is composed using only Chinese characters and are called 
Kanshi, Waka consists of 5 phrases each of which involves 5, 7, 5, 7, 7 Japanese syllables 
respectively. 
15  Man’yōshū is the oldest existing collection of Japanese poetry, compiled sometime during the 
Nara period. The anthology is one of the most revered of Japan’s poetic compilations. The com-
piler is today widely believed to be Ōtomo no Yakamochi. The collection contains more than 4500 
poems whose composers range from Emperor, noblemen to soldiers staying far away at the front, 
ordinary people, etc. Therefore the names of many of the poem composers are unknown. 
16  It is believed that until Kanji (Chinese characters) were introduced from China, that the Japanese 
culture did not have characters. When Kanji was imported from China around third century, ﬁ rstly 
the pronunciation of each Kanji was linked to adequate Japanese syllables to express it. Then it 
5.4 Computing Culture

128
ideographic parts. In this sense, Manyo-kana are the ﬁ rst Japanese characters  created 
by the Japanese, although they had used kanji already. 
 All characters that had been invented in ancient civilizations were ideographs. 
Hieroglyphs and sphenograms have been long disused, but kanji are still being used. 
Kanji have historical memories in themselves. Their worth is their cultural heritage, 
which is deeply rooted in Asia. Ideographs work best when they can easily be asso-
ciated with sound; this relationship between sound and image is one of the reasons 
why kanji has persisted in Japan for such a long time. 
 Kanji characters originated from geometrical, cultural backgrounds. The shape 
and structure of ideographical Kanji characters are based on these cultural statuses. 
According to several books by Shizuka Sirakawa ( 2007 ,  2012 ), the character ‘文’ 
(letter) meant a tattoo at ﬁ rst. ‘文’ is an ideograph that represents a human with a 
tattoo on his chest. This means this character has a cultural and historical back-
ground, which was formed in a region where people were tattooed. Customs related 
to the tattoo are widely spread among Paciﬁ c races, especially among Eastern Asian 
races. Kanji are also analogies that collect human associations, which can help us 
understand the Asian culture. Then, what about Western analogies? 
5.4.3  Western Visual Analogies 
 Contemporary Western analogies derived from ideographs are, for example, desk-
top metaphors of a PC, various icons of the Internet, and operation icons of Microsoft 
Ofﬁ ce. For future computing of memory recall, we can use analogies that have 
existed since the age of Plato. An analogy is a link between two different things. By 
analogizing two different things as a predicate, we can connect them. Moreover, we 
can represent the ﬁ gures with them. These are the characteristics of analogies. 
 The visual rhetoric of art will obtain richer expressions in intermedia by treating 
these analogies as the subject of recognition computing. We can obtain deeper 
understandingof nonverbal signals by using this method in ﬁ elds like image recog-
nition, which processes and recognizes visible objects with a computer. We can 
understand that cultural information is formed by crossing from the worldwide 
study of brains and consciousness to informatics and cultural ﬁ elds. 
 Gottfried Wilhelm Leibniz would have noticed that his “art of combinations 
(Dascal  2008 ),” in which experiences were represented as ideographs, was required 
for analogies in this era of instant searches. Leibniz’s Monad, which is the substance 
of something—or subject in the context of subject-verb, in other words—is pioneer-
ing a visual language tool that helps us ﬁ nd what words or images are appropriate 
in a given context, or what the best combination of words is to discover a meaning. 
If you want to know the data format of computers or the method to edit data, you 
became possible for Japanese sentences to be described as a series of Kanji characters. These Kanji 
characters are called Manyo-kana. 
5 Cultures, Subconscious and Creativity Software

129
should learn from the “art of combinations” of Leibniz. In Japan, there is a similar 
system named ‘Gengo’ (玄語) in which Baien wrote down his dichotomy of phe-
nomena based on yin and yang, I-Ching, and Confucianism, in the spirit of hankan- 
goitsu (反観合一), which combines two complementary phenomena (Fig.  5.1 ).
 Ideographic kanji characters that are used in ‘Gengo’ by Baien can be analogies 
to deepen our imagination and thinking. The predicative property of analogies have 
relations with Leibniz’s Monad and have the potential to realize parallel processing, 
which processes both global and local information. We can add visual analogies of 
cultural information to global communication by using this method. Minor media 
and intellectual content will add to their potential contexts and depth with current 
digital information. We should know how Westerners have seen Japan in history 
before we design this tool.  
5.4.4  Western View of Japan 
 Many foreigners say that the word ‘Japan’ is likened to concepts like video games, 
manga, and anime. Also they say that, without the contribution of Japan, computer 
games would not be like the current stage (Aoyama and Izushi  2003 ). 
Static
Dynamic
Universe
Spirit
Material
 Fig. 5.1   One example of “Hankan-Goitsu” ﬁ gures 
 
5.4 Computing Culture

130
 Japonisms won great popularity in Europe triggered by an international exhibi-
tion held in Paris in 1867, when Japan participated for the ﬁ rst time. Japonism was 
a long-standing movement that had continued for more than 30 years in the advanced 
countries, and was seen as a big movement similar to the Renaissance. Though the 
sense of beauty was clearly different, French impressionists in the latter half of the 
nineteenth century assimilated the Japanese Ukiyo-e (Harris  2011 ; Calza and 
Carpenter  2007 ), which had been painted by artists like Katsushika Hokusai, 17 and 
Kitagawa Utamaro. 18 Artists empathized with the asymmetry that contributed to the 
blankness of Ukiyo-e and with the Japanese spirituality that existed under fresh 
composition and bright colors. For example, Vincent van Gogh longed for the clear, 
bright coloring of Japanese art, and tried to use it in his paintings. He wrote that he 
recollected Japan’s warm beauty with the idea that they could see a small ﬂ ower on 
the ground if they wanted to paint a ﬂ ower. 
 Monet pointed out that the chromatic sensations of impressionists were changing 
to the Japanese ones, which were based on the nature-view of Ukiyo-e. Monet said 
that he himself was inﬂ uenced by the nature-view of Utagawa Hiroshige 19  in paint-
ing landscapes. He bought a large piece of land, and constructed a garden, in order 
to paint the landscape, and hired many outdoor workmen and made them build a 
Japanese arched bridge on the pond. Monet’s great work “Bridge over a Pond of 
Water Lilies” was made there in his later years. They say its horizontally long com-
position was inﬂ uenced by the effect of Japanese picture scrolls or the Japanese 
wind wall picture. 
 The American philosopher and Orientalist Ernest Fenollosa (Pound and 
Fenollosa  1979 ; Fenollosa  1999 ), whose work focused on Japanese art history that 
had played an important role in Japanese culture, highly evaluated Buddhist pic-
tures from the Heian era that were abandoned when the Haibutsu Kishaku 20 move-
ments occurred in the early Meiji era, Yamato-e (Japanese pictures) from the 
17  Katsushika Hokusai (31 October 1760–10 May 10 1849) was a Japanese artist, Ukiyo-e painter 
and printmaker of the late Edo period. Born in Edo (now Tokyo), Hokusai is best known as the 
author of the woodblock print series Thirty-six Views of Mount Fuji (Fugaku Sanjūroku-kei, 
1831), The Great Wave off Kanagawa, created during the 1820s and others. 
18  Kitagawa Utamaro (1753–October 31, 1806) was a Japanese printmaker and painter, who is 
considered one of the greatest artists of woodblock prints (Ukiyo-e). He is known especially for his 
masterfully composed studies of women, known as Bijinga. He also produced nature studies, par-
ticularly illustrated books of insects. His work reached Europe in the mid-nineteenth century and 
became very popular, especially in France. He inﬂ uenced the European Impressionists, particu-
larly with his use of partial views and his emphasis on light and shade. 
19  Hirosige (1797–12 October 1858) was a Japanese Ukiyo-e artist, and one of the last great artists 
in that tradition. Legend has it that Hiroshige determined to become a Ukiyo-e artist when he saw 
the prints of Hokusai. From then to Hokusai’s death in 1849, they were rival Ukiyo-e artists. 
20  Haibutsu Kishaku (廃仏毀釈) is a movement against Buddhism that occurred in the early Meiji 
period. Haibutsu means destroying Buddha statues and Kishaku means throwing away the 
Buddhism principle. Along with the power shift from Shogun to Emperor, there was a tendency to 
respect Shinto (Japanese original religion) and to dismiss Buddhism. Because of this for a while in 
Japan there was a movement to destroy Buddhism temples, statues, etc. During that period many 
valuable Buddhist heritage artefacts were broken or exported to foreign countries. 
5 Cultures, Subconscious and Creativity Software

131
Kamakura era, and ink and wash paintings from the Muromachi era. He introduced 
the value of Japanese arts to the wider world. Tenshin Okakura (Bharucha  2009 ), 21 
who helped the Americans put the Japanese art collection into the Boston museum, 
followed Fenollosa, and the value of Japanese culture rose within the country. 
Japanese culture has since become popular in foreign countries. 
 Today, Japanese manga and cartoon animations are very popular even outside of 
Japan. I would like to call this ‘present-day Japonism.’ The Damier Canvas and 
Monogram Canvas by Louis Vuitton were affected by the Japanese gothic taste, Art 
Nouveau, and Ichimatsu (check design) or Kamon (family emblem) designs. 22 
5.5  Visual Analogies of Kanji Connect the World 
 In Japonism, Westerners were inﬂ uenced by the natural freshness and feelings hid-
den behind their artistic logic, which overcame many problems. Not only Japanese 
cartoon animations and manga, but also Kanji as a visual letter sparks images within 
our brain. We associate a Kanji character with both the word that it means and 
images within our brain related to its ideographic characteristic (Nakamura et al. 
 2000 ). We can visually understand the broad meanings of a Japanese sentence from 
kanji and kana at a glance, showing that we visually understand the kanji, and that 
we autonomously recall the kana or alphabet. In fact, we sometimes notice that we 
remember kanji with its ‘shape,’ which shows that kanji has visual analogies. 
 There had been ideographic images within the brain from the time of Egyptian 
hieroglyphs and sphenograms in Babylon. However, those became phonograms 
used by other systems of language. Ancient Egyptian characters also turned into an 
alphabet; ‘A’ means A. ‘A’ is not ‘B.’ This phonogram is the starting point of Western 
logistics that classify phenomena. Westerners constructed Polis in the Greek era, 
formed Nomos (rules) and Oikous (house communities) and lived with a strong 
literacy that can be called left-brained. Most Westerners have considered that the 
function of the right side of the brain is only for artistic activities. However, I think 
Westerners are also looking back, based on the above-mentioned present-day 
Japonism. I have noticed that recently behaviors of Westerners and Japanese are 
becoming similar. For example, Westerners used to say that a person with a camera 
21  Tenshin Okakura (26 December 1863–2 September 1913) was a Japanese scholar who contrib-
uted to the development of arts in Japan. Outside of Japan, he is chieﬂ y remembered as the author 
of “The Book of Tea.” Although his original name was Kakuzo Okakura, in Japan he is well known 
by his poet name: Tenshin Okakura. He was invited to the Museum of Fine Arts, Boston in 1904 
and became the ﬁ rst head of the Asian art division in 1910. He is also known as one of the founders 
of the Tokyo University of the Arts. 
22  Kamon or Mon are Japanese emblems used to decorate and identify an individual or family. 
While Mon is used to refer to either an individual or family, Kamon refers speciﬁ cally to emblems 
used to identify a family. Kamon and Mon are similar to the badges and coats of arms in European 
heraldic tradition, which likewise are used to identify individuals and families. 
5.5 Visual Analogies of Kanji Connect the World

132
at a sightseeing spot should be a Japanese. However recently I meet many Westerners 
who take pictures with as little hesitation as the Japanese. What is this? 
 One of the answers might be that emotions or feelings, which have not been well 
evaluated in Western culture since the Greek-era have now moved beyond Western 
individualism and are becoming the basis of Westerners’ ways of thinking and 
behaving. The trigger might be technology. Technology brings about our innate 
nostalgia. Technology as we think of it now is as old as the invention of telephones 
or movies in the nineteenth century. Westerners listened to moral voices, watched 
the impressive images of movies, and unconsciously started to think back. I guess 
that we can deduce that telephones and movies have something to do with the rela-
tion between phonographic and ideographic characters. 
 Foreigners nowadays learn kanji by using their PC’s translation function to trans-
late roman letters to Kanji. In reality, this operation is the change from the phono-
gram to the ideograph. Kanji, which is a visual language, has both images within 
our brains like movies and the logic of phonograms. While we compare Kanji and 
Manyo-kana sentences in Man’yoshu, the impression is largely different. Kana give 
us a feeling of voice, and Kanji give us a visual impression. Kanji includes plenty of 
culture in their background. Neighboring icons have fused into a word with a new 
sense, and imaginations move ahead. 
 Torahiko Terada says in his book that the changes in movie scenes and connec-
tions of parts of Renku are alike because they are unconsciously connected (Terada 
 1996 ). To make this connection universal, we should use the ideographic and logical 
aspects of kanji. 
 The following statement is only my supposition as to the relation between cul-
tures and computers, but we can create a universal interface that connects local and 
global parts of the world, by connecting early Kanji characters that show the con-
struction of Kanji and Western metaphors or visual analogies as described above. 
There is no software to collect all of the chaotic information on the Internet, which 
is a huge accumulation system of images, icons, and texts. We have not obtained a 
key to the analogies that connect this information. However, the key is the cultural 
accumulation of ideographical images within our brains over history. These images 
have possibilities as analogies that connect Western and Eastern people using com-
puter software, by stimulating their subconscious. 
 What is important in communication between different cultures using a com-
puter is to make it interactive. To realize deeper communication, we should com-
pose cultural interactivity within software, while acknowledging how Westerners 
think of Japan. 
 The Islamic and Asian view of the world will come under review because global 
capitalism—the control of the global market by capitalist countries led by America—
magniﬁ es the negative aspects of wars and capital economics across the globe. We 
need to communicate globally without losing our underlying ethnicity. We cannot 
take our culture off as if it were clothing. The true value of cultural computing is to 
create media to properly represent these cultures to each other. 
5 Cultures, Subconscious and Creativity Software

133
 References 
 Adami C (1997) Introduction to artiﬁ cial life. Springer, Berlin 
 Aitchison J (2000) Language change: progress or decay? Cambridge University Press, Cambridge 
 Aoyama Y, Izushi H (2003) Hardware gimmick or innovation? Technological, cultural, and social 
foundations of the Japanese video game industry. Res Policy 32(3):423–444  
 Ashby WR (2012) An introduction to cybernetics. Filiquarian Legacy Publishing, Minneapolis 
 Bateson G (2002) Mind and nature: a necessary unity (advances in systems theory, complexity, and 
the human sciences. Hampton Press, New York 
 Bharucha R (2009) Another Asia: Rabindranath Tagore and Okakura Tenshin. Oxford University 
Press, Oxford  
 Calza GC, Carpenter JT (2007) Ukiyo-e. Phaidon Press, New York 
 Cook I, Miles S (2010) Beijing 2008. In: Gold J, Gold M (eds) Olympic cities: city agendas, plan-
ning and the world games. Routledge, London, pp 340–358  
 Copeland J (1993) Artiﬁ cial intelligence: a philosophical introduction. Wiley-Blackwell, Hoboken 
 Costache G, Mulryan R, Steinberg E, Corcoran P (2006) In-camera person-indexing of digital 
images. In: 2006 digest of technical paper, international conference on consumer electronics. 
IEEE, New York, pp 7–11 
 Damasio A (2005) Descartes’ error: emotion, reason, and the human brain. Penguin, New York 
 Dascal M (2008) Gottfried Wilhelm Leibniz: the art of controversies (the new synthese historical 
library). Springer, Berlin  
 Dawkins R (2006) The selﬁ sh gene. Oxford University Press, Oxford 
 Digital Content Association of Japan (2012) White paper on digital contents (in Japanese). Digital 
Content Association of Japan, Tokyo 
 Duda RO, Hart PE (1998) Pattern classiﬁ cation and scene analysis. Wiley, Hoboken 
 Fenollosa E (1999) Noh, or accomplishment: a study of the classical stage of Japan. Pelican 
Publishing, New York 
 Gaitatzes A, Christopoulos D, Roussou M (2001) Reviving the past: cultural heritage meets virtual 
reality. In: Proceedings of the 2001 conference on virtual reality, archeology, and culture heri-
tage. ACM, New York, pp 103–110 
 Hanania LR (2014) Cultural diversity in international law: the effectiveness of the UNESCO con-
vention on the protection and promotion of the diversity of cultural expressions. Routledge, 
London 
 Harris F (2011) Ukiyo-e: the art of the Japanese print. Tuttle Publishing, Vermont 
  Hu W, Pan Z, Liu X, Fang X, Shi J (2003) Digitized world heritage protection methods. Acta 
Simulata Systematica Sinica, Beijing  
 Hu J, Bartneck C, Salem B, Rauterberg M (2008) ALICE’s adventure in cultural computing. Int 
J Arts Technol 1(1/2008):102–118 
    Ivers JM (2003) Information and meaning: connecting thinking, reading, and writing. Longman, 
London 
 Jenkins JM, Oatley K, Stein N (eds) (1996) Human emotions: a reader. Wiley-Blackwell, Hoboken 
 Joseph CG, Riley GD (2014) Expert systems: principles and programming. Course Technology, 
Boston  
 Kaneko T (2012) Digital archiving printing blocks and establishing woodblock bibliography. 
Scholarly Res Commun 3(4):1–16  
 Koehn P (2010) Statistical machine translation. Cambridge University Press, Cambridge 
 Lanning S (2012) Concise guide to information literacy. Libraries Unlimited, Westport 
 Levy S (1993) Artiﬁ cial life: a report from the frontier where computers meet biology. Vintage, 
New York 
 McMahon AMS (1994) Understanding language change. Cambridge University Press, Pittsburg 
 Nakamura K, Honda M, Okada T, Hanakawa T, Toma K, Fukuyama H, Konishi J, Shibasaki (2000) 
Participation of the left posterior inferior temporal cortex in writing and mental recall of kanji 
References

134
orthographyA functional MRI study. Brain J Newrol 954–967. Oxford University Press, 
Oxford  
 O’Reilly T (2009) What is Web 2.0. O’Reilly Media, Sebastopol 
 Pierce JR (1980) An introduction to information theory: symbols, signals and noise. Dover 
Publications, New York 
 Pound E, Fenollosa E (1979) The classical Noh theatre of Japan. New Directions Publishing, 
New York 
 Rauterberg M, Hu J, Langereis G (2010) Cultural computing – how to investigate a form of uncon-
scious user experiences in mixed realities. In: Wong K, Ciancarini P, Rauterberg M, Nakatsu R 
(eds) Entertainment computing symposium 2010, IFIP advances in information and communi-
cation technology, vol 333. Springer, Berlin/New York, pp 190–197 
 Ronchi AM (2009) eCulture: cultural content in the digital age. Springer, Berlin 
 Rosenthal DF et al (eds) (1995) Computational auditory analysis, Proceedings of the IJCAI-95 
workshop. CRC Press, Boca Raton 
 Russell S, Norvig P (2009) Artiﬁ cial intelligence: a modern approach. Prentice Hall, Englewood 
Cliffs 
 Sadun E, Sande S (2013) Talking to Siri: learning the language of apple’s intelligent assistant. Que 
Publishing, Indianapolis  
 Shanahan M (1997) Solving the frame problem: a mathematical investigation of the common sense 
law of inertia. The MIT Press, Boston 
 Shelly GB, Frydenberg M (2010) Web 2.0: concepts and applications. Cengage Learning, 
Singapore  
 Shirakawa S (2007) Jitou (in Japanese). Heibonsha, Tokyo 
 Shirakawa S (2012) Joyo Jikai (in Japanese). Heibonsha, Tokyo 
 Stone JV (2015) Information theory: a tutorial introduction. Sebtel Press, Shefﬁ eld 
 Terada T (1996) The complete works of Torahiko Terada (in Japanese). Iwanami Shoten, Tokyo 
 Tosa N (1993) Neuro baby. In: SIGGRAPH’93, machine culture visual proceedings. ACM, New 
York, p 167 
 Tosa N (2010) Cultural computing – creative power integrating culture, unconsciousness and soft-
ware. In: Wong K, Ciancarini P, Rauterberg M, Nakatsu R (eds) Entertainment computing 
symposium 2010, IFIP advances in information and communication technology, vol 333. 
Springer, Berlin/New York, pp 223–232 
 Tosa N, Murakami K, Kakimoto K, Sato S (1994) Neuro-character. In: AAAI’94 Workshop, AI/A- -
life and entertainment  
 Tosa N, Matsuoka S, Ellis B, Ueda H, Nakatsu R (2005) Cultural computing with context-aware 
application: ZENetic computer. In: Entertainment computing – ICEC 2005. Lecture notes in 
computer science, vol 3711, pp 13–23  
 Warwick K (2011) Artiﬁ cial intelligence: the basics. Routledge, London 
 Wiener N (1965) Cybernetics, second edition: or the control and communication in the animal and 
the machine. The MIT Press, Boston  
 Wilks Y (2009) Machine translation: its scope and limits. Springer, Berlin 
5 Cultures, Subconscious and Creativity Software
www.allitebooks.com

