

SMART DATA PRICING

WILEY SERIES ON INFORMATION 
AND COMMUNICATION TECHNOLOGY
Series Editors: T. Russell Hsing and Vincent K. N. Lau
A complete list of the titles in this series appears at the end of this volume.

SMART DATA PRICING
Edited by
Soumya Sen, Carlee Joe-Wong, Sangtae Ha,
and Mung Chiang

Copyright ¬© 2014 by John Wiley & Sons, Inc. All rights reserved
Published by John Wiley & Sons, Inc., Hoboken, New Jersey
Published simultaneously in Canada
No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or
by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as
permitted under Section 107 or 108 of the 1976 United States Copyright Act, without either the prior
written permission of the Publisher, or authorization through payment of the appropriate per-copy fee to
the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax
(978) 750-4470, or on the web at www.copyright.com. Requests to the Publisher for permission should
be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ
07030, (201) 748-6011, fax (201) 748-6008, or online at http://www.wiley.com/go/permission.
Limit of Liability/Disclaimer of Warranty: While the publisher and author have used their best efforts in
preparing this book, they make no representations or warranties with respect to the accuracy or
completeness of the contents of this book and specifically disclaim any implied warranties of
merchantability or fitness for a particular purpose. No warranty may be created or extended by sales
representatives or written sales materials. The advice and strategies contained herein may not be suitable
for your situation. You should consult with a professional where appropriate. Neither the publisher nor
author shall be liable for any loss of profit or any other commercial damages, including but not limited to
special, incidental, consequential, or other damages.
For general information on our other products and services or for technical support, please contact our
Customer Care Department within the United States at (800) 762-2974, outside the United States at
(317) 572-3993 or fax (317) 572-4002.
Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may
not be available in electronic formats. For more information about Wiley products, visit our web site at
www.wiley.com.
Library of Congress Cataloging-in-Publication Data:
Smart data pricing / edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang
pages cm
Includes index.
ISBN 978-1-118-61166-1 (hardback)
1. Telecommunication‚ÄìPricing. 2. Resource allocation. I. Sen, Soumya, 1982-
HE7631.S57 2014
384‚Ä≤.043‚Äìdc23
2013051204
Printed in the United States of America
ISBN: 9781118611661
10 9 8 7 6 5 4 3 2 1

CONTENTS
FOREWORD
xv
PREFACE
xvi
CONTRIBUTORS
xx
I
SMART DATA PRICING IN TODAY‚ÄôS ECOSYSTEM
1
1
Will Smart Pricing Finally Take Off?
3
Andrew Odlyzko
1.1
Introduction
3
1.2
Telecom Mistakes
7
1.3
Voice and Other Missed Opportunities in Telecom
10
1.4
The Telecom Industry and Innovation
12
1.5
The Large Telecommunications Revenues
12
1.6
The High Potential for Profits in
Telecommunications
13
1.7
Telco (R)evolutions
14
1.8
Capital Intensity
16
1.9
Mysteries of Investment, Costs, Profits, and Prices
18
1.10
A Historical Vignette: Bridger Mitchell and Flat
Rates
20
1.11
Another Historical Vignette: Flat Rates for Data
24
1.12
Directions for Smart Pricing Research and
Deployment
25
1.13
Growth in Demand
26
1.14
Technology Trends
27
1.15
Conclusions
28
Acknowledgments
29
References
29
2
Customer Price Sensitivity to Broadband Service Speed:
What Are the Implications for Public Policy?
35
Victor Glass, Stela Stefanova, and Ron Dibelka
2.1
Introduction
35
2.2
Model
38
2.3
Data
39
v

vi
CONTENTS
2.4
Variable Descriptions
39
2.5
Results
41
2.6
Conclusions
44
References
45
3
Network Neutrality with Content Caching and Its Effect on
Access Pricing
47
Fatih Kocak, George Kesidis, and Serge Fdida
3.1
Introduction
47
3.2
Background
49
3.3
Two Different Eyeball ISPs
51
3.4
Three Different Congestion Points Per ISP, Fixed
Caching Factors
52
3.5
One Congestion Point Per ISP, Fixed Caching
Factors
55
3.6
Three Different Congestion Points Per ISP, Fixed
Caching Factors, Multiple Providers of One of the
Types
56
3.7
Numerical Experiments
57
3.8
Future Work
62
References
64
II
TECHNOLOGIES FOR SMART DATA PRICING
67
4
Pricing under Demand Flexibility and Predictability
69
Ozgur Dalkilic, John Tadrous, Atilla Eryilmaz, and Hesham El-Gamal
4.1
Introduction
69
4.2
Pricing Under Demand Flexibilities
71
4.2.1
The Day-Ahead Electricity Market with Flexible
Consumers
72
4.2.2
Optimal Time-Dependent Pricing under
Convexity Assumptions
77
4.2.3
Optimal Bundle Pricing under Discreteness
Assumptions
78
4.2.4
Numerical Examples and Insights
79
4.3
Pricing Under Predictable Demand
80
4.3.1
Pricing for Demand Shaping and Proactive
Download in Data Networks
83
4.3.2
Cost Minimization via Proactive Data Service
and Demand Shaping
86
4.3.3
Pricing Policies Attaining Modified
Profiles
89
References
92
5
Dual Pricing Algorithms by Wireless Network Duality for
Utility Maximization
97
Chee Wei Tan and Liang Zheng

CONTENTS
vii
5.1
Introduction
97
5.2
Utility Maximization
99
5.3
The Wireless Network Duality
103
5.3.1
Wireless Network Duality and
Algorithms
105
5.3.2
Smooth and Nonsmooth Utility
105
5.3.3
Nonsmooth Special Case:U(ùú∏) =
min
l=1,‚Ä¶,L
ùõæl
ùõΩl
106
5.3.4
Wireless Network Duality
108
5.3.5
Interference Load Minimization
112
5.3.6
Utility Maximization Algorithm
113
5.3.7
A Software Implementation
116
5.3.8
Connection between Dual Algorithm and
Pricing Function in Game Theory
117
5.4
Numerical Examples
119
5.5
Conclusion
122
References
123
6
Human Factors in Smart Data Pricing
127
Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang
6.1
Introduction
127
6.2
Methodology
128
6.2.1
Designing Systems with Users in Mind
128
6.2.2
Expert Evaluations
132
6.2.3
Conducting a Field Trial
133
6.2.4
Choosing an Evaluation Method
135
6.3
HCI Lessons from the Energy Market
135
6.4
User Psychology in Home Networks
136
6.4.1
Network Management and QoS Control
136
6.4.2
Implications of Throttling
138
6.4.3
Response to Capping
139
6.5
User Psychology in Bandwidth Pricing
140
6.5.1
Effects of Variable Pricing
140
6.5.2
Effects of Speed-Tier Pricing
141
6.5.3
Effects of Dynamic Time-Dependent
Pricing
142
6.6
Day-Ahead Dynamic TDP
143
6.7
Perspectives of Internet Ecosystem Stakeholders
144
6.7.1
Operator Perspectives
144
6.7.2
Consumer Viewpoints
145
6.7.3
Content Provider Considerations
146
6.7.4
Application Developer Concerns
147
6.7.5
Policy Evolution
147
6.8
Lessons from Day-Ahead Dynamic TDP Field
Trials
148
6.8.1
Trial Objectives
148
6.8.2
Trial Structure
148

viii
CONTENTS
6.8.3
Application User Interface
152
6.8.4
Trial Results
155
6.9
Discussions and Conclusions
162
Acknowledgments
164
References
164
III
USAGE-BASED PRICING
167
7
Quantifying the Costs of Customers for Usage-Based Pricing
169
L√°szl√≥ Gyarmati, Rade Stanojevic, Michael Sirivianos, and Nikolaos
Laoutaris
7.1
Introduction
169
7.2
The Cost of a Customer in a Network
170
7.2.1
Datasets Used in the Case Studies
171
7.3
Discrepancy, the Metric of Comparing Different
Cost-Sharing Policies
172
7.4
How Do We Compute the Costs of the Customers?
173
7.4.1
Case Study: F-Discrepancy in Backbone
Networks
175
7.5
Where Do We Meter the Traffic?
180
7.5.1
Case Study: M-Discrepancy in Backbone
Networks
181
7.6
What Is the Impact of the Diverse Costs of the
Devices?
183
7.6.1
Case Study: TCO Discrepancy in Backbone
Networks
184
7.7
Who is Liable for the Incurred Costs?
185
7.7.1
Case Study: L-Discrepancy in Backbone
Networks
188
7.8
Related Work
190
7.9
Conclusions
191
References
191
8
Usage-Based Pricing Differentiation for Communication
Networks: Incomplete Information and Limited Pricing
Choices
195
Shuqin Li and Jianwei Huang
8.1
Introduction
195
8.1.1
Related Work
197
8.2
System Model
198
8.3
Complete Price Differentiation Under Complete
Information
200
8.3.1
User‚Äôs Surplus Maximization Problem in
Stage 2
200
8.3.2
Service Provider‚Äôs Pricing and Admission
Control Problem in Stage 1
200

CONTENTS
ix
8.3.3
Properties
204
8.4
Single Pricing Scheme
205
8.4.1
Problem Formulation and Solution
205
8.4.2
Properties
206
8.5
Partial Price Differentiation Under Complete
Information
209
8.5.1
Three-Level Decomposition
210
8.5.2
Solving Level 2 and Level 3
212
8.5.3
Solving Level 1
214
8.6
Price Differentiation Under Incomplete
Information
217
8.6.1
Extensions to Partial Price Differentiation under
Incomplete Information
220
8.7
Connections with the Classical Price Differentiation
Taxonomy
220
8.8
Numerical Results
221
8.8.1
When is Price Differentiation Most
Beneficial?
221
8.8.2
What is the Best Trade-Off of Partial Price
Differentiation?
226
8.9
Conclusion
227
Appendix 8.A
228
8.A.1
Complete Price Differentiation Under Complete
Information with General Utility Functions
228
8.A.2
Proof of Proposition 8.1
231
8.A.3
Proof of Lemma 8.2
232
8.A.4
Proof of Theorem 8.4
233
8.A.5
Proof of Theorem 8.6
238
References
238
9
Telecommunication Pricing: Smart Versus Dumb Pipes
241
Atanu Lahiri
9.1
Introduction
241
9.2
Uniform Ordering
243
9.2.1
Dumb Pipe
244
9.2.2
Smart Pipe
247
9.2.3
Smart Pipe Versus Dumb Pipe
249
9.3
Nonuniform Ordering
255
9.3.1
Smart Pipe Versus Dumb Pipe Revisited
255
9.4
Conclusion
264
References
266
IV
CONTENT-BASED PRICING
267
10
Economic Models of Sponsored Content in Wireless
Networks with Uncertain Demand
269
Matthew Andrews, Ulas Ozen, Martin I. Reiman, and Qiong Wang

x
CONTENTS
10.1
Introduction
269
10.1.1
Research Questions
270
10.1.2
Previous Work
271
10.1.3
Designing Contracts Under Uncertain
Demand
272
10.1.4
The Models
273
10.2
Analyzing Sponsored Content When EUs Pay Per
Byte
276
10.2.1
Content Provider‚Äôs Problem
276
10.2.2
Service Provider‚Äôs Problem
277
10.2.3
A Pareto Analysis of the Two-Parameter
Contract
279
10.2.4
Summary of the Analysis with a Contract Price c
and Additional Revenue from End Users
280
10.2.5
Numerical Example
281
10.3
Analyzing Sponsored Content in the Case of EU
Quotas
282
10.3.1
Case 1: Sponsorship-Insensitive Transition
Probabilities
284
10.3.2
Case 2: Sponsorship-Sensitive Transition
Probabilities
285
10.4
Summary
287
References
287
11
CDN Pricing and Investment Strategies under Competition
289
Yang Song, Lixin Gao, and Arun Venkataramani
11.1
Introduction
289
11.2
Related Works
291
11.2.1
The Pricing of a Monopoly CDN
291
11.2.2
CDNs in Content Delivery Supply Chain
292
11.2.3
Compare CDN and Other Multiple-Choice
Markets
293
11.3
Background
294
11.3.1
Static Analysis
294
11.3.2
Predictive Analysis
295
11.3.3
Dynamic Analysis
296
11.3.4
Summary
300
11.4
Content Producers‚Äô CDN Selection Problem
300
11.4.1
Precise-Coverage Model
300
11.4.2
Approximate-Coverage Model
301
11.5
CDN Pricing Game Under Competition
302
11.5.1
Two-CDN Pricing Games
302
11.5.2
The n-CDN Pricing Games
307
11.6
CDN Competition Under Market Structure
Change
308
11.6.1
Assumptions
309

CONTENTS
xi
11.6.2
Market State Change Through CDN
Federation
309
11.6.3
The Dynamic CDN Game
311
11.7
Conclusion
317
Acknowledgments
318
References
318
12
Smart Pricing and Market Formation in Hybrid Networks
321
Aris M. Ouksel, Doug Lundquist, and Sid Bhattacharyya
12.1
Spectrum Shortage
321
12.2
Peer-To-Peer Networking
323
12.3
Commercial Viability
325
12.4
Self-Balancing Supply/Demand
328
12.5
Hybrid Network Model Overview
330
12.5.1
Organization
330
12.5.2
Algorithms
331
12.5.3
Hardware
331
12.5.4
Distributed Accounting
331
12.5.5
Network Security
332
12.6
Incentive Modeling
332
12.7
Flow Model
333
12.8
Prioritization Model
336
12.8.1
Divisible Incentives
337
12.8.2
Indivisible Incentives
338
12.9
Conclusion
338
References
339
13
To Tax or To Subsidize: The Economics of User-Generated
Content Platforms
341
Shaolei Ren and Mihaela van der Schaar
13.1
Introduction
341
13.2
Model
343
13.2.1
Intermediary
344
13.2.2
Content Producers
345
13.2.3
Content Viewers
346
13.3
Profit Maximization on User-Generated Content
Platforms
346
13.3.1
Definition of Equilibrium
346
13.3.2
Optimal Content Viewing
347
13.3.3
Equilibrium Content Production
350
13.3.4
Optimal Payment Rate
352
13.3.5
Overjustification Effects
356
13.4
Extension to Heterogeneous Production Costs
356
13.5
Conclusion
361
References
361

xii
CONTENTS
V
MANAGING CONTENT DELIVERY
363
14
Spare Capacity Monetization by Opportunistic Content
Scheduling
365
Bell Labs and Alcatel-Lucent
14.1
Summary
365
14.2
Background
367
14.3
The Plutus Approach
368
14.3.1
Pricing Model
371
14.4
Architecture and Design
375
14.4.1
Components
376
14.4.2
Client-Side Monitoring of Available
Capacity
382
14.5
Performance Evaluation
383
14.5.1
Network Utilization
383
14.5.2
Delay
384
14.5.3
User Experience
386
14.6
Conclusions and Future Work
387
Acknowledgments
387
References
388
15
Asynchronous Content Delivery and Pricing in Cellular
Data Networks
391
Vijay Gabale, Umamaheswari Devi, Ravi Kokku, and Shivkumar
Kalyanraman
15.1
Introduction
391
15.1.1
Surging Mobile Data Traffic and Declining
Operator Profits
391
15.1.2
Traffic Variations and Peak-Time
Congestion
392
15.1.3
Yield Management through Smart Pricing
392
15.2
User Survey
393
15.2.1
Setup and Goals
393
15.2.2
State of User QoE
394
15.2.3
Delay Tolerance
394
15.2.4
Delay Elasticity by Traffic Type
395
15.2.5
Price Sensitivity
396
15.2.6
Adoption
396
15.2.7
Pricing Interface
397
15.3
Time-Shifting Traffic
398
15.3.1
Time-Shifting Taxonomy
398
15.3.2
Comparison of the Time-Shifting
Alternatives
400
15.4
Pricing to Enable Delivery-Shifting
402
15.4.1
Computing (Price, EDT) Options
402
15.4.2
Integration with an MNO‚Äôs Infrastructure
404

CONTENTS
xiii
15.5
Simulation Results
406
15.5.1
Performance Measures
406
15.5.2
Simulation Setup
406
15.5.3
Results
408
15.6
Conclusion
411
References
412
16
Mechanisms for Quota Aware Video Adaptation
415
Jiasi Chen, Amitabha Ghosh, and Mung Chiang
16.1
Introduction
415
16.1.1
Two Conflicting Trends
415
16.1.2
Current Approaches in Practice
416
16.2
Related Work
417
16.2.1
Video Adaptation
417
16.2.2
Video Streaming Protocols
417
16.2.3
Quota Aware Video Adaptation
418
16.3
A Potential Solution: QAVA
418
16.3.1
Trading off Quality Versus Cost Versus
Volume
418
16.3.2
Incentives for Players in QAVA
Ecosystem
419
16.3.3
Design Considerations
420
16.4
QAVA System Design
421
16.4.1
A Modular Architecture Design
421
16.4.2
Module Placement
423
16.4.3
QAVA Operational Example
424
16.5
Stream Selection
425
16.5.1
Video Request, Utility, and Cost Model
425
16.5.2
Stream Selection as Knapsack Problems
427
16.5.3
Solving Finite-Horizon Markov Decision
Process
429
16.6
User and Video Profilers
430
16.6.1
Profiling User Behavior
430
16.6.2
Profiling Video Cost and Utility
432
16.7
Performance Evaluation
433
16.7.1
Experimental Setup
433
16.7.2
Comparing Stream Selection Algorithms
434
16.7.3
Single-User Examples
434
16.7.4
Multiuser Stream Selection
434
16.7.5
Sensitivity to Prediction Error
437
16.8
Conclusions
438
References
438
17
The Role of Multicast in Congestion Alleviation
441
Alan D. Young
17.1
Congestion in Cellular Networks
441

xiv
CONTENTS
17.2
Video, The Application
442
17.3
Why is Unicast not Ideal for All Video?
444
17.4
Why is Multicast Better for Video in Some
Circumstances?
445
17.5
Broadcast, Multicast, and Unicast Architectures for the
Delivery of Video
447
17.6
Future Potential Architectures Mixing Broadcast,
Multicast and Unicast
449
17.7
Conclusions
450
Reference
451
VI
PRICING IN THE CLOUD
453
18
Smart Pricing of Cloud Resources
455
Yu Xiang and Tian Lan
18.1
Data Center VM Instance Pricing
457
18.1.1
Dynamic Scheduling and Server Consolidation
for Fixed Pricing Scheme
457
18.1.2
Price Estimation for the Uniform Pricing
Scheme
458
18.2
Data Center SLA-Based Pricing
461
18.3
Data Center Time-Dependent Pricing
466
18.3.1
Electricity Cost
467
18.3.2
Workload Constraints
468
18.4
Conclusion and Future Work
474
References
474
19
Allocating and Pricing Data Center Resources with
Power-Aware Combinatorial Auctions
477
Benjamin Lubin and David C. Parkes
19.1
Introduction
477
19.1.1
Related Work
478
19.2
A Market Model of Data Center Allocation
480
19.2.1
Buyer Valuation Model
482
19.2.2
Defining The Goods in the Market
486
19.2.3
Seller Cost Model
487
19.3
Experimental Results
489
19.3.1
Scalability and Complexity
492
19.4
Going Beyond Processing and Power
493
19.5
Pricing
495
19.6
Conclusions
497
Acknowledgments
498
References
498
INDEX
501

FOREWORD
Smart phones, tablets, and other video and music streaming devices fuel an exploding
demand for network, cloud, and content services. Providers find it difficult to increase
revenue to match the investments required to address this demand. The wireless net-
works are getting stressed and the quality of service suffers. The experience of other
industries suggests that smarter pricing mechanisms might improve the matching of
resources and users and the revenue of providers, thereby increasing user welfare both
in the short term and long term. Researchers are exploring this possibility and a num-
ber of recent workshops on this topic attest to the perceived urgency of developing
effective approaches.
This collection of papers presents the analysis of the pricing of network services
and content conducted by leading researchers from industry and academia. The top-
ics include the following: the tension between the users‚Äô preference for simple tariffs
and potential benefits of more complex schemes; the users‚Äô sensitivity to quality
of service and their willingness to shift demand; economic incentives for efficient
caching and infrastructure improvements; and pricing schemes for content and for
cloud resources.
Researchers will welcome this timely and broad coverage of Smart Data Pricing
(SDP).
Jean Walrand
University of California, Berkeley, CA
xv

PREFACE
As the demand for data in both wired and wireless broadband networks continues to
grow every year, Internet Service Providers (ISPs) are increasingly turning to pric-
ing both as a congestion management tool and as a revenue generation model. This
evolution in the pricing regime is evidenced by the elimination of flat-rate plans in
favor of $10/GB or higher usage based overage fees in the United States and various
other countries in Asia and Europe. This rapid transition from unlimited data plans to
a reign of penalty-based mechanisms, including throttling, capping, and usage-based
fees, all within a span of just 4 years as witnessed in the United States is shown in
Figure 1. Consequently, Smart Data Pricing (SDP) will play a major role in the future
of mobile, broadband, and content. SDP refers to a departure from the traditional
flat-rate or byte-counting models to considering pricing as a network management
solution. Thus, SDP will impact not only end users and network operators, but will
also engage content providers, policy makers, mobile advertisers, vendors, and device
suppliers. SDP incorporates the following principles:
1. Pricing for end-user Quality of Experience (QoE) and not just linear
byte-counting: Simple policies like usage-based pricing (byte-counting)
(i) force users to pay the same amount per unit of bandwidth consumed
irrespective of the congestion levels on the network, and (ii) fail to account
for the fact that different applications have different bandwidth requirements
to attain a certain QoE for the user. SDP should try to match the price for
delivering application-specific desired QoE requirements of the user to the
ISP‚Äôs congestion cost at the time of delivery.
2. Application layer control to impact physical layer resource management:
Today‚Äôs smart devices, with their easy-to-use graphical user interfaces, can
potentially enable consumer-specified choice for access quality. Whether done
manually or in an automated mode, users‚Äô specifications of their willingness
to pay for their desired QoE of different applications can be taken in as inputs
at the APP layer and used to control PHY layer resource allocation and media
selection (e.g., WiFi offloading versus 3G). But enabling this interaction
requires consumer trials to understand how to design incentives and create
interfaces that can be effective in modifying end-user behavior.
xvi

PREFACE
xvii
Verizon to phase out 
unlimited data plans  
(May 2012)
All carriers require 
caps for iPad LTE  
(March 2012)
AT&T introduces 
$10/GB overage 
charges  
(June 2010)
Comcast moves 
towards tiered 
usage-based billing 
(May 2012)
AT&T begins 
throttling 
(April 2011)
Comcast 
introduces 
250GB caps 
(August 2008)
Verizon requires caps 
on new data plans  
(July 2011)
T-Mobile throttles 
to enforce data 
caps 
(May 2011)
Time-Warner 
Texas trial 
(June 2008)
AT&T starts throttling  
unlimited iPhone users  
(July 2011)
Verizon 
introduces shared 
data plans  
(June 2012)
AT&T caps U-verse 
to 250GB & DSL to 
150GB with 
$10/50GB overage 
(May 2011)
T-Mobile 
eliminates 
data contracts 
(March 2013)
AT&T offers 
sponsored 
data plans 
(Jan. 2014)
T-Mobile ends 
overage charges on 
existing data plans 
(April 2014)
Netflix agrees to 
pay Comcast for 
prioritized traffic 
(Feb. 2014)
FCC proposes net 
neutrality rules 
allowing paid 
Internet ‚Äúfast lanes‚Äù 
(May 2014)
Wireless 
Wireline 
Figure 1
Timeline of the evolution in pricing plans in the United States.
3. Incorporating edge devices as a part of the network management system:
Instead of only managing traffic in the network core, SDP explores ways to
make edge devices (e.g., smart mobile devices and customer-premise equip-
ments like gateways) a part of the network resource allocation and management
system. For example, instead of throttling traffic in the network core using
the policy charging and rules function (PCRF), the edge devices (e.g., home
gateways) themselves can locally regulate demand based on a user‚Äôs budget,
QoE requirements, and network load or available prices. Such measures to
push control from the network core out to end users, while preserving the
end-to-end principles of the Internet, have been gaining attention among net-
working research groups (for example, the M3I1 collaboration in Europe).
SDP can refer to (a) time/location/app/congestion dependent dynamic pricing, (b)
usage-based pricing with throttling/booster, (c) WiFi offloading/proactive caching,
(d) two-sided pricing/reverse billing/sponsored content, (e) quota-aware content dis-
tribution, (f) shared data pricing, and any combination or extension of the above. For
instance, two-sided pricing can include QoE enhancements, or it may simply refer
to content providers partially subsidizing data. SDP can benefit end users, network
operators, and content providers by improving users‚Äô Quality of Experience; lower-
ing ISP congestion and CapEx/OpEx, thus increasing their revenue/profit margin and
decreasing churn, and encouraging more consumption and ad revenue for content/app
providers. But to realize these benefits, SDP requires pricing models that capture the
interplay between technical and economic factors, as well as interfaces between net-
work providers and content & application providers; effective user interface designs;
1http://www.m3i.org/

xviii
PREFACE
field trials; and a combination of smart ideas, systematic execution, and informed
policy.
This volume of collected essays on SDP has immensely benefitted from the annual
SDP Forum, which organizes workshops to bring together industry experts, aca-
demics, and regulators for in-depth discussions on the topic. SDP 2012 was held
in Princeton, New Jersey, and the SDP 2013 and 2014 Workshops were was held in
conjunction with IEEE INFOCOM in Turin, Italy and Toronto, Canada. The work-
shops have been attended by professionals from AT&T, Verizon, Comcast, NECA,
Alcatel-Lucent, Cisco Systems, Qualcomm, Microsoft, ACS, and many other lead-
ing networking companies. It therefore comes with little surprise that several of the
chapters in this volume have been contributed by industry researchers and showcase
some cutting-edge research in this area.
The first three chapters of this book discuss SDP‚Äôs feasibility in the current Inter-
net ecosystem. The first chapter looks back on previous efforts to promote SDP and
asks whether the current market climate will be more receptive. The next chapter
approaches SDP‚Äôs feasibility from a customer perspective, using empirical data to
examine their price sensitivity. Finally, the third chapter incorporates regulatory con-
cerns by examining network neutrality in the context of content caching.
The next three chapters address SDP‚Äôs technical feasibility. The first chapter in
this section develops a pricing model that accounts for the flexibility and predictabil-
ity of customer demand. The second chapter focuses on wireless networks, showing
how pricing can be used to make wireless resource allocation more efficient. The last
chapter focuses on SDP‚Äôs interface between ISPs and users, examining how the ISP
can communicate prices to users through interfaces on their devices.
The next three chapters of the book shift to variants on usage-based pricing, a
particular form of SDP. The first chapter examines whether usage-based pricing can
in fact help ISPs by quantifying the distribution of infrastructure costs among ISP
customers. The next two chapters then turn to differentiated pricing: the first of these
develops a model for differentiated usage-based pricing, while the second examines
the benefits of non-differentiated and differentiated pricing for ISPs and end users.
Another form of SDP, content-based pricing, is discussed in the next four chapters.
The first chapter discusses a variant of usage-based or capped pricing, in which con-
tent providers subsidize the delivery of their content to end users, sponsoring users‚Äô
Internet access. The second chapter shifts the focus to content delivery networks and
the impact of competition on their pricing and investment, while the third chapter dis-
cusses the economics of a hybrid model in which content delivery can be offloaded to
a secondary P2P network during congested times. The last chapter considers the eco-
nomics of content providers, focusing on how the owners of user-generated content
platforms, e.g., social networking websites, can best monetize this content.
The next four chapters discuss technical aspects of realizing economically efficient
models of content delivery. The first chapter investigates the idea of opportunistic
content transfer, offloading traffic to times of lower congestion with a monetary dis-
count given during times of lower congestion. The next chapter considers a similar
idea, in which sessions like content transfers can be spread over time, but with prices
determined by the deadline of each session‚Äôs completion. The third chapter focuses

ACKNOWLEDGMENTS
xix
on video content, and shifts the focus away from ISPs to consider how a user might
distribute a budget for consuming videos over time. Finally, the last chapter considers
multicast technology and how it can alleviate network congestion.
The last two chapters of the book consider pricing in the cloud. The first chapter
investigates and compares three different schemes for pricing data center resources,
namely real-time instance pricing, deadline-based service level agreements, and
time-dependent pricing. The last chapter proposes using combinatorial auctions to
price and allocate resources in a data center while taking into account its electricity
constraints.
The diversity of topics explored in these book chapters reflects SDP‚Äôs broad poten-
tial impact. Indeed, SDP brings together ideas from such diverse fields as network
engineering, economics, human-computer interaction, data science, and technology
policy to answer fundamental questions about broadband pricing. Yet there remain
significant emerging themes which this book does not cover. For instance, little rig-
orous analysis has been done on shared data plans, which have recently become
mainstream in the U.S. Perhaps more significantly, ‚Äúnetwork neutrality‚Äù is emerging
as a fundamental issue, with new regulations from the FCC and Netflix‚Äôs agreement
with Comcast to pay for a separate ‚Äúfast lane‚Äù for its streaming traffic. And as more
and more devices become connected to the Internet, pricing for the Internet of Things
is becoming an important question. The emergence of these and other topics will
ensure that SDP remains an exciting and relevant research topic in the years to come.
Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang
ACKNOWLEDGMENTS
We would like to thank all of the participants of the first, second, and third Smart
Data Pricing Workshops, held respectively in Princeton, New Jersey on July 30 and
31, 2012; Turin, Italy on April 19, 2013; and Toronto, Canada on May 2, 2014. We
are also grateful to all of the contributing authors for their time and effort, as well as
our colleagues who served as reviewers for the contributions.

CONTRIBUTORS
Matthew Andrews,
Bell Labs, Alcatel-Lucent, Murray Hill, NJ
Randeep Bhatia,
Bell Labs, Alcatel-Lucent, Murray Hill, NJ
Sid Bhattacharyya,
Department of Information and Decision Sciences,
University of Illinois at Chicago, Chicago, IL
Jiasi Chen,
Princeton University, Princeton, NJ
Mung Chiang,
Princeton University, Princeton, NJ
Ozgur Dalkilic,
The Ohio State University, Columbus, OH
Umamaheswari Devi,
IBM Research, Bangalore, India
Ron Dibelka,
National Exchange Carrier Association, Inc., Whippany, NJ
Hesham El-Gamal,
The Ohio State University, Columbus, OH
Atilla Eryilmaz,
The Ohio State University, Columbus, OH
Serge Fdida,
UPMC, Paris, France
Vijay Gabale,
IBM Research, Bangalore, India
Lixin Gao,
University of Massachusetts, Amherst, MA
Amitabha Ghosh,
UtopiaCompression Corporation, Los Angeles, CA
Victor Glass,
National Exchange Carrier Association, Inc. Whippany, NJ
Bhawna Gupta,
Bell Labs, Alcatel-Lucent, Murray Hill, NJ
L√°szl√≥ Gyarmati,
Telefonica Research, Barcelona, Spain
Sangtae Ha,
University of Colorado, Boulder, CO
Jianwei Huang,
The Chinese University of Hong Kong, Hong Kong, China
Carlee Joe-Wong,
Princeton University, Princeton, NJ
Shivkumar Kalyanraman,
IBM Research, Bangalore, India
George Kesidis,
The Pennsylvania State University, University Park, State
College, PA
Fatih Kocak,
The Pennsylvania State University, University Park, State
College, PA
xx

CONTRIBUTORS
xxi
Ravi Kokku,
IBM Research, Bangalore, India
Atanu Lahiri,
University of Washington, Seattle, WA
Tian Lan,
George Washington University, Washington, DC
Nikolaos Laoutaris,
Telefonica Research, Barcelona, Spain
Shuqin Li,
Alcatel-Lucent Shanghai
Benjamin Lubin,
Boston University Boston, MA; Harvard University,
Cambridge, MA
Doug Lundquist,
Department of Information and Decision Sciences, University
of Illinois at Chicago, Chicago, IL
Andrew Odlyzko,
University of Minnesota, Minneapolis, MN
Aris M. Ouksel,
Department of Information and Decision Sciences, University of
Illinois at Chicago, Chicago, IL
Ulas Ozen,
Ozyegin University, Istanbul, Turkey
David C. Parkes,
Harvard University, Cambridge, MA
Martin I. Reiman,
Alcatel-Lucent Bell Labs
Shaolei Ren,
Florida International University, Miami, FL
Mihaela van der Schaar,
University of California, Los Angeles, Los
Angeles, CA
Soumya Sen,
Carlson School of Management, University of Minnesota,
Minneapolis, MN
Michael Sirivianos,
Cyprus University of Technology, Limassol, Cyprus
Yang Song,
University of Massachusetts, Amherst, MA
Rade Stanojevic,
Telefonica Research, Barcelona, Spain
Stela Stefanova,
National Exchange Carrier Association, Inc., Whippany, NJ
John Tadrous,
The Ohio State University, Columbus, OH
Chee Wei Tan,
City University of Hong Kong, Hong Kong, China
Arun Venkataramani,
University of Massachusetts, Amherst, MA
Qiong Wang,
University of Illinois Urbana-Champaign, Champaign, IL
Yu Xiang,
George Washington University, Washington, DC
Alan D. Young,
P & Y Associates, LLC
Liang Zheng,
City University of Hong Kong, Hong Kong, China

PART I
Smart Data Pricing in Today‚Äôs
Ecosystem


1
Will Smart Pricing Finally
Take Off?
ANDREW ODLYZKO
1.1
INTRODUCTION
Will smart pricing dominate telecommunications? We certainly do see growth
in sophisticated pricing in many areas of the economy. Congestion charges for
cars entering central business districts and ‚Äúsmart‚Äù electric meter deployments are
spreading. Airlines are even beginning to auction seat upgrades [1]. And there is no
shortage of desire for smart pricing in telecommunications. For a survey of recent
developments, see Reference 2. Many new technological developments, such as
software-defined networking (SDN), are touted as facilitating differentiated services
and differentiated pricing. The overwhelming consensus of the industry, as well as
of the research community, and of regulators, is that flat rates are irrational. Thus,
for example, in 2011, Jon Leibowitz, the then-Chairman of the US Federal Trade
Commission could not ‚Äúquite understand why something like metering hasn‚Äôt taken
off yet.‚Äù (See Reference 3 for references to this and similar recent quotes, as well as
for a summary of the arguments in favor of flat rates.)
Yet there are reasons for caution in the rush to smart pricing. After all, the mod-
ern consensus about its desirability is not new. It goes back centuries, to the days of
snail mail. Furthermore, industry has often either stumbled onto flat or almost flat
rates, or been forced into them, all against its will, and ended up benefiting. Thus,
for example, US wireless service providers have been boasting of the low per-minute
voice call revenues that reign in United States, much lower than in most of the world.
What they universally neglect to mention is that these low prices are the result of the
success of the block-pricing plan introduced by AT&T Wireless in 1998, which also
eliminated roaming and long-distance charges. This plan, the result not of a careful
study of historical precedents or the economics of communications but rather the fruit
of a desperate carrier looking for a way to gain customers, was widely derided but
proved unexpectedly popular. It forced the rest of the industry to follow suit with
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
3

4
WILL SMART PRICING FINALLY TAKE OFF?
similar plans and led to large increases in voice usage (see, e.g., the chart in Refer-
ence 4). The end result is that the United States has the world‚Äôs highest per-subscriber
voice usage, yielding those low average per-minute prices that the industry boasts of.
Probably not coincidentally, US wireless service providers are among the world‚Äôs
most profitable. This story, and others similar to it, should make one cautious about
rushing to follow the industry consensus. This is true even when such a consensus
is fortified by scholarly studies, because those tend to be even more biased toward
fine-grained pricing. The telecom industry and telecom researchers have historically
been notorious for not understanding what is in the industry‚Äôs own interests.
The traditional preoccupation with smart pricing is likely to be reinforced by the
economics of telecom. Contrary to common opinion, it is not all that capital intensive.
As is demonstrated in Section 1.8, telecom is simply not in the same category as such
large and important industries as electricity or roads when it comes to the ratio of
capital investment to revenues. Telecom is primarily about service, customer inertia,
and territorial strategic plays (where the territories may be physical or virtual).
Although the telecom industry is not very capital intensive, communications is
extremely valuable and any society is willing to pay astonishing amounts for it. As an
example, by some measures, the United States spends almost 50% more on telecom
services than it does for electricity. (See Section 1.5 for more data and references.)
Furthermore, in spite of all the complaints from the industry about its supposedly
impoverished state, there appears to be very large profits in many parts of it. As this
passage is being written in the summer of 2013, Verizon is in the process of buy-
ing out Vodafone‚Äôs 45% stake in the Verizon Wireless unit for $130 billion. This
means that the whole of Verizon Wireless is being valued at almost $300 billion. As
will be shown in Section 1.9, that is about four times the cost of replacing all the
tangible assets of that enterprise. It is also almost enough to replace the entire US
telecom infrastructure, both wireless and wired, with the latter redone in fiber. This
is anomalous by traditional standards, but then, as will be discussed in Section 1.9,
the entire economy is behaving anomalously, with very high corporate profits, low
interest rates, and low capital investment. Whether this is a temporary aberration, or
whether we are in a new economic era, remains to be seen. However, telecom is very
much in the mainstream of this historically unusual behavior, and so many traditional
yardsticks of financial performance may not apply.
While the telecom industry has often been blind to profitable opportunities, it
has always been aware that high profits are possible. However, it has usually faced
difficulties in using their favorite methods for profit extraction because of various
combinations of legal and regulatory constraints and the peculiar nature of demand
for communication services. Table 1.1 shows an approximation of current prices paid
by users for varying amounts of data from various services.
This table demonstrates the main problem faced by telecom. The most valuable
information can often be conveyed in just a few bits. Thus, for example, in the early
days of postal services, when receivers paid on delivery, information would often be
transmitted in the form of small modifications in the address. The addressee would
then scan the envelope, figure out what the message was, and refuse to accept (and
pay for) the letter.

INTRODUCTION
5
TABLE 1.1
Price per Megabyte
SMS
$1000.00
Cellular voice
1.00
Wireline voice
0.10
Residential Internet
0.01
Backbone Internet
0.0001
Practices from two centuries ago may seem irrelevant, but in fact they are very
instructive, as the basic economic issues have always been the same, even as technol-
ogy has changed drastically, cf. [5]. Thus, for example, today, we have the telecom
industry investing heavily in deep packet inspection. In the past, post offices had
employees hold letters up against burning candles to make sure that there were no
enclosures that were subject to extra fees. The basic incentive is to extract as much
value as possible, and that usually requires fine-grained pricing to achieve successful
price discrimination. But usually, in communication as well as in transportation, lim-
its are placed on what service providers are allowed to do. The net neutrality debate is
just another instance of the ancient conflict between economic efficiency and fairness
in markets [6]. Giving unfettered control of any critical service to any provider, or an
oligopoly of providers, either de jure or de facto (by allowing natural monopoly mech-
anisms to operate), is equivalent to abolishing property rights with the usual negative
impacts on innovation and efficiency. Hence, we have almost always had constraints,
such as those of common carriage. The real question is about the appropriate level of
constraints.
Public talk of capacity limits is often just a public relations measure, designed
to overcome opposition to service provider strategies. Thus, for example, in early
2013, Michael Powell, the President of the US cable industry association [and former
Chairman of the Federal Communications Commission (FCC)] admitted, contradict-
ing many earlier declarations by a variety of executives and experts, that ‚Äúcable‚Äôs
interest in usage-based pricing was not principally about network congestion, but
instead about pricing fairness‚Äù [7]. Whenever business leaders talk of ‚Äúfairness,‚Äù it is
generally safe to assume that they are really after extracting more revenues through
differential pricing. This is neither a novel nor is it nefarious. In fact, differential
pricing was and is at the core of regulatory economics, as it can be used to pro-
mote social welfare, and has been frequently mandated by governments. However,
historically, the degree of price discrimination that was allowed varied depending
on economics, with more discrimination being allowed when the costs of providing
those services have been large [8]. The question for the near future is whether mod-
ern telecom should be allowed more power to discriminate. Further, even if it is given
that power, one should consider whether it would be wise to use it. The right answer
depends on the balance between growth in demand and improvements in technology.
The main problem, past, present, and future, that is faced by telecom is that the
most valuable information usually requires just a few bits to convey. The second main
problem is that because of technological progress, transmission capacity is growing.
Thus the industry is faced with the challenge of persuading users to pay for big pipes

6
WILL SMART PRICING FINALLY TAKE OFF?
when the additional value that enlarging those pipes provides is not all that high.
(There are arguments that the value of transmission capacity, as well as that of com-
puting power and storage, should be measured on a logarithmic scale, so that going
from what is now a slow 1 Mbps link to a 1 Gbps one corresponds only to an increase
in value from 6 to 9, cf. [9].) At the moment, that additional capacity is consumed
largely by video. But the value is still dominated by the low bandwidth voice and
texting.
The general conclusion of this work, based on the study of trends in demand and
supply, is that in wireline communication, the critical issue faced by the telecom
industry is not handling overpowering exafloods of traffic, as has often been claimed,
cf. [10‚Äì12], but stimulating demand to fill the growing capacity of transmission sys-
tems [13]. The most effective way to do that is to offer flat rates and open access to
encourage innovation. To the extent that any market segmentation is needed, it is best
handled by offering flat rate services with different peak speeds. Pricing by volume of
traffic (whether using caps or other schemes) may be attractive at the moment to ser-
vice providers preoccupied with trying to protect their traditional subscription video
service revenues. However, it is an ineffective instrument that does not address any
of the issues well and, in the long run, is likely to damage not only the economy as a
whole but also the profits of service providers. Any truly ‚Äúsmart pricing‚Äù measures,
such as congestion charges, are likely to be detrimental to the industry.
These general conclusions for wired communications apply directly mainly to the
richer and more industrialized countries. Even in those, there is likely to be excep-
tional situations where the cost structure forces some ‚Äúsmart pricing‚Äù approaches. For
poor countries, the best choices along the frontier of feasible technological and busi-
ness models is likely to lean further toward ‚Äúsmart pricing.‚Äù This would be consistent
with the general observation, cf. [5], that at the consumer level, sophisticated pricing
is most appropriate for large and relatively infrequent transactions, and simple pric-
ing for small and frequent ones. This is also what we observe in the market today,
with the greatest proliferation of ‚Äúsmart pricing‚Äù in less-developed countries, where
the relative burden of telecommunications charges is higher.
In wireless communication, the optimal choice even in rich countries appears to be
different than that for wireline, because of a different balance between feasible supply
and potential demand. There have been widespread projections that wireless data traf-
fic would continue to double each year, as it had done for several years. Those are now
being disproved, as growth rates are declining (see Section 1.13). Still, those rates are
high, and there is far more traffic that are likely to use the radio path if that were fea-
sible, as wireless data traffic is under 5% of wireline. Coupled with the low value of
most of this data, and the resulting low likelihood of service providers being able to
extract large new revenues, it appears probable that the incentives for the industry
will be to constrain usage and to implement differentiated quality of service to pro-
tect the most valuable low bandwidth applications. So somewhat finer-grained pricing
is likely to prevail in this domain than in wireline. Still, the need to limit what Nick
Szabo [14] has aptly called the mental transaction costs involved in fine-grained pric-
ing, and related concerns, is likely to restrict the complexity of schemes that succeed.
The sophisticated pricing plans so beloved of researchers are likely to be confined to

TELECOM MISTAKES
7
areas such as business-to-business dealings and may be of limited applicability even
there.
However, the strong prejudice in favor of ‚Äúsmart pricing‚Äù among both industry
leaders and academic researchers guarantees that many schemes will be developed,
and quite a few will be deployed. Chances are that, as was true of many sophisticated
prioritization schemes developed for voice private branch exchanges (PBXs) or early
data switches, they will not see much use. But for those cases where they might be
used, it appears that most of current research, as well as academic instruction, is
missing some important ingredients. As is discussed in Section 1.12, it will likely be
important to explore the most effective ways to introduce noise and other impairments
into communication systems to provide differential quality of service. (On the other
hand, there will likely also be demand for methods to detect such actions.)
The next section reviews briefly some of the main fallacies that invigorate the
push for ‚Äúsmart pricing.‚Äù This is followed by a section on some missed opportunities
in telecommunications, demonstrating how this industry tends to ‚Äústumble to suc-
cess,‚Äù pursuing mistaken goals, and prospering by accident. Section 1.4 has a very
brief discussion of the reasons telecom has been so poor at innovating in services and
is likely to remain poor in the future. Section 1.5 discusses this industry‚Äôs place in the
entire economy. Section 1.6 points out that high profits have not infrequently been
obtained in this sector. Section 1.7 sketches the main changes that have taken place
in the money flows in telecommunications in recent decades. Section 1.8 demon-
strates that, contrary to general opinion, this industry is not all that capital intensive.
Section 1.9 discusses some of the puzzles of the modern economy and the degree
to which the telecom industry exhibits similar behavior. Section 1.12, cited earlier,
discusses some missing ingredients in modern research and education, should ‚Äúsmart
pricing‚Äù become widespread. Sections 1.10 and 1.11 take a historical look at some
earlier work on telecom pricing and the degree to which it reflected the prejudices
we observe today. Sections 1.13 and 1.14 then discuss the growth in the demand for
data traffic and improvements in transmission technologies and what the contrasts
are with those that for optimal pricing strategies. Finally, Section 1.15 provides the
conclusions.
1.2
TELECOM MISTAKES
Many of the basic but general issues that have a bearing on the possible adoption of
smart pricing have already been explored in the literature (see, e.g., [5, 15‚Äì17]) and so
will be touched on very lightly here. However, they do need to be mentioned, because
there are many misapprehensions about the nature of telecom and these issues often
have an important bearing on the optimal choices of pricing policies. For example,
we are constantly told that content is king. (Content is taken here to mean material
prepared by professionals for wide distribution and not, as some use it, to denote
anything in digital form.) But
Content is not king.

8
WILL SMART PRICING FINALLY TAKE OFF?
Yes, content, in the sense of material prepared by professionals for wide distribu-
tion, is important. But it is simply nowhere near as important as basic connectivity,
and the revenues of various services reflect that. This is discussed in detail in Ref-
erences 5, 18. Evidence of this fundamental fact is all around, and some of this will
show up later in this paper (e.g., in the observation that US wireless carriers have rev-
enues about three times as large as those that the cable industry derives from subscrip-
tion video). However, content has historically attracted disproportionate attention and
continues to do so today. For example, an article in the Economist [19] stated
A common saying in the industry is that Mexico‚Äôs phone sector may be about four times
more valuable than the television market, but the latter is four times as powerful.
What is especially perplexing about the centuries-old preoccupation with content
is that content is not cheap. For telecom service providers to sell content, they gener-
ally have to buy it at high prices. (And so, net of what they pay to content producers,
US cable networks appear to be getting more revenue out of Internet access and voice
services than out of carrying subscription video and all on a far smaller slice of their
transport capacity.) Back in 2005, Ed Whitacre, then the CEO of AT&T, caused a
flare-up in the net neutrality debate with his threat that he would not let Google use
his wires without payment. Strangely enough, it is not clear if anybody raised the
question as to whether his basic premise was correct, that is, in the absence of any
legal or regulatory constraint, it would be Google paying AT&T. Why should not
AT&T have to pay Google? Perhaps Whitacre was right, and Bing might have been an
acceptable substitute for Google search for AT&T customers. But perhaps not. Imag-
ine that Whitacre had said he was not going to let ESPN or HBO use AT&T‚Äôs U-Verse
wires without payment. Instead of being called evil by small groups of advocates of
an open Internet, he surely would have been called insane by almost everybody.
Because content is not king, the vast majority of papers and discussions about
net neutrality, industry structure, and related issues are of doubtful relevance. For
example, many academic papers start with the assumption that the Internet is a
two-sided market. It simply is not. Most of the values that users get from it is not
content but simple connectivity, such as being able to tell their friends and business
partners they are stuck in traffic. Compared to old communication technologies, the
Internet does provide many unique features and, in particular, allows for bridging
content and connectivity. (The main search service of Google, which provides
the bulk of that company‚Äôs revenues and profits but very little traffic, is in this
intermediate zone, as are most of the facilities of social networks that users care
about.) However, the features that matter the most are not the ones that allow content
providers to target individual consumers but the ones that allow for group formation
and for individuals or groups to become creators and distributors.
Closely allied to the myth that content is king is another extremely widespread and
extremely damaging notion, that of streaming video, [20]. However, all the evidence
suggests that
True streaming video is, and will remain, a very small fraction of traffic.

TELECOM MISTAKES
9
Video does dominate current Internet traffic by volume, but it is almost exclusively
transmitted as faster-than-real-time progressive downloads. That is the only method
that makes sense technologically. (Video conferencing is completely different, but we
now have enough experience to be able to predict safely that it will not be contributing
giant amounts of traffic.) Furthermore, this was easily predictable and was predicted
a long time ago. For example, George Gilder wrote about it two decades ago, and
he attributes the idea to Nicholas Negroponte even earlier. Although their prediction
has come true, almost everyone thinks that the floods of video they consume are
true streaming video. This skews business decisions and public policy discussions,
because networks dominated by real-time long-lived data flows of predictable size
and with tight latency constraints do indeed lend themselves to many of the pricing
and network management techniques that are so beloved by both top managers and
telecom researchers, cf. [21].
The myth of real-time streaming video is so pervasive and strong that it also affects
networking researchers. For the past decade, this author has been taking polls ask-
ing those in the audience to raise their hands if they saw any advantage at all, for
anyone, in transmitting video faster than real time. Usually, even among networking
researchers, at most, 10% have responded. The highest positive response rates were
around 40%, in a couple of groups of audiences packed with researchers working on
wireless ad-hoc networks, and who understand that one cannot count on connectiv-
ity being maintained, but can use buffers to compensate. (While one can envisage
ultra-reliable wired networks, in the wireless arena, this is simply not achievable;
there are far too many unpredictable sources of impairments.) This demonstrates that
even networking researchers do not know what is happening in today‚Äôs networks or
why it is happening.
The preoccupation with real-time streaming video leads to the constant question-
ing about the potential demand for high speed access. Who needs gigabit in the home,
is the question that is being asked, because the most that most observers can imagine
is a few streams that might possibly come to 20 Mbps each in some future high defini-
tion (HD) television (TV). This perfectly illustrates the lack of vision not just for the
future but on the present that afflicts this industry. After all, why are people buying
300 Mbps home WiFi access points if all they are after is streaming a few movies?
Yet such routers are selling, and high speed home access is also selling (when offered
at reasonable cost), because they allow for low transaction latency.
The main function of data networks is to cater to human impatience.
This is something that the computer industry, as well as many other competitive
industries, whether online search or Internet commerce, understand well. If users do
not get their web search results in a second, they go away. On the other hand, the
telecom industry has a hard time assimilating this notion. Yet, if you want to download
a 8 GB video to your portable device in less than a minute, you absolutely have to
have a gigabit link. Hence,
Overprovisioning is not a bug but a feature, as it is indispensable
to provide low transaction latency, which is the main function of data networks.

10
WILL SMART PRICING FINALLY TAKE OFF?
Once you have overengineered your network, it becomes clearer that pricing by
volume is not particularly appropriate, as it is the size and availability of the con-
nection that creates most of the value. That is also what the users perceive directly.
Generally speaking (and there are obviously exceptions, buffer bloat can lead to con-
trary experience), increased bandwidth means that things happen faster, the network
is more responsive, etc. This is something immediately perceptible to users. It does
not require them to engage in any mental transaction costs to figure out where they
are with respect to violating some volume caps, for example.
In wireline, the vision of a largely empty network dominated (initially in value, and
eventually likely also in volume) by cascades of mostly machine-to-machine transac-
tions driven by human impatience that was easy to predict a long time ago, cf. [21],
does appear to be realistic and likely inevitable. As George Gilder has said, ‚ÄúYou
waste that which is plentiful‚Äù and in most wired networks, bandwidth is plentiful.
Wireless, though, appears to be different, as will be discussed later.
1.3
VOICE AND OTHER MISSED OPPORTUNITIES IN TELECOM
Correct technological predictions are hard in general, but telecom predictions seem to
be worse when compared to other areas. Some of the many mistakes can be excused
easily. For example, the popularity of wireless had been consistently underestimated
by the industry for several decades. But this was understandable, because the service
was novel, and the high value that people had placed on mobility was not easy to
predict. (There is a saying that you cannot tell how many people will use a bridge
by counting how many swim across a river.) But others are far more surprising and
illustrate well how telecom has often ‚Äústumbled to success.‚Äù As just one example,
on an e-mail discussion list as recently as the summer of 2006, one of the top tech-
nical officers of a major US cable company insisted that the idea of taking some of
the bandwidth away from video services and employing it for Internet access was
impractical. He insisted that ‚Äú[t]he vast majority of folk in this country watch analog
tv and don‚Äôt have electronics to consume them digitally, don‚Äôt want them or can‚Äôt
afford them.‚Äù Yet today, Internet access is already, or is about to become, the main
business of the cable networks.
The most perplexing of the many mistakes that telecom has made is in neglect of
voice. Even today, voice services provide the bulk of worldwide telecom revenues, but
the industry has not been paying attention. When 3G was being prepared for deploy-
ment around the turn of the millennium, industry was touting it as an enabler of all
sorts of fancy digital ‚Äúcontent‚Äù services. But it was obvious that voice offered the
greatest profit opportunities [22], and voice has indeed been the main revenue gen-
erator for 3G. However, while the industry did benefit from this easy-to-anticipate
but unanticipated windfall, it has neglected other opportunities in voice [22]. Those
opportunities include voice messaging, and, perhaps most important, high quality
voice. Current wireless voice quality is poor, far poorer than the ‚Äútoll quality‚Äù voice
standard of wired services. (And that ‚Äútoll quality‚Äù is also poor, given what is possible

VOICE AND OTHER MISSED OPPORTUNITIES IN TELECOM
11
with modern codecs.) From this, and from the rapid expansion of wireless revenues,
the industry appears to have concluded that the public does not care about voice qual-
ity. It is far more probable that the public accepted low quality wireless voice in order
to gain mobility. But this does not mean that quality could not be sold as an added
value feature. It might have provided large additional revenues and profits in the 3G
world. There capacity was constrained, and therefore, it would have been possible
to charge extra for higher quality. As it is, HD voice, which is part of the plan for
long-term evolution (LTE), is likely to just become a standard service, as its resource
requirements are low compared to the capacity of the new system.
It is impossible to prove that high quality voice, if deployed and marketed prop-
erly, would have been a great success. Soon we may obtain some indication from the
public‚Äôs reaction to HD voice in LTE. But even before that, there were a variety of
reasons for believing that voice was promising, including the success of Integrated
Digital Enhanced Network (iDEN) with its simple push-to-talk feature. Human cul-
ture is primarily an oral one, and we have the astonishing success of the telephone
to look back to, which surprised many observers by attracting far more usage and
spending than postal services and the telegraph.
Those who denigrate voice can point to data such as that of Table 1.2. It shows
steady level of voice traffic on US wireless networks (based on the data from Refer-
ence 23), which represents a decline in voice usage on a per-user basis, because the
number of subscriptions has been growing during the period covered by this table. It
has been surmised that this decline was due to usage migrating from voice to texting.
That may very well be true, but it does not necessarily mean voice is unimportant.
Texting has major advantages (in particular, being asynchronous, and thus less intru-
sive than voice), and the phenomenon shown in this table may be an indicator of a
substantial opportunity in voice messaging, one that possibly could have generated
good revenues in the restricted 3G environment.
Moving forward, the opportunity to gain additional revenues with HD voice
appears to be gone, but voice should not be neglected, as it is right now, in a variety
of services. Furthermore, it appears that in the development of video services, the
industry is neglecting social communication in the traditional preoccupation with
content.
TABLE 1.2
Voice to Text Substitution (US)
Year
Voice Minutes billions
Texts billions
2005
1495
81
2006
1798
159
2007
2119
363
2008
2203
1005
2009
2275
1563
2010
2241
2052
2011
2296
2304
2012
2300
2190

12
WILL SMART PRICING FINALLY TAKE OFF?
1.4
THE TELECOM INDUSTRY AND INNOVATION
The telecom industry has repeatedly shown that it can perform well in increasing
transmission capacity. It has also shown itself to be miserably poor at inventing new
services. This may very well be the result of a basic cultural mismatch. The basic mis-
sion of telecom carriers is to provide ubiquitous connectivity. This is not an easy task,
especially because it involves being able to respond to massive disasters, natural or
man-made. Most likely, the skills, mindset, and the organization that can accomplish
this are simply not tuned to anticipating what the capricious public will want. Even
when very smart people with innovative ideas join such organizations, their initia-
tives tend to be blocked. From this perspective, it would be best, both for the society
and for their shareholders, if telcos stuck to their expertise, which is that of provid-
ing ‚Äúdumb pipes.‚Äù Unfortunately, that is not likely to happen, as their managers (and
shareholders) dream of ‚Äúcontent‚Äù and other glamorous futures.
1.5
THE LARGE TELECOMMUNICATIONS REVENUES
Measuring revenues of the telecommunications sector is not simple. (For example,
should one count the home WiFi access points people buy or the cost of the WiFi
equipment in a personnel computer (PC) or tablet?) Even concentrating just on the
revenues of service providers presents serious problems, as various bundles mix com-
munications with content. However, any reasonable methodology shows that telecom
attracts very large revenues. Here we cite some figures from Reference 24, which has
extensive statistics (and discussion) based on data up to the year 2011. A very attrac-
tive feature is that those statistics cover all the advanced industrialized nations over
about two decades and thus provide interesting international comparisons. (It should
be mentioned that other sources sometimes show different estimates. For example, for
2011, Table 3.4 of Reference 24 shows US wireless telecom revenues of $210 billion,
while CTIA, the industry association, computes it at $170 billion for that year.) In
that year, telecom revenues inside the Organisation for Economic Co-operation and
Development (OECD) countries came to $1.35 trillion, with United States accounting
for $526 billion (others sometimes cite figures as low as $350 billion for the United
States). Hence, it seems safe to estimate worldwide telecom revenues in 2011 as being
close to $2 trillion. About half of the revenues (for OECD and, therefore, likely for
the whole world) comes from wireless.
For comparison, worldwide advertising spending for 2013 was projected to come
to $518 billion, which was only around a quarter of telecom revenues [25]. (In the
United States alone, advertising is more significant, as at $172 billion it comes close
to a third of telecom revenues.) As only about $100 billion of advertising goes into
online forms, there is still plenty of room for Facebook, Google, and other companies
to grow their advertising businesses. But there is no way that the telecom business
can be supported by anything in its present size by ads alone.
Yet another interesting comparison (relevant to later discussions of capital
intensity) is with the electric power industry. In the United States, total revenues

THE HIGH POTENTIAL FOR PROFITS IN TELECOMMUNICATIONS
13
TABLE 1.3
US Wireless Industry Statistics
Revenues
Capex
Capex/
Year
($ billions)
($ billions)
Revenues
2004
102.1
27.9
27.3%
2005
113.5
25.2
22.2
2006
125.5
24.4
19.4
2007
138.9
21.1
15.2
2008
148.1
20.2
13.6
2009
152.6
20.4
13.3
2010
159.9
24.9
15.6
2011
169.8
25.3
14.9
2012
185.0
30.1
16.3
from electricity sales from end users, residential as well as commercial, came to $364
billion in 2012 (based on the statistics from the US Energy Information Administra-
tion). Of this amount, something like a third went to pay for fuel; so, the total amount
this industry had to cover for maintenance and nonfuel operations, and provide for
profits and interest was only about half of what the telecom industry received.
Yet another interesting comparison is with Google. In 2012, its worldwide rev-
enues came to just about $50 billion. Its growth and profit rates were far higher than
that for most telecom service providers, but still, it commanded just 2.5% of the tele-
com revenue stream. So, telcos will not get rich by squeezing Google alone. (Even
squeezing Microsoft, with worldwide revenues of about $80 billion per year, would
be of limited help.)
A few other figures are interesting. Some key statistics of the US wireless industry,
drawn from Reference 23, are presented in Table 1.3.
Thus from 2004 to 2011, the cellular industry increased its revenues by 66%. The
US cable industry increased its revenues during that period from $60.0 billion to
$97.6 billion, or 63% [26]. However, residential video grew just from $41.8 billion
to $56.9 billion, or 36%, and the bulk of the growth came from the ‚Äúother‚Äù category
(dominated by voice and Internet access), which went from $18.2 billion to $40.7
billion, a growth rate of 124%. Content may have all the glamor but this is not where
the main action is.
1.6
THE HIGH POTENTIAL FOR PROFITS
IN TELECOMMUNICATIONS
The telecom industry has often earned very high profits. For example, the British Post
Office had an extraordinarily high net profit margin of 68% in 1839, on the eve of the
Penny Post reform [5]. (This was a conscious move to tax first-class letters. It served
primarily as just another tax to help pay for the general government expenses, and
secondarily as a subsidy for the ‚Äúcontent‚Äù inside newspapers, which were carried for
free.) More recently, over the past few years, Carlos Slim Hel√∫ has been ranked as the

14
WILL SMART PRICING FINALLY TAKE OFF?
richest person in the world. This resulted largely from the splendid profits of Telmex
and Telcel, which still enjoy dominant positions in Mexican communications and, by
most evaluations, manage to keep prices high and penetration of advanced services
low in a poor country.
Monopolies have at times been very innovative and have worked to lower costs
as well as promote usage. The examples of the pre-1840 British Post Office and of
Mexican telecom industry today (as well as many others, including many govern-
ments in recent times which milked the telecom sector to support other activities)
suggest that in telecom, the incentives may not always point in that direction. Instead,
short-term profit maximization can often be achieved by raising prices and limiting
usage. Advocates of the Penny Post reform in Britain, not infrequently, promised that
the increase in business from the new, lower and simpler, postage rates would com-
pensate for decreased revenue per letter. This did not happen, and the profits from
this service declined drastically. Yet, no serious attempts to go back were made, as
the reform was wildly popular, both for lowering the costs of communication and for
the simplicity it brought, with the complex system of distance-dependent tariffs and
limitations to a single sheet dispensed with.
On the other hand, the Penny Post reform did lead to a switch from a regime of
static revenues to one of rapid growth. This is a phenomenon that has occurred a num-
ber of times when prices were simplified and lowered, a phenomenon that typically
does not fit the economic models used to support ‚Äúsmart pricing,‚Äù which tend to be
static. It took a quarter century, but eventually British Post Office profits exceeded
those attained before the Penny Post reform [5].
1.7
TELCO (R)EVOLUTIONS
The historical pattern, going back centuries, has been for telecommunications to grow
faster than the economy as a whole [5]. That applied also at the end of the twentieth
century. Among the OECD countries, telecommunications revenue as a fraction of
gross domestic product (GDP) increased from 2.13% in 1985 and 2.36% in 1995 to
3.58% in 2001 (Table 3.2 on p. 77 of Reference 24). That was the high point, though,
and over the past few years, it has been close to 3%. One of the contemporary justifi-
cations offered for the Internet bubble was that the creation of the Internet, allowing
interconnection of the growing number of computers, would yield dramatic produc-
tivity improvements, and this would stimulate increased spending on telecom. Some
analysts predicted that the fraction of GDP going to this sector would double. It did
for some countries (Korea went from 2.05% in 1990 to 4.70% in 2002 and was at
4.36% in 2011), but overall the growth has been far more modest. The United States
went from 2.71% in 1995 to 4.10% in 2001 and then down to 3.51% in 2011. Thus it
appears that modern economies are only willing to expand around 3% of their output
on telecommunications.
What is especially intriguing is that some countries that are not just rich, but
have excellent telecom infrastructures, manage to spend only modest amounts on that
industry. There are some outliers (Luxembourg and Norway, in particular, with 1.2%

TELCO (R)EVOLUTIONS
15
of GDP going into telecom) that can be disregarded, because they have very high
incomes per capita, so that looking at fractions of GDP conceals substantial total
spending. However, Finland at 2.58% and Sweden at 1.51% (both for 2011) provide
intriguing examples that deserve deeper investigations.
In addition to overall growth, there have been large additional changes within the
industry. The most obvious one is the rise of wireless. In terms of the number of
people served, and the revenues and profits, it dwarfs the Internet. (It was also built
primarily on the value of the low bandwidth voice and messaging services, and until
recently, the contribution of content to this growth has been negligible.) According to
statistics in Reference 24 (Table 3.4), mobile revenues accounted for 47.8% of total
telecom revenues in the OECD countries in 2011, 39.9% in the United States, and
a record high of 84.4% in Japan. (This figure for Japan is suspiciously high, as it is
hard to imagine how that country could maintain and expand its wired infrastructure
on just 15.6% of telco revenues that came to 2.85% of GDP in 2011. According to
Table 4.1.12 in Reference 24, in June 2012 Japan had almost half of the OECD‚Äôs
fiber connections, with 65% of its broadband subscribers on fiber.) Thus the share of
GDP that goes to wireline has been decreasing. It appears that wired services survived
largely because of a collapse in most of their costs.
In the US setting, a rough rule of thumb a couple of decades ago, before the rise of
the Internet, was that access, switching, and long distance each accounted for about
one-third of the total cost of the phone system. Today, only access is significant. This
can be seen by looking at financials of two prominent companies. Level 3, especially
after its absorption of Global Crossing, is universally regarded as the largest Tier-1
backbone carrier. Its share of world Internet traffic has been estimated at 10‚Äì20%
[partially depending on how one counts its relatively new content delivery network
(CDN) business]. Yet its revenues for 2012 were only $6.4 billion. In the worldwide
telecom industry with revenues of $2 trillion (or even in the wireline sector of that
industry with revenues of $1 trillion), this is extremely small. This demonstrates that
long distance transport has become very inexpensive.
The other prominent company is Akamai, the largest CDN company. It has at var-
ious times claimed to deliver up to 20% of the world Internet traffic. But its revenues
in 2012 were just $1.4 billion. Thus switching (of which Akamai has to do a lot) has
also become inexpensive.
The same conclusions about the relatively low significance of long-distance trans-
mission and switching in modern telecom can also be reached by looking at prices for
Internet transit (in which large customers, whether Internet Service Providers (ISPs)
or businesses or universities, pay for access to the Internet) or for CDN services. At
current CDN prices for about $0.01‚Äì$0.02 per gigabyte (in large volumes, several
petabytes per month), the whole volume of world Internet traffic, still under 50,000
PB per month in mid-2013, would cost only $6‚Äì12 billion per year to deliver.
The collapse in costs of switching and transport is what has led to the transfor-
mation of the effective architecture of the Internet documented in References 27, 28.
(The excess fiber buildout of the Internet bubble was also an enabler of this trans-
formation.) Tier-1 carriers such as Level 3 have become much less significant, as
lower ranked ISPs have been interconnecting, and large content providers have been

16
WILL SMART PRICING FINALLY TAKE OFF?
building out their own long-distance networks that allow them to reach the ISPs at
the edges.
Various other changes have taken place, often ones that appear not to have
been documented. For example, at least in the United States, businesses used to
provide a disproportionate fraction of telecom revenues through a conscious and
government-sanctioned price discrimination policy. That price discrimination has
disappeared, or even reversed, as enterprises are able to obtain advantageous deals
in many cases.
Several conclusions appear inescapable when one considers the figures cited ear-
lier. One is that with practically all costs coming from the access piece, that is, (for
wired services) installing and maintaining the wire to the end user, the marginal costs
of carrying extra traffic are close to negligible. Hence, charging according to volume
of traffic cannot easily be justified on the basis of costs.
An even more fundamental implication of the new cost structure is for network
engineering and management. An important goal of much of telecom research has
been to devise ways to increase the engineering efficiency of the system. We now have
practical applications where this was achieved [29, 30]. However, there the high uti-
lization occurred in controlled environments, with high volumes of predictable traffic,
and with highly trained professional managing the network. (Something similar has
happened to the backbone of the public Internet. The low utilizations that prevailed
in the late 1990s, cf. [21], have been increased in many, perhaps most, networks,
although there are no publicly available statistics on the subject. This was a result of
more attention paid to traffic engineering, as well as slower rates of traffic growth, and
slower progress in available transmission technologies.) However, on a global scale,
and from the perspective of the welfare of the entire system, any efficiency gains at
the core have to be balanced against the costs at the edges. Given the imbalance we
have, with edge costs dwarfing those at the core, it makes sense to overprovision the
core to an absurd degree in order to keep things simple (and thus inexpensive) for
the users at the edges. But of course optimizations are done locally, not globally, so
the temptation is always to introduce something more clever that ends up hurting the
system.
The final point is that the collapse of costs means that even with a diminished flow
of funding for the wireline sector, it is possible to build high capacity networks. The
big question is whether one can induce incumbent service providers to do so.
1.8
CAPITAL INTENSITY
The telecom industry frequently boasts of its high capital investments. It is also widely
accepted that this industry is characterized by very high fixed capital commitments.
But neither of these notions is true. For examples of truly capital intensive businesses,
one needs to look at industries such as electric power, railroads, or highways.
In the OECD countries, telecom investment as fraction of revenues was 13.9%
in 2011 (Table 3.8 in Reference 24). US wireless service providers have also been
investing about 15% of their revenues in recent years, as is shown by Table 1.3. This

CAPITAL INTENSITY
17
has been typical also for the wireline telephone industry for the past half a century at
least, with the exception of the Internet bubble years. Then investment spiked up to
27.2% of revenues for OECD as a whole. Similarly, the US cellular industry invested
close to 30% of its revenues in the early 2000s, during its rapid growth phase. But
now it is down to the traditional telco level of about 15%. That is not very high by
the standards of industries that are really capital intensive.
A 2006 estimate of what is needed to maintain US highways (not just the interstate
system, but all major highways, but excluding local streets) at about their then level of
service called for spending $223.4 billion in 2013 (Table 2.1 of Reference 31). Of this
amount, $125.1 billion was to be for capital expenditures (with 40% of that for addi-
tional capacity) and $98.4 billion for operations and maintenance (ordinary repairs,
snow removal, etc.). Actual expenditures have fallen short of these desiderata, but the
main point is that transportation experts estimated that a healthy state of their industry
required devoting 56% of the total annual expenditures to capital investments.
A good way to compare capital intensity of different industries is to look at replace-
ment costs as compared to annual revenues. In 1913, US railroads had book value of
$16.6 billion and annual revenues of $3.2 billion (in current dollars) [32]. Thus it
would have taken 5 years of revenue to pay for the investment that went into creat-
ing that network. This comparison has to be treated with caution, in that the book
value had a lot of what was then called water in it, and so was overstated. On the
other hand, book value was also understated, in that it was based on historical costs,
and a brand new replacement of various lines, with the need to tear down buildings
in cities that had become densely populated in the meantime, would have cost far
more.
US electric power industry had revenues of $364 billion in 2012, as was mentioned
before, and of this something close to a third was accounted for by fossil fuel pur-
chases. Hence, a fairer comparison to telecom, where most of the ‚Äúfuel‚Äù that provides
value is generated by users, is closer to $250 billion, or half of telecom revenues. Yet
the book value of the US electric power industry is around $1 trillion. Replacement
cost is likely to be far higher, as the NIMBY (‚Äúnot in my backyard‚Äù) opposition, envi-
ronmental concerns and the like have driven costs of construction very high. A typical
example is presented by nuclear power plants. Until recently, the United States had
104 operational nuclear reactors that provided about 20% of the nation‚Äôs electricity.
While there have been promises of novel designs for nuclear reactors that would be
both safe and inexpensive to build, so far none have shown to satisfy both criteria,
and current estimates of building new ones are on the order of $5‚Äì10 billion each.
Hence, just replacing existing US reactors would cost $500‚Äì1000 billion.
Compared to roads, railroads, or the electric power industry, telecom is not very
capital intensive. Just 1 year of the OECD estimate of $526 billion telecom revenue
for the United States would suffice to provide a brand new infrastructure, with fiber to
almost every house or business. For example, financial analysts estimate that wiring
up from scratch every home in Kansas City with fiber would cost about $1200 per
household [33]. At that rate, every one of the roughly 140 million households and
business establishments could be covered for just $170 billion. Of course, not every
place is as easy to operate as Kansas City, but if we exclude some small proportion of

18
WILL SMART PRICING FINALLY TAKE OFF?
the nation (and the debates are whether this is 3%, 5%, or 10%), we could accomplish
a complete rewiring for under $200 billion.
In wireless, industry statistics show that cumulative capital investment, from the
start of service three decades ago, came to $365 billion by the end of 2012 [23]. Much
of that investment has of course been written off, as old equipment gets replaced. So
to replace everything (and it is far easier to replace telecom installations, even cell
towers, than it is to replace electric power plants) would probably not cost more than
half of the cumulative total, or about $180 billion. But just to be safe, let us assume
it would take $240 billion.
When we add this up, we find that a modern telecom infrastructure for the United
State, with fiber to almost every premise, would not cost more than $450 billion,
which is well under 1 year‚Äôs annual revenue. But there is no sign of willingness from
the industry to spend that kind of money, even though Verizon is willing to pay $130
billion to buy out Vodafone‚Äôs share of Verizon Wireless.
Hence, we can indeed conclude that modern telecom is less about high capital
investments and far more a game of territorial control, strategic alliances, services,
and marketing.
1.9
MYSTERIES OF INVESTMENT, COSTS, PROFITS,
AND PRICES
The relatively low capital intensity of telecommunications has to be placed in a
proper context. Industrialized countries in general have been reducing their capital
investments. For example, in 2012, US investment came to only 16.2% of GDP, as
compared to about 20% for most of the 1980s and 1990s [34]. Some sources put
US fixed capital formation rate even lower. For example, the World Bank reports
US investments at 20% of GDP as recently as 2006 but down to 14% in 2010 and
15% in 2011 [35]. (In contrast, China‚Äôs capital investments came to 46.1% of GDP
in 2012 [34].)
The low capital investments in the rich economies is one of the major modern
puzzles. Another one is the very high level of profits at the same time when interest
rates are very low. (This phenomenon, as well as the historically abnormally high
fraction of profits going to the finance sector, predates the crash of 2008 and the
resulting action by monetary authorities to drive down interest rates.) Why do not
entrepreneurs take advantage of those record low bond rates and compete away
those abnormally high profits? (An interesting perspective is that in the nineteenth
century, it was taken for granted that, just as basic economic logic would predict, low
interest rates go together with low corporate profits. It is only in modern times that
the mantra of low interest rates boosting profits has become dominant.) That would
reduce the high unemployment and increase growth rates. Yet, that is not happening,
showing that the normal dynamics of capitalism are not operating the way theory
and historical norms predict.
One worry is that a substantial part of the apparently high profits is an accounting
mirage. After all, if profits can be moved around the world to escape all taxmen, so

MYSTERIES OF INVESTMENT, COSTS, PROFITS, AND PRICES
19
that even Starbucks in the United Kingdom shows up as not making any profits, while
the parent company is thriving, how far can one trust any of these figures? But even
if this is a factor, other statistics, such as the record lows of GDP going for wages,
still present a conundrum.
An illustration of the these modern financial puzzles is provided by the valuation
of Verizon Wireless. At the price of $130 billion for the 45% share owned by Voda-
fone, the entire business is valued at almost $300 billion. Yet, based on the capital
investment figures for the US wireless industry cited in Section 1.8, the assets of this
service provider could be replaced for something like $80 billion, a quarter of the mar-
ket value. Traditionally, the Tobin Q (the ratio of market value to replacement cost)
has been around 1 for most industries, and recently has been around 2. For wireless
to be at twice, even the elevated level found elsewhere is remarkable. It likely reflects
the inertia of the system. The limited radio spectrum, multi-year contracts, and the
like keep this sector locked up.
Yet another puzzle is the claim that building out fiber networks to the home is
impossibly expensive. Yet, at the cost of $1500 per household (in excess of the $1200
estimate of Reference 33 for the Google project in Kansas City, were it to reach every
household), and at a cost of a capital of 8% (which we are told is an impossible target
for state and municipal pension funds to reach), this would cost only $10 per house
per month. The problem is that managers and their shareholders expect much higher
rates of return than 8% per year. One of the paradoxes is that the same observers
who claim that pension funds cannot hope to earn 8% annually are also predicting
continuation of much higher corporate profit rates.
Associated with the puzzle of high profits and low interest rates is the decreased
relation of visible costs relevant to the ostensible provision of goods and services to
the prices and profits we see in the marketplace. Thus, for example, a recent investiga-
tion by a US Senate committee found that among 30 for-profit colleges, ‚Äúan average of
22.4 percent of revenue went to marketing and recruiting, 19.4 percent to profits and
17.7 percent to instruction‚Äù [36]. The American for-profit higher education industry
might be thought of as an outlier, in that its real business could be regarded as more
to find naive and educationally unqualified people who will sign up for student loans
and less to provide real education and training. However, it is not all that unusual
(and it is not certain just how high the instructional spending is in the nonprofit edu-
cational sector). Consider the pharmaceutical sector. The high cost of research and
development (R&D) there is supposed to be driving the economics of this industry.
Yet, the statistics for the 19 largest pharmaceutical and biotech companies in the world
showed that of their health care revenues of $498 billion, $71 billion went for R&D,
$110 billion for profits (a mixture of figures for 2006 and 2008 from Reference 37),
and the bulk for various other expenses.
Similarly, surprising statistics occur in telecom. A recent financial analyst report
estimated that for Sprint and T-Mobile, the costs of running the network in 2012
came to 31.1% and 26.7%, respectively, while the costs of acquiring new customers
(just selling and marketing expenses, and handset subsidies, but excluding overhead
expenses, and resources devoted to retaining current customers) were 26.6% and
22.1%, respectively [38].

20
WILL SMART PRICING FINALLY TAKE OFF?
Statistics such as those mentioned above demonstrate that the focus in our modern
world is on seizing strategic bottlenecks in the economy and squeezing high prof-
its out of them with as little investment as possible. Apple is an example of having
achieved outstanding success at this (and so is Google). Apple‚Äôs own R&D expendi-
tures are extraordinarily low for what is a shining light for technical innovation (much
less than half of Nokia‚Äôs R&D spending in 2010, e.g., cf. [39]). Most of the R&D that
makes Apple products attractive is performed by suppliers who have to accept very
modest profits. More than that, the key advantage that Apple now has is the plethora
of apps for its devices, which have been built largely by independent suppliers. These
app developers received $6.5 billion over 4 years [40], but there are about 300,000
of these developers, so the average payout has been very modest. On the other hand,
Apple has been earning more than twice in profits each quarter as much as all the app
developers earned in revenue in 4 years ($13.1 billion in the fourth quarter of 2012).
It is noteworthy that initially Apple had a closed app system, and it achieved suc-
cess by opening it up to outside developers, but keeping tight control.
The conclusion of this discussion is that modern economy is full of paradoxes
and does not fit the traditional model of how capitalism is supposed to function. But
in any event, it appears that service providers are reluctant to invest much but are
anxious to obtain high profits. Thus the drive for ‚Äúsmart pricing‚Äù is natural. On the
other hand, the low marginal costs of handling actual traffic means that there is a lot
of flexibility in pricing. Hence, user preferences can play a substantial role, no matter
what management‚Äôs favorite models tell them to do.
1.10
A HISTORICAL VIGNETTE: BRIDGER MITCHELL
AND FLAT RATES
In evaluating prospects for various pricing plans, it is useful to take a historical view,
especially because this is almost never done. For instance, modern arguments in favor
of ‚Äúsmart pricing‚Äù for data networks are nowhere near as strong as those present a
century ago for the voice telephone network. In those days, the industry faced high
marginal costs (primarily those of the human operators involved in setting up calls), so
the case for charging for calls was overwhelming in the standard model the industry
used. Arguments can be made that moving to usage-based pricing was instrumen-
tal in promoting the spread of telephony in large cities, cf. [41]. However, what is
most remarkable is that flat rates persisted in most of the United States. It does not
appear that the industry ever tried to understand how it happened, or how they were
prospering with the supposedly irrational and ruinous flat pricing model.
An excellent example of the strength of the ‚Äúsmart pricing‚Äù dogma is offered
by an article by Bridger Mitchell from 1978 on charging for local voice calls [42].
It was based on an earlier and more extensive Rand report issued 2 years earlier,
which acknowledged extensive comments and suggestions from numerous other
researchers in the field, and was published in one of the most prestigious journals in
economics. Hence, it can be taken as representing the consensus of the established
telecom economics community of that time.

A HISTORICAL VIGNETTE: BRIDGER MITCHELL AND FLAT RATES
21
Unlike most papers and books in this area, Mitchell did not use derogatory terms
for flat rates. However, a deep-seated bias against them pervades the paper. There is
also a very obvious ignorance of their effects. Aside from the savings on the costs of
the measurement and billing system, there is no hint that flat rates are advantageous
for anyone, and it is hard not to draw impression from the paper that they are just a
cancerous sore on the body politic and ought to be eliminated as soon as possible.
While Mitchell did mention that ‚Äúmost telephone subscribers prefer flat rates,‚Äù that
is as far as he went. Nowhere did he mention the experiments that showed that vast
majorities of people who participated in the AT&T experiments (and later in exper-
iments at GTE) and were offered a choice continued with flat rates, even though it
cost them more than switching to what Mitchell referred to as usage-sensitive pricing
(USP) (also in the literature of the period often called local measured service (LMS)).
Nor did he mention the analyses of the reasons for the preference. To what extent he
had access to such studies is not clear. Some of the people he thanks for ‚Äúcomments
and suggestions‚Äù were involved in the AT&T studies, but actual publication did not
come until after the Mitchell paper appeared (such as References 43‚Äì45). However,
there was plenty of older historical evidence on telecom pricing and that is also not
mentioned.
The Mitchell paper started off with
Although payment for nearly all other goods and services, including toll (long distance)
telephone calls, increases with greater consumption, nearly 90 percent of the residential
telephone subscribers and more than half the business subscribers in the United States
now pay a flat monthly rate for local calls ...
Recently, however, the telephone companies and regulatory commissions have been
moving cautiously towards imposing usage charges for local telephone calls ...
This was then followed by a long recitation, taking up the rest of the first page, of var-
ious reasons USP was supposedly advancing or about to advance in the United States.
(With the benefit of hindsight, we can tell those reasons were not strong enough. The
trend went the other way, with even long-distance voice telephony moving toward
flat rates.)
What was the basic justification for the move to USP? ‚Äú[T]he costs of local ser-
vice [had] moved upward since the late 1960‚Äôs at a rate not far below the general
price index.‚Äù (All quotes in this section not attributed to any other source are from
the Mitchell paper.) So there was not a crisis caused by surging usage, just the gen-
eral pressure to avoid raising rates in a high inflation environment that led to the
Nixon wage-price freeze, which was followed by even more dramatic price escala-
tion. On the other hand, ‚Äútechnological advances [had] benefited long distance far
more than local telephone calling.‚Äù And what were the advances that Mitchell cited?
‚ÄúDevelopment in microwave communications, coaxial cable, satellites, and waveg-
uides.‚Äù Certainly, all these contributed to lowering costs of providing phone service.
What is interesting is Mitchell listed only advances in transmission and said noth-
ing at all about switching. Electronic switching systems were advancing rapidly by
the mid-1970s. The Bell System introduced the 1ESS switch a decade earlier, for

22
WILL SMART PRICING FINALLY TAKE OFF?
example. With the ongoing and widely recognized advances in computing technolo-
gies, it should have been obvious that switching costs would decline dramatically
(even if they had not at that point) and that this would apply to local as well as
long-distance telephony. Mitchell was not unaware of electronic switching; as in dis-
cussing the costs of metering local calls, he did mention that such costs were much
lower in local offices with electronic exchanges than in those with electromechanical
ones, which made USP more attractive. But he completely ignored the effect of the
new technologies on the basic costs of switching and thus of providing voice services.
The one cost element that was clearly not going to decline to any appreciable extent
was local transmission, which meant primarily maintenance of the copper wire from
the local central office to the customer. This was the 1970s, long before the era of
the Internet or the various online computer services, and before PCs started pene-
trating households in any numbers. Hence, only voice services were of interest to
regulators, legislators, and the public. So the link to the home was expected to con-
tinue as a copper wire. And the costs of installing and maintaining that copper were
almost completely independent of usage. Hence, all the discussion about advantages
of USP in Mitchell‚Äôs paper ignored the vital point that the one component of costs of
service that could not be appreciably reduced would not be affected by switching to
USP.
Mitchell noted that ‚Äú[a] welfare analysis of two-part tariffs requires knowledge
of demand at different prices.‚Äù However, ‚Äúno data are available as yet on calling
rates under usage-sensitive pricing,‚Äù so he proceeded to make a variety of assump-
tions (which he admitted were simplified). Some of the questionable features of those
assumptions are noted in the following text. However, this is not a careful review of
his paper, so not everything is examined. The point is just to point out some of the
more strikingly peculiar features of his work.
Mitchell decided to ‚Äú[ignore] ... the dynamic effects of the number of subscribers in
the telephone network on the value of service to any one subscriber.‚Äù Today, it appears
to be widely understood that the number of users is extremely important in determin-
ing value, especially for new products and services. This is shown, for example, by
the frequent invocations of Metcalfe‚Äôs Law, which does convey the message about
the value of connectivity, even though there are serious arguments that its quantita-
tive form i s incorrect [46]. Interestingly enough, the first modern studies of network
effects were carried out inside the phone industry by Jeff Rohlfs [47] some years
before Metcalfe formulated his ‚ÄúLaw‚Äù and before Mitchell wrote his paper. Still, as
Mitchell explained, ignoring this effect was not unreasonable for voice telephony in
the United States in the 1970s, where this service had achieved an almost complete
penetration. He did cite some published papers that had considered the influence of
this effect on the early development of the telephone system.
What Mitchell did not say, but was implicit in his analysis, is that he was also ignor-
ing the intensity of usage as a determinant of value. This is now widely recognized
as important. Financial analysts, investors, and the press cite figures from social net-
works, say, or from more neutral outside monitoring organizations such as comScore
about the average length of time that users spend on those networks. The big change in
this perception, that is, heavy usage increases value, took place in the early days of the

A HISTORICAL VIGNETTE: BRIDGER MITCHELL AND FLAT RATES
23
Internet bubble, when AOL, then the dominant online service provider, switched from
metered rates to flat ones [5]. Management resisted the move and was only induced
to make it by competition, as it feared (correctly) that the time spent online would
jump. But once they moved to the new environment (assisted by improvements in
technology, as well as presence of competitive local service providers who were able
to lease modems for the AOL dial service at more affordable rates than the ILECs had
charged), they came to appreciate the value of intensity of usage and proudly hailed
measures showing it was increasing. But that was two decades later, so one cannot
fault Mitchell too much for ignoring it, as there were not many examples of this effect
playing a major role in telephony in his time. On the other hand, there was extensive
historical evidence of such effects, going back to the early days of postal services.
An interested researcher could easily have discovered this.
Overall, Mitchell‚Äôs models are simplistic, but that is of necessity true of all eco-
nomic models. Still, even given the low level of complexity that Mitchell limited
himself to, there are many questionable aspects of his work. For example, there is lit-
tle analysis of the sensitivity of the results to basic assumptions. (This can be excused
to some extent, of course, because this was before the era of widespread of desk-
top PCs and spreadsheets, so such calculations were not as easy to perform then
as they are today.) In particular, Mitchell did not exhibit any combination of basic
parameters for his model under which flat rates are optimal. Yet such must exist. The
logic of bundling (clearly understood to merchants since time immemorial and expli-
cated in the economics literature in the 1960s and visible in Figure 1 of Mitchell‚Äôs
paper) argues that for some parameters, flat rates provide higher profits for service
providers.
The strangest omission on Mitchell‚Äôs part was of the basic comparison of US and
foreign volumes of usage. He allowed that one should do some real studies of the
effects of USP. He also wrote that ‚Äúnew insights for US practice could be gained
from a comparative analysis of the telephone pricing and demand experience of for-
eign utilities that have long operated with various forms of measured service.‚Äù (Note
that what he regarded as potentially valuable were just the lessons about applying
USP, an indication of the deep bias against flat rates.) And earlier he cited briefly
some Norwegian experiences with peak-load pricing. But nowhere did he even hint
at the most salient difference between the United States and the rest of the world in
the 1970s, namely, that daily usage of a phone line was about three times higher in the
United States than in the rest of the world (see Reference 5 for data and references).
This dramatic difference (especially when combined with a look at revenues of telcos
in different countries) casts doubts on various Mitchell‚Äôs estimates of marginal costs,
as well as his assumptions about marginal utilities and the effects that USP might
have on usage.
Another major issue, although one probably inevitable given the kinds of eco-
nomic models that Mitchell relied on, was the static nature of his analysis. Consumers
were supposed to have certain willingness to spend, and once prices were changed,
they would adjust quickly and settle into a new equilibrium usage pattern. Yet, what
we observe in practice is that changes in pricing lead not only to an instantaneous
response but also to changes in long-term growth rates. This occurred when AOL

24
WILL SMART PRICING FINALLY TAKE OFF?
introduced flat rates in 1996. There was a quick jump, followed by vigorous growth,
as opposed to the static level of usage under metered rates. Earlier, the same phe-
nomenon took place with the introduction of the Penny Post in Britain in 1840, as
well as with the drastic lowering of taxes on newspapers in 1836 [9].
To be fair to the many researchers in the telecommunications economics com-
munity, it should be said that there were some papers that did consider some of the
long-range effects. Particularly noteworthy was the work of Jeff Rohlfs [47] on net-
work effects. Also, about the time that the Mitchell‚Äôs paper [42] appeared, results
from the AT&T and GTE experiments with metered local rates were becoming avail-
able, and so the awareness of the limitations of the consensus view was becoming
wider. But this consensus view continued, and continues, to dominate.
1.11
ANOTHER HISTORICAL VIGNETTE: FLAT RATES FOR DATA
Another interesting historical vignette is the advocacy of flat rates for data services
by Loretta Anania and Richard Jay Solomon. They were among the early pioneers
researching the pricing of broadband services, in the days of Integrated Services
Digital Network (ISDN) and asynchronous transfer mode (ATM) [48‚Äì50]. They also
appear to have been unique in that community in arguing for flat rates. Furthermore,
they had very good arguments, based on excellent insights into data networks,
in particular about the lack of direct relation between volume and value of data
transfers.
There are at least two interesting aspects to the work of Anania and Solomon. One
is the very limited impact it has had, as measured in citations. This appears to reflect
the strong bias in favor of ‚Äúsmart pricing.‚Äù The other interesting aspect of Anania‚Äôs
and Solomon‚Äôs work is the limited range of arguments they presented, which reflects
the lack of studies on flat rates. Their early arguments for flat rates were basically
limited to pointing out that users would have large opportunities to bypass service
provider controls [49]:
‚Ä¶ dynamic allocation of network resources will become increasingly difficult for the
carrier (or regulator) to track. So, with integrated digital networks, the flat-rate, or
pay-in-advance subscription solution, may be the best method of pricing.
Later, they began to mention user preferences, but without much emphasis or
detail [50]. This can again be taken as an indication of how little attention has been
paid historically to flat rates. This tradition continues. One can cite a variety of
recent papers, such as References 51, and 52, that fail to address many of the key
advantages of flat rates.
Given all these precedents, it appears inevitable that the industry, and the net-
working research community, will continue to press for ‚Äúsmart pricing.‚Äù As will be
explained later, there are reasons to doubt whether they will be very successful. How-
ever, to the extent they are, it appears they are neglecting some important aspect of
implementing ‚Äúsmart pricing.‚Äù

DIRECTIONS FOR SMART PRICING RESEARCH AND DEPLOYMENT
25
1.12
DIRECTIONS FOR SMART PRICING RESEARCH AND
DEPLOYMENT
Current research directions on smart pricing are probably not optimal for influencing
applications. Most of the work appears to be inspired by the desire to control conges-
tion and to maximize the engineering efficiency of networks. However, engineering
efficiency has seldom been the main driving force behind telecom pricing in the past,
and it is not now either. Far more important has been the incentive to maximize rev-
enues through price discrimination. While the basic incentives and practices of price
discrimination are ancient, they were first explicated by the French ‚Äúeconoengineers‚Äù
of the middle of the nineteenth century [53]. Their work was motivated by the desire
to understand business policies of the most revolutionary industry of that era, namely,
railroads. There is a memorable and oft-quoted 1849 passage by Jules Dupuit [54]
on this subject
It is not because of the few thousand francs which would have to be spent to put a roof
over the third-class carriages or to upholster the third-class seats that some company
or other has open carriages with wooden benches. ... What the company is trying to
do is to prevent the passengers who can pay the second-class fare from traveling third
class; it hits the poor, not because it wants to hurt them, but to frighten the rich. ...
And it is again for the same reason that the companies, having proved almost cruel to
the third-class passengers and mean to the second-class ones, become lavish in dealing
with first-class passengers. Having refused the poor what is necessary, they give the rich
what is superfluous.
This description is not an exaggeration. In fact, many railroads did not have any seats
in third-class carriages. Some refused to run any third-class carriages, and among
those that did, such carriages went by special trains that were slow and ran at incon-
venient times. Thus not only was ‚Äúversioning‚Äù common, so was a form of what is
now called damaged goods practice, where extra costs were incurred in order to offer
an inferior service at a lower price. A contemporary account claimed that ‚Äúthe hum-
bler order of passengers will not easily forget that a [railway] director once proposed
to hire a number of chimney-sweeps to render‚Äîwhat, with the best company, are
nothing better than locomotive hutches‚Äîperfectly untenable‚Äù [55]. (It should be said
that no evidence has been found that chimney sweeps were actually hired to make
third-class travel less attractive. This was just a suggestion, but a very revealing one
that explains the motivations driving many policy decisions.)
The incentives that drove railroad managers to versioning and damaged goods have
also been present in telecommunications. One of the fundamental obstructions to the
introduction of fundamentally new networking technologies, or sophisticated pricing
for the current ones, is that, in a slight paraphrase of Scott Bradner‚Äôs memorably pithy
quote [56],
The Internet is not reliably bad enough to drive the creation of a new network.
But that could be changed through ‚Äúdamaged goods‚Äù practices. ‚ÄúBufferbloat,‚Äù
which is now an accidental impairment on many networks, could be introduced

26
WILL SMART PRICING FINALLY TAKE OFF?
systematically. Various types of noise or artificial packet drops (coupled with
Deep Packet Inspection and statistical profiling, as is already done in various
traffic-shaping practices) could be introduced much more widely. For example,
because the most valuable types of communication tend to use little bandwidth (as
will be discussed in more depth later), and voice is very latency sensitive, artificial
increases in latency could decrease the quality of Voice over Internet Protocol (VoIP)
services. If smart pricing is to spread, there should be far more research on such
approaches and they should be part of the standard networking courses.
There is also too little research on bamboozling customers. The financial ana-
lyst Craig Moffett and his colleagues noted that ‚Äú[f]or years, the telecom industry
has thrived on obfuscation‚Äù [57]. Even earlier, back in 1998, Scott Adams in one of
his Dilbert books talked of phone companies that ‚Äúform confusopolies to make it
impossible for the average individual to determine who has the lowest price,‚Äù [58,
p. 161]. Furthermore, there is now solid quantitative research that demonstrates the
effectiveness of confusing users with complex pricing plans [59]. Hence, this feature
of complicated pricing deserves more attention both in research programs and in the
education of students for the workplace.
1.13
GROWTH IN DEMAND
To evaluate prospects of various pricing schemes, we have to consider the balance of
demand and supply of data transport.
Wireline traffic growth has been decelerating over the past few years and is now
taking more than 2 years to double. This is shown by the mostly widely cited project
to estimate and predict traffic growth, Cisco‚Äôs Visual Networking Index (VNI) [60].
The May 2013 VNI report projects that the traffic on the wired Internet will grow
only 25% from 2012 to 2013 and will have a compound growth rate of 21% from
2012 to 2017. The sources for the VNI studies are confidential, though, and there are
some estimates of growth rates that are somewhat higher than those of VNI.
Here we cite some public data that generally support the VNI observations.
(References and URLs are available at Reference 61.) The European IX association
reports their aggregate peak traffic growth has declined from 57% in 2008 to 45%
in 2012. TeleGeography estimates that the ‚Äú[g]rowth in worldwide international
Internet capacity declined from 63% in 2009 to 33% in 2013,‚Äù [62]. Australia is an
outlier among industrialized countries in that it is still maintaining a high growth
rate at 59% during the year ended June 2013, just about the same as the annual
compound rate of 60% over the previous 4 years. However, Australia‚Äôs Internet
traffic per capita is still only about half that of the United States.
The most intriguing outlier in the available statistics is Japan. It has the most
advanced infrastructure in the world, in terms of fraction of wireline broadband
subscribers who have fiber. Along with Hong Kong and South Korea, it usually
shows up at the top of rankings by effective speed of connections. Yet, Japanese
Internet traffic is relatively low and is growing slowly. The latest measurement from
the remarkable cooperative industry effort, covering about 40% of the Japanese
market (see Reference 61), taken in May 2013 and kindly provided by Kenjiro Cho

TECHNOLOGY TRENDS
27
(see also Reference 63 for earlier but more detailed summary) shows a continuation
of the 20‚Äì25% annual growth rate of wireline traffic that has prevailed over the past
half a dozen years.
In wireless, the calls for urgent action to deal with the perceived spectrum shortage
were and continue to be fueled by reports and predictions of data traffic more than
doubling each year (cf. [64, p. 76] and [65, 66]).
In Australia, the data downloaded to mobile handsets grep 43% from the fourth
quarter of 2012 to the second quarter of 2013, an annual rate of 105%. However, in
the United States, the growth of 123% from 2010 to 2011 moderated to 69% in the
following year. The Cisco VNI of May 2013 projects a 66% annual growth rate of
mobile data between 2012 and 2017. While this is a substantial decline from earlier
VNI projections, it is doubtful whether even that rate can be sustained for long, as is
discussed in the next section.
While growth rates for wireless traffic far exceed those for wireline, it is important
to remember that total volumes of data transmitted by mobile wireless technologies
(so excluding WiFi) are still low. For both Australia in mid-2013 and the United States
for year-end 2012, they were under 3% of total Internet traffic for those countries.
Thus the potential demand just from people switching their usage from wireline to
wireless is huge.
1.14
TECHNOLOGY TRENDS
The three main ingredients of the ICT (information and communication technologies)
industry are computing, storage, and communication. They have all been riding the
Moore‚Äôs Law curve, with relatively steady and predictable rates of improvement. (See
Reference 61 for some statistics and references.) Those rates have declined, but over
the past few years, the amount of raw computing, or raw storage, or basic photonic
transmission that can be performed for a unit cost has been doubling about every 2
years. While there have always been fears that progress might grind to a halt, that has
not happened, even though there are various indications of slowdowns. But perhaps
even more important than a general slowdown is that locality is becoming more pro-
nounced. While magnetic storage densities are still increasing rapidly, the bandwidth
to disks is growing much more slowly. Similarly, much of the improvement in raw
computing power is now coming from putting more cores on a chip, but the band-
width to the chip is an increasingly important barrier to the utilization of that power.
Thus in both computing and storage, data moves less, or as the database community
has been saying for a long time, is becoming ‚Äúcooler.‚Äù
The arrival of the Internet led to a dramatic jump in data traffic in the mid-1990s,
when for a while there actually was the ‚ÄúInternet traffic doubling every 100 days‚Äù
phenomenon. This was followed by several years of doubling every year. However,
for most of the past decade, worldwide Internet traffic growth has been decelerating,
as discussed in Section 1.13. It is not impossible that it may fall substantially below
the level of growth in computing power and storage, as has been predicted by the
Cisco measurement and forecasting effort [60], especially because that has happened
in Japan.

28
WILL SMART PRICING FINALLY TAKE OFF?
On the other hand, the volumes of either broadcast video or magnetic disk storage
dwarf the Internet‚Äôs transmission capacity. Thus, should masses of people suddenly
‚Äúcut the cord‚Äù and attempt to obtain their favorite TV programs over the Internet,
networks would collapse under the load. However, there is no sign of that happening,
and the switch to the more natural mode of on-demand viewing is proceeding fairly
slow (facilitated by kludgy half-way solutions such as video recorders). Similarly,
there is great promise in machine-to-machine communication, but it is also arriving
at a measured pace. Therefore, wireline networks do have an incentive to encourage
innovative uses of their facilities. This incentive is especially important because of
the competition from wireless. As we have discovered over the past three decades,
mobility is extremely attractive. Both usage and investment are moving toward wire-
less, and if application developers concentrate their energies on the low traffic, small
screen size, and low power mobile devices, wireline could become a backwater.
As for mobile wireless, it is very difficult to estimate the growth of transmission
capacity, because there are so many technological and economic dimensions to
this problem. Currently, the shift to 4G and LTE offers a quantum jump in data
capacity. However, beyond that, the possible improvements in modulation and
related approaches appear to be rather limited. The industry is aiming for a 1000 √ó
boost, and while it usually does say that the time frame for this jump in traffic is
impossible to predict, it does cite prominently the recent 2 √ó annual growth rates,
cf. [65, 66]. It appears very unlikely that even 50% per year growth rates could be
maintained for long.
Note that one of the favorite routes to increasing capacity, namely, assigning more
spectrum for mobile wireless, can offer only limited relief. The National Broadband
Plan released by the Federal Communications Commission in March 2010 reports
that the United States currently has 547 MHz that can be used for such purposes and
calls for doubling that within 10 years [64]. However, such a doubling would only
compensate for 1 year of 100% annual growth and for 2 years of 50% annual growth.
Substantial improvements in capacity could be achieved just by building more
facilities, but that would require greatly increased capital spending. That could come
from either higher revenues from users or from restructuring the industry so it spends
less on marketing, lobbying, and other activities and more on construction. As neither
is likely to happen, we are likely to see traffic limited by available capacity. Combined
with the wide disparity of various types of bits, this suggests that pricing will play a
significant role in balancing demand and supply.
For wired networks, the capacity limitations of mobile wireless, as well as the
‚Äúmental transactions costs‚Äù that are likely to be imposed by pricing, leave a substantial
opening. However, to exploit their advantage, they will need to encourage use, and
that argues for the simplest possible pricing, which is flat rate.
1.15
CONCLUSIONS
As technology advances, implementing ‚Äúsmart pricing‚Äù is becoming easier. Further,
the deep (and irrational) prejudice in favor of ‚Äúsmart pricing‚Äù is likely to drive the

REFERENCES
29
industry and academic researchers to continue pursuing a variety of schemes, some
to the point of deployment.
At the same time, general technology advances are complicating life and intensi-
fying users‚Äô desire for simplicity. In the wireline arena, we find rapid improvements
in transmission capacity, and relatively slow growth in demand from consumers. This
creates incentives for service providers to stimulate usage and thus argues for flat rates
and simple networks, with large pipes, with any market segmentation determined by
the size of the pipe.
In wireless, technology improvements are slower and therefore demand growth
faster. Thus in this area, pricing is likely to play a larger role. But the human desire to
avoid ‚Äúmental transaction costs‚Äù will still argue for simplicity, at least at individual
consumer level.
There may well be more sophistication at the business-to-business level, when
companies contract with service providers to provide certain transmissions in ways
invisible to consumers, just as today Amazon sells ebooks with the wireless delivery
achieved seamlessly by an established carrier. The arguments for simplicity are not as
important at the business-to-business level as it is with consumers, because companies
come closer to the economic rationality so beloved by experts. However, it is not clear
whether ‚Äúsmart pricing‚Äù will spread far even there, because managers appear to prefer
strategic games to real market. Furthermore, the example of Apple‚Äôs app store shows
that even at the level of businesses, there are advantages to simplicity.
ACKNOWLEDGMENTS
This paper was prepared with the partial support of DARPA contract FA8750-13-2-
0023 on ‚ÄúThe evolution of control plane resilience.‚Äù
REFERENCES
1. S. McCartney. Flier auctions: better seats, going once, going twice .... Wall Street Journal,
April 25, 2013.
2. S. Sen, C. Joe-Wong, S. Ha, and M. Chiang. ‚ÄúA survey of broadband data pric-
ing: past proposals, current plans, and future trends,‚Äù ACM Computing Surveys
Volume 46(2), November 2013, 10.1145/2543581.2543582. Preprint available at:
‚ü®http://arxiv.org/pdf/1201.4197v2.pdf‚ü©.
3. A. Odlyzko, B. St. Arnaud, E. Stallman, and M. Weinberg, Know Your Limits:
Considering the Role of Data Caps and Usage Based Billing in Internet Access Ser-
vice, Public Knowledge, 2012. Available at: ‚ü®http://publicknowledge.org/files/UBP%
20paper%20FINAL.pdf‚ü©.
4. D. Levinson and A. Odlyzko, ‚ÄúToo expensive to meter: the influence of transaction costs
in transportation and communication,‚Äù Philosophical Transactions of the Royal Society A,
366(1872), 2008, 2033‚Äì2046. Preprint available at: ‚ü®http://ssrn.com/abstract=1735657‚ü©.
5. A. M. Odlyzko. ‚ÄúThe history of communications and its implications for the Internet,‚Äù
2000 unpublished manuscript. Available at: ‚ü®http://ssrn.com/abstract=235284‚ü©.

30
WILL SMART PRICING FINALLY TAKE OFF?
6. A. M. Odlyzko. ‚ÄúNetwork neutrality, search neutrality, and the never-ending conflict
between efficiency and fairness in markets,‚Äù Review of Network Economics, 8(1), 2009,
40‚Äì60. Preprint available at: ‚ü®http://ssrn.com/abstract=1095350‚ü©.
7. K. Bode. ‚ÄúCable Industry Finally Admits Caps Not About Congestion After Insisting
for Years Caps Were About Congestion,‚Äù DSL Reports, Jan. 17, 2013. Available at:
‚ü®http://www.dslreports.com/shownews/Cable-Industry-Finally-Admits-Caps-Not-About-
Congestion-122791‚ü©.
8.
A. M. Odlyzko. ‚ÄúThe evolution of price discrimination in transportation and its impli-
cations for the Internet,‚Äù Review of Network Economics, 3(3), 2004, 323‚Äì346. Preprint
available at: ‚ü®http://ssrn.com/abstract=596301‚ü©.
9. A. M. Odlyzko. ‚ÄúThe volume and value of information,‚Äù International Journal of Commu-
nication, 6, 2012. Available at: ‚ü®http://ijoc.org/ojs/index.php/ijoc/article/view/1570/740‚ü©.
10. R. N. Clarke. ‚ÄúCosts of neutral/unmanaged IP networks,‚Äù Review of Network Economics,
8(1), 2009. Preprint available at: ‚ü®http://ssrn.com/abstract=903433‚ü©.
11. B. Swanson. The coming exaflood. Wall Street Journal, Jan. 20, 2007.
12. B. Swanson and G. Gilder, Estimating the Exaflood. Discovery Institute white paper, Jan.
29, 2008. Available at: ‚ü®http://www.discovery.org/a/4428‚ü©.
13. A. M. Odlyzko. ‚ÄúThreats to the Internet: too much or too little growth?‚Äù Inter-
net Evolution, Feb. 25, 2008. Available at: ‚ü®http://www.internetevolution.com/author.
asp?section_id=592&doc_id=146747&‚ü©.
14. N. Szabo. ‚ÄúThe mental accounting barrier to micropayments,‚Äù 1996 white paper. Available
at: ‚ü®http://szabo.best.vwh.net/micropayments.html‚ü©.
15. A. M. Odlyzko. ‚ÄúInternet pricing and the history of communications,‚Äù Computer Networks,
36, 2001, 493‚Äì517. Preprint available at: ‚ü®http://ssrn.com/abstract=235283‚ü©.
16. A. M. Odlyzko. ‚ÄúThe many paradoxes of broadband,‚Äù First Monday, 8(9), 2003,
1‚Äì15. Available at: ‚ü®http://firstmonday.org/htbin/cgiwrap/bin/ojs/index.php/fm/article/
view/1072/992‚ü©.
17. A. M. Odlyzko. ‚ÄúTelecom dogmas and spectrum allocations,‚Äù 2004 paper written for the
Wireless Unleashed blog. Available at: ‚ü®http://www.dtc.umn.edu/‚àºodlyzko/doc/telecom.
dogmas.spectrum.pdf‚ü©.
18. A. M. Odlyzko. ‚ÄúContent is not king,‚Äù First Monday, 6(2), 2001. Available at:
http://firstmonday.org/htbin/cgiwrap/bin/ojs/index.php/fm/article/view/833/742.
19. Anonymous. Let Mexico‚Äôs moguls battle. Economist, Feb. 4, 2012.
20. A. M. Odlyzko. The delusions of net neutrality. In Telecommunications Pol-
icy Research Conference, 2008. Available at: ‚ü®http://www.dtc.umn.edu/‚àºodlyzko/doc/
net.neutrality.delusions.pdf‚ü©.
21. A. Odlyzko. ‚ÄúThe current state and likely evolution of the Internet. In Proceedings Globe-
com‚Äô99, IEEE, 1999, pp. 1869‚Äì1875. Preprint available at: ‚ü®http://www.dtc.umn.edu/‚àº
odlyzko/doc/globecom99.pdf ‚ü©.
22. A. M. Odlyzko. ‚ÄúTalk, Talk, Talk: so who needs streaming video on a phone? The killer
app for 3G may turn out to be‚Äìsurprise‚Äìvoice calls,‚Äù Forbes, Aug. 20, 2001, p. 28. Preprint
available at: ‚ü®http://www.dtc.umn.edu//‚àºodlyzko/doc/3g.accidental.success.txt‚ü©.
23. CTIA - The Wireless Association. Semi-Annual Year-End 2012 Top-Line Survey Results.
Available at: ‚ü®http://files.ctia.org/pdf/CTIA_Survey_YE_2012_Graphics-_FINAL.pdf ‚ü©.
24. OECD. OECD Communications Outlook 2013. Available at:
‚ü®http://www.oecd-ilibrary.org/science-and-technology/oecd-communications-outlook-
2013_comms_outlook-2013-en‚ü©.

REFERENCES
31
25. Plunkett Research. Advertising & Banding Industry Overview. Available at: ‚ü®http://
www.plunkettresearch.com/advertising-branding-market-research/industry-
statistics‚ü©. Downloaded Sept. 26, 2013.
26. National Cable & Telecommunications Association. Cable industry revenue 1996‚Äì2011.
Available at: ‚ü®http://www.ncta.com/Stats/CustomerRevenue.aspx‚ü©. Downloaded Sept. 28,
2012.
27. C. Labovitz, S. Iekel-Johnson, D. McPherson, J. Oberheide, F. Jahanian, and M. Karir.
ATLAS Internet Observatory 2009 Annual Report. Available at: ‚ü®http://www.nanog.org/
meetings/nanog47/presentations/Monday/Labovitz_ObserveReport_N47_Mon.pdf‚ü©.
28. C. Labovitz, S. Iekel-Johnson, D. McPherson, J. Oberheide, and F. Jahanian. Inter-
net inter-domain traffic. In ACM Computer Communication Review, Oct. 2010,
pp.
75‚Äì86.
Available
at:
‚ü®http://www.sigcomm.org/sites/default/files/ccr/papers/
2010/October/1851275-1851194.pdf‚ü©.
29. C.-H. Hong, S. Kandula, R. Mahajan, M. Zhang, V. Gill, M. Nanduri, and R. Wattenholer.
Achieving high utilization with software-driven WAN. In ACM SIGCOMM 2013, 2013.
Available at: ‚ü®http://conferences.sigcomm.org/sigcomm/2013/papers/sigcomm/p15.pdf‚ü©.
30. S. Jain, A. Kumar, S. Mandal, J. Ong, L. Poutievski, A. Singh, S. Venkata, J. Wanderer,
J. Zhou, M. Zhu, J. Zolla, U. H√∂lzle, S. Stuart, and A. Vahdat. B4: experience with a
globally-deployed software defined WAN. ACM SIGCOMM 2013, 2013. Available at:
‚ü®http://conferences.sigcomm.org/sigcomm/2013/papers/sigcomm/p3.pdf‚ü©.
31. National Cooperative Highway Research Program (NCHRP). Future Dinancing Options
to Meet Highway and Transit Needs, Dec. 2006. Available at: ‚ü®http://onlinepubs.trb.
org/onlinepubs/nchrp/nchrp_w102.pdf ‚ü©.
32. U.S. Department of Commerce, Bureau of the Census. Historical Statistics of the United
States: Colonial Times to 1970, 1975.
33. C. Kirjner and R. Parameswaran. Google Fiber‚Äìhow much will Google spend to overbuild
Kansas City? How much would it cost to expand? BernsteinResearch report, Financial
Analyst report, April 8, 2013.
34. T. Orlik. Beijing falls short on rebalancing. Wall Street Journal, May 23, 2013.
35. World Bank. Gross fixed capital formation (% of GDP), interactive table at
‚ü®http://data.worldbank.org/indicator/NE.GDI.FTOT.ZS‚ü©, downloaded May 27, 2013.
36. T. Lewin. Senate committee report on for-profit colleges condemns costs and practices.
New York Times, July 30, 2012.
37. Pharmaceutical industry. Wikipedia entry for the pharmaceutical industry. Available at:
‚ü®http://en.wikipedia.org/wiki/Pharmaceutical_industry‚ü©. Downloaded Oct. 7, 2013.
38. C. Moffett and N. Del Deo. Sprint: how long is long-term? MoffettNathanson Research
report, Financial Analyst report, Oct. 11, 2013.
39. A. Troianovski and S. Grundberg. Nokia‚Äôs bad call on smartphones. Wall Streen Journal,
July 19, 2012.
40. D. Streitfeld. As boom lures app creators, tough part is making a living. New York Times,
Nov. 18, 2012.
41. R. R. John. Network Nation: Inventing American Telecommunications. Harvard University
Press, Cambridge, MA, 2010.
42. B. M. Mitchell. ‚ÄúOptimal pricing of local telephone service,‚Äù American Economic Review,
68(4), 1978, 517‚Äì537.
43. J. G. Cosgrove and P. B. Linhart. Customer choices under local measured telephone ser-
vice. Public Utilities Fortnightly, Aug. 30, 1979, pp. 27‚Äì31.

32
WILL SMART PRICING FINALLY TAKE OFF?
44. L. Garfinkel and P. B. Linhart. The transition to local measured telephone service. Public
Utilities Fortnightly, Aug. 16, 1979, pp. 17‚Äì21.
45. T. F. Wong. ‚ÄúIdentifying tariff induced shifts in the subscriber distribution of local tele-
phone usage,‚Äù in L. Courville, A. de Fontenay, and R. Dobell, eds., Economic Analysis
of Telecommunications: Theory and Applications, North-Holland, Amsterdam, 1983, pp.
263‚Äì278.
46. B. Briscoe, A. Odlyzko, and B. Tilly. Metcalfe‚Äôs Law is wrong. IEEE Spectrum, July 2006,
pp. 26‚Äì31. Available at: ‚ü®http://www.spectrum.ieee.org/jul06/4109‚ü©.
47. J. Rohlfs. ‚ÄúA theory of interdependent demand for a communications service,‚Äù Bell Journal
of Economics and Management Science, 5, 1974, 16‚Äì37.
48. L. Anania and R. J. Solomon. ‚ÄúUser arbitrage and ISDN,‚Äù InterMedia, Jan. 1988, pp.
25‚Äì31.
49. L. Anania and R. J. Solomon. ‚ÄúModels of network infrastructure: pricing ISDN for access,‚Äù
in J. H. Alleman and R. D. Emmerson, eds., Perspectives on the Telephone Industry: The
Challenge for the Future, Harper & Row, New York, 1989, pp. 287‚Äì303.
50. L. Anania and R. J. Solomon. ‚ÄúFlat‚Äîthe minimalist price,‚Äù in L. W. McKnight and J. P.
Bailey, eds., Internet Economics, MIT Press, Cambridge, Mass. 1997, pp. 91‚Äì118.
51. J. M. Bauer and S. S. Wildman. The economics of usage-based pricing in local broad-
band markets. NCTA white paper, Dec. 2012. Available at: ‚ü®http://i.ncta.com/ncta_com/
PDFs/Wildmanreport_web.pdf ‚ü©.
52. A. Nevo, J. L. Turner, and J. W. Williams. ‚ÄúUsage-based pricing and demand for residential
broadband,‚Äù preprint, Sept. 2013. Available at: ‚ü®http://ssrn.com/abstract=2330426 ‚ü©.
53. R. B. Ekelund Jr., and R. F. H√©bert. Secret Origins of Microeconomics: Dupuit and the
Engineers. University Chicago Press, Chicago, 1999.
54. R. B. Ekelund. ‚ÄúPrice discrimination and product differentiation in economic theory: an
early analysis,‚Äù Quarterly Journal of Economics, 84(2), 1970, 268‚Äì278.
55. Anonymous. Railway comfort. Household Words: A Weekly Journal Conducted by
Charles Dickens, Aug. 3, 1850, pp. 449‚Äì450.
56. S. Bradner. Will there be a next-generation network? Network World, July 21, 2003. Avail-
able at: ‚ü®http://www.networkworld.com/columnists/2003/0721bradner.html‚ü©.
57. C. Moffett, N. Del Deo, and A. Chan. Quick take ‚Äì AT&T (T): market share(ing) Part II ...
A quieter voice. BernsteinResearch report, Financial Analyst report, July 18, 2012.
58. S. Adams. The Dilbert Future: Thriving on Business Stupidity in the 21st Century. Harper-
Collins, New York, 1998.
59. M. Miao and K. Jayakar. ‚ÄúBounded rationality and consumer choice: an eval-
uation of consumer choice of mobile bundles in China,‚Äù Preprint available at:
‚ü®http://ssrn.com/abstract=2241581 ‚ü©.
60. Cisco Visual Networking Index. Available at:
‚ü®http://www.cisco.com/en/US/netsol/ns827/networking_solutions_sub_solution.html‚ü©.
61. MINTS. Minnesota Internet Traffic Studies project. Available at: ‚ü®http://www.dtc.
umn.edu/mints/‚ü©.
62. TeleGeography. ‚ÄúEurope emerges as global Internet hub,‚Äù Sept. 18, 2013 press release,
‚ü®http://www.telegeography.com/products/commsupdate/articles/2013/09/18/europe-
emerges-as-global-internet-hub/‚ü©.
63. K. Cho. ‚ÄúBroadband traffic report: traffic trends over the past year,‚Äù Internet Infras-
tructure Review, 16, 2012, 33‚Äì37. Available at: ‚ü®http://www.iij.ad.jp/en/company/
development/iir/pdf/iir_vol16_report_EN.pdf ‚ü©.

REFERENCES
33
64. U.S. Federal Communications Commission. Connecting America: The National
Broadband Plan, March 2010. Available at: ‚ü®http://download.broadband.gov/plan
/national-broadband-plan.pdf‚ü©.
65. 4G Americas. Meeting the 1000x Challenge: The Need for Spectrum, Technology
and Policy Innovation, white paper, Oct. 2013. Available at: ‚ü®http://www.4gamericas.
org/documents/2013_4G_20Americas_20Meeting_20the_201000x_20Challenge_2010_
204_2013_FINAL.pdf‚ü©.
66. Qualcomm, Inc. The 1000x Mobile Data Challenge: More Small Cells, More Spectrum,
Higher Efficiency, July 25, 2013 presentation deck. Available at: ‚ü®http://www.qualcomm.
com/media/documents/tags/1000x-challenge‚ü©.


2
Customer Price Sensitivity
to Broadband Service Speed:
What are the Implications for
Public Policy?
VICTOR GLASS, STELA STEFANOVA, and RON DIBELKA
2.1
INTRODUCTION
In the prebroadband era,1 recovering a local telephone company‚Äôs network costs for
voice service was a relatively straightforward process. The users of the local network
fell into two categories: end users who bought phone service and long-distance carri-
ers who sold long-distance service to end users. The pricing arrangements were also
relatively clear. The end user bought local service from the local telephone company
and long-distance carriers such as AT&T and MCI paid the local phone companies for
the use of their networks to complete long-distance calls. The relationships between
the local and long-distance companies were clearly defined by Federal Communica-
tions Commission (FCC) rules and a standard tariff defined the services rendered by
the local telephone company and the charges to long-distance carriers.
The broadband world has complicated network cost recovery considerably. In the
broadband world, voice service is only one application traversing broadband net-
works, so it is no longer straightforward to separate it from other services. Accessing
many applications over a broadband pipe produces diverse traffic patterns among
users in comparison to traditional voice service, and to a large extent, usage is not
closely tied to the prices they pay for broadband services. End users can buy a vari-
ety of broadband plans; the more expensive ones include higher speed access to
the Internet, traditional voice, and cable TV. End users buying the same broadband
plan often differ significantly in their use of the broadband network. The relation-
ship between bandwidth use and price paid is far more tenuous among application
1Following the introduction of access charges with 47 C.F.R. Part 69 of FCC rules.
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
35

36
CUSTOMER PRICE SENSITIVITY TO BROADBAND SERVICE SPEED
providers. Google and Yahoo are heavy bandwidth users because they essentially
take pictures of the Internet to improve their web site performance.2 YouTube, Net-
flix, and other video providers take up perhaps one-third of the Internet‚Äôs bandwidth in
the United States.3 These applications providers pay a fraction of the bandwidth cost
of an end user to the Broadband Service Provider (BSP). By contrast, small applica-
tion providers such as a local restaurant face a usage/cost relationship close to those
for end users.
Billing application providers is beyond the capabilities of many BSPs. If an appli-
cation provider is not in a BSP‚Äôs service area, it typically does not have or want a
contractual relationship with the BSP. Without a contract, these application providers
can terminate traffic free of charge. In case of default, BSPs recover their network
costs from their customers. This is the so-called bill-and-keep arrangement.
A major policy issue is whether bill-and-keep is a welfare maximizing strategy
from a government policy perspective. The answer to this question often depends
on perspective. Application providers support bill-and-keep because they fear that
BSPs could exercise monopoly power to raise terminating rates for their traffic. BSPs
oppose bill-and-keep but face the almost impossible challenge of how to bill millions
of application providers. The FCC supports a bill-and-keep system but recognizes
that it needs a funding base to subsidize broadband service where private businesses
cannot make a business case for offering broadband services at speeds widely avail-
able elsewhere. To raise support funds, the FCC recognizes that it may want to assess
application providers and use the funds raised to make broadband service univer-
sally available. If, however, nothing is done to recover network costs from application
providers, wireline BSPs may not build out to remote customers and may introduce
usage limits such as the 10 GB per month consumption threshold already instituted
by Verizon Wireless and AT&T Wireless more than which a customer pays an extra
charge.
The focus of our paper is whether it is in the financial interest of application
providers as a group to buy down end user charges. A reasonable case could be made
that application providers, as a group, may be willing to subsidize end users if two
conditions hold: First, end users are price sensitive to the cost of broadband speeds. If
so, lowering the price of broadband service will encourage them to buy higher speed
service and use the Internet more intensively. As a result, they would not throttle
their use of Internet and will not be deterred from accessing applications with higher
bandwidth requirements, which would foster new applications development. Second,
subsidization of end users must be competitively neutral across providers and across
networks. Research in the two-sided market literature shows that if subscribers to
higher speed tiers are price elastic, it may be beneficial for content providers who
do not enter in direct contractual relationships with end users to subsidize prices for
2Scott Cleland, December, 2008, ‚ÄúA First-Ever Research Study: Estimating Google‚Äôs U.S. Con-
sumer Internet Usage & Cost‚Äî2007‚Äì2010.‚Äù Available at www.netcompetition.org/study_of_google_
internet_usage_costs2.pdf.
3Scott Cleland, December, 2008, ‚ÄúA First-Ever Research Study: Estimating Google‚Äôs U.S. Con-
sumer Internet Usage & Cost‚Äî2007‚Äì2010.‚Äù Available at www.netcompetition.org/study_of_google_
internet_usage_costs2.pdf.

INTRODUCTION
37
high speed offerings through the public support system (e.g., [1]). Buying down of
end user charges could be done through a universal broadband fund such as the newly
established Connect America Fund (CAF). The intended goal of CAF is ‚Äúto enable
all US households to access a network that is capable of providing both high-quality
voice‚Äîgrade service and broadband that satisfies the National Broadband Availabil-
ity target,‚Äù currently set at 4 Mbps downstream and 1 Mbps upstream.4 To the extent
that a private sector business case cannot be made to offer this minimum service,
CAF funds should be available to fund the shortfall.5 In fact, the FCC is currently
evaluating whether end users, content providers, or both should contribute to CAF,
which is designed to foster universal broadband connectivity.6
Estimating price elasticities of demand has a second and important benefit to BSPs
whether the buy down occurs or not. If demand is price elastic to speed, it will
affect their pricing strategies. Lower prices may boost demand for broadband ser-
vices at higher speeds. Unfortunately, the empirical economic literature offers mixed
results for price elasticity of demand for broadband. Some studies find own-price
elasticity of broadband demand to be larger [2‚Äì4], while others estimate smaller
price sensitivities [5, 6]. One simple explanation for this variation in estimates is
that the choice to access to the broadband differs from the choice of which band-
width service level to subscribe to once the customer chooses to buy broadband
service. Specifically, households may have different price sensitivities for gaining
access to the Internet and the service level they choose. Varian [4] estimates will-
ingness to pay for speed using experimental data collected in 1998 and 1999. The
own-price elasticities of demand for bandwidth range from ‚àí1.3 to ‚àí3.1. He finds
that lower service bandwidths are perceived as substitutes for the level of band-
width chosen by participants in the experiment and reports low willingness to pay
for higher bandwidths. In a more recent experimental survey design study, Rosston
et al. [7] estimate households‚Äô willingness to pay for speed and reliability. They find
that households value broadband highly, but values for very fast speeds are only
marginally higher than values for fast speeds. They explain that a typical house-
hold does not use applications requiring blazing speeds. Glass and Stefanova [8] find
highly inelastic own-price elasticities of demand by looking at the total subscribers
of a BSP and the lowest price for its introductory offer. The estimates are ‚àí0.66 using
data from 2005 and ‚àí0.21 using data from 2009. These estimates are based on the
introductory offer prices and can be interpreted as estimates of the price sensitivity
of gaining access to the Internet. The lower price elasticity estimated from the 2009
dataset suggests that access to the Internet has become more of a necessity in the later
period.
These studies suggest that once a household has subscribed to broadband, it may
have different price sensitivity for access to the Internet as it relates to expected usage.
A household may perceive bandwidth as a differentiated service, which is captured
4‚ÄúAvailability,‚Äù Chapter 8, Connecting America: The Broadband National Plan, 2010, p. 163
5‚ÄúAvailability,‚Äù Chapter 8, Connecting America: The Broadband National Plan, 2010, p. 163
6FCC has issued a Further Notice of Proposed Rulemaking on USF contribution reform on April 30,
2012, seeking comment on what services and service providers should contribute to the Fund and how
contributions should be assessed.

38
CUSTOMER PRICE SENSITIVITY TO BROADBAND SERVICE SPEED
to some extent by the choice of speed tiers. Even a low speed tier connection can be
used for browsing e-mail, You Tube video, and near-real time video,7 but customers
who are heavy users, especially of near- and real-time video, are far more likely to
purchase a high speed tier. In the current study, we use a detailed demand and price
data collected in 2010 to estimate a demand model for Internet speed tiers offered by
rural BSPs and use the parameter estimates to calculate price elasticities of demand
for three differentiated speed tiers‚Äîwith downstream speeds up to 3 Mbps, between
3 and 6 Mbps and with downstream speeds above 6 Mbps.8
2.2
MODEL
Our goal is to estimate price elasticities of demand for different speed service pack-
ages purchased by broadband users. The generalized Leontief [9], the Rotterdam
model [10], the Translog model [11], and the Almost Ideal Demand System (AIDS)
[12] are among the most popular attempts to provide flexible, but theoretically con-
sistent, functional forms to study consumer purchases of different products. We use
an AIDS model for our estimation.
The AIDS model is specified in the usual way:
wi = ùõºi +
‚àë
j
ùõæij ln Pj + ùõΩi ln
(X
P
)
,
where X is the total expenditure on broadband in a given market, Pj is the price of the
jth service, wi is the share of the total expenditures spent on the ith good, and P is the
price index defined as
ln P = ùõº0 +
‚àë
j
ùõºi ln Pi + 1
2
‚àë
i
‚àë
j
ùõæij ln Pi ln Pj.
We estimate the standard AIDS model specified above and an AIDS model with
demographic variables. Following Heien and Wessells [13], demographic variables
can be incorporated into the model by including them in the intercepts of the share
equations.
ùõºi = ùúåi0 +
‚àë
k
ùúåikdk,
where dk denotes the kth demographic characteristic. ùõºi, ùõæij, ùõΩi, ùúåi0, and ùúåik are param-
eters to be estimated. Parameter restrictions are added to ensure that the demand
equations are consistent with the theory:
‚àë
i
ùõºi = 1 for adding up,
‚àë
i
ùõæij = 0 and
‚àë
i
ùõΩi = 0 for linear homogeneity, ùõæij = ùõæji for symmetry.
7‚ÄúGoals for high-performance America,‚Äù Chapter 2, Connecting America: The Broadband National Plan,
2012, p. 17.
8FCC has used 3 and 6 Mbps as threshold speeds for reporting broadband services in its form 477.

VARIABLE DESCRIPTIONS
39
These conditions guarantee that the sum of the budget shares is unity. Homo-
geneity restrictions imply that the budget shares will not change if all prices and
expenditures are multiplied by the same positive constant. The symmetry restric-
tions require that compensated demand effects be symmetric to be consistent with
consumer theory.
In order to have the budget shares for each market add up to 1 in the model with
demographic variables, the adding up restriction was replaced by
‚àë
i
ùúåi0 = 1 and
‚àë
i
ùúåik = 0,
for k = 1, ‚Ä¶ , K.
For a complete system of demand equations, the variance covariance matrix is
singular because of the adding up property, so we drop one of the tiers and estimate
the model using maximum likelihood. It is shown that maximum likelihood estimates
are invariant to which product is dropped in the estimation [14].
Expenditure elasticities are computed at mean shares using the following expres-
sion,
ei = 1 + ùõΩi
wi
.
Price elasticities are given by
eij = ùõøij +
ùõæij ‚àíùõΩi
(
wj ‚àíùõΩi ln
(
X
P
))
wi
,
where ùõøij = 1 if i = j and 0 otherwise.
2.3
DATA
The data used in our analysis were obtained in 2010 from a nationwide survey of
rate of return rural local exchange carriers (RLECs) participating in the National
Exchange Carrier Association (NECA) pools and their affiliated Internet service
providers. We collected data on Internet services purchased by rural households
from these providers. Companies reported price, upload and download speed, and
total number of subscribers for all Internet packages they offer. We used data for
194 broadband providers which reported at least 3 broadband services‚Äîone with
download speed below 3 Mbps, one with download speed below 6 Mbps, and one
with download speed greater than or equal to 6 Mbps. If a company offered more
than one service in any of the three categories, we aggregated the services into the
three representative service tiers.
2.4
VARIABLE DESCRIPTIONS
We aggregated the service tiers into three categories‚Äîservices with downstream
speed below 3 Mbps, services with downstream speed between 3 and 6 Mbps, and

40
CUSTOMER PRICE SENSITIVITY TO BROADBAND SERVICE SPEED
services with downstream speed above 6 Mbps. The resulting average speeds within
these categories are 1.29 Mbps for the service tiers below 3 Mbps, 3.34 Mbps for
the middle category, and 7.93 Mbps for the top category of services. Average prices
increase with the speed offered and the average price of $75.37 paid per month for
the top tiers is almost two times the average price of $37.93 paid per month for the
lowest service tiers. The average number of subscribers for the tiers below 3 Mbps is
2016, while the average number of subscribers for the highest speed tiers is less than
a quarter of that: 479. Average upload speeds also increase with the higher download
speeds but are in general much lower than the download speeds. The average upload
speed for the highest tier in our data of 6 Mbps and above is 1.29 Mbps. The average
expenditure for all three service tiers per company is $135,335/month. The expendi-
ture share for the lowest tier is 60% of total, for the middle tier is 28%, and for the
top tier is 12%. Table 2.1 shows the summary statistics for the aggregated sample.
To derive the demographic variables, we matched the serving territories of the
RLECs with census data as well as data published on the National Broadband Map
web site.9 We include variables to control for age, education, income, race, and den-
sity of the population of the markets in our study. Percentage of population of age
less than 19 years and age greater than 60 years will be interpreted relative to the per-
centage of population of age between 19 and 60 years old. Educational achievement
TABLE 2.1
Statistics for Variables Used in the AIDS Model
Variable
Mean
Standard Deviation
Minimum
Maximum
Monthly price‚Äîtier 1
$37.93
$13.93
$15.00
$169.95
Monthly price‚Äîtier 2
$53.36
$19.07
$20.85
$199.95
Monthly price‚Äîtier 3
$75.37
$35.81
$20.85
$229.95
Subscribers‚Äîtier 1
2,016
2,840
9
16,608
Subscribers‚Äîtier 2
940
1,833
1
12,949
Subscribers‚Äîtier 3
479
1,493
1
12,697
Upspeed‚Äîtier 1 (in Mbps)
0.43
0.24
0.06
2.00
Upspeed‚Äîtier 2 (in Mbps)
0.76
0.49
0.26
4.00
Upspeed‚Äîtier 3 (in Mbps)
1.29
1.43
0.26
10.00
Downspeed‚Äîtier 1 (in Mbps)
1.04
0.44
0.13
2.38
Downspeed‚Äîtier 2 (in Mbps)
3.34
0.59
3.00
5.50
Downspeed‚Äîtier 3 (in Mbps)
7.93
2.63
6.00
20.10
Total expenditure
$135,335
$168,844
$3,898
$1,209,118
Share‚Äîtier 1
0.60
0.32
0.01
1.00
Share‚Äîtier 2
0.28
0.27
0.00
0.97
Share‚Äîtier 3
0.12
0.20
0.00
0.98
9The National Broadband Map is a joint project of the National Telecommunications and Information
Administration (NTIA), the FCC, and all states, http://www.broadbandmap.gov/.

RESULTS
41
is often found to be important in studies of broadband adoption. We include a vari-
able for the percentage of population with bachelor‚Äôs degree or higher. People living
in markets with lower household density may find it more beneficial to subscribe to
higher speed broadband, if available, because of a larger need to telecommute, use
telemedicine applications, or do online shopping, compared to households living in
more densely populated areas. Percentage of population with incomes below fed-
eral poverty levels is also included in the model. White and Asian households are
often found to be positively correlated with broadband adoption when compared to
non-White, non-Asian populations, thus we include the percentage of population of
White and Asian race to our model.
2.5
RESULTS
The explanatory variables include the logarithms of prices and expenditures for the
three service tiers in both models and demographic characteristics of the markets in
the second model. The parameter estimates are reported in Table 2.2. Most of the
price coefficients achieve statistical significance at the 0.01 level, while the demo-
graphic variables in the AIDS model with demographics, are mostly insignificant.
The exceptions are the negative coefficient on income below poverty levels for tier 3
and the negative coefficient for tier 3 on percentage of white population in the market.
Tables 2.3 and 2.4 reports the uncompensated own- and cross-price elasticities and
expenditure elasticities for each service tier and corresponding asymptotic standard
errors. All but two of the elasticities are statistically significantly different from zero
at the 0.05 level.
All elasticities have the expected signs. Own-price elasticities of broadband ser-
vices are negative and indicate elastic demand.10 The elasticity estimates increase
with speed with services below 3 Mbps having the lowest estimate (‚àí1.721 with the
standard AIDS model and ‚àí1.746 when demographics are included) and services
above 6 Mbps having the highest estimate (‚àí2.707 and ‚àí2.788, respectively). Sub-
scribers to higher tiers, who we expect are more heavy users of the Internet (watching
video, playing online precision games, etc.) are more sensitive to price, while lower
tier subscribers, who we expect use the internet primarily for web browsing and
checking e-mail, are less price sensitive.
Cross-price elasticities are positive, indicating that service tiers are substitutes.
Cross-price elasticities of the higher speed tier with respect to the lower speed tier
is always larger than the cross-price elasticity of the lower tier with respect to the
higher speed tier. This observation is compatible with the idea that lower speed users
are much less concerned by the monthly charges for higher speed services than higher
10We performed sensitivity analysis using different thresholds for definitions of the three tiers. Even though
the magnitude of the elasticity estimates varied with the definition, we found the same quantitative rela-
tionships between the lowest, medium, and highest service tiers. One interesting finding was the inelastic
demand for the lowest tier when it was defined to include only services below 1 Mbps. This is consistent
with results and interpretation of our earlier study [8], as the introductory offer competes with the choice
of not accessing the Internet.

TABLE 2.2
Econometric Estimates of the AIDS Models
Variable
Standard AIDS Model
Expenditure Shares
AIDS Model with Demographics
Expenditure Shares
Tier 1
Tier 2
Tier 3
Tier 1
Tier 2
Tier 3
Constant
1.318*
‚àí0.129
‚àí0.189
0.950
‚àí0.257
0.306
(0.197)
(0.188)
(0.138)
(0.683)
(0.57)
(0.4)
Log of Price 1
‚àí0.506*
0.309*
0.196*
‚àí0.490*
0.299*
0.192*
(0.071)
(0.055)
(0.038)
(0.07)
(0.057)
(0.038)
Log of Price 2
0.309*
‚àí0.321*
0.012
0.299*
‚àí0.325*
0.026
(0.055)
(0.061)
(0.037)
(0.057)
(0.064)
(0.038)
Log of Price 3
0.196*
0.012
‚àí0.208*
0.192*
0.026
‚àí0.218*
(0.038)
(0.037)
(0.028)
(0.038)
(0.038)
(0.031)
Expenditures
‚àí0.062*
0.036*
0.026*
‚àí0.040
0.014
0.026
42

(0.017)
(0.016)
(0.011)
(0.02)
(0.022)
(0.0141)
Age <19 years
0.432
‚àí0.150
‚àí0.282
(1.215)
(1.034)
(0.789)
Age >60 years
‚àí0.091
0.247
‚àí0.156
(0.78)
(0.659)
(0.528)
Bachelor degree or higher
‚àí0.491
0.382
0.110
(0.413)
(0.402)
(0.229)
Household density
‚àí0.001
0.000
0.000
(0.001)
(0.001)
(0.001)
Income below poverty
0.465
0.296
‚àí0.760*
(0.509)
(0.436)
(0.389)
White
0.090
0.205
‚àí0.295*
(0.257)
(0.241)
(0.148)
Asian
‚àí5.462
9.451
‚àí3.997
(4.406)
(5.343)
(4.678)
Note: Values in parentheses are standard errors. Asterisk denotes significance at 0.05 level. Log likelihood ratio test fails to rejects
the null hypothesis of no demographic effects in the model at 0.05 level but rejects it at 0.1 level.
43

44
CUSTOMER PRICE SENSITIVITY TO BROADBAND SERVICE SPEED
TABLE 2.3
Own-Price and Cross-Price Elasticities of Broadband Service Tiers
Standard AIDS Model
Price
AIDS Model with Demographics
Price
Quantity
Tier 1
Tier 2
Tier 3
Tier 1
Tier 2
Tier 3
Tier 1
‚àí1.721*
0.509*
0.315*
‚àí1.746*
0.502*
0.310*
(0.111)
(0.088)
(0.059)
(0.124)
(0.095)
(0.061)
Tier 2
0.978*
‚àí2.164*
0.057
1.045*
‚àí2.198*
0.101
(0.194)
(0.216)
(0.13)
(0.23)
(0.235)
(0.139)
Tier 3
1.383*
0.104
‚àí2.706*
1.390*
0.183
‚àí2.788*
(0.289)
(0.304)
(0.231)
(0.309)
(0.322)
(0.253)
Note: Values in parentheses are standard errors. Asterisk denotes significance at 0.05 level.
TABLE 2.4
Income Elasticities of Broadband Service Tiers
Standard AIDS Model
AIDS Model with Demographics
Tier
Income Elasticity
Standard Error
Income Elasticity
Standard Error
Tier 1
0.897
0.029
0.934
0.037
Tier 2
1.130
0.060
1.053
0.079
Tier 3
1.220
0.096
1.215
0.117
speed users are concerned with the cost of a lower speed service tier. Estimated expen-
diture elasticities show that all broadband services are normal goods and the demand
is positively correlated with income levels.
2.6
CONCLUSIONS
This study utilizes cross-sectional data from rural rate of RLECs to estimate market
demand functions for broadband service tiers. In addition to prices and number of sub-
scribers by service tier, the data include demographic characteristics of the markets.
We used two specifications of the AIDS to estimate the demand parameters and price
and income elasticities. Our empirical findings indicate that DSL customers are price
sensitive and price sensitivity increases for customers purchasing higher bandwidth
packages. Together with our earlier study [8], the overall results suggest that DSL
access has become a communications necessity, but customers are very price sensi-
tive to the DSL service level they buy. Our results are consistent with other studies that
find high household valuation for broadband but low incremental values for higher
speeds. Moreover, the empirical results strongly suggest that application providers,
as a group, would benefit from buying down the price of DSL for end users. Network
providers would receive additional funds to expand network capacity and they would
be less likely to introduce monthly capacity limits. Application providers, as a group,

REFERENCES
45
would benefit from greater use of the Internet and higher likelihood that end users
would access applications with higher bandwidth needs.
REFERENCES
1. P. Hande, M. Chiang, A. R. Calderbank, and S. Rangan, ‚ÄúNetwork pricing and rate allo-
cation with content provider participation,‚Äù Proceedings of IEEE INFOCOM, Princeton,
NJ, 2009.
2. D. Kridel, P. Rappoport, and L. Taylor ‚ÄúThe demand for high-speed access to the Inter-
net: the case of cable modems,‚Äù in D. G. Loomis and L. D. Taylor, eds., Forecasting the
Internet: understanding the explosive growth of data communications, Kluwer Academic
Publishers, Norwell, MA, 2001.
3. A. Goolsbee, ‚ÄúSubsidies, the value of broadband, and the importance of fixed costs,‚Äù in
R. Crandall and J. H. Alleman, eds., Broadband: should we regulate high-speed internet
access?, Brooking Institution Press, Washington, D.C., 2002, pp. 278‚Äì294.
4. H. R. Varian, The demand for bandwidth: evidence from the INDEX project, 2002.
Available at http://www.sims.berkeley.edu/‚àºhal/Papers/brookings.pdf. Accessed March
30, 2014.
5. R. K. Goel, E. T. Hsieh, M. A. Nelson, and R. Ram, ‚ÄúDemand elasticities for Internet
services,‚Äù Applied Economics, 38, 2006, 975‚Äì980.
6. K. T. Duffy-Deno, ‚ÄúBusiness demand for broadband access capacity,‚Äù Journal of Regula-
tory Economics, 24, 2003, 359‚Äì372.
7. G. Rosston, S. Savage, and D. Waldman, ‚ÄúHousehold demand for broadband Internet ser-
vice in 2010,‚Äù B. E. Journal of Economic Analysis and Policy Advances, 10(1), 2010.
8. V. Glass and S. Stefanova, ‚ÄúAn empirical study of broadband diffusion in rural America,‚Äù
Journal of Regulatory Economics, 38(1), 2010, 70‚Äì85.
9. W. E. Diewert, ‚ÄúAn application of the Shephard duality theorem: a generalized Leontief
production function,‚Äù Journal of Political Economy, 79, 1971, 481‚Äì507.
10. H. Theil, ‚ÄúThe information approach to demand analysis,‚Äù Econometrica, 6, 1965,
375‚Äì380.
11. L. R. Christensen, D. W. Jorgenson, and L. J. Lau, ‚ÄúTranscendental logarithmic utility
functions,‚Äù American Economic Review, 65 1975, 367‚Äì383.
12. A. Deaton and J. Muellbauer, ‚ÄúAn almost ideal demand system,‚Äù American Economic
Review, 70, 1980, 312‚Äì326.
13. D. Heien and C. R. Wessells, ‚ÄúDemand systems estimation with microdata: a censored
regression approach,‚Äù Journal of Business and Economic Statistics, 8, 1990, 365‚Äì371.
14. R. Pollak and T. Wales, ‚ÄúEstimation of the linear expenditure system,‚Äù Econometrica, 37,
1969, 611‚Äì628.


3
Network Neutrality with Content
Caching and Its Effect
on Access Pricing‚àó
FATIH KOCAK, GEORGE KESIDIS, and SERGE FDIDA
3.1
INTRODUCTION
The continuing network (net) neutrality debate (e.g., [1‚Äì3], 26) involves several dif-
ferent entities, such as Internet service providers (ISPs),1 content providers (CPs),
users, and governments (including partnerships). Although there are many different
perceptions for the definition and the coverage of net neutrality, one succinct defini-
tion is provided in [4]: ‚Äú[net neutrality] usually means broadband service providers
charge consumers only once for Internet access, do not favor one CP over another,
and do not charge CPs for sending information over broadband lines to end users.‚Äù
CPs, such as Amazon, Google, Yahoo!, and eBay, typically support net neutrality
because under nonneutral conditions, they expect additional access-networking
expenses and additional limitations or exclusions on their access to their cus-
tomers [5]. In contrast to CPs, ISPs (particularly residential ISPs) such as AT&T,
Verizon, Comcast, and Deutsche Telekom typically believe that neutrality regu-
lations threaten the profitability of their enormous infrastructure investments and
maintenance costs [1, 5] and that CPs do not pay a fair share of these costs while
profiting from advertising that is arguably not requested by consumers.2 Also,
flat-rate pricing frameworks leading to ‚Äúall-you-can-eat" consumer behavior result
in high transport costs and congestion in the ISPs‚Äô access networks, e.g., [6], which
makes ISPs complain about this and leads them to take blocking (e.g., Comcast
‚àóThis research was supported by NSF CNS grant 1116626.
1Equivalently, network service providers or access providers.
2Note that neutrality regulations for wireless access in the United States have not been instituted at the
time of writing of this chapter; see [6] for discussions of the mobile wireless access scenario.
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
47

48
NETWORK NEUTRALITY WITH CONTENT CACHING
blocking peer-to-peer (P2P) applications [7]) or pricing (e.g., [8]) measures. It has
been argued that some of these problems can be compensated by side payments
between CPs and ISPs [9‚Äì13]. Alternatively, the introduction of premium service
classes for applications has been suggested for critical applications such as health
monitoring and home security (which are being increasingly used [4]); streamed
spectacle events such as sports activities or newly released movies [5]; and inter-
active real-time video-conferencing/video-phone sessions. Applications engaged
in premium services will obviously receive a higher quality of service (QoS)
than applications under best-effort network-access service and will need to pay
usage-based costs (perhaps after a quota). Such payments are (content/application)
neutral in nature [14] because of the willingness of the users to pay for the premium
content [9]. Under net neutrality with flat-rate priced access,3 ISPs may not have
the incentive to improve their existing infrastructure by increasing capacity [15]
(particularly the router/switch infrastructure to drive fiber to the home (FTTH)) or
by improved security measures such as virus and spam filtering [5]. (Note that such
usage-based costs may need to be authenticated to the human subscriber/end user.)
Regarding QoS management, the physical location of requested content is obvi-
ously important to the goal of decreasing delay experienced by the users [16]. This
in turn underscores the importance of caching data proximal to the users, includ-
ing their ISP. Some large CPs, such as eBay and Google, cache their content around
the world on their own servers, while smaller CPs often use intermediary content
distributors, such as Akamai, who have caching agreements with local ISPs at differ-
ent locations [5]. Such agreements or more dedicated partnerships between ISPs and
CPs (i.e., ‚Äúeyeball‚Äù ISPs) lead to scenarios wherein ISPs may cache each other‚Äôs con-
tent, which raises issues of transit pricing between them; see Figure 3.1. To achieve
end-to-end QoS, Bornstaedt et al. [17] argued that a sending ISP should pay for the
transport traffic over an interconnection between ISPs.
Notwithstanding arguments for and against side payments, the necessity for pro-
viding a single interface (single contract including mutual services) to the end user is
emphasized by several presenters in [6]. Product offers to the end users are assumed to
be made in mainly two different ways: pull (on-demand) or push. Product offers can
be prepared in distributed (among ISPs), partially centralized (by any of the ISPs), or
fully centralized (by an external single facilitator entity) ways [18]. We herein primar-
ily consider the ‚Äúpull‚Äù demand model for content product where content requested in
the recent past is cached in anticipation of similar demand locally.
In the following, we first give a background on our problem setting in Section 3.2.
A model involving two different eyeball ISPs connected at peering point(s), where
revenue is generated corresponding to net traffic transmitted, is initially considered
in Sections 3.3 and 3.4. We consider a caching model captured by a single parameter,
Œ¶, affecting the revenue generated by transit traffic. We assume that there is no limit
on the throughput downstream to the users of each ISP. In Section 3.5, we modify the
model so that there is an upper bound on the throughput that the users can receive via
their ISP. So, two possible mechanisms to distribute the allowed throughput among
3Limited only by uplink and downlink bandwidth of the service agreement.

BACKGROUND
49
Tier 1 interface/net
Tier 2 interface
Tier 3, LM-ISP
CDN
ISP1
ISP2
CP
ISP2‚Äôs
content
cache
Subscribers
Figure 3.1
A CP may use a content distribution network (CDN) as depicted or may have a
local caching agreement with a last-mile (LM) ISP, or neither.
the types of demands (local or remote content) are introduced. We next consider the
scenario where there are multiple providers competing for the same group of users
(without the throughput limit condition, as in the initial model). User/customer migra-
tion among competing ISPs because of the price difference between them is modeled
by their ‚Äúloyalties" to the ISPs. In Section 3.6, consideration of two ISPs competing
for the same set of users is added to the model described in Section 3.4. We provide the
results of numerical experiments on performance at Nash equilibrium in Section 3.7.
We conclude with a discussion of future work in Section 3.8.
3.2
BACKGROUND
Suppose there is an eyeball-ISP provider whose revenue from its subscribers due to
its local content is
pD,
(3.1)
where p is a usage-based price and D is the total demand at that price. Note that ISPs
are continuing to depart from pure flat-rate pricing (based on access bandwidth) for
unlimited monthly volume, for example, [19, 20].
Following [21], suppose that there are two broad classes of applications, one of
which is significantly sensitive to congestion of access bandwidth, for example,
delay-sensitive interactive real-time applications. Assume that applications of the
other, best-effort type are unlikely to engage in usage-based pricing for access

50
NETWORK NEUTRALITY WITH CONTENT CACHING
bandwidth. As pricing reduces, the demand for access-bandwidth reservation
increases, causing additional congestion so that best-effort service will be increas-
ingly inadequate for congestion-sensitive applications. Therefore, the demand for
usage-priced access-bandwidth reservation may accelerate with reduced price. More
specifically, say there is positive threshold
DùúÉ< Dmax
such that overall demand sensitivity to price is greater when D ‚â•DùúÉthan when D <
DùúÉ. That is, for
dmax > dùúÉ,
a convex, piecewise-linear model for access bandwidth would be
D(p) = max{Dmax ‚àídmaxp, ÃÇDùúÉ‚àídùúÉp},
(3.2)
where
ÃÇDùúÉ= DùúÉ+ (Dmax ‚àíDùúÉ)dùúÉ
dmax
,
pùúÉ= (Dmax ‚àíDùúÉ)
dmax
,
pmax =
ÃÇDùúÉ
dùúÉ
= pùúÉ+ DùúÉ
dùúÉ
,
so that D(pùúÉ) = DùúÉ, see Figure 3.2.
So, in this model, the price range [pùúÉ, pmax] (equivalently, demand range [0, DùúÉ])
corresponds to low demand sensitivity to price, dùúÉ. The pricing range [0, pùúÉ]
(demand range [DùúÉ, Dmax]), when delay-sensitive applications typically need to
Dmax
DŒ∏
‚àídmax
‚àídŒ∏
PŒ∏
Pmax
Figure 3.2
Convex piecewise-linear demand response.

TWO DIFFERENT EYEBALL ISPs
51
adopt usage-priced (reserved or priority) access-bandwidth service, corresponds to
higher demand sensitivity to price, dmax.
Alternatively, suppose a convex, differentiable demand model that can approxi-
mate (3.2), specifically
D(p) = Dmax
(
1 ‚àí
p
pmax
)ùõº
.
(3.3)
Here, ùõº‚â•1 and given dmax > dùúÉ> 0 and 0 < DùúÉ< Dmax, pmax may be found using
D‚Ä≤(0) = ‚àídmax and D‚Ä≤((D)‚àí1(DùúÉ)) = D‚Ä≤(pùúÉ) = ‚àídùúÉ. The specific forms of demand in
Eqs. (3.2) and (3.3) are studied herein because they are tractable.
In [21], we explored the interior Nash equilibria resulting from such convex
demand responses. Note how the above models reduce to linear demand response
(e.g., by taking ùõº= 1), that is, revenue quadratic in prices, as assumed in many prior
papers, for example, [22].
3.3
TWO DIFFERENT EYEBALL ISPs
Again, we consider a game focusing on two different eyeball ISPs, indexed a and b, on
a platform of users and CPs, that is, the ISPs also serve as CPs so no separate pricing
by CPs is modeled. For k, j ‚àà{a, b}, the demand for ISP k‚Äôs content is Dk(pj) when it
is based on ISP j‚Äôs access-bandwidth price pj. In the following, the same price pj will
be used by ISP j irrespective of content source; that is, content is neutrally priced in
this sense.
Suppose there are peering points between these two ISPs where the net transit
traffic flow in one direction will correspond to the net revenue for the (net) receiving
Cached remote (b)
content
Non cached
remote (b)
content
(1 ‚àí Œ¶a)Db(pa)
Non cached
remote (a)
content
(1 ‚àí Œ¶b)Da(pb)
Local (a) content
ISP a ‚Äôs subscribers
ISP b ‚Äôs subscribers
Congestion
Point
Congestion
Point
Congestion
Point
Congestion
Point
Congestion
Point
Congestion
Point
ISP a
ISP b
Œ¶aDb(pa)
Cached remote (a)
content
Œ¶bDa(pb)
Db(pa)
Local (b) content
Db(pb)
Figure 3.3
Caching remote content.

52
NETWORK NEUTRALITY WITH CONTENT CACHING
ISP at rate pt from the (net) transmitting ISP. For example, France telecom charges
pt =$3 per megabit, whereas pricing from the digital subscriber line access mul-
tiplexer (DSLAM) to core, that is, access bandwidth, for their CPs is $40 per
megabit [23]. This said, many existing peering agreements among nontransit ISPs
have no transit pricing, that is, pt = 0. See [24,25] for recent studies of models of
transit pricing for a network involving a transit ISP between the CPs and end user
ISPs.
Without caching, transit traffic volume is obviously maximal and remote content
may be subject to additional delay possibly increasing demand (reducing demand
sensitivity) for usage-priced bandwidth reservations. However, poorer delay perfor-
mance may instead reduce demand for remote content or cause subscribers to change
to ISPs that cache remote content. So, caching will result in reduced demand for pre-
mium services by transit traffic; in the following, we model this with a caching factor
Œ¶k. We assume fixed caching factors for each of the ISPs, which means the selected
caching factors by the ISPs do not change no matter how their demand changes. The
case where the caching factor is adapted because of the demand changes is among
the future work.
3.4
THREE DIFFERENT CONGESTION POINTS PER ISP, FIXED
CACHING FACTORS
By simply separately accounting for the demand for premium-access service by two
different user populations with similar content preferences, we take the utilities as
Ua(pa, pb) =Da(pa)pa + Œ¶aDb(pa)pa
+ [(1 ‚àíŒ¶a)Db(pa) ‚àí(1 ‚àíŒ¶b)Da(pb)]+pt,
Ub(pa, pb) =Db(pb)pb + Œ¶bDa(pb)pb
+ [(1 ‚àíŒ¶b)Da(pb) ‚àí(1 ‚àíŒ¶a)Db(pa)]+pt,
where [x]+ ‚à∂= max{x, 0} in the second (transit revenue) terms. Note that Œ¶k ‚â§1 will
be chosen by ISP k at its minimal value, which we here assume to be strictly positive
again because an ISP that does not cache any remote content may lose subscribers
or demand for remote content may be reduced owing to poor delay performance,
cf. Section 3.5. We will also assume that pt is fixed and, by volume discount, pt <
min{pa, pb}. Also, we have assumed different ‚Äúupstream‚Äù congestion points for local
and remote traffic and no revenue from cached (best-effort) traffic. Moreover, for
ùõº> 1 (i.e., not linear demand response) note how this model assumes three different
congestion points, one at the peering point, one at the local content source, and one
at the cached content source, but not a single one further downstream toward the
users, cf. Section 3.5. That is, in this section, we consider three separate congestion
points per ISP for an example of convex demand (assumptions that include the linear
demand-response scenario as a special case).

THREE DIFFERENT CONGESTION POINTS PER ISP, FIXED CACHING FACTORS
53
Again suppose, for k ‚àà{a, b}, that
Dk(p) = Dmax,k
(
1 ‚àí
p
pmax
)ùõº
,
(3.4)
where the maximal price pmax > 0 and ùõº‚â•1 are also assumed to be common param-
eters for both ISPs to simplify the following expressions for Nash equilibria. Note
that U ‚à∂= pD(p) with a > 1 and 0 ‚â§p ‚â§pmax is maximized at p‚àó= pmax‚àï(1 + a),
i.e., U‚Ä≤(p‚àó) = 0 and U‚Ä≤‚Ä≤(p‚àó) < 0. Without loss of generality, assume the demand ratio
ùõø‚à∂=
Dmax,b
Dmax,a
‚â§1,
(3.5)
that is, demand for ISP a‚Äôs content is generally higher than that for ISP b.
The Nash equilibrium is a ‚Äústalemate" pricing point (p‚àó
a, p‚àó
b) at which neither ISP‚Äôs
utility will improve by a price change, that is,
arg max
pa Ua(pa, p‚àó
b) =p‚àó
a
and
(3.6)
arg max
pb Ub(p‚àó
a, pb) =p‚àó
b.
(3.7)
The first-order Nash equilibrium conditions and the solutions of these for three
cases are provided in the following text.
Case 1: (1 ‚àíŒ¶a)Db(p‚àó
a) > (1 ‚àíŒ¶b)Da(p‚àó
b).
ùúïUa(pa, pb)
ùúïpa
= D‚Ä≤
a(pa)pa + Da(pa) + Œ¶a[D‚Ä≤
b(pa)pa
+ Db(pa)] + (1 ‚àíŒ¶a)D‚Ä≤
b(pa)pt = 0
ùúïUb(pa, pb)
ùúïpb
= D‚Ä≤
b(pb)pb + Db(pb) + Œ¶b[D‚Ä≤
a(pb)pb
+ Da(pb)] = 0.
The solution is as follows:
p‚àó
a = pmax
1 + ùõº‚àí
pt(1 ‚àíŒ¶a)ùõøùõº
(1 + ùõº)(1 + Œ¶aùõø),
(3.8)
p‚àó
b = pmax
1 + ùõº.
(3.9)
The requirement pt < p‚àó
a < p‚àó
b < pmax gives the following condition on pt for
an interior Nash equilibrium:
pmax
pt
>1 + ùõº(ùõø+ 1)
1 + ùõøŒ¶b
.
(3.10)
Another way to put the case condition (1 ‚àíŒ¶a)Db(p‚àó
a) > (1 ‚àíŒ¶b)Da(p‚àó
b) is

54
NETWORK NEUTRALITY WITH CONTENT CACHING
1 <(1 ‚àíŒ¶a)ùõø
1 ‚àíŒ¶b
(pmax ‚àíp‚àó
a
pmax ‚àíp‚àó
b
)ùõº
and
(3.11)
1 <(1 ‚àíŒ¶a)ùõø
1 ‚àíŒ¶b
(
1 +
(1 ‚àíŒ¶a)ùõøpt
(1 + Œ¶aùõø)pmax
)ùõº
.
(3.12)
Case 2: (1 ‚àíŒ¶a)Db(p‚àó
a) < (1 ‚àíŒ¶b)Da(p‚àó
b).
ùúïUa(pa, pb)
ùúïpa
= D‚Ä≤
a(pa)pa + Da(pa) + Œ¶a[D‚Ä≤
b(pa)pa
+ Db(pa)] = 0
ùúïUb(pa, pb)
ùúïpb
= D‚Ä≤
b(pb)pb + Db(pb) + Œ¶b[D‚Ä≤
a(pb)pb
+ Da(pb)] + (1 ‚àíŒ¶b)D‚Ä≤
a(pb)pt = 0.
The solution is as follows:
p‚àó
a = pmax
1 + ùõº,
(3.13)
p‚àó
b = pmax
1 + ùõº‚àí
pt(1 ‚àíŒ¶b)ùõº
(1 + ùõº)(ùõø+ Œ¶b).
(3.14)
The requirement pt < p‚àó
b < p‚àó
a < pmax imposes the following condition on pt:
pmax
pt
>1 + ùõº(ùõø+ 1)
ùõø+ Œ¶b
(3.15)
The case condition (1 ‚àíŒ¶a)Db(p‚àó
a) < (1 ‚àíŒ¶b)Da(p‚àó
b) can be rewritten as
1 > (1 ‚àíŒ¶a)ùõø
1 ‚àíŒ¶b
(pmax ‚àíp‚àó
a
pmax ‚àíp‚àó
b
)ùõº
and
(3.16)
1 > (1 ‚àíŒ¶a)ùõø
1 ‚àíŒ¶b
(
1 +
(1 ‚àíŒ¶a)ùõøpt
(1 + Œ¶aùõø)pmax
)ùõº
.
(3.17)
Case 3: (1 ‚àíŒ¶a)Db(p‚àó
a) = (1 ‚àíŒ¶b)Da(p‚àó
b).
ùúïUa(pa, pb)
ùúïpa
= D‚Ä≤
a(pa)pa + Da(pa)
+ Œ¶a[D‚Ä≤
b(pa)pa + Db(pa)] = 0
ùúïUb(pa, pb)
ùúïpb
= D‚Ä≤
b(pb)pb + Db(pb)
+ Œ¶b[D‚Ä≤
a(pb)pb + Da(pb)] = 0.

ONE CONGESTION POINT PER ISP, FIXED CACHING FACTORS
55
The solution of the above equations is as follows:
p‚àó
a = p‚àó
b = pmax
1 + ùõº.
(3.18)
The case condition reduces to
1 ‚àíŒ¶b
1 ‚àíŒ¶a
=
Dmax,b
Dmax,a
= ùõø.
(3.19)
3.5
ONE CONGESTION POINT PER ISP, FIXED CACHING FACTORS
In this scenario, at ISP a, the demands Da(pa) (demand for local content) and Db(pa)
(demand for remote content) share a common significant congestion point proximal
to the users, for example, in a wireless-access setting. Again, we consider a system
where the players (eyeball ISPs) select access prices (plays) pa, pb > pt.
Given the prices pa for local content, we want an expression for demand ÃÇDaa (local
content at ISP a) and ÃÇDba (remote content at ISP a) that has the following intuitive
property:
lim
Dmax,b‚Üí0
ÃÇDaa = Da(pa) and
lim
Dmax,a‚Üí0
ÃÇDba = Db(pa)
(3.20)
and similarly for ISP b regarding ÃÇDbb and ÃÇDab as a function of pb.
The following assumed property is also intuitive because the presence of remotely
originated traffic will congest locally originated traffic and vice versa:
ÃÇDaa ‚â§Da(pa)
and
ÃÇDba ‚â§Db(pa)
(3.21)
and similarly for the other ISP b.
Proportion Rule. Suppose that the throughput limit downstream to the users is Lk
for ISP k ‚àà{a, b}. Then, at ISP a, the demands are as follows:
ÃÇDaa =
‚éß
‚é™
‚é®
‚é™‚é©
Da(pa)
Da(pa) + Db(pa)La,
if Da(pa) + Db(pa) > La
Da(pa),
else.
and
ÃÇDba =
‚éß
‚é™
‚é®
‚é™‚é©
Db(pa)
Da(pa) + Db(pa)La,
if Da(pa) + Db(pa) > La
Db(pa),
else.
And similarly for ISP b.

56
NETWORK NEUTRALITY WITH CONTENT CACHING
Critical Price Rule. Another way to split the throughput among the demands is as
follows. For ISP a, when Da(pa) + Db(pa) > La, a new price p‚àó
a is chosen so that
Da(p‚àó
a) + Db(p‚àó
a) = La.
(3.22)
If pa < p‚àó
a, then congestion will occur.
So, the expressions for the ISP revenues here can be taken as
Ua(pa) = ÃÇDaapa + Œ¶a ÃÇDbapa
+ [(1 ‚àíŒ¶a) ÃÇDba ‚àí(1 ‚àíŒ¶b) ÃÇDab]+pt
Ub(pb) = ÃÇDbbpb + Œ¶b ÃÇDabpb
+ [(1 ‚àíŒ¶b) ÃÇDab ‚àí(1 ‚àíŒ¶a) ÃÇDba]+pt.
3.6
THREE DIFFERENT CONGESTION POINTS PER ISP, FIXED
CACHING FACTORS, MULTIPLE PROVIDERS OF ONE OF THE TYPES
In this scenario, ISP a in Figure 3.3 is replaced by two ISPs, namely, ISP a1 and a2,
which compete for the same group of subscribers. So, we need to consider three utility
functions; Ua1, Ua2, and Ub; three demand functions, Da1, Da2, and Db; and three
access prices for each of the ISPs‚Äô own subscribers, pa1, pa2, and pb. But the number
of caching factors increases to four: Œ¶a1,b, Œ¶a2,b, Œ¶b,a1, and Œ¶b,a2 (Œ¶m,n meaning
willingness of ISP m to cache the content of ISP n). And, there are two transit prices,
pt1 (for the traffic between ISP a1 and ISP b) and pt2 (for ISPs a2 and b).
Ua1(pa1, pb) = ùúéa1Da1(pa1)pa1 + ùúéa1Œ¶a1,bDb(pa1)pa1
+[ùúéa1(1 ‚àíŒ¶a1,b)Db(pa1))
‚àí(1 ‚àíŒ¶b,a1)Da1(pb)]+pt1
Ua2(pa2, pb) = ùúéa2Da2(pa2)pa2 + ùúéa2Œ¶a2,bDb(pa2)pa2
+[ùúéa2(1 ‚àíŒ¶a2,b)Db(pa2))
‚àí(1 ‚àíŒ¶b,a2)Da2(pb)]+pt2
Ub(pa1, pa2, pb) = Db(pb)pb + Œ¶b,a1Da1(pb)pb
+Œ¶b,a2Da2(pb)pb + [(1 ‚àíŒ¶b,a1)Da1(pb)
‚àíùúéa1(1 ‚àíŒ¶a1,b)Db(pa1)]+pt1
+[(1 ‚àíŒ¶b,a2)Da2(pb))
‚àíùúéa2(1 ‚àíŒ¶a2,b)Db(pa2)]+pt2,

NUMERICAL EXPERIMENTS
57
where
ùúéai =
1‚àïpai
1‚àïpa1 + 1‚àïpa2
,
‚àÄi ‚àà{1, 2},
represents customer stickiness (loyalty, inertia) to the ith ISP (e.g., [9]); that is,
because ùúéai ‚àù1‚àïpai, the subscribers will not completely switch to the ISP with the
lowest price.
The demand-response model provided in Eq. (3.3) is used here, now with k ‚àà
{a1, a2, b}.
3.7
NUMERICAL EXPERIMENTS
First, numerical results were obtained for the scenario where there are three con-
gestion points per ISP (with fixed caching factors, as explained in Section 3.4) with
ùõº‚àà{1, 2}, Dmax,a = 20, Dmax,b = 10, pmax = 5, pt = 1, Œ¶a = 0.5, and Œ¶b = 0.3 as
the selected parameter values.
By using Ua(pa, pb) (Figure 3.4) and Ub(pa, pb) (Figure 3.5), the Nash equilibrium
point (p‚àó
a, p‚àó
b) were found in the following way:
1. Uniformly at random over (pt, pmax) select an initial point ùõæ(0) = (p(0)
a , p(0)
b ).
2. ‚àÄk ‚â•1, find the updated point ùõæ(k) = (p(k)
a , p(k)
b ) by synchronous best-response
updates, which are
p(k)
a = arg max
pa Ua(pa, p(k‚àí1)
b
)
p(k)
b = arg max
pb Ub(p(k‚àí1)
a
, pb).
3. (a) If ùõæ(k‚àí1) ‚âàùõæ(k), stop.
(b) Else, return to step 2.
It was observed that the Nash equilibrium point found by using the above proce-
dure is the same as the equilibrium point corresponding to the proper case solution
provided in Section 3.4 (regardless of the randomly selected starting point) and it was
found in just a few iterations (Figs. 3.4‚Äì3.7).
It can be observed in Figures 3.8 and 3.9 that p‚àó
a > p‚àó
b and Ua(p‚àó
a, p‚àó
b) > Ub(p‚àó
a, p‚àó
b)
for both values of ùõº. This is intuitive because Dmax,a > Dmax,b, which implies that
the demand for ISP a‚Äôs content will be larger than ISP b‚Äôs at the same price. This
immediately implies larger gain for ISP a, which also means that ISP a might have
some margin for increasing pa in order to gain even more utility. Therefore p‚àó
a > p‚àó
b
in this setting.
Next, numerical results were obtained for the model defined in Section 3.5,
where one congestion point per ISP and fixed caching factors assumptions are used.

58
NETWORK NEUTRALITY WITH CONTENT CACHING
0
5
5
4
4
3
3
2
2
1
1
10
20
30
40
Ua
pb
pa
Figure 3.4
Ua(pa, pb) (three congestion points for each ISP, fixed caching factors) (ùõº= 1).
0
5
5
5
4
4
3
3
2
2
1
1
pb
pa
10
15
20
25
30
Ub
Figure 3.5
Ub(pa, pb) (three congestion points for each ISP, fixed caching factors) (ùõº= 1).

NUMERICAL EXPERIMENTS
59
0
5
5
4
4
3
3
2
2
1
1
5
10
15
25
20
Ua
pb
pa
Figure 3.6
Ua(pa, pb) (three congestion points for each ISP, fixed caching factors) (ùõº= 2).
0
5
5
4
4
3
3
2
2
1
1
5
10
15
20
Ub
pb
pa
Figure 3.7
Ub(pa, pb) (three congestion points for each ISP, fixed caching factors) (ùõº= 2).

60
NETWORK NEUTRALITY WITH CONTENT CACHING
1
1.5
2
2.5
3
3.5
4
4.5
5
0
5
10
15
20
25
30
35
pa
Ua
ùõº = 1
ùõº = 2
Figure 3.8
Ua(pa, p‚àó
b) (three congestion points for each ISP, fixed caching factors).
1
1.5
2
2.5
3
3.5
4
4.5
5
0
5
10
15
20
25
pb
Ub
ùõº = 1
ùõº = 2
Figure 3.9
Ub(p‚àó
a, pb) (three congestion points for each ISP, fixed caching factors).

NUMERICAL EXPERIMENTS
61
Here, the throughput limit is split among the ISPs according to the proportion rule, cf.
Section 3.5. ùõº‚àà{1, 2}, Dmax,a = 20, Dmax,b = 10, pmax = 5, pt = 1, Œ¶a = 0.5, Œ¶b =
0.3, La = 50, and Lb = 5 are the selected parameters values. Notice that one of the
throughput limits (La) is selected, which is significantly larger than the other one (Lb)
to analyze the scenario where congestion does not occur downstream to the users of
ISP a, whereas it does occur for ISP b. If both of the throughput limits selected are
very large, then the problem reduces to the three congestion points scenario (Section
3.4), because there will be no distribution of the throughput limit between the two
different kinds of demand at the congestion point (of each ISP).
The Nash equilibrium point was again quickly found by using synchronous
best-response updates.
In Figures 3.10 and 3.11, behaviors similar to those with Figures 3.8 and 3.9 are
observed. But, it is worth noting that in Figure 3.11, for values of pb where Ub
is increasing (for both ùõº‚àà{1, 2}), the capacity Lb is fully utilized. In this region,
increasing pb does not lead to a decrease in the demand, which means that there is a
linear increase in the utility of ISP b. But, after the peak, the total demand at ISP b is
smaller than Lb; therefore, the increase in price pb leads to decreases in both demand
and utility.
Finally, numerical results were obtained for the case where there are multiple
providers competing for the same group of subscribers (Section 3.6). Again,
synchronous best-response updates are used, but for three utility functions
(Ua1(pa1, pa2, pb), Ua2(pa1, pa2, pb), and Ub(pa1, pa2, pb)) depending on the corre-
sponding three access pricing parameters (pa1, pa2, and pb). So, generally, for n
1
1.5
2
2.5
3
3.5
4
4.5
5
0
5
10
15
20
25
30
35
pa
Ua
ùõº = 1
ùõº = 2
Figure 3.10
Ua(pa, p‚àó
b) (one congestion point for each ISP, fixed caching factors).

62
NETWORK NEUTRALITY WITH CONTENT CACHING
1
1.5
2
2.5
3
3.5
4
4.5
5
0
2
4
6
8
10
12
pb
Ub
ùõº = 1
ùõº = 2
Figure 3.11
Ub(p‚àó
a, pb) (one congestion point for each ISP, fixed caching factors).
competing ISPs (n = 2 in our case of ISPs a1 and a2), the synchronous best-response
update step (n + 1 player synchronous updates) is as follows:
p(k)
i
= arg max
pi Ui(pi, p(k‚àí1)
‚àíi
), ‚àÄi,
where i is the index of the ISP (including the noncompeting ISP (in our case, ISP b)),
pi is the price used by ISP i, and p‚àíi is the set of prices used by the other ISPs.
The parameter values can be selected in various combinations. We used the param-
eters Dmax,a1 = 20, Dmax,a2 = 20, Dmax,b = 10, pmax = 5, pt1 = 1, pt2 = 1, Œ¶a1,b =
0.2, Œ¶a2,b = 0.8, Œ¶b,a1 = 0.5, and Œ¶b,a2 = 0.5. These were selected so as to analyze
the effect of (static but different) caching factors of competing ISPs (ISPs a1 and a2)
on the utilities. It can observed from Figures 3.12 and 3.13 that the ISP with smaller
Œ¶ (a1) also has (again following intuition) a smaller utility compared to its competi-
tor ISP (a2). The effect of ùõºon the utilities and the equilibrium prices are in the same
as the previous cases.
3.8
FUTURE WORK
In the future, we will extend our models of demand in the presence of a more complex
mixture of applications with different service requirements and will do so by using
more diverse, though naturally coupled, demand response models for each type of
provider. Moreover, we will consider these problems in the context of competition

FUTURE WORK
63
1
1.5
2
2.5
3
3.5
4
4.5
5
0
2
4
6
8
10
12
14
pa1
Ua1
ùõº = 1
ùõº = 2
Figure 3.12
Ua1(pa1, p‚àó
a2, p‚àó
b) (three congestion points for each ISP, fixed caching factors,
competing ISPs).
1
1.5
2
2.5
3
3.5
4
4.5
5
0
2
4
6
8
10
12
14
16
18
pa2
Ua2
ùõº = 1
ùõº = 2
Figure 3.13
Ua2(p‚àó
a1, pa2, p‚àó
b) (three congestion points for each ISP, fixed caching factors,
competing ISPs).

64
NETWORK NEUTRALITY WITH CONTENT CACHING
1
1.5
2
2.5
3
3.5
4
4.5
5
0
5
10
15
20
25
30
35
40
45
pb
Ub
ùõº = 1
ùõº = 2
Figure 3.14
Ub(p‚àó
a1, p‚àó
a2, pb) (three congestion points for each ISP, fixed caching factors, com-
peting ISPs).
(multiple providers of each type) and collaboration between providers of different
types, where we could use, for example, Shapley values to decide how to share rev-
enue in the latter case.
We will also consider the dynamic selection of a caching factor. For example, we
can model the sensitivity of customer loyalty ùúéto the caching factor Œ¶ in a way so
as to reflect the loss in demand by user migration because of poor delay performance
in the best-effort service class because of inadequate caching. So, the utilities of the
ISPs will be affected by this potential loss because of user migration, and hence, they
will depend on the caching factors as well as the access prices. As ISPs adjust their
caching factors, in addition to their access prices, capturing the trade-off between the
user migration and the transit traffic revenue.
REFERENCES
1. P. Waldmeir. The net neutrality dogfight shaking up cyberspace. Financial Times, Mar. 23,
2006.
2. P. Hande, M. Chiang, R. Calderbank, and S. Rangan. Network pricing and rate allocation
with content provider participation. In Proceedings IEEE INFOCOM, 2009.
3. J. Musacchio, G. Schwartz, and J. Walrand. ‚ÄúA two-sided market analysis of provider
investment incentives with an application to the net-neutrality issue,‚Äù Review of Network
Economics, 8(1), 2009, 22‚Äì39.

REFERENCES
65
4. R. Hahn and S. Wallsten. ‚ÄúThe economics of net neutrality,‚Äù Economists‚Äô Voice, 3(6), 2006,
1‚Äì7.
5. P. Ganley and B. Allgrove. ‚ÄúNet neutrality: a user‚Äôs guide,‚Äù Computer Law and Security
Report, 22(6), 2006, 454‚Äì463.
6. ETICS. First Economics and Technologies for Inter-Carrier Services (ETICS) Workshop
Proceedings, 2010.
7. Comcast v. FCC, 600 F. 3d 642 (D.C. Cir. 2010).
8. S. Sen, C. Joe-Wong, S. Ha, and M. Chiang. ‚ÄúPricing data: a look at past proposals, current
plans, and future trends,‚Äù Arxiv preprint, arXiv:1201.4197, 2012.
9. S. Caron, G. Kesidis, and E. Altman. Application neutrality and a paradox of side pay-
ments. In Proceedings ACM ReArch, Philadelphia, Nov. 30,2010. See also http://arxiv.
org/abs/1006.3894
10. E. Altman, P. Bernhard, S. Caron, G. Kesidis, J. Rojas-Mora, and S. Wong. A
study of non-neutral networks. Telecommunication Systems Journal Special Issue on
Socio-economic Issues of Next Generation Networks, June 2011.
11. E. Altman, A. Legout, and Y. Xu. Network non-neutrality debate: an economic analysis.
In Proceedings IFIP Networking, 2011.
12. Y. Wu, H. Kim, P. H. Hande, M. Chiang, and D. H. K. Tsang. Revenue sharing among ISPs
in two-sided markets. In Proceedings of IEEE INFOCOM Mini Conference, Shanghai,
2011.
13. P. Njoroge, A. E. Ozdaglar, N. E. Stier-Moses, and G. Y. Weintraub. Investment in Two
Sided Markets and the Net Neutrality Debate. Columbia Business School DRO (Decision,
Risk and Operations) Working Paper No. 2010-05, Oct. 2012.
14. R. B. Chong. ‚ÄúThe 31 Flavors of Net Neutrality,‚Äù 12 Intellectual Property Law Bulletin,
vol. 12, 2008.
15. H.K. Cheng, S. Bandyopadhyay, and H. Guo. The debate on net neutrality: a policy per-
spective. Information Systems Research, 22(1), 2011, 60‚Äì82.
16. J. Goldsmith and T. Wu. Who Controls the Internet: Illusions of a Borderless World.
Oxford University Press, New York, 2006.
17. F. Bornstaedt, M. G. Roettgermann, F. T. Johansen, and H. L√∏nsethagen. ‚ÄúThe Sending
Party Network Pays‚Äù: a first step towards end-to-end quality of service. In Proceedings
IEEE ICIN, 2011.
18. R. Douville. ETICS Architecture(s). In Second Economics and Technologies for
Inter-Carrier Services (ETICS) Workshop, June 2011.
19. A. Shin. Who‚Äôs the bandwidth bandit? The Washington Post, Oct. 4, 2006. Available at:
http://blog.washingtonpost.com/thecheckout /2006/10/bandwidth_bandit.html.
20. K. Bode. AT&T To impose caps. Overages Mar. 13,2011. Available at: http://www.
dslreports.com/shownews/Exclusive-ATT-To-Impose-Caps-Overages-113149.
21. G. Kesidis. Side-payment profitability under convex demand-response modeling
congestion-sensitive applications. In Proceedings IEEE ICC, Ottawa, June 2012.
22. N. Economides. ‚ÄúNet neutrality: non-discrimination and digital distribution of content
through the internet,‚Äù I/S: A Journal of Law and Policy, 4(2), 2008, 209‚Äì233.
23. E.Pouyllau. Personal Communication ARC MANEUR Meeting. INRIA, Paris, May. 2011.
24. A. Dhamdhere and C. Dovrolis. Can ISPs be profitable without violating ‚ÄúNetwork Neu-
trality‚Äù? In Proceedings ACM NetEcon, Seattle, WA, 2008.

66
NETWORK NEUTRALITY WITH CONTENT CACHING
25. V. Valancius, C. Lumezanu, N. Feamster, R. Johari, and V. V. Vazirani. How many tiers?
Pricing in the internet transit market. In Proceedings ACM SIGCOMM, 2011.
26. A.A. Gilroy. Net neutrality: background and issues. CRS Report for Congress, RS22444,
2008.

PART II
Technologies for
Smart Data Pricing


4
Pricing under Demand Flexibility
and Predictability
OZGUR DALKILIC, JOHN TADROUS, ATILLA ERYILMAZ,
and HESHAM EL-GAMAL
4.1
INTRODUCTION
The essence of smart pricing is exploiting the price responsiveness of the demand side
to achieve objectives such as obtaining higher profit, improving customer experience,
and sustaining reliable operation. The enormous pace of advances in technology and
engineering and new economic practices cause rapid changes in consumer behavior
that create new dynamics as well as problems affecting the physical infrastructures
and the corresponding markets. Hence, more sophisticated and novel smart pricing
methods are required to control and take advantage of the demand-side dynamics.
Smart pricing refers to various techniques such as charging consumers depending
on the service usage time, setting location-based tariffs, and imposing prices based
on consumer activity levels. For instance, hourly and daily fluctuations in demand are
striking patterns that are common to both the Internet and the electricity grid as seen
in Figure 4.1. Considering this pattern, Internet service providers and mobile opera-
tors charge their subscribers based on the amount of data communicated or the time
of communication in order to alleviate congestion in the network [1, 2]. Similarly,
electricity usage also can be priced based on the amount or the time of consumption
so that daily fluctuations of the grid load are reduced [3].
The driving factors for smart pricing are the consumer characteristics and con-
sumers‚Äô economic incentives. Consumption amount, service usage time, demand pat-
terns over certain periods of time, and randomness of the load are several aspects of
the overall consumer behavior and they consequently affect the price setters‚Äô strate-
gies. On the other hand, consumer behavior is naturally responsive to the pricing
decisions because humans oversee their own economic welfare. Therefore, the result-
ing closed loop interactions are critical to the operation of the physical infrastructure
and the corresponding market in terms of reliability, stability, and efficiency.
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
69

70
PRICING UNDER DEMAND FLEXIBILITY AND PREDICTABILITY
3AM
9AM
3PM
9PM
1
1.1
1.2
1.3
System demand (MWh)
Day
Mon
Tue
Wed
Thu
Fri
1
1.1
1.2
1.3
System demand (MWh)
Week
700 k
600 k
500 k
400 k
300 k
200 k
100 k
0
700 k
600 k
500 k
400 k
300 k
200 k
100 k
0
29
30
01
02
03
04
05
18:00
20:00
22:00
00:00
02:00
04:00
06:00
08:00
10:00
12:00
14:00
16:00
Inbound
Outbound
Current:
Current:
306.72 k
548.55 k
Average:
Average:
236.41 k
423.71 k
453.97 k
781.07 k
Maximum:
Maximum:
Inbound
Outbound
Current:
Current:
315.30 k
566.63 k
Average:
Average:
240.52 k
431.56 k
398.59 k
780.82 k
Maximum:
Maximum:
Bits per second
Bits per second
Traffic graph
Traffic graph
Day
Week
RRDTOOL/TOBI OETIKER
RRDTOOL/TOBI OETIKER
(a)
(b)
Figure 4.1
Hourly and daily fluctuations in demand in different systems. Consumer activity
drops to minimum levels during late night, then increases significantly during the day to attain
its peak, and again drops during night. (a) Demand pattern at a basestation of a wireless network
operator, as measured by RRDTool [4, 5]. (b) Total hourly system demand as measured by ISO
New England [6].

PRICING UNDER DEMAND FLEXIBILITIES
71
Demand-side characteristics are increasingly exposed to the market because
of sophisticated control methods, ubiquitous communication capabilities, and
innovative market practices. For instance, the trend for deregulation in energy
markets, smart power meters for households, or advanced data gathering, tracking,
and management methods over the Internet causes the consumers to be more active,
more controllable, and more predictable. Therefore, the producers and intermediaries
have more incentives and possibilities to influence or directly control the consumer
behavior via smart pricing strategies in order to reduce costs and sustain stable
operation. In this chapter, we focus on demand-side flexibilities and the predictability
of consumer activities and discuss the means of exploiting these aspects of consumer
behavior by using smart pricing techniques.
Demand-side flexibilities usually comprise temporal elasticities involving defer-
ring loads until a specified deadline, shifting consumption within a certain period of
time, and using a service intermittently. Consumers, who are motivated by their eco-
nomic needs, are capable of exercising these flexibilities owing to technologies such
as intelligent devices with two-way communication capabilities and sophisticated
software applications that are able to manage user demand. Hence, consumers can
be incentivized to defer or shift their demand by time- and consumption-dependent
smart pricing methods as investigated in Section 4.2.
Predictability of consumer activities is a powerful capability reaped through the
significant advancement of machine learning algorithms and sophisticated statisti-
cal modeling tools [7‚Äì11]. It captures the correlated and repeated user behavioral
patterns over time, as well as the statistically anticipated future demand. The abil-
ity of suppliers/service providers to harness such an opportunity has a significant
potential in smoothing-out demand fluctuations over time, reducing commodity costs,
and enhancing the consumer satisfaction with high quality services. Essentially, sup-
pliers/service providers can proactively serve portions of the peak-hour load, ahead
of time, particularly during the off-peak hour, based on the anticipated demand of
each consumer. Hence, at the actual peak-demand instant, a considerable amount of
load will be already served and excessive costs will be avoided. Such a capability is
referred to as proactive service.
In the rest of this chapter, demand-side flexibility features are introduced in
Section 4.2, followed by an example design of pricing policies for the day-ahead
electricity markets with flexible demand in Section 4.2.1. In Section 4.3, the notion
of predictable user demand and proactive data service is discussed. Section 4.3.1
provides an example optimization of smart pricing policies for demand shaping and
proactive data services.
4.2
PRICING UNDER DEMAND FLEXIBILITIES
Flexibilities and responsiveness to price are intimately related aspects of consumer
behavior that have been present in almost all types of markets. In its simplest form,
consumers, who have the elasticity to be served earlier or later than their intended
time, can observe the market prices and decide on their time of consumption to
obtain economic benefits. Recently, consumers have more ground to exhibit their

72
PRICING UNDER DEMAND FLEXIBILITY AND PREDICTABILITY
temporal flexibilities in various markets, thanks to the rapid advances in technology
and engineering. For example, energy consumption controllers can manage the elec-
tricity usage of households by deferring tasks like using washing machines to late
night hours when the electricity price is lower [12]. Furthermore, as an increasingly
common measure in mobile software industry, smart applications have the ability
to regulate a mobile data user‚Äôs downloads considering the type of network connec-
tion (e.g., Wi-Fi and 4G) so that user‚Äôs payments are reduced or data plan limits are
not exceeded [13, 14]. It should also be noted that consumers, who are economically
driven entities, will have more motivation to employ their existing as well as emerging
flexibilities in order to obtain economic benefits.
Although the increased elasticity of the demand side brings in advantages to the
market, it also raises concerns that can be critical to the physical infrastructures and
the corresponding markets. The closed-loop system resulting from supply demand
interactions and the random fluctuating demand behavior have already created issues
such as existence of equilibrium prices and system stability under random variations.
These issues are further amplified by the increasing flexibility of the demand side.
As an example, consider the electricity grid that exhibits daily load fluctuations as
shown in Figure 4.1. It is beneficial for the grid to have shiftable demand that can
be activated during low demand hours to shave the peak load. As discussed earlier,
smart pricing policies can achieve this goal by incentivizing consumers to use their
devices during late night hours. However, higher penetration of demand flexibilities
into the market and increased price responsiveness of consumers may cause undesir-
able peaks in the grid load. Moreover, market prices may not reach equilibrium or
equilibria because of the high responsiveness of flexible consumers. Consequently,
the closed-loop dynamic system can exhibit increased volatility in price, supply, and
demand [15, 16].
Smart pricing strategies are anticipated to exploit the increased flexibility of
demand as well as alleviate the issues created by these flexibilities. Hence, smart
pricing is essential in influencing consumers and incentivizing them to practice their
flexibilities in order to cut down supplier costs and maintain reliable market operation
by lessening abrupt changes in prices and system load. For instance, time-dependent
pricing can be implemented to decrease the variability of the total load in mobile data
networks by establishing peak and off-peak prices and communicating them to the
subscribers to incentivize them to change their time of use and consumption amounts
[17]. In this section, we focus on the smart electricity grid to explore demand-side
flexibilities deeper with more specific examples. In the rest of the section, we study
two smart pricing methods that harness the temporal flexibilities of consumers to
obtain smoother grid load.
4.2.1
The Day-Ahead Electricity Market with Flexible Consumers
The smart electrical grid is coming into prominence as one of the systems that will be
extensively reaping the benefits of flexibilities in the demand side. The penetration
of information and communication technologies into the operation of the electrical
network transforms it into the smart grid [18]. This evolution turns the demand side

PRICING UNDER DEMAND FLEXIBILITIES
73
into a more controllable entity so that the resulting demand-side flexibilities can be
intensively exploited for more efficient grid operation [19‚Äì21].
The flexibilities of electricity consumers such as end users and distributers arise
in different forms. Changing the amount of consumption, shaping the demand pro-
file over a day or a week, delaying the activation of electric loads such as household
appliances or factory machines, and shifting the time of use of electricity through-
out the day are the type of flexibilities that can be harnessed for various objectives
[12, 22‚Äì24]. For example, smart meters in households can communicate to the load
aggregators or electricity retailers the usage preferences and load requirements of
consumers in response to electricity prices. Then, via energy consumption controllers
the electricity usage of household appliances can be administered by changing the
time of the activation of the individual devices as seen in Figure 4.2. In such a sce-
nario, the objective of the operator would be to decrease its costs while preserving
consumer satisfaction, and the consumers would benefit from lower prices or rewards
for their contribution [12, 25].
The methods that take advantage of demand-side flexibilities for efficient and
reliable grid operation can be collected under demand-side management or demand
response, which have recently drawn considerable attention in the engineering com-
munity [20, 21, 26, 27]. The common objective of these techniques is to alleviate the
fluctuations of the grid load in order to decrease the capital, operational, and mainte-
nance costs and increase robustness and reliability of the electrical grid. For example,
as a demand response technique, load aggregators and companies can participate in
the grid operation; they help the grid operator in smoothing out the grid load pro-
file by shedding their load when the operator signals them to do so [28]. It should
be noted that the parties involved in demand response are economically driven enti-
ties. Therefore, a viable way to implement sophisticated smart pricing schemes is to
incentivize the participants to expose their flexibilities such as the ability to shift or
delay load or to change consumption levels.
Flexible demand
Price
pn(t)
dm(t)
Operator
Smart consumers
Users
m
Time t 
User 3
User 2
User 1
Required 
energy
Service duration
Required power
level
Job waiting
queue 
Procurement cost:
production or
Market purchase  
Figure 4.2
Intermediaries such as load aggregators and retailers can control their customers‚Äô
demand by delaying the activation time of the individual tasks. Depending on the electricity
prices, the customers can adjust their preferences such as service deadlines.

74
PRICING UNDER DEMAND FLEXIBILITY AND PREDICTABILITY
In the literature, there are numerous works that utilize optimization and game
theoretic techniques to exploit the demand-side flexibilities in the electrical grid
by the help of smart pricing, For example, [12, 23, 24, 29‚Äì33]. In various works,
it is the key concept to build practically useful demand response models and to
devise corresponding distributed smart pricing algorithms [23, 30]. In general,
the objective is to achieve optimum social welfare, which is measured as the
aggregate system utility minus the total costs incurred. Toward this objective,
pricing algorithms are designed to incentivize the participating units to shift their
demand while maximizing their own utilities. In these problems, the presence of
supply uncertainty as well as the dynamics of the day-ahead and the real-time
planning can also be taken into account [24, 32]. Furthermore, game theoretic
approaches are also employed by formulating games between subscribers of utility
companies in order to develop distributed algorithms to reach the Nash equilibrium
[29, 31].
Although envisioned to significantly improve the grid efficiency, demand-side
flexibilities and economic incentives of consumers can have adverse effects on the
electrical grid operation [15]. For instance, the consumers with shiftable loads can
act opportunistically and greedily by purchasing the maximum amount of electricity
that they can at lower prices [16, 25, 34]. If a large number of such consumers
schedule their loads in the hour of the day with the lowest price, the total load in the
grid significantly deviates from its predicted daily pattern. In this case, the supply
deficit should be settled in a balancing market that incurs additional costs to both
suppliers and consumers [35]. Furthermore, if the market price quickly responds
to changes in load, intelligent consumer behavior creates high supply and price
volatility giving rise to a closed-loop system with stability problems [36].
Including the consumers with flexible demand together with the suppliers in
the electricity market is a feasible strategy to mitigate the adverse effects of the
demand-side flexibilities [35]. In the following, two smart pricing strategies are
presented for the day-ahead electricity market comprising multiple number of
suppliers and consumers where consumers can flexibly shift some of their total daily
demand within a day.
4.2.1.1
Day-Ahead Electricity Market Day-ahead electricity market is imple-
mented 1 day before the procurement of electric power. It involves transactions
between generator companies as suppliers and intermediaries such as load aggrega-
tors, distributors, and retailers as consumers. At the termination of the market, the
day-ahead prices are established.
The market is operated by a nonprofit third party called Independent System Oper-
ator (ISO). The ISO is responsible for administering the transactions between the
market participants, setting the day-ahead prices, determining generation and con-
sumption schedules, and ensuring the critical constraint of matching supply and load
at all times. The day-ahead schedules for the load, supply, and the price are computed
for the duration of a day that is divided into T time slots. The slotted time structure
models the appropriate durations, possibly ranging from minutes to hours, over which
the load-supply matching will be performed by establishing the day-ahead schedules.

PRICING UNDER DEMAND FLEXIBILITIES
75
The intermediaries are economically driven parties, so they naturally seek ways of
attaining lower prices. In order to increase their profit, the intermediary parties exploit
the demand-side flexibilities of their customers. Consequently, intermediaries appear
as flexible consumers to the day-ahead market by reflecting the flexibilities of the end
users. For instance, a load aggregator can shape its load by moving its customers‚Äô
shiftable loads to the times of the day with lower market prices. Hence, the load
aggregator becomes more price responsive as seen by the market operator.
We consider M generator companies (suppliers) and N intermediaries (consumers)
with flexible loads in the day-ahead market that is operated by an ISO.
1. Suppliers. At each time slot, generator m is required to provide the amount
of power that is determined by its supply schedule ùê¨m ‚âú(sm
t )T
t=1. By generating ùê¨m
amount of power over the time horizon, company m obtains pm(ùê¨m) of revenue from
the market, but it also pays Cm(ùê¨m) for generation costs.
Given the market prices, the goal of each generator company is to offer the sup-
ply schedule to the market that maximizes the company‚Äôs profit. Accordingly, the
optimization problem for generator company m is formulated as
max
ùê¨m‚â•ùüé
pm(ùê¨m) ‚àíCm(ùê¨m).
(4.1)
2. Consumers. Consumer n has a total Dn amount of load that has to be served
completely by the end of the time horizon. The load schedule of consumer n is defined
over the time slots as ùê±n ‚âú(xn
t )T
t=1, and it has to satisfy ‚àëT
t=1 xn
t = Dn. By consuming
ùê±n amount of power, consumer n pays pn(ùê±n) to the market and obtains Un(ùê±n) amount
of utility.
Consumer n aims to allocate its total daily load Dn at the most favorable time slots
based on its utility functions and market price. This objective is formulated as the
following optimization problem
max
ùê±n‚â•ùüé
Un(ùê±n) ‚àípn(ùê±n)
(4.2)
s.t.
T
‚àë
t=1
xn
t = Dn.
(4.3)
Demand-Side Flexibilities. The flexibility of consumer demand is modeled by
the utility function Un(ùê±n) together with the constraint to satisfy the predetermined
demand Dn over the scheduling horizon T. In particular, for the first algorithm, the
utility function is separable and additive over time, that is, Un(ùê±n) = ‚àëT
t=1 un
t (xn
t ),
whereas for the second algorithm the utility function is arbitrary, that is, no structure
such as convexity is assumed. For example, if a demand needs to be served over a
limited interval, say between slots t1 and t2, we can set un
t (x) = 0 for t ‚àâ{t1, ‚Ä¶ , t2}.
As another example, if a consumer has a higher preference for time slot t0 than for
time slot t, we set un
t0(x) ‚â•un
t (x). Such ordering over time between utility functions
can be utilized to model the scenario where a user wants its demand to be served at

76
PRICING UNDER DEMAND FLEXIBILITY AND PREDICTABILITY
0
5
10
15
20
0
0.5
1
Time (h)
(a)
(b)
Utility
 
 
Utility obtained for 10 kW
0
2
4
6
8
10
0
0.2
0.4
0.6
0.8
1
Energy consumption (kW)
Utility
 
 
t0 = 14 (preferred slot)
t = t0+1, t0‚àí1 
t = t0+2, t0‚àí2
Figure 4.3
Utility obtained per 10 kW energy consumed at each time slot (a) and utility
functions for different time slots (b) for consumer n with preferred time slot tn
0 = 14.
t0 and a disutility is imposed for every time slot in which the serving time is delayed,
as depicted in Figure 4.3.
3. ISO. The ISO‚Äôs objective is to maximize the social welfare, which is defined as
the total utility obtained by the participating entities in the market minus the total costs
incurred. While maximizing social welfare, the ISO is also responsible for matching
supply to load. This objective is formulated as
max
(ùê±n)N
n=1,(ùê¨m)M
m=1
N
‚àë
n=1
Un(ùê±n) ‚àí
M
‚àë
m=1
Cm(ùê¨m)
(4.4)
s.t.
N
‚àë
n=1
xn
t ‚â§
M
‚àë
m=1
sm
t ,
‚àÄt ‚àà{1, ‚Ä¶ , T},
(4.5)
T
‚àë
t=1
xn
t = Dn,
‚àÄn,
(4.6)
xn
t ‚â•0, sm
t ‚â•0,
‚àÄn, m, t,
(4.7)
where the constraint (4.5) is for matching supply to load and the constraint (4.6) is
for satisfying each consumer‚Äôs demand over the time horizon.

PRICING UNDER DEMAND FLEXIBILITIES
77
Remark 4.1 (Distributed solutions).
The knowledge of the cost and utility func-
tions are required by the ISO to solve the welfare problem (4.4). However, this infor-
mation is private to the market participants. Noting that the suppliers and the con-
sumers are economically driven parties who aim to maximize their own welfare, it is
more desirable to obtain distributed solutions.
Next, two distributed algorithms that achieve the optimum solution of the social
welfare problem are presented under different sets of assumptions. In the first algo-
rithm, we assume that the cost and the utility functions possess various convexity and
smoothness properties. In the second algorithm, on the contrary, we do not restrict
ourselves to any particular class of cost and utility functions. Instead, we simply
assume that the feasible set of the social welfare problem is finite and discrete.
4.2.2
Optimal Time-Dependent Pricing under Convexity Assumptions
In this setup, cost and utility functions assume convexity properties:
1. Suppliers. Electric power plants exhibit a two-level cost structure: generation
costs and ramp up/down costs. Ramp up/down costs are associated with the changes in
the power output of a generator. Furthermore, both types of costs can be time-varying.
Hence, the following multi-time scale cost function can be used for the generator
company m:
Cm(ùê¨m) =
T
‚àë
t=1
f m
t (sm
t ) +
T‚àí1
‚àë
t=1
gm
t (|sm
t+1 ‚àísm
t |).
(4.8)
Assumption 4.1 (Convex costs). Generation cost function f m
t (s) and ramp up/down
cost function gm
t (s) are increasing and strictly convex in s ‚â•0 for all t and m.
Remark 4.2 (Ramp Costs).
The cost structure with convex ramp up/down costs
also captures the hard limits on ramping amounts while giving a tractable mathe-
matical formulation for analysis. For instance, quadratic functions penalize changes
in generation between consecutive time slots with increasingly higher costs. Intu-
itively, the given cost structure is tantamount to the Lagrangian relaxation of equality
constraints in duality theory.
2. Consumers: Similarly to the suppliers, time-dependent utility functions can be
used to capture the consumer satisfaction. Specifically, the total utility that consumer
n gets from its load schedule ùê±n can be expressed by
Un(ùê±n) =
T
‚àë
t=1
un
t (xn
t ).
(4.9)
We make the following assumption on utility functions:

78
PRICING UNDER DEMAND FLEXIBILITY AND PREDICTABILITY
Assumption 4.2 (Concave utilities). Consumer utility function un
t (x) is increasing
and strictly concave in x ‚â•0 for all t and n.
The objective function in Eq. (4.4) is concave because of Assumptions 1 and 2,
and the constraints (4.5)‚Äì(4.7) define a convex set. Hence, the optimization problem
is a convex program and it has a unique global optimum. Furthermore, the objective is
separable over the consumer set. These observations motivate the use of well-known
dual optimization methods, and one such algorithm, which results in time-dependent
market prices and achieves the optimal solution of problem (4.4), is given in Refer-
ences 37 and 38.
4.2.3
Optimal Bundle Pricing under Discreteness Assumptions
Although the cost and utility structures of Section 4.2.2 cover a wide range of sup-
plier and consumer characteristics, convexity assumptions can be quite restrictive as
well. For instance, power plants usually consist of multiple generating units; hence,
activation and deactivation costs introduce discontinuities to the total cost [39]. On
the other hand, obtaining zero utility when a task is not processed and obtaining a
constant level of utility when a task is processed are a common consumer character-
istics that result in discontinuous and nonconcave utility functions. Therefore, in this
setup, the utility and cost functions are not assumed to have any particular structure.
Instead, the following assumption facilitates the development.
Assumption 4.3 (Discrete and finite feasible set). The feasible set for the social
welfare problem is finite and discrete.
This assumption is practically meaningful because the amount of supplied and
demanded power can be well approximated by quantization with sufficiently small
bins. For instance, the production bids from the generating units can be easily
enforced to be multiples of kilowatt or megawatt.
The idea leading to the distributed bundle pricing algorithm is based on linearizing
the problem (4.4) and then solving the linear program with distributed primal-dual
methods. Note that the linearized problem would be still difficult to solve because
of the arbitrary structures of the cost and utility functions. However, optimality of
the primal-dual solutions for a linear problem can be established via complementary
slackness (CS) conditions, which introduce further simplifications. In particular, the
market participants‚Äô common objective is maximizing their own welfare; hence, the
local solutions possess certain properties on the maximal values of the primal and dual
variables. The reader is referred to References 37 and 38 for the detailed derivations
of the algorithm presented here and to References 40 and 41 for a thorough study of
primal-dual methods for linear programs.
The distributed bundle pricing algorithm, which achieves the optimal value of the
problem (4.4), is depicted in Figure 4.4. In the algorithm, ùúãn
x and ùúãm
s are the sur-
plus terms for consumer n and supplier m, respectively; ùúãis the surplus term for the
overall market transactions; and pn(ùê±n) and pm(ùê¨m) are the bundle prices for the pro-
duction and consumption schedules ùê±n and ùê¨m, respectively. Bundle prices are for

PRICING UNDER DEMAND FLEXIBILITIES
79
œÄ(0) = max
(x,s)
œÄn 
x (0) = max Un(xn) ‚àí pn(xn)
xn
œÄm
s (0) = max pm(sm) ‚àí Cm(sm)
œÄ(k + 1), œÄn 
x(k + 1), œÄm
s (k + 1), pn(xn)(k + 1), pm(sm)(k + 1).
sm
sm‚ààSm
n
m
pn(xn)
pm(sm)
Œ£
Œ£
‚àí
pm(sm)(k)
sm(k)
pm(sm)(k + 1)
pn(xn)(k + 1)
xn(k)
pm(sm)(k) ‚àí Cm(sm)
pn(xn)(k), pm(sm)(k) are the cooresponding bundle prices.
sm(k) = arg max
xn‚ààœán
Un(xn) ‚àí pn(xn)(k)
xn(k) = arg max
pn(xn)(k)
Supplier m computers:
Consumer n computers:
ISO check the CS conditions:
Satified ‚áí xn(k), sm(k) are the optimum schedules:
Not satified ‚áí Solve the restricted dual problem, update
Supplier m
Smart consumer n
Market
operated by ISO
Figure 4.4
Distributed bundle pricing algorithm obtained by the primal-dual method under
discreteness assumptions.
the schedules over the whole optimization horizon T, and they are specific to mar-
ket participants. The initialization step of the algorithm and the fact that the market
participants solve their own local problems simplifies the process of verifying CS
conditions for the ISO [38].
Remark 4.3 (Complexity of solving the problem).
The market participants are
required to solve their own welfare problems which can be hard to solve due to the
arbitrary structure of the utility and cost functions. Nevertheless, the highly complex
problem of the ISO in Eq. (4.4) is decomposed into smaller problems that can be more
manageable for the individuals.
4.2.4
Numerical Examples and Insights
For the numerical experiments, consumer utility functions of the form un
t (x) =
(x+1)1‚àïùõΩn
t ‚àí1 are used, where un
t (x) is strictly concave in x for ùõΩn
t > 1. For the gener-
ator company, functions f m
t (s) = (1‚àïùõºm
t
) sùõºm
t for generation costs and gm
t (ùõøs) = ùúåm
t |ùõøs|
for ramp costs are used, where f m
t (s) is strictly convex in s for ùõºm
t > 1.
In the numerical setup, which represents a typical urban area and its surroundings,
there are N = 20 consumers (load aggregators) with flexible loads, M = 10 generator

80
PRICING UNDER DEMAND FLEXIBILITY AND PREDICTABILITY
companies, and the schedules are determined for the next 20 time slots. Parameters ùõΩn
t ,
ùõºm
t , and ùúåm
t are selected randomly for each participant such that the convexity assump-
tions are satisfied. For simplicity, the generator cost parameters are set identical for
all time slots, that is, ùõºm
t = ùõºm and ùúåm
t = ùúåm for all t. On the other hand, to model the
flexibilities a preferred time slot tn
0 is randomly chosen for each consumer n and ùõΩn
tn
0
value is assigned randomly. Then, for other time slots, t ‚â†tn
0 ùõΩn
t is increased as the dif-
ference |t ‚àítn
0| gets larger, that is, ùõΩn
t = ùõΩn
tn
0ùúà|t‚àítn
0| with ùúà> 1. With this construction,
un
t0(x) > un
t¬±1(x) > un
t¬±2(x) > ‚Ä¶ for all x > 0 is obtained. The described characteristics
of the utility functions used in the numerical examples are demonstrated in Figure 4.3.
It is worth noting that the specific flexibilities of different loads or devices that belong
to a single consumer are not considered in this utility model.
Furthermore, in order to model a realistic market environment and to investigate
the effects of the flexible load on electricity market, inflexible load, which does not
shift between time slots, is introduced. Inflexible load has a sinusoidal pattern that
effectively models fluctuations in electric load during the course of a day. In the
numerical example, the total flexible load is set to approximately 5% of the inflexible
load.
Figure 4.5a displays the load allocation achieved by the time-dependent dis-
tributed pricing algorithm. As expected, the flexible consumers are incentivized to
shift their demand to the time slots where inflexible load has the lowest concentration
and, hence, the lowest prices occur. Moreover, prices at these time slots show a
fairly smooth behavior. This is similar to the desired output of demand response
mechanisms (e.g., [30]) that stack more load or shed load when a surplus or deficit
in supply, respectively, is predicted.
For comparison, a baseline day-ahead pricing scheme is also examined in which
flexible consumers do not participate; price schedule is determined based on the
inflexible load. In this scheme, each flexible consumer decides on its load schedule
that maximizes its utility based on the already-settled day-ahead prices. Resulting
price schedule and load allocation are presented in Figure 4.5b, where it is observed
that the flexible load concentrates at the time slots where the lowest prices are wit-
nessed. Nevertheless, this is an expected outcome because all the flexible consumers
can opt to serve their demand at time slots with low price as long as their flexibilities
are loose enough. Furthermore, although the consumers with flexible demand maxi-
mize their welfare, the generator companies suffer high production costs that are not
compensated by the market price.
4.3
PRICING UNDER PREDICTABLE DEMAND
Recent studies on human behavioral patterns have asserted that the activities of
humans are highly predictable [7‚Äì11, 42]. These findings are strengthened by the
success of existing machine learning and statistical modeling tools that harness such
a predictability in characterizing customer interests and preferences. Yet, several
prediction capabilities are considerably underutilized in the direction of resource
allocation and demand management.

PRICING UNDER PREDICTABLE DEMAND
81
2
4
6
8
10
12
14
16
18
20
6
8
10
Time (h)
Price ($)
Market price
2
4
6
8
10
12
14
16
18
20
5
6
7
8
Time (h)
(a)
(b)
Energy (MW)
Inflexible load
Total load
2
4
6
8
10
12
14
16
18
20
6
8
10
Time (h)
Price ($)
Market price
2
4
6
8
10
12
14
16
18
20
5
6
7
8
Time (h)
Energy (MW)
Inflexible load
Total load
Figure 4.5
Smoother load allocation is achieved by the distributed time-dependent pricing
algorithm. (a) Price and load schedules obtained by the distributed time-dependent pricing
algorithm. (b) Price and load schedules obtained by the baseline scheme.

82
PRICING UNDER DEMAND FLEXIBILITY AND PREDICTABILITY
In data networks, for example, service providers incur a proportional cost because
of the resources harnessed in data delivery. These costs typically vary on a timely
basis depending on the consumer activities. For instance, Figure 4.1 a shows that the
demand on data services consistently drops to minimum levels during late night and
early morning hours. Peak demand, however, occurs during the noon and early night
hours. Coupling this observation with the fact that energy costs grow superlinearly
with the total load (see, e.g., [43‚Äì48]), service providers are urged to substantially
shape the users demand over time in order to render it evenly distributed and min-
imize excessive peak costs. This can be realized through proactive data services, a
resource allocation paradigm that utilizes the predictability of the user demand in
load balancing as follows.
Essentially, data items with high popularity can be partially delivered and stored
on the devices of respective consumers during the off-peak hour, that is, when the
demand levels are reasonably low. These portions can then be pulled directly from
the devices at the actual instant of demand, which is projected to occur during the
peak hour. Thus, only the unserved parts will need to be supplied as actual demand
during the peak hour, and service providers effectively cut down extreme peak-hour
costs, while attaining a higher level of consumer satisfaction [49‚Äì55]. Besides cost
minimization, consumers will experience a better quality of service (QoS) perfor-
mance in terms of service delays, and buffering. Figure 4.6 provides an illustration
of the load patterns under proactive data service.
The quality of proactive service, however, relies heavily on the accuracy of pre-
dictions made. While the randomness associated with the demand patterns may result
in an undesired confusion at the service provider, pricing incentives can be offered
so as to enhance the certainty about future demands. While the direct approach for
demand shaping offers discounts on the original price at the off-peak time to reg-
ulate the demand fluctuations (cf. [1, 17]), the pricing approach considered in this
section aims to render the users demand more deterministic, rather than changing
their activity times.
No longer served in
the peak hour
Load under proactive
service
Load under no
proactive service
Proactively served
load
Proactive service
Off-peakhour
Peak hour
Aggregate load
under no proactive
service
Aggregate load
under proactive
service
Time
Figure 4.6
Through proactive service capabilities, service providers can even the aggregate
load over time by partially serving the peak-hour demand during the preceding off-peak hour.

PRICING UNDER PREDICTABLE DEMAND
83
Such indirect approach yields price allocation strategies over data items and varies
from a user to another, that is, user and data-item-dependent pricing. With proactively
served items receiving lower prices, consumer demand can be efficiently shaped to
increase the likelihood of these items [50, 51], as discussed in the following sections.
4.3.1
Pricing for Demand Shaping and Proactive Download in Data Networks
This section is concerned with the joint design of proactive data service strategies
and pricing policies to minimize the expected service provider costs and to enhance
of the certainty about the random user demand.
To utilize the predicable demand capabilities, service providers need to have suf-
ficient knowledge regarding several aspects of their respective customers, a require-
ment that can be fulfilled through intelligent learning and tracking of the user inter-
actions. Such interactions include the following.
1. Activity Patterns. Each user has an intrinsic activity profile determined by the
time instants at which he/she requests data. Such activities depend on a variety of
elements, including age, type of work, education level, economical status, and so on.
The aggregation of user activity patterns by the service providers allows for a strong
acquaintance with the load levels over time (like in Fig. 4.1) and gives meaningful
estimates about the cost dynamics. This can particularly be captured by the parameter
qn,t, which is the probability that user n will remain silent at time t. Thus, the user
requests a data item with probability 1 ‚àíqn,t.
2. Interests and Preferences. These represent a key element that characterizes the
demand of each user when active. For instance, between two lectures, a student may
decide to watch a YouTube video, thus becoming active with respect to the YouTube
service provider. Now, among the available collection of YouTube videos, he/she
selects a specific comedy movie. Such a choice is governed by the user‚Äôs perception
of this video, which ultimately is tied to his/her own interests and preferences. Several
service providers, such as Netflix, Hulu, and YouTube, already employ sophisticated
collaborative filtering techniques (cf. [56‚Äì59]) in order to infer these quantities. Nev-
ertheless, they can further be utilized in proactive data services, as discussed in the fol-
lowing section. In the sequel, the vector ùêØn ‚à∂= (vn(m))M
m=1, with vn(m) ‚àà[0, 1], repre-
sents the valuation (or rating) of data item m (m = 1, ¬∑ ¬∑ ¬∑ , M) as recognized by user n.
3. Economical Responsiveness. As users belong to a variety of economic classes,
their responses to a service price differs from one to another, even though they
might share the same interest in such a service. Rich users, for example, may pay
for an expensive data item as long as it is well preferred. On the other hand, the rest
of the users, who equally prefer this data item, may decide not to buy this item in
favor of buying another cheaper one with a similar or slightly less quality. Service
providers can leverage the economical responsiveness to enhance the proactive
service performance.
The responsiveness of user n at time t depends on the price vector ùê≤n,t ‚à∂=
(yn,t(m))M
m=1, where yn,t(m) ‚àà[0, ymax] is the price of data item m as set by the

84
PRICING UNDER DEMAND FLEXIBILITY AND PREDICTABILITY
service provider to user n, and time t. The maximum allowable price for a data
item is ymax. Now, the economical responsiveness is measured by a function
ùúôm,t ‚à∂[0, ymax]M ‚Üí[0, 1] that maps pricing vectors into demand profiles. An
example mapping considered here is
ùúôm,t(ùê≤n,t) = (1 ‚àíqn,t)
vn(m)‚àïyn,t(m)
‚àëM
j=1 vn(j)‚àïyn,t(j)
,
‚àÄm, n, t.
(4.10)
The ratio of vn(m)‚àïyn,t(m) quantifies the utility of choosing item m, while dividing by
the sum of utilities for all data items captures the relative utility of choosing item m
among the M data items.
Figure 4.7 displays the above three aspects on a diagram illustrating the high level
operation of cost minimization and demand shaping through: proactive services and
pricing. While each user has a wide set of characteristics such as culture, age, educa-
tion, work, and economic state, the service provider can only observe his/her demand
and payments.
Examples for such service provider networks are Netflix and YouTube, which are
supposed to have a collection of M data items and N end users.
4.3.1.1
Demand Profiles The service provider can divide the operational time axis
into numerable time slots, t = 0, 1, ¬∑ ¬∑ ¬∑ to facilitate the cost optimization process and
efficiently enable proactive data services. To each time slot t, a demand profile for
user n (n = 1, ¬∑ ¬∑ ¬∑ , N) is constructed and denoted by ùê©n,t, where ùê©n,t ‚à∂= (Pn,t(m))M
m=1
is a collection of probabilities quantifying the demand of this user over the set of M
Service provider
Tracking &
learning
Optimizing & 
scheduling
Activity patterns
Interests & 
preferences
Economical 
responsiveness
Proactive service
Demand shaping prices
Demand
Payment
User
Culture
Education
Age
Work
Economical status
etc.
Figure 4.7
The cyclic interactions between the user and service provider taking place during
cost minimization under proactive data services.

PRICING UNDER PREDICTABLE DEMAND
85
data items, at that specific time slot. Further,
Pn,t(m) ‚à∂= ùúôm,t(ùê≤n,t).
Thus, Pn,t(m) is the probability that user n requests item m at time t when offered
a pricing vector ùê≤n,t. Naturally, the mapping ùúôm,t decreases in yn,t(m) and depends
implicitly on qn,t and ùêØn as manifested in Eq. (4.10).
The random variable ùêàn,t(m) describes the demand of user n to data item m at time
t, which is equal to 1 if such an event happens and is 0 otherwise. That given, the
distribution of ùêàn,t(m) is
ùêàn,t(m) =
{
1,
with probability Pn,t(m),
0,
with probability 1 ‚àíPn,t(m).
As a number of works suggest (cf. [9, 11, 17, 51]), the user activity patterns exhibit
a periodic behavior that typically repeats itself over a course of a single day, a result
that has been further manifested by the measurements depicted in Figure 4.1a and
extended in References 4 and 5. The service provider can divide the day into a cycle
of T time slots over which qn,t varies from one slot to another, but with qn,t = qn,kT+t,
for any positive integer k and time slot t = 0, ¬∑ ¬∑ ¬∑ , T ‚àí1. In other words, the activity
profile for every user n is cyclostationary with a period of T slots.
Remark 4.4 (Cyclostationary demand profiles).
With the service provider tar-
geting new pricing schemes in response to the users activity patterns, interests and
preferences, and economical responsiveness, the optimized prices are periodic and
the demand profile of every user is cyclostationary with period T.
Following Remark 4.4, the demand profiles satisfy ùê©n,t = ùê©n,t+kT for any user n,
time t, and nonnegative integer k. Figure 4.8 illustrates the periodic nature of user
demand statistics over time. With the introduced notation, the total load encountered
at slot t for a nonproactive network is given by
Lt ‚à∂=
M
‚àë
m=1
N
‚àë
n=1
S(m)ùêàn,t(m),
t ‚â•0,
(4.11)
with S(m) being the size of data item m.
pn,t + 1
pn,t + T ‚àí 1 pn,t
pn,t
pn,t + 1
Time
Demand profile
of user n at slot t
One cycle of T slots
Figure 4.8
Cyclostationary demand profiles.

86
PRICING UNDER DEMAND FLEXIBILITY AND PREDICTABILITY
In the following, the constructed demand profiles are harnessed in cost minimiza-
tion. Section 4.3.2 addresses the cost profile and proactive data service allocation,
while Section 4.3.3 discusses the pricing strategies leveraged to attain the new
profiles.
4.3.2
Cost Minimization via Proactive Data Service and Demand Shaping
The service provider seeks an optimal allocation of proactive data services, demand
profiles, and pricing policies attaining the optimized profiles to minimize the time
average cost of data delivery. The cost at each slot is typically a superlinear function
of the aggregate load denoted by C. Proactive downloads constitute a key enabling
parameter to the optimization framework and are modeled as follows. The proactive
download value of data item m at time t + 1 is denoted by xn,t+1(m) ‚â§S(m) and served
to user n at time slot t. Such proactive downloads are assumed to take place only
for the one-slot-ahead data; hence, take into account the potential items receiving
fast updates (as some YouTube channels, and social networks experience fast update
rates). The vector ùê±n,t+1 ‚à∂= (xn,t+1(m))M
m=1 captures all the proactive downloads made
to user n at time t.
The resulting aggregate load at the service provider in time slot t can be written in
terms of Lt as
Lt +
‚àë
m,n
xn,t+1(m) ‚àíxn,t(m)ùêàn,t(m).
(4.12)
Figure 4.9 illustrates the dynamics of proactive downloads for some user n at time t.
The service provider now can optimize over the proactive downloads ùê±, demand
profiles ùê©, and pricing policies ùê≤to minimize its time average expected cost as
User n
Service provider
Content
update
S(m) ‚àí xn,t(m)
Œ£ xn,t + 1(m)
Slot
t
Slot
t + 1
Time
Data request for item m
Time
Figure 4.9
Dynamics of proactive downloads for a single user.

PRICING UNDER PREDICTABLE DEMAND
87
minimize
ùê±,ùê©,ùê≤
1
T
T‚àí1
‚àë
t=0
ùêÑ
[
C
(
Lt +
‚àë
m,n
xn,t+1(m) ‚àíxn,t(m)ùêàn,t(m)
)]
subject to
0 ‚â§xn,t(m) ‚â§S(m),
‚àÄm, n, t = 0, ¬∑ ¬∑ ¬∑ , T ‚àí1,
User flexibility measures
(4.13)
Economical responsiveness
(4.14)
ùê±n,0 = ùê±n,T,
‚àÄn.
(4.15)
The following remarks about the above formulation can be made.
Remark 4.5 (User flexibility). The constraints (4.13) are posed to provide a guar-
antee on the user satisfaction under demand shaping. Essentially, the output modi-
fied profiles are not allowed to considerably deviate from the initial profiles (those
obtained under no demand shaping). These constraints protect the users from drastic
pricing policies, for otherwise service providers may abruptly influence the econom-
ical responsiveness to render the demand fully deterministic.
To elaborate further on the user flexibility, one can think of a service provider
that targets all users demand to be directed to the data item with the smallest size. It
can substantially raise the prices of the rest of data items. This will lead to a major
change in the demand profiles of those users who do not essentially prefer such an
item. Thus, users will feel unsatisfied about the quality of the cheap data items, with
the rest being overpriced.
One of the potential metrics that capture the user flexibility is the entropy of his/her
initial profile [60]. Given that user n is active at time t, then the initial probabil-
ity of requesting item m is denoted by ÃÉùúãn,t(m), with the normalized profile ÃÉùùÖn,t ‚à∂=
( ÃÉùúãn,t(m))M
m=1. The entropy of such a profile H(ÃÉùùÖn,t) quantifies the certainty about the
users demand. High values of entropy reflect an indeterministic user who equally
prefers any of the offered data items. On the other hand, small values of entropy reveal
a deterministic user, who is more specific about the content to choose. Hence, high
entropy users exhibit more flexibility to change their demand in response to pricing
policies, whereas low entropy ones are typically less flexible.
Coupling this observation with the notion that deterministic users facilitate proac-
tive data downloads, the user flexibility measure can be realized by an M-dimensional
ball centered at the initial normalized profile with a radius proportional to the entropy
of that profile [51]. This is called the entropy-ball constraint (EBC). Figure 4.10
depicts an illustrating shape for the EBC with M = 3.
Remark 4.6 (Economical responsiveness).
By considering the economical
responsiveness constraints (4.14), price allocation is required to attain the optimized
demand profiles through the mapping ùúôm,t. As the objective function does not directly
involve pricing, the optimization can be conducted first over proactive downloads
and demand profiles and then price allocation step can be carried out separately to
achieve the optimal profiles.

88
PRICING UNDER DEMAND FLEXIBILITY AND PREDICTABILITY
(0,0,1)
(1,0,0)
(0,1,0)
Zero entropy at corner
points implies
deterministic demand
M-point
simplex
~
n,t(1)
œÄ
~
n,t(2)
œÄ
~
n,t(3)
œÄ
Maximum entropy center
point ( 1/3,1/3,1/3)
implies unpredictable or
flexible demand
Entropyball
constraint
Figure 4.10
An example of M = 3 data items that user n can choose from in slot t. Entropy
ball shrinks to a zero radius at the corner points and attains a maximum radius at the center
point.
Price allocation strategies that utilize the economical responsiveness knowledge
are addressed in more detail in Section 4.3.3.
Remark 4.7 (Infinite-horizon cost minimization).
The set of constraints (4.15)
posed above ensures that the optimization over one cycle (or a day) is sufficient to
minimize the infinite-horizon time average expected cost.
Detailed proof of this result is detailed in Reference 50.
Remark 4.8 (Inflexible users).
Under no demand shaping, proactive downloads
only can be employed to smooth-out the network traffic over time and leverage sig-
nificant cost reduction gains.
In Reference 50 the cost reduction via proactive downloads only is proven to
scale with the number of users at least as the first derivative of the cost function
does. Figure 4.11 depicts the effect of proactive downloads on the network load. The
expected load is considerably balanced through optimal proactive services as com-
pared to that of reactive allocation strategies.
Remark 4.9 (Nonconvexity of the optimization).
In general, the optimization
problem is nonconvex, even under a convex cost function C [61]. The reason is the
product form of xn,t(m)ùêàn,t(m) with both xn,t(m) and ùêàn,t(m) being optimization vari-
ables. This gives rise to potentially suboptimal, but efficient, solutions through suc-
cessive approximations of convex problem.
In Reference 51, an iterative algorithm has been developed, under a convex cost
function C. The algorithm starts with a point (ÃÉùê±, ÃÉùê©), where ÃÉùê©is the initial demand

PRICING UNDER PREDICTABLE DEMAND
89
5
10
15
20
25
30
35
40
0
20
40
60
80
Expected load
Time slots over 5 days (8 slots per day)
 
 
Smoothed-out load with proactive downloads
Normal load without proactive downloads
Figure 4.11
Expected total load under proactive downloads only with quadratic cost
function.
profiles and ÃÉùê±is the associated globally optimal1 proactive download. In other words,
the initial point is the result of optimal proactive downloads only without demand
shaping.
The algorithm applies a series of successive solutions to approximate convex opti-
mization problem, until it converges to a locally optimal solution of the original
problem (ÃÇùê±, ÃÇùê©), with a strictly lower cost than that of (ÃÉùê±, ÃÉùê©). That is, with demand
shaping, the system can leverage a strictly reduced cost beyond that of proactive
downloads only. A numerical example on this algorithm is provided in the following
section.
4.3.3
Pricing Policies Attaining Modified Profiles
Upon the calculation of the optimized profiles ÃÇùê©, the service provider assigns new
pricing policies, ùê≤, so that the users adjust their demand accordingly. Figure 4.12
illustrates this step for some user n at time slot t.
Generally, the mapping functions ùúôm,t capturing the economical responsiveness
can fit the optimized profiles through multiple pricing policies. The service provider
Economical responsiveness
Modified
demand profile
ÀÜpn,t
Itemized pricing
vector for user n
(
M
m=1
m,t
)
(vn, yn,t)
œï
‚àó
yn,t
Figure 4.12
Price allocation step utilizes the economical responsiveness of the users to attain
the optimized profiles.
1When the demand profiles are given, a convex cost function C yields a convex optimization problem in
ùê±. Hence, globally optimal ÃÉùê±is attainable. Full proof is given in Reference 50.

90
PRICING UNDER DEMAND FLEXIBILITY AND PREDICTABILITY
then needs to carefully select the best of such policies. One possible objective is the
maximization of the proportionally fair price allocation over all data items, users, and
time slots. That is,
maximize
ùê≤
T‚àí1
‚àë
t=0
M
‚àë
m=1
N
‚àë
n=1
log yn,t(m)
subject to
ÃÇPn,t(m) = ùúôm,t(ùê≤n,t(m)),
‚àÄm, n, t,
0 ‚â§yn,t(m) ‚â§ymax,
‚àÄm, n, t.
(4.16)
The optimization (4.16) can further be decoupled across time and users. With the
instance realization in Eq. (4.10), the service provider may solve a geometric pro-
gramming problem per user n and time slot t.
Remark 4.10 (General form of economical responsiveness). The choice of ùúôm,t
in Eq. (4.10) and the objective function of Eq. (4.16) are not the only possible choices
for the pricing problem. Instead, any general mapping and objective functions can
be incorporated depending on several factors including the system size, the type of
service, and so on. In the case of choices that yield a nonconvex pricing problem,
efficient local optimal solutions can still be achieved through approximate solutions.
The following example illustrates smart pricing for proactive download and
demand shaping under a quadratic cost function.
Example 4.1 Quadratic Cost Function
In this example, the cost incurred at the service provider takes a quadratic form of the
aggregate load, that is, C ‚à∂‚Ñù+ ‚Üí‚Ñù+, with C(L) = L2. The following assumptions
are used throughout the example.
(i) For any time slot t, ùêàn,t(m) is independent of ùêàn,t+1(j) for all m, j. (ii) For any two
users n, k such that n ‚â†k, ùêàn,t(m) is independent of ùêàk,t(j) for all m, j.
Setup. Suppose that the number of daily time slots is T = 2, one slot captures
the peak-demand dynamics, whereas the other captures the off-peak. Also, consider
a small system of N = 2 users and M = 3 data items with sizes ùêí= (3, 2, 4). The
activity of the users during the off-peak hour are qn,0 = 1 ‚àíp0, n = 1, 2 with p0 = 0.1.
At the peak hour, the activity is qn,1 = 1 ‚àíp1, n = 1, 2. The initial profiles of both
users during the off-peak hour are ÃÉùê©1,0 = p0 ‚ãÖ(0.8, 0.1, 0.1), ÃÉùê©2,0 = p0 ‚ãÖ(0.3, 0.1, 0.6).
Likewise, the same profile structure applies during the peak hour with p0 replaced by
p1. The parameters p0 and p1 represent the user activity during the off-peak and peak
hours.
Proactive Data Download without Demand Shaping. With the service provider
applying proactive data download to the initial profiles but not shaping them, the
allocation of such downloads is a convex problem. Under p1 = 0.9 > p0, only the
peak-hour load is partially served during the off-peak hour. That is, ÃÉùê±n,1 ‚âΩ0 but
ÃÉùê±n,0 = 0. Solving this problem for the above setup yields the initial feed (ÃÉùê±, ÃÉùê©) for
an iterative algorithm that jointly assigns proactive downloads and demand profiles.

PRICING UNDER PREDICTABLE DEMAND
91
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
œÄn,1(3)
œÄn,1(2)
œÄn,1(1)
Probability simplex
Entropy-ball
flexibility regions
Evolution of the
modified profile
Modified profile
ÀÜœÄ2,1 = (0.311,0.221,
          0.468)
Initial profile
Àú2,1 = (0.3,0.1,0.,0.6)
œÄ
ÀúœÄ1,1 = (0.8,0.1,0.1)
Modified profile
ÀÜœÄ1,1 = (0.877,0.122,
          0.001)
Figure 4.13
Evolution of demand profiles throughout the iterative algorithm. Optimized pro-
files always lie on the boundary of the flexibility regions.
Joint Proactive Download and Demand Shaping. Under the user flexibility met-
ric featuring the entropy-ball constraints developed, the iterative algorithm utilizes
successive solutions to approximate convex problems2 to guarantee that the resulting
cost is strictly less than that obtained under (ÃÉùê±, ÃÉùê©). Figure 4.13 depicts the evolution
of the demand profiles under such an algorithm. The resulting profiles are always
pushed to the boundary of the entropy-ball regions. Further, convergence takes place
in a relatively small number of steps.
Smart Pricing. Upon obtaining the new peak-hour profiles ÃÇùê©1,1 and ÃÇùê©2,1, the smart
pricing algorithm of Eq. (4.16) is invoked to assign new prices for the available items.
Assuming economical responsiveness ùúôm,t of Eq. (4.10), user preference vectors ùêØ1 =
(0.8, 0.1, 0.1) and ùêØ2 = (0.3, 0.1, 0.6), and maximum price ymax =$5, the results of the
simulations are summarized in Table 4.1. It should be noted that the modified profiles
always lie on the boundary of the entropy ball, as the service provider is interested in
pushing the profiles in the direction of the most deterministic behavior that minimizes
the cost. Interestingly, the second user receives the smallest price for the second data
items, which originally was the least likely to be requested. The reason is that the size
TABLE 4.1
Modified Profiles and Corresponding Prices
Modified
Modified
Item
Profile
Profile
Prices
Prices
Index
ÃÇùê©1,1‚àïp1
ÃÇùê©2,1‚àïp1
ùê≤‚àó
1,1, $
ùê≤‚àó
2,1, $
1
0.8772
0.3111
0.0274
3.7592
2
0.1222
0.2211
0.0246
1.7632
3
0.0006
0.4678
5.0000
5.0000
2Detailed algorithm is provided in References 50 and 51.

92
PRICING UNDER DEMAND FLEXIBILITY AND PREDICTABILITY
of this data item is smallest, so the service provider finds it more efficient to increase
the likelihood of this item for the second user than improving the certainty about the
third item, with a positive proactive download, because it has the largest size and,
hence, most contribution to the cost.
REFERENCES
1. C. Joe-Wong, S. Ha, and M. Chiang. ‚ÄúTime-dependent broadband pricing: feasibility
and benefits. In 2011 31st International Conference on Distributed Computing Systems
(ICDCS). IEEE, 2011, pp. 288‚Äì298.
2. S. Sen, C. Joe-Wong, S. Ha, and M. Chiang, ‚ÄúIncentivizing time-shifting of data: a survey
of time-dependent pricing for internet access,‚Äù IEEE Communications Magazine, 50(11),
2012, 91‚Äì99.
3. A. J. Wood and B. F. Wollenberg, Power generation, operation, and control. Wiley-
Interscience, Hoboken NJ, 2012.
4. IIT Wireless Services, Illinois Institute of Technology, 2013 [online]. Available:
http://www.iit.edu/ots/wireless.shtml
5. RRDtool Gallery, RRDtool, 2013 [online]. Available: http://oss.oetiker.ch/rrdtool/gallery/
index.en.html
6. Iso New England, historical data. Available at: http://www.iso-ne.com/markets/hstdata/
index.html
7. N. Eagle and A. Pentland. ‚ÄúReality mining: sensing complex social systems,‚Äù Personal
and Ubiquitous Computing, 10, 2006, 255‚Äì268.
8. K. Farrahi and D. Gatica-Perez. Discovering human routines from cell phone data with
topic models. In The 12th IEEE International Symposium on Wearable Computers,
pp. 29‚Äì32, 2008.
9. B. S. Jensen, J. E. Larsen, K. Jensen, J. Larsen, and L. K. Hansen. ‚ÄúEstimating human
predictability from mobile sensor data. 2010 IEEE International Workshop on Machine
Learning for Signal Processing (MLSP), pp. 196‚Äì201, Sept. 2010.
10. R. Kwok. ‚ÄúPersonal technology: phoning in data,‚Äù Nature, 458, 2009, 959‚Äì961.
11. C. Song, Z. Qu, N. Blumm, and A. Barabas. ‚ÄúLimits of predictability in human mobility,‚Äù
Science, 327, 2010, 1018‚Äì1021.
12. C. Joe-Wong, S. Sen, S. Ha, and M. Chiang, ‚ÄúOptimized day-ahead pricing for smart grids
with device-specific scheduling flexibility,‚Äù IEEE Journal on Selected Areas in Communi-
cations, 30(6), 2012, 1075‚Äì1085.
13. S. Higginbotham, ‚ÄúMobile operators want to charge based on time and apps,‚Äù gigaOm,
December 14 2010.
14. ‚ÄúThe Mother of Invention: Network Operators in the Poor World Are Cutting Costs and
Increasing Access in Innovative Ways,‚Äù Special Report, The Economist, September 24
2009.
15. D. Materassi, M. Roozbehani, and M. A. Dahleh. Equilibrium price distributions in energy
markets with shiftable demand. In 2012 IEEE 51st Annual Conference on Decision and
Control (CDC). IEEE, 2012, pp. 3183‚Äì3188.

REFERENCES
93
16. M. Roozbehani, A. Faghih, M. I. Ohannessian, and M. A. Dahleh, The intertemporal utility
of demand and price elasticity of consumption in power grids with shiftable loads. In
2011 50th IEEE Conference on Decision and Control and European Control Conference
(CDC-ECC). IEEE, 2011, pp. 1539‚Äì1544.
17. S. Ha, S. Sen, C. Joe-Wong, Y. Im, and M. Chiang. Tube: time-dependent pricing for
mobile data. In Proceedings of the ACM SIGCOMM 2012 Conference on Applications,
Technologies, Architectures, and Protocols for Computer Communication. ACM, 2012,
pp. 247‚Äì258.
18. H. Farhangi. ‚ÄúThe path of the smart grid,‚Äù IEEE Power and Energy Magazine, 8(1), 2010,
18‚Äì28.
19. D. Kirschen. ‚ÄúDemand-side view of electricity markets,‚Äù IEEE Transactions on Power
Systems, 18(2), 2003, 520‚Äì527.
20. P. Palensky and D. Dietrich. ‚ÄúDemand side management: demand response, intelligent
energy systems, and smart loads,‚Äù IEEE Transactions on Industrial Informatics, 7(3),
2011, 381‚Äì388.
21. G. Strbac. ‚ÄúDemand side management: benefits and challenges,‚Äù Energy Policy, 36(12),
2008, 4419‚Äì4426.
22. A. Papavasiliou and S. S. Oren. ‚ÄúSupplying renewable energy to deferrable loads: algo-
rithms and economic analysis,‚Äù In 2010 IEEE Power and Energy Society General Meeting.
IEEE, 2010, pp. 1‚Äì8.
23. N. Li, L. Chen, and S. Low. Optimal demand response based on utility maximization in
power networks. In 2011 IEEE Power and Energy Society General Meeting. IEEE, 2011,
pp. 1‚Äì8.
24. L. Jiang and S. Low. Multi-period optimal energy procurement and demand response in
smart grid with uncertain supply. In 2011 50th IEEE Conference on Decision and Control
and European Control Conference (CDC-ECC). IEEE, 2011, pp. 4348‚Äì4353.
25. S. Chen, N. Shroff and P. Sinha. Heterogeneous Delay Tolerant Task Scheduling and
Energy Management in the Smart Grid with Renewable Energy. Selected Areas in Com-
munications, IEEE Journal on, 31(7), 2013, 1258‚Äì1267.
26. M. H. Albadi and E. El-Saadany. Demand response in electricity markets: an overview. In
IEEE Power Engineering Society General Meeting, 2007. IEEE, 2007, pp. 1‚Äì5.
27. F. Rahimi and A. Ipakchi, ‚ÄúDemand response as a market resource under the smart grid
paradigm,‚Äù IEEE Transactions on Smart Grid, 1(1), 2010, 82‚Äì88.
28. R. Faranda, A. Pievatolo, and E. Tironi, ‚ÄúLoad shedding: a new proposal,‚Äù IEEE Transac-
tions on Power Systems, 22(4), 2007, 2086‚Äì2093.
29. A. Mohsenian-Rad, V. Wong, J. Jatskevich, and R. Schober. Optimal and autonomous
incentive-based energy consumption scheduling algorithm for smart grid. In Innovative
Smart Grid Technologies (ISGT), 2010. IEEE, 2010, pp. 1‚Äì6.
30. L. Chen, N. Li, S. Low, and J. Doyle. Two market models for demand response in power
networks. In IEEE SmartGrid Comm, 2010.
31. A. Mohsenian-Rad, V. Wong, J. Jatskevich, R. Schober, and A. Leon-Garcia, ‚ÄúAutonomous
demand-side management based on game-theoretic energy consumption scheduling for the
future smart grid,‚Äù IEEE Transactions on Smart Grid, 1(3), 2010, 320‚Äì331.
32. P. Samadi, A. Mohsenian-Rad, R. Schober, V. Wong, and J. Jatskevich. Optimal real-time
pricing algorithm based on utility maximization for smart grid. In 2010 First IEEE Inter-
national Conference on Smart Grid Communications (SmartGridComm). IEEE, 2010, pp.
415‚Äì420.

94
PRICING UNDER DEMAND FLEXIBILITY AND PREDICTABILITY
33. M. He, S. Murugesan, and J. Zhang. Multiple timescale dispatch and scheduling for
stochastic reliability in smart grids with wind generation integration. In 2011 Proceedings
IEEE INFOCOM. IEEE, 2011, pp. 461‚Äì465.
34. A. Faghih, M. Roozbehani, and M. Dahleh. Optimal utilization of storage and the induced
price elasticity of demand in the presence of ramp constraints. In 2011 50th IEEE Con-
ference on Decision and Control and European Control Conference (CDC-ECC). IEEE,
2011, pp. 842‚Äì847.
35. C. Su and D. Kirschen, ‚ÄúQuantifying the effect of demand response on electricity markets,‚Äù
IEEE Transactions on Power Systems, 24(3), 2009, 1199‚Äì1207.
36. M. Roozbehani, M. A. Dahleh, and S. K. Mitter. ‚ÄúVolatility of Power Grids Under
Real-Time Pricing,‚Äù IEEE Transactions on Power Systems, 27(4), 2012, 1926‚Äì1940.
37. O. Dalkilic, O. Candogan, and A. Eryilmaz. Pricing algorithms for the day-ahead electric-
ity market with flexible consumer participation. In The 2nd IEEE International Workshop
on Smart Data Pricing (SDP). IEEE, 2013.
38. O.
Dalkilic,
O.
Candogan,
and
A.
Eryilmaz.
Pricing
Algorithms
for
the
Day-Ahead Electricity Market with Flexible Consumer Participation. Available at:
http://www2.ece.ohio-state.edu/ dalkilio/pricealg2012.pdf, Tech. Rep., 2012 [online].
The Department of Electrical and Computer Engineering, The Ohio State University.
39. N. P. Padhy. ‚ÄúUnit commitment-a bibliographical survey,‚Äù IEEE Transactions on Power
Systems, 19(2), 2004, 1196‚Äì1205.
40. C. Papadimitriou and K. Steiglitz. Combinatorial Optimization: Algorithms and Complex-
ity. Dover Publications, New York, 1998.
41. D. Acemoglu, O. Candogan, A. Ozdaglar, and P. Parrilo. ‚ÄúIterative auction design for
graphical valuations,‚Äù 2012.
42. H. Yu, D. Zheng, B. Y. Zhao, and W. Zheng. Understanding user behavior in large-scale
video-on-demand systems. In EuroSys‚Äô06, 2006.
43. A. Nag, M. Tornatore, and B. Mukherjee. ‚ÄúEnergy-efficient and cost-efficient capacity
upgrade in mixed-line-rate optical networks,‚Äù IEEE/OSA Journal of Optical Communica-
tions and Networking, 4(12), 2012, 1018‚Äì1025.
44. Y. Wu, P. A. Chou, and S.-Y. Kung. ‚ÄúMinimum-energy multicast in mobile ad hoc net-
works using network coding,‚Äù IEEE Transactions on Communications, 53(11), 2005,
1906‚Äì1918.
45. K. Bicakci, H. Gultekin, and B. Tavli. ‚ÄúThe impact of one-time energy costs on net-
work lifetime in wireless sensor networks,‚Äù IEEE Communications Letters, 13(12), 2009,
905‚Äì907.
46. M. K. Karray. ‚ÄúAnalytical evaluation of QoS in the downlink of OFDMA wireless cellular
networks serving streaming and elastic traffic,‚Äù IEEE Transactions on Wireless Commu-
nications, 9(5), 2010, 1799‚Äì1807.
47. L. Z. Ribeiro and L. A. DaSilva. ‚ÄúA framework for the dimensioning of broadband mobile
networks supporting wireless Internet services,‚Äù IEEE Wireless Communications, 9(3),
2002, 6‚Äì13.
48. X. Zheng and Y. Cai. Reducing electricity and network cost for online service providers
in geographically located internet data centers. In IEEE/ACM International Conference
on Green Computing and Communications (GreenCom), 2011, pp. 166‚Äì169, 4‚Äì5 Aug.
2011.

REFERENCES
95
49. J. Tadrous, A. Eryilmaz, and H. El Gamal. ‚ÄúProactive resource allocation: harnessing the
diversity and multicast gains,‚Äù IEEE Transactions on Information Theory, 2013, DOI:
10.1109/TIT.2013.2257911.
50. J. Tadrous, A. Eryilmaz, and H. El Gamal. ‚ÄúProactive data download and user demand
shaping for data networks,‚Äù IEEE Transactions on Information, 59(8), 2013, 4833‚Äì4854.
submitted. Also available on: http://arxiv.org/pdf/1304.5745.pdf.
51. J. Tadrous, A. Eryilmaz, and H. El Gamal. Pricing for demand shaping in proactive data
networks. In The 2nd IEEE International Workshop on Smart Data Pricing (SDP), April
2013.
52. J. Tadrous, A. Eryilmaz, and H. El Gamal. Proactive content distribution for dynamically
changing content. In Proceedings of 2013 IEEE International Symposium on Information
Theory (ISIT), July 2013.
53. J. Tadrous, A. Eryilmaz, and H. El Gamal. Proactive resource allocation in cognitive radio
networks. 2011 Conference Record of the Forty Fifth Asilomar Conference on Signals,
Systems and Computers (ASILOMAR), pp. 1425‚Äì1429, 6‚Äì9 Nov. 2011.
54. J. Tadrous, A. Eryilmaz, and H. El Gamal. Proactive multicasting with predictable
demands. 2011 IEEE International Symposium on Information Theory Proceedings (ISIT),
pp. 239‚Äì243, July 31 2011-Aug. 5 2011.
55. H. El Gamal, J. Tadrous, and A. Eryilmaz. Proactive resource allocation: Turning pre-
dictable behavior into spectral gain. In 2010 48th Annual Allerton Conference on Commu-
nication, Control, and Computing (Allerton), pp. 427‚Äì434, Sept. 29 2010-Oct. 1 2010.
56. Z. Huang, D. Zeng, and H. Chen. ‚ÄúA comparison of collaborative-filtering recommenda-
tion algorithms for e-commerce,‚Äù IEEE Intelligent Systems, 22(5), 2007, 68‚Äì78.
57. T. L. Wickramarathne, K. Premaratne, M. Kubat, and D. T. Jayaweera. ‚ÄúCoFiDS: a
belief-theoretic approach for automated collaborative filtering,‚Äù IEEE Transactions on
Knowledge and Data Engineering, 23(2), 2011, 175‚Äì189.
58. J. Salter and N. Antonopoulos. ‚ÄúCinemaScreen recommender agent: combining collabo-
rative and content-based filtering,‚Äù IEEE Intelligent Systems, 21(1), 2006, 35‚Äì41.
59. L. Kozma, A. Ilin, and T. Raiko. Binary principal component analysis in the Netflix col-
laborative filtering task. In IEEE International Workshop on Machine Learning for Signal
Processing, 2009. MLSP 2009, pp. 1‚Äì6, 1‚Äì4 Sept. 2009.
60. T. Cover and J. Thomas. Elements of Information Theory. Wiley ‚àíInterscience, Hoboken
NJ, 2006.
61. S. Boyd and L. Vandenberge. Convex Optimization. Cambridge University Press, United
Kingdom, Cambrdige, 2004.


5
Dual Pricing Algorithms by
Wireless Network Duality
for Utility Maximization
CHEE WEI TAN and LIANG ZHENG
5.1
INTRODUCTION
As wireless networks are becoming more heterogeneous and ubiquitous in our life, it
is also becoming more difficult to allocate wireless resources and price them. A wire-
less service provider, through the dynamic measurement of network conditions, for
example, interference, channel variation, number of users, and users‚Äô mobility, can
put in place a data pricing policy that determines a price for wireless resource alloca-
tion according to the type of demand for these resources. Recently, smart wireless data
pricing has become an important topic of research [1‚Äì11]. An effective pricing algo-
rithm can lead to more efficient use of the limited resources in the system and increase
the overall utility or revenue [12‚Äì14]. A pareto optimal utility can be achieved using
suitable pricing that reflects the amount of resources being consumed [11]. The goal
of pricing is thus to encourage users to adopt a social behavior that maximizes social
welfare rather than a purely noncooperative, that is, myopic and greedy, approach
to resource allocation, which can lead to unfairness or unstable network conditions.
How should wireless resources in large-scale heterogeneous wireless networks be
analyzed and designed with clearly defined fairness and optimality in mind?
Wireless network optimization optimally matches the demand and supply of wire-
less resources subject to network constraints [15, 16]. Roughly speaking, it requires
solving a constrained optimization problem to maximize a system objective subject
to the demand and supply constraints of data services in addition to the diverse QoS
constraints, interference, congestion, fairness, heterogeneity in wireless technologies,
market power factors, and so on. It is common to specify the objective as the total
social welfare of all the users, and a widely used social welfare is the sum of utilities.
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
97

98
DUAL PRICING ALGORITHMS BY WIRELESS NETWORK DUALITY
Another possible objective is the egalitarian fairness of the system. If only a portion
of the users experiences better network conditions than other users, the pricing algo-
rithm can drive the prices very high for users in the system at a time of congestion
and high interference, exposing some users to unfairness. It is thus important that an
optimal data pricing algorithm be designed through a judicious optimization of the
wireless network utility.
Wireless network utility maximization is intimately related to the signal-to-
interference-and-noise-ratio (SINR) assignment for all users. A shadow price
associated with SINR assignment constraints determines the performance received
by the user. Given a set of power budget and interference temperature constraints,
the SINR assignment of all users must be jointly coordinated, but there are two
major hurdles that need to be overcome. First, algorithms that adapt the transmit
power and interference temperature based on allocated SINR targets assume that the
SINR targets are within the feasibility region, which, however, requires a centralized
admission controller. Second, the algorithms have to be decentralized, practical to
deploy, and be fast enough with minimal or, preferably, no parameter tuning. This
is especially important because secondary users can arrive and depart in a dynamic
setting, and so resources have to be adapted fast enough to converge to a new
optimal operating point whenever the network conditions change. This, however,
is challenging because of the tight coupling between primary and secondary users
in the SINR assignment. It is desirable that the resource allocation for primary and
secondary users be distributed with minimal overhead.
There are several works that partially address these two challenges in the litera-
ture. Hande et al. [17] study the SINR assignment in the context of wireless cellular
networks by a reparameterization of the feasible SINR region and propose a load
and spillage algorithm that jointly updates the SINR assignment and power. This
algorithm, however, confines the optimality by considering a reduced feasible SINR
region. Huang et al. [18] propose algorithms to coordinate the secondary users by
sensing a feedback signal from the primary users‚Äô interference temperature condition
to reduce outage but do not address the joint optimal SINR assignment and power
allocation. Lotfinezhad et al. [19] propose a radio admission control and scheduling
policy, which, however, does not handle the interference temperature constraint. To
coordinate the interference temperature by controlling the SINR assignment, Ragan
and Madan [20] propose a belief propagation framework by wireless scheduling to
solve a nonconvex utility maximization problem. Utility maximization algorithms
using fractional frequency reuse have been proposed in References 21 and 22 for
wireless cellular networks. Krishnan and Luss [23] consider a joint SINR assignment
and power control to maximize the worst-case SINR with an interference temperature
constraint. In Reference 24, this optimization of the egalitarian fairness of SINR is
solved for individual power constraints using a nonlinear Perron‚ÄìFrobenius theory.
The main contributions of this chapter are summarized as follows.
‚Ä¢ We solve the wireless network utility maximization problem by parameterizing
the global optimality in terms of SINR assignment, power and interference tem-
perature allocation as optimization problems having spectral radius constraints.

UTILITY MAXIMIZATION
99
These spectral radius constraints capture fundamental characteristics of the
underlying competition for resources. A special case that maximizes the
egalitarian fairness of all the SINRs as the utility is solved optimally using a
tuning-free geometrically fast convergent algorithm.
‚Ä¢ We develop a wireless network duality and characterize analytically the power
and interference temperature of the primal and dual networks. The relationship
between them and the gradients of the spectral radius constraints in the util-
ity maximization problem is established. The wireless network duality is thus
useful for the computation of shadow price for SINR assignment.
‚Ä¢ The utility maximization problem is solved using an optimization technique
that can be interpreted as iteratively minimizing the interference load in the
network. In particular, the egalitarian fairness SINR problem is adapted itera-
tively to solve the general utility maximization problem, which can further be
solved distributively by leveraging the wireless network duality.
‚Ä¢ Our algorithms can be practically implemented in today‚Äôs wireless networks
(3GPP systems) as they reuse a power control submodule already widely imple-
mented. Numerical evaluations show that our algorithms have good perfor-
mance, often yielding the optimal solution in tens of iterations even for a large
number of users.
The rest of this chapter is organized as follows. In Section 5.2, we present the sys-
tem model and reformulate our utility maximization problem in the SINR domain
with spectral radius constraints. Then, using the nonlinear Perron‚ÄìFrobenius the-
ory, we first solve a special case of the utility maximization problem, the weighted
max‚Äìmin SINR, in Section 5.3.1. Next, using nonnegative matrix theory, we present
the wireless network duality that we use to design a distributed algorithm to solve the
utility maximization problem. We evaluate the performance of our algorithms numer-
ically in Section 5.4. Finally, we conclude the chapter in Section 5.5. All the proofs
can be found in our paper [25].
The following notation is used. We let ùêûl denote the lth unit coordinate vector
and ùêàdenote the identity matrix. The superscripts (‚ãÖ)
‚ä§denotes transpose. We denote
ùê±‚àòùê≤as a Schur product of ùê±and ùê≤, that is, ùê±‚àòùê≤= [x1y1, ‚Ä¶ , xLyL]
‚ä§, and denote ùê±‚àïùê≤
as the component-wise division between ùê±and ùê≤, that is, ùê±‚àïùê≤= [x1‚àïy1, ‚Ä¶ , xL‚àïyL]
‚ä§.
Let ùüè= [1, ‚Ä¶ , 1]‚ä§‚àà‚ÑùL. For a vector ùê±= [x1, ‚Ä¶ , xL]
‚ä§, diag(ùê±) is its diago-
nal matrix diag(x1, ‚Ä¶ , xL). Let eùê±denote eùê±= (ex1, ‚Ä¶ , exL)‚ä§and log ùê±denote
log ùê±= (log x1, ‚Ä¶ , log xL). The Perron‚ÄìFrobenius eigenvalue of an irreducible
nonnegative matrix ùêÖis denoted as ùúå(ùêÖ), and the Perron right and left eigenvector
of ùêÖassociated with ùúå(ùêÖ) are denoted by ùê±(ùêÖ) and ùê≤(ùêÖ), respectively. An equality
involving eigenvectors is true up to a scaling constant.
5.2
UTILITY MAXIMIZATION
The network utility is a network-wide quality-of-service (QoS) measurement that
quantifies the efficiency of the wireless resource allocation. Before talking about the

100
DUAL PRICING ALGORITHMS BY WIRELESS NETWORK DUALITY
pricing strategies that serve to maximize the network utility, in this section, we first
introduce the concept of utility function and its dependence on all the users‚Äô resource
allocation.
We consider wireless networks with L users transmitting simultaneously on a
shared spectrum. Owing to the shared nature of the wireless medium, the interference
is unavoidable when users are transmitting simultaneously, that is, each user‚Äôs trans-
mission leads to interference for other users. The signal-to-interference-and-noise
ratio (SINR) is an important performance metric used to measure the quality of wire-
less transmission. Let ùêÜ= [Glk]L
l,k=1 > 0L√óL represent the channel gain, where Glk is
the channel gain from the kth transmitter to the lth receiver, and ùêß= [n1, ‚Ä¶ , nL]
‚ä§> ùüé,
where nl is the noise power at the lth user. The vector ùê©= [p1, ‚Ä¶ , pL]
‚ä§is the transmit
power vector. Now, the SINR of the lth user in the primary network can be given in
terms of ùê©:
SINRP
l (ùê©) =
plGll
‚àë
k‚â†l
pkGlk + nl
.
(5.1)
From Eq. (5.1), we can observe the intimate connection between the SINR and users‚Äô
transmit power: a user would like to achieve a high SINR by increasing its transmit
power, while this increase, in turn, gives rise to a higher interference level for other
users. We also define a nonnegative matrix ùêÖwith entries:
Flk =
{
0,
if l = k
Glk,
if l ‚â†k
(5.2)
and the vector
ùêØ=
(
1
G11
, 1
G22
, ‚Ä¶ ,
1
GLL
)‚ä§
.
(5.3)
Assuming that ùêÖis irreducible, that is, each link has at least an interferer, we denote
vector ùú∏as the SINR for all users for brevity and its equivalent form is given by
ùõæl =
pl
( diag(ùêØ)(ùêÖùê©+ ùêß))
l
,
l = 1, ‚Ä¶ , L,
(5.4)
where we use ùêÖand ùêØin Eqs. (5.2) and (5.3), respectively. Thus, the utility function
can be expressed as
U(ùú∏) =
L
‚àë
l=1
ùúîlul(SINR(ùê©)),
(5.5)
which is a sum of individual utility of each user. The positive vector ùùéis used to
reflect a priority of the utility of each user. For example, the utility function can be
the weighted sum rate [26‚Äì28] and the ùõº-fairness utility [29].
As the SINR is a nontrivial nonlinear function of power, the joint SINR assign-
ment and power control is a great challenge of resource allocation policy. It is also

UTILITY MAXIMIZATION
101
important to consider the power constraints for the system that reflect the available
resource budget in the wireless networks. A general power constraint set ùí´is given
by
ùí´= {ùê©| ùê∞‚ä§
l ùê©‚â§pl,
l = 1, ‚Ä¶ , L},
(5.6)
where ùê©‚àà‚ÑùL and ùê∞l ‚àà‚ÑùL, l = 1, ‚Ä¶ , L are, respectively, the upper bound and posi-
tive weight vector for the weighted power constraints. In particular, when ùê∞l = ùêûl, we
have the individual power constraint pl ‚â§pl for all l, and when ùê∞l = ùüè, l = 1, ‚Ä¶ , L,
we have a single total power constraint ùüè‚ä§ùê©‚â§min
l=1,‚Ä¶,L pl. Next, let q denote the inter-
ference temperature vector, consisting of the total interference and the noise for each
user, i.e., q = diag(v)(Fp + n). To mitigate the interference coming from the other
users in the wireless networks, we also impose an individual interference temper-
ature constraint to each user, and the interference temperature constraint set ùí¨is
given by
ùí¨= {ùê™| ùêû‚ä§
l ùê™‚â§ql,
l = 1, ‚Ä¶ , L}.
(5.7)
Using the system model introduced above, the utility maximization problem is
then given by
maximize
U(ùú∏)
subject to
ùê©‚ààùí´,
ùê™‚ààùí¨,
ùê™= diag(ùêØ)(ùêÖùê©+ ùêß),
ùõæl = pl‚àïql,
l = 1, ‚Ä¶ , L,
variables:
ùú∏, ùê©, ùê™.
(5.8)
Denote the optimal ùê©in Eq. (5.8) as ùê©‚ãÜ. To proceed further, we reformulate Eq. (5.8)
as an equivalent optimization problem in the SINR domain with a set of spectral
radius constraints, whose problem structure is useful for developing the wireless net-
work duality and proposing a distributed pricing algorithm.
Then, we have the following result.
Theorem 5.1
The optimal value in Eq. (5.8) is equal to the optimal value of the
following problem:
maximize
U(ùú∏)
subject to
ùúå( diag(ùú∏‚àòùêØ)(ùêÖ+ (1‚àïpl)ùêßùê∞‚ä§
l )) ‚â§1,
l = 1, ‚Ä¶ , L,
ùúå( diag(ùêØ)(ùêÖdiag(ùú∏) + (1‚àïql)ùêßùêû‚ä§
l )) ‚â§1,
l = 1, ‚Ä¶ , L,
variables:
ùú∏.
(5.9)
Let us denote the optimal solution of Eq. (5.9) by ùú∏‚ãÜ. In addition, we have
ùúå( diag(ùú∏‚ãÜ‚àòùêØ)(ùêÖ+ (1‚àïpi)ùêßùê∞‚ä§
i )) = 1,
(5.10)
where
i = arg max
l=1,‚Ä¶,L ùúå( diag(ùú∏‚ãÜ‚àòùêØ)(ùêÖ+ (1‚àïpl)ùêßùê∞‚ä§
l )),
(5.11)

102
DUAL PRICING ALGORITHMS BY WIRELESS NETWORK DUALITY
or
ùúå( diag(ùêØ)(ùêÖdiag(ùú∏‚ãÜ) + (1‚àïqj)ùêßùêû‚ä§
j )) = 1,
(5.12)
where
j = arg max
l=1,‚Ä¶,L ùúå( diag(ùêØ)(ùêÖdiag(ùú∏‚ãÜ) + (1‚àïql)ùêßùêû‚ä§
l )).
(5.13)
Using a logarithmic mapping of a variable, Eq. (5.9) can be transformed to an
optimization problem with a convex constraint set. For ùú∏= (ùõæ1, ‚Ä¶ , ùõæL)‚ä§> ùüé, let
ÃÉùõæl = log ùõæl,
l = 1, ‚Ä¶ , L,
That is, ùú∏= eÃÉùú∏. Then, Eq. (5.9) is equivalent to
maximize
U(eÃÉùú∏)
subject to
log ùúå(diag(eÃÉùú∏‚àòùêØ)(ùêÖ+ (1‚àïpl)ùêßùê∞‚ä§
l )) ‚â§0,
l = 1, ‚Ä¶ , L,
log ùúå( diag(ùêØ)(ùêÖdiag(eÃÉùú∏) + (1‚àïql)ùêßùêû‚ä§
l )) ‚â§0,
l = 1, ‚Ä¶ , L,
variables:
ÃÉùú∏.
(5.14)
Let us denote the optimal solution of Eq. (5.14) by ÃÉùú∏‚ãÜ. Note that ÃÉùú∏‚ãÜ= log ùú∏‚ãÜfor all l.
Remark 5.1
For an irreducible nonnegative matrix ùêÖ‚àà‚ÑùL√óL
+
, log ùúå(diag(eÃÉùú∏)ùêÖ) is
a convex function [30], because of the log-convexity property of the Perron‚ÄìFrobenius
eigenvalue [31]. Therefore, the constraint set in Eq. (5.14) is convex.
Now, we make the following assumption on the objective function that is useful
in our proposed distributed pricing algorithm later in Section 5.3.8.
Assumption 5.1
The utility function U(ùú∏) is concave in log ùõæl for all l.
We briefly introduce the concept of Pareto optimality and Pareto dominance on
the utility feasible set and then propose a pricing algorithm that is Pareto optimal. An
SINR vector ÃÇùú∏Pareto dominates the another SINR vector ùú∏if u(ÃÇùõæl) is greater than
u(ùõæl) for all l, and at least one of these inequalities is strict. In this case, the network
utility computed by ÃÇùú∏is sure to be greater than the network utility computed by ùú∏.
An SINR vector ÃÇùú∏is Pareto optimal if there does not exist any ùú∏that Pareto domi-
nates it. In other words, no user can increase its utility without hurting any other users
when the current resource allocation is Pareto optimal. Notably, the optimal resource
allocation is Pareto optimal; however, it does not Pareto dominate all the resource
allocation. Figure 5.1 illustrates the concept of Pareto optimality and Pareto dom-
inance by a two-user example. The gray region in Figure 5.1 is the utility feasible
region. Any points above the dashed line in the utility feasible region dominate the
resource allocation vector ùê≤, for example, the feasible point ùê±. The resource alloca-
tion vector ùê≥is Pareto optimal; however, although u1(ùê≥) > u1(ùê±) and u1(ùê≥) > u1(ùê≤),
it Pareto dominates neither ùê±nor ùê≤. An optimal pricing algorithm can coordinate the

THE WIRELESS NETWORK DUALITY
103
‚àí4
‚àí3
‚àí2
‚àí1
0
1
2
3
‚àí2.5
‚àí2
‚àí1.5
‚àí1
‚àí0.5
0
0.5
1
1.5
2
u(z)
u(y)
u(x)
Region of Pareto
dominance for u(y)
Pareto optimality
Utility feasible region
u1
u2
Figure 5.1
Illustration of the Pareto optimality and Pareto dominance. The utility feasible
region is for a two-user example with the utility function U(ùú∏) = 0.6 log ùõæ1 + 0.4 log ùõæ2, that
is, u(ùõæ1) = 0.6 log ùõæ1 and u(ùõæ2) = 0.4 log ùõæ2, respectively. The channel gains are given by G11 =
0.76, G12 = 0.19, G21 = 0.11, and G22 = 0.78. The weights and upper bound for the weighted
power constraints are ùê∞1 = (0.78, 0.12)‚ä§, ùê∞2 = (0.46, 0.85)‚ä§, and ùê©= (7.5, 6.0)‚ä§.
users to maximize the overall network utility based on a feedback signal to balance
between the change (increase or decrease) of its own utility and the impact on other
users‚Äô utility caused by this change. In the next section, we use the wireless network
duality to yield such a pareto optimal pricing algorithm.
5.3
THE WIRELESS NETWORK DUALITY
The heterogeneity of a wireless network further complicates the network optimization
as our wireless network technologies such as cellular networks, cognitive radio net-
works, and femtocell networks are changing rapidly. An important feature in wireless
networks that can be exploited for utility maximization is the notion of wireless net-
work duality. Network duality is a fundamental concept in multiuser communication
[32, 33]. Network dualities for wireless cellular and ad-hoc networks were investi-
gated in References 34 and 35 for a total power minimization problem (a convex
problem) using linear programming duality. A network duality was later developed
for a max‚Äìmin weighted SINR problem (a nonconvex problem) in References 26, 36,
and 37 using nonnegative matrix theory and geometric programming duality. These
network dualities (including the one in this chapter) assert that two different net-
works, respectively, a primal network and a dual network, can be construed to attain
an identical SINR performance. For example, the well-known uplink‚Äìdownlink dual-
ity in cellular network states that the uplink network reverses the link directions in
the downlink network, as illustrated in Figure 5.2. Hence, a feasible SINR for one

104
DUAL PRICING ALGORITHMS BY WIRELESS NETWORK DUALITY
(a)
(b)
Figure 5.2
Uplink‚Äìdownlink duality. (a) The uplink network. (b) The downlink network.
is also feasible for the other. There are many applications for the uplink‚Äìdownlink
duality, for example, beamforming and power control optimization in Reference 34
and optimizing the energy-robustness trade-off in cellular network in Reference 38.
In this section, we develop a wireless network duality involving the primary net-
work and the dual network, as illustrated in Figure 5.3(a) and (b), respectively, which
facilitates a distributed pricing algorithm design. The primary network and the dual
network, comprising the wireless network duality, are constructed to attain identical
SINR performance. In particular, the dual network reverses the link directions in the
primary network (cf. Figure 5.3), that is, the channel gain from the kth transmitter to
the lth receiver is Gkl in the dual network. This will be used to propose and analyze
distributed algorithms for jointly optimal SINR assignment, power and interference
temperature control. Our algorithms are based on a novel wireless network duality
that decouples SINR assignment, power and interference temperature. Further, the
(a)
(b)
Primary base station
Secondary base station
Primary user
Secondary user
Primary link
Secondary link
Figure 5.3
Wireless network duality. (a) The primal network. (b) The dual network.

THE WIRELESS NETWORK DUALITY
105
power and interference temperature in the primal and the dual networks are jointly
optimized to solve the utility maximization problem formulated for the primal net-
work subject to the power budget and interference temperature constraints. Through
this wireless network duality, the egalitarian SINR fairness problem can be interpreted
as solving the general utility maximization problem in a distributed manner when the
weights in the egalitarian SINR fairness problem are tuned appropriately.
5.3.1
Wireless Network Duality and Algorithms
In this section, we consider Eq. (5.14) for both smooth and nonsmooth utility func-
tions. In particular, in Section 5.3.3, a max‚Äìmin weighted SINR problem (for egali-
tarian SINR fairness) will be first solved using a nonlinear Perron‚ÄìFrobenius theory.1
This is then used together with the wireless network duality in Section 5.3.4 to solve
Eq. (5.14). It will be shown that the transmit power and interference temperature can
be analytically expressed as the Perron right eigenvectors of the specially constructed
matrices associated with the spectral radius constraints in Eq. (5.14). This leads to the
development of a wireless network duality involving the dual network as illustrated in
Figure 5.3b, which facilitates a distributed algorithm design to maximize the primal
network utility.
5.3.2
Smooth and Nonsmooth Utility
The reformulation introduced in Section 5.2 allows us to decompose the utility max-
imization problem in Eq. (5.8) into first optimizing ùú∏, that is, optimizing the SINR
assignment and then optimizing the power ùê©and interference temperature ùê™. In this
section, we discuss the assumption for the objective function, which will also be use-
ful in our proposed distributed algorithm in Section 5.3.6 to solve Eq. (5.8) for both
smooth and nonsmooth utility functions.
For example, the ùõº-fairness utility [29] satisfies Assumption 5.1, given by
U(ùú∏) =
‚éß
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™‚é©
L
‚àë
l=1
log ùõæl,
if ùõº= 1,
L
‚àë
l=1
(1 ‚àíùõº)‚àí1ùõæ1‚àíùõº
l
,
if ùõº> 1.
Note that Eq. (5.14) includes the sum rate maximization problem studied in Refer-
ences 27 and 28, when U(ùú∏) = ‚àëL
l=1 log(1 + ùõæl), but this objective function does not
satisfy Assumption 5.1, and henceforth, it is a nonconvex problem that requires global
optimization techniques, for example, those studied in References 27 and 28.
1There are several extensions to the classical (linear) Perron‚ÄìFrobenius theorem in nonnegative matrix
theory for classes of nonlinear maps. We use the finite dimensional nonlinear Perron‚ÄìFrobenius theory
developed in Reference 39.

106
DUAL PRICING ALGORITHMS BY WIRELESS NETWORK DUALITY
If U(ùú∏) is differentiable and separable, that is, U(ùú∏) = ‚àëL
l=1 Ul(ùõæl), let ‚àáUl(ùõæl) =
ùúïUl‚àïùúïùõæl and ‚àá2Ul(ùõæl) = ùúï2Ul‚àïùúï2ùõæl denote the first-order and second-order derivatives
of Ul(ùõæl) with respect to ùõæl, respectively. Then, Ul(ùõæl) is concave in log ùõæl if and only
if the curvature is sufficiently large [17]:
‚àá2Ul(ùõæl) ‚â§‚àí‚àáUl(ùõæl)
ùõæl
.
(5.15)
In the general case (when U(ùú∏) can be nonsmooth), we consider the subgradient of
U(ùú∏), whose definition is given as follows.
Definition 5.1 (cf. [40]). The subgradient ùê†‚àà‚ÑùL of U(ùú∏) at ÃÇùú∏satisfies
U(ùú∏) ‚â§U(ÃÇùú∏) + ùê†‚ä§(ùú∏‚àíÃÇùú∏)
for any feasible ùú∏. If U(ùú∏) is concave and differentiable at ùú∏, the subgradient is unique
and given by its gradient ùê†= ‚àáU(ùú∏). On the other hand, if U(ùú∏) is concave but not
differentiable, its subgradient is in the set
‚ãÇ
{ùê†| U(ùú∏) ‚â§U(ÃÇùú∏) + ùê†‚ä§(ùú∏‚àíÃÇùú∏)}
for any feasible ùú∏.
5.3.3
Nonsmooth Special Case: U(ùú∏) = min
l=1,‚Ä¶,L
ùú∏l
ùú∑l
In this section, let us consider the max‚Äìmin weighted SINR problem (for egalitarian
SINR fairness), which is a special case of Eq. (5.9) that has a nonsmooth concave
objective function:
maximize
min
l=1,‚Ä¶,L
ùõæl
ùõΩl
subject to
ùúå( diag(ùú∏‚àòùêØ)(ùêÖ+ (1‚àïpl)ùêßùê∞‚ä§
l )) ‚â§1,
l = 1, ‚Ä¶ , L,
ùúå( diag(ùêØ)(ùêÖdiag(ùú∏) + (1‚àïql)ùêßùêû‚ä§
l )) ‚â§1,
l = 1, ‚Ä¶ , L,
variables:
ùú∏,
(5.16)
where ùú∑is a positive vector with the entry ùõΩl used to reflect a priority of the lth link.
A larger ùõΩl indicates a higher priority.
Let us define the following set of nonnegative matrices:
ùêÅl = diag(ùêØ)
(
ùêÖ+ 1
pl
ùêßùê∞‚ä§
l
)
,
l = 1, ‚Ä¶ , L,
(5.17)
ùêÉl =
(
ùêà+
1
ql ‚àínlvl
diag(ùêØ)ùêßùêû‚ä§
l
)
diag(ùêØ)ùêÖ,
l = 1, ‚Ä¶ , L.
(5.18)

THE WIRELESS NETWORK DUALITY
107
By applying the nonnegative matrix theory and the nonlinear Perron‚ÄìFrobenius the-
ory, we obtain a closed-form solution to Eq. (5.16) as well as the corresponding
optimal solution in Eq. (5.8), which is unique.
Lemma 5.1
The optimal value of Eq. (5.16) is given by
1
max
l=1,‚Ä¶,L{ùúå(diag(ùú∑)ùêÅl), ùúå(ùêÉl diag(ùú∑))}.
(5.19)
The optimal solution to Eq. (5.16) ùú∏‚ãÜis a vector with ùõæ‚ãÜ
l ‚àïùõΩl equal to a common value
ùõæ‚ãÜ
m‚àïùõΩm =
1
max
l=1,‚Ä¶,L{ùúå(diag(ùú∑)ùêÅl), ùúå(ùêÉl diag(ùú∑))}
for all l, where
m = arg max
l=1,‚Ä¶,L
{ùúå( diag(ùú∑)ùêÅl
), ùúå(ùêÉl diag(ùú∑))}.
(5.20)
If the optimal value is 1‚àïùúå(diag(ùú∑)ùêÅm) for m in Eq. (5.20), the optimal power and
interference temperature in Eq. (5.8) is, respectively, given by
ùê©‚ãÜ=
pm
ùê∞‚ä§
mùê±( diag(ùú∑)ùêÅm
)ùê±( diag(ùú∑)ùêÅm
)
(5.21)
and
ùê™‚ãÜ= diag(ùú∏‚ãÜ)‚àí1ùê©‚ãÜ,
and if the optimal value is 1‚àïùúå(ùêÉm diag(ùú∑)) for m in Eq. (5.20), the optimal interfer-
ence temperature and power in Eq. (5.8) is, respectively, given by
ùê™‚ãÜ=
qm
ùêû‚ä§
mùê±(ùêÉm diag(ùú∑))ùê±(ùêÉm diag(ùú∑))
(5.22)
and
ùê©‚ãÜ= diag(ùú∏‚ãÜ)ùê™‚ãÜ.
We next give an intriguingly simple algorithm to compute the analytical solution
in Lemma 5.1. In particular, by applying the nonlinear Perron‚ÄìFrobenius theory in
Reference 39, the following algorithm computes ùê©‚ãÜgiven in Lemma 5.1.
Theorem 5.2
Starting from any initial point ùê©(0), ùê©(k) converges geometrically
fast to the power ùê©‚ãÜgiven in Lemma 5.1.

108
DUAL PRICING ALGORITHMS BY WIRELESS NETWORK DUALITY
Algorithm 5.1
Max‚Äìmin weighted SINR Algorithm
Initialize ùê©(0).
1) Each lth user updates its power pl(k + 1) as follows:
pl(k + 1) =
ùõΩl
SINRP
l (ùê©(k))
pl(k).
2) Normalize ùê©(k + 1):
ùê©(k + 1) ‚Üê
ùê©(k + 1)
max
l=1,‚Ä¶,L
{ùê∞‚ä§
l ùê©(k + 1)
pl
,
ùêû‚ä§
l diag(ùêØ)ùêÖùê©(k + 1)
ql ‚àínlvl
}.
Remark 5.2
At Step 1, the Foschini‚ÄìMiljanic power control algorithm update in
Reference 41 (a power control submodule widely implemented in 3GPP systems)
is used. At Step 2, the computation of ùê∞‚ä§
l ùê©(k + 1) and the normalization of ùê©(k +
1) can be computed by a gossip algorithm in a distributed manner [42]. Notice
that ùêû‚ä§
l diag(ùêØ)(ùêÖùê©(k + 1) + ùêß) and nl are, respectively, the interference and the noise
power at lth receiver, which can be measured from the interference temperature. Thus,
ùêû‚ä§
l diag(ùêØ)ùêÖùê©(k + 1) can be locally obtained.
Interestingly, using the Friedland‚ÄìKarlin inequalities in References 43 and 27,
Eq. (5.16) is equivalent to Eq. (5.9) with a smooth objective function given by
U(ùú∏) =
L
‚àë
l=1
(ùê±(ùõÄ)‚àòùê≤(ùõÄ))
l log ùõæl,
(5.23)
where ùõÄ‚àà{diag(ùú∑)ùêÅl, ùêÉl diag(ùú∑)} is the matrix defined for the mth user with m
given in Eq. (5.20): if the optimal value for Eq. (5.16) is 1‚àïùúå(diag(ùú∑)ùêÅm) for m in Eq.
(5.20), then ùõÄ= diag(ùú∑)ùêÅm; if the optimal value for Eq. (5.16) is 1‚àïùúå(ùêÉm diag(ùú∑))
for m in Eq. (5.20), then ùõÄ= ùêÉm diag(ùú∑).
5.3.4
Wireless Network Duality
In this section, we develop a dual network having identical SINR performance as
the primal network but with all the link directions reversed. The concept of the dual
network is actually a virtual network using the same topology of the primal network.
Thus, we use ùêÖ‚ä§as the channel fading matrix in the dual network (because of the
reversed link directions).
We now turn to solve Eq. (5.14) for general utility functions that satisfy Assump-
tion 5.1 using a projected subgradient method [40]. Interestingly, this method can
be made distributed by connecting the gradients of the spectral radius functions
in Eq. (5.14) with the power and the interference temperature in both the primal

THE WIRELESS NETWORK DUALITY
109
and the dual networks (cf. Figure 5.3). This is achieved by applying the wireless
network duality that exploits the structure of the spectral radius functions in
Eq. (5.14).
Recall that we have already defined the nonnegative matrices ùêÅl and ùêÉl given in
Eqs. (5.17) and (5.18), respectively. The gradients ùê†‚àà‚ÑùL of log ùúå(diag(ùú∏)ùêÅl) and
log ùúå(ùêÉl diag(ùú∏)) at ùú∏are given, respectively, by [27, 43]
ùê†= ùê±( diag(ùú∏)ùêÅl
)‚àòùê≤( diag(ùú∏)ùêÅl
)
(5.24)
and
ùê†= ùê±(ùêÉl diag(ùú∏))‚àòùê≤(ùêÉl diag(ùú∏)),
(5.25)
normalized such that ùüè‚ä§ùê†= 1. We already know from the reformulation in Section
5.2 that the Perron right eigenvectors of the matrices in Eqs. (5.10) and (5.12) are the
optimal transmit power ùê©‚ãÜand the optimal interference temperature ùê™‚ãÜof the primal
network, respectively, which also appear in Eq. (5.24) for l = i in Eqs. (5.11) and
(5.25) for l = j in Eq. (5.13), respectively. Observe that the gradient for the spectral
radius function is the Schur product of the Perron right and left eigenvectors (recall
that the Schur product is the component-wise product of two vectors). This interest-
ing characterization leads naturally to the development of a dual network, where a
physical interpretation can be given to the Perron left eigenvectors of the matrices in
Eqs. (5.10) and (5.12). It enables a distributed method to compute ùê†in Eqs.(5.24) and
(5.25). As shown in Figure 5.3b, the dual network reverses the link direction of the
primal network, that is, the channel gain from the kth transmitter to the lth receiver is
Gkl in the dual network.
Definition 5.2
Let the power ùê¨and the interference temperature ùê≠in the dual net-
work be given, respectively, by
ùê¨= diag(ùú∏)ùê≠
(5.26)
and
ùê≠= diag(ùêØ)(ùêÖ‚ä§ùê¨+ ùê∞ùúÑ),
(5.27)
where the weight vector ùê∞ùúÑfor the transmit power constraint in the primal network is
assumed to be a virtual received noise in the dual network, and the index ùúÑcorresponds
to either i in Eq. (5.11) or j in Eq. (5.13), which indicates the power or interference
temperature constraint that is tight at optimality of Eq. (5.14). Now, the SINR of the
lth user in the dual network can be given in terms of ùê¨:
SINRD
l (ùê¨) =
sl
(diag(ùêØ)(ùêÖ‚ä§ùê¨+ ùê∞ùúÑ))
l
.
(5.28)
Observe that the channel matrix in Eq. (5.1) is replaced by its transpose in Eq.
(5.28). However, this dual network must achieve all possible SINR values that are

110
DUAL PRICING ALGORITHMS BY WIRELESS NETWORK DUALITY
feasible in the primal network. Combining Eqs. (5.26) and (5.27), we have
ùê¨= diag(ùú∏‚àòùêØ)(ùêÖ‚ä§ùê¨+ ùê∞ùúÑ)
(5.29)
and
ùê≠= diag(ùêØ)(ùêÖ‚ä§diag(ùú∏)ùê≠+ ùê∞ùúÑ
).
(5.30)
Corresponding to the primal network power and interference temperature con-
straints, the dual network power and interference temperature constraints can be
given, respectively, by (note the use of ùúÑ, where ùúÑcan be i in Eq. (5.11) or ùúÑcan be j
in Eq. (5.13))
ùêß‚ä§ùê¨‚â§pùúÑ,
and
ùêß‚ä§ùê≠‚â§qùúÑ.
Moreover, it is still true that either the dual network power constraint or the dual
network interference temperature constraint is tight at optimality. We then have the
following result that connects the transmit powers and interference temperatures of
both the primal and dual networks, which is used in a distributed algorithm design in
Section 5.3.6.
Lemma 5.2
The Perron right and left eigenvector of the nonnegative matrix
diag(ùú∏‚ãÜ)ùêÅi, where ùêÅi is given in Eq. (5.17) with i in Eq. (5.11), satisfy
ùê±( diag(ùú∏‚ãÜ)ùêÅi
) = ùê©‚ãÜ
(5.31)
and
ùê≤( diag(ùú∏‚ãÜ)ùêÅi
) = diag(ùú∏‚ãÜ‚àòùêØ)‚àí1ùê¨‚ãÜ,
(5.32)
respectively. The Perron right and left eigenvector of the nonnegative matrix
ùêÉj diag(ùú∏‚ãÜ), where ùêÉj is given in Eq. (5.18) with j in Eq. (5.13), satisfy, respectively,
ùê±(ùêÉj diag(ùú∏‚ãÜ)) = ùê™‚ãÜ
(5.33)
and
ùê≤(ùêÉj diag(ùú∏‚ãÜ)) = diag(ùú∏‚ãÜ‚àïùêØ)ùê≠‚ãÜ.
(5.34)
Finally, Table 5.1 summarizes the wireless network duality that characterizes the
transmit power and interference temperature in the primal and the dual networks
as the Perron right and left eigenvectors of appropriately constructed nonnegative
matrices.

TABLE 5.1
The Wireless Network Duality Illustrates the Connection between the Primal and the Dual Networks in
Terms of Both the Perron Right and Left Eigenvectors of the Nonnegative Matrices Associated with the Spectral
Radius Constraints in Eq. (5.14)
Wireless Network Duality
Primal Network
Dual Network
Power
budget
constraint
‚éß
‚é™
‚é®
‚é™‚é©
ùê©‚ãÜ= ùê±(diag (ùú∏‚ãÜ‚àòùêØ) (ùêÖ+ (1‚àïpi
) ùêßùê∞‚ä§
i
))
= (ùêà‚àídiag (ùú∏‚ãÜ‚àòùêØ) ùêÖ)‚àí1 diag (ùú∏‚ãÜ‚àòùêØ) ùêß
ùê∞‚ä§
i ùê©‚ãÜ‚â§pi
‚Üî
‚Üî
ùê¨‚ãÜ= diag (ùú∏‚ãÜ‚àòùêØ) ùê≤(diag (ùú∏‚ãÜ‚àòùêØ) (ùêÖ+ (1‚àïpi
) ùêßùê∞‚ä§
i
))
= (ùêà‚àídiag (ùú∏‚ãÜ‚àòùêØ) ùêÖ‚ä§)‚àí1 diag (ùú∏‚ãÜ‚àòùêØ) ùê∞i
ùêß‚ä§ùê¨‚ãÜ‚â§pi
Interference
temperature
constraint
‚éß
‚é™
‚é®
‚é™‚é©
ùê™‚ãÜ= ùê±
((
ùêà+
1
qj ‚àínjvj
diag (ùêØ) ùêßùêû‚ä§
j
)
diag (ùêØ) ùêÖdiag
(
ùú∏‚ãÜ)
)
= (ùêà‚àídiag (ùêØ) ùêÖdiag (ùú∏‚ãÜ))‚àí1 diag (ùêØ) ùêß
ùêû‚ä§
j ùê™‚ãÜ‚â§qj
‚Üî
‚Üî
ùê≠‚ãÜ= diag (ùú∏‚ãÜ‚àïùêØ)‚àí1 ùê≤
((
ùêà+
1
qj ‚àínjvj
diag (ùêØ) ùêßùêû‚ä§
j
)
diag (ùêØ) ùêÖdiag (ùú∏‚ãÜ)
)
= (ùêà‚àídiag (ùêØ) ùêÖ‚ä§diag (ùú∏‚ãÜ))‚àí1 diag (ùêØ) ùê∞j
ùêß‚ä§ùê≠‚ãÜ‚â§qj
111

112
DUAL PRICING ALGORITHMS BY WIRELESS NETWORK DUALITY
5.3.5
Interference Load Minimization
In Section 5.2, the constraints of the utility maximization problem in Eq. (5.8) can
be succinctly reformulated as spectral radius constraints, that is, ùúå( diag(ùú∏)ùêÅl
) ‚â§
1 ‚àÄl and ùúå(ùêÉl diag(ùú∏)) ‚â§1 ‚àÄl, where ùêÅl and ùêÉl are given in Eqs. (5.17) and (5.18),
respectively. These spectral radius functions capture the effect of interference on the
feasibility of SINR assignment. The spectral radius thus plays the role of a useful mea-
sure for interference, which we call the interference load. This means that a smaller
ùúå( diag(ùú∏)ùêÅl
) or ùúå(ùêÉl diag(ùú∏)) indicates a smaller interference load on the network,
which leads to a larger feasible SINR region that can be optimized. On the other
hand, the interference load increases with interference and, therefore, reduces the
feasible SINR region. This connection between the interference load and our utility
maximization problem in Section 5.2 is made precise in the following. By leveraging
both the wireless network duality in Section 5.3.4 and the interference load minimiza-
tion problem (to be introduced in the following), a distributed algorithm will then be
proposed to solve the utility maximization problem in Eq. (5.9).
First, let us consider the following convex optimization problem given by
maximize
ùú∂‚ä§ÃÉùú∏
subject to
ùúå( diag(eÃÉùú∏)ùêÅl
) ‚â§1,
l = 1, ‚Ä¶ , L,
ùúå(ùêÉl diag(eÃÉùú∏)) ‚â§1,
l = 1, ‚Ä¶ , L,
variables:
ÃÉùú∏,
(5.35)
where ùêÅl and ùêÉl are given in Eqs. (5.17) and (5.18), respectively, ÃÉùú∏is the logarith-
mic mapping by ÃÉùú∏= log ùú∏, and ùú∂‚àà‚ÑùL
+ is a given probability vector that is used to
approximate U(eÃÉùú∏) using its Taylor series expansion up to the first-order terms (cf.
proof of Theorem 5.3).
In the following, it is fruitful to consider the interference load minimization prob-
lem that is intimately related to Eq. (5.35) and instead minimizes a spectral radius
function subject to a single linear constraint:
minimize
max
l=1,‚Ä¶,L{ùúå(diag(eÃÉùúº)ùêÅl), ùúå(ùêÉl diag(eÃÉùúº))}
subject to
ùú∂‚ä§ÃÉùúº‚â•0,
variables:
ÃÉùúº,
(5.36)
where ÃÉùúºis the logarithmic transformation: ÃÉùúº= log ùúº. The following result connects
Eqs. (5.35) and (5.36).
Lemma 5.3
Let ùú∏‚ãÜand ùúº‚ãÜbe the optimal solution of Eqs. (5.35) and (5.36), respec-
tively, and let ùúâ‚ãÜand ùúÅ‚ãÜbe the optimal value of Eqs. (5.35) and (5.36), respectively.
Then, ùú∏‚ãÜand ùúº‚ãÜsatisfy
ùú∏‚ãÜ= 1
ùúÅ‚ãÜùúº‚ãÜ.
(5.37)
Furthermore, because ùú∂is a probability vector, ùúâ‚ãÜand ùúÅ‚ãÜsatisfy
ùúâ‚ãÜ= ‚àílog ùúÅ‚ãÜ.

THE WIRELESS NETWORK DUALITY
113
‚àí0.8
‚àí0.7
‚àí0.6
‚àí0.5
‚àí0.4
‚àí0.3
‚àí0.2
‚àí0.1
0
‚àí1
‚àí0.8
‚àí0.6
‚àí0.4
‚àí0.2
0
0.2
œâ1 log Œ≥1
œâ2 log Œ≥2
Œ≥
Œ±
Œî
Œî
=
U (Œ≥ )
1
U (Œ≥ )
boundary of the feasible
region for Eq. (5.35)
boundary of the feasible
region for Eq. (5.36)
Figure 5.4
Illustration of the connection between Eqs. (5.35) and (5.36). Achievable region
for a two-user example with objective function ‚àë
l ùúîl log ùõæl. The channel gains are given by
G11 = 0.69, G12 = 0.12, G21 = 0.13, and G22 = 0.70 and the weight is ùúî= [0.40, 0.60]‚ä§.
The maximum power and interference temperature for users are ùê©= [1.50, 1.00]‚ä§W and
ùê™= [2.50, 3.00]‚ä§W, respectively. The noise powers for both users are 1 W. The intersection
point of the direction ùú∂and achievable region is the optimal solution. Moreover, the minimiza-
tion of Problem (5.36) also intersects with the optimal solution of Eq. (5.35) at the boundary
of the feasible region.
The formulation of Eq. (5.36) that minimizes the interference load thus provides
a connection (by choosing ùú∂to be proportional to the subgradient of the utility func-
tion) between the general utility maximization problem in Eq. (5.8) and its special
case of egalitarian SINR fairness optimization in Eq. (5.16). An interesting interpre-
tation of Lemma 5.3 is that the optimal SINR in the general utility maximization
can be scaled relative to the optimal SINR achieved under the egalitarian SINR fair-
ness. Figure 5.4 illustrates the geometric interpretation of the connection between
Problems (5.35) and (5.36) by an example using U(ùú∏) = ‚àëL
l=1 ùúîl log ùõæl with a
positive ùùé.
5.3.6
Utility Maximization Algorithm
In Eq. (5.36), we have shown that it is possible to find a scaling factor that connects the
SINR assignment in problem (5.35) (which is related to Eq. (5.14) through a Taylor‚Äôs
series first-order approximation) with the egalitarian SINR fairness. This means that
Eq. (5.35) can be first solved by considering Eq. (5.36) to find the scaling factor
and then to scale the optimal solution of Eq. (5.36) to finally obtain the solution of
Eq. (5.14).

114
DUAL PRICING ALGORITHMS BY WIRELESS NETWORK DUALITY
We use the projected subgradient method to solve Eq. (5.36). The parameter ùú∂in
Eq. (5.36) is updated iteratively. In particular, at the (k + 1)th iteration, we update
ùú∂(k) as the subgradient of U(eÃÉùú∏) at ÃÉùú∏(k). Thus, instead of solving Eq. (5.14) directly,
we replace the objective function of Eq. (5.14) in a neighborhood of a feasible point
ÃÉùú∏(k) by its Taylor series (cf. proof of Theorem 5.3), which is a successive convex
approximation technique. Meanwhile, the algorithm iterates according to the subgra-
dient of both the objective function and the constraint functions. However, computing
the gradient of the spectral radius functions, that is, the Schur product of the Perron
right and left eigenvectors, requires centralized computation in general. This Schur
product is the shadow price of the SINR assignment for utility maximization.
However, by exploiting the wireless network duality, this task can be made dis-
tributed. Making use of the results in Section 5.3.4, we can then obtain a distributed
algorithm to solve Eq. (5.14). Observe that the gradient ùê†‚àà‚ÑùL of ùúå( diag(ùúº)ùêÅl
) and
ùúå(ùêÉl diag(ùúº)) in terms of ùê©, ùê™, ùê¨, and ùê≠are, respectively, given by (cf. Lemma 5.2)
ùê†= ùê©‚àò( diag(ùúº‚àòùêØ)‚àí1ùê¨)
(5.38)
and
ùê†= ùê™‚àò( diag(ùúº‚àïùêØ)ùê≠),
(5.39)
normalized such that ùüè‚ä§ùê†= 1. Furthermore, Eqs. (5.38) and (5.39) can be rewritten,
respectively, as
gl = pl
( 1
ùúÇlvl
)
sl
(5.40)
and
gl = ql
(ùúÇl
vl
)
tl.
(5.41)
Now, in Eqs. (5.40) and (5.41), the respective variables pl, ql, sl, tl, and ùúÇl can be
locally obtained, thus making the gradient computation distributed. We next use Eqs.
(5.40) and (5.41) to obtain a distributed algorithm based on the projected subgradient
method to solve Eq. (5.8).
Theorem 5.3
Starting from any initial point ùúº(0), if the step size ùúà(k) satisfies
‚àû
‚àë
k=0
ùúà(k) = ‚àû,
‚àû
‚àë
k=0
(ùúà(k))2 < ‚àû,
then ùê©(k) and ùê™(k) in Algorithm 5.2 converge to the optimal solution ùê©‚ãÜand ùê™‚ãÜof
Eq. (5.8), respectively.
Furthermore, if a constant step size is used in Step 4, Algorithm 5.2 is guaranteed
to converge to a neighborhood of the optimal solution.
Remark 5.3
If U(ùú∏) is smooth, Algorithm 5.2 solves Eq. (5.36) with ùú∂given by
‚àáU(ùú∏‚ãÜ)
ùüè‚ä§‚àáU(ùú∏‚ãÜ), where ùú∏‚ãÜis the optimal solution to (5.8) (cf. Figure 5.4).

THE WIRELESS NETWORK DUALITY
115
Algorithm 5.2
Utility Maximization Algorithm
Initialize ùúº(0), set the step size ùúà(0) ‚àà(0, 1).
1. Compute the weight ùú∂(k):
if U(ùúº) is smooth,
ùú∂(k) =
‚àáU(ùúº(k))
ùüè‚ä§‚àáU(ùúº(k)),
else
ùú∂(k) =
ÃÇùê†
ùüè‚ä§ÃÇùê†, where ÃÇùê†satisfies
U(ùúº) ‚â§U(ùúº(k)) + ÃÇùê†‚ä§(ùúº‚àíùúº(k)) for any feasible ùúº.
end if
2. In the primal network, set the power and interference temperature output of
Algorithm 5.1 with ùú∑= ùúº(k), which upon its convergence solves the
primal network optimization problem:
maximize
min
l=1,‚Ä¶,L
SINRP
l (ùê©)
ùúÇl(k)
subject to
ùê∞‚ä§
l ùê©‚â§pl,
l = 1, ‚Ä¶ , L,
ùêû‚ä§
l ùê™‚â§ql,
l = 1, ‚Ä¶ , L,
ùê™= diag(ùêØ)(ùêÖùê©+ ùêß),
variables:
ùê©, ùê™
as ùê©(k) and ùê™(k), respectively.
The computation of this step also provides in addition the value of ùúÑk, that is, the
ikth power or jkth interference temperature constraint that is tight in the primal
network optimization problem, where ik = arg max
l=1,‚Ä¶,L ùúå( diag(ùúº(k)‚àòùêØ)(ùêÖ+ (1‚àïpl)
ùêßùê∞‚ä§
l )) and jk = arg max
l=1,‚Ä¶,L ùúå( diag(ùêØ)(ùêÖdiag(ùúº(k)) + (1‚àïql)ùêßùêû‚ä§
l )).
In the dual network, set the power and interference temperature output of Algori-
thm 5.1 with ùú∑= ùúº(k) and with SINRP(ùê©) replaced by SINRD(ùê¨) at Step 1 of
Algorithm 5.1 and the normalization at Step 2 of Algorithm 5.1 maxl=1,‚Ä¶,L
{ùê∞‚ä§
l ùê©(k + 1)‚àïpl, ùêû‚ä§
l diag(ùêØ)ùêÖùê©(k + 1)‚àï(ql ‚àínlvl)} replaced by max{ ùêß‚ä§ùê¨(k+1)
pùúÑk
,
ùêß‚ä§diag(ùêØ)ùêÖ‚ä§ùê¨(k+1)
(qùúÑk ‚àíùêß‚ä§diag(ùêØ)ùê∞ùúÑk )} which on its convergence solves the dual network optimization
problem:
maximize
min
l=1,‚Ä¶,L
SINRD
l (ùê¨)
ùúÇl(k)
subject to
ùêß‚ä§ùê¨‚â§pùúÑk,
ùêß‚ä§ùê≠‚â§qùúÑk,
ùê≠= diag(ùêØ)(ùêÖ‚ä§ùê¨+ ùê∞ùúÑk),
variables:
ùê¨, ùê≠
as ùê¨(k) and ùê≠(k) respectively.

116
DUAL PRICING ALGORITHMS BY WIRELESS NETWORK DUALITY
Algorithm 5.2
3. Each lth user updates its gradient gl(k) as follows:
if ùú∂(k)‚ä§log ùúº(k) < 0
gl(k) = ùõºl(k),
else
if ùúÑk = ik
gl(k) = pl(k)sl(k)‚àï(ùúÇl(k)vl), l = 1, ‚Ä¶ , L,
if ùúÑk = jk
gl(k) = ql(k)tl(k)ùúÇl(k)‚àïvl, l = 1, ‚Ä¶ , L.
end if
4. Update ùúº(k + 1):
ùúº(k + 1) ‚Üêùúº(k)e‚àíùúà(k)(ùê†(k)‚àïùüè‚ä§ùê†(k)).
5. Update ùúà(k + 1) according to Theorem 5.3 and go to Step 1.
Remark 5.4
As we run Algorithm 5.1 at each iteration of Algorithm 5.2 as an
inner loop, Algorithm 5.2 is a two time-scale algorithm. At Step 2, we obtain the
primal network power ùê©(k) and the primal network interference temperature ùê™(k)
from the output of Algorithm 5.1 by using the input weight parameter ùúº(k). Similarly,
we can also obtain the dual network power ùê¨(k) and the dual network interference
temperature ùê≠(k) in the same way. This means that ùê©(k), ùê™(k), ùê¨(k), and ùê≠(k) are the
optimal solutions of Algorithm 5.1 for a given ùúº(k). The computation of ùüè‚ä§‚àáU(ùúº(k)),
ùú∂(k)‚ä§log ùúº(k), and ùüè‚ä§ùê†(k) can be made distributed by a gossip algorithm [42].
5.3.7
A Software Implementation
The spectral radius function is an important feature that characterizes the optimal
wireless network utility. We next discuss how to compute this function numerically
when it is used in optimization problems. Our spectral radius function is implemented
as a Matlab routine using the cvx software. The cvx software tool in Reference 44 is
a Matlab toolbox software for rapid definition, manipulation, and solution of convex
optimization problems and is freely available for download. This cvx software solves
optimization problems that are appropriately modeled using a set of libraries known
as atom library in cvx. The modularity of the atom library software facilitates new
functionalities that are specific to some optimization problems with unique features
by adding new (user-defined) cvx atoms in cvx. In addition, new cvx atoms need
to follow the disciplined convex programming ruleset (DCP ruleset for short), which
are drawn from basic principles of convex optimization. This means that a violation
of a set of modeling rules can lead to parsing software error.
We now discuss how the convex spectral radius function used in the previous
sections given by
f(ÃÉùú∏) = ùúå( diag(eÃÉùú∏)ùêÅ),
(5.42)

THE WIRELESS NETWORK DUALITY
117
can conform to the cvx DCP ruleset, thereby facilitating its cvx implementation to
solve optimization problems. A trick to numerically evaluate Eq. (5.42) is an appli-
cation of the Perron‚ÄìFrobenius theorem to rewrite Eq. (5.42) as
f ‚à∂‚ÑùL ‚Üí‚Ñù+,
f(ÃÉùú∏) ‚âúinf{ùúÜ| diag(eÃÉùú∏)ùêÅùê≥‚â§ùúÜùê≥},
where ùê≥‚àà‚ÑùL is an (auxiliary) optimization variable. Thus, Eq. (5.42) can be evalu-
ated numerically by solving a geometric program (a special class of convex optimiza-
tion problems). Using the cvx software, the implementation of the spectral radius
function in cvx is given by
function cvx_optval = spectral_radius( x, B )
s = size( B, 1 );
cvx_begin gp
variables rho z( s )
minimize( rho );
subject to
diag( exp(x) ) * B * z <= rho * z;
cvx_end
The above function cvx_optval is then put into a subdirectory named
as @cvx in the cvx software package, and Matlab can automatically recognize
the function call of spectral_radius whenever it is used in the constraints or
objectives of a convex optimization problem that follows the cvx DCP ruleset. This
cvx software implementation can be useful for verifying the solution computed by
the distributed dual algorithms and the nonlinear Perron‚ÄìFrobenius-theory-based
fixed-point algorithm in the previous sections.
5.3.8
Connection between Dual Algorithm and Pricing Function
in Game Theory
There are several approaches in the literature to solving the wireless utility maxi-
mization problem. A well-studied approach to maximize the utility using distributed
power control is to design a noncooperative power control game where users maxi-
mize their utility. The outcome of the game results in a Nash equilibrium that is often
inefficient.
In the seminal work [11], pricing of transmit powers was introduced to obtain
Pareto improvement of the noncooperative power control game, that is, to obtain
improvements in user utilities relative to the case with no pricing. In particular, the
lth user solves a local utility maximization problem given by
maximize
ul(SINR(ùê©)) + cl(ùê©)
subject to
ùê©‚ààùí´,
ùê™‚ààùí¨,
variables:
pl, ql,
(5.43)

118
DUAL PRICING ALGORITHMS BY WIRELESS NETWORK DUALITY
where cl(‚ãÖ) is a general pricing function, which is not restricted to any particular form.
In Eq. (5.43), the lth user treats the transmit powers of other users as fixed and only
optimizes its own transmit power. In Reference 11, the pricing function is linearly pro-
portional to the transmit powers in Eq. (5.43), that is, cl(ùê©) = cùõºlpl, where c and {ùõºl}
are positive scalars. Clearly, this pricing function imposes a price that increases with
the transmit power of the user. The pricing factor, that is, c, is a common parameter
shared by all the users in the game. It is important to note that c has to be appro-
priately tuned (possibly by a centralized controller through multiple rounds of the
noncooperative power control game) such that user‚Äôs self-interest leads to best pos-
sible improvement in overall utility maximization.
Saraydar et al. [11] also explored the noncooperative game equilibrium of equaliz-
ing the SINR (called the equal-SIR equilibrium in Reference 11), which is equivalent
to solve the max‚Äìmin SINR fairness optimization in Eq. (5.16). It is interesting to
note that the max‚Äìmin SINR fairness optimization (when used appropriately as an
iterative computational submodule) can achieve the social optimum in terms of util-
ity maximization (as used in our dual algorithms). In the following, we state a result
that establishes a connection between our dual algorithms for solving Eq. (5.8) in the
previous sections and the noncooperative game-theoretic pricing function introduced
in Reference 11.
Theorem 5.4
The optimal solution of Eq. (5.43) is equal to the optimal solution of
Eq. (5.8), if the pricing function cl(ùê©) is given by
cl(ùê©) = ‚àí(1‚àïùúîl)
L
‚àë
j‚â†l
ùúîjuj(ùê©).
(5.44)
Proof:
Denote the optimal power of Eq. (5.8) by ùê©‚ãÜ, and ùê©‚Ä≤ is a vector with p‚Ä≤
j =
p‚ãÜ
j , j ‚â†l and p‚Ä≤
l being any feasible value satisfying ùê©‚Ä≤ ‚ààùí´. Then, we have
L
‚àë
j=1
ùúîjuj(ùê©‚ãÜ) ‚â•
L
‚àë
j=1
ùúîjuj(ùê©‚Ä≤).
(5.45)
Dividing both sides of Eq. (5.45) by ùúîl and separating ul(ùê©‚ãÜ) and ul(ùê©‚Ä≤), respectively,
from the summation, we can obtain
ul(ùê©‚ãÜ) + 1
ùúîl
L
‚àë
j‚â†l
ùúîjuj(ùê©‚ãÜ) ‚â•ul(ùê©‚Ä≤) + 1
ùúîl
L
‚àë
j=1
ùúîjuj(ùê©‚Ä≤).
(5.46)
Substituting Eq. (5.44) into Eq. (5.46), we can rewrite Eq. (5.46) as ul(ùê©‚ãÜ) ‚àícl(ùê©‚ãÜ) ‚â•
ul(ùê©‚Ä≤) ‚àícl(ùê©‚Ä≤), which is the definition of a Nash equilibrium [11].
‚óæ

NUMERICAL EXAMPLES
119
5.4
NUMERICAL EXAMPLES
In this section, we provide numerical examples to illustrate the performance of Algo-
rithm 5.1 in Section 5.3.3 and Algorithm 5.2 in Section 5.3.6, illustrating the con-
vergence properties of Algorithms 5.1 and 5.2. Recall that an optimization problem
having two different utility functions can be constructed to yield the same optimal
solution for egalitarian SINR fairness (cf. (5.23) in Section 5.3.3). By setting the
weight of Eq. (5.23) appropriately, and applying Algorithms 5.1 and 5.2 to solve
the max‚Äìmin SINR and the weighted sum of logarithmic SINR utility, respectively,
we evaluate the numerical convergence of the power and interference temperature
iterates.
We use the following channel gain matrix
ùêÜ=
‚é°
‚é¢
‚é¢
‚é¢‚é£
0.69
0.12
0.14
0.13
0.70
0.13
0.14
0.15
0.75
‚é§
‚é•
‚é•
‚é•‚é¶
,
and the following weights for the power constraints:
ùê∞1 = [ 0.8491 0.9340 0.6781 ]‚ä§
ùê∞2 = [ 0.7577 0.7431 0.3922 ]‚ä§
ùê∞3 = [ 0.6555 0.1712 0.7060 ]‚ä§.
We set ùê©= [1.50 1.00 1.20]‚ä§W and ùê™= [2.50 3.00 2.20]‚ä§W. The noise power
of each user is 1 W.
Figure 5.5 plots the evolution of the power and interference temperature for three
users that run Algorithm 5.1 with ùú∑equal to ùüè. We set the initial power vector to
ùê©(0) = [0.5 0.5 0.5]‚ä§W and run Algorithm 5.1 for 10 iterations before it terminates.
0
2
4
6
8
10
0.48
0.5
0.52
0.54
0.56
0.58
Iteration
(a)
(b)
Power (W)
Evolution of power
 
User 1 (Algorithm 5.1)
User 2 (Algorithm 5.1)
User 3 (Algorithm 5.1)
0
2
4
6
8
10
1.5
1.55
1.6
1.65
1.7
Iteration
Interference (W)
Evolution of interference
 
User 1 (Algorithm 5.1)
User 2 (Algorithm 5.1)
User 3 (Algorithm 5.1)
Figure 5.5
Illustration of the convergence of Algorithm 5.1 with randomly chosen initial
ùê©(0). We plot the trajectory of power for each of the three users in (a) and the trajectory of
interference temperature for each of the three users in (b). We can observe from the figures
that the convergence of Algorithm 5.1 is geometrically fast.

120
DUAL PRICING ALGORITHMS BY WIRELESS NETWORK DUALITY
0
100
200
300
400
500
600
700
0.2
0.4
0.6
0.8
1
1.2
Iteration
Power (W)
Evolution of power
User 1 (Algorithm 5.2)
User 2 (Algorithm 5.2)
User 3 (Algorithm 5.2)
0
100
200
300
400
500
600
700
1.4
1.5
1.6
1.7
1.8
1.9
Iteration
Interference (W)
Evolution of interference
User 1 (Algorithm 5.2)
User 2 (Algorithm 5.2)
User 3 (Algorithm 5.2)
(a)
(b)
Figure 5.6
Illustration of the convergence of Algorithm 5.2 with randomly chosen initial
ùúº(0). Algorithm 5.2 is a distributed algorithm. ùê©(k) and ùê™(k) are obtained from Step 2, which
terminates when ùúÄ= 10‚àí13. The number of iterations in the figure corresponds to the outer loop
(slower time scale). We plot the trajectory of power for each of the three users in (a) and the
trajectory of interference temperature for each of the three users in (b).
Figure 5.5 shows that Algorithm 5.1 converges geometrically fast to the optimal solu-
tion (verifying Theorem 5.2). The optimal ùú∏‚ãÜis [0.3273 0.3273 0.3273]‚ä§(verifying
Lemma 5.1).
Figure 5.6 plots the evolution of the power and interference temperature for
three users that run Algorithm 5.2. The objective function that we use in this
numerical example is U(ùú∏) = ‚àëL
l=1 ùúîl log ùõæl, where ùùéis [0.23 0.41 0.36]‚ä§. The
sum of weighted logarithmic SINR satisfies Assumption 5.1. We set the initial ùúºto
ùúº(0) = [0.82 0.90 1.11]‚ä§and run Algorithm 5.2 for 700 iterations and run Algorithm
5.1 as an inner loop. The stopping criterion for the inner loop is ùúÄ= 10‚àí13. We use
a constant step size, that is, ùúà(k) = 0.04 for all k. Figure 5.6 shows that Algorithm
5.2 converges to the optimal solution (verifying Theorem 5.3). The optimal ùê©‚ãÜ
is [0.31 0.57 0.86]‚ä§W and the optimal ùê™‚ãÜis [1.72 1.65 1.51]‚ä§W so that ùê∞‚ä§
2 ùê©‚ãÜ
is equal to p2 (verifying Theorem 5.1). We also adjust the value of ùúÄto verify
the robustness of our algorithm. Figure 5.7 shows the evolution of the power and
0
100
200
300
400
500
600
700
0.2
0.4
0.6
0.8
1
1.2
Iteration
(a)
(b)
Power (W)
Evolution of power
User1 (Algorithm 5.2)
User2 (Algorithm 5.2)
User3 (Algorithm 5.2)
0
100
200
300
400
500
600
700
1.4
1.5
1.6
1.7
1.8
1.9
Iteration
Interference (W)
Evolution of interference
 
User1 (Algorithm 5.2)
User2 (Algorithm 5.2)
User3 (Algorithm 5.2)
Figure 5.7
An illustration of Algorithm 5.2. All the other parameters are the same as Figure
5.6 except that ùúÄ= 10‚àí3.

NUMERICAL EXAMPLES
121
500
(a)
(b)
1000
1500
2000
2500
3000
0.04
0.06
0.08
0.1
0.12
0.14
Iteration
Power (W)
Evolution of power
User1 (Algorithm 5.2)
User2 (Algorithm 5.2)
User3 (Algorithm 5.2)
User4 (Algorithm 5.2)
User5 (Algorithm 5.2)
500
1000
1500
2000
2500
3000
1.8
1.85
1.9
1.95
2
Iteration
Interference (W)
Evolution of interference
User1 (Algorithm 5.2)
User2 (Algorithm 5.2)
User3 (Algorithm 5.2)
User4 (Algorithm 5.2)
User5 (Algorithm 5.2)
Figure 5.8
An illustration of Algorithm 5.1 for 30 users. In this figure, we show the power
and interference temperature evolution for only five users.
interference temperature when the inner loop of Algorithm 5.2, that is, Algorithm
5.1, terminates with ùúÄ= 10‚àí3 keeping all the other parameters the same as those
used in Figure 5.6. Furthermore, we also run Algorithm 5.2 with a suitably large
number of primary and secondary users. Figure 5.8 shows the evolution of the power
and interference temperature for 5 users out of 30 users.
Next, we compare the convergence of the power and interference temperature
in two different problems that have the same optimal solution. From the second
numerical example, we already know in advance that the second power constraint
is tight at optimality. Thus, we can set U(ùú∏) = ‚àëL
l=1
(ùê±(ùêÅ2)‚àòùê≤(ùêÅ2))
l log ùõæl. Although
the solution of these two different problems are the same, Figure 5.9 shows that Algo-
rithm 5.1 converges faster than Algorithm 5.2.
To illustrate, we list down the cvx Matlab routine to solve the following utility
maximization problem example using the cvx atom mentioned in Section 5.3.7:
0
500
1000
1500
2000
2500
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
Iteration
(a)
(b)
Power (W)
Evolution of power (User 1)
Max‚àímin SINR
Sum of log SINR
0
500
1000
1500
2000
2500
1.6
1.7
1.8
1.9
2
2.1
2.2
Iteration
Interference (W)
Evolution of interference (User 1)
Max‚àímin SINR
Sum of log SINR
Figure 5.9
Performance comparison of Algorithms 5.1 and 5.2 by solving two equivalent
problems, namely, Eqs. (5.16) and (5.9) with a utility given by Eq. (5.23). (a) and (b) show
the trajectories of the power and the interference temperature iterates, respectively, for User 1.
The number of iterations in the figure corresponds to the inner loop (faster time scale). With
the weight ùùéchosen as in Eq. (5.23), these two algorithms converge to the same solution. As
shown, Algorithm 5.1 converges much faster than Algorithm 5.2.

122
DUAL PRICING ALGORITHMS BY WIRELESS NETWORK DUALITY
minimize
ùùé‚ä§ÃÉùú∏
subject to
log ùúå( diag(eÃÉùú∏)ùêÅl
) ‚â•0,
l = 1, ‚Ä¶ , 3
variables:
ÃÉùú∏.
(5.47)
Using the software atom developed for the spectral radius function in Section 5.3.7,
the cvx code to solve Eq. (5.47) numerically is given by
cvx_begin
variables gamma_tilde(3)
maximize( w‚Äô * gamma_tilde );
subject to
log( spectral_radius( gamma_tilde, B1 ) ) <= 0;
log( spectral_radius( gamma_tilde, B2 ) ) <= 0;
log( spectral_radius( gamma_tilde, B3 ) ) <= 0;
cvx_end
In the above, the matrices B1, B2, and B3 are evaluated using Eq. (5.17), and they
contain the problem parameters, that is, the channel gains, the weight and weighted
power constraints, and so on.
5.5
CONCLUSION
We studied the network utility maximization in a wireless network with both power
budget constraints and interference temperature constraints in this chapter. We first
reformulated the problem as one in the SINR domain that has appropriately con-
structed spectral radius constraints. The advantages of our reformulation were that,
firstly, it captured the entire feasible SINR region and, secondly, it decoupled the
SINR assignment for primary and secondary users from power and interference tem-
perature control. We also studied a special case of egalitarian fairness utility, which is
the max‚Äìmin weighted SINR problem using the nonlinear Perron‚ÄìFrobenius theory,
and a geometrically fast convergent (with no parameter tuning) algorithm was pro-
posed to solve this max‚Äìmin weighted SINR problem. Then, we developed a wireless
network duality and established its connection to the gradient of the spectral radius
function as shadow prices for SINR assignment in the general utility maximization
problem. We leveraged the wireless network duality and an interference load min-
imization problem, which interestingly is related to the max‚Äìmin weighted SINR
problem, to develop a distributed algorithm to solve the utility maximization problem.
Extensive numerical examples demonstrated the good performance of our algorithms,
particularly the flexibility, the fast convergence time, and the robustness to different
numbers of primary and secondary users. We also discussed a connection between
this shadow price dual algorithm approach for utility maximization with a noncoop-
erative power control game in obtaining improvements in user utilities relative to the
case with no pricing.

REFERENCES
123
REFERENCES
1. S. Ha, S. Sen, C. Joe-Wong, Y. Im, and M. Chiang. TUBE: time-dependent pricing for
mobile data. In Proceedings of ACM SIGCOMM, 2012.
2. C. Joe-Wong, S. Ha, and M. Chiang. Time dependent broadband pricing: feasibility and
benefits. In Proceedings of IEEE ICDCS, 2011.
3. S. Sorooshyari, C. W. Tan, and M. Chiang. ‚ÄúPower control for cognitive radio networks:
axioms, algorithms, and analysis,‚Äù IEEE/ACM Transactions on Networking, 20(3), 2012,
878‚Äì891.
4. S. Ren and M. van der Schaar. ‚ÄúData demand dynamics in wireless communications mar-
kets,‚Äù IEEE Transactions on Signal Processing, 60(4), 2012, 1986‚Äì2000.
5. Y. Cui, T. Ma, and X. Cheng. Multi-hop access pricing in public area WLANs. In Pro-
ceedings of IEEE INFOCOM, 2011.
6. P. Hande, M. Chiang, R. Calderbank, and S. Rangan. Network pricing and rate allocation
with content provider participation. In Proceedings of IEEE INFOCOM, 2009.
7. P. Hande, M. Chiang, R. Calderbank, and J. Zhang. Pricing under constraints in access
networks: revenue maximization and congestion management. In Proceedings of IEEE
INFOCOM, 2010.
8. E. Altman, P. Bernhard, S. Caron, G. Kesidis, J. Rojas-Mora, and S. Wong. ‚ÄúA model
of network neutrality with usage-based prices,‚Äù Telecommunication Systems, 52(2), 2011,
1‚Äì9.
9. S. Caron, G. Kesidis, and E. Altman. ‚ÄúApplication neutrality and a paradox of side pay-
ments,‚Äù In Proc. ACM ReARCH, 2010.
10. S. Ren, J. Park, and M. van der Schaar. ‚ÄúEntry and spectrum sharing scheme selection
in femtocell communications markets,‚Äù IEEE/ACM Transactions on Networking, 21(1),
2012, 218‚Äì232.
11. C. U. Saraydar, N. B. Mandayam, and D. J. Goodman. ‚ÄúEfficient power control via pric-
ing in wireless data networks,‚Äù IEEE Transactions on Communications, 50(2), 2002,
291‚Äì303.
12. S. Shakkottai and R. Srikant. ‚ÄúEconomics of network pricing with multiple ISPs,‚Äù
IEEE/ACM Transactions on Networking, 14(6), 2006, 1233‚Äì1245.
13. S. Shakkottai, R. Srikant, A. Ozdaglar, and D. Acemoglu. ‚ÄúThe price of simplicity,‚Äù IEEE
Journal on Selected Areas in Communications, 26(7), 2008, 1269‚Äì1276.
14. T. Basar and R. Srikant. Revenue-maximizing pricing and capacity expansion in a
many-users regime. In Proceedings of IEEE INFOCOM, vol. 1, 2002.
15. S. Shakkottai and R. Srikant. ‚ÄúNetwork optimization and control,‚Äù NOW Monograph in
Foundations and Trends in Networking, 2(3), 2007, 271‚Äì379.
16. M. Chiang, P. Hande, T. Lan, and C. W. Tan. ‚ÄúPower control in wireless cellular networks,‚Äù
NOW Monograph in Foundations and Trends in Networking, 2(4), 2008, 381‚Äì533.
17. P. Hande, S. Rangan, M. Chiang, and X. Wu. ‚ÄúDistributed uplink power control for optimal
SIR assignment in cellular data networks,‚Äù IEEE/ACM Transactions on Networking, 16(6),
2008, 1420‚Äì1433.
18. S. Huang, X. Liu, and Z. Ding. ‚ÄúDecentralized cognitive radio control based on inference
from primary link control information,‚Äù IEEE Journal on Selected Areas in Communica-
tions, 29(2), 2011, 394‚Äì406.

124
DUAL PRICING ALGORITHMS BY WIRELESS NETWORK DUALITY
19. M. Lotfinezhad, L. Ben, and E. S. Sousa. Optimal control of constrained cognitive radio
networks with dynamic population size. In Proceedings of IEEE INFOCOM, 2010.
20. S. Rangan and R. Madan. ‚ÄúBelief propagation methods for intercell interference coordina-
tion in femtocell networks,‚Äù IEEE Journal on Selected Areas in Communications, 30(3),
2012, 631‚Äì640.
21. A. L. Stolyar and H. Viswanathan. Self-organizing dynamic fractional frequency reuse
for best-effort traffic through distributed inter-cell coordination. In Proceedings of IEEE
INFOCOM, 2009.
22. A. L. Stolyar and H. Viswanathan. Self-organizing dynamic fractional frequency reuse in
OFDMA systems. In Proceedings of IEEE INFOCOM, 2008.
23. K. R. Krishnan and H. Luss. Power selection for maximizing SINR in femtocells for spec-
ified SINR in macrocell. In Proceedings of IEEE WCNC, 2011.
24. C. W. Tan, M. Chiang, and R. Srikant. ‚ÄúFast algorithms and performance bounds for sum
rate maximization in wireless networks,‚Äù IEEE/ACM Transactions on Networking, 21(3),
2012, 706‚Äì719.
25. L. Zheng and C. W. Tan. ‚ÄúCognitive radio network duality and algorithms for utility max-
imization,‚Äù IEEE Journal on Selected Areas in Communications, 31(3), 2013, 500‚Äì513.
26. C. W. Tan, M. Chiang, and R. Srikant. ‚ÄúMaximizing sum rate and minimizing MSE on mul-
tiuser downlink: optimality, fast algorithms and equivalence via max‚Äìmin SINR,‚Äù IEEE
Transactions on Signal Processing, 59(12), 2011, 6127‚Äì6143.
27. C. W. Tan, S. Friedland, and S. H. Low. ‚ÄúNonnegative matrix inequalities and their appli-
cation to nonconvex power control optimization,‚Äù SIAM Journal on Matrix Analysis and
Applications, 32(3), 2011, 1030‚Äì1055.
28. C. W. Tan, S. Friedland, and S. H. Low. ‚ÄúSpectrum management in multiuser cognitive
wireless networks: optimality and algorithm,‚Äù IEEE Journal on Selected Areas in Com-
munications, 29(2), 2011, 421‚Äì430.
29. J. Mo and J. Walrand. ‚ÄúFair end-to-end window-based congestion control,‚Äù IEEE/ACM
Transactions on Networking, 8(5), 2000, 556‚Äì567.
30. J. F. C. Kingman. ‚ÄúA convexity property of positive matrices,‚Äù Proceedings of the American
Mathematical Society, 12(2), 1961, 283‚Äì284.
31. S. Boyd and L. Vanderberghe. Convex Optimization. Cambridge University Press, Cam-
bridge, U.K, 2004.
32. P. Viswanath and D. N. C. Tse. ‚ÄúSum capacity of the vector Gaussian broadcast channel
and uplink‚Äìdownlink duality,‚Äù IEEE Transactions on Information Theory, 49(8), 2003,
1912‚Äì1921.
33. W. Yu. ‚ÄúUplink‚Äìdownlink duality via minimax duality,‚Äù IEEE Transactions on Informa-
tion Theory, 52(2), 2006, 361‚Äì374.
34. F. Rashid-Farrokhi, K. J. Ray Liu, and L. Tassiulas. ‚ÄúTransmit beamforming and power
control for cellular wireless systems,‚Äù IEEE Journal on Selected Areas in Communica-
tions, 16(8), 1998, 1437‚Äì1449.
35. B. Song, R. L. Cruz, and B. D. Rao. ‚ÄúNetwork duality for multiuser MIMO beam-
forming networks and applications,‚Äù IEEE Transactions on Communication, 55(3), 2007,
618‚Äì630.
36. D. W. H. Cai, T. Quek, and C. W. Tan. ‚ÄúA unified analysis of max‚Äìmin weighted SINR
for MIMO downlink system,‚Äù IEEE Transactions on Signal Processing, 59(8), 2011,
3850‚Äì3862.

REFERENCES
125
37. D. W. H. Cai, T. Quek, C. W. Tan, and S. H. Low. ‚ÄúMax‚Äìmin SINR coordinated multipoint
downlink transmission - duality and algorithms,‚Äù IEEE Transactions on Signal Processing,
60(10), 2012, 5384‚Äì5395.
38. C. W. Tan, D. P. Palomar, and M. Chiang. ‚ÄúEnergy-robustness tradeoff in cellular network
power control,‚Äù IEEE/ACM Transactions on Networking, 17(3), 2009, 912‚Äì925.
39. U. Krause. ‚ÄúConcave Perron‚ÄìFrobenius theory and applications,‚Äù Nonlinear Analysis,
47(2001), 2001, 1457‚Äì1466.
40. D. P. Bertsekas. Nonlinear Programming. Athena Scientific, Belmont, MA, USA, 2nd
edition, 2003.
41. G. J. Foschini and Z. Miljanic. ‚ÄúA simple distributed autonomous power control algorithm
and its convergence,‚Äù IEEE Transactions on Vehicular Technology, 42(4), 1993, 641‚Äì646.
42. S. Boyd, A. Ghosh, and D. Shah. ‚ÄúRandomized gossip algorithms,‚Äù IEEE Transactions on
Information Theory, 52(6), 2006, 2508‚Äì2530.
43. S. Friedland and S. Karlin. ‚ÄúSome inequalities for the spectral radius of non-negative matri-
ces and applications,‚Äù Duke Mathematical Journal, 42(3), 1975, 459‚Äì490.
44. M. Grant and S. Boyd. CVX: Matlab software for disciplined convex programming, ver-
sion 1.21, 2011. http://cvxr.com/cvx.


6
Human Factors in Smart Data
Pricing
SOUMYA SEN, CARLEE JOE-WONG, SANGTAE HA,
and MUNG CHIANG
6.1
INTRODUCTION
Smart data pricing (SDP) explores mechanisms beyond traditional flat-rate or
usage-based pricing models to alleviate network congestion, monetize bandwidth,
and help consumers save on their monthly bills. But realizing such mechanisms
requires the creation of the right economic incentives and tools to understand
and modify consumer behavior in a desired manner. The need for such a holistic
approach makes SDP a truly interdisciplinary research topic that draws on principles
from network engineering, economics, and human‚Äìcomputer interaction (HCI).
Therefore, understanding how to enable consumers to respond to SDP incentives
remains the most important factor in the successful adoption of such data pricing
plans. HCI researchers have explored related issues in the context of computer
networks and electricity markets, and in this chapter, we introduce these earlier
findings and build on them to address the needs of mobile networks. In mobile
networks, the feasibility of SDP is particularly promising because of the variance in
users‚Äô content consumption behaviors, varying degrees of elasticity of demand of
different content types, and the richness of capabilities afforded by smart devices to
make them a part of the network congestion management infrastructure.
Past research has shown that consumers prefer simplicity in billing, predictability
in their expense, and ease in understanding feedback (e.g., pricing signals) from the
network. Hence, for SDP to be successful, these user concerns must be addressed in
both the realization of the data plan (i.e., creation of economic incentives) and the
means of communicating with users (i.e., the design of the user interfaces (UIs) for
the feedback-control loop between the users and the network operators). To achieve
this, we need to understand user psychology through HCI techniques such as focus
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
127

128
HUMAN FACTORS IN SMART DATA PRICING
group studies, testing of user reaction to designs of interfaces that convey the pricing
signals, development of experimental testbeds and application prototypes for offering
new pricing plans, and field trials of these pricing plans.
In this chapter, we first discuss some of the basic principles and methodologies of
HCI research in Section 6.2, followed by a detailed overview of findings from previ-
ous HCI works that have studied user psychology in energy markets (Section 6.3),
home network management (Section 6.4), and bandwidth pricing (Section 6.5).
We then discuss in Section 6.6 how day-ahead dynamic time-dependent pricing
(DDTDP) has the potential to account for the lessons learned from previous HCI
research and meet the design goals of creating a ‚Äúwin‚Äîwin‚Äù for both consumers
and operators. We follow this introduction to DDTDP with a discussion of the per-
spectives of various stakeholders of the Internet ecosystem (i.e., network operators,
users, application developers, content providers, and regulators) on the feasibility
and promise of DDTDP in Section 6.7. In Section 6.8, we then discuss our trial of
DDTDP, the system implementation and the graphical user interface (GUI) features,
followed by the results from the trial using both HCI-based qualitative findings (e.g.,
from focus groups, trial debriefing) and quantitative validation (e.g., from usage
logs). Finally, we conclude in Section 6.9 with a discussion of the results learned
from this trial and past HCI works, as well as future directions that can be explored
as SDP practices continue to evolve.
6.2
METHODOLOGY
In this section, we give an overview of HCI research techniques relevant to SDP. We
focus on the process of designing and testing the effectiveness of SDP systems, for
example, designing UIs for offering prices and then evaluating them through expert
analysis and field or laboratory studies. For a more detailed overview of HCI in
general, including its theoretical underpinnings, we refer the reader to Reference 1.
Readers familiar with the basic design principles and methodologies may skip ahead
to Section 6.3 for information on prior HCI works on related topics.
6.2.1
Designing Systems with Users in Mind
Arguably, the most important factor in the successful adoption of SDP mechanisms
is the usability and convenience of the application interfaces designed to modify user
behavior. As many SDP mechanisms involve direct user interaction with the prices
[e.g., selecting a desired quality-of-service (QoS) or delaying traffic to later times],
complete SDP systems usually require a UI to facilitate this interaction. This interface
should effectively communicate relevant information and simplify actions desired by
users, for example, making it easy for them to delay a particular app until a cheaper
time.
Interface design begins by considering the goals of target users. In the context of
SDP, these would be SDP customers, with the general goal of saving as much money
as possible without compromising their experience. More specifically, we can con-
struct scenarios of how a user might interact with the interface; for instance, suppose

METHODOLOGY
129
an Internet Service Provider (ISP) offers a QoS-based pricing plan, in which a user
can choose to pay more for higher QoS on a given session. One scenario might be that
‚ÄúAlice is streaming YouTube on her Galaxy tablet during her lunch break and wants
to view an HD video with higher QoS. She opens the pricing app on her tablet, scrolls
through a list of apps to the YouTube app, and checks the box with ‚Äòhigher QoS.‚Äô She
then clicks on the YouTube icon, opening the YouTube app, and starts playing the
video with higher QoS.‚Äù
Scenarios allow designers to imagine tasks that a user wishes to perform, which
express the dynamics of the interface and allow problems to be spotted in transi-
tioning from one stage of a task to another. Designers can also imagine scenarios
in which users make errors and wish to correct them‚Äîfor instance, if a user acci-
dentally selects the wrong app for higher QoS, is there a clear sequence of actions
for unselecting it? By focusing on a user‚Äôs perspective, scenarios allow a designer to
simplify user interactions and transitions between app screens.
To facilitate navigation among screens, a designer needs to ensure that links to
different screens are clearly labeled and visible. In particular, users should under-
stand the effect of clicking any given button, for example, whether it will simply
bring them to another screen or take some action that affects the amount spent on
their data plan. If a user is required to provide input to the interface, such as speci-
fying particular apps for higher QoS, then the interface must first indicate the types
of information being requested. We illustrate some key principles of interface design
by discussing DataWiz,1 a free mobile application for data monitoring for iOS and
Android platforms, which was developed by the authors and colleagues at DataMi.2
DataWiz is a monitoring and alerting application with several desirable functional-
ities, but does not include pricing components. These GUIs, shown in Figure 6.1,
were based on several focus group studies, feedback from multiple network opera-
tors, and the help of HCI researchers and professional graphic designers and app
developers:
‚Ä¢ Consistency. Navigation sequences, layout, and terminology should be as con-
sistent as possible throughout the app, for example, similar displays for daily
and monthly information. DataWiz‚Äôs main screen (Fig. 6.1a) allows users to tap
the weekly and monthly bars to display weekly or monthly usage on the center
pie chart, in a manner analogous to the daily usage shown in the figure.
‚Ä¢ Shortcuts. Users should be able to quickly execute repeated sequences of
actions, for example, selecting some actions as ‚Äúdefault.‚Äù For instance, tapping
the monthly bar of the main screen in Figure 6.1a displays the monthly usage
on the pie chart, while the default was set to daily usage to give the user an
immediate update on how much data he/she has used up from his/her ‚Äúvirtual‚Äù
daily quota.
‚Ä¢ Informative Feedback. Should a user input something into the interface, there
should be some confirmation, for example, highlighting an app after it is
1DataWiz, http://scenic.princeton.edu/datawiz/.
2DataMi, http://www.datami.com.

130
HUMAN FACTORS IN SMART DATA PRICING
(a)
(b)
(c)
(d)
(e)
(f)
Figure 6.1
DataWiz screenshots, illustrating basic design principles. (a) Home screen, (b)
usage graphs, (c) usage prediction, (d) usage details,(e) maps screen, and (f) settings screen.
selected, to confirm that this input was received. In Figure 6.1b, users can
switch between displaying 3G and WiFi, as well as daily, weekly, and monthly
usage. Their selection is highlighted accordingly, for example, 3G monthly
usage in the figure.
‚Ä¢ Closure. Users should receive an indication when an action has been completed,
for example, confirmation that they have finished selecting higher QoS. For
instance, when toggling between DataWiz‚Äôs graph displays in Figure 6.1b, a
new graph is displayed when the selection has been completed.
‚Ä¢ Error Prevention and Handling. Users should be able to easily reverse actions or
go back to a previous screen, aiding them in correcting errors and reducing user
anxiety at accidentally pressing a wrong button. For instance, users at DataWiz‚Äôs

METHODOLOGY
131
usage prediction screen (Fig. 6.1c) can press the back button to easily return to
the home screen of Figure 6.1a.
‚Ä¢ Simplicity. Few screens and simple displays are easier for users to understand
and take less storage on the interface‚Äôs physical device. In DataWiz, the number
of screens is minimized, with the app‚Äôs main screens easily accessible from the
four links on the top of the screens in Figure 6.1c‚Äìe.
To achieve these goals, designers can manipulate the following basic visual tools of
interface design to suggest appropriate actions to users.
‚Ä¢ Font and Color. Font style and color can be used to further differentiate different
groupings. For instance, one section might have a white and another a dark gray
background. On DataWiz‚Äôs usage prediction screen (Fig. 6.1c), colors separate
the past from the future: the white bars indicate future (i.e., predicted) usage,
whereas green bars indicate past usage. The larger font of the dates of the usage
details screen in Figure 6.1d shows how font size can be used to draw attention
to blocks of text, while the orange icons in the map screen of Figure 6.1e draw
attention to the locations where the user has consumed data.
‚Ä¢ Grouping and Structure. Information that is logically separate should be sepa-
rated either by space or by placing it on different lines, for example, prices for
different times of the day might be separated by extra space between them. On
DataWiz‚Äôs settings page in Figure 6.1f, we see this grouping with thicker lines
dividing the billing data, data cap, and alert settings.
‚Ä¢ Alignment and Order. Users generally read from top to bottom and left to right;
thus information should be placed to reflect this order. For instance, in a list of
prices and corresponding times, we might put the most recent time at the top
to reflect the fact that it is most immediately important. In the DataWiz app,
the monthly data cap setting is listed above the weekly and daily caps on the
settings screen (Fig. 6.1f) to reflect its greater importance.
‚Ä¢ Icons. Design of intuitive icons is an essential component of a well-designed
interface as it helps users to navigate with ease. Figure 6.1c‚Äìe shows naviga-
tional icons on the top (from left to right) for (a) ‚Äúback‚Äù to the home screen
(Fig. 6.1a), (b) the ‚Äúusage prediction‚Äù screen (Fig. 6.1c), (c) the ‚Äúusage details‚Äù
screen (Fig. 6.1d), and (d) the ‚Äúusage location‚Äù or map screen (Fig. 6.1e). Simi-
larly, on the home screen (Fig. 6.1a), the user has access to two additional icons
at the bottom of the screen for modifying ‚Äúsettings‚Äù and viewing the ‚Äúusage
location.‚Äù In between these icons is an icon at the bottom center of the screen
that can be swiped upwards to pull out the usage graphs.
‚Ä¢ White Space. White space allows the designer to separate blocks of related
elements, enforcing the desired grouping and structure. Including extra space
around a particular button or piece of information also highlights this informa-
tion. On DataWiz‚Äôs main screen (Fig. 6.1a), we see white space used around the
center circle to draw attention to its information.
Throughout the design process, a designer should continually evaluate the inter-
face prototype and incorporate feedback to improve the design. Even at the earliest

132
HUMAN FACTORS IN SMART DATA PRICING
iterations, evaluation is important, because it is much easier to correct major mistakes
at an early stage. In the case of SDP, experts might review the design to anticipate
any problems users would have or users might be asked to explore the interface in
a laboratory or a natural setting. In the remainder of this chapter, we consider these
methods for evaluating the success of SDP UIs.
6.2.2
Expert Evaluations
While trials with future users would provide the most accurate evaluation of a proto-
type interface design, it is infeasible to conduct such trials at every design iteration.
Thus, we first focus on methods for expert analysis, which have lower overhead and
can help identify obvious problems. These fall into two categories: ensuring that
designs adhere to accepted cognitive principles and that they are consistent with
known empirical results.
An expert or designer can conduct a cognitive walkthrough with the aid of sce-
nario descriptions like the ones used in the interface design. First, the expert specifies
a user‚Äôs desired task (e.g., delaying an app store download from 8 pm until midnight to
take advantage of lower prices at midnight). Given this task, the evaluator writes down
the specific list of actions required to accomplish the task‚Äîfor instance, clicking on
the ‚ÄúDeferral‚Äù tab in the app, selecting the ‚ÄúApp Store‚Äù application, and entering
‚Äúmidnight‚Äù as the desired time for the App Store to start downloading. For each task,
the evaluator also writes down the system response (e.g., the App Store icon is high-
lighted after it is selected by the user). The evaluator then asks the following four
questions in order to assess whether a user can easily complete the given task.
‚Ä¢ Does the Action Achieve the User‚Äôs Goal at That Point? Is it reasonable to
assume that, as part of achieving the larger task, a user would set the action‚Äôs
effect as an intermediate goal? For instance, the user might make ‚Äúselecting the
App Store‚Äù a subgoal of delaying App Store downloads.
‚Ä¢ Will the User See That the Action Is Available? With each action, the user will
generally need to press a button or provide input. An undesirable design would
require intermediate steps such as navigating to a separate screen on the app to
select the appropriate button.
‚Ä¢ Will Users Be Able to Identify the Appropriate Action? Given that the action‚Äôs
effect is a subgoal and that the user can see that the action is available, the
designer must ensure that users can recognize how to execute this action, for
example, pressing the correct button.
‚Ä¢ Will Users Understand the Feedback from the Action? After a user takes an
action and feedback is given, the user must understand the meaning of this feed-
back, for example, that highlighting a button means it was successfully selected.
More generally, an evaluator can examine the entire system to assess whether it
conforms to general design guidelines, called heuristics. While many different heuris-
tics have been suggested, most generally conform to the design principles suggested
in Section 6.2.1. Additionally, the designer should create a help screen allowing users
to search for documentation and instructions should they require them.

METHODOLOGY
133
6.2.3
Conducting a Field Trial
A trial with real users is the most effective way to test an interface, as the inter-
face‚Äôs success ultimately rests on its reception by users. While user responses can be
best tested in the field, that is, in a user‚Äôs natural environment, in some situations a
controlled laboratory setting may yield more insight. For instance, it is easier to test
specific features of the design when users work with the interface in a controlled set-
ting while the features are varied. Field studies are also usually more expensive, as
a researcher may need to travel to participants‚Äô homes or workplaces and purchase
portable recording equipment. Laboratory studies, on the other hand, require partic-
ipants to take the time to come to a research laboratory. In the following discussion,
we outline different aspects of the trial design for both options.
Participants. It is important to recruit participants representative of actual interface
users, and ideally to choose people who will become actual users. In particular, partic-
ipants‚Äô knowledge of computing devices and their experience with similar interfaces
should be similar to that of real users. The number of participants recruited depends
on the purpose of the trial: if a statistical analysis is used, at least 10 participants are
necessary, while 3‚Äì5 are generally adequate to identify usability problems [2].
Variables and Hypotheses. In a laboratory setting, researchers should identify the
dependent and independent variables. For instance, are researchers comparing the
speed of user response with two different designs? These variables are especially
important in a laboratory setting, where experiments can be set up to evaluate the
dependent variables for all possible combinations of independent variables. The
experiments are designed to test hypotheses or predictions of how the independent
variables affect dependent ones. For instance, we might hypothesize that one design
yields a faster user response than another. The experimental results will then either
validate the hypothesis or validate the null hypothesis, that is, the baseline assump-
tion that the dependent variable is not affected by the independent one. Hypothesis
testing is especially powerful when combined with a careful experimental design
that allows statistical methods to be used for calculating quantitative confidence
metrics of the hypothesis‚Äôs validity.
Experimental Design. Once a hypothesis has been chosen, the experimenter must
choose whether to vary the dependent variables between subjects or within subjects.
Between-subject variation involves randomly sorting subjects into different groups,
each of which will experience a different combination of the independent variables.
One of the groups, designated as the ‚Äúcontrol‚Äù group, experiences no manipulation
of the experimental variables, which helps to ensure that observed differences in the
dependent variables are in fact due to changes in the independent variables. This type
of variation eliminates any learning effect, in which a user‚Äôs experience with one set
of variables affects his or her experience with another.
The learning effect can be a serious disadvantage of within-subject or repeated
experiments, in which the same group of subjects is exposed to a variety of experi-
mental conditions in sequence. By varying the sequence, the learning effect can be
somewhat controlled, though not completely. Within-subject experiments have the
advantage of controlling for subject variation; they also require fewer total subjects

134
HUMAN FACTORS IN SMART DATA PRICING
and thus fewer experimental resources. Another possibility is a mixed design, in
which one variable is manipulated between groups and another within groups.
Quantitative Analysis. Quantitative methods can be combined with standard sta-
tistical tools for hypothesis testing on quantitative variables. SDP‚Äôs main quantitative
aspect is the user‚Äôs willingness to consume less data during congested hours, which
may be tested for different interface designs and pricing plans. However, depending
on the type of SDP in question, other quantitative metrics may also be relevant, for
example, measuring the average amount of time that a user delays apps given a set
of time-dependent prices. Standard statistical tests and comparisons can be used to
conduct such tests [3].
Qualitative Analysis. We identify two main methods of soliciting qualitative data
on participants‚Äô experiences: protocol analysis and interviews or questionnaires. Pro-
tocol analysis can involve analyzing audio or video recordings of the user interacting
with the interface; however, in the context of SDP, it is perhaps more applicable to
think of recording keystrokes within the interface, as pricing interfaces generally
do not require active engagement aside from pressing buttons and typing in input.
These keystrokes can tell us how often users press the wrong buttons, how often they
use different features of the interface, and how rapidly they perform different tasks.
One potentially significant disadvantage is the volume of data collected, especially
from very engaged users; this can be mitigated by automated analysis that summarizes
the raw keystroke logs.
The quantitative data provided by protocol analysis can be supplemented by more
subjective data provided directly by experiment participants. Structured postexper-
iment interviews can provide high level insights into participants‚Äô experience and
identify any unexpected design flaws. These are generally conducted according to an
interview template of topics to cover and specific questions to ask. The interviewer
usually begins with a very general question and then focuses on specific points, either
following the question script or jumping off of comments in the subject‚Äôs responses.
A more fixed form of questioning uses prepared questionnaires or surveys. While
less flexible, these methods also have less overhead and are thus especially effective
with large numbers of subjects or ones in remote locations. Given these limitations,
most experimenters conduct pilot studies with the questionnaire to identify possi-
ble points of confusion or misunderstanding before releasing it to more respondents.
Questionnaires usually need to be distributed to large numbers of people in order to
yield a reasonable number of responses.
Questionnaires should begin by explaining the type of information sought and
then proceed to ask questions tending to this purpose. Given that survey respon-
dents are often self-selecting, the survey should include general questions on a user‚Äôs
background, to put the other responses in context for the experimenter and ensure a
representative sample population. These will then be followed by open-ended, scalar,
multiple-choice, or ranking questions. Open-ended questions are the most flexible
question format but also require more effort on the part of the participant and are
the least likely to yield consistent answers. Thus, it is usually best to employ other
types of questions. Scalar or rank questions ask a user either to assign numbers, for
example, on a scale from 1 to 10, to describe the accuracy of a specific statement;

HCI LESSONS FROM THE ENERGY MARKET
135
or to rank several choices, usually in order of preference. These types of questions
give more consistent results;however, it is important to specify what the numbers
on a scale mean. Moreover, while too many choices can paralyze users or result
in arbitrary decisions, too few can skew responses and miss subtleties in user opin-
ions. If scalar or ranking questions are not appropriate, multiple-choice questions are
usually employed.
6.2.4
Choosing an Evaluation Method
In the above discussion, we identified five methods for evaluating an interface: cogni-
tive walkthroughs, heuristic analysis, statistical methods, laboratory studies, and field
trials. In the latter two cases, we can identify two types of user feedback: interview- or
questionnaire-based and protocol analyses. In Table 6.1, we summarize key features
of these five types of user feedback, as described in Reference 1, to aid researchers
in choosing the evaluation method most appropriate for their situation.
In practice, experimenters would likely combine several of the techniques in
Table 6.1 to gain a comprehensive evaluation. For instance, one could use statistical
and protocol methods to yield objective, evidence-based quantifiable information
and then use information from cognitive walkthroughs, heuristics, or interviews to
ensure that subjective user impressions match this empirical evidence. Interviews and
heuristic analyses would focus more on high level information insights, while other
methods yield insights into the specific effects of different interface features. In terms
of necessary resources, statistical data collection and keystroke logging for protocol
analysis require the most resources, while cognitive walkthroughs require the most
expertise. None of these methods is very intrusive or obvious to users during their
interaction with the interface, introducing only minimal bias into the trial results.
In the next three sections, we explore HCI research works that have utilized the
above methodologies to investigate SDP and related topics in various contexts. We
first discuss lessons on interface design from HCI works in energy markets and then
give an overview of HCI studies on Internet usage and data pricing.
6.3
HCI LESSONS FROM THE ENERGY MARKET
Like broadband networks, electricity grids suffer from periods of peak demand.
To relieve this peak demand, schemes such as time-dependent pricing (TDP) and
usage visualization have been practiced in the electricity market, and hence, lessons
TABLE 6.1
Features of Different Evaluation Methods
Cognitive
Heuristic
Statistical
Interview
Protocol
walkthrough (w.t.)
Objectivity
No
No
Yes
No
Yes
Information
Low level
High level
Low/high level
High level
Low level
Equipment
Low
Low
Medium
Low
Medium
Expertise
High
Medium
Medium
Low
High

136
HUMAN FACTORS IN SMART DATA PRICING
from it can be useful in the context of data networks. HCI works that have studied
users‚Äô energy consumption have ranged from power strips that change color to
show the energy used by individual electrical sockets [4] to a large-scale media art
installation visualizing energy consumption in an office building [5]. These studies
on user-friendly interface design bring out a key trade-off in HCI design, which is
whether to visualize the information on energy usage pictorially or numerically.
The energy consumption monitoring application WattBot used color coding as a
qualitatively simple way to indicate the usage amounts to the users [6]. However,
users have also been found to quantitatively track changes in their energy usage
behavior by viewing their usage history [7] and to care about the convenience of
monitoring their usage. For example, researchers testing a desktop widget that
showed computer energy efficiency found that users appreciated the inconspicuous,
easy-access nature of the widget [8]. These lessons on using color coding for
qualitative feedback and numerical usage history for quantitative feedback can be
transferred to the design of client-side GUIs in broadband pricing applications, as
discussed in Section 6.8.3.
6.4
USER PSYCHOLOGY IN HOME NETWORKS
In Sections 6.4.1 and 6.4.2, we discuss related research efforts from HCI researchers
on understanding the interaction between users and networks. We first explore works
that have focused on studying user psychology and its role in interface designs for
developing home network management and control tools and then investigate how
users respond to nonmonetary penalty mechanisms (e.g., throttling and capping)
imposed by ISPs on their home bandwidth usage. In Section 6.5, we cover lessons
learned about user behavior and psychology from HCI research that involved
incentives and pricing signals from the network to the end users to modify their
usage behavior.
6.4.1
Network Management and QoS Control
Today, bandwidth is becoming a new type of resource that has to be shared and man-
aged by multiple agents, often operating in a distributed framework. This effect can
be observed in the case of shared data plans offered by wireless network operators in
which a data cap is shared across different members and devices. Similarly, in the case
of wired networks, multiple household members and Internet-enabled devices need
to share the same broadband access link. This sharing burdens users with the task of
‚Äúdigital housekeeping‚Äù in which they have to set up, maintain, and troubleshoot their
connectivity as well as understand, monitor, and share limited bandwidth speed or a
data cap. HCI and networking researchers have been grappling with this issue [9, 10]
and have created a few useful tools that can help household users understand, diag-
nose, and manage their home bandwidth usage. One such domestic tool for bandwidth
management is the Home Watcher.
The Home Watcher project [11] provides an appliance that shows who is using the
bandwidth as well as how much each user is using. It also allows users to limit each

USER PSYCHOLOGY IN HOME NETWORKS
137
other‚Äôs bandwidth (and therefore, their Internet-related activities) from a publically
situated open access display. This allowed the researchers to study the social conse-
quences of revealing real-time resource usage and contention in the household.
The Home Watcher field study with 24 occupants in six households revealed
several interesting insights. Making bandwidth usage activities visible reinforced
existing beliefs about other household occupants‚Äô computing activities and increased
people‚Äôs awareness of their routines and activities, for example, alerting people
about who else is online at given times of the day. Thus, Home Watcher raised
some questions of user privacy: information about household members‚Äô bandwidth
consumption patterns can affect daily routines and relationships. As Home Watcher
also allows members to control each other‚Äôs bandwidth, it revealed the politics of
visibility and control. Participants desired more control to limit usage based on the
time of day and importance of each user‚Äôs activities on shared machines. They also
wanted mechanisms to let others know when and why they were being throttled.
However, there are concerns that existing power hierarchies in the home (e.g.,
between parents and children) may be threatened by the option to control others‚Äô
Internet usage. These consequences and desires for finer granular control and com-
munication between users are thus relevant to developing usage control applications
in wired and wireless bandwidth and data cap sharing environments.
Other HCI researchers have focused on creating interactive visual tools for
home network access as well as bandwidth controls. Eden [12] is an ‚Äúinteractive,
direct manipulation home network management system‚Äù that aims to make it
easier for household users to visualize the physical location of different devices in
their home and perform membership management, access authentication, network
monitoring, and QoS policy setting for bandwidth prioritization. It uses a customized
Linux-based wireless router/access point and provides users with personalized
visual representations of network devices and settings that can be managed with
simple drag-and-drop moves. The Eden system also provides users with an interface
element called a badge, which associates particular network control and prioritiza-
tion properties with individual or groups of devices (e.g., a sites restriction badge,
application restriction badge, faster badge, and slower badge). A trial of Eden with
20 participants showed that most users were able to understand the mapping of
spatial home boundaries to the logical boundary of their home network and were able
to use the badges effectively for parental control and other bandwidth prioritization
activities.
While the previous systems worked within the limits of the underlying physical
infrastructure by treating it as a preordained fixed set of facilities, the Homework
project [13] took a new approach to provide users with access to parts of the home
network infrastructure that have traditionally remained closed or hidden. One of the
motivating reasons for this was that traditional Internet protocols and architecture
were designed for configuration by experienced system administrators. In a home
network setting, however, bandwidth access is locally negotiated between household
members and requires immediate resolution of problems, so these users sometimes
need direct control over their home network. Homework adopts a gateway model
to change the home network infrastructure by developing a customized dedicated

138
HUMAN FACTORS IN SMART DATA PRICING
router that can capture traffic information and make it available to applications. It pro-
vides users with information and control over which machines can receive an Internet
Protocol (IP) address to join the home network by implementing a Dynamic Host
Configuration Protocol (DHCP) sever within a customized router. It also implements
a dynamic name service (DNS) proxy into the router to give fine-granular control
over which devices can access which specific sites. The DNS proxy intercepts domain
name resolution requests for sites and drops requests if the requesting device is not
allowed to access that domain, thus enabling parental controls. The Homework sys-
tem was tested with 12 households in the United Kingdom and confirmed many of the
observations in other works, including increases in social discord and privacy con-
cerns. Many users were found to like having access to such control over their network
infrastructure, but they viewed these features as mechanisms to issue threats rather
than substitutes for negotiations within the family about network usage. Nevertheless,
these results show the potential for reshaping the home network by allowing a range
of interactive possibilities to manage and control the infrastructure.
Such systems for home network management and control provide an understand-
ing of the features that users want, how such information can be presented to them
using effective UIs and how user actions can be mapped onto the underlying phys-
ical infrastructure. These studies can inform our design choices for user-friendly
applications for wired and wireless network pricing and user-mediated bandwidth
prioritization and control.
6.4.2
Implications of Throttling
Many US operators have been throttling user bandwidth in an effort to control net-
work congestion [14]. Only 30% of online Americans are reported to receive the
‚Äúadvertised‚Äù speed, even though ISPs charge them higher fees for higher speeds [15].
This issue of throttling, along with the net-neutrality issues involved in creating a
tiered Internet service, has led HCI researchers to develop a visual network probe to
educate and empower consumers about their data speeds. Kermit [16] is a probe that
collects data from users‚Äô routers and calculates bandwidth counts and the online sta-
tus of each machine. Kermit provides users with a visual interface to estimate their
broadband connection speed, identify network bottlenecks, and control and prioritize
their usage by displaying real-time and historical information about bandwidth usage
for all household devices on the home network.
The field trial of Kermit with 10 households provided many design guidelines for
future home broadband tools. It showed that users benefit from visualizations that
allow for a less cluttered and personalizable display as more devices are added to the
home network, as well as from more context about the network upload, download,
bandwidth, and speed they are receiving. Users also need to be able to perceive visual
differences to understand how their actions of limiting or prioritizing devices are
affecting the network. They also like the options of controlling, scheduling, and lim-
iting actions, as well as tools to remind them to reverse such actions. Thus, designers
should incorporate these functionalities into the interface over a system that securely
stores and handles the large amounts of traffic measurement data collected. These

USER PSYCHOLOGY IN HOME NETWORKS
139
tools can not only educate and empower consumers but can also help them become
broadband speed ‚Äúwatchdogs‚Äù to effectively participate in net-neutrality debates.
6.4.3
Response to Capping
Besides throttling and poor performance due to network congestion, users are also
facing bandwidth caps imposed by ISPs. How users use and interact with the Inter-
net in a metered bandwidth environment is of interest to web designers, application
and service developers, and content providers in customizing their user experience.
Many countries such as Africa, India, and Australia have had low bandwidth caps
in digital subscriber line (DSL) for years, while most US operators introduced data
caps after 2010. In Africa, Chetty et al. [17] conducted studies of users who have only
known capped plans for Internet access to find out how data caps change usage pat-
terns and what strategies users use to cope with the limitations. They found that caps
affect how, when, and for how long users access the Internet. For example, in Kenya,
Internet users deliberately plan their online activities before going online at Inter-
net cafes [18]. In South Africa, some users avoid high bandwidth-consuming sites
at the beginning of the month so as to stretch their caps through the monthly billing
cycle. Caps, therefore, effectively force people to put a price on their Internet access,
as in usage-based pricing. Additionally, to help navigate their bandwidth caps, users
require new visual tools that reveal which applications consume their bandwidth the
most and the cost incurred from visiting different sites.
Further studies on the effects of data caps by Chetty et al. [19] revealed that
home users face difficulties with three types of uncertainties about their bandwidth
usage, namely, invisible balances (inability to track usage and leftover bandwidth),
mysterious processes (unidentifiable users and background processes), and multiple
users. A qualitative study of 12 households living with data caps in South Africa
showed that caps limit browsing activities and users preferred limitless consumption
to faster but capped connections. Users generally have inadequate tools and warnings
to prevent them from going overboard or to identify freeloaders on their wireless
networks. Users also liked parental controls to limit children‚Äôs access to gaming
and multimedia-rich content and were even found to avoid downloading software
updates, thus increasing security risks to the network. Moreover, because of the caps
many households were found to create informal data sharing networks; families
without caps or with workplace connections would download videos, movies,
and music to share with their capped friends and relatives through CDs, DVDs,
and so on. Family members would sometimes even visit friends and relatives to
get online once when their Internet connection was capped. Another interesting
behavior was that while users self-censor their usage early in the month, they go
on ‚Äúbinge downloads‚Äù at the end of the billing cycle to use up most of the data cap
because of the ‚Äúuse-it-or-lose-it‚Äù nature of today‚Äôs capped plans, thus potentially
increasing network congestion. These behaviors suggest that many usage and pricing
assumptions relevant in unlimited bandwidth scenarios may not hold in capped
environments, which in turn will affect the design of applications and devices
operating in a usage-based, tiered, and capped plans.

140
HUMAN FACTORS IN SMART DATA PRICING
Researchers have also developed another system, BISMark (Broadband Internet
Service BenchMARK) [20], with similar features that helps users not only under-
stand but also actively control how different devices in a home can share the available
bandwidth cap. BISMark is a router firmware running on network gateways that
gathers usage statistics and reports them to a controller to display usage informa-
tion. BISMark provides users with visibility into which users and applications are
consuming more bandwidth and policies to control how the cap is allocated across
different users, devices, application, time of day, and so on. BISMark implements and
enforces the user-specified policies via a secure OpenFlow control channel to each
gateway device. It also allows users within a single household to trade caps with each
other to increase overall resource utilization efficiency.
6.5
USER PSYCHOLOGY IN BANDWIDTH PRICING
Section 6.4 focused on HCI research studying user behavior under unlimited, capped,
or bandwidth-throttled data plans without explicitly invoking pricing as a tool to mod-
ify user behavior. In this section, we discuss works that have studied user psychology
and behavior when the network provides explicit pricing signals to users.
6.5.1
Effects of Variable Pricing
One of the early works on user reaction to pricing was conducted by the Berke-
ley Internet Demand Experiment (INDEX) [21, 22] in which users were exposed
to different usage-based pricing models, including flat-rate and pay-per-byte pric-
ings. INDEX is a prototype to offer differentiated-quality service on demand, with
prices that reflect resource cost. The INDEX Control Center is an interface running
on a desktop through which customers specify their choices and control access to
the Internet. The interface also shows users a ‚Äúspending meter‚Äù to reveal the cost
incurred till the present time of an active session. This meter can be toggled to show
the cost incurred till that time of the day or the entire month. The spending meter
is updated every minute to keep users aware of their spending behavior in real time.
INDEX also allows customers to instantaneously shift between different service qual-
ities, even during an ongoing session, by clicking on the appropriate service quality.
The INDEX project experiments exposed the participants to various forms of pricing
plans, including volume pricing, volume plus capacity charge, self-selecting tariff,
and so on. The experimental data showed that users are highly price sensitive. More-
over, in asymmetric bandwidth settings in which users can separately choose and pay
for bandwidth in the upstream and downstream directions, it was found that most
users are aware of this asymmetry, and they do reduce their bill. The authors also
compared user behavior when their costs are determined by megabytes of data trans-
ferred versus minutes of connected time and found that the connected time goes up
dramatically under volume pricing compared with connect time charges. The most
important findings from the INDEX project are [22] that (i) the demand is very sensi-
tive to price and to quality; (ii) differences in demand among users are persistent and

USER PSYCHOLOGY IN BANDWIDTH PRICING
141
large; and (iii) the commodity form of the service (e.g., transport of traffic by volume
or time) has a big impact on demand.
6.5.2
Effects of Speed-Tier Pricing
Recent research has focused on creating experimental testbeds for mobile data pric-
ing. SpeedGate [23] from AT&T is one such testbed allowing experimentation with
different dynamic pricing schemes without accessing or modifying the core network
elements (e.g., Policy charging and rules function (PCRF) and Policy and charging
enforcement function (PCEF)). SpeedGate allows mobile users from any carrier with
any type of smart phone to participate in pricing trials (i.e., carrier independence)
and maintains persistent connections to smartphones over a virtual private network
(VPN) even as users roam between different wireless networks (3G, 4G/LTE, WiFi).
Most importantly, it allows dynamic speed-tier assignments: the testbed can redirect
smartphone users to different ports on proxy servers in real time and adjust their max-
imum available bandwidth per user session (i.e., QoS level) dynamically based on the
data pricing strategies used.
A trial of Speedgate to understand user‚Äôs willingness to pay (WTP) for various
speed tiers with a total of 29 users revealed many interesting results. It showed
that users‚Äô WTP depends on the amount of bandwidth-intensive applications they
used, their access to WiFi networks, and the speed of the 3G/4G connections, which
depends on the coverage in the user‚Äôs location. In particular, some users showed less
willingness to pay for higher speed tiers, mainly because there was no real guarantee
that they would indeed receive the maximum speed, and hence, their WTP depended
on their experience because of varying network coverage. The results also suggested
that most participants showed a limited dynamic range of WTP for wireless services
regardless of the speed tiers offered. A second laboratory study with 12 participants
for measuring WTP through rating of applications (stock, Pandora, YouTube)
showed that WTP for higher speed tiers was higher for more bandwidth-intensive
applications.
The researchers also conducted a separate trial [24] at the Purdue University cam-
pus by developing a smartphone application to study users‚Äô responses to incentives
and disincentives and to observe the impact of their psychological characteristics.
Their results showed that pricing schemes with probabilistic payments of higher
incentive amounts have more positive results compared to schemes with determin-
istic payments of lower incentive amounts, even when the total payout is statistically
similar in both schemes. This result is rather interesting given that customers in wired
networks have been known to be risk averse, with a preference for flat-rate fees over
the uncertainties involved with variable pricing. This new observation may, therefore,
indicate that consumers in resource-constrained mobile networks are more risk seek-
ing and want to save more on their monthly bills and, hence, potentially are more
responsive to dynamic pricing plans. Furthermore, their study suggested a positive
relationship between compliance with incentives and a user‚Äôs psychological agree-
ableness and a negative relationship between compliance and a user‚Äôs neuroticism
(i.e., the extent of negative emotions experienced).

142
HUMAN FACTORS IN SMART DATA PRICING
6.5.3
Effects of Dynamic Time-Dependent Pricing
The most basic form of TDP in practice is a two-period plan that charges different
rates during the daytime and night time. For example, BSNL in India offers unlimited
night time (2‚Äì8 am) downloads on monthly data plans of Rs 500 ($10) and above.
Another variation of TDP is one in which users can choose the time of day when
they want higher network performance. For example, in 2010, the European operator
Orange introduced a ‚ÄúDolphin Plan‚Äù for ¬£15 ($23.50 USD) per month that allows
unlimited web access during a ‚Äúhappy hour‚Äù corresponding to users‚Äô morning com-
mute (8‚Äì9 am), lunch break (12 noon to 1 pm), late afternoon break (4‚Äì5 pm), or late
night (10‚Äì11 pm) [25, 26]. This plan lets customers self-sort into different times of
the day, temporally distributing the peak demand.
More dynamic forms of TDP have been offered for voice calls in India and Africa.
In Africa, MTN Uganda‚Äôs dynamic tariffing plans have shown that fiscally conscious
users do respond to dynamic pricing plans that vary the incentives depending on the
network conditions. Their customers can check the price discounts available on their
handsets and decide on their usage accordingly. At 4 am, when the network would
otherwise be little used, usage was found to be as high as 99% if discounts were
offered [27]. These dynamic discounts were even found to modify the temporal usage
patterns and peak demand periods. For example, in addition to the normal peak hour
at 8 am, a new peak hour at 1 am was observed as more people took advantage of
cheaper prices for calls after midnight. Customers in developing countries were thus
very price sensitive and were willing to stay up late in the night to save money, hinting
at similar potential for TDP for mobile data. Another important effect observed with
time-dependent price discounts was that incentives can in fact increase the overall
demand because of a ‚Äúsales-day effect‚Äù psychology. For example, when Vodacom
introduced a similar TDP scheme in Tanzania, overall call volumes increased by
20‚Äì30% in areas where dynamic tariffing was practiced.
Similar levels of effectiveness of TDP for voice calls have been reported by net-
working researchers from TDP field trials conducted in the UC Berkeley student dor-
mitories using a computer-telephony service [28]. The experimental subjects could
use the service to make and receive phone calls from their computers or phones. While
the trial did not involve real money, users‚Äô budget constraints were simulated through
allocating a limited number of tokens per user per week. This experimental setup
was then used to conduct a different pricing experiment each week to understand
how prices can be used to change user behavior (e.g., entice them to talk less, talk at
another time, or use a lower quality connection). The authors found that with their
token scheme as a budget constraint, static pricing policies can be used to influence
users‚Äô behaviors, but a simple congestion pricing scheme fails to encourage users
to talk less. For example, using TDP, they encouraged users to shift 30% of their
calls from the peak to the off-peak hours. Similarly, by using call-duration pricing (a
variant of usage-based pricing) and charging a higher rate as a call lasts longer, the
authors could encourage three times as many calls (18% instead of 6%) to terminate
after a price increase. However, when using a simple congestion pricing scheme that
charges a rate depending on the number of people calling (i.e., a real-time dynamic
congestion pricing), they found that this pricing plan did not get users to terminate

DAY-AHEAD DYNAMIC TDP
143
their calls earlier. They conjecture that users did not adjust their behavior because
they did not know how long the price increases or decreases would last.
These observations hint that to make a congestion pricing scheme effective, the
price changes need to be of relatively longer duration to incentivize users to change
their behavior. The results from these experiments hint at two key lessons: (i) net-
working and HCI researchers do need to jointly identify effective ways to commu-
nicate the pricing signals back to the users and (ii) for dynamic TDP to change user
behavior, users need to be made aware of the prices (and how long they will last) in
advance, through plans such as DDTDP.
Our own experience from field trials of the TUBE system [29], which offered
dynamic day-ahead TDP in the case of mobile data traffic, confirmed similar user
behaviors, as discussed in Section 6.8. Our experiments also found a 30% reduc-
tion in the maximum observed peak-to-average usage ratio and a 130% increase in
usage, particularly in the discounted, off-peak hours. These results are promising in
that they indicate the feasibility of introducing such plans if they are designed care-
fully to facilitate users‚Äô understanding of and reactions to pricing signals from the
network.
6.6
DAY-AHEAD DYNAMIC TDP
As alluded to above, DDTDP has certain features that make it an attractive pricing
option to explore.
1. Price Guarantees. Users‚Äô general preference for flat-rate pricing is primarily
driven by their preference for certainty in their monthly usage bills. Dynamic
real-time pricing is, therefore, not very conducive to users as it is harder for
them to react to changing prices at such a fine timescale [28]. Instead, DDTDP
provides prices to users a day in advance, giving them an opportunity to plan
their usage ahead of time.3
2. Advance Notice. In Reference 28, the authors noted that unless users are
informed of the prices in advance, they usually do not change their usage
behavior as they do not know for how long the offered prices are going to last.
In DDTDP, the offered prices are for specified durations (e.g., hourly rates),
and hence, users can determine how long they need to wait for discounted rates
and decide accordingly whether to stop using data for noncritical applications.
3. Granular Price Offerings. In contrast to simple two-period pricing, DDTDP
provides operators with the opportunity to vary prices at a finer time gran-
ularity (e.g.,1-h or 30-mi time periods). Many mobile applications that may
not wait for half a day can wait for an hour or less (sometimes even without
3As the prices are offered in advance, an important component of offering DDTDP is determining the
optimal prices to offer while accounting for the estimated time elasticity of demands for various price
points from historical data. An analytical model and algorithms to enable such computation of optimized
prices has been described in our previous work [29].

144
HUMAN FACTORS IN SMART DATA PRICING
the user being involved, as in the case of downloads, backup, caching, M2M
applications, etc.). The operator can take advantage of the inherent time elas-
ticity of demand of such applications to set the time-varying incentives.
4. Adaptive Pricing.The operator can adapt the prices offered for each day based
on the observed user behavior given the incentives offered previously [29]. This
daily adaptation of prices introduces a ‚Äúdynamic‚Äù aspect into the pricing plan.
It also helps the operator spread out the demand temporally without shifting
the peak demand from one time of the day to another, as has been observed to
happen under simpler two-period pricing (e.g., all subscribers waiting to make
longer calls at 1 am [27]).
5. User Feedback Mechanism. DDTDP will create a control-feedback loop
between the network operator and its clients, with the users having GUIs that
will help them better understand and react to the prices on offer. It will thus
enable end users to easily and conveniently respond to these time-varying
pricing signals. DDTDP divides the congestion management functionalities
between the network core and the end user devices, thus making these smart
devices a part of the network management solution suite.
Despite these advantages of DDTDP, introducing any new pricing scheme must
account for its possible impact on the entire Internet ecosystem. In Section 6.7, we,
therefore, discuss how various stakeholders of this ecosystem that we interacted with
through SDP forums and workshops (www.smartdatapricing.org)‚Äînamely ISPs,
vendors, content providers, software developers, and regulators‚Äîview the potential
of DDTDP.
6.7
PERSPECTIVES OF INTERNET ECOSYSTEM STAKEHOLDERS
Changes in pricing policy can affect multiple stakeholders in the Internet ecosystem,
including network operators, consumers, content providers, software developers, and
regulators. In this section, we provide the perspectives of these different stakeholders
to understand the drivers of current changes in broadband pricing and the benefits
that new plans such as DDTDP can bring.
6.7.1
Operator Perspectives
By 2016, ISPs are expected to carry 18.1 PB per month in managed IP traffic.4
While this growth promises more revenue for ISPs, many ISPs are concerned about
handling such traffic volumes on their network, as seen by Comcast‚Äôs initiative to
cap their wired network users at 300 GB per month [14]. Rural local exchange car-
riers (RLECs) suffer from an especially acute problem: although the cost of pro-
viding middle-mile bandwidth to their users has declined over the years, because
4Cisco‚Äôs definition of ‚Äúmanaged IP‚Äù includes traffic from both corporate IP wide area networks and IP
transport of television and video-on-demand.

PERSPECTIVES OF INTERNET ECOSYSTEM STAKEHOLDERS
145
of an increase in the DSL demand needed to fill the middle mile, the bandwidth
requirements of home users have increased quite sharply [30]. Indeed, rural cus-
tomers‚Äô average home broadband speed is still less than the Federal Communications
Commission‚Äôs (FCC) 4 Mbps target, but the digital expansion required to meet this
target is hampered by the high cost of middle-mile upgrades in rural areas [30]. New
access pricing mechanisms that bring down middle-mile investment costs by incen-
tivizing users to reduce RLEC peak demand and overprovisioning needs can thus be
helpful in bridging the digital divide.
ISPs‚Äô current penalty mechanisms (e.g., overage fees, throttling, and termination)
to reduce peak traffic, however, can be harmful to the entire Internet ecosystem and
ineffective in bringing down peaks. For example, usage-based pricing does not incen-
tivize users to avoid congested, peak-usage times, and thus does not reduce peak usage
relative to average usage over the day [31]. As Clark pointed out, ‚Äúthe fundamental
problem with simple usage fees is that they impose usage costs on users regardless of
whether the network is congested or not.‚Äù [32] Even two-period, for example, day-
time and night time, pricing cannot always reduce peak usage, as many applications
can be deferred for a few hours but are unlikely to wait for half a day to get discounted
rates.
Dynamic day-ahead TDP does not suffer from many of the problems posed by
these other pricing plans. Many US ISPs at the National Exchange Carrier Associ-
ation‚Äôs Expos in 2011 and 2012 thought that DDTDP could benefit both ISPs and
customers, informing us that ‚ÄúClearly, customers do not want any form of usage
measurement or control under traditional definitions. I‚Äôd be very interested in seeing
a pitch for time-dependent pricing‚Äù (Delhi ISP, email communication, September
2011). An Indian telecom executive was more specific, telling us that TDP can ben-
efit ISPs by reducing peak traffic as well as customers by letting them save money
during lower price times. Given these advantages to ISPs, it is therefore necessary
to examine customer viewpoints on TDP, as user responses to the prices offered will
ultimately determine TDP‚Äôs efficacy.
6.7.2
Consumer Viewpoints
Consumers today face increasing costs of Internet subscriptions as well as harsh
penalties from network operators in overage fees. For example, Verizon‚Äôs move in
2012 to only offer shared data plans for all new consumers increased most customers‚Äô
monthly bills [33]. To avoid overage fees from going over their monthly data caps,
consumers are increasingly relying on usage-tracking and data compression apps
(e.g., Onavo, 3G Watchdog Pro, and DataWiz). These trends are also observed out-
side the United States; in South Africa, for instance, consumers use ISP-provided
usage-tracking tools [19] to stay within their data caps and often plan their Internet
activities in advance to avoid wasting time online.
Empowering users to monitor and control their spending on Internet usage is
emerging as a new area of research that needs to consider economic incentives and
HCI aspects in a holistic manner [34]. For instance, under dynamic TDP users‚Äô
interactions with the prices offered can be made more convenient by automatically

146
HUMAN FACTORS IN SMART DATA PRICING
scheduling applications such as large downloads and cloud synchronization to
discounted periods even without user intervention.
To better understand user acceptability of TDP plans, we conducted pretrial sur-
veys in India and the United States. The US surveys were conducted online and by the
authors in person in Philadelphia and on college campuses, while the survey in India
was conducted by a professional marketing firm in five major cities (Kolkata, Mum-
bai, Delhi, Madras, and Bangalore), as seen in Figure 6.2. We received 155 responses
to the US survey and 546 responses to the survey in India.
In both surveys, we asked respondents for the maximum length of time for which
they would delay different types of apps in exchange for a given discount on their
data plan. More than 50% told us that they would wait 10 minutes to stream YouTube
videos and that they would wait 3‚Äì5 hours for file downloads. In India, we also found
that individuals without mobile phones hesitated to use mobile data because of the
high cost of data plans but did realize the usefulness of having a mobile data plan.
Residents in rural areas of the United States express similar sentiments [35], suggest-
ing that lower cost time-dependent broadband access fees would boost user Internet
adoption and help to bridge the United States‚Äô digital divide.
6.7.3
Content Provider Considerations
Content providers are becoming increasingly sensitive to users‚Äô desire to avoid exces-
sive data usage and avoid paying overage fees for their Internet usage. These concerns
have generally manifested as extra options for users to downgrade their quality of
experience in exchange for using less data. For instance, Netflix offers such an option
for users to stream lower quality videos [36], as well as another option for iPhone
Figure 6.2
Consumer survey in India.

PERSPECTIVES OF INTERNET ECOSYSTEM STAKEHOLDERS
147
users to use only WiFi. ISPs‚Äô measures to penalize demand are thus driving changes
to not just their users‚Äô behavior but also the business plans of content providers.
6.7.4
Application Developer Concerns
Incentive-based pricing plans, such as TDP, require a feedback-control loop between
the network backend and client-side devices, with the latter requiring new mobile
applications that will support such functionalities. In developing these apps, however,
developers must contend with the different mobile platforms prevalent today (i.e.,
iOS, Android, and Windows Mobile). The openness of these different platforms can
make developing such applications difficult; for example, until the release of iOS 7
in 2013, such pricing apps could not run in the background and could not access the
usage of specific apps [37, 38]. The Android and Windows platforms, however, have
generally been more open.
New TDP pricing plans will create an opportunity for developers of nonpricing
apps to optimize their apps according to changing pricing conditions. For instance,
many apps can preload content during lower price times, for example, magazine apps
preloading articles and pictures. Such preloading can not only save users money but
can also reduce the delay in displaying content when users open an app. Moreover,
the temporal flattening of demand eases congestion, allowing users to achieve higher
throughput and better performance. Video applications, which tend to have the high-
est usage volumes, can especially benefit from such usage shifting. Implementing
such measures, however, would require open APIs that allow apps to run in the back-
ground and access network prices in real time. Apps and systems that accommodate
such features can thus help developers provide a better quality of experience and
savings for their users.
6.7.5
Policy Evolution
Changes in pricing policies often lead to politically charged debates on network neu-
trality in the United States, but academics have cautioned that this ongoing debate
overlooks the need for service providers to have flexibility in exploring different pric-
ing regimes [39]: ‚ÄúRestricting network providers‚Äô ability to experiment with different
protocols may also reduce innovation by foreclosing applications and content that
depend on a different network architecture and by dampening the price signals needed
to stimulate investment in new applications and content.‚Äù
However, more recently, US regulators have accepted ‚Äúthe importance of business
innovation to promote network investment and efficient use of networks, including
measures to match price to cost‚Äù [40], particularly for ISPs operating in the wire-
less sector. In ‚ÄúNew Rules for an Open Internet,‚Äù the former Federal Communica-
tions Commission Chairman J. Genachowski explicitly specified that [41]: ‚ÄúThe rules
also recognize that broadband providers need meaningful flexibility to manage their
networks to deal with congestion... And we recognize the importance and value of
business-model experimentation.‚Äù

148
HUMAN FACTORS IN SMART DATA PRICING
6.8
LESSONS FROM DAY-AHEAD DYNAMIC TDP FIELD TRIALS
6.8.1
Trial Objectives
The TUBE (Time-dependent Usage-based Broadband price Engineering) system
is an experimental testbed used to study user responses to day-ahead dynamic
time-dependent usage-based pricing of bandwidth in mobile networks. For this trial,
a prototype was developed that can compute optimized prices in the ISP backend (as
described in References 29 and 42). These prices were displayed to the users through
client-side UIs, which also let them monitor, control, and modify their behavior
in response to the offered prices. The key steps in carrying out the trial were the
following.
‚Ä¢ Create a ‚Äúvirtual‚Äù ISP (i.e., bandwidth reseller) for the purpose of the trial by
operating as a middleman between a real mobile operator and its participating
clients, who are offered time-varying prices.
‚Ä¢ Develop a communication infrastructure with server-side (ISP) implementation
for computing and sending price information to a client-side app running on
client (end user) mobile devices.
‚Ä¢ Conduct pretrial surveys and focus group studies to incorporate feedback in the
design of client-side GUIs.
‚Ä¢ Validate results based on qualitative posttrial debriefings and quantitative results
collected during the trial.
6.8.2
Trial Structure
6.8.2.1
Pretrial Focus Groups Focus group studies conducted in the design phase
helped us to incorporate feedback from users to create intuitive and simple to use UIs.
During these five-person sessions conducted at the Princeton University campus, we
identified several functionality goals for the TDP app and solicited opinions on our
app designs and the form factor of the devices used. We also received feedback on
the designs from leading industry experts at AT&T, MTA, NECA, Bell Labs, and
Reliance Communications. This iterative process of seeking user feedback and mod-
ifying the interfaces accordingly continued for a 4-month period to create a prototype
of the mobile application for the client-side devices. Many of the functionalities that
we incorporated had been found to be desirable by users in the context of energy mar-
kets and home network management solutions (e.g., usage monitoring and history,
color coding of information, parental control) as described in Section 6.4.
These pretrial studies suggested that participants liked the idea of day-ahead
dynamic time-varying prices because it empowers them to choose not only how
much but also when to use their device so as to save on their monthly bills. The focus
group studies provided insights about the following features of DDTDP.
‚Ä¢ Time Granularity. Participants typically preferred TDP prices that varied at an
hourly granularity rather than on the order of minutes (e.g., real time). Real-time

LESSONS FROM DAY-AHEAD DYNAMIC TDP FIELD TRIALS
149
price changes are harder for users to track; moreover, uncertainties in the dura-
tion of the offered prices make it harder for users to adapt to price changes
[28].
‚Ä¢ Time Horizon. The idea of ‚Äúday-ahead‚Äù prices, as practiced in some electricity
markets, was found to be appealing as it allows for advance planning of usage.
The feasibility of this behavior is supported by reports that price-conscious
Internet cafe users in Kenya plan their online activities before going online [18].
‚Ä¢ Information Visualization. Our participants found it useful to view superim-
posed usage and price history so as to be able to determine when they used how
much of their data cap.
‚Ä¢ Color Coding. The participants found viewing the TDP price discounts in a
color-coded form (e.g., red (<10%), orange (10‚Äì19%), yellow (20‚Äì29%), and
green (>30%)) to be an intuitive way to communicate the prices. This idea for
color-coding TDP prices or discounts was inspired by the traffic light signaling
system and previous works in electricity sockets [4, 6]. The price discounts were
also made available as numerical values to accommodate users who wished to
see more details and as a secondary signal for color-blind users.
‚Ä¢ Application Control. The idea to have a parental control feature to block certain
apps at certain times of the day when prices are high was well received. More-
over, participants also wanted information on the cost of each application‚Äôs data
usage, or alternatively, a display showing the top bandwidth- (budget) consum-
ing applications on their device.
This feedback from pretrial focus group studies was incorporated in the design of the
mobile TDP application.
6.8.2.2
Participants, Billing, and Timeline To conduct this day-ahead TDP trial,
we recruited 10 trial primary participants (the ‚Äúprimary participant‚Äù paid the monthly
bills) in the Princeton, New Jersey, area through word of mouth and email lists. The
primary trial participants were each given a jailbroken iPad2 with a 2-GB data plan
from AT&T and our client-side app installed.5 We set the devices‚Äô WiFi connectivity
to ‚Äúoff‚Äù by default, because the goal of the trial was to determine if the 3G traffic
can be made to wait for discounted periods when economic incentives are offered.
However, to avoid skewing participants‚Äô usage patterns, we also asked participants
to use the devices as they normally would, with the result that many of the primary
participants shared the device with their family members.
The iPads were the only tablets owned by the participating families, and they were
actively engaged with the iPads throughout the trial. Our trial setup did not impede
the devices‚Äô mobility in any way (Section 6.8.2.3 discusses the setup implemented
with AT&T to realize this). The demographic information of the primary participants
and any secondary users who shared the device is given in Table 6.2.
During the trial period, we paid all participants‚Äô monthly AT&T bills for the iPad‚Äôs
2-GB data plan and overage fees. Participants paid us according to a DDTDP plan
5The devices were returned after the end of the trial, with an option of purchasing it at a discounted rate.

150
HUMAN FACTORS IN SMART DATA PRICING
TABLE 6.2
Demographics of the DDTDP Trial Participants
Age & Gender
Occupation
Secondary Participants
P1
Female, 40
Personal assistant
None
P2
Male, 33
Graduate student
None
P3
Female, 34
Office staff
Female, 3
P4
Female, 50
Accounts manager
Female, 26 (waitress);
male, 23 (waiter)
male, 18 (student); female, 5
P5
Female, 21
Student
None
P6
Female, 48
Admin. assistant
Female, 22 (restaurant cook)
P7
Female, 35
Office manager
Male, 41 (software engineer)
P8
Male, 31
Graduate student
None
P9
Female, 30
HR manager
Male, 32 (theater technician)
P10
Female, 43
Office support
Male, 43 (systems technician);
male, 14; female, 8
Trial participants 
TDP prices 
Wireless data
service provider
 
User spending 
Revenue
TDP
server 
Figure 6.3
Money flow diagram for the DDTDP trial.
with time-varying price discounts on a baseline usage-based fee of $10/GB. Thus,
we effectively became a resale ISP of AT&T‚Äôs connectivity for these participants, as
illustrated in Figure 6.3. To avoid creating multiple sources of incentives, we did not
give any additional monetary incentive for participating in the trial.
We performed extensive in-laboratory testing of the TDP system between April
and July 2011. The trial was conducted from July 2011 to April 2012, during which
we visited participants three to four times. In the first phase of the trial, from July to
September 2011, we handed out the iPads without the TDP app6 installed to let our
participants familiarize themselves with the device and to monitor their pre-DDTDP
usage. In the second phase of the trial, from October to November 2011, we installed
the DDTDP client app on participants‚Äô iPads and provided basic operational instruc-
tions. We also began offering DDTDP price discounts. From December 2011 to Jan-
uary 2012, we tested participants‚Äô changes in usage in response to different types of
price displays. From February to March 2012, we continued to offer DDTDP, visiting
the participants again in April for a posttrial debriefing to obtain feedback on their
experience during the trial.
6We use the terms ‚ÄúTDP app‚Äù and ‚ÄúDDTDP app‚Äù interchangeably as DDTDP was the only form of TDP
tested in our trial.

LESSONS FROM DAY-AHEAD DYNAMIC TDP FIELD TRIALS
151
Three researchers coded the audio data and transcriptions of all participant
interviews. The excerpts presented here are representative of the participants‚Äô
interview responses and represent mutually agreed upon themes that emerged from
their answers. Where applicable, we support our qualitative findings with observed
data on participants‚Äô quantitative usage patterns and pricing history.
6.8.2.3
Implementation and Setup Becoming a resale ISP requires architecting
and prototyping a system with two main interfaces: one with the real network opera-
tor (here, AT&T) and one with trial participants‚Äô devices. The first interface consisted
of an APN (Access Point Name) between AT&T‚Äôs mobile network core and our lab-
oratory server facilities, which redirected trial participants‚Äô uplink and downlink data
traffic to our DNS-enabled and network address translation (NAT)-enabled servers
before rerouting it back to the Internet. Thus, participants‚Äô data traffic, but not voice
traffic, flowed through our laboratory severs, as illustrated in Figure 6.4.
This APN setup allowed our server to monitor participants‚Äô aggregate usage at dif-
ferent times and adjust the future offered prices accordingly. We assigned a unique
IP address to each device and created a Netfilter rule to measure its usage and store it
in a MySQL database. In each hour, a price point for the next twenty-fourth hour was
calculated using a Matlab-based prediction algorithm that estimated future demand as
a function of the prices offered. All prices were announced 24 hours in advance (i.e.,
DDTDP). To interface with the apps on users‚Äô devices, the client-side apps were con-
figured to pull the new prices each hour, so that at any time, a participant could launch
our TDP app to see the prices for the next 24 hours and plan their usage accordingly.
The server supports JavaScript Object Notation (JSON)/Hypertext Transfer Protocol
(HTTP) and can exchange information with any device with browsing capability. All
server modules were implemented on a Linux platform with an Intel Xeon 2.0 GHz
CPU and 8 GB of RAM.
The client-side (iPad) system module is the mobile application (DDTDP app) with
which trial participants interact. In order to bypass iOS platform restrictions that con-
strained many of the possible TDP functionalities, we jailbroke the iPads to gain root
End
user
3G
AT&T
Firewall
VPN
TDP
server
Internet
Figure 6.4
Schematic of the data flow in the DDTDP trial setup.

152
HUMAN FACTORS IN SMART DATA PRICING
access to the operating system. The jailbreaking allowed us to implement such fea-
tures as monitoring per-application usage volumes, blocking apps on users‚Äô request,
and displaying a price indicator next to the battery indicator on the iPad home screen.
We tracked each application‚Äôs usage by hooking internal functions and running a dae-
mon process to send requests and display the DDTDP prices, as well as to block apps
if needed. The app increased the iPads‚Äô battery consumption by no more than 4%
compared to typical usage without the DDTDP app.
6.8.3
Application User Interface
We next discuss the UI features of the DDTDP app, grouped by the following func-
tionality goals.
1. Data Monitoring. Finding intuitive ways to communicate price and usage infor-
mation to users for educating them about their data consumption behavior.
2. Consumer
Empowerment.
Identifying
information
that
will
empower
consumers to have better control over their usage.
3. Automation. Understanding if and when consumers would like to automate
their usage and scheduling decisions using an ‚Äúautopilot‚Äù mode of operation.
We first focus on the monitoring features, whose purpose is to display price and
usage information.
1. Indicator Bar. Participants could conveniently check the current price by glanc-
ing at an indicator bar next to the battery icon on the top icon tray of the iPad‚Äôs
home screen, as shown in Figure 6.5.7 The indicator bar is color coded, with red
denoting discounts <10% and green discounts >30%, and shows the percentage
discount from the baseline price ($10/GB in this trial).
2. Price Information. The home screen of the DDTDP app displays price and
usage information in a split screen, as shown in Figure 6.6a. The user‚Äôs cur-
rent DDTDP bill for the month is displayed on top, followed by a scrollable
list of color-coded percentage price discounts and usage information. The list
includes data on the past and future 24 hours, highlighting the current hour‚Äôs
information; clicking on the entry for an hour toggles the price display between
$/GB prices and percentage discounts from the $10/GB baseline.
Figure 6.5
Color-coded price discount indicator bar on the iPad home screen for easy
reference.
7Incorporating this feature in the iPad app required jailbreaking the device. Implementing it on more open
platforms, such as Android, does not require jailbreaking.

LESSONS FROM DAY-AHEAD DYNAMIC TDP FIELD TRIALS
153
(a)
(b)
(c)
Figure 6.6
Screen views of information displayed by the app. The main screen (a) is split to
show a scrollable history list on top and either the color-coded future prices and history or (c)
the top five bandwidth-consuming apps below. The landscape view (b) shows the prices and
usage superimposed on the same graph.
The bottom of the main screen displays the future prices as an easily under-
standable color-coded bar graph, helping users compare the discounts in dif-
ferent hours. Using the navigation buttons at the bottom of the screen, users
can instead view the past price information, overlaid with their usage history
by day, week, or month; and a list of the apps that consume the most data.
3. Usage History. As described earlier, users can monitor their usage from the list
and graphs on the DDTDP app‚Äôs main screen. Interested users can also turn the
iPad horizontally to activate a larger landscape view of their usage, as seen in
Figure 6.6b. Users can swipe left through their superimposed price and usage
history, allowing them to quickly determine how much data they consumed at
different price levels and at different times. This data can be viewed on a daily,
weekly, or monthly granularity.
4. Top-Five Apps. In the pretrial focus groups, most people did not know which
apps consumed the most data. We thus provided an option on the bottom half
of the app‚Äôs main screen, shown in Figure 6.6c, that displays the data usage
volume of the five apps that use the most data.
5. High Usage Notifications. We tested users‚Äô responsiveness to pop-up notifica-
tions of high prices and accompanying usage-deferral recommendations (e.g.,
notices of low price future times).
We next discuss features designed to empower users in scheduling their usage
according to the DDTDP prices.
1. Parental Control. As many of the primary participants shared their devices with
younger secondary users, we provided a blocking feature to help the primary
participant control others‚Äô usage. The user can select an app from a list of all

154
HUMAN FACTORS IN SMART DATA PRICING
(a)
(b)
(c)
Figure 6.7
Screen views of different usage control features in the app. Users can (a) manually
schedule apps for different times, (b) allocate their budget to different weeks, and (c) adjust
delay tolerances for different apps for autopilot scheduling.
installed apps and then select times (on a half-hour granularity) in which that
app should be blocked from using data, as seen in Figure 6.7a. For instance, par-
ticipants could prevent their children from streaming media-rich content with
high data volumes at high price times.
2. Budget Adjustment. Users could set a monthly budget for each billing cycle.
As seen in Figure 6.7b, they could further control their spending by adjust-
ing weekly budget sliders to divide their monthly budget among the weeks of
their monthly billing cycle. By default, the budget was divided equally among
the weeks of the billing cycle, with progressive adjustment of the remaining
monthly budget across the remaining weeks as the month progresses. Users
could also add money to their monthly budget.
3. App-Delay Sensitivity Settings. Users could set different delay sensitivities for
each installed app by adjusting sliders between ‚Äúhigh‚Äù and ‚Äúlow‚Äù tolerance, as
shown in Figure 6.7c. When combined with automated application scheduling,
this feature allowed the scheduling to account for individual delay preferences
while scheduling enough data in low price periods to keep the user within the
specified weekly budget.
To fully exploit the potential of user-specified delay sensitivities and the available
budget, we also provided an optional autopilot mode of operation. In this mode, the
TDP app computed a usage schedule for different apps to keep users within their
specified budgets, based on the given prices for the next day and their predicted usage
of different apps. The autopilot mode attempted as much as possible to defer only
apps marked as delay insensitive. The autopilot mode provided warnings and blocked
apps until their scheduled period and displayed the schedule to users on a schedule
screen.

LESSONS FROM DAY-AHEAD DYNAMIC TDP FIELD TRIALS
155
6.8.4
Trial Results
We now discuss users‚Äô reactions to the DDTDP prices offered in our trial setup.
We evaluated the trial results in two ways: quantitatively, by measuring the change
in usage in response to prices offered, and qualitatively, by conducting posttrial
interviews with the trial participants. In these interviews, we sought to understand
participants‚Äô general attitudes toward pricing before questioning them about their
experience with the trial app and how the trial affected their opinions of TDP‚Äôs
potential impact on the Internet ecosystem.
6.8.4.1
Opinion on Smart Devices About 70% of our participants had used some
form of smart devices before (e.g., Android and iPhones) and were positive about the
convenience and usefulness of these devices. One participant (P7) described how the
iPad is very useful for leisure-time activities: ‚Äúin the morning when I exercise I just
have Netflix going,‚Äù while another (P3) told us the educational purpose that it serves
for her toddler: ‚ÄúShe loves apps, and now she chooses her own YouTube videos, like
nursery rhymes and stuff.‚Äù But in spite of these benefits, not everyone views such
smart devices as a necessary gadget: ‚ÄúDo I like having them, are they convenient?
Absolutely, but it is definitely a luxury item.‚Äù (P6).
6.8.4.2
Understanding of Data Plans and Usage Before participating in our
DDTDP trial, most participants were relatively unaware of their data usage and
data plans. About 80% reported that they did not know how much data they used
or which apps consumed the most data. A few, however, had some idea: ‚ÄúI would
think any kind of video and music sites‚Äù (P6) and ‚ÄúI assume that anything that‚Äôs
running constantly or streaming, you know, like a movie is going to use more than
just browsing the Internet I would think‚Äù (P9). Another participant knew that her
tablet consumed more data than her phone: ‚ÄúI also know I‚Äôve used the iPad a lot
more liberally for things like that [TV shows] than I would on my iPhone.‚Äù
Despite their relative lack of knowledge about mobile data usage, most of our
participants were concerned about recent data plan changes. When asked whether
current data plans are reasonable, participants expressed concern over ISPs‚Äô shift from
unlimited flat rate to tiered plans with $10/GB overages. One of them explained: ‚ÄúTo
me, I think it‚Äôs a fair price, but I know when my children uses it, if they use Netflix or
something, then it gets to be too expensive.‚Äù(P10). These pricing changes prompted
some participants to pay more attention to their data usage: ‚ÄúI didn‚Äôt really have to
pay attention to that until this iPad came up because the data plan I have for the
family phones is unlimited data for one price.‚Äù
6.8.4.3
Effectiveness of DDTDP DDTDP‚Äôs goal is to use economic incentives to
even out network usage over the day by exploiting the different degrees of time sen-
sitivity of different applications. Such shifting can greatly benefit ISPs, as traffic data
from our partner ISPs shows that the network traffic can vary by a factor of 10 over the
day and by a factor of 2 within a few minutes. However, its success depends on users‚Äô
willingness to pay attention and respond to the prices offered. Our trial results indi-
cate that such economic incentives when offered through intuitive GUIs can indeed

156
HUMAN FACTORS IN SMART DATA PRICING
help in modifying usage behavior and shifting traffic to off-peak hours. Moreover, the
incentives offered can further improve spectrum utilization in these off-peak hours by
generating additional new demand.
All of our participants thought DDTDP would be viable ‚Äúas long as the interface
is simple to use‚Äù (P2). Some of our participants, however, were concerned about
planning for future prices: participant P3, a mother of a toddler, thought that ‚Äú[I]t‚Äôs
definitely useful, but for families it really needs to be predictable.‚Äù Day-ahead pricing,
in which prices for each hour are announced 1 day in advance, can provide some
predictability, which was enough for some participants. Price-sensitive users ‚Äúmade
a conscious effort to look for the discounts‚Äù (P10), adapting their usage in order to
save money: ‚ÄúI think it is a nice option to have where I can get a discount per month
depending on when I use it, and I can schedule my day that way‚Äù (P10). Moreover,
they did not feel that paying attention to the prices was overly burdensome: ‚ÄúI go to
my bank account everyday, so I would think that this would just become a natural
thing‚Äù (P6). In fact, the DDTDP app helped users avoid unnecessary usage at high
price periods: ‚ÄúYes, and [I] was less likely to goof off and waste more time and data‚Äù
(P5).
By measuring usage with DDTDP, we found that participants‚Äô efforts to pay atten-
tion to the prices do flatten out the traffic level over the day. To measure the reduction
in peak traffic, we calculated the peak-to-average ratio (PAR), that is, the ratio of
usage in the peak period to average per-period usage, for each day. We then compared
the PARs from a control period of pre-DDTDP, that is, no variation in prices over
the day, to those observed with DDTDP. We find that DDTDP reduces the PAR from
pre-DDTDP usage, with a 30% reduction in the maximum observed PAR: Figure 6.8a
shows the distribution of peak-to-average ratios on pre-DDTDP and DDTDP days of
the trial.
In addition to reducing the PAR, we observed that participants‚Äô awareness of high
discounts induced a ‚Äúsales-day‚Äù effect among several participants; that is, they started
using more than they otherwise would have. Figure 6.8b shows the average daily traf-
fic for pre-DDTDP and DDTDP traffic; we see that traffic with DDTDP is much larger
than pre-DDTDP, with a 130% overall increase. Combined with Figure 6.8a‚Äôs result
that the PAR decreases, we conclude that participants consumed much more traffic
during off-peak periods when DDTDP discounts were offered. When asked about
this, participant P9 told us ‚Äú[laughs] Kind of! But that also goes toward my person-
ality of if it‚Äôs on sale I must buy it!‚Äù This result benefits ISPs: with DDTDP, they
can offer discounts to shift traffic from peak to off-peak periods, as well as increase
demand in off-peak hours. The result is mutually beneficial, as ISPs benefit from
‚Äúvalley filling‚Äù and users gain by consuming more at the discounted rates in off-peak
times.
We also measured the types of applications shifted to lower price times. Partici-
pants generally delayed streaming and media services: Figure 6.8c shows the distri-
bution of application usage among movies, web traffic, downloads, music, news and
magazines, and other types of apps. We see a very significant increase in movie traffic
with TDP, and smaller increases in the ‚Äúmusic‚Äù and ‚Äúother‚Äù categories. When asked
about the apps they were willing to shift, participants‚Äô responses were consistent with

157
3
4
5
6
7
8
9
10
11
12
13
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Peak-to-average ratio
Probability CDF
 
 
Pre‚àíDDTDP
DDTDP
Pre‚àíDDTDP
DDTDP
(a)
0
10
20
30
40
50
60
70
80
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Average usage (MB)
Probability CDF
 
 
(b)
Movies
Web
Downloads
Music
News/Magazines
Other
Average daily usage (MB)
(c)
0
10
20
30
40
Pre‚àíDDTDP
DDTDP
Figure 6.8
Usage statistics for TIP and TDP. (a) Peak-to-average ratios, (b) average daily usage, and (c) app distribution.

158
HUMAN FACTORS IN SMART DATA PRICING
these measurements, with most participants willing to defer social networking and
streaming. Participants P6 gave the examples of ‚ÄúSocial networking, emailing, or
Skyping, I would definitely wait for that,‚Äù while participant P9 said that ‚ÄúIf I‚Äôm surfing
the web, I‚Äôm doing it now, I am not waiting, but for my movie usage it‚Äôs kind of specific,
so yeah.‚Äù Similarly, participant P1 was willing to shift nonurgent activities: ‚ÄúIf I‚Äôm
trying to look up directions [GPS], it probably couldn‚Äôt wait. But if I were trying to
research on buying something and the discounts weren‚Äôt good, I could wait a couple
of hours to do it later.‚Äù
We found that TDP helps address consumers‚Äô concerns about the rising cost of
mobile data plans; although many users are not fully aware of their monthly usage,
they do want to save on their data plans. Given the right economic incentives, users
are willing to modify their usage behavior in order to save money, which can also
lower network congestion for ISPs. Our DDTDP trial yielded ‚Äúflatter‚Äù traffic usage
over the day, with lower peaks and higher off-peak demand.
6.8.4.4
Effectiveness of the User Interface We next examine (i) the effectiveness
of different features of our DDTDP app‚Äôs UI, (ii) a comparison of the effectiveness of
different ways of displaying prices to users (e.g., color coding vs numerical values),
and (iii) the effect of showing their usage history. Although the app‚Äôs main function
was to display prices, our participants viewed the app as a more general informational
tool: ‚ÄúTo me, this application educates you‚Äù (P4). Participants unanimously agreed
on the usefulness of three key features: (i) a price indicator bar on the iPad‚Äôs home
screen, (ii) color coding the price discounts, and (iii) displaying usage history over
time.
We first consider participants‚Äô responses to the ‚Äúpassive‚Äù price indicator displays
(i.e., when no explicit warning or notification message is sent to the users). For this
part of the trial, we used a color-coding scheme with orange for a price discount of
less than 29% and green for discounts of 30% or more. To quantify the actual effects
of the price indicator, we analyzed the usage in periods in which we intentionally
varied the discounts by 1% to switch the color from orange to green. We defined
two experimental stages and three period types: in the first experimental stage, all
period types had a 10% discount and orange price indicator. In the second stage, type
1 periods switched to a higher (28%) discount with orange indicator, type 2 periods
to a slightly higher (30%) discount with green indicator, and type 3 periods to a lower
9% discount with orange indicator. We then compared type 2 and type 3 periods to
type 1 periods to see if users paid attention to the range of numerical discount values
or just the color coding. Table 6.3 summarizes the three period types.
TABLE 6.3
Period Types in the Price Display Experiment
Period Type
Second Stage Color
Second Stage Discount, %
1
Orange
28
2
Green
30
3
Orange
9

LESSONS FROM DAY-AHEAD DYNAMIC TDP FIELD TRIALS
159
Figure 6.9a plots each participant‚Äôs average change in usage in Type 2 versus Type
1 periods. The price discounts in both periods increased by comparable amounts in the
second experiment stage (28% and 30% respectively), but the indicator color changed
from orange to green only for Type 2 periods. We found that participants increased
their usage more when the color changed (Type 2 periods): each point on the graph in
Figure 6.9a represents one participant, and the size of the point is proportional to their
usage amount. We see that most participants‚Äô data points lie above the reference line,
so that usage increased more (or decreased less) in Type 2 when compared to Type 1
periods. Wilcoxon‚Äôs signed rank test yields only a 9.8% probability that the observed
differences between the percent changes come from a symmetric distribution about
zero. These results indicate that participants changed their usage because of the color
of the indicator, despite the comparable numerical discounts.
Figure 6.9b shows the average percentage change in usage for each user in Type 1
periods versus Type 3 periods. For both period types, the color did not change, but the
discount in Type 1 periods increased significantly (i.e., 28% in Type 1 versus 9% in
Type 3 periods). Thus, if participants had reacted to the numerical price discounts, we
would expect usage to increase in Type 1 and decrease in Type 3 periods: participants‚Äô
data points should lie above the reference line. However, participants‚Äô changes in
usage were comparable for both periods, with only half of users‚Äô data points above
the reference line in Figure 6.9b. Some participants increased their usage dramatically
in both types of periods, while most decreased their usage in both types of periods.
Thus, participants were mostly agnostic to the numerical values of the discounts,
likely because they only paid attention to the indicator color, which remained the
same for both types of periods.
Our posttrial interviews confirmed that the observed usage changes represent con-
scious decision making on the part of the trial participants. Participants generally did
pay attention to the price indicator color and chart of future prices: participant P4
‚Äúpaid attention to the little color icon that you guys have up on the top, and I tried to
tell everyone not to use it unless it was in green [high-discount periods]... I do look
at the chart and see at what point the discounts might come in,‚Äù while participant P7
checked the price indicator before using data: ‚ÄúI would see if it‚Äôs a good color for
me‚Äù (P7). A few participants also checked the numerical discount: ‚ÄúI do look at the
percentage. I will go to the app and just see where it‚Äôs gonna be over the next few
hours‚Äù (P10).
In a separate phase of the trial, we explicitly reminded participants of high price
periods with pop-up notifications that were sent every 10 min if participants used
a lot of data in high price periods. While many participants liked being notified, for
example, ‚ÄúAs a bill-payer I would think it is very useful‚Äù (P4), others thought that the
notifications interfered with using their devices: ‚Äúthe pop-ups were a bit annoying. I
think it would be nice if the warning messages appear on the top of the screen‚Äù (P2).
The notifications, however, were generally successful: 90% of participants either
decreased or did not increase their usage after one notification. About 60‚Äì80% of
participants decreased their usage in response to multiple consecutive notifications.
Figure 6.10 shows the distribution of observed changes in usage in response to the
notifications sent; multiple notifications were only sent if participants consumed more

160
‚àí500
0
(a)
(b)
500
1000
1500
2000
2500
‚àí500
0
500
1000
1500
2000
2500
Weighted average change in type 1 periods (%)
Weighted average change in type
2 periods (%)
Weighted average change in type
1 periods (%)
‚àí60
‚àí50
‚àí40
‚àí30
‚àí40
‚àí20
0
20
40
60
‚àí100
0
100
200
300
400
500
‚àí500
0
500
1000
1500
2000
2500
Weighted average change in type 3 periods (%)
‚àí55
‚àí50
‚àí45
‚àí40
‚àí35
‚àí30
‚àí45
‚àí40
‚àí35
‚àí30
Figure 6.9
Changes in usage for period types 1, 2, and 3. (a) Period types 1 and 2 and (b) period types 1 and 3.

LESSONS FROM DAY-AHEAD DYNAMIC TDP FIELD TRIALS
161
‚àí150
‚àí100
50
0
50
100
150
200
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Change in usage due to each notification (%)
Probability CDF
 
 
After first notification
After second
After third
After fourth
After fifth
Figure 6.10
Changes in participant usage volumes in response to notifications sent.
than 2 MB of data in consecutive 10-min intervals. We see that only a small minority
of participants increased their usage after receiving a notification.
Some participants suggested that prediction-based pop-ups with usage sugges-
tions, for example, warnings such as ‚Äú[i]f you watched this movie, you would be
over your usage quota‚Äù (P9) would be more useful than reminders of high prices.
Even alerting users to future low price times would be useful, as that would allow
users to plan ahead: ‚ÄúI think it‚Äôs a great idea, when the iPad would say ‚ÄòIf you wait
for half an hour, you can have 25% discount.‚Äô I thought it was incredibly useful for
my decision‚Äù (P6).
In fact, participants not only paid attention to the prices offered but also used the
usage history displays to track their usage and amount spent over time. A mother
of three explained how the app allowed her to monitor and control her children‚Äôs
usage when she was at work: ‚ÄúI can go back and see when they were using it!‚Äù (P4).
She also gave an anecdote on having used this feature to check whether people at
an iPad repair shop had used her data plan while fixing her broken screen. Another
user (P3) suggested including a usage indicator on the home screen, similar to the
price indicator, showing the remaining monthly budget. Our results thus imply that
users find icons on this top task bar convenient for monitoring the current price and
amount spent but prefer notifications to contain explicit suggestions for better ways
to use mobile data.
6.8.4.5
Empowering User Choice We finally turn to app features that help users
decide how to use mobile data so as to save money while still enjoying the use of
their device. In addition to the price displays and usage history discussed earlier, we
showed users which apps consumed the most data, allowing them to better choose
which apps to stop using so as to use less data. We also allowed users to control the
usage of secondary users such as children with an explicit scheduling functionality

162
HUMAN FACTORS IN SMART DATA PRICING
and to control their own usage with an autopilot feature that automatically delayed
time-insensitive apps to lower price periods.
We displayed the data used by the top five data-consuming apps to educate our
participants about which apps use the most data. Participants found this informa-
tion useful for keeping track of their usage and controlling how much total data they
consumed: ‚ÄúAbsolutely. I mean it would be nice if there were an indicator on the
app icon themselves.‚Äù Even the displays within our TDP app increased their aware-
ness of per-app data usage: ‚Äúusually it‚Äôs always the same type of thing‚Äîthe Internet,
YouTube, Facebook, those type of things‚Äù (P4). This awareness prompted participant
P4 to pay more attention to her usage in general, including that not shown on our app:
‚ÄúIf I connect to my email and work and I have a thousand emails in my mailbox and
it downloads all that stuff that‚Äôs a big consumer as well.‚Äù
While looking at their usage history allowed participants to monitor the usage
of secondary users, many participants wanted to control this usage as well. Most
were concerned about their children‚Äôs usage; as participant P6 stated: ‚ÄúI don‚Äôt think
they realize how long they‚Äôve been on there.‚Äù Participants liked the idea of explicitly
blocking certain apps at certain times in order to curtail their children‚Äôs usage: ‚ÄúI think
there‚Äôs a lot of parents that would use it‚Äù (P4). Indeed, as discussed in Section 6.4,
some studies have found that parents liked the idea of controlling their children‚Äôs data
usage even on wired networks [11‚Äì13].
Finally, we allowed our participants to control their own usage with an ‚Äúautopilot
mode‚Äù in which the DDTDP app scheduled usage based on users‚Äô predicted behavior,
their usage history, and the future prices. Although this autopilot mode was designed
to help users save money by delaying the least time-sensitive apps, our participants
preferred to manually control their usage: ‚ÄúI like to control my device manually‚Äù
(P2). Some were hesitant to use the autopilot mode because of concerns about the
loss of control: ‚ÄúIt‚Äôs really annoying to be put in the autopilot mode. I would not
want a computer to tell me what to use and when to use it‚Äù (P3). As participant P8
pointed out, an autopilot mode would only be accepted by users ‚Äúif it is sufficiently
intelligent to figure out the importance of each application‚Äôs usage.‚Äù In fact, although
our app allowed users to input and adjust different apps‚Äô delay sensitivities within
the scheduling algorithm, participants were still concerned that automatic scheduling
would interfere with their desired usage: ‚Äú[T]hat might not be the way you want it
scheduled‚Äù (P4). Participants were more accepting of automated scheduling of non-
critical apps: ‚ÄúIf you could put it in a queue and let the system figure out when the
cheapest time to do it is‚Äù (P7). Effectively implementing TDP thus requires HCI
researchers to balance users‚Äô desire to control their usage decisions with their will-
ingness to automatically schedule noncritical apps.
6.9
DISCUSSIONS AND CONCLUSIONS
Our investigations reveal that consumers today are concerned about the increasing
cost of data plans but are neither fully aware of their monthly usage nor equipped
to effectively manage and control it to stay within their budget. DDTDP offers a

DISCUSSIONS AND CONCLUSIONS
163
potential ‚Äúwin‚Äîwin‚Äù for both network operators and consumers, but its efficacy rests
on if and how it can modify user behavior. We develop a system that offers DDTDP
and conduct a trial that provides an initial validation of DDTDP‚Äôs promise as a future
direction of Internet pricing, following similar trends in other markets such as elec-
tricity and transport networks. We find that when economic incentives are offered to
users in a simple and comprehensible format, many will be willing to wait for such
a feedback signal from the network and change their behavior for noncritical mobile
applications.
In our trial, the maximum PAR of data demand decreased by 30% while the total
traffic increased by up to 130% with DDTDP, mostly because of the filling up of
discounted valley periods from the sales-day effect. This observation bolsters the
intuition that DDTDP can lead to a ‚Äúflatter‚Äù demand profile with lower peaks and
better spectrum utilization in off-peak hours. Additionally, the availability of such
a client-side DDTDP application not only enables users to make deferral decisions
but also helps them to self-educate, monitor, and control their usage and expenses.
Our trial participants liked UI information displays, such as the color-coded price
discounts, the indicator bar on the home screen, usage history, and so on. The trial
also revealed that while users in general are not willing to wait for critical applica-
tions, they are quite willing to delay noncritical applications when TDP incentives
are provided.
The trial also revealed interesting insights on the user-control aspects of DDTDP.
First, our participants viewed parental control at the granularity of apps as being use-
ful in managing their usage in a TDP regime. Second, they showed a desire to control
their usage manually instead of delegating control to an autopilot mode. When cou-
pled with the desire for parental control, we see that users want to take charge of
their consumption behaviors, for themselves and their families, in ways that require
transparency and flexibility. Therefore, realizing automated DDTDP would require
careful consideration of this trade-off. This also leads to a direction for future research
on the trade-off between users‚Äô willingness to implicitly reveal their delay tolerances
to network operators and the privacy and trust aspects related to such disclosures.
As HCI tackles increasingly complex sociotechnical ecosystems, for example,
mobile Internet, cloud computing, and smart grids, incorporating economic analysis
as a part of user behavior studies is becoming important. Out work on investigating
user behavior in a new TDP regime is an initial building block in this area of HCI
research. Our work also introduces a framework for realistic experimentation with
the HCI aspects of network economics. By interposing between ISPs and their cus-
tomers, we act as a resale ISP with user-facing apps and ISP-side economic analysis.
Future research on Internet pricing will need to address related issues on how simi-
lar HCI design principles can be effective in enabling other pricing variants, such as
app-based or QoS-based pricing. Additionally, HCI within SDP will need to address
the latest challenges brought about by the introduction of shared data plans in the
United States, which requires both real-time rating and charging for all subscribers
and new mechanisms for users to allocate and control the shared data caps. Many of
the findings and design principles laid out in this chapter will be relevant in addressing
these new challenges as SDP continues to evolve.

164
HUMAN FACTORS IN SMART DATA PRICING
ACKNOWLEDGMENTS
The authors would like to acknowledge Mr. R. Rill and Ms. D. Butnariu for their
assistance with application development and Ms. J. Bawa for her help during the
trial participant debriefing process. We are also thankful to all our industry partners,
including AT&T, MTA, Reliance, and NECA. The work has also immensely benefited
from extensive discussions with participants of the Workshop on Smart Data Pricing
(SDP 2012, Princeton, US & SDP 2013, Turin, Italy).
REFERENCES
1. A. Dix, J. Finlay, G. D. Abowd, and R. Beale. Human‚ÄìComputer Interaction. Pearson
Prentice-Hall, Harlow, UK, 3rd edition, 2004.
2. J. Nielsen and T. K. Landauer. A mathematical model of the finding of usability problems.
In Proceedings of the INTERACT and CHI conference on Human factors in computing
systems, pp. 206‚Äì213. ACM, 1993.
3. R. Langley. Practical Statistics Simply Explained, Dover Books Explaining Science Series.
Dover Publications, Mineola, New York, 1971.
4. F. Heller and J. Borchers. PowerSocket: towards on-outlet power consumption visualiza-
tion. In CHI Extended Abstracts, pp. 1981‚Äì1986. ACM, 2011.
5. T. Grace Holmes. Eco-visualization: combining art and technology to reduce energy con-
sumption. In Proceedings of C&C, pp. 153‚Äì162. ACM, 2007.
6. D. Petersen, J. Steele, and J. Wilkerson. WattBot: a residential electricity monitoring and
feedback system. In CHI Extended Abstracts, pp. 2847‚Äì2852. ACM, 2009.
7. M. Chetty, D. Tran, and R. E. Grinter. Getting to green: understanding resource consump-
tion in the home. In Proceedings of ACM UbiComp, pp. 242‚Äì251. ACM, 2008.
8. T. Kim, H. Hong, and B. Magerko. Design requirements for ambient display that supports
sustainable lifestyle. In Proceedings of DIS, pp. 103‚Äì112. ACM, 2010.
9. R. E. Grinter, W. K. Edwards, M. Chetty, E. S. Poole, J. Y. Sung, J. Yang, A. Crabtree, P.
Tolmie, T. Rodden, C. Greenhalgh, and S. Benford. ‚ÄúThe ins and outs of home networking:
the case for useful and usable domestic networking,‚Äù Transactions on Computer-Human
Interaction, 16, 2009, 8.
10. E. S. Poole, M. Chetty, R. E. Grinter, and W. K. Edwards. More than meets the eye: trans-
forming the user experience of home network management. In Proceedings of ACM DIS,
pp. 455‚Äì464. ACM, 2008.
11. M. Chetty, R. Banks, R. Harper, T. Regan, A. Sellen, C. Gkantsidis, T. Karagiannis, and
P. Key. Who‚Äôs hogging the bandwidth? The consequences of revealing the invisible in the
home. Proceedings of ACM SIGCHI, pp. 659‚Äì668. ACM, 2010.
12. J. Yang, W. K. Edwards, and D. Haslem. Eden: supporting home network management
through interactive visual tools. In Proceedings of ACM UIST, pp. 109‚Äì118. ACM, 2010.
13. R. Mortier, T. Rodden, P. Tolmie, T. Lodge, R. Spencer, A. Crabtree, A. Koliousis, and
J. Sventek. Homework: putting interaction into the infrastructure. In Proceedings of ACM
UIST, pp. 197‚Äì206. ACM, 2012.
14. Comcast. About excessive use of data, Oct. 2012. Available at: http://customer.comcast.
com/help-and-support/internet/data-usage-what-are-the-different-plans-launching.

REFERENCES
165
15. FCC. Internet access services: status as of June 30, 2009, 2010.
16. M. Chetty, D. Haslem, A. Baird, U. Ofoha, B. Sumner, and R. Grinter. Why is my Internet
slow? Making network speeds visible. In Proceedings of ACM SIGCHI, pp. 1889‚Äì1898.
ACM, 2011.
17. M. Chetty, R. Banks, A. J. Bernheim Brush, J. Donner, and R. E. Grinter. While the meter
is running: computing in a capped world. Interactions, 18(2), 2011, 72‚Äì75.
18. S. P Wyche, T. N. Smyth, M. Chetty, P. M. Aoki, and R. E Grinter. Deliberate interactions:
characterizing technology use in Nairobi, Kenya. In Proceedings of ACM SIGCHI, pp.
2593‚Äì2602. ACM, 2010.
19. M. Chetty, R. Banks, A. J. Brush, J. Donner, and R. Grinter. You‚Äôre capped: understanding
the effects of bandwidth caps on broadband use in the home. In Proceedings of ACM
SIGCHI, pp. 3021‚Äì3030. ACM, 2012.
20. H. Kim, S. Sundaresan, M. Chetty, N. Feamster, and W. K. Edwards. Communicating with
caps: managing usage caps in home networks. In Proceedings of ACM SIGCOMM (Posters
and Demos), pp. 470‚Äì471. ACM, 2011.
21. H. Varian. The demand for bandwidth: evidence from the INDEX project, 2002. Available
at: http://people.ischool.berkeley.edu/‚àºhal/Papers/brookings.pdf.
22. R. Edell and P. Varaiya. Providing internet access: What we learn from INDEX, 1999.
Keynote Speech, IEEE INFOCOM.
23. Y.-F. R. Chen and R. Jana. SpeedGate: a smart data pricing testbed based on speed tiers.
In Proceedings of the Workshop on Smart Data Pricing (SDP) at INFOCOM 2013, pp.
3195‚Äì3200. IEEE, 2013.
24. J. M. Dyaberi, B. S. Parsons, V. S. Pai, K. Kannan, Y.-F. R. Chen, R. Jana, D. Stern, A.
Varshavsky, and B. Wei. ‚ÄúManaging cellular congestion using incentives,‚Äù IEEE Commu-
nications Magazine, 50(11), 2012, 100‚Äì107.
25. S. Sen, C. Joe-Wong, S. Ha, and M. Chiang. ‚ÄúIncentivizing time-shifting of data: a survey
of time-dependent pricing for internet access,‚Äù IEEE Communications Magazine, 50(11),
2012, 91‚Äì99.
26. S. Sen, C. Joe-Wong, S. Ha, and M. Chiang. ‚ÄúA survey of broadband data pricing: past
proposals, current plans, and future trends,‚Äù ACM Computing Surveys, 46(2), 2014, to
appear.
27. The Economist. The Mother of Invention: Network Operators in the Poor World Are Cut-
ting Costs and Increasing Access in Innovative Ways, Sept. 2009. Special Report.
28. The Economist J. Shih, R. Katz, and A. D. Joseph. Pricing experiments for a
computer-telephony-service usage allocation. In Proceedings of IEEE GLOBECOM, pp.
2450‚Äì2454. IEEE, New York, 2001.
29. S. Ha, S. Sen, C. Joe-Wong, Y. Im, and M. Chiang. TUBE: time-dependent pricing for
mobile data. In Proceedings of ACM SIGCOMM, pp. 247‚Äì258. ACM, 2012.
30. V. Glass, J. Prinzivalli, and S. Stefanova. Persistence of middle mile problems for rural
exchanges local carriers. In Smart Data Pricing Workshop, July 2012. Available at:
http://scenic.princeton.edu/SDP2012/Talks-VictorGlass.pdf.
31. A. Odlyzko, B. St. Arnaud, E. Stallman, and M. Weinberg. Know Your Limits: Consid-
ering the Role of Data Caps and Usage Based Billing in Internet Access Service. Public
Knowledge, 2012. White Paper.
32. D. D. Clark. ‚ÄúInternet cost allocation and pricing‚Äù in L. W. McKnight and J. P. Bailey, eds.,
Internet Economics, MIT Press, Cambridge, Massachusetts, USA, 1997, pp. 215‚Äì252.

166
HUMAN FACTORS IN SMART DATA PRICING
33. B. X. Chen. Shared mobile data plans: who benefits? New York Times, Bits Blog, July
2012.
34. S. Sen, C. Joe-Wong, S. Ha, J. Bawa, and M. Chiang. When the price is right: enabling
time-dependent pricing of mobile data. In Proceedings of ACM SIGCHI, pp. 2477‚Äì2486.
ACM, 2013.
35. N. Anderson. US rural broadband: you can get it, but you can‚Äôt afford it. Ars Technica,
2008. Available at: http://arstechnica.com/uncategorized/2008/03/us-rural-broadband-
you-can-get-it-but-you-cant-afford-it/.
36. J. Newman. Netflix has bandwidth cap sufferers covered. PC World, June 2011. Availa-
ble at: http://www.pcworld.com/article/230982/Netflix_Has_Bandwidth_Cap_Sufferers_
Covered.html.
37. Sergey Lossev. iOS 7 feature gem: cellular data usage statistics. For Techies Only,
2013. Available at: http://www.fortechiesonly.com/2013/07/ios-7-feature-gem-cellular-
data-usage.html.
38. S. Perez. The best features of iOS 7. TechCrunch, 2013. Available at: http://techcrunch.
com/2013/06/10/the-best-features-of-ios-7/.
39. C. S. Yoo. Network neutrality, consumers, and innovation. University of Chicago Legal
Forum, 25, 2009, 179‚Äì262.
40. A. Schatz and S. E. Ante. ‚ÄúFCC chief backs usage-based broadband pricing,‚Äù December
2 2010. Wall Street Journal.
41. J. Genachowski. New rules for an open internet. FCC, 2010.
42. C. Joe-Wong, S. Ha, and M. Chiang. Time-dependent broadband pricing: feasibility and
benefits. In Proceedings of IEEE ICDCS, pp. 288‚Äì298. IEEE, 2011.

PART III
Usage-Based Pricing


7
Quantifying the Costs of
Customers for Usage-Based
Pricing
L√ÅSZL√ì GYARMATI, RADE STANOJEVIC, MICHAEL SIRIVIANOS,
and NIKOLAOS LAOUTARIS
7.1
INTRODUCTION
The intense competition among telecom operators is a significant driving force behind
the growing popularity of usage-based pricing in communication networks. The com-
petition among the operators results in shrinking profit margins: the operators drop
prices in order to attract or retain customers and face continuously increasing traffic
volumes. In terms of reduction of capital expense (CAPEX) and operational expense
(OPEX), the advancements in the technology are not able to keep up with the speed of
the increase in traffic. As a consequence, prices offered to customers should take into
account any induced expenses to sustain the profitability of the network operators.
Although operators have incentives to move toward usage-based pricing schemes,
customers are also paying more attention to their expenses given the recent state of
the global economy: they do not want to subsidize the costs of others. To meet the
expectations toward usage-based pricing, operators have to understand the cost of
their infrastructure and be aware as to how individual customers affect these costs.
Understanding and optimizing the total cost of ownership (TCO) of a network,
that is, both CAPEX and OPEX, is an important aspect of network operations, and
therefore, it has received substantial attention from procurement, network develop-
ment, and network planning departments of large telcos [1]. However, the impact
of individual customers on the cost of the network is much less understood because
of reasons such as difficulties of monitoring and nonlinearities of cost‚Äìcapacity
functions.
It is crucial to quantify how individual customers affect the TCO of a network as
this can be used to design better tariff schemes that reflect the usage and costs of the
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
169

170
QUANTIFYING THE COSTS OF CUSTOMERS FOR USAGE-BASED PRICING
customers. For example, a customer could receive discounts if it inflicts low costs
or charged more in the opposite case. In this chapter, we focus on the quantification
of the customers‚Äô costs in communication networks, that is, how an operator should
share the cost of the infrastructure among its customers. The structure of the chapter
is as follows. First, we review the cost of the network infrastructure and also how this
cost is affected by the aggregate traffic of the customers (Section 7.2). Afterwards, we
introduce a metric, namely, discrepancy, that quantifies the differences of cost-sharing
policies (Section 7.3). The forthcoming sections introduce several factors that impact
the quantification of the customers‚Äô costs. In all the cases, we apply the introduced
methodologies on real-world datasets: we derive the costs of the customers of a large
backbone network. Section 7.8 discusses related work while the conclusion is arrived
at in Section 7.9.
7.2
THE COST OF A CUSTOMER IN A NETWORK
We start with an example to show the pitfalls of the quantification of customers‚Äô cost
in a communication network. In Figure 7.1, we depict a toy infrastructure used by
two customers. The customers access web services using their mobile devices. Let
us assume that the aggregate cost of the infrastructure is $21k; we compute this by
summing up all the expenditure of the parts of the network. Now we have to share this
amount between the customers. A straightforward way is to look at the volume of the
traffic they inject into the network and share the cost of the infrastructure proportional
to this. As both customers have traffic of 10 Mbps, they both have a cost of $10.5k.
This is a simple cost-sharing policy; however, it has some limitations in terms of
fairness. One may ask why should customer 1 partially cover the costs of the other
customer? An alternate cost-sharing policy is when we consider exactly which parts
of the network were used by which customer. In this way, customer 1 has only $4.5k
cost because it uses a link partially with the other customer and an additional one
exclusively.
Additional factors impact the quantified cost of the customers including the pre-
cise cost of the infrastructure itself. The cost of a network consists of CAPEX and
OPEX for all devices present in the network. The CAPEX is the one-time cost paid
$4k
$10k
$2k
$5k
Customer 1
Customer 2
10 Mbps
10 Mbps
Figure 7.1
Quantifying the costs of the customers is challenging. The customers use different
parts of the infrastructure and, hence, can be accounted for diverse costs even of their traffic is
identical.

THE COST OF A CUSTOMER IN A NETWORK
171
whenever equipment is bought and installed [1]. It depends on the amount of traffic
the device must carry at a specific level of quality of service (QoS). A key observation
is that the capacity needed to guarantee a certain QoS depends on the peak traffic that
needs to be carried. This is because for a given capacity, QoS is minimized when the
traffic peaks. The OPEX corresponds to operational costs such as real estate, energy,
and personnel. It also depends on the amount of traffic and the QoS; however, that
dependence is more elastic. The cost-sharing policies we discuss are generic enough
to capture both CAPEX and OPEX with appropriate parameterization.
Next, we describe how we determine the aggregate cost that the sharing policies
distribute. A network consists of various network devices, for example, routers and
links. Let L denote the set of devices of the network. Let xl
i(t) denote the traffic volume
of customer i ‚ààN on network device l ‚ààL during the time interval t ‚àà[1, T]. Fur-
thermore, let cl denote the cost of network device l ‚ààL. The cost of a specific device
depends on the maximum amount of traffic that it has to carry during a certain time
interval. Thus, we obtain cl by examining the available capacity rates of the device
(e.g., 1 and 10 Gbps) and then using the cost of the smallest device whose capacity
satisfies the requested service-level agreement (SLA) for the given traffic demand.
For example, the operator fulfills its SLA by upgrading its devices when utilization
hits the 50% threshold. To this end, we assume that the costs follow a step function
C ‚à∂‚Ñù‚Üí‚Ñù. Thus, the cost of device l is
cl = C
(
max
t‚ààT
‚àë
i‚ààN
xl
i(t)
)
.
(7.1)
7.2.1
Datasets used in the Case Studies
In the remainder of the chapter, we introduce several factors that influence the quan-
tified cost of the customers. We also present case studies to illustrate the applicability
of the methodology in real-world scenarios. To this end, we use several datasets from
a tier-1 backbone network, which interconnects with other Internet Service Providers
(ISPs) that it serves. In our dataset, the network consists of tens of points of presence
(PoPs) and each customer connects to the network at one or more PoPs through one
or more interfaces. Overall, the datasets contain the per-link and per-customer traffic
statistics of more than 1000 links over a period of 3 weeks, with a 2-h granularity
(i.e., reporting volumes sent and received within 2 h). For additional details on the
datasets, we refer to Reference 2.
The cost of a network link depends, on the one hand, on the capacity of the inter-
face, that is, how much traffic it is capable of forwarding. On the other hand, the
geographic location and the applied technology have an impact as well. Hardware
costs, energy prices, deployment costs, and taxation, among others, contribute to the
cost of a network device. Thereby, it is challenging to accurately quantify the cost
of every single device. To estimate the cost of the network links, we use a wholesale
point-to-point transport price database. In our empirical analysis, we apply the prices
of network links with different bandwidth, ranging from E-1 (2 Mbps) throughout

172
QUANTIFYING THE COSTS OF CUSTOMERS FOR USAGE-BASED PRICING
STM-4 (622 Mbps) and 2.5G waves to 40G waves (40,000 Mbps). The costs of these
links define a step function for the network expenditures.
Although we analyze a backbone network as a case study, we emphasize that the
methodology we use to quantify the costs of the customers is general enough to be
applied in access networks [3] or for the whole end-to-end traffic of the customers.
7.3
DISCREPANCY, THE METRIC OF COMPARING DIFFERENT
COST-SHARING POLICIES
The operator can quantify the cost of the customers in numerous ways using
cost-sharing policies. We will present several orthogonal factors that could be com-
bined arbitrarily to create cost-sharing policies that are in line with the objectives
of the operator. The quantification of the customers‚Äô costs is a multifacet problem
covering the following questions:
‚Ä¢ How do we compute the costs of the customers?
‚Ä¢ Where do we meter the traffic?
‚Ä¢ What is the impact of the diverse costs of the devices?
‚Ä¢ Who is liable for the incurred costs?
Before addressing these questions and introducing the appropriate types of discrep-
ancies, we first introduce the metric we use to quantify the discrepancies of a pair of
cost-sharing procedures. Let N denote the set of customers who utilize resources in
the network. Let A and B denote the sets of costs allocated to each customer using
two different cost-sharing policies. It holds that |A| = |B| = |N|. Accordingly, ai ‚ààA
denotes the cost of customer i ‚ààN quantified based on the first cost-sharing policy
while bi ‚ààB represents customer i‚Äôs cost based on the second policy. We define the
discrepancy of the costs of customer i as
d(ai, bi) = max
{ai
bi
, bi
ai
}
.
(7.2)
We use this measure of discrepancy because it describes the relation of the costs with
a simple, comprehensible value. In the case studies, we use several statistics of the
customers‚Äô individual discrepancies to quantify the discrepancy of two cost-sharing
policies including the 95th percentile and the median.
illustrative example. Let us assume that three customers utilize the resources of
the network with costs presented in Table 7.1. The operator quantified the costs
of the customers using two cost-sharing policies. As we compute the discrepancy
of the policies for each customer, we gain both individual and aggregate insights.
For example, the two policies are identical in case of the third customer; however,
the discrepancy of the policies is 4 in case of the second customer, that is, the cost
of the customer is four times higher in case of policy A. For aggregate insights, we

HOW DO WE COMPUTE THE COSTS OF THE CUSTOMERS?
173
TABLE 7.1
Illustrative Example for Computing
Discrepancies
Cost Based on
Cost Based on
Policy A
Policy B
Discrepancy
Customer 1
150
300
2
Customer 2
200
50
4
Customer 3
150
150
1
We quantify the costs of the customers using two cost-sharing poli-
cies and derive the discrepancies of these policies.
investigate the distribution of the discrepancies, for example, the median discrepancy
of the policies is 2.
7.4
HOW DO WE COMPUTE THE COSTS OF THE CUSTOMERS?
The first source of discrepancies in some cost allocation methods is the function
that the operator uses to compute the contribution of the customers to the aggregate
cost (i.e., F-discrepancy). We next present four policies that strike different bal-
ances between precision and resource needs. We consider these methods because
operators apply some of these policies (e.g., the 95Percentile-Customer and the
Aggregate-Peak-Device) in practice to determine the costs a customer inflicts and
consequently the price the customers pays. For example, one can easily map some
of the tariffs (e.g., based on the purchased raw capacity or on the 95th percentile of
the traffic) used in practice to the introduced policies (e.g., Volume-Customer and
95Percentile-Customer).
‚Ä¢ Volume-Customer. We measure the amount of data that a single customer sends
on a specific network device (e.g., on a single link) for the whole analyzed time
period. Afterwards, we share the cost of the device proportionally to the traffic
volumes of the customers using it. Hence, the cost of customer i for device l is
cl
i = cl ‚ãÖ
‚àë
t‚ààT xl
i(t)
‚àë
j‚ààN
‚àë
t‚ààT xl
j(t)
.
(7.3)
‚Ä¢ 95Percentile-Customer. We distribute the cost of the device proportional to the
95th percentile [4] of the customers‚Äô traffic that traverses the particular device:
cl
i = cl ‚ãÖ
P95
(‚Ä¶ , xl
i(t), ‚Ä¶ )
‚àë
j‚ààN P95
(
‚Ä¶ , xl
j(t), ‚Ä¶
),
(7.4)
where P95() denotes the 95th percentile of the arguments.

174
QUANTIFYING THE COSTS OF CUSTOMERS FOR USAGE-BASED PRICING
‚Ä¢ Peak-Customer. Under this policy, we share the expenditure of the network
device proportional to the customers‚Äô maximum usage volumes for the given
time interval:
cl
i = cl ‚ãÖ
maxt‚ààT xl
i(t)
‚àë
j‚ààN maxt‚ààT xl
j(t)
.
(7.5)
‚Ä¢ Aggregate-Peak-Device. Operators plan the capacity of the network based on
the maximum utilization, for example, the 50% of the capacity of a device is
larger than the expected maximum of the traffic that traverses it. Accordingly,
we distribute the cost of the devices based on the contribution of individual
customers to the peak utilization. Assuming that the peak utilization of device
l happens at time step tm = arg maxt
‚àë
j‚ààN xl
j(t), we allocate the following cost
to customer i as
cl
i = cl ‚ãÖ
xl
i(tm)
‚àë
j‚ààN xl
j(tm)
.
(7.6)
We evaluate F-discrepancies by comparing a policy with Aggregate-Peak-Device,
which shares the costs in a fair way when it is guaranteed that new unallocated capac-
ity from an upgrade will soon find a customer to amortize it. The F-discrepancies of
the policies arise from the misalignment of traffic peaks: the peak of a customer‚Äôs traf-
fic may not coincide with the peak of the aggregate traffic the device carries. Before
presenting a date-driven evaluation of F-discrepancies, we first illustrate the intro-
duced policies.
illustrative example. Let us assume that two customers utilize device L1
with traffic volumes depicted in Figure 7.2. On the basis of the time series of
the customers, we compute their costs, that is, what portion of the total cost
of the device is related to each customer. The percentages of the cost that cus-
tomer 1 covers are 69.9%, 56.2%, 60%, and 53.3% of the total cost of the
device for the Volume-Customer, Peak-Customer, 95Percentile-Customer, and
Aggregate-Peak-Device policies, respectively. In terms of discrepancies these are
1.31, 1.05, 1.13, and 1.0 having Aggregate-Peak-Device as reference. We use the
introduced formulae of the policies to compute the shares of the customers. For
example, in case of the 95Percentile-Customer policy, customer 1 has a traffic
of 9 Mbps while the cumulative traffic is 15 Mbps resulting in 60% cost share.
The main cause behind the discrepancies of the costs are the misalignment of the
customers‚Äô peak, and that the different policies consider diverse parts of the time
series to compute a value that describes the traffic of the customer.
The introduced policies quantify the cost of the customers using different functions
on a per-device basis. The F-discrepancies of the customers emerge at two different
levels.
‚Ä¢ Device-Level Discrepancies. The discrepancy among different policies based
on the customers‚Äô costs is computed separately for each network device. In this

HOW DO WE COMPUTE THE COSTS OF THE CUSTOMERS?
175
(b)
L1
(a)
Customer 1
Customer 2
0
2
4
6
8
10
12
14
Traffic (Mpbs)
5
10
15
20
25
Aggregate peak
Peak-customer 2
Peak-customer 1
Customer 2
Customer 1
Figure 7.2
Illustrative example for F-discrepancies. The misalignment of the customers‚Äô
peak causes cost differences across policies. (a) Toplogy and (b) traffic pattern of L1.
case, the set of costs is
{cl
i | ‚àÄi ‚ààN} , l ‚ààL
(7.7)
and has cardinality |N||L|. For example, the F-discrepancy of customer i in case
of policies a and b is d(al
i, bl
i).
‚Ä¢ Network-Level Discrepancies. We first summarize the costs of a customer over
all the devices of the network, that is, we compute the total cost of each cus-
tomer. Afterwards, we compute the discrepancies of the policies. In this case,
the set of the costs over which we compute the discrepancies is
{
‚àë
l‚ààL
cl
i | ‚àÄi ‚ààN
}
(7.8)
and has cardinality |N|. For example, for policies a and b, the F-discrepancy of
customer i is d(‚àë
l‚ààL al
i, ‚àë
l‚ààL bl
i).
7.4.1
Case Study: F-Discrepancy in Backbone Networks
In the case studies, we use the datasets introduced in Section 7.2.1 to evaluate the var-
ious discrepancies of the cost-sharing policies. We use a uniform cost function for the
network devices in this section to focus on the specific properties of the cost-sharing
policies.

176
QUANTIFYING THE COSTS OF CUSTOMERS FOR USAGE-BASED PRICING
0
Volume-customer
95Percentile-customer
Peak-customer
Aggregate-peak-device
Customer 10
Customer 9
Customer 8
Customer 7
Customer 6
Customer 5
Customer 4
Customer 3
Customer 2
Customer 1
200
400
600
800
1000
1200
1400
Monthly cost ($)
Figure 7.3
Device-level cost of customers for varying cost-sharing policies. Link between
two European PoPs.
7.4.1.1
Device-Level F-Discrepancies To showcase the intricacies of F-discrepan-
cies, we start with an example based on a backbone link between two major PoPs in
Europe. The monthly cost of this link is $2163. In Figure 7.3, we plot the amount
of this cost attributed to each one of the 10 largest customers according to the
four policies. The F-discrepancy, that is, the ratio of the cost computed by the
Aggregate-Peak-Device policy and the cost computed by the simpler policy X‚àà
[Volume-Customer, 95Percentile-Customer, Peak-Customer] is as high as 2.36 for
customer 4 in this example. This particular customer impacts the aggregate peak of
the device disproportionally more than the other customers when we focus on the
traffic volumes of the customers. For several other customers the F-discrepancies
are much milder, that is, the different cost-sharing policies are more or less in
agreement. In the case of customer 4, the Volume-Customer policy fails by 50% to
approximate well the Aggregate-Peak-Device policy (thus, in this particular case,
the F-discrepancy is 2). This means that the traffic of this customer is peaky instead
of uniformly spread throughout the day.
We now look at F-discrepancies across all customers and all links in our dataset.
In Figure 7.4, we plot the F-discrepancies for the three simpler policies and we sum-
marize the main statistics in Table 7.2. The results show generally high
F-discrepancies. For example, 60% of the customers are assigned 25% higher or
lower cost than the real one they inflict according to Aggregate-Peak-Device. F-dis-

177
0
20
40
60
80 100
Percentage of traffic
1.0
1.2
1.4
1.6
1.8
2.0
Ratio of costs
(c)
0
20
40
60
80
100
Percentage of customers
1.0
1.5
2.0
2.5
3.0
3.5
4.0
4.5
5.0
Ratio of costs
1.0
1.00
20
40
60
80 100
Percentage of traffic
0
20
40
60
80 100
Percentage of traffic
1.2
1.4
1.6
1.8
2.0
Ratio of costs
1.0
1.2
1.4
1.6
1.8
2.0
Ratio of costs
0
20
40
60
80
100
Percentage of customers
(a)
(b)
0
20
40
60
80
100
Percentage of customers
1.5
2.0
2.5
3.0
3.5
4.0
4.5
5.0
Ratio of costs
1.0
1.5
2.0
2.5
3.0
3.5
4.0
4.5
5.0
Ratio of costs
Figure 7.4
Distribution of the device-level F-discrepancies between the simpler cost-sharing policies and the Aggregate-Peak-Device policy. Distri-
butions are based on the percentage of the customers and the traffic (insets). All the policies have high F-discrepancies, especially the F-discrepancies
of the Volume-Customer policy are large. (a) Volume-Customer, (b) Peak-Customer, and (c) 95Percentile-Customer.

178
QUANTIFYING THE COSTS OF CUSTOMERS FOR USAGE-BASED PRICING
TABLE 7.2
Device-Level F-Discrepancies Compared to the
Aggregate-Peak-Device Policy
Method
>25%
Median
95th Percentile
Volume-Customer
0.592
1.372
63.07
Peak-Customer
0.520
1.263
89.55
95Percentile-Customer
0.508
1.259
80.79
crepancies are particularly high for Volume-Customer and smaller for Peak-Customer
and 95Percentile-Customer. The last two policies are sensitive to peaks, albeit those
of particular customers instead of peaks of the aggregate traffic on the device.
Volume-Customer is even less accurate because it is not looking at any peaks but
only at aggregate volume over a longer time scale.
To illustrate the differences between the policies, Figure 7.5 depicts a portion
of the time series of a link where a large F-discrepancy (3.07) exists between the
Volume-Customer and the Aggregate-Peak-Device policies. The figure shows the
traffic pattern of the customer with the large F-discrepancy and the aggregate traf-
fic pattern of the other customers. The traffic of the customer is marginal compared
to the traffic of the others, yielding a very low Volume-Customer cost. However, dur-
ing the peak, the customer with the large discrepancy contributes a significant portion
to the aggregate traffic, thereby inducing a 3.07 times higher Aggregate-Peak-Device
than Volume-Customer cost.
0
Traffic
20
40
60
80
100
# 2-h interval
Customer
Others
Figure 7.5
Time series of the traffic of a customer with a large (3.07) F-discrepancy on a
single link. Volume-Customer versus Aggregate-Peak-Device policy.

HOW DO WE COMPUTE THE COSTS OF THE CUSTOMERS?
179
summary and implications. In the case of device-level discrepancies, numerous
and substantial F-discrepancies exist. This implies that operators should apply the
Aggregate-Peak-Device policy for computing the costs in case of a single device
instead of the simpler policies.
7.4.1.2
Network-Level F-Discrepancies We now examine F-discrepancies in
the context of the entire backbone network. We do this by summing the costs of a
customer over all the network‚Äôs devices. We present the relative aggregate costs of
the 10 largest customers in Figure 7.6; we consider the largest cost as the baseline.
We present the F-discrepancies of the policies in Table 7.3. The results reveal that
F-discrepancies at the network level are much smaller than that at the device level.
For example, the network-level median F-discrepancies are approximately 40% less
than the device-level ones. This is because in large networks, positive and negative
cost differences at each device cancel each other out; thus, the cost predictions of
the simpler policies become more aligned.
summary and implications. F-discrepancies although important for individual
links or small networks tend to become less significant for larger networks.
0
Customer 10
Customer 9
Customer 8
Customer 7
Customer 6
Customer 5
Customer 4
Customer 3
Customer 2
Customer 1
20
40
60
80
100
Relative cost (%)
Volume-customer
95Percentile-customer
Peak-customer
Aggregate-peak-device
Figure 7.6
Aggregate relative costs of the 10 largest customers; comparison normalized by
the largest cost.

180
QUANTIFYING THE COSTS OF CUSTOMERS FOR USAGE-BASED PRICING
TABLE 7.3
Network-Level F-Discrepancies Compared to the
Aggregate-Peak-Device Policy
Method
>25%
Median
95th Percentile
Volume-Customer
0.5
1.251
3.141
Peak-Customer
0.35
1.151
12.71
95Percentile-Customer
0.37
1.181
5.046
7.5
WHERE DO WE METER THE TRAFFIC?
The traffic metering method is the second source of the discrepancies (i.e.,
M-discrepancy). The resource requirements of the traffic monitoring tools depend
on the resolution of metering. The main cause behind the M-discrepancies is the
trade-off that operators face: increasing the precision of the metering improves the
validity of the quantified cost; however, this comes with an elevated cost for traffic
monitoring. We consider the two corner cases of traffic metering:
‚Ä¢ Customer-Ingress (CI). Each customer can have several ingress devices
through which it injects its traffic to the network. The operator keeps track of
the customers‚Äô usage solely on the ingress devices. This is the least expensive
metering method. The operator uses the ingress traffic time series to share the
network-wide expenditures among the customers.
‚Ä¢ Customer-per-Device (CD). If the operator deploys more advanced network
monitoring tools, it can capture the time series of the customers not only on
the ingress devices but also on all the devices located in the network. This is the
most expensive metering method and is typically done using NetFlow technol-
ogy, which comes at a high procurement and administration cost. Metering the
actual traffic on each network device allows the operator to compute the costs of
the customers based on the device-specific time series. Therefore, the operator
faces a trade-off: more accurate expenditure sharing versus more cost efficient
operation.
We define M-discrepancy as follows. First, we compute the cost of customer i on each
device l using a given cost allocation function (e.g., based on the Volume-Customer
policy of Section 7.4), and we compute the network-level cost of customer i as
‚àë
l‚ààL cl
i. Second, we compute using the given cost allocation function the customer‚Äôs
share (c‚àó
i ) of the network‚Äôs total cost (c = ‚àë
l‚ààL cl) using the ingress traffic time
series of the customers. The total ingress traffic of customer i is x‚àó
i (t) = ‚àë
l‚ààIi xl
i(t),
where Ii denotes the set of ingress devices that customer i uses. Accordingly, the
M-discrepancy of customer i is
di
(
‚àë
l‚ààL
cl
i, c‚àó
i
)
,
(7.9)
where di is our metric of discrepancy (Eq. 7.2).

WHERE DO WE METER THE TRAFFIC?
181
(b)
(a)
L1
L2
L0
Customer 1
Customer 2
0
5
10
15
20
25
Traffic (Mpbs)
5
10
15
20
25
Aggregate peak
Peak-customer 2
Peak-customer 1
Customer 2
Customer 1
Figure 7.7
Illustrative example for M-discrepancies: metering traffic only at the ingress link
(L0) causes customer 1 to have a larger share of the cost than if we meter at all devices. (a)
Topology and (b) traffic pattern of L0.
illustrative example. Let us now assume that the customers traffic on L0 is
as we show in Figure 7.7. The network consists of two additional devices: L1 on
which the traffic of the customers is as depicted in Figure 7.2 and L2 which is solely
utilized by customer 1 with a constant traffic of 10 Mbps. For illustration purposes,
we separate the two flows of customer 1, one on L1 and the other on L2, with a
dashed line in the Figure 7.7. Let us assume that the traffic on device L2 can be
transmitted on a device with modest capacity while the capacity of L1 should be
larger. The diverse device capacities imply diverse costs as well. In the case of
ingress metering, that is, sharing the cost of the network just based on the traffic of
L0, the cost of customer 1 is 83.9%, 73.1%, 76%, and 72% of the cost of the whole
network for the Volume-Customer, Peak-Customer, 95Percentile-Customer, and
Aggregate-Peak-Device policies, respectively. However, if we measure the traffic
of the customers on all the devices then shares of costs of customer 1 are 75.9%,
65%, 68%, and 62.7%. If we compare these cost fractions, we encounter large
discrepancies caused by the level of the metering.
7.5.1
Case Study: M-Discrepancy in Backbone Networks
Similar to F-discrepancies, we use the datasets introduced in Section 7.2.1 and a uni-
form cost function to analyze M-discrepancies. We compute the discrepancy in the
customer‚Äôs network-level cost derived by (i) metering its traffic at its ingress links

182
QUANTIFYING THE COSTS OF CUSTOMERS FOR USAGE-BASED PRICING
TABLE 7.4
Network-Level M-discrepancies of the Cost-Sharing
Policies
Method
>25%
Median
95th Percentile
Volume-Customer
0.695
1.543
34.53
Peak-Customer
0.752
1.738
32.34
95Percentile-Customer
0.750
1.630
19.10
Aggregate-Peak-Device
0.763
1.801
28.52
Comparison of the Customer-Ingress and the Customer-per-Device costs of the cus-
tomers.
TABLE 7.5
Discrepancies with the Aggregate-Peak-Device Policy Using
Customer-per-Device (Real Traffic) Metering
Method
>25%
Median
95th Percentile
Volume-Customer + CI
0.760
1.816
32.69
Aggregate-Peak-Device + CI
0.763
1.801
28.52
Volume-Customer + CD
0.500
1.251
3.141
Aggregate-Peak-Device + CD
0.0
1.0
1.0
Abbreviations: CI, Customer-Ingree; CD, Customer-per-Device.
(Customer-Ingress or CI) and (ii) metering its traffic on each device that the customer
uses (Customer-per-Device or CD). All of the policies result in high M-discrepancies
(ratios as high as 34) as summarized in Table 7.4.
Up to this point, we analyzed the impact of different discrepancies separately.
Next, we quantify the joint effect of F-discrepancies and M-discrepancies, that is,
how large can the difference be between the most and the least accurate combination
of function and metering schemes. We do this by comparing the network-level
costs of customers under the Volume-Customer + CI, Volume-Customer + CD, and
Aggregate-Peak-Device + CI policies with the nominally accurate one, namely,
the Aggregate-Peak-Device + CD policy. The results are summarized in Table 7.5.
The Volume-Customer policy has the smallest M-discrepancy, that is, the median
discrepancy of the Customer-Ingress and the Customer-per-Device costs is 1.5. On
the contrary, the Aggregate-Peak-Device policy yields the largest M-discrepancies.
The reason behind this is twofold. First, when metering traffic at the ingress links,
traffic that results in peaks at individual links does not result in peaks of the aggre-
gate ingress traffic. Second, under Customer-Ingress, the Aggregate-Peak-Device
policy takes into account only the time interval with the largest aggregate traf-
fic while the peaks of the internal devices may happen in other time intervals
neglected by the Aggregate-Peak-Device + CI policy. We observe that under the
Aggregate-Peak-Device + CI combination, the costs diverge by at least 25% for 76%

WHAT IS THE IMPACT OF THE DIVERSE COSTS OF THE DEVICES?
183
of the customers. In addition, we note that under the Volume-Customer + CI policy
and metering, the discrepancy can be as high as 32.
summary and implications. The level at which the operator meters the traffic
of the customers has a large impact on the quantified costs. Therefore, operators
should apply sophisticated metering strategies (e.g., network-wide deployment of
NetFlow-capable traffic monitoring devices) in order to accurately quantify the costs
of the customers. Moreover, the simple methods are no longer aligned with the real
cost of the customers (i.e., with the Aggregate-Peak-Customer policy) if the traffic
is metered on the ingress links.
7.6
WHAT IS THE IMPACT OF THE DIVERSE COSTS OF THE
DEVICES?
The third class of discrepancies is related to the total cost of ownership (TCO) of
different devices of the network (i.e., TCO discrepancy). Owing to the heterogeneous
nature of the network‚Äîcaused by the geographic and technological differences of
its parts‚Äîthe same traffic patterns imply diverse expenditures for the operator on
different devices. Therefore, additional discrepancies occur when we consider the
TCO of the network in more detail. The following levels of TCO impact the costs
and the discrepancies of the customers:
‚Ä¢ Pieces of Cost. Even if the capacities of two particular equipment are equal,
their costs can vary significantly because of the technology differences (newer
vs older generation), location (cost of shipping), differences in purchase price,
ad so on.
‚Ä¢ Location-Dependent Costs. The network operator deals with diverse costs at
each geographic location where it has a presence. The causes behind the varying
costs include but are not limited to the following factors: energy (e.g., the energy
price in Germany can be twice as much as that in the United Kingdom), facility
costs (e.g., the rental cost of office space in Hong Kong can be four times higher
than that in Germany [5]), taxation, and personnel costs.
Contrary to the former types of discrepancies, in the case of the TCO, only
network-level discrepancies exist. Formally, we define the network-level TCO
discrepancy of customer i as
d
(
‚àë
l‚ààL
cl
i,
‚àë
l‚ààL
cl ‚ãÖ
‚àë
l‚ààL el
i
‚àë
l‚ààL
‚àë
i‚ààN el
i
)
.
(7.10)
where the first term considers the diverse costs of the devices contrary to the second.
el
i denotes the cost of customer i in case of device l assuming uniform cost across all
the devices (el = e‚àó, ‚àÄl ‚ààL).

184
QUANTIFYING THE COSTS OF CUSTOMERS FOR USAGE-BASED PRICING
7.6.1
Case Study: TCO Discrepancy in Backbone Networks
Now we take into account that our dataset (Section 7.2.1) contains a geographically
distributed set of links with diverse costs. We compute the TCO discrepancies
by computing the ratio between the customers‚Äô costs given links with uniform
and diverse costs. In Figure 7.8, we illustrate the TCO discrepancies under the
Aggregate-Peak-Device policy. Each customer is affected by the TCO discrepancies.
The difference between the two costs can be as high as 5% of the cost of the entire
network.
We report the quantified TCO discrepancies of four policies in Table 7.6. The
results show generally extreme TCO discrepancies; some customers have TCO dis-
crepancies as high as 900. In addition, 80% of the customers are assigned 25% higher
or lower cost when the diverse costs of the links is considered.
0
0.0
0.0
0.5
0.5
1.0
1.0
1.5
1.5
2.0
2.0
2.5
2.5
0
Uniform costs (%)
5
5
10
10
15
15
20
20
True costs (%)
Figure 7.8
The customers‚Äô total costs for the uniform and true link costs using the
Aggregate-Peak-Device cost-sharing policy; the size of the circles is proportional to the aggre-
gate traffic volume of the customers.
TABLE 7.6
Network-Level TCO Discrepancies, That is, the Costs
of the Customers Based on Uniform Versus Diverse Link Costs
Method
>25%
Median
95th Percentile
Volume-Customer
0.830
4.305
961.1
Peak-Customer
0.802
4.187
933.1
95Percentile-Customer
0.817
4.079
922.4
Aggregate-Peak-Device
0.840
4.019
862.1

WHO IS LIABLE FOR THE INCURRED COSTS?
185
summary and implications. TCO discrepancies have a very large impact on the
costs of the customers. Cross-subsidization problems arise if the impact of TCO dif-
ferences is neglected. Network operators are aware of the fact that different parts of
their network have different TCOs. The implication of our results is that this diversity
should also be reflected in the quantification of the customers‚Äô costs‚Äîand eventually
in the tariffs too.
7.7
WHO IS LIABLE FOR THE INCURRED COSTS?
On the basis of the discussion of Section 7.2, one may conclude that splitting the cost
among customers is straightforward: for each device of the network, each customer
should pay in proportion to his/her contribution to the peak traffic carried by the
device. Things, however, are not that simple owed to liability complications. If we
were to build from scratch a new network for a fixed set of customers of known
demand, then the cost attributed to each customer should be proportional to the sum
of its contributions to the peaks of individual devices. Splitting costs based on the
contribution to the peak is indeed exact but only for this ‚Äúoffline problem.‚Äù However,
in reality, networks are not deployed as a single event but grow organically with the
addition of new customers and the ramping up of their traffic. Under this more realistic
case, peak-based cost sharing is not guaranteed to be fair. Consider, for example, the
case in which a network is already operating at the maximum utilization allowed by
QoS constraints and a small new customer triggers an expensive upgrade that leads
to a new network with plentiful unallocated capacity. In Figure 7.9, we illustrate the
case when a new customer arrives to the network and pushes the aggregate traffic
of the device above the upgrade threshold. Peak-based cost sharing would attribute
only a small fraction of the overall cost to the new customer. Is that fair? The answer
depends on what happens with the unallocated capacity. If the network can easily sell
it to new or existing customers, then indeed it is fair. If, however, selling this leftover
capacity is not guaranteed, then the new customer may have a larger liability for the
upgrade costs.
The final type of discrepancies is caused by the different types of customer liability
(i.e., L-discrepancy). We examine the following policies.
Traffic
Time
Upgrade 
threshold
With a new customer
Figure 7.9
The traffic of a new customer may increase the aggregate traffic of a device to such
an extent that the capacity of the device should be upgraded. Who should cover the elevated
costs of the network in such a case?

186
QUANTIFYING THE COSTS OF CUSTOMERS FOR USAGE-BASED PRICING
‚Ä¢ Aggregate-Peak-Device. This is the already introduced policy that is the mea-
sure of fairness when the customer liability is proportional to the aggregate peak
of devices.
‚Ä¢ Trigger. With this policy, the operator allocates the cost of the device exclusively
to the customer that triggered the capacity upgrade. This policy is applied when
the operator is not confident that it can sell the newly obtained but unallocated
capacity. To this end, the operator utilizes the historical traffic patterns of the
customers and their arriving order. For example, the cost of the first customer
is equal to the cost of the device that is capable to transmit his traffic demand.
We assume that the customers are numbered based on their arriving order while
ti denotes the time when the customer started to use the network. Accordingly,
the cost of customer i in case of the Trigger policy is
cl
i = C
(
max
t‚â§ti
‚àë
j‚àà{N|j‚â§i}
xl
j (t)
)
‚àíC
(
max
t‚â§ti
‚àë
j‚àà{N|j<i}
xl
j
(ti
)
)
.
(7.11)
The main drawbacks of Trigger are (i) it assigns cost only to the customer whose
traffic triggers upgrades and 0 to everyone else; therefore, order of arrival can
have a huge impact on the costs attributed to a customer; and (ii) it is difficult
to compute Trigger because it requires extensive historical data on the order of
customer arrival and traffic build up.
‚Ä¢ Shapley.
The Shapley cost-sharing policy lies between the two above pre-
sented extremes, the Aggregate-Peak-Device and Trigger policies. It assigns
to customers partial liability for upgrades, thereby avoiding the all-or-nothing
assignments of Triggers. Therefore, it is less strict than Trigger but more strict
than Aggregate-Peak-Device because it assigns ‚Äúaveraged‚Äù liabilities rather
than proportional liabilities based on a single time interval when a device
peaks.
The main advantage of the Shapley over the Aggregate-Peak-Device policy is
that its allocations are more stable than that of the Aggregate-Peak-Device pol-
icy in view of customer churn. For example, let us imagine that the aggregate
peak traffic of a device is P and appears at t1 (see Fig. 7.10). We also assume
Traffic
Time
P
P‚àíùúÄ
Customer X
t1
t2
Aggregate
Figure 7.10
The Shapley policy is a robust cost-sharing policy as it takes into account all the
local maxima of the aggregate traffic in quantifying the costs of the customers.

WHO IS LIABLE FOR THE INCURRED COSTS?
187
that the device at time t2 has load P ‚àíùúÄ. Now let us suppose that customer X is
responsible for 90% of P at t1 and 1% of P ‚àíùúÄat t2. Then if a small 2ùúÄcustomer
leaves from P at t1, then the peak will move to t2 and X will go from paying
90% to paying only 1% after a tiny 2ùúÄperturbation of the aggregate traffic.
On the contrary, the Shapley policy is aware of such situations as it takes into
account all the local maxima of the aggregate traffic in quantifying the costs of
the customers.
Under the Shapley policy, the cost of each customer is proportional to its average
marginal contribution to the device‚Äôs total cost. Particularly, let us consider all
the possible S ‚äÇN subsets (coalitions) of the customers who utilize resources
of the network device l. The cost of coalition S depends on the aggregate traffic
volume of the participants, that is , it is equal to the cost of a network device
that has sufficient capacity:
vl(S) = C
(
max
t‚ààT
‚àë
j‚ààS
xl
j (t)
)
.
(7.12)
On the basis of the v cost function of the coalitions, we compute the Shapley
value of customer i as
ùúôi(vl) = 1
N!
‚àë
Œ†‚ààSN
(vl (S (Œ†, i)) ‚àívl (S (Œ†, i) ‚ßµi)
) ,
(7.13)
where Œ† is a permutation of arrival order of the set N and S(Œ†, i) denotes the
set of players who arrived no later than i. The (ùúô1(v), ‚Ä¶ , ùúôN(v)) Shapley values
describe the fair distribution of costs in the case of the S = N grand coalition.
Fair in a way that it satisfies four intuitive fairness criteria [6‚Äì8]. We quantify
the cost of customer i based on its Shapley value for the device l as
cl
i = cl ‚ãÖ
ùúôi(vl)
‚àë
j‚ààN ùúôj(vl).
(7.14)
illustrative example. We present the traffic patterns of two customers and the
thresholds where the capacity of the device needs to be upgraded in Figure 7.11.
Customer 1 is liable for 53.3% and 87.5% of the cost of the device in case of the
Aggregate-Peak-Device and Shapley policies, respectively. Thus, the discrepancy is
1.64. The peak of the aggregate traffic happens in a time step where the customers‚Äô
traffic volumes are balanced. Although there are local maxima where the traffic of
customer 2 is small, it is not considered by the Aggregate-Peak-Device policy. From
a Shapley policy viewpoint, the traffic peak of customer 1 is too large to be transmitted
with a lower capacity device, that is , its traffic is mainly responsible for the total cost
of the device. If we assume that customer 1 arrived first, it causes 100% of the costs
according to the Trigger policy because its peak needs a larger-capacity device whose
leftover capacity can be used by customer 2 afterwards.

188
QUANTIFYING THE COSTS OF CUSTOMERS FOR USAGE-BASED PRICING
(b)
L1
(a)
Customer 1
Customer 2
0
2
4
6
8
10
12
14
Traffic (Mpbs)
5
10
15
20
25
Aggregate peak
Peak-customer 2
Peak-customer 1
Customer 2
Customer 1
Figure 7.11
Illustrative example for L-discrepancies. The capacity thresholds of device L1
are shown with dashed lines. (a) Topology and (b) traffic pattern of L1.
Customers can have both device- or network-level L-discrepancies, depending on
whether we consider the costs of the customers on particular devices (e.g., cl
i) or on
the aggregate (e.g., ‚àë
l‚ààL cl
i).
7.7.1
Case Study: L-Discrepancy in Backbone Networks
Out of the three policies described earlier, one, the Trigger policy, requires historic
information on customer arrival events as well as customer traffic information on long
time scales that relate to network upgrade events. As we do not have full historic
information on all the links, we omit the analysis of the Trigger policy in this case
study.
7.7.1.1
Device-Level
L-Discrepancies We
present
the
L-discrepancies
in
Table 7.7 by computing the ratio between Shapley and the Aggregate-Peak-Device
policies. L-discrepancies are quite high (ratios up to 472) pointing to the fact that
liability can bias significantly the cost-sharing picture that a telco has. For example,
the difference between the costs of the Shapley and the Aggregate-Peak-Device
policies is substantial: the median ratio of the costs is 1.5; however, in some cases,
the ratio can be larger than 400.
We present in Figure 7.12 a part of the time series of a customer with a large
L-discrepancy (3.25) along with the aggregate time series of the other customers
who utilize the same link. The dashed horizontal lines denote the traffic volumes
where the capacity of the link needs to be upgraded. The traffic of the customer is

WHO IS LIABLE FOR THE INCURRED COSTS?
189
TABLE 7.7
Device-Level L-Discrepancies
Compared to the Aggregate-Peak-Device Policy
Method
>25%
Median
95th Percentile
Shapley
0.674
1.497
472.4
100
Traffic
120
140
160
180
200
# 2-h interval
Customer
Others
Figure 7.12
Time series of a customer with large (3.25) L-discrepancy (Shapley vs
Aggregate-Peak-Device policy). The dashed lines represent the traffic volumes where the
capacity of the link needs to be upgraded.
small enough to be transmitted over a link with lower capacity. However, the traffic
of the other customers pushes the link to have larger capacity and thus larger cost.
The Shapley policy considers this fact when it computes the average marginal con-
tribution of the customer. As a result, the cost of the customer is less if we compute
it based solely on time of the largest utilization of the device. On the contrary, the
Aggregate-Peak-Customer policy focuses only on the time interval when the link
has its aggregate peak. The particular customer has significant share of the aggregate
peak and thus of the cost of the link according to the Aggregate-Peak-Customer. This,
however, masks who is responsible for the link‚Äôs larger capacity.
7.7.1.2
Network-Level L-Discrepancies We show the network-level L-discrepan-
cies in Table 7.8. At the network level, the number and the magnitude of the
L-discrepancies is smaller than that at the device level. Nevertheless, for more than
50% of the customers, the costs are off by at least 25%. The median L-discrepancies
of the policies are notable too.

190
QUANTIFYING THE COSTS OF CUSTOMERS FOR USAGE-BASED PRICING
TABLE 7.8
Network-Level L-Discrepancies
Compared to the Aggregate-Peak-Device Policy
Method
>25%
Median
95th Percentile
Shapley
0.54
1.316
179.3
summary and implications. The liability of network upgrades plays an important
role in the quantification of the costs of customers. The implication of the results is
that if the network is not built in one shot but is rather organically grown and upgraded,
then the Aggregate-Peak-Customer policy may induce cross-subsidization problems:
customers may be accounted for costs of upgrades for which they are not liable (or not
in that degree). From a customer point of view, this cross-subsidization may not be tol-
erated in a long run, given the competitive environment of communication networks.
That is, the customers may select other operator where they are not liable for the costs
of others. From the operator point of view, the large L-discrepancies dictate that it
needs to take them under serious consideration. If it is anticipated that the market for
data services will be healthy, the operator should choose the Aggregate-Peak-Device
policy. If, however, it expects difficulties in selling its capacity, our results indicate
that Shapley should be the policy of choice.
7.8
RELATED WORK
We refer to the textbook of Courcoubetis and Weber [9] for a thorough treatment of
pricing in communication networks. More detailed analyses of the challenge of cost
sharing in backbone networks were carried out in References 2 and 10.
Several studies investigated how to reduce the transit costs including ISP
peering [11‚Äì13], CDNs [14], P2P localization [15], and traffic smoothing [16].
Dimitropoulos et al. [4] presented a comprehensive analysis of the 95th percentile
pricing. A proposal by Laoutaris et al. [17, 18] showed how traffic can be transferred
in the network without increasing the 95th percentile of the customers. A recent
proposal by Stanojevic et al. [19] proposes to the customers of transit providers
to form a coalition to reduce their transit costs. Valancius et al. [20] show that a
small number of pricing tiers are enough to extract close-to-optimal efficiency in the
transit provider. Motiwala et al. [21] developed a cost model that operators can use
to evaluate the costs of their routing and peering decisions. The net neutrality debate
is in many ways related to the question of who is responsible for the costs in the
network [22].
Owing to the desirable fairness properties [6‚Äì8] of the Shapley value [23],
recent studies proposed pricing and cost-sharing mechanisms using Shapley values.
Briscoe [24, 25] motivates the usage of mechanisms that share the costs of the users
fairly as a way to reduce widely known cross-subsidization (the phenomenon in
which a small set of customers is subsidized by a large fraction of other customers of
the service) of the common infrastructure that often happens in the communication

REFERENCES
191
networks [26]. Stanojevic et al. [27] investigated the cross-subsidization of cellular
subscribers from a service plan selection point of view. Cooperative approaches
for cost sharing are investigated in case of interdomain routing [28, 29], and IP
multicast [6, 7]. Ma et al. [30, 31] presented a fair revenue sharing method for ISPs
that quantifies the importance of each ISP in the Internet ecosystem. The work
of Stanojevic et al. [3] empirically investigated the temporal usage effects using
the Shapley and the 95Percentile-Customer method in case of asymmetric digital
subscriber line (ADSL) subscribers.
7.9
CONCLUSIONS
Network operators need to know accurately the costs of their customers to apply
smart data pricing schemes in practice. Despite the widespread availability of big data
infrastructures, the quantification of the costs of individual customers is a challenging
task in communication networks. This chapter provided a thorough analysis of four
nontrivial underlying mechanism impacting the quantification of the costs. The influ-
encing factors include temporal/spatial characteristics of the customers, nonlinear
cost‚Äìcapacity relationships, measurement infrastructure issues, and high variability
of the component costs. On the basis of the findings of our case studies, usage-based
tariffs should include device-level expenditures and measurements to assure their
accuracy and fairness.
REFERENCES
1. W. B. Norton. The Internet Peering Playbook: Connecting to the Core of the Internet.
DrPeering Press, 2012.
2. L. Gyarmati, R. Stanojevic, M. Sirivianos, and N. Laoutaris. Sharing the cost of backbone
networks: cui bono? In Proceedings of the 2012 ACM Conference on Internet Measure-
ment Conference, IMC ‚Äô12, pp. 509‚Äì522, New York, NY, USA, 2012. ACM.
3. R. Stanojevic, N. Laoutaris, and P. Rodriguez. On economic heavy hitters: shapley value
analysis of 95th-percentile pricing. In Proceedings of the 10th ACM SIGCOMM Confer-
ence on Internet Measurement, IMC ‚Äô10, pp. 75‚Äì80, New York, NY, USA, 2010. ACM.
4. X. Dimitropoulos, P. Hurley, A. Kind, and M. Stoecklin. ‚ÄúOn the 95-percentile billing
method,‚Äù. In S. Moon, R. Teixeira, and S. Uhlig, eds., Passive and Active Network Mea-
surement, Lecture Notes in Computer Science, vol. 5448, Springer Berlin, Heidelberg,
2009, pp. 207‚Äì216.
5. Cushman & Wakefield. Office Space Across the World, 2012.
6. A. Archer, J. Feigenbaum, A. Krishnamurthy, R. Sami, and S. Shenker. ‚ÄúApproximation
and collusion in multicast cost sharing,‚Äù Games and Economic Behavior, 47(1), 2004,
36‚Äì71.
7. J. Feigenbaum, C. H. Papadimitriou, and S. Shenker. ‚ÄúSharing the cost of multicast trans-
missions,‚Äù Journal of Computer and System Sciences, 63(1), 2001, 21‚Äì41.
8. H. Moulin and S. Shenker. ‚ÄúStrategyproof sharing of submodular costs: budget balance
versus efficiency,‚Äù Economic Theory, 18, 2001, 511‚Äì533. Doi: 10.1007/PL00004200.

192
QUANTIFYING THE COSTS OF CUSTOMERS FOR USAGE-BASED PRICING
9. C. Courcoubetis and R. Weber. Pricing and Communications Networks. John Wiley &
Sons, Ltd, 2003, West Sussex, England.
10. L. Gyarmati, M. Sirivianos, and N. Laoutaris. Simplicity vs Precision: sharing the cost of
backbone networks. In NetEcon 2012 - Seventh Workshop on the Economics of Networks,
Systems, and Computation, 2012.
11. B. Augustin, B. Krishnamurthy, and W. Willinger. Ixps: mapped? In Proceedings of the
9th ACM SIGCOMM Conference on Internet Measurement Conference, IMC ‚Äô09, pp.
336‚Äì349, New York, NY, USA, 2009. ACM.
12. A. Dhamdhere and C. Dovrolis. The internet is flat: modeling the transition from a tran-
sit hierarchy to a peering mesh. In Proceedings of the 6th International Conference,
Co-NEXT ‚Äô10, pp. 21:1‚Äì21:12, New York, NY, USA, 2010. ACM.
13. A. Dhamdhere, C. Dovrolis, and P. Francois. A value-based framework for internet peering
agreements. In Teletraffic Congress (ITC), 2010 22nd International, 2010.
14. L. Qiu, V. N. Padmanabhan, and G. M. Voelker. On the placement of web server replicas.
In IEEE INFOCOM, pp. 1587‚Äì1596, 2001.
15. D. R. Choffnes and F. E. Bustamante. Taming the torrent: a practical approach to reducing
cross-ISP traffic in peer-to-peer systems. In Proceedings of the ACM SIGCOMM 2008
Conference on Data Communication, SIGCOMM ‚Äô08, pp. 363‚Äì374, New York, NY, USA,
2008. ACM.
16. M. Marcon, M. Dischinger, K. P. Gummadi, and A. Vahdat. The local and global effects
of traffic shaping in the internet. In Third International Conference on Communication
Systems and Networks (COMSNETS), 2011.
17. N. Laoutaris, G. Smaragdakis, P. Rodriguez, and R. Sundaram. Delay tolerant bulk data
transfers on the internet. In Proceedings of the Eleventh International Joint Conference
on Measurement and Modeling of Computer Systems, SIGMETRICS ‚Äô09, pp. 229‚Äì238,
New York, NY, USA, 2009. ACM.
18. N. Laoutaris, M. Sirivianos, X. Yang, and P. Rodriguez. Inter-data center bulk transfers
with netstitcher. In Proceedings of the ACM SIGCOMM 2011 Conference, SIGCOMM ‚Äô11,
pp. 74‚Äì85, New York, NY, USA, 2011. ACM.
19. R. Stanojevic, I. Castro, and S. Gorinsky. Cipt: using tuangou to reduce ip transit costs. In
Proceedings of the Seventh Conference on Emerging Networking Experiments and Tech-
nologies, CoNEXT ‚Äô11, pp. 17:1‚Äì17:12, New York, NY, USA, 2011. ACM.
20. V. Valancius, C. Lumezanu, N. Feamster, R. Johari, and V. V. Vazirani. How many tiers?
Pricing in the internet transit market. In Proceedings of the ACM SIGCOMM 2011 Con-
ference, SIGCOMM ‚Äô11, pp. 194‚Äì205, New York, NY, USA, 2011. ACM.
21. M. Motiwala, A. Dhamdhere, N. Feamster, and A. Lakhina. ‚ÄúTowards a cost model for
network traffic,‚Äù SIGCOMM Computer Communication Review, 42(1), 2012, 54‚Äì60.
22. K. C. Claffy. ‚ÄúNetwork neutrality‚Äù: the meme, its cost, its future,‚Äù SIGCOMM Computer
Communication Review, 41(5), 2011, 44‚Äì45.
23. L. S. Shapley. ‚ÄúA Value for n-Person Games,‚Äù In Annals of Mathematical Studies, H. W.
Kuhn and A. W. Tucker (eds.), 1953, pp. 307‚Äì318.
24. B. Briscoe. ‚ÄúFlow rate fairness: dismantling a religion,‚Äù SIGCOMM Computer Communi-
cation Review, 37(2), 2007, 63‚Äì74.
25. B. Briscoe. ‚ÄúA fairer, faster internet,‚Äù IEEE Spectrum, 45(12), 2008, 42‚Äì47.
26. K. Cho, K. Fukuda, H. Esaki, and A. Kato. The impact and implications of the growth
in residential user-to-user traffic. In SIGCOMM ‚Äô06, pp. 207‚Äì218, New York, NY, USA,
2006. ACM.

REFERENCES
193
27. R. Stanojevic, V. Erramilli, and K. Papagiannaki. Cognitive bias in network services.
In Proceedings of the 11th ACM Workshop on Hot Topics in Networks, HotNets-XI,
pp. 49‚Äì54, New York, NY, USA, 2012. ACM.
28. R. Mahajan, D. Wetherall, and T. Anderson. Negotiation-based routing between neigh-
boring ISPs. In Proceedings of the 2nd Conference on Symposium on Networked Systems
Design & Implementation - Volume 2, NSDI‚Äô05, pp. 29‚Äì42, Berkeley, CA, USA, 2005.
USENIX Association.
29. G. Shrimali, A. Akella, and A. Mutapcic. ‚ÄúCooperative interdomain traffic engineer-
ing using Nash bargaining and decomposition,‚Äù IEEE/ACM Transactions on Networking,
18(2), 2010, 341‚Äì352.
30. R. T. B. Ma, D. M. Chiu, J. C. S. Lui, V. Misra, and D. Rubenstein. Internet economics:
the use of shapley value for ISP settlement. In Proceedings of the 2007 ACM CoNEXT
Conference, CoNEXT ‚Äô07, pp. 6:1‚Äì6:12, New York, NY, USA, 2007. ACM.
31. R. T. B. Ma, D.-M. Chiu, J. C. S. Lui, V. Misra, and D. Rubenstein. On cooperative set-
tlement between content, transit and eyeball internet service providers. In Proceedings of
the 2008 ACM CoNEXT Conference, CoNEXT ‚Äô08, pp. 7:1‚Äì7:12, New York, NY, USA,
2008. ACM.


8
Usage-Based Pricing
Differentiation for
Communication Networks:
Incomplete Information and
Limited Pricing Choices‚àó
SHUQIN LI and JIANWEI HUANG
8.1
INTRODUCTION
Pricing is important for the design, operation, and management of communication
networks. Pricing has been used with two different meanings in the area of commu-
nication networks. One is the ‚Äúoptimization-oriented‚Äù pricing for network resource
allocation: it is made popular by Kelly‚Äôs seminal work on network congestion
control [2, 3]. For example, the Transmission Control Protocol (TCP) has been
successfully reverse engineered as a congestion-pricing-based solution to a network
optimization problem [4, 5]. A more general framework of network utility maximiza-
tion (NUM) was subsequently developed to forward-engineer many new network
protocols (see a recent survey in Reference [6]). In various NUM formulations,
the ‚Äúoptimization-oriented‚Äù prices often represent the Lagrangian multipliers of
various resource constraints and are used to coordinate different network entities
to achieve the maximum system performance in a distributed manner. The other
is the ‚Äúeconomics-based‚Äù pricing, which is used by a network service provider to
various objectives including revenue maximization. The proper design of such a
pricing becomes particularly challenging today because of the exponential growth
of data volume and applications in both wireline and wireless networks. In this
‚àóThis work is supported by the General Research Funds (Project Number CUHK 412710 and CUHK
412511) established under the University Grant Committee of the Hong Kong Special Administrative
Region, China. Part of the results have appeared in IEEE GLOBECOM 2009 [1].
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
195

196
USAGE-BASED PRICING DIFFERENTIATION
chapter, we focus on studying the ‚Äúeconomics-based‚Äù pricing schemes for managing
communication networks.
Economists have proposed many sophisticated pricing mechanisms to extract sur-
pluses from the consumers and maximize revenue (or profits) for the providers. A
typical example is the optimal nonlinear pricing (e.g., [7, 8]). In practice, however,
we often observe simple pricing schemes deployed by the service providers. Typi-
cal examples include flat-fee pricing and (piecewise) linear usage-based pricing. One
potential reason behind the gap between ‚Äútheory‚Äù and ‚Äúpractice‚Äù is that the optimal
pricing schemes derived in economics often has a high implementational complex-
ity. Besides a higher maintenance cost, complex pricing schemes are not ‚Äúcustomer
friendly‚Äù and discourage customers from using the services [9, 10]. Furthermore,
achieving the highest possible revenue with complicated pricing schemes requires
knowing the information (identity and preference) of each customer, which can be
challenging in large-scale communication networks. It is then natural to ask the fol-
lowing two questions:
1. How to design simple pricing schemes to achieve the best trade-off between
complexity and performance?
2. How does the network information structure impact the design of pricing
schemes?
This chapter tries to answer the above two questions with some stylized communi-
cation network models. Different from some previous work that considered a flat-fee
pricing scheme in which the payment does not depend on the resource consumption
(e.g., [9, 11, 12]), here we study the revenue maximization problem with the linear
usage-based pricing schemes, where a user‚Äôs total payment is linearly proportional
to allocated resource. In wireless communication networks, the usage-based pricing
scheme has become increasingly popular because of the rapid growth of wireless data
traffic. In June 2010, AT&T in the United States switched from the flat-free-based
pricing (i.e., unlimited data for a fixed fee) to the usage-based pricing schemes for
3G wireless data [13]. Verizon followed up with similar plans in July 2011. Simi-
lar usage-based pricing plans have been adopted by major Chinese wireless service
providers including China Mobile and China UniCom. Thus, the research on the
usage-based pricing is of great practical importance.
In this chapter, we consider the revenue maximization problem of a monopolist
service provider facing multiple groups of users. Each user determines its optimal
resource demand to maximize the surplus, which is the difference between its utility
and payment. The service provider chooses the pricing schemes to maximize his/her
revenue, subject to a limited resource. We consider both complete information and
incomplete information scenarios and design different pricing schemes with different
implementational complexity levels.
Our main contributions are as follows.
‚Ä¢ Complete Network Information. We propose a polynomial algorithm to compute
the optimal solution of the partial price differentiation problem, which includes

INTRODUCTION
197
the complete price differentiation scheme and the single pricing scheme as
special cases. The optimal solution has a threshold structure, which allocates
positive resources with priorities to users with high willingness to pay.
‚Ä¢ Revenue Gain under Complete Network Information. Compared to the single
pricing scheme, we identify the two important factors behind the revenue
increase of the (complete and partial) price differentiation schemes: the
differentiation gain and the effective market size. The revenue gain is the most
significant when users with high willingness to pay are minority among the
whole population and total resource is limited but not too small.
‚Ä¢ Incomplete Network Information. We design an incentive-compatible scheme
with the goal to achieve the same maximum revenue that can be achieved with
the complete information. We find that if the differences of willingness to pays
of users are larger than some thresholds, this incentive-compatible scheme can
achieve the same maximum revenue. We further characterize the necessary and
sufficient condition for the thresholds.
8.1.1
Related Work
It is often quite challenging to design a practical pricing schemes in communica-
tion networks. The main difficulties including dealing with the incomplete infor-
mation structure and limiting the implementational complexity. Under incomplete
network information, customers have the private information that is unknown by
the service providers. The study of incomplete information is a significant part of
microeconomics, especially in several important branches, such as incentive theory
[14], information economics [15], organization theory [16], and contract theory [17].
In particular, there exists a rich body of literature on monopoly revenue maximiza-
tion with incomplete information, for example, [7, 8, 18‚Äì26]. Mussa and Rosen in
Reference [7] and Maskin and Riley in Reference [8] proposed the optimal price
differentiation strategies based on product qualities and quantities, respectively. Arm-
strong in Reference [22], Bakos and Brynjolfsson in Reference [23], and Geng et
al. in Reference [24] studied the optimal multiproduct bundling schemes. Stokey
Reference [18], Baron and Besanko in [19], Hart and Tirole in Reference [20], and
Acquisti and Varian in Reference [21] focused on multistage price differentiation.
Cabral et al. in Reference [25] and Aoyagi in Reference [26] studied the pricing and
revenue maximization problem with network externalities. Although these existing
results on pricing provide theoretical optimal solutions under incomplete information,
they are seldom directly applied in practice, mainly because of their high implemen-
tational complexity. In a practical system, a service provider often needs to constrain
the number of pricing choices for the customers, either due to implementation com-
plexity constraint or users‚Äô aversion to too many choices [27].
However, the issue of optimal pricing design subject to complexity constraint is
less understood in the literature. One related analytical result is Reference [9], where
the authors discussed complexity issue in flat-fee pricing. To the best of our knowl-
edge, our study about partial price differentiation is the first result about the optimal
design of limited price choices in usage-based pricing schemes. It is interesting to

198
USAGE-BASED PRICING DIFFERENTIATION
compare our results on partial price differentiation with results in References [9]
and [28]. Shakkottai et al. in Reference [9] showed that the revenue gain of price dif-
ferentiation is small with a flat entry-fee-based Paris Metro Pricing (e.g., [29]), and a
complicated differentiation strategy may not be worthwhile. Chau et al. [28] further
derived the sufficient conditions of congestion functions that guarantee the viability
of these Paris Metro Pricing schemes. By contrast, our results show that the revenue
gain of price differentiation can be substantial for a usage-based pricing system.
Some recent work of usage-based pricing and revenue management in commu-
nication network includes References [30‚Äì38]. Basar and Srikant in Reference [30]
investigated the bandwidth allocation problem in a single-link network with the single
pricing scheme. Shen and Basar in Reference [31] extended the study to a more gen-
eral nonlinear pricing case with the incomplete network information scenario. They
discussed the single pricing scheme under incomplete information with a contin-
uum distribution of users‚Äô types. In contrast, our study on the incomplete information
focuses on the linear pricing with a discrete setting of users‚Äô types. We also show that,
besides the single pricing scheme, it is also possible to design differentiation pricing
schemes under incomplete information. Daoud et al. [32] studied an uplink power
allocation problem in a CDMA system, where the interference among users are the
key constraint instead of the limited total resource considered in this chapter. Jiang et
al. in Reference [33], Hande et al. in Reference [34], and Ha et al. in Reference [35]
focused on the study of the time-dependent pricing. He and Walrand in Reference
[36], Shakkottai and Srikant in Reference [37], and Gajic et al. in Reference [38]
focused on the interaction between different service providers embodied in the pric-
ing strategies, rather than the design of the pricing mechanism. Besides, none of the
related work considered the partial differential pricing as in this chapter.
8.2
SYSTEM MODEL
We consider a network with a total amount of S limited resource (which can be in
the form of rate, bandwidth, power, time slot, etc.). The resource is allocated by a
monopolistic service provider to a set ‚Ñê= {1, ‚Ä¶ , I} of user groups. Each group
i ‚àà‚Ñêhas Ni homogeneous users1 with the same utility function
ui(si) = ùúÉi ln(1 + si),
(8.1)
where si is the allocated resource to one user in group i and ùúÉi represents the willing-
ness to pay of group i. The logarithmic utility function is commonly used to model
the proportionally fair resource allocation in communication networks (see Refer-
ence [30] for detailed explanations). The analysis of the complete information case
can also be extended to more general utility functions (see Appendix 8.A.1). Without
the loss of generality, we assume that ùúÉ1 > ùúÉ2 > ¬∑ ¬∑ ¬∑ > ùúÉI. In other words, group 1
contains users with the highest valuation, and group I contains users with the lowest
valuation.
1A special case is Ni=1 for each group, that is, all users in the network are different.

SYSTEM MODEL
199
We consider two types of information structures:
1. Complete Information. The service provider knows each user‚Äôs utility function.
Although the complete information is a very strong assumption, it is the most
frequently studied scenario in the network pricing literature [30‚Äì34, 36‚Äì38].
The significance of studying the complete information is twofold. It serves
as the benchmark of practical designs and provides important insights for the
incomplete information analysis.
2. Incomplete Information. The service provider knows the total number of groups
I, the number of users in each group Ni, i ‚àà‚Ñê, and the utility function of each
group ui, i ‚àà‚Ñê. It does not know which user belongs to which group. Such
assumption in our discrete setting is analogous to that the service provider
knows only the users‚Äô type distribution in a continuum case. Such statistical
information can be obtained through long-term observations of a stationary
user population.
The interaction between the service provider and users can be characterized as a
two-stage Stackelberg model shown in Figure 8.1.
The service provider publishes the pricing scheme in Stage 1, and users respond
with their demands in Stage 2. The users want to maximize their surpluses by opti-
mizing their demands according to the pricing scheme. The service provider wants to
maximize its revenue by setting the right pricing scheme to induce desirable demands
from users. As the service provider has a limited total resource, it must guarantee that
the total demand from users is no larger than what it can supply.
The details of pricing schemes depend on the information structure of the service
provider. Under complete information, because the service provider can distinguish
different groups of users, it announces the pricing and the admission control decisions
to different groups of users. It can choose from the complete price differentiation
scheme, the single pricing scheme, and the partial price differentiation scheme to
realize a desired trade-off between the implementational complexity and the total
Stage 1 : service provider sets prices
Complete information
of each user?
Scheme 1: Complete price
differentiation
NO, statistical information only
Scheme 1: No price differentiation
Scheme 2: Incentive compatible
price differentiation
Scheme 2: No price differentiation
Stage 2: Each admitted user i decides resource quantity si
Service provider
must guarantee
Scheme 3: Partial price
differentiation
YES
{ni, pi}
si
ni si ‚â§ S
Figure 8.1
A two-stage Stackelberg model.

200
USAGE-BASED PRICING DIFFERENTIATION
revenue. Under incomplete information, it publishes a common price menu to all
users and allows users to freely choose a particular price option in this menu. All
these pricing schemes are discussed one by one in the following sections.
8.3
COMPLETE PRICE DIFFERENTIATION UNDER
COMPLETE INFORMATION
We first consider the complete information case. As the service provider knows the
utility and the identity of each user, it is possible to maximize the revenue by charging
a different price to each group of users. The analysis will be based on backward
induction, starting from Stage 2 and then moving to Stage 1.
8.3.1
User‚Äôs Surplus Maximization Problem in Stage 2
If a user in group i has been admitted into the network and offered a linear price pi in
Stage 1, then it solves the following surplus maximization problem,
maximize
si‚â•0
ui(si) ‚àípisi,
(8.2)
which leads to the following unique optimal demand
si(pi) =
(ùúÉi
pi
‚àí1
)+
, where (‚ãÖ)+ ‚âúmax(‚ãÖ, 0).
(8.3)
Remark 8.1
The analysis of the Stage 2 user surplus maximization problem
is the same for all pricing schemes. The result in Eq. (8.3) will be also used in
Sections 8.4‚Äì8.6.
8.3.2
Service Provider‚Äôs Pricing and Admission Control Problem in Stage 1
In Stage 1, the service provider maximizes its revenue by choosing the price pi and
the number of admitted users ni for each group i subject to the limited total resource
S. The key idea is to perform a complete price differentiation (CP) scheme, that is,
charging each group with a different price.
CP ‚à∂maximize
p‚â•0,s‚â•0,n
‚àë
i‚àà‚Ñê
nipisi
(8.4)
subject to si =
(ùúÉi
pi
‚àí1
)+
, i ‚àà‚Ñê,
(8.5)
ni ‚àà{0, ‚Ä¶ , Ni} , i ‚àà‚Ñê,
(8.6)
‚àë
i‚àà‚Ñê
nisi ‚â§S,
(8.7)

COMPLETE PRICE DIFFERENTIATION UNDER COMPLETE INFORMATION
201
where p
Œî= {pi, i ‚àà‚Ñê}, s
Œî= {si, i ‚àà‚Ñê}, and n
Œî= {ni, i ‚àà‚Ñê}. We use bold symbols
to denote vectors in the sequel. Constraint (8.5) is the solution of the Stage 2 user
surplus maximization problem in Eq. (8.3). Constraint (8.6) denotes the admission
control decision, and constraint (8.7) represents the total limited resource in the
network.
The CP problem is not straightforward to solve, because it is a nonconvex opti-
mization problem with a nonconvex objective function (summation of products of ni
and pi), a coupled constraint (8.7), and integer variables n. However, it is possible to
convert it into an equivalent convex formulation through a series of transformations,
and thus the problem can be solved efficiently.
First, we can remove the (‚ãÖ)+ sign in constraint (8.5) by realizing the fact that there
is no need to set pi higher than ùúÉi for users in group i; users in group i already demand
zero resource and generate zero revenue when pi = ùúÉi. This means that we can rewrite
constraint (8.5) as
pi =
ùúÉi
si + 1 and si ‚â•0, i ‚àà‚Ñê.
(8.8)
Plugging Eq. (8.8) into Eq. (8.4), the objective function becomes ‚àë
i‚àà‚Ñê
ni
ùúÉisi
si+1. We can
further decompose the CP problem in the following two subproblems:
1. Resource Allocation. For a fixed admission control decision n, solve for the
optimal resource allocation s.
CP1 ‚à∂maximize
s‚â•0
‚àë
i‚àà‚Ñê
ni
ùúÉisi
si + 1
subject to
‚àë
i‚àà‚Ñê
nisi ‚â§S.
(8.9)
Denote the solution of CP1 as s‚àó= (s‚àó
i (n), ‚àÄi ‚àà‚Ñê). We further maximize the
revenue of the integer admission control variables n.
2. Admission Control.
CP2 ‚à∂maximize
n
‚àë
i‚àà‚Ñê
ni
ùúÉis‚àó
i (n)
s‚àó
i (n) + 1
subject to ni ‚àà{0, ‚Ä¶ , Ni} , i ‚àà‚Ñê.
(8.10)
Let us first solve the CP1 subproblem in s. Note that it is a convex optimization
problem. By using Lagrange multiplier technique, we can get the first-order necessary
and sufficient condition:
s‚àó
i (ùúÜ) =
(‚àö
ùúÉi
ùúÜ‚àí1
)+
,
(8.11)
where ùúÜis the Lagrange multiplier corresponding to the resource constraint (8.9).

202
USAGE-BASED PRICING DIFFERENTIATION
Meanwhile, we note the resource constraint (8.9) must hold with equality, because
the objective is a strictly increasing function in si. Thus, by plugging Eq. (8.11) into
(8.9), we have
‚àë
i‚àà‚Ñê
ni
(‚àö
ùúÉi
ùúÜ‚àí1
)+
= S.
(8.12)
This weighted water-filling problem (where
1
‚àö
ùúÜcan be viewed as the water level)
in general has no closed-form solution for ùúÜ. However, we can efficiently determine
the optimal solution ùúÜ‚àóby exploiting the special structure of our problem. Note that
because ùúÉ1 > ¬∑ ¬∑ ¬∑ > ùúÉI, then ùúÜ‚àómust satisfy the following condition:
Kcp
‚àë
i=1
ni
(‚àö
ùúÉi
ùúÜ‚àó‚àí1
)
= S,
(8.13)
for a group index threshold value Kcp satisfying
ùúÉKcp
ùúÜ‚àó> 1 and ùúÉKcp+1
ùúÜ‚àó
‚â§1.
(8.14)
In other words, only groups with index no larger than Kcp will be allocated the posi-
tive resource. This property leads to the following simple Algorithm 8.1 to compute
ùúÜ‚àóand group index threshold Kcp: we start by assuming Kcp = I and compute ùúÜ. If
Eq. (8.14) is not satisfied, we decrease Kcp by one and recompute ùúÜuntil Eq. (8.14)
is satisfied.
Algorithm 8.1
Resource-Allocation-CP({ni, ùúÉi}i‚àà‚Ñê, S):
k ‚ÜêI, ùúÜ(k) ‚Üê
( ‚àëk
i=1 ni
‚àö
ùúÉi
S+‚àëk
i=1 ni
)2
while ùúÉk ‚â§ùúÜ(k)
k ‚Üêk ‚àí1, ùúÜ(k) ‚Üê
( ‚àëk
i=1 ni
‚àö
ùúÉi
S+‚àëk
i=1 ni
)2
end while
Kcp ‚Üêk, ùúÜ‚àó‚ÜêùúÜ(k)
return (Kcp, ùúÜ‚àó)
End pseudo-code.
As ùúÉ1 > ùúÜ(1) =
( n1
s+n1
)2
ùúÉ1, Algorithm 8.1 always converges and returns the
unique values of Kcp and ùúÜ‚àó. The complexity is ùí™(I), that is, linear in the number of
user groups (not the number of users).

COMPLETE PRICE DIFFERENTIATION UNDER COMPLETE INFORMATION
203
With Kcp and ùúÜ‚àó, the solution of the resource allocation problem can be written as
s‚àó
i =
‚éß
‚é™
‚é®
‚é™‚é©
‚àö
ùúÉi
ùúÜ‚àó‚àí1,
i = 1, ‚Ä¶ , Kcp;
0,
otherwise,
(8.15)
For the ease of discussion, we introduce a new notion of the effective market, which
denotes all the groups allocated nonzero resource. For resource allocation subproblem
CP1, the threshold Kcp describes the size of the effective market. All groups with
indices no larger than Kcp are effective groups, and users in these groups as effective
users. An example of the effective market is illustrated in Figure 8.2.
Now let us solve the admission control subproblem CP2. Denote the objective Eq.
(8.10) as Rcp(n), by Eq. (8.15), then Rcp(n)
Œî= ‚àëKcp
i=1ni
(‚àö
ùúÉi
ùúÜ‚àó(n) ‚àí1
) ‚àö
ùúÉiùúÜ‚àó(n). We first
relax the integer domain constraint of ni as ni ‚àà[0, Ni]. As Eq. (8.13), by taking the
derivative of the objective function Rcp(n) with respect to ni, we have
ùúïRcp(n)
ùúïni
= ni
‚éõ
‚éú
‚éú‚éù
‚àö
ùúÉi
ùúÜ‚àó(n) ‚àí1
‚éû
‚éü
‚éü‚é†
ùúï
‚àö
ùúÉiùúÜ‚àó(n)
ùúïni
,
(8.16)
Also from Eq (8.13), we have ùúÜ‚àó=
( ‚àëKcp
i=i ni
‚àö
ùúÉi
S+‚àëKcp
i=1 ni
)2
, thus ùúï
‚àö
ùúÜ‚àó(n)
ùúïni
> 0, for i = 1, ‚Ä¶ , Kcp,
and ùúï
‚àö
ùúÜ‚àó(n)
ùúïni
= 0, for i = Kcp + 1, ‚Ä¶ , I. This means that the objective Rcp(n) is strictly
increasing in ni for all i = 1, ‚Ä¶ , Kcp, thus it is optimal to admit all users in the
effective market. The admission decisions for groups not in the effective market
are irrelevant to the optimization, because those users consume zero resource.
Therefore, one of the optimal solutions of the CP1 subproblem is n‚àó
i = Ni for all
i ‚àà‚Ñê. Solving CP1 and CP2 subproblems leads to the optimal solution of the CP
problem:
Nonzero resource
Group 1
Group 2
Group 3
Group 4
Group 5
Threshold (size) of
effective market
Kcp = 4
Group 6
Zero resource
Effective marker
Willingness to pay decreases
Figure 8.2
A six-group example for effective market: the willingness to pays decrease from
group 1 to group 6. The effective market threshold can be obtained by Algorithm 8.1 and is
four in this example.

204
USAGE-BASED PRICING DIFFERENTIATION
Theorem 8.1
There exists an optimal solution of the CP problem that satisfies the
following conditions:
‚Ä¢ All users are admitted: n‚àó
i = Ni for all i ‚àà‚Ñê.
‚Ä¢ There exist a value ùúÜ‚àóand a group index threshold Kcp ‚â§I, such that only the
top Kcp groups of users receive positive resource allocations,
s‚àó
i =
{‚àö
ùúÉi
ùúÜ‚àó‚àí1,
i = 1, ‚Ä¶ , Kcp;
0,
otherwise,
with the prices
p‚àó
i =
{‚àö
ùúÉiùúÜ‚àó,
i = 1, ‚Ä¶ , Kcp;
ùúÉi,
otherwise.
The values of ùúÜ‚àóand Kcp can be computed as in Algorithm 8.1 by setting ni = Ni,
for all i ‚àà‚Ñê.
Theorem 8.1 provides the right economic intuition: the service provider maximizes
its revenue by charging a higher price to users with a higher willingness to pay. It is
easy to check that pi > pj for any i < j. The users with low willingness to pay are
excluded from the markets.
8.3.3
Properties
Here we summarize some interesting properties of the optimal complete price differ-
entiation scheme:
8.3.3.1
Threshold Structure The threshold-based resource allocation means that
higher willingness to pay groups have higher priories of obtaining the resource at the
optimal solution.
To see this clearly, assume the effective market size is K(1) under parameters
{ùúÉi, N(1)
i }i‚àà‚Ñêand S. Here the superscript (1) denotes the first parameter set. Now
consider another set of parameters {ùúÉi, N(2)
i }i‚àà‚Ñêand S, where N(2)
i
‚â•N(1)
i
for each
group i and the new effective market size is K(2). By Eq. (8.13), we can see that
K(2) ‚â§K(1). Furthermore, we can show that if some high willingness to pay group
has many more users under the latter system parameters, that is, N(2)
i
is much larger
than N(1)
i
for some i < K(1), then the effective size will be strictly decreased, that is,
K(2) < K(1). In other words, the increase of high willingness to pay users will drive
the low willingness to pay users out of the effective market.
8.3.3.2
Admission Control with Pricing Theorem 8.1 shows the explicit admis-
sion control is not necessary at the optimal solution. Also from Theorem 8.1, we can
see that when the number of users in any effective group increases, the price, p‚àó
i , for
all i ‚àà‚Ñêincreases and resource, s‚àó
i , for all ‚àÄi ‚â§Kcp decreases. The prices serve as
the indications of the scarcity of the resources and will automatically prevent the low
willingness to pay users to consume the network resource.

SINGLE PRICING SCHEME
205
8.4
SINGLE PRICING SCHEME
In Section 8.3, we showed that the CP scheme is the optimal pricing scheme to max-
imize the revenue under complete information. However, such a complicated pricing
scheme is of high implementational complexity. In this section, we study the single
pricing scheme. It is clear that the scheme will in general suffer a revenue loss com-
paring with the CP scheme. We will try to characterize the impact of various system
parameters on such revenue loss.
8.4.1
Problem Formulation and Solution
Let us first formulate the single pricing (SP) problem.
SP ‚à∂maximize
p‚â•0, n
p
‚àë
i‚àà‚Ñê
nisi
subject to si =
(ùúÉi
p ‚àí1
)+
, i ‚àà‚Ñê
ni ‚àà{0, ‚Ä¶ , Ni} , i ‚àà‚Ñê
‚àë
i‚àà‚Ñê
nisi ‚â§S.
Comparing with the CP problem in Section 8.3, here the service provider charges a
single price p to all groups of users. After a similar transformation as in Section 8.3,
we can show that the optimal single price satisfies the following weighted
water-filling condition
‚àë
i‚àà‚Ñê
Ni
(ùúÉi
p ‚àí1
)+
= S.
Thus we can obtain the following solution that shares a similar structure as complete
price differentiation.
Theorem 8.2
There exists an optimal solution of the SP problem that satisfies the
following conditions:
‚Ä¢ All users are admitted: n‚àó
i = Ni, for all i ‚àà‚Ñê.
‚Ä¢ There exist a price p‚àóand a group index threshold Ksp ‚â§I, such that only the
top Ksp groups of users receive positive resource allocations,
s‚àó
i =
‚éß
‚é™
‚é®
‚é™‚é©
ùúÉi
p‚àó‚àí1,
i = 1, 2, ‚Ä¶ , Ksp,
0,
otherwise,

206
USAGE-BASED PRICING DIFFERENTIATION
with the price
p‚àó= p(Ksp) =
‚àëKsp
i=1 NiùúÉi
S + ‚àëKsp
i=1 Ni
.
The value of Ksp and p‚àócan be computed as in Algorithm 8.2.
Algorithm 8.2
Threshold-SP ({Ni, ùúÉi}i‚àà‚Ñê, S):
k ‚ÜêI, p(k) ‚Üê
‚àëk
i=1 NiùúÉi
S+‚àëk
i=1 Ni
while ùúÉk ‚â§p(k)
k ‚Üêk ‚àí1, p(k) ‚Üê
‚àëk
i=1 NiùúÉi
S+‚àëk
i=1 Ni
end while
Ksp ‚Üêk, p‚àó‚Üêp(k)
return Ksp, p‚àó
End pseudo-code.
8.4.2
Properties
The SP scheme shares several similar properties as the CP scheme (Section 8.3.3),
including the threshold structure and admission control with pricing. Similarly, we
can define the effective market for the SP scheme.
It is more interesting to notice the differences between these two schemes. To
distinguish solutions, we use the superscript ‚Äúcp‚Äù for the CP scheme, and ‚Äúsp‚Äù for
the SP scheme.
Proposition 8.1
Under same parameters {Ni, ùúÉi}i‚àà‚Ñêand S:
1. the effective market of the SP scheme is no larger than the one of the CP scheme,
that is, Ksp ‚â§Kcp.
2. there exists a threshold k ‚àà{1, 2 ‚Ä¶ , Ksp}, such that
‚Ä¢ groups with indices less than k (high willingness to pay users) are charged
with higher prices and allocated less resources in the CP scheme, that is,
pcp
i
‚â•p‚àóand scp
i
‚â§ssp
i , ‚àÄi ‚â§k, where the equality holds if only if i = k and
ùúÉk = p‚àó2
ùúÜ‚àó,
‚Ä¢ groups with indices greater than k (low willingness to pay users) are charged
with lower prices and allocated more resources in the CP scheme, that is,
pcp
i
< p‚àóand scp
i
> ssp
i , ‚àÄi ‚â•k,
where p‚àóis the optimal single price.
The proof is given in Appendix 8.A.2. An illustrative example is shown in
Figures 8.3 and 8.4.

SINGLE PRICING SCHEME
207
Price
Group
p1
cp
p2
cp
pk
cp
pk+1
cp
pK cp
cp
p‚àó : the optimal price
of the SP scheme
1
2
3
k
Ksp
Kcp
k + 1
Figure 8.3
Comparison of prices between the CP scheme and the SP scheme.
Resource
Group
Resource allocation of the
CP scheme
Resource allocation of the
SP scheme
1
2
3
k
Ksp
Kcp
k + 1
Figure 8.4
Comparison of resource allocation between the CP scheme and the SP scheme.
It is easy to understand that the SP scheme makes less revenue, because it is a
feasible solution to the CP problem. A little bit more computation sheds more light on
this comparison. We introduce the following notations to streamline the comparison:
‚Ä¢ Neff (k) ‚âú‚àëk
i=1 Ni: the number of effective users, where k is the size of the effec-
tive market.
‚Ä¢ ùõæi(k) ‚âú
Ni
Neff (k), i = 1, 2, ‚Ä¶ , k: the fraction of group i‚Äôs users in the effective
market.

208
USAGE-BASED PRICING DIFFERENTIATION
‚Ä¢ s(k) ‚âú
S
Neff (k): the average resource per an effective user.
‚Ä¢ ùúÉ(k) ‚âú‚àëk
i=1 ùõæiùúÉi: the average willingness to pay per an effective user.
On the basis of Theorem 8.1, the revenue of the CP scheme is
Rcp(Kcp) = Neff (Kcp)
(
s(Kcp)ùúÉ(Kcp) + g(Kcp)
s(Kcp) + 1
)
,
(8.17)
where
g(Kcp) = 1
ùúÜ‚àó
Kcp
‚àë
i=1
Kcp
‚àë
j>i
ùõæiùõæj(pcp
i ‚àípcp
j )2.
(8.18)
On the basis of Theorem 8.2, the revenue of the SP scheme is
Rsp(Ksp) = Neff (Ksp)
(
s(Ksp)ùúÉ(Ksp)
s(Ksp) + 1
)
.
(8.19)
From Eqs. (8.17) and (8.19), it is clear to see that Rcp ‚â•Rsp because of two factors:
one is the nonnegative term in Eq. (8.18) and the other is Kcp ‚â•Ksp: a higher level
of differentiation implies a no smaller effective market. Let us further discuss them
in the following two cases:
‚Ä¢ If Kcp = Ksp, then the additional term of Eq. (8.18) in Eq. (8.17) means that
Rcp ‚â•Rsp. The equality holds if and only if Kcp = 1, in which case g(Kcp) = 0.
Note that in this case, the CP scheme degenerates to the SP scheme. We name
the nonnegative term g(Kcp) in Eq. (8.18) as price differentiation gain, as it
measures the average price difference between any effective users in the CP
scheme. The larger the price difference, the larger the gain. When there is no
differentiation in the degenerating case (Kcp = 1), the gain is zero.
‚Ä¢ If Kcp > Ksp, because the common part of two revenue Neff (K)
(
s(K)ùúÉ(K)
s(K)+1
)
=
SùúÉNeff (K)
S+Neff (K) is a strictly increasing function of Neff (K), price differentiation makes
more revenue even if the positive differentiation gain g(Kcp) is not taken into
consideration. The result that more consumers with purchasing power always
mean more revenue in the service provider‚Äôs pocket is intuitive.
Finally, we note that the CP scheme in Section 8.3 requires the complete network
information. The SP scheme here, on the other hand, works in the incomplete infor-
mation case as well. This distinction becomes important in Section 8.6.

PARTIAL PRICE DIFFERENTIATION UNDER COMPLETE INFORMATION
209
8.5
PARTIAL PRICE DIFFERENTIATION UNDER COMPLETE
INFORMATION
For a service provider facing thousands of user types, it is often impractical to
design a price choice for each user type. The reasons behind this, as discussed
in Reference [10], are mainly high system overheads and customers‚Äô aversion.
However, as we have shown in Section 8.4, the single pricing scheme may suffer a
considerable revenue loss. How to achieve a good trade-off between the implemen-
tational complexity and the total revenue? In reality, we usually see that the service
provider offers only a few pricing plans for the entire users population; we term it
as the partial price differentiation scheme. In this section, we answer the following
question: if the service provider is constrained to maintain a limited number of
prices, p1, ‚Ä¶ , pJ, J ‚â§I, then what is the optimal pricing strategy and the maximum
revenue? Concretely, the partial price differentiation (PP) problem is formulated as
follows.
PP ‚à∂maximize
ni,pi,si,pj,aj
i
‚àë
i‚àà‚Ñê
nipisi
subject to si =
(ùúÉi
pi
‚àí1
)+
, ‚àÄi ‚àà‚Ñê,
(8.20)
ni ‚àà{0, ‚Ä¶ , Ni}, ‚àÄi ‚àà‚Ñê,
(8.21)
‚àë
i‚àà‚Ñê
nisi ‚â§S,
(8.22)
pi =
‚àë
j‚ààùí•
aj
ipj,
(8.23)
‚àë
j‚ààùí•
aj
i = 1, aj
i ‚àà{0, 1}, ‚àÄi ‚àà‚Ñê.
(8.24)
Here ùí•denotes the set {1, 2, ‚Ä¶ , J}. As we consider the complete information sce-
nario in this section, the service provider can choose the price charged to each group,
thus constraints (8.20)‚Äì(8.22) are the same as in the CP problem. Constraints (8.23)
and (8.24) mean that pi charged to each group i is one of J choices from the set
{pj, j ‚ààùí•}. For convenience, we define cluster ùíûj Œî= {i | aj
i = 1}, j ‚ààùí•, which is a
set of groups charged with the same price pj. We use superscript j to denote clusters
and subscript i to denote groups through this section. We term the binary variables
a
Œî= {aj
i, j ‚ààùí•, i ‚àà‚Ñê} as the partition, which determines which cluster each group
belongs to.
The PP problem is a combinatorial optimization problem and is more difficult
than the previous CP and SP problems. On the other hand, we notice that this PP
problem formulation includes the CP scheme (J = I) and the SP scheme scenario
(J = 1) as special cases. The insights we obtained from solving these two special
cases in Sections 8.3 and 8.4 will be helpful to solve the general PP problem.

210
USAGE-BASED PRICING DIFFERENTIATION
8.5.1
Three-Level Decomposition
To solve the PP problem, we decompose and tackle it in three levels. In the lowest
level 3, we determine the pricing and resource allocation for each cluster, given a
fixed partition and fixed resource allocation among clusters. In level 2, we compute
the optimal resource allocation among clusters, given a fixed partition. In level 1, we
optimize the partition among groups.
8.5.1.1
Level 3: Pricing and Resource Allocation in Each Cluster For a fix parti-
tion a and a cluster resource allocation s
Œî= {sj}j‚ààùí•, we focus the pricing and resource
allocation problems within each cluster ùíûj, j ‚ààùí•:
Level-3: maximize
ni,si,pj
‚àë
i‚ààCj
nipjsi
subject to
si =
(ùúÉi
pj ‚àí1
)+
,
‚àÄi ‚ààùíûj,
ni ‚â§Ni,
‚àÄi ‚ààùíûj,
‚àë
i‚ààùíûj
nisi ‚â§sj.
The level-3 subproblem coincides with the SP scheme discussed in Section 8.4,
because all groups within the same cluster ùíûj are charged with a single price pj. We
can then directly apply the results in Algorithm 8.2 to solve the level-3 problem. We
denote the effective market threshold2 for cluster ùíûj as Kj, which can be computed
in Algorithm 8.2. An illustrative example is shown in Figure 8.5, where the cluster
contains four groups (groups 4‚Äì7), and the effective market contains groups 4 and 5,
A cluster Cj 
Nonzero resource
Effective market
Zero resource
Willingness to pay decreases
Threshold (size) of effective
market Kj = 5
Group 4
Group 5
Group 6
Group 7
Figure 8.5
An illustrative example of level 3: the cluster contains four groups, group 4‚Äì7;
and the effective market contains groups 4 and 5, thus Kj = 5.
2Note that we do not assume that the effective market threshold equals to the number of effective groups, for
example, there are two effective groups in Figure 8.5, but threshold Kj = 5. Later we will prove that there
is unified threshold for the PP problem. Then by this result, the group index threshold actually coincides
with the number of effective groups.

PARTIAL PRICE DIFFERENTIATION UNDER COMPLETE INFORMATION
211
thus Kj = 5. The service provider obtains the following maximum revenue obtained
from cluster ùíûj:
Rj(sj, a) =
sj ‚àë
i‚ààCj, i‚â§Kj NiùúÉi
sj + ‚àë
i‚ààCj, i‚â§Kj Ni
.
(8.25)
8.5.1.2
Level 2: Resource Allocation among Clusters For a fix partition a, we
then consider the resource allocation among clusters.
Level 2: maximize
sj‚â•0
‚àë
j‚ààùí•
Rj(sj, a)
subject to
‚àë
j‚ààùí•
sj ‚â§S.
We will show in Section 8.5.2 that subproblems in level 2 and level 3 can be trans-
formed into a complete price differentiation problem under proper technique condi-
tions. Let us denote its optimal value as Rpp(a).
8.5.1.3
Level 1: Cluster Partition Finally, we solve the cluster partition problem.
Level-1: maximize
aj
i‚àà{0,1}
Rpp(a)
subject to
‚àë
j‚ààùí•
aj
i = 1, i ‚àà‚Ñê.
This partition problem is a combinatorial optimization problem. The size of its
feasible set is S(I, J) = 1
J!
‚àëJ
t=1(‚àí1)J+tC(J, t)tI, Stirling number of the second kind
[39, Chap.13], where C(J, t) is the binomial coefficient. Some numerical examples
are given in the third row of Table 8.1. If the number of prices J is given, the
feasible set size is exponential in the total number of groups I. For our problem,
however, it is possible to reduce the size of the feasible set by exploiting the
special problem structure. More specifically, the group indices in each cluster
should be consecutive at the optimum. This means that the size of the feasible set
is C(I ‚àí1, J ‚àí1) as shown in the last row of Table 8.1 and thus is much smaller
than S(I, J).
TABLE 8.1
Numerical Examples for Feasible Set Size of the Partition Problem in
Level 1
Number of Groups
I = 10
I = 100
I = 1000
Number of Prices
J = 2
J = 3
J = 2
J = 3
J = 2
S(I, J)
511
9330
6.33825 √ó 1029
8.58963 √ó 1046
5.35754 √ó 10300
C(I ‚àí1, J ‚àí1)
9
36
99
4851
999

212
USAGE-BASED PRICING DIFFERENTIATION
Level 3
Level 1
Level 1‚Ä≤
Kpp : pKpp <  Œ∏Kpp
Level 2
The CP scheme
The SP scheme
Level 2
Level 3
Cluster partition
Cluster partition
Equivalent
simplification
Resource allocation
among clusters
Pricing and resource
allocation
in each cluster
Figure 8.6
Decomposition and simplification of the general PP problem: The three-level
decomposition structure of the PP problem is shown in the left-hand side (LHS). After sim-
plifications in Sections 8.5.2 and 8.5.3, the problem will be reduced to structure in right-hand
side (RHS).
Next we discuss how to solve the three-level subproblems. A route map for the
whole solution process is given in Figure 8.6.
8.5.2
Solving Level 2 and Level 3
The optimal solution (8.25) of the level-3 problem can be equivalently written as
Rj(s, a) =
sj ‚àë
i‚ààCj, i‚â§Kj NiùúÉi
sj + ‚àë
i‚ààCj, i‚â§Kj Ni
(a)= sjNjùúÉj
sj + Nj ,
(8.26)
where
‚éß
‚é™
‚é™
‚é®
‚é™
‚é™‚é©
Nj =
‚àë
i‚ààCj, i‚â§Kj
Ni,
ùúÉj =
‚àë
i‚ààCj, i‚â§Kj
NiùúÉi
Nj .
(8.27)
The equality (a) in Eq. (8.26) means that each cluster ùíûj can be equivalently treated
as a group with Nj homogeneous users with the same willings to pay ùúÉj. We name
this equivalent group as a super group (SG). We summarize the above result as the
following lemma.
Lemma 8.1
For every cluster Cj and total resource sj, j ‚ààùí•, we can find an equiv-
alent SG that satisfies conditions in Eq. (8.27) and achieves the same revenue under
the SP scheme.

PARTIAL PRICE DIFFERENTIATION UNDER COMPLETE INFORMATION
213
Nonzero resource
Zero resource
Willingness to pay decreases
Kc : threshold for clusters
Group 1
Group 2
Group 3
Group 4
Group 5
Group 6
C1 (or SG1)
C2 (or SG2)
K1 : threshold in C1
K2 : threshold in C2
Figure 8.7
An example of coupling thresholds.
On the basis of Lemma 8.1, the level-2 and level-3 subproblems together can be
viewed as the CP problem for SGs. As a cluster and its SG from a one-to-one map-
ping, we will use the two words interchangeably in the sequel.
However, simply combining Theorems 8.1 and 8.2 to solve level-2 and level-3 sub-
problems for a fixed partition a can result in a very high complexity. This is because
the effective markets within each SG and between SGs are coupled together. An
illustrative example of this coupling effective market is shown in Figure 8.7, where
Kc is the threshold between clusters and has three possible positions (i.e., between
group 2 and group 3, between group 5 and group 6, or after group 6); and K1 and K2
are thresholds within cluster ùíû1 and ùíû2, which have two or three possible positions,
respectively. Thus, there are (2 √ó 3) √ó 3 = 18 possible thresholds possibilities in
total.
The key idea resolving this coupling issue is to show that the situation in Figure 8.7
cannot be an optimal solution of the PP problem. The results in Sections 8.3 and 8.4
show that there is a unified threshold at the optimum in both the CP and SP cases, for
example, Figure 8.2. Next we will show that a unified single threshold also exists in
the PP case.
Lemma 8.2
At any optimal solution of the PP scheme, the group indices of the
effective market is consecutive.
The proof of Lemma 8.2 can be found in Appendix 8.A.3. The intuition is that the
resource should be always allocated to high willingness to pay users at the optimum.
Thus, it is not possible to have Figure 8.7 at an optimal solution, where high willing-
ness to pay users in group 2 are allocated zero resource while low willingness to pay
users in group 3 are allocated positive resources.
On the basis of Lemma 8.2, we know that there is a unified effective market thresh-
old for the PP problem, denoted as Kpp. As all groups with indices larger than Kpp
make zero contribution to the revenue, we can ignore them and only consider the par-
tition problem for the first Kpp groups. Given a partition that divides the Kpp groups
into J clusters (SGs), we can apply the CP result in Section 8.3 to compute the optimal
revenue in the level 2 based on Theorem 8.1.

214
USAGE-BASED PRICING DIFFERENTIATION
Rpp(a) =
J‚àë
j=1
NjùúÉj ‚àí
(‚àëJ
j=1 Nj‚àö
ùúÉj
)2
S + ‚àëJ
j=1 Nj
=
Kpp
‚àë
i=1
NiùúÉi ‚àí
(‚àëJ
j=1 Nj‚àö
ùúÉj
)2
S + ‚àëKpp
i=1 Ni
,
(8.28)
8.5.3
Solving Level 1
8.5.3.1
With a Given Effective Market Threshold Kpp
On the basis of the previous
results, we first simplify the level-1 subproblem and prove the following theorem.
Theorem 8.3
For a given threshold Kpp, the optimal partition of the level-1 sub-
problem is the solution of the following optimization problem.
Level-1‚Ä≤minimize
aj
i,Nj,ùúÉj
‚àë
j‚ààùí•
Nj‚àö
ùúÉj
subject toNj =
‚àë
i‚ààùí¶pp
Niaj
i, j ‚ààùí•,
ùúÉj =
‚àë
i‚ààùí¶pp
Niaj
i
Nj ùúÉi j ‚ààùí•,
‚àë
j‚ààùí•
aj
i = 1, aj
i ‚àà{0, 1} , i ‚ààùí¶pp j‚ààùí•,
ùúÉKpp > pJ =
‚àö
ùúÉJ(a)ùúÜ(a),
(8.29)
where ùí¶pp Œî= {1, 2, ‚Ä¶ , Kpp}, ùúÉJ(a) is the value of average willingness to pay of the
Jth group for the partition a, and ùúÜ(a) =
( ‚àë
j‚ààùí•Nj‚àö
ùúÉj
S+‚àëKpp
i=1 Ni
)2
.
Proof: The objective function and the first three constraints in the level-1 subprob-
lem are easy to understand: if the effective market threshold Kpp is given, then the
objective function of the level-1 subproblem, maximizing Rpp in Eq. (8.28) over a, is
as simple as minimizing ‚àëJ
j=1 Nj‚àö
ùúÉj as the level-1 subproblem suggested; the first
three constraints are given by the definition of the partition.
Constraint (8.29) is the threshold condition that supports Eq. (8.28), which means
that the least willingness to pay users in the effective market has a positive demand. It
ensures that calculating the revenue by Eq. (8.28) is valid. Remember that the solution
of the CP problem of level 2 and level 3 is threshold based, and Lemma 8.2 indicates
that Eq. (8.29) is sufficient for that all groups with willingness larger than group Kpp
can have positive demands. Otherwise, we can construct another partition leading to

PARTIAL PRICE DIFFERENTIATION UNDER COMPLETE INFORMATION
215
a larger revenue (please refer to the proof of Lemma 8.2) or equivalently leading to a
less objective value of the level-1 subproblem. This leads to a contradiction.
‚óæ
The level-1 subproblem is still a combinatorial optimization problem with a large
feasible set of a (similar to the original level 1). The following result can help us to
reduce the size of the feasible set.
Theorem 8.4
For any effective market size Kpp and number of prices J, an optimal
partition of the PP problem involves consecutive group indices within clusters.
The proof of Theorem 8.4 is given in Appendix 8.A.4. We first prove that this
result is true for the level-1 subproblem without constraint (8.29) and further show
that this result will not be affected by Eq. (8.29). The intuition is that high willingness
to pay users should be allocated positive resources with priority. It implies that groups
with similar willingness to pays should be partitioned in the same cluster, instead of
several far away clusters. Or equivalently, the group indices within each cluster should
be consecutive.
We define ùíúas the set of all partitions with consecutive group indices within each
cluster, and v(a) = ‚àë
j‚ààùí•Nj‚àö
ùúÉj is the value of objective of the level-1 subproblem
for a partition a. Algorithm 8.3 finds the optimal solution of the level-1 subproblem.
The main idea for this algorithm is to enumerate every possible partition in set ùíú,
and then check whether the threshold condition (8.29) can be satisfied. The main part
of this algorithm is to enumerate all partitions in set ùíúof C(Kpp ‚àí1, J ‚àí1) feasible
partitions. Thus the complexity of Algorithm 8.3 is no more than ùí™((Kpp)J‚àí1).
Algorithm 8.3
Level-1(Kpp, J):
k ‚ÜêKpp, v‚àó‚Üê
‚àö‚àëk
i=1 Ni
‚àëk
i=1 NiùúÉi, a‚àó‚Üê0
for a ‚ààùíú
if ùúÉk >
‚àö
ùúÉJ(a)ùúÜ(a)
if v(a) < v‚àó
v‚àó‚Üêv(a), a‚àó‚Üêa
end if
end if
end for
return a‚àó
End pseudo-code.
8.5.3.2
Search the Optimal Effective Market Threshold Kpp
We know the optimal
market threshold Kpp is upper bounded, that is, Kpp ‚â§Kcp ‚â§I. Thus we can first run
Algorithm 8.1 to calculate the effective market size for the CP scheme Kcp. Then,
we search the optimal Kpp iteratively using Algorithm 8.3 as an inner loop. We start

216
USAGE-BASED PRICING DIFFERENTIATION
by letting Kpp = Kcp and run Algorithm 8.3. If there is no solution, we decrease Kpp
by one and run Algorithm 8.3 again. The algorithm will terminate once we find an
effective market threshold where Algorithm 8.3 has an optimal solution. Once the
optimal threshold and the partition of the clusters are determined, we can further run
Algorithm 8.1 to solve the joint optimal resource allocation and pricing scheme. The
pseudo-code is given in Algorithm 8.4 as follows.
Algorithm 8.4
Solving PPD
pi ‚ÜêùúÉi
(k, ùúÜ) ‚áêResource-Allocation-CP({Ni, ùúÉi}i‚àà‚Ñê,S),
a‚àó‚áêLevel-1(k,J)
while a‚àó== 0
k ‚Üêk ‚àí1
a‚àó‚áêLevel-1(k,J)
end while
for j ‚Üê1, ‚Ä¶ J
Nj ‚Üê‚àëk
i=1 Niaj
i, ùúÉj ‚Üê‚àëk
i=1
Niaj
i
Nj ùúÉi
end for
(k, ùúÜ) ‚áêResource-Allocation-CP({Nj, ùúÉj}i‚ààùí•, S)
for j ‚Üê1, , ‚Ä¶ J
pj ‚Üê
‚àö
ùúÉjùúÜ, sj ‚Üê
‚àö
ùúÉj
ùúÜ‚àí1
end for
for i ‚Üê1, ‚Ä¶ , k
pi ‚Üê‚àëJ
j=1 aj
i
‚àö
ùúÉjùúÜ
end for
return {pi}i‚àà‚Ñê
End pseudo-code.
In Algorithm 8.4, it invokes two functions: Resource-Allocation-CP ({NiùúÉi}i‚àà‚Ñê,
S) as described in Algorithm 8.1 and Level-1 (k, J) as in Algorithm 8.3.
The above analysis leads to the following theorem.
Theorem 8.5
The solution obtained by Algorithm 8.4 is optimal for the
PP problem.
Proof: It is clear that Algorithm 8.4 enumerates every possible value of the effective
market size for the PP problem Kpp, and for a given Kpp its inner loop Algorithm 8.3
enumerates every possible partition in set ùíú. Therefore, the result in Theorem 8.4
follows.
‚óæ

PRICE DIFFERENTIATION UNDER INCOMPLETE INFORMATION
217
Next we discuss the complexity of Algorithm 8.4. The complexity of Algo-
rithm 8.1 is ùí™(I), and we run it twice in Algorithm 8.4. The worst case complexity
of Algorithm 8.3 is ùí™(IJ‚àí1), and we run it no more than I ‚àíJ times. Thus the whole
complexity of Algorithm 8.4 is no more than ùí™(IJ), which is polynomial of I.
8.6
PRICE DIFFERENTIATION UNDER INCOMPLETE INFORMATION
In Sections 8.3‚Äì8.5, we discuss various pricing schemes with different implemen-
tational complexity level under complete information, the revenues of which can be
viewed as the benchmark of practical pricing designs. In this section, we further study
the incomplete information scenario, where the service provider does not know the
group association of each user. The challenge for pricing in this case is that the ser-
vice provider needs to provide the right incentive so that a group i user does not
want to pretend to be a user in a different group. It is clear that the CP scheme in
Section 8.3 and the PP scheme in Section 8.5 cannot be directly applied here. The
SP scheme in Section 8.4 is a special case, because it does not require the user-group
association information in the first place and thus can be applied in the incomplete
information scenario directly. On the other hand, we know that the SP scheme may
suffer a considerable revenue loss compared with the CP scheme. Thus it is natural
to ask whether it is possible to design an incentive-compatible differentiation scheme
under incomplete information. In this section, we design a quantity-based price menu
to incentivize users to make the right self-selection and to achieve the same maximum
revenue of the CP scheme under complete information with proper technical con-
ditions. We name it the incentive-compatible complete price (ICCP) differentiation
scheme.
In the ICCP scheme, the service provider publishes a quantity-based price menu,
which consists of several step functions of resource quantities. Users are allowed
to freely choose their quantities. The aim of this price menu is to make the users
self-differentiated, so that to mimic the same result (the same prices and resource allo-
cations) of the CP scheme under complete information. On the basis of Theorem 8.1,
there are only K (without confusion, we remove the superscript ‚Äúcp‚Äù to simplify the
notation) effective groups of users receiving nonzero resource allocations, thus there
are K steps of unit prices, p‚àó
1 > p‚àó
2 > ¬∑ ¬∑ ¬∑ > p‚àó
K in the price menu. These prices are
exactly the same optimal prices that the service provider would charge for K effec-
tive groups as in Theorem 8.1. Note that for the K + 1, ‚Ä¶ , I groups, all the prices in
the menu are too high for them, then they will still demand zero resource. The quan-
tity is divided into K intervals by K ‚àí1 thresholds, s1
th > s2
th > ¬∑ ¬∑ ¬∑ > sK‚àí1
th
. The ICCP
scheme can be specified as follows:
p(s) =
‚éß
‚é™
‚é®
‚é™‚é©
p‚àó
1
when s > s1
th
p‚àó
2
when s1
th ‚â•s > s2
th
‚ãÆ
p‚àó
K
when sK‚àí1
th
‚â•s > 0.
(8.30)
A four-group example is shown in Figure 8.8.

218
USAGE-BASED PRICING DIFFERENTIATION
Price
Resource
p4
‚àó
s4
‚àó
s3
‚àó
s2
‚àó
s1
‚àó
0
p1
‚àó
p2
‚àó
p3
‚àó
sth
3
sth
2
sth
1
Figure 8.8
A four-group example of the ICCP scheme, where the prices p‚àó
1 > p‚àó
2 > p‚àó
3 > p‚àó
4
are the same as the CP scheme. To mimic the same resource allocation as under the CP scheme,
one necessary (but not sufficient) condition is sj‚àí1
th ‚â•s‚àó
j for all j, where s‚àó
j is the optimal resource
allocation of the CP scheme.
Note that in contrast to the usual ‚Äúvolume discount,‚Äù here the price is nondecreas-
ing in quantity. This is motivated by the resource allocation in Theorem 8.1, in which
a user with a higher ùúÉi is charged a higher price for a larger resource allocation. Thus
the observable quantity can be viewed as an indication of the unobservable users‚Äô
willingness to pay and helps to realize price differentiation under incomplete infor-
mation.
The key challenge in the ICCP scheme is to properly set the quantity thresholds so
that users are perfectly segmented through self-differentiation. This is, however, not
always possible. Next we derive the necessary and sufficient conditions to guarantee
the perfect segmentation.
Let us first study the self-selection problem between two groups: group i and group
q with i < q. Later on, we will generalize the results to multiple groups. Here group
i has a higher willingness to pay and will be charged with a higher price p‚àó
i in the
CP case. The incentive-compatible constraint is that a high willingness to pay user
cannot get more surplus by pretending to be a low willingness to pay user, that is,
max
s
Ui(s; p‚àó
i ) ‚â•max
s
Ui(s; p‚àó
q), where Ui(s; p) = ùúÉi ln(1 + s) ‚àíps is the surplus of a
group i user when it is charged with price p.
Without confusion, we still use s‚àó
i to denote the optimal resource allocation under
the optimal prices in Theorem 8.1, that is, s‚àó
i = arg max
si‚â•0 Ui(si; p‚àó
i ). We define si‚Üíq as
the quantity satisfying
{ Ui(si‚Üíq; p‚àó
q) = Ui(s‚àó
i ; p‚àó
i )
si‚Üíq < s‚àó
i
.
(8.31)
In other words, when a group i user is charged with a lower price p‚àó
q and demands
resource quantity si‚Üíq, it achieves the same as the maximum surplus under the optimal
price of the CP scheme p‚àó
i , as showed in Figure 8.9. As there are two solutions of the
first equation of Eq. (8.31), we constraint si‚Üíq to be the one that is smaller than s‚àó
i .

PRICE DIFFERENTIATION UNDER INCOMPLETE INFORMATION
219
si
s‚àó
i
q
1
2
3
4
1
2
3
4
Surplus
Œ∏iln(1 + s)‚Äìp‚àó
qs
Œ∏iln(1 + s)‚Äìp‚àó
is
Resource
Figure 8.9
When the threshold sq‚àí1
th
< si‚Üíq, the group i user cannot obtain U(s‚àó
i , p‚àó
i ) if it
chooses the lower price pq at a quantity less than sq‚àí1
th . Therefore, it will automatically choose
the high price p‚àó
i to maximize its surplus.
To maintain the group i users‚Äô incentive to choose the higher price p‚àó
i instead of
p‚àó
q, we must have sq‚àí1
th
‚â§si‚Üíq, which means a group i user cannot obtain Ui(s‚àó
i , p‚àó
i ) if
it chooses a quantity less than sq‚àí1
th . In other words, it will automatically choose the
higher (and the desirable) price p‚àó
i to maximize its surplus. On the other hand, we
must have sq‚àí1
th
‚â•s‚àó
q in order to maintain the optimal resource allocation and allow a
group q user to choose the right quantity-price combination (illustrated in Fig. 8.8).
Therefore, it is clear that the necessary and sufficient condition that the ICCP
scheme under incomplete information achieves the same maximum revenue of the
CP scheme under complete information is
s‚àó
q ‚â§si‚Üíq, ‚àÄi < q, ‚àÄq ‚àà{2, ‚Ä¶ , K}.
(8.32)
By solving these inequalities, we can obtain the following theorem (detailed proof in
Appendix 8.A.5).
Theorem 8.6
There exist unique thresholds {t1, ‚Ä¶ ,tK‚àí1}, such that the ICCP
scheme achieves the same maximum revenue as in the complete information case if
‚àö
ùúÉq
ùúÉq+1
‚â•tq
for q=1, ‚Ä¶ , K ‚àí1.
Moreover, tq is the unique solution of the equation
t2 ln t ‚àí(t2 ‚àí1) +
t ‚àëq
k=1 Nk + Nq+1
S + ‚àëKcp
k=1 Nk
(t ‚àí1) = 0
over the domain t > 1.

220
USAGE-BASED PRICING DIFFERENTIATION
We want to mention that the condition in Theorem 8.6 is necessary and sufficient
for the case of K = 2 effective groups.3 For K > 2, Theorem 8.6 is sufficient but not
necessary. The intuition of Theorem 8.6 is that users need to be sufficiently different
to achieve the maximum revenue.
The following result immediately follows Theorem 8.6.
Corollary 8.1
The tqs in Theorem 8.6 satisfy tq < troot for q = 1, ‚Ä¶ , K ‚àí1, where
troot ‚âà2.21846 is the larger root of equation t2 ln t ‚àí(t2 ‚àí1) = 0.
The Corollary 8.1 means that the users do not need to be extremely different to
achieve the maximum revenue.
When the conditions in Theorem 8.6 are not satisfied, there may be revenue loss
by using the pricing menu in Eq. (8.30). As it is difficult to explicitly solve the param-
eterized transcend equation (8.31), we are not able to characterize the loss in a closed
form yet.
8.6.1
Extensions to Partial Price Differentiation under Incomplete
Information
For any given system parameters, we can numerically check whether a partial price
differentiation scheme can achieve the same maximum revenue under both the com-
plete and incomplete information scenarios. The idea is similar as we described in this
section. As the PP problem can be viewed as the CP problem for all effective SGs,
then we can check the ICCP bound in Theorem 8.6 for SGs (once the SG partition is
determined by the searching using Algorithm 8.4). Deriving an analytical sufficient
condition (as in Theorem 8.6) for an incentive-compatible partial price differentiation
scheme, however, is highly nontrivial and is part of our future study.
8.7
CONNECTIONS WITH THE CLASSICAL PRICE
DIFFERENTIATION TAXONOMY
In economics, price differentiation is often categorized by the first/second/third-degree
price differentiation taxonomy [40]. This taxonomy is often used in the context of
unlimited resources and general pricing functions. The proposed schemes in this
chapter have several key differences from these standard concepts, mainly because
of the assumption of limited total resources and the choice of linear usage-based
pricing.
In the first-degree price differentiation, each user is charged a price based on its
willingness to pay. Such a scheme is also called the perfect price differentiation, as it
captures users‚Äô entire surpluses (i.e., leaving users with zero payoffs). For the com-
plete price differentiation scheme under complete information in Section 8.3, the
service provider does not extract all surpluses from users, mainly because of the
choice of linear price functions. All effective users obtain positive payoffs.
3There might be other groups who are not allocated positive resource under the optimal pricing.

NUMERICAL RESULTS
221
In the second-degree price differentiation, prices are set according to quantities
sold (e.g., the volume discount). The pricing scheme under incomplete information
in Section 8.6 has a similar flavor of quantity-based charging. However, our pro-
posed pricing scheme charges a higher unit price for a larger quantity purchase,
which is opposite to the usual practice of volume discount. This is due to our moti-
vation of mimicking the optimal pricing differentiation scheme under the complete
information. Our focus is to characterize the sufficient conditions, under which the
revenue loss owing to incomplete information (also called information rent [14, 41])
is zero.
In the third-degree price differentiation, prices are set according to some customer
segmentation. The segmentation is usually made based on users‚Äô certain attributes
such as ages, occupations, and genders. The partial price differentiation scheme in
Section 8.5 is analogous to the third-degree price differentiation, but here the user
segmentation is still based on users‚Äô willingness to pay. The motivation of our scheme
is to reduce the implementational complexity.
8.8
NUMERICAL RESULTS
We provide numerical examples to quantitatively study several key properties of price
differentiation strategies in this section.
8.8.1
When is Price Differentiation Most Beneficial?
Definition 8.1
(Revenue gain) We define the revenue gain G of one pricing scheme
as the ratio of the revenue difference (between this pricing scheme and the single
pricing scheme) normalized by the revenue of single pricing scheme.
In this subsection, we study the revenue gain of the CP scheme, that is,
G(N, ùúΩ, S)
Œî=
Rcp‚àíRsp
Rsp
, where N
Œî= {Ni, ‚àÄi ‚àà‚Ñê} denotes the number of users in
each groups, ùúΩ
Œî= {ùúÉi, ‚àÄi ‚àà‚Ñê} denotes their willingness to pays, and S is the total
resource. Notice that this gain is the maximum possible differentiation gain among
all PP schemes.
We first study a simple two-group case. According to Theorems 8.1 and 8.2, the
revenue under the SP scheme and the CP scheme can be calculated as follows:
Rsp =
‚éß
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™‚é©
S(N1ùúÉ1 + N2ùúÉ2)
N1 + N2 + S ,
1 ‚â§t <
‚àö
S + N1
N1
;
SN1ùúÉ1
N1 + S,
t ‚â•
‚àö
S + N1
N1
;

222
USAGE-BASED PRICING DIFFERENTIATION
and
Rcp =
‚éß
‚é™
‚é™
‚é®
‚é™
‚é™‚é©
S(N1ùúÉ1 + N2ùúÉ2) + N1N2(
‚àö
ùúÉ1 ‚àí
‚àö
ùúÉ2)2
N1 + N2 + S
,
1 ‚â§t < S + N1
N1
;
SN1ùúÉ1
N1 + S,
t ‚â•S + N1
N1
;
where t =
‚àöùúÉ1
ùúÉ2 > 1.
The revenue gain will depend on five parameters, S, N1, ùúÉ1, N2, and ùúÉ2. To simplify
notations, let N = N1 + N2 be the total number of the users, ùõº= N1
N the percentage of
group 1 users, and s = S
N the level of normalized available resource. Thus the revenue
gain can be expressed as
G(t, ùõº, s) =
‚éß
‚é™
‚é™
‚é®
‚é™
‚é™‚é©
ùõº(1 ‚àíùõº)(t ‚àí1)2
s(1 + ùõº(t2 ‚àí1)) ,
1 < t <
‚àö
s + ùõº
ùõº
;
(1 ‚àíùõº)(s + ùõº‚àítùõº)2
ùõºs(1 + s)t2
,
‚àö
s + ùõº
ùõº
‚â§t ‚â§s + ùõº
ùõº
.
(8.33)
Next we discuss the impact of each parameter.
Observation 8.1
In terms of the parameter t, G monotonically increases
in
(
1,
‚àö
s+ùõº
ùõº
)
and decreases in
[‚àö
k+ùõº
ùõº, k+ùõº
ùõº
)
. The maximum is obtained at
tG‚àímax =
‚àö
k+ùõº
ùõº, when the resource allocated to the group 2 user just becomes zero
in the SP scheme.
One example is showed in Figure 8.10.
It is clear that the revenue gain is not monotonic in the willingness to pay ratio.
Its behavior can be divided into three regions: the increasing Region (1) with t ‚àà
(
1,
‚àö
s+ùõº
ùõº
)
, the decreasing Region (2) with t ‚àà
[‚àö
k+ùõº
ùõº, k+ùõº
ùõº
)
, and the zero Region
(3) with t ‚â•k+ùõº
ùõº.
It is also interesting to note that three regions are closed related to the effective
market sizes: Ksp = Kcp = 2 in Region (1); Ksp = 1 and Kcp = 2 in Region (2); and
Kcp = Ksp = 1 in Region (3) where the CP scheme degenerates to the SP scheme. The
peak point of the revenue gain correspond to the place where the effective market of
the SP Scheme changes.
Intuitively, the CP scheme increases the revenue by charging the high willingness
groups with high prices, thus the revenue gain increases first when the difference of
willingness to pays increase. However, when the difference of willingness to pay is
very large, the CP scheme obtains most revenue from the high willingness to pay

NUMERICAL RESULTS
223
5
10
15
20
25
0.1
0.2
0.3
0.4
0.5
t
(1)
(2)
(3)
G(t,0.01,0.2)
Figure 8.10
One example of the revenue gain G(t, 0.01, 0.2) for the CP scheme. It is clear
that the revenue gain can be divided into three regions. Region (1), increasing region, where
Kcp = Ksp = 2 and the revenue gain comes from the differentiation gain. Region (2), decreasing
region, where Kcp = 2, Ksp = 1, and the revenue gain comes from larger effective market and
differentiation gain. Region (3), zero region, where Kcp = Ksp = 1 and is a degenerating case
where two pricing scheme coincide.
users, while the SP scheme declines the low willingness to pay users but serves the
high willingness to pays only. Both schemes lead to similar resource allocation in this
region, and thus the revenue gain decreases as the difference of willingness to pays
increases.
Figure 8.10 shows the revenue gain under usage-based pricing can be very high
in some scenario, for example, over 50% in this example. We can define this peak
revenue gain as
Gmax(ùõº, s)=max
t‚â•1 G(t, ùõº, s)=
(ùõº‚àí1)(
‚àö
s+ùõº‚àí
‚àö
ùõº)2
s(1 + s)
.
Figure 8.11 is shown how Gmax changes in s with different parameters ùõº.
Observation 8.2
For a fixed s, Gmax(ùõº, s) monotonically decreases in ùõº.
When ùõºis small, which means high willingness to pay users are minorities in
the effective market, the advantage of price differentiation is very evident. As shown
in Figure 8.11, when ùõº= 0.1, the maximum possible revenue gain can be over than
20%; and when ùõº= 0.01, this gain can be even higher than 50%. However, when high
willingness to pay users are majority, the price differentiation gain is very limited, for
example, the gain is no larger than 8% and 2% for ùõº= 0.5 and 0.9, respectively.
Intuitively, high willingness to pay users is the most profitable users in the market.
Ignoring them is detrimental in terms of revenue even if they only occupy a small
fraction of the population. As the SP scheme is set based on the average willingness
to pay of the effective market, the high willingness to pay users will be ignored (in the

224
USAGE-BASED PRICING DIFFERENTIATION
20
40
60
80
100
0.1
0.2
0.3
0.4
0.5
1
2
3
4
5
0.1
0.2
0.3
0.4
0.5
s
s
Gmax(Œ±, s)
Gmax(Œ±, s)
Œ±=0.01
Œ±=0.1
Œ±=0.5
Œ±=0.9
Figure 8.11
For a fixed s, Gmax(ùõº, s) monotonically increases in ùõº. For a fixed ùõº, Gmax(ùõº, s)
first increases in s and then decreases in s.
sense of not charging the desirable high price) when ùõºis small. In contrast, ignoring
the low willingness to pay users when ùõºis large is not a big issue.
Observation 8.3
For parameter k, Gmax(ùõº, s) is not a monotonic function in s. Its
shape looks like a skewed bell. The gain is small when s is either very small or very
large.
Small s means that resource is very limited, and both schemes allocates the
resource to high willingness to pay users (see the discussion of the threshold
structure in Sections 8.3 and 8.4), and thus there is not much difference between two
pricing schemes. While s is very large, that is, the resource is abundant, the prices
and the resource allocation with or without differentiation become similar (which
can be easily checked from formulations in Theorems 8.1 and 8.2). In these two
scenarios, similar resource allocations lead to similar revenues. These explains the
bell shape for parameter s.
We find that the revenue gain can be very high under two conditions based on
the above observations. First, the high willingness to pay users is minorities in the
effective market. Second, the total resource is comparatively limited.
For cases with three or more groups, the analytical study becomes much more chal-
lenging because of many more parameters. Moreover, the complex threshold structure
of the effective market makes the problem even complicated. We will present some
numerical studies to illustrate some interesting insights.
For illustration convenience, we choose a three-group example and three different
sets of parameters as shown in Table 8.2. To limit the dimension of the problem, we
set the parameters such that the total number of users and the average willingness

NUMERICAL RESULTS
225
TABLE 8.2
Parameter Settings of a Three-Group Example
ùúÉ1
N1
ùúÉ2
N2
ùúÉ3
N3
ùúÉ
Case 1
9
10
3
10
1
80
2
Case 2
3
33
2
33
1
34
2
Case 3
2.2
80
1.5
10
1
10
2
200
400
600
800
1000
0.05
0.10
0.15
G(Œ∏, N, S)
0
20
40
60
80
100
0
20
40
60
80
100
with same average willingness to pay 
N1 N2 N3
N1 N2 N3
0
20
40
60
80
100
N1 N2 N3
Case 1
Case 2
Case 3
S
Figure 8.12
An example of the revenue gain of the three-group market with the same average
willingness to pay.
to pay (i.e., ùúÉ= ‚àë3
i=1 NiùúÉi‚àï(‚àë3
i=1 Ni)) of all users are the same across three differ-
ent parameter settings. This ensures that the SP scheme achieves the same revenue
in three different cases when resource is abundant. Figure 8.12 illustrates how the
differentiation gain changing changes in resource S.
Similar to the analytical study of the two-group case, Figure 8.12 shows that the
revenue gain is large only when the high willingness to pay users are minorities (e.g.,
case 1) in the effective market and the resource is limited but not too small (100 ‚â§S ‚â§
150 in all three cases). When resource S is large enough (e.g., ‚â•150), the gain will
gradually diminish to zero as the resource increases. For each curve in Figure 8.12,
there are two peak points. Each peak point represents a change of the effective market
threshold in the SP scheme, that is, when the resource allocation to a group becomes
zero. In numerical studies of networks with I > 3 groups (not shown in this chapter),
we have observed the similar conditions for achieving a large differentiation gain and
the phenomenon of I ‚àí1 peak points.

226
USAGE-BASED PRICING DIFFERENTIATION
8.8.2
What is the Best Trade-Off of Partial Price Differentiation?
In Section 8.5, we design Algorithm 8.4 that optimally solves the PP problem with a
polynomial complexity. Here we study the trade-off between total revenue and imple-
mentational complexity.
To illustrate the trade-off, we consider a five-group example with parameters
shown in Table 8.3. Note that high willingness to pay users is minorities here.
Figure 8.13 shows the revenue gain G as a function of total resource S under different
PP schemes (including CP scheme as a special case), and Figure 8.14 shows how
the effective market thresholds change with the total resource.
We enlarge Figures 8.13 and 8.14 within the range of S ‚àà[0, 50], which is the most
complex and interesting part because of several peak points. Similar to Figure 8.12,
we observe I ‚àí1 = 4 peak points for each curve in Figure 8.13. Each peak point again
represents a change of effective market threshold of the single pricing scheme, as we
can easily verify by comparing Figure 8.14 with Figure 8.13.
As the resource S increases from 0, all gains in Figure 8.13 first overlap with each
other, then the two-price scheme separates from the others at S = 3.41, after that the
three-price scheme separates at S = 8.89, and finally the four-price scheme separates
at near S = 20.84. These phenomena are due to the threshold structure of the PP
TABLE 8.3
Parameter Setting of a Five-Group Example
Group Index i
1
2
3
4
5
ùúÉi
16
8
4
2
1
Ni
2
3
5
10
80
10
20
30
40
50
0.02
0.04
0.06
0.08
0.10
0.12
0.14
100
200
300
400
500
0.05
0.10
0.15
0.20
S
S
Complete price differentiation
(Five prices)
Four prices
Three prices
Two prices
G
G
Figure 8.13
Revenue gain of a five-group example under different price differentiation
schemes.

CONCLUSION
227
10
20
30
40
50
2
3
4
5
100
200
300
400
500
2
3
4
5
Threshold of the effective market
S
S
21
22
23
24
25
3.5
4.0
4.5
5.0
S
Two prices
Three prices
Four prices
Five prices
Single price
Single price
Figure 8.14
Corresponding thresholds of effective markets of Figure 8.13‚Äôs Example.
scheme. When the resource is very limited, the effective markets under all pricing
scheme include only one group with the highest willingness to pay and all pric-
ing schemes coincide with the SP scheme. As the resource increases, the effective
market enlarges from two groups to finally five groups. The change of the effective
market threshold can be directly observed in Figure 8.14. Comparing across differ-
ent curves in Figure 8.14, we find that the effective market size is nondecreasing
with the number of prices for the same resource S. This agrees with our intuition
in Section 8.4.2, which states that the size of effective market indicates the degree of
differentiation.
Figure 8.13 provides the service provider a global picture of choosing the most
proper pricing scheme according to achieve the desirable financial target under a
certain parameter setting. For example, if the total resource S = 100, the two-price
scheme seems to be a sweet spot, as it achieves a differential gain of 14.8% compared
to the SP scheme and is only 2.4% worser than the CP scheme with five prices.
8.9
CONCLUSION
In this chapter, we study the revenue-maximizing problem for a monopoly service
provider under both complete and incomplete network information. Under complete
information, our focus is to investigate the trade-off between the total revenue
and the implementational complexity (measured in the number of pricing choices
available for users). Among the three pricing differentiation schemes we proposed
(i.e., complete, single, and partial), the partial price differentiation is the most
general one and includes the other two as special cases. By exploiting the unique
problem structure, we designed an algorithm that computes the optimal partial
pricing scheme in polynomial time and numerically quantizes the trade-off between

228
USAGE-BASED PRICING DIFFERENTIATION
implementational complexity and total revenue. Under incomplete information,
designing an incentive-compatible differentiation pricing scheme is difficult in
general. We show that when the users are significantly different, it is possible to
design a quantity-based pricing scheme that achieves the same maximum revenue as
under complete information.
APPENDIX 8.A
8.A.1
COMPLETE PRICE DIFFERENTIATION UNDER COMPLETE
INFORMATION WITH GENERAL UTILITY FUNCTIONS
In this section, we extend the solution of complete price differentiation problem to
general form of increasing and concave utility functions ui(si). We denote Ri(si) as
the revenue collected from one user in group i. On the basis of the Stackelberg model,
the prices satisfy pi = u‚Ä≤
i(si), si ‚â•0 i ‚àà‚Ñê, thus
Ri(si) = u‚Ä≤
i(si)si, si ‚â•0.
(8.A.1)
Therefore, we can rewrite the complete price differentiation problem with general
utility function (CPG) as follows.
CPG ‚à∂maximize
s‚â•0,n
‚àë
i‚àà‚Ñê
niRi(si)
subject to ni ‚àà{0, ‚Ä¶ , Ni} , i ‚àà‚Ñê.
(8.A.2)
‚àë
i‚àà‚Ñê
nisi ‚â§S
(8.A.3)
By similar solving technique in Section 8.3, we can solve CPG Problem by decom-
posing it into two subproblems: resource allocation subproblem CPG1 and admission
control subproblem CPG2. In subproblem CPG1, for given n, we solve
CPG1 ‚à∂maximize
s‚â•0
‚àë
i‚àà‚Ñê
niRi(si)
subject to
‚àë
i‚àà‚Ñê
nisi ‚â§S.
After solving the optimal resource allocation s‚àó
i (n), i ‚àà‚Ñê, we further solve admis-
sion control subproblem:
CPG2 ‚à∂maximize
n
‚àë
i‚àà‚Ñê
niRi(s‚àó
i (n))
subject to ‚à∂ni ‚àà{0, ‚Ä¶ , Ni}.
We are especially interested in the case that constraint (8.A.3) is active in
CPG Problem, which means the resource bound is tight in the considered problem;

COMPLETE PRICE DIFFERENTIATION
229
otherwise, CPG problem degenerates to a revenue maximization without any
bounded resource constraint. We can prove the following results.
Proposition 8.A.1
If the resource constraint (8.A.3) is active in the optimal solu-
tion of the CPG problem (or CPG1 Subproblem), then one of optimal solutions of
CPG2 Subproblem is
n‚àó
i = Ni, i ‚àà‚Ñê.
(8.A.4)
Proof: We first release the variable ni to real number and calculate the first derivative
as follows:
ùúïRi
ùúïni
= Ri(s‚àó
i ) + ni
ùúïRi(s‚àó
i )
ùúïsi
ùúïs‚àó
i
ùúïni
, i ‚àà‚Ñê.
(8.A.5)
Plugging Eq. (8.A.1), R‚Ä≤
i(si) = u‚Ä≤‚Ä≤
i (si) si + u‚Ä≤
i(si), and we have
ùúïRi
ùúïni
= u‚Ä≤
i(s‚àó
i )
(
s‚àó
i + ni
ùúïs‚àó
i
ùúïni
)
+ ni u‚Ä≤‚Ä≤
i (s‚àó
i ) s‚àó
i
ùúïs‚àó
i
ùúïni
, i ‚àà‚Ñê.
(8.A.6)
As the resource constraint (8.A.3) is active in the optimal solution of
CPG1 subproblem, that is, ‚àë
i‚àà‚Ñê
nisi = S, by taking derivative of ni in both sides of it,
we have
s‚àó
i + ni
ùúïs‚àó
i
ùúïni
= 0.
(8.A.7)
Substituting Eq. (8.A.7) into Eq. (8.A.6), because we assume the utility function
ui(si) is increasing and concave function, then we have
ùúïRi
ùúïni
= ‚àíu‚Ä≤‚Ä≤
i (s‚àó
i ) s‚àó
i
2 ‚â•0, i ‚ààùí¶.
(8.A.8)
Thus we can conclude that one of optimal solutions for CPG2 subproblem is n‚àó
i =
Ni, i ‚àà‚Ñê.
‚óæ
Proposition 8.A.1 points out that when the resource constraint (8.A.3) is active,
the CPG problem can be greatly simplified: its solution can be obtained by solv-
ing CPG subproblem with parameters ni = Ni, i = 1, ‚Ä¶ , I. The following proposition
provides a sufficient condition that the resource constraint (8.A.3) is active.
Proposition 8.A.2
If u‚Ä≤‚Ä≤
i (si)si + ui(si) > 0, si ‚â•0, i ‚àà‚Ñê, then the resource con-
straint is active at the optimal solution.
Proof:
Let ùúÜand ùúái, i ‚àà‚Ñê, be the Lagrange multiplier of constraint (8.A.3) and
si ‚â•0, i ‚àà‚Ñê, respectively, thus the KKT conditions of CGP1 subproblem is given
as follows:

230
USAGE-BASED PRICING DIFFERENTIATION
ni
ùúïRi(s‚àó
i )
ùúïsi
‚àíniùúÜ‚àó+ ùúá‚àó
i = 0, i ‚àà‚Ñê;
ùúÜ‚àó
(
‚àë
i‚àà‚Ñê
nis‚àó
i ‚àíS
)
= 0;
ùúá‚àó
i s‚àó
i = 0;
ùúÜ‚àó‚â•0;
ùúá‚àó
i ‚â•0, i ‚àà‚Ñê;
s‚àó
i ‚â•0, i ‚àà‚Ñê.
We denote ùí¶‚à∂= {i | s‚àó
i > 0} and ùí¶‚à∂= {i | s‚àó
i = 0}.
For i ‚ààùí¶,
ùúïRi(s‚àó
i )
ùúïsi
= ùúÜ‚àó, i ‚àà‚Ñê;
(8.A.9)
ùúÜ‚àó
(
‚àë
i‚ààùí¶
nis‚àó
i ‚àíS
)
= 0.
(8.A.10)
For i ‚ààùí¶,
ùúïRi(0)
ùúïsi
‚â§ùúÜ‚àó, i ‚àà‚Ñê;
(8.A.11)
As u‚Ä≤‚Ä≤
i (si)si + ui(si) > 0, si ‚â•0, i ‚àà‚Ñêand Eq. (8.A.9), we have
ùúÜ‚àó=
ùúïRi(s‚àó
i )
ùúïsi
= u‚Ä≤‚Ä≤
i (s‚àó
i )s‚àó
i + ui(s‚àó
i ) > 0.
By Eq. (8.A.10), we must have ‚àë
i‚àà‚Ñênis‚àó
i ‚àíS = 0, that the resource constraint is
active at the optimal solution.
‚óæ
Next, let us discuss how to calculate the optimal solution. To guarantee uniqueness
resource allocation solution, we assume that the revenue is a strictly concave function
of the demand,4 that is, ùúï2Ri(si)
ùúïs2
i
< 0, i ‚àà‚Ñê. Thus we have the following theorem.
Theorem 8.A.1
If ùúï2Ri(si)
ùúïs2
i
< 0, i ‚àà‚Ñê, then there exists an optimal solution of
CGP problem as follows:
‚Ä¢ All users are admitted: n‚àó
i = Ni for all i ‚àà‚Ñê.
‚Ä¢ There exist a value ùúÜ‚àóand a group index threshold Kcp ‚â§I, such that only the
top Kcp groups of users receive positive resource allocations,
4This assumption has been frequently used in the revenue management literature [42].

COMPLETE PRICE DIFFERENTIATION
231
s‚àó
i =
‚éß
‚é™
‚é®
‚é™‚é©
ùúïRi
ùúïsi
‚àí1
(ùúÜ‚àó),
i ‚ààùí¶;
0,
otherwise,
(8.A.12)
where values of ùúÜ‚àóand effective market ùí¶can be computed as in Algorithm
8.A.1.
In Algorithm 8.A.1, we use notation f ‚àí1 denotes its inverse function and rearrange
the group index satisfying
ùúïR(1)
ùúïs(1)
‚àí1
(0) ‚â•
ùúïR(2)
ùúïs(2)
‚àí1
(0) ‚â•¬∑ ¬∑ ¬∑ ‚â•
ùúïR(I)
ùúïs(I)
‚àí1
(0).
Algorithm 8.A.1
Threshold-General-Utility
k ‚ÜêI, ùúÜ‚Üê
ùúïR(k)
ùúïs(k)
‚àí1
(0)
while
k‚àë
i=1
n(i)
(
ùúïR(i)
ùúïs(i)
‚àí1
(ùúÜ)
)+
‚â•S,
k ‚Üêk ‚àí1
ùúÜ‚Üê
ùúïR(k)
ùúïs(k)
‚àí1
(0)
end while
return ùí¶= {(1), (2), ‚Ä¶ , (k)}
End pseudo-code.
Remark 8.A.1
The complexity of Algorithm 8.A.1 is also ùí™(I), that is, linear in the
number of user groups (not the number of users).
Remark 8.A.2
There are several functions satisfying the technical conditions in
Theorem 8.A.1, for example, the standard ùõº-fairness functions
ui(si) =
‚éß
‚é™
‚é®
‚é™‚é©
(1 ‚àíùõº)‚àí1s1‚àíùõº
i
,
0 ‚â§ùõº< 1;
log si,
ùõº= 1.
8.A.2
PROOF OF PROPOSITION 8.1
Proof:
We first focus on the key water-filling problems that we solve for the two
pricing schemes (the CP scheme on the LHS and the SP scheme on the RHS):

232
USAGE-BASED PRICING DIFFERENTIATION
‚àë
i‚àà‚Ñê
Ni
(‚àö
ùúÉi
ùúÜ‚àó‚àí1
)+
= S =
‚àë
i‚àà‚Ñê
Ni
( ùúÉi
p‚àó‚àí1
)+
.
(8.A.13)
Let ùúÉ= p‚àó2
ùúÜ‚àóbe the solution of the equation of
‚àö
ùúÉ
ùúÜ‚àó= ùúÉ
p‚àó. By comparing it with ùúÉi,
i ‚àà‚Ñê, there are three cases:
‚Ä¢ Case 1.
ùúÉ> ùúÉ1 ‚áí
‚àö
ùúÉi
ùúÜ‚àó=
‚àö
ùúÉi
‚àö
ùúÉ
p‚àó
>
ùúÉi
p‚àó, ‚àÄi ‚àà‚Ñê.
This case cannot be possible. As if every term in the left summation is strictly
larger than its counterpart in the right summation, then Eq. (8.A.13) cannot hold.
‚Ä¢ Case 2. ùúÉI ‚â•ùúÉ‚áí
‚àö
ùúÉi
ùúÜ‚àó=
‚àö
ùúÉi
‚àö
ùúÉ
p‚àó
‚â§
ùúÉi
p‚àó, ‚àÄi ‚àà‚Ñê. Similar to Case 1, it can-
not hold, either.
‚Ä¢ Case 3. ‚àÉk, s.t. 1 ‚â§k < I and ùúÉk ‚â•ùúÉ‚â•ùúÉk+1
‚áí
‚éß
‚é™
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é™‚é©
‚àö
ùúÉi
ùúÜ‚àó=
‚àö
ùúÉi
‚àö
ùúÉ
p‚àó
‚â§ùúÉi
p‚àó, i = 1, 2, ‚Ä¶ , k;
‚èü‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èü‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èü
The equality holds only when ùúÉ= ùúÉk and i = k.
‚àö
ùúÉi
ùúÜ‚àó=
‚àö
ùúÉi
‚àö
ùúÉ
p‚àó
‚â•ùúÉi
p‚àó, i = k + 1, ‚Ä¶ , I.
‚èü‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èü‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èü
The equality holds only when ùúÉ= ùúÉk+1 and i = k + 1.
Similar argument as the above two case, we have Kcp ‚â•k and Ksp ‚â•k, oth-
erwise (8.A.13) can not hold. Further, Kcp ‚â•Ksp, since if ùúÉKsp
p‚àó‚àí1 > 0, then
‚àö
ùúÉKcp
ùúÜ‚àó‚àí1 > 0.
By Theorems 8.1 and 8.2, we prove the proposition.
‚óæ
8.A.3
PROOF OF LEMMA 8.2
We can first prove the following lemma.
Lemma 8.A.1
Suppose an effective market of the single pricing scheme is denoted
as ùí¶= {1, 2, ‚Ä¶ , K}. If we add a new group v of Nv users with ùúÉv > ùúÉK, then the
revenue strictly increases.
Proof: We denote the single price before joining group v is p, the price after joining
group v is p‚Ä≤, the effective market become ùí¶‚Ä≤. By Theorem 8.2, we have

COMPLETE PRICE DIFFERENTIATION
233
p =
‚àëK
i=1 NiùúÉi
S + ‚àëK
i=1 Ni
with ùúÉK > p and ùúÉK+1 ‚â§p.
As the optimal revenue is obtained by selling out the total resource S, thus to prove
that the total revenue strictly increases if and only if, we can prove p‚Ä≤ > p. We consider
the following two cases.
‚Ä¢ If after group v joining in, the new effective market satisfies ùí¶‚Ä≤ = ùí¶‚à™{v},
then we have
p‚Ä≤ =
‚àëK
i=1 NiùúÉi + NvùúÉv
S + ‚àëK
i=1 Ni + Nv
.
As ùúÉv > ùúÉK > p, we have p‚Ä≤ > p, because of the following simple fact.
Fact 8.A.1
For any a1, b1, a2, b2 > 0, the following two inequality are equiv-
alent:
a1
b1
‚â•a2
b2
‚áîa1
b1
‚â•a1 + a2
b1 + b2
‚â•a2
b2
.
(8.A.14)
‚Ä¢ If after group v joining in, the new effective market shrinks, namely, ùí¶‚Ä≤ ‚äÇùí¶‚à™
{v}, ùí¶‚Ä≤ ‚â†ùí¶‚à™{v}, then we have p‚Ä≤ > ùúÉK > p.
‚óæ
By the above Lemma 8.A.1, we further prove Lemma 8.2.
Proof: We prove Lemma 8.2 by contradiction. Suppose that the group indices of the
effective market under the optimal partition a is not consecutive. Suppose that group i
is not an effective group, and there exists some group j, j > i, which is an effective
group. We consider a new partition a‚Ä≤ by putting group i into the cluster to which
group j belongs and keeping other groups unchanged. According to Lemma 8.A.1,
the revenue under partition a‚Ä≤ is greater than that under partition a, thus partition a is
not optimal. This contradicts to our assumption and thus completes the proof.
‚óæ
8.A.4
PROOF OF THEOREM 8.4
For convenience, we use the notation (¬∑ ¬∑ ¬∑ ‚à™¬∑ ¬∑ ¬∑ | ¬∑ ¬∑ ¬∑ ‚à™¬∑ ¬∑ ¬∑ | ¬∑ ¬∑ ¬∑) to denote a partition
with the groups between bars connected with ‚Äú‚à™‚Äù representing a cluster, for example,
three partitions for J = 2, Kpp = 3 are (1|2 ‚à™3), (1 ‚à™2 | 3), and (1 ‚à™3 | 2). In addition,
we introduce the compound group to simplify the notation of complex clusters with
multiple groups. A cluster containing group i can be simply represented as Pre(i) ‚à™
i ‚à™Post(i), where Pre(i) (or Post(i)) refers as a compound group composing of all the
groups with willingness to pay larger (or smaller) than that of group i in the cluster.
Note that the compound groups can be empty in certain cases.
Before we prove the general case in Theorem 8.4, we first prove the results is true
for the following two special cases in Lemmas 8.A.2 and 8.A.3.

234
USAGE-BASED PRICING DIFFERENTIATION
Lemma 8.A.2
For a three-group effective market with two prices, that is, Kpp = 3,
J = 2, an optimal partition involves consecutive group indices within clusters.
Proof:
There are three partitions for Kpp = 3, J = 2, and only (1 ‚à™3 | 2) is with
discontinuous group index within clusters. To show our result, we only need to prove
one of partitions with group consecutive is better than (1 ‚à™3 | 2). We have two main
steps in this proof; first, we prove this result is true for PP problem without consider
constraint (8.29). Further, we show that constraint (8.29) will not affect the optimality
of partitions with consecutive group indices within each cluster.
Step 1: (Without Constraint (8.29))
Without considering constraint (8.29), we want to show that a1 = (1 ‚à™2 | 3) is
always better than a2 = (1 ‚à™3 | 2). Mathematically, what we try to prove is
v(a2) > v(a1),
(8.A.15)
where v(a2) = (N1 + N3)
‚àöN1ùúÉ1+N3ùúÉ3
N1+N3
+ N2
‚àö
ùúÉ2, and v(a1) = (N1 + N2)
‚àöN1ùúÉ1+N2ùúÉ2
N1+N2
+
N3
‚àö
ùúÉ3. With the new notation
ŒîV(i, j) ‚à∂= (Ni + Nj)
‚àö
NiùúÉi + NjùúÉj
Ni + Nj
‚àíNi
‚àö
ùúÉi ‚àíNj
‚àö
ùúÉj,
it is easy to see that (8.A.15) is equivalent to the following inequality:
ŒîV(1, 3) > ŒîV(1, 2).
(8.A.16)
We prove the inequality (8.A.16) by considering the following two cases.
(a) If N1 ‚â§N2, we define a function of x as follows,
g(j; x) ‚à∂= (Nj + N1)
‚àö
NjùúÉj + N1(ùúÉj + x)
Nj + N1
‚àíN1
‚àö
ùúÉj + x ‚àíNj
‚àö
ùúÉj.
It is easy to check that
g(j; x)|x=ùúÉ1‚àíùúÉj = ŒîV(1, j), and g(j; x)|x=0 = 0;
and if x > 0, then
g‚Ä≤(j; x) = ùúïg(j; x)
ùúïx
= N1
2
‚éõ
‚éú
‚éú
‚éú
‚éú‚éù
1
‚àö
NjùúÉj+N1(ùúÉj+x)
Nj+N1
‚àí
1
‚àöùúÉj + x
‚éû
‚éü
‚éü
‚éü
‚éü‚é†
> 0
and
ùúïg‚Ä≤(j; x)
ùúïùúÉj
= N1
4
‚éõ
‚éú
‚éú
‚éú
‚éú‚éù
1
(ùúÉj + x)1.5 ‚àí
1
(
NjùúÉj+N1(ùúÉj+x)
Nj+N1
)1.5
‚éû
‚éü
‚éü
‚éü
‚éü‚é†
< 0.

COMPLETE PRICE DIFFERENTIATION
235
As ùúÉ2 > ùúÉ3, it immediately follows that
g‚Ä≤(3; x) ‚â•N1
2
‚éõ
‚éú
‚éú
‚éú
‚éú‚éù
1
‚àö
N3ùúÉ2+N1(ùúÉ2+x)
N1+N3
‚àí
1
‚àö
ùúÉ2 + x
‚éû
‚éü
‚éü
‚éü
‚éü‚é†
.
As N2 ‚â•N1, then we have
g‚Ä≤(3; x) ‚â•N1
2
‚éõ
‚éú
‚éú
‚éú
‚éú‚éù
1
‚àö
N3ùúÉ2+N1(ùúÉ2+x)
N1+N3
‚àí
1
‚àö
ùúÉ2 + x
‚éû
‚éü
‚éü
‚éü
‚éü‚é†
‚â•g‚Ä≤(2; x).
Thus, it follows
ŒîV(1, 3) = ‚à´
ùúÉ1‚àíùúÉ3
0
g‚Ä≤(3; x)dx > ‚à´
ùúÉ1‚àíùúÉ2
0
g‚Ä≤(2; x)dx = ŒîV(1, 2),
that is, Eq. (8.A.16) is obtained.
Let us see a special case of Eq. (8.A.16). When N1 = N2, then
ŒîV(1, 2) = (N1 + N1)
‚àö
N1ùúÉ2 + N1ùúÉ1
N1 + N1
‚àíN1
‚àö
ùúÉ1 ‚àíN1
‚àö
ùúÉ2,
then we have
ŒîV(1, 3) > (N1 + N1)
‚àö
N1ùúÉ2 + N1ùúÉ1
N1 + N1
‚àíN1
‚àö
ùúÉ1 ‚àíN1
‚àö
ùúÉ2.
(8.A.17)
Notice that although Eq. (8.A.17) is defined with the assumption that N1 ‚â§N2, it also
holds for the case N1 > N2 as Eq. (8.A.17) does not contain the parameter N2. This
result will be used in the proof later.
(b) If N1 > N2, we define a function of m as
f(m) ‚à∂= (N1 + m)
‚àö
N1ùúÉ1 + mùúÉ2
N1 + m
‚àíN1
‚àö
ùúÉ1 ‚àím
‚àö
ùúÉ2.
It is easy to obtain that
df(m)
dm
=
(‚àö
N1ùúÉ1+mùúÉ2
N1+m
‚àí
‚àö
ùúÉ2
)2
2
‚àö
N1ùúÉ1+mùúÉ2
N1+m
> 0,

236
USAGE-BASED PRICING DIFFERENTIATION
that is, the function f is an increasing function of m.
Thus it follows that
ŒîV(1, 2) = f(N2) < f(N1)
(a)
< ŒîV(1, 3),
where (a) results from Eq. (8.A.17), the RHS of which is equal to f(N1).
Step 2: (Checking Constraint (8.29))
We want to prove that a1 satisfying constraint (8.29) is the sufficient condition of
a2 satisfying Eq. (8.29).
Consider if a1 does not satisfy Eq. (8.29), it means
‚àö
ùúÉ3 ‚â§
‚àö
ùúÜ(a1) =
‚àö
v(a1)
S + ‚àë3
i=1 Ni
.
By the result in Step 1, we know that v(a1) < v(a2), then we have
‚àö
ùúÉ3 <
‚àö
ùúÜ(a2) =
‚àö
v(a2)
S + ‚àë3
i=1 Ni
,
and further
ùúÉ3 <
‚àö
ùúÉ3ùúÜ(a2) <
‚àö
N3ùúÉ3 + N1ùúÉ1
N1 + N3
ùúÜ(a2) =
‚àö
ùúÉ1ùúÜ(a2).
It means a2 cannot satisfy Eq. (8.29) either. Thus we see that constraint (8.29) actually
does not affect the result in Step 1. In conclusion, we show that in a simple case
with Kpp = 3, J = 2, an optimal partition involves consecutive group indices within
clusters.
‚óæ
Further, based on Lemma 8.A.2, we prove another simple special case.
Lemma 8.A.3
For a four-group effective market with two prices, that is, Kpp = 4,
J = 2, an optimal partition involves consecutive group indices within clusters.
Proof:
For Kpp = 4 and J = 2 case, there are a total of seven possible partitions.
Three among them are with consecutive group index, (1 | 2 ‚à™3 ‚à™4), (1 ‚à™2 | 3 ‚à™4),
and (1 ‚à™2 ‚à™3 | 4). We denote a set composed by these three partitions as Œ£c. We need
to show the remaining four partitions are no better than some partition in Œ£c. To show
this, we only need to transform them to some three-group case and apply the result
of Lemma 8.A.2.
‚Ä¢ Case 1. (1 ‚à™4, 2 ‚à™3) is not optimal because we can prove (1 ‚à™2 ‚à™3, 4) ‚ààŒ£c is
better. To show that, we take 2 ‚à™3 as a whole, then by Lemma 8.A.2, it follows
that ŒîV(1, 4) > ŒîV(1, 2 ‚à™3).

COMPLETE PRICE DIFFERENTIATION
237
‚Ä¢ Case 2. (2, 1 ‚à™3 ‚à™4) is not optimal, because we can prove (1 ‚à™2, 3 ‚à™4) ‚ààŒ£c is
better. To show that, we take 3 ‚à™4 as a whole, then by Lemma 8.A.2, it follows
ŒîV(1, 3 ‚à™4) > ŒîV(1, 2).
‚Ä¢ Case 3. (3, 1 ‚à™2 ‚à™4) is not optimal, because we can prove (1 ‚à™2 ‚à™3, 4) ‚ààŒ£c is
better. To show that, we take 1 ‚à™2 as a whole, then by Lemma 8.A.2, it follows
that ŒîV(1 ‚à™2, 4) > ŒîV(1 ‚à™2, 3).
‚Ä¢ Case 4. (1 ‚à™3, 2 ‚à™4) is not optimal, because we can prove (1 ‚à™2 ‚à™3, 4) ‚ààŒ£c
is better. To show that, by Lemma 8.A.2, it follows that ŒîV(2, 4) > ŒîV(2, 3)
and that ŒîV(1, 3)
(b)
> ŒîV(1, 2 ‚à™3). Here inequality (b) is also easily obtained, if
we notice that ùúÉ1 > ùúÉ2‚à™3 > ùúÉ3, thus group 2 ‚à™3 can be also treated as the role
of group 2 in Lemma 8.A.2.
‚óæ
Now Let us prove Theorem 8.4. For convenience, we introduce the notation Com-
pound group, such as Pre(i) or Post(i), which represents some part of a cluster with
ordered group indices. For a group i in some cluster, Pre(i) (or Post(i)) refers to a com-
pound group composing of all the groups with willingness to pay larger (or smaller)
than that of group i. For example, in a cluster 1 ‚à™2 ‚à™3 ‚à™5 ‚à™7 ‚à™8, Pre(3) = 1 ‚à™2,
Post(3) = 5 ‚à™7 ‚à™8. Note that compound groups can be empty, denoted as ‚àÖ. In the
last example, Pre(1) = Post(8) = ‚àÖ. As all the groups within the compound group
belong to one cluster, we can apply Lemma 8.2. For example, with the previous
cluster setting, NPre(3) = N1 + N2, and ùúÉPre(3) = N1ùúÉ1+N2ùúÉ2
N1+N2
. By this equivalence rule, a
compound group actually has not much difference with one original group. The con-
clusions of Lemmas 8.A.2 and 8.A.3 can be easily extended to compound groups.
Proof:
Without the loss of generality, suppose that the group indices order within
each cluster is increasing.
Now consider one partition with discontinuous group indices within some clusters.
We can check the group indices continuity for every single group. For example, a
group c belonging to a cluster ùíû, and its next neighbor in this cluster is group d, if
c ‚àíd = 1, then the group indices until c are consecutive, and if c ‚àíd > 1, then the
group indices are discontinuous and we find a gap between c and d.
Suppose that checking group indices continuity for each group following the
increasing indices order (or equivalently decreasing willingness to pay order) from
group 1 to group Kpp. We do not find any gap until group u1 in cluster ùí∞. We denote
group u1 next neighbor in cluster ùí∞is group u2. As there is a gap between u1 and
u2, there exists a group v in another cluster ùí±and satisfying v = u1 + 1 < u2. Now
we can construct a better partition by rearranging the two clusters ùí∞and ùí±, while
keeping other clusters unchanged. We can view ùí∞as (Pre(u2) ‚à™Post(u1)), and ùí±as
(v ‚à™Post(v)), because there is no group before v in SG ùí±, otherwise it contradicts
with the fact that we do not find any gap until group u1. It is easy to show that there is
some new partition better than the original one by Lemmas 8.A.2 and 8.A.3. There
are two cases depending on whether Post(v) is empty or not. If Post(v) = ‚àÖ, according
to Lemma 8.A.2, we find another partition with ùí∞‚Ä≤ = Pre(u2) ‚à™v, ùí±‚Ä≤ = Post(u1)
better than the original ùí∞and ùí±. If Post(v) ‚â†‚àÖ, no matter ùúÉPost(v) is larger than

238
USAGE-BASED PRICING DIFFERENTIATION
ùúÉPost(u2) or not, according to Lemma 8.A.3, it is easy to construct other partitions
better than the original ùí∞and ùí±, because the compound groups in these original
clusters (ùí∞= (Pre(u2) ‚à™Post(u1)), and ùí±= (v ‚à™Post(v))) does not satisfy the
property of consecutive group indices within each cluster.
In conclusion, we show that for general cases, if there is any gap in the partition,
then we can construct another partition that is better, which is equivalent to that the
optimal partition must satisfy consecutive group indices within each cluster.
‚óæ
8.A.5
PROOF OF THEOREM 8.6
Proof:
As Ui(s, pq) is a strictly increasing function in the interval [0, s‚àó
i ], then Eq.
(8.32) holds, if and only if the following inequality holds:
Ui(s‚àó
q, pq) ‚â§Ui(si‚Üíq, pq), ‚àÄi < q.
(8.A.18)
As t1q > ¬∑ ¬∑ ¬∑ > tKq, Eq. (8.A.18) can be simplified to
t2
q‚àí1q ln tq‚àí1q ‚àí(t2
q‚àí1q ‚àí1) +
‚àëK
k=1 Nktkq
‚àëK
k=1 Nk + S
(tq‚àí1q ‚àí1) ‚â•0,
(8.A.19)
where tiq =
‚àö
ùúÉi
ùúÉq . With a slight abuse of notation, we abbreviate tq‚àí1q as tq, (q =
2, ‚Ä¶ , K) in the sequel. It is easy to see that the following inequality is the necessary
and sufficient condition of Eq. (8.A.19) for q = 2, and sufficient condition of Eq.
(8.A.19) for q > 2:
t2
q ln tq ‚àí(t2
q ‚àí1) +
tq
‚àëq‚àí1
k=1 Nk + Nq
‚àëK
k=1 Nk + S
(tq ‚àí1) ‚â•0.
(8.A.20)
Let g(t) be the LHS of the inequality (8.A.20). It is easy to check that g(t) is a convex
function, with g(1) = 0, g(‚àû) = ‚àûand g‚Ä≤(1) < 0. So there exists a root tq > 1. When
t > tq, the inequality (8.A.20) holds, thus Eq. (8.A.18) holds, and the conclusion in
Theorem 8.6 follows.
‚óæ
REFERENCES
1. S. Li, J. Huang, and S. Li. Revenue maximization for communication networks with
usage-based pricing. In Proceedings of the IEEE Global Telecommunications Conference,
pp. 1‚Äì6, 2009.
2. F. Kelly. Charging and rate control for elastic traffic. In European Transactions on
Telecommunications, 1997.

REFERENCES
239
3. F. Kelly, A. Maulloo, and D. Tan. ‚ÄúRate control for communication networks: shadow
prices, proportional fairness and stability,‚Äù Journal of the Operational Research Society,
49, 1998, 237‚Äì252.
4. S. Low and D. Lapsley. ‚ÄúOptimization flow control: basic algorithm and convergence,‚Äù
IEEE/ACM Transactions on Networking (TON), 7(6), 1999, 861‚Äì874.
5. S. Kunniyur and R. Srikant. ‚ÄúEnd-to-end congestion control schemes: utility functions,
random losses and ecn marks,‚Äù IEEE/ACM Transactions on Networking (TON), 11(5),
2003, 702.
6. M. Chiang, S. Low, A. Calderbank, and J. Doyle. ‚ÄúLayering as optimization decomposi-
tion: a mathematical theory of network architectures,‚Äù Proceedings of the IEEE, 95, 2007,
255‚Äì312.
7. M. Mussa and S. Rosen. ‚ÄúMonopoly and product quality,‚Äù Journal of Economic Theory,
18(2), 1978, 301‚Äì317.
8. E. Maskin and J. Riley. ‚ÄúMonopoly with incomplete information,‚Äù RAND Journal of Eco-
nomics, 15, 1984, 171‚Äì196.
9. S. Shakkottai, R. Srikant, A. Ozdaglar, and D. Acemoglu. ‚ÄúThe price of simplicity,‚Äù IEEE
Journal on Selected Areas in Communications, 26(7), 2008, 1269‚Äì1276.
10. V. Valancius, C. Lumezanu, N. Feamster, R. Johari, and V. Vazirani. ‚ÄúHow many tiers?
Pricing in the internet transit market,‚Äù SIGCOMM-Computer Communication Review,
41(4), 2011, 194.
11. D. Acemoglu, A. Ozdaglar, and R. Srikant. The marginal user principle for resource allo-
cation in wireless networks. In Proceedings of IEEE Conference on Decision and Control,
vol. 2, 2004, pp. 1544‚Äì1549.
12. R. Gibbens, R. Mason, and R. Steinberg. ‚ÄúInternet service classes under competition,‚Äù
IEEE Journal on Selected Areas in Communications, 18(12), 2000, 2490‚Äì2498.
13. John Cox ‚ÄúAT&T shifts to usage-based wireless data plan,‚Äù Network World Available
online:
http://www.networkworld.com/news/2010/060210-att-ends-unlimited-wireless-
offering.html?source=nww rss.
14. J.-J. Laffont and D. Martmort. The Theory of Incentives: The Principal Agent Modle.
Princeton University Press, Princeton, HJ, 2002.
15. J. Arrow. Collected Papers of Kenneth J. Arrow, Volume 4: The Economics of Information.
Harvard University Press, Cambridge, MA, 1984.
16. J. Tirole. The Theory of Industrial Organization. MIT Press, Cambridge, MA,
1988.
17. P. Bolton and M. Dewatripont. Contract Theory. MIT Press, Cambridge, MA, 2005.
18. N. Stokey. ‚ÄúIntertemporal price discrimination,‚Äù Quarterly Journal of Economics, 93(3),
1979, 355‚Äì371.
19. D. Baron and D. Besanko. ‚ÄúRegulation and information in a continuing relationship,‚Äù
Information Economics and Policy, 1(4), 1984, 267‚Äì302.
20. O. Hart and J. Tirole. ‚ÄúContract renegotiation and coasian dynamics,‚Äù Review of Economic
Studies, 55(4), 1988, 509‚Äì540.
21. A. Acquisti and H. Varian. ‚ÄúConditioning prices on purchase history,‚Äù Marketing Sciences,
24(3), 2005, 367‚Äì381.
22. M. Armstrong. ‚ÄúPrice discrimination by a many-product firm,‚Äù Review of Economic Stud-
ies, 66(1), 1999, 151‚Äì168.

240
USAGE-BASED PRICING DIFFERENTIATION
23. Y. Bakos and E. Brynjolfsson. ‚ÄúBundling information goods: pricing, profits, and effi-
ciency,‚Äù Management Science, 45(12), 1999, 1613‚Äì1630.
24. X. Geng, M. Stinchcombe, and A. Winston. ‚ÄúBundling information goods of decreasing
value,‚Äù Magagement Science, 51(4), 2005, 662‚Äì667.
25. L. Cabral, D. Salant, and G. Woroch. ‚ÄúMonopoly pricing with network externalities,‚Äù Inter-
national Journal of Industrial Oranization, 17, 1999, 199‚Äì214.
26. M. Aoyagi. ‚ÄúCoordinating adoption decisions under externalities and incomplete informa-
tion,‚Äù Games and Economic Behavior, 77(1), 2013, 77‚Äì89.
27. B. Schwartz. The Paradox of Choice: Why More is Less. Harper Perennial, New York,
2005.
28. C. Chau, Q. Wang, and D. Chiu. On the viability of paris metro pricing for communication
and service networks. In Proceedings of IEEE INFOCOM, 2010, pp. 1‚Äì9.
29. A. Odlyzko. ‚ÄúParis metro pricing for the internet. In Proceedings of the 1st ACM Confer-
ence on Electronic Commerce, 1999, pp. 140‚Äì147.
30. T. Basar and R. Srikant. Revenue-maximizing pricing and capacity expansion in a
many-users regime. In Proceedings of IEEE INFOCOM, vol. 1, 2002, pp. 294‚Äì301.
31. H. Shen and T. Basar. ‚ÄúOptimal nonlinear pricing for a monopolistic network service
provider with complete and incomplete information,‚Äù IEEE Journal on Selected Areas
in Communications, 25(6), 2007, 1216‚Äì1223.
32. A. Daoud, T. Alpcan, S. Agarwal, and M. Alanyali. A stackelberg game for pricing uplink
power in wide-band cognitive radio networks. In Proceedings of IEEE Conference on
Decision and Control, 2008, pp. 1422‚Äì1427.
33. L. Jiang, S. Parekh, and J. Walrand. Time-dependent network pricing and bandwidth
trading. In Proceedings of IEEE Network Operations and Management Symposium Work-
shops, 2008, pp. 193‚Äì200.
34. P. Hande, M. Chiang, R. Calderbank, and J. Zhang. Pricing under constraints in access
networks: Revenue maximization and congestion management. In Proceedings of IEEE
INFOCOM, 2010.
35. S. Ha, S. Sen, C. Joe-Wong, Y. Im, and M. Chiang. Tube: time-dependent pricing for
mobile data. In Proceedings of ACM SIGCOMM, Helsinki, Finland, 2012.
36. L. He and J. Walrand. Pricing and revenue sharing strategies for internet service providers.
In Proceedings IEEE INFOCOM, vol. 1, 2005.
37. S. Shakkottai and R. Srikant. ‚ÄúEconomics of network pricing with multiple ISPs,‚Äù
IEEE/ACM Transactions on Networking (TON), 14(6), 2006, 1233‚Äì1245.
38. V. Gajic, J. Huang, and B. Rimoldi. Competition of wireless providers for atomic users:
equilibrium and social optimality. In Proceedings of 47th Allerton Conference on Com-
munication, Control, and Computing, Urbana-Champaign, IL, 2009.
39. J. van Lint and R. Wilson. A Course in Combinatorics. Cambridge University Press, 2001.
40. B. Pashigian. Price Theory and Applications. McGraw-Hill, New York, 1995.
41. A. Mas-Colell, M. Whinston, and J. Green. Microeconomic Theory. Oxford University
Press, 1995.
42. K. Talluri and G. Van Ryzin. The Theory and Practice of Revenue Management.
Springer-Verlag, 2005.

9
Telecommunication Pricing: Smart
Versus Dumb Pipes‚àó
ATANU LAHIRI
9.1
INTRODUCTION
Discriminatory pricing of telecommunication services today is reminiscent of prac-
tices that date back to the eighteenth century, when navigation tolls varied from one
cargo type to another‚Äîthe toll for a ton of sand was not the same as that for a ton
of timber [3]. Similarly, consumers of wireless services are now paying different
per-byte prices for traffic generated by different services, such as voice calls, SMS
(short message service) text messages, picture mails, and mobile Internet [2]. For
instance, if one assumes a data rate of 100 KB/min of voice, and 100 bytes per SMS
text, a price of 10 cents/min of voice turns out to be equivalent to $1/MB, whereas a
price of 20 cents per SMS text amounts to a whopping $2000/MB [1].
Such discriminatory pricing, particularly the pricing of text messages, has recently
come under tremendous opposition from consumers‚Äîto the extent that even the US
Senate felt compelled to examine its legality and economic impacts [4]. Experts testi-
fying at a hearing at the US Senate Judiciary Committee argued that the average price
of an SMS text message far exceeded the marginal cost of the wireless path [5], with
no apparent economic justifications. Even the Wall Street Journal, which is known for
its dislike for regulations on corporations, voiced opposition to such pricing, demand-
ing a system where all bytes would be treated as just bytes. Mossberg [6], in his
weekly column there,
‚ÄúWe need a wireless mobile device ecosystem that mirrors the PC/Internet ecosystem,
one where the consumers‚Äô purchase of network capacity is separate from their purchase
of the hardware and software they use on that network. It will take government action,
or some disruptive technology or business innovation, to get us there.‚Äù
‚àóThis chapter is motivated by recent articles on wireless pricing by Lahiri et al. [1, 2]. For the sake of
exposition, we use a different, but more elegant, model here.
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
241

242
TELECOMMUNICATION PRICING: SMART VERSUS DUMB PIPES
Carriers, on the other hand, have been vocal at the Senate hearing about their
support for discriminatory pricing. Some carriers even took additional steps towards
protecting their smart-pipe strategy; for instance, fearing that open platforms such as
Android‚Äîalong with its user-developed services that could not be tagged or metered
separately‚Äîwill disrupt discriminatory pricing, AT&T stayed away from them until
2010 [7].
The common wisdom is thus that dumb pipes work in favor of consumers and
smart pipes in favor of carriers. In this chapter, we put this wisdom to economic tests.
We will do so by comparing the two pricing regimes in terms of their impacts on prof-
its and welfare. In economic terms, the smart-pipe strategy means pricing different
services differently. For example, consider the following pricing by a national car-
rier: for voice calls, one can either choose a plan that costs $80 a month and includes
1000 min of call time or another that costs $60 a month but includes only 700 min.
Consumers can also purchase 300 text messages for a price of $5 a month, or 1000
text messages for $10 a month. Likewise, they can get limited access to the web for
$10 a month, or unlimited access for $15 a month. For each service, consumers thus
pick from a separate menu of plans.
In the case of dumb pipes, however, a carrier would simply price the traffic carried,
giving each consumer the right to allocate the purchased traffic between various ser-
vices according to his/her preferences. Thus, there is just one menu to choose from.
The dumb-pipe strategy is best characterized as quasi-bundling [8]‚Äîit is a way of
bundling several services into one common bundle, namely, ‚Äúbytes,‚Äù while leaving to
each consumer the task of determining his/her actual bundle composition. An astute
reader may immediately contrast this with conventional bundling that puts the seller
in charge of deciding the bundle composition [9]. We develop a two-stage model of
quasi-bundling in this chapter.
We will model the monopolist‚Äôs tariff design problem assuming that it faces a
heterogeneous market. The monopoly setting is relevant to telecommunications.
Although the wireless market in the United States has several major players, each
happens to possess substantial monopoly power. This is reflected in the fact that the
price charged for carrying a text message is often several hundred times the marginal
cost of carrying it. The close relationship of a carrier with handset manufacturers,
along with various other consumer lock-in mechanisms, contributes to such pricing
power. Further, while modeling the monopoly problem, we will ignore all over-limit
usage and revenues resulting from such usage; over-limit usage occurs when, for
example, a consumer who is on a 1000-min plan uses 1100 min in a month. As
explained by Masuda and Whang [10], this simplification is reasonable when a
consumer‚Äôs monthly usage is deterministic.
For the purpose of exposition, we will only consider settings in which the monop-
olist faces discrete consumer types and sells multiple services. When it sells smart
pipes, it offers a separate price schedule (or menu) for each service. Each schedule
consists of a number of plans, one aimed at each consumer type, and each plan pro-
vides a fixed amount of usage for a price. On the other hand, when the carrier sells
dumb pipes, it faces the task of designing only one price schedule to price traffic
consumption; each plan then provides a certain level of traffic usage for a price.

UNIFORM ORDERING
243
We will examine two models, each with two types of consumers. In the first model,
consumers differ primarily in their incomes and those with higher incomes are willing
to pay more for every service. In other words, consumer preferences are uniformly
ordered across services. In the second one, this ordering is not uniform, just as one
would expect when preferences are driven primarily by consumers‚Äô idiosyncratic
tastes: one segment of consumers is willing to pay more for certain services and the
other segment is willing to do the same for the rest.
For the two models mentioned earlier, uniform ordering and nonuniform order-
ing, we will compare all three surpluses‚Äîproducer, consumer, and social‚Äîunder
smart pipes with that under dumb pipes. We will show that the prevalent view regard-
ing the welfare impacts of smart and dumb pipes hold in certain circumstances, but
it does not in many others. In particular, we will identify circumstances in which
smart pipes surprisingly lead to a higher consumer surplus. A related finding is that
smart pipes can lead to a higher social surplus. Finally, we will discuss why the wis-
dom that smart pipes increase profits may not hold when consumer types are ordered
nonuniformly.
9.2
UNIFORM ORDERING
Consider a carrier serving a market with two types of consumers, indistinguishable
ex ante to the carrier. Let the consumer types be indexed by i, i = 1 or 2. Types 1
and 2 comprise fractions 1 ‚àíf and f, respectively, of the whole population. The firm
offers n different wireless services, which are indexed by j, j ‚àà{1, 2, ..., n}.
The value of a service to a consumer is taken to be of the form ùõºt1‚àíùúå
1‚àíùúå, where ùõºis
a constant, t is the amount of the service used (in bytes), and 0 < ùúå< 1. Value func-
tions of this form have the support of empiricists [11]. Besides, they have desirable
properties‚Äîthey are concave and also exhibit constant relative risk aversion [12]. In
our context, the parameter ùúåreflects the desire for diversity in use of services: a con-
sumer with a higher ùúåprefers allocating traffic more evenly between various services
than does a consumer with a lower ùúå. Following the paper on bundling by Armstrong
[13], we will assume hereafter that the total value of a set of services to a consumer
is the sum of their individual values:
Assumption 9.1
The reservation price of a type-i consumer using tj bytes on ser-
vice j is given by ‚àën
j=1 vij(tj), where v1j(t) = ùõºj
t1‚àíùúå
1‚àíùúåand v2j(t) = ùõºjùúÉj
t1‚àíùúå
1‚àíùúå, with ùõºj > 0
and ùúÉj > 0, ‚àÄj.
When the consumer types are uniformly ordered, we can assume without loss of
generality that ùúÉj ‚â•1, ‚àÄj. Thus, one consumer type, namely, type 2, gets an equal or
higher value from every service vis-√°-vis the other, namely, type 1. Such a scenario is
expected when type 2 has a substantially higher income vis-√°-vis type 1 and, there-
fore, is willing to pay more for every telecommunication service. In the next section,
we will examine the other scenario, in which consumer type 2 gets higher values from
some services, but consumer type 1 gets so from the rest.

244
TELECOMMUNICATION PRICING: SMART VERSUS DUMB PIPES
Smart pipe:
Carrier offers
a menu for
each service
Consumer chooses
from each menu
Dumb pipe:
Carrier offers
one menu to
price traffic
Consumer chooses
from the menu
Consumer allocates
purchased traffic
to different services
Figure 9.1
Timeline.
For the sake of clarity, we will assume a constant marginal cost throughout our
analysis. We will also normalize all fixed costs to zero as they are sunk for our pur-
poses.
Assumption 9.2
The carrier‚Äôs marginal cost is c dollars per byte of traffic.
The firm (i.e., the carrier) offers nonlinear price schedules consisting of plans of
the form (p, t), where p is the price charged for t bytes of usage. If the carrier employs
the smart-pipe strategy, it announces a separate price schedule for each service. When
using the dumb-pipe approach, it announces just one price schedule to price the total
traffic consumption (see Fig. 9.1).
9.2.1
Dumb Pipe
In the case of dumb pipes, the carrier offers a single schedule to price traffic. The
price schedule or menu consists of two plans here, (p1, t1) and (p2, t2), aimed at types
1 and 2, respectively. A consumer who purchases a plan has to decide on how much
to use for each service. For a type-i consumer, this allocation problem‚Äîassuming
that the consumer is allocating t bytes of traffic‚Äîis as follows:
max
tij‚â•0, ‚àën
j=1 tij‚â§t
n
‚àë
j=1
vij(tij).
Let the solution to the above problem be (t‚àó
ij(t), j ‚àà{1, 2, ..., n}), that is, t‚àó
ij(t) is the
traffic that a type-i consumer will allocate to service j when dividing t units of traffic
optimally between the n services. This solution can be found from
v‚Ä≤
ij(t‚àó
ij(t)) = v‚Ä≤
ik(t‚àó
ik(t)), ‚àÄj, k ‚àà{1, 2, ..., n}, and
n
‚àë
j=1
t‚àó
ij(t) = t.
(9.1)

UNIFORM ORDERING
245
Equation (9.1) is readily solved for the value functions described in Assumption 9.1.
For type-1 consumers, they are equivalent to the following equations.
( ùõºj
ùõºk
) 1
ùúå
=
t‚àó
1j(t)
t‚àó
1k(t), ‚àÄj, k ‚àà{1, 2, ..., n}, and
n
‚àë
j=1
t‚àó
1j(t) = t.
(9.2)
The solution for type-1 consumers is, therefore,
t‚àó
1j(t) =
(ùõºj
ùõº
) 1
ùúå
t, where ùõº=
( n
‚àë
j=1
ùõº
1
ùúå
j
)ùúå
.
(9.3)
Figure 9.2, which assumes a two-service scenario, shows the fractions of total traffic
that a type-1 consumer allocates to the two services.
When ùúåis small, each consumer allocates a greater percentage to the service that
he/she values more, which is the service with the higher ùõºparameter‚Äîservice 1 in the
example. When ùúåis large, his/her allocation becomes more even. Clearly, ùúåreflects
his/her affinity for diversity in use of services.
For type-2 consumers, Eq. (9.1) can be rewritten as
( ùõºjùúÉj
ùõºkùúÉk
) 1
ùúå
=
t‚àó
2j(t)
t‚àó
2k(t), ‚àÄj, k ‚àà{1, 2, ..., n}, and
n
‚àë
j=1
t‚àó
2j(t) = t.
(9.4)
0.2
0.2
0.4
0.4
0.6
0.6
0.8
0.8
1.0
1.0
Service 1
Service 2
Figure 9.2
Type-1 consumer‚Äôs traffic allocation for ùõº1 = 3 and ùõº2 = 2.

246
TELECOMMUNICATION PRICING: SMART VERSUS DUMB PIPES
The solution for type-2 consumers is, therefore, similar.
t‚àó
2j(t) =
(ùõºjùúÉj
ùõºùúÉ
) 1
ùúå
t, where ùúÉ=
‚éõ
‚éú
‚éú
‚éú‚éù
‚àën
j=1 ùõº
1
ùúå
j ùúÉ
1
ùúå
j
‚àën
j=1 ùõº
1
ùúå
j
‚éû
‚éü
‚éü
‚éü‚é†
ùúå
.
(9.5)
We can derive the maximum value or the reservation price for traffic of each con-
sumer type by substituting the optimal t‚àó
ij(t) values back into the respective value
functions. Let vi(t) denote the maximum value that a consumer of type i can derive
from optimally allocating t units of traffic to different services. Then
v1(t) =
n
‚àë
j=1
v1j(t‚àó
1j(t)) = ùõºt1‚àíùúå
1 ‚àíùúå,
v2(t) =
n
‚àë
j=1
v2j(t‚àó
2j(t)) = ùõºùúÉt1‚àíùúå
1 ‚àíùúå.
(9.6)
We now turn to the problem of designing a pricing menu consisting of two plans,
namely, (p1, t1) and (p2, t2). Although this appears difficult at first sight, comparing
Eq. (9.6) with Assumption 9.1, we can easily see that the problem of designing a
menu for traffic is, in fact, structurally no different from the problem of pricing any
one service. Further, ùúÉj ‚â•1, ‚àÄj, implies that ùúÉ‚â•1, which, in turn, means that type 2
is also the high type here just as it is in the case of any service.
Individual Rationality. A consumer will only purchase a plan that offers him/her a
nonnegative utility. The individual rationality constraints for types 1 and 2 are
v1(t1) ‚â•p1,
(IR1)
v2(t2) ‚â•p2.
(IR2)
Incentive Compatibility. Each consumer picks the plan that generates the highest
surplus for him/her. These constraints are
v1(t1) ‚àíp1 ‚â•v1(t2) ‚àíp2,
(IC1)
v2(t2) ‚àíp2 ‚â•v2(t1) ‚àíp1.
(IC2)
The carrier‚Äôs problem is to maximize the profit subject to the individual rationality
and incentive compatibility constraints above. Its profit, with the plans selected as
posited, is
(1 ‚àíf) (p1 ‚àíct1
) + f (p2 ‚àíct2
) .
There are three possible outcomes [14]: no one is served, only high type consumers
are served, or all are served. When only the high type (type 2) is served, the firm

UNIFORM ORDERING
247
extracts the entire surplus‚Äîthe price equals the reservation price of the high type.
When both types are served, the carrier‚Äôs profit is maximized when the low type is
indifferent between purchasing and not purchasing, and the high type, between pur-
chasing the plan aimed at the low type and its own plan. Hence, only the IR1 and IC2
constraints are binding. Using the IR1 and IC2 constraints to substitute for pi in terms
of vi, i = 1, 2, we can immediately reduce the firm‚Äôs problem to
max
t1,t2‚â•0 (1 ‚àíf) (v1(t1) ‚àíc t1
) + f (v2(t2) ‚àív2(t1) + v1(t1) ‚àíc t2
) .
Henceforth, we will refer to the optimal schedule‚Äîthe solution to the
second-degree discrimination problem‚Äîby {(pSB
1 ,tSB
1 ), (pSB
2 ,tSB
2 )}. The optimal
usages, along with the corresponding optimal profit and the consumer surplus for
each consumer type, are shown in Table 9.1.
The optimal prices can easily be obtained from the optimal usages and the fact
that IR1 and IC2 become equalities.
As a benchmark, the table also provides the first-best (FB) solution, the one the
carrier would use when it can identify each consumer‚Äôs type and accordingly charge
each a different price. Let us first compare usages for each consumer type. The usage
of traffic by the high type (type 2) is unaffected by the degree of discrimination‚Äîit
is always at a level where its marginal willingness to pay equals the marginal cost.
The same is not the case for the low type (type 1). If low type consumers make up
a small fraction of the population, that is, f ‚â•1‚àïùúÉ, the carrier will not serve them at
all. Even when the carrier serves them, it only serves them a quantity that is below
the FB level.
Lemma 9.1
The solution to the second-degree discrimination problem (the opti-
mal usage level for each consumer type) is continuous in f. The optimal profit and
consumer surplus are also continuous in f.
Proof: The optimal usage level for each consumer type, tSB
i
in Table 9.1, is contin-
uous at f = 1‚àïùúÉand, therefore, it is continuous everywhere in [0, 1]. Because vi(t) is
continuous in t and tSB
i
is continuous in f, the result follows immediately.
‚óæ
9.2.2
Smart Pipe
When using the smart-pipe strategy, the carrier offers a separate schedule for each of
the n services. The schedule for a service j consists of two plans, {(p1j,t1j), (p2j,t2j)},
one for each of the two consumer types. Note that this problem is separable across
services‚Äîthe firm can independently find the optimal nonlinear price schedule for
each service. When ùúÉj ‚â•1, the solution for service j will be the same as the one in
Table 9.1, except that ùõºand ùúÉwill need to be replaced by ùõºj and ùúÉj, respectively.
Henceforth, we are going to denote this optimal schedule for service j by {(pSB
1j ,tSB
1j ),
(pSB
2j ,tSB
2j )}.

TABLE 9.1
Optimal Menu for Pricing Traffic; ùúΩ‚â•1
Case
Usage
Profit
Consumer Surplus
First-Degree Discrimination
‚àÄf,
tFB
1
=
(ùõº
c
) 1
ùúå
ùúãFB
1
= (1 ‚àíf)ùúåc
‚àí1‚àíùúå
ùúåùõº
1
ùúå
1 ‚àíùúå
0
all served
tFB
2
=
(ùõºùúÉ
c
) 1
ùúå
ùúãFB
2
= fùúåc
‚àí1‚àíùúå
ùúå(ùõºùúÉ)
1
ùúå
1 ‚àíùúå
0
Second-Degree Discrimination
f < 1
ùúÉ,
tSB
1
= tFB
1
(1 ‚àífùúÉ
1 ‚àíf
) 1
ùúå
ùúãSB =
0
all served
tSB
2
= tFB
2
ùúãFB
1
(1 ‚àífùúÉ
1 ‚àíf
) 1
ùúå
+ ùúãFB
2
f(ùúÉ‚àí1)ùõº
1
ùúå
(1 ‚àíùúå)
( 1 ‚àífùúÉ
c(1 ‚àíf)
) 1‚àíùúå
ùúå
1
ùúÉ‚â§f, only
tSB
1
= 0
ùúãSB = ùúãFB
2
0
type 2 served
tSB
2
= tFB
2
0
248

UNIFORM ORDERING
249
9.2.3
Smart Pipe Versus Dumb Pipe
Without the loss of generality, we can assume that ùúÉn ‚â•ùúÉn‚àí1 ‚â•¬∑ ¬∑ ¬∑ ‚â•ùúÉ1 ‚â•1
so
that
1‚àïùúÉn ‚â§1‚àïùúÉn‚àí1 ‚â§¬∑ ¬∑ ¬∑ ‚â§1‚àïùúÉ1 ‚â§1.
This
ordering
also
implies
that
1‚àïùúÉn ‚â§1‚àïùúÉ‚â§1‚àïùúÉ1. When not all ùúÉj parameters are equal,1 the two pricing
strategies or regimes are equivalent only if the proportion of the high type is at an
extreme level, for example, when f ‚â•1‚àïùúÉ1. When f ‚â•1‚àïùúÉ1, under either regime
only type-2 consumers are served and their usage is at a level where the marginal cost
equals the marginal value. However, significant differences between the two pricing
regimes exist at all other values of f. For example, when 0 < f < 1‚àïùúÉn, all consumers
use all services regardless of the regime but their usage amounts differ; as a result,
profits and consumer surpluses differ. When 1‚àïùúÉn ‚â§f < 1‚àïùúÉ, the smart-pipe strategy
restricts certain services to type-2 consumers, while the dumb-pipe strategy makes
all services available to all consumers. When 1‚àïùúÉ‚â§f < 1‚àïùúÉ1, type-1 consumers are
not served at all in the case of dumb pipes; however, in the case of smart pipes, they
are served all services whose ùúÉj parameters are strictly less than ùúÉ.
Theorem 9.1
When the two consumer types are uniformly ordered, either smart
pipes or dumb pipes can result in a higher consumer surplus. In particular,
(a) Smart pipes result in a strictly higher consumer surplus at values of f satisfy-
ing 1‚àïùúÉ‚â§f < 1‚àïùúÉ1.
(b) There exists an f a such that smart pipes lead to a strictly a higher consumer
surplus at values of f satisfying f a < f < 1‚àïùúÉ. Therefore, smart pipes lead to
a higher consumer surplus at all f satisfying f a < f < 1‚àïùúÉ1.
(c) Smart pipes and dumb pipes are identical in terms of consumer welfare at
values of f satisfying f ‚â•1‚àïùúÉ1, as they both lead to a zero consumer surplus.
Proof: We will prove the three parts in order.
(a) The consumer surplus under dumb pipes is 0 if 1‚àïùúÉ‚â§f < 1. However, the
consumer surplus under smart pipes is strictly positive if 1‚àïùúÉ‚â§f < 1‚àïùúÉ1 (see
Table 9.1). Therefore, smart pipes lead to a strictly higher surplus at values of
f satisfying 1‚àïùúÉ‚â§f < 1‚àïùúÉ1.
(b) If f < 1‚àïùúÉn, the consumer surplus under dumb pipes is Œì(ùõº, ùúÉ, f), where
Œì(ùõº, ùúÉ, f) = ùõº
1
ùúåf(ùúÉ‚àí1)
(1 ‚àíùúå)
( 1 ‚àífùúÉ
c(1 ‚àíf)
) 1‚àíùúå
ùúå
.
It immediately follows that
ùúïŒì(ùõº, ùúÉ, 0)
ùúïf
= ùõº
1
ùúå(ùúÉ‚àí1)
(1 ‚àíùúå)c
‚àí
( 1‚àíùúå
ùúå
)
.
(P1)
1If ùúÉ1 = ùúÉ2 = ¬∑ ¬∑ ¬∑ = ùúÉn, each ùúÉj also equals ùúÉ, making the smart-pipe and dumb-pipe strategies equivalent.

250
TELECOMMUNICATION PRICING: SMART VERSUS DUMB PIPES
The consumer surplus under smart pipes is ‚àën
j=1 Œì(ùõºj, ùúÉj, f), and its derivative,
too, can be similarly expressed.
Let Œìd(f) denote the difference between the two surpluses, that is, Œìd(f) =
Œì(ùõº, ùúÉ, f) ‚àí‚àën
j=1 Œì(ùõºj, ùúÉj, f). We can now use the Holder‚Äôs Inequality to show
that ùúïŒìd(0)
ùúïf
> 0.
n
‚àë
j=1
ùõº
1
ùúå
j ùúÉj =
n
‚àë
j=1
(ùõºjùúÉj)
(
ùõº
1‚àíùúå
ùúå
j
)
<
( n
‚àë
j=1
ùõº
1
ùúå
j ùúÉ
1
ùúå
j
)ùúå( n
‚àë
j=1
ùõº
1
ùúå
j
)1‚àíùúå
=
(‚àën
j=1 ùõº
1
ùúå
j ùúÉ
1
ùúå
j
)ùúå
(‚àën
j=1 ùõº
1
ùúå
j
)ùúå
( n
‚àë
j=1
ùõº
1
ùúå
j
)
= ùúÉùõº
1
ùúå.
The inequality above is actually strict, because not all ùúÉj parameters are iden-
tical. It then immediately follows from (P1) that ùúïŒìd(0)
ùúïf
> 0. Further, Œìd(f) is
0 when f = 0, and by Lemma 9.1, it is also continuous in f. Therefore, there
must exist an f t ‚àà(0, 1‚àïùúÉ) such that Œìd(f) > 0 if 0 < f < f t, implying that
dumb pipes lead to a higher consumer surplus at small values of f. However,
according to part (a), Œìd(1‚àïùúÉ) < 0. Therefore, it follows from the Intermediate
Value Theorem that there must be at least one f ‚àà(f t, 1‚àïùúÉ) such that Œìd(f) = 0;
let us denote the largest of these f values by f a. This definition of f a implies
that smart pipes do lead to a higher consumer surplus at values of f satisfying
f a < f < 1‚àïùúÉ.
(c) The proof follows from the fact that only type 2 is served under the stated
condition.
‚óæ
One of the fascinating consequences of Theorem 9.1 is that the consumer surplus
can be higher under smart pipes. To see this clearly, consider the scenario in which the
monopolist sells two services, namely, 1 and 2, with ùúÉ2 > ùúÉ1 > 1. Depending on the
value of f, the fraction of high type consumers, the equilibrium usages obtained from
Table 9.1 is going to be in one of the four distinct regions, labeled U1, U2, U3, and U4
in Figure 9.3, with different equilibrium outcomes. In U1, where 0 < f < 1‚àïùúÉ2, both
types enjoy both services irrespective of the pricing strategy. However, in U2, where
1‚àïùúÉ2 ‚â§f < 1‚àïùúÉ, type 1 can no longer enjoy service 2 under smart pipes, but it still
enjoys both services under dumb pipes. Moving on to U3, where 1‚àïùúÉ‚â§f < 1‚àïùúÉ1,
type 1 continues to enjoy service 1 if the carrier employs the smart-pipe strategy,
although it gets fully shut out if the carrier implements dumb pipes. Finally, type 1
is fully shut out in U4, where 1‚àïùúÉ1 ‚â§f < 1, regardless of the pricing strategy. Note
that type 2, being the high type, enjoys all services in all regions.

UNIFORM ORDERING
251
f
0.1
0.2
0.3
0.4
0.8
0.2
1.0
0.6
0.4
Consumer surplus
U1
U2
U3
U4
f = fa
Figure 9.3
Consumer surplus comparison with uniformly ordered consumer types;
smart pipe (solid) versus dumb pipe (dashed); c = 1, ùúå= 0.5, ùõº1 = 1, ùõº2 = 0.5, ùúÉ1 = 1.2,
and ùúÉ2 = 3.
Figure 9.3 also depicts how the consumer surplus varies with the fraction of type-2
consumers across these regions. In region U3, the dumb-pipe strategy shuts out the
low type consumer, driving the consumer surplus to zero, but smart pipes still allow
the low type to use one of the two services, leading to a strictly positive consumer
surplus. More intriguingly, in parts of region U2, where both types are served both
services under dumb pipes, smart pipes lead to a higher consumer surplus despite
restricting the low type to only one service.
Let us now examine the intuition behind these apparently counterintuitive results.
As expected, the dumb-pipe approach favorably affects the consumer surplus in U1,
and in parts of U2, because it lets all consumers freely allocate the purchased traffic
between the two services. However, in U3 and in parts of U2, such pricing signifi-
cantly reduces the carrier‚Äôs incentive to serve the low type. Because the carrier is not
able to restrict the low type to only one service in these regions, serving the low type
adequately there requires ceding too large an information rent (i.e., surplus) to the
high type. On the other hand, the smart-pipe strategy allows the carrier to restrict ser-
vice 2 to the high type, creating more flexibilities to curb the information rent. Viewed
differently, when restricting one service to only one consumer type is no longer an
option, the carrier is forced to severely underserve the low type in order to control the
consumer surplus that goes to the high type. The net implication is that the prevalent
view held by consumers against smart pipes becomes inapplicable when the fraction
of the high type is moderate to large.
Let us now consider the impact of ùúå. Figure 9.4 illustrates how f a changes with
ùúå. Evidently, f a is lower at lower values of ùúå, that is, consumers find smart pipes
preferable over a wider range of values of f.

252
TELECOMMUNICATION PRICING: SMART VERSUS DUMB PIPES
0.1
0.2
0.3
0.4
0.5
0.6
0.2
0.3
0.4
0.5
fa
œÅ
Figure 9.4
f a versus ùúå; c = 1, ùõº1 = 1, ùõº2 = 0.5, ùúÉ1 = 1.2, and ùúÉ2 = 3.
This phenomenon can be explained as follows. Recall that ùúåindicates consumers‚Äô
desire for diversity in their use of services. When ùúåis close to 1, consumers want to
allocate traffic more evenly between services. On the other hand, when ùúåis close to
0, consumers benefit more by concentrating their usage on a few services. Hence, the
primary benefit of dumb pipes‚Äîthe freedom to allocate traffic between services‚Äîis
less valuable to consumers at lower values of ùúå.
Lemma 9.2
When the two consumer types are uniformly ordered, smart pipes result
in a strictly higher profit at values of f satisfying 0 < f < 1‚àïùúÉ1. The two profits are
equal at all other f.
Proof: The two profits equal if f ‚â•1‚àïùúÉ1, because only type-2 consumers are served
under either regime and the usage under either regime is at a level where the marginal
value equals the marginal cost. In other words, the two strategies lead to the same
equilibrium.
Moving on to the scenario in which 0 < f < 1‚àïùúÉ1, let tSB
1
and tSB
2
denote the equi-
librium usages for the dumb-pipe strategy. Let the corresponding optimal prices be
pSB
1 and pSB
2 . We have to allow the possibility that tSB
1
= 0.
We will now show that there exists a feasible solution under the smart-pipe regime,
which leads to the same levels of usage. Let us first construct the smart-pipe plans,
(p1j, t1j), for the low type consumer with the objective of completely extracting all
its surplus: if tSB
1
> 0, we will set t1j = t‚àó
1j(tSB
1 ) and p1j = v1j(t‚àó
1j(tSB
1 )). Additionally, if
tSB
1
= 0, we will set t1j = p1j = 0.
While designing the smart-pipe plans for the high type, (p2j, t2j), let us set t2j =
t‚àó
2j(tSB
2 ) and fix p2j so that the IC2 constraint becomes binding for all j, that is,
p2j = p1j + (v2j(t2j) ‚àív2j(t1j)).

UNIFORM ORDERING
253
Note that the revenue earned from the low type segment is the same under both
strategies, that is, ‚àën
j=1 p1j = pSB
1 . We can also show that the revenue earned from the
high type segment is at least as large as, that is, ‚àën
j=1 p2j ‚â•pSB
2 ,
n
‚àë
j=1
p2j =
n
‚àë
j=1
p1j +
n
‚àë
j=1
(v2j(t2j) ‚àív2j(t1j))
= pSB
1 +
n
‚àë
j=1
(v2j(t‚àó
2j(tSB
2 )) ‚àív2j(t‚àó
1j(tSB
1 )))
‚â•pSB
1 +
n
‚àë
j=1
(v2j(t‚àó
2j(tSB
2 )) ‚àív2j(t‚àó
2j(tSB
1 )))
= pSB
1 + (v2(tSB
2 ) ‚àív2(tSB
1 ))
= pSB
2 .
The last step in the derivation above involves exploiting the incentive compatibility
constraint for type 2. The second last step (the inequality step) follows from the fact
that consumers benefit more from allocating according to their own preferences than
they do from allocating according to those of the other type, that is,
n
‚àë
j=1
v2j(t‚àó
2j(tSB
1 )) ‚â•
n
‚àë
j=1
v2j(t‚àó
1j(tSB
1 )).
As a feasible solution results in an identical or higher profit for the carrier, from the
carrier‚Äôs perspective, smart pipes must be at least weakly superior to dumb pipes when
0 < f < 1‚àïùúÉ1. This superiority of smart pipes is, in fact, strict, because the feasible
solution designed above is clearly a suboptimal one.
‚óæ
We now turn to a comparison of the social surpluses. According to Lemma 9.2,
when consumers are uniformly ordered, the smart-pipe strategy is superior from the
carrier‚Äôs viewpoint. More interestingly, it suggests that smart pipes accomplish a
higher producer surplus even in regions in which it leads to a higher consumer surplus.
Therefore, in contrast to what consumer advocates believe, the smart-pipe strategy is
not a mechanism that merely transfers surplus from consumers to the carrier. As indi-
cated by the numerical example in Figure 9.5, discrimination can also lead to a higher
social surplus.
We now formally state the comparison of the social surpluses under the two strate-
gies as our next theorem.
Theorem 9.2
When the two consumer types are uniformly ordered, smart pipes
lead to both a strictly higher profit and a strictly higher consumer surplus at val-
ues of f satisfying f a < f < 1‚àïùúÉ1. Further, there exists an f s < f a such that smart

254
TELECOMMUNICATION PRICING: SMART VERSUS DUMB PIPES
0.2
0.4
0.6
0.8
1.0
f
1.5
2.0
2.5
3.0
3.5
Social surplus
U1
U2
U3
U4
f = fs
Figure 9.5
Social surplus comparison with uniformly ordered consumer types; smart pipe
(solid) versus dumb pipe (dashed); c = 1, ùúå= 0.5, ùõº1 = 1, ùõº2 = 0.5, ùúÉ1 = 1.2, and ùúÉ2 = 3.
pipes lead to a strictly higher social surplus at values of f satisfying f s < f ‚â§f a and,
consequently, at all f satisfying f s < f < 1‚àïùúÉ1.
Proof: Note that f a is as defined in Theorem 9.1. The first part follows immediately
from Theorem 9.1 and Lemma 9.2. The rest follows from Lemma 9.1: because the
difference between the social welfare under the two strategies is positive at f = f a
and the difference is continuous by Lemma 9.1, there must exist an f s < f a such that
smart pipes lead to a strictly higher social surplus when f s < f ‚â§f a.
‚óæ
The implication is obvious. If we impose a ban on the smart-pipe strategy, it can
quickly become a lose‚Äìlose proposition for both the carrier and consumers. Only in
U1, which is characterized by a few high income consumers and a large number of
low income consumers, the ban would work as expected, that is, it would lead to a
higher consumer surplus as well as a higher profit.
The existing literature on second-degree price discrimination also identifies
instances in which discrimination is preferable (to uniform pricing across consumer
classes) from the social planner‚Äôs viewpoint [15‚Äì17]. Similarly, the literature on
third-degree discrimination also finds instances in which the discrimination across
different consumer markets leads to a higher social surplus [18, 19]. In essence, we
are here examining discrimination across services (calling, messaging, etc.) that use
the same resource (traffic). Despite the difference in the nature of discrimination, the
intuition behind Theorem 9.2 is still very similar to what one finds in the existing
literature: when discrimination is not possible, the producer feels constrained;
in response, it reduces its output and forgoes certain consumer segments, which,
in turn, adversely affects social welfare. Clearly, our finding here has significant

NONUNIFORM ORDERING
255
policy implications for governments that are currently debating how to regulate the
telecommunication sector optimally from the societal perspective.
9.3
NONUNIFORM ORDERING
We now examine the other possible scenario, which is nonuniform ordering of con-
sumer types: one consumer type is the high type for services {1, 2, ..., m ‚àí1}, while
the other is the high type for services {m, m + 1, ..., n}. One expects such nonuniform
ordering when consumers‚Äô preferences depend more on their idiosyncratic tastes for
different services and less on their income differences. Let us assume that type 1
is the high type for services {1, 2, ..., m ‚àí1}, that is, ùúÉj < 1, ‚àÄj ‚àà{1, 2, ..., m ‚àí1},
and that type 2 is the high type for services {m, m + 1, ..., n}, that is, ùúÉj ‚â•1, ‚àÄj ‚àà
{m, m + 1, ..., n}. As before, without the loss of generality, we can assume that ùúÉn ‚â•
ùúÉn‚àí1 ‚â•¬∑ ¬∑ ¬∑ ‚â•ùúÉm ‚â•1 > ùúÉm‚àí1 ‚â•ùúÉm‚àí2 ‚â•¬∑ ¬∑ ¬∑ ‚â•ùúÉ1.
The pricing problem for the smart-pipe strategy is still identical to the problem dis-
cussed in Section 9.2 except that the roles of the two consumer types have now inter-
changed for services j ‚àà{1, 2, ..., m ‚àí1}. Therefore, the solution for services {m, m +
1, ..., n} would still be as mentioned earlier. The solutions for services {1, 2, ..., m ‚àí1}
would, however, be as shown in Table 9.2.
A material implication is that, in the case of smart pipes, type 1 will end up with
some surplus whenever type 2 is served any of the first (m ‚àí1) services. Recall that,
in the previous section, type 1 could never enjoy any surplus.
Note that, in the case of dumb pipes, either type-1 or type-2 consumers can be the
high type depending on the relative sizes of the ùõºj parameters. Without the loss of
generality, we will assume that type 2 is the high type in the case of dumb pipes, that
is, ùúÉ‚â•1. Therefore, the solution in the case of dumb pipes is also the same as that
discussed in the previous section.
9.3.1
Smart Pipe Versus Dumb Pipe Revisited
What is perhaps most interesting about nonuniform ordering is that discrimination no
longer guarantees a higher profit. Before we can discuss this outcome, the following
result is necessary:
Lemma 9.3
When the two consumer types are not uniformly ordered, smart pipes
lead to a strictly higher profit at values of f satisfying 1‚àïùúÉ‚â§f < 1.
Proof: Recall that ùõºand ùúÉare as given by Eqs. (9.3) and (9.5), respectively. When
f ‚â•1
ùúÉ, under dumb pipes, only the high type (type 2) is served. Therefore, the profit
is
fùúåc‚àí1‚àíùúå
ùúå(ùõºùúÉ)
1
ùúå
1 ‚àíùúå
=
fùúåc‚àí1‚àíùúå
ùúå‚àën
j=1(ùõºjùúÉj)
1
ùúå
1 ‚àíùúå
.
Henceforth, we will refer to the jth term of the sum above as the dumb-pipe profit
attributable to service j; thus the dumb-pipe profit attributable to service j is

TABLE 9.2
Optimal Menu for Service j; ùúΩj < 1
Case
Usage
Profit
Consumer Surplus
First-Degree Discrimination
‚àÄf,
tFB
1j =
(ùõºj
c
) 1
ùúå
ùúãFB
1j
=
(1 ‚àíf)ùúåc
‚àí1 ‚àíùúå
ùúå
ùõº
1
ùúå
j
1 ‚àíùúå
0
all served
tFB
2j =
(ùõºjùúÉj
c
) 1
ùúå
ùúãFB
2j
=
fùúåc
‚àí1 ‚àíùúå
ùúå
(ùõºjùúÉj)
1
ùúå
1 ‚àíùúå
0
Second-Degree Discrimination
1 ‚àíùúÉj < f,
tSB
1j = tFB
1j
ùúãSB
j
= ùúãFB
1j +
(1 ‚àíf)(1 ‚àíùúÉj)ùõº
1
ùúå
j
1 ‚àíùúå
(f ‚àí1 + ùúÉj
cf
) 1‚àíùúå
ùúå
all served
tSB
2j = tFB
2j
‚éõ
‚éú
‚éú
‚éú
‚éú‚éù
1 ‚àí
(1 ‚àíf
ùúÉj
)
f
‚éû
‚éü
‚éü
‚éü
‚éü‚é†
1
ùúå
ùúãFB
2j
‚éõ
‚éú
‚éú
‚éú
‚éú‚éù
1 ‚àí
(1 ‚àíf
ùúÉj
)
f
‚éû
‚éü
‚éü
‚éü
‚éü‚é†
1
ùúå
0
f ‚â§1 ‚àíùúÉj, only
tSB
1j
= tFB
1j
ùúãSB
j
= ùúãFB
1j
0
type 1 served
tSB
2j = 0
0
256

NONUNIFORM ORDERING
257
fùúåc‚àí1‚àíùúå
ùúå(ùõºjùúÉj)
1
ùúå
1 ‚àíùúå
.
Under smart pipes, the total profit from services {m, m + 1, ..., n} is at least what the
carrier gets by serving the high type alone. As type 2 is the high type for {m, m +
1, ..., n}, the profit from these services is at least
fùúåc‚àí1‚àíùúå
ùúå‚àën
j=m(ùõºjùúÉj)
1
ùúå
1 ‚àíùúå
.
This last expression is identical to the sum of the profits attributable to services
{m, m + 1, ..., n} under dumb pipes.
Now consider services {1, 2, ..., m ‚àí1}, that is, the ones for which type 1 is the
high type. We are going to partition this set of services into two subsets and show
that, for each set, smart pipes lead to a strictly higher profit. First, consider the subset
of these services that are served to type 1 only. Let us call this subset J1; note that
f ‚â§1 ‚àíùúÉj, ‚àÄj ‚ààJ1. The total profit under smart pipes from these services is
(1 ‚àíf)ùúåc‚àí1‚àíùúå
ùúå‚àë
j‚ààJ1 ùõº
1
ùúå
j
1 ‚àíùúå
.
For each j ‚ààJ1, fùúÉ
1
ùúå
j < ùúÉ
1
ùúå
j < ùúÉj ‚â§(1 ‚àíf), as 0 < ùúÉj, ùúå< 1, and f ‚â§1 ‚àíùúÉj. Rearrang-
ing the terms, we get (1 ‚àíf) > fùúÉ
1
ùúå
j , implying that the smart-pipe profit from service
j is indeed higher than that attributable to it under dumb pipes.
Now, consider the subset J2 of {1, 2, ..., m ‚àí1}, which consists of services offered
to both types. Note that f > 1 ‚àíùúÉj, ‚àÄj ‚ààJ2. The total profit under smart pipes
attributable to J2 is
‚àë
j‚ààJ2
ùúåc‚àí1‚àíùúå
ùúåùõº
1
ùúå
j
1 ‚àíùúå
‚éõ
‚éú
‚éú‚éù
(1 ‚àíf) + f
(f ‚àí1 + ùúÉj
f
) 1
ùúå‚éû
‚éü
‚éü‚é†
.
When f ‚â•1‚àïùúÉ, the difference between this profit and that under dumb pipes from J2
is
‚àë
j‚ààJ2
ùúåc‚àí1‚àíùúå
ùúåùõº
1
ùúå
j
1 ‚àíùúå
‚éõ
‚éú
‚éú‚éù
(1 ‚àíf) + f
‚éõ
‚éú
‚éú‚éù
(f ‚àí1 + ùúÉj
f
) 1
ùúå
‚àíùúÉ
1
ùúå
j
‚éû
‚éü
‚éü‚é†
‚éû
‚éü
‚éü‚é†
.
Each term in the sum above is 0 when f = 1. Further, when 1 ‚àíùúÉj ‚â§f < 1, the deriva-
tive of the jth term with respect to f is

258
TELECOMMUNICATION PRICING: SMART VERSUS DUMB PIPES
ùúåc‚àí1‚àíùúå
ùúåùõº
1
ùúå
j
1 ‚àíùúå
‚éõ
‚éú
‚éú
‚éú
‚éú‚éù
‚àí(1 + ùúÉ
1
ùúå
j ) +
( f‚àí1+ùúÉj
f
) 1‚àíùúå
ùúå(1 ‚àíùúÉj + (f + ùúÉj ‚àí1)ùúå)
fùúå
‚éû
‚éü
‚éü
‚éü
‚éü‚é†
.
The second derivative with respect to f is
ùúåc‚àí1‚àíùúå
ùúåùõº
1
ùúå
j
1 ‚àíùúå
‚éõ
‚éú
‚éú
‚éú
‚éú‚éù
(1 ‚àíùúÉj)2 ( f‚àí1+ùúÉj
f
) 1+ùúå
ùúå(1 ‚àíùúå)
(f + ùúÉj ‚àí1)3ùúå2
‚éû
‚éü
‚éü
‚éü
‚éü‚é†
.
Because this second derivative is positive when f > 1 ‚àíùúÉj, the first derivative is max-
imized at f = 1, and the maximum value is
ùúåc‚àí1‚àíùúå
ùúåùõº
1
ùúå
j
1 ‚àíùúå
(
‚àí1 + ùúÉ
1‚àíùúå
ùúå
j
(1 ‚àíùúÉj
ùúå
))
.
By differentiating the expression above with respect to ùúÉj, we can show that its max-
imum value is, in fact, the following negative number:
ùúåc‚àí1‚àíùúå
ùúåùõº
1
ùúå
j
1 ‚àíùúå
(
‚àí1 + (1 ‚àíùúå)
1‚àíùúå
ùúå
)
.
The first derivative of each term, therefore, is negative. Furthermore, as noted earlier,
each term in the sum equals 0 at f = 1. Hence, the sum must be positive if f < 1, that
is, the smart-pipe profit must be higher.
The three comparisons presented above, for the sets {m, m + 1, ..., n}, J1, and J2,
respectively, together imply that smart pipes result in a strictly higher profit at values
of f satisfying f ‚â•1‚àïùúÉ.
‚óæ
We are now ready for our next result, which shows that dumb pipes are superior
from the carrier‚Äôs viewpoint when ùúÉis below a threshold and f is not too large. Is
it not interesting that a pricing strategy, which apparently constrains the carrier and
offers consumers greater freedom, can actually lead to a higher profit?
Theorem 9.3
When the two consumer types are not uniformly ordered, either smart
pipes or dumb pipes may lead to a higher profit. In particular, if ùúÉ< ùúÉk, where
ùúÉk =
‚àëm‚àí1
j=1 ùõº
1
ùúå
j + ‚àën
j=m ùõº
1
ùúå
j ùúÉj + ùúå‚àëm‚àí1
j=1 (ùõºjùúÉj)
1
ùúå
ùõº
1
ùúå
,

NONUNIFORM ORDERING
259
there exists an f k ‚àà(0, 1‚àïùúÉ) such that dumb pipes result in a strictly higher profit at
values of f satisfying 0 < f < f k.
Proof:
Before proceeding with the proof, let us note that ùúÉk > 1 by definition. In
other words, we aim to show that, when ùúÉis between this threshold and 1, dumb
pipes lead to a higher profit unless f is too large.
When f < min(1‚àïùúÉ, 1 ‚àíùúÉm‚àí1, 1‚àïùúÉn), under dumb pipes, all services are served to
both consumer types. So, the dumb-pipe profit equals
ùúåc‚àí1‚àíùúå
ùúå
1 ‚àíùúå
‚éõ
‚éú
‚éú‚éù
f(ùõºùúÉ)
1
ùúå+ (1 ‚àíf)
(ùõº(1 ‚àífùúÉ)
1 ‚àíf
) 1
ùúå‚éû
‚éü
‚éü‚é†
.
And, its derivative at f = 0 is
ùúåc‚àí1‚àíùúå
ùúå
1 ‚àíùúåùõº
1
ùúå
(1 ‚àíùúÉ‚àíùúå
ùúå
+ ùúÉ
1
ùúå
)
= ùúåc‚àí1‚àíùúå
ùúå
1 ‚àíùúå
(
ùõº
1
ùúå
(
1 ‚àíùúÉ
ùúå
‚àí1
)
+
n
‚àë
j=1
ùõº
1
ùúå
j ùúÉ
1
ùúå
j
)
.
Under smart pipes, when f < min(1‚àïùúÉ, 1 ‚àíùúÉm‚àí1, 1‚àïùúÉn), services {1, 2, ..., m ‚àí1}
are offered only to type 1. Hence, the profit is
n
‚àë
j=m
‚éõ
‚éú
‚éú‚éù
ùúåc‚àí1‚àíùúå
ùúå
1 ‚àíùúå
‚éõ
‚éú
‚éú‚éù
f(ùõºjùúÉj)
1
ùúå+ (1 ‚àíf)
(ùõºj(1 ‚àífùúÉj)
1 ‚àíf
) 1
ùúå‚éû
‚éü
‚éü‚é†
‚éû
‚éü
‚éü‚é†
+
m‚àí1
‚àë
j=1
‚éõ
‚éú
‚éú
‚éú‚éù
(1 ‚àíf)ùúåc‚àí1‚àíùúå
ùúåùõº
1
ùúå
j
1 ‚àíùúå
‚éû
‚éü
‚éü
‚éü‚é†
,
and its derivative at f = 0 is
ùúåc‚àí1‚àíùúå
ùúå
1 ‚àíùúå
( n
‚àë
j=m
ùõº
1
ùúå
j
(1 ‚àíùúÉj ‚àíùúå
ùúå
+ ùúÉ
1
ùúå
j
)
‚àí
m‚àí1
‚àë
j=1
ùõº
1
ùúå
j
)
= ùúåc‚àí1‚àíùúå
ùúå
1 ‚àíùúå
( n
‚àë
j=m
ùõº
1
ùúå
j
(1 ‚àíùúÉj
ùúå
+ ùúÉ
1
ùúå
j
)
‚àí
n
‚àë
j=1
ùõº
1
ùúå
j
)
= ùúåc‚àí1‚àíùúå
ùúå
1 ‚àíùúå
( n
‚àë
j=m
ùõº
1
ùúå
j
(1 ‚àíùúÉj
ùúå
+ ùúÉ
1
ùúå
j
)
‚àíùõº
1
ùúå
)
.
Therefore, the derivative of the difference between the two profits‚Äîthe dumb-pipe
profit minus the smart-pipe profit‚Äîis positive at f = 0 when
ùúÉ<
‚àën
j=m ùõº
1
ùúå
j ùúÉj + ùõº
1
ùúå‚àí‚àën
j=m ùõº
1
ùúå
j + ùúå‚àëm‚àí1
j=1 (ùõºjùúÉj)
1
ùúå
ùõº
1
ùúå

260
TELECOMMUNICATION PRICING: SMART VERSUS DUMB PIPES
=
‚àën
j=m ùõº
1
ùúå
j ùúÉj + ‚àëm‚àí1
j=1 ùõº
1
ùúå
j + ùúå‚àëm‚àí1
j=1 (ùõºjùúÉj)
1
ùúå
ùõº
1
ùúå
= ùúÉk.
Now, note that the difference between the two profits is 0 at f = 0, and by
Lemma 9.1, the difference is continuous. Hence, when ùúÉ< ùúÉk, Lemma 9.3 implies
the existence of a threshold f k ‚àà(0, 1‚àïùúÉ) such that the difference is positive at values
of f satisfying 0 < f < f k.
‚óæ
Theorem 9.3 differs from the results found in the existing literature, which show
that discrimination typically results in a higher profit when compared to the case of
uniform or nondiscriminatory pricing [15‚Äì19]. The reason for this difference is that
the dumb-pipe strategy essentially amounts to quasi-bundling‚Äîit is, in fact, a means
of bundling all services into one bundle, even though the seller does not play any role
in determining the bundle composition.
Let us now carefully examine the case of two services, namely, 1 and 2. Let ùúÉ2 >
1 > ùúÉ1 and ùúÉ> 1. It follows that 1‚àïùúÉ2 < 1‚àïùúÉ< 1. This time, however, Tables 9.1
and 9.2 together imply that we need to examine three scenarios, and not just one, to
get the complete picture. They are as follows:
Case X: 1 ‚àíùúÉ1 < 1
ùúÉ2
< 1
ùúÉ;
Case Y: 1
ùúÉ2
‚â§1 ‚àíùúÉ1 < 1
ùúÉ;
Case Z: 1
ùúÉ2
< 1
ùúÉ‚â§1 ‚àíùúÉ1.
For each scenario, we again end up with four distinct regions, with different equilib-
rium outcomes. Consider the profit plot shown in Figure 9.6, which provides us with
an example of Case X. In this case, if the carrier uses the smart-pipe approach, type 1
always enjoys service 1, for which it is the high type. Similarly, type 2 always enjoys
service 2. However, type 1 can enjoy service 2 only in X1 and X2, where f < 1‚àïùúÉ2,
and type 2 can enjoy service 1 only in X2, X3, and X4, where f > 1 ‚àíùúÉ1. Under dumb
pipes, type 2 is always served, because ùúÉ> 1 for this example. Type 1 is served only
if f < 1‚àïùúÉ, that is, in regions X1, X2, and X3.
Further, for the example in Figure 9.6, ùúÉk = 1.4341 and ùúÉ= 1.2411. According
to Theorem 9.3, quasi-bundling should be preferable when ùúÉis small, specifically,
when it is below ùúÉk. As can be seen from Figure 9.6, dumb pipes indeed lead to a
higher profit in both X1 and X2. It further shows that dumb pipes perform better even
in parts of X3. For the sake of brevity, we will skip similar discussions for Cases Y
and Z.
Note that a small ùúÉ, that is, a ùúÉclose to 1, means that the reservation prices for
traffic of the two consumer types are very similar. In other words, a small ùúÉimplies a
strong inverse relationship between the preferences of the two consumer types. Prior

NONUNIFORM ORDERING
261
0.2
0.4
0.6
0.8
1.0 f
4.0
4.5
5.0
5.5
Profit
X1
X2
X3
X4
f = fk
Figure 9.6
Profit comparison with nonuniformly ordered consumer types; smart pipe (solid)
versus dumb pipe (dashed); c = 1, ùúå= 0.5, ùõº1 = 1.5, ùõº2 = 1.25, ùúÉ1 = 0.6 and ùúÉ2 = 1.8.
research has shown that such strong inverse relationships increase the effectiveness
of bundling [9]. Theorem 9.3 extends the same insight to the case of quasi-bundling.
Also, Lemma 9.2 and Theorem 9.3 collectively establish that a necessary condition
for quasi-bundling to be effective from a producer‚Äôs viewpoint is that the primary
source of consumer heterogeneity is taste and not income, and a necessary condition
for it to be highly effective is that the reservation price for traffic be similar across
different segments.
We now turn our attention to consumer welfare. The following theorem describes
certain sufficient conditions under which the smart-pipe strategy unexpectedly leads
to a higher consumer surplus.
Theorem 9.4
When the two consumer types are not uniformly ordered, either smart
pipes or dumb pipes can lead to a higher consumer surplus. In particular, the follow-
ing holds:
(a) Smart pipes lead to at least as much in consumer surplus as do dumb pipes at
values of f satisfying f ‚â•1‚àïùúÉand a strictly higher consumer surplus at values
of f satisfying f > max(1‚àïùúÉ, 1 ‚àíùúÉm‚àí1).
(b) If 1‚àïùúÉ> 1 ‚àíùúÉm‚àí1, there exists an f b in (0, 1‚àïùúÉ) such that smart pipes result in
a strictly higher consumer surplus at values of f satisfying f b < f < 1‚àïùúÉ; con-
sequently, under smart pipes, the consumer surplus is higher at all f satisfying
f b < f < 1.
(c) If 1‚àïùúÉ< 1‚àïùúÉm, there exists an f c in (0, 1‚àïùúÉ) such that smart pipes result in a
strictly higher consumer surplus at values of f satisfying f c < f < 1‚àïùúÉm.

262
TELECOMMUNICATION PRICING: SMART VERSUS DUMB PIPES
Proof:
We will prove the three parts in order.
(a) The first part follows directly from the fact that the consumer surplus under dumb
pipes is 0 if f ‚â•1‚àïùúÉ. Further, if f > max(1‚àïùúÉ, 1 ‚àíùúÉm‚àí1), under smart pipes, the sur-
plus is positive‚Äîtype 1 must get a positive surplus, because it is profitable for the
carrier to offer service (m ‚àí1) to type 2 there.
(b) Let Œìd(f) denote the difference between the two consumer surpluses (i.e., the
consumer surplus under dumb pipes minus that under smart pipes) at a given f. It
follows from part (a) that Œìd(f) is negative for f ‚â•1‚àïùúÉ. Also, by Lemma 9.1, Œìd(f)
is continuous in f. Therefore, there must exist an f b in (0, 1‚àïùúÉ) such that Œìd(f) is
negative at values of f satisfying f b < f < 1‚àïùúÉ.
(c) If 1‚àïùúÉ< 1‚àïùúÉm, Œìd(f) is again negative for any f satisfying 1‚àïùúÉ‚â§f < 1‚àïùúÉm. This
is because, under smart pipes, the consumer surplus is positive‚Äîtype 2 must get a
positive surplus, because it is profitable for the carrier to offer service m to type 1
there. Moreover, Œìd(f) is continuous in f. Therefore, there ought to exist an f c in
(0, 1‚àïùúÉ) such that Œìd(f) is negative for values of f satisfying f c < f < 1‚àïùúÉm.
‚óæ
The conditions described in parts (b) and (c) of Theorem 9.4 are very mild, in the
sense that our assumptions regarding the ùúÉj parameters imply that minj‚â§m‚àí1(1 ‚àíùúÉj) =
(1 ‚àíùúÉm‚àí1) and that maxj‚â•m(1‚àïùúÉj) = 1‚àïùúÉm. Figure 9.7, which uses the same parame-
ter values as Figure 9.6, illustrates Theorem 9.4. In Figure 9.7, as predicted by the
theorem, smart pipes indeed lead to a higher consumer surplus in X4 and a part of
X3.
Moving on to social welfare, Figure 9.8 indicates that smart pipes lead to a higher
social surplus in X4 and a part of X3.
0.2
0.4
0.6
0.8
1.0
f
0.2
0.4
0.6
0.8
Consumer surplus
X1
X2
X3
X4
f = fb
Figure 9.7
Consumer surplus comparison with nonuniformly ordered consumer types;
smart pipe (solid) versus dumb pipe (dashed); c = 1, ùúå= 0.5, ùõº1 = 1.5, ùõº2 = 1.25, ùúÉ1 = 0.6
and ùúÉ2 = 1.8.

NONUNIFORM ORDERING
263
0.2
0.4
0.6
0.8
1.0
f
4.0
4.5
5.0
5.5
Social surplus
X1
X2
X3
X4
f = fs
Figure 9.8
Social surplus comparison with nonuniformly ordered consumer types; smart
pipe (solid) versus dumb pipe (dashed); c = 1, ùúå= 0.5, ùõº1 = 1.5, ùõº2 = 1.25, ùúÉ1 = 0.6
and ùúÉ2 = 1.8.
This figure also shows that dumb pipes can result in a higher social surplus at rel-
atively moderate values of f, for example, in X2. Evidently, the common wisdom
regarding which strategy is better from the point of view of the social planner is
not applicable in this context as well‚Äîdepending on the sizes of different market
segments, either strategy might result in a higher social surplus.
Theorem 9.5
When the two consumer types are not uniformly ordered, smart pipes
lead to a strictly higher profit while leading to at least as much in consumer surplus
at values of f satisfying f ‚â•1‚àïùúÉ. Further, if 1‚àïùúÉ> 1 ‚àíùúÉm‚àí1, the smart-pipe strategy
leads to strictly higher surpluses for both the carrier and consumers at values of
f satisfying f ‚â•1‚àïùúÉ; on the other hand, if 1‚àïùúÉ< 1‚àïùúÉm, it leads to strictly higher
surpluses at values of f satisfying 1‚àïùúÉ‚â§f < 1‚àïùúÉm. Finally, there exists an f s < 1‚àïùúÉ
such that smart pipes lead to a strictly higher social surplus at values of f satisfying
f s < f < 1‚àïùúÉand, consequently, at all f satisfying f s < f < 1.
Proof: All parts except the very last one follow immediately from Lemma 9.3 and
Theorem 9.4. The last part follows from the continuity of these surpluses with respect
to f: because the difference between the social surpluses under the two regimes‚Äîthe
one under dumb pipes minus that under smart pipes‚Äîis negative at f = 1‚àïùúÉand the
difference is also continuous by Lemma 9.1, there must exist an f s < 1‚àïùúÉsuch that
smart pipes also lead to a strictly higher social surplus at all f satisfying f s < f < 1‚àïùúÉ.
‚óæ
Theorems 9.4 and 9.5 extend the counterintuitive findings described in the con-
text of uniform ordering to the case of nonuniform ordering. The intuition is still

264
TELECOMMUNICATION PRICING: SMART VERSUS DUMB PIPES
the same. While using smart pipes, the carrier selectively serves the two consumer
types; for example, in X4, it restricts service 2 to type-2 consumers only. However,
when discrimination across services is not possible, the carrier has to choose between
serving type 1 both services there and serving them none. Serving both adequately
requires ceding too large a surplus to type 2. The carrier, therefore, finds it preferable
to shut out type-1 consumers in X4 while significantly raising the price on type 2
consumers.
9.4
CONCLUSION
In this chapter, we have examined the economic impacts of service-based discrimina-
tion on the market for telecommunication services. We have analyzed a market with
discrete consumer types, who may or may not be uniformly ordered with regards
to their preferences for various services. We have closely examined‚Äîanalytically
and numerically‚Äîhow various surpluses behave depending on the pricing strategy
used by the carrier. When a carrier employs the smart-pipe strategy, it announces a
separate schedule for each service. When it does not discriminate across services,
that is, uses the dumb-pipe strategy, it offers just one schedule to price all traffic
consumption.
Service-based discrimination is commonly expected to lower consumer and
social welfare. It is also expected to lead to a higher producer surplus. We have
established‚Äîthrough rigorous economic arguments‚Äîthat these expectations are
often untrue. Specifically, the impact of discrimination is far more complex than
often argued, or even imagined. As unambiguously demonstrated in this work,
the nature of consumer heterogeneity and relative sizes of different market seg-
ments play a pivotal role in determining which strategy would lead to a higher
surplus.
Intriguingly, when consumers differ mainly in their incomes and their ordering is
thus uniform across services, the expectation that smart pipes harm consumers is true
only in situations that involve a few high type consumers and a large number of low
type consumers. In fact, despite their natural appeal to consumers, dumb pipes can be
detrimental to consumer welfare‚Äîin situations, unable to prevent certain consumers
from using a service, the carrier may decide to completely forgo them while rais-
ing the price on the rest. A similar phenomenon also occurs when consumers differ
mainly in their tastes for different services and their ordering is consequently nonuni-
form. The main lesson, therefore, is that discrimination allows a producer greater
flexibility with regards to how it serves different market segments, which may even
help it expand coverage, leading to higher surpluses for consumers. This ability of dis-
criminatory pricing to lead to higher consumer welfare gets more pronounced when
consumers‚Äô affinity for diversity in use, captured by the parameter ùúå, becomes lower.
This is because, when ùúåis low, the benefits derived from dumb pipes, which primarily
arise from the freedom to allocate traffic between services, are also low.
Another insight that emerges from this chapter is that the perception that dis-
crimination is always beneficial for the producer holds only in the case of uniform

CONCLUSION
265
ordering. It does not hold in the case of nonuniform ordering. The reason is that
an inverse ordering of consumer preferences can turn dumb pipes into a very
effective bundling strategy. Equally noteworthy is the insight that service-based
discrimination is not always detrimental to social welfare as often believed. The
smart-pipe strategy is, in fact, win‚Äìwin for the carrier and consumers in many
situations. The implication is intriguing. The usual arguments about how smart pipes
serve as a mechanism for reallocating surplus from consumers to the carrier have
little merit. These usual ‚Äúzero-sum‚Äù arguments fail to recognize that smart pipes can
indeed drive the social surplus higher, creating the possibility of a higher surplus for
everyone.
In summary, the salient contribution of this chapter is that it explains why banning
smart pipes may not benefit consumers as expected. Further, it explains why dumb
pipes do not always lead to a lower producer surplus or a higher social surplus. All
these findings have critical implications for everyone, including carriers, consumers,
and policymakers. Consumers need to understand that service-based discrimination
can work in their favor before they extend unqualified support for a ban on discrimina-
tion, or they embrace open platforms with the hope of rendering such discrimination
ineffective. Likewise, policymakers should consider the negative impacts a ban on
discrimination may produce, including the most unexpected impact of a lower sur-
plus for everyone. A carrier should also note that smart pipes are not necessarily
more profitable‚Äîthey can indeed be suboptimal when consumers are nonuniformly
ordered.
This chapter also contributes towards the broader debate on net neutrality. In par-
ticular, it sheds light on the issue of neutrality with respect to different services that
use the same communication network. Contrary to what supporters of neutrality may
claim, the results above all point to the fact that when assessing economic impacts of
neutrality, relying on the prevalent wisdom can be futile. Analytical models that rest
on well-tested economic theories are desired for proper evaluation of likely conse-
quences.
A word on extending this work to competitive settings is in order now. One way
to model a firm, which is not a monopoly but has substantial pricing power, could be
to use slightly different participation (Individual Rationality) constraints. So far we
have assumed that a consumer must get a nonnegative utility from any plan he/she
purchases. Equivalently, we have implicitly assumed the so-called ‚Äúoutside‚Äù utility
to be zero. It is possible to imagine a setting where the outside utility is positive, as
will be the case if consumers have the ability to switch to alternatives offered by the
competing firms. Each consumer will then seek a plan that provides them with a util-
ity at least as large as that obtained from the best of all such alternatives. However,
extending the work this way is not at all trival, because many more mathematical pos-
sibilities will emerge. For example, if the outside utility for one service is high and
that for another is low, under dumb pipes, a consumer may allocate all of his/her pur-
chased traffic to the service with the lower outside utility. Thus, the pricing problem
may not have interior solutions, implying that analyses of corner solutions may also
become necessary. Interested readers may refer to Reference 20 for additional useful
guidelines.

266
TELECOMMUNICATION PRICING: SMART VERSUS DUMB PIPES
REFERENCES
1. A. Lahiri, R. M. Dewan, and M. Freimer. ‚ÄúThe disruptive effect of open platforms on the
market for wireless services,‚Äù Journal of Management Information Systems, 29(3), 2011,
81‚Äì109.
2. A. Lahiri, R. M. Dewan, and M. Freimer. ‚ÄúPricing of wireless services: service pricing vs.
traffic pricing,‚Äù Information Systems Research, 24(2), 2013, 418‚Äì435.
3. A. Odlyzko. ‚ÄúThe evolution of price discrimination in transportation and its implications
for the internet,‚Äù Review of Network Economics, 3(3), 2004, 323‚Äì346.
4. ABC News. Cell phone execs grilled by Senate over texting charges, June 18, 2009. Avail-
able at: http://abcnews.go.com/video/playerindex?id=7856703.
5. S. Keshav. Testimony of Professor Srinivasan Keshav at the hearing on June 16 at the
United States Senate Judiciary Committee, 2009. Available at: http://www.judiciary.
senate.gov/hearings/testimony.cfm?id=e655f9e2809e5476862f735da14b66b2/&wit_id=
e655f9e2809e5476862f735da14b66b2-0-3.
6. W. S. Mossberg. Free my phone. The Wall Street Journal, Oct. 22, 2007. Available at:
http://online.wsj.com/article/SB119264941158362317.html.
7. R. Jackson. AT&T Android phones from Dell, HTC and Motorola coming soon!
Jan. 6, 2010, Available at: http://phandroid.com/2010/01/06/att-android-phones-from-
dell-htc-and-motorola-coming -soon/.
8. K. Brown and P. J. Alexander. ‚ÄúBundling in cable television: a pedagogical note with a
policy option,‚Äù International Journal on Media Management, 6(3), 2004, 162‚Äì167.
9. W. J. Adam and J. L. Yellen. ‚ÄúCommodity bundling and the burden of monopoly,‚Äù Quar-
terly Journal of Economics, 90(3), 1976, 475‚Äì498.
10. Y. Masuda and S. Whang. ‚ÄúOn the optimality of fixed-up-to tariff for telecommunication
service,‚Äù Information Systems Research, 17(3), 2006, 247‚Äì253.
11. I. Friend and M. E. Blume. ‚ÄúThe demand for risky assets,‚Äù American Economic Review,
65(5), 1975, 900‚Äì922.
12. P. S. Armington. ‚ÄúA theory of demand for products distinguished by place of production,‚Äù
IMF Staff Papers, 16(1), 1969, 159‚Äì178.
13. M. Armstrong. ‚ÄúPrice discrimination by a many-product firm,‚Äù Review of Economic Stud-
ies, 66(1), 1999, 151‚Äì168.
14. M. Mussa and S. Rosen. ‚ÄúMonopoly and product quality,‚Äù Journal of Economic Theory,
18(2), 1978, 301‚Äì317.
15. M. Katz. ‚ÄúNonuniform pricing, output and welfare under monopoly,‚Äù Review of Economic
Studies, 50(1), 1983, 37‚Äì56.
16. K. W. S. Roberts. ‚ÄúWelfare considerations of nonlinear prices,‚Äù Economic Journal,
89(353), 1979, 66‚Äì83.
17. A. Spence. ‚ÄúNonlinear prices and welfare,‚Äù Journal of Public Economics, 8(1), 1977,
1‚Äì18.
18. R. Schmalensee. ‚ÄúOutput and welfare implications of monopolistic third-degree price dis-
crimination,‚Äù American Economic Review, 71(1), 1981, 242‚Äì247.
19. H. Varian. ‚ÄúPrice discrimination and social welfare,‚Äù American Economic Review, 75(4),
1985, 870‚Äì875.
20. M. Armstrong and J. Vickers. ‚ÄúCompetitive price discrimination,‚Äù RAND Journal of Eco-
nomics, 32(4), 2001, 1‚Äì27.

PART IV
Content-Based Pricing


10
Economic Models of Sponsored
Content in Wireless Networks
with Uncertain Demand
MATTHEW ANDREWS, ULAS OZEN, MARTIN I. REIMAN,
and QIONG WANG
10.1
INTRODUCTION
One persistent trend in wireless communications in recent years is that demand for
bandwidth is exploding, whereas revenue per subscriber is either flat or growing at a
much slower rate. Hence, there is a mismatch between the amount of revenue coming
in from the end users (EUs) of the network and the amount of investment that is
required for wireless capacity to keep pace with demand.
Variable pricing and bundling are two traditional ways for revenue enhancement.
In the first case (e.g. [1]), the service provider charges different fees for the same ser-
vice provided at different times of day or different locations, effectively using pricing
as a control device to fit demand within capacity while discriminating between users
with different needs. In the second case, the service provider offers a single package
that contains both high revenue-per-bit services and low revenue-per-bit services, and
uses the gains from the former to cover the loss of the latter. The potential of either
method ultimately rests on the pockets of EUs and, hence, is limited by the latter‚Äôs
budget.
In this chapter, we investigate an approach whereby the service provider can tap
into an alternative source of revenue, originating from sales of advertisements or prod-
ucts and channelled by the content provider in the form of sponsorship of viewing.
The gain comes from removing inefficiency of the current arrangement under which
the content provider derives profit from its content (e.g., by showing advertisements)
while EUs pay for the cost of viewing it. To maximize its profit, the provider natu-
rally wants to increase the number of views of its content but is unlikely to get help
from EUs who are wary about wasting their precious bandwidth quotas on content
such as embedded advertisements. The reluctance is strong not only because the use
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
269

270
ECONOMIC MODELS OF SPONSORED CONTENT
of bandwidth can be heavy (in the case when an advertisement includes rich video)
but also because EUs are uncertain and thus cannot control such use. Unlike voice
service, which is charged by minutes, data service is sold in units of bytes and it is
harder for the EUs to interpret how many bytes will be consumed when they perform
a web action. Typically, when an EU clicks on a link, the only indication they would
get that the resulting web page is large is if it takes a long time to load.
We consider a solution that allows the content provider to ‚Äúsponsor‚Äù its content so
that it does not get charged to the EUs‚Äô monthly quotas. The arrangement removes
EUs‚Äô concern about paying an uncertain amount of bandwidth cost for content that is
of little immediate value to them. As a consequence, more content will be accessed,
not only because some of it is free but also because users are effectively given more
quota. The content provider‚Äôs profit increases as long as the cost of sponsoring
stays below the new revenue from increased viewing of its content. Moreover, the
provider‚Äôs image also improves as fewer users will think of it as an irresponsible
party that pushes costly and worthless materials to them. Content sponsoring also
benefits the service provider by giving it the opportunity to charge content providers
who, as the ‚Äúover-the-top‚Äù companies, have a greater willingness to pay than EUs.
Income from this new source enables the service provider to recover the value
of some of the mobile services that it is enabling and use that revenue to finance
capacity expansion.
10.1.1
Research Questions
The concept of sponsored content introduces the following set of research questions.
In this chapter, we shall mostly focus on the first one.
‚Ä¢ What is the proper way to design a contract between the service provider and the
content provider for sponsored content? The service provider needs to design
the contract in such a way that induces the content provider to participate in
sponsoring and make decisions that improve the service provider‚Äôs profit. The
main contribution of this chapter is the design of a contract that not only does
this but also maximizes the gain to the entire system, while at the same time
transferring a significant share of the gain to the service provider itself. More-
over, we will show that the contract is win‚Äìwin‚Äìwin for the service provider,
the content provider and the EUs in the sense that if sponsoring occurs, then all
participants in the system will be better off than if there were no sponsoring.
‚Ä¢ What are the main types of content for which the sponsored content concept is
most applicable? Our model will shed some light on this problem because it will
generate a set of conditions regarding when the content provider will decide to
sponsor. At a crude level, the concept makes most sense for content that gen-
erates significant economic value to the content provider on each view. Some
examples include advertising (especially advertising for luxury items), shop-
ping sites (where the content provider cost of sponsoring could be wrapped into
the purchase), large content such as movies (especially for sites where content
must be purchased because again the cost of sponsoring could be wrapped into

INTRODUCTION
271
the cost of the purchase) and applications such as games that include ‚Äúin-app
purchases.‚Äù
‚Ä¢ To what extent should consumers be informed that sponsored content is free to
them and if so, how should this information be communicated? We believe that
the sponsored content concept has value even if the EU is unaware of which
content is sponsored because it would still prevent a big depletion of quota for
large content that the EU would prefer to not pay for. However, it is likely that
the dynamics of the system would be significantly transformed if the users do
know what content is free to them.
‚Ä¢ How can sponsored content be implemented at scale? Realizing the concept
at a small scale is simple because all we need to do is inspect packets within
the network to decide whether the EU will be charged or not. [This could for
example be done on the basis of Internet Protocol (IP) address.] In addition,
we would need a way to manage the payments from the content provider to
the service. Achieving all this on the scale of a large service provider without
bringing significant extra signaling into the network is an important challenge.
‚Ä¢ What are the ‚Äúnet-neutrality‚Äù implications of sponsored content? The topic is
relevant because if a content provider sponsors its content, then the service
provider will treat that content differently than the content of other content
providers. Hence, the service provider would not be treating the content of all
content providers in an identical manner which is required under some defini-
tions of network neutrality.
10.1.2
Previous Work
Networks that allow the option of content provider pricing were studied in
References 2 and 3. The first paper considers a network utility maximization (NUM)
setting where both the content provider and the EU have a utility and we wish to
set prices at both end points and route traffic so that the aggregate utility minus the
cost of the network is maximized. This setup was considered for both an Internet
Service Provider (ISP) in a competitive market where the prices are determined by
the market as well as a monopolistic ISP that has complete freedom to set prices.
The second paper [3] considers a model where there is one local ISP for the content
provider and one local ISP for the EUs. Two mechanisms are studied in this setting.
In the first, there is no collusion and each ISP tries to selfishly maximize profit. In the
second, a Nash bargaining solution is used to determine the profit division between
the two ISPs.
There have also been a number of studies motivated by the question of network
neutrality and some of these are related to the concept of sponsored content.
In Reference 4, Economides and Hermalin consider a situation where the ser-
vice provider partitions bandwidth and charges content providers for access
to a given bandwidth partition. Conditions are presented for which a single
partition is welfare maximizing. Mitra and Wang [5] study a model where the
service provider maintains two pipes that can be accessed by content providers: a

272
ECONOMIC MODELS OF SPONSORED CONTENT
best-effort pipe and a managed bandwidth pipe that provides improved quality for
an additional fee. In this setting, the service provider optimizes over the amount
of best-effort bandwidth and the price of managed bandwidth. A key feature of
this model is that when new applications enter the market, they typically rely on
the best-effort pipe and so the rate of new service generation critically depends
on the amount of best-effort bandwidth that is available. Lastly, in Reference 6,
Njoroge et al. consider a model where each service provider controls access to
a certain subset of EUs. Moreover, each service provider can charge a content
provider for access to ‚Äúits‚Äù consumers. The paper describes a setting in which
this nonneutral regime can drive higher investment and, hence, maximize social
welfare.
As already discussed, much of the focus of this chapter relates to how contracts
should be designed between a content provider and a service provider. Similar issues
of contract design have been discussed in a different context in the marketing disci-
pline under the banner of ‚Äúchannel coordination‚Äù [7] and have been widely addressed
in the supply chain literature (e.g., see Reference 8 for review). More recent work in
References 9 and 3 has started the consideration of coordinating contracts in the net-
work setting. Our paper fits closely with this stream of thoughts. In particular, our
contracting arrangement is equivalent to the stylized buyback contract discussed in
both References 7 and 8.
10.1.3
Designing Contracts Under Uncertain Demand
As already discussed, the focus of our presentation is on designing contracts between
the service provider and content provider so that there is a win‚Äìwin‚Äìwin for all par-
ties in the system (including the EUs). By this, we mean that all parties are better off
than if the content was not sponsored. Our model differs from the prior models dis-
cussed earlier in that the underlying demand from the end users is uncertain. It is not
simply a function of price and user/content provider utility. (In addition, the NUM
model of Reference 2 assumes strictly concave utility functions as a consequence of
demand being elastic with respect to price and, hence, does not capture a natural situ-
ation where the content provider is paid a fixed price per view by advertisers.) Lastly,
our model extends beyond simple per-byte pricing and attempts to capture the notion
of EU quota dynamics.
The fact that we treat underlying demand as a random variable has two effects
on our analysis. First, the problem faced by the content provider is similar to the
‚ÄúNewsvendor‚Äù problem that is common in supply chain analysis. (In a Newsvendor
problem, a retailer must purchase inventory to cover uncertain demand over a fixed
time period. When the time period is over, the inventory only has a salvage value
that is well below the purchasing price.) In our setting, the Newsvendor problem
arises because the content provider must decide how much content to sponsor in a
time period without knowing what the EU demand is. Second, the uncertain demand
coupled with a reservation fee paid in advance will allow the service provider to
control how much content is sponsored by the content provider, even when the latter‚Äôs
revenue grows in proportion to the number of views of its content.

INTRODUCTION
273
We model the interaction between the service and the content providers as a Stack-
elberg game in which the service provider offers a contract parameterized by two fixed
fees: a reservation fee proportional to the maximum number of views to be sponsored
and a usage fee for each sponsored view that actually takes place. By accepting this
contract, the content provider determines the maximum number of sponsored views
and pays the corresponding reservation fee in advance, and assumes the payment of
the usage fee for each view of its content by EUs, up to the aforementioned maximum.
We divide our discussions into two parts that reflect different ways of modeling
EU payments.
‚Ä¢ In Section 10.2, we present a simple model in which service provider congestion
costs, EU bandwidth costs, and the price that the content provider must pay for
sponsoring content are all determined on a per-byte basis. A key feature of this
model is that the underlying demand from the EUs is a random variable but
the service provider would like to control the amount of bandwidth it has to
provide.
We focus on the relationship between the service provider and a single
content provider. We show that the aforementioned two-fee contract is incentive
compatible: by charging a proper reservation fee, the content provider will be
induced to choose the maximum number of sponsored views to optimize the
total expected profit of both parties. It is also in the service provider‚Äôs best
interest to charge such a fee to bring about this outcome, because it can then
use the per-use fee to transfer the profit to itself. In Section 10.2.5, we present
a numerical example to demonstrate how the optimization might work in
practice.
‚Ä¢ In Section 10.3, we indicate how the results can be adapted for the case of EU
quotas. In most current wireless data plans, the EUs pay a certain fee for a fixed
quota of data. They do not pay on a byte-by-byte basis. This has a significant
effect on the model because it is now much less explicit how much EU rev-
enue the service provider is giving up when content is sponsored. In particular,
we model an EU quota via a Markov Chain and describe the dynamics of the
process according to whether the content is sponsored.
10.1.4
The Models
In this paper, we consider a contractual relationship between a single service provider
(SP) and a single content provider (CP) in offering sponsored views of content (e.g.,
a webpage, an advertisement, or an online video). The situation is formally modeled
as a Stackelberg game in which the SP is the leader who sets price parameters of
the contract and the CP is the follower who responds by determining the maximum
number of views it is willing to sponsor within a fixed period, for example, monthly.
The purpose of sponsoring is to raise revenue by increasing the number of views of
the said content. To model this effect, we assume EU will always access the said
content if it is sponsored and with a smaller probability if it is not.

274
ECONOMIC MODELS OF SPONSORED CONTENT
This problem can be naturally extended to the case of multiple CPs competing
for the attentions of the EUs by sponsoring their own content. That situation leads
to interesting competitive dynamics between the content providers and we leave its
analysis for future work.
We define two basic models. In the first, the EUs pay for bandwidth on a per-byte
‚Äúpay-as-you-go‚Äù basis. In the second model, we aim to capture the more common
situation in which EUs pay for bandwidth via monthly quotas.
10.1.4.1
Model of Sponsored Content with Per-Byte End-User Costs The EUs
generate N (a random variable) potential views in a period for content items that for
ease of exposition are all assumed to have the same size ùúÉ. (It would not be difficult to
extend to a situation where ùúÉis the mean size of heterogeneous content.) Let F be the
cumulative distribution function of N and let F = 1 ‚àíF. If the content is sponsored, it
is viewed with probability 1. If content is not sponsored, it is viewed with probability
q < 1. (The parameter q here captures the strategic behavior of the EUs.) Let bin(m, q)
denote a binomial random variable with m ‚ààIN0 trials and success probability q. Then
E[bin(m, q)] = mq.
The SP charges only the CP for sponsored content and the EUs for nonsponsored
content, all on a per-byte basis. As we assume constant size for content, we denote
EUs‚Äô payment per view for nonsponsored content by r. (The fact that an EU does not
have to pay this amount for sponsored content is the main reason why the probability
(=1) of viewing sponsored content is more than the probability (=q) of viewing non-
sponsored content. The CP‚Äôs decision is denoted by B, defined as the maximum num-
ber of views the CP is willing to sponsor. The actual number of sponsored views is,
therefore, min{N, B} and the total number of views is min{N, B} + bin([N ‚àíB]+, q).
As mentioned earlier, the payment from the CP to the SP is structured as an ex ante
reservation fee and an ex post usage fee. We define c to be the reservation fee per
view and b to be the usage fee per view. Hence, the total revenue that the SP collects
from the CP in a given period is cB + bmin{N, B}.
It remains to define the advertising revenue earned by CP and the bandwidth cost
incurred by SP. We assume that CP earns revenue a for each view and, hence, its
total revenue is a(min{N, B} + bin([N ‚àíB]+, q)). (We assume that all parameters are
known by the SP and leave the interesting case where a and q are private information
of the CP for future work.) The cost for the SP is dependent on the total congestion
on its network, which is given by a nondecreasing function C(‚ãÖ). We let B be the total
load on the network excluding the EU‚Äôs views of the CP‚Äôs content. The total load
without sponsoring is
B0 = B + ùúÉbin(N, q)
and the total load with a sponsoring level of B is
B + ùúÉmin[N, B] + ùúÉbin ([N ‚àíB]+, q).

INTRODUCTION
275
So the expected congestion cost paid by the SP is
E [C (B + ùúÉmin[N, B] + ùúÉbin ([N ‚àíB]+, q))].
(10.1)
Our goal is to determine the maximum number of views that the CP should sponsor
to maximize the total profit of both CP and SP. We also study the fees charged by SP
that can induce this outcome.
10.1.4.2
Model of Sponsored Content with EU Quotas We now describe a more
refined model in which EUs do not pay for bandwidth on a per-byte basis. Each EU
instead pays periodically for a base data quota and has the ability to buy additional
quota in case the base quota is exhausted in a period. More formally, we assume there
is a homogeneous population of K EUs, all of whom are served by a single SP who
periodically charges a fixed subscription fee. At the beginning of each billing cycle,
every EU gets a bandwidth quota that she can use anytime within the period. The
starting point of the first cycle of EUs is uniformly distributed over a period length.
When an EU has exhausted her quota before the end of a period, she can wait until she
gets new quota at the beginning of the next period or refill her quota immediately by
paying an additional amount d. The choice between waiting and refilling is assumed
to be independent of the number of times that the EU has refilled before.
An EU‚Äôs opportunity to access content within a unit time period is a Poisson dis-
tributed random variable with mean ùúÜ. The likelihood of an EU taking the opportunity
to view the content depends on the amount of the quota she has for the remainder of
the period (this is a strong assumption because it does not take into account that an
EU may use her quota more aggressively when it is about to expire). We model EU‚Äôs
decision by a discrete-state Markov chain. States are indexed by i = 0, ..., S, where
EUs in the states of smaller index have more available quota left. EUs in state S have
exhausted their quotas and are waiting for the next period to arrive. An EU in state i
views unsponsored content with probability qi (i = 0, ..., S), where qS = 0. We remark
that by using the Markov model, the periods will not have an equal length. However,
we focus on this model as an approximation to a regular billing cycle because of its
tractability.
10.1.4.3
Implementation Issues We conclude this section with a brief discussion
of what the SP needs to track in order to implement a sponsored content offering.
As already mentioned, the interaction between the SP and CP would happen on a
periodic basis, for example, monthly. In order to perform the correct optimization,
the SP needs to know a number of parameters, for example, q, a, and the distribution
of N. The SP could estimate q and the distribution of N by monitoring EU behavior.
However, the correct value of a (the value of a view to the CP) has to come from the
CP itself. (The case in which the CP can try to ‚Äúcheat‚Äù by giving an incorrect value
of a generates a whole new set of interesting research questions that we will address
in future work.)
Once SP has decided on the prices b, c and CP has decided on the sponsoring level
B, the system is then operated by the SP. It has to identify which traffic is associated

276
ECONOMIC MODELS OF SPONSORED CONTENT
with the CP and charge the CP or EU appropriately. This depends on whether or not
the particular view is sponsored which in turn depends on whether or not we have
reached the sponsoring level B.
Of all these implementation issues, probably the most challenging is identifying
the traffic associated with the CP because that involves monitoring the traffic at line
rate and determining the content provider from which the content is being requested.
10.2
ANALYZING SPONSORED CONTENT WHEN EUs PAY PER BYTE
10.2.1
Content Provider‚Äôs Problem
We start with the simplest situation in which the reservation fee c = 0. Recall that B
denotes the maximum number of sponsored views, a > 0 denotes the (advertising)
revenue to the CP of each view, and b ‚â•0 denotes the usage fee per sponsored view
paid by the CP to the SP. The revenue received by the CP is E[a(min(N, B) + bin([N ‚àí
B]+, q)] and the cost paid by the CP to the SP is E[bmin(N, B)]. The net revenue to
the CP is
E [
(a ‚àíb) min (N, B) + abin (
[N ‚àíB]+ , q)]
= aqE [N] + (aq ‚àíb) E [min (N, B)],
(10.2)
where q = 1 ‚àíq, and we have used [x ‚àíy]+ = x ‚àímin(x, y). Let B‚àó(b) denote the
maximizing value of B for given b. Then B‚àó(b) = ‚àûif aq > b and B‚àó(b) = 0 if aq < b.
If aq = b, the CP‚Äôs net revenue function becomes a constant, and hence, the CP is
indifferent between any choice of B‚àó(b) ‚àà[0, ‚àû). In other words, if the CP does not
need to pay a reservation fee in advance for sponsoring but price b is paid for each
view of sponsored content, then the CP‚Äôs optimal choice of B‚àó(b) is either zero or
infinity with a transition point where the CP is indifferent between sponsoring any
content or not.
Now, consider the case with a per-unit reservation fee c > 0. Then CP‚Äôs revenue
function becomes
aqE[N] + (aq ‚àíb)E[min(N, B)] ‚àícB.
This is a standard Newsvendor model. If c ‚â•aq ‚àíb, then B‚àó= 0, that is, the CP will
not sponsor any content viewing if the combined reservation and usage fees exceed
the additional revenue from advertisement. If N has a continuous distribution function
(F has no jumps), then
B‚àó= F‚àí1
(
c
aq ‚àíb
)
.
(10.3)
In our setting, N is a discrete random variable, so F has jumps, and there may not
be a B‚àósuch that Eq. (10.3) holds exactly. On the other hand, N is likely to be an
extremely large integer (in our numerical Example, E[N] is on the order of 107), so
Eq. (10.3) will hold almost exactly. In particular, because B‚àóis defined by

ANALYZING SPONSORED CONTENT WHEN EUs PAY PER BYTE
277
F(B‚àó‚àí1) >
c
aq ‚àíb,
F(B‚àó) ‚â§
c
aq ‚àíb,
the error we make in assuming that Eq. (10.3) holds is miniscule and will henceforth
be ignored.
10.2.2
Service Provider‚Äôs Problem
First, consider the case with no contract cost (i.e., c = 0) and no revenue from EUs
(i.e., r = 0). The SP‚Äôs revenue from the CP is bE[min(N, B)]. The SP pays a conges-
tion cost, given by a function C. Recall that B is the ‚Äúbaseline‚Äù congestion without the
EU, and the congestion cost is given by Eq. (10.1). We remark that congestion cost
may not be a convex function of B even if C is linear because min[N, B] is concave.
The SP wants to choose b to maximize
bE
[
min
(
N, B‚àó(b)
)]
‚àíE
[
C
(
B + ùúÉmin [N, B‚àó(b)
] + ùúÉbin
([N ‚àíB‚àó(b)
]+ , q
))]
.
Recall that with b < aq, B‚àó(b) = ‚àû, and with b > aq, B‚àó(b) = 0. Thus the SP wants to
choose either b as large as possible subject to b < aq, in which case the SP‚Äôs profit is
lim
b‚Üëaq bE [min (N, B‚àó(b)
)]
‚àíE
[
C
(
B + ùúÉmin [N, B‚àó(b)
] + ùúÉbin
([N ‚àíB‚àó(b)
]+ , q
))]
= aqE [N] ‚àíE [C (B + ùúÉN)],
or b > aq, in which case the SP‚Äôs profit is ‚àíC(B + ùúÉbin(N, q)). The SP will choose
the alternative yielding the higher profit.
Now consider the case with fixed contract cost c > 0. The SP‚Äôs revenue from the
CP is bE[min(N, B)] + cB. So the SP wants to choose c and b to maximize
bE[min(N, B‚àó(b, c))] + cB‚àó(b, c)
‚àíE
[
C
(
B + ùúÉmin[N, B‚àó(b, c)]
+ ùúÉbin
([N ‚àíB‚àó(b, c)]+, q
))]
.
Given the relationship F(B‚àó(b, c)) =
c
aq‚àíb from Eq. (10.3), the SP‚Äôs problem is equiv-
alent to choosing B ‚â•0 and b ‚àà[0, aq) to maximize
bE [min (N, B)] + F (B)
(aq ‚àíb) B
‚àíE [C (B + ùúÉmin [N, B] + ùúÉbin (
[N ‚àíB]+ , q))].

278
ECONOMIC MODELS OF SPONSORED CONTENT
We now consider the optimal b for a given B. Looking at the first-order derivative of
the profit function
E [min (N, B)] ‚àíF (B) B =
B
‚à´
0
F (x) dx ‚àíF (B) B ‚â•0,
we conclude that SP wants to set b as high as possible such that b < aq. Thus with B
fixed, the SP‚Äôs profit is
lim
b‚Üëaq bE [min (N, B)] + F (B)
(aq ‚àíb) B
‚àíE [C (B + ùúÉmin [N, B] + ùúÉbin (
[N ‚àíB]+ , q))]
= aqE [min (N, B)]
‚àíE [C (B + ùúÉmin [N, B] + ùúÉbin (
[N ‚àíB]+ , q))],
so that the optimal profit is attained using B‚àógiven by
B‚àó= arg max
B
{
aqE [min (N, B)]
‚àíE [C (B + ùúÉmin [N, B] + ùúÉbin (
[N ‚àíB]+ , q))]}
.
Of course, in practice the limit cannot be attained: the SP needs to keep c > 0 to
induce the CP to choose the SP‚Äôs desired B‚àó. Thus there is some small ùúÄsuch that
b = aq ‚àíùúÄand c = F(B‚àó)ùúÄ, that is, while a positive reservation fee is necessary to
induce optimal B, the SP is better off to keep it as low as possible and derive all its
profit by setting b as high as possible.
We also remark that because of Eq. (10.3), when finding B‚àówe must optimize
over the support of N. In reality, we would typically wish to restrict the optimization
further to between (say) F(0.02) and F(0.98) because otherwise the system would be
overly sensitive to the exact values of b and c.
10.2.2.1
Revenue from EUs Suppose that SP earns revenue from the EUs, that is,
rE[bin((N ‚àíB)+, q)] where r is the revenue rate. So the SP wants to choose c and b
to maximize
bE [min (N, B‚àó(b, c)
)] + cB‚àó(b, c)
‚àíE
[
C
(
B + ùúÉmin [N, B‚àó(b, c)
] + ùúÉbin
([N ‚àíB‚àó(b, c)
]+ , q
))]
+ rE
[
bin
((N ‚àíB‚àó(b, c)
)+ , q
)]
.
If r ‚â•aq
q , it is not beneficial for the SP to offer sponsored content option to CP because
the additional revenue from CP is not high enough to compensate for the loss in

ANALYZING SPONSORED CONTENT WHEN EUs PAY PER BYTE
279
revenues from the EUs . This is the case if content revenues are low (i.e., for low a
values) and/or the content is popular (i.e., for high q values).
Now, consider the case with r < aq
q . Similarly as above, the SP‚Äôs problem is equiv-
alent to choosing B and b to maximize
bE [min (N, B)] + F (B)
(aq ‚àíb) B
‚àíE [C (B + ùúÉmin [N, B] + ùúÉbin (
[N ‚àíB]+ , q))]
+ rE [bin (
(N ‚àíB)+ , q)].
Checking the derivative with respect to b, we conclude that SP wants to set b as high as
possible such that b < aq as above. We can again optimize over B, the only difference
being the additional term rE[bin((N ‚àíB)+, q)].
10.2.3
A Pareto Analysis of the Two-Parameter Contract
The system performance, that is, the aggregate profit achieved by the SP and the CP,
is given by
ùúãS (B) = E [amin (N, B) + (a + r) bin (
[N ‚àíB]+ , q)]
‚àíE [C (B + ùúÉmin [N, B] + ùúÉbin (
[N ‚àíB]+ , q))],
and the SP takes the following share
bE [min (N, B)] + F (B)
(aq ‚àíb) B
‚àíE [C (B + ùúÉmin [N, B] + ùúÉbin (
[N ‚àíB]+ , q))]
+ rE [bin (
(N ‚àíB)+ , q)].
Let BS denote the system optimal number of sponsored views, that is,
BS = arg maxB{ùúãS(B)}. The increase of the total expected profit from sponsoring is
ùúãS (BS) ‚àí(r + a) qE [N] ‚àíE [C (B + ùúÉbin (N, q)
)],
and from the system‚Äôs perspective, sponsoring only makes sense if
ùúãS (BS) > (r + a) qE [N] ‚àíE [C (B + ùúÉbin (N, q)
)].
From the earlier discussion, we know that the inequality is not satisfied if r ‚â•aq
q .
However, we remark that even if r ‚â§aq
q , sponsored content might not generate suf-
ficient advertising revenue to offset the combined effect of losing EU revenue and
increasing congestion cost. Such situations will be identified by the optimization of

280
ECONOMIC MODELS OF SPONSORED CONTENT
ùúãS(B) when the optimal solution BS = 0. This will happen if the congestion function
C(‚ãÖ) increases steeply, for example, if,
(aq ‚àírq) F (0) < G‚Ä≤ (0),
where,
G (B) ‚â°E [C (B + ùúÉmin (N, B) + ùúÉbin (
(N ‚àíB)+ , q))]
is an increasing and convex function of B, in which case dùúãS‚àïdB < 0 for all B ‚â•0.
Assume now that ùúãS(BS) ‚â•(r + a)qE[N] ‚àíC(B + ùúÉbin(N, q)). As the system
profit is maximized at BS and the SP‚Äôs share is increasing with b for any given B (and,
hence, CP‚Äôs share is decreasing with b), a contract (b, c) is Pareto efficient if and only
if B‚àó(b, c) = BS. Therefore, Pareto efficient contracts can be characterized by the
single parameter b < aq where c = F(BS)(aq ‚àíb). Under the set of Pareto efficient
contracts, any allocation of additional system profit can be possible. The SP‚Äôs share of
profit will have a range of [rqE[N] ‚àíC(B + ùúÉbin(N, q)), ùúãS(BS) ‚àíaqE[N]), whereas
CP‚Äôs profit will have a range of [aqE[N], ùúãS(BS) ‚àírqE[N] + C(B + ùúÉbin(N, q))]. We
remark that for CP to achieve profit of ùúãS(BS) ‚àírqE[N] + C(B + ùúÉbin(N, q)), CP
needs to negotiate from SP the most favorable per-unit price b such that
rqE [N] ‚àíC (B + ùúÉbin (N, q)
)
= bE [min (N, BS)] + F (BS) (aq ‚àíb) BS
‚àíE
[
C
(
B + ùúÉmin [N, BS] + ùúÉbin
((N ‚àíBS)+ , q
))]
+ rE
[
bin
((N ‚àíBS)+ , q
)]
.
When r is small, b that satisfies this equality might be negative.
10.2.4
Summary of the Analysis with a Contract Price c and Additional
Revenue from End Users
The findings from the above analysis can be summarized as follows.
‚Ä¢ The system performance, that is, the total expected profit for both the SP and
the CP, is given by
ùúãS (B) = E [amin (N, B) + (a + r) bin (
[N ‚àíB]+ , q)]
‚àíE [C (B + ùúÉmin [N, B] + ùúÉbin (
[N ‚àíB]+ , q))] .
Optimizing the above determines whether sponsoring should take place.
‚Ä¢ Although, as noted above, the system profit function ùúãS(B) is not necessarily a
concave function, finding the system optimal B is not a hard problem given that
ùúãS(B) is defined by one variable.

ANALYZING SPONSORED CONTENT WHEN EUs PAY PER BYTE
281
‚Ä¢ Charging a single usage fee b is not enough to enforce a sponsored view to the
CP. SP needs to charge a reservation fee c to induce the optimal limit on the
sponsored views. By keeping c as low as possible and b as high as possible,
the SP transfers all the expected gains from sponsoring to itself.
‚Ä¢ Under any coordinating contract, the system profit is maximized (i.e., achieves
Pareto optimum of the CP and the SP profits). Moreover, any allocation of addi-
tional profits is possible. Such a contract is definitely a win‚Äìwin‚Äìwin contract
for CP, SP, and EUs.
10.2.5
Numerical Example
We now present a numerical example to illustrate the above concepts. Consider the
case of a large CP for which N has a truncated normal distribution with mean N =
5 √ó 107 views per month. (The distribution is truncated to two standard deviations on
each side.) The size of the content ùúÉis 7.416 Mbit and the CP receives $0.0125 profit
for each view (before paying any sponsoring charge to the SP). We assume EUs pay
at a rate $10/GB for nonsponsored content and so this translates to a cost per view of
r = 10ùúÉ‚àï(8 √ó 109). For the SP congestion cost, we set the baseline congestion B = 0
and use a piecewise linear function given by
C(x) =
‚éß
‚é™
‚é™
‚é®
‚é™
‚é™‚é©
3rx
5ùúÉ
if x ‚â§19N
20
10r
(
x ‚àí893N
1000
)/
ùúÉ
otherwise.
(This stylized cost function reflects, in a simple manner, the additional costs, such as
lost customer good will, of exceeding the nominal system capacity.) We set q = 0.2,
that is, an EU is five times as likely to view the content when it is free to them than
they are when they have to pay for the bandwidth. In Figures 10.1 and 10.2, we show
system profit as a function of B when the standard deviation of the underlying normal
distribution is 2N‚àï5 and N‚àï10, respectively. We can see that as the uncertainty in
N increases (i.e., the standard deviation increases), the optimal amount of content
to sponsor decreases because there is more likelihood that the realization of N will
correspond to the steep part of the SP congestion cost curve. We can also see that
although the system profit is not concave, it is simple to identify the optimal value
of B.
In Figure 10.3, we fix B to its optimal value (in this case, 4.5 √ó 107 views) for the
case that the standard deviation is N‚àï10. We then plot both SP profit and CP profit
as a function of b. (Recall that c is then determined from b and B via Eq. (10.3). In
particular, as b increases from 0 to aq = 0.01, c decreases from 0.0086 to 0.) As b
increases, more of the excess system profit generated from the sponsored content is
transferred from CP to SP. As a comparison, we also plot the baseline profit for SP
and CP that would occur in the case that no content is sponsored (i.e., B = 0).

282
ECONOMIC MODELS OF SPONSORED CONTENT
System profit
1.0
0.8
0.4
0.2
0.0
‚àí400,000
‚àí300,000
300,000
‚àí200,000
200,000
‚àí100,000
100,000
0.6
1e8
B
0
Figure 10.1
System profit when standard deviation is 2N‚àï5.
System profit
1.0
0.8
0.4
0.2
0.0
350,000
250,000
300,000
200,000
150,000
100,000
50,000
0.6
1e8
B
0
Figure 10.2
System profit when standard deviation is N‚àï10.
10.3
ANALYZING SPONSORED CONTENT IN THE CASE OF EU
QUOTAS
Recall that we model quota usage via a discrete-state Markov Chain with state space
{0, ‚Ä¶ , S}. An EU in state i views the content with probability qi. EUs in state S have
exhausted their quota and are waiting for the next period to arrive. (Hence, qS = 0.)
When a user exhausts its quota it can pay to immediately renew it via an additional
charge. An EU‚Äôs opportunity to access content within a unit time period is a Poisson
distributed random variable with mean ùúÜ. We let K denote the number of EUs and so

ANALYZING SPONSORED CONTENT IN THE CASE OF EU QUOTAS
283
CP and SP profit
CP profit
SP profit
0.000
0.002
0.004
0.006
0.008
0.010
250,000
300,000
200,000
150,000
100,000
50,000
b
0
Figure 10.3
The sloped lines represent SP and CP profits as a function of b when the standard
deviation is N‚àï10 and B is optimized for system profit. The horizontal lines represent the
baseline profit for SP and CP in the case of no sponsoring.
the total number of potential views is given by the random variable ŒõK, which has a
Poisson distribution with mean ùúÜK.
Let pi be the transition rate from state i to state i + 1 (i = 0, ‚Ä¶ , S ‚àí2); p‚Ä≤
S‚àí1 and
p‚Ä≤‚Ä≤
S‚àí1 be the rates from state S ‚àí1 to state S and state 0, respectively; and pS be the
rate from state S to state 0. Transition rates between all other states are zero. Rates pi
(i = 0, ..., S ‚àí2) reflect how fast EUs run down their quota. Define
ùúí=
p‚Ä≤
S‚àí1
p‚Ä≤
S‚àí1 + p‚Ä≤‚Ä≤
S‚àí1
as the fraction of EUs who choose to wait for the next period after exhausting their
quotas and denote pS‚àí1 as the rate of EUs in state S ‚àí1 using up their quotas. Then
p‚Ä≤
S‚àí1 = ùúípS‚àí1 and p‚Ä≤‚Ä≤
S‚àí1 = (1 ‚àíùúí) pS‚àí1.
The rate pS is inversely related to the residual time until the next billing cycle.
The transition rates imply the following steady-state probability for an EU to be
in state i:
Pi =
ùúås
1 + ùúå1 + ¬∑ ¬∑ ¬∑ + ùúåS‚àí1 + ùúíùúåS
(i = 0, ..., S ‚àí1)
PS =
ùúíùúåS
1 + ùúå1 + ¬∑ ¬∑ ¬∑ + ùúåS‚àí1 + ùúíùúåS
,
(10.4)
where ùúåi = p0
pi
(i = 1, ...., S).

284
ECONOMIC MODELS OF SPONSORED CONTENT
Although, as in the previous model, there are again two possible outcomes for each
unsponsored potential view‚Äîviewed or not viewed, the probability of viewing is a
bit more complicated. In particular, a potential view is associated with a user in state i
with probability Pi, 0 ‚â§i ‚â§S, and such a user views content with probability qi. Thus
the number of actual views when there are m potential views is a binomial random
variable bin(m, Q), where Q = ‚àëS‚àí1
i=0 qiPi. Let Q = 1 ‚àíQ, and note that Q < 1.
Let D be the base revenue that SP receives from the EUs for their regular monthly
quotas and let ùúèbe the rate at which EUs refill their quota ‚Äúearly.‚Äù From the Markov
Chain transition probabilities, we have
ùúè= K(1 ‚àíùúí)pS‚àí1PS‚àí1.
Hence, the SP revenue from the EUs is D + dùúè= D + dK(1 ‚àíùúí)pS‚àí1PS‚àí1.
10.3.1
Case 1: Sponsorship-Insensitive Transition Probabilities
We begin with the case in which the Markov Chain transition probabilities do not
change when CP‚Äôs content is sponsored (i.e., the users simply switch their viewing
from another content provider). We can obtain similar conclusions as before with Q
playing the role of q. In particular, the CP‚Äôs expected profit is given by
E
[
(a ‚àíb)min(ŒõK, B) + abin
([ŒõK ‚àíB]+ , Q
)]
‚àícB
=
(
aQ ‚àíb
)
E [min (ŒõK, B)] + aQE [ŒõK] ‚àícB.
As in Section 10.2.1, this is again a standard Newsvendor model and so the CP deci-
sion leads to a relationship of the form
B‚àó(b, c) =
‚éß
‚é™
‚é™
‚é®
‚é™
‚é™‚é©
F‚àí1
(
c
aQ ‚àíb
)
if c < aQ ‚àíb
0
otherwise.
(10.5)
The SP choice of b and c is, therefore, equivalent to a choice of b and B so long as
c > 0. (Once again, therefore, we need c > 0 in order for the SP to be able to control
the system.)
Similar to the per-byte cases, the system profit for a fixed value of B is
aQE [min (ŒõK, B)] + aQE [ŒõK] + (D + dùúè)
‚àíE
[
C
(
B + ùúÉmin [ŒõK, B] + ùúÉbin
((ŒõK ‚àíB)+ , Q
))]
.
Hence, as in the previous model, we can optimize system profit via a univariate opti-
mization over B. Once the optimal value of the B has been obtained, the split between
the SP and CP can be controlled by an appropriate choice of b.

ANALYZING SPONSORED CONTENT IN THE CASE OF EU QUOTAS
285
10.3.2
Case 2: Sponsorship-Sensitive Transition Probabilities
The above analysis assumed that sponsoring content does not have a material affect
on how fast the EUs consume their quota. It just causes the EUs to consume additional
bandwidth corresponding to the sponsored content. In reality, of course, the knowl-
edge that the CP‚Äôs content is sponsored may affect the dynamics of quota usage. In
particular, sponsoring may slow the rate at which quota is consumed, thereby lower-
ing the probability that a user has to refill. In this case, the sponsoring of the content
is cannibalizing the revenue that the SP obtains from the EUs.
A general analysis of this case is beyond the scope of this chapter. Here we take
an initial step in the following by using a simple case to highlight issues involved.
In particular, we consider a two-state model as in Figure 10.4. EUs are in state 0 if
they have available quota to use and in state 1 if they do not. We define p0(B) as EUs‚Äô
transition rate out of state 0 and assume it is a decreasing function of B, that is, EUs
exhaust their quotas more slowly if they get more sponsored bandwidth. Let ùúíbe the
(constant) fraction of EUs who do not refill their quotas, so ùúíp0(B) is EUs‚Äô transition
rate into state 1. We also define p1(B) as the transition rate at which EUs move from
state 1 back to state 0 as a result of monthly replenishment of quotas. We assume
p1(B) to be an increasing function of B. As more content is sponsored, those who run
out of their quotas will do so later in their monthly cycles, hence, get replenishment
sooner and move back to state 0 faster.
Following the above definitions, the steady-state probability for EUs to be in states
0 and 1 are
P0(B) =
p1(B)
ùúíp0(B) + p1(B) and P1(B) =
ùúíp0(B)
ùúíp0(B) + p1(B).
(10.6)
Obviously, pi(0) and Pi(0) (i = 0, 1) are transition rates and steady-state probabilities,
respectively, for the case without sponsorship. Observe that p1(B)P1(B) is the rate at
which an EU moves from state 1 back to state 0. As more sponsored content results
in fewer EUs in state 1, it is natural to assume that p1(B) and p0(B) should be such
that p1(B)P1(B) decreases in B.
(1‚àíœá)P0(B)
P1(B)
œáP0(B)
1
0
Figure 10.4
Transition of EU states.

286
ECONOMIC MODELS OF SPONSORED CONTENT
As before, we define D as the subscription revenue that SP receives from the EUs
to pay for their monthly quotas. Define
ùúè(B) = K(1 ‚àíùúí)p0(B)P0(B)
to be the rate at which EUs refill their quota ‚Äúearly.‚Äù For the convenience of discussion,
we denote Q(B) ‚â°q0P0(B) as the probability that EUs access nonsponsored content.
Let Q(B) = 1 ‚àíQ(B). Given B, the expected profit of the system is
aQ (B) E [min (ŒõK, B)] + aQ (B) E [ŒõK] + (D + dùúè(B)
)
‚àíE
[
C
(
B + ùúÉmin (ŒõK, B) + ùúÉbin
((ŒõK ‚àíB)+ , Q (B)
))]
.
Compare the above with the case without sponsorship, the difference in profit is
aQ (B) E [min (ŒõK, B)] + aQ (B) E [ŒõK] ‚àíaQ (0) E [ŒõK]
+ dùúè(B) ‚àídùúè(0)
‚àíE
[
C
(
B + ùúÉmin (ŒõK, B) + ùúÉbin
((ŒõK ‚àíB)+ , Q (B)
))]
+ E [C (B + ùúÉbin (ŒõK, Q (0)
))] .
Examining each component in the above,
aQ(B)E [min(ŒõK, B)] + aQ(B)E [ŒõK] ‚àíaQ(0)E [ŒõK]
(10.7)
is the increase of advertising revenue because of sponsoring, which increases in B,
that is, more sponsoring leads to higher advertisement revenue. The incremental cost
from sponsoring contents
E
[
C
(
B + ùúÉmin (ŒõK, B) + ùúÉbin
((ŒõK ‚àíB)+ , Q (B)
))]
‚àíE [C (B + ùúÉbin (ŒõK, Q (0)
))]
always increases in B. The change of the refill revenue
dùúè(B) ‚àídùúè(0) = dK(1 ‚àíùúí) [p0(B)P0(B) ‚àíp0(0)P0(0)]
(10.8)
is always negative because from Eq. (10.6),
p0(B)P0(B) = p1(B)P1(B)‚àïùúí,
and the right-hand side decreases in B.
In comparison with Case 1, the additional advertisement revenue in Eq. (10.7) is
higher here because Q(B)(‚â°q0P0(B)) increases in B instead of being fixed. This extra
reward is accrued by the CP. On the other hand, the last component Eq. (10.8) shows

REFERENCES
287
an additional negative profit impact of content sponsoring, the cannibalization of the
SP‚Äôs refill revenue because of slower use of EUs‚Äô quotas. Like the bandwidth cost,
this loss of revenue is assumed by the SP. To recoup its loss and share the extra gain,
it is in the SP‚Äôs best interest to require a more demanding transfer payment than that
in Case 1 from the CP.
10.4
SUMMARY
In this chapter, we have introduced some of the natural research questions that arise
if content providers in a wireless network are allowed to sponsor their content and
thereby make it free to EUs. We considered the case of a single content provider, a
single service provider, and a pool of EUs and showed that it is possible to design
contracts that are win‚Äìwin‚Äìwin for all participants in system. This was first done
in a setting where EUs pay for nonsponsored content on a per-byte basis. We then
extended the model to incorporate EU data quotas. A key feature of all the models
that we considered is that the content has uncertain demand, that is, the number of
potential views is a random variable. This naturally led to a two-component price
structure with a reservation fee and a usage fee.
We believe that this work can be extended in a number of natural ways. First, many
interesting questions arise when we consider multiple content providers interacting
with a single SP. For example, how should the SP decide which CPs should be allowed
to sponsor content? Moreover, if different content has a different value of q (i.e., the
probability that an EU views nonsponsored content is dependent on the identity of
that content), how should that affect the cost of sponsoring?
Other potential variations include making the cost of sponsoring dependent on the
user location, the time of day, or the current congestion in the network. We can also
envisage a situation where sponsored content is provided its own quality-of-service
guarantees by the network. Lastly, our entire framework is predicated on the knowl-
edge of a number of different parameters, for example, a, q, and the distribution of
N. One interesting network measurement task would be to monitor current network
traffic and then estimate each of these parameters.
REFERENCES
1. S. Ha, S. Sen, C. Joe-Wong, Y. Im, and M. Chiang. Tube: time-dependent pricing for mobile
data. In SIGCOMM, pp. 247‚Äì258, 2012.
2. P. Hande, M. Chiang, A. Calderbank, and S. Rangan. Network pricing and rate allocation
with content provider participation. In INFOCOM, pp. 990‚Äì998, 2009.
3. Y. Wu, H. Kim, P. H. Hande, M. Chiang, and D. H. K. Tsang. Revenue sharing among ISPs
in two-sided markets. In INFOCOM, pp. 596‚Äì600, 2011.
4. N. Economides and B. E. Hermalin. ‚ÄúThe economics of network neutrality,‚Äù RAND Journal
of Economics, 43(4), 2012, 602‚Äì629.

288
ECONOMIC MODELS OF SPONSORED CONTENT
5. D. Mitra and Q. Wang. A model-based study of the impact of managed services and the
spawning of applications in broadband networks. Workshop on Telecom Economics, Engi-
neering and Policy, 24th International Teletraffic Congress (ITC 2012), 2012.
6. P. Njoroge, A. Ozdaglar, N. Stier-Moses, and G. Weintraub. Investment in two sided markets
and the net neutrality debate. In Columbia Working Paper # DRO-2010-05, 2010.
7. B. A. Pasternack. ‚ÄúOptimal pricing and return policies for perishable commodities,‚Äù Mar-
keting Science, 4(2), 1985, 166‚Äì176.
8. G. P. Cachon. ‚ÄúSupply chain coordination with contracts,‚Äù Handbooks in Operations
Research and Management Science, 11, 2003, 229‚Äì340.
9. L. He and J. Walrand. Pricing and revenue sharing strategies for internet service providers.
In INFOCOM 2005, pp. 205‚Äì216. IEEE, 2005.

11
CDN Pricing and Investment
Strategies under Competition
YANG SONG, LIXIN GAO, and ARUN VENKATARAMANI
11.1
INTRODUCTION
A content delivery network (CDN) is a large distributed system that caches content
at multiple locations on the Internet. When an end user makes a request, a CDN
chooses the best server (usually the nearest one) to serve the content. CDNs enhance
the user-perceived experience by reducing the delay and improving the availability
of the content. By aggregating traffic across different content producers, CDNs also
save individual investments in infrastructure for peak demand.
Owing to the technological and economical advantages, the CDN market has
developed rapidly since its conception. The tremendous growth of Internet content
further boosts the market. Today, 35‚Äì45% of the backbone traffic is from CDNs [1].
The majority of CDN traffic is delivered by three CDNs: Akamai technologies
(Akamai for short), Level 3 Communications (Level 3 for short), and Limelight
networks (Limelight for short). Their respective shares of the total CDN traffic are
48%, 25%, and 18% [2]. The rest of the CDN traffic is carried by relatively smaller
CDNs such as Edgecast networks and Amazon CloudFront.
With CDNs competing with each other to attract business from content producers,
the impact of this competition on shaping the CDN market is poorly understood.
The unit price of CDN service has been dropping by more than 15% for at least five
consecutive years [3]. It is unclear whether the dropping prices may result in a price
war wherein no CDN can remain profitable. Recent events such as Level 3 charging a
lower price than Akamai‚Äôs to attract Netflix‚Äôs video content drew a lot of attention [4,
5]. In light of such events, it is important to establish a rigorous technical foundation to
understand and analyze pricing strategies practiced by CDNs and maintain a healthy
market to benefit all participants.
Not only pricing competition is heated among CDNs but CDN market structure
is also forced to change because of dramatic traffic increase (video traffic in par-
ticular). The growing traffic attracts potential new players to enter the market and
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
289

290
CDN PRICING AND INVESTMENT STRATEGY UNDER COMPETITION
motivates incumbent players to expand and improve. For example, several Internet
service providers (ISPs) attempt to build their own CDN service [6], and multiple
Tier-1 ISPs and regional ISPs have already done so [7]. The incumbent players such
as Akamai and Level 3 keep expanding their footprints [8, 9]. The changing structure
not only makes the market highly competitive but also introduces complex dynamics.
As a result, it is hard for both newcomers and incumbents to make wise decisions.
For example, is it economically beneficial for a new CDN to enter the market? How
much investment should one make? We need a theoretical model to guide decisions
under a market structure that is changing constantly.
CDNs form a market with unique features. CDNs deploy servers close to end users,
including computers or devices that request the content. Depending on the servers‚Äô
locations, end users may receive various service qualities. For example, end users
in China are likely to see little improvement in service quality by going through a
CDN that has no cache presence in Asia. We refer to the set of end users who can
receive improved service quality through a CDN as the coverage of the CDN. In
other words, the set of end users is covered by the CDN. CDNs get paid by con-
tent providers for delivering their content to end users. Ideally, a content producer
will select a CDN that covers all of its end users. However, in most cases, even
the biggest CDN may not be able to include all the end users of a content pro-
ducer. Content producers thus may select different CDNs for different end users. As a
result, a content producer can subscribe to multiple CDNs at the same time [10]. We
refer to the market where a customer can simultaneously select multiple providers
as multiple-choice market. The multiple-choice market is different from the classical
single-choice market where only one provider is chosen from a set of mutually exclu-
sive alternatives. The single-choice market assumes that the alternatives can perfectly
substitute for each other. For example, a cell phone user only needs to subscribe to
one service provider for all the phone calls, no matter where the callee is located.
We demonstrate that the multiple-choice markets can be prone to price wars. We pro-
vide sufficient conditions for price wars in two-CDN pricing games and propose an
incentive-compatible pricing strategy to avoid them.
Another unique feature of the CDN market is that CDNs, especially smaller CDNs,
are open for cooperation. Large CDNs are more appealing to large content producers,
which usually require a broad coverage and a big capacity. Because the majority of
Internet traffic is generated by large content producers [11], if small CDNs federate
with each other to become a big CDN, they can attract more traffic than the total traffic
they attract as individual CDNs. Not surprisingly, several CDNs have already formed
a federation in order to compete more directly with the big CDNs in the market [12].
However, we show that CDN federation is not always beneficial for small CDNs. It
is important to derive conditions of a profitable federation and instruct small CDNs
to act accordingly.
With all the unique features of the CDN market, it is interesting to know how
efficient this type of market is and how selfish behavior can degrade the efficiency.
The results will be valuable for any multiple-choice market.
In this chapter, we address the challenges described earlier. We first focus on CDN
pricing. We introduce a game-theoretic model to analyze the price competition among

RELATED WORKS
291
CDNs. We derive sufficient conditions for price wars in a two-CDN pricing game.
Then we prove that if CDNs incorporate future impact into current decision making,
then price wars can be avoided. We proceed to introduce a predictive pricing strat-
egy that is both incentive-compatible and efficient. That is, either CDN that deviates
from the strategy will get a lower utility, and the total utility under the strategy is
at least two-thirds of the social optimal utility. Then, we discuss a model to analyze
the price competition for n-CDN games. We provide pricing strategies under vari-
ous market structures through empirical analysis. The result shows that CDNs with
bigger coverage always attract more traffic and charge a higher price.
Next, we focus on CDNs‚Äô investment strategies. We formulate a dynamic CDN
game where the market structure, for example, the number of CDNs and their corre-
sponding coverage, can be changed. We first analyze market changes caused by CDN
federation and provide the conditions for small CDNs to benefit from a CDN federa-
tion. Then, we consider market changes because of new CDNs‚Äô entry and incumbent
CDNs‚Äô investment and exit. The game is complicated by the fact that a CDN must
consider the actions of its rivals while determining the best reaction scheme. Using
the Markov perfect equilibrium approach, we derive the best investment strategy in
the dynamic market. More importantly, we show that the investment strategy can
lead to an equilibrium state that achieves up to 90% of the social optimal utility. The
result indicates that the competition in multiple-choice markets can be efficient, and
it may not be necessary for policy makers to interfere with a multiple-choice market
to improve its social utility. The conclusion is applicable for any market with similar
features.
The rest of the chapter is organized as follows. We begin by providing an
overview of previous works and background in CDN economics (Section 11.2
and Section 11.3). Section 11.4 discusses the content producers‚Äô CDN selection
problem. We then present the pricing and development strategy in Sections 11.5
and 11.6. Lastly, we conclude this chapter in Section 11.7.
11.2
RELATED WORKS
We will introduce three research areas that are closely related to CDN economics
under competition. We first show the studies on the pricing of a monopoly CDN.
Then we talk about the economics of CDNs as a part of the content delivery chain.
Lastly, we introduce the difference between CDN market and several well-known
multiple-choice markets.
11.2.1
The Pricing of a Monopoly CDN
We first introduce the pricing models used in the CDN industry. The most common
model is to charge based on traffic volume delivered by a CDN over a period of time,
for example, a month. This pricing model usually offers a volume discount, the larger
the volume, the more the deduction [16]. The disadvantage of this volume-based
model is that it fails to consider the bursty traffic [17], which can demand a costly

292
CDN PRICING AND INVESTMENT STRATEGY UNDER COMPETITION
investment from CDNs. The second pricing model enables CDNs to charge based
on the bursty traffic. With the second charging model, a CDN periodically monitors
the bandwidth usage and charges customers according to the 95-percentile usage. In
this case, customers commit to a maximum bandwidth usage in advance. If the actual
usage goes over the commitment by more than 5%, a penalty may be charged. The last
pricing model is based on request. A customer is charged by the number of requests
served by a CDN. This model is not widely used. A CDN may provide all types of
pricing models, and customers can select the one that is best for their business.
Previous works on CDN pricing mainly focus on the best pricing scheme of a
monopoly CDN when facing multiple heterogeneous content producers [18‚Äì20].
Content producers are given the option of either self-provisioning or subscribing to a
CDN. Content producers‚Äô decisions are a function of the CDN‚Äôs pricing scheme. The
studies [19, 20] show that the optimal pricing scheme is determined by the patterns
of the traffic. When traffic is Possion, CDNs should provide volume discounts to
content providers. While facing bursty traffic and the burst varies across content
providers, volume discounts can be suboptimal. In this case, a percentile-based
pricing is more profitable than volume-based pricing.
Because of the rapid development of the CDN market, the monopoly CDN model
may not be suitable for the current situation any more. As we have mentioned in
Section 11.1, a content producer can subscribe to multiple CDNs at the same time.
Under this situation, a CDN‚Äôs price is mainly driven by the heated competition among
CDNs rather than traffic patterns. In this chapter, we study the pricing schemes under
competition.
11.2.2
CDNs in Content Delivery Supply Chain
Before CDNs and big content providers became big players, the supply chain of the
Internet was clear and simple. Essentially, small networks (including content produc-
ers, CDNs and access networks) purchased transit from backbone networks, that is,
they establish transit relationships, and both backbone networks and small networks
peered among themselves to exchange traffic for free. However, as CDNs and content
producers emerge as the biggest traffic contributors in the Internet [11], it becomes
unclear which side gains more benefit from the connections, the content or the transit.
Thus, it is hard to judge who should get paid in the supply chain. Transit networks
argue that delivering the high volume content involves huge cost, and thus content
producers or CDNs should pay for the service. On the other hand, content producers
and CDNs insist that their content and service are valuable and help transit networks
attract end users. There are many papers addressing the network neutrality debate [21,
22], and in this chapter, we focus on the debate that involves CDNs.
The debate is highlighted by a recent event between Level 3 (a backbone network
and a CDN) and Comcast (an access network) [23, 24]. Originally, the relationship
between Level 3 and Comcast is peering. In late 2010, Level 3 started to carry the
traffic from Netflix, which significantly increased the traffic sent from Level 3 to
Comcast. Level 3 then informed Comcast that they needed to add additional inter-
connect capacity. Comcast rejected the request, citing that their relationship was no

RELATED WORKS
293
longer peering because the traffic exchanged was unbalanced and requested Level 3
to pay for the connection. Level 3 eventually paid Comcast for the extra traffic. The
result is supported by a study of Clark and Bauer [5]. Their paper points out that it is
economically efficient for a CDN to pay access networks.
A number of studies formulate models to describe the position of CDNs in the
Internet supply chain. One popular model involves two-sided markets [25]. It com-
bines the access networks and the CDNs together as one platform and analyzes the
best policy for the platform facing end users on one side and content producers on the
other. In another related paper, Chuang [4] argues that the network structure is better
measured under bilateral oligopoly relationship as shown in Figure 11.1. Compared
with the two-sided market model, bilateral oligopoly preserves the market power for
both CDNs and access networks, and it is capable of analyzing the competition within
both CDN and access networks. According to the author, the competition is an indis-
pensable factor to maintain economical sustainability in the Internet. Although the
bilateral oligopoly relationship is of great interest, as far as we know, it has not been
used by any analytical model. We try to take the first step toward the goal by focus-
ing on the competition in the locus of CDN market (marked by the dashed line in
Fig. 11.1). Because the relationship between CDNs and content producers has sev-
eral unique properties that are ubiquitous among entities in the Internet, for example,
customers can subscribe to several CDNs at the same time, and CDNs have both
overlapped and unique service ranges, analyzing the competition between CDNs and
content producers can provide useful insight for other competition in the Internet as
well.
11.2.3
Compare CDN and Other Multiple-Choice Markets
There are many markets where customers face multiple choices. For example, a firm
or a company may purchase multiple units of computers from multiple brands to meet
their needs; a household may have multiple vehicles for different usages; and on one
trip to a grocery store, customers regularly purchase multiple products on carbonated
soft drinks, ready-to-eat cereals, canned soups, and so on. The previous research in
this area focuses on modeling customers‚Äô multiple-choice behavior as firms‚Äô poli-
cies, customers‚Äô preference and demographics, and other related parameters change.
Dube [26] proposed a model to analyze customers‚Äô multiple choices on carbonated
End
users
End
users
Access
network
Access
network
CDN
CDN
Content
producer
Content
producer
Figure 11.1
Bilateral oligopoly model.

294
CDN PRICING AND INVESTMENT STRATEGY UNDER COMPETITION
soft drinks, and used the model to predict customers‚Äô future purchase. Hendel [27]
developed a model to characterize firms‚Äô computer purchase behavior. Chandra Bhat
and Sen [28] designed a model not only to estimate vehicle holdings in a family but
also to predict the miles of travel for each vehicle. All these previous models focus
on one-time multiple-choice purchase rather than a series of purchases that happen
over time. There are two reasons that these models do not need (and never intend)
to consider the market and customer behavior change over time. First, the markets
addressed in these models are relatively stable. The number of competitors and their
efficiency tend to stay consistent, and prices are also steady. Second, goods sold in
these markets are durable and usually last a while after purchase. However, the CDN
market is a different type of multiple-choice market. First, the CDN market sells ser-
vice and charges content producers based on usage. It is easy for customers to switch
among CDNs. Second, the CDN market exhibits high dynamics. New CDNs enter
the market constantly, and incumbent CDNs keep expending their coverages, and the
pricing of the CDN market changes dramatically. In the dynamic CDN market, we
are not only interested in how customers make multiple-CDN selection as the market
state changes, but more importantly, we also want to understand how CDNs survive
and compete with customers‚Äô multiple-choice behavior and whether the competition
is efficient and sustainable over the long term.
11.3
BACKGROUND
11.3.1
Static Analysis
In economics, competition is the rivalry among firms or providers that aim to achieve
higher utilities, market share, and so on by adjusting the price, investment, innova-
tion, or other marketing strategies [29]. Competition in economics has a long history
stretching back to the nineteenth century. The original work was introduced in Ref-
erence 14 by Cournot. Cournot‚Äôs model assumes that the demand in the market is
a decreasing function of price and the competing firms choose quantities of a good
to produce in order to maximize their own utility. The conclusion is that every firm
eventually chooses the same quantity to produce and earns positive utility. As the
number of firms increases, the price approaches marginal cost. Following the work
of Cournot, Bertrand [13] took a different analysis approach. In Bertrand‚Äôs model, the
quantity is determined solely by the demand in the market and firms control prices
rather than quantity. As a result, customers only purchase the good from the firm with
the minimum price. The final outcome is an equilibrium where any firm in the market
has zero utility. Since the two original papers, there have been a variety of models that
discuss the competition among firms. Some of them produce more realistic results
with the assumption that the firms are willing to supply only up to a quantity that
maximizes their utility [30, 31]. Others focus on differentiated goods. For example,
the Hotelling model [32] assumes that the goods associate with a cost depending on
the location of the firms.
The previous models we introduced assume that an action has no long-term effect,
for example, when a firm needs to make a decision, it ignores what other firms would

BACKGROUND
295
do to react to its action in the future. The models also assume the state of the market,
for example, the number of firms or the efficiency of each firm, is static. We refer
to the analysis on games with only immediate impact and static market state as the
static analysis. In the following subsections, we relax the constraints and introduce
more realistic models to analyze the competition.
11.3.2
Predictive Analysis
One of the important factors that the static analysis rules out is the impact of com-
petitors‚Äô current actions on the future. If actions are made with respect to the future,
the same competitors may behave very differently. Repeated games capture the idea
that a player takes into account the impact of his/her current action on the future. In a
repeated game, a base game (or called a stage game) is played in finite or infinite rep-
etitions with prediction. We name the analysis used in repeated games the predictive
analysis.
We take the prisoners‚Äô dilemma as an example. In the classical version of the
game, two prisoners are arrested and under investigation. If neither of them con-
fesses, both of them will be sentenced to 1 year. If one of them confesses and the
other keeps silence, then the one who confesses will be set free, and the other one
will be sentenced to 3 years. If both of them confess, then both of them will get 2
years. Table 11.1 shows the utility of the prisoners with different actions. Note that,
the longer the sentence, the lower the utility.
Suppose the game is played iteratively with the same pair of prisoners. We first
assume no prisoner is concerned about the future impact. Then any rational prisoner
would confess, because if they only consider the gain of the current iteration, con-
fession always rewards more than silence. Thus, the only possible outcome in every
iteration is that both prisoners confess. The interesting part of this result is that pur-
suing individual reward logically leads the prisoners to confess, but they would get a
better reward if they both keep silence. The utility gained by each prisoner over time
will be
Us = 0 + ùõø‚ãÖ0 + ùõø2 ‚ãÖ0 + ùõø3 ‚ãÖ0 + ¬∑ ¬∑ ¬∑
= 0,
(11.1)
where ùõø< 1 is a discount factor. The discount factor indicates the value reduction for
the future utility because the future utility cannot be obtained immediately.
Next, we assume that every prisoner makes decisions knowing that, in the next
iteration, the other prisoner will act based on his/her current action. In this case, the
TABLE 11.1
Utility of Prisoners
Prisoner 1: Silence
Prisoner 1: Confession
Prisoner 2: Silence
Both get 2
Prisoner 1: 3, prisoner 2: ‚àí1
Prisoner 2: Confession
Prisoner 1: ‚àí1, prisoner 2: 3
Both get 0

296
CDN PRICING AND INVESTMENT STRATEGY UNDER COMPETITION
outcome will be changed. The strategy of prisoners is (i) always keep silence in the
first iteration and (ii) if the other prisoner also keeps silence, then play silence in the
next iteration; otherwise, always confess in all the future iterations. We will show in
the following text that prisoners always have incentive to keep silence if the discount
factor is small. If a prisoner keeps silence in the current iteration, the utility Us he/she
gets is
Us = 2 + ùõø‚ãÖ2 + ùõø2 ‚ãÖ2 + ùõø3 ‚ãÖ2 + ¬∑ ¬∑ ¬∑
=
2
1 ‚àíùõø.
(11.2)
In this case, both prisoners will play silence in every iteration and earn a utility of 2.
If a prisoner confesses, then the utility Uc he/she gets is
Us = 3 + ùõø‚ãÖ0 + ùõø2 ‚ãÖ0 + ùõø3 ‚ãÖ0 + ¬∑ ¬∑ ¬∑
= 3.
(11.3)
Although the confessed prisoner earns a high utility in the first iteration, he/she
will get 0 for all the future iterations. Note that, as long as the discount factor is
larger than 1
3, silence is always a better strategy than confession.
We can see that the future impact may dramatically change players‚Äô strategy. This
is because the promise of future reward or the threat of future punishment provides
incentive for both players to cooperate in the current iteration.
Although predictive analysis models the impact of the current actions on the future,
it fails to model the state change of the game. For example, in the prisoners‚Äô dilemma
game, we assume the utility gained under the same condition is constant. However,
the utility may change over time in reality. If silence no long gives a utility of 2 but
0, then the prisoners‚Äô strategy should be changed accordingly. In general, the state
change can be driven by both internal or external forces. An internal force can be a
firm‚Äôs investment or improvement in its technology, and an external force can be the
outside market shock that may change the demand in the market we are interested in.
The next model we introduce helps us to handle the case where the game state can
change.
11.3.3
Dynamic Analysis
Both static and predictive analysis assume that the state of the game, for example,
the efficiency of the firms or the number of competitors, stays the same over time.
However, this assumption is not always true in reality. For example, players or firms
can actively impact their efficiency by reducing their cost or adopting a new technol-
ogy, and they can also change the total number of players by entering or exiting the
game. The state of the game can also be changed by external causes. For example,
the demand of customers can decrease if an outside alternative emerges. Introducing
the state change can make the analysis more complicated, but it can provide useful
insight for more realistic scenarios.

BACKGROUND
297
11.3.3.1
One-Player Dynamic Analysis We start with the simplest case, where
there is only one player. We assume the base game is played iteratively. The utility
that the player gains at time t is
Ut = ùúã(ùúît, xt),
(11.4)
where ùúît is the state of the game and xt is the action taken by the player at time t. The
utility over time is thus
U =
‚àû
‚àë
t=0
ùúã(ùúît, xt).
(11.5)
The state of the game can change over time. The state at time t + 1 is determined by
the previous state, the action taken, and the outside market change. That is, ùúît+1 =
T(ùúît, xt, ot), where ot represents the change from the outside.
The goal of the game is to determine the best action to maximize the player‚Äôs
utility over time. Maximizing utility over time is equivalent to solving the following
maximization problem.
max {U} = maxx
{ ‚àû
‚àë
t=0
ùúã(ùúît, xt)
}
.
(11.6)
Define a new function V = max {U} and assume the initial state is ùúî0, then Eq. (11.6)
will be expanded as follows.
V(ùúî0) = max {U} = maxx
{ ‚àû
‚àë
t=0
ùúã(ùúît, xt)
}
= maxx0
{
ùúã(ùúî0, x0) + ùõø
[
maxx
‚àû
‚àë
t=1
ùõø(t‚àí1)ùúã(ùúît, xt)
]}
= maxx0
{ùúã(ùúî0, x0) + ùõøV (ùúî1)}
= maxx0
{ùúã(ùúî0, x0) + ùõøV (T (ùúî0, x0, o0))} .
(11.7)
Drop the time subscripts, we get
V(ùúî) = maxx {ùúã(ùúî, x) + ùõøV(T(ùúî, x, o))} .
(11.8)
We refer to Eq. (11.8) as the value equation of the one-player dynamic game. Similar
to solving the Bellman equations [33], we can solve Eq. (11.8). The solution is a
reaction function x = R(ùúî), which gives the best reaction x under state ùúî. We name the
reaction function the optimal action or strategy. We will briefly talk about a numerical
method to solve Eq. (11.8). Please refer to References 33‚Äì35 for other methods to
solve the equation.
Rewrite Eq. (11.8) in the iterative form
Vk(ùúî) = maxx
{ùúã(ùúî, x) + ùõø(Vk‚àí1 (T (ùúî, x, o))
)} ,
(11.9)

298
CDN PRICING AND INVESTMENT STRATEGY UNDER COMPETITION
where Vk(ùúî) represents the result derived from the k-th iteration. Start with k = 1. Let
V0(ùúî) be any bounded function that maps ùúîto a real number. Solve the maximization
function on the right side of the equation by letting the derivative of x equal to 0.
Replace x with the solution of the maximization function, and then we get the function
of V1(ùúî). Next, let k = 2, and solve the right side with V1(ùúî) and get V2(ùúî). Repeat
the process until ||Vk(ùúî) ‚àíVk‚àí1(ùúî)|| ‚â§ùúÄ, where ùúÄis the desired degree of accuracy.
11.3.3.2
Multiple-Player Dynamic Analysis In the previous subsection, we focus
on the case where there is only one player in the game. Now, we discuss the case where
n players are involved. Player i, where i = 1, ‚Ä¶ , n, solves the following maximization
function to maximize his/her utility over time:
max {Ui (ùúî)
} = max
{ ‚àû
‚àë
t=0
ùúãi
(ùúît, xt
i
)
}
,
(11.10)
where ùúãi and xi are player i‚Äôs utility and action. Note that, for a n-player
game, the state of the game depends on all players‚Äô actions. That is, ùúît+1 =
T(ùúît, xt
1, ‚Ä¶ , xt
i, ‚Ä¶ , xt
n, ot). Define a new function Vi(ùúî) to be ‚Äúmax {Ui(ùúî)},‚Äù and
then player i‚Äôs value equation can be written as
Vi (ùúî) = maxxi
{ùúãi
(ùúî, xi
) + ùõø(Vi
(T (ùúî, x1, ‚Ä¶ , xi, ‚Ä¶ , xn, o)))} .
(11.11)
The solution of the n-player game is n reaction functions R1, ‚Ä¶ , Ri, ‚Ä¶ Rn, where
xi = Ri(ùúî), and we name them the optimal action or strategy. Pakes and McGuire [34]
and Ericson and Pakes [35] propose a method to solve Eq. (11.11). We will briefly
introduce this method.
The iterative forms of the n players‚Äô value equations are as follows:
Vk+1
1
(ùúî) = maxxk
1
{ùúã(ùúî, xk
1
) + ùõøVk
1
(T (ùúî, xk
1, ‚Ä¶ , xk
i , ‚Ä¶ , xk
n, o))}
(11.12)
Vk+1
2
(ùúî) = maxxk
2
{ùúã(ùúî, xk
2
) + ùõøVk
2
(T (ùúî, xk
1, ‚Ä¶ , xk
i , ‚Ä¶ , xk
n, o))}
(11.13)
¬∑ ¬∑ ¬∑
Vk+1
n
(ùúî) = maxxkn
{ùúã(ùúî, xk
n
) + ùõøVk
n
(T (ùúî, xk
1, ‚Ä¶ , xk
i , ‚Ä¶ , xk
n, o))} ,
(11.14)
where Vk
i is the function derived from the k-th iteration. To derive Vk+1
i
, we let the
derivative of the function on the right side equal to 0. That is,
{ùúã(ùúî, xk
1
) + ùõøVk
1
(T (ùúî, xk
1, ‚Ä¶ , xk
i , ‚Ä¶ , xk
n, o))}‚Ä≤ |||xk
1
= 0
(11.15)
{ùúã(ùúî, xk
2
) + ùõøVk
2
(T (ùúî, xk
1, ‚Ä¶ , xk
i , ‚Ä¶ , xk
n, o))}‚Ä≤ |||xk
2
= 0
(11.16)
¬∑ ¬∑ ¬∑
{ùúã(ùúî, xk
n
) + ùõøVk
n
(T (ùúî, xk
1, ‚Ä¶ , xk
i , ‚Ä¶ , xk
n, o))}‚Ä≤ |||xkn
= 0.
(11.17)

BACKGROUND
299
By solving the system of nonlinear equations, we can get xk
i as a function of ùúî,
denoted by xk
i = f k
i (ùúî). Note that, the system of equations may not be easy to solve,
because they include n variables. We can use the methods in References 34 and 35
to simplify the process. In the i-th equation of the system, replace xk
j by the function
f k‚àí1
j
(ùúî) derived from the previous iteration, where j = 1, ‚Ä¶ , n and j ‚â†i. Then, the
equations become
{ùúã(ùúî, xk
1
) + ùõøVk
1
(T (ùúî, xk
1, f k‚àí1
2
, ‚Ä¶ , f k‚àí1
n
, o))}‚Ä≤ |||xk
1
= 0
(11.18)
{ùúã(ùúî, xk
2
) + ùõøVk
2
(T (ùúî, f k‚àí1
1
, xk
2, ‚Ä¶ , f k‚àí1
n
, o))}‚Ä≤ |||xk
2
= 0
(11.19)
¬∑ ¬∑ ¬∑
{ùúã(ùúî, xk
n
) + ùõøVk
n
(T (ùúî, f k‚àí1
1
, ‚Ä¶ , f k‚àí1
n‚àí1 , xk
n, o))}‚Ä≤ |||xkn
= 0.
(11.20)
As a result, we reduce the n-variable system of nonlinear equations to n one-variable
equations. This significantly reduces the computational cost.
Compared to static analysis and predictive analysis, dynamic analysis allows the
state of games to change, and thus it can provide a solution suitable for more realistic
scenarios. However, we can also see that deriving the optimal strategy using dynamic
analysis can be hard and, in most cases, we can only use numerical methods to solve
the problem. Dynamic analysis is explicitly summarized in the original works [34,
35]: ‚Äúwe give up on analytic elegance in favor of an ability to numerically analyze
the more complex situations that might better approximate what is observed in real
data or situations.‚Äù
11.3.3.3
Applications of Dynamic Analysis Dynamic analysis has been widely
used to study a variety of markets under a dynamic state [15]. A number of
papers apply dynamic analysis to show how policies can change the market state.
Gowrisankaran and Town [36] use it to examine the hospital industry. It formulates a
model where patients choose admission to a single hospital, while hospitals choose
investment, entry, exit, and pricing strategies. They demonstrate the effect of policies
such as universal health care or medicare reimbursement on hospitals‚Äô development
decisions. Ryan [37] uses dynamic analysis to study the impact of environmental
regulations on the cement industry where each customer selects one firm for cement
supplement. The author shows that 1990 Amendments to the Clean Air Act on the
US Portland cement industry has significantly increased the sunk cost of entry. The
author also shows that static analysis can miss the welfare penalty on customers and
draw a wrong conclusion on the amendments‚Äô effect on incumbent firms. Dynamic
analysis is also used to explain industry structure and dynamics. For example,
Lainz [38] uses the model to show that cost increase can result in the increase of
firms‚Äô sizes in the market. Dynamic analysis has also proved to be useful to study
mergers [39] and technology adoption [40]. In this chapter, we use dynamic analysis
to study multiple-choice markets (CDN market in particular). The customers in
multiple-choice markets make provider selection in a fine-grained manner, and the

300
CDN PRICING AND INVESTMENT STRATEGY UNDER COMPETITION
feature distinguishes it from all the markets mentioned earlier. We explore the
best development strategy in this type of market and demonstrate what the market
structure is at the equilibrium state and how efficient the market is in terms of price
of anarchy.
11.3.4
Summary
In this section, we introduce three analytical models to characterize competition in
economics. Static analysis ignores the impact of a current action on the future and
the market state change. Predictive analysis considers the impact but it ignores the
market state change. Dynamic analysis can model the market state change but the
computation cost can be high. In the following sections, we use these methods to
characterize the competition among CDNs.
11.4
CONTENT PRODUCERS‚Äô CDN SELECTION PROBLEM
We introduce two methods to model content producers‚Äô CDN selection. The first
one models the coverages of CDNs with a Venn diagram, and it is capable of
explicitly representing coverage overlaps among CDNs. We refer to the model as
the precise-coverage model. It is obvious that the precise-coverage model does not
scale well, because the regions in the Venn diagram increase exponentially as the
number of CDNs increases. The second method is more suitable for large-scale
analysis. It ignores the overlaps and uses the size to quantify CDNs‚Äô coverages
approximately. The simplification makes it easy to scale. We refer to the model as
approximate-coverage model.
In both models, we assume that content producers make decisions independently.
This allows us to focus on one content producer, named S. S may select one or mul-
tiple CDNs from N available ones, represented by D1, ‚Ä¶ , Di, ‚Ä¶ , DN. The selection
depends on their performance and prices.
In reality, a CDN‚Äôs performance is determined by many factors, including cover-
age, cache size at the CDN servers, congestion level, server selection algorithms, load
balancing algorithms, traffic demand patterns, and network conditions. However, one
of the most dominant factors is the coverage. In this chapter, we select the coverage
as the single metric to measure CDNs‚Äô performance.
11.4.1
Precise-Coverage Model
The precise-coverage model describes the universe of S‚Äôs end users in a Venn dia-
gram as shown in Figure 11.2. Each circle represents the perceived coverage of a
CDN. The circles divide the universe into subsets. We use GI to represent the subset
that is exclusively covered by a group of CDNs whose indexes are in the set, I. For
example, G{1} represents the subset of end users who are covered by D1 only and
G{1,2} represents the end users who are covered by both D1 and D2. Note that, G{1}
and G{1,2} are subsets that do not overlap. Figure 11.2 shows the universe of end users

CONTENT PRODUCERS‚Äô CDN SELECTION PROBLEM
301
U
G{1}
G{12}
G{123}
G{23}
G{2}
G{3}
G{13}
Gœï
Figure 11.2
Divide end users into eight groups according to CDNs‚Äô perceived coverage.
who are divided into eight subsets by three CDNs. The traffic volume that S sends to
GI is represented by vGI.
If a subset is served by a CDN that covers the region, then each unit of traffic gets
benefit ùúÇ1. If a subset is served by a CDN that does not cover it, the benefit is ùúÇ2.
Apparently, ùúÇ1 > ùúÇ2. Suppose pi is the price charged by Di. Then, S chooses Di for
GI if and only if S prefers it over all the alternatives. That is,
ùúÇGI
i
‚àípi > ùúÇGI
q ‚àípq,
(11.21)
where q = 1, 2, ‚Ä¶ , N and q ‚â†i. If Di covers GI, ùúÇGI
i
= ùúÇ1. Otherwise, ùúÇGI
i
= ùúÇ2. The
CDN selection problem is equivalent to the following maximization problem. Select
the best CDNs so that
ùúãs =
‚àë
GI
maxDi
{
ùúÇGI
i
‚àípi
}
vGI.
(11.22)
If several CDNs provide the same utility, then S divides traffic evenly among them.
We use an M √ó K matrix named E to represent S‚Äôs CDN selection. The rows of
E represent CDNs, and the columns represent end users‚Äô subsets divided by CDNs‚Äô
perceived coverages. Therefore, K = 2M. Eij is the percentage of subset j‚Äôs traffic that
is delivered by Di. As a result, the utility of S can be written as
ùúãs =
K
‚àë
j=1
N
‚àë
i=1
[
Eij
(
ùúÇ
Gj
i
‚àípi
)
vGj
]
.
(11.23)
11.4.2
Approximate-Coverage Model
The precise-coverage model is able to provide fine-grained details about coverage.
But the model does not scale well. The next model we will introduce is more suitable
for a large number of CDNs.
We use parameter ùõºi to represent content producer S‚Äôs perceived coverage of CDN
Di, where 0 ‚â§ùõºi ‚â§1. The parameter reflects how well Di can serve S‚Äôs need. Thus,

302
CDN PRICING AND INVESTMENT STRATEGY UNDER COMPETITION
the parameter changes as Di‚Äôs coverage or S‚Äôs need changes. The larger Di‚Äôs coverage,
the larger ùõºi, and the higher S‚Äôs traffic volume, the smaller ùõºi.
To enable S to make multiple-CDN selection, we assume S‚Äôs benefit from Di is
equal to ùúâ(vi + ùõæ)ùõºi, where vi is the traffic volume served by Di, and ùúâand ùõæare
constants whose values stay the same across different CDNs. This benefit function is
increasing and concave. The increasing property means that the more traffic volume
S sends to Di, the more benefit. The concave property indicates that the increase in
the benefit generated by a one-unit volume increase becomes smaller as the total
volume increases. The ‚Äúdiminishing return‚Äù as volume scales enables S to split traffic
to multiple CDNs rather than use one CDN for all the traffic. This model has been
widely used by multiple discrete choice analysis (refer to Reference 41 for details).
S‚Äôs utility gained from Di is the benefit minus price: ui = ùúâ(vi + ùõæ)ùõºi ‚àípivi. The total
utility of S then can be written as U = ‚àëN
i=1 ui = ‚àëN
i=1(ùúâ(vi + ùõæ)ùõºi ‚àípivi). Suppose the
total traffic of S is Vs, then S‚Äôs CDN selection problem is equivalent to the following
optimization problem. Choose the optimal vi so that
max U =
N
‚àë
i=1
(ùúâ(vi + ùõæ)ùõºi ‚àípivi)
(11.24)
s.t.
N
‚àë
i=1
vi ‚â§Vs.
(11.25)
Note that ‚àëN
i=1 vi can be smaller than Vs, because S‚Äôs traffic can be delivered by ISPs
directly.
In order to make the CDN selection problem scale, the approximate-coverage
model simplifies the way to describe the service quality that S receives from CDNs.
The model uses a single parameter ùõºi to represent S‚Äôs perceived coverage size for Di
and implicitly assumes that the perceived coverage size is the only parameter to deter-
mine Di‚Äôs service. An important factor that the approximate-coverage model ignores
is the overlap among CDNs. If a CDN‚Äôs coverage is already covered by other CDNs,
no matter how big its coverage is, using the CDN may provide little improvement for
S‚Äôs end users‚Äô experience. The precise-coverage model is able to describe the cover-
age overlaps and adjust service quality accordingly, but it does not scale well. While
deciding which model to use for the CDN selection problem, we have to make the
trade-off between the scalability and the precision.
11.5
CDN PRICING GAME UNDER COMPETITION
First, we analytically determine the optimal pricing strategy for two-CDN games.
Then, we numerically characterize the strategy for n-CDN games.
11.5.1
Two-CDN Pricing Games
A two-CDN pricing game is defined as a repeated game where price decisions are
made iteratively by two CDNs, D1 and D2. D1 selects a price at the beginning of a

CDN PRICING GAME UNDER COMPETITION
303
period, and that price is stable for the rest of the period. D2 cannot change its price
during the period when D1 is about to move and vice versa. After a CDN decides its
price, S makes CDN selection.
We use v1 and v2 to represent the volume of S‚Äôs traffic that is exclusively covered
by D1 and D2, respectively, and v12 is the volume that is covered by both CDNs, and
vùúôis the rest of the traffic, for example, the traffic that is covered by neither of the
CDNs.
Assume the utility of Di during period t is ùúãi = pivDi ‚àíc, where pi is the price, vDi
is the traffic served by Di, and c is the cost. According to the precise-coverage model
in Section 11.4.1, content producer S can make four possible CDN selections: case
1: if p2 < p1 ‚àí(ùúÇ1 ‚àíùúÇ2), S uses D2 for all the traffic, and ùúã1 = ‚àíc, ùúã2 = p2(v1 + v2 +
v12 + vùúô) ‚àíc; case 2: if p1 ‚àí(ùúÇ1 ‚àíùúÇ2) < p2 < p1, S uses D1 for v1 and D2 for the rest,
and ùúã1 = p1v1 ‚àíc, ùúã2 = p2(v2 + v12 + vùúô) ‚àíc; case 3: if p1 < p2 < p1 + (ùúÇ1 ‚àíùúÇ2), S
uses D2 for v2 and D1 for the rest, and ùúã1 = p1(v1 + v12 + vùúô) ‚àíc, ùúã2 = p2v2 ‚àíc;
case 4: if p2 > p1 + (ùúÇ1 ‚àíùúÇ2), S uses D1 for all the traffic, and ùúã1 = p1(v1 + v2 +
v12 + vùúô) ‚àíc, ùúã2 = ‚àíc.
If both CDNs ignore the impact of the current action on the future and maxi-
mize their current utility, then the competition can lead to price wars. Fortunately,
we also show that if both CDNs plan ahead and maximize utility over time, then a
price war can be avoided. We name the former strategy the nonpredictive strategy
(Section 11.5.1.1) and the latter the predictive strategy (Section 11.5.1.2).
11.5.1.1
Nonpredictive Strategy A price war is commercial competition charac-
terized by repeated cutting of prices below those of competitors, and it may eventually
force firms to close because of profit reduction. In this chapter, we say a price war
occurs if a series of price reduction leads to a state where at least one CDN cannot
avoid zero or negative utility by changing its price.
Any CDN that applies the nonpredictive strategy aims to maximize its current util-
ity. Assume D2 is about to move and the current price of D1 is p1. It is straightforward
that D2 will select a price that makes S choose one of the first three CDN selection
cases. Within each case, D2 can reach the highest possible utility if it charges the
highest price in corresponding range. Note that, only in case 3, D2 selects a price that
is higher than p1, and in case 1 and case 2, D2 will choose an action that is prone to
price war (charge a price lower than D1). Only if case 3 yields more utility than case
1 and case 2, then D2 will charge a higher price than D1. It is easy to verify that the
condition is
p1 < min
{
2ŒîùúÇv2
v1 + v12 + vùúô
+ ŒîùúÇ+ ùúÄ,
ŒîùúÇv2
v12 + vùúô
+ ùúÄ
}
,
(11.26)
where ŒîùúÇ= ùúÇ1 ‚àíùúÇ2 and ùúÄis the smallest price unit. We define the right side of the
inequality as the turning price of D2, denoted by pT
2. Similarly, we can derive the
same condition for D1 to charge a higher price than the current price of D2, which is
p2 < min
{
2ŒîùúÇv1
v2 + v12 + vùúô
+ ŒîùúÇ+ ùúÄ,
ŒîùúÇv1
v12 + vùúô
+ ùúÄ
}
.
(11.27)

304
CDN PRICING AND INVESTMENT STRATEGY UNDER COMPETITION
P1 (price of D1)
P2 (price of D2)
turning price
Figure 11.3
Prices oscillate in a cycle.
We define the right side of the inequality as the turning price of D1, denoted by pT
1.
We use pT to represent the larger one between pT
1 and pT
2. Note that, the price will
keep decreasing till it hits pT and bounce back to a high price, where a new round of
decreasing starts. The price oscillates in a cycle as shown in Figure 11.3. This figure
shows a unique property of the multiple-choice market, where one of the CDNs will
voluntarily increase its price in order to get a higher utility. The price increase can
happen because the multiple-choice market allows a CDN to take a full advantage of
its unique coverage. Whenever it is not profitable to compete for the overlap cover-
age, a CDN can focus on attracting end users in its exclusive coverage and charge a
high price for the service. This will never happen to a single-choice market, where
providers have to always compete for the same service, and increasing price will only
make a provider less competitive. Thus, the multiple-choice market is less prone to
price wars compared to the single-choice market.
However, price wars can still happen in multiple-choice markets. As the price
decreases, the utility decreases as well. As the lowest price can be reached is pT,
the lowest income gained by a CDN is max{pT(v1 + v2 + v12 + vùúô), (pT ‚àíŒîùúÇ)(v1 +
v12 + vùúô), (pT ‚àíŒîùúÇ)(v2 + v12 + vùúô)}. We name the value the bottom value. If the bot-
tom value is smaller than c, then one CDN will find itself having negative utility
before reaching pT, and the CDN cannot make positive utility by changing its price.
The result is a price war. When a price war happens, the best nonpredictive strategy
is to exit the game. We have the following theorem.
Theorem 11.1
In the two-CDN pricing game, if CDNs apply the nonpredictive
strategy and the bottom value is smaller than c, then the pricing game must lead
to price wars.
The overlapped coverage is linked to the likelihood of price wars. If two CDNs are
fully overlapped (v1 = v2 = 0), then pT = 0 and the bottom price is 0. Then a price
war must occur. The game becomes less prone to price wars as the overlapped cov-
erage decreases. Let us consider a game where two CDNs have partially overlapped
coverage and assume the game leads to a price war with the nonpredictive strategy.
Without the loss of generality, suppose pT
1 > pT
2. Let D1 keep its coverage stable, and
the other CDN D2 reduce its coverage by decreasing the overlapped coverage. Thus,
v1 increases and v12 decreases. According to the definitions, both pT and the bottom

CDN PRICING GAME UNDER COMPETITION
305
value will increase. If the increase makes the bottom value larger than c, then pT will
be reached before the utility goes below zero, and the price bounces back before a
price war can happen. That is, if the total covered region stays the same, the less the
overlap, the less prone a game to a price war.
11.5.1.2
Predictive Strategies In this subsection, we assume any CDN that is
about to move knows that its rival CDN will select a price based on its current move
in the next period. The price strategy can be denoted by a pair of reaction functions
R1(‚ãÖ) and R2(‚ãÖ) as follows:
pt
1 = R1
(pt‚àí1
2
) ,
pt+1
2
= R2
(pt
1
) ,
(11.28)
where pt
i is Di‚Äôs price at t. Because the reaction functions consider the consequences
of the current action on the future, we name them the predictive strategy.
D1‚Äôs utility over time is U1 = ùúã1(pt
1, pt‚àí1
2 ) + ùõøùúã1(pt
1, pt+1
2 ) + ùõø2ùúã1(pt+2
1 , pt+1
2 ) +
ùõø3ùúã1(pt+2
1 , pt+3
2 ) + ¬∑ ¬∑ ¬∑. Substitute D2‚Äôs price using its reaction function, and then
the utility over time can be written as U1 = ùúã1(pt
1, pt‚àí1
2 ) + ùõøùúã1(pt
1, R2(pt
1)) +
ùõø2ùúã1(pt+2
1 , R2(pt
1)) + ùõø2ùúã1(pt+2
1 , R2(pt+2
1 )) + ¬∑ ¬∑ ¬∑. Note that at period t + 2, the game
will repeat the same decision process as it has at period t. We define a new function
V1 = max {U1
}. Then, to maximize D1‚Äôs utility over time is equivalent to solving
the following maximization function:
V1
(pt‚àí1
2
) = maxpt
1
{ùúã1
(pt
1, pt‚àí1
2
) + ùõøùúã1
(pt
1, R2
(pt
1
)) + ùõø2V1
(R2
(pt
1
))}.
(11.29)
The solution of Eq. (11.29) is the optimal reaction function R1. Similarly, we can
derive the maximization function of D2:
V2
(pt‚àí1
1
) = maxpt
2
{ùúã2
(pt‚àí1
1 , pt
2
) + ùõøùúã2
(R1
(pt
2
) , pt
2
) + ùõø2V2
(R1
(pt
2
))}.
(11.30)
The solution of Eq. (11.30) is the optimal reaction function R2. We can solve the pair
of equations using the Markov perfect equilibrium theorem [42, 43]. In the following
content, we introduce the results for two different two-CDN pricing games, one with
the same-size coverage (v1 = v2) and the other with the subsumed coverage (v2 = 0).
For the CDN pricing game with the same-size coverage, the optimal predictive
strategy is given by
Ri(p) =
‚éß
‚é™
‚é™
‚é®
‚é™
‚é™‚é©
pf
for p ‚â•pf ,
pl
for pf > p > pl,
pf
for p ‚â§pl,
(11.31)
where i = 1, 2 and pf and pl satisfy two functions (details can be found in
Reference 44): (ùúÇ1(2v1+ v12)+ùúÇ2vùúô)‚àï(2v1 + (5‚àï4)(v12+ vùúô)) < pf < (ùúÇ1(2v1+ v12) +
ùúÇ2vùúô)‚àï(2v1 + v12 + vùúô) and (1 + (3‚àï2ùõΩ+ 1))(pl ‚àíùúÄ) < pf < (1 + (3‚àï2ùõΩ+ 1))pl, and

306
CDN PRICING AND INVESTMENT STRATEGY UNDER COMPETITION
ùõΩ=
2v1
v12+vùúô. Note that, at the equilibrium state, both CDNs will charge a price equal
to pf . According to the strategy, if the rival CDN charges a price that is greater
than or equal to pf, or smaller than pl, then a CDN needs to charge pf . If the rival
CDN‚Äôs price is between pf and pl, then a CDN needs to charge pl. The optimal
predictive strategy of the same-size coverage game is motivated by incentives, and it
strategically forces the two CDNs to stay at pf instead of competing to price wars.
When any CDN deviates from pf, the strategy makes sure that the other CDN will
choose a price so that the deviating CDN can get the maximal utility only if its price
goes back to pf .
For the subsumed coverage CDN pricing game, the optimal predictive strategy is
given by
R1(p2) =
‚éß
‚é™
‚é™
‚é®
‚é™
‚é™‚é©
p2 ‚àíùúÄ
for p2 > pf
2
pf
1
for pf
2 ‚â•p2 > pf
1 ‚àí(ùúÇ1 ‚àíùúÇ2)
p2 + (ùúÇ1 ‚àíùúÇ2) ‚àíùúÄ
for p2 ‚â§pf
1 ‚àí(ùúÇ1 ‚àíùúÇ2)
R2(p1) =
‚éß
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™‚é©
p1 ‚àí(ùúÇ1 ‚àíùúÇ2) ‚àíùúÄ
for p1 > pf
1
pf
2
for pf
1 ‚â•p1 > pf
2
p1 ‚àíùúÄ
for pf
2 ‚â•p1 > pl
pf
2
for pl ‚â•p1
(11.32)
where
pf
1,
pf
2,
and
pl
satisfy
(pf
2 ‚àíùúÄ)(1 + ùõΩ) < pf
1ùõΩ< pf
2(1 + ùõΩ),
(pf
1 ‚àíùúÄ‚àí
(ùúÇ1 ‚àíùúÇ2))((ùõΩ‚àï2) + 2) < 2pf
2 < (pf
1 ‚àí(ùúÇ1 ‚àíùúÇ2))((ùõΩ‚àï2) + 2),
pf
2(v1 + v12 + vùúô) >
ùúÇ1v12 + ùúÇ2(v1 + vùúô), and 2(pl ‚àíùúÄ) < pf
2 < 2pl. Note that, at the equilibrium state, D1
and D2 will charge pf
1 and pf
2, respectively. The strategy adopts a similar method as
the same-size case to force the two CDNs to stay at pf
1 and pf
2. It is interesting to see
that, under the optimal strategy, the larger CDN always charges a higher price.
Not all the CDN pricing games have an optimal strategy. The sufficient condi-
tion for its existence in the same-size game is that 0 ‚â§ùõΩ< 2 and (2v12 + 5vùúô)ùúÇ1 >
(39v12 + 46vùúô)ùúÇ2. The first condition requires the overlapped coverage of D1 and D2
to be large enough, and the second condition requires ùúÇ1 to be larger than ùúÇ2. Note that
a game that satisfies the first condition can be prone to a price war, and the optimal
predictive strategy ensures that the price war can be avoided. More details about the
sufficient conditions can be found in References 44 and 45.
We define the social optimal utility as the utility obtained by CDNs if they maxi-
mize their total utility instead of individual utilities. The social optimal utility is thus
the highest utility that can be reached if all CDNs act selflessly. The closer the actual

CDN PRICING GAME UNDER COMPETITION
307
utility to the social optimal utility, the more efficient the strategy. Because the predic-
tive strategy strategically forces CDNs to stay at a high price rather than compete to
price wars, it is efficient in terms of price of anarchy. We have the following theorem.
Theorem 11.2
The utility obtained under the optimal predictive strategies in Eqs.
(11.31) and (11.32) is at least two-thirds of the social optimal utility.
Please refer to Reference 44 for proof. The predictive strategy is apparently bene-
ficial for CDNs, because the total utility is close to the social optimal utility (defined
as the highest utility the CDN market can get). But the benefit for CDN market does
not necessarily mean the loss for content producers, because content producers will
never pay more than what CDN service can provide. That is because content produc-
ers have two options to deliver traffic to end users: going through an ISP or a CDN.
If CDNs charge more than what their service worths, content producers can always
switch to ISPs. The predictive strategy is designed to help CDNs to compete more
efficiently rather than squeeze the revenue from content producers.
11.5.2
The n-CDN Pricing Games
In Section 11.5.1, we focus on two-CDN pricing games. Now, we extend the game to
n CDNs. In a n-CDN pricing game, CDN Di decides prices to maximize its own utility
UDi = pivDi ‚àíc, knowing that content producer S makes CDN selection to maximize
Eqs. (11.24) and (11.25). We say the game is under the equilibrium state if (i) content
producer S cannot increase its utility by changing traffic distribution and (ii) CDNs
cannot increase their utility by adjusting prices.
We will only demonstrate how to solve this problem with S as a big content pro-
ducer. We omit the CDN pricing game that competes for small content producers
because, unlike the big content producers who normally select multiple CDNs, small
content producers usually select one CDN only, and any single-choice model [46]
can solve the problem.1
Big content producers are the most important customers of the CDN market,
because they possess huge traffic volume and pay great amount of money for traffic
delivery [10]. To simplify the discussion but still preserve meaningful insights,
we assume that a big content producer will only select among big CDNs (This
assumption is consistent with the decision made by big content producers in
reality [10]). Further, from a big content producer‚Äôs perspective, the big CDNs have
either a high coverage ùõº1 or a lower coverage ùõº2. We call them type 1 and type 2 big
CDN, respectively. A type 1 CDN is intended to model Akamai, and a type 2 CDN
resembles Level 3 or Limelight. We further assume CDNs with the same coverage
have the same price. p1 and p2 represent the prices of the two types of big CDNs,
and n1 and n2 represent their numbers.
1As small content producers make little impact on the traffic distribution of the CDN market, henceforth,
we simplify the computation by assuming that small content producers choose one CDN randomly from
all CDNs.

308
CDN PRICING AND INVESTMENT STRATEGY UNDER COMPETITION
Unfortunately, the solution of the CDN selection problem in Eqs. (11.24) and
(11.25) has no closed form, so we apply a numerical method to solve it. Because of
the way we solve the CDN selection problem, the CDN pricing game has to be solved
numerically as well. We enumerate all possible prices that CDNs can charge (with a
step equal to 0.1) and solve the CDN selection problem. Then let CDNs choose the
best price that can maximize their own utility.
We play eight CDN pricing games where the number of type 1 CDNs are either one
or two and the number of type 2 CDNs ranges from one to four. We set Vs = 10, ùõæ=
1, ùúâ= 10, ùõº1 = 0.8, ùõº2 = 0.7. We choose these values so that when there are one type
1 CDN and two type 2 CDNs in the market, their traffic shares are consistent with the
percentages in the real market (introduced in Section 11.1). Note that, an arbitrary
unit can be attached to Vs, for example, MB,GB,TB, and PB. For all the runs, there is
always an equilibrium state. The result is shown in Table 11.2. We compare different
games‚Äô price, traffic volume, and utility at the equilibrium state. We can see that type
1 CDNs always charge a higher price than type 2 CDNs do. But as the number of type
2 CDN increases, type 1 CDNs‚Äô price will decrease slightly. Moreover, type 1 CDNs
always attract more traffic, and thus they always obtain a higher utility. An interesting
observation is as the number of type 2 CDNs increases, the total utility gained by all
CDNs can reduce. The reduction can be caused by the heated competition among
CDNs. If there is one type 1 CDN, then having two type 2 CDNs can result in the
highest utility. If there are two type 2 CDNs, then having one type 2 CDN can result
in the highest utility.
Note that, if we play the n-CDN pricing game repeatedly as we did in the two-CDN
pricing game, the outcome of the game will not change. That is because, with a stable
market state, the base game will produce the same result in each iteration.
11.6
CDN COMPETITION UNDER MARKET STRUCTURE CHANGE
The CDN pricing game shows that a CDN with a larger coverage can obtain more
utility than the CDNs with a smaller coverage. An interesting question now arises as
to why not small CDNs invest to become big CDNs. In reality, CDNs indeed manage
TABLE 11.2
The Equilibrium State with Different Numbers of CDNs
Number of CDNs
Price
Volume
Utility
Type 1
Type 2
Type 1
Type 2
Type 1
Type 2
Type 1
Type 2
Total
1
1
3.0
2.6
3.2
1.7
3.2
1.0
4.2
1
2
3.0
2.8
2.9
1.0
2.9
0.8
4.5
1
3
2.9
2.8
2.7
0.7
2.5
0.6
4.3
1
4
2.8
2.7
2.4
0.6
1.9
0.4
3.5
2
0
2.8
‚Äì
2.5
‚Äì
2.0
‚Äì
4
2
1
3.2
2.6
1.7
1.5
2.1
0.8
5.0
2
2
3.1
2.7
1.6
0.8
1.7
0.6
4.6
2
3
2.9
2.6
1.5
0.6
1.3
0.4
3.8
2
4
2.8
2.6
1.5
0.4
1.2
0.3
3.6

CDN COMPETITION UNDER MARKET STRUCTURE CHANGE
309
to expand their coverages through a variety of approaches including federation or
investment. Nevertheless, the models presented in the previous section are no longer
suitable to analyze this case because they all assume the market state, for example,
the number of CDNs and their coverages, is fixed. In the following subsections,
we use dynamic analysis to solve the CDN competition game. To simulate the
situation in reality, we allow coverage change, as well as entry and exit. With these
additional features, we address the following questions. How to make the federation
or investment decision so that a CDN can get the highest utility? What is the
equilibrium state in the dynamic game? Is the equilibrium state efficient compared
to social optimal utility? We first discuss the case where market state is changed
by federation, and then we focus on the case where market state is changed by
investment, entry, exit, and market shocks.
11.6.1
Assumptions
Suppose there are M content producers, represented by S1, ‚Ä¶, Sj, ‚Ä¶, SM. The end
users are evenly distributed over the network and request the same amount of traf-
fic from the same content producer. Depending on the traffic volume generated, we
divide content producers into K levels from low to high. There are sk content produc-
ers at the kth level, and their volume is vk, where k = 1, ‚Ä¶ , K. We assume both sk and
vk follow power law distribution over k, because the majority of the Internet traffic is
generated by a small number of content producers [11]. More precisely, vk = v0kùõΩv,
where ùõΩv > 0, and sk = s0kùõΩs, where ùõΩs < 0. In the following subsections, we suppose
content producers are categorized into three levels, corresponding to small, medium,
and big content producers, and vk = v0k6, and sk = s0k‚àí5. Content producers in dif-
ferent levels have different perceived coverage as shown in Table 11.3.
11.6.2
Market State Change Through CDN Federation
CDN federation is a collection of CDNs that are operated autonomously by differ-
ent entities but are interconnected through open interfaces, so that they can work
collectively as a logical content delivery infrastructure [47]. CDN federation is an
efficient and economic way for small CDNs to expand their coverage and compete
more directly against large CDNs, such as Akamai. It has been under fast development
recently. In June 2011, a group of small CDNs make one step forward to federation by
founding an Operator Carrier Exchange (OCX) to interconnect their networks [12].
Edgecast networks built a platform where small CDNs can buy and sell capacity with
an easy-to-use online control panel. In this section, we will not discuss the technical
TABLE 11.3
Perceived Coverage ùú∂i of Content Producers in
Different Levels
Content Producers
Type 1 CDN
Type 2 CDN
Small CDN
Small
1
1
1
Medium
0.8
0.75
‚Äì
Big
0.75
0.7
‚Äì

310
CDN PRICING AND INVESTMENT STRATEGY UNDER COMPETITION
problems and feasibility of CDN federation [48]. Instead, we will focus on the eco-
nomic incentives of CDN federation. We will answer the questions of whether it is
profitable for small CDNs to join a federation, and to what extent.
Federation impacts the market state by changing the number of CDNs and their
coverage. If k small CDNs form a federation, the number of small CDNs decreases
by k, and the number of big CDNs increases by 1, the new big CDNs‚Äô coverage is
the combination of the small CDNs‚Äô coverage. To determine whether a federation is
profitable, we compute the utility with and without a federation.
On the basis of the current status of the CDN market, we assume the numbers
of type 1, type 2, and small CDNs are n1 = 1, n2 = 2, and n3 = 20, respectively,
and small CDNs can federate to become a type 2 big CDN. CDNs conduct the
n-CDN pricing game for every content producer independently (introduced in
Section 11.5.2). We compare the utility gained by CDNs with and without a
federation. Note that, a CDN‚Äôs utility is equal to the summation of the utility gained
from every content producer. The result is shown in Figure 11.4. We demonstrate
four cases in the figure: no federation, three CDNs forming a federation, four CDNs
forming a federation, and five CDNs forming a federation. For each case, we plot
the utility of a type 1 CDN, a type 2 CDN, a small CDN, and a member of the CDN
federation. We can see that a federation with three or four CDNs can be beneficial,
because the members of the federation can gain more utility than individual small
CDNs. Not surprisingly, as the number of members grows, the utility of each
member decreases. If more than four CDNs are needed in order to form a federation,
small CDNs may not have the motivation to join in, because acting as independent
small CDNs can gain more utility than the small CDNs in the federation. The reason
is twofold. First, the more members in the federation, the smaller share of the utility
each of them will get. Second, as more small CDNs join the federation to compete
with big CDNs, the competition among small CDNs becomes moderate and small
CDNs‚Äô utility increases.
No fed
3-CDN fed
4-CDN fed
5-CDN fed
0
1
2
3
4
5
6
√ó 105
Utility
 
Type 1 big CDNs
Federation (type 2)
Small CDNs
Member of federation
Figure 11.4
Utility comparison before and after federation.

CDN COMPETITION UNDER MARKET STRUCTURE CHANGE
311
For the current CDN market, a beneficial CDN federation has four or less member
CDNs. If the CDN market has more big CDNs, the threshold will become smaller.
But if two small CDNs can form a type 2 CDN, then forming a federation is always a
better choice for these small CDNs, no matter how many big CDNs are in the market.
That is because the federation can attract traffic from big content producers which
contribute more traffic than small content producers.
11.6.3
The Dynamic CDN Game
In this subsection, we discuss the dynamic CDN game where the market state can be
changed through the voluntary investment, entry and exit, as well as the involuntary
market shocks. We model the dynamic CDN game as an infinitely repeated game
where, at the beginning of each period, every CDN chooses an action (invest, enter,
or exit) to maximize its utility over time. If a CDN decides to exit, it will get a scrap
value in the current period. If it chooses to enter or invest, the market state change will
take effect at the beginning of the next period. Within each period, the market state is
stable and CDNs conduct the n-CDN pricing game introduced in Section 11.5.2. As
CDNs‚Äô utility is totally determined by the market state, in the dynamic CDN game,
each CDN aims to choose an action that can result in a market state that can benefit
itself most. We use a vector ùúî= [l1, l2, ‚Ä¶ , li, ‚Ä¶ , ln] to represent the market state,
where li is the type of incumbent CDN Di. We start with the case where the market
state is changed by voluntary actions. Then we consider the case with market shocks.
11.6.3.1
Voluntary Dynamic CDN Game We first introduce a game where the
market state can be changed by voluntary actions only (no market shocks). The game
is referred to as the voluntary dynamic CDN game. We apply the Markov perfect
equilibrium theory [34, 43] to derive the optimal reaction scheme in the game.
Any CDN, represented by Di, aims to select proper actions to maximize its utility
over time. Di is allowed to invest, enter or exit the market. For simple explanation,
we first consider the case where Di is allowed to invest only. Later, we will add the
other actions. We use xt
i to represent Di‚Äôs investment at time t, then Di‚Äôs utility over
time is equal to
Ii
(ùúî0) =
‚àû
‚àë
t=0
ùõøt (ùúãi
(ùúît) ‚àíxt
i
) ,
(11.33)
where ùúît is the market state at t and ùúãi(ùúît) represents Di‚Äôs utility from the n-CDN
pricing game under ùúît.
According to the dynamic analysis in Section 11.3.3, a CDN Di should solve the
following value equation.
Vi
(ùúî0) = max
{ ‚àû
‚àë
t=0
ùõøt (ùúãi
(ùúît) ‚àíxt
i
)
}
= max x0
i
{ùúãi
(ùúî0) ‚àíx0
i + ùõøVi
(ùúî1)} .
(11.34)

312
CDN PRICING AND INVESTMENT STRATEGY UNDER COMPETITION
Note that at time t = 1, Di faces the same maximization problem as the one it faces
at t = 0, but the market state changes to ùúî1.
Assume investment xi either enhances Di by one level in the type rank or fails to
do so. We use ùúêi to represent the result of investment xi. ùúêi is a random variable whose
value depends on xi.
Pr(ùúêi|xi) =
‚éß
‚é™
‚é®
‚é™‚é©
ùúÜxi
1 + ùúÜxi
ùúêi = 1 (level increment),
1
1 + ùúÜxi
ùúêi = 0 (no level increment).
(11.35)
Note that the probability to have a level increment is a monotonically increas-
ing concave function of xi. If xi = 0, the probability is 0. We define a vector
ùúê= [ùúê1, ‚Ä¶ , ùúêi, ‚Ä¶ , ùúên] to represent the market change after the investment xt
1, ‚Ä¶ , xt
n.
The market state at time t + 1, ùúît+1, depends on the market state at time t and the
investments of all n incumbent CDNs. That is, ùúît+1 = ùúît + ùúê. Thus, the expected
value of Vi(ùúî1) is
Vi
(ùúî1) =
‚àë
ùúê1
¬∑ ¬∑ ¬∑
‚àë
ùúêi
¬∑ ¬∑ ¬∑
‚àë
ùúên
Vi
(ùúî0 + ùúê)
Pr (ùúê1|x0
1
) ¬∑ ¬∑ ¬∑ Pr (ùúêi|x0
i
) ¬∑ ¬∑ ¬∑ Pr (ùúên|x0
n
) .
Then, Di‚Äôs value equation can be written as
Vi
(ùúî0) = maxx0
i
{
ùúãi
(ùúî0) ‚àíx0
i + ùõø(‚àë
ùúê1
¬∑ ¬∑ ¬∑
‚àë
ùúêi
¬∑ ¬∑ ¬∑
‚àë
ùúên
Vi
(ùúî0 + ùúê) Pr (ùúê1|x0
1
) ¬∑ ¬∑ ¬∑ Pr (ùúêi|x0
i
) ¬∑ ¬∑ ¬∑ Pr (ùúên|x0
n
) }
.
Next, we expand the value equation to include exit strategy. We assume Di obtains
a scrap value Œ¶ when it exits the market. Thus, if the expected utility over time is
less than Œ¶, Di will quit. Di always prefers an action that can result in a higher value
between exit and staying. After including exit, Di‚Äôs value equation becomes
Vi
(ùúî0) = max
{
Œ¶, maxx0
i
{
ùúãi
(ùúî0) ‚àíx0
i + ùõø(‚àë
ùúê1
¬∑ ¬∑ ¬∑
‚àë
ùúêi
¬∑ ¬∑ ¬∑
‚àë
ùúên
Vi
(ùúî0 + ùúê) Pr (ùúê1|x0
1
) ¬∑ ¬∑ ¬∑ Pr (ùúêi|x0
i
) ¬∑ ¬∑ ¬∑ Pr (ùúên|x0
n
) }}
.
Dropping the time subscripts, we get Di‚Äôs value equation with investment and exit.
Vi(ùúî) = max
{
Œ¶, maxxi
{
ùúãi(ùúî) ‚àíxi + ùõø( ‚àë
ùúê1
¬∑ ¬∑ ¬∑
‚àë
ùúêi
¬∑ ¬∑ ¬∑
‚àë
ùúên
Vi(ùúî+ ùúê)Pr(ùúê1|x1) ¬∑ ¬∑ ¬∑ Pr(ùúêi|xi) ¬∑ ¬∑ ¬∑ Pr(ùúên|xn)
}}
.

CDN COMPETITION UNDER MARKET STRUCTURE CHANGE
313
Next, we introduce entry to the value equation. We assume a new CDN enters the
market as a small CDN and it pays a sunk cost xe. If the expected utility over time
is higher than xe, then a CDN will enter. Otherwise, it stays inactive. A new CDN‚Äôs
expected utility over time is
Ve(ùúî) = ùõø( ‚àë
ùúê1
¬∑ ¬∑ ¬∑
‚àë
ùúêi
¬∑ ¬∑ ¬∑
‚àë
ùúên
Ve(ùúî+ e + ùúê)
Pr(ùúê1|x1) ¬∑ ¬∑ ¬∑ Pr(ùúêi|xi) ¬∑ ¬∑ ¬∑ Pr(ùúên|xn),
(11.36)
where e represents market state change after the entry. Note that, if a CDN enters, the
size of ùúîand ùúêwill increase by one in order to match the total number of CDNs in
the new market state.
The incumbent CDNs need to take entries into account while estimating their util-
ity over time. Assume a new CDN‚Äôs sunk cost xe is a random variable that is uniformly
distributed on [xel, xeu]. We use E(ùúî) to represent the probability that xe < Ve(ùúî), hat
is, an entry occurs, and (1 ‚àíE(ùúî)) to represent the probability that there is no entry.
After including entries, Di‚Äôs value equation becomes
Vi(ùúî) = max
{
Œ¶, maxxi
{
ùúãi(ùúî) ‚àíxi + ùõøE(ùúî)
( ‚àë
ùúê1
¬∑ ¬∑ ¬∑
‚àë
ùúêi
¬∑ ¬∑ ¬∑
‚àë
ùúên
Vi(ùúî+ e + ùúê)Pr(ùúê1|x1) ¬∑ ¬∑ ¬∑ Pr(ùúêi|xi) ¬∑ ¬∑ ¬∑
Pr(ùúên|xn) + ùõø(1 ‚àíE(ùúî))(
‚àë
ùúê1
¬∑ ¬∑ ¬∑
‚àë
ùúêi
¬∑ ¬∑ ¬∑
‚àë
ùúên
Vi(ùúî+ ùúê)Pr(ùúê1|x1) ¬∑ ¬∑ ¬∑ Pr(ùúêi|xi) ¬∑ ¬∑ ¬∑ Pr(ùúên|xn)
}}
.
We refer to the equation as Di‚Äôs value equation of the voluntary dynamic CDN game.
In the following subsections, we make the same assumptions as we did in
Section 11.6.1. In order to resemble the reality, for example, a new CDN is willing
to enter when one type 1 and two type 2 CDNs are in the market, and there are less
than five big CDNs at the equilibrium state, we assume that the scrap value Œ¶ is 0.8
and xel and xeu are 1 and 2, respectively. The discount factor ùõøis set to be 0.925, a
value commonly used in dynamic analysis [34, 35]. Note that, we do not intend to
precisely predict what will happen in the real CDN market. We aim to show how
CDNs‚Äô strategy may change as the market state changes, and whether the dynamics
can produce an efficient market.
The best investment strategy is shown in Table 11.4. In this table, the first two
columns show the number of type 1 and type 2 CDNs at the current market state and
the rest of the columns show type 2 and small CDNs‚Äô best investment under corre-
sponding market states (The best strategy of type 1 big CDNs is to avoid investment
in any of the states). In general, if there are four or more big CDNs in the market, then
small CDNs do not invest. Otherwise, they always invest. The investment increases as
more small CDNs are competing in the market (the number of small CDNs is speci-
fied in the third row). Type 2 CDNs‚Äô best strategy is to invest only if there is no type 1

314
CDN PRICING AND INVESTMENT STRATEGY UNDER COMPETITION
TABLE 11.4
Best Investment Strategy for Voluntary Dynamic CDN Games
Best investment
Current state
Small CDNs
Type 2 CDNs
Type 1 #
Type 2 #
1
2
3
4
5
0
0
2.3
4.3
6.1
7.6
9.0
1.1
0
1
3.6
5.1
6.3
7.8
8.3
0.85
0
2
4.0
4.9
5.6
6.3
6.9
0.73
0
3
3.1
3.7
4.1
4.4
5.0
0.58
0
‚â•4
0
0
0
0
0
0.35
1
0
3.0
4.1
5.0
5.8
6.5
0
1
1
2.8
3.4
4.0
4.5
5.3
0
1
2
2.1
2.5
2.8
3.0
3.3
0
1
‚â•3
0
0
0
0
0
0
2
0
4.2
4.9
5.6
6.1
6.5
0
2
1
2.5
2.8
3.1
3.2
3.3
0
2
‚â•2
0
0
0
0
0
0
3
0
7.3
7.9
8.4
9.0
9.2
0
3
‚â•1
0
0
0
0
0
0
CDN in the market. The best entry strategy is as follows. If there are more than seven
CDNs in the market, then no CDN should enter. Otherwise, CDNs can enter.
If all CDNs apply the best strategy, the voluntary dynamic CDN game will con-
verge to an equilibrium state. Because the level increment ùúêand the sunk cost xe are
random variables, different games may have different equilibria. We simulate 10,000
games with an initial state where there are one type 1 CDN and two type 2 CDNs.
At the equilibriums state, there are 1.0 type 1 CDN, 3.0 type 2 CDNs, and 2.9 small
CDNs on an average (Fig. 11.5a), and the type 1 CDN attracts 38.2% of all the traffic,
and each type 2 and small CDN attract 17.6% and 2.7%, respectively. The utilities
gained by the three types of CDNs are 1.16, 0.55, and 0.08 per period.
Type 1
(a)
(b)
Type 2
Small
0
1
2
3
4
Type 1
Type 2
Small
0
1
2
3
Figure 11.5
Average number of CDNs at the equilibrium state. (a) The voluntary dynamic
CDN game and (b) Perfect cartel game.

CDN COMPETITION UNDER MARKET STRUCTURE CHANGE
315
To understand how efficient the equilibrium is, we compare the utility at the equi-
librium state with the social optimal utility. We define a perfect cartel game to com-
pute the social optimal utility. Assume that a perfect cartel can control the investment
of all the CDNs and it aims to maximize the social utility of the CDN market. The
value equation of the perfect cartel game is as follows.
V(ùúî) = max
{
Œ¶, maxx
{
n
‚àë
i=1
(ùúãi(ùúî) ‚àíxi) + ùõøE(ùúî)( ‚àë
ùúê1
¬∑ ¬∑ ¬∑
‚àë
ùúêi
¬∑ ¬∑ ¬∑
‚àë
ùúên
V(ùúî+ e + ùúê)Pr(ùúê1|x1) ¬∑ ¬∑ ¬∑ Pr(ùúêi|xi)
¬∑ ¬∑ ¬∑ Pr(ùúên|xn) + ùõø(1 ‚àíE(ùúî))( ‚àë
ùúê1
¬∑ ¬∑ ¬∑
‚àë
ùúêi
¬∑ ¬∑ ¬∑
‚àë
ùúên
V(ùúî+ ùúê)Pr(ùúê1|x1) ¬∑ ¬∑ ¬∑ Pr(ùúêi|xi) ¬∑ ¬∑ ¬∑ Pr(ùúên|xn)
}}
Assume the conditions stay the same as the voluntary dynamic CDN game. The best
strategy of the perfect cartel game is to promote a type 2 CDN to be a type 1 CDN
if there are less than three type 1 CDNs in the market. The equilibrium state of the
perfect cartel game has three type 1 CDNs, one type 2 CDNs, and no small CDN
(Fig. 11.5b). The utilities of each type 1 CDN and type 2 CDN are 0.92 and 0.80,
respectively, and thus the social optimal utility is 3.56. As a result, the total utility of
the voluntary dynamic CDN game is 85.4% of the social optimal utility.
11.6.3.2
Dynamic CDN Game with Market Shocks In the dynamic CDN game,
we allow both voluntary market state change and market shocks. We say a market
shock happens when content producers downgrade the perceived type of the incum-
bents CDNs. The downgrade can be caused by several reasons, including the increase
of content producers‚Äô traffic or the improvement of outside competitors such as ISPs.
We assume that when a downgrade happens, it happens to all the incumbent CDNs
and the probability of its occurrence is Pr(ùúè). With market shocks, Di‚Äôs value equation
becomes
Vi(ùúî) = max
{
Œ¶, maxxi
{
ùúãi(ùúî) ‚àíxi + ùõøE(ùúî)( ‚àë
ùúè
‚àë
ùúê1
¬∑ ¬∑ ¬∑
‚àë
ùúêi
¬∑ ¬∑ ¬∑
‚àë
ùúên
Vi(ùúî+ e + ùúê)Pr(ùúê1|x1, ùúè) ¬∑ ¬∑ ¬∑
Pr(ùúêi|xi, ùúè) ¬∑ ¬∑ ¬∑ Pr(ùúên|xn, ùúè)Pr(ùúè) + ùõø(1 ‚àíE(ùúî))
( ‚àë
ùúè
‚àë
ùúê1
¬∑ ¬∑ ¬∑
‚àë
ùúêi
¬∑ ¬∑ ¬∑
‚àë
ùúên
Vi(ùúî+ ùúê)Pr(ùúê1|x1, ùúè) ¬∑ ¬∑ ¬∑
Pr(ùúêi|xi, ùúè) ¬∑ ¬∑ ¬∑ Pr(ùúên|xn, ùúè)Pr(ùúè)
}}
.
The best investment strategy under different Pr(ùúè) is shown in Table 11.5. The
first two columns show the numbers of type 1 and type 2 CDNs in the current market

316
CDN PRICING AND INVESTMENT STRATEGY UNDER COMPETITION
TABLE 11.5
Best Investment Strategy with Market Shocks
Best Investment Strategy
Current State
p = 0.1
p = 0.05
p = 0.01
T-1
T-2
Small
T ‚àí2
Small
T ‚àí2
Small
T ‚àí2
0
0
0.5‚Äì0.7
0.7‚Äì1.0
0.9‚Äì1.3
0
1
0
1.1
0.5‚Äì0.7
1.1
0.7‚Äì1.0
1.2
0
2
0
0.7
0.1‚Äì0.2
0.9
0.5‚Äì0.7
0.9
0
3
0
0.6
0
0.6
0.2‚Äì0.2
0.8
0
4
0
0.6
0
0.4
0
0.6
0
5
0
0.5
0
0.5
0
0.4
1
0
0
0.3‚Äì0.5
0.5‚Äì0.8
1
1
0
0
0
0
0.3‚Äì0.4
0
1
2
0
0.1
0
0.2
0.1‚Äì0.1
0
1
3
0
0
0
0.1
0
0
1
‚â•4
0
0
0
0
0
0
2
0
0
0.1‚Äì0.2
0.5‚Äì0.8
2
1
0
0
0
0
0.1‚Äì0.1
0
2
‚â•2
0
0
0
0
0
0
3
0
0
0
0.5‚Äì0.7
3
‚â•1
0
0
0
0
0
0
state, and the rest of the columns show the best investment strategy of small and
type 2 CDNs (The best strategy of type 1 big CDNs is to avoid investment in any
of the states). If the probability of market shocks is high, it is hard for small CDNs
to survive. Thus, small CDNs only invest when there is no big CDN in the market.
The best strategy of a type 2 CDN is to invest if there is no type 1 CDN. If there is
already one type 1 CDN, then invest if two or three type 2 CDNs are in the market
and the probability of market shock is high. The best entry strategy is as follows.
When Pr(ùúè) = 0.1, a CDN should never enter if there are four or more CDNs in the
market. The threshold is five and seven CDNs for Pr(ùúè) = 0.05 and Pr(ùúè) = 0.01,
respectively.
To demonstrate the features at the equilibrium state, we simulate 10,000 periods
with all CDNs applying their best strategy. The result is shown in Table 11.6. The first
TABLE 11.6
Average Number of CDNs at Equilibrium State
Dynamic CDN Game
Perfect Cartel Game
p
Type 1
Type 2
Small
Type 1
Type 2
Small
0.1
0.5
0.4
2.0
0
1.7
1.8
0.05
0.8
1.0
2.6
0
2.7
2.7
0.01
1.1
2.6
2.9
0
3.4
2.0

CONCLUSION
317
p = 0.10
p = 0.05
p = 0.01
0
0.2
0.4
0.6
0.8
1
Unified total utility
 
Dynamic CDN game
Perfect cartel game
Figure 11.6
Compare total utility of the dynamic CDN game and perfect cartel game.
column represents the probability of market shocks. The next three columns show
the average numbers of different types of CDNs at the equilibrium state. We can see
that there are always more small CDNs than type 1 and type 2 big CDNs. As the
probability of market shock decreases, the number of CDNs at the equilibrium state
increases. We also show the equilibrium state of the perfect cartel game with market
shocks in the last three columns. There is no type 1 CDN, but there are more type 2
CDNs compared to the dynamic CDN game.
We compare the total utility of the dynamic CDN game with the social optimal
utility (the perfect cartel game). The result is shown in Figure 11.6. The first obser-
vation is that as the probability of market shocks decreases, the utility of both games
increases. Further, as the probability decreases, the utility of the dynamic game gets
closer to the social optimal utility. With the probability ranges from 0.1 to 0.01, the
dynamic game can achieve 63‚Äì90% of the social optimal utility. That is, the dynamic
CDN game becomes more efficient as the probability of market shocks decreases.
11.7
CONCLUSION
In this chapter, we study the competition in CDN market. CDN market is a unique
market because content producers can select multiple CDNs at the same time, and
small CDNs are open for cooperation. We propose the best pricing and investment
strategies in the competitive and dynamic market. We demonstrate that by imple-
menting the proposed strategies, CDN competition can be efficient in terms of price
of anarchy. Because of the complexity of the CDN competition problem, we are
only able to provide analytical result for small-scale CDN pricing games. For the
large-scale pricing and investment games, we give up the analytic elegance for a better
approximation for realistic scenarios. The results in this chapter provide an insightful
analysis for the CDN market, and it is also generally applicable to any multiple-choice
market with similar features.

318
CDN PRICING AND INVESTMENT STRATEGY UNDER COMPETITION
ACKNOWLEDGMENTS
This work is supported by US NSF grants CNS-0917078.
REFERENCES
1. C. Labovitz. CDN and Over-The-Top Traffic Data, 2012.
2. C. Labovitz. First Data on Changing Netflix and CDN Market Share, 2012.
3. The State Of The CDN Market: Video, Pricing, Contract, Volume and Market Sizing
Trends. Available at: www.cdnpricing.com.
4. J. Chuang. ‚ÄúLoci of competition for future Internet architectures,‚Äù Communications Mag-
azine, 49(7), 2011, 38‚Äì43.
5. D. Clark and S. Bauer. Interconnection in the Internet: the policy challenge. In The 39th
Research Conference on Communication, Information and Internet Policy, 2011.
6. Dan Rayburn. Content Delivery Summit. Understand the CDN economics: build vs buy.
Available at: http://www.contentdeliverysummit.com/2012/.
7. List of Vendors in the Content Delivery Ecosystem. Available at: http://blog.
streamingmedia.com/the_business_of_online_vi/2011/07/updated-list-of-vendors-in-the-
content-delivery-ecosystem.html.
8. BusinessTech.
Level
3
enters
South
Africa.
Available
at:
http://businesstech.
co.za/news/internet/30472/level-3-enters-south-africa/.
9. Justin
Lee.
CDN
Provider
Akamai
Expands
Services
to
Costa
Rica,
Names
Asia-Pacific
Executives.
Available
at:
http://www.thewhir.com/web-hosting-news/
cdn-provider-akamai-expands-
services-to-costa-rica-names-asia-pacific-executives.
10. D. Rayburn. CDN Pricing Stable: Survey Data Shows Pricing Down 15% This year. Avail-
able at: http://blog.streamingmedia.com/the_business_of_online_vi/2012/09/cdn-pricing-
stable-survey-data-shows-pricing-down-15-this-year.html.
11. C. Labovitz, S. Iekel-Johnson, D. McPherson, J. Oberheide, and F. Jahanian. ‚ÄúInternet
inter-domain traffic,‚Äù SIGCOMM Computer Communication Review, 41(4), 75‚Äì86, 2010.
12. Dan Rayburn Federated CDN. Available at: http://blog.streamingmedia.com/the_business
_of_online_vi/2011/06/telco-and-carriers-forming-new-federated-cdn-group-called-ocx-
operator-carrier-exchange.html.
13. J. Bertrand. Revue de la Theorie Mathematique de la Richesse Sociale et des Recherches
sur les Principes Mathhatiques de la Theorie des Richesses. Journal des Savants, 1883.
14. A. A. Cournot. Recherches sur les principes math√©matiques de la th√©orie des richesses.
L. Hachette, 1838.
15. U. Doraszelski and A. Pakes. A Framework for Applied Dynamic Analysis in IO, vol. 3.
Elsevier, New York, 2007. Draft Date: September, 2006. Chapter 33, pp. 2183‚Äì2162.
16. Pricing chart of Amazon CloudFront. Available at: http://aws.amazon.com/cloudfront/
pricing/.
17. Choosing a CDN. Available at: http://www.streamingmedia.com/Articles/Editorial/Featur
ed-Articles/Choosing-a-CDN-65114.aspx.
18. R. Buyya, M. Pathan, and A. Vakali. Content Delivery Networks. Springer Publishing
Company, Incorporated, 1st edition, 2008, New York.

REFERENCES
319
19. K. Hosanagar, J. Chuang, R. Krishnan, and M. D. Smith. ‚ÄúService adoption and pric-
ing of content delivery network (CDN) services,‚Äù Management Science, 54(9), 2008,
1579‚Äì1593.
20. K. Hosanagar, R. Krishnan, M. Smith, and J. Chuang. Optimal pricing of content delivery
network (CDN) services. In Proceedings of the Proceedings of the 37th Annual Hawaii
International Conference on System Sciences (HICSS‚Äô04) - Track 7 - Volume 7, HICSS
‚Äô04, pages 70205.1‚Äì, Washington, DC, USA, 2004. IEEE Computer Society.
21. V. Kocsis and P. Bijl. ‚ÄúNetwork neutrality and the nature of competition between network
operators,‚Äù International Economics and Economic Policy, 4(2), 2007, 159‚Äì184.
22. R. Mason. ‚ÄúSimple competitive Internet pricing,‚Äù European Economic Review, 44(4-6),
2000, 1045‚Äì1056.
23. D. Goldman. Netflix is a bandwidth hog. Who will pay? (Hint: You.). Available at:
http://money.cnn.com/2010/11/30/technology/netflix_level3_comcast_traffic/index.htm.
24. W. Norton. The Netflix, Comcast and Level 3 Story. Available at: http://drpeering.
net/AskDrPeering/blog/articles/Ask_DrPeering/Entries/2011/9/6_Access_Power_Peering.
html.
25. N. S. Economides and J. Tg. ‚ÄúNetwork neutrality on the Internet: a two-sided market anal-
ysis,‚Äù Information Economics and Policy, 24(2), 2012, 91‚Äì104.
26. J.-P. Dube. ‚ÄúMultiple discreteness and product differentiation: Demand for carbonated soft
drinks,‚Äù. Marketing Science, 23(1), 2004, 66‚Äì81.
27. I.
Hendel.
Estimating
Multiple-Discrete
Choice
Models:
An
Application
to
Computeri-Zzation Returns. Working Paper 168, National Bureau of Economic
Research, October 1994.
28. C. R. Bhat and S. Sen. ‚ÄúHousehold vehicle type holdings and usage: an application of
the multiple discrete-continuous extreme value (mdcev) model,‚Äù Transportation Research
Part B: Methodological, 40(1), 2006, 35‚Äì53.
29. Competition in economics. Available at: https://en.wikipedia.org/wiki/Competition_
(economics).
30. M. Shubik. Strategy and Market Structure. John Wiley & Sons, Inc., New York, 1959.
31. X. Vives. ‚ÄúEdgeworth and modern oligopoly theory,‚Äù European Economic Review,
37(2-3), 1993, 463‚Äì476.
32. H. Hotelling. ‚ÄúStability in competition,‚Äù. Economic Journal, 39(1), 1929, 41‚Äì57.
33. Bellman equations. Available at: http://en.wikipedia.org/wiki/Bellman_equation.
34. A. Pakes and P. McGuire. ‚ÄúComputing Markov-perfect Nash equilibria: Numerical impli-
cations of a dynamic differentiated product model,‚Äù RAND Journal of Economics, 25(4),
1994, 555‚Äì589.
35. R. Ericson and A. Pakes. ‚ÄúMarkov-perfect industry dynamics: a framework for empirical
work,‚Äù Review of Economic Studies, 62(1), 1995, 53‚Äì82.
36. G. Gowrisankaran and R. J. Town. ‚ÄúDynamic equilibrium in the hospital industry,‚Äù Journal
of Economics & Management Strategy, 6(1), 1997, 45‚Äì74.
37. S. P. Ryan. The Costs of Environmental Regulation in a Concentrated Industry. 2006 Meet-
ing Papers 9, Society for Economic Dynamics, 2006.
38. C. A. Laincz. ‚ÄúMarket structure and endogenous productivity growth: how do R&D subsi-
dies affect market structure?‚Äù Journal of Economic Dynamics and Control, 29(1-2), 2005,
187‚Äì223.

320
CDN PRICING AND INVESTMENT STRATEGY UNDER COMPETITION
39. S. Berry and A. Pakes. ‚ÄúSome applications and limitations of recent advances in empiri-
cal industrial organization: merger analysis,‚Äù American Economic Review, 83(2), 1993‚Äì,
247‚Äì52.
40. F. Schivardi and M. Schneider. Strategic Experimentation and Disruptive Technological
Change. CEPR Discussion Papers 4925, C.E.P.R. Discussion Papers, 2005.
41. J. Kim, G. M. Allenby, and P. E. Rossi. ‚ÄúModeling consumer demand for variety,‚Äù Mar-
keting Science, 21(3), 2002, 229‚Äì250.
42. E. Maskin and J. Tirole. Markov Perfect Equilibrium, I: Observable Actions. Harvard
Institute of Economic Research Working Papers 1799, Harvard‚ÄìInstitute of Economic
Research, 1997.
43. A. Pakes. IO Class Notes: Multiple Agent Dynamics; An Intro to Markov Perfect Equi-
libria, 2009.
44. Y. Song, A. Venkataramani, and L. Gao. On CDN pricing game. Available at:
https://sites.google.com/site/cdngametechreport/cdn.
45. Y. Song, A. Venkataramani, and L. Gao. On CDN pricing game. In The 2nd IEEE Inter-
national Workshop on Smart Data Pricing, 2013.
46. M. E. B. Akiva and S. R. Lerman. Discrete Choice Analysis: Theory and Application to
Predict Travel Demand, Mit Press Series in Transportation Studies, 9. Mit Press, 1985,
Boston.
47. Dan Rayburn Cisco: the need for CDN federation. Available at: http://www.streaming
media.com/Articles/Editorial/Featured-Articles/Cisco-The-Need-for-CDN-Federation-83
223.aspx.
48. Dan Rayburn CDN Federation: A Badly-Defined Solution in Search of a Real Prob-
lem? Available at: http://www.streamingmedia.com/Articles/Editorial/Featured-Articles/
CDN-Federation-A-Badly-Defined-Solution-in-Search-of-a-Real-Problem-80757.aspx.

12
Smart Pricing and Market
Formation in Hybrid Networks
ARIS M. OUKSEL, DOUG LUNDQUIST, and
SID BHATTACHARYYA
12.1
SPECTRUM SHORTAGE
Over the past decade, the total demand in the United States for wireless services has
approximately doubled annually. Although that trend is slowing (with 60% growth
forecast for 2014), growth is still expected to be strong for the next several years [1].
This growing demand for wireless services is creating the so-called ‚Äúspectrum short-
age,‚Äù which the United States is starting to address through its National Broadband
Plan. In short, the demand for information too often exceeds the capacity of wireless
networks to deliver it. In major markets, this phenomenon is already affecting service
quality, as users experience reduced data rates because of peak activity.
The growth in demand for wireless services has three main sources. First, the num-
ber of network subscribers has been steadily increasing; this is largely due to the
popularity of smartphones and tablets, which are continually becoming more pow-
erful and more useful. Second, individual applications are becoming increasingly
data intensive; streaming video is the most familiar example and, as video quality
improves, becomes more data intensive. Third, the peak density of network sub-
scribers is increasing. In the near future, applications requiring machine-to-machine
communication (such as vehicular safety) will materially add to demand. Together,
these growth factors are making demand outpace expected service availability in
many areas.
The Federal Communication Commission‚Äôs forecasts project 275 MHz of addi-
tional spectrum will be needed to meet demand by 2014 [2]. The shortage will not, of
course, be experienced uniformly. While rural areas may not experience substantial
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
321

322
SMART PRICING AND MARKET FORMATION IN HYBRID CELLULAR
quality-of-service (QoS) degradation, urban areas (where the densities of both users
and infrastructure are highest) certainly will, especially during times of peak demand.
Even now, networks must often cap consumption of wireless services, whether by
imposing steep fees for exceeding data plans or simply limiting users‚Äô download
speeds. A thorough and current survey of extant methods for reducing congestion
is provided by Sen et al. [3]. Networks that can maintain or improve their QoS in the
face of this growing demand will have a clear competitive advantage.
Numerous solutions have been proposed and implemented to increase network
capacity and address the imminent spectrum shortage. One class of solutions is tech-
nological, which includes developing wireless standards with faster data rates, such
as the recent IEEE 802.11ac. Another involves more efficient ownership. Many usage
rights are owned by firms with no near-term prospects of actually using them; net-
works with an urgent need for additional usage rights might buy them to expand
capacity. Researchers have also proposed methods to flatten peak demand by incen-
tivizing delayed network activity [4, 5]. Our solution is a novel network architecture
and incentive program to encourage use of peer-to-peer (P2P) networking to expand
the capacity of cellular networks.
Our model, in essence, provides a relief valve for congestion in cellular networks.
When cellular networks are congested, they can subcontract a set of P2P networks
to manage some of their load. Each P2P network will consist of multiple WiFi base
stations, each governing network traffic in its vicinity. We envision that not all nodes
will be within direct communication range of a base station, so the P2P network will
require participants to act cooperatively‚Äîforwarding network traffic for others. Par-
ticipation incentives will be offered to join the P2P network rather than remaining
in the congested cellular network and may be adjusted to reflect differing participa-
tion, increasing for nodes that relay network traffic for other nodes and decreasing for
nodes that consume a larger fraction of the P2P network‚Äôs capacity. Additional incen-
tives may be offered to encourage more continuous participation (and longer-term
data caching), as opposed to nodes only remaining in the P2P network while they
are actively requesting information. The roles and incentives of this hybrid network
architecture are given in Table 12.1.
TABLE 12.1
Network Roles and Incentives
Party
Role
Incentive
Cellular network
Pays P2P network
Improves response time
Provides aggregate usage
data
Can delay adding capacity
Can support more subscribers
P2P network
Provides network services
Paid by cellular network
Distributes incentives to
participants
Optimizes responsiveness
Network subscribers
Opts into P2P network
Paid by P2P network
Potentially paid for forward-
ing other users‚Äô traffic

PEER-TO-PEER NETWORKING
323
Currently, cellular network subscription plans typically allow users to switch
between 3G/4G and WiFi networks, the incentive for users being that using the WiFi
network does not deplete the subscriber‚Äôs minutes or data plan, as applicable. The
differences between our proposed hybrid network and extant commercial models are
‚Ä¢ cellular network selection of P2P participants,
‚Ä¢ incentive distribution for P2P network participation,
‚Ä¢ multi-hop access to WiFi base stations (rather than only direct communication),
‚Ä¢ automatic activity-driven incentive adjustments in the P2P network.
Managing this hybrid network to maximize profitability will entail solving multi-
ple optimization problems, which we address in the following sections of this chapter.
What participation level should the P2P network seek? Given the need for multi-hop
communication between nodes and the base station, the P2P network will need suffi-
cient density to enable continuous routing paths. However, although some additional
density will be desirable as a safety margin (for when nodes exit the P2P network),
additional participation may provide little value. Thus, the optimal network density
is slightly higher than the minimum sufficient density. How should participants be
incentivized to achieve the optimal density, especially given that willingness to par-
ticipate will differ according to location, time, and other factors? And, finally, what
contextual information needs to be gathered to support these decisions in dynamic
environments?
We present our model from a bottom-up perspective, introducing its components
and underlying concepts before explaining how they operate together. Before intro-
ducing our optimization model, the next three sections will cover
‚Ä¢ P2P networking,
‚Ä¢ commercial viability,
‚Ä¢ Self-Balancing Supply/Demand (SBSD)protocol.
12.2
PEER-TO-PEER NETWORKING
The defining characteristic of P2P networking is the equality of network participants.
In client‚Äìserver models, all communication progresses up and down the network
hierarchy. For example, a message sent from one client to another is not transmitted
directly but must be sent up to a server and then down to the destination client. In
contrast, the network architecture and node roles are more flexible in P2P models;
nodes typically act as routers for their peers (other nodes in the network) and forward
network traffic for them. In fact, any node in a P2P network may function as a client
or server in regard to a particular query or response‚Äîprovided, of course, that it
has the requested information and that the nodes have common protocols to regulate
their interactions. Compared to traditional client‚Äìserver models, P2P offers some
important advantages:

324
SMART PRICING AND MARKET FORMATION IN HYBRID CELLULAR
‚Ä¢ Load Sharing. The decentralized structure of P2P networks enables better load
sharing, because network traffic does not have to always be routed through a
centralized server. Better predictive caching models (placing information near
likely query sources) support improved load sharing.
‚Ä¢ Faster Response Time. By decentralizing network traffic, each peer server may
only need to respond to relatively few queries even under heavy total network
traffic. Consequently, response time can be faster. This is especially important
for multi-hop routing in wireless ad hoc networks, where the communication
medium must be shared among potentially large node groups.
‚Ä¢ Minimal Oversight. Typically, P2P applications require minimal oversight,
because they do not rely on the continuous operation and availability
of centralized servers. The loss of a server node will not disable the
network.
Although our concern is wireless networking, the principles of P2P models apply
to both wired and wireless networks. For wired networks, the music sharing appli-
cation Napster is a well-known early P2P model, although in fact it was supported
by centralized servers. In Napster‚Äôs P2P model, users would register their available
files at one of Napster‚Äôs servers, where other users were able to search for content.
The actual file transfer, however, occurred directly between the two users in ques-
tion. Other more recent P2P applications, such as Freenet (www.freenet.net), operate
entirely without such centralized server support.
As far as wireless networks, P2P models have been proposed and implemented
for numerous uses; although somewhat dated, Akyildiz and Wang [6] provides a
good introduction to their basic practical issues. Of particular interest are situational
awareness applications, where groups of nodes share their knowledge about contex-
tual variables, such as the location, mobility, density, and activity of groups of nodes.
Many such applications (e.g., vehicular safety by sharing real-time mobility data)
rely on all nodes gathering and forwarding continuous updates on variables of inter-
est. These applications naturally conform to P2P models when contextual data is not
sent to or obtained from centralized locations. Situational awareness applications can
rely on networks of static or mobile nodes, with somewhat different characteristics
in practice for each.
When nodes are static, data is typically gathered continuously by sensor nodes
and directed to one or more data sinks. Most often, the data sinks may simply store
the data (e.g., in remotely deployed environmental monitoring networks) or intermit-
tently forward batches of data outside the sensor network (to respond to queries or
provide real-time updates to network users). In some cases, however, the informa-
tion might be used by the sensor nodes themselves (e.g., cross-checking observed
variables as a means to detect observation errors or defective sensors).
For networks of mobile nodes, similar concerns arise. Mobile node groups may
elect data sinks or interface with fixed infrastructure points. Compared to static
topologies, the fluidity of such networks tends to make reliance on direct communi-
cation between nodes more advisable. Routing data to sinks can impose delays that
degrade the value of continuous updates. For some applications, such as suggesting

COMMERCIAL VIABILITY
325
travel routes, moderate delays may be acceptable. Other applications, such as
vehicular safety, may be extremely time sensitive. For those, pure P2P models are
a natural and promising approach. Although P2P computing has numerous uses, it
also presents a number of challenges not present in client‚Äìserver models, especially
for multi-hop wireless networking.
‚Ä¢ Free Riding. P2P networking for multi-hop wireless networks requires that users
forward traffic for others. Policies must be implemented to make free riding
(using the P2P service without forwarding traffic for others) infeasible, essen-
tially by making free access contingent on providing services to other nodes.
Other nodes will either have their network access restricted or be charged for it.
‚Ä¢ Weaker Network Security. Wireless networks are inherently less secure than
wired networks, as any transmission can be overheard by nearby nodes.
Depending on the nature of the communication protocol and messages,
security concerns may include not only eavesdropping but even the proper
operation of the communication model.
‚Ä¢ User Density Requirements. In order to route packets quickly, multi-hop wire-
less routing requires sufficient node density to build complete end-to-end routes
without waiting for nodes to move into mutual communication range. The vari-
ety of potential P2P transmission ranges can, of course, allow for varying den-
sities over a route. However, as the maximum data rate is generally higher for
shorter transmission ranges, higher density should allow greater P2P network
throughput.
‚Ä¢ Encouraging Participation. User density provides an upper bound on the num-
ber of potential P2P network participants. Not all of them are likely to be willing
to forward network traffic for other users. Yet the presence of more willing users
will tend to drive down the cost of establishing a given P2P network density.
12.3
COMMERCIAL VIABILITY
In order to apply P2P as a support mechanism for cellular networks, the system must
be commercially viable. That is, the network company must recoup any expenses
associated with providing and monitoring the P2P service. Although a great deal of
research has been directed toward technical issues of P2P schemes, the relevant eco-
nomic considerations have been largely ignored. The basic economic issues have been
briefly covered in Reference [7], although little beyond recognizing that they exist as
open research problems.
We advocate a voluntary participation model, where the network compensates
cooperative P2P behaviors in the form of additional usage rights or reduced subscrip-
tion charges. Extant research, such as Reference [8], suggests that wireless network
subscribers are generally willing to modify their network usage in accordance with
incentive programs, even if the incentives are small. The core economic question is
what performance improvements can be obtained at what cost to the network provider.
The P2P network can provide additional network capacity, but the end result of this

326
SMART PRICING AND MARKET FORMATION IN HYBRID CELLULAR
extra capacity may take different forms depending on the network provider‚Äôs strategic
goals, such as the following.
‚Ä¢ More Data per User. The most direct use of the additional capacity is to simply
increase monthly data plans across the board for all users.
‚Ä¢ Increased Subscription Revenues. A network might keep its existing subscrip-
tion plans in place and use the additional capacity for promotions to attract new
customers.
‚Ä¢ Driving Down Operating Costs. Network providers will need to continuously
add capacity in order to keep up with growing demand for wireless services.
However, adopting P2P models can delay the need for such expansions, with
consequent lower operating costs.
These basic principles of P2P system goals are easily understood but do not
address the crucial question of participation pricing. That is, what compensation
should be offered to attract the needed P2P participation density? Not so low as to
fail to form a useful P2P network but not so high as to bring in many more nodes
than those required. This efficiency problem becomes more difficult in dynamic
wireless environments, where nodes may move rapidly, participate intermittently,
and so on. Ideally, the network would also monitor the popularity of queries to drive
data caching decisions. To achieve that, network providers need to continuously
monitor node density, the popularity of queries, and the persistence of nodes in the
network.
While the cellular network is congested, the P2P network will operate contin-
uously in parallel with it. To ensure its continuous operation, incentives must be
paid out to encourage cooperative behaviors among nodes. This gives rise to two
fundamental questions that must be answered. First, what total incentives will be
distributed to the P2P network participants; that is, how much will it cost to create
and maintain it? Second, how will those incentives be distributed to the individual
participants?
In general, we would assume an increasing asymptotic function for the total value
of the set of participating nodes over any given time period. This implies a decreasing
and approximately hyperbolic function for the value of each individual node‚Äôs partic-
ipation. Further, assuming nodes have variable willingness to participate, increasing
the node density will reduce the cost of obtaining a given number of participants.
The exact function parameters will, of course, vary across different networks but its
general shape will be known. Importantly, however, when node density is high in the
cellular network, the costs of creating the P2P network will be relatively low.
The next question is devising functions that describe this model. Here, there are
analogues with congestion pricing in transportation. In those models, such as Nie
[9], the goal is inducing a sufficient number of drivers to leave the roads to achieve a
system optimal set of travel times. In a real-time environment, this can be achieved by
requiring payment of tolls and, in principle, accruing additional payments to drivers
that are not on the road. Applying this type of model to our proposed P2P network
requires a slightly different framework.

COMMERCIAL VIABILITY
327
Instead of charging drivers to remain on the roads, we would approach the problem
strictly from an incentivization standpoint. That is, because network users already pay
subscription fees, there is no need to levy additional charges. Instead, the P2P network
functions to support the cellular network, and so participation (to enable gathering
state information as well as actually forwarding packets for other nodes) would be
rewarded. The incentives distributed to create the P2P network can be obtained as a
prorated share of subscription fees for the congested periods. Because these incentives
will be distributed according to individual nodes‚Äô assistance in creating the network,
the P2P network can function entirely on a compensated voluntary basis.
We can formulate the costs of maintaining the P2P network as follows. Assume
that n users wish to use the cellular network that can only support c users at the desired
QoS. Assume also that each of the n users has paid ki to use the cellular network
during interval i. Then, the users above the cellular network‚Äôs capacity can provide
(n ‚àíc) ki over interval i. This quantity must be shared with the P2P network partici-
pants, whose share in interval i we indicate by ùúîi, 0 < ùúîi < 1. There will remain the
quantity (n ‚àíc) ki
(1 ‚àíùúîi
) to be kept by the cellular and P2P network providers.
Although the above model serves to illustrate how the P2P network will be funded,
multiple practical refinements suggest themselves. First, the (n ‚àíc) users may be
insufficient (or indeed too numerous) to form a P2P network with adequate QoS.
Second, the cellular network provider will wish to minimize ùúîi within each interval
in order to maximize profitability, while maintaining adequate QoS in both the P2P
and cellular networks. Lastly, the size of the interval i is important; finer granularity
will enable faster response to changing network conditions, potentially enhancing
both profitability and QoS.
In order to set appropriate incentives in dynamic environments, the network
provider must continuously gather smart pricing information (SPI). This information
can then be leveraged to enhance routing performance (in terms of packet delivery
ratio and latency). The key difference between the cellular network and the P2P
network is that the cellular network can reasonably ensure access to any requested
information, while the P2P network only allows access to information cached at
participating nodes and then only probabilistically. So, it is imperative for the P2P
network to not only provide complete routing paths but also to cache information
likely to be requested by nearby nodes.
The P2P network requires estimates of the following.
‚Ä¢ Demand for Information. It is a well-known fact that information is often
requested by multiple users. In fact, this is essential to Google‚Äôs caching
functions, where more popular pages are kept more accessible. Applications
with a geographic component (such as travel assistance) are especially likely
to have coocated demand. On the other hand, it is also true that unique or
highly infrequent requests should not be retained in the P2P network, as their
likelihood of reuse is small.
‚Ä¢ Required Incentives. We expect that users will largely rely on pricing assistance
software to set their participation threshold. That is because few users would
wish to constantly monitor such microtransactions. These automated assistants

328
SMART PRICING AND MARKET FORMATION IN HYBRID CELLULAR
will inform the network provider, at the very least, about which price offers are
accepted and which are rejected. Combined with data about time and participa-
tion density, this information will support estimating participation as a function
of incentive price.
‚Ä¢ Predictive Caching. To place information near likely queries, it is necessary
to gather information about the locations of query sources. Then, participating
nodes can cache information in accordance with estimated future demand. This
will both reduce the communication costs of searching for information (i.e., a
smaller set of nodes can be searched) and of obtaining it (because routing paths
will be shorter).
12.4
SELF-BALANCING SUPPLY/DEMAND
Our SBSD protocol is a paradigm for demand-driven information search and discov-
ery. Unlike point-to-point routing protocols [such as Ad Hoc On-Demand Distance
Vector (AODV) and Dynamic Source Routing (DSR)], which focus narrowly on con-
structing routing paths between known pairs of nodes, SBSD combines dynamic
controlled flooding with predictive caching [10]. Our SBSD‚Äôs predictive caching
model and medium access control functions encompass the SPI requirements for our
proposed P2P network model.
Flooding-based routing performs well in high mobility environments, where mes-
sage destinations are very often unknown and any routes between them are ephemeral.
Further, when multiple nodes request the same information, flooding can enable sub-
stantially faster responses to network users by widely caching popular information.
This is a sensible approach when query sources do not know the query‚Äôs destination
and when multiple nodes often request the same information.
The basic SBSD model strives to flood query packets (and any matching responses
found) in the vicinity of their sources. The depth of a given query‚Äôs flooding depends
on its popularity (how many other nodes have posted the same query) relative to others
nearby. All else equal, the size of the flooding area is approximately a linear func-
tion of the frequency of demand. SBSD also controls the persistence of information
according to a spatiotemporal utility function (given in the next paragraph). Packets
closer in time and distance to their sources will be retained longer.
Each node will retain a queue of queries and responses to be retained until expira-
tion (or perhaps discarded in the unlikely event of memory storage being overloaded).
The items in this queue are ranked according to the utility function:
u = ‚àía
‚àö
h
3‚àö
f
,
where u is the item‚Äôs utility, a is its age (the time since the item was created or most
recently requested), h is the hop count (the number of hops traversed en route to its
location), and f is its frequency (the number of unique users interested in the item,
either posting the same query or receiving the same response).

SELF-BALANCING SUPPLY/DEMAND
329
The utility-based ranking is used to enable autonomous node decisions to create
predictable group behaviors. Each node individually estimates the set of high utility
items it will be able to forward during their remaining times to live. This estimation
creates a forwarding threshold. Items with sufficiently high utility are forwarded until
their utility declines below the threshold (primarily due to aging without compen-
sating demand increases). The low utility items are simply cached until expiration,
unless new demand for them boosts their frequency or resets their age. As most nearby
copies of an item will have similar utility values, an item‚Äôs flooding area tends to
expand to a predictable flooding depth given a locally known arrival rate for new
items.
Our utility function provides the important result of creating a linear relationship
between an item‚Äôs popular and its total contribution to network congestion during
its lifetime [11]. That is, more popular items are granted a proportionally greater
consumption of network resources. The above utility function approximates the
negative ratio between the network congestion an item will ultimately be allowed to
create and how much it has already created. That is, as an item‚Äôs flooding proceeds,
the transmissions of its copies add more to network congestion, which lowers the
utility of creating new copies in the network. Further, this ratio‚Äôs approximation
is made without incurring the communication overhead to calculate either item
separately.
We have developed a number of extensions to our SBSD protocol enabling
more efficient delivery than provided through flooding. In a variety of ways, these
extensions reduce the prevalence of redundant transmissions (where recipients
have already received a copy of a transmitted packet). They can be applied to
increase search depth for queries, propagation depth for response data, additional
transmissions for more reliable delivery, or combinations thereof. The most recent
of these extensions, Reference [12], considers geographically constrained flooding
areas for vehicular networking in order to boost network throughput.
The SBSD model provides a means to obtain the following essential data, which
may be delivered intermittently in batches or via sampling to the network provider.
‚Ä¢ What Information Is Popular? Highly skewed demands for information are seen
in many domains. Although somewhat dated, Reference [13] for example, ana-
lyzed a large search engine log (of a billion searches) and found that the most
popular 25 queries accounted for 1.5% of search activity. Streaming video is
another case, where the most popular videos can accumulate hundreds of mil-
lions of views while many videos struggle to reach a few thousand.
‚Ä¢ Where Is It Popular? In terms of predictive caching for the P2P network, it is
vital to know the corelation between popularity and location. If, for example,
two users want the same information but are miles apart, multi-hop routing is
probably not a good approach. However, many situational awareness applica-
tions tend to naturally provide users with information that is closely correlated
with location. Vehicular safety and travel information are good examples, as
many cars in an area will need the same information about nearby vehicles and
travel routes.

330
SMART PRICING AND MARKET FORMATION IN HYBRID CELLULAR
‚Ä¢ Node Density, Topology, and Mobility. In order to estimate the participation
requirements for the P2P network, the network provider must know an approx-
imate distribution of the node population. The alternative would be to learn this
on the fly, which naturally adds an extra layer of delay to the P2P network. That
is, if node density is insufficient, that fact has to be learned before incentives
can be offered to boost density.
‚Ä¢ Willingness to Participate. The set of nodes in a given area will be known to the
cellular network. From their past participation history, the cellular network will
be able to estimate what incentives are necessary to ensure sufficient coopera-
tion to achieve performance targets. Such estimates may be further refined by
considering node density and cellular network congestion
12.5
HYBRID NETWORK MODEL OVERVIEW
Our proposed model [14] will regulate load sharing in the hybrid cellular‚ÄìP2P net-
work. When the cellular network becomes congested, it will release a portion of its
customers and assign them to the P2P network. The goal is that all users will receive
better QoS than in the congested cellular network. The customers who remain in the
cellular network will benefit from the reduced congestion level, while those added to
the P2P network will receive QoS at least equal to what they would have obtained if
they remained in the congested cellular network. As customers enter and leave the
networks, they will need to be assigned to one network or the other. Ultimately, when
the cellular network‚Äôs congestion is sufficiently low, all customers in the P2P network
will resume using the cellular network.
Our intention is to implement our model without disrupting the cellular network‚Äôs
existing methods of operation. Instead, our model will seamlessly add capacity to
the cellular network through a system of voluntary, incentivized participation. Rather
than attempt to dynamically adjust incentives to current needs, the cellular network
will assign nodes to the P2P network with indeterminate future incentives. Imple-
menting this model will require coordinating organizational, algorithmic, hardware,
distributed accounting, and security elements.
12.5.1
Organization
We propose a voluntary participation regime. By default, customers will be candidates
for participation in the P2P network. Although they may choose to never participate,
they would then no longer be eligible to receive the participation incentives. When
the cellular network actually becomes congested, and customers are assigned to the
P2P network, they may also opt out through the user interface. But requiring users to
explicitly opt out will make the default participation more prevalent.
The cellular network will need to determine the desired node density for the
P2P network (to provide QoS comparable to that of the cellular network). This
determination might be accomplished through a combination of initial context-based
estimates and iterative convergence. In general terms, the trade-off is that increasing

HYBRID NETWORK MODEL OVERVIEW
331
participation will initially improve performance (by providing greater end-to-end
connectivity) but eventually cause congestion from the participants‚Äô own network
traffic.
Smart selection of P2P network participants can maximize the benefit to the cel-
lular network while minimizing the cost for the P2P network. For example, nodes
that are both near the P2P infrastructure and are conducting data-intensive activities
would be ideal candidates. This will improve the QoS of the cellular network for a
while, because the routing path will be short, minimizing the incentives needed to
deliver the requested content. More generally, network congestion within the area
covered by a P2P network can be managed by a combination of shorter transmission
ranges and smaller P2P networks. Both of those techniques will increase the network
throughput per unit area.
12.5.2
Algorithms
Nodes participating in the P2P network will use our SBSD protocol [10] for infor-
mation search and discovery. The SBSD protocol is built around demand-driven con-
trolled flooding. It causes more popular information to be cached more widely, more
persistently, and nearer to future query sources. Ultimately, this approach will reduce
the costs of information search within the network; not all traffic will need to be
routed all the way to the P2P network‚Äôs infrastructure. Further, SBSD will automati-
cally regulate the boundaries for competing traffic of nearby P2P infrastructure points
without any centralized oversight.
12.5.3
Hardware
Ideally, the SBSD algorithms would be offered as chips or modules that can be eas-
ily swapped out of phones, although they might initially be offered as free or low
cost software applications to encourage adoption. Each smartphone or other mobile
computing device will contain a miniaturized module that provides the SBSD func-
tionality (to allow participation in the P2P network) and tracks participation (for
real-time conversion to incentives). This module will be a ‚Äúblack box‚Äù to prevent
tampering with the dynamic pricing. As well, the mobile devices will require inter-
operable wireless technology components to enable interacting with the P2P network
(various WiFi technologies are, of course, standard features on smartphones).
12.5.4
Distributed Accounting
The total of incentives to be distributed among the P2P network participants depends
on the congestion level as well. That is, the P2P incentives are taken as a portion of
the cellular network users‚Äô prorated subscription costs. The presence of heavier traffic
in the cellular network indicates more intense demand for wireless services. If QoS
can be maintained while adding additional capacity, greater revenues and profits can
be realized. Further, this intense demand should translate into greater willingness to
participate in the P2P network, which can then operate with a reduced incentivization
plan.

332
SMART PRICING AND MARKET FORMATION IN HYBRID CELLULAR
The cellular network needs a mechanism for evaluating each node‚Äôs participation
as a fraction of P2P network activity. This has two applications. First, the P2P network
must aggregate participation data as a baseline for prorating each node‚Äôs incentives
according the fraction of network traffic they forward. Second, in order to regulate
activity within the P2P network, nodes will track their own generated traffic compared
to that of their peers. Priority access will be granted to nodes that generate less traffic.
Those nodes that generate more traffic will have their packets delayed the most if the
P2P network becomes congested.
Because nodes may only participate in the P2P network for short periods, it may
be desirable to offer an additional layer of incentives for more persistent participa-
tions. Alternatively, more redundant caching may be used to address intermittent node
participation without sacrificing QoS (especially for continuous streaming applica-
tions). Yet, this redundancy also limits throughput, so a balance must be struck for
more reliable delivery at reduced volume.
12.5.5
Network Security
Controls will be necessary to exclude noncustomers from the P2P network. When a
node is assigned to the P2P network, it needs to have its registration confirmed. This
will be achieved through direct interactions with nearby nodes; those with an appro-
priate encrypted ID (belonging to a participating cellular network) will have their
traffic forwarded by other nodes and interact directly with the P2P network infras-
tructure. This functionality will be provided by the SBSD module.
12.6
INCENTIVE MODELING
Our proposed P2P incentive model was inspired by our earlier work in modeling
congestion management and vehicular pollution in the transportation domain [15].
The similarities between transportation and wireless networking are clear: in both,
individual users of a shared resource (whether a set of roads or the wireless com-
munication medium) impose negative externalities on other users. The basis of our
solution is a Pigouvian tax model in which users are charged according to their neg-
ative externalities in order to arrive at a socially optimal consumption of the shared
resource.
In the transportation domain, traffic congestion is primarily relieved by charging
tolls (to directly reduce the number of vehicles on the road, either by inducing them
to take less congested routes, switch modes, or not drive during congested times).
Related models have been developed to support searches and dynamic pricing for
parking spaces, which can also suffer from congestion when demand exceeds supply
[16]. Likewise, packet routing can be modeled as a set of data flows between sources
and destinations and network congestion as a cost that rises with the volume of data
the network handles.
For our P2P network, we wish to minimize network congestion primarily through
autonomous node decisions. This is accomplished through a pair of models both of

FLOW MODEL
333
which offer users trade-offs between their individual QoS and their earned incentives.
The first is a flow model that estimates the P2P network congestion generated by a
given set of nodes and their generated network traffic. The second is a prioritization
model, where some network traffic may be delayed during congested periods; this is
analogous to charging tolls for faster travel routes or paying some vehicles to park
during peak traffic. In both cases, users have the option to receive improved QoS by
accepting a smaller quantity of incentives.
12.7
FLOW MODEL
Our flow model represents the P2P network as a graph of vertices and edges, in which
data flows are managed to maintain congestion below an acceptable level determined
by the cellular network. Each vertex represents a nonnull set of participating mobile
devices and each edge represents a link between such groups of mobile devices.
Depending on the granularity desired, nodes at a given vertex might all be in mutual
communication range or be more dispersed. Edges represent direct communication
links between at least one pair of nodes from adjacent vertices. Data flows over edges;
when network traffic is heavier, the flows become slower.
Consider a graph network G(V, A) with a set V of vertices and a set E of edges.
‚Ä¢ For an edge e ‚ààE, let xe be its network traffic (x ‚â•0) and t(xe
) be the time
required to traverse e, where we assume t(xe
) is a nonnegative, strictly increas-
ing, and convex function. Because our SBSD model uses controlled flooding,
we adopt a first-order approximation of modeling network traffic as uniform
across all edges in E.
‚Ä¢ The planning horizon is M periods. For precise management, the planning hori-
zon may be divided into an arbitrarily large number of periods but which will
entail additional computational costs and more frequent information gathering
about network topology and congestion. On the other hand, if peak network
traffic is sufficiently uniform, it might be sufficient to simply set M = 1, that is,
a single-period planning horizon.
‚Ä¢ Let R and S, respectively, denote the sets of origin and destination nodes. The
amount of network traffic to be routed from any r ‚ààR to any s ‚ààS is represented
by qrs.
‚Ä¢ The set of paths connecting an origin‚Äìdestination pair rs is denoted by Krs, and
during a period m, the flow on path k‚àÄk ‚ààKrs is represented by f rs
km.
‚Ä¢ The P2P network participation incentives are equally shared among all partici-
pating nodes and are depleted as nodes contribute to network congestion. Nodes
are permitted to purchase additional congestion rights from other nodes. Let
the unit price of buying additional congestion rights for period m through the
competitive bidding process be ùúåm multiplied by a transaction cost factor ùúè.
‚Ä¢ Let ùúÄ(m, xe
) denote the congestion (i.e., the delay on all other network traffic)
inflicted by network traffic x on edge e in period ‚ààM. Following our assumption

334
SMART PRICING AND MARKET FORMATION IN HYBRID CELLULAR
that t(xe
) increases with x, ùúÄ(m, xe
) is a nonnegative, strictly increasing, and
convex function.
‚Ä¢ Let Cm be the maximum network congestion permitted in a period m; the max-
imum congestion permitted over the entire planning horizon is ‚àëM
m=1 Cm.
‚Ä¢ Each node in the P2P network is granted the right to inflict an average amount
of congestion by injecting new network traffic. Let A
(‚àëM
m=1 Cm
)
be the cost
of assigning the ‚àëM
m=1 Cm congestion rights over the planning horizon. As this
communication will further increase network traffic, the function A
(‚àëM
m=1 Cm
)
is a nonnegative, strictly increasing, and convex.
We formulate the equilibrium problem with network congestion costs as
Input Data. C (‚ãÖ) , ùúÄn (‚ãÖ) , t (‚ãÖ) , ùúåm, ùúè, qrs, m, where e ‚ààE, r ‚ààR, s ‚ààS, and M =
1, 2, ‚Ä¶ , m.
Decision Variables. Mm, xe, f rs
km, where k ‚ààKrs, r ‚ààR, s ‚ààS, e ‚ààE, and M =
1, 2, ‚Ä¶ , m.
min Z (x, Cm, f rs
km
) =
M
‚àë
m=1
‚àë
e
(
‚à´
xe
0
t (xe
) dt + xe
(ùúåmùúè))
+ A
( M
‚àë
m=1
Cm
)
subject to:
M
‚àë
m=1
‚àë
k
f rs
km = qrs r ‚ààR, s ‚ààS
‚àë
r
‚àë
s
‚àë
k
f rs
kmùõørs
e,k,m = xe e ‚ààE, k ‚ààK, r ‚ààR, s ‚ààS, m ‚ààM
ùõø= 1 if e‚ààK
= 0 otherwise
ùúÄ(m, xe
) ‚â§Cm e ‚ààE, m ‚ààM
f rs
km ‚â•0 k ‚ààKrs, r ‚ààR, s ‚ààS, xe ‚â•0, e ‚ààE, m ‚ààM
The above model extends [17], a single-period pollution credit trading model with
a known total pollution cap M1 and no transaction costs. Setting our model parameters
as m = 1, ùúÄ(x1
) = ‚àë
e ùúåmxe, and A
(‚àëM
m=1 Cm
)
= œÑ = 0, and using a known constant
Cm, our model reduces to the one from [17]. Our model is feasible, similar to the
simpler classical traffic assignment problem, and contains features needed to consider
the broader impacts of network congestion policies, which are needed to guard against
unintended consequences of policy decisions. The following are few examples.
Variable Period and Horizon Caps. Letting Cm(m = 1, 2, ‚Ä¶ , M) change allows
analyzing the consequences of dynamic congestion caps, such as for peak and
off-peak loads. The overall cap ‚àëM
m=1 Cm may also be changed. During many

FLOW MODEL
335
periods, no monitoring may be needed, for example, for light network traffic
typical of late evening and early morning. Variable horizon caps allow consid-
ering transitions across temporal monitoring boundaries.
Realistic Congestion Levels. Congestion is not a simple linear function of node
density but is affected by node behaviors, network topology, and sources of
interference from outside the P2P network. The pollution constraint represented
by ùúÄ(m, xe
) is a nonnegative, strictly increasing, and convex function; it does
not assume linearity.
Moving Beyond Simple Linear Relationships. Including congestion rights
A (C1, C2, ‚Ä¶ , Cm
) in the objective function lets us explicitly incorporate the
effect of congestion rights on optimal flows in our analysis. This is particularly
necessary for systems with many monitoring points, which increases system
complexity.
Cellular Network Involvement. The model determines the optimal congestion cap
but the cellular network might select a different congestion cap to achieve other
goals, such as operating the P2P network to reach particular performance tar-
gets. The model also informs system planners what costs are required to impose
a range of potential congestion cap distributions.
Incentive models can yield unintended consequences. As shown in Reference [18],
price discrimination across different types of network traffic sometimes benefits the
network provider at the expense of customers, sometimes the opposite, and in some
cases benefits both. To better understand the likely consequences of network policy
decisions, our flow model might be further developed to consider the following factors
more deeply.
Balancing Congestion. To balance congestion across cellular and P2P compo-
nents of the hybrid network, the congestion target for the P2P network must
match that of the cellular network. However, the P2P network has the addi-
tional constraint of requiring a minimum node density to provide continuous
routing paths.
Graph Modeling. The grouping of P2P network nodes into vertices is a necessary
abstraction for our model; treating each node as a vertex would continuously
require an enormous amount of communication to track network topology.
However, the abstraction leads to difficult modeling questions. How many
nodes should a vertex contain? What area should those nodes occupy? How
many hops should traverse a vertex? One solution is for the cellular network
may specifically select nodes that are densely located on or near major roads.
This will simultaneously address P2P node density concerns while conforming
to the link-based transportation model assumptions.
Density Modeling. In transportation models, vehicle density converts almost
directly to traffic density. There might be some large trucks and buses that
take up additional space but, typically, they compose a small fraction of
total vehicular traffic. For wireless networking, however, it is important to

336
SMART PRICING AND MARKET FORMATION IN HYBRID CELLULAR
distinguish between individual nodes. Individual node contributions to traffic
can vary far greater than vehicle sizes (e.g., compare a customer watching
streaming video vs one intermittently loading web pages).
Monitored Variables. Pollution in the transportation model corresponds to the net-
work congestion produced by each node. The impact of congestion will be felt
differently in the cellular and P2P networks. That is, in the cellular network,
assuming a constant per-node network traffic quantity, congestion rises linearly
with the node population governed by a given cell tower. In the P2P network,
however, the benefits of node population initially outweigh the likely costs of
congestion.
Predictive Congestion Cap. As congestion in the P2P network increases, some
network traffic will simply expire before it reaches its destination. In terms
of congestion management, it would be better for nodes to post their queries
in subsequent periods. For such cases, a sensible policy would be to enforce
delays on additional traffic for which congestion rights cannot be bought from
other network participants.
Intermittent Node Participation. To improve the model‚Äôs accuracy, the length of
each period should be less than the typical duration of P2P participation. This
will allow better assessments of incentive requirements and needs for new par-
ticipations but will require additional tracking of nodes. Given those facts, the
cellular network might opt instead to provide additional incentives for nodes
willing to participate across multiple periods.
12.8
PRIORITIZATION MODEL
We have also formulated low overhead approaches to regulating P2P network traffic
in terms of autonomous forwarding decisions by individual nodes. That is, how do
nodes prioritize network traffic without exacerbating congestion by adding many new
rounds of communication? When the P2P network is congested, the participation
incentives can be adjusted according to the willingness of nodes to accept delays on
their communications. While maintaining the same total incentives for the entire P2P
network, nodes that accept such delays will obtain a share of participation incentives
from other nodes.
We enable nodes to rank traffic through another utility model, this one reflecting
the external costs of network congestion. Broadly, nodes accumulate incentives by
forwarding network traffic for other nodes and may consume incentives by injecting
their own traffic into the P2P network. Like our previous model for route assignments,
this model is also inspired from the transportation domain with the goal of jointly
capping vehicular pollution and congestion [16]. In that paper, models were presented
for cases where tradable pollution credits were either divisible or indivisible, that is,
a seller‚Äôs supply of pollution credits would be sold either in whole or not at all. For
example, a driver who elected to delay travel until congestion was relieved might
prefer to sell his/her entire stock of credits. In this networking domain, it may likewise
happen that transactions involve some of all of the node‚Äôs participation incentives.

PRIORITIZATION MODEL
337
12.8.1
Divisible Incentives
In this case, each P2P network user will choose a priority level from a range of options
offered by the network provider. According to the priority level chosen, a node‚Äôs
traffic will be more or less delayed, which will transfer credits from the high pri-
ority users to the low priority ones. As needed, nodes may purchase quantities of
credits from other users or, in the absence of nearby sellers, from the P2P network
provider.
Transactions are not actively conducted by individual nodes, nor are they neces-
sarily chosen to maximize incentive accumulation for particular nodes. Instead, our
model will rank potential transactions with a combination of individual node profit
and awareness of a transaction‚Äôs effect on network congestion, according to the utility
function for a trade g between a seller i and a buyer j as follows:
gij(p, ùõº, c(ŒîE)) = ùõºij
[
ùõæij
(
c (ŒîEi
) ‚àíc (ŒîEi
))
+ (1 ‚àíùõæij
) (
pj ‚àípi
) ùúÉ(
pj ‚àípi
)
ùúÉ
(
c (ŒîEi
) ‚àíc(ŒîEi)
)]
,
where ùúÉ(z) is a step function (equal to 1 for
z > 0 and 0 otherwise), ŒîE is the reduc-
tion in network congestion from accepting a forwarding delay, and ùõæij is a parameter
expressing buyer preferences (for a trade between a seller i and a buyer j), 0 < ùõæij < 1.
A buyer with ùõæij = 0 will prefer the lowest price seller from among those whose con-
gestion costs exceed a floor c (ŒîEi
). In other words, buyer j prefers matches with
high consumption of P2P network capacity. Without the loss of generality, the floor
can be set to 0. A buyer with ùõæij = 1 will select the seller with the highest congestion
contribution, so long as the seller i ceases initiating any new communications within
the P2P network (which it no longer could, having sold all its incentives to buyer j).
The model makes several assumptions. Notably, it explicitly considers the possi-
bility that a seller may sell all his/her credits. This may not actually happen in the
above formulation; the sale may be partial, in which case, buyer j is simply overesti-
mating the value of its matching with seller i. As a result, this may lead to a suboptimal
solution or unfeasibility. A compensating parameter ùõºij =
dj
si that encourages trans-
actions that relieve network congestion is introduced to favor sellers with smaller
supplies of pollution credits to sell.
Utility is highest when either (i) P2P network usage pricing maximizes the price
differential between buyer and seller, that is, a lower selling price increases utility, or
(ii) the incentive depletion rate is high, making network usage more expensive, then
demand for incentives will rise and sellers will ask higher prices for theirs. These
two cases suggest the existence of price equilibria between sellers and buyers. Setting
arbitrarily high seller prices and low buyer prices will not promote trading. The utility
function, therefore, encapsulates the market incentives for network users to either
participate solely by assisting peers or use the network at shorter more expensive
intervals by purchasing incentives at increasing prices.

338
SMART PRICING AND MARKET FORMATION IN HYBRID CELLULAR
12.8.2
Indivisible Incentives
When most transactions involve fully depleting a user‚Äôs incentives, the assumption
of indivisibility is a reasonable approximation. For example, many users in the P2P
network might elect to participate only in order to earn the participation incentives. In
that case, they might sell their credits immediately upon joining (or leaving) the P2P
network. Alternatively, there might be a small number of very heavy network users
who wish to buy large quantities of incentives from their peers. The case of indivis-
ible incentives uses a slightly different utility function than the one given earlier for
divisible incentives:
gij (p, ùõº, c (ŒîE)) = ùõºij
[
ùõæij
(
c (ŒîEi
) ‚àíc (ŒîEi
))
ùúÉ((dj + 1) ‚àísi
)
+ (ùõæij
) (
pj ‚àípi
) ùúÉ(
pj ‚àípi
)] ùúÉ
(
c(ŒîEi) ‚àíc (ŒîEi
))
,
where gij(p, ùõº, c(ŒîE)) differs only in step function
ùúÉ((dj + 1) ‚àísi). Here the utility
is higher if the transaction results in a seller surrendering all its incentives and thus
ceasing to contribute to network congestion.
In both the divisible and indivisible models, the objective of transactions is to
maximize the system utility. As the utility expresses the best matching for the whole
system in terms of achieving network congestion relief, it must adjust prices in order
to achieve system goals. That is, transactions must optimize congestion relief for all
the partitions ùîì(S) of set S of sellers. For each partition ùîì(S), the best match between
the elements of partition ùîì(S) (which are disjoint subsets of S covering S) and the
buyers must be found so the total utility is optimal.
The aggregate utility of a set of matches can be computed in several ways and
will determine whether the individual buyers and sellers are optimally matched. The
complexity of the problem is NP-hard in both the divisible and indivisible formula-
tions [19]. Note that not all partitions need to be considered. A partition is said to be
feasible if at least one element can be matched to one buyer. Further, let Ei be the
congestion contributed by seller i. Assume seller i has been matched to a buyer j. In
other words, there exists a unique element of ùîì(S), that has been matched to buyer j
and contains seller i. We say that a partition ùîì(S) is relevant if the set of transactions
does not result in exceeding the system-wide congestion cap determined to provide
adequate QoS.
12.9
CONCLUSION
Currently, both cellular and WiFi networks are ubiquitous in urban areas. The WiFi
networks may be underutilized during peak cellular network usage, because of diffi-
culties in joining or remaining in a WiFi network. This is especially true for highly
mobile network users for which direct communication with infrastructure is infeasi-
ble. The problem is creating a framework for enabling the cellular network to shift
some of its network load to a set of WiFi networks, thereby relieving congestion in
the cellular network while offering adequate QoS to the nodes removed from it.

REFERENCES
339
In this chapter, we have presented our model for a hybrid cellular‚ÄìP2P network,
which was inspired by our earlier work in modeling congestion management and
vehicular pollution in the transportation domain. The similarities between transporta-
tion and wireless networking are clear: in both, individual users of a shared resource
(whether a set of roads or the wireless communication medium) impose negative
externalities on other users. The basis of our solution is a Pigouvian tax model, in
which users are charged according to their negative externalities in order to arrive at
a socially optimal consumption of the shared resource.
During times when the cellular network is congested, a set of P2P networks will
be created to increase the entire system‚Äôs capacity. Although the cellular network will
select nodes to join the P2P network, they will have the option to decline (and remain
in the congested cellular network). However, remaining nodes that agree to partici-
pate in the P2P network will be incentivized for their assistance in forwarding other
nodes‚Äô network traffic. These incentives will be paid out from subscription fees, thus
allowing P2P network participants to partially recoup their costs of cellular network
usage in return for expanding its capacity.
REFERENCES
1. PricewaterhouseCoopers LLC, Real time: The growing demand for data‚Äî2012 North
American wireless industry survey, 2013.
2. Federal Communications Commission, Mobile broadband: the benefits of additional spec-
trum, October 2010.
3. S. Sen, C. Joe-Wong, S. Ha, and M. Chiang, ‚ÄúA survey of smart data pricing: Past propos-
als, current plans, and future trends,‚Äù ACM Computing Surveys, 46(2), 2014.
4. S. Ha, S. Sen, C. Joe-Wong, Y. Im, and M. Chiang, ‚ÄúTUBE: time-dependent pricing for
mobile data,‚Äù Proceedings of SIGCOMM‚Äô12, Helsinki, Finland, pp. 247‚Äì258, Aug. 2012.
5. P. Loiseau, G. Schwartz, J. Musacchio, S. Amin, and S. Sastry, ‚ÄúIncentive Mechanisms
for Internet Congestion Management: Fixed-Budget Rebate Versus Time-of-Day Pricing,‚Äù
IEEE/ACM Transactions on Networks, 22(2), 2013, 647‚Äì661.
6. I. Akyildiz and X. Wang, ‚ÄúA survey on wireless mesh networks,‚Äù IEEE Radio Communi-
cations, 2005, s23‚Äìs30.
7. Z. Wan, ‚ÄúCommercial issues in hybrid cellular ad-hoc networks,‚Äù IEEE 2011 Conference
on Management of E-commerce and E-governance, Shanghai, China, 2011.
8. J. Dyaberi, B. Parsons, K. Kannan, V. Pai, Y. Chen, R. Jana, D. Stern, A. Varshavsky, and B.
Wei, ‚ÄúManaging cellular congestion using incentives,‚Äù IEEE Communications Magazine,
50(11), 2012, 100‚Äì107.
9. Y. Nie, ‚ÄúTransaction costs and tradable mobility credits,‚Äù Transportation Research Part B:
Methodological, 46(1), 2012, 189‚Äì203.
10. A. Ouksel and D. Lundquist, ‚ÄúDemand-driven publish/subscribe in mobile environments,‚Äù
Wireless Networks,16(8), 2010, 2237‚Äì2261.
11. D. Lundquist, A Context-Aware Paradigm for Information Discovery and Dissemination
in Mobile Environments, Advisor: Aris Ouksel, University of Illinois at Chicago, Chicago,
IL, 2011.

340
SMART PRICING AND MARKET FORMATION IN HYBRID CELLULAR
12. A. Ouksel and D. Lundquist, ‚ÄúA context-aware cross-layer broadcast model for ad hoc
networks,‚Äù Personal and Ubiquitous Computing, 18(4), 2014, 851‚Äì864.
13. C. Silverstein, H. Marais, M. Henzinger, and M. Moricz, ‚ÄúAnalysis of a very large web
search engine query log,‚Äù ACM Special Interest Group on Information Retrieval, 33(1),
1999, 6‚Äì12.
14. A. Ouksel and D. Lundquist, ‚ÄúDF100: CACL: A context-aware cross-layer broadcast
scheduling scheme,‚Äù Provisional UIC patent, 2012.
15. A. M. Ouksel and T. Lee, Public Policy Implications of Cap and Trade of Pollution Cred-
its and Switching of Travel Modes Incentives, University of Illinois: CISORS Technical
Report #5, 2011.
16. A. Ouksel, Pollution Measurements and Pollution Maps, University of Illinois: CISORS
Technical Report #12, 2011.
17. H. Yang and X. Wang, ‚ÄúManaging network mobility with tradable credits,‚Äù Transportation
Research Part B: Methodological, 45(3), 2011, 580‚Äì594.
18. A. Lahiri, R. Dewan, and M. Freimer, ‚ÄúPricing of Wireless Services: Service Pricing vs.
Traffic Pricing,‚Äù Information Systems Research, 24(2), 2013, 418‚Äì435.
19. C. Papadimitriou and K. Steiglitz, Combinatorial Optimization: Algorithms and Complex-
ity, Prentice Hall, Inc., New Jersey, 1982.

13
To Tax or To Subsidize:
The Economics of
User-Generated Content
Platforms
SHAOLEI REN and MIHAELA VAN DER SCHAAR
13.1
INTRODUCTION
Enabled by ubiquitous broadband connectivity and seamlessly accessible wireless
connections, user-generated content platforms have witnessed in the past few years
an explosive growth, allowing everyone to conveniently publish information online
and share their knowledge, opinions, experiences, and so on with the rest of the world.
Every day, millions of people ‚Äútweet‚Äù on Twitter, update their status on Facebook,
ask and answer questions on Yahoo! Answers, and share their videos on YouTube.
As user-generated content platforms are becoming an integral part of our lives, both
Internet users and platform owners are eager to see the continuing growth of such
platforms, which are nonetheless largely hindered by a number of obstacles, notably
low quality content and lack of revenue sources. Typically, users can view the con-
tent for free while they post content on user-generated content platforms voluntarily.
Thus, users often have little incentive to devote their efforts into improving content
quality, resulting in low quality content published on the platforms. To tackle this,
various mechanisms have been proposed to promote high quality content produced
by users. For example, a common approach is to eliminate or hide low quality con-
tent as adopted by popular web sites such as Yahoo! Answers [1]. While incentivizing
high quality content contributions on user-generated content platforms still remains
an active research area (see References 1 and 2 and references therein), turning the
user-generated content into profit has become increasingly important for platform
owners, as advertising accounts for a major (and possibly the only) revenue source
while the operational cost (e.g., bandwidth, energy, and marketing) for managing
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
341

342
THE ECONOMICS OF USER-GENERATED CONTENT PLATFORMS
user-generated content platforms is skyrocketing. Even though sophisticated algo-
rithms may be employed to increase the advertising revenue (e.g., displaying more
relevant advertisement or use auction mechanisms for selling advertisement space),
the continuously increasing operational cost still catapults the exploration of alterna-
tive revenues as one of the key challenges for user-generated content platform owners,
thereby motivating our study of the economics of user-generated content platforms
from the perspective of profit maximization.
On a user-generated content platform as illustrated in Figure 13.1, the platform
owner is referred to as an intermediary, while the users can be classified as content
producers and content viewers, although a user can be both a producer and a viewer.
While content producers post content on the platform voluntarily without any obli-
gation, content producers still receive benefits by publishing their content: millions
of users engaging daily in Internet activities such as blogs, for which they receive
no monetary rewards, suggest that content producers may simply derive satisfaction
from attracting content viewers‚Äô attention (see, e.g., References 1, 3, and 4). In addi-
tion to social satisfaction, the intermediary may also provide economic incentives by
subsidizing (i.e., paying) content producers for their contribution. The logic behind
‚Äúsubsidizing‚Äù is that the intermediary gives away some of its advertising revenue to
content producers in the hope that the total advertising revenue may increase because
of the increased amount of content available on the platform. Opposite to subsidiz-
ing, the intermediary may tax (i.e., charge) content producers for using the platform‚Äôs
service (e.g., storage space and bandwidth): if content producers have intrinsic social
incentives to produce content, taxing content producers will give the intermediary an
additional revenue source while still attracting some content producers, although the
intermediary may suffer from reduced advertising revenue because of decreased user
traffic resulting from less content production. In general, subsidizing content pro-
ducers can be considered as a reward for providing content, whereas taxing content
producers can be considered as a usage fee for utilizing the intermediary‚Äôs resources.
While, in practice, ‚Äúsubsidizing content producers‚Äù can be observed more often (e.g.,
YouTube Partner and Squidoo) than ‚Äútaxing content producers‚Äù (e.g., Google Picasa,
which taxes its users for storage exceeding the free quota), there is no simple answer
Content
producers
Content
viewers
Intermediary
Content
Content
Figure 13.1
Illustration of user-generated content platform.

MODEL
343
to the question of which strategy maximizes the intermediary‚Äôs profit, which is crucial
for the long-term growth of user-generated content platforms.
Concluding whether subsidizing or taxing content producers maximizes the inter-
mediary‚Äôs profit requires an appropriate model as the foundation. Naturally, with both
content producers and content viewers as participants, user-generated content plat-
form can be modeled as a two-sided market, where two user groups (i.e., content
producers and content viewers) interact and provide each other with network bene-
fits [5]. Besides user-generated content platforms, two-sided market can also model
a variety of other markets such as a broadband communications market with content
producers and end users [6] and payment card industry with merchants and customers
[7]. Unlike other two-sided markets, however, user-generated content platforms have
the following characteristics that have not been adequately addressed by the exist-
ing research. First, content producers compete for the content viewers‚Äô attention,
that is, intragroup negative externalities, which have been neglected by most exist-
ing research on two-sided markets (see References 5 and 8 for a survey). Second,
content viewers tend to have love for variety, that is, intergroup positive externali-
ties, which have been incorporated by the existing literature [9] but not well suited to
user-generated content platforms. Last but not least, user-generated content exhibits a
diverse content quality and substitutability, that is, different content often has different
qualities but may substitute each other to a certain extent from the content viewers‚Äô
perspective. In what follows, in order to provide a formal analysis on when subsidiz-
ing or taxing content producers is profit maximizing for the intermediary, we provide
a new model for user-generated content platform, which captures all the above three
characteristics. As subsidizing content producers per content view is a common prac-
tice in the Internet industry (e.g., YouTube Partner) while not taxing users for viewing
content is also a common practice (e.g., YouTube and Yahoo! Answers). we focus on
a class of payment schemes in which the intermediary subsidizes or taxes content
producers on a basis of per content view, while it provides the service for free to con-
tent viewers. Our analysis provides a formal guidance for the intermediary to decide
its optimal payment to the content producers for profit maximization. In particular,
we recommend that the intermediary should subsidize the content producers under
the following circumstances: (i) there are few content viewers; (ii) content production
cost is high; (iii) content producers do not receive strong social satisfaction; or (iv)
there are more popular user-generated content platforms where the content viewers
can go and view content.
The rest of this chapter is organized as follows. The model is described in
Section 13.2. In Section 13.3, we analyze the problems of content viewers, content
producers, and the intermediary. In Section 13.4, we outline how our analysis can be
extended to the case of heterogeneous production costs. Finally, concluding remarks
are offered in Section 13.5.
13.2
MODEL
We consider an online user-generated content platform owned by a profit-maximizing
intermediary. Content on the platform is produced and viewed by individual users.

344
THE ECONOMICS OF USER-GENERATED CONTENT PLATFORMS
Our model is a three-stage game that is played by the intermediary, content producers,
and content viewers in the following order.
‚Ä¢ Stage 1. The intermediary sets a payment rate per content view, paid to content
producers.
‚Ä¢ Stage 2. Given the payment rate chosen by the intermediary, each content pro-
ducer chooses whether or not to produce content on the platform.
‚Ä¢ Stage 3. Given available content, content viewers, consolidated as a representa-
tive content viewer, allocate their total content views over available content.
While a single user can be a content producer and a content viewer at the same time,
it is assumed in our analysis that the decision making of a user as a content producer
is separable from that as a content viewer. In the following text, we describe the
problems of the intermediary, content producers, and content viewers in detail.
13.2.1
Intermediary
It is well known that advertising is one of the most prevailing revenue sources in the
Internet industry, especially for online content platforms such as YouTube and Yahoo!
Answers. Hence, we consider a scenario in which the intermediary monetizes its con-
tent platform by displaying contextual advertisement to content viewers. Although a
platform may use different bases (e.g., pay per click, pay per sale, and pay per impres-
sion) to charging advertisers, the advertising revenue is in general increases with the
number of times that content with advertisement is viewed (or content views). For
simplicity, we assume that the intermediary‚Äôs advertising revenue is proportional to
the total number of content views in the platform, as in Reference 10.
The intermediary chooses the amount of money, denoted by ùúÉ, which it subsidizes
a content producer for each time the content producer‚Äôs content is viewed. We refer to
ùúÉas the payment rate (to content producers per content view). We allow ùúÉto be any
real number. The intermediary subsidizes content producers if ùúÉ> 0, while it taxes
them if ùúÉ< 0. Let b be the intermediary‚Äôs profit per content view without account-
ing for payment to content producers and b can be interpreted as advertising revenue
minus operation cost per content view. Note that b can be negative if the operation
cost is larger than the advertising revenue. We assume that b is an exogenously given
as a constant independent of the total number of content views, while the intermediary
may increase its advertising revenue per content view by developing algorithms for
displaying relevant advertisement or auction mechanisms for selling advertisement
space (which is outside of the scope of this chapter). Let x(ùúÉ) be the total number
of content views, which is determined by the decisions of users, that the intermedi-
ary obtains when it chooses ùúÉ. Neglecting fixed operation cost, we can express the
intermediary‚Äôs profit as
Œ†(ùúÉ) = (b ‚àíùúÉ)x(ùúÉ).
(13.1)
The intermediary‚Äôs problem is to maximize its profit by choosing a payment rate.

MODEL
345
13.2.2
Content Producers
As evidenced by the exploding number of YouTube users, a popular user-generated
content platform can attract a huge number of content producers. To capture this fact,
we consider a continuum of content producers of mass one as in prior work [11‚Äì13].
We index content producers by i (and sometimes j without ambiguity), where i is
uniformly distributed over the interval [0, 1]. Content producer i can produce content
of quality qi ‚â•0 while incurring production cost c > 0. The quality of content is
represented by a nonnegative scalar, and we treat it as an internal feature of content
(e.g., how fun or informative content is). Also, the production cost is the same for
all content producers, and this assumption will be relaxed in Section 13.4. Content
producers produce differentiated content, or in other words, no two content producers
can produce identical content. We sometimes refer to content produced by content
producer i as content i.
Given the payment rate chosen by the intermediary, content producers make deci-
sions regarding whether to produce content or not. Once a content producer produces
content, it posts the content on the intermediary‚Äôs platform. In other words, the inter-
mediary‚Äôs platform is the only platform on which the content producers can provide
their content. We assume that a user cannot provide content produced by others, for
example, because of copyright restrictions. That is, content i can be posted on the
platform only by content producer i. We represent the decision of content producer i
by a binary variable yi, which takes value 0 if content producer i chooses not to pro-
duce and 1 otherwise. The decisions of all the content producers are summarized in
y = (yi)i‚àà[0,1] ‚àà{0, 1}[0,1]. Note that y determines content available on the platform.
There are two major types of benefits that a content producer obtains by posting
its content on the platform. One is payment from the intermediary, which can also
be interpreted as a cost when the payment rate is negative, while the other is social
satisfaction. Millions of users engaging daily in Internet activities such as blogs, for
which they receive no monetary rewards, suggest that content producers may simply
derive satisfaction from attracting content viewers‚Äô attention (see, e.g., References
1, 3, and 4). We use content views to quantify the amount of received attention and
assume that a content producer‚Äôs satisfaction is proportional to the number of content
views of its content. Let s > 0 be the social benefit, measured in a monetary unit, per
content view that a content producer derives from content viewers‚Äô attention. Let xi(y)
be the number of content views that content i attracts, given available content on the
platform determined by y. Note that (xi(y))i‚àà[0,1] is determined by content viewers.
The payoff function of content producer i is given by
ùúãi(ùúÉ, y) =
{
(ùúÉ+ s)xi(y) ‚àíc
if yi = 1,
0
if yi = 0.
(13.2)
Content producers make production decisions simultaneously to maximize their own
payoffs given the payment rate chosen by the intermediary.
Remark: In our model, each content producer can produce only one piece of con-
tent. However, if there is a content producer who can produce up to m ‚â•1 pieces of
content, it can be treated as m separate content producers in our model as long as the

346
THE ECONOMICS OF USER-GENERATED CONTENT PLATFORMS
cost of producing any ÃÉm ‚â§m pieces is ÃÉmc (i.e., constant returns to scale, as assumed
in Reference 9).
13.2.3
Content Viewers
We can expect that content viewers have diverse preferences toward content. In
order to study their aggregate content viewing behavior conveniently, we adopt
the widely used representative agent model [14]. That is, we analyze the optimal
decision of a representative content viewer to determine the content views that each
piece of available content receives. The representative content viewer has a fixed
number of content views to be allocated to available content, which is denoted by
T > 0. Note that T can be interpreted as the size of the representative content viewer
or the market size on the viewer side. Besides the intermediary‚Äôs platform, there
are other platforms that offer (differentiated) content. For convenience, we assume
that ‚Äúoutside‚Äù content has a fixed aggregate quality qa > 0. In Section 13.3.2, we
illustrate how the aggregate quality can be derived from a distribution of individual
qualities. The assumption that qa is independent of y can be justified by noting that
there are many content platforms on the Internet and thus changes on a single content
platform have negligible impacts on the other platforms.
Let xi be the number of content views of content i for i ‚àà[0, 1] and xa be the total
number of content views of outside content (i.e., content on the other platforms).
We use x = ((xi)i‚àà[0,1], xa) ‚àà‚Ñù[0,1]
+
√ó ‚Ñù+ to denote a content view allocation of the
representative content viewer. Let U(x) be the utility of the representative content
viewer when its content view allocation is x. Then the representative content viewer‚Äôs
problem, given the decisions of the content producers, y, can be written as
max
x
U(x)
(13.3)
s.t., ‚à´
1
0
xidi + xa = T,
(13.4)
xi ‚â•0 for all i ‚àà[0, 1], xa ‚â•0,
(13.5)
xi = 0 for all i such that yi = 0.
(13.6)
The constraint in Eq. (13.4) requires that the total number of content views be equal
to T. The constraints in Eq. (13.5) are nonnegativity constraints for numbers of con-
tent views. The constraints in Eq. (13.6) impose that the content viewer cannot allo-
cate a positive number of content views to unavailable content.
13.3
PROFIT MAXIMIZATION ON USER-GENERATED CONTENT
PLATFORMS
13.3.1
Definition of Equilibrium
In this chapter, we analyze the optimal decision making of the intermediary, the
content producers, and the representative content viewer. In Section 13.2, we have

PROFIT MAXIMIZATION ON USER-GENERATED CONTENT PLATFORMS
347
modeled the interaction among them as a three-stage game (with perfect information).
Hence, we adopt the solution concept of subgame perfect equilibrium. The strategy
of the intermediary is the payment rate ùúÉ, that of content producer i is the production
decision yi(ùúÉ) as a function of ùúÉ, and that of the content viewer is the content view
allocation x(ùúÉ, y) as a function of (ùúÉ, y). As the payment rate ùúÉdoes not affect the rep-
resent content viewer‚Äôs problem Eqs. (13.3)‚Äì(13.6) directly, we restrict attention to
the strategies of the content viewer that depend only on y, writing its strategy as x(y).
In the following, we define the equilibrium of the game played by the intermediary,
the content producers, and the representative content viewer.
Definition 13.1
(ùúÉ‚àó, y‚àó(ùúÉ), x‚àó(y)) is an equilibrium if
(i) x‚àó(y) is an optimal solution to the content viewer‚Äôs problem (13.3)‚Äì(13.6),
given y,
(ii) for each content producer i ‚àà[0, 1], y‚àó
i (ùúÉ) is an optimal production decision,
given ùúÉ, x‚àó
i (y), and (y‚àó
j (ùúÉ))j‚â†i, that is,
(ùúÉ+ s)x‚àó
i (y‚àó(ùúÉ)) ‚àíc ‚â•0
if y‚àó
i (ùúÉ) = 1
(13.7)
and
(ùúÉ+ s)x‚àó
i (1, y‚àó
‚àíi(ùúÉ)) ‚àíc ‚â§0
if y‚àó
i (ùúÉ) = 0,
(13.8)
where (1, y‚àó
‚àíi(ùúÉ)) is the production decision profile equal to y‚àó(ùúÉ) except that yi = 1,
and
(iii) ùúÉ‚àóis an optimal payment rate for the intermediary given y‚àó(ùúÉ) and x‚àó(y), that is,
(b ‚àíùúÉ‚àó)x(ùúÉ‚àó) ‚â•(b ‚àíùúÉ)x(ùúÉ)
for all ùúÉ‚àà‚Ñù,
(13.9)
where x(ùúÉ) = ‚à´1
0 x‚àó
i (y‚àó(ùúÉ))di.
In the remainder of this chapter, we characterize the equilibrium by analyzing each
agent‚Äôs problem in detail.
13.3.2
Optimal Content Viewing
For analytical tractability, we impose the following assumptions on the utility func-
tion U of the representative content viewer.
Assumption 13.1
U(x) = U(x‚Ä≤) for all x and x‚Ä≤ such that xi = x‚Ä≤
i for almost all
i ‚àà[0, 1] (with respect to the Lebesgue measure) and xa = x‚Ä≤
a.
Assumption 13.2
U is continuous on its domain and twice continuously differen-
tiable on the interior of its domain. It is additively separable in its arguments (i.e.,
all of its cross partial derivatives are zero).

348
THE ECONOMICS OF USER-GENERATED CONTENT PLATFORMS
Assumption 13.3
(i) For all i ‚àà[0, 1] such that qi = 0, ùúïU‚àïùúïxi = 0 for all xi > 0.
(ii) For all i ‚àà[0, 1] such that qi > 0, ùúïU‚àïùúïxi > 0 and ùúï2U‚àïùúïx2
i < 0 for all xi > 0,
while ùúïU‚àïùúïxi ‚Üí+‚àûas xi ‚Üí0 and ùúïU‚àïùúïxi ‚Üí0 as xi ‚Üí+‚àû.
(iii) ùúïU‚àïùúïxa > 0 and ùúï2U‚àïùúïx2
a < 0 for all xa > 0, while ùúïU‚àïùúïxa ‚Üí+‚àûas xa ‚Üí0
and ùúïU‚àïùúïxa ‚Üí0 as xa ‚Üí+‚àû.
Assumption 13.4
ùúïU‚àïùúïxi is continuous and increasing in qi for all i ‚àà[0, 1] and
ùúïU‚àïùúïxa is continuous and increasing in qa.
We briefly discuss the above assumptions. Assumption 13.1 means that the content
views of a single piece of content have an infinitesimal effect on the utility. Additive
separability in Assumption 13.2 excludes complementarity between two pieces of
content. Assumption 13.3(i) says that the marginal utility from content of quality 0 is
0. Assumption 13.3(ii) and (iii) have that the utility from content of a positive quality
is increasing in its content views at a diminishing rate. Assumption 13.4 states that
the higher quality of content leads to the larger marginal utility from content.
Assumptions 13.2 and 13.3 guarantee that for each y ‚àà{0, 1}[0,1], there exists an
optimal content view allocation x‚àó(y) satisfying the following optimality conditions:
x‚àó
i (y) > 0 for all i such that qi > 0 and yi = 1, x‚àó
a(y) > 0,
(13.10)
x‚àó
i (y) = 0 for all i such that qi = 0 or yi = 0,
(13.11)
‚à´
1
0
x‚àó
i (y)di + x‚àó
a(y) = T,
(13.12)
ùúïU
ùúïxi
(x‚àó(y)) = ùúïU
ùúïxa
(x‚àó(y)) for all i such that qi > 0 and yi = 1.
(13.13)
By Assumption 13.4, we have x‚àó
i (y) > x‚àó
j (y) for all i and j such that qi > qj and yi =
yj = 1, that is, content of a higher quality attracts more content views. Consider a
content view allocation x‚Ä≤(y) satisfying x‚Ä≤
i(y) = x‚àó
i (y) for almost all i ‚àà[0, 1] such
that yi = 1, x‚Ä≤
i(y) = 0 for all i such that yi = 0 and x‚Ä≤
a(y) = x‚àó
a(y). Then x‚Ä≤(y) satisfies
all the constraints of the content viewer‚Äôs problem while achieving the same utility as
x‚àó
a(y) by Assumption 13.1. Thus, x‚Ä≤(y) is also an optimal content view allocation. In
this chapter, we focus on optimal solutions of the kind x‚àó(y) in which the optimality
conditions are satisfied for all i ‚àà[0, 1] such that yi = 1. Note that such an optimal
solution x‚àó(y) is unique for each y under our assumptions.
A particular form of a utility function satisfying Assumptions 13.1‚Äì13.4, which
we shall use extensively as an illustration, is the quality-adjusted version of the
well-known Dixit‚ÄìStiglitz utility function [15], defined as
U(x) =
[
‚à´
1
0
qix
ùúé‚àí1
ùúé
i
di + qax
ùúé‚àí1
ùúé
a
] ùúé
ùúé‚àí1
,
(13.14)
where ùúé> 1 measures the elasticity of substitution between different pieces of con-
tent. In the extreme case where ùúé‚Üí+‚àû, content becomes perfectly substitutable

PROFIT MAXIMIZATION ON USER-GENERATED CONTENT PLATFORMS
349
[15], whereas when ùúé‚Üí1, content becomes unsubstitutable. Dixit‚ÄìStiglitz utility
function provides an effective and tractable means of capturing constant elasticity
of substitution in a market. More precisely, it provides a rigorous characterization
of product diversity through the parameter ùúé> 1 and combines multiple types of
product consumption into an aggregate utility, which is particularly suitable for
user-generated content platforms where content producers produce diversified
content. Next, by using the optimality conditions (13.10)‚Äì(13.13), we obtain the
optimal solution
x‚àó
i (y) =
Tqùúé
i
qùúé
a + ‚à´1
0 yjqùúé
j dj
yi
for all i ‚àà[0, 1], and
(13.15)
x‚àó
a(y) =
Tqùúé
a
qùúé
a + ‚à´1
0 yjqùúé
j dj
=
T
1 +
‚à´1
0 yjqùúé
j dj
qùúéa
,
(13.16)
assuming that the integral ‚à´1
0 yjqùúé
j dj exists. Note that [‚à´1
0 yjqùúé
j dj]1‚àïùúécan be interpreted
as the aggregate quality of content on the intermediary‚Äôs platform, which reflects
not only the overall quality but also the quantity of available content.1 Also, [qùúé
a +
‚à´1
0 yjqùúé
j dj]1‚àïùúécan be interpreted as the aggregate quality of all available content. The
total content views in the intermediary‚Äôs platform at the optimal solution are given by
x(y) =
T ‚à´1
0 yjqùúé
j dj
qùúé
a + ‚à´1
0 yjqùúé
j dj
=
T
1 +
qùúéa
‚à´1
0 yjqùúé
j dj
,
(13.17)
and the indirect utility of the content viewer is
U‚àó(y) = U(x‚àó(y)) = T
(
qùúé
a + ‚à´
1
0
yjqùúé
j dj
) 1
ùúé‚àí1
.
(13.18)
We can see that the optimal number of the content views of content i, if produced, is
increasing in its quality, qi, and the size of the content viewer, T, while it is decreasing
in the aggregate quality of all available content. Let us treat the platforms other than
the intermediary‚Äôs platform as a single platform. Then the optimal total number of
the content views in a platform (i.e., x‚àó
a(y) and x(y)) is increasing in the size of the
1Similarly, the aggregate quality of content on other platforms, qa, can be derived from a distribution of
individual qualities. We index content producers providing content on the other platforms by k, and suppose
that the content producers on other platforms are uniformly distributed over [0, 1] with total mass na. Then
the Dixit‚ÄìStiglitz utility function U can be modified as U(x) =
[
‚à´1
0 qix
ùúé‚àí1
ùúé
i
di + na ‚à´1
0 qkx
ùúé‚àí1
ùúé
k
dk
]
ùúé
ùúé‚àí1
. If we
set qa = (na ‚à´1
0 qùúé
k dk)1‚àïùúé, assuming that the integral exists, we obtain the same optimal number of content
views in the intermediary‚Äôs platform in both approaches, while xa represents the total number of content
views in the other platforms, that is, xa = ‚à´1
0 xkdk.

350
THE ECONOMICS OF USER-GENERATED CONTENT PLATFORMS
content viewer and the aggregate quality of content available on the platform, while
it is decreasing in the aggregate quality of content available on the other platform.
Finally, the per-capita indirect utility, U‚àó(y)‚àïT, is increasing in the aggregate quality
of all available content.
13.3.3
Equilibrium Content Production
At equilibrium, no content producer can gain by unilaterally changing its production
decision. In other words, equilibrium content production decisions y‚àó(ùúÉ) can be con-
sidered as a Nash equilibrium of the game played by the content producers, given the
payment rate ùúÉand anticipating the optimal content view allocation x‚àó(y) of the con-
tent viewer. In the following lemma whose proof is omitted for brevity, we provide
some basic properties of equilibrium content production decisions.
Lemma 13.1
Let y‚àó(ùúÉ) be an equilibrium strategy profile of the content producers.
(i) If ùúÉ‚â§‚àís, then y‚àó
i (ùúÉ) = 0 for all i ‚àà[0, 1].
(ii) If ùúÉ> ‚àís, y‚àó
i (ùúÉ) = 1 and qj > qi, then y‚àó
j (ùúÉ) = 1.
Lemma 13.1(i) shows that if the intermediary chooses ùúÉ‚â§‚àís, no content producer
will produce content and thus the intermediary will obtain no content views, that is,
x(ùúÉ) = 0. Hence, Œ†(ùúÉ) = 0 for any ùúÉ‚â§‚àís. Now consider the case where ùúÉ> ‚àís.
Let us define ÃÉIq = {i ‚àà[0, 1] ‚à∂qi ‚â§q} for all q ‚àà‚Ñù. Assuming that ÃÉIq is (Lebesgue)
measurable for every q, we define F(q) to be the measure of ÃÉIq. Then F(‚ãÖ) can be con-
sidered as the cumulative distribution function of the qualities of content that can be
produced by the content producers. We assume that F(‚ãÖ) has a continuous probabil-
ity distribution function f(‚ãÖ) with support [0, 1].2 Lemma 13.1(ii) implies that for any
equilibrium strategy profile y‚àó(ùúÉ) of the content producers, there exists a threshold, or
sometimes called the marginal content quality, q‚àó
m(ùúÉ) ‚àà[0, 1], such that y‚àó
i (ùúÉ) = 1 if
qi > q‚àó
m(ùúÉ) and y‚àó
i (ùúÉ) = 0 if qi < q‚àó
m(ùúÉ). If q‚àó
m(ùúÉ) ‚àà(0, 1), a content producer who can
produce content of quality q‚àó
m(ùúÉ) is indifferent between producing and not producing
given payment rate ùúÉ. For convenience, we restrict attention to threshold strategies of
the content producers in which all indifferent producers choose to produce, although
given Assumption 13.1 and the assumption on F(‚ãÖ), the behavior of indifferent pro-
ducers does not affect the utility of the content viewer as well as the profit of the
intermediary.
At the optimal content view allocation, the content viewer allocates the same num-
ber of content views to two pieces of available content of equal quality. That is, if
qi = qj and yi = yj = 1, then x‚àó
i (y) = x‚àó
j (y). For each q ‚àà[0, 1] and qm ‚àà[0, 1], we
define z‚àó(q|qm) = x‚àó
i (y) where q = qi, yi = 1, and yj = 1 if and only if qj ‚â•qm for all
j ‚â†i. In other words, z‚àó(q|qm) is the number of content views that a content producer
receives if it produces content of quality q while all the other content producers use
threshold qm. We can obtain the following properties of z‚àó(q|qm).
2More generally, we can have a finite support [q, q] where 0 ‚â§q < q < +‚àû. We can think of using 1
instead of q as a normalization, while we use 0 instead of sufficiently small q to simplify our analysis.

PROFIT MAXIMIZATION ON USER-GENERATED CONTENT PLATFORMS
351
Lemma 13.2
For all qm ‚àà[0, 1], z‚àó(0|qm) = 0 and z‚àó(q|qm) > 0 for all q > 0.
z‚àó(q|qm) is continuous and increasing in each of q and qm.
With the Dixit‚ÄìStiglitz utility function in Eq. (13.14), we have
z‚àó(q|qm) =
T(ùúé+ 1)qùúé
(ùúé+ 1)qùúé
a + (1 ‚àíqùúé+1
m
)
,
(13.19)
which obviously satisfies the properties in Lemma 13.2.
By Lemma 13.2, we have (ùúÉ+ s)z‚àó(0|qm) ‚àíc < 0 for all qm ‚àà[0, 1]. If
(ùúÉ+ s)z‚àó(1|qm) ‚àíc ‚â•0, then there exists a unique minimum element of the set
{q ‚àà[0, 1] ‚à∂(ùúÉ+ s)z‚àó(q|qm) ‚àíc ‚â•0} because z‚àó(q|qm) is continuous and increasing
in q. We define a mapping QùúÉ‚à∂[0, 1] ‚Üí[0, 1] by
QùúÉ(qm) =
‚éß
‚é™
‚é®
‚é™‚é©
arg min{q ‚àà[0, 1]‚à∂
if (ùúÉ+ s)z‚àó(1|qm) ‚àíc ‚â•0,
(ùúÉ+ s)z‚àó(q|qm) ‚àíc ‚â•0}
1
otherwise.
(13.20)
QùúÉ(qm) is the threshold of the optimal production decisions, given payment rate ùúÉ
when the content producers expect that only producers who can produce content of
quality higher than qm choose to produce. Thus, if q‚àó
m is a fixed point of the mapping
QùúÉ, that is, q‚àó
m = QùúÉ(q‚àó
m), then no content producer can gain from unilateral deviation
when the content producers use threshold q‚àó
m.
Definition 13.2
q‚àó
m is an equilibrium marginal content quality (or equilibrium pro-
duction threshold), given payment rate ùúÉ, if it satisfies q‚àó
m = QùúÉ(q‚àó
m).
By Lemma 13.2, z‚àó(1|1) is the maximum number of content views that a content
producer can attract in the platform. Hence, for ùúÉ> ‚àís, if (ùúÉ+ s)z‚àó(1|1) ‚àíc ‚â§0,
a content producer can never obtain a positive payoff from producing content. The
condition (ùúÉ+ s)z‚àó(1|1) ‚àíc ‚â§0 can be rewritten as ùúÉ‚â§ùúÉ, where
ùúÉ=
c
z‚àó(1|1) ‚àís.
(13.21)
We establish the existence and uniqueness of an equilibrium marginal content quality
in Proposition 13.1, whose proof can be found in Reference 16 and references therein.
Proposition 13.1
For any ùúÉ> ‚àís, there exists a unique equilibrium marginal con-
tent quality given payment rate ùúÉ, q‚àó
m(ùúÉ). q‚àó
m(ùúÉ) = 1 for ùúÉ‚â§ùúÉand q‚àó
m(ùúÉ) ‚àà(0, 1) for
ùúÉ> ùúÉ. Moreover, q‚àó
m(ùúÉ) is continuous and decreasing in ùúÉon [ùúÉ, +‚àû) and approaches
zero as ùúÉ‚Üí+‚àû.
Proposition 13.1 guarantees the existence of a unique equilibrium threshold and
shows that if the the content producer who can produce content of the highest quality

352
THE ECONOMICS OF USER-GENERATED CONTENT PLATFORMS
can never obtain a positive payoff (because of high production cost, low payment
rate from the intermediary, or low satisfaction from attracting content views), then
(almost) no content producers choose to produce content at equilibrium.
In practice, the content producers may not have complete information regarding
each other (e.g., about the distribution of qualities), and hence, they may not be able
to make decisions that strike the equilibrium at one shot. In such a scenario, the con-
tent producers may use an adjustment process to update their decisions based on the
limited information. A natural and well-studied approach to modeling an adjustment
process is the best-response dynamics, in which each decision maker chooses the best
action in response to the decisions made by others. In this chapter, we consider the
best-response dynamics based on the naive (or static) expectation. Specifically, time
is discrete and labeled as t = 1, 2, ‚Ä¶ Let qm,t be the threshold used by the content
producers in period t = 1, 2, ‚Ä¶ At the end of each period t = 1, 2, ‚Ä¶, the content
producers observe qm,t (or the qualities of all content available on the platform in
period t) and expect that qm,t is used when they make production decisions in period
t + 1. That is, each content producer i expects to attract z‚àó(qi|qm,t) content views if
it chooses to produce in period t + 1. Then content producer i chooses to produce
in period t + 1 if (ùúÉ+ s)z‚àó(qi|qm,t) ‚àíc ‚â•0, and given an initial belief qm,0 ‚àà[0, 1],
the best-response dynamics induces a sequence of thresholds {qm,t}‚àû
t=0 that evolve
following the relationship
qm,t+1 = QùúÉ(qm,t)
(13.22)
for t = 0, 1, ‚Ä¶ Similar decision processes have been adopted in the existing liter-
ature (e.g., [11‚Äì13] and references therein). Essentially, the dynamics defined by
Eq. (13.22) is a fixed-point iteration for QùúÉ(‚ãÖ), and it converges regardless of the
initial point if QùúÉ(‚ãÖ) is a contraction mapping [17]. Following the contraction map-
ping theorem, we can easily specify further a sufficient condition for convergence,
and we omit the details here for brevity. It should be noted that, by considering the
dynamics specified by Eq. (13.22), we implicitly assume that content produced in the
previous periods has little value and will not significantly affect the content views
in the current period (e.g., news content). Moreover, the dynamics specified by Eq.
(13.22) requires that all the content producers update production decisions in every
period. If only a randomly chosen fraction ùúÄ‚àà(0, 1] of the content producers can
update their decisions in each period, the sequence of thresholds is generated by
qm,t+1 = (1 ‚àíùúÄ)qm,t + ùúÄQùúÉ(qm,t). This modification does not affect the equilibrium
analysis although it slows down the convergence.
13.3.4
Optimal Payment Rate
From Proposition 13.1, we can see that x(ùúÉ) > 0 if and only if ùúÉ> ùúÉ. Also, from Eq.
(13.1), we can see that Œ†(ùúÉ) > 0 only if ùúÉ< b. Suppose that b ‚â§ùúÉ. Then Œ†(ùúÉ) = 0 for
ùúÉ‚â§ùúÉand Œ†(ùúÉ) < 0 for ùúÉ> ùúÉ. Hence, the maximum profit of the intermediary is zero,
and any ùúÉ‚â§ùúÉis an optimal payment rate. In the remainder of this chapter, we shall
assume ùúÉ< b. In this case, Œ†(ùúÉ) = 0 for ùúÉ‚â§ùúÉ, Œ†(ùúÉ) > 0 for ùúÉ‚àà(ùúÉ, b), and Œ†(ùúÉ) ‚â§0

PROFIT MAXIMIZATION ON USER-GENERATED CONTENT PLATFORMS
353
for ùúÉ‚â•b. Hence, when searching for an optimal payment rate, we can restrict atten-
tion to the interval (ùúÉ, b). Then the problem of the intermediary to find an optimal
payment rate ùúÉ‚àócan be written as
max
ùúÉ‚àà(ùúÉ,b)(b ‚àíùúÉ)x(ùúÉ),
(13.23)
where x(ùúÉ) = ‚à´1
q‚àóm(ùúÉ) z‚àó(q|q‚àó
m(ùúÉ))dF(q).
Using Lemma 13.2, we can show that ‚à´1
qm z‚àó(q|qm)dF(q) is continuous and
decreasing in qm on [0, 1], and thus by Proposition 13.1, x(ùúÉ) is continuous and
increasing in ùúÉon [ùúÉ, +‚àû). That is, an increase in ùúÉon [ùúÉ, +‚àû) will encourage
more content producers to produce content and make the intermediary to attract
more content views from the content viewer. Then it follows that the intermediary‚Äôs
problem (13.23) has an optimal solution by extending the region of ùúÉinto a compact
set [ùúÉ, b]. Moreover, if we assume that the objective function Œ†(ùúÉ) is strictly concave
on (ùúÉ, b), the intermediary‚Äôs problem has a unique solution. In this case, the unique
optimal payment rate ùúÉ‚àósatisfies the first-order optimality condition
Œ†‚Ä≤(ùúÉ) = ‚àíx(ùúÉ) + (b ‚àíùúÉ)x‚Ä≤(ùúÉ) = 0,
(13.24)
assuming that x is differentiable. Moreover, if 0 ‚àà(ùúÉ, b), we can find out whether
the intermediary should subsidize or tax the content producers by examining the
sign of Œ†‚Ä≤(0). Specifically, ùúÉ‚àóhas the same sign as that of Œ†‚Ä≤(0). If Œ†‚Ä≤(0) > 0, or
(b ‚àíùúÉ)x‚Ä≤(0) > x(0), the first-order gain from increased content views dominates the
first-order loss from payment to the content producers as the intermediary increases
ùúÉfrom 0. Thus, in this case, it is optimal for the intermediary to subsidize the content
producers, that is, ùúÉ‚àó> 0. On the other hand, if Œ†‚Ä≤(0) < 0, or x(0) > (b ‚àíùúÉ)x‚Ä≤(0), it
is optimal for the intermediary to tax the content producers, that is, ùúÉ‚àó< 0.
In the remainder of this chapter, to gain insights on the optimal payment rate, we
focus on the quality-adjusted Dixit‚ÄìStiglitz utility function and uniform distribution
of content qualities. In this case, z‚àó(1|1) = T‚àïqùúé
a and thus ùúÉ= cqùúé
a‚àïT ‚àís. In Proposi-
tion 13.2, whose proof is given in Reference 16 and references therein, we study the
optimal payment rate and its sign.
Proposition 13.2
Suppose that the utility function U(x) of the representative con-
tent viewer is given by the Dixit‚ÄìStiglitz utility function in Eq. (13.14) and that the
qualities of content that can be produced by the content producers are uniformly
distributed on [0, 1]. Then there exists a unique optimal payment rate ùúÉ‚àó‚àà(cqùúé
a‚àïT ‚àí
s, b) that maximizes the intermediary‚Äôs profit. The equilibrium marginal content qual-
ity given ùúÉ‚àó, denoted by q‚àó‚àó
m , is the unique root of the following equation in the variable
qm on (q‚àó
m(b), 1):
‚àí
T (b + s) qùúé
a
[
(ùúé+ 1) qùúé
a + 1 ‚àíqùúé+1
m
]2 +
c (ùúé+ qùúé+1
m
)
(ùúé+ 1)3 q2ùúé+1
m
= 0,
(13.25)

354
THE ECONOMICS OF USER-GENERATED CONTENT PLATFORMS
and ùúÉ‚àóis given by
ùúÉ‚àó=
c
[
(ùúé+ 1) qùúé
a + 1 ‚àí(q‚àó‚àó
m
)ùúé+1]
T (ùúé+ 1) (q‚àó‚àó
m )ùúé
‚àís.
(13.26)
Moreover, if 0 ‚àà(cqùúé
a‚àïT ‚àís, b), then
‚éß
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™‚é©
ùúÉ‚àó‚àà(0, b)
if
ùúé
q‚àó
m(0) + [q‚àó
m(0)]ùúé< c(b + s)(ùúé+ 1)qùúé
a
Ts2
,
ùúÉ‚àó= 0
if
ùúé
q‚àó
m(0) + [q‚àó
m(0)]ùúé= c(b + s)(ùúé+ 1)qùúé
a
Ts2
,
ùúÉ‚àó‚àà
(cqùúé
a
T
‚àís, 0
)
if
ùúé
q‚àó
m(0) + [q‚àó
m(0)]ùúé> c(b + s)(ùúé+ 1)qùúé
a
Ts2
.
(13.27)
Proposition 13.2 provides conditions under which the profit-maximizing inter-
mediary subsidizes or taxes the content producers. We can see that the intermediary
should subsidize the content producers in the following cases:
1. The total number of content views T is sufficiently small;
2. The production cost c is sufficiently large;
3. Social satisfaction per content view s is sufficiently small;
4. The aggregate quality of content on the other platforms qa is sufficiently large;
5. Outside profit per content view b is sufficiently large.
The first four cases lead to a situation in which it is difficult for a content producer
to make a profit from providing content on the intermediary‚Äôs platform. Thus, in these
cases, the intermediary tends to subsidize the content producers in order to encourage
content production. The statements can also be mathematically verified. Let us take
the first case as an example. When T is sufficiently small, q‚àó
m(0) will approach 1,
making the left-hand side of the first inequality in Eq. (13.27) reach ùúé+ 1. Thus,
the first inequality in Eq. (13.27) will hold when T is sufficiently small. In the last
case, the intermediary derives high outside profit per content view, for example, from
advertisement. Hence, it subsidizes off for the intermediary to subsidize the content
producers in order to increase content production on its platform, while it has more
revenue to share with them.
Numerical results illustrating the impacts of qa, c, and T are plotted in Figure 13.2.
It can be seen that the intermediary can improve its profit significantly by using the
proposed payment scheme compared to the case in which it does not use a payment
scheme at all (i.e., the case where ùúÉ= 0). For example, we observe from Figure 13.2b
that by optimally choosing the payment rate, the intermediary‚Äôs profit increases from
approximately 0.21‚Äì0.5 (nearly 150% increase) when c = 1.5.

PROFIT MAXIMIZATION ON USER-GENERATED CONTENT PLATFORMS
355
0
0.5
1
0
1
2
3
4
Œ∏
Œ∏
Profit
 
 
Taxing
Subsidizing
0
0.5
1
0
0.5
1
1.5
Profit
 
c = 0.2
c = 0.5
c = 1.0
c = 1.5
Taxing
Subsidizing
0
0.5
1
0
0.2
0.4
0.6
0.8
Œ∏
Profit
 
 
qa = 0.8
qa = 1.0
qa = 1.5
qa = 2.0
(a)
(b)
(c)
(d)
0
0.5
1
0
1
2
3
Œ∏
Profit
T = 5
T = 10
T = 20
T = 25
Taxing
Subsidizing
Œ≥ = 0
Œ≥ = 0.1
Œ≥ = 0.2
Œ≥ = 0.4
Figure 13.2
Profit versus price ùúÉ. ùúé= 2, b = 1, s = 0.4. (a) Impact of qa. T = 10, c = 1.0.
(b) Impact of c. T = 10, qa = 1.5. (c) Impact of T. c = 1.0, qa = 1.5. (d) Impact of ùõæ. T = 10,
c = 1.5, qa = 1.5.
Finally, we conclude this chapter by discussing two extreme cases, qa ‚Üí0 and
ùúé‚Üí+‚àû. First, consider the case where qa ‚Üí0. In this case, the aggregate quality
of content on the other platforms is negligible (e.g., very low quality or little content
available), and the intermediary becomes virtually a monopolist in the market. As the
content producers who can produce content of the highest quality 1 have the strongest
incentive to produce, almost all the T content views will be devoted to content on
the intermediary‚Äôs platform as long as there is some content on the platform. Note
that x(ùúÉ) > 0 if and only if ùúÉ> ùúÉand that ùúÉ‚Üí‚àís as qa ‚Üí0. Thus, as qa ‚Üí0, the
optimal payment ùúÉ‚àóconverges to ‚àís while the maximum profit converges to (b +
s)T. Next, consider the case where ùúé‚Üí+‚àû. In this case, content becomes perfectly
substitutable, and almost all the content views will be devoted to content of the highest
quality among content on all the platforms. This can be verified by taking the limits
of x‚àó
i (y) and x‚àó
a(y) given in Eqs. (13.15) and (13.16), respectively, as ùúé‚Üí+‚àûwith
‚à´1
0 yjqùúé
j dj = [1 ‚àí(q‚àó
m)ùúé+1]‚àï(ùúé+ 1). When qa > 1, we have x‚àó
i ‚Üí0 for all i and x‚àó
a ‚Üí
T. Thus, content produced on the intermediary‚Äôs platform will attract no content views
and the intermediary cannot obtain a positive profit regardless of the payment rate ùúÉ.
On the contrary, when qa < 1, we have x‚àó
a ‚Üí0 and x ‚ÜíT with x‚àó
i ‚àïx‚àó
j ‚Üí+‚àûfor all
i, j such that qi > qj > qa. When qa < 1, we again have ùúÉ‚Üí‚àís as ùúé‚Üí+‚àû. Hence,
the optimal payment rate ùúÉ‚àóconverges to ‚àís, while the maximum profit converges
to (b + s)T. To sum up, when qa ‚Üí0 or ùúé‚Üí+‚àûwith qa < 1, the intermediary can

356
THE ECONOMICS OF USER-GENERATED CONTENT PLATFORMS
attract almost all the T content views while extracting almost all the social satisfaction
of the content producers.
Remark: Suppose that the aggregate quality of content on the other platforms qa
is derived from a distribution of qualities. Suppose further that the qualities are uni-
formly distributed on the interval [ql, qh] with total mass na, where 0 ‚â§ql < qh. Then
by the relationship qa = (na ‚à´1
0 qùúé
kdk)1‚àïùúé, we obtain
qa =
[
na
(qùúé+1
h
‚àíqùúé+1
l
)
1 + ùúé
]1
ùúé
= n
1
ùúé
a q
ùúé+1
ùúé
h
[
1 ‚àí
( ql
qh
)ùúé+1]1
ùúé(
1
1 + ùúé
)1
ùúé.
(13.28)
As
limùúé‚Üí+‚àûn1‚àïùúé
a
= limùúé‚Üí+‚àû
[
1 ‚àí(ql‚àïqh
)ùúé+1]1‚àïùúé
= limùúé‚Üí+‚àû(1‚àï(1 + ùúé))1‚àïùúé= 1
and limùúé‚Üí+‚àûq(ùúé+1)‚àïùúé
h
= qh, we have qa ‚Üíqh as ùúé‚Üí+‚àû. Thus, when ùúé‚Üí+‚àû,
the highest quality qh determines the aggregate quality qa, and we have qa > 1 if
qh > 1 and qa < 1 if qh < 1.
13.3.5
Overjustification Effects
Now, we briefly discuss overjustification effects on the intermediary‚Äôs equilibrium
profit.
It has been argued that an external incentive such as money or prizes decreases a
person‚Äôs intrinsic motivation to perform a task, and such phenomenon is referred to as
overjustification effects [18]. In the context of user-generated content platforms, con-
tent producers‚Äô internal incentive to produce content may decrease in the long term if
the intermediary chooses to subsidize content producers. We model overjustification
effects using the following formula
s‚Ä≤ = max [0, s ‚àíùõæ‚ãÖmax(0, ùúÉ)] ,
(13.29)
where s‚Ä≤ is the new social satisfaction per content view in the presence of overjustifi-
cation effects and ùõæ‚àà[0, ‚àû) indicates the severity of overjustification effects. Note
that if the intermediary taxes content producers, overjustification effects do not exist,
that is, s‚Ä≤ = s. We show the profits under various values of ùõæin Figure 13.2d and
observe that even though overjustification effects exist, the intermediary can still
increase its profit by applying the proposed payment scheme, as long as overjusti-
fication effects are not too strong (e.g., ùõæis not too large). In the presence of strong
overjustification effects (e.g., ùõæ‚â•1), a content producer‚Äôs incentive to produce con-
tent will even decrease if the intermediary subsidizes content producers for content
production (unless the intermediary subsidizes content producers sufficiently high).
13.4
EXTENSION TO HETEROGENEOUS PRODUCTION COSTS
In the analysis so far, it has been assumed that all the content producers incur the same
production cost c when they choose to produce content. In this chapter, we extend

EXTENSION TO HETEROGENEOUS PRODUCTION COSTS
357
our model and generalize the preceding analysis by relaxing this assumption and
considering a scenario in which the content producers have different production costs.
We assume that there are K groups of content producers and that the production cost
of a content producer in group k is given by ck > 0 for k = 1, ‚Ä¶ , K. We assume that
c1 < c2 < ¬∑ ¬∑ ¬∑ < cK. We use Ik to denote the set of the indexes of the content producers
in group k, for k = 1, ‚Ä¶ , K. Then {I1, ‚Ä¶ , Ik} forms a partition of [0, 1]. The mass of
the content producers in group k is denoted by nk so that ‚àëK
k=1 nk = 1. We assume
that for each k the qualities of content that can be produced by the content producers
in group k are distributed according to a cumulative distribution function Fk(‚ãÖ), which
has a continuous probability distribution function fk(‚ãÖ) with support [0, 1].
With heterogeneous production costs, the definition of an equilibrium is modified
so that (ii) in Definition 13.1 becomes as follows: for each content producer i ‚ààIk,
k = 1, ‚Ä¶ , K, y‚àó
i (ùúÉ) is an optimal production decision, given ùúÉ, x‚àó
i (y), and (y‚àó
j (ùúÉ))j‚â†i,
that is,
(ùúÉ+ s)x‚àó
i (y‚àó(ùúÉ)) ‚àíck ‚â•0
if y‚àó
i (ùúÉ) = 1
(13.30)
and
(ùúÉ+ s)x‚àó
i (1, y‚àó
‚àíi(ùúÉ)) ‚àíck ‚â§0
if y‚àó
i (ùúÉ) = 0,
(13.31)
while (i) and (iii) remain the same. When ùúÉ> ‚àís, equilibrium production decisions
are characterized by thresholds, one for each group. We use qm,k ‚àà[0, 1] to denote
the threshold used by the content producers in group k, for k = 1, ‚Ä¶ , K. We also use
a vector notation ùê™m = (qm,1, qm,2, ‚Ä¶ , qm,K) ‚àà[0, 1]K. As before, we use z‚àó(q|ùê™m) to
denote the number of content views that a content producer receives if it produces con-
tent of quality q while all the other content producers use thresholds ùê™m. Lemma 13.2
can be modified so that the following holds: (i) for all ùê™m ‚àà[0, 1]K, z‚àó(0|ùê™m) = 0 and
z‚àó(q|ùê™m) > 0 for all q > 0 and (ii) z‚àó(q|ùê™m) is continuous and increasing in q and each
element of ùê™m. We define a mapping ùêêùúÉ‚à∂[0, 1]K ‚Üí[0, 1]K so that the kth element
of ùêêùúÉ(ùê™m) is given by
QùúÉ,k(ùê™m) =
‚éß
‚é™
‚é®
‚é™‚é©
arg min{q ‚àà[0, 1] ‚à∂
if (ùúÉ+ s)z‚àó(1|ùê™m) ‚àíck ‚â•0,
(ùúÉ+ s)z‚àó(q|ùê™m) ‚àíck ‚â•0}
1
otherwise,
(13.32)
for k = 1, ‚Ä¶ , K. Equilibrium content production is characterized by a fixed point of
ùêêùúÉ, as defined in the following.
Definition 13.3
ùê™‚àó
m is an equilibrium marginal content quality vector (or equilib-
rium production threshold vector), given payment rate ùúÉif it satisfies ùê™‚àó
m = ùêêùúÉ(ùê™‚àó
m).
The following properties of equilibrium thresholds can be readily established.

358
THE ECONOMICS OF USER-GENERATED CONTENT PLATFORMS
Lemma 13.3
Let ùê™‚àó
m be an equilibrium marginal content quality vector, given pay-
ment ùúÉ> ‚àís. Then 0 < q‚àó
m,1 ‚â§q‚àó
m,2 ‚â§¬∑ ¬∑ ¬∑ ‚â§q‚àó
m,K ‚â§1 and
z‚àó(q‚àó
m,k|ùê™‚àó
m)
z‚àó(q‚àó
m,l|ùê™‚àó
m) = ck
cl
,
(13.33)
for all k, l ‚â§k‚àó, where k‚àó= max{k ‚àà{1, ‚Ä¶ , K}‚à∂q‚àó
m,k < 1}.
In the previous analysis, we have defined ùúÉas the payment rate that induces the
content producers to start producing content. That is, ùúÉwas the payment under which
a content producer who can produce content of the highest quality 1 is indifferent
between producing and not producing. As there are K heterogeneous groups in the
current analysis, we define K payment rates, ùúÉ1, ‚Ä¶ , ùúÉK, where ùúÉk is the payment
rate that induces the content producers in group k to start producing content. Follow-
ing c1 < c2 < ¬∑ ¬∑ ¬∑ < cK, it is obvious that ùúÉ1 < ùúÉ2 < ¬∑ ¬∑ ¬∑ < ùúÉK. First, the indifference
condition satisfied at ùúÉ= ùúÉ1 is (ùúÉ+ s)z‚àó(1|(1, ‚Ä¶ , 1)) = c1. Hence, we obtain
ùúÉ1 =
c1
z‚àó(1|(1, ‚Ä¶ , 1)) ‚àís.
(13.34)
Now consider k = 2, ‚Ä¶ , K. At ùúÉ= ùúÉk, there are some content producers who choose
to produce in each group l < k, and the following indifference conditions should be
satisfied.
(ùúÉk + s) z‚àó(
qk
m,l|
(
qk
m,1, ‚Ä¶ , qk
m,k‚àí1, 1, ‚Ä¶ , 1
))
= cl, for l = 1, ‚Ä¶ , k ‚àí1, and
(13.35)
(ùúÉk + s) z‚àó(
1|
(
qk
m,1, ‚Ä¶ , qk
m,k‚àí1, 1, ‚Ä¶ , 1
))
= ck.
(13.36)
Note that Eqs. (13.35) and (13.36) together define a system of k equations in
k unknowns, qk
m,1, ‚Ä¶ , qk
m,k‚àí1, and ùúÉk. To simplify our analysis, we impose the
following assumption.
Assumption 13.5
For any q ‚àà[0, 1], q‚Ä≤ ‚àà(0, 1], and ùê™m ‚àà[0, 1]K, the ratio
z‚àó(q|ùê™m)‚àïz‚àó(q‚Ä≤|ùê™‚àó
m) is independent of ùê™m.
We can verify that z‚àó(q|ùê™m) induced by the Dixit‚ÄìStiglitz utility function satisfies
Assumption 13.5. By Assumption 13.5, we can write z‚àó(q|ùê™m)‚àïz‚àó(q‚Ä≤|ùê™‚àó
m) as ÃÉz(q, q‚Ä≤).
By modified Lemma 13.2, given q‚Ä≤ ‚àà(0, 1], ÃÉz(q, q‚Ä≤) is continuous and increasing
in q with ÃÉz(0, q‚Ä≤) = 0 and ÃÉz(q‚Ä≤, q‚Ä≤) = 1. Hence, there exists unique qk
m,k‚àí1 ‚àà(0, 1)
that satisfies ÃÉz(qk
m,k‚àí1, 1) = ck‚àí1‚àïck. The remaining thresholds, qk
m,1, ‚Ä¶ , qk
m,k‚àí2, can be
obtained by solving ÃÉz(qk
m,l, qk
m,l+1) = cl‚àïcl+1 from l = k ‚àí2 to l = 1 recursively. This

EXTENSION TO HETEROGENEOUS PRODUCTION COSTS
359
yields the k ‚àí1 thresholds qk
m,1, ‚Ä¶ , qk
m,k‚àí1 such that 0 < qk
m,1 < ¬∑ ¬∑ ¬∑ < qk
m,k‚àí1 < 1.
Then using Eq. (13.36), we obtain
ùúÉk =
ck
z‚àó
(
1|
(
qk
m,1, ‚Ä¶ , qk
m,k‚àí1, 1, ‚Ä¶ , 1
)) ‚àís
(13.37)
for k = 2, ‚Ä¶ , K. On the basis of the discussion so far, we can obtain the following
proposition, which is stated without a proof because of space limitation.
Proposition 13.3
For any ùúÉ> ‚àís, there exists a unique equilibrium marginal con-
tent quality vector given payment rate ùúÉ, ùê™‚àó
m(ùúÉ). For each k = 1, ‚Ä¶ , K, the following
properties hold. q‚àó
m,k(ùúÉ) = 1 for ùúÉ‚â§ùúÉk and q‚àó
m,k(ùúÉ) ‚àà(0, 1) for ùúÉ> ùúÉk. q‚àó
m,k(ùúÉ) is
continuous and decreasing in ùúÉon [ùúÉk, +‚àû) and approaches zero as ùúÉ‚Üí+‚àû. For
ùúÉ‚àà[ùúÉk, ùúÉk+1) ([ùúÉK, +‚àû) when k = K), we have 0 < q‚àó
m,1(ùúÉ) < ¬∑ ¬∑ ¬∑ < q‚àó
m,k(ùúÉ) ‚â§1 =
q‚àó
m,k+1(ùúÉ) = ¬∑ ¬∑ ¬∑ = q‚àó
m,K(ùúÉ).
As in Section 13.3.3, we can consider a best-response dynamics for the content
producers to adjust their production decisions based on the thresholds used in the pre-
vious period. Let ùê™m,t = (qm,1,t, qm,2,t, ‚Ä¶ , qm,K,t
) be the vector of the thresholds used
in period t = 1, 2, ‚Ä¶ Then starting from an initial belief ùê™m,0, the dynamics yields
a sequence {ùê™m,t}‚àû
t=0 generated by ùê™m,t+1 = ùêêùúÉ(ùê™m,t) for t = 0, 1, ‚Ä¶ More specific
results regarding the equilibrium marginal content quality vector and the convergence
of the best-response dynamics can be obtained using the Dixit‚ÄìStiglitz utility func-
tion. The details are omitted for brevity.
Now we turn to the intermediary‚Äôs problem of finding an optimal payment rate.
Note that we have x(ùúÉ) = ‚àëK
k=1 nk ‚à´1
q‚àó
m,k(ùúÉ) z‚àó(q|ùê™‚àó
m(ùúÉ))dFk(q). We assume that ùúÉ1 < b.
Then Œ†(ùúÉ) = 0 for ùúÉ‚â§ùúÉ1, Œ†(ùúÉ) > 0 for ùúÉ‚àà(ùúÉ1, b), and Œ†(ùúÉ) ‚â§0 for ùúÉ‚â•b. Hence,
we can restrict attention to the interval (ùúÉ1, b) when searching for an optimal payment
rate. Also, if ùúÉk ‚â•b for some k, then it is not profitable for the intermediary to induce
content production by producers in groups k, k + 1, ‚Ä¶ , K, and we can ignore these
groups in the analysis. Hence, without the loss of generality, we assume that ùúÉK < b.
For concreteness, we will focus on the Dixit‚ÄìStiglitz utility function and uniform
distribution of qualities for each group. In this case, we have
z‚àó(q|ùê™m
) =
T(ùúé+ 1)qùúé
(ùúé+ 1)qùúé
a + ‚àëK
k=1 nk
(
1 ‚àíqùúé+1
m,k
).
(13.38)
Thus, we have ÃÉz(q, q‚Ä≤) = (q‚àïq‚Ä≤)ùúé, from which we get qk
m,l = (cl‚àïck)1‚àïùúé
for
l = 1, ‚Ä¶ , k ‚àí1, for k = 2, ‚Ä¶ , K. Hence, we have ùúÉ1 = c1qùúé
a‚àïT ‚àís and
ùúÉk =
ck
{
qùúé
a +
1
ùúé+1
‚àëk‚àí1
l=1 nl
[
1 ‚àí
( cl
ck
)ùúé+1
ùúé
]}
T
‚àís
(13.39)

360
THE ECONOMICS OF USER-GENERATED CONTENT PLATFORMS
for k = 2, ‚Ä¶ , K.
Let ùúÉK+1 = b. We consider the problems maxùúÉ‚àà[ùúÉk,ùúÉk+1] Œ†(ùúÉ) for k = 1, ‚Ä¶ , K. Once
we obtain Œ†‚àó
k = maxùúÉ‚àà[ùúÉk,ùúÉk+1] Œ†(ùúÉ), we have maxùúÉ‚àà(ùúÉ1,b) Œ†(ùúÉ) = max{Œ†‚àó
1, ‚Ä¶ , Œ†‚àó
K}
and an optimal payment rate is the one that achieves the maximum profit. As in the
previous analysis, when solving maxùúÉ‚àà[ùúÉk,ùúÉk+1] Œ†(ùúÉ), we replace the choice variable ùúÉ
with q‚àó
m,k, where the corresponding region of q‚àó
m,k is [q‚àó
m,k(ùúÉk+1), q‚àó
m,k(ùúÉk)]. Note that
q‚àó
m,k(ùúÉk) = 1 for k = 1, ‚Ä¶ , K and q‚àó
m,k(ùúÉk+1) = qk+1
m,k for k = 1, ‚Ä¶ , K ‚àí1. When the
intermediary chooses q‚àó
m,k ‚àà[q‚àó
m,k(ùúÉk+1), q‚àó
m,k(ùúÉk)], we have q‚àó
m,l = (cl‚àïck)1‚àïùúéq‚àó
m,k for
l < k and q‚àó
m,l = 1 for l > k. The corresponding value of ùúÉis given by
ùúÉ=
ck
{
qùúé
a +
1
ùúé+1
‚àëk
l=1 nl
[
1 ‚àí
( cl
ck
)ùúé+1
ùúé(
q‚àó
m,k
)ùúé+1
]}
T
(
q‚àó
m,k
)ùúé
‚àís,
(13.40)
while the total number of content views in the platform is
x =
T ‚àëk
l=1 nl
[
1 ‚àí
(
cl
ck
)ùúé+1
ùúé(
q‚àó
m,k
)ùúé+1
]
(ùúé+ 1) qùúé
a + ‚àëk
l=1 nl
[
1 ‚àí
( cl
ck
)ùúé+1
ùúé(
q‚àó
m,k
)ùúé+1
].
(13.41)
Hence, the problem maxùúÉ‚àà[ùúÉk,ùúÉk+1] Œ†(ùúÉ) can be transformed into maxq‚àó
m,k‚àà[q‚àó
m,k(ùúÉk+1),
q‚àó
m,k(ùúÉk)] ÃÉŒ†k(q‚àó
m,k), where
ÃÉŒ†k
(
q‚àó
m,k
)
=
T (b + s) ‚àëk
l=1 nl
[
1 ‚àí
( cl
ck
)ùúé+1
ùúé(
q‚àó
m,k
)ùúé+1
]
(ùúé+ 1) qùúé
a + ‚àëk
l=1 nl
[
1 ‚àí
(
cl
ck
)ùúé+1
ùúé(
q‚àó
m,k
)ùúé+1
]
‚àí
ck
‚àëk
l=1 nl
[
1 ‚àí
( cl
ck
)ùúé+1
ùúé(
q‚àó
m,k
)ùúé+1
]
(ùúé+ 1)
(
q‚àó
m,k
)ùúé
.
(13.42)
By taking the second-order derivative of ÃÉŒ†k, we can show that ÃÉŒ†k is strictly
concave on (q‚àó
m,k(ùúÉk+1), q‚àó
m,k(ùúÉk)). Hence, there exists a unique optimal solution to
maxq‚àó
m,k‚àà[q‚àó
m,k(ùúÉk+1),q‚àó
m,k(ùúÉk)] ÃÉŒ†k(q‚àó
m,k). As in the case of a homogeneous production
cost, we can also analyze whether the intermediary should subsidize or tax the
content producers. Nevertheless, we omit the result because of its similarity to
Proposition 13.2.

REFERENCES
361
13.5
CONCLUSION
In this chapter, we studied the economics of user-generated content platforms
by focusing on the profit maximization problem of an intermediary who owns a
user-generated content platform. We considered a class of payment schemes in
which the intermediary subsidizes or taxes content producers per content view
while it provides the service for free to content viewers. We analyzed a three-stage
game using backward induction. First, we used the representative content viewer to
determine how content viewers‚Äô attention is allocated across a variety of available
content. Next, after establishing the threshold property of equilibrium production
decisions, we showed the existence and uniqueness of an equilibrium production
threshold used by the content producers and derived its properties. Lastly, we
formalized the intermediary‚Äôs profit maximization problem and studied the optimal
payment rate by using the quality-adjusted Dixit‚ÄìStiglitz utility function and the
uniform distribution of content qualities as a concrete example. We provided con-
ditions under which the intermediary should subsidize or tax the content producers
and discussed qualitatively the impacts of the aggregate quality of outside content
and content substitutability on the intermediary‚Äôs profit. We also discussed the
effectiveness of the proposed payment scheme in the presence of overjustification
effects. As an extension of our model, we considered heterogeneity in the content
producers‚Äô production costs. There are various directions to extend our work, among
which we mention only a few as follows. First, we can consider a more general
class of payment schemes. In this chapter, we considered anonymous and linear
payment schemes, but the intermediary may use personalized (e.g., quality depen-
dent) and nonlinear payment schemes as well. Second, we can consider a scenario
where a content producer can choose a production intensity, which determines
the production cost and the content quality, and can choose a content platform to
post its content among several competing platforms. Third, we can incorporate the
intermediary‚Äôs payment decision into its back-end resource management (e.g., data
centers). As shown in our preliminary work [19], jointly optimizing the payment
decision and resource management by exploring the interactions among them can
significantly enhance the intermediary‚Äôs profitability. Last but not least, the tree-stage
game studied in this chapter can be extended to other application scenarios (e.g.,
customer-to-customer market [20]) or incorporate additional decisions to model the
intermediary‚Äôs investment strategy (e.g., infrastructure and technology investment
on television content platforms [21]).
REFERENCES
1. A. Gosh and P. McAfee. ‚ÄúIncentivizing high-quality user-generated content,‚Äù World Wide
Web, 2011.
2. S. Jain, Y. Chen, and D. C. Parkes. Designing Incentives for Online Question and Answer
Forums. In ACM Conf. Electronic Commerce, 2009.
3. V. K. Singh, R. Jain, and M. S. Kankanhalli. Motivating Contributors in Social Media
Networks. In ACM SIGMM Workshop on Social Media, 2009.

362
THE ECONOMICS OF USER-GENERATED CONTENT PLATFORMS
4. Wikipedia,‚ÄúUser-generatedcontent,‚Äùhttp://en.wikipedia.org/wiki/User-generated_content
5. J. C. Rochet and J. Tirole. ‚ÄúPlatform competition in two-sided markets,‚Äù Journal of the
European Economic Association, 1, 2003, 990‚Äì1029.
6. P. Hande, M. Chiang, A. R. Calderbank, and S. Rangan. Network pricing and rate alloca-
tion with content provider participation. In IEEE Infocom, April 2009.
7. J. C. Rochet and J. Tirole. ‚ÄúCooperation among competitors: some economics of payment
card associations,‚Äù Rand Journal of Economics, 33, 2002, 549‚Äì570.
8. J. C. Rochet and J. Tirole. ‚ÄúTwo-sided markets: a progress report,‚Äù RAND Journal of Eco-
nomics, 37, 2006, 645‚Äì667.
9. A. Hagiu. ‚ÄúMerchant or two-sided platform?‚Äù Review of Network Economics, 6(2), 2007,
115‚Äì133.
10. J. Musacchio, G. Schwartz, and J. Walrand. ‚ÄúA two-sided market analysis of provider
investment incentives with an application to the net-neutrality issue,‚Äù Review of Network
Economics, 8(1), 2009, 22‚Äì39.
11. Y. Jin, S. Sen, R. Guerin, K. Hosanagar, and Z.-L. Zhang. Dynamics of competition
between incumbent and emerging network technologies. In NetEcon, Aug. 2008.
12. S. Ren, J. Park, and M. van der Schaar. ‚ÄúEntry and spectrum sharing scheme selection
in femtocell communications markets,‚Äù IEEE/ACM Transactions on Networking, 21(2),
2013, 218‚Äì-232.
13. S. Ren and M. van der Schaar. ‚ÄúData demand dynamics in communications markets,‚Äù IEEE
Transactions on Signal Processing, 60(4), 2012, 1986‚Äì2000.
14. J. Nair, A. Wierman, and B. Zwart. ‚ÄúExploiting network effects in the provisioning of large
scale systems,‚Äù SIGMETRICS Performance Evaluation Review, 39(2), 2011, 26‚Äì28.
15. A. K. Dixit and J. E. Stiglitz. ‚ÄúMonopolistic competition and optimum product diversity,‚Äù
American Economic Review, 67(3), 1977, 297‚Äì308.
16. S. Ren, J. Park, and M. van der Schaar. Maximizing profit on user-generated content plat-
forms with participant heterogeneity. In IEEE Infocom, 2012.
17. J. R. Munkres. Elements of Algebraic Topology. Perseus Books Publishing, New York,
1993.
18. M. R. Lepper, D. Greene, and R. E. Nisbett. ‚ÄúUndermining children‚Äôs intrinsic interest
with extrinsic reward: a test of the ‚Äòoverjustification‚Äô hypothesis,‚Äù Journal of Personality
and Social Psychology 28(1), 1973, 129‚Äì137.
19. S. Ren and M. van der Schaar. Joint design of dynamic scheduling and pricing in wireless
cloud computing. In IEEE Infocom, 2013.
20. S. Ren and M. van der Schaar. Revenue maximization in customer-to-customer markets.
In GameNets, 2012.
21. S. Ren and M. van der Schaar. ‚ÄúPricing and investment for online TV content platforms,‚Äù
IEEE Transaction on Multimedia, 14(6), 2012, 1566‚Äì1578.

PART V
Managing Content Delivery


14
Spare Capacity Monetization
by Opportunistic Content
Scheduling
BELL LABS and ALCATEL-LUCENT
14.1
SUMMARY
In recent years, mobile data traffic has been growing at an exponential rate with traf-
fic volume doubling every year and some studies predicting even more than 18-fold
increase in data traffic in the next 5 years [1]. This rapid increase in data traffic is
making it necessary to grow network capacity at a much faster rate than ever before.
Unfortunately, the rate of growth of data revenue is much lower than the rate of growth
of traffic, raising the specter that at some point capacity costs may even begin to
outweigh revenues thus greatly lowering the incentives for capital investments. At
the same time, the highly uneven usage by data users has resulted in significant net-
work inefficiencies whereby even congested networks are heavily underutilized most
of the time. In this chapter, we present the capacity monetization system PLUTUS
that taps this stranded network capacity for additional revenue and enhanced network
efficiency.
Many factors have contributed to the mobile data tsunami, including the intro-
duction of smartphones along with a wide variety of multimedia-focused mobile
applications and the increase in performance of the mobile technology as it moved
from 2G on to 4G. The industry‚Äôs bold but short experimentation with unlimited data
plans allowed the subscribers armed with powerful devices to unleash an onslaught
of uncontrolled traffic. The resulting data usage patterns that have emerged are
chaotic at best creating random, intermittent bottlenecks and congested hotspots
spread across time and space. This has created a situation where even at low average
utilization, the peak network load can be significantly high. As CAPEX decisions are
mostly driven by peak load, this has driven up the cost of carrying data over mobile
network. Operators have responded by putting in place tiers, caps, and throttling
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
365

366
SPARE CAPACITY MONETIZATION BY OPPORTUNISTIC CONTENT SCHEDULING
in order to regulate bandwidth demand. However, by over pricing data and over
restricting usage, operators run the risk of stifling the demand for mobile data, thus
loosing the opportunity to generate high revenue from increasing data usage.
There is growing recognition on the part of operators that they must tap into the
abundant unused spare capacity in their network both to create new sources of rev-
enue and to keep data delivery costs low. According to some studies [2, 3], peak
load to average utilization ratio in mobile networks can be as high as four times
with most of the traffic carried during a few busy hours while the network stays
underutilized the rest of the time. As all the time periods where the network is under-
utilized is already sunk cost for the operator, additional traffic can be carried during
such time periods at negligible marginal cost. As reported in [1,4] every other bit
being carried on mobile networks is now video, with more than 25% coming from
Youtube alone [1,4]. As audio and video traffic involves downloading large files or
chunks thereof (e.g., using progressive download or adaptive streaming), it can be
easily time shifted to periods with low network utilization. Likewise, content recom-
mended on social networks (e.g., Facebook) and media sites (e.g., Netflix, Pandora)
that has a high chance of being watched could be preloaded and cached onto users
device during off-peak times. In addition, the abundant capacity of WiFi and Small
Cell networks can also be tapped for carrying time-shifted traffic. Operators can,
therefore, start generating additional revenues by selling their unused capacity at
a relatively low price as well as increase network efficiency by encouraging sub-
scribers to shift their usage to appropriate times on available networks. This controlled
rearrangement of data usage patterns can lead to a reduction in the peak-to-average
ratio ideally flattening the load curve, thus slowing down the rate of network expan-
sion by accommodating more traffic without investing in capacity enhancements.
Similar ideas have been tried in other industries such as smart electric grids [5, 6]
for reducing peak load by shifting load toward off-peak hours when electricity is
cheaper or for alleviating road congestion by the use of tolls or for increased effi-
ciency by Yield Management [7] approaches practiced in airline, hotel, and other
industries.
In this chapter, we present the design of PLUTUS, a capacity monetization and
network efficiency enhancement system. The PLUTUS system lets the operator real-
ize extra revenue by delivering additional data using unused capacity of diverse access
networks. The PLUTUS system is best suited for the delivery of large files (multime-
dia content, app updates, etc.) that constitute the majority of the traffic on the mobile
network and are also the biggest source of congestion. A data file marked for deliv-
ery using the PLUTUS system is opportunistically transferred at the right time using
the best available network. This includes dynamic resuming or suspending of data
transfers in reaction to the availability of unused capacity. It also includes seamless
network switchovers while maintaining session continuity. In addition, the PLUTUS
system data transfers are tightly controlled to make the best use of the spare capacity
by evenly spreading out the network load. In PLUTUS data items transferred to the
users handset are cached locally in the device storage. This enables local playback of
multimedia content providing a high quality experience.

BACKGROUND
367
As 80% of the mobile network cost is in the radio access network (RAN), which
is also the most capacity constrained portion of the network, monetizing the spare
capacity in RAN can bring the most benefit. As reported in previous studies [2, 3],
the cell loads fluctuate unpredictably and rapidly at the granularity of minutes and
there may not be much correlation among cells in different locations. The PLUTUS
system is designed for fast identification and reaction to changes in available capac-
ity at the cell/sector/carrier level without introducing significant signaling or data
overheads, which has been a challenging problem [8‚Äì10]. In addition, the PLUTUS
system dynamically and quickly adapts to changes in the traffic patterns to avoid cre-
ating any new peaks or congestion in the network. All this is accomplished while
factoring in the mobility of users.
In order to increase users‚Äô confidence and gain widespread acceptance, the PLU-
TUS system also provides reasonable estimates for the additional delays introduced
by time shifting. These estimates are derived from data collected on the historic
patterns of users‚Äô mobility, network access and usage. In order to stay within the
estimated delays, a combination of offline- and online-controlled scheduling of data
transfers that adapts dynamically to changes in network and user state is applied.
This scheduling also aims to minimize battery drain and avoid tying up scarce RAN
resources from data transfers that may get stretched out for a long time when there
is limited capacity to share. By preloading and locally caching content in advance
of consumption, PLUTUS can further reduce peak loads and also enhance the user
experience. The PLUTUS system also addresses efficient ways of interfacing with
existing applications and services that want to take advantage of the spare capacity
in the network. The rest of the chapter is structured as follows. We start out by sur-
veying the related work in this space. Next we describe the main ideas used in the
PLUTUS system including how pricing plans can be designed to give the right incen-
tive to the user while ensuring that the operators are able to profitably monetize the
spare capacity in their network. Then we present the design and architecture of the
PLUTUS system. Finally, we present implementation details and performance results
from various trials with subscribers and operators around the world.
14.2
BACKGROUND
Pricing plans for wireless data have seen a number of changes over the past few years.
First, to drive up user adoption, the expensive metered data plans were replaced by the
popular unlimited all-you-can-eat plans. As initially the data traffic was not very high,
these plans made good revenue for the Internet service providers (ISPs). But in recent
years, these plans have contributed to the exponential growth in the data traffic making
it unprofitable for the service providers to continue to offer them. The ISPs have
responded by replacing these with tiered and sometimes usage-based plans [11, 12].
Some of these plans include surcharges for exceeding tier limits while others throttle
the data transfers once the limit is crossed. ISPs are also trying other ways of charging
for data, namely, based on time [13] and application [14].

368
SPARE CAPACITY MONETIZATION BY OPPORTUNISTIC CONTENT SCHEDULING
Data pricing has been an active area of research with many ideas influenced by
pricing work in other industries (e.g., utilities, road transportation, airlines). As early
as in 1950s, Houthakker [15], Steiner, and others proposed a dynamic pricing scheme
where pricing for peak periods is higher than the pricing for off-peak periods and
traffic is charged based on when it traverses the network. Odlyzko [16] have proposed
static partitioning of the network resources into separate logical traffic classes that are
charged differently. Interested reader is referred to Sen et al. [17] for a comprehensive
survey of the large body of work in this area. Unfortunately, so far there has been little
adoption by ISPs of any of these proposed pricing schemes. However, this is likely to
change as the ISPs must implement efficient schemes to manage their growing traffic
costs and remain profitable. We believe that the key to adoption is a pricing scheme
that cannot only be easily implemented by the ISP but is also predictable and simple
for the user. This is the motivation behind the approach taken in this chapter.
The ability to quickly detect and react to congestion is key for efficient monetiza-
tion of spare capacity. Many schemes have been proposed for wireline networks [18],
but there is limited work for wide area broadband wireless networks. This is because
the shared nature of the transmission channel, interference from external sources,
and use of rate adaptation algorithms (e.g., proportional fair) makes it a challenging
problem. It has been proposed that channel utilization may be a better measure of
congestion in wireless network [19]. Solutions to determine channel utilization are
based on both active probing [8, 9, 19, 20, 35] and passive probing [10]. We describe
a client-based active probing approach that we have developed for PLUTUS.
ISPs are also implementing other solutions for managing traffic growth includ-
ing video optimizations (e.g. transcoding, transrating, pacing, adaptive streaming),
offloading (to WiFi, small cells), upgrading to more efficient IP and 4G technolo-
gies, and so on. These solutions are orthogonal to PLUTUS and their use does not
eliminate the need for time shifting and, when used in conjunction with PLUTUS,
can achieve even greater network utilization. Detailed discussion of these solutions,
however, is out of scope of this chapter.
14.3
THE PLUTUS APPROACH
The PLUTUS system enables the operator to deliver additional data using capacity
that is already built into the network and is not currently in use. The main idea is
to classify data transfers into one of two classes, the ‚ÄúAny Time Data‚Äù (ATD) class
for transfers that can happen at any time irrespective of the state of the network and
the ‚ÄúSurplus Data‚Äù (SD) class for delivery using capacity that is not in use by the
ATD class (however, some minimum capacity may be reserved for the SD class).
Note that the ATD class corresponds to the present mode of operation without any
time shifting, while the SD class represents data transfers at opportunistic times when
the network has unused capacity or when other networks (e.g., WiFi, small cells) are
available. The SD class data transfers may, therefore, incur additional delays but have
negligible marginal cost for delivery and, therefore, can include price discounts to

THE PLUTUS APPROACH
369
incentivize user adoption. The PLUTUS system manages all aspects of delivery for
data items in the SD class including classification, opportunistic scheduling, tempo-
rary or long-term caching, differential accounting and charging, and so on. The ATD
class data transfers, however, continue to operate as before.
The typical use case for PLUTUS is as follows. An application or user uses
PLUTUS to issue a SD class data transfer request at any time irrespective of
the loading state of the network. On submission, a delivery estimate is provided
followed by status updates and notifications as the data is delivered. In that respect,
PLUTUS has resemblance to the ‚ÄúDigital FedEx Service‚Äù [21] proposal for deeply
discounted delivery of content using spare network capacity which in turn is inspired
by courier-based delivery of physical goods scheduled to happen by a fixed set of
deadlines. The PLUTUS system fully manages the data delivery including transfers
at times when the network has unused capacity and scheduling to evenly spread out
the network load. PLUTUS suspends or resumes the data delivery in reaction to
the changes in the availability of unused capacity, and it caches the transferred data
locally at the receiver. In PLUTUS, transferred data is consumed directly from local
cache. This ensures high quality user experience that is not impacted by network
impairments [22] with delivered data available for use even when not connected to
the network.PLUTUS uses a progressive mode of delivery and can let the user start
using the data before it is fully transferred (e.g., for multimedia content playback).
This is unlike existing pricing approaches [16, 23] that only provide price incentives
to time shift usage but have limited guarantees on the user experience during or after
the time shift, PLUTUS can ensure, post-delivery, high quality user experience that
is not impacted by network impairments with delivered data available for use even
when not connected to the network. The PLUTUS system is, therefore, very well
suited for the delivery of multimedia clips and files, e-mail attachments, application,
software updates and so on, which constitute a significant portion of the traffic on
the mobile network [4].
With PLUTUS, the network can be thought of being partitioned into separate
logical channels that differ only in the price paid by the users to use them. The
higher priced channel referred to as the ATD channel retains commonly used pric-
ing structures that are currently in place for the mobile networks (flat, tiered, etc.).
The discounted channel referred to as the SD channel offers discounts over the ATD
channel. A typical SD channel pricing offering may include a tiered data plan at a
50% discount over an identical ATD plan or a zero-rated media application for a
fixed monthly subscription such that the user is not charged for any data usage within
the application all of which is carried over the SD channel. Thus PLUTUS maintains
the simplicity of logical channels each with relatively constant and easily understood
pricing. This is in contrast to much of the recent work [23] that relies heavily on
incentives that are time and space dependent. We believe that staying with pricing
plans that the users are already comfortable with as well as by not requiring signif-
icant enhancements to the network accounting and charging systems can make for
an easier adoption. Section 14.3.1 describes a more formal mathematical model for
setting the discounts on SD channel.

370
SPARE CAPACITY MONETIZATION BY OPPORTUNISTIC CONTENT SCHEDULING
PLUTUS uses priority as one of the mechanisms for creating logical channels:
data transfers over the SD channel are carried out using only the capacity which
is not in use by the ATD channel. The SD channel capacity is, therefore, not fixed
but can exhibit wide temporal and spatial variations depending on the usage on the
ATD channel. This means that by itself the SD channel data sessions may not only
experience wide throughput variations but also suffer from periods of interruptions
when no capacity is available. In a modified form, some minimum capacity may be
reserved for SD sessions, thereby partitioning network capacity between the SD and
the ATD channels. In the rest of the chapter, we mostly focus on the priority-based
approach and where needed point out the extensions for the capacity partitioning
approach.
Even with time shifting, the network can quickly become unusable if the traffic
load shifted from the peak gets concentrated to create new peaks. If this happens,
then the pricing mechanisms will not be very effective in fully exploiting the avail-
able spare capacity in the network. PLUTUS solves this problem by load balancing
the traffic on the SD channel and by caching the transferred data in the local cache thus
avoiding loading the network at the time of consumption. Load balancing is managed
using an efficient delay and interruption-tolerant protocol and via special proxies that
tightly schedule the transfer of data over the SD channel. This scheduling also mini-
mizes the amount of time the sessions are kept radio active. This reduces the battery
drain on the users‚Äô device and network resources unnecessarily during the transfers.
In addition, because data is routed via proxies, it can be closely tracked, identified,
(de)prioritized, and differentially charged by the network.
The pricing mechanisms considered in this chapter bear close resemblance to
the Paris Metro Pricing (PMP) proposal [16] that uses price differentiation. As in
PLUTUS, the basic idea in PMP is to partition the network into separate logical chan-
nels such that user is charged different prices for using them. The rationale being
that the channels with higher prices would stay less congested than those with lower
prices, thus providing a better service. PMP‚Äôs mechanisms for creating logical chan-
nels include fixed partitioning of network capacity among channels or giving higher
priority to traffic carried over higher priced channels. The biggest advantage of PMP
comes from its simplicity. However, PMP is not without its challenges [16]. This
is especially so when PMP is used as a mechanism for flattening the peaks and for
encouraging the use of spare capacity in mobile networks. First and foremost, the
adoption of an approach such as PMP may be limited if the users are not satisfied with
the even lower quality of service (QoS) for the lower priced channels especially in
mobile networks where the capacity is already constrained. Second, such an approach
may not be very effective in managing congestion because multimedia content, which
is a significant portion of the mobile traffic, has high QoS requirement and is, there-
fore, not well suited for shifting to lower capacity channels. With PLUTUS, on the
other hand, the quality of experience stays high especially with multimedia content,
because the data is cached and served from local storage. Unlike PLUTUS, PMP does
not include any additional provisions for evenly distributing traffic load. Thus with
PMP, the network channels may quickly become unusable because of traffic getting
concentrated around (new) peak periods. Other issues with PMP [16] are how to set

THE PLUTUS APPROACH
371
prices and allocate capacities for the channels and how to ensure predictable perfor-
mance of the channels. Finally, the interface modification needed for the applications
and network to make use of the different channels is a challenge as well. These chal-
lenges are addressed by PLUTUS as we describe in the following text starting with
how to set discounts for the SD channel.
14.3.1
Pricing Model
One of the biggest challenges faced by service providers in pricing data is how to set
price-based incentives and discounts. There is the fear that highly discounted plans
can end up cannibalizing the premium full price plans ending in lower overall revenue.
On the other hand, if the discounts are not substantial, then they may not be effective
in driving the shift of traffic over to surplus capacity. In this section, we present a
pricing scheme for which the service provider revenue can only increase no matter
how heavily the discounted plans are subscribed. This is possible with our approach
as the traffic on the SD channel can be very evenly load balanced and, therefore,
any revenue lost from discounts is gained by the stranded capacity that gets released
when the traffic is moved over to the SD channel. In addition, with the tight control
that can be exerted on the data transfer delays in our approach, the right amount of
segregation can be created between the end-users experience on data transfer using
the SD channel versus using the ATD channel. For example, content delivery could
be artificially delayed even when there is spare capacity to make the SD channel less
appealing to users who demand high quality. As pointed out by Odlyzko [16] and
Deneckere and McAfee [24], such segregation mechanisms, which are widely prac-
ticed by many industries (e.g., Couriers, Hi-Tech), can result in stable performance
of the different channels with even load distribution. Furthermore, it has been estab-
lished [24] that such a mechanism when used for price discrimination can be a strict
Pareto improvement: can promote social welfare with strict benefits for all parties
(service providers and users).
As mentioned earlier, the network cost is driven by peak load as new capacity
is added when peak load reaches the current capacity. However, even at peak loads,
the overall network is heavily underutilized. Typically, the peak-to-average-load ratio
P is in the range 3‚Äì4. This implies that the highest average network utilization N is
mostly between 25% and 35% (assuming that capacity exhaust happens at peak loads
corresponding to full 100% network usage). We show that with our pricing scheme,
the spare capacity can be discounted by as much as N percent while maintaining or
increasing the ISP‚Äôs revenues. Therefore, under our scheme, the spare capacity can
be sold at almost one-third the price of any time data in most networks. In reality, the
actual discount offered by the ISP may be less because they would want to set the
discount just enough to maximize the overall revenue. We also show how to compute
this optimal discount under our scheme.
Theorem 14.1
Let the maximum network utilization in the present mode of oper-
ation (without subsidies for off-peak usage) be N percent. Then as long as the price
charged for data transfer on the SD channel is at least N percent of the price charged
for an equivalent any time data plan, the service providers revenue can not go down.

372
SPARE CAPACITY MONETIZATION BY OPPORTUNISTIC CONTENT SCHEDULING
Proof:
Let us assume that in the present mode of operation, the average revenue per user
is R units and there are U users. So the ISP makes a total revenue of UR units with
the peak network load of PU units and average network load of U units. Here P is
the peak-to-average-load ratio, and this is related to the highest average utilization N
percent as N = 100‚àïP.
Now let the ISP offer a surplus capacity plan at S percent discount. Then the frac-
tional discount for using the SD channel is s = S‚àï100. The ISP derives an average
revenue of sR per ‚Äúnonpremium‚Äù user that signs up to use the surplus capacity plan
while they continue to get an average revenue of R from a ‚Äúpremium‚Äù user that stays
on the ATD channel. Let us denote by x(s) and 1 ‚àíx(s) the resulting fractional sizes
of the partition of the users into premium and nonpremium classes, respectively. x(s)
is an indicator of the take rate of the discounted plan: the smaller the x(s), the higher
the popularity of the discount s. Note that it is possible that a user signs up for both
the plans. We can think of such users as representing two logical users, one premium
and the other nonpremium, thus ensuring that these two user classes are disjoint.
The difference between a premium and nonpremium users is that the former con-
tributes P units to the peak load but only contributes 1 unit to the average load and
generates R units of revenue for the ISP. On the other hand, the nonpremium user
contributes l < P units of peak load while contributing 1 unit to the average load and
provides a revenue of sR units. Here l = 0 when using priority-based partitioning (i.e.,
the nonpremium users can use only capacity left over from premium users). We can
assume l = 1 for capacity-based partitioning (i.e., minimum capacity is reserved for
nonpremium users) because it represents even load distribution on the SD channel
(as attained in our scheme) carried over reserved capacity proportional to the average
load of nonpremium users. We start out by assuming l = 1 and show later how our
results extend to l = 0.
Let us consider the point in the evolution of the system under the new pricing
scheme where the total number of users (SD and ATD users) is equal to the number
of users in the system before introducing the new pricing scheme. As can be seen in
the following, it is not required that the system must go through such a state for the
proof to hold but rather is only used to illustrate the impact of the pricing change on
the system parameters (peak load, revenue). The peak load in the network in this state
is, therefore,
Peak load = x(s)UP + (1 ‚àíx(s))U,
(14.1)
and the revenue is
Revenue = x(s)UR + (1 ‚àíx(s))sUR.
(14.2)
Note that this revenue can be lower than before (UR). However, because the peak
has come down, the network now can sustain additional users without capacity expan-
sion. The operator can keep adding new users (premium and nonpremium in the same
ratio as before) till the peak load reaches PU the peak load we started with. Let y(s) be

THE PLUTUS APPROACH
373
the fractional increase in the number of users. That is, the network can now accom-
modate (1 + y(s))U users. From Eq. (14.1), it, therefore, follows
[x(s)P + (1 ‚àíx(s))](1 + y(s))U = UP.
(14.3)
From Eq. (14.2), it, therefore, follows that for the combined revenue from all these
users to be no less than the original revenue without subsidies, we must have
[x(s) + (1 ‚àíx(s))s](1 + y(s))UR >= UR.
(14.4)
From Eqs. (14.3) and (14.4), we can infer that as long as s >= 1‚àïP = N‚àï100, Eq.
(14.4) holds for all 0 ‚â§x(s) ‚â§1. This means that as long as the SD channel price is at
least N percentage of the ATD channel the ISP‚Äôs revenue can only go up irrespective
of the take rate of the discounted plan (i.e., the value x(s)).
In the l = 0 (priority-based partitioning), the nonpremium users do not contribute
to the peak load, and hence, Eq. (14.3) for the maximum off-peak load (both pre-
mium and nonpremium users contribute equally to the average network utilization)
is changed to
[x(s) + (1 ‚àíx(s))](1 + y(s))U ‚â§UP or 1 + y(s) ‚â§P
(14.5)
along with an additional constraint on the peak load owing to premium users alone:
[x(s)P](1 + y(s))U ‚â§UP or (1 + y(s))x(s) ‚â§1,
(14.6)
with at least one of these two constraints holding tight at optimality. It can be seen that
even for l = 0 at s >= 1‚àïP = N‚àï100, the inequality (14.4) holds for all possible 0 ‚â§
x(s) ‚â§1 implying the ISP revenue can only increase. In particular, the ISP revenue is
strictly higher unless there are no premium users (i.e., x(s) = 0) at the selected value
of s.
‚óæ
Corollary 14.1
For our scheme, the optimal ISP revenue is obtained by maxi-
mizing a function that depends on the popularity of the subsidized plan and the
peak-to-average-load ratio P (before subsidized plan is offered).
Proof: We only consider l = 1 because the other case is similarly handled. From the
proof of Theorem 14.1, it follows that the ISP‚Äôs revenue maximization problem is
max ùõº[X1(s) + X2(s)s]
such that
ùõº
[
X1(s) + X2(s)
P
]
= 1
and
1
P ‚â§s ‚â§1,

374
SPARE CAPACITY MONETIZATION BY OPPORTUNISTIC CONTENT SCHEDULING
where at fractional discount s for SD channel, the ISP has X1(s) premium and X2(s)
nonpremium users. As before, this is a logical partitioning of users into disjoint sets.
The functions X1(s) and X2(s) depend very much on inherent value the users derive
from a given discount s versus their experience on each of the two channels. As such
user surveys, focus groups, and other means may be employed to estimate these func-
tions. The parameter ùõºrepresents the additional users that can be accommodated and
can be determined based on the value of the functions X1(s) and X2(s). Once these
functions are determined, the optimal fractional discount s can be derived by solving
the optimization problem.
‚óæ
So far we assumed a single pricing tier for each of the premium and nonpremium
class. In practice, pricing plans may offer multiple tiers (e.g., monthly data bundle
of 5 GB for $50 or 3 GB for $30, etc.) and users may have many possible ways of
adopting new pricing plans such as by moving from a higher to a lower tier of the
premium class and making up for the reduced data bundle by supplementing with a
nonpremium pricing plan tier. The analysis presented above can also be extended to
this more general case; however, we omit the details for lack of space.
The pricing plan presented above can also be offered in a ‚Äúbundled‚Äù mode where
instead of offering new surplus capacity plans, the ISP may just increase the amount
of data provided to the user at a slightly higher cost. The additional data would be
allowed only at off-peak times (over the SD channel). The analysis presented above
directly applies to this case by virtue of the logical partitioning of each user into the
premium and the nonpremium classes.
14.3.1.1
Other Scenarios
14.3.1.1.1
Network Efficiency Enhancements Without Pricing Plan Changes With
our SD-channel-based delivery approach, network peaks can also be flattened and
the user experience enhanced by anticipating, delivering, and locally caching data
in advance of usage. This can even be accomplished without price-based incentives
as long as there are effective mechanisms for predicting user behavior. Although no
prediction mechanism is perfect and, therefore, much of the data preloaded into the
local cache may get wasted and not be consumed, this is not a significant problem
because the marginal cost of delivering data using spare capacity is negligible. Note
that in such a mode of operation, no user behavior change is required (adoption of new
pricing schemes or delayed data consumption) and the user may even be oblivious to
any such preloading and caching of data.
14.3.1.1.2
Sender-Pays or Two-Sided Pricing The approach described here can
easily accommodate pricing schemes where the content provider is charged for all
or portion of the content delivery. Such pricing models have been tried in the past
(e-book delivery for Kindle) and are being considered as an equivalent of toll-free
service for data traffic. For such pricing mechanisms to be appealing to the content
providers, the delivery costs especially for large multimedia files (movies, shows)
should be fairly low. This is possible when the content is delivered using surplus

ARCHITECTURE AND DESIGN
375
network capacity because it has negligible marginal cost. With this approach, the
additional benefit is predictable delivery estimates and higher quality playback expe-
rience as the content is cached locally on the users device [potentially with digital
rights management (DRM) and access controls for premium content]. Also with
PLUTUS, the charging can be simple as the content provider can simply pay accord-
ing to the size of the delivered data and PLUTUS can ensure that the users data plan
is not charged for the bytes delivered on the SD channel. This addresses many of the
issues with sender-pays plans [25].
14.4
ARCHITECTURE AND DESIGN
There can be wide variations in the SD channel capacity, and therefore, it may not
be well suited for session-oriented protocols such as Transmission Control Protocol
(TCP) that time out or exhibit poor performance under impairments. Moreover, keep-
ing the sessions ‚Äúalive‚Äù for long periods of time can drain the handset battery quickly
and also unnecessarily tie up limited radio resources (e.g., traffic channels). There-
fore, the implementation of SD channel requires more than just strictly prioritizing
the ATD channel data packets over SD channel packets in the network routers and
switches and RAN elements. The end applications that use the SD channel need to
be resilient to session interruptions and must be capable of relaunching sessions after
capacity becomes available again. Also the network must be able to convey capacity
availability to the applications that must always stay ready in standby mode to be able
to avail of this capacity. The system could, therefore, get complex if each application
and the network were to be modified to work this way. A more scalable approach is to
enhance the network to provide most of these features, thus minimizing the impact on
individual applications. This motivates our design for PLUTUS system whose main
components are shown in Figure 14.1.
The Control and Scheduling Components (CSC) track and control all the data
transfers on the SD channel. These data transfers are routed via proxy components
[Server Proxy Components (SPC) and Client Proxy Component (CPC)] that can
Webserver/CDN
Data path
Control
3G / 4G / Femto / WiFi
CSC
CSC
AC
AC
API
CMC
CCM
CPC
CCC
SMC
SPC
SCC
PLUTUS
server
PLUTUS
client
Mobile handset
Application
CSC: Control and Scheduling Comp.
AC: Admin Comp.
SMC: Server Monitoring Comp.
CMC: Client Monitoring Comp.
SPC: Server Proxy Comp.
CPC: Client Proxy Comp.
SCC: Server Caching Comp.
CCC: Client Caching Comp.
CCM: Client Connection Manager
API: Application Interface
Figure 14.1
Architecture of the PLUTUS system.

376
SPARE CAPACITY MONETIZATION BY OPPORTUNISTIC CONTENT SCHEDULING
suspend or resume data transfers as needed. The Server Monitoring Component
(SMC) and Client Monitoring Component (CMC) together track the network state
including the availability of capacity on the SD channel, the availability of other
network accesses (e.g., WiFi, Femto), and also the user‚Äôs radio link state and device
state (battery, storage). The information on alternative network availability is used
by the PLUTUS Client Connection Manager component (CCM) for automatically
switching over data transfers to the best network. Owing to the possibility of long
interruptions, the SD channel data sessions operate mostly in the background
with data caching performed by the Server Caching Component (SCC) and Client
Caching Component (CCC). PLUTUS exposes application programming interfaces
(APIs) for applications to initiate data transfers over the SD channel as well as for
getting notifications on the status of data transfer and for accessing their transferred
data from the PLUTUS caches. The PLUTUS system has additional Admin Com-
ponents (AC) for accounting and charging of data transferred over SD channels
and for provisioning of operator policies and user preferences for controlling
the data transfer process. We describe all these components in the following in
detail.
14.4.1
Components
14.4.1.1
The Scheduling component The CSC is responsible for computing esti-
mates on delays for data transfers on the SD channel and also for scheduling the data
transfers within the estimated delays. Using historic data to predict anticipated user
and network dynamics, the CSC constructs a globally efficient, low delay, data trans-
fer schedule. Data transfers are then instrumented according to this schedule with
changes applied based on the actual system dynamics.
First, the amount of capacity predicted to be available on the SD channel of each
cell in each time period along with the predicted availability of the access points
(e.g., cells, WiFi, small cells) to each device during each time period is computed.
This is based on the past and current trends on network and device availability, user
mobility, device usage, traffic load, etc. Each data transfer job is then characterized
by the deadline by which it needs to finish (its delay estimate), the outstanding data
to be transferred (size), and the set of other jobs that must be processed before it
(e.g., based on a ordering specified by the user or their submission time). Next a
global scheduling problem is solved for assigning the (pre-emptive) processing of
the data transfer jobs on selected access points at times when the SD channel of
the access points is predicted to be available to the respective jobs. It is accept-
able to schedule a single data transfer job over several nonconsecutive times or dif-
ferent accesses. The objective is to complete jobs by their deadline such that all
the job ordering constraints are enforced. The solution to the scheduling problem
is the temporal assignments of jobs and portions thereof to the access points and
the rates for the underlying data transfer. The solution to the scheduling problem
also provides data transfer delay estimates in the case when a priori deadlines are
not given.

ARCHITECTURE AND DESIGN
377
We now show how to mathematically model and solve this scheduling problem.
We assume that the scheduling is performed at the granularity of time slots each of
which is ùúèseconds long. In other words, the deadlines for job completion have to
be at the granularity of ùúèso either a job can be scheduled in this time slot or not.
The choice for ùúèdepends on whether we want the schedule to be more flexible in
adapting to dynamic changes (ùúèshould be small) or we want to reduce the overhead
of recomputing the schedule more frequently (ùúèshould be large). In practice, ùúè= 1
second can provide a good trade-off for these two requirements.
Let A denote the set of access points (e.g., cells, WiFi, small cells). For an access
point a ‚ààA, let I(a) denote the set of time slots when it is predicted to be available. Let
ca(i) denote the available capacity in bytes of access point a ‚ààA in time slot i ‚ààI(a).
Thus ca(i) is ùúètimes the average available rate of access point a in time slot i. Let U be
the set of users, and let J(u) be the list of jobs j1(u), j2(u), ‚Ä¶ of user u ‚ààU arranged
in the order in which they need to be processed. Each job jk(u) is characterized by its
size sk(u) in bytes, its arrival time ak(u), and its deadline dk(u). Let au(t) denote the
preferred access point a ‚ààA of user u among the access points that are available to
user u ‚ààU at time slot t. Note that au(t) is not defined if user u is not in proximity
of any available access point. In case there are multiple such access point, then we
assume that there is a mechanism to pick the preferred one (e.g., prefer WiFi to 3G).
The schedule is determined by solving a max-flow problem in a graph constructed
as follows. The graph has four types of nodes: user nodes (V1), one per user u ‚ààU;
job nodes (V2), which are one for each job for each user,
‚à™u‚ààU{ji(u)|ji(u) is in list J(u)};
available time slot nodes (V3) one per access point and time slot in which it is
available
‚à™a‚ààAI(a);
and a pair of source and sink nodes s and t, respectively. In this graph, the edges and
their capacities are as follows. From the source node s, there is a directed edge to
each of the nodes in V1 of infinite capacity. From a node v1 ‚ààV1 that corresponds to
user u, there is a directed edge to every node v2 ‚ààV2 that corresponds to the job jk(u)
for user u. This edge has capacity set to the size sk(u) of job jk(u). From every node
v2 ‚ààV2 that corresponds to the job jk(u) for user u, there is a directed edge to every
time slot node v3 ‚ààV3, which has the following properties. The time slot i corre-
sponding to v3 must be in the time interval (ak(u), dk(u)) in which the job is available
to be processed. The node v3 must correspond to the access point au(i) that is avail-
able to user u in time slot i. The capacity of this edge is set to ca(i) corresponding to
the available capacity of access point a in time slot i. Finally, there is a directed edge
from every time slot node v3 ‚ààV3, which corresponds to time slot i and access point
a, to the sink node t of capacity ca(i). It can be seen that a feasible flow from s to t
in this graph corresponds to a schedule that satisfies all constraints except possibly
the constraint on the ordering among the jobs of a user. However, the latter can be

378
SPARE CAPACITY MONETIZATION BY OPPORTUNISTIC CONTENT SCHEDULING
easily attained by rearranging the schedule individually for each user so that the jobs
are scheduled in the desired order on the set of access points and time slots deter-
mined using flow computation. The max-flow in this graph corresponds to a schedule
that maximizes the total amount of processing of the jobs, and in particular, it can
be used to test feasibility of processing all jobs. Other objective functions (besides
maximizing the total flow) can also be used to enforce additional requirements (e.g.,
fairness).
The scheduling problem as defined can be solved using linear programming tech-
niques but can quickly become intractable even for medium size networks with a
few millions of users. However, we believe that fast heuristics with bounded perfor-
mance should be possible under practical assumptions. Additional constraints may be
introduced in the problem formulation for a more efficient schedule. These include
constraints to minimize the delay for data transfers. It may also include constraints
to avoid high signaling load on the network and high device battery drain because of
frequent job interruptions (e.g., because of pre-emptions, lack of capacity, network
switchovers) resulting in inefficient traversals between different radio states [26]. In
addition, constraints may also be introduced to take advantage of the spectral efficient
wireless broadcast and multicast capacity if available for data transfers. This involves
identifying overlaps across different users jobs that can be scheduled together using
multicast [27].
This ‚Äúoffline‚Äù solution to the scheduling problem serves as a guide for the ‚Äúonline‚Äù
scheduling of the data transfers. It provides the necessary input to make the decision
as to when to start, suspend, and resume each of the data transfer and at what rate.
As the offline solution is based on predictions regarding the availability of capacity at
the access points, mobility of the user, and the parameters of the currently submitted
data transfer jobs (sizes, deadlines,) it can quickly become suboptimal unless it is
dynamically updated to deal with the occasional deviations in user actions, mobility,
network conditions, and unanticipated traffic loads. In addition, the schedule must be
dynamically updated to accommodate new data transfer jobs. Most of the times, it
should be possible to handle these changes efficiently locally with only incremental
updates thus requiring very infrequent computationally intensive recomputations of
the schedule.
Online scheduling optimizations in PLUTUS also include adjusting the schedule
including the job priorities to give more opportunities to data transfers that have fallen
behind or at times when they can make more efficient use of network resources (e.g.,
when radio link is of higher quality), thus increasing the network efficiency. An addi-
tional consideration is to keep the SD sessions radio active for the least amount of
time in order to minimize battery drain and to avoid tying up scarce RAN resources.
By scheduling data transfers, which share limited capacity (e.g., within one cell), one
at a time rather than all at the same time, the CSC not only lowers the average transfer
time but also reduces the average time spent in radio active state. The benefit of serial
over parallel data transfer scheduling within a single cell is illustrated in Figure 14.2.
When all three data transfers are scheduled together (as in Fig. 14.2a), they all take
a long time to finish because each one gets only one-third of the cell‚Äôs capacity and,

ARCHITECTURE AND DESIGN
379
1
(a)
(b)
1
2
2
3
3
Figure 14.2
Serial scheduling is more efficient. (a) Parallel data transfer and (b) serial data
transfer.
therefore, also stays active for the whole time. When scheduled one at a time (as
in Fig. 14.2b), they all still finish within the same time period. However, some data
transfers finish earlier (1 and 2), and more importantly, each of them stay active only
one-third of the time. More generally, the CSC scheduler not only schedules a few
data transfers at any given time but also pre-empts and switches data transfers in order
to make fair progress across all of them. Such fairness is required to gain the trust of
the end users possibly by also putting a neutral entity in charge of overseeing the
scheduling operations.
14.4.1.2
The Proxy components and the Data Transfer Protocol In PLUTUS, the
SD channel application‚Äôs data session is proxied via the CPC that runs in the back-
ground on the client side and is optionally proxied via the network-resident SPC.
The session data flow for a download involving both the CPC and the SPC is illus-
trated in Figure 14.1. Upload works in the same way and is, therefore, not described.
The download can have two logical phases. In the first phase, data is downloaded by
the SPC from the data source in the network and temporarily cached in the server
cache SCC. In the second phase, the data cached in the SCC is downloaded by the
CPC to the client cache CCC using the disruption-tolerant data transfer (DTDT) pro-
tocol running between the SPC and CPC. The second phase does not have to wait
for the first phase to finish but rather the download to the client may start as soon
as the data is available on the server cache. The DTDT takes care of suspending or
resuming content transfer and stopping or restarting sessions in reaction to schedul-
ing controls from the CSC. The DTDT can be implemented using any standard data
transfer protocol (e.g., TCP) when enhanced with the additional capability of auto-
matically stopping and starting data connections and rate limiting. All the state about
how much data is transferred and where to resume data transfer from is maintained
by the CPC because it has that information. The SPC component is not required if
(for download) the data source server is capable of resuming the data transfer from
any specified offset. Such capability is widely supported by http downloads from web
servers on the World Wide Web. In such cases, the CPC makes the request to the data
source server to resume the data transfer from the position where it terminated the last
time (e.g., via range request for http downloads). This is, therefore, well suited for
multimedia content because commonly used protocols such as progressive download
and adaptive bitrate streaming are all based on http download. The preferred mode
of operation for the PLUTUS system is to avoid proxying all the data transfers via a
SPC as it results in a more distributed and scalable architecture.

380
SPARE CAPACITY MONETIZATION BY OPPORTUNISTIC CONTENT SCHEDULING
14.4.1.3
The Monitoring and Data collection component The CMC and the SMC
together monitor the surplus capacity of the network. Note that it is not just sufficient
to use network-based QoS mechanisms to prioritize ATD traffic over SD traffic. Mon-
itoring is needed to identify opportune times when SD channel data transfers can be
started, otherwise data transfers must be kept alive all the time with serious impact
on battery life and network performance. In PLUTUS the focus is mostly on RAN
and in particular on cell level (per radio link) monitoring. Typical monitoring systems
make the assumption that the available capacity can be determined as the difference
of the capacity of the bottlenecked link to the offered load. However, in a mobile net-
work, this is not always the case because the capacity of the radio link is very much
dependent on the channel quality of the users and, hence, can be time varying. Thus
even though the observed load on the cell may be low, the cell may still not have any
capacity left over. Therefore, a monitoring solution has to measure the cell load in
conjunction with the users channel quality. On the network side, such monitoring is
best done from the cells base transceiver station (BTS) where both the users channel
quality and the allocated BTS resource usage can be monitored. This results in more
accurate monitoring but can be a challenge to deploy because of (i) the significant
cost and challenge of upgrading all the BTSs many with proprietary interfaces, (ii)
the additional cell (e.g., backhaul) overhead to send monitored data from the BTSs
to the PLUTUS system, and (iii) the resulting high delays in informing the PLUTUS
clients of the changes in network load thus slowing their reaction time.
On the client side, a combination of active and passive probing techniques can
be used for monitoring local conditions such as the users channel quality as well for
estimating global network state including cell congestion. Network availability is
accurately estimated by passively monitoring the radio channel slot occupancy [28].
However, this can be challenging because it requires access to proprietary
vendor-specific APIs for the radio modem of the device. Active probing, on the other
hand, involves sending probe packets to estimate the available bandwidth and, there-
fore, is mostly independent of the device firmware, hardware, operating system, and
so on. The challenge with active probing, however, is the additional signaling and data
overhead it can introduce. We describe in Section 14.4.2 how active-probing-based
client-side monitoring of available capacity is implemented in PLUTUS.
In addition to tracking the user and network state, the CMC monitors the device
state including battery level, charging status, storage usage, processor occupancy, and
so on. This is to ensure that device resource usage is according to user preferences
and settings (e.g., SD channel data transfers only when battery level is high or the
handset is getting charged). Data is also collected by the CMC on the availability of
other networks (WiFi, small cells) so that data transfers can be moved to the least cost
network. Data may also be collected by the CMC on the users network and content
access and mobility patterns. This may include data on the locations much frequented
by the user, the types of networks available there, their loading state, and their prob-
ability of being used by the user. Such historic data can be a sufficiently accurate
predictor of the future [2, 29, 30] and, therefore, helps in deciding when and where to
schedule users data transfers on the SD channel. Likewise data collected on the users
content access patterns helps to predict contents of interest that can be preloaded in

ARCHITECTURE AND DESIGN
381
advance of users request. Although there can be privacy concerns related to the col-
lection of such personal data, these may be ameliorated by opt-out and anonymization
mechanisms [31].
14.4.1.4
The Admin component As transferring large files may not just incur sig-
nificant cost to the user but may also result in substantial battery drain and quickly
fill up the storage on their device, PLUTUS lets the user set preferences via the AC to
control the transfer process. This may include allowing content transfer only above
certain battery levels or only during charging periods or only when there is enough
storage on the device. It may also include preferring the use of their home WiFi
and requiring automatic switchover to make use of a preferred access network when
available. Likewise the operator may configure policies to block data transfers during
certain time periods or may allow the use of their managed WiFi hotspots. In order
to enforce these preferences and policies, PLUTUS closely tracks the network and
device state including the availability of network accesses.
The AC also interfaces with policy and charging functions (e.g., PCRF) in the
network to convey session information (e.g., TCP connection‚Äôs 5 tuple) for every
data transfer over the SD channel. This helps the network gateways to identify, clas-
sify, differentially account, and charge all the packets belonging to the SD channel
traffic.
14.4.1.5
The Application, User Interfacing component Applications interface
via the PLUTUS APIs to request data transfer on the SD channel. The request may
be triggered from a direct user action where the user explicitly selects a digital item
to be delivered via their SD channel data plan. The request may also be triggered by
an indirect user action where the user has allowed the application to automatically
deliver data items that become available on their social networks, subscribed
channels, playlists, video queues, camera folder and so on. The data transfer is
then routed via the SD proxies and is scheduled for delivery by the CSC using the
DTDT protocol. The PLUTUS APIs provide delivery state updates to the application
including when the data item is available for use. Delivered item is cached locally
and is accessed by the application using PLUTUS APIs.
14.4.1.6
The Prediction and Preloading Component The PLUTUS system is ide-
ally suited for preloading content on users device in advance of consumption. An
important challenge, however, is to be able to deliver content that has the greatest
chance of being consumed by the user. However, more and more traffic on the mobile
network is from recommendation-based content. This includes much of the usage
on Pandora, Netflix, and even Youtube [32], three of the biggest source for mobile
data traffic [4]. In addition, social-network-based recommendations can play a big
role in this preloading as Facebook, Twitter, and other social networks are becom-
ing a significant source of referrals [33] especially for video content [34]. This is in
addition to subscription-based preloading of content from media channels, playlists,
movie queues, watch it later applications, magazines, news web sites, and so on. The
best delivery options for preloading popular content may be mobile multicast and

382
SPARE CAPACITY MONETIZATION BY OPPORTUNISTIC CONTENT SCHEDULING
broadcast. Thus a combination of unicast and multicast may be used for preloading
content [27].
14.4.2
Client-Side Monitoring of Available Capacity
PLUTUS uses an active probing mechanism whereby traffic is occasionally down-
loaded by the client to allow it to sample the available bandwidth [18] on the SD
channel. One of the parameters that the client measures is the download through-
put. However, throughput by itself is not enough to estimate the available capacity.
This is because in wireless networks, the throughput depends not only on the avail-
able capacity but also on the maximum cell capacity (which can vary from cell to
cell based on its technology, frequency, number of carriers, etc.) and clients channel
quality. In particular, even with only one client on the cell, the download throughput
may be low if the client has poor channel quality. In addition, the throughput also
depends on the number of users or level of sharing in the cell. This is because the
base station or eNodeB uses proportionally fair scheduling to divide radio resources
fairly and evenly between all active users attached to a cell.
The estimation of the available capacity by the client proceeds as follows. First, by
correlating historic data about channel conditions, as measured by parameters such as
signal-to-noise ratio (SNR) and received signal strength indication (RSSI) with user
throughput, PLUTUS computes the maximum cell capacity for each channel condi-
tion. This is performed separately for each cell. Then in real time, the client measures
the download throughput and simultaneously evaluates its channel conditions over a
sequence of time windows. Each of these time windows is short enough that within
each of these windows, either there is no (ATD channel) data transfer from any other
user or the cell capacity is fully utilized from such data transfers. Thus in these time
windows, a PLUTUS client gets 1/n-th of the maximum cell throughput, that is pos-
sible for the given channel condition. Here n is the number of cell users active during
the time window, inclusive of this client. This is illustrated in Figure 14.3.
Let the client observe throughput B0, B1, ‚Ä¶ , Bk over a time period defined by a
sequence of time windows t0, t1, ‚Ä¶ , tk. Let the max channel capacity in these time
windows (as estimated by channel quality measurements) be C1, C2, ‚Ä¶ , Ck. Then
the average available capacity over this time period spanning these k time windows is
estimated as l‚àïk, where l ‚â§k is the number of time windows in which the throughput
exceeds half the cells max capacity: those time windows ti for which Bi > Ci‚àï2. This
is because in such time windows, there is no other active user, otherwise the through-
put would be at most Ci‚àï2. This fraction is then compared to a cell-specific capacity
threshold ùúè. Only if the fraction is not less than ùúè, the cells available capacity can be
utilized for SD channel data transfers in the subsequent time period.
Usually, the active probing as described earlier operates independent of client‚Äôs
data transfers. However, in PLUTUS, the two are combined. The PLUTUS proxy
components monitor the capacity availability as it is transferring users data. In other
words, no special data transfers are needed for active probing, thus eliminating the
overheads. The only exception is when there is no available capacity on the cell
and, hence, the users data transfers are kept suspended. In that case, there is some

PERFORMANCE EVALUATION
383
Mbps
T1 = C1/2
T2 = C2
T3 = C3/3
C3
n1=2
t1
t2
t3
Time (Seconds)
C = Max cell capacity
T = Client throughput
n = Number of active users
(including probing client)
n2=1
n3=3
C1
Figure 14.3
Active probing throughput in three time windows.
impact on the data transfers on the ATD channel by the active probing for SD channel
capacity. However, this is minimized by appropriately spacing out the active probing
activities while still ensuring that capacity availability can be detected in a timely
manner. Further optimizations include scheduling probing activities across clients
within a cell to ensure that only a small number of clients are actively probing in
the cell at any given time. The selection of clients for active probing within each
cell is dynamically adjusted to keep the probing load spread across the clients, thus
minimizing their battery drain from probing.
14.5
PERFORMANCE EVALUATION
We implemented the PLUTUS system with client software running on Android and
iOS handsets and other control and server software resident in the network. Here
we present some results from analyzing the performance of PLUTUS on a commer-
cial network for which data was collected using a tool developed internally. The data
includes network load and other information for a day from more than 5000 3G cell
sites. We also present results on the performance of the PLUTUS system in the con-
trolled laboratory environment of mobile operators.
14.5.1
Network Utilization
The traditional understanding is that during peak hours the network is very heavily
loaded and there is not much spare capacity during those times. As a result, most
solutions for utilizing spare capacity are primarily designed to look for spare capacity
during ‚Äúoff-peak‚Äù hours. However, we found that this view is not accurate and even
busy cell sites can exhibit many short periods of network availability even during
peak hours. This effect is particularly pronounced when the network load is analyzed
at the smaller time granularity of minutes. As a result, we have designed PLUTUS to
quickly identify and react to availability of spare capacity even at these short intervals
thus maximizing the efficiency gains.

384
SPARE CAPACITY MONETIZATION BY OPPORTUNISTIC CONTENT SCHEDULING
24
A
B
C D
0
0
15
16
17
18
19
20,000
40,000
60,000
80,000
100,000
120,000
Down usage (KB)
1
Hour
Hour
Downlink usage per hour
Down usage (in 2 min) for peak hours 15‚Äì19
2
3
4
5
6
7
8
9
10 11 12 13 14 15 16 17 18 19 20 21 22 23
500,000
1,000,000
1,500,000
2,000,000
Down usage (KB)
Figure 14.4
Network load.
Figure 14.4 shows the typical load of a congested cell. The top graph shows the
hourly distribution of load where hours 15‚Äì19 are seen to be the most loaded and can
be identified as peak hours. However, as we drill down to 2-min data intervals for the
peak hours, it is clearly seen that there are many time intervals where the network
load is quite low, for example, between peaks at A,B and C,D, and this spare capacity
can be leveraged for data transfers on the SD channel even during peak hours. The
PLUTUS system‚Äôs capability to detect spare capacity even in peak periods not only
enables it to maximize the utilization gains but also helps it to reduce the wait time
for SD data session, making it more attractive to the user.
14.5.2
Delay
In PLUTUS, the SD channel data sessions have a lower priority than the ATD sessions
and, hence, can incur additional delays as they are waiting for capacity to become
available. We used the network load data from top 200 loaded cells of the aforemen-
tioned 3G network, to analyze the delay introduced by using the SD channel instead
of the ATD channel. We used the current network load as baseline and introduced
new data sessions of different sizes. The comparison was done for equal number of
SD and ATD sessions over a 24-h period. However, the number of sessions varied
in proportion to the existing load on the system at a given time to reflect higher user
activity at busy times compared to nonbusy times. To compute delay, we compare

PERFORMANCE EVALUATION
385
the time difference between completing the new data session on an ATD versus SD
channel.
The 200 cells used for this analysis have an average utilization of 35%. Although
we do not have any data on how close these cells are to exhausting their capacity
but given that these are the top loaded cells for a heavily utilized network, we can
reasonably assume that their peak-to-load ratio is close to 3.
In our analysis, we allow the SD channel to use available capacity from the net-
work only if the total load on the network at that time is 70% of the network capacity.
If the network load is higher, the network is considered as congested and only ATD
traffic is allowed. As seen in Figure 14.5, almost 87% of the smallest (10 MB) SD
channel data sessions incur no additional delay compared to equivalent ATD channel
data sessions. Also 65% of large data sessions (500 MB) incur no additional delays.
In this network with maximum throughput of 60 MB/min, the available throughput at
average network utilization of 35% is 39 MB/min. Therefore, a 500-MB ATD session
can take approximately 13 min to finish while only 12% of equivalent SD sessions
incur additional delays of 4 min or more. This means that 88% of 500-MB SD ses-
sions incur no more than 30% additional delay. Also more than 80% of small and
medium sized sessions incur no additional delay at all. The relatively short delay on
the SD channel is due to the availability of enough intermittent network capacity even
during peak periods as was shown in the previous section. In addition, during peak
periods, because an ATD session gets additional service (compared to an equivalent
SD session) only at times when the network is highly loaded (70% or more), it cannot
finish much faster.
We analyzed the delay performance of PLUTUS in a laboratory environment under
different congestion conditions. In particular, we considered two scenarios where net-
work is congested either 20% or 50% of the time. In this laboratory, the maximum
throughput of the clients ranged between 500 and 600 Kbps. As shown in Figure 14.6,
when network is congested 20% of the time, there is an additional SD channel delay
of less than a minute for a download of 63 MB data that takes 20 min on the ATD
0
0
10 MB
100 MB
500 MB
2
4
6
8
10
10+
Delay (min)
Demands Vs delay : threshold = 70%
10
20
30
40
50
60
70
80
90
100
Demands (%)
Figure 14.5
SD channel additional delay.

386
SPARE CAPACITY MONETIZATION BY OPPORTUNISTIC CONTENT SCHEDULING
Delay Performance
Congestion = 20%
Congestion = 50%
Data downloaded on ATD
channel in 20 min
Additional delay on SD channel
(in minutes)
62.9 MB
0.89
44.94 MB
3.762
Figure 14.6
SD channel delay versus congestion.
channel. Even for networks with 50% congestion when the SD channel has spare
capacity only half the time, a user download of 45 MB that takes over 20 min, sees
an additional delay of just 3.7 min or 18%. As in most networks the peak period is
less than 50%, it follows that the users will see very short additional delays between
sessions on ATD and SD channel. Moreover, although an ATD session would stay
active 100% of the time during the download, the SD session would be active only
68% of the time, 50% of the time when network is not congested and an additional
18% because of the delay. As SD sessions are active for a shorter duration during the
download the PLUTUS system can not only improve device and battery performance
but also reduce the impact on the network by not tying up precious resources for as
long.
14.5.3
User Experience
In the laboratory environment, we also studied the impact on session quality of users
moving some of their sessions to the subsidized SD channel. Figure 14.7 shows the
network with four peaks created by ATD session activity. The grey curve depicts the
0
0
300
600
900
1200
1500
1800
2100
2400
Time (s)
100
200
300
400
500
600
(Bandwidth ‚Äì Mbps)
Avg Thruput ‚Äì 6 ATD sessions
Avg Thruput ‚Äì 3 ATD + 3 SD sessions
xxx
Figure 14.7
User performance.

ACKNOWLEDGMENTS
387
average throughput of six ATD sessions that were active for 5 min and then inactive
for the next 5 min thereby creating a pattern of 5-min long-peak and off-peak peri-
ods. The black curve depicts user throughput as three of the six ATD sessions were
converted into SD sessions so that only three ATD sessions stayed active during peak
times and the activity of the three SD sessions got shifted to off-peak times. As can
be seen that this resulted in the throughput of the individual ATD sessions going up
from 100 Kbps to more than 150 Kbps. This means that the premium ATD users see
less buffering and better quality even during peak times. The ATD sessions that got
time shifted as SD sessions to off-peak periods got even better average throughput
of more than 250 Kbps. This is because the PLUTUS system scheduled at most two
SD sessions simultaneously in order to avoid creating new peaks and to reduce the
length of time that SD sessions are active. Thus with PLUTUS spreading out the load
more evenly in the network, it results in improved device throughput across the board,
thereby increasing user satisfaction.
14.6
CONCLUSIONS AND FUTURE WORK
In this chapter, we presented a capacity monetization and network efficiency enhance-
ment PLUTUS system for efficiently and cost-effectively delivering multimedia con-
tent using unused capacity of diverse access networks. It works by scheduling the
data transfers at the appropriate times using the appropriate access networks and by
caching data on the large storage on end devices. We showed that with PLUTUS the
operators revenue increase can be ensured using only simple and predictable pricing
plans. We addressed the many challenges of designing the scheduling and monitor-
ing components of the PLUTUS system. We also presented the initial results on the
viability along with the efficiency gains from deploying the PLUTUS system both in
commercial and in laboratory environments.
Future research directions include creating improved models for predictions of the
network state and user behavior based on the data collected by the PLUTUS clients.
Linear-programming-based approach to model and solve the basic scheduling prob-
lem can be quite powerful but can also be computationally intensive. Future research
directions include the design of faster heuristics with bounded performance guar-
antees that can also flexibly accommodate the various constraints of the scheduling
problem. Future work also includes personalized recommendation systems that can
maximize the ‚Äúhit‚Äù ratio while balancing the limits on the network capacity for deliv-
ering content along with the storage on users device for preloading content.
ACKNOWLEDGMENTS
We thank the entire Kaveri team at Alcatel-Lucent Ventures for their contributions to
the PLUTUS system.

388
SPARE CAPACITY MONETIZATION BY OPPORTUNISTIC CONTENT SCHEDULING
REFERENCES
1. Cisco. Cisco visual networking index: global mobile data traffic forecast, 2011-2016.
2. U. Paul, A. P. Subramanian, M. M. Buddhikot, and S. R. Das. Understanding traffic dynam-
ics in cellular data networks. In Proceedings IEEE INFOCOM, 2011
3. M. El-Sayed, A. Mukhopadhyay, C. Urrutia-Vald√©s, and Z. J. Zhao. Mobile data explosion:
monetizing the opportunity through dynamic policies and QoS pipes. Bell Labs Technical
Journal, 16(2), 2011, 79‚Äì100.
4. Sandvine. Global Internet Phenonomena Report 1H 2012. Available at: http://www.
sandvine.com/downloads/documents/Phenomena_1H_2012/Sandvine_Global_Internet_
Phenomena_Report_1H_2012.pdf, 2012.
5. P. Du and N. Lu. Appliance commitment for household load scheduling. IEEE Transac-
tions on SmartGrid, 2(2), 2011, 411‚Äì419.
6. A. H. Mohsenian-Rad, V. W. S. Wong, J. Jatskevich, and R. Schober. Optimal and
Autonomous Incentive-Based Energy Consumption Scheduling Algorithm for Smart Grid.
Innovative Smart Grid Technologies 2010. IEEE, 2010.
7. A. Ingold, I. Yeoman, and U. McMahon. Yield Management: Strategies for the Service
Industries, 2001.
8. K. Lakshminarayanan, V. Padmanabhan, and J. Padhye. Bandwidth estimation in broad-
band access networks. In Proceedings of ACM Internet Measurements Conference,
Taormina, Oct. 2004.
9. D. Koutsonikolas and Y. Charlie Hu. On the feasibility of bandwidth estimation in 1x evdo
networks. In MICNET, 2009.
10. A. Gerber, J. Pang, O. Spatscheck, and S. Venkataraman. Speed testing without speed tests:
estimating achievable download speed from passive measurements. In IMC, 2010.
11. Kevin C. Tofel, Gigaom. ATT ends Flat-rate mobile plans. Available at: http://gigaom.com
/mobile/att-shuts-down-the-mobile-broadband-buffet/2010
12. arstechnica. Verizon confirms the future of 3G data is tiered. Available at: http://arstechn
ica.com/gadgets/2010/09/verizon-confirms-the-future-of-3g-data-is-tiered/2010
13. Stacey Higginbotham, Gigaom. Differential data rates based on Time and Apps. Available
at:
http://gigaom.com/2010/12/14/mobile-operators-want-to-charge-based-on-time-and
-apps/2010
14. MTN.
MTN
provides
free
facebook.
Available
at:
http://www.mtn.co.ug/MTN-
Services/Communication/Facebook.aspx, 2011.
15. H. S. Houthakker. Can Speculators Forcast Prices. The Review of Economics and Statis-
tics, 1957.
16. A. Odlyzko. Paris metro pricing for the Internet. Proceedings of the 1st ACM Conference
on Electronic Commerce, pp. 140‚Äì147, ACM, 1999.
17. S. Sen, S. Ha, C. Joe-Wong, and M. Chiang. Pricing Data: A Look at Past Proposals,
Current Plans, and Future Trends. Available at: http://arxiv.org/abs/1201.4197
18. R. S. Prasad, M. Murray, C. Dovrolis, and K. Claffy. ‚ÄúBandwidth estimation: metrics,
measurement techniques, and tools,‚Äù IEEE Network, 17, 2003, 27‚Äì35.
19. A. Jardosh, K. Ramachandran, K. Almeroth, and E. Belding-Royer. Understanding con-
gestion in IEEE 802.11b wireless networks. In Proceedings of the Internet Measurement
Conference, Oct. 2005.

REFERENCES
389
20. P. Acharya, A. Sharma, E. M. Belding, K. C. Almeroth, and K. Papagiannaki. ‚ÄúRate
adaptation in congested wireless networks through real-time measurements,‚Äù IEEE Trans-
actions on Mobile Computing, 9(11), 2010, 1535‚Äì1550.
21. S. Humair. Yield management for telecommunication networks: defining a new landscape.
PhD Thesis, MIT, 2001.
22. F. Qian, K. S. Quah, J. Huang, J. Erman, A. Gerber, Z. M. Mao, S. Sen, and O. Spatscheck.
Web caching on smartphones: Ideal vs. Reality. In Mobisys, 2012.
23. S. Ha, S. Sen, C. Joe-Wong, Y. Im, and M. Chiang. TUBE: time dependent pricing for
mobile data. In SIGCOMM, 2012.
24. R. J. Deneckere, R. P. McAfee. ‚ÄúDamaged goods,‚Äù Journal of Economics and Management
Strategy, 5(2), 1996, 149‚Äì174.
25. D. Bubley. New Report: 10 Reasons Why the ‚Äútoll-free‚Äù 1-800 Apps Concept Won‚Äôt Work.
Available at: http://disruptivewireless.blogspot.com/2012/07/new-report-10-reasons-why-
toll-free-1.html, 2012.
26. J. Huang, F. Qian, A. Gerber, Z. M. Mao, S. Sen, and O. Spatscheck. A close examination
of performance and power characteristics of 4G LTE networks. In Mobisys, 2012.
27. R. Bhatia, G. Narlikar, I. Rimac, and A. Beck. UNAP: user-centric network-aware push
for mobile content delivery. In IEEE INFOCOM 2009, April 2009.
28. N. Shah, T. Kamakaris, U. Tureli, and M. Buddhikot. Wideband spectrum sensing probe
for distributed measurements in cellular band. In International Workshop on Technology
and Policy for Accessing Spectrum, ACM, vol. 222, Aug. 2006.
29. P. Deshpande, A. Kashyap, C. Sung, and S. R. Das. Predictive methods for improved vehic-
ular WiFi access. In Proceedings MobiSys ‚Äô09, June 2009.
30. A. J. Nicholson and B. D. Noble. BreadCrumbs: forecasting mobile connectivity. In Pro-
ceedings of the Annual International Conference Mobile Computing and Networking
(MobiCom), pp. 46‚Äì57, 2008.
31. C. Shepard, A. Rahmati, C. Tossell, L. Zhong, and P. Kortum. ‚ÄúLiveLab: measuring wire-
less networks and smartphone users in the field,‚Äù ACM SIGMETRICS Performance Eval-
uation Review, 38(3), 2010, 15‚Äì20.
32. R. Zhou, S. Khemmarat, and L. Gao. The impact of YouTube recommendation system on
video views. In Internet Measurement Conference, 2010.
33. Zoe Fox, Mashable Impact of Social Media Referrals. Available at: http://mashable.com
/2012/02/01/pinterest-traffic-study/
34. REELSEO. Facebook is the 2nd Largest Referral Source for Online Video. Available at:
http://www.reelseo.com/facebook-2nd-video/2010
35. S. Sen, J. Yoon, J. Hare, J. Ormont, and S. Banerjee. Can they hear me now?: A case for a
client-assisted approach to monitoring wide-area wireless networks. In Internet Measure-
ment Conference, 2011.


15
Asynchronous Content
Delivery and Pricing in
Cellular Data Networks
VIJAY GABALE, UMAMAHESWARI DEVI, RAVI KOKKU, and
SHIVKUMAR KALYANRAMAN
15.1
INTRODUCTION
Cellular and wireless data traffic have been growing at unprecedented rates over the
past few years. According to the Cisco Visual Networking Index [1], in 2012, mobile
data traffic grew by 70% and was nearly 12 times greater than the total global Internet
traffic seen during the year 2000. This growth trend is expected to continue for at least
another 5 years, with predictions of 66% compound annual growth rate (CAGR) for
mobile data traffic during 2012‚Äì2017. In particular, video constituted half of the total
mobile data during 2012 and is projected to rise to two-thirds level by 2017.
15.1.1
Surging Mobile Data Traffic and Declining Operator Profits
The exponential growth in mobile data traffic, especially in the form of video, is
severely stressing the cellular backhaul and core networks. On one hand, emerging
applications are bandwidth heavy and/or pose stringent requirements for end-user
quality of experience (QoE); on the other hand, mobile network operators (MNOs)
are unable to charge in proportion to the costs incurred by the higher demands and,
hence, are faced with declining profits. MNOs are, therefore, on the lookout for solu-
tions that can help to manage the traffic growth without degradation to end-user QoE
and also boost their revenues. Some solutions in this direction that are in active explo-
ration are (i) capacity expansion via infrastructure upgrades, for example, increased
number of base stations, deployment of Femto cells, and enabling WiFi offload [2];
(ii) design of sophisticated resource allocation, multimedia content management, and
delivery techniques such as caching, including at the cell edge [3‚Äì5], transcoding [6],
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
391

392
ASYNCHRONOUS CONTENT DELIVERY AND PRICING
and just-in-time delivery [7]; and (ii) moving away from flat pricing toward pricing
schemes that are smarter‚Äîadopting variable, dynamic, and adaptive pricing meth-
ods to manage growth such as usage-based pricing, tiered wireless data pricing [8],
and time-of-the-day pricing and providing economic incentives to promote access
patterns and behaviors that can alleviate congestion.
While capacity expansion and upgradation can become inevitable at a certain
stage, rolling out upgrades is often expensive, and hence, any alternate techniques
that delay expansion without impacting user QoE can result in significant cost savings
for MNOs.
15.1.2
Traffic Variations and Peak-Time Congestion
One aspect of the traffic demand observed in operational networks that can be lever-
aged for better traffic management (and, hence, delaying capacity expansion) is the
significant variation in utilization levels over time. Such variations are primarily due
to cyclic and regular patterns in everyday human activity; for example, networks see
more utilization during days than nights [9, 10], cellular base stations in residen-
tial areas are more loaded during mornings and late evenings, whereas base stations
near commercial areas are busy during office hours [11], etc. In fact, measurements
at a commercially deployed base station (reported in Section 15.3.2) point to large
variations in achievable throughput even at short timescales of the order of minutes.
This aspect has been reported and corroborated in certain other works [9, 12]. Conse-
quently, while networks are overloaded and congested during certain peak times of a
day, they remain sparingly used during certain other times. In other words, while the
peak demand is higher than the base station capacity, the average demand is much
lower.
Flows in session during peak periods compete for bottleneck resources (such as
the spectrum bandwidth), which reduces the bandwidth achieved by each flow and
increases the packet delay. Such ineffective use leads to a lower yield of the network
resources. The yield of a network deployment is a function of the number of ‚Äúuseful‚Äù
bytes carried by the network during any interval of time, that is, bytes that do not get
dropped, get delivered in time, and do not lead to degradation of end-user QoE, and,
hence, are of value.
15.1.3
Yield Management through Smart Pricing
When the average demand is observed to be much lower than the capacity, and con-
gestion occurs only at certain points in time, such peak-time congestion can be eased
without expanding network capacity if part of the peak-time traffic is time shifted
to periods of lighter use. For this purpose, data traffic can be considered to be of
two broad types: (i) delay-inelastic traffic‚Äîwhich users cannot tolerate any delay
for any reason‚Äîand (ii) delay-elastic traffic‚Äîwhich can be deferred or for which
users may be willing to wait, in exchange for incentives. Large multimedia and other
file downloads, cloud synchronization, video uploads, and software updates are some
examples of traffic that is delay elastic. Note that delay-elastic traffic is in turn of two

USER SURVEY
393
types: in the first type, the delivery is awaited by users (even if time shifted) for direct
consumption, e.g., as in the cae of multimedia files, and in the second one, users are
agnostic about transfers and consume content only passively, e.g., software updates.
As video traffic dominates the data carried on mobile networks and content
consumption penetrates into larger sections of the society, many of whom react
positively to incentives, there is much scope for lowering peaks by including
mechanisms to time-shift traffic. In particular, designing incentive and delivery
mechanisms for time-shifting traffic can help both delay-elastic and delay-inelastic
traffic. For delay-elastic traffic, consumers can also benefit in terms of QoE if their
expectations are negotiated and appropriately set in exchange for incentives, such
as price discounts, and the altered expectations are adequately met. User-agnostic
traffic such as software updates can be shifted by setting the right policies, such as
performing updates during nighttime, without affecting the QoE of a user in any way.
When some delay-elastic traffic is moved away from peak period, delay-inelastic
traffic during that time also benefits because of less contention for bottleneck
resources, thereby improving the overall network yield.
Time-shifting traffic, however, introduces a radically different delivery model than
what consumers are normally used to and may also require changes to the applications
to adhere to the new delivery semantics. As a first step to understand the implica-
tions of this changed delivery model and to gauge the sensitivity of consumers to the
various aspects of such a delivery model, we conduct a detailed user survey with a
representative set of user population. We discuss the setup and results of our study
in Section 15.2 and derive interesting insights that are useful for designing traffic
time-shifting mechanisms.
Details of our user survey is followed by a description of approaches to
time-shifting traffic and their high level comparison in Section 15.3. Section 15.4
describes a pricing scheme for one of the approaches and its integration with the
MNO‚Äôs infrastructure. Section 15.5 evaluates the time-shifting approaches through
simulations, while Section 15.6 concludes.
15.2
USER SURVEY
This section describes the survey that we conducted to specifically understand how
users would react to a model that offers delay versus price trade-off and summarizes
the results obtained.
15.2.1
Setup and Goals
The survey page, available at [13], includes several relevant questions to collect inputs
from more than 100 users. The set of people taking the survey includes engineers,
Internet-savvy nonengineers, people active on social networks such as Facebook, and
other tech-savvy users. About 20% respondents are from North America, about 10%
from Europe, and the remaining are from India.
The intention of our survey is to find answers to the following questions.

394
ASYNCHRONOUS CONTENT DELIVERY AND PRICING
‚Ä¢ Current State of User QoE. Do users experience degraded QoE during peak
hours?
‚Ä¢ Delay Tolerance. What fraction of the users is willing to accept delays to content
delivery if offered discounts?
‚Ä¢ Delay Elasticity by Traffic Type. What kind of traffic are users willing to delay
if offered incentives?
‚Ä¢ Price Sensitivity. For a given discount, how long can users wait for the content
to be available for consumption?
‚Ä¢ Adoption. Given discounts on content delivery, would users increase content
consumption (i.e., network usage) further?
‚Ä¢ Pricing Interface. Given discounts, how frequently would users like to make
choices of pricing?
While a larger user base will make the results even more representative and author-
itative, our current observations shed light on several interesting aspects that motivate
and guide the design of solutions for time-shifting traffic.
15.2.2
State of User QoE
In our survey, we asked users to report the top three connectivity problems that they
typically face when using cellular data network. A few representative responses
reported by many users are as follows.
I get very low download speed on my wireless broadband connection in the morning dur-
ing office hours. The 4G (LTE) network connection on my phone often slows down and
sometimes breaks when I am commuting, especially, close to the office. Video stream-
ing on my phone over 3G is usually faster during early mornings or late evenings (off
peak hours); however, because the data plans are relatively more expensive than wired
broadband, I restrict my usage.
While some of the above problems may have several other possible root causes
than network congestion, most of the responses suggest the impression the users carry
about network connectivity: poor QoE during peak hours. These responses indicate
the viability of a pricing/delivery model that can make the users aware of network
congestion explicitly and then provide them with the option to delay content delivery
for a discount.
15.2.3
Delay Tolerance
Next, to understand the delay-tolerance thresholds of users, we asked the following
question: If provided with a delivery promise in terms of an expected delivery time
(EDT), how long can you wait for the content to be delivered and available?
Users‚Äô responses are summarized in Figure 15.1. The figure shows that roughly
50 users when choosing delays are sensitive to discounts offered (indicated by
f(discount)), while more than 40 are willing to delay the download (by 1‚Äì6 h) for an

USER SURVEY
395
0
10
20
30
40
50
60
f(delay)
f(discount)
f(content)
f(time-of-day)
User response
Figure 15.1
Tolerance to delays.
EDT promise for better QoE even without any discount (indicated by f(delay)). This
is possibly because of the existing low bandwidth experience in the network and lack
of good QoE [14]. About 20% of the users are also sensitive to the specific content
type (indicated by f(content)) and time of the day (indicated by f(time-of-day)). Note
that a user could select multiple options for this question. For example, delay that is
acceptable to a user can depend on both discount and time of the day.
15.2.4
Delay Elasticity by Traffic Type
To get a sense of the content types that are delay elastic, we asked users to select
the traffic classes for which they would accept delays to the delivery for discounted
rates. Users‚Äô responses are summarized in Figure 15.2. The figure shows that only
0
15
30
45
60
75
90
No-delay
5 min-vid
10 min-vid
UL-video
UL-photos
DL-movie
DL-old-mov
DL-music
User response
Figure 15.2
Tolerance for content types.

396
ASYNCHRONOUS CONTENT DELIVERY AND PRICING
about 10% of the users are particular about receiving all the content with no extra
delay. Others show increased tolerance to different content and transfer types. As
expected, people are more willing to tolerate longer delays for larger transfers. Also,
more than 50% of the respondents are willing to delay video and photo uploads,
possibly because they themselves do not consume the content.
15.2.5
Price Sensitivity
We then asked the users to indicate the discount levels acceptable to them. Response
summary in Figure 15.3 shows that most users are willing to wait for up to 2 h if
given 50% discount, but not as many users are willing to tolerate higher delays even
for 75% discount. However, it shows that many users are price sensitive, and they can
trade a delay of 1‚Äì2 h, for a sizeable discount.
15.2.6
Adoption
Next, to get a sense of the additional network usage and revenue that the new pricing
scheme can lead to, we asked the users as to whether they would be accessing more
content, if given a 50% discount on the original price and a promise of delivery within
an EDT. Figure 15.4 shows that more than 50% of the respondents would increase
usage by 2√ó if given 50% discount. As this increased adoption is barely sufficient to
balance the discount offered, it does not lead to an increase in the operator revenue.
However, the same figure also shows that more than 20% of the respondents would
increase usage by 3√ó for the same 50% discount, which has the potential to increase
operator revenues. Thus, by providing appropriate discounts and managing expecta-
tions on delivery times, the operators can not only manage congestion but also expect
their revenues to grow.
0
10
20
30
40
50
60
25%-1hr
50%-2hr
75%-3hr
75%-4hr
User response (%)
Figure 15.3
Response to discounts.

USER SURVEY
397
0
10
20
30
40
50
60
No-increase
Some-incr.
2X-50%disc
3X-50%disc
User response (%)
Figure 15.4
Adoption of discounts.
15.2.7
Pricing Interface
We finally asked users for their choice of interaction to avail discounts: per-request
discounts, day-ahead notification of discounted time periods, or monthly discount
plans. Figure 15.5 shows that most respondents are interested in getting discounts:
About 45% preferred the maximum flexibility provided by per-object pricing and
delivery-time decisions (i.e., choosing the price of an object just before downloading),
while about 30% chose to keep it simple with monthly discounts. Only about 10%
chose to get day-ahead discounts. The main reason could be that day-ahead discounts
require users to keep track of daily price changes, which could get cumbersome, while
month-ahead discounts obviates such day-to-day tracking.
0
10
20
30
40
50
60
No-discount
Per-object
Month-ahead
Day-ahead
User response (%)
Figure 15.5
Interface to pricing.

398
ASYNCHRONOUS CONTENT DELIVERY AND PRICING
15.3
TIME-SHIFTING TRAFFIC
The results of the user survey in the previous section suggest that a majority of the
users is amenable to traffic deferrals by bounded time durations, in exchange for
proportionate discounts. In this section, we discuss approaches for realizing such
deferrals.
Internet service providers and MNOs have traditionally offered flat-rate data pric-
ing schemes that charge a fixed amount of money for data service and place no caps
on data usage. The explosion in data traffic in recent years, however, has led net-
work operators to move away from a flat pricing model to tiered and usage-based
pricing [8]. Usage-based and tiered pricing schemes can limit per-user demands but
do not explicitly attempt to reduce traffic congestion periods. This is because such
schemes do not include any measures that can promote requests to be spread out over
time.
To help to reduce peak-time congestion and delay the requirement of network
capacity upgrades, an MNO requires more sophisticated differential pricing schemes
that will aid in intelligent time shifting of traffic. A survey of such pricing techniques
can be found in Reference 15. For example, Murphy and Murphy [16] and Paul and
Subramanian [17] propose to smoothen traffic by providing incentives in the form of
higher access rates during off-peak hours. In a similar vein, the TUBE system [12]
has helped in renewing this direction of research for cellular networks by developing
a time-of-the-day pricing scheme. This scheme provides price discounts for off-peak
accesses and incentivizes increased usage.
15.3.1
Time-Shifting Taxonomy
Request-Shift Versus Delivery-Shift. Consider the typical browsing and content con-
sumption pattern of any user: (i) selection, the user selects an object to view (and
clicks on a hyperlink); (ii) request, the user device issues a request to the content
server for the object on a transport connection; (iii) delivery, the content server deliv-
ers the object on the transport connection; and (iv) consumption, the user uses (e.g.,
views) the object.
In such a setting, time-shifting traffic can be realized using two possible
approaches (see Fig. 15.6):
‚Ä¢ Request-Shift. In this approach, if there is congestion at a certain point in time,
users are provided an incentive to stop making requests and return back at a
later point in time during a low price period and reissue their object requests.
With Request-shift, the three steps of request, delivery, and consumption hap-
pen close together in time during a low price period of user‚Äôs (or their agent‚Äôs)
choosing. Note that with this approach, delivery is expected to be confined to
the chosen low price period, which can be away from the time the user makes
a selection (or intends to select) by a large duration.
‚Ä¢ Delivery-Shift. In this approach, an object request is collected immediately
when the user intends to view the object, but the user is provided an EDT of

TIME-SHIFTING TRAFFIC
399
Request-shift
Delivery-shift
Synchronous,
continuous delivery
Asynchronous, intermittent delivery
Select
Consumption
Consumption
Time
Time
Delivery
end
Delivery
end
Select /
request /
delivery start
Request /
delivery start
Figure 15.6
Request-shift and Deliver-shift approaches of time-shifting traffic.
when the object will be ready to consume. The object‚Äôs delivery is spread
over time, and the request‚Äìresponse transaction is asynchronous to be able
to opportunistically transmit during noncongested periods at short time
scales.
An instance of the Request-shift approach is the TUBE system [12]. TUBE com-
putes time-dependent prices a priori, typically a day in advance, using past history
of network traffic by time and a user-behavior model that predicts user responses
to prices offered. TUBE uses a feedback loop between the price-computation and
user-behavior models to adapt and optimize price computation based on user‚Äôs reac-
tion to the prices. To simplify the task of choosing a time for issuing a request so
that the overall usage is optimized, TUBE also includes an autopilot mode that can
schedule requests on behalf of the users. The prices are computed over time durations
of the order of 30 min to 1 h.
An instance of the Delivery-shifting approach is the Async system [18]. Async
introduces a ‚Äúsachet‚Äù model in which users (or automated user agents) are allowed to
choose the delivery price and expected delivery time (EDT) of different objects at fine
granularity. For realizing this model, as shown in Figure 15.7, for each object request,
Async presents users with a set of (price, EDT) options to choose from. Thus, the
Async system facilitates an MNO to negotiate a delay in content delivery with users in
exchange for incentives. The negotiated delay is used by the MNO to actively manage
content delivery in such a way that QoE improves for both deferred flows and regular
flows (which are not deferred). The price for a request for a given EDT is computed
by determining the total traffic levels during the times at which the request is likely to
be scheduled. By charging a price that is in proportion to the expected traffic levels,
the MNO can offer higher discounts for longer delays. Note that deferred deliveries
under Async are not just best-effort attempts but are associated with EDTs. By letting

400
ASYNCHRONOUS CONTENT DELIVERY AND PRICING
Async client
Async proxy
Network delivers opportunistically
within the agreed delivery time
User select a Watch-later option
Request an object
Present (price,EDT) options
Watch-now @ price $$$
Watch in 2-hrs @ price $
Watch in 1-hr @ price $$
Figure 15.7
Async user interface.
the users to choose the (price, EDT) combination, users get flexibility in choosing the
level of service and price they want. At the same time, the MNO also gets to control
when and at what price content is delivered.
15.3.2
Comparison of the Time-Shifting Alternatives
The Request-shift approach leads to a simple system implementation, requiring no
changes to the network elements, except for setting different charging rules dynami-
cally. The onus is on the user (or a user agent) to issue requests at appropriate times.
On the other hand, Request-shift approaches can have the following drawbacks. (i) As
the network has no control over the amount of traffic that would arrive in the low price
period, time-shifted traffic may again encounter congestion, thereby disappointing
the user who chose to defer the traffic. (ii) Transmission opportunities that become
available over short time scales in the time intervening between the object selection
and final consumption cannot be utilized, lowering the overall network utilization.
(iii) Owing to lack of active network control, the system cannot adapt satisfactorily
if actual conditions deviate from the predictions. In other words, reasonably accurate
estimates of future traffic conditions are required a priori for the system to compute
time-of-the-day prices and be effective in practice.
To understand the variations over time in the usage of cellular data links and the
capacity that is available, we conducted a set of experiments over a week. In these
experiments, we measure and characterize the achievable throughput across different

TIME-SHIFTING TRAFFIC
401
0
150
300
450
600
750
900
1050
1200
8 AM
. . . 9 AM
. . . 10 AM
. . . 11 AM
. . . 12 PM
. . . 1 PM
. . . 2 PM
. . . 3 PM
. . . 4 PM
. . . 5 PM
. .
Download throughput (Kbps)
Time
30th December (Sunday)
31st December (Monday)
1st January (Tuesday)
Figure 15.8
Achievable throughput using downlink probes.
base stations in Bangalore, India. Figure 15.8 shows measurements of throughput
with backlogged flows (for a duration of 50 s) using the cellular network of a lead-
ing wireless service provider in India from two different locations (in Bangalore).
Figure 15.8 shows that there is a lack of any temporal predictability in the achiev-
able throughput (and, hence, load) at cellular base stations; as can be seen, the load
can vary significantly across two consecutive half-hour time periods and can be very
different at a given time of the day on different days. We observed similar variations
at other commercially deployed base stations also. These observations indicate that
meeting user expectations with a Delivery-shift approach may be easier than that with
a Request-shift approach.
The Async system, which is an instance of Delivery-shifting, strives to overcome
the shortcomings of Request-shifting approaches but has to address the following
issues. First, it requires active management of content delivery using an in-network
element (essentially a content proxy) in order to opportunistically transmit deferred
flows during off-peak times. Second, because object delivery can be spread over
longer durations, in comparison to Request-shift, and can be intermittent, the number
of outstanding requests in the system can be higher. Further, the system has to tolerate
disconnections because of mobility and user activity such as device switch off, neces-
sitating that state be managed. Finally, Async requires a reliable sensing method to
estimate periods of low utilization to transmit deferred traffic to improve spectrum
utilization in comparison to Request-shift. Async successfully addresses these issues
by designing an application layer protocol that can manage content delivery, with
client-side maintenance of content transfer state [18]. Additionally, such active man-
agement allows the system to be more dynamic and adaptive in that delivery times
and associated prices can be computed using current traffic conditions in association
with coarse estimates of nondeferrable traffic.

402
ASYNCHRONOUS CONTENT DELIVERY AND PRICING
15.4
PRICING TO ENABLE DELIVERY-SHIFTING
In order to enable Delivery-shifting, we now turn to describing a method for comput-
ing a price for a specified delay for flows arriving at a base station. This method can
be used for putting together a set of (price, EDT) options that Async uses for nego-
tiation with end users (refer Section 15.3.1 and Figure 15.7). While such options can
be computed in several different ways, we present a simple scheme to illustrate the
feasibility of the Delivery-shift approach and quantify possible gains.
Pricing schemes that can facilitate time shifting fall under the broad category of
congestion pricing. Congestion pricing methods have been proposed in the past for
wired networks [19, 20] and in other domains such as electricity supply [21, 22]. The
prior methods, however, are not based on an asynchronous opportunistic delivery and
do not consider determining EDT-dependent prices.
The pricing method that we present in the following computes prices so that con-
gestion cost for the operator is minimized (assuming convex cost functions). One
can in addition consider a feedback loop that accounts for the effect of the prices on
users‚Äô demand, which in turn can influence the price computation. It is also possible
to consider maximizing benefits to the user or profits to the operator. (In our evalu-
ation, we do consider a user-behavior model in determining a user‚Äôs response to the
options they are presented with and the (price,EDT) option that they choose.) Never-
theless, we show that the following approach can effectively alleviate congestion for
a given discount budget and thereby demonstrate the potential of the overall method.
(Consideration of the aspects of benefits to user, profits to operator, and user-behavior
model can only improve the effectiveness of the pricing scheme.)
15.4.1
Computing (Price, EDT) Options
For every incoming request, Async presents a set of (price,EDT) options to the users.
EDTs can be a fixed set of values, such as 1, 2, and 4 h, or chosen based on the
context and length of the request. Price for a given EDT is computed based on an
estimation of the total traffic level or congestion during the times that the incoming
request is likely be scheduled. To estimate congestion, we determine an allocation for
the incoming request with respect to the EDT under consideration in the manner of
water-filling algorithm, so that the maximum traffic at any point in time is minimized.
This gives a reference schedule for the incoming request that can potentially be used
by a network-side entity for actively managing its delivery.
Note that computing a reference schedule requires some knowledge of nonde-
ferrable traffic, that is, non-Async traffic, arriving in the future. We assume that
historical loads are available for estimating such future traffic. Such historical infor-
mation can be obtained using the total cell-level load information (available with
the network operator) and details of Async traffic available with the Async sys-
tem (because all Async requests pass through the Async system). To account for
deviations in the actual traffic from the estimated one and be adaptive, we recom-
pute reference schedules for outstanding Async requests periodically or when a new
request arrives, using their pending transmission sizes. (We, however, do not make

PRICING TO ENABLE DELIVERY-SHIFTING
403
changes to negotiated prices or EDTs of outstanding requests.) Such recomputation
aids in reducing errors while determining prices for future flows. Further, because
prices are computed at runtime, updates to the actual traffic can be made use of while
computing prices. Hence, unlike approaches such as TUBE [23], prices in our scheme
can evolve based on the load observed at runtime.
In what follows, we describe our pricing methodology in greater detail.
15.4.1.1
Assumptions and Definitions Time is assumed to be divided into discrete
periods. The duration of a period can be set appropriately based on the desired gran-
ularity, for example, we set each period to be 30-min long. Let C denote the base
station capacity in terms of aggregate bytes that can be transmitted in a period. We
denote the total aggregate load owing to regular flows (i.e., non-Async flows) in time
period t as Dt. The total number of Async flows active at time t is denoted by Nt and
the number of bits allocated to Async flow i in period t is denoted by xi,t. Thus, the
total traffic at the base station at time t is then given by ùõºt = Dt + ‚àëNt
i=1 xi,t.
To quantify the degree of congestion, we classify the congestion experienced at a
base station into one of a set of L distinct levels. To enable such a classification, the
base station‚Äôs transmission capacity [0, C) is partitioned into L discrete subranges,
given by [T0, T1), ‚Ä¶ , [TL‚àí1, TL), where TùìÅ‚àí1 < TùìÅfor 1 ‚â§ùìÅ‚â§L. Thus, the conges-
tion level at a base station in period t is given by the subrange in which the total traffic
it sees in that period, ùõºt, lies and is said to be ùìÅif ùõºt ‚àà[TùìÅ‚àí1, TùìÅ). For each level ùìÅ,
we assign a constant but monotonically increasing congestion weight KùìÅ. We then
define a convex congestion-cost function (which is piecewise linear) for time period
t as follows.
Bt =
L
‚àë
ùìÅ=1
KùìÅ‚ãÖmax (min(ùõºt, TùìÅ+1) ‚àíTùìÅ, 0) .
(15.1)
It is easy to see that this function is nondecreasing with ùõºt. This cost function
allows the MNOs to choose different level thresholds (TùìÅ) and appropriate cost (KùìÅ)
for the level based on their experience, for example, based on the probability of facing
overload and related operational expenditure.
15.4.1.2
Allocating Async Flows to Minimize Congestion Cost To compute a
price for an EDT, we first formulate and solve the problem of allocating N Async
flows over P time periods so that the aggregate congestion cost over the time periods
is minimized. This optimization problem is formulated as follows.
PACKING
Minimize
‚àëP
t=1 Bt,
such that ‚àëN
i=1 xi,t ‚â§C ‚àíDt, ‚àÄt = 1, ‚Ä¶ , P
Fi = ‚àëP
t=1 xi,t,
‚àÄi = 1, ‚Ä¶ , N
xi,t ‚â•0,
‚àÄt = 1, ‚Ä¶ , P, ‚àÄi = 1, ‚Ä¶ , N,
(15.2)

404
ASYNCHRONOUS CONTENT DELIVERY AND PRICING
where Fi is the size (in bits) of Async flow i. The constraints in Eq. (15.2) ensure
that the base station capacity is not exceeded and the flow is served completely. The
capacity of a base station depends on the channel quality seen by the users and, hence,
in general, is dynamic for cellular systems. For the above optimization problem, we
assume an average capacity given by the average signal quality experienced.
Note that even though the objective cost function is piecewise linear, the problem
can be solved optimally because the slope of the objective is bounded and all
the constraints are linear. We assume that at least one of the congestion weights
and congestion-level widths is strictly increasing and the other is monotonically
increasing.
15.4.1.3
Computing Per-Flow Options When a new flow arrives, we solve the
optimization problem PACKING once for each EDT to be presented to the user (with
P set to that EDT E). In solving the problem, we use the allocations in the future
periods to previously accepted Async flows (obtained as solutions to instances of
PACKING solved when those flows arrived) and estimates of D (traffic because of
regular flows). If the problem is infeasible for the largest acceptable EDT, then we
declare that the incoming request cannot be scheduled and send a notification back
to the client. We compute a price for EDT E, pE, as follows:
pE =
‚àëE
t=1 Bt
‚àëE
t=1
‚àëL
ùìÅ=1 KùìÅ‚ãÖ(TùìÅ‚àíTùìÅ‚àí1)
.
(15.3)
We assume that Bt = 0 if xi,t = 0 to avoid a large value of Dt (regular traffic) for
some t (with no Async traffic allocated) affecting the price computation; i is the new
request under consideration. Also, pE lies between 0.0 and 1.0 and can be used along
with a base price. For instance, a fraction pE of the base price may be charged for the
request.
It can be shown that the prices computed in the above manner are monotoni-
cally decreasing with increase in EDTs, ensuring higher incentives for waiting for
a longer time. This, unlike models in prior work such as in TUBE [23], gives users
an easy-to-understand interface: wait more, gain more [17]. Moreover, Async offers
higher discounts to the requests arriving in low congestion periods, thus incentivizing
users to increase their usage.
15.4.2
Integration with an MNO‚Äôs Infrastructure
In the 3GPP specification for cellular networks, differential pricing per flow is
generally achieved by adding rules to a system referred to as Policy and Charging
Rules Function (PCRF) [24]. A rule specifies the price to be paid per byte by a flow
identified by the standard 5-tuple:
<src-ip,src-port,dst-ip,dst-port,proto>
In the above, ip addresses and ports can be provided as wildcards. When a flow passes
through the Gateway GPRS Support Node (GGSN), where it needs to be billed, a

PRICING TO ENABLE DELIVERY-SHIFTING
405
PCEF
PCRF
GGSN
Flows are billed appropriately
Port 1
Port 2
No price
Price p1
Price p2 < p1
Price p3 < p2
Price p4 < p3
small # of Async rules,
scalable solution
Port 3
Port 4
Port 5
Figure 15.9
A simple mechanism for billing flows in Async.
module called Policy and Charging Enforcement Function (PCEF) [24] finds a rule
matching the flow and uses it for determining the charges.
To realize our pricing scheme, a small set of ports, each of which maps to a
price per byte, can be assigned for the Async flows at a network element, which we
shall refer to as the Async proxy. Async flows are made to pass through the proxy
so that they can be managed. One rule per port i of the form (src-ip=proxy-IP,
src-port=i, price=$$) can then be added to the PCRF. By assigning ports to
flows based on the download price chosen by the user, ports at the proxy can be used
for price differentiation. This approach is minimally intrusive to the cellular network
deployment and also scalable, because it only adds a small set of rules (as many as
the number of discrete pricing levels) to the PCRF. Note that this change to the set of
PCRF rules does not affect PCEF (its scalability, in particular), because the charging
enforcement functionality of PCEF is independent of how the rule for a flow is spec-
ified in PCRF or retrieved from it. Our approach for billing Async flows is illustrated
in Figure 15.9.
Recall that for each incoming Async flow, a set of (price, EDT) options is com-
puted as described in Section 15.4.1.3. To facilitate billing as described earlier, only
those options with prices close to the prices specified in PCRF rules (based on a dif-
ference threshold) are considered. For each option included in the final set using the
above rule, the final price is rounded to the highest discrete price in PCRF not exceed-
ing the computed price. On the basis of the price that the user agrees to, the port on
which the user can connect to for downloading the content is communicated. Thus,
in a simple end-to-end manner, we can enable deadline and price aware transfer of
content.
To enable a Request-shift approach such as TUBE, time-dependent rules can be
added to PCRF; for instance, a price-per-byte rule can be added for each period of
the day. In such a case, every byte of traffic arriving in a particular time period will
be billed according to the pricing rule set for that time period. Further, because the
number of periods in a day is small, of the order of a few tens, it is sufficient to add
and delete a small set of rules per day, thus incurring only a small overhead. Hence,
it is quite simple for a mobile network operator to deploy a time-dependent pricing

406
ASYNCHRONOUS CONTENT DELIVERY AND PRICING
scheme. On the flip side, such time-dependent pricing is flow agnostic. For instance,
if a flow starts in a low price period because of the discounted price but does not
finish within the period and continues in the next period, whose price is high, it needs
to either be torn down, resulting in incomplete downloads or poor streaming, or pay
a higher price to continue the service. In contrast, because Async‚Äôs pricing method
provides a price agreement for each object request, which maps to a flow, and is
independent of the time of transfer, it is immune to such time-based issues.
Note that retransmissions from the proxy may be billed multiple times by the
MNO‚Äôs infrastructure. Peng et al. [25] studied and discussed the problem and pro-
vided a few solutions for MNOs to avoid overcharging for the retransmitted content.
15.5
SIMULATION RESULTS
We now present a simulation study to evaluate the efficacy of the Delivery-shift and
Request-shift approaches. We consider recent work in TUBE [23] as a representative
pricing scheme for the Request-shift approach. In this section, we first describe the
performance measures and simulation setup used in evaluating the two approaches.
Subsequently, we describe the results of the evaluation.
15.5.1
Performance Measures
The main idea in both the Request-shift and Delivery-shift approaches is to alleviate
congestion by deferring delay-elastic flows. Hence, to compare the two approaches,
we define the following two performance measures: (i) aggregate base station load
(over time) and (ii) total (end-to-end) delivery time for delayed flows.
To compute the first performance measure, we divide time into multiple peri-
ods and compute the aggregate traffic transmitted from the base station during each
period. We then plot a cumulative distribution function (or CDF) of the load values.
The second performance measure, total delivery time, is defined as the difference
between the time a user selects an object and the time at which the corresponding
content is completely delivered (i.e., all the bytes of the requested object are deliv-
ered at the client). Thus, the total delivery time measures the extent to which a scheme
time shifts traffic to ease congestion. Both the schemes use discount as a means to
achieve traffic shifts, and the higher the discount, the higher the chances of traffic
shifts. To ensure that the traffic shifts are not just due to discounts but also due to
effective delivery mechanisms, we also compare the total discount offered by the two
schemes.
15.5.2
Simulation Setup
For the evaluation, we first choose an aggregate traffic pattern depicting traffic vari-
ations over a day. For this, we observe the traces from a leading service provider
in India and consider different base traffic instances. One such instance is shown
in Figure 15.10. The pricing schemes that we consider for both Delivery-shift and

SIMULATION RESULTS
407
0
30
60
90
120
150
180
210
240
270
300
4
8
 12  16  20  24  28  32  36  40  44  48
Aggregate traffic (MB)
Time period
Traffic pattern
Tube
Async
Async with discount cap
Figure 15.10
Aggregate traffic (load per time period) with a Delivery-shift and a
Request-shift mechanisms. The base station capacity is 270 MB/period.
Request-shift divide a day‚Äôs time into multiple time periods. We consider 30-min time
periods and choose an aggregate traffic load for 48 continuous periods for 24 h. We
assume base station capacity to be 270 MB/period. We then generate flow requests
period by period to match the aggregate load. We distribute the flow arrival times uni-
formly randomly within each period. Each generated flow is one of the four content
types: web request, short video, long video, and file download. The mean sizes for
the four types are chosen from different sets, for example, 50 KB, 5 MB, 25 MB, and
50 MB.
We implement the Async pricing scheme for Delivery-shifting described in
Section 15.4 using CVXOPT library [26]. In the Async framework, flows are of two
types. (i) Flows that are amenable for deferrals, referred to as Async flows. Upon
arrival, such flows are presented with a set of possible (price, EDT) options. (2)
Flows that are not amenable for deferrals and do not wish to pass through the Async
system, referred to as regular or non-Async flows. The Async pricing program
takes the following as input: (i) details of Async flows (time of arrival, object size,
type of flow) and (ii) an estimate of the cumulative non-Async traffic (based on
historic trends). It should be pointed out that non-Async flows are not presented to
the in-network control element, and hence, unlike Async traffic, the total amount of
actual non-Async traffic is not available at runtime to the pricing component. The
pricing scheme only uses coarse estimates based on historic data (as described in
Section 15.4.1). The parameters of the pricing scheme (described in Section 15.4.1)
are set as follows: we partition the base station capacity into L = 10 equal congestion
levels. For each level, we set Kl = Kl‚àí1 + 1 for l ‚â•2 with K1 = 1.
As output, the pricing program determines the delivery method (NOW or deferred)
and, if deferred, the EDT, for each Async flow. Async flows for which deliver NOW
option is chosen are delivered without delay, just like a regular flow. We assume a
proportional fair scheduling scheme (which is commonly used by cellular base station

408
ASYNCHRONOUS CONTENT DELIVERY AND PRICING
schedulers) for making allocations to the regular flows while computing (price, EDT)
for the deferred flows.
For use with Request-shifting, we also implement the pricing scheme described in
Reference 23 to determine per-period discounts based on the aggregate loads speci-
fied. We employ the user-response model described therein to determine the aggre-
gate amount of traffic shifts across periods. For fair comparison, we use the same
user-behavior model for the Async pricing scheme mentioned earlier to determine
the final (price,EDT) options selected by end users. Specifically, for each of the con-
tent types described earlier, we choose a patience index (which models the amount of
time by which users can shift their requests) as described in Reference 23. For the four
content types mentioned earlier, we use 0.5, 1, 1.5, and 2 as the respective patience
indices. These patience indices are then used in choosing the end-user‚Äôs (price, EDT)
option from among the set computed for a request. For both the schemes, we compute
the discount as a fraction between 0.0 and 1.0, which essentially provides the discount
rate per byte served. It should be pointed out that the TUBE pricing approach of Ha
et al. [23] computes byte-level shifts, that is, the fraction of bytes that shift from one
period to a later period. When extended to flows, a flow that does not complete within
a period carries over into the next period. Owing to this, TUBE time periods are con-
strained to be reasonably granular, for example, at least 15-min long; else, the actual
price charged for a flow may not match the price that a user expects to pay when
deferring a flow. On the other hand, because the price computed for Delivery-shifting
is on a per-object basis, it is not impacted by the times at which the object is actually
delivered, and hence, no constraints are placed on period granularity.
In this chapter, our focus is on the scope of the Delivery-shift and Request-shift
approaches in depeaking congestion while improving the network yield. Hence, as
mentioned earlier, for Delivery-shift, we assume that an entity in the network (such
as a proxy) can schedule the deferred flows such that the reference schedule com-
puted by the pricing module is followed. The Delivery-shift approach is better able
to utilize short-term transmission opportunities and improve yield (as described in
Section 15.1) because of the following: (i) not restricting a flow to a single or few
time periods, as described earlier‚Äîhence, traffic spread can be wider‚Äîand (ii) active
network control, which can sense such opportunities. One scheme that is capable of
adapting to and making use of capacity variations is described in Reference 18.
We performed our evaluation for two cases: predictable and unpredictable traffic
patterns. As TUBE computes per-period prices in an offline manner assuming a pre-
dictable traffic pattern, the first case allows us to compare Async with TUBE in a fair
manner. For the second case, we scale the traffic pattern (e.g., increase the aggregate
traffic in each period by up to 30%) to introduce unpredictability. The second case
evaluates the adaptive nature of Async to runtime deviations to the traffic pattern
assumed.
15.5.3
Results
15.5.3.1
Predictable Traffic Conditions Figure 15.10 shows the input traf-
fic assumed and the aggregate traffic as observed with the two approaches for

SIMULATION RESULTS
409
time-shifting traffic. Given that the base station capacity is 270 MB per time period,
periods 0‚Äì22 are congested in comparison to the remaining periods. Instead of
shifting the flows entirely, the schedule computed by Async pricing can be used
to serve the flows over multiple time periods and utilize the transfer opportunities
whenever they become available. Further, such a schedule is computed and adapted
periodically at runtime by considering the state (i.e., residual content and deadline)
of active Async flows. Hence, as can be observed from the figure, the traffic curve
for Async is smoother than that for TUBE. Thus, because of runtime determination
of congestion and computation of appropriate price and EDT, the Delivery-shift
mechanism in Async is more effective in alleviating congestion.
15.5.3.1.1
Flow Deferrals and Discount To evaluate Async pricing, we generated
a total of 750 flows for the duration of 24 h to conform to the aggregate input traffic
chosen. (Recall that TUBE pricing operates at the aggregate traffic level and does
not make use of flow-level details.) Table 15.1 shows the mean percentage of bytes
deferred over several runs under Async and TUBE. Note that, although the input
trace is the same, the number of bytes deferred by the two mechanisms are different
because Async computes the deferrals in response to the runtime traffic schedule
(considering both the deferred and nondeferred flows), while TUBE precomputes the
deferrals. In addition to the deferrals, Table 15.1 also shows the mean values of total
discounts. In the case of Async, for every flow deferred, we compute the discount
as the product of the rate of discount per byte and the total size in bytes of the flow.
For TUBE, we compute the total discount using per-period discounts and aggregate
per-period traffic. Note that the discounts offered by Async are comparable to that
of TUBE. Further, for a fair comparison with TUBE, we also compute an Async
schedule wherein we restrain Async from offering the discounts once the cumulative
discount offered becomes equal to the total TUBE discount. Figure 15.10 shows that
the traffic shift with above-mentioned discount cap is almost similar to that without
any discount cap. This shows that, in comparison to the Request-shift mechanism in
TUBE, the Delivery-shift mechanism in Async can better depeak the traffic for a
given discount budget. For fair comparison, we let the discount cap remain active in
presenting the results for the two performance measures.
15.5.3.1.2
Aggregate Load In Figure 15.11, we plot the CDF of aggregate traffic
per time period. In our setup, the maximum aggregate load a base station can handle in
one period, that is, the base station capacity, is 270 MB. From the figures, we can see
that Delivery-shift is more effective in reducing the peaks with a load less than 65%
of the capacity in 90% of the periods. We observe a similar behavior when we remove
TABLE 15.1
Comparison of Deferrals and Discounts
Mechanism
Deferrals
Total Discount, Units
TUBE
7.4
313
Async
11.2
389
Async with discount cap
9.8
313

410
ASYNCHRONOUS CONTENT DELIVERY AND PRICING
0
10
20
30
40
50
60
70
80
90
100
80
100
120
140
160
180
200
220
CDF
Load (MB/period)
Async
Tube
Figure 15.11
Better congestion management with Delivery-shift because of runtime price
computation.
the discount cap. However, with TUBE‚Äôs Request-shifting, more than 30% of time
periods are faced with load exceeding 65% of capacity, reaching up to 80%. This
shows that the Delivery-shift mechanism of Async is more effective in alleviating
congestion.
15.5.3.1.3
Total Delivery Time Figure 15.12 shows the CDF of the total delivery
times of flows under the two delivery mechanisms. As the Delivery-shift mechanism
of Async does not wait for low price time periods, but computes schedules for flows
in a feasible manner whenever there is capacity available, the EDTs are much lower
than the flow deferrals under the Request-shift mechanisms. The median delivery
time of flow deferrals in Async is about 18 periods, which is 50% lower than the
0
10
20
30
40
50
60
70
80
90
100
0
5
10
15
20
25
30
CDF
Time period
Delivery time Async
Delivery time Tube
Figure 15.12
Smaller total delivery time with Delivery-shift than Request-shift.

CONCLUSION
411
median delivery time of flows deferral in TUBE. Thus, for a given discount budget,
the Delivery-shift mechanism of Async reduces the delivery time of flows while also
depeaking the traffic in an effective manner.
15.5.3.2
Handling Deviations to Estimated Traffic In another set of experiments,
we consider deviations to actual traffic from that estimated by scaling (increasing by
30%) the input traffic pattern in Figure 15.10. Note that, to enable request shifts,
TUBE computes prices for different time periods by assuming the original (non-
scaled) traffic pattern. In comparison, by design, Async reacts to the changes in traffic
at runtime. As a result, as we can see in Figure 15.13, even when there is unpredictable
increase in traffic, Delivery-shift outperforms the Request-shift mechanism by better
smoothing the traffic and managing the congestion. It can be observed that with the
scaled input traffic, there is a peak with TUBE in time period 32, whereas the traffic
is smoother with Async. Moreover, even with a 30% increase to the input traffic, the
median delivery time in Async is lower than that of TUBE by 45%. Thus, because of
the lack of network-side control, the Request-shift approach does not react effectively
to the deviation in input traffic patterns. Further, flows shifting to the presumed low
traffic periods may suffer from increased contention.
A comparison summary of the salient features of the Request-shift and
Delivery-shift approaches discussed in this chapter is presented in Table 15.2
15.6
CONCLUSION
In this chapter, we have considered and evaluated time shifting of traffic to ease
the peak-time congestion and increase the overall yield of cellular data networks.
We have discussed two approaches for time shifting, namely, Request-shifting and
Delivery-shifting, and, using appropriate instantiations, evaluated them qualitatively
0
30
60
90
120
150
180
210
240
270
300
330
360
4
8
12
16
20
24
28
32
36
40
44
48
Aggregate traffic (MB)
Time period
Scaled-traffic
Unsmoothed
Tube
Async
Figure 15.13
Better adaptation to deviations from assumptions to input traffic with
Delivery-shift.

412
ASYNCHRONOUS CONTENT DELIVERY AND PRICING
TABLE 15.2
Overall Comparison of the Request-Shift and Delivery-Shift Approaches
Request-Shift
Delivery-Shift
Feature
(e.g., TUBE)
(e.g., Async)
Ease of
implementation
Simpler. Involves offline
computation and
dissemination of
time-of-day prices
More complex, requiring
runtime computation of
prices at fine granularity,
down to the level of
individual requests
Runtime network
control
None
Requires active intervention
to control when deferred
flows get transmitted
Yield management
Cannot make use of short
time-scale transmission oppor-
tunities
Can put short time-scale
transmission opportunities
to good use
Depeaking traffic
Less effective
More effective
Robustness
Requires reasonable
estimates of future traffic
to be effective
Can adapt at runtime to
deviations from expected
traffic
Ease of integration
with PCRF
Easy to provide time-of-day
prices but flow-level
expectations may be
violated
Easy to provide a few discrete
prices. Pricing agreements
can be made and honored
at flow level
and quantitatively. Our evaluations suggest that while the Request-shift approach
is simple to instantiate, it may not effectively alleviate congestion, whereas the
Delivery-shift approach exercises greater network control over how flows are
deferred and, hence, achieves better congestion and yield management, leading
to higher QoE, albeit with extra system complexity. Our user survey sheds light
on several design considerations that are important for implementing either of the
approaches in real networks.
REFERENCES
1. CISCO. Cisco visual networking index: global mobile data traffic forecast update,
2012‚Äì2017. Available at: http://www.cisco.com/en/US/solutions/collateral/
ns341/ns525/ns537/ns705/ns827/white_paper_c11-520862.html.
2. K. Lee, J. Lee, Y. Yi, I. Rhee, and S. Chong. Mobile data offloading: how much can WiFi
deliver? In Proceedings of the 6th International COnference, Co-NEXT ‚Äô10, 2010.
3. J. Erman, A. Gerber, M. Hajiaghayi, D. Pei, S. Sen, and O. Spatscheck. ‚ÄúTo cache or not
to cache: the 3G case,‚Äù IEEE Internet Computing, 15(2), 2011, 27‚Äì34.
4. S. Woo, E. Jeong, S. Park, J. Lee, S. Ihm, and K. S. Park. Comparison of caching strategies
in modern cellular backhaul networks. In ACM MobiSys, 2013.
5. Altobridge.
Wireless
network
caching.
Available
at:
http://www.altobridge.com/
data-at-the-edge/wireless-network-caching/. May 2014.

REFERENCES
413
6. J. Xin, C.-W. Lin, and M.-T. Sun. Digital video transcoding. Proceedings of the IEEE,
93(1), 2005, 84‚Äì97.
7. ByteMobile. Advantages of bytemobile‚Äôs video optimization solution. Available at:
http://www.bytemobile.com/docs/WP_VideoOptimizationSolution.pdf. May 2013.
8. G. Kesidis, A. Das, and G. de Veciana. flat-rate and usage-based pricing for tiered com-
modity Internet services. In 42nd Annual Conference on Information Sciences and Sys-
tems, 2008, pp. 304‚Äì308, 2008.
9. U. Paul, A. P. Subramanian, M. M. Buddhikot, and S. R. Das. Understanding traffic dynam-
ics in cellular data networks. In INFOCOM, 2011.
10. Y. Zhang and A. Arvidsson. Understanding the characteristics of cellular data traffic. In
CellNet, 2012.
11. C-Ran. The road towards green radio access network. Available at: http://labs.chinamobile.
com/cran/. May 2014.
12. S. Ha, S. Sen, C. Wong, Y. Im, and M. Chiang. TUBE: time-dependent pricing for mobile
data. In ACM SIGCOMM, 2012.
13. V. Gabale. Affordable pricing for cellular data networks. Available at: https://docs.google.
com/forms/d/12Ac6LUzJ7qJI-I8r-xSGlpquBBcKUrG8edHPaDGQOyE/viewform.
May 2014.
14. X. Liu, F. Dobrian, H. Milner, J. Jiang, V. Sekar, I. Stoica, and H. Zhang. ‚ÄúA case for a
coordinated internet video control plane,‚Äù. SIGCOMM Computer Communication Review,
24 (4), 2012, 359‚Äì370.
15. S. Sen, C. Joe-Wong, S. Ha, and M. Chiang. Pricing Data: Past Proposals, Current Plans,
and Future Trends. arXiv, July 2012. Available at http://arxiv.org/abs/1201.4197.
16. P. Key, L. Massoulie, and M. Vojnovic. Farsighted users harness network time-diversity.
In Proceedings of IEEE INFOCOM, vol. 4, pp. 2383‚Äì2394, 2005.
17. N. Laoutaris and P. Rodriguez. Good things come to those who (can) wait or how to handle
delay tolerant traffic and make peace on the internet. In ACM HotNets-VII, 2008.
18. V. Gabale, U. Devi, R. Kokkku, V. Kolar, M. Madhavan, and S. Kalyanaraman. Async:
de-congestion and yield management in cellular data networks. In submission, May 2013.
19. J. Murphy and L. Murphy. Bandwidth allocation by pricing in atm networks. In IFIP
TC6 Second International Conference on Broadband Communications II, pp. 333‚Äì351,
1994.
20. A. Ganesh, K. Laevens, and R. Steinberg. Congestion pricing and adaptation. In IEEE
INFOCOM, pp. 959‚Äì965. IEEE, 2001.
21. M. Roozbehani, M. Dahleh, and S. Mitter. Dynamic pricing and stabilization of supply
and demand in modern electric power grids. In International Conference on Smart Grid
Communications, pp. 543‚Äì548. IEEE, 2010.
22. P. Samadi, A. Mohsenian-Rad, R. Schober, V. W. S. Wong, and J. Jatskevich. Optimal
real-time pricing algorithm based on utility maximization for smart grid. In International
Conference on Smart Grid Communications, pp. 415‚Äì420. IEEE, 2010.
23. S. Ha, S. Sen, C. Joe-Wong, Y. Im, and M. Chiang. TUBE: time-dependent pricing for
mobile data. In ACM SIGCOMM, 2012.
24. 3GPP. TS 23.203 Policy and charging control architecture. http://www.3gpp.org/ftp/
Specs/html-info/23203.htm.
25. C. Peng, G.-H. Tu, C.-Y. Li, and S. Lu. Can we pay for what we get in 3g data access? In
Mobicom, 2012.
26. CVXOPT. Python Software for Convex Optimization. http://cvxopt.org. May 2014.


16
Mechanisms for Quota Aware
Video Adaptation
JIASI CHEN, AMITABHA GHOSH, and MUNG CHIANG‚àó
16.1
INTRODUCTION
16.1.1
Two Conflicting Trends
Two recent and conflicting trends in Internet applications motivate the discussion
in this work: video traffic becoming dominant and usage-based pricing becoming
prevalent.
Video Traffic Becoming Dominant. Video consumption is on the rise. For example,
Cisco predicts that 70% of all mobile traffic will be from video alone by 2016 [1].
Likewise, wireline traffic is also dominated by video, with NetFlix accounting for
almost 30% of wireline Internet traffic [2]. Together with YouTube, Netflix, Hulu,
HBO Go, iPad personalized video magazine apps, and news webpages with embed-
ded videos, video traffic is surging on both wireline and wireless Internet.
Usage-Based Pricing Becoming Prevalent. Tiered pricing, or usage-based pricing,
is becoming increasingly commonplace in the United States as well as in other coun-
tries for both wireless and wireline broadband. Table 16.1 compares the usage fees
from various international Internet Service Providers (ISPs).
These two trends, video traffic becoming dominant and usage-based pricing
becoming prevalent, are at odds with each other. On the one hand, videos, espe-
cially on high resolution devices (e.g., iPhone 5, iPad 3, and Android tablets),
consume much more data than other types of traffic. For instance, 15 min of
low bitrate YouTube video per day uses up 1 GB a month; likewise, one single
standard-definition movie can take up to 2 GB. On the other hand, usage-based
pricing threatens the business model of delivering entertainment via the high-speed
Long-Term Evolution (LTE). These factors can result in high overage charges by the
service provider, subscription to more expensive data plans, or even discontinuation
‚àóWork was done while the author was a postdoctoral research associate at the Princeton University.
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
415

416
MECHANISMS FOR QUOTA AWARE VIDEO ADAPTATION
TABLE 16.1
Usage Fees for Wireline and Wireless ISPs Around the World
Wireline/
Baseline
Overage
Carrier
Country
Wireless
Quota, GB
Charge
AT&T
USA
Wireless
2
10 USD per GB
Verizon
USA
Wireless
2
10 USD per GB
Reliance [3]
India
Wireless
2
0.01 Rupee per 10 kB
Rogers [4]
Canada
Wireline
80
2 CAD per GB
AT&T
USA
Wireline
250
10 USD per 50 GB
of data service by disgruntled users. Given this conflict, a natural question to ask
is: Can a consumer stay within his/her monthly data quota without suffering a
noticeable drop in video quality (distortion)?
16.1.2
Current Approaches in Practice
In today‚Äôs practice, there are two main approaches to balancing the competing goals
of delivering high quality video while consuming less data.
16.1.2.1
Decrease Video Consumption Through Self-Imposed Warnings Con-
sumers may be warned by (i) service providers or (ii) self-imposed warnings to stop
watching more videos once their usage-based charges become too high. In the first
case, consumer concern over ‚Äúbill shock‚Äù has resulted in legislation against service
providers. For example, the European Union passed regulations in 2010 requiring
mobile ISPs to provide warnings when a consumer has reached 80% of his/her quota
and to block data access once the usage fee reaches ‚Ç¨50 [5]. Similarly, the Federal
Communications Commission (FCC) worked with commercial ISPs on a program to
provide warnings to consumers when their data quota limits are reached [6].
Mobile applications that can report real-time data usage are also becoming increas-
ingly prevalent. External applications, such as Onavo and DataWiz, provide con-
sumers with attractive graphical user interfaces (GUIs) for monitoring data usage [7,
8]. Google also introduced a built-in data monitoring application in a recent version
of the Android operating system [9]. Overall, however, these straightforward warning
systems can be undesirable, as they could result in dissatisfied users.
16.1.2.2
Decrease Data Consumption by Lowering Video Quality Content
providers (CPs) can take a one size fits all approach of cutting back bitrates across
all video requests, for all users, and at all times. For example, the YouTube mobile
app automatically chooses a low quality video for requests made over a cellular
data network, versus high quality video when a WiFi connection is used. Netflix
implemented a similar approach in Canada in 2011 for both wireless and wireline
customers in the light of expensive usage-based charges by Canadian ISPs. Netflix
allows consumers to choose between three different qualities: low (0.3 GB/h),
medium (0.7 GB/h), and high (1 GB/h); however, this approach cuts down the

RELATED WORK
417
quality across all videos, without taking user preferences and remaining quota into
account.
16.2
RELATED WORK
In this section, we give a brief background on existing video adaptation techniques
and streaming protocols.
16.2.1
Video Adaptation
Video adaptation is the process of modifying a video to suit the user preferences,
usage environments, resource constraints, content characteristics, or digital rights
among other factors. In the context of this work, we consider video adaptation as
a possible solution to the conflict between the growing demand for video traffic
and usage-based data pricing. Adapting video quality with respect to resource
constraints and user utility has been extensively studied since the 1990s, as surveyed,
for example, by Chang and Vetra [10]. Liu et al. also considered video adaptation
to maximize users‚Äô quality of experience (QoE), using the control knobs of video
bitrate and content delivery network (CDN) selection [11].
16.2.2
Video Streaming Protocols
In order to perform video adaptation, the appropriate technologies must be enabled
in practice. The algorithms and systems to perform such video adaptation have long
been studied in the research community [11‚Äì14].
Traditionally, in practice, videos were streamed using the User Datagram Protocol
(UDP) because of their time-sensitive nature. More recently, video streaming over
the Hyper Text Transfer Protocol (HTTP) has become common, because of HTTP‚Äôs
widespread acceptance, its ability to traverse Network Address Translations (NATs),
and its support for caching at CDNs [15]. Various protocols, such as Scalable Video
Coding (SVC), have also been proposed [16]. With SVC, each video is encoded into
a base and multiple enhancement quality layers. Within the video, the video quality
may be modulated.
However, SVC never gained widespread adoption. Increasingly, but increasingly
interest from industry has focused on dynamic adaptive HTTP video streaming over
HTTP. Apple, Microsoft, and Adobe have developed proprietary HTTP video stream-
ing protocols that perform intra-video bitrate switching to adapt to varying channel
conditions. These protocols are supported by various web technologies:
‚Ä¢ Apple HTTP Live Streaming. Quicktime, iOS (iPhone, iPod Touch, iPad),
Android;
‚Ä¢ Microsoft Smooth Streaming. Microsoft Silverlight, also adopted by Netflix;
‚Ä¢ Adobe OSMF. Adobe Flash.

418
MECHANISMS FOR QUOTA AWARE VIDEO ADAPTATION
Recent progress by an industrial consortium has resulted in the Moving Picture
Experts Group‚ÄìDynamic Adaptive Streaming over HTTP (MPEG-DASH) stan-
dard [17], which aims to address the lack of interoperability between current video
streaming protocols by providing an open interface to access the quality levels
of a video. These lines of work still focus on modifying the video quality based
on channel conditions, but underscore the increasing interest, in both academia
and industry, in video adaptation technologies. Specifically, encoding and storing
multiple bitrate versions of each video enables video quality adaptation with respect
to each user‚Äôs data quota in the context of usage-based pricing.
16.2.3
Quota Aware Video Adaptation
Jan et al. [18] developed a system for compressing images on webpages under a data
quota. Although the motivation of addressing quota concerns is similar, its application
is only to images and webpages. Recently, systems such as Onavo [7] enable users
to save on data plans by forwarding all images and text data through a proxy server,
where they are compressed. However, they do not exploit consumer usage patterns or
deal with video traffic, which has a much larger range of compressibility (than images
and text) and comprises the bulk of mobile data consumption. These can provide
substantial additional data saving opportunity.
16.3
A POTENTIAL SOLUTION: QAVA
16.3.1
Trading off Quality Versus Cost Versus Volume
As a potential solution to the problem of video consumption under capped data plans,
we propose the QAVA (Quota Aware Video Adaptation) system. Our premise is the
following: Not every video bit is needed for every consumer and the bitrates can be
adjusted not only based on screen resolution and channel conditions but also based
on usage patterns. QAVA can be customized to each user‚Äôs demand and monthly data
quota by adaptively choosing an appropriate bitrate for each video request, thereby
shaping the supply for the user. We will show that by leveraging video compressibility
and profiling usage behavior, QAVA can significantly mitigate the conflict between
the growing demand for video traffic and usage-based pricing.
At the heart of QAVA is a Stream Selector (SS), which takes inputs from a User
Profiler (UP) and a Video Profiler (VP), to select a particular bitrate and pre-emptively
compress the more compressible videos early in the billing cycle. The VP provides
information related to a video, such as its compressibility, which measures the extent
to which the size of a video can be reduced without a significant distortion in quality.
The UP predicts consumer usage patterns from past history and customizes the sys-
tem to every user‚Äôs flavor for watching certain types of videos. The SS then uses the
information provided by both VP and UP to optimize QAVA for each user based on
his/her monthly data quota.
The benefits to a QAVA-enabled user include the ability to watch more videos
under a given monthly data plan without suffering a noticeable distortion in video

A POTENTIAL SOLUTION: QAVA
419
Cost
Distortion
Number of videos
Figure 16.1
A three-way trade-off between distortion, cost, and the number of videos
watched. For a fixed cost, QAVA enables a user to watch the desired videos while minimizing
distortion.
quality, as compared to a non-QAVA user. Or, phrased differently, if a user‚Äôs demand
for video traffic remains the same or goes down, QAVA tries to save money for the
user with a minimum impact on video quality. This three-way trade-off is illustrated
in Figure 16.1. Across the three competing goals of minimizing cost, maximizing
the number of videos watched, and minimizing distortion, QAVA strikes a graceful,
tunable trade-off.
16.3.2
Incentives for Players in QAVA Ecosystem
A natural question to our proposed approach is: What are the incentives for different
players in the ecosystem to use QAVA? We address this from the perspective of three
major players: users, ISPs, and CPs.
Users. A user has the most obvious incentive, because QAVA enables him/her to
stop worrying about his/her monthly data plan and watch all the videos he/she wants
with minimal distortion.
ISPs. An ISP has two options: it may wish to (i) reduce data traffic to lower network
congestion and thereby cut down on operational and capital expenditure costs, or (ii)
preserve traffic to continue receiving overage charges from customers and/or usage
fees from CPs. In the first case, QAVA ensures that all customers remain below their
quota, which indirectly lowers the traffic rate. In the second case, the ISP can set
quota parameter to ensure that its users still consume the same amount of data as
non-QAVA users but receive better video quality.
Content Providers. The advantages for a CP are threefold. Firstly, as QAVA allows
a user to access more content under the same data plan, the CP achieves a greater
profit from advertising revenue through increased content consumption. Secondly,
the CP improves customer satisfaction by removing his/her worries about exceeding
the quota, which can be marketed as a competitive advantage over other CPs. Thirdly,
QAVA reduces the potential need for the CP to pay the ISP for customer data charges.
QAVA is thus mutually advantageous from the perspectives of all three players.
In the remainder of this work, we discuss QAVA‚Äôs contribution along three different
dimensions:

420
MECHANISMS FOR QUOTA AWARE VIDEO ADAPTATION
‚Ä¢ Architecture. We design a modular system architecture for QAVA comprising
three functional modules: stream selector, user profiler, and video profiler. Our
design makes QAVA a deployable system that can be used by real-world con-
sumers.
‚Ä¢ Algorithms. We design an online bitrate selection algorithm for the SS module
based on the concepts of finite-horizon Markov Decision Process (MDP) [19].
This algorithm runs at the heart of QAVA, enabling it to provide a graceful,
tunable control of the quality, cost, and volume trade-off.
‚Ä¢ Experiments. We evaluate the performance of QAVA through simulations using
traces of real video requests.
16.3.3
Design Considerations
There are several alternatives and variants for designing the QAVA architecture. We
briefly describe these alternatives, their advantages and disadvantages, and our design
decisions.
16.3.3.1
Availability of Video Versions We assume that all the videos are
pre-encoded and stored on the CP‚Äôs server. An alternative to this is on-the-fly
transcoding and adaptation, which requires compressing each video dynamically at
the particular bitrate determined by the SS module. This can be a time-consuming
operation and has significant implementation challenges; however, it would be
capable of adapting video feeds for live events. In contrast, pre-encoded streams
can be selected with minimal computation but cannot handle video streams of live
events.
We also assume that the different versions of a video chosen by the SS module
are supported by the channel in terms of bandwidth requirement. These sustainable
video versions may be preselected by the content provider based on typical wireless or
wireline bandwidth, or chosen on-the-fly based on bandwidth estimation techniques
currently proposed for use in adaptive HTTP video streaming algorithms [14].
16.3.3.2
Time Scale of Video Adaptation There are two choices for the time scale
of video adaptation: (i) intervideo adaptation and (ii) intravideo adaptation. Intervideo
adaptation is choosing a single bitrate stream for the entire duration of the requested
video, whereas intravideo adaptation involves dividing each video into smaller clips
and choosing the correct adaptation operation for each clip.
Intervideo adaptation is suitable for video clips of short duration (e.g., Youtube
videos of less than 5 min), because the spatial and temporal activities tend to be sim-
ilar throughout the duration. However, for longer videos such as movies, it is more
appropriate to stream different bitrate versions for different parts of the video depend-
ing on the spatial and temporal activities. The algorithms presented in this work apply
equally to inter- or intravideo rate switching. QAVA can be used for intravideo adapta-
tion by considering each smaller segment as a separate video request. Such intravideo
switching requires synchronous bit stream switching, which can be achieved with the
advent of new video streaming protocols such as MPEG-DASH [17]. QAVA can also

QAVA SYSTEM DESIGN
421
work with existing channel-based switching algorithms by optimizing and restricting
the rates available as input to those algorithms.
16.3.3.3
Heterogeneous Data Quota. Data usage under a single data plan can be
decomposed into three usage layers: (i) multiple users, (ii) multiple devices per user,
and (iii) multiple traffic types per user per device. QAVA‚Äôs control knob is on video
traffic per user per device; thus the ‚Äúvideo quota‚Äù per device must be set. To accom-
modate non-video data traffic, the video quota should be set to a percentage of the
total data quota based on historical video data usage. Running QAVA per user is also
possible by aggregating video request logs across devices. This results in coarser
granularity user profiling but may improve the performance by decreasing sensitivity
to noise. For the remainder of this work, we focus on the case of a single fixed video
quota and a single user with a single device, but QAVA can easily be extended to
encompass the other cases just outlined.
16.4
QAVA SYSTEM DESIGN
16.4.1
A Modular Architecture Design
The architecture of QAVA comprises three different modules, each one is responsible
for a specific function. The modules work together to enable QAVA to optimize across
the three performance goals shown in Figure 16.1. We first describe the motivation
for each of the modules.
16.4.1.1
Selecting Right Bitrates The basic operation of QAVA is to choose an
appropriate bitrate for every video request made by a user. This bitrate selection is
based on two factors: (i) the user‚Äôs data consumption pattern and (ii) the particular
video requested. This job is performed by a Stream Selector (SS) module running
at the heart of QAVA on the CP‚Äôs server, as shown in Figure 16.2. We focus on the
pre-encoded bit stream scenario, where each video has multiple copies; each copy is
pre-encoded in a different bitrate and stored on the CP‚Äôs server. The number of copies
of different bitrates of a video is predetermined by the CP.
User
profiler
(online)
User device
Video request
Content provider‚Äôs
server
Video delivery at right bit rate
Access
network
Backbone
Stream
selector
(online)
Video
profiler
(offline)
Figure 16.2
QAVA‚Äôs modular system architecture: The UP module sits on a user device,
whereas the SS and VP modules are located on a content provider‚Äôs server. A video request
originating from a user device travels through the access network and the backbone to the
server, which then runs a stream selection algorithm to choose an appropriate bitrate to deliver
to the user.

422
MECHANISMS FOR QUOTA AWARE VIDEO ADAPTATION
16.4.1.2
Profiling Usage Behavior A user‚Äôs past data consumption history gives
an indication of his/her future usage pattern. As the video requests from a user can
arrive at different times without any prior knowledge, a prediction of these arrival
times is helpful to QAVA so it can choose the appropriate bitrates to serve the requests.
A simple usage pattern could be watching on an average xd number of videos (or,
equivalently, yd bytes) on day d of a week. When the number xd (or yd) remains
approximately the same for the same day d across different weeks, we may notice a
weekly pattern. More complex usage behavior can lead to small-scale seasonal varia-
tions (daily or hourly) as well as trends, which are long-term variations due to habitual
changes that lead to a steady increase or decrease in data usage over months or years.
QAVA employs a user profiler (UP) module to find patterns in usage behavior and
to predict future video requests. In particular, the UP module estimates the probabil-
ity of a video request arriving in a given time interval. The length of this interval can
be uniform or variable depending on the past data consumption history and is config-
ured by a system parameter. We design the UP module as an application that can be
installed on a user device (client), as shown in Figure 16.2.
16.4.1.3
Estimating Video Compressibility In addition to staying within a
monthly data quota, the SS algorithm also aims to minimize video distortion.
For this, the algorithm needs to know to what extent the requested video can be
compressed and how much distortion it would cause in doing so. Different videos
have different levels of compressibility depending on their spatial and temporal
activities as well as on the choice of encoder. For example, a talk show that has very
little motion in it can be greatly compressed using an H.264/AVC encoder, whereas
a motion-rich sports video may not be compressible to the same extent.
The SS algorithm should be careful in choosing the right bitrate for every video
request to avoid the following undesirable situation. Suppose the algorithm chooses
a high bitrate for an easily compressible video when the user has a lot of quota left,
possibly in the beginning of a month. Then it might be forced to choose low bitrates
for some not-so-easily compressible videos near the end of the billing cycle in order to
stay within the monthly budget, thus causing significant distortion. A possible remedy
is to choose low bitrates for easily compressible videos even when there is sufficient
quota left. However, such intelligent online decisions can be made only if the system
knows about the distortion versus bitrate trade-off for every video and can learn the
quota consumption pattern over a billing cycle for each user. QAVA employs an offline
video profiler (VP) module to compute this distortion for every bitrate and store it on
the CP‚Äôs server, as shown in Figure 16.2.
We now summarize the three modules of QAVA.
‚Ä¢ Stream Selector (SS). The SS module is at the heart of QAVA and is located on
the CP‚Äôs server. It is an online module that decides the right bitrate for every
video request.
‚Ä¢ User Profiler (UP). The UP module predicts the probability of future video
requests from past usage history and also computes a user-specific distribution

QAVA SYSTEM DESIGN
423
of video types reflecting a user‚Äôs taste of watching different types of videos. It
is an online module and is located on the user device.
‚Ä¢ Video Profiler (VP). The VP module is located on the CP‚Äôs server and is an
offline entity. It computes the distortion for every bitrate version of all the stored
videos. We loosely call this the ‚Äúcompressibility‚Äù of the videos.
Other types of module separation and interconnections are also possible. For
example, the VP and SS modules can be combined into a single module performing
joint optimization. The SS requests videos of a certain compressibility, and the VP
optimizes over various codecs to generate videos with desired characteristics. This
would provide a finer decision granularity to the SS, but is computationally complex
as the VP also runs video encoding operations.
16.4.2
Module Placement
In this section, we discuss the location of the various modules in QAVA. Although
we refer to the specific modules of QAVA, our discussion of SS module placement is
applicable to any general video adaptation system that makes online decisions.
The placement of the UP and VP modules is fairly intuitive: by necessity, the VP
module is located on the CP‚Äôs server, as only the CP knows about the video charac-
teristics. Profiling the video on the user device is not feasible because of the CPU
(central processing unit) and battery limitations. The UP module logs user data, so
it should be placed on the user device to alleviate user concerns over data collection
and privacy. The placement of VP and UP modules is shown in Figure 16.2.
16.4.2.1
ContentProvider-Based or ISP-Based Architectures The location of the
SS module that runs the bitrate selection algorithm is, however, not so intuitive. For
every video request, the SS module requires inputs from both UP and VP. One possi-
bility is to place the SS module in the ISP‚Äôs access network. Then, in order to satisfy
a video request, the SS module first needs the video compressibility information to
be sent from the CP, as well as user information from the UP module. After receiv-
ing these inputs, the SS module runs the SS algorithm to choose the right bitrate. It
then sends another request to the server to transmit the actual video in the selected
bitrate. Overall, this results in unnecessary messages and potential delay, which is
undesirable for delay-sensitive traffic such as video.
Alternatively, the SS module could be placed on the CP‚Äôs server. In order to satisfy
a video request, the SS module still needs user information from the UP module but
already has access to information from the colocated VP. The selected bitrate can thus
be transmitted immediately after the SS algorithm is run. As this reduces the amount
of message passing, placing the SS module on the CP is more desirable. This also
makes QAVA complementary to other video adaptation approaches [11].
Placing the SS and VP modules on the CP‚Äôs server incurs some monetary cost
to the CP, which must be overcome by the advantages discussed in Section 16.3.2.
We argue that the cost to the CP is small: it must install the SS module on its server
(one time) and compute the video profiles of all videos (a small amount of text data

424
MECHANISMS FOR QUOTA AWARE VIDEO ADAPTATION
compared to video data size). And regardless of where the SS module is placed, our
algorithms are equally applicable.
16.4.2.2
Client-Based Architectures In case QAVA operates without the support
from a CP or an ISP, client-based architectures are possible. We discuss two potential
architectures: (i) a transcoding-based system and (ii) a throttling-based system.
In a transcoding-based solution, all traffic from the client is routed through a web
proxy. By inspecting the packets, video traffic can be distinguished and transcoded on
the fly by the proxy server to the correct bitrate. This approach has the advantage of
using standard web proxy technology and can handle all types of videos as long as the
transcoder has the appropriate codecs. However, there are significant implementation
challenges in terms of latency minimization: the proxy and transcoder must perform
quickly in order to satisfy the demands of delay-sensitive video traffic. Moreover,
implementing a transcoder for HTTP video streaming is also difficult.
A throttling-based solution leverages the emerging popularity of adaptive HTTP
video streaming [17]. In this technology, the videos automatically adjust their bitrates
based on their estimates of TCP throughput. By limiting the bandwidth observed by
the rate switching algorithm, QAVA can force the video bitrates to automatically settle
to the rates determined by the SS module. This throttling can be performed on the
client device or on a web proxy. In terms of implementation, this approach is simpler
than the transcoding-based solution but suffers from the limitation that only adaptive
HTTP video streams can be modified in this way.
16.4.3
QAVA Operational Example
In this work, we focus on the case where the SS module is located on the CP‚Äôs
server. The following description does not change significantly for other placement
options. The relationship between the different modules describing their inputs, out-
puts, and update frequencies is shown in Table 16.2. The input to the SS module
is the compressibility of the requested video, the user‚Äôs remaining monthly budget,
and the user‚Äôs profile as determined by the UP module. For every request, it runs the
stream selection algorithm and outputs the selected bitrate version. The input to the
VP module is the set of all videos stored on the CP‚Äôs server, and its output is the com-
pressibility of each video. The input to the UP module is the time stamps for the user‚Äôs
past video requests, as well as the compressibility of those videos. Its output is the
predicted video request probability and the video type distribution (i.e., compressibil-
ity distribution) specific to that user. These quantities characterize the user‚Äôs behavior
and are fed to the SS module. These predictions can be made in the beginning of the
billing cycle, or updated more periodically throughout the billing cycle.
To be concrete, we give an operational example.
1. The CP computes and stores the compressibility of all the videos on the server.
2. At the beginning of a billing cycle, the UP makes predictions (to be used in the
current cycle) of the video request probability and the compressibility distribu-
tion, based on its log of the past requests of a user.

STREAM SELECTION
425
TABLE 16.2
Three Key Functional Modules of QAVA with Their Inputs, Outputs,
and Update Frequency
Module
Input
Output
Frequency
SS
Compressibility of
video request,
remaining monthly
budget, and the user
profile
Selected bitrate version to
deliver for the video
request
Every
request
UP
Time stamps and
compressibility of all
past video requests
Probability of a video
request arriving at a time
interval, and the video
compressibility
distribution for all past
requests. Together these
comprise the user profile
Every
billing
cycle
VP
All videos stored in the
content provider‚Äôs
server
Compressibility of all
videos
Offline
Abbreviations: SS, stream selector; UP, user profiler; VP, video profiler.
3. When a user requests a video in his/her current billing cycle, the request is sent
to the SS module, which selects the bitrate to be delivered. The CP also sends the
compressibility of the requested video to the UP. The UP logs this as well as the
timestamp of the request.
4. Once the current billing cycle is over, the UP updates its predictions based on the
recent request logs. Steps 2‚Äì4 repeat for the next billing cycle.
16.5
STREAM SELECTION
In this section, we first describe the video request, utility, and cost model and then
formulate the bitrate selection problem. We also introduce the key notation, as sum-
marized in Table 16.3.
16.5.1
Video Request, Utility, and Cost Model
We divide the length of a billing cycle (e.g., month) into T time intervals, indexed by
t = 1, ‚Ä¶ , T, and assume that a user has a total budget B (measured in bytes) in one
billing cycle. In each time interval t, a video request arrives with a certain probability,
denoted by pt. The remaining budget of the user at time t is bt. The request probability
pt and budget bt are provided by the UP module for each user.
Each video is encoded into M different bitrates, indexed by j = 1, ‚Ä¶ , M. Associ-
ated with each video request arriving at time t is a vector of utilities ùêÆt = (ut1, ‚Ä¶ , utM)

426
MECHANISMS FOR QUOTA AWARE VIDEO ADAPTATION
TABLE 16.3
Table of Key Notation
Symbol
Meaning
utj
Utility of bitrate version j for a video request arriving at t
ctj
Cost of bitrate version j for a video request arriving at t
xtj
Indicator variable (1 if bitrate j is chosen for video request at t; 0
otherwise)
M
Number of bitrates for each video
T
Number of time intervals in a billing cycle
P(ùêÆ, ùêú)
User-specific joint probability distribution of video types based on
past history.
pt
Probability of a video request arrival at t
bt
Remaining user budget at t
B
Total user budget in one billing cycle
and a vector of costs ùêút = (ct1, ‚Ä¶ , ctM) for different bitrate versions of the video.1
When there is no video request arrival at time t, the vectors ùêÆt and ùêút are null vectors
with all components being zero, because then no bitrate is selected. The VP module
provides the utility and cost of each video, ùêÆt and ùêút, respectively.
Each user might prefer different types of videos with different compressibilities.
For example, he/she might want to watch news clips that have different compress-
ibilities than sports videos. To capture this effect, we introduce a joint probability
distribution P(ùêÆ, ùêú), which is user specific and represents the probability that a user
requests videos with certain utility‚Äìcost characteristics. This distribution is provided
by the UP module for each user.
In Figure 16.3, we show a typical utility versus cost function for a video encoded
using the H.264/AVC codec with a resolution of 720 √ó 480 pixels. Such utility‚Äìcost
10
20
30
40
25
30
35
40
45
Cost (MB)
Utility (PSNR in dB)
Figure 16.3
Video utility versus cost showing diminishing returns for increasing cost. The
x-axis represents the size of the video when encoded from 100 to 900 Kbps in 100 Kbps incre-
ments.
1We note that these utility and cost vectors are fixed and not time dependent. The use of the time index t
in utj and ctj is purely for the ease of exposition.

STREAM SELECTION
427
curves are usually concave with diminishing returns for utility at higher cost (or
equivalently, higher bitrate, as bitrate is proportional to data size for a fixed-length
video). A video with a flat utility‚Äìcost curve is ‚Äúeasily compressible,‚Äù because low-
ering the bitrate decreases the utility only slightly. In contrast, a ‚Äúhard-to-compress‚Äù
video has a steep curve. We measure the utility utj of bitrate version j as its peak
signal-to-noise ratio (PSNR) √ó the duration of the video [20]. The cost cij is the size
in bytes. Discussion of the utility and cost metrics is reserved for Section 16.6.2.
16.5.2
Stream Selection as Knapsack Problems
We now formulate the problem of choosing the right bitrate by the SS module as
different versions of the well-known knapsack problem [21] studied in combinatorial
optimization. We first present an offline formulation, which is easy to understand, and
then motivate the need for an online stochastic formulation.
16.5.2.1
Offline Multiple-Choice Knapsack Problem The goal of the stream
selector is to choose the right bitrate for every video request made by a user in
a single billing cycle. We aim to maximize the sum of the utilities across all the
video requests without exceeding the user‚Äôs quota. In other words, we maximize the
average video utility. An alternative formulation is to maximize the minimum utility
across all videos requested during the billing cycle. However, as the high level goal
of QAVA is to maximize the overall user satisfaction, we optimize the average utility
over time instead of the worst-case experience, as in the alternative formulation.
For a video request arriving at time t, we define a decision vector ùê±t =
(xt1, ‚Ä¶ , xtM), where each xtj takes the value 1 if bitrate version j is chosen and 0
otherwise. Then our problem is
maximize
T
‚àë
t=1
M
‚àë
j=1
utjxtj
subject to
T
‚àë
t=1
M
‚àë
j=1
ctjxtj ‚â§B
M
‚àë
j=1
xtj = 1, ‚àÄt
variables
xtj ‚àà{0, 1}, ‚àÄt, j,
(16.1)
where the first constraint says that the cost of the selected bitrates for all the videos
requested in a billing cycle must not exceed the total budget B, and the second con-
straint says that only one bitrate version may be selected for each video.
This optimization problem is known as the multiple-choice knapsack problem
(MCKP) [21]. In the regular single-choice knapsack problem, we are given a set of

428
MECHANISMS FOR QUOTA AWARE VIDEO ADAPTATION
items, each with an associated value and weight. The objective is to pick a subset
of the items such that the total value is maximized while not exceeding the knap-
sack capacity. In our stream selection problem, the items are the individual bitrate
versions of the videos, and the multiple choices arise because exactly one version of
each video must be selected.
The traditional offline version of MCKP, where all the input items are known
in advance, is well studied. The problem is NP-hard, but pseudo-polynomial time
dynamic programming (DP) solutions exist [21]. Contrary to this offline version, the
SS module does not know the video requests in advance, and so needs to make deci-
sions in an online manner. This requires a modification to the above formulation to
handle online requests.
16.5.2.2
Online Stochastic Knapsack Problem Unlike the traditional offline
MCKP, in our scenario, the video requests are revealed one by one in an online
manner. Thus, existing DP solutions to the offline knapsack problem cannot be used.
Online algorithms handle this situation by making a decision on the fly when a
new video request arrives, without any prior knowledge of future requests. Once a
decision is made, it cannot be revoked or changed in the future.
As the data quota is reset after a billing cycle is over, there is a time deadline before
which all the actions must be made. We also note that the bitrate decisions for future
intervals should not depend on the decisions taken at previous intervals, given the cur-
rent remaining budget. This implies the Markov property. The problem can naturally
be modeled as a finite-horizon MDP. A key assumption is that the video requests are
independent of time and, therefore, the transition probabilities are stationary.
The MDP formulation allows the SS module to make foresighted bitrate selec-
tion decisions by taking into account the future impact of its current decisions on the
long-term utility. This is better than just an online algorithm that makes myopic deci-
sions at every time step. For example, a greedy solution might choose a bitrate that
maximizes only the utility of the current request without overshooting the quota.
Figure 16.4 shows a simple example of choosing between three different
bitrates over one time step. The state of the system is defined as the four-tuple
st = (t, bt, ùêÆt, ùêút), comprising the current time interval t, the remaining quota bt, and
the utility and cost vectors ùêÆt and ùêút, respectively. There are three possible actions:
(i) choose the lowest bitrate, that is, ùê±t = (1, 0, 0); (ii) choose the second bitrate, that
is, ùê±t = (0, 1, 0); or (iii) choose the third bitrate, that is, ùê±t = (0, 0, 1). If the lowest
bitrate is chosen, the system moves to time t + 1 with remaining budget bt ‚àíct1. The
algorithm collects utility (reward) ut1 and receives the new video request with utility
and cost vectors ùêÆt+1 and ùêút+1. If the second bitrate is chosen, the system moves to
time t + 1 but now subtracts the cost ct2 from its remaining budget, leaving it with
bt ‚àíct2. It also collects utility ut2. A similar state transition results from choosing
the third bitrate.
The set of actions {ùê±1, ‚Ä¶ , ùê±T} taken by the algorithm at every time step is called
a policy. A policy that solves the MCKP of Eq. (16.1) is called an optimal pol-
icy. If the arriving video requests are known, an optimal policy can be determined
using the traditional offline techniques previously mentioned. However, because the

STREAM SELECTION
429
(t,
bt,
ut,
ct)
xt = (1,0,0)
xt = (0,1,0)
xt = (0,0,1)
(t +1,
bt‚àí
ct1,
ut+1,
ct+1)
(t +1,
bt‚àí
ct2,
ut+1,
ct+1)
(t +1,
bt‚àí
ct3,
ut+1,
ct+1)
Figure 16.4
Stream selection modeled as a finite-horizon Markov decision process. A one
step state transition is shown with three bitrate choices.
video requests are not known a priori, the MDP finds a policy that instead maxi-
mizes the expected sum of the utilities. We develop a solution using DP and online
optimization.
16.5.3
Solving Finite-Horizon Markov Decision Process
The optimal policy can be found using the well-known backward induction tech-
niques for finite-horizon MDPs [19]. We first define Ut(bt) as the expected utility
accumulated from time t until the end of the billing cycle at time T, when the remain-
ing quota is bt. This expected utility assumes that the optimal action is applied in each
state. Then, the optimal action at each time step t is found by solving
maximize
utjxtj + Ut+1(bt ‚àíctjxtj)
subject to
ctjxtj ‚â§bt
M
‚àë
j=1
xtj = 1
variables
xtj ‚àà{0, 1}, ‚àÄj,
(16.2)
where the first constraint ensures that the cost of the selected bitrate is less than the
remaining quota. The objective function has an intuitive meaning: it maximizes the
current utility plus the sum of the expected utilities, subject to the remaining quota.
The problem can be solved in O(M) time by discarding the bitrates that violate the
constraints and then picking the bitrate j‚àóthat maximizes the objective function. It is
solved every time a video is requested.
Solving Eq. (16.2) requires the computation of Ut(bt). It can be shown that the
solution can be found by dynamic programming using
Ut(bt) = pt
(utj‚àó+ E(ùêÆ,ùêú)
[Ut+1
(bt ‚àíctj‚àó
)]) + (1 ‚àípt
) Ut+1(bt),
(16.3)

430
MECHANISMS FOR QUOTA AWARE VIDEO ADAPTATION
with boundary condition is that the expected accumulated utility is 0 when the billing
cycle is over, or the remaining budget is less than 0 [22]. In this work, we choose the
budget granularity to be 1, so bt takes on possible values 1, ‚Ä¶ , B. The running time of
computing the U(‚ãÖ) matrix is O(TBMŒì), where Œì is the cardinality of the set {(ùêÆ, ùêú)}
in the video type distribution.
The online and offline components of the MDP stream selection algorithm are
summarized in Algorithm 16.1. In the special case of two bitrates (M = 2), our algo-
rithm reduces to that of Papastavrou et al. [23]. With accurate user and video profiling,
Algorithm 16.1 maximizes the sum utility while staying under the quota. In the case
of inaccurate inputs, however, the algorithm may exceed the quota. In that case, the
algorithm should simply choose the lowest bitrate, although this case never occurs in
our numerical simulations.
Algorithm 16.1
MDP Stream Selection Algorithm
DP Computation of Utility Matrix
Input: Video type distribution P(ùêÆ, ùêú), quota B, and billing cycle length T.
Output: A matrix ùêîof size T √ó B.
1. Initialize Ut(bt) = 0, ‚àÄt > T, bt < 0.
2. Compute each entry Ut(bt) of ùêî, using (16.3).
Online Bitrate Selection
Input: Utility‚Äìcost vectors ùêÆt and ùêút, remaining budget bt, quota B, billing cycle
length T, and matrix ùêî.
Output: Optimal bitrate j‚àó.
if bt < 0
Choose j‚àó= 1.
else
Discard the bitrates with cost greater than bt.
Compute j‚àóthat maximizes the objective function of (16.2).
end
Update bt+1 = bt ‚àíctj‚àó.
16.6
USER AND VIDEO PROFILERS
In this section, we detail the functionality of the UP and VP modules. We first describe
different patterns in user behavior and tastes and then propose the UP algorithm. The
VP module is also briefly explained.
16.6.1
Profiling User Behavior
The UP runs on the client device and characterizes each user through (i) the video
request probability at each time interval and (ii) the distribution of video types pre-
ferred by the user.

USER AND VIDEO PROFILERS
431
16.6.1.1
User Viewing Pattern and Taste Depending on their lifestyles, different
users have different time preferences for watching videos. For example, some users
prefer watching videos on weekends rather than on weekdays, whereas others watch
more in the evening after working hours than in the mornings. The taste in content
of the users can also be different. For example, some users watch sports videos more
often than movie trailers, whereas some others watch more news clips than music
videos. Such preferences in user behavior can lead to well-defined patterns, in terms
of both the viewing times and the types of the videos being watched.
The job of the UP is to estimate these temporal viewing patterns and video type
preferences for each user. The UP module does this based on the user‚Äôs past video
request records, spanning either the previous billing cycle or the entire history. In this
work, we consider requests from the last billing cycle.
16.6.1.2
Computing Video Request Probability In each time interval t, there is a
certain probability pt that the user requests a video. This request probability can either
vary with each interval or be constant. As a first attempt, we compute the average
request probability per interval, and set pt for each interval equal to this average. The
average request probability is computed by summing the number of requests in the
previous billing cycle and dividing by the number of periods T. The time interval
should be set small enough so that the average request probability is less than 1 but
not so small as to inhibit the computation of Eq. (16.3).
There are several alternative approaches, including fitting distributions and
prediction-based techniques. The arrival rate of videos might follow a particular
known distribution (e.g., Poisson), in which case the probability of an arrival can be
computed directly from the distribution itself. Alternatively, one can use more sophis-
ticated time series analysis techniques. For example, at the beginning of the billing
cycle, one can predict the sequence of future viewing times in the upcoming billing
cycle and then compute the average request probability by adding up the predicted
number of requests and finally dividing that by the number of intervals. One can also
design online algorithms, such as predicting the sequence of viewing times for inter-
vals t + 1, t + 2, ‚Ä¶ , T, while at interval t, and updating the predictions when a new
video request arrives. Such alternatives trade off accuracy versus computation need.
We have developed one such online algorithm based on ‚Äútriple exponential
smoothing‚Äù [24]. However, here we will employ the simple averaging technique
previously mentioned. The resulting computation requires less memory and power
and can be performed easily on a resource-constrained (in terms of battery and
memory) client device. Our goal is not necessarily to develop the best UP but to
find a method that works well in the system as a whole. To establish this, we run
trace-driven simulations in Section 16.7 to compare the performance of QAVA when
the UP module uses the average request probability, to a scenario when the UP
module has perfect knowledge of future arrivals. We find that our technique, while
simple, achieves close to optimal performance (more than 95% on an average).
16.6.1.3
Computing Video Type Distribution The joint probability distribution
P(ùêÆ, ùêú) reflects a user‚Äôs preference for watching different types of videos. For

432
MECHANISMS FOR QUOTA AWARE VIDEO ADAPTATION
example, a user who watches a lot of sports videos (which are not so compressible)
will have a different distribution from a user who watches a lot of talk shows (more
compressible). This video type distribution can remain the same over the length
of a billing cycle, or can be time dependent, reflecting, for instance, the fact that a
user watches more sports videos at night and more news clips in the morning. As
a first-order approximation, we assume that the distribution does not change with
time. The distribution is computed once at the beginning of a billing cycle based on
the video requests in the last billing cycle.
Our method is as follows: Each video request arriving at time interval t in the pre-
vious billing cycle has a (ùêÆt, ùêút) pair associated with it. The probability distribution is
calculated by counting the frequency of each (ùêÆt, ùêút) pair from the last billing cycle
and then normalizing appropriately to form a probability distribution. As the util-
ity and cost are continuous variables, they can be binned for greater computational
efficiency; however, in our dataset, we find this optimization unnecessary. Through
simulation, we show that this estimate performs very well, compared to the ideal sce-
nario when the distribution of the requested videos is perfectly known ahead of time.
Our user profiling algorithms are summarized in Algorithm 16.2.
Algorithm 16.2
User Profiling Algorithm
Input: Time stamps and utility‚Äìcost vectors (ùêÆt, ùêút) of each video request in the pre-
vious billing cycle.
Output: Video request probability pt, ‚àÄt, and the video type joint probability distri-
bution P(ùêÆ, ùêú).
1. Count the number of requests nr, and the number of time intervals T in the last
billing cycle.
2. Compute average request probability as p = nr‚àïT, and set pt = p, ‚àÄt.
3. Count the number of times each (ùêÆt, ùêút) pair appears in the past; denote this count
by n(ùêÆt,ùêút).
4. Construct the joint probability distribution by computing the individual
probabilities as p(ùêÆt, ùêút) = n(ùêÆt,ùêút)‚àï‚àë
(ùêÆ‚Ä≤
t,ùêú‚Ä≤
t) n(ùêÆ‚Ä≤
t,ùêú‚Ä≤
t)
16.6.2
Profiling Video Cost and Utility
The purpose of the VP running on the VP module is to estimate the utility and cost for
all the bitrate versions of all videos stored on the CP‚Äôs server. There are many estima-
tion techniques for computing the quality of a video. One standard objective metric is
the PSNR, which we employ. The PSNR is a well-known objective metric for measur-
ing video quality. A video typically comprises a sequence of images, and the PSNR
for each image is defined as a function of the mean square error (MSE) between the
original and compressed image. Mathematically, it is expressed in the logarithmic unit
of decibel (dB) as PSNR = 10 log10(Q2‚àïD), where D is the pixel-wise MSE between
the original and reconstructed image and Q is the maximum pixel value (usually 255).

PERFORMANCE EVALUATION
433
We compute the video PSNR as the PSNR averaged over all images in the sequence.
Typical PSNR values for lossy video compression are between 20 and 30 dB, where
higher is better. To account for the duration of the video, we set the utility equal to the
PSNR √ó the video duration. An example utility‚Äìcost curve is shown in Figure 16.3.
There exist other, potentially more accurate, metrics of video utility (e.g., mean
opinion scores or MOS [25]), as well as means of calculating subjective metrics
from objective measurements [26‚Äì28]. However, we choose PSNR as it can be
easily computed using a mathematical formula (in contrast to MOS that requires
time-consuming human experiments) and is very well known to the multimedia
community.
Measuring the cost of a video in bytes naturally follows from the fact that the data
quota is measured in bytes. The VP calculates the utility and the cost in megabytes
for all the videos only once. These utility and cost vectors are stored alongside the
videos on the CP‚Äôs server.
16.7
PERFORMANCE EVALUATION
We evaluate the performance of QAVA stream selection by comparing it with three
alternatives: (i) a hindsight-based offline, optimal algorithm that knows all the video
requests in a billing cycle ahead of time; (ii) a worst-case online algorithm; and (iii)
a na¬®ƒ±ve method (used by, e.g., Netflix). We also explore the sensitivity of QAVA to
UP prediction errors.
16.7.1
Experimental Setup
Our simulations are based on the public-domain traces of 2 weeks of YouTube video
requests from a wireless campus network [29]. The data comprises 16,337 users mak-
ing a total of 611,968 requests over 14 days. YouTube is the largest source of video
traffic, so the dataset captures a major portion of video viewing behavior [2]. The
first week of trace data is used to train both VP and UP. The second week emulates a
billing cycle where the stream selector is run for each user‚Äôs requests.
Each video is encoded in H.264/AVC at 100, 200, 300, 400, and 500 Kbps. The
stream selector chooses one bitrate from the first four choices. The 500 Kbps version
is treated as a reference for computing the PSNR of the other bitrates. The cost of each
video is its size in megabytes. We set the user‚Äôs quota at the halfway point between
the minimum data usage (always selecting 100 Kbps) and the maximum data usage
(always selecting 400 Kbps) and also sweep across quotas when appropriate. The
period length is set to 30 min, as we experimentally find that varying the period length
does not greatly change system performance.
One limitation of this evaluation is that not all videos were available from YouTube
at the time of this study. In the training phase, missing videos are not included while
generating the video type probability distribution. In the test phase, the utility‚Äìcost
curves of missing videos are sampled from the video type distribution of the training
phase. This gives an advantage to our algorithm, because the probability distribution
of the training phase is similar to that of the test phase. We also examine the effect of
mis-estimation of the distribution.

434
MECHANISMS FOR QUOTA AWARE VIDEO ADAPTATION
16.7.2
Comparing Stream Selection Algorithms
We first evaluate the offline algorithm that solves problem (16.1) with the knowledge
of all future video requests. It achieves the best possible performance and is treated as
the benchmark against which we compare the performance of the online algorithms.
We call this the hindsight offline optimal algorithm.
Zhou et al. [30] present an online algorithm to solve Eq. (16.1) with a worst-case
performance guarantee regardless of the sequence of video requests. We call this
the online MCKP algorithm and chose this to compare with our MDP algorithm
because it optimizes for the worst-case performance, while our algorithm optimizes
for expected performance. The MCKP algorithm, however, uses less information than
our MDP algorithm, needing only the maximum and minimum utility-to-cost ratio
across all requested videos, and an estimate of the sum data of the smallest bitrates.
The MCKP algorithm does not use prediction or time deadlines but requires only the
quota.
The second online algorithm we compare with is the na¬®ƒ±ve solution currently used
by Netflix. Netflix allows subscribers to select a default streaming bitrate. We assume
that a Netflix user chooses one bitrate for the entire billing cycle and is also intelli-
gent enough to presciently choose the maximum bitrate that fits all videos in the
quota. Clearly, this algorithm is an ideal algorithm and not suitable for practical
use, because it assumes advance knowledge of the number of videos to be watched.
Comparison with this Netflix method allows us to evaluate how our MDP algorithm
performs against an existing practical solution.
16.7.3
Single-User Examples
To understand the operation of the stream selector, we first run the algorithm for a
single user with a target quota of 1426 MB (see Fig. 16.5). The video requests arrive
in bursts, and each algorithm selects the bitrate of each video. The Netflix method
always chooses 200 Kbps. The MDP algorithm has foresight and thus chooses lower
bitrates in the beginning of the billing cycle, knowing to save for later. The MCKP
algorithm does not use time deadlines, only the remaining quota, and so it chooses
high bitrates in the beginning before cutting back as it starts depleting the quota. The
offline optimal algorithm chooses a variety of bitrates over time.
We also sweep across different monthly quotas and measure the utility obtained
by each algorithm (see Fig. 16.6). The offline algorithm performs the best, with MDP
and MCKP close behind. The Netflix method exhibits a staircase-like shape, because
as the quota increases, the default user-selected bitrate can increase. In all cases, the
algorithms use less data than the target quota.
16.7.4
Multiuser Stream Selection
16.7.4.1
Average Performance We now present the evaluation results of the MDP
algorithm for multiple users. Each trial takes as input a fixed set of video requests
and a quota and computes the utility obtained by each algorithm. Some input combi-
nations achieve higher utility than others. In order to fairly compare across multiple

PERFORMANCE EVALUATION
435
0
100
200
0
200
400
Bitrates (MDP)
0
200
400
Bitrates (MDKP)
Time (h)
0
100
200
Time (h)
 
 
0
100
200
0
200
400
Bitrates (Netflix)
Time (h)
0
100
200
Time (h)
0
200
400
Bitrates (offline)
Figure 16.5
Bit rate selection by different algorithms for a single user. The MDP and MCKP
algorithms choose different bitrates over time, while Netflix chooses a constant bitrate and the
offline algorithm chooses the optimal bitrates.
800
1000
1200
1400
1600
1800
2000
2200
3500
4000
4500
Utility
 
 
Quota (MB)
MDP
MCKP
Netflix
Hindsight offline optimal
Figure 16.6
Quality‚Äìcost trade-off for a single user with different quota and fixed video
requests. MDP obtains close to optimal utility, while MCKP and Netflix perform suboptimally.
trials, we normalize the utility across different users by measuring the utility of the
online algorithm as a fraction of the offline optimal utility. To normalize the quota,
we measure data as a fraction of the total data if the 400 Kbps bitrate were always
selected.
Figure 16.7 shows the average utility across 10 different users. We observe that,
on an average, the MDP algorithm performs better than the MCKP algorithm. The
Netflix method resembles a staircase function as in the single-user case and obtains
especially low utility for low quotas. This is arguably the most important scenario:

436
MECHANISMS FOR QUOTA AWARE VIDEO ADAPTATION
 
 
0.4
0.5
0.6
0.7
0.8
0.9
1
0.85
0.9
0.95
1
Normalized quota
% of Optimal utility
MCKP
Netflix
MDP
Figure 16.7
Quality‚Äìcost trade-off averaged and normalized over multiple users. The MDP
algorithm achieves nearly optimal performance, with the MCKP algorithm close behind. Both
algorithms outperform the na¬®ƒ±ve Netflix method.
When the user‚Äôs quota is small compared to the number of videos he/she wishes to
watch. For these low quotas, the MDP has a definite advantage over MCKP, which in
turn outperforms the Netflix method.
16.7.4.2
Performance Variability To examine the utility distribution, and not just
the average, we plot their cumulative distribution functions (CDFs) in Figure 16.8a
across multiple quotas and users. The ideal result is a step function at 1, indicating
100% of the trials result in optimal utility. We see the Netflix method performs the
worst, obtaining, for example, less than 95% utility in 50% of the time. The MCKP
curve is steeper, indicating it has less performance variation, which makes intuitive
sense as the algorithm optimizes for the worst case. The MDP algorithm optimizes for
the average-case performance but not the spread and thus exhibits greater variation
but is closer to the ideal step function.
0.85
0.9
0.95
1
0
0.2
0.4
0.6
0.8
1
CDF
 
 
MDP
MCKP
Netflix
(a)
1
CDF
0.8
0.6
0.4
0.2
0‚àí5
0
5
MDP vs MCKP utility % difference
(b)
% of optimal utility
Figure 16.8
(a) CDF of the utility achieved by MDP, MCKP, and Netflix algorithms. (b)
Distribution of MDP performance improvement over MCKP.

PERFORMANCE EVALUATION
437
The MDP and MCKP algorithms are further compared in Figure 16.8b, which
shows the CDF of their percentage utility difference. If the MDP were always bet-
ter than the MCKP, we would see a step function at 0. However, we observe that
the MCKP sometimes outperforms the MDP algorithm. This may occur because the
MCKP optimizes for worst-case performance, so when a user‚Äôs behavior exhibits high
variability, the MCKP is better able to handle the user‚Äôs requests.
On the surface, these simulations seem to suggest the Netflix method performs
reasonably well in general. It achieves above 85% of the optimal utility, suggest-
ing that this na¬®ƒ±ve solution is acceptable for most users. However, the caveat is that
our simulated Netflix method assumes perfect knowledge of the number of video
requests in the billing cycle, so that the user knows how to correctly set the default
bitrate given the quota. This is represented by the sharp jumps with increasing quota
in Figures 16.6 and 16.7. If the user sets the default bitrate too high, he/she will over-
shoot his/her quota. If the user sets the default bitrate too low, he/she will obtain
suboptimal utility. A main advantage of QAVA is that it automatically adjusts the
bitrate, so the Netflix user does not need to estimate his/her usage to set his/her default
bitrate, which might result in over- or undershooting the quota.
16.7.5
Sensitivity to Prediction Error
It is important to examine how errors from the UP module affect the performance
of the SS algorithm. There are two possible sources of error: video request proba-
bility and video type distribution. To test sensitivity to request probability error, we
measure the utility obtained by the MDP algorithm when it uses (i) the estimated
average arrival rate trained on historical data, (ii) the true average arrival rate of the
test data, and (iii) the true request times. These results are averaged across multiple
users and shown in Figure 16.9a, with the error bars indicating standard deviation.
We observe that the greater the information accuracy, the greater the average utility.
The performance difference is quite small, which suggests that the MDP algorithm
Estimated
average
True
average
True
0.9
1
0.95
Percentage of optimal utility
Percentage of optimal utility
MyStr3
 
 
Random
Estimate
True
0.94
(a)
(b)
0.96
0.98
1
Figure 16.9
Effect of user profiler prediction error. Our video and user profiler use imperfect
estimates of user behavior, but achieve good performance compared to the case with perfect
information. (a) Arrival rate. (b) Video type.

438
MECHANISMS FOR QUOTA AWARE VIDEO ADAPTATION
performs well independent of arrival probability accuracy. In addition to the perfor-
mance results shown in Figure 16.9a, the average difference between the true and
estimated arrival rate (the input to the algorithm) is 8%. This suggests our user pro-
filing technique is sufficient to capture variability of user behavioral patterns.
To analyze the sensitivity of the SS to video type prediction errors, we perform the
following experiment. We calculate the true video type distribution of the test data and
also randomly generate a video type distribution. This random distribution has both
random videos (drawn from the pool of requested videos from all users) and random
probabilities. The utility obtained by the MDP algorithm using the random, estimated,
and true distributions, averaged across all users, is shown in Figure 16.9b with the
error bars indicating standard deviation. We find that the average utility increases
only slightly as more accurate information is known, suggesting robustness of the
MDP algorithm to video type distribution errors.
16.8
CONCLUSIONS
Two emerging trends of Internet applications, video traffic becoming dominant
and usage-based pricing becoming prevalent, are at odds with each other. Current
approaches in practice center on either decreasing video consumption through
self-imposed warnings or decreasing data consumption by lowering video quality,
both of which degrade user quality of experience. Given this conflict, is there a way
for users to stay within their monthly data plans (data quotas) without suffering a
noticeable degradation in video quality? We proposed an online video adaptation
mechanism, QAVA, that manages this trade-off by leveraging the compressibility of
videos and by predicting consumer usage behavior throughout a billing cycle. QAVA
automatically selects the best bit rate to enable the consumer to stay under his/her
data quota, while suffering minimal distortion. We developed the QAVA architecture
and its main modules, including SS, user profiling, and video profiling. Online
algorithms were designed through dynamic programming and evaluated using real
video request traces. Empirical results based on real video traces showed that QAVA
performed better than existing approaches in literature and practical solutions. This
suggests that QAVA can provide an effective solution to the dilemma of usage-based
pricing of heavy video traffic.
REFERENCES
1. CISCO. ‚ÄúCisco Visual Networking Index: Global Mobile Data Traffic Forecast Update,‚Äù
2011‚Äì2016.
2. Sandvine. ‚ÄúGlobal Interet Phenomena Report,‚Äù Sandvine, 2012.
3. Reliance. Reliance 3G Plans & Pricing. Available at: http://www.rcom.co.in/Rcom/
personal/3G/HTML/PostpaidDataPlans.html, 2012.
4. ROGERS hi-speed internet. FAQ. Available at: http://www.keepingpace.ca/faq.html,
2012.

REFERENCES
439
5. Matthew
Lasar
arstechnica.
‚ÄúEU
cracks
down
on
‚Äúbill
shock‚Äù
roaming
hor-
ror
stories,‚Äù
arstechnica.
Available
at:
http://arstechnica.com/tech-policy/2010/03/
eu-cracks-down-on-bill-shock-roaming-horror-stories/, 2010.
6. Cecilia Kang and Hayley Tsukayama. ‚ÄúFCC holds off on ‚Äúbill shock‚Äù rule as
industry plans alerts for reaching monthly limits,‚Äù Washington Post. Available at:
http://www.washingtonpost.com/blogs/post-tech/post/fcc-holds-off-on-bill-shock-rule-as
-industry-plans-alerts-for-reaching-monthly-limits/2011/10/17/gIQAF0CbrL_blog.html,
2011.
7. Onavo. Available at: http://www.onavo.com/.
8. DataMi. DataWiz. Available at: http://www.datami.com/.
9. ‚ÄúIce Cream Sandwich‚ÄîAndroid Developer. Available at: http://developer.android.
com/about/versions/android-4.0-highlights.html, 2012.
10. S. F. Chang and A. Vetra. ‚ÄúVideo adaptation: concepts, technologies, and open issues,‚Äù
Proceedings of the IEEE, 93(1), 2005, 148‚Äì58.
11. X. Liu, F. Dobrian, H. Milner, J. Jiang, V. Sekar, I. Stoica, and H. Zhang. A case fo a
coordinated internet video control plane. In ACM SIGCOMM, 2012.
12. R. Rejaie, M. Handley, and D. Estrin. Quality adaptation for congestion controlled video
playback over the Internet. In ACM SIGCOMM, 1999.
13. J. Liu, B. Li, and Y. Zhang. ‚ÄúAn end-to-end adaptation protocol for layered video mul-
ticast using optimal rate allocation," IEEE Transactions on Multimedia, 6(1), 2004,
87‚Äì102.
14. C. Liu, I. Bouazizi, and M. Gabbouj. ‚ÄúRate adaptation for adaptive HTTP streaming,‚Äù In
ACM MMSys, 2011.
15. S. Akhshabi, A. C. Began, and C. Dovrolis. ‚ÄúAn experimental evaluation of rate-adaptation
algorithms,‚Äù In MMSys, 2011.
16. H. Schwarz, D. Marpe, and T. Wiegand. ‚ÄúOverview of the scalable video coding exten-
sion of the H.264/AVC standard,‚Äù IEEE Transactions on Circuits and Systems for Video
Technology, 17(9), 2007, 1103‚Äì20.
17. MPEG-DASH. http://dashpg.com/.
18. R. H. Jan, C. P. Lin, and M. S. Chern. ‚ÄúAn optimization model for Web content adaptation,‚Äù
Computer Networks, 50(7), 2006, 953‚Äì65.
19. M. L. Puterman. Markov Decision Processes: Discrete Stochastic Dynamic Programming.
John Wiley & Sons, Inc., New York, 2005.
20. A. Bovik. The Essential Guide to Video Processing. Elsevier, Burlington, MA, 2009.
21. H. Kellerer, U. Pferschy, and D. Pisinger. Knapsack Problems. Springer, Heidelberg, Ger-
many 2004.
22. J. Chen, A. Ghosh, J. Magutt, and M. Chiang. QAVA: quota-aware video adaptation. In
ACM CoNEXT, 2012.
23. J. D. Papastavrou, S. Rajagopalan, and A. J. Kleywegt. ‚ÄúThe dynamic and stochastic knap-
sack problem with deadlines,‚Äù Management Science, 42(12), 1996, 1706.
24. P. R. Winters. ‚ÄúForecasting sales by exponentially weighted moving averages,‚Äù Manage-
ment Science, 6(3), 1960, 324‚Äì42.
25. ITU-R. Recommendation BT.500: Methodology for the subjective assessment of the qual-
ity of television pictures. In International Telecommunication Union, 2012.

440
MECHANISMS FOR QUOTA AWARE VIDEO ADAPTATION
26. Y. Wang, M. Schaar, S. Chang, and A. C. Loui. ‚ÄúClassification-based multidimen-
sional adaptation prediction for scalable video coding using subjective quality evalua-
tion,‚Äù IEEE Transactions on Circuits and Systems for Video Technology, 15(10), 2005,
1270‚Äì8.
27. F. Dobrian, V. Sekar, A. Awan, I. Stoica, D. A. Joseph, A. Ganjam, J. Zhan, and H. Zhang.
Understanding the impact of video quality on user engagement. In ACM SIGCOMM, 2011.
28. K. T. Chen, C. Y. Huang, P. Huang, and C. L. Lei. Quantifying skype user satisfaction. In
ACM SIGCOMM, 2006.
29. M. Zink, K. Suh, Y. Gu, and J. Kurose. Watch global cache local: YouTube network traces
at a campus network - measurements and implications. In IEEE MMCN, 2008.
30. Y. Zhou, D. Chakrabarty, and R. Lukose. ‚ÄúBudget Constrained Bidding in Keyword Auc-
tions and Online Knapsack Problems,‚Äù WWW, 2007.

17
The Role of Multicast in
Congestion Alleviation
ALAN D. YOUNG
17.1
CONGESTION IN CELLULAR NETWORKS
At the AT&T‚Äôs analyst conference in New York on November 7th, 2012, Ralph de la
Vega, the President and CEO of their Mobility Business said that AT&T‚Äôs mobile net-
work traffic has grown by 25,000% over the past 5 years. According to Cisco‚Äôs Visual
Networking Index (VNI) [1], mobile network traffic in North America will grow
17-fold between 2011 and 2016. These staggering increases in data consumption are
of course mirrored in the wireline world too but increasing capacity in the wireline
world can be achieved by upgrading infrastructure with more and faster equipment,
to do the same in the wireless world requires more radio frequency spectrum. This is
a resource, which is in increasingly short supply, and it is not at all clear that enough
spectrum to satisfy the expected growth in demand can be obtained (at any price).
Indeed, the growth in data usage has been so dramatic that the unlimited data plans
of a few years ago, used to drive the rapid growth of smartphones, are gone for good,
as the operators try to ensure that they can support future growth and get a good return
on their huge investments in wireless spectrum and infrastructure. However, merely
trying to ration the remaining bandwidth and/or increasing the price might not be
enough to deliver that return. Increase the price too much and growth will decline,
limit the bandwidth user can use too much and the same depression in growth will
result. Failure to manage the use of bandwidth properly will result in the equally
undesirable result of congestion.
In some places, we have already started to see issues. For instance, in New York
City, because of the dense population and concentration of smartphone users, the data
rates available at certain times of the day are very restricted. So much so in fact that
it is almost impossible to exceed one‚Äôs monthly data cap, leading to situations where
people are paying for data they cannot use.
Cisco‚Äôs VNI predicts that video will grow from 58% of all mobile data traffic
in North America in 2011 to 69% in 2016. In light of this, the current chapter will
begin by looking at video as an application and its impact on network resources,
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
441

442
THE ROLE OF MULTICAST IN CONGESTION ALLEVIATION
before investigating how multicast architectures can be integrated into the overall
mobile network architecture in an attempt to alleviate the congestion problem. It will
inevitably get worse if nothing is done.
17.2
VIDEO, THE APPLICATION
Video applications are the main culprit for the massive increase in data usage on
mobile networks over the past few years and are likely to be the main driver of band-
width going forward. It is, therefore, important to study video as an application in a
little depth.
Video applications are the most bandwidth-intensive applications contemplated
for use over mobile networks. There are, of course, many types of video applications,
which will be explored in more detail in the following text, but in general, video has
the following characteristics and requirements that should be taken into account when
designing a network to transport it.
‚Ä¢ The video decoder in a device converts the incoming compressed video into
a frame size and rate that can be displayed on its screen. It needs a sustained
stream of data with a very low bit error rate (i.e., typically better than 10‚àí10
or 1 bit error in 10 billion) in order to operate properly. Failure to achieve this
will result in screen freezes and/or loss of synchronization of any accompanying
audio, which will obviously be objectionable to the viewer even at a relatively
low rate of occurrence. Buffering the video in the device to smoothen temporary
losses in transmission from the cell tower to the smartphone (or elsewhere in
the network) helps but only to a certain extent. If there are too many gaps in
transmission or the incoming rate on an average is not sufficient to sustain the
rate the video decoder needs, there will still be breaks in the video.
‚Ä¢ The network must be able to deliver the entire video (a relatively large amount of
data) to the device within the period of time the video content is to be watched.
The degree of flexibility the network operator/content provider has in delivering
the content to the viewer depends on several things, such as the quality of the
video required, the length of the clip, and probably, most importantly, whether
or not the content is live. If the content is live, there is little flexibility‚Äîthe
bandwidth available from server to smartphone must be at least equal to the
rate of compressed video data for the duration of the live content. Buffering is of
limited use because the content is live. One can hardly transmit more data when
the bandwidth is available to cover times when it is not, because the data has not
yet been produced! If too much buffering is used the event cannot be considered
live anymore. If the content can be delayed by the content provider or network
operator, or buffered by the device, or both, there are many more options and
the requirements on the network can be relaxed a little. In such circumstances,
the content (or parts thereof) can be compressed in time (as well as spatially)
and transmitted in burst form to the device in blocks, for storage in the device‚Äôs
buffer. Alternatively, if there is limited bandwidth and the device has sufficient

VIDEO, THE APPLICATION
443
15
30
45
60
Instantaneous information rate
Time (s)
2048 kbits/s or 4 √ó real time for 15 s
1536 kbits/s or 3 √ó real time in two bursts of 10 s each 
512 kbits/s in real time 
Figure 17.1
Different data transfer schemes for the same block of data.
storage, the data can be sent at a slower rate (thereby taking longer to transmit
than the actual time the video content would take to play). Clearly, the quality
and length of the video are also important factors, because they dictate how
much total data needs to be transferred (see Fig. 17.1).
‚Ä¢ The business model for video is perhaps not considered when designing a
mobile network, but it should be! Video is, bit for bit, perhaps the most expen-
sive application to transmit over certain networks, and this is especially true
for network architectures that were not designed with video in mind in the first
place. Not only is the amount of bandwidth high compared practically to any
other application for video but also it is, in most applications (save, perhaps,
for video conferencing), highly asymmetrical. In other words, the bandwidth is
all one way with very little (if anything) going in the opposite direction. Most
mobile phone networks were designed for much more symmetric traffic flows.
This means that there is a lot of inefficiency built in which only compounds the
expense of transporting video over such networks. More subtly, however, from
the content provider‚Äôs perspective, the cost of acquiring or producing content
can only be paid back if sufficient people watch the content in a given time.
Revenue comes from either direct or indirect payment for viewing the content,
or, more likely, through advertising. Either way, the amount of revenue is
directly linked to the number of people who watch it. In order to turn a profit,
the cost of making and delivering the content must be less than the revenue
obtained. If the economics of video were based on the bandwidth consumed,
there is no way it could profit as currently configured. An SMS text message
is typically charged on a basis, which is literally thousands of times more per
bit than what is charged for video. Yet it is video and not SMS that determines
the cost of provisioning and operating a network, and it is video that has the

444
THE ROLE OF MULTICAST IN CONGESTION ALLEVIATION
growing proportion. If this fundamental problem is not resolved in the long
term, significant breakage will occur, as the costs of transporting video in the
manner it is currently transported on mobile networks cannot be sustained.
17.3
WHY IS UNICAST NOT IDEAL FOR ALL VIDEO?
In the past, the underlying infrastructure used for any telecommunication network
was designed for the application, or the primary use. Because different applications
have different needs and characteristics, the network infrastructures built for them
looked very different and were largely incompatible with other applications. Now,
of course, as everything converges toward an all-IP future, all applications will also
need to converge to using a common unified IP network for communications.
This is generally considered to be a beneficial trend, but it does create a mismatch,
particularly in the case of video. This mismatch for video is primarily because of the
general architecture of the Internet, rather than with the IP protocol suite on which
the Internet is based. The Internet relies on unicast transmission, where each packet
of data originates from one unique network address and is sent to a unique destination
address. This is fine for most applications, but for video, it starts to break down when
large numbers of network addresses all request the same video at the same time. If the
number of requests for a piece of content exceeds the capability of the server to deliver
those requests, the server will at best cap the number of simultaneous connections and
deny addition requests; at worst, it will crash and deny access to everyone. President
Obama‚Äôs first inauguration speech on January 20, 2009, will be remembered not only
for its obvious historic significance but also because the live streaming feed on the
Internet was accessed by so many people that it caused web servers to crash and back-
bones to be stretched to the limit. As the amount of video on the Internet increases,
together with the number of devices that can access this content, the likelihood of
server request and/or bandwidth overload situations increases as well.
To date, the approach to solving this particular issue has been to build ever-larger
data centers so that more and more requests for video can be serviced. However,
this is becoming unsustainable, as the cost of building, operating, and maintaining
such facilities (even with the economies of scale) rises faster than the revenues that
support the services because facilities have to be sized in order to cope with peaks
of demand rather than the average demand. As a result, the operating efficiency of
large data centers is actually decreasing because most of the time the load is much
lower than the peak.
As already hinted, a similar situation exists on IP networks. As requests for video
are serviced, the amount of bandwidth coming out over each server rapidly multiplies.
In fact, the amount of bandwidth required is generally the product of the number of
viewers and the bandwidth of the stream. Using the example of President Obama‚Äôs
inaugural address, which was streamed live over the Internet and watched by more
than 7 million viewers simultaneously, the required bandwidth was more than a ter-
abit per second (150 kbits/s √ó 7,000,000). Content delivery networks (CDNs) have
helped alleviate this fundamental problem to a certain extent, but this only helps the

WHY IS MULTICAST BETTER FOR VIDEO IN SOME CIRCUMSTANCES?
445
backbone. CDNs do nothing to resolve the problem on the last mile. As such, the
delivery of video over unicast networks is very inefficient for situations where the
same content is watched by a large number of people on a local network (e.g., a cell
tower) within a short period of time as the unicast protocol requires the transmission
of the same data multiple times.
It can be argued that as video consumption is moving from linear broadcast, in
which everyone receives the same stream of data, to on demand, a unicast environ-
ment is necessary. While this is true for a significant portion of video, it is also true
that even in a totally on-demand environment, unicast fails when the number of users
demanding a piece of content (whether it is live or not) causes the bandwidth to exceed
the capacity of the system. Imagine if the Super Bowl was only available as a uni-
cast stream‚Äîit would require colossal resources in both the data center and network
environments. It should also be remembered that linear television (TV) still accounts
for the vast majority of revenue for the video industry and, as such, could provide a
valuable source of revenue for the network operators who ‚Äútune‚Äù their networks to
be able to carry such content. Consumers have shown little inclination so far to pay
for content delivered over the Internet; however, they still expect to be able to access
content over the Internet from any device. Many content providers (i.e., HBO‚ìáwith
HBO GO‚ìá) have responded by allowing limited on-demand access to their libraries
on a variety of devices (including smartphones and other devices using the cellu-
lar networks) conditioned on the consumer paying for a subscription to their linear
services. This has led to increased demand for bandwidth on cellular networks (and
indeed all networks) but with little-to-no additional revenue for the network operators.
Figure 17.2 illustrates the issue.
There is little doubt that the amount of data transmission capacity required to
support the growth in users, devices, and content is not going to be easy to deliver.
Spectrum is not limitless. What does exist is in high demand and, therefore, expensive.
Modulation technology is approaching the Shannon limit (a fundamental telecom-
munication theory that limits the information transfer rate across a given amount of
spectrum with a given amount of power), and so realistically, the only way to increase
data capacity on cellular networks is to reduce the size of each cell. This would be
very costly. A better approach may, therefore, be to address the inefficiencies of using
only unicast delivery for all applications, and especially video, thereby creating more
headroom for growth. This, if achieved, could at least put off more costly alternatives
or be combined with alternatives to bring down the overall cost (provided, of course,
that there are ways to address the inefficiencies at a lower cost).
17.4
WHY IS MULTICAST BETTER FOR VIDEO IN SOME
CIRCUMSTANCES?
Multicast transmission allows more than one destination address on a network
to receive data packets originating from a single source address on the network.
It differs slightly from broadcast: whereas broadcast packets are received by all
network addresses regardless of whether or not they request them (similar to

446
THE ROLE OF MULTICAST IN CONGESTION ALLEVIATION
Smartphone
Video server
Video data leaving server is directly
proportional to the number of viewers
Spectrum used at each tower is
directly proportional to the number of
viewers
The same data is replicated multiple
times, multiplying the bandwidth
used
Cell tower
Unicast
Video
content 
Figure 17.2
Unicast delivery.
broadcast television on a cable TV network), multicast packets are only received by
those addresses that request (or ‚Äújoin‚Äù) the multicast stream. Unlike unicast, which
is, as already discussed, a point-to-point mechanism, multicast has no means of
acknowledging receipt of a data packet. If this is required, separate provisions need
to be made. Fortunately, multicast and unicast packets can coexist on IP networks,
so this is relatively straightforward to implement.
The requirement to join a multicast stream provides a very efficient mechanism
for delivery of video over a network with bandwidth constraints. When a receiving
network node wishes to receive multicast packets from a particular source address it
sends a join request into the network, and the first router it encounters with packets
from the requested source address simply replicates those packets and sends them to
the requesting node. In this manner, the problem of replicating traffic unnecessarily
(i.e., in situations when large numbers of network nodes are all requesting the same
content at the same time) is avoided. This is illustrated in Figure 17.3.
Of course, not every scenario is suited to multicast. But by intelligently and per-
haps dynamically switching between multicast and unicast, it should be possible to
make much more efficient use of server and network resources in any CDN.
The remainder of this chapter will cover various potential content delivery options
and configurations. It is not intended to be an exhaustive list, but rather intended to
stimulate thinking in how to better match the network and server resources to the
applications that utilize those resources.

BROADCAST, MULTICAST, AND UNICAST ARCHITECTURES
447
Multicast‚àó
Smartphone
Video
content
‚àó Multicast ‚Äò‚ÄòJoins‚Äô‚Äô have been left off for simplicity
Video data bandwidth leaving server is directly
proportional to the number of different pieces of content
being viewed simultaneously and independent of the
number of viewers
Video server
Cell tower
Only the content actually being
watched is delivered to the
cell tower
The spectrum used is proportional to the
number of different pieces of content
being simultaneously viewed and
independent of the number of viewers
Figure 17.3
Multicast delivery.
17.5
BROADCAST, MULTICAST, AND UNICAST ARCHITECTURES
FOR THE DELIVERY OF VIDEO
The most common delivery architecture used for video today is, by far, broadcast.
However, over time, many delivery mechanisms have evolved to include a mixture
of broadcast, multicast, and unicast. Those that rely on only one architecture tend
to struggle, as the nature of the video application has changed from linear only to a
mixture of on-demand, linear, and interactive.
Cable TV systems, for instance, were built based solely on an end-to-end broadcast
architecture until relatively recently. Programmers for the most part delivered their
content via satellite, often uplinked directly from their playout facilities to thousands
of cable headends (point-to-multipoint broadcast architecture). Each cable headend
would also receive local broadcasts transmitted terrestrially in the very high frequency
(VHF)/ultra high frequency (UHF) spectrum (a lot of which has now been reassigned
to the cellular network operators). The headend would then redistribute the video con-
tent through a tree and branch broadcast infrastructure to end users (i.e., consumers).
Every single TV channel the cable operator offered was delivered to every single cus-
tomer‚Äôs home, whether they watched the channel or not. As the number of channels
grew, cable operators expanded the bandwidth delivered to each home in steps from
330 MHz to 450 MHz, then to 550 MHz, on to 750 MHz, then 860 MHz, and finally
1000 MHz, which is the practical limit.
As the Internet grew and cable modem services were developed to deliver
always-on broadband Internet to homes as well, operators found that they had to

448
THE ROLE OF MULTICAST IN CONGESTION ALLEVIATION
reuse their bandwidth more and more. Originally, one headend could serve thousands
of homes with all of the bandwidth shared by each. In a broadcast architecture,
this is fine. However, with broadband Internet, which is of course based on unicast
architecture, the available bandwidth per home soon became an issue. To counteract
this, cable operators began to migrate to an architecture where the bandwidth of the
system was shared between a smaller and smaller number of homes, so as the demand
of the system rose, the number of homes that bandwidth was shared between would
fall. Now some operators share 1000 MHz of bandwidth between as few as 50 homes.
As these changes were happening, there was a period of time between about 2005
and 2010 when operators were challenged because there was pressure to deliver
increasing numbers of high definition channels (in order to compete with satellite
broadcasters) as well as to deliver faster and faster broadband speeds to satisfy
demand from consumers. To resolve the problem, many cable operators started to
incorporate multicast to alleviate the pressure on their networks. The idea was to
assign an amount of bandwidth to the linear channels that was significantly less
than the bandwidth required for all of the channels. Only if at least one person
on a particular node was watching a channel would it be transmitted on that node
segment. Clearly, the amount of bandwidth that was necessary depended on how
many different channels would be watched by a particular group of people at the
same time. This is a statistical problem that can, fortunately, be modeled using the
Pareto‚Äôs distribution. The reduction in bandwidth needed to deliver essentially the
same selection of channels as before allowed operators to grow their broadband
businesses much faster than would have been possible otherwise.
As cable operators migrate their networks to an all-IP architecture, it is likely that
they will continue to utilize a combination of unicast and multicast, to help optimize
bandwidth resources while delivering the full suite of services demanded of them.
The telephone operators became interested in video only after it became clear that
the cable operators were going to take a substantial portion for their traditional tele-
phony and data business. Unfortunately, the telephone operators found that it was
substantially more challenging for them to deliver video using twisted pair than it
was for cable operators to deliver telephony over coaxial cables! The fact that the
last mile bandwidth to the home was limited forced the telephone operators to use a
multicast architecture from day 1, and today, the only multichannel video operators
that use a completely IP architecture from end-to-end are telephone operators. Linear
video is broadcast to headends, as with cable operators, and is then delivered in an IP
multicast format to homes using the existing twisted pair cables via DSLAMs (dig-
ital subscriber loop access multiplexers). Because the resulting networks are all IP,
telephone operators are able to deliver other video services such as video on demand,
and, of course, broadband Internet, using unicast IP over the same infrastructure.
Cellular networks, in contrast to both the cable and wireline telephone operators,
have maintained their use of a unicast-only architecture throughout. Their approach
has been to acquire more spectrum and utilize more spectrally efficient transmission
techniques. It is ironic that most of the spectrum acquired by the cellular providers
to meet the increasing demand for transmission capacity came from the TV
broadcasters. While this spectrum was previously used to deliver video in broadcast

FUTURE POTENTIAL ARCHITECTURES MIXING BROADCAST
449
format to tens of millions of homes, it is now used to deliver essentially the same
application (video) but in unicast format. This is the main reason why AT&T saw a
25,000% increase in traffic on its mobile networks in just 5 years‚Äîhad they used
a mixture of multicast and unicast, this figure would likely have been a lot lower.
Logic would seem to suggest that if we are to migrate to an all-IP infrastructure, it
should not be an all-unicast IP infrastructure.
17.6
FUTURE POTENTIAL ARCHITECTURES MIXING BROADCAST,
MULTICAST AND UNICAST
Some of the possible architectures that could be considered for cellular networks will
be investigated in the following text.
The falling cost per gigabyte of storage has made it feasible to consider adding
storage at cell sites. This would allow popular content to be stored (cached) at the
cell site, therefore, reducing the demand for backhaul capacity. In a similar manner,
broadcast channels could be delivered to the cell towers. There would still be a need
to determine what content to cache at each tower, and how long to keep it there. But
initial algorithms could be as simple as triggering a caching operation after a certain
number of users at a cell site request the same content within a defined period of
time. The question of how long content could be stored would be dependent on how
much storage was available and how long it takes before the rate of requests to view
drops below a predetermined point. Many content providers would also restrict what
content could be stored and for how long, and although this would clearly need to be
taken into account, it will not be considered further here. Another issue that would
need to be addressed in order to implement this solution would be how to manage
handover between cells. For instance, suppose a user is viewing a piece of content
that is being drawn from the cache at the cell tower serving that user. If this user
moves out of range of that tower, and into range of another tower that does not have
that content cached, there would be a need to communicate to the new tower what
content it needs to acquire and what bit rate it needs to be able to deliver the content at.
Caching content at the cell site does not do anything to alleviate congestion on the
last hop, between the cell tower and the mobile handset. If, however, a combination
of multicast and local storage on mobile handsets was used, it should be possible
to make better use of the available spectrum. For content, which is consumed live
by a sufficient number of people within a single cell site, or more likely within a
common locality, an operator could leverage the multicast capability of all towers in
that locality. This would clearly be more bandwidth efficient than if the same number
of users (assuming a sufficiently large number of users) were each to make unicast
requests at the same time for the same streaming feed‚Äîwhich is how it is done today.
For on-demand content that is not live, storage on the device can be leveraged.
Most smartphones today come with multiple gigabytes of storage, and the amount
of storage on devices is increasing steadily. In a similar way to the above scenario
where popular content is cached at the cell tower, popular content could be cached
directly on smartphones. There are several differences, however. First, the algorithm

450
THE ROLE OF MULTICAST IN CONGESTION ALLEVIATION
to determine what to cache and what not to cache would need to be more sophisti-
cated. It would need to be able to predict what content a particular user was likely
to request in the near future. Assuming that such an algorithm were to be developed,
the content could be downloaded to the user‚Äôs smartphone during an off-peak period.
If the content was unique to the user, then unicast would be the best method to use.
However, if a large enough number of smartphone users were predicted to request the
same content, it would be more efficient to multicast the content to all users (again
during off-peak periods).
In this scenario, and assuming the algorithm was able to correctly predict which
content a user was likely to want to watch, there would be no need for the content
to be downloaded again. In addition to reducing the load on the cellular network,
there are a number of other advantages. For one, the quality of the content could
be enhanced, which would facilitate the user projecting the video to another device,
such as a big screen TV or a computer screen. Another advantage from a business
perspective is that providers could push content to users‚Äô phones and then advertise
its availability. This could even become a revenue stream for the operators‚Äîpopular
TV shows could be pushed at night to users‚Äô smartphones in advance of broadcast,
and the keys to decrypt the programming could be distributed with the content and
activated at a particular time (e.g., by a text message). There are all sorts of potential
business models where users would get access to the keys at different times depending
on what subscription they have, or as part of a promotion or competition.
Another potential option for content distribution is the use of ad hoc networks for
direct device-to-device communication and redistribution of content. This would not
use any spectrum from the tower. However, it would require much greater intelligence
in the network to manage as well as agreement on new protocols and spectrum that
could be used locally. It would be best utilized in areas where the cell phone density
is relatively high and where content that a user desires is available on one or more
nearby smartphones. A peering network could be formed between the devices, and
the content transferred, either all from one device or in parts from multiple different
devices. Clearly, this is only plausible for certain types of content, and controls would
need to be carefully managed to prevent the redistribution of private or personal mate-
rial. But, despite the difficulties, it could nonetheless be another tool for the network
operator to efficiently manage the limited spectrum available.
17.7
CONCLUSIONS
It is clear that the recent growth in data consumption on mobile networks has been
tremendous and that video accounts for the lion‚Äôs share of that growth.
We have seen that an all-unicast network architecture cannot efficiently meet the
needs of all video applications. In particular, the video applications that generate the
most income for the content providers (linear TV) are also the most inefficient to
deliver via unicast. Although on-demand video is a growing portion of the content
viewed, it is by no means the entirety. Even if it was, the use of unicast end to end to
service every request is highly inefficient.

REFERENCE
451
Usage patterns change over time, and it is important that the network architectures
of the future are flexible enough to adapt to these changes. As we continue to migrate
to an all-IP infrastructure, we are going to move from a situation where the network
infrastructure was designed specifically for the application [e.g., a cable TV network
infrastructure for TV or a public switched telephone network (PSTN) for telephony],
so that it was optimized for that one application and incompatible with pretty much
everything else, to a situation where the network infrastructure is based on IP and is
generic. Along with the benefits of such a migration come the challenges of optimiz-
ing the network for all applications and implementing business models, which are
sustainable.
From a pricing point of view, the idea of charging users a flat rate for an unlimited
amount of data (or at least as much data as they can use) has failed because users
had no disincentive to streaming as much video as they wanted leaving the oper-
ators struggling to keep up. Going forward, as unpopular as it may be, the reality
is that the more data/bandwidth/spectrum resources that an application and/or user
uses, the more money needs to be charged. This will force everyone in the ecosys-
tem (operators, providers, and users) to consider (whether directly or indirectly) the
resources required to deliver/receive each particular service. From a pricing point of
view, users could be charged a per gigabyte fee for unicast data and a much lower flat
fee for the ability to receive multicast data and content providers would be charged on
the same basis except that the multicast fee would be for the right to deliver a certain
amount of data using multicast. This pricing structure (or something similar) would
incentivize everyone to be more conservation minded and would fuel innovation and
development in this area.
REFERENCE
1. Cisco Visual Networking Index. Available at http://www.cisco.com/web/solutions/sp/
vni/vni_mobile_forecast_highlights/index.html. Accessed April 4, 2014.


PART VI
Pricing in the Cloud


18
Smart Pricing of Cloud
Resources
YU XIANG and TIAN LAN
Large investments have been made in recent years in data centers and cloud com-
puting. A survey by KPMG International [1] in February 2012 shows that more
than 50% of senior executives find the most important impact of cloud computing
to their business models to be its cost benefits. Accordingly, much research has been
focused on demystifying various economic issues in data center and cloud comput-
ing, for example, economic and pricing models, cost-optimization techniques, tariff
and charging structures, and business objectives.
As in today‚Äôs clouds the demand for resources in clouds are dynamically fluctuat-
ing because of many factors, thus offering fixed resources to all the users regardless
of their demands may either not be able to meets some users‚Äô demand or leave some
resources wasted. Therefore, one thing attracts most attention in today‚Äôs Cloud com-
puting is the idea of optimizing the utilization of computing resources among all
cloud users, so that the computing resources can be distributed in the most effective
manner and restrict the underutilization to a certain level. The intuitive idea to deal
with this is that the resources should be regulated by the law of supply and demand,
that is, when demand rises but supply remains the same, the price of types of vir-
tual machines (VMs) should go up, and when demand drops, then prices should fall
accordingly.
To implement this idea, cloud providers such as Amazon EC2 [2, 3] employs this
sort of market-driven resource allocation for unused capacity. In Amazon EC2‚Äôs spot
markets, instead of renting a server for fixed price per hour for each hour that the
server runs, users can make a bid for a certain number of hours of a certain type
of server. The spot price is set by the cloud provider, which fluctuates in real time
according to spot instances supply and demand. When the bid exceed the spot price,
the instance will run until the spot price exceed the bid, in which case the instance will
be terminated without notice. To use spot instances, users shall place a request that
specifies the instance type, the availability zone desired, the number of spot instances
desired, and the bidding price per instance hour. Amazon EC2 API provides the spot
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
455

456
SMART PRICING OF CLOUD RESOURCES
Spot Instance Pricing History
Product:
Instance Type:
Date Range:
Zone:
Cancel
Close
Linux/UNIX
$0.1750
$0.1650
$0.1700
$0.1600
$0.1550
$0.1500
May 17
May 18
May 19
May 20
May 21
May 22
May 23
m1.large
1 week
ap-southeast-1a
ap-southeast-1a
Figure 18.1
Amazon EC2 VM spot instance price History: price of a m1.large linux spot
instance in US Southeast-1a from May 17 to May 23, 2012 [4].
price history for the past 90 days to help customers decide their bids [4], as shown in
Figure18.1.
Cloud resources can be dynamically allocated not only based on just the demand
and supply such as in the case of spot instances but also based on service level agree-
ment (SLA), that is, the providers has to ensure users can get certain service level
when dynamically allocating resources based on demand and supply to maximize
revenue. SLA is a critical bridge between cloud providers and customers, as in clouds,
the providers aim to obtain the revenues by leasing the resources and users rent these
resources to meet their application requirements. SLA provides a platform for users
to indicate their required quality of service (QoS) [5], which specifies responsibilities,
guarantees, warranties, performance levels in terms of availability, response time, and
so on. Owing to the fast-growing power consumption and application heterogeneity
of data centers, cost optimization and smart service pricing are also becoming ever
more urgent and important. In contrast to the adoption of low power devices and
energy saving solutions in References 6 and 7, a cost-optimization approach in Ref-
erences 8 and 9 exploits the diversities of electricity prices over time and geographic
regions. In particular, a load-balancing algorithm is proposed in Reference 9 to coor-
dinate cloud computing workload with electricity prices at distributed data centers, in
order to achieve the goal of minimizing the total electricity cost while guaranteeing
the average service delay experienced by all jobs.
These queuing-based models for price data center services based on an average
service delay may be unsatisfactory to cloud users, not only because they may have
heterogeneous job requirements and spending budgets but also because of a funda-
mental limitation of the average delay approach‚Äîindividual job completion times
are still randomly scattered over a wide range of values. Delayed response may frus-
trate users and, consequently, result in revenue loss. Therefore, the ability to deliver
according to predefined job deadlines increasingly becomes a competitive require-
ment [10, 11]. Cloud providers and users can negotiate individual job deadlines to

DATA CENTER VM INSTANCE PRICING
457
determine costs and penalties based on the desired performance and budget. This
presents an opportunity to offer deadline-dependent pricing, which generates an addi-
tional source of revenue for cloud providers. It immediately raises the following
question: How to jointly optimize both electricity cost of distributed data centers and
total revenue from deadline-dependent pricing, in order to maximize the net profit
cloud providers receive? Wang et al. [12] studied the problem of data center net profit
optimization (NPO), which aims to maximize the difference between the total revenue
from deadline-dependent pricing and the electricity cost of distributed data centers.
This chapter studies cloud resources allocation based on three types of pricing
models, that is, to find out the optimal resource allocation that maximizes the total rev-
enue, where the revenue function depends on various pricing models we employed;
for instances, as we discussed earlier, price of cloud resource can be determined by
three major factors such as demand and supply in current markets, the SLA level
cloud servers provided, and the predefined job deadline users required. We proposed
the detailed pricing model with respect to these three factors separately in the fol-
lowing sections and then obtain the optimal cloud resource allocation to maximize
the revenue function formulated by these pricing models, an comparison of overall
revenue with heuristic static pricing scheme is shown for each pricing model.
18.1
DATA CENTER VM INSTANCE PRICING
Amazon‚Äôs spot instances mechanism can be described as a continuous seal-bid uni-
form price auction, where VMs of the same type are sold at identical price and the
providers assigns resources to bidders in decreasing order of their bids until all avail-
able resources have been allocated, and the spot price may be adjusted when there are
no instances running at the current spot price [13]. In this section, we formulate the
problem of dynamic resource allocation for simultaneous spot markets, and here the
goal is to allocate unused data center resources to each spot market in a timely man-
ner that maximize the total revenue, subject to the capacity constraints of individual
machines. In the rest of this section, we shall present our solution approach to achieve
this goal for both fixed pricing scheme, where price of a VM type is fixed and thus is
independent from market situation, and the uniform pricing scheme, where the price
of a VM type is adjustable according to market demand and supply.
18.1.1
Dynamic Scheduling and Server Consolidation for Fixed Pricing
Scheme
In the fixed pricing scheme, each VM type has a fixed price that does not fluctuate with
the current supply and demand situation. Hence, the virtual machine revenue maxi-
mization problem (VRMP) can be modeled as a multiple knapsack problem (MKP) as
follows: given a set of machines M and D resource types (differed in CPU, memory,
and disk), where each machine m ‚ààM has a capacity cdm for each type of VM d ‚ààD.
The set of VMs to be scheduled is V and each VM i has a size aid for each d ‚ààD and a
value vi. To formulate the optimization problem, we would first choose the optimiza-
tion variable (which is the VM scheduling parameter xim), then define the objective

458
SMART PRICING OF CLOUD RESOURCES
and constraints. As we mentioned earlier, the objective is to maximize the total value,
which is the summation of all of the chosen VMs(for a chosen VM, xim = 1; for an
abandoned VM, xim = 0), which is vixim. While the constraints for this goal is the
machine capacity, that is, the summation of the size of all chosen VMs should be
smaller than or equal to cdm. On the basis of the intuition above, the problem can be
formulated as
maximize
‚àë
i‚ààV
‚àë
m‚ààM
vixim
subject to
‚àë
i‚ààV
aidxim ‚â§cdm,
‚àÄm ‚ààM, d ‚ààD,
xim ‚àà{0, 1},
‚àÄi ‚ààV, m ‚ààM.
(18.1)
It can be noticed that this MKP formulation is an NP-hard combinatorial optimiza-
tion problem, we propose a 1
2 ‚àíùúÄlocal search algorithm [14] that can approximate
the optimal solutions, which is specified by Algorithm 18.1. In this algorithm, S is the
current set of VMs on machine m, S‚Ä≤ is the set of VMs chosen to maximize the total
value, and vj is the value of VM j. As it is depicted, the algorithm proceeds in rounds.
For each round, first maximize the total revenue among pending requests and current
running VMs on machine m; then if there is a potential new configuration for m by
scheduling, first try to schedule all VMs using available free capacity and then pre-
empt and migrate VMs when the total demand is reaching capacity. To achieve fast
convergence rate, we require each local search operation to improve solution quality
for each machine m by at least (1 + ùúÄ).
Algorithm 18.1 Local Search Approximation Algorithm Local( P) for VRMP
1: for ‚àÄm ‚ààM do
2: Find a set of VMs S‚Ä≤ that among pending requests and the current running
VMs on the machine m, maximize the total value R(S‚Ä≤) = ‚àë
j‚ààS‚Ä≤ vj.
3: end for
4: while ‚àÉa machine m such that R(S‚Ä≤) ‚â•R(S) do
5: Schedule the requests in S‚Ä≤‚àñS, preempt and migrate VMs in S‚àñS‚Ä≤ if necessary.
6: end while
18.1.2
Price Estimation for the Uniform Pricing Scheme
We now consider the case in which the price of each instance vary with the
demand‚Äìsupply curve and the resource availability. In this scenario, above all,
we need to periodically analyzes the market situation and predict the demand and
supply curves, on which the price of instances depend. The prediction of the demand
curves can be constructed by capturing the relationship between the quantity of
acceptable requests and the bidding price(as shown in Figure 18.2) over time period

DATA CENTER VM INSTANCE PRICING
459
Price
t0 + T Time
t0
p1
p2
p3
q1,t
q1,t
q2,t
q2,t
q3,t
q3,t
Quantity
Quantity
Figure 18.2
Example demand curve at time t and over time.
[t0, t0 + T] at sampling interval Œît, where t0 denotes the current time and T denotes
the prediction period. Then we can decide the expected price for each type of VM
in each market based on the prediction. Finally, we will be able to make online
scheduling decisions for revenue maximization.
Let pi denote the ith bidding price in decreasing order, di,t denote the demand that
bids at price pi, and qi,t denote the demand that bids at price at least pi at time t.
As the spot instances mechanism allows requests with bidding prices higher than or
equal to the spot price ps to be accepted, then when ps equals pi, we can schedule qi,t
VM requests. (Demand curve as shown in Fig. 18.2.) As the bidding price of each
individual VM request is independent of the current market situation, we can model
the demand quantity to di,t independently for each pi to predict the expected demand
curve. Then we are able to predict the future demand di,t for each pi from t0 to t0 + T.
Our approach to do this is to adopt an autoregressive (AR) model [15] that estimates
di,t from the historical values di,t‚àí1, ..., di,t‚àík as
di,t =
k
‚àë
j=1
ùúôjdi,t‚àíj + ùúÄt,
where ùúôj with j ‚àà1, 2, .., k is the set of parameters of the historical values and ùúÄt
is uncorrelated white noise with mean 0 and standard deviation ùúéùúÄ, and all these
parameters can be obtained from historical demand data. This is an appropriate model
because it is not only lightweight and easy to implement but also capable of capturing
short-term trends to let us compute the expected demand curve.
Now we have the demand and supply curve, our objective is now to schedule
requests of each spot market to maximize the expected revenue over the next pre-
diction period. This dynamic revenue maximization with variable price (DRMVP)
problem is identical to the former VRMP except that price of individual VMs is deter-
mined by the estimated demand curve Rùúè(qùúè). Again to formulate the optimization
problem, first, we choose the same optimization variable as in Section 18.1.1, which
is the scheduling vector of VMs. The difference is this time the variable varies with
time because the price varies with time based on the demand curve, so it is defined
as xùúèm. And the objective is the sum of the revenue over demand prediction period
‚àë
ùúè‚ààT Rùúè(qùúè), subject to the constraints that the total VMs scheduled during time ùúè

460
SMART PRICING OF CLOUD RESOURCES
should be smaller than or equal to the total number of VM requests in ùúè, and the total
size of all chosen VMs should not exceed the machine capacity cmd, noticed that each
VM size aùúèd here also varies with time because of demand curve prediction. Now we
can model this problem as follows:
maximize
‚àë
ùúè‚ààT
Rùúè(qùúè)
subject to
‚àë
m‚ààM
xùúèm = qùúè,
‚àÄùúè‚ààT,
‚àë
ùúè‚ààT
aùúèdxùúèm ‚â§cmd,
‚àÄm ‚ààM, d ‚ààD,
xùúèm, qùúè‚àà‚Ñï‚à™{0},
‚àÄm ‚ààM, ùúè‚ààT.
(18.2)
As the objective function of this optimization problem is nonlinear, the problem is
even more difficult to solve that of the fixed priced case; however, the revenue function
Rùúè(qùúè) for a single VM type is a piecewise linear function, and it can be observed from
the Rùúè(qùúè) using examples in Figure 18.2. In some situations, scheduling a VM can
cause the current market price to be lowered, resulting in a sharp drop in total revenue.
Thus motivated by similar work on market clearing algorithms for piecewise linear
objective functions, our approach to deal with this issue is to approximate R‚Ä≤
ùúè(qùúè) =
maxq‚â§qùúè{Rùúè(q)} using a concave envelope function Reùúè(qùúè), which is computed by
constructing a upper convex hull using the extreme points in R‚Ä≤
ùúè(qùúè). Reùúè(qùúè) has the
following property.
Lemma 18.1
Reùúè(qùúè) ‚â§2 ‚ãÖR‚Ä≤
ùúè(qùúè) for any qùúè.
Proof: For any qùúè, assume Reùúè(qùúè) is on a linear segment with extreme points (qi, Rei)
and (qj, Rej) when i ‚â§j. By definition of convex hull, Rei and Rej are also points
on R‚Ä≤
ùúèwith slope piùúèand pjùúè, respectively. Thus we have piùúè‚â•pjùúè, Reùúè(qi) = qi ‚ãÖpiùúè,
and Reùúè(qj) = qj ‚ãÖpjùúè. The slope ps of the segment of Reùúè(qùúè) can be bounded by ps =
qj‚ãÖpjùúè‚àíqi‚ãÖpiùúè
qj‚àíqi
‚â§pjùúè. The total overestimate of Reùúè(qùúè) at (qùúè, Reùúè(qùúè)) can be bounded
by Œî = Reùúè(qùúè) ‚àíR‚Ä≤
ùúè(qùúè) ‚â§(qùúè‚àíqi) ‚ãÖps ‚â§qùúè‚ãÖpjùúè. Then we get Reùúè(qùúè) ‚àíR‚Ä≤
ùúè(qùúè) ‚â§
R‚Ä≤
ùúè(qùúè). The lemma follows.
Define vqùúè= Reùúè(qùúè) ‚àíReùúè(qùúè‚àí1) as value for scheduling the qth request for type
ùúè. As Reùúè(qùúè) is concave, vqùúèis a nonincreasing function of q. Now we have the value
of each request, we can construct an instance VRMP‚Äô where each VM has value
according to differentials of Reùúè(qùúè).
‚óæ
Theorem 18.1
Running Algorithm 18.1 using vqùúèdefined above is a 1
4 ‚àíùúÄapprox-
imation algorithm DRMVP.
Proof: As the values of VMs are nonincreasing, any solution of VRMP‚Äô that sched-
ules qùúèVMs of type ùúèhas a corresponding solution in DRMVP that schedules the

DATA CENTER SLA-BASED PRICING
461
TABLE 18.1
Average Revenue Achieved by Different Policies
Policy
Metric
Income
Revenue Loss
Net Income
Static
Mean
67,030.44
399.01
66,631.43
Standard deviation
13,573.32
172.45
13,400.87
Dynamic
Mean
78,026.33
3398.36
74,627.97
Standard deviation
15,173.28
1083.63
14,089.65
qùúèmost valuable VMs with at least 1
2 the revenue. As Algorithm 18.1 is a 1
2 approx-
imation algorithm of VRMP‚Äô, we have shown that every solution of VRMP‚Äô has a
corresponding solution in DRMVP with at least half the total revenue.
The implementation results using eight type of VMs provided by Amazon EC2
simulated over a 1000 machine data center is shown in Table 18.1. From the col-
lected data, we can see that the dynamic resource allocation has contributed to a great
revenue gain.
‚óæ
18.2
DATA CENTER SLA-BASED PRICING
Cloud resources can not only be dynamically allocated based on just the demand
and supply such as in the case of spot instances but also based on SLA, that is,
the providers has to ensure users can get certain service level when dynamically
allocating resources based on demand and supply to maximize revenue. SLA is a
critical bridge between cloud providers and customers, as in clouds, the providers
aim to obtain the revenues by leasing the resources and users rent these resources to
meet their application requirements. SLA provides a platform for users to indicate
their required QoS [5], which specifies responsibilities, guarantees, warranties,
performance levels in terms of availability, response time, and so on. Usually,
cloud providers charge users according to their requirement level for their tasks.
For example, Amazon EC2 offers spot instances at a much lower price than that of
reserved resources. Service instances (including the user and the VMs he/she rented
for service) may have different attributes such as arrival rate, execution time, and
pricing mechanism. The challenge here is how much resources must be distributed
to a VM to maintain the promised performance in SLAs when trying to maximize
the total revenue. Allocate more resources to those who have high arrival rate and
high price will certainly ensure revenue, but in practice, there are cases when users
have low arrival rate but high price and vice versa.
Our goal in this section is to maximize the SLA-based revenues [16] by proper
resource allocation, that is, to schedule resources among different service instances
in an adaptive manner based on the dynamic situation. For the rest of the section,
first, we formulate the resource allocation problem based on the queuing theory to
model user‚Äôs requirement using parameters such as resource quantity, request arrival,
service time, and pricing models. Then we propose our optimal SLA-based resource
allocation algorithms, by which providers can maximize their revenues.

462
SMART PRICING OF CLOUD RESOURCES
In order to find how many servers should be assigned for each service instance
in order to achieve maximum revenue for a pricing model, we first formulate our
mathematical model for this as follows: A data center consists of N homogeneous
servers that are grouped into clusters dynamically; each cluster is virtualized as a sin-
gle machine. The provider signs SLAs with m users, the number of servers allocated
to each service instance is n1, n2, ..., nm, we assume that the more servers assigned,
the more powerful the virtual machine is. We also assume that the requests from users
are Poisson distributed with arrival rate ùúÜand service rate ùúá, thus the average service
time is exponentially distributed with mean 1
ùúá, and the service rate of a VM with n
servers is nùúá. Thus based on the above description, each service instance can be mod-
eled as a FIFO (first in, first out) M/M/1 queue. Here we define service intensity ùúåas
the ratio of arrival rate to service throughput of one server:
ùúå= ùúÜ
ùúá.
The pricing mechanism specifies how service requests are charged, mostly provider
oriented. Here we propose two user-oriented pricing mechanisms MRT (mean
response time) and IRT (instant response time), in which users are charged according
to achieved performance in terms of MRT, which is the mean of the time interval
between a request arrives at the system and the instant at which the service is
completed. Usually providers divide time into time slots, and we calculate the mean
response time of every time slot. For the MRT pricing model, let F be an offset
factor of the actual response time to benchmark, which is defined as
F = r
R,
where r is the measured average response time during a time slot and R is a benchmark
of response time defined in SLA, which determines by users‚Äô requirement. Then the
pricing mechanism can be formulated as
B = b(1 ‚àíF),
where B is the price of each service provision and b is the price constant. As shown
in Figure 18.3a, B is the linear function of r and when r ‚â•R, the provider will be
penalized, also b‚àïR is the slope of the price function,
q = b
R.
As MRT is of less practical value as a performance metric when response time
varies quite a lot, we propose the IRT pricing model, where request is charged accord-
ing to measured response time. That is,
B =
{
b
if r ‚â§R,
0
otherwise.
(18.3)

DATA CENTER SLA-BASED PRICING
463
b
b
r
r
R
R
B
B
(a)
(b)
Figure 18.3
Price models. (a) Price model in terms of MRT and (b) price model in terms of
IRT.
The pricing model can be illustrated as in Figure 18.3b, in which the charge under this
model is determined by the number of service provisions with response time within
required R.
Now we are ready to study the optimal allocation based on MRT and IRT. On the
basis of some mathematical background of the most popular M/M/1 model in queuing
theory, the average response time ri of service instance i at the steady system state is
ri =
1
niùúái
‚àíùúÜi
and the service performance level is
Fi =
1
(niùúái ‚àíùúÜi)Ri
.
The mean revenue gi is calculated as
gi = bi
(
1 ‚àí
1
(niùúái ‚àíùúÜi)Ri
)
.
The overall revenues during a time slot from service instance i is
Gi = ùúÜigi = ùúÜibi
(
1 ‚àí
1
(niùúái ‚àíùúÜi)Ri
)
.
Then the optimization problem can be formulated as
maximize
m
‚àë
i=1
ùúÜibi
(
1 ‚àí
1
(niùúái ‚àíùúÜi)Ri
)
subject to
m
‚àë
i=1
ni = N.
(18.4)

464
SMART PRICING OF CLOUD RESOURCES
This optimization problem can be solved using Lagrange method. The Lagrange com-
posite function can be constructed as
L(ni) =
m
‚àë
i=1
ùúÜibi
(
1 ‚àí
1
(niùúái ‚àíùúÜi)Ri
)
+ ùúÜ
(
N ‚àí
m
‚àë
i=1
ni
)
.
where ùúÜis the Lagrange multiplier constant. Letting dL‚àïdni = 0, with i =
0, 1, 2, ..., m,
ùúÜibi
Ri
ùúái
(niùúái ‚àíùúÜi)2 ‚àíùúÜ= 0
ni =
2
‚àö
1
ùúÜ
2‚àöqiùúåi + ùúåi;
then substituting this into the constraint of the optimization problem, we have
N =
2
‚àö
1
ùúÜ
m
‚àë
j=1
2‚àöqjùúåj +
m
‚àë
j=1
ùúåj
2
‚àö
1
ùúÜ=
N ‚àí‚àëm
j=1 ùúåj
‚àëm
j=1
2‚àöqjùúåj
.
Then we yield the final answer, which is the number of servers used for each service
instance,
ni =
N ‚àí‚àëm
j=1 ùúåj
‚àëm
j=1
2‚àöqjùúåj
2‚àöqiùúåj + ùúåj.
This holds when the request arrival rate of each service instance is less than the
service processing rate according to M/M/1 queuing model, otherwise the length of
request queue will not converge. Thus our result only holds when
ùúÜi ‚â§niùúái.
Thus we have
ni ‚â•ùúåi.
What is more, Figure 18.3 shows that the providers would be penalized once mean
response time cannot meet the requirement in SLA, which is Ri; hence, our results
ensures that
ri =
1
niùúái ‚àíùúÜi
‚â§Ri.

DATA CENTER SLA-BASED PRICING
465
Finally, we have the lower bound of resources that can be assigned for each service
instance:
ni ‚â•
1
ùúáiRi ‚àíùúÜi
+ ùúåi.
Next we will consider the optimal solution for IRT pricing model, the sojourn time
probability distribution is
ùúî(t) = (ùúá‚àíùúÜ)e(ùúÜ‚àíùúá)t.
Assuming that service instance i is allocated to ni servers, then the mean revenue
brought by a service provision is
gi = ‚à´
Ri
0
biùúî(t)dt = bi(1 ‚àíe(ùúÜi‚àíniùúái)Ri).
Then the overall mean revenue from service instance i during a time slot is
Gi = ùúÜigi = ùúÜibi(1 ‚àíe(ùúÜi‚àíniùúái)Ri).
Thus our optimization problem can be formulated as
maximize
m
‚àë
i=1
ùúÜibi(1 ‚àíe(ùúÜi‚àíniùúái)Ri)
subject to
m
‚àë
i=1
ni = N.
(18.5)
Constructing Lagrange composite function
L(ni) =
m
‚àë
i=1
ùúÜibi
(1 ‚àíe(ùúÜi‚àíniùúái)Ri) + ùúÜ
(
N ‚àí
m
‚àë
i=1
ni
)
.
Letting dL‚àïdni = 0, where i = 0, 1, 2, ..., m,
ùúÜiùúáibiRie(ùúÜi‚àíniùúái)Ri ‚àíùúÜ= 0
ni = ln(ùúÜiùúáibiRi)
ùúáiRi
= lnùúÜ
ùúáiRi
+ ùúåi.

466
SMART PRICING OF CLOUD RESOURCES
600
500
400
300
200
100
Profit
‚àí100
0
0
20
40
Time (5 min)
MRT
Heuristic
60
80
100
500
450
350
250
150
50
400
300
200
100
Profit
0
20
40
Time (5 min)
MRT
Heuristic
60
80
100
Figure 18.4
Evolution of revenue during 5 min over time with traces.
Then we have
N =
m
‚àë
j=1
ln(ùúÜjùúájbjRj)
ùúájRj
‚àílnùúÜ
m
‚àë
j=1
1
ùúájRj
+
m
‚àë
j=1
ùúåj
lnùúÜ=
‚àëm
j=1
ln(ùúÜjùúájbjRj)
ùúájRj
+
m
‚àë
j=1
ùúåj ‚àíN
‚àëm
j=1
1
ùúájRj
.
Finally, we get
ni = ùúåi + ln(ùúÜiùúáibiRi)
ùúáiRi
‚àí
‚àëm
j=1
ln(ùúÜjùúájbjRj)
ùúájRj
+
m
‚àë
j=1
ùúåj ‚àíN
ùúáiRi
‚àëm
j=1
1
ùúájRj
.
And bounds should be obtained similarly as for the MRT case.
Experiments have been run on a C-based simulator we developed, and events been
simulated include arrival, departure, resource allocation for both the MRT and IRT
pricing models with the synthetic dataset, and the traced data set. Experimental results
for both MRT and IRT shown in Figure 18.4 proved that our algorithms outperform
heuristic method.
18.3
DATA CENTER TIME-DEPENDENT PRICING
In this section, we consider the problem of data center NPO, which aims to maximize
the difference between the total revenue from deadline-dependent pricing and the
electricity cost of distributed data centers [12]. Time-dependent pricing, which

DATA CENTER TIME-DEPENDENT PRICING
467
charges users based on not only how much resources are consumed but also when
they are consumed, has been widely studied in the electricity industry [17‚Äì20]
and the Internet service provider (ISP) industry [21‚Äì23] as an effective solution
to even out resource consumption peaks and reduce operating costs. However, the
problem for data center pricing is largely different because the prices are determined
by job deadlines (i.e., completion times), whereas job duration or progress are
irrelevant.
The goal here is to maximize the data center net profit through job scheduling. It
requires (i) to maximize the total revenue as a function of individual job completion
deadlines, (ii) to minimize the electricity cost by scheduling jobs to different time and
locations, and (iii) to satisfy a capacity constraint at each distributed data center. We
formulate this problem as a constrained optimization [12], whose solutions character-
izes an interesting trade-off between delay and cost‚Äîwhile completing a job earlier
generates a higher revenue, it restricts the set of feasible scheduling decisions, caus-
ing higher electricity cost. While being a complex, mixed-integer optimization due to
the scheduling formulation, the NPO problem remains to be hard because of the cou-
pling of scheduling decisions and job completion deadlines. There is no closed-form,
differentiable function that computes job completion deadlines by scheduling
decisions, which is often necessary if standard optimization techniques are to be
applied.
As we mentioned earlier, deadline-dependent pricing charges users based on both
the amount and the instance time at which the resources are consumed. Suppose that
a cloud computing service consists of a set of N distributed data centers and that its
billing cycle is divided into T periods. Let K be the total number of jobs submitted
for the next cycle. To enable deadline-dependent SLA and pricing, each user request
i not only contains the number of demanded VM instances (i.e., ri) and the total sub-
scription time (i.e., ùúÇi) but is also associated with a bid function Ui(t), which measures
the payment user i is willing to make if his/her job is accepted and scheduled to com-
plete by period t. For example, a bid function is flat when a user is indifferent to job
deadlines, whereas it becomes strictly decreasing when a user is willing to pay more
to get his/her job completed early.
18.3.1
Electricity Cost
In the electricity market of North America, Regional Transmission Organization
(RTO) is responsible for transmit electricity over large interstate areas and electricity
prices are regionally different. Electricity prices remain the same for a relatively
long period in some regions, whereas they may change every hour, even 15 min in
the regions who have wholesale electricity markets [9, 17, 18]. In this paper, we
consider cloud computing services consisting of distributed regional data centers,
which are subject to different electricity prices. When servers at each data center
are homogeneous, the total electricity consumption at each data center j over period
t can be calculated directly by multiplying the number of active servers mj(t) and
the electricity consumption per server cj. Let Pj(t) be the electricity price of data
center j at time t. We also assume that Pj(t) for t = 1, ‚Ä¶ , T is known noncausally at

468
SMART PRICING OF CLOUD RESOURCES
the beginning of each billing cycle. In practice, this can be achieved by stochastic
modeling of electricity prices [24, 25] or by purchasing forward electricity contracts
in the whole sale market [26, 27]. Thus the total electricity cost for N data centers
over the next cycle is given as
ùêÉCtotal =
N
‚àë
j=1
T
‚àë
t=1
mj(t)cjPj(t).
(18.6)
18.3.2
Workload Constraints
We denote the number of VM instances received by job i from data center j at period t
as xi,j(t). We consider two types of jobs: divisible jobs and indivisible jobs. An indivis-
ible job that requires ri VM instances and a subscription time ùúÇi cannot be interrupted
and must have ri VM running continuously for ùúÇi periods, whereas a divisible job
can be partitioned arbitrarily into any number of portions, as long as the total VM
instance hour is equal to the demand riùúÇi. Each portion of a divisible job can run
independently from other portions. Examples of applications that satisfy this divisi-
bility property include image processing, database search, Monte Carlo simulations,
computational fluid dynamics, and matrix computations [28]. Given the scheduling
decisions xi,j(t) of all jobs, the aggregate workload for each regional data center must
satisfy a service rate constraint
K
‚àë
i=1
xi,j(t) ‚â§ùúájmj(t), ‚àÄj, t,
(18.7)
where ùúáj is the service rate per server at regional data center j and mj(t) is the number
of active server at time t. There is also a limitation on the number of servers at each
location. Therefore, we have
mj(t) ‚â§Mj, ‚àÄt.
(18.8)
All user requests for the next cycle are collectively handled by a job scheduler,
which decides the location and time for each job to be processed in a judiciary manner.
This scheme can be viewed as a generalization of existing on-spot VM instances
in Amazon EC2, which allows users to bid for multiple periods and different job
deadlines (or job completion times). The system model is illustrated in Figure 18.5.
Let di denote the scheduled completion time of job i, the total revenue received by
the cloud provider over the next cycle is given as
ùêÉUtotal =
K
‚àë
i=1
Ui(di).
(18.9)
The goal of this paper is to design a job scheduler that maximizes the net profit
Utotal ‚àíCtotal over feasible scheduling decisions xi,j(t), subject to the workload con-
straints. For a given job completion time di, we denote the set of all feasible job

DATA CENTER TIME-DEPENDENT PRICING
469
2vms
5vms
2vms
3 h
2 h
2 h
1 h
1vm
Front-end
server
Job
scheduler
Data center 1
Data center 2
T
T
C
C
Figure 18.5
An illustration of our system model. Four jobs with different parameters are
submitted to a front-end server, where a job scheduler decides the location and time for each
job to be processed, by maximizing the net profit that a data center operator receives.
scheduling decisions by a set ùí≥(di). In particular, for a divisible job, a user is only
concerned with the total VM instance hour received before time di. This implies
ùí≥(di) =
{
xi,j(t) ‚à∂
N
‚àë
j=1
di
‚àë
t=1
xi,j(t) = riùúÇi,
}
,
(18.10)
where riùúÇi is the total demand of job i. On the other hand, an indivisible job must be
assigned to a single regional data center and run continuously before completion. It
will have a feasible scheduling set as
ùí≥(di) =
{
xi,j(t) ‚à∂xi,j(t) = 0 or ri ‚ãÖùüè(di‚àíùúÇi‚â§t‚â§di)
}
,
(18.11)
where ùüè(di‚àíùúÇi‚â§t‚â§di) is an indicator function and equals to 1 if t belongs to the scheduled
execution interval [di ‚àíùúÇi, di] and 0 otherwise. We suppress the positivity constraints
of xi,j(t) for simplicity of expressions.
We formulate the data center NPO problem as follows:
ùêèùê´ùê®ùêõùê•ùêûùê¶ùêçùêèùêé‚à∂
maximize
K
‚àë
i=1
Ui(di) ‚àí
N
‚àë
j=1
T
‚àë
t=1
mj(t)cjPj(t)
(18.12)
subject to
K
‚àë
i=1
xi,j(t) ‚â§ùúájmj(t), ‚àÄj, t
(18.13)
mj(t) ‚â§Mj, ‚àÄj
(18.14)
{xi,j(t)} ‚ààùí≥(di), ‚àÄi
(18.15)
variables di, xi,j(t), mj(t).
(18.16)

470
SMART PRICING OF CLOUD RESOURCES
The above problem can be looked at graphically as illustrated in Figure 18.5. It
requires a joint optimization of revenue and electricity cost, which is a mixed-integer
optimization because the scheduling decisions xi,j(t) are discrete for indivisible jobs.
Further, because of our deadline-dependent pricing mechanism, the maximization of
revenue over completion time di is coupled with the minimization of electricity cost
over feasible scheduling decisions ùí≥(di). However, there is no closed-form, differ-
entiable function that represents di by ùí≥(di). Therefore, off-the-shelf optimization
algorithms cannot be directly applied.
It is worth noticing that our formulation of Problem NPO in Eq. (18.12) also incor-
porates sharp job deadlines. For instance, if job i must be completed before time t‚àó,
we can impose a utility function with Ui(t) = ‚àí‚àû, for all t > t‚àó, so that scheduling
decisions with a completion time later than t‚àóbecomes infeasible in Problem NPO.
Problem NPO is a complex joint optimization over both revenue and electricity
cost, whose optimization variables; scheduling decisions {xi,j(t)} ‚ààùí≥(di) and job
completion time di are not independent of each other. There is no closed-form, dif-
ferentiable function that relates the two optimization variables. Let xi(t) = ‚àë
j xi,j(t)
be the aggregate service rate received by job i at time t. For given scheduling decisions
xi,j(t), we could have replaced constraint (18.15) by a supremum
di = sup
ùúè
{
ùúè‚à∂
ùúè‚àë
t=1
xi(t) < riùúÇi
}
,
(18.17)
where riùúÇi is the total demand of job i. However, it still requires evaluating supremum
and inequalities and, therefore, does not yield a differentiable function to represent
di by scheduling decisions {xi,j(t)}.
To overcome this difficulty, an approximation of the job completion time function
in Eq. (18.17) by a differentiable function is proposed in Reference 12:
ÃÇdi = 1
ùõΩ‚ãÖlog
(
1
riùúÇi
T
‚àë
t=1
eùõΩt ‚ãÖxi(t)
)
,
(18.18)
where ùõΩis a positive constant and 1‚àï(riùúÇi) normalizes the service rate xi(t). The accu-
racy of this approximation is given as follows.
Theorem 18.2
For a positive constant ùõΩand a bounded service rate 0 ‚â§xi(t) ‚â§
xmax, we have
riùúÇi ‚ãÖ
[
1 ‚àílog(1 + ùõΩ‚àïxmax)
ùõΩ‚àïxmax
]
‚â§
ÃÇdi
‚àë
t=1
xi(t) ‚â§riùúÇi.
(18.19)
Hence, limùõΩ‚Üí‚àûÃÇdi = di, that is, the approximation in Eq. (18.18) becomes exact.
By the approximation in Eq. (18.18), we obtain a closed-form, differentiable
expression for ÃÇdi, which guarantees an approximated completion of job i off by

DATA CENTER TIME-DEPENDENT PRICING
471
a logarithmic term xmax log(1 + ùõΩ‚àïxmax)‚àïùõΩin the worst case. The approximation
becomes exact as ùõΩapproaches infinity. However, often there are practical constraints
or overhead concerns on using large ùõΩ. We choose an appropriate ùõΩsuch that the
resulting optimality gap is sufficiently small.
An algorithmic solution for Problem NPO with divisible jobs is derived in
Reference 12. The problem has a feasible set:
ùí≥(di) =
{
xi,j(t) ‚à∂
N
‚àë
j=1
di
‚àë
t=1
xi,j(t) = riùúÇi
}
.
(18.20)
In order to solve the problem, we leverage the approximation of job completion time
in Eq. ([18.18]) to obtain an approximated version of Problem NPO. The resulting
problem has an easy-to-handle analytical structure and is convex for certain choices
of Ui functions. Further, when the problem is nonconvex, we then convert it into a
sequence of linear programming and solve it using an efficient algorithm. It provides
useful insights for solving Problem NPO with indivisible jobs.
Rewriting Eq. (18.15) in Problem NPO using the approximation in Eq. (18.18)
and the feasible set in Eq. (18.20), we obtain a net profit optimization problem for
divisible jobs (named Problem NPOD) as follows:
ùêèùê´ùê®ùêõùê•ùêûùê¶ùêçùêèùêéùêÉ‚à∂
maximize
K
‚àë
i=1
Ui( ÃÇdi) ‚àí
N
‚àë
j=1
T
‚àë
t=1
mj(t)cjPj(t)
(18.21)
subject to
K
‚àë
i=1
xi,j(t) ‚â§ùúájmj(t), ‚àÄj, t
(18.22)
mj(t) ‚â§Mj, ‚àÄj
(18.23)
ÃÇdi = 1
ùõΩlog
(
1
riùúÇi
T
‚àë
t=1
N
‚àë
j=1
eùõΩtxi,j(t)
)
(18.24)
N
‚àë
j=1
T
‚àë
t=1
xi,j(t) = riùúÇi
(18.25)
variables ÃÇdi, xi,j(t), mj(t),
(18.26)
where completion time becomes a differentiable function of xi,j(t). The optimization
variables in Problem NPOD may still be integer variables, that is, the number of
active servers mj(t) and the number of demanded VM instances xi,j(t). We can lever-
age rounding techniques (e.g., [29]) to relax Problem NPOD so that its optimization
variables become continuous.
As inequality constraints in Eqs. (18.22), (18.23), and (18.25) are linear, we inves-
tigate the convexity of the optimization objective in Eq. (18.21), which is a function

472
SMART PRICING OF CLOUD RESOURCES
of xi,j(t) and mj(t), by plugging in the equality constraint (18.24). It is shown [12] that
for ÃÇdi in Eq. (18.24) and a positive differentiable Ui(‚ãÖ), the objective function of Prob-
lem NPOD is convex if U‚Ä≤‚Ä≤(y) ‚â•ùõΩU‚Ä≤(y) for all y > 0 and concave if U‚Ä≤‚Ä≤(y) ‚â§ùõΩU‚Ä≤(y)
for all y > 0. The two conditions of Ui(‚ãÖ) capture a wide range of functions in prac-
tice. Let a > 0 and b be arbitrary constants. Examples of Ui(‚ãÖ) that result in a concave
objective function include certain exponential and logarithmic functions. Examples
that result in a convex objective function include linear Ui(y) = b ‚àíax and logarithm
Ui(y) = a ‚àíb log(y). We remark that when U‚Ä≤‚Ä≤(y) ‚â§ùõΩU‚Ä≤(y) for all y > 0, Problem
NPOD is a concave maximization. It can be solved efficiently by off-the-shelf con-
vex optimization algorithms, for example, primal-dual algorithm and interior point
algorithm [30].
On the other hand, when Problem NPOD maximizes a convex objective, an iter-
ative solution based on difference of convex programming is proposed [12]. Relying
on a linearization of the objective, the following iterative algorithm is used to solve
Problem NPOD via a sequence of linear programming. It starts at some random initial
point x(0)
i,j (t), solves the linear programming with x(k‚àí1)
i,j
(t), and, therefore, generates a
sequence {x(k)
i,j (t)}‚àû
k=0. This procedure is indeed a special case of the difference of con-
vex programming and has been extensively used in solving many nonconvex programs
of similar forms in machine learning [31]. It is shown that the sequence {x(k)
i,j (t)}‚àû
k=0
converges to a local minimum or a saddle of Problem NPOD, as in Theorem 18.2.
We further apply a primal-dual algorithm [30] to obtain a distributed solution to each
linear programming. The algorithm is summarized in Fig. 18.6.
Finally, we evaluate our algorithmic solution for Problem NPOD over a 24-h
cycle, divided into T = 144 10-min periods. The goal is to obtain empirically
Initialize a feasible point {xi,j (t)}, k = 0, and step size Œ¥ > 0. 
(0)
for each k, iteratively solve the linearization:
Find effective profit for each data center j and period t:
Œìj (t) =
for each job i
Schedule job i to maximize ‚àëj,t Œìj (t) ¬∑ xi,j  (t), satisfying
(k)
(k)
(k)
(k)
(k)
(k)
(k)
(k‚àí1)
(k‚àí1)
(k‚àí1)
(k)
NPOD: ‚àëi,j,t xi,j  (t) = ri Œ∑i
(t) =  Œªj       (t) + Œ¥(mj    (t) ‚àí Mj)
NPOI: xi,j  (t) = 0 or ri ¬∑ 1(y‚àíŒ∑i ‚â§ t ‚â§y) for some y
end for
end for
Obtain mj    (t) = ‚àëi xi,j (t)
Update price
k ‚Üê k + 1
Ui (di          )
eŒ≤t
ri Œ∑i Œ≤eŒ≤di
Œºj
ÀÜ
‚Ä≤
ÀÜ
cjPj (t) + Œªj   (t)
‚àí
Œªj
+
Figure 18.6
Algorithmic solution for Problem NPOD.

DATA CENTER TIME-DEPENDENT PRICING
473
validated insights about the feasibility/efficiency of our solution using synthesized
data from a recent study [9]. We construct N = 3 regional data centers, which
reside in different electricity markets and have electricity prices P1(t) =$56‚àïMWh,
P2(t) =$(51 + 15 cos 0.05t)‚àïMWh,
and
P3(t) =$(45 + 20 sin 0.06t)‚àïMWh.
The
data centers host M1 = 2000, M2 = 1000, and M3 = 1000 servers. Each server is
operating at cj = 1200 W with ùúáj = 4 VMs per server for j = 1, 2, 3.
We construct two types of jobs: elephant jobs that subscribes ri ‚àà[50, 100] VMs
for ùúÇi = [10 ‚àí20] periods and mice jobs that subscribes ri ‚àà[5, 20] VMs for ùúÇi =
[1 ‚àí10] periods. In our simulations, both ri and ùúÇi are uniformly randomly gener-
ated from their ranges. We fix the total workload to be K = 1200 jobs, each being
an elephant job with probability 20% and a mice job with probability 80%. Job i is
associated with a nonlinear bid function, given by
Ui(di) = riùúÇi ‚ãÖ(a ‚àíb log t) (dollars),
(18.27)
where a ‚àà[0.01, 0.02] and b ‚àà[0.001, 0.002] are uniformly distributed. Using this
nonlinear bid function, the approximation of job completion time will result in a con-
vex objective function in Eqs. (18.12) and (18.21). All numerical results shown in
this section are averaged over five realizations of random parameters.
To provide benchmarks for our evaluations, we also implement a greedy algo-
rithm that sequentially schedules all jobs with a largest job first (LJF) policy and a
heuristic algorithm NPOI (net profit optimization problem for indivisible jobs) by
assuming indivisible jobs in problem NPOI. Figure 18.7 compares the optimized net
profit of NPOD, NPOI, and LJF algorithms. When jobs are indivisible, our NPOI
algorithm improves the net profit by 12% over the baseline LJF algorithm (from $1868
NPOD
NPOI
LJF
0
500
1000
1500
2000
2500
3000
3500
Dollar
 
Net profit
Total revenue
Electricity cost
Figure 18.7
A comparison of optimized net profit of NPOD, NPOI, and LJF.

474
SMART PRICING OF CLOUD RESOURCES
to $2095), while an additional 16% increment (to $2394) can be achieved by NPOD
if all jobs are divisible. We also notice that our NPOI algorithm is able to simultane-
ously improve total revenue and cut down electricity cost, compared to the baseline
LJF algorithm. This is achieved by the joint optimization over job completion time
di and scheduling decisions xi,j(t).
18.4
CONCLUSION AND FUTURE WORK
This chapter discussed three different approaches on smart pricing of cloud services
and resources: VM-based pricing, SLA-based pricing, and time-dependent pricing.
There is a large number of open problems on topics discussed in this chapter. Many of
them are due to the delicate trade-off between operators‚Äô goal of profit maximization
and users‚Äô demand for individual performance optimization. In a multiuser environ-
ment, while maximizing their total revenue, cloud operators may need to consider
establishing a social scheduling policy that would prevent ‚Äúpoor‚Äù users from being
entirely deprived of resources. Algorithmic solutions to the nonconvex problem of job
scheduling and NPO has not been found. Further, to analyze different pricing poli-
cies, user payment models must be constructed to reflect not only users‚Äô satisfaction
and willingness to pay but also their budget and financial means. Further challenges
will arise as stochastic arrivals/departures of users‚Äô demand and cloud resources are
incorporated.
REFERENCES
1. KPMG International. ‚ÄúClarity in the Cloud‚Äù, Online technical report at http ‚à∂
‚àï‚àïwww.kpmg.com‚àï, Nov. 2011.
2. N. Chohan. See spot run: using spot instances for mapreduce workflows. In USENIX Hot-
Cloud Workshop, 2010.
3. S. Yi, D. Kondo, and A. Andrzejak. Reducing costs of spot instances via checkpointing in
the amazon elastic compute cloud. IEEE International Conference on Cloud Computing,
2010.
4. Amazon Elastic Compute Cloud User Guide. Getting Started with Spot Instances.
docs.amazonwebservices.com/AWSEC2, Oct. 2008.
5. R. Buyya, Cs. Yeo, J. Broberg, and I. Brandic. ‚ÄúCloud computing and emerging IT plat-
forms: vision, hype, and reality for delivering computing as the 5th utility,‚Äù Future Gen-
eration Computer Systems, 25, 2009, 599‚Äì616.
6. X. Fan, W. Weber, and L. A. Barroso. Power provisioning for a warehouse sized computer.
In Proceedings of the 34th Annual International Symposium on Computer Architecture,
2007.
7. S. Nedevschi, L. Popal, G. Iannaccone, S. Ratnasamy, and D. Wetherall. Reducing network
energy consumption via sleeping and rate-adaptation. In Proceedings of the 5th USENIX
Symposium on Networked Systems Design & Implementations (NSDI), 2008.
8. L. Parolini, B. Sinopoli, and B. Krogh. Reducing data center energy consumption via coor-
dinated cooling and load management. In Proceedings of ACM Workshop on Power Aware
Computing and Systems, 2008.

REFERENCES
475
9. L. Rao, X. Liu, L. Xie, and W. Liu. Minimizing electricity cost: optimization of distributed
internet data centers in a multi-electricity market environment. In Procedings of IEEE
Infocom, 2010.
10. P. Patel, A. Ranabahu, and A. Sheth. Service level agreement in cloud computing. In Pro-
ceedings of the Workshop on Best Practices in Cloud Computing, 2009.
11. C. Wilson, H. Ballani, T. Karagiannis, and A. Rowstron. Better never than late, meeting
deadlines in data center networks. In Proceedings of SIGCOMM, 2011.
12. W. Wang, P. Zhang, T. Lan, and V. Aggarwal. Data center net profit optimization with
individual job deadlines. In Proceedings of CISS 2012 (Invited paper), March 2012.
13. A. Danak and S. Mannor. Resource allocation with supply adjust- ment in distributed com-
puting systems. In International Conference on Distributed Computing Systems (ICDCS),
2010.
14. L. Fleischer. Tight approximation algorithms for maximum general assignment problems.
In ACM Symposium on Discrete Algorithms, 2006.
15. W. W. S. Wei. Time Series Analysis: Univariate and Multivariate Methods. Addison Wes-
ley, Reading, MA, 1990.
16. C. Gong, J. Liu, Q. Zhang, H. Chen, and Z. Gong. The characteristics of cloud computing.
39th International Conference on Parallel Processing Workshops, pp.275‚Äì279, 2010.
17. S. Littlechild. Wholesale spot price pass-through. Journal of Regulatory Economics, 23(1),
2003, 61‚Äì91.
18. S. Borenstein. ‚ÄúThe long-run efficiency of real-time electricity pricing,‚Äù The Energy Jour-
nal, 26(3), 2005, 93‚Äì116.
19. K. Herter. ‚ÄúResidential implementation of critical-peak pricing of electricity,‚Äù Energy Pol-
icy, 35(4), 2007, 2121‚Äì2130.
20. A. Faruqui, R. Hledik, and S. Sergici, ‚ÄúPiloting the smart grid,‚Äù Electricity Journal, 22(7),
2009, 55‚Äì69.
21. H. Chao. ‚ÄúPeak load pricing and capacity planning with demand and supply uncertainty,‚Äù
Bell Journal of Economics, 14(1), 1983, 179‚Äì190.
22. G. Brunekreeft. Price Capping and Peak-Load-Pricing in Network Industries. Diskus-
sionsbeitrage des Instituts fur Verkehrswissenschaft und Regionalpolitik, Universitat
Freiburg, vol. 73, Freiburg, Germany, 2000.
23. H. Sangtae, S. Soumya, J. Carlee, I. Youngbin, and C. Mung. ‚ÄúTUBE: time-dependent pric-
ing for mobile data,‚Äù In Procedings of ACM SIGCOMM 2012 Conference on Applications,
Technologies, Architectures, and Protocols for Computer Communication, SIGCOMM
‚Äô12, pp. 247‚Äì258, 2012.
24. P. Skantze, M. D. Ilic, and J. Chapman. Stochastic modeling of electric power prices in a
mult-market environment. IEEE Power Engineering Society Winter Meeting, 2000.
25. S. Fleten and J. Lemming, ‚ÄúConstructing forward price curves in electricity markets,‚Äù
Energy Economics, 25, 2007, 409‚Äì424.
26. C. K. Woo, I. Horowitz, and K. Hoang. ‚ÄúCross hedging and value at risk: wholesale elec-
tricity forward contracts,‚Äù Advances in Investment Analysis and Portfolio Management, 8,
2001, 283‚Äì301.
27. R. Weber. Cutting the electric bill for Internet-scale systems. In Proceedings of SIG-
COMM, pp. 123‚Äì134, 2009.
28. B. Veeravalli and W. H. Min. ‚ÄúScheduling divisible loads on heterogeneous linear daisy
chain networks with arbitrary processor release times,‚Äù IEEE Transactions on Parallel and
Distributed Systems, 15, 2010, 273‚Äì288.

476
SMART PRICING OF CLOUD RESOURCES
29. A. Neumaier and O. Shcherbina. ‚ÄúSafe bounds in linear and mixed-integer linear program-
ming,‚Äù Mathematical Programming, 99, 2004, 283‚Äì296.
30. S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press, Cam-
bridge, United Kingdom, 2004.
31. B. K. Sriperumbudur and G. R. G. Lanckriet. ‚ÄúOn the Convergence of the
Concave-Convex Procedure‚Äù, Online technical report at http ‚à∂‚àï‚àïcosmal.ucsd.edu‚àï‚àº
gert‚àïpapers‚àïnips_cccp.pdf, 2009.

19
Allocating and Pricing Data
Center Resources with
Power-Aware Combinatorial
Auctions
BENJAMIN LUBIN and DAVID C. PARKES
19.1
INTRODUCTION
As data centers become ever more essential to not only our economy but also our
daily lives, it is increasingly important for them to be well managed. Three specific
aspects are of paramount importance: ensuring that the right resources be allocated to
the right use, ensuring that power is used only when it is providing real benefit, and
making sure that the prices charged to users for service are providing incentives that
support such allocative and power efficiency. In this chapter, we look at a method for
employing a combinatorial market mechanism to achieve these ends.
In 2006, US data centers used about 61 billion kWh; that is, 1.5% of the 4 trillion
kWh consumed in total. This is the amount of energy used by 5.8 million average
US households (5% of all households) [1]. Producing this power resulted in 37
million metric tons of CO2, or 0.6% of the 5.9 billion metric tons released from all
sources. That is roughly 16% of that produced by the burning of jet fuel and more
than that used to power TVs. This electricity cost $4.5 billion and required a peak
load capacity of about 7 GW, more than double the level of consumption in 2000 [2,
3]. This pace of rising data center energy consumption has slowed, with global data
center power usage rising 56% over its 2005 level by 2010 [4], but this modestly
slower growth rate is still alarmingly fast and a serious cause for concern. Peak
usage has reached approximately 30 GW, and of this, an average of only 6‚Äì12% of
electricity goes to actual computation, the rest powering idle computers and support
systems such as cooling [5].
Given rising power consumption and its associated financial and environmen-
tal costs, data-center operators realize that the established practice of running large
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
477

478
ALLOCATING DATA CENTER RESOURCES WITH COMBINATORIAL AUCTIONS
numbers of significantly underutilized servers is no longer acceptable and are eager
for energy-saving solutions.
Market paradigms have often been proposed as useful for allocating limited com-
putational resources and satisfying multicriteria objectives. The earliest work on such
markets was for time sharing on the PDP-11 in the 1960s by Sutherland [6]. In the
intervening years, there have been proposals to use such methods in high performance
computing and grid computing, as well as in data centers.
However, existing proposals have deficiencies that can render them impractical for
modern data centers. Here, we describe a general method for overcoming these con-
cerns and illustrate its applicability to one specific environment. Our method provides
the following:
A Realistic Model of Resources. We support a fine granularity of computational
entity (e.g., core vs server, which is especially important as multicore machines
become the norm) and fine control over the power state of machines (e.g.,
Dynamic Voltage and Frequency Scaling (DVFS), not just on/off). We also han-
dle heterogeneous applications running on heterogeneous classes of servers.
A Realistic Representation of Goals. We use a general form of utility function
expressed in terms of outcome percentile and derived from standard long-term
service-level agreements (SLAs)
that are programatically interpreted as
short-term utility functions in a dynamic environment.
Principled Optimization. We adopt mixed-integer programming (MIP) for opti-
mization of data center resources, providing a carefully formulated MIP model
that can scale to large problem sizes.1
We show that a market-based approach provides a natural, feasible, and advanta-
geous framework for representing the milieu of physical and computational resources,
and the applications that consume these resources, in modern day data centers.
Experimental results indicate that such a system can robustly and scalably improve
net profits of our data-center prototype by up to 137%. We envision reallocating
resources in the data center in roughly 10-min periods. So it is important that our
mechanism should be able to compute an allocation within one time period, permit-
ting the allocation to be realized on time. For large instances of 1000 machines and
10 applications (all associated with different customers), each with a realistic demand
of 2700 transactions a second, when limiting MIP solve time to 10 min, we achieve
an average solve time of 5.16 min, with a negligible approximation imposed on the
instances that timeout. Thus a dedicated machine can optimize the usage on 1000
others, providing an acceptable 0.1% overhead factor.
19.1.1
Related Work
In many ways, the modern problem of allocating data center resources is a reca-
pitulation of the problem of allocating slices of the early time-sharing systems of
1We leverage recent advances in MIP technology that enable combinatorial markets to be cleared quickly
in practice by exploiting problem structure and despite NP-hard winner determination problems [7].

INTRODUCTION
479
the 1960s. The modern need for expressive ways for users to describe their require-
ments has parallels in early methods such as IBM‚Äôs Job Control Language (JCL).
Consequently, there is a long history of proposed methods for describing user‚Äôs com-
putational requirements and for allocating resources based on those requirements.
Most of these systems have not taken a market approach. Rather, they have assumed
that resource owners require effective ways to allocate their hardware and that they
would thus gather enough information to approximately solve an appropriate bin
packing problem. Pricing has typically been a separate consideration‚Äîeither because
the system owner and users are in the same firm or because it has been handled by a
separate human-mediated contracting process.
There are a number of limitations to such an approach. First, just because the
hardware may be owned by the same firm as the users does not guarantee that appro-
priate prioritization of jobs will be manifest in the system‚Äîcompetition for resources
occurs even within cooperative organizations. Thus hardware ownership may have
less importance than is often assumed as, inevitably, there are two sides to the allo-
cation problem: those who need resources and those who have them. If the allocator
can make an accurate estimate of user needs, then treating the system as monolithic
is without loss. However, this is difficult in practice, and thus it is often essential for
users to provide this information. As soon as they do so, they may be incentivized
to misrepresent their needs, in order to obtain more resources or a better price. If, as
is ideal, we wish to confront this potential gaming of the system, the full allocation
problem falls into the field of mechanism design, which considers the problem of
designing systems for gathering information necessary for optimal allocation when
agents may attempt to game the system. Viewed from this lens, pricing creates power-
ful incentives for participants and is thus also essential for moderating manipulation
of the system and thereby enabling high quality outcomes. In this chapter, we adopt
this view and construct a market mechanism that attempts to balance the ‚Äúbuyers‚Äù
and ‚Äúsellers‚Äù view of the data center. Our method is directly scalable to the allocation
of a thousand machines and could be replicated in a straightforward way to handle
arbitrary numbers of such pools. We view this approach as better capturing the full
scope of the allocation problem, although clearly the simpler problem of allocation
on behalf of a single monolithic owner is still important and challenging in its own
right.
Chase et al. [8] and Chen et al. [9] present a market-based system for data
center resource allocation and are able to experimentally demonstrate significant
energy savings over static allocations. However, their greedy clearing mechanism
imposes restrictions on the form of utility that can be modeled, SLAs are not directly
represented, and demand/utility computations occur with respect to mean statistics
instead of distributional information. Their model does not handle the heterogeneity
of data-center machines or modern power-throttling architectures (instead simply
turning machines on and off) and allocates servers rather than cores. The nonlinear
cost model that we use is related to the one provided by Chen et al. [9]. But rather
than identifying total-value maximizing allocations with respect to SLAs, they treat
SLAs as constraints and attempt to find the cheapest allocation subject to meeting
implied quality constraints.

480
ALLOCATING DATA CENTER RESOURCES WITH COMBINATORIAL AUCTIONS
One branch of work on resource allocation in data centers has focused on utility
computing, which seeks to provide access to data centers in a way that is analogous
to that of a public utility (e.g., gas, water, power) [10, 11]. In general, utility com-
puting views computational resources as easily substituted for one another, whereas
we allow only particular machines to be configured for, and capable of running, cer-
tain applications. Rather than argue for a more radical shift in how computation is
bought, sold, and deployed, we propose a more gradual evolutionary step by creating
a market that handles the heterogeneity in present data centers and encompasses and
generalizes the present contract format (SLAs).
There is an extensive literature on using market-based methods in related contexts,
including computational grids and high performance computing. Yeo and Buyya
[12] provide an abstract model of a market-based resource manager as comprised
by its various parts, including a market model, an economic model, pricing, ten-
dering, bidding, buyer/seller focus, a trading environment, QoS attributes, resource
composition, an execution service/support, an accounting mechanism, management
control, and a job model. The authors offer an extensive survey of existing systems
according to these properties. In another survey, Broberg et al. [13] contrast several
different market-based allocations systems and evaluate their pros and cons. These
authors argue that fixed pricing can be problematic, that optimal combinatorial bid-
ding and pricing can be expensive, and propose a particular ad hoc pricing mechanism
that seeks a compromise between expressivity and scalability. In general, all allo-
cation methods must grapple with this trade-off; we handle it by appeal to modern
mixed-integer optimization algorithms that are ‚Äúanytime‚Äù and can thus be stopped
early at high quality approximate solutions.
A market in our setting is combinatorial in nature; participants must be able to
bid (indirectly, via SLAs) on ‚Äúpackages‚Äù of items, where the value for a package
need not be a linear combination of the value for its constituent items. There is a long
literature on combinatorial auctions; an excellent overview is provided in the book
by Crampton et al. [14].
19.2
A MARKET MODEL OF DATA CENTER ALLOCATION
In this section, we describe how to represent the energy-aware data-center alloca-
tion problem as a market. Using a market for the internal allocation both ensures that
resources will be used in an economically optimal way and opens a path to expos-
ing customers to the mechanism as well. In turn, this can enable better information
revelation and thus higher efficiency allocations and/or higher revenue. To begin, we
describe the type of operation we see such a system operating within and define some
needed terminology.
Typical data centers have thousands of servers, many of which will share the same
hardware and software configuration. We call such equivalence classes ‚Äúmachine
groups‚Äù and assume that this partitioning is performed by a separate offline process.
The owner of a data center typically contracts (either internally or externally) to pro-
vide these resources to a set of applications (each associated with a customer), each

A MARKET MODEL OF DATA CENTER ALLOCATION
481
with time-varying load and utility and a range of resource requirements and impor-
tance.
In present use, each application is associated with an SLA that is negotiated
between the customer and the data-center provider. Such an agreement specifies a
price, a performance objective (e.g., a cap on the 95th percentile of response time),
and a penalty for failing to meet the objective. The SLA is useful for assigning
a relative importance to the applications, but despite its quantitative nature, it is
generally used at present in only a qualitative way, as a guideline for personnel
when manually configuring data-center operations. Yet, SLAs suggest a direction
toward application utility functions that are highly relevant to obtaining reasonable
performance in a power-constrained environment [15, 16]. Here, we introduce a
system that adopts SLAs for the purpose of utility-based optimization of resource
configurations.
When allocating resources in the data center, we seek to optimize the operator‚Äôs
business value for the data center: that is, the revenue net of costs. This means assign-
ing (portions of) the machines from discrete machine groups to the various applica-
tions as well as specifying the power for each machine and thus restraining overall
consumption. For this, we use a detailed model of the power saving modes available
to modern servers and assume access to monitors of both power consumption and
application usage.
Our market allocates goods (cores of machines from the various machine groups)
to applications, as illustrated in Figure 19.1. The market is repeatedly cleared over
brief periods, allocating resources to maximize the value reflected in short-term bids.
User
User
User
User
User
User
User
Buyers
Asks
Market
Goods
User
User
User
User
User
System
administration
Demand
Bids
Sellers
Application
Application
Application
Provider
Provider
Provider
Energy
costs
Hardware
costs
Hard
constraints
Supply and 
allocation 
constraints
Prices and soft 
constraints 
Figure 19.1
The data center market model.

482
ALLOCATING DATA CENTER RESOURCES WITH COMBINATORIAL AUCTIONS
These short-term bids are generated automatically from predictions about future sup-
ply and demand as well as applications‚Äô long-term SLAs. In our experiments, we have
used 10-min intervals, chosen to match the demand volatility we see in the applica-
tions we are modeling. The winner-determination problem requires optimization and
could be approximately solved via heuristic search. We choose to formulate it as a
mixed-integer program and solve it via a commercial solver, specifically IBM ILOG
CPLEX. The form of the buyer (or customer‚Äôs) value model and seller cost model
have been chosen to ease formulation of the problem as a MIP, as described in the
following.2
The formulation presented here is myopic in that it predicts demand in the next
period and seeks the optimal allocation for that period. Instead, we could formu-
late a stochastic optimization problem that predicts multiple time steps forward and
seeks an optimal allocation over that longer time period. However, such a formu-
lation will be complex and difficult to solve with much fidelity over the short time
frame available to the solver, and thus we view a single time-step solution as a rea-
sonable simplification. Moreover, if reasoning about future time periods, we would
ideally permit participant‚Äôs bids to capture changes in value over time, leading to a
scheduled market instead of the spot market presented here. We leave this important
extension for future work.
For each period, we use a myopic net revenue maximization objective:
max
‚àë
a‚ààA
Va ‚àíùúÖEtotal
a
‚àíHtotal
a
,
(19.1)
where Va is the value of the chosen allocation of machines to application (associated
with a particular buyer) a ‚ààA, ùúÖis the dollar cost of a kiloWatt-hour of energy, Etotal
a
is the total energy used to establish and maintain the chosen allocation for the current
period, and Htotal
a
is the dollar cost for the hardware.
The objective is thus quite straightforward, and the complexity comes from the
constraints that define and restrict these variables. We begin by defining the buyer
value, Va, that is, the value associated with application a of some buyer. We note that
throughout this section we treat Va as the buyer‚Äôs true value for the service he/she
receives. In practice, this value is not known a priori to the mechanism and must
instead rely on the buyer‚Äôs reported values. The existence of strategic opportunities
to customers for misreporting values will depend on the interaction with the pricing
rule used to charge for the service. We defer discussion of pricing rules and their
incentive properties to Section 19.5.
19.2.1
Buyer Valuation Model
The contracts signed for data center provisioning are typically in terms of SLAs. We
model a per-application SLA contract as a piecewise linear function for the value of
2The size of the formulation will grow linearly with the number of applications and machine groups.
However, it will grow with the square of the number of power modes (because it encodes a transition
matrix from one mode to the next). Fortunately, polynomial growth in the size of the MIP need not imply
exponential growth in practical computation time, and we examine scalability in Section 19.3.1.

A MARKET MODEL OF DATA CENTER ALLOCATION
483
Value for 95th percentile response time
0
5000
10,000
15,000
20,000
25,000
30,000
35,000
40,000
45,000
50,000
0
0.2
0.4
0.6
0.8
1
1.2
Response time per transaction (s)
Value per month ($)
A value
B value
Figure 19.2
SLAs as provided by two different applications.
receiving a given response time at a given demand percentile. This form has a number
of advantages. As in contracts commonly used in practice, it is expressed in terms of
an outcome metric percentile (e.g., 95th percentile). This enables the most extreme
cases to be ignored as outliers but captures ‚Äúbad-case‚Äù behavior in a way that the mean
does not. While typical industry SLAs specify a single value for service exceeding a
threshold quality at this percentile, we generalize this notion to allow a range of pos-
sible service levels. We are thus able to capture the value of degraded-but-still-useful
service in a way that traditional SLAs cannot. Figure 19.2 shows an example of an
SLA value curve of this form for two different applications A and B.
Rather than having bidders interact directly with the market, we use a proxy that
operates on their behalf. This shields the human buyers from having to deal with
low level details, instead of letting them to concentrate on the high level value func-
tion with which they are familiar. The bidding proxy takes the SLA thus provided
and combines it with supply and demand prediction and an application performance
model, to represent the SLA as a short-term bid; that is, a bid that is appropriate for
the period of time for which the market is cleared.
In order to construct this short-term bid, the bidding proxy needs a model of how a
given supply of machines (and thus transaction capacity) and application demand for
the next planning episode will translate to the long-term response-time distribution
(and in turn to, e.g., its 95th percentile) and thus to the value curve associated with
an SLA.
As a very simple example, let us assume that transaction processing is described
as an M/M/1 queue (exponential interarrival and service times). In this case, the
response-time distribution is exponential with mean response time 1‚àï(ùúá‚àíùúÜ), where
ùúáis the supply and ùúÜis the demand, both in transactions per unit time. The fraction
of response times above a percentile P is given by the exponential quartile function:
‚àíln(1‚àíP)
(ùúá‚àíùúÜ) . The proxy composes the customer‚Äôs SLA (Fig. 19.2) with this response-time

484
ALLOCATING DATA CENTER RESOURCES WITH COMBINATORIAL AUCTIONS
0
0.5
1
1.5
2
2.5
√ó-107
√ó-107
0
1
2
3
4
0
5
10
15
20
25
Demand in MCycles per period
Supply in MCycles per period
Value in dollars per period
Figure 19.3
Application value by supply and demand.
model, resulting in a value function over both supply and demand at, for example,
the 95th percentile (Fig. 19.3). As depicted in the figure, the value is scaled by pre-
dicted demand relative to the mean statistic. This is necessary to translate from the
long-term value specified in the SLA into a short-term bid. Thus, we, on behalf of
the bidder, estimate future demand and figure out an appropriate bid for the trans-
actions expected in the current period. With this conversion, the market tracks the
long-term statistics that are a customer‚Äôs true concern (as reflected in the SLA). We
note that this bid conversion is not done for strategic reasons, but rather to gen-
erate value-based information that can be used to drive good short-term allocation
decisions.3
In addition, the bidding proxy needs a predictive model of application demand over
the next period to construct its short-term bid. We have found it sufficient to simply
use statistics gathered over a small window of previous periods to provide a Gaus-
sian model of the distribution of possible demand in the next period via a maximum
likelihood estimation (MLE) of mean and standard deviation. The bidding proxy
draws equal weighted samples from this Gaussian demand prediction model and
takes a slice from the value model (Fig. 19.3) for each sample, in a process of inverse
3Depending on the pricing structure ultimately used by the market, incentives for strategic bidding may or
may not be present. Where such incentives remain, the consequent bidder strategizing will be outside the
scope of the bid conversion process described.

A MARKET MODEL OF DATA CENTER ALLOCATION
485
0
2
4
6
8
0
5
10
15
20
25
Supply in TCycles period
14
12
10
Dollars per period
Figure 19.4
Expected short-term value for a single application.
transform sampling. These slices are averaged to produce a single consumption-value
curve that manifests our demand model. By taking a piecewise linear approxima-
tion of this curve (obtained by chaining the control points of the originally supplied
response-time/value curve through these transformations), we arrive at a utility curve,
which is provided to the market in a given period as a bid. An example of such a bid
is shown in Figure 19.4.
Through these transformations, we arrive at a value function, which is a mapping
from potential resources bundles to agent value and used by the winner-determination
algorithm to clear the market. In particular, the bidder proxy creates a function
Va = Fa(Qa),
(19.2)
for application a, where Fa is the piecewise linear function we have established
through the process just described and Qa is the number of cycles provided to appli-
cation a by the chosen allocation. To formulate this function, any standard MIP rep-
resentation for a piecewise linear function can be used, which will induce auxiliary
constraints and variables in order to account for the various line segments.
Importantly, the value function is specified in terms of cycles, not in terms of the
underlying machine groups and power modes that are supplying them. This results in
a significant dimensionality reduction and simplifies the winner-determination prob-
lem. However, in cases where differences in the underlying hardware architecture are
important to application performance (e.g., all cycles are not equal and xeon cycles
perform differently from atom cycles), an extension to a more complex higher dimen-
sional model is available; see Reference 17 for details.
Next, we turn our attention to modeling the argument to our function Fa, the total
number of cycles provided to application a in a period, defined as
Qa =
‚àë
g‚ààGa
‚àë
f‚ààMg
‚àë
t‚ààMg
ùõæg,t(ùúè‚àíùõøg,f,t)Csold
g,f,t,a ‚àÄa ‚ààA,
(19.3)

486
ALLOCATING DATA CENTER RESOURCES WITH COMBINATORIAL AUCTIONS
where Ga is the set of machine groups that can support application a, Mg is the set
of power modes available to machines in group g, ùõæg,t(‚ãÖ) is the number of cycles
provided by a machine from group g in mode t over a period of time given by its
argument, ùúèis the amount of time in the current period, ùõøg,f,t is the amount of time it
takes to transition from mode f to mode t, and each Csold
g,f,t,a variable defines a quantity
of cores (i.e., goods) allocated from group g that were in mode f and are now in
mode t (described in more detail in the following text). With these definitions, the
expression then captures the total cycles provided to application a, accounting for
reductions due to time spent in transitioning power level and considering all machine
groups and power levels.
19.2.2
Defining The Goods in the Market
Within each machine group, we track only the number of cores in each power state.
An allocation of some quantity of such cores is ultimately mapped into an assign-
ment of cores on physical machines in postprocessing. This avoids the creation of
immaterial distinctions that would only complicate winner determination and is sim-
ilar to complexity-reduction methods that have been used to good effect in recent
high profile government bandwidth auctions [18, 19]. We currently use a fast but
potentially only approximate greedy assignment for this postprocessing, but more
sophisticated methods could be used if the identities of machines in a group are
important.
To properly encode the data-center cost model, described in the next section, we
need a representation of goods that captures not just static power states but power
state transitions, enabling us to account for resultant changes in energy usage, cycle
loss, and increases in failure rate. Consequently, our goods are manifest in Csold
g,f,t,a
variables that capture the number of cores in a given machine group starting in mode
f in the previous period, transitioning to (the possibly identical) mode t in the current
period and assigned to a given application a.
Constraints are defined to ensure that an allocation of these goods will be phys-
ically implementable; for example, on present day platforms it is required that all
cores on the same physical machine be at the same power level:
|coresg|
‚àë
f‚ààMg
Msold
g,f,t =
‚àë
f‚ààMg
‚àë
a‚ààA
Csold
g,f,t,a + CpartUnsold
g,t
,
(19.4)
|coresg|
‚àë
f‚ààMg
Munsold
g,f,t
=
‚àë
f‚ààMg
Cunsold
g,f,t
‚àíCpartUnsold
g,t
,
(19.5)
‚àÄt ‚ààMg ‚àÄg ‚ààG,
where |coresg| is the number of cores per machine in group g, Cunsold
g,f,t
are variables
counting the unassigned cores, Msold
g,f,t and Munsold
g,f,t
count sold and unsold machines,
respectively, and CpartUnsold
g,t
count the unsold cores on partially sold machines.

A MARKET MODEL OF DATA CENTER ALLOCATION
487
Additionally, we need to restrain available supply, through the machine counts:
|machinesg| =
‚àë
f‚ààMg
‚àë
t‚ààMg
Msold
g,f,t + Munsold
g,f,t
‚àÄg ‚ààG,
(19.6)
where |machinesg| is the number of machines in group g.
19.2.3
Seller Cost Model
On the supply side of the market, we explicitly model both the hardware and energy
costs of running the data center‚Äôs machines in their various power states. Our model
captures the power consumed and performance attained by each machine as a func-
tion of the number of active and inactive cores, as measured empirically on an IBM
BladeCenter HS21 Server (Figs. 19.5 and 19.6). Modern dynamic voltage and fre-
quency scaling (DVFS) enabled machines can have their most efficient state at less
than full power: for example, a maximum of 64 versus 50 MCycles/W with four cores
active (taking the ratio of the curves in each figure).
30
140
145
150
155
0
2500
5000
7500
10,000
0
0
1
2
3
4
Active cores
250
200
150
100
50
0
Power (W)
14000
12000
10000
8000
6000
4000
2000
MCycles per second
Figure 19.5
Power and speed under low power.
30
165
190
215
240
0
3000
6000
9000
12,000
0
0
0
1
2
3
4
Active cores
250
200
150
100
50
Power (W)
14000
12000
10000
8000
6000
4000
2000
MCycles per second
Figure 19.6
Power and speed under high power.

488
ALLOCATING DATA CENTER RESOURCES WITH COMBINATORIAL AUCTIONS
We define the energy requirements (i.e., power over the time period) of the active
machines and cores as follows:4
Esold =
‚àë
g‚ààG
‚àë
f‚ààMg
‚àë
t‚ààMg
Emult(Etrans
g,f,t
+ Ebase,active
g,ùúè,t
)Msold
g,f,t
+
‚àë
g‚ààG
‚àë
f‚ààMg
‚àë
t‚ààMg
‚àë
a‚ààA
EmultEcore,active
g,ùúè,t
Csold
g,f,t,a,
(19.7)
where Etrans
g,f,t
is the energy required to go from power state f to t, Ebase,active
g,ùúè,t
is the
base power for an active machine, and Ecore,active
g,ùúè,t
is the incremental energy needed
to run a fully loaded core in this power state. Both of there are parameterized by ùúè
so as to only include energy for that period of time when the machine has reached its
destination power level, excluding that used in the transition period (energy for the
transition is accounted for by Etrans
g,f,t
and on some hardware may occur at full power
regardless of the proximal power levels). Here Emult accounts for the typically two- to
threefold increase in energy needed to run power supply units, uninterruptible power
supplies, network switches and storage, and, most importantly, cooling equipment.
All elements of this expression are ultimately constants, except for the Msold
g,f,t and
Csold
g,g,f,ta variables.
We stipulate the hardware costs for active cores across the full data center as fol-
lows:
Hsold =
‚àë
g‚ààG
‚àë
f‚ààMg
‚àë
t‚ààMg
(Hbase
g,ùúè,g + Htransition
g,f,t
)Msold
g,f,t ,
(19.8)
where Hbase
g,ùúè,g is the prorated cost for each machine (again accounting for only that
period of time cycles are actually being provided, as opposed to power level transi-
tions) and includes not only the amortized server cost but also supporting equipment,
buildings, and personnel; and Htransition
g,f,t
accounts for the cost associated with an
increased failure rate on a state transition due to, for example, spinning up/down hard
drives. We expect each of these numbers to be easily obtainable through a principled
evaluation of existing business practices and capital investments.
Episodic formulations have a common problem in that they may not bear large
transition costs when they create a temporary loss in utility, despite a long-term gain.
Consequently, we also include sell-side tracking of the power state of machines over
previous periods (similarly to the buyer-demand prediction), which can be used to
predict the expected time that a machine transitioned to a new state will stay within it.
This can be used to amortize transition costs over a good estimate of their appropriate
time frame. This adjustment can be calculated exogenously to the rest of the system
and is used to adjust the Etrans
g,f,t
and Htransition
g,f,t
constants.
A system administrator might, in addition, wish to specify additional restrictions
on the allocation based on technical requirements that are not externally visible or
4Note this expression captures the entire seller side of the market, so its Esold is unparameterized.

EXPERIMENTAL RESULTS
489
those that are unstated by buyers but can reasonably be inferred as being part of
their intent. Considerable flexibility is possible; some examples include min/max
cores/machines for a given application, min/max energy used in a given machine
group or for a given application, and max cores in a given machine group that can
be allocated to a given application if a certain number is already allocated to specific
alternative application (anti-colocation).
19.3
EXPERIMENTAL RESULTS
We have evaluated our market-based system in a set of simulation experiments
to establish computational tractability and effective allocative behavior over a
wide range of environments. Each experiment has been performed on a 3.2 GHz
dual-processor dual-core workstation with 8 GB of memory and IBM ILOG CPLEX
11.1. Each data point is the mean of 10 randomly generated time-dependent demand
traces.
Our synthetic traces are the sum of two sinusoidal curves (e.g., 1-day period with
9000 peak transactions/min plus 1-week period with 36,000 peak transactions/min)
and a noise term drawn from a Gaussian with a standard deviation equal to 25%
of the signal. These match well with real customer traces, where request density is
time dependent and oscillates over both days and weeks [20]. Unlike captured data,
synthetic traces enable us to test not only robustness to wide variation in absolute load
level but also different amounts of correlation among applications. Each transaction
is assumed to use 300 MCycles, which is representative of the processing needed to
produce a custom database report. Lastly, each allocation period is 10 min, which is
fast enough to react to dynamic changes in the load, but without being so short as to
require hysteresis in the model beyond that implicit in the transition costs.
Because no allocator in the literature has comparable capabilities, we adopt as a
benchmark a sophisticated greedy allocator, which operates as follows:
1. Put all the machines in their highest efficiency state.
2. Determine the target supply for each application by calculating what is required
to produce its ideal response time at its 95th percentile of demand.
3. Allocate cores (from feasible machine groups) to the applications, weighted by
the marginal value of supply to each application. If an application‚Äôs supply of
high efficiency cores is exhausted, then bump one of the machines supporting
it into a higher power state. Stop when either all the targets have been met or
all the cores/states have been allocated.
4. Consider each application in turn and trim the allocation until the expected
value at the 95th percentile of demand is greater than or equal to the expected
cost.
5. Place remaining machines in their lowest power state.
For exposition purposes we consider a simple scenario with two applications
(i.e., two customers) and three machine groups (each capable of supporting the first,

490
ALLOCATING DATA CENTER RESOURCES WITH COMBINATORIAL AUCTIONS
0
0.2
0.4
0.6
0.8
Price per kilowatt-hour
Mean power bought and 95th-percentile response time by energy price
Mean power bought in (kwh)
Mean 95th-percentile response (s)
1
0
500
1000
1500
2000
 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Market power usage
Static power usage
Market response time
Static response time
Figure 19.7
Energy used and response time as the cost of energy is varied under market and
heuristic algorithms. Bars indicate one standard error over 10 random traces at each price point.
second, and both applications, respectively), for a simulated week of time-varying
demand. We also provide results where we vary the price of energy, to demonstrate
the flexibility that a market-based allocation scheme can bring to bear.
Figure 19.7 shows the effect of varying the price of energy under both the market
and the static-allocation algorithm. We can see that, as expected, under both algo-
rithms, the energy used falls and consequently the mean response time rises as the
price of energy is increased. However, bidding proxies in the market (representing
customers) find it profitable to purchase enough energy to maintain a near-optimal
response time until the price finally reaches such a point that such high energy usage
can no longer be sustained and more energy-frugal allocations are chosen.
In Figure 19.8, we see the impact of the choice of these allocations on buyer (i.e.,
customer) and seller value, as judged by SLAs and revenue net of cost, respectively.
The greedy allocation is cheaper to provide because of the static power levels and
also results in significantly lower buyer value over a wide range of prices. The max-
imum revenue net cost improvement is 137% higher in the market model, although
margins become slim when energy is expensive.
It is also important to consider distributive effects to customers in the data-center
setting. In this scenario, the A application induces a larger load than B, but with
a smaller marginal value for cycles. Consequently, as energy prices rise, the static
allocator quickly devotes the limited resources that can be afforded to the B alloca-
tion, thereby starving the A application, as seen in Figure 19.9. The market allocation
not only maintains the allocation for the B application but also recognizes that some
resources can profitably be given to A. This is made possible by switching machines

EXPERIMENTAL RESULTS
491
0
0.2
0.4
0.6
0.8
1
0
1000
2000
V
Value ($)
 
 
Market
Static
0
1000
2000
Price per kilowatt-hour
0
0.2
0.4
0.6
0.8
1
 
Price per kilowatt-hour
Cost ($)
 
 
Market
Static
Figure 19.8
Buyer value and seller revenue net cost as the cost of energy is varied under
market and heuristic algorithms. (a) Buyer value by energy price and (b) seller cost by energy
price.
0
0.2
0.4
0.6
Price per kilowatt-hour
0.8
1
0
10
20
30
40
50
60
Allocation by energy price
Mean cores used
 
Market A
Market B
Static A
Static B
Figure 19.9
Application allocation by energy cost under market and static algorithms.

492
ALLOCATING DATA CENTER RESOURCES WITH COMBINATORIAL AUCTIONS
0
0.2
0.4
0.6
0.8
Price per kilowatt-hour
1
0
10
20
30
40
50
60
70
80
Allocation by energy price
Mean cores used
 
 
Market high
Market low
Static high
Static low
Figure 19.10
Power mode allocation by energy cost under market and static algorithms.
between their most efficient modes to conserve energy and their high power modes
to track spikes in demand. Figure 19.10 shows that in this setting the static allocator
has placed all the machines in the high efficiency ‚Äúlow power‚Äù mode, whereas the
market has made use of both modes. When the price for power is low, the most effi-
cient allocation is to maintain quite a few machines in the high power state. However,
as the price crosses ¬¢40/kWh, there is a phase change and it becomes much more
efficient to run mostly in the low power mode. Beyond about ¬¢60/kWh, it becomes
impossible to afford the energy needed to maintain a supply sufficient to keep a low
response time and the optimal allocation shrinks.
19.3.1
Scalability and Complexity
To evaluate the scalability of our MIP formulation, we evaluated 10 instances of a sce-
nario with 200 quad-core machines in each of five groups for a total of 1000 machines.
We configured 10 applications, each with a demand for some 2700 transactions per
second, to draw upon these resources with each group supporting three of the appli-
cations in a ring topology. We restricted the optimizer to no more than 10 min of
computation per instance, taking advantage of the anytime nature of modern MIP
solvers. Four of the instances were capped to 10 min, and the average solve time
was 5.16 min over all 10 instances, well within the time of a single period. Further,
the approximation resulted in only a 0.08% revenue loss when compared to the opti-
mal solution, which would have taken an additional 29 min on an average for these
difficult cases. Thus a single machine is capable of optimizing the usage on 1000
others, providing an acceptable 0.1% overhead factor. For a data center with many

GOING BEYOND PROCESSING AND POWER
493
more machines, one could decompose them into multiple machine pools, each of a
size around 1000.
We have also investigated the effect on runtime of the structure of the bipartite
graph that defines which application can be supplied by each machine group. For
this, we use a scenario with five applications and five machine groups, where sup-
ply is set so as to be just sufficient to meet demand. The average solve time of the
winner-determination problem increases nonlinearly as we vary the number of edges
in the bipartite graph. A graph with 30% of the edges (already highly connected for
current data centers) takes only 3.8% of the time needed to clear the market with a
complete graph. With 50% connectivity, the computation time has risen to 58.8%, and
with 60% connectivity, the timing has already risen to 86.6%. Interestingly, eliminat-
ing even a relatively substantial number of edges does not produce a correspondingly
large increase in the application response time, as the system can still find an allo-
cation that supports the demand. With 60% of the edges, we are only 8% above
the response time of the complete graph. Consequently, moderately restricting the
number of machine groups on which an application can run (e.g., for administrative
reasons) will only modestly decrease solution quality.
We have shown that a market mechanism can allocate resources under realistic
load conditions and more efficiently than the static allocators consistent with current
practice. Further, we have shown that such a market can be cleared using a mod-
est amount of computing power within an allocation window that is short enough to
capture the essential dynamics of typical loads. So far we have described and evalu-
ated methods for participants to describe their value to the market (the ‚Äúbidding lan-
guage‚Äù problem) and a method for clearing the market (the ‚Äúwinner-determination‚Äù
problem). In the rest of the chapter, we first discuss an important class of gener-
alizations to our model and then turn to the essential task of devising prices for
the market that have the necessary computational, economic, and game theoretic
properties.
19.4
GOING BEYOND PROCESSING AND POWER
So far we have considered only two properties of the data center in our resource
allocation: CPU cycles and the energy needed to produce them. In general, such a
system can handle any single aspect of the computational resources: CPU, mem-
ory, disk space, or bandwidth. In many cases, loads are bound by only a single such
attribute, and the system described will be effective; it need not be CPU as we have
illustrated but could be another attribute with suitable changes to the response-time
model. However, more generally, there will be situations where application perfor-
mance is heavily dependent on multiple attributes or where the data center is being
used by a heterogeneous mixture of applications each with its own attribute perfor-
mance profile.
To model the cost structure for more attributes is straightforward. We introduce
additional variables that track how much of each attribute from a given machine
group has been allocated to an application a. As these attributes can be reasonably

494
ALLOCATING DATA CENTER RESOURCES WITH COMBINATORIAL AUCTIONS
modeled as having linear costs, these variables can be included in the objective with
cost constants that vary by machine group (e.g., some groups have expensive memory
or high speed bandwidth; others do not).
In the formulation, we have described up until now, the aggregate goods trans-
ferred from one side of the market to the other are total CPU cycles, and these are
then assumed by the buyer proxy to be evenly divided across its application‚Äôs load.
There is a simplifying assumption here, in that we have modeled all cycles as fungible
(see Reference 17 for a relaxation of this assumption). If we maintain this assump-
tion in our multiple attribute model, we have a variable for the total amount of each
attribute assigned to each application. Consequently, the buyer proxy must submit a
more complex buyer value function:
Va = Fa(Qcpu
a , Qmemory
a
, ...),
(19.9)
where each of the QX
a variables is the aggregate amount of attribute X given to appli-
cation a. As before, we decompose F into a response-time model and a value model
over the resulting time:
Va = VResponse/Time
a
(Ra(Qcpu
a , Qmemory
a
, ...)).
(19.10)
Thus, moving to multiple attributes does not change the piecewise linear SLA
value curve VResponse Time
a
, as may, for example, be seen in Figure 19.2, that the buyer
enters into the system. We still assume value to be a direct function of response time.
However, we previously assumed the response time, Ra(‚ãÖ), was a one-dimensional
function of CPU cycles, and now it must be a multidimensional function of multiple
attributes. The most straightforward model for this is multiplicative, where the pre-
vious queuing model over CPU is multiplicatively altered by a factor for each of the
attributes. Adopting a softmax function, to encode a threshold of quantity needed for
good performance, is a reasonable approach for modeling the factors.
The bidder proxy would then compose this response-time model with the
user-specified value model, yielding a nonlinear multivariate value function. This
is sampled to produce a multivariate piecewise linear value function, which is
submitted into the market as the buyer‚Äôs bid.
So there is a straightforward way to extend both the buyer and seller side of the
market. The catch comes from the complexity of clearing this market. Methods
for encoding a single-dimensional, piecewise linear function into a MIP are very
effective if there are a modest number of inflection points. Such methods extend to
multiple dimensions but scale in an exponential manner. So working with a small
number of attributes can be coupled with exact (or almost exact) MIP solutions.
But this approach will be too slow for more than a few attributes, and it will make
more sense to skip the linearization step and approximately solve the resulting
nonlinear programming problem directly. Such an approach will not guarantee the
fully efficient solution, but in the data-center context, local optima may well be
sufficient.

PRICING
495
19.5
PRICING
We have shown how buyers can specify value over complex combinations of
resources and how sellers can specify their costs for providing these resources. And
we have shown that a MIP formulation can be used to clear the resulting market and
produce an allocation. But what payment should be asked of the buyer in return for
these resources?
The simplest solution would be to have fixed prices associated with each resource
type and simply charge the users for the amount of resources they actually use. This is
the same pricing model as that used in Amazon EC2 (note that here decisions about
quantity and quality of machines to buy is optimized by the system; on EC2, such
a decision is left to the user who typically does not have the information needed to
make an optimal choice). Fixed prices have the advantage of being simple for buyers
to understand; they are often a fixed markup over the seller cost, making them easy
for sellers to compute. However, they are not adaptive and thus do not take advantage
of the information revelation that occurs in the market. Sellers may set the markup
too high and thereby miss out on profitable business when buyers are unwilling to
meet the price. Alternatively, they may price too low, forgoing revenue they might
otherwise enjoy by leaving much of the surplus from trade with the buyers. However,
it is important to emphasize that even when using fixed exogenous prices, a market
such as the one described here can still be useful as an internal allocation method that
attempts to establish the proper trade-off between performance and consumption.
Another alternative is to still use easily understood linear prices (e.g., a single
price per unit of each type of good, as opposed to more complex prices based on
bundles of goods), but to determine what these prices should be, using the bids sub-
mitted to the system. This has the advantage of adaptivity, by choosing prices based
on the information revealed by the buyers in the course of interacting with the system.
However, because the market is combinatorial in nature, we cannot actually find per-
fect market clearing prices without using nonlinear bundle prices (which we consider
shortly). One way around this is to find and use a set of linear prices that come as
close to clearing the market as possible using a linear programming approximation;
see Reference 21 for details.
However, such formulations are very complex. While participants will immedi-
ately understand the linear prices produced, the same cannot be said for the process
used to arrive at them. Consequently, we may instead choose to simply charge the
buyers their stated value: the so-called ‚Äúfirst-price auction.‚Äù This is both adaptive in
the above sense and simple‚Äîit is instantly recognizable to anyone who has seen a
single good ‚ÄúEnglish‚Äù auction for, for example, art, cars, or cattle. There is, how-
ever, a problem. As is common we will assume quasi-linearity in the sequel, that is, a
buyer‚Äôs utility is exactly his/her value minus the payment he/she is charged. Suppose
buyers act so as to maximize their expected utility and may, therefore, submit bids
to the system inconsistent with their true value, if they believe they will get either a
better set of resources or a lower payment. The first price rule provides a large such
incentive for buyers to benefit from these manipulations [22].

496
ALLOCATING DATA CENTER RESOURCES WITH COMBINATORIAL AUCTIONS
The classic solution to this problem is to instead use the Vickrey‚ÄîClarke‚ÄîGroves
(VCG) mechanism [23]. This mechanism clears at the efficient trade and charges each
buyer its marginal impact on the economy, that is, each agent i is charged the differ-
ence between the optimal trade without i and with i, as measured by the total reported
value of the agents other than i. This mechanism has many desirable properties. It is
individually rational, meaning that agents are never forced to incur a negative profit.
It is budget balanced, meaning that it will never run at a deficit. And, it is strate-
gyproof, meaning that agents will have a dominant strategy to truthfully report their
bids to the system, solving the problem identified in the first-price auction.
The VCG payment rule has justifiably received an enormous amount of attention in
the literature. However, it too has drawbacks, many of which are listed in an oft-cited
paper by Rothkopf [24]. Chief among these is that it can produce unacceptably low
revenue. Consider an example from Ausubel et al. [25], with two items for sale, A
and B. Bidder 1 wants the AB bundle for $1. Bidder 2 wants just A for $1, and Bidder
3 wants B for just $1. VCG gives the goods to Bidders 2 and 3, but charges $0, the
marginal impact of each of these players. For these reasons, adopting VCG may not
be appropriate in the data center setting, despite its many desirable properties.
Another consequence of the low revenue of VCG is that it can often be profitable
for sets of participants to come together and manipulate their bids so as to subvert the
system. Informally, VCG is not ‚Äúcollusionproof‚Äù‚Äîit is not strategyproof for coali-
tions of agents working together. Payment rules that have this property are said to
choose payments in the ‚ÄúCore,‚Äù and such rules are now available for combinatorial
markets of the type proposed here [26]. However, such prices are typically not strat-
egyproof (i.e., the VCG payments, which are the only ones that are strategyproof in
sufficiently complex settings, are not in the core). Because of this, it is now com-
mon to choose those payments in the buyer-optimal core that are closest to the VCG
payments, in an attempt to mitigate the strategic incentives that must inevitably arise
[27]; see also Reference 28 for related ideas in the context of two-sided combinatorial
markets [28]. Such pricing represents an attempt to balance the need for both reason-
able revenue and reasonable incentive properties and as such have recently been used
in the United Kingdom to clear combinatorial bandwidth auctions [18, 19, 29].
While appealing in theory and offering increasing practicality, core payments still
retain one major disadvantage. They are exceedingly complex and hard for buyers to
understand. This is less of a problem when they can be imposed by governments on
large players purchasing exceedingly valuable resources, as in bandwidth auctions.
But it is less clear that they can be adopted in more modest settings.
One such setting is the sale of sponsored-search advertising on sites such as
Google. Most systems in this space have adopted a simple yet effective payment
rule known as the generalized second price (GSP) auction [30]. In these settings,
the goods being sold can be easily sorted into a value order that is known to be
consistent with all the bids‚Äîspecifically, ads placed at the top of the page are more
valuable to every bidder than those placed further down. The basic rule is then very
simple: the market is cleared efficiently at the bids, and players are charged not
their bid, but the bid of the player they displaced into the next lower spot. That is,
they are charged the price required for them to win their slot holding the other bids

CONCLUSIONS
497
constant‚Äîor equivalently, a separate second-price auction is effectively applied at
each slot in turn from highest value to low, among only those bidders who have
not already been satisfied. The GSP mechanism is easily understood, reasonably
efficient in practice, results in relatively small amounts of strategic behavior (even
though it is not strategyproof), and generates reasonable amounts of revenue for the
seller. In short, for settings that meet its requirements, it is an extremely effective
mechanism.
A payment rule similar in spirit to the GSP rule can easily be constructed for our
setting. First, the efficient allocation at the reported bid is determined, as we have
described. We then consider each agent-allocation pair in turn, ordered from highest
reported value to lowest. For each such pair, we find the highest value for the buyer‚Äôs
allocation among all buyers further down the list and charge this for the payment. In
other words, we charge each buyer the price needed to win the bundle away from the
next-most eager bidder. While not strategyproof, or core, there is reason to believe
such a rule should work well in practice, and it is certainly simple.
Any of the above payment rules could potentially be adopted for use with our
mechanism. As we have discussed, each comes with its own pros and cons. Consid-
ering them in balance, we can easily see a role for several of the choices. Clearly
fixed prices will continue to be important; we argue that they can indeed be coupled
with more complex bidding and allocation systems. We believe core-based rules will
continue to garner significant academic interest and, provided that implementations
can hide their complexity, may well see practical application in these settings. But we
see the fastest immediate impact in GSP-like rules that are simple and should have
reasonable properties in practice.
19.6
CONCLUSIONS
We have established that suitably designed combinatorial markets can find practical
application to power-managed resource allocation in data centers. Further, it is pos-
sible to inject revenue-based utility functions directly into the present data-center
business/allocation model without the large changes associated with utility comput-
ing; this creates the streamlined migration path required for rapid industry adoption.
Such markets obviate the need for operators to divine their customers‚Äô value profile,
quantify the trade-offs of multiobjective optimization, and facilitate the use of com-
binatorial optimization in a scalable way, provided carefully designed models are
used.
There are many intriguing avenues for future work in this space. First, the results
presented here are in simulation; a real-world implementation and trial is thus a clear
direction to take. One initial step in this direction might be to evaluate the market
approach on a model of a Google compute cluster based on the real-world demand
traces they have recently released [31]. More generally, one possibility is to consider
richer SLA models, such as models that capture the importance of the timing of fail-
ures. For most applications, it is better to suffer an occasional transaction failure over
a long period of time than to become completely unresponsive for even a short time

498
ALLOCATING DATA CENTER RESOURCES WITH COMBINATORIAL AUCTIONS
period‚Äîyet the standard percentile-based SLA model does not distinguish between
these cases. The present system is straightforwardly scalable by simply deploying
multiple copies of the market. However, this approach makes each market an island.
Consequently, very large installations may need a way to transfer loads across these
islands, and a higher level market is a reasonable way to perform such coordination.
Thus it makes sense to consider a hierarchical allocation paradigm, where a market
clears at each level, a compelling generalization of the present approach.
ACKNOWLEDGMENTS
Our profound thanks to Jeff Kephart and Rajarshi Das, our coauthors on much of
the work described herein. Any errors are our own. An earlier version of this work
appeared in IJCAI-09 [32]. We would also like to thank IBM Research where much
of this work took place.
REFERENCES
1. US EPA. Report to Congress on Server and Data Center Energy Efficiency, Aug. 2007.
2. US DOE and EPA. Carbon Dioxide Emissions from the Generation of Electric Power in
the United States, Jul. 2000.
3. US EIA. Emissions of Greenhouse Gases Report: Carbon Diaoxide Emissions, Dec. 2008.
4. J. Koomey. Growth in Data Center Electricity Use 2005 to 2010. Analytics Press, Oakland,
CA. Aug. 1 2010, 2011.
5. J. Glanz. Power, polution and the internet. New York Times, Sept. 22 2012.
6. I. E. Sutherland. ‚ÄúA futures market in computer time,‚Äù Communications of the ACM, 11(6),
1968, 449‚Äì451.
7. T. Sandholm. ‚ÄúExpressive commerce and its application to sourcing: how we conducted
$35 billion of generalized combinatorial auctions,‚Äù AI Magazine, 28(3), 2007, 45.
8. J. S. Chase, D. C. Anderson, P. N. Thakar, A. M. Vahdat, and R. P. Doyle. Managing energy
and server resources in hosting centers. In Proceedings of the 18th ACM Symposium on
Operating Systems Principles (SOSP-01), pp. 103‚Äì116. ACM, New York, NY, 2001.
9. Y. Chen, A. Das, W. Qin, A. Sivasubramaniam, Q. Wang, and N. Gautam. Managing server
energy and operational costs in hosting centers. In Proceedings ACM SIGMETRICS Int.
Conf. on Measurement and Modeling of Computer Systems (05), pp. 303‚Äì314. ACM, New
York, NY, 2005.
10. C. Low and A. Byde. Market-based approaches to utility computing. Technical Report 23,
HP Laboratories, Bristol, Feb. 2006.
11. A. Byde. A comparison between mechanisms for sequential compute resource auctions.
In Proceedings of the 5th International Joint Conference on Autonomous Agents and Mul-
tiagent Systems (AAMAS-06), 8(12), 1199‚Äì1201, 2006.
12. C. S. Yeo and R. Buyya. ‚ÄúA taxonomy of market-based resource management systems
for utility-driven cluster computing,‚Äù Software, Practice & Experience, 36(13), 2006,
1381‚Äì1419.

REFERENCES
499
13. J. Broberg, S. Venugopal, and R. Buyya. ‚ÄúMarket-oriented grids and utility comput-
ing: the state-of-the-art and future directions,‚Äù Journal of Grid Computing, 6(3), 2007,
255‚Äì276.
14. P. Cramton, Y. Shoham, and R. Steinberg, editors, Combinatorial Auctions. MIT Press,
Cambridge, MA, Jan. 2006.
15. J. O. Kephart and R. Das. ‚ÄúAchieving self-management via utility functions,‚Äù IEEE Inter-
net Computing, 11(1), 2007, 40‚Äì48.
16. M. Steinder, I. Whalley, J. E. Hanson, and J. O. Kephart. Coordinated management of
power usage and runtime performance. In Proceedings of the 9th International Symposium
on Integrated Network Management (NOMS-08), pp. 387‚Äì394, 2008.
17. M. Guevara, B. Lubin, and B. C. Lee. Navigating heterogeneous processors with market
mechanisms. In Proceedings of the 19th International Symposium on High Performance
Computer Architecture (HPCA-13), 2013. Forthcoming.
18. P. Cramton. A review of the l-band auction. Technical report, Office of Communications,
United Kingdom, Aug. 2008.
19. P. Cramton. A review of the 10-40ghz auction. Technical report, Office of Communica-
tions, United Kingdom, Sept. 2008.
20. G. Pacifici, W. Segmuller, M. Spreitzer, and A. Tantawi. ‚ÄúCPU demand for web serving:
measurement analysis and dynamic estimation,‚Äù Performance Evaluation, 65(6), 2008,
531‚Äì553.
21. B. Lubin, D. Parkes, J. Shneidman, S. Lahaie, R. Cavallo, and A. Juda. ‚ÄúIce: an expressive
iterative combinatorial exchange,‚Äù Journal of Artificial Intelligence Research, 33, 2008,
33‚Äì77.
22. B. Lubin and D. C. Parkes. Quantifying the strategyproofness of mechanisms via metrics
on payoff distributions. In Proceedings of the 25th Conference on Uncertainty in Artificial
Intelligence (UAI-09), 2009.
23. V. Krishna. Auction Theory. Academic Press, University Park, PA, 2002.
24. M. H. Rothkopf. ‚ÄúThirteen reasons why the vickrey-clarke-groves process is not practical,‚Äù
Operations Research, 55(2), 2007, 191‚Äì197.
25. L. M. Ausubel and Paul Milgrom. ‚ÄúAscending auctions with package bidding,‚Äù Frontiers
of Theoretical Economics, 1(1), 2002, 1‚Äì42.
26. R. Day and P. Milgrom. Core-selecting package auctions. International Journal of game
Theory, 36(3), 2008, 393‚Äì407.
27. R. W. Day and P. Cramton. The Quadratic Core-Selecting Payment Rule for Combinatorial
Auctions. Working Paper, Sept. 2008.
28. D. C. Parkes, J. R. Kalagnanam, and M. Eso. Achieving budget-balance with vickrey-based
payment schemes in exchanges. In Proceedings of the 17th International Joint Conference
on Artificial Intelligence, pp. 4‚Äì10, 2001.
29. P. Cramton, E. Kwerel, G. Rosston, and A. Skrzypacz. ‚ÄúUsing spectrum auctions to
enhance competition in wireless services,‚Äù Journal of Law and Economics, 54(4), 2011,
S167‚ÄìS188.
30. B. Edelman, M. Ostrovsky, and M. Schwarz. ‚ÄúInternet advertising and the generalized
second price auction: selling billions of dollars worth of keywords,‚Äù American Economic
Review, 97(1), 2007, 242‚Äì259.
31. C. Reiss, J. Wilkes, and J. L. Hellerstein. Google cluster-usage traces: format +
schema. Technical report, Google Inc., Mountain View, CA, USA, Nov. 2011. Revised

500
ALLOCATING DATA CENTER RESOURCES WITH COMBINATORIAL AUCTIONS
2012.03.20.
Posted
at
URL
http://code.google.com/p/googleclusterdata/wiki/Trace
Version2.
32. B. Lubin, J. Kephart, R. Das, and D. C. Parkes. Expressive power-based resource allocation
for data centers. In Proceedings of the 21st International Joint Conference on Artificial
Intelligence (IJCAI-09), 2009.

INDEX
any time data (ATD) class
CSC see control and scheduling component
(CSC)
data transfer, 369
logical channels, 369‚Äì70
performance evaluation
channel delay vs. congestion, 385‚Äì6, 386
data session vs. delay, 384‚Äì5, 385
network utilization, 383‚Äì4, 384
user performance, 386, 386‚Äì7
segregation mechanism, 371
application user interface
app-delay sensitivity settings, 154, 154
bandwidth consumption, 153, 153
budget adjustment, 154, 154
functionality goals, 152
indicator bar, 152
parental control, 153‚Äì4, 154
price information, 152‚Äì3, 153
usage history, 153, 153
usage notifications, 153, 153
approximate-coverage model, 301‚Äì2
asynchronous content delivery and pricing
mobile data traffic
operator profits, 391
variations and peak-time congestion, 392
yield management, 392‚Äì3
time-shifting traffic see time-shifting traffic
user survey
adoption, 396, 397
delay elasticity, 395‚Äì6
delay tolerance, 394‚Äì5, 395
price sensitivity, 396
pricing interface, 397, 397
QoE, 394
setup and goals, 393‚Äì4
atom library, 116
backbone network
aggregate-peak-device, 174
Smart Data Pricing, First Edition. Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang.
¬© 2014 John Wiley & Sons, Inc. Published 2014 by John Wiley & Sons, Inc.
customer liability see customer liability
device-level F-discrepancy see device-level
F-discrepancy
network-level F-discrepancy, 175, 179, 179‚Äì80,
180
95th percentile-customer, 173
peak-customer, 174
TCO discrepancy, 183‚Äì5, 184, 185
traffic metering method see traffic metering
method
traffic pattern, 174‚Äì5, 175
volume-customer, 173
Bertrand model, 294‚Äì5
bilateral oligopoly model, 293, 293
Broadband Internet Service BenchMARK
(BISMark) router, 140
broadband service provider (BSP), 36
buyer valuation model
application value, 484, 484
bidding proxy, 483‚Äì4
expected short-term value, 485, 485
machine groups, 485‚Äì6
short-term bid, 483
SLAs, 482‚Äì3, 483
transaction processing, 483‚Äì4
caching factors see congestion points
capital expense (CAPEX) see customer cost
CDN see content delivery network (CDN); content
distribution network (CDN)
cellular networks, 441‚Äì2, 448‚Äì9
Cisco‚Äôs Visual Networking Index (VNI), 441
client monitoring component (CMC), 375‚Äì6
cloud resource allocation
Amazon EC2, 455‚Äì6, 456
cloud computing, 455
cost-optimization approach, 456
deadline-dependent pricing, 457
demand and supply, 456
queuing-based models, 456
501

502
INDEX
cloud resource allocation (Continued)
SLA-based pricing, 461‚Äì6
time-dependent pricing see time-dependent
pricing (TDP)
VM-based pricing see VM-based pricing
color coding, 149
combinatorial market mechanism
business value, 481
buyer valuation model see buyer valuation
model
efficiency, 480
goods allocation, 481, 481, 486
machine groups, 480
seller cost model, 487‚Äì9
SLA, 481
stochastic optimization problem, 482
winner-determination problem, 482, 486
complete price (CP) differentiation
concave utility function see concave utility
function
PP differentiation see partial price (PP)
differentiation problem
revenue gain
effective market, users, 223‚Äì4, 224
parameter k, 224‚Äì5, 225, 225
parameter t, 222‚Äì3, 223
total resource, 221‚Äì2
service provider pricing
admission control, 201‚Äì3
effective market threshold, 202‚Äì4, 203
limited total resource, 200‚Äì201
nonconvex optimization problem, 201
properties, 204
resource allocation problem, 201‚Äì3
single pricing problem
effective market, 207‚Äì8
group index threshold, 205‚Äì6
parameters, 206‚Äì7, 207
price differentiation gain, 208
water-filling condition, 205
surplus maximization problem, 200
compound annual growth rate (CAGR), 391
concave utility function
compound group, clusters
four-group effective market, 236‚Äì8
three-group effective market, 234‚Äì6
inequality condition, 238
inverse function, 230‚Äì231
optimal revenue, 232‚Äì3
resource constraint, 228‚Äì30
Stackelberg model, 228
water-filling problem, 231‚Äì2
congestion alleviation
ad hoc networks, 450
caching content, 449
CDNs, 444‚Äì5
cellular networks, 441‚Äì2
content storage, 449
Internet, 444
IP network, 444
multicast transmission, 445‚Äì6, 447
on-demand content, 449‚Äì50
unicast delivery, 445, 446
video applications, 442‚Äì4
video delivery see video delivery
congestion points
caching remote content, 51, 56
critical price rule, 56
demand-response model, 57
intuitive property, 55
Nash equilibrium, 53‚Äì5
one point, 61, 61‚Äì2
proportion rule, 55
three points, 57, 58‚Äì60, 63‚Äì4
transit prices, 56
Connect America Fund (CAF), 37
content delivery network (CDN), 417, 444‚Äì5
approximate-coverage model, 301‚Äì2
bilateral oligopoly model, 293, 293
charging model, 292
dynamic analysis
applications, 299‚Äì300
customer demand, 296
multiple-player analysis, 298‚Äì9
one-player analysis, 297‚Äì8
features, 290
market structure
content producer, 309, 309
dynamic voluntary game see dynamic
voluntary game
equilibrium state, 308‚Äì9
federation, 309‚Äì11, 310
vs. multiple-choice market, 293‚Äì4
n-CDN pricing game, 307‚Äì8, 308
precise-coverage model, 300‚Äì301, 301
predictive analysis, 295, 295‚Äì6
request based model, 292
static analysis, 294‚Äì5
supply chain, 292‚Äì3
two-CDN pricing game
nonpredictive strategy, 303‚Äì5, 304
predictive strategy, 305‚Äì7
price selection, 302‚Äì3
volume-based model, 291‚Äì2
content distribution network (CDN), 48, 49
content providers (CPs), 47‚Äì8
control and scheduling component (CSC)
admin component, 381

INDEX
503
applications interface, 381
architecture, 375, 375
client-side monitoring, 382‚Äì3, 383
CMC, 375‚Äì6
DTDT protocol, 375, 379
monitoring and data collection, 380‚Äì381
preloading content, 381‚Äì2
scheduling problem
access point, 376‚Äì7
max-flow problem, 377‚Äì8
offline solution, 378
serial scheduling, 378‚Äì9, 379
SMC, 375‚Äì6
cost minimization
economical responsiveness, 87‚Äì8
infinite-horizon, 88
inflexible users, 88, 89
nonconvexity of optimization, 88‚Äì9
proactive downloads, 86, 86
user flexibility, 87, 88
Cournot model, 294‚Äì5
cross-price elasticity, 41, 44
customer cost
backbone network see backbone network
cost-sharing policy, 172‚Äì3, 173
points of presence, 171‚Äì2
quality of service, 171
routers and links, 171
SLA, 171
toy infrastructure, 170, 170‚Äì171
customer liability
aggregate-peak-device, 186
device-level L-discrepancy, 188‚Äì9, 189, 189
network-level L-discrepancy, 189‚Äì90, 190
peak-based cost sharing, 185, 185
QoS constraints, 185
Shapley policy, 186, 186‚Äì8, 188
splitting cost, 185
trigger policy, 186
customer price sensitivity
bill-and-keep system, 36
BSP, 36
CAF, 37
data, 39
econometric estimates, 41, 42‚Äì3
end users conditions, 36
income elasticity, 41, 44
Internet speed tiers, 38
long-distance
carriers, 35
service, 35
model, 38‚Äì9
own- and cross-price elasticity, 41, 44
price elasticity of demand, 37
variable descriptions
percentage of population, 41
service tiers, 39‚Äì40
statistics, 40
voice service, 35
data center resource allocation
application allocation, 490, 491
attributes, 493‚Äì4
buyer and seller value, 490, 491
buyer value function, 494
computational grids, 480
CPU, 493
greedy allocator, 489
hardware ownership, 479
high performance computing, 480
information gathering, 479
market model see combinatorial market
mechanism
MIP, 478
power consumption, 477‚Äì8
price of energy, 490, 490
pricing, 495‚Äì7
realistic model of resources, 478
response time model, 494
scalability and complexity, 492‚Äì3
SLA, 479
static allocator, 492, 492
utility computing, 480
data consumption, 416‚Äì17
day-ahead dynamic TDP (DDTDP)
adaptive pricing, 144
application user interface see application user
interface
data plans and usage, 155
economic incentives, 155
field trial objectives, 148
granular price offerings, 143‚Äì4
implementation and setup, 151, 151‚Äì2
participants, billing, and timeline, 149‚Äì51, 150,
150
pretrial focus groups, 148‚Äì9
price guarantees, 143
smart devices opinion, 155
usage statistics, 156, 157
user choice empowerment, 161‚Äì2
user feedback mechanism, 144
user interface, 158‚Äì61
day-ahead electricity market
consumers, 75‚Äì6, 76
demand-side management, 73
electricity consumers flexibilities, 73
intermediaries, 73, 73
ISO, 74‚Äì6

504
INDEX
day-ahead electricity market (Continued)
Nash equilibrium, 74
optimization and game theoretic techniques, 74
slotted time structure models, 74
smart grid, 72
suppliers, 75
degree of flexibility, 442
delay-elastic traffic, 392‚Äì3
delay-inelastic traffic, 392‚Äì3
device-level F-discrepancy, 174‚Äì5
vs. aggregate-peak-device policy, 176, 178, 178
customer and traffic percentage, 176‚Äì7, 177
monthly cost, 176, 176
time series, 178, 178‚Äì9
device-level L-discrepancy, 188‚Äì9, 189, 189
disruption-tolerant data transfer (DTDT) protocol,
375, 379
Dixit‚ÄìStiglitz utility function, 348‚Äì9
dual pricing algorithms
channel gain matrix, 119
myopic and greedy approaches, 97
pareto optimal utility, 97
power and interference temperature, 119‚Äì21,
119‚Äì21
wireless network duality
channel fading matrix, 108
game theory, 117‚Äì18
interference load minimization, 112‚Äì13
interference temperature, 109‚Äì10
max‚Äìmin weighted SINR problem, 103
nonsmooth special case, 106‚Äì8
Perron right eigenvectors, 105, 109‚Äì11
primary and dual network, 104, 104‚Äì5
smooth and nonsmooth utility functions,
105‚Äì6
software implementation, 116‚Äì17
spectral radius functions, 109, 122
uplink‚Äìdownlink duality, 103‚Äì4, 104
utility maximization algorithm, 113‚Äì16
wireless cellular and ad-hoc networks, 103
wireless network utility maximization
interference temperature constraint, 101
optimal value and solution, 101‚Äì2
Perron‚ÄìFrobenius eigenvalue, 102
power constraint, 101, 121, 121
QoS measurement, 99
SINR assignment, 98‚Äì100
utility function, 102‚Äì3
dumb pipes
nonuniform ordering
consumer surplus, 261‚Äì2, 262
higher profit, 255, 257‚Äì8
quasi-bundling, 258‚Äì61, 261
social surplus, 262‚Äì4, 263
uniform ordering
benefits, 251‚Äì2, 252
consumer surplus, 249‚Äì51, 251
discrimination problem, 247
incentive compatibility, 246‚Äì7
individual rationality, 246‚Äì7
net implication, 251
policy implication, 253‚Äì5
social surplus, 252‚Äì4, 254
type-1 consumer, 244‚Äì5, 245
type-2 consumer, 245‚Äì6
dynamic programming (DP) solutions, 428
dynamic revenue maximization with variable price
(DRMVP), 459
dynamic voltage and frequency scaling (DVFS),
487
dynamic voluntary game
average number, 314, 314
investment strategy, 313‚Äì14, 314
market shocks, 315‚Äì17, 316, 317
market state, 312‚Äì13
Markov perfect equilibrium theory, 311‚Äì12
perfect cartel game, 314, 314‚Äì15
value equation, 313
economics-based pricing
CP differentiation see complete price (CP)
differentiation
flat-fee pricing, 196‚Äì8
incomplete price differentiation see
incentive-compatible complete price
(ICCP) differentiation
logarithmic utility function, 198‚Äì9
price differentiation taxonomy
customer segmentation, 221
perfect price differentiation, 220
quantity-based charging, 221
revenue gain, 221‚Äì3, 223
two-stage Stackelberg model, 199‚Äì200
end users (EUs)
contract design, uncertain demand, 272‚Äì3
network neutrality, 271‚Äì2
NUM, 271
sponsored content, 270‚Äì271
billing cycle, 275
congestion cost, 281
content provider problem, 276‚Äì7
implementation issues, 275‚Äì6
insensitive transition probability, 284
Markov model, 275
per-byte end-user cost, 274‚Äì5
Poisson distribution, 282‚Äì3
sensitive transition probability, 285, 285‚Äì7
service provider problem, 277‚Äì9

INDEX
505
Stackelberg game, 273
standard deviation, 281, 283
system profit function, 280‚Äì282, 282
transition rates, 283‚Äì4
two-parameter contract, Pareto analysis,
279‚Äì80
eyeball-ISP provider, 49‚Äì51
fine-grained pricing, 4
first-price auction, 495
fixed prices, 495
flow model
equilibrium problem, congestion cost, 334
factors, 335‚Äì6
graph network, 333‚Äì4
policy decision, 334‚Äì5
generalized second price (GSP) auction, 496‚Äì7
gross domestic product (GDP), 14‚Äì15
human‚Äìcomputer interaction (HCI)
bandwidth pricing
dynamic forms, TDP, 142‚Äì3
speed-tier pricing, 141
variable pricing, 140‚Äì141
DataWiz screenshots, 129, 130
DDTDP
adaptive pricing, 144
application user interface see application user
interface
data plans and usage, 155
economic incentives, 155
field trial objectives, 148
granular price offerings, 143‚Äì4
implementation and setup, 151, 151‚Äì2
participants, billing, and timeline, 149‚Äì51,
150, 150
pretrial focus groups, 148‚Äì9
price guarantees, 143
smart devices opinion, 155
usage statistics, 156, 157
user choice empowerment, 161‚Äì2
user feedback mechanism, 144
user interface, 158‚Äì61
designing systems, 128‚Äì32
different evaluation methods, 135, 135
energy market, 135‚Äì6
expert evaluations, 132
field trial
experimental design, 133‚Äì4
qualitative and quantitative analysis,
134
questionnaires, 134‚Äì5
recruit participants, 133
variables and hypotheses, 133
higher QoS, 129
home networks
data caps, 139‚Äì40
network management and QoS control,
136‚Äì8
throttling implications, 138‚Äì9
information communication, 128
interface design, 130, 131
Internet ecosystem stakeholders
application developer, 147
consumer viewpoints, 145‚Äì6
content providers, 146‚Äì7
operator perspectives, 144‚Äì5
policy evolution, 147
screen navigation, 129
hybrid network
network roles and incentives, 322, 322
P2P network see peer-to-peer (P2P) network
model
SBSD protocol
algorithms, 331
flooding-based routing, 328
network provider, 329‚Äì30
network security, 332
query packets, 328
utility function, 328‚Äì9
incentive-compatible complete price (ICCP)
differentiation
maximum revenue, 219‚Äì20
partial price differentiation, 220
self-differentiation, 217‚Äì18, 218
self-selection problem, 218‚Äì19, 219
income elasticity, 41, 44
Independent System Operator (ISO), 74‚Äì5
Internet Demand Experiment (INDEX) project,
140‚Äì141
Internet service providers (ISPs), 47‚Äì9, 49
congestion points see congestion points
eyeball-ISP provider, 49, 51‚Äì2
Internet speed tiers, 38
IP network, 444
knapsack problems
finite-horizon Markov decision process,
429‚Äì30
offline multiple-choice, 427‚Äì8
online stochastic process, 428‚Äì9, 429
local measured service (LMS), 21
local search approximation algorithm, 458, 458

506
INDEX
mean response time (MRT), 462
mixed-integer programming (MIP), 478
mobile network operators (MNOs), 391‚Äì2
modular architecture design
bitrate selection, 421
user profiler, 421, 422
video compression, 422‚Äì3
multiple knapsack problem (MKP), 457‚Äì8
multiple-choice knapsack problem (MCKP),
427‚Äì8, 434
n-CDN pricing game, 307‚Äì8, 308
network neutrality
applications, 49‚Äì50
CDN, 48, 49
content providers (CPs), 47‚Äì8, 49
differentiable demand model, 51
interior Nash equilibria, 51
ISPs see Internet service providers (ISPs)
product offers, 48
QoS management, 48
usage-priced access-bandwidth reservation, 50
network utility maximization (NUM), 271
network-level L-discrepancy, 189‚Äì90, 190
nonlinear Perron‚ÄìFrobenius theory, 105
nonuniform ordering
pricing problem, solution, 255‚Äì6, 256
smart pipes vs. dumb pipes
consumer surplus, 261‚Äì2, 262
higher profit, 255, 257‚Äì8
quasi-bundling, 258‚Äì61, 261
social surplus, 262‚Äì4, 263
NP-hard combinatorial optimization problem, 458
operational expense (OPEX) see customer cost
optimal content viewing
aggregate quality, 349‚Äì50
Dixit‚ÄìStiglitz utility function, 348‚Äì9
infinitesimal effect, 347‚Äì8
marginal quality, 348
utility function, 347
optimal policy, 428‚Äì9
own-price elasticity, 41, 44
Paris metro pricing (PMP), 370‚Äì371
partial price (PP) differentiation problem
maximum revenue, 209
three-level decomposition
cluster partition, 211, 211‚Äì12, 212
effective market size, 215‚Äì17
effective market threshold, 214‚Äì15
pricing and resource allocation, 210,
210‚Äì211
super group, 212‚Äì14
trade-off, 226, 226‚Äì7, 226‚Äì7
peak-to-average ratio (PAR), 156, 157
peer-to-peer (P2P) network model
advantages, 323‚Äì4
cellular network capacity, 327
congestion pricing, 326‚Äì7
flow model
equilibrium problem, congestion cost, 334
factors, 335‚Äì6
graph network, 333‚Äì4
policy decision, 334‚Äì5
mobile nodes, 324‚Äì5
multi-hop wireless networks, 325
network congestion, 332‚Äì3
packet routing, 332
participation density, 326‚Äì7
Pigouvian tax model, 332
prioritization model
divisible incentives, 337
indivisible incentives, 338
transportation domain, 336
quality of service
algorithms, 331
distributed accounting, 331‚Äì2
network security, 332
organization, 330‚Äì331
routing performance, 327‚Äì8
static nodes, 324
voluntary participation model, 325‚Äì6
wired networks, 324
wireless networks, 324
Perron right eigenvectors, 105, 109‚Äì11
Pigouvian tax model, 332
PLUTUS system
ATD class see any time data (ATD) class
cell networks, 366
data pricing, 367‚Äì8
PMP, 370‚Äì371
RAN, 367
SD class see surplus data (SD) class
precise-coverage model, 300‚Äì301, 301
predictable traffic conditions
aggregate load, 409‚Äì10, 410
flow deferrals and discount, 409, 409
total delivery time, 410, 410‚Äì411
price estimation
demand curve, 458‚Äì9, 459
DRMVP, 459
optimization problem, 459‚Äì60
revenue estimation, 460
revenue gain, 461
pricing under demand flexibility
closed-loop system, 72

INDEX
507
day-ahead electricity market
consumers, 75‚Äì6, 76
demand-side management, 73
electricity consumers flexibilities, 73
intermediaries, 73, 73
ISO, 74‚Äì6
Nash equilibrium, 74
optimization and game theoretic techniques,
74
slotted time structure models, 74
smart grid, 72
suppliers, 75
demand-side characteristics, 71
demand-side dynamics, 69
demand-side flexibilities, 71
hourly and daily fluctuations, 69, 70
numerical experiments, 79‚Äì80, 81
optimal bundle pricing under discreteness, 78‚Äì9
optimal time-dependent pricing under
convexity, 77‚Äì8
predictability of consumer activities, 71
and responsiveness, 71
pricing under predictable demand
cost minimization
economical responsiveness, 87‚Äì8
infinite-horizon cost minimization, 88
inflexible users, 88, 89
nonconvexity of optimization, 88‚Äì9
proactive downloads, 86, 86
user flexibility, 87, 88
demand shaping and proactive download
activity patterns, 83
demand profiles, 84‚Äì5
economical responsiveness, 83‚Äì4, 84
interests and preferences, 83
machine learning and statistical modeling tools,
80
peak demand, 82
pricing policies, modified profiles
economical responsiveness, 90
joint proactive download and demand
shaping, 91, 91‚Äì2
mapping functions, 89
price allocation step, 89, 89
proactive data download without demand
shaping, 90
quadratic cost function, 90
proactive data service, 82, 82
proportional cost, 82
prioritization model
divisible incentives, 337
indivisible incentives, 338
transportation domain, 336
proactive service, 71
quality of experience (QoE), 391‚Äì2
quality of service (QoS), 48, 171, 185
quota aware video adaptation (QAVA)
availability of video, 420
client-based architectures, 424
content provider-/ISP-based architectures,
423‚Äì4
ecosystem, players incentives, 419‚Äì20
error prediction, 437, 437‚Äì8
experimental setup, 433
heterogeneous data, 421
modular architecture design see modular
architecture design
performance variability, 436, 436‚Äì7
stream selection see stream selection
three functional modules, 424, 425
time scale, 420‚Äì421
trade off quality vs. cost vs. volume, 418‚Äì19
user profiler see user profiler
video cost and utility, 432‚Äì3
radio access network (RAN), 367
scalable video coding (SVC), 417
self-balancing supply/demand (SBSD) protocol
algorithms, 331
flooding-based routing, 328
network provider, 329‚Äì30
network security, 332
query packets, 328
utility function, 328‚Äì9
server monitoring component (SCC), 375‚Äì6
service-level agreement (SLA), 171
Shapley policy, 186, 186‚Äì8, 188
signal-to-interference-and-noise-ratio (SINR), 98
single pricing (SP) problem
effective market, 207‚Äì8
group index threshold, 205‚Äì6
parameters, 206‚Äì7, 207
price differentiation gain, 208
water-filling condition, 205
SLA-based pricing
Amazon EC2, 461
average response time, 463
heuristic method, 466, 466
IRT, 463, 463
Lagrange composite function, 465‚Äì6
mean revenue, 463
M/M/1 queuing model, 464
MRT, 462, 463
offset factor, 462
optimization problem, 463‚Äì4
Poisson distribution, 462
QoS, 461

508
INDEX
SLA-based pricing (Continued)
queuing theory, 461
service intensity, 462
sojourn time probability distribution, 465
smart pipes
nonuniform ordering
consumer surplus, 261‚Äì2, 262
higher profit, 255, 257‚Äì8
quasi-bundling, 258‚Äì61, 261
social surplus, 262‚Äì4, 263
uniform ordering
benefits, 251‚Äì2, 252
consumer surplus, 249‚Äì51, 251
net implication, 251
nonlinear pricing, 247‚Äì8, 248
policy implication, 253‚Äì5
social surplus, 252‚Äì4, 254
sponsored content, 270‚Äì271
billing cycle, 275
congestion cost, 281
content provider problem, 276‚Äì7
implementation issues, 275‚Äì6
insensitive transition probability, 284
Markov model, 275
per-byte end-user cost, 274‚Äì5
Poisson distribution, 282‚Äì3
sensitive transition probability, 285, 285‚Äì7
service provider problem, 277‚Äì9
Stackelberg game, 273
standard deviation, 281, 283
system profit function, 280‚Äì282, 282
transition rates, 283‚Äì4
two-parameter contract, Pareto analysis,
279‚Äì80
stage game, 295, 295‚Äì6
stream selection
algorithms, 434
average performance, 434‚Äì6, 436
knapsack problems see knapsack problems
single user, 434, 435
video request, utility, and cost model, 425‚Äì7
surplus data (SD) class
CSC see control and scheduling component
(CSC)
data transfer, 368‚Äì9
efficiency enhancement, 374
logical channels, 369‚Äì70
maximization problem, 373‚Äì4
peak load, 371‚Äì2
performance evaluation
channel delay vs. congestion, 385‚Äì6, 386
data session vs. delay, 384‚Äì5, 385
network utilization, 383‚Äì4, 384
user performance, 386, 386‚Äì7
premium and nonpremium user, 372‚Äì4
segregation mechanism, 371
sender-pays plans/two-sided pricing, 374‚Äì5
surplus capacity plan, 372
user experience, 369
TCO see total cost of ownership (TCO)
TDP see time-dependent pricing (TDP)
telecom industry, smart pricing
block-pricing plan, 3
Bridger Mitchell, flat rates
AOL, 23
economics community, 24
electronic switching, 22
local measured service, 21
local voice calls rates, 20
logic of bundling, 23
Nixon wage-price freeze, 21
peak-load pricing, 23
usage-sensitive pricing, 21‚Äì2
value of connectivity, 22
capital intensity, 16‚Äì18
caution reasons, 3
challenges, 5‚Äì6
congestion charges, 3
data flat rates, 24
demand growth, 26‚Äì7
fiber networks, 19
fine-grained pricing, 4‚Äì5
high profits, 13‚Äì14, 18‚Äì19
and innovation, 12
low capital investments, 18
mental transaction costs, 6
modern financial puzzles, 19
net neutrality, 5
price per megabyte, 4‚Äì5
research and development (R&D)
cost, 19‚Äì20
directions, 25‚Äì6
revenues, 12‚Äì13, 13
technology trends, 27‚Äì8
telco (r)evolutions
cost structure, 16
GDP, 14‚Äì15
government-sanctioned price discrimination
policy, 16
Tier-1 carriers, 15
telecom mistakes, 10
content, 7‚Äì8
video streaming, 9
transmission capacity, 6
usage-based pricing, 5
Verizon Wireless, 4
voice to text substitution, 11, 11

INDEX
509
wireless communication, 6
wireless voice quality, 10‚Äì11
wireline communication, 6
telecommunication services
monopoly setting, 242
nonuniform ordering see nonuniform ordering
text messages, 241‚Äì2
uniform ordering see uniform ordering
time-dependent pricing (TDP), 142‚Äì3
deadline-dependent pricing, 466‚Äì7
differentiable function, 470‚Äì471
divisible and indivisible jobs, 468
electricity cost, 467‚Äì8
net profit maximization, job scheduling, 467
NPO problem, 469‚Äì70
NPOD problem, 471‚Äì3, 472‚Äì3
service rate constraint, 468
system model, 468, 469
time-shifting traffic, 393
Delivery-shift, 398‚Äì9, 399
assumptions and definitions, 403
Async flows, 403‚Äì5, 405
Async system, 399‚Äì401, 400
congestion pricing, 402
EDT, 402‚Äì3
input traffic pattern, 411, 411
per-flow options, 404
performance measures, 406
predictable traffic conditions, 408‚Äì11
salient features, 411, 412
simulation setup, 406‚Äì8
PCEF, 405
PCRF, 404‚Äì5
Request-shift, 398, 399
achievable throughput, 400‚Äì401, 401
disadvantages, 400
performance measures, 406
predictable traffic conditions, 408‚Äì11
salient features, 411, 412
simulation setup, 406‚Äì8
TUBE system, 399, 405
usage-based and tiered pricing schemes, 398
total cost of ownership (TCO), 183‚Äì5, 184, 185
traffic metering method
customer-ingress, 180‚Äì181, 181
customer-per-device, 180
M-discrepancy, 181‚Äì3, 182
two-CDN pricing game
nonpredictive strategy, 303‚Äì5, 304
predictive strategy, 305‚Äì7
price selection, 302‚Äì3
uniform ordering
constant marginal cost, 244, 244
dumb pipes
benefits, 251‚Äì2, 252
consumer surplus, 249‚Äì51, 251
discrimination problem, 247
incentive compatibility, 246‚Äì7
individual rationality, 246‚Äì7
net implication, 251
policy implication, 253‚Äì5
social surplus, 252‚Äì4, 254
type-1 consumer, 244‚Äì5, 245
type-2 consumer, 245‚Äì6
reservation price, 243
smart-pipes
benefits, 251‚Äì2, 252
consumer surplus, 249‚Äì51, 251
net implication, 251
nonlinear pricing, 247‚Äì8, 248
policy implication, 253‚Äì5
social surplus, 252‚Äì4, 254
uplink‚Äìdownlink duality, 103‚Äì4, 104
usage-based pricing, 415, 416
usage-sensitive pricing (USP), 21
user interface
key features, 158
participant usage, 159, 161, 161
period types, 158, 158‚Äì9, 160
user profiler (UP)
user device (client), 421, 422
video computing, probability, 431‚Äì2
viewing pattern, 431
user psychology
bandwidth pricing
dynamic forms, TDP, 142‚Äì3
speed-tier pricing, 141
variable pricing, 140‚Äì141
home networks
data caps, 139‚Äì40
network management and QoS control
Eden system, 137
Home Watcher project, 136‚Äì7
Homework project, 137‚Äì8
resource sharing, 136
throttling implications, 138‚Äì9
user-generated content platforms
content producers, 345‚Äì6
benefits, 345
payoff function, 345
pieces, 345‚Äì6
subsidizing/taxing producers, 342‚Äì3
content quality, 341
content viewers, 346
heterogeneous production costs, 356‚Äì60
intermediary, 342, 344
profit maximization

510
INDEX
user-generated content platforms (Continued)
definition of equilibrium, 346‚Äì7
equilibrium content production, 350‚Äì352
optimal content viewing see optimal content
viewing
optimal payment rate, 352‚Äì6, 355
overjustification effects, 356
two-sided market, 343
Verizon Wireless, 4
Vickrey‚ÄìClarke‚ÄìGroves (VCG) mechanism,
496
video adaptation, 417
video consumption, 416
video decoder, 442
video delivery
bandwidth sharing, 448
cable operators, 448
cable TV systems, 447
cellular networks, 448‚Äì9
telephone operators, 448
video streaming protocols, 417‚Äì18
video traffic, 415, 424
VM-based pricing
dynamic scheduling, 457‚Äì8
price estimation see price estimation
willingness to pay (WTP), 141
wireless network
duality
channel fading matrix, 108
game theory, 117‚Äì18
interference load minimization, 112‚Äì13
interference temperature, 109‚Äì10
max‚Äìmin weighted SINR problem, 103
nonsmooth special case, 106‚Äì8
Perron right eigenvectors, 105, 109‚Äì11
primary and dual network, 104, 104‚Äì5
smooth and nonsmooth utility functions,
105‚Äì6
software implementation, 116‚Äì17
spectral radius functions, 109, 122
uplink‚Äìdownlink duality, 103‚Äì4, 104
utility maximization algorithm, 113‚Äì16
wireless cellular and ad-hoc networks, 103
utility maximization
interference temperature constraint, 101
optimal value and solution, 101‚Äì2
Perron‚ÄìFrobenius eigenvalue, 102
power constraint, 101, 121, 121
QoS measurement, 99
SINR assignment, 98‚Äì100
utility function, 102‚Äì3

WILEY SERIES ON INFORMATION 
AND COMMUNICATION TECHNOLOGY
Series Editors: T. Russell Hsing and Vincent K. N. Lau
The Information and Communication Technology (ICT) book series focuses on creat-
ing useful connections between advanced communication theories, practical designs,
and end-user applications in various next generation networks and broadband access
systems, including fiber, cable, satellite, and wireless. The ICT book series examines the
difficulties of applying various advanced communication technologies to practical sys-
tems such as WiFi, WiMax, B3G, etc., and considers how technologies are designed in
conjunction with standards, theories, and applications. 
The ICT book series also addresses application-oriented topics such as service man-
agement and creation and end-user devices, as well as the coupling between end devices
and infrastructure. 
T. Russell Hsing, PhD, is the Executive Director of Emerging Technologies and Services
Research at Telcordia Technologies. He manages and leads the applied research and
development of information and wireless sensor networking solutions for numerous ap-
plications and systems. Email: thsing@telcordia.com 
Vincent K.N. Lau, PhD, is Associate Professor in the Department of Electrical Engi-
neering at the Hong Kong University of Science and Technology. His current research
interest is on delay-sensitive cross-layer optimization with imperfect system state infor-
mation. Email: eeknlau@ee.ust.hk
Wireless Internet and Mobile Computing: Interoperability and Performance
Yu-Kwong Ricky Kwok and Vincent K. N. Lau
Digital Signal Processing Techniques and Applications in Radar Image Processing
Bu-Chin Wang 
The Fabric of Mobile Services: Software Paradigms and Business Demands
Shoshana Loeb, Benjamin Falchuk, and Euthimios Panagos
Fundamentals of Wireless Communications Engineering Technologies
K. Daniel Wong
RF Circuit Design, Second Edition
Richard Chi-Hsi Li 
Networks and Services: Carrier Ethernet, PBT, MPLS-TP, and VPLS
Mehmet Toy
Equitable Resource Allocation: Models, Algorithms, and Applications
Hanan Luss
Vehicle Safety Communications: Protocols, Security, and Privacy
Luca Delgrossi and Tao Zhang

WiFi, WiMAX, and LTE Multi-hop Mesh Networks: Basic Communication Protocols
and Application Areas
Hung-Yu Wei, Jarogniew Rykowski, and Sudhir Dixit
Smart Data Pricing
Edited by Soumya Sen, Carlee Joe-Wong, Sangtae Ha, and Mung Chiang

WILEY END USER LICENSE AGREEMENT
Go to www.wiley.com/go/eula to access Wiley‚Äôs ebook EULA.

