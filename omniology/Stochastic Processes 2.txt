Leif Mejlbro
Stochastic Processes 2
Probability Examples c-9
Download free books at

2 
Leif Mejlbro
Probability Examples c-9
Stochastic Processes 2
Download free eBooks at bookboon.com

3 
Probability Examples c-9 – Stochastic Processes 2
© 2009 Leif Mejlbro & Ventus Publishing ApS
ISBN 978-87-7681-525-7
Download free eBooks at bookboon.com

Stochastic Processes 2
 
4 
Contents
 
Introduction  
5
1  
Theoretical background  
6
1.1  
The Poisson process  
6
1.2  
Birth and death processes  
8
1.3  
Queueing theory in general  
11
1.4  
Queueing system of innitely many shop assistants  
11
1.5  
Queueing system of a nite number of shop assistants, and with forming of queues  
12
1.6  
Queueing systems with a nite number of shop assistants and without queues 
15
1.7  
Some general types of stochastic processes  
17
2  
The Poisson process  
19
3  
Birth and death processes  
37
4  
Queueing theory  
52
5  
Other types of stochastic processes  
117
 
Index  
126
Contents
Download free eBooks at bookboon.com
Click on the ad to read more
www.sylvania.com
We do not reinvent  
the wheel we reinvent 
light.
Fascinating lighting offers an infinite spectrum of 
possibilities: Innovative technologies and new  
markets provide both opportunities and challenges. 
An environment in which your expertise is in high 
demand. Enjoy the supportive working atmosphere 
within our global group and benefit from international 
career paths. Implement sustainable ideas in close 
cooperation with other specialists and contribute to 
influencing our future. Come and join us in reinventing 
light every day.
Light is OSRAM

Stochastic Processes 2
 
5 
Introduction
Introduction
This is the ninth book of examples from Probability Theory. The topic Stochastic Processes is so big
that I have chosen to split into two books. In the previous (eighth) book was treated examples of
Random Walk and Markov chains, where the latter is dealt with in a fairly large chapter. In this book
we give examples of Poisson processes, Birth and death processes, Queueing theory and other types
of stochastic processes.
The prerequisites for the topics can e.g. be found in the Ventus: Calculus 2 series and the Ventus:
Complex Function Theory series, and all the previous Ventus: Probability c1-c7.
Unfortunately errors cannot be avoided in a ﬁrst edition of a work of this type. However, the author
has tried to put them on a minimum, hoping that the reader will meet with sympathy the errors
which do occur in the text.
Leif Mejlbro
27th October 2009
Download free eBooks at bookboon.com

Stochastic Processes 2
 
6 
1. Theoretical background
1
Theoretical background
1.1
The Poisson process
Given a sequence of independent events, each of them indicating the time when they occur.
We
assume
1. The probability that an event occurs in a time interval I ⫅[0, +∞[ does only depend on the length
of the interval and not of where the interval is on the time axis.
2. The probability that there in a time interval of length t we have at least one event, is equal to
λt + t ε(t),
where λ > 0 is a given positive constant.
3. The probability that we have more than one event in a time interval of length t is t ε(t).
It follows that
4. The probability that there is no event in a time interval of length is given by
1 −λt + tε(t).
5. The probability that there is precisely one event in a time interval of length t is λt + t ε(t).
Here ε(t) denotes some unspeciﬁed function, which tends towards 0 for t →0.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
360°
thinking.
© Deloitte & Touche LLP and affiliated entities.
Discover the truth at www.deloitte.ca/careers 

Stochastic Processes 2
 
7 
1. Theoretical background
Given the assumptions on the previous page, we let X(t) denote the number of events in the interval
]0, t], and we put
Pk(t) := P{X(t) = k},
for k ∈N0.
Then X(t) is a Poisson distributed random variable of parameter λt. The process
{X(t) | t ∈[0, +∞[}
is called a Poisson process, and the parameter λ is called the intensity of the Poisson process.
Concerning the Poisson process we have the following results:
1) If t = 0, (i.e. X(0) = 0), then
Pk =
⎧
⎨
⎩
1,
for k = 0,
0,
for k ∈N.
2) If t > 0, then Pk(t) is a diﬀerentiable function, and
P ′
k(t) =
⎧
⎨
⎩
λ {Pk−1(t) −Pk(t)} ,
for k ∈N and t > 0,
−λ P0(t),
for k = 0 and t > 0.
When we solve these diﬀerential equations, we get
Pk(t) = (λt)k
k!
e−λt,
for k ∈N0,
proving that X(t) is Poisson distributed with parameter λt.
Remark 1.1 Even if Poisson processes are very common, they are mostly applied in the theory of
tele-traﬃc. ♦.
If X(t) is a Poisson process as described above, then X(s + t) −X(s) has the same distribution as
X(t), thus
P{X(s + t) −X(s)} = (λt)k
k!
e−λt, for k ∈N0.
If 0 ≤t1 < t2 ≤t3 < t4, then the two random variables X (t4) −X (t3) and X (t2) −X (t1) are
independent. We say that the Poisson process has independent and stationary growth.
The mean value function of a Poisson process is
m(t) = E{X(t)} = λt.
The auto-covariance (covariance function) is given by
C(s, t) = Cov(X(s) , X(t)) = λ min{s, t}.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
8 
1. Theoretical background
The auto-correlation is given by
R(s, t) = E{X(s) · X(t)} = λ min(s, t) + λ2st.
The event function of a Poisson process is a step function with values in N0, each step of the size
+1. We introduce the sequence of random variables T1, T2, . . . , which indicate the distance in time
between two succeeding events in the Poisson process. Thus
Yn = T1 + T2 + · · · + Tn
is the time until the n-th event of the Poisson process.
Notice that T1 is exponentially distributed of parameter λ, thus
P {T1 > t} = P{X(t) = 0} = e−λt,
for t > 0.
All random variables T1, T2, . . . , Tn are mutually independent and exponentially distributed of pa-
rameter λ, hence
Yn = T1 + T2 + · · · + Tn
is Gamma distributed, Yn ∈Γ

n , 1
λ

.
Connection with Erlang’s B-formula. Since Yn+1 > t, if and only if X(t) ≤n, we have
P{X(t) ≤n} = P {Yn+1 > t} ,
from which we derive that
n

k=1
(λt)k
k!
e−λt = λn+1
n!
 +∞
t
yn e−λy dy.
We have in particular for λ = 1,
n

k=0
tk
k! = et
n!
 +∞
t
yn e−y dy,
n ∈N0.
1.2
Birth and death processes
Let {X(t) | t ∈[0, +∞[} be a stochastic process, which can be in the states E0, E1, E2, . . . . The
process can only move from one state to a neighbouring state in the following sense: If the process is
in state Ek, and we receive a positive signal, then the process is transferred to Ek+1, and if instead
we receive a negative signal (and k ∈N), then the process is transferred to Ek−1.
We assume that there are non-negative constants λk and μk, such that for k ∈N,
1) P{one positive signal in ] t, t + h [| X(t) = k} = λk h + h ε(h).
2) P{one negative signal in ] t, t + h [| X(t) = k} = μk h + h ε(h).
Download free eBooks at bookboon.com

Stochastic Processes 2
 
9 
1. Theoretical background
3) P{no signal in ] t, t + h [| X(t) = k} = 1 −(λk + μk) h + h ε(h).
We call λk the birth intensity at state Ek, and μk is called the death intensity at state Ek, and the
process itself is called a birth and death process. If in particular all μk = 0, we just call it a birth
process, and analogously a death process, if all λk = 0.
A simple analysis shows for k ∈N and h > 0 that the event {X(t + h) = k} is realized in on of the
following ways:
• X(t) = k, and no signal in ] t, t + h [.
• X(t) = k −1, and one positive signal in ] t, t + h [.
• X(t) = k + 1, and one negative signal in ] t, t + h [.
• More signals in ] t, t + h [.
We put
Pk(t) = P{X(t) = k}.
By a rearrangement and taking the limit h →0 we easily derive the diﬀerential equations of the
process,
⎧
⎨
⎩
P ′
0(t) = −λ0 P0(t) + μ1 P1(t),
for k = 0,
P ′
k(t) = −(λk + μk) Pk(t) + λk−1 Pk−1(t) + μk+1 Pk+1(t),
for k ∈N.
In the special case of a pure birth process, where all μk = 0, this system is reduced to
⎧
⎨
⎩
P ′
0(t) = −λ0 P0(t),
for k = 0,
P ′
k(t) = −λk Pk(t) + λk−1 Pk−1(t),
for k ∈N.
If all λk > 0, we get the following iteration formula of the complete solution,
⎧
⎨
⎩
P0(t) = c0 e−λ0 t,
for k = 0,
Pk(t) = λk−1 e−λkt 	 t
0 eλkτ Pk−1(τ) dτ + ck e−λkt,
for k ∈N.
From P0(t) we derive P1(t), etc.. Finally, if we know the initial distribution, we are e.g. at time t = 0
in state Em, then we can ﬁnd the values of the arbitrary constants ck.
Let {X(t) | t ∈[0, +∞[} be a birth and death process, where all λk and μk are positive, with the
exception of μ0 = 0, and λN = 0, if there is a ﬁnal state EN. The process can be in any of the states,
therefore, in analogy with the Markov chains, such a birth and death process is called irreducible.
Processes like this often occur in queueing theory.
If there exists a state Ek, in which λk = μk, then Ek is an absorbing state, because it is not possible
to move away from Ek.
For the most common birth and death processes (including all irreducible processes) there exist non-
negative constants pk, such that
Pk(t) →pk
and
P ′
k(t) →0
for t →+∞.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
10 
1. Theoretical background
These constants fulﬁl the inﬁnite system of equations,
μk+1 pk+1 = λk pk,
for k ∈N0,
which sometimes can be used to ﬁnd the pk.
If there is a solution (pk), which satisﬁes
pk ≥0
for all k ∈N0,
and
+∞

k=0
pk = 1,
we say that the solution (pk) is a stationary distribution, and the pk are called the stationary proba-
bilities. In this case we have
Pk(t) →pk
for t →+∞.
If {X(t) | t ∈[0, +∞[} is an irreducible process, then
pk = λk−1λk−2 · · · λ1λ0
μkμk−1 · · · μ2μ1
· p0 := ak p0,
for k ∈N0,
where all ak > 0.
The condition of the existence of a stationary distribution is then reduced to that the series 
k ak is
convergent of ﬁnite sum a > 0. In this case we have p0 = 1
a.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
We will turn your CV into 
an opportunity of a lifetime
Do you like cars? Would you like to be a part of a successful brand?
We will appreciate and reward both your enthusiasm and talent.
Send us your CV. You will be surprised where it can take you.
Send us your CV on
www.employerforlife.com

Stochastic Processes 2
 
11 
1. Theoretical background
1.3
Queueing theory in general
Let {X(t) | t ∈[0, +∞[} be a birth and death process as described in the previous section.
We
shall consider them as services in a service organization, where “birth” corresponds to the arrival of a
new customer, and “death” correspond to the ending of the service of a customer. We introduce the
following:
1) By the arrival distribution (the arrival process) we shall understand the distribution of the arrivals
of the customers to the service (the shop). This distribution is often of Poisson type.
2) It the arrivals follow a Poisson process of intensity λ, then the random variable, which indicates
the time diﬀerence between two succeeding arrivals exponentially distributed of parameter λ. We
say that the arrivals follow an exponential distribution, and λ is called the arrival intensity.
3) The queueing system is described by the number of shop assistants or serving places, if there is
the possibility of forming queues or not, and the way a queue is handled. The serving places are
also called channels.
4) Concerning the service times we assume that if a service starts at time t, then the probability that
it is ended at some time in the interval ]t, t + h[ is equal to
μ h + h ε(h),
where μ > 0.
Then the service time is exponentially distributed of parameter μ.
If at time t we are dealing with k (mutually independent) services, then the probability that one
of these is ended in the interval ]t, t + h[ equal to
k μ h + h ε(h).
We shall in the following sections consider the three most common types of queueing systems. Concern-
ing other types, cf. e.g. Villy Bæk Iversen: Teletraﬃc Engineering and Network Planning Technical
University of Denmark.
1.4
Queueing system of inﬁnitely many shop assistants
The model is described in the following way: Customers arrive to the service according a Poisson
process of intensity λ, and they immediately go to a free shop assistant, where they are serviced
according to an exponential distribution of parameter μ.
The process is described by the following birth and death process,
{X(t) | t ∈[0, +∞[}
med λk = λ and μk = k μ
for alle k.
The process is irreducible, and the diﬀerential equations of the system are given by
⎧
⎨
⎩
P ′
0(t) = −λ P0(t) + μ P1(t),
for k = 0,
P ′
k(t) = −(λ + k μ)Pk(t) + λ Pk−1(t) + (k + 1)μ Pk+1(t),
for k ∈N.
The stationary probabilities exist and satisfy the equations
(k + 1)μ pk+1 = λ pk,
k ∈N0,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
12 
1. Theoretical background
of the solutions
pk = 1
k!
λ
μ
k
exp

−λ
μ

,
k ∈N0.
These are the probabilities that there are k customers in the system, when we have obtained equilib-
rium.
The system of diﬀerential equations above is usually diﬃcult to solve. One has, however, some partial
results, e.g. the expected number of customers at time t, i.e.
m(t) :=
+∞

k=1
k Pk(t),
satisﬁes the simpler diﬀerential equation
m′(t) + μ m(t) = λ.
If at time t = 0 there is no customer at the service, then
m(t) = λ
μ

1 −e−μt
,
for t ≥0.
1.5
Queueing system of a ﬁnite number of shop assistants, and with form-
ing of queues
We consider the case where
1) the customers arrive according to a Poisson process of intensity λ,
2) the service times are exponentially distributed of parameter μ,
3) there are N shop assistants,
4) it is possible to form queues.
Spelled out, we have N shop assistants and a customer, who arrives at state Ek. If k < N, then the
customer goes to a free shop assistant and is immediately serviced. If however k = N, thus all shop
assistants are busy, then he joins a queue and waits until there is a free shop assistant. We assume
here queueing culture.
With a slight change of the notation it follows that if there are N shop assistants and k customers
(and not k states as above), where k > N, then there is a common queue for all shop assistants
consisting of k −N customers.
This process is described by the following birth and death process {X(t) | t ∈[0, +∞[} of the
parameters
λk = λ
and
μk =
⎧
⎨
⎩
k μ,
for k < N,
N μ,
for k ≥N.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
13 
1. Theoretical background
The process is irreducible. The equations of the stationary probabilities are
⎧
⎨
⎩
(k + 1)μ pk+1 = λ pk,
for k < N,
N μ pk+1 = λ pk,
for k ≥N.
We introduce the traﬃc intensity by
ϱ :=
λ
N μ.
Then we get the stationary probabilities
pk =
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
λ
μ
k
· 1
k! p0 = ϱk·N k
k!
· p0,
for k < N,
λ
μ
k
·
1
N k−N · N! · p0 = ϱk · N N
N!
· p0,
for k ≥N.
Remark 1.2 Together with the traﬃc intensity one also introduce in teletraﬃc the oﬀer of traﬃc.
By this we mean the number of customers who at the average arrive to the system in a time interval of
length equal to the mean service time. In the situation above the oﬀer of traﬃc is λ
μ. Both the traﬃc
intensity and the oﬀer of traﬃc are dimensionless. They are both measured in the unit Erlang.♦
The condition that (pk) become stationare probabilities is that the traﬃc intensity ϱ < 1, where
+∞

k=N
N N
N! ϱk =
(ϱ N)N
(1 −ϱ) · N!.
If, however, ϱ ≥1, it is easily seen that the queue is increasing towards inﬁnity, and there does not
exist a stationary distribution.
We assume in the following that ϱ < 1, so the stationary probabilities exist
1) If N = 1, then
pk = ϱk(1 −ϱ),
for k ∈N0.
2) If N = 2, then
pk =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
1 −ϱ
1 + ϱ,
for k = 0,
2ϱk · 1 −ϱ
1 + ϱ,
for k ∈N.
3) If N > 2, the formulæ become somewhat complicated, so they are not given here.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
14 
1. Theoretical background
The average number of customers at the service is under the given assumptions,
⎧
⎪
⎨
⎪
⎩
ϱ
1 −ϱ,
for N = 1,

+∞
k=1 k pk,
generelt (naturligvis).
The average number of busy shop assistants is
⎧
⎨
⎩
ϱ,
for N = 1,

N−1
k=1 k pk + N 
+∞
k=N pk,
in general.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
AXA Global 
Graduate Program
Find out more and apply

Stochastic Processes 2
 
15 
1. Theoretical background
The waiting time of a customer is deﬁned as the time elapsed from his arrival to the service of him
starts. The staying time is the time from his arrival until he leaves the system after the service of
him. Hence we have the splitting
staying time = waiting time + service time.
The average waiting time is in general given by
V =
+∞

k=N
k −N + 1
N μ
pk,
which by a computation is
V =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
ϱ
μ(1 −ϱ),
for N = 1,
ϱN · N N−1
μ · N! · (1 −ϱ)2 · p0,
generelt.
In the special case of N = 1 the average staying time is given by
O =
ϱ
μ(1 −ϱ) + 1
μ =
1
μ −λ.
The average length of the queue (i.e. the mean number of customers in the queue) is
λV =
+∞

k=N+1
(k −N)pk = ϱN+1 · N N
N! · (1 −ϱ)2 · p0.
1.6
Queueing systems with a ﬁnite number of shop assistants and without
queues
We consider here the case where
1) the customers arrive according to a Poisson process of intensity λ,
2) the times of service are exponential distributed of parameter μ,
3) there are N shop assistants or channels,
4) it is not possible to form a queue.
The diﬀerence from the previous section is that if a customer arrives at a time when all shop assistants
are busy, then he immediately leaves the system. Therefore, this is also called a system of rejection.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
16 
1. Theoretical background
In this case the process is described by the following birth and death process {X(t) | t ∈[0, +∞[}
with a ﬁnite number of states E0, E1, . . . , EN, where the intensities are given by
λk =
⎧
⎨
⎩
λ,
for k < N,
0,
for k ≥N,
and
μk = k μ.
This process is also irreducible. The corresponding system of diﬀerential equations is
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
P ′
0(t) = −λ P0(t) + μ P1(t),
for k = 0,
P ′
k(t) = −(λ + k μ)Pk(t) + λ Pk−1(t) + (k + 1)μ Pk+1(t),
for 1 ≤k ≤N −1,
P ′
N(t) = −N μ PN(t) + λ PN−1(t),
for k = N.
In general, this system is too complicated for a reasonable solution, so instead we use the stationary
probabilities, which are here given by Erlang’s B-formula:
pk =
1
k!
λ
μ
k

N
j=0
1
j!
λ
μ
j ,
for k = 0, 1, 2, . . . , N.
The average number of customers who are served, is of course equal to the average number of busy
shop assistants, or channels. The common value is
N

k=1
k pk = λ
μ (1 −pN) .
We notice that pN can be interpreted as the probability of rejection. This probability pN is large,
when λ >> μ. We get from
N

j=0
1
j!
λ
μ
j
=
exp
λ
μ

N!
 +∞
λ/μ
yN e−y dy,
the probability of rejection
pN =
1
N!
λ
μ
N

N
j=0
1
j!
λ
μ
j =
λ
μ
N
exp

−λ
μ

	 +∞
λ/μ yN e−y dy
.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
17 
1. Theoretical background
1.7
Some general types of stochastic processes
Given two stochastic processes, {X(t) | t ∈T} and {Y (s) | s ∈T}, where we assume that all the
moments below exist. We deﬁne
1) the mean value function,
m(t) := E{X(t)},
for t ∈T,
2) the auto-correlation,
R(x, t) := E{X(s)X(t)},
for s, t ∈T,
3) the auto-covariance,
C(s, t) := Cov(X(s), X(t)),
for s, t ∈T,
4) the cross-correlation,
RXY (s, t) := E{X(s)Y (t)},
for s, t ∈T,
5) the cross-covariance,
CXY (s, t) := Cov(X(s), Y (t)),
for s, t ∈T.
A stochastic process {X(t) | t ∈R} is strictly stationary, if the translated process {X(t + h) | t ∈R}
for every h ∈R has the same distribution as {X(t) | t ∈R}.
In this case we have for all n ∈N, all x1, . . . , xn ∈R, and all t1, . . . , tn ∈R that
P {X (t1 + h) ≤x1 ∧· · · ∧X (tn + h) ≤xn}
does not depend on h ∈R.
Since P{X(t) ≤x} does not depend on t for such a process, we have
m(t) = m,
and the auto-covariance C(s, t) becomes a function in the real variable s −t. We therefore write in
this case,
C(s, t) := C(s −t).
Analogously, the auto-correlation is also a function only depending on s and t, so we write
R(s, t) := R(s −t).
Conversely, if m(t) = m and C(s, t) = C(s −t), then we call the stochastic process {X(t) | t ∈R}
weakly stationary.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
18 
1. Theoretical background
Let us consider a stochastic process {X(t) | t ∈R} of mean 0 and auto-correlation
R(τ) = E{X(t + τ)X(t)}.
If R(τ) is absolutely integrable, we deﬁne the eﬀect spektrum by
S(ω) =
 +∞
−∞
eiωτ R(τ) dτ,
i.e. as the Fourier transformed of R(τ).
Furthermore, if we also assume that S(ω) is absolutely
integrable, then we can apply the Fourier inversion formula to reconstruct R(τ) from the eﬀect
spectrum,
R(τ) = 1
2π
 +∞
−∞
e−iωτ S(ω) dω.
In particular,
E

|X(t)|2
= R(0) = 1
2π
 +∞
−∞
S(ω) dω.
A stochastic process {X(t) | t ∈T} is called a normal process, or a Gaußiann process, if for every
n ∈N and every t1, . . . , tn ∈T the distribution of {X (t1) , . . . , X (tn)} is an n-dimensional normal
distribution. A normal process is always completely speciﬁed by its mean value function m(t) and its
auto-covariance function C(s, t).
The most important normal process is the Wiener process, or the Brownian movements
{W(t) | t ≥0}.
This is characterized by
1) W(0) = 0,
2) m(t) = 0,
3) V {W(t)} = α t,
where α is a positive constant,
4) mutually independent increments.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
19 
2. The Poisson process
2
The Poisson process
Example 2.1 Let {X(t), t ∈[0, ∞[} be a Poisson process of intensity λ, and let the random variable
T denote the time when the ﬁrst event occurs.
Find the conditional distribution of T, given that at time t0 precisely one event has occurred, thus ﬁnd
P {T ≤t | X (t0) = 1} .
When t ∈[0, t0], then the conditional distribution is given by
P {T ≤t | X (t0) = 1}
=
P {X(t) = 1 ∧X (t0) = 1}
P {X (t0) = 1}
= P {X(t) = 1 ∧X (t0) −X(t) = 0}
P {X (t0) = 1}
=
P{X(t) = 1} · P {X (t0) −X(t) = 0}
P {X (t0) = 1}
= λ t e−λt · e−λ(t0−t)
λ t0e−λ t0
= t
t0
,
because
Pk(t) = P{X(t) = k} = (λ t)k
k!
e−λ t,
k ∈N,
and where we furthermore have applied that X (t0) −X(t) has the same distribution as X (t0 −t).
The conditional distribution is a rectangular distribution over ]0, t0[.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
ibili
because 
e Graduate Programme  
for Engineers and Geoscientists
Month 16
I was a construction
supervisor in 
the North Sea 
advising and 
helping foremen 
solve problems
I was a
he
s
Real work 
International opportunities 

ree work placements
al 
Internationa
or

ree wo
I wanted real responsibili 
 I joined MITAS because 
www.discovermitas.com

Stochastic Processes 2
 
20 
2. The Poisson process
Example 2.2 Let {X1(t), t ≥0} and {X2(t), t ≥0} denote two independent Poisson processes of
intensity λ1 and λ2, resp., and let the process {Y (t), t ≥0} be deﬁned by
Y (t) = X1(t) + X2(t).
Prove that {Y (t), t ≥0} is a Poisson process.
We ﬁrst identify
Pn(t) = P{X(t) = n} = (λ1t)n
n!
e−λ1t,
and
Qn(t) = P{X(t) = n} = (λ2t)n
n!
e−λ2t.
We get from X1(t) and X2(t) being independent that
P{Y (t) = n}
=
P {X1(t) + X2(t) = n}
=
n

j=0
P {X1(t) = j} · P {X2(t) = n −j} =
n

j=0
(λ1t)j
j!
e−λ1t · (λ2t)n−j
(n −j)! e−λ2t
=
n

j=0
n!
j!(n −j)! λj
1 · λn−j
2
· tn
n! e−(λ1+λ2)t =
n

j=0
 n
j

λj
1λn−j
2
· tn
n! e−(λ1+λ2)t
=
(λ1 + λ2)n · tn
n! · exp (−(λ1 + λ2) t) .
It follows that {Y (t), t ≥0} is also a Poisson process (of intensity λ1 + λ2).
Example 2.3 A Geiger counter only records every second particle, which arrives to the counter.
Assume that the particles arrive according to a Poisson process of intensity λ. Denote by N(t) the
number of particles recorded in ]0, t], where we assume that the ﬁrst recorded particle is the second to
arrive.
1. Find P{N(t) = n}, n ∈N0.
2. Find E{N(t)}.
Let T denote the time diﬀerence between two succeeding recorded arrivals.
3. Find the frequency of T.
4. Find the mean E{T}.
1. It follows from
Pn(t) = (λt)n
n!
e−λt,
n ∈N0,
that
P{N(t) = n}
=
P2n(t) + P2n+1(t) =
(λt)2n
(2n)! + (λt)2n+1
(2n + 1)!

e−λt
=
(λt)2n
(2n + 1)! (2n + 1 + λt)e−λt,
n ∈N0.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
21 
2. The Poisson process
2. The mean is
E{N(t)}
=
∞

n=0
n P{N(t) = n} = e−λt
 ∞

n=1
n(λt)2n
(2n)!
+
∞

n=1
n(λt)2n+1
(2n + 1)!

=
e−λt

λt
2
∞

n=0
(λt)2n+1
(2n + 1)! +
∞

n=1
(n + 1
2)(λt)2n+1
(2n + 1)!
−1
2
∞

n=1
(λt)2n+1
(2n + 1)!

=
e−λt
λt
2 · sinh λt + λt
2 (cosh λt −1) −1
2 (sinh λt −λt)

=
e−λt
λt
2 · eλt −1
4

eλt −e−λt
= λt
2 −1
4 + 1
4 e−2λt.
3. & 4. It follows from T = Tj + Tj+1 that T ∈Γ

2 , 1
λ

, thus the frequency is
f(x) =
⎧
⎨
⎩
λ2x e−λx
for x > 0,
0
for x ≤0,
and the mean is
E{T} = 2
λ.
Example 2.4 From a ferry port a ferry is sailing every quarter of an hour. Each ferry can carry N
cars. The cars are arriving to the ferry port according to a Poisson process of intensity λ (measured
in quarter−1).
Assuming that there is no car in the ferry port immediately after a ferry has sailed at 900, one shall
1) ﬁnd the probability that there is no car waiting at 915 (immediately after the departure of the next
ferry),
2) ﬁnd the probability that no car is waiting at 930 (immediately after the departure of the next ferry).
3) A motorist arrives at p07 1
2 . What is the probability that he will not catch the ferry at p15, but
instead the ferry at 930?
Measuring t in the unit quarter of an hour we have
P{X(t) = n} = (λt)n
n!
e−λt,
n ∈N0.
1) From t = 1 follows that the wanted probability is
P{X(1) ≤N} =
N

n=0
λn
n! e−λ.
2) We have two possibilities:
Download free eBooks at bookboon.com

Stochastic Processes 2
 
22 
2. The Poisson process
a) Either there has arrived during the ﬁrst quarter of an hour ≤N cars, which are all carried
over, so we allow during the next quarter N cars to arrive,
b) or during the ﬁrst quarter N + j cars have arrived, 1 ≤j ≤N, and at most N −j cars in the
second quarter.
We therefore get the probability
P{X(1) ≤N} · P{X(1) ≤N} +
N

j=1
P{X(1) = N + j} · P{X(1) ≤N −j}
=
 N

n=0
λn
n! e−λ
2
+
N

j=1
λN+j
(N + j)! e−λ ·
N−j

n=0
λn
n! e−λ = e−2λ
⎧
⎨
⎩
 N

n=0
λn
n!
2
+
N

j=1
N−j

n=0
λN+j+n
n!(N + j)!
⎫
⎬
⎭
= e−2λ
⎧
⎨
⎩
 N

n=0
λn
n!
2
+
N−1

n=0
N−n

j=1
λN+j+n
n!(N + j)!
⎫
⎬
⎭.
3) Now the time 907 1
2 corresponds to t = 1
2, so the probability is
N

j=0
P

X
1
2

= N + j

= exp

−λ
2
 2N

n=N
1
n!
λ
2
n
.
Example 2.5 Paradox of waiting time.
Each morning Mr. Smith in X-borough takes the bus to his place of work. The busses of X-borough
should according to the timetables run with an interval of 20 minutes. It is, however, well-known in
X-borough that the busses mostly arrive at random times to the bus stops (meaning mathematically
that the arrivals of the busses follow a Poisson process of intensity λ = 1
20 min−1, because the average
time diﬀerence between two succeeding busses is 20 minutes).
One day when Mr. Smith is waiting extraordinary long time for his bus, he starts reasoning about how
long time he at the average must wait for the bus, and he develops two ways of reasoning:
1) The time distance between two succeeding buses is exponentially distributed of mean 20 minutes,
and since the exponential distribution is “forgetful”, de average waiting time must be 20 minutes.
2) He arrives at a random time between two succeeding busses, so by the “symmetry” the average
waiting time is instead 1
2 · 20 minutes = 10 minutes.
At this time Mr. Smith’s bus arrives, and he forgets to think of this contradiction.
Can you decide which of the two arguments is correct and explain the mistake in the wrong argument?
The argument of (1) is correct. The mistake of (2) is that the length of the time interval, in which
Mr. Smith arrives, is not exponentially distributed. In fact, there will be a tendency of Mr. Smith to
arrive in one of the longer intervals.
This is more precisely described in the following way. Let t denote Mr. Smith’s arrival time. Then
Download free eBooks at bookboon.com

Stochastic Processes 2
 
23 
2. The Poisson process
1)
P{wait in more than x minutes} = P{N(t + x) −N(t) = 0} = P{N(x) = 0} = e−λx.
This shows that the waiting time is exponentially distribution of the mean 1
λ = 20 minutes.
2) Let X1, X2, . . . , denote the lengths of the succeeding intervals between the arrivals of the busses.
By the assumptions, the Xk are mutually independent and exponentially distributed of parameter
λ.
Put
Sn =
n

k=1
Xk.
The surprise is that the Xk, for which
Sk =
k

j=1
Xk < t <
k+1

j+1
Xj = Sk+1,
have the frequency
(1) ft(x) =
⎧
⎨
⎩
λ2x e−λx,
0 < x ≤t,
λ(1 + λt)e−λx,
t < x.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
MASTER IN MANAGEMENT
mim.admissions@ie.edu
Follow us on IE MIM Experience
www.ie.edu/master-management
#10 WORLDWIDE
MASTER IN MANAGEMENT 
FINANCIAL TIMES
55 Nationalities
in class
5 Specializations
Personalize your program 
Length: 1O MONTHS
Av. Experience: 1 YEAR
Language: ENGLISH / SPANISH
Format: FULL-TIME
Intakes: SEPT / FEB
• STUDY IN THE CENTER OF MADRID AND TAKE ADVANTAGE OF THE UNIQUE OPPORTUNITIES
  THAT THE CAPITAL OF SPAIN OFFERS
• PROPEL YOUR EDUCATION BY EARNING A DOUBLE DEGREE THAT BEST SUITS YOUR
  PROFESSIONAL GOALS
• STUDY A SEMESTER ABROAD AND BECOME A GLOBAL CITIZEN WITH THE BEYOND BORDERS
  EXPERIENCE
93%
OF MIM STUDENTS ARE
WORKING IN THEIR SECTOR 3 MONTHS
FOLLOWING GRADUATION

Stochastic Processes 2
 
24 
2. The Poisson process
We shall now prove (1). First notice that the frequencies of the Sn are given by
gn(x) =
λn
(n −1)! xn−1e−λx,
x > 0.
(a) First assume that x < t. Then the even occurs that the interval has the length ≤x, if
Sn = y
and
t −y < Xn+1 ≤x,
for some combination of n and y, where t −x < y ≤t.
Then
Ft(x)
=
∞

n=1
 t
t−x
gn(y)

e−λ(t−y) −e−λx
dy =
 t
t−x
 ∞

n=1
gn(y)

·

e−λ(t−y) −e−λx
dy
=
 t
t−x
λ

e−λteλy −e−λx
dy = λe−λt
 t
t−x
eλydy −λxe−λx = 1 −e−λx −λxe−λx,
where we have used that
∞

n=1
gn(y) = λ
∞

n=1
(λy)n−1
(n −1)! e−λy = λ.
By a diﬀerentiation,
ft(x) = λ2xe−λx
for x ≤t.
(b) Then let x > t. The event occurs that the interval has length ≤x, if either
Sn = y
and
t −y < Xn+1 ≤x
for some combination of n and y, or if S1 ∈[t, x].
Then
Ft(x)
=
∞

n=1
 t
0
gn(y)

e−λ(t−y) −e−λx
dy +

e−λt −e−λx
=
λ
 t
0

e−λ(t−y) −e−λx
dy +

e−λt −e−λx
=
1 −e−λt −λte−λx + e−λt −e−λx = 1 −(1 + λt)e−λx.
By diﬀerentiation,
ft(x) = λ(1 + λt)e−λx,
for x > t.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
25 
2. The Poisson process
We have now found the distribution, so we can compute the mean
μ(t)
=
 ∞
0
xft(x) dx =
 t
0
λ2x2e−λx dx +
 ∞
t
λx(1 + λt)e−λx dx
=

−λx3e−λxt
0 + 2
 t
0
λxe−λx dx + (1 + λt)
 ∞
t
λxe−λxdx
=

−λx2e−λx−2xe−λx1
0+2
 t
0
e−λx dx+(1+λt)

−xe−λx−1
λ e−λx
∞
t
=
−λt2e−λt −2te−λt + 2
λ

1 −e−λt
+ (1 + λt)

te−λt + 1
λ e−λt

=
−λt2e−λt−2te−λt+ 2
λ −2
λ e−λt+te−λt+ 1
λ e−λt+λt2e−λt+te−λt
=
2
λ −1
λ e−λt.
An interpretation of this result is that for large values of t, i.e. when the Poisson process has been
working for such a long time that some buses have arrived, then the mean is almost equal to 2
λ, and
deﬁnitely not 1
λ, which Mr. Smith tacitly has used in his second argument.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Stochastic Processes 2
 
26 
2. The Poisson process
Example 2.6 Denote by {X(t), t ≥0} a Poisson process of intensity a, and let ξ be a ﬁxed positive
number. We deﬁne a random variable V by
V = inf{v ≥ξ | there is no event from the Poisson process in the interval ]v −ξ, v]}.
xi
V
tau_4
tau_3
tau_2
tau_1
0
(On the ﬁgure the τi indicate the times of the i-th event of the Poisson process, V the ﬁrst time when
we have had an interval of length ξ without any event).
1) Prove that the distribution function F(v) of V fulﬁls
(2) F(v) =
⎧
⎨
⎩
e−aξ +
	 ξ
0 F(v −x) a e−ax dx,
v ≥ξ,
0,
v < ξ.
2) Prove that the Laplace transform of V is given by
L(λ) = (a + λ)e−(a+λ)ξ
λ + a e−(a+λ)ξ .
Hint: Use that
 ∞
0
F(v) e−λv dv = 1
λ L(λ)
for λ > 0.
3) Find the mean E{V }.
(In one-way single-track street cars are driving according to a Poisson process of intensity a; a pedes-
trian needs the time ξ to cross the street; then V indicates the time when he has come safely across
the street).
The assumptions are
P{X(t) = n} = (a t)n
n!
e−at,
n ∈N0,
and
P {T1 > t} = P{X(t) = 0} = e−at.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
27 
2. The Poisson process
1) Clearly, F(v) = 0 if v < ξ. If v = ξ, then
F(v) = F(ξ) = P {T1 > ξ} = P{X(ξ) = 0} = e−aξ.
If v > ξ, then τi = v −ξ and v −x ∈]v −ξ, c] for x ∈[0, ξ[, and we are led to the following
computation
F(v)
=
P{V ≤v} = P{V = ξ} + P{ξ < V ≤v} = e−aξ + P{ξ < V ≤v}
=
e−aξ +
 v
x=v−ξ
P{V = x} dP{T > v −x}
(3)
=
e−aξ +
 0
ξ
P{V = v −x} dP{T > x} = e−aξ +
 0
ξ
F(v −x) de−ax
=
e−aξ +
 ξ
0
F(v −x) a e−ax dx.
Here (3) is a generalized sum (i.e. an integral), where V = x and T > v −x, which of course will
contribute to F(v).
2) If L(λ) =
	 ∞
0
f(v) e−λv dv then the Laplace transform of V is
 ∞
0
F(v) e−λv dv = 1
λ
 ∞
0
f(v) e−λv dv = 1
λ L(λ)
for λ > 0.
When we Laplace transform the result of (2), then
1
λ L(λ)
=
1
λ e−aξe−aλξ +
 ∞
0
 ξ
0
F(v −x) a e−ax dx

e−λv dv
=
1
λ e−(a+λ)ξ +
 ξ
0
 ∞
0
F(v −x) e−λv dv

a e−ax dx
=
1
λ e−(a+λ)ξ +
 ξ
0
 ∞
x
F(v −x) e−λv dv

a e−ax dx
=
1
λ e−(a+λ)ξ +
 ξ
0
 ∞
0
F(v) e−λv dv

e−λx · a e−ax dx
=
1
λ e−(a+λ)ξ + 1
λ L(λ) · a
 ξ
0
e−(λ+a)x dx
=
1
λ e−(a+λ)ξ + 1
λ L(λ) ·
a
a + λ

1 −e−(a+λ)ξ
,
thus
e−(a+λ)ξ = L(λ) ·

1 −
a
a + λ +
a
a + λ e−(a+λ)ξ

= L(λ) · λ + a e−(a+λ)ξ
a + λ
,
and hence
L(λ) = (a + λ)e−(a+λ)ξ
λ + a e−(a+λ)ξ .
Download free eBooks at bookboon.com

Stochastic Processes 2
 
28 
2. The Poisson process
3) The mean is
E{V }
=
−L′(0)
=
lim
λ→0+

e−(a+λ)ξ −ξ(a + λ)e−(a+λ)ξ
λ + a e−(a+λ)ξ
−(a + λ)e−(a+λ)ξ ·

1 −a ξ e−(a+λ)ξ

λ + a e−(a+λ)ξ2

=
−

e−aξ −ξ a e−aξ
a e−aξ
−a e−aξ 
1 −a ξ e−aξ
(a e−aξ)2

= −e−aξ + ξ a e−aξ + 1 −a ξ e−aξ
a e−aξ
=
1 −e−aξ
a e−aξ
= 1
a

eaξ −1

.
Example 2.7 To a taxi rank taxis arrive from the south according to a Poisson process of intensity
a, and independently there also arrive taxis from the north according to a Poisson process of intensity
b.
We denote by X the random variable which indicates the number of taxies, which arrive from the
south in the time interval between two succeeding taxi arrivals from the north.
Find P{X = k}, k ∈N0, as well as the mean and variance of X.
The length of the time interval between two succeeding arrivals from the north has the frequency
f(t) = b e−bt,
t > 0.
When this length is a (ﬁxed) t, then the number of arriving taxies from the south is Poisson distributed
of parameter a t. By the law of total probability,
P{X = k}
=
 ∞
0
(a t)k
k!
e−at · b e−kt dt = b ak
k!
 ∞
0
tke−(a+b)t dt
=
b ak
k! ·
k!
(a + b)k+1 =

a
a + b
k
·
b
a + b,
k ∈N0,
so X ∈NB

1,
b
a + b

is negative binomially distributed..
It follows by some formula in any textbook that
E{X} = 1 · a
b = a
b
and
V {X} = a(a + b)
b2
= a
b

1 + a
b
 
.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
29 
2. The Poisson process
Example 2.8 The number of car accidents in a given region is assumed to follow a Poisson process
{X(t), t ∈[0, ∞[} of intensity λ, and the number of persons involved in the i-th accident is a random
variableYi, which is geometrically distributed,
P {Yi = k} = p qk−1,
k ∈N,
where p > 0, q > 0 and p + q = 1. We assume that the Yi are mutually independent, and independent
of {X(t), t ≥0}.
1. Find the generating function of X(t).
2. Find the generating function of Yi.
Denote by Z(t) the total number of persons involved in accidents in the time interval ]0, t].
3. Describe the generating function of Z(t) expressed by the generating function of Yi and the gener-
ating function of X(t).
Hint: Use that
P{Z(t) = k} =
∞

i=0
P {X(t) = i ∧Y1 + Y2 + · · · + Yi = k} .
4. Compute E{Z(t)} and V {Z(t)}.
1) Since X(t) is a Poisson process, we have
P{X(t) = k} = (λ t)k
k!
e−λt,
k ∈N0.
We ﬁnd its generating function by using a table,
PX(t)(s) = exp(λt(s −1)).
2) Also, by using a table, the generating function of Yi is
PYi(s) =
p(s)
1 −q s.
The Yi are mutually independent, so the generating function of Y1 + · · · + Yi is given by

ps
1 −qs

,
i ∈N.
3) The generating function of Z(t) is
PZ(t)(s)
=
∞

k=0
P{Z(t) = k} sk =
∞

k=0
 ∞

i=0
P {X(t) = i ∧Y1 + · · · + Yi = k}

sk
=
∞

i=1
P{X(t) = i}
 ∞

k=0
P {Y1 + · · · + Yi = k) sk

=
∞

i=1
P{X(t) = i}

ps
1 −qs

= PX(t)

ps
1 −qs

= exp

λt

ps
1 −qs −1

=
exp

λ t
 s −1
1 −qs

= exp

λt
p
q ·
1
1 −qs −1

.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
30 
2. The Poisson process
4) It follows from
P ′
Z(t)(s) = λt ·
p
(1 −qs)2 PZ(t)(s)
med
P ′
Z(t)(1) = λt
p ,
and
P ′′
Z(t)(s) =

λt ·
p
(1 −qs)2
2
PZ(t)(s) + λt ·
2pq
(1 −qs)3 PZ(t)(s),
where
P ′′
Z(t)(1) =
λt
p
2
+ λt · 2q
p2 ,
that
E{Z(t)} = P ′
Z(t)(1) = λt
p
and
V {Z(t)}
=
P ′′(1) + P ′(1) −(P ′(t))2 =
λt
p
2
+ λt · 2q
p2 + λt
p −
λt
p
2
=
λt · 2q + p
p2
= λt · 1 + q
p2 .
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
“The perfect start 
of a successful, 
international career.”
CLICK HERE 
to discover why both socially 
and academically the University 
of Groningen is one of the best 
places for a student to be 
www.rug.nl/feb/education
Excellent Economics and Business programmes at:

Stochastic Processes 2
 
31 
2. The Poisson process
Example 2.9 (Continuation of Example 2.8).
Assume that the number of car accidents in a city follows a Poisson process {X(t), t ∈[0, ∞[} of
intensity 2 per day. The number of persons involved in one accident is assumed to be geometrically
distributed with p = 1
2.
Find the mean and variance of the number of persons involved in car accidents in the city per week.
It follows from Example 2.8 that
E{Z(t)} = λt
p
and
V {Z(t)} = λt · 1 + q
p2 .
In the speciﬁc case the intensity is λ = 2, and the time span is t = 7 days. Furthermore, p = q = 1
2,
thus
E{Z(7)} = 2 · 7
1
2
= 28
and
V {Z(7)} = 2 · 7 · 1 + 1
2
 1
2
2 = 2 · 7 · 6 = 84.
Example 2.10 Given a service to which customers arrive according to a Poisson process of intensity
λ (measured in the unit minut−1).
Denote by I1, I2 and I3 three succeeding time intervals, each of the length of 1 minute.
1. Find the probability that there is no customer in any of the three intervals.
2. Find the probability that there is precisely one arrival of a customer in one of these intervals and
none in the other two.
3. Find the probability that there are in total three arrivals in the time intervals I1, I2 and I3, where
precisely two of them occur in one of these intervals.
4. Find the value of λ, for which the probability found in 3. is largest.
Then consider 12 succeeding time intervals, each of length 1 minute. Let the random variable Z denote
the number of intervals, in which we have no arrival.
5. Find the distribution of Z.
6. For λ = 1 ﬁnd the probability P{Z = 4} (2 dec.).
1) Let
I1 = ]0, 1],
I2 = ]1, 2],
I3 = ]2, 3].
Then
P{no event in I1 ∪I2 ∪I3 = ]0, 3]} =

e−λ3 = e−3λ.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
32 
2. The Poisson process
2) By a rearrangement,
P{one event in one interval, none in the other two} = P{one event in ]0, 3]} = 3λ e−3λ.
3) We have
P{two events in one interval, one in another one, and none in the remaining one}
= P{two events in one interval, one in the remaining two intervals}
= 3 · λ2
2 · e−λ · 2λ e−2λ = 3λ3e−3λ.
4) We conclude from 3. that g(λ) = 3λ3e−3λ > 0 for λ > 0 with g(λ) →0 for λ →0+, and for
λ →∞. By a diﬀerentiation,
g′(λ) =

9λ2 −9λ3
e−3λ = 9λ2(1 −λ)e−3λ = 0
for λ = 1 > 0,
thus the probability is largest for λ = 1 med g(1) = 3 e−3.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
American online      
LIGS University 
▶▶enroll by September 30th, 2014 and 
▶▶save up to 16% on the tuition!
▶▶pay in 10 installments / 2 years
▶▶Interactive Online education
▶▶visit www.ligsuniversity.com to 
      find out more!
is currently enrolling in the
Interactive Online BBA, MBA, MSc, 
DBA and PhD  programs:
Note: LIGS University is not accredited by any 
nationally recognized accrediting agency listed 
by the US Secretary of Education. 
More info here. 

Stochastic Processes 2
 
33 
2. The Poisson process
5) Assume now that we have 12 intervals. From
P{no arrival in an interval} = e−λ,
we get
P{Z = k} =
 12
k

e−λk 
1 −e−λ12−k ,
k = 0, 1, 2, . . . , 12,
thus Z ∈B

12, e−λ
.
6) By insertion of λ = 1 an k = 4 into the result of 5. we get
P{Z = 4} =
 12
4
 
e−1 
1 −e−124
= 495 ·

0.3679 · 0.632124 = 0.2313 ≈0.23.
Example 2.11 A random variable X is Poisson distributed with parameter a.
1. Compute the characteristic function of X.
2. Prove for large values of a that X is approximately normally distributed of mean a and variance a
(more precisely,
lim
n→∞P
X −a
√a
≤x

= Φ(x)
for all x ∈R).
To a service customers arrive according to a Poisson process of intensity λ = 1 minut−1. Denote by
X the number of customers who arrive in a time interval of length 100 minutes.
3. Apply Chebyshev’s inequality to ﬁnd an lower bound of
(4) P{80 < X < 120}.
4. Find an approximate expression of (4) by using the result of 2..
1) We get from
P{X = k} = ak
k! e−a,
k ∈N0,
the characteristic function
kX(ω) =
∞

k=0
eiωk · ak
k! e−a = e−a
∞

k=0
1
k!

eiω a
k = e−a · exp

a · eiω
= exp

a

eiω −1

.
2) Put
Xa = X −a
√a .
Download free eBooks at bookboon.com

Stochastic Processes 2
 
34 
2. The Poisson process
Then the characteristic function of Xa is given by
kXa(ω)
=
∞

k=0
exp

iω · k −a
√a
 ak
k! e−a = e−iω√a · e−a
∞

k=0
1
k!

a · exp

i ω
√a
k
=
e−iω√a · e−a exp

a · exp

i ω
√a

= exp

a

exp
 iω
√a

−1

−iω√a

.
It follows from
a

exp
 iω
√a

−1

−iω√a
=
a

1 + iω
√a −1
2!
ω2
a + 1
a ε
1
a

−1

−iω√a
=
−1
2 ω2 + ε
1
a

→−1
2 ω2
for a →∞,
that
k(ω) = lim
a→∞kXa(ω) = exp

−1
2 ω2

,
hence k(ω) is the characteristic function of a normally distributed random variable from N(0, 1).
It follows that {Xa} for a →∞converges in distribution towards the normal distribution N(0, 1),
thus
lim
a→∞P
X −a
√a
≤x

= Φ(x)
for every x ∈R.
3) If t = 100 and λ = 1 minut−1, then
P{X = n} = 100n
n!
e−100,
n ∈N0,
hence a = 100 and σ2 = 100. Then by Chebyshev’s inequality
P{|X −100| ≥20} ≤100
202 = 1
4,
so
P{80 < X < 120} = 1 −P{|X −100| ≥20} ≥1 −1
4 = 3
4.
4) An approximate expression of
P{80 < X < 120} = P{|X −100| < 20} = P
!!!!
X −100
10
!!!! < 2

is then by 2. given by
Φ(2) −Φ(−2) = 2Φ(2) −1 ≈2 · 0.9772 −1 = 0.9544.
However, since X is an integer, we must here use the correction of continuity. Then the interval
should be 80.5 < x < 119.5. We get the improved approximate expression,
P{80.5 < X < 119.5}
=
P{|X −100| < 19.5} = P
!!!!
X −100
10
!!!! < 1.95

=
Φ(1.95) −Φ(1.95) = 2Φ(1.95) −1
≈
2 · 0.9744 −1 = 0, 9488.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
35 
2. The Poisson process
Remark 2.1 For comparison a long and tedious computation on a pocket calculator gives
P{80 < X < 120} ≈0.9491.
♦
Example 2.12 In a shop there are two shop assistants A and B. Customers may freely choose if they
will queue up at A or at B, but they cannot change their decision afterwards. For all customers at A
their serving times are mutually independent random variables of the frequency
f(x) =
⎧
⎨
⎩
λ e−λx,
x > 0,
0,
x ≤0,
(λ is a positive constant),
and for the customers at B the serving times are mutually independent random variables of frequency
g(y) =
⎧
⎨
⎩
2λ e−2λy,
y > 0,
0,
y ≤0.
At a given time Andrew arrives and is queueing up at A, where there in front of him is only one
customer, and where the service of this customer has just begun. We call the serving time of this
customer X1, while Andrew’s serving time is called X2.
At the same time Basil arrives and joins the queue at B, where there in front of him are two waiting
customers, and where the service of the ﬁrst customer has just begun. The service times of these two
customers are denoted Y1 and Y2, resp..
1. Find the frequencies of the random variables X1 + X2 and Y1 + Y2.
2. Express by means of the random variables Y1, Y2 and X1 the event that the service of Basil starts
after the time when the service of Andrew has started, and ﬁnd the probability of this event.
3. Find the probability that the service of Basil starts after the end of the service of Andrew.
Assume that the customers arrive to the shop according to a Poisson process of intensity α.
4. Find the expected number of customers, who arrive to the shop in a time interval of length t.
5. Let N denote the random variable, which indicates the number of customers who arrive to the shop
during the time when Andrew is in the shop (thus X1 + X2). Find the mean of N.
1) Since Xi ∈Γ

1, 1
λ

is exponentially distributed we have X1 + X2 ∈Γ

2, 1
λ

, thus
fX1+X2(x) =
⎧
⎨
⎩
λ2x e−λx,
x ≥0,
0,
x < 0,
Since Yi ∈Γ

1, 1
2λ

, we have Y1 + Y2 ∈Γ

2, 1
2λ

with the frequency
gY1+Y2(y) =
⎧
⎨
⎩
4λ2y e−2λy,
y ≥0,
0,
y < 0.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
36 
2. The Poisson process
2) The event is expressed by X1 < Y1 + Y2. The probability of this event is
P {X1 < Y1 + Y2}
=
 
{0<x<y}
λ e−λx · 4λ2y e−2λy dx dy
=
 ∞
0
4λ2y e−2λy
 y
0
λ e−λx dx

dy
=
 ∞
0
4λ2y e−2λy 
−e−λxy
x=0 dy
=
 ∞
0
4λ2y e−2λy dy −
 ∞
0
4λ2y e−3λy dy
=
 ∞
0
t e−t dt −4
9
 ∞
0
t e−t dt = 5
9.
3) We must have in this case that X1 + X2 < Y1 + Y2. Hence the probability is
P {X1 + X2 < Y1 + Y2} =
 
{0<x<y}
λ2x e−λx · 4λ2y e−2λy dx dy
=
 ∞
0
4λ2y e−2λy
 y
0
λ2x e−λx dx

dy =
 ∞
0
4λ2y e−2λy

−λx e−λxy
0 +
 y
0
λ e−λx dx

dy
=
 ∞
0
4λ2y e−2λy
 y
0
λ e−λx dx −
 ∞
0
4λ3y2e−3λy dy
= P {X1 < Y1 + Y2} −4
27
 ∞
0
(3λ)3y2e−3λy dy = 5
9 −4
27 · 2 = 15 −8
27
= 7
27.
4) If X(t) indicates the number of arrived customers in ]0, t], then
P{X(t) = n} = (αt)n
n!
e−αt,
n ∈N0,
and
m(t) = E{X(t)} =
∞

n=0
n (αt)n
n!
e−αt = α t.
5) Finally, (cf. 4.),
E{N} = α E {X1 + X2} = α
 1
λ + 1
λ

= 2α
λ .
Download free eBooks at bookboon.com

Stochastic Processes 2
 
37 
3. Birth and death processes
3
Birth and death processes
Example 3.1 Consider a birth process {X(t), t ∈[0, ∞[} of states E0, E1, E2, . . . and positive birth
intensities λk. The diﬀerential equations of the process are
⎧
⎨
⎩
P ′
0(t) = −λ0P0(t),
P ′
k(t) = −λkPk(t) + λk−1Pk−1(t),
k ∈N,
and we assume that the process at t = 0 is in state E0. It can be proved that the diﬀerential equations
have a uniquely determined solution (Pk(t)) satisfying
Pk(t) ≥0,
∞

k=0
Pk(t) ≤1.
One can also prove that either 
∞
k=0 Pk(t) = 1 for all t > 0, or 
∞
k=0 Pk(t) < 1 for all t > 0.
Prove that

∞
k=0 Pk(t) = 1 for all t > 0, if and only if 
∞
k=0
1
λk
is divergent.
Hint: First prove that
1
λk
a(t) ≤
 t
0
Pk(s) ds ≤1
λk
,
k ∈N0,
t > 0,
where a(t) = 1 −
∞
k=0 Pk(t).
We get by a rearrangement and recursion,
λkPk(t) = −P ′
k(t) + λk−1Pk−1(t) = −P ′
k(t) −P ′
k−1(t) + λk−2Pk−2(t) = · · · = −
k

j=0
P ′
j(t),
hence by integration,
λk
 t
0
Pk(s) ds =
⎡
⎣−
k

j=0
Pj(s)
⎤
⎦
t
0
=
k

j=0
Pj(0)Pj(t) = 1 −
k

j=0
Pj(t),
because at time t = 0 we are in state E0, so P0(0) = 0, and Pj(0) = 0, j ∈N.
Thus we have the estimates
a(t) = 1 −
∞

j=0
Pj(t) ≤1 −
k

j=0
Pj(t) = λk
 t
0
Pk(s) ds ≤1,
from which
1
λk
a(t) ≤
 t
0
Pk(s) ds ≤1
λk
.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
38 
3. Birth and death processes
Assume that 
∞
k=0 Pk(t) = 1. Applying the theorem of monotonous convergence (NB The Lebesgue
integral!) it follows from the right hand inequality that
∞

k=0
1
λl
≥
∞

k=0
 t
0
Pk(s) ds =
 t
0
∞

k=0
Pk(s) ds =
 t
0
1 dt = t
for alle t ∈R+,
proving that the series 
∞
k=0
1
λk
is divergent.
Then assume that 
∞
k=0 Pk(t) < 1, thus
a(t) = 1 −
∞

k=0
Pk(t) > 0.
Using the theorem of monotonous convergence and the left hand inequality we get

k=0
1
λk

· a(t) ≤
∞

k=0
 t
0
Pk(s) ds ≤t
for all t ∈R+.
Now a(t) > 0, so this implies that
∞

k=0
1
λk
≤
t
a(t) < ∞,
and the series 
∞
k=0
1
λk
is convergent.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Stochastic Processes 2
 
39 
3. Birth and death processes
Example 3.2 To a carpark, cars arrive from 900 (t = 0) following a Poisson process of intensity λ.
There are in total N parking bays, and we assume that no car leaves the carpark. Let En, n = 0, 1,
. . . , N, denote the state that n of the parking bays are occupied.
1) Find the diﬀerential equations of the system.
2) Find Pn(t), n = 0, 1, . . . , N.
3) Find the stationary probabilities pn, n = 0, 1, . . . , N.
Put λ = 1 minute−1 and N = 5. Find the probability that a car driver who arrives at 903 cannot ﬁnd
a vacant parking bay.
1) This is a pure birth process with
λn =
⎧
⎨
⎩
λ
for n = 0, 1, . . . , N −1,
0
for n = N,
and the system of diﬀerential equations
P ′
0(t)
=
−λ P0(t),
P ′
n(t)
=
−λ Pn(t) + λ Pn−1(t),
n = 1, 2, . . . , N −1,
P ′
N(t)
=
λ PN−1(t),
and initial conditions
Pn(0) =
⎧
⎨
⎩
1
for n = 0,
0
for n > 0.
2) The system of 1. can either be solved successively or by consulting a textbook,
Pn(t) =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
e−λt (λt)n
n!
,
n = 0, 1, 2, . . . , N −1,
1 −
N−1
n=0
(λt)n
n!
e−λt,
n = n.
3) It follows immediately that
Pn(t) →

0,
n < N,
1,
n = N,
for t →∞,
thus
pn =
⎧
⎨
⎩
0,
n < N,
1,
n = n.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
40 
3. Birth and death processes
4) First identify
λ = 1 minute−1,
t = 3
and
N = 5.
Then by insertion,
P

no parking bay at 903
= P5(3) = 1 −
4

n=0
Pn(3) = 1 −
4

n=0
3n
n! e−3 = 0.1847 ≈0.185.
Example 3.3 Given a stochastic birth and death process X(t), t ∈[0, ∞[}, which can be in the states
E4, E5, E6 and E7.
Assume that the birth intensity λk is in state Ek given by
λk = αk(7 −k),
and that the death intensity μk in state Ek is equal to
μk = βk(k −4),
where α and β are positive constants.
Find the stationary probabilities in each of the two cases below
1) β = α,
2) β = 2α.
The equations of equilibrium are here
μk+1pk+1 = λkpk
for k = 4, 5, 6.
Thus
p5
=
λ4
μ5
p4 = 12α
5β p4 = 12
5
α
β
1
p4,
p6
=
λ5
μ6
p5 = 10α
12β · 12
5
α
β = 2
α
β
2
p4,
p7
=
λ6
μ7
p6 = 6α
21β · 2
α
β
2
= 4
7
α
β
3
p4.
Furthermore,
p4 + p5 + p6 + p7 = 1.
However, the exact values can ﬁrst be found when we know the relationship between α and β.
1) If β = α, then
1 = p4

1 + 12
5 + 2 + 4
7

= 35 + 84 + 70 + 20
35
p4 = 209
35 p4,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
41 
3. Birth and death processes
hence
p4 = 35
209,
p5 = 12
5 · 35
209 = 84
209,
p6 = 70
209,
p7 = 4
7 · 35
209 =
20
2 + 9,
so
p = (p4, p5, p6, p7) =
1
209 (35, 84, 70, 20).
2) If β = 2α, then α
β = 1
2, hence
p5 = 6
5 p4,
p6 = 1
2 p4,
p7 = 1
14 p4,
and
1 = p4 + p5 + p6 + p7 = p4

1 + 6
5 + 1
2 + 1
14

= 70 + 84 + 35 + 5
70
p4 = 97
35 p4,
from which
p4 = 35
97,
p5 = 42
97,
p6 = 35
194,
p7 =
5
194,
i.e.
p = (p4, p5, p6, p7) =
1
194 (70, 84, 35, 5).
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
 
  
 
                . 

Stochastic Processes 2
 
42 
3. Birth and death processes
Example 3.4 Given a birth and death process of the states E0, E1, E2, . . . , birth intensities λk and
death intensities μk. Assume furthermore that
a. λk = μk = k α, k ∈N0, (where a is a positive constant).
b. P1(0) = 1.
1. Find the diﬀerential equations of the process.
One may now without proof use that under the assumptions above,
P1(t) =
1
(1 + αt)2 .
2. Find P0(t), P2(t) and P3(t).
3. Sketch the graph of P0(t) + P1(t).
4. Sketch the graph of P2(t).
5. Find limt→∞Pn(t) for every n ∈N0.
1) We have
P ′
0(t) = −λ0P0(t) + μ1P1(t) = α P1(t),
and
P ′
k(t)
=
−(λk + μk) Pk(t) + λk−1Pk−1(t) + μk+1Pk+1(t)
=
(k −1)αPk−1(t) −2kαPk(t) + (k + 1)αPk+1(t)
for k ∈N.
2) If P1(0) = 1, then Pk(0) = 0 for k ∈N0 \ {1}. It follows from
P ′
0(t) = α P1(t) =
α
(1 + αt)2 ,
by an integration that
P0(t) =
 t
0
α dτ
(1 + ατ)2 =

−
1
1 + ατ
t
0
= 1 −
1
1 + αt =
αt
1 + αt.
If k = 1, we get by a rearrangement,
P2(t)
=
1
2α {P ′
1(t) −0 · P0(t) + 2α P1(t)} = 1
2α

−
2α
(1 + αt)3 +
2α
(1 + αt)2

=
1
(1 + αt)2 −
1
(1 + αt)3 =
αt
(1 + αt)3 .
Download free eBooks at bookboon.com

Stochastic Processes 2
 
43 
3. Birth and death processes
If k = 2, we get by a rearrangement,
P3(t)
=
1
3α {P ′
2(t) −α P1(t) + 4α P2(t)}
=
1
3α

3α
(1+αt)4 −
2α
(1+αt)3 −
α
(1+αt)2 +
4α
(1+αt)2 −
4α
(1+αt)3

=
1
3α

3α
(1 + αt)4 −
6α
(1 + αt)3 +
3α
(1 + αt)2

=
(1 + αt)2 −2(1 + αt) + 1
(1 + αt)4
=
α2t2
(1 + αt)4 .
Summing up,
P0(t) =
αt
1 + αt,
P1(t) =
1
(1 + αt)2 ,
P2(t) =
αt
(1 + αt)3 ,
P3(t) =
α2t2
(1 + αt)4 .
0
0.2
0.4
0.6
0.8
1
0.5
1
1.5
2
2.5
3
Figure 1: The graph of 1 −
x
(1 + x)2 with x = αt.
3) It follows that
P0(t) + P1(t) =
αt
1 + αt +
1
(1 + αt)2 = 1 + αt + α2t2
(1 + αt)2
= 1 −
αt
(1 + αt)2 .
If we put x = αt, we see that we shall only sketch
1 −
x
(1 + x)2 = 1 −
1
1 + x +
1
(1 + x)2 ,
which has a minimum for x = 1, and has y = 1 as an asymptote.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
44 
3. Birth and death processes
0
0.2
0.4
0.6
0.8
1
0.5
1
1.5
2
2.5
3
Figure 2: The graph of
x
(1 + x)3 with x = αt.
4) If we put x = αt, it follows that we shall only sketch
ϕ(x) =
x
(1 + x)3 .
From
ϕ′(x) =
1
(1 + x)3 −
3x
(1 + x)4 = 1 −2x
(1 + x)4 ,
follows that we have a maximum for x = 1
2, corresponding to
ϕ
1
2

=
1
2
 3
2
3 = 4
27.
5) Clearly,
lim
t→∞P0(t) = lim
t→∞
αt
1 + αt = 1.
We conclude from
∞

n=0
Pn(t) = 1
and
Pn(t) ≥0,
that
lim
t→∞
∞

n=1
Pn(t) = 0,
hence
lim
t→∞Pn(t) = 0
for alle n ∈N.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
45 
3. Birth and death processes
Example 3.5 A power station delivers electricity to N customers.
If a customer at time t uses
electricity there is the probability μh + h ε(h) that he does not use electricity at time t + h, and
probability 1 −μh + h ε(h) that he is still using electricity at time t + h.
However, if he to time t does not use electricity, then there is the probability λh + h ε(h) that he uses
electricity at time t + h, and probability 1 −λh + h ε(h) that he does not do it.
The customers are using electricity mutually independently.
Denote by Ek the state that k consumers use electricity, k = 0, 1, . . . , N.
Find the diﬀerential equations of the system.
Find the stationary probabilities.
We put Xk(t) = 1, if the k-th customer uses electricity at time t, and Xk(t) = 0, if he does not do it.
Let n and j ∈{0, 1, . . . , N}, and assume that the system is in state Ej, i.e.
N

k=1
Xk(t) = j
at time t.
How can we realize that we are in state En at time t + h?
There must be an m ∈{0, 1, . . . , j}, such that j −m of the customers who were using electricity at
time t, still are using electricity at time t + h.
Furthermore, n −j + m of the customers, who did not use electricity at time t, must use electricity
at time t + h, is we are in state En.
Thus we get the condition m ≥j −n, so
m ∈{max{0, j −n}, . . . , min{j, N −n}},
and
j ∈{0, 1, . . . , N}.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.mastersopenday.nl
Visit us and find out why we are the best!
Master’s Open Day: 22 February 2014
Join the best at
the Maastricht University
School of Business and
Economics!
Top master’s programmes
• 33rd place Financial Times worldwide ranking: MSc 
International Business
• 1st place: MSc International Business
• 1st place: MSc Financial Economics
• 2nd place: MSc Management of Learning
• 2nd place: MSc Economics
• 2nd place: MSc Econometrics and Operations Research
• 2nd place: MSc Global Supply Chain Management and 
Change
Sources: Keuzegids Master ranking 2013; Elsevier ‘Beste Studies’ ranking 2012; 
Financial Times Global Masters in Management ranking 2012
Maastricht
University is
the best specialist
university in the
Netherlands
(Elsevier)

Stochastic Processes 2
 
46 
3. Birth and death processes
Summing up, if the conditions above are fulﬁlled, then
1) m of the customers, who used electricity at time t, do not do it at time t + h.
2) j −m use electricity both at time t and at time t + h.
3) n −j + m did not use electricity at time t, but they do it at time t + h.
4) N −n −m neither use electricity at time t nor at time t + h.
For ﬁxed j this can be done of the probability
min{j,N−n}

m=max{0,j−n}

j
m

{μh + hε(h)}m{1 −μh + hε(h)}j−m

N −j
n −j + m

{λh + hε(h)}n−j+m{1 −λh + hε(h)}N−n−m.
When we multiply this equation by Pj(t) and then sum with respect to j, we get
Pn(t + h)
=
N

j=0
Pj(t)
min{j,N−n}

m=max{0,j−n}

j
m
 
N −j
n −j + m

×
(5)
×{μh + hε(h)}m{1 −μh + hε(h)}j−m ×
×{λh + hε(h)}n−j+m{1 −λh + hε(h)}N−m−n.
If m = 0 in the inner sum, then j ≤n, and we isolate the term
 j
0
  N −j
n −j

{μh + hε(h)}0{1 −μh + hε(h)}j{λh + hε(h)}n−j{1 −λh + hε(h)}N−n
=

N −j
n −j

{1 −μh + hε(h)}j{1 −λh + hε(h)}N−nhn−j{λ + ε(h)}n−j.
It follows clearly that if j ̸= n, n −1, then we get terms of the type hε(h),
If furthermore j = n, then we get the term

N −n
0

{1 −μh + hε(h)}n{1 −λh + hε(h)}N−n · 1
= (1 −μh)n(1 −λh)N−n + hε(h) = 1 −nμh + (N −n)λh + h ε(h).
If instead j = n −1, then we get the term

N −n + 1
1

{1 −μh + hε(h)}n−1{1 −λh + hε(h)}N−1 · h · (λ + hε(h))
= (N −n + 1)hλ + hε(h).
If m = 1 in the inner sum of (5), then
j −n ≤n ≤min{j, N −n},
thus 1 ≤j ≤n + 1. For such j we get the contribution
 j
1
 
N −j
n −j + 1

μh(1 −μh)j−1(λh)n−j+1(1 −λh)N−n−m + hε(h).
Download free eBooks at bookboon.com

Stochastic Processes 2
 
47 
3. Birth and death processes
It follows immediately that if j ̸= n + 1, then all these terms are of the type hε(h).
For j = n + 1 we get the contribution

n + 1
1
 
N −n −1
0

μh(1 −μh)n(1 −λh)N−n−m + hε(h) = (n + 1)μh + hε(h).
If m ≥2, we only get terms of the type hε(h).
We now include ε functions. Then (5) is reduced by this analysis for n = 1, . . . , N −1, to
Pn(t + h)
=
Pn{1 −nμh −(N −n)λh + hε(h)} + Pn−1(t) · (N −n + 1)hλ + hε(h)
+Pn+1(t) · (n + 1) · μh + hε(h),
thus by a rearrangement
Pn(t + h) −Pn(t)
= −h {(nμ + (N −n)λ)Pn(t)} + h(N −n + 1)λPn−1(t) + h(n + 1)μPn+1(t) + hε(h),
and hence dividing by h, followed by taking the limit h →0,
P ′
n(t) = −{nμ + (N −n)λ}Pn(t) + (N −n + 1)λPn−1(t) + (n + 1)μPn+1(t).
There are some modiﬁcations for n = 0 and n = N, in which cases we get instead
P ′
0(t) = −N λ P0(t) + μ P1(t),
and
P ′
N(t) = −N μ PN(t) + λ PN−1(t).
Then we have for the stationary probabilities,
0
=
−N λ p0 + μ p1,
0
=
−{nμ + (N −n)λ}pn + (N −n + 1)λpn−1 + (n + 1)μpn+1,
n = 1, . . . , N −1,
0
=
−N μ pN + λ pN−1,
hence
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
p1 = N · λ
μ p0
pn+1 =

n
n + 1 + N −n
n + 1 · λ
μ

pn −N −n + 1
n + 1
· λ
μ pn−1
n = 1, . . . , N −1,
pN = 1
N · λ
μ pN−1.
In order to ﬁnd the pattern we compute p2, i.e. we put n = 1 into the general formula
p2
=
1
2 + N −1
2
· λ
μ

p1 −N
2
λ
μ

p0 = N
2 · λ
μ · p0 + N(N −1)
2
λ
μ
2
p0 −N
2 · λ
μ · p0
=
 N
2

·
λ
μ
2
p0.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
48 
3. Birth and death processes
Now
p1 = N ·
λ
μ
1
p0 =
 N
1

·
λ
μ
1
p0,
so we guess that we in general have
pn =

N
n

·
λ
μ
m
p0.
This is true for n = 0, 1, 2.
Assume that the claim holds for all indices up to n. If n ≤N −1, then
pn+1
=

n
n + 1 + N −n
n + 1 · λ
μ

pn −N −n + 1
n + 1
· λ
μ pn−1
=
n
n + 1 ·
N!
n!(N −n)!
λ
μ
n
+ N −n
n + 1 ·
N!
n!(N −n)!
λ
μ
n+1
p0
−N −n + 1
n + 1
·
N!
(n −1)!(N −n + 1)!
λ
μ
n
p0
=
N!
(n + 1) · (n −1)!(N −n)!
λ
μ
n
p0 −
N!
(n + 1)(n −1)!(N −n)!
λ
μ
n
p0
+
N!
(n + 1)!(N −n −1)!
λ
μ
n+1
p0
=

N
n + 1
 λ
μ
n+1
p0,
and the claim follows by induction. Then
1 =
N

n=0
pn = p0
N

n=0
 N
n
 λ
μ
n
= p0 ·

1 + λ
μ
N
= p0
λ + μ
μ
N
,
hence
pn =
 N
n

·
λ
μ
n
·

μ
λ + μ
N
=
 N
n
 
λ
λ + μ
n 
μ
λ + μ
N−n
.
The solution above is somewhat clumsy, though it follows the ordinary way one would solve problems
of this type without too much training.
Alternatively we see that we have a birth and death process of states E0, E1, . . . , EN, and
intensities
λk = (N −k)λ,
μk = kμ,
k ∈{0, 1, . . . , N}.
The corresponding system of diﬀerential equations becomes
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
P ′
0(t) = −NλP0(t) + μP1(t),
P ′
k(t) = −{(N −k)λ+kμ}Pk(t)+(N −k+1)λPk−1(t)+(k+1)μPk+1(t),
for 1 ≤k ≤N −1,
P ′
N(t) = −NμPN(t) + λPN−1(t).
Download free eBooks at bookboon.com

Stochastic Processes 2
 
49 
3. Birth and death processes
The stationary probabilities pk are found from
μkpk = λk−1pk−1,
k = 1, 2, . . . , N,
thus
pk = N −k + 1
k
· λ
μ · pk−1.
Then by recursion,
pk = (N −k + 1)(N −k + 2) · N
k · (k −1) · 1
·
λ
μ
k
p0 =
N!
k!(N −k)!
λ
μ
k
p0 =

N
k
 λ
μ
k
p0.
Finally, it follows from
1 =
N

k=0
pk = p0
N

k=0

N
k
 λ
μ
k
= p0
λ
μ + 1
N
= p0
λ + μ
μ
N
that
pk =
 N
k
 λ
μ
k
p0 =

k
 λ
μ
k
·
 μ
λ+μ
N
=
 N
k

·

λ
λ + μ
k  μ
λ+μ
N−k
,
for k = 0, 1, 2, . . . , N, so we get a binomial distribution B

N,
λ
λ + μ

of mean N ·
λ
λ + μ.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Stochastic Processes 2
 
50 
3. Birth and death processes
Example 3.6 Given a stochastic process {X(t), t ∈[0, ∞[} by the following: At time t = 0 there are
N cars in a carpark. No car arrives, and the cars leave the carpark mutually independently. If a car
is staying at its parking bay at time t, then there is the probability μh + hε(h) [where μ is a positive
constant] that it leaves the carpark in the time interval ]t, t + h].
Put X(t) = k, k = 0, 1, . . . , N, if there are k cars in the carpark at time t, and put
Pk(t) = P{X(t) = k}.
1. Prove that we have a death process with μk = kμ, k = 0, 1, . . . , N.
2. Find the diﬀerential equations of the system.
3. Find the stationary probabilities.
4. Prove that the mean value function
m(t) =
N

k=1
k Pk(t)
is a solution of the diﬀerential equation
dx
dt + μx = 0,
and then ﬁnd m(t).
5. Given that X(t) is binomially distributed, ﬁnd the probabilities Pk(t), k = 0, 1, . . . , N.
We introduce a random variable T by putting T = t, if the last car leaves the carpark at time t.
6. Find the distribution function and the frequency of T.
1) This follows e.g. from the fact that the probability that one of the k cars leaves the carpark in the
time interval ]t, t + h] is
k{μh + hε(h)} · {1 −μh + hε(h)}k−1 = kμh + hε(h),
from which we conclude that μk = kμ.
2) The diﬀerential equations are immediately found to be
⎧
⎨
⎩
P ′
k(t) = −kμPk(t) + (k + 1)μPk+1(t),
0 ≤k ≤N −1,
P ′
N(t) = −NμPN(t).
3) The stationary probabilities become
k pk = 0,
k = 0, 1, . . . , N.
Since 
N
k=0 pk = 1, we get
pk = 0
for k = 1, 2, . . . , N
and
p0 = 1.
This result is of course obvious, because the carpark at last is empty.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
51 
3. Birth and death processes
4) If we multiply the k-th equation of 2. by k, and then sum from 1 to N, we get
N

k=1
k P ′
k(t)
=
−μ
N

k=1
k2Pk(t) + μ
N−1

k=1
k(k + 1)Pk+1(t)
=
−μ
N

k=1
k2Pk(t) + μ
N

k=1
(k −1 = jPk(t) = −μ
N

k=1
k Pk(t),
which is also written
m′(t) + μ m(t) = 0,
m(t) =
N

k=1
k Pk(t).
From m(0) = N follows that m(t) = N e−μt.
5) Since X(t) is binomially distributed of parameter of numbers N, and since we also know the mean,
we can ﬁnd the probability parameter, thus
X(t) ∈B

N, e−μt
,
and
Pk(t) =
 N
k

e−kμt 
1 −e−μtN−k ,
k = 0, 1, . . . , N.
6) Now, T ≤t, if and only if X(t) = 0. Hence
F(t) =
⎧
⎨
⎩
P0(t) = (1 −e−μt)N ,
for t ≥0,
0
for t < 0,
and ﬁnally by diﬀerentiation
f(t) =
⎧
⎨
⎩
N (1 −e−μt)N−1 μ e−μt,
for t ≥0,
0,
for t < 0.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
52 
4. Queueing theory
4
Queueing theory
Example 4.1 Customers arrive to a shop by a Poisson process of intensity λ. There are 2 shop
assistants and possibility of forming a queue. We assume that the service times are exponentially
distributed of parameter μ.
It is given that there are no customers in the shop in at the average 10 % of the time and that 1
λ = 11.
Find 1
μ.
Then ﬁnd the probability that both shop assistants are busy.
Here, N = 2 and p0 = 1
10 and 1
λ = 11. In fact, it was given that P0(t) →p0 = 10 % for t →∞.
The traﬃc intensity ϱ is for N = 2 given by
p0 = 1 −ϱ
1 + ϱ = 1
10,
hvoraf ϱ = 9
11.
On the other hand, the traﬃc intensity is deﬁned by
ϱ =
λ
Nμ = λ
2μ =
1
2 · 11 μ = 9
11,
dvs. 1
μ = 18.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Get Help Now
Go to www.helpmyassignment.co.uk for more info
Need help with your
dissertation?
Get in-depth feedback & advice from experts in your 
topic area. Find out what you can do to improve
the quality of your dissertation!

Stochastic Processes 2
 
53 
4. Queueing theory
Hence
p1 = 2ϱ · 1 −ϱ
1 + ϱ = 2 · 9
11 · 1
10,
and therefore,
P{both shop assistants busy} = 1 −p0 −p1 = 1 −1
10 −18
110 = 81
110.
Example 4.2 Customers arrive to a shop following a Poisson process of intensity λ. We have 1
shop assistant and it is possible to form a queue. We assume that the service times are exponentially
distributed of parameter μ. It is assumed that the traﬃc intensity is ϱ = 6
5, where it is well-known
that this implies that the system does not work properly (the queue increases indeﬁnitely). Compare
the advantages of the following two possibilities:
1) Another shop assistant is hired (of the same service time distribution as the ﬁrst one).
2) Improvement of the service, such that the average service time is lowered to its half.
We have a queueing system with possibility of forming a queue. The parameters are
N = 1,
ϱ = 6
5
and
λ,
μ.
Since ϱ = 6
5 > 1, this system does not work properly.
1) If another shop assistant is hired, then the parameters are changed to
N = 2,
ϱ = 3
5
and
λ, μ unchanged.
Then
p0 = 1 −ϱ
1 + ϱ = 1
4.
The average waiting time is
V1 =
1
4 ·
3
5
2
· 2
μ · 2
2
5
2 = 9
16 · 1
μ,
and the average staying time is
O1 = 9
16 · 1
μ + 1
μ = 25
16 · 1
μ.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
54 
4. Queueing theory
Remark 4.1 It should here be added that one can also ﬁnd
the average number of customers = 15
8 ,
the average number of busy shop assistants = 6
5,
the average length of the queue = 27
40.
♦
2) If instead the service is improved as indicated, then the parameters become
N = 1,
ϱ = 3
5,
λ unchanged,
μ is doubled.
The average waiting time is then
V2 =
ϱ
2μ(1 −ϱ) = 12
16 · 1
μ,
and the average staying time is
O2 = 12
16 · 1
μ + 1
2μ = 20
16 · 1
μ.
Remark 4.2 Again we add for completeness,
the average number of customers = 3
5,
ther average number of busy shop assistants = 3
5,
the average length of the queue = 9
10.
♦
By comparing the two cases we get
V1 < V2,
and on the contrary
O1 > O2,
and the question does not have a unique answer.
The customer will prefer that the sum of waiting time and service time is as small as possible. Since
V1 + O1 = 34
16 · 1
μ
and
V2 + O2 = 32
16 · 1
μ,
it follows that the customer will prefer the latter system, while it is far more uncertain what the shop
would prefer, because we do not know the costs of each of the two possible improvements.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
55 
4. Queueing theory
Example 4.3 We consider an intersection which is not controlled by traﬃc lights. One has noticed
that cars doing a left-hand turn are stopped and therefore delay the cars which are going straight on.
Therefore, one plans to build a left-hand turn lane. Assuming that arrivals and departures of the cars
doing the left-hand turn are exponentially distributed with the parameters λ and μ, where λ
μ = 1
2, one
shall compute the smallest number of cars of the planned left-hand turn lane, if the probability is less
than 5 % of the event that there are more cars than the new lane can contain.
Here N = 1, so the capacity of the system is
ϱ =
λ
Nμ = 1
2.
The stationary probabilities are
pk = ϱk(1 −ϱ) =
1
2
k+1
,
k ∈N0.
Let n denote the maximum number of cars in the left turn lane. Then we get the condition
∞

k=n+1
pk =
∞

k=n+1
1
2
k+1
=
1
2n+1 < 5 % = 1
20,
thus 1
2n < 1
10, which is fulﬁlled for n ≥4.
Example 4.4 Given a queueing system of exponential distribution of arrivals and exponential distri-
bution of service times (the means are called 1
λ and 1
μ, resp.). The number of service places is 2. We
furthermore assume that it is possible to form a queue. Assuming that 1
λ = 1 (minute) and 1
μ = 1
(minute),
1. ﬁnd the average waiting time,
2. ﬁnd the average staying time.
For economic reasons the number of service places is cut down from 2 to 1, while the service at the
same time is simpliﬁed (so the service time is decreased), such that the customer’s average staying
time is not prolonged. Assuming that the constant λ is unchanged,
3. ﬁnd the average service time 1
μ1
, such that the average staying time in the new system is equal to
the average staying time in the previous mentioned system,
4. ﬁnd in which of the two systems the probability is largest for a customer to wait.
Here N = 2, 1
λ = 1 and 1
μ = 1. This gives the traﬃc intensity
ϱ =
λ
Nμ =
1
2 · 1 = 1
2,
and
p0 = 1 −ϱ
1 + ϱ = 1
3.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
56 
4. Queueing theory
1) The average waiting time is
V = p0 · ϱN · N N−1
μ · N!(1 −ϱ)2 =
1
3 ·
 1
2
2 · 21
1 · 2!

1 −1
2
2 = 1
3 minute.
2) The staying time is the waiting time plus the serving time, so the average staying time is
O = V + 1
μ = 1
3 + 1 = 4
3 minute.
3) In the new system the traﬃc intensity is
ϱ1 =
λ
N1μ1
= 1
μ1
,
idet N1 = 1.
The average waiting time is for N1 given by some theoretical formula,
V1 =
ϱ1
μ1 (1 −ϱ1) =
1
μ1 (μ1 −1),
and the average staying time is for N1 = 1 given by
O1 = V1 + 1
μ1
=
1
μ1 −1.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
By 2020, wind could provide one-tenth of our planet’s 
electricity needs. Already today, SKF’s innovative know-
how is crucial to running a large proportion of the 
world’s wind turbines. 
Up to 25 % of the generating costs relate to mainte-
nance. These can be reduced dramatically thanks to our 
systems for on-line condition monitoring and automatic 
lubrication. We help make it more economical to create 
cleaner, cheaper energy out of thin air. 
By sharing our experience, expertise, and creativity, 
industries can boost performance beyond expectations. 
Therefore we need the best employees who can 
meet this challenge!
The Power of Knowledge Engineering
Brain power
Plug into The Power of Knowledge Engineering. 
Visit us at www.skf.com/knowledge

Stochastic Processes 2
 
57 
4. Queueing theory
We want that O1 = O = 4
3. Hence, μ1 −1 = 3
4, i.e. μ1 = 7
4, and
1
μ1
= 4
7.
4) The probability of waiting in the old system is
1 −p0 −p1 = 1 −1 −ϱ
1 + ϱ −2 ϱ 1 −ϱ
1 + ϱ = 1 −1
3 −2 · 1
2 · 1
3 = 1
3.
The probability of waiting in the new system is
1 −˜p0 = 1 −(1 −ϱ1) = ϱ1 = 1
μ1
= 4
7.
We see by comparison that there is largest probability of waiting in the new system.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Stochastic Processes 2
 
58 
4. Queueing theory
Example 4.5 Given a service (a shop) of which we assume:
a. There is only one shop assistant.
b. It is not possible to form a queue.
c. The customers arrive according to a Poisson process of intensity λ.
d. The service time is exponentially distributed of mean μ.
1. Find the diﬀerential equations of this system.
2. Solve these under the assumption that at time t = 0 there is no customer.
Assume from now on that λ
μ = 6.
3. Find the stationary probabilities and the probability of rejection.
Assuming that the probability of rejection is too large, we change the system, such that there are two
shop assistants A and B, and the service is changed, such that a customer at his arrival goes to A
and is served by him, if A is vacant at the arrival of the customer. If on the other hand A is busy,
then the customer will turn to B in order to be serviced. If also B is busy, the customer is rejected.
The assumptions of the arrivals and service times are the same as before. We want to compute in this
system:
4. The stationary probabilities and the probability of rejection.
5. The probability that A and B, res., are busy.
6. Finally, ﬁnd the smallest number of shop assistants, for which the probability of rejection is smaller
than 1
2.
1) Since N = 1, the diﬀerential equations of the system are
⎧
⎨
⎩
P ′
0(t) = −λP0(t) + μP1(t),
P ′
1(t) = λP0(t) −μP1(t),
thus written in the form of a matrix equation,
d
dt
 P0(t)
P1(t)

=
 −λ
μ
λ
−μ
  P0(t)
P1(t)

.
2) The characteristic polynomial (in R) is
!!!!
−λ −R
μ
λ
−μ −R
!!!! = (R + λ)(R + μ) −λμ = R2 + (λ + μ)R.
The roots are R = 0 and R = −λ −μ.
For R = 0 we get the eigenvector (μ, λ).
Download free eBooks at bookboon.com

Stochastic Processes 2
 
59 
4. Queueing theory
For R = −λ −μ we get the eigenvector (1, −1).
The complete solution is

P0(t)
P1(t)

= c1
 μ
λ

+ c2e−(λ+μ)t

1
−1

.
The initial conditions are P0(0) = 1 and P1(0) = 0, thus
⎧
⎨
⎩
1 = μc1 + c2,
0 = λc1 −c2,
and hence
c1 =
1
λ + μ,
c2 =
λ
λ + μ,
and the solution becomes
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
P0(t) =
μ
λ + μ +
λ
λ + μ e−(λ+μ)t,
P1(t) =
λ
λ + μ −
λ
λ + μ e−(λ+μ)t.
3) If λ
μ = 6, then
λ
λ + μ =
λ
μ
λ
μ + 1 = 6
7
and
μ
λ + μ = 1
7,
and λ + μ = 7μ, thus
⎧
⎪
⎪
⎨
⎪
⎪
⎩
P0(t) = 1
7 + 6
7 exp(−7μt),
P1(t) = 6
7 −6
7 exp(−7μt),
t ≥0.
The stationary probabilities are obtained by letting t →∞, thus
p0 = 1
7
and
p1 = 6
7.
In particular, the probability of rejection is p1 = 6
7.
4) We have the following states:
E0: No customer in the system.
E1: A serves a customer, while B does not.
E2: A is vacant, while B serves a customer.
E3: Both A and B serve customers.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
60 
4. Queueing theory
There is no change for A, so by 3.,
⎧
⎪
⎪
⎨
⎪
⎪
⎩
P0(t) + P2(t) = 1
7 + 6
7 exp(−7μt),
P1(t) + P3(t) = 6
7 −6
7 exp(−7μt),
t ≥0.
By taking the limit t →∞we get
p0 + p2 = 1
7
and
p1 + p3 = 6
7.
We can realize P0(t + h) in the following ways, if the system at time t is in state
(i) E0, and no customer arrives,
P0(t) · {1 −λh + hε(h)}.
(ii) E0, some customer arrive, and they are served until they are ﬁnished,
hε(h).
(iii) E1, and there is no customer coming, and A’s customer is serviced to the end,
P1(t) · {μh + hε(h)}.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Stochastic Processes 2
 
61 
4. Queueing theory
(iv) E1, and there arrive customers, who are served,
hε(h).
(v) E2, and no new customer is coming, and B’s customer is served to the end,
P2(t) · {μh + hε(h)}.
(vi) E2 in all other cases,
hε(h).
(vii) E3 in general,
hε(h).
By adding these we get
P0(t + h) = P0(t) · {1 −λh + hε(h)} + {P1(t) + P2(t)} · {μh + hε(h)} + hε(h).
Then compute the derivative in the usual way by taking the limit. This gives
P ′
0(t) = lim
h→0 {P0(t + h) −P0(t)} = −λP0(t) + μ {P1(t) + P2(t)} .
Then by taking the limit t →∞,
0 = −λp0 + μ {p1 + p2} = −6μp0 + μ {p1 + p2} ,
hence
6p0 = p1 + p2.
We are still missing one equation, when we want to ﬁnd the stationary probabilities. We choose
to realize P3(t + h). This can be done, if the system at time t is in state
(i) E0, and at least two customers arrive,
hε(h).
(ii) E1, and at least one customer arrives, and neither A nor B ﬁnish their customers,
P1(t) · {λh + hε(h)} · {1 −μh + hε(h)}2.
(iii) E2, and at least one customer arrives, and neither A nor B ﬁnish their customers,
P2(t) · {λh + hε(h)} · {1 −μh + hε(h)}2.
(iv) E3, and neither A nor B ﬁnish their customers,
P3(t) · {1 −μh + hε(h)}2.
(v) Other, all of probability
hε(h).
Download free eBooks at bookboon.com

Stochastic Processes 2
 
62 
4. Queueing theory
When we add these probabilities we get
P3(t + h)
=
{P1(t) + P2(t)} · {λh + hε(h)} · {1 −μh + hε(h)}2
+P3(t) · {1 −μh + hε(h)}2 + hε(h).
A rearrangement followed by a reduction gives
P3(t + h) −P3(t) = λh {P1(t) + P2(t)} −2μhP3(t) + hε(h).
Then divide by h and let h →0. This will give us the diﬀerential equation
P ′
3(t) = λ {P1(t) + P2(t)} −2μP3(t),
hence by taking the limit t →∞,
0 = λ (p1 + o2) −2μp3 = 6μ (p1 + p2) −2μp3,
so
p3 = 3 (p1 + p2) = 18p0.
Summing up we have obtained the four equations
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
p0 + p2
=
1
7,
p1 + p3
=
6
7,
6p0
=
p1 + p2,
p3
=
18p0,
thus
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
p0 + p2
=
1
7,
18p0 + p1
=
6
7,
6p0 −p1 −p2
=
0,
p3
=
18p0.
By addition of the former three equations, we get 25p0 = 1, thus p0 = 1
25. Then
p1 = 6
7 −18
25 =
6
175 (25 −21) = 24
175,
and
p2 = 1
7 −1
25 = 18
175,
and
p3 = 18
25,
so
(p0, p1, p2, p3) =
 1
25, 24
175, 18
175, 18
25

,
and the probability of rejection is
p3 = 18
25.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
63 
4. Queueing theory
5) The probability that A is busy is
p1 + p3 = 6
7.
The probability that B is busy is
p2 + p3 = 18
175 + 18
25 = 144
175

< 6
7

.
6) We have in the general case of N shop assistants, where Ej denotes that j customers are served,
the system of diﬀerential equations
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
P ′
0(t) = −λP0(t) + μP1(t),
P ′
k(t) = −(λ + kμ)Pk(t) + λPk−1(t) + (k + 1)μPk+1(t),
1 ≤k ≤N −1,
P ′
N(t) = −NμPN(t) + λPN−1(t).
Hence by taking the limit t →∞,
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
0 = −λp0 + μp1,
0 = −(λ + kμ)pk + λpk−1 + (k + 1)μpk+1,
1 ≤k ≤N −1,
0 = −NμpN + λpN−1.
Since λ
μ = 6, we get by a division by μ, followed by a rearrangement that
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
0 = 6p0 −p1,
6pk −(k + 1)pk+1 = 6pk−1 −kpk,
1 ≤k ≤N −1,
0 = 6pN−1 −NpN.
Then by recursion, 6pk−1 −k pk = 0, thus
kpk = 6pk−1,
1 ≤k ≤N.
The easiest way to solve this recursion formula is to multiply by
(k −1)!
6k
̸= 0,
and then do the recursion,
k!
6k pp = (k −1)!
6k−1
pk−1 = · · · = 0!
60 p0 = p0,
k = 0, 1, . . . , N,
thus
pk = 6k
k! p0,
k = 0, 1, . . . , N.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
64 
4. Queueing theory
Since p is a probability vector, we get the condition
1 =
N

k=0
pk = p0
N

k=0
6k
k! ,
thus
p0 =
1

N
k=0
6k
k!
.
The task is to ﬁnd N, such that the probability of rejection pN ≤1
2. Using
pN =
6N
N!

N−1
k=0
6k
k! + 6N
N!
≤1
2,
if
6N
N! ≤
N−1

k=0
6k
k! ,
we compute the following table,
k
0
1
2
3
4
6k
k!
1
6
18
36
54

k−1
j=0
6j
j!
⋆
1
7
25
61
It follows that N ≥4 gives pN ≤1
2, so we shall at least apply 4 service places.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
EXPERIENCE THE POWER OF 
FULL ENGAGEMENT…
     RUN FASTER.
          RUN LONGER..
                RUN EASIER…
READ MORE & PRE-ORDER TODAY 
WWW.GAITEYE.COM
Challenge the way we run

Stochastic Processes 2
 
65 
4. Queueing theory
Example 4.6 At a university there are two super computers A and B. Computer A is used for
university tasks, while computer B is restricted to external tasks. Both systems allow forming queues,
and the service times (i.e. the times used for computation of each task) is approximately exponentially
distributed of mean 1
μ = 3 minutes. The university tasks arrive to computer A approximately as a
Poisson process of intensity λA = 1
5 min−1, while the tasks of computer B arrive as a Poisson process
of intensity λB = 3
10 min−1. Apply the stationary probabilities for the two computers A and B to
compute
1. The fraction of time, A (resp. B) is vacant.
2. The average waiting time at A (resp. B).
It is suggested to join the two systems to one, such that each computer can be used to university tasks
as well external tasks. This means that we have a queueing system with two “shop assistants”. Use
again the stationary probabilities of this system to compute
3. The fraction of time both computers are vacant.
4. The fraction of time both computers are busy.
5. The average waiting time.
1) In both cases, N = 1.
For A we have the capacity
ϱA =
λA
NμA
= 3
5,
thus
p0,A = 1 −ϱA = 2
5.
For B we have the capacity
ϱB =
λB
NμB
= 9
10,
thus
p0,B = 1 −ϱB = 1
10.
These probabilities indicate the fraction of time, in which the given computer is vacant.
2) Since N = 1, the respective average waiting times are
VA =
ϱA
μ (1 −ϱA) = 3 ·
3
5
1 −3
5
= 9
2 minutes,
and
VB =
ϱB
μ (1 −ϱB) = 3 ·
9
10
1 −9
10
= 27 minutes.
3) The sum of two Poisson processes is again a Poisson process, here with the parameter
λ = λA + λB = 1
5 + 3
10 = 1
2.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
66 
4. Queueing theory
Hence the capacity
ϱ =
λ
Nμ = 1
2 · 1
2 · 3 = 3
4.
The fraction of time, in which none of the computers is busy, is
p0 = 1 −ϱ
1 + ϱ = 1 −3
4
1 + 3
4
= 1
7.
4) The probability that both computers are busy is
1 −p0 −p1 = 1 −1
7 −2ϱ 1 −ϱ
1 + ϱ = 1 −1
7 −2 · 3
4 · 1
7 = 14 −2 −3
14
= 9
14.
5) The average waiting time is
V =
p0ϱNN N−1
μ · N!(1 −ϱ)2 = 1
7
3
4
2
· 21 · 3 · 1
2! ·
1

1 −3
4
2 = 1
7 · 9
16 · 2 · 3
2 · 16 = 27
7 minutes.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
PDF components for PHP developers
www.setasign.com
SETASIGN
This e-book  
is made with 
SetaPDF

Stochastic Processes 2
 
67 
4. Queueing theory
Example 4.7 Given a birth and death process of the states E0, E1, E2, . . . , where the birth intensity
λk in state Ek decreases in increasing k as follows,
λk =
α
k + 1,
where α is a positive constant, while the death intensities μk are given by
μk =
⎧
⎨
⎩
μ,
k ∈N,
0,
k = 0,
where μ > 0.
1. Find the stationary probabilities.
The above may be viewed as a model of a queueing process, where
a. it is possible to form a queue,
b. there is only 1 channel,
c. the service time is exponentially distributed of mean 1
μ,
d. the arrival frequency decreases with increasing queue length according to the given formula. (Some
customers will avoid a long queue and immediately leave the queue ).
2. Compute for α = μ the probability that there are at most 3 customers in the system (3 dec.).
3. Compare the probability of 2. with the corresponding probability in the case of one shop assistant
and λk = α constant and μ = 3α (3 dec.).
1) The system of diﬀerential equations for λk =
α
k + 1 and μ > 0 is given by
⎧
⎪
⎪
⎨
⎪
⎪
⎩
P ′
0(t) = −αP0(t) + μP1(t),
P ′
k(t) = −

α
k + 1 + μ

Pk(t) + α
k Pk−1(t) + μ Pk+1(t),
k ∈N.
By taking the limit t →∞we get
⎧
⎪
⎪
⎨
⎪
⎪
⎩
0 = −αp0 + μp1,
0 = −

α
k + 1 + μ

pk + α
k pk−1 + μpk+1,
k ∈N,
thus
−
α
k + 1 pk + μpk+1 = −α
k pk−1 + μpk = · · · = 0,
k ∈N,
and hence
μpk = α
k pk−1,
k ∈N.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
68 
4. Queueing theory
When this equation is multiplied by
k! μk−1
αk
̸= 0,
it follows by a recursion that
k!
μ
α
 k
pk = (k −1)!
μ
α
 k−1
pk−1 = · · · = 0!
μ
α
 0
p0 = p0,
hence
pk = 1
k!
α
μ
k
p0,
k ∈N0.
It follows from
1 =
∞

k=0
pk = p0
∞

k=0
1
k!
α
μ
k
= p0 exp
α
μ

,
that
p0 = exp

−α
μ

,
thus
pk = 1
k!
α
μ
k
exp

−α
μ

,
k ∈N0.
2) Put α = μ. The probability that there are at most 3 customers in the system is
p0 + p1 + p2 + p3 = 1
e

1 + 1
1! + 1
2! + 1
3!

= 16
6e ≈0.9810.
3) The diﬀerential equations of the new system are
⎧
⎨
⎩
P ′
0(t) = −αP0(t) + 3αP1(t),
P ′
k(t) = −4αPk(t) + αPk−1(t) + 3αPk+1(t),
k ∈N.
By taking the limit t →∞we get the equations of the stationary probabilities,
⎧
⎨
⎩
0 = −αp0 + 3αp1,
0 = −4αpk + αpk−1 + 3αpk+1,
k ∈N.
We rewrite these and get by a reduction,
3pk+1 −pk = 3pk −pk−1 = · · · = 3p1 −p0 = 0,
k ∈N,
thus 3pk = pk−1. Multiply this equation by 3k−1 in order to get
3kpk = 3k−1pk−1 = · · · = 30p0 = 00,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
69 
4. Queueing theory
hence
pk = 1
3k p0,
k ∈N0.
It follows from
1 =
∞

k=0
pk = p0
∞

k=0
1
3
k
= p0 ·
1
3
1 −1
3
= 3
2 · p0,
that p0 = 2
3, and the probability that there are at most three customers in this system is
p0 + p1 + p2 + p3 = p0

1 + 1
3 + 1
32 + 1
33

= 2
3 · 27 + 9 + 3 + 1
27
= 80
81 ≈0.9877.
There is a slightly higher probability in this case that there are at most three customers in this
system than in the system which was considered in 2..
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.sylvania.com
We do not reinvent  
the wheel we reinvent 
light.
Fascinating lighting offers an infinite spectrum of 
possibilities: Innovative technologies and new  
markets provide both opportunities and challenges. 
An environment in which your expertise is in high 
demand. Enjoy the supportive working atmosphere 
within our global group and benefit from international 
career paths. Implement sustainable ideas in close 
cooperation with other specialists and contribute to 
influencing our future. Come and join us in reinventing 
light every day.
Light is OSRAM

Stochastic Processes 2
 
70 
4. Queueing theory
Example 4.8 Given the following queueing model: M machines are working mutually independently
of each other and they need no operation by men, except in the case when they break down. There are
in total N service mechanics (where N < M) for making repairs. If a machine is working at time t,
it is the probability λh + hε(h) that it breaks down before time t + h, and probability 1 −λh + hε(h)
that it is still working. Analogously, if it is repaired at time t, then there is the probability μh + hε(h)
that it is working again before t + h, and probability 1 −μh + hε(h) that it is not working. When a
machine breaks down, it is immediately repaired by a service mechanic, if he is vacant. Otherwise, the
machine is waiting in a queue, until a service mechanic becomes vacant. We deﬁne the coeﬃcient of
loss of a machine as
1
M · average number of machines in the queue,
and the coeﬃcient of loss of a service mechanic as
1
N · average number of vacant service mechanics.
Denote by Ek the state that k machines do not work, k = 0, 1, . . . , M.
1) Prove that the constants λk and μk are given by
λk = (M −k)λ,
μk = kμ,
0 ≤k ≤N,
λk = (M −k)λ,
μk = Nμ,
N ≤k ≤M.
2) Find a recursion formula for pk (express pk+1 by pk).
3) Find the average number of machines in the queue (expressed by the pk-erne), and prove in par-
ticular that if N = 1 this can be written
M −λ + μ
λ
(1 −p0) .
4) Find the probability that there are precisely 0, 1, 2, . . . , N vacant service mechanics.
5) Find the coeﬃcients of loss of a machine and a service mechanics in the case of
λ
μ = 0, 1;
M = 6;
N = 1.
It should be mentioned for comparison that in the case when
λ
μ = 0, 1;
M = 20;
N = 3,
the coeﬃcient of loss of a machine is 0.0169 and the coeﬃcient of loss of a service mechanics is
0.4042. Which one of the two systems is best?
This problem of machines was ﬁrst applied in the Swedish industry.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
71 
4. Queueing theory
1) Let 0 ≤k ≤M, and assume that we are in state Ek, thus k machines are being repaired or
are waiting for reparation, and M −k machines are working. The latter machines have each the
probability
λh + hε(h)
of breaking down in the time interval ]t, t + h] of length h. Since M −k machines are working, we
get
λk = (M −k)λ
for 0 ≤k ≤M.
If we are in state Ek, where 0 ≤k ≤N, then all k machines are being repaired. Each of these
have the probability
μh + hε(h)
for being repaired before time t + h, thus
μk = kμ,
for 0 ≤k ≤N.
If instead N < k ≤M, then all service mechanics are working, so
μk = Nμ,
for N < k ≤M.
2) By a known formula,
μk+1pk+1 = λkpk,
thus
pk+1 =
λk
μk+1
pn,
for n = 0, 1, . . . , M −1.
When we insert the results of 1., we get
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
pk+1 = (M −k)λ
(k + 1)μ pk
for k = 0, 1, . . . , N −1,
pk+1 = (M −k)λ
Nμ
pk
for k = N, . . . , M −1.
When the ﬁrst equation is multiplied by
1

M
k + 1

μ
λ
 k+1
,
we get
pk+1

M
k + 1
 λ
μ
k+1
=
(M −k)λ
(k + 1)μ ·

M
k


M
k + 1
 · 1
λ
μ
·
pk
 M
k

=
pk
 M
k
 λ
μ
k = · · · =
p0
 M
0
 λ
μ
0 = p0,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
72 
4. Queueing theory
hence
pk =

M
k
 λ
μ
k
p0
for k = 0, 1, . . . , N.
We put n = N + m, m = 0, 1, . . . , M −N −1, into the second equation. Then
pN+m+1
=
M −N −m
Mμ
· λ
μ pN+m =
1
N m+1
λ
μ
m+1
· (M −N −m) · · · (M −N)pN
=
1
N m+1
λ
μ
m+1
·
(M −N)!
(M −N −m −1)! pN,
hence
pN+m =
1
N m
λ
μ
m
·
(M −N)!
(M −N −m)! pN =
M!
N!(M −N −m)! ·
1
N m
λ
μ
N+m
p0,
for m = 0, 1, . . . , M −N.
3) The average number of machines in the queue is
M

k=N+1
(k −N)pk =
M

k=N
(k −N)pk.
We get in particular for N = 1,
M

k=1
(k −1)pk =
M

k=1
kpk −
M

k=1
pk =
M

k=1
kpk −(1 −p0) .
Then by the recursion formula of 2.,
pk+1 = (M −k) λ
μ pk = M λ
μ pk −λ
μ pk,
k = 1, . . . , M −1.
Hence
M

k=1
kpk
=
M−1

k=1
kpk + MpM = M
M−1

k=1
pk + MpM −μ
λ
M−1

k=1
pk+1 = M
M

k=0
pk −Mp0 −μ
λ
M

k=2
pk
=
M (1 −p0) −μ
λ (1 −p0 −p1) = M −μ
λ (1 −p0) −Mp0 + μ
λ p1.
It follows from
p1 = M −0
0 + 1 · λ
μ p0 = M · λ
μ p0,
by insertion that the average number of machines in the queue is for N = 1 given by
M

k=1
(k −1)pk
=
M

k=1
kpk −(1 −p0) = M −μ
λ m (1 −p0) −Mp0 + μ
λ · M · λ
μ p0 −(1 −p0)
=
M −
μ
λ + 1
 
(1 −p0) = M −λ + μ
λ
(1 −p0) .
Download free eBooks at bookboon.com

Stochastic Processes 2
 
73 
4. Queueing theory
4) If there are n ∈{1, 2, . . . , N} vacant service mechanics, the system is in state EN−n, so the
probability is
pN−n =

M
N −n
 λ
μ
N−n
p0,
n = 1, 2, . . . , N.
If there is no vacant service mechanic, we get the probability
1 −
N

n=1

M
N −n
 λ
μ
N−n
p0 = 1 −p0
N−1

n=0
 M
n
 λ
μ
n
.
5) If λ
μ = 1
10, M = 6 and N = 1, then the coeﬃcient of loss of the machine is by 3. given by
1
M ·

M −

1 + μ
λ
 
(1 −p0)

= 1 −1
6 (1 + 10) · (1 −p0) = 1 −11
6 (1 −p0) .
We shall only ﬁnd p0. We get by using the recursion formulae
p1 = 6
10 p0,
p2 = 5
10 p1,
p3 = 4
10 p2,
p4 = 3
10 p3,
p5 = 2
10 p4,
p6 = 1
10 p5,
hence
1
=
6

k=0
pk = p0

1 + 6
10

1 + 5
10

1 + 4
10

1 + 3
10

1 + 2
10

1 + 1
10

≈
p0 · 2.0639,
so
p0 ≈0.4845.
We also get by insertion the coeﬃcient of loss of the machine,
1 −11
6 (1 −p0) ≈0.05049.
The loss coeﬃcient of the service mechanic is
1
N · p0 = p0 ≈0.4845.
By comparison we see that the coeﬃcients of loss are smallest in the system, where
λ
μ = 1
10,
M = 20,
N = 3,
so this system is the best.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
74 
4. Queueing theory
Example 4.9 In a shop the service time is exponentially distributed of mean 1
μ, thus the frequency
is given by
f(x) =
⎧
⎨
⎩
μ e−μx,
x > 0,
0,
x ≤0.
Let X1, X2, . . . denote the service times of customer number 1, 2, . . . . We assume that the Xi are
mutually independent and that they all have the frequency f(x) above.
In total there arrive to the shop N customers, where N is a random variable, which is independent of
all the Xi, and N can have the values 1, 2, . . . , of the probabilities
P{N = k} = p qk−1,
k ∈N,
where p > 0, q > 0, and p + q = 1.
1) Prove that Yn = 
n
i=1 Xi has the frequency
fn(x) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
μ (μx)n−1
(n −1)! e−μx,
x > 0,
0,
x ≤0.
2) Find the frequency and the distribution function of Y = 
N
i=1 Xi by using that
P{Y ≤x} =
∞

k=1
P {N = k ∧Yk ≤x} .
3) Find mean and variance of Y .
1) Since Xi ∈Γ

1, 1
μ

, it follows that
Yn =
n

k=1
Xk ∈Γ

n, 1
μ

,
and the frequency is
fn(x) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
μ (μx)n−1
(n −1)! e−μx,
x > 0,
0,
x ≤0.
2) It follows immediately (without using generating functions),
P{Y ≤x} =
∞

k=1
P {N = k, Yk ≤x} =
∞

k=1
P{N = k} · P {Yk ≤x} =
∞

n=1
pqn−1
 x
0
fn(t) dt.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
75 
4. Queueing theory
Thus we get for x > 0 the frequency
g(x)
=
∞

n=1
p qn−1fn(x) = p
∞

n=1
qn−1 ·
μ
(n −1)! (μx)n−1e−μx = pμ
∞

n=0
(qμx)n
n!
e−μx
=
pμ e+qμx · e−μx = pμ · e−pμx,
so Y ∈Γ

1, 1
pμ

is exponentially distributed of frequency
g(x) =
⎧
⎨
⎩
pμ e−pμx
for x > 0,
0
for x ≤0,
and distribution function
G(x) =
⎧
⎨
⎩
1 −e−pμx
for x > 0,
0
for x ≤0.
3) Since Y ∈Γ

1, 1
pμ

, we have
E{X} = 1
pμ
og
V {X} =
1
p2μ2 .
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
360°
thinking.
© Deloitte & Touche LLP and affiliated entities.
Discover the truth at www.deloitte.ca/careers 

Stochastic Processes 2
 
76 
4. Queueing theory
Example 4.10 An old-fashioned shop with one shop assistant to serve the customers can be con-
sidered as a queuing system of one channel with the possibility of forming a queue. The customers
arrive according to a Poisson process of intensity λ, and the service time is exponentially distributed
of parameter μ. It has been noticed that when the system is in its equilibrium, then the shop assistant
is in mean busy 3
4 of the time, and the average staying time of customers is 10 minutes.
1. Prove that 1
λ = 1
18 hour and 1
μ = 1
24 hour.
2. Find the probability that a customer is served immediately.
3. Find the average queue length.
The shop is closed at 1730 and only the customers who are already in the shop are served by the shop
assistant, before he leaves for his home.
4. Find the probability that there at 1730 are 0, 1, 2, . . . customers in the shop.
5. Led the random variable T denote the time from 1730 until the shop assistant has served all cus-
tomers. Find the distribution of T.
It follows from λk = λ and μk = μ that
μpk+1 = λpk,
n ∈N0.
The traﬃc intensity is
ϱ =
λ
Nμ = λ
μ,
which we assume satisﬁes ϱ < 1, so p0 = 1 −ϱ. Thus
pk = λ
μ pk−1 = · · · =
λ
μ
k
p0 = ϱk · (1 −ϱ).
1) The staying time is
O =
1
μ −λ = 10 minutes = 1
6 hour,
and the shop assistant is busy
3
4 = 1 −p0 = ϱ = λ
μ.
Hence λ = 3
4 μ and 6 = μ −λ = 1
4 μ, thus μ = 24 and λ = 3
4 · 24 = 18, corresponding to
1
λ = 1
18 hour
and
1
μ = 1
24 hour.
2) A customer is immediately served if the system is in state E0. The probability of this event is
p0 = 1 −ϱ = 1 −3
4 = 1
4.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
77 
4. Queueing theory
3) The average queue length is
ϱ2
1 −ϱ =
9
16
1 −3
4
= 9
4.
4) The probability that there are n customers in the shop at 1730 (t ≈∞) is
pn = ϱn(1 −ϱ) = 1
4 ·
3
4
n
.
5) Assume that there are k customers in the shop.
Then the service time is Erlang distributed,
Γ

k, 1
μ

, of frequency
μ · (μx)k−1
(k −1)! e−μx,
x > 0,
k ∈N.
It follows that the distribution of T is given by
P{T = 0} = 1
4
and
F ′
T (x)
=
∞

k=1
1
4
3
4
k
μ · (μx)k−1
(k −1)! e−μx = 1
4 · 3
4 μ · e−μx
∞

k=1
3
4 μx
k−1
·
1
(k −1)!
=
3
16 μ e−μx exp
3
4 μx

= 3
16 μ · exp

−1
4 μx

.
Then by an integration,
P{T ≤x} =
⎧
⎪
⎨
⎪
⎩
1 −3
4 exp

−μ
4 x
 
,
x ≥0,
0,
x < 0.
When we insert μ = 24, found above, we get
P{T ≤x} =
⎧
⎪
⎨
⎪
⎩
1 −3
4 e−6x,
x ≥0,
0,
x < 0.
Alternatively, T has the Laplace transform
LT (λ) = P(L(λ)),
where
L(λ) =
μ
λ + μ
Download free eBooks at bookboon.com

Stochastic Processes 2
 
78 
4. Queueing theory
and
P(s) =
∞

k=0
pksk = 1
4
∞

k=0
3
4 s
k
= 1
4 ·
1
1 −3
4 s
=
1
4 −3s.
Hence by insertion,
LT (λ) =
1
4 −
3μ
λ + μ
= λ + μ
4λ + μ = 1
4 · 1 + 3
4 ·
1
4 μ
λ + 1
4 μ
.
We recognize this Laplace transform as corresponding to
FT (x) =
⎧
⎪
⎨
⎪
⎩
1 −3
4 exp

−μ
4 x
 
,
x ≥0,
0,
x < 0.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
We will turn your CV into 
an opportunity of a lifetime
Do you like cars? Would you like to be a part of a successful brand?
We will appreciate and reward both your enthusiasm and talent.
Send us your CV. You will be surprised where it can take you.
Send us your CV on
www.employerforlife.com

Stochastic Processes 2
 
79 
4. Queueing theory
Example 4.11 Given a service, where we assume:
a. There are two channels.
b. The customers arrive by a Poisson process of intensity 1 min−1.
c. The service time is at each of the two channels exponentially distributed of mean 1 minute.
d. It is possible to form a queue.
1. Compute the average waiting time.
2. Find the fraction of time, in which both channels are vacant, and the fraction of time, in which
both channels are busy.
The ﬂow of customers is then increased such that the customers now arrive according to a Poisson
process of intensity λ = 2 min−1 (the other assumptions are unchanged).
3. What is the impact of this change on the service?
The service is then augmented by another channel of the same type as the old ones.
4. Compute in this system for λ = 2 the average waiting time.
1) The process is described by a birth and death process with
λk1
and
μ1 = 1,
μk = 2 for k ≥N = 2, thus μ = 1.
The traﬃc intensity is
ϱ =
λ
Nμ = 1
2.
We have
p0 = 1 −ϱ
1 + ϱ = 1
3
og
pk = 2ϱk · 1 −ϱ
1 + ϱ = 1
3
1
2
k−1
for k ∈N.
The waiting time is given by
V = p0 · ϱN · N N−1
μ · N!(1 −ϱ)2 = 1
3 ·
1
2
2
·
1

1 −1
2
2 = 1
3.
2) Both channels are vacant in the fraction of time
p0 = 1
3.
Both channels are busy in the fraction of time
∞

k=2
pk = 1 −p0 −p1 = 1 −1
3 −1
3 = 1
3.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
80 
4. Queueing theory
3) The only change in the new system is λk = 2, thus
λk = 2
and
μ1 = 1,
μk = 2 for k ≥2,
and μ = 1.
The traﬃc intensity is
ϱ =
λ
Nμ =
2
2 · 1 = 1.
The queue will increase indeﬁnitely.
4) Then we shift to N = 3 with λ = 2 and μ = 1, so
λk = 2,
μ1 = 1,
μ2 = 2
and
μk = 3
for k ≥3.
The traﬃc intensity is
ϱ =
λ
Nμ =
2
3 · 1 = 2
3.
It follows from
pk =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
ϱk · 1
k! N kp0,
k < N,
ϱk · N N
N! p0,
k ≥N,
that
p1 = 2
3 · 1
1! · 3p0 = 2p0
and
p2 =
2
3
2
· 32
2! p0 = 2p0,
and
pk =
2
3
k
· 33
3! p0 = 2
2
3
k−1
p0
for k ≥3.
The sum is
1 =
∞

k=0
pk = p0

1 + 2 + 2 + 2
∞

k=3
2
3
k−2
= p0

3 + 2
∞

k=2
2
3
k−2
= 9p0,
from which p0 = 1
9. The waiting time is obtained by insertion,
V = p0ϱN · N N−1
μ · N!(1 −ϱ)2 = 1
9 ·
2
3
3
· 32
1 · 3!

1 −2
3
2 =
2
3
3
3 · 2
1
3
2 =
2
3
2
= 4
9.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
81 
4. Queueing theory
Example 4.12 Given a service for which
a. There are three channels.
b. The customers arrive according to a Poisson process of intensity 1 min−1.
c. The service time for each channel is exponentially distributed of mean 1 minute.
d. It is possible to form a queue.
1. Prove that the stationary probabilities are given by
pk =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
4
11 · 1
k!,
k < 3,
2
33 ·
1
3
k−3
,
k ≥3.
2. Find the fraction of time, in which all three channels are busy.
3. Compute the average length of the queue.
Decrease the number of channels to two while the other assumptions are unchanged. Compute in this
system,
4. the stationary probabilities,
5. the fraction of time, in which both channels are busy,
6. the average length of the queue.
Finally, decrease the number of channels to one, while the other assumptions are unchanged.
7. How will this system function?
1) The traﬃc intensity is
ϱ =
λ
Nμ =
1
3 · 1 = 1
3.
It follows from
pk =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
ϱk · 1
k! N kp0,
k < N,
1
N! ϱkN Np0,
k ≥N,
that
pk =
1
3
k
· 1
k! 3k · p0 = 1
k! p0
for k = 0, 1, 2, 3,
and
pk =
1
3
k
· 33
3! p0 = 1
6
1
3
k−3
p0
for k ≥3,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
82 
4. Queueing theory
hence
1 =
∞

k=0
pk = p0

1 + 1 + 1
2 + 1
6
∞

k=3
1
3
k−3
= p0
⎧
⎪
⎨
⎪
⎩
5
2 + 1
6 ·
1
1 −1
3
⎫
⎪
⎬
⎪
⎭
= p0
5
2 + 1
4

= 11
4 p0,
from which p0 = 4
11, thus
pk =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
4
11 · 1
k!,
k = 0, 1, 2,
2
33
1
3
k−3
,
k ≥3.
2) The fraction of time, in which all three channels are busy, is given by
∞

k=3
pk = 2
33
∞

k=3
1
3
k−3
= 2
33 ·
1
1 −1
3
= 2
33 · 3
2 = 1
11.
Alternatively, it is given by
1 −p0 −p1 −p2 = 1 −4
11 −4
11
1
1! −4
11
1
2! = 1
11.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
AXA Global 
Graduate Program
Find out more and apply

Stochastic Processes 2
 
83 
4. Queueing theory
3) The average length of the queue is
∞

k=4
(k −3)pk
=
∞

k=4
(k −3) · 2
33
1
3
k−3
= 2
33
∞

k=1
k
1
3
k
=
2
33 · 1
3 ·
1

1 −1
3
2 = 2
33 · 1
3 · 9
4 = 1
22.
4) If N = 2, then ϱ = 1
2. The stationary probabilities are
pk =
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
1 −1
2
1 + 1
3
= 1
3,
k = 0,
2
1
2
k
· 1 −1
2
1 + 1
2
= 1
3 ·
1
2k−1 ,
k ∈N.
5) The fraction of times, in which both channels are busy, is
1 −p0 −p1 = 1 −1
3 −1
3 = 1
3.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
84 
4. Queueing theory
6) The average length of the queue is
∞

k=3
(k −2)pk =
∞

k=3
(k −2) · 2
3 · 1
2k = 2
3 ·
1
2
3 ∞

k=1
k
1
2
k−1
= 1
12 ·
1

1 −1
2
2 = 1
3.
7) If there is only one channel, the traﬃc intensity becomes ϱ = 1, and the queue is increasing
indeﬁnitely.
Example 4.13 A shop serves M customers, and there is one shop assistant in the shop. It is possible
to form a queue. We assume that the service time is exponentially distributed of mean 1
μ. Assume
also that if a customer is not in the shop at time t, then there is the probability λh + hε(h) [where λ
is a positive constant] that this customer arrives to the shop before the time t + h. Finally, assume
that the customers arrive to the shop mutually independent of each other. Thus we have a birth and
death process {X(t), t ∈[0, ∞[} of the states E0, E1, . . . , EM, where Ek denotes the state that there
are k customers in the shop, k = 0, 1, 2, . . . , M.
1) Prove that the birth intensities λk and death intensities μk, k = 0, 1, 2, . . . , M, are given by
λk = (M −k)λ,
μk =
⎧
⎨
⎩
0,
k = 0,
μ,
k = 1, 2, . . . , M.
2) Find the equations of the stationary probabilities pk, k = 0, 1, 2, . . . , M.
3) Express the stationary probabilities pk, k = 0, 1, 2, . . . , M, by means of p0.
4) Compute the stationary probabilities pk, k = 0, 1, 2, . . . M.
5) Find, expressed by the stationary probability p0, the average number of customers, who are not in
the shop.
6) Compute the stationary probabilities, ﬁrst in the case, when λ
μ = 1 and M = 5, and then in the
case, when λ
μ = 1
2 and M = 5.
1) If we are in state Ek, then M −k of the customers are not in the shop. They arrive to the shop
before time t + h of probability
(M −k){λ + ε(h)}h,
(a time interval of length h, and we divide by h before we go to the limit h →0). Hence, the birth
intensity is
λk = (M −k)λ,
k = 0, 1, . . . , M.
If we are in state E0, then no customer is served, so μ0 = 0.
In any other state precisely one customer is served with the intensity μ, so
μk = μ,
k = 1, 2, . . . , M.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
85 
4. Queueing theory
2) The equations of the stationary probabilities are
μk+1pk+1 = λkpk.
Thus, in the explicit case,
pk+1 = (M −k) λ
μ pk.
3) We get successively
p0 = p0,
p1 = M · λ
μ p0,
p2 = M(M −1)
λ
μ
2
p0,
and in general
pk =
M!
(M −k)!
λ
μ
k
p0,
k = 0, 1, 2, . . . , M.
4) It follows from the equation
1 =
M

k=0
pk = M!
M

k=0
1
(M −k)!
λ
μ
k
p0 = p0 · M!
λ
μ
M
M

k=0
1
k!
μ
λ
 k
p0
that
p0 =
1
M! 
M
k=0
1
k!
λ
μ
M−k =
μ
λ
 M
M! 
M
k=0
1
k!
μ
λ
 k ,
and hence
p
=
μ
λ
 M
M! 
M
k=0
1
k!
μ
λ
 k

1, M λ
μ, M(M −1)
λ
μ
2
, · · · ,
M!
(M −k)!
λ
μ
k
, · · · , M!
λ
μ
M
=
1
M! 
M
k=0
1
k!
μ
λ
 k
⎛
⎜
⎝
μ
λ
 M
M!
,
μ
λ
 M−1
(M −1)! , · · · ,
μ
λ
 M−k
(M −k)! , · · · , 1
⎞
⎟
⎠.
5) The average number of customers who are not in the shop is by e.g. 3.,
M

k=0
(M −k)pk
=
M−1

k=0
M!
(M −k −1)!
λ
μ
k
p0 =
M

k=1
M!
(M −k)!
λ
μ
k−1
p0
=
μ
λ
M

k=1
pk = μ
λ (1 −p0) .
Download free eBooks at bookboon.com

Stochastic Processes 2
 
86 
4. Queueing theory
6) If λ
μ = 1 and M = 5, then
1 =
5

k=0
5!
(5 −k)! p0 = {1 + 5 + 20 + 60 + 120 + 120}p0 = 326p0,
and
p =
1
326 (1, 5, 20, 60, 120, 120).
7) N˚ar λ
μ = 1
2 og M = 5, er
1 =
5

k=0
5!
(5 −k)!
1
2
k
p0 =

1 + 5
2 + 5 + 15
2 + 15
2 + 15
4

p0 = 109
4 p0
and
p =
4
109

1, 5
2, 5, 15
2 , 15
2 , 15
4

=
1
109 (4, 10, 20, 30, 30, 15).
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
ibili
because 
e Graduate Programme  
for Engineers and Geoscientists
Month 16
I was a construction
supervisor in 
the North Sea 
advising and 
helping foremen 
solve problems
I was a
he
s
Real work 
International opportunities 

ree work placements
al 
Internationa
or

ree wo
I wanted real responsibili 
 I joined MITAS because 
www.discovermitas.com

Stochastic Processes 2
 
87 
4. Queueing theory
Example 4.14 Given two queueing systems, A and B, which are mutually independent. We assume
for each of the two systems:
a. there is one channel,
b. it is possible to form a queue,
c. the customers arrive according to a Poisson process of intensity λ,
d. the service times are exponentially distributed of parameter μ,
e. the traﬃc intensity is ϱ = λ
μ = 1
2.
Denote by X1 the random variable which indicates the number of customers in system A, and by X2
the random variables which indicates the number of customers in system B.
1. Compute by using the stationary probabilities,
P {X1 = k}
and
P {X2 = k} ,
k ∈N0.
Let Z = X1 + X2 denote the total number of customers in the two systems.
2. Compute P{Z = k}, k ∈N0.
3. Compute the mean of Z
Consider another queuing system C, in which we assume,
a. there are two channels,
b. it is possible to form a queue,
c. the customers arrive according to a Poisson process of intensity 2λ,
d. the service times are exponentially distributed of the parameter μ,
e. the traﬃc intensity is ϱ = 2λ
2μ = 1
2.
Let the random variable Y denote the number of customers in system C.
4. Compute by using the stationary probabilities,
P{Y = k}
and
P{Y > k},
k ∈N0.
5. Compute the mean of Y .
6. Prove for all k ∈N0 that
P{Z > k} > P{Y > k}.
Hint to 6.: One may without proof use the formula,
∞

i=N
i xi−1 = xN−1{N −(N −1)x}
(1 −x)2
,
|x| < 1,
N ∈N.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
88 
4. Queueing theory
1) The two queueing systems follow the same distribution, and N = 1 and ϱ = 1
2, so we get by a
known formula,
P {X1 = k} = P {X2 = k} = pk = ϱk · (1 −ϱ) =
1
2
k+1
,
k ∈N0.
2) A straightforward computation gives
P{Z = k}
=
k

j=0
P {X1 = j} · P {X2 = k −j} =
k

j=0
1
2
j+1
·
1
2
k−j+1
=
(k + 1) ·
1
2
k+2
,
k ∈N0.
3) It follows from
E {X1} = E {X2} =
∞

k=1
k
1
2
k+1
= 1
4
∞

k=1
k ·
1
2
k−1
= 1
4 ·
1

1 −1
2
2 = 1,
that
E{Z}
=
∞

k=1
k(k + 1)
1
2
k+2
=
∞

k=2
k(k −1)
1
2
k+1
= 1
8
∞

k=2
k(k −1)
1
2
k−2
=
1
8 ·
2!

1 −1
2
3 = 2.
4) Roughly speaking, A and B are joined to get C, so we have N = 2 and ϱ = 1
2. Then it follows that
P{Y = 0} = p0 = 1 −ϱ
1 + ϱ = 1
3,
and
P{Y = k} = 2ϱk · 1 −ϱ
1 + ϱ = 1
3
1
2
k−1
,
k ∈N.
Thus
P{Y > k} =
∞

j=k+1
1
3
1
2
j−1
= 1
3 ·
1
2
k
·
1
1 −1
2
= 1
3 ·
1
2
k−1
,
k ∈N0.
5) The mean is
E{Y } =
∞

k=1
1
3 k
1
2
k−1
= 1
3 ·
1

1 −1
2
2 = 4
3.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
89 
4. Queueing theory
6) It follows from 2. that
P{Z > k}
=
∞

j=k+1
(j + 1)
1
2
j+2
= 1
4
∞

j=k+2
j
1
2
j−1
=
1
4 ·
 1
2
k+1 
k + 2 −(k + 1) 1
2


1 −1
2
2
=
1
2
k+2
· {2k + 4 −k −1}
=
k + 3
8
·
1
2
k−1
> 1
3 ·
1
2
k−1
= P{Y > k}.
We notice that P{Y = k} = P{Y > k} for k ∈N, and that this is not true for k = 0.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
MASTER IN MANAGEMENT
mim.admissions@ie.edu
Follow us on IE MIM Experience
www.ie.edu/master-management
#10 WORLDWIDE
MASTER IN MANAGEMENT 
FINANCIAL TIMES
55 Nationalities
in class
5 Specializations
Personalize your program 
Length: 1O MONTHS
Av. Experience: 1 YEAR
Language: ENGLISH / SPANISH
Format: FULL-TIME
Intakes: SEPT / FEB
• STUDY IN THE CENTER OF MADRID AND TAKE ADVANTAGE OF THE UNIQUE OPPORTUNITIES
  THAT THE CAPITAL OF SPAIN OFFERS
• PROPEL YOUR EDUCATION BY EARNING A DOUBLE DEGREE THAT BEST SUITS YOUR
  PROFESSIONAL GOALS
• STUDY A SEMESTER ABROAD AND BECOME A GLOBAL CITIZEN WITH THE BEYOND BORDERS
  EXPERIENCE
93%
OF MIM STUDENTS ARE
WORKING IN THEIR SECTOR 3 MONTHS
FOLLOWING GRADUATION

Stochastic Processes 2
 
90 
4. Queueing theory
Example 4.15 Given two mutually independent queueing systems A and B. We assume for each of
the two systems,
a. there is one channel,
b. it is possible to form a queue,
c. customers arrive to A according to a Poisson process of intensity λA = 1
3 minute−1, and they
arrive to B according to a Poisson process of intensity λB = 2
3 minute−1,
d. the service times of both A and B are exponentially distributed of the parameter μ = 1 minute−1.
Let the random variable XA denote the number of customers in system A, and let the random variable
XB denote the number of customers in system B. Furthermore, we let YA and YB, resp., denote the
number of customers in the queue at A and B, resp..
1. Find by using the stationary probabilities,
P {XA = k}
and
P {XB = k} ,
k ∈N0.
2. Find the average waiting times at A and B, resp..
3. Find by using the stationary probabilities,
P {YA = k}
and
P {YB = k} ,
k ∈N0.
4. Find the means E {XA + XB} and E {YA + YB}.
5. Compute P {XA + XB = k}, k ∈N0.
The two queueing systems are now joined to one queueing system of two channels, where the customers
arrive according to a Poisson process of intensity λ = λA + λB, and where the serving times are
exponentially distributed of parameter μ = 1 minute−1. Let X denote the number of customers in the
system, and let Y denote the number of customers in the queue.
6. Find by using the stationary probabilities,
P{X = k}
and
P{Y = k},
k ∈N0.
7. Find the means E{X} and E{Y }.
1A. Since λA = 1
3 minute−1 and μ = 1 minute−1, and N = 1, we get the traﬃc intensity ϱA = 1
3.
The stationary probabilities are
P {XA = k} = pA,k = 2 ·
1
3
k+1
,
k ∈N0.
1B. Analogously, λB = 2
3 minute−1 and μ = 1 minute−1, and N = 1, so ϱB = 2
3, and
P {XB = k} = pB,k = 1
3
2
3
k
= 1
2
2
3
k+1
,
k ∈N0.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
91 
4. Queueing theory
2A. The waiting time at A is given by
VA =
ϱA
μ (1 −ϱA) =
1
3
1 · 2
3
= 1
2.
2B. Analogously, the waiting time at B is
VB =
ϱB
μ (1 −ϱB) =
2
3
1 · 1
3
= 2.
3A. Assume that there is no queue at A. Then either there is no customer at all in the system, or
there is precisely one customer, who is served for the time being,
P {YA = 0} = P {XA = 0} + P {XA = 1} = 2 ·
1
3 + 1
9

= 8
9.
If k ∈N, then
P {YA = k} = P {XA = k + 1} = 2 ·
1
3
k+2
.
3B. Analogously,
P {YB = 0} = P {XB = 0} + P {XB = 1} = 1
3

1 + 2
3

= 5
9
and
P {YB = k} = P {XB = k + 1} = 1
2
2
3
k+2
,
k ∈N0.
4. It follows from
E {XA} = 2
∞

k=1
k
1
3
k+1
= 2
9
∞

k=1
k
1
3
k−1
= 2
9 ·
1

1 −1
3
2 = 1
2
and
E {XB} = 2
9
∞

k=1
k
2
3
k−1
= 2
9 ·
1

1 −2
3
2 = 2,
that
E {XA + XB} = 1
2 + 2 = 5
2.
It follows from
E {YA} = 2
∞

k=1
k
1
3
k+2
= 2
27
∞

k=1
k
1
3
k−1
= 2
27 ·
1

1 −1
3
2 = 1
6
Download free eBooks at bookboon.com

Stochastic Processes 2
 
92 
4. Queueing theory
and
E {YB} = 1
2
∞

k=1
k
2
3
k+2
= 4
27
∞

k=1
k
2
3
k−1
= 4
27 ·
1

1 −2
3
2 = 4
3,
then
E {YA + YB} = 1
6 + 4
3 = 3
2.
5. If k ∈N0, then
P {XA + XB = k}
=
k

j=0
P {XA = j} · P {XB = k −j}
=
k

j=0
2 ·
1
3
j+1
· 1
2 ·
2
3
k−j+1
=
k

j=0
1
3
k+2
· 2k−j+1
=
1
3
k+2 k+1

n=1
2n =

2k+2 −2

·
1
3
k+2
=
2
3
k+2
−2
1
3
k+2
=
2
3k+2

2k+1 −1

.
6. The traﬃc intensity is
ϱ = λA + λB
Nμ
=
1
3 + 2
3
2 · 1 = λ
2μ = 1
2.
It follows that
P{X = k} = pk =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
1
3,
k = 0,
2
3
1
2
k
,
k ∈N.
Since Y = (X −2) ∨0, we get
P{Y = 0} = P{X = 0} + P{X = 1} + P{X = 2} = 1
3 + 1
3 + 1
6 = 5
6
and
P{Y = k} = P{X = k + 2} = 2
3
1
2
k+2
= 1
6
2
3
k
,
k ∈N.
7. By a straightforward computation,
E{X} = 2
3
∞

k=1
k
1
2
k
= 1
3
∞

k=1
k
1
2
k−1
= 1
3 ·
1

1 −1
2
2 = 4
3
Download free eBooks at bookboon.com

Stochastic Processes 2
 
93 
4. Queueing theory
and
E{Y } = 1
6
∞

k=1
k
1
2
k
= 1
4 E{X} = 1
3.
Example 4.16 Consider a birth and death process E0, E1, E2, . . . , where the birth intensities λk
are given by
λk =
α
k + 1,
k ∈N0,
where α is a positive constant, while the death intensities μk are given by
μk =
⎧
⎨
⎩
0,
k = 0,
μ,
k = 1,
2μ,
k ≥2,
where μ > 0. We assume that α
μ = 8.
1. Find the equations of the stationary probabilities pk, k ∈N0.
2. Prove that
pk = 2 · 4k · 1
k! p0,
k ∈N,
and ﬁnd p0.
The above can be viewed as a model of the forming of a queue in a shop, where
a. there are two shop assistants,
b. the service time is exponentially distributed of mean 1
μ,
c. the frequency of the arrivals is decreasing with increasing number of customers according to the
indicated formula.
3. Compute by means of the stationary probabilities the average number of customers in the shop. (3
dec.).
4. Compute by means of the stationary probabilities the average number of busy shop assistants. (3
dec.).
5. Compute by means of the stationary probabilities the probability that there are more than two
customers in the shop. (3 dec.).
1) We have
μk+1pk+1 = λkpk,
k ∈N0,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
94 
4. Queueing theory
thus
p1 = λ0
μ1
p0 = α
μ p0 = 8p0
and
pk = λk−1
μk
pk−1 = α
k · 1
2μ pk−1 = 4
k pk−1
for k ≥2.
2) If k = 1, then
p1 = 8p0 = 2 · 41
1! p0,
and the formula is true for k = 1. Then assume that
pk−1 = 2 · 4k−1 ·
1
(k −1)! p0.
Then
pk = 4
k pk−1 = 2 · 4k
k! p0,
and the formula follows by induction.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Stochastic Processes 2
 
95 
4. Queueing theory
It follows from
1 =
∞

k=0
pk = p0

1 + 2
∞

k=1
4k
k!

= p0

2e4 −1

that
p0 =
1
2e4 −1.
3) The task is now changed to queueing theory. Since pk is the probability that there are k customers
in the shop, the mean of the number of customers in the shop is
∞

k=1
kpk = 2 · 4 · p0
∞

k=1
4k−1
(k −1)! =
8e4
2e4 −1 ≈4.037.
4) The average number of busy shop assistants is
0 · p0 + 1 · p1 + 2
∞

k=2
pk = p1 + 1 (1 −p0 −p1)
=
2 −2p0 −p1 = 2 −2p0 −8p0
=
2 −10p0 = 2 −
10
2e4 −1 = 1.908.
5) The probability that there are more than two customers in the shop is
∞

k=3
pk = 1 −p0 −p1 −p2 = 1 −p0

1 + 8 + 32
2

= 1 −
25
2e4 −1 ≈0.769.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
96 
4. Queueing theory
Example 4.17 Consider a birth and death process of the states E0, E1, E2, . . . , where the birth
intensities λk are given by
λk =
 2λ,
k = 0,
λ,
k ∈N,
while the death intensities μk are given by
μk =

0,
k = 0,
μ,
k ∈N.
Here, λ and μ are positive constants, and we assume everywhere that λ
μ = 3
4.
1. Find the equations of the stationary probabilities, and prove that the stationary probabilities are
given by
pk = 2 ·
3
4
k
p0,
k = 1, 2, 3, . . . ,
and ﬁnally, ﬁnd p0.
The above can be considered as a model of forming queues in a shop, where
a. there is one shop assistant,
b. the service time is exponentially distributed of mean 1
μ,
c. the customers arrive according to a Poisson process of intensity 2λ. However, if there already are
customers in the shop, then half of the arriving customers will immediately leave the shop without
being served.
2. Compute by means of the stationary probabilities the average number of customers in the shop.
3. Compute by means of the stationary probabilities the average number of customers in the queue.
We now assume that instead of one shop assistant there are two shop assistants and that all arriving
customers are served (thus we have the birth intensities λk = 2λ, k ∈N0).
4. Compute in this queueing system the stationary probabilities and then ﬁnd the average number of
customers in the queue.
1) The equations of the stationary probabilities are
μk+1pk+1 = λkpk,
k ∈N0,
thus
p1 = 2λ
μ p0 = 3
2 p0 = 2 ·
3
4
1
p0,
and
pk = λ
μ pk−1 = 3
4 pk−1,
k ≥2,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
97 
4. Queueing theory
hence by recursion,
pk =
3
4
k−1
p1 = 2 ·
3
4
k
p0,
k ≥2.
We get
1 =
∞

k=0
pk = p0 + p0
∞

k=1
2 ·
3
4
k
= p0
⎧
⎪
⎨
⎪
⎩
1 + 2 · 3
4 ·
1
1 −3
4
⎫
⎪
⎬
⎪
⎭
= p0

1 + 3
2 · 4

= 7p0,
so
p0 = 1
7
and
pk = 2
7 ·
3
4
k
,
k ∈N.
2) Since pk is the probability that there are k customers in the shop, the average number of customer
in the shop is
∞

k=1
kpk = 2
7 · 3
4
∞

k=1
k ·
3
4
k−1
= 3
14 ·
1

1 −3
4
2 = 3
14 · 16 = 24
7 .
3) If there are k customers in the queue, there must also be 1 customer, who is being served, so the
average is
∞

k=1
kpk+1 = 2
7 · 3
4 · 3
4
∞

k=1
k
3
4
k−1
= 3
28 · 24 = 18
7 ,
where we have used the result of 2.
4) The traﬃc intensity is ϱ = 2λ
2 · μ = 3
4, and since N = 2, we get
p0 = 1 −ϱ
1 + ϱ = 1
7
and
pk = 2
7
3
4
k
,
k ∈N.
We see that they are identical with the stationary probabilities found in 1..
The average length of the queue is given by (end here we get to the divergence from the previous
case)
∞

k=3
(k −2)pk
=
2
7
∞

k=3
(k −2)
3
4
k
= 2
7
∞

k=1
k
3
4
k+2
= 2
7 ·
3
4
3 ∞

k=1
k
3
4
k−1
=
2
7 ·
3
4
3
·
1

1 −3
4
2 = 2
7 · 27
4 = 27
14.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
98 
4. Queueing theory
Example 4.18 Consider a birth and death process of states E0, E1, E2, . . . , and with birth intensities
λk given by
λk =
⎧
⎪
⎨
⎪
⎩
α,
k = 0, 1,
α
k ,
k ≥2,
where α is a positive constant, and where the death intensities are given by
μk =
 0,
k = 0,
μ,
k ∈N,
where μ > 0.
We assume in the following that α
μ = 2.
1. Find the equations of the stationary probabilities pk, k ∈N0.
2. Prove that
pk =
2k
(k −1)! p0,
k ∈N,
and ﬁnd p0.
The above can be considered as a model of forming a queue in a shop where
a. there is one shop assistant,
b. the serving time is exponentially distribution of mean 1
μ,
c. the frequency of arrivals decreasis with increasing number of customers according to the formula
for λk above.
3. Compute by means of the stationary probabilities the average length of the queue (3 dec.).
4. Compute by means of the stationary probabilities the average number of customers in the shop (3
dec.).
1) We have
μk+1pk+1 = λkpk,
k ∈N0,
and
∞

k=0
pk = 1.
Hence, successively,
μp1 = αp0,
μp2 = αp1,
and
μpk =
α
k −1 pk−1
for k ≥3.
It follows from α
μ = 2 that
(6) p1 = 2p0,
p2 = 2p1,
pk =
2
k −1pk−1,
k ≥3,
and
∞

k=0
pk = 1.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
99 
4. Queueing theory
2) We infer from (6) that p1 = 2p0 and p2 = 2p2 = 4p0, and for k ≥3,
pk =
2
k −1 pk−1 =
22
(k −1)(k −2) pk−2 = · · · =
2k−2
(k −1)! p2 =
22
(k −1)! p0.
A check shows that the latter formula is also true for k = 1 and k = 2, thus
pk =
2k
(k −1)! p0,
k ∈N.
Then we ﬁnd p0 from
1 =
∞

k=0
pk = p0

1 +
∞

k=1
2k
(k −1)!

= p0

1 + 2
∞

k=1
2k−1
(k −1)!

= p0

1 + 2e2
,
thus
p0 =
1
1 + 2e2
(≈0.0634),
and
pk =
2k
(k −1)! ·
1
1 + 2e2 ,
k ∈N.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
“The perfect start 
of a successful, 
international career.”
CLICK HERE 
to discover why both socially 
and academically the University 
of Groningen is one of the best 
places for a student to be 
www.rug.nl/feb/education
Excellent Economics and Business programmes at:

Stochastic Processes 2
 
100 
4. Queueing theory
3) The average length of the queue is (notice that since 1 customer is served, we have here k −1
instead of k),
∞

k=2
(k −1)pk =
∞

k=2
k −1
(k −1)! 2k p0 = 4
∞

k=2
2k−2
(k −2)! p0 = 4e2p0 =
4e2
1 + 2e2 ≈1.873.
4) The average number of customers is
∞

k=1
kpk
=
∞

k=1 (2)
(k −1)pk +
∞

k=1
pk = 4e2p0 + (1 −p0)
=
4e2
1 + 2e2 +
2e2
1 + 2e2 =
6e2
1 + 2e2 ≈2.810.
Example 4.19 Given a queueing system, for which
a. there is one shop assistant,
b. it is possible to form a queue,
c. the customers arrive according to a Poisson process of intensity λ,
d. the serving times are exponentially distributed of parameter μ,
e. the traﬃc intensity λ
μ is 2
3.
Let the random variable X denote the number of customers in the system, and let Y denote the number
of customers in the queue.
1. Find by means of the stationary probabilities,
P{X = k}
and
P{Y = k},
k ∈N0.
2. Find the means E{X} and E{Y }.
The system is changed by introducing another shop assistant, whenever there are 3 or more customers
in the shop; this extra shop assistant is withdrawn after ending his service, if the number of customers
then is smaller than 3. The other assumptions are unchanged.
3. Explain why this new system can be described by a birth and death process of states E0, E1, E2,
. . . , birth intensities λk = λ, k ∈N0, and death intensities μk given by
μk =
⎧
⎨
⎩
0,
k = 0,
μ,
k = 1, 2,
2μ,
k = 3, 4, . . . .
4. Find the stationary probabilities pk of this system.
5. Find the average number of customers in the system,
∞

k=1
kpk.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
101 
4. Queueing theory
1) Since N = 1, it follows that
pk = 1
3
2
3
k
,
k ∈N0,
thus
P{X = k} = pk = 1
3
2
3
k
,
k ∈N0,
and
P{Y = 0}
=
P{X = 0} + P{X = 1} = 1
3

1 + 2
3

= 5
9,
P{Y = k}
=
P{X = k + 1} = 1
3
2
3
k+1
,
k ∈N.
2) The means are
E{X} =
∞

k=1
kpk = 1
3 · 2
3
∞

k=1
k ·
2
3
k−1
= 2,
and
E{Y } =
∞

k=1
1
3

k 2
3
k+1
= 2
3 E{X} = 4
3.
3) The birth intensities λk = λ, k ∈N0, are clearly not changed, and μ0 = 0, μ1 = μ2 = μ. When
k ≥3, another shop assistant is also serving the customers, so μk = 2μ for k ≥3.
4) We have
μk+1pk+1 = λkpk.
Thus we get the equations
p1 = λ
μ p0 = 2
3 p0,
p2 = λ
μ p1 = 2
3 p1,
and
pk+1 = λ
2μ pk = 1
3 pk,
k ≥2.
Hence
p1 = 2
3 p0,
p2 = 4
9 p0,
and
pk =
1
3
k−2
p2 = 3
1
3
k
p0
for k ≥3.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
102 
4. Queueing theory
It follows from
1
=
∞

k=0
p0 = p0

1 + 2
3 + 4
9 + 4
∞

k=3
1
3
k
= p0
⎧
⎨
⎩
5
3 + 4
9
∞

j=0
1
3
j
⎫
⎬
⎭= p0
⎧
⎪
⎨
⎪
⎩
5
3 + 4
9 ·
1
1 −1
3
⎫
⎪
⎬
⎪
⎭
=
p0
5
3 + 4
9 · 3
2

= p0
5
3 + 2
3

= 7
3 p0,
that
p0 = 3
7,
p1 = 2
7,
p2 = 4
21,
and
pk = 4
7 ·
1
3
k−1
,
k ≥3.
5) The average number of customers is
∞

k=1
kpk
=
2
7 + 8
21 + 4
7
∞

k=3
k ·
1
3
k−1
= 6 + 8
221 + 4
7
 ∞

k=1
k
1
3
k−1
−1 −2
3

=
2
3 + 4
7
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
1

1 −1
3
2 −5
3
⎫
⎪
⎪
⎪
⎬
⎪
⎪
⎪
⎭
= 2
3 + 4
7
9
4 −5
3

= 2
3 + 4
7 · 27 −20
4 · 3
= 2
3 + 1
3 = 1.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
American online      
LIGS University 
▶▶enroll by September 30th, 2014 and 
▶▶save up to 16% on the tuition!
▶▶pay in 10 installments / 2 years
▶▶Interactive Online education
▶▶visit www.ligsuniversity.com to 
      find out more!
is currently enrolling in the
Interactive Online BBA, MBA, MSc, 
DBA and PhD  programs:
Note: LIGS University is not accredited by any 
nationally recognized accrediting agency listed 
by the US Secretary of Education. 
More info here. 

Stochastic Processes 2
 
103 
4. Queueing theory
Example 4.20 Given a queueing for which
a. there is one channel,
b. there is the possibility of an (unlimited) queue,
c. the customers arrive according to a Poisson process of intensity λ,
d. the service times are exponentially distributed of parameter μ,
e. the traﬃc intensity λ
μ is 4
5.
Let the random variable X denote the number of customers in the system.
1. Find by using the stationary probabilities,
P{X = k}
and
P{X > k},
k ∈N0.
2. Find the mean E{X}.
We then change the system, such that there is only room for at most 3 waiting customers, thus only
room for 4 customers in total in the system (1 being served and 3 waiting). The other conditions are
unchanged. This system can be described by a birth and death process of the states E0, E1, E2, E3,
E4 and
birth intensities:
λk =
 λ,
k = 0, 1, 2, 3,
0,
k = 4,
death intensities:
μk =

0,
k = 0,
μ,
k = 1, 2, 3, 4.
Let the random variable Y denote the number of customers in this system.
3. Find by means of the stationary probabilities,
P{Y = k},
k = 0, 1, 2, 3, 4,
(3 dec.).
4. Find the means E{Y } (3 dec.).
Now the intensity of arrivals λ is doubled, while the other assumptions are the same as above. This will
imply that the probability of rejection becomes too big, so one decides to hire another shop assistant.
Then the system can be described by a birth and death process with states E0, E1, E2, E3, E4, E5,
(where E5 corresponds to 2 customers being served and 3 waiting).
5. Find the equations of this system of the stationary probabilities p0, p1, p2, p3, p4, p5.
6. ﬁnd the stationary probabilities (3 dec.).
1) We have
P{X = k} = pk = ϱk(1 −ϱ) = 1
5
4
5
k
,
k ∈N0,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
104 
4. Queueing theory
hence
P{X > k} =
∞

j=k+1
1
5
4
5
j
= 1
5 ·
4
5
k+1
1 −4
5
=
4
5
k+1
,
k ∈N0.
2) The mean is
E{X} = 1
5 · 4
5
∞

k=1
k
4
5
k−1
= 4
25 ·
1

1 −4
5
2 = 4.
3) It follows from
μk+1pk+1 = λkpk,
that
p1 = λ
μ p0 = 4
5 p0,
p2 =
4
5
2
p0,
p3 =
4
5
3
p0,
p4 =
4
5
4
p0,
hence
1 = p0

1 + 4
5 +
4
5
2
+
4
5
3
+
4
5
4
= p0 ·
1 −
4
5
5
1 −4
5
= p0

5 −4 ·
4
5
4
,
and
P{Y = 0}
=
p0
=
1
5 −4
 4
5
4
≈
0.297,
P{Y = 1}
=
p1
=
4
5 p0
≈
0.238,
P{Y = 2}
=
p2
=
4
5 p1
≈
0.190,
P{Y = 3}
=
p3
=
4
5 p2
≈
0.152,
P{Y = 4}
=
p4
=
4
5 p3
≈
0.122.
4) The mean is
E{Y } = 1 · p1 + 2p2 + 3p3 + 4p4 =

4
5 + 2
4
5
2
+ 3
4
5
3
+ 4
4
5
4
p0 ≈1.563.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
105 
4. Queueing theory
5) The birth intensities are
λk =
 2λ,
k = 0, 1, 2, 3, 4,
0,
k = 5,
and the death intensities are
μk =
⎧
⎨
⎩
0,
k = 0,
μ,
k = 1,
2μ,
k = 2, 3, 4, 5.
It follows from
μk+1pk+1 = λkpk,
that
p1 = 2λ
μ p0 = 8
5,
and
pk = 2λ
2μ pk−1 = 4
5 pk−1
for k = 2, 3, 4, 5.
6) Now
pk = 2
4
5
k
p0
for k = 1, 2, 3, 4, 5,
thus
1
=
p0

1 + 8
5

1 + 4
5 +
4
5
2
+
4
5
3
+
4
5
4
= p0
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
1 + 8
5 ·
1 −
4
5
5
1 −4
5
⎫
⎪
⎪
⎪
⎬
⎪
⎪
⎪
⎭
=
p0

9 −8
4
5
5
,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
106 
4. Queueing theory
and hence
p0
=
1
9 −8
4
5
5
≈
0, 157,
p1
=
2 · 4
5 p0
≈
0.251,
p2
=
4
5 p1
≈
0.201,
p3
=
4
5 p2
≈
0.161,
p4
=
4
5 p3
≈
0.128,
p5
=
4
5 p4
≈
0.103.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Stochastic Processes 2
 
107 
4. Queueing theory
Example 4.21 Given two queueing systems A and B, which are independent of each other.
We
assume for each of the systems,
a. there is one shop assistant,
b. It is possible to have a queue,
c. customers are arriving to A according a Poisson process of intensity λA = 3
4 minute−1, and to B
according to a Poisson process of intensity λB = 1
2 minute−1,
d. the service times at both A and B are exponentially distributed of parameter μ = 1 minute−1.
Let the random variable XA denote the number of customers in system A, and let XB denote the
number of customers in system B.
1. Find by means of the stationary probabilities,
P {XA = k}
and
P {XB = k} ,
k ∈N0.
2. Find the average waiting times at A and B, resp..
3. Compute the probabilities P {XB > k}, k ∈N0, and then ﬁnd
P {XA < XB} .
The arrivals of the customers at A is now increased, such that the customers arrive according to a
Poisson process of intensity 1 minute−1. For that reason the two systems are joined to one queueing
system with two shop assistants, thus the customers now arrive according to a Poisson process of
intensity
λ =

1 + 1
2

minute−1 = 3
2 minute−1,
and the service times are still exponentially distributed with the parameter
μ = 1 minut−1.
Let Y denote the number of customers in this new system.
4. Find by means of the stationary probabilities,
P{Y = k},
k ∈N0.
5. Prove that the average number of customers in the new system, E{Y }, is smaller than E {XA + XB}.
1A. We get from ϱA = λA
μ = 3
4 and N = 1 that
P {XA = k} = pA,k = 1
4
3
4
k
,
k ∈N0.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
108 
4. Queueing theory
1B. Analogously, ϱB = 1
2, so
P {XB = k} = pB,k =
1
2
k+1
,
k ∈N0.
2. Since N = 1, the waiting times are
VA =
ϱA
μ (1 −ϱA) =
3
4
1 · 1
4
= 3
and
VB =
ϱB
μ (1 −ϱB) = 1.
3. We get
P {XB > k} =
∞

j=k+1
1
2
j+1
=
1
2
k+2
1 −1
2
=
1
2
k+1
,
k ∈N0,
so
P {XA < XB}
=
∞

k=0
P {XA = k} · P {XB > k} =
∞

k=0
1
4
3
4
k
·
1
2
k+1
=
1
8
∞

k=0
3
8
k
= 1
8 ·
1
1 −3
8
= 1
5.
The new traﬃc intensity is
ϱ = λ
2μ =
3
2
2 · 1 = 3
4,
and since N = 2, we get
p0 = 1 −ϱ
1 + ϱ = 1
7,
pk = 2ϱk · 1 −ϱ
1 + ϱ = 2
7
3
4
k
,
k ∈N,
thus
P{Y = 0} = 1
7
and
P{Y = k} = 2
7
3
4
k
,
k ∈N.
Then
E{Y } = 2
7 · 3
4
∞

k=1
k
3
4
k−1
= 3
14 ·
1

1 −3
4
2 = 3 · 16
14
= 24
7 ,
and
E {XA} = 1
4 · 3
4
∞

k=1
k
3
4
k−1
= 3
16 · 16 = 3,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
109 
4. Queueing theory
and
E {XB} = 1
4
∞

k=1
k
1
2
k−1
= 1
4 ·
1

1 −1
2
2 = 1,
hence
E {XA + XB} = 3 + 1 = 4 > 24
7 = E{Y }.
Example 4.22 Given two independent queueing systems A and B, where we assume for each of them,
a. there is one shop assistant,
b. it is possible to create a queue,
c. the customers arrive according to a Poisson process of intensity λ = 3
5 min−1,
d. the service times are exponentially distributed of parameter μ = 1 min−1.
Let the random variable XA denote the number of customers in system A, and let XB denote the
number of customers in system B, and put Z = XA + XB.
1. Compute by means of the stationary probabilities,
P {XA = k}
and
P {XB = k} ,
k ∈N0.
2. Find the means E {XA}, E {XB} and E{Z}.
3. Compute P{Z = k}, k ∈N0.
The number of arrivals of customers to A is increased, so the customers are arriving according
to a Poisson process of intensity 1 minute−1.
Therefore, the two systems are joined to one sys-
tem with two shop assistants, so the customers now arrive according to a Poisson process of in-
tensity

1 + 3
5

minute−1, and the service times are still exponentially distributed of parameter
μ = 1 minute−1.
Let Y denote the number of customers in this system.
4. Compute by means of the stationary probabilities,
P{Y = k}
and
P{Y > k},
k ∈N0.
5. Find the mean E{Y }.
1) The traﬃc intensities are
ϱA = ϱB =
λ
N · μ = 3
5,
and since N = 1, we get
P {XA = k} = P {XB = k} = 2
5
3
5
k
,
k ∈N0.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
110 
4. Queueing theory
2) The means are
E {XA} = E {XB} = 2
5 · 3
5
∞

k=1
k
3
5
k−1
= 6
25 ·
1

1 −3
5
2 = 6
4 = 3
2,
thus
E{Z} = E {XA} + E {XB} = 3.
3) The probabilities are
P{Z = k}
=
k

j=0
P {XA = j} · P {XB = k −j} =
k

j=0
2
5
3
5
j
· 2
5
3
5
k−j
=
4
25 (k + 1)
3
5
k
,
k ∈N0.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
 
  
 
                . 

Stochastic Processes 2
 
111 
4. Queueing theory
4) The traﬃc intensity of the new system is
ϱ =
λ
N · μ =
1 + 3
5
2 · 1 = 4
5,
and since N = 2, we get
p0 = 1 −ϱ
1 + ϱ = 1
9
and
pk = 2ϱk 1 −ϱ
1 + ϱ = 2
9
4
5
k
,
k ∈N.
Thus
P{Y = 0} = 1
9
and
P{Y = k} = 2
9
4
5
k
,
k ∈N,
and hence
P{Y > k} =
∞

j=k+1
P{Y = j} = 2
9
∞

j=k+1
4
5
j
= 2
9 ·
4
5
k+1
1 −4
5
= 8
9
4
5
k
.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
112 
4. Queueing theory
5) The mean is
E{Y } = 2
9 · 4
5
∞

k=1
k
4
5
k−1
= 8
45 ·
1

1 −4
5
2 = 40
9 .
Example 4.23 Given a queueing system, for which
a. There are two shop assistants.
b. The customers arrive according to a Poisson process of intensity λ = 3 min−1.
c. The service times are exponentially distributed of parameter μ = 2 min−1.
d. It is possible to queue up.
1. Find the stationary probabilities.
2. Find by means of the stationary probabilities the probability that we have more than two customers
in the shop.
3. Find by means of the stationary probabilities the average length of the queue.
Then chance the system, such that it becomes a rejection system, while the other assumptions a.–c.
are unchanged.
4. Find the probability of rejection of this system.
1) We get from
λ = 3,
μ = 2
and
N = 2,
that the traﬃc intensity is
ϱ =
λ
N · μ =
3
2 · 2 = 3
4.
From N = 2 we ﬁnd the pk by a known formula,.
p0 = 1 −ϱ
1 + ϱ = 1
7
and
pk = 2ϱk · 1 −ϱ
1 + ϱ = 2
7 ·
3
4
k
,
k ∈N.
In particular,
p1 = 2
7 · 3
4 = 3
14
and
p2 = 2
7 · 9
16 = 9
56.
2) The probability that there are more than two customers in the shop is
∞

k=3
pk = 1 −p0 −p1 −p2 = 1 −8 + 12 + 9
56
= 1 −29
56 = 27
56.
Alternatively,
∞

k=3
pk = 2
7
∞

k=3
3
4
k
= 2
7
3
4
3
·
1
1 −3
4
= 2
7 · 3 · 3 · 3 · 4
4 · 4 · 4
= 27
56.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
113 
4. Queueing theory
3) The average length of the queue is again given by a known formula,
∞

k=3
(k −2)pk = 2
7 ·
3
4
3 ∞

k=3
(k −2)
3
4
k−3
= 2
7 ·
3
4
3
·
1

1 −3
4
2 = 27
14.
4) The probability of rejection is p2, because N = 2. It is given by some known formula in any
textbook,
p2 =
3
2
2
· 1
2!

2
j=0
1
j!
3
2
j =
9
8
1 + 3
2 + 9
8
=
9
8 + 12 + 9 = 9
29.
Example 4.24 Given a queueing system, for which
a. There are two shop assistants.
b. The customers arrive according to a Poisson process of intensity λ = 5

quarter−1
.
c. The service times are exponentially distributed of parameter μ = 3

quarter−1
.
d. It is possible for queue up.
1. Prove that the stationary probabilities are given by
pk =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
1
11,
k = 0,
2
11
5
6
k
,
k > 0.
2. Find by means of the stationary probabilities the average waiting time.
3. Find by means of the stationary probabilities the average length of the queue.
Then the service is rationalized, such that the average service time is halved. At the same time one
removes one of the shop assistants for other work in the shop.
4. Check if the average waiting time is bigger or smaller in the new system than in the old system.
1) It follows from N = 2, λ = 5 and μ = 3 that the traﬃc intensity is
ϱ =
λ
Nμ =
5
2 · 3 = 5
6.
Since N = 2, we may use a known formula, so
p0 = 1 −ϱ
1 + ϱ = 1
11
and
pk = 2ϱkp0 = 1
11
5
6
k
,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
114 
4. Queueing theory
and hence
pk =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
1
11,
k = 0,
2
11 ·
5
6
k
,
k ∈N.
2) The average waiting time V is again found by some known formula,
V = p0ϱN · N N−1
μ · N!(1 −ϱ)2 =
1
11 ·
5
6
2
· 21
3 · 2 ·
1
6
2
=
52 · 2
11 · 3 · 2 = 25
33 quarter.
3) Also the average length of the queue is found by a given formula,
∞

k=3
(k −2)pk
=
∞

k=3
(k −2)
5
6
k
· 2
11 = 2
11 ·
5
6
3 ∞

k=1
k
5
6
k−1
=
2
11 ·
5
6
3
·
1

1 −5
6
2 = 2 · 53
11 · 6 = 125
33
(= λ V ).
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.mastersopenday.nl
Visit us and find out why we are the best!
Master’s Open Day: 22 February 2014
Join the best at
the Maastricht University
School of Business and
Economics!
Top master’s programmes
• 33rd place Financial Times worldwide ranking: MSc 
International Business
• 1st place: MSc International Business
• 1st place: MSc Financial Economics
• 2nd place: MSc Management of Learning
• 2nd place: MSc Economics
• 2nd place: MSc Econometrics and Operations Research
• 2nd place: MSc Global Supply Chain Management and 
Change
Sources: Keuzegids Master ranking 2013; Elsevier ‘Beste Studies’ ranking 2012; 
Financial Times Global Masters in Management ranking 2012
Maastricht
University is
the best specialist
university in the
Netherlands
(Elsevier)

Stochastic Processes 2
 
115 
4. Queueing theory
4) We have in the new system that N = 1, λ = 5, μ = 6 and ϱ = 5
6.
Then the average waiting time is because N = 1 given by a known formula,
V =
ϱ
μ(1 −ϱ) =
5
6
6 · 1
5
= 5
6 quarter.
It is seen that the average waiting time is larger in the new system than in the old one.
Example 4.25 Given a queueing system, for which
a. There are two shop assistants.
b. The customers arrive according to a Poisson process of intensity λ = 8

quarter−1
.
c. The service times are exponentially distributed of parameter μ = 6

quarter−1
.
d. It is possible to queue up.
1. Prove that the stationary probabilities are given by
Pk =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
1
5,
k = 0,
2
5
2
3
k
,
k ∈N.
2. Find by means of the stationary probabilities the average number of customers in the shop.
3. Find by means of the stationary probabilities the average waiting time.
4. Find by means of the stationary probabilities the probability that both shop assistants are busy.
5. Find the median in the stationary distribution.
1) The traﬃc intensity is
ϱ =
λ
Nμ =
8
2 · 6 = 2
3.
Then by a known formula,
p0 = 1 −ϱ
1 + ϱ = 1
5,
pk = 2ϱkp0 = 2
5
2
3
k
,
k ∈N.
2) By computing the mean it follows that the average number of customers is
∞

k=1
kpk =
∞

k=1
k · 2
5
2
3
k
= 2
5 · 2
3
∞

k=1
k ·
2
3
k−1
= 4
15 ·
1

1 −2
3
2 = 4
15 · 9
1 = 12
5 .
Download free eBooks at bookboon.com

Stochastic Processes 2
 
116 
4. Queueing theory
3) The average waiting time is also found by a standard formula,
V =
p0ϱ2 · 2
μ · 2 · (1 −ϱ)2 =
1
5 ·
2
3
2
· 2
6 · 2 ·
1
3
2 =
4
5 · 6 = 2
15 quarter
(= 2 minutes).
Supplement. The average length of queue is also easily found by some known formula,
∞

k=3
(k −2)pk
=
∞

k=3
(k −2) · 2
5 ·
2
3
k
=
∞

ℓ=1
ℓ
2
3
ℓ−1
· 2
5
2
3
3
=
1

1 −2
3
2 · 2
5 ·
2
3
3
=
2 · 23 · 52
5 · 33
= 16
15 = λ V = 8 · 2
15.
4) The complementary event: Both shop assistants are busy with the probability
1 −(p0 + p1) = 1 −
1
5 + 4
14

= 1 −7
15 = 8
15.
Alternatively, the probability is given by
∞

k=2
pk =
∞

k=2
2
5
2
3
k
= 2
5 ·
2
3
3
· 3 = 8
15.
5) The distribution is discrete, and
∞

k=2
pk = 8
15 > 1
2,
cf. 4.. Thus
p0 = 1
5,
p1 = 4
15,
p2 = 8
45.
Finally,
P{X ≥2} =
∞

k=2
pk = 8
15 > 1
2,
and
P{X ≤2} = p0 + p1 + p2 = 1
5 + 4
15 + 8
45 = 9 + 12 + 8
45
= 29
45 > 1
2.
Since both probabilities are ≥1
2, the median is (X) = 2.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
117 
5. Other types of stochastic processes
5
Other types of stochastic processes
Example 5.1 An aeroplane has 4 engines (2 on each wing), and it can carry through a ﬂight if just
1 motor from each wing is working. At start (t = 0) all 4 engines are intact, but they may break down
during the ﬂight. We assume (as a crude approximation) that the operating times of the 4 engines are
mutually independent and exponentially distributed of mean 1
λ (which hopefully is much larger than
the ﬂight time). The system can be described as a Markov process of 4 states:
E4: all 4 engines are working,
E3: 3 engines are working,
E2: 1 engine in each wing is working,
E1: the aeroplane has crashed.
1. Derive the system of diﬀerential equations of the probabilities
Pi(t) = P {the process is in state Ei at time t} ,
i = 1, 2, 3, 4.
(Notice that this is not a birth and death process, because the probability of transition from E3 to
E1 in a small time interval of length h is almost proportional to h.)
2. Find Pi(t), i = 1, 2, 3, 4.
1) It follows from the diagram
E4
4λ
−→
E3
2λ
−→
E2
2λ
−→
E1
E3
λ→
E1
that we have the conditions
P4(t + h)
=
(1 −4λh)P4(t) + hε(h),
P3(t + 4)
=
(1 −3λh)P3(t) + 4λhP4(t) + hε(h),
P2(t + h)
=
(1 −2λh)P2(t) + 2λhP3(t) + hε(h),
P1(t + h)
=
P(t) + 2λhP2(t) + λhP3(t) + hε(h),
hence by a rearrangement and taking the limit h →0 we get the system of diﬀerential equations,
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
P ′
4(t) = −4λP4(t),
P4(0) = 1,
P ′
3(t) = −3λP3(t) + 4λP4(t),
P3(0) = 0,
P ′
2(t) = −2λP2(t) + 2λP3(t),
P2(0) = 0,
P ′
1(t) = 2λP2(t) + λP3(t),
P1(0) = 0.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
118 
5. Other types of stochastic processes
0
0.2
0.4
0.6
0.8
1
0.5
1
1.5
2
2.5
3
t
Figure 3: The graphs of P1(t), . . . , P4(t) for λ = 1.
2) It follows immediately that
P4(t) = e−4λt.
By insertion into the next diﬀerential equation we get
P ′
3(t) + 3λP3(t) = 4λe−4λt,
hence
P3(t) = e−3λt
 t
0
e3λτ ·4λe−4λτ dτ = e−3λt
 t
0
4λe−λτ dτ = e−3λt 
4 −4e−λt
= 4e−3λt −4e−4λt.
Then by insertion into the next equation and a rearrangement,
P ′
2(t) + 2λP2(t) = 8λe−3λt −8λe−4λt,
the solution of which is
P2(t)
=
e−2λt
 t
0
e2λτ 
8λe−3λτ −8λe−4λτ
dτ = e−2λt
 t
0

8λe−λτ −8λe−2λτ
dτ
=
e−2λt 
4 −8e−λt + 4e−λt
= 4e−2λt −8e−3λt + 4e−4λt.
Finally, P1(t) is found from the condition
4

k=1
Pk(t) = 1,
thus
P1(t) = 1 −P2(t) −P3(t) −P4(t),
and we get summing up,
P4(t)
=
e−4λt,
P3(t)
=
4e−3λt −4e−4λt,
P2(t)
=
4e−2λt −8e−3λt + 4e−4λt,
P1(t)
=
1 −4e−2λt + 4e−3λt −e−4λt.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
119 
5. Other types of stochastic processes
Example 5.2 Let Y and Z be independent N(0, 1) distributed random variables, and let the process
{X(t), t ∈R} be deﬁned by
X(t) = Y cos t + Z sin t.
Find the mean value function m(t) and the autocorrelation R(s, t).
The mean value function is
m(t) = E{X(t)} = E{Y cos t} + E{Z sin t} = cos t · E{Y } + sin t · E{Z} = 0.
The autocorrelation is
R(s, t)
=
E{X(s)X(t)} = E{(Y cos s + Z sin s)(Y cos t + Z sin t)}
=
cos s · cos t · E

Y 2
+ sin s · sin t · E

Z2
+ (cos s · sin t + sin s · cos t)E{Y Z}
=
cos s · cos t · E

Y 2
+ sin s · sin t · E{Y 2} + 0

E

Z2
= E

Y 2
=
cos(s −t)

V {Y } + (E{Y })2
= cos(s −t).
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Stochastic Processes 2
 
120 
5. Other types of stochastic processes
Example 5.3 Let {X(t), t ≥0} denote a Poisson process of intensity a, and let {Y (t), t ≥0} be
given by
Y (t) = X(t + 1) −X(t).
Compute the mean value function and the autocovariance of {Y (t), t ≥0}.
We have
P{X(t) = n} = (at)n
n!
e−at,
n ∈N0.
The mean value function is obtained by ﬁrst noticing that
P{T(t) = n} = P{X(t + 1) −X(t) = n} = P{X(1) = n} = an
n! e−a,
thus Y (t) = X(1), (The Poisson process is “forgetful”) and
m(t) = E{Y (t)} =
∞

n=1
n an
n! e−λ = a.
If s ≤t, then
Cov(Y (s), Y (t))
=
Cov(X(s + 1) −X(s), X(t + 1) −X(t)) = a · (s + 1 −min{s + 1, t} −s + s)
=
a (s + 1 −min{s + 1, t}).
If therefore s + 1 ≤t, then
Cov(Y (s), Y (t)) = 0,
and if s + 1 > 1, then
Cov(Y (s), T(t)) = a{s + 1 −t}.
Summing up,
Cov(Y (s), Y (t)) =
⎧
⎨
⎩
a{1 −|s −t|},
for |s −t| < 1,
0,
for |s −t| ≥1.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
121 
5. Other types of stochastic processes
Example 5.4 Let X1 and X2 be independent random variables, both normally distributed of mean 0
and variance σ2. We deﬁne a stochastic process {X(t), t ∈R} by
X(t) = X1 sin t + X2 cos t.
1) Find the mean value function m(t) and the autocorrelation R(s, t).
2) Prove that the process {X(t), t ∈R} is weakly stationary.
3) Find the values of s −t, for which the random variables X(s) and X(t) are non-correlated.
4) Given the random variables X(s) and X(t), where s −t is ﬁxed as above. Are X(s) and X(t)
independent?
1) The mean value function is
m(t) = E{X(t)} = sin t · E {X1} + cos t · E {X2} = 0.
The autocorrelation is
R(s, t)
=
E{X(s)X(t)} = E {(X1 sin s + X2 cos s) (X1 sin t + X2 cos t)}
=
sin s · sin t · E

X2
1

+ cos s · cos t · E

X2
2

+ (· · · ) · E {X1X2}
=
sin s · sin t

V {X1} +

E

X2
1

+ cos s · cos t

V {X2} + E

X2
2

+ 0
=
(cos s · cos t + sin s · sin t)σ2 = cos(s −t) · σ2.
2) A stochastic process is weakly stationary, if m(t) = m is constant, and C(s, t) = C(s −t). In the
speciﬁc case,
m(t) = 0 = m,
and
C(s, t)
=
Cov{X(s), X(t)} = E{X(s)X(t)} −E{X(s)} · E{X(t)}
=
R(s, t) −m(s)m(t) = σ2 cos(s −t),
and we have proved that the process is weakly stationary.
3) It follows from
Cov{X(s), X(t)} = C(s, t) = σ2 cos(s −t),
that X(s) and X(t) are non-correlated, if
s = t + π
2 + pπ,
p ∈Z,
i.e. if
s −t = π
2 + pπ,
p ∈Z.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
122 
5. Other types of stochastic processes
4) Since (X(s), X(t)) with s −t = π
2 + pπ, p ∈Z, follows a two-dimensional normal distribution, and
X(s) and X(t) are non-correlated, we conclude that they are independent.
Example 5.5 Let {X(t), t ∈R} be a stationary process of mean 0, autocorrelation R(τ) and eﬀect
spectrum S(ω).
Let {Y (t), t ∈R} be deﬁned by
Y (t) = X(t + a) −X(t −a),
where a > 0.
Express the autocorrelation and the eﬀect spectrum of {Y (t)} by the corresponding expressions of
{X(t)} (and a).
The assumptions are
m(t) = 0,
R(τ) = E{X(t + τ)X(t)}
and
S(ω) =
 ∞
−∞
eiωτR(τ) dτ.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Get Help Now
Go to www.helpmyassignment.co.uk for more info
Need help with your
dissertation?
Get in-depth feedback & advice from experts in your 
topic area. Find out what you can do to improve
the quality of your dissertation!

Stochastic Processes 2
 
123 
5. Other types of stochastic processes
Hence for Y (t) = X(t + a) −X(t −a), a > 0,
RY (τ)
=
E{Y (t + τ)Y (t)} = E{[X(t + τ + a) −X(t + τ −a)] · [X(t + a) −X(t −a)]}
=
E{X(t + τ + a)X(t + a)} −E{X(t + τ + a)X(t −a)}
−E{X(t + τ −a)X(t + a)} + E{X(t + τ −a)X(t −a)}
=
RX(τ) −RX(τ + 2a) −RX(τ −2a) + RX(τ)
=
2RX(τ) −RX(τ + 2a) −RX(τ −2a),
so
SY (ω)
=
 ∞
−∞
eiωτRY (τ) dτ
=
2
 ∞
−∞
eiωτRX(τ) dτ −
 ∞
−∞
eiωτRX(τ + 2a) dτ −
 ∞
−∞
eiωτRX(τ −2a) dτ
=
2SX(ω) −e−2iaωSX(ω) −e2iaωSX(ω) = 2{1 −cos 2aω}SX(ω)
=
4 sin2 aω SX(ω).
Download free eBooks at bookboon.com

Stochastic Processes 2
 
124 
5. Other types of stochastic processes
Example 5.6 Let {X(t), t ∈R} be a stationary process of mean 0 and eﬀect spectrum S(ω), and let
Y = 1
n
n

k=1
X(kT),
hvor T > 0.
Prove that
E

Y 2
=
1
2πn2
 ∞
−∞
S(ω) ·
sin2
1
2 nωT

sin2
1
2 ωT
 dω.
Hint:
sin2
1
2 nωT

sin2
1
2 ωT
 =
n−1

m=−(n−1)
(n −|m|)e−iωmT .
First compute
E

Y 2
=
1
n2 E
 n

k=1
n

m=1
X(kT)X(mT)

=
1
n2 E
 n

k=1
X(kT)X(kT) + 2
n−1

k=1
n

m=k+1
X(kT)X(mT)

=
1
n2
n

k=1
R(0) + 2
n2
n−1

k=1
n−k

m=1
E{X(kT)X((k + m)T)}
=
n
n2 R(0) + 2
n2
n−1

k=1
n−k

m=1
R(mT) = n
n2 R(0) + 2
n2
n−1

m=1
n−m

k=1
R(mT)
=
n
n2 R(0) + 2
n2
n−1

m=1
(n −m)R(mT) = 1
n2
n−1

m=−(n−1)
(n −|m|)R(|m|T).
Using
R(−mT) = E{X(kT)X((k −m)T)} = E{X(kT)X((k + m)T)} = R(mT),
and the hint and the inversion formula we get
E

Y 2
=
1
n2
n−1

m=−(n−1)
(n −|m|)R(mT) = 1
n2
n−1

m=−(n−1)
(n −|m|) · 1
2π
 ∞
−∞
e−imωT S(ω) dω
=
1
2πn2
 ∞
−∞
S(ω)
n−1

m=−(n−1)
(n −|m|)e−iωmT dω =
1
2πn2
 ∞
−∞
S(ω) ·
sin2
1
2 nωT

sin2
1
2 ωT
 dω,
and the formula is proved.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
125 
5. Other types of stochastic processes
Example 5.7 Let {W(t), t ≥0} be a Wiener process..
1) Find the autocorrelation R(s, t) and the autocovariance C(s, t), s, t ∈R+.
2) Let 0 < s < t. Find the simultaneous frequency of the two-dimensional random variable {W(s), W(t)}.
The Wiener process is a normal process {W(t), t ≥0} with
W(0) = 0,
m(t) = 0,
V {W(t)} = α t
(α > 0),
and of independent increments. It follows from m(t) = 0 that
C(s, t) = Cov{W(s), W(t)} = R(s, t) −m(s)m(t) = R(s, t).
1) If 0 < s < t, then
R(s, t)
=
C(s, t) = Cov{W(s), W(t)} = Cov{W(s), W(s) + [W(t) −W(s)]}
=
Cov{W(s), W(s)} + Cov{W(s), W(t) −W(s)}
=
V {W(s)} + 0
(independent increments)
=
α · s.
Analogously, R(s, t) = C(s, t) = α · t, if 0 < t < s, thus
R(s, t) = C(s, t) = α · min{s, t} =
 αs,
if 0 < s < t,
αt,
if 0 < t < s.
2) If 0 < s < t, then (W(s), W(t) −W(s)) has the simultaneous frequency
f(x, y) =
1
√
2παs exp

−1
2
x2
αs

·
1
,
2πα(t −s)
exp

−1
2
y2
α(t −s)

for (x, y) ∈R2. Finally, it follows that
(W(s), W(t)) = (W(s), {W(t) −W(s)} + W(s))
has the frequency
g(x, y) = f(x, y −x) =
1
2πα
,
s(t −s)
exp

−1
2
 x2
αs + (y −x)2
α(t −s)

,
(x, y) ∈R2.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
126 
Index
Index
absorbing state, 13, 25
Arcus sinus law, 10
closed subset of states, 13
convergence in probability, 28
cycle, 22
discrete Arcus sinus distribution, 10
distribution function of a stochastic process, 4
double stochastic matrix, 22, 39
drunkard’s walk, 5
Ehrenfest’s model, 32
geometric distribution, 124, 133
initial distribution, 11
invariant probability vector, 11, 22, 23, 25, 26,
28, 30, 32, 36, 39
irreducible Markov chain, 12, 18–23, 32, 36, 39,
41, 43, 45, 47, 50, 53, 62, 65, 67, 70,
73, 75, 78, 80, 86, 88, 91, 93, 98, 103,
106, 108, 114, 116, 122, 125, 128, 131
irreducible stochastic matrix, 83, 120
limit matrix, 13
Markov chain, 10, 18
Markov chain of countably many states, 101
Markov process, 5
outcome, 5
periodic Markov chain, 14
probability of state, 11
probability vector, 11
random walk, 5, 14, 15
random walk of reﬂecting barriers, 14
random walk of absorbing barriers, 14
regular Markov chain, 12, 18–23, 36, 39, 43, 47,
50, 53, 56, 62, 65, 67, 70, 73, 75, 78,
80, 83, 86, 88, 91, 100, 101, 103, 106,
108, 114, 116, 122, 125, 128, 131
regular stochastic matrix, 26, 30, 120
ruin problem, 7
sample function, 4
state of a process, 4
stationary distribution, 11, 43, 50
stationary Markov chain, 10
stochastic limit matrix, 13
stochastic matrix, 10
stochastic process, 4
symmetric random walk, 5, 9
transition probability, 10, 11
vector of state, 11
Download free eBooks at bookboon.com

