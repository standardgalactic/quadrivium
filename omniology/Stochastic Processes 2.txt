Leif Mejlbro
Stochastic Processes 2
Probability Examples c-9
Download free books at

2 
Leif Mejlbro
Probability Examples c-9
Stochastic Processes 2
Download free eBooks at bookboon.com

3 
Probability Examples c-9 â€“ Stochastic Processes 2
Â© 2009 Leif Mejlbro & Ventus Publishing ApS
ISBN 978-87-7681-525-7
Download free eBooks at bookboon.com

Stochastic Processes 2
 
4 
Contents
 
Introduction  
5
1  
Theoretical background  
6
1.1  
The Poisson process  
6
1.2  
Birth and death processes  
8
1.3  
Queueing theory in general  
11
1.4  
Queueing system of innitely many shop assistants  
11
1.5  
Queueing system of a nite number of shop assistants, and with forming of queues  
12
1.6  
Queueing systems with a nite number of shop assistants and without queues 
15
1.7  
Some general types of stochastic processes  
17
2  
The Poisson process  
19
3  
Birth and death processes  
37
4  
Queueing theory  
52
5  
Other types of stochastic processes  
117
 
Index  
126
Contents
Download free eBooks at bookboon.com
Click on the ad to read more
www.sylvania.com
We do not reinvent  
the wheel we reinvent 
light.
Fascinating lighting offers an infinite spectrum of 
possibilities: Innovative technologies and new  
markets provide both opportunities and challenges. 
An environment in which your expertise is in high 
demand. Enjoy the supportive working atmosphere 
within our global group and benefit from international 
career paths. Implement sustainable ideas in close 
cooperation with other specialists and contribute to 
influencing our future. Come and join us in reinventing 
light every day.
Light is OSRAM

Stochastic Processes 2
 
5 
Introduction
Introduction
This is the ninth book of examples from Probability Theory. The topic Stochastic Processes is so big
that I have chosen to split into two books. In the previous (eighth) book was treated examples of
Random Walk and Markov chains, where the latter is dealt with in a fairly large chapter. In this book
we give examples of Poisson processes, Birth and death processes, Queueing theory and other types
of stochastic processes.
The prerequisites for the topics can e.g. be found in the Ventus: Calculus 2 series and the Ventus:
Complex Function Theory series, and all the previous Ventus: Probability c1-c7.
Unfortunately errors cannot be avoided in a ï¬rst edition of a work of this type. However, the author
has tried to put them on a minimum, hoping that the reader will meet with sympathy the errors
which do occur in the text.
Leif Mejlbro
27th October 2009
Download free eBooks at bookboon.com

Stochastic Processes 2
 
6 
1. Theoretical background
1
Theoretical background
1.1
The Poisson process
Given a sequence of independent events, each of them indicating the time when they occur.
We
assume
1. The probability that an event occurs in a time interval I â«…[0, +âˆ[ does only depend on the length
of the interval and not of where the interval is on the time axis.
2. The probability that there in a time interval of length t we have at least one event, is equal to
Î»t + t Îµ(t),
where Î» > 0 is a given positive constant.
3. The probability that we have more than one event in a time interval of length t is t Îµ(t).
It follows that
4. The probability that there is no event in a time interval of length is given by
1 âˆ’Î»t + tÎµ(t).
5. The probability that there is precisely one event in a time interval of length t is Î»t + t Îµ(t).
Here Îµ(t) denotes some unspeciï¬ed function, which tends towards 0 for t â†’0.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
360Â°
thinking.
Â© Deloitte & Touche LLP and affiliated entities.
Discover the truth at www.deloitte.ca/careers 

Stochastic Processes 2
 
7 
1. Theoretical background
Given the assumptions on the previous page, we let X(t) denote the number of events in the interval
]0, t], and we put
Pk(t) := P{X(t) = k},
for k âˆˆN0.
Then X(t) is a Poisson distributed random variable of parameter Î»t. The process
{X(t) | t âˆˆ[0, +âˆ[}
is called a Poisson process, and the parameter Î» is called the intensity of the Poisson process.
Concerning the Poisson process we have the following results:
1) If t = 0, (i.e. X(0) = 0), then
Pk =
â§
â¨
â©
1,
for k = 0,
0,
for k âˆˆN.
2) If t > 0, then Pk(t) is a diï¬€erentiable function, and
P â€²
k(t) =
â§
â¨
â©
Î» {Pkâˆ’1(t) âˆ’Pk(t)} ,
for k âˆˆN and t > 0,
âˆ’Î» P0(t),
for k = 0 and t > 0.
When we solve these diï¬€erential equations, we get
Pk(t) = (Î»t)k
k!
eâˆ’Î»t,
for k âˆˆN0,
proving that X(t) is Poisson distributed with parameter Î»t.
Remark 1.1 Even if Poisson processes are very common, they are mostly applied in the theory of
tele-traï¬ƒc. â™¦.
If X(t) is a Poisson process as described above, then X(s + t) âˆ’X(s) has the same distribution as
X(t), thus
P{X(s + t) âˆ’X(s)} = (Î»t)k
k!
eâˆ’Î»t, for k âˆˆN0.
If 0 â‰¤t1 < t2 â‰¤t3 < t4, then the two random variables X (t4) âˆ’X (t3) and X (t2) âˆ’X (t1) are
independent. We say that the Poisson process has independent and stationary growth.
The mean value function of a Poisson process is
m(t) = E{X(t)} = Î»t.
The auto-covariance (covariance function) is given by
C(s, t) = Cov(X(s) , X(t)) = Î» min{s, t}.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
8 
1. Theoretical background
The auto-correlation is given by
R(s, t) = E{X(s) Â· X(t)} = Î» min(s, t) + Î»2st.
The event function of a Poisson process is a step function with values in N0, each step of the size
+1. We introduce the sequence of random variables T1, T2, . . . , which indicate the distance in time
between two succeeding events in the Poisson process. Thus
Yn = T1 + T2 + Â· Â· Â· + Tn
is the time until the n-th event of the Poisson process.
Notice that T1 is exponentially distributed of parameter Î», thus
P {T1 > t} = P{X(t) = 0} = eâˆ’Î»t,
for t > 0.
All random variables T1, T2, . . . , Tn are mutually independent and exponentially distributed of pa-
rameter Î», hence
Yn = T1 + T2 + Â· Â· Â· + Tn
is Gamma distributed, Yn âˆˆÎ“

n , 1
Î»

.
Connection with Erlangâ€™s B-formula. Since Yn+1 > t, if and only if X(t) â‰¤n, we have
P{X(t) â‰¤n} = P {Yn+1 > t} ,
from which we derive that
n

k=1
(Î»t)k
k!
eâˆ’Î»t = Î»n+1
n!
 +âˆ
t
yn eâˆ’Î»y dy.
We have in particular for Î» = 1,
n

k=0
tk
k! = et
n!
 +âˆ
t
yn eâˆ’y dy,
n âˆˆN0.
1.2
Birth and death processes
Let {X(t) | t âˆˆ[0, +âˆ[} be a stochastic process, which can be in the states E0, E1, E2, . . . . The
process can only move from one state to a neighbouring state in the following sense: If the process is
in state Ek, and we receive a positive signal, then the process is transferred to Ek+1, and if instead
we receive a negative signal (and k âˆˆN), then the process is transferred to Ekâˆ’1.
We assume that there are non-negative constants Î»k and Î¼k, such that for k âˆˆN,
1) P{one positive signal in ] t, t + h [| X(t) = k} = Î»k h + h Îµ(h).
2) P{one negative signal in ] t, t + h [| X(t) = k} = Î¼k h + h Îµ(h).
Download free eBooks at bookboon.com

Stochastic Processes 2
 
9 
1. Theoretical background
3) P{no signal in ] t, t + h [| X(t) = k} = 1 âˆ’(Î»k + Î¼k) h + h Îµ(h).
We call Î»k the birth intensity at state Ek, and Î¼k is called the death intensity at state Ek, and the
process itself is called a birth and death process. If in particular all Î¼k = 0, we just call it a birth
process, and analogously a death process, if all Î»k = 0.
A simple analysis shows for k âˆˆN and h > 0 that the event {X(t + h) = k} is realized in on of the
following ways:
â€¢ X(t) = k, and no signal in ] t, t + h [.
â€¢ X(t) = k âˆ’1, and one positive signal in ] t, t + h [.
â€¢ X(t) = k + 1, and one negative signal in ] t, t + h [.
â€¢ More signals in ] t, t + h [.
We put
Pk(t) = P{X(t) = k}.
By a rearrangement and taking the limit h â†’0 we easily derive the diï¬€erential equations of the
process,
â§
â¨
â©
P â€²
0(t) = âˆ’Î»0 P0(t) + Î¼1 P1(t),
for k = 0,
P â€²
k(t) = âˆ’(Î»k + Î¼k) Pk(t) + Î»kâˆ’1 Pkâˆ’1(t) + Î¼k+1 Pk+1(t),
for k âˆˆN.
In the special case of a pure birth process, where all Î¼k = 0, this system is reduced to
â§
â¨
â©
P â€²
0(t) = âˆ’Î»0 P0(t),
for k = 0,
P â€²
k(t) = âˆ’Î»k Pk(t) + Î»kâˆ’1 Pkâˆ’1(t),
for k âˆˆN.
If all Î»k > 0, we get the following iteration formula of the complete solution,
â§
â¨
â©
P0(t) = c0 eâˆ’Î»0 t,
for k = 0,
Pk(t) = Î»kâˆ’1 eâˆ’Î»kt 	 t
0 eÎ»kÏ„ Pkâˆ’1(Ï„) dÏ„ + ck eâˆ’Î»kt,
for k âˆˆN.
From P0(t) we derive P1(t), etc.. Finally, if we know the initial distribution, we are e.g. at time t = 0
in state Em, then we can ï¬nd the values of the arbitrary constants ck.
Let {X(t) | t âˆˆ[0, +âˆ[} be a birth and death process, where all Î»k and Î¼k are positive, with the
exception of Î¼0 = 0, and Î»N = 0, if there is a ï¬nal state EN. The process can be in any of the states,
therefore, in analogy with the Markov chains, such a birth and death process is called irreducible.
Processes like this often occur in queueing theory.
If there exists a state Ek, in which Î»k = Î¼k, then Ek is an absorbing state, because it is not possible
to move away from Ek.
For the most common birth and death processes (including all irreducible processes) there exist non-
negative constants pk, such that
Pk(t) â†’pk
and
P â€²
k(t) â†’0
for t â†’+âˆ.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
10 
1. Theoretical background
These constants fulï¬l the inï¬nite system of equations,
Î¼k+1 pk+1 = Î»k pk,
for k âˆˆN0,
which sometimes can be used to ï¬nd the pk.
If there is a solution (pk), which satisï¬es
pk â‰¥0
for all k âˆˆN0,
and
+âˆ

k=0
pk = 1,
we say that the solution (pk) is a stationary distribution, and the pk are called the stationary proba-
bilities. In this case we have
Pk(t) â†’pk
for t â†’+âˆ.
If {X(t) | t âˆˆ[0, +âˆ[} is an irreducible process, then
pk = Î»kâˆ’1Î»kâˆ’2 Â· Â· Â· Î»1Î»0
Î¼kÎ¼kâˆ’1 Â· Â· Â· Î¼2Î¼1
Â· p0 := ak p0,
for k âˆˆN0,
where all ak > 0.
The condition of the existence of a stationary distribution is then reduced to that the series 
k ak is
convergent of ï¬nite sum a > 0. In this case we have p0 = 1
a.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
We will turn your CV into 
an opportunity of a lifetime
Do you like cars? Would you like to be a part of a successful brand?
We will appreciate and reward both your enthusiasm and talent.
Send us your CV. You will be surprised where it can take you.
Send us your CV on
www.employerforlife.com

Stochastic Processes 2
 
11 
1. Theoretical background
1.3
Queueing theory in general
Let {X(t) | t âˆˆ[0, +âˆ[} be a birth and death process as described in the previous section.
We
shall consider them as services in a service organization, where â€œbirthâ€ corresponds to the arrival of a
new customer, and â€œdeathâ€ correspond to the ending of the service of a customer. We introduce the
following:
1) By the arrival distribution (the arrival process) we shall understand the distribution of the arrivals
of the customers to the service (the shop). This distribution is often of Poisson type.
2) It the arrivals follow a Poisson process of intensity Î», then the random variable, which indicates
the time diï¬€erence between two succeeding arrivals exponentially distributed of parameter Î». We
say that the arrivals follow an exponential distribution, and Î» is called the arrival intensity.
3) The queueing system is described by the number of shop assistants or serving places, if there is
the possibility of forming queues or not, and the way a queue is handled. The serving places are
also called channels.
4) Concerning the service times we assume that if a service starts at time t, then the probability that
it is ended at some time in the interval ]t, t + h[ is equal to
Î¼ h + h Îµ(h),
where Î¼ > 0.
Then the service time is exponentially distributed of parameter Î¼.
If at time t we are dealing with k (mutually independent) services, then the probability that one
of these is ended in the interval ]t, t + h[ equal to
k Î¼ h + h Îµ(h).
We shall in the following sections consider the three most common types of queueing systems. Concern-
ing other types, cf. e.g. Villy BÃ¦k Iversen: Teletraï¬ƒc Engineering and Network Planning Technical
University of Denmark.
1.4
Queueing system of inï¬nitely many shop assistants
The model is described in the following way: Customers arrive to the service according a Poisson
process of intensity Î», and they immediately go to a free shop assistant, where they are serviced
according to an exponential distribution of parameter Î¼.
The process is described by the following birth and death process,
{X(t) | t âˆˆ[0, +âˆ[}
med Î»k = Î» and Î¼k = k Î¼
for alle k.
The process is irreducible, and the diï¬€erential equations of the system are given by
â§
â¨
â©
P â€²
0(t) = âˆ’Î» P0(t) + Î¼ P1(t),
for k = 0,
P â€²
k(t) = âˆ’(Î» + k Î¼)Pk(t) + Î» Pkâˆ’1(t) + (k + 1)Î¼ Pk+1(t),
for k âˆˆN.
The stationary probabilities exist and satisfy the equations
(k + 1)Î¼ pk+1 = Î» pk,
k âˆˆN0,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
12 
1. Theoretical background
of the solutions
pk = 1
k!
Î»
Î¼
k
exp

âˆ’Î»
Î¼

,
k âˆˆN0.
These are the probabilities that there are k customers in the system, when we have obtained equilib-
rium.
The system of diï¬€erential equations above is usually diï¬ƒcult to solve. One has, however, some partial
results, e.g. the expected number of customers at time t, i.e.
m(t) :=
+âˆ

k=1
k Pk(t),
satisï¬es the simpler diï¬€erential equation
mâ€²(t) + Î¼ m(t) = Î».
If at time t = 0 there is no customer at the service, then
m(t) = Î»
Î¼

1 âˆ’eâˆ’Î¼t
,
for t â‰¥0.
1.5
Queueing system of a ï¬nite number of shop assistants, and with form-
ing of queues
We consider the case where
1) the customers arrive according to a Poisson process of intensity Î»,
2) the service times are exponentially distributed of parameter Î¼,
3) there are N shop assistants,
4) it is possible to form queues.
Spelled out, we have N shop assistants and a customer, who arrives at state Ek. If k < N, then the
customer goes to a free shop assistant and is immediately serviced. If however k = N, thus all shop
assistants are busy, then he joins a queue and waits until there is a free shop assistant. We assume
here queueing culture.
With a slight change of the notation it follows that if there are N shop assistants and k customers
(and not k states as above), where k > N, then there is a common queue for all shop assistants
consisting of k âˆ’N customers.
This process is described by the following birth and death process {X(t) | t âˆˆ[0, +âˆ[} of the
parameters
Î»k = Î»
and
Î¼k =
â§
â¨
â©
k Î¼,
for k < N,
N Î¼,
for k â‰¥N.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
13 
1. Theoretical background
The process is irreducible. The equations of the stationary probabilities are
â§
â¨
â©
(k + 1)Î¼ pk+1 = Î» pk,
for k < N,
N Î¼ pk+1 = Î» pk,
for k â‰¥N.
We introduce the traï¬ƒc intensity by
Ï± :=
Î»
N Î¼.
Then we get the stationary probabilities
pk =
â§
âª
âª
âª
âª
â¨
âª
âª
âª
âª
â©
Î»
Î¼
k
Â· 1
k! p0 = Ï±kÂ·N k
k!
Â· p0,
for k < N,
Î»
Î¼
k
Â·
1
N kâˆ’N Â· N! Â· p0 = Ï±k Â· N N
N!
Â· p0,
for k â‰¥N.
Remark 1.2 Together with the traï¬ƒc intensity one also introduce in teletraï¬ƒc the oï¬€er of traï¬ƒc.
By this we mean the number of customers who at the average arrive to the system in a time interval of
length equal to the mean service time. In the situation above the oï¬€er of traï¬ƒc is Î»
Î¼. Both the traï¬ƒc
intensity and the oï¬€er of traï¬ƒc are dimensionless. They are both measured in the unit Erlang.â™¦
The condition that (pk) become stationare probabilities is that the traï¬ƒc intensity Ï± < 1, where
+âˆ

k=N
N N
N! Ï±k =
(Ï± N)N
(1 âˆ’Ï±) Â· N!.
If, however, Ï± â‰¥1, it is easily seen that the queue is increasing towards inï¬nity, and there does not
exist a stationary distribution.
We assume in the following that Ï± < 1, so the stationary probabilities exist
1) If N = 1, then
pk = Ï±k(1 âˆ’Ï±),
for k âˆˆN0.
2) If N = 2, then
pk =
â§
âª
âª
âª
â¨
âª
âª
âª
â©
1 âˆ’Ï±
1 + Ï±,
for k = 0,
2Ï±k Â· 1 âˆ’Ï±
1 + Ï±,
for k âˆˆN.
3) If N > 2, the formulÃ¦ become somewhat complicated, so they are not given here.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
14 
1. Theoretical background
The average number of customers at the service is under the given assumptions,
â§
âª
â¨
âª
â©
Ï±
1 âˆ’Ï±,
for N = 1,

+âˆ
k=1 k pk,
generelt (naturligvis).
The average number of busy shop assistants is
â§
â¨
â©
Ï±,
for N = 1,

Nâˆ’1
k=1 k pk + N 
+âˆ
k=N pk,
in general.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
AXA Global 
Graduate Program
Find out more and apply

Stochastic Processes 2
 
15 
1. Theoretical background
The waiting time of a customer is deï¬ned as the time elapsed from his arrival to the service of him
starts. The staying time is the time from his arrival until he leaves the system after the service of
him. Hence we have the splitting
staying time = waiting time + service time.
The average waiting time is in general given by
V =
+âˆ

k=N
k âˆ’N + 1
N Î¼
pk,
which by a computation is
V =
â§
âª
âª
âª
â¨
âª
âª
âª
â©
Ï±
Î¼(1 âˆ’Ï±),
for N = 1,
Ï±N Â· N Nâˆ’1
Î¼ Â· N! Â· (1 âˆ’Ï±)2 Â· p0,
generelt.
In the special case of N = 1 the average staying time is given by
O =
Ï±
Î¼(1 âˆ’Ï±) + 1
Î¼ =
1
Î¼ âˆ’Î».
The average length of the queue (i.e. the mean number of customers in the queue) is
Î»V =
+âˆ

k=N+1
(k âˆ’N)pk = Ï±N+1 Â· N N
N! Â· (1 âˆ’Ï±)2 Â· p0.
1.6
Queueing systems with a ï¬nite number of shop assistants and without
queues
We consider here the case where
1) the customers arrive according to a Poisson process of intensity Î»,
2) the times of service are exponential distributed of parameter Î¼,
3) there are N shop assistants or channels,
4) it is not possible to form a queue.
The diï¬€erence from the previous section is that if a customer arrives at a time when all shop assistants
are busy, then he immediately leaves the system. Therefore, this is also called a system of rejection.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
16 
1. Theoretical background
In this case the process is described by the following birth and death process {X(t) | t âˆˆ[0, +âˆ[}
with a ï¬nite number of states E0, E1, . . . , EN, where the intensities are given by
Î»k =
â§
â¨
â©
Î»,
for k < N,
0,
for k â‰¥N,
and
Î¼k = k Î¼.
This process is also irreducible. The corresponding system of diï¬€erential equations is
â§
âª
âª
âª
âª
â¨
âª
âª
âª
âª
â©
P â€²
0(t) = âˆ’Î» P0(t) + Î¼ P1(t),
for k = 0,
P â€²
k(t) = âˆ’(Î» + k Î¼)Pk(t) + Î» Pkâˆ’1(t) + (k + 1)Î¼ Pk+1(t),
for 1 â‰¤k â‰¤N âˆ’1,
P â€²
N(t) = âˆ’N Î¼ PN(t) + Î» PNâˆ’1(t),
for k = N.
In general, this system is too complicated for a reasonable solution, so instead we use the stationary
probabilities, which are here given by Erlangâ€™s B-formula:
pk =
1
k!
Î»
Î¼
k

N
j=0
1
j!
Î»
Î¼
j ,
for k = 0, 1, 2, . . . , N.
The average number of customers who are served, is of course equal to the average number of busy
shop assistants, or channels. The common value is
N

k=1
k pk = Î»
Î¼ (1 âˆ’pN) .
We notice that pN can be interpreted as the probability of rejection. This probability pN is large,
when Î» >> Î¼. We get from
N

j=0
1
j!
Î»
Î¼
j
=
exp
Î»
Î¼

N!
 +âˆ
Î»/Î¼
yN eâˆ’y dy,
the probability of rejection
pN =
1
N!
Î»
Î¼
N

N
j=0
1
j!
Î»
Î¼
j =
Î»
Î¼
N
exp

âˆ’Î»
Î¼

	 +âˆ
Î»/Î¼ yN eâˆ’y dy
.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
17 
1. Theoretical background
1.7
Some general types of stochastic processes
Given two stochastic processes, {X(t) | t âˆˆT} and {Y (s) | s âˆˆT}, where we assume that all the
moments below exist. We deï¬ne
1) the mean value function,
m(t) := E{X(t)},
for t âˆˆT,
2) the auto-correlation,
R(x, t) := E{X(s)X(t)},
for s, t âˆˆT,
3) the auto-covariance,
C(s, t) := Cov(X(s), X(t)),
for s, t âˆˆT,
4) the cross-correlation,
RXY (s, t) := E{X(s)Y (t)},
for s, t âˆˆT,
5) the cross-covariance,
CXY (s, t) := Cov(X(s), Y (t)),
for s, t âˆˆT.
A stochastic process {X(t) | t âˆˆR} is strictly stationary, if the translated process {X(t + h) | t âˆˆR}
for every h âˆˆR has the same distribution as {X(t) | t âˆˆR}.
In this case we have for all n âˆˆN, all x1, . . . , xn âˆˆR, and all t1, . . . , tn âˆˆR that
P {X (t1 + h) â‰¤x1 âˆ§Â· Â· Â· âˆ§X (tn + h) â‰¤xn}
does not depend on h âˆˆR.
Since P{X(t) â‰¤x} does not depend on t for such a process, we have
m(t) = m,
and the auto-covariance C(s, t) becomes a function in the real variable s âˆ’t. We therefore write in
this case,
C(s, t) := C(s âˆ’t).
Analogously, the auto-correlation is also a function only depending on s and t, so we write
R(s, t) := R(s âˆ’t).
Conversely, if m(t) = m and C(s, t) = C(s âˆ’t), then we call the stochastic process {X(t) | t âˆˆR}
weakly stationary.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
18 
1. Theoretical background
Let us consider a stochastic process {X(t) | t âˆˆR} of mean 0 and auto-correlation
R(Ï„) = E{X(t + Ï„)X(t)}.
If R(Ï„) is absolutely integrable, we deï¬ne the eï¬€ect spektrum by
S(Ï‰) =
 +âˆ
âˆ’âˆ
eiÏ‰Ï„ R(Ï„) dÏ„,
i.e. as the Fourier transformed of R(Ï„).
Furthermore, if we also assume that S(Ï‰) is absolutely
integrable, then we can apply the Fourier inversion formula to reconstruct R(Ï„) from the eï¬€ect
spectrum,
R(Ï„) = 1
2Ï€
 +âˆ
âˆ’âˆ
eâˆ’iÏ‰Ï„ S(Ï‰) dÏ‰.
In particular,
E

|X(t)|2
= R(0) = 1
2Ï€
 +âˆ
âˆ’âˆ
S(Ï‰) dÏ‰.
A stochastic process {X(t) | t âˆˆT} is called a normal process, or a GauÃŸiann process, if for every
n âˆˆN and every t1, . . . , tn âˆˆT the distribution of {X (t1) , . . . , X (tn)} is an n-dimensional normal
distribution. A normal process is always completely speciï¬ed by its mean value function m(t) and its
auto-covariance function C(s, t).
The most important normal process is the Wiener process, or the Brownian movements
{W(t) | t â‰¥0}.
This is characterized by
1) W(0) = 0,
2) m(t) = 0,
3) V {W(t)} = Î± t,
where Î± is a positive constant,
4) mutually independent increments.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
19 
2. The Poisson process
2
The Poisson process
Example 2.1 Let {X(t), t âˆˆ[0, âˆ[} be a Poisson process of intensity Î», and let the random variable
T denote the time when the ï¬rst event occurs.
Find the conditional distribution of T, given that at time t0 precisely one event has occurred, thus ï¬nd
P {T â‰¤t | X (t0) = 1} .
When t âˆˆ[0, t0], then the conditional distribution is given by
P {T â‰¤t | X (t0) = 1}
=
P {X(t) = 1 âˆ§X (t0) = 1}
P {X (t0) = 1}
= P {X(t) = 1 âˆ§X (t0) âˆ’X(t) = 0}
P {X (t0) = 1}
=
P{X(t) = 1} Â· P {X (t0) âˆ’X(t) = 0}
P {X (t0) = 1}
= Î» t eâˆ’Î»t Â· eâˆ’Î»(t0âˆ’t)
Î» t0eâˆ’Î» t0
= t
t0
,
because
Pk(t) = P{X(t) = k} = (Î» t)k
k!
eâˆ’Î» t,
k âˆˆN,
and where we furthermore have applied that X (t0) âˆ’X(t) has the same distribution as X (t0 âˆ’t).
The conditional distribution is a rectangular distribution over ]0, t0[.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
ibili
because 
e Graduate Programme  
for Engineers and Geoscientists
Month 16
I was a construction
supervisor in 
the North Sea 
advising and 
helping foremen 
solve problems
I was a
he
s
Real work 
International opportunities 

ree work placements
al 
Internationa
or

ree wo
I wanted real responsibili 
 I joined MITAS because 
www.discovermitas.com

Stochastic Processes 2
 
20 
2. The Poisson process
Example 2.2 Let {X1(t), t â‰¥0} and {X2(t), t â‰¥0} denote two independent Poisson processes of
intensity Î»1 and Î»2, resp., and let the process {Y (t), t â‰¥0} be deï¬ned by
Y (t) = X1(t) + X2(t).
Prove that {Y (t), t â‰¥0} is a Poisson process.
We ï¬rst identify
Pn(t) = P{X(t) = n} = (Î»1t)n
n!
eâˆ’Î»1t,
and
Qn(t) = P{X(t) = n} = (Î»2t)n
n!
eâˆ’Î»2t.
We get from X1(t) and X2(t) being independent that
P{Y (t) = n}
=
P {X1(t) + X2(t) = n}
=
n

j=0
P {X1(t) = j} Â· P {X2(t) = n âˆ’j} =
n

j=0
(Î»1t)j
j!
eâˆ’Î»1t Â· (Î»2t)nâˆ’j
(n âˆ’j)! eâˆ’Î»2t
=
n

j=0
n!
j!(n âˆ’j)! Î»j
1 Â· Î»nâˆ’j
2
Â· tn
n! eâˆ’(Î»1+Î»2)t =
n

j=0
 n
j

Î»j
1Î»nâˆ’j
2
Â· tn
n! eâˆ’(Î»1+Î»2)t
=
(Î»1 + Î»2)n Â· tn
n! Â· exp (âˆ’(Î»1 + Î»2) t) .
It follows that {Y (t), t â‰¥0} is also a Poisson process (of intensity Î»1 + Î»2).
Example 2.3 A Geiger counter only records every second particle, which arrives to the counter.
Assume that the particles arrive according to a Poisson process of intensity Î». Denote by N(t) the
number of particles recorded in ]0, t], where we assume that the ï¬rst recorded particle is the second to
arrive.
1. Find P{N(t) = n}, n âˆˆN0.
2. Find E{N(t)}.
Let T denote the time diï¬€erence between two succeeding recorded arrivals.
3. Find the frequency of T.
4. Find the mean E{T}.
1. It follows from
Pn(t) = (Î»t)n
n!
eâˆ’Î»t,
n âˆˆN0,
that
P{N(t) = n}
=
P2n(t) + P2n+1(t) =
(Î»t)2n
(2n)! + (Î»t)2n+1
(2n + 1)!

eâˆ’Î»t
=
(Î»t)2n
(2n + 1)! (2n + 1 + Î»t)eâˆ’Î»t,
n âˆˆN0.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
21 
2. The Poisson process
2. The mean is
E{N(t)}
=
âˆ

n=0
n P{N(t) = n} = eâˆ’Î»t
 âˆ

n=1
n(Î»t)2n
(2n)!
+
âˆ

n=1
n(Î»t)2n+1
(2n + 1)!

=
eâˆ’Î»t

Î»t
2
âˆ

n=0
(Î»t)2n+1
(2n + 1)! +
âˆ

n=1
(n + 1
2)(Î»t)2n+1
(2n + 1)!
âˆ’1
2
âˆ

n=1
(Î»t)2n+1
(2n + 1)!

=
eâˆ’Î»t
Î»t
2 Â· sinh Î»t + Î»t
2 (cosh Î»t âˆ’1) âˆ’1
2 (sinh Î»t âˆ’Î»t)

=
eâˆ’Î»t
Î»t
2 Â· eÎ»t âˆ’1
4

eÎ»t âˆ’eâˆ’Î»t
= Î»t
2 âˆ’1
4 + 1
4 eâˆ’2Î»t.
3. & 4. It follows from T = Tj + Tj+1 that T âˆˆÎ“

2 , 1
Î»

, thus the frequency is
f(x) =
â§
â¨
â©
Î»2x eâˆ’Î»x
for x > 0,
0
for x â‰¤0,
and the mean is
E{T} = 2
Î».
Example 2.4 From a ferry port a ferry is sailing every quarter of an hour. Each ferry can carry N
cars. The cars are arriving to the ferry port according to a Poisson process of intensity Î» (measured
in quarterâˆ’1).
Assuming that there is no car in the ferry port immediately after a ferry has sailed at 900, one shall
1) ï¬nd the probability that there is no car waiting at 915 (immediately after the departure of the next
ferry),
2) ï¬nd the probability that no car is waiting at 930 (immediately after the departure of the next ferry).
3) A motorist arrives at p07 1
2 . What is the probability that he will not catch the ferry at p15, but
instead the ferry at 930?
Measuring t in the unit quarter of an hour we have
P{X(t) = n} = (Î»t)n
n!
eâˆ’Î»t,
n âˆˆN0.
1) From t = 1 follows that the wanted probability is
P{X(1) â‰¤N} =
N

n=0
Î»n
n! eâˆ’Î».
2) We have two possibilities:
Download free eBooks at bookboon.com

Stochastic Processes 2
 
22 
2. The Poisson process
a) Either there has arrived during the ï¬rst quarter of an hour â‰¤N cars, which are all carried
over, so we allow during the next quarter N cars to arrive,
b) or during the ï¬rst quarter N + j cars have arrived, 1 â‰¤j â‰¤N, and at most N âˆ’j cars in the
second quarter.
We therefore get the probability
P{X(1) â‰¤N} Â· P{X(1) â‰¤N} +
N

j=1
P{X(1) = N + j} Â· P{X(1) â‰¤N âˆ’j}
=
 N

n=0
Î»n
n! eâˆ’Î»
2
+
N

j=1
Î»N+j
(N + j)! eâˆ’Î» Â·
Nâˆ’j

n=0
Î»n
n! eâˆ’Î» = eâˆ’2Î»
â§
â¨
â©
 N

n=0
Î»n
n!
2
+
N

j=1
Nâˆ’j

n=0
Î»N+j+n
n!(N + j)!
â«
â¬
â­
= eâˆ’2Î»
â§
â¨
â©
 N

n=0
Î»n
n!
2
+
Nâˆ’1

n=0
Nâˆ’n

j=1
Î»N+j+n
n!(N + j)!
â«
â¬
â­.
3) Now the time 907 1
2 corresponds to t = 1
2, so the probability is
N

j=0
P

X
1
2

= N + j

= exp

âˆ’Î»
2
 2N

n=N
1
n!
Î»
2
n
.
Example 2.5 Paradox of waiting time.
Each morning Mr. Smith in X-borough takes the bus to his place of work. The busses of X-borough
should according to the timetables run with an interval of 20 minutes. It is, however, well-known in
X-borough that the busses mostly arrive at random times to the bus stops (meaning mathematically
that the arrivals of the busses follow a Poisson process of intensity Î» = 1
20 minâˆ’1, because the average
time diï¬€erence between two succeeding busses is 20 minutes).
One day when Mr. Smith is waiting extraordinary long time for his bus, he starts reasoning about how
long time he at the average must wait for the bus, and he develops two ways of reasoning:
1) The time distance between two succeeding buses is exponentially distributed of mean 20 minutes,
and since the exponential distribution is â€œforgetfulâ€, de average waiting time must be 20 minutes.
2) He arrives at a random time between two succeeding busses, so by the â€œsymmetryâ€ the average
waiting time is instead 1
2 Â· 20 minutes = 10 minutes.
At this time Mr. Smithâ€™s bus arrives, and he forgets to think of this contradiction.
Can you decide which of the two arguments is correct and explain the mistake in the wrong argument?
The argument of (1) is correct. The mistake of (2) is that the length of the time interval, in which
Mr. Smith arrives, is not exponentially distributed. In fact, there will be a tendency of Mr. Smith to
arrive in one of the longer intervals.
This is more precisely described in the following way. Let t denote Mr. Smithâ€™s arrival time. Then
Download free eBooks at bookboon.com

Stochastic Processes 2
 
23 
2. The Poisson process
1)
P{wait in more than x minutes} = P{N(t + x) âˆ’N(t) = 0} = P{N(x) = 0} = eâˆ’Î»x.
This shows that the waiting time is exponentially distribution of the mean 1
Î» = 20 minutes.
2) Let X1, X2, . . . , denote the lengths of the succeeding intervals between the arrivals of the busses.
By the assumptions, the Xk are mutually independent and exponentially distributed of parameter
Î».
Put
Sn =
n

k=1
Xk.
The surprise is that the Xk, for which
Sk =
k

j=1
Xk < t <
k+1

j+1
Xj = Sk+1,
have the frequency
(1) ft(x) =
â§
â¨
â©
Î»2x eâˆ’Î»x,
0 < x â‰¤t,
Î»(1 + Î»t)eâˆ’Î»x,
t < x.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
MASTER IN MANAGEMENT
mim.admissions@ie.edu
Follow us on IE MIM Experience
www.ie.edu/master-management
#10 WORLDWIDE
MASTER IN MANAGEMENT 
FINANCIAL TIMES
55 Nationalities
in class
5 Specializations
Personalize your program 
Length: 1O MONTHS
Av. Experience: 1 YEAR
Language: ENGLISH / SPANISH
Format: FULL-TIME
Intakes: SEPT / FEB
â€¢ STUDY IN THE CENTER OF MADRID AND TAKE ADVANTAGE OF THE UNIQUE OPPORTUNITIES
  THAT THE CAPITAL OF SPAIN OFFERS
â€¢ PROPEL YOUR EDUCATION BY EARNING A DOUBLE DEGREE THAT BEST SUITS YOUR
  PROFESSIONAL GOALS
â€¢ STUDY A SEMESTER ABROAD AND BECOME A GLOBAL CITIZEN WITH THE BEYOND BORDERS
  EXPERIENCE
93%
OF MIM STUDENTS ARE
WORKING IN THEIR SECTOR 3 MONTHS
FOLLOWING GRADUATION

Stochastic Processes 2
 
24 
2. The Poisson process
We shall now prove (1). First notice that the frequencies of the Sn are given by
gn(x) =
Î»n
(n âˆ’1)! xnâˆ’1eâˆ’Î»x,
x > 0.
(a) First assume that x < t. Then the even occurs that the interval has the length â‰¤x, if
Sn = y
and
t âˆ’y < Xn+1 â‰¤x,
for some combination of n and y, where t âˆ’x < y â‰¤t.
Then
Ft(x)
=
âˆ

n=1
 t
tâˆ’x
gn(y)

eâˆ’Î»(tâˆ’y) âˆ’eâˆ’Î»x
dy =
 t
tâˆ’x
 âˆ

n=1
gn(y)

Â·

eâˆ’Î»(tâˆ’y) âˆ’eâˆ’Î»x
dy
=
 t
tâˆ’x
Î»

eâˆ’Î»teÎ»y âˆ’eâˆ’Î»x
dy = Î»eâˆ’Î»t
 t
tâˆ’x
eÎ»ydy âˆ’Î»xeâˆ’Î»x = 1 âˆ’eâˆ’Î»x âˆ’Î»xeâˆ’Î»x,
where we have used that
âˆ

n=1
gn(y) = Î»
âˆ

n=1
(Î»y)nâˆ’1
(n âˆ’1)! eâˆ’Î»y = Î».
By a diï¬€erentiation,
ft(x) = Î»2xeâˆ’Î»x
for x â‰¤t.
(b) Then let x > t. The event occurs that the interval has length â‰¤x, if either
Sn = y
and
t âˆ’y < Xn+1 â‰¤x
for some combination of n and y, or if S1 âˆˆ[t, x].
Then
Ft(x)
=
âˆ

n=1
 t
0
gn(y)

eâˆ’Î»(tâˆ’y) âˆ’eâˆ’Î»x
dy +

eâˆ’Î»t âˆ’eâˆ’Î»x
=
Î»
 t
0

eâˆ’Î»(tâˆ’y) âˆ’eâˆ’Î»x
dy +

eâˆ’Î»t âˆ’eâˆ’Î»x
=
1 âˆ’eâˆ’Î»t âˆ’Î»teâˆ’Î»x + eâˆ’Î»t âˆ’eâˆ’Î»x = 1 âˆ’(1 + Î»t)eâˆ’Î»x.
By diï¬€erentiation,
ft(x) = Î»(1 + Î»t)eâˆ’Î»x,
for x > t.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
25 
2. The Poisson process
We have now found the distribution, so we can compute the mean
Î¼(t)
=
 âˆ
0
xft(x) dx =
 t
0
Î»2x2eâˆ’Î»x dx +
 âˆ
t
Î»x(1 + Î»t)eâˆ’Î»x dx
=

âˆ’Î»x3eâˆ’Î»xt
0 + 2
 t
0
Î»xeâˆ’Î»x dx + (1 + Î»t)
 âˆ
t
Î»xeâˆ’Î»xdx
=

âˆ’Î»x2eâˆ’Î»xâˆ’2xeâˆ’Î»x1
0+2
 t
0
eâˆ’Î»x dx+(1+Î»t)

âˆ’xeâˆ’Î»xâˆ’1
Î» eâˆ’Î»x
âˆ
t
=
âˆ’Î»t2eâˆ’Î»t âˆ’2teâˆ’Î»t + 2
Î»

1 âˆ’eâˆ’Î»t
+ (1 + Î»t)

teâˆ’Î»t + 1
Î» eâˆ’Î»t

=
âˆ’Î»t2eâˆ’Î»tâˆ’2teâˆ’Î»t+ 2
Î» âˆ’2
Î» eâˆ’Î»t+teâˆ’Î»t+ 1
Î» eâˆ’Î»t+Î»t2eâˆ’Î»t+teâˆ’Î»t
=
2
Î» âˆ’1
Î» eâˆ’Î»t.
An interpretation of this result is that for large values of t, i.e. when the Poisson process has been
working for such a long time that some buses have arrived, then the mean is almost equal to 2
Î», and
deï¬nitely not 1
Î», which Mr. Smith tacitly has used in his second argument.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Stochastic Processes 2
 
26 
2. The Poisson process
Example 2.6 Denote by {X(t), t â‰¥0} a Poisson process of intensity a, and let Î¾ be a ï¬xed positive
number. We deï¬ne a random variable V by
V = inf{v â‰¥Î¾ | there is no event from the Poisson process in the interval ]v âˆ’Î¾, v]}.
xi
V
tau_4
tau_3
tau_2
tau_1
0
(On the ï¬gure the Ï„i indicate the times of the i-th event of the Poisson process, V the ï¬rst time when
we have had an interval of length Î¾ without any event).
1) Prove that the distribution function F(v) of V fulï¬ls
(2) F(v) =
â§
â¨
â©
eâˆ’aÎ¾ +
	 Î¾
0 F(v âˆ’x) a eâˆ’ax dx,
v â‰¥Î¾,
0,
v < Î¾.
2) Prove that the Laplace transform of V is given by
L(Î») = (a + Î»)eâˆ’(a+Î»)Î¾
Î» + a eâˆ’(a+Î»)Î¾ .
Hint: Use that
 âˆ
0
F(v) eâˆ’Î»v dv = 1
Î» L(Î»)
for Î» > 0.
3) Find the mean E{V }.
(In one-way single-track street cars are driving according to a Poisson process of intensity a; a pedes-
trian needs the time Î¾ to cross the street; then V indicates the time when he has come safely across
the street).
The assumptions are
P{X(t) = n} = (a t)n
n!
eâˆ’at,
n âˆˆN0,
and
P {T1 > t} = P{X(t) = 0} = eâˆ’at.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
27 
2. The Poisson process
1) Clearly, F(v) = 0 if v < Î¾. If v = Î¾, then
F(v) = F(Î¾) = P {T1 > Î¾} = P{X(Î¾) = 0} = eâˆ’aÎ¾.
If v > Î¾, then Ï„i = v âˆ’Î¾ and v âˆ’x âˆˆ]v âˆ’Î¾, c] for x âˆˆ[0, Î¾[, and we are led to the following
computation
F(v)
=
P{V â‰¤v} = P{V = Î¾} + P{Î¾ < V â‰¤v} = eâˆ’aÎ¾ + P{Î¾ < V â‰¤v}
=
eâˆ’aÎ¾ +
 v
x=vâˆ’Î¾
P{V = x} dP{T > v âˆ’x}
(3)
=
eâˆ’aÎ¾ +
 0
Î¾
P{V = v âˆ’x} dP{T > x} = eâˆ’aÎ¾ +
 0
Î¾
F(v âˆ’x) deâˆ’ax
=
eâˆ’aÎ¾ +
 Î¾
0
F(v âˆ’x) a eâˆ’ax dx.
Here (3) is a generalized sum (i.e. an integral), where V = x and T > v âˆ’x, which of course will
contribute to F(v).
2) If L(Î») =
	 âˆ
0
f(v) eâˆ’Î»v dv then the Laplace transform of V is
 âˆ
0
F(v) eâˆ’Î»v dv = 1
Î»
 âˆ
0
f(v) eâˆ’Î»v dv = 1
Î» L(Î»)
for Î» > 0.
When we Laplace transform the result of (2), then
1
Î» L(Î»)
=
1
Î» eâˆ’aÎ¾eâˆ’aÎ»Î¾ +
 âˆ
0
 Î¾
0
F(v âˆ’x) a eâˆ’ax dx

eâˆ’Î»v dv
=
1
Î» eâˆ’(a+Î»)Î¾ +
 Î¾
0
 âˆ
0
F(v âˆ’x) eâˆ’Î»v dv

a eâˆ’ax dx
=
1
Î» eâˆ’(a+Î»)Î¾ +
 Î¾
0
 âˆ
x
F(v âˆ’x) eâˆ’Î»v dv

a eâˆ’ax dx
=
1
Î» eâˆ’(a+Î»)Î¾ +
 Î¾
0
 âˆ
0
F(v) eâˆ’Î»v dv

eâˆ’Î»x Â· a eâˆ’ax dx
=
1
Î» eâˆ’(a+Î»)Î¾ + 1
Î» L(Î») Â· a
 Î¾
0
eâˆ’(Î»+a)x dx
=
1
Î» eâˆ’(a+Î»)Î¾ + 1
Î» L(Î») Â·
a
a + Î»

1 âˆ’eâˆ’(a+Î»)Î¾
,
thus
eâˆ’(a+Î»)Î¾ = L(Î») Â·

1 âˆ’
a
a + Î» +
a
a + Î» eâˆ’(a+Î»)Î¾

= L(Î») Â· Î» + a eâˆ’(a+Î»)Î¾
a + Î»
,
and hence
L(Î») = (a + Î»)eâˆ’(a+Î»)Î¾
Î» + a eâˆ’(a+Î»)Î¾ .
Download free eBooks at bookboon.com

Stochastic Processes 2
 
28 
2. The Poisson process
3) The mean is
E{V }
=
âˆ’Lâ€²(0)
=
lim
Î»â†’0+

eâˆ’(a+Î»)Î¾ âˆ’Î¾(a + Î»)eâˆ’(a+Î»)Î¾
Î» + a eâˆ’(a+Î»)Î¾
âˆ’(a + Î»)eâˆ’(a+Î»)Î¾ Â·

1 âˆ’a Î¾ eâˆ’(a+Î»)Î¾

Î» + a eâˆ’(a+Î»)Î¾2

=
âˆ’

eâˆ’aÎ¾ âˆ’Î¾ a eâˆ’aÎ¾
a eâˆ’aÎ¾
âˆ’a eâˆ’aÎ¾ 
1 âˆ’a Î¾ eâˆ’aÎ¾
(a eâˆ’aÎ¾)2

= âˆ’eâˆ’aÎ¾ + Î¾ a eâˆ’aÎ¾ + 1 âˆ’a Î¾ eâˆ’aÎ¾
a eâˆ’aÎ¾
=
1 âˆ’eâˆ’aÎ¾
a eâˆ’aÎ¾
= 1
a

eaÎ¾ âˆ’1

.
Example 2.7 To a taxi rank taxis arrive from the south according to a Poisson process of intensity
a, and independently there also arrive taxis from the north according to a Poisson process of intensity
b.
We denote by X the random variable which indicates the number of taxies, which arrive from the
south in the time interval between two succeeding taxi arrivals from the north.
Find P{X = k}, k âˆˆN0, as well as the mean and variance of X.
The length of the time interval between two succeeding arrivals from the north has the frequency
f(t) = b eâˆ’bt,
t > 0.
When this length is a (ï¬xed) t, then the number of arriving taxies from the south is Poisson distributed
of parameter a t. By the law of total probability,
P{X = k}
=
 âˆ
0
(a t)k
k!
eâˆ’at Â· b eâˆ’kt dt = b ak
k!
 âˆ
0
tkeâˆ’(a+b)t dt
=
b ak
k! Â·
k!
(a + b)k+1 =

a
a + b
k
Â·
b
a + b,
k âˆˆN0,
so X âˆˆNB

1,
b
a + b

is negative binomially distributed..
It follows by some formula in any textbook that
E{X} = 1 Â· a
b = a
b
and
V {X} = a(a + b)
b2
= a
b

1 + a
b
 
.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
29 
2. The Poisson process
Example 2.8 The number of car accidents in a given region is assumed to follow a Poisson process
{X(t), t âˆˆ[0, âˆ[} of intensity Î», and the number of persons involved in the i-th accident is a random
variableYi, which is geometrically distributed,
P {Yi = k} = p qkâˆ’1,
k âˆˆN,
where p > 0, q > 0 and p + q = 1. We assume that the Yi are mutually independent, and independent
of {X(t), t â‰¥0}.
1. Find the generating function of X(t).
2. Find the generating function of Yi.
Denote by Z(t) the total number of persons involved in accidents in the time interval ]0, t].
3. Describe the generating function of Z(t) expressed by the generating function of Yi and the gener-
ating function of X(t).
Hint: Use that
P{Z(t) = k} =
âˆ

i=0
P {X(t) = i âˆ§Y1 + Y2 + Â· Â· Â· + Yi = k} .
4. Compute E{Z(t)} and V {Z(t)}.
1) Since X(t) is a Poisson process, we have
P{X(t) = k} = (Î» t)k
k!
eâˆ’Î»t,
k âˆˆN0.
We ï¬nd its generating function by using a table,
PX(t)(s) = exp(Î»t(s âˆ’1)).
2) Also, by using a table, the generating function of Yi is
PYi(s) =
p(s)
1 âˆ’q s.
The Yi are mutually independent, so the generating function of Y1 + Â· Â· Â· + Yi is given by

ps
1 âˆ’qs

,
i âˆˆN.
3) The generating function of Z(t) is
PZ(t)(s)
=
âˆ

k=0
P{Z(t) = k} sk =
âˆ

k=0
 âˆ

i=0
P {X(t) = i âˆ§Y1 + Â· Â· Â· + Yi = k}

sk
=
âˆ

i=1
P{X(t) = i}
 âˆ

k=0
P {Y1 + Â· Â· Â· + Yi = k) sk

=
âˆ

i=1
P{X(t) = i}

ps
1 âˆ’qs

= PX(t)

ps
1 âˆ’qs

= exp

Î»t

ps
1 âˆ’qs âˆ’1

=
exp

Î» t
 s âˆ’1
1 âˆ’qs

= exp

Î»t
p
q Â·
1
1 âˆ’qs âˆ’1

.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
30 
2. The Poisson process
4) It follows from
P â€²
Z(t)(s) = Î»t Â·
p
(1 âˆ’qs)2 PZ(t)(s)
med
P â€²
Z(t)(1) = Î»t
p ,
and
P â€²â€²
Z(t)(s) =

Î»t Â·
p
(1 âˆ’qs)2
2
PZ(t)(s) + Î»t Â·
2pq
(1 âˆ’qs)3 PZ(t)(s),
where
P â€²â€²
Z(t)(1) =
Î»t
p
2
+ Î»t Â· 2q
p2 ,
that
E{Z(t)} = P â€²
Z(t)(1) = Î»t
p
and
V {Z(t)}
=
P â€²â€²(1) + P â€²(1) âˆ’(P â€²(t))2 =
Î»t
p
2
+ Î»t Â· 2q
p2 + Î»t
p âˆ’
Î»t
p
2
=
Î»t Â· 2q + p
p2
= Î»t Â· 1 + q
p2 .
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
â€œThe perfect start 
of a successful, 
international career.â€
CLICK HERE 
to discover why both socially 
and academically the University 
of Groningen is one of the best 
places for a student to be 
www.rug.nl/feb/education
Excellent Economics and Business programmes at:

Stochastic Processes 2
 
31 
2. The Poisson process
Example 2.9 (Continuation of Example 2.8).
Assume that the number of car accidents in a city follows a Poisson process {X(t), t âˆˆ[0, âˆ[} of
intensity 2 per day. The number of persons involved in one accident is assumed to be geometrically
distributed with p = 1
2.
Find the mean and variance of the number of persons involved in car accidents in the city per week.
It follows from Example 2.8 that
E{Z(t)} = Î»t
p
and
V {Z(t)} = Î»t Â· 1 + q
p2 .
In the speciï¬c case the intensity is Î» = 2, and the time span is t = 7 days. Furthermore, p = q = 1
2,
thus
E{Z(7)} = 2 Â· 7
1
2
= 28
and
V {Z(7)} = 2 Â· 7 Â· 1 + 1
2
 1
2
2 = 2 Â· 7 Â· 6 = 84.
Example 2.10 Given a service to which customers arrive according to a Poisson process of intensity
Î» (measured in the unit minutâˆ’1).
Denote by I1, I2 and I3 three succeeding time intervals, each of the length of 1 minute.
1. Find the probability that there is no customer in any of the three intervals.
2. Find the probability that there is precisely one arrival of a customer in one of these intervals and
none in the other two.
3. Find the probability that there are in total three arrivals in the time intervals I1, I2 and I3, where
precisely two of them occur in one of these intervals.
4. Find the value of Î», for which the probability found in 3. is largest.
Then consider 12 succeeding time intervals, each of length 1 minute. Let the random variable Z denote
the number of intervals, in which we have no arrival.
5. Find the distribution of Z.
6. For Î» = 1 ï¬nd the probability P{Z = 4} (2 dec.).
1) Let
I1 = ]0, 1],
I2 = ]1, 2],
I3 = ]2, 3].
Then
P{no event in I1 âˆªI2 âˆªI3 = ]0, 3]} =

eâˆ’Î»3 = eâˆ’3Î».
Download free eBooks at bookboon.com

Stochastic Processes 2
 
32 
2. The Poisson process
2) By a rearrangement,
P{one event in one interval, none in the other two} = P{one event in ]0, 3]} = 3Î» eâˆ’3Î».
3) We have
P{two events in one interval, one in another one, and none in the remaining one}
= P{two events in one interval, one in the remaining two intervals}
= 3 Â· Î»2
2 Â· eâˆ’Î» Â· 2Î» eâˆ’2Î» = 3Î»3eâˆ’3Î».
4) We conclude from 3. that g(Î») = 3Î»3eâˆ’3Î» > 0 for Î» > 0 with g(Î») â†’0 for Î» â†’0+, and for
Î» â†’âˆ. By a diï¬€erentiation,
gâ€²(Î») =

9Î»2 âˆ’9Î»3
eâˆ’3Î» = 9Î»2(1 âˆ’Î»)eâˆ’3Î» = 0
for Î» = 1 > 0,
thus the probability is largest for Î» = 1 med g(1) = 3 eâˆ’3.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
American online      
LIGS University 
â–¶â–¶enroll by September 30th, 2014 and 
â–¶â–¶save up to 16% on the tuition!
â–¶â–¶pay in 10 installments / 2 years
â–¶â–¶Interactive Online education
â–¶â–¶visit www.ligsuniversity.com to 
      find out more!
is currently enrolling in the
Interactive Online BBA, MBA, MSc, 
DBA and PhD  programs:
Note: LIGS University is not accredited by any 
nationally recognized accrediting agency listed 
by the US Secretary of Education. 
More info here. 

Stochastic Processes 2
 
33 
2. The Poisson process
5) Assume now that we have 12 intervals. From
P{no arrival in an interval} = eâˆ’Î»,
we get
P{Z = k} =
 12
k

eâˆ’Î»k 
1 âˆ’eâˆ’Î»12âˆ’k ,
k = 0, 1, 2, . . . , 12,
thus Z âˆˆB

12, eâˆ’Î»
.
6) By insertion of Î» = 1 an k = 4 into the result of 5. we get
P{Z = 4} =
 12
4
 
eâˆ’1 
1 âˆ’eâˆ’124
= 495 Â·

0.3679 Â· 0.632124 = 0.2313 â‰ˆ0.23.
Example 2.11 A random variable X is Poisson distributed with parameter a.
1. Compute the characteristic function of X.
2. Prove for large values of a that X is approximately normally distributed of mean a and variance a
(more precisely,
lim
nâ†’âˆP
X âˆ’a
âˆša
â‰¤x

= Î¦(x)
for all x âˆˆR).
To a service customers arrive according to a Poisson process of intensity Î» = 1 minutâˆ’1. Denote by
X the number of customers who arrive in a time interval of length 100 minutes.
3. Apply Chebyshevâ€™s inequality to ï¬nd an lower bound of
(4) P{80 < X < 120}.
4. Find an approximate expression of (4) by using the result of 2..
1) We get from
P{X = k} = ak
k! eâˆ’a,
k âˆˆN0,
the characteristic function
kX(Ï‰) =
âˆ

k=0
eiÏ‰k Â· ak
k! eâˆ’a = eâˆ’a
âˆ

k=0
1
k!

eiÏ‰ a
k = eâˆ’a Â· exp

a Â· eiÏ‰
= exp

a

eiÏ‰ âˆ’1

.
2) Put
Xa = X âˆ’a
âˆša .
Download free eBooks at bookboon.com

Stochastic Processes 2
 
34 
2. The Poisson process
Then the characteristic function of Xa is given by
kXa(Ï‰)
=
âˆ

k=0
exp

iÏ‰ Â· k âˆ’a
âˆša
 ak
k! eâˆ’a = eâˆ’iÏ‰âˆša Â· eâˆ’a
âˆ

k=0
1
k!

a Â· exp

i Ï‰
âˆša
k
=
eâˆ’iÏ‰âˆša Â· eâˆ’a exp

a Â· exp

i Ï‰
âˆša

= exp

a

exp
 iÏ‰
âˆša

âˆ’1

âˆ’iÏ‰âˆša

.
It follows from
a

exp
 iÏ‰
âˆša

âˆ’1

âˆ’iÏ‰âˆša
=
a

1 + iÏ‰
âˆša âˆ’1
2!
Ï‰2
a + 1
a Îµ
1
a

âˆ’1

âˆ’iÏ‰âˆša
=
âˆ’1
2 Ï‰2 + Îµ
1
a

â†’âˆ’1
2 Ï‰2
for a â†’âˆ,
that
k(Ï‰) = lim
aâ†’âˆkXa(Ï‰) = exp

âˆ’1
2 Ï‰2

,
hence k(Ï‰) is the characteristic function of a normally distributed random variable from N(0, 1).
It follows that {Xa} for a â†’âˆconverges in distribution towards the normal distribution N(0, 1),
thus
lim
aâ†’âˆP
X âˆ’a
âˆša
â‰¤x

= Î¦(x)
for every x âˆˆR.
3) If t = 100 and Î» = 1 minutâˆ’1, then
P{X = n} = 100n
n!
eâˆ’100,
n âˆˆN0,
hence a = 100 and Ïƒ2 = 100. Then by Chebyshevâ€™s inequality
P{|X âˆ’100| â‰¥20} â‰¤100
202 = 1
4,
so
P{80 < X < 120} = 1 âˆ’P{|X âˆ’100| â‰¥20} â‰¥1 âˆ’1
4 = 3
4.
4) An approximate expression of
P{80 < X < 120} = P{|X âˆ’100| < 20} = P
!!!!
X âˆ’100
10
!!!! < 2

is then by 2. given by
Î¦(2) âˆ’Î¦(âˆ’2) = 2Î¦(2) âˆ’1 â‰ˆ2 Â· 0.9772 âˆ’1 = 0.9544.
However, since X is an integer, we must here use the correction of continuity. Then the interval
should be 80.5 < x < 119.5. We get the improved approximate expression,
P{80.5 < X < 119.5}
=
P{|X âˆ’100| < 19.5} = P
!!!!
X âˆ’100
10
!!!! < 1.95

=
Î¦(1.95) âˆ’Î¦(1.95) = 2Î¦(1.95) âˆ’1
â‰ˆ
2 Â· 0.9744 âˆ’1 = 0, 9488.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
35 
2. The Poisson process
Remark 2.1 For comparison a long and tedious computation on a pocket calculator gives
P{80 < X < 120} â‰ˆ0.9491.
â™¦
Example 2.12 In a shop there are two shop assistants A and B. Customers may freely choose if they
will queue up at A or at B, but they cannot change their decision afterwards. For all customers at A
their serving times are mutually independent random variables of the frequency
f(x) =
â§
â¨
â©
Î» eâˆ’Î»x,
x > 0,
0,
x â‰¤0,
(Î» is a positive constant),
and for the customers at B the serving times are mutually independent random variables of frequency
g(y) =
â§
â¨
â©
2Î» eâˆ’2Î»y,
y > 0,
0,
y â‰¤0.
At a given time Andrew arrives and is queueing up at A, where there in front of him is only one
customer, and where the service of this customer has just begun. We call the serving time of this
customer X1, while Andrewâ€™s serving time is called X2.
At the same time Basil arrives and joins the queue at B, where there in front of him are two waiting
customers, and where the service of the ï¬rst customer has just begun. The service times of these two
customers are denoted Y1 and Y2, resp..
1. Find the frequencies of the random variables X1 + X2 and Y1 + Y2.
2. Express by means of the random variables Y1, Y2 and X1 the event that the service of Basil starts
after the time when the service of Andrew has started, and ï¬nd the probability of this event.
3. Find the probability that the service of Basil starts after the end of the service of Andrew.
Assume that the customers arrive to the shop according to a Poisson process of intensity Î±.
4. Find the expected number of customers, who arrive to the shop in a time interval of length t.
5. Let N denote the random variable, which indicates the number of customers who arrive to the shop
during the time when Andrew is in the shop (thus X1 + X2). Find the mean of N.
1) Since Xi âˆˆÎ“

1, 1
Î»

is exponentially distributed we have X1 + X2 âˆˆÎ“

2, 1
Î»

, thus
fX1+X2(x) =
â§
â¨
â©
Î»2x eâˆ’Î»x,
x â‰¥0,
0,
x < 0,
Since Yi âˆˆÎ“

1, 1
2Î»

, we have Y1 + Y2 âˆˆÎ“

2, 1
2Î»

with the frequency
gY1+Y2(y) =
â§
â¨
â©
4Î»2y eâˆ’2Î»y,
y â‰¥0,
0,
y < 0.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
36 
2. The Poisson process
2) The event is expressed by X1 < Y1 + Y2. The probability of this event is
P {X1 < Y1 + Y2}
=
 
{0<x<y}
Î» eâˆ’Î»x Â· 4Î»2y eâˆ’2Î»y dx dy
=
 âˆ
0
4Î»2y eâˆ’2Î»y
 y
0
Î» eâˆ’Î»x dx

dy
=
 âˆ
0
4Î»2y eâˆ’2Î»y 
âˆ’eâˆ’Î»xy
x=0 dy
=
 âˆ
0
4Î»2y eâˆ’2Î»y dy âˆ’
 âˆ
0
4Î»2y eâˆ’3Î»y dy
=
 âˆ
0
t eâˆ’t dt âˆ’4
9
 âˆ
0
t eâˆ’t dt = 5
9.
3) We must have in this case that X1 + X2 < Y1 + Y2. Hence the probability is
P {X1 + X2 < Y1 + Y2} =
 
{0<x<y}
Î»2x eâˆ’Î»x Â· 4Î»2y eâˆ’2Î»y dx dy
=
 âˆ
0
4Î»2y eâˆ’2Î»y
 y
0
Î»2x eâˆ’Î»x dx

dy =
 âˆ
0
4Î»2y eâˆ’2Î»y

âˆ’Î»x eâˆ’Î»xy
0 +
 y
0
Î» eâˆ’Î»x dx

dy
=
 âˆ
0
4Î»2y eâˆ’2Î»y
 y
0
Î» eâˆ’Î»x dx âˆ’
 âˆ
0
4Î»3y2eâˆ’3Î»y dy
= P {X1 < Y1 + Y2} âˆ’4
27
 âˆ
0
(3Î»)3y2eâˆ’3Î»y dy = 5
9 âˆ’4
27 Â· 2 = 15 âˆ’8
27
= 7
27.
4) If X(t) indicates the number of arrived customers in ]0, t], then
P{X(t) = n} = (Î±t)n
n!
eâˆ’Î±t,
n âˆˆN0,
and
m(t) = E{X(t)} =
âˆ

n=0
n (Î±t)n
n!
eâˆ’Î±t = Î± t.
5) Finally, (cf. 4.),
E{N} = Î± E {X1 + X2} = Î±
 1
Î» + 1
Î»

= 2Î±
Î» .
Download free eBooks at bookboon.com

Stochastic Processes 2
 
37 
3. Birth and death processes
3
Birth and death processes
Example 3.1 Consider a birth process {X(t), t âˆˆ[0, âˆ[} of states E0, E1, E2, . . . and positive birth
intensities Î»k. The diï¬€erential equations of the process are
â§
â¨
â©
P â€²
0(t) = âˆ’Î»0P0(t),
P â€²
k(t) = âˆ’Î»kPk(t) + Î»kâˆ’1Pkâˆ’1(t),
k âˆˆN,
and we assume that the process at t = 0 is in state E0. It can be proved that the diï¬€erential equations
have a uniquely determined solution (Pk(t)) satisfying
Pk(t) â‰¥0,
âˆ

k=0
Pk(t) â‰¤1.
One can also prove that either 
âˆ
k=0 Pk(t) = 1 for all t > 0, or 
âˆ
k=0 Pk(t) < 1 for all t > 0.
Prove that

âˆ
k=0 Pk(t) = 1 for all t > 0, if and only if 
âˆ
k=0
1
Î»k
is divergent.
Hint: First prove that
1
Î»k
a(t) â‰¤
 t
0
Pk(s) ds â‰¤1
Î»k
,
k âˆˆN0,
t > 0,
where a(t) = 1 âˆ’
âˆ
k=0 Pk(t).
We get by a rearrangement and recursion,
Î»kPk(t) = âˆ’P â€²
k(t) + Î»kâˆ’1Pkâˆ’1(t) = âˆ’P â€²
k(t) âˆ’P â€²
kâˆ’1(t) + Î»kâˆ’2Pkâˆ’2(t) = Â· Â· Â· = âˆ’
k

j=0
P â€²
j(t),
hence by integration,
Î»k
 t
0
Pk(s) ds =
â¡
â£âˆ’
k

j=0
Pj(s)
â¤
â¦
t
0
=
k

j=0
Pj(0)Pj(t) = 1 âˆ’
k

j=0
Pj(t),
because at time t = 0 we are in state E0, so P0(0) = 0, and Pj(0) = 0, j âˆˆN.
Thus we have the estimates
a(t) = 1 âˆ’
âˆ

j=0
Pj(t) â‰¤1 âˆ’
k

j=0
Pj(t) = Î»k
 t
0
Pk(s) ds â‰¤1,
from which
1
Î»k
a(t) â‰¤
 t
0
Pk(s) ds â‰¤1
Î»k
.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
38 
3. Birth and death processes
Assume that 
âˆ
k=0 Pk(t) = 1. Applying the theorem of monotonous convergence (NB The Lebesgue
integral!) it follows from the right hand inequality that
âˆ

k=0
1
Î»l
â‰¥
âˆ

k=0
 t
0
Pk(s) ds =
 t
0
âˆ

k=0
Pk(s) ds =
 t
0
1 dt = t
for alle t âˆˆR+,
proving that the series 
âˆ
k=0
1
Î»k
is divergent.
Then assume that 
âˆ
k=0 Pk(t) < 1, thus
a(t) = 1 âˆ’
âˆ

k=0
Pk(t) > 0.
Using the theorem of monotonous convergence and the left hand inequality we get

k=0
1
Î»k

Â· a(t) â‰¤
âˆ

k=0
 t
0
Pk(s) ds â‰¤t
for all t âˆˆR+.
Now a(t) > 0, so this implies that
âˆ

k=0
1
Î»k
â‰¤
t
a(t) < âˆ,
and the series 
âˆ
k=0
1
Î»k
is convergent.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Stochastic Processes 2
 
39 
3. Birth and death processes
Example 3.2 To a carpark, cars arrive from 900 (t = 0) following a Poisson process of intensity Î».
There are in total N parking bays, and we assume that no car leaves the carpark. Let En, n = 0, 1,
. . . , N, denote the state that n of the parking bays are occupied.
1) Find the diï¬€erential equations of the system.
2) Find Pn(t), n = 0, 1, . . . , N.
3) Find the stationary probabilities pn, n = 0, 1, . . . , N.
Put Î» = 1 minuteâˆ’1 and N = 5. Find the probability that a car driver who arrives at 903 cannot ï¬nd
a vacant parking bay.
1) This is a pure birth process with
Î»n =
â§
â¨
â©
Î»
for n = 0, 1, . . . , N âˆ’1,
0
for n = N,
and the system of diï¬€erential equations
P â€²
0(t)
=
âˆ’Î» P0(t),
P â€²
n(t)
=
âˆ’Î» Pn(t) + Î» Pnâˆ’1(t),
n = 1, 2, . . . , N âˆ’1,
P â€²
N(t)
=
Î» PNâˆ’1(t),
and initial conditions
Pn(0) =
â§
â¨
â©
1
for n = 0,
0
for n > 0.
2) The system of 1. can either be solved successively or by consulting a textbook,
Pn(t) =
â§
âª
âª
âª
â¨
âª
âª
âª
â©
eâˆ’Î»t (Î»t)n
n!
,
n = 0, 1, 2, . . . , N âˆ’1,
1 âˆ’
Nâˆ’1
n=0
(Î»t)n
n!
eâˆ’Î»t,
n = n.
3) It follows immediately that
Pn(t) â†’

0,
n < N,
1,
n = N,
for t â†’âˆ,
thus
pn =
â§
â¨
â©
0,
n < N,
1,
n = n.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
40 
3. Birth and death processes
4) First identify
Î» = 1 minuteâˆ’1,
t = 3
and
N = 5.
Then by insertion,
P

no parking bay at 903
= P5(3) = 1 âˆ’
4

n=0
Pn(3) = 1 âˆ’
4

n=0
3n
n! eâˆ’3 = 0.1847 â‰ˆ0.185.
Example 3.3 Given a stochastic birth and death process X(t), t âˆˆ[0, âˆ[}, which can be in the states
E4, E5, E6 and E7.
Assume that the birth intensity Î»k is in state Ek given by
Î»k = Î±k(7 âˆ’k),
and that the death intensity Î¼k in state Ek is equal to
Î¼k = Î²k(k âˆ’4),
where Î± and Î² are positive constants.
Find the stationary probabilities in each of the two cases below
1) Î² = Î±,
2) Î² = 2Î±.
The equations of equilibrium are here
Î¼k+1pk+1 = Î»kpk
for k = 4, 5, 6.
Thus
p5
=
Î»4
Î¼5
p4 = 12Î±
5Î² p4 = 12
5
Î±
Î²
1
p4,
p6
=
Î»5
Î¼6
p5 = 10Î±
12Î² Â· 12
5
Î±
Î² = 2
Î±
Î²
2
p4,
p7
=
Î»6
Î¼7
p6 = 6Î±
21Î² Â· 2
Î±
Î²
2
= 4
7
Î±
Î²
3
p4.
Furthermore,
p4 + p5 + p6 + p7 = 1.
However, the exact values can ï¬rst be found when we know the relationship between Î± and Î².
1) If Î² = Î±, then
1 = p4

1 + 12
5 + 2 + 4
7

= 35 + 84 + 70 + 20
35
p4 = 209
35 p4,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
41 
3. Birth and death processes
hence
p4 = 35
209,
p5 = 12
5 Â· 35
209 = 84
209,
p6 = 70
209,
p7 = 4
7 Â· 35
209 =
20
2 + 9,
so
p = (p4, p5, p6, p7) =
1
209 (35, 84, 70, 20).
2) If Î² = 2Î±, then Î±
Î² = 1
2, hence
p5 = 6
5 p4,
p6 = 1
2 p4,
p7 = 1
14 p4,
and
1 = p4 + p5 + p6 + p7 = p4

1 + 6
5 + 1
2 + 1
14

= 70 + 84 + 35 + 5
70
p4 = 97
35 p4,
from which
p4 = 35
97,
p5 = 42
97,
p6 = 35
194,
p7 =
5
194,
i.e.
p = (p4, p5, p6, p7) =
1
194 (70, 84, 35, 5).
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
 
  
 
                . 

Stochastic Processes 2
 
42 
3. Birth and death processes
Example 3.4 Given a birth and death process of the states E0, E1, E2, . . . , birth intensities Î»k and
death intensities Î¼k. Assume furthermore that
a. Î»k = Î¼k = k Î±, k âˆˆN0, (where a is a positive constant).
b. P1(0) = 1.
1. Find the diï¬€erential equations of the process.
One may now without proof use that under the assumptions above,
P1(t) =
1
(1 + Î±t)2 .
2. Find P0(t), P2(t) and P3(t).
3. Sketch the graph of P0(t) + P1(t).
4. Sketch the graph of P2(t).
5. Find limtâ†’âˆPn(t) for every n âˆˆN0.
1) We have
P â€²
0(t) = âˆ’Î»0P0(t) + Î¼1P1(t) = Î± P1(t),
and
P â€²
k(t)
=
âˆ’(Î»k + Î¼k) Pk(t) + Î»kâˆ’1Pkâˆ’1(t) + Î¼k+1Pk+1(t)
=
(k âˆ’1)Î±Pkâˆ’1(t) âˆ’2kÎ±Pk(t) + (k + 1)Î±Pk+1(t)
for k âˆˆN.
2) If P1(0) = 1, then Pk(0) = 0 for k âˆˆN0 \ {1}. It follows from
P â€²
0(t) = Î± P1(t) =
Î±
(1 + Î±t)2 ,
by an integration that
P0(t) =
 t
0
Î± dÏ„
(1 + Î±Ï„)2 =

âˆ’
1
1 + Î±Ï„
t
0
= 1 âˆ’
1
1 + Î±t =
Î±t
1 + Î±t.
If k = 1, we get by a rearrangement,
P2(t)
=
1
2Î± {P â€²
1(t) âˆ’0 Â· P0(t) + 2Î± P1(t)} = 1
2Î±

âˆ’
2Î±
(1 + Î±t)3 +
2Î±
(1 + Î±t)2

=
1
(1 + Î±t)2 âˆ’
1
(1 + Î±t)3 =
Î±t
(1 + Î±t)3 .
Download free eBooks at bookboon.com

Stochastic Processes 2
 
43 
3. Birth and death processes
If k = 2, we get by a rearrangement,
P3(t)
=
1
3Î± {P â€²
2(t) âˆ’Î± P1(t) + 4Î± P2(t)}
=
1
3Î±

3Î±
(1+Î±t)4 âˆ’
2Î±
(1+Î±t)3 âˆ’
Î±
(1+Î±t)2 +
4Î±
(1+Î±t)2 âˆ’
4Î±
(1+Î±t)3

=
1
3Î±

3Î±
(1 + Î±t)4 âˆ’
6Î±
(1 + Î±t)3 +
3Î±
(1 + Î±t)2

=
(1 + Î±t)2 âˆ’2(1 + Î±t) + 1
(1 + Î±t)4
=
Î±2t2
(1 + Î±t)4 .
Summing up,
P0(t) =
Î±t
1 + Î±t,
P1(t) =
1
(1 + Î±t)2 ,
P2(t) =
Î±t
(1 + Î±t)3 ,
P3(t) =
Î±2t2
(1 + Î±t)4 .
0
0.2
0.4
0.6
0.8
1
0.5
1
1.5
2
2.5
3
Figure 1: The graph of 1 âˆ’
x
(1 + x)2 with x = Î±t.
3) It follows that
P0(t) + P1(t) =
Î±t
1 + Î±t +
1
(1 + Î±t)2 = 1 + Î±t + Î±2t2
(1 + Î±t)2
= 1 âˆ’
Î±t
(1 + Î±t)2 .
If we put x = Î±t, we see that we shall only sketch
1 âˆ’
x
(1 + x)2 = 1 âˆ’
1
1 + x +
1
(1 + x)2 ,
which has a minimum for x = 1, and has y = 1 as an asymptote.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
44 
3. Birth and death processes
0
0.2
0.4
0.6
0.8
1
0.5
1
1.5
2
2.5
3
Figure 2: The graph of
x
(1 + x)3 with x = Î±t.
4) If we put x = Î±t, it follows that we shall only sketch
Ï•(x) =
x
(1 + x)3 .
From
Ï•â€²(x) =
1
(1 + x)3 âˆ’
3x
(1 + x)4 = 1 âˆ’2x
(1 + x)4 ,
follows that we have a maximum for x = 1
2, corresponding to
Ï•
1
2

=
1
2
 3
2
3 = 4
27.
5) Clearly,
lim
tâ†’âˆP0(t) = lim
tâ†’âˆ
Î±t
1 + Î±t = 1.
We conclude from
âˆ

n=0
Pn(t) = 1
and
Pn(t) â‰¥0,
that
lim
tâ†’âˆ
âˆ

n=1
Pn(t) = 0,
hence
lim
tâ†’âˆPn(t) = 0
for alle n âˆˆN.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
45 
3. Birth and death processes
Example 3.5 A power station delivers electricity to N customers.
If a customer at time t uses
electricity there is the probability Î¼h + h Îµ(h) that he does not use electricity at time t + h, and
probability 1 âˆ’Î¼h + h Îµ(h) that he is still using electricity at time t + h.
However, if he to time t does not use electricity, then there is the probability Î»h + h Îµ(h) that he uses
electricity at time t + h, and probability 1 âˆ’Î»h + h Îµ(h) that he does not do it.
The customers are using electricity mutually independently.
Denote by Ek the state that k consumers use electricity, k = 0, 1, . . . , N.
Find the diï¬€erential equations of the system.
Find the stationary probabilities.
We put Xk(t) = 1, if the k-th customer uses electricity at time t, and Xk(t) = 0, if he does not do it.
Let n and j âˆˆ{0, 1, . . . , N}, and assume that the system is in state Ej, i.e.
N

k=1
Xk(t) = j
at time t.
How can we realize that we are in state En at time t + h?
There must be an m âˆˆ{0, 1, . . . , j}, such that j âˆ’m of the customers who were using electricity at
time t, still are using electricity at time t + h.
Furthermore, n âˆ’j + m of the customers, who did not use electricity at time t, must use electricity
at time t + h, is we are in state En.
Thus we get the condition m â‰¥j âˆ’n, so
m âˆˆ{max{0, j âˆ’n}, . . . , min{j, N âˆ’n}},
and
j âˆˆ{0, 1, . . . , N}.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.mastersopenday.nl
Visit us and find out why we are the best!
Masterâ€™s Open Day: 22 February 2014
Join the best at
the Maastricht University
School of Business and
Economics!
Top masterâ€™s programmes
â€¢ 33rd place Financial Times worldwide ranking: MSc 
International Business
â€¢ 1st place: MSc International Business
â€¢ 1st place: MSc Financial Economics
â€¢ 2nd place: MSc Management of Learning
â€¢ 2nd place: MSc Economics
â€¢ 2nd place: MSc Econometrics and Operations Research
â€¢ 2nd place: MSc Global Supply Chain Management and 
Change
Sources: Keuzegids Master ranking 2013; Elsevier â€˜Beste Studiesâ€™ ranking 2012; 
Financial Times Global Masters in Management ranking 2012
Maastricht
University is
the best specialist
university in the
Netherlands
(Elsevier)

Stochastic Processes 2
 
46 
3. Birth and death processes
Summing up, if the conditions above are fulï¬lled, then
1) m of the customers, who used electricity at time t, do not do it at time t + h.
2) j âˆ’m use electricity both at time t and at time t + h.
3) n âˆ’j + m did not use electricity at time t, but they do it at time t + h.
4) N âˆ’n âˆ’m neither use electricity at time t nor at time t + h.
For ï¬xed j this can be done of the probability
min{j,Nâˆ’n}

m=max{0,jâˆ’n}

j
m

{Î¼h + hÎµ(h)}m{1 âˆ’Î¼h + hÎµ(h)}jâˆ’m

N âˆ’j
n âˆ’j + m

{Î»h + hÎµ(h)}nâˆ’j+m{1 âˆ’Î»h + hÎµ(h)}Nâˆ’nâˆ’m.
When we multiply this equation by Pj(t) and then sum with respect to j, we get
Pn(t + h)
=
N

j=0
Pj(t)
min{j,Nâˆ’n}

m=max{0,jâˆ’n}

j
m
 
N âˆ’j
n âˆ’j + m

Ã—
(5)
Ã—{Î¼h + hÎµ(h)}m{1 âˆ’Î¼h + hÎµ(h)}jâˆ’m Ã—
Ã—{Î»h + hÎµ(h)}nâˆ’j+m{1 âˆ’Î»h + hÎµ(h)}Nâˆ’mâˆ’n.
If m = 0 in the inner sum, then j â‰¤n, and we isolate the term
 j
0
  N âˆ’j
n âˆ’j

{Î¼h + hÎµ(h)}0{1 âˆ’Î¼h + hÎµ(h)}j{Î»h + hÎµ(h)}nâˆ’j{1 âˆ’Î»h + hÎµ(h)}Nâˆ’n
=

N âˆ’j
n âˆ’j

{1 âˆ’Î¼h + hÎµ(h)}j{1 âˆ’Î»h + hÎµ(h)}Nâˆ’nhnâˆ’j{Î» + Îµ(h)}nâˆ’j.
It follows clearly that if j Ì¸= n, n âˆ’1, then we get terms of the type hÎµ(h),
If furthermore j = n, then we get the term

N âˆ’n
0

{1 âˆ’Î¼h + hÎµ(h)}n{1 âˆ’Î»h + hÎµ(h)}Nâˆ’n Â· 1
= (1 âˆ’Î¼h)n(1 âˆ’Î»h)Nâˆ’n + hÎµ(h) = 1 âˆ’nÎ¼h + (N âˆ’n)Î»h + h Îµ(h).
If instead j = n âˆ’1, then we get the term

N âˆ’n + 1
1

{1 âˆ’Î¼h + hÎµ(h)}nâˆ’1{1 âˆ’Î»h + hÎµ(h)}Nâˆ’1 Â· h Â· (Î» + hÎµ(h))
= (N âˆ’n + 1)hÎ» + hÎµ(h).
If m = 1 in the inner sum of (5), then
j âˆ’n â‰¤n â‰¤min{j, N âˆ’n},
thus 1 â‰¤j â‰¤n + 1. For such j we get the contribution
 j
1
 
N âˆ’j
n âˆ’j + 1

Î¼h(1 âˆ’Î¼h)jâˆ’1(Î»h)nâˆ’j+1(1 âˆ’Î»h)Nâˆ’nâˆ’m + hÎµ(h).
Download free eBooks at bookboon.com

Stochastic Processes 2
 
47 
3. Birth and death processes
It follows immediately that if j Ì¸= n + 1, then all these terms are of the type hÎµ(h).
For j = n + 1 we get the contribution

n + 1
1
 
N âˆ’n âˆ’1
0

Î¼h(1 âˆ’Î¼h)n(1 âˆ’Î»h)Nâˆ’nâˆ’m + hÎµ(h) = (n + 1)Î¼h + hÎµ(h).
If m â‰¥2, we only get terms of the type hÎµ(h).
We now include Îµ functions. Then (5) is reduced by this analysis for n = 1, . . . , N âˆ’1, to
Pn(t + h)
=
Pn{1 âˆ’nÎ¼h âˆ’(N âˆ’n)Î»h + hÎµ(h)} + Pnâˆ’1(t) Â· (N âˆ’n + 1)hÎ» + hÎµ(h)
+Pn+1(t) Â· (n + 1) Â· Î¼h + hÎµ(h),
thus by a rearrangement
Pn(t + h) âˆ’Pn(t)
= âˆ’h {(nÎ¼ + (N âˆ’n)Î»)Pn(t)} + h(N âˆ’n + 1)Î»Pnâˆ’1(t) + h(n + 1)Î¼Pn+1(t) + hÎµ(h),
and hence dividing by h, followed by taking the limit h â†’0,
P â€²
n(t) = âˆ’{nÎ¼ + (N âˆ’n)Î»}Pn(t) + (N âˆ’n + 1)Î»Pnâˆ’1(t) + (n + 1)Î¼Pn+1(t).
There are some modiï¬cations for n = 0 and n = N, in which cases we get instead
P â€²
0(t) = âˆ’N Î» P0(t) + Î¼ P1(t),
and
P â€²
N(t) = âˆ’N Î¼ PN(t) + Î» PNâˆ’1(t).
Then we have for the stationary probabilities,
0
=
âˆ’N Î» p0 + Î¼ p1,
0
=
âˆ’{nÎ¼ + (N âˆ’n)Î»}pn + (N âˆ’n + 1)Î»pnâˆ’1 + (n + 1)Î¼pn+1,
n = 1, . . . , N âˆ’1,
0
=
âˆ’N Î¼ pN + Î» pNâˆ’1,
hence
â§
âª
âª
âª
âª
âª
âª
âª
âª
âª
â¨
âª
âª
âª
âª
âª
âª
âª
âª
âª
â©
p1 = N Â· Î»
Î¼ p0
pn+1 =

n
n + 1 + N âˆ’n
n + 1 Â· Î»
Î¼

pn âˆ’N âˆ’n + 1
n + 1
Â· Î»
Î¼ pnâˆ’1
n = 1, . . . , N âˆ’1,
pN = 1
N Â· Î»
Î¼ pNâˆ’1.
In order to ï¬nd the pattern we compute p2, i.e. we put n = 1 into the general formula
p2
=
1
2 + N âˆ’1
2
Â· Î»
Î¼

p1 âˆ’N
2
Î»
Î¼

p0 = N
2 Â· Î»
Î¼ Â· p0 + N(N âˆ’1)
2
Î»
Î¼
2
p0 âˆ’N
2 Â· Î»
Î¼ Â· p0
=
 N
2

Â·
Î»
Î¼
2
p0.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
48 
3. Birth and death processes
Now
p1 = N Â·
Î»
Î¼
1
p0 =
 N
1

Â·
Î»
Î¼
1
p0,
so we guess that we in general have
pn =

N
n

Â·
Î»
Î¼
m
p0.
This is true for n = 0, 1, 2.
Assume that the claim holds for all indices up to n. If n â‰¤N âˆ’1, then
pn+1
=

n
n + 1 + N âˆ’n
n + 1 Â· Î»
Î¼

pn âˆ’N âˆ’n + 1
n + 1
Â· Î»
Î¼ pnâˆ’1
=
n
n + 1 Â·
N!
n!(N âˆ’n)!
Î»
Î¼
n
+ N âˆ’n
n + 1 Â·
N!
n!(N âˆ’n)!
Î»
Î¼
n+1
p0
âˆ’N âˆ’n + 1
n + 1
Â·
N!
(n âˆ’1)!(N âˆ’n + 1)!
Î»
Î¼
n
p0
=
N!
(n + 1) Â· (n âˆ’1)!(N âˆ’n)!
Î»
Î¼
n
p0 âˆ’
N!
(n + 1)(n âˆ’1)!(N âˆ’n)!
Î»
Î¼
n
p0
+
N!
(n + 1)!(N âˆ’n âˆ’1)!
Î»
Î¼
n+1
p0
=

N
n + 1
 Î»
Î¼
n+1
p0,
and the claim follows by induction. Then
1 =
N

n=0
pn = p0
N

n=0
 N
n
 Î»
Î¼
n
= p0 Â·

1 + Î»
Î¼
N
= p0
Î» + Î¼
Î¼
N
,
hence
pn =
 N
n

Â·
Î»
Î¼
n
Â·

Î¼
Î» + Î¼
N
=
 N
n
 
Î»
Î» + Î¼
n 
Î¼
Î» + Î¼
Nâˆ’n
.
The solution above is somewhat clumsy, though it follows the ordinary way one would solve problems
of this type without too much training.
Alternatively we see that we have a birth and death process of states E0, E1, . . . , EN, and
intensities
Î»k = (N âˆ’k)Î»,
Î¼k = kÎ¼,
k âˆˆ{0, 1, . . . , N}.
The corresponding system of diï¬€erential equations becomes
â§
âª
âª
âª
âª
â¨
âª
âª
âª
âª
â©
P â€²
0(t) = âˆ’NÎ»P0(t) + Î¼P1(t),
P â€²
k(t) = âˆ’{(N âˆ’k)Î»+kÎ¼}Pk(t)+(N âˆ’k+1)Î»Pkâˆ’1(t)+(k+1)Î¼Pk+1(t),
for 1 â‰¤k â‰¤N âˆ’1,
P â€²
N(t) = âˆ’NÎ¼PN(t) + Î»PNâˆ’1(t).
Download free eBooks at bookboon.com

Stochastic Processes 2
 
49 
3. Birth and death processes
The stationary probabilities pk are found from
Î¼kpk = Î»kâˆ’1pkâˆ’1,
k = 1, 2, . . . , N,
thus
pk = N âˆ’k + 1
k
Â· Î»
Î¼ Â· pkâˆ’1.
Then by recursion,
pk = (N âˆ’k + 1)(N âˆ’k + 2) Â· N
k Â· (k âˆ’1) Â· 1
Â·
Î»
Î¼
k
p0 =
N!
k!(N âˆ’k)!
Î»
Î¼
k
p0 =

N
k
 Î»
Î¼
k
p0.
Finally, it follows from
1 =
N

k=0
pk = p0
N

k=0

N
k
 Î»
Î¼
k
= p0
Î»
Î¼ + 1
N
= p0
Î» + Î¼
Î¼
N
that
pk =
 N
k
 Î»
Î¼
k
p0 =

k
 Î»
Î¼
k
Â·
 Î¼
Î»+Î¼
N
=
 N
k

Â·

Î»
Î» + Î¼
k  Î¼
Î»+Î¼
Nâˆ’k
,
for k = 0, 1, 2, . . . , N, so we get a binomial distribution B

N,
Î»
Î» + Î¼

of mean N Â·
Î»
Î» + Î¼.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Stochastic Processes 2
 
50 
3. Birth and death processes
Example 3.6 Given a stochastic process {X(t), t âˆˆ[0, âˆ[} by the following: At time t = 0 there are
N cars in a carpark. No car arrives, and the cars leave the carpark mutually independently. If a car
is staying at its parking bay at time t, then there is the probability Î¼h + hÎµ(h) [where Î¼ is a positive
constant] that it leaves the carpark in the time interval ]t, t + h].
Put X(t) = k, k = 0, 1, . . . , N, if there are k cars in the carpark at time t, and put
Pk(t) = P{X(t) = k}.
1. Prove that we have a death process with Î¼k = kÎ¼, k = 0, 1, . . . , N.
2. Find the diï¬€erential equations of the system.
3. Find the stationary probabilities.
4. Prove that the mean value function
m(t) =
N

k=1
k Pk(t)
is a solution of the diï¬€erential equation
dx
dt + Î¼x = 0,
and then ï¬nd m(t).
5. Given that X(t) is binomially distributed, ï¬nd the probabilities Pk(t), k = 0, 1, . . . , N.
We introduce a random variable T by putting T = t, if the last car leaves the carpark at time t.
6. Find the distribution function and the frequency of T.
1) This follows e.g. from the fact that the probability that one of the k cars leaves the carpark in the
time interval ]t, t + h] is
k{Î¼h + hÎµ(h)} Â· {1 âˆ’Î¼h + hÎµ(h)}kâˆ’1 = kÎ¼h + hÎµ(h),
from which we conclude that Î¼k = kÎ¼.
2) The diï¬€erential equations are immediately found to be
â§
â¨
â©
P â€²
k(t) = âˆ’kÎ¼Pk(t) + (k + 1)Î¼Pk+1(t),
0 â‰¤k â‰¤N âˆ’1,
P â€²
N(t) = âˆ’NÎ¼PN(t).
3) The stationary probabilities become
k pk = 0,
k = 0, 1, . . . , N.
Since 
N
k=0 pk = 1, we get
pk = 0
for k = 1, 2, . . . , N
and
p0 = 1.
This result is of course obvious, because the carpark at last is empty.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
51 
3. Birth and death processes
4) If we multiply the k-th equation of 2. by k, and then sum from 1 to N, we get
N

k=1
k P â€²
k(t)
=
âˆ’Î¼
N

k=1
k2Pk(t) + Î¼
Nâˆ’1

k=1
k(k + 1)Pk+1(t)
=
âˆ’Î¼
N

k=1
k2Pk(t) + Î¼
N

k=1
(k âˆ’1 = jPk(t) = âˆ’Î¼
N

k=1
k Pk(t),
which is also written
mâ€²(t) + Î¼ m(t) = 0,
m(t) =
N

k=1
k Pk(t).
From m(0) = N follows that m(t) = N eâˆ’Î¼t.
5) Since X(t) is binomially distributed of parameter of numbers N, and since we also know the mean,
we can ï¬nd the probability parameter, thus
X(t) âˆˆB

N, eâˆ’Î¼t
,
and
Pk(t) =
 N
k

eâˆ’kÎ¼t 
1 âˆ’eâˆ’Î¼tNâˆ’k ,
k = 0, 1, . . . , N.
6) Now, T â‰¤t, if and only if X(t) = 0. Hence
F(t) =
â§
â¨
â©
P0(t) = (1 âˆ’eâˆ’Î¼t)N ,
for t â‰¥0,
0
for t < 0,
and ï¬nally by diï¬€erentiation
f(t) =
â§
â¨
â©
N (1 âˆ’eâˆ’Î¼t)Nâˆ’1 Î¼ eâˆ’Î¼t,
for t â‰¥0,
0,
for t < 0.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
52 
4. Queueing theory
4
Queueing theory
Example 4.1 Customers arrive to a shop by a Poisson process of intensity Î». There are 2 shop
assistants and possibility of forming a queue. We assume that the service times are exponentially
distributed of parameter Î¼.
It is given that there are no customers in the shop in at the average 10 % of the time and that 1
Î» = 11.
Find 1
Î¼.
Then ï¬nd the probability that both shop assistants are busy.
Here, N = 2 and p0 = 1
10 and 1
Î» = 11. In fact, it was given that P0(t) â†’p0 = 10 % for t â†’âˆ.
The traï¬ƒc intensity Ï± is for N = 2 given by
p0 = 1 âˆ’Ï±
1 + Ï± = 1
10,
hvoraf Ï± = 9
11.
On the other hand, the traï¬ƒc intensity is deï¬ned by
Ï± =
Î»
NÎ¼ = Î»
2Î¼ =
1
2 Â· 11 Î¼ = 9
11,
dvs. 1
Î¼ = 18.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Get Help Now
Go to www.helpmyassignment.co.uk for more info
Need help with your
dissertation?
Get in-depth feedback & advice from experts in your 
topic area. Find out what you can do to improve
the quality of your dissertation!

Stochastic Processes 2
 
53 
4. Queueing theory
Hence
p1 = 2Ï± Â· 1 âˆ’Ï±
1 + Ï± = 2 Â· 9
11 Â· 1
10,
and therefore,
P{both shop assistants busy} = 1 âˆ’p0 âˆ’p1 = 1 âˆ’1
10 âˆ’18
110 = 81
110.
Example 4.2 Customers arrive to a shop following a Poisson process of intensity Î». We have 1
shop assistant and it is possible to form a queue. We assume that the service times are exponentially
distributed of parameter Î¼. It is assumed that the traï¬ƒc intensity is Ï± = 6
5, where it is well-known
that this implies that the system does not work properly (the queue increases indeï¬nitely). Compare
the advantages of the following two possibilities:
1) Another shop assistant is hired (of the same service time distribution as the ï¬rst one).
2) Improvement of the service, such that the average service time is lowered to its half.
We have a queueing system with possibility of forming a queue. The parameters are
N = 1,
Ï± = 6
5
and
Î»,
Î¼.
Since Ï± = 6
5 > 1, this system does not work properly.
1) If another shop assistant is hired, then the parameters are changed to
N = 2,
Ï± = 3
5
and
Î», Î¼ unchanged.
Then
p0 = 1 âˆ’Ï±
1 + Ï± = 1
4.
The average waiting time is
V1 =
1
4 Â·
3
5
2
Â· 2
Î¼ Â· 2
2
5
2 = 9
16 Â· 1
Î¼,
and the average staying time is
O1 = 9
16 Â· 1
Î¼ + 1
Î¼ = 25
16 Â· 1
Î¼.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
54 
4. Queueing theory
Remark 4.1 It should here be added that one can also ï¬nd
the average number of customers = 15
8 ,
the average number of busy shop assistants = 6
5,
the average length of the queue = 27
40.
â™¦
2) If instead the service is improved as indicated, then the parameters become
N = 1,
Ï± = 3
5,
Î» unchanged,
Î¼ is doubled.
The average waiting time is then
V2 =
Ï±
2Î¼(1 âˆ’Ï±) = 12
16 Â· 1
Î¼,
and the average staying time is
O2 = 12
16 Â· 1
Î¼ + 1
2Î¼ = 20
16 Â· 1
Î¼.
Remark 4.2 Again we add for completeness,
the average number of customers = 3
5,
ther average number of busy shop assistants = 3
5,
the average length of the queue = 9
10.
â™¦
By comparing the two cases we get
V1 < V2,
and on the contrary
O1 > O2,
and the question does not have a unique answer.
The customer will prefer that the sum of waiting time and service time is as small as possible. Since
V1 + O1 = 34
16 Â· 1
Î¼
and
V2 + O2 = 32
16 Â· 1
Î¼,
it follows that the customer will prefer the latter system, while it is far more uncertain what the shop
would prefer, because we do not know the costs of each of the two possible improvements.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
55 
4. Queueing theory
Example 4.3 We consider an intersection which is not controlled by traï¬ƒc lights. One has noticed
that cars doing a left-hand turn are stopped and therefore delay the cars which are going straight on.
Therefore, one plans to build a left-hand turn lane. Assuming that arrivals and departures of the cars
doing the left-hand turn are exponentially distributed with the parameters Î» and Î¼, where Î»
Î¼ = 1
2, one
shall compute the smallest number of cars of the planned left-hand turn lane, if the probability is less
than 5 % of the event that there are more cars than the new lane can contain.
Here N = 1, so the capacity of the system is
Ï± =
Î»
NÎ¼ = 1
2.
The stationary probabilities are
pk = Ï±k(1 âˆ’Ï±) =
1
2
k+1
,
k âˆˆN0.
Let n denote the maximum number of cars in the left turn lane. Then we get the condition
âˆ

k=n+1
pk =
âˆ

k=n+1
1
2
k+1
=
1
2n+1 < 5 % = 1
20,
thus 1
2n < 1
10, which is fulï¬lled for n â‰¥4.
Example 4.4 Given a queueing system of exponential distribution of arrivals and exponential distri-
bution of service times (the means are called 1
Î» and 1
Î¼, resp.). The number of service places is 2. We
furthermore assume that it is possible to form a queue. Assuming that 1
Î» = 1 (minute) and 1
Î¼ = 1
(minute),
1. ï¬nd the average waiting time,
2. ï¬nd the average staying time.
For economic reasons the number of service places is cut down from 2 to 1, while the service at the
same time is simpliï¬ed (so the service time is decreased), such that the customerâ€™s average staying
time is not prolonged. Assuming that the constant Î» is unchanged,
3. ï¬nd the average service time 1
Î¼1
, such that the average staying time in the new system is equal to
the average staying time in the previous mentioned system,
4. ï¬nd in which of the two systems the probability is largest for a customer to wait.
Here N = 2, 1
Î» = 1 and 1
Î¼ = 1. This gives the traï¬ƒc intensity
Ï± =
Î»
NÎ¼ =
1
2 Â· 1 = 1
2,
and
p0 = 1 âˆ’Ï±
1 + Ï± = 1
3.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
56 
4. Queueing theory
1) The average waiting time is
V = p0 Â· Ï±N Â· N Nâˆ’1
Î¼ Â· N!(1 âˆ’Ï±)2 =
1
3 Â·
 1
2
2 Â· 21
1 Â· 2!

1 âˆ’1
2
2 = 1
3 minute.
2) The staying time is the waiting time plus the serving time, so the average staying time is
O = V + 1
Î¼ = 1
3 + 1 = 4
3 minute.
3) In the new system the traï¬ƒc intensity is
Ï±1 =
Î»
N1Î¼1
= 1
Î¼1
,
idet N1 = 1.
The average waiting time is for N1 given by some theoretical formula,
V1 =
Ï±1
Î¼1 (1 âˆ’Ï±1) =
1
Î¼1 (Î¼1 âˆ’1),
and the average staying time is for N1 = 1 given by
O1 = V1 + 1
Î¼1
=
1
Î¼1 âˆ’1.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
By 2020, wind could provide one-tenth of our planetâ€™s 
electricity needs. Already today, SKFâ€™s innovative know-
how is crucial to running a large proportion of the 
worldâ€™s wind turbines. 
Up to 25 % of the generating costs relate to mainte-
nance. These can be reduced dramatically thanks to our 
systems for on-line condition monitoring and automatic 
lubrication. We help make it more economical to create 
cleaner, cheaper energy out of thin air. 
By sharing our experience, expertise, and creativity, 
industries can boost performance beyond expectations. 
Therefore we need the best employees who can 
meet this challenge!
The Power of Knowledge Engineering
Brain power
Plug into The Power of Knowledge Engineering. 
Visit us at www.skf.com/knowledge

Stochastic Processes 2
 
57 
4. Queueing theory
We want that O1 = O = 4
3. Hence, Î¼1 âˆ’1 = 3
4, i.e. Î¼1 = 7
4, and
1
Î¼1
= 4
7.
4) The probability of waiting in the old system is
1 âˆ’p0 âˆ’p1 = 1 âˆ’1 âˆ’Ï±
1 + Ï± âˆ’2 Ï± 1 âˆ’Ï±
1 + Ï± = 1 âˆ’1
3 âˆ’2 Â· 1
2 Â· 1
3 = 1
3.
The probability of waiting in the new system is
1 âˆ’Ëœp0 = 1 âˆ’(1 âˆ’Ï±1) = Ï±1 = 1
Î¼1
= 4
7.
We see by comparison that there is largest probability of waiting in the new system.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Stochastic Processes 2
 
58 
4. Queueing theory
Example 4.5 Given a service (a shop) of which we assume:
a. There is only one shop assistant.
b. It is not possible to form a queue.
c. The customers arrive according to a Poisson process of intensity Î».
d. The service time is exponentially distributed of mean Î¼.
1. Find the diï¬€erential equations of this system.
2. Solve these under the assumption that at time t = 0 there is no customer.
Assume from now on that Î»
Î¼ = 6.
3. Find the stationary probabilities and the probability of rejection.
Assuming that the probability of rejection is too large, we change the system, such that there are two
shop assistants A and B, and the service is changed, such that a customer at his arrival goes to A
and is served by him, if A is vacant at the arrival of the customer. If on the other hand A is busy,
then the customer will turn to B in order to be serviced. If also B is busy, the customer is rejected.
The assumptions of the arrivals and service times are the same as before. We want to compute in this
system:
4. The stationary probabilities and the probability of rejection.
5. The probability that A and B, res., are busy.
6. Finally, ï¬nd the smallest number of shop assistants, for which the probability of rejection is smaller
than 1
2.
1) Since N = 1, the diï¬€erential equations of the system are
â§
â¨
â©
P â€²
0(t) = âˆ’Î»P0(t) + Î¼P1(t),
P â€²
1(t) = Î»P0(t) âˆ’Î¼P1(t),
thus written in the form of a matrix equation,
d
dt
 P0(t)
P1(t)

=
 âˆ’Î»
Î¼
Î»
âˆ’Î¼
  P0(t)
P1(t)

.
2) The characteristic polynomial (in R) is
!!!!
âˆ’Î» âˆ’R
Î¼
Î»
âˆ’Î¼ âˆ’R
!!!! = (R + Î»)(R + Î¼) âˆ’Î»Î¼ = R2 + (Î» + Î¼)R.
The roots are R = 0 and R = âˆ’Î» âˆ’Î¼.
For R = 0 we get the eigenvector (Î¼, Î»).
Download free eBooks at bookboon.com

Stochastic Processes 2
 
59 
4. Queueing theory
For R = âˆ’Î» âˆ’Î¼ we get the eigenvector (1, âˆ’1).
The complete solution is

P0(t)
P1(t)

= c1
 Î¼
Î»

+ c2eâˆ’(Î»+Î¼)t

1
âˆ’1

.
The initial conditions are P0(0) = 1 and P1(0) = 0, thus
â§
â¨
â©
1 = Î¼c1 + c2,
0 = Î»c1 âˆ’c2,
and hence
c1 =
1
Î» + Î¼,
c2 =
Î»
Î» + Î¼,
and the solution becomes
â§
âª
âª
âª
â¨
âª
âª
âª
â©
P0(t) =
Î¼
Î» + Î¼ +
Î»
Î» + Î¼ eâˆ’(Î»+Î¼)t,
P1(t) =
Î»
Î» + Î¼ âˆ’
Î»
Î» + Î¼ eâˆ’(Î»+Î¼)t.
3) If Î»
Î¼ = 6, then
Î»
Î» + Î¼ =
Î»
Î¼
Î»
Î¼ + 1 = 6
7
and
Î¼
Î» + Î¼ = 1
7,
and Î» + Î¼ = 7Î¼, thus
â§
âª
âª
â¨
âª
âª
â©
P0(t) = 1
7 + 6
7 exp(âˆ’7Î¼t),
P1(t) = 6
7 âˆ’6
7 exp(âˆ’7Î¼t),
t â‰¥0.
The stationary probabilities are obtained by letting t â†’âˆ, thus
p0 = 1
7
and
p1 = 6
7.
In particular, the probability of rejection is p1 = 6
7.
4) We have the following states:
E0: No customer in the system.
E1: A serves a customer, while B does not.
E2: A is vacant, while B serves a customer.
E3: Both A and B serve customers.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
60 
4. Queueing theory
There is no change for A, so by 3.,
â§
âª
âª
â¨
âª
âª
â©
P0(t) + P2(t) = 1
7 + 6
7 exp(âˆ’7Î¼t),
P1(t) + P3(t) = 6
7 âˆ’6
7 exp(âˆ’7Î¼t),
t â‰¥0.
By taking the limit t â†’âˆwe get
p0 + p2 = 1
7
and
p1 + p3 = 6
7.
We can realize P0(t + h) in the following ways, if the system at time t is in state
(i) E0, and no customer arrives,
P0(t) Â· {1 âˆ’Î»h + hÎµ(h)}.
(ii) E0, some customer arrive, and they are served until they are ï¬nished,
hÎµ(h).
(iii) E1, and there is no customer coming, and Aâ€™s customer is serviced to the end,
P1(t) Â· {Î¼h + hÎµ(h)}.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Stochastic Processes 2
 
61 
4. Queueing theory
(iv) E1, and there arrive customers, who are served,
hÎµ(h).
(v) E2, and no new customer is coming, and Bâ€™s customer is served to the end,
P2(t) Â· {Î¼h + hÎµ(h)}.
(vi) E2 in all other cases,
hÎµ(h).
(vii) E3 in general,
hÎµ(h).
By adding these we get
P0(t + h) = P0(t) Â· {1 âˆ’Î»h + hÎµ(h)} + {P1(t) + P2(t)} Â· {Î¼h + hÎµ(h)} + hÎµ(h).
Then compute the derivative in the usual way by taking the limit. This gives
P â€²
0(t) = lim
hâ†’0 {P0(t + h) âˆ’P0(t)} = âˆ’Î»P0(t) + Î¼ {P1(t) + P2(t)} .
Then by taking the limit t â†’âˆ,
0 = âˆ’Î»p0 + Î¼ {p1 + p2} = âˆ’6Î¼p0 + Î¼ {p1 + p2} ,
hence
6p0 = p1 + p2.
We are still missing one equation, when we want to ï¬nd the stationary probabilities. We choose
to realize P3(t + h). This can be done, if the system at time t is in state
(i) E0, and at least two customers arrive,
hÎµ(h).
(ii) E1, and at least one customer arrives, and neither A nor B ï¬nish their customers,
P1(t) Â· {Î»h + hÎµ(h)} Â· {1 âˆ’Î¼h + hÎµ(h)}2.
(iii) E2, and at least one customer arrives, and neither A nor B ï¬nish their customers,
P2(t) Â· {Î»h + hÎµ(h)} Â· {1 âˆ’Î¼h + hÎµ(h)}2.
(iv) E3, and neither A nor B ï¬nish their customers,
P3(t) Â· {1 âˆ’Î¼h + hÎµ(h)}2.
(v) Other, all of probability
hÎµ(h).
Download free eBooks at bookboon.com

Stochastic Processes 2
 
62 
4. Queueing theory
When we add these probabilities we get
P3(t + h)
=
{P1(t) + P2(t)} Â· {Î»h + hÎµ(h)} Â· {1 âˆ’Î¼h + hÎµ(h)}2
+P3(t) Â· {1 âˆ’Î¼h + hÎµ(h)}2 + hÎµ(h).
A rearrangement followed by a reduction gives
P3(t + h) âˆ’P3(t) = Î»h {P1(t) + P2(t)} âˆ’2Î¼hP3(t) + hÎµ(h).
Then divide by h and let h â†’0. This will give us the diï¬€erential equation
P â€²
3(t) = Î» {P1(t) + P2(t)} âˆ’2Î¼P3(t),
hence by taking the limit t â†’âˆ,
0 = Î» (p1 + o2) âˆ’2Î¼p3 = 6Î¼ (p1 + p2) âˆ’2Î¼p3,
so
p3 = 3 (p1 + p2) = 18p0.
Summing up we have obtained the four equations
â§
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
â¨
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
â©
p0 + p2
=
1
7,
p1 + p3
=
6
7,
6p0
=
p1 + p2,
p3
=
18p0,
thus
â§
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
â¨
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
â©
p0 + p2
=
1
7,
18p0 + p1
=
6
7,
6p0 âˆ’p1 âˆ’p2
=
0,
p3
=
18p0.
By addition of the former three equations, we get 25p0 = 1, thus p0 = 1
25. Then
p1 = 6
7 âˆ’18
25 =
6
175 (25 âˆ’21) = 24
175,
and
p2 = 1
7 âˆ’1
25 = 18
175,
and
p3 = 18
25,
so
(p0, p1, p2, p3) =
 1
25, 24
175, 18
175, 18
25

,
and the probability of rejection is
p3 = 18
25.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
63 
4. Queueing theory
5) The probability that A is busy is
p1 + p3 = 6
7.
The probability that B is busy is
p2 + p3 = 18
175 + 18
25 = 144
175

< 6
7

.
6) We have in the general case of N shop assistants, where Ej denotes that j customers are served,
the system of diï¬€erential equations
â§
âª
âª
âª
âª
â¨
âª
âª
âª
âª
â©
P â€²
0(t) = âˆ’Î»P0(t) + Î¼P1(t),
P â€²
k(t) = âˆ’(Î» + kÎ¼)Pk(t) + Î»Pkâˆ’1(t) + (k + 1)Î¼Pk+1(t),
1 â‰¤k â‰¤N âˆ’1,
P â€²
N(t) = âˆ’NÎ¼PN(t) + Î»PNâˆ’1(t).
Hence by taking the limit t â†’âˆ,
â§
âª
âª
âª
âª
â¨
âª
âª
âª
âª
â©
0 = âˆ’Î»p0 + Î¼p1,
0 = âˆ’(Î» + kÎ¼)pk + Î»pkâˆ’1 + (k + 1)Î¼pk+1,
1 â‰¤k â‰¤N âˆ’1,
0 = âˆ’NÎ¼pN + Î»pNâˆ’1.
Since Î»
Î¼ = 6, we get by a division by Î¼, followed by a rearrangement that
â§
âª
âª
âª
âª
â¨
âª
âª
âª
âª
â©
0 = 6p0 âˆ’p1,
6pk âˆ’(k + 1)pk+1 = 6pkâˆ’1 âˆ’kpk,
1 â‰¤k â‰¤N âˆ’1,
0 = 6pNâˆ’1 âˆ’NpN.
Then by recursion, 6pkâˆ’1 âˆ’k pk = 0, thus
kpk = 6pkâˆ’1,
1 â‰¤k â‰¤N.
The easiest way to solve this recursion formula is to multiply by
(k âˆ’1)!
6k
Ì¸= 0,
and then do the recursion,
k!
6k pp = (k âˆ’1)!
6kâˆ’1
pkâˆ’1 = Â· Â· Â· = 0!
60 p0 = p0,
k = 0, 1, . . . , N,
thus
pk = 6k
k! p0,
k = 0, 1, . . . , N.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
64 
4. Queueing theory
Since p is a probability vector, we get the condition
1 =
N

k=0
pk = p0
N

k=0
6k
k! ,
thus
p0 =
1

N
k=0
6k
k!
.
The task is to ï¬nd N, such that the probability of rejection pN â‰¤1
2. Using
pN =
6N
N!

Nâˆ’1
k=0
6k
k! + 6N
N!
â‰¤1
2,
if
6N
N! â‰¤
Nâˆ’1

k=0
6k
k! ,
we compute the following table,
k
0
1
2
3
4
6k
k!
1
6
18
36
54

kâˆ’1
j=0
6j
j!
â‹†
1
7
25
61
It follows that N â‰¥4 gives pN â‰¤1
2, so we shall at least apply 4 service places.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
EXPERIENCE THE POWER OF 
FULL ENGAGEMENTâ€¦
     RUN FASTER.
          RUN LONGER..
                RUN EASIERâ€¦
READ MORE & PRE-ORDER TODAY 
WWW.GAITEYE.COM
Challenge the way we run

Stochastic Processes 2
 
65 
4. Queueing theory
Example 4.6 At a university there are two super computers A and B. Computer A is used for
university tasks, while computer B is restricted to external tasks. Both systems allow forming queues,
and the service times (i.e. the times used for computation of each task) is approximately exponentially
distributed of mean 1
Î¼ = 3 minutes. The university tasks arrive to computer A approximately as a
Poisson process of intensity Î»A = 1
5 minâˆ’1, while the tasks of computer B arrive as a Poisson process
of intensity Î»B = 3
10 minâˆ’1. Apply the stationary probabilities for the two computers A and B to
compute
1. The fraction of time, A (resp. B) is vacant.
2. The average waiting time at A (resp. B).
It is suggested to join the two systems to one, such that each computer can be used to university tasks
as well external tasks. This means that we have a queueing system with two â€œshop assistantsâ€. Use
again the stationary probabilities of this system to compute
3. The fraction of time both computers are vacant.
4. The fraction of time both computers are busy.
5. The average waiting time.
1) In both cases, N = 1.
For A we have the capacity
Ï±A =
Î»A
NÎ¼A
= 3
5,
thus
p0,A = 1 âˆ’Ï±A = 2
5.
For B we have the capacity
Ï±B =
Î»B
NÎ¼B
= 9
10,
thus
p0,B = 1 âˆ’Ï±B = 1
10.
These probabilities indicate the fraction of time, in which the given computer is vacant.
2) Since N = 1, the respective average waiting times are
VA =
Ï±A
Î¼ (1 âˆ’Ï±A) = 3 Â·
3
5
1 âˆ’3
5
= 9
2 minutes,
and
VB =
Ï±B
Î¼ (1 âˆ’Ï±B) = 3 Â·
9
10
1 âˆ’9
10
= 27 minutes.
3) The sum of two Poisson processes is again a Poisson process, here with the parameter
Î» = Î»A + Î»B = 1
5 + 3
10 = 1
2.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
66 
4. Queueing theory
Hence the capacity
Ï± =
Î»
NÎ¼ = 1
2 Â· 1
2 Â· 3 = 3
4.
The fraction of time, in which none of the computers is busy, is
p0 = 1 âˆ’Ï±
1 + Ï± = 1 âˆ’3
4
1 + 3
4
= 1
7.
4) The probability that both computers are busy is
1 âˆ’p0 âˆ’p1 = 1 âˆ’1
7 âˆ’2Ï± 1 âˆ’Ï±
1 + Ï± = 1 âˆ’1
7 âˆ’2 Â· 3
4 Â· 1
7 = 14 âˆ’2 âˆ’3
14
= 9
14.
5) The average waiting time is
V =
p0Ï±NN Nâˆ’1
Î¼ Â· N!(1 âˆ’Ï±)2 = 1
7
3
4
2
Â· 21 Â· 3 Â· 1
2! Â·
1

1 âˆ’3
4
2 = 1
7 Â· 9
16 Â· 2 Â· 3
2 Â· 16 = 27
7 minutes.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
PDF components for PHP developers
www.setasign.com
SETASIGN
This e-book  
is made with 
SetaPDF

Stochastic Processes 2
 
67 
4. Queueing theory
Example 4.7 Given a birth and death process of the states E0, E1, E2, . . . , where the birth intensity
Î»k in state Ek decreases in increasing k as follows,
Î»k =
Î±
k + 1,
where Î± is a positive constant, while the death intensities Î¼k are given by
Î¼k =
â§
â¨
â©
Î¼,
k âˆˆN,
0,
k = 0,
where Î¼ > 0.
1. Find the stationary probabilities.
The above may be viewed as a model of a queueing process, where
a. it is possible to form a queue,
b. there is only 1 channel,
c. the service time is exponentially distributed of mean 1
Î¼,
d. the arrival frequency decreases with increasing queue length according to the given formula. (Some
customers will avoid a long queue and immediately leave the queue ).
2. Compute for Î± = Î¼ the probability that there are at most 3 customers in the system (3 dec.).
3. Compare the probability of 2. with the corresponding probability in the case of one shop assistant
and Î»k = Î± constant and Î¼ = 3Î± (3 dec.).
1) The system of diï¬€erential equations for Î»k =
Î±
k + 1 and Î¼ > 0 is given by
â§
âª
âª
â¨
âª
âª
â©
P â€²
0(t) = âˆ’Î±P0(t) + Î¼P1(t),
P â€²
k(t) = âˆ’

Î±
k + 1 + Î¼

Pk(t) + Î±
k Pkâˆ’1(t) + Î¼ Pk+1(t),
k âˆˆN.
By taking the limit t â†’âˆwe get
â§
âª
âª
â¨
âª
âª
â©
0 = âˆ’Î±p0 + Î¼p1,
0 = âˆ’

Î±
k + 1 + Î¼

pk + Î±
k pkâˆ’1 + Î¼pk+1,
k âˆˆN,
thus
âˆ’
Î±
k + 1 pk + Î¼pk+1 = âˆ’Î±
k pkâˆ’1 + Î¼pk = Â· Â· Â· = 0,
k âˆˆN,
and hence
Î¼pk = Î±
k pkâˆ’1,
k âˆˆN.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
68 
4. Queueing theory
When this equation is multiplied by
k! Î¼kâˆ’1
Î±k
Ì¸= 0,
it follows by a recursion that
k!
Î¼
Î±
 k
pk = (k âˆ’1)!
Î¼
Î±
 kâˆ’1
pkâˆ’1 = Â· Â· Â· = 0!
Î¼
Î±
 0
p0 = p0,
hence
pk = 1
k!
Î±
Î¼
k
p0,
k âˆˆN0.
It follows from
1 =
âˆ

k=0
pk = p0
âˆ

k=0
1
k!
Î±
Î¼
k
= p0 exp
Î±
Î¼

,
that
p0 = exp

âˆ’Î±
Î¼

,
thus
pk = 1
k!
Î±
Î¼
k
exp

âˆ’Î±
Î¼

,
k âˆˆN0.
2) Put Î± = Î¼. The probability that there are at most 3 customers in the system is
p0 + p1 + p2 + p3 = 1
e

1 + 1
1! + 1
2! + 1
3!

= 16
6e â‰ˆ0.9810.
3) The diï¬€erential equations of the new system are
â§
â¨
â©
P â€²
0(t) = âˆ’Î±P0(t) + 3Î±P1(t),
P â€²
k(t) = âˆ’4Î±Pk(t) + Î±Pkâˆ’1(t) + 3Î±Pk+1(t),
k âˆˆN.
By taking the limit t â†’âˆwe get the equations of the stationary probabilities,
â§
â¨
â©
0 = âˆ’Î±p0 + 3Î±p1,
0 = âˆ’4Î±pk + Î±pkâˆ’1 + 3Î±pk+1,
k âˆˆN.
We rewrite these and get by a reduction,
3pk+1 âˆ’pk = 3pk âˆ’pkâˆ’1 = Â· Â· Â· = 3p1 âˆ’p0 = 0,
k âˆˆN,
thus 3pk = pkâˆ’1. Multiply this equation by 3kâˆ’1 in order to get
3kpk = 3kâˆ’1pkâˆ’1 = Â· Â· Â· = 30p0 = 00,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
69 
4. Queueing theory
hence
pk = 1
3k p0,
k âˆˆN0.
It follows from
1 =
âˆ

k=0
pk = p0
âˆ

k=0
1
3
k
= p0 Â·
1
3
1 âˆ’1
3
= 3
2 Â· p0,
that p0 = 2
3, and the probability that there are at most three customers in this system is
p0 + p1 + p2 + p3 = p0

1 + 1
3 + 1
32 + 1
33

= 2
3 Â· 27 + 9 + 3 + 1
27
= 80
81 â‰ˆ0.9877.
There is a slightly higher probability in this case that there are at most three customers in this
system than in the system which was considered in 2..
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.sylvania.com
We do not reinvent  
the wheel we reinvent 
light.
Fascinating lighting offers an infinite spectrum of 
possibilities: Innovative technologies and new  
markets provide both opportunities and challenges. 
An environment in which your expertise is in high 
demand. Enjoy the supportive working atmosphere 
within our global group and benefit from international 
career paths. Implement sustainable ideas in close 
cooperation with other specialists and contribute to 
influencing our future. Come and join us in reinventing 
light every day.
Light is OSRAM

Stochastic Processes 2
 
70 
4. Queueing theory
Example 4.8 Given the following queueing model: M machines are working mutually independently
of each other and they need no operation by men, except in the case when they break down. There are
in total N service mechanics (where N < M) for making repairs. If a machine is working at time t,
it is the probability Î»h + hÎµ(h) that it breaks down before time t + h, and probability 1 âˆ’Î»h + hÎµ(h)
that it is still working. Analogously, if it is repaired at time t, then there is the probability Î¼h + hÎµ(h)
that it is working again before t + h, and probability 1 âˆ’Î¼h + hÎµ(h) that it is not working. When a
machine breaks down, it is immediately repaired by a service mechanic, if he is vacant. Otherwise, the
machine is waiting in a queue, until a service mechanic becomes vacant. We deï¬ne the coeï¬ƒcient of
loss of a machine as
1
M Â· average number of machines in the queue,
and the coeï¬ƒcient of loss of a service mechanic as
1
N Â· average number of vacant service mechanics.
Denote by Ek the state that k machines do not work, k = 0, 1, . . . , M.
1) Prove that the constants Î»k and Î¼k are given by
Î»k = (M âˆ’k)Î»,
Î¼k = kÎ¼,
0 â‰¤k â‰¤N,
Î»k = (M âˆ’k)Î»,
Î¼k = NÎ¼,
N â‰¤k â‰¤M.
2) Find a recursion formula for pk (express pk+1 by pk).
3) Find the average number of machines in the queue (expressed by the pk-erne), and prove in par-
ticular that if N = 1 this can be written
M âˆ’Î» + Î¼
Î»
(1 âˆ’p0) .
4) Find the probability that there are precisely 0, 1, 2, . . . , N vacant service mechanics.
5) Find the coeï¬ƒcients of loss of a machine and a service mechanics in the case of
Î»
Î¼ = 0, 1;
M = 6;
N = 1.
It should be mentioned for comparison that in the case when
Î»
Î¼ = 0, 1;
M = 20;
N = 3,
the coeï¬ƒcient of loss of a machine is 0.0169 and the coeï¬ƒcient of loss of a service mechanics is
0.4042. Which one of the two systems is best?
This problem of machines was ï¬rst applied in the Swedish industry.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
71 
4. Queueing theory
1) Let 0 â‰¤k â‰¤M, and assume that we are in state Ek, thus k machines are being repaired or
are waiting for reparation, and M âˆ’k machines are working. The latter machines have each the
probability
Î»h + hÎµ(h)
of breaking down in the time interval ]t, t + h] of length h. Since M âˆ’k machines are working, we
get
Î»k = (M âˆ’k)Î»
for 0 â‰¤k â‰¤M.
If we are in state Ek, where 0 â‰¤k â‰¤N, then all k machines are being repaired. Each of these
have the probability
Î¼h + hÎµ(h)
for being repaired before time t + h, thus
Î¼k = kÎ¼,
for 0 â‰¤k â‰¤N.
If instead N < k â‰¤M, then all service mechanics are working, so
Î¼k = NÎ¼,
for N < k â‰¤M.
2) By a known formula,
Î¼k+1pk+1 = Î»kpk,
thus
pk+1 =
Î»k
Î¼k+1
pn,
for n = 0, 1, . . . , M âˆ’1.
When we insert the results of 1., we get
â§
âª
âª
âª
â¨
âª
âª
âª
â©
pk+1 = (M âˆ’k)Î»
(k + 1)Î¼ pk
for k = 0, 1, . . . , N âˆ’1,
pk+1 = (M âˆ’k)Î»
NÎ¼
pk
for k = N, . . . , M âˆ’1.
When the ï¬rst equation is multiplied by
1

M
k + 1

Î¼
Î»
 k+1
,
we get
pk+1

M
k + 1
 Î»
Î¼
k+1
=
(M âˆ’k)Î»
(k + 1)Î¼ Â·

M
k


M
k + 1
 Â· 1
Î»
Î¼
Â·
pk
 M
k

=
pk
 M
k
 Î»
Î¼
k = Â· Â· Â· =
p0
 M
0
 Î»
Î¼
0 = p0,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
72 
4. Queueing theory
hence
pk =

M
k
 Î»
Î¼
k
p0
for k = 0, 1, . . . , N.
We put n = N + m, m = 0, 1, . . . , M âˆ’N âˆ’1, into the second equation. Then
pN+m+1
=
M âˆ’N âˆ’m
MÎ¼
Â· Î»
Î¼ pN+m =
1
N m+1
Î»
Î¼
m+1
Â· (M âˆ’N âˆ’m) Â· Â· Â· (M âˆ’N)pN
=
1
N m+1
Î»
Î¼
m+1
Â·
(M âˆ’N)!
(M âˆ’N âˆ’m âˆ’1)! pN,
hence
pN+m =
1
N m
Î»
Î¼
m
Â·
(M âˆ’N)!
(M âˆ’N âˆ’m)! pN =
M!
N!(M âˆ’N âˆ’m)! Â·
1
N m
Î»
Î¼
N+m
p0,
for m = 0, 1, . . . , M âˆ’N.
3) The average number of machines in the queue is
M

k=N+1
(k âˆ’N)pk =
M

k=N
(k âˆ’N)pk.
We get in particular for N = 1,
M

k=1
(k âˆ’1)pk =
M

k=1
kpk âˆ’
M

k=1
pk =
M

k=1
kpk âˆ’(1 âˆ’p0) .
Then by the recursion formula of 2.,
pk+1 = (M âˆ’k) Î»
Î¼ pk = M Î»
Î¼ pk âˆ’Î»
Î¼ pk,
k = 1, . . . , M âˆ’1.
Hence
M

k=1
kpk
=
Mâˆ’1

k=1
kpk + MpM = M
Mâˆ’1

k=1
pk + MpM âˆ’Î¼
Î»
Mâˆ’1

k=1
pk+1 = M
M

k=0
pk âˆ’Mp0 âˆ’Î¼
Î»
M

k=2
pk
=
M (1 âˆ’p0) âˆ’Î¼
Î» (1 âˆ’p0 âˆ’p1) = M âˆ’Î¼
Î» (1 âˆ’p0) âˆ’Mp0 + Î¼
Î» p1.
It follows from
p1 = M âˆ’0
0 + 1 Â· Î»
Î¼ p0 = M Â· Î»
Î¼ p0,
by insertion that the average number of machines in the queue is for N = 1 given by
M

k=1
(k âˆ’1)pk
=
M

k=1
kpk âˆ’(1 âˆ’p0) = M âˆ’Î¼
Î» m (1 âˆ’p0) âˆ’Mp0 + Î¼
Î» Â· M Â· Î»
Î¼ p0 âˆ’(1 âˆ’p0)
=
M âˆ’
Î¼
Î» + 1
 
(1 âˆ’p0) = M âˆ’Î» + Î¼
Î»
(1 âˆ’p0) .
Download free eBooks at bookboon.com

Stochastic Processes 2
 
73 
4. Queueing theory
4) If there are n âˆˆ{1, 2, . . . , N} vacant service mechanics, the system is in state ENâˆ’n, so the
probability is
pNâˆ’n =

M
N âˆ’n
 Î»
Î¼
Nâˆ’n
p0,
n = 1, 2, . . . , N.
If there is no vacant service mechanic, we get the probability
1 âˆ’
N

n=1

M
N âˆ’n
 Î»
Î¼
Nâˆ’n
p0 = 1 âˆ’p0
Nâˆ’1

n=0
 M
n
 Î»
Î¼
n
.
5) If Î»
Î¼ = 1
10, M = 6 and N = 1, then the coeï¬ƒcient of loss of the machine is by 3. given by
1
M Â·

M âˆ’

1 + Î¼
Î»
 
(1 âˆ’p0)

= 1 âˆ’1
6 (1 + 10) Â· (1 âˆ’p0) = 1 âˆ’11
6 (1 âˆ’p0) .
We shall only ï¬nd p0. We get by using the recursion formulae
p1 = 6
10 p0,
p2 = 5
10 p1,
p3 = 4
10 p2,
p4 = 3
10 p3,
p5 = 2
10 p4,
p6 = 1
10 p5,
hence
1
=
6

k=0
pk = p0

1 + 6
10

1 + 5
10

1 + 4
10

1 + 3
10

1 + 2
10

1 + 1
10

â‰ˆ
p0 Â· 2.0639,
so
p0 â‰ˆ0.4845.
We also get by insertion the coeï¬ƒcient of loss of the machine,
1 âˆ’11
6 (1 âˆ’p0) â‰ˆ0.05049.
The loss coeï¬ƒcient of the service mechanic is
1
N Â· p0 = p0 â‰ˆ0.4845.
By comparison we see that the coeï¬ƒcients of loss are smallest in the system, where
Î»
Î¼ = 1
10,
M = 20,
N = 3,
so this system is the best.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
74 
4. Queueing theory
Example 4.9 In a shop the service time is exponentially distributed of mean 1
Î¼, thus the frequency
is given by
f(x) =
â§
â¨
â©
Î¼ eâˆ’Î¼x,
x > 0,
0,
x â‰¤0.
Let X1, X2, . . . denote the service times of customer number 1, 2, . . . . We assume that the Xi are
mutually independent and that they all have the frequency f(x) above.
In total there arrive to the shop N customers, where N is a random variable, which is independent of
all the Xi, and N can have the values 1, 2, . . . , of the probabilities
P{N = k} = p qkâˆ’1,
k âˆˆN,
where p > 0, q > 0, and p + q = 1.
1) Prove that Yn = 
n
i=1 Xi has the frequency
fn(x) =
â§
âª
âª
â¨
âª
âª
â©
Î¼ (Î¼x)nâˆ’1
(n âˆ’1)! eâˆ’Î¼x,
x > 0,
0,
x â‰¤0.
2) Find the frequency and the distribution function of Y = 
N
i=1 Xi by using that
P{Y â‰¤x} =
âˆ

k=1
P {N = k âˆ§Yk â‰¤x} .
3) Find mean and variance of Y .
1) Since Xi âˆˆÎ“

1, 1
Î¼

, it follows that
Yn =
n

k=1
Xk âˆˆÎ“

n, 1
Î¼

,
and the frequency is
fn(x) =
â§
âª
âª
â¨
âª
âª
â©
Î¼ (Î¼x)nâˆ’1
(n âˆ’1)! eâˆ’Î¼x,
x > 0,
0,
x â‰¤0.
2) It follows immediately (without using generating functions),
P{Y â‰¤x} =
âˆ

k=1
P {N = k, Yk â‰¤x} =
âˆ

k=1
P{N = k} Â· P {Yk â‰¤x} =
âˆ

n=1
pqnâˆ’1
 x
0
fn(t) dt.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
75 
4. Queueing theory
Thus we get for x > 0 the frequency
g(x)
=
âˆ

n=1
p qnâˆ’1fn(x) = p
âˆ

n=1
qnâˆ’1 Â·
Î¼
(n âˆ’1)! (Î¼x)nâˆ’1eâˆ’Î¼x = pÎ¼
âˆ

n=0
(qÎ¼x)n
n!
eâˆ’Î¼x
=
pÎ¼ e+qÎ¼x Â· eâˆ’Î¼x = pÎ¼ Â· eâˆ’pÎ¼x,
so Y âˆˆÎ“

1, 1
pÎ¼

is exponentially distributed of frequency
g(x) =
â§
â¨
â©
pÎ¼ eâˆ’pÎ¼x
for x > 0,
0
for x â‰¤0,
and distribution function
G(x) =
â§
â¨
â©
1 âˆ’eâˆ’pÎ¼x
for x > 0,
0
for x â‰¤0.
3) Since Y âˆˆÎ“

1, 1
pÎ¼

, we have
E{X} = 1
pÎ¼
og
V {X} =
1
p2Î¼2 .
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
360Â°
thinking.
Â© Deloitte & Touche LLP and affiliated entities.
Discover the truth at www.deloitte.ca/careers 

Stochastic Processes 2
 
76 
4. Queueing theory
Example 4.10 An old-fashioned shop with one shop assistant to serve the customers can be con-
sidered as a queuing system of one channel with the possibility of forming a queue. The customers
arrive according to a Poisson process of intensity Î», and the service time is exponentially distributed
of parameter Î¼. It has been noticed that when the system is in its equilibrium, then the shop assistant
is in mean busy 3
4 of the time, and the average staying time of customers is 10 minutes.
1. Prove that 1
Î» = 1
18 hour and 1
Î¼ = 1
24 hour.
2. Find the probability that a customer is served immediately.
3. Find the average queue length.
The shop is closed at 1730 and only the customers who are already in the shop are served by the shop
assistant, before he leaves for his home.
4. Find the probability that there at 1730 are 0, 1, 2, . . . customers in the shop.
5. Led the random variable T denote the time from 1730 until the shop assistant has served all cus-
tomers. Find the distribution of T.
It follows from Î»k = Î» and Î¼k = Î¼ that
Î¼pk+1 = Î»pk,
n âˆˆN0.
The traï¬ƒc intensity is
Ï± =
Î»
NÎ¼ = Î»
Î¼,
which we assume satisï¬es Ï± < 1, so p0 = 1 âˆ’Ï±. Thus
pk = Î»
Î¼ pkâˆ’1 = Â· Â· Â· =
Î»
Î¼
k
p0 = Ï±k Â· (1 âˆ’Ï±).
1) The staying time is
O =
1
Î¼ âˆ’Î» = 10 minutes = 1
6 hour,
and the shop assistant is busy
3
4 = 1 âˆ’p0 = Ï± = Î»
Î¼.
Hence Î» = 3
4 Î¼ and 6 = Î¼ âˆ’Î» = 1
4 Î¼, thus Î¼ = 24 and Î» = 3
4 Â· 24 = 18, corresponding to
1
Î» = 1
18 hour
and
1
Î¼ = 1
24 hour.
2) A customer is immediately served if the system is in state E0. The probability of this event is
p0 = 1 âˆ’Ï± = 1 âˆ’3
4 = 1
4.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
77 
4. Queueing theory
3) The average queue length is
Ï±2
1 âˆ’Ï± =
9
16
1 âˆ’3
4
= 9
4.
4) The probability that there are n customers in the shop at 1730 (t â‰ˆâˆ) is
pn = Ï±n(1 âˆ’Ï±) = 1
4 Â·
3
4
n
.
5) Assume that there are k customers in the shop.
Then the service time is Erlang distributed,
Î“

k, 1
Î¼

, of frequency
Î¼ Â· (Î¼x)kâˆ’1
(k âˆ’1)! eâˆ’Î¼x,
x > 0,
k âˆˆN.
It follows that the distribution of T is given by
P{T = 0} = 1
4
and
F â€²
T (x)
=
âˆ

k=1
1
4
3
4
k
Î¼ Â· (Î¼x)kâˆ’1
(k âˆ’1)! eâˆ’Î¼x = 1
4 Â· 3
4 Î¼ Â· eâˆ’Î¼x
âˆ

k=1
3
4 Î¼x
kâˆ’1
Â·
1
(k âˆ’1)!
=
3
16 Î¼ eâˆ’Î¼x exp
3
4 Î¼x

= 3
16 Î¼ Â· exp

âˆ’1
4 Î¼x

.
Then by an integration,
P{T â‰¤x} =
â§
âª
â¨
âª
â©
1 âˆ’3
4 exp

âˆ’Î¼
4 x
 
,
x â‰¥0,
0,
x < 0.
When we insert Î¼ = 24, found above, we get
P{T â‰¤x} =
â§
âª
â¨
âª
â©
1 âˆ’3
4 eâˆ’6x,
x â‰¥0,
0,
x < 0.
Alternatively, T has the Laplace transform
LT (Î») = P(L(Î»)),
where
L(Î») =
Î¼
Î» + Î¼
Download free eBooks at bookboon.com

Stochastic Processes 2
 
78 
4. Queueing theory
and
P(s) =
âˆ

k=0
pksk = 1
4
âˆ

k=0
3
4 s
k
= 1
4 Â·
1
1 âˆ’3
4 s
=
1
4 âˆ’3s.
Hence by insertion,
LT (Î») =
1
4 âˆ’
3Î¼
Î» + Î¼
= Î» + Î¼
4Î» + Î¼ = 1
4 Â· 1 + 3
4 Â·
1
4 Î¼
Î» + 1
4 Î¼
.
We recognize this Laplace transform as corresponding to
FT (x) =
â§
âª
â¨
âª
â©
1 âˆ’3
4 exp

âˆ’Î¼
4 x
 
,
x â‰¥0,
0,
x < 0.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
We will turn your CV into 
an opportunity of a lifetime
Do you like cars? Would you like to be a part of a successful brand?
We will appreciate and reward both your enthusiasm and talent.
Send us your CV. You will be surprised where it can take you.
Send us your CV on
www.employerforlife.com

Stochastic Processes 2
 
79 
4. Queueing theory
Example 4.11 Given a service, where we assume:
a. There are two channels.
b. The customers arrive by a Poisson process of intensity 1 minâˆ’1.
c. The service time is at each of the two channels exponentially distributed of mean 1 minute.
d. It is possible to form a queue.
1. Compute the average waiting time.
2. Find the fraction of time, in which both channels are vacant, and the fraction of time, in which
both channels are busy.
The ï¬‚ow of customers is then increased such that the customers now arrive according to a Poisson
process of intensity Î» = 2 minâˆ’1 (the other assumptions are unchanged).
3. What is the impact of this change on the service?
The service is then augmented by another channel of the same type as the old ones.
4. Compute in this system for Î» = 2 the average waiting time.
1) The process is described by a birth and death process with
Î»k1
and
Î¼1 = 1,
Î¼k = 2 for k â‰¥N = 2, thus Î¼ = 1.
The traï¬ƒc intensity is
Ï± =
Î»
NÎ¼ = 1
2.
We have
p0 = 1 âˆ’Ï±
1 + Ï± = 1
3
og
pk = 2Ï±k Â· 1 âˆ’Ï±
1 + Ï± = 1
3
1
2
kâˆ’1
for k âˆˆN.
The waiting time is given by
V = p0 Â· Ï±N Â· N Nâˆ’1
Î¼ Â· N!(1 âˆ’Ï±)2 = 1
3 Â·
1
2
2
Â·
1

1 âˆ’1
2
2 = 1
3.
2) Both channels are vacant in the fraction of time
p0 = 1
3.
Both channels are busy in the fraction of time
âˆ

k=2
pk = 1 âˆ’p0 âˆ’p1 = 1 âˆ’1
3 âˆ’1
3 = 1
3.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
80 
4. Queueing theory
3) The only change in the new system is Î»k = 2, thus
Î»k = 2
and
Î¼1 = 1,
Î¼k = 2 for k â‰¥2,
and Î¼ = 1.
The traï¬ƒc intensity is
Ï± =
Î»
NÎ¼ =
2
2 Â· 1 = 1.
The queue will increase indeï¬nitely.
4) Then we shift to N = 3 with Î» = 2 and Î¼ = 1, so
Î»k = 2,
Î¼1 = 1,
Î¼2 = 2
and
Î¼k = 3
for k â‰¥3.
The traï¬ƒc intensity is
Ï± =
Î»
NÎ¼ =
2
3 Â· 1 = 2
3.
It follows from
pk =
â§
âª
âª
âª
â¨
âª
âª
âª
â©
Ï±k Â· 1
k! N kp0,
k < N,
Ï±k Â· N N
N! p0,
k â‰¥N,
that
p1 = 2
3 Â· 1
1! Â· 3p0 = 2p0
and
p2 =
2
3
2
Â· 32
2! p0 = 2p0,
and
pk =
2
3
k
Â· 33
3! p0 = 2
2
3
kâˆ’1
p0
for k â‰¥3.
The sum is
1 =
âˆ

k=0
pk = p0

1 + 2 + 2 + 2
âˆ

k=3
2
3
kâˆ’2
= p0

3 + 2
âˆ

k=2
2
3
kâˆ’2
= 9p0,
from which p0 = 1
9. The waiting time is obtained by insertion,
V = p0Ï±N Â· N Nâˆ’1
Î¼ Â· N!(1 âˆ’Ï±)2 = 1
9 Â·
2
3
3
Â· 32
1 Â· 3!

1 âˆ’2
3
2 =
2
3
3
3 Â· 2
1
3
2 =
2
3
2
= 4
9.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
81 
4. Queueing theory
Example 4.12 Given a service for which
a. There are three channels.
b. The customers arrive according to a Poisson process of intensity 1 minâˆ’1.
c. The service time for each channel is exponentially distributed of mean 1 minute.
d. It is possible to form a queue.
1. Prove that the stationary probabilities are given by
pk =
â§
âª
âª
âª
â¨
âª
âª
âª
â©
4
11 Â· 1
k!,
k < 3,
2
33 Â·
1
3
kâˆ’3
,
k â‰¥3.
2. Find the fraction of time, in which all three channels are busy.
3. Compute the average length of the queue.
Decrease the number of channels to two while the other assumptions are unchanged. Compute in this
system,
4. the stationary probabilities,
5. the fraction of time, in which both channels are busy,
6. the average length of the queue.
Finally, decrease the number of channels to one, while the other assumptions are unchanged.
7. How will this system function?
1) The traï¬ƒc intensity is
Ï± =
Î»
NÎ¼ =
1
3 Â· 1 = 1
3.
It follows from
pk =
â§
âª
âª
â¨
âª
âª
â©
Ï±k Â· 1
k! N kp0,
k < N,
1
N! Ï±kN Np0,
k â‰¥N,
that
pk =
1
3
k
Â· 1
k! 3k Â· p0 = 1
k! p0
for k = 0, 1, 2, 3,
and
pk =
1
3
k
Â· 33
3! p0 = 1
6
1
3
kâˆ’3
p0
for k â‰¥3,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
82 
4. Queueing theory
hence
1 =
âˆ

k=0
pk = p0

1 + 1 + 1
2 + 1
6
âˆ

k=3
1
3
kâˆ’3
= p0
â§
âª
â¨
âª
â©
5
2 + 1
6 Â·
1
1 âˆ’1
3
â«
âª
â¬
âª
â­
= p0
5
2 + 1
4

= 11
4 p0,
from which p0 = 4
11, thus
pk =
â§
âª
âª
âª
â¨
âª
âª
âª
â©
4
11 Â· 1
k!,
k = 0, 1, 2,
2
33
1
3
kâˆ’3
,
k â‰¥3.
2) The fraction of time, in which all three channels are busy, is given by
âˆ

k=3
pk = 2
33
âˆ

k=3
1
3
kâˆ’3
= 2
33 Â·
1
1 âˆ’1
3
= 2
33 Â· 3
2 = 1
11.
Alternatively, it is given by
1 âˆ’p0 âˆ’p1 âˆ’p2 = 1 âˆ’4
11 âˆ’4
11
1
1! âˆ’4
11
1
2! = 1
11.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
AXA Global 
Graduate Program
Find out more and apply

Stochastic Processes 2
 
83 
4. Queueing theory
3) The average length of the queue is
âˆ

k=4
(k âˆ’3)pk
=
âˆ

k=4
(k âˆ’3) Â· 2
33
1
3
kâˆ’3
= 2
33
âˆ

k=1
k
1
3
k
=
2
33 Â· 1
3 Â·
1

1 âˆ’1
3
2 = 2
33 Â· 1
3 Â· 9
4 = 1
22.
4) If N = 2, then Ï± = 1
2. The stationary probabilities are
pk =
â§
âª
âª
âª
âª
âª
â¨
âª
âª
âª
âª
âª
â©
1 âˆ’1
2
1 + 1
3
= 1
3,
k = 0,
2
1
2
k
Â· 1 âˆ’1
2
1 + 1
2
= 1
3 Â·
1
2kâˆ’1 ,
k âˆˆN.
5) The fraction of times, in which both channels are busy, is
1 âˆ’p0 âˆ’p1 = 1 âˆ’1
3 âˆ’1
3 = 1
3.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
84 
4. Queueing theory
6) The average length of the queue is
âˆ

k=3
(k âˆ’2)pk =
âˆ

k=3
(k âˆ’2) Â· 2
3 Â· 1
2k = 2
3 Â·
1
2
3 âˆ

k=1
k
1
2
kâˆ’1
= 1
12 Â·
1

1 âˆ’1
2
2 = 1
3.
7) If there is only one channel, the traï¬ƒc intensity becomes Ï± = 1, and the queue is increasing
indeï¬nitely.
Example 4.13 A shop serves M customers, and there is one shop assistant in the shop. It is possible
to form a queue. We assume that the service time is exponentially distributed of mean 1
Î¼. Assume
also that if a customer is not in the shop at time t, then there is the probability Î»h + hÎµ(h) [where Î»
is a positive constant] that this customer arrives to the shop before the time t + h. Finally, assume
that the customers arrive to the shop mutually independent of each other. Thus we have a birth and
death process {X(t), t âˆˆ[0, âˆ[} of the states E0, E1, . . . , EM, where Ek denotes the state that there
are k customers in the shop, k = 0, 1, 2, . . . , M.
1) Prove that the birth intensities Î»k and death intensities Î¼k, k = 0, 1, 2, . . . , M, are given by
Î»k = (M âˆ’k)Î»,
Î¼k =
â§
â¨
â©
0,
k = 0,
Î¼,
k = 1, 2, . . . , M.
2) Find the equations of the stationary probabilities pk, k = 0, 1, 2, . . . , M.
3) Express the stationary probabilities pk, k = 0, 1, 2, . . . , M, by means of p0.
4) Compute the stationary probabilities pk, k = 0, 1, 2, . . . M.
5) Find, expressed by the stationary probability p0, the average number of customers, who are not in
the shop.
6) Compute the stationary probabilities, ï¬rst in the case, when Î»
Î¼ = 1 and M = 5, and then in the
case, when Î»
Î¼ = 1
2 and M = 5.
1) If we are in state Ek, then M âˆ’k of the customers are not in the shop. They arrive to the shop
before time t + h of probability
(M âˆ’k){Î» + Îµ(h)}h,
(a time interval of length h, and we divide by h before we go to the limit h â†’0). Hence, the birth
intensity is
Î»k = (M âˆ’k)Î»,
k = 0, 1, . . . , M.
If we are in state E0, then no customer is served, so Î¼0 = 0.
In any other state precisely one customer is served with the intensity Î¼, so
Î¼k = Î¼,
k = 1, 2, . . . , M.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
85 
4. Queueing theory
2) The equations of the stationary probabilities are
Î¼k+1pk+1 = Î»kpk.
Thus, in the explicit case,
pk+1 = (M âˆ’k) Î»
Î¼ pk.
3) We get successively
p0 = p0,
p1 = M Â· Î»
Î¼ p0,
p2 = M(M âˆ’1)
Î»
Î¼
2
p0,
and in general
pk =
M!
(M âˆ’k)!
Î»
Î¼
k
p0,
k = 0, 1, 2, . . . , M.
4) It follows from the equation
1 =
M

k=0
pk = M!
M

k=0
1
(M âˆ’k)!
Î»
Î¼
k
p0 = p0 Â· M!
Î»
Î¼
M
M

k=0
1
k!
Î¼
Î»
 k
p0
that
p0 =
1
M! 
M
k=0
1
k!
Î»
Î¼
Mâˆ’k =
Î¼
Î»
 M
M! 
M
k=0
1
k!
Î¼
Î»
 k ,
and hence
p
=
Î¼
Î»
 M
M! 
M
k=0
1
k!
Î¼
Î»
 k

1, M Î»
Î¼, M(M âˆ’1)
Î»
Î¼
2
, Â· Â· Â· ,
M!
(M âˆ’k)!
Î»
Î¼
k
, Â· Â· Â· , M!
Î»
Î¼
M
=
1
M! 
M
k=0
1
k!
Î¼
Î»
 k
â›
âœ
â
Î¼
Î»
 M
M!
,
Î¼
Î»
 Mâˆ’1
(M âˆ’1)! , Â· Â· Â· ,
Î¼
Î»
 Mâˆ’k
(M âˆ’k)! , Â· Â· Â· , 1
â
âŸ
â .
5) The average number of customers who are not in the shop is by e.g. 3.,
M

k=0
(M âˆ’k)pk
=
Mâˆ’1

k=0
M!
(M âˆ’k âˆ’1)!
Î»
Î¼
k
p0 =
M

k=1
M!
(M âˆ’k)!
Î»
Î¼
kâˆ’1
p0
=
Î¼
Î»
M

k=1
pk = Î¼
Î» (1 âˆ’p0) .
Download free eBooks at bookboon.com

Stochastic Processes 2
 
86 
4. Queueing theory
6) If Î»
Î¼ = 1 and M = 5, then
1 =
5

k=0
5!
(5 âˆ’k)! p0 = {1 + 5 + 20 + 60 + 120 + 120}p0 = 326p0,
and
p =
1
326 (1, 5, 20, 60, 120, 120).
7) NËšar Î»
Î¼ = 1
2 og M = 5, er
1 =
5

k=0
5!
(5 âˆ’k)!
1
2
k
p0 =

1 + 5
2 + 5 + 15
2 + 15
2 + 15
4

p0 = 109
4 p0
and
p =
4
109

1, 5
2, 5, 15
2 , 15
2 , 15
4

=
1
109 (4, 10, 20, 30, 30, 15).
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
ibili
because 
e Graduate Programme  
for Engineers and Geoscientists
Month 16
I was a construction
supervisor in 
the North Sea 
advising and 
helping foremen 
solve problems
I was a
he
s
Real work 
International opportunities 

ree work placements
al 
Internationa
or

ree wo
I wanted real responsibili 
 I joined MITAS because 
www.discovermitas.com

Stochastic Processes 2
 
87 
4. Queueing theory
Example 4.14 Given two queueing systems, A and B, which are mutually independent. We assume
for each of the two systems:
a. there is one channel,
b. it is possible to form a queue,
c. the customers arrive according to a Poisson process of intensity Î»,
d. the service times are exponentially distributed of parameter Î¼,
e. the traï¬ƒc intensity is Ï± = Î»
Î¼ = 1
2.
Denote by X1 the random variable which indicates the number of customers in system A, and by X2
the random variables which indicates the number of customers in system B.
1. Compute by using the stationary probabilities,
P {X1 = k}
and
P {X2 = k} ,
k âˆˆN0.
Let Z = X1 + X2 denote the total number of customers in the two systems.
2. Compute P{Z = k}, k âˆˆN0.
3. Compute the mean of Z
Consider another queuing system C, in which we assume,
a. there are two channels,
b. it is possible to form a queue,
c. the customers arrive according to a Poisson process of intensity 2Î»,
d. the service times are exponentially distributed of the parameter Î¼,
e. the traï¬ƒc intensity is Ï± = 2Î»
2Î¼ = 1
2.
Let the random variable Y denote the number of customers in system C.
4. Compute by using the stationary probabilities,
P{Y = k}
and
P{Y > k},
k âˆˆN0.
5. Compute the mean of Y .
6. Prove for all k âˆˆN0 that
P{Z > k} > P{Y > k}.
Hint to 6.: One may without proof use the formula,
âˆ

i=N
i xiâˆ’1 = xNâˆ’1{N âˆ’(N âˆ’1)x}
(1 âˆ’x)2
,
|x| < 1,
N âˆˆN.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
88 
4. Queueing theory
1) The two queueing systems follow the same distribution, and N = 1 and Ï± = 1
2, so we get by a
known formula,
P {X1 = k} = P {X2 = k} = pk = Ï±k Â· (1 âˆ’Ï±) =
1
2
k+1
,
k âˆˆN0.
2) A straightforward computation gives
P{Z = k}
=
k

j=0
P {X1 = j} Â· P {X2 = k âˆ’j} =
k

j=0
1
2
j+1
Â·
1
2
kâˆ’j+1
=
(k + 1) Â·
1
2
k+2
,
k âˆˆN0.
3) It follows from
E {X1} = E {X2} =
âˆ

k=1
k
1
2
k+1
= 1
4
âˆ

k=1
k Â·
1
2
kâˆ’1
= 1
4 Â·
1

1 âˆ’1
2
2 = 1,
that
E{Z}
=
âˆ

k=1
k(k + 1)
1
2
k+2
=
âˆ

k=2
k(k âˆ’1)
1
2
k+1
= 1
8
âˆ

k=2
k(k âˆ’1)
1
2
kâˆ’2
=
1
8 Â·
2!

1 âˆ’1
2
3 = 2.
4) Roughly speaking, A and B are joined to get C, so we have N = 2 and Ï± = 1
2. Then it follows that
P{Y = 0} = p0 = 1 âˆ’Ï±
1 + Ï± = 1
3,
and
P{Y = k} = 2Ï±k Â· 1 âˆ’Ï±
1 + Ï± = 1
3
1
2
kâˆ’1
,
k âˆˆN.
Thus
P{Y > k} =
âˆ

j=k+1
1
3
1
2
jâˆ’1
= 1
3 Â·
1
2
k
Â·
1
1 âˆ’1
2
= 1
3 Â·
1
2
kâˆ’1
,
k âˆˆN0.
5) The mean is
E{Y } =
âˆ

k=1
1
3 k
1
2
kâˆ’1
= 1
3 Â·
1

1 âˆ’1
2
2 = 4
3.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
89 
4. Queueing theory
6) It follows from 2. that
P{Z > k}
=
âˆ

j=k+1
(j + 1)
1
2
j+2
= 1
4
âˆ

j=k+2
j
1
2
jâˆ’1
=
1
4 Â·
 1
2
k+1 
k + 2 âˆ’(k + 1) 1
2


1 âˆ’1
2
2
=
1
2
k+2
Â· {2k + 4 âˆ’k âˆ’1}
=
k + 3
8
Â·
1
2
kâˆ’1
> 1
3 Â·
1
2
kâˆ’1
= P{Y > k}.
We notice that P{Y = k} = P{Y > k} for k âˆˆN, and that this is not true for k = 0.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
MASTER IN MANAGEMENT
mim.admissions@ie.edu
Follow us on IE MIM Experience
www.ie.edu/master-management
#10 WORLDWIDE
MASTER IN MANAGEMENT 
FINANCIAL TIMES
55 Nationalities
in class
5 Specializations
Personalize your program 
Length: 1O MONTHS
Av. Experience: 1 YEAR
Language: ENGLISH / SPANISH
Format: FULL-TIME
Intakes: SEPT / FEB
â€¢ STUDY IN THE CENTER OF MADRID AND TAKE ADVANTAGE OF THE UNIQUE OPPORTUNITIES
  THAT THE CAPITAL OF SPAIN OFFERS
â€¢ PROPEL YOUR EDUCATION BY EARNING A DOUBLE DEGREE THAT BEST SUITS YOUR
  PROFESSIONAL GOALS
â€¢ STUDY A SEMESTER ABROAD AND BECOME A GLOBAL CITIZEN WITH THE BEYOND BORDERS
  EXPERIENCE
93%
OF MIM STUDENTS ARE
WORKING IN THEIR SECTOR 3 MONTHS
FOLLOWING GRADUATION

Stochastic Processes 2
 
90 
4. Queueing theory
Example 4.15 Given two mutually independent queueing systems A and B. We assume for each of
the two systems,
a. there is one channel,
b. it is possible to form a queue,
c. customers arrive to A according to a Poisson process of intensity Î»A = 1
3 minuteâˆ’1, and they
arrive to B according to a Poisson process of intensity Î»B = 2
3 minuteâˆ’1,
d. the service times of both A and B are exponentially distributed of the parameter Î¼ = 1 minuteâˆ’1.
Let the random variable XA denote the number of customers in system A, and let the random variable
XB denote the number of customers in system B. Furthermore, we let YA and YB, resp., denote the
number of customers in the queue at A and B, resp..
1. Find by using the stationary probabilities,
P {XA = k}
and
P {XB = k} ,
k âˆˆN0.
2. Find the average waiting times at A and B, resp..
3. Find by using the stationary probabilities,
P {YA = k}
and
P {YB = k} ,
k âˆˆN0.
4. Find the means E {XA + XB} and E {YA + YB}.
5. Compute P {XA + XB = k}, k âˆˆN0.
The two queueing systems are now joined to one queueing system of two channels, where the customers
arrive according to a Poisson process of intensity Î» = Î»A + Î»B, and where the serving times are
exponentially distributed of parameter Î¼ = 1 minuteâˆ’1. Let X denote the number of customers in the
system, and let Y denote the number of customers in the queue.
6. Find by using the stationary probabilities,
P{X = k}
and
P{Y = k},
k âˆˆN0.
7. Find the means E{X} and E{Y }.
1A. Since Î»A = 1
3 minuteâˆ’1 and Î¼ = 1 minuteâˆ’1, and N = 1, we get the traï¬ƒc intensity Ï±A = 1
3.
The stationary probabilities are
P {XA = k} = pA,k = 2 Â·
1
3
k+1
,
k âˆˆN0.
1B. Analogously, Î»B = 2
3 minuteâˆ’1 and Î¼ = 1 minuteâˆ’1, and N = 1, so Ï±B = 2
3, and
P {XB = k} = pB,k = 1
3
2
3
k
= 1
2
2
3
k+1
,
k âˆˆN0.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
91 
4. Queueing theory
2A. The waiting time at A is given by
VA =
Ï±A
Î¼ (1 âˆ’Ï±A) =
1
3
1 Â· 2
3
= 1
2.
2B. Analogously, the waiting time at B is
VB =
Ï±B
Î¼ (1 âˆ’Ï±B) =
2
3
1 Â· 1
3
= 2.
3A. Assume that there is no queue at A. Then either there is no customer at all in the system, or
there is precisely one customer, who is served for the time being,
P {YA = 0} = P {XA = 0} + P {XA = 1} = 2 Â·
1
3 + 1
9

= 8
9.
If k âˆˆN, then
P {YA = k} = P {XA = k + 1} = 2 Â·
1
3
k+2
.
3B. Analogously,
P {YB = 0} = P {XB = 0} + P {XB = 1} = 1
3

1 + 2
3

= 5
9
and
P {YB = k} = P {XB = k + 1} = 1
2
2
3
k+2
,
k âˆˆN0.
4. It follows from
E {XA} = 2
âˆ

k=1
k
1
3
k+1
= 2
9
âˆ

k=1
k
1
3
kâˆ’1
= 2
9 Â·
1

1 âˆ’1
3
2 = 1
2
and
E {XB} = 2
9
âˆ

k=1
k
2
3
kâˆ’1
= 2
9 Â·
1

1 âˆ’2
3
2 = 2,
that
E {XA + XB} = 1
2 + 2 = 5
2.
It follows from
E {YA} = 2
âˆ

k=1
k
1
3
k+2
= 2
27
âˆ

k=1
k
1
3
kâˆ’1
= 2
27 Â·
1

1 âˆ’1
3
2 = 1
6
Download free eBooks at bookboon.com

Stochastic Processes 2
 
92 
4. Queueing theory
and
E {YB} = 1
2
âˆ

k=1
k
2
3
k+2
= 4
27
âˆ

k=1
k
2
3
kâˆ’1
= 4
27 Â·
1

1 âˆ’2
3
2 = 4
3,
then
E {YA + YB} = 1
6 + 4
3 = 3
2.
5. If k âˆˆN0, then
P {XA + XB = k}
=
k

j=0
P {XA = j} Â· P {XB = k âˆ’j}
=
k

j=0
2 Â·
1
3
j+1
Â· 1
2 Â·
2
3
kâˆ’j+1
=
k

j=0
1
3
k+2
Â· 2kâˆ’j+1
=
1
3
k+2 k+1

n=1
2n =

2k+2 âˆ’2

Â·
1
3
k+2
=
2
3
k+2
âˆ’2
1
3
k+2
=
2
3k+2

2k+1 âˆ’1

.
6. The traï¬ƒc intensity is
Ï± = Î»A + Î»B
NÎ¼
=
1
3 + 2
3
2 Â· 1 = Î»
2Î¼ = 1
2.
It follows that
P{X = k} = pk =
â§
âª
âª
âª
â¨
âª
âª
âª
â©
1
3,
k = 0,
2
3
1
2
k
,
k âˆˆN.
Since Y = (X âˆ’2) âˆ¨0, we get
P{Y = 0} = P{X = 0} + P{X = 1} + P{X = 2} = 1
3 + 1
3 + 1
6 = 5
6
and
P{Y = k} = P{X = k + 2} = 2
3
1
2
k+2
= 1
6
2
3
k
,
k âˆˆN.
7. By a straightforward computation,
E{X} = 2
3
âˆ

k=1
k
1
2
k
= 1
3
âˆ

k=1
k
1
2
kâˆ’1
= 1
3 Â·
1

1 âˆ’1
2
2 = 4
3
Download free eBooks at bookboon.com

Stochastic Processes 2
 
93 
4. Queueing theory
and
E{Y } = 1
6
âˆ

k=1
k
1
2
k
= 1
4 E{X} = 1
3.
Example 4.16 Consider a birth and death process E0, E1, E2, . . . , where the birth intensities Î»k
are given by
Î»k =
Î±
k + 1,
k âˆˆN0,
where Î± is a positive constant, while the death intensities Î¼k are given by
Î¼k =
â§
â¨
â©
0,
k = 0,
Î¼,
k = 1,
2Î¼,
k â‰¥2,
where Î¼ > 0. We assume that Î±
Î¼ = 8.
1. Find the equations of the stationary probabilities pk, k âˆˆN0.
2. Prove that
pk = 2 Â· 4k Â· 1
k! p0,
k âˆˆN,
and ï¬nd p0.
The above can be viewed as a model of the forming of a queue in a shop, where
a. there are two shop assistants,
b. the service time is exponentially distributed of mean 1
Î¼,
c. the frequency of the arrivals is decreasing with increasing number of customers according to the
indicated formula.
3. Compute by means of the stationary probabilities the average number of customers in the shop. (3
dec.).
4. Compute by means of the stationary probabilities the average number of busy shop assistants. (3
dec.).
5. Compute by means of the stationary probabilities the probability that there are more than two
customers in the shop. (3 dec.).
1) We have
Î¼k+1pk+1 = Î»kpk,
k âˆˆN0,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
94 
4. Queueing theory
thus
p1 = Î»0
Î¼1
p0 = Î±
Î¼ p0 = 8p0
and
pk = Î»kâˆ’1
Î¼k
pkâˆ’1 = Î±
k Â· 1
2Î¼ pkâˆ’1 = 4
k pkâˆ’1
for k â‰¥2.
2) If k = 1, then
p1 = 8p0 = 2 Â· 41
1! p0,
and the formula is true for k = 1. Then assume that
pkâˆ’1 = 2 Â· 4kâˆ’1 Â·
1
(k âˆ’1)! p0.
Then
pk = 4
k pkâˆ’1 = 2 Â· 4k
k! p0,
and the formula follows by induction.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Stochastic Processes 2
 
95 
4. Queueing theory
It follows from
1 =
âˆ

k=0
pk = p0

1 + 2
âˆ

k=1
4k
k!

= p0

2e4 âˆ’1

that
p0 =
1
2e4 âˆ’1.
3) The task is now changed to queueing theory. Since pk is the probability that there are k customers
in the shop, the mean of the number of customers in the shop is
âˆ

k=1
kpk = 2 Â· 4 Â· p0
âˆ

k=1
4kâˆ’1
(k âˆ’1)! =
8e4
2e4 âˆ’1 â‰ˆ4.037.
4) The average number of busy shop assistants is
0 Â· p0 + 1 Â· p1 + 2
âˆ

k=2
pk = p1 + 1 (1 âˆ’p0 âˆ’p1)
=
2 âˆ’2p0 âˆ’p1 = 2 âˆ’2p0 âˆ’8p0
=
2 âˆ’10p0 = 2 âˆ’
10
2e4 âˆ’1 = 1.908.
5) The probability that there are more than two customers in the shop is
âˆ

k=3
pk = 1 âˆ’p0 âˆ’p1 âˆ’p2 = 1 âˆ’p0

1 + 8 + 32
2

= 1 âˆ’
25
2e4 âˆ’1 â‰ˆ0.769.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
96 
4. Queueing theory
Example 4.17 Consider a birth and death process of the states E0, E1, E2, . . . , where the birth
intensities Î»k are given by
Î»k =
 2Î»,
k = 0,
Î»,
k âˆˆN,
while the death intensities Î¼k are given by
Î¼k =

0,
k = 0,
Î¼,
k âˆˆN.
Here, Î» and Î¼ are positive constants, and we assume everywhere that Î»
Î¼ = 3
4.
1. Find the equations of the stationary probabilities, and prove that the stationary probabilities are
given by
pk = 2 Â·
3
4
k
p0,
k = 1, 2, 3, . . . ,
and ï¬nally, ï¬nd p0.
The above can be considered as a model of forming queues in a shop, where
a. there is one shop assistant,
b. the service time is exponentially distributed of mean 1
Î¼,
c. the customers arrive according to a Poisson process of intensity 2Î». However, if there already are
customers in the shop, then half of the arriving customers will immediately leave the shop without
being served.
2. Compute by means of the stationary probabilities the average number of customers in the shop.
3. Compute by means of the stationary probabilities the average number of customers in the queue.
We now assume that instead of one shop assistant there are two shop assistants and that all arriving
customers are served (thus we have the birth intensities Î»k = 2Î», k âˆˆN0).
4. Compute in this queueing system the stationary probabilities and then ï¬nd the average number of
customers in the queue.
1) The equations of the stationary probabilities are
Î¼k+1pk+1 = Î»kpk,
k âˆˆN0,
thus
p1 = 2Î»
Î¼ p0 = 3
2 p0 = 2 Â·
3
4
1
p0,
and
pk = Î»
Î¼ pkâˆ’1 = 3
4 pkâˆ’1,
k â‰¥2,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
97 
4. Queueing theory
hence by recursion,
pk =
3
4
kâˆ’1
p1 = 2 Â·
3
4
k
p0,
k â‰¥2.
We get
1 =
âˆ

k=0
pk = p0 + p0
âˆ

k=1
2 Â·
3
4
k
= p0
â§
âª
â¨
âª
â©
1 + 2 Â· 3
4 Â·
1
1 âˆ’3
4
â«
âª
â¬
âª
â­
= p0

1 + 3
2 Â· 4

= 7p0,
so
p0 = 1
7
and
pk = 2
7 Â·
3
4
k
,
k âˆˆN.
2) Since pk is the probability that there are k customers in the shop, the average number of customer
in the shop is
âˆ

k=1
kpk = 2
7 Â· 3
4
âˆ

k=1
k Â·
3
4
kâˆ’1
= 3
14 Â·
1

1 âˆ’3
4
2 = 3
14 Â· 16 = 24
7 .
3) If there are k customers in the queue, there must also be 1 customer, who is being served, so the
average is
âˆ

k=1
kpk+1 = 2
7 Â· 3
4 Â· 3
4
âˆ

k=1
k
3
4
kâˆ’1
= 3
28 Â· 24 = 18
7 ,
where we have used the result of 2.
4) The traï¬ƒc intensity is Ï± = 2Î»
2 Â· Î¼ = 3
4, and since N = 2, we get
p0 = 1 âˆ’Ï±
1 + Ï± = 1
7
and
pk = 2
7
3
4
k
,
k âˆˆN.
We see that they are identical with the stationary probabilities found in 1..
The average length of the queue is given by (end here we get to the divergence from the previous
case)
âˆ

k=3
(k âˆ’2)pk
=
2
7
âˆ

k=3
(k âˆ’2)
3
4
k
= 2
7
âˆ

k=1
k
3
4
k+2
= 2
7 Â·
3
4
3 âˆ

k=1
k
3
4
kâˆ’1
=
2
7 Â·
3
4
3
Â·
1

1 âˆ’3
4
2 = 2
7 Â· 27
4 = 27
14.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
98 
4. Queueing theory
Example 4.18 Consider a birth and death process of states E0, E1, E2, . . . , and with birth intensities
Î»k given by
Î»k =
â§
âª
â¨
âª
â©
Î±,
k = 0, 1,
Î±
k ,
k â‰¥2,
where Î± is a positive constant, and where the death intensities are given by
Î¼k =
 0,
k = 0,
Î¼,
k âˆˆN,
where Î¼ > 0.
We assume in the following that Î±
Î¼ = 2.
1. Find the equations of the stationary probabilities pk, k âˆˆN0.
2. Prove that
pk =
2k
(k âˆ’1)! p0,
k âˆˆN,
and ï¬nd p0.
The above can be considered as a model of forming a queue in a shop where
a. there is one shop assistant,
b. the serving time is exponentially distribution of mean 1
Î¼,
c. the frequency of arrivals decreasis with increasing number of customers according to the formula
for Î»k above.
3. Compute by means of the stationary probabilities the average length of the queue (3 dec.).
4. Compute by means of the stationary probabilities the average number of customers in the shop (3
dec.).
1) We have
Î¼k+1pk+1 = Î»kpk,
k âˆˆN0,
and
âˆ

k=0
pk = 1.
Hence, successively,
Î¼p1 = Î±p0,
Î¼p2 = Î±p1,
and
Î¼pk =
Î±
k âˆ’1 pkâˆ’1
for k â‰¥3.
It follows from Î±
Î¼ = 2 that
(6) p1 = 2p0,
p2 = 2p1,
pk =
2
k âˆ’1pkâˆ’1,
k â‰¥3,
and
âˆ

k=0
pk = 1.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
99 
4. Queueing theory
2) We infer from (6) that p1 = 2p0 and p2 = 2p2 = 4p0, and for k â‰¥3,
pk =
2
k âˆ’1 pkâˆ’1 =
22
(k âˆ’1)(k âˆ’2) pkâˆ’2 = Â· Â· Â· =
2kâˆ’2
(k âˆ’1)! p2 =
22
(k âˆ’1)! p0.
A check shows that the latter formula is also true for k = 1 and k = 2, thus
pk =
2k
(k âˆ’1)! p0,
k âˆˆN.
Then we ï¬nd p0 from
1 =
âˆ

k=0
pk = p0

1 +
âˆ

k=1
2k
(k âˆ’1)!

= p0

1 + 2
âˆ

k=1
2kâˆ’1
(k âˆ’1)!

= p0

1 + 2e2
,
thus
p0 =
1
1 + 2e2
(â‰ˆ0.0634),
and
pk =
2k
(k âˆ’1)! Â·
1
1 + 2e2 ,
k âˆˆN.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
â€œThe perfect start 
of a successful, 
international career.â€
CLICK HERE 
to discover why both socially 
and academically the University 
of Groningen is one of the best 
places for a student to be 
www.rug.nl/feb/education
Excellent Economics and Business programmes at:

Stochastic Processes 2
 
100 
4. Queueing theory
3) The average length of the queue is (notice that since 1 customer is served, we have here k âˆ’1
instead of k),
âˆ

k=2
(k âˆ’1)pk =
âˆ

k=2
k âˆ’1
(k âˆ’1)! 2k p0 = 4
âˆ

k=2
2kâˆ’2
(k âˆ’2)! p0 = 4e2p0 =
4e2
1 + 2e2 â‰ˆ1.873.
4) The average number of customers is
âˆ

k=1
kpk
=
âˆ

k=1 (2)
(k âˆ’1)pk +
âˆ

k=1
pk = 4e2p0 + (1 âˆ’p0)
=
4e2
1 + 2e2 +
2e2
1 + 2e2 =
6e2
1 + 2e2 â‰ˆ2.810.
Example 4.19 Given a queueing system, for which
a. there is one shop assistant,
b. it is possible to form a queue,
c. the customers arrive according to a Poisson process of intensity Î»,
d. the serving times are exponentially distributed of parameter Î¼,
e. the traï¬ƒc intensity Î»
Î¼ is 2
3.
Let the random variable X denote the number of customers in the system, and let Y denote the number
of customers in the queue.
1. Find by means of the stationary probabilities,
P{X = k}
and
P{Y = k},
k âˆˆN0.
2. Find the means E{X} and E{Y }.
The system is changed by introducing another shop assistant, whenever there are 3 or more customers
in the shop; this extra shop assistant is withdrawn after ending his service, if the number of customers
then is smaller than 3. The other assumptions are unchanged.
3. Explain why this new system can be described by a birth and death process of states E0, E1, E2,
. . . , birth intensities Î»k = Î», k âˆˆN0, and death intensities Î¼k given by
Î¼k =
â§
â¨
â©
0,
k = 0,
Î¼,
k = 1, 2,
2Î¼,
k = 3, 4, . . . .
4. Find the stationary probabilities pk of this system.
5. Find the average number of customers in the system,
âˆ

k=1
kpk.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
101 
4. Queueing theory
1) Since N = 1, it follows that
pk = 1
3
2
3
k
,
k âˆˆN0,
thus
P{X = k} = pk = 1
3
2
3
k
,
k âˆˆN0,
and
P{Y = 0}
=
P{X = 0} + P{X = 1} = 1
3

1 + 2
3

= 5
9,
P{Y = k}
=
P{X = k + 1} = 1
3
2
3
k+1
,
k âˆˆN.
2) The means are
E{X} =
âˆ

k=1
kpk = 1
3 Â· 2
3
âˆ

k=1
k Â·
2
3
kâˆ’1
= 2,
and
E{Y } =
âˆ

k=1
1
3

k 2
3
k+1
= 2
3 E{X} = 4
3.
3) The birth intensities Î»k = Î», k âˆˆN0, are clearly not changed, and Î¼0 = 0, Î¼1 = Î¼2 = Î¼. When
k â‰¥3, another shop assistant is also serving the customers, so Î¼k = 2Î¼ for k â‰¥3.
4) We have
Î¼k+1pk+1 = Î»kpk.
Thus we get the equations
p1 = Î»
Î¼ p0 = 2
3 p0,
p2 = Î»
Î¼ p1 = 2
3 p1,
and
pk+1 = Î»
2Î¼ pk = 1
3 pk,
k â‰¥2.
Hence
p1 = 2
3 p0,
p2 = 4
9 p0,
and
pk =
1
3
kâˆ’2
p2 = 3
1
3
k
p0
for k â‰¥3.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
102 
4. Queueing theory
It follows from
1
=
âˆ

k=0
p0 = p0

1 + 2
3 + 4
9 + 4
âˆ

k=3
1
3
k
= p0
â§
â¨
â©
5
3 + 4
9
âˆ

j=0
1
3
j
â«
â¬
â­= p0
â§
âª
â¨
âª
â©
5
3 + 4
9 Â·
1
1 âˆ’1
3
â«
âª
â¬
âª
â­
=
p0
5
3 + 4
9 Â· 3
2

= p0
5
3 + 2
3

= 7
3 p0,
that
p0 = 3
7,
p1 = 2
7,
p2 = 4
21,
and
pk = 4
7 Â·
1
3
kâˆ’1
,
k â‰¥3.
5) The average number of customers is
âˆ

k=1
kpk
=
2
7 + 8
21 + 4
7
âˆ

k=3
k Â·
1
3
kâˆ’1
= 6 + 8
221 + 4
7
 âˆ

k=1
k
1
3
kâˆ’1
âˆ’1 âˆ’2
3

=
2
3 + 4
7
â§
âª
âª
âª
â¨
âª
âª
âª
â©
1

1 âˆ’1
3
2 âˆ’5
3
â«
âª
âª
âª
â¬
âª
âª
âª
â­
= 2
3 + 4
7
9
4 âˆ’5
3

= 2
3 + 4
7 Â· 27 âˆ’20
4 Â· 3
= 2
3 + 1
3 = 1.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
American online      
LIGS University 
â–¶â–¶enroll by September 30th, 2014 and 
â–¶â–¶save up to 16% on the tuition!
â–¶â–¶pay in 10 installments / 2 years
â–¶â–¶Interactive Online education
â–¶â–¶visit www.ligsuniversity.com to 
      find out more!
is currently enrolling in the
Interactive Online BBA, MBA, MSc, 
DBA and PhD  programs:
Note: LIGS University is not accredited by any 
nationally recognized accrediting agency listed 
by the US Secretary of Education. 
More info here. 

Stochastic Processes 2
 
103 
4. Queueing theory
Example 4.20 Given a queueing for which
a. there is one channel,
b. there is the possibility of an (unlimited) queue,
c. the customers arrive according to a Poisson process of intensity Î»,
d. the service times are exponentially distributed of parameter Î¼,
e. the traï¬ƒc intensity Î»
Î¼ is 4
5.
Let the random variable X denote the number of customers in the system.
1. Find by using the stationary probabilities,
P{X = k}
and
P{X > k},
k âˆˆN0.
2. Find the mean E{X}.
We then change the system, such that there is only room for at most 3 waiting customers, thus only
room for 4 customers in total in the system (1 being served and 3 waiting). The other conditions are
unchanged. This system can be described by a birth and death process of the states E0, E1, E2, E3,
E4 and
birth intensities:
Î»k =
 Î»,
k = 0, 1, 2, 3,
0,
k = 4,
death intensities:
Î¼k =

0,
k = 0,
Î¼,
k = 1, 2, 3, 4.
Let the random variable Y denote the number of customers in this system.
3. Find by means of the stationary probabilities,
P{Y = k},
k = 0, 1, 2, 3, 4,
(3 dec.).
4. Find the means E{Y } (3 dec.).
Now the intensity of arrivals Î» is doubled, while the other assumptions are the same as above. This will
imply that the probability of rejection becomes too big, so one decides to hire another shop assistant.
Then the system can be described by a birth and death process with states E0, E1, E2, E3, E4, E5,
(where E5 corresponds to 2 customers being served and 3 waiting).
5. Find the equations of this system of the stationary probabilities p0, p1, p2, p3, p4, p5.
6. ï¬nd the stationary probabilities (3 dec.).
1) We have
P{X = k} = pk = Ï±k(1 âˆ’Ï±) = 1
5
4
5
k
,
k âˆˆN0,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
104 
4. Queueing theory
hence
P{X > k} =
âˆ

j=k+1
1
5
4
5
j
= 1
5 Â·
4
5
k+1
1 âˆ’4
5
=
4
5
k+1
,
k âˆˆN0.
2) The mean is
E{X} = 1
5 Â· 4
5
âˆ

k=1
k
4
5
kâˆ’1
= 4
25 Â·
1

1 âˆ’4
5
2 = 4.
3) It follows from
Î¼k+1pk+1 = Î»kpk,
that
p1 = Î»
Î¼ p0 = 4
5 p0,
p2 =
4
5
2
p0,
p3 =
4
5
3
p0,
p4 =
4
5
4
p0,
hence
1 = p0

1 + 4
5 +
4
5
2
+
4
5
3
+
4
5
4
= p0 Â·
1 âˆ’
4
5
5
1 âˆ’4
5
= p0

5 âˆ’4 Â·
4
5
4
,
and
P{Y = 0}
=
p0
=
1
5 âˆ’4
 4
5
4
â‰ˆ
0.297,
P{Y = 1}
=
p1
=
4
5 p0
â‰ˆ
0.238,
P{Y = 2}
=
p2
=
4
5 p1
â‰ˆ
0.190,
P{Y = 3}
=
p3
=
4
5 p2
â‰ˆ
0.152,
P{Y = 4}
=
p4
=
4
5 p3
â‰ˆ
0.122.
4) The mean is
E{Y } = 1 Â· p1 + 2p2 + 3p3 + 4p4 =

4
5 + 2
4
5
2
+ 3
4
5
3
+ 4
4
5
4
p0 â‰ˆ1.563.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
105 
4. Queueing theory
5) The birth intensities are
Î»k =
 2Î»,
k = 0, 1, 2, 3, 4,
0,
k = 5,
and the death intensities are
Î¼k =
â§
â¨
â©
0,
k = 0,
Î¼,
k = 1,
2Î¼,
k = 2, 3, 4, 5.
It follows from
Î¼k+1pk+1 = Î»kpk,
that
p1 = 2Î»
Î¼ p0 = 8
5,
and
pk = 2Î»
2Î¼ pkâˆ’1 = 4
5 pkâˆ’1
for k = 2, 3, 4, 5.
6) Now
pk = 2
4
5
k
p0
for k = 1, 2, 3, 4, 5,
thus
1
=
p0

1 + 8
5

1 + 4
5 +
4
5
2
+
4
5
3
+
4
5
4
= p0
â§
âª
âª
âª
â¨
âª
âª
âª
â©
1 + 8
5 Â·
1 âˆ’
4
5
5
1 âˆ’4
5
â«
âª
âª
âª
â¬
âª
âª
âª
â­
=
p0

9 âˆ’8
4
5
5
,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
106 
4. Queueing theory
and hence
p0
=
1
9 âˆ’8
4
5
5
â‰ˆ
0, 157,
p1
=
2 Â· 4
5 p0
â‰ˆ
0.251,
p2
=
4
5 p1
â‰ˆ
0.201,
p3
=
4
5 p2
â‰ˆ
0.161,
p4
=
4
5 p3
â‰ˆ
0.128,
p5
=
4
5 p4
â‰ˆ
0.103.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Stochastic Processes 2
 
107 
4. Queueing theory
Example 4.21 Given two queueing systems A and B, which are independent of each other.
We
assume for each of the systems,
a. there is one shop assistant,
b. It is possible to have a queue,
c. customers are arriving to A according a Poisson process of intensity Î»A = 3
4 minuteâˆ’1, and to B
according to a Poisson process of intensity Î»B = 1
2 minuteâˆ’1,
d. the service times at both A and B are exponentially distributed of parameter Î¼ = 1 minuteâˆ’1.
Let the random variable XA denote the number of customers in system A, and let XB denote the
number of customers in system B.
1. Find by means of the stationary probabilities,
P {XA = k}
and
P {XB = k} ,
k âˆˆN0.
2. Find the average waiting times at A and B, resp..
3. Compute the probabilities P {XB > k}, k âˆˆN0, and then ï¬nd
P {XA < XB} .
The arrivals of the customers at A is now increased, such that the customers arrive according to a
Poisson process of intensity 1 minuteâˆ’1. For that reason the two systems are joined to one queueing
system with two shop assistants, thus the customers now arrive according to a Poisson process of
intensity
Î» =

1 + 1
2

minuteâˆ’1 = 3
2 minuteâˆ’1,
and the service times are still exponentially distributed with the parameter
Î¼ = 1 minutâˆ’1.
Let Y denote the number of customers in this new system.
4. Find by means of the stationary probabilities,
P{Y = k},
k âˆˆN0.
5. Prove that the average number of customers in the new system, E{Y }, is smaller than E {XA + XB}.
1A. We get from Ï±A = Î»A
Î¼ = 3
4 and N = 1 that
P {XA = k} = pA,k = 1
4
3
4
k
,
k âˆˆN0.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
108 
4. Queueing theory
1B. Analogously, Ï±B = 1
2, so
P {XB = k} = pB,k =
1
2
k+1
,
k âˆˆN0.
2. Since N = 1, the waiting times are
VA =
Ï±A
Î¼ (1 âˆ’Ï±A) =
3
4
1 Â· 1
4
= 3
and
VB =
Ï±B
Î¼ (1 âˆ’Ï±B) = 1.
3. We get
P {XB > k} =
âˆ

j=k+1
1
2
j+1
=
1
2
k+2
1 âˆ’1
2
=
1
2
k+1
,
k âˆˆN0,
so
P {XA < XB}
=
âˆ

k=0
P {XA = k} Â· P {XB > k} =
âˆ

k=0
1
4
3
4
k
Â·
1
2
k+1
=
1
8
âˆ

k=0
3
8
k
= 1
8 Â·
1
1 âˆ’3
8
= 1
5.
The new traï¬ƒc intensity is
Ï± = Î»
2Î¼ =
3
2
2 Â· 1 = 3
4,
and since N = 2, we get
p0 = 1 âˆ’Ï±
1 + Ï± = 1
7,
pk = 2Ï±k Â· 1 âˆ’Ï±
1 + Ï± = 2
7
3
4
k
,
k âˆˆN,
thus
P{Y = 0} = 1
7
and
P{Y = k} = 2
7
3
4
k
,
k âˆˆN.
Then
E{Y } = 2
7 Â· 3
4
âˆ

k=1
k
3
4
kâˆ’1
= 3
14 Â·
1

1 âˆ’3
4
2 = 3 Â· 16
14
= 24
7 ,
and
E {XA} = 1
4 Â· 3
4
âˆ

k=1
k
3
4
kâˆ’1
= 3
16 Â· 16 = 3,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
109 
4. Queueing theory
and
E {XB} = 1
4
âˆ

k=1
k
1
2
kâˆ’1
= 1
4 Â·
1

1 âˆ’1
2
2 = 1,
hence
E {XA + XB} = 3 + 1 = 4 > 24
7 = E{Y }.
Example 4.22 Given two independent queueing systems A and B, where we assume for each of them,
a. there is one shop assistant,
b. it is possible to create a queue,
c. the customers arrive according to a Poisson process of intensity Î» = 3
5 minâˆ’1,
d. the service times are exponentially distributed of parameter Î¼ = 1 minâˆ’1.
Let the random variable XA denote the number of customers in system A, and let XB denote the
number of customers in system B, and put Z = XA + XB.
1. Compute by means of the stationary probabilities,
P {XA = k}
and
P {XB = k} ,
k âˆˆN0.
2. Find the means E {XA}, E {XB} and E{Z}.
3. Compute P{Z = k}, k âˆˆN0.
The number of arrivals of customers to A is increased, so the customers are arriving according
to a Poisson process of intensity 1 minuteâˆ’1.
Therefore, the two systems are joined to one sys-
tem with two shop assistants, so the customers now arrive according to a Poisson process of in-
tensity

1 + 3
5

minuteâˆ’1, and the service times are still exponentially distributed of parameter
Î¼ = 1 minuteâˆ’1.
Let Y denote the number of customers in this system.
4. Compute by means of the stationary probabilities,
P{Y = k}
and
P{Y > k},
k âˆˆN0.
5. Find the mean E{Y }.
1) The traï¬ƒc intensities are
Ï±A = Ï±B =
Î»
N Â· Î¼ = 3
5,
and since N = 1, we get
P {XA = k} = P {XB = k} = 2
5
3
5
k
,
k âˆˆN0.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
110 
4. Queueing theory
2) The means are
E {XA} = E {XB} = 2
5 Â· 3
5
âˆ

k=1
k
3
5
kâˆ’1
= 6
25 Â·
1

1 âˆ’3
5
2 = 6
4 = 3
2,
thus
E{Z} = E {XA} + E {XB} = 3.
3) The probabilities are
P{Z = k}
=
k

j=0
P {XA = j} Â· P {XB = k âˆ’j} =
k

j=0
2
5
3
5
j
Â· 2
5
3
5
kâˆ’j
=
4
25 (k + 1)
3
5
k
,
k âˆˆN0.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
 
  
 
                . 

Stochastic Processes 2
 
111 
4. Queueing theory
4) The traï¬ƒc intensity of the new system is
Ï± =
Î»
N Â· Î¼ =
1 + 3
5
2 Â· 1 = 4
5,
and since N = 2, we get
p0 = 1 âˆ’Ï±
1 + Ï± = 1
9
and
pk = 2Ï±k 1 âˆ’Ï±
1 + Ï± = 2
9
4
5
k
,
k âˆˆN.
Thus
P{Y = 0} = 1
9
and
P{Y = k} = 2
9
4
5
k
,
k âˆˆN,
and hence
P{Y > k} =
âˆ

j=k+1
P{Y = j} = 2
9
âˆ

j=k+1
4
5
j
= 2
9 Â·
4
5
k+1
1 âˆ’4
5
= 8
9
4
5
k
.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
112 
4. Queueing theory
5) The mean is
E{Y } = 2
9 Â· 4
5
âˆ

k=1
k
4
5
kâˆ’1
= 8
45 Â·
1

1 âˆ’4
5
2 = 40
9 .
Example 4.23 Given a queueing system, for which
a. There are two shop assistants.
b. The customers arrive according to a Poisson process of intensity Î» = 3 minâˆ’1.
c. The service times are exponentially distributed of parameter Î¼ = 2 minâˆ’1.
d. It is possible to queue up.
1. Find the stationary probabilities.
2. Find by means of the stationary probabilities the probability that we have more than two customers
in the shop.
3. Find by means of the stationary probabilities the average length of the queue.
Then chance the system, such that it becomes a rejection system, while the other assumptions a.â€“c.
are unchanged.
4. Find the probability of rejection of this system.
1) We get from
Î» = 3,
Î¼ = 2
and
N = 2,
that the traï¬ƒc intensity is
Ï± =
Î»
N Â· Î¼ =
3
2 Â· 2 = 3
4.
From N = 2 we ï¬nd the pk by a known formula,.
p0 = 1 âˆ’Ï±
1 + Ï± = 1
7
and
pk = 2Ï±k Â· 1 âˆ’Ï±
1 + Ï± = 2
7 Â·
3
4
k
,
k âˆˆN.
In particular,
p1 = 2
7 Â· 3
4 = 3
14
and
p2 = 2
7 Â· 9
16 = 9
56.
2) The probability that there are more than two customers in the shop is
âˆ

k=3
pk = 1 âˆ’p0 âˆ’p1 âˆ’p2 = 1 âˆ’8 + 12 + 9
56
= 1 âˆ’29
56 = 27
56.
Alternatively,
âˆ

k=3
pk = 2
7
âˆ

k=3
3
4
k
= 2
7
3
4
3
Â·
1
1 âˆ’3
4
= 2
7 Â· 3 Â· 3 Â· 3 Â· 4
4 Â· 4 Â· 4
= 27
56.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
113 
4. Queueing theory
3) The average length of the queue is again given by a known formula,
âˆ

k=3
(k âˆ’2)pk = 2
7 Â·
3
4
3 âˆ

k=3
(k âˆ’2)
3
4
kâˆ’3
= 2
7 Â·
3
4
3
Â·
1

1 âˆ’3
4
2 = 27
14.
4) The probability of rejection is p2, because N = 2. It is given by some known formula in any
textbook,
p2 =
3
2
2
Â· 1
2!

2
j=0
1
j!
3
2
j =
9
8
1 + 3
2 + 9
8
=
9
8 + 12 + 9 = 9
29.
Example 4.24 Given a queueing system, for which
a. There are two shop assistants.
b. The customers arrive according to a Poisson process of intensity Î» = 5

quarterâˆ’1
.
c. The service times are exponentially distributed of parameter Î¼ = 3

quarterâˆ’1
.
d. It is possible for queue up.
1. Prove that the stationary probabilities are given by
pk =
â§
âª
âª
âª
â¨
âª
âª
âª
â©
1
11,
k = 0,
2
11
5
6
k
,
k > 0.
2. Find by means of the stationary probabilities the average waiting time.
3. Find by means of the stationary probabilities the average length of the queue.
Then the service is rationalized, such that the average service time is halved. At the same time one
removes one of the shop assistants for other work in the shop.
4. Check if the average waiting time is bigger or smaller in the new system than in the old system.
1) It follows from N = 2, Î» = 5 and Î¼ = 3 that the traï¬ƒc intensity is
Ï± =
Î»
NÎ¼ =
5
2 Â· 3 = 5
6.
Since N = 2, we may use a known formula, so
p0 = 1 âˆ’Ï±
1 + Ï± = 1
11
and
pk = 2Ï±kp0 = 1
11
5
6
k
,
Download free eBooks at bookboon.com

Stochastic Processes 2
 
114 
4. Queueing theory
and hence
pk =
â§
âª
âª
âª
â¨
âª
âª
âª
â©
1
11,
k = 0,
2
11 Â·
5
6
k
,
k âˆˆN.
2) The average waiting time V is again found by some known formula,
V = p0Ï±N Â· N Nâˆ’1
Î¼ Â· N!(1 âˆ’Ï±)2 =
1
11 Â·
5
6
2
Â· 21
3 Â· 2 Â·
1
6
2
=
52 Â· 2
11 Â· 3 Â· 2 = 25
33 quarter.
3) Also the average length of the queue is found by a given formula,
âˆ

k=3
(k âˆ’2)pk
=
âˆ

k=3
(k âˆ’2)
5
6
k
Â· 2
11 = 2
11 Â·
5
6
3 âˆ

k=1
k
5
6
kâˆ’1
=
2
11 Â·
5
6
3
Â·
1

1 âˆ’5
6
2 = 2 Â· 53
11 Â· 6 = 125
33
(= Î» V ).
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.mastersopenday.nl
Visit us and find out why we are the best!
Masterâ€™s Open Day: 22 February 2014
Join the best at
the Maastricht University
School of Business and
Economics!
Top masterâ€™s programmes
â€¢ 33rd place Financial Times worldwide ranking: MSc 
International Business
â€¢ 1st place: MSc International Business
â€¢ 1st place: MSc Financial Economics
â€¢ 2nd place: MSc Management of Learning
â€¢ 2nd place: MSc Economics
â€¢ 2nd place: MSc Econometrics and Operations Research
â€¢ 2nd place: MSc Global Supply Chain Management and 
Change
Sources: Keuzegids Master ranking 2013; Elsevier â€˜Beste Studiesâ€™ ranking 2012; 
Financial Times Global Masters in Management ranking 2012
Maastricht
University is
the best specialist
university in the
Netherlands
(Elsevier)

Stochastic Processes 2
 
115 
4. Queueing theory
4) We have in the new system that N = 1, Î» = 5, Î¼ = 6 and Ï± = 5
6.
Then the average waiting time is because N = 1 given by a known formula,
V =
Ï±
Î¼(1 âˆ’Ï±) =
5
6
6 Â· 1
5
= 5
6 quarter.
It is seen that the average waiting time is larger in the new system than in the old one.
Example 4.25 Given a queueing system, for which
a. There are two shop assistants.
b. The customers arrive according to a Poisson process of intensity Î» = 8

quarterâˆ’1
.
c. The service times are exponentially distributed of parameter Î¼ = 6

quarterâˆ’1
.
d. It is possible to queue up.
1. Prove that the stationary probabilities are given by
Pk =
â§
âª
âª
âª
â¨
âª
âª
âª
â©
1
5,
k = 0,
2
5
2
3
k
,
k âˆˆN.
2. Find by means of the stationary probabilities the average number of customers in the shop.
3. Find by means of the stationary probabilities the average waiting time.
4. Find by means of the stationary probabilities the probability that both shop assistants are busy.
5. Find the median in the stationary distribution.
1) The traï¬ƒc intensity is
Ï± =
Î»
NÎ¼ =
8
2 Â· 6 = 2
3.
Then by a known formula,
p0 = 1 âˆ’Ï±
1 + Ï± = 1
5,
pk = 2Ï±kp0 = 2
5
2
3
k
,
k âˆˆN.
2) By computing the mean it follows that the average number of customers is
âˆ

k=1
kpk =
âˆ

k=1
k Â· 2
5
2
3
k
= 2
5 Â· 2
3
âˆ

k=1
k Â·
2
3
kâˆ’1
= 4
15 Â·
1

1 âˆ’2
3
2 = 4
15 Â· 9
1 = 12
5 .
Download free eBooks at bookboon.com

Stochastic Processes 2
 
116 
4. Queueing theory
3) The average waiting time is also found by a standard formula,
V =
p0Ï±2 Â· 2
Î¼ Â· 2 Â· (1 âˆ’Ï±)2 =
1
5 Â·
2
3
2
Â· 2
6 Â· 2 Â·
1
3
2 =
4
5 Â· 6 = 2
15 quarter
(= 2 minutes).
Supplement. The average length of queue is also easily found by some known formula,
âˆ

k=3
(k âˆ’2)pk
=
âˆ

k=3
(k âˆ’2) Â· 2
5 Â·
2
3
k
=
âˆ

â„“=1
â„“
2
3
â„“âˆ’1
Â· 2
5
2
3
3
=
1

1 âˆ’2
3
2 Â· 2
5 Â·
2
3
3
=
2 Â· 23 Â· 52
5 Â· 33
= 16
15 = Î» V = 8 Â· 2
15.
4) The complementary event: Both shop assistants are busy with the probability
1 âˆ’(p0 + p1) = 1 âˆ’
1
5 + 4
14

= 1 âˆ’7
15 = 8
15.
Alternatively, the probability is given by
âˆ

k=2
pk =
âˆ

k=2
2
5
2
3
k
= 2
5 Â·
2
3
3
Â· 3 = 8
15.
5) The distribution is discrete, and
âˆ

k=2
pk = 8
15 > 1
2,
cf. 4.. Thus
p0 = 1
5,
p1 = 4
15,
p2 = 8
45.
Finally,
P{X â‰¥2} =
âˆ

k=2
pk = 8
15 > 1
2,
and
P{X â‰¤2} = p0 + p1 + p2 = 1
5 + 4
15 + 8
45 = 9 + 12 + 8
45
= 29
45 > 1
2.
Since both probabilities are â‰¥1
2, the median is (X) = 2.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
117 
5. Other types of stochastic processes
5
Other types of stochastic processes
Example 5.1 An aeroplane has 4 engines (2 on each wing), and it can carry through a ï¬‚ight if just
1 motor from each wing is working. At start (t = 0) all 4 engines are intact, but they may break down
during the ï¬‚ight. We assume (as a crude approximation) that the operating times of the 4 engines are
mutually independent and exponentially distributed of mean 1
Î» (which hopefully is much larger than
the ï¬‚ight time). The system can be described as a Markov process of 4 states:
E4: all 4 engines are working,
E3: 3 engines are working,
E2: 1 engine in each wing is working,
E1: the aeroplane has crashed.
1. Derive the system of diï¬€erential equations of the probabilities
Pi(t) = P {the process is in state Ei at time t} ,
i = 1, 2, 3, 4.
(Notice that this is not a birth and death process, because the probability of transition from E3 to
E1 in a small time interval of length h is almost proportional to h.)
2. Find Pi(t), i = 1, 2, 3, 4.
1) It follows from the diagram
E4
4Î»
âˆ’â†’
E3
2Î»
âˆ’â†’
E2
2Î»
âˆ’â†’
E1
E3
Î»â†’
E1
that we have the conditions
P4(t + h)
=
(1 âˆ’4Î»h)P4(t) + hÎµ(h),
P3(t + 4)
=
(1 âˆ’3Î»h)P3(t) + 4Î»hP4(t) + hÎµ(h),
P2(t + h)
=
(1 âˆ’2Î»h)P2(t) + 2Î»hP3(t) + hÎµ(h),
P1(t + h)
=
P(t) + 2Î»hP2(t) + Î»hP3(t) + hÎµ(h),
hence by a rearrangement and taking the limit h â†’0 we get the system of diï¬€erential equations,
â§
âª
âª
âª
âª
âª
âª
âª
âª
â¨
âª
âª
âª
âª
âª
âª
âª
âª
â©
P â€²
4(t) = âˆ’4Î»P4(t),
P4(0) = 1,
P â€²
3(t) = âˆ’3Î»P3(t) + 4Î»P4(t),
P3(0) = 0,
P â€²
2(t) = âˆ’2Î»P2(t) + 2Î»P3(t),
P2(0) = 0,
P â€²
1(t) = 2Î»P2(t) + Î»P3(t),
P1(0) = 0.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
118 
5. Other types of stochastic processes
0
0.2
0.4
0.6
0.8
1
0.5
1
1.5
2
2.5
3
t
Figure 3: The graphs of P1(t), . . . , P4(t) for Î» = 1.
2) It follows immediately that
P4(t) = eâˆ’4Î»t.
By insertion into the next diï¬€erential equation we get
P â€²
3(t) + 3Î»P3(t) = 4Î»eâˆ’4Î»t,
hence
P3(t) = eâˆ’3Î»t
 t
0
e3Î»Ï„ Â·4Î»eâˆ’4Î»Ï„ dÏ„ = eâˆ’3Î»t
 t
0
4Î»eâˆ’Î»Ï„ dÏ„ = eâˆ’3Î»t 
4 âˆ’4eâˆ’Î»t
= 4eâˆ’3Î»t âˆ’4eâˆ’4Î»t.
Then by insertion into the next equation and a rearrangement,
P â€²
2(t) + 2Î»P2(t) = 8Î»eâˆ’3Î»t âˆ’8Î»eâˆ’4Î»t,
the solution of which is
P2(t)
=
eâˆ’2Î»t
 t
0
e2Î»Ï„ 
8Î»eâˆ’3Î»Ï„ âˆ’8Î»eâˆ’4Î»Ï„
dÏ„ = eâˆ’2Î»t
 t
0

8Î»eâˆ’Î»Ï„ âˆ’8Î»eâˆ’2Î»Ï„
dÏ„
=
eâˆ’2Î»t 
4 âˆ’8eâˆ’Î»t + 4eâˆ’Î»t
= 4eâˆ’2Î»t âˆ’8eâˆ’3Î»t + 4eâˆ’4Î»t.
Finally, P1(t) is found from the condition
4

k=1
Pk(t) = 1,
thus
P1(t) = 1 âˆ’P2(t) âˆ’P3(t) âˆ’P4(t),
and we get summing up,
P4(t)
=
eâˆ’4Î»t,
P3(t)
=
4eâˆ’3Î»t âˆ’4eâˆ’4Î»t,
P2(t)
=
4eâˆ’2Î»t âˆ’8eâˆ’3Î»t + 4eâˆ’4Î»t,
P1(t)
=
1 âˆ’4eâˆ’2Î»t + 4eâˆ’3Î»t âˆ’eâˆ’4Î»t.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
119 
5. Other types of stochastic processes
Example 5.2 Let Y and Z be independent N(0, 1) distributed random variables, and let the process
{X(t), t âˆˆR} be deï¬ned by
X(t) = Y cos t + Z sin t.
Find the mean value function m(t) and the autocorrelation R(s, t).
The mean value function is
m(t) = E{X(t)} = E{Y cos t} + E{Z sin t} = cos t Â· E{Y } + sin t Â· E{Z} = 0.
The autocorrelation is
R(s, t)
=
E{X(s)X(t)} = E{(Y cos s + Z sin s)(Y cos t + Z sin t)}
=
cos s Â· cos t Â· E

Y 2
+ sin s Â· sin t Â· E

Z2
+ (cos s Â· sin t + sin s Â· cos t)E{Y Z}
=
cos s Â· cos t Â· E

Y 2
+ sin s Â· sin t Â· E{Y 2} + 0

E

Z2
= E

Y 2
=
cos(s âˆ’t)

V {Y } + (E{Y })2
= cos(s âˆ’t).
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Stochastic Processes 2
 
120 
5. Other types of stochastic processes
Example 5.3 Let {X(t), t â‰¥0} denote a Poisson process of intensity a, and let {Y (t), t â‰¥0} be
given by
Y (t) = X(t + 1) âˆ’X(t).
Compute the mean value function and the autocovariance of {Y (t), t â‰¥0}.
We have
P{X(t) = n} = (at)n
n!
eâˆ’at,
n âˆˆN0.
The mean value function is obtained by ï¬rst noticing that
P{T(t) = n} = P{X(t + 1) âˆ’X(t) = n} = P{X(1) = n} = an
n! eâˆ’a,
thus Y (t) = X(1), (The Poisson process is â€œforgetfulâ€) and
m(t) = E{Y (t)} =
âˆ

n=1
n an
n! eâˆ’Î» = a.
If s â‰¤t, then
Cov(Y (s), Y (t))
=
Cov(X(s + 1) âˆ’X(s), X(t + 1) âˆ’X(t)) = a Â· (s + 1 âˆ’min{s + 1, t} âˆ’s + s)
=
a (s + 1 âˆ’min{s + 1, t}).
If therefore s + 1 â‰¤t, then
Cov(Y (s), Y (t)) = 0,
and if s + 1 > 1, then
Cov(Y (s), T(t)) = a{s + 1 âˆ’t}.
Summing up,
Cov(Y (s), Y (t)) =
â§
â¨
â©
a{1 âˆ’|s âˆ’t|},
for |s âˆ’t| < 1,
0,
for |s âˆ’t| â‰¥1.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
121 
5. Other types of stochastic processes
Example 5.4 Let X1 and X2 be independent random variables, both normally distributed of mean 0
and variance Ïƒ2. We deï¬ne a stochastic process {X(t), t âˆˆR} by
X(t) = X1 sin t + X2 cos t.
1) Find the mean value function m(t) and the autocorrelation R(s, t).
2) Prove that the process {X(t), t âˆˆR} is weakly stationary.
3) Find the values of s âˆ’t, for which the random variables X(s) and X(t) are non-correlated.
4) Given the random variables X(s) and X(t), where s âˆ’t is ï¬xed as above. Are X(s) and X(t)
independent?
1) The mean value function is
m(t) = E{X(t)} = sin t Â· E {X1} + cos t Â· E {X2} = 0.
The autocorrelation is
R(s, t)
=
E{X(s)X(t)} = E {(X1 sin s + X2 cos s) (X1 sin t + X2 cos t)}
=
sin s Â· sin t Â· E

X2
1

+ cos s Â· cos t Â· E

X2
2

+ (Â· Â· Â· ) Â· E {X1X2}
=
sin s Â· sin t

V {X1} +

E

X2
1

+ cos s Â· cos t

V {X2} + E

X2
2

+ 0
=
(cos s Â· cos t + sin s Â· sin t)Ïƒ2 = cos(s âˆ’t) Â· Ïƒ2.
2) A stochastic process is weakly stationary, if m(t) = m is constant, and C(s, t) = C(s âˆ’t). In the
speciï¬c case,
m(t) = 0 = m,
and
C(s, t)
=
Cov{X(s), X(t)} = E{X(s)X(t)} âˆ’E{X(s)} Â· E{X(t)}
=
R(s, t) âˆ’m(s)m(t) = Ïƒ2 cos(s âˆ’t),
and we have proved that the process is weakly stationary.
3) It follows from
Cov{X(s), X(t)} = C(s, t) = Ïƒ2 cos(s âˆ’t),
that X(s) and X(t) are non-correlated, if
s = t + Ï€
2 + pÏ€,
p âˆˆZ,
i.e. if
s âˆ’t = Ï€
2 + pÏ€,
p âˆˆZ.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
122 
5. Other types of stochastic processes
4) Since (X(s), X(t)) with s âˆ’t = Ï€
2 + pÏ€, p âˆˆZ, follows a two-dimensional normal distribution, and
X(s) and X(t) are non-correlated, we conclude that they are independent.
Example 5.5 Let {X(t), t âˆˆR} be a stationary process of mean 0, autocorrelation R(Ï„) and eï¬€ect
spectrum S(Ï‰).
Let {Y (t), t âˆˆR} be deï¬ned by
Y (t) = X(t + a) âˆ’X(t âˆ’a),
where a > 0.
Express the autocorrelation and the eï¬€ect spectrum of {Y (t)} by the corresponding expressions of
{X(t)} (and a).
The assumptions are
m(t) = 0,
R(Ï„) = E{X(t + Ï„)X(t)}
and
S(Ï‰) =
 âˆ
âˆ’âˆ
eiÏ‰Ï„R(Ï„) dÏ„.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Get Help Now
Go to www.helpmyassignment.co.uk for more info
Need help with your
dissertation?
Get in-depth feedback & advice from experts in your 
topic area. Find out what you can do to improve
the quality of your dissertation!

Stochastic Processes 2
 
123 
5. Other types of stochastic processes
Hence for Y (t) = X(t + a) âˆ’X(t âˆ’a), a > 0,
RY (Ï„)
=
E{Y (t + Ï„)Y (t)} = E{[X(t + Ï„ + a) âˆ’X(t + Ï„ âˆ’a)] Â· [X(t + a) âˆ’X(t âˆ’a)]}
=
E{X(t + Ï„ + a)X(t + a)} âˆ’E{X(t + Ï„ + a)X(t âˆ’a)}
âˆ’E{X(t + Ï„ âˆ’a)X(t + a)} + E{X(t + Ï„ âˆ’a)X(t âˆ’a)}
=
RX(Ï„) âˆ’RX(Ï„ + 2a) âˆ’RX(Ï„ âˆ’2a) + RX(Ï„)
=
2RX(Ï„) âˆ’RX(Ï„ + 2a) âˆ’RX(Ï„ âˆ’2a),
so
SY (Ï‰)
=
 âˆ
âˆ’âˆ
eiÏ‰Ï„RY (Ï„) dÏ„
=
2
 âˆ
âˆ’âˆ
eiÏ‰Ï„RX(Ï„) dÏ„ âˆ’
 âˆ
âˆ’âˆ
eiÏ‰Ï„RX(Ï„ + 2a) dÏ„ âˆ’
 âˆ
âˆ’âˆ
eiÏ‰Ï„RX(Ï„ âˆ’2a) dÏ„
=
2SX(Ï‰) âˆ’eâˆ’2iaÏ‰SX(Ï‰) âˆ’e2iaÏ‰SX(Ï‰) = 2{1 âˆ’cos 2aÏ‰}SX(Ï‰)
=
4 sin2 aÏ‰ SX(Ï‰).
Download free eBooks at bookboon.com

Stochastic Processes 2
 
124 
5. Other types of stochastic processes
Example 5.6 Let {X(t), t âˆˆR} be a stationary process of mean 0 and eï¬€ect spectrum S(Ï‰), and let
Y = 1
n
n

k=1
X(kT),
hvor T > 0.
Prove that
E

Y 2
=
1
2Ï€n2
 âˆ
âˆ’âˆ
S(Ï‰) Â·
sin2
1
2 nÏ‰T

sin2
1
2 Ï‰T
 dÏ‰.
Hint:
sin2
1
2 nÏ‰T

sin2
1
2 Ï‰T
 =
nâˆ’1

m=âˆ’(nâˆ’1)
(n âˆ’|m|)eâˆ’iÏ‰mT .
First compute
E

Y 2
=
1
n2 E
 n

k=1
n

m=1
X(kT)X(mT)

=
1
n2 E
 n

k=1
X(kT)X(kT) + 2
nâˆ’1

k=1
n

m=k+1
X(kT)X(mT)

=
1
n2
n

k=1
R(0) + 2
n2
nâˆ’1

k=1
nâˆ’k

m=1
E{X(kT)X((k + m)T)}
=
n
n2 R(0) + 2
n2
nâˆ’1

k=1
nâˆ’k

m=1
R(mT) = n
n2 R(0) + 2
n2
nâˆ’1

m=1
nâˆ’m

k=1
R(mT)
=
n
n2 R(0) + 2
n2
nâˆ’1

m=1
(n âˆ’m)R(mT) = 1
n2
nâˆ’1

m=âˆ’(nâˆ’1)
(n âˆ’|m|)R(|m|T).
Using
R(âˆ’mT) = E{X(kT)X((k âˆ’m)T)} = E{X(kT)X((k + m)T)} = R(mT),
and the hint and the inversion formula we get
E

Y 2
=
1
n2
nâˆ’1

m=âˆ’(nâˆ’1)
(n âˆ’|m|)R(mT) = 1
n2
nâˆ’1

m=âˆ’(nâˆ’1)
(n âˆ’|m|) Â· 1
2Ï€
 âˆ
âˆ’âˆ
eâˆ’imÏ‰T S(Ï‰) dÏ‰
=
1
2Ï€n2
 âˆ
âˆ’âˆ
S(Ï‰)
nâˆ’1

m=âˆ’(nâˆ’1)
(n âˆ’|m|)eâˆ’iÏ‰mT dÏ‰ =
1
2Ï€n2
 âˆ
âˆ’âˆ
S(Ï‰) Â·
sin2
1
2 nÏ‰T

sin2
1
2 Ï‰T
 dÏ‰,
and the formula is proved.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
125 
5. Other types of stochastic processes
Example 5.7 Let {W(t), t â‰¥0} be a Wiener process..
1) Find the autocorrelation R(s, t) and the autocovariance C(s, t), s, t âˆˆR+.
2) Let 0 < s < t. Find the simultaneous frequency of the two-dimensional random variable {W(s), W(t)}.
The Wiener process is a normal process {W(t), t â‰¥0} with
W(0) = 0,
m(t) = 0,
V {W(t)} = Î± t
(Î± > 0),
and of independent increments. It follows from m(t) = 0 that
C(s, t) = Cov{W(s), W(t)} = R(s, t) âˆ’m(s)m(t) = R(s, t).
1) If 0 < s < t, then
R(s, t)
=
C(s, t) = Cov{W(s), W(t)} = Cov{W(s), W(s) + [W(t) âˆ’W(s)]}
=
Cov{W(s), W(s)} + Cov{W(s), W(t) âˆ’W(s)}
=
V {W(s)} + 0
(independent increments)
=
Î± Â· s.
Analogously, R(s, t) = C(s, t) = Î± Â· t, if 0 < t < s, thus
R(s, t) = C(s, t) = Î± Â· min{s, t} =
 Î±s,
if 0 < s < t,
Î±t,
if 0 < t < s.
2) If 0 < s < t, then (W(s), W(t) âˆ’W(s)) has the simultaneous frequency
f(x, y) =
1
âˆš
2Ï€Î±s exp

âˆ’1
2
x2
Î±s

Â·
1
,
2Ï€Î±(t âˆ’s)
exp

âˆ’1
2
y2
Î±(t âˆ’s)

for (x, y) âˆˆR2. Finally, it follows that
(W(s), W(t)) = (W(s), {W(t) âˆ’W(s)} + W(s))
has the frequency
g(x, y) = f(x, y âˆ’x) =
1
2Ï€Î±
,
s(t âˆ’s)
exp

âˆ’1
2
 x2
Î±s + (y âˆ’x)2
Î±(t âˆ’s)

,
(x, y) âˆˆR2.
Download free eBooks at bookboon.com

Stochastic Processes 2
 
126 
Index
Index
absorbing state, 13, 25
Arcus sinus law, 10
closed subset of states, 13
convergence in probability, 28
cycle, 22
discrete Arcus sinus distribution, 10
distribution function of a stochastic process, 4
double stochastic matrix, 22, 39
drunkardâ€™s walk, 5
Ehrenfestâ€™s model, 32
geometric distribution, 124, 133
initial distribution, 11
invariant probability vector, 11, 22, 23, 25, 26,
28, 30, 32, 36, 39
irreducible Markov chain, 12, 18â€“23, 32, 36, 39,
41, 43, 45, 47, 50, 53, 62, 65, 67, 70,
73, 75, 78, 80, 86, 88, 91, 93, 98, 103,
106, 108, 114, 116, 122, 125, 128, 131
irreducible stochastic matrix, 83, 120
limit matrix, 13
Markov chain, 10, 18
Markov chain of countably many states, 101
Markov process, 5
outcome, 5
periodic Markov chain, 14
probability of state, 11
probability vector, 11
random walk, 5, 14, 15
random walk of reï¬‚ecting barriers, 14
random walk of absorbing barriers, 14
regular Markov chain, 12, 18â€“23, 36, 39, 43, 47,
50, 53, 56, 62, 65, 67, 70, 73, 75, 78,
80, 83, 86, 88, 91, 100, 101, 103, 106,
108, 114, 116, 122, 125, 128, 131
regular stochastic matrix, 26, 30, 120
ruin problem, 7
sample function, 4
state of a process, 4
stationary distribution, 11, 43, 50
stationary Markov chain, 10
stochastic limit matrix, 13
stochastic matrix, 10
stochastic process, 4
symmetric random walk, 5, 9
transition probability, 10, 11
vector of state, 11
Download free eBooks at bookboon.com

