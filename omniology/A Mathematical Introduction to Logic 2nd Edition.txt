
Sponsoring Editor 
Production Editor 
Editorial Coordinator 
Marketing Manager 
Cover Design 
Copyeditor 
Composition 
Printer 
Barbara Holland 
Julie Bolduc 
Karen Frost 
Marianne Rutter 
Judy Arisman, Arisman Design 
Kristin Landon 
Interactive Composition Corporation 
The Maple-Vail Book Manufacturing Group 
This book is printed on acid-free paper. @ 
Copyright @ 2001,1972 by HARCOURTIACADEMIC PRESS 
All rights reserved. 
No part of this publication may be reproduced or transmitted in any form or by any 
means, electronic or mechanical, including photocopy, recording, or any 
information storage and retrieval system, without permission in writing from the 
publisher. 
Requests for permission to make copies of any part of the work should be mailed to: 
Permissions Department, Harcourt, Inc., 6277 Sea Harbor Drive, Orlando, Florida 
32887-6777. 
Academic Press 
A Harcourt Science and Technology Company 
525 B Street, Suite 1900, San Diego, California 921 01-4495, USA 
http://www.academicpress. com 
Academic Press 
Harcourt Place, 32 Jamestown Road, London NW1 7BY, UK 
http://www.academicpress.com 
HarcourtIAcadem ic Press 
A Harcourt Science and Technology Company 
200 Wheeler Road, Burlington, Massachusetts 01 803, USA 
httpdlww. harcourt-ap.com 
Library of Congress Catalog Card Number: 00-1 10670 
International Standard Book Number: 0-1 2-238452-0 
PRINTED IN THE UNITED STATES OF AMERICA 
0 0 0 1  0 2 0 3 0 4 0 5 M B 9 8 7 6 5 4 3 2  1 

for Eric and Ben 

Contents 
CHAPTER ZERO Useful Facts about Sets 
CHAPTER ONE Sentential Logic 
1.0 Informal Remarks on Formal Languages 
1.1 The Language of Sentential Logic 
1.2 Truth Assignments 
1.3 A Parsing Algorithm 
1.4 Induction and Recursion 
1.5 Sentential Connectives 
1.6 Switching Circuits 
1.7 Compactness and Effectiveness 
CHAPTER TWO First-Order Logic 
2.0 Preliminary Remarks 
2.1 First-Order Languages 
2.2 Truth and Models 
2.3 A Parsing Algorithm 
2.4 A Deductive Calculus 
2.5 Soundness and Completeness Theorems 
2.6 Models of Theories 
2.7 Interpretations Between Theories 
2.8 Nonstandard Analysis 
CHAPTER THREE Undecidability 
3.0 Number Theory 
3.1 Natural Numbers with Successor 
3.2 Other Reducts of Number Theory 
3.3 A Subtheory of Number Theory 
3.4 Arithmetization of Syntax 
vii 

... 
VIII 
Contents 
3.5 Incompleteness and Undecidability 
3.6 Recursive Functions 
3.7 Second Incompleteness Theorem 
3.8 Representing Exponentiation 
CHAPTER 
FOUR Second-Order Logic 
4.1 Second-Order Languages 
4.2 Skolem Functions 
4.3 Many-Sorted Logic 
4.4 General Structures 
SUGGESTIONS FOR FURTHER READING 

Preface 
T 
his book, like the first edition, presents the basic 
concepts and results of logic: the topics are proofs, 
truth, and computability. As before, the presentation 
is directed toward the reader with some mathematical back- 
ground and interests. In this revised edition, in addition to 
numerous "local" changes, there are three "global" ways in 
which the presentation has been changed: 
First, I have attempted to make the material more ac- 
cessible to the typical undergraduate student. In the main 
development, I have tried not to take for granted informa- 
tion or insights that might be unavailable to a junior-level 
mathematics student. 
Second, for the instructor who wants to fit the book to his 
or her course, the organization has been made morefixible. 
Footnotes at the beginning of many of the sections indicate 
optional paths the instructor - 
or the independent reader - 
might choose to take. 
Third, theoretical computer science has influenced logic 
in recent years, and some of that influence is reflected in this 
edition. Issues of computability are taken more seriously. 
Some material on finite models has been incorporated into 
the text. 
The book is intended to serve as a textbook for an in- 
troductory mathematics course in logic at the junior-senior 
level. The objectives are to present the important concepts 
and theorems of logic and to explain their significance and 
their relationship to the reader's other mathematical work. 
As a text, the book can be used in courses anywhere from 
a quarter to a year in length. In one quarter, I generally reach 
the material on models of first-order theories (Section 2.6). 
The extra time afforded by a semester would permit some 
glimpse of undecidability, as in Section 3.0. In a second 

x 
Preface 
term, the material of Chapter 3 (on undecidability) can be more adequately cov- 
ered. 
The book is intended for the reader who has not studied logic previously, but who 
has some experience in mathematical reasoning. There are no specific prerequisites 
aside from a willingness to function at a certain level of abstraction and rigor. 
There is the inevitable use of basic set theory. Chapter 0 gives a concise summary 
of the set theory used. One should not begin the book by studying this chapter; it is 
instead intended for reference if and when the need arises. The instructor can adjust 
the amount of set theory employed; for example it is possible to avoid cardinal 
numbers completely (at the cost of losing some theorems). The book contains 
some examples drawn from abstract algebra. But they are just examples, and are 
not essential to the exposition. T e  later chapters (Chapter 3 and 4) tend to be more 
demanding of the reader than are the earlier chapters. 
Induction and recursion are given a more extensive discussion (in Section 1.4) 
than has been customary. I prefer to give an informal account of these subjects in 
lectures and have a precise version in the book rather than to have the situation 
reversed. 
Exercises are given at the end of nearly all the sections. If the exercise bears a 
boldface numeral, then the results of that exercise are used in the exposition in the 
text. Unusually challenging exercises are marked with an asterisk. 
I cheerfully acknowledge my debt to my teachers, a category in which I include 
also those who have been my colleagues or students. I would be pleased to receive 
comments and corrections from the users of this book. The Web site for the book 
can be found at http://www.math.ucla.edu/" h belamil. 

Introduction 
ymbolic logic is a mathematical model of deductive 
thought. Or at least that was true originally; as with 
other branches of mathematics it has grown beyond 
the circumstances of its birth. Symbolic logic is a model 
in much the same way that modem probability theory is a 
model for situations involving chance and uncertainty. 
How are models constructed? You begin with a real-life 
object, for example an airplane. Then you select some fea- 
tures of this original object to be represented in the model, 
for example its shape, and others to be ignored, for example 
its size. And then you build an object that is like the original 
in some ways (which you call essential) and unlike it in oth- 
ers (which you call irrelevant). Whether or not the resulting 
model meets its intended purpose will depend largely on 
the selection of the properties of the original object to be 
represented in the model. 
Logic is more abstract than airplanes. The real-life ob- 
jects are certain "logically correct" deductions. For example, 
All men are mortal. 
Socrates is a man. 
Therefore, Socrates is mortal. 
The validity of inferring the third sentence (the conclu- 
sion) from the first two (the assumptions) does not depend 
on special idiosyncrasies of Socrates. The inference is jus- 
tified by the form of the sentences rather than by empirical 
facts about mortality. It is not really important here what 
"mortal" means; it does matter what "all" means. 
Borogoves are mimsy whenever it is brillig. 
It is now brillig, and this thing is a borogove. 
Hence this thing is rnimsy. 

xi i 
Introduction 
Again we can recognize that the third sentence follows from the iirst two, even 
without the slightest idea of what a mirnsy borogove might look like. 
Logically correct deductions are of more interest than the above frivolous ex- 
amples might suggest. In fact, axiomatic mathematics consists of many such de- 
ductions laid end to end. These deductions made by the working mathematician 
constitute real-life originals whose features are to be mirrored in our model. 
The logical correctness of these deductions is due to their form but is indepen- 
dent of their content. This criterion is vague, but it is just this sort of vagueness that 
prompts us to turn to mathematical models. A major goal will be to give, within 
a model, a precise version of this criterion. The questions (about our model) we 
will initially be most concerned with are these: 
1. What does it mean for one sentence to "follow logically" from certain others? 
2. If a sentence does follow logically from certain others, what methods of 
proof might be necessary to establish this fact? 
3. Is there a gap between what we can prove in an axiomatic system (say for 
the natural numbers) and what is true about the natural numbers? 
4. What is the connection between logic and computability? 
Actually we will present two models. The first (sentential logic) will be very 
simple and will be woefully inadequate for interesting deductions. Its inadequacy 
stems from the fact that it preserves only some crude properties of real-life de- 
ductions. The second model (first-order logic) is admirably suited to deductions 
encountered in mathematics. When a working mathematician asserts that a par- 
ticular sentence follows from the axioms of set theory, he or she means that this 
deduction can be translated to one in our model. 
This emphasis on mathematics has guided the choice of topics to include. This 
book does not venture into many-valued logic, modal logic, or intuitionistic logic, 
which represent different selections of properties of real-life deductions. 
Thus far we have avoided giving away much information about what our model, 
fu-st-order logic, is like. As brief hints, we now give some examples of the expres- 
siveness of its formal language. First, take the English sentence that asserts the 
set-theoretic principle of extensionality, "If the same things are members of a first 
object as are members of a second object, then those objects are the same." This 
can be translated into our first-order language as 
VxVy(Vz(z E X  *Z 
E y)+x=y). 
As a second example, we can translate the sentence familiar to calculus students, 
"For every positive number E there is a positive number 6 such that for any x whose 
distance from a is less than 6, the distance between f (x) and b is less than E" as 
VE(E > 0- 
36(6 > OAVx(dxa < 6 -+dfxb < E))). 
We have given some hints as to what we intend to do in this book. We should 
also correct some possible misimpressions by saying what we are not going to do. 
This book does not propose to teach the reader how to think. The word "logic" is 
sometimes used to refer to remedial thinking, but not by us. The reader already 
knows how to think. Here are some intriguing concepts to think about. 

e assume that the reader already has 
some familiarity with normal everyday 
1
.
 , .  
set-theoretic apparatus. Nonetheless, we 
give here a brief summary of facts from set theory 
we will need; this will at least serve to establish 
the notation. It is suggested that the reader, instead 
er this chapter at the outset, simply 
efer to it if and when issues of a set-theoretic na- 
later chapters. The author's favorite 
book on set theory is of course his Elements of Set 
Theury (see the list of references at the end of this 
First a word about jargon. Throughout the book 
we will utilize an assortment of standard mathe- 
matical abbreviations. We use "3' to signify the 
end of a proof. A sentence "If . . . , then . . ." will 
sometimes be abbreviated ". . . j 
. . . ." We also 
have "+=" for the converse implication (for the pe- 
1 4 
a 
culiar way the word "implication" is used in math- 
ematics). For "if and only if" we use the shorter 
"iff" (this has become part of the mathematical lan- 
guage) and the symbol "+." For the word "there- 
fore" we have the ":." 
abbreviation. 
The notational device that extracts "x # y" as 
the denial of "x = y" and "x 6 y" as the denial 
of "x E y" will be extended to other cases. For 
example, in Section 1.2 we define "X ); rr"; then 
"X &CI r"is its denial. 
Now then, a set is a collection of things, called 
its members or elements. As usual, we write "t E 
A" to say that t is a member of A, and "t $ A" to 
say that t is not a member of A. We write "x = y" to 

2 
A Mathematical Introduction to Logic 
mean that x and y are the same object. That is, the expression "x" on the 
left of the equals sign is a name for the same object as is named by the 
other expression "y." If A = B, then for any object t it is automatically 
true that t E A iff t E B. This holds simply because A and B are the 
same thing. The converse is the principle of extensionality: If A and B 
are sets such that for every object t, 
~
E
A
 
iff ~ E B ,  
then A = B. This reflects the idea of what a set is; a set is determined 
just by its members. 
A useful operation is that of adjoining one extra object to a set. For 
a set A, let A; t be the set whose members are (i) the members of A, 
plus (ii) the (possibly new) member t. Here t may or may not already 
belong to A, and we have 
A; t = A U {t) 
using notation defined later, and 
~
E
A
 
iff A ; t = A .  
One special set is the empty set 0, which has no members at all. Any 
other set is said to be nonempty. For any object x there is the singleton 
set {x) whose only member is x. More generally, for any finite number 
XI, . . . , x,, of objects there is the set {xl , . . . , x, } whose members are 
exactly those objects. Observe that {x, y} = {y, x}, as both sets have 
exactly the same members. We have only used different expressions to 
denote the set. If order matters, we can use ordered pairs (discussed 
later). 
This notation will be stretched to cover some simple infinite cases. 
For example, (0, 1,2, . . .} is the set W of natural numbers, and {. . . , -2, 
- 1,0, 1,2, . . . } is the set Z of all integers. 
We write "{x I -x-}" 
for the set of all objects x such that x - .  
We will take considerable liberty with this notation. For example, 
{(m, n) I m -c n in N} is the set of all ordered pairs of natural 
numbers for which the first component is smaller than the second. And 
{x E A I x } is the set of all elements x in A such that -x-. 
If A is a set all of whose members are also members of B, then A is a 
subset of B, abbreviated "A 
B." Note that any set is a subset of itself. 
Also, 0 is a subset of every set. ("0 
A" is "vacuously true," since 
the task of verifying, for every member of 0 ,  that it also belongs to A 
requires doing nothing at all. Or from another point of view, "A 
B" 
can be false only if some member of A fails to belong to B. If A = 0 ,  
this is impossible.) From the set A we can form a new set, the power set 
P A  of A, whose members are the subsets of A. Thus 
PA = {x I x 
A}. 

Cha~ter 0: Useful Facts about Sets 
3 
For example, 
The union of A and B, A U B, is the set of all things that are members 
of A or B (or both). For example, A; t = A U {t). Similarly, the inter- 
section of A and B, A n B, is the set of all things that are members 
of both A and B. Sets A and B are disjoint iff their intersection is 
empty (i.e., if they have no members in common). A collection of sets 
is pairwise disjoint iff any two members of the collection are disjoint. 
More generally, consider a set A whose members are themselves sets. 
The union, U A, of A is the set obtained by dumping all the members 
of A into a single set: 
U A = {x I x belongs to some member of A). 
Similarly for nonempty A, 
n 
A = {x I x belongs to all members of A). 
For example, if 
then 
Two other examples are 
A U B = U{A, B), 
In cases where we have a set A, for each natural number n, the union 
of all these sets, U{A, I n E N), is usually denoted "UnEw An" or just 
"U, A, ." 
The ordered pair (x, y) of objects x and y must be defined in such a 
way that 
(x,y)=(u,u) 
iff 
X = U  
and y = u .  
Any definition that has this property will do; the standard one is 
(x, Y) = {{xl, {x, Y)). 
For ordered triples we define 
(x, y, z) = ((x, Y), z). 

4 
A Mathematical Introduction to Logic 
More generally we define n-tuples recursively by 
for n > 1. It is convenient to define also (x) = x; the preceding equation 
then holds also for n = 1. S is ajnite sequence (or string) of members 
of A iff for some positive integer n, we have S = (xl, . . . , x,), where 
each xi E A. (Finite sequences are often defined to be certain finite 
functions, but the above definition is slightly more convenient for us.) 
A segment of the finite sequence S = (xl , . . . , x,) is a finite sequence 
( ~ k , ~ k + i ,  
..., xm-1,xm), 
where l S k ( m ( n .  
This segment is an initial segment iff k = 1 and it is proper iff it is 
different from S. 
If (xl, . . . , x,) = (yl, . . . , y,), then it is easy to see that xi = yi 
for 1 ( i 5 n. (The proof uses induction on n and the basic property 
of ordered pairs.) But if (xl , . . . , x,) = (yl , . . . , y,), then it does not 
in general follow that m = n. After all, every ordered triple is also an 
ordered pair. But we claim that m and n can be unequal only if some xi 
is itself a finite sequence of yj's, or the other way around: 
LEMMA OA 
Assume that (xl, . . . , x,) = (yi, . . . , Ym, . . . , ~ r n + ~ ) +  
Thenxl = ( ~ 1 ,  yk+l). 
PROOF. We use induction on m. If m = 1, the conclusion is irnme- 
diate. For the inductive step, assume that (xl, . . . , x,, x,+l) = 
(y1, . . . , Ym+k, ~ m + l + ~ ) .  Then the first ~Omp~nents 
of this ordered 
pair must be equal: (XI, . . . , x,) = (yl, . . . , Y,+~). Now apply 
the inductive hypothesis. 
-I 
For example, suppose that A is a set such that no member of A is a 
finite sequence of other members. Then if (xl , . . . , x,) = (yl , . . . , y,) 
and each Xi and yj is in A, then by the above lemma m = n. Whereupon 
we have xi = yi as well. 
From sets A and B we can form their Cartesian product, the set 
A x B of all pairs (x, y) for which x E A and y E B. An is the set of 
all n-tuples of members of A. For example, 
= (A x A) x A. 
A relation R is a set of ordered pairs. For example, the ordering 
relation on the numbers 0-3 is captured by -and in fact is - 
the set of 
ordered pairs 
The domain of R (written dom R) is the set of all objects x such that 
(x, y) E R for some y. The range of R (written ran R) is the set of all 
objects y such that (x, y) E R for some x. The union of dom R and 
ran R is the jeld of R, fld R. 

Chapter 0: Useful Facts about Sets 
5 
An n-ary relation on A is a subset of An. If n > 1, it is arelation. But a 
1 -ary (unary) relation on A is simply a subset of A. A particularly simple 
binary relation on A is the equality relation {(x, x) I x E A} on A. For 
an n-ary relation R on A and subset B of A, the restriction of R to B 
is the intersection R n Bn. For example, the relation displayed above is 
the restriction to the set B = (0, 1,2,3) of the ordering relation on N. 
Afinction is a relation F with the property of being single-valued: 
For each x in dom F there is only one y such that (x, y) E F. As usual, 
this unique y is said to be the value F(x) that F assumes at x. (This 
notation goes back to Euler. It is a pity he did not choose (x) F instead; 
that would have been helpful for the composition of functions: f o g is 
the function whose value at x is f (g(x)), obtained by applying first g 
and then f .) 
We say that F maps A into B and write 
to mean that F is a function, dom F = A, and ran F 
B. If in addition 
ran F = B, then F maps A onto B. F is one-to-one iff for each y in 
ran F there is only one x such that (x, y) E F. If the pair (x, y) is in 
dom F, then we let F (x , y ) = F ((x , y ) ) . This notation is extended to 
n-tuples; F(xl, . . . , x,) = F((xl, . . . , x,)). 
An n-ary operation on A is a function mapping An into A. For exam- 
ple, addition is a binary operation on N, whereas the successor operation 
S (where S(n) = n + 1) is a unary operation on N. If f is an n-ary o p  
eration on A, then the restriction of f to a subset B of A is the function 
g with domain Bn which agrees with f at each point of Bn. Thus, 
This g will be an n-ary operation on B iff B is closed under f ,  in the 
sense that f (bl, . . . , bn) E B whenever each bi is in B. In this case, 
g = f n Bn+', in agreement with our definition of the restriction of a 
relation. For example, the addition operation on N, which contains such 
triples as ((3,2), 5), is the restriction to N of the addition operation on 
W, which contains many more triples. 
A particularly simple unary operation on A is the identity function 
I d  on A, given by the equation 
for X E A  
Thus I d  = {(x, x) I x E A}. 
For a relation R, we define the following: 
R is reflexive on A iff (x, x) E R for every x in A. 
R is symmetric iff whenever (x, y) E R, then also (y , x) E R. 
R is transitive iff whenever both (x, y) E R and (y, z) E R (if this 
ever happens), then also (x, z) E R. 

6 
A Mathematical Introduction to Logic 
R satisfies trichotomy on A iff for every x and y in A, exactly one of 
the three possibilities, (x, y) E R, x = y, or (y , x) E R, holds. 
R is an equivalence relation on A iff R is a binary relation on A that 
is reflexive on A, symmetric, and transitive. 
R is an ordering relation on A iff R is transitive and satisfies tri- 
chotomy on A. 
For an equivalence relation R on A we define, for x E A, the equiv- 
alence class [x] of x to be {y I (x, y) E R). The equivalence classes 
then partition A. That is, the equivalence classes are subsets of A such 
that each member of A belongs to exactly one equivalence class. For x 
and y in A, 
1x1 = [YI iff Ix,y) f R. 
The set N of natural numbers is the set (0, 1,2, . . .). (Natural num- 
bers can also be defined set-theoretically, a point that arises briefly in 
Section 3.7.) A set A is finite iff there is some one-to-one function f 
mapping (for some natural number n) the set A onto {0, 1, . . . , n - 1). 
(We can think of f as "counting" the members of A.) 
A set A is countable iff there is some function mapping A one-to-one 
into N. For example, any finite set is obviously countable. Now consider 
an infinite countable set A. Then from the given function f mapping 
A one-to-one into N, we can extract a function f' mapping A one-to- 
one onto N. For some a0 E A, f (ao) is the least member of ran f ,  let 
f '(ao) = 0. In general there is a unique a, E A such that f (a,) is the 
(n + 1)st member of ran f ;  let f '(a,) = n. Note that A = {ao, al, . . .). 
(We can also think of f' as "counting" the members of A, only now the 
counting process is infinite.) 
THEOREM 
OB Let A be a countable set. Then the set of all finite 
sequences of members of A is also countable. 
PROOF. The set S of all such finite sequences can be characterized 
by the equation 
Since A is countable, we have a function f mapping A one- 
to-one into N. 
The basic idea is to map S one-to-one into N by assigning 
to (ao, a1 , . . . , a,) the number 2f 
3f 
. . .  . p m  
f @,)+I 
where p, is the (m + 1)st prime. This suffers from the defect 
that this assignment might not be well-defined. For conceivably 
there could be (ao, al, . . . , a,) = (bo, bl, . . . , b,), with ai and 
bj in A but with m # n. But this is not serious; just assign to 
each member of S the smallest number obtainable in the above 

Chapter 0: Useful Facts about Sets 
7 
fashion. This gives us a well-defined map; it is easy to see that it 
is one-to-one. 
-I 
At times we will speak of trees, which can be useful in providing 
intuitive pictures of some situations. But our comments on trees will 
always be informal; the theorems and proofs will not rely on trees. 
Accordingly, our discussion here of trees will be informal. 
For each tree there is an underlying finite partial ordering. We can 
draw a picture of this partial ordering R; if (a, b) E R, then we put a 
lower than b and connect the points by a line. Pictures of two typical 
tree ordering are shown. 
(In mathematics, trees grow downward, not upward.) There is always a 
highest point in the picture (the root). Furthermore, while branching is 
permitted below some vertex, the points above any given vertex must 
lie along a line. 
In addition to this underlying finite partial ordering, a tree also has a 
labeling function whose domain is the set of vertices. For example, one 
tree, in which the labels are natural numbers, is shown. 
At a few points in the book we will use the axiom of choice. But 
usually these uses can be eliminated if the theorems in question are 
restricted to countable languages. Of the many equivalent statements of 
the axiom of choice, Zorn's lemma is especially useful. 
Say that a collection C of sets is a chain iff for any elements x and 
yofC,eitherx s y o r y  s x .  
ZORN'S LEMMA Let A be a set such that for any chain C 
A, the set 
U C is in A. Then there is some element m E A which is maximal 
in the sense that it is not a subset of any other element of A. 

8 
A Mathematical Introduction to Logic 
Cardinal Numbers 
All infinite sets are big, but some are bigger than others. (For example, 
the set of real numbers is bigger than the set of integers.) Cardinal num- 
bers provide a convenient, although not indispensable, way of talking 
about the size of sets. 
It is natural to say that two sets A and B have the same size iff there is 
a function that maps A one-to-one onto B. If A and B are finite, then this 
concept is equivalent to the usual one: If you count the members of A 
and the members of By then you get the same number both times. But it 
is applicable even to infinite sets A and By where counting is difficult. 
Formally, then, say that A and B are equinumerous (written A .- B) 
iff there is a one-to-one function mapping A onto B. For example, the 
set N of natural numbers and the set Z of integers are equinumerous. It 
is easy to see that equinumerosity is reflexive, symmetric, and transitive. 
For finite sets we can use natural numbers as measures of size. The 
same natural number would be assigned to two finite sets (as measures 
of their size) iff the sets were equinumerous. Cardinal numbers are 
introduced to enable us to generalize this situation to infinite sets. 
To each set A we can assign a certain object, the cardinal number 
(or cardinality) of A (written card A), in such a way that two sets are 
assigned the same cardinality iff they are equinumerous: 
cardA=cardB iff 
A-B. 
(K) 
There are several ways of accomplishing this; the standard one these 
days takes card A to be the least ordinal equinumerous with A. (The 
success of this definition relies on the axiom of choice.) We will not 
discuss ordinals here, since for our purposes it matters very little what 
card A actually is, any more than it matters what the number 2 actually 
is. What matters most is that (K) holds. It is helpful, however, if for a 
finite set A, card A is the natural number telling how many elements A 
has. Something is a cardinal number, or simply a cardinal, iff it is card A 
for some set A. 
(Georg Cantor, who first introduced the concept of cardinal number, 
characterized in 1895 the cardinal number of a set M as "the general 
concept which, with the help of our active intelligence, comes from the 
set M upon abstraction from the nature of its various elements and from 
the order of their being given.") 
Say that A is dominated by B (written A 5 B) iff A is equinumerous 
with a subset of B. In other words, A 5 B iff there is a one-to-one 
function mapping A into B. The companion concept for cardinals is 
c a r d A ~ c a r d B  iff 
A s B .  
(It is easy to see that < is well defined; that is, whether or not K < h 
depends only on the cardinals K and h themselves, and not the choice of 

Chapter 0: Useful Facts about Sets 
9 
sets having these cardinalities.) Dominance is reflexive and transitive. A 
set A is dominated by N iff A is countable. The following is a standard 
result in this subject. 
SCHRODER-BERNSTEIN 
THEOREM (a) For any sets A and B, if A 5 B 
andB5A,thenA--B. 
(b) For any cardinal numbers K and A, if K 5 h and h 5 K, then 
K = h .  
Part (b) is a simple restatement of part (a) in terms of cardinal num- 
bers. The following theorem, which happens to be equivalent to the 
axiom of choice, is stated in the same dual manner. 
THEOREM 
OC 
(a) For any sets A and B, either A .I 
B or B 5 A. 
(b) For any cardinal numbers K and A, either K 5 h or h 5 K. 
Thus of any two cardinals, one is smaller than the other. (In fact, any 
nonempty set of cardinal numbers contains a smallest member.) The 
smallest cardinals are those of finite sets: 0, 1,2, . . . . There is next the 
smallest infinite cardinal, card N, which is given the name KO. Thus we 
have 
where K 1  is the smallest cardinal larger than KO. The cardinality of the 
real numbers, card W, is called "2'0." Since W is uncountable, we have 
KO < 2'0. 
The operations of addition and multiplication, long familiar for finite 
cardinals, can be extended to all cardinals. To compute K + h we choose 
disjoint sets A and B of cardinality K and A, respectively. Then 
K + h = card(A U B). 
This is well defined; i.e., K + h depends only on K and h, and not on the 
choice of the disjoint sets A and B. For multiplication we use 
K h = card(A x B). 
Clearly these definitions are correct for finite cardinals. The arithmetic 
of infinite cardinals is surprisingly simple (with the axiom of choice). 
The sum or product of two infinite cardinals is simply the larger of them: 
CARDINAL 
ARITHMETIC 
THEOREM For cardinal numbers K andh, if K 5 
h and h is infinite, then K + h = A. Furthermore, if K # 0, then 
Kah=h. 
In particular, for infinite cardinals K, 

10 
A Mathematical Introduction to Logic 
THEOREM 
OD For an infinite set A, the set Un A"+' of all finite se- 
quences of elements of A has cardinality equal to card A. 
We already proved this for the case of a countable A (see Theo- 
rem OB). 
PROOF. Each A"+' has cardinality equal to card A, by the cardinal 
arithmetic theorem (applied n times). So we have the union of No 
sets of this size, yielding Ho card A = card A points altogether. 
-I 
EXAMPLE. It follows that the set of algebraic numbers has cardinal- 
ity KO. First, we can identify each polynomial (in one variable) 
over the integers with the sequence of its coefficients. Then by 
the theorem there are Ho polynomials. Each polynomial has a fi- 
nite number of roots. To give an extravagant upper bound, note 
that even if each polynomial had No roots, we would then have 
No . Ho = Ho algebraic numbers altogether. Since there are at least 
this many, we are done. 
Since there are uncountably many (in fact, 2R0) real numbers, it 
follows that there are uncountably many (in fact, 2'0) transcendental 
numbers. 

,' b. $& 
- 
formal Remarks on 
$4 
,% 
- .  
*
.
 
IF 
=?, 
rmal Languages 
are about to construct (in the next section) a 
guage into which we can translate English sen- 
ike natural languages (such as English 
, it will be a formal language, with pre- 
tion rules. But before the precision be- 
e will consider here some of the features to 
rated into the language. 
st example, the English sentence "Traces 
m were observed" can be translated into 
anguage as, say, the symbol K. Then for 
the closely related sentence "Traces of potassium 
were not observed," we can use (1 
K). Here 1 is 
our negation symbol, read as "not." One might also 
nk of translating "Traces of potassium were not 
served" by some new symbol, for example, J, 
t we will prefer instead to break such a sentence 
wn into atomic parts as much as possible. For an 
unrelated sentence, 'The sample contained chlo- 
rine," we choose, say, the symbol C. Then the fol- 
lowing compound English sentences can be trans- 
lated as the formulas shown at the right: 
If traces of potassium were ob- (K - 
(1 
C)) 
ed, then the sample did not 
sample contained chlorine, 
(C A K) 
assium were ob- 
11 

12 
A Mathematical Introduction to Logic 
The second case uses our conjunction symbol A to translate "and." 
The first one uses the more familiar arrow to translate "if. . . , then . . . ." 
In the following example the disjunction symbol V is used to translate 
Uor77: 
Either no traces of potassium were observed, or 
((1 K) V ( 1  C)) 
the sample did not contain chlorine. 
Neither did the sample contain 
( 1  (C V K)) 
chlorine, nor were traces of 
or 
potassium observed. 
((1 C) A ( 1  K)) 
For this last sentence, we have two alternative translations. The re- 
lationship between them will be discussed later. 
One important aspect of the decompositions we will make of com- 
pound sentences is that whenever we are given the truth or falsity of the 
atomic parts, we can then immediately calculate the truth or falsity of 
the compound. Suppose, for example, that the chemist emerges from 
her laboratory and announces that she observed traces of potassium but 
that the sample contained no chlorine. We then know that the four above 
sentences are true, false, true, and false, respectively. In fact, we can con- 
struct in advance a table giving the four possible experimental results 
(Table I). We will return to the discussion of such tables in Section 1.2. 
TABLE I 
Use of formal languages will allow us to escape from the imprecision 
and ambiguities of natural languages. But this is not done without cost; 
our formal languages will have a sharply limited degree of expressive- 
ness. 
In order to describe a formal language we will generally give three 
pieces of information: 
1. We will specify the set of symbols (the alphabet). In the present 
case of sentential logic some of the symbols are 
2. We will specify the rules for forming the "grammatically correct" 
finite sequences of symbols. (Such sequences will be called well-formed 
formulas or wfs.) For example, in the present case 

Chapter 1 : Sentential Logic 
13 
will be a wff, whereas 
will not. 
3. We will also indicate the allowable translations between English 
and the formal language. The symbols AI , Az, . . . can be translations 
of declarative English sentences. 
Only in this third part is any meaning assigned to the wffs. This 
process of assigning meaning guides and motivates all we do. But it 
will also be observed that it would theoretically be possible to carry out 
various manipulations with wffs in complete ignorance of any possible 
meaning. A person aware of only the first two pieces of information 
listed above could perform some of the things we will do, but it would 
make no sense to him. 
Before proceeding, let us look briefly at another class of formal 
languages of widespread interest today. These are the languages used 
by (or at least in connection with) digital computers. 
There are many of these languages. In one of them a typical wff is 
011010110101000111110001000001111010. 
In another a typical wff is 
(Here #is a symbol called a blank; it is brought into the alphabet so that 
a wff will be a string of symbols.) A well-known language called C++ 
has wffs such as 
In all cases there is a given way of translating the wffs into English, 
and (for a restricted class of English sentences) a way of translating 
from English into the formal language. But the computer is unaware of 
the English language. An unthinking automaton, the computer juggles 
symbols and follows its program slavishly. We could approach formal 
languages that way, too, but it would not be much fun. 
SECTION 1.1 
The Language of Sentential Logic 
We assume we are given an infinite sequence of distinct objects which 
we will call symbols, and to which we now give names (Table 11). We 
further assume that no one of these symbols is a finite sequence of other 
symbols. 

14 
A Mathematical Introduction to Logic 
TABLE II 
Symbol 
Verbose name 
Remarks 
left parenthesis 
right parenthesis 
negation symbol 
conjunction symbol 
disjunction symbol 
conditional symbol 
biconditional symbol 
first sentence symbol 
second sentence symbol 
nth sentence symbol 
punctuation 
punctuation 
English: not 
English: and 
English: or (inclusive) 
English: i f .  then - 
English: if and only if 
Several remarks are now in order: 
1. The five symbols 
are called sentential connective symbols. Their use is suggested by the 
English translation given above. The sentential connective symbols, 
together with the parentheses, are the logical symbols. In translating to 
and from English, their role never changes. The sentence symbols are 
the parameters (or nonlogical symbols). Their translation is not fixed; 
instead they will be open to a variety of interpretations, as we shall 
illustrate shortly. 
2. We have included infinitely many sentence symbols. On the one 
hand, a more modest alternative would be to have one sentence symbol 
A, and a prime '. Then we could use the potentially infinite sequence 
in place of 
This alternative has the advantage that it brings the total number of 
different symbols down to nine. On the other hand, a less modest al- 
ternative would be to allow an arbitrary set of 
sentence symbols, 
countable or not. Much of what is said in this chapter would con- 
tinue to be applicable in this case; the exceptions are primarily in Sec- 
tion 1.7. 
3. Some logicians prefer to call A, the nth proposition symbol (and 
to speak of propositional logic instead of sentential logic). This stems 

Chapter 1 : Sentential Logic 
15 
from wanting the word "sentence" to refer to a particular utterance, and 
wanting a proposition to be that which a sentence asserts. 
4. We call these objects "symbols," but we remain neutral as to what 
the exact ontological status of symbols might be. In the leftmost column 
of our list of symbols, names of the symbols are printed. For example, 
A243 is one symbol, namely the 243rd sentence symbol. (On the other 
hand, "A243" is a name of that symbol. The conditional symbol may 
or may not have the geometric property of being shaped like an arrow, 
although its name "+" does.) The symbols themselves can be sets, 
numbers, marbles, or objects from a universe of linguistic objects. In 
the last case, it is conceivable that they are actually the same things as 
the names we use for them. Another possibility, which will be explained 
in the next chapter, is that the sentence symbols are themselves formulas 
in another language. 
5. We have assumed that no symbol is a finite sequence of other 
symbols. We mean by this that not only are the symbols listed distinct 
(e.g., A3 # -), but no one of them is a finite sequence of two or more 
symbols. For example, we demand that A3 # (1, 
Aq, (). The purpose of 
this assumption is to assure that finite sequences of symbols are uniquely 
decomposable. If 
and each ai and each bj is a symbol, then pn = n and aj = bi. (See 
Chapter 0, Lemma OA, and subsequent remarks.) 
An expression is a finite sequence of symbols. We can specify an 
expression by concatenating the names of the symbols; thus ( 1  Al) is 
the sequence ((, 1, 
Al, )). This notation is extended: If a! and #I are 
sequences of symbols, then a!#I is the sequence consisting first of the 
symbols in the sequence a! followed by the symbols in the sequence #I. 
For example, if a! and #I are the expressions given by the equations 
then (a! + #I) is the expression 
We should now look at a few examples of possible translations of 
English sentences into expressions of the formal language. Let A, B, 
. . . , Z be the first twenty-six sentence symbols. (For example, E = As.) 
1. English: The suspect must be released from custody. Transla- 
tion: R. 
English: The evidence obtained is admissible. Translation: E. 
English: The evidence obtained is inadmissible. Translation: ( 1  E). 

A Mathematical Introduction to Logic 
English: The evidence obtained is admissible, and the suspect need 
not be released from custody. Translation: (E A ( 1  R)). 
English: Either the evidence obtained is admissible, or the suspect 
must be released from custody (or possibly both). Translation: (E V R). 
English: Either the evidence obtained is admissible, or the suspect 
must be released from custody, but not both. Translation: ((E V R) A 
( 1  (E A R))). We intend always to use the symbol V to translate the 
word "or" in its inclusive meaning of "and/or." 
English The evidence obtained is inadmissible, but the suspect need 
not be released from custody. Translation: ((1 E) A ( 1  R)). On the other 
hand, the expression ((1 E) V ( 1  R)) translates the English: Either the 
evidence obtained is inadmissible or the suspect need not be released 
from custody. 
2. English: If wishes are horses, then beggars will ride. Translation: 
(W --, B). 
English: Beggars will ride if and only if wishes are horses. Transla- 
tion: (B e, W). 
3. English: This commodity constitutes wealth if and only if it is 
transferable, limited in supply, and either productive of pleasure or pre- 
ventive of pain. Translation: (W t+ (T A (L A (P V Q)))). Here W is 
the translation of "This commodity constitutes wealth." Of course in the 
preceding example we used W to translate a different sentence. We are 
not tied to any one translation. 
One note of caution: Do not confuse a sentence in the English lan- 
guage (Roses are red) with a translation of that sentence in the formal 
language (such as R). These are different. The English sentence is pre- 
sumably either true or false. But the formal expression is simply a se- 
quence of symbols. It may indeed be interpreted in one context as a true 
(or false) English sentence, but it can have other interpretations in other 
contexts. 
Now some expressions cannot be obtained as translations of any 
English sentences but are mere nonsense, such as 
We want to define the well-formed formulas (wffs) to be the "grarn- 
matically correct" expressions; the nonsensical expressions must be 
excluded. The definition will have the following consequences: 
(a) Every sentence symbol is a wff. 
(b) If a and /3 are wffs, then so are ( 1  a), (a! A B), (a V B), (a -+ B), 
and (a o 
B). 
(c) No expression is a wff unless it is compelled to be one by (a) 
and (b). 

Chapter 1 : Sentential Logic 
17 
We want to make this third property (about compulsion) more pre- 
cise. A well-formed formula (or simply formula or w$) is an expres- 
sion that can be built up from the sentence symbols by applying some 
finite number of times the formula-building operations (on expressions) 
defined by the equations 
For example, 
is a wff, as can be seen by contemplating its ancestral tree: 
The tree illustrates the construction of the expression from four sen- 
tence symbols by five applications of formula-building operations. This 
example is atypical in that it uses all five formula-building operations. 
For a smaller example, A3 is a wff; its ancestral tree has only a single 
vertex; each formula-building operation is used zero times. But this is 
as small as examples get; we do not count the empty sequence as being 
"built up from the sentence symbols." 
This sort of construction, of taking some basic building blocks (here 
the sentence symbols) and "closing" under some operations (here five 
operations), occurs frequently both in logic and in other branches of 
mathematics. In Section 1.4, we will examine this sort of construction 
in a more general setting. 
We can elaborate on the "building" idea as follows. Define a con- 
struction sequence to be a finite sequence (&,, . . . , E,) of expressions 

18 
A Mathematical Introduction to Logic 
such that for each i 5 n we have at least one of 
~i is a sentence symbol 
E~ = &,(s 
for some j < i 
si = 
E
~
)
 
for some j < i, k < i 
where 
is one of the binary connectives, A, V, *, -. Then the well- 
formed formulas can be characterized as the expressions a such that 
some construction sequence ends with a. We can think of ~i as the 
expression at stage i in the building process. 
For our earlier example, 
we obtain a construction sequence by squashing its ancestral tree into a 
linear ordering. 
One feature of this sort of construction is that it yields an induction 
principle. Say that a set S is closed under a two-place function f iff 
whenever x E S and y E S then f (x, y) E S, and similarly for one-place 
functions and so forth. 
INDUCTION 
PRINCIPLE If S is a set of wffs containing all the sentence 
symbols and closed under all five formula-building operations, 
then S is the set of all wffs. 
FIRST PROOF. Consider an arbitrary wff a. It is built up from sentence 
symbols by applying some finite number of times the forrnula- 
building operations. Worlung our way up the corresponding an- 
cestral tree, we find that each expression in the tree belongs to S. 
Eventually (that is, after a finite number of steps) at the top of the 
tree we find that a E S. 
-I 
SECOND PROOF. We will repeat the argument, but without the trees. 
Consider an arbitrary wff a. It is the last member of some con- 
struction sequence (sl, . . . , s,). By ordinary strong numerical in- 
duction on the number i, we see that each si E S, i 5 n. 
That is, we suppose, as our inductive hypothesis, that E j  E S 
for all j < i. We then verify that si E S, by considering the 
various cases. So by strong induction on i, it follows that Ei E S 
for each i 5 n. In particular, the last member a belongs to S. -I 
This principle will receive much use in the coming pages. In the 
following example we use it to show that certain expressions are not 
wffs. 
EXAMPLE. Any expression with more left parentheses than right 
parentheses is not a wff. 

Chapter 1: 
Sentential Logic 
19 
PROOF. The idea is that we start with sentence symbols (having 
zero left parentheses and zero right parentheses), and then ap- 
ply formula-building operations which add parentheses only in 
matched pairs. We can rephrase this argument as follows: The 
set of "balanced" wffs (having equal numbers of left and right 
parentheses) contains all sentence symbols and is closed under 
the formula-building operations. The induction principle then as- 
sures us that all wffs are balanced. 
-I 
A special feature of our particular formula-building operations is that 
they build up and never down. That is, the expression Eo(a, p) always 
includes as a segment the entire sequence a (and the entire sequence p) 
plus other symbols. In particular, it is longer than either a or #I. 
This special feature will simplify the problem of determining, given 
a wff (o, exactly how it was built up. All the building blocks, so to speak, 
are included as segments in the sequence (o. For example, if (o does not 
contain the symbol &, then (o can be built up without ever using A4. 
(See Exercise 4.) 
Exercises 
1. Give three sentences in English together with translations into our 
formal language. The sentences should be chosen so as to have an 
interesting structure, and the translations should each contain 15 or 
more symbols. 
2. Show that there are no wffs of length 2, 3, or 6, but that any other 
positive length is possible. 
3. Let a be a wff; let c be the number of places at which binary con- 
nective symbols (A, V, +, *) occur in a ;  let s be the number of 
places at which sentence symbols occur in a. (For example, if a is 
(A -+ (1 
A)) then c = 1 and s = 2.) Show by using the induction 
principle that s = c + 1. 
4. Assume we have'a construction sequence ending in (o, where (o does 
not contain the symbol Aq. Suppose we delete all the expressions 
in the construction sequence that contain A4. Show that the result is 
still a legal construction sequence. 
5. Suppose that a is a wff not containing the negation symbol 1. 
(a) Show that the length of a (i.e., the number of symbols in the 
string) is odd. 
(b) Show that more than a quarter of the symbols are sentence 
symbols. 
Suggestion: Apply induction to show that the length is of the form 
4k + 1 and the number of sentence symbols is k + 1. 

2 0 
A Mathematical Introduction to Logic 
SECTION 1.2 
Truth Assignments 
We want to define what it means for one wff of our language to fol- 
low logically from other wffs. For example, Al should follow from 
(Al A A2). For no matter how the parameters Al and A2 are translated 
back into English, if the translation of (Al /\A2) is true, then the transla- 
tion of A1 must be true. But the notion of all possible translations back 
into English is unworkably vague. Luckily the spirit of this notion can 
be expressed in a simple and precise way. 
Fix once and for all a set {F, T) of truth values consisting of two 
distinct points: 
F, called falsity, 
T, called truth. 
(It makes no difference what these points themselves are; they might as 
well be the numbers 0 and 1 .) Then a truth assignment v for a set S of 
sentence symbols is a function 
v : S + {F, T] 
assigning either T or F to each symbol in S. These truth assignments 
will be used in place of the translations into English mentioned in the 
preceding paragraph. 
(At this point we have committed ourselves to two-valued logic. It is 
also possible to study three-valued logic, in which case one has a set of 
three possible truth values. And then, of course, it is a small additional 
step to allow 512 or KO truth values; or to take as the set of truth values 
the unit interval [0, 11 or some other convenient space. A particularly 
interesting case is that for which the truth values form something called 
a complete Boolean algebra. But it is two-valued logic that has always 
had the greatest significance, and we will confine ourselves to this case.) 
Let S be the set of wffs that can be built up from S by the five 
formula-building operations. (scan also be characterized as the set of 
wffs whose sentence symbols are all in S; see the remarks at the end of 
the preceding section.) We want an extension 5 of v, 
ii : s + {F, TI, 
that assigns the correct truth value to each wff in s. It should meet the 
following conditions: 
0. For any A E S, B(A) = v(A). (Thus Ti is an extension of v .) 
For any a, in S: 
T if V(a) = F, 
1. V((l a)) = F otherwise. 

Chapter 1 : Sentential Logic 
2 1 
2. E((a A /3)) = T if V(a) = T and B(/3) = T, 
F otherwise. 
T if V(a) = T or B(B) = T (or both), 
3. V((a v /3)) = F otherwise. 
F if 
E(a) = T and V(/3) = F, 
4. V((a -+ /3)> = T otherwise. 
T if E(a) = V(/3), 
5. V((a * 
/3)) = F otherwise. 
Conditions 1-5 are given in tabular form in Table 111. It is at this point 
that the intended meaning of, for example, the conjunction symbol enters 
into our formal proceedings. Note especially the intended meaning of 
-+. Whenever a is assigned F, then (a --, /I) 
is considered "vacuously 
true" and is assigned the value T. For this and the other connectives, it 
is certainly possible to question how accurately we have reflected the 
common meaning in everyday speech of "if . . . , then," "or," etc. But 
our ultimate concern lies more with mathematical statements than with 
the subtle nuances of everyday speech. 
TABLE Ill 
For example, we might translate the English sentence, "If you're 
telling the truth then I'm a monkey's uncle,'' by the formula (V + M). 
We assign this formula the value T whenever you are fibbing. In as- 
signing the value T, we are certainly not asserting any causal connec- 
tion between your veracity and any simian features of my nephews or 
nieces. The sentence in question is a conditional statement. It makes an 
assertion about my relatives provided a certain condition -that you are 
telling the truth- is met. Whenever that condition fails, the statement 
is vacuously true. 
Very roughly, we can think of a conditional formula (a! -+ /3) as 
expressing a promise that if a certain condition is met (viz., that a is 
true), then /3 is true. If the condition a turns out not to be met, then the 
promise stands unbroken, regardless of /3. 
As an example of the calculation of V, let a be the wff 

2 2 
A Mathematical Introduction to Logic 
and let v be the truth assignment for (A1, A2, A6) such that 
We want to compute E(a). We can look at the tree which displays the 
'construction of a: 
Working from the bottom up, we can assign to each vertex of the tree 
the value 3(B). So as a first step we compute 
Next we compute E((A2 3 (A1 + As))) = F, and so forth. Finally, at 
the top of the tree we arrive at E(a) = T. 
Actually this computation can be carried out with much less writing. 
First, the tree can be given in starker form: 
And even this can be compressed into a single line (with the parentheses 
restored): 

Chapter 1 : Sentential Logic 
23 
((A2 + (A1 + A,)) - ((4 
A A,) + A,)) - 
T F T  F F  
T  T T T  F F  
THEOREM 
12A For any truth assignment v for a set S there is a 
unique function 3 : S + [ F ,  T )  meeting the aforementioned 
conditions 0-5. 
The full proof of this theorem will emerge in the next two sections (1.3 
and 1.4). But it should already seem extremely plausible, especially in 
light of the preceding example. In proving the existence of 3, 
the crucial 
issue will, in effect, be the uniqueness of the trees mentioned in the 
example. 
We say that a truth assignment v satisjies q iff V(q) = T .  (Of course 
for this to happen, the domain of v must contain all sentence symbols in 
q.) Now consider a set C of wffs (thought of as hypotheses) and another 
wff t (thought of as a possible conclusion). 
DEFINITION. 
C tautologically implies t (written C + t )  iff every 
truth assignment for the sentence symbols in X and t that satisfies 
every member of C also satisfies T. 
This definition reflects our intuitive feeling that a conclusion follows 
from a set of hypotheses if the assumption that the hypotheses are true 
guarantees that the conclusion is true. 
Several special cases of the concept of tautological implication de- 
serve mention. First, take the special case in which C is the empty set 0. 
Observe that it is vacuously true that any truth assignment satisfies every 
member of 0. (How could h s  fail? Only if there was some unsatisfied 
member of 0, which is absurd.) Hence we are left with: 0 k t iff every 
truth assignment (for the sentence symbols in t )  satisfies t . In this case 
we say that t is a tautology (written + r). For example, the wff ((A2 -) 
(Al -+ A6)) * 
((A2 A A1) --, A6)) was in a recent example found to be 
satisfied by one of the eight possible truth assignments for [Al, A2, A6). 
In fact, it is satisfied by the other seven as well, and hence is a tautology. 
Another special case is that in which no truth assignment satisfies 
every member of X. Then for any t, it is vacuously true that C + r. 
For example, 
There is no deep principle involved here; it is simply a by-product of 
our definitions. 
EXAMPLE. {A, (A --, B)) + B. There are four truth assignments for 
[A, B]. It is easy to check that only one of these four satisfies both 
A and (A --, B), namely the v for which v(A) = v(B) = T. This 
v also satisfies B. 

24 
A Mathematical Introduction to Logic 
If X is singleton (a), then we write "a 
t" in place of "{a) + t ." If 
both a 
t and T 
a ,  then a and t are said to be tautologically equiv- 
alent (written a 
t). For example, in Section 1.0 we encountered 
the wffs ( 1  (C VK)) and ((1 C) A(1 K)) as alternative translations of an 
English sentence. We can now assert that they are tautologically equiv- 
alent. 
We can already state here a nontrivial fact whose proof will be given 
later (in Section 1.7). 
COMPACTNESS 
THEOREM Let X be an infinite set of wffs such that for 
any finite subset Xo of X, there is a truth assignment that satisfies 
every member of Xo. Then there is a truth assignment that satisfies 
every member of X. 
This theorem can be restated more simply as: If every finite subset of 
X is satisfiable, then X itself is satisfiable. (Readers familiar with some 
general topology might try to discover why this is called "compactness 
theorem"; it does assert the compactness of a certain topological space. 
They can then prove the theorem for themselves, by using Tychonoff's 
theorem on product spaces.) 
Truth Tables 
There is a systematic procedure, which we will now illustrate, for check- 
ing, given wffs 01, . . . , ak, and r, whether or not 
In particular (when k = O), the procedure will, given a wff, decide 
whether or not it is a tautology. 
As a first example, we can show that 
To do this, we consider all truth assignments for {A, B). There are four 
such assignments; in general there are 2" truth assignments for a set of 
n sentence symbols. The four can be listed in a table: 
This table can then be expanded to include ( 1  (A A B)) and ((1 A) V 
( 1  B)). For each formula we compute the T's and F's the way described 
before, writing the truth value under the correct connective (Table IV). 
(The two leftmost columns of Table IV are actually unnecessary.) We 
can now see from this table that all those truth assignments satisfying 
( 1  (A A 8)) - 
and there are three such -also satisfy ((1 A) V ( 1  B)). 

TABLE IV 
T  
T  
F T T T  
F T F F T  
T  
F  
T T F F  
F T T T F  
F  
T  
T F F T  
T F T F T  
F  
F  
T F F F  
T F T T F  
In fact, the converse holds also, and thus 
To show that ( 1  (A A B)) &c= ((1 A) A ( 1  B)) we can construct the 
table as before. But only one line of the table is needed to establish that 
there is indeed a truth assignment satisfying ( 1  (A A B)) that fails to 
satisfy ((1 A) A ( 1  B)). 
The more generally applicable a procedure it is, the less efficient it 
is likely to be. For example, to show that 
we could apply the truth-table method. But this requires eight lines 
(for the eight possible truth assignments for [A, B, C)). With a little 
cleverness, the tedium in this particular case can be reduced: 
((A v (B A C)) o 
((A v B) A (A v C))). 
T  T  
T  T T  T T T  
F F F F  
T  F F F F F  
F T T T T  T  F T T T F T T  
In the first line we assumed only that v(A) = T. Since that is enough 
information to obtain T for the wff, we assume in all later lines that 
v(A) = F. In the second line we assume that v(B) = F; this again lets 
us obtain T for the wff. So we may limit ourselves to the case v(B) = T. 
Since the expression is symmetric in B and C, we may further suppose 
v(C) = T. This leaves only the third line, whereupon we are done. 
As an example of the avoidance of a 16-line table, consider the 
following tautology : 
(f((P 
Q)+R)+S)+((P+R)+S)). 
T  
T  T  
F  T  F F T  
T T T  R R R F  T  T R R R F  
Here in the first line we dispose of the case where v(S) = T. In the 
second line we dispose of the case where either v(P) = F or v(Q) = F. 

26 
A Mathematical Introduction to Logic 
The third line incorporates the two remaining possibilities; here R is the 
truth value assigned to R and R is the opposite value. 
For the above example it is possible to see directly why it is a tautol- 
ogy. The stronger the antecedent (the expression on the left side), the 
weaker the conditional. Thus 
The problem of developing effective procedures that reduce the 
tedium is important for theorem proving by machine. Some of the pro- 
grams here may require testing wffs of sentential logic having thousands 
of sentence symbols. Truth tables are far too cumbersome for anything 
this large. The problem of developing highly efficient methods is a cur- 
rent area of research in computer science. 
Digression. Applying the truth-table method-carried 
out in 
full-to 
a wff with n sentence symbols requires making a table of 
2" lines. The trouble is, as n increases, 2" grows "exponentially." For 
example, suppose you can generate the table at the rate of a million lines 
per second. (We are supposing you are aided by a computer, of course.) 
Then if n = 80, say, you will need "merely" 280 microseconds to form 
the complete table. How long is that? Converted to years, 280 microsec- 
onds is about 38 billion years. For comparison, the age of the universe 
is around 15 billion years. The conclusion is that 280 microseconds is 
more time than there has been time! 
Is there a faster method? Might there be some general method that, 
given any wff a with n sentence symbols, will determine whether or 
not a is a tautology in only l0nS microseconds (or some other function 
of n that grows like a polynomial instead of growing exponentially)? 
(For n = 80, l0nS microseconds comes to only 9 hours.) The answer 
to thrs question is unknown, but it is widely believed that the answer is 
negative. The question is called the "P versus NP" problem, the most 
prominent open problem in theoretical computer science today. 
A Selected List of Tautologies 
1. Associative and commutative laws for A, V, *. 
2. Distributive laws: 
((A A (B V C)) * ((A A B) V (A A C))). 
((A V (B A C)) * ((A V B) A (A V C))). 

Chapter 1 : Sentential Logic 
27 
3. Negation: 
De Morgan's laws: 
4. Other 
Excluded middle: (A V ( 1  A)). 
Contradiction: 
( 1  (A A ( 1  A))). 
contraposition: 
((A --t B) * ((1 B) --t ( 1  A))). 
Exportation: 
(((A A B) --, C) * (A --, (B --, C))). 
Exercises 
1. Show that neither of the following two formulas tautologically im- 
plies the other: 
Suggestion: Only two truth assignments are needed, not eight. 
2. (a) Is (((P --, Q) --, P) --, P) a tautology? 
(b) Define a k  recursively as follows: 00 = (P --, Q) and a k + l  = 
(ak -) P). For which values of k is a k  a tautology? (Part (a) 
corresponds to k = 2.) 
3. (a) Determine whether or not ((P --t Q) V (Q --, P)) is a tautology. 
(b) Determine whether or not ((PA Q) --, R) tautologically implies 
((P --, R) v (Q --, R)). 
4. Show that the following hold: 
(a) C; a + B iff C + (a -, B). 
(b) a +=I B iff 
(d * B). 
(Recall that C; a! = C U[a), the set C together with the one possibly 
new member a .) 
5. Prove or refute each of the following assertions: 
(a) If either C + a! or C + #J, then C + (a! V /I). 
(b) If C + (a! V B), then either C + a! or C + B. 
6. (a) Show that if vl and v2 are tnlth assignments which agree on all 
the sentence symbols in the wff a!, then Bl(a!) = Z2(a!). Use 
the induction principle. 

A Mathematical Introduction to Loaic 
(b) Let S be a set of sentence symbols that includes those in E and 
t (and possibly more). Show that E + t iff every truth assign- 
ment for S which satisfies every member of E also satisfies t. 
(This is an easy consequence of part (a). The point of part (b) 
is that we do not need to worry about getting the domain of a 
truth assignment exactly perfect, as long as it is big enough. For 
example, one option would be always to use truth assignments 
on the set of all sentence symbols. The drawback is that these 
are infinite objects, and there are a great many - 
uncountably 
many - 
of them.) 
7. You are in a land inhabited by people who either always tell the 
truth or always tell falsehoods. You come to a fork in the road 
and you need to know which fork leads to the capital. There is a 
local resident there, but he has time only to reply to one yes-or-no 
question. What one question should you ask so as to learn which 
fork to take? Suggestion: Make a table. 
8. (Substitution) Consider a sequence a 1, a2, . . . of wffs. For each wff 
p let p* be the result of replacing the sentence symbol A, by a,, 
for each n. 
(a) Let v be a truth assignment for the set of all sentence symbols; 
define u to be the truth assignment for which u(A,) = v(a,). 
Show that i(p) = iT(p*). Use the induction principle. 
(b) Show that if p is a tautology, then so is p*. (For example, one 
of our selected tautologies is ((A A B) * (B A A)). From this 
we can conclude, by substitution, that ((a A /I) * 
(/3 A a)) is 
a tautology, for any wffs a and /3.) 
9. (Duality) Let a be a wff whose only connective symbols are A, V, 
and 1 .  Let a* be the result of interchanging A and V and replacing 
each sentence symbol by its negation. Show that a* is tautologically 
equivalent to ( 1  a). Use the induction principle. 
Remark: It follows that if a +=I /3 then a* +=I /3*. 
10. Say that a set C1 
of wffs is equivalent to a set C2 of wffs iff for any 
wff a ,  we have El + a iff E2 + a. A set E is independent iff no 
member of E is tautologically implied by the remaining members 
in E. Show that the following hold. 
(a) A finite set of wffs has an independent equivalent subset. 
(b) An infinite set need not have an independent equivalent subset. 
*(c) Let E = {ao, 
a1 , . . .}; show that there is an independent equiv- 
alent set E'. (By part (b), we cannot hope to have E' S E in 
general.) 
11. Show that a truth assignment v satisfies the wff 

Chapter I 
: Sentential Logic 
29 
iff v(Ai) = F for an even number of i's, 1 5 i 5 n. (By the 
associative law for *, the placement of the parentheses is not 
crucial.) 
12. There are three suspects for a murder: Adams, Brown, and Clark. 
Adams says "I didn't do it. The victim was an old acquaintance of 
Brown's. But Clark hated him." Brown states "I didn't do it. I didn't 
even know the guy. Besides I was out of town all that week." Clark 
says "I didn't do it. I saw both Adarns and Brown downtown with 
the victim that day; one of them must have done it." Assume that 
the two innocent men are telling the truth, but that the guilty man 
might not be. Who did it? 
13. An advertisement for a tennis magazine states, "If I'm not playing 
tennis, I'm watching tennis. And if I'm not watching tennis, I'm 
reading about tennis." We can assume that the speaker cannot do 
more than one of these activities at a time. What is the speaker 
doing? (Translate the given sentences into our formal language; 
consider the possible truth assignments.) 
14. Let S be the set of all sentence symbols, and assume that v : S + 
{F, T} is a truth assignment. Show there is at most one extension 
iT meeting conditions 0-5 listed at the beginning of h s  section. 
(Suppose that iS1 and v:! are both such extensions. Use the induction 
principle to show that Vl = V2.) 
15. Of the following three formulas, which tautologically imply which? 
(a) (A * 
B) 
(b) ( 1  ((A + B) + ( 1  (B + A)))) 
(c) (((1 A) V B) A (A V ( 1  B))) 
SECTION 1.3 
A Parsing Algorithm 
The purpose of this section is to prove that we have used enough paren- 
theses to eliminate any ambiguity in analyzing wffs. (The existence 
of the extension ii of a truth assignment v will hinge on this lack of 
ambiguity. ' ) 
It is instructive to consider the result of not having parentheses at all. 
The resulting ambiguity is illustrated by the wff 
The reader who has already accepted the existence of 5 may omit almost all of this 
section. The final subsection, on omittini parentheses, will still be needed. 

30 
A Mathematical Introduction to Logic 
which can be formed in two ways, corresponding to ((A1 V A2) A As) 
and to (A, V (A2 A A3)). If v(A1) = T and v(As) = F, then there is an 
unresolvable conflict that arises in trying to compute v(A1 V A2 A As). 
We must show that with our parentheses this type of ambiguity does 
not arise but that on the contrary each wff is formed in a unique way. 
There is one sense in which this fact is unimportant: If it failed, we 
would simply change notation until it was true. For example, instead 
of building formulas by means of concatenation, we could have used 
ordered pairs and triples: (1, 
a) and (a, A, p), and so forth. (This is, in 
fact, a tidy, but untraditional, method.) It would then be immediate that 
formulas had unique decompositions. But we do not have to resort to 
this device, and we will now prove that we do not. 
LEMMA 13A Every wff has the same number of left as right paren- 
theses. 
PROOF. This was done as an example at the end of Section 1.1. -I 
LEMMA 13B Any proper initial segment of a wff contains an excess 
of left parentheses. Thus no proper initial segment of a wff can 
itself be a wff. 
PROOF. We apply the induction principle to the set S of wffs pos- 
sessing the desired property (that proper initial segments are left- 
heavy). A wff consisting of a sentence symbol alone has no proper 
initial segments and hence is in S vacuously. To verify that S is 
closed under EA, consider a and /3 in S. The proper initial seg- 
ments of (a A #I) 
are the following: 
1. (. 
2. (ao, where a 0  is a proper initial segment of a. 
3. (a. 
4. (aA. 
5. (a A /lo, where Po is a proper initial segment of j3. 
6. (a A /I. 
By applying the inductive hypothesis that a and #l 
are in S 
(in cases 2 and 5), we obtain the desired conclusion. For closure 
under the other four formula-building operations, the argument is 
similar. 
-I 
A Parsing Algorithm 
We are now going to describe a procedure that, given an expression, 
both wfll determine whether or not the expression is a legal wff, and if 
it is, will construct the tree showing how it was built up from sentence 
symbols by application of the formula-building operations. Moreover, 

Chapter 1 : Sentential Logic 
3 1 
we will see that this tree is uniquely determined by the wff. It is this 
last fact that will assure us that we have enough parentheses for an 
unambiguous notation. 
Assume then that we are given an expression. We will construct a tree, 
with the given expression at the top. Initially it is the only vertex in the 
tree, but as the procedure progresses, the tree will grow downward from 
the given expression. For an example, imagine the tree in Section 1.1. 
The algorithm consists of the following four steps: 
1. If all minimal vertices (the -ones at the bottom) have sentence 
symbols, then the procedure is completed. (The given expression is 
indeed a wff, and we have constructed its tree.) Otherwise, select a 
minimal vertex having an expression that is not a sentence symbol. We 
examine that expression. 
2. The first symbol must* be (. If the second symbol is the negation 
symbol, jump to step 4. Otherwise, go on to step 3. 
3. Scan the expression from the left until first reaching (a, where 
a is a nonempty expression having a balance between left and right 
parentheses.** Then a is the first of the two constituents. The next 
symbol must* be A, V, +, or *. This is the principal connective. The 
remainder of the expression, B), must* consist of an expression #I and a 
right parenthesis. We extend the tree by creating two new vertices below 
the present one, with a as the expression at the "left child" vertex, and 
B as the expression at the "right child" vertex. Return to step 1. 
4. The first two symbols are now known to be (1. 
The remainder 
of the expression, B), must* consist of an expression #I and a right 
parenthesis. We extend the tree by creating one new vertex below the 
present one, with /3 as the expression at the child vertex. Return to step 1. 
Now for some comments in support of the correctness of this algo- 
rithm. 
First, given any expression, the procedure halts after a finite number 
of steps. This is because any vertex contains a shorter expression than 
the one above it, so the depth of the tree is bounded by the length of the 
given expression. 
Secondly, the choices made by the procedure could not have been 
made differently. For example, in step 3 we arrive at an expression a. We 
could not use less than a for a constituent, because it would not have a 
balance between left and right parentheses (as required by Lemma 13A). 
* If not, then the expression here is not a wff. We reject the given expression as a non-wff, 
and halt. 
** If the end of the expression is reached before finding such an a, then the expression 
here is not a wff. We reject the given expression as a non-wff, and halt. 

3 2 
A Mathematical Introduction to Logic 
We could not use more than a ,  because that would have the proper initial 
segment a that was balanced (violating Lemma 13B). Thus a is forced 
upon us. And then the choice of the principal connective is inevitable. 
We conclude that this algorithm constructs the only possible tree for the 
given expression. 
Thirdly, if the algorithm uses the footnotes to reject the given expres- 
sion, then that expression could not have been a wff - 
the rejection is 
correct. That is because the only possible attempt to make its tree failed. 
Finally, if the algorithm does not use the rejection footnotes, then the 
given expression is indeed a legal wff. That is because we h v e  its tree; 
by working our way up the tree, we find inductively that every vertex 
has a wff, including the top vertex. 
The second remark above lets us conclude that our language has 
enough parentheses; each wff has a unique tree of the sort constructed 
here. We have "unique readability." And not only does a unique tree exist 
for a wff, we know how to construct it; we can carry out this algorithm, 
using a sufficiently large piece of paper. 
Now to go back to the question of the existence of the extension 
V of a truth assignment v: It is the uniqueness of the trees that is the 
crucial fact here. For any wff q there is a unique tree constructing it. 
By working our way up this tree, assigning a truth value V(a) at each 
vertex a ,  we can unambiguously arrive at a value for E(q). And the 
function described in this way meets conditions 0-5 listed at the start 
of Section 1.2. And not only that, we know how, given q and the values 
of v at its sentence symbols, to carry out the calculation of V(q). 
Thus, using the parsing algorithm, we can make a function v as 
described in Theorem 12A. And there can be only one such 5; cf. Ex- 
ercise 14 in Section 1.2. 
The only reason the existence of T is an issue at all is that in Sec- 
tion 1.2 it is described by recursion. That is, V(q) is specified by making 
use of the function B itself, applied to smaller formulas. In the next 
section, we approach the matter of defining a function by recursion 
more generally. By treating the subject more abstractly, we can better 
isolate what is at stake. 
Polish Notation 
It is possible to avoid both ambiguity and parentheses. This can be done 
by a very simple device. Instead of, for example, (a A p) we use Asp. 
Let the set of P-wffs be the set generated from the sentence symbols by 
the five operations 

Chapter 1 : Sentential Logic 
33 
For example, one P-wff is 
Here the need for an algorithm to analyze the structure is quite ap- 
parent. Even for the short example above, it requires some thought to 
see how it was built up. We will give a unique readability theorem for 
such expressions in Section 2.3. 
This way of writing formulas (but with N, K, A, C, and E in place 
of 1, A, V, +, and *, respectively) was introduced by the Polish logi- 
cian Eukasiewicz. The notation is well suited to automatic processing. 
Computer compiler programs often begin by converting the formulas 
given them into Polish notation. 
Omitting Parentheses 
Hereafter when naming wffs, we will not feel compelled to mention 
explicitly every parenthesis. To establish a more compact notation, we 
now adopt the following conventions: 
1. The outermost parentheses need not be explicitly mentioned. For 
example, when we write "A A B" we are referring to (A A B). 
2. The negation symbol applies to as little as possible. For example, 
1 
A A B is ( 1  A) A B, i.e., ((1 A) A B). It is not the same as ( 1  (A A 
B)). 
3. The conjunction and disjunction symbols apply to as little as pos- 
sible, given that convention 2 is to be observed. For example, 
4. Where one connective symbol is used repeatedly, grouping is to 
the right: 
a + B +  y is a+(#l+ 
y). 
It must be admitted that these conventions violate what was said ear- 
lier about naming expressions. We can get away with this only because 
we no longer have any interest in naming expressions that are not wffs. 
Exercises 
1. Rewrite the tautologies in the "selected list" at the end of Section 1.2, 
but using the conventions of the present section to minimize the 
number of parentheses. 
2. Give an example of wffs a and /3 and expressions y and S such that 
(aAB)=(yAS)buta # y. 

34 
A Mathematical Introduction to Logic 
3. Carry out the argument for Lemma 13B for the case of the operation 
E, . 
4. Suppose that we modify our definition of wff by omitting all right 
parentheses. Thus instead of 
we use 
((AA(iB-+ (CVD. 
Show that we still have unique readability (i.e., each wff still has 
only one possible decomposition). Suggestion: These expressions 
have the same number of parentheses as connective symbols. 
5. The English language has a tendency to use two-part connectives: 
"both . . . and . . ." "either . . . or . . ." "if . . . , then . . . ." How does 
this affect unique readability in English? 
6. We have given an algorithm for analyzing a wff by constructing its 
tree from the top down. There are also ways of constructing the tree 
from the bottom up. Th~s 
can be done by loolung through the formula 
for innermost pairs of parentheses. Give a complete description of 
an algorithm of this sort. 
7. Suppose that left and right parentheses are indistinguishable. Thus, 
instead of (a V (/3 A y)) we have (a V I/3 A yll. Do formulas still 
have unique decomposition? 
SECTION 1.4 
Induction and Recursion' 
1 nduction 
There is one special type of construction that occurs frequently both in 
logic and in other branches of mathematics. We may want to construct 
a certain subset of a set U by starting with some initial elements of U, 
and applying certain operations to them over and over again. The set we 
seek will be the smallest set containing the initial elements and closed 
under the operations. Its members will be those elements of U which 
can be built up from the initial elements by applying the operations 
some finite number of times. 
On the one hand, the concepts in this section are important, and they arise in many 
places throughout mathematics. On the other hand, readers may want to postpone - 
not 
skip - 
study of this section. 

Chapter 1 : Sentential Logic 
35 
In the special case of immediate interest to us, U is the set of expres- 
sions, the initial elements are the sentence symbols, and the operations 
are E,, EA, etc. The set to be constructed is the set of wffs. But we will 
encounter other special cases later, and it will be helpful to view the 
situation abstractly here. 
To simplify our discussion, we will consider an initial set B 2 U 
and a class F of functions containing just two members f and g, where 
f : U x U + U  
and g : U + U .  
Thus f is a binary operation on U and g is a unary operation. (Actu- 
ally F need not be finite; it will be seen that our simplified discussion 
here is, in fact, applicable to a more general situation. F can be any 
set of relations on U, and in Chapter 2 this greater generality will be 
utilized. But the case discussed here is easier to visualize and is gen- 
eral enough to illustrate the ideas. For a less restricted version, see 
Exercise 3 .) 
If B contains points a and b, then the set C we wish to construct will 
contain, for example, 
Of course these might not all be distinct. The idea is that we are given 
certain bricks to work with, and certain types of mortar, and we want C 
to contain just the things we are able to build. 
In defining C more formally, we have our choice of two definitions. 
We can define it "from the top down" as follows: Say that a subset S of 
U is closed under f and g iff whenever elements x and y belong to S, 
then so also do f (x, y) and g(x). Say that S is inductive iff B 5 S and 
S is closed under f and g. Let C* be the intersection of all the inductive 
subsets of U; thus x E C* iff x belongs to every inductive subset of 
U. It is not hard to see (and the reader should check) that C* is itself 
inductive. Furthermore, C* is the smallest such set, being included in 
all the other inductive sets. 
The second (and equivalent) definition works "from the bottom up." 
We want C, to contain the things that can be reached from B by applying 
f and g a finite number of times. Temporarily define a construction 
sequence to be a finite sequence (xl, . . . , x,) of elements of U such that 
for each i _( n we have at least one of 
Xi E B, 
X i =  f(xj,xk) forsome j < i , k  < i ,  
xi = g(xj) 
for some j < i. 
In other words, each member of the sequence either is in B or results 
from earlier members by applying f or g. Then let C, be the set of all 
points x such that some construction sequence ends with x. 

36 
A Mathematical Introduction to Logic 
Let Cn be the set of points x such that some construction sequence 
of length n ends with x . Then C1 = B , 
and C, = Un Cn. For example, g (f (a, f (b, b))) is in C5 and hence in 
C,, as can be seen by contemplating the tree shown: 
We obtain a construction sequence for g( f (a, f (b, b))) by squashing 
this tree into a linear sequence. 
1. The natural numbers. Let U be the set of all real numbers, 
and let B = {O). Take one operation S, where S(x) = x + 1. Then 
c* = {O, 1,2, . . .}. 
The set C, of natural numbers contains exactly those numbers 
obtainable from 0 by applying the successor operation repeatedly. 
2. The integers. Let U be the set of all real numbers; let B = 
{O}. This time take two operations, the successor operation S and 
the predecessor operation P : 
S ( x ) = x + l  and P(x)=x-1. 
Now C, contains all the integers, 
Notice that there is more than one way of obtaining 2 as a member 
of C,. For 2 is S(S(O)), but it is also S(P (S(S(0)))). 
3. The algebraic functions. Let U contain all functions whose 
domain and range are each sets of real numbers. Let B contain 
the identity function and all constant functions. Let 3 contain the 
operations (on functions) of addition, multiplication, division, and 
root extraction. Then C, is the class of algebraic functions. 
4. The well-formed formulas. Let U be the set of all expres- 
sions and let B be the set of sentence symbols. Let 3 contain the 
five formula-building operations on expressions: E,, EA, Ev, E,, 
and E,. Then C, is the set of all wffs. 

Chapter 1 : Sentential Logic 
37 
At this point we should verify that our two definitions are actually 
equivalent, i.e., that C* = C,. 
To show that C* s C, we need only check that C, is inductive, i.e., 
that B S C, and C, is closed under the functions. Clearly B = C1 S C,. 
If x and y are in C,, then we can concatenate their construction sequences 
and append f (x, y) to obtain a construction sequence placing f (x, y) 
in C,. Similarly, C, is closed under g. 
Finally, to show that C, s C* we consider a point in C, and a 
construction sequence (xo, . . . , xn) for it. By ordinary induction on i, 
yve can see that xi E C*, i 5 n. First xo E B S C*. For the inductive 
step we use the fact that C* is closed under the functions. Thus we 
conclude that u 
Cn = C, = C* = n { S  1 S 
is inductive}. 
R 
(A parenthetical remark: Suppose our present study is embedded in 
axiomatic set theory, where the natural numbers are usually defined 
from the top down. Then our definition of C, (employing finiteness and 
hence natural numbers) is not really different from our definition of C*. 
But we are not working within axiomatic set theory; we are working 
within informal mathematics. And the notion of natural number seems 
to be a solid, well-understood intuitive concept.) 
Since C* = C,, we call the set simply C and refer to it as the set 
generatedfrom B by the functions in F. 
We will often want to prove 
theorems by using the following: 
INDUCTION 
PRINCIPLE Assume that C is the set generated from B by 
the functions in 3. If S is a subset of C that includes B and is 
closed under the functions of 3 then S = C .  
PROOF. S is inductive, so C = C* s S. We are given the other 
inclusion. 
-I 
The special case now of interest to us is, of course, Example 4. Here 
C is the class of wffs generated from the set of sentence symbols by the 
formula-building operations. This special case has interesting features 
of its own. Both a and /3 are proper segments of &*(a, p), i.e., of (a A /3). 
More generally, if we look at the family tree of a wff, we see that each 
constituent is a proper segment of the end product. 

3 8 
A Mathematical Introduction to Logic 
Suppose, for example, that we temporarily call an expression spe- 
cial if the only sentence symbols in it are among {A2, A3, A5) and the 
only connective symbols in it are among {l 
, +). Then no special wff 
requires As or El\ for its construction. In fact, every special wff belongs 
to the set C, generated from [A2, A3, As) by E, and E,. (We can use 
the induction principle to show that every wff either belongs to C, or is 
not special.) 
Recursion 
We return now to the more abstract case. There is a set U (such as the 
set of all expressions), a subset B of U (such as the set of sentence 
symbols), and two functions f and g, where 
f : U x U + U  
and g : U + U .  
C is the set generated from B by f and g. 
The problem we now want to consider is that of defining a function 
on C recursively. That is, we suppose we are given 
1. Rules for computing z(x) for x E B. 
2a. Rules for computing z( f (x, y)), making use of z(x) and h(y). 
2b. Rules for computing z(&)), making use of z(x). 
(For example, this is the situation discussed in Section 1.2, where z is 
the extension of a truth assignment for B.) It is not hard to see that there 
can be at most one function h on C meeting all the given requirements. 
But it is possible that no such hexists; the rules may be contradictory. 
For example, let 
U = the set of real numbers, 
B = IOl, 
f(x,y> = x  my, 
g(x) = x + 1. 
Then C is the set of natural numbers. Suppose we impose the following 
requirements on h: 
Then no such function h can exist. (Try computing %(I), noting that we 
have both 1 = g(0) and 1 = f (g(O), g(O)).) 
A similar situation is encountered in algebra.2 Suppose that you 
have a group G that is generated from B by the group multiplication 
It is hoped that examples such as this will be useful to the reader with some algebraic 
experience. The other readers will be glad to know that these examples are merely 
illustrative and not essential to our development of the subject. 

Cha~ter 1 : Sentential Loaic 
3 9 
and inverse operation. Then an arbitrary map of B into a group H is 
not necessarily extendible to a homomorphism of the entire group G 
into H. But if G happens to be a free group with set B of independent 
generators, then any such map is extendible to a homomorphism of the 
entire group. 
Say that C isfreely generated from B by f and g iff in addition to 
the requirements for being generated, the restrictions fc and gc of f 
and g to C meet the following conditions: 
1. fc and gc are one-to-one. 
2. The range of fc, the range of gc, and the set B are pairwise 
disjoint. 
The main result of this section, the recursion theorem, says that if C 
is freely generated then a function h on B always has an extension h on 
C that follows the sorts of rules considered above. 
RECURSION 
THEOREM Assume that the subset C of U is freely gen- 
erated from B by f and g , where 
Further assume that V is a set and F, G, and h functions such that 
Then there is a unique function 
such that 
(i) For x in B, %(x) = h(x); 
(ii) For x , y in C, 
Viewed algebraically, the conclusion of this theorem says that any 
map h of B into V can be extended to a homomorphism h from C (with 
operations f and g) into V (with operations F and G). 
If the content of the recursion theorem is not immediately apparent, 
try looking at it chromatically. You want to have a function h that paints 
each member of C some color. You have before you 
1. h, telling you how to color the initial elements in B; 
2. F, which tells you how to combine the color of x and y to obtain 
the color off (x, y) (i.e., it gives h( f (x, y)) in terms of h(x) and h(y)); 

40 
A Mathematical Introduction to Logic 
3. G, which similarly tells you how to convert the color of x into the 
color of g (x). 
The danger is that of a conflict in which, for example, F is saying 
"green" but G is saying "red" for the same point (unlucky enough to 
be equal both to f (x, y) and g(z) for some x, y , z). But if C is freely 
generated, then this danger is avoided. 
EXAMPLES. Consider again the examples of the preceding subsection. 
1. B = (0) with one operation, the successor operation S. 
Then C is the set N of natural numbers. Since the successor oper- 
ation is one-to-one and 0 is not in its range, C is freely generated 
from (0) by S. Therefore, by the recursion theorem, for any set 
V,anya E V,andany F :  V + ~thereisauniqueg: 
N +  V 
such that z(0) = a and Z(S(X)) = ~ ( h ( x ) )  
for each x E N. 
For example, there is a unique 5 : N + N such that x(0) = 0 
- 
and %(S(x)) = 1 - h(x). This function has the value 0 at even 
numbers and the value 1 at odd numbers. 
2. The integers are generated from (0) by the successor and 
predecessor operations but not freely generated. 
3. Freeness fails also for the generation of the algebraic func- 
tions in the manner described. 
4. The wffs are freely generated from the sentence symbols by 
the five formula-building operations. This fact is implicit in the 
parsing algorithm of the preceding section; we now want to focus 
on it here: 
UNIQUE 
READABILITY THEOREM The five formula-building operations, 
when restricted to the set of wffs, 
(a) Have ranges that are disjoint from each other and from the 
set of sentence symbols, and 
(b) Are one-to-one. 
In other words, the set of wffs isfreely generated from the set 
of sentence symbols by the five operations. 
PROOF. TO show that the restriction of EA is one-to-one, suppose 
that 
where a, B, y, and S are wffs. Delete the first symbol of each 
sequence, obtaining 
Then we must have a! = y , lest one be a proper initial segment of 
the other (in contradiction to Lemma 13B). And then it follows at 

Chapter 1 : Sentential Logic 
4 1 
once that /3 = 6. The same argument applies to Ev, E, , and E, ; 
for E, a simpler argument suffices. 
A similar line of reasoning tells us that the operations have 
disjoint ranges. For example, if 
where a, #J, y, and S are wffs, then as in the above paragraph 
we have a = y. But that implies that A = --', contradicting 
the fact that our symbols are distinct. Hence EA and E, 
(when 
restricted to wffs) have disjoint ranges. Similarly for any two 
binary connectives. 
The remaining cases are simple. If ( l a )  = (#J A y), then 
/3 begins with 1 ,  which no wff does. No sentence symbol is a 
sequence of symbols beginning with (. 
-I 
Now let us return to the question of extending a truth assignment v 
to ii. First consider the special case where v is a truth assignment for 
the set of all sentence symbols. Then by applying the unique readability 
theorem and the recursion theorem we conclude that there is a unique 
extension ii to the set of all wffs with the desired properties. 
Next take the general case where v is a truth assignment for a set S 
of sentence symbols. Thk set S generated from S by the five formula- 
building operations is freely generated, as a consequence of the unique 
readability theorem. So by the recursion theorem there is a unique ex- 
tension ii of v to that set, having the desired properties. 
EXAMPLE. We can appl~the 
recursion theorem to establish that there 
is a unique function h defined on the set of wffs such that 
- 
- h (A) = 1 for a sentence symbol A, 
- h((l a)) = 3 + %(a), 
h((a A PI) = 3 + %(a) + Z(/3), 
and similarly for V, +, and *. This function gives the length of 
each wff. 
PROOF 
OFTHE RECURSION THEOREM. Theideaistolethbetheunion 
of many approximating functions. Temporarily call a function v 
(which maps part of C into V) acceptable if it meets the conditions 
imposed on 
by (i) and (ii). More precisely, v is acceptable iff 
the domain of v is a subset of C, the range a subset of V, and for 
any x and y in C: 
(it) If x belongs to B and to the domain of v, then v (x) = h (x). 
(ii') If f (x, y) belongs to the domain of v, then so do x and y, 
and v (f (x , y )) = F (v(x) , v (y)). If g (x) belongs to the domain 
of v, then so does x , and v (g (x)) = G (v (x)). 

A Mathematical Introduction to Lonic 
Let K be the collection of all acceptable functions, and let h = 
(J K, the union of all the acceptable functions. Thus 
(x, Z) E h iff 
(x, Z) belongs to some acceptable v 
iff 
v (x) = z for some acceptable v. 
We claim that h meets our requirements. The argument is set- 
theoretic, and comprises four steps. First, here is an outline of 
four steps: 
1. We claim that h is a function (i.e., that it is single-valued). 
Let 
S = {X E C I for at most one z, (x, z) E h) 
= {x E C I all acceptable functions defined at x agree 
there] 
It is easy to verify that S is inductive, by using (if) and (ii'). Hence 
S = C and h is a function. 
2. We claim that 5 E K ;  i.e., that 5 itself is an acceptable 
function. This follows fairly easily from the definition of 5 and 
the fact that it is a function. 
3. We claim that h is defined throughout C. It suffices to show 
that the domain of is inductive. It is here that the assumption of 
freeness is used. For example, one case is the following: Suppose 
that x is in the domain of h. Then h; (g(x), ~ ( h ( x ) ) )  
is accept- 
able. (The freeness is required in showing that it is acceptable.) 
Consequently, g(x) is in the domain of x. 
4. We claim that 5 is unique. For given two such functions, 
let S be the set on which they agree. Then S is inductive, and so 
equals C. 
I 
Now for the details. 
1. As above, let 
S = {X E C I for at most one z, (x, z) E h] 
= {x E C I all acceptable functions defined at x agree there] 
Toward showing that S is inductive, first consider some x in B. 
Suppose that vl and v2 are acceptable functions defined at x; we 
seek to show that vl(x) = v2(x). But condition (it) tells us that 
both vl (x) and v2 (x) must equal h(x), so indeed vl (x) = v2 (x). 
This shows that x E S; since x was an arbitrary member of B we 
have B 5 S. 
Secondly we must check that S is closed under f and g. So 
suppose that some x and y are in S ;  we ask whether f (x, y) is in 
S. So suppose that vl and v2 are acceptable functions defined at 

Chapter 1 : Sentential Logic 
43 
f (x, y); we seek to show that they agree there. But condition (ii') 
tells us that Vljf (x, Y)) = F(v1(x), v~(Y)) 
and ~ 2 ( f  
(x, Y)) = 
F(v2(x), v2(y)). And because x and y are in S, we have vl (x) = 
v2(x) and vl (y) = v2(y) (and these are defined). So we conclude 
that vl(f (x, y)) = v2(f (x, y)). This shows that f(x, y) E S. 
Hence S is closed under f. A similar argument shows that S is 
closed under g . 
Thus S is inductive and so S = C. This shows that & is single- 
valued, i.e., is a function. Because Z includes every acceptable 
function as a subset, we can say that 
whenever v is an acceptable function and x E dom v. 
2. We claim that % is acceptable. Clearly domh 
C and 
rang 5 V (by (*)), and we have just verified that Z is a function. 
It remains to check that h satisfies conditions (it) and (ii'). 
First we examine (if). Assume x E B and x E dom A (so that 
(X , Z(X)) E a). There must be some acceptable v with v (x) = h(x). 
Because v satisfies (it), we have v(x) = h(x) whenceZ(x) = h(x). 
So h satisfies (it). 
Secondly we examine (ii'). Assume that f (x, y) E dom h. 
Again there must be some acceptable v with v(f (x, y)) = 
- 
h(f (x, y)). Because v satisfies (ii'), we have v(f (x, y))= 
F (v(x), v(y)). Now h(x) = v(x) and h(y) = v(y) and hence 
In a similar way, we find that Z(g(x)) = G(Z(x)) whenever 
g(x) E domx. Hence Z meets condition (ii') and so is accept- 
able. 
3. Next we must show that domg is inductive. First consider 
a point x in B. Then the set {(x, h(x))) is a (small) acceptable 
function. For it clearly satisfies (if). It also satisfies (ii') because 
x 4 ran fc and x 4 ran gc. Thus { (x, h (x))) is acceptable and 
therefore is included in g. Hence x E domx. This shows that 
3 s dam%. 
We further claim that domg is closed under f and g. Toward 
this end, consider any s and t in dom Z. We hope that f (s, t) E 
domg. But if not, then let 
the result of adding this one additional pair to %. It is clear that v is 
a function, dom v 2 C, and ran v 5 V. We claim that v satisfies 
(it) and (ii'). 

44 
A Mathematical Introduction to Logic 
First take (i'). If x E B n dorn v then x # f (s, t), by freeness. 
- 
Hence x E dorn h and we have v (x) = h (x) = h (x) . 
Next take (ii'). Assume that f (x, y) E dorn v for some x and 
- 
y in C. If f(x, y) E domh then v(f(x, y)) = h(f (x,y)) = 
F (h(x) , h ( ~ ) )  = F (v (x), v (y )) since h is acceptable. The other 
possibility is that f (x, y) = f (s, t). Then by freeness we have 
x = s and y = t, and we know that these points are in domh s 
dorn v. By construction, 
Finally suppose that g(x) E dom v for x in C. Then by freeness 
we have g(x) # f (s, t). Hence g (x) E domx, and consequently 
v(g(x>> = Z(g(x)) = G ( W )  = G(v(x)). 
Thus v is acceptable. But that tells us that v s h, so that 
f (s, t) E dorn i; after all. 
A similar argument shows that dorn h is closed under g as well. 
Hence dorn h is inductive and therefore coincides with C. 
4. To show that 5 is unique, suppose that g1 and52 both satisfy 
the conclusion of the theorem. Let S be the set on which they agree: 
Then it is not hard to verify that S is inductive. Consequently 
S = C andhl = $2. 
-I 
One final comment on induction and recursion: The induction prin- 
ciple we have stated is not the only one possible. It is entirely possible to 
give proofs by induction (and definitions by recursion) on the length of 
expressions, the number of places at which connective symbols occur, 
etc. Such methods are inherently less basic but may be necessary in 
some situations. 
Exercises 
1. Suppose that C is generated from a set B = {a, b] by the binary 
operation f and unary operation g. List all the members of C2. How 
many members might C3 have? C4? 
2. Obviously (A3 -+ /\Ad is not a wff. But prove that it is not a wff. 
3. We can generalize the discussion in this section by requiring of 3 
only that it be a class of relations on U. C, is defined as before, 
except that (xa, xl , . . . , x, ) is now a construction sequence provided 
thatforeachi _( n wehaveeitherxi E Bor (xh, . . . , ~ j ~ , ~ i )  
E R 
for some R E 3 and some jl, . . . , jk all less than i. Give the correct 
definition of C* and show that C* = C,. 

Chapter 1 : Sentential Logic 
45 
SECTION 1.5 
Sentential Connectives 
We have thus far employed five sentential connective symbols. Even 
in the absence of a general definition of "connective," it is clear that 
the five familiar ones are not the only ones possible. Would we gain 
anything by adding more connectives to the language? Would we lose 
anything by omitting some we already have? 
In this section we make these questions precise and give some an- 
swers. First consider an informal example. We could expand the lan- 
guage by adding a three-place sentential connective symbol #, called 
the majority symbol. We allow now as a wff the expression (#orSy) 
whenever a ,  /3, and y are wffs. In other words, we add a sixth formula- 
building operator to our list: 
Then we must give the interpretation of this symbol. That is, we must 
say how to compute W((#aB y )), given the values v(a), T(/?), and v(y). 
We choose to define 
V((#a/3 y )) is to agree with the majority of B(a), iJ(B), V(y). 
We claim that this extension has gained us nothing, in the following 
precise sense: For any wff in the extended language, there is a tauto- 
logically equivalent wff in the original language. (On the other hand, 
the wff in the original language may be much longer than the wff in 
the extended language.) We will prove this (in a more general situa- 
tion) below; here we just note that it relies on the fact that (#My) is 
tautologically equivalent to 
(We note parenthetically that our insistence that iJ((#olBy)) be cal- 
culable from @(a), iJ(B), iJ( y )) plays a definite role here. In everyday 
speech, there are unary operators like "it is possible that" or "I believe 
that." We can apply one of these operators to a sentence, producing a 
new sentence whose truth or falsity cannot be determined solely on the 
basis of the truth or falsity of the original one.) 
In generalizing the foregoing example, the formal language will be 
more of a hindrance than a help. We can restate everything using only 
functions. Say that a k-place Booleanfunction is a function from {F, T ) ~  
into {F, T ) .  (A Boolean function is then anything which is a k-place 
Boolean function for some k. We stretch this slightly by permitting 
F and T  the~selves to be 0-place Boolean functions.) Some sample 

46 
A Mathematical Introduction to Loaic 
Boolean functions are defined by the equations (where X iz {F, TI) 
From a wff a we can extract a Boolean function. For example, if a 
is the wff Al A A2, then we can make a table, Table V. The 22 lines 
of the table correspond to the 22 truth assignments for {Al, A2]. For 
each of the 22 pairs 2, we set B.(W equal to the truth value a receives 
when its sentence symbols are given the values indicated by 2. 
TABLE V 
In general, suppose that a is a wff whose sentence symbols are at 
most A1, . . . , A,. We define an n-place Boolean function B: 
(or just 
B, if n seems unnecessary), the Boolean function realized by a ,  by 
B: (XI, . . . , X,) = the truth value given to a when 
A ,  . . . , A 
are given the values XI, . . . , X, . 
Or, in other words, B: (XI, . . . , X,) = T(a), where v is the truth as- 
signment for {Al, . . . , A,] for which v(Ai) = Xi. Thus B: comes from 
looking at T(a) as a function of v, with a fixed. 
For example, the Boolean functions listed previously are obtainable 
in this way: 
= 
+A2 9 
E = Bil *A2. 
From these functions we can compose others. For example, 

Chapter 1 : Sentential Logic 
4 7 
(The right-hand side of this equation can be compared with the result of 
putting 1 
Al V 1 
A2 into Polish notation.) We will shortly come to the 
question whether every Boolean function is obtainable in this fashion. 
As the theorem below states, in shifting attention from wffs to the 
Boolean functions they realize, we have in effect identified tautologi- 
cally equivalent wffs. Impose an ordering on {F, T] by defining F c T. 
(If F = 0 and T = 1, then this is the natural order.) 
THEOREM 
15A 
Let a and /3 be wffs whose sentence symbols are 
among A1, . . . , A,. Then 
(a) a t /3 iff for all 2 E {F, TIn, ~ ~ ( 2 )  
9 ~ ~ ( 2 ) .  
(b) a 
/3 iff B, = Bg. 
(c) + a iff B, is the constant function with value T. 
PROOF OF (A). a + /3 iff for all 2" truth assignments v for Al, . . . , 
An, whenever v(a) = T, then also U(/3) = T. (This is true even if 
the sentence symbols in a and /3 do not include all of A1, . . . , A,; 
cf. Exercise 6 of Section 1.2.) Thus 
a + /3 iff for all 2" assignments v, U(a) = T + V(/3) = T, 
ifff0rall2~n-tuples?, 
B;(?)=T&?~;(%)=T, 
iff for all 2" n-tuples 2 ,  
B," (2) 5 B;(z), 
where F < T. 
In addition to identifying tautologically equivalent wffs, we have 
freed ourselves from the formal language. We are now at liberty to 
consider any Boolean function, whether it is realized by a wff or not. 
But this freedom is only apparent: 
THEOREM 15B Let G be an n-place Boolean function, n > 1. We 
can find a wff a such that G = B,", i.e., such that a realizes the 
function G. 
The primary reason for introducing Boolean functions is to allow us 
to formulate this theorem. The theorem was stated by Ernil Post in 192 1. 
PROOF. Case I: G is the constant function with value F. Let a = 
Al A l A l .  
Case II: Otherwise there are k points at which G has the value 
T, k > 0. List these: 

48 
A Mathematical Introduction to Logic 
Let 
k = {A' 
iff xij = T, 
( 1  A,) 
iff Xi, = F, 
Yi = bil A ... A bin, 
a! =yi v y 2 v . ' . v y k .  
We claim that G = B:. 
At this point it might be helpful to consider a concrete example. 
Let G be the three-place Boolean function as follows: 
Then the list of triples at which G assumes the value T has four 
members: 
F F T  i A 1  A i A 2  AA3, 
F T F  i A 1  AA2 A i A 3 ,  
T F F  
A1 A 7 A 2  A i A 3 ,  
TTT 
A1AA2AA3. 
To the right of each triple above is written the corresponding 
conjunction yi . Then a! is the formula 
( l A 1  A i A 2  AA3) V ( i A 1  AA2 A i A 3 ) V  
(A1 A i A 2 A i A 3 ) V ( A 1  AA2AA3). 
Notice how a! lists explicitly the triples at which G assumes the 
value T. 
To return to the proof of the theorem, note first that B: (h 
= T 
(For the truth assignment corresponding to Xi 
hence satisfies a.) On the other hand, only one 
for {Al, . . . , An 1 can satisfy yi, whence only k 
can satisfy a. Hence 
= F for the 
n u s  in all cases, B: (F) = G(?). -I 
From this theorem we know that every Boolean function is realiz- 
able. Of course the a! that realizes G is not unique; any tautologically 
equivalent wff will also realize the same function. It is metimes of 
interest to choose a to be as short as possible. (In the example done 
above, the wff 
also realizes G.) 

Chapter 1 : Sentential Logic 
49 
As a corollary to the above theorem, we may conclude that we have 
enough (in fact, more than enough) sentential connectives. For suppose 
that we expand the language by adding some exotic new sentential con- 
nectives (such as the majority connective discussed at the beginning of 
this section). Any wff p of this expanded language realizes a Boolean 
function B;. By the above theorem we have a wff a of the original lan- 
guage such that B; = B,". Hence p and a are tautologically equivalent, 
by Theorem 15A. 
In fact, the proof shows that a can be of a rather special form. For 
one thing, the only sentential connective symbols in a are A, V, and 
1. Furthermore, a is in so-called disjunctive normal fonn (abbreviated 
DNF). That is, a is a disjunction 
where each yi is a conjunction 
and each Bij is a sentence symbol or the negation of a sentence symbol. 
(The advantages of wffs in disjunctive normal form stem from the fact 
that they explicitly list the truth assignments satisfying the formula.) 
Thus we have the consequence: 
COROLLARY 
15C 
For any wff p, we can find a tautologically equiv- 
alent wff a in disjunctive normal form. 
Because every function G : {F, T)" + {F, T) for n > 1 can be 
realized by a wff using only the connective symbols in {A, V, l ) ,  we 
say that the set {A, V, 1) 
is complete. (Actually the completeness is 
more a property of the Boolean functions K, A, and N that correspond to 
these symbols. But the above terminology is convenient.) Once we have 
a complete set of connectives, we know that any wff is tautologically 
equivalent to one all of whose connectives are in that set. (For given any 
wff p, we can make a using those connectives and realizing Bp. Then 
a ++ p.) The completeness of {A, V, 1) 
can be improved upon: 
THEOREM 
1 5D Both (1, A) and (1, V) are complete. 
PROOF. We must show that any Boolean function G can be realized 
by a wff using only, in the first case, (1, 
A). We begin with a wff a 
using { i ,  A, V) thatrealizes G. It suffices to find a tautologically 
equivalent a' that uses only (1, A}, For this we use De Morgan's 
law: 
By applying this repeatedly, we can completely eliminate V 
from a. 

50 
A Mathematical Introduction to Logic 
(More formally, we can prove by induction on a that there is a 
tautologically equivalent a' in which only the connectives A, 1 
occur. Two cases in the inductive step are 
Case 1: If a is ( 1  /3), then let a' be ( 1  B'). 
Case V: If a is (/3 V y), then let a' be 1 
( 1  /3' A i yf). Since 
/3' and y ' are tautologically equivalent to /3 and y , respectively, 
a' = 1 ( 1 / 3 ' A l  yf) 
+=I l ( l B  
+=I B V Y  
- 
- a. 
In future proofs that a set of connectives is complete, this induction 
will be omitted. Instead we will just give, for example, the method 
of simulating V by using 1 
and A. 
-I 
Showing that a certain set of connectives is not complete is usually 
more difficult than showing that one is complete. The basic method is 
first to show (usually by induction) that for any wff a using only those 
connectives, the function B: has some peculiarity, and secondly to show 
that some Boolean function lacks that peculiarity. 
EXAMPLE. {A, +] is not complete. 
PROOF. The idea is that with these connectives, if the sentence sym- 
bols are assigned T, then the entire formula is assigned T. In 
particular, there is nothing tautologically equivalent to 1 
A. 
In more detail, we can show by induction that for any wff a 
using only these connectives and having A as its only sentence 
symbol, we have A + a .  (In terms of functions, this says that 
B: (T) = T .) The same argument shows that {A, V, +, *} 
is 
not complete. 
-I 
For each n there are 22n n-place Boolean functions. Hence if we iden- 
tify a connective with its Boolean function (e.g., A with the function K 
mentioned before), we have 22n n-ary connectives. We will now catalog 
these for n 5 2. 
-. 
0-ary Connectives 
There are two 0-place Boolean functions, F and T. For the correspond- 
ing connective symbols we take I and T. Now an n-ary connective 
symbol combines with n wffs to produce a new wff. When n = 0, we 
have that I is a wff all by itself. It differs from the sentence symbols in 
that U(I) = F for every v ;  i.e., I is a logical symbol always assigned 
the value F. Similarly, T is a wff, and U(T) = T for every v ,  Then, for 
example, A + I is a wff, tautologically equivalent to 1 
A, as can be 
seen from a two-line truth table. 

Chapter 1 : Sentential Logic 
5 1 
Unary Connectives 
There are four unary connectives but only one of any interest. The 
interesting case is negation. The other three one-place Boolean functions 
are the identity function and the two constant functions. 
Binary Connectives 
There are 16 binary connectives, but only the last 10 listed in Table VI 
are "really binary." 
TABLE VI 
Symbol 
Equivalent 
T 
I 
A 
B 
1 A  
1 B  
AAB 
AVB 
A --+ B 
A-B 
A t B  
( A v B ) A ~ ( A A B )  
-(A VB) 
i(AAB) 
Remarks 
two-place constant, essentiauy 0-ary 
tweplace constant, essentially 0-ary 
projection, essentially unary 
projection, essentially unary 
negation, essentially unary 
negation, essentially unary 
and; if F = 0 and T = 1, then this gives 
multiplication in the field (0,l) 
or (inclusive) 
conditional 
biconditional 
reversed conditional 
exclusive or, "A or B and not both"; if 
F = 0 and T = 1, then this gives the 
usual addition (modulo 2) in the 
field (0, 1) 
nor, "neither A nor B" 
nand, "not both A and B"; the symbol is 
called the Sheffer stroke 
the usual ordering, where F < T 
the usual ordering, where F c T 
Ternary Cohnectives 
There are 256 ternary connectives; 2 are essentially 0-ary, 6 (= 2 (i)) 
are essentially unary, and 30 (= 10 - (:)) are essentially binary. This 
leaves 218 that are really ternary. We have thus far mentioned only 
the majority connective #. There is, similarly, the minority connective. 
In Exercise 7 we encounter +3, ternary addition modulo 2. +3a/3y is 
assigned the value T iff an odd number of a ,  /3, and y are assigned 
T. This formula is equivalent both to a + /3 +-to 
a * 
/3 * y . 
Another ternary connective arises in Exercise 8. 

52 
A Mathematical Introduction to Logic 
EXAMPLE. {I) and { J) are complete. 
PROOF. For I 
Since { l ,  V) is complete and 1, 
V can be simulated using only 
I, we conclude that {I) is complete. 
-I 
EXAMPLE. 
(1, +) is complete. In fact, of the 10 connectives that 
are really binary, eight have the property of forming, when added 
to 1 ,  a complete set, The two exceptions are + and *; see 
Exercise 5. 
EXAMPLE. { I ,  -+) is complete. In fact, because with this set we can 
realize even the two 0-place Boolean functions, it is supercorn- 
plete. 
Exercises 
1. Let G be the following three-place Boolean function. 
(a) Find a wff, using at most the connectives V, A, and 1 ,  that 
realizes G. 
(b) Then find such a wff in which connective symbols occur at not 
more than five places. 
2. Show that I and J. are the only binary connectives that are complete 
by themselves. 
3. Show that {i, 
#) is not complete. 
4. Let M be the ternary minority connective. (Thus $(Map y) always 
disagrees with the majority of u(a), 'iS(B), and i?(y).) Show the 
following: 
(a) { M, I )  is complete. 
(b) {M) is not complete. 
5. Show that {T, I ,  1 ,  *, +) is not complete. 'Suggestion: Show that 
any wff a using these connectives and the sentence symbols A and 
B has an even number of T's among the four possible values of 
- 
v(a>. 
Remark: Another approach uses the algebra of the field (0, 1). 
Any Boolean function realizable with these connectives has a cer- 
tain linearity property. 

Chapter 1 : Sentential Logic 
5 3 
6. Show that {A, *, +} is complete but that no proper subset is com- 
plete. 
7. Let +3 be the ternary connective such that +3a#l y is equivalent to 
~ + B + Y .  
(a) Show that {T, I ,  A, +3) is complete. 
(b) Show that no proper subset is complete. 
Remark: +3 is the ternary parity connective; the condition for 
- 
v(+alaza3) = T is that T(ai) = T for an odd number of i's. 
+ is the binary parity connective. The function G in the proof of 
Theorem 15B is the 3-place parity function. 
8. Let I1 be the ternary connective such that IIaB y is assigned the value 
T iff exactly one of the formulas a ,  B, y is assigned the value T. 
Show that there are no binary connectives o and A such that IIaB y 
is equivalent to (a o #I) n y . 
9. Say that a formula a is in conjunctive normal form (abbreviated 
CNF) iff it is a conjunction 
where each yi is a disjunction 
and each Bij is either a sentence symbol or the negation of a sentence 
symbol. 
(a) Find a formula in conjunctive normal form that is tautologically 
equivalent to A * B * C. 
(b) Show that for any formula, we can find a tautologically equiv- 
alent formula in conjunctive normal form. 
10. Add the 0-place connectives T, I to our language. For each wff 
p and sentence symbol A, let pq be the wff obtained from p by 
replacing A by T. Similarly for pf . Then let p t  = (p$ V pf). 
Prove the following: 
(a) v + v t .  
(b) If p + $ and A does not appear in $, then p t  + $. 
(c) The formula p is satisfiable iff p t  is satisfiable. 
Remarks: We can think of p t  as trying to say everything p says, 
but without being able to use the symbol A. Parts (a) and (b) state 
that p t  is the strongest A-free consequence of p. The formulas (p 
and p t  are not tautologically equivalent in general, but they are 
"equally satisfiable" by part (c). The operation of forming p t  from 
p is (in another context) called resolution on A. 
1 1. (Interpolation theorem) If a + /3, then there is some y all of whose 
sentence symbols occur both in a and in #I and such that a + y .+ 
#I. Suggestion: Use the preceding exercise. 

54 
A Mathematical Introduction to Logic 
Remarks: There is an analogue of Exercise 11 that holds for first- 
order logic. But the proof in that case is very different, because there 
is no analogue of Exercise 10. 
12. Is the set {A, T, I} 
complete? Support your answer. 
SECTION 1.6 
Switching Circuits' 
Consider an electrical device (traditionally a black box) having n inputs 
and one output (Fig. 1). Assume that to each input we apply a signal 
having one of two values and that the output has one of two values. The 
two possible values we call F and T. (We could also define the F value 
as 0 potential and choose the unit of potential so that the T value has 
potential I.) Further assume that the device has no memory; i.e., the 
present output level depends only on the present inputs (and not on past 
history). Then the performance of the device is described by a Boolean 
function: 
G(X1, . . . , X,) = the output level given the input signalsX1, . . . , X,. 
Figure 1. Electrical device with three inputs. 
Devices meeting all these assumptions constitute an essential part of 
digital-computer circuitry. There is, for example, the two-input AND 
gate, for which the output is the minimum of the inputs (where F < T). 
This device realizes the Boolean function K of the preceding section. 
It is convenient to attach the labels Al and A2 to the inputs and to label 
the output Al A A2. 
Similar devices can be made for other sentential connectives. For a 
two-input OR gate (Fig. 2) the output voltage is the maximum of the in- 
put voltages. Corresponding to the negation connective there is the NOT 
device (or inverter), whose output voltage is the opposite of the input 
voltage. 
A circuit can be constructed from various devices of this sort. And it 
is again natural to use wffs of our formal language to label the voltages 
This section, which discusses an application of the ideas of previous sections, may be 
omitted without loss of continuity. 

Chaater 1 : Sentential Logic #I
Figure 2. OR gate. 
at different points (Fig. 3). Conversely, given the wff thus attached to 
the output, we can approximately reconstruct the circuit, which looks 
very much like the tree of the wff's formation. 
Figure 3. Circuit with wffs as labels. 
A, 
i 
7 
A2 
- 
For example, the circuit for 
((A A B) A D) V ((A A B) A i 
C) 
AND 
would probably be as shown in Fig. 4. Duplication of the circuit for 
A A B would not usually be desirable. 
. A1 A A2 
- 
>- 
& 
- 
Figure 4. Circuit for ((A A B) A D) V ((A A B) A 1C). 
OR 
D 
- 
* 
Tautologically equivalent wffs yield circuits having ultimately the 
- 
1 
As 
(A1 A As) V l A ,  
AND 
L 
A3 
- 
OR 
- 
7 
- - 
A 
- 
B
-
 
NOT 
AND 
C 
r NOT - 
L - - 
AND 
f 

56 
A Mathematical Introduction to Logic 
same performance, although possibly at different cost and (if the devices 
are not quite instantaneous in operation) different speed. Define the 
delay (also called the depth) of a circuit as the maximum number of 
boxes through which the signal can pass in going from an input to the 
output. The corresponding notion for formulas is conveniently defined 
by recursion. 
1. The delay of a sentence symbol is 0. 
2. The delay of 1 
a! is one greater than the delay of a. 
3. The delay of a! AB is one greater than the maximum of the delay 
of a! and the delay of #I. 
And similarly for any other connective. 
For example, the circuit of (Al A A2) V 1 
A3 uses three devices and 
has a delay of 2. The tautologically equivalent formula 1 
(Ag A (1 
A1 V 
1 
A2)) gives a circuit having five devices and a delay of 4. The problem 
facing many a computer engineer can be stated: Given a circuit (or its 
wff), find an equivalent circuit (or a tautologically equivalent wff) for 
which the cost is a minimum, subject to constraints such as a maximum 
allowable delay. For this problem there is some catalog of available 
devices; for example, she might have available 
NOT, two-input AND, three-input OR. 
(It is clearly desirable that the available devices correspond to a com- 
plete set of connectives.) The catalog of devices determines a formal 
language, having a connective symbol for each device. 
EXAMPLE 1. Inputs: A, B, C. Output: To agree with the majority of 
A, B, and C. Devices available: two-input OR, two-input AND. 
One solution is 
((AAB) v (AAC)) v (BAC), 
which uses five devices and has a delay of 3. But a better solution 
is 
(AA(B V C)) V (BAC), 
which uses four devices and has the same delay. Furthermore, 
there is no solution using only three devices; cf. Exercise 1. 
EXAMPLE 2. 
Inputs: A and B. Output: T if the inputs agree, F oth- 
erwise; i.e., the circuit is to test for equality. Device available: 
two-input NOR. One solution is 
This uses five devices; is there a better solution? And there is 

Chapter 1 : Sentential Logic 
57 
the deeper question: Is there an efficient procedure for finding a 
minimal solution? These are questions that we merely raise here. 
In recent years a great deal of work has gone into investigating 
questions of this type. 
EXAMPLE 3. (Relay switching) Inputs: A, 1 
A, B, 1 
B, . . . Devices: 
OR (any number of inputs), AND (any number of inputs). Cost: 
Devices are free, but each use of an input costs one unit. To test 
for equality of A and B we could use 
The wiring diagram for the circuit is shown in Fig. 5. The circuit 
will pass current iff A and B are assigned the same value. (This 
formula, equivalent to A * 
B, has the property that its truth value 
changes whenever the value of one argument changes. For this 
reason, the circuit is used, with double-throw switches, in wiring 
hallway lights.) 
Figure 5. Wiring diagram for (A A B) V (1A A +). 
But there is one respect in which relay circuits do not fit the 
description given at the beginning of this section. Relays are bilat- 
eral devices; they will pass current in either direction. This feature 
makes "bridge" circuits possible (Fig. 6). The methods described 
here do not apply to such circuits. 
Figure 6. Bridge circuit. 

58 
A Mathematical Introduction to Logic 
EXAMPLE 4. There are four inputs, and the circuit is to realize the 
Boolean function G, where G is to have the value T at (F, F, F, 
T), (F, F, T, F), (F, F, T, T), (F, T, F, F), (F, T, F, T), (F, T, 
T, F), (F,T,T,T), and (T, F, F,T). G is to have the value 
F at (T, F, F, F), (T, F, T, F), (T, T, F, F), (T, T, T, F), and 
(T, T, T, T). At the remaining three points, (F, F, F, F), (T, F, 
T, T), and (T, T, F, T), we don't care about the value of G. (The 
application of the circuit is such that these three combinations 
never occur.) 
We know that G can be realized by using, say, { A ,  V, 1). 
But 
we want to do this in an efficient way. The first step is to repre- 
sent the data in a more comprehensible form. We can do this by 
means of Fig. 7. Since G(F, F, F, T) = T, we have placed a T in 
the square with coordinates (1 
A, 1 
B, 1 
C, D). Similarly, there 
is an F in the square with coordinates (A, B, -I C, 1 
D) because 
G(T, T, F, F) = F. The three squares we do not care about are 
left blank. 
L
-
B
-
I
-
B
d
-
B
J
 
Figure 7. Diagram for Example 4. 
Now we look for a simple geometrical pattern. The shaded area 
includes all T's and no F's. It corresponds to the formula 
which is reasonably simple and meets all our requirements. Note 
that the input B is not needed at all. 

Chapter 1 : Sentential Logic 
59 
Exercises 
1. In Example 1 of this section, verify that there is no solution using 
only three devices. 
2. Define a literal to be a wff which is either a sentence symbol or the 
negation of a sentence symbol. An implicant of (p is a conjunction 
a of literals (using distinct sentence symbols) such that a + (p. We 
showed in Section 1.5 (cf. Corollary 15C) that any satisfiable wff (p 
is tautologically equivalent to a disjunction a1 V . . . Vcl, where each 
ai is an implicant of (p. An implicant a of (p is prime iff it ceases to be 
an implicant upon the deletion of any of its literals. Any disjunction 
of implicants equivalent to p clearly must, if it is to be of minimum 
length, consist only of prime implicants. 
(a) Find all prime implicants of 
(b) Which disjunctions of prime implicants enjoy the property of 
being tautologically equivalent to the formula in part (a)? 
3. Repeat (a) and (b) of Exercise 2, but for the formula 
SECTION 1.7 
Compactness and Effectiveness 
Compactness 
We now give a proof of the compactness theorem mentioned earlier 
(Section 1.2). Call a set C of wffs satisfiable iff there is a truth assign- 
ment that satisfies every member of C . 
COMPACTNESS 
THEOREM A set of wffs is satisfiable iff every finite 
subset is satisfiable. 
Let us temporarily say that C is finitely satisfiable iff every finite 
subset of C is satisfiable. Then the compactness theorem asserts that 
this notion coincides with satisfiability. Notice that if C is satisfiable, 
then automatically it is finitely satisfiable. Also if C is finite, then the 
converse is trivial. (Every set is a subset of itself.) The nontrivial part is 
to show that if an infinite set is finitely satisfiable, then it is satisfiable. 
PROOF 
OF THE COMPACTNESS 
THEOREM. The proof consists of two dis- 
tinct parts. In the first part we take our given finitely satisfiable 
set C and extend it to a maximal such set A. In the second part 
we utilize A to make a truth assignment that satisfies C. 

60 
A Mathematical Introduction to Logic 
For the first part let a1, a2, . . . be a fixed enumeration of the 
wffs. (This is possible since the set of sentence symbols, and hence 
the set of expressions, is countable; see Theorem OB.) Define by 
recursion (on the natural numbers) 
A,; a,+l 
if this is finitely satisfiable, 
An+l = An ; 1 
+ 
otherwise. 
(Recall that A,; a,+l = A, U {an+l}.) Then each A, is finitely 
satisfiable; see Exercise 1. Let A = U, A,, the limit of the An's. 
It is clear that (1) C E A and that (2) for any wff a either 
a! E A or ( 1  a )  E A. Furthermore, (3) A is finitely satisfiable. 
For any finite subset is already a finite subset of some A, and 
hence is satisfiable. 
This concludes the first part of the proof; we now have a set 
A having properties (1)-(3). There is in general not a unique 
such set, but there is at least one. (An alternative proof of the 
existence of such a A a n d  one that we can use even if there are 
uncountably many sentence symbols -employs Zom's lemma. 
The reader familiar with uses of Zom's lemma should perceive 
its applicability here.) 
For the second part of the proof we define a truth assignment 
v for the set of all sentence symbols: 
v(A)= T iff 
A E A 
for any sentence symbol A. Then for any wff p, we claim that 
v satisfies p iff p E A. 
This is proved by induction on p; see Exercise 2. Since C E A, 
v must then satisfy every member of C. 
-I 
COROLLARY 
17A If C t= 
t ,  then there is a finite Co E C such that 
x o  I= 
t. 
PROOF. We use the basic fact that C t= t iff C ; 1 
t is unsatisfiable. 
Co k t for every finite Co & C 
=+ Co; 1 
t is satisfiable for every finite 
Co E C 
=+ C ;  1 
t is finitely satisfiable 
=+ C ;  i 
t is satisfiable 
* C k t .  
In fact, the above corollary is equivalent to the compactness theorem; 
see Exercise 3. 

Chapter 1 : Sentential Logic 
6 1 
Effectiveness and computability 
Although the method of truth tables is rather cumbersome to use, the 
existence of the method yields interesting theoretical conclusions. Sup- 
pose we ask of a set X of wffs whether or not there is an effective 
procedure that, given a wff t , will decide whether or not X + t . By an 
effective procedure we mean one meeting the following conditions: 
1. There must be exact instructions (i.e., aprogram) explaining how 
to execute the procedure. The instructions must be finite in length. After 
all, it must be possible to give the instructions to the person or machine 
doing the calculations, and one cannot give someone all of an infinite 
object. But we impose no upper limit in advance on exactly how long 
the instructions can be. If there are more lines in the instructions than 
there are electrons in the universe, we merely shrug and say, "That's a 
pretty long program." 
2. These instructions must not demand any brilliance or originality 
on the part of the person or machine following them. The idea is that a 
diligent clerk (who knows no mathematics but is very good at following 
directions) or your computing machine (which does not think at all) 
should be able to execute the instructions. That is, it must be possible 
for the instructions to be mechanically implemented. The procedure 
must avoid random devices (such as the flipping of a coin), or any such 
device that can, in practice, only be approximated. 
3. In the case of a decision procedure, as asked for above, the pro- 
cedure must be such that, given a wff t, after a finite number of steps 
the procedure produces a "yes" or "no" answer. (That is, the procedure 
must be an algorithm for determining the answer.) 
On the other hand, we place no bound in advance on the amount of 
time that might be required before the answer appears. Nor do we place 
any advance bound on the amount of scratch paper (or other storage 
medium) that might be required. These will depend on, among other 
things, the input t. But for any one t ,  the procedure is to require only a 
finite number of steps to produce the answer, and so only a finite amount 
of scratch paper will be consumed. It is no fair doing an infinite number 
of steps and then giving the answer. 
People with a digital computing machine may regard a procedure as 
being effective only when it can be carried out on their machine in a 
"reasonable" length of time. Of course, the matter of what is reasonable 
may change with the circumstances. Next year they plan to get a faster 
machine with more memory. At that time, their idea of what can be done 
in a reasonable length of time will be considerably extended. We want 
here a concept of effective procedure that is the limiting case where 
all the practical restrictions on running time and memory space are 
removed. 

62 
A Mathematical Introduction to Logic 
Of course the foregoing description can hardly be considered a pre- 
cise definition of the word "effective." And, in fact, that word will be used 
only in an informal intuitive way throughout this book. (In Chapter 3 
we will meet a precise counterpart, "recursive.") But as long as we 
restrict ourselves to positive assertions that there does exist an effective 
procedure of a certain sort, the informal approach suffices. We simply 
display the procedure, show that it works, and people will agree that it 
is effective. (But this relies on the empirical fact that procedures which 
appear effective to one mathematician also appear so to others.) If we 
wanted a negative result, that there did not exist an effective procedure 
of a certain sort, then this informal viewpoint would be inadequate. (In 
Chapter 3 we do want to obtain just such negative results.) Because the 
notion of effectiveness is informal, definitions and theorems involving 
it will be marked with a star. For example: 
*THEOREM 
17B There is an effective procedure that, given any ex- 
pression E, will decide whether or not it is a wff. 
PROOF. See the algorithm in Section 1.3 and the footnotes thereto. 
-I 
There is one technical point here, stemming from the fact that our lan- 
guage has infinitely many different sentence symbols. When we speak 
of being "given" an expression E, we imagine that someone might write 
down the symbols in E, one after the other. It is implausible that anyone 
has the potential of writing down any one of an infinitude of symbols. 
To avoid this, we adopt the following "input/output format": Instead of 
writing down As, for example, we use A"", a string of five symbols. 
Now the total number of symbols in our alphabet is only nine: 
(If we identify these nine symbols with the digits 1-9, we get expressions 
that look particularly familiar in computational settings! And we still 
have the 0 digit for separating expressions.) 
Theorem 17B states that the set of wffs is decidable in the sense of 
the following definition: 
*DEFINITION. 
A set C of expressions is decidable iff there exists 
an effective procedure that, given an expression a, will decide 
whether or not a E C. 
For example, any finite set is decidable. (The instructions can simply 
list the finitely many members of the set. Then the algorithm can check 
the input against the list.) Some infinite sets are decidable but not all. 
On the one hand, there are uncountably many (2Ko, to be exact) sets 
of expressions. On the other hand, there can be only countably many 
effective procedures. This is because the procedure is completely deter- 

Chapter 1 : Sentential Logic 
63 
mined by its (finite) instructions. There are only KO finite sequences of 
letters, and the instructions, when written out, form a finite sequence of 
letters. 
*THEOREM 
1 7C There is an effective procedure that, given a finite 
set C; t of wffs, will decide whether or not C 
t. 
PROOF. The truth-table procedure (Section 1.2) meets the require- 
ment. 
-I 
In this theorem we specified that C; t was finite, since one cannot 
be "given" in any direct and effective way all of an infinite object. 
'COROLLARY 
17D For a finite set C, the set of tautological conse- 
quences of C is decidable. In particular, the set of tautologies is 
decidable. 
If C is an infinite set - 
even a decidable one - 
then in general its set 
of tautological consequences may not be decidable. (See Chapter 3.) But 
we can obtain a weaker result, which is in a sense half of decidability. 
Say that a set A of expressions is efectively enumerable iff there 
exists an effective procedure that lists, in some order, the members of 
A. If A is infinite, then the procedure can never finish. But for any 
specified member of A, it must eventually (i.e., in a finite length of 
time) appear on the list. 
To give more of a feeling for this concept, we now state an equivalent 
way of formulating it. 
*THEOREM 
17E A set A of expressions is effectively enumerable iff 
there exists an effective procedure that, given any expression E ,  
produces the answer "yes" iff E E A. 
If E 4 A, the procedure might produce the answer "no"; more likely 
it will go on forever without producing any answer, but it must not 
lie to us and produce the answer "yes." Such a procedure is called a 
semidecision procedure -it is half of a decision procedure: 
*DEFINITION. A set A of expressions is semidecidable iff there exists 
an effective procedure that, given any expression E, produces the 
answer "yes" iff E E A. 
Thus Theorem 17E states that a set is effectively enumerable iff it is 
semidecidable. 
PROOF. If A is effectively enumerable, then given any E we can 
examine the listing of A as our procedure chums it out. If and 
when E appears, we say "yes." (Thus if E $ A, no answer is ever 
given. It is this that keeps A from being decidable. When E has 
failed to occur among the first 10'' enumerated members of A, 
there is in general no way of knowing whether E 4 A -in which 

64 
A Mathematical Introduction to Logic 
case one should give up looking - 
or whether E will occur in the 
very next step.) 
Conversely, suppose that we have the procedure described 
in the theorem. We want to create a listing of A. The idea is 
to enumerate all expressions, and to apply our given procedure to 
each. But we must budget our time sensibly. It is easy enough to 
enumerate effectively all expressions: 
Then proceed according to the following scheme: 
1. Spend one minute testing ~ 1 ,  
for membership in A (using 
the given procedure). 
2. Spend two minutes testing EI, then two minutes testing 82. 
3. Spend three minutes testing ~ 1 ,  
three minutes testing ~ 2 ,  
and 
three minutes testing ~ 3 .  
And so forth. Of course whenever our procedure produces a 
"yes" answer, we put the accepted expression on the output list. 
Thus any member of A will eventually appear on the list. (It 
will appear infinitely many times, unless we modify the above 
instructions to check for duplication.) 
-I 
Clearly any decidable set is also semidecidable. (We get a semide- 
cision procedure even if the "no" bulb has burned out.) Hence any 
decidable set is effectively enumerable. 
*THEOREM 
17F A set of expressions is decidable iff both it and its 
complement (relative to the set of all expressions) are effectively 
enumerable. 
PROOF. Exercise 8. This result is sometimes called "Kleene's 
theorem." 
-I 
Observe that if sets A and B are effectively enumerable, then so are 
A U B and A r\ B (Exercise 11). The class of decidable sets is also 
closed under union and intersection, and it is in addition closed under 
complementation. 
Now for a more substantive result: 
*THEOREM 
17C If C is a decidable set of wffs, then the set of tau- 
tological consequences of C is effectively enumerable. 
PROOF. Actually it is enough for C to be effectively enumerated; 
consider an enumeration 

Chapter 1 : Sentential Logic 
65 
Given any wff t ,  we can test (by truth tables) successively whether 
or not 
and so forth. If any of these conditions is met, then we answer 
"yes." Otherwise, we keep trying. 
This does produce an affirmative answer whenever C I= t ,  by 
the corollary to the compactness theorem. 
-I 
Later on, we will want to use effective procedures to compute func- 
tions. We will say that a function f is efectively computable (or simply 
computable) iff there exists an effective procedure that, given an input 
x ,  will eventually produce the correct output f (x). 
Exercises 
1. Assume that every finite subset of C is satisfiable. Show that the 
same is true of at least one of the sets C; a and C; 1 
a. (This is 
part of the proof of the compactness theorem.) Suggestion: If not, 
then El; a and C2; 1 
a are unsatisfiable for some finite C1 & C 
and C2 E C. Look at C1 U C2. 
2. Let A be a set of wffs such that (i) every finite subset of A is 
satisfiable, and (ii) for every wff a, either a E A or ( 1  a) E A. 
Define the truth assignment v: 
v(A) = T iff A E A ,  
F iff A $ A  
for each sentence symbol A. Show that for every wff p, F((p) = T 
iff p E A. (This is part of the proof of the compactness theorem.) 
Suggestion: use induction on p. 
3. Show that from the corollary to the compactness theorem we can 
prove the compactness theorem itself (far more easily than we can 
starting from scratch). 
4. In 1977 it was proved that every planar map can be colored with 
four colors. Of course, the definition of "map" requires that there 
be only finitely many countries. But extending the concept, sup- 
pose we have an infinite (but countable) planar map with countries 
C1, C2, C3, . - . . Prove that this infinite planar map can still be col- 
ored with four colors. (Suggestion: Partition the sentence symbols 
into four parts. One sentence symbol, for example, can be used to 
translate, "Country C7 is colored red." Form a set C1 of wffs that 
say, for example, C7 is exactly one of the colors. Form another set 

66 
A Mathematical Introduction to Logic 
C2 of wffs that say, for each pair of adjacent countries, that they 
are not the same color. Apply compactness to C1 U C2.) 
5. Where C is a set of wffs, define a deduction from C to be a finite 
sequence (ao, . . . , a,) of wffs such that for each k 5 n, either (a) 
a k  is a tautology, (b) a k  E X, or (c) for some i and j less than k, ai 
is (a, + ark). (In case (c), one. says that a k  is obtained by modus 
ponens from ai and aj.) Give a deduction from the set 
the last component of which is P. 
6. Let (ao, . . . , an) be a deduction from a set C of wffs, as in the 
preceding problem. Show that X + a k  for each k 5 n. Suggestion: 
Use strong induction on k, so that the inductive hypothesis is that 
C + ai for all i < k. 
7. Show that whenever C b t ,  then there exists a deduction from 
C, the last component of which is t . Remark: This result is called 
' b ~ ~ m p l e t e n e ~ ~ ~ ~ ;  
the concepts in Exercises 5-7 will reappear in 
Section 2.4. 
8. Prove Theorem 17F. Remark: Two semidecision procedures make 
a whole. 
*9. The concepts of decidability and effective enumerability can be 
applied not only to sets of expressions but also to sets of integers 
or to sets of pairs of expressions or integers. Show that a set A of 
expressions is effectively enumerable iff there is a decidable set B 
of pairs (a, n) (consisting of an expression a and an integer n) such 
that A = dom B. 
10. Let C be an effectively enumerable set of wffs. Assume that for each 
wff t ,  either E + t or X + 1 t. Show that the set of tautological 
consequences of C is decidable. 
(a) Do this where "or" is interpreted in the exclusive sense: either 
X b t or X + -I t but not both. 
(b) Do this where "or" is interpreted in the inclusive sense: either 
C + t o r  C + ltorboth. 
11. (a) Explain why the union of two effectively enumerable sets is 
again effectively enumerable. 
(b) Explain why the intersection of two effectively enumerable sets 
is again effectively enumerable. 
12. For each of the following conditions, give an example of an unsat- 
isfiable set 
of formulas that meets the condition. 
(a) Each member of F is -by 
itself - 
satisfiable. 
(b) For any two members yl and fi of F, the set {yl, M} is satisfi- 
able. 
(c) For any three members y ~ ,  
)EZ, and y3 of F, the set { yl, fi, B} 
is satisfiable. 


68 
A Mathematical Introduction to Loaic 
TABLE VII 
Formal expression 
Intended translation 
"Zero." Here 0 is a constant symbol, intended to 
name the number 0. 
"The successor oft ." Here S is a one-place function 
symbol. t is to be an expression that names some 
number a. Then St names S(a), the successor of a. 
For example, SO is intended to name the number 1. 
"vl is less than Pf;?' Here < is a two-place predicate 
symbol. At the end of Section 2.1 we will adopt 
conventions letting us abbreviate the expression in 
the more usual style: vl < ~f;?. 
"For every natural number." The symbol V is the 
universal quantifier symbol. More generally, with 
each translation of the language into English there 
will be associated a certain set A (the so-called uni- 
verse); V will then become "for every member of 
the universe A:' 
"For every natural number vl , zero is less than vl ." 
Or more euphoniously, "Every natural number is 
larger than 0." This formal sentence is false in the 
intended translation, since zero is not larger than 
itself. 
One abbreviation is mentioned in Table VII. There will be more 
(Table VIII). 
Actually we will not be quite as generous as the tables might suggest. 
There are two economy measures that we can take to obtain simplifica- 
tion without any essential loss of linguistic expressiveness: 
First, we choose as our sentential connective symbols just 1 
and +. 
We know from Section 1.5 that these form a complete set, so there is no 
compelling reason to use more. 
Secondly, we forego the luxury of an existential quantifier, 3 x. In its 
place we use 1 Vx 1. 
This is justified, since an English sentence like 
There is something rotten in the state of Denmark, 
is equivalent to 
It is not the case that for every x, x is not rotten in the state 
of Denmark. 
Thus the formula 3 vl V q vl = q becomes, in unabbreviated form, 

Chapter 2: First-Order Logic 
69 
TABLE Vlll 
-- 
Abbreviated expression 
Intended translation 
"x equals y." In unabbreviated form this will 
become =xy. 
"There exists a natural number v such that." Or 
more generally, "there exists a member of the 
universe such that." 
"There is exactly one natural number." Again 
this formal sentence is false in the intended 
translation. 
Vvl(0 < VI VO = vl) 
"Every natural number is greater than or equal 
to zero." 
For an example in an ad hoc language, we might translate "Socrates 
is a man" as Hs, where H is a one-place predicate symbol intended 
to translate "is a man" and s is a constant symbol intended to name 
Socrates. Similarly, to translate "Socrates is mortal" we take Ms. Then 
"All men are mortal" is translated as V vl(Hvl + Metl). 
The reader will possibly recognize the symbols V and 3 from previ- 
ous mathematical contexts. Indeed, some mathematicians, when writing 
on the blackboard during their lectures, already use a nearly formalized 
language with only vestigial traces of English. That our first-order lan- 
guages resemble theirs is no accident. We want to be able to take one 
step back and study not, say, sets or groups, but the sentences of set 
theory or group theory. (The term metamathematics is sometimes used; 
the word itself suggests the procedure of stepping back and examining 
what the mathematician is doing.) The objects you, the logician, now 
study are the sentences that you, the set theoretician, previously used in 
the study of sets. This requires formalizing the language of set theory. 
And we want our formal languages to incorporate the features used in, 
for example, set theory. 
SECTION 2.1 
Fi rst-Order Languages 
We assume henceforth that we have been given infinitely many distinct 
objects (which we call symbols), arranged as follows: 
A. Logical symbols 
0. Parentheses: ( , ). 
1. Sentential connective symbols: +, 1. 

70 
A Mathematical Introduction to Logic 
2. Variables (one for each positive integer n): 
3. Equality symbol (optional): =. 
B. Parameters 
0. Quantifier symbol: V. 
1. Predicate symbols: For each positive integer n, some set (pos- 
sibly empty) of symbols, called n-place predicate symbols. 
2. Constant symbols: Some set (possibly empty) of symbols. 
3. Function symbols: For each positive integer n, some set (pos- 
sibly empty) of symbols, called n-place function symbols. 
In A.3 we allow for the possibility of the equality symbol's being 
present, but we do not assume its presence. Some languages will have 
it and others will not. The equality symbol is a two-place predicate 
symbol but is distinguished from the other two-place predicate symbols 
by being a logical symbol rather than a parameter. (This status will affect 
its behavior under translations into English.) We do need to assume that 
some n-place predicate symbol is present for some n. 
In B .2, the constant symbols are also calledO-place function symbols. 
This will often allow a uniform treatment of the symbols in B.2 and B.3. 
As before, we assume that the symbols are distinct and that no symbol 
is a finite sequence of other symbols. 
In order to specify which language we have before us (as distinct 
from other first-order languages), we must (i) say whether or not the 
equality symbol is present, and (ii) say what the parameters are. 
We now list some examples of what this language might be: 
1. Pure predicate language 
Equality: No. 
n-place predicate symbols: A;, A;, . . . . 
Constant symbols: al, a*, . . . . 
n-place function symbols (n > 0): None. 
2. Language of set theory 
Equality: Yes (usually). 
Predicate parameters: One two-place predicate symbol E. 
Function symbols: None (or occasionally a constant symbol 0). 
3. Language of elementary number theory (as in Chapter 3) 
Equality: Yes. 
Predicate parameters: One two-place predicate symbol <. 
Constant symbols: The symbol 0. 

Chapter 2: 
First-Order Logic 
7 1 
One-place function symbols: S (for successor). 
Two-place function symbols: + (for addition), (for multiplication), 
and E (for exponentiation). 
In examples 2 and 3 there are certain intended translations of the 
parameters. We will presently give a number of examples of sentences 
that can be translated into these languages and a few examples of sen- 
tences that cannot be so translated. 
It is important to notice that our notion of language includes the 
language for set theory. For it is generally agreed that, by and large, 
mathematics can be embedded into set theory. By this is meant that 
(a) Statements in mathematics (such as the fundamental theorem of 
calculus) can be expressed in the language of set theory; and 
(b) The theorems of mathematics follow logically from the axioms 
of set theory. 
Our model of first-order logic is fully adequate to mirror this procedure. 
EXAMPLES in the language of set theory. Here it is intended that V 
should mean "for all sets" and E should mean "is a member of." 
1. 'There is no set of which every set is a member." We will 
translate this into the language of set theory using several steps. 
The intermediate sentences are neither in English nor in the formal 
language but are in a mixed language. 
 there is a set of which every set is a member] 
1 
3 vl [Every set is a member of vl] 
13vlV'Q'@ E Vl 
Although it is tempting to stop here, we must now replace q E vl 
by EZ)LV~, since predicate symbols will always go at the left in 
such contexts. Furthermore, 3 vl must be replaced by 1 
V vl 1, 
as mentioned earlier. And we must use the correct number of 
parentheses. The finished product is 
2. Pair-set axiom: "For any two sets, there is a set whose mem- 
bers are exactly the two given sets." Again we carry out the trans- 
lation in stages. 
V vl V Z)L [There is a set whose members are exactly vl and 
~121 
V vl V q 3 % [The members of Q are exactly vl and q ]  
Vv1v'f&3~Vv4(v4 
E v3 f)v4=vl V v 4 = q )  
Now we replace 3 u3 by 1 
V u3 1 ,  v4 E v3 by ~v4u3, and v4 = vi 
by =v4vi. In addition, we must eliminate t, and A in favor of 
our chosen connectives + and 1. Thus 
a V # ?  becomes l q + # ? ;  
a + #? becomes 1 
((a + #?) + 1 
(#? + a)). 

72 
A Mathematical Introduction to Logic 
The finished product is 
The finished product is not nearly as pleasant to read as the ver- 
sion that preceded it. As we have no interest in deliberately making 
life unpleasant for ourselves, we will eventually adopt conventions 
allowing us to avoid seeing the finished product at all. But for the 
moment it should be regarded as an interesting, even if unattractive, 
novelty. 
EXAMPLES in the language of elementary number theory. Here it is 
intended that V should mean "for all natural numbers" and that 
<, 0, S, +, *, and E should have the obvious meanings. 
1. As a name for the natural number 2 we have the term SSO, 
since 2 is the successor of the successor of zero. Similarly, for 4 
we have the term SSSSO. For the phrase "2 + 2" it is tempting to 
use SSO + SSO. But we will adopt the policy of always putting 
the function symbol at the left (i.e., we will use Polish notation 
for function symbols). Thus corresponding to the English phrase 
"2 + 2" we have the term + SSO SSO. The English sentence "%o 
plus two is four" is translated as 
= + SSOSSOSSSSO. 
(The spaces are inserted to help the reader, but they do not con- 
stitute an official feature of the language.) 
2. "Any nonzero natural number is the successor of some num- 
ber." We will perform the translation in three steps: 
V VI [ If vl is nonzero, then vl is the successor of some number.] 
v Vl ( ( 1  =vlO) + ( 1  v Q ( 1  =vl SQ))). 
3. "Any nonempty set of natural numbers has a least element." 
This cannot be translated into our language, because we cannot 
express "any . . . set." This requires either something like the (first- 
order) language for set theory or a second-order language for 
number theory. We could, however, translate, "The set of primes 
has a least element." (The first step is to convert this sentence into, 
"There is a smallest prime." We leave the other steps to the reader; 
hints can be found in the next section.) 
EXAMPLES in ad hoc languages 
1. "All apples are bad." 

Chapter 2: 
First-Order Logic 
73 
2. "Some apples are bad." 
Intermediate step: 3 vl (Awl A Bvl). 
Finished product: (1 
V  v l ( i  (1 (Avl + (1 Bvl))))). 
These two examples illustrate patterns that arise continually. 
An English sentence which asserts that everything in a certain 
category has some property is translated 
A sentence which asserts that there is some object or objects in 
the category and having the property is translated 
The reader should be cautioned against confusing the two pat- 
terns. For example, 
translates "Everything is an apple and is bad," which is a much 
stronger assertion than the sentence in the first example. Similarly, 
3 vl (Awl + B v l )  translates "There is something which is bad, if 
it is an apple." This is a much weaker assertion than the sentence 
in the second example. It is true (vacuously) even if all apples are 
good, provided only that the world has something which is not an 
apple. 
3. "Bobby's father can beat up the father of any other kid on 
the block." Establish a language in which V  is intended to mean 
"for all people," Kx is to mean "x is a kid on the block," b  is to 
mean "Bobby," Bxy is to mean "x can beat up y," and f  x is to 
mean "the father of x." Then a translation is 
V v 1 ( K v l  + ( ( i = v l b )  + Bfbf ~ 1 ) ) .  
4. In calculus, we learn the meaning of "the function f  con- 
verges to L as x approaches a": 
This is, apart from notational matters, a formula of the sort we 
are interested in, using a predicate symbol for ordering, function 
symbols for f ,  subtraction, and absolute values, and constant 
symbols for 0, a, and L. 
Formulas 
An expression is any finite sequence of symbols. Of course most ex- 
pressions are nonsensical, but there are certain interesting expressions: 
the terms and the wffs. 

74 
A Mathematical Introduction to Logic 
The terms are the nouns and pronouns of our language; they are the 
expressions that can be interpreted as naming an object. The atomic 
formulas will be those wffs having neither connective nor quantifier 
symbols. 
wffs 
The terms are defined to be those expressions that can be built up 
from the constant symbols and the variables by prefixing the function 
symbols. To restate this in the terminology of Chapter 1, we define for 
each n-place function symbol f , an n-place term-building operation 3f 
on expressions: 
terms 
DEFINITION. 
The set of t e r n  is the set of expressions that can be 
built up from the constant symbols and variables by applying (zero 
or more times) the Ff operations. 
, 
other 
wffs 
atomic 
formulas 
If there are no function symbols (apart from the constant symbols), 
then the terms are just the constant symbols and the variables. In this 
case we do not need an inductive definition. 
Notice that we use Polish notation for terms by placing the function 
symbol at the left. The terms do not contain parentheses or commas. We 
will later prove a unique readability result, showing that given a term, 
we can unambiguously decompose it. 
The terms are the expressions that are translated as names of objects 
(noun phrases), in contrast to the wffs which are translated as assertions 
about objects. 
Some examples of terms in the language of number theory are 
all other 
expressions 
+wSO, 
sssso, 
+EvlSSO EqSSO. 
The atomic formulas will play arole roughly analogous to that played 
by the sentence symbols in sentential logic. An atomic formula is an 
expression of the form 
Ptl ..-t,,, 
where P is an n-place predicate symbol and tl, . . . , t, are terms. 
For example, =vlq is an atomic formula, since = is a two-place 
predicate symbol and each variable is a term. In the language of set 
theory we have the atomic formula E V S ~ .  

Chapter 2: First-Order Logic 
75 
Notice that the atomic formulas are not defined inductively. In- 
stead we have simply said explicitly just which expressions are atomic 
formulas. 
The well-formed formuhs are those expressions that can be built up 
from the atomic formulas by use (zero or more times) of the connective 
symbols and the quantifier symbol. We can restate this in the terminol- 
ogy of Chapter 1 by first defining some formula-building operations on 
expressions: 
DEFINITION. 
The set of well-formedformulas (wffs, or justformulas) 
is the set of expressions that can be built up from the atomic 
formulas by applying (zero or more times) the operations C,, 
E,,andQi 
(i = 1,2, ...). 
For example, on the one hand, 1 
v3 is not a wff. (Why?) On the other 
hand, 
Q v l ( ( l Q % ( l  =wl)) 
+(lQ'02(~'02~1+ 
(7vv4(~~4'02 
+ ( 1 
~v4~1)))))) 
is a wff, as is demonstrated by the foilowing tree: 

76 
A Mathematical Introduction to Logic 
But it requires some study to discover that this wff is the axiom of 
regularity for set theory. 
Free Variables 
Two examples of wffs are VQEQV~ and ( 1  V v l ( i V  QEQV~)). But 
there is an important difference between the two examples. The second 
might be translated back into English as 
There is a set such that every set is a member of it. 
The first example, however, can be translated only as an incomplete 
sentence, such as 
Every set is a member of 
, . 
We are unable to complete the sentence without knowing what to do 
with vl. In cases of this sort, we will say that vl occurs free in the wff 
V Q E Q V ~ .  In contrast, no variable occurs free in ( 1  V v l ( l  V Q EQV~)). 
But of course we need a precise definition which does not refer to 
possible translations to English but refers only to the symbols 
themselves. 
Consider any variable x. We define, for each wff a ,  what it means 
for x to occurfree in a. This we do by recursion: 
1. For atomic a, x occurs free in a iff x occurs in (i.e., is a symbol 
of) a. 
2. x occurs free in ( 1  a )  iff x occurs free in a. 
3. x occurs free in (a + /3) iff x occurs free in a or in /3. 
4. x occurs free in V Vi a iff x occurs free in a and x # vi . 
This definition makes tacit use of the recursion theorem. We can 
restate the situation in terms of functions. We begin with the function h 
defined on atomic formulas: 
h (a) = the set of all variables, if any, in the atomic formula a. 
And we want to extend h to a function h defined on all wffs in such a 
way that 
- 
- h(E,(a)) = a a ) ,  
h(E+(a, B)) = h(a) U h(/3), 
- 
h ( Qi (a)) = h(a) after removing vi , if present. 
Then we say that x occurs free in a (or that x is a free variable of a )  iff x E 
- 
h (a). The existence of a unique such h (and hence the meaningfulness 
of our definition) follows from the recursion theorem of Section 1.4 
and from the fact (proved in Section 2.3) that each wff has a unique 
decomposition. 

Chapter 2: 
First-Order Logic 
77 
If no variable occurs free in the wff ar (i.e., if h(a) = a), then ar is a 
sentence. (The sentences are intuitively the wffs translatable into English 
without blanks, once we are told how to interpret the parameters.) 
For example, V %(A% + B%) and V v3(P2)3 4 V Q QQ) are sen- 
tences, but vl occurs free in ( V vl Avl 4 B vl). The sentences are usually 
the most interesting wffs. The others lead a second-class existence; they 
are used primarily as building blocks for sentences. 
In translating a sentence from English, the choice of particular vari- 
ables is unimportant. We earlier translated "All apples are bad" as 
V vl (Avl 4 Bvl). We could equally well have used 
The variable is, in effect, used as a pronoun, just as in English we might 
say, "For any object whatsoever, if it is an apple, then it is bad." (We 
have incorporated into our language an adequate supply of pronouns: 
itl, itz, . . . .) Since the choice of particular variables is unimportant, 
we will often not even specify the choice. Instead we will write, for 
example, Vx(Ax 4 Bx), where it is understood that x is some variable. 
(The unimportance of the choice of variable will eventually become a 
theorem.) 
Similar usages of variables occur elsewhere in mathematics. In 
i is a "dummy" variable but j occurs free. 
On Notation 
We can specify a wff (or indeed any expression) by writing a line that 
displays explicitly every symbol. For example, 
But this way of writing things, while splendidly complete, may not 
be readily comprehensible. The incomprehensibility can be blamed (in 
part) on the simplifications we wanted in the language (such as the lack 
of an existential quantifier symbol). We naturally want to have our cake 
and eat it too, so we now will agree on methods of specifying wffs in 
more indirect but more readable ways. These conventions will let us 
write a line such as 
to name the same wff as is named by the other line above. 
Note well that we are not changing our definition of what a wff is. 
We are simply conspiring to fix certain ways of naming wffs. In the 
(rare) cases where the exact sequence of symbols becomes important, 

78 
A Mathematical Introduction to Logic 
we may have to drop these new conventions and revert to primitive 
notation. 
We adopt then the following abbreviations and conventions. Here a 
and #? are formulas, x is a variable, and u and t are terms. 
( a  V #?) abbreviates ( ( 1  a )  + #?). 
( a  A #?) abbreviates ( 1 ( a  + ( 1 #?))). 
( a  or t,) abbreviates ((a + 8 )  A ( p  + a)); i.e., 
( l ((a + #?I + ( l (B + a)))). 
3 x a abbreviates ( 1  
V x (  1 
a)). 
u = t abbreviates =ut. A similar abbreviation applies to some other 
two-place predicate and function symbols. For example, 2 < 3 abbre- 
viates <2 3 and 2 + 2 abbreviates +2 2. 
u # t abbreviates ( 1  =ut); similarly u $ t abbreviates ( 1 
<ut). 
For parentheses we will use not only ( and ) but also [ and 1, etc. And 
we omit mention of just as many as we possibly can. Toward that end 
we adopt the following conventions: 
1. Outermost parentheses may be dropped. For example, V x a + p 
is ( V x a  + #?). 
2. 1, 
V, and 3 apply to as little as possible. For example, 
l a  A#? is ( ( l a ) A # ? ) ,  andnot 
l ( a A / ? ) ;  
V x a + # ?  is ( V x a + # ? ) ,  
andnot Vx(a+#?); 
3 x a A # ?  is ( 3 x a A # ? ) ,  andnot 3 x ( a A # ? ) .  
In suchcases we might even addgratuitousparentheses, as in (3 x a)A#?. 
3. A and V apply to as little as possible, subject to item 2. For 
example, 
4. When one connective is used repeatedly, the expression is grouped 
to the right. For example, 
EXAMPLES of how we can eliminate abbreviations, rewriting the for- 
mula in an unabbreviated way that explicitly lists each symbol in 
order: 
1. 3 x(Ax A Bx) is ( 1  V x (  1 
( 1 
(Ax + ( 1  Bx))))). 
But ( 1  V x(Ax + ( 1  Bx))) would be an equivalent formula (in any 
reasonable notion of equivalence). 
2. 3 x Ax + Bx is ( ( 1  V x ( 1  Ax)) + Bx). 
3 x(Ax + Bx) is ( 1  V x (  1 
(Ax + Bx))). 
We will try to use the various alphabets in a systematic way. The 
system is listed below, but there will be occasional exceptions for special 
reasons. 

Chapter 2: First-Order Logic 
79 
Predicate symbols: Uppercase italic letters. Also E, <. 
Variables: Vi, U ,  V ,  X, y, Z. 
Function symbols: f, g , h. Also S, +, etc. 
Constant symbols: a, b, . . . . Also 0. 
Terms: u, t. 
Formulas: Lowercase Greek letters. 
Sentences: a, t. 
Sets of formulas: Uppercase Greek letters, plus certain italic letters 
that pretend to be Greek, viz., A (alpha) and T (tau). 
Structures (see the next section): Uppercase German (Fraktur) letters. 
Exercises 
1. Assume that we have a language with the following parameters: 
V, intended to mean "for all things"; N, intended to mean "is a 
number"; I ,  intended to mean "is interesting"; <, intended to mean 
"is less than"; and 0, a constant symbol intended to denote zero. 
Translate into this language the English sentences listed below. If 
the English sentence is ambiguous, you will need more than one 
translation. 
(a) Zero is less than any number. 
(b) If any number is interesting, then zero is interesting. 
(c) No number is less than zero. 
(d) Any uninteresting number with the property that all smaller 
numbers are interesting certainly is interesting. 
(e) There is no number such that all numbers are less than it. 
(f) There is no number such that no number is less than it. 
2. With the same language as in the preceding exercise, translate back 
into good English the wff 
Vx(Nx + Zx + i 
Vy(Ny + Zy + i 
x < y)). 
In 3-8, translate each English sentence into the first-order lan- 
guage specified. (You may want to carry out the translation in several 
steps, as in some of the examples.) Make full use of the notational 
conventions and abbreviations to make the end result as readable 
as possible. 
3. Neither a nor b is a member of every set (V, for all sets; E, is a 
member of; a, a; b, b.) 
4. If horses are animals, then heads of horses are heads of animals. 
(V, for all things; E, is a horse; A, is an animal; hx, the head of x.) 
5. (a) You can fool some of the people all of the time. (b) You can 
fool all of the people some of the time. (c) You can't fool all of 
the people all of the time. (V, for all things; P, is a person; T, is a 

80 
A Mathematical Introduction to Logic 
time; Fxy, you can fool x at y. One or more of the above may be 
ambiguous, in which case you will need more than one translation.) 
6. (a) Adams can't do every job right. (b) Adarns can't do any job 
right. (V, for all things; J, is a job; a, Adams; Dxy, x can do y 
right.) 
7. (a) Nobody likes everybody. (b) No Democrat likes every Repub- 
lican. (V, for all people; Lxy, x likes y; D, is a Democrat; R, is a 
Republican.) 
8. (a) Every farmer who owns a donkey needs hay. (b) Every farmer 
who owns a donkey beats it. (V, for all things; F, is a farmer; D, is 
a donkey; Oxy, x owns y; H, needs hay; Bxy, x beats y.) 
9. Give a precise definition of what it means for the variable x to occur 
free as the ith symbol in the wff a. (If x is the ith symbol of a but 
does not occur free there, then it is said to occur bound there.) 
10. Rewrite each of the following wffs in a way which explicitly lists 
each symbol in the actual order: 
(a) 3 vlPvl A Pwl. 
(b) VvlAvl A Bvl + 3 ' & i C ' &  V D q .  
In each case, say which variables occur free in the wff. 
SECTION 2.2 
Truth and Models 
In sentential logic we had truth assignments to tell us which sentence 
symbols were to be interpreted as being true and which as false. In first- 
order logic the analogous role is played by structures, which can be 
thought of as providing the dictionary for translations from the formal 
language into English. (Structures are sometimes called interpretations, 
but we prefer to reserve that word for another concept, to be encountered 
in Section 2.7.) 
A structure for a first-order language will tell us 
1. What collection of things the universal quantifier symbol (V) 
refers to, and 
2. What the other parameters (the predicate and function symbols) 
denote. 
Formally, astructure !2l for our given first-order language is a function 
whose domain is the set of parameters and such that1 
The symbol 'W' is the letter A in the German (Fraktur) alphabet. The next two letters 
are 13 and C. 

Chapter 2: 
Fi rst-Order Logic 
8 1 
1. 8 assigns to the quantifier symbol V a nonempty set IMI called 
the universe (or domain) of 8. 
2. 8 assigns to each n-place predicate symbol P an n-ary relation 
P
'
 
5 181"; i.e., P
'
 
is a set of n-tuples of members of the universe. 
3. 8 assigns to each constant symbol c a member C
'
 
of the uni- 
verse 181. 
4. 8 assigns to each n-place function symbol f an n-ary operation 
fa on 181; i.e., fa : IIMln + IIMI. 
The idea is that 8 assigns meaning to the parameters. V is to mean 
"for everything in 181." The symbol c is to name the point c
'
.
 
The 
atomic formula Ptl - - - tn is to mean that the n-tuple of points named by 
tl, . . . , tn is in the relation Pa. (We will shortly restate these conditions 
more carefully.) 
Note that we require the universe 181 to be nonempty. Notice also that 
fa must have all of IIMIn in for its domain; we have made no provision 
for partially defined functions. 
EXAMPLE. Consider the language for set theory, whose only param- 
eter (other than b') is E. Take the structure IM with 
IIMI = the set of natural numbers, 
E
'
 
= the set of pairs (m, n) such that m < n. 
(Thus we translate E as "is less than.") In the presence of a structure 
we can translate sentences from the formal language into English 
and attempt to say whether these translations are true or false. The 
sentence of this first-order language 
(or more formally, ( 1  V vl ( 1  V %( 1 
E qvl)))), which under an- 
other translation asserts the existence of an empty set, is now 
translated under 8 into 
There is a natural number such that no natural number 
is smaller, 
which is true. Because of this we will say that 3 x Vy 1 
y E x is 
true in IM, or that IM is a model of the sentence. On the other hand, 
IM is not a model of the pair-set axiom, 
as the translation of this sentence under 8 is false. For there is no 
natural number m such that for every n, 
n < m  iff n =  1. 
(The reader familiar with axiomatic set theory can check that IM 

82 
A Mathematical Introduction to Logic 
is a model of the extensionality axiom, the union axiom, and the 
axiom of regularity.) 
EXAMPLE. Again assume the language has only the parameters V 
and a two-place predicate symbol E; But this time, consider the 
finite structure B with universe IBl consisting of a set of four 
distinct objects {a, b, c, d). Suppose the binary relation EB is the 
following set of pairs: 
EB = {(a, b), (b, a), (b, 4 ,  (c, c)}. 
Then we'can picture B as the directed graph whose vertex-set is 
the universe {a, b, c, d}: 
Here we interpret Exy as saying there is an edge from vertex x to 
vertex y in the graph. (If the binary relation EB had been symmetric, 
then we could have pictured the structure as an undirected graph.) 
Consider now the sentence 3 x V y 7 
y Ex. Under the structure 
B ,  we can translate this as follows: 
There is a vertex such that for any vertex, 
no edge points from the latter to the former. 
(The English version is harder to read than the symbolic one!) This 
sentence is true in B, because no edge points to the vertex d. 
In the preceding examples it was intuitively pretty clear that certain 
sentences of the formal language were true in the structure and some 
were false. But we want a precise mathematical definition of "a is true 
in %." This should be stated in mathematical terms, without employing 
translations into English or a supposed criterion for asserting that some 
English sentences are true while the others are false. (If you think you 
have such a criterion, try it on the sentence "This sentence is false.") In 
other words, we want to take our informal concept of "a is true in 2l" 
and make it part of mathematics. 
In order to define "a is true in %," 
for sentences a and structures %, we will find it desirable first to define 
a more general concept involving wffs. Let 
p be a wff of our language, 
!2l a structure for the language, 

Chapter 2: 
First-Order Logic 
83 
s : V + IQI a function from the set V of all variables into the universe 
IQI of Q. 
Then we will define what it means for Q to satisfy cp with s, 
The informal version is 
cp[s] if and only if the translation of cp determined by Q, where 
the variable x is translated as s (x) wherever it occurs free, is true. 
The formal definition of satisfaction proceeds as follows: 
I. Terms. We define the extension 
a function from the set T of all terms into the universe of a. The idea 
is that S(t) should be the member of the universe lQ1 that is named by 
'the term t. 3 is defined by recursion as follows: 
1. For each variable x, S(x) = s (x). 
2. For each constant symbol c, T(c) = c". 
3. If tl, . . . , tn are terms and f is an n-place function symbol, then 
A commutative diagram, for n = 1, is 
81 
If' 
T -  
1%I 
The existence of a unique such extension 3 of s follows from the recur- 
sion theorem (Section 1.4), by using the fact that the terms have unique 
decompositions (Section 2.3). Notice that T depends both on s and on Q. 
(In fact a reasonable alternative notation for T(t) would be t "[s], which 
explicitly displays the dependence on Q.) 
11. Atomic fomulas. The atomic formulas were defined explicitly, 
not inductively. The definition of satisfaction of atomic formulas is 
therefore also explicit, and not recursive. 
1. km =tlt2[s] iff S(tl) = S(t2). 
(Thus = means =. Note that = is a logical symbol, not a parameter 
open to interpretation.) 
2. For an n-place predicate parameter P, 
Ptl . - - tn [s] iff (S(tl), . . . , T(tn)) E pa. 

84 
A Mathematical Introduction to Logic 
In. Other w$s. The wffs we defined inductively, and consequently 
here satisfaction is defined recursively. 
1. For atomic formulas, the definition is above. 
2. +a 
cp[sl iff F" cp[sI. 
3. 
(cp + $)[s] iff either Fa cp[s] or kg $ [s] or both. 
(In other words, if M satisfies cp with s then M satisfies $ with s.) 
4. +a Vxcp[s] iff foreveryd E IMI, wehave 
cp[s(x Id)]. 
Here s (x I d) is the function which is exactly like s except for one thing: 
At the variable x it assumes the value d. This can be expressed by the 
equation 
(Thus V means "for all things in lM1 .") 
At this point the reader might want to reconsider the informal version 
of +a cp[s] on page 83 and observe how it has been formalized. 
We should remark that the definition of satisfaction is another ap- 
plication of the recursion theorem together with the fact that the wffs 
have unique decompositions. The definition can be restated in terms of 
functions to make it clearer how the recursion theorem of Section 1.4 
applies: 
(i) Consider one fixed M. 
(ii) Define a function h (extending a function h defined on atomic 
formulas) such that for any wff cp, h(q) is a set of functions from V 
into IMI. 
(iii) Define 
We leave to the reader the exercise of writing down the explicit 
definition of h and the clauses that uniquely determine its extension 
- 
h. (See Exercise 7.) An elegant alternative is to have x(cp) be a set of 
functions on the set of those variables that occur free in cp. 
EXAMPLE. Assume that our language has the parameters V, P (a two- 
place predicate symbol), f (a one-place function symbol), and c (a 
constant symbol). Let M be the stmc ture fo@is language defined 
as follows: 
IMl = N, 
the set of all natural numbers, 
pa = the set of pairs (m, 
n) such that m 5 n, 
fa = the successor function S; f "(n) = n + 1, 
c" = 0. 
We can summarize this in one line, by suppressing the fact that M 

Chapter 2: 
First-Order Logic 
85 
is really a function and merely listing its components: 
a= (W; 5, S,O). 
This notation is unambiguous only when the context makes clear 
just which components go with which parameters. 
Let s : V + N be the function for which s(vi) = i - 1; i.e., 
s(vl) = 0, s ( 3 )  = 1, and so forth. . 
1. S( f f w) = S(S(2)) = 4 and S( f vl) = S(0) = 1. 
2. S(C) = 0 and S( f f c) = 2; no use is made of s. 
3. ba Pcf vl [s]. This is informally obvious, since when we 
translate back into English we get the true sentence "0 ( 1." More 
formally, the reason is that 
4. Fa V vl Pcvl. The translation into English is "0 is less 
than or equal to any natural number." Formally we must verify 
that for any n in N, 
which reduces to 
i.e., 0 5 n. 
5. Fa V vl PQ vl [s] because there is a natural number m such 
that 
In fact, since s (3) 
= 1, we must take m to be 0. 
The reader is to be cautioned against confusing, for example, 
the function symbol f with thefunction f ". 
EXAMPLE. Previously we considered the structure ?I3 with 
1231 ={a,b,c,dl 
and ~ ~ = { ( a , b ) , ( b , a ) , ( b , c ) , ( c , c ) J  
for the language with parameters V and E: 

86 
A Mathematical Introduction to Logic 
Then ks V Q 1 
E Q V ~  
[s] iff s(vl) = d. That is, there is no 
edge pointing to the vertex d, but d is the only such vertex. Tak- 
ing the negation of the formula, we have +s 3 Q Ewvl [s] iff 
~ ( ~ 1 1  
E {a, b, GI. 
At this point we pause to verify that when we want to know whether 
or not a structure !2l satisfies a wff (p with s, we do not really need all 
of the (infinite amount of) information s gives us. All that matter are 
the values of the function s at the (finitely many) variables which occur 
free in (p. In particular, if (p is a sentence, then s does not matter at all. 
THEOREM 
22A Assume that sl and s2 are functions from V into 
which agree at all variables (if any) that occur free in the wff (p. 
Then 
ka(p[~il iff 
l=a(p[~21. 
PROOF. Because satisfaction was defined recursively, this proof 
uses induction. We consider the fixed structure ??l 
and show by 
induction that every wff (p has the property that whenever two 
functions sl , $2 agree on the variables free in (p then 2l satisfies (p 
with sl iff it does so with $2. 
Case 1: (p = Ptl . . . t,, is atomic. Then any variable in (p occurs 
free. Thus sl and s2 agree at all the variables in each ti. It follows 
that Fl (ti) = Z2 (ti) for each i; a detailed proof would use induction 
on ti. Consequently, !2l satisfies Ptl . . . t,, with sl iff it does so 
with s2. 
Cases 2 and 3: ~q has the form 1 
a! or a! + /?. These cases are 
immediate from the inductive hypothesis. 
Case 4: (p = Vx +. Then the variables free in (p are those free 
in + with the exception of x. Thus for any d in IQI, sl(x I d) and 
s2(x I d) agree at all variables free in +. By inductive hypothesis, 
then, !2l satisfies + with sl (x I d) iff it does so with s2(x I d). From 
this and the definition of satisfaction we see that 2l satisfies Vx + 
with sl iff it does so with s*. 
-I 
In effect, the above proof amounts to looking through the definition 
of satisfaction and seeing what information given by s was actually 
used. There is an analogous fact regarding structures: If !2l and ?I3 agree 
at all the parameters that occur in (p, then 
(p[s] iff 
(p[s]. 
This theorem justifies the followiag notation: Suppose that (p is a 
formula such that all variables occurring free in (p are included among 
vl, . . . , vk. Then for elements al, . . . , ak of 1!?ll, 

Chapter 2: 
First-Order Logic 
87 
means that IM satisfies (o with some (and hence with any) function 
s : V + IIMI for which s(v~) = ai, 1 5 i 5 k. To return to a recent 
example where IM = (N; 5, S, 0), we have Fa V 3 P vl 3 [On but 
Fa v 3  Pvi3%51. 
COROLLARY 
22 B For a sentence a, either 
(a) IM satisfies a with every function s from V into 1!2ll, or 
(b) IM does not satisfy a with any such function. 
If alternative (a) holds, then we say that a is true in !2l (written +a a )  
or that IM is a model of a. And if alternative (b) holds, then of course 
a is false in IM. (They cannot both hold since IIMI is nonempty). IM is a 
model of a set C of sentences iff it is a model of every member of C .  
EXAMPLE. If 
is the real field, (R; 0, 1, +, x), and 12 is the rational 
field, (0; 0, 1, +, x), is there a sentence true in one and false in 
the other? Yes; because fi is irrational, the sentence 3 x (x x = 
1 + 1) is false in the rational field, but true in the real field. 
EXAMPLE. Suppose our given language has only the parameters V 
and P, where P is a two-place predicate symbol. Then a structure 
IM is determined by the universe IIMI and the binary relation pa. 
With some minor illegality we again write 
Now consider the problem of characterizing the class of all models 
of the following sentences: 
1. Vx V y x = y. A structure (A; R) is a model of this iff A 
contains exactly one element. R can either be empty or can be the 
singleton A x A. 
2. Vx V y Pxy. A structure (A; R) is a model of this iff R = 
A x A. A can be any nonempty set. 
3. Vx Vy 1 
Pxy. A structure (A; R) is a model of this iff 
R = 0. 
4. V x 3 y Pxy. The condition for (A; R) to be a model of this 
is that the domain of R is A. 
The notational conventions adopted earlier were done in a ra- 
tional way: 
1. 
(a A #I) [s] iff bra a[s] and +a #I[s]; similarly for V 
and *. 
2, 
3 x a [s] iff there is some d E IIMI with the property that 
+a ~ S ( X  
Id)l. 

88 
A Mathematical Introduction to Logic 
The proof for the second of these is as follows: 
+, 3xc;r[s] iff + m l V ~ l c ; r [ ~ ] ,  
iff 
FBVx1ct[s], 
iff it is not the case that for all d in IBI, 
+GI 1a[s(x Id)], 
iff it is not the case that for all d in IQI, 
k n  ~ S ( X  
Id)l, 
iff for some d in IMI , 
a [s (x I d)]. 
Logical Implication 
We now have the necessary tools to formulate the important concept of 
logical implication for our language. 
DEFINITION. 
Let I' be a set of wffs, (p a wff. Then I' logically implies 
(p, written I' + q, iff for every structure B for the language and 
every function s : V + 1Bl such that B satisfies every member 
of I' with s, B also satisfies (p with s. 
We use the same symbol, " b," that was used in Chapter 1 for tau- 
tological implication. But henceforth it will be used solely for logical 
implication. As before we will write "y + (p" in place of " { y ]  + (p." 
Say that (p and 11 are logically equivalent ((p +$ +) iff (p + + and 
+ I= v. 
The first-order analogue of the concept of a tautology is the concept 
of a valid formula: A wff (p is valid iff M + (p (written simply "b 9"). 
Thus (p is valid iff for every I# and every s : V + 1!2ll,!2l satisfies (p 
with s. 
For sentences, the concept of logical implication can be stated more 
concisely, by applying Theorem 22A: 
COROLLARY 
22C For a set C ; t of sentences, C b t iff every model 
of C is also a model of t. A sentence t is valid iff it is true in 
every structure. 
EXAMPLES of logical implication. Readers are invited to convince 
themselves of each of the following: 
1. Vv1 Qv1 
Qv2. 
2. Qvl F V vl Qvl . Here it suffices to find just one structure 
I# and just one function s : V + IBl such that on the one hand, 
Q vl [s] but, on the other hand, B is not a model of V vl Q vl . 
IMI will need to have at least two members. 
3. + l l a + a .  
I f 2 l i ~ a m o d e l o f l i a , t h e n + ~ i a  
whence 
a. But one might raise the objection: Aren't we 

Chapter 2: 
Fi rst-Order Logic 
89 
using here the law of double negation, the law we are claiming 
to prove? The answer is a definite yes and no. We are proving 
the law of double negation for the formal language we are talking 
about (sometimes called the object language). In doing so, we can 
of course use any correct reasoning (out in the meta-language, 
English), exactly as we might do in reasoning about vector spaces 
or graphs. In particular, the reasoning might involve principles 
that when formally modeled would involve 1 
1 a and a. There 
is no circularity. But the meta-language sentences we use are- 
unsurprisingly -related to the object language formulas we talk 
about. In this connection, see the book's only picture (at the end 
of Section 2.4). 
4. V vl Qvl 
3 w Qw. Recall that the universe of any 
structure is nonempty. 
5. 3 x V y Pxy + V y 3 x Pxy . This example will come up 
again in Section 2.4. 
6. V y 3 x  Pxy 
3xVy Pxy. 
7. + 3 x(Qx 4 Vx Qx). This is a strange -but 
valid - 
sentence. 
The definition of logical implication is very much like the definition 
of tautological implication in Chapter 1. But there is an important dif- 
ference of complexity. Suppose in sentential logic you want to know 
whether or not a wff cr is a tautology. The definition requires that you 
consider finitely many truth assignments, each of which is a finite func- 
tion. For each such truth assignment u, you must calculate E(or), which 
can be effectively done in a finite length of time. (Consequently, the set 
of tautologies is decidable, as was observed before.) 
In contrast to the finitary procedure for tautologies, suppose that you 
want to know whether or not a wff cp (of our first-order language) is 
valid. The definition requires that you consider every structure a. (In 
particular this requires using every nonempty set, of which there are a 
great many.) For each of these structures, you then must consider each 
function s from the set V of variables into IBI. And for each given 2l 
and s, you must determine whether or not 
satisfies cp with s. When 
12ll is infinite, this is a complicated notion in itself. 
In view of these complications, it is not surprising that the set of 
valid formulas fails to be decidable (cf. Section 3.5). What is surpris- 
ing is that the concept of validity turns out to be equivalent to another 
concept (deducibility) whose definition is much closer to being fini- 
tary. (See Section 2.4.) Using that equivalence we will be able to show 
(under some reasonable assumptions) that the set of validities (i.e., the 
set of valid wffs) is effectively enumerable. The effective enumeration 
procedure yields a more concrete characterization of the set of valid 
formulas. 

90 
A Mathematical Introduction to Logic 
Definability in a Structure 
Suppose we want to study the real field, (R; 0, 1, +, -), consisting of the 
set R of real numbers, together with the distinguished elements 0 and 1 
and the two operations of addition and multiplication. We can consider 
the real field as a structure 
where the language (with equality) has constant symbols 0 and 1 and 
two-place function symbols + and #. 
Although we have not included an ordering symbol < in the lan- 
guage, we still have a way to say "x > 0.'' Because in this structure, the 
nonnegative elements are exactly the elements with square roots. That 
is, the formula 3 q x = 3 3 is satisfied in the structure R whenever 
x is assigned a nonnegative number, and only then: 
Because of this fact, we will say that the interval [0, oo) is definable in 
R, and that the formula 3 q vl = 3 3 defines it. 
Moreover, the ordering relation on the reals, i.e., the binary relation 
is defined in the structure R by the formula expressing "vl 5 q": 
For a smaller example, take the directed graph 
where the language has parameters V and E: 
Then in IM, the set {b, c) (the range of the relation E') is defined by the 
formula 3 3 Eqvl. In contrast, the set {b) is not definable in IM. This 
is because there is no definable property in this structure that would 
separate b and c; the proof of this fact will utilize the homomorphism 
theorem, to be proved later in this section. 
We now want to set forth precisely this concept of definability of 
a subset of the universe or of a relation on the universe. Consider a 
structure IM and a formula q whose free variables are among vl , . . . , vk. 
Then we can construct the k-ary relation on IIMI 
Call this the k-ary relation q dejnes in IM. In general, a k-ary relation 

Chapter 2: 
First-Order Logic 
9 1 
on [%I is said to be definable in % iff there is a formula (whose free 
variables are among vl, . . . , vk) that defines it there. 
EXAMPLE. Assume that we have a part of the language for number 
theory, specifically that our language has the paramekrs V, 0, S, 
+, and *. Let 8 be the intended structure: 
181 = N, the set of natural numbers. 
0% = 0, the number 0. 
S%, +%, and 
are S, +, and -, the functions of successor, 
addition, and multiplication. 
In one equation, 
3 =  
(N; 0, S, +, -). 
Some relations on N are definable in 8 and some are not. One 
way to show that some are not definable is to use the fact that 
there are uncountably many relations on N but only countably 
many possible defining formulas. (There is, however, an inherent 
difficulty in giving a specific example. After all, if something is 
undefinable, then it is hard to say exactly what it is! Later we 
will get to see a specific example, the set of dijdel numbers of 
sentences true in 3; see Section 3.5.) 
I 
1. The ordering relation {(m, n) I m < n} is defined in 8 by 
the formula 
2. For any natural number n, {n} is definable. For example, (2) 
is defined by the equation 
Vl = SSO. 
Because of this we say that n is a definable element in 3. 
3. The set of primes is definable in 8. We could use the formula 
if we had parameters 1 and < for 1 and <. But since (1) and < 
are definable in 8 ,  it is really quite unnecessary to add parameters 
for them; we can simply use their definitions instead. Thus the set 
of primes is definable by 
3 ~ S O + S q = v l A v Q v q  (v1=Q*v3+ 
Q = so v q = SO). 
4. Exponentiation, {(m , n, p) I p = mn} is also definable in 
8 .  This is by no means obvious; we will give a proof later (in 
Section 3.8) using the Chinese remainder theorem. 

92 
A Mathematical Introduction to Logic 
In fact, we will argue later that any decidablerelation on N is definable 
in 3, 
as is any effectively enumerable relation and a great many others. 
To some extent the complexity of a definable relation can be measured 
by the complexity of the simplest defining formula. This idea will come 
up again at the end of Section 3.5. 
Definability of a Class of Structures 
Many a mathematics class, on its first day, begins with the instructor 
saying something like one of the following: 
1. "A graph is defined to consist of a nonempty set V together with 
a set E such that. . . ." 
2. "A group is defined to consist of a nonempty set G together with 
a binary operation o satisfying the axioms. . . ." 
3. "An orderedJield is defined to consist of a nonempty set F together 
with two binary operations + and - and a binary relation < satisfying 
the axioms. . . ." 
4. "A vector space is defined to consist of a nonempty set V together 
with a binary operation + and, for each real number r, an operation 
called scalar multiplication such that. . . ." 
We want to abstract from this situation. In each case, the objects of 
study (the graphs, the groups, and so forth) are structures for a suitable 
language. Moreover, they are required to satisfy a certain set C of sen- 
tences (referred to as "axioms"). The course in question then studies the 
models of the set E of axioms - 
or at least some of the models. 
For a set C of sentences, let Mod C be the class of all models of C, 
i.e., the class of all structures for the language in which every member 
of C is true. For a single sentence t we write simply "Mod t" instead 
of "Mod {t ) ." (The reader familiar with axiomatic set theory will notice 
that Mod C, if nonempty, is a proper class; i.e., it is too large to be a set.) 
A class K: of structures for our language is an elementary class (EC) 
iff K: = Mod t for some sentence t. K: is an elementary class in the 
wider sense (ECa) 
iff K: = Mod C for some set C of sentences. (The 
adjective "elementary" is employed as a synonym for "first-order.") 
EXAMPLES 
1. Assume that the language has equality and the two pa- 
rameters t/ and E, where E is a two-place predicate symbol. 
Then a graph is a structure for this language !2i = (V; Eg) 
consisting of a nonempty set V of objects called vertices (or 
nodes), and an edge relation Eg that is symmetric (if u E"v then 
vEgu) and irreflexive (never vEgv). The axiom stating that the 
edge relation is symmetric and irreflexive can be translated by 
the sentence 

Chapter 2: 
First-Order Logic 
93 
So the class of all graphs is an elementary class. For directed 
graphs or digraphs, the assumption of symmetry is dropped. And 
if one wants to allow "loops" then the assumption of irreflexivity 
is dropped. But perhaps the instructor then explains that the course 
will study only Jinite graphs. Is the class of all finite graphs an 
elementary class? No, we will prove later that it is not, not even 
in the wider sense. 
2. Assume that the language has equality and the parameters 
V and P, where P is a two-place predicate symbol. As before, a 
structure (A; R) for the language consists of a nonempty set A 
together with a binary relation R on A. (A; R) is called an ordered 
set iff R is transitive and satisfies the trichotomy condition (which 
states that for any a and b in A, exactly one of (a, b) E R, a = b, 
(b, a )  E R holds). Because these conditions can be translated into 
a sentence of the formal language, the class of nonempty ordered 
sets is an elementary class. It is, in fact, Mod t ,  where t is the 
conjunction of the three sentences 
VxVyVz(xPy +yPz +xPz); 
VxVy(xPyVx = y v  yPx); 
v x  v y(x P y 4  1 y  Px). 
The next two examples assume that the reader has had some 
contact with algebra. 
3. Assume that the language has = and the parameters V and 
o, where o is a two-place function symbol. The class of all groups 
is an elementary class, being the class of all models of the con- 
junction of the group axioms: 
The class of all infinite groups is ECA. To see this, let 
Thus A, translates, "There are at least n things." Then the group 
axioms together with {A2, A3, . . .) form a set C for which Mod C 
is exactly the class of infinite groups. We will eventually (in Sec- 
tion 2.6) be able to show that the class of infinite groups is not EC. 
4. Assume that the language has equality and the parameters 
V, 0,1, +, *. Fields can be regarded as structures for this language. 

A Mathematical Introduction to Logic 
The class of all fields is an elementary class. The class of fields of 
characteristic zero is ECA. It is not EC, a fact which will follow 
from the compactness theorem for first-order logic (Section 2.6 
again). 
In courses about graphs or groups or vector spaces, one usually encoun- 
ters the concept of what it means for two of the structures in question, Q 
and B ,  to be isomophic: Roughly speaking, there must be a one-to-one 
correspondence between their universes IQI and 1231 that "preserves" 
the operations b d  relations. 
It is then explained that two isomorphic structures, although not 
identical, must have all the same mathematical properties. We want to 
define here the isomorphism concept in a general setting, and to show 
that two isomorphic structures must satisfy exactly the same sentences. 
Let Q, B be structures for the language. A homomorphism h of Q 
into !I3 is a function h : I QI + 193 1 with the properties: 
(a) For each n-place predicate parameter P and each n-tuple (al, . . . , 
a,) of elements of IQI , 
(a1 ,..., a,) E pa 
iff 
(h(a1) ,..., h(a,)) E pg. 
(b) For each n-place function symbol f and each such n-tuple, 
In the case of a constant symbol c this becomes 
Conditions (a) and (b) are usually stated: "h preserves the relations 
and functions." (It must be admitted that some authors use a weakened 
version of condition (a); our homomorphisms are their "strong homo- 
morphisms.") 
If, in addition, h is one-to-one, it is then called an isomorphism (or 
an isomorphic embedding) of Q into B. If there is an isomorphism of 
Q onto B (i.e., an isomorphism h for which ran h = IBI), then Q and 
B are said to be isomorphic (written Q Z B). 
The reader has quite possibly encountered this concept before in 
special cases such as structures that are groups or fields. 
' This topic can be postponed somewhat. But homomorphisms will be used in the proof 
of the completeness theorem (with equality). And we make use of the isomorphism 
concept, starting in Section 6 of Chapter 2. 

Chapter 2: 
First-Order Logic 
95 
EXAMPLE. Assume that we have a language with the parameters V, 
+, and *. Let IM be the structure (N; +, -). We can define a function 
h : N + {e,o) by 
e 
if n is even, 
h(n) = o if n is odd. 
Then h is a homomorphism of IM onto 23, where 1% 1 = {e, o] and 
+", 
aB are given by the following tables: 
It can then be verified that condition (b) of the definition is satis- 
fied. For example, if a and b are both odd numbers, then h (a +b) = 
e and h(a) +B h(b) = o +B o = e. 
EXAMPLE. Let P be the set of positive integers, let < p be the usual 
ordering relation on P, and let < N  be the usual ordering relation 
on N. Then there is an isomorphism h from the structure (P; <p) 
onto (N; cN); 
we take h(n) = n - 1. Also the identity map 
Id : P + N is an isomorphism of (P; < p) into (N; cN). Because 
of this last fact, we say that (P; < p) is a substructure of (N; cN). 
More generally consider two structures IM and 93 for the language 
such that IIMI 2 IBI. It is clear from the definition of homomorphism 
that the identity map from IIMI into 1931 is an isomorphism of IM into 
??3 iff 
(a) pa is the restriction of pB to li#l, for each predicate param- 
eter P; 
(b) f is the restriction of f to IMI, for each function symbol f ,  
and cZL = cB for each constant symbol c. 
If these conditions are met, then IM is said to be a substructure of 93, 
and 93 is an extension of I#. 
For example, in a language with a two-place function symbol +, the 
structure (Q; +Q) is a substructure of (C; +c). Here +c is the addition 
operation on complex numbers. And +Q, addition on the rationals, is 
exactly the restriction of +c to the set Q. 
In this example, the set Q is closed under +c ; that is, the sum of two 
rational numbers is rational. More generally, whenever IM is a substruc- 
ture of 23, then 
must be closed under f for every function symbol 
f . After all, f B(i) (where i E IQIn) is nothing but f '(Z), which must 
be some element in 1IMl. This closure property even holds for the 0-place 
function symbols; cB must belong to 1IMl for each constant symbol c. 

9 6 
A Mathematical Introduction to Logic 
Conversely, suppose we have a structure 93, and let A be any non- 
empty subset of 1931 that is closed under all of 93's functions, as in 
the preceding paragraph. Then we can make a substructure of 93 with 
universe A. In fact there is only one way to do this. The universe is A, 
each predicate parameter P is assigned the restriction of pB to A, and 
similarly for the function symbols. As an extreme case, if the language 
has no function symbols at all (not even constant symbols), then we can 
make a substructure out of any nonempty subset A of 193 1. 
These are basically algebraic concepts, but the following theorem 
relates them to the logical concepts of truth and satisfaction. 
HOMOMORPHISM 
THEOREM 
Let h be a homomorphism of !?I into 93, 
and let s map the set of variables into I!?II. - 
(a) For any term t, we have h (-S(t)) = h o s (t), where T(t) is 
- 
computed in !?I and h o s (t) is computed in 93. 
(b) For any quantifier-free formula a not containing the equal- 
ity symbol, 
a [ s ]  iff 
kB a [ h o s ] .  
(c) If h is one-to-one (i.e., is an isomorphism of !?I into 931, 
then in part (b) we may delete the restriction "not containing the 
equality symbol." 
(d) If h is a homomorphism of !?I onto 93, then in (b) we may 
delete the restriction "quantifier-free." 
PROOF. Part (a) uses induction on t; see Exercise 13. Note that h o s  
maps the set of variables into 1931; its extension to the set of all 
- - 
terms is h o s. It is h o s that is here being evaluated at t. 
(b) For an atomic formula such as Pt, we have 
kg P t [ s ]  es Z(t) E pra 
+ h(Y(t)) E pB since h is a homomorphism 
+ h o ( t )  E pB by (a) 
kg P t [ h o s ] .  
An inductive argument is then required to handle the connective 
symbols 1 and + , but it is completely routine. 
(c) In any case, 
+ h(Y(u)) = h (Y(t)) 
- - 
es h o s (u) = h o s (t) by (a) 
+ Fb u = tIh o s]. 
If h is one-to-one, the arrow in the second step can be reversed. 
(d) We must extend the routine inductive argument of part (b) 
to include the quantifier step. That is, we must show that if (o has 

Chapter 2: 
First-Order Logic 
97 
the property that for every s, 
then Vx (o enjoys the same property. We have in any case (as a 
consequence of the inductive hypothesis on (o) the implication 
Fa Qx (o[h 0 sl * Frrr v x  (o[sl. 
This is intuitively very plausible; if (o is true of everything in the 
larger set 1% 1, then a fortiori it is true of everything in the smaller 
set ran h. The details are, for an element a of IaI, 
I=s v x  (o[h 0 sl* I=% (o[(h 0 s)(x I h(a))l 
+ I=% (ow0 (s(x la))], 
the functions 
being the same 
by the inductive 
hypothesis. 
Now for the converse, suppose that 
Vx (o[h o s], so that 
1 
q[(h o S) (x I b)] for some element b in 193 1. We need the 
implication 
(*) If for some b in 1% 1, ks 1 
(o [(h o s) (x I b)], then for 
some a in IMI, 
1 
q[(h o s) (R 1 h (a))]. 
X 
For given (*), we can proceed: 
1 
~ [ ( h  
0 s)(x I h(a))] + k% 
1 
(o[h 0 (s(x I a))], 
the functions 
being the same 
by the inductive 
hypothesis 
* F m  Vx ~[sl.. 
If h maps 
onto 1% 1, then (*) is immediate; we take a such that 
b = h (a). (But there might be other fortunate times when (*) can 
be asserted even if h fails to have range 1 ?I3 1 .) 
-I 
l b o  structures 
and 23 for the language are said to be elementarily 
equivalent (written = 93) iff for any sentence a, 
COROLLARY 
22 D Isomorphic structures are elementarily equivalent: 
Actually more is true. Isomorphic structures are alike in every "struc- 
tural" way; not only do they satisfy the same first-order sentences, they 
also satisfy the same second-order (and higher) sentences (i.e., they are 
secondarily equivalent and more). 
There are elementarily equivalent structures that are not isomorphic. 
For example, it can be shown that the structure (R; -cR) 
consisting of 
the set of real numbers with its usual ordering relation is elementarily 

98 
A Mathematical Introduction to Logic 
equivalent to the structure (Q; -cQ) consisting of the set of rational 
numbers with its ordering (see Section 2.6). But Q is a countable set 
whereas R is not, so these structures cannot be isomorphic. In Section 2.6 
we will see how easy it is to make elementarily equivalent structures of 
differing cardinalities. 
EXAMPLE, revisited. We had an isomorphism h from (P; <p) onto 
(N; < N). SO in particular, (P; < p) = (N; cN); these structures 
are indistinguishable by first-order sentences. 
We furthermore noted that the identity map was an isomor- 
phic embedding of (P; <p) into (N; xN). Hence for a function s: 
V + P and a quantifier-free (g, 
This equivalence may fail if (g contains quantifiers. For example, 
but 
An automolphism of the structure 8 is an isomorphism of 8 onto 
8. The identity function on 181 is trivially an automorphism of 8. 8 
may or may not have nontrivial automorphisms. (We say that 8 is rigid 
if the identity function is its only automorphism.) As a consequence of 
the homomorphism theorem, we can show that an automorphism must 
preserve the definable relations: 
COROLLARY 
22E Let h be an automorphism of the structure 8, and 
let R be an n-ary relation on 181 definable in 8. Then for any 
al, . . . ,an in 181, 
PROOF. Let (g be a formula that defines R in 8. We need to know 
that 
But this is immediate from the homomorphism theorem. 
This corollary is sometimes useful in showing that a given relation 
is not definable. Consider, for example, the structure (R; <) consisting 
of the set of real numbers with its usual ordering. An automorphism 
of this structure is simply a function h from R onto R that is strictly 
increasing: 

Chapter 2: First-Order Logic 
99 
One such automorphism is the function h for which h(a) = a3. Since 
this function maps points outside of N into N, the set N is not definable 
in this structure. 
Another example is provided by elementary algebra books, which 
sometimes explain that the length of a vector in the plane cannot be 
defined in terms of vector addition and scalar multiplication. For the 
map that takes a vector x into the vector 2x is an automorphism of the 
plane with respect to vector addition and scalar multiplication, but it is 
not length-preserving. From our viewpoint, the structure in question, 
has for its universe the plane E, has the binary operation + of vector 
addition, and has (for each r in the set R) the unary operation fr of scalar 
multiplication by r .  (Thus the language in question has a one-place 
function symbol for each real number.) The doubling map described 
above is an automorphism of this structure. But it does not preserve the 
set of unit vectors, 
{xlx E E andxhaslength 1). 
So this set cannot be definable in the structure. (Incidentally, the homo- 
morphisms of vector spaces are called linear transfomultions.) 
Exercises 
1. Show that (a) r; a + (g iff I' + (a + (g); and (b) (g I=+ + iff 
I= (v -e- +I* 
2. Show that no one of the following sentences is logically implied 
by the other two. (This is done by giving a structure in which the 
sentence in question is false, while the other two are true.) 
(a) Vx V y V z(Pxy + Pyz + Pxz). Recall that by our conven- 
tiona+p + y isa+(p+y). 
(b) Vx V y(Pxy + Pyx + x = y). 
(c) v x 3 y  P x y + 3 y V x  Pxy. 
3. Show that 
4. Show that if x does not occur free in a, then a 
Vx a. 
5. Show that the formula x = y + Pz f x + Pz f y (where f is a 
one-place function symbol and P is a two-place predicate symbol) 
is valid. 
6. Show that a formula 8 is valid iff Vx 8 is valid. 
7. Restate the definition of "B satisfies (g with s" in the way described 

1 00 
A Mathematical Introduction to Logic 
on page 84. That is, define by recursion a function 
such that U 
satisfies 40 with s iff s E x((p). 
8. Assume that C is a set of sentences such that for any sentence t ,  
either X + t or X + 1 t. Assume that U is a model of C .  Show 
that for any sentence t ,  we have +a t iff C + t. 
9. Assume that the language has equality and a two-place predicate 
symbol P. For each of the following conditions, find a sentence a 
such that the structure U is a model of a iff the condition is met. 
(a) IUI has exactly two members. 
(b) P' is a function from 
into IUI . (Afunction is a single-valued 
relation, as in Chapter 0. For f to be a function from A into B, 
the domain of f must be all of A; the range of f is a subset, 
not necessarily proper, of B .) 
(c) P' is a permutation of IUI; i.e., P" is a one-to-one function 
with domain and range equal to 1941. 
10. Show that 
I=% v 'u;! Qvl'U;!lk"ll iff Fa V uz Qcuz. 
Here Q is a two-place predicate symbol and c is a constant symbol. 
11. For each of the following relations, give a formula which defines 
it in (N; +, a ) .  (The language is assumed to have equality and the 
parameters V, +, and 0 ) .  
(a) (01. 
(b) (11. 
H 
(c) {(m, n) I n is the successor of m in%}. 
(d) {(m, n) I m < n in N). 
Digression: This is merely the tip of the iceberg. A relation on 
N is said to be arithmetical if it is definable in this structure. 
All decidable relations are arithmetical, as are many others. 
The arithmetical relations can be arranged in a hierarchy; see 
Section 3.5. 
12. Let 93 be the structure (R; +, 
a ) .  (The language is assumed to have 
equality and the parameters V, +, and *. 93 is the structure whose 
universe is the set W of real numbers and such that +% and 0% are 
the usual addition and multiplication operations.) 
(a) Give a formula that defines in 93 the interval [0, oo). 
(b) Give a formula that defines in 93 the set (2). 
* (c) Show that any finite union of intervals, the endpoints of which 
are algebraic, is definable in R. (The converse is also true; these 
are the only definable sets in the structure. But we will not prove 
this fact.) 
13. Prove part (a) of the homomorphism theorem. 

Chapter 2: First-Order Logic 
101 
14. What subsets of the real line R are definable in (R; <)?What subsets 
of the plane R x R are definable in (R; <)? 
Remarks: The nice thing about (R; <) is that its automorphisms 
are exactly the order-preserving maps from R onto itself. But stop 
after the binary relations. There are 213 definable ternary relations, 
so you do not want to catalog all of them. 
Show that the addition relation, {(m, n, p) I p = m + n), is not 
definable in (N; .). Suggestion: Consider an automorphism of (N; a) 
that switches two primes. 
Digression: Algebraically, the structure of the natural numbers 
with multiplication is nothing but the free Abelian semigroup with 
No generators (viz. the primes), together with a zero element. There 
is no way you could define addition here. If you could define addi- 
tion, then you could define ordering (by Exercise 11 and the natural 
transitivity statement). But one generator looks just like another. 
That is, there are 2'0 automorphisms - 
simply permute the primes. 
None of them is order-preserving except the identity. 
16. Give a sentence having models of size 2n for every positive inte- 
ger n, but no finite models of odd size. (Here the language should 
include equality and will have whatever parameters you choose.) 
Suggestion: One method is to make a sentence that says, "Every- 
thing is either red or blue, and f is a color-reversing permutation." 
Remark: Given a sentence a ,  it might have some finite models 
(i.e., models with finite universes). Define the spectrum of a to be 
the set of positive integers n such that a has a model of size n. This 
exercise shows that the set of even numbers is a spectrum. 
For example if a is the conjunction of the field axioms (there 
are only finitely many, so we can take their conjunction), then its 
spectrum is the set of powers of primes. This fact is proved in any 
course on finite fields. The spectrum of 1 
a ,  by contrast, is the set 
of all positive integers (non-fields come in all sizes). 
Giinter Asser in 1955 raised the question: Is the complement of 
every spectrum a spectrum? Once you realize that simply taking 
a negation does not work (cf. the preceding paragraph), you see 
that this is a nontrivial question. In fact the problem, known as the 
spectrum problem, is still open. But modern work has tied it to 
another open problem, whether or not co-NP = NP. 
17. (a) Consider a language with equality whose only parameter (aside 
from V) is a two-place predicate symbol. P. Show that if U is 
finite and U = 23, then U is isomorphic to 23. Suggestion: 
Suppose the universe of U has size n. Make a single sentence a 
of the form 3 vl . - - 3  u, 8 that describes U "completely." That 
is, on the one hand, a must be true in U. And on the other hand, 
any model of cr must be exactly like (i.e., isomorphic to) U. 

102 
A Mathematical Introduction to Logic 
*(b) Show that the result of part (a) holds regardless of what param- 
eters the language contains. 
18. A universal (Vl ) formula is one of the form V xl . V x, 8, where 
8 is quantifier-free. An existential (3 1) formula is of the dual form 
3xl~~~3xn8.LetUbeasubstructureof%,andlets 
: V + IUI. 
(a) Show that if +a @[s] and @ is existential, then FB @[s]. And 
if kg (~[s] 
and (P is universal, then kg (~[s]. 
(b) Conclude that the sentence 3 x Px is not logically equivalent to 
any universal sentence, nor Vx Px to any existential sentence. 
Remark: Part (a) says (when (P is a sentence) that any univer- 
sal sentence is "preserved under substructures." Being universal 
is a syntactic property - 
it has to do with the string of symbols. 
In contrast, being preserved under substructures is a semantic 
property -it 
has to do with satisfaction in structures. But this 
semantic property captures the syntactic property up to logical 
equivalence (which is all one could ask for). That is, if a is a 
sentence that is always preserved under substructures, then a 
is logically equivalent to a universal sentence. (This fact is due 
to Log and Tarski.) 
19. An 3 2  formula is one of the form 3 x1 
3 x, 8, where 8 is 
universal. 
(a) Show that if an 3 2  sentence in a language not containing func- 
tion symbols (not even constant symbols) is true in U, then it 
is true in some finite substructure of U. 
(b) Conclude that Vx 3 y Pxy is not logically equivalent to any 3 2  
sentence. 
20. Assume the language has equality and a two-place predicate symbol 
P. Consider the two structures (N; 
<) and (R; <) for the language. 
(a) Find a sentence true in one structure and false in the other. 
*(b) Show that any 3 2  sentence (as defined in the preceding exer- 
cise) true in (R; <) is also true in (N; <). Suggestion: First, 
for any finite set of real numbers, there is an automorphism 
of (R; <) taking those real numbers to natural numbers. Sec- 
ondly, by Exercise 18, universal formulas are preserved under 
substructures. 
21. We could consider enriching the language by the addition of a new 
quantifier. The formula 3!x a (read "there exists a unique x such 
that a") is to be satisfied in U by s iff there is one and only one 
a E I%[ such that kg a[s(x I a)]. Assume that the language has the 
equality symbol and show that this apparent enrichment comes to 
naught, in the sense that we can find an ordinary formula logically 
equivalent to 3 !x a. 
22. Assume that U is a structure and h is a function with ran h = 121. 

Chapter 2 : Fi rst-Order Logic 
1 03 
Show that there is a structure 23 such that h is a homomorphism of 
23 onto U. Suggestion: We need to take 1231 = dom h. In general, 
the axiom of choice will be needed to define the functions in 23, 
unless h is one-to-one. 
Remark: The result yields an "upward Lijwenheim-Skolem the- 
orem without equality" (cf. Section 2.6). That is, any structure U 
has an extension to a structure 23 of any higher cardinality such that 
U and 23 are elementarily equivalent, except for equality. There is 
nothing deep about this. Not until you add equality. 
23. Let U be a structure and g a one-to-one function with dom g = IUI. 
Show that there is a unique structure 23 such that g is an isomor- 
phism of U onto 23. 
24. Let h be an isomorphic embedding of U into 23. Show that there is 
a structure & isomorphic to 23 such that U is a substructure of &. 
Suggestion: Let g be a one-to-one function with domain 1231 such 
that g(h (a)) = a for a E IUI. Form C such that g is an isomorphism 
of 23 onto &. 
Remark: The result stated in this exercise should not seem sur- 
prising. On the contrary, it is one of those statements that is obvious 
until you have to prove it. It says that if you can embed U isomor- 
phically into 23, then for all practical purposes you can pretend 24 
is a substructure of 23. 
Consider a fixed structure 2 .  Expand the language by adding a 
new constant symbol c, for each a E IUI. Let U+ be the struc- 
ture for this expanded language that agrees with U on the original 
parameters and that assigns to c, the point a. A relation R on 
121 is said to be definable from points in U iff R is definable in 
U+. (This differs from ordinary definability only in that we now 
have parameters in the language for members of 1531.) Let R = 
(R; <, +, -1. 
(a) Show that if A is a subset of R consisting of the union of finitely 
many intervals, then A is definable from points in 8 
(cf. Exer- 
cise 12). 
(b) Assume that M = R. Show that any subset of IUI that is non- 
empty, bounded (in the ordering <%), and definable from points 
in U has a least upper bound in IUI. 
Digression: Often when people speak of definability within a 
structure, this is the concept they mean. The more standard phrase 
is "definable from parameters"; here "points" is used because the 
word "parameter" is used in a different sense in this chapter. 
The real ordered field can be characterized up to isomorphism 
by saying that it is a complete ordered field. (This fact should 
be included in any analysis course.) But completeness (i.e., that 
nonempty bounded sets have least upper bounds) is not a first- 

1 04 
A Mathematical Introduction to Logic 
order property. See Example 4 in Section 4.1 for its second-order 
statement. The first-order "image" of completeness is given by the 
schema obtained from that second-order statement by replacing X 
by a first-order formula 9. The resulting schema (i.e., the set of 
sentences you get by letting 9 vary and taking universal closure) 
says that the least-upper-bound property holds for the sets that are 
definable from points. Ordered fields satisfying those sentences are 
called "real closed-ordered fields." 
The surprising fact is that such fields were not invented by logi- 
cians. They were previously studied by algebraists and you can read 
about them in van der Waerden's Modem Algebra book (volume I). 
Of course, he uses a characterization of them that does not involve 
logic. 
What Tarski showed is that any real closed-ordered field is el- 
ementarily equivalent to the field of real numbers. From this it 
follows that the theory of the real-ordered field is decidable. 
26. (a) Consider a fixed structure U and define its elementary type to 
be the class of structures elementarily equivalent to U. Show 
that this class is ECA. Suggestion: Show it is Mod Th U. 
(b) Call a class K of structures elementarily closed or ECL if when- 
ever a structure belongs to K then all elementarily equivalent 
structures also belong. Show that any such class is a union of 
ECA classes. (A class that is a union of ECA classes is said to 
be an ECAx class; this notation is derived from topology.) 
(c) Conversely, show that any class that is the union of ECA classes 
is elementarily closed. 
27. Assume that the parameters of the language are V and a two-place 
predicate symbol P. List all of the non-isomorphic structures of 
size 2. That is, give a list of structures (where the universe of each 
has size 2) such that any structure of size 2 is isomorphic to exactly 
one structure on the list. 
28. For each of the following pairs of structures, show that they are 
not elementarily equivalent, by giving a sentence true in one and 
false in the other. (The language here contains V and a two-place 
function symbol 0.) 
(a) (R; x) and (R* ; x *), where x is the usual multiplication op- 
eration on the real numbers, R* is the set of non-zero reals, and 
x* is x restricted to the non-zero reals. 
(b) (N; 
+) and (P; +*), where P is the set of positive integers, and 
+* is usual addition operation restricted to P. 
(c) Better yet, for each of the four structures of parts (a) and (b), 
give a sentence true in that structure and false in the other 
three. 

Chapter 2: First-Order Logic 
1 05 
SECTION 2.3 
A Parsing Algorithm' 
As in sentential logic, we need to know that we can decompose formulas 
(and terms) in a unique way, discovering how they are built up. The 
uniqueness is necessary to justify our definitions by recursion, such as 
the definition of satisfaction in the preceding section. 
For terms we used Polish notation; for formulas we relied on paren- 
theses. Accordingly, we first consider a decomposition procedure for 
terms, showing unique readability. And then we extend the methods to 
cover the formulas. 
Recall that the terms are built up from the variables and constant 
symbols by operations corresponding to the function symbols. We now 
define a function K on the symbols involved such that for a symbol s, 
K(s) = 1 - n, where n is the number of terms that must follow s to 
obtain a term: 
K(x) = 1 - 0 =  1 foravariablex; 
K(c) = 1 - 0  = 1 for a constant symbol c; 
K(f) = 1 - n 
for an n-place function symbol f. 
We then extend K to the set of expressions using these symbols by 
defining 
Since no symbol is a finite sequence of others, this definition is unam- 
biguous. 
LEMMA 23A For any term t, K(t) = 1. 
PROOF. Use induction on t. The inductive step, for an n-place func- 
tion symbol f ,  is 
n times 
In fact, K was chosen to be the unique function on these symbols 
for which Lemma 23A holds. It follows from this lemma that if E is a 
concatenation of m terms, then K(E) = m. 
By a terminal segment of a string (sl, . . . , s,) of symbols we mean 
a sequence of the form (sk, sk+1, . . . , sn), where 1 I 
k I 
n. 
LEMMA 23B Any terminal segment of a term is a concatenation of 
one or more terms. 
This section may be omitted by a reader willing to accept the meaningfulness of our 
many definitions by recursion. 

106 
A Mathematical Introduction to Logic 
PROOF. We use induction on the term. For a one-symbol term (i.e., 
a variable or a constant symbol) the conclusion follows trivially. 
For a term f tl 
t,, any terminal segment (other than the term 
itself) must equal 
where k 5 n and ti is a terminal segment of tk. By the inductive 
hypothesis t; is a concatenation of, say, m terms, where m 2 1. 
So altogether we have m + (n - k) terms. 
-I 
COROLLARY 
23C No proper initial segment of a term is itself a term. 
If tl is a proper initial segment of a term t, then K(tl) < 1. 
PROOF. Suppose a term t is divided into a proper initial segment tl 
and a terminal segment t2. Then 1 = K (t) = K(tl) + K(t2), and 
by Lemma 23B, K (t2) > 1. Hence K (tl ) < 1 and tl cannot be 
a term. 
-I 
Parsing Terms 
We want an algorithm that, given an expression, will determine whether 
or not the expression is a legal term, and if it is, will construct the unique 
tree showing how the term is built up. 
Assume then that we are given an expression. We will construct a 
tree, with the given expression at the top (i.e., the root). Initially it is 
the only vertex in the tree, but as the procedure progresses, the tree will 
grow downward. 
The algorithm consist of the following two steps. 
1. If each minimal vertex (at the bottom) has a single symbol (which 
must* be a variable or a constant symbol), then the procedure is com- 
pleted. (The given expression is indeed a term, and we have constructed 
its tree.) Otherwise, select a minimal vertex having an expression with 
two or more symbols. We examine that expression. 
2. The first symbol must* be an n-place function symbol, say f ,  
where n > 0. We extend the tree downward by creating n new vertices 
below the present one. Scan the expression after the f , until first reaching 
a string t (of variables, constant symbols, and function symbols) with 
K (t) = I.** Then t is the expression that goes at the leftmost unlabeled 
new vertex. Repeat with the remainder of the expression, until all n new 
vertices have been labeled, and the expression has been exhausted.** 
Return to step 1. 
* If not, then the expression here is not a term. We reject the given expression as a 
non-term, and halt. 
** If the end of the expression is reached before finding such an t ,  then the expression here 
is not a term. We reject the given expression as a non-term, and halt. 

Chapter 2: First-Order Lonic 
As in Section 1.3, the crucial point is that the tree could not have 
been made differently. In step 2, we selected the first string t we found 
with K (t) = 1. We could not have used less than t (because we needed 
K (t) = 1 by Lemma 23A). We could not have used more than t (because 
that longer string would have the proper initial segment t with K (t ) = 1, 
contradicting Corollary 23C). The choice of t was the only possible 
choice. 
When the algorithm halts, either it has rejected the given expression 
as a non-term, or it has constructed the one tree demonstrating that the 
given expression is a legal tree. 
We can rephrase the uniqueness in the terminology of Section 1.4 as 
follows: 
UNIQUE 
READAB~L~TY THEOREM 
FOR TERMS The set of terms is freely 
generated from the set of variables and constant symbols by the 
Ff operations. 
If 
PROOF. First, it is clear t h a t x  f # g, then ranFf is disjoint from 
ran Fg; 
this requires checking only the first symbol. Furthermore, 
both ranges are disjoint from the set of variables and constant 
symbols. It remains only to show that Ff, when restricted to 
terms, is one-to-one. Suppose, for a two-place f ,  we have 
By deleting the first symbol we are left with 
If tl # t3, then one would be a proper initial segment of the other, 
which is impossible for terms by Corollary 23C. So tl = t3, and 
we are then left with t2 = t4. 
-I 
Parsing Formulas 
To extend this argument to formulas, we now define K on the other 
symbols: 
K(() = -1; 
KO) = 1; 
K(V) = -1; 
K(1) = 0; 
K(-+) = -1; 
K(P) = 1 - n for an n-place predicate symbol P; 
K(=) = -1. 
The idea behind the definition is again that K (s) should be 1 - n, where 
n is the number of things (right parentheses, terms, or formulas) required 
to go after s. We extend K as usual to the set of all expressions: 

108 
A Mathematical Introduction to Logic 
1
~
~
~
~
2
3
0
 
Forany wffa, K(a) = 1. 
PROOF. Another straightforward induction. 
LEMMA 23 E For any proper initial segment a' of a wff a ,  K (a') < 1. 
PROOF. Use induction on a. The details are left to Exercise 1. 
-1 
COROLLARY 
23F No proper initial segment of a formula is itself a 
formula. 
Armed with these facts, we can proceed as in Section 1.3. Instead of 
sentence symbols at the minimal vertices, we now have atomic formulas 
(which are distinguished by having first an n-place predicate symbol, 
followed by n terms). 
A wff that is non-atomic must begin either with V vi or with (. In 
the former case we have one new vertex; in the latter case we need to 
examine the next symbol to see if it is 7. If not, then we can either count 
parentheses or use the K function - 
both methods work - 
to find the 
correct split. 
Again, the uniqueness can be phrased in the terminology of Sec- 
tion 1.4 as follows: 
UNIQUE READABILITY 
THEOREM 
FOR FORMULAS 
The set of wffs is freely 
generated from the set of atomic formulas by the operations 
El, E,, 
and Qi (i = 1,2,. ..). 
PROOF. The unary operations El and Qi are obviously one-to-one. 
As in Section 1.4, we can show that the restriction of I, to wffs 
is one-to-one. 
The disjointness half of the theorem follows from the ad hoc 
observations: 
1. ran El, ran Qi, ran Qj, and the set of atomic formulas are 
pairwise disjoint, for i # j. (Just look at the first two symbols.) 
2. ran E,, 
ran Qi, ran Qj , and the set of atomic formulas are 
similarly painvise disjoint, for i # j. 
3. For a wff #J, 
( 1  a )  # (#J -) y), because no wff begins 
with 1. 
Hence ran El is disjoint from the range of the restriction 
of E, 
to wffs. 
-1 
Exercises 
1. Show that for a proper. initial segment a' of a wff a ,  we have 
K(af) < 1. 
2. Let E be an expression consisting of variables, constant symbols, and 
function symbols. Show that E is a term iff K(E) = 1 and for every 
terminal segment E' of E we have K(E') > 0. Suggestion: Prove the 

Chapter 2: 
First-Order Logic 
1 09 
stronger result that if K(E') > 0 for every terminal segment E' of E, 
then s is a concatenation of K(s) terms. (This algorithm is due to 
Jkkowski.) 
SECTION 2.4 
A Deductive Calculus 
Suppose that C 
t. What methods of proof might be required to 
demonstrate that fact? Is there necessarily a proof at all? 
Such questions lead immediately to considerations of what consti- 
tutes a proof. A proof is an argument that you give to someone else 
and that completely convinces that person of the correctness of your 
assertion (in this case, that C k t). 
Thus a proof should be finitely long, as you cannot give all of an 
infinite object to another person. If the set C of hypotheses is infinite, 
they cannot all be used. But the compactness theorem for first-order 
logic (which we will prove in Section 2.5 using the deductive calculus 
of this section) will ensure the existence of a finite Co G C such that 
Co I= t. 
Another essential feature of a proof (besides its being finite in length) 
is that it must be possible for someone else (if that person is to be 
convinced by it) to check the proof to ascertain that it contains no fal- 
lacies. This check must be effective; it must be the sort of thing that 
can be carried out without brilliant flashes of insight on the part of 
the checker. In particular, the set of proofs from the empty set of hy- 
potheses (i.e., proofs that + t )  should be decidable. This implies that 
the set of formulas provable without hypotheses must be effectively 
enumerable. For one could in principle enumerate provable sentences 
by generating all strings of symbols and sorting out the proofs from 
the nonproofs. When a proof is discovered, its last line is entered on 
the output list. (This issue will be examined more carefully at the end 
of Section 2.5.) But here again there is a theorem (the enumerability 
theorem, proved in Section 2.5) stating that, under reasonable condi- 
tions, the validities -the 
set of valid formulas -is 
indeed effectively 
enumerable. 
Thus the compactness theorem and the enumerability theorem are 
necessary conditions for satisfactory proofs of logical implication al- 
ways to exist. Conversely, we claim that these two theorems are suffi- 
cient for proofs (of some sort) to exist. For suppose that C + t. By 
the compactness theorem, then, there is a finite set {ao, . . . , an) 5 C 
that logically implies t . Then a0 --, . . -+ an --, t is valid (Exercise 1, 
Section 2.2). So to demonstrate conclusively that C k t one need only 
carry out a finite number of steps in the enumeration of the validities 

110 
A Mathematical Introduction to Logic 
until cro + . . . + an + t appears, and then verify that each cri E C. 
(This should be compared with the complex procedure suggested by the 
original definition of logical implication, discussed in Section 2.2.) The 
record of the enumeration procedure that produced a0 + . - . + an + t 
can then be regarded as a proof that C + t. As a proof, it should be 
acceptable to anyone who accepts the correctness of your procedure for 
enumerating validities. 
Against the foregoing general (and slightly vague) discussion, the 
outline of this section can be described as follows: We will introduce 
formal proofs but we will call them deductions, to avoid confusion 
with our English-language proofs. These will mirror (in our model of 
deductive thought) the proofs made by the working mathematician to 
convince his or her colleagues of certain truths. Then in Section 2.5 we 
will show that whenever C + t, there is a deduction of t from C (and 
only then). This will, as is suggested by the foregoing discussion, yield 
proofs of the compactness theorem and the enumerability theorem. And 
in the process we will get to see what methods of deduction are adequate 
to demonstrate that a given sentence, is, in fact, logically implied by 
certain others. In other words, our goal is to produce a mathematically 
precise concept of deduction that, in the context of first-order logic, is 
adequate and correct. 
Formal Deductions 
We will shortly select an infinite set A of formulas to be called logical 
axioms. And we will have a rule of inference, which will enable us to 
obtain a new formula from certain others. Then for a set r of formulas, 
the theorems of r will be the formulas which can be obtained from 
r U A by use of the rule of inference (some finite number of times). If 
q is a theorem of r (written r I- q), then a sequence of formulas that 
records (as explained below) how qp was obtained from r U A with the 
rule of inference will be called a deduction of q from r. 
The choice of A and the choice of the rule (or rules) of inference 
are far from unique. In this section we are presenting one deductive 
calculus for first-order logic, chosen from the array of possible calculi. 
(For example, one can have A = 0 by using many rules of inference. 
We will take the opposite extreme; our set A will be infinite but we will 
have only one rule of inference.) 
Our one rule of inference is traditionally known as modus ponens. It 
is usually stated: From the formulas a and a + B we may infer /I: 
Thus the theorems of a set r are the formulas obtainable from r U A 
by use of modus ponens some finite number of times. 

Chapter 2: First-Order Logic 
11 1 
DEFINITION. 
Adeduction ofq from r is a finite sequence (ao, . . . , a,) 
of formulas such that a, is q and for each k 5 n, either 
(a) a k  isin r U A, or 
(b) a k .  is obtained by modus ponens from two earlier formulas 
in the sequence; that is, for some i and j less thank, aj is ai + a k .  
If such a deduction exists, we say that q is deducible from r ,  or that 
q is a theorem of r ,  and we write r I- 
40. 
There is another viewpoint that is useful here: A deduction of q from 
r can be viewed as a construction sequence, showing how 
can be 
obtained from the set r U A by applying modus ponens zero or more 
times. (We hesitate to say that q is built "up" from r U A. Unlike the 
formula-building operations that produce longer formulas from shorter 
ones, modus ponens can produce shorter formulas from longer ones.) 
That is, the set of theorems of r is exactly the set of formulas that are 
obtainable from the "base" set r U A by applying modus ponens. 
The situation here differs from the one discussed in Section 1.4 in two 
ways, one unimportant and one important. The unimportant difference is 
that we get the set of theorems by closing under the "partially defined" 
operation of modus ponens, whose domain consists only of pairs of 
formulas of the form (a, a + p )  (in contrast to the "totally defined" 
formula-building operations). The more important difference is that the 
set of theorems is not freely generated from r U A by modus ponens. 
This reflects the fact that a theorem never has a unique deduction. In 
Sections 1.3 and 2.3, we were concerned to show that for any wff q, 
there was a unique tree (which we could effectively calculate) showing 
how was built up by use of formula-building operations. Now the tree 
is by no means unique, and calculating one such tree is a very different 
matter from before. 
Nevertheless, this viewpoint does yield the following induction prin- 
ciple. We say that a set S of formulas is closed under modus ponens if 
whenever both a E S and (a + p) E S then also 
E S. 
~NDUCT~ON 
PRINCIPLE Suppose that S is a set of wffs that includes 
r U A and is closed under modus ponens. Then S contains every 
theorem of r . 
For example, if the formulas p, y, and y A 
p -+ a are all in r U A, 
then r k a ,  as is evidenced by the tree which displays how a was 

112 
A Mathematical Introduction to Logic 
obtained. Although it is tempting (and in some ways more elegant) to 
define a deduction to be such a tree, it will be simpler to take deductions 
to be the linear sequences obtained by squashing such trees into straight 
lines. 
Now at last we give the set A of logical axioms. These are arranged 
in six groups. Say that a wff (p is a generalization of @ iff for some 
n p 0 and some variables xl, . . . , x,, 
We include the case n = 0; any wff is a generalization of itself. The 
logical axioms are then all generalizations of wffs of the following 
forms, where x and y are variables and a and /3 are wffs: 
1. Tautologies; 
2. V x a -+ a:, where t is substitutable for x in a ;  
3. Vx(a + p) + (Vx a + Vx p); 
4. a + V x a, where x does not occur free in a. 
And if the language includes equality, then we add 
5. x = x ;  
6, x = y + (a + a'), where a is atomic and a' is obtained from a 
by replacing x in zero or more (but not necessarily all) places by y. 
For the most part groups 3-6 are self-explanatory; we will see var- 
ious examples later. Groups 1 and 2 require explanation. But first we 
should admit that the above list of logical axioms may not appear very 
natural. Later it will be possible to see where each of the six groups 
originated. 
Substitution 
In axiom group 2 we find 
V x a  +a:. 
Here a: is the expression obtained from the formula a by replacing the 
variable x, wherever it occurs free in a ,  by the term t .  This concept can 
also be (and for us officially is) defined by recursion: 
1. For atomic a, a: is the expression obtained from a by replacing 
the variable x by t . (This is elaborated upon in Exercise 1. Note that a: 
is itself a formula.) 
2. ( 1  a): = ( 1  a:). 
ifx = y, 
4, m a ) :  = {;;;:) 
ifx + y. 

Chapter 2 : First-Order Logic 
113 
1. q," = yJ. 
2. (Qx -r Vx Px); = (Qy -r Vx Px). 
3. I f a i s l V y x  =y,thenVxa-ra:is 
4. For s as in 3,Vxa +a; is 
The last example above illustrates a hazard which must be guarded 
against. On the whole, V x a --, a,X seems like a plausible enough axiom. 
("If a is true of everything, then it should be true oft .") But in Example 4, 
we have a sentence of the formV x a --, a j, which is nearly always false. 
The antecedent, Vx 1 
V y x = y, is true in any structure whose universe 
contains two or more elements. But the consequent, 7 V y y = y, is false 
in any structure. So something has gone wrong. 
The problem is that when y was substituted for x, it was immediately 
"captured" by the V y quantifier. We must impose a restriction on axiom 
group 2 that will preclude this sort of quantifier capture. Informally, we 
can say that a term t is not substitutable for x in a if there is some variable 
y in t that is captured by a V y quantifier in a:. The real definition is 
given below by recursion. (Since the concept will be used later in proofs 
by induction, a recursive definition is actually the most usable variety.) 
Let x be a variable, t a term. We define the phrase "t is substitutable 
for x in a" as follows: 
1. For atomic a ,  t is always substitutable for x in a. (There are no 
quantifiers in a ,  so no capture could occur.) 
2. t is substitutable for x in ( 1  a )  iff it is substitutable for x in a. t 
is substitutable for x in (a -r #3) iff it is substitutable for x in both a 
and #3. 
3. t is substitutable for x in V y a iff either 
(a) x does not occur free in V y a ,  or 
(b) y does not occur in t and t is substitutable for x in a. 
(The point here is to be sure that nothing in t will be captured by the 
V y prefix and that nothing has gone wrong inside a earlier.) 
For example, x is always substitutable for itself in any formula. If t 
contains no variables that occur in a, then t is substitutable for x in a. 
The reader is cautioned not to be confused about the choice of words. 
Even if t is not substitutable for x in a ,  still aj is obtained from a by 
replacing x wherever it occurs free by t. Thus in forming a;, we carry 
out the indicated substitution even if a prudent person would think it 
unwise to do so. 

114 
A Mathematical Introduction to Logic 
Axiom group 2 consists of all generalizations of formulas of the form 
where the term t is substitutable for the variable x  in the formula a. For 
example, 
is in axiomgroup 2. Here x  is vl, a is Avl + V w A w ,  andt is w .  On 
the other hand, 
is not in axiom group 2, since u;! is not substitutable for vl in V w Bvl w. 
Tautologies 
Axiom group 1 consists of generalizations of formulas to be called 
tautologies. These are the wffs obtainable from tautologies of sentential 
logic (having only the connectives 1 and -+) by replacing each sentence 
symbol by a wff of the first-order language. For example, 
belongs to axiom group 1. It is a generalization of the formula in square 
brackets, which is obtained from a contraposition tautology 
by replacing A by V y  1 P y  and B by P x .  
There is another, more direct, way of looking at axiom group 1. 
Divide the wffs into two groups: 
1. The prime formulas are the atomic formulas and those of the form 
V x  a. 
2. The nonprime formulas are the others, i.e., those of the form 1 
a! 
Ora!+p. 
Thus any formula is built up from prime formulas by the operations 
E, and &,. 
Now go back to sentential logic, but take the sentence 
symbols to be the prime formulas of our first-order language. Then any 
tautology of sentential logic (that uses only the connectives 1, +) is in 
axiom group 1. There is no need to replace sentence symbols here by 
first-order wffs; they already are first-order wffs. Conversely, anything 
in axiom group 1 is a generalization of a tautology of sentential logic. 
(The proof of this uses Exercise 8 of Section 1.2.) 
EXAMPLE, revisited. 
( Q y - P y  --, 1 P x )  + ( P x  --, 1 V y 1  Py). 

Chapter 2: 
First-Order Logic 
115 
This has two sentence symbols (prime formulas), V y 1 
Py and Px. 
So its truth table has four lines: 
( V y l P y  --, 1 P x )  --, (Px --, 1 V y 1 P y )  
T  
F F T  T 
T  F F T  
T  
T T F  T 
F  T F T  
F  
T F T  T 
T  T T F  
F  
T  T F  T 
F  T  T F  
From the table we see that it is indeed a tautology. 
On the other hand, neither Vx(Px --, Px) nor Vx Px --, Px is 
a tautology. 
One remark: We have not assumed that our first-order language has 
only countably many formulas. So we are potentially employing an 
extension of Chapter 1 to the case of an uncountable set of sentence 
symbols. 
A second remark: Taking all tautologies as logical axioms is overkill. 
We could get by with much less, at the expense of lengthening deduc- 
tions. On the one hand, the tautologies form a nice decidable set (the 
decidability will be important for the enumerability theorem in Sec- 
tion 2.5). On the other hand, there is no known fast decision procedure 
for tautologies, as noted in Section 1.7. One option would be to cut 
axiom group 1 down to a set of tautologies for which we do know de- 
cision procedures that are fast (the technical term is "polynomial-time 
decidable"). The other tautologies would then be obtainable from these 
by use of modus ponens. 
A third remark: Now that first-order formulas are also wffs of sen- 
tential logic, we can apply concepts from both Chapters 1 and 2 to them. 
If r tautologically implies p, then it follows that r also logically im- 
plies p. (See Exercise 3,) But the converse fails. For example, V x Px 
logically implies PC. But V x Px does not tautologically imply PC, as 
Vx Px and PC are two different sentence symbols. 
THEOREM 
24B r I- p iff r U A tautologically implies p. 
PROOF. (+): This depends on the obvious fact that {a, a --, p )  
tautologically implies p. Suppose that we have a truth assignment 
v that satisfies every member of r U A. By induction we can see 
that v satisfies any theorem of r. The inductive step uses exactly 
the above-mentioned obvious fact. 
(+): Assume that r U A tautologically implies p. Then by 
the corollary to the compactness theorem (for sentential logic), 
there is a finite subset { yl , . . . , y, , hl , . . . , A,) that tautologically 
implies p . Consequently, 

116 
A Mathematical Introduction to Logic 
is a tautology (cf. Exercise 4 of Section 1.2) and hence is in A. 
By applying modus ponens rn + n times to this tautology and to 
{yl, . . . , ym, Al, . . . , A,} we obtain q. 
-I 
(The above proof is related to Exercise 7 in Section 1.7. It uses 
sentential compactness for a possibly uncountable language.) 
Deductions and Metatheorems 
We now have completed the description of the set A of logical axioms. 
The set of theorems of a set r is the set built up from r U A by modus 
ponens. For example, 
(Here r = 0 ;  we write "F a" in place of "0 F a.") The formula 
P x  --, 3 y  P y  can be obtained by applying modus ponens (once) to two 
members of A, as displayed by the pedigree tree: 
(in axiom group 2) 
( V y  1 P y  + 1 P x )  + (Px + - I v y - P y )  
(in axiom group 1) 
We get a deduction of P x  --+ 3 y  P y  (from 0 )  by compressing this 
tree into a linear three-element sequence. 
As a second example, we can obtain a generalization of the formula 
in the first example: 
I- V x ( P x  4 
y  P y ) .  
This fact is evidenced by the following tree, which displays the con- 
struction of V x ( P x  --, 3 y  P y )  from A by modus ponens: 
V x ( V y  1 P y  + 1 P x )  
(in axiom group 2) 
(a member of axiom group 3) 
/' 
V x [ ( V y  1 P y  + 1 P x )  + (Px + 1Vy1Py)l 
(in axiom group 1) 

Cha~ter 2: 
First-Order Logic 
Again we can compress the tree into a deduction. 
In these examples the pedigree trees may seem to have been pulled 
out of the air. But we will shortly develop techniques for generating 
such trees in a somewhat systematic manner. These techniques will 
rely heavily on the generalization theorem and the deduction theorem 
below. 
Notice that we use the word "theorem" on two different levels. We say 
that a is a theorem of r if r I- a. We also make numerous statements 
in English, each called a theorem, such as the one below. It seems 
unlikely that any confusion will arise. The English statements could 
have been labeled metatheorems to emphasize that they are results about 
deductions and theorems. 
The generalization theorem reflects our informal feeling that if we 
can prove -x - 
without any special assumptions about x, we then are 
entitled to say that "since x was arbitrary, we have V x -x-. 
11 
45 
GENERALIZATION 
THEOREM If r I- (p and x dohnot occur free in any 
formula in r, then r I- V x (p. 
PROOF. Consider a fixed set r and a variable x not free in r .  We 
will show by induction that for any theorem (p of r ,  we have 
r I- V x (p. For this it suffices (by the induction principle) to show 
that the set 
includes r U A and is closed under modus ponens. Notice that x 
can occur free in (p. 
Case 1 : (p is a logical axiom. Then V x (p is also a logical axiom. 
Andso r k V x p .  
Case 2: (p E r. Then x does not occur free in (p. Hence 
is in axiom group 4. Consequently, r I- V x  (p, as is evidenced by 
the tree: 
(in r )  
(in axiom group 4) 
Case 3: (p is obtained by modus ponens from @ and @ 
(p. Then by inductive hypothesis we have r I- Vx @ and r I- 
Vx(@ --+ (p). This is just the situation in which axiom group 3 is 
useful. That r k Vx (p is evidenced by the tree: 

118 
A Mathematical Introduction to Logic 
(in axiom group 3) 
So by induction I' I- Vx q for every theorem q of r. 
(The sole reasons for having axiom groups 3 and 4 are indicated by 
the above proof.) 
The restriction that x not occur free in r is essential. For example, 
Px i+ 
V x Px, and so by the soundness theorem to appear in Section 2.5, 
PX F Vx Px. On the other hand, x will in general occur free in the 
formula q. For example, at the beginning of this subsection we showed 
first that 
k (Px -+ 3 y Py). 
The second example there, 
I- Vx(Px + 3 y Py), 
was obtained from the first example as in case 3 of the above proof. 
The proof of the generalization theorem actually yields somewhat 
more than was stated. It shows how we can, given a deduction of q from 
r ,  effectively transform it to obtain a deduction of Vx q from r. 
LEMMA 24C (RULE T) 
If r I- a l ,  . . . , I' I- a, and {al, . . . , a,) tau- 
tologically implies #I, then r k p. 
PROOF. a1 + . . . --+ a, + #I is a tautology, and hence a logical 
axiom. Apply modus ponens n times. 
-I 
DEDUCTION 
THEOREM If l'; y I- q, then r I- (y -+ q). 
(The converse clearly holds also; in fact, the converse is essentially 
the rule modus ponens.) 
r; y I- q 
iff ( r ;  y) U A tautologically implies q, 
iff r U A tautologically implies (y --+ p), 
iff r I-(y +q). 

Chapter 2 : First-Order Logic 
119 
SECOND PROOF The second proof does not use the compactness the- 
orem of sentential logic as does the first proof. It shows in a direct 
way how to transform a deduction of (p from r; y to obtain a de- 
duction of (y + (p) from r. We show by induction that for every 
theorem (p of r ; y the formula ( y + (p) is a theorem of r . 
Case 1: (p = y. Then obviously I- (y + (p). 
Case 2: (p is a logical axiom or a member of r .  Then r I- (p. 
And (p tautologically implies (y + 
(p), whence by rule T we have 
r I- (Y + PI. 
Case 3 : (p is obtained by modus ponens from + and + + 
(p. By 
the inductive hypothesis, r I- (y + +) and r I- (y + (+ + 
(p)). 
And the set { y + +, y + (+ + 
(p)} tautologically implies y +(p. 
Thus, by rule T, r I- (y + (p). 
So by induction the conclusion holds for any (p deducible from 
r; y. 
-I 
COROLLARY 
24D (CONTRAPOSITION) r; (p I- 1 + iff r; I- 1 
(p. 
; (p I- 1 + =+ 
k (p + 1 + by the deduction theorem, 
I
-
 
byruleT, 
=+ r; + I- 1 
(p 
by modus ponens. 
(In the second step we use the fact that (p + 1 + tautologically 
implies + + 1 
(p.) By symmetry, the converse holds also. 
-I 
Say that a set of formulas is inconsistent iff for some #?, both #? and 
-I #? are theorems of the set. (In this event, any formula a! is a theorem 
of the set, since #? + 1 
#? + a! is a tautology.) 
COROLLARY 
24E (REDUCTIO 
AD ABSURDUM) If r; (p is inconsistent, 
then r k 1 
(p. 
PROOF. From the deduction theorem we have r k ((p + p) and 
r k ((p + 1 
#?). And {(p + #?, 
(p + 1 
#?) tautologically implies 
l 
qa. 
-I 
EXAMPLE. I-3xVy(p+Vy3x(p. 
There are strategic advantages to working backward. 
It suffices to show that 3 x V y (p I- V y 3 x (p, by the deduction 
theorem. 

A Mathematical Introduction to L o ~ i c  
It suffices to show that 3 x V  y q 
3 x q, by the generalization 
theorem. 
It suffices to show that 1 V x  1 V y q  I- 1 V x  i q ,  as this is the 
same as the preceding. 
It suffices to show that V  x -I q I- V  x -I V  y q, by contraposition 
(and rule T). 
It suffices to show that V x  7 q I- 1 V  y q, by generalization. 
It suffices to show that {V x 1 q, V  y q) is inconsistent, by reductio 
ad absurdum. 
And this is easy: 
1. V  x -I q I- 1 q by axiom group 2 and modus ponens. 
2. V  y q I- q for the same reason. 
Lines 1 and 2 show that {Vx 1 
q, V y q} is inconsistent. 
Strategy 
As the preceding example indicates, the generalization and deduction 
theorems (and to a smaller extent the corollaries) will be very useful 
in showing that certain formulas are deducible. But there is still the 
matter of strategy: For a given r and q, where should one begin in 
order to show that r k q? One could, in principle, start enumerating 
all finite sequences of wffs until one encountered a deduction of q 
from r. Although this would be an effective procedure (for reasonable 
languages) for locating a deduction if one exists, it is far too inefficient 
to have more than theoretical interest. 
One technique is to abandon formality and to give in English a proof 
that the truth of r implies the truth of q. Then the proof in English can 
be formalized into a legal deduction. (In the corning pages we will see 
techniques for carrying out such a formalization in a reasonably natural 
way.) 
There are also useful methods based solely on the syntactical form 
of q. Assume then that q is indeed deducible from r but that you are 
seeking a proof of this fact. There are several cases: 
1. Suppose that q is (@ --+ 8). Then it will suffice to show that 
r ;  + I- 8 (and this will always be possible). 
2. Suppose that q is Vx +. If x does not occur free in r, then it 
will suffice to show that r I- @. (Even if x should occur free in r, the 
difficulty can be circumvented. There will always be a variable y such 
that r I- V  y @; 
and V  y +; k V X  +. See the re-replacement lemma, 
Exercise 9.) 
3. Finally, suppose that q is the negation of another formula. 
3a. If q is i ( +  -+ O), then it will suffice to show that r k + and 
r I- -I 8 (by rule T). And this will always be possible. 
3b. If q is 1 1 
@, then of course it will suffice to show that r I- @. 

Chapter 2 : First-Order Logic 
3c. The remaining case is where p is 1 
Vx +. It would suffice to 
show that r I- 
1 I++:, where t is some term substitutable for x in @. 
(Why?) Unfortunately this is not always possible. There are cases in 
which 
and yet for every term t, 
(One such example is r = 0, + = 1 
(Px + V y Py).) Contraposition 
is handy here; 
iff 
(A variation on this is: r; V y a  k 1 V x  @ if r; Vx 11. I- 
l a . )  If all 
else fails, one can try reductio ad absurdum. 
EXAMPLE (Q~A). If x does not occur free in a ,  then 
To prove this, it suffices (by rule T) to show, that 
and 
For the first of these, it suffices (by the deduction and generaliza- 
tion theorems) to show that 
{(a +Vx B), a1 I- B. 
But this is easy; Vx #I --+ #? is an axiom. 
To obtain the converse, 
it suffices (by the deduction and generalization theorems) to show 
that 
{Qx(a + B), a )  I- B. 
This again is easy. 
In the above example we can replace a by 1 
a, #I by 1 
#?, 
and use 
the contraposition tautology (among other things) to obtain the related 
fact: 

122 
A Mathematical Introduction to Lonic 
(Q3e). If x does not occur free in a ,  then 
The reader might want to convince him- or herself that the above 
formula is valid. 
Frequently an abbreviated style is useful in writing down a proof of 
deducibility, as in the following example. 
In line 1, "Ax 6" means that the formula belongs to axiom group 6. 
In line 3, "1,2; T" means that this line is obtained from lines 1 and 2 by 
rule T. In line 4, "3; gen2" means that the generalization theorem can be 
applied twice to line 3 to yield line 4. In the same spirit we write "MP," 
"ded," and "RAA" to refer to modus ponens, the deduction theorem, 
and reductio ad absurdurn, respectively. 
It must be emphasized that the four numbered lines above do not 
constitute a deduction of Vx Vy(x = y + y = x). Instead they form 
a proof (in the meta-language we continue, with little justification, 
to call English) that such a deduction exists. The shortest deduction 
of Vx V y(x = y + y = x) known to the author is a sequence of 
17 formulas. 
1. I- x = y + Pxz + Pyz. Ax 6. 
2. I- Vz Pxz + Pxz. Ax 2. 
3. I- x = y + Vz Pxz + Pyz. 1,2; T. 
4. {X = y, vz PXZ} I- PYZ. 3; M P ~ .  
5. {x = y, Vz Pxz) I- Vz Pyz. 4; gen. 
6. I - x = y + V z P x z + V z ~ ~ z . 5 ; d e d ~ .  
EXAMPLE (EQ~). Let f be a two-place function symbol. Then 
PROOF. TLtVo members of axiom group 6 are 

Chapter 2: 
First-Order Logic 
123 
From V x x = x (in axiom group 5) we deduce 
f x1x2 = f ~1x2. 
The three displayed formulas tautologically imply 
x1 = Y1 -+x2 = Y2 -+ fx1x2 = fy1y2. 
(a) (Vx(Px + Qx), Vz Pz} I- Qc. It is not hard to show that 
such a deduction exists. The deduction itself consists of seven 
formulas. 
(b) {Vx(Px + Qx), Vz Pz) I- Qy. This is just like (a). The 
point we are interested in here is that we can use the same seven- 
element deduction, with c replaced throughout by y. 
(c) (Vx(Px --+ Qx), Vz Pz) I- 
V y Qy. This follows from 
(b) by the generalization theorem. 
(d) (Vx(Px -+ Qx), Vz Pz) k Vx Qx. This follows from 
(c) by use of the fact that V y Qy I- V x Qx . 
Parts (a) and (b) of the foregoing example illustrate a sort of inter- 
changeability of constant symbols with free variables. This interchange- 
ability is the basis for the following variation on the generalization 
theorem, for which part (c) is an example. Part (d) is covered by Corol- 
lary 24G. (p; is, of course, the result of replacing c by y in (p. 
THEOREM 
24F (GENERALIZATION 
ON CONSTANTS) 
Assume that r I- (p 
and that c is a constant symbol that does not occur in r. Then there 
is a variable y (which does not occur in (p) such that r I- V y (p;. 
Furthermore, there is a deduction of V y (p; from r in which c 
does not occur. 
PROOF. Let (ao, . . . , a,) be a deduction of (p from r. (Thus a, = 
(p.) Let y be the first variable that does not occur in any of the ai's. 
We claim that 
is a deduction from r of (p;. 
So we must check that each (ak); is 
in r U A or is obtained from earlier formulas by modus ponens. 
Case 1: a k  E r. Then c does not occur in a k .  So (ak); = ak, 
which is in r. 
Case 2: at is a logical axiom. Then (ak); is also a logical 
axiom. (Read the list of logical axioms and'note that introducing 
a new variable will transform a logical axiom into another one.) 
Case 3: a k  is obtained by modus ponens from ai and a j (which 
is (ai + ak)) for i, j less than k. Then (aj); = ((ai); + (ak);). 
So (ak); is obtained by modus ponens from (ai); and (a j);. 

124 
A Mathematical Introduction to Logic 
This completes the proof that (*) above is a deduction of (p;. 
Let Q, be the finite subset of r that is used in (*). Thus (*) is 
a deduction of (p; from Q,, and y does not occur in Q,. So by 
the generalization theorem, @ I- V y 40;. 
Furthermore, there is a 
deduction of V y (p; from @ in which c does not appear. (For the 
proof to the generalization theorem did not add any new symbols 
to a deduction.) This is also a deduction from r of V y (p;. 
-I 
We will sometimes want to apply this theorem in circumstances in 
which not just any variable will do. In the following version, there is a 
variable x selected in advance. 
COROLLARY 
24G Assume that r I- 
(p:, 
where the constant symbol 
c does not occur in r or in (p. Then r I- 
Vx (p, and there is a 
deduction of Vx (p from r in which c does not occur. 
PROOF. By the above theorem we have a deduction (without c) from 
r of V y(((pt)i), where y does not occur in (p:. 
But since c does 
not occur in (p, 
(v:)', 
= 60;. 
It remains to show that V y (p; 
I- Vx (p. We can easily do this if 
we know that 
is an axiom. That is, x must be substitutable for y in (p;, 
and 
(lo;): 
must be (p. This is reasonably clear; for details see the 
re-replacement lemma (Exercise 9). 
-1 
COROLLARY 
24H (RULE El) Assume that the constant symbol c does 
not occur in (p, @, or r ,  and that 
Then 
and there is a deduction of @ from r ;  3 x (p in which c does not 
occur. 
PROOF. By contraposition we have 
r ;  * k 19:. 
So by the preceding corollary we obtain 
r ; l g I - v x l q .  
Applying contraposition again, we have the desired result. 
-I 

Chapter 2: 
First-Order Logic 
125 
"EI" stands for "existential instantiation," a bit of traditional termi- 
nology. 
We will not have occasion to use rule EI in any of our proofs, but it 
may be handy in exercises. It is the formal counterpart to the reasoning: 
'We know there is an x such that - 
x -. So call it c. Now from - 
c - 
we can prove @." But notice that rule EI does not claim that 3 x (p I- (p:, 
which is in fact usually false. 
EXAMPLE, revisited. I- 3 x V y (p -+ V y 3 x (p. 
By the deduction theorem, it suffices to show that 
By rule EI it suffices to show that 
where c is new to the language. By the generalization theorem it 
suffices to show that 
Since V y (p,X F (p:, 
it suffices to show that 
By contraposition this is equivalent to 
which is trivial (by axiom group 2 and modus ponens). 
We can now see roughly how our particular list of logical axioms 
was formed. The tautologies were included to handle the sentential 
connective symbols. (We could economize considerably at this point by 
using only some of the tautologies.) Axiom group 2 reflects the intended 
meaning of the quantifier symbol. Then in order to be able to prove the 
generalization theorem we added axiom groups 3 and 4 and arranged 
for generalizations of axioms to be axioms. 
Axiom groups 5 and 6 will turn out to be just enough to prove the 
crucial properties of equality; see the subsection on equality. 
As we will prove in Section 2.5, every logical axiom is a valid for- 
mula. It might seem simpler to use as logical axioms the set of all valid 
formulas. But there are two (related) objections to doing this. For one, 
the concept of validity was defined semantically. That is, the definition 
referred to possible meanings (i.e., structures) for the language and to 
the concept of truth in a structure. For our present purposes (e.g., proving 
that the validities are effectively enumerable) we need a class A with 
a finitary, syntactical definition. That is, the definition of A involves 
only matters concerning the arrangement of the symbols in the logical 
axioms; there is no reference to matters of truth in structures. A second 

126 
A Mathematical Introduction to Logic 
objection to the inclusion of all valid formulas as axioms is that we 
prefer a decidable set A, and the set of validities fails to be decidable. 
~lphabetic Variants 
Often when we are discussing a formula such as 
we are not interested in the particular choice of the variables x and y. 
We want (x, y) to be a pair of distinct variables, but often it makes no 
difference whether the pair is (v4, v) 
or (v8, vl ) . 
But when it comes time to substitute a term t into a formula, then 
the choice of quantified variables can make the difference between the 
substitutability of t and its failure. In this subsection we will discuss 
what to do when substitutability fails. As will be seen, the difficulty can 
always be surmounted by suitably juggling the quantified variables. 
For example, suppose we want to show that 
I - v x v y  Pxy + v y  Pyy. 
There is the difficulty that y is not substitutable for x in V y Pxy, so 
the above sentence is not in axiom group 2. This is a nuisance resulting 
from an unfortunate choice of variables. For example, showing that 
k v x v z  Pxz + v y  Pyy 
involves no such difficulties. So we can solve our original problem if 
we know that 
k v x v y  Pxy + v x v z  Pxz, 
which, again, involves no difficulties. 
This slightly circuitous strategy (of interpolating Vx Vz Pxz be- 
tween V x V y Pxy and V y Pyy) is typical of a certain class of prob- 
lems. Say that we desire to substitute a term t for x in a wff q. If t is, 
in fact, not so substitutable, then we replace Vx q by V x q', where t is 
substitutable for x in q'. In the above example q is V y Pxy and qp' is 
V z Pxz. In general q' will differ from q only in the choice of quantified 
variables. But q' must be formed in a reasonable way so as to be logi- 
cally equivalent to q. For example, it would be unreasonable to replace 
Vy P x y b y  Vx Pxx,orVyVzQxyzbyVzVzQxzz. 
THEOREM 
241 (EXISTENCE 
OF ALPHABETIC 
VARIANTS) Let q be a for- 
mula, t a term, and x a variable. Then we can find a formula q' 
(which differs from q only in the choice of quantified variables) 
such that 
(a) q I- q' andq' k q; 
(b) t is substitutable for x in q'. 

Chapter 2: First-Order Logic 
127 
PROOF. We consider fixed t and x, and construct (pl by recursion on 
(p. The first cases are simple: For atomic (p we take (p' = (p, and 
then (1 
(p)' = (7 
(p'), ((p --, @)' = ((pl + 
@ I ) .  But now consider 
the choice of ( V y (p)'. 
If y does not occur in t ,  or if y = x, then we can just take 
(V y (p)' = V y (p'. But for the general case we must change the 
variable. 
Choose a variable z that does not occur in (p' or t or x .  Then 
define (V y (p)' = Vz((pl),Y. To verify that (b) holds, we note that 
z does not occur in t and t is substitutable for x in gp' (by the 
inductive hypothesis). Hence (since x # z) t is also substitutable 
for x in ( P I ) : .  
To verify that (a) holds, we calculate: 
(P k (P' 
by the inductive hypothesis; 
:.Vy (p I- v y  (pl. 
Y 40' I- ((PI): 
since z does not occur in (p'; 
:- 
V y (p' k V z((p'); 
by generalization; 
:. v y (p I- v z((p');. 
In the other direction, 
V
)
 
I- 
( ( ( p ) ) ,  
which is (p' by Exercise 9; 
(pl I- 
(p; 
by the inductive hypothesis; 
:.Vz((p'),Y I- (p 
:. V z((p1); I- V y (p 
by generalization. 
The last step uses the fact that y does not occur free in ((p'),Y unless 
y = z, and so does not occur free in V z((pl); in any case. 
-I 
The formulas (p' constructed as in the proof of this theorem will be 
called alphabetic variants of (p. The moral of the theorem is: One should 
not be daunted by failure of substitutability; the right alphabetic variant 
will avoid the difficulty. 
Equality 
We list here (assuming that our language includes =) the facts about 
equality that will be needed in the next section. First, the relation defined 
by vl = is reflexive, symmetric, and transitive (i.e., is an equivalence 
relation): 
Eql: 
I- V x x  = x .  
PROOF. Axiom group 5. 

128 
A Mathematical Introduction to Logic 
PROOF. Page 122. 
PROOF. Exercise 11. 
In addition, we will need to know that equality is compatible with 
the predicate and function symbols: 
Eq4 (for a two-place predicate symbol P): 
I- Vx1 Vx2 v y1 v y2(x1 = y1 -' x2 = y2 -' Px1x2 -' Py1y2). 
Similarly for n-place predicate symbols. 
PROOF. It suffices to show that 
(x1 = Yl, X2 = Y2, Px1x2) 1- Py1y2. 
This is obtained by application of modus ponens to the two mem- 
bers of axiom group 6: 
Eq5 (for a two-place function symbol f ): 
Similarly for n-place function symbols. 
PROOF. Page 122. 
Final Comments 
A logic book in the bootstrap tradition might well begin with this section 
on a deductive calculus. Such a book would first state the logical axioms 
and the rules of inference and would explain that they are acceptable to 
reasonable people. Then it would proceed to show that many formulas 
were deducible (or deducible from certain nonlogical axioms, such as 
axioms for set theory). 
Our viewpoint is very different. We study, among other things, the 
facts about the procedure described in the preceding paragraph. And 
we employ in this any correct mathematical reasoning, whether or not 
such reasoning is known to have counterparts in the deductive calculus 
under study. 
Figure 8 is intended to illustrate the separation between (a) the level 
at which we carry out our reasoning and prove our results, and (b) the 
level of the deductive calculus which we study. 

Chapter 2: 
First-Order Logic 
The study. in English, of the view below: 
Ir rba, then r k v ,  
r ; a t - & ~ - @ - r t - a  
h V x 7 S x  -0 
b W P x  -L VxPx) 
%(Px 4 Vx Px) 
Figure 8. The meta-language above, in which we study the object 
language below, 
Exercises 
1. For a term u, let u-;i be the expression obtained from u by replacing 
the variable x by the term r .  Restate this definition without using 
any form of the word "replace" or its synonyms. Suggestion: Use 
recursion on u. (Observe that from the new definition it is clear that 
u; is itself a term.) 
2. To which axiom groups, if any, do each of the following formulas 
belong? 
(a) [(VxPx+Vy Py)+Pz]+[Vx 
Px+(Vy Py-+Pz)]. 
(b) V y[Vx(Px + Px) + (PC + PC)]. 
(c) v x 3 y  Pxy + 3 y  Pyy. 
3. (a) Let U be a structure and let s : V -+ IUI. Define a truth assign- 
ment v on the set of prime formulas by 
v(a) = T 
iff 

130 
A Mathematical Introduction to Logic 
Show that for any formula (prime or not), 
- 
v(a) = T iff 
ka a[s]. 
Remark: This result reflects the fact that -I and + were treated 
in Chapter 2 the same way as in Chapter 1. 
(b) Conclude that if r tautologically implies (p, then r logically 
implies (p. 
4. Give a deduction (from 0) of Vx (p -) 3 x (p. (Note that you should 
not merely prove that such a deduction exists. You are instead asked 
to write out the entire deduction.) 
5. Find a function f such that if a formula (p has a deduction of length 
n from a set r , and if x does not occur free in r , then V x (p has a 
deduction from r of length f (n). The more slowly your function 
grows, the better. 
6. (a) Show that if I- a --t #3, then I- Vx a -) Vx #3. 
(b) Showthatitisnotingeneraltruethata+#3 
t== Vxa+Vx #3. 
7. (a) Show that I- 3x(Px +Vx Px). 
(b) Show that {Qx, V y(Qy + Vz Pz)} I- Vx Px. 
8. (Q2b) Assume that x does not occur free in a. Show that 
Also show that, under the same assumption, we have Q3a: 
9. (Re-replacement lemma) (a) Show by example that ((p;): 
is not in 
general equal to (p. And that it is possible both for x to occur in 
(9;): 
at a place where it does not occur in (p, and for x to occur in 
(O at a place where it does not occur in ((p;):. 
(b) Show that if y does not occur at all in (p, then x is substitutable 
for y in (p; and ((p;): 
= (p. Suggestion: Use induction on (o. 
10. Show that 
v x v y  Pxy I- v y v x  Pyx. 
11. (Eq3) Show that 
12. Show that any consistent set r of formulas can be extended to a 
consistent set A having the property that for any formula a ,  either 
a E A or ( l a )  E A. (Assume that the language is countable. Do 
not use the compactness theorem of sentential logic.) 
13. Show that I- Py *Vx(x = y --t Px). 
Remarks: More generally, if t is substitutable for x in (p and x 
does not occur in t, then 

Cha~ter 2: 
First-Order Logic 
Thus the formula Vx(x = t -+ p) offers an alternative of sorts to 
the substitution p,X. 
14- Show that I- (Vx((1 Px) + Qx) -, Vy((7 Qy) + Py)). 
15. Show that deductions (from 0 )  of the following formulas exist: 
(a) 3 x a  V 3 x  p * 3 x ( a  V p). 
(b) V x a  V V X P  +Vx(a Vp). 
16. Show that deductions (from 0) of the following formulas exist: 
(a) 3 x ( a A P ) + 3 x a A 3 x j 3 .  
(b) V x ( a r \ ~ ) * V x a A V x p .  
17, Show that deductions (from 0 )  of the following formulas exist: 
(a) Vx(a +/I) + ( 3 x a  + 3 x p ) .  
(b) 3x(Py A Qx) * Py A 3 x  Qx. 
SECTION 2.5 
Soundness and Completeness Theorems 
In this section we establish two major theorems: the soundness of our 
deductive calculus ( r  I- p + r + p) and its completeness ( r  + 
p =+ r I- p). We will then be able to draw a number of interesting 
conclusions (including the compactness and enumerability theorems). 
Although our deductive calculus was chosen in a somewhat arbitrary 
way, the significant fact is that some such deductive calculus is sound 
and complete. This should be encouraging to the "working mathemati- 
cian" concerned about the existence of proofs from axioms; see the 
Retrospectus subsection of Section 2.6. 
SOUNDNESS THEOREM If r I- p, then r + p. 
The soundness theorem tells that our deductions lead only to "cor- 
rect" conclusions - 
deductions would be rather pointless otherwise! 
The idea of the proof is that the logical axioms are logically implied by 
anything, and that modus ponens preserves logical implications. 
LEMMA 25A Every logical axiom is valid. 
PROOF 
OF THE SOUNDNESS THEOREM, 
ASSUMING 
THE LEMMA. We show 
by induction that any formula p deducible from r is logically im- 
plied by r. 
Case 1: p is a logical axiom. Then by the lemma + p, so a 
fortiori r + p. 
Case 2: p E r. Then clearly r + p. 
Case 3: p is obtained by modus ponens from @ and @ --+ p, 
where (by the inductive hypothesis) r + @ and r k (@ --+ p). 
It then follows at once that r + p. 
-I 

132 
A Mathematical Introduction to Logic 
It remains, of course, to prove that lemma. We know from Exercise 6 
of Section 2.2 that any generalization of a valid formula is valid. So it 
suffices to consider only logical axioms that are not themselves gener- 
alizations of other axioms. We will examine the various axiom groups 
in order of complexity. 
Axiom group 3: See Exercise 3 of Section 2.2. 
Axiom group 4: See Exercise 4 of Section 2.2. 
Axiom group 5: Trivial. !A satisfies x = x with s iff s(x) = s(x), 
which is always true. 
Axiom group 1 :  We know from Exercise 3 of the preceding section 
that if 0 tautologically implies a ,  then 0 + a. And that is just what we 
need. 
Axiom group 6 (for an example, see Exercise 5 of Section 2.2): As- 
sume that a is atomic and a' is obtained from a by replacing x at some 
places by y. It suffices to show that 
{X = y, a} + a'. 
So take any !A, s such that 
Then any term t has the property that if t' is obtained from t by replacing 
x at some places by y, then f(t) = Z(r'). This is obvious; a full proof 
would use induction on t. 
If a is tl = t2, then a' must be ti = t;, where ti' is obtained from 9 as 
described. 
+!a 4
~
1
 
iff Wl) = S(t2), 
iff f(ti) = ;(ti), 
iff 
af[s]. 
Similarly, if a is Ptl . . t,, then a' is Pti . . t; and an analogous 
argument applies. 
Finally, we come to axiom group 2. It will be helpful to consider first 
a simple case: we will show that Vx Px --+ P t  is valid. Assume that 
Then for any d in [!A[, 
So in particular we may take d = f(t): 
This is equivalent (by the definition of satisfaction of atomic formulas) 
to 
S(t) E pa, 

Cha~ter 2: 
First-Order Logic 
133 
which in turn is equivalent to 
For this argument to be applicable to the nonatomic case, we need a 
way of passing from (a) to (b). This will be provided by the substitution 
lemma below, which states that 
l=r# (p[s(x I W))l iff l=a (p,X[sl 
whenever t is substitutable for x in (p. 
Consider a fixed !2l and s. For any term u, let u: be the result of 
replacing the variable x in u by the term t. 
This looks more complicated than it is. It asserts that a substitution 
can be carried out either in the term u or in s, with equivalent results. 
The corresponding commutative diagram is shown. 
substitution 
terms 
+ terms 
of t for x 
I'lrl 
PROOF. By induction on the term u. If u is a constant symbol or 
a variable other than x, then uf = u and the desired equation 
reduces to T(u) = Y(u). If u = x, then the equation reduces to 
T(t) = Z(t). The inductive step, although cumbersome to write, 
is mathematically trivial. 
-I 
The substitution lemma is similar in spirit; it states that a substitution 
can be carried out either within (p or in s, with equivalent results. For 
an example see Exercise 10 of Section 2.2. 
SUBSTITUTION LEMMA If the term t is substitutable for the variable x 
in the wff q, then 
l=a (p,"[sl iff l=a ~ [ s ( x  
I s(t))l. 
PROOF. We use induction on (p to show that the above holds for 
every s. 
Case 1: (p is atomic. Then the conclusion follows from the 
preceding lemma. For example, if (p is Pu for some term u, then 
Pu:[s] iff Z(uf) E P", 
iff s (x 1 Y(t)) (u) E Pa 
by Lemma 25B, 
iff +a Pu[s(x I s(t))]. 

134 
A Mathematical Introduction to Logic 
Case 2: q is 1 
@ or @ + 8. Then the conclusion for q follows 
at once fiom the inductive hypotheses for @ and 8. 
Case 3: q is V y @, and x does not occur free in q. Then s and 
s(x I T(t)) agree on all variables that occur free in q. And also q,X 
is simply q. So the conclusion is immediate. 
Case 4: q is V y @, and x does occur free in q. Because t is 
substitutable for x in q, we know that y does not occur in t and t 
is substitutable for x in @ (see the definition of "substitutable"). 
By the first of these, 
for any d in I%[. Since x # y, q,X = Vy @,X. 
V; rsi 
iff for every d ,  
+ , ~ r s ( ~  
I d)i, 
iff for every d, +a @ [S(Y I d) (x I T(t))l by 
the inductive hypothesis and (*), 
iff +a ~ S ( X  
I S(t))l. 
So by induction the lemma holds for all q. 
hiom group 2: Assume that t is substitutable for x in q. Assume 
that U satisfies Vx q with s. We need to show that 
9: [s]. We know 
that for any d in I%[, 
In particular, let d = T(t): 
+a ds(x I T(t))l, 
So, by the substitution lemma, 
+a q," rs1. 
Hence Vx q + q,X is valid. 
This completes the proof that all logical axioms are valid. And so the 
soundness theorem is proved. 
COROLLARY 
25C If I- (q ++ @), then q and @ are logically equiva- 
lent. 
COROLLARY 
25D If q' is an alphabetic variant of q (see Theo- 
rem 24I), then q and q' are logically equivalent. 
Recall that a set r is consistent iff there is no formula q such that 
both r I- q and r I- 1 
q. Define r to be satisJiable iff there is some U 
and s such that U satisfies every member of r with s. 
COROLLARY 
25E If F is satisfiable, then r is consistent. 
This corollary is actually equivalent to the soundness theorem, as the 
reader is invited to verify. 

Chapter 2: 
First-Order Logic 
135 
The completeness theorem is the converse to the soundness theorem 
and is a deeper result. 
(a) If r + rg,then r I- rg. 
(b) Any consistent set of formulas is satisfiable. 
Actually parts (a) and (b) are equivalent; cf. Exercise 2. So it suffices 
to prove part (b). We will give a proof for a countable language; later 
we will indicate what alterations are needed for languages of larger 
cardinality. (A countable language is one with countably many symbols, 
or equivalently, by Theorem OB, one with countably many wffs.) 
The ideas of the proof are related to those in the proof of the com- 
pactness theorem for sentential logic. We begin with a consistent set r. 
In steps 1-3 we extend r to a set A of formulas for which 
(i) r 
A. 
(ii) A is consistent and is maximal in the sense that for any formula 
a, eithera E A or(1a) E A. 
(iii) For any formula rg and variable x, there is a constant c such that 
Then in step 4 we form a structure M in which members of r not 
containing = can be satisfied. IUI is the set of terms, and for a predicate 
symbol P, 
(tl, ..., tn) E P' 
iff 
P t l . . . ~  
E A. 
Finally, in steps 5 and 6 we change U to accommodate formulas con- 
taining the equality symbol. 
It is suggested that on a first reading the details which are provided 
for most of the steps be omitted. Once the outline is clearly in mind, the 
entire proof should be read. (The nondetails are marked with a stripe in 
the left margin.) 
I PROOF, Let r be a consistent set of wffs in a countable language. 
STEP 1 : Expand the language by adding a countably infinite set of 
new constant symbols. Then r remains consistent as a set of wffs 
in the new language. 
Details: If not then for some #l, there is a deduction (in the expanded 
language) of (#l A 1 
#l) from r. This deduction contains only finitely 
many of the new constant symbols. By the theorem for generalization 
on constants (Theorem 24F), each can be replaced by a variable. We 
then have a deduction (in the original language) of (#l' A 1 
p') from r. 
This contradicts our assumption that r was consistent. 

136 
A Mathematical Introduction to Logic 
STEP 2: For each wff (p (in the new language) and each variable x, 
we want to add to r the wff 
1 V x q  -+ 1(p;, 
where c is one of the new constant symbols. (The idea is that c 
volunteers to name a counterexample to (p, if there is any.) We 
can do this in such a way that r together with the set O of all the 
added wffs is still a consistent set. 
Details: Adopt a fixed enumeration of the pairs ((p, x), where (p is a 
wff (of the expanded language) and x is a variable: 
This is possible since the language is countable. Let O1 be 
where cl is the first of the new constant symbols not occurring in (pl. 
Then go on to (q2, x2) and define €5. In general, On is 
where c, is the first of the new constant symbols not occurring in qn or 
in ek for any k < n. 
Let O be the set {el, 02, . . .}. We claim that r U O is consistent. If 
not, then (because deductions are finite) for some m 2 0, 
is inconsistent. Take the least such m. Then by RAA 
Now 
is 
for some x, (p, and c. So by rule T, we obtain the two facts: 
Since c does not appear in any formula on the left side, we can apply 
the Corollary 24G to the second of these, obtaining 
This and (*) contradict the leastness of m (or the consistency of r ,  if 
m = 0). 

Chapter 2: First-Order Logic 
137 
STEP 3: We now extend the consistent set r U O to a consistent set 
A which is maximal in the sense that for any wff q either q E A 
or ( l q )  E A. 
Details: We can imitate the proof used at the analogous place in 
the proof of sentential compactness in Section 1.7. Or we can argue as 
follows: Let A be the set of logical axioms for the expanded language. 
Since r U O is consistent, there is no formula #I 
such that r U O U A 
tautologically implies both #I and 1 
#I. (This is by Theorem 24B; the 
compactness theorem of sentential logic is used here.) Hence there is 
a truth assignment v for the set of all prime formulas that satisfies 
rUOUA.Let 
A = {qpIV(qp) = T). 
Clearly for any qp either qp E A or ( -I q) E A but not both. Also we 
have 
A I- q =+ A tautologically implies q (since A G A), 
+ V(q) = T 
since v satisfies A, 
a ~ E A .  
Consequently, A is consistent, lest both q and ( 1  q) belong to A. 
Actually, regardless of how A is constructed, it must be de- 
ductively closed. That is, 
A I- q 
A bl 1 
q 
by consistency, 
=+ (19) 4 A, 
=+ q E A 
' by maximality. 
STEP 4: We now make from A a structure .% for the new language, 
but with the equality symbol (if any) replaced by a new two-place 
predicate symbol E. .% will not itself be the structure in which r 
will be satisfied but will be a preliminary structure. 
(a) I.%[ = the set of all terms of the new language. 
(b) Define the binary relation E" by 
(u, t) E E' 
iff the formula u = t belongs to A. 
(c) For each n-place predicate parameter P, define the n-ary 
relation P' by 
(ti, ..., t n ) E p Z  iff 
P t l - . - t n ~ A .  
(d) For each n-place function symbol f ,  let f a  be the function 
defined by 

138 
A Mathematical Introduction to Logic 
This includes the n = 0 case; for a constant symbol c we take cn = c. 
Define also a function s : V 4 [%I, namely the identity function 
s(x) = x on V .  
It then follows that for any term t, s(t) = t. For any wff (p, let (p* 
be the result of replacing the equality symbol in (p by E. Then 
+ a ( p * [ ~ ]  
iff 
(p E A. 
Details: That s(t) = t can be proved by induction on t, but the proof 
is entirely straightforward. 
The other claim, that 
Pa p* [ ~ l  iff 
(p E A, 
we prove by induction on the number of places at which connective or 
quantifier symbols appear in (p . 
Case 1: Atomic formulas. We defined % in such a way as to make 
this case immediate. For example, if (p is Pt, then 
+a Pt[s] iff s(t) E P". 
iff t E pn, 
iff P ~ E A .  
Similarly, 
u Et [s] iff (s(u), s(t)) E E", 
iff (u, t )  E E%, 
iff u = t ~ A .  
Case 2: Negation. 
l=n (-(p)*[sI if F a  v*[sI, 
iff (p # A by inductive hypothesis, 
iff (-I (p) E A by properties of A. 
Case 3: Conditional. 
l=a(rg+@)*[sl iff Fa(p*[~l 
or l=a@*[~I, 
iff (p # A or @ E A by inductive hypothesis, 
iff ( 1 4 0 ) ~  
A or @ € A ,  
=+ A k ((p -+ @), in fact tautologically, 
* ( p # A  or [ ~ E A  
and dl-@], 
=+ ( 1 r g ) ~ A  
or @ € A ,  
which closes the loop. And 
A
(
)
 
iff 
( ( p + @ ) ~  A. 
(This should be compared with Exercise 2 of Section 1.7.) 
Case 4: Quantification. We want to show that 
Vx(p*[s] iff Vx(p E A. 

Chapter 2: First-Order Logic 
(The notational ambiguity is harmless since Vx(q*) is the same as 
(V x q)* .) A includes the wff 8: 
To show that 
we can argue: If q* is true of everything, then it is true of c, whence by 
the inductive hypothesis q,X E A. But then V x q~ E A, because c was 
chosen to be a counterexample to q if there was one. In more detail: 
F a  Qx ~ * [ s l  * F a  ~*[s(x 
I c ) ~  
=+ 
(q*): [s] 
by the substitution lemma 
=+ pa (q,X)* [s] , 
this being the same formula 
==?~,XEA 
by the inductive hypothesis 
* (14~:) 4 A 
by consistency 
= $ ( l V x q ) $ A  
s i n c e 8 ~ A a n d A i s  
deductively closed 
+ V x q  E A. 
(This is our only use of 0. 
We needed to know that if ( 1  Vx q) E A, 
then for a particular c we would have ( 1  q,X) E A.) 
We turn now to the converse. We can almost argue as follows: 
FaVxq*[s] 3 kg q*[s(x It)] forsomet 
--' Fa (qf )*[s] 
by the substitution lemma 
=+ ( ~ f 4 A  
by the inductive hypothesis 
--' Vxq # A 
since A is deductively closed. 
The flaw here is that the two wavy implications require that t be 
substitutable for x in q. This may not be the case, but we can use the 
usual repair: We change to an alphabetic variant @ of q~ in which t is 
substitutable for x. Then 
Fa Vx q* [s] =+ Fa q* [S(X I t)] for some t, henceforth fixed 
=+ Fa @* [s (x I t)] by the semantical equivalence of 
alphabetic variants (Corollary 25D) 
==? 
(@f)*[s] 
by the substitution lemma 
**f$A 
by the inductive hypothesis 
= + v x @ # A  
since A is deductively closed 
=+Vxq 4 A 
by the syntactical equivalence of 
alphabetic variants (Theorem 241). 
This completes the list of possible cases; it now follows by induction 
that for any q, 
q*[s] iff 
q E A. 

140 
A Mathematical Introduction to Logic 
If our original language did not include the equality symbol, then 
we are done. For we need only restrict U to the original language to 
obtain a structure that satisfies every member of r with the identity 
function. 
But now assume that the equality symbol is in the language. Then 
U will no longer serve. For example, if r contains the sentence 
c = d (where c and d are distinct constant symbols), then we need a 
structure 23 in which cB = dB. We obtain 23 as the quotient structure 
U /  E of U modulo E'. 
STEP 5: E' 
is an equivalence relation on IQI . For each t in IQI let 
[t] be its equivalence class. E' 
is, in fact, a congruence relation 
for a. This means that the following conditions are met: 
(i) E" is an equivalence relation on IUI. 
(ii) P" is compatible with E" for each predicate symbol P: 
(tl, . . . , t,) E pa and ti ~ " t :  
for 1 5 i 5 n + (ti, . . . , t;) E P" 
(iii) fa is compatible with E" for each function symbol f :  
" 
" " 
ti  ti for 1 5 i 5 n =+ f (tl, . . . , t,) E f (ti, . . . , t;). 
Under these circumstances we can form the quotient structure U /  E, 
defined as follows: 
(a) IU/ E I is the set of all equivalence classes of members of IUI. 
(b) For each n-place predicate symbol P, 
([tl], . . . , [t,]) E palE iff (tl,. . . , t,) E P". 
(c) For each n-place function symbol f ,  
This includes the n = 0 cases: 
Let h : IUI 4 [%/El be the natural map: 
h(t) = [t]. 
Then h is a homomorphism of U onto U / E .  Furthermore, E " / ~  
is the equality relation on I%/ E I .  Consequently, for any 9: 
So U /  E satisfies every member of A (and hence every member of 
r )  with h o s. 

Chapter 2: First-Order Logic 
141 
Details: Recall that 
t Eat' 
iff 
(t = t') E A, 
iff 
A k t = t'. 
(i) En is an equivalence relation on U by properties Eql , Eq2, and 
Eq3 of equality. 
(ii) P" is compatible with Ea by property Eq4 of equality. 
(iii) f" is compatible with E" by property Eq5 of equality. 
It then follows from the compatibility of P" with E" that palE is 
well defined. Similarly, f "IE is well defined because f" is compatible 
with En, 
It is immediate from the construction that h is a homomorphism of 
M onto M/ E. And 
[t] E"IE [t'] iff t E't', 
iff 
[t]=[tt]. 
Finally, 
v 
A * P a  q*[sl 
by step 4 
+ PalE q*[h o s] by the homomorphism theorem 
+ P"/E 40[h 0 ~ 1 ,  
the last step being justified by the fact that E"IE is the equality relation 
on lU/El. 
STEP 6: Restrict the structure U/E to the original language. This 
restriction of M/ E satisfies every member of r with h o s. i 
For an uncountable language, a few modifications to the foregoing 
proof of the completeness theorem are needed. Say that the language has 
cardinality A. (By this we mean that it has A symbols or, equivalently, 
A formulas.) We will describe the modifications needed, assuming the 
reader has a substantial knowledge of set theory. In step 1 we add A 
new constant symbols; the details remain unchanged. In step 2, only the 
details change. The cardinal A is an initial ordinal. (We have tacitly well 
ordered the language here.) "Enumerate" the pairs 
indexed by ordinals less than A. For a! c A, 8, is 
where c, is the first of the new constant symbols not in q, or in O8 for 
any 
< a!. (This excludes at most No card(a!) constant symbols, so 
there are some left.) Finally, in step 3, we can obtain the maximal set A 
by use of Zorn's lemma. The rest of the proof remains unchanged. 

1 42 
A Mathematical Introduction to Logic 
COMPACTNESS 
THEOREM (a) If r  + (p, then for some finite ro G r  
we have ro + (p. 
(b) If every finite subset ro of r  is satisfiable, then r  is satis- 
fiable. 
In particular, a set X of sentences has a model iff every finite subset 
has a model. 
PROOF TO prove part (a) of the compactness theorem, we simply 
observe that 
~ + v = $ ~ F ( P  
+ ro I- 
(p for some finite ro G r, deductions being finite 
=$ ro +v. 
Part (b) has a similar proof. If every finite subset of r  is sat- 
isfiable, then by soundness every finite subset of I' is consistent. 
Thus r  is consistent, since deductions are finite. So by complete- 
ness, r is satisfiable. (Actually parts (a) and (b) are equivalent; 
cf. Exercise 3 of Section 1.7.) 
i 
When a person first hears of the compactness theorem, his natural 
inclination is to try to combine (by some algebraic or set-theoretic op- 
eration) the structures in which the various finite subsets are satisfied, 
in such a way as to obtain a structure in which the entire set is satisfied. 
In fact, such a proof is possible; the operation to use is the ultraprod- 
uct construction. But we will refrain from digressing further into this 
intriguing possibility. 
Notice that the compactness theorem involves only semantical no- 
tions of Section 2.2; it does not involve deductions at all. And there are 
proofs that avoid deductions. The same remarks apply to the following 
theorem. 
*ENUMERABIL~TY THEOREM For a reasonable language, the set of valid 
wffs can be effectively enumerated. 
By a reasonable language we mean one whose set of parameters can 
be effectively enumerated and such that the two relations 
{(P, n) I P is an n-place predicate symbol} 
and 
{( f, n) I f is an n-place function symbol} 
are decidable. For example, any language with only finitely many pa- 
rameters (such a language will be called afinite language) is certainly 
reasonable, because finite sets are always decidable. On the other hand, 
a reasonable language must be countable, since we cannot effectively 
enumerate an uncountable set, (In fact, a stronger statement applies: As 

Chapter 2: 
First-Order Logic 
1 43 
in Section 1.7, a suitable input/output format is needed in which the 
underlying set of symbols communicated is finite, which implies that 
the set of all strings is countable.) 
A precise version of this theorem will be given in Section 3.4. (See 
especially item 20 there.) The proofs of the two versions are in essence 
the same. 
PROOF. The essential fact is that A, and hence the set of deductions, 
is decidable. 
Suppose that we are given some expression E .  (The assumption 
of reasonableness enters already here. There are only countably 
many things eligible to be given by one person to another.) We 
want to decide whether or not E is in A. First we check that 
E has the syntactical form necessary to be a formula. (For sen- 
tential logic we gave detailed instructions for such a check; see 
Section 1.3. Similar instructions can be given for first-order lan- 
guages, by using Section 2.3.) If E passes that test, we then check 
(by constructing a truth table) to see if E is a generalization of a 
tautology. If not, then we proceed to see if E has the syntactical 
form necessary to be in axiom group 2. And so forth. If E has not 
been accepted by the time we finish with axiom group 6, then E 
is not in A. 
(The above is intended to convince the reader that he really can 
tell members of A from nonmembers. The reader who remains 
dubious can look forward to the rerun in Section 3.4.) 
Since A is decidable, the set of tautological consequences of 
A is effectively enumerable; see Theorem 17G. But 
{a I a is a tautological consequence of A) 
= {a I I- a) by Theorem 24B, 
= {a I a is valid). 
An alternative to the last paragraph of this proof is the following 
argument, which is possibly more illuminating: First we claim that the 
set of deductions (from 0) is decidable. For given a finite sequence 
ao, . . . ,a, we can examine each ai in turn to see if it is in A or is 
obtainable by modus ponens from earlier members of the sequence. 
Then to enumerate the validities, we begin by enumerating all finite 
sequences of wffs. We look at each sequence as it is produced and 
decide whether or not it is a deduction. If not, we discard it. But if it is, 
then we put its last member on the list of validities. Continuing in this 
way, we generate-in 
an inefficient way - 
a list on which any valid 
formula will eventually appear. 
*COROLLARY 
25F Let r be a decidable set of formulas in a reason- 
able language. 

1 44 
A Mathematical Introduction to Logic 
(a) The set of theorems of r is effectively enumerable. 
(b) The set {(p 1 r + (p} of formulas logically implied by r is 
effectively enumerable. 
(Of course parts (a) and (b) refer to the same set. This corollary 
includes the enumerability theorem itself, in which r = 0.) 
PROOF 1. Enumerate the validities; whenever you find one of the 
form 
check to see if a,, . . . , a1 are in r. If so, then put a 0  on the list of 
theorems of r. In this way, any theorem of r is eventually listed. 
-I 
PROOF 2. r U A is decidable, so its set of tautological consequences 
is effectively enumerable. And that is just the set we want. i 
For example, let r be the (decidable) set of axioms for any of the 
usual systems of set theory. Then this corollary tells us that the set of 
theorems of set theory is effectively enumerable. 
More generally, in setting up some axiomatic theory, it is natural 
to insist that the set of axioms be decidable. After all, we want proofs 
from these axioms to be convincing arguments that can be ver@ied. Part 
of the verification process involves checlung that statements alleged 
to be axioms are indeed axioms. For this to be possible, the set of 
axioms needs to be decidable (or at least semidecidable). This has the 
consequence that the set of theorems that follow from the axioms is 
effectively enumerable. 
*COROLLARY 
25G Assume that r is a decidable set of formulas in 
a reasonable language, and for any sentence a either r + a or 
r + i 
a. Then the set of sentences implied by r is decidable. 
PROOF. If r is inconsistent, then we have simply the (decidable) 
set of all sentences. So assume that r is consistent. Suppose 
that we are given a sentence a and asked to decide whether or 
not r + a. We can enumerate the theorems of r and look for 
a or la. Eventually one will appear, and then we know the 
answer. 
I 
(Observe that this proof actually describes two decision procedures. 
One is correct when r is inconsistent, the other is correct when r is con- 
sistent. So in either case a decision procedure exists. But we cannot nec- 
essarily determine effectively, given a finite description of r, which one 
is to be used. A set is decidable if there exists a decision procedure for it. 
That is not the same as having a known decision procedure in our hands.) 

Chapter 2: 
first-Order Logic 
1 45 
It should be remarked that our proofs of enumerability cannot, in 
general, be strengthened to proofs of decidability. For almost all lan- 
guages the set of validities is not decidable. (See Church's Theorem, 
Section 3.5.) 
Historical Notes 
The completeness theorem (for countable languages) was contained in 
the 1930 doctoral dissertation of Kurt Godel. (It is not to be confused 
with the "Godel incompleteness theorem," published in 193 1. We will 
consider this latter result in Chapter 3.) The compactness theorem (for 
countable languages) was given as a corollary. 
The compactness theorem for uncountable languages was implicit 
in a 1936 paper by Anatolii Mal'cev. His proof used Skolem functions 
(cf. Section 4.2) and the compactness theorem of sentential logic. The 
first explicit statement of the compactness theorem for uncountable 
languages was in a 1941 paper by Mal'cev. 
The enumerability theorem, as well as following from Godel's 1930 
work, was also implicit in results published in 1928 by Thoralf 
Skolem. 
The proof we have given for the completeness theorem is patterned 
after one given by Lwn Henkin in his dissertation, published in 1949. 
Unlike Godel's original proof, Henlun's proof generalizes easily to lan- 
guages of any cardinality. 
Exercises 
1. (Semantical rule EI) Assume that the constant symbol c does not 
occur in (p, +, or r ,  and that r ;  (p,X + +, Show (without using the 
soundness and completeness theorems) that r ;  3 x (p + +. 
2. Prove the equivalence of parts (a) and (b) of the completeness the- 
orem. Suggestion: r + (p iff r U { l q )  is unsatisfiable. And A 
is satisfiable iff A 
I ,  where I is some unsatisfiable, refutable 
formula like i V x x  =x. 
Remark: Similarly, the soundness theorem is equivalent to the 
statement that every satisfiable set of formulas is consistent. 
3. Assume that r I- 
(p and that P is a predicate symbol which occurs 
neither in r nor in (p. Is there a deduction of (p from r in which 
P nowhere occurs? Suggestion: There are two very different ap- 
proaches to this problem. The "soft" approach makes use of two 
languages, one that contains P and one that does not. The "hard" 
approach considers the question whether P can be systematically 
eliminated from a given deduction of (p from r. 

146 
A Mathematical Introduction to Logic 
4. Let r = { i V v 1  Pvl, P ~ , '  
P g ,  . . .). IS r consistent? Is r satisfi- 
able? 
5. Show that an infinite map can be colored with four colors iff every 
finite submap of it can be. Suggestion: Take a language having a 
constant symbol for each country and having four one-place predicate 
symbols for the colors. Use the compactness theorem. 
6. Let C1 and C2 be sets of sentences such that nothing is a model 
of both C1 and C2. Show that there is a sentence t such that 
Mod C1 2 Mod t and Mod C2 5 Mod i t. (This can be stated: 
Disjoint ECa classes can be separated by an EC class.) Suggestion: 
C1 U C2 is unsatisfiable; apply compactness. 
7. The completeness theorem tells us that each sentence either has a 
deduction (from 0) or has a counter-model (i.e., a structure in which 
it is false). For each of the following sentences, either show there is 
a deduction or give a counter-model. 
(a) Qx(Qx + v Y QY) 
(b) ( 3 x  Px - + V y  Qy) -+Vz(Pz -+ Qz) 
(c) Vz(Pz+ Q z ) + ( 3 x P x + V y Q y )  
(d) i 3 y Vx(Pxy * 1 
Pxx) 
8. Assume the language (with equality) has just the parameters V and 
P ,  where P is a two-place predicate symbol. Let U be the structure 
with IUl = Z, the set of integers (positive, negative, and zero) and 
with (a, b) E P" iff la - b 1 = 1. Thus U looks like an infinite 
graph: 
Show that there is an elementarily equivalent structure 23 that is not 
connected. (Being connected means that for every two members of 
123 I, there is a path between them. A path - 
of length n - 
from a 
to b is a sequence (po, PI,. . . , pn) with a = po and b = p, and 
(pi, 
E P' 
for each i .) Suggestion: Add constant symbols c 
and d. Write down sentences saying c and d are far apart. Apply 
compactness. 
9. In Section 2.4 we used a certain set A of logical axioms. That set 
can be altered, within limits. 
(a) Suppose we add to A some formula + that is not valid. Show 
that the soundness theorem now fails. 
(b) At the other extreme, suppose we take no logical axioms at all: 
A = 0. Show that the completeness theorem now fails. 
(c) Suppose we modify A by adding one new valid formula. Explain 
why both the soundness theorem and the completeness theorem 
still hold. 

Chapter 2: First-Order Logic 
147 
SECTION 2.6 
Models of Theories 
In this section we will leave behind deductions and logical axioms. 
Instead we return to topics discussed in Section 2.2. But now, in the 
presence of the theorems of the preceding section, we will be able to 
answer more questions than we could before. 
Filiite Models 
Some sentences have only infinite models, for example, the sentence 
saying that < is an ordering with no largest element. The negation of 
such a sentence isflnitely valid, that is, it is true in every finite structure. 
It is also possible to have sentences having only finite models. For 
example, any model of Vx V y x = y has cardinality 1. But if all models 
of C are finite, then there is a finite bound on the size of the models, by 
the following theorem. 
THEOREM 
26A If a set Z of sentences has arbitrarily large finite 
models, then it has an infinite model. 
PROOF. For each integer k 2 2, we can find a sentence hk that 
translates, "There are at least k things." For example, 
Consider the set 
By hypothesis any finite subset has a model. So by compactness 
the entire set has a model, which clearly must be infinite. 
-I 
For example, it is a priori conceivable that there might be some very 
subtle equation of group theory that was true in every finite group but 
false in every infinite group. But by the above theorem, no such equation 
exists. 
The proof to this theorem illustrates a useful method for obtaining a 
structure with given properties. One writes down sentences (possibly in 
an expanded language) stating the properties one wants. One then argues 
that any finite subset of the sentences has a model. The compactness 
theorem does the rest. We will see more examples of this method in the 
coming pages. 
COROLLARY 
266 The class of all finite structures (for a fixed lan- 
guage) is not ECa. The class of all infinite structures is not EC. 

148 
A Mathematical Introduction to Logic 
PROOF. The first sentence follows immediately from the theorem. 
If the class of all infinite structures is Mod t ,  then the class of all 
finite structures is Mod 1 t. But this class isn't even ECA, much 
less EC. 
i 
The class of infinite structures is ECa, being Mod{h2, h3, . . .). 
Next we want to consider decision problems connected with finite 
structures. For any structure U, define the theory of U, written Th U, 
to be the set of all sentences true in U. For aflnite structure U, is Th U 
decidable? Is the set of sentences having finite models decidable? 
The following observations will help here: 
1. Any finite structure U is isomorphic to a structure with universe 
{1,2, . . . , n) where n is the size of U (i.e., n = card IUI). The idea here 
is, where IMI = {al, . . . , a,), simply to replace ai by i. 
For example, suppose the language has only the parameters V and 
a two-place predicate symbol E (for the "edge" relation in a directed 
graph). Consider the finite structure 93 with universe 193 1 consisting of 
a set of four distinct objects {a, b, c, d), and with 
Then 93 is isomorphic to the structure 
But there are other possibilities here; if we had focused on the mem- 
bers of 193 1 in the order b, a, d, c then we would have arrived at the 
isomorphic (but different) structure 
2. A finite structure of the sort just described can, for a finite lan- 
guage, be specified by a finite string of symbols. In the example, 
the above line completely specifies the structure, and it can be written 
down with numerals in base 10 (or your favorite base) along with punc- 
tuation and delimiters (e.g., parentheses). Therefore such a structure can 
be communicated to another person or to a machine. The finite string of 
symbols can be written down in a suitable input format. 
3. Given a finite structure U for a finite language, with universe 
(1, . . . , n) (and by the preceding observation, it is possible to be given 
such an object), a wff q, and an assignments, of numbers in this universe 
to the variables free in q (there are only finitely many, of course), we 
can effectively decide whether or not 
q[s,]. 

Chapter2: First-Order Logic 
149 
For example, given 
we can organize the computation in the tree form shown in Fig. 9. We 
find that the sentence (p, which says "Anything in the range of E is 
related to itself," is false in 23. 
Figure 9. Checking the sentence V V ~ ( ( + " ~ ~ ~ E V ~ V ~ )  
Ev1 vl) in a structure 
with universe of size 4. 
At each leaf in the tree (i.e., each minimal vertex), we have an atomic 
formula and we do a "table look-up" to see if it is satisfied. Notice that 
each quantifier triggers a search through the n-element universe. For 
a formula (p with k quantifiers, the number of leaves in the tree will 
be bounded by a polynomial in n of degree k. If the language contains 
function symbols, then each term needs to be evaluated, using the (finite) 
function provided by the structure. 
In particular, restricting ourselves to sentences, we can effectively 
decide, given U as above and a sentence a ,  whether or not IU is a 
model of a. (In fact here a could even be a second-order sentence, as in 
Chapter 4.) 
"THEOREM 
26C For a finite structure U in a finite language, Th IU is 
decidable. 

150 
A Mathematical Introduction to Logic 
PROOF 1. By observation 1, we can replace U by an isomorphic 
structure with universe of the form (1, . . . , n), without changing 
which sentences are true. Then apply observation 3. 
-I 
PROOF 2. By Exercise 17(a) of Section 2.2, there is a sentence 6% 
that specifies U up to isomorphism. It follows that 
@etails: For ''S" note that if a is true in U, then it is true in all 
isomorphic copies, and hence in all models of aa. So aa 21 a 
a. The 
other direction is simpler; if 6% + a then a is true in all models 
of an, of which U is one.) Apply Corollary 25G, noting that for 
each a ,  either 
a or 21% l a .  
-I 
4. Given a sentence a and a positive integer n, we can effectively 
decide whether or not a has an n-element model. That is, the binary 
relation 
{(a, n) I a has a model of size n) 
is decidable. 
The key idea is that there are only finitely many structures to check, 
and we can do that. The sentence a has a model of size n if and only 
if it has a model with universe (1, . . . , n) by observation 1. With the 
language restricted to the parameters that occur in a ,  there are only 
finitely many such structures, and we can systematically generate all of 
them. (For example, if the only parameters are V and a 2-place predicate 
symbol, then there are 2"' different structures.) Applying observation 3, 
we test to see if any of these are models of a. 
5. The spectrum of a sentence a is defined to be (n I a has a model 
of size n). See Exercise 16 in Section 2.2. It follows from observation 4 
that the spectrum of any sentence is a decidable set of positive integers. 
*THEOREM 
26D For a finite language, {a 1 a has a finite model) is 
effectively enumerable. 
PROOF. Here is a semidecision procedure: Given a ,  first check to 
see if it has a model of size 1, by using observation 4. If not, try 
size 2. Keep going. 
-I 
*COROLLARY 
26E Assume the language is finite, and let @ be the set 
of sentences true in every finite structure. Then its complement, 
- 
@, is effectively enumerable. 
PROOF. Forasentencea, 
a E I e 
( l a )  has afinite model. 
We can apply the above semidecision procedure to (1 
a). 
-I 

Chapter 2: First-Order Logic 
151 
It follows (by Theorem 17F) that <p is decidable if and only if it 
is effectively enumerable. But this does not happen. We state without 
proof the following: 
*TRAKHTENBROT'S 
THEOREM 
(1 950) The set of sentences 
@ = {a 1 a is true in every finite structure) 
is not in general decidable or effectively enumerable. 
Thus the analogue of the enumerability theorem for finite structures 
only is false. 
Size of Models 
In the proof of the completeness theorern in Section 2.5, we started with 
a consistent set r and formed a structure M/E in which it was satisfied. 
How large was that stkture? We claim that if our initial language 
was countable, then IM/E I is a countable set. Thus a consistent set of 
sentences in a countable language has a countable model. 
IU/E was constructed from a preliminary structure IU. The universe 
of IU was the set of all terms in the language obtained by adding a 
countable set of new constant symbols. But the augmented language 
was still countable, so the set of all expressions (and hence the set of all 
terms) was countable. That is, IMI was countable. 
The universe of IU/E consisted of equivalence classes of members 
of IU, so it, too, is a countable set. (We can map IU/E I one-to-one into 
1Ml by assigning to each equivalence class some chosen member.) The 
conclusion is that IU/ E is'a countable structure, as claimed. 
LOWENHEIM-SKOLEM THEOREM 
(1 91 5) (a) Let r be a satisfiable set 
of formulas in a countable language. Then r is satisfiable in some 
countable structure. 
(b) Let C be a set of sentences in a countable language. If C 
has any model, then it has a countable model. 
PROOF. First observe that r is consistent, by the soundness theorem. 
Then by the completeness theorem (plus the foregoing remarks) 
it can be satisfied in a countable structure. 
i 
(There is another, more direct proof of this theorem that will be indi- 
cated in Section 4.2; see especially Exercise 1 there. That proof, which 
does not use a deductive calculus, begins with an arbitrary structure IU 
in which r can be satisfied, and by various manipulations extracts from 
it a suitable countable substructure in which r is still satisfied.) 
The Lowenheim-Skolem theorem was published by Leopold 
Lowenheim in 1915 for the case where r is a singleton; Thoralf Skolem 
in 1920 extended this to a possibly infinite r . The theorem marked a new 
phase in mathematical logic. Earlier work had been done in the direction 

A Mathematical Introduction to Logic 
of formalizing mathematics by means of formal languages and deduc- 
tive calculi; this work was initiated largely by Gottlob Frege in 1879. 
For example, the Principia Mathernatica (1910-1913) of Whitehead 
and Russell carried out such a formalization in great detail. But the 
modern phase began when logicians stepped back and began to prove 
results about the formal systems they had been constructing. Other early 
work in this trend was done by David Hilbert, Ernil Post, Kurt Gijdel 
(as mentioned before), Alfred Tarski, and others. 
For a sample application of the Lowenheim-Skolem theorem, let 
AST be your favorite set of axioms for set theory. We certainly hope 
these axioms are consistent. And so they have some model. By the 
Lijwenheim-Skolem theorem, the axioms have a countable model 6. 
Of course, 6 is also a model of all the sentences logically implied by 
AST. One of these sentences asserts (when translated back into English 
according to the intended translation) that there are uncountably many 
sets. There is no contradiction here, but the situation is sufficiently 
puzzling to be called "Skolem's paradox." It is true that in the structure 
6 there is no point that satisfies the formal definition of being a one- 
to-one map of the natural numbers onto the universe. But this in no 
way excludes the possibility of there being (outside 6 )  some genuine 
function providing such a one-to-one correspondence. 
Recall that the theory of M, written ThU, is the set of all sentences 
true in M. We can apply the Lowenheim-Skolem theorem (with C = 
Th U) to prove that for any structure M for a countable language, there 
is a countable elementarily equivalent structure 93. If 93 is a model of 
Th U then M -= 93 because 
and 
For example, the real field (119; 0,1, +, .) is an uncountable structure for 
a finite language. Therefore there must be some countable structure (also 
a field) satisfying exactly the same sentences. (In fact Tarski showed we 
can take the field of algebraic real numbers for this.) 
EXAMPLE. Consider the structure 
We claim that there is a countable structure Mo, elementarily 
equivalent to '37 (so that 
and % satisfy exactly the same sen- 
tences) but not isomorphic to %. 
PROOF. We will construct Mo by using the compactness theorem. 
Expand the language by adding a new constant symbol c. Let 
C = (0 < c,SO < c,SSO < c,. ..). 

Chapter 2: First-Order Logic 
153 
We claim that C U Th '37 has a model. For consider a finite 
subset. That finite subset is true in 
(where k = cnk) for some large k. So by the compactness theorem 
C U Th '37 has a model. 
By the Lowenheim-Skolem theorem, C UTh '37 has a countable 
model 
Let % be the restriction of i)32 to the original language: 
Since !?& is a model of Th'37, we have 9& = '37: 
We leave it to the reader to verify that ?Dlo is not isomorphic to 
'37. (l!IJlol contains the "infinite" number cm.) 
-I 
What about uncountable1 languages? Assume that in the proof of 
the completeness theorem we started with a set r in a language of 
cardinality A. We claim that in this case, the structure IU/ E we made 
has cardinality ~ h .  
IU/ E was constructed from that prelimiriary structure U. The universe 
of I# was the set of all terms in the language obtained by adding h new 
constant symbols. So the augmented language still had cardinality A. 
So (by Theorem OD) the set of all expressions (and hence the set of all 
terms) had cardinality ch. (In fact, because we had at least the h new 
constant symbols, the set of terms had cardinality exactly h.) 
The universe of U/ E consisted of equivalence classes of members of 
IZl, so card IU/ E I ( card IUI. (We can map I%/ E 1 one-to-one into 1IUl 
by assigning to each equivalence class some chosen member, but now 
we may need the axiom of choice.) Thus, when the smoke had cleared, 
r was satisfied in a structure U/ E of cardinality LA. 
LOWENHEIM--SKOLEM THEOREM (a) Let r be a satisfiable set of for- 
mulas in a language of cardinality A. Then r is satisfiable in some 
structure of size i h .  
(b) Let C be a set of sentences in a language of cardinality A. 
If C has any model, then it has a model of cardinality sh. 
The reader who wishes to avoid uncountable cardinals is advised to skip to the subsection 
Theories. 

154 
A Mathematical Introduction to Logic 
The earlier version of the Lowenheim-Skolem theorem is a special 
case of this version, wherein h = No. 
Suppose that we have an uncountable structure U for a countable 
language. By the Lowenheim-Skolem theorem (applied to Th U) there 
is a countable 'IS that is a model of Th U, and hence U = 'IS, as noted 
previously. 
Conversely, suppose that we start with a countable structure 'IS. Is 
there an uncountable M such that I# = %?If 'IS is finite (and the language 
includes equality), then this is impossible. But if 'IS is infinite, then there 
will be such an M, by the following "upward and downward Lowenheim- 
Skolem theorem." The upward part is due to Tarski, whence the "T" of 
"LST." 
LST THEOREM Let r be a set of formulas in a language of cardinality 
A, and assume that r is satisfiable in some infinite structure. Then 
for every cardinal K 1 A, there is a structure of cardinality K in 
which r is satisfiable. 
PROOF. Let U be the infinite structure in which r is satisfiable. 
Expand the language by adding a set C of K new constant symbols. 
Let 
C = {cl # c2 I CI, c2 distinct members of C). 
Then every finite subset of C U r is satisfiable in the structure 
U, expanded to assign distinct objects to the finitely many new 
constant symbols in the subset. (Since U is infinite, there is room 
to accommodate any finite number of these.) So by compactness 
C U r is satisfiable, and by the Lowenheim-Skolem theorem it 
is satisfiable in a structure 'IS of cardinality (K. (The expanded 
language has cardinality h + K = K.) But any model of C clearly 
has cardinality LK. SO 'IS has cardinality K; restrict 'IS to the 
original language. 
-I 
COROLLARY 
26F (a) Let C be a set of sentences in a countable lan- 
guage. If C has some infinite model, then C has models of every 
infinite cardinality. 
(b) Let U be an infinite structure for a countable language. Then 
for any infinite cardinal A, there is a structure 'IS of cardinality h 
such that 'IS -= U. 
PROOF. (a) Take r = C, h = No in the theorem. 
(b) Take C = ThM in part (a). 
Consider a set C of sentences, to be thought of as nonlogical ax- 
ioms. (For example, C might be a set of axioms for set theory or a set 
of axioms for number theory.) Call C categorical iff any two models 
of C are isomorphic. The above corollary implies that if C has any 

Chapter 2: 
First-Order Logic 
infinite models, then C is not categorical. There is, for example, no 
set of sentences whose models are exactly the structures isomorphic 
to (N; 0, S, +, .). This is indicative of a limitation in the expressive 
ness of first-order languages. (As will be seen in Section 4.1, there are 
categorical second-order sentences. But second-order sentences are p e  
culiar objects, obtained at the cost of holding the notion of subset fixed, 
immune from interpretation by structures.) 
Theories 
We define a theory to be a set of sentences closed under logical impli- 
cation. That is, T is a theory iff T is a set of sentences such that for any 
sentence a of the language, 
(Note that we admit only sentences, not formulas, with free variables.) 
For example, there is always a smallest theory, consisting of the 
valid sentences of the language. At the other extreme there is the theory 
consisting of all the sentences of the language; it is the only unsatisfiable 
theory. 
For a class K of structures (for the language), define the theory of K 
(written Th K:) by the equation 
Th K = {a I a is true in every member of K). 
(This concept arose previously in the special case K = {a).) 
THEOREM 
26C Th K: is indeed a theory. 
PROOF. Any member of K is a model of ThK. Thus if a is true 
in every model of ThK, then it is true in every member of K. 
Whence it belongs to Th K. 
-I 
For example, if the parameters of the language are V, 0,1, +, and *, 
and F is the class of all fields, then Th F ,  the thwry of fields, is simply 
the set of all sentences of the language which are true in all fields. If F0 
is the class of fields of characteristic 0, then Th Fo is the theory of fields 
of characteristic 0. 
Recall that for a set C of sentences, we defined Mod C to be the class 
of all models of C. Th Mod C is then the set of all sentences which are 
true in all models of C. But this is just the set of all sentences logically 
implied by C .  Call this set the set of consequences of C, Cn C. Thus 
For example, set theory is the set of consequences of a certain set of 
sentences, known, unsurprisingly, as axioms for set theory. A set T of 
sentences is a thwry iff T = Cn T. 

A Mathematical Introduction to Loaic 
A theory T is said to be complete iff for every sentence a ,  either 
a E T or (1 
a )  E T. For example, for any one structure U, Th{U) 
(written, as before, "ThM") is always a complete theory. In fact, it is 
clear upon reflection that Th K is a complete theory iff any two members 
of K are elementarily equivalent. And a theory T is complete iff any 
two models of T are elementarily equivalent. 
For example, the theory of fields is not complete, since the sentences 
are true in some fields but false in others. The theory of algebraically 
closed fields of characteristic 0 is complete, but this is by no means 
obvious. (See Theorem 26J.) 
*DEFINITION. 
A theory T is axiomatizable iff there is a decidable set 
C of sentences such that T = Cn C. 
DEFINITION. 
A theory T isJinitely axiomatizable iff T = Cn C for 
some finite set C of sentences. 
In the latter case we have T = Cn{a) (written "T = Cn a"), where 
a is the conjunction of the finitely many members of C. For example, 
the theory of fields is finitely axiomatizable. For the class 3 of fields 
is Mod @, where @ is the finite set of field axioms. And the theory of 
fields is Th Mod @ = Cn @. 
The theory of fields of characteristic 0 is axiomatizable, being Cn <Po, 
where 
consists of the (finitely many) field axioms together with the 
infinitely many sentences: 
This thwry is not finitely axiomatizable. To prove this, first note that no 
finite subset of 
has the entire theory as its set of consequences. (For 
that finite subset would be true in some field of very large characteristic.) 
Then apply the following: 
THEOREM 
26H If Cn C is finitely axiomatizable, then there is a finite 
Co S C such that Cn Co = Cn C. 
PROOF. Say that Cn C is finitely axiomatizable; then Cn C = Cn t 
for some one sentence t. In general t 4 C, but at least C b t. 
( t  E Cn t = Cn C .) By the compactness theorem there is a finite 
Co S C such that Co + t .  Then 
Cnt G CnCo c_ CnC, 
whence equality holds. 

Chapter 2: First-Order Logic 
157 
We can now restate Corollaries 25F and 25G in the present termi- 
nology : 
*COROLLARY 
261 (a) An axiomatizable theory (in a reasonable lan- 
guage) is effectively enumerable. 
(b) A complete axiomatizable theory (in a reasonable lan- 
guage) is decidable. 
We can represent the relationships among these concepts by means 
of a diagram (in which we have included the results of Exercise 6): 
Decidable 
Finitely axiomatizable 
For example, a theory that is given in axiomatic form (such as 
Zermelo-Fraenkel set theory, which is Cn AZF for a certain set Am) 
is effectively enumerable. We will argue in Section 3.7 that set the- 
ory (if consistent) is not decidable and not complete. Number theory, 
the theory of the structure (N; 0, S, <, +, ., E), is complete but is not 
effectively enumerable and hence not axiomatizable (Section 3.5). 
We can use part (b) of the preceding corollary to establish the de- 
cidability of an axiomatizable theory, provided we can show that the 
theory in question is complete. This can sometimes be done by means 
of the Log-Vaught test for completeness. 
Say that a theory T is No-categorical iff all the infinite countable 
models of T are isomorphic. More generally, for a cardinal K, say that T 
is K-categorical iff all models of T having cardinality K are isomorphic. 
LOLVAUGHT 
TEST (1 954) Let T be a theory in a countable lan- 
guage. Assume that T has no finite models. 
(a) If T is No-categorical, then T is complete. 
(b) If T is K -categorical for some infinite cardinal K, then T is 
complete. 
PROOF. It suffices to show for any two models Q and 23 of T that 
Q = 23. Since M and 23 are infinite, there exist (by the LST 
theorem) structures Q1 = Q and 23' = 23 having cardinality K .  24' 
is isomorphic to B1, so we have 
Thus M = 23. 
(If T is a theory in a language of cardinality A, then we must demand 
that A 5 K .) 

A Mathematical Introduction to logic 
The converse to the to$-Vaught test is false. That is, there are com- 
plete theories which are not K-categorical for any K. 
In Section 3.1 we will apply the Lo$-Vaught test to prove the decid- 
ability of the theory of the natural numbers with zero and successor. It 
can also be used to prove the decidability of the theory of the complex 
field. But this proof will utilize an excursion into algebra. 
THEOREM 
261 (a) The theory of algebraically closed fields of char- 
acteristic 0 is complete. 
*(b) The theory of the complex field 
is decidable. 
PROOF. Let A be the class of algebraically closed fields of charac- 
teristic 0. Then A = Mod(ao U r), where 
consists as before 
of the axioms for fields of characteristic 0, and r consists of the 
sentences 
V a V b V c ( a # O - + 3 x a ~ x * x + b ~ x  
+c=O), 
VaVbVcVd(a#O-+3xa-x-xox + b * x * x  +cox +d=O), 
The set a. U r is decidable and Th A = Cn(ao U r ) ,  so this 
theory is axiomatizable. Part (a) of the theorem asserts that the 
theory is also complete, whence it is decidable. 
Part (b) follows from part (a). For we have C E A, whence 
Th A 
Th C. The completeness of Th A implies that equality 
holds; see Exercise 2. 
To prove part (a), we apply the Lo$-Vaught test. The models 
of Th A are exactly the members of A. These are all infinite. We 
further claim that Th A is categorical in any uncountable cardinal- 
ity. This is equivalent to saying that any two algebraically closed 
fields of characteristic 0 having the same uncountable cardinality 
are isomorphic. 
This last assertion is a known result of algebra. We will sketch 
the proof, for the interest of those readers familiar with this topic. 
Any field 5 is obtainable in the following way: (1) One begins 
with the prime subfield, which is determined to within isomor- 
phism by the characteristic of 5. (2) One takes a transcendental 
extension, determined within isomorphism by the cardinality of 
the transcendence basis, i.e., by the transcendence degree of 5 
(over its prime subfield). (3) One finally takes some algebraic ex- 
tension. We thus have a theorem of Steinitz: Two algebraically 
closed fields are isomorphic iff they have the same characteristic 
and the same transcendence degree. 
If the transcendence degree of an infinite field 5 is K ,  then the 
cardinality of 5 is the larger of K and No. Hence for an uncountable 

Chapter 2: 
First-Order Logic 
159 
field, the cardinality equals the transcendence degree. So we con- 
clude from Steinitz's theorem that two algebraically closed fields 
having the same characteristic and the same uncountable cardi- 
nality are isomorphic. 
-I 
The theory of the real field 
is also decidable. But this result (which is due to Tarski) is much deeper 
than the above theorem. The theory of the real field is not categorical in 
any infinite cardinality, so the Log-Vaught test cannot be applied. 
As a final application, we can show that the ordering of the rationals 
is elementarily equivalent to the ordering of the reals, 
where Q and R are the rationals and reals, respectively, and < Q and <R 
are the corresponding orderings. To show elementary equivalence, we 
show that both are models of some complete theory (which then must 
coincide with the theory of each structure). The key fact is provided by 
a theorem of Cantor: Any two countable dense linear orderings without 
endpoints are isomorphic. 
To give the details, we must back up a little. The language here has 
equality and the parameters V and <. Let S be the conjunction of the 
following sentences: 
1. Ordering axioms (trichotomy and transitivity): 
2. Density: 
VxVy(x < y -+ 3z(x < z < y)). 
3. No endpoints: 
The dense linear orderings without endpoints are, by definition, the 
structures for this language that are models of 6. It is clear that they are 
all infinite. Furthermore, we claim that the theory of these orderings, 
Cn 6, is Ho-categorical. This is provided by the following fact. 
THEOREM 
26K (CANTOR) Any countable model of S is isomorphic to 
(Q, <Q). 
We leave the proof to Exercise 4. 

160 
A Mathematical Introduction to Logic 
We can now apply the Log-Vaught test to conclude that CnS is 
complete. Hence any two models of S are elementarily equivalent; in 
particular, 
We can also conclude that these structures have decidable theories. 
Prenex Normal Form 
It will at times be convenient to move all the quantifier symbols to the 
left of other symbols. For example, 
'd x(Ax -+ V y Bxy ) 
is equivalent to 
v x  b' y(Ax --+ Bxy). 
And 
Vx(Ax --+ 3 y Bxy) 
is equivalent to 
V x 3 y(Ax -+ Bxy). 
Define a prenex formula to be one of the form (for some n 2 0) 
where Qi is V or 3 and a! is quantifier-free. 
PRENEX 
NORMAL 
FORM THEOREM For any formula, we can find a log- 
ically equivalent prenex formula. 
PROOF. We will make use of the following quantifier manipulation 
rules. 
Qla. ~ V x a !  ++ 3x-a!. 
Qlb. i 3 x a !  
v x i a ! .  
Q2a. 
(a! -+ Vx B) 
V X ( ~  
-+ B) for x not free in a!. 
Q2b. 
(a! -+3xB) b+ 3x(a - + B )  forx notfreeina!. 
Q3a. (Vxa!-+B) ++ 3x(a!-+#l)forxnotfreeinB. 
Q3b. (3xa!-B) ++Vx(a!-+B)forxnotfreein~. 
Q1 is clear; for the others see the examples in Section 2.4 and 
Exercise 8 there. 
We now show by induction that every formula has an equivalent 
prenex formula. 
1. For atomic formulas this is vacuous, as any quantifier-free 
formula is trivially a prenex formula. 
2. If a! is equivalent to the prenex a!', then V x a! is equivalent 
to the prenex V x a!'. 

Chapter 2: First-Order Logic 
3. If a is equivalent to the prenex a', then 1 a is equivalent to 
i 
a'. Apply Q1 to 1 
a' to obtain a prenex formula; for example, 
4. Finally we come to the case of a + B. By inductive hy- 
pothesis we have prenex formulas a' and #I' equivalent to a and 
/I, respectively. By our theorems on alphabetic variants, we may 
further assume that any variable that occurs quantified in one of 
the formulas a' and B' does not occur at all in the other. We 
then use Q2 and Q3 to obtain a prenex formula equivalent to 
a' -+ B' (and hence to a -+ B). Observe that there is some lati- 
tude in the order in which the rules Q2 and 4 3  are applied. For 
example, 
(where x and y do not occur in +, u does not occur in q) is 
equivalent to any of the following: 
Retrospectus 
At the beginning of this book it was stated that symbolic logic is a 
mathematical model of deductive thought. This is as good a time as 
any to reflect on that statement, in the light of the material treated 
thus far. 
As a first example, consider a mathematician working in set theory. 
He uses a language with an equality symbol, a symbol E for member- 
ship, and numerous defined symbols (0, U, and others). In principle the 
defined symbols could be eliminated and any sentence replaced by an 
equivalent sentence in which the defined symbols did not appear. (In 
this connection see Section 2.7, where this topic is treated systemati- 
cally.) He takes as primitive (or undefined) notions the concepts of set 
and membership. He adopts some set AST of axioms involving these 
concepts. He asserts that for certain sentences (his theorems), these 
sentences are true provided the axioms are true, regardless of what the 
undefined notions of set and membership actually mean. In support 
of these assertions he offers proofs, which are finitely long arguments 
intended to convince his colleagues of the correctness of the assertions. 
In terms of first-order logic we can describe all this as follows: The 
language here is a first-order language with equality and a two-place 
predicate symbol E. Thus V and E are the only parameters open to 
interpretation. There is a certain set AST of sentences in this language 

1 62 
A Mathematical Introduction to Logic 
singled out as being the set of (nonlogical) axioms. Then certain other 
sentences are logical consequences of AST, i.e., are true in any model of 
AST. If t is a consequence of AST (and only then), there is a deduction 
of t from AST. 
Next consider a more typical case of the hypothetical working math- 
ematician, that of the algebraist or analyst. The algebraist uses axioms 
for (say) group theory, but he also employs some amount of set theory. 
Similarly, the analyst deals with sentences that involve both numbers 
and sets of numbers. In both cases it is generally recognized that one 
could, in principle, convert the assertions of algebra and analysis to as- 
sertions of set theory. And then the remarks of the preceding paragraph 
again apply. 
The interest that symbolic logic holds for the mathematician is largely 
due to the accuracy with which it mirrors mathematical deductions. In 
the long run, it will surely be useful to understand the fundamental 
processes of doing mathematics. 
There remains the question of the accuracy with which first-order 
logic mirrors nonmathematical deductive thought. Logic, symbolic and 
nonsymbolic, has always formed a traditional part of the philosophical 
study of the process by which people come to hold certain ideas. Non- 
mathematical examples to which first-order logic applies are provided 
by a vast array of frivolous situations. Lewis Carroll gave such exam- 
ples, one of which inferred that babies cannot manage crocodiles from 
the three hypotheses: (1) Babies are illogical. (2) Nobody is despised 
who can manage a crocodile. (3) Illogical persons are despised. 
But what of nonfrivolous situations? Here the applicability is ob- 
scured by the fact that we usually do not make explicit the assump- 
tions we use in drawing conclusions. There are specific areas (in di- 
verse fields such as physics, medicine, and law) where assumptions 
not only can be made explicit but are being made explicit. In some 
cases it appears that less than the full versatility of first-order logic is 
required to formalize the real-life deductions. Possibly in other cases - 
ranging from everyday life to quantum mechanics - 
more features may 
be necessary. 
Exercises 
1. Show that the following sentences are finitely valid (i.e., that they 
are true in every finite structure): 
(a) 3 x 3 y 3 z[(Px f x -+ Pxx) V (Pxy A Pyz A 1 Pxz)] 
(b) 3 x v y 3 z[(Qzx -+ QZY) 
-+ (Qxy -+ Qxdl 
Suggestion: Show that any model of the negation must be infinite. 
2. Let Tl and T2 be theories (in the same language) such that (i) TI 
Tz, (ii) Tl is complete, and (iii) T2 is satisfiable. Show that Tl = T2. 

Chapter 2 : First-Order Logic 
1 63 
3. Establish the following facts: 
(a) C1 G C2 + Mod C2 G Mod C1. 
(bj C (gThM0dCandK:GMod ThK. 
(c) Mod C = Mod Th Mod C and Th K: = Th Mod ThK. (Part 
(c) follows from (a) and (b).) 
4. Prove that any two countable dense linear orderings without end- 
points are isomorphic (Theorem 26K). Suggestions: Let U and 23 
be such structures with IUI = {ao, a1 , . . .) and 1% 
/ = {bo, bl , . . .). 
Construct an isomorphism in stages; at stage 2n be sure a, is paired 
with some suitable bj , and at stage 2n + 1 be sure 6, is paired with 
some suitable ai. 
5. Find prenex formulas equivalent to the following. 
(a) (3x Ax A 3 x  Bx) -+ Cx. 
(b) Vx Ax * 3 x  Bx. 
*6. Prove the converse to part (a) of Corollary 261: An effectively enu- 
merable theory (in a reasonable language) is axiomatizable. Sug- 
gestion: The set {ao, a1 ,a2, . . . } is equivalent (in the sense of having 
the same models) to the set {ao, a 0  A a1 ,a0 A a1 A 02, . . . ). 
7. Consider a language with a two-place predicate symbol <, and 
let '37 = (N; <) be the structure consisting of the natural numbers 
with their usual ordering. Show that there is some U elementarily 
equivalent to '37 such that <" has a descending chain. (That is, 
there must be ao, a1 , . . . in IUI such that (ai+i, ai ) E <" for all i .) 
Suggestion: Apply the compactness theorem. 
Remark: The point of this exercise is to demonstrate that in 
this language, one can not express, "There is no descending chain." 
8. Assume that a is true in all infinite models of a theory T. Show 
that there is a finite number k such that a is true in all models U of 
T for which IUl has k or more elements. 
9. Say that a set C of sentences has thefinite model property iff each 
member a of C, if it has any models at all, has a finite model. 
Assume that C is a set of sentences in a finite language (i.e., a 
language with finitely many parameters) and that C has the finite 
model property. Give an effective procedure that, given any member 
a of C, will decide whether or not a has any models. Suggestion: Is 
the set of such sentences effectively enumerable? Is its complement 
effectively enumerable? 
10. Assume we have a finite language without function symbols. 
(a) Show that the set of satisfiable 3 2  sentences is decidable. (See 
Exercise 19 in Section 2.2 for terminology and background.) 
Suggestion: Apply the preceding exercise. 

1 64 
A Mathematical Introduction to Logic 
(b) Show that the set of valid V 2  sentences is decidable. (A V 2  
formula is one of the form V x l  .Vx, 3 yl . . 3 y, I9 where 
I9 is quantifier-free.) 
Remarks: In first-order logic, the "decision problem" (Entschei- 
dungsproblem) is the problem of deciding, given a formula, whether 
or not it is valid. By Church's theorem (Section 3.9, this problem 
in general is unsolvable. This exercise gives a solvable subcase of 
the decision problem. 
SECTION 2.7 
Interpretations Between Theories' 
In some cases a theory Tl can be shown to be every bit as powerful as 
another theory To. This is certainly the case if the theories are in the 
same language and To 2 TI. But even if the theories are in different 
languages, there may exist a way of translating from one language to 
the other in such a way that members of To are translated as members 
of TI. This sort of situation will be examined in this section. 
We will begin by discussing the topic of defined symbols. This topic, 
as well as having significant interest of its own, will serve as an example 
for the situation of the preceding paragraph, wherein To is constructed 
from Tl by adding a new defined symbol. If the definition is done prop- 
erly, the original theory Tl should in principle be just as strong as the 
new To. We will consider only the case of defined function symbols, 
since the case of defined predicate symbols presents, in comparison, no 
real difficulties. 
Defining Functions 
Frequently in mathematics it is useful to introduce definitions of new 
functions. For example, in set theory one defines the power-set operation 
P by a sentence like, "Let P x  be the set whose members are the subsets 
of x." Or by a sentence in a formal language (here containing E, 2 ,  
and PI, 
Now definitions are unlike theorems and unlike axioms. Unlike the- 
orems, definitions a& not things we prove. We just declare them by 
fiat. But unlike axioms, we do not expect definitions to add substantive 
information. A definition is expected to add to our convenience, not to 
our knowledge. 
The results of this section will be used only in the latter part of Section 3.7. 

Chapter 2: 
First-Order Logic 
165 
If this expectation is to be realized, the definition must be made in 
a reasonable way. As an example of a most unreasonable definition in 
number theory, suppose that we introduce a new function symbol by the 
"definition" 
f ( x ) = y  
iff x c y .  
(Or by the sentence in a formal language: V vl V uz( f vl = uz * vl < 
q).) Since we know that 1 < 2, we see that f (1) = 2. But also 1 < 3, 
so we obtain f (1) = 3. And so we come to the conclusion (which does 
not itself involve f )  that 2 = 3. 
Obviously this definition of f was in some way very bad. It did not 
just make matters convenient for us; it enabled us to conclude that 2 = 3, 
which we could not have done without the definition. The trouble was 
that the definition bestowed the name " f (1)" ambiguously upon many 
things (2 and 3 among them). Thus f (1) was not "well defined." Names 
ought to designate unique objects. 
In this subsection we want to consider conditions under which we can 
be assured that a definition will be satisfactory. To simplify the notation, 
we will consider only the definition of a one-place function symbol f ,  
but the remarks will apply to n-place function symbols as well. 
Consider then a theory T in a language not yet containing the one- 
place function symbol f .  (For example, T might be the set of conse- 
quences of your favorite axioms for set theory.) We want to add f to 
the language, introducing it by the definition 
where (P is a formula in the original language (i.e., a formula not con- 
taining f )  in which only vl and q may occur free. 
THEOREM 
27A In the above situation, the following are equivalent: 
(a) (The definition is noncreative.) For any sentence a in the 
smaller language, if 
(in the augmented language), then already T t= a. 
(b) (f is well defined.) The sentence 
is in the theory T. (Here "3 !q 9" is an abbreviation for a longer 
formula; see Exercise 21 of Section 2.2.) 
PROOF. TO obtain (a) =$ (b), simply note that S + E .  So by taking 
a = E in part (a), we obtain T 
E .  
Conversely, assume that T t= 
E. Let U be a model of T. 
(U is a structure for the original language.) Ford E Irzll, let F(d) 

166 
A Mathematical Introduction to Logic 
be the unique e E IUI such that pa q[d, el. (There is a unique 
such e because pa 
21.) Let (U, F) be the structure for the aug- 
mehted language that agrees with U on the original parameters 
and that assigns F to the symbol f .  Then it is easy to see that 
(U, F) is a model of 6. Furthermore, U and (U, F) satisfy the 
same sentences of the original language. In particular (U, F) is a 
model of T. Hence 
(This argument can be stated more briefly by using second-order 
logic. E is logically equivalent to the sentence 3 f 6 .) 
Interpretations 
The basic idea is that it is possible for one theory to be just as strong (in 
a sense to be made precise) as another theory in another language. In 
considering two languages simultaneously, there is no point in allowing 
them to conflict; e.g., the negation symbol of one language should not 
be a predicate symbol in the other. We can eliminate such conflicts by 
assuming that each of the languages is obtained from a third parent 
language by deleting some parameters (and perhaps equality). 
For example, axiomatic set theory is at least as strong as the theory of 
the natural numbers with zero and successor, i.e., the theory of (N; 0, S). 
Any sentence in the language of (N; 0, S) can be translated in a natural 
way into a sentence of set theory. (This translation is sketched briefly 
in Section 3.7.) If the original sentence was true in (N; 0, S), then the 
translation will be a consequence of the axioms of set theory. (This is 
not obvious; the proof uses facts to be developed in Section 3.1 .) 
Let us look more carefully at a second example. Consider on the one 
hand the theory of 
in its language, and on the other hand the theory of 
in its language. (Here Z is the set of all integers, positive, negative, and 
zero.) We will shortly be in a position to claim that the second theory is 
as strong as the first. How might a sentence about the natural numbers 
N with 0 and S be translated into a sentence about the integers Z with 
addition and multiplication? 
The first clue is provided by Lagrange's theorem from number the- 
ory: an integer is nonnegative iff it is the sum of four squares. Thus a 
quantifier V x in the first language (where x is intended to range over N) 

Chapter 2 :  First-Order Logic 
can be replaced by 
in the second language. 
The second clue is that (0) and the successor function (viewed as a 
relation) are definable in (Z; +, 
a ) .  The set (0) is defined by 
01 + v1 = v1. 
The successor relation (extended to Z) is defined by 
Thus the sentence about (N; 0, S) 
VxSx#O 
can be translated into 
So much for examples. For our general discussion it will be helpful 
to introduce the notation 
q(t) = qp', 
Wl - 
v(t17t2) = (a1 
)h 7 
and so forth. Thus q = q(vl) = q(vl, u;?). If we use "q(x)" we will 
not worry too much about whether or not x is substitutable for vl in q. 
If it is not, then we actually want q(x) to be +:, 
where + is a suitable 
alphabetic variant of q. 
Assume now that we have the following general situation: 
Lo is a language. (A language can for all practical purposes be a set 
of parameters, possibly augmented by the equality symbol.) 
Tl is a theory in a (possibly different) language L1, which includes 
equality. 
DEFINITION. 
An interpretation n of Lo into Tl is a function on the 
set of parameters of Lo such that 
1. n assigns to V a formula 
of L1 in which at most vl occurs 
free, such that 
(The idea is that in any model of TI, the formula zt, should define 
a nonempty set to be used as the universe of an Lo-structure.) 
2. n assigns to each n-place predicate parameter P a formula 
n p  of L1 in which at most the variables vl, . . . v,, occur free. 

168 
A Mathematical Introduction to Logic 
3. n assigns to each n-place function symbol f a formula nf 
of L1, in which at most vl, . . . , v,, v,+l occur free, such that 
(ii) 
Tl k V vl . . . V v,(nv(vl) -+ . . . -+ nv(vn)-+ 
3 x(~v(x) 
A v vn+l(nf ( ~ 1 ,  
- . - , vn+l) * vn+l = x))). 
(In English, this formula becomes, "For all 3 in the set defined by 
nv, there is a unique x such that n (3, x), and furthermore x is 
in the set defined by nv." The idea is to ensure that in any model 
of TI, nf defines a function on the universe defined by nv. In the 
case of a constant symbol c, we have n = 0 and (ii) becomes 
In other words, nc defines a singleton whose one member is also 
in the set defined by nv.) 
For example, if Lo is the language of (N; 0, S) and Tl is the theory 
of (Z; +, -), then we have 
(We are here exploiting the fact that in (Z; +, -) we can, in effect, define 
the structure (N; 0, S).) 
If Lo coincides with L1, there is trivially the identity interpretation 
n, for which 
nv = v1 = v1, 
np = Pvl ... v,, 
nf = f v l . .  -21, = V,+l. 
The conditions (i) and (ii) are then met no matter what Tl is. 
Now assume that n is an interpretation and let 'IS be a model of TI. 
There is a natural way to extract from 'IS a structure " 'IS for Lo. Namely, 
let 
lk'IS 1 =the set defined in 23 by nv, 
pnB = the relation defined in 93 by np , restricted to IR 'IS I, 
f =%(al, . . . , a,) = the unique b such that ka n [al, . . . , a,, b], 
where al, . . . , a, are in IR'ISl. 
By condition (i) in the definition of interpretations, 1" 'IS 1 # 0. And, by 
condition (ii), the definition of f nB makes sense; i.e., there is a unique 
b meeting the above condition. Hence "'IS is indeed a structure for the 
language Lo. 
Define the set n-I [TI] of Lo-sentences by the equation 
Z-'[T~] = Thin% 1 'IS E Mod TI) 
= {a I a is an Lo-sentence true in every structure "'IS 
obtainable from a model 93 of TI}. 

Chapter 2: First-Order Logic 
169 
This is a theory, as is Th K for any class K. It is a satisfiable theory iff 
TI is satisfiable. 
EXAMPLE. Earlier in this section we had a theory T containing the 
sentence 
v v1 3!% (o. 
We augmented the language to a larger language L+ that contained 
a function symbol f .  The "definition" of f was provided by the 
L+-sentence 
We showed that for a sentence cr in the original language of T, if 
T; 6 k a, then T k a. 
We have an interpretation 5t from L+ into T. 5t is the identity 
interpretation on all parameters except f .  The formula xf is (o. The 
fact that T k E is just what we need to verify that x is indeed an 
interpretation. For any model M of T, nM is a structure previously 
called (M, F); it is a model of T; 6. 
We claim that 
First observe that any model 'B of T; 6 equals "& where M is the 
restriction of '13 to the language of T. Hence for an L+-sentence cr, 
for every model M of T 
for every model 'B of T; 6 
Syntactical Translation 
In the preceding subsection on interpretations we talked about arbitrary 
models and such. But the reader may already have noticed that there is 
a much more down-to-earth thing to be said about an interpretation 5t 
of Lo into Tl . Briefly: We can, given a formula (o of Lo, find a formula 
(on in L1 which in some sense corresponds exactly to (o. We define (on 
by recursion on (o. 
First, consider an atomic formula a of Lo. For example, if a is 
then a is logically equivalent to 
And we can take for an the L1 -formula 

170 
A Mathematical Introduction to Logic 
In general, scan an atomic formula a from right to left. The rightmost 
place at which a function symbol occurs will initiate a segment of the 
form gxl . x,, for some n-place g. (In the example n = 1 .) Replace this 
by some new variable y, and prefix V y(ng(xl, . . . , x,, y))+. Continue 
to the next place at which a function symbol occurs. Finally, replace the 
predicate symbol P (if a parameter) by np (with the correct variables). 
The definition of an can be stated more carefully by using recursion 
on the number of places at which function symbols occur in a. If that 
number is zero, then a is Pxl . . x, and an is zp(xl, . . . , x,). Other- 
wise, take the rightmost place at which a function symbol g occurs. If 
g is an n-place symbol, then that place initiates a segment gxl 
x,. 
Replace this segment by some new variable y, obtaining a formula we 
can call a,g"i..'xn. 
Then an is 
For example, 
The interpretation of a nonatomic formula is defined in the obvi- 
ous way. ( 1  (o)n is (--.I (on), ((o + @)R is ((on.+ 
and (Vx (o)n is 
Vx(nv(x) + (on). (Thus the quantifiers are "relativized to nv.) 
The sense in which (on "says the same thing" as (o is made precise in 
the following basic lemma. 
LEMMA 278 Let n be an interpretation of Lo into TI, and let !l3 be 
a model of TI. For any formula (o of Lo and any map s of the 
variables into In !l3 1, 
l=fl!B(o[sl iff l=!B(oK[s1. 
This is not a deep fact. It just says that (on was defined correctly. 
PROOF. We use induction on (o, but only the case of an atomic 
formula a is nontrivial. For a, we use induction on the number of 
places at which function symbols occur. It is easy if that number 
is zero. Otherwise, 
where p:x 
= a. (We have quietly assumed that g is a one-place 
symbol; the notation is bad enough already.) Let 
b = the unique b such that kB zg [s(x), bJJ 
= gnB(s(x)). 

Chapter 2: First-Order Logic 
171 
Then 
a" [s] + ki23 Bn [s(y I b)l 
+ knB B [S (y I b)] by the inductive hypothesis 
* kc8 ,qx[s1 
by the substitution lemma 
* I="% (~'[sl. 
The following corollary justifies our choice of notation for n-' [TI]. 
COROLLARY 
27C For a sentence a of Lo, 
a E Z - ~ [ T ~ ]  iff 
an E Tl. 
PROOF. Recall that by definition 
a E n - ' [ ~ ~ ]  
+ for every model '93 of TI, kng a 
u for every model '93 of TI, kB an by Lemma 27B 
+ TI k a". 
DEFINITION. An interpretation n of a theory To into a theory Tl is 
an interpretation rt of the language of To into Tl such that 
In other words, it is necessary that for an Lo-sentence a, 
n-I [TI] is the largest theory that n interprets into TI. If To = n-'[TI], 
then we have 
In this case n is said to be a faithful interpretation of To into TI. 
To return to an earlier example, consider the structures (N; 0, S) and 
(Z; +, a ) .  We had an interpretation n into Th(Z; +, a), where 
~ v ( ~ ) = ~ y l ~ ~ 2 3 y 3 3 ~ 4 ~ = ~ ~  
'y1 +y2'y2+y3.y3+y4.y4, 
n0(x)=x + X  =x, 
%(x, Y)=VZ(Z * Z =  
Az + z # z  + x  + z =  y). 
We now claim that n is a faithful interpretation of Th(N; 0, S) into 
Th(Z; +, .). For in this case, "(Z; +, .) is the structure (N; 0, S). Hence 
In Chapter 3 we will be able to show that there is no interpretation of 
Th(Z; +, .) into Th(N; 0, S). Thus the former theory is strictly stronger 
than the latter. 

A Mathematical Introduction to Logic 
Finally, let us return to the situation with which we started this section. 
Assume that T is a theory containing the sentence E, where 
E = v v l  3!2]2p; 
S = Vv1V2]2(fv1 = 
*p); 
L+ = the language obtained by adding the new function symbol f 
to the language of T ; 
n = the interpretation of L+ into T that is the identity interpretation 
on all parameters except f ,  and nf = p. 
In fact, n is a faithful interpretation of Cn(T; 6) into T, since, as 
noted previously, 
We can now draw an additional conclusion; the definition is eliminable. 
THEOREM 
27D Assume that we have the situation described above. 
Then for any L+-sentence a we can find the sentence an in the 
original language such that 
(a) T ;  S t= (a * 
an). 
(b) T;S Fa +=+ T F a " .  
(c) If f does not occur in a ,  then t= (a * a"). 
PROOF. Part (c) follows from the fact that n is the identity inter- 
pretation on all parameters except f .  Part (b) restates that n is a 
faithful interpretation of Cn(T; S) into T. Since x is faithful, for 
(a) it suffices to show that 
T 
(a * a")". 
This follows from (c), since (a * 
a")" is (a" * 
a""), which is 
valid. 
-I 
Exercises 
1. Assume that Lo and L1 are languages with the same parameters 
except that Lo has an n-place function symbol f not in L1 and L1 
has an (n + 1)-place predicate symbol P not in Lo. Show that for 
any Lo-theory T there is a faithful interpretation of T  into some 
L 1 -theory. 
2. Let Lo be the language with equality and the two-place function 
symbols + and *. Let L1 be the same, but with three-place predicate 
symbols for addition and multiplication. Let rti = (W; +, a )  be the 
structure for Li consisting of the natural numbers with addition and 
multiplication (i = 0, 1). Show that any relation definable by an 
Lo-formula in 
is also definable by an L1-formula in %I. 

Chapter 2: First-Order Logic 
1 73 
3. Show that an interpretation of a complete theory into a satisfiable 
theory is faithful. 
SECTION 2.8 
Nonstandard Analysis1 
The differential and integral calculus was originally described by 
Leibniz and Newton in the seventeenth century in terms of quantities 
that were infinitely small yet nonzero. Newton used in his calculations 
a number o that, being infinitely small, could be multiplied by any finite 
number and still be negligible. But it was necessary to divide by o, so it 
had to be nonzero. Leibniz's dx was less than any assignable quantity, 
yet was nonzero. 
These ideas were not easy to comprehend or to accept. Throughout 
the eighteenth century this business of working with infinitesimals was 
attacked (e.g., by Bishop Berkeley), distrusted (e.g., by D'Alembert), 
and used in enthusiastic experimentation (e.g., by Euler). While Euler 
was creating the mathematics that students now study in advanced cal- 
culus, he used infinitesimals in a loose, free-swinging manner that would 
not be tolerated in today's freshmen. Only in the nineteenth century were 
the foundations of calculus presented in the form now found in text- 
books. The treatment of limits was then rigorous, and debate subsided. 
In 1961 Abraham Robinson introduced a new method for treating 
limits, rescuing infinitesimals from their intellectual disrepute. This 
method combines the intuitive advantages of working with infinitely 
small quantities with modem standards of rigor. The basic idea is to 
utilize a nonstandard model of the theory of the real numbers. 
Construction of *s 
We will use a very large first-order language. In addition to symbols 
for +, ., and < we might as well add symbols for the exponentiation 
and absolute-value functions. And since there is no good reason to stop 
t h e r ~  
we go all the way and include a symbol for every operation on the 
set R of reals. We do the same for every relation on R. Thus we have 
the language with equality and the following parameters: 
0. V, intended to mean "for all real numbers." 
1. An n-place predicate symbol PR for each n-ary relation R on R. 
2. A constant symbol c, for each r E R. 
3. An n-place function symbol f, for each n-ary operation F on R. 
' This section may be omitted without loss of continuity. 

1 74 
A Mathematical Introduction to Logic 
For this language there is the standard structure 9, 
with 151 = R, 
a - R, c$ = r, and f; = F. But now let us form a nonstandard 
PR - 
structure, by using the compactness theorem. Let r be the set 
Th% U {crP,v1 I r E R). 
(Here c,P, vl formalizes "r is less than vl .") Any finite subset of r can 
be satisfied in % by assigning to vl some large real number. Hence by 
the compactness theorem there is a structure M and an element a E IMI 
such that r is satisfied in U when vl is assigned a. Since U is a model 
of ThR, we have M = %. There is also an isomorphism h of % into 
(but not onto) M defined by 
To check that this is indeed an isomorphism, we use the fact that M = %. 
h is one-to-one, since for rl # r2, the sentence c,, # c, holds in % and 
hence in M. h preserves a binary relation R(= ~z),since 
for any r and 
s in R, 
A similar calculation applies to any n-ary relation. Next we must show 
that h preserves any function F(= f :). 
Again for notational ease, sup- 
pose that F is a binary operation. Consider any r and s in R, and let 
t = F (r, s). Then 
Now the sentence ct = f ,eres holds in % and hence in U. Hence 
So h preserves f,. For the constant symbols we have by the definition 
of h, 
h (c?) = h (r) 
- '2l 
-cr . 
Since we have an isomorphic copy of % inside U, we can find an- 
other structure *% isomorphic to M such that % is a substructure of *%. 
The idea is simply to replace in M the point c: 
by the point r (provided 
that IMI n R = 0, as can always be arranged). For details, see Exer- 
cise 24 of Section 2.2. Since *% is isomorphic to M, there is a point 
b E I*%I such that *% satisfies r when vl is assigned b. In particular, 
* % = 3. 

Chapter 2: First-Order Logic 
175 
To go much further, we need a less cumbersome notation. We will 
use an asterisk to indicate passage from % to *%. 
1. For each n-ary relation R on R, let * R be the relation piR assigned 
to the symbol PR by *%. In particular, R is a unary relation on R. Its 
image *R equals the universe of *%, since the sentence VxPwx is true 
in % and hence in *%. Since R is a substructure of *?X, we have that 
each relation R equals the restriction of * R to R. 
2. For each n-ary operation F on R, let * F be the operation f k8 
assigned to the symbol f, by *R. F is then the restriction to R of *F. 
Observe that czR = r, so we need no special notation for this. 
There is a general method (to be used heavily in the remainder of this 
section) for demonstrating properties of a relation * R or an operation 
* F. One simply observes (1) that R or F has the property, (2) that the 
property can be expressed by a sentence of the language, and (3) that 
% = *%. 
For example, the binary relation *< on *R is transitive. This is because 
< is transitive, and this property can be expressed by the sentence 
By similar reasoning, * < satisfies trichotomy on *R and thus is an 
ordering relation on * R. 
For another example, we can prove that the binary operation *+ on 
*R is commutative, since + is commutative and the commutative law 
can be expressed by a sentence. By applying this reasoning to each of 
the field axioms, we see that (*R; 0, 1, *+, *.) is a field. 
This general method is used so much, we will shortly begin to take 
it for granted. If, for example, we assert that * la *+ bl *f * la 1 *+ * Ibl 
for a and b in *R, we will take for granted that the reader perceives that 
the general method yields this fact. 
We have R c *R, but R # *R. For we have some point b such that 
k*m 
c,P,.vl [b]; i.e., r *< b. Thus b is infinitely large, being larger 
(in the ordering *<) than any standard r, i.e., any r E R. Its reciprocal 
1 */ b will be a sample infinitesimal. 
Properties of % that cannot be expressed in the language are likely 
to fail in *R. The least-upper-bound property is one such. There are 
non-empty bounded subsets S of *R that have no least upper bound 
(with respect to the ordering * <). For example, R is such a subset of 
*R. It is bounded by the infinite b of the preceding paragraph. But it has 
no least upper bound; see Exercise 7. 
Define the set F ofjnite elements by the equation 
F = { x E  *RI*IxI*<y forsome YEW). 

1 76 
A Mathematical Introduction to Logic 
Similarly, define the set Z of infinitesimals by the equation 
Z =  {xE*R I *Ixl *< y forallpositive y E R). 
If A 
R is unbounded, then *A contains infinite points. For the 
sentence "for any real r there is an element a E A larger than r" is true 
and formalizable. Take some infinite positive b; there must be a larger 
(and hence infinite) member of *A. For example, *N contains infinite 
numbers. 
The only standard infinitesimal, i.e., the only member of R n Z, is 0. 
But there are other infinitesimals. For by the usual (formalizable) rules 
for inequalities, the reciprocal of any infinite number is an infinitesimal. 
Algebraic Properties 
In the next theorem we collect some algebraic facts about F and Z that 
will be useful later. 
THEOREM 
28A (a) F is closed under addition *+, subtraction *-, 
and multiplication * ,. 
(b) Z is closed under addition *+, subtraction *-, and multi- 
plication from F :  
X E Z  and Z E F + X * . Z E Z .  
In algebraic terminology, part (a) says that F is a subring of the field 
*R, and part (b) says that Z is an ideal in the ring F. We will see a little 
later what the quotient ring F/Z is. 
PROOF. (a)Letx andy befinite,sothat*Ixl *< a,*lyl *< bfor 
standard a and b in R. Then 
whence x *+ y, x *- y are finite. Also 
whence x * a  y is finite, too. 
(b) Let x and y be infinitesimals. Then for any positive standard 
a, *Ixl *< a/2 and *IyI *< a/2. Hence 
so that x *+ y and x *- y are infinitesimal. If z is finite, then 
* lzl *< b for some standard b. Since x is infinitesimal, we have 
* IX I *< a/b, whence 
Thus x *. z is also infinitesimal. 

Chapter 2: 
First-Order Logic 
177 
DEFINITION. 
x is infinitely close to y (written x -- y) iff x *- y is 
infinitesimal. 
THEOREM 
288 (a) -- is an equivalence relation on *R. 
(b) If u 2: v andx -- y, then u*+x -- v*+y and *-u 2: 
*- v. 
(c) If u -- v and x 2: y and x, y, u, v are finite, then u *. x 2 
v *. y. 
PROOF. This is a consequence of part (b) of the preceding theorem 
(Z is an ideal in a. 
(a) 2: is reflexive since 0 is infinitesimal. -- is symmetric since 
the negative (* -) of an infinitesimal is infinitesimal. Finally, sup- 
pose that x -- y and y -- z. Then 
since Z is closed under addition. 
(b) If u 2: v and x E y, then 
since Z is closed under addition. Also *- u -- *- v since Z is 
closed under negation. 
since Z is closed under multiplication from F. 
For standard r and s, we have r 2: s iff r = s, as 0 is the only 
standard infinitesimal. 
LEMMA 
28C If x $ y and at least one is finite, then there is a 
standard q strictly between x and y . 
PROOF. We may suppose that x *< y. In fact, we may further 
suppose that 0 *< x *< y; the case x *< y *s 
0 is similar and the 
case x *< 0 *< y is trivial. Since x $ y there is a standard b such 
that0 < b *< y*-x. Sincexisfinitewehavex *< mbforsome 
positive integer m; take the least such m. Then x *< mb *< y. 
(By the leastness of m, (m - l)b *I 
x. So mb *i 
x *+ b *< y.) 
-I 
THEOREM 
28D Everyx E F i s  infinitely close to auniquer E R. 
PROOF. For x E F the set 
of standard points below x has an upper bound in R. Let r be its 
least upper bound; we claim that x -- r. 

A Mathematical Introduction to Logic 
If x $ r, then by the lemma there is a standard q between x 
and r. If r < q *< x, then r fails to be an upper bound for S. If 
x *< q < r, then q is also an upper bound for S, contradicting 
the leastness of r. Hence x 2: r. 
This establishes the existence of r . As for the uniqueness, note 
that if x -- r and x 2: s, then r 2: S. For standard r and s this 
implies that r = s. 
-I 
COROLLARY 
28E Each finite x has a unique decomposition of the 
form x = s *+ i ,  where s is standard and i is infinitesimal. 
We call s the standard part of x, written st(x). (Another notation for 
the standard part of x is Ox.) Of course for standard r, st(r) = r. The 
next theorem summarizes some properties of the st function. 
THEOREM 
28F (a) st maps F onto R. 
(b) st(x) = 0 iff x is infinitesimal. 
(c) S~(X *+ y) = st(x) + st(y). 
(d) st(x * a  y) = st(x) st(y). 
PROOF. (a) and (b) are clear. Since st(x) 2: x and st(y) 2: y, we 
have by part (b) of Theorem 28B that st(x) + st(y) = x *+ y. 
Hence the left side equals st(x *+ y). Part (d) is similar and uses 
part (c) of Theorem 28B. 
-I 
(In algebraic teminology, this theorem asserts that st is a homomor- 
phism of the ring F onto the field R, with kernel 2. Consequently, the 
quotient ring F / Z  is isomorphic to the real field R.) 
Henceforth in this section we will streamline our notation by omitting 
the asterisks on the symbols for the arithmetic operations *+, *-, 
* a ,  
and */. 
Convergence 
In calculus courses convergence is usually treated in terms of E'S and 6's 
and variables that come delicately close to certain values. We will give 
here the beginning of an alternative treatment of convergence, where 
variables come infinitely close to the limiting values. 
DEFINITION. 
Let F : R + R. Then F converges at a to b iff when- 
ever x is infinitely close to (but different from) a, then * F(x) is 
infinitely close to b. 
PROOF OF EQUIVALENCE WITH THE ORDINARY 
DEFINITION. 
First Suppose 
that F converges at a to b in the ordinary sense. That is, for any 
E > 0 there is a 6 > 0 such that 
O#jtx-al<6 
=+ I b - F ( x ) ~ < E  foranyx. 
The displayed sentence (concerning the standard numbers E and 

Chapter 2: First-Order Logic 
1 79 
6) is formalizable and thus holds in *%. Now if x in *R is infinitely 
close to (but different from) a, then certainly 0 # * Ix - a1 *< 6. 
Hence *I b - * F(x) 1 *< E. Since E was arbitrary, b -- * F (x). 
Conversely, assume that the condition stated in the definition 
is met. Then for any standard E > 0, the sentence 
ThereexistsS> Osuchthatforallx, O#la-xl (6 + Ib-F(x)I < E  
(when formalized) holds in *%, since we can take 6 to be infinites- 
imal. Hence the sentence holds in ?X also. 
-I 
First remark: It is entirely possible that F does not converge at a to 
any number. On the other hand, F converges at a to at most one b. For 
if i is a nonzero infinitesimal, then b = st(*F(a + i)). It is traditional 
to denote this b by "limx,a F (x) ." Thus 
lim F(x) = st(*F(a + i ) ) .  
x+a 
Second remark: It is not really necessary to have dom F = R. It is 
enough for a to be an accumulation point of dom F. (a is an accumu- 
lation point of S iff a is infinitely close to, but different from, some 
member of *S.) 
COROLLARY 
28G F is continuous at a iff whenever x -- a, then 
*F(x) -- F(a). 
Now consider a function F : R + R and a standard a E R. Then 
the derivative Ff(a) is 
lim F(a + h) - F(a) 
h-+O 
h 
By our definition of limit, this can also be stated: F' (a ) = b iff for every 
nonzero infinitesimal dx we have dF/dx -- b, where d F  = * F(a + 
dx) - F(a). Thus if there is such a b (i.e., if Ff(a) exists), then 
for any nonzero infinitesimal dx. Here dF/dx is the result of dividing 
d F  by dx. The fact that we simply use division here greatly facilitates 
calculations. 
EXAMPLE. Let F(x) = x2. Then Ff(a) = 24-2, since 
THEOREM 
28H If Ff(a) exists, then F is continuous at a. 
PROOF. For any nonzero infinitesimal dx we have 
*F(a + dx) - F(a) 21 Ff(a). 
dx 

180 
A Mathematical Introduction to Logic 
The right side is standard, so the left side is at least finite. Con- 
sequently, when we multiply the left side by the infinitesimal 
dx we are left with the fact that *F(a + dx) - F(a) E Z, i.e., 
*F(a + dx) 2: F(a). 
-I 
The reader should note that this result is not some nonstandard ana- 
logue of a classical theorem, nor even a generalization of a classical 
theorem. It is a classical theorem. It is only the proof that is nonstan- 
dard. The same remarks apply to the next theorem. Let F o G be the 
function whose value at a is F(G(a)). 
CHAIN 
RULE Assume that Gf(a) and Ff(G(a)) exist. Then (F o 
G)'(a) exists and equals F1(G(a)) . Gf(a). 
PROOF. First, notice that *(F o G )  =* F o *G, since the sentence 
V vl f F,Gvl = f Ff v1 holds in the structures. Now consider any 
nonzero infinitesimal dx. Let 
dG = *G(a + dx) - G(a), 
dF = *(F o G)(a + d x )  - (F o G)(a) 
= * F (*G(a + dx)) - F (G(a)) 
= *F(G(a) + dG) - F(G(a)). 
Then dG N 0 since G is continuous at a. If dG # 0, then by the 
last of these equations dF/dG N F1(G(a)), whence 
If dG = 0, then dF = 0 and Gf(a) -- dG/dx = 0, so we again 
have 
These theorems are but samples of the treatment of convergence in 
terms of infinite proximity. The method is not at all limited to elemen- 
tary topics. One can construct delta functions S with the property that 
00 
.f-00 
S = 1 and yet S(x) - 0 for x $ 0. Original results in analysis 
(e.g., in the theory of Hilbert spaces) have been obtained by the method 
of nonstandard analysis. Possibly the method will be more widely used 
in the future as more analysts become familiar with it. 
Exercises 
1. (Q is dense in R.) Let Q be the set of rational numbers. Show that 
every member of *R is infinitely close to some member of *Q. 
2. (a) Let A 
R and F : A + R. Then F is also a binary relation on 
R; show that *F : *A + *R. 
(b) Let S : N + R. Recall that S is said to converge to b iff for every 
E > 0 there is some k such that for all n > k, IS(n) - b 1 < E .  

Chapter 2: First-Order Logic 
181 
Show that this is equivalent to the condition: *S(x) cz b for every 
infinite x E *N. 
(c) Assume that Si : N + R and Si converges to bi for i = 1,2. 
Show that S1 + S2 converges to bl + b2 and S1 S2 converges to 
bl bZ. 
3. Let F : A + R be one-to-one, where A c R. Show that if x E *A 
but x 4 A, then *F(x) 4 R. 
4. Let A c R. Show that A = *A iff A is finite. 
5. (Bolzano-Weierstrass theorem) Let A c R be bounded and infinite. 
Show that there is a point p E R that is infinitely close to, but 
different from, some member of *A. Suggestion: Let S : N + A 
with S one-to-one; look at *S(x) for infinite x E *N. 
6. (a) Show that *Q has cardinality at least 2'0, where Q is the set of 
rational numbers. Suggestion: Use Exercise 1. 
(b) Show that *N has cardinality at least 2'0. 
7. Let A be a subset of R having no greatest member. Then as a subset 
of * R, A will have upper bounds (with respect to the ordering * <) 
in *R. But show that A does not have a least such bound. 

In this chapter we will focus our attention 
specific language, the language of number 
This will be the first-order language with e 
and with the following parameter 
V, intended to mean "for all natural numbers." 
(Recall that the set N of natural numbers is the s 
{0, 1,2, . . .}. Zero is natural.) 
0, a constant symbol intended to denote 
number 0. 
S, a one-place function symbol intended to 
note the successor function S : N + N, i.e., t 
function for which S(n) = n + 1, 
<, a two-place predicate symbol intended t 
denote the usual (strict) ordering relation on N. 
+, ., E, two-place knction symbols inte 
to denote the operations +, ., and E of add 
multiplication, and exponentiation, respectively. 
We will let % be the intended structure far this 
language. Thus we may informally write 

Chapter 3: 
Undecidabilitv 
i.e., restrictions of % to sublanguages: 
Finally, in Section 3.8 we will consider 
For each of these structures we will raise the same questions: 
(A) Is the theory of the structure decidable? If so, what is a nice set 
of axioms for the theory? Is there a finite set of axioms? 
(B) What subsets of N are definable in the structure? 
(C) What do the nonstandard models of the theory of the structure 
look like? (By "nonstandard" we mean "not isomorphic to the intended 
structure.") 
Our reason for choosing number theory (rather than, say, group 
theory) for special study is this: We can show that a certain subtheory of 
number theory is an undecidable set of sentences. We will also be able to 
infer that any satisfiable theory that is at least as strong as this fragment 
of number theory (e.g., the full number theory or set theory) must be 
undecidable. In particular, such a theory cannot be both complete and 
axiomatizable. 
In order to show that our subtheory of number theory is undecid- 
able, we will show that it is strong enough to represent (in a sense 
to be made precise) facts about sequences of numbers, certain opera- 
tions on numbers, and ultimately facts about decision procedures. This 
last feature then lets us perform a diagonal argument that demonstrates 
undecidability. 
We could alternatively use, in place of a subtheory of number theory, 
some other theory (such as a fragment of the theory of finite sets) in 
which we could conveniently represent facts about decision procedures. 
Before giving examples of the expressiveness of the language of num- 
ber theory, it is convenient to introduce some notational conventions. 
As a concession to everyday usage, we will write 
x < y ,  
X + Y ,  x - y ,  and x E y  
in place of the official 
<xy, 
+xy, 
-xy, and Exy. 
For each natural number k we have a term skO (the numeral for k) that 
denotes it: 
S'O = 0, 
S'O = SO, 
s20 = SSO, 
etc. 
(The set of numerals is generated from (0) by the operation of 

A Mathematical Introduction to Logic 
prefixing S.) The fact that every natural number can be named in the 
language will be a useful feature. 
Even though only countably many relations on N are definable in '32, 
almost all the familiar relations are definable. For example, the set of 
primes is defined in '32 by 
Later we will find it important to show that many other specific relations 
are definable in '32. 
One naturally expects the expressiveness of the language to be 
severely restricted when some of the parameters are omitted. For exam- 
ple, the set of primes, as we shall see, is not definable in 
On the 
other hand, in Section 3.8 we will show that any relation definable in '32 
is also definable in !YIM. 
Preview 
The main theorems of this chapter - 
the theorems associated with the 
names of Godel, Tarski, and Church - 
are proved in Section 3.5. But 
we can already sketch here some of the ideas involved. We want to 
compare the concepts of truth and proof; that is, we want to compare 
the set of sentences true in '32 with the set of sentences that might be 
provable from an appropriate set A of axioms. 
We can assign to each formula a of the language of number theory 
an integer fla, called the Godel number of a .  Any sufficiently straight- 
forward way of assigning distinct integers to formulas would suffice 
for our purposes; a particular assignment is adopted at the beginning of 
Section 3.4. What is important is that from a we can effectively find 
the number fla, and conversely. Similarly, to each finite sequence D of 
formulas (such as a deduction) we assign an integer G(D). 
Note that for 
any set A of formulas, we can form the corresponding set {fla I a E A) 
of numbers. 
There are now three ways in which to proceed: the self-reference ap- 
proach, the diagonalization approach, and the computability approach. 
It will be argued later, however, that the three approaches are more 
closely related than they appear-they 
are three aspects of one ap- 
proach. 
First, in the self-reference approach, we make a sentence a that can 
be thought of as saying, "I am unprovable." More specifically, we have 
the following: 
THEOREM 
30A Let A E Th '32 be a set of sentences true in '32, and 
assume that the set {fla I a E A) of Godel numbers of members 
of A is a set definable in '32. Then we can find a sentence a such 
that a is true in '32 but a is not deducible from A. 

Chapter 3: 
Undecidability 
185 
PROOF. We will construct a to express (in an indirect way) that a 
itself is not a theorem of A. Then the argument will go roughly as 
follows: If A t- a ,  then what a says is false, contradicting the fact 
that A consists of true sentences. And so A .F a ,  whence a is true. 
To construct a ,  we begin by considering the ternary relation R 
defined by 
(a, 6, c )  E R iff a is the Godel number of some formula 
a and c is the value of 6 at some 
deduction from A of a (sbO). 
Then because {ga I a E A) is definable in (57, it follows that R 
is definable also. (The details of this step must wait until later 
sections.) Let p be a formula that defines R in (57. Let q be the 
GMel number of 
vr 
212 
(We use here the notation: ~ ( t )  
= spy, rp(tl, t2) = (pt, )t2 , and 
so forth.) Then let a be 
Thus a says that no number is the value of G at a deduction from 
A of the result of replacing, in formula number q, the variable 
ul by the numeral for q; i.e., no number is the value of G at a 
deduction of a. 
Suppose that, contrary to our expectations, there is a deduc- 
tion of a from A. Let k be the value of G at a deduction. Then 
(q, q, k )  E R and hence 
It is clear that 
and the two displayed lines tell us that a is false in '57. But A t- a 
and the members of A are true in (57, so we have a contradiction. 
Hence there is no deduction of a from A. And so for every k, 
we have (q, q, k )  4 R. Thus for every k 
from which it follows (with the help of the substitution lemma) 
that 
i.e., a is true in rt. 
We will argue later - 
using something called Church's thesis -that 
any decidable set of natural numbers must be definable in (57. The con- 
clusion will then be that Th (57 is not axiomatizable. 

186 
A Mathematical Introduction to Logic 
COROLLARY 
30B The set { g t  I kfl t ) of Godel numbers of sentences 
true in '32 is a set that is not definable in '32. 
PROOF. If this set were definable, we could take A = Th '32 in the 
preceding theorem to obtain a contradiction. 
-I 
Section 3.5 will follow the self-reference approach, but with a varia- 
tion in which the sentence a tries to say, "I am false." (The well-known 
liar paradox is relevant here!) 
But if this "self-reference" construction seems too much like a magic 
trick, there is a second way to describe the situation: the diagonalization 
approach, which does not use an obvious self-reference. 
We start by defining the following binary relation P on the natural 
numbers: 
(a, b) E P # a is the Godel number of a formula 4(v1) 
(with just vl free) and kfl a(sbO). 
(More informally, (a, 
b) E P + "a is true of b.") Then any set of natural 
numbers that is definable in '32 equals, for some a, the "vertical section" 
of P. Namely, we take a to be the Godel number of a formula defining 
the set, and use the fact that kn a(sbO) ++ kn a(vl) [b]. 
So any definable (in '32) set of natural numbers is somewhere on the 
list P1, P2, . . . . Now we "diagonalize out" of the list. Define the set: 
(More informally, b E H u "b is not true of b.") Then H is nowhere 
on the list PI, P2, . . . . (H # P3 because 3 E H + 3 6 P3, so the 
number 3 belongs to exactly one of these two sets and not to the other.) 
Therefore H is not definable in 'JZ. 
Why is H undefinable? After all, we have above specified that 
b E H # not [b is M t  the Godel number of a formula a(vl) 
(with just vl free) and kn a(sbO)]. 
What is the barrier to translating this specification into the language of 
arithmetic? We will show that the barrier is not being the Godel number 
of a formula - 
we can translate that - 
and the barrier is not having vl 
free and not substituting the numeral sbO into a formula. By the process 
of elimination, we will show that the only possible barrier is saying of 
a sentence that is true in 'JZ. 
THEOREM 
30C (a) The set { g t  I knt) of Godel numbers of sen- 
tences true in '32 is not definable in '32. 
*(b) The theory Th '32 is undecidable. 
*(c) The theory Th '32 is not axiomatizable. 

Chapter 3: 
Undecidability 
PROOF. Part (a), which is the same as Corollary 30B in the self- 
reference approach, has the diagonal proof sketched above. That 
is, if to the contrary Th '32 were definable in '32, then the above set 
H would also be definable, which it is not. 
Part (b) will then follow, after we argue every decidable set 
of natural numbers must be definable in '32. If Th '32 were decid- 
able, then the corresponding set {tft I kn t) of numbers would 
be decidable and hence definable in '32, which it is not. 
And part (c) is an immediate consequence of part (b) and 
Corollary 261, since Th '32 is a complete theory. 
-I 
And thirdly, the computability approach presents us with a stark 
difference between what is true and what is provable. From Section 2.6 
we know that whenever A is a decidable set (or even an effectively 
enumerable set) of axioms we might choose for Th '32, the set Cn A of 
provable sentence will be an effectively enumerable set. 
In contrast, the computability approach will show -using Church's 
thesis- that the set Th '32 of all true sentences is not effectively enu- 
merable. This fact, which is closely related to Theorem 30C, will follow 
from another diagonal argument in Section 3.6. 
"THEOREM 
300 For any decidable (or even effectively enumerable) 
set A of axioms, 
because the set on the left is effectively enumerable and the set 
on the right is not. 
Theorem 30D presents the dilemma: Either the axioms are lying to 
us by allowing us to deduce false sentences, or else the axioms are 
incomplete, in the sense that some true sentences cannot be deduced 
from those axioms. 
This computability approach is implicit in parts of Section 3.5, but 
it is in Section 3.6 that the approach explicitly appears, and where it is 
compared with the other two approaches. 
SECTION 3.1 
Natural Numbers with Successor 
We begin with a situation that is simple enough to let us give reasonably 
complete answers to our questions. We reduce the set of parameters 
to just V, 0, and S, eliminating <, +, -, and E. The corresponding 
reduct of '32 is 
'Xs = (N; 0, S). 

188 
A Mathematical Introduction to Logic 
In this restricted language we still have the numerals, naming each point 
in N. But the sentences we can express in the language are, from the 
viewpoint of arithmetic, uninteresting. 
We want to ask about '31s the same questions that interest us in the 
case of '3l. We want to know about the complexity of the set Th nS; 
we 
want to study definability in f l S ;  and we want to survey the nonstandard 
models of '31s. 
To study the theory of the natural numbers with successor (Th '31s), 
we begin by listing a few of its members, i.e., sentences true in '31s. 
(These sentences will ultimately provide an axiomatization for the 
theory.) 
S 1. V x Sx # 0, a sentence asserting that zero has no predecessor. 
S2. V x  V y(Sx = Sy -+ x = y). This asserts that the successor 
function is one-to-one. 
S3. V y( y # 0- 3 x y = Sx). This asserts that any nonzero number 
is the successor of something. 
S4.1 V x S x # x .  
S4.2 V x  SSx f x .  
... 
S4.n V x Snx # x, where the superscript n indicates that the symbol 
S occurs at n consecutive places. 
Let As be the set consisting of the above sentences S 1, S2, S3, S4.n 
(n = 1,2, . . .). Clearly these sentences are true in '31s; i.e., !?Is is a 
model of As. Hence 
(Anything true in every model of As is true in this model.) What is 
not so obvious is that equality holds. We will prove this by considering 
arbitrary models of As. 
What can be said of an arbitrary model 
of the axioms As? S" must be a one-to-one map of lUl onto 1UI - {o"), 
by S1, S2, and S3. And by S4.n, there can be no loops of size n. Thus 
IUI must contain the "standard" points: 
which are all distinct. The arrow here indicates the action of S". There 
may or may not be other points. If there is another point a in IUI, then 
there will be the successor of a, its successor, etc. Not only that, but 
since (by S3) each nonzero element has a predecessor (something of 
which it is the successor) which is (by S2) unique, IUI must contain 
the predecessor of a, its predecessor, etc. These must all be distinct lest 

Chapter 3: Undecidability 
189 
there be a finite loop. Thus a belongs to a "Z-chain": 
' 
M 
-..*-+ *-+a -+ sM(a) -+ S (S (a)) -+ .... 
(We refer to these as Z-chains because they are arranged like the set 
Z of all integers {. . . , -1,0, 1,2, . . .).) There can be any number of 
Z-chains. But any two Z-chains must be disjoint, as S2 prohibits merg- 
ing. Similarly, any Z-chain must be disjoint from the standard part. 
This can be restated in another way. Say that two points a and b in IUI 
are equivalent if the function S' can be applied a finite number of times 
to one point to yield the other point. This is an equivalence relation. (It 
is clearly reflexive and symmetric; the transitivity follows from the fact 
that S' is one-to-one.) The standard part of IUI is the equivalence class 
containing 0%. For any other point (if any) a in IUI, the equivalence class 
of a is the set generated from {a) by SM and its inverse. This equivalence 
class is the Z-chain described above. 
Conversely, any structure 23 (for this language) that has a stan- 
dard part 
and a nonstandard part consisting of any number of separate Z-chains 
is a model of As. (Check through the list of axioms in As, and note that 
each is true in 23.) We thus have a complete characterization of what 
the models of As must look like. 
If a model M of As has only countably many Z-chains, then IUI 
is countable. In general, if the set of Z-chains has cardinality1 A, then 
altogether the number of points in IUI is KO + KO. A. By facts of cardinal 
arithmetic (cf. Chapter 0) this number is the larger of KO and A. Hence 
KO if U has countably many Z-chains, 
b 
if U has an uncountable number A of Z-chains. 
LEMMA 31 A If U and U' are models of As having the same number 
of Z-chains, then they are isomorphic. 
PROOF. There is a unique isomorphism between the standard part 
of U and the standard part of U'. By hypothesis we are given a 
one-to-one correspondence between the set of Z-chains of U and 
the set of Z-chains of U'; thus each chain of U is paired with a chain 
of U'. Clearly any two Z-chains are isomorphic. By combining 
all the individual isomorphisms (which uses the axiom of choice) 
we have an isomorphism of U onto U'. 
-I 
Thus a model of As is determined to within isomorphism by its num- 
ber of Z-chains. For '32s this number is zero, but any number is possible. 
To avoid uncountable cardinals, see Exercise 3. 

190 
A Mathematical Introduction to Logic 
The reader should note that there is no sentence of the language which 
says, "There are no Z-chains." In fact, there is no set X of sentences 
such that a model U of As satisfies E iff U has no Z-chains. For by the 
LST theorem there is an uncountable structure U with U = ns. But U 
has uncountably many Z-chains and nS has none. 
THEOREM 
31 B Let U and 23 be uncountable models of As of the 
same cardinality. Then U is isomorphic to 23. 
PROOF. By the above discussion, U has card% Z-chains, and 23 
has card 23 Z-chains. Since card U = card 23, they have the same 
number of Z-chains and hence are isomorphic. 
-I 
THEOREM 
31 C Cn As is a complete theory. 
PROOF. Apply the Log-Vaught test of Section 2.6. The preceding 
theorem asserts that the theory Cn As is categorical in any un- 
countable power. Furthermore, As has no finite models. Hence 
the Log-Vaught test applies. 
-I 
PROOF. We have Cn As & Th TIs; the first theory is complete and 
the second is satisfiable. 
-I 
*COROLLARY 
31 E ~h (32s is decidable. 
PROOF. Any complete and axiomatizable theory is decidable (by 
Corollary 25G). As is a decidable set of axioms for this theory. 
-I 
Elimination of Quantifiers 
Once one knows a theory to be decidable, it is tempting to try to find a 
realistically practical decision procedure. We will give such a procedure 
for Th ns, based on "elimination of quantifiers." 
DEFINITION. A theory T admits elimination of quantifiers iff for 
every formula (p there is a quantifier-free formula @ such that 
Actually it is enough to consider only formulas @ of a rather special 
form: 
THEOREM 
31 F Assume that for every formula (p of the form 
where each ai is an atomic formula or the negation of an atomic 
formula, there is a quantifier-free formula + such that T 
((p c-, @). Then T admits elimination of quantifiers. 

Chapter 3: Undecidability 
191 
PROOF. First we claim that we can find a quantifier-free equivalent 
for any formula of the form 3 x 8 for quantifier-free 8. We begin 
by putting 8 into disjunctive normal form (Corollary 15C). The 
resulting formula, 
is logically equivalent to 
By assumption, each disjunct of this formula can be replaced by 
a quantifier-free formula. 
We leave it to the reader to show (in Exercise 2) that by using 
the above paragraph one can obtain a quantifier-free equivalent 
for an arbitrary formula. 
-I 
In the special case where the theory in question is the theory Th U of 
a structure U, the definition can be restated: Th U admits elimination of 
quantifiers iff for every formula (p there is a quantifier-free formula $ 
such that (p and $ are "equivalent in U"; i.e., 
for any map s of the variables into I U I. 
THEOREM 
31 G Th !lIs 
admits elimination of quantifiers. 
PROOF. By the preceding theorem, it suffices to consider a formula 
3x(cro A -. . A a,), 
where each cri is atomic or is the negation of an atomic formula. 
We will describe how to replace this formula by another that is 
quantifier-free. The equivalence of the new formula to the given 
one will, in fact, be a consequence of As; see Exercise 3. 
In the language of !lIs the only terms are of the form Sku, where 
u is 0 or a variable. The only atomic formulas are equations. We 
may suppose that the variable x occurs in each cri. For if x does 
not occur in a ,  then 
Thus each cri has the form 
or the negation of this equation, where u is 0 or a variable. We 
may further suppose u is different from x, since Smx = Snx could 
bereplacedby O=Oifm = n, andbyO#Oifm # n. 

1 92 
A Mathematical Introduction to Logic 
Case 1 : Each cri is the negation of an equation. Then the formula 
may be replaced by 0 = 0. (Why?) 
Case 2: There is at least one cri not negated; say cro is 
where the term t does not contain x. Since the solution for x must 
be non-negative, we replace cro by 
(or by 0 = 0 if m = 0). Then in each other crj we replace, say, 
first by 
which in turn becomes 
We now have a formula in which x no longer occurs, so the quan- 
tifier may be omitted. 
-I 
There are several interesting by-products of the quantifier elimi- 
nation procedure. For one, we get an alternative proof of the com- 
pleteness of CnAs. Suppose we begin with a sentence a. The 
quantifier elimination procedure gives a quantifier-free sentence t such 
that (by Exercise 3) As 
(a t-, t). Now we claim that either As k t  
or As k 1 
t . For t is built up from atomic sentences by means of 1 
and -+. An atomic sentence must be of the form SkO = S'O and is de- 
ducible from As if k = 1, but is refutable (i.e., its negation is deducible) 
from As if k # I. (In fact, just {Sl, S2) suffices for this.) Since every 
atomic sentence can be deduced or refuted, so can every quantifier- 
free sentence. This establishes the claim. And so either As k a or 
As k la. 
Another by-product concerns the problem of definability in ns; see 
Exercises 4 and 5. For any formula gp in which just vl and q occur free 
we now can find a quantifier-free $ (with the same variables free) such 
that 
I=%, Q Vl Q 212(gp t-, $1. 
Thus the relation (p defined is also definable by a quantifier-free formula. 

Chapter3: Undecidability 
193 
Exercises 
1. Let A; be the set of sentences consisting of S 1, S2, and all sentences 
of the form 
where p is a wff (in the language of '32s) in which no variable except 
vl occurs free. Show that As g Cn A:. Conclude that Cn A; = 
Th rts. (Here p(t) is by definition pp' . The sentence displayed above 
is called the induction axiom for p.) 
2. Complete the proof of Theorem 3 IF. Suggestion: Use induction. 
3. The proof of quantifier elimination for Th '32s showed how, given a 
formula p, to find a quantifier-free $. Show that 
without using the completeness of Cn As. (This yields an alternative 
proof of the completeness of Cn As, not involving Z-chains or the 
LoS-Vaught test.) 
4. Show that a subset of N is definable in rts iff either it is finite or its 
complement (in N) is finite. 
5. Show that the ordering relation { (m , n ) I m < n in N) is not defihable 
in '32s. Suggestion: It suffices to show there is no quantifier-free 
definition of ordering. Call a relation R E N x N linear if it can 
be covered by a finite number of lines. Call R colinear if it is the 
complement of a linear relation. Show that any relation definable 
in '32s is either linear or colinear. And that the ordering relation is 
neither linear nor colinear. 
6. Show that Th '32s is not finitely axiomatizable. Suggestion: Show that 
no finite subset of As suffices, and then apply Section 2.6. 
SECTION 3.2 
Other Reducts of Number Theory' 
First let us add the ordering symbol < to the language. The intended 
structure is 
rtL = (N; 0, S, <). 
This section may be omitted without disastrous effects. 

A Mathematical Introduction to Lonic 
We want to show that the theory of this structure is (like Th n s )  decidable 
and also admits elimination of quantifiers. But unlike Th ns, it is finitely 
axiomatizable and is not categorical in any infinite cardinality. 
As axioms of Th 9IL we will take the finite set AL consisting of the 
six sentences listed below. Here x 5 y is, of course, an abbreviation for 
(x < y V x = y), and x g y abbreviates the negation of this formula. 
v x v y  
v x v y  
v x v y  
On the one hand, it is easy to see that all six axioms are true in '3tL. 
Thus Cn A E Th 'illL. On the other hand, the opposite inclusion is not 
obvious, and requires proof. We begin by listing some consequence of 
these axioms. 
(I) AL I-VXX < S X .  
PROOF. In L1 take y to be x. 
PROOF. In L4 take y to be x. 
(trichotomy). 
PROOF. From AL we can deduce the biconditionals: 
(5) AL I- S1 and AL I- S2. 
PROOF. S1 follows from L2 and (1). S2 comes from (4) by use of 
L3 and (2). 
-I 
PROOF. This follows from (1) and (2), by using L5. 

Chapter 3: 
Undecidability 
195 
Thus any model U of AL is (when we ignore <%) also a model of 
As. So it must consist of a standard part plus zero or more Z-chains. In 
addition, it is ordered by <'. 
THEOREM 32A The theory Cn AL admits elimination of quantifiers. 
PROOF. Again we consider a formula 
where each Pi is atomic or the negation of an atomic formula. The 
terms are, as in Section 3.1, of the form Sku, where u is 0 or a 
variable. There are two possibilities for atomic formulas, 
sku = slt and sku < slt. 
1. We can eliminate the negation symbol. Replace tl $ t2 by 
t2 < tl V tl = t2 and replace tl # t2 by tl < t2 V t2 < tl . (This is 
justified by L3 and L4.) By regrouping the atomic formulas and 
noting that 
we may again reach formulas of the form 
where now each at is atomic. 
2. We may suppose that the variable x occurs in each ai. This 
is because if x does not occur in a ,  then 
Furthermore, we may suppose that x occurs on only one side of 
the equality or inequality ai. For Skx = SIX can be dealt with as 
in Section 3.1. Skx < SIX can be replaced by 0 = 0 if k < I ,  and 
0 # 0 otherwise. (This is justified by L1 and L4.) 
Case 1: Suppose that some ai is an equality. Then we can 
proceed as in case 2 of the quantifier-elimination proof of 
Theorem 3 1 G. 
Case 2: Otherwise each ai is an inequality. Then the formula 
can be rewritten 
(Here Ai indicates the conjunction of formulas indexed by i, so 
yo A yl A 
. A yk can be abbreviated Ai yi.) In the first con- 
junction, Ai ti < Smix, we have the lower bounds on x; in the 
second conjunction, Aj Snjx < u j ,  we have the upper bounds. If 
the second conjunction is empty (i.e., if there are no upper bounds 

196 
A Mathematical Introduction to Logic 
on x), then we can replace the formula by 0 = 0. (Why?) If the 
first conjunction is empty (i.e., if there are no lower bounds on x), 
then we can replace the formula by 
/\ snj0 < u j ,  
i 
which asserts that zero satisfies the upper bounds. Otherwise, we 
rewrite the formula successively as 
This last formula says "any lower bound plus one satisfies any up- 
per bound, and furthermore zero satisfies any upper bound." This 
implies that there is a gap between the greatest lower bound and 
the least upper bound, whence there is a solution for x. The second 
part guarantees that the solution for x is not forced to be negative. 
In each case, we have arrived at a quantifier-free version of the 
given formula. 
-I 
COROLLARY 
32B (a) Cn A is complete. 
(b) Cn AL = Th'JIL. 
*(c) Th !?IL is decidable. 
PROOF. (a) The argument that followed the proof of Theorem 3 1G 
is applicable here also. (b) This follows from (a), since Cn AL E 
Th 'JIL and Th 'JIL is satisfiable. For (c), we can use the fact that 
any complete axiomatizable theory is decidable. But the quantifier 
elimination proof yields a more efficient decision procedure. -I 
COROLLARY 
32C A subset of N is definable in 'JIL iff it is either 
finite or has finite complement. 
PROOF. Compare Exercise 4 of the preceding section. 
-I 
On the other hand, 'JIL has more definable binary relations than has 
nS. 
For the ordering relation {(m, n) I m < n) is not definable in 'JIs, 
by Exercise 5 of the preceding section. 
COROLLARY 
32D The addition relation, 
{(m, n, p) Im + n = p), 
is not definable in !TIL. 

Chapter 3: 
Undecidabilitv 
197 
PROOF. If we could define addition, we could then define the set of 
even natural numbers. But this set is neither finite nor has finite 
complement. 
-I 
Now suppose we augment the language by the addition symbol +. 
The intended structure is 
The theory of this structure is also decidable, as we will prove shortly. 
But to keep matters from getting even more complicated, we will avoid 
listing any convenient set of axioms for the theory. 
The nonstandard models of Th 
must also be models of Th 91L. 
So they have a standard part, followed by some Z-chains. But ordering 
among the Z-chains can no longer be arbitrary. Let U be a nonstandard 
model of Th %A. The ordering <' induces a well-defined ordering on 
the set of Z-chains. (See Exercise 3.) We claim that there is no largest 
Z-chain, there is no smallest Z-chain, and there is between any two Z- 
chains another one. The reasons, in outline, can be stated simply: If a 
belongs to some Z-chain (i.e., is an infinite element of U), then a +a a 
is in a larger 2-chain. There must be some b such that b +' b is either 
a or its successor; b must be in a smaller Z-chain. If a1 and a2 belong to 
different Z-chains, then there must be some b such that b+' 
b is either 
a1 +a a2 or its successor. And b will lie in a Z-chain between that of 
a1 and that of a2. (These statements should seem quite plausible. The 
reader who enjoys working with infinite numbers might supply some 
details.) 
"THEOREM 
32E (PRESBURGER, 
1929) The theory of the structure 
91A = (N; 0, S, <, +) is decidable. 
The proof is again based on a quantifier elimination procedure. 
The theory of 
itself does not admit elimination of quantifiers. 
For example, the formula defining the set of even numbers 
is not equivalent to any quantifier-free formula. We can overcome 
this by adding a'new symbol ~2 for congruence modulo 2. Sim- 
ilarly, we add symbols ~ 3 ,  
~
4
,
 
. . . . The intended structure for 
this expanded language is 
%= = (N; 0, S, <, +, ~
2
,
 
~ 3 , .  
. .), 
where k is the binary relation of congruence modulo k. It turns 
out that the theory of this structure does admit elimination of 
quantifiers. 
This by itself does not imply that the theory of either structure 
is decidable. After all, we can start with any structure, and expand 

198 
A Mathematical Introduction to Logic 
it to a structure having additional relations until a structure is ob- 
tained that admits elimination of quantifiers. To obtain decidabil- 
ity, we must show that we can, given a sentence a ,  (1) effectively 
find a quantifier-free equivalent a', and then (2) effectively decide 
if a' is true. 
We will now give the quantifier elimination procedure for 
Th n'. For a term t and a natural number n, let nt be the term 
t + t + . . + t, with n summands. Ot is 0. Then any term can be 
expanded to one of the form 
for k 2 0, ni 2 0 (where the xi's are variables). For example, 
becomes 
As usual we begin with a formula 3 y(P1 A . . A B,), where 
Pi is an atomic formula or the negation of one. 
1. Eliminate negation. Replace l ( t l  = t2) by (tl < t2 V t2 < tl). 
Replace 7(tl < t2) by (tl = t2 V t2 < tl). And replace ~ ( t l  
E, t2) 
by 
Then regroup into a disjunction of formulas of the form 
where each ui is atomic. We may further suppose, as before, that 
y occurs in each ui, and in fact that ai has one of the four forms 
where u and t are terms not containing y. In what follows we 
will take the liberty of writing these formulas with a subtraction 
symbol: 
n y =  u - t ,  
ny G ,  u - t, 
n y <  u - t ,  
u - t  < ny. 
These are merely abbreviations for the formulas without subtrac- 
tion obtained by transposing terms. 

Chapter 3: Undecidability 
199 
For example, we might have at this point the formula 
where t, u, v, and w are terms not containing y. 
2. Uniformize the coefficients of y. Let p be the least common 
multiple of the coefficients of y. Each atomic formula can be 
converted to one in which the coefficient of y is p, by "multiplying 
through" by the appropriate factor. This is obviously legitimate 
for equalities and inequalities. In the case of congruences one 
must remember to raise the modulus also: 
a -, 
b iff ka rkm 
kb. 
In the example above p is 12, and we obtain 
3. Eliminate the coefficient of y . Replace py by x and add the 
new conjunct x 
0. (In place of 3 y . 12y . we can equally 
well have, "There exists a multiple x of 12 such that . - . x . - .") 
Our example is now converted to 
4. Special case. If one of the atomic formulas is an equality, 
x + t = U, then we can replace 
3 x 0  
Here replacement of x by "u - t" is the natural thing; we transpose 
terms to compensate for the absence of subtraction. For example, 
5. We may assume henceforth that = does not occur. So we 
have a formula of the form 
where ri, si, ti, ui, vi, and wi are terms not containing x. This can 
be abbreviated 
3~ [ A r j - s j < x  
A A x < t i - ~ i  A A-~=rn,ui-wi 
j cl 
i c k  
i c n  
1 
If there are no congruences (i.e., n = 0), then the formula as- 
serts that there is a nonnegative space between the lower and 

200 
A Mathematical introduction to Logic 
upper bounds. We can replace the formula by the quantifier-free 
formula: 
Let M be the least common multiple of the moduli mo, . . . , 
m,- 1. Then a + M 
a. So as a increases, the pattern of residues 
of a modulo mo, . . . , m,-1 has period M. Thus, in searching for a 
solution to the congruences, we need only search M consecutive 
integers. 
We now have a formula that asserts the existence of a natural 
number which is not less than certain lower bounds L1, . . . , LI 
and which satisfies certain upper bounds and certain congruences. 
If there is such a solution, then one of the following is a solution: 
(The last line is needed to cover the case in which every Lj is 
negative. To avoid having to treat this line as a special case, we 
will add a new lower bound of 0. That is, let rl = 0 and sl = SO 
so that 
is a formula 0 < x + SO asserting that x is nonnegative. We now 
have I + 1 lower bounds.) 
Our formula (asserting the existence of a solution for x) can 
now be replaced by a quantifier-free disjunction that asserts that 
one of the numbers in the above matrix is a nonnegative solution: 
In our continuing example we have, after adding the new lower 
bound on x, 
The quantifier-free equivalent is a disjunction of 72 conjunctions. 
Each conjunction has six constituents. 

Chapter 3: 
Undecidability 
This proves half of the theorem. If we are given a sentence a ,  
the above procedure tells us how to find effectively a quantifier- 
free sentence t (in the language of %') that is true (in the intended 
structure) iff a is. Now we must decide if t is true. 
But this is easy. It is enough to look at atomic sentences. Any 
variable-free term can be put in the form SnO. Then, for example, 
is true iff n =, 
p. 
Thus we have a decision procedure for Th %A. In 1974 Michael 
Fischer and Michael Rabin showed, however, that there is no decision 
procedure that is fast enough to be feasible for very long formulas. 
A set D of natural numbers is said to beperiodic if for some positive 
p, any number n is in D iff n + p is in D. D is eventually periodic iff 
there exist positive numbers M and p such that for all n greater than M, 
n E D i f f n + p  E D. 
THEOREM 
32F A set of natural numbers is definable in (N; 0, S, 
<, +) iff it is eventually periodic. 
PROOF. Exercise 1 asserts that every eventually periodic set is de- 
finable. Conversely, suppose D is definable. Then D is defin- 
able in %' by a quantifier-free formula (whose only variable is 
vl). Since the class of eventually periodic sets is closed under 
union, intersection, and complementation, it suffices to show that 
every atomic formula in the language of %' 
whose only vari- 
able is vl defines an eventually periodic set. There are only four 
possibilities: 
where u and t are numerals. The first two formulas define finite 
sets (which eventually have period I), the third defines a set with 
finite complement, and the last formula defines a periodic set with 
period m . 
-I 
COROLLARY 
32G The multiplication relation 
{(m, n, p) I p = m . n in N) 
is not definable in (N; 0, S, <, +). 
PROOF. If we had a definition of multiplication, we could then use 
that to define the set of squares. But the set of squares is not 
eventually periodic. 
-I 

202 
A Mathematical Introduction to Logic 
Exercises 
1. Show that any eventually periodic set of natural numbers is definable 
in the structure 
2. Show that in the structure (N; +) the following relations are 
definable: 
(a) Ordering, { (m, n) I m c n). 
(b) Zero, (0). 
(c) Successor, { (m, n) I n = S(m)). 
3. Let U be a model of Th '57~ (or equivalently a model of AL). For a 
and b  in 1% I define the equivalence relation: 
a  -- b  
S' can be applied a finite number of times to one 
of a, b  to reach the other. 
Let [a] be the equivalence class to which a belongs. Order equiva- 
lence classes by 
[ a ] + [ b ]  iff a<'b 
and a y b .  
Show that this is a well-defined ordering on the set of equivalence 
classes. 
4. Show that the theory of the real numbers with its usual ordering, 
Th(R; c), admits elimination of quantifiers. (Assume that the lan- 
guage includes equality.) 
SECTION 3.3 
A Subtheory of Number Theory 
We now return to the full language of number theory, as described in 
Section 3.0. The parameters of the language are V, 0, S, <, +, -, and 
E. The intended structure for this language is 
'57 = (N; 0, S, c ,  +, ., E). 
Actually in (N; -, E) we can define {O), S, <, and+. (See Exercise 1 .) 
As we will show in Section 3.8, in (N; +, .) we can define E as well as 
0, S, and c . So there are ways in which we could economize. The luxury 
of having all these parameters (particularly E) will simplify some of the 
proofs. 
As we shall see, Th '57 is a very strong theory and is neither decidable 
nor axiomatizable. In order to prove this fact (and a number of related 
results), it will be strategically wise to select for study a finitely axiom- 
atizable subtheory of Th'57. As hinted at in Section 3.0, this subtheory 
should be strong enough to represent (in a sense to be made precise) 
facts about decidable sets. The subtheory we have selected is Cn AE, 

Chapter 3: Undecidability 
203 
where A is the set consisting of the eleven sentences listed below. (As 
in the preceding section, x 5 y abbreviates x < y V x = y.) 
Set AE of Axioms 
v x v y  (Sx=Sy-+x=y) 
v x v y  ( x < y V x = y V y < x )  
v x v y  x +Sy=S(x + y )  
v x v y  x*Sy=xmy+x 
Since '57 is a model of A E, we have Cn A 5 Th '57. But (as we will 
prove in Section 3.5) equality does not hold here. In fact, it can be shown 
that AE bL S3, where S3 is the sentence V y(y # 0 -+ 3 x y = Sx). 
The first five axioms give us some, but not all, of the axioms regard- 
ing S and < that were useful in the preceding sections. The other six 
axioms are the "recursion" equations for addition, multiplication, and 
exponentiation. 
We first show that certain simple sentences in Th'57 are deducible 
from AE. 
LEMMA 33A (a) AE I- VX x $0. 
(b) For any natural number k, 
Notice that (a) can be thought of as the k = -1 case of (b), where 
the empty disjunction is I. The lemma tells us that AE "knows" that 
the numbers less than 7, for example, are exactly 0, 1,2,3,4, 5,6. So in 
any model of A E, the standard points -the ones denoted by numerals 
skO - 
are ordered in the natural way, and (by L3) the infinite points, if 
any, are all larger than any standard point. 
PROOF. Part (a) is L2. For (b) we use induction (in English) on k. 
We have as a consequence of L1, 
x < S O * x < O v x = 0 -  

204 
A Mathematical Introduction to Logic 
which together with L2 gives 
which is the k = 0 case of (b). For the inductive step we again 
apply L 1 : 
x < sk+'0 t, x < sk0 V x = sk0. 
By the inductive hypothesis, x < skO can be replaced by 
X = so0 V - - V X = sk-lo, 
whereby we obtain (b). 
LEMMA 33B For any variable-free term t, there is a unique natural 
number n such that 
PROOF. The uniqueness is immediate. (Why? Because AE, weak 
as it is, at least knows, by S1, that 7 # 0, and by S2 80 times, 
that 87 # 80.) For the existence half, we use induction on t. If t 
is 0, we take n = 0. If t is Su, then by the inductive hypothesis 
A I- u = SmO for some m. Hence A I- t = Sm+l 0. 
Now suppose t is ul + 2-42. By the inductive hypothesis 
AE I- t =SmO + SnO for some m and n. We now apply A2 n 
times and A1 once to obtain AE I- t = Sm+"O. The arguments for 
multiplication and exponentiation are similar. 
-I 
As a special case of this lemma we have "2 + 2 = 4" (i.e., S20 + 
S20 = S40) as a consequence of AE. AE is at least smart enough to 
evaluate variable-free terms. And the proof shows more than this. The 
proof provides exact instructions for how, given such a term t, to find 
effectively the unique number n such that A I- t = SnO. 
THEOREM 
33C For any quantifier-free sentence t true in 'JZ, AE I- t . 
PROOF. Exercise 2. Start with the atomic sentences; these will be of 
the form tl = tz or tl < t2 for variable-free terms tl and t2. Show 
that AE proves t if t is true in 'JZ, and refutes t (i.e., proves 1 
t )  
if t is false in 'JZ. 
-I 
Later on, we will improve on Theorem 33C by allowing t to contain 
"bounded quantifiers"; see Theorem 331. 
A simplified notation (used earlier in Section 2.7) for substitution 
will be helpful in the coming pages: 
and so forth. Thus (o = (o(vl) = (o(vl, u;?). Usually the term substituted 

Chapter 3: 
Undecidability 
205 
will be a numeral, for example 
But at times we will also substitute other terms, e.g., ~ ( x )  
= (p?, where 
x is a variable. If, however, x is not substitutable for ul in (p, then we 
must take q(x) = $?, where $ is a suitable alphabetic variant of v. 
In the next proof (and elsewhere in this chapter) we make use of 
the following consequence of the substitution lemma of Section 2.5: 
For a formula rp in which at most vl , . . . , u, occur free and for natural 
numbers al , . . . , a,, 
An existential ( 3  1) formula is one of the form 3 x1 - - 3  
xk8, where 
0 is quantifier-free. The following result improves Theorem 33C: 
COROLLARY 
33D If t is an existential sentence true in '57, then 
AE I- t. 
PROOF. If 3 u13 %0 is true in '57, then for some natural numbers 
m and n, 8(Sm0, SnO) is true in '57. As this is a quantifier-free true 
sentence, it is deducible from A E. But it in turn logically implies 
3 % 3 % 8 .  
-I 
On the other hand, it is known that there are true universal (\dl) 
sentences (i.e., of the form Vxl . . VxkO for quantifier-free 8) that are 
not in Cn A E .  
Representable Relations 
Let R be an m-ary relation on N; i.e., R g Nm. We know that a formula 
p (in which only vl, . . . , um occur free) defines R in '57 iff for every 
al, . . . , a, in N, 
(The last condition here is equivalent to the preceding one by the sub- 
stitution lemma.) We can recast this into two implications: 
We will say that p also represents R in the theory Cn A if in these two 
implications the notion of truth in '57 can be replaced by the stronger 
notion of deducibility from A E. 
More generally, let T be any theory in a language with 0 and S. Then 
p represents R in T iff for every al, . . . , a, in N: 
(al,. . . ,a,) E R J p(SalO,. . . , SamO) E T, 
(al,. . . , a,) 4 R -4 (1 
p(SalO, . . . , ShO)) E T. 

A Mathematical Introduction to Logic 
For example, p represents R in the theory Th % iff p defines R in %. 
But p represents R in Cn A iff for all al, . . . , a, : 
The equality relation on N, for example, is represented in Cn A by the 
formula vl = Q. For 
A relation is representable in T iff there exists some formula that rep- 
resents it in T. 
The concept of representability should be compared with that of 
definability. In both cases we are somehow describing relations on the 
natural numbers by formulas. In the case of definability, we ask about 
the truth of sentences in the interpretation. In the case of representability 
in Cn A E, we ask instead about the deducibility of sentences from the 
axioms. 
Say that a formula q, in which no variables other than vl, . . . , v, 
occur free, is numeralwise determined by AE iff for every m-tuple 
al, . . . , a, of natural numbers, either 
THEOREM 
33E A formula p represents a relation R in Cn AE iff 
(1) p is numeralwise determined by A E, and 
(2) p defines R in %. 
PROOF. We use the fact that % is a model of AE. If p represents R 
in Cn AE, then it is clear that (1) holds; (2) holds since "AE I-" 
implies "Pn." Conversely, if (1) and (2) hold, then we have 
(al, . . . , a,) E R =+ Pfl p(SalO,. . . , SamO) 
by (2) 
+ AEbL ip(SalO, ..., SamO) since%isamodel 
of AE 
+AEk~(SalO,...,SamO) by(1). 
Similarly for the complement of R and 1 
p. 
Church's Thesis 
We now turn to the relationship of the concepts of representability and 
decidability. 
*THEOREM 
33F Assume that R is a relation representable in a con- 
sistent axiomatizable theory. Then R is decidable. 

Chapter 3: Undecidability 
207 
PROOF. Say that p represents R in the consistent axiomatizable 
theory T. Recall that T is effectively enumerable (Corollary 25F). 
The decision procedure is as follows: 
Given al, . . . , a,, enumerate the members of T. If, in the 
enumeration, p (Sat 0, . . . , Sam 0) is found, then we are done and 
(al, . . . , a,) E R. If, in the enumeration, 1 
p(Sal 0, . . . , SamO) is 
found, then we are done and (al,. . . ,a,) 4 R. 
By the representability, one sentence or the other always ap- 
pears eventually, whereupon the procedure terminates. Since T is 
consistent, the answer given by the procedure is correct. 
-I 
*COROLLARY 
33G Any relation representable in a consistent finitely 
axiomatizable theory is decidable. 
What about the converse to the above corollary? We cannot really 
hope to prove the converse on the basis of our informal notion of de- 
cidability. For our informal approach is usable only for giving lower 
bounds on the class of decidable relations (i.e., for showing that certain 
relations are decidable) and is unsuited to giving upper bounds (i.e., for 
showing undecidability). 
It is nevertheless possible to make plausibility arguments in support 
of the converse. This will be easier to do at the end of Section 3.4 than 
here. Roughly, the idea is that in a finite number of axioms we could 
capture the (finitely long) instructions for the decision procedure. 
The assertion that both the above corollary and its converse are cor- 
rect is generally known as Church's thesis. This assertion is not really 
a mathematical statement susceptible to proof or disproof; rather it is a 
judgment that the correct formalization of the informal notion of decid- 
ability is by means of representability in consistent and finitely axiom- 
atizable theories. 
DEFINITION. 
A relation R on the natural numbers is recursive iff it 
is representable in some consistent finitely axiomatizable theory 
(in a language with 0 and S). 
Church's thesis now can be put more succinctly: A relation is de- 
cidable iff it is recursive. Or perhaps more accurately: The concept of 
recursiveness is the correct precise counterpart to the informal concept 
of decidability. The situation is analogous to one encountered in calcu- 
lus. An intuitively continuous function (defined on an interval) is one 
whose graph you can draw without lifting your pencil off the paper. But 
to prove theorems, some formal counterpart of this notion is needed. 
And so one gives the usual definition of E-8-continuity. One should ask 
if the precise notion of E-8-continuity is an accurate formalization of 
intuitive continuity. If anything, the class of E-6-continuous functions is 
too broad. It includes nowhere differentiable functions, whose graphs 
cannot be drawn without lifting the pencil. But accurate or not, the class 

208 
A Mathematical Introduction to Logic 
of E-8-continuous functions has been found to be a natural and important 
class in mathematical analysis. 
Very much the same situation occurs with recursiveness. One should 
ask if the precise notion of recursiveness is an accurate formalization of 
the informal notion of decidability. Again, the precisely defined class 
(of recursive relations) appears to be, if anything, too broad. It includes 
relations for which any decision procedure will, for large inputs, require 
so much computing time and memory ("scratchpad") space as to make 
implementation absurd. Recursiveness corresponds to decidability in 
an idealized world, where length of computation and amount of mem- 
ory are disregarded. But in any case, the class of recursive relations 
has been found to be a natural and important class in mathematical 
logic. 
Empirical evidence that the class of recursive relations is not too 
narrow is provided by the following: 
1. Any relation considered thus far that mathematicians have felt 
was decidable has been found to be recursive. 
2. Several people have tried giving precise definitions of idealized 
computing agents. The best-known such idealized agents are the "Turing 
machines," introduced by Alan Turing in 1936. (A variation on that idea 
leads to the register machines described in Section 3.6.) The idea was 
to devise something that could carry out any effective procedure. In 
all cases, the class of relations having decision procedures executable 
by such a computing agent has been exactly the class of recursive 
relations. (Because of the importance of Turing's analysis of effec- 
tive computability, Church's thesis is often called the Church-Turing 
thesis.) 
The fact that so many different (yet equivalent) definitions for the 
class of recursive relations have been found is some indication of the 
naturalness and importance of the concept. 
In this book we will continue to exclude the informal notion of decid- 
ability from nonstarred theorems. But in the remainder of the exposition 
we will accept Church's thesis. For example, we will speak of a set's 
being undecidable when we have a theorem stating it to be nonrecursive. 
Obviously any relation representable in Cn AE is recursive. We will 
prove later that the converse also holds; if a relation is representable in 
any consistent finitely axiomatizable theory, then it is representable in 
the one theory we have selected for special study. (This was, of course, 
a motivating factor in our selection.) 
The use of the word "recursive" in this context is the result of histori- 
cal accident - 
even of historical error. Recently several mathematicians 
have argued that the word "computable" would more accurately reflect 
the intended ideas. But in the present context, we want to reserve the 
word "computable" for an informal concept, to be defined next. For 
relations we have the informal concept of decidability; for functions the 

Chapter 3: Undecidability 
209 
analogous concept is computability. (As notational shorthand, a string 
al, . . . , ak can be written as 2.) 
*DEFINITION. 
A function f : Nk -+ N is computable iff there is an 
effective procedure that, given any k-tuple 2 of natural numbers, 
will produce f (2). 
For example, addition and multiplication are computable. Effective 
procedures, using base- 10 notation, for these functions are taught in the 
elementary schools. (Strictly speaking, in the concept of computabil- 
ity one should refer to being given numerals, not numbers. For it is 
numerals - 
strings of symbols like the triple 3 17 or the triple XCI - 
that can be communicated. Nonetheless, we will suppress this point.) On 
the other hand, of the uncountably many functions from Nk into N, 
only 
countably many can be computable, because there are only countably 
many effective procedures. 
We want to give a mathematical counterpart to the informal concept 
of computability, just as in the case of decidable relations. The clue to 
the correct counterpart is provided by the next theorem. Recall that any 
function f : Nk -+ N is also a (k + 1)-ary relation on N: 
At one time it was popular to distinguish between the function and 
the relation (which was called the graph of the function). Current set- 
theoretic usage takes a function to be the same thing as its graph. But 
we still have the two ways of looking at the function. 
*THEOREM 
33H The following three conditions on a function 
f : Nk + N are equivalent: 
(a) f is computable. 
(b) When viewed as a relation, f is a decidable relation. 
(c) When viewed as a relation, f is an effectively enumerable 
relation. 
PROOF. (a) + (b): Assume that f is computable; we will de- 
scribe the decision procedure. Given (al, . . . , ak, b), first com- 
pute f (al, . . . , ak). Then look to see if the result is equal to b. If 
it is say "yes," otherwise say "no." 
(b) =+ (c): Any decidable relation is effectively enumerable. 
For we can enumerate the set of all (k + 1)-tuples of numbers, and 
place on the output list those which meet the test of belonging to 
the relation. 
(c) + (a): Assume that we have an effective enumeration of 
(the graph of) f .  To compute f (al, . . . , ak) we examine the 
(k + 1)-tuples in the enumeration until we find the one that begins 
with a1 . . . , ak. Its last component is then the desired function 
value. 
-I 

210 
A Mathematical Introduction to Logic 
Thus by using Church's thesis, we can say that f is computable iff 
f (viewed as a relation) is recursive. The class of recursive functions is 
an interesting class even apart from its connection with incompleteness 
theorems of logic. It represents an upper bound to the class of functions 
that can actually be computed by programs for digital computers. The 
recursive functions are those which are calculable by digital comput- 
ers, provided one ignores practical limitations on computing time and 
memory space. 
We can now describe our plans for this section and the next. Our 
basic goal is to obtain the theorems of Section 3.5. But some ground- 
work is required before we can prove those theorems; we must ver- 
ify that a number of relations (intuitively decidable) and a number 
of functions (intuitively computable) are representable in Cn AE and 
hence are recursive. In the process we will show (Theorem 34A) that 
recursiveness is equivalent to representability in Cn A E. In the remain- 
der of the present section we will establish general facts about rep- 
resentability, and will show, for example, that certain functions for 
encoding finite sequences of numbers into single numbers are repre- 
sentable. Then in Section 3.4 we apply these results to particular re- 
lations and functions related to the syntactical features of the formal 
language. 
The author is sufficiently realistic to know that many readers will be 
more interested in the theorems of Section 3.5 than in the preliminary 
spadework. If the reader is willing to believe that intuitively decidable re- 
lations are all representable in Cn A E, and intuitively computable func- 
tions are functionally representable (a concept we will define shortly) 
there, then most if not all of the proofs in this spadework become un- 
necessary. But it is hoped that the definitions and the statements of the 
results will still receive some attention. 
Numeralwise Determined Formulas 
Theorem 33E tells us that we can show a relation to be representable 
in Cn AE by finding a formula that defines it in TI and is numeralwise 
determined by AE. The next theorem will be useful in establishing 
numeralwise determination. 
THEOREM 
331 (a) Any atomic formula is numeralwise determined 
by AE. 
(b) If rg and $ are numeralwise determined by A E, then so are 
lrgandrg-+$. 
(c) If rg is nuineralwise determined by A E, then so are the fol- 
lowing formulas (obtained from rg by "bounded quantification"): 

Chapter 3: Undecidability 
21 1 
PROOF. Part (a) follows from Theorem 33C. Part (b) is easy. It 
remains to prove part (c). We will consider a formula 
in which just the variables y and z occur free. Consider two natural 
numbers a and b; we must show that either 
Case 1 : For some c less than a, 
(This case occurs iff 3 x(x < SaO A rp(x, SaO, SbO)) is true in %.) 
We also have 
And the sentences in (1) and (2) logically imply the sentence 
Case 2: Otherwise for every c less than a, 
(This case occurs iff Vx(x < SaO --+ -I p(x, SaO, SbO)) is true in 
%.) We know from Lemma 33A that 
The sentence in (4) together with the sentences in (3) (for 
c = 0, . . . , a - 1) logically imply 
And this is equivalent to 
This shows that 3 x(x < y A rp(x, y, z)) is numeralwise deter- 
mined by AE. By applying this result to 1 
rp we obtain the fact 
that the dual formula, Vx(x < y --+ q(x, y, z)), is numeralwise 
determined by A as well. 
-I 
The argument in case 2 relied on the fact that the x quantifier was 
bounded by SaO. We will see that it is possible for 

212 
A Mathematical introduction to Logic 
all to be consequences of AE without having 
Qx 1 
$(x) 
be a consequence. 
The preceding theorem is a useful tool for showing many relations 
to be representable in Cn A E. For example, the set of primes is repre- 
sented by 
This formula defines the primes in '3t, and by the preceding theorem is 
numeralwise determined by A E .  It therefore represents the set of primes 
in Cn A E .  
Representable Functions 
Often it is more convenient to work with functions than with relations. 
Let f : Nm -+ N be an m-place function on the natural numbers. A for- 
mula (o in which only vl , . . . , um+~ 
occur free will be said tofinctionally 
represent f (in the theory Cn AE) iff for every a 1, . . . , am in N, 
(Observe that the "c" 
half of this sentence is equivalent to (o(SalO, . . . , 
SamO, Sf(al~...~am)O). 
The "+" 
half adds an assertion of uniqueness.) 
THEOREM 
33 J 
If (o functionally represents f in Cn A E, then it also 
represents f (as a relation) in Cn A E. 
PROOF, WITH m = 1. Since (o functionally represents f ,  we have 
for any b: 
If (a, b) E f ,  i.e., if f (a) = b, then the right half of this bicondi- 
tional is valid and we get 
But otherwise the right half is refutable from A (i.e., its negation 
is deducible), whence 
The converse of this theorem is false. But we can change the formula: 
THEOREM 33K Let f be a function on N that is (as a relation) repre- 
sentable in Cn A E. Then we can find a formula (o that functionally 
represents f in Cn A E . 

Chapter 3: Undecidability 
PROOF. TO simplify the notation we will take f to be a one-place 
function on N. The desired sentence, 
v v2[p(SU0, ,,) 
* 
'U;? = S ~ ( ~ ) O ] ,  
is equivalent to the conjunction of the two sentences 
p(SUO, Sf (a)O) 
and 
The sentence (1) is a theorem of AE whenever p represents f .  
The sentence (2) is an assertion of uniqueness; we must construct 
p in such a way that this will also be a theorem of A E .  
Begin with a formula 0 known to represent f (as a binary 
relation). Let p be 
We can then rewrite (2) as 
To show this to be a theorem of A E it clearly suffices to show that 
Call this set of hypotheses (to the left of "I-") r. Since L3 E AE 
it suffices to show that 
r I- % g ~ f ( ~ ) o  
and 
It is easy to obtain (4), since from the last member of r we get 
sf ("'0 < w --+ - e (sao, sf (")o) 
and we know that 
To obtain (3) we first note that we have as theorems of A E ,  
and 
le(SaO,SbO) forb=O, ..., f(a) - 1. 
The formulas (6) and (7) imply the formula 
Since 8 (SaO, w) 
E r, we have (3). 

21 4 
A Mathematical Introduction to Logic 
This shows (2) to be a theorem of AE; (5) and (8) show (1) to 
be a theorem of A as well. 
-I 
We next want to show that certain basic functions are representable 
(in Cn A E) and that the class of representable functions has certain clo- 
sure properties. Henceforth in this section, when we say that a function 
or relation is representable, we will mean that it is representable in the 
theory Cn A E. But the phrase "in Cn A E'' will usually be omitted. 
In simple cases, an m-place function might be represented by an 
equation 
In fact, any such equation, when the variables in t are among ul , . . . , urn, 
defines in '32 an m -place function f . (The value of f at (a . . . , a,) 
is the number assigned in '32 to t when ui is assigned ai, 1 I. i 5 m.) 
Furthermore, we know that any equation is numeralwise determined by 
A E, SO the equation represents f as arelation. In fact, it even functionally 
represents f, for the sentence 
-sf (al,...,am) 
V W ~ + ~ [ U ~ + ~  
= t(SalO, . . . , SamO) * um+l - 
01 
is logically equivalent to 
t(Sa'O, . . ., S ~ O )  
= s f  (a~~...~arn)o 
7 
which is a quantifier-free sentence true in !?I. 
(Here t (u 1, . . . , u,) is the 
term obtained by replacing ul by u 1, then vz by u2, etc.) For example: 
1. The successor function is represented (functionally) by the 
equation 
2. Any constant function is representable. The m-place function that 
constantly assumes the value b is represented by the equation 
3. The projection function (where 1 5 i 5 m) 
is represented by the equation 
4. Addition, multiplication, and exponentiation are represented by 
the equations 
respectively. 

Chapter 3: Undecidabilitv 
21 5 
The reader should not be misled by these simple examples; not every 
representable function is representable by an equation. 
We next want to show that the family of representable functions is 
closed under composition. To simplify the notation, we will consider a 
one-place function f on N, 
where 
Suppose that g is functionally represented by $ and hi by Bi . To represent 
f it would be reasonable to try either 
(Think of $(yl, y2, 'u;?) as saying "g(y1, y2) = Q" and think of 
Bi(vl, yl) as saying "hi(vl) = yi." Then the first formula translates, 
''For any Y l ,  Y2, if h l ( ~ 1 )  = y1 and h2(~1) = Y2, then g(y1, y2) = %." 
The second formula translates, "There exist yl , y2 such that h 1 (vl) = yl 
and h2(u1) = y2 and g(yl, y2) = Q." Either one is a reasonable way 
of saying, "g(h (vl), h2(vl)) = Q." There are two choices, because 
when something is unique, either quantifier can be used for it.) 
Actually either formula would work; let (o be 
Consider any natural number a; we have at our disposal 
And we want 
But (I), (2), and (3) imply (4), as the reader is asked to verify in 
Exercise 4. 
More generally we have 
THEOREM 
331 Let g be an n-place function, let h 1, . . . , h, be m- 
place functions, and let f be defined by 

216 
A Mathematical introduction to Logic 
From formulas functionally representing g and h 1, . . . , hn we can 
find a formula that functionally represents f .  
In the above proof we have m = 1 and n = 2. But the general case 
is proved in exactly the same way. 
In order to obtain a function such as 
we note that 
The above theorem then can be applied (twice) to show that f is repre- 
sentable (provided that g and h are). 
To facilitate discussion of functions with an arbitrary number of 
variables, we will use vector notation. For example, the equation in the 
above theorem can be written 
Another important closure property of the functions representable in 
Cn AE is closure under the "least-zero" operator. 
THEOREM 
33M Assume that the (m + 1)-place function g is repre- 
sentable and that for every al, . . . , a, there is a b such that 
Then we can find a formula that represents the m-place function 
f ,  where 
f (a1 , . . . , a,) = the least b such that g(al, . . . , a,, b) = 0. 
(In vector notation we can rewrite this last equation: 
f (i) = the least b such that g(i, b) = 0. 
The traditional notation for the least-zero operator is 
f (2) = pb[g(Z, b) = 01 
and the operator is often called "the p-operator.") 
PROOF. TO simplify the notation we take m = 1; thus 
f(a) = b iff g(a,b) = 0 andforall c < b, g(a,c) #O. 
If t,b represents g, then we can obtain a formula representing f (as 
a relation) simply by formalizing the right side of this equivalence: 

Chapter 3: Undecidabilitv 
21 7 
This formula defines (the graph of) f and is numeralwise deter- 
mined by A E. 
-I 
A Catalog 
We now construct a repertoire of representable (in Cn AE) functions and 
relations, including in particular functions for encoding and decoding 
sequences. 
0. As a consequence of Theorem 331, any relation that has (in 3) 
a 
quantifier-free definition is representable. And the class of representable 
relations is closed under unions, intersections, and complements. And 
if R is representable, then so are 
{(al ,..., a,,b) (forallc < b, (al ,... ,a,,c) E R )  
and 
{(al, . . . , a,, b) ( for some c < b, (al, . . . , a,, c) E R). 
For example, any finite relation has a quantifier-free definition, as does 
the ordering relation. 
1. A relation R is representable iff its characteristic function KR is. 
(KR is the function for which KR (i) = 1 when ii E R, and KR (2) = 0 
otherwise.) 
PROOF. (+) Say that R is a unary relation (a subset of N) and 
that KR is represented by +(vl, u;?). We claim that Ilr (v17 SO) 
represents R. For it defines R and is numeralwise determined 
by AE. 
(=+) Say that (o (vl ) represents R. Then 
represents (the graph of) KR, for the same reason as in the last 
pmagraph. (Actually this formula even functionally represents 
KR, as the reader can verify.) 
-I 
2. If R is a representable binary relation and f , g are representable 
functions, then 
(2 I (f ( 3 ,  g(2)) E R )  
is representable. Similarly for an m-ary relation R and functions 
f i , - - . , f m -  
PROOF. Its characteristic function at 2 has the value KR( f (z), 
g(2)). Thus it is obtained from representable functions by com- 
position. 
-I 
For example, suppose that R is a representable ternary relation. Then 

218 
A Mathematical Introduction to Logic 
is representable, being 
{(*, Y)~(I:(*, Y ) ,  I:(*, 
y), I:(*, 
y)) E R ) .  
In this way we can rearrange and repeat variables in describing a repre- 
sentable relation. 
3. If R is a representable binary relation, then so is 
P = {(a, b) ( for some c 5 b, (a, c) E R). 
PROOF. We have from catalog item 0 that if 
Q = {(a, b) ( for some c < b, (a, c) E R ) ,  
then Q is representable. And 
(a,b) E P * (a,S(b)) E Q 
* (I?(a, b), s(I:(~, b))) E Q. 
Hence by catalog item 2, P is representable. 
More generally, if R is a representable (m + 1)-ary relation, then 
{(al, . . . ,am, b) ( for some c 5 b, (al,. . . ,am, c) E R )  
is also representable. In vector notation this relation becomes 
((2, b) ( for some c 5 b, (2, c) E R). 
Similarly 
((2, b) ( for all c _< b, (2, C) E R )  
is representable. 
4. The divisibility relation 
{(a, b) ( a divides b in N) 
is representable. 
PROOF. We have a divides b iff for some q ( b, a .q = b. We know 
that {(a, b, q) ( a-q = b) is representable, as it has a quantifier-free 
definition. Upon applying the above items, we get the divisibility 
relation. (In yet further detail, from catalog item 3 we get the 
representability of 
R = {(a, b, c) ( for some q ( c, a q = b) 
and a divides b iff (a, b, b) E R .) 
5. The set of primes is representable. 
6. The set of pairs of adjacent primes is representable. 
PROOF. (a, b) is a pair of adjacent primes iff a is prime and b is 
prime and a < b and there does not exist any c < b such that 

Chapter 3: 
Undecidability 
21 9 
a < c and c is prime. The right side of this equivalence is easily 
formalized by a numeralwise determined formula. 
-1 
Note (for future use in Section 3.8) that we have not yet used the fact 
that exponentiation is representable. 
Observe that as this catalog progresses, we are in effect building up 
a "language" C such that anything (any relation, any function) that is 
C-definable (in Tt) will be certain to be representable in our theory. 
Thus, Theorem 331 tells us that (a) atomic formulas are allowed in C, 
(b) all sentential connectives are permitted, and (c) bounded quantifiers 
can be used. (Unbounded quantifiers are not in general allowed.) Then 
our catalog gradually adds particular predicate symbols and function 
symbols; catalog item 6 adds a two-place predicate symbol for "adja- 
cent primality"; and catalog item 7 will add a function symbol for the 
prime-listing function. Theorem 33L justifies using these function sym- 
bols inside expressions of C. 
7. The function whose value at a is pa, the (a + 1)st prime, is 
representable. (Thus po = 2, pl = 3, p2 = 5, p3 = 7 , p4 = 11,andso 
forth.) 
PROOF. pa = b iff b is prime and there exists some c 5 ba2, such 
that (i)-(iii) hold: 
(i) 2 does not divide c. 
(ii) For any q < b and any r 5 b, if (q, r) is a pair of adjacent 
primes, then for all j < c, 
q divides c 
ri+' divides c. 
(iii) ba divides c and ba+' does not. 
This equivalence is not obvious, but at least the relation defined 
by the right-hand side is representable. To verify the equivalence, 
first note that if pa = b, then we can take 
It is easy to check that this value of c meets all the conditions. 
Conversely, suppose c is a number meeting conditions (i)-(iii). 
We claim that c must be 
2' 
3l . . . . ba powers of larger primes. 
Certainly the exponent of 2 in c is 0, by (i). We can use (ii) to 
work our way across to the prime b. But by (iii) the exponent of 
bis a, so bmust bethe(a + l)stprime, pa. 
-1 

220 
A Mathematical Introduction to Logic 
This function will be very useful in encoding finite sequences of 
numbers into single numbers. Let 
. . . . . pz+l 
(ao, 
7 am) = Po 
= n 
pp'+l. 
i l m  
This holds also for m = - 1 ; we define ( ) = 1. For example, 
The idea is that 72 safely encodes the pair (2, 1). 
There are other ways to encode pairs of numbers and finite sequences 
of numbers. In Section 3.8, we will make use of a pairing function 
that has the advantage of growing at a polynomial rate, unlike the growth 
rate of 2'+l 3b+1. Here is a very different way to encode, for example, the 
numbers 24,117,ll (in that order). First we convert to numerals in base 
9: 26, 140, 12. Secondly, we concatenate these numerals, separated by 
9's: 269 1409 12. The triple is encoded by the number thereby designated 
(in base lo), that is, 269,140,912. This method may seem tricky, but it 
produces a result that is much smaller than 22531 5 12, which requires 
73 digits in base 10. 
8. For each m, the function whose value at ao, . . . , am is (ao, . . . , am) 
is representable. 
9. There is a representable function (whose value at (a, b) is written 
(a)&) such that for b < m, 
(This is our "decoding" function. For example, (72)o = 2 and (72)1 = 1 .) 
PROOF. We define (a)b to be the least n such that either a = 0 or 
pg+2 does not divide a. (There always is such an n.) Observe that 
(O)b = 0, and for a # 0, (a)b is one less than the exponent of 
p b  in the prime factorization of a (but not less than 0). Hence for 
b L m ,  
To prove representability we use the least-zero operator. Let 
R = {(a, b, n) I a = 0 or pgf2 does not divide a]. 
Then (a)b = pn[KF(a, b, n) = 01, where R is the complement 
of R. 
-I 
Since the method used in the above proof will be useful elsewhere 
as well, we here state it separately: 

Chapter 3: 
Undecidabi l itv 
THEOREM 
33N Assume that R is a representable relation such that 
for every 2 there is some n such that (2 , n ) E R. Then the function 
f defined by 
f (2) = the least n such that (2, n) E R 
is representable. 
PROOF. f (2) = pn [Kx(2, n) = 01. 
We will later use the notation 
f (2) = pn[(;, n) E R]. 
10. Say that b is a sequence number iff for some m _> - 1 and some 
ao, . . . , a,, 
b = (ao, . . . , a,). 
(When rn = - 1 we get ( ) = 1 .) Then the set of sequence numbers is 
representable. 
PROOF. Exercise 5. 
1 1. There is a representable function lh such that 
lh(ao, ..., a,) = m + 1. 
(Here "h" 
stands for "length." For example, lh72 = 2.) 
PROOF. We define lh a to be the least n such that either a = 0 or 
p,, does not divide a. This works. 
-I 
12. There is a representable function (whose value at (a, b) is called 
the restriction of a to b, written a 1 b) such that for any b _( m + 1, 
PROOF. Let a 1 b be the least n such that either a = 0 or both n # 0 
and for any j < b, any k < a 
pj divides a =+ p: divides n . 
This works. 
13. (Primitive recursion) With a (k + 1)-place function f we asso- 
ciate another function 7 
such that y(a, bl , . . . , bk) encodes the values 
of f (j, bl, . . . , bk) for all j < a. Specifically, let 
For example, F(0, a) = ( ) = 1, encoding the first zero values of 
f .  fll, g) = (f (0,6)). In any case, J(a, $) is a sequence number of 
length a, encoding the first a values of f . 

222 
A Mathematical Introduction to Logic 
Now suppose we are given a (k + 2)-place function g. There exists 
a unique function f satisfying 
f (a, a) = g(T(a? 6 ,  a ?  a). 
For example, 
f ( 0 , 6  = g(( ), 0, 6, 
f (1,;) = g((f (0, B))? 1,;). 
(The existence and uniqueness of this f should be intuitively clear. For 
a proof, we can apply the recursion theorem of Section 1.4, obtaining 
first 7 and then extracting f .) 
THEOREM 
33P Let g be a (k + 2)-place function and let f be the 
unique (k + 1)-place function such that for all a and (k-tuples) 6, 
f(a, 6 = g(T(a, 5), a, 5). 
If g is representable, then so is f .  
PROOF. First we claim that 7 is representable. 
This follows from the fact that 
F(a, 6) = the least s such that s is a sequence number of 
length a and for i less than a, (s)~ = g(s I i, i, 6). 
It then follows that f is representable, since 
f (a, 6 = g t n a ,  a), a, a) 
and the functions on the right are representable. 
Actually the phrase "primitive recursion" is more commonly applied 
to a simpler version of this, given in Exercise 8. 
14. For a representable function F, the function whose value at 
a , 6  is 
i <a 
is also representable. Similarly with C in place of n. (For a = 0, we 
use the standard conventions: The empty product - 
the product of no 
numbers - 
is 1, and the empty sum is 0.) 
PROOF. Call this function G; then 
G(O,6) = 1, 
G(a + 1, a) = F(a, 5) . ~ ( a ,  
a). 
Apply Exercise 8. 
15. Define the concatenation of a and b, a * b, by 

Chapter 3: 
Undecidability 
223 
This is a representable function of a and b, and 
The concatenation operation has the further property of being associa- 
tive on sequence numbers. 
16. We will also want a "capital asterisk operation. Let 
*its f (i) = f (0) * f (1) * - * f (a - 1). 
For a representable function F, the function whose value at a, 6 is 
*ia 
F (i, 6) is representable. 
-L 
-L 
-L 
*ica+l F(i, b) = *i,aF(i, b) * F(a, b). 
So this is just like catalog item 14. 
Exercises 
1. Show that in the structure (N; ., E) we can define the addition re- 
lation { (m, n , m + n) ( m, n in N). Conclude that in this structure 
{O), the ordering relation <, and the successor relation {(n, S(n)) ( 
n E N) are definable. (Remark: This result can be strengthened by 
replacing the structure (N; a ,  E) by simply (N; E). The multipli- 
cation relation is definable here, by exploiting one of the laws of 
exponents: (da)b = dab.) 
2. Prove Theorem 33C, stating that true (in 32) quantifier-free sen- 
tences are theorems of AE. (See the outline given there.) 
3. A theory T (in a language with 0 and S) is called w-complete iff 
for any formula (o and variable x, if pi,,,, belongs to T for every 
natural number n, then Vx(o belongs to T. Show that if T is a 
consistent w-complete theory in the language of 32 and if A 
T, 
thenT =Th32. 
4. Show that in the proof preceding Theorem 33L, formula (4) is 
logically implied by the set consisting of formulas (I), (2), and (3). 
5. Show that the set of sequence numbers is representable (catalog 
item 10). 
6. Is 3 a sequence number? What is lh 3? Find (1 * 3) * 6 and 1 * (3 * 6). 
7. Establish the following facts: 
(a) a + 1 < pa. 
(b) (b)k 5 b; equality holds iff b = 0. 
(c) lh a _< a; equality holds iff a = 0. 
(d) a r i  5. a. 
(e) lh(a ti) is the smaller of i and Ih a. 

224 
A Mathematical Introduction to Logic 
8. Let g and h be representable functions, and assume that 
Show that f is representable. 
9. Show that there is a representable function f such that for every 
n, a07 .. . , an, 
f ((a07 . -
9
 an)) = an. 
(For example, f (72) = 1 and f (750) = 2.) 
10. Assume that R is a representable relation and that g and h are 
representable functions. Show that f is representable, where 
11. (Monotone recursion) Assume that R is a representable binary re- 
lation on N. Let C be the smallest subset of N (i.e., the intersection 
of all subsets) such that for all n, ao, . . . , an-1, b, 
Further assume that (1) for all n, ao, . . . , an-l, b, 
((ao, . . . , an-l), b) E R =+ ai < b (for all i < n), 
and (2) there is a representable function f such that for all n, 
a09 - .- ,an-l,b, 
((ao,. .-,an-l),b) E R =+ n < f (b) 
Show that C is representable. (C is, in a sense, generated by R. 
C # 0 in general because if (( ), b) E R, then b E C.) 
SECTION 3.4 
Arithmetization of Syntax 
In this section we intend to develop two themes: 
1. Certain assertions about wffs can be converted into assertions 
about natural numbers (by assigning numbers to expressions). 
2. These (English) assertions about natural numbers can in many 
cases be translated into the formal language. And the theory Cn AE is 
strong enough to prove many of the translations so obtained. 
This will give us the ability to construct formulas that, by expressing 
facts about numbers, indirectly express facts about formulas (even about 
themselves!). Such an ability will be exploited in Section 3.5 to obtain 
results of undefinability and undecidability. 

Chapter 3: 
Undecidability 
22 5 
Godel Numbers 
We first want to assign numbers to expressions of the formal language. 
Recall that the symbols of our language are those listed in Table IX. 
TABLE 1X 
Parameters 
Logical symbols 
0. v 
1. ( 
2. 0 
3. 1 
4. S 
5. 1 
6. < 
7. + 
8. + 
9. = 
10. 
11. q 
12. E 
13. w, 
etc. 
There is a function h assigning to each symbol the integer listed to 
its left. Thus h (b') = 0, h (0) = 2, and h (vi) = 9 + 2i. In order to make 
our subsequent work more widely applicable, we will assume only that 
we have some language with 0 and S which is recursively numbered. By 
this we mean that we have a one-to-one function h from the parameters 
of that language into the even numbers such that the two relations 
{(k, m) ( k is the value of h at some m-place predicate parameter) 
and 
{(k, m) ( k is the value of h at some m-place function symbol) 
are both representable in Cn AE. Of course in the case of the lan- . 
guage of % these sets are even finite. The first set is ((6, 2)) and the 
second is 
We define h on the logical symbols as before; thus h (s) is an odd number 
for each logical symbol s. 
For an expression E = SO. . sn of the language we define its Gijdel 
number, fl (E), by 
For example, using our original function h for the language of %, we 
obtain 
fl(3 25 % = 0) 
= ft((+'%( l=250))) 

226 
A Mathematical Introduction to Lonic 
This is a large number, being of the order of 1.3 x 10'~. TO a set @ 
of expressions we assign the set 
of Godel numbers. 
To a sequence (ao, . . . , an) of expressions (such as a deduction), we 
assign the number 
We now proceed to show that various relations and functions having 
to do with Godel numbers are representable in Cn AE (and hence are 
recursive). As in the preceding section, whenever we say that a relation 
or function is representable (without specifying a theory) we mean that 
it is representable in the theory Cn AE. 
We will make use of certain abbreviations in the language we use (i.e., 
English, although it is coming to differ more and more from what one 
ordinarily thinks of as English). For "there is a number a such that" we 
write "3a." In the same spirit, "3a, b < c" means "there are numbers 
a and b both of which are less than c such that." Similarly, we may 
employ "V." We would not have dared to employ such abbreviations in 
Chapter 2, for fear of creating confusion between the formal language 
and the meta-language (English). But by now we trust the reader to 
avoid such erroneous ways, 
1. The set of Godel numbers of variables is representable. 
PROOF. Itis {a ( (3b < a)a = (11 +2b)).Itfollowsfromresults 
of the preceding section that this is a representable set. 
-I 
2. The set of Godel numbers of terms is representable. 
PROOF. The set of terms was defined inductively. And terms were 
built up from constituents with smaller Godel numbers. We will 
treat this case in some detail, since it is typical of the argument 
used for inductively defined relations. 
Let f be the characteristic function of the set of Godel numbers 
of terms. From the definition of "term" we obtain 
' 1 
if a is the Giidel number of a variable, 
1 
if (3i < El, 3k < a) [i is a sequence number 
& (V j < lh i) f ((i) j )  = 1 & k is the value of 
h at some (lh i)-place function symbol & 
a = (k) * * j ~ l h i ( i ) ~ I ,  
0 
otherwise. 
But what upper bound for i can we use in place of that "0" 
symbol? Before we can argue that f is representable, we will 

Chapter 3: Undecidability 
227 
need an upper bound on i that depends in some representable 
way on a. 
The claim is that we can take i < aa lha. To see this, suppose 
that a = #stl , - tn (where s is an n-place function symbol and 
tl, . . . , tn are terms). Then we want to take i = (#tl, . . . , #tn). 
How big could this be, in terms of a ?  We have the bounds: 
i = 2"1+1 
iitn+l 
" ' Pn-1 
a 
< 2" - - .pn-1 
- 
< 20 ... a 
Plha-1 
because n = lh i < lh a 
(a)lh,-l+l 
< aa . an (lha times) because a = 2(")0+' - , - p,,-, 
> plha-l 
- 
- 
- (aa)lha - 
- aalha 
So in the above equation for f ,  we replace 
by aa lha. 
Although the right side of this equation refers to f ,  it refers 
only to f ((i) ,), where (i), < a. This feature permits us to apply 
primitive recursion. f (a) = &=(a), a), where 
1 
if a is the Godel number of a variable, 
1 
if (3i < aa lha, 3k < a )  [i is a sequence number 
& (V j < lh i ) (s)(~), = 1 & k is the value of 
h at some (lh i)-place function symbol & 
a = ( k )  * *,<lhi(i)jl, 
0 otherwise. 
For if in this equation we set s equal to T(a), then ( s ) ( ~ ) ,  = f ((i) j )  
for (i) j < a. Hence by Theorem 33P, f is representable provided 
that g is. 
It remains to show that g is representable. But this is straight- 
forward, by using results of the preceding section. Briefly, the 
graph of g is the union of three relations, corresponding to the 
three clauses in the above equation. Each of the three is obtained 
from equality and other representable relations by bounded quan- 
tification and the substitution of representable functions. 
-I 
3. The set of Godel numbers of atomic formulas is representable. 
PROOF. a is the Godel number of an atomic formula iff (3i < 
aa lh a, 3k < a )  [i is a sequence number & (V j < lh i )  (i) j is the 
Godel number of a term & k  is the value of h at some (lh i)-place 
predicate symbol & a = ( k )  * * j<lh (i) 
-I 
4. The set of Godel numbers of wffs is representable. 

228 
A Mathematical Introduction to Logic 
PROOF. The wffs were inductively defined. Let f be the character- 
istic function of the set, then 
1 
if a is the Godel number of an atomic formula, 
1 
if(3i < a ) [ a = ( h ( ( ) , h ( - ) ) * i * ( h ( ) ) )  
& f (i) = 11, 
1 
if ( 3 ,  j < a)[a = (h(()) * i * (h(+)) * j * (h 0)) 
& f ( 0  = f ( j )  = 11, 
1 
if ( 3 ,  j < a)[a = (h(V)) * i * j & i is the Godel 
number of a variable and f (j) = 11, 
0 otherwise. 
By the same argument used for the set of Godel numbers of terms, 
we have the representability of f .  
i 
5. There is arepresentable function Sb such that for a term or formula 
a, variable x , and term t , 
PROOF. We will need to define Sb(a, b, c) making use of values 
Sb(i, b, c) where i < a. As in the case of catalog item 2 (the char- 
acteristic function of the set of terms), it will then be possible to 
show that both % and Sb are representable. 
The function Sb is described by the following six clauses 
(i)-(vi): 
(i) If a is the G6del number of a variable and a = b then 
(ii) If (3i < a'"', 
3k < a)[i is a sequence number & (V j < 
lh i ) (i) is the Godel number of a term & k is the value of h at some 
(lh i )-place function or predicate symbol & a = (k) * *, <lh i (i ) j] 
then 
for that i and k. 
(iii) If (3i t a)[i is the Godel number of a wff & a = 
(h(0, h(-)) * i * (h0))I then 
for that i. 
(iv) If ( 3 ,  j < a)[i and j are Godel numbers of wffs & a = 
(h(0) * i * (h(+)) * j * (h ()))I then 
for that i and j. 

Chapter 3: 
Undecidability 
229 
(v) If (3i, j < a)[i is the Godel number of a variable & i # b 
& j is the Godel number of a wff & a = (h(V)) * i * j] then 
Sb(a, b, c) = (h(V)) * i * Sb(j, b, c) 
for that i and j. 
(vi) If none of the above conditions on a and b are met (where 
we ignore the displayed equation for Sb(a, b, c)) then 
Sb(a, b, c) = a. 
Then the function Sb is obtained by primitive recursion 
Sb(a, b, c) = ~(?%(a, b,c),a, b,c) 
where G is a 4-place function. The graph of G is the union of six 
5 -ary relations 
corresponding to the six clauses above. 
The first of the six is 
R1 = { (s, a, b, c, d) ( a is the Godel number of a variable & 
a = b & d = c } .  
The second one is 
R2 = {(s, a ,  b, c, d) ( (3i < aalha, 3k < a)[i is a sequence number 
& (V j < lh i)(i), is the Godel number of a term & k is the 
value of h at some (lh i)-place function or predicate symbol & 
a = (k) * *j<lhi(i)j & d = (k) * *j<lhi (~)(i)~l} 
and the others are similar translations of the corresponding clauses 
in the description of Sb. 
It is necessary to note that G is indeed a function; it is single- 
valued. This is because no two clauses could apply to one number 
a. And if, for example, clause (ii) applies to a, then we know from 
Section 2.3 that the numbers i and k are uniquely determined. 
Finally, we apply the usual methods to verify that R1-R6 are 
representable, so G is representable, so 5 is representable, so Sb 
is representable. (Substitution is a complicated operation!) 
-I 
6. The function whose value at n is B(SnO) is representable. 
PROOF. Call this function f ;  then 
f (0) = (h (O)), 
f (n + 1) = (h(S)) * f (n). 
Apply Exercise 8 of the preceding section. 
7. There is a representable relation Fr such that for a term or formula 
a and a variable x, 
(Ba, Bx) E Fr + x occurs free in a. 

230 
A Mathematical Introduction to Logic 
8. The set of Godel numbers of sentences is representable. 
PROOF. a is the Godel number of a sentence iff a is the Godel 
number of a formula and for any b < a, if b is the Godel number 
of a variable then (a, b) # Fr. 
i 
9. There is a representable relation Sbl such that for a formula a ,  
variable x, and term t, (#a, fix, #t ) E Sbl iff t is substitutable for x in a .  
PROOF. Exercise 1. 
10. The relation Gen, where (a, b) E Gen iff a is the Giidel number of 
a formula and b is the Godel number of a generalization of that formula, 
is representable. 
PROOF. (a, b) E Gen iff a = b or ( 3 ,  j < b) [i is the Godel number 
of a variable and (a, j) E Gen and b = ((h 0) 
* i * j]. Apply 
the usual argument to the characteristic function of Gen. 
i 
11. The set of Godel numbers of tautologies is representable. 
The set of tautologies is informally decidable since we can use the 
method of truth tables. To obtain representability, we recast truth tables 
in terms of Godel numbers. There are several preliminary steps: 
11.1 The relation R, such that (a, b) E R iff a is the Godel number 
of a formula a and b is the Godel number of a prime constituent of a ,  
is representable. 
PROOF. (a, b) E R e 
a is the Giidel number of a formula and one 
of the following: 
(i) a = b & ( 4 0  # h(0. 
(ii) (3i < a)[a = (h (0, h (I)) * i * ((h())) and (i, b) E R]. 
(iii) The analogue to (ii) but with +. 
Apply the usual argument to the characteristic function of R. i 
11.2 There is a representable function P such that for a formula 
a ,  P(#a) = (#PI, . . . , #Pn), the list of Godel numbers of prime con- 
stituents of a. in numerical order. 
PROOF. First define a function g for locating the next prime con- 
stituent in ha after by (where ha is the formula a for which 
a = #a). 
g(a, y) = the least n such that either n = a + 1 or both 
y < nand (a,n) E R. 
Next define a function h such that h (a, n) gives the (n + 1)st prime 
constituent of ha (if there are that many): 
h(a, 0) = g(a, 0) 
h(a, n + 1) = g(a, h(a, n)). 

Chapter 3: 
Undecidability 
231 
Finally, let P (a) = *i 
,k (h (a, i)) where k is the least number for 
which h(a, k) > a. 
-I 
1 1.3 Say that the integer v encodes a truth assignment for a iff v is 
a sequence number and lh v = lh P(#a) and (Vi < lh v)(3e < 2 ) ( ~ ) ~  
= 
((P(#a))i, e). This is a representable condition on v and #a. 
For example, if P(#a) = (#Po, . . . , ##?n), then 
v = ((#PO, eo), . , (##?n7 en)), 
where each ei is 0 or 1. We will later need an upper bound for v in terms 
of #a. The largest v is obtained when each ei is 1. Also #Pi ( #a, so 
that 
v 5 ((#a7 I), -
*
-
7
 (#a, 1)) 
= * i t l h ~ ( g c r )  ((#a7 1))- 
11.4 There is a representable relation Tr such that for a formula a 
and a v which encodes a truth assignment for a (or more), (#a, v) E Tr 
iff that truth assignment satisfies a. 
PROOF. Exercise 2. 
Finally, a is a tautology iff a is a formula and for every v encoding a 
truth assignment for a, (#a, v) E Tr. The (English) quantifier on v can 
be bounded by a representable function of #a, as explained in 11 -3. 
12. The set of Godel numbers of formulas of the form Vx (p + 
(of, 
where t is a term substitutable for the variable x in (p, is representable. 
PROOF. aisofthisformiff(3wff(o <a)(3variablex <a)(3term 
t < a)[t is substitutable for x in (p and a = Vx (o + (p:]. Here 
"(p < a7' means that #(p < #a. This is easily rewritten in terms of 
Godel numbers: a belongs to the set iff (3 f < a)(3x < a)(3t < a) 
[ f is the Godel number of a formula & x is the Godel number of 
a variable & t is the Godel number of term and ( f, x, t) E Sbl & 
a = ( 4  ( 1 7  h(W) * X * f * (h(+)) * Sb(f7 X, t) * (h0))l. 
13. The set of Godel numbers of formulas of the form V x(a + #?) + 
V x a -+ V x #? is representable. 
PROOF. y is of this form iff (3 variable x < y)(3 formulas 
a ,  #? < y) [ y  = Vx(a + #?) + V x a  + Vx#?]. This is eas- 
ily rewritten in terms of Godel numbers, as in 12. 
i 
14. The set of G6del numbers of formulas of the form a + Vx a ,  
where x does not occur free in a, is representable. 
PROOF. Similar to 13. 
15. The set of Godel numbers of formulas of the form x = x is 
representable. 

23 2 
A Mathematical Introduction to Logic 
PROOF. Similar to 13. 
16. The set of Godel numbers of formulas of the form x = y +a +a', 
where a is atomic and a' is obtained from a by replacing x at zero or 
more places by y, is representable. 
PROOF. This is similar to 13, except for the relation of "partial 
substitution." Let (a, b, x , y ) E Psb iff x and y are Godel numbers 
of variables, a is the Godel number of an atomic formula, b is a 
sequence number of length lh a, and for all j c lh a, either (a) = 
(b) or (a) = x and (b) = y. This relation is representable. -I 
17. The set of Godel numbers of logical axioms is representable. 
PROOF. a is a logical axiom iff 38 _( a such that a is a generaliza- 
tion of #l and #l is in one of the sets in items 1 1-16. 
-I 
18. For a finite set A of formulas, 
{G(D) ( D is a deduction from A) 
is representable. In fact it is enough here for #A to be representable. 
PROOF. A number d belongs to this set iff d is a sequence number 
of positive length and for every i less than lh d, either 
1- (d)i E #A, 
2. (d)i is the Godel number of a logical axiom, or 
3- (3j, k 
i)[(d) j = (h(0) * (d)k * (h(+)) * (d)i * (h0))I. 
This is representable whenever #A is, as is certainly the case 
for finite A. 
-I 
19. Any recursive relation is representable in Cn AE. 
PROOF. Recall that the relation R is recursive iff there is some finite 
consistent set A of sentences such that some formula p represents 
R in Cn A. (There is no loss of generality in assuming that the 
language has only finitely many parameters: those in the finite set 
A, those in p, and 0, S, and V.) In the case of a unary relation R, 
we have that a E R iff the least D which is a deduction from A of 
either p(SaO) or 1 
p(SaO) is, in fact, a deduction of the former. 
More formally, a E R iff the last component off (a) is #p(SaO), 
where 
f (a) = the least d such that d is in the set of item 18 and the 
last component of d is either #p (Sa 0) or # 1 
p (Sa 0). 
For this (fixed) p, there always is such a d. 
-I 
Since the converse to item 19 is immediate, we have 
THEOREM 
34A A relation is recursive iff it is representable in the 
theory Cn AE . 

Chapter3: 
Undecidability 
233 
Henceforth we will usually use the word "recursive" in preference 
to "representable." 
COROLLARY 
34B Any recursive relation is definable in Tt. 
20. Now suppose we have a set A of sentences such that #A is re- 
cursive. Then # Cn A need not be recursive (as we will show in the next 
section). But we do have a way of defining Cn A from A: 
a E Cn A iff 
3d[d is the number of a deduction from A 
and the last component of d is a and a is the 
Godel number of a sentence] 
The part in square brackets is recursive, by the proof to item 18. But we 
cannot in general put any bound on the number d. The best we can say 
is that # Cn A is the domain of a recursive relation (or, as we will say 
later, is recursively enumerable). 
Item 20 will play a key role our subsequent work. In particular, it 
will later be restated as Theorem 351. 
21. If #A is recursive and Cn A is a complete theory, then # Cn A is 
recursive. 
In other words, a complete recursively axiomatizable theory is re- 
cursive. This is the analogue to Corollary 25G, which asserts that a 
complete axiomatizable theory is decidable. 
The proof is essentially unchanged. Let (in the consistent case) 
g(s) = the least d such that s is not the Godel number of a sentence, 
or d is in the set of item 18 and the last component of d is 
either s or is (h (0, h (1)) * s * (h 0)). 
Thus g(#a) is 6 of the least deduction of a or ( 1 
a) from A. And 
s E #CnA iff s > 0 and the last component of g(s) is s. 
-I ; 
At this point we might reconsider the plausibility of Church's thesis. 
Suppose that the relation R is decidable. Then there is a finite list of 
explicit instructions (a program) for the decision procedure. The pro- 
cedure itself will presumably consist of certain atomic steps, which 
are then performed repeatedly. (The reader familiar with computer pro- 
gramming will know that a short program can still require much time 
for its execution, but some commands will be utilized over and over.) 
Any one atomic step is presumably very simple. 
By devices akin to Godel numbering, we can mirror the decision 
procedure in the integers. The characteristic function of R can then be 
put in the form 

234 
A Mathematical Introduction to Lonic 
K R  
(2) = U [the least s such that 
(i) ( s ) ~  
encodes the input 2; 
(ii) for all positive i < lh s, (s)~ is obtained from (s)~- by perfor- 
mance of the applicable atomic step; 
(iii) the last component of s describes a terminal situation, at which 
the computation is completed], 
where U (the upshot function) is some simple function that extracts 
from the last component of s the answer (affirmative or negative). The 
recursiveness of R is now reduced to the recursiveness of U and of 
the relations indicated in (i), (ii), and (iii). In special cases, such as 
decision procedures provided by the register machines of Section 3.6, 
the recursiveness of these components is easily verified. It seems most 
improbable that any decision procedure will ever be regarded as effective 
and yet will have components that are nonrecursive. For example, in (ii), 
it seems that it ought to be possible to make each atomic step extremely 
simple, and in particular to make each one recursive. 
Exercises 
1. Supply a proof for item 9 of this section. 
2. Supply a proof for item 11.4 of this section. 
3. Use Exercise 11 of Section 3.3 to give a new proof that the set of 
Godel numbers of terms is representable (item 2). 
4. Let T be a consistent recursively axiomatizable theory (in a recur- 
sively numbered language with 0 and s). Show that any relation 
representable in T must be recursive. 
SECTION 3.5 
Incompleteness and Undecidability 
In this section we reap the rewards of our work in Sections 3.3 and 3.4. 
We have assigned Godel numbers to expressions, and we have shown 
that certain intuitively decidable relations on N (related to syntactical 
notions about expressions) are representable in Cn A E .  
Throughout this section we assume that the language in question is 
the language of %. (This affects the meaning of "Cn" and "theory.") 
FIXED-POINT LEMMA Given any formula B in which only vl occurs 
free, we can find a sentence a such that 
AE k [a t, / ~ ( s ~ ~ o ) ] .  
We can think of a as indirectly saying, "B is true of me." Ac- 
tually, of course, a doesn't say anything; it's just a string of sym- 
bols. And even when translated into English according to the intended 

Chapter 3: Undecidability 
235 
structure 'Jl, it then talks of numbers and their successors and products 
and so forth. It is only by virtue of our having associated numbers with 
expressions that we can think of a as referring to a formula, in this case 
to a itself. 
PROOF. Let 8(vl, %, v3) functionally represent in Cn AE a func- 
tion whose value at (#a, n) is #(a(SnO)). (See items 5 and 6 in 
Section 3.4.) First consider the formula 
(We may suppose v3 is substitutable for vl in B. The above formula 
has only vl free. It defines in 'Jl a set to which #a belongs iff 
#(a (SflaO)) is in the set defined by B.) Let q be the Godel number 
of (1). Let a be 
Thus a is obtained from (1) by replacing vl, by SqO. Notice that 
a does assert (under 'Jl) that #a is in the set defined by B. But we 
must check that 
is a consequence of A E .  Because 8 functionally represents a func- 
tion whose value at (q, q) is #a, we have 
We can obtain (2) as follows: 
(-+) It is clear (by looking at a )  that 
Hence 
which gives half of (2). 
(t) 
The sentence in (3) implies 
But the part in square brackets is just a .  
(Sometimes the notation la1 is used for SflaO. In this notation, the 
fixed-point lemma states that A I- (a o 
B ([a1 )).) 
Our first application of this lemma does not concern the subthwry 
Cn AE, and requires only the weaker fact that 

236 
A Mathematical Introduction to Logic 
TARSKI UNDEFINABILITY 
THEOREM 
(1 933) The set # Th % is not defin- 
able in %. 
PROOF. Consider any formula B (which you suspect might define 
# Th %). By the fixed-point lemma (applied to 1 
B) we have a 
sentence a such that 
(If B did define Th %, then a would indirectly say "I am false.") 
Then 
so either a is true but (its Godel number is) not in the set B defines, 
or it is false and in that set. Either way a shows that B cannot define 
# Th %. 
-I 
The above theorem gives at once the undecidability of the theory 
of %: 
COROLLARY 
35A 
# Th % is not recursive. 
PROOF. Any recursive set is (by Corollary 34B) definable in %. 
-I 
GODEL INCOMPLETENESS 
THEOREM 
(1931) If A G Th % and #A is re- 
cursive, then Cn A is not a complete theory. 
Thus there is no complete recursive axiomatization of Th %. 
PROOF. Since A s Th %, we have Cn A s Th %. If Cn A is a com- 
plete theory, then equality holds. But if Cn A is a complete theory, 
then # Cn A is recursive (item 21 of the preceding section). And 
by the above corollary, # Th % is not recursive. 
-I 
In particular, Cn AE is not a complete theory and so is not equal to 
Th %. And the incompleteness would not be eliminated by the addition 
of any recursive set of true axioms. (By a recursive set of sentences we 
mean of course a set E for which # E  is recursive.) 
We can extract more information from the proof of Godel's theorem. 
Suppose we have a particular recursive A s Th% in mind. Then by 
item 20 in Section 3.4 we can find a formula B that defines # Cn A in 
3. 
The sentence a produced by the proof of Tarski's theorem is (as we 
noted there) a true sentence not in Cn A. This sentence asserts that #a 
does not belong to the set defined by B, i.e., it indirectly says, "I am 
not a theorem of A." Thus A F  a, and of course A F  1 a as well. This 
way of viewing the proof is closer to Godel's original proof, which did 
not involve a detour through Tarski's theorem. For that matter, Godel's 
statement of the theorem did not involve Th%; we have taken some 
liberties in the labeling of theorems. 

Chapter3: Undecidability 
237 
Next we need a lemma which says (roughly) that one can add one 
new axiom (and hence finitely many new axioms) to a recursive theory 
without losing the property of recursiveness. 
LEMMA 35 B If # Cn E is recursive, then # Cn(E ; t ) is recursive. 
PROOF. a! E Cn(X; t )  # ( t  -+ a) E Cn E. Thus 
a E # Cn(E; t )  (=$ a is the Godel number of a sentence 
and (h(0) * #t * (h(+)) * a * (h 0)) 
is in #CnX. 
This is recursive by the results of the preceding sections. 
THEOREM 
35C (STRONG 
UNDECIDABILITY 
OF CN AE) Let T be a the- 
ory such that T U AE is consistent. Then #T is not recursive. 
(Notice that because throughout this section the language in question 
is the language of %, the word "theory" here means "theory in the 
language of %.") 
PROOF. Let T' be the theory Cn(T U AE). If #T is recursive, then 
since AE is finite we can conclude by the above lemma that #T' 
is also recursive. 
Suppose, then, that #T' is recursive and so is represented in 
Cn AE by some formula p. From the fixed-point lemma we get a 
sentence a such that 
(Indirectly a asserts, "I am not in T'.") 
a 4 T' =+ #a $#T' 
=+ AE I- lp(SfluO) 
=+ A E I - 0  
by (*I 
=+ a E T'. 
So we get a E T'. But this, too, is untenable: 
a E T' =+ #a E#T' 
=+ AE I- p(S'"0) 
=+ A E I - 1 a  
by (*I 
=+ ( 1 0 )  E T', 
which contradicts the consistency of T'. 
COROLLARY 
35 D Assume that # X is recursive and X U A is con- 
sistent. Then Cn E is not a complete theory. 
PROOF. A complete recursively axiomatizable theory is recursive 
(item 2 1 of Section 3.4). But # Cn X is not recursive, by the above 
theorem. 
-I 
This corollary is Godel's incompleteness theorem again, but with 
truth in % replaced by consistency with AE . 

238 
A Mathematical Introduction to Logic 
CHURCH'S 
THEOREM 
(1 936) The set of Godel numbers of valid sen- 
tences (in the language of %) is not recursive. 
PROOF. In the strong undecidability of CnAE, take T to be the 
smallest theory in the language, the set of valid sentences. 
-1 
The set of Godel numbers of valid wffs is not recursive either, lest 
the set of valid sentences be recursive. 
This proof applies to the language of fl. For a language with more 
parameters, the set of valid sentences is still nonrecursive (lest its inter- 
section with the language of % be recursive). Actually it is enough for 
the language to contain at least one two-place predicate symbol. (See 
Corollary 37G.) On the other hand, some lower bound on the language 
is needed. If the language has V as its only parameter (the language of 
equality), then the set of valid formulas is decidable. (See Exercise 6.) 
More generally, it is known that if the only parameters are V and one- 
place predicate symbols, then the set of valid formulas is decidable. 
Recursive Enumerability 
A relation on the natural numbers is said to be recursively enumerable 
iff it is of the form 
with Q recursive. Recursively enumerable relations play an important 
role in logic. They constitute the formal counterpart to the effectively 
enumerable relations (as will be explained presently). 
(The standard abbreviation for "recursively enumerable" is "r.e." 
When the term "computable" is used instead of "recursive," then one 
speaks of computably enumerable - 
abbreviated c.e. -relations.) 
Recursively enumerable relations are - 
like the recursive relations 
- 
definable in %. If (o (vl , Q) defines in % a binary relation Q, then 
3 ~ ( o ( v 1 , ~ )  
defines {a I 3b (a, b) E Q). 
THEOREM 
35E 
The following conditions on an rn-ary relation R are 
equivalent: 
1. R is recursively enumerable. 
2. R is the domain of some recursive relation Q. 
3. For some recursive (m + 1)-ary relation Q, 
4. For some recursive (m + n)-ary relation Q, 
R = {(ai,. ,am) I gbi, . , bn ( ~ 1 , .  . . ,am, b ~ ,  
. . . , bn) E Q}. 
PROOF. By definition 1 and 3 are equivalent. Also 2 and 3 are equiv- 
alent by our definition (in Chapter 0) of domain and (m + 1)-tuple. 

Chapter 3: 
Undecidability 
239 
Clearly 3 implies 4. So we have only to show that 4 implies 3. 
This is because 
gbl,.. ., b, (a1 ,... ,am,bl ,..., b,) E Q 
iff 3c(al, ...,am, (c)o, ..-, (c)n-l) E Q 
and 
is recursive whenever Q is recursive. (Here we have used our 
sequence decoding function to collapse a string of quantifiers into 
a single one.) 
-I 
By part 4 of this theorem, R is recursively enumerable iff it is defin- 
able in !Yl by a formula 3 xl . 
e 3 xnV, where (o is numeralwise deter- 
mined by AE. In fact, we can require here that (o be quantifier-free; this 
result was proved in 1961 (with exponentiation) and in 1970 (without 
exponentiation). The proofs involve some number theory; we will omit 
them here. 
Notice that any recursive relation is also recursively enumerable. For 
if R is recursive, then it is defined in !Yl by a formula 3 x1 
.3 x,p, 
where (o is numeralwise determined by AE and xl, . . . , x, do not occur 
in (o. 
THEOREM 
35F A relation is recursive iff both it and its complement 
are recursively enumerable. 
This is the formal counterpart to the fact (cf. Theorem 17F) that a 
relation is decidable iff both it and its complement can be effectively 
enumerated. 
PROOF. If a relation is recursive, then so is its complement, whence 
both are recursively enumerable. 
Conversely, suppose that both P and its complement are re- 
cursively enumerable; thus for any ;, 
for some recursive Q and R. Let 
f (2) = the least b such that either (2, b) E Q or (2, b) E R. 
Such a number b always exists, and f is recursive. Finally, 
so P is recursive. 
The recursively enumerable relations constitute the formal counter- 
part of the effectively enumerable relations. For we have the following 

240 
A Mathematical Introduction to Logic 
informal result, paralleling a characterization of recursive enumerability 
given by Thwrem 35E. 
"LEMMA 35G A relation is effectively enumerable iff it is the do- 
main of a decidable relation. 
PROOF. Assume that Q is effectively enumerated by some proce- 
dure. Then 2 E Q iff 3n [z appears in the enumeration in n steps]. 
The relation defined in square brackets is decidable and has do- 
main Q. 
Conversely, to enumerate {(a, b) ( 3n (a, b, n) E R) for de- 
cidable R, we check to see if ((rn)o, (m)l, (m)2) E R for m = 
0, 1,2, . . . . Whenever the answer is affirmative, we place ((rn)o, 
( m ) ~ )  
on the output list. 
-I 
*COROLLARY 
35H (CHURCH'S 
THESIS, SECOND FORM) A relation is 
effectively enumerable iff it is recursively enumerable. 
PROOF. By identifying the class of decidable relations with the class 
of recursive relations, we automatically identify the domains of 
decidable relations with domains of recursive relations. 
-I 
The second form of Church's thesis is, in fact, equivalent to the first 
form. To prove the first form from the second, we use Theorems 35F 
and 17F. 
We have already shown that a recursively axiomatizable theory is 
recursively enumerable, but using different words. We restate the result 
here, as it indicates the role recursive enumerability plays in logic. 
THEOREM 
351 If A is a set of sentences such that #A is recursive, 
then # Cn A is recursively enumerable. 
PROOF. Item 20 of Section 3.4. 
In particular, # Cn AE is recursively enumerable, but (by Theorem 
35C) it is not recursive. In the next section, we will see other examples 
of recursively enumerable sets that are not recursive. 
This theorem is the precise counterpart of the informal fact that a 
theory with a decidable set of axioms is effectively enumerable (Corol- 
laries 25F and 261). It indicates the gap between what is provable in 
an axiomatic theory and what is true in the intended structure. With 
a recursive set of axioms, all we can possibly obtain is a recursively 
enumerable set of consequences. But by Tarski's theorem, Th 9l is not 
even definable in 3, 
much less recursively enumerable. 
Even if we expand the language or add new axioms, the same 
phenomenon is present. As long as we can recursively distinguish de- 
ductions from nondeductions, the set of thwrems can be only recur- 
sively enumerable. For example, the set of sentences of number theory 
provable in your favorite system of axiomatic set theory is recursively 

Chapter 3: 
Undecidability 
241 
enumerable. Furthermore, this set includes AE and is consistent (un- 
less you have very strange favorites). It follows that this set theory is 
nomecursive and incomplete. (This topic is discussed more carefully in 
Section 3.7.) 
Weak Representability 
Consider a recursively enumerable set Q, where 
a E Q e 3b (a, b) E R 
for recursive R. We know there is a formula p that represents R in 
Cn A E. Consequently, the formula 3 e p  defines Q in 'SZ. This formula 
cannot represent Q in Cn AE unless Q is recursive. But it can come 
halfway. 
a E Q =+ (a,b) E R 
for some b 
=+ A I- p (SaO, SbO) 
for some b 
* AE I- 3 @p(Sao, W) 
a 4 Q =+ (a,b> 4 R  
for all b 
+ AE F ~ ~ ( s ~ o , s ~ o )  
forallb 
=+ A
E
~
 
3 Wp(SaO, W) 
The last step is justified by the fact that if AE I- 7 rg(SbO) for all 
b, then A bL 3 x rg(x). (The term o-consistency is given to this prop- 
erty.) For it is impossible for 3 x rg(x), 1 
rg(s00), 1 
rg(S lo), . . . all to be 
true in n. 
Thus we have 
It will be convenient to formulate a definition of this half of repre- 
sentability. 
DEFINITION. Let Q be an n-ary relation on N, $ a formula in which 
only vl , . . . , v, occur free. Then $ weakly represents Q in a 
theory T iff for every al, . . . , a, in n ,  
Observe that if Q is representable in a consistent theory T, then Q 
is also weakly representable in T. 
THEOREM 
351 A relation is weakly representable in Cn AE iff it is 
recursively enumerable. 
PROOF. We just showed that a recursively enumerable unary rela- 
tion Q is weakly representable in Cn A E; the same proof applies 
to n-ary Q with only notational changes. Conversely, let Q be 

242 
A Mathematical Introduction to Logic 
weakly represented by $ in Cn A E. Then 
(al,. . . ,a,) E Q e 3 0  [D is adeductionof $(SalO,, , . ,SanO) 
from the axioms A 
* 3d (d, f(a1, ...,a, 1) E P 
for a certain recursive function f and recursive relation P. 
-1 
Arithmetical Hierarchy 
Define a relation on the natural numbers to be arithmetical iff it is 
definable in 9. 
But some arithmetical relations are, in a sense, more 
definable than others. We can organize the arithmetical relations into a 
hierarchy according to how definable the relations are. 
Let El be the class of recursively enumerable relations; these rela- 
tions are "one quantifier away" from recursiveness. Extending this idea, 
we define the class of Ck relations and the class of Ilk relations. For 
example, the first few classes consist of relations of the form shown in 
the second column: 
El : {a' 1 3b (i, 
b) E R), 
R recursive. 
nl : 
(7;: 1 ~b (i, b) E R), 
R recursive. 
C2 : {i 1 3cVb (i, b, c) E R), 
R recursive. 
n2 : {i 1 Vc3b (i, b, c) E R) , 
R recursive. 
In general, a relation Q is in lIk iff it is of the form 
for a recursive relation R. Here "0" 
is to be replaced by "V" if k is odd 
and by "3" if k is even. Similarly, Q is in Ek iff it has the form 
for recursive R, where now "0" 
is replaced by "3" if k is odd and by 
"V" if k is even. 
The classes Ek and Ilk can also be defined by recursion on k. C1 is 
the class of recursively enumerable relations. Next, a relation belongs 
to Ilk iff its complement is in Ek. And a relation is in Ck+1 iff it is the 
domain of a relation in nk. (We can even start from k = 0, by letting 
Co be the class of recursive relations.) 
EXAMPLE, The set of Giidel numbers of formulas numeralwise 
determined by AE is in l12. 
PROOF. a belongs to this set iff [a is the Godel number of a for- 
mula a] and Vb3d[d is G of a deduction from AE either of 
CY(S(~)OO, 
S(b)lO, . . .) or of the negation of this sentence]. By the 
technique of Section 3.4, we can show that the phrases in 
square brackets define recursive relations. By using the English 

Chapter 3: Undecidability 
243 
counterpart to prenex form, we obtain the desired form, 
{a I Vb3d (a, 
b, d) E R), 
with R recursive. 
One more bit of notation: Let A1 be the class of recursive relations. 
Then our earlier result (Theorem 35F) stating that a relation is recursive 
iff both it and its complement are recursively enumerable can now be 
stated by the equation 
Since this equation holds, we proceed to define A, for n > 1 by the 
analogous equation, 
A, = C, n n,. 
The following inclusions hold: 
The case A1 G El was mentioned previously (cf. Theorem 35F); its 
proof hinged on the possibility of "vacuous quantification." The proofs 
of the other cases are conceptually the same. If x  does not occur in 
p, then p, V x  p, and 3 x  p are all equivalent. For example, a rela- 
tion in El is defined by a formula 3 y (p, where p is numeralwise de- 
termined by AE. But the same relation is defined by 3 y V x  (p and 
V x  3 y p (where x  does not occur in p). Hence the relation is also in C2 
and n 2 .  
It is also true that all the inclusions shown are proper inclusions, 
i.e., equality does not hold. But we will not prove this fact here. The 
inclusions are shown pictorially in Fig. 10. 
The class of arithmetical relations equals Uk Ek and also Uk nk. For 
example, any relation in C2 is arithmetical, being defined in 9l by a for- 
mula 3 x  V y (p, where p is numeralwise determined by A 
Conversely, 
any arithmetical relation is defined in 9l by some prenex formula. The 
quantifier-free part of this prenex formula defines a recursive relation 
(since quantifier-free formulas are numeralwise determined by AE). 
Consequently, the defined relation falls somewhere in the hierarchy. 
The technique of "collapsing" 33 
.3 quantifiers used in the proof of 
Theorem 35E (and its dual technique for VV . V) can be used to good 
advantage here. 

A Mathematical Introduction to Loeic 
nonarithmetical sets 
arithmetical sets 
Figure 10. Picture of PN. 
Thus we have the following result, which relates definability in %to 
the hierarchy we have just built up from the recursive relations: 
THEOREM 
35 K A relation on the natural numbers is arithmetical (i.e., 
definable in %) iff it is in Ek for some k, and this property in turn 
is equivalent to being in nl for some 1. 
In particular, any recursively enumerable relation is arithmetical, as 
noted previously. 
There are certain tricks which are useful in locating specific arith- 
metical relations in the hierarchy. For example, let A be the set of Godel 
numbers of formulas a such that for some n, 
AE I-a(SnO) 
and (Vi -en) AE F i a ( s i 0 ) .  
Then a E A iff [a is the Godel of a wff a ]  and 3n3D[D is a deduction 
from A of a (SnO)] and (Vi < n) (3Di) [Di is a deduction from AE of 
-I a(SiO)]. The parts in square brackets are recursive so we count the 
remaining quantifiers. The bounded quantifier "Vi < n" need not be 
counted. For we have 
(Vi < n)(3d)(d, i) E P 
(3d)(Vi < n)((d)i, i) E P. 
Use of this fact lets us push the bounded quantifier inward until it merges 
with the recursive part. Consequently, A E El. 
The following theorem generalizes Theorem 351. 

Chapter 3: 
Undecidability 
245 
THEOREM 
351 Let A be a set of sentences such that #A is in Ck, 
where k > 0. Then # Cn A is also in Ck. 
PROOF. Return to the proofs of items 18 and 20 of Section 3.4. We 
had there: 
a E # Cn A 
a is the Godel number of a sentence and 3d[d is a 
sequence number and the last component of d is a and 
for every i less than lh d, either (1) (d)i E #A, (2) (d)i 
is the Godel number of a logical axiom, or (3) for some 
j and 1 less than i, (d) = (h (0) * (d)! * (h (-+)) 
*(d)i * (h0))I- 
Since #A E Ek in (1) we must replace "(d)i E #A" by something 
of the form 
for recursive Q. It remains to convert the result into an English 
prenex expression in Ek form. We suggest that the reader set k = 2 
and write out this expression; the device used in the preceding 
example will help. 
-1 
Exercises 
1. Show that there is no recursive set R such that # Cn A E 
R and 
#{a I ( 1  a) E Cn AE) 
R, the complement of R. (Ths result can 
be stated: The theorems of AE cannot be recursively separated from 
the refutable sentences.) Suggestion: Make a sentence a saying "My 
Godel number is not in R." Look to see where #a is. 
2. Let A be a recursive set of sentences in a recursively numbered 
language with 0 and S. Assume that every recursive relation is rep- 
resentable in the theory Cn A. Further assume that A is o-consistent; 
i.e., there is no formula rg such that A I- 3 x rg(x) and for all a E N, 
A I- 1 
rg(SaO). Construct a sentence a indirectly asserting that it 
is not a theorem of A, and show that neither A I- a nor A I- 1 
a. 
Suggestion: See Section 3.0. 
Remark: This is a version of the incompleteness theorem that 
is closer to Godel's original 193 1 argument. Note that there is no 
requirement that the axioms A be true in 3. 
Nor is it required that 
A include AE; the fixed-point argument can still be applied. 
3. Let T be a theory in a recursively numbered language (with 0 and S). 
Assume that all recursive subsets of N are weakly representable in 
T. Show that #T is not recursive. Suggestion: Construct a binary 
relation P such that any weakly representable subset of N equals 
{b I (a, b) E P )  for some a ,  and such that P is recursive if gT is. 

246 
A Mathematical Introduction to Logic 
Consider the set H = {b I (b, b) 4 P ) .  See Section 3.0. The argu- 
ment given there for the "diagonal approach" in the special case 
T = Th % can be adapted here. 
Remark: This exercise gives a version of the result, "Any suffi- 
ciently strong theory is undecidable." 
4. Show that there exist 2'0 nonisomorphic countable models of Th 3. 
Suggestion: For each set A of primes, make a model having an 
element divisible by exactly the primes in A. 
5. (Lindenbaum) Let T be a decidable consistent theory (in a rea- 
sonable language). Show that T can be extended to a complete 
decidable consistent theory T'. Suggestion: Examine in turn each 
sentence a; add either a or l a  to T. But take care to maintain 
decidability. 
6. Consider the language of equality, having V as its only parameter. 
Let A, be the translation of "There are at least n things," cf. the 
proof of Theorem 26A. Call a formula simple iff it can be built up 
from atomic formulas and the 1,'s by use of connective symbols 
(but no quantifiers). Show how, given any formula in the language 
of equality, we can find a logically equivalent simple formula. Sug- 
gestion: View this as an elimination-of-quantifiers result (where the 
quantifiers in A, do not count). Use Theorem 31F. 
7. (a) Assume that A and B are subsets of N belonging to Ek (or 
nk). Show that A U B and A n B also belong to Ek (or TIk, 
respectively). 
(b) Assume that A is in Ek (or Ilk) and that the functions fi, . . . , 
fm are recursive. Show that 
is also in Ek (or ilk, respectively). Suggestion: First do this for 
E 1. Then observe that the argument used can be generalized. 
8. Let T be a theory in a recursively numbered language (with 0 and 
S). Let n be fixed, n > 0. Assume that all subsets of N in En are 
weakly representable in T. 
Show that #T is not in n,. (Observe that 
Exercise 3 is a special case of this, wherein n = 0. The suggestions 
given there cany over to the present case.) 
9. Show that 
{#a I AE; a is o-consistent) 
(see Exercise 2) is a n3 set. 
10. The theory Cn AE has many complete extensions, of which Th 9l 
is but one. How many? That is, what is the cardinality of the set of 
complete theories (in the language) that extend A E? 

Chapter 3: 
Undecidability 
247 
SECTION 3.6 
Recursive Functions 
We have used recursive functions (i.e., functions that, when viewed 
as relations, are recursive) to obtain theorems of incompleteness and 
undecidability of theories. But the class of recursive functions is also 
an interesting class in its own right, and in this section we will indicate 
a few of its properties. 
Recall that by Church's thesis, a function is recursive iff it is com- 
putable by an effective procedure (page 210). This fact is responsi- 
ble for much of the interest in recursive functions. At the same time, 
this fact makes possible an intuitive understanding of recursiveness, 
which greatly facilitates the study of the subject. Suppose, for exarn- 
ple, that you are suddenly asked whether or not the inverse of a re- 
cursive permutation of N is recursive. Before trying to prove this, you 
should first ask yourself the intuitive counterpart: Is the inverse of a 
computable permutation f also computable? You then - 
one hopes - 
perceive that the answer is affirmative. To compute f -'(3), you can 
compute f (0), f (1), . . . until for some k it is found that f (k) = 3. 
Then f -'(3) = k. Having done this, you have gained two advan- 
tages. For one, you feel certain that the answer to the question re- 
garding recursive permutations must also be affirmative. And secondly, 
you have a good outline of how to prove this; the proof is found 
by making rigorous the intuitive proof. This strategy for approach- 
ing problems involving recursiveness will be very useful in this 
section. 
Before proceeding, it might be wise to summarize here some of the 
facts about recursive functions we have already established. We know 
that a function f is recursive iff it (as a relation) is representable in 
Cn AE, by Theorem 34A. Consequently, every recursive function is 
weakly representable in this theory. 
In Section 3.3 a repertoire of recursive functions was developed. In 
addition, it was shown that the class of recursive functions is closed 
under certain operations, such as composition (Theorem 33L) and the 
"least-zero" operator (Theorem 33M). 
We also know of a few functions that are not recursive. There are 
uncountably many (to be exact, 2 K ~ )  
functions from Nm into N altogether, 
but only countably many of them can be recursive. So an abundance of 
nonrecursive functions exists, despite the fact that the most commonly 
met functions (such as the polynomials) were shown in Section 3.3 to be 
recursive. By catalog item 1 of Section 3.3, the characteristic function of 
a nonrecursive set is nonrecursive. For example, if f (a) = 1 whenever 
a is the Godel number of a member of Cn AE and f (a) = 0 otherwise, 
then f is not recursive. 

248 
A Mathematical Introduction to Logic 
Normal Form 
For any computable function, such as the polynomial function a2 +3a + 
5, one can in principle design a digital computer into which one feeds 
a and out of which comes a2 + 3a + 5 (Fig. 11). But if you then want 
a different function, you must build a different computer. (Or change 
the wiring in the one you have.) It was recognized long ago that it is 
usually more desirable to build a single general-purpose stored-program 
computer. Into this you feed both a and the program for computing your 
polynomial (Fig. 12). This "universal" computer requires two inputs, 
and it will compute any one-place computable function (if supplied 
with enough memory space), provided that the right program is fed 
into it. Of course, there are some programs that do not produce any 
function on N, as many a programmer has, to his sorrow, discovered. 
(Such programs produce malfunctions instead!) 
program 
Figure 1 1 . Special-purpose 
computer. 
Figure 1 2. General-purpose computer. 
In thls subsection and the next, we will repeat what has just been 
said, but with recursive functions and with proofs. For our universal 
computer we will have a recursive relation TI and a recursive function 
U. Then for any recursive f : N + N there will exist an e (analogous 
to the program) such that 
f (a) = U(the least k such that (e, a, k) E TI) 
= U ( P ~  
(e, a, k) E TI), 
where the second equation is to be understood as being an abbreviation 
for the first. Actually e will here be the Godel number of a formula 

Chapter 3: 
Undecidability 
249 
rp that represents (or at least weakly represents) f in Cn AE. And the 
numbers k for whlch (e, a, k) E Tl will encode both f (a) and G of a 
deduction from AE of rp (SaO, sf (a)O). 
DEFINITION. 
For each positive integer m, let T, be the (m + 2)-ary 
relation to which an (m + 2)-tuple (e, all . . . , a,, k) belongs iff 
(i) e is the Gijdel number of a formula rp in which only vl , . . . , 
v, , v,+ 
occur free; 
(ii) k is a sequence number of length 2, and (k)o is G of a 
deduction from A of rp(SalO, . . . , Sam 0, S(k)l~). 
The idea here is that for any one-place recursive function f we 
can first of all take e to be the Godel number of a formula rp weakly 
representing f (as a relation). Then we know that for any a and b, 
AE I- q(SaO,~bO) iff b = f(a). 
So any number k meeting clause (ii) of the definition must equal 
((k)~, f (a)), where (k)o is G of a deduction of rp(SaO, sfta)O) from 
AE. (We have departed from the usual definition of T, 
here by not 
requiring that k be as small as possible.) 
Take for the "upshot" function U the function 
This U is recursive and in the situation described in the preceding para- 
graph we have U (k) = f (a). 
LEMMA 36A For each m, the relation T, is recursive. 
PROOF, FOR m = 2. (e, a1 , a2, k) E T2 iff e is the Godel number of 
a formula, #(V vl V uz V v3) * e is the Godel number of a sentence, 
k is a sequence number of length 2, and (k)o is G of a deduction 
from AE of 
where g(n) = #SnO. From Section 3.4 we know all this to be 
recursive. 
-1 
THEOREM 
36B (a) For any recursive function f : Nm + N, there is 
an e such that for all al, . . . , a,, 
(In particular, such a number k exists.) 
(b) Conversely, for any e such that Val - - . am3k (e, a1 , . . . , 
a,, k) E T,, the function whose value at a1 , . . . , a, is U (pk(e, 
al, . . . , a,, k) E T,) is recursive. 

250 
A Mathematical Introduction to Logic 
PROOF. Part (b) follows immediately from the fact that U and T, 
are recursive. As for part (a), we take for e the Godel number of 
a formula (p weakly representing f in Cn AE. Given any 2, we 
know that AE I- (p(SalO, . . . , SamO, ~f("0). If we let d be g of a 
deduction from A of this sentence, then (e, 22, (d, f (i)) ) E T, . 
Hence there is some k for which (e, i, k) E T,. And for any such 
k, we know that AE I- (p(SalO, . . . , SamO, 
0), since (k)o is 
of a deduction. Consequently, U (k) = (k) = f (7;) by our choice 
of (p. Thus we have U(pk (e, i, k) E T,) = f (7;). 
-1 
This theorem, due to Kleene in 1936, shows that every recursive 
function is representable in the normal form 
f ( i )  = U(pk(e,i,k) E T,). 
Thus a computing machine able to calculate U and the characteristic 
function of Tl is a "universal" computer for one-place recursive func- 
tions. The input e corresponds to the program, and it must be chosen 
with care if any output is to result (i.e., if there is to be any k such that 
(e, a ,  k )  € Tl). 
Recursive Partial Functions 
The theory of recursive functions becomes more natural if we consider 
the broader context of partial functions. 
DEFINITION. An m-place partial function is a function f with 
dom f G Nm and ran f E N. If 22 4 dom f ,  then f (i) is said to 
be undefined. If dom f = Nm, then f is said to be total. 
The reader is hereby cautioned against reading too much into our 
choice of the words "partial" and "total" (or the word "undefined," for 
that matter). A partial function f may or may not be total; the words 
"partial" and "total" are not antonyms. 
We will begin by looking at those partial functions that are informally 
computable. 
*DEFINITION. An m-place partial function f is computable iff there 
is an effective procedure such that (a) given an m-tuple 7;: in dom f ,  
the procedure produces f (7;); and (b) given an m-tuple 2 not in 
dom f ,  the procedure produces no output at all. 
This definition extends the one previously given for total functions. 
At that time we proved a result (Theorem 33H), part of which generalizes 
to partial functions. 
*THEOREM 
36C An m-place partial function f is computable iff f 
(as an (m + 1)-ary relation) is effectively enumerable. 

Chapter 3: Undecidability 
251 
PROOF. The proof is reminiscent of the proof of another result, 
Theorem 17E. First suppose we have a way of effectively enu- 
merating f .  Given an m-tuple 2, we examine the listing of the 
relation as the procedure chums it out. If and when an (m + 1)- 
tuple beginning with 2 appears, we print out its last component 
as f (2). 
Conversely, assume that f is computable, and first suppose 
that f is a one-place partial function. We can enumerate f as a 
relation by the following procedure: 
1. Spend one minute calculating f (0). 
2. Spend two minutes calculating f (0), then two minutes cal- 
culating f (1). 
3. Spend three minutes calculating f (0), three minutes calcu- 
lating f (1), and three minutes calculating f (2). 
And so forth. Of course, whenever one of these calculations 
produces any output, we place the corresponding pair on the list 
of members of the relation f .  
For a computable m-place partial function, instead of calcu- 
lating the value of f at 0, 1,2, . . . we calculate its value at ((O)O, 
-
1
 
o 
-
1
 
o 
-
1
 
e t  
-1 
In the case of a computable total function f ,  we were also able to 
conclude that f was a decidable relation. But this may fail for a nontotal 
f .  For example, let 
ifa E #CnAE, 
(a) = { :ndefined 
otherwise. 
Then f is computable. (We compute f (a) by enumerating #Cn AE 
and looking for a.) But f is not a decidable relation, lest #Cn AE be 
decidable. On the basis of this example and the foregoing theorem, 
we select our definition for the precise counterpart of the concept of 
computable partial function. 
DEFINITION. 
A recursive partial function is a partial function that, 
as a relation, is recursively enumerable. 
The reader should be warned that "recursive partial function" is an 
indivisible phrase; a recursive partial function need not be (as relation) 
recursive. But at least for a total function our terminology is consistent 
with past practice. 
THEOREM 
36D Let f : Nm + N be a total function. Then f is a 
recursive partial function iff f is recursive (as a relation). 
PROOF. If f is recursive (as a relation), then a fortiori f is re- 
cursively enumerable. Conversely, suppose that f is recursively 

2 52 
A Mathematical Introduction to Logic 
enumerable. Since f is total, 
f(G) # b 
3c[f(G) = c &  b # c]. 
The form of the right-hand side shows that the complement of 
f is also recursively enumerable. Thus by Theorem 35F, f is 
recursive. 
-1 
In first discussing normal form results, we pictured a two-input de- 
vice (Fig. 13). For any computable partial function, there is some pro- 
gram that computes it. But now the converse holds: Any program will 
produce some computable partial function. Of course many programs 
will produce the empty function, but that is a computable partial func- 
tion. 
Figure 13. Computer with program for f .  
For the recursive partial functions the same considerations apply. 
Define, for each e E N, the m-place partial function [el, by 
IIell,(al, . . . , a,) = U(pk (e, al, . . . , a,, k) E T,). 
The right-hand side is to be understood as undefined if there is no such 
k. In other words, 
2; E domCel, 
iff 3k (e, al, . . . , a,, k) E T,, 
in which case the value [en, (G) is given by the above equation. 
The following theorem is an improved version of Theorem 36B: 
NORMAL 
FORM THEOREM (KLEENE, 1943) (a) The (m + 1)-place par- 
tial function whose value at (e, al, . . . , a,) is [elm(al, . . . , a,) 
is a recursive partial function. 
(b) For each e >_ 0, [elm is an m-place recursive partial 
function. 
(c) Any m-place recursive partial function equals [elm for 
some e. 
PROOF. (a) We have 

Chapter 3: Undecidability 
2 53 
The part in square brackets is recursive, so the function (as a 
relation) is recursively enumerable. 
(b) The above proof still applies, e now being held fixed. 
(c) Let f be an m-place recursive partial function, so that 
((2, b) I f (2;) = b) is recursively enumerable. Hence there is a 
formula (p that weakly represents this relation in Cn A E. We claim 
that f = [#pjmd For if f (z) = b, then A 
I- 
(p (Sal 0, . . . , SamO, 
sbO). Hence there is a k such that (#(p, 2, k) E T,. For any such 
k, U(k) = b, since AE bL (p(SalO, . . . , Sam 0, SCO) for c # b. Sim- 
ilarly, if f (2) is undefined, then AE bL (p(SalO, . . . , Sam 0, SCO) for 
any c, whence [#(pj, 
is undefined here also. 
-1 
Part (a) of the normal form theorem (in the case m = 1) tells us that 
the function @ defined by the equation 
is a recursive partial function. And part (c) tells us that @ is "universal" 
in the sense that we can get any one-place recursive partial function 
from @ by holding the first variable fixed at a suitable value. 
The informal counterpart of the universal function @ is the computer 
operating system. The operating system takes two inputs, the program 
e and the data a. And it runs the program on that data. But the operating 
system itself is computable as a two-place partial function. 
The proof of normal form theorem gives us a way to compute the 
values of our "operating system" 0, 
albeit in an extremely inefficient 
way. The straightforward idea of "looking at the program e and doing 
what it says to the data a" has been obscured, to say the least. 
The function [enns is said to be the m-place recursive partial function 
with index e. Part (c) of the normal form theorem tells us that every 
recursive partial function has an index. The proof shows that the Godel 
number of a formula weakly representing a function is always an index 
of the function. 
We now have a convenient indexing [On 1, [l j 1, . . . of all the one- 
place recursive partial functions. Function [en 1 is produced by the "in- 
structions" encoded by e. Of course, that function will be empty unless 
e is the Godel number of a formula and certain other conditions are met. 
All the recursive total functions are included in our enumeration of 
recursive partial functions. But we cannot tell effectively by looking at 
a number e whether or not it is the index of a total function: 
THEOREM 
36E {e I [enl is total) is not recursive. 
PROOF. Call this set A. Consider the function defined by 
[ ~ ] ~ ( a ) + l  i f a ~ A ,  
ifa 4 A. 

254 
A Mathematical Introduction to Logic 
Then f ,  by its construction, is total. Is it recursive? We have 
f(a) = b  +==+ 
[(a 4 A & b  = 0) or (a E A & 3k((a, a, k) E Tl 
& b  = U(k) + 1 & (Vj < k)(a, a, j) 4 TI))]. 
Thus if A is recursive, then f (as a relation) is recursively enu- 
merable. But then f is a total recursive function, and so equals 
[el for some e E A. But f (e) = [en (e) + 1, so we cannot have 
f = [en 1. This contradiction shows that A cannot be recursive. 
-1 
It is not hard to show that A is in n2. This classification is the best 
possible, as it can be shown that A is not in X2. 
THEOREM 
36F The set 
K = {a I [a 1 (a) is defined) 
is recursively enumerable but not recursive. 
PROOF. K is recursively enumerable, since a E K 
3 k (a, a, k) 
E Tl. To see that K cannot be recursive, consider the function 
defined by 
if a E K, 
ifa 4 K. 
This is a total function. ~ x a c t l ~  
as in the preceQng theorem, we 
have that K cannot be recursive. 
-1 
COROLLARY 
36C (UNSOLVABILITY 
OF THE HALTING 
PROBLEM) The re- 
lation 
{(e, a) I [en 1 (a) is defined) 
is not recursive. 
PROOF. We have a E K iff the pair (a, a) belongs to this relation. 
(Thus the problem of membership in K is "reducible" to the halt- 
ing problem.) If this relation were recursive, then K would be, 
which is not the case. 
-1 
This corollary tells us that there is no effective way to tell, given a 
program e for a recursive partial function and an input a, whether or not 
the function [en 1 is defined at a. 
We can obtain an indexing of the recursively enumerable relations 
by using the following characterization. 
THEOREM 
36H A relation on N is recursively enumerable iff it is 
the domain of some recursive partial function. 
PROOF. The domain of any recursively enumerable relation is also 
recursively enumerable; cf. part 4 of Theorem 35E. In particular, 

Chapter 3: 
Undecidability 
255 
the domain of any recursive partial function is recursively enu- 
merable. 
Conversely, let Q be any recursively enumerable relation, 
where 
€ 
iix Q e 3b(ii,b) E R 
with R recursive. Let 
f (ii) = p b  (ii, b) E R; 
i.e., 
f (2) = b # (Z, b) E R & (VC < b)(z,c) $ R. 
Then f ,  as a relation, is recursive. Hence f is a recursive partial 
function. Clearly its domain is Q. 
-1 
Thus our indexing of the recursive partial functions induces an in- 
dexing of the recursively enumerable relations. Define 
Then Wo, Wl, W2, . . . is a list of all recursively enumerable subsets 
of N. In Theorem 36E we showed that {e I We = N) is not recursive. 
Similarly, Theorem 36F asserts that {e I e E We) is not recursive. Define 
a relation Q by 
Then Q is recursively enumerable, since (e , a )  E Q e 3 k (e, a, k) E TI. 
Furthermore, Q is universal for recursively enumerable sets, in the sense 
that for any recursively enumerable A 
N there is some e such that 
A = {a I (e, a )  E Q}. The unsolvability of the halting problem can be 
stated: Q is not recursive. 
We can apply the classical diagonal argument to "diagonalize out" 
of the list Wo, Wl , W2, . . . of recursively enumerable sets. The set 
{a I a $ W.} cannot coincide with any W,. In fact this set is exactly K, 
the complement of the set K in Theorem 36F. Because 
the set T cannot equal any W,; the number q witnesses the inequality 
of the two sets K and W,. 
And there is more: Whenever W, is a recursively enumerable subset 
of K, 
that is, W, 
T, then we can produce a number in 
that is not 
in W,. Such a number is q itself. To see this, observe that in the line 
displayed in the preceding paragraph we cannot have both sides false 
(q E K and q E W,) because W, 
K. 
So both sides are true. 
Theorem 36F asserts that K, although recursively enumerable, is 
not recursive. To show non-recursiveness, it suffices to show that its 
complement K is not recursively enumerable. The preceding paragraph 

A Mathematical Introduction to Loaic 
does this in a particularly strong way, thereby giving us a second proof 
of Theorem 36F. 
At this point, let us reconsider the Gijdel incompleteness theorem, 
from the computability point of view. 
The set K is recursively enumerable (i.e., El). It follows (cf. Theo- 
rem 35K) that K is arithmetical; that is, K is definable in the structure Sn. 
So there is a formula x(vl) with just vl free that defines K in Sn. 
And so the set K is defined in Sn by the formula 1 
x (vl). Thus we have 
This fact tells how we can "reduce" questions about membership in the 
set K to questions about Th Sn. Imagine that we are given a number a, 
and we want to know whether or not a E K. 
We can compute the number 
#( -I x (SaO)). (Informally, it is clear that we can eflectively compute this 
number. Formally, we apply item 5 from Section 3.4 to make sure we 
can recursively compute the number.) If we somehow had an oracle for 
# Th Sn (i.e., a magic device that, given a number, would tell us whether 
or not that number was in # Th Sn), then we could answer the question 
"IS a E KT' 
Now let us eliminate the magic. For sets A and B of natural numbers, 
we say that A is many-one reducible to B (in symbols, A 5, B) iff there 
exists a total recursive function f such that for every number a, 
The earlier example tells us that 
5, # Th Sn. More generally, the ar- 
gument shows that any arithmetical set is many-one reducible to # Th Sn. 
LEMMA 361 Assume that A and B are sets of natural numbers with 
A sm 
B. 
(a) If B is recursive, then A is also recursive. 
(b) If B is recursively enumerable, thenA is also recursively 
enumerable. 
(c) If B is En for some n, the A is also En for that n. 
PROOF. Part (a) is already familiar; it was, in different terminology, 
catalog item 2 in Section 3.3. 
Part (b) is essentially part (a) "plus a quantifier." That is, be- 
cause B is recursively enumerable, we know that for some recur- 
sive binary relation Q, 
c E B e 
3b Q(c, b). 
If f is the total recursive function that many-one reduces A to 
B, then every number a, 
a E A e 
f (a) E B e 
3b[Q( f (a), b)l. 

Chapter 3: 
Undecidability 
257 
The part in square brackets is recursive (i.e., {(a, b) I Q (f (a), b)) 
is recursive), as in part (a) of the lemma. So we have A in the 
required form to be recursively enumerable. 
Part (c) is essentially part (a) "plus n quantifiers" and is proved 
like part (b). 
-1 
Our reason for examining the particular set K is that it gives us the 
following consequence: 
GODEL l NCOMPLETENESS THEOREM Th 32 is not recursively axiomatiz- 
able. 
PROOF. Th32 cannot be recursively enumerable, lest K be recur- 
sively enumerable, by the preceding lemma. But any recursively 
axiomatizable theory would be recursively enumerable (item 20 
of Section 3.4; also Theorem 351). 
-1 
In starkest terms, the situation is this: Any recursively axiomatizable 
theory is recursively enumerable. But Th 32 is not recursively enumer- 
able. So any recursively axiomatizable subtheory must be incomplete. 
It will be worth while to go over this proof again, but replacing 
negative statements (such-and-such a set does not have a particular 
property) by positive statements. 
Assume that T is any recursively axiomatizable subtheory of Th 32. 
(So by the above theorem, T is incomplete.) We want to lay our hands 
on a sentence demonstrating the incompleteness. 
We have made a total recursive function f that many-one reduces z 
to #Th32, namely f (a) = #( 1 
x(SaO)); then for every a, 
And f (a) is (the Giidel number of) the sentence saying "a 4 K." 
Consider the set J of numbers defined by the condition 
a E J e 
f (a) E #T. 
Thus J is the set of numbers that T "knows" are not in K. There are 
two observations to be made concerning J: 
First, J is recursively enumerable. It is many-one reduced by f to 
the recursively enumerable set #T; apply Lemma 36I(b). 
Secondly, J r. 
We have T 
Th 32, so if T knows that a 4 K, 
then really a 4 K: 
So J is a recursively enumerable subset of T. It is aproper subset, 
because 
is not recursively enumerable. That is, there is some number 
q withq E 
andq 4 J. Consequently, f (q) E #Th32but f (q) 4 #T. 
That is, the sentence (1 
x(SQO)) is true (in 32) but fails to be in T, 
thereby demonstrating the incompleteness of T. 

A Mathematical Introduction to Logic 
And what does this sentence "say"? For q, we can take any number 
for which Wq = J. Then q E H and q $ J. 
Here then is the situation: 
says q 4 K 
i.e., q 4 Wq 
i.e.,q$J 
sinceWq=J 
i.e., f (q) $ #T 
by definition of J 
i.e., T y ( 7 x(Sq0)). 
The sentence we made to witness the incompleteness of T asserts its 
own unprovability in the axiomatizable theory T ! 
The computability approach and the self-reference approach to 
G6del's incompleteness theorem are not so different after all. Moreover, 
the computability approach is close to the diagonalization approach 
(of Section 3.0), but with the diagonal argument moved to a different 
context. 
Reduction of Decision Problems1 
Suppose we have a two-place recursive partial function. f .  Then we 
claim that, for example, the function g defined by 
is also a recursive partial function. On the basis of informal computabil- 
ity this is clear; one computes g by plugging in 3 for the first variable 
and then following the instructions for f .  A proof can be found by for- 
malizing this argument. There is some formula p = p(vl, w, %) that 
weakly represents f (as a relation) in Cn AE. Then g is weakly repre- 
sented by p(S30, vl, w), provided that vl and q are substitutable in p 
for w and 25. (If not, we can always use an alphabetic variant of p.) 
Now all this is not very deep. But by standing back and looking at 
what was said, we perceive a more subtle fact. We were able to transform 
effectively the instructions for f into instructions for g. So there should 
be a recursive function that, given an index for f and the number 3, 
will produce an index for g. The following formulation of this fact is 
sometimes known by the cryptic name of "the S-m-n theorem." 
PARAMETER 
THEOREM For each m > 1 and n 1 1 there is a recursive 
function p such that for any e, z,;, 
(Equality here means of course that if one side is defined, then so also 
is the other side, and the values coincide. Sometimes a special symbol 
"E" is used for this role.) 
The remainder of this section can be skipped on a first reading. 

Chapter 3: 
Undecidability 
259 
On the left side of the equation 2 consists of arguments for the func- 
tion [en,,,; 
on the right side 2 consists of parameters upon which 
the function [p (e, ;)J, depends. In the example we had m = n = 1 
and a1 = 3. Since p depends on m and n, the notation "p:" 
would be 
logically preferable. But, in fact, we will use simply "p." 
PROOF, 
FOR rn = n = 1 . It is possible to give a proof along the lines 
indicated by the discussion that preceded the theorem. But to avoid 
having to cope with alphabetic variants, we will adopt a slightly 
different strategy. 
We know from the normal form theorem that the three-place 
partial function h defined by 
is a recursive partial function. Hence there is a formula $ that 
weakly represents h (as a relation). We may suppose that in $ the 
variables vl and Q are not quantified. We can then take 
Then p (e, a) is the Gijdel number of a formula weakly represent- 
ing the function g (b) = [en2 (a, b). Hence it is an index of g. 
We will utilize the parameter theorem to show that certain sets are 
not recursive. We already know that K = {a I [anl (a) is defined) is 
not recursive. For a given nonrecursive set A we can sometimes find a 
(total) recursive function g such that 
or a (total) recursive function g' such that 
In either case it then follows at once that A cannot be recursive lest K be. 
In the former case we have K 5, A and A is not l7 1 (by Lemma 361); in 
the latter case 
5, A and A is not El. In either case, A is not recursive. 
The function g or g' can often be obtained from the parameter theorem. 
EXAMPLE. {a I W, = 0 )  is not recursive. 
PROOF. Call this set A. First, note that A E nl, since W, = 0 
iff VbVk (a, b, k) 4 TI. Consequently, K cannot be many-one 
reducible to A, but it is reasonable to hope that K might be. That 
is, we want a total recursive function g such that 
[anl (a) is undefined e dom[g(a)Jl = 0. 

A Mathematical Introduction to Logic 
This will hold if for all b, [g (a) 1 (b) = [an 1 (a). So start with 
the recursive partial function 
and let g(a) = p($, a), where f is an index for f. Then 
Thus this g shows that 
is many-one reducible to A. 
THEOREM 
36J (RICE, 1953) Let C be a set of one-place recursive par- 
tial functions. Then the set {e I [ell E C) of indices of members 
of C is recursive iff either C is empty or C contains all one-place 
recursive partial functions. 
PROOF. Only one direction requires proof. Let Ic = {e I [enl E C) 
be the set of indices of members of C. 
Case I: The empty function 0 is not in C. If nothing at all is 
in C we are done, but suppose some function $ is in C. We can 
show that K is many-one reducible to Ic if we have a recursive 
total function g such that 
For thena E K e 
I[g(a)D1 E C e g(a) E IC. 
We can obtain g from the parameter theorem by defining 
where 
$ (b) 
ifa E K, 
uen2(a9b) = {undefined 
ifa $ K. 
The above is a recursive partial function, since 
and the right-hand side is recursively enumerable. 
Case 11: 0 E C. Then apply case I to the complement of C. We 
can then conclude that IF is not recursive. But IF is the complement 
of Ic, so Ic cannot be recursive. 
Thus in either case, Ic is not recursive. 
-I 
EXAMPLES. For any fixed e, the set {a I W, = We} is not recursive, as 
a consequence of Rice's theorem. In particular, {a I W, = 0 )  is 
not recursive, a result proved in an earlier example. For two other 
applications of Rice's theorem, we can say that {a I W, is infinite} 
and {a I W, is recursive} are not recursive. 

Chapter 3: Undecidability 
261 
Register ~achines 
There are many equivalent definitions of the class of recursive func- 
tions. Several of these definitions employ idealized computing devices. 
These computing devices are like digital computers but are free of any 
limitation on memory space. The first definition of this type was pub- 
lished by Alan Turing in 1936; similar work was done by Emil Post at 
roughly the same time. We will give here a variation on this theme, due 
to Shepherdson and Sturgis (1963). 
A register machine will have a finite number of registers, numbered 
1,2, . . . , K. Each register is capable of storing a natural number of 
any magnitude. The operation of the machine will be determined by a 
program. A program is a finite sequence of instructions, drawn from the 
following list: 
I r (where 1 5 r p K). "Increment r ." The effect of this instruction 
is to increase the contents of register r by 1. The machine then proceeds 
to the next instruction in the program. 
D r (where 1 p r p K ) .  "Decrement r ." The effect of this instruction 
depends on the contents of register r .  If that number is nonzero, it is 
decreased by 1 and the machine then proceeds, not to the next instruc- 
tion, but to the following one. But if the number in register r is zero, the 
machine just proceeds to the next instruction. In summary: The machine 
tries to decrement register r and skips an instruction if it is successful. 
T q (where q is an integer-positive, negative, or zero). "Transfer q." 
All registers are left unchanged. The machine takes as its next instruc- 
tion the qth instruction following this one in the program (if q 
0), or 
the lq 1 th instruction preceding this one (if q < 0). The machine halts if 
there is no such instruction in the program. An instruction of T 0 results 
in a loop, with the machine executing this one instruction over and over 
again. 
1. Program to clear register 7. 
Try to decrement 7. 
Go back and repeat. 
Halt. 
2. Program to move a number from register r to register s. 
Clear register s 
I+" 
r 
(Use the program of the first example.) 
Take 1 from r .  
Halt when zero. 
Add 1 to s. 
Repeat. 

A Mathematical Introduction to Logic 
This program has seven instructions altogether. It leaves a zero 
in register r . 
3. Program to add register 1 to registers 2 and 3. 
4. (Addition) Say that a and b are in registers 1 and 2. We want 
a + b in register 3, and we want to leave a and b still in registers 1 
and 2 at the end. 
Register contents 
Clear register 3. 
a
b
O
 
Move number from register 1 to register 4. 
0 b 
0 
a 
Add register 4 to registers 1 and 3, 
a
b
a
 
0 
Move number from register 2 to register 4. 
a 
0 
a 
b 
Add register 4 to registers 2 and 3. 
a 
b 
a + b  
0 
This program has 27 instructions as it is written, but three of 
them are unnecessary. (In the fourth line we begin by clearing 
register 4, which is already clear.) At the end we have the number 
a back in register 1. But during the program register 1 must be 
cleared; this is the only way of determining the number a. 
5. (Subtraction) Let a 
b = max(a - b, 0). We leave this 
program to the reader (Exercise 1 I). 
Now suppose f is an n-place partial function on N. Possibly there 
will be a program P such that if we start a register machine (having all 
the registers to which P refers) with a1 , . . . , a, in registers 1, . . . , n and 
apply program P, then the following conditions hold: 
(i) If f (al, . . . , a,) is defined, then the calculation eventually termi- 
nates with f (al, . . . , a,) in register n + 1. Furthermore, the calculation 
terminates by seeking a (p + 1)st instruction, where p is the length of P. 
(ii) If f (al, . . . , a,) is undefined, then the calculation never termi- 
nates. 
If there is such a program P, we say that P calculates f .  
THEOREM 
36K Let f be a partial function. Then there is a program 
that calculates f iff f is a recursive partial function. 
Thus by using register machines we arrive at exactly the class of 
recursive partial functions, a class we originally defined in terms of 
representability in consistent finitely axiomatizable theories. The fact 

Chapter 3: 
Undecidability 
2 63 
that such different approaches produce the same class of partial functions 
is evidence that this is a significant class. 
OUTLINE 
OF PROOF. TO show that the functions calculable by reg- 
ister machines are recursive partial functions, one "arithmetizes 
calculations" in the same spirit as we arithmetized deductions in 
Section 3.4. That is, one assigns Godel numbers to programs and 
to sequences of memory configurations. One then verifies that the 
relevant concepts, translated into numerical relations by the Giidel 
numbering, are all recursive. (After going through this, one per- 
ceives that, from a sufficiently general point of view, deductions 
and calculations are really about the same sort of thing.) 
Conversely, to show that the recursive partial functions are cal- 
culable by register machines, one can work through Sections 3.3 
and 3.4 again, but where functions were previously shown to be 
representable in Cn AE, they must now be shown to be calculable 
by register machines. This is not as hard as it might sound, since 
after the first few pages, the proofs are all the same as the ones 
used before. There is a reason for this similarity. It can be shown 
that the class of all recursive functions is generated from a certain 
handful of recursive functions by the operation of composition (in 
the sense of Theorem 33L) and the "least-zero" operator (Theo- 
rem 33M). Much of the work in Sections 3.3 and 3.4 amounts 
to a verification of this fact. Thus once one has shown that each 
function in this initial handful is calculable by a register machine 
and that the class of functions calculable by register machines 
is closed under composition and the least-zero operator, then the 
earlier work can be carried over, yielding the calculability of all 
recursive functions. 
-I 
Exercises 
1, Define functions f and g by 
f 
= { 0 if Goldbach's conjecture is true, 
1 otherwise; 
0 if in the decimal expansion of n there 
g(n> = 
is a run of at least n consecutive 7's, 
1 
otherwise. 
Is f recursive? Is g recursive? (Goldbach's conjecture says that 
every even integer greater than 2 is the sum of two primes. The first 
edition of this book used Fermat's last theorem here.) 

264 
A Mathematical Introduction to Logic 
2. Define the "diagonal" function d (a) = Ra] 1 (a) + 1. 
(a) Show that d is a recursive partial function. 
(b) By part (a), we have d = [[ell for a certain number e. So on 
the one hand, d (e) = Re] (e) and on the other hand d (e) = 
[el 1 (e) + 1. Can we cancel, to conclude that 0 = l? Suggestion: 
Use the special symbol "z" 
to mean that either both sides of 
the equation are undefined, or both sides are defined and equal. 
Restate the argument in this notation. 
3, (a) Show that the range of any recursive partial function is recur- 
sively enumerable. 
(b) Show that the range of a strictly increasing (i.e., f (n) < 
f (n + I)) total recursive function f is recursive. 
(c) Show that the range of a nondecreasing (i.e., f (n) 5 f (n + 1)) 
total recursive function f is recursive. 
4. (a) Let A be a nonempty recursively enumerable subset of N. Show 
that A is the range of some total recursive function. 
(b) Show that any infinite recursively enumerable subset of N 
includes an infinite recursive subset. 
5. Show that every recursive partial function has infinitely many 
indices. 
6. Give an example of a function f and a number e such that for 
all a, 
but e is not the Giidel number of a formula weakly representin& 
7. Show that the parameter theorem can be strengthened by requiring 
p to be one-to-one. 
8. Recall that the union of two recursively enumerable sets is recur- 
sively enumerable (Exercise 7 of Section 3.5). Show that there is a 
total recursive function g such that Wg(a,b) = Wa U Wb. 
9. Show that {a I W, has two or more members) is in XI but not in Ill. 
10. Show that there is no recursively enumerable set A such that {[[a] 1 I 
a E A) equals the class of total recursive functions on N. 
11. Give register machine programs that calculate the following func- 
tions: 
(a) Subtraction, a 
b = max(a - b, 0). 
(b) Multiplication, a . b. 
(c) max(a, b). 
12. Assume that there is a register machine program that calculates the 
n-place partial function f .  Show that given any positive 

Chapter 3: 
Undecidability 
2 65 
integers rl, . , . , m (all distinct), p, and k, we can find a program 
Q such that whenever we start a register machine (having all the 
registers to which Q refers) with al, . . . , a, in registers rl, . . , , r, 
and apply program Q, then (i) if f (al, . . . , a,) is defined, then the 
calculation eventually terminates with f (al, . . . , a,) in register p, 
with the contents of registers 1,2, . . . , k (except for register p) the 
same as their initial contents, and furthermore the calculation ter- 
minates by seeking a (q + 1)st instruction, where q is the length 
of Q; (ii) if f (al, . . . , a,) is undefined, then the calculation never 
terminates. 
13. Let g : Nn+l + N be a (total) function that is calculated by some 
register machine program. Let f (al, . . . , a,) = pb[g(al, . . . , 
a,, b) = 01, where the right-hand side is undefined if no such b 
exists. Show that the partial function f can be calculated by some 
register machine program. 
14. Show that the following sets have the given location in the arithmeti- 
cal hierarchy. (In each case, the 'given location is the best possible, 
but we will not prove that fact.) 
(a) {e I [ell is total} is n2. 
(b) {e I We is finite) is E2. 
(c) {e I We is cofinite} is E3. 
(d) {e I We is recursive) is E3. 
15. Let Tot = {e I Ken is total}. Clearly Tot c K. Show that there is 
no recursive set A with 
Tot 
A G K. 
Remark: This result includes Theorems 36E and 36F; the proofs 
used there can be adapted here. 
16. (a) Show that each n2 set of natural numbers is, for some number 
e, the set 
{a I Vb3c T2(e, a, b, c)). 
(b) Show that the set {a 1 not Vb3c T2(a, a, b, c)) is E2 but 
not n2. 
*(c) Generalize parts (a) and (b) to show that for each n, there is a 
set that is En but not n,. 
17. Assume that A is a set of natural numbers that is arithmetical but 
is not nm. Use the argument of page 256 to show that fl Th% 
is not Em. 
Remark: Exercises 16 and 17 give a proof of Tarski's theorem 
(that fl Th % is not arithmetical) from computability theory. 

266 
A Mathematical Introduction to Logic 
SECTION 3.7 
Second Incompleteness Theorem 
Let us return once again to item 20 in Section 3.4. Suppose that we 
have a recursively axiomatizable theory T given by a recursive set A of 
axioms (i.e., #A is recursive). Then as in item 20 
a E #T 
3d [d is the number of a deduction from A 
and the last component of d is a and a 
is the Godel number of a sentence]. 
The set of pairs (a, d) meeting the condition in brackets is recursive; let 
n (vl , 3) 
be a formula- chosen in some natural way -that 
numeral- 
wise represents that binary relation in A E. 
For any sentence a ,  we can express "T I-a" by the sentence 
3 Q n(S"0, R). Let us give that sentence a name; define 
(Here Prb abbreviates "provable." The subscript should perhaps be "A" 
instead of "T"; in constructing the sentence we utilize the recursiveness 
of the set A of axioms.) 
LEMMA 37A Let T be a recursively axiomatizable theory as above. 
(a) Whenever T I- a then AE I- PrbT a. 
(b) If in addition T includes AE, then T has the "reflection" 
property: 
PROOF. If T I- a then we can let d be the number of a deduction 
of a from the axioms A for T .  We have AE I- n (Sou 0, SdO), 
and hence AE I- PrbT a. This gives part (a), from which part (b) 
follows immediately. 
-I 
Thus under modest assumptions, whenever T proves a, sentence, it 
knows that it proves the sentence. Note that part (b) does not say that 
T I- 
(a + PrbT a). For example, if a is true (in '31) but unprovable 
from AE, then the sentence (a + PrbA, a )  is not provable from AE, 
and in fact is false in '31. 
Returning now to the proof of the Godel incompleteness theorem 
(in the self-reference approach), we can apply the fixed-point lemma to 
obtain a sentence a asserting its own unprovability in T :  
The following lemma provides part of the incompleteness theorem (the 
other part being Exercise 2 in Section 3.5): 

Chapter 3: 
Undecidability 
267 
LEMMA 378 Let T be a recursively axiomatizable theory including 
A and let a be obtained from the fixed-point lemma as above. If 
T is consistent, then T If a. 
T I- a + T I- PrbT a by reflection 
=+ T I- 1 
a 
by choice of a 
whence T is inconsistent. 
So far, this lemma merely reflects ideas employed in Section 3.5, and 
the proof of Lemma 37B was not very complex. And that is exactly the 
point: The proof is not very complex, so perhaps it can be carried out 
within the theory T, if T is "sufficiently strong." That, we can hope that 
the steps 
can be carried out in a sufficiently strong extension T of AE. 
If so, we get a remarkable conclusion. Let Cons T be the sentence 
1 
PrbT 0 = SO, which we think of as saying "T is consistent." (Here 
0 = SO is chosen simply as a convenient sentence refutable from AE.) 
If T lets us carry out the steps in the preceding paragraph, then we can 
conclude: 
T If Cons T, 
unless T is inconsistent 
(Of course, an inconsistent theory contains every sentence, including 
sentences asserting - 
falsely -the theory's consistency. The situation 
we are finding here is that, under suitable assumptions, this is the only 
way that a theory can prove its own consistency.) Let's check the details: 
Suppose T I- Cons T. Then by the preceding paragraph, T I- 
1 
PrbT a. 
By choice of a ,  we then get T I- a. Lemma 37B then applies. 
To make matters less vague, call the theory T suficiently strong if it 
meets the following three "derivability" conditions. 
1. AE C T. This implies by Lemma 37A that T has the reflection 
property, T I- a j T I- PrbT a. 
2. For any sentence a ,  T I- (PrbT a + PrbT PrbT a). This is the 
reflection property, formalized within T. 
3. For any sentences p and a ,  T I- (PrbT (p + a )  + (hbT p + 
PrbT a)). This is modus ponens, formalized within T. 
FORMALIZED 
LEMMA 
378 Assume that T is a sufficiently strong re- 
cursively axiomatizable theory, and let a be a sentence such that 
Then T I- (Cons T + 1 
PrbT a). 

268 
A Mathematical Introduction to Logic 
PROOF. We put the pieces together carefully. By the choice of a 
we get 
T k (a + (fibT a + 0 = SO)). 
Applying first reflection and then formalized modus ponens to 
this formula yields 
T k (PrbT 0 + PrbT (fibT 0 + 0 = SO)) 
after which another application of formalized modus ponens 
yields 
The formula displayed above (to the right of the turnstile), to- 
gether with PrbT o + PrbT PrbT o (formalized reflection) imply 
by sentential logic PrbT a + 1 
Cons T. 
-I 
GODEL'S 
SECOND INCOMPLETENESS 
THEOREM 
(1 931 ) Assume that T is 
a sufficiently strong recursively axiomatizable theory. Then 
T k Cons T if and only if T is inconsistent. 
PROOF. If T I- Cons T then by Formalized Lemma 37B we have 
T k 1 
PrbT a whence by our choice of a ,  we have T k a. We 
conclude from the (unformalized) Lemma 37B that T is incon- 
sistent. 
i 
We can squeeze a bit more out of these ideas. Lemma 37B can be 
regarded as a special case (where t is 0 = SO) of the following: 
LEMMA 37C Let T be a recursively axiomatizable theory including 
A E, let t be a sentence, and let a be obtained from the fixed-point 
lemma so that 
AE k (0 * (PrbTO + t)). 
If T I- a ,  then T I- t. 
PROOF. We can think of a as saying, "If I am provable, then t ." If 
T k a then by reflection T k PrbT a. By the choice of a ,  we 
have T I- t. 
-1 
Actually we are not interested in this lemma, but in its formalization: 
FORMALIZED 
LEMMA 37C Assume that T is a sufficiently strong re- 
cursively axiomatizable theory. Let t be a sentence, and let a be 
a sentence such that 
AE I- (0 * (RbT o + t)). 
Then T I- (PrbT o + P r b ~  
t). 

Chapter 3: 
Undecidability 
269 
PROOF. We proceed as before. By the choice of a we get 
T 
(a + (PrbT a + t)). 
Applying first reflection and then formalized modus ponens to 
this formula yields 
T 
(PI'bT a + PrbT PrbT 0 + t)) 
after which another application of formalized modus ponens yields 
T 
(PrbT 0 + (PrbT PrbT a + PrbT t)). 
The formula displayed above (to the right of the turnstile), to- 
gether with PrbT a + PrbT PrbT a (formalized reflection) imply 
by sentential logic PrbT a + PrbT t. 
-1 
LOB'S THEOREM 
(1 955) Assume that T is a sufficiently strong re- 
cursively axiomatizable theory. If t is any sentence for which 
T I- (PrbT t + t),then T I- t. 
Clearly if T I- t ,  then T I- (p + r )  for any sentence p. So the 
conclusion to Lob's theorem can be stated 
PROOF. Given the sentence t ,  we construct a to say, "If I am prov- 
able then t," as above. Suppose that T I- (PrbT t + t). By 
Formalized Lemma 37C we have T 
(PrbT a + PrbT t). By 
our choice of a ,  we conclude that T I- a. So by the (unformalized) 
Lemma 37C, we have T I- t. 
-1 
Lob's theorem was originally devised in order to solve the problem 
given in Exercise 1. But it implies (and in a sense is equivalent to) 
Godel's second incompleteness theorem. Assume that T is a sufficiently 
strong axiornatizable theory. Applying Lob's theorem and taking t to 
be 0 = SO, we have 
that is, 
T I- Cons T + T is inconsistent. 
Thus we obtain a proof of the second incompleteness theorem. 
But there is an issue not yet examined: What theories are sufficiently 
strong? Are there any at all (apart from the trivial case of the inconsistent 
theory)? 
Yes, and here are two. The first is called "Peano arithmetic" (PA). 
Its axioms consist of the AE axioms, plus all the "induction axioms." 
These are the universal closures of formulas having the form 

A Mathematical Introduction to Logic 
for a wff p. The induction axioms - 
which state the ordinary principle of 
mathematical induction - 
enable us to carry out many arguments about 
the natural numbers (e.g., the commutative law of addition) within Peano 
arithmetic. But to be sure that formalized reflection and formalized 
modus ponens can be derived with Peano arithmetic, one must carry out 
the details, which we will not go through here. 
We know that Peano arithmetic is consistent, because it is true in '31. 
But by the second incompleteness theorem, PA cannot prove its own 
consistency, We "know" that PA is consistent by means of an argument 
we carry out either in informal mathematics, or -if 
we want-in 
set 
theory. So set theory has a higher "consistency strength than PA: It 
proves the consistency of PA and PA does not. 
A second sufficiently strong theory is axiomatic set theory. Or to be 
more careful, it is the set of sentences in the language of number theory 
that are provable in axiomatic set theory. The next subsection deals with 
this situation. This thwry has the advantage that it is quite believable - 
on an informal level -that formalized reflection and formalized modus 
ponens are derivable. But what are our grounds for thinking that set 
thwry is consistent? We know that PA is consistent because it is true in 
the "standard model" '31 of number theory. It is not at all clear that we 
can meaningfully speak of a "standard model of set theory"! 
Applications to Set Theory 
We know that in the language of number theory, Cn AE is incomplete 
and nonrecursive, as is any compatible recursively axiomatizable theory 
in the language. 
But now suppose we leave arithmetic for a while and look at set the- 
ory. Here we have a language (with the parameters V and E) and a set 
of axioms. In all presently accepted cases the set of axioms is recursive. 
Or more precisely, the set of Gijdel numbers of the axioms is recursive. 
And so the theory (set theory) obtained is recursively enumerable. We 
claim that this theory, if consistent, is not recursive and hence not com- 
plete. We can already sketch the argument in rough form. We can, in a 
very real sense, embed the language of number theory in set theory. We 
can then look at that fragment of set theory which deals with the natu- 
ral numbers and their arithmetic (the shaded area in Fig. 14). That is a 
theory compatible with AE . And so it is nonrecursive. Now if set thwry 
were recursive, then its arithmetical part would also be recursive, which 
it is not. As a bonus, we will come across the second incompleteness 
theorem for the case of set theory. 
~enceforth by set thwry (ST) we mean that theory (in the language 
with equality having the two parameters V and E) which is the set of con- 
sequences of the reader's favorite set-theoretic axioms. (The standard 
Zermelc+Fraenkel axioms will do nicely, if the reader has no favorite. 

Chapter 3: 
Undecidability 
271 
I 
Sentences 7 
m the 
I 
language of num- I . 
ber theory 
(recursive) 
Set theory 
(recursively 
Sentences in the language of 
number theory (recursive) 
(b) 
Figure 14. Set theory and number theory. (a) Flat picture. (b) A more accurate 
picture. 
We ask only that the set of axioms be recursive, and that it be strong 
enough to yield certain everyday facts about sets.) We need an inter- 
pretation n of Cn AE into ST. (The remainder of this section assumes a 
familiarity with Section 2.7.) But the existence of such a n is a standard 
result of set theory, although it is not usually stated in these words. We 
need formulas of the language of ST that adequately express the concept 
of being a natural number, being the sum of two given numbers, and so 
forth. To find these formulas, we turn to the way in which the arithmetic 
of natural numbers can be "embedded" in set theory. That is, on the one 
hand, natural numbers such as 2 or 7 do not appear to be sets. On the 
other hand, we can, when we choose, select sets to represent numbers. 
The standard approach is to take 0 to be the set 0 and n + 1 to be the 
set n; n. This has the fringe benefit that each number is the set of all 
smaller numbers (e.g., 3 E 7). Let w be the collection of all these sets 

2 72 
A Mathematical Introduction to Logic 
(these "number-sets"); thus w is the set representing N. 
The formula nv is the result of eliminating the defined symbol w 
from the formula vl E w. The formula no is similarly obtained from 
the set-theoretic formula vl = 0 ,  and the formula ns is obtained from 
3 = v1 U {vl). The formula n, is simply vl E %. For x+ we use the 
translation into the language of ST of 
Forany f, 
iff :wxw+wandforallaandb 
inwwehave f ( a , 0 )  = a  
and f(a,bU {b)) = f(a, b) U {f(a, b))? 
then f (v1, %) = 213. 
(The manner of translation is partially indicated in Chapter 0.) The 
formulas n. and n~ are obtained in much the same fashion. 
The claim that this n is an interpretation of Cn AE into ST makes a 
number (and the number is 17) of demands on ST. 
(i) 3 vlnv must be in ST. It is, since we can prove in set theory that 
w is nonempty. 
(ii) For each of the five function symbols f in the language of 
AE, ST must contain a sentence asserting, roughly, that nf defines a 
function on the set defined by nv. (The exact sentence is set forth in 
the definition of interpretation in Section 2.7.) In the case of 0, we have 
in ST the result that there is a unique empty set and that it belongs to 
w. The case for S is simple, since ns defines a unary operation on the 
universe of all sets, and w is closed under this operation. For + we 
must use the recursion theorem on w. That is, we can prove in ST (as 
sketched in Section 1.4) that there is a unique f : w x w + w such that 
f (a, 0 )  = a and f (a, b U {b}) = f (a, b) U {f (a, b)] for a, b in w. 
The required property of n+ then follows. Similar arguments apply to 
and E. 
(iii) For each of the 1 1 sentences a in A E, the sentence an must be 
in ST. For example, in the case of L3, we have in ST the fact that for 
any rn and n in w, either rn E n, rn = n, or n E rn. 
Since these demands are finite in number, there is a finite @ 
ST 
such that n is also an interpretation of Cn A into Cn a. 
THEOREM 
37D (STRONG 
UNDECIDABILITY 
OF SET THEORY) Let T be a 
theory in the language of set theory such that T U ST (or at least 
T U @) is consistent. Then flT is not recursive. 
PROOF. Let A be the consistent theory Cn(T U a). Let A. be the 
corresponding theory n-' [A] in the language of number theory. 
From Section 2.7 we know that A. is a consistent theory (since 
A is). Also AE E AO, since if a E AE, then an E Cn@ 
A. 

Chapter 3: 
Undecidability 
2 73 
Hence by the strong undecidability of Cn AE (Theorem 35C), #Ao 
is not recursive. 
NOW we must derive the nonrecursiveness of T from that of 
Ao. We have 
a E A. 
iff an E A 
and by the lemma below, #an depends recursively on #a. That is, 
#Ao srn 
#A. Hence #A cannot be recursive, lest #Ao be. Similarly, 
we have 
t E A iff (4p + t )  f T, 
where 4p is the conjunction of the members of @. Since #(4p + t) 
depends recursively on #t, we have #A 5, #T so that #T cannot 
be recursive lest #A be. 
-1 
LEMMA 
37E There is a recursive function p such that for any formula 
a of the language of number theory, p (#a) 
= # (an). 
PROOF. In Section 2.7 we gave explicit instructions for construct- 
ing an. The construction in some cases utilized formulas #In for 
formulas #I simpler than a. The methods of Sections 3.3 and 3.4 
can be applied to the Godel numbers of these formulas to show 
that p is recursive. But the details are not particularly attractive, 
and we omit them here. 
i 
COROLLARY 
37F If set theory is consistent, then it is not complete. 
PROOF. Set theory has a recursive set of axioms. If complete, the 
theory is then recursive (by item 21 of Section 3.4). By the fore- 
going theorem, this cannot happen if ST is consistent. 
-1 
COROLLARY 
37G In the language with equality and a two-place 
predicate symbol, the set of (Godel numbers of) valid sentences 
is not recursive. 
PARTIAL PROOF. In the foregoing theorem take T = Cn0, the set of 
valid sentences. The theorem then assures us that #T is nonrecur- 
sive, provided that @ is consistent. We have not given the finite 
set @ explicitly. But we assure the reader that @ can be chosen in 
such a way as to be provably consistent. 
-1 
It should be noted that n is not an interpretation of ThC32 into ST 
(unless ST is inconsistent). For n - l [ ~ ~ ]  
is a recursively enumerable 
theory in the language of C32, as a consequence of Lemma 37E. Hence 
it cannot coincide with ThC32, and it can include the complete theory 
Th C32 only if it is inconsistent. 

2 74 
A Mathematical Introduction to Logic 
Godel's Second l ncompleteness Theorem 
for Set Theory 
We can employ our usual tricks to find a sentence a of number theory 
which indirectly asserts that its own interpretation an is not a theorem 
of set theory. For let D be the ternary relation on N such that 
(a, b, c) E D iff a is the Godel number of a formula a of number 
theory and c is the G a e l  number of a deduction 
from the axioms of ST of ~ ! ( s ~ o ) ~ .  
The relation D is recursive (by the usual arguments); let S(vl, q, 
Q) 
represent D in Cn AE. Let r be the Godel number of 
and let a be 
Observe that 0 does indirectly assert that an $ ST. We will now prove 
that the assertion is correct: 
LEMMA 37H If ST is consistent, then an $ ST. 
PROOF. Suppose to the contrary that an is deducible from the ax- 
ioms of ST; let k be G of such a deduction. Then (r, r, k) E D. 
Applying our interpretation n, we conclude that 1 
on is in ST, 
whence ST is inconsistent. Thus 
ST is consistent + an $ ST. 
Now the above proof, like all those in this book, is carried out in 
informal mathematics. But all of our work in the book could have been 
carried out within ST. Indeed it is common knowledge that essentially 
all work in mathematics can be carried out in ST. Imagine actually doing 
so. Then instead of a proof of an English sentence, "ST is consistent 
+ an $ ST," we have a deduction from the axioms of ST of a certain 
sentence in the formal language of set theory: 
Here Cons(ST) is the result of translating (in a nice way) "ST is 
consistent'? into the language of set theory. Similarly, 
is the result of 
translating "an 4 ST." But we already have a sentence in the language 

Chapter 3: Undecidability 
2 75 
of set theory asserting that a" 4 ST. It is a". This strongly suggests 
that 
is (or is provably equivalent in ST to) a", from which we get 
(Cons(ST) + an) 
as a theorem of ST. 
Now this can actually be carried out in such a way as to have 
be 
a". We have given above an argument, which we hope will convince 
&e reader that this is at least probable. And from it we now have the 
result: 
GODEL'S 
SECOND INCOMPLETENESS 
THEOREM 
FOR SET THEORY The sen- 
tence Cons(ST) is not a theorem of ST, unless ST is inconsistent. 
PROOF. By the above (plausibility) argument 
(Cons(ST) + a") 
is a theorem of ST. So if Cons(ST) is also a theorem of ST, then a" 
is, too. But by Lemma 37H, if an E ST, then ST is inconsistent. 
-I 
Of course if ST is inconsistent, then every sentence is a theorem, 
including Cons(ST). Because of this, a proof of Cons(ST) within ST 
would not convince people that ST was consistent. (And by Godel's 
second theorem, it would convince them of the opposite.) But prior to 
Godel's work it was possible to hope that Cons(ST) might be provable 
from assumptions weaker than the axioms of set theory, ideally assump- 
tions already known to be consistent. But we now see that Cons(ST) is 
not in any subtheory of ST, unless of course ST is inconsistent. 
We are left with the conclusion that any recursively axiomatizable 
theory of sets (provided it meets the desirable conditions of being 
consistent and strong enough to prove everyday facts) is an incom- 
plete theory. This raises a challenge: to find additional axioms to add 
to the theory. On the one hand, we want the additional axioms to 
strengthen the theory in useful ways. On the other hand, we want the 
additional axioms to reflect accurately our informal ideas about what 
sets really are and how they really behave. 
Exercises 
1. Let a be a sentence such that 
(Thus a says "I am provable," in contrast to the sentence "I am 
unprovable" that has been found to have such interesting properties.) 
Does AE I- a ?  

276 
A Mathematical Introduction to Logic 
2. Let T be a theory in a recursively numbered language, and assume 
that there is an interpretation of Cn A into T. Show that T is strongly 
undecidable; i.e., whenever T' is a theory in the language for whlch 
T U T' is consistent, then #T' is not recursive. 
SECTION 3.8 
Representing Exponentiation' 
In Sections 3.1 and 3.2 we studied the theory of certain reducts of rt 
and found them to be decidable. Then in Section 3.3 we added both 
multiplication and exponentiation. The resulting theory was found (in 
Section 3.5) to be undecidable. Actually it would have been enough 
to add only multiplication (and forego exponentiation); we would still 
have undecidability. 
Let flM be the reduct of IYt obtained by dropping exponentiation: 
Thus the symbol E does not appear in the language of nM. 
Let AM be 
the set obtained from AE by dropping El and E2. The purpose of this 
section is to show that all the theorems of Sections 3.3-3.5 continue to 
hold when "A E" and "W' are replaced by "A 
and "nM 
." The key fact 
needed to establish this claim is that exponentiation is representable in 
Cn AM. That is, there is a formula E in the language of CSZM such that 
for any a and b, 
Thus ~ ( x ,  
y, z) can be used to simulate the formula xEy = z without 
actual use of the symbol E. 
If we look to see what relations and functions are representable in 
Cn AM, we find at first that everything (except for exponentiation itself) 
that was shown to be representable in Cn AE is (by the same proof) 
representable in Cn AM. Until, that is, we reach item 7 in the catalog 
listing of Section 3.3. To go further, we must show that exponentiation 
itself is representable in Cn AM. 
We know that exponentiation can be characterized by the recursion 
equations 
This section may be omiued without loss of continuity. 

Chapter 3: 
Undecidability 
277 
From what we know about primitive recursion (catalog item 13 in 
Section 3.3 plus Exercise 8 there), we might think of defining 
E* (a, b) = the least s such that [(s)~ = 1 and 
for alli < b, ( s ) ~ + ~  
= ( s ) ~  -a]. 
For then ab = (E* (a, b))b. This fails to yield a proof of representabil- 
ity, because we do not yet know that the decomposition function (a)b 
is representable in Cn AM. But we do not really need that particular 
decomposition function (which corresponded to a particular way of 
encoding sequences). All we need is some function 6 that acts like a 
decomposition function; the properties we need are summarized in the 
following lemma. 
LEMMA 38A There is a function S representable in Cn AM such that 
for every n, ao, . . . , a,, there is an s for which S(s, 5) = a; for 
all i 5 n. 
Once the lemma has been established, we can define 
E** (a, b) = the least s such that [S (s, 0) = 1 and 
for all i < b, S(s, i + 1) = S(s, i) . a]. 
The lemma assures us that such an s exists. E** is then representable in 
Cn AM, as is exponentiation, since 
ab = S(E**(a, b), b). 
A function S that establishes the lemma will be provided by some facts 
of number theory. 
A Pairing Function 
As a first step toward proving the foregoing lemma, we will construct 
functions for encoding and decoding pairs of numbers. It is well known 
that there exist functions mapping N x N one-to-one onto N. In partic- 
ular, the function J does this, where in the diagram shown, J (a, b) has 
been written at the point with coordinates (a, b). 
+
+
+
+
 
X
X
X
X
 
&
&
A
&
 
No D 
P2 BJ 
J 

2 78 
A Mathematical Introduction to Logic 
For example, J (2, 1) = 8 and J (O,2) = 3. To obtain an equation 
for J (a, b), we note that along the line x + y = n there are n + 1 points 
(with coordinates in W). Thus 
J (a, b) = the number of points in the plane to which J assigns smaller 
values 
= [the number of points on lines x + y = n for 
n = 0, 1,. . . , (a + b  - I)] + [thenumberofpointson the 
linex+y=a+bforwhichx < a ]  
= [ 1 + 2 + . . . + ( a + b ) l + a  
- 
- '(a+b)(a+b+ 
2 
1)+a 
= ;[(a + b)2 +3a + b]. 
Let K and L be the corresponding projection functions onto the axes, 
i.e., the unique functions such that 
K(J(a, b)) = a ,  L(J(a, b)) = b. 
For example, K (7) = 1, the x-coordinate of the point ( 1,2) in the plane 
to which J assigned the number 7. Similarly, L (7) = 2, the y-coordinate 
of that point. 
We claim that J, K, and L are representable in Cn AM. The function 
H (a) = the least b such that a 5 2b 
has the property that H (a) = ;a for even a. Then we can write 
J(a, b) = H((a + b) . (a + b + 1)) + a ,  
K (p) = the least a such that [for some b 5 p, J (a, b) = p], 
L (p) = the least b such that [for some a 5 p, J (a, b) = p]. 
From the form of the four preceding equations we conclude that H, J ,  
K , and L are representable in Cn A M .  
The Godel p-function 
Let p be the function defined as follows: 
P(c, d, i) = the-remainder in c + [l + (i + 1). dl 
= the least r such that for some q 5 c, 
c = q S [ 1 + ( i + 1 ) . d ] + r .  
This unlikely-looking function produces a satisfactory decomposition 
function for Lemma 38A. Let 
It is clear that S is representable in Cn AM. What is not so obvious is 
that it meets the conditions of Lemma 38A. We want to show: 
For any n and any ao, . . . , a,, there are numbers 
c and d such that (c, d, i) = ai for all i ( n. 
For then it follows that 6 ( J  (c, d), i) = P(c, d, i) = ai for i 5 n. 
< 

Chapter3: Undecidability 
2 79 
Now (*) is a statement of number theory, not logic. The proof of (a) 
is based on the Chinese remainder theorem. Numbers do, . . . , d, are 
said to be relatively prime in pairs iff no prime divides both di and dj 
for i # j. 
CHINESE 
REMAINDER 
THEOREM Let do, . . . , d,,, be relatively prime in 
pairs; let ao, . . . , a, be natural numbers with each ai < di. Then 
we can find a number c such that for all i 5 n, 
ai = the remainder in c i 
di. 
PROOF. Let p = IIi<,di, and for any c let F (c) be the (n + 1)-tuple 
of remainders when c is divided by do, . . . , d,. Notice that there 
are p possible values for this (n + 1)-tuple. 
We claim that F is one-to-one on {k I 0 5 k < p}. For suppose 
that F (cl) = F (c2). Then each di divides Icl - cz I .  Since the di 's 
are relatively prime, p must divide Icl - c2 1. For cl , c2 less than 
p, this implies that cl = c2. 
Hence the restriction of F to {k I 0 5 k < p} takes on all p 
possible values. In particular, it assumes (at some point c) the 
value (ao, . . . , a,). And that is the c we want. 
i 
LEMMA 38B For any s 2 0, the s + 1 numbers 
are relatively prime in pairs. 
PROOF. All these numbers have the property that any prime factor 
q cannot divide s!, whence q > s. If the prime q divides both 
1+ j.s!and l+k.s!,thenitdividestheirdifference, Ij -kl.s!. 
Sinceqdoesnotdivides!,itdivides Ij-kl.ButIj-kl 
5 s < q. 
This is possible only if I j - k 1 = 0. 
i 
PROOF OF (*). Assume we are given ao, . . . , a,; we need numbers 
c and d such that the remainder when c is divided by 1 + (i + 1) d 
is ai, for i ( n. 
Let s be the largest of {n, ao, . . . , a,) and let d = s !. Then by 
Lemma 38B, the numbers 1 + (i + 1) . d are relatively prime in 
pairs for i ( n. So by the Chinese remainder theorem there is a c 
such that the remainder in c t [l + (i + 1) dl is ai for i 5 n. i 
This completes the proof of Lemma 38A. And by the argument that 
followed that lemma, we can conclude: 
THEOREM 
38C Exponentiation is representable in Cn AM. 
Armed with this theorem, we can now return to catalog item 7 of 
Section 3.3. The proof given there now establishes that the function in 
question (whose value at n is p,) is representable in Cn A M .  For it was 

TABLE X 
Structure 
Theory 
Models of the theory 
Definable sets 
Comments 
(N) 
Decidable. Not finitely 
Any infinite set. 
0 and N. 
axiomatizable. Admits 
{0) is not definable. 
elimination of quantifiers. 
As above. 
As above. 
Decidable. Finitely 
axiomatizable. 
Admits elimination of 
quantifiers. 
Decidable (Presburger). 
(N; 0, S, < , +, .) 
Not arithmetical. 
.'. not recursively 
axiomatizable. 
Any infinite set with 
0, {o), N - {Oh N. 
distinguished element. 
S is not definable. 
Standard part plus any 
Finite and cofinite sets. 
(0) is definable in (N; S). 
number of 2-chains. 
< is not definable. 
As above, with any 
Finite and cofinite sets. 
(01 and S are definable 
ordering of the 2-chains. + is not definable. 
in (N; e). 
The 2-chains are densely Eventually periodic sets. 
(01, S, and < are 
ordered without 
- is not definable. 
definable in (N; +). 
endpoints. 
Also there is a suitable 
addition operation. 
As above, but with a 
All arithmetical relations The arithmetical relations 
suitable multiplication 
are definable. 
are definable in 
operation. 
(N; s ,  .I, (N +, o h  
and (N; i, 
D), where 
D(x, Y) = (4,. 

Chapter 3: Undecidability 
281 
formed by allowable methods from relations and functions (including 
exponentiation) known to be representable in Cn AM. 
The same phenomenon persists throughout Sections 3.3 and 3.4. 
The representability proofs given there now establish representability 
in Cn AM. Thus any recursive relation is representable in Cn AM, and if 
the relation happens to be a function, then it is functionally representable. 
The proofs given in Section 3.5 then apply to f l ~  
and AM as well as to 
rt and AE. In particular, we have the strong undecidability of Cn AM: 
Any theory T in the language of rtM for which T U AM is consistent 
cannot be recursive. 
Notice that any relation definable in rt (i.e., any arithmetical relation) 
is also definable in (nM. For exponentiation, being representable in a 
subtheory of Th rtM, is a fortiori definable in rtM. 
By the new version 
of Tarski's theorem, #ThrtM is not definable in (nM, and consequently 
#ThrtM cannot be arithmetical. 
In the terminology of Section 2.7, we can say that there is a faithful 
interpretation of Th rt into Th rtM. It equals the identity interpretation 
on all parameters except E, and to E it assigns a formula defining ex- 
ponentiation in !JIM. 
In Table X we summarize some of the results of Chapter 3 on number 
theory and its reducts. 
Exercises 
1. Let D(a, b) = (a)b. Show that any arithmetical relation is definable 
in the structure (N; <, D). Remark: One may well ask why Th ~ I A ,  
arithmetic with addition, is decidable (as shown in Section 3.2), while 
Th n M ,  the theory of arithmetic with addition and multiplication, is 
undecidable. One answer is that, as this section shows, multiplication 
lets us do a certain amount of sequence coding and decoding. The 
point of this exercise is to show that once we have the decoding 
function D and ordering, we have the full complexity of arithmetic 
with addition, multiplication, and exponentiation. 
2. Show that the addition relation {(a, b, c) I a + b = c) is definable in 
the structure (N; S, .). Suggestion: Under what conditions does the 
equation S(ac) a S(bc) = S(c . c . S(ab)) hold? 
3. (a) Show that Th(Z; +, .) is strongly undecidable. (See Exercise 2 
of Section 3.7.) 
(b) (This part assumes a background in algebra.) Show that the the- 
ory of rings is undecidable and that the theory of commutative 
rings is undecidable. 

Second-Order Languag 
sive languages than the first-ard 
sidered thus far, by allowing 
predicate or function symbols. F 
V P 3 x ( P x  - V x  P x )  
deserves to be called valid. (Now V is 
rarneter, since P  is treated as a predicat 
n we have the n-place predicate variabl 

Chapter 4: second-order Logic 
283 
individual variables by applying the function symbols (both the func- 
tion parameters and the function variables). Atomic formulas are again 
expressions Ptl . tn, where tl, . . . , tn are terms and P is an n-place 
predicate symbol (parameter or variable). The definition of wff is aug- 
mented by new formula-building operations: If q is a wff, then so also 
are VX; q and V Fy q. The concept of a variable occurring free in q 
is defined just as before. A sentence is a wff a in which no variable 
(individual, predicate, or function) occurs free. 
It should be remarked that the roles played by predicate parame- 
ters and free predicate variables are essentially the same. There is the 
same close relationship between constant symbols and free individual 
variables, and between function parameters and free function variables. 
By a structure we continue to mean a function on the set of parame- 
ters meeting the conditions set forth in Section 2.2. We must extend the 
definition of satisfaction in the natural way. Let V now be the set of all 
variables, individual, predicate, or function. Lets be a function on V that 
assigns to each variable the suitable type of object. Thus s (ul) is a mem- 
ber of the universe, s (Xn) is an n-ary relation on the universe, and s(Fn) 
is an n -ary operation. For a term t , F(t ) is defined in the natural way. In 
particular, if F is a function variable, then F(Ftl . tn) is the result of 
applying the function s (F) to (F(tl ) , . . . , F(tn)) . Satisfaction of atomic 
formulas is also defined essentially as before. For a predicate variable X, 
k a X t l - - - t n [ ~ ]  
iff 
(F(tl)y ..., F(tn)) E s(X). 
The only new features in the definition of satisfaction arise from our 
new quantifiers. 
5. km V Xy q [s] iff for every n-ary relation R on I%[, we have 
km q[s(Xy I R)1. 
6. 
VFrq[s] iff for every function f : IUIn + IIUI, we have 
km p[s(FI I f 11. 
Again it is easy to see that only the values of s at variables occurring 
free in the formula are significant. For a sentence a ,  we may unam- 
biguously speak of its being true or false in IU. Logical (semantical) 
implication is defined exactly as before. 
EXAMPLE 1. A well-ordering is an ordering relation such that any 
nonempty set has a least (with respect to the ordering) element. 
This last condition can be translated iuto the second-order 
sentence 
Here, as elsewhere, we omit the subscripts on X and F when they 
are immaterial, and we omit the superscripts if they are clear from 
the context. 

284 
A Mathematical Introduction to Logic 
EXAMPLE 2. One of Peano's postulates (the induction postulate) 
states that any set of natural numbers that contains 0 and is closed 
under the successor function is, in fact, the set of all natural num- 
bers. This can be translated into the second-order language for 
number theory as 
VX(X0 A v y(Xy --, XSy) --, v y Xy). 
Any model of S1, S2, and the above Peano induction postu- 
late is isomorphic to (N; 0, S); see Exercise 1. Thus this set of 
sentences is categorical; i.e., all its models are isomorphic. 
EXAMPLE 3. For any formula p in which the predicate variable Xn 
does not occur free, the formula 
is valid. (Here other variables may occur free in q in addition to 
vl , . . . , v, .) It says that there exists a relation consisting of exactly 
the n-tuples satisfying p. Formulas of this form are called relation 
comprehension formulas. There are also the analogous function 
comprehension formulas. If @ is a formula in which the variable 
Fn does not occur free, then 
is valid. (Here "3!vn+l @" is an abbreviation for a formula ob- 
tained from Exercise 21 of Section 2.2.) 
EXAMPLE 4. In the ordered field of real numbers, any bounded non- 
empty set has a least upper bound. We can translate this by the 
second-order sentence 
It is known that any ordered field that satisfies this second-order 
sentence is isomorphic to the ordered field of reds. 
EXAMPLE 5. For each n > 2, we have a first-order sentence An which 
translates, "There are at least n things." For example, A3 is 
The set {A2, As, . . .) has for its class of models the ECA class 
consisting of the infinite structures. There is a single second- 
order sentence that is equivalent. A set is infinite iff there is an 
ordering on it having no last element. Or more simply, a set is 

Chapter 4: Second-Order Logic 
285 
infinite iff there is a transitive irreflexive relation R on the set 
whose domain is the entire set. This condition can be translated 
into a second-order sentence A,: 
Another sentence (using a function variable) that defines the class 
of infinite structures is 
which says there is a one-to-one function that is not onto. 
The preceding example shows that the compactness theorem fails for 
second-order logic: 
THEOREM 
41A There is an unsatisfiable set of second-order sen- 
tences every finite subset of which is satisfiable. 
PROOF. The set is, in the notation of the above example, 
The Lowenheim-Skolem theorem also fails for second-order logic. 
By the language of equality we mean the language (with =) having no 
parameters other than V. A structure for this language can be viewed 
as being simply a nonempty set. In particular, a structure is determined 
to within isomorphism by its cardinality. A sentence in this language is 
therefore determined to within logical equivalence by the set of cardi- 
nalities of its models (called its spectrum). 
THEOREM 
41 B There is a sentence in the second-order language of 
equality that is true in a set iff its cardinality is 2". 
PROOF, 
USING 
CONCEPTS 
FROM ALGEBRA 
AND ANALYSIS. 
Consider first 
the conjunction of the (first-order) axioms for an ordered field, 
further conjoined with the second-order sentence expressing the 
least-upper-bound property (see Example 4 of this section). This 
is a sentence whose models are exactly the isomorphs of the real 
ordered field (i.e., the structures isomorphic to the ordered field 
of real numbers). We now convert the parameters 0, 1, +, -, < to 
variables (individual, function, or predicate as appropriate) which 
we existentially quantify. The resulting sentence has the desired 
properties. 
-I 
There are other cardinal numbers with second-order characteriza- 
tions of this sort; cf. Exercise 2. 

286 
A Mathematical Introduction to Logic 
THEOREM 
41 C The set of Godel numbers of valid second-order sen- 
tences is not definable in 'JZ by any second-order formula. 
Here we assume that Giidel numbers have been assigned to second- 
order expressions in a manner like that used before. Although our proof 
applies to the second-order language of number theory, the theorem is 
true for any recursively numbered language having at least a two-place 
predicate symbol. 
PROOF. Let T 2  be the second-order theory of ';M, i.e., the set of 
second-order sentences true in 9. 
The same argument used to 
prove Tarski's theorem shows that f
l
~
~
 
is not definable in 'T& by 
any second-order formula. 
Now let a! be the conjunction of the members of AE with the 
second-order Peano induction postulate (Example 2). Any model 
of a! is isomorphic to n, cf. Exercise 1. Consequently, for any 
sentence a, 
o E T 2  iff (a -+ a )  is valid. 
Consequently, the set of (Godel numbers of) validities cannot be 
definable lest # T ~  
be. 
-I 
A fortiori, the set of Godel numbers of second-order validities is 
not arithmetical and not recursively enumerable. That is, the enumer- 
ability theorem fails for second-order logic. (In the other direction, 
one can show that this set is not definable in number theory of or- 
der three, or even of order w. But these are topics we will not enter into 
here.) 
It is interesting to compare the effect of a second-order universal 
sentence, such as the Peano induction postulate 
VX(X0 A v y(Xy --, XSy) ' 
v y Xy) 
and the corresponding first-order "schema," i.e., the set of all sentences 
where q~ is a first-order formula having just vl free. If U is a model of 
the Peano induction postulate, then any subset of IUI containing 0' and 
closed under sa is in fact all of IUI. On the other hand, if U is a model of 
the corresponding axiom schema, we can say only that every definable 
subset of IUI containing oa and closed under S' is all of lUI. There 
may well be undefinable subsets for which this fails. (For example, 
take any model U of Th(N; 0, S) having 2-chains. Then U satisfies 
the above first-order schema, but it does not satisfy the second-order 
induction postulate. The set of standard points is simply not definable 
in %.) 
A 

Chapter 4: Second-Order Logic 
287 
Exercises 
1. Show that any structure for the language with parameters V, 0, and 
S that satisfies the sentences 
v x  Sx #O 
(S 1) 
and the Peano induction postulate 
is isomorphic to 'JZs = (N; 0, S). 
2. (a) Give a sentence in the second-order language of equality that is 
true in a set iff its cardinality is KO. 
(b) Do the same for K1. 
3. Let q be a formula in which only the n-place predicate variable X 
occurs free. Say that an n-ary relation R on 
is implicitly dejhed 
in 
by q iff 
satisfies q with an assignment of R to X but does 
not satisfy q with an assignment of any other relation to X. Show 
that fl Th '31, the set of Godel numbers of first-order sentences true 
in '31, is implicitly definable in '31 by a formula without quantified 
predicate or function variables. Suggestion: The idea is to write down 
conditions that the set of true sentences must meet. 
4. Consider a language (with equality) having the one-place predicate 
symbols I and S and the two-place predicate symbol E. Find a 
second-order sentence a such that (i) if A is a set for which A n PA = 
Q ~ ~ ~ ~ ~ I ~ I = A u P A , I ' = A , s ~ = P A , E ~ = { ( ~ , ~ )  
I a ~ b s  
A), then 
is a model of a ; and (ii) every model of a is isomorphic 
to one of the sort described in (i). Remark: Roughly speaking, a 
translates "S = PI ." 
SECTION 4.2 
- 
- 
- 
- 
Skolem Functions 
We want to show how, given any Jirst-order formula, one can find 
a logically equivalent prenex second-order formula of a very special 
form: 
existential quantifiers 
universal individual 
quantifiers 
quan tifier-free formula 

2 88 
A Mathematical Introduction to to@ 
This is a prenex formula wherein all universal quantifiers are indi- 
vidual ones that follow a string of existential individual and function 
quantifiers. 
In the simplest example, observe that 
In the "$" direction this is easy to see. For the "t=" 
direction, consider 
a structure IU and an assignment function s satisfying V x 3 y V(X, y). 
We know that for any a E I%[ there is at least one b E 1311 such that 
We obtain a function f on I%[ by choosing one such b for each a and 
taking f (a) = b. (The axiom of choice is used here.) Then 
This function f is called a Skolemfunction for the formula Vx 3 y q~ in 
the structure IU. 
The same argument applies more generally. As a second example, 
suppose that we begin with the formula 
(We have listed only yl , y2, and y3, but possibly other variables occur 
free in @ as well.) Here we already have the existential quantifier 3 yl 
at the left. What remains is 
This is a special case of the first example (with p(xl, y2) = Vx2 Vx3 
3 y3 @(y1, y2, y3)). It is logically equivalent, as before, to 
Now we have the existential quantifiers 3 yl 3 F2 at the left; what re- 
mains is 
By the same reasoning as before, this is logically equivalent to 
where F3 is a three-place function variable. Thus the original formula 
is equivalent to 
For quantifier-free @, this is in the form we desire. 
SKOLEM NORMAL 
FORM THEOREM For any first-order formula, we can 
find a logically equivalent second-order formula consisting of 

Chapter 4: Second-Order Logic 
2 89 
(a) First a string (possibly empty) of existential individual and 
function quantifiers, followed by 
(b) A string (possibly empty) of universal individual quantifiers, 
followed by 
(c) A quantifier-free formula. 
A formal proof could be given using induction, but the preceding 
example illustrates the general method. 
Recall that a universal (V1) formula is a first-order prenex formula 
all of whose quantifiers are universal: Vxl V x2 
V xk a, where a! is 
quantifier-free. Similarly, an existential (gl) formula is a first-order 
prenex formula all of whose quantifiers are existential. 
COROLLARY 
42A For any first-order p, we can find a universal for- 
mula e in an expanded language containing function symbols, 
such that p is satisfiable iff 8 is satisfiable. 
By applying this corollary to 1 
p, we obtain an existential formula 
(with function symbols) that is valid iff p is valid. 
PROOF. Again we will only illustrate the situation by an example. 
Say that 40 is 
First we replace p by the logically equivalent formula in Skolem 
form: 
Then for 0 we take 
where c, f ,  and g are new function symbols having zero, one, and 
three places, respectively. In general 0 is not logically equivalent 
to 40. But we do have 0 t= 
p (in the expanded language). And 
any model !2.l of p can be expanded (by defining cM, f ', and 
gM correctly) to be a model of 6. Thus p and 8 are "equally 
.satisfiable." 
4 
This result reduces the general problem of testing first-order formulas 
for satisfiability to the special case of universal formulas (with function 
symbols). And by the same token, it reduces the problem of testing 
for validity to the I1 case. From these reductions we can derive an 
undecidability result for first-order logic: 
COROLLARY 
42B Consider a recursively numbered language having 
a two-place predicate symbol and infinitely many k-place function 
symbols for each k 2 0. 

A Mathematical Introduction to Loeic 
(a) The set of Gadel numbers of satisfiable universal (first-order) 
sentences is not recursive. 
(b) The set of GSdel numbers of valid existential (first-order) 
sentences is not recursive. 
PROOF. (b) Given any sentence a we can, by applying Corollary 42A 
to i 
a ,  effectively find an existential sentence that is valid iff a 
is valid. Hence a decision procedure for the existential validities 
would yield a decision procedure for arbitrary validities, in con- 
tradiction to Church's theorem. 
-I 
We can use predicate variables instead of function variables in these 
results, but at a price. Suppose we begin with a first-order formula. 
It is equivalent to a formula @ in Skolem normal form; suppose for 
simplicity that @ = 3 F ip, where ip has only individual quantifiers and 
F is a one-place function variable. We can choose ip in such a way that 
F occurs only in equations of the form u = Ft (for terms t and u not 
containing F). This can be done by replacing, for example, an atomic 
formula a(Ft) by either V x(x = Ft -+ a(x)) or 3 x(x = Ft A a (x)). 
Next observe that a formula 
wherein F occurs only in the form shown, is equivalent to 
If one pursues this question (as we will not do here) one finds that 
any first-order formula is logically equivalent to a second-order formula 
consisting of 
(a) A string of existential predicate quantifiers, followed by 
(b) A string of universal individual quantifiers, followed by 
(c) A string of existential individual quantifiers, followed by 
(d) A quantifier-free formula. 
There are corresponding versions - 
see Exercise 4 -of 
Corollar- 
ies 42A and 42B. The analogue of Corollary 42A reduces the problem 
of testing first-order formulas for satisfiability to the special case of V2 
formulas (with predicate symbols). The problem of testing for validity 
is reduced to the I2 case. 
The analogue of Corollary 42B can be compared with Exercise 10 
in Section 2.6, where it is shown that the set of V2 validities without 
function symbols is decidable. 
Herbrand Expansions 
We have seen (in Corollary 42A) how, given a formula of first-order 
logic, to find an "equally satisfiable" universal formula. And thus 

Chapter 4: Second-Order Logic 
29 1 
(Corollary 42B) the question of satisfiability in first-order logic is 
reducible to the question of satisfiability of universal formulas. 
Now we go one step further: satisfiability of these universal formulas 
is reducible -but 
in a weaker sense - 
to satisfiability in sentential 
logic. 
EXAMPLE. We know that V x 3 y Pxy 
3 y V x Pxy. But pretend 
we did not know this, and that we are interested in determin- 
ing whether or not logic implication holds here. That is equiv- 
alent to determining whether or not the hypothesis Vx 3 y Pxy 
together with the negation of the conclusion i 
3 y V x Pxy is 
unsatisfiable. 
By the Skolem normal form theorem, we can replace these sen- 
tences by certain logically equivalent sentences; we wish to deter- 
mine whether or not 3 F V x PxFx together with 3 G V y 1 
PGyy 
is unsatisfiable. And as in Corollary 42A, we replace these sen- 
tences by equally satisfiable universal sentences; we wish to de- 
termine whether or not the set (Vx Pxfx, VyPgy y) is unsat- 
isfiable (where f and g are new function symbols). 
But this set of universal sentences is satisfiable, and moreover, 
the set can be made to generate its own model. Here is how. For 
the universe of our model we will use the Herbrand universe H, 
which is the set of all terms (in the language with f and g). Thus 
H contains, for each variable u, the terms 
Let A be the set of all instances of the universal sentences, that 
is, the formulas obtained by dropping all the universal quantifiers 
and plugging in (for the universally quantified variables) arbitrary 
terms from the Herbrand universe. Thus A contains, for each 
variable u, the quantifier-free formulas 
Pufu, Pgufgu,. .. , 1 
Pguu, 1 
Pgfufu,. .. . 
Now we consider A from the point of view of sentential logic. 
The sentence symbols are the atomic formulas, e.g., Pgf u f u. 
And in this example A is satisfiable in sentential logic. That is, 
there is a truth assignment v on the set of sentence symbols so 
that G(a) = T for every a! in A. Here is one such v :  
T if tl is shorter than t2 
v(Pt1t2) = F 
if tl is at least as long as t2 
Finally, we use this truth assignment v (in sentential logic) to 
make a structure 4'] (in first-order logic) that will be a model of 
the universal sentences. The universe is the Herbrand universe: 

292 
A Mathematical Introduction to Logic 
H. (There are echos of the completeness proof of Sec- 
tion 2.5 here.) The function symbols are interpreted autony- 
mously - 
as naming themselves: f fj (t) is f t  and gSj (t) is gt . 
Where v comes in is to interpret the predicate symbol P :  
This structure works. First t=' 
V  x PX f x because for every 
term t in the Herbrand universe, (t, ft) E PSj. Secondly 
t=' 
V  y  1 
P g y  y  because for every term t  in the Herbrand uni- 
verse, (gt, t )  4 P'. 
We conclude that the hypothesis V  x  3 y  P x y  together with the 
negated conclusion 1 3 y  V  x  P x y  is indeed satisfiable, and hence 
V x 3 y  P x y  p 3 y v x  Pxy. 
To what extent can we generalize from this example? Assume, for 
simplicity, that the language does not contain equality. (Exercise 7 indi- 
cates the changes needed to accommodate equality.) Suppose we want 
to determine whether or not r t= p for a set r; q of formulas in first- 
order logic. This is equivalent to determining whether or not the set 
r; 7 
p is unsatisfiable. 
We can replace each of the formulas here by a logically equivalent 
formula in Skolem normal form. And as in Corollary 42A, we get an 
equally satisfiable set \I, of universal formulas. (In applying Skolem 
normal form, we use diflerent Skolem function symbols for each for- 
mula, so that there is no clash between formulas.) This brings us to the 
situation: 
r t= p 
\I, is unsatisfiable 
and \I, is a set of universal formulas. 
Let H be the Herbrand universe, that is, the set of all terms in the 
language of \I,. Let A be the set of all instances of the universal formulas 
in \I, (i.e., formulas obtained by dropping all the universal quantifiers and 
plugging in for the universally quantified variables arbitrary terms from 
the Herbrand universe). Then A consists of quantifier-free formulas 
only. We consider A from the viewpoint of sentential logic, where the 
sentence symbols are the atomic formulas. 
Case I: A is unsatisfiable in sentential logic. In this case, we can 
conclude that \I, is unsatisfiable and r t= 
p in first-order logic. This 
is because a universal formula logically implies all of its instances. 
Therefore \I, t== 
S for every S in A (in first-order logic). Any model of \I, 
must be a model of A. But from a model iX of A we can ex tract a truth 
assignment v that satisfies A in sentential logic. (Remember Exercise 3 
in Section 2.4. Note the interesting interplay between first-order logic 
and sentential logic.) 

Chapter 4: Second-Order Logic 
293 
Case 11: A is satisfiable in sentential logic, say by the truth assign- 
ment v. Then we will use v to make a structure fi in which * is satisfiable 
and r 
q because fi will give a counterexample. 
As in the example, the universe 16 1 is the Herbrand universe H, the 
set of all terms in the language of *. And again the function symbols 
are interpreted autonymously : f fi (tl , . . . , t,) = f tl . . t, . To interpret 
a predicate symbol P we use the truth assignment v: 
Then we claim that every formula in \Ir is satisfied in fi by the identity 
function s(x) = x on the variables. First, note that Z(t) = t for any term 
t in H; we had the same situation in step 4 of the completeness proof 
in Section 2.5. Secondly, note that for an atomic formula Ptl . . t,, 
By Exercise 3 of Section 2.4 again, any formula 6 in A is satisfied in Ej 
with s (because $(S) = T). 
Consider any formula in *. It is a universal formula; to simplify the 
notation, say it is V vl V uz 8(vl, w, q ) ,  where 8 is quantifier-free. We 
need to check for any terms tl and t2 in H that kB 88[[, t2, qJ. This 
is equivalent (by the substitution lemma) to saying that the formula 
8(tl, t2, q )  is satisfied in fi by s. But this formula is an instance of 
Vvl Vw8(vl, w, q ) ,  andso 8(tl, t2, q )  isin A. As notedabove, our 
construction was arranged so that every formula in A is satisfied in fi 
with s. This is what we needed. 
We can summarize the result as follows. For simplicity, the result is 
stated only for sentences. 
HERBRAND'S 
THEOREM Consider a set r; q of sentences in a first- 
order language without equality. Let A be as above. Then either 
(case I) A is unsatisfiable in sentential logic and r t= q, or (case 11) 
A is satisfiable in sentential logic and the structure fi constructed 
above is a model of r in which q is false. 
(Herbrand's work was in his 1930 dissertation, completed not long 
before he was killed in a mountain-climbing accident. His statement of 
the theorem was quite different from this one, but the ideas follow his 
work, and 1928 work of Thoralf Skolem.) 
In case I, by the compactness theorem of sentential logic, some finite 
subset of A is unsatisfiable. This fact can be used to obtain a proof of 
the compactness theorem for first-order logic, not relying on Section 
2.5 or the deductive calculus of Section 2.4. 
Moreover, a proof of the enumerability theorem, similarly indepen- 
dent of Sections 2.4 and 2.5, can be extracted from the Herbrand ap- 
proach. Take the special case r = 0. If q~ is valid then as we produce 

294 
A Mathematical Introduction to Logic 
more and more of A, at some point we will have an unsatisfiable set, 
a fact we can recognize by use of truth-tables. If q is not valid, then 
as we produce more and more of A, we are making a structure in 
which q fails, but the structure is infinite and the construction never 
terminates. 
Exercises 
1. Prove the Lowenheim-Skolem theorem in the following improved 
form: Let U be a structure for a countable language. Let S be a 
countable subset of IUI. Then there is a countable substructure 23 of 
U with S 
1231 with the property that for any function s mapping 
the variables into 123 1 and any (first-order) q, 
t=a q[sl iff 
t=b dsl. 
Suggestion: Choose Skolem functions for all formulas. Close Sunder 
the functions. Remark: A substructure 23 with this property is said 
to be an elementary substructure. Note that the propeky implies (by 
taking q to be a sentence) that U = 23. On the one hand, this form 
gives a stronger conclusion than we had in Section 2.6. Not only 
do we get that ThU has some countable model, we get a countable 
submodel. On the other hand, the proof uses the axiom of choice. 
2. Extend the previous exercise to the uncountable case. Assume that U 
is a structure for a language of cardinality A. Let S be a subset of IUI 
having cardinality K .  Show that there is an elementary substructure 
23 of U of cardinality at most K + h with S E 123 1. 
3. Show that Corollary 42B is optimal in the following sense: 
(a) Given any 
sentence a we can effectively decide whether or 
not a is satisfiable. 
(b) Given any V1 sentence a we can effectively decide whether or 
not a is valid. 
4. (a) State the two corollaries (analogous to 42A and 42B) described 
at the end of this section. 
(b) Supply proofs. 
5. Repeat the example given for Herbrand expansions, but for the con- 
verse: 3 y VxPxy t= Vx 3 yPxy. Show that in this case the set A 
is unsatisfiable in sentential logic. 
6. Apply the method of Herbrand expansions to establish the following: 
3x(Px --, VxPx). 
7. Modify the Herbrand expansion construction to accomodate a lan- 
guage with equality. Suggestion: In effect, step 5 of the completeness 
proof in Section 2.5 must be added. Add enough universal sentences 
to assure that {(tl, t2) 1 v (tI = t2) = 9 s  a congruence relation. 

Chapter 4: Second-Order Logic 
295 
SECTION 4.3 
~p 
Many-Sorted Logic 
We now return to first-order languages, but with many sorts of variables, 
ranging over different universes. (In the next section this will be applied 
to the case in which one sort of variable is for elements of a universe, 
another for subsets of that universe, yet another for binary relations, and 
so forth.) 
In informal mathematics one sometimes says things like, "We use 
Greek letters for ordinals, capital script letters for sets of integers, . . . ." 
In effect, one thereby adopts several sorts of variables, each sort having 
its own universe. We now undertake to examine this situation precisely. 
As might be expected, nothing is drastically different from the usual 
one-sorted situation. None of the results of this section are at all deep, 
and most of the proofs are omitted. 
Assume that we have a nonempty set I, whose members are called 
sorts, and symbols arranged as follows: 
A. bgical symbols 
0. Parentheses: (, ). 
1. Sentential connective symbols: 7, 
+. 
2. Variables: For each sort i, there are variables vi , vi, . . . of 
sort i. 
3. Equality symbols: For some i E I there may be the symbol 
=i, said to be a predicate symbol of sort (i, i). 
B. Parameters 
0. Quantifier symbols: For each sort i there is a universal quan- 
tifier symbol Vi . 
1. Predicate symbols: For eachn > 0 andeach n-tuple til, . . . , in) 
of sorts, there is a set (possibly empty) of n-place predicate 
symbols, each of which is said to be of sort (il , . . . , in). 
2. Constant symbols: For each sort i there is a set (possibly 
empty) of constant symbols each of which is said to be of 
sort i. 
3. Function symbols: For each n > 0 and each (n + 1)-tuple 
(il,. . . , in? in+i) of sorts, there is a set (possibly empty) of 
n-place function symbols, each of which is said to be of sort 
(il, a
.
 a in7 in+l). 
As usual, we must assume that these categories of symbols are 
disjoint, and further that no symbol is a finite sequence of other 
symbols. 
Each term will be assigned a unique sort. We define the set of terms 
of sort i inductively,-simultaneously for all i: 

296 
A Mathematical Introduction to Logic 
1. Any variable of sort i or constant symbol of sort i is a term of 
sort i. 
2. If tl, . . . , t, are terms of sort il, . . . , in, respectively, and f is a 
function symbol of sort (il , . . . , in, 
then f tl 
t, is a term of sort 
in+l. 
This definition can be recast into a more familiar form. The set of 
pairs (t , i) such that t is a term of sort i is built up from (i.e., generated 
from) the basic set 
((u:, i) I n 2 1 & i E I) U ((c, i) I c is a constant symbol of sort i) 
by the operations that, for a function symbol f of sort (il , . . . , in, i,+l), 
produce the pair ( f tl . t, , i,+l ) from the pairs (tl , il ) , . . . , (t, , in). 
An atomic formula is a sequence Ptl . t, consisting of a predicate 
symbol of sort (il , . . . , in) and terms tl , . . . , t, of sort il , . . . , in, respec- 
tively. The nonatornic formulas are then formed using the connectives 
1, 
-+ and the quantifiers Vi ui. 
A many-sorted structure U is a function on the set of parameters 
which assigns to each the correct type of object: 
1. To the quantifier symbol Vi , U assigns a nonempty set [%Ii called 
the universe of U of sort i. 
2. To each predicate symbol P of sort (il, . . . ,in), U assigns a 
relation 
3. To each constant symbol c of sort i, U assigns a point ca in [%Ii. 
4. To each function symbol f of sort (il, . . . , in, 
U assigns a 
function 
The definitions of truth and satisfaction are the obvious ones, given 
that Vi is to mean "for all members of the universe 1% I of sort i ." 
In a many-sorted structure, the universes of the various sorts might or 
might not be disjoint. But since we have no equality symbols between 
sorts, any nondisjointness must be regarded as accidental. In partic- 
ular, there will always be an elementarily equivalent structure whose 
universes are disjoint. 
Reduction to One-Sorted Logic 
Many-sorted languages may at times be convenient (as in the following 
section). But there is nothing essential that can be done with them that 
cannot already be done without them. We now proceed to make this 
assertion in a more precise form. 

Chapter 4: Second-Order Logic 
297 
We will consider a one-sorted language having all the predicate, 
constant, and function symbols of our assumed many-sorted language, 
In addition, it will have a one-place predicate symbol Qi for each i in I .  
There is a syntactical translation taking each many-sorted formula (p 
into a one-sorted formula (p*. In this translation all equality symbols are 
replaced by =. The only other change is in the quantifiers (the quantifier 
symbols and the quantified variables): We replace 
where v is a variable chosen not to conflict with the others. Thus the 
quantifiers of sort i are "relativized" to Q;. (The free variables are left 
alone.) 
Turning now to semantics, we can convert a many-sorted structure 
IU into a structure IU* for the above one-sorted language. The universe 
I%* 1 is the union U;,, 
[%Ii of all the universes of U. To Qi is assigned 
the set 
On the predicate and constant symbols, %* agrees with IU. 
For a function symbol f ,  the function f MI is an arbitrary extension of 
fa. (Of course this last sentence does not completely specify f '*. 
The 
results we give for IU* hold for any structure obtained in the manner just 
described.) 
LEMMA 43A A many-sorted sentence a is true in % iff a* is true 
in IU*. 
To prove this, one makes a stronger statement concerning formulas: 
k a  ~ [ s l  * 
kn* ~ * [ s l  
where s(ui) e IIUI;. The stronger statement is then proved by induction. 
Consider now the other direction. A one-sorted structure is not al- 
ways convertible into a many-sorted structure. So we will impose some 
conditions. Let @ be the set consisting of the following one-sorted 
sentences: 
1. 3vQiv,foreachi in I. 
2. V ul . V un(Qryl + . . + 
Qin un + Pin+, 
f ul . a un), for each 
function symbol f of sort (il, . . . , in, in+l). We include the case n = 0, 
in which case the above becomes the sentence Qic for a constant symbol 
c of sorti. 
Notice that the above IU* was a model of @. A one-sorted model 23 
of @ does convert into a many-sorted 23g. The conversion is performed 

298 
A Mathematical Introduction to Logic 
in the natural way: 
lBuli = Q?; 
pgU = pg n (Q: 
x . . . x Q:), 
where P is a predicate symbol 
of sort (il,. . . , in) 
c%fl 
= 
f g" 
f f g  n ( Q I  x . . x Q? x Q:+,), 
the restriction of 
f to Qil x . - . x Q?, where f is a function symbol 
of sort (il, . . . , in, in+l). 
LEMMA 43 B If 2? is a model of @, then 2?g is a many-sorted struc- 
ture. Furthermore, a many-sorted sentence a is true in B* iff a* 
is true in 23. 
The proof is similar to the proof of Lemma 43A. 
Notice that Bu* is not in general equal to 23. (For example, 1% 1 may 
contain points not belonging to any Q? .) On the other hand, a*' is equal 
to a. 
THEOREM 
43C In the many-sorted language 
iff in the one-sorted language 
E *  U @ k a*. 
PROOF. (=J) Assume that C k a and let B be a one-sorted model 
of C* U @ (where C* = (a* I a E C)). Then B* is a model of 
E by Lemma 43B. Hence Bu is a model of a. So by Lemma 43B 
again, 93 is a model of a *. 
(+) 
Similar, with Lemma 43A. 
-I 
By using Theorem 43C, we can now infer the following three theo- 
rems from the corresponding one-sorted results. 
COMPACTNESS 
THEOREM If every finite subset of a set E of many- 
sorted sentences has a model, then C has a model. 
PROOF. Assume that every finite subset Co of C has a many-sorted 
model %. Then a finite subset E$ of C* has the model U;S. Hence 
by the ordinary compactness theorem, C* has a model 23. Bu is 
then a model of C . 
-I 
ENUMERABILITY 
THEOREM For a recursively numbered many-sorted 
language, the set of GGdel numbers of valid sentences is recur- 
sively enumerable. 
PROOF. For a many-sorted a, we have by Theorem 43C, 
/=a iff 
@/=a* 

Chapter 4: Second-Order Logic 
299 
Since @ is recursive, Cn @ is recursively enumerable. And a* 
depends recursively on a ,  so we can apply Exercise 7(b) of Sec- 
tion 3.5. 
-I 
L~WENHEIM--~KOLEM 
THEOREM For any many-sorted structure (for a 
countable language) there is an elementarily equivalent countable 
structure. 
PROOF. Say that the iiven structure is a. Then 'U* is a one-sorted 
model of (Th U)* U@. Hence by the ordinary Lowenheim-Skolem 
theorem, (Th a)* U @ has a countable model '23. 'Bg is a model of 
Th U and so is elementarily equivalent to U. 
-I 
SECTION 4.4 
General Structures 
We now return to the discussion of second-order logic begun in Sec- 
tion 4.1. We discussed there (a) the syntax, i.e., the set of wffs for second 
order, and (b) the semantics, i.e., the concept of structure (which was 
the same as for first order) and the definition of satisfaction and truth. 
In this section we want to leave (a) unchanged, but we want to present 
an alternative to (b). The idea can be stated very briefly: We view the 
language (previously thought of as second-order) now as being a many- 
sorted elementary (i.e., first-order) language. The result is to make open 
to interpretation not only the universe over which individual variables 
range but also the universes for the predicate and function variables. This 
approach is particularly suited to number theory; that case is examined 
briefly at the end of this section. 
The Many-Sorted Language 
Despite the fact that we want ultimately to consider the grammar of Sec- 
tion 4.1, it will be expedient to consider also a many-sorted (first-order) 
language constructed from the second-order language of Section 4.1. 
We take No sorts: the one individual sort (with variables vl, 3, 
. . .); for 
each n > 0, the n-place predicate sort (with variables Xy, X", . . .); and 
for each n > 0, the n-place function sort (with variables F;, Fg, . . .). 
We will use equality (=) only between terms of the individual sort. 
The predicate and function parameters of our assumed second-order 
language will also be parameters of the many-sorted language, and will 
take as arguments terms of the individual sort. (For a function parameter 
f ,  the term f is of the individual sort. The only terms of predicate or 
function sort are the variables of those sorts.) 
In addition, we now use twa new classes of parameters. For each 
n > 0 there is a membership predicate parameter E, which takes as 

300 
A Mathematical Introduction to Logic 
arguments one term of the n-place predicate sort (i.e., a variable Xk) 
and n terms of the individual sort. Thus, for example, 
is a wff. Its intended interpretation is that the triple denoted by (3, 
vl , Q) 
is to belong to the relation denoted by x3. This is exactly the interpre- 
tation assigned previously to the second-order formula 
and, in fact, readers are advised to identify these two formulas closely 
in their minds. 
For each n > 0, there is also the evaluation function parameter En. 
En takes as arguments one term of the n-place function sort (i.e., a 
variable F:) 
and n terms of the individual sort. The resulting term, 
En Fntl . . t,, 
is itself of the individual sort. Again readers are advised to identify 
closely the term E,Fntl . . . t, with the previous F tl . . . t,. 
There is an obvious way of translating between the second-order 
language of Section 4.1 and the present many-sorted language. In one 
direction we stick on the E, and En symbols; in the other direction we 
take them off. The purpose of these symbols is to make the language 
conform to Section 4.3. 
A many-sorted structure has universes for each sort and assigns suit- 
able objects to the various parameters (as described in the preceding 
section). First, we want to show that without loss of generality, we may 
suppose that E, is interpreted as genuine membership and En as genuine 
evaluation. 
THEOREM 
44A Let U be a structure for the above many-sorted lan- 
guage such that the diierent universes of U are disjoint. Then 
there is a homomorphism h of U onto a structure 23 such that 
(a) h is one-to-one, in fact the identity, on the individual uni- 
verse (from which it follows that 
t=2l pis1 iff 
t=23 YJ[h osl 
for each formula 9). 
(b) The n-place predicate universe of '23 consists of certain n- 
ary relations over the individual universe, and (R, a1 , . . . , a,) is 
in E: iff (al, . . . , a,) E R. 
(c) The n-place function universe of 23 consists of certain 
n-place functions on the individual universe, and E:( 
f, a1 , . . . , 
a,) = f (al, . . . , a,). 
PROOF. Since the universes of U are disjoint, we can define h on one 
universe at a time. On the individual universe U, 
h is the identity. 

Chapter 4: Second-Order Logic 
301 
On the universe of the n-place predicate sort, 
h(Q) = ((al, . . . , a,) I each ai is in U and 
M 
(Q,al, .. .,an) isin&,). 
Thus 
( a ,  . . . , a )  E h 
iff 
(Q, al, . . . , an) is in E:. 
(1) 
Similarly, on the universe of the n-place function sort, 
h(g) is the n-place function on U whose value at 
2l 
(al, . . . , a  n )  is En(g,al, . . . , a  d. 
Thus 
For E: we take simply the membership relation, 
(R,al ,..., an)isin&? iff 
( a l ,  
a
)
.
 (3) 
For E: 
we take the evaluation function, 
On the other parameters (inherited from the second-order lan- 
guage) B agrees with IU. 
Then it is clear upon reflection that h is a homomorphism of 
U onto B. That h preserves E, follows from (1) and (3), where in 
(3) we take R = h(Q). Similarly, from (2) and (4) it follows that 
h preserves En. 
Finally, we have to verify the parenthetical remark of part (a). 
This follows from the many-sorted analogue of the homomor- 
phism theorem of Section 2.2, by using the fact that we have 
equality only for the individual sort, where h is one-to-one. 
-I 
By the above theorem, we can restrict attention to structures B in 
which E,, and En are fixed by (b) and (c) of the theorem, But since E: 
and E: 
are determined by the rest of B, we really do not need them 
at all. When we discard them, we have a general pre-structure for our 
second-order grammar. 
General Structures for Second-Order Languages 
These structures provide the alternative semantics mentioned at the be- 
ginning of this section. 
DEFINITION. 
A general pre-structure IU for our second-order lan- 
guage consists of a structure (in the original sense), together with 
the additional sets: 
(a) For each n > 0, an n-place relation universe, which is a 
set of n-ary relations on I%[; 

3 02 
A Mathematical Introduction to Logic 
(b) For each n > 0, an n-place function universe, which is a 
set of functions from IIUIn into 'IIUI. 
IU is a general structure if, in addition, all comprehension sen- 
tences are true in IU. 
The last sentence of the definition requires explanation. First, a com- 
prehension sentence is a sentence obtained as a generalization of a 
comprehension formula (see Example 3 of Section 4.1). Thus it is a 
generalization of 
3 X n v v l  -.- 
vvn(Xnvl...vn o q ) ,  
where Xn does not occur free in q, or a generalization of 
where Fn does not occur free in @. (Here q and @ can have individual 
variables, predicate variables, and function variables.) 
Next we must say what it means for a comprehension sentence (or 
any second-order sentence for that matter) to be tnie in O. Assume then 
that IU is a general pre-structure. Then a sentence a is true in O iff the 
result of converting a into a many-sorted sentence (by adding en and 
En) is true in O, with E, interpreted as membership and En as evaluation. 
More generally, let q be a second-order formula, and let s be a func- 
tion that assigns to each individual variable a member of [MI, to each 
predicate variable a member of the relation universe of O, and to each 
function variable a member of the function universe of IU. Then we say 
that IU satisfies q with s (written 
q[s]) iff the many-sorted version 
of q is satisfied with s in the structure IU, where E, is interpreted as 
membership and En as evaluation. 
The essential consequences of this definition of satisfaction are the 
following, which should be compared with 5 and 6 of page 283. 
~8 Vxn q[s] iff for every R in the n-place relation 
universe of IU, 
q[s (P 
1 R)]. 
kz V Fn q[s] iff for every f in the n-place relPOen f v n r 7 ; o ~  
universe of a ,  ~8 q [ s ( ~ ~  
I f)]. 
This, then, is the alternative approach mentioned at the beginning 
of the section. It involves treating the second-order grammar as being 
a many-sorted first-order grammar in disguise. Because this approach 
is basically first-order, we have. the Lowenheim-Skolem theorem, the 
compactness theorem, and the enumerability theorem. 
LOWENHEIM-SKOLEM THEOREM If the set E of sentences in a count- 
able second-order language has a general model, then it has a 
countable general model. 

Chapter 4: 
Second-Order Logic 
3 03 
Here a countable general model is one in which every universe is 
countable (or equivalently, the union of all the universes is countable). 
PROOF. Let r be the set of comprehension sentences. Then C U r, 
viewed as a set of many-sorted sentences, has a countable many- 
sorted model by the Lijwenheim-Skolem theorem of the pre- 
ceding section. By Theorem 44A, a homomorphic image of that 
model is a general pre-structure satisfying C U r ,  and hence is a 
general model of C . 
-I 
COMPACTNESS 
THEOREM If every finite subset of a set C of second- 
order sentences has a general model, then C has a general model. 
PROOF. The proof is exactly as above. Every finite subset of E U r 
has a many-sorted model, so we can apply the compactness the- 
orem of the preceding section. 
-I 
ENUMERABILITY 
THEOREM Assume that the language is recursively 
numbered. Then the set of Godel numbers of second-order 
sentences that are true in every general structure is recursively 
enumerable. 
PROOF. A sentence a is true in every general structure iff it is a 
many-sorted consequence of r. And gr is recursive. 
-I 
The above two theorems assure us that there is an acceptable deduc- 
tive calculus such that t is deducible from C iff t is true in every general 
model of C (see the remarks at the beginning of Section 2.4). But now 
that we know there is such a complete deductive calculus, there is no 
compelling reason to go into the detailed development of one. 
We can compare the two approaches to second-order semantics as 
follows: The version of Section 4.1 (which we will now call absolute 
second-order logic) is a hybrid creature, in which the meaning of the 
parameters is left open to interpretation by structures, but the concept of 
being (for example) a subset is not left open, but is treated as having a 
fixed meaning. The version of the present section (general second-order 
logic) avoids appealing to a fixed notion of subset, and consequently is 
reducible to first-order logic. In this respect it is like axiomatic set theory, 
where one speaks of sets and sets of sets and so forth, but the theory is 
a first-order theory. 
By enlarging the class of structures, general second-order logic di- 
minishes the cases in which logical implication holds. That is, if every 
general model of E is a general model of a ,  it then follows that C /= a 
in absolute second-order logic. But the converse fails. For example, 
take C = 0: The set of sentences true in all general models is a recur- 
sively enumerable subset of the nonarithmetical set of valid sentences 
of absolute second-order logic. 

304 
A Mathematical Introduction to Logic 
Models of Analysis 
We can illustrate the ideas of this section by focusing attention on the 
most interesting special case: general models of second-order number 
theory. Consider then the second-order language for number theory, with 
the parameters 0, S, <, -, and E. We take as our set of axioms the set A; 
obtained from AE by adding as a twelfth member the Peano induction 
postulate (Example 2, Section 4.1). From Exercise 1 of Section 4.1, we 
can conclude that any model (in the semantics of that section) of A; is 
isomorphic to rt. 
But what of the general models of our axiom set? They can differ 
from 'Dl in either (or both) of two ways. We can employ the compact- 
ness theorem as before to construct (nonstandard) general models of the 
axioms having infinite numbers (i.e., models U with an element larger 
than the denotation of SnO in the ordering <'). We can also find (non- 
absolute) general models in which, for example, the set universe (the 
unary relation universe) is less than the full power set of the individual 
universe. Indeed, any countable general model must be of this kind. 
It is traditional for logicians to refer to second-order number theory 
as analysis. The name derives from the fact that it is possible to identify 
real numbers with sets of natural numbers. In second-order number 
theory we have quantifiers over sets of natural numbers, which we can 
view as quantifiers over real numbers. The appropriateness of the name 
is nevertheless open to question, but its usage is well established. By 
a mdel of analysis we will mean a general model of the above axiom 
set A;. 
Define an w-model of analysis to be a model of analysis in which 
the individual universe is N and the denotations of 0 and S are the 
genuine 0 and S. (Consequently, the denotations of <, +, *, and E are 
also standard.) The motivation for studying w-models can be stated as 
follows: We have a clear understanding - 
or so we think -of 
the set N. 
But we do not have anything like the same understanding of its power 
set PN. For example, we may be uncertain whether its cardinality is HI 
or H2 or more. So it is reasonable to hold fixed that which we are sure 
of (N), but to leave open to interpretation by a structure that which we 
are not sure of (PN). 
Among the w-models of analysis there is the one absolute model, 
whose n-place relation universe consists of all n-ary relations on N (and 
whose function universes consist of all possible functions). A first-order 
sentence is true in an arbitrary w-model of analysis iff it is true in 'Dl. 
But the w-model may disagree with the absolute model on second-order 
sentences. 
In the next theorem we assert that an w-model of analysis is com- 
pletely determined by its set universe (i.e., its one-place relation uni- 
verse). 

Chapter 4: Second-Order Logic 
3 05 
THEOREM 
44B If and '23 are w-models of analysis having the same 
one-place relation universe, then O = '23. 
PROOF. Suppose R belongs to the three-place relation universe of 
O. Let (R) be the "compression" of R into a unary relation: 
(R) = ((a, 6, c) I (a, b, c) E R). 
Our sequence-encoding function is recursive and hence is first- 
order definable in number theory by a formula q. (R) is in the set 
universe of 
by virtue of the comprehension sentence 
Thus (R) is in the set universe of '23; we unpack it by a similar 
argument. R is in the three-place relation universe of B by virtue 
of the comprehension sentence 
A similar argument applies to the function universes. 
Consequently, we can identify an w-model of analysis with its set 
universe (which is included in PN). Not every subclass of PN is then 
an w-model of analysis, but only those for which the comprehension 
sentences are satisfied. 
EXAMPLES OF W-MODELS. We need only specify the set universe. 
1. PN is the absolute model. 
2. Let (A; E ~ )  
be a model of the usual axioms for set theory 
such that (i) the relation EA is the genuine membership relation 
{(a, b) I a E A, b E A, and a E b) on the universe A, and 
(ii) A is transitive, i.e., if a E b E A, then a E A. Then the 
collection of all those subsets of N that belong to A is an o-model 
of analysis. 
3. For a class A 
PN, define IDA to be the class of all sets 
B G N which are definable in the w pre-structure with set uni- 
verse A by a formula of the language of second-order number 
theory, augmented by parameters for each set in A. Then define 
by transfinite recursion on the ordinals: 
4% = 0, 
& + 1 =  
ID&, 
A, = U,,, 
& for limit A. 
By cardinality considerations we see that this stops growing 
at some ordinal #3 for which 
= A@. Let Po be the least 

306 ' 
A Mathematical Introduction to Logic 
such /I; 
it can be shown (from the Lowenheim-Skolem theorem) 
that Po is a countable ordinal. Ah coincides with U, 
(the 
union being over all ordinals a) and is called the class of rarni- 
fied analytical sets. It is an w-model of analysis; the truth of the 
comprehension sentences follows from the fact that IDAh G Ah. 

Suggestions for Further 
Reading 
Jon Barwise (editor). Handbook of Mathematical Logic. North-Holland 
Publishing Company, Amsterdam, 1978. This "handbook" collects 
3 1 expository articles on model theory, set theory, recursion theory, 
and proof theory, written by experts. 
Jon Barwise and John Etchemendy. The Language of First-Order Logic. 
Center for the Study of Language and Information, Stanford, 1992. 
This introductory textbook comes with a disk for the Tarski's World 
software package. The s k e  authors have produced the Turing's 
World and Hyperproof software packages. 
J. L. Bell and M. Machover. A Course in Mathematical Logic. North- 
Holland Publishing Company, Amsterdam, 1977. 
George Boolos and Richard Jeffrey. Computability and Logic. 
Cambridge University Press, Cambridge, 1974 (third edition 1989). 
This textbook gives a lively treatment of some of topics in the present 
book, addressed to a different audience. 
C. C. Chang and H. J. Keisler. Model Theory. North-Holland Publishing 
Company, Amsterdam, 1973 (third edition 1990). This remains the 
classic book on model theory. 
Herbert B. Enderton. Elements of Set Theory. Academic Press, New 
York, 1977. This is the author's favorite book on set theory. 
Wilfrid Hodges. A Shorter Model Theory. Cambridge University Press, 
Cambridge, 1997. This is a shorter version of his Model Theory, 
published in 1993. 
Hartley Rogers. Theory of Recursive Functions and Eflective Com- 
putability. McGraw-Hill Book Company, New York, 1967. This book 
is still the standard work in its field. 
Joseph R. Shoenfield. Mathematical Logic. Association for Symbolic 
Logic and A K Peters, Natick, Massachusetts, 2000. First published 
by Addison-Wesley in 1967, the book gives a compact graduate-level 
treatment. 

308 
A Mathematical Introduction to Logic 
Jean van Heijenoort (editor). From Frege to GGdel: A Source Book 
in Mathematical bgic, 1879-1 931. Harvard University Press, 
Cambridge, Massachusetts, 1967. This is a collection of 46 fun- 
damental papers in logic, translated into English and supplied with 
commentaries. 

List of Svmbols 
The numbers indicate the pages on which the symbol first 
occurs. 
-1 
1 
==+ 
1 
+= 
1 
+ 
1 
. , 
1 
F 
1 
E 
1 
f - 
- 
1 
A; t 
2 
0 
2 
{ x ~ ~ * * * , x n }  
2 
(x I -x-I 
2 
N 
2 
Z 
2 
C - 
P 
2 
u 
3 
n 
3 
U 
3 
n 
3 
( X I ,  ..., x,,) 3,4 
A x B  
4 
dom R 
4 
ran R 
4 
fld R 
4 
An 
4 
F : A + B  
5 
f o g  
5,180 
R 
5 
[ X I  
6 
A - B  
8 
card A 
8 
1
5
 
8 
KO 
9 
1 
11 
+ 
11 
A 
11 
v 
12 
0 
14 
E 
17 
2
F
 
20 
T 
20 
T 
20 
+ 
23 
+=I 
24 
IJ 
32 
C* 
35 
c, 
35 
h 
38 
# 
45 
B,n 
46 
L 
T 
3. 
1 + 
* 
V 
3 
Y n  = 
< 
0 
S + 
- 
E 
Ff 
Q, 
# < 
IUI 
sn 
+a ~ [ s l  
S 
s(x 1 d )  
I= 

31 0 
List of Symbols 
I=+ 
Mod 
EC 
ECA 
I=% 
vlla1i.. . i an1 
Q 
UZB 
% = B  
Q n  
3, 
3! 
A 
l- 
ded 
RAA 
EI 
An 
Th 
Cn 
AZF 
AST 
v(t1, ... , t n )  
ns 
RB 
nV'[T] 
vR 
* A  
h 
Psb 
En 
nn 
An 
Tm 
U 
llellm 
K 
we 
T4 
261 
- 
262 
Prb 
266 
Cons 
267 
PA 
269 
ST 
2 70 
A M  
2 76 
xr 
282 
q' 
282 
Qi 
297 
%* 
297 
Bn 
297 
@ 
297 
En 
299 
En 
300 
I=: 
v[sl 
302 
(R) 
305 
DA 
305 

Index 
Abbreviations, 1 
Absolute model, 304,305 
Absolute second-order logic, 
303 
Adjoining, 2 
Algebraically closed fields, 
158-159 
Algebraic numbers, 10 
Algorithm, 61 
Alphabetic variants, 126-1 27 
Analysis, models of, 304-306 
Analysis, nonstandard. See 
Nonstandard analysis 
Arithmetic. See Number 
theory 
Arithmetical hierarchy, 
242-245 
Arithmetical relations, 100, 
242 
Arithmetization of syntax, 
224-234 
Asser, Giinter, 101 
Atomic formulas, 74-75,83 
Automorphism, 98-99 
Axiomatizable theory, 
156-1 57 
Axioms, logical. See Logical 
axioms 
Berkeley, George, 173 
Biconditional symbol, 14 
Binary connectives, 51 
Bolzano-Weierstrass 
theorem, 1 8 1 
Boolean algebra, 20 
Boolean functions, 45-52 
Bounded quantifiers, 204, 
21cL211 
Bound variables, 80 
Bridge circuit, 57 
Circuits, switching, 54-59 
Closed, 5,18,35,lll 
Compactness theorem 
history of, 145 
in first-order logic, 109, 
142,293 
in many-sorted logic, 298 
in second-order logic, 285, 
303 
in sentential logic, 24, 
59-60 
Completeness theorem, 66, 
Calculus, deductive. b e  
135-145 
Deductive calculus 
Complete sets of connectives, 
Cantor, Georg, 8 
49 
Cantor's theorem, 159,163 
Complete theory, 156 
Capital asterisk operation, 223 
Composition, 5, 215-216 
Cardinal arithmetic theorem, 
Comprehension formulas, 
9-10 
284 
Cardinality of languages, 141 
Computability approach to 
Cardinality of structures, 
incompleteness, 184, 
153-154,157 
187,257-258 
Cardinal numbers, 8-10 
Computable, 65,208-209 
Carroll, Lewis, 162 
Computable functions, 
Cartesian product, 4 
209-210,25&25 1 
Categorical sets, 154, 157 
See also Recursive 
Categoricity in power, 157 
functions 
Chain, 7 
Computably enumerable 
Chain rule, 180 
(c.e.), 238 
Characteristic function, 217 
Computing agents, idealized, 
Chinese remainder theorem, 
208,261-263 
91,279 
Concatenation function, 
Church's theorem, 145, 
222-223 
164,238 
Conditional sentence, 21 
Church's thesis, 185, 187, 
Conditional symbol, 14 
206-2 10,233-234,240, 
Congruence relation, 140 
247 
Conjunction symbol, 14 

312 
Index 
Conjunctive normal form 
(CNF), 53 
Connectives. See Sentential 
connectives 
Consequences, set of, 155 
Consequent, 1 13 
Consistent sets, 1 19, 135 
Constants, generalization on, 
123-124 
Constant symbols, 70,79 
Construction sequences, 
17-1 8,35-37,111 
Contraposition, 27, 1 19, 121 
Convergence, 178-1 80 
Countable language, 135, 
145,151-153 
Countable sets, 6 
C++, 13 
Craig's theorem, 163 
DiAlembert, Jean, 173 
Decidable sets, 62-63, 
144,185 
See also Church's thesis 
Decidable theory, 144,157 
See also Undecidability 
Decoding function, 220 
Deducible formulas, 11 1 
Deductions, 66,110-1 12 
Deduction theorem, 
118-120 
Deductive calculus, 66,109 
alphabetic variants, 
126-127 
equality, 127-1 28 
formal deductions, 
110-112 
metatheorems and, 
116-120 
strategy, 120-1 26 
substitution, 112-1 14 
tautologies, 1 14-1 16 
Definability 
in a structure, 90-92 
of a class of structures, 
92-94 
Definable element, 91 
Definable relations, 90-92, 
98,287 
from points, 103 
Defined function symbols, 
164-166,169,172 
Definition by recursion, 
38-44 
Delay of circuit, 56 
De Morgan's laws, 27,49 
Dense order, 159 
Depth of circuit, 56 
Derivability conditions, 267 
Descriptions. See Defined 
function symbols 
Diagonal function, 264 
Diagonalization approach to 
incompleteness, 184, 
186-1 87,245-246 
Directed graphs (digraphs), 
82.93 
Disjoint set, 3 
Disjunction symbol, 14 
Disjunctive normal form 
DM), 49 
Divisibility, 21 8 
Domain 
of relation, 4 
of structure, 81 
Dominance, 8-9 
Donkey sentences, 80 
Double negation, 89 
Dovetailing, 64 
Duality, 28 
Effective computability, 65 
See also Recursive 
functions 
Effective enumerability, 
63-66 
See also Recursively 
enumerable relations 
Effective procedures, 6145 
See also Church's thesis 
Elementarily closed (ECL), 
104 
Elementary class (EC, ECa), 
92-93 
Elementary equivalence, 97 
Elementary substructure, 294 
Elementary type, 104 
Eliminable definition, 172 
Elimination of quantifiers, 
190-192 
Entscheidungsproblem, 164 
Enumerability theorem, 109, 
142-143,145,293 
in many-sorted logic, 298 
in second-order logic, 286, 
303 
Equality, 1-2.127-128 
language of, 246,285 
Equality symbol, 70 
Equinumerous, 8 
Equivalence classes and 
relations, 6, 189 
Euler, Leonhard, 5,173 
Evaluation function 
parameter, 300 
Eventually periodic set, 201 
Excluded middle, 27 
Exclusive disjunction, 5 1 
Existential formula (31). 102, 
205 
Existential instantiation (rule 
EI), 124-125.145 
Existential quantifiers, 67.87, 
287,288 
Exponential growth, 26 
Exponentiation, 
representation of, 
276-281 
Exportation, 27 
Expressions, 15-16,73-74 
Extension, 95 
Extensionality, principle of, 2 
Faithful interpretations, 
171-172 
Falsity, 20 
Field (of relation), 4 
Fields, 87,92,93-94,285 
real-closed, 104 
theory of, 155-156, 
158-159 
See also Algebraically 
closed fields 
Finite graphs, 93 
Finite language, 142 
Finitely axiomatizable 
theories, 156 
Finitely valid, 147 
Finite model property, 163 
Finite models, 147-15 1 

l ndex 
313 
Finite sequence (string), 4 
Finite set, 6 
First-order language, 67-72, 
167 
examples of, 7&73 
formulas, 73-76 
free variables, 76-77 
notation, 77-79 
First-order logic 
completeness theorem, 
135-145 
deductive calculus, 
1@9-129 
interpretations between 
theories, 164-172 
language of, 69-79 
models of theories, 
147-162 
parsing algorithm, 
105-108 
soundness theorem, 
131-135 
translation methods, 6849 
truth and models, 8&99 
Fischer, Michael, 201 
Fixed-point lemma, 234-235 
Formal languages, 1 1- 13 
computer, 13 
features in, 1 1-1 3 
sentential logic and, 13-19 
Formula-building operations, 
17,75 
Formulas 
atomic, 74-75, 83 
comprehension, 284 
generalization of, 1 16 
satisfaction of, 83-86 
unique readability of, 
4041,108 
well-formed (wffs), 12, 
17-18,75 
Freely generated sets, 39-40 
See also Unique readability 
theorem 
Free variables, 76-77 
Frege, Gottlob, 152 
Function comprehension 
formulas, 284 
Functions, 5 
defining, 164- 166 
recursive, 247-263 
representable, 2 12-2 17 
Skolem, 145,287-290 
Function symbols, 70, 
79,128 
Function universe, 302 
Function variables, 282 
Generalization 
on constants, 123- 124 
of formulas, 1 12 
Generalization theorem, 
117-118 
General pre-structure, 301 
General second-order logic, 
303 
General structures, 
299-306 
Generated sets, 37 
freely, 39 
Godel, Kurt, 145,152 
B-function, 278-279,281 
completeness theorem, 
135-145 
incompleteness theorem, 
145,236,256,257-258 
numbers, 91, 184, 
225-234.286 
second incompleteness 
theorem, 266-270, 
274-275 
Goldbach's conjecture, 263 
Graphs, 92 
connected, 146 
directed, 82,93 
finite, 93 
of function, 209 
Groups, 38,92 
Halting problem, 
unsolvability of, 254 
Henkin, Leon, 145 
Herbrand expansions, 
290-294 
Herbrand, Jacques, 293 
Herbrand's theorem, 293 
Herbrand universe, 29 1 
Heterological, 186 
Hilbert, David, 152 
Homomorphisms, 94-99 
Homomorphism theorem, 
96-97 
Hyperreal numbers. See 
Nonstandard analysis 
Hypothesis, 23.67, 109,213 
Identity function, 5 
Identity interpretation, 168 
Iff, use of, 1 
Implicant, 59 
Implicitly definable relations, 
287 
Incompleteness theorem 
(Godel) 
first, 145,236,256, 
257-258 
second, 266-270,274-275 
undecidability and, 
234-245 
Inconsistent sets, 1 19 
Inconsistent sets. See 
Consistent sets 
Independent axiomatizations, 
28 
Index 
of recursively enumerable 
set, 255 
of recursive partial 
function, 253 
Individual variables, 282-283 
Induction, 30.34-38 
principle, 1 8-1 9,37,44, 
111-112 
Inductive sets, 35 
Induction axiom. See Peano 
induction postulate 
Infinitely close, 177 
Infinitesimal, 176 
Initial segment, 4 
Input/output format, 62,209 
Instances, 29 1 
Integers, 2 
Interpolation theorem, 53 
Interpretations, 80 
between theories, 
164-172,273 
Intersection, 3 
Isomorphic embedding, 94 
Isomorphic structures, 94 
Isomorphism, 94 

314 
1 ndex 
Kleene normal form, 
249-250,252-254,257 
Kleene's theorem, 64,239 
Lagrange's theorem, 166 
Languages 
many-sorted, 299-30 1 
of equality, 285 
See also First-order 
languages, Formal 
languages, Second-order 
logic 
Least-zero operator, 21 6, 
220-221 
Leibniz, G. W. v., 173 
Length, 22 1 
Lindenbaum's theorem, 246 
Linear connectives, 52 
Linear transformations, 99 
Literal, 59 
Liib's theorem, 269 
Logical axioms, 1 10,112, 
125 
recursiveness of, 232 
validity of, 131-134 
Logical implication, 88-99 
Logically equivalence, 88 
Logical symbols, 14, 
69-70 
Log-Vaught test, 157-160, 
190 
Lowenheim, Leopold, 15 1 
Liiwenheim-~kolem 
theorem, 103, 15 1-155, 
190 
in many-sorted logic, 299 
in second-order logic, 285, 
302-303 
LST theorem, 154 
Eukasiewicz, Jan, 33 
See also Polish notation 
Majority connective, 45 
MalEev, Anatolii, 145 
Many-one reducibility, 256 
Many-sorted logic, 295-299 
application to second-order 
logic, 299-301 
Many-valued logic, 20 
Map, 5 
Map coloring, 65, 146 
Material conditional, 21 
Membership predicate, 
299-300 
Meta-language, 89, 129 
Metamathematics, use of 
term, 69 
Metatheorems, 1 16-1 20 
Models, 80-99 
of analysis, 304-306 
of theories, 147-162 
Modus ponens, 66.1 10-1 1 1, 
116 
Monotone connectives, 54 
Monotone recursion, 224 
p-operator, 21 6,220-221 
Nand, 5 1 
Natural numbers, 2 
See also Number theory 
Negation symbol, 14.17 
Newton, Isaac, 173 
Nonlogical symbols, 14 
Nonprime formulas, 1 14 
Nonstandard analysis, 
173-181 
algebraic properties, 
176-178 
construction of hypeneals, 
173-176 
convergence in, 178-1 80 
Nonstandard models, 
152-153,183,304 
Normal form theorem, 
for recursive functions, 
252-253 
Skolem, 288-289 
Notation, 77-79 
NP, 26,101 
Number theory, 182 
language of, 70,72,182 
with addition, 196-1 97, 
280 
with exponentiation, 
202-205,280 
with multiplication, 
276-28 1 
with ordering, 193-196, 
280 
with successor, 187-193, 
280 
Numerals, 183-1 84,209 
Numeralwise determined 
formulas, 206, 
210-212 
Object language, 89 
Occur free, 76-77 
wcompleteness, 223 
wconsistency, 24 1,245 
wmo&ls of analysis, 
304-306 
One-sorted logic, 296-299 
One-to-one functions, 5 
Onto, 5 
Operating system, 253 
Operations, 5 
Ordered n -tuples, 3-4 
Ordered pairs, 3,4 
Ordering relations, 6,93,159, 
284 
Pairing function, 220, 
277-278 
Pairwise disjoint set, 3 
Parameters, 14,70 
Parameter theorem, 258-260, 
264 
Parentheses, use of, 33,78 
Parity connective, 53 
Parsing algorithm 
in first-order logic, 
105-1 08 
in sentential logic, 29-33 
Parsing formulas, 29-33, 
107-108 
Parsing terms, 106107 
Partial functions, 250 
Partial recursive functions. 
See Recursive functions, 
partial 
Partition, 6 

Index 
Peano arithmetic (PA), 
269-270 
Peano induction postulate, 
193,284,286-287 
Periodic set, 201 
Permutation, 100 
Polish notation, 32-33,74 
Polynomial-time decidable, 
26,115 
Post, Emil, 47, 152,261 
Power set, 2-3 
Predicate calculus. See 
First-order logic 
Predicate symbols, 70.79, 
128 
Predicate variables, 282 
Prenex formulas, 160 
Prenex normal form, 160-1 61 
Presburger's theorem, 
' 
197-198 
Prime formulas, 1 14-1 15 
Prime implicants, 59 
Prime n u m b ,  9 1,184, 
218-219 
Primitive recursion, 22 1-222, 
227 
Principia Mathematics 
(Whitehead and 
Russell), 152 
Proof, nature of, 109 
See also Deductive 
calculus 
Propositional logic, 14 
Proposition symbol, 14-15 
Quantifier capture, 1 13 
Quantifiers, 70 
bounded, 204,2 10-211 
elimination of, 190-192 
existential, 287,288 
Quantifier symbol, universal, 
80 
Quotient structure, 140 
Rabin, Michael, 20 1 
Ramified analytical sets, 306 
Range (of relation), 4 
Reasonable language, 
142-1 44 
See also Recursively 
numbered language 
Recursion, 32,3844 
monotone, 224 
primitive, 221-222.227 
Recursion theorem, 39-40, 
4142 
Recursive functions, 247-250 
normal form, 248-250 
partial, 250-258,262 
reduction of decision 
problems, 258-260 
register machines, 261-263 
Recursively axiomatizable 
theories, 233,240 
Recursively enumerable 
(r.e.) relations, 233, 
23 8-24 1 
Recursively inseparable sets. 
245 
Recursively numbered 
language, 225 
Recursive relations, 207-2 10, 
232 
See also Recursively 
enumerable relations 
Reductio ad absurdum, 1 19, 
121 
Reducts of number theory, 
182-1 83,193-202 
Reflexive relations, 5 
Register machines, 208, 
261-263 
Relation comprehension 
formulas, 284 
Relations, 4 4  
Relation universe, 301 
Relay circuits, 57 
Representable functions, 
212-217 
Representable relations, 
205-206 
and numeralwise 
det&ned 
formulas, 
206,210-212 
weakly, 24 1-242 
Re-replacement lemma, 130 
Resolution, 53 
Restriction. 5,221 
Rice's theorem, 260 
Rigid structure, 98 
Robinson, Abraham, 173 
Root of tree, 7 
Rule EI, 124-125, 145 
Rules of inference, 1 10 
Rule T, 1 18 
Satisfaction of formulas, 23, 
83-86 
Satisfiable sets, 5940.134 
Schema, 286 
Schriider-Bemstein theorem, 
9 
Second-order logic 
absolute, 303 
and many-sorted logic, 
295-299 
general structures, 
299-306 
language of, 282-286 
Skolem functions, 145, 
287-290 
Segments of sequences, 4 
initial, 4 
terminal, 105-106 
Self-reference, 234-235, 3 15 
approach to 
incompleteness, 
184-186 
Semantics and syntax, 125 
Semidecidable set, 63 
Semidecision procedure, 63 
Sentences, 77.79 
Sentence symbols, 14, 115 
Sentential connectives, 14, 
45-54 
binary, 5 1 
ternary, 5 1-5 2 
unary, 5 1 
0-ary, 50 
Sentential logic 
compactness, 24,5940 
connectives, 45-52 
language of, 13-1 9 
parsing algorithm, 29-33 
tautologies, 23 
truth assignments, 20-27 
Sequence encoding and 
decoding, 220,277,281 
Sequence number, 22 1 
Sequences, finite, 4 

Index 
Sets 
concept, 1-2 
countable, 6 
disjoint, 3 
empty versus nonempty, 2 
finite, 6 
intersection of, 3 
ordered, 93 
painvise disjoint, 3 
power, 2-3 
union of, 3 
Set theory (ST) 152, 157, 
161-162,240-241, 
270-275 
Godel incompleteness 
theorems for, 274-275 
language of, 70,7 1 
Sheffer stroke, 5 1 
Shepherdson, John C., 261 
Shepherdson-Sturgis 
machines, 261-263 
Simplification of formulas, 59 
Single-valued relations, 5 
Skolem, Thoralf, 145.15 1, 
293 
functions, 145,287-290 
Lowenheirn-Skolem 
theorem, 151-155 
normal form, 288-289 
paradox, 152 
S-m-n 
theorem. See 
Parameter theorem 
Soundness theorem, 66, 13 1 
Spectrum, 101,150,285 
Standard part, 178 
Steinitz's theorem, 158-1 59 
Strategy for deductions, 
120-126 
String, 4 
Strong undecidability, 237, 
272-273 
Structures, 80-8 1 
cardinality of, 153-154 
definability in, 90-92 
definability of a class of, 
92-94 
general, 299-306 
Sturgis, H. E., 261 
Subsets, 2 
Substitutability, 1 13 
Substitution, 28, 1 12-1 14 
and alphabetic variants, 
126 
lemma, 133-1 34 
of terms, 1 12,129 
representability of, 228 
Substructures, 95-96.294 
Sufficiently strong theory, 
246,267 
Switching circuits, 54-59 
Symbols 
logical, 14,69-70 
nonlogical, 14 
parameter, 7 1 
sentential connective, 14, 
45-54 
Symmetric relations, 5 
Syntactical translation, 
169-172 
Syntax, arithmetization of, 
224-234 
Syntax and semantics, 125 
Tarski, Alfred, 152, 154, 159, 
286 
undefinability theorem, 
236,240 
Tautological equivalence, 24 
Tautological implication, 23 
Tautologies, 23 
in first-order languages, 
114-1 16 
representability of, 
230-23 1 
selected list of, 26-27 
Term-building operations, 74 
Terminal segment, 105-106 
Terms, 74.79 
parsing, 106-107 
representing, 226-227 
unique readability of, 107 
Ternary connectives, 5 1-52 
Theorem, concept of, 
110-111,117 
Theories, 155-160 
axiomatizable, 156 
finitely axiomatizable, 156 
interpretations between, 
164-172 
models of, 147-1 62 
of structures, 148, 152, 155 
Total function, 250 
T -predicate, 249 
Trakhtenbrot's theorem, 15 1 
Transitive relations, 5 
Trees, 7 
of deduction, 1 16-1 17 
of well-formed formulas, 
17,22,75 
Trichotomy, 6,93,159,194 
Truth, 20 
undefinability of, 236,240 
Truth and models, in 
first-order logic, 80-99 
Truth assignments, 20-27 
Truth tables, 24-26 
Truth values, 20 
Turing, Alan, 208,261 
Turing machine, 208 
Two-valued logic, 20 
'Qchonoff's theorem, 24 
Ultraproducts, 142 
Unary connectives, 5 1 
Uncountable languages, 141, 
153-154 
Undecidability 
incompleteness and, 
234-235 
of number theory, 1 82- 187 
of set theory, 272 
strong, 237,272-273 
Undefinability theorem, 
Tarski, 236,240 
Union, 3 
Unique existential quantifier, 
102,165 
Unique readability theorem 
for formulas, 108 
for terms, 107 
in sentential logic, 4041 
Universal formulas (VI), 102 
Universal quantifier symbol, 
68,70,80 
Universe, of structures, 81 
Unsolvability of halting 
problem, 254 
Valid formula, 88-89 
in second-order logic, 286 

Index 
317 
Variables, 70.79 
bound, 80 
free, 76-77 
function, 282 
individual, 282-283 
predicate, 282 
Vaught's test, See 
hLVaught test 
Vector spaces, 92,99 
Weakly representabilit~. 
Z-chains, 189-1 90, 197 
24 1-242 
Zermel-Fraenkel 
set theory, 
Well-defined function, 165 
157,270 
Well-formed formulas (wffs), 
0-ary connectives, 50 
12,17-18,75 
0-place function symbols, 70 
Well-ordering, 283 
Zorn's lemma, 7,60, 14 1 

