
The Art and Science of
Military Deception

For a listing of recent titles in the 
Artech House Intelligence and Information Operations Series, 
turn to the back of this book.

The Art and Science of
Military Deception
Hy Rothstein
Barton Whaley
Editors

Library of Congress Cataloging-in-Publication Data
A catalog record for this book is available from the U.S. Library of Congress.
British Library Cataloguing in Publication Data
A catalog record for this book is available from the British Library.
ISBN-13:  978-1-60807-551-5
Cover design by Vicki Kane
© 2013 Artech House
The two cover photos represent efforts to camouflage the Lockheed Burbank Aircraft Plant 
during World War II. The top photo is the airfield before being camouflaged. The second 
photo shows the plant after camouflage. The goal was to keep it from being found from the 
air and bombed.
All rights reserved. Printed and bound in the United States of America. No part of this 
book may be reproduced or utilized in any form or by any means, electronic or mechani­
cal, including photocopying, recording, or by any information storage and retrieval system, 
without permission in writing from the publisher.
All terms mentioned in this book that are known to be trademarks or service marks have 
been appropriately capitalized. Artech House cannot attest to the accuracy of this infor­
mation. Use of a term in this book should not be regarded as affecting the validity of any 
trademark or service mark.
10 9 8 7 6 5 4 3 2 1

To the United States Special Operations Forces: for your courage, patience and 
persistence in defending people against threats to their liberty and happiness and for 
pursuing justice, anywhere and anytime, we humbly dedicate this book to you.
All royalties for this book will go to the Special Operations Warrior Foundation 
which provides college scholarships for the surviving children of fallen Special Op­
erations Forces, family services and educational counseling and support to wounded 
Special Operations warriors.
In Memoriam
Dr. Bart Whaley
Consummate gentleman, scholar, and the last great master of stratagem


vii
Contents
Acknowledgments 
xvii
Introduction 
xix
 CHAPTER 1 
Beware of the Dog 
1
Section I: The Ethics of Political-Military Deception 
9
 CHAPTER 2 
Intelligence Ethics 
11
Section II: Principles and Other Fundamentals 
19
Introduction	
19
The Structure of Deception	
19
 CHAPTER 3 
On Simulation and Dissimulation 
21
 CHAPTER 4 
The 8 Principles of Security and the 8 Principles of Deception 
23
The Principles of Security	
23
The Principles of Deception	
23
 CHAPTER 5  
Ruses and Stratagems of War 
25
Ruses and Stratagems of War	
25
 CHAPTER 6  
The Problem of Deception 
29
The Problem of Deception	
29
The Infrequency and Neglect of Deception	
29
Principles, Techniques and Effectiveness of Deception	
30
Types of Deception	
32

Contents
viii 
The Art and Science of Military Deception
 CHAPTER 7 
Deception Maxims: Fact and Folklore 
39
 CHAPTER 8 
The Principle of Naturalness 
41
Conclusion	
43
 CHAPTER 9 
Tactical Deception in Air-Land Warfare 
45
Section III: Myths of Deception  
55
Introduction	
55
 CHAPTER 10 
Meinertzhagen’s False Claim to the Haversack Ruse (1917) 
57
 CHAPTER 11 
The Ultra Secret: Enigma Unwrapped 
A Review of F.W. Winterbotham’s The Ultra Secret	
59
 CHAPTER 12 
The Ultra Variations: A Review of Anthony Cave Brown’s Bodyguard of Lies	
63
Section IV: Theories: How Deception Works 
73
Introduction	
73
How Deception Works	
73
 CHAPTER 13 
“Window” as Written in Most Secret War	
75
 CHAPTER 14 
The Psychology of Deception 
89
 CHAPTER 15 
“Killing No Murder” The Strategy of Indirect Approach 
97
 CHAPTER 16 
Cognitive Factors in Deception and Counterdeception 
105
Introduction	
105
Biases in Perception	
107
Implications for Intelligence Analysis	
112

 
Contents
The Art and Science of Military Deception	
ix
Cognitive Biases	
115
Biases in Estimating Probabilities	
115
Biases in Evaluation of Evidence	
119
Oversensitivity to Consistency	
120
Biases in the Perception of Causality	
123
Bias Toward Causal Explanations	
124
Internal vs. External Causes of Behavior	
125
Conclusion	
127
Appendix	
130
Endnotes	
131
 CHAPTER 17 
The Theory of Practical Joking—Its Relevance to Physics 
135
 CHAPTER 18 
Styles in Deception 
145
Styles in Deception	
145
 CHAPTER 19 
The Process of Deception 
147
Section V: Deception Traditions 
149
Introduction	
149
Deception Traditions	
149
A British Tradition of Stratagem: 
And Its Influence on American, Israeli, 
Indian and Pakistani Doctrine 
151
 CHAPTER 20 
Conditions Making for Success and Failure of Denial and Deception: Democratic Regimes 153
 CHAPTER 21 
Some Notes on the Organization of Deception (1944) 
161
Some Notes on the Organization of Deception in the United States Forces	
161
American Attempts at Deception: A Spotty Record 
167
 CHAPTER 22 
The Actor’s Tale 
169

Contents
x 
The Art and Science of Military Deception
 CHAPTER 23 
American Strategic Deception in the Pacific: 1942–44 
173
 CHAPTER 24 
A Pentagon Proposal to Continue a Deception Organization after 
WW2 (1945)—General Conclusions 
177
General Recommendations	
178
A Russian Tradition of Stratagem: 1939 to the Present 
179
 CHAPTER 25 
Catching NATO Unawares: Soviet Army Surprise and Deception Techniques 
181
Surprise in Its Strategic Context	
181
The Advantages of Surprise	
182
A Heavy Blow	
183
Speed and Flexibility in the Advance	
184
Simultaneous Attacks Throughout the Enemy’s Depth	
184
Air Superiority	
184
The Possibilities of Strategic Surprise	
185
The Limits of Modern Surveillance	
185
Assessing Intentions	
186
Operational Surprise	
187
Eight Methods	
187
Operational Deception	
188
Examples of Maskirova	
189
Tasks of Maskirovka	
190
Principles of Deception	
190
Conclusions	
191
 CHAPTER 26 
The Red Mask: The Nature and Legacy of Soviet Military Deception 
193
The Chinese Tradition of Stratagem: circa 350 BC to the Present 
199
 CHAPTER 27 
Foreword to General Griffith’s Sun Tzu 
201
 CHAPTER 28 
Stratagem: The Chinese View in the Sun Tzu 
203

 
Contents
The Art and Science of Military Deception	
xi
 CHAPTER 29 
Chinese Deception Doctrine: A View from Open Sources 
207
Preface	
207
Introduction and Overview	
208
Implications for the U.S. 	
208
Limits of Open Sources	
209
Background of the Two Authors	
210
A Unique Chinese Deception Theory?	
211
Examples of Chinese Deception Aspirations	
211
Chinese History as a Source of Future Deception Models 	
214
Section VI: Tactical Camouflage: Now You See It, Now You Don’t 
215
Introduction	
215
 CHAPTER 30 
Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets 
217
Section VII: Strategic Deception 
239
Introduction	
239
Strategic Deception	
239
 CHAPTER 31 
Biggest Hoax of the War: Operation FORTITUDE: The Allied Deception Plan that 
Fooled the Germans about Normandy 
241
 CHAPTER 32 
Soviet Deception in the Cuban Missile Crisis—Learning from the Past 
251
Maskirovka	
252
Close-hold Planning	
252
Developing a Cover Story	
253
Getting the Cubans on Board	
253
Keeping the Secret at Home	
254
Secrecy in Transit	
255
Unloading in Cuba	
256
Movement to Field Sites	
257
Disingenuous Diplomacy	
258
Denouement	
258
In Conclusion	
259
Footnotes	
260
 CHAPTER 33 
The Barry and Thomas Critique of the Pentagon Report: In the Lessons and 
Non-Lessons of the Air and Missile Campaign in Kosovo 
263

Contents
xii 
The Art and Science of Military Deception
 CHAPTER 34 
Denial and Deception Practices of WMD Proliferators: Iraq and Beyond 
267
Section VIII: Irregular Warfare and Non-State Actors  
289
Introduction	
289
Terrorists and Other Non-State Actors—Constraints and Opportunities	
289
 CHAPTER 35 
Conditions Making for Success and Failure of Denial and Deception: 
Nonstate and Illicit Actors 
291
 CHAPTER 36 
The Evolution of a Revolt 
297
 CHAPTER 37 
The Inherent Vulnerabilities of Technology: Insights from the National Training 
Center’s Opposing Force 
309
 CHAPTER 38 
Tactical Deception and Strategic Surprise in  al-Qai’da’s Operations 
315
 CHAPTER 39 
How Can Weak Powers Win? 
337
Section IX: Ambush and Counterambush 
373
Introduction	
373
Ambush	
373
 CHAPTER 40 
How to Ambush a NATO Fortress 
375
Main Circumstances	
375
 CHAPTER 41 
High Desert Ambush: Hard Lessons Learned the Hard Way 
379
Contemporary Issues	
380
 CHAPTER 42 
A Modern Day “Trojan Horse”—Operation JAQUE and the Use of Stratagem
in a Hostage Rescue Operation 
383
Operation Willing Spirit	
385
Partnership - U.S. and Colombian Special Operational Forces 	
385

 
Contents
The Art and Science of Military Deception	
xiii
Operation Willing Spirit Campaign Planning 	
386
The Reconnaissance Plan and Operation Ellipse	
387
Problems From Within	
388
Cracking the FARC Communication Codes 	
389
Operation JAQUE—“Check”	
389
Conclusions	
391
Section X: Deception Planners and Planning 
393
Introduction	
393
Deception Planners and Planning	
393
Preconditions	
393
Process	
394
 CHAPTER 43 
A Commander Improvises His Own Deception Planning Team 
395
 CHAPTER 44 
Deception Planning in 145 Different Disciplines: Lessons from Behind Other Hills 
397
How They Deceive	
397
The Essence of Deception: Hiding the Real and Showing the False	
397
What They Hide and Show: The 5 Ws	
399
Bluff and Double Bluff	
401
The Theory of Outs	
403
In Con Games	
403
In Magic	
404
In General	
405
In War	
406
Time Out of Joint	
408
Magicians—The One-Ahead Method	
409
Practical Jokers: It’s Earlier Than You Think	
409
Con Artists: It’s Later Than You Think	
409
Soldiers	
410
The Theory of Indirect Approach	
410
Direction, Misdirection, and Indirection	
411
Section XI: Naval Warfare 
413
 CHAPTER 45 
How to Cheat on Naval Tonnage Treaty Limits 1919–1939 
415
 CHAPTER 46 
Harwood and the First Deception of WWII, 1939 
421

Contents
xiv 
The Art and Science of Military Deception
Section XII: Air War 
423
 CHAPTER 47 
MiG Sweep—Operation BOLO 
425
 CHAPTER 48 
Aerial Deception since the Second World War 
433
 CHAPTER 49 
Detection of the B-2 Bomber and a Brief History on ‘Stealth’ 
435
Scouting for Surveillance	
435
Detection of the B-2 Stealth Bomber and a Brief History on “Stealth”	
435
Overview of stealth technology 	
435
Potential vulnerabilities	
436
The Roke Manor system 	
437
A natural technological progression	
438
Military consequences	
439
Section XIII: Ground War: Theory and Practice 
441
 CHAPTER 50 
Night Action by Gideon at Moreh—Perhaps 1249 B.C. 
443
 CHAPTER 51 
BCTP: Be Unpredictable, Take Risks—Or Lose 
447
 CHAPTER 52 
The Monkey’s Paw 
455
 CHAPTER 53 
1st Cav in Desert Storm—Deception, Firepower and Movement 
459
Ground War: U.S. Training for Conventional Field Combat 
465
Introduction	
465
 CHAPTER 54 
Deception Operations in REFORGER 88 
467
 CHAPTER 55 
Voices in the Sand: Deception Operations at the NTC 
475

 
Contents
The Art and Science of Military Deception	
xv
 CHAPTER 56 
OPFOR Counterreconnaissance at the National Training Center 
483
Section XIV: Economic Warfare 
487
 CHAPTER 57 
The Farewell Dossier: Duping the Soviets 
489
The Farewell Dossier	
489
Soviet S&T Espionage	
490
US Computer Export Policy	
491
Strong Suspicions and Skepticism	
492
Presidential Interest	
492
A Defector in Place	
493
Interest in Technology Transfer	
493
A Deception Operation	
494
National Security Directive	
494
Good-by to Farewell	
495
An Important Contribution	
495
Notes	
495
Section XV: Cost Effectiveness 
497
 CHAPTER 58 
The One Percent Solution: Costs and Benefits of Military Deception 
499
Section XVI: When Your Deception Plan is Compromised: Plan B 
531
 CHAPTER 59 
Battle of the Gothic Line, 25 Aug 1944: Operation OLIVE 
533
Section XVII: When Deception Backfires 
537
 CHAPTER 60 
Polyakov’s Run 
539
Act One 	
540
“Top Hat” 	
541
Red Herring? 	
541
Act Two 	
542
Act Three	
543

Contents
xvi 
The Art and Science of Military Deception
Section XVIII: Detecting Deception: When Detective Meets Deceiver 
545
 CHAPTER 61 
Counterintelligence (CI) vs. Counterespionage (CE) 
547
 CHAPTER 62 
Counter-Deception Planning 
551
Counter-Deception Planning: Methodologies	
551
The Nature of a Counter-Deception System	
551
Seat-of-the-Pants Counter-Deception Methods	
552
Detection of Deception: Three Theories	
553
Reconstructive Inference	
553
Testing for Signals and Sprignals	
554
Incongruity Testing	
558
Guarding Against Expectation, Self-Deception, and Commitment	
564
Vulnerability Assessment	
567
Countermeasures	
568
Notes	
570
Conclusion 
577
A Cultural Handicap?	
577
The Erosion of Strategy and Stratagem	
578
Competent Commanders are Good Deceivers	
579
More Deception is Coming	
579
Glossary of Terms Relating to Deception 
581
About the Editors 
583

 
xvii
Acknowledgments
This book is part of a research project supported by the Office of the Secretary of De­
fense. We would like to thank Ben Riley for his insights and encouragement and for 
always thinking “big.” We also want to thank Glenn Fogg and Nancy Ann Budden 
who continuously ensure that fresh ideas are presented to the appropriate authorities in 
Washington for action.
The editors wish to thank Rebecca Lorentz. This work would not have been pos­
sible without her extraordinary assistance. Finally, this manuscript was significantly 
improved by the sharp eyes of Cindy Rothstein.


xix
Introduction
I did send for thee to tutor thee
In stratagems of war.
—Shakespeare, Henry VI  (c.1591), Pt. I, Act IV, Scene 5
Deception among people in a civilized society is something to be loathed even though 
it seems to be part of human nature. However, deception in war is a virtue. Stratagems 
aid commanders in hiding both intentions and capabilities from the enemy. They si­
multaneously reveal a false reality designed to guide the enemy to take actions that are 
detrimental to his cause. When properly designed and executed, stratagems reduce the 
horrific costs of war. 
Yet the importance that U.S. military senior leaders have historically place on deception 
is uneven.1 During World War II, the U.S. Army slowly and begrudgingly learned to use 
deception to great effect. General Eisenhower, perhaps more than anyone else, recognized 
the critical role of deception in seizing the Normandy beachhead before the Allied Forces 
drove towards Berlin. In 1947, as Chief of Staff of the Army and reflecting on his wartime 
experience, he wrote a memo to his Director of Plans and Operations saying, “…no major 
operations should be undertaken without planning and executing deception measures.”2 
However, Eisenhower also recognized the fragile place deception held in American mili­
tary thinking. In the same memo he stated, “As time goes on… there is a danger that these 
two means [psychological warfare and cover and deception] may in the future not be con­
sidered adequately in our planning.”3 Again, the future President of the United States was 
reflecting of his wartime experience.
General Eisenhower considered it essential that the War Department “take those steps 
that are necessary to keep alive the arts of… cover and deception.” He also directed the War 
Department to maintain “a nucleus of personnel capable in handling these arts in case an 
emergency arises.” His expressed purpose in this guidance about deception was “the fur­
therance of national security.”4
Eisenhower’s concerns about the durability of deception in American military thinking 
seems odd considering the significant contributions of successful stratagems during World 
War II. Military officers, if nothing else, should be propelled by results, and the modest 
stratagem investments during the Second World War brought exceptional results.5 Never­
theless, Eisenhower’s insights and concerns regarding the future of deception in the U.S. 
1.	
 James Monroe, “Deception: Theory and Practice” (M.S. Thesis, Naval Postgraduate School, 2012), 3.
2.	
 See Dwight D. Eisenhower, The Papers of Dwight David Eisenhower: The Chief of Staff, ed. Louis Galambos, Vol. 
VIII, Baltimore: Johns Hopkins Press, 1978, 1763; Monroe, 2.
3.	
 Ibid.
4.	
 Ibid.
5.	
 Barton Whaley makes this point in “The one percent solution: costs and benefits of military deception,” John 
Arquilla and Douglas Borer, eds., Information Strategy and Warfare: A Guide to Theory and Practice, New York: 
Routledge, 2007.

Introduction
xx 
The Art and Science of Military Deception
military were prescient. The U.S. military failed to act on General Eisenhower’s instructions 
and continues to fall short on maintaining the necessary capabilities to competently plan 
and conduct deception in support of higher-level military operations. This failure places 
the United States at a disadvantage in the rough-and-tumble arena of international politics.
To be sure, deception has played an important role in American military history. 
During the American Revolution, General Washington continuously deceived the Brit­
ish about his capabilities and intentions, ultimately denying General Cornwallis the 
use of all of his forces and thus setting the stage for the final showdown at Yorktown. 
During the Civil War, General Johnston held Union forces in check with little more than 
decoy cannons made of painted tree trunks. During the Second World War, and follow­
ing the lead of the British, deception reached a high point in both the war in the Pacific 
and in Europe. This is exemplified in the Battle of Midway and Operation Overlord. 
Even in Vietnam, the Military Assistance Command Vietnam—Studies and Observation 
Group (MACVSOG) made excellent use of deception, though it was never exploited at 
a theater level. During Operation Desert Storm, General Schwarzkopf deceived the Iraqi 
leadership into believing the coalition’s strike into Kuwait would come from the sea 
rather than through the uncharted desert—a maneuver now referred to as the left hook. 
This evidence of deception proficiency can lead defense experts to believe that con­
cerns regarding U.S. military deception know-how are unwarranted. Yet self-deception 
can be as lethal as deception. Any careful and informed look into contemporary military 
operations validates General Eisenhower’s concerns expressed in his 1947 memo. The 
careful and programmed use of stratagem in military operations is, at best, episodic. 
Why this is so is both astonishing and elusive. For some Americans, deception is suf­
ficiently odious, even evil, and is unacceptable under any circumstances. In the U.S. 
military, where firepower, maneuver, speed, agility, and superb logistics almost always 
result in a perceived force advantage, the style of warfare that logically follows is of 
an attrition form that is aimed at the cumulative destruction of the enemy. Given these 
conditions, the habitual and systematic use of deception seems pointless. The United 
States seems to assume that the instrument of deception is a tool reserved for the weak 
or desperate. While these two broad explanations—the odious, unacceptable nature of 
deception and its incompatible features relative to the American way of war—have mer­
it, they do not adequately account for America’s halfhearted appreciation of deception.
The United States lacks a sufficient intellectual, ethical, and institutional framework to 
understand, plan, and execute sophisticated and high-level deception operations against its 
enemies.6 In other words, the absence of both national policy and bureaucratic processes 
hamper the use of deception as an instrument of national policy. Recreating the capability 
to use deception requires a few key prerequisites: policy, apparatus, operators, and practice.
National policy legitimizes the use of deception as an instrument of statecraft. It de­
scribes the parameters for its use and shows the commitment that permeates a bureau­
cracy. Policy is the ultimate authorization that provides stable and continuous direction. 
A permanent apparatus, at all appropriate levels, to contemplate, plan, control, and 
terminate deception is necessary in order to ensure that operations are integrated with 
and are mutually supporting of other activities. A permanent apparatus is much more 
likely to cultivate institutional knowledge and ensure compliance with national policies 
than with informal or temporary offices.
6.	
 Walter Jajko, “Deception: Appeal for Acceptance; Discourse on Doctrine; Preface to Planning,” Comparative 
Strategy, Vol. 21, 2002, p. 353.

 
Introduction
The Art and Science of Military Deception	
xxi
Operators who have a penchant for the craft of deception are obviously indispens­
able. These individuals must be selected based on a combination of attributes that in­
clude intellect, imagination, operational art, and knowledge of the target. History has 
shown that individuals who excel in this craft are often eccentric and unorthodox. 
Leaders must not only tolerate unorthodoxy, but must ensure that there is a direct, 
responsive and unchallengeable relationship between leader and deceiver that tran­
scends a normal chain of command. This special relationship will also make certain 
that deception operators are intimately familiar with the objectives and thinking of their 
leadership. 
Finally, the prerequisites of policy, apparatus, and operators must be nurtured by realis­
tic and persistent practice. Wartime is too late to learn how to conduct deception. Exercises 
are key for developing the skills for inventing, integrating, controlling, and terminating de­
ception operations. Furthermore, exercises provide a mechanism for policy makers, com­
manders and operators to become accustomed to engaging in deception. They are a syn­
chronization and socialization tool for both wartime and peacetime deception operations.7
These deception prerequisites seem rather obvious, straightforward, and uncompli­
cated. In fact, the U.S. military excels in similar enterprises that require the same pre­
requisites. Therefore, the military ought to be fully capable of planning and executing 
high level deception operations. 
The purpose of this book is to set in motion a renaissance for using deception as 
an instrument of statecraft. Its contents have been carefully culled from the vast body 
of literature on deception. The various sections are designed to cumulatively provide 
sufficient breadth and depth on the subject in order to satisfy the novice as well as the 
expert. Additionally, sections and many of the individual pieces are preceded with ex­
pert commentary that is designed to illuminate the importance of the section or individ­
ual article, or to provide interesting background information to help establish context. 
The readings appear in their original format where practical. Properly understood, the 
contents of this book provide the reader with sufficient knowledge to pursue General 
Eisenhower’s vision for the proper role of deception in support of the national interest. 
7.	
 Experts have identified various frameworks for deception that include both policy issues and processes. The ideas 
expressed above reflect aspects of many of these frameworks, but are mostly drawn from Walter Jajko’s article 
previously cited.


1
C H A P T E R  1
Beware of the Dog1
Roald Dahl
This short fictional piece can be an appropriate trigger for any discussion of deception 
basics.
Roald (pronounced RU-all) Dahl was born in Wales to Norwegian parents.  Al­
though he’d greatly exaggerated the autobiographical elements in this, his first short 
story, he had been an RAF fighter pilot in World War II when in 1940 he unromanti­
cally ran out of fuel and crash-landed his antiquated Gloster Gladiator biplane fighter 
in the Libyan Desert.  Having been moderately injured in the face, Dahl recovered over 
the next few weeks in British military hospitals.  He was then transferred to duty in the 
USA, where, for the remainder of the war, he worked with William Stephenson’s secret 
British Security Coordination (BSC). 
Dahl’s simple story, substantially elaborated, became the basis of three major fic­
tional tales.  First came an episode in English spy thriller writer Len Deighton’s best-
selling “The Ipcress File” (1962) in which a British intelligence officer is kidnapped and 
awakens in a prison cell that he is led to believe is behind the Iron Curtain in Hungary.  
CIA Director Allen Dulles included that chapter in his “Great Spy Stories from Fiction” 
(1969).
The second version was the rather competent M-G-M thriller movie starring James 
Garner, “36 Hours” (1964).  In that film, a U.S. Army major (Garner) who knows the 
where and when secrets of the forthcoming D-Day invasion is rendered unconscious 
and kidnapped by the Nazis. He awakens in a simulated American hospital in a fake 
post-war “Allied Occupied Germany” where the disguised Germans plan to get the 
secrets from him. A single discrepancy—a nick on his chin from shaving that he’d given 
himself only 36 hours earlier alerts him to the truth that he’d been in a coma for mere 
hours, not months. 
This plot was recycled for the third time in 1989 for an American TNT-TV drama 
titled “Breaking Point,” in which an American agent is captured by the Nazis who at­
tempt to pry the D-Day secrets from him.  When torture fails, they try the above type 
of deceptive charade.
Dahl is most widely remembered as the author of imaginatively bizarre children’s 
stories, including “Charlie and the Chocolate Factory” (1964); and his rough marriage 
(1953–83) to American movie star Patricia Neal.
1.	
Roald Dahl, “Beware of the Dog,” Harper’s, October 1944, pp. 436–442. Reprinted with permission of the Estate 
of Roald Dahl.

Beware of the Dog
2 
The Art and Science of Military Deception

 
Beware of the Dog
The Art and Science of Military Deception	
3

Beware of the Dog
4 
The Art and Science of Military Deception

 
Beware of the Dog
The Art and Science of Military Deception	
5

Beware of the Dog
6 
The Art and Science of Military Deception

 
Beware of the Dog
The Art and Science of Military Deception	
7

Beware of the Dog
8 
The Art and Science of Military Deception

9
Section I:
The Ethics of Political-Military Deception
MAN: Uh, is this a game of chance?
W. C. Fields: Not the way I play it.
—My Little Chickadee (movie, 1940)


11
C H A P T E R  2
Intelligence Ethics1
R.V. Jones
Dr. Reginald Victor (“R.V.”) Jones was responsible for coordinating scientific intel­
ligence during World War II, and helped with the development of radar, breaking the 
secrets of German Beam navigation, preparing for D-Day and helping Britain deal with 
the V1 Flying Bombs and the V2 Rockets.  After the war Jones was professor of natural 
philosophy at the University of Aberdeen (1946–1981).
1.	
R. V. Jones, Reflections on Intelligence, London: Heinemann, 1989, 35–56. Published by William Heinemann. 
Reprinted with permission of The Random House Group Limited.

Intelligence Ethics
12 
The Art and Science of Military Deception

 
Intelligence Ethics
The Art and Science of Military Deception	
13

Intelligence Ethics
14 
The Art and Science of Military Deception

 
Intelligence Ethics
The Art and Science of Military Deception	
15

Intelligence Ethics
16 
The Art and Science of Military Deception

 
Intelligence Ethics
The Art and Science of Military Deception	
17

Intelligence Ethics
18 
The Art and Science of Military Deception

19
Section II: 
Principles and Other Fundamentals
Introduction
It was beautiful and simple as all truly great swindles are.
— O. Henry, “The Octopus Marooned,” The Gentle Grafter (1908)
He [Gregg Toland] showed me the inside of that bag of tricks, and, like all good magic, 
the secrets are ridiculously simple. 
— Orson Welles, 1972
The Structure of Deception
The basic structure of deception is simple—one thing is hidden (dissimulated) while 
another is shown (simulated) in its place.  Deception is the deliberate distortion of per­
ceived reality.  Operationally, it is done by changing the pattern of distinguishing char­
acteristics of the thing (whatever object or event) detected by the sensory system of the 
target.
Reality is distorted, deceptively portrayed by both nature and man.  Nature’s decep­
tions are either without purpose—as with physical illusions such as a mirage or mirror 
images—or purposefully (and then, always to the advantage of the species involved as 
with all evolutionary bits of camouflage that have survival value).  Humans’ deceptions 
are also either without purpose—unintentional representations, or purposeful—with 
intent to deceive.  Nature does this unconsciously; humans do it either unconsciously, 
as with self-deception and some deceptions of others, or consciously (and then, always 
to some personal advantage).
Every deception operation, whether of man or nature, is comprised of only two 
basic parts: dissimulation and simulation.  In 1597, English philosopher Francis Bacon 
was the first to expound on this crucial dichotomy in his important and aptly titled es­
say, “On Simulation and Dissimulation,” where he applied it to interpersonal relations.
This two-part simulation-versus-dissimulation notion was first applied to military 
theory (introducing the two terms “positive” and “negative” camouflage) in a memo 
written in 1918 by Col. Richard Meinertzhagen.1  In 1920, British artist-painter Solo­
mon J. Solomon was the first to apply the two-part simulation-versus-dissimulation 
notion to military theory.  He did this in his pioneering book, Strategic Camouflage.  
Modern mathematicians Von Neumann and Morgenstern flirted with this two-fold 
concept for all deception, writing in their revolutionary book that introduced the world 
to the Theory of Games.
1.	
Timothy Ferris, The Mind’s Sky: Human Intelligence in a Cosmic Context, New York: Bantam, 1992, pp. 185, 193.

Section II: Principles and Other Fundamentals 
20 
The Art and Science of Military Deception
Of the two possible motives for bluffing, the first is the desire to give a (false) im­
pression of strength in (real) weakness; the second is the desire to give a (false) impres­
sion of weakness in (real) strength.  Both are instances of inverted signaling — i.e. of 
misleading the opponent.
Finally, American psychologist Paul Ekman wrote that “There are two primary 
ways to lie:  to conceal and to falsify.”  He noted, correctly, that specialists in military 
deception also make this same distinction.2
Dissimulation is hiding the real.  It is covert. Half of a deception is concealed from 
the target.  Its task is to conceal—or at least obscure—the truth.  Operationally, dis­
simulation is done by hiding one or more of the characteristics that make up the distinc­
tive pattern of the real thing.
Simulation is showing the false.  It is overt. Half of a deception is presented to the 
target.  Its task is to pretend, portray, and profess an intended lie.  Simulation is done 
by showing one or more characteristics that comprise the distinctive pattern of a false 
thing.
Both simulation and dissimulation are always present together in any single act of 
deception.  Nothing is ever “just” hidden; something is always shown in its stead, even 
if only implicitly.  Thus, the homeowner who hides money in the cookie jar is pretending 
(showing) there is no money at home.3  It is the two in combination that misdirect the 
attention and interest of the target, inducing it to form misperceptions (false hypoth­
eses) about the real nature of what is impending.
Dissimulation and simulation are also widely referred to as denial and deception 
(D&D).  However, we find that model less precise than defining deception as having 
two elements: dissimulation and simulation. 
2.	
 John von Neumann, Oskar Morgenstern, Theory of Games and Economic Behavior, NJ: Princeton University 
Press, 1944, p. 189.
3.	
 A 1987 British Gallup poll found that 16% of Britons kept substantial sums of money hidden in their homes.  

21
C H A P T E R  3
On Simulation and Dissimulation1
Sir Francis Bacon
This short essay by the remarkable early English philosopher of science, lawyer, and 
intelligence officer states for the first time the taxonomy of hiding and showing.  The 
essay distinguishes three degrees of hiding oneself—secrecy, where a man makes himself 
invisible; dissimulation, a negative position where he gives evidence that he is some­
thing other than himself; and simulation, giving affirmative evidence of what that other 
self is.  He then lists three advantages of simulation and dissimulation and their three 
disadvantages. 
This idea of hiding-and-showing as a linked pair (dichotomy) was already old in 
1597 when Francis Bacon raised this everyman’s notion to the level of philosophy in 
this essay.  The reader will appreciate that this seemingly simple concept of simultane­
ously hiding one thing and showing something else in its place is the basis for both the 
theory of deception and all attempts to analyze deceptions.
It is no accident that we owe the refinement of this concept to Bacon rather than 
some other Elizabethan humanist.  He was, after all, a great admirer of Machiavelli.  
Moreover, like his Italian model, Bacon was an historian, writer, diplomat, and an 
ambitious politician whose great ups and greater downs came at the whims of tyrants.  
Additionally, Bacon had early experience as a secret agent, since age 16, in the cutthroat 
politics of the English court.
Dissimulation is but a faint kind of Policy or Wisdome; for it asketh a strong wit and a 
strong heart to know when to tell truth, & to doe it.  Therfore it is the weaker sort of 
politics that are the great Dissemblers.
Tacitus saith: Livia sorted well with the arts of her husband, & dissimulation of her 
sonne: attributing arts or policy to Augustus, & dissimulation to Tiberius.  And againe, 
when Mucianus encourageth Vespasian to take arms against Vitellius, he saith: We rise 
not against the piercing judgment of Augustus; nor the extreme caution or closenesse 
of Tiberius.  These properties, of Arts or Policy, and Dissimulation or Closenesse, are 
indeed habits and faculties severall, and to be distinguished.  For if a man have that 
penetration of judgment as he can discerne what things are to be laid open, and what 
to be secretted, and what to be shewed at halfe lights, and to whom, and when, (which 
indeed are arts of State, and arts of Life, as Tacitus well calleth them); to him, a habit 
of Dissimulation is a hindrance and a poorenesse.  But if a man cannot obtaine to that 
judgment, then it is left to him, generally, to be close, and a Dissembler.  For where a 
man cannot choose or vary in particulars, there it is good to take the safest and wariest 
way in generall; like the going softly by one that cannot well see.  Certainly the ablest 
men that ever were have had all an opennesse and francknesse of dealing; and a name of 
certainty and veracity; but then they were like horses well managed; for they could tell 
1.	
Sir Francis Bacon, “On Simulation and Dissimulation” in Essays of Francis Bacon, 1627.

On Simulation and Dissimulation
22 
The Art and Science of Military Deception
passing well when to stop or turne: and at such times when they thought the case indeed 
required Dissimulation, if then they used it, it came to passe that the former opinion 
spred abroad of their good faith and clearnesse of dealing made them almost invisible.
There be three degrees of this hiding and vailing of a man’s selfe.  The first Close­
nesse, Reservation, and Secrecy; when a man leaveth himself without observation, or 
without hold to be taken, what he is.  The second, Dissimulation, in the negative; when 
a man lets fall signes and arguments, that he is not that he is.  And the third Simulation, 
in the affirmative; when a man industriously and expressly faigns, and pretends to be 
that he is not.  
For the first of these, Secrecy; it is indeed, the vertue of a Confessour.  And assur­
edly, the secret man, heareth many Confessions.  For who will open himselfe to a blab 
or a babler?  But if a man be thought secret, it inviteth discoverie; as the more close aire 
sucketh in the more open: and as in confession the revealing is not for worldly use, but 
for the ease of  a man’s heart, so secret men come to the knowledge of many things in 
that kinde; while men rather discharge their mindes then impart their mindes.  In few 
words, mysteries are due to secrecy.  Besides (to say truth) nakednesse is uncomely, as 
well in minde as body; and it addeth no small reverence to men’s manners, and actions, 
if they be not altogether open.  As for talkers and futile persons, they are commonly 
vaine, and credulous withall.  For he that talketh what he knoweth, will also talke what 
he knoweth not.  Therefore set it downe; that an habit of Secrecy is both politick and 
morall.  And in this part it is good that a man’s face give his tongue leave to speake.  
For the discovery of a man’s selfe by the tracts of his countenance is a great weaknesse 
and betraying; by how much it is many times more marked and beleeved then a man’s 
words.  
For the second, which is Dissimulation.  It followeth many times upon Secrecy by a 
necessity: so that he that will be secret must be a Dissembler in some degree.  For men 
are too cunning to suffer a man to keepe an indifferent carriage betweene both, and to 
be secret, without swaying the balance on either side.  They will so beset a man with 
questions, and draw him on, and picke it out of him, that without an absurd silence, 
he must shew an inclination one way; or if he doe not, they will gather as much by his 
silence as by his speech.  As for equivocations, or oraculous speeches, they cannot hold 
out long.  So that no man can be secret, except he give himselfe a little scope of Dis­
simulation; which is, as it were, but the skirts or traine of Secrecy.  
But for the third degree, which is Simulation and false profession; that I hold more 
culpable, and lesse politicke; except it be in great and rare matters.  And therefore a gen­
erall custome of Simulation (which is this last degree) is a vice, rising either of a naturall 
falsenesse or fearefulnesse, or of a minde that hath some maine faults; which because a 
man must needs disguise, it maketh him practise Simulation in other things lest his hand 
should be out of use.  
The great advantages of Simulation and Dissimulation are three.  First, to lay asleepe 
opposition, and to surprize.  For where a man’s intentions are published, it is an alarum 
to call up all that are against them.  The second is, to reserve to a man’s selfe, a faire 
retreat.  For if a man engage himselfe by a manifest declaration, he must goe through 
or take a fall.  The third is, the better to discover the minde of another.  For to him that 
opens himselfe men will hardly shew themselves adverse; but will (faire) let him goe on, 
and turne their freedome of speech to freedome of thought.  And therefore it is a good 
shrewd proverb of the Spaniard; Tell a lye, and finde a troth.

23
C H A P T E R  4
The 8 Principles of Security and the 8 Principles 
of Deception1
R.V. Jones
This excerpt by R.V. Jones is a concise, clear specification of the ways to hide something 
real (dissimulation) and the corresponding ways to show something false (simulation) 
in its place.  
The Principles of Security
I hope that, without being historically comprehensive, the examples that I have given 
above will illustrate the principles of deception as far as I know them. As a first step, 
what has to be done is to prevent the enemy from deducing at least one of the following:
1.	 Where you are, and/or where he is.
2.	 What weapons and forces you have at your disposal.
3.	 What you intend to do.
4.	 Where you intend to do it.
5.	 When you intend to do it.
6.	 How you intend to do it.
7.	 Your knowledge of the enemy’s intentions and techniques.
8.	 How successful the enemy’s operations are.
All these objectives are in a sense negative, but they may be sufficient to achieve 
surprise. Basically they involve security rather than deception.  Wolfe, for example, 
surprised Montcalm at Quebec because Montcalm had not thought that the Heights of 
Abraham could be scaled;2 and the introduction of centimetric radar helped to change 
the balance in the battle of the Atlantic because the Germans were unaware that we had 
developed this new technique.
The Principles of Deception
These negative objectives are the function of the security organisation: each objective 
has a positive counterpart, which properly constitutes deception. The corresponding 
objectives of deception therefore are that the enemy must be persuaded to deduce:
1.	
Reginald V. Jones, “Intelligence and Deception,” in  Robert L. Pfaltzgraff, Jr., Uri Ra’anan, and Warren H. Milberg 
(editors), Intelligence Policy and National Security, Hamden, CT.: Archon Books, 1981, pp. 17-19.
2.	
Similarly, the Japanese surprised the British at Singapore, but there was an element also of self-deception in the 
British command.  See N. F. Dixon, On the Psychology of Military Incompetence, London: Jonathan Cape, 1976.

The 8 Principles of Security and the 8 Principles of Deception
24 
The Art and Science of Military Deception
1.	 You are somewhere else, and/or he is somewhere else.
2.	 Your weapons and forces are different from what they are.
3.	 You intend to do something else.
4.	 You intend to do it elsewhere.
5.	 You intend to do it at a different time.
6.	 You intend to do it in a different manner.
7.	 Your knowledge of the enemy is either greater or less than actually is.
8.	 His operations are either more or less successful than they actually are.
In short, you are seeking to provide your adversary with clues in his several chan­
nels of observation which are consistent with one another, but from which he will build 
up a false picture of reality. You hope then that, basing his own actions on this picture, 
he will at some crucial time either act incorrectly and so make himself vulnerable, or he 
will fail to take advantage of a situation which is in fact favourable to him but which 
he assesses as unfavourable.
There is scope for artistry in the devising and presentation of clues. While these 
should be consistent in every channel by which the victim can derive evidence, they 
should not be too obvious. For example, if bogus espionage reports are to be fabricated, 
they should include the kinds of error and misinterpretation a genuine spy is likely to 
make, so that the analytical officer on the other side will be led to feel that he is getting 
at the truth by eliminating the errors introduced by faulty observation or interpretation 
on the part of the spy. The picture that the analyst builds up will then be all the more 
convincing. As a member of the Double Cross operation said: “An item of information 
that the analyst has worked out for himself is worth ten that he has been told”. Or the 
supposed spy may report an item faithfully and correctly, but, add that he himself does 
not believe it. I call this the Herodotus touch because of the statement in his History 
that he could scarcely credit what the Phoenicians had reported when they sailed round 
Southern Africa, “The sun rose on the other side,” which subsequent scholars have 
taken as twin testimony to the bona fides of Herodotus and to the feat of seamanship 
on the part of the Phoenicians.
A further touch of artistry in deception is to provide an alternative to your true 
intentions so valid that if your adversary detects it as a hoax, you can then switch to it 
as your major plan and exploit the fact that he has discounted it as a serious operation.

25
C H A P T E R  5
Ruses and Stratagems of War1
General Sir A.P. Wavell
Always mystify and mislead the enemy.
— Stonewall Jackson
General Archibald Wavell had originally issued this brief paper as Commander-in-Chief 
India, in July 1942 “to stimulate commanders of all grades to consider methods of de­
ceiving the enemy, by outlining means which have proved successful in the past.”
This is the classic appreciation of deception by the one officer who directly and sin­
gle-handedly transmitted Britain’s institutional memory of military deception between 
the two world wars.  He brought its theory and practice from WWI to WWII and from 
the North African front to the China-Burma-India Theatre and to London GHQ where 
it resonated with Churchill’s own views and soon with the United States, Britain’s ally.  
What Wavell said more than sixty years ago holds true today. 
Ruses and Stratagems of War
Possibly because the British character is normally simple and straightforward, more 
probably because our military training is stereotyped and unimaginative, deception of 
an enemy does not seem to come naturally to us.  Hence we are apt to suffer in the field 
through lack of guile and to fall too easily into the enemy’s traps and to miss opportuni­
ties of setting traps of our own.
Some years ago in a public lecture I referred to the definition by a distinguished sol­
dier of his ideal infantryman as “athlete, stalker, marksman”, and said that my ideal in­
fantryman was “cat-burglar, poacher, gunman”.  The point of my definition, as against 
the other, was that the characters I named risk their life and liberty in the exercise of 
their profession and have to defend them with their wits, as does the soldier on service, 
while the athlete, stalker and marksman do not. In fact one is a peace definition of a 
soldier, the other for war.
The object of this note is to stimulate commanders of all grades to consider methods 
of deceiving the enemy, by outlining means which have proved successful in the past.
Practically all ruses and stratagems in war are variations or developments of a few 
simple tricks that have been practised by man on man since man has hunted man, i.e. 
since the existence of the human race.  They can be roughly divided under the following 
heads (with the modern equivalent suggested in brackets):
1.	
Archibald (General Sir) Wavell, Brief Paper as Commander in Chief in India, July, 1942.  See also Archibald (Gen­
eral Sir) Wavell, Speaking Generally: Broadcasts, Orders and Addresses in Time of War (1939–1943), London: 
Macmillan, 1946, pp. 80-83.

Ruses and Stratagems of War
26 
The Art and Science of Military Deception
••
False information or disguise (“Camouflage”) 
••
Feigned retreat (“booby traps”) 
••
Encouragement of treachery (“Fifth Column’’) 
••
Weakening of morale (“war of nerves”)
To convey false information to the enemy by some means or other is the commonest 
trick of all. It has many variations.  To hoist false colours was a frequent ruse in older 
naval warfare; it has its counterpart today in Q-ships or disguised raiders.
Deception may be achieved by word of mouth. The Greek Sinon, posing as a de­
serter, persuaded the Trojans to pull the Wooden Horse inside the walls of Troy.  The 
Wooden Horse itself has its modern equivalent in the German capture of Bergen and 
Narvik by soldiers concealed in apparently harmless merchant ships.  Similarly in me­
dieval times a castle was once captured by soldiers hidden under brushwood in a cart.
Two of Napoleon’s Marshals secured an important bridge over the Danube simply 
by walking across and assuring the enemy guard at the other end that an armistice had 
been declared; meanwhile a party crept up behind them and finally rushed the enemy 
end of the bridge.  There have been instances in this war of parties being bluffed into 
surrender by persuading them that they were surrounded, etc.
Doing the same thing many times till the enemy is accustomed to it and then sud­
denly doing something quite different at the same time of day is sometimes effective in 
securing surprise.
Camouflage is the modern term for methods of concealment which have been prac­
tised by savages and others for many hundreds of years. In Shakespeare’s Macbeth 
Malcolm made good use of the wood of Birnam; his instructions to his troops would, 
suitably paraphrased, be equally appropriate today: 
Let every soldier hew him down a bough 
And bear’t before him: thereby shall we shadow 
The numbers of our host, and make discovery 
Err in report of us.
The effect of this ruse on Macbeth’s morale was decisive.
The trick of putting one’s cap or helmet on a stick and thrusting it out to draw the 
enemy’s fire probably dates from the first day that warriors wore head-dresses.
The stratagem of feigned retreat to induce the enemy to leave a strong position 
and become disorganized in pursuit is a very old one.  In the classic fight between the 
three Horatii and the three Curiatii, the surviving Roman by purposeful flight got his 
opponents strung out and was then able to kill them one by one.  The feigned with­
drawal of the Greeks put the Trojans off their guard; and a pretended retreat of the 
Norman horsemen broke up the Saxon formation and was the deciding factor at Hast­
ings (1066).  In 1918 General Gouraud disorganized a German attack at Rheims by a 
temporary withdrawal.
Drawing the enemy on to a minefield and the use of “booby traps” are modern 
developments of this ruse.
So-called Fifth Column methods are very old.  Rahab of Jericho, Delilah of Gaza 
and Jael the Kenite were early Fifth Columnists; and military history is full of instances 
of troops or commanders being bought or suborned by the enemy.

 
Ruses and Stratagems of War
The Art and Science of Military Deception	
27
Propaganda by wireless or by dropping leaflets is only a modern means of applying 
a very old technique for defeating an enemy.
Means of playing on the enemy’s fears by terrifying appearance or by unusual noise 
are amongst the very oldest devices of war.  The savage painted himself and shouted 
war-cries to terrify his enemies.  Gideon in his famous night attack, described in the 
seventh chapter of Judges, made his small force wave torches and shout battle-cries to 
alarm their foes.  Bahram of Persia (“that great hunter” of FitzGerald’s Rubaiyat) once 
stampeded his opponent’s cavalry during a night attack by tying nose-bags full of rat­
tling stones round the necks of his own horses.  The whistling bomb of the Nazi, the 
crackers and shouts of the small Japanese party which has penetrated to the rear and 
wishes to simulate a large force, are modern developments.
These few notes show that there is nothing new about the general principles of 
deceiving the enemy.  Every commander of any grade should constantly be considering 
methods of misleading his opponent, of playing on his fears and of disturbing his mental 
balance.
Belisarius, Justinian’s famous general (c. AD 555), was possibly the greatest master 
of stratagem who has held the highest commands. He won two almost bloodless victo­
ries, at Carchemish and outside Constantinople, by a mixture of bluff and daring which 
persuaded his opponents he was much stronger than he actually was. He also made 
frequent use of feigned withdrawals and ambushes.
Perhaps the most elementary principle of all deception is to attract the enemy’s at­
tention to what you wish him to see and to distract his attention from what you do not 
wish him to see.  It is by these methods that the skillful conjurer obtains his results.
NOTE: Many of Wavell’s techniques may also be classified as psychological warfare.  
Deception and psychological warfare often overlap. 


29
C H A P T E R  6 
The Problem of Deception1
Cynthia Grabo
Grabo was a professional American intelligence analyst with the U.S. Army from 1942–
49, then with the interagency National Watch Committee from 1950 to 1975, and finally 
with its successor organization, the Strategic Warning Staff until her retirement in 1980.
Unlike  Wohlstetter, Handel, Vertzberger and the many other pessimists, Grabo leans 
toward the optimistic view that intelligence analysis can filter the noise (and redundan­
cies) from the relevant signals to detect and give timely warning of hostile events—even 
when those events are cloaked by deception.  This excerpt is from the declassified article 
originally written by Grabo in the early 1970s and condensed in 2002 by Jan Goldman.
The Problem of Deception
Confidence that a study of history and of techniques and principles of indications analy­
sis will enable us to come to the right judgment of the adversary’s intentions fades as one 
contemplates the chilling prospect of deception.  There is no single facet of the warning 
problem so unpredictable, and yet so potentially damaging in its effect, as deception.  
Nor is confidence in our ability to penetrate the sophisticated deception effort in any 
way restored by a diligent study of examples.  On the contrary, such a study will only 
reinforce a conclusion that the most brilliant analysis may founder in the face of decep­
tion and that the most expert and experienced among us on occasion may be as vulner­
able as the novice.
The Infrequency and Neglect of Deception
There can be no question that, at least until quite recently, deception has been one of 
the least understood, least researched and least studied aspects of both history and in­
telligence.  Military historians often have not even perceived the role which deception 
has played in the outcome of some major military operations.  Indeed, the revelation in 
recent years of the part that deception played in World War II has led to a wholly new 
understanding of the history of that conflict.  What accounts for the neglect of such an 
important subject?
One reason for the scant attention to deception almost certainly is its rarity.  If true 
warning problems are seldom encountered, useful examples of deception are rarer still, 
and indeed a number of major crises of recent years seemingly have involved relatively 
little if any deception. A second, and related, factor is that the deception effort is likely 
to be the most secret and tightly held aspect of any operation and that countries often 
1.	
Cynthia M. Grabo, Anticipating Surprise: Analysis for Strategic Warning, Washington, D.C.: Joint Military Intel­
ligence College, Center for Strategic Intelligence Research, 2002, pp. 119–128.

The Problem of Deception
30 
The Art and Science of Military Deception
have been reluctant, even after the fact, to relax security on the deception plan, even 
when other aspects of the operation are fairly well known.  The exceptions, in which the 
deception operation has been recorded for our benefit and study, usually have been the 
result of the publication of articles or memoirs by participants in the plan, or the declas­
sification of war records, usually well after the event.  Deception tends to be forgotten 
and neglected between wars because it is usually not an instrument of peace.  Few coun­
tries have made a practice of extensive or elaborate deception in time of peace.  There 
are some exceptions to this, particularly in the field of counterintelligence and espionage 
in which deception is routinely practiced.
One reason why active deception is reserved for the exceptional situation involving 
national security interests is that success in deception is heavily dependent on its rar­
ity and on the prior establishment of credibility.  Any country that constantly or even 
frequently disseminates falsehoods would rapidly lose credibility and acceptance with 
other nations, and with its own populace.  It is one thing to be highly security conscious 
and not to reveal much, and quite another to engage in an active deception effort to 
mislead.  The most effective deceptions are by those whom we have come to trust, or at 
least who have been relatively truthful in their dealings with us over a period of years.  
Thus the true deception operation, at least a major and sophisticated one, usually is 
reserved only for that critical situation in the life of the nation when it is most essential 
to conceal one’s intent.  This will usually be in preparation for or in time of war.
Principles, Techniques and Effectiveness of Deception
The principle of deception, most simply stated, is to induce the adversary to make the 
wrong choice; or, as General Sherman put it, the trick is to place the victim on the horns 
of a dilemma and then to impale him on the one of your choosing.  If this is left entirely 
to chance, the probability of the enemy’s making the right or wrong choice will be in 
direct ratio to the number of alternatives which he perceives as equally viable.  Although 
surprise can result from sheer misunderstanding, “the possibility of surprise through 
misunderstanding diminishes nearly to the vanishing point as one considers the more 
elaborate strategic operations.”2  Therefore, the planner must develop one or more plau­
sible alternatives as bait for his victim and then employ a range of stratagems to mislead 
him.  “The ultimate goal of stratagem is to make the enemy quite certain, very decisive 
and wrong.”3  If this ideal cannot be achieved (and this writer believes that it would be 
a rare situation in which such total deception could be achieved), the mere presenting 
of alternative solutions nonetheless will serve to confuse the adversary and lead him to 
disperse his effort or to make at least a partially wrong response.
In other words the best stratagem is the one that generates a set of warning signals 
susceptible to alternative, or better yet, optional interpretations, where the intended so­
lution is implausible in terms of the victim’s prior experience and knowledge while the 
false solution (or solutions) is plausible.  If the victim does not suspect the possibility 
that deception may be operating he will inevitably be gulled.  If he suspects deception, 
he has only four courses open to him: These are, in summary: 
2.	
Bart Whaley, Stratagem: Deception and Surprise in War, Norwood, MA: Artech House, 2007, p. 133. The most 
thorough, published exposition on military deception is in Strategic Military Deception, Donald C. Daniel and 
Katherine L. Herbig, editors, New York: Pergamon Press, 1982.
3.	
Whaley, 135.

 
The Problem of Deception
The Art and Science of Military Deception	
31
1.	 To act as if no deception is being used.
2.	 To give equal weight to all perceived solutions (in violation of the principle of 
economy of force).
3.	 To engage in random behavior, risking success or failure on blind guesswork.
4.	 To panic, which paradoxically may offer as good a chance of success as the “rational” course in 
3.4
Thus, even a primitive deception effort will, by threatening various alternatives, create 
enough uncertainty to distract the most wily opponent and force him either to disperse his 
effort or gamble on being right.  Further, Whaley concludes, in a judgment of greatest impor­
tance for warning, that even the most masterful deceivers have proved to be easy dupes for 
more primitive efforts.  “Indeed, this is a general finding of my study—that is, the deceiver 
is almost always successful regardless of the sophistication of his victim in the same art.  On 
the face of it, this seems an intolerable conclusion, one offending common sense. Yet it is the 
irrefutable conclusion of the historical evidence.”5
A related, and also unexpected, finding of Whaley’s study is that only a small repertoire 
of stratagems is necessary “to insure surprise after surprise.”  The fact that the victim may 
be familiar with specific ruses “does not necessarily reduce much less destroy their efficacy.  
This can be predicted from the theory, which postulates that it is the misdirection supplied 
by selective planting of false signals that yields surprise and not the specific communications 
channels (that is, ruses) used.”6  In other words, the same tricks can be used over and over 
again, and stratagem can be effective with only a small number of basic ruses or scenarios.
Whaley goes on to note that, as between security and deception, deception is by 
far the most effective in achieving surprise since the only important security in this case 
will be the protection of the deception plan itself, which usually needs to be revealed 
only to a very small number of individuals.  If the security on the deception plan is 
tight enough, security on the rest of the operation can be outright slovenly, and “the 
most efficient stratagems calculatedly utilize known inefficiencies in general operational 
security.”  Whaley cites some examples of the extreme security maintained on decep­
tion plans, which the warning analyst should well heed, since it will upset the accepted 
theory that enemy plans may be learned from full confessions of high-ranking prisoners 
or defectors, or from interception of valid communications, authentic war plans, and 
the like.  Thus, in preparation for the Pearl Harbor attack, the Japanese Navy  issued a 
war plan on 5 November which gave full and accurate details of the planned attacks on 
the Philippines and Southeast Asia but which omitted any reference to the Pearl Harbor 
missions of the Navy, this portion of the order having been communicated only verbally.  
In the Suez attack in 1956, the entire British military staff from the Allied CinC on 
down were not informed on the collusion of the UK and France with Israel, so tightly 
was this held.  In the Korean war, the U.S. planned an amphibious feint (the so-called 
Kojo feint) which only the most senior commanders knew to be a bluff; even the plan­
ners and commanders of the naval bombardment and carrier strike forces thought the 
operation was real and behaved accordingly.  Thus, the misleading of one’s own people 
has been an important feature in many deceptions, with the unwitting participants in 
the plan convincingly carrying out their roles in good faith, thus contributing materially 
4.	
Whaley, 142–143.
5.	
Whaley, 146.
6.	
Whaley, 228.

The Problem of Deception
32 
The Art and Science of Military Deception
to the success of the operation.  So effective has security been on deception operations, 
that Whaley concludes that there have been almost no cases in which the deception plan 
itself was prematurely disclosed to the victim.
Types of Deception
This subject may be approached in a number of ways.  Whaley identifies five specific va­
rieties of military deception: intention (whether an attack or operation will occur at all), 
time, place, strength, style (the form the operation takes, weapons used, and so forth).
For strategic warning, the subject of this book, it will be obvious that the first of 
these (intention) is the most important.  Indeed, some might say that this is the only 
variety of deception which should properly be defined as strategic, the other types above 
being essentially tactical problems.  In fact, however, strategic warning or the perception 
of the adversary’s intention often does fall victim to one or more of the other forego­
ing varieties of deception as well.  Thus, in the Tet offensive of 1968, we were less the 
victims of misperception of the enemy’s intention as such (it was obvious that attacks 
of some type and scope were in preparation) than of the other factors.  We greatly un­
derestimated the strength of the attacks; we were astounded at some of the places (par­
ticularly cities) in which the attacks occurred; we misperceived the style of the offensive 
in some degree (that is, the extent of covert infiltration of saboteurs and troop units, 
again particularly into the major cities); and there was something of a misestimate of 
the timing of the attacks in that it was generally assumed that they would be launched 
before or after the holidays rather than during them (a factor which accounted for so 
many South Vietnamese troops being on leave and for the lax security).  Thus, it was all 
these misperceptions of the enemy’s planning and intentions which contributed to the 
surprise—and initial success—of the Tet offensive.  We were the victims of a combina­
tion of effective security, enemy deception and self-deception.
The history of warfare is filled with examples of the achievement of surprise in 
time, place or strength, or a combination of them. Whaley finds that, of the examples 
which he studied in which surprise was achieved, the most common mode was place (72 
percent), followed by time (66 percent), and strength (57 percent). The least frequent 
type of surprise which he found was style, which prevailed in 25 percent of the cases he 
analyzed. There are nonetheless some very famous examples, including the dropping of 
the first atomic weapon on Hiroshima, and the introduction of Soviet strategic missiles 
into Cuba.
We may close this very inadequate discussion of this approach to types of surprise 
and deception by observing that one of the greatest and most successful military surpris­
es in history, the Pearl Harbor attack, involved at least four of these modes. The United 
States had not correctly perceived the Japanese intention to attack U.S. territory at all 
and thus to bring the U.S. into the war—a step which logically appeared to be a gross 
strategic miscalculation, as indeed it was. The place of attack was not perceived, since 
the great bulk of the evidence pointed to Japanese attacks in Southeast Asia (which were 
in fact initiated almost simultaneously). The time of the attack contributed greatly to its 
success, Sunday morning having been deliberately chosen because the bulk of the U.S. 
warships would then normally be in port. The strength of the attack of course was not 
anticipated (since it was not expected at all where it occurred), security and deception 
having effectively screened the movements of the Japanese task force.

 
The Problem of Deception
The Art and Science of Military Deception	
33
A second approach to types of surprise and deception, which is somewhat broader 
and perhaps more pertinent to strategic warning, is to examine the various methods or 
measures which may be used to achieve one or more of the foregoing types of surprise. 
We may identify roughly five of these: security, political deception, cover, active military 
deception, confusion and disinformation.
1. Security in itself is not strictly speaking a type of deception, in that it involves no 
active measures to mislead the adversary to a false conclusion, but is designed only to 
conceal preparations for attack. Thus the sophisticated analyst should take care to dis­
tinguish normal or routine security measures from true deception. Nonetheless, the line 
between deception and security is narrow and the two are very often confused. More­
over, an effective security program often can do much to mislead or deceive the intended 
victim of attack even if no more sophisticated measures are undertaken. Although secu­
rity alone will not normally lead the adversary to undertake the wrong preparations or 
to deploy forces incorrectly, it may lead him to undertake very inadequate countermea­
sures or even to fail to alert his forces at all if security is totally effective.
In general, the greater the number of military measures which must be undertaken 
for the operation, and the larger the mobilization and deployment of forces required, 
the less likely it is that security alone can mislead. Whaley cites the views of Clausewitz 
that the high visibility of large-scale operations makes their concealment unlikely, and 
that true surprise is therefore more likely to be achieved in the realm of tactics than in 
strategy. This in fact has been borne out in recent examples. Although it was possible in 
large measure to conceal the military deployments required for the closure of the Berlin 
sector borders, it was not possible to conceal those for the invasion of Czechoslovakia, 
and in fact the USSR made no particularly great effort to do so. Some writers have ar­
gued that modern collection systems and communications will make security measures 
even less effective in the future—and this, would appear likely to be the case. Thus, the 
prospects are that various forms of active or deliberate deception will assume even more 
importance if surprise is to be achieved.
2. Preeminent among such methods is political deception—probably the easiest of 
all deception measures and possibly the most common. While political means may be 
used to promote tactical surprise, this method is of particular value as a strategic mea­
sure to conceal intent. Moreover it is one of the most economical means of deception 
and one in which the likelihood of disclosure is remote, since so few people need be 
involved in the plan. There are a variety of political deception tactics, of which we will 
note a few:
The direct or indirect falsehood may be put forth through diplomatic channels, of­
ficial statements, the press or other media. In its simplest and most crude form, the state 
simply denies that it has any intent whatever of doing what it is preparing to do and as­
serts that all such charges are false—a method sometimes used, particularly if the stakes 
are very high. The more subtle method of the indirect falsehood is often preferred, how­
ever, and permits the leadership to maintain some degree of credibility after the event, 
or at least to deny charges of outright prevarication. This tactic was used by the USSR 
in a number of its public statements prior to the Cuban missile crisis, for example in 
the celebrated TASS statement of 11 September 1962 in which the USSR stated that all 
weapons being sent to Cuba were “designed exclusively for defensive purposes,” and 
that there was “no need” for the USSR to deploy its missiles to any other country.
Another method of political deception which has often been used, particularly to 
lull suspicions in the relatively short term as final preparations for the attack are being 

The Problem of Deception
34 
The Art and Science of Military Deception
made, is to offer to enter into “negotiations” to discuss the matter at issue when in 
fact there is no intention of reaching any sort of agreement. This tactic was used by the 
USSR on the eve of the counterattack to suppress the Hungarian revolt in November 
1956, when Soviet officers opened negotiations with the Hungarians on Soviet “troop 
withdrawal.” A form of this ruse was also used by the North Koreans for about two 
weeks before the attack on South Korea in 1950 when they issued “peace proposals” 
calling for a single national election.
Whaley identifies a slightly different form of this deception tactic, which is to lead the 
adversary to believe that the firm decision to attack is actually bluff. “This is a fairly com­
mon type of ruse, one intended to restore the initiative and insure surprise by implying that 
options other than war are still open, thereby concealing the full urgency of a crisis and 
encouraging the intended victim in the belief that he has more time and more options than 
is, in fact, the case.”7  He notes that this ruse was used at Port Arthur, at Pearl Harbor, in the 
German attack on the USSR in 1941, by the British in the attack at Alamein in 1942, and in 
the Israeli attack on Egypt in 1967.
A somewhat similar and relatively subtle form of political deception is to downplay 
the seriousness of the situation in diplomacy and in public statements in an effort to 
create the impression that the nation does not consider its vital interests at stake, or that 
its relations with the intended victim are pretty good or even improving. This may result 
in a quite sudden shift in propaganda to a more conciliatory tone, and friendly gestures 
to the adversary, after the decision or at least contingency decision to attack has already 
been reached. This is a quite common tactic, and one in which dictatorships are usually 
masters, particularly since their complete control of the press makes a shift in the pro­
paganda line so easy. The USSR employed this tactic for weeks and even months prior 
to its attack on Japanese forces in Manchuria in August 1945, when it undertook an os­
tensible easing of tensions with Japan and began to be “almost cordial” to the Japanese 
Ambassador in Moscow, while the buildup of forces for the attack was under way in the 
Far East. The effort to deceive by political means will often entail not only the deception 
of many of one’s own people, but may extend on occasion even to the leadership of al­
lied nations, if the issue is of sufficient importance. And true practitioners of the art of 
deception even have been known to deceive their superiors (by failing to inform them of 
their plans)—although clearly this is a risky business undertaken only in the interests of 
tactical surprise for a specific military operation when war already is in progress.
3. Cover (here meaning the “cover plan” or “cover story”) is a form of military 
deception which should be distinguished from active military deception, although it 
may often be used in conjunction with it. Cover will be used when it may be presumed 
that the military buildup itself cannot be concealed from the adversary, and its purpose 
therefore is to offer some seemingly plausible explanation (other than planned aggres­
sion) for the observable military activity. It may involve simply the putting out of false 
statements about the scale or purpose of the military buildup in order to conceal the 
real intention by attributing the military preparations to something else. Throughout 
history, the most usual explanation offered has been that the troops are “on maneu­
vers,” although it is possible to think of other pretexts which might sometimes be used 
to explain troop movements, such as an alleged civil disturbance or disaster in a border 
area. The likelihood that the pretext of maneuvers would be used by the USSR to mask 
preparations for aggression was long recognized by Western intelligence, and the USSR 
7.	
 Whaley A548.

 
The Problem of Deception
The Art and Science of Military Deception	
35
and its Warsaw Pact allies also professed to believe that NATO exercises could serve as 
a cover for attack.
Despite our presumed understanding of this tactic, the USSR achieved at least partial 
success with its several announcements during July and August of 1968 that its troops 
were engaged in various “exercises” in the western USSR and Eastern Europe. In fact, 
there were no bona fide exercises and the sole activity under way was the mobilization 
and deployment of Soviet and Warsaw Pact forces for the invasion of Czechoslovakia.
4. Active military deception is at once the most difficult form of deception to carry 
out, at least on any large scale, and also one of the most effective and successful. If secu­
rity and political deception measures are most effective in lulling suspicions as to intent, 
active military deception is the primary means whereby the adversary is led to misde­
ploy his forces and to prepare for an attack at the wrong place and the wrong time. Even 
when strategic deception has failed, or was never possible in the first place, positive 
military deception has proved enormously effective in achieving tactical surprise, and 
hence in gaining victory and/or greatly reducing the attacker’s casualties in the opera­
tion. Whaley in his treatise has compiled some impressive statistics on the effectiveness 
and rewards of positive deception operations, some of which have been so valuable and 
successful as literally to affect the course of history (as in the Normandy invasion).
The successful military deception operation may range from a relatively simple hoax 
or feint to a highly complex series of interrelated and mutually consistent measures all 
designed to create the wrong impression in the mind of the adversary (or to support his 
original but false conceptions) as to timing, nature, strength and place of the attack. 
Among the recognized techniques of active military deception are:
••
Camouflage of military movements and of new military installations
••
Maintenance of dummy equipment at vacated installations or in areas of the front 
where the attack is not to occur
••
The simulation of a great deal of activity using only a few pieces of military equip­
ment moving about
••
The use of noisemakers or recordings to simulate a lot of activity
••
The planting of seemingly valid, but actually false, military orders in the hands of 
the adversary
••
The sending out of “defectors” with seemingly plausible but false stories
••
The use of doubled agents for the same purpose
••
The sending of invalid military messages by radio in the clear or in ciphers which 
the adversary is known to be reading 
••
The maintenance of normal garrison communications while the units themselves 
deploy under radio silence
••
The establishment of entirely spurious radio nets to simulate the presence of forces 
which do not exist at all or to convey an impression of a buildup of forces in some 
area other than the planned attack
••
A concentration of reconnaissance, bombing or artillery fire in an area other than 
the area of attack, or at least the equalization of such activity over a wide area so 
that the actual area of attack is not discernible from such preparatory measures

The Problem of Deception
36 
The Art and Science of Military Deception
••
False announcements or other deception as to the whereabouts of leading 
commanders
••
Obvious training exercises for a type of attack (such as amphibious) which is not 
planned
••
False designations for military units
••
Actual deployments or feints by ground or naval units to simulate attack in the 
wrong area
••
The use of enemy uniforms and other insignia
••
Announcements that leaves are being granted on the eve of attack, or even the ac­
tual issuance of numerous passes for a day or so just prior to attack
The above list does not exhaust the tricks and ruses which have been devised and 
successfully used in military operations. Such active deception measures of course are 
often supplemented by political and propaganda deception measures, cover stories and 
extremely tight security on the real military operation. Thus the effect of the measures 
collectively can be the total misleading of the adversary as to the coming attack, even 
sometimes when he has accepted its likelihood and indeed may be well prepared for it 
in other respects.
It is obvious that a number of ruses cited above would be of limited use, and indeed 
could be counterproductive, in a strategic deception designed to conceal that an attack 
is planned at all, or in any area. In such cases, one does not wish to stir up a lot of mili­
tary activity, or plant false documents about impending attacks, which will only arouse 
suspicions and stir the enemy’s intelligence services into greater collection efforts. Some 
measures, such as bombing and artillery fire or even highly obvious and unusual recon­
naissance, cannot be undertaken at all before hostilities have begun. For these reasons, 
some of the time-honored devices of military deception would not be used prior to an 
initial surprise attack which opens a war, the attack with which strategic warning is 
particularly concerned. At the same time, the reader can easily see that a substantial 
number of the tactics cited above could be most effectively applied to deceive us in a 
period prior to the initial attack. Among the ruses which should particularly concern 
us are: communications deception, especially the maintenance of normal communica­
tions accompanied by radio silence on deployments; planted military orders and other 
documents; the use of false defectors and doubled agents; and any of the other measures 
which might be used effectively to distract us from concentrating on the preparations 
for the real attack. For we may be reasonably certain that the greater and more impor­
tant the operation, the greater and more sophisticated will be the positive deception ef­
fort. The fact that we have encountered relatively few cases of active military deception 
since World War II should not reassure us—in fact, it only increases our vulnerability.
5. Confusion and disinformation probably rank second only to political deception 
in the ease with which they can be used to mislead and distract the opposition. Confu­
sion and disinformation tactics do not have to be highly sophisticated to be successful, 
although of course they may be. Even an elementary program to flood the market with 
a mass of conflicting stories and reports can be highly effective in distracting the time 
and attention of analysts and their superiors from the reliable intelligence on which 
they should be concentrating their efforts. Particularly if a crisis atmosphere already 
exists, as is highly likely, and some of the reports are sensational but have some degree 

 
The Problem of Deception
The Art and Science of Military Deception	
37
of plausibility, they can prove to be a tremendous distraction. If the volume of such 
planted information is large enough, the analytical system can literally be overwhelmed 
to a degree that some important and valid facts become lost in the mill, and others are 
not accorded their proper weight.
Moreover, such a mass of material compounds immeasurably the problem of ana­
lyst fatigue, always a factor in crisis situations, and may tend to generate a series of “cry 
wolf” alarms which will reduce the credibility of the authentic warning when or if it is 
received.
A conspicuous example of the damage that can be done by a large volume of false 
or unevaluated information was in the Chinese intervention in Korea in October-No­
vember 1950. This is not to say that the Chinese themselves necessarily had devised a 
sophisticated or extensive disinformation program. It is probable that a high percentage 
of the mass of spurious and contradictory reports which so confused the situation that 
summer and fall was never planted by the communists at all but was rather the product 
of the several highly productive paper mills in the Far East.
Most of those who have examined the intelligence failure that year have given al­
together too little, if indeed any, attention to the adverse effects of the volume of this 
spurious material on the analytical process. Regardless of the origins of the material 
in this case, something of the same problem could surely arise again in another crisis 
should our adversaries choose to exercise their full capabilities to employ such tactics.


39
C H A P T E R  7 
Deception Maxims: Fact and Folklore1
L. Daniel Maxim
Dr. L. Daniel Maxim earned a Ph.D. from New York University in engineering and sci­
ence. After a brief but important role contributing to deception studies, he subsequently 
went on to serve as President of Everest Consulting Associates.  An active member of 
the Coast Guard Auxiliary, his continued research has specialized in toxicology and 
epidemiology.
We only list Maxim’s ten concise maxims, thereby condensing his 50 pages to a 
more acceptable two.
1.	 Magruder’s Principle: It is generally easier to induce a target to maintain a pre‑ex­
isting belief than to deceive him for the purpose of changing his belief.  The Ger­
mans did this to the Americans in their winter offensive in the Ardennes in 1944, 
Operation WACHT AM RHINE [Watch on the Rhine].  Even that code name 
suggested a defensive operation, which is what the Americans assumed would 
occur.
2.	 There are limitations to human information processing that are deceptively 
exploitable.
•	 The “law of small number” means that you should not make conclusions based 
on a small set of data; there’s no statistical certainty in doing so.
•	 There is a frequent inability of targets to detect small changes in friendly indica­
tors, even if the cumulative change over time is large. This is the basis for using 
conditioning (cry-wolf) as a deceptive technique. 
3.	 Multiple Forms of Surprise: You can achieve surprise in the following categories: 
size, activity, location, unit, time, equipment (SALUTE), intent, and style (the 
manner/intensity with which you execute missions).
4.	 Jones’ Lemma: Deception generally becomes more difficult as the number of 
sources available to the target to confirm the “real” increases. However, the 
greater the number of sources that can be deceptively manipulated, the greater 
the chance that you can provide the target “confirming, all-source intelligence.” 
5.	 Choice of Types of Deception: Ambiguity-reducing deceptions can be employed 
to make the enemy quite certain, very decisive, and wrong.  Ambiguity-enhancing 
deceptions can be employed to mask your efforts when the target already has in 
his possession some elements of “friendly indicator truth,” thus creating “noise.”
6.	 Husbanding of Deception Assets: It may be wise to withhold the employment of 
deception capabilities until the stakes are high. The Soviets know we’re revital­
izing our deception capabilities, so let their intelligence-collection and decision-
1.	
Central Intelligence Agency, Office of Research and Development, Deception Research Program, Deception Max­
ims: Fact and Folklore, Washington: Office of Research and Development, Central Intelligence Agency, 1980, pp. 
4-40.

Deception Maxims: Fact and Folklore
40 
The Art and Science of Military Deception
cycle folks continually contend with “our threat,” while friendly commanders 
employ it at the time and place of their choosing.
7.	 Sequencing Rule: Deception activities should be sequenced to maximize the por­
trayal of the deception story for as long as possible. Unit activities indicating the 
true mission should be masked (operational security, or OPSEC) to the last pos­
sible instant.
8.	 Importance of Feedback: An intelligence collection scheme should be employed 
to determine if the deception is being adopted, rejected, or deceptively countered. 
Deception-related Primary Intelligence Requirements/Intelligence Requirements 
(PIR/IRs) should be nominated and Named Areas of Interest/Tactical Areas of 
Interest (NAI/TAIs) established to facilitate feedback on and exploitation of the 
deception.
9.	 The Monkey’s Paw: Deception efforts may produce subtle, unwanted reactions 
from the target and friendly units. Effect proper coordination in order to ensure 
that deceptions don’t result in unit fratricide. Also, make sure that the deception 
objective is framed in terms of what you want the target to do, rather than think. 
The 23rd Headquarters-Special Troops was a Top Secret Organization attached 
to the U.S. 12th Army Group Headquarters in World War II. This 1100-man 
unit conducted 21 deception operations from 1944–1945. In Operation BREST, 
it portrayed an armor attack build-up, which was apparently believed by the Ger­
mans, because—due to lack of coordination—an actual armored unit tried to 
attack in that area. In another similar operation, the weakened German division 
opposite the phony armor build-up believed the story. However, the German com­
mander, feeling that he was about to be overrun by U.S. armor, launched a spoil­
ing attack—definitely not what the American commander had wanted him to do.
10.	 Care in the Design of Planned Placement of Deceptive Material: Generally, if the 
target’s intelligence collection system has to “work for” the deceptive indicators 
you want to portray, the greater the likelihood he’ll accept them as “truth.” You 
can’t baldly “announce” what you’re doing, or he’ll be suspicious.

41
C H A P T E R  8 
The Principle of Naturalness
Barton Whaley
I think anything out of the ordinary routine of life well worth reporting.
—Sherlock Holmes in The Hound of the Baskervilles (1901)
Each time an animal shifts from its natural rhythm, there is a reason, and thus an 
opportunity for us to ask why.
—Mark Elbroch, Mammal Tracks and Sign (2003)
To protect against the nemesis of inconsistency the magician deploys a cloak of natural­
ness. For magicians, naturalness is the result of making each sleight or other conjuring 
move simulate some normal gesture, action, or posture. Similarly, they build all their 
tricked props (gimmicks) to simulate common objects. They do this precisely in order to 
avoid having the spectators notice the secret actions or suspect the gimmick.	
Note that the word naturalness, like many others in conjuror’s jargon, has a mean­
ing quite oblique to that in standard English; in this case, naturalness means feigned 
naturalness. Most top-class performers will go to great effort to develop this quality in 
both the design and practice of their tricks. Success in this is, perhaps, the highest test 
of their art. Indeed, as the great Swedish-American sleight-of-hand artist, Nate Leipzig, 
confessed, “There are a lot of good tricks which I never touch for some moves in them 
are not natural.”
The practice of “naturalness” is itself a deceptive technique to lull suspicion. As 
magician Jean Foley said in 1924, “Naturalness is the mother of misdirection.” Audi­
ences look for tricky moves and overlook those that seem natural even when they aren’t. 
Naturalness can also be contrived by conditioning an audience to accept certain moves 
as being innocent. For example, the magician may need one unfamiliar and hence un­
natural move to work a particularly effective trick. She will overcome this telltale by in­
troducing it several times during a previous trick where it will be seen as truly innocent. 
Therefore it is either accepted without notice or, at worst, noticed but quickly dismissed 
as merely some idiosyncratic gesture of the performer, something to do with general 
performing style and not with some specific secret method. By repetition, the unnatural 
has become natural, a new deception asset to be used when needed.
The concept of naturalness was kicking around in French magic circles since 1853 
when Ponsin added it to his friend Decremps’ list of the “Immortal Principles,” urging 
magicians to use only natural moves in both sleights and feints. And French master 
illusionist Robert Houdin perpetuated this rule in 1868 in advising that “The more 
simple and natural the movements of the performer, the less likely is the spectator to 
detect the trick.” However the word and concept have come to be associated with the 
late Dai Vernon because this modern Canadian master sleight-of-hand artist made it the 

The Principle of Naturalness
42 
The Art and Science of Military Deception
keystone of his teaching and performance. Vernon began to work up this notion around 
1903 when at age 8 or 9 he got his first book on how to cheat at cards, Artifice Ruse and 
Subterfuge at the Card Table: A Treatise on the Science and Art of Manipulating Cards. 
Of all the many books on the subject, this one by the mysterious S. W. Erdnase was (and 
still is) the best by far; Vernon quickly memorized this superb textbook. Erdnase points 
out that all deceptive actions “must be in perfect harmony with the usual procedure of 
the game.” In addition, the cheat must observe the “inviolable rule” of “uniformity of 
action,” namely, “Any departure from his customary manner of holding, shuffling, cut­
ting or dealing the cards may be noticed, and is consequently avoided.” Thus “Whether 
the procedure is true or ‘blind’ the same apparent action is maintained throughout.”1
The problem of simulated naturalness in magic has been analyzed in depth by the 
late Spanish master, Arturo de Ascanio, in The Psychology of Palming.2 There, he ar­
gues that a playing card is never suspected of being palmed, even for a long time, if the 
performer maintains naturalness in all gestures, posture, and actions with the “sinning 
hand.” He explains that “The attentive eye of the spectator will not see anything, it will 
glide over the palming hand, like the look of a warlike observer over a well hidden gun: 
nothing unusual is seen ....”
To achieve this apparent but false naturalness requires analyzing each trick in min­
ute detail. Each weak point must be found and every discrepancy in it identified. Then 
each discrepancy either must be hidden within some natural gesture, posture, or action 
or must be shown to have some plausible but false reason. For example, relaxed han­
dling can keep a palmed coin hidden indefinitely. Similarly, a two-headed coin may be 
openly shown or a gaffed card shown as an implicit part of an otherwise honest packet 
of cards.
Magicians who use unnatural moves are engaging in “conjuring for conjurors,” 
which entertains only when the spectators are other magicians ever-eager for a new ef­
fect or a new method at whatever cost in naturalness.
Some military deceivers use this technique of simulated naturalness. For example, 
mobilization is conventionally interpreted by intelligence analysts as a preliminary to 
war. To hide this common telltale, the Egyptian Army mobilized and partially mobilized 
several times during the months before their attack on Israel in 1973. The Israeli ana­
lysts, partly lulled, discounted the final genuine mobilization that came at Yom Kippur.
Three spectacular tactical military examples were the three successive British and 
Anzac withdrawals from their beachheads on Gallipoli during the 31 days between 
December 8, 1915, and January 9, 1916. They did this in the face of a disciplined and 
aggressive force of 120,000 Turkish and German troops that had the beaches in full 
view from the cliffs. London expected to lose between 25,000 and 40,000 men out of 
their total force of 120,000 plus all material.  However, Lt.-Gen. Sir Charles Monro 
ordered that all visual and audible signs of activity outside the tents simulate normalcy 
while actual withdrawals took place under cover of night. The three withdrawals had 
gone undetected and unopposed—his ruse had worked. With only 10 casualties, Monro 
1.	
S. W. Erdnase, Artifice Ruse and Subterfuge at the Card Table: A Treatise on the Science and Art of Manipulating 
Cards, Chicago, 1902, pp. 11, 22.  All subsequent reprints give the main title as The Expert at the Card Table. See 
also Gerritt M. Evans, How Gamblers Win: or, the Advantage Player’s Manual, New York: Gerritt M. Evans & 
Co., 1865, pp. 82–83.
2.	
Arturo de Ascanio, The Psychology of Palming, Madrid, 1982, pp. 5–6.

 
The Principle of Naturalness
The Art and Science of Military Deception	
43
got his entire Allied force of 120,000 safely evacuated—plus nearly 95% of its artillery 
and horses.3
Conclusion
Examples of systematic and comprehensive application of the Principle of Naturalness 
are rare in military practice and almost entirely overlooked by military theory and mili­
tary doctrine. I suggest that these three gaps be promptly filled. The most obvious lesson: 
Keep your deception plans simple, if you expect to keep them so seemingly “natural” 
that the enemy won’t attract suspicion.
3.	
The only case study of these extraordinary events is Whaley, Stratagem, 1969, pp. A56–A65.


45
C H A P T E R  9
Tactical Deception in Air-Land Warfare
Charles Fowler and Robert F. Nesbit
Charles Fowler was a member and served as chairman of the Defense Science Board 
(DSB).  This article is based on a 1982–83 report done by the DSB. Fowler went on to 
serve as president of C.A. Fowler Associates.  
Robert F. Nesbit earned his Master’s degree in electrical engineering from North­
eastern University and his was Vice President of the Center for Integrated Intelligence 
Systems at the Mitre Corporation at the time this article was written.  In that position, 
he led the center serving the Department of Defense for the integration of intelligence 
systems.

Tactical Deception in Air-Land Warfare
46 
The Art and Science of Military Deception

 
Tactical Deception in Air-Land Warfare
The Art and Science of Military Deception	
47

Tactical Deception in Air-Land Warfare
48 
The Art and Science of Military Deception

 
Tactical Deception in Air-Land Warfare
The Art and Science of Military Deception	
49

Tactical Deception in Air-Land Warfare
50 
The Art and Science of Military Deception

 
Tactical Deception in Air-Land Warfare
The Art and Science of Military Deception	
51

Tactical Deception in Air-Land Warfare
52 
The Art and Science of Military Deception

 
Tactical Deception in Air-Land Warfare
The Art and Science of Military Deception	
53


55
Section III:
Myths of Deception 
Introduction
First, let’s dispel a few of the myths that inhibit our ability to understand deception. 
The following quotations illustrate “The Tangled Web vs. the KISS Principle.”
O, what a tangled web we weave, 
When first we practise to deceive!
—Sir Walter Scott, Marmion (1808), Canto 6, Stanza 17
“Keep it simple, stupid” — KISS — is our constant reminder.
—Kelly Johnson, lead engineer of Lockheed’s top secret  “Skunk Works,”
More Than My Share of It All (1985), 161
“O what a tangled web we weave
When first we practise to deceive!
But when we’ve practised quite a while
How vastly we improve our style!”
—J. R. Pope (died 1941), “A Word of Encouragement” in Punch
This section exposes one general and three specific myths about deception.  The 
first, “The Tangled Web vs. the KISS Principle,” is particularly important because it 
tends to inhibit commanders and their staffs from adopting deceptive strategies and tac­
tics.  The next three readings are exposés of specific myths and one outright fabrication 
that have distorted the historical record. 


57
C H A P T E R  1 0 
Meinertzhagen’s False Claim to the Haversack 
Ruse (1917)
Barton Whaley
If you do not like the past, change it. ... Changing the past, especially through 
forgery and myth-making, may well be the most serious of all the abuses of 
history.
—William L. Burton1
The Meinertzhagen myth began soon after the end of World War One.  Richard Mein­
ertzhagen was a major in the British Army in the early 1920s.  However, he was well into 
his 40s and his long but undistinguished military career was failing.  He did not like his 
past.  So he began to change it.
Even in a nation that celebrates its eccentrics, Richard Meinertzhagen was an out­
standing British example, and in the narrow world of military deception and intelligence 
he was a giant—until 1993.  There had been occasional derogatory rumors, tightly held 
among colleagues and acquaintances, during his life but none in print until he’d been 
safely dead for four years.  In 1971, journalist and former MI-6 station chief Malcolm 
Muggeridge publicly labeled his first cousin “a fantasist full of tall stories which varied 
in the telling and were often, to me, totally incredible, though all calculated to make 
him appear a man of stupendous courage, resourcefulness and ruthlessness.”  However, 
being undocumented, all of these otherwise yellow-flag allegations had been dismissed 
out of hand and, it can be argued, rightly so.  Then came 1993, the vintage year when a 
few researchers began to back bare assertions of Meinertzhagen’s deceptions with some 
solid scraps of checkable evidence.  Oliver and Boyd pioneered the hard job of win­
nowing the facts of his life from the fictions.  However, Meiner, as Lawrence of Arabia 
called him, was the antithesis of most legendary figures — those quiet doers on whom 
we impose heroic fictions.  He actively invented and promoted his own legend.  Indeed, 
far more so than such other tellers of tall tales, as his friend Lawrence or the likes of 
Ernest Hemingway or Orson Welles.  Where their kind would exaggerate and embellish 
an already good story, Meinertzhagen preferred creative invention, and to such a degree 
that he became more myth than legend, more fake than fact, more lie than truth.  The 
prime example:
“Spent today in deceiving the enemy.  I have been busy lately compiling a dummy Staff 
Officer’s notebook containing all sorts of nonsense about our plans and difficulties.  To­
day I took it out to the country north-west of Beersheba with a view to passing it on to 
1.	
 William L. Burton, “The Use and Abuse of History,” The American Historical Association Newsletter, Vol. 20, 
No. 2, February 1982.

Meinertzhagen’s False Claim to the Haversack Ruse (1917)
58 
The Art and Science of Military Deception
the enemy without exciting suspicion.  ...  I was well mounted and near Girheir I found 
a Turkish patrol who at once gave chase.  I galloped away for a mile or so and then they 
pulled up, so I stopped, dismounted and had a shot at them at about 600 yards.  That 
was too much for them and they at once resumed the chase, blazing away harmlessly all 
the time.  Now was my chance, and in my effort to mount I loosened my haversack, field-
glasses, water-bottle, dropped my rifle, previously stained with some fresh blood from my 
horse, and in fact did everything to make them believe I was hit and that my flight was 
disorderly.  They had now approached close enough and I made off, dropping the haver­
sack which contained the notebook and various maps, my lunch, etc.  I saw one of them 
stop and pick up the haversack and rifle, so I now went like the wind for home and soon 
gave them the slip, well satisfied with what I had done and that my deception had been 
successful.  If only they act on the contents of the notebook, we shall do great things.”
— Meinertzhagen’s Diary entry for 10 Oct 1917 at Rafa, Palestine.2
This is an excerpt from the mendacious diary-memoir of Britain’s most imaginative 
deception planning-operating impostor of the Great War, serving in the East African 
and Palestine campaigns.  His lies inspired the unwitting General Wavell, who at the 
outset of  WWII became the mentor of Brigadier Dudley Clarke and Peter Fleming and 
thence to Col. John Henry Bevan and Sir John Masterman in London and from them 
to the American Army.
Although Meinertzhagen falsely claims credit for all (or virtually all) of the exten­
sive material on deception and intelligence operations, it does serve to show that these 
activities were in use not just at the time of his later interpolations, but also where 
independently verified (probably contemporarily) with the historical events described.  
Consequently, his book retains some marginal value as the basis for hypotheses about 
these matters and as leads to where to start research. 
2.	
 Richard Meinertzhagen, Army Diary: 1899–1926, London: Oliver and Boyd, 1960, pp. 222–223, 283–286.

59
C H A P T E R  11 
The Ultra Secret: Enigma Unwrapped 
A Review of F.W. Winterbotham’s The Ultra Secret1
David Kahn
David Kahn received his doctorate degree from Oxford University in 1974 and worked 
as an op-ed editor for Newsday until 1998.
Wing-Commander “Freddie” Winterbotham’s The Ultra Secret2 became a stunning 
best-seller when it first appeared in 1974.  Although wildly applauded at the time, Kahn, 
America’s world-class amateur historian of cryptology, is one of the few who recognized 
some of the very serious weak parts of Winterbotham’s memoir.
This book reveals the greatest secret of World War II and intelligence buffs.  But it has 
to be read with caution.  
“The Ultra Secret” tells how the British and the Americans exploited the informa­
tion they obtained from cracking German messages enciphered with a cipher machine 
named the “Enigma.”  So valuable was this intelligence that it was given a special 
security classification, “Ultra,” which the intelligence itself came to be called.  The 
author, an R.A.F. officer, was put in charge of distributing Ultra under tight security to 
Churchill and to commands around the world.  Winterbotham therefore saw much of 
the output and in this book has correlated it with the events of the war. 
The stories he tells are revelations.
During the Battle of Britain, Ultra told the R.A.F. Fighter Command well in ad­
vance of radar detection how many bombers would be thrown 
against England and when.  This enabled the British to parcel 
out their few fighters so that some would always be available 
to attack an oncoming wave.  These tactics denied the Ger­
mans command of the air over England and consequently any 
possibility of invasion.  
During the campaigns in North Africa, Ultra kept Gen. 
B.L. Montgomery informed fairly exactly of Gen. Erwin Rom­
mel’s order of battle and, in some cases, of his plans.  It also 
enabled the British to know when supply ships would sail from 
Italy—and to sink them, thus eventually starving Rommel of 
1.	
David Kahn, “The Ultra Secret: Enigma Unwrapped,” New York Times, December 29, 1974.  A review of F.W. 
Winterbotham, The Ultra Secret, UK: Littlehampton Book Services, Ltd., 1974. From The New York Times, De­
cember 29 © 1974,  The New York Times. All rights reserved. Used by permission and protected by the Copyright 
Laws of the United States. The printing, copying, redistribution, or retransmission of this Content without express 
written permission is prohibited.
2.	
 F.W. Winterbotham, The Ultra Secret, New York: Dell, 1975.

The Ultra Secret: Enigma Unwrapped A Review of F.W. Winterbotham’s The Ultra Secret 
60 
The Art and Science of Military Deception
vital fuel.  Another intercept led to the Battle of Cape Matapan, which turned the Medi­
terranean from an Italian to a British lake.  
The tide of the Battle of the Atlantic turned when Ultra dug deep into the naval 
Enigma in 1943 and revealed where the U-boats met their milch-cow supply subma­
rines.  Throughout the tough fighting in Normandy, Ultra delivered masses of intercepts 
from Hitler’s messages on down, often within hours of their dispatch.  This, “probably 
Ultra’s greatest triumph,” Winterbotham says, led to the “destruction of a large part of 
the German Army in the west.”
Dozens of such stories crowd “The Ultra Secret” which is filled as well with sketch­
es of the famous as Winterbotham, this bringer of good and bad tidings, saw them 
(Churchill was always polite).  This makes exciting reading, and it constantly provides 
fresh insights into some of the best-known episodes of the war, for even the official 
historians did not have access to Ultra intercepts.  The new material makes the book 
essential to the historiography of World War II.  
But all is not exactly as Winterbotham tells it.  He exaggerates the importance of 
Ultra, calling it “decisive” and writing as though it alone won the war.  
Everyone now agrees that Ultra was of supreme importance, and that without it the 
war would have lasted longer.  Even Gen. Mark Clark, criticized here for not exploit­
ing Ultra properly during the Italian campaign, acknowledges that the reading of some 
Hitler signals saved his neck during the Anzio landings.  But neither Marshal of the 
Royal Air Force Sir John Slessor, who wrote the foreward, nor Vice Admiral Sir Nor­
man Denning, who was in charge of the Admiralty’s U-boat tracking room, would say, 
in answer to my questions, that without Ultra, Britain would have lost the battles of 
Britain and the Atlantic.  
Winterbotham, however, seems often to suggest that merely cracking the Engima 
sufficed to win the war.  Of course it did not: otherwise things would have been a lot 
easier.  But though Winterbotham himself sometimes gives cases where knowledge of 
German signals could not affect a battle, usually for lack of men or guns, cases where 
no messages were intercepted, and also cases where a change of plan falsified Ultra in­
formation, his attitude of Ultra-won-all negates them. 
This tone is the basic flaw of the book, the reason the general reader needs to salt 
its information with knowledge of how wars are won.  It is why the book is not history 
but merely a contribution to it.  One that has to be checked, at that.  
Winterbotham has written from memory 30 years after the events, using messages 
in the German archives to refresh his recollection of intercepts where he could, so it 
is not surprising that errors stipple the text.  The American solutions of the Japanese 
diplomatic and naval cryptosystems had nothing to do with the breaking of Enigma.  
Winterbotham’s attributing the original Enigma solution to information from a Polish 
employee of the cipher machine factory cheats the Poles of credit for one of the great 
cipher solutions of history.  The facts are these: 
On July 15, 1928, Polish cryptanalysts noticed a decided change in the letter fre­
quencies of German army cryptograms, which they were intercepting.  The Poles quick­
ly concluded that the Germans had begun using the Enigma, which was invented and 
publicly sold early in the 1920’s.  Purchase of one of the commercial models showed 
that the Reichswehr had altered it for secrecy.  
In 1932, the Polish Biuro Szyfrow (cipher bureau) got additional manpower in the 
form of three young mathematicians, Henryk Zygalski, Marian Rejewski and Jerzy Ro­
zycki.  They had achieved a partial solution in their office, hidden in the forest of Pyry 

 
The Ultra Secret: Enigma Unwrapped A Review of F.W. Winterbotham’s The Ultra Secret 
The Art and Science of Military Deception	
61
outside Warsaw, when Poland’s French allies furnished some key Enigma documents.  
Major Gustave Bertrand of French cryptographic espionage had obtained them from a 
Reichswehr cipher unit employee, Hans-thilo Schmidt, who wanted money.  (Bertrand 
has told this story in his book, “Enigma.”)  With this help, the Poles completed their 
solution, and on July 26, 1939, presented two reconstructions of the machine to the 
French and two to the English. 
These enabled the British codebreaking unit at Bletchley, a small town 50 miles 
northwest of London, to solve the later variations of the machine and other machines 
used for different branches of the German armed forces.  Security forbade Winterbo­
tham from recounting these details, but he properly and generously credits the achieve­
ment.  To generate up-to-the-minute solutions for these other machines, incidentally, 
the Bletchley geniuses evolved perhaps the first modern electronic computer, which they 
nicknamed the “Colossus.”
Why has the story remained under tight wraps so long?  It seems that after World 
War II, Britain gathered up as many of the tens of thousands of Enigmas as she could 
find and later sold them to some of the emerging nations.  Presumably if she could read 
Enigma messages in 1940, she could do so in 1950.  Only recently have these countries 
replaced their Enigmas with new cryptosystems.  


63
C H A P T E R  12 
The Ultra Variations: A Review of Anthony Cave 
Brown’s Bodyguard of Lies1
Michael Howard
This was the earliest overview of Allied deception operations against Germany in 
WWII. It involved seven years of research that covered a wealth of obscure documents 
and choice interviews. At the time it was published, it was a generally useful first break­
through into large parts of the previously classified literature. However, it was seriously 
marred by many gaps and several important errors of fact or interpretation. The most 
outrageous example was Brown’s faulty interpretation that, in 1940, Churchill had de­
liberately sacrificed the city of Coventry to German bombers rather than reveal the fact 
that the British were reading the German codes, a false story that has managed to stay 
ahead of the evidence, having been retold as recently as 2004 by American columnist 
George Will. However, the then U.S. President Carter’s Press Secretary, Jody Powell, 
was raving about this book to anyone who’d listen—strong evidence of how little under­
stood military deception had then been at the highest level of U.S. government became 
clear. Conversely, all the experts (Trevor-Roper, Michael Howard, Pforzheimer, Wheat­
ley, Constantinides, and J. Ransom Clark) were properly unhappy with the book’s high 
rate of errors of both fact and interpretation. Brown consistently proved in this and 
later books that his understanding of intelligence and military deception were consider­
ably less than he and the too-credulous main-line media reviewers believed. Fortunately, 
Brown’s book has been recently superceded by Holt (2004).
Mr. Brown (often incorrectly double-barrel surnamed “Cave Brown”), an English­
man, served in the RAF as a photographer, then as a newspaper reporter and  foreign 
correspondent, most notably for the Daily Mail (London) in the 1950s and early 1960s. 
He freelanced after 1962. Brown was famous for his outrageous expense accounts fu­
eled by a sybaretic lifestyle. He settled permanently in the United States in 1969 where 
he lived until his death in 2006.
The “Ultra” secret is secret no longer.  It seeped out gradually: there was never a single 
moment at which it was revealed, although publishers and journalist greet each new 
book of “ultra” memoirs as if it were a blinding flash of illumination.  Unlike the “Dou­
ble Cross system” – the total British control of German agents in the United Kingdom 
about which only a handful of people knew anything until Sir John Masterman broke 
ranks and told all – British interception and reading of German radio communications 
was known about by many thousands of people at the time and assumed to be taking 
place by anyone with any understanding of intelligence operations and signals systems.  
1.	
Michael Howard, “The Ultra Variations,” Times Literary Supplement, May 28, 1976. A review of Anthony Cave 
Brown, Bodyguard of Lies, New York: Dell, 1975.

The Ultra Variations: A Review of Anthony Cave Brown’s Bodyguard of Lies
64 
The Art and Science of Military Deception
The activities of the civil-military teams of cryptanalysts at Bletchley Park were a very 
open secret by the end of the war, and referred to with increasing frankness as the war 
years became more distant.  
What was not, and perhaps is still not, generally appreciated was the success with 
which the British had penetrated German ciphers, and the way in which they were able 
to turn their knowledge to operational effect.  Central to this success was the capture 
or reconstruction of the “Enigma” machines on which the German High Command 
enciphered its most sensitive traffic and which it believed to remain secure until the very 
end of the war.  The most sensational revelation of this was made by Group Captain 
Winterbotham, an RAF liaison officer who dealt with this material at Bletchley, in his 
book The Ultra Secret (1974).  But David Kahn had already dealt with “Enigma” in The 
Code Breakers (1967; and Gustave Bertrand’s Enigma (1973) has given us what surely 
must be a definitive account of the Allies’ acquisition and operation of the machine.  
Few of these works give any idea of the continuous baffling complexity of cipher 
breaking even once the “Enigma” machines had been reconstructed. Different branches 
of the German services used different keys: the settings were constantly changed: and 
though an occasional operational coup put the cryptanalysts in possession of a set of 
keys, it was exceptional for them to be able to read any set of traffic currently for any 
prolonged period.  Nor was “Enigma” the only system used by the enemy.  There were 
others no less ingenious which cryptanalysts had to solve without any adventitious aids.  
So the generalization that the Allies were “reading enemy signals traffic throughout the 
war” is very misleading.  We were reading some of it most of the time and most of it 
some of the time.  The operational contribution of the knowledge so gleaned still cannot 
be assessed from open sources.  
Something has been revealed, however, about the importance of “Ultra” for de­
ception operations.  To put it very briefly, our reading of German traffic gave us some 
idea of what they feared we might do, which enabled our deception staff to play on 
those fears.  Even more important, it enabled them to see how the enemy was swal­
lowing our deception measures.  A signal from a double agent could be traced from his 
Abwehr controlling officer upward through German channels of communication till it 
reached the intelligence authorities at OKW, and down again through the distribution 
of information and directives to the various Commands.  No less important, we knew 
what information was being derived from German agents in neutral capitals who were 
not under British control.  Without “Ultra” and the “Double Cross system”, Allied 
deception could never have played the central part which it did in ensuring that the 
overwhelming majority of allied offensive operations against Germany (Salerno being 
the striking exception) secured almost complete tactical surprise.  Some of the work of 
the deception staffs has become public knowledge.  The story of Operation Mincemeat 
in spring 1943, when bogus documents indicating an imminent assault on Greece rather 
than Sicily were planted on the Germans by means of an allegedly drowned liaison of­
ficer washed up on the beaches of Spain, has already been told by one of those chiefly 
responsible, Ewen Montagu, in his book The Man Who Never Was.  The massive de­
ception operations mounted in 1944 to persuade the Germans that the main allied as­
sault was being prepared against the Pas de Calais rather than Normandy were partially 
described by Chester Wilmot in The Struggle for Europe, and the role played by the 
double agents was filled in by Sir John Masterman in The Double Cross System.  But 
these were only the most spectacular successes of a continuous activity.  From 1942 
onwards not a single military operation of any magnitude was mounted by the Western 

 
The Ultra Variations: A Review of Anthony Cave Brown’s Bodyguard of Lies
The Art and Science of Military Deception	
65
allies in the European theatre without a deception element being included as an intrinsic 
part of the plan.  Bogus radio traffic, visual deception by dummies to foil aerial recon­
naissance, deliberately planted rumours, reports by double agents: all were as carefully 
organized and orchestrated as the movements of the forces themselves.  
These are the activities which Anthony Cave Brown sets out to chronicle in Body­
guard of Lies, or at least the activities which he originally set out to chronicle when he 
began work, by his own account, over twelve years ago.  In the writing, however, the 
book has swollen to such gargantuan proportions, and contains so many lengthy digres­
sions on such matters as the German Resistance, the French Resistance, and the per­
sonalities involved in them, that the original object is lost for scores of pages at a time. 
This is a pity, because the history of deception in itself is difficult enough to disen­
tangle, without access to information which still remains classified.  It has been made 
a great deal easier by the release in Washington of a great quantity of material which is 
still withheld in this country; but for purely British activities, particularly those relating 
to “Ultra” and “Double Cross”, the researcher is still dependent very largely on per­
sonal revelations of a very uneven kind.  Sir John Masterman’s book counts virtually as 
a primary source, since it was compiled from the original documents while the author 
was still working with MI 5.  Group Captain Winterbotham, on the other hand, was 
writing from memory thirty years after the event; while such autobiographies as that 
of Dusan Popov, one of the greatest double agents of the war, contain an entertaining 
quantity of straightforward fiction.  There are in addition the personal memories of the 
surviving participants, for what they are worth after a third of a century, but these are 
not worth much unless they can be checked against more contemporary evidence.  From 
the German side fortunately there is very complete documentation; and for those with 
a nose for such things unexpected treasures can be turned up in the records of the Navy 
and the RAF.   
In spite of these difficulties Mr. Cave Brown has worked like a Trojan and come 
across an enormous quantity of information.  For his sheer pertinacity he deserves very 
great credit indeed.  What he has not done however is even to try to evaluate how much 
of this information is relevant, and how much reliable.  It is hard to see why he includes 
information about, for example, German agents in Ireland, the assassination of Hey­
drich (in great detail), or the raid on German heavy water supplies in Norway – unless 
he hopes that this will help to sell the book.  
But more important than his irrelevances is his total lack of critical acumen.  Any 
story gets bunged down, whatever its source.  No distinction is drawn between the 
very accurate accounts of deception operations for Overlord in the SHAEF files, the 
highly questionable assertions of self-justifying or self-inflating autobiographers, and 
the obiter dicta of elderly gentlemen in their anecdotage.  Down they all go, facts, gos­
sip, rumour, irrelevances, speculation, to be smothered in a rich sauce of romantic prose 
(“In its long history of doom and intrigue many fanciful figures had passed through the 
Portcullis Gate of Edinburgh Castle – Claverhouse and the marquess of Argyll, Queen 
Margaret and the Duke of Gordon…”) and peppered liberally with solecisms, inaccura­
cies, and straightforward howlers.  
Some of the slips are just silly and venial.  Bradfield College is nowhere near Rugby, 
the Royal Patriotic Schools are not in Battersea, General Mason-Macfarlane did not 
negotiate the Italian surrender, Liddell Hart was not an adviser to Eisenhower nor Asher 
Lee to Churchill, Sir James Marshall Cornwall was not Vice-Chief of the Imperial Gen­
eral Staff in 1940, and so on.  None of these matter much, save as indicators of the 

The Ultra Variations: A Review of Anthony Cave Brown’s Bodyguard of Lies
66 
The Art and Science of Military Deception
sloppiness of Mr. Cave Brown’s work.  Other errors, though more understandable, are 
dangerously misleading.  “Special Means” did not include, as Mr. Cave Brown would 
have us believe, “a wide variety of surreptitious, sometimes murderous, always intricate 
operations of covert warfare”.  It was a term which British intelligence applied very 
specifically to the transmission of information to German intelligence, mainly through 
double agents: surreptitious and intricate certainly, but hardly murderous.  Nor did the 
Twenty Committee “control” any double agents – much less operate an interrogation 
centre.  The Twenty Committee was simply a liaison body between the armed forces, 
MI 5 and MI 6.  Double agents, as Hugh Trevor-Roper has already patiently explained 
in the New York Review of Books for February 19, were controlled by B-1a, a branch 
of MI 5, and the credit for their successful manipulation is due primarily to the head of 
that section, Colonel “Tar” Robertson.  To write the story of deception without even a 
mention of this organization is really to produce Hamlet without the prince. 
As for the solecisms, they are hilarious.  The Beaufort Hunt, we are informed, “was 
one of the most influential political groups in England … as much a political conspiracy 
as a sport”.  Mr. Ewen Montagu of Mincemeat fame, who went on to become a highly 
controversial figure as Chairman of Quarter Sessions and who was never even elevated 
to the High court Bench, became, we are told, “one of England’s great jurists”.  The 
movements of the Guards Armoured Division were falsely reported to the Germans 
because, according to Mr. Cave Brown, Rundstedt was expected to believe that “no 
general as blue-blooded as the commanding officer of the Guards Armoured, General 
Sir Allan Henry Shafto Adair (the sixth baronet, Harrow, Grenadier Guards, late gover­
nor of Harrow and Ensign of the King’s Bodyguard of the Yeomen of the Guard), would 
ever allow himself to be very far from the main battle at H Hour”.  Connoisseurs will 
regret the omission from the British edition of the splendid description in the American 
edition of this book of the gentle Colonel Oliver Stanley as being “a man of towering 
anger.  Had he not blackballed the Aga Khan for the Turf club?”  There are times when 
the astral body of the late Daisy Ashford seems to take over from Mr. Cave Brown and 
insert into his massive narrative a kind of military supplement to The Young Visiters.
Mr. Cave Brown has in fact a very substantial chip on his shoulder about the British 
aristocracy. His book is not so much popular history as populist history.  No opportu­
nity is missed of taking a crack at that poor old Aunt Sally, the British upper classes.  
The remarkable military record of Eton College is chronicled (with typical irrelevance) 
with the comment “it was said afterwards that Eton had produced lions with brains, but 
its critics claimed that it also produced leaders who were unscrupulous, opportunistic, 
and concerned only with the preservation of their class and Empire”.  Well, fair enough.  
No Harrovian would disagree.  But on it goes.  The skill and dedication of the British 
deception staff is ascribed to “a malevolence perhaps born of the realization that, if they 
failed, their class would not survive”.  In their attempt to keep their existence secret, we 
are told “they failed, just as they would fail to survive as a class”.  Finally their object 
is described as: 
not only the defeat of Hitler; it was also the preservation of the Empire and of Britain as a 
world leader.  Who could foresee that in winning a great victory over the most proficient 
military machine in the world … the secret bureaus of England would be unable to preserve 
the very entity they were sworn to maintain – the power of London? 

 
The Ultra Variations: A Review of Anthony Cave Brown’s Bodyguard of Lies
The Art and Science of Military Deception	
67
All this tells us at least as much about Mr. Cave Brown’s social prejudices as it does 
about the group he is trying to describe.  The historian can only regret that he should 
have allowed his vision to be so distorted, whether by a personal hang-up or by a desire 
to play to the gallery in the Middle West.  The lengths to which he goes to resurrect 
all the old, discredited Anglophobe myths of the 1950s—that British Mediterranean 
strategy was motivated by a desire to retain a strangehold on Arabian oil, that Brooke 
deliberately plotted to place Eisenhower in a position of elevated impotence, leaving all 
the significant jobs to the British-rather suggests the latter. 
None of it contributes notably to the history of deception which Mr. Cave Brown set 
out to tell.  Neither do his long digressions on the group which he terms “the Schwarze 
Kapelle”, the loose association of opponents to the regime within the German establish­
ment, of which Canaris, chief of the Abwehr, was supposed to be the leader.  The only 
serious reason for dragging this in would be to explain the truly astonishing inefficiency 
of the Abwehr’s operations against Britain.  But Mr. Cave Brown goes far beyond this 
in trying to prove a tortuous theory that, had it not been for “Ultra”, which gave them 
all the information they needed, the Allies would have responded more readily to the 
Schwarze Kappelle’s overtures; in which case their plots against Hitler might have suc­
ceeded, von Stauffenberg’s bomb would (presumably) have exploded to better effect, 
and the war been brought to an earlier and more satisfactory end. 
This at least appears to be the theory that Mr. Cave Brown is trying to prove; but 
so lush is his prose, so voluminous are his anecdotes, so labyrinthine are his digres­
sions that it is never entirely easy to see what he is getting at.  The same applies to his 
forays into the history of the French Resistance.  The breaking of the Prosper network 
may have been due to its premature alerting as part of an Allied deception operation, 
Starkey, in the summer of 1943, but then again it may not.  Mr. Cave Brown starts by 
asserting that it was. 
When the leaders of the resistance were stirred into activity in support of “Starkey”, the 
Germans reacted with savagery and cunning to destroy certain key clandestine organizations 
in France…A deception operation that might otherwise have been written off as a rather 
muddied rehearsal for a performance that was still many months in the future had been 
transformed into a tragedy.  
A few pages later this opinion is revised.  The Resistance leaders, we are told, were 
captured “as a result of the lack of security which attended their activities—some of 
which they had been instructed to take in support of Starkey [my italics]—and the dili­
gence of the S[icherheits] D[ienst]”.  That may well be nearer the mark.  But Mr. Cave 
Brown is unwise to step into the Serbonian bog of Resistance history without preparing 
himself rather more carefully, and one awaits with interest what the experts will have to 
say about this part of his work.  
It is rare however for Mr. Cave Brown to come out with a judgment even so forth­
right and unequivocal as this.  More frequently he leaves himself open a line of retreat.  
Some reported statement we are told “may have been close to the truth”, or “may not 
have been wrong”.  “There may”, we are told, for instance, “have been some truth in 
these charges”; or, alternatively, they “cannot be discounted”.  Such phrases as “It is 
conceivable that”, or “there are many who maintain that”, such rhetorical questions as 
“was there a connection?”, such forensic artifices as “by a remarkable coincidence—if 
it was a coincidence” occur throughout the work.  As a result Mr. Cave Brown further 

The Ultra Variations: A Review of Anthony Cave Brown’s Bodyguard of Lies
68 
The Art and Science of Military Deception
inflates his narrative with a wealth of sensational gossip for which he ultimately accepts 
no responsibility, instead of going through the no doubt tedious process of scrutinizing, 
evaluating and comparing his sources, discarding the evident rubbish, and producing a 
serious study based on evidence which he had satisfied himself to be correct. 
Had Mr. Cave Brown done this, one might be inclined to take rather more seriously 
what he has to say about such controversial issues as the Battle of Britain, the German 
air raid on Coventry, the Dieppe raid in August 1942 and the British air raid on Nurem­
berg in March 1944: matters on which the British press have recently quoted his views 
as if they were gospel truth.  
Let us take first the Battle of Britain.  Thanks to “Ultra”, claims Mr. Cave Brown, 
“Churchill knew that Hitler would not invade without aerial superiority, but he delib­
erately led the world to believe that Britain was in mortal peril in order to rally his own 
people to meet the threat and enlist the support and sympathy of the United States”.  
The only source quoted for this remarkable statement is the recollections of Group Cap­
tain Winterbotham.  Winterbotham is an insecure foundation for this, as for much else.  
In the summer of 1940 we were no doubt reading the Luftwaffe traffic, which provided 
an enormous tactical advantage in fighting the Battle of Britain.  But were we reading 
the traffic of OKW which alone might have indicated Hitler’s strategic intentions?  And 
if we were, would it have revealed a clear intention on the part of Hitler not to invade 
before he had secured aerial supremacy?  Did he indeed have any clear intentions at that 
time?  Did one need to have “Ultra” to appreciate that the Germans could not invade 
unless they had aerial supremacy?  Above all, how could “Ultra” or any other agency 
reveal that the Luftwaffe would not secure aerial supremacy, as indeed it very nearly 
did? 
The ubiquitous Winterbotham is also the sole source for Mr. Cave Brown’s claims 
about the Coventry raid on November 14, 1940, which have already received a great 
deal of publicity over here.  No other authority is quoted for the categorical statement 
“Ultra gave Churchill at least forty-eight, possibly sixty hours’ warning of the devastat­
ing raid that was planned for Coventry”.  And presumably Winterbotham is also the 
source for the following paragraph: 
But if no extraordinary defensive measures could be taken to protect Coventry, might not 
a confidential warning that their city was about to be attacked on a large scale be given 
to civic authorities and to the fire-fighting, ambulance and hospital services?  Should not 
the population of the inner city, together with those in hospitals who could be moved, be 
evacuated?  To all these propositions, Churchill said no; there must be no evacuations and 
no warnings…it would alert the German intelligence service to the fact that the British had 
foreknowledge of the raid. 
Apart from his cheerful assumptions about the administrative feasibility of evacu­
ating a hundred thousand people at forty-eight hours’ notice, one finds in Mr. Cave 
Brown’s narrative no attempt to check on whether Winterbotham’s memory after thirty 
years was entirely reliable.  Most of the records are still inaccessible, but a lot of the 
people involved are still around, and if Mr. Cave Brown had devoted a tithe of the time 
to questioning them that he did to exploring the ramifications of the Prosper network 
he might have come up with rather a different story. 
Intelligence sources, no doubt “Ultra” foremost among them, did indeed alert the 
British as early as November 11 to German intentions of launching a major raid on 

 
The Ultra Variations: A Review of Anthony Cave Brown’s Bodyguard of Lies
The Art and Science of Military Deception	
69
the United Kingdom in the near future, but they gave no indication of what the target 
would be.  It was in response to this original general warning that the RAF launched 
its ill-fated spoiling attack, Operation cold Water.  It was not in fact until the afternoon 
of November 14 that firm intelligence came through that the raid was due that nights, 
and that Coventry was the target.  This indeed is what Winterbotham states in his own 
book, whatever private communications he may have made to Mr. Cave Brown later.  
The effective warning which we had of the raid on Coventry was thus not forty-eight 
hours, let alone sixty.  It was about four. 
As for the Dieppe raid, Mr. Cave Brown alleges that Churchill deliberately allowed 
this to go ahead in full awareness of its sacrificial nature in order to persuade the Ameri­
cans of the impracticability of opening a “Second Front” in north-west Europe in 1942.  
More important for our purposes, he states that the central British deception staff, the 
London Controlling Section, headed by Colonel Oliver Stanley, was allowed to mount 
what they believed to be a deception operation which actually focused German atten­
tion on Dieppe.  When Colonel Stanley discovered how he had been used, we are told, 
he “resigned abruptly…He could no longer be a member of an entourage that would 
sacrifice or risk 5,000 loyal Empire troops to keep Russia in the war.”
For this very remarkable allegation Mr. Cave Brown quotes no source at all, and a 
very little gentle digging would have revealed to him the absurdity of the whole story.  
We know from the German documents that von Rundstedt’s headquarters was not par­
ticularly alerted to Dieppe as a possible target, although they were certainly kept on the 
qui vive along the whole of the coast of north-west Europe.  In any case the contribution 
of the London Controlling Section to this, if indeed it made any at all, must have been 
minimal.  Set up the previous autumn in response to a suggestion from Wavell, it was 
at this period under-staffed, inexperienced and entirely uninfluential.  Stanley himself 
was very sceptical as to what it might achieve and he gave it no impetus.  Several times 
he attempted to resign, and in fact did so in June, 1942, two months before the Dieppe 
raid, when the section was entirely reorganized under Colonel John Bevan.  So much 
for that canard. 
Let us in conclusion consider Mr. Cave Brown’s most contentious allegations, those 
bearing on the British air raid on Nuremberg on March 30, 1944.  This, it will be re­
called, was a disaster.  Allied bombers were directed in a single stream, under clear skies, 
against a target deep inside Germany, and suffered very heavy losses as a result.  The 
official figure was 108 aircraft lost on operations, which Mr. Cave Brown inflates by 
reference to unnamed confidential and semi-official sources, to 178. 
As always after a military catastrophe, there was an immediate crop of bitter ru­
mours to the effect that the operation had been betrayed in advance-rumours which Mr. 
Cave Brown treats as hard evidence.  The only corroboration he can produce is a re­
ported statement by General de Guingand some thirty years after the event, to the effect 
that “on at least one occasion the deception people were authorized to reveal the target 
of a major air attack on a German city to the Germans beforehand, in order to reinforce 
the credibility of an agent who was to be used to mislead the German high command”.  
This city he thought was Stuttgart but, says Mr. Cave Brown, “he could not be sure that 
it was not Nuremberg”.  General de Guingand has since categorically denied, in private 
correspondence, that the name of Nuremberg was mentioned at all.  In any case as Chief 
of Staff of 21 Army Group he would have had no responsibility for and little connection 
with any such operation.  The second pillar on which Mr. Cave Brown builds his case 
is also decidedly rickety. 

The Ultra Variations: A Review of Anthony Cave Brown’s Bodyguard of Lies
70 
The Art and Science of Military Deception
What about the course of the raid itself?  Does the evidence indicate that the Ger­
mans were expecting it?  Fortunately we have a most careful analysis of all the evidence 
on both sides by an independent and highly reputable historian, Martin Middlebrook, 
who in his book The Nuremberg Raid reaches the unequivocal conclusion that they 
were not.  Anyone who wishes to form a conclusion as to Mr. Cave Brown’s qualities 
as a historian need only compare his chapter on the raid with Mr. Middlebrook’s book 
and see how, while using such evidence which seems to prove his case, Mr. Cave Brown 
ignores everything that does not.  So unready were the German night fighters that, so far 
from their laying an effective ambush, a third of the bomber force was past the fighter 
assembly beacon at Aachen before they intervened.  Indeed the war diary of the Ger­
man 1st Fighter Corps which Mr. Cave Brown claims to have used (though he calls it 
throughout 1st Air Corpos), and to which Mr. Middlebrook has kindly called my atten­
tion, states specifically: “The British decoy manoeuvres prevented an early recognition 
of the target….the 1st Fighter Corpos presumed that the real attack would begin on an­
other target.”  In fact, as Mr. Middlebrook points out, hardly any German single-seater 
fighters reached Nuremberg, and the unit nearest to Nuremberg never even took off. 
Mr. Cave Brown further states that “at least one prisoner claimed that he saw some­
one in the Luftwaffe had marked the route to be taken (to Nuremberg) on a wall map”.  
The source of this statement is a work by David Irving.  Mr. Middlebrook showed 
conclusively in his book, by reference to RAF records, that this prisoner never existed.  
Despite much publicity and intensive investigations, no RAF man has ever been found 
who claims to have been told this or a similar story by the Germans before the Nurem­
berg raid.  The German officers concerned at the Oberursel interrogation centre have 
denied all knowledge of this and similar incidents to which Mr. Cave Brown refers; but 
the chapter in which Mr. Middlebrook exposes the falsity of these rumours is blandly 
ignored. 
It might further be asked why, if an attack on this scale did have to be mounted to 
establish the credibility of a double agent (itself an implausible hypothesis), the RAF 
should have chosen Nuremberg, an objective at almost extreme range, rather than one 
closer at hand and easier to reach.  Stuttgart was a far better target for this purpose, and 
two raids which were mounted against it at about the same time as the Nuremberg raid 
would have fitted de Guingand’s description equally well—if indeed his memory is to 
be taken seriously at all.  Mr. Cave Brown discounts these by claiming that the Nurem­
berg raid was mounted with the deliberate intention of bringing on a prolonged fighter 
battle, in order to increase the attrition of the Luftwaffe fighter strength before D-Day.  
For this purpose, says Mr. Cave Brown, the bomber force was accompanied by 70–80 
Mosquito night fighters.  But Mr. Middlebrook by careful analysis of RAF records has 
shown that altogether only fifty-five Mosquitos were in action that night.  Thirty-six of 
them were on “intruder” operations against German airfields, sometimes many miles 
from the scene of the bomber operation.  This left a total of nineteen fighters to escort 
the 700-strong bomber force.  What kind of attrition does Mr. Cave Brown imagine that 
these were supposed to inflict? 
Why, it may be asked, devote so much time to breaking this butterfly on the wheel?  
Mr. Cave Brown, it may be alleged (though not by his publishers, who liken him to Ar­
thur Bryant, Winston Churchill, and, rather more plausibly, Frederick Forsyth), is not 
a serious historian:  he is only a journalist writing popular history.  Why take him to 
pieces in the TLS?   Do any of his mistakes really matter to anyone except those blood­
less pedants, the academic historians? 

 
The Ultra Variations: A Review of Anthony Cave Brown’s Bodyguard of Lies
The Art and Science of Military Deception	
71
To this it must be replied that they matter a great deal to the friends and relations 
of those who died in Coventry, at Dieppe, and on the Nuremberg raid, allegedly to 
further the Machiavellian plots of Churchill and a gang of unscrupulous Old Etonians 
who were concerned only with the preservation of their own class and Empire; to say 
nothing of the courageous men and women who were killed in the French and German 
Resistance.  Any historian, however popular or populist, owes it to the memory of these 
people to get things right, and to spare no labour in doing so.  Besides, Mr. Cave Brown 
comes before us with the enthusiastic recommendations of American official historians 
who ought to know better; and his allegations have been put forward as if they were es­
tablished and incontrovertible facts in British newspapers, including The Sunday Times, 
which certainly ought to know better.  In spite of all that can be done to set the record 
straight, millions of people are now likely to believe, and hundreds of historians to re­
peat, that the Coventry raid was known about three days in advance but kept quiet; and 
that the Nuremberg raid was deliberately betrayed to the enemy.  Perhaps the damage 
done by such books as this and by the journalists who allow themselves to be taken in 
by them can never be completely undone.  Mud is easy enough to throw, and some of 
it always sticks.  
The sad thing is that it is all so unnecessary.  There is in this book all the material 
for a first-class study of Allied operational deception, if only the author had taken the 
trouble to winnow out the grain from the chaff.  As it is, he has protected his truths, not 
by a bodyguard of lies exactly, but by so confusing a fog of half-truths, insinuations, 
romantic inventions and irrelevant digressions that the deception staffs would have rec­
ognized him as a genius at their profession and recruited him on the spot.  But specialists 
in Second World War literature will know how to classify this work.  “Farrago” is the 
mot juste. 


73
Section IV: 
Theories: How Deception Works
Introduction
How Deception Works
Developing and implementing successful stratagems necessitate understanding human psy­
chological processes.1 Field commanders make many mental calculations prior to major 
military campaigns and individual battles. Both history and logic reinforce the fact that the 
commander whose mental calculations prove more accurate than his opponent’s tends to 
triumph in war, often regardless of numerical or material advantage.  In other words, war is 
fought in the minds of men long before it takes place on the ground.2
Having established that stratagem is a psychological phenomenon, to create surprise 
inducing sufficient dysfunction into an opponent’s analytical process to cause him to act 
contrary to his real interests becomes the goal. This necessitates the deliberate misrepresen­
tation of reality in order to gain a competitive advantage.3 Misrepresenting reality calls for 
understanding the reality in which the opponent exists. 
B. H. Liddell Hart’s strategy of the indirect approach, though not intended to be a tome 
on deception, offers insights into its psychology. Liddell Hart tells us that a direct approach 
to an objective along “lines of natural expectation” is costly and unlikely to succeed. The 
reason has less to do with numbers or material advantage than with the control and “stabil­
ity or equilibrium” associated with preparation for an expected action. Accordingly, accom­
modating an opponent’s expectations assures the equilibrium in his favor and stiffens his 
resistance and resolve. Alternatively, an indirect approach that takes advantage of expecta­
tions creates disequilibrium and surprise.4
Achieving surprise results from an opponent choosing the wrong course of action among 
alternatives.5 In other words, the “lines of natural expectation” can be blurred by increasing 
the number of viable alternatives. To illustrate this point mathematically, pursuing a single, 
viable course of action, one out of one, provides the enemy with certainty regarding one’s 
intentions. The enemy is unlikely to make the wrong decision or to be surprised. By simply 
1.	
Bart Whaley clearly identifies deception as “a psychological notion” in his classic book, Stratagem—Deception and 
Surprise in War.
2.	
Sun Tzu discusses the many mental calculations that first take place within the “temple” for the successful com­
mander. He reminds us that the commander who fails to subject his plan to mental calculation also fails to win 
wars.
3.	
D. C. Daniel and K. L. Herbig, “Propositions on Military Deception,” in Strategic Military Deception,  Daniel and 
Herbig (eds), New York: Pergamon Press 1982, p. 3.
4.	
B. H. Liddell Hart, Letter to The Army Quarterly, January 1928, p. 400.
5.	
It is entirely possible that the enemy will undermine his own efforts through faulty analysis or as a result of an 
overbearing, delusional decision maker, such as Joseph Stalin. However, deception is about inducing behavior, not 
hoping the enemy shoots himself in the foot. 

Section IV: Theories: How Deception Works 
74 
The Art and Science of Military Deception
increasing the viable courses of action to two, the enemy has a 50% chance of picking the 
wrong alternative—even without any use of deception. The geometric leap from certainty 
to even odds is nontrivial. Further increasing the number of viable alternatives increases the 
probability of the enemy choosing the wrong alternative. However, increasing the number of 
alternatives requires increasing the investment in deception, often at the expense of the ac­
tual operation. A balance must be attained. Still, the forfeiture of surprise is certain without 
the presence of more than one viable course of action.6
The goal of stratagem is to ensure that the victim is surprised. Accordingly, first it is 
necessary to present the enemy with multiple, viable alternatives. Only then can the strate­
gist bias the probabilities of the alternatives through a process of hiding the real information 
and showing false information to induce the enemy to choose the wrong alternative. Though 
simple in conception, the devil lies in the details.7
6.	
Bart Whaley, Stratagem—Deception and Surprise in War, Norwood: MA, Artech House, 2007, p. 69.
7.	
Ibid, 73.

75
C H A P T E R  13
“Window” as Written in Most Secret War1
R. V. Jones
This chapter is Dr. R.V. Jones’s statement of his theory of “Spoof.”  This became the 
basis for the war of electronic measures, electronic countermeasures (ECM), electronic 
counter-countermeasures (ECCM), and to infinity or, if sooner, final victory.  
NOTE: “D.T.” was an early German term for radar. 
1.	
From Most Secret War: British Scientific Intelligence 1939–1950, London: Hamish Hamilton, 1978, pp. 287–299. 
Reproduced by permission of Penguin Books, LTD.

“Window” as Written in Most Secret War
76 
The Art and Science of Military Deception

 
“Window” as Written in Most Secret War
The Art and Science of Military Deception	
77

“Window” as Written in Most Secret War
78 
The Art and Science of Military Deception

 
“Window” as Written in Most Secret War
The Art and Science of Military Deception	
79

“Window” as Written in Most Secret War
80 
The Art and Science of Military Deception

 
“Window” as Written in Most Secret War
The Art and Science of Military Deception	
81

“Window” as Written in Most Secret War
82 
The Art and Science of Military Deception

 
“Window” as Written in Most Secret War
The Art and Science of Military Deception	
83

“Window” as Written in Most Secret War
84 
The Art and Science of Military Deception

 
“Window” as Written in Most Secret War
The Art and Science of Military Deception	
85

“Window” as Written in Most Secret War
86 
The Art and Science of Military Deception

 
“Window” as Written in Most Secret War
The Art and Science of Military Deception	
87


89
C H A P T E R  1 4
The Psychology of Deception1
Ray Hyman  
This article is possibly the most concise account of the psychology of deception, and 
is a valuable introductory survey of the history and theory of the entire field from con 
artists to gambling cheats and magicians.  Professor Hyman concludes that a “strong” 
psychology of deception is possible, although he suggests a cross-disciplinary theory is 
apt to be most effective.
Ray Hyman, born in 1928, was inspired to take up magic at age 7 by a birthday box 
of tricks from his father.  He worked his way through college as a professional mental­
ist, doing mind reading, palmistry, and hypnotism.  In 1953, he earned a Ph.D. from 
Johns Hopkins University.  In 1961, Hyman moved to the University of Oregon where 
he was a professor of psychology from 1964 until emerited.  There, among other things, 
he taught a seminar on the “Psychology of Deception.”  He is a semi-professional plat­
form magician and mentalist.
Hyman is a noted skeptical investigator of psychic phenomena and a founding mem­
ber (since 1976) of the Committee for the Scientific Investigation of the Paranormal 
(CSICOP) and served on the editorial board of its journal, “The Skeptical Enquirer.” 
1.	
Ray Hyman, “The Psychology of Deception,” Annual Review of Psychology, Vol. 40, 1989, pp. 133–154. Used, 
with permission, from the Annual Reviews of Psychology, Volume 40 © 1989 by Annual Reviews www.annualre­
views.org.

The Psychology of Deception
90 
The Art and Science of Military Deception

 
The Psychology of Deception
The Art and Science of Military Deception	
91

The Psychology of Deception
92 
The Art and Science of Military Deception

 
The Psychology of Deception
The Art and Science of Military Deception	
93

The Psychology of Deception
94 
The Art and Science of Military Deception

 
The Psychology of Deception
The Art and Science of Military Deception	
95


97
C H A P T E R  15 
“Killing No Murder” The Strategy of Indirect 
Approach1
B.H. Liddell Hart
This letter by Liddell Hart, dated “12th November, 1927,” ends with the first appear­
ance in print of his theory and term, “The Strategy of Indirect Approach.” There he 
previews the key elements of this theory in phrases and even whole sentences that will 
echo through all his later writings:
More and more clearly has the fact emerged that a direct approach to the object or objective 
along the ‘line of natural expectation’ has ever tended to negative results.  The reason being 
that the strength of an enemy country or force lies far less in its numbers or resources than 
in its stability or equilibrium — of control, moral, and supply. … To move along the ‘line of 
natural expectation’ is to consolidate the enemy’s equilibrium, and by stiffening it to aug­
ment its resisting power.
By stressing “expectation,” Liddell Hart surely implies our enemy’s perception—es­
timate or preconception—of our most likely course of action.
In contrast, the decisive victories in military history have come from the strategy of indirect 
approach, wherein the dislocation of the enemy’s moral, mental or material balance is the 
vital prelude to an attempt at his overthrow.
Here, Liddell Hart consolidates the previous point by leaning toward the psycho­
logical element.
This theory is inclusive of but wider than the [Camon-Napoleon] manœuvre sur les der­
rières....  Where the one is concerned primarily with the logistical moves, the other seeks to 
probe deeper to the psychological foundations.
Here, Liddell Hart explicitly separates the physical and psychological parts of his 
theory and elevates the latter.  In other words, he is clear that although “indirect” can 
include the specific direction of movement of military units in a physical environment 
(geospatial battle space), its general meaning is the psychological one of perceived ex­
pectations.  Critics of his Indirect Approach theory consistently go off-target by focus­
ing narrowly on the geometrical vector implied by the word “indirect” and overlooking 
its overriding stress upon the psychological element of expectedness. 
 The strategy of indirect approach is, indeed, the highest and widest fulfilment of the prin­
ciple of surprise.
1.	
B.H. Liddell Hart, “Killing No Murder,” The Army Quarterly, Vol. 15, January 1928, Correspondence with the 
Editors, pp. 396-401.

“Killing No Murder” The Strategy of Indirect Approach
98 
The Art and Science of Military Deception
Where surprise is precisely the enemy’s revised perception that his initial expecta­
tions have been overturned.

 
“Killing No Murder” The Strategy of Indirect Approach
The Art and Science of Military Deception	
99

“Killing No Murder” The Strategy of Indirect Approach
100 
The Art and Science of Military Deception

 
“Killing No Murder” The Strategy of Indirect Approach
The Art and Science of Military Deception	
101

“Killing No Murder” The Strategy of Indirect Approach
102 
The Art and Science of Military Deception

 
“Killing No Murder” The Strategy of Indirect Approach
The Art and Science of Military Deception	
103


105
C H A P T E R  1 6
Cognitive Factors in Deception and 
Counterdeception1
Richards J. Heuer, Jr.
Richards J. Heuer, Jr. served with the CIA for forty-five years.  He was recruited while 
a graduate student at UC Berkeley by former CIA Director Richard Helms.  Heuer is 
most known for his book, “Psychology of Intelligence Analysis,” where he discussed the 
human mind’s weaknesses in dealing with uncertainty. Heuer’s advice to the intelligence 
community has been in support of creating an environment that promotes and rewards 
critical thinking. 
Introduction
To be successful, deception must achieve a desired impact upon the thinking of the 
deception target, either a national or military decision­ maker or the intelligence ana­
lyst working for the decision-maker. The chances of success are enhanced the more 
a deceiver understands about the thought processes of the target leaders or analysts. 
Conversely, the chances of avoiding deception increase the more one understands one’s 
own information processing capabilities and limitations. In examining these judgmental 
processes, one can either determine the propensities and pre­dilections of individual per­
sons or examine those factors that most men and women seem to have in common. This 
paper takes the latter approach.
That human beings often make erroneous judgments is self-evident from our daily 
experience, and it has been demonstrated by many psycho­logical experiments. Military, 
political and economic issues involving interaction with other nations are among the 
most complex analytical pro­blems. This complexity is normally exacerbated by lack 
of information concerning some critical elements of a problem and a large volume of 
frag­mentary, ambiguous and even erroneous information concerning other ele­ments. 
Judgments must be made in the face of great uncertainty.
Over 20 years ago, Herbert Simon advanced the concept of “bounded” or limited 
rationality.1 Because of limits in our mental capacity, he argued, the human mind can­
not cope directly with the complexity of the world. Rather we construct in our mind 
a simplified model of reality and then work with this mental model. We behave ratio­
nally within the confines of our mental model, but this model is generally not very well 
adapted to the requirements of the real world.
Simon’s theory of bounded rationality was stimulated by earlier psy­chological re­
search on perception, memory, attention span, and reasoning capacity that documents 
1.	
Richards J. Heuer, Jr., “Cognitive Factors in Deception and Counterdeception,” in Multidisciplinary Perspectives 
on Military Deception, Donald C. Caniels, et al., editors, United States Naval Postgraduate School, May, 1980, pp. 
45–101.

Cognitive Factors in Deception and Counterdeception
106 
The Art and Science of Military Deception
limitations in our “mental machinery.” A princi­pal thesis underlying more recent re­
search has been that these limitations cause us to employ various simplifying strate­
gies when processing infor­mation to make judgments and decisions. Psychologists have 
conducted many experiments to identify these strategies and to show how—at least in 
laboratory situations—they affect our judgment and decisions. Students of international 
relations, particularly Robert Jervis,2 have con­ducted historical research to document 
instances in which political and military decisions appear to have been significantly 
influenced by these psychological variables.
This research provides substantial experimental and historical evi­dence to support 
Jervis’ conclusion that “perceptions of the world and of other actors diverge from re­
ality in patterns that we can detect and for reasons that we can understand.”3  These 
patterns of erroneous perception and judgment are frequently called “biases.” A bias, 
as the term is used here, is an error in judgment that is consistent and predictable. It 
is not predictable in the sense that all persons under the same circumstances will make 
the same error all the time. Rather, it is predictable in a statistical sense, in that given a 
large number of cases most people will be influenced by this tendency most of the time.
One can identify several types of biases. Motivational biases result from the influ­
ence on judgment of our ambitions and fears, and the need to perceive our past behavior 
as commendable and consistent. The func­tional roles and circumstances of organiza­
tions generate patterns of biased organizational judgment.4  Cultural biases are rooted 
in predisposi­tions inherent in one’s cultural values and heritage.
This paper deals only with perceptual and cognitive biases. Perceptual biases arise 
from the nature of the process by which we perceive the world about us, and they limit 
the accuracy of our perceptions. Cognitive biases result not from any intellectual or 
emotional predisposition toward a certain judgment, but simply from the way the mind 
tends to work. They influence how we estimate probabilities, evaluate evidence, and 
attribute causality.
Of the diverse forms of bias, we have opted to discuss perceptual and cognitive 
baises for two reasons. They are the most general forms of bias, presumably affecting 
all persons regardless of cultural background or organizational affiliation. Cognitive 
biases are also the least well known, for most research on these biases is of recent origin.
The paper is divided into three sections, one dealing with perceptual biases, one 
with cognitive biases, and a concluding section that includes discussion of the broad 
problem of countering deception. Not all percep­tual and cognitive biases are discussed 
here, for we have selected just those that seem most relevant to the problem of decep­
tion. The first two sections present the biases sequentially with a concluding discussion 
re­lating them to the deception problem. These discussions are principally from the point 
of view of the deception planner, for countering deception involves basically different 
problems discussed primarily in the conclusion. An appendix contains a brief summary 
of all the biases and their implications.
A word of caution before proceeding further. How humans perceive and process 
information to arrive at analytical judgments is not fully un­derstood. Although the 
evidence presented here is persuasive, it is not conclusive. The intention of this paper 
is not to deliver the last word in psychological theory, for psychologists differ among 
themselves just as much as historians, intelligence analysts or priests. The purpose is to 
2.	
For example, Richard Betts contends that military intelligence has an or­ganizational bias toward “worst-case” analysis in 
analyses that support pro­curement planning and “best-case” analysis in evaluating the results of mili­tary operations.

 
Cognitive Factors in Deception and Counterdeception
The Art and Science of Military Deception	
107
describe the current state of knowledge from a perspective that views hu­man cognitive 
processes as a critical variable in explaining fallible hu­man judgment. The aim is to 
learn something about how people make judg­ments, and to provide guidelines concern­
ing how to exploit this knowledge to deceive others or prevent being deceived ourselves. 
The guidance is limited to principles that will generally be helpful, not firm rules that 
guarantee an optimal result, for judgment is not guided by algorithms that ensure a cor­
rect answer.
Biases in Perception
The process of perception links the individual to his or her environ­ment and is critical 
to accurate understanding of the world about us. We tend to think of perception as a 
passive process: we see, hear, smell, taste or feel stimuli that impinge upon our senses. If 
we are at all ob­jective, we record what is actually there.
Yet perception is demonstrably an active rather than a passive process; it constructs 
rather than records “reality.” Perception implies understand­ing as well as awareness. It 
is a process of inference in which the in­dividual constructs his or her own version of “re­
ality” on the basis of information provided by the senses. This sensory input is mediated 
by complex and poorly understood mental processes that determine which in­formation 
we attend to, how we organize it, and the meaning we attribute to it. Thus what we 
perceive and how readily we perceive it is strongly influenced by our past experience, 
education, cultural values and role requirements, as well as by the stimuli recorded by 
our receptor organs. This should shake some traditional assumptions about “objectiv­
ity” in analysis.
Expectations Condition Perception
Many experiments have been conducted to demonstrate the extraordin­ary extent to 
which the information obtained by an observer depends upon the observer’s own 
expectations, assumptions and preconception.  For example, when you looked at 
Figure 1, above, what did you see? Did you note that the article is written twice in each 
of the three phrases.
This is commonly overlooked, because perception is influenced by our ex­pectations 
about how these familiar phrases are normally written. If you perceived Figure 1 cor­
rectly, you have exceptional powers of obser­vation, were lucky, or have seen the figure 
before. This simple experi­ment demonstrates one of the most fundamental principles 
concerning perception: we tend to perceive what we expect to perceive. A corollary of 
Figure 1  Perception is a process of constructing reality rather than recording it.

Cognitive Factors in Deception and Counterdeception
108 
The Art and Science of Military Deception
this principle is that it takes more information, and more unambiguous information, to 
recognize an unexpected phenomenon than an expected one.
Another classical experiment to demonstrate the influence of expecta­tions on per­
ception used playing cards, some of which were gimmicked so the spades were red and 
the hearts black. Pictures of the cards were flashed briefly on a screen and, needless to 
say, the test subjects iden­tified the normal cards more quickly and accurately than the 
anomalous ones. After test subjects became aware of the existence of red spades and 
black hearts, their performance with the gimmicked cards improved but still did not ap­
proach the speed or accuracy with which normal cards could be identified.5  This shows 
that patterns of expectation become so deeply embedded that they continue to influence 
perceptions even when we are alerted to and try to take account of the existence of data 
that do not fit our preconceptions. Trying to be objective does not guarantee accurate 
perception.
The position of the test subject identifying playing cards is an­alogous to that of 
the intelligence analyst or government leader trying to make sense of the paper flow 
that crosses his desk. What is actually perceived in that paper flow, as well as how it is 
interpreted, depends in part, at least, on the analyst’s patterns of expectation.  We do 
not have expectations just about the color of hearts and spades.  We have a set of as­
sumptions and expectations about the motivations of people and the processes of gov­
ernment in foreign countries. Events consistent with these expectations are perceived 
and processed easily; those which contradict prevailing expectations tend to be ignored 
or distorted in perception. Of course, this distortion is a subconscious or pre-conscious 
process, as illustrated by how you presumably ignored the extra words in the triangles 
in Figure 1.
This tendency to perceive what we expect is far more important than any tendency 
to perceive what we want. In fact, there may be no real tendency toward wishful think­
ing. The commonly cited evidence supporting the claim that people tend to perceive 
what they want to perceive can generally be explained equally well by the expectancy 
thesis or the avail­ability bias (to be discussed later).6
Expectations have many diverse sources, including past experience, professional 
training, and cultural and organizational norms. All these influences predispose us to 
pay particular attention to certain kinds of information and to organize and interpret 
this information in certain ways. Perception is also influenced by the context in which 
it occurs. Different circumstances evoke different sets of expectations. We are more 
attuned to hearing footsteps behind us when walking in an alley at night than along a 
city street in daytime, and the meaning we attribute to the sound of footsteps will vary 
under these differing circumstances.  A military intelligence analyst is similarly tuned 
to perceive indica­tors of potential conflict. When the evidence is ambiguous, as is com­
monly the case in intelligence analysis, this predisposition increases the likelihood the 
indicators will be perceived accurately when they in fact exist and escape the attention 
of other observers, but it also increases the chances they will be perceived erroneously 
when they are not really there.
Patterns of expectation, rooted in past experience and training, tell us, subcon­
sciously, what to look for, what is important, and how to interpret what we see. These 
patterns form a “mind set” that predis­poses us to think in certain ways. A mind set is 
akin to a screen or lens through which we perceive the world. For example, the follow­
ing truisms have been part of the mind set of intelligence analysts:

 
Cognitive Factors in Deception and Counterdeception
The Art and Science of Military Deception	
109
••
A totalitarian government enjoying the support of effective military and security 
organizations cannot be overthrown by popular opinion.
••
When the position of a dictatorial ruler is threatened, he will defend his position 
with force if necessary.
••
The principal threat to friendly governments comes from the left, not the right.
These premises were part of the lens through which U.S. policy makers and intel­
ligence analysts alike perceived developments in Iran in 1978 prior to the fall of the 
Shah. They had a significant impact on where analysts focused their attention, what 
they expected to happen, and how they interpreted the unfolding events. That all these 
“truisms” were proven wrong in that instance is perhaps no small part of the explana­
tion why the Shah’s demise took the United States government by surprise.
There is a tendency to think of a mind set as something bad, to be avoided. One 
should have an open mind and be influenced by the facts rather than by preconceived 
notions! But there is no such thing as “the facts of the case.” There is only a very selec­
tive subset of the over­all mass of data to which we have been subjected that we take as 
facts and judge to be relevant to the question at issue. Actually, mind sets are neither 
good nor bad; they are unavoidable. There is no conceivable way of coping with the vol­
ume of stimuli that impinge upon our senses, or with the volume and complexity of the 
data we have to analyze, with­out some kind of simplifying preconceptions about what 
to expect, what is important, and what is related to what. “There is a grain of truth 
in the otherwise pernicious maxim that an open mind is an empty mind.”7  Objective 
analysis is not achieved by avoiding preconceptions (that would be ignorance or self-
delusion), but by making our basic assumptions and reasoning as explicit as possible so 
they can be challenged by others and we can ourselves examine their validity.
Perceptions Resist Change
One of the most important characteristics of perceptions is that they are quick to form, 
but resistant to change. Once we have perceived an ob­ject, event or situation and formed 
some judgment about its essential characteristics, we are biased toward continuing to 
perceive it in the same manner even though the object of our perception may change.
Figure 2 illustrates this principle by showing part of a longer series of progressively 
modified drawings that change almost imperceptibly from a man into a woman.8 The 
right hand drawing in the top row, when viewed alone, has equal probability of being 
perceived as a man or a wo­man. When test subjects are shown the entire series of draw­
ings, one by one, their perception of this intermediate drawing is biased according to 
which end of the series they started from. Test subjects who start by viewing a picture 
that is clearly a man are biased in favor of continuing to see a man long after an “ob­
jective observer” (i.e., an observer looking at a single picture) recognizes that the man 
is now a woman. Similarly, test subjects who start at the woman end of the series are 
biased in favor of continuing to see a woman. Once an observer has formed an image, 
that is, once he or she has developed a mind set or expectation concerning the phenom­
enon being observed, this conditions future perception of that phenomenon. This is the 
basis for yet another general principle of per­ception: new information is assimilated to 
existing images.

Cognitive Factors in Deception and Counterdeception
110 
The Art and Science of Military Deception
This principle explains why gradual, evolutionary change often goes unnoticed. It 
also explains the phenomenon that an intelligence analyst assigned to work on a topic 
or country for the first time may generate accurate insights that have been overlooked 
by experienced analysts who have worked on the same problem for ten years. A fresh 
perspective is sometimes useful, for past experience can handicap as well as aid analysis. 
This tendency to assimilate new information to pre-existing images is greater “the more 
ambiguous the information, the more confident the actor is of validity of his image, and 
the greater his commitment to the estab­lished view.”9
Figure 3 provides the reader an opportunity to test for him or her­self the persistence 
of established Images. Look at the picture. What do you see—an old woman or a young 
woman? Now look again to see if you can visually and mentally reorganize the data to 
form a different image—that of a young woman if your original perception was of an 
old woman, or of the old woman if you first perceived the young one.10  Do not look 
at the footnote unless you need clues to help you identify the other image.3 Again, this 
illustrates the principle that perceptions are quick to form but resistant to change.
When you have seen Figure 3 from both perspectives, try shifting back and forth 
from one perspective to the other. Do you notice some initial difficulty in making this 
switch? One of the most difficult mental feats is to take a familiar body of data and 
reorganize it visually or mentally to perceive it from a different perspective. Yet this 
is what intelli­gence analysts are constantly required to do. In order to understand in­
ternational interactions, we must understand the situation as it appears to each of the 
opposing forces, and constantly shift back and forth from one perspective to the other 
as we try to fathom how each side interprets an ongoing series of interactions. Trying to 
perceive Soviet as well as U.S. interpretations of international events is comparable to 
seeing both the old and young women in Figure 3; once we have perceived events one 
way, we tend to resist alternate perspectives.
3.	
The old woman’s nose, mouth and eye are, respectively, the young woman’s chin, necklace and ear.  The old woman 
is seen in profile looking left.  The young woman is also looking left, but we see her mainly from behind so most 
facial features are not visible; her eyelash, nose and curve of her cheek may be seen just above the old woman’s 
nose.  
Figure 2  Impressions resist change.

 
Cognitive Factors in Deception and Counterdeception
The Art and Science of Military Deception	
111
Impact of Ambiguity
Initial exposure to ambiguous or blurred stimuli interferes with accurate perception even 
after more and better information becomes avail­able.  This effect has been demonstrated 
experimentally by projecting onto a screen pictures of common, everyday things such as 
a dog standing on grass, a fire hydrant, and an aerial view of a highway cloverleaf inter­
section.11  The initial projection was blurred in varying degrees, and the pictures were 
then brought into focus slowly to determine at what point test subjects could identify 
them correctly. This experiment showed two things. First, those who started viewing the 
pictures when they were most out of focus had more difficulty identifying them when 
they became clearer than those who started viewing at a less blurred stage. In other 
words, the greater the initial blur, the clearer the pic­ture had to be before people could 
recognize it. Second, the longer time that people were exposed to a blurred picture, the 
clearer the picture had to be made before they could recognize it.
What happened in this experiment, and what presumably happens in real life with 
cognitive as well as visual perceptions, is that despite ambigu­ous stimuli we form some 
sort of tentative hypothesis about what it is we are seeing. The longer we are exposed 
to the ambiguous data, the greater confidence we develop in this initial and perhaps 
erroneous impression, so the greater the impact this initial impression has on our sub­
sequent per­ceptions. For a time as the picture becomes clearer, there is no obvious 
contradiction; the new data is assimilated to our previous image, and the initial inter­
pretation is maintained until the contradiction becomes so obvious that it forces itself 
upon our consciousness. The early but in­correct impression tends to persist because the 
Figure 3  It is difficult to look at the same data from different perspectives.

Cognitive Factors in Deception and Counterdeception
112 
The Art and Science of Military Deception
amount of information nec­essary to invalidate a perception is considerably greater than 
the amount of information required to form an initial impression. The problem is not 
that there is any inherent difficulty in grasping new perceptions or new ideas, but that 
established perceptions are so difficult to lose. Thus inaccurate perceptions generated 
by ambiguous data may persist even after additional information has been received to 
clarify the initial ambiguity. One might seek to limit the adverse impact of this tendency 
by suspending judgment for as long as possible as new information is being received.
Implications for Intelligence Analysis
Understanding the ways in which perception is commonly distorted has significant im­
plications for comprehending the nature and limitations of intelligence analysis. If we 
consider the circumstances under which accurate perception is most difficult, we find 
these are exactly the circumstances under which intelligence analysis is generally con­
ducted—dealing with highly ambiguous situations on the basis of information that is 
processed incrementally under pressure for early judgment. This is a recipe for inac­
curate perception. That intelligence analysts perform as well as they do is testimony 
to their generally sound judgment, training and dedi­cation in performing an extremely 
difficult task.
Intelligence seeks to illuminate the unknown. Almost by definition, intelligence 
analysis deals with highly ambiguous situations. Yet we have seen that the greater the 
ambiguity of the stimuli, the greater the impact of expectations and pre-existing im­
ages on the perception of that stimuli. Thus despite maximum striving for objectivity, 
the intelligence analyst’s own preconceptions are likely to exert a greater impact on the 
analytical product than in other fields where the analyst is working with less ambig­uous 
and less discordant information.
Moreover, the intelligence analyst is among the first to look at new problems at an 
early stage when the evidence is very fuzzy indeed. The analyst then follows a prob­
lem as additional increments of evidence are re­ceived and the picture gradually clari­
fies—much as the test subjects in the experiment demonstrating that initial exposure to 
blurred stimuli in­terferes with accurate perception even after more and better informa­
tion becomes available. If the results of this experiment can be generalized to apply to 
intelligence analysts, it suggests that because the analyst starts observing a potential 
problem situation at its early and most un­clear stage, he or she is at a disadvantage as 
compared with others—for example, policy makers—whose first exposure may come at 
a later stage when more and better information is available.
The receipt of information in small increments over time also facilitates assimilation 
of this information to the analyst’s existing views.  No one item of information may be 
sufficient to prompt the analyst to change his view. The cumulative message inherent in 
many pieces of infor­mation is not examined as a whole. The Intelligence Community 
review of community performance before the 1973 Arab-Israeli War noted:
The problem of incremental analysis—especially as it applies to the current intelligence pro­
cess—was also at work in the period preceding hostilities. Analysts, according to their own 
accounts, were often preceding on the basis of the day’s take, hastily comparing it with 
material received the previous day.  They then produced in ‘assembly line fashion’ items 
which may have reflected perceptive intuition but which [did not] accrue from a systematic 
consideration of an accumulated body of inte­grated evidence.

 
Cognitive Factors in Deception and Counterdeception
The Art and Science of Military Deception	
113
And finally, the intelligence analyst operates in an environment that exerts strong 
pressures for premature judgment. Policy makers’ needs for interpretive analysis are 
greatest within at most two or three days after a new event occurs. The system requires 
the intelligence analyst to make an almost instant diagnosis before sufficient hard infor­
mation becomes available to make a well-grounded judgment. This diagnosis can only 
be based upon the analyst’s preconceptions concerning how and why events norm­ally 
transpire in a given society.
As time passes and more information is received, a fresh look at all the evidence 
might suggest a different explanation. Yet we have seen from the various perception ex­
periments that an early judgment adversely affects the formation of future perceptions. 
Once an observer thinks he or she knows what is happening, this perception tends to 
resist change. The new information received incrementally fits easily into the analyst’s 
pre­vious image. This perceptual bias is reinforced by organizational pres­sures favoring 
consistent interpretation, for once the analyst has committed him or herself in writing, 
both the analyst and the organization has a vested interest in maintaining the original 
diagnosis.
Implications for Deception
One overwhelming conclusion stands out with respect to deception: it is far easier to 
lead a target astray by reinforcing the target’s existing beliefs, thus causing the target to 
ignore the contrary evidence of one’s true intent, than it is to persuade a target to change 
his or her mind.
Military operations possess a certain logic. Terrain, weather, sup­plies and the rela­
tive balance of forces often suggest optimal tactics or strategy. Yet, if the preferred 
alternative is equally obvious to the enemy, these advantages can be offset by the en­
emy’s counter-preparations. Thus planners of military operations may use deception 
to conceal their true intent, and in doing so they are faced with two basic alternatives. 
They can plan to attack in a place, time and manner most expected by the enemy, while 
seeking through deception to achieve surprise by changing the enemy’s expectations. Or 
they can reinforce the enemy’s expectations while planning a surprise attack in a differ­
ent place, time or manner.
The tendencies to perceive what we expect to perceive and to assimi­late new infor­
mation to existing images make it far easier to reinforce a target’s existing beliefs than 
to change them. Deceptions that follow this principle seldom fail, for the odds are then 
strongly in favor of the deceiver. The human capacity to rationalize contradictory evi­
dence is easily sufficient to outweigh the pernicious effects of security leaks and uncon­
trolled channels of information that deception planners might otherwise fear are certain 
to compromise their efforts.
Deceptions that require persuading a target of something he is not already pre­
disposed to believe should be avoided if at all possible. If nonetheless required by the 
operational situation, the chances for success may be enhanced by following a simple 
sequencing rule. Because of the ten­dency to integrate new information into existing be­
liefs, the first goal in any effort to change beliefs must be to ensure that the target is at 
least considering seriously the desired alternative hypothesis. This may require initiating 
the deception with strong and obvious evidence that forces the desired conclusion to 
be at least considered seriously by in­telligence analysts and policy makers. This is then 

Cognitive Factors in Deception and Counterdeception
114 
The Art and Science of Military Deception
followed in quick succession by additional supporting evidence that leads the target to 
a reasoned conclusion in favor of the desired alternative.
The opposite tactic, which seems incorrect from a psychological point of view, 
would be to save the more dramatic evidence until after the stage has been set by trans­
mitting a number of supporting messages. The expectation is that the target initially 
attributes little importance to the supporting messages, but once the key is received the 
other pieces are perceived to fall into place forming a coherent and persuasive pic­ture. 
The weakness of this tactic is that the target may have failed to notice, forgotten or mis­
interpreted the earlier evidence, for information that does not fit neatly into an existing 
hypothesis tends to be ignored or misperceived.  Intelligence analysts and policy makers 
are commonly confronted with a large amount of discordant information. They have 
only a limited capacity to sort and store discordant or seemingly irrele­vant information 
in memory in a manner that makes it possible to recall it for the evaluation of hypoth­
eses that are not now under consideration.
Planning and implementing a deception typically involves a major in­vestment of 
time, energy and ego. When people make such an investment in preparing a message, 
they tend to overestimate how clear this message will be to the receiver. This results 
from the importance of context in perceiving and interpreting a signal; when a message 
is placed in a dif­ferent context it assumes a different meaning. The message developed 
by the deception planners is understood by them in the context of the endless meetings 
in which alternatives were weighed and details worked out. They are so familiar with 
their own thinking that they risk overlooking the de­gree to which the message is clear 
to them only because they know what to look for.
The target of a deception is likely to have a different agenda of concerns, differ­
ent predispositions and a different information base than the deception planners. Nor­
mally this will lead to a different interpreta­tion of messages. If the deception planners 
have sufficient understanding of the target’s situation and thinking, messages may be 
planned to take advantage of the particular context in which they will be received, but 
in practice the target may miss many clues the deceiver sets out for him and may assign 
considerable weight to factors the deceiver regards as trivial or to information of which 
the deceiver is wholly unaware. To the extent that the deception signals reinforce the 
target’s expectations, there is a large margin for error and these miscalculations have 
little impact.  If the goal is to change the target’s mind, however, they may be critical.
It is not by accident that discussion to this point has concerned im­plications for 
the perpetration of deception rather than its detection.  The counterdeception problem 
is extremely difficult. When should we dis­believe our eyes and ears and the seemingly 
logical conclusions of our mind? When should we second guess, and say to ourselves 
that since most of the evidence points to X, then Y must be true rather than X? Even in 
the absence of deliberate deception, the evidence at the most critical junctures is typi­
cally so ambiguous that the proper conclusion is far from obvious. To the extent that 
we cannot believe the evidence, the an­alytical problem becomes even more complicated. 
The problem of detecting deception is not simply a matter of accurate perception.  It is 
embedded in the much larger problem of effective intelligence collection and analysis, 
and we reserve discussion of these points until the end of this paper.

 
Cognitive Factors in Deception and Counterdeception
The Art and Science of Military Deception	
115
Cognitive Biases
The cognitive biases discussed here are grouped according to whether they affect the 
estimation of probabilities, the evaluation of evidence, or the attribution of causality.
Biases in Estimating Probabilities
Estimating probabilities is important because we live in a probabilis­tic world. Social, 
political, military and economic developments are not rigidly determined but occur or 
fail to occur with some degree of probabil­ity. Decision makers cannot be certain of the 
outcome of their actions, so they must weigh the probabilities of alternative outcomes. 
The information on which these decisions are based also involves many uncertainties 
ex­pressed in probabilistic terms. The intelligence analyst, for example, is constantly as­
sessing probabilities with respect to the intentions of for­eign leaders, the capability of 
military forces, the future consequences of current events, or the credibility of sources.
Typically, these probability judgments are expressed in imprecise terms such as pos­
sibly, probably or very likely terms that unfortunately have different meanings to dif­
ferent people. But the issue here is not whether communication and decision making 
can or should be improved by re­placing those verbal qualifiers with numerical ranges 
of probability. It is whether the estimates themselves are influenced by systematic biases 
that affect their accuracy. Research by experimental psychologists sug­gests that this is 
in fact the case. Knowledge of these biases may be useful to those planning deception 
or seeking to avoid it.
Availability Bias
One of the simplified rules of thumb we use in making probability es­timates is known 
as the availability rule. In this sense availability re­fers to imaginability or retrievability. 
Psychologists have shown that two of the cues we use in judging the probability of an 
event are 1) the ease with which we can imagine relevant instances of the event, and 2) 
the number or frequency of such events that we can easily remember.12  In other words, 
we are using the availability rule of thumb whenever we estimate frequency or prob­
ability on the basis of how easily we can recall or imagine instances of whatever it is we 
are trying to estimate.
Normally this works quite well. If one thing actually occurs more frequently and 
therefore is more probable than another, we probably will be able to recall more in­
stances of it. Events that are likely to occur generally are easier to imagine than unlikely 
events. We are constantly making inferences based on these assumptions. We estimate 
the probability of successful deception by recalling historical examples of deception un­
der similar circumstances. We estimate the probability that a politician will lose an elec­
tion by imagining ways in which he may lose popular sup­port. Although this generally 
works well, we are often led astray be­cause the ease with which things come to mind is 
influenced by many fac­tors, such as emotional saliency, vividness and how recently we 
have been exposed to them, all of which may be unrelated to the correct probability. 
When this happens, our judgment is biased in favor of the probability of those events 
that are most available. For example, the Soviet assessment of the likelihood that Ger­
many may once again become a military threat to Soviet interests seems clearly biased 
by the ready availability of vivid memories of the Second World War. 

Cognitive Factors in Deception and Counterdeception
116 
The Art and Science of Military Deception
Intelligence analysts often have difficulty estimating the likelihood of low probabil­
ity events, especially when those events have potentially very serious consequences. For 
example, what is the likelihood of civil war in Canada, perhaps even including Soviet 
or Cuban assistance to Quebec, during the next ten years? Or the likelihood of an ag­
gressively anti-American, Castro-like government coming to power in Mexico? It is 
diffi­cult for us to imagine such developments, so we assign them a very low pro­bability, 
but imaginability is most likely irrelevant to an accurate assess­ment of the probability 
that either of these developments will actually occur. To the extent that our estimate is 
influenced by ready imaginabil­ity rather than by a full analysis of the causal factors at 
work, we are likely to underestimate the true probability.
Sino-Soviet reconciliation is another low probability, high signifi­cance event, but 
here the availability bias is likely to cause people to overestimate the probability of it 
actually happening. This is because it is so easy to imagine such a development and 
what impact it would have on U.S. policy. In fact, our memory of having been taken by 
surprise by the Sino-Soviet split causes many people to be preoccupied by the possibility 
of reconciliation. Analysts working full time on this question are con­sidering the opera­
tive causal factors, not making quick and easy infer­ences on the basis of imaginability. 
But the policymaker or generalist who does not have the time or the information to go 
into details must un­consciously take shortcuts, and the obvious shortcut is to use the 
avail­ability rule of thumb for making inferences about probability.
Anchoring Bias
Another strategy that people seem to use intuitively and unconsciously to simplify the 
task of mentally processing complex information is called “anchoring.” Some natural 
starting point is used as a first approximation to the desired judgment. This starting 
point is then adjusted, based on the results of additional information or analysis. Typi­
cally, however, the starting point serves as an anchor or drag that reduces the amount of 
adjustment, so that the final estimate remains closer to the starting point than it ought 
to be.
Anchoring has been demonstrated by asking a group of test subjects to estimate one 
or more known quantities, for example, the percentage of people in the United States 
who are age 55 or older. In an experiment that used this question, the test subjects 
were given starting percentages that were selected randomly—they were drawn out of a 
bowl—and were then asked to adjust these arbitrary starting points until they reached 
their best estimate in response to the question. Because of insufficient adjustment, those 
who started out with an estimate that was too high ended with higher estimates than 
those who started with an estimate that was too low, and vice versa. Even the totally 
arbitrary starting points ac­ted as an anchor, causing drag or inertia that inhibited full 
adjustment of estimates to the point that the test subjects would otherwise have consid­
ered desirable.13
Policy makers and intelligence analysts deal with dynamic situations.  They must 
continually review their estimates in response to changes in the situation or the receipt 
of previously unavailable information. Ideally, there should be a direct correlation be­
tween changes in the situation and/or new information and changes in the estimate, but 
such is frequently not the case. There is much evidence to suggest that people do not 
change their judgments enough. Once an estimate is made, thinking becomes an­chored 
and moves only within a narrow range around that spot.

 
Cognitive Factors in Deception and Counterdeception
The Art and Science of Military Deception	
117
Overconfidence Bias
Problems of perception and bias might be less serious if people had a better apprecia­
tion for the limits of their own knowledge. Many tests have been conducted that show 
people have difficulty expressing accurately the degree of uncertainty in what they know 
or believe. People tend to be overconfident about how much they know.
The Subjective Probabilities Assessment Test (SPAT) uses 75 general knowledge 
questions with known answers taken from an almanac. Test subjects are asked not just 
to answer the questions, but for each question to also assign a probability that shows 
how confident they are that their answer is the correct one. For questions with two 
possible answers, a 50% proba­bility indicates complete uncertainty about which of the 
two answers is correct, while 100% indicates absolute certainty that the chosen answer 
is the proper one.
Performance on the SPAT test is not measured by the number of correct answers, 
but by the “calibration” between assessed probability that the answer is correct and the 
actual number of correct answers at each probabil­ity level. If a subject indicates 70% 
certainty on ten questions, then a perfect score would be seven correct and three incor­
rect answers. Under such circumstances, we would say that the person’s subjective or 
intuitive feeling of certainty is perfectly calibrated with the reality of his per­formance. 
On the other hand, only five or six correct answers would in­dicate overconfidence 
and eight or nine correct answers under-confidence in assessing the accuracy of one’s 
knowledge.
Figure 4 shows the results from testing almost 1,000 DIA and CIA intelligence ana­
lysts and managers.14  For questions on which analysts expressed 100% confidence, the 
median analyst was correct only 76% of the time.
Figure 4 

Cognitive Factors in Deception and Counterdeception
118 
The Art and Science of Military Deception
When expressed confidence was 90%, the judgment was correct on only 632 of the 
questions, and so on as indicated in the graph. In brief, the test demonstrated that the 
intuitive feelings of certainty of intelligence an­alysts do not conform with reality. The 
analysts are markedly overconfident of how much they know.
Very similar results have been found with test groups not affiliated with the intel­
ligence community.15  Experiments have shown that the overcon­fidence bias is greater 
for difficult questions than for easy ones. Train­ing involving feedback on one’s perfor­
mance improves the calibration be­tween expressed confidence and actual performance; 
weather forecasters per­form exceptionally well on the SPAT test, doubtless because they 
commonly receive rapid feedback on the accuracy of their probability judgments. On 
the other hand, neither superior intellectual ability nor expertise in the subject matter 
of the questions has been found to improve performance in assessing the certainty of 
one’s knowledge.
The intelligence analyst’s subjective overconfidence may not be trans­lated into over­
confident intelligence judgments. Organizational and moti­vational incentives also in­
fluence how the analyst expresses his level of confidence when writing an intelligence 
report. Hedging to avoid embar­rassment in the event of error and overwriting to mask 
ignorance are not un­common. The bias toward overconfidence applies to the private 
feelings of analysts, not necessarily to the way they present these feeling in formal intel­
ligence products.
Implications for Deception
Availability bias may make analysts believe that strategic deception is more common 
than it really is, and thus cause them to be more disposed to perceive it. Successful cases 
of deception are far more salient, and con­sequently more available for recall in memory, 
than cases in which deception was not employed under comparable circumstances. De­
ception attracts both the popular imagination and the attention of historians, while the 
absence of deception in strategic operations does not. When an analyst is faced with a 
situation in which deception may or may not be employed, his or her estimate of the 
probability of deception is influenced by this easy retrievability of past instances of 
deception.
The availability bias also suggests that employees of watch offices will tend to over­
estimate the probability of whatever it is they are watch­ing for. Having been briefed and 
trained to recognize certain indicators, and having imagined and rehearsed scenarios 
that include the watched-for de­velopments, it is not surprising that the watched-for 
developments are at the forefront of their minds as they try to forecast the future course 
of events. To the extent that the watched-for development is judged more pro­bable, the 
perceptual bias of seeing what we expect to see also plays a greater role.
If the goal of a deception is to induce ambiguity or to persuade the watch officers 
that what they are watching for is not happening, e.g., that there is no intent to attack 
when an attack is in fact planned, a watch of­fice is an extremely difficult deception 
target. On the other hand, it may be possible to exploit the watch officers’ preconcep­
tions, for example, as part of a plan to exploit the cry wolf syndrome. The watch office 
might be provoked to issue an alert of impending attack several times when no attack is 
in fact planned, so that future alerts will be received more skeptically. In this procedure, 
the availability of the attack scenario is countered by building up in the watch officers 
another availability—the memory of re­cent false alarms.

 
Cognitive Factors in Deception and Counterdeception
The Art and Science of Military Deception	
119
Policy makers and others seeking to avoid deception would do well to keep the 
availability bias in mind and to check the extent to which it in­fluences their thinking 
on critical issues. If their judgments of the like­lihood of future events are determined 
by imaginability or retrievability rather than by causal analysis, they should have little 
confidence in these judgments and should seek an independent assessment based on 
more systema­tic analysis.
The significance of the anchoring bias to the deception planner depends upon the 
type of deception being planned. If the goal is to change a target’s previous beliefs, an­
choring will facilitate achieving this objective.
Because the anchoring bias tends to prevent analysts from revising their estimates 
as much as they should when new information is received, analysts seeking to avoid 
surprise will generally wish to try to overcome this bias. The prognosis is not favorable. 
In one experiment, the bias persisted even after test subjects had been given feedback 
to show the bias and after they had been urged to try to overcome this tendency in an­
swering a new set of estimation questions.16  This is a common finding in experiments 
dealing with cognitive biases; the biases persist even after test subjects are informed of 
them and instructed to try to avoid them or compensate for them.
One possible technique for avoiding the anchoring bias, to weigh anchor so to 
speak, may be to ignore one’s own or others’ earlier judgments and re­think a problem 
from scratch. In other words, consciously avoid using any prior judgment as a starting 
point. There is no experimental evidence to show that this is possible or that it will 
work, but it certainly seems worth trying. Alternatively, it is sometimes possible to avoid 
human error by employing formal statistical procedures. Bayesian statistical analysis, 
for example, can be used to revise prior judgments on the basis of new in­formation in a 
way that is designed to avoid any anchoring bias.17
Overconfidence exacerbates the impact of all the biases. Although a written esti­
mate may have been hedged, if the analyst’s subjective feeling is one of overconfidence 
and satisfaction with his or her estimative per­formance, there will be few efforts to 
improve. For the deception planner, the implications of a target’s overconfidence are the 
same as the implica­tions of the anchoring bias. It is one more obstacle to overcome in 
inducing a target to change his or her mind, but it can be readily exploited if the objec­
tive is to reinforce the target’s existing convictions. In ambiguity-inducing deceptions, 
the intent is to reduce the target’s confidence.
Biases in Evaluation of Evidence
Collection and evaluation of evidence are crucial steps in analysis.  Are there systematic 
biases in the way we handle evidence? We have seen in our discussion of perception that 
new information tends to be assimilated to existing images. Thus the order in which we 
receive information affects our judgment. Evidence received early in an investigation 
has a greater impact on our thinking than evidence received after our impressions have 
already formed. At present, however, we are concerned with several other problems as 
discussed below.

Cognitive Factors in Deception and Counterdeception
120 
The Art and Science of Military Deception
Oversensitivity to Consistency
Consistency is normally an appropriate guideline for evaluating evidence. We formulate 
alternative explanations or predictions and select the one which encompasses the great­
est amount of evidence within a logically consistent scenario. When very little evidence 
is available, however, we tend to be oversensitive to consistency. We have more confi­
dence in conclusions drawn from a very small body of consistent information than from 
a larger body of less consistent data. This is incorrect, because conclusions drawn from 
very small samples are highly unreliable.
Test subjects were asked to predict students’ class standing on the basis of grades 
obtained in the freshman year, and to indicate the amount of confi­dence they had in 
their predictions. The predictions were almost identical when based on a single B in 
one course as when based on an A in one course and a C in another, but there was 
a significant difference in level of confidence. Subjects expressed far more confidence 
when predicting from a single grade than from an inconsistent pair of grades. This is 
not justifiable statistically.18
Similarly, a government leader is likely to have more confidence in a re­commendation 
reached unanimously by a group of three advisors than in a recom­mendation concurred 
in by 10 members of a 12-man panel. This, too, is incon­sistent with the laws of statisti­
cal probability. When an intelligence an­alyst has little data on a certain subject, but all 
the data are consistent, the analyst is likely to overestimate the degree of confidence he 
or she should have in the judgment drawn from that data.
Absence of Evidence
One of the significant differences between intelligence analysis and most academic re­
search concerns degree of control, in determining the data that are used. The academic 
researcher generally tries to define his or her research problem as one for which the 
data are known to be available. The intelligence or policy analyst is generally drawing 
inferences from very incomplete data.  He or she must work with the evidence at hand 
and somehow take into account the fact that much relevant information is known to be 
missing.
Ideally, intelligence analysts should recognize that relevant evidence is lacking and 
be able to factor this into their calculations, estimating the potential impact of the 
missing data and adjusting confidence in their judgment downward in recognition that 
key information is unavailable. Unfor­tunately, this ideal may not be the norm. “Out of 
sight, out of mind” may be a better description of the impact of gaps in the evidence.
This problem can be demonstrated using a fault tree, which is a schema­tic drawing 
showing all the things that might go wrong with any endeavor.  Fault trees are often 
used to study the fallibility of complex systems such as a nuclear reactor or space cap­
sule. Figure 5 is a fault tree showing all the reasons why an automobile might not start.
The “car won’t start” fault tree in Figure 5 was shown to several groups of experi­
enced mechanics.19  One group was shown the full tree and asked to imagine 100 cases 
in which a car won’t start. Members of this group were then asked to estimate how 
many of the 100 cases were attributable to each of the seven major branches of the tree, 
that is, to battery failure, ignition sys­tem failure, etc. A second group of mechanics was 
shown only an incomplete version of the tree; three major branches were omitted in 
order to test how sensitive the test subjects were to what was left out.

 
Cognitive Factors in Deception and Counterdeception
The Art and Science of Military Deception	
121
If the mechanics’ judgment had been fully sensitive to the missing in­formation, 
then the number of cases of failure that would normally be attri­buted to the omitted 
branches should have been added to the “Other Problems” category. In practice, how­
ever, the “Other Problems” category was increased by only half as much as it should 
have been, indicating that the mechanics shown the incomplete tree were unable to fully 
recognize and incorporate in­to their judgments the fact that some of the causes for a car 
not starting were missing from the fault tree. When the same experiment was run with 
non­mechanics, the effect of the missing branches was much greater.
As compared with most questions of intelligence analysis, the “car won’t start” ex­
periment involved rather simple analytical judgments. That the pre­sentation of relevant 
variables in the abbreviated fault tree was incomplete could and should have been rec­
ognized easily by the experienced mechanics selected as test subjects. That the mechan­
ics performed so poorly on this experiment suggests that intelligence analysts may have 
similar problems. Missing data is a normal characteristic of intelligence problems, and it 
is probably more difficult to recognize and incorporate the missing data in judgment in 
abstract intelligence problems than in the more concrete “car won’t start” experiment.
Persistence of Impressions Based on Discredited Evidence
Impressions tend to persist even after the evidence that has created those impressions 
is fully discredited. Psychologists have become interested in this phenomenon because 
many of their experiments require that the test subjects be deceived, for example, that 
they be made to believe they were successful or unsuccessful in performing some task or 
that they possess cer­tain abilities or personality traits when this is not in fact the case. 
Figure 5

Cognitive Factors in Deception and Counterdeception
122 
The Art and Science of Military Deception
Pro­fessional ethics require that test subjects be disabused of these false im­pressions at 
the end of the experiment, but this has proven surprisingly dif­ficult to achieve.
Students’ erroneous impressions concerning their logical problem-solving abilities 
persevered even after the students were informed that manipulation of good or poor 
teaching performance had virtually guaranteed their success or failure.20  Similarly, test 
subjects asked to distinguish true from fic­titious suicide notes were given feedback that 
had no relationship to actual performance; the test subjects had been randomly divided 
into two groups, with members of one group being given the impression of above aver­
age suc­cess and the other of relative failure at this task. The subjects’ erroneous impres­
sions of the difficulty of the task and of their own performance per­sisted even after 
they were informed of the deception, that is, informed that their alleged performance 
had been preordained by their assignment to one or the other test group. Moreover, the 
same phenomenon was found among observers of the experiment as well as the immedi­
ate participants.21 The impressions persisted even after the evidence on which they were 
based was fully discredited.
There are several cognitive processes that might account for this pheno­menon. The 
previously mentioned tendency to interpret new information in the context of pre-exist­
ing impressions is relevant here but probably not suf­ficient to explain why the pre-ex­
isting impression cannot be eradicated even when the new information authoritatively 
discredits the evidence on which it is based. An interesting but speculative explanation 
draws on the strong human tendency to seek causal explanations.
When evidence is first received, it is perceived within a context that implies caus­
al connections between the evidence and some antecedents that explain the evidence. 
The stronger the perceived causal linkage between the evidence and its antecedents, the 
stronger the impression created by the evi­dence. Thus in the experiment with suicide 
notes, one test subject attribu­ted her apparent success in distinguishing real from ficti­
tious notes to her empathetic personality and the insights she gained from the writings 
of a novelist who committed suicide. Another ascribed her apparent failure to lack of fa­
miliarity with people who might contemplate suicide. Even after learning that the feed­
back concerning their performance was invalid, these subjects retained this plausible 
basis for inferring that they were either well or poorly qualified for the task. Thus their 
initial impressions of task difficulty and of their own ability remained unchanged.22
In more general terms, when evidence is received, we postulate a set of causal con­
nections that explains this evidence. Even though the evidence may subsequently be 
discredited, the causal linkages remain plausible and may be seen as sufficient to imply 
the existence of an event even in the absence of the now-discredited evidence. The pre­
viously preceived causal linkage comes easily to mind. It is a readily “available” (note 
previous discussion of availability bias) explanation that makes the event seem more 
likely than it would have appeared prior to receipt of the discredited evidence.
Implications for Deception
The bias favoring a small amount of consistent information over a large body of less 
consistent data supports the common maxim in deception opera­tions that the deceiver 
should control as many information channels as possible in order to reduce the amount 
of discrepant information available to the tar­get. Deception can be effective even with a 
small amount of information as long as the target does not receive contradictory data. 
Not only should the notional picture be consistent, but the deceiver should actively 

 
Cognitive Factors in Deception and Counterdeception
The Art and Science of Military Deception	
123
discredit the real picture as well. To achieve maximum consistency, it is necessary to 
discredit the true as well as build up the false.
To deception planners, the “car won’t start” experiment suggests that deception is 
unlikely to fail because of information that is not provided.  The absence of evidence is 
often overlooked, so errors of omission will be less serious than errors of commission. 
Conversely, the analyst attempting to detect deception would be well advised to con­
sider carefully what informa­tion is missing. If the enemy were planning X, what would 
be the observable consequences of this plan, what is the likelihood this evidence could 
in fact be observed, and what inferences should be drawn from the fact that certain 
evidence is not observed?
Neither of the above conclusions is at all surprising. The persistence of impressions 
based on discredited evidence, however, does have counter-in­tuitive implications. The 
impressions created by information fed through a double agent may persist even after 
the opposition learns that its agent has come under control and that information from 
this source cannot be trusted.  If we give credence to information and it affects our 
thinking and we subse­quently learn that this information was deliberately leaked by an 
enemy, this subsequent knowledge does not necessarily reduce the impact of the initial 
re­port.  Once information rings a bell, so to speak, the bell cannot be “unrung.”
The ambiguity of most real world situations contributes to the opera­tion of this per­
severance phenomenon. Rarely in the real world is evidence so thoroughly discredited 
as is possible in the experimental laboratory.  Assume, for example, that you receive a 
report that an intelligence agent you run has come under hostile control. Assume further 
that you have formed a number of impressions on the basis of reporting from this agent.
It is easy to rationalize the perseverance of these impressions by arguing that the 
information was true despite the agent being under hostile con­trol, or by doubting the 
validity of the report claiming the agent is un­der control. In the latter case, the phe­
nomenon of impression perseverance may itself affect evaluation of the evidence that 
supposedly discredits the impression; it is because we retain our initial impression that 
we disbelieve the new evidence.
It is a truism that security is an essential element of successful deception. If the 
deception is undertaken to protect the security of an operational plan, compromise of 
the deception might be worse than no de­ception at all, for it could attract attention to 
the true plan. While security is obviously desirable, it may not be quite as essential as 
past deception planners have believed, for there are cognitive factors that help reduce 
the adverse consequences of security leaks. The persistence of impressions based on 
discredited evidence is one of these. Others dealing with the human capacity to ratio­
nalise contradictory evidence have been discussed in the perceptual biases section. There 
is empirical evi­dence to support this conclusion. Of the 63 cases of strategic surprise 
or deception studied by Barton Whaley, none had perfect security. Some more or less 
specific warnings were present in every case, yet surprise or deception was successful 
nonetheless.23
Biases in the Perception of Causality
We cannot see causation in the same sense that we see a desk or a tree. Even when we 
observe one billiard ball strike another and then ob­serve the previously stationary ball 
begin to move, we are not seeing causa­tion. The most we can see is the juxtaposition of 

Cognitive Factors in Deception and Counterdeception
124 
The Art and Science of Military Deception
events in time and space. The perception of causation results only from a complex pro­
cess of infer­ence, not from direct observation. As other forms of inference, it is subject 
to systematic biases. The two biases discussed in this section increase the likelihood that 
analysts will perceive deception when it is not in fact present.
Bias Toward Causal Explanations
We have a deep psychological need to understand our environment. Un­derstanding im­
plies order, so we arrange our observations into regular pat­terns and relationships. Hap­
penings that we cannot understand may be at­tributed to God’s will or to fate, which is 
somehow preordained, for we resist the thought that outcomes may be determined by 
forces that interact in random, unpredictable ways. People generally do not accept the 
notion of chance or randomness. Even dice players behave as though they exert some 
control over the outcome of a throw of dice.24
Because of this need to impose order on our environment, we may seek and see pat­
terns that actually are not there. Some recent research in pal­eobiology seems to illustrate 
this tendency. A group of paleobiologists has developed a computer program to simu­
late evolutionary changes in animal species over time. But the transitions from one time 
period to the next are not determined by natural selection or any other regular process; 
they are determined by computer-generated random numbers. The patterns that are 
produced by this program are very similar to the patterns in nature that paleobiologists 
have been trying to understand. Events that seem, in­tuitively, to have a very strong pat­
tern, were in fact generated by random processes.25  This suggests that there may, in fact, 
be no valid causal explanation of evolution.
B.F. Skinner noted a similar phenomenon in the course of experiments with the be­
havioral conditioning of pigeons. The normal pattern of these experiments was that the 
pigeons were given positive reinforcement, in the form of food, whenever they pecked 
on the proper lever at the proper time. To obtain the food regularly, they had to learn 
to peck in a certain se­quence. Skinner demonstrated that the pigeons “learned” and fol­
lowed a pattern even when the food was actually dispensed randomly.26
These examples suggest that in military and foreign affairs, where the patterns are 
at best very difficult to fathom, there may be many events for which there is no valid 
causal explanation. Our bias against random­ness as an explanation may cause us to 
impose a pattern on these events so that we see causal relationships that are not in fact 
there. It clear­ly does not do much for our ego as analysts to admit that some of the 
things we are called upon to explain might be caused by random processes such as the 
random numbers used in the paleobiologists’ computer program.  And it is certainly 
unlikely that the customers for our intelligence would appreciate such an explanation, 
so there are motivational biases that rein­force the cognitive bias favoring order over 
randomness.
The need to perceive order and reason in the world around us causes us to over­
estimate the extent to which other countries or other people are pursuing a coherent, 
rational, goal-maximizing policy. We tend to see the actions of other governments as 
the intentional result of central direc­tion and planning, and to overlook the fact that the 
same behavior might be more accurately explained by accident, blunder, the unintended 
consequence of well-intentioned policy, improperly executed orders, bargaining among 
semi-independent bureaucratic entities, or following standard operating procedures un­
der inappropriate circumstances.

 
Cognitive Factors in Deception and Counterdeception
The Art and Science of Military Deception	
125
Internal vs. External Causes of Behavior
Attribution theory is a sub-field of psychology dealing with how we assess the causes of 
behavior. Most research in attribution theory employs a basic dichotomy between inter­
nal and external causes of behavior. In­ternal causes include a person’s attitude, beliefs 
and personality. Ex­ternal causes include such factors as incentives and constraints, role 
re­quirements, or difficulty of a task. Attribution theory examines the cir­cumstances un­
der which we attribute behavior to either internal or exter­nal causes. Such differences in 
attribution may have significant conse­quences for behavior, as our response to friendly 
or unfriendly actions of other persons may be quite different if we attribute the behav­
ior to the nature of the person than if we see the behavior as resulting from situa­tional 
constraints over which that person had little control.
The fundamental attributional error is to overestimate the importance of personal 
traits and dispositions in determining behavior. When we ob­serve another’s behavior, 
we are too quick to infer broad personal quali­ties or dispositions from this behavior and 
to expect that these same dis­positions will determine the actor’s behavior in other con­
texts. The so-called “Peter Principle” is a simple illustration of this bias. An employee is 
promoted to his or her level of incompetence because the supervisor at­tributes the em­
ployee’s promotion-meriting performance exclusively to per­sonal ability and assumes 
that this personal characteristic will continue to determine performance despite changes 
in the situational context. Much research into personality traits, however, shows that 
personal traits are not consistent determinants of behavior; which trait predominates at 
any given time is heavily dependent upon the situational context in which the behavior 
takes place.
Most interesting for our purposes, however, is that susceptibility to this attribu­
tional error depends upon whether we are examining our own be­havior or observing 
the behavior of others. We tend to attribute the be­havior of others to the nature of the 
person, while we see our own behavior as conditioned by the nature of the situation in 
which we find ourselves.27
This bias is partially explained by differences in information avail­able to actors and 
observers. In evaluating our own behavior, we compare our present behavior with our 
own past behavior in similar or different contexts. This past behavior is well known to 
us, so it is easy to com­pare the impact of different situations on our behavior over time. 
This causes us to focus on the nature of the situation as the principal variable explain­
ing differences in our own behavior. The observer of another per­son, on the other hand, 
typically lacks this depth of knowledge of the other person’s behavior in other circum­
stances. So the observer’s orien­tation is to examine how the actor’s behavior compares 
with the behavior of other persons under similar circumstances. This prompts a focus 
on the nature of the person rather than on the nature of the situation. Other differences 
in perspective between actor and observer may also contribute to this bias.
I know of no experimental evidence that this bias applies to our percep­tion of 
the behavior of countries as well as the behavior of individuals, but such an extrapola­
tion seems plausible and is supported by personal ex­perience. Reportedly one of the 
persistent differences between intelligence analysts responsible for the Soviet Union and 
those responsible for China and working on Sino-Soviet relations is this: Soviet analysts 
tend to at­tribute Chinese behavior to the nature of the Chinese, while they see Soviet 
options as circumscribed by many situational constraints. Chinese analysts tend to take 

Cognitive Factors in Deception and Counterdeception
126 
The Art and Science of Military Deception
the opposite view, that is, that the Russians behave like Russians while Chinese actions 
are the product of the situation in which the Chinese find themselves.28
Thus familiarity, either with oneself or the country for which one is responsible, 
produces empathy and understanding, and attribution of behavior to external circum­
stances rather than to the nature of the actor. Lack of information concerning the past 
behavior and current circumstances of an actor, or lack of empathy for whatever reason, 
causes us to perceive that actor’s behavior as stemming from the nature of the actor. As 
with all the cognitive biases, we are describing a tendency, not a black and white rule 
that applies to all people in all cases. In assessing the behavior of others, we normally 
do make some allowance for situational pressures and role requirements, but this allow­
ance is often insufficient.
A principal implication for international relations is that this bias sows the seeds 
of mistrust and misunderstanding, as countries have quite dif­ferent perceptions of the 
causes of each other’s behavior. There are also several corollaries and related biases that 
are quite relevant to the analysis of international affairs.29
When we fall prey to the attributional bias of judging another country’s behavior 
to be more heavily influenced by the nature of the people or the leaders than is in fact 
the case, we tend to perceive this state as more hostile than it really is. If actions that 
adversely affect our interests are attributed to the predispositions and attitudes of the 
other country, we perceive these actions as expressing hostility. If, however, the other 
nation’s actions are actually responsive to situational constraints, it is unnecessary to 
assume hostile intent. Similarly, attribution of behavior to personal or national charac­
teristics and the assumption that these char­acteristics are consistent over time leads to 
the perception of behavior as inflexible and unchanging. Conversely, to the extent that 
behavior is attributed to external circumstances, it is perceived as flexible and subject to 
influence by our own actions.
Implications for Deception
Deception planners need to avoid these biases relating to causality in order to evaluate 
accurately the situation in which they find themselves and to estimate how a target is 
likely to respond to whatever information is provided. But the most direct relevance of 
these biases to the question of deception is their impact on the analyst seeking to detect 
and avoid deception. Both biases tend to make analysts perceive deception when it is 
not really there.
Deception is an example par excellence of a policy that is centrally directed, well 
planned, and highly coherent and rational. As a causal explanation, deception is in­
trinsically satisfying precisely because it is so orderly and rational. When other per­
suasive explanations are not avail­able (perhaps because the phenomena we are seeking 
to explain were actually caused by mistakes, failure to follow orders, or other factors 
unknown to us), deception offers a convenient and easy explanation. It is convenient 
because intelligence analysts are generally sensitive to the possibility of deception, and 
its detection is often taken as indicative of sophisticated, penetrating analysis. It is easy 
because almost any evidence can be rationalized to fit the deception hypothesis; in fact, 
one might argue that once deception has been raised as a serious possibility, this hypoth­
esis is almost immune to disconfirmation. While deception is by no means an uncom­
mon phenomenon, I suspect that our bias toward seeing events as part of an orderly 
pattern leads us to perceive deception more frequently than is warranted.

 
Cognitive Factors in Deception and Counterdeception
The Art and Science of Military Deception	
127
This tendency to perceive deception is reinforced by the bias toward per­ceiving 
the behavior of others as caused by the nature of the person rather than by situational 
constraints. When another person or government employs deception, we commonly 
(although perhaps erroneously) consider this decision to stem primarily from the nature 
of the person or government rather than the nature of the situation in which this per­
son or government finds it­self. It is satisfying to attribute deviousness and malevolence 
to our enemies. And if they are devious and malevolent, of course they will en­gage in 
deception. Deception is “them” acting, not just responding to events. When we observe 
activity that we do not otherwise understand, deception may be a more attractive ex­
planation than to simply admit that we have insuf­ficient information or understanding 
of the situation,
Our recollection of the many cases in which deception has proven successful makes 
us think we should be more rather than less sensitive to the possibility of deception. But 
the fact that deception is generally successful does not mean people are insufficiently 
disposed to perceive it, or that increased alertness will protect us from being taken in. 
Deception is gen­erally successful despite our predisposition to perceive it, not because 
of any tendency to overlook this possibility. As we shall see shortly, greater alertness 
to deception increases our vulnerability to the most common form of deception. To 
determine whether governments tend to be oversensitive to deception or not sensitive 
enough, it is insufficient to look only at the many cases in which countries have been de­
ceived. It is equally necessary to examine cases in which they have perceived deception 
erroneously. Such cases may be equally common but are seldom documented as they are 
intrinsi­cally less interesting to historians.
Conclusion
We have examined a number of perceptual and cognitive biases and their implications 
for strategic deception and counterdeception. For quick refer­ence, the biases and their 
implications are summarized in tabular form in the Appendix. Three primary conclu­
sions emerge from this examination.
1.	 Perceptual and cognitive biases strongly favor the deceiver as long as the goal of 
deception is to reinforce a target’s preconceptions or to simply create ambiguity 
and doubt about the deceiver’s intentions. Under these circumstances, which are 
by far the most common forms of deception,30 the deceiver clearly holds most of 
the cards. If the situation is such that the deceiver can achieve planned goals only 
by changing the target’s preconceptions, how­ever, the target is shielded by many 
of the same perceptual and cognitive biases that otherwise work to his or her 
disadvantage.
2.	 While security is obviously desirable for any deception plan, perfect security is 
rarely attained and deceptions succeed without it. When the deception is planned 
to reinforce preconceptions, the target’s ability to rationalize discrepant informa­
tion tends to offset security leaks and uncontrolled channels of information.  Even 
after a source of information has been discredited, impres­sions created by the 
information from that source tend to persist.
3.	 Analysts are generally predisposed to perceive deception. In­stances of successful 
deception are far easier to recall than cases in which deception was not employed 

Cognitive Factors in Deception and Counterdeception
128 
The Art and Science of Military Deception
under similar circum­stances, and this sensitizes us to the possibility of deception. 
We are attracted to deception as an explanation for otherwise in­congruous events 
because the deception explanation enables us to impose order and reason on a dis­
orderly world, and because it en­ables us to attribute deviousness and malevolence 
to our enemies. These factors sometimes cause us to perceive deception when it is 
not really present.
One might think that the analysts’ predisposition to perceive deception would offset 
the advantages we have attributed to the deceiver, but such is not the case. Deception is 
generally successful despite the target’s alert­ness. According to Barton Whaley’s analysis 
of 68 cases of strategic sur­prise or deception between 1914 and 1968, deception was 
successful in 91% of the cases in which it was attempted.31  As in so many other fields, 
major advantages accrue to the actor who seizes the initiative, rather than to the reactor 
who seeks to parry the initiatives of others. Whaley’s finding highlights the unenviable 
position of the intelligence analyst seeking to avoid being deceived, and the remainder 
of our conclusion is devoted to a closer look at the analyst’s plight and what might be 
done to alleviate it.
The fundamental problem involved in avoiding deception, and avoiding intelligence 
surprise in general, is the problem of determining when to change our mind in response 
to new information that does not jibe with our current conception. If we are unrecep­
tive to new information, we can­not learn from experience or keep abreast of changing 
circumstances and situations. If we are too receptive, we are unduly influenced by the 
most recent report or the latest short-term trend. There is no magic formula that tells 
us when to discount discrepant evidence and when to revise our thinking to take it into 
account. But as a general rule, we err more of­ten on the side of being too wedded to our 
established views and thus too quick to reject information that does not fit these views, 
than on the side of being too quick to revise our beliefs. Thus, most of us would do well 
to be more open to evidence and ideas that are at variance with our preconceptions.
In his study of surprise attacks, Abraham Ben-Zvi identified two kinds of informa­
tion on which estimates of impending conflict might be based—strategic assumptions 
and tactical indicators.32  Examples of strategic assumptions include the U.S. belief in 
1941 that Japan wished to avoid war at all costs because it recognized U.S. military 
superiority, and the Israeli belief in 1973 that the Arabs would not attack Israel as long 
as they lacked sufficient airpower to secure control of the skies. Such pre­conceptions 
are based on a large body of interrelated evidence and have usually been held for a 
long time. Tactical indicators are the specific reports concerning preparations or intent 
to initiate hostile action, or more generally, specific evidence from current events that 
indicates the direction in which events are moving. This distinction between strategic 
assumptions and tactical indicators is very similar to the distinction we have been mak­
ing between pre-existing beliefs and new information.
Ben-Zvi studied five cases of intelligence failure to foresee a sur­prise attack: Pearl 
Harbor, German attack on the Soviet Union in 1941, Chinese intervention in the Ko­
rean war, Chinese attack on India in 1962, and the Arab attack on Israel in 1973. He 
found that in each case tacti­cal indicators of impending attack were present but were 
discounted because they conflicted with analysts’ and policy makers’ preconceptions.4 
4.	
 CIA post mortems on cases of intelligence failure have also found that information that would have permitted an accurate 
assessment was generally available, but that this information assumed significance only with the benefit of hindsight.

 
Cognitive Factors in Deception and Counterdeception
The Art and Science of Military Deception	
129
The strategic assumptions were not revised in the light of the increasing flow of contrary 
tactical information. Ben-Zvi argues that whenever stra­tegic assumptions of intention 
to attack and tactical indicators of impend­ing attack converge, an immediate threat is 
perceived and appropriate pre­parations are made. But when there is a divergence be­
tween strategic as­sumptions and tactical indicators, the strategic assumptions always 
pre­vail. Thus despite the evidence of preparations for an attack, the actual attack comes 
as a “surprise,” as in the five cases analyzed. Ben-Zvi concludes that tactical indicators 
should be given increased weight in the decision making process.
This may well be appropriate advice. It certainly accords with our conclusion that 
people err most often by being too quick to reject new in­formation that does not con­
form to their preconceptions. But Ben-Zvi does not consider cases in which alarming 
tactical indicators have been proper­ly discounted as maneuvers, bluff or deception rath­
er than as indicators of impending attack. Ascribing more weight to tactical indicators 
in all cases will increase the frequency of false alarms, and this too entails costs. While 
we should in general be more open to changing our minds as a result of discrepant tacti­
cal or other information, in any single case it is impossible to know a priori whether we 
should revise our estimate or stick with a long-established view.
Alertness to the possibility of deception can influence the degree of one’s openness 
to new information, but not necessarily in a desirable direc­tion. The impetus for chang­
ing one’s estimate of the situation can only come from the recognition of an incompat­
ibility between a present estimate and some new evidence. If people can explain new 
evidence to their own  satisfaction with little change in their existing beliefs, they will 
rarely feel the need for drastic revision of these beliefs. Deception provides a readily 
“available” explanation for discrepant evidence; if the evidence does not fit one’s pre­
conceptions, it may be dismissed as deception. Fur­ther, the more alert or suspicious one 
is of deception, the more readily available is this explanation. Alertness to deception 
presumably prompts a more careful and systematic review of the evidence. But anticipa­
tion of deception also leads the analyst to be more skeptical of all the evidence, and to 
the extent that evidence is deemed unreliable, the analyst’s pre­conceptions must play a 
greater role in determining which evidence to be­lieve. This leads to a paradox: the more 
alert we are to deception, the more likely we are to be deceived.
Actually, this paradox applies only to the type of deception in which the deceiver’s 
goal is to exploit and reinforce our preconceptions. If the deceiver’s goal is to sow con­
fusion or make us change our mind, it will be to our advantage to ignore the evidence 
and stand by our preconceptions.
The problem of how to detect deception is not generically different from other 
common problems of intelligence analysis. It is, for example, very similar to the general 
problem of early warning. From a cognitive per­spective, there are no prescriptions that 
apply uniquely to the deception problem. Consideration of ways to improve our abil­
ity to detect deception is a part of the much broader problem of improving intelligence 
analysis in general.
While cognitive psychology does not provide direct insights on how to detect decep­
tion, it can be of indirect assistance. By better understand­ing how our mind processes 
information, including the diverse perceptual and cognitive biases to which we are sub­
ject, we can hope to compensate for some of these basic problems in human informa­
tion processing. We can iden­tify situations in which our normal faith in our impres­
sions should be suspended, and in which some more systematic means of handling the 

Cognitive Factors in Deception and Counterdeception
130 
The Art and Science of Military Deception
evi­dence may be appropriate. We can also identify guidelines concerning the types of 
analytical methods that may be most useful in supplementing in­tuitive judgment.
A common factor in cases of successful deception, and in most cases of intelligence 
surprise in general, is that analysts have become fixed in a mind set that does not re­
spond effectively to discrepant information. Thus methods for breaking mind sets are 
particularly relevant to the pro­blem of detecting deception.  This includes such practices 
as competitive analysis, use of a devil’s advocate to analyze alternative scenarios, in­
terdisciplinary brainstorming and other techniques that facilitate the identification and 
analysis of alternative hypotheses.
Current research suggests that people perform poorly at generating a full set of 
hypotheses.33  If the correct hypothesis is not even formula­ted for consideration, there 
is clearly little chance of making an accurate estimate. Formation of alternative hypoth­
eses and identification of the indicators and observables associated with each hypoth­
esis helps direct an economical search for information. The hypotheses also serve as an 
organ­izational structure for storage and recall of information in memory.
There is a strong tendency to view the significance of evidence in terms of the degree 
to which it supports, contradicts or seems irrelevant to what we already believe to be the 
case. We overlook the fact the evidence we think of as supporting our case may also be 
quite consistent with sev­eral alternative hypotheses, so we draw from the evidence false 
confirma­tion of our pre-existing beliefs. We can avoid this by evaluating the evi­dence 
in terms of its diagnosticity in helping revise our estimates of the relative likelihood of 
each hypothesis.
As we saw in the old woman-young lady experiment, it is difficult to look at the 
same data from several different perspectives. Yet this is exactly what is required for 
the simultaneous evaluation of multiple hypo­theses. Some sort of methodological aid is 
useful to facilitate this task, as an aid to memory and to help integrate the many proba­
bilistic judgments that are required. There are a variety of computer programs available 
for this purpose,34 but significant benefits might also be obtained by simple paper-and-
pencil techniques.
Our intention in these final paragraphs has been to be suggestive, not prescriptive. 
Traditional, intuitive methods of analysis have not been sufficiently effective in detect­
ing deception, so it is necessary to explore other alternatives. We have tried to point out 
some useful directions for this exploratory effort, but a fuller discussion of analytical 
methodology goes far beyond the scope of this paper. 
Appendix
Review of Biases and Their Implications for Deception
Bias
Implication
Perceptual
Biases
We tend to see what we expect to see.  It takes more in­
formation to recognize an unexpected phenomenon than 
an expected one.
It is far easier to reinforce a target’s existing preconcep­
tions than to change those beliefs.  

 
Cognitive Factors in Deception and Counterdeception
The Art and Science of Military Deception	
131
Perceptions are quick to form but resistant to change.  
Once we have formed an impression about an object, 
event or situation, we are biased toward continuing to 
perceive it in the same way.
It is far easier to reinforce a target’s existing preconcep­
tions than to change them.  Ability to rationalize contra­
dictory information may offset hazards of security leaks 
or uncontrolled channels.
Initial exposure to ambiguous or blurred stimuli inter­
feres with accurate perception even after more and better 
information becomes available.
Impact of information can be affected by the sequence 
used in feeding it to a target.
Biases in Estimating Probabilities
We estimate probability according to how easily we 
can imagine an event or recollect instances of the event.  
Known as availability bias.
Because deception is more salient than absence of decep­
tion, analysts will believe deception is more common 
than it really is, and thus be more disposed to perceive it.  
Employees of watch offices will generally overestimate the 
probability of whatever they are watching for.  This leads 
to the cry wolf syndrome that can be exploited by decep­
tion planners.  Analysts seeking to avoid surprise should 
not make judgments based on availability.    
We estimate probability by seizing upon some natural 
starting point as a first approximation, then adjust the 
estimate incrementally in response to new information 
or further analysis.  Normally we do not adjust enough.  
Known as anchoring bias.
Because people do not revise their judgments enough as 
new information is received, it is easier to conduct a de­
ception aimed at reinforcing the target’s existing precon­
ceptions than to change these beliefs. 
In translating our subjective feelings of certainty into 
a probability estimate, we are generally overconfident 
about how much we know.
Overconfidence exacerbates the impact of all the biases, 
for if we are satisfied with our judgments we will make 
fewer efforts to improve them.  An overconfident target is 
easier to deceive when the deception involves exploiting 
existing preconceptions.
Biases in Evaluating Evidence
We are biased toward seeing events as part of an orderly, 
causal pattern. Randomness, accident and error tend to 
be rejected as explanations for obser­ved events. We over­
estimate the extent to which other people or countries are 
pursuing a coherent, rational goal-maximizing policy.
We are predisposed to perceive deception even when it is 
not really there. As a causal explanation, deception is in­
trinsically satisfying because it is so orderly and rational.
We tend to attribute the behavior of others to the nature 
of the person or country, while we see our own behavior 
as conditioned by the nature of the situation in which we 
find ourselves. 
We are predisposed to believe our enemies will engage in 
deception.  It is satisfying to attribute deviousness and 
malevolence to our enemies, and if they are devious and 
malevolent, of course they will engage in deception. 
Endnotes
1.	
Herbert A. Simon, Models of Man: Social and National (New York: Wiley, 1957).
2.	
Robert Jervis, Perception and Misperception in International Poli­tics (Princeton, N.J.: Princeton University 
Press, 1976).
3.	
Ibid., p. 3.
4.	
Richard Betts, “Analysis, War and Decision: Why Intelligence Failures Are Inevitable,” World Politics, XXXI 
(October, 1978), 65.

Cognitive Factors in Deception and Counterdeception
132 
The Art and Science of Military Deception
5.	
Jerome S. Bruner and Leo Postman, “On the Perception of Incongruity: A Paradigm,” in Perception and Per­
sonality: A Symposium, eds. Jerome S. Bruner and David Krech. New York: Greenwood Press, 1968.
6.	
Jervis, op. cit., Chapter 10.
7.	
Betts, op. cit., p.84.
8.	
Drawings devised by Gerald Fisher in 1967.
9.	
Jervis, op. cit., p. 195.
10.	
This picture was originally published in Puck magazine in 1915 as a cartoon entitled “My Wife and My 
Mother-in-law.”
11.	
Jerome S. Bruner and Mary C. Potter, “Interference in Visual Recog­nition,” Science. 144 (1964), 424-425.
12.	
Amos Tversky and Daniel Kahneman, “Availability: A Heuristic for Judging Frequency and Probability,” 
Cognitive Psychology. 5 (1973), 207-232.
13.	
Amos Tversky and Daniel Kahneman, “Anchoring and Calibration in the Assessment of Uncertain Quanti­
ties,” Oregon Research Institute Research Bulletin, 12 (1972).
14.	
R. M. Cambridge and R. C. Shreckengost, Are You Sure? The Subjec­tive Probability Assessment Test (Infor­
mation Science Center Monograph, Office of Training, Central Intelligence Agency, March 1978).
15.	
Sarah Lichtenstein, Baruch Fischhoff and L. D. Phillips, Calibra­tion of Probabilities: The State of the Art. 
Technical Report DDI-3 (Eugene, Oregon: Oregon Research Institute, 1976).
16.	
M. Alpert and H. Raiffa, “A Progress Report on the Training of Probability Assessors,” Unpublished Manu­
script (Cambridge, Mass.: Harvard University, 1968).
17.	
Nicholas Schweitzer, “Bayesian Analysis: Estimating the Probabil­ity of Middle East Conflict,” Quantitative 
Approaches to Political Intelli­gence: The CIA Experience, ed. Richards J. Heuer, Jr. (Boulder, Colo.: Westview 
Press, 1978); Stephen J. Andriole, “Computer-Based Bayesian Fore­casting Methodologies” and Richards J. 
Heuer, Jr., “Applications of Bayesian Inference in Political Intelligence,” both in Gerald W. Hopple and James 
A. Kuhlman, eds., Expert Generated Data: Applications in International Affairs (Boulder, Colo.: Westview 
Press, Forthcoming 1980).
18.	
Daniel Kahneraan and Amos Tversky, “Intuitive Prediction: Biases and Corrective Procedures,” Management 
Science, special issue devoted to fore­casting applications, in press.
19.	
Baruch Fischhoff, Paul Slovic and Sarah Lichtenstein, Fault Trees: Sensitivity of Estimated Failure Probabili­
ties to Problem Presentation, Tech­nical Report PTR-1042-77-8 (Eugene, Oregon: Decision Research, August, 
1977).
20.	
R. R. Lau, M. R. Lepper and L. Ross, “Persistence of Inaccurate and Discredited Personal Impressions: A 
Field Demonstration of Attributional Perseverance,” paper presented at 56th Annual Meeting of the Western 
Psycho­logical Association (Los Angeles, April 1976).
21.	
Lee Ross, Mark R. Lepper and Michael Hubbard,”Perseverance in Self­Perception and Social Perception: Bi­
ased Attributional Processes in the Debriefing Paradigm,” Journal of Personality and Social Psychology, 32, 5 
(1975), 880-892.
22.	
Lee Ross, Mark R. Lepper, Frit Strack and Julia Steinmetz, “Social Explanation and Social Expectation: Ef­
fects of Real and Hypothetical Ex­planations on Subjective Likelihood,” Journal of Personality and Social Psy­
chology. 33, 11 (1977), 818.
23.	
Barton Whaley, Stratagem. Deception and Surprise in War (MIT, Un­published Manuscript, 1969), 164.
24.	
Ellen J. Langer, “The Psychology of Chance,” Journal for the Theory of Social Behaviour. 7 (1977), 185-208.
25.	
Gina Bari Kolata, “Paleobiology: Random Events over Geological Time,” Science. 189 (1975), 625-626.
26.	
B. F. Skinner, “Superstition In the Pigeon,” Journal of Experi­mental Psychology. 38 (1948), 168-172.
27.	
B. F. Skinner, “Superstition In the Pigeon,” Journal of Experi­mental Psychology. 38 (1948), 168-172.
28.	
Based on author’s discussion with CIA analysts.
29.	
For a more detailed discussion of these, see Jervis, op. cit., Chapters 8 and 9.
30.	
Based on secondary analysis of Whaley, op. cit., Appendix B.  Of the cases of deception studied by Whaley, 
792 exploited the target’s pre­conceptions.
31.	
Based on secondary analysis of Whaley, op. cit., Appendix B.
32.	
Abraham Ben-Zvi, “Hindsight and Foresight: A Conceptual Framework for the Analysis of Surprise Attacks,” 
World Politics, XXVIII, 3 (1976), 381-395.

 
Cognitive Factors in Deception and Counterdeception
The Art and Science of Military Deception	
133
33.	
Thomas Mehle and Charles Gettys, “Pre-Decision Behavior: Are People Any Good at Coming Up with Hy­
potheses?”, paper presented at the Bayes Conference (Los Angeles, February 1979). Additional research on 
this topic is underway at the Decision Processes Laboratory, University of Oklahoma.
34.	
Programs of this type for use in early warning and other intelli­gence problems have been developed by several 
contractors, in particular Decisions & Designs, Inc., McLean, Va. For several references, see footnote 17.


135
C H A P T E R  17
The Theory of Practical Joking—Its Relevance to 
Physics1
R. V. Jones
Dr. Jones was a leading military deception planner, experimental physicist, and practical 
joker—three nominally separate activities that he links by theory in this landmark paper.  
By doing so, Jones extends his special theory of military deception into other disciplines 
in order to create the first general and systematic theory of deception.
Specifically, Jones argued that practical jokes and hoaxes work for the same rea­
sons that military deception plans work.  Both involve “induced incongruities” where, 
by presenting false evidence, the deceiver lets the victim “build up an incorrect but 
self-consistent world-picture,” thus causing him to take actions that are incongruent 
with reality.  Dr. William Harris took Jones’s concept and proposed that it be reverse 
engineered to detect deception—a process he labeled “incongruity analysis” and, later 
“incongruity testing.”  Whaley then applied Incongruity Analysis as the basis of all de­
ception detection or counterdeception.
1.	
R. V. Jones, “The Theory of Practical Joking: Its Relevance to Physics,” Bulletin of the Institute of Physics, Vol. 8, 
June 1957, pp. 193-201. © Institute of Physics.  Reproduced by permission of IOP Publishing.  

The Theory of Practical Joking—Its Relevance to Physics
136 
The Art and Science of Military Deception

 
The Theory of Practical Joking—Its Relevance to Physics
The Art and Science of Military Deception	
137

The Theory of Practical Joking—Its Relevance to Physics
138 
The Art and Science of Military Deception

 
The Theory of Practical Joking—Its Relevance to Physics
The Art and Science of Military Deception	
139

The Theory of Practical Joking—Its Relevance to Physics
140 
The Art and Science of Military Deception

 
The Theory of Practical Joking—Its Relevance to Physics
The Art and Science of Military Deception	
141

The Theory of Practical Joking—Its Relevance to Physics
142 
The Art and Science of Military Deception

 
The Theory of Practical Joking—Its Relevance to Physics
The Art and Science of Military Deception	
143

The Theory of Practical Joking—Its Relevance to Physics
144 
The Art and Science of Military Deception

145
C H A P T E R  1 8
Styles in Deception1
Amrom Katz
Amrom Katz was an early expert on space reconnaissance.  Between 1941–1954 his 
research led to the improvement of photographic reconnaissance equipment.  He went 
on to serve as the chief civilian physicist at an air reconnaissance lab at Wright-Patterson 
Air Force Base.  In 1954, Katz joined the RAND Corporation as a senior scientist, 
where he focused on reconnaissance systems for airplanes and aircraft.
Styles in Deception
With arts voluptary I couple practices joculary; for the deceiving of the senses is 
one of the pleasures of the senses.
—Francis Bacon, The Advancement of Learning, 16052
There are at least two types of deception. The first is illustrated by three-card Monte, 
a popular game at state fairs, carnivals, and elsewhere. The operator of the game (who 
is usually the winner in the short run and is always the winner in the long run) shuffles 
three cards on a table, with all three cards remaining in full view of the bettor. One of the 
cards is, perhaps, a queen of spades and is shown to the bettor. After turning the three 
cards face down, the operator moves them in and out of position. The trick is to deceive 
the bettor, in full view, about which card is the queen. Another version of this game is 
played with three walnut shells and a pea. This is what we can and will call surreptitious 
deception. The replacement of one type of ICBM in the silo by a larger, more advanced 
ICBM while we are presumably monitoring known missile sites is properly described as 
surreptitious deployment. However, the deployment of ICBMs by methods not known 
to us, in places we do not know about, leaving target signatures that are either unde­
tectable, so nondescript as to catch no one’s attention, unidentifiable, or misidentified 
should properly be called covert deployment. It is a good bet that the U.S. intelligence 
community would do much better at detecting surreptitious deployment of ICBMs than 
at detecting covert deployment. For exactly the same reason, the Soviet Union is more 
likely to deploy extra missiles covertly than to deploy them surreptitiously—if they 
choose to cheat at all.
We can arbitrarily divide camouflage-and-deception (C/D) methodology into two 
types: A and B. C/D Type A is very technical: encrypting telemetry, jamming receivers, 
putting out false signals, substituting space shots for MIRV testing. Type A is very mod­
ern, very technological, very elegant—a match for our skills, aptitudes, techniques, and 
style. We would expect the Soviets to do this if they do anything. Camouflage, elegant 
1.	
Amrom Katz, “The Fabric of Verification: The Warp and the Woof,” in Verification and SALT: The Challenge of 
Strategic Deception, William Potter, editor, Boulder, CO: Westview, 1980, pp. 211-212.
2.	
 Sir Francis Bacon.

Styles in Deception
146 
The Art and Science of Military Deception
or otherwise, of standard methods of constructing missile sites would be included in 
this. It is what we expect the Soviets to do; it is a game we might win.  
So why should they play this game? Because we prefer it, we’re prepared for it, and 
we’re good at it? These are precisely the reasons why they should choose an alternate 
course and go to C/D Type B. Type B is characterized by attempts to cause us to look in 
the wrong places, to give us a form of intelligence judo, to throw us a bone that we can 
chew on for a while (such as a poorly camouflaged site). In the meantime, the Soviets 
could be tearing off in another direction (without our following), so that we may miss 
an entire phenomenon. C/D Type B is very ingenious and characterized by a modus ope­
randi that we are unprepared to believe in, expect, react to, detect, appreciate, under­
stand, or be good at. In short, it’s not our style. By temperament, style, preference, and 
mentality, our people are geared—and geared very well—to cope with and, perhaps, 
win at C/D Type A. 
What about Type B? It requires another type of person who is not encountered of­
ten, who would expect the Soviets to be doing C/D Type B and would worry about it.

147
C H A P T E R  1 9
The Process of Deception
Barton Whaley
The deception planning process is often implied in the literature on deception. Here, this 
process is made explicit.
The Process of Deception has, in the following sequence, 10 steps:
1.	 In planning a deception, the planner must know its strategic goal. For the magi­
cian, this is always simply to provide the audience with a pleasing and surprising 
effect or puzzle, for that is all they expect if he is to earn his keep. For the military 
commander, it may be to launch a surprise invasion of another country, effect a 
landing on an enemy beach with minimum initial opposition, get the jump on the 
enemy with a new attack or counter-attack, or simply get a reconnaissance or res­
cue party in and out of hostile territory with sufficiently low casualties to assure 
success. These goals pose the kinds of problems that the planner initially faces; 
they are the givens he must work within.
2.	 The planner must decide how he wants his target to react in such a given situ­
ation.  The magician requires only that his audience concentrate their attention 
and interest on the portrayed effect to the exclusion of the secret method. For 
the military deception planner, however, the problem is more subtle, as best put 
by Britain’s most experienced WWII deception planner, Brigadier Dudley Clarke, 
head of the so-called A Force deception planning team in Cairo:
In the first Deception Plan I ever tackled I learned a lesson of inestimable value.
The scene was Abyssinia... Gen. Wavell wanted the Italians to think he was about to 
attack them from the south in order to draw off forces from those opposing him on the 
northern flank.  The Deception went well enough—but the result was just the opposite 
of what Wavell wanted. The Italians drew back in the South, and sent what they could 
spare from there to reinforce the North, which was of course the true British objective. 
After that it became a creed in ‘A’ Force to ask a General ‘What do you want the enemy 
to do?’, and never ‘What do you want him to think?’
3.	 Only then must the planner by himself—whether general or magician—decide 
what he wants the target to think about the facts or event, precisely what it is they 
should perceive.
4.	 He must decide specifically what is to be hidden about those facts or impending 
events and what is to be shown in their stead. In doing this he should remember 
the caveat that hiding and showing ideally take place simultaneously, as any de­
viation from simultaneity gives the target more time to discover the switch. In 

The Process of Deception
148 
The Art and Science of Military Deception
military practice, hiding usually takes place prior to showing, only sometimes 
simultaneously, and fortunately rarely afterwards because of the extreme risk.
5.	 The planner now analyzes the pattern of the real thing to be hidden so as to iden­
tify its distinguishing characteristics (charcs), specifically which of these charcs 
must be deleted or added in order to give another pattern that suitably masks, 
repackages, or dazzles.
6.	 He does the same for the false thing to be shown to give another pattern that 
plausibly mimicks, invents, or decoys.
7.	 At this point the planner has designed a desired effect together with its hidden 
method. He must now explore the means available for presenting this effect to the 
target. The magician may be limited by the type of apparatus he has at hand, his 
ability to purchase or construct appropriate new apparatus, or his theatrical abil­
ity. Military commanders or practitioners of intelligence may be limited by their 
available deception assets and will often have too little time to acquire additional 
ones. They must make do or go back to Stage Four planning and try for an alter­
native design.
8.	 Having the effect and the means, the planning phase has ended and the opera­
tional phase begins. In magic, the planner is usually also the performer. In the 
military and intelligence fields, the deception planner usually hands over the plan 
of execution to operational units to present (sell) the effect.
9. 	 The channels through which the false charcs (and patterns) are communicated 
must be ones open (directly or indirectly) to the target’s sensors. A magician 
should not use a ‘false count’ of clicking coins before a deaf spectator. An intelli­
gence officer should not plant disinformation in a newspaper unless he has reason 
to believe the enemy monitors that paper.
10.	 In order for the deception to succeed, the target must accept (buy) the effect, per­
ceiving it as an illusion. Deception will fail at this point only if the target takes 
no notice of the presented effect, notices but judges it irrelevant, misconstrues its 
intended meaning, or detects its method. Conversely, the target will:
•	 Take notice, if the effect is designed to attract his attention;
•	 Find it relevant, if the effect can hold his interest;
•	 Form the intended hypothesis about its meaning, if the projected pattern of 
charcs is congruent with patterns that are already part of his experience and 
memory; and
•	 Fail to detect the deception, if none of the ever-present charcs that are incongru­
ent are accessible to his sensors.
Effective deception planning must anticipate all four of these contingencies. And a 
wise deceiver will seek feedback, monitoring the target’s responses, to assure that these 
four contingencies are being met.

149
Section V: 
Deception Traditions
Introduction
Deception Traditions
The use of guile in military and political affairs has been present in varying degrees, over 
time, in all cultures. In fact, the rules of the game have changed little since antiquity. 
Sun Tzu and Clausewitz now rank as the two quintessential philosophers of war and 
appear on every military officer’s reading list. They seem to represent two important but 
distinct military traditions. The connection between politics and strategy is common to 
both, but Clausewitz’s advocacy for battle and Sun Tzu’s preference for deception in lieu 
of battle has inaccurately portrayed the Western way of war as preferring open battle 
to that of Oriental trickery. In actuality, there is little in Sun Tzu not found in Western 
military treatises. 
At the same time that Sun Tzu declared that deception is the Tao of war, the Greek 
Xenophon was preaching that every general must be a contriver of stratagems and that 
stratagems produce the greatest effects in war. Devising stratagem has historically been 
linked to the definition of the good general. The difference between China and the West 
is that Sun Tzu offers a succinct handbook filled with handy maxims for memorization. 
In contrast, the obscure plodding style of a Thucydides is less accessible and much of 
Western military thought, though advocating many of the same principles as Sun Tzu, 
is tedious.1
Mao Zedong read Sun Tzu as did Che Guevara and other modern guerrilla warfare 
icons. The intensification of interest in Sun Tzu in the 1960’s created a cult and the 
Western fascination with him continues with no end in sight.
The mostly accepted notion of Western war as heroic, face-to-face open battle, 
versus the Eastern ethos of trickery, deceit, misdirection and the avoidance of pitched 
battle, is deceptive in its own right. Both balance of power situations and asymmetrical 
power relationships promote stratagems. The Cold War nuclear balance fueled decep­
tion just as stratagems of weak actors against numerically, logistically, and technologi­
cally superior powers manifest themselves in the strategy and tactics of guerrilla warfare 
and terrorism.
The cult of Sun Tzu may exaggerate his unique merits. We should not ignore other 
cultural traditions of stratagem. Kautilya, the Hindu Machiavelli, composed his Artha­
shastra, allegedly ca 300 B.C. Nor should we ignore the Islamic tradition of stratagem 
1.	
Everett L. Wheeler, “Stratagems in the Western Tradition: Reflections and Response,” paper presented at the Con­
ference on Strategic Deception in Modern Democracies: Ethical, Legal, and Policy Challenges, sponsored by the 
Triangle Institute for Security Studies, The United States Army War College, The U.S. Naval Academy, and Duke 
University’s Kenan Institute for Ethics, Chapel Hill, NC, October 31–November 1, 2003.

Section V: Deception Traditions 
150 
The Art and Science of Military Deception
captured in the book, The Subtle Ruse: The Book of Arabic Wisdom and Guile. An 
ancient Arab proverb asserts that a trick is worth more than a tribe.
The perception of Western honor and open war versus Oriental trickery paints 
an artificial picture. Chivalry and honor exist in the Chinese, Japanese, and Hindu 
traditions of war too. The Western belief in the “decisive battle” does not accurately 
represent what Western military treatises actually say. The “cult” often forgets British 
theorist G.F.R. Henderson, whose writings on Stonewall Jackson call for a return of 
maneuver, deception, and surprise. Henderson’s students, Edmund Allenby in WWI 
and A.P. Wavell in WWII, would not forget their mentor’s teachings. Likewise Winston 
Churchill became an advocate of stratagem. Nor should we overlook the writings of 
T.E. Lawrence, a theorist of guerrilla warfare. The inter-war years would see Liddell 
Hart, a reader of Sun Tzu, develop his strategy of the indirect approach that arguably 
opened the WWII stratagematic floodgates.2
We live in an age of stratagems and we also seem to be entering a new age of law­
lessness in international behavior. Not accepting the universality of stratagem can result 
in self-deception.
2.	
 Ibid.

151
A British Tradition of Stratagem: 
And Its Influence on American, Israeli, 
Indian and Pakistani Doctrine


153
C H A P T E R  2 0
Conditions Making for Success and Failure of 
Denial and Deception: Democratic Regimes1
M. R. D. Foot
M. R. D. Foot was an army officer during the Second World War and was awarded the 
French Croix de Guerre for work with the SAS in Brittany. He taught politics and his­
tory at Oxford, and for six years was a professor of modern history at Manchester. Foot 
was the first editor of “Gladstone’s Diaries” and has written—among other books—
“SOE in France” (the official history), “Resistance,” “MI9,” (with J.M. Langley) and 
“Six Faces of Courage.”
1.	
M. R. D. Foot, “Conditions Making for Success and Failure of Denial and Deception: Democratic Regimes,” in 
Strategic Denial and Deception, Roy Godson and James J. Wirtz, editors, NJ: Transaction, 2002, pp. 95–114.

Conditions Making for Success and Failure of Denial and Deception: Democratic Regimes
154 
The Art and Science of Military Deception

 
Conditions Making for Success and Failure of Denial and Deception: Democratic Regimes
The Art and Science of Military Deception	
155

Conditions Making for Success and Failure of Denial and Deception: Democratic Regimes
156 
The Art and Science of Military Deception

 
Conditions Making for Success and Failure of Denial and Deception: Democratic Regimes
The Art and Science of Military Deception	
157

Conditions Making for Success and Failure of Denial and Deception: Democratic Regimes
158 
The Art and Science of Military Deception

 
Conditions Making for Success and Failure of Denial and Deception: Democratic Regimes
The Art and Science of Military Deception	
159


161
C H A P T E R  2 1
Some Notes on the Organization of Deception 
(1944)1
Brigadier Dudley Clarke
Brigadier Dudley Clarke was an officer in the British Army, known as a pioneer of 
military deception operations during the Second World War.  His ideas for combining 
fictional orders of battle, visual deception, and double agents helped define Allied decep­
tion strategy during the war.  For example, in January 1941, Clarke began Operation 
Abeam, fabricating the existence of a British paratrooper regiment in the Mediterranean 
region. It would be two years before such troops reached the Mediterranean region, but 
Clarke played on Italian fears of an airborne assault. 
This piece, long believed lost, was recently discovered in a U.S. archive.2  It is pub­
lished here in its entirety for the first time.
Some Notes on the Organization of Deception in the United States Forces
Deception of the enemy on a systematic, continuous and theater-wide basis was first 
started, so far as I am aware, by General Wavell in the Middle East at the end of 1940.  
The instrument that was devised to affect it was “A” Force; and if I personally were to 
start all over again with the experience of the four succeeding years before me I would 
still build up a machine on the same lines as the “A” Force of 1944.  At the same time I 
am fully conscious that “A” Force was first shaped to meet the special needs of particu­
lar personalities and conditions and then developed to keep pace with a vastly changing 
strategy, so that, however well it may have fitted into the British Mediterranean War 
Machine, it provides by no means a set pattern for other nations and other theaters.  
We have in fact, both here and in N.W. Europe, seen failure in attempts to build up an 
American “A” Force.  It seems clear, therefore, that the United States will need to design 
a special deception organization to fit their own characteristics and the peculiarities of 
their own theaters of operations.  Nevertheless I am venturing to suggest that any such 
organization will only succeed if it is firmly based on certain principles, which I have be­
come convinced from my own experience are sure foundations for this very specialized 
work.  The aim of this paper is to present those principles in an objective and impersonal 
manner, so that the authorities concerned may avoid the very real danger of blunting this 
sensitive weapon by forcing it into place in a rigid military machine.  Rather, I suggest, 
should the machine adapt itself to turn this new weapon to the best advantage against 
the enemy as it has successfully done with so many other innovations.  I have stressed 
1.	
Brigadier Dudley Clarke, Some Notes on the Organization of Deception, 1944. 
2.	
As first reported in a 2005 revised printing of Thaddeus Holt, The Deceivers, NY: Scribner, 2004.  The last four 
paragraphs had been previously published in Michael I. Handel (editor), Strategic and Operational Deception in 
the Second World War, London: Frank Cass, 1987, pp. 88–90.

Some Notes on the Organization of Deception (1944)
162 
The Art and Science of Military Deception
this point at the beginning because I myself have had to meet a certain American intoler­
ance of the apparently illogical situation of “A” Force in fitting neither into a square nor 
a round pigeon-hole.  This comes, I know, from an understandable dislike of “private 
armies”, and a neatness of mind which ranges each component of the war machine in its 
appropriate staff section.  I am sure that a more sympathetic view would prevail if there 
were a clearer understanding of the conditions under which “A” Force came into the 
world and grew up, and I will therefore preface any thesis on principles with an attempt 
to describe in brief the background from which they have emerged.
“A” Force started under two handicaps of which any similar American organisation 
is happily free.  The first handicap was a lack of precedent:  Deception on a big scale had 
never been practiced before and it had to prove its worth at the same time as it was try­
ing to find its feet.  As a result the early “A” Force could only operate freely in the zones 
of operation of the more imaginative commanders who, amid the successive adversities 
of 1941, were prepared to give a trial to anything which offered them a prospect of help.  
This led to the organization extending in an unbalanced way, dependent upon “selling” 
itself, and inevitably shaped to suit the personalities concerned.  Chief among the latter 
was of course General Wavell, who numbered amongst his characteristics a sense of 
security-mindedness far beyond anything we know at the present time.  It may well be 
that we no longer need it to that degree; but in 1941 he was striving, with pitifully in­
adequate forces, simultaneously to recover a shattered army from Greece and Crete, to 
conquer the vast territory of Italian East Africa, to invade Vichy-French Syria, defeat the 
rebel forces of Iraq, and to launch a counter-offensive against the German-Italian Desert 
Armies on the Egyptian border.  Small wonder, perhaps, that he placed security in the 
forefront of his policy, but to the budding “A” Force it represented the second major 
handicap and one which made the “selling” process all the more difficult.  At that time 
we thought, rightly I believe; that deception would only succeed so long as the enemy 
was kept in ignorance of the fact that it was being practiced at all.  From this it followed 
that only the smallest possible inner circle of our own people was initiated into it, and 
every effort was made to hide from all the rest the fact that any Deception Organisation 
even existed.  Hence “A” Force started on the basis of a “Secret Service” — and in fact 
remained so until well on in 1943 — a circumstance which had the greatest influence 
on its growth and on the shape it finally assumed.  In the early days the Commander of 
“A” Force received his instructions in every case direct from the Commander-in-Chief 
himself, either verbally or in the C-in-C’s own handwriting, and dealt with nobody ex­
cept his Chief of Staff and the two Directors of Operations and Intelligence. He held, as 
cover, an appointment on the C-in-C’s personal staff, and no deception document was 
ever handled in GHQ outside the C-in-C’s personal secretariat.  When instructions had 
to be issued by GHQ to implement a deception scheme the C-in-C personally addressed 
them to the Army Commander concerned with the request that no one but his Chief of 
Staff should be informed of their real purpose.  In consequence of this very elaborate 
protection “A” Force was able to preserve an almost complete incognito, and it was 
probably not until 1943 that the enemy began to detect the existence of a far-reaching 
deception machinery in the Allied ranks.  On our side the incognito was dispelled to 
a certain extent during the operations against Sicily, when certain details of the cover 
plan for the landings had necessarily to be disseminated amongst a large force of Brit­
ish, American and Canadian troops to whom it was probably something of a novelty.  
Since then the Germans cannot fail to have realized a good deal of the deceptions that 
have been practiced upon them and, although the need for stringent secrecy regarding 

 
Some Notes on the Organization of Deception (1944)
The Art and Science of Military Deception	
163
deception is still as great as ever, the organizations employed upon it no longer have to 
be hampered by the conditions which affected “A” Force so greatly at the start.
I have tried to picture this background in some detail in order to explain the fact 
that “A” force never started as a logical blueprint conception, but developed by trial 
and error to fit every kind of condition extending from defeat to victory.  For all its 
rigidity the British Army is not a very logically minded institution, and often has suc­
ceeded by this process of trial and error in producing something which “works” no 
matter how illogical it may appear. The peculiar British system of brevet promotion is a 
good example which works extremely well, though it must seem strangely puzzling to 
an American.  I will not, therefore, defend the logic of “A” force, but will claim that in 
shaping itself into something workable it has discovered a few basic facts which must 
be inseparable, from any other organization of the same type.
The first concerns the scope of the organization’s activities and, in particular, the 
directions in which they should be focused. Until this is properly understood there will 
be a tendency to muddle deception with psychological warfare and even to suggest that 
the same instrument can serve both purposes.  A moment’s examination of the aims of 
the two will show this to be fundamentally unsound, and any attempt to mix both in 
practice will be highly dangerous. Nevertheless the danger is often present and is some­
times curiously difficult to dispel.  The essential difference lies of course in the audience 
for whom the two organisations cater.  Psychological warfare starts at the apex of a 
triangle and endeavors to spread its arms as wide as it can to embrace the broadest pos­
sibly base.  It matters little if many of its audience can detect the origin of their messages 
nor if a privileged few can recognize distortion of the truth; its appeal is to the masses 
and it is unlikely to influence the thought or actions of the enlightened inner circles of 
the General Staff.  Deception, on the other hand works in exactly the opposite way.  It 
starts at the base of the triangle and concentrates its influence towards a single point 
at the apex; its essential aim is to conceal the origin of its messages by directing them 
upon this single point from as many different directions as possible.  It cares little for 
the thoughts and actions of the masses, but it must penetrate directly into the innermost 
circles of all. Its audience is narrowed down to a small handful of individuals, as repre­
sented by the senior members of the enemy’s Intelligence Staff, and sometimes even to a 
single individual in the person of the Head of that Intelligence Staff.  If they can influ­
ence him to accept as true the evidence they have manufactured for his benefit, then they 
have accomplished their entire aim, since it is only through the Head of the Intelligence 
that any enemy commander receives the impression of his opponent upon which he has 
to base his plan of operation.  It is necessary, therefore, that the single-purposeness of 
any deception machine should be recognized from the start and its shape dictated by 
the overriding need to concentrate every ounce of its diverse efforts upon that one ulti­
mate target.  As a corollary it follows that those who direct the deception machine must 
have an adequate knowledge of the small group of men on whom all their activities 
are focused, of their national characteristics, their language, thoughts and professional 
methods with all their strengths and their weaknesses.
It is this note on personalities which leads me to the next principle, which I firmly 
believe to be a foundation stone in the successful application of deception.  Deception 
is essentially an art and not a science, and those who practice it must be recognized as 
falling into the category of artists and not of artisans.  This is, I know, difficult to ac­
cept in professional military circles where it is widely believed that the art of war can be 
taught to the average educated man, even though he may have little aptitude for it.  But, 

Some Notes on the Organization of Deception (1944)
164 
The Art and Science of Military Deception
nevertheless, I am convinced it is true; and twice in “A” Force I have seen highly quali­
fied and highly intelligence staff officers of the British Regular Army fail completely to 
cope with the work, although both did brilliantly afterwards on the Operations Staff. 
What they lacked was just the sheer ability to create, to make something out of nothing, 
to conceive their own original notion and then to clothe it with realities until eventually 
it would appear as a living fact.  And, since that is precisely what the Deception Staff 
must do all the time, it follows that the art of creation is an essential attribute in all 
who are charged with such work.  To expect those who have not this art to produce the 
required results will lead to risks beyond that of mere failure.
If this thesis is accepted it is easy to see why one brain — and why one alone — must 
be left unhampered to direct any one deception plan.  It is after all little more than a 
drama played upon a vast stage, and the author and producer should be given as free 
a hand in the theater of war as in the other theater.  (Also, of course, in both they must 
have the necessary qualifications to justify that confidence).  It is not a bad parallel to 
compare a Commander in the field with the impresario who wants to mount a suc­
cessful play at his theater.  He decided on the type of play he wants—drama, comedy, 
musical, etc. and instructs an author to produce a script.  Having accepted the script, 
he appoints a producer to mount the play.  From that point onwards he may well leave 
everything else to those two, and look only to the results obtained.  Provided these are 
satisfactory, the impressario who is not himself an author or producer, wisely leaves 
them to rule the cast, scenery, costumes and all else that goes to make the play.  The wise 
Commander-in-Chief will follow the same example.  In his case the matter is simplified 
by the fact that the head of his Deception Staff doubles the roles of author and pro­
ducer.  The Commander therefore tells him what sort of deception he needs, examines 
the plans produced for him with the required aim in view and, once the final version is 
approved, watches only the results and leaves all else to his specialist.  In both peace and 
war, however, the Chief is the best judge of the results; in both cases he assesses them by 
the reactions of the audience (or the enemy), and should interfere in proportion to the 
degree in which they fail or succeed to achieve the object he himself has set.
And it is this mention of the “object” which brings me to the last of the principles I 
have tried to enunciate.  For the theatrical impressario this presents no difficulty — all 
he wants is to see the audience moved to tears, laughter or rhythm in concert with the 
plan — but to the General it is a problem which merits most careful thought.  His audi­
ence is the enemy and he alone must decide what he wants them to do — to advance?  
to withdraw?  to thin out or to reinforce?   Whatever he chooses, the main point is that 
his “object” [objective] must be to make the enemy DO something.  It matters noth­
ing what the enemy THINKS, it is only what he DOES that can affect the battle.  It is 
therefore wrong, and always wrong, for any Commander to tell his Deception Staff to 
work out a plan “to make the enemy think we are going to do so-and-so.”  It may be 
that the plan will succeed but that the enemy will react to it in a totally unexpected way, 
upon which the Commander will probably blame the Deception Staff who have in fact 
produced exactly the results they set out for.  It is this boomerang effect which has made 
many people apprehensive of using the deception weapon, and it cannot be stressed too 
strongly that, if used in the wrong way, it can prove a real danger.  But there is one sure 
way to avoid any possible risk, and that is to get the OBJECT right.  Given a correct 
“object”, the deception plan may fail but it cannot in any way do harm.  Give it a wrong 
“object” and it will invariably give wrong results. Our theatrical impressario after all 
will not attempt to dictate to the author the plot of the play, but that is precisely what 

 
Some Notes on the Organization of Deception (1944)
The Art and Science of Military Deception	
165
the General does who tells his Deception Staff that he wants the enemy to be made to 
“think” something. It assumes a knowledge of the enemy’s likely reactions which the 
Deception Staff should know from experience very much better than the General.  It is 
for the latter to say what he wants them to do, and for the specialists to decide what the 
enemy must be made to think in order to induce them to act in the manner required.  
Perhaps an illustration will explain this best.  In the early part of 1941 General Wavell 
wanted the Italian reserves drawn to the south in order to ease his entry into Northern 
Abyssinia.  He considered this might be done by inducing them to reinforce the captured 
province of British Somaliland, and he gave instructions for a Deception Plan to be 
worked to persuade the Italians that we were about to invade Somaliland.  Deception 
was new then and on the surface that appeared to all concerned to be a perfectly laud­
able object.  The plan, innocently ignoring the real object of influencing the location of 
the enemy’s reserves, was entirely successful; but the results were totally unexpected.  
In face of the threatened invasion, the Italians evacuated British Somaliland. Not only 
had General Wavell to draw upon his own meager forces to re-occupy the country, but 
the Italian garrison was freed to swell the forces in the north which were to block our 
advance at Keren.  Had a different object been chosen, quite a different deception plan 
would have emerged and perhaps a quite different effect produced upon the actions of 
the enemy.
That concludes this brief review; and I will end by summarizing that to be successful 
any deception organisation needs:	
a.	 To be so organized that it directs the whole of its efforts to influence the enemy’s 
intelligence staff—and that alone.
b.	 To be composed of senior officers with a real knowledge of the intelligence staff 
that is to become their audience.
c.	 To be directed, as specialists in an art, by a Commander and Staff who tell them 
what results they require and who leave them unhampered to arrange the best 
means of obtaining those results.
d.	 To be given an object in terms of the manner in which the enemy is required to 
ACT in order to further the operational plans of their own Commander.
Provided these four principles are faithfully observed, it matters little how the orga­
nization is shaped and it can best take the form most suited to the nationality concerned 
and the theater of war affected.
Rear H.Q. “A” Force
/s/ D.W. Clarke
c/o G.H.Q. M.E.F.
D. W. CLARKE
30 October 1944
Brigadier Commander “A” Force


167
American Attempts at Deception: 
A Spotty Record


169
C H A P T E R  2 2
The Actor’s Tale1
Douglas Fairbanks, Jr.
Douglas Fairbanks, Jr. was commissioned as a reserve officer in the United States Navy 
at the onset of World War II and was assigned to a Commando staff in the United 
Kingdom.   Having witnessed (and participated in) British training and cross-channel 
harassment operations emphasizing the military art of deception, Fairbanks attained a 
depth of understanding and appreciation of military deception then unheard of in the 
United States Navy.  Upon returning from his military career, Fairbanks went into the 
family business of acting, and between 1954 and 1956 he made a number of half-hour 
programs as part of a syndicated series for television called “Douglas Fairbanks, Jr. 
Presents.”
1.	
Douglas Fairbanks Jr., “The Actor’s Tale”, in Trojan Horses,  Martin Young and Robbie Stamp, editors,  London: 
The Bodley Head, 1989, pp. 165–170.  Reprinted by permission of The Random House Group Limited.

The Actor’s Tale
170 
The Art and Science of Military Deception

 
The Actor’s Tale
The Art and Science of Military Deception	
171


173
C H A P T E R  2 3
American Strategic Deception in the Pacific: 
1942–441
Katherine L. Herbig
Taking into consideration Japanese preoccupations and intentions, the strategic de­
mands of being on the defensive, the shortcomings of the Japanese intelligence system, 
and the loss of means to act other than as the deception demanded, the U.S. victory in 
the Pacific War demonstrates the important role of U.S. strategic deception. Strategic 
deceptions like Wedlock were not perfect, and their failings can be as profitably studied 
for lessons as their successes. They were good enough, however, to reinforce concerns 
for areas of secondary importance, to generate additional reinforcements for these areas 
at the expense of reinforcing actual targets, and to waste flagging intelligence resources 
in sorting out superfluous scenarios from true ones. The U.S. was winning the Pacific 
War regardless of its deceptions, on the basis of its much larger pool of economic and 
human resources. Strategic deception helped to reduce the cost in lives by directing and 
holding Japanese forces away from the Marianas and, later on during Bluebird, from 
Okinawa, when these important strongholds were invaded. The history of the Pacific 
War is the more complete for having written into the familiar story the little-known 
chapter on U.S. strategic deception.
1.	
Katherine L. Herbig, “American Strategic Deception in the Pacific: 1942–44,” in Strategic and Operational Decep­
tion in the Second World War, Michael J. Handel, editor, Great Britain: Frank Cass & Co, 1987, pp. 260–264.  
Reprinted by permission of Frank Cass & Co. (Taylor& Francis Group).

American Strategic Deception in the Pacific: 1942–44
174 
The Art and Science of Military Deception

 
American Strategic Deception in the Pacific: 1942–44
The Art and Science of Military Deception	
175


177
C H A P T E R  2 4
A Pentagon Proposal to Continue a Deception 
Organization after WW2 (1945)—General 
Conclusions1
Colonel Newman Smith
Prior to World War II, Newman Smith was a combat veteran and a successful interna­
tional banker who spoke French, German, and Spanish.  He took a position in charge 
of strategic deception in Joint Security Control.  Colonel Smith was one of only four 
American officers to work on strategic deception during the war.  
When the United States entered World War II, the use of military cover and deception 
on a systematic theater and world-wide basis was unknown to the United States Army. 
Its value as a military weapon was conclusively proved during the various campaigns of 
the war. This is generally confirmed by senior Army commanders.
Despite British experience from 1940 until the United States’ entry Into the war and 
the fact that cover and deception had been very successfully practiced by them during 
that time, the United States authorities failed to profit by this experience and did not 
fully grasp its import and value in winning battles until two years later.
While a deception organisation finally was set up within the United States Joint 
Chiefs of Staff organisation, its directives were restricted through a lack of understand­
ing of deception as it was then being practiced, and no firm deception policies were 
formulated until near the end of the war.
Finally after senior commanders were convinced beyond question of the value of 
theater and world-wide cover and deception, no steps were taken for its vigorous devel­
opment in theaters of primary United States responsibility until it was too late to realise 
its full effect.
United States Pacific theater commanders, unfamiliar with results obtained by cover 
and deception in the Mediterranean and European theaters, were indifferent to its use, 
except on a local tactical scale, and initially appeared reluctant to attempt its overall 
employment. 
A preponderance of reserve officers were assigned to cover and deception duties, 
thus failing to provide an adequate nucleus of Regular Army officers for its future 
peacetime development and use.
1.	
Colonel Newman Smith, “A Pentagon Proposal to Continue a Deception Organization after WW2 (1945),” In­
formal Memorandum on the Origin, Development and Activities of the Special (Deception) Section, Joint Security 
Control, 1942–1945, Washington, DC: The Pentagon, November 20, 1945, p. 37, Paragraphs 125–134.

A Pentagon Proposal to Continue a Deception Organization after WW2 (1945)—General Conclusions
178 
The Art and Science of Military Deception
The organisation initially created for implementing deception failed to meet the re­
quirements of the highly specialized and complex character of the mission on a theater 
and world-wide scale.  By splitting functions between different groups, progress in cor­
recting deficiencies was further retarded. 
While the principle of theater and world-wide cover and deception was finally ac­
cepted as a weapon of war, only a piecemeal wartime policy grew out of it. No formal­
ized peacetime doctrine and policy with respect to cover and deception now exists, nor 
is any agency of the War Department charged with its future development. The Navy 
Department has established an organization responsible for the peacetime study and 
development of cover and deception.
General Recommendations
It is urgently recommended:
a.	 That an interim peacetime deception organization be established within the War 
Department at the earliest practicable date to accomplish the missions outlined in 
Section XVII, in collaboration with the Navy deception organization.
b.	 That emphasis be placed upon a thorough study of the experience gained in World 
War II, with a view to the establishment of a permanent peacetime War Depart­
ment and inter-service organization charged with the making of plans and keeping 
them current and in a ready-for-use status.
The Pentagon
Washington, D.C.
November 20, 1945
Newman Smith
Colonel, MI
Chief, Army Special Section

179
A Russian Tradition of Stratagem:
1939 to the Present


181
C H A P T E R  2 5
Catching NATO Unawares: Soviet Army Surprise 
and Deception Techniques
C. J. Dick
Mr. Charles Dick, educated as a historian and trained as an intelligencer, was a Research 
Associate at the Soviet Studies Research Centre, Royal Military Academy, Sandhurst.  
He was the Centre’s Director from 1989, including after its renaming in 1993 as the 
Conflict Studies Research Centre, until his retirement in 1995.
Marx and Lenin teach that victory in war goes to the side with superior resources.  
This is a disheartening notion for the Soviet leadership as the Warsaw Pact is markedly 
weaker than NATO in almost every measure of military potential – size (and reliability) 
of population, wealth, industrial power and technological progress; only in currently de­
ployed military strength is the Pact stronger.  General Secretary Mikhail Gorbachev and 
the Soviet leadership well know that, in 1941, the Germans came within measureable 
distance of destroying Soviet communism, and that in order to preserve their power and 
system, the Soviets must avoid the repetition of such a war.  They realize, as well, that a 
strategic nuclear exchange would make the last war look like a skirmish.  
The Soviets do not, however, seem to conclude from this that a war against NATO 
cannot be won.  Historically they have been conservative in their use of military force, 
and it would be difficult, in 1986, to postulate a plausible scenario for a decision to at­
tack NATO, but they have by no means adopted the fashionable Western notion that 
war can no longer serve as an instrument of policy.  
Surprise in Its Strategic Context
The Soviets conclude instead that a war with NATO must be won very quickly, in its initial 
period: this is defined as “the period of time which elapses between the start of hostilities and 
the completion by the combatants of their mobilization, concentration and deployment.”  
Of course, as the aggressor will have a considerable advance in preparations and mobiliza­
tion over the defender, the concept of the initial period really applies only to the latter.   This 
means that the Soviets must seize a vital area of NATO and destroy key combat groupings 
before NATO can either complete its defensive preparations or agree on the use of nuclear 
weapons.1
1.	
 This section owes a great deal to P.H. Vigor’s admirable Soviet Blitzkrieg Theory, London, 1983.

Catching NATO Unawares: Soviet Army Surprise and Deception Techniques
182 
The Art and Science of Military Deception
The federal German Republic, the economic and military heart of NATO Europe, 
represents, in the Soviet view, just such a small and vulnerable area, which could be 
swallowed up in the course of a single, strategic offensive operation.  The distance from 
the inner German border (IGB) to the Ruhr, across the North German Plain, is only 
300-400km.  The distance to Mainz through the Fulda Gap is only about 150km.  In a 
significant comparison, the Soviets point out, that, in the Vistula-Oder operation dur­
ing World War II, they advanced 500km on a front about 500km wide in 17 days – an 
average of 30km a day for combined-arms (infantry) armies and up to 70km a day for 
tank armies.  In the process, 35 German divisions were totally destroyed and another 25 
suffered 50-70% casualties.  The Soviets see no reason why today’s entirely mechanized 
army could not be at least as effective under favourable circumstances.  
The Soviets identify five essentials for a quick victory.  These are surprise, a heavy 
blow, a rapid advance, simultaneous attacks throughout the enemy’s depth and air 
superiority.  
The Advantages of Surprise
••
Recent Soviet writings stress that “the element of surprise has long been the most 
important principle of military art… The employment in modern combat of nuclear 
weapons, highly effective conventional weapons and highly mobile forces has dras­
tically increased the role and significance of surprise strikes.”2  Surprise is seen to 
confer five advantages. 
••
NATO’s reinforcement plans will be pre-empted and rendered largely unworkable.  
Given the alliance’s maldeployment, it may even be possible to prevent some NATO 
corps from occupying FEBA positions; certainly surprise will thwart NATO’s rather 
extensive obstacle and field fortification plan which could threaten the viability of So­
viet tactical and even operational techniques.  Instead of having to conduct difficult and 
costly breakthrough operation, the Soviets will impose their style of war, clashing with 
NATO formations while they are on the move, in a series of meeting engagements – a 
form of combat for which they train intensively, but which is ignored by most of the al­
liance armies.  The Soviets believe that the meeting engagement will be the typical battle 
in the next war, and their tactics (so often derided by Western officers) are perfectly 
suited to such combats.3
••
Surprise, and the initiative it confers, is seen to be force multipliers making it possible to 
achieve at least a limited strategic objective with much smaller forces than would be re­
quired against a prepared enemy.  A particularly significant example is the Soviet attack 
on Manchuria in 1945 when the Red Army chose to strike with a superiority of only 
1.2:1, but with the advantage of surprise.4  The benefits of surprise in a future war are 
seen similarly to outweigh the disadvantages of incomplete mobilization.  Since surprise 
obviates the need for breakthrough operations, there is no need for large, vulnerable 
2.	
 Lt.Gen. V.G. Reznichenko, Taktika (Moscow, 1984).
3.	
 For a further examination of this important point, see C.J. Dick, “Soviet Battle Drills,” IDR 5/1985, and “Soviet 
Operational Concepts,” Military Review, October and November, 1985.  
4.	
 For the importance of the Manchurian operation in Soviet thinking, see J. Despres, L. Dzirkais and B.Whaley, 
Timely Lessons of History—the Manchurian model for Soviet strategy (Santa Monica, 1976).

 
Catching NATO Unawares: Soviet Army Surprise and Deception Techniques
The Art and Science of Military Deception	
183
concentrations and strong second echelons at every level.5  In short, it undermines the 
rationale of both NATO’s operational nuclear force and the Deep Strike plan, at least 
in its deeper (and more expensive) versions.
••
The concept of operational manoeuvre groups (OMGs) seems to have become an 
essential feature of contemporary Soviet operational planning (see C.N. Donnelly in 
IDR 9/1982 and C.J. Dick in IDR 6/1983).  Surprise makes it much easier to insert 
major groupings into the enemy rear, thus prolonging the effects of surprise.  
••
By ensuring that there will be a series of meeting engagements, surprise lessens 
the logistic burden and the number of casualties in offensive operations.  Soviet 
research shows that, in 1944-45, tank armies involved in fast-moving, manoeuvre 
warfare and advancing at 16-45km a day suffered only one-third the loss in men 
and two-thirds the tank losses (mostly easily repairable mechanical breakdowns) of 
tank armies advancing 4.5-13km a day.  They also used only one-third the amount 
of fuel and one-fourth the quantity of ammunition of the armies involved in fighting 
through a prepared, balanced defense. 
••
It will be just as important for the USSR to surprise the Warsaw Pact as to catch 
NATO unawares.  Otherwise, some reluctant Pact allies might attempt to opt out 
and leak Soviet intentions to the West.  It would be as well to give the ordinary 
soldiers and populations of these allies little time to reflect on the need for and 
desirability of war.
A Heavy Blow
The weight of the blow must be great enough to carry it to the strategic objective (here 
postulated as the Rhine) in a single, non-stop offensive operation.  Moreover, it must 
be delivered by the forces in place in peacetime, as a major mobilization and forward 
deployment would prejudice surprise.  As Marshal V.D. Sokolovski has written: “It is 
necessary to keep deployed in peacetime sufficient armed forces to reach at least the 
nearest strategic objectives before successive echelons are mobilized and sent into action 
… so that the main aims of the war can be attained in the initial period, without addi­
tional mobilization … He who, right from the start, can get his troops deepest into en­
emy territory will be best able to exploit his nuclear strikes and prevent the enemy from 
mobilizing.  This will be of great importance in Europe because distances are so small.”6
Herein, doubtless, lies an explanation for the steady growth of the Group of Soviet 
Forces in Germany (GSFG), and the modernization of the East German Army.  Over 
the last decade, GSFG has expanded by approximately 10% in tanks, 20% in combat 
APCs/MICVs, 35% in artillery and over 50% in attack helicopters.  These increases 
take into account the much publicized Brezhnev troop withdrawals of 1979, and the 
trend shows no sign of changing.  
5.	
See C.N. Donnelly, “The Soviet Concept of Echelonning,” NATO Review, December 1984, and Dick, “Soviet 
Operational Concepts,” op. cit.
6.	
V.D. Sokolovski, Military Strategy, 3rd edition, translated in London, 1975. 

Catching NATO Unawares: Soviet Army Surprise and Deception Techniques
184 
The Art and Science of Military Deception
Speed and Flexibility in the Advance
••
A high tempo of operations has a paralyzing effect on enemy commanders, who be­
come disoriented when prevented from implementing long prepared defensive plans 
and faced with uncertainty about the attacker’s progress and intentions.  They are 
limited to reacting belatedly to the latter’s initiatives, making proper exploitation 
of his weaknesses impossible. 
••
The psychological impact of a rapid advance on enemy commanders, troops and 
civilians alike can quickly induce a climate of collapse, not least in that most im­
portant military objective of all, the minds of the enemy’s political decision-makers.  
The Soviets believe that NATO, being an alliance of disparate, bourgeois states, 
riddled with disaffected groups and with no real cohesion under the surface, is 
prone to this sort of collapse.7
••
Speedy progress can negate the enemy’s nuclear weapons, reducing his decision-
making time and making targeting difficult.  Friendly and enemy units will become 
so intermingled that nuclear strikes will become impossible in many cases.  
Simultaneous Attacks Throughout the Enemy’s Depth
The enemy must be attacked throughout his entire deployment.  Much investment has 
been poured into Soviet forces for this purpose; the operational–tactical missile troops 
now being equipped with missiles accurate enough to deliver improved conventional 
munition (ICM) warheads effectively, long-range strike aviation, seven airborne divi­
sions, at least eight air-assault brigades (a growth area) and many independent battal­
ions, a massive special-purpose forces effort, as well as OMGs and forward and raiding 
detachments from the ground forces.  Apart from spreading confusion and panic, these 
attacks in the enemy’s depth have four principal missions:
1.	 The destruction, or at least disruption, of enemy nuclear delivery means and as­
sociated command, control and logistics. 
2.	 The disruption of the enemy’s command, control and communications. 
3.	 The destruction and disruption of enemy air and air-defense forces as part of the 
counter-air operation. 
4.	 The obstruction and delay of enemy reserve and troop deployments and of the 
withdrawal of defeated enemy elements, as well as disruption of the logistic 
system.  In this way, if the defense crumbles from within, it will be possible to 
dispense with a strong second operational echelon, the mobilization of which 
would prejudice surprise and which is vulnerable to nuclear, or even conventional 
interdiction. 
Air Superiority
This is an obvious precondition both for rapid advance and for deep operations.  The 
counter-air operation has now assumed an importance almost equal to the ground opera­
tion, as has the air-defense operation.  The type of aircraft being supplied to the modern­
7.	
 See B. Byely, et. al., Marxism-Leninism on War and Army (Moscow, 1972).

 
Catching NATO Unawares: Soviet Army Surprise and Deception Techniques
The Art and Science of Military Deception	
185
ized Soviet Air Force, its reorganization and its new operational concepts demonstrate 
the Soviet awareness of this point.  
The Possibilities of Strategic Surprise
Strategic surprise is defined as concealment of the intention to launch an offensive and/
or its timing.8  It is achieved through “large-scale deceptive actions, regroupings and 
concentrations, concealing troops and installations, and misinforming the enemy.”9 His­
torically, the Soviets have been very successful in implementing such measures.  Perhaps 
the most pertinent example is the war with Japan in 1945.  The Japanese knew they 
were going to be attacked, but believed the blow would not fall before March 1946; they 
thought that the bad weather combined with the urgent Soviet need to increase force 
levels in the Far East would preclude an offensive in 1945, while the government was 
taken in by Soviet diplomatic deception.
The Limits of Modern Surveillance
Many experts reject past examples of successful surprise as irrelevant, arguing that mod­
ern means of surveillance make surprise impossible.  In doing so, they ignore three basic 
points.  
1.	 If the aggressor’s objective  is a limited one, as has been postulated for the Sovi­
ets in a war with NATO, then his tell-tale preparations will be correspondingly 
small (given as high a level of peacetime preparedness as that of the GSFG and of 
selected non-Soviet Warsaw Pact formations). 
2.	 Surveillance merely provides data.  Technical progress in intelligence gathering 
has not made interpretation any easier nor lessened the possibilities for deception 
and disinformation.  This is particularly important because the people that the 
Soviets have to surprise are NATO’s political leaders, who will make the crucial 
decisions about mobilization and deployment.  Political leaders, at least in a de­
mocracy, may be overly cautious, concerned that a hasty reaction could provoke 
the very war they wish to avoid.  
3.	 Surprise does not have to be total to impart of substantial advantage to an aggres­
sor.  This is particularly true if the objective is a limited one and victory can be 
achieved before its effects have worn off.  
It must be remembered that, while progress in the surveillance field has indeed 
amounted to a “transparency revolution”, other technological advances have actually 
made surprise easier to achieve.  The increased range of modern missiles and aircraft 
makes it possible to deliver a massive, deep, highly accurate blow (conventional as well 
as nuclear) without warning.  The time required to move fully mechanized, combat-
ready formations in the forward area from their peacetime garrisons to their deploy­
ment areas is now to be reckoned in hours, rather than the days or weeks that used to 
8.	
 This section owes much to Michael I. Handel, “Intelligence and Deception” and “Intelligence and the Problems of 
Strategic Surprise,” Journal of Strategic Studies, 1/1982 and 3/1984, respectively. 
9.	
 Quotation from Major General Matsulenko, “Operational Maskirovka in the Third Period of the Great Patriotic 
War,” the Great Soviet Encyclopaedia, Vol.15. 

Catching NATO Unawares: Soviet Army Surprise and Deception Techniques
186 
The Art and Science of Military Deception
provide ample warning.  Moreover, the equipment, structures and training of many con­
temporary armies make it very difficult to distinguish between offensive and defensive 
preparations and exercises.  This is particularly true if the potential aggressor is wont 
to use highly visible, large-scale military activity for the purpose of applying political 
pressure, or if he desensitizes the intended victim by accustoming him over time to a 
high level of military activity.  
Thus, for example, the Egyptians made warlike preparations twenty times between 
January and October 1973 and actually cancelled three cross-canal attacks at the last 
minute because of Israeli counter-mobilizations; they would not have struck in October 
had the Israelis reacted then, but would have continued their game of cat and mouse 
until an occasion when their enemy remained supine.10  In the Polish crisis of 1981, on 
the other hand, when Soviet and Warsaw Pact military preparations were undertaken 
which would normally have been considered alarming, NATO did not react because 
these preparations could be explained in terms of the Polish situation.11
Assessing Intentions
Clearly, as war-like preparations can be made ambiguous, an assessment of an enemy’s 
capability to attack is an insufficient basis on which to reach the decision to counter-
mobilize.  Such precipitous counter-mobilization could appear threatening to the enemy.  
At best, it would lead to a series of futile and expensive mobilizations which would soon 
become politically unacceptable (the reason for the Israeli failure to react in October 
1973).  It is essential, therefore, to divine the enemy’s intentions before preparing for war 
and this puts a premium on political over military indicators. 
••
Disinformation: A major problem facing intelligence staffs in this effort is sorting 
genuine signals from the background “noise” in time.  Before initiating prepara­
tions for war, NATO governments are going to demand very strong evidence of the 
USSR’s intentions to attack.  Given systematic Soviet deception and disinformation, 
intelligence will be unable to supply it.  The Soviets will do everything they can to 
complicate and confuse the picture and it will be extremely difficult to penetrate 
a well prepared, long-term disinformation plan.   Analysts are therefore generally 
gloomy about the prospects of avoiding surprise at the outset of the next war. 
••
Surprise in Europe: It is worth noting that the Soviet Union has achieved strategic 
surprise, as to intention and/or timing, three times in recent history—in the 1968 
invasion of Czechoslovakia, the 1979 occupation of Afghanistan and the 1981 
events in Poland. If the Kremlin leaders cold-bloodedly decided that an invasion of 
Western Europe was necessary, they would desensitize NATO, accustoming the al­
liance to a threatening military posture and level of preparedness, while using every 
available conduit to assure the West that war was un-thinkable. They could then 
manufacture some crisis (such as Poland in 1981) as a cover for the final, uncon­
cealable military preparations.
10.	  See Janice Stein, “Military Deception, Strategic Surprise and Conventional Deterrence—a political analysis of 
Egypt and Israel, 1971-1973,” Journal of Strategic Studies, 1/1982, for an excellent analysis of this crisis and its 
wider implications. 	
	
	
	
	
	
	
	
	
	
11.	  See C.N. Donnelly, “The Military Significance of the Polish Crisis,” RUSI and Brassy’s Defence Yearbook, 1983.

 
Catching NATO Unawares: Soviet Army Surprise and Deception Techniques
The Art and Science of Military Deception	
187
If, in a less likely scenario, there was no pre-conceived plan to go to war, but that 
decision was only taken during the course of a crisis, the Soviets would endeavour to 
convince the West that it was “just another crisis,” solvable like all its predecessors. Sur­
prise, at least as to timing, would then be achieved by striking before the crisis peaked 
(as in the Polish case) or after it appeared to be resolved (as with Czechoslovakia in 
1968).
In any case, to steal a march of even a few days could give the Soviets a decisive edge 
over NATO, given the alliance’s dependence on several days of preparation to establish 
a viable defense. SACEUR’s intelligence staff may warn of the probability of attack for 
some time, but the doubts of many of NATO’s leaders will delay the decision to institute 
countermeasures until it is too late. Thus, SACEUR is unlikely to be astonished when 
the Soviets cross the IGB, but he is likely to be surprised in the military sense, in that he 
will not have been allowed to deploy and prepare defenses in good time. 
Operational Surprise
Operational surprise is defined by Major General Matsulenko as stemming from suc­
cessful concealment of the timing, strength, direction and/or mode of the offensive.12  
Obviously, it will be most easily achieved if preceded by strategic surprise. Indeed, the 
two in combination can be devastating, particularly if the objective is limited.
Eight Methods
Soviet sources insist that operational surprise can also be achieved on its own.  Although 
modern surveillance means make it difficult fully to conceal preparations for a large-
scale offensive, Soviet Major General S.P. Solov’ev states that concealment of the true 
scale, and especially the direction and timing, of the main attack is “a quite achievable 
task which should always occupy the centre of attention … Innovative search in solving 
the problem of gaining the element of surprise in military operations is one of the most 
important tasks of military cadres.”13  He identifies eight ways in which operational 
surprise can be achieved.  
1.	 By forgoing detailed preparations and attacking “from a flying start”, surprise as 
to timing can be achieved.  The Soviet invasion of Manchuria provides a good ex­
ample.  The Soviets launched a sudden onslaught with only a 1.2:1 superiority in 
men, 4.8:1 in tanks and artillery and 2.5:1 in aircraft – figures not too dissimilar 
to the force ratios pertaining to the Central Region today.  
2.	 The enemy can be confused as to actual intentions by misleading behaviour, such 
as a low level of activity or obviously defensive preparations.  
3.	 Attacking at an unlikely time usually catches the enemy badly off balance.  In 
both the Manchurian and Vistula-Oder operations, for instance, the defense was 
caught off guard by the Soviets’ decision to attack in unfavourable weather.  
4.	 Time after time in history, an attacker has gained a decisive advantage by striking 
along an unexpected axis terrain dismissed by the enemy as unsuitable for a major 
12.	  Major General Matsulenko, op cit. The term “op­erational” is used in the Soviet sense of warfare conducted at the 
level of front (army group) and army (corps).
13.	  Maj Gen S.P. Solov’ev, “Strategic Surprise,” Voennaya Mysl. 1 /1979.

Catching NATO Unawares: Soviet Army Surprise and Deception Techniques
188 
The Art and Science of Military Deception
offensive; in Soviet eyes, the best terrain for tanks is any area where there are no 
enemy anti-tank weapons. 
5.	 Unexpected operational methods can have a paralyzing effect on the enemy.  The 
German blitzkrieg is the best known example.  It is less commonly realised that 
the Soviets more than repaid them in their own coin with the imaginative use of 
“mobile groups”.  
6.	 A considerable shock can be delivered by the unexpected employment on a large 
scale of new, or greatly improved weapons.  Soviet T-34s and Katyushas came as 
an unpleasant technological surprise to the Wehrmacht, as did more recently (in 
1973) the SA-6/ZSU-23-4 combination to the Israelis.  Soviet writings lay great 
emphasis on the impact this aspect of surprise will have in the next war.  
7.	 Strict security is, of course, essential for surprise, and Soviet secrecy is legendary.  
Their security was never penetrated by the Germans, but this was understandable.  
In the Vistula-Oder operation, which involved 2.2 million men, 34,500 guns and 
mortars, 6,500 tanks and SP artillery guns and 4,800 aircraft, only oral instruc­
tions were issued until D-day minus four, when only four written operation orders 
were issued.  
8.	 The last method, deception, is so important that it will be treated separately.  
Operational Deception
Despite the “transparency revolution,” Western armies remain vulnerable to operational 
level deception for three reasons.  
The overconfidence of some intelligence officers renders them fallible. This is es­
pecially true where oracular faith is placed in SIGINT, the most easily spoofed of all 
intelligence-gathering means.
Closely related to the first point is the pronounced tendency to disparage Soviet op­
erational flexibility. Soviet lack of tactical imagination is taken to imply a lack of opera­
tional imagination too, despite all the historical evidence to the contrary. Knowing this, 
the Soviets can tailor their deception to confirm the enemy view of their stereotyped 
practices. US forces may be particularly vulnerable to this, because of an often dubious 
picture of their enemy and because of Air Land Battle’s reliance at times on templating 
the Soviet forces in the absence of hard intelligence.
Modern war has seen a simultaneous massive increase in the volume of data avail­
able to intelligence staffs and a drastic shortening of the time available for analysis, 
dissemination and subsequent decision-making. This must increase the possibilities of 
surprise through deception. The Soviets will try to allow the enemy enough time to no­
tice and act on their deception, but insufficient time to analyze the information in detail.
The mobility and flexibility of modern mechanized and air-mobile formations are 
such that the deception plan does not have to work for long. As with strategic decep­
tion, it does not have to be totally successful either. An ambiguous picture will often be 
enough to prevent the enemy from reacting in time. (It is also worth mentioning that 
the very nature of manoeuvre warfare, with its sudden, rapid and radical changes in the 
situation and frequent shifts of emphasis between axes will generate so much “noise” 
that, even without hostile deception to complicate matters, intelligence will have the 
greatest difficulty in divining enemy intentions.)

 
Catching NATO Unawares: Soviet Army Surprise and Deception Techniques
The Art and Science of Military Deception	
189
Examples of Maskirova
Soviet military writings use the term “maskirovka”, an amalgam of concealment, cam­
ouflage, simulation and disinformation which combines security and deception. Though 
at unit and sub-unit levels, maskirovka may, because of time constraints, consist of little 
more than the use of dead ground, coupled with a misleading smoke concentration on a 
false axis, it can become very sophisticated at higher levels. During World War II, mas­
sive concentrations were achieved, totally undetected by the Germans (often in very bare 
terrain). Prior to the battle of Kursk, the Central Front alone was covertly reinforced by 
ten rifle divisions, seven tank regiments, 23 tank-destroyer brigades, over 9,000 guns 
and mortars and 1,300 aircraft.
In offensive operations, simulation took place on a grand scale. Thus, before the 
Vistula-Oder operation, over 1,000 dummy tanks and SP artillery guns were deployed 
with scores of real ones (to create tracks), and with the real communications nets of the 
1st and 2nd Tank Armies, on a false axis; all the German intelligence combat indicators 
for each stage of an offensive in preparation were duly supplied. Meanwhile, the true 
concentration (on an axis through difficult terrain) was successfully disguised as a false 
one. The Soviets were also prepared to devote very substantial forces to feint attacks on 
false axes. For example, the 4th Guards and 5th Shock Armies were used in this way 
in the Iassi-Kishinev operation, as was the reinforced 36th Army in Manchuria. These 
troops, who took very heavy casualties, were not considered wasted. They were not 
only misleading the enemy, but also fixing enemy formations (and drawing in reserves) 
and killing enemy soldiers.
Deception is not a forgotten art, as it tends to be in the West. Rather it is stressed as 
a mandatory component of all strategic, operational and tactical plans. In fact, the Sovi­
ets have formed well-equipped specialist units at operational level purely to implement 
Figure 1  Vistula-Order Operation

Catching NATO Unawares: Soviet Army Surprise and Deception Techniques
190 
The Art and Science of Military Deception
deception. Sophisticated modern surveillance techniques permit the design of dummies 
to emanate “heat, light and electro-magnetic energy.”14
Tasks of Maskirovka
Maskirovka is pervasive in Soviet military literature and has a myriad of uses, but in the 
operational sphere, eight basic tasks are listed:
1.	 Masking an increase in or redeployment of forces and/or weapons which the en­
emy has spotted.
2.	 Blocking the enemy’s perception and/or identification of new weapons.
3.	 Very importantly, distracting the enemy’s attention from other activities.
4.	 In high-intensity combat, effectively overloading the enemy intelligence’s analyti­
cal capability.
5.	 By presenting an illusion of strength where there is weakness, inspiring awe in an 
opponent or focusing his attention on an area where no real threat exists.
6.	 In a complementary fashion, lulling the enemy into a false sense of security by 
presenting an image of weakness where there is really strength.
7.	 Accustoming the enemy to particular patterns of behaviour so that he does not 
recognize offensive preparations.
8.	 Confusing enemy expectations, leading him to misunderstand Soviet actions so 
that he fails to find the correct response to them.
Principles of Deception
It is obviously impossible to list the ingredients of Soviet deception as one would for the 
recipe for a cake. The first principle, as Soviet writers never tire of reiterating, is creativ­
ity and originality; stereotype is fatal to any prospect of success. Scrupulous adherence 
to the following basic principles is also stressed:
A.	 Any deception plan must have a clearly defined aim which supports the real op­
erational scheme. It must be directed at a specific target, usually the enemy com­
mander, and be based on his known prejudices and likely reactions; ideally, it will 
confirm his preconceptions (as known, for instance, from a study of his training 
manuals and exercise play, from his reaction to previous moves and from the na­
ture of his deployment).
B.	 Control is always exercised at the highest possible level. Otherwise, various un­
coordinated lower-level deception schemes can compromise each other, and the 
main plan, through revealing anomalies.
C.	 Preparation and execution must be thorough. Sufficient resources must be allo­
cated to ensure credibility, and their activities constantly monitored to elimi­nate 
errors and breaches of security. There must be close co-ordination between the ac­
tual operational plan and the deception scheme (preferably passing the former off 
14.	  Colonel V. Shchedrov, “Camouflaging Troops During Regrouping of Troops and Manoeuvre,” Voennaya Mysl. 
6/1966.

 
Catching NATO Unawares: Soviet Army Surprise and Deception Techniques
The Art and Science of Military Deception	
191
as the latter). Each stage of the deception scheme is implemented when it appears 
that the enemy has fallen for the previous one.
D.	 Credibility is, of course, a sine qua non. The deception plan must be a plausible 
alternative to the real one, and it must unfold in logical and realistic fashion, 
feeding the enemy with the combat indicators he would expect to see, yet not so 
readily as to excite suspicion; the enemy intelligence must be made to work for 
its material so that it believes it has penetrated security (and so that, as a conse­
quence, it defends its inter­pretation with conviction).
E.	 It is important to feed as many of the enemy’s intelligence collection sources as 
possible; a picture painted by one alone will arouse suspicion. There must, too, be 
the normal minor inconsistencies and ambiguities. Timing is also important. Intel­
ligence must be given enough time to collect and interpret the false in­formation, 
but not enough for thorough analysis.
F.	 Flexibility in execution is a vital attribute of deception. Enemy reactions, both 
predicted and unforeseen, must dictate the unfolding of the plan; radical modi­
fications may become necessary if, for instance, the enemy misses some signals, 
misinterprets some and does not buy others.  
G.	 Security is as vital to the deception plan as it is to the operational one.  
Conclusions
The current debate about improving NATO’s conventional defense tends to concentrate 
on “bean counts” and the relative merits of rival items of hardware for scarce funds. 
Perhaps both military and political leaders need to spend more time on the intangibles, 
beginning with the problem of how to cope with the danger of surprise without, at the 
same time, running the risk of alarming the Soviets in period of crisis, or of giving them 
an excuse for pre-emptive action.
••
Field fortifications: One useful measure, which could help to lessen the pact of sur­
prise, might be the construction of a belt of field fortifications, manned by infantry, 
along the IGB. Soviets have considerable respect, born of painful wartime experi­
ence, for a combination of anti-tank ditches, minefields and strong points in depth 
backed by strong, armoured reserves.15  Such mobility denial would, in effect, act as 
a force multiplier for the defense, cancelling out the advantage surprise confers on 
the attacker. The Soviets would be forced to echelon their offensive forces in greater 
depth to ensure penetration. This would compel them either to deploy substantial 
extra formations, compromising surprise or to plan a much weaker initial blow on 
a narrower front. In either case, NATO’s task would be greatly simplified and the 
prospects of “deep strike” having worthwhile targets dramatically improved.  All 
this would be achieved without impairing crisis stability, given the unambiguously 
defensive nature of such defenses.
••
Accepting surprise: NATO’s senior commanders would do well to plan on the basis 
that they will (not may) be the victims of strategic surprise. To count on several days 
for preparation is to confuse warning time, which may exist, with preparation time, 
15.	  Major J.B.A. Bailey, in “The Case for Pre­placed Field Defenses,” IDR 7/1984, makes a persuasive case for field 
fortifications which need not reflect either the expense or the mentality of a “Maginot Line”.

Catching NATO Unawares: Soviet Army Surprise and Deception Techniques
192 
The Art and Science of Military Deception
which almost certainly will not. It is more than likely that little, if any, augmenta­
tion of force levels will be possible prior to hostilities, and obviously reinforcement 
schedules will be most unreliable in the face of Soviet deep attacks. As things stand 
at present, the Soviets will be able to impose their style of warfare on NATO. This 
means that the alliance will have to accept the inevitability of meeting engagements 
and battles. Western forces need to accept the logic of this and train for them.

193
C H A P T E R  2 6
The Red Mask: The Nature and Legacy of Soviet 
Military Deception1
David M. Glantz
David M. Glantz is an American military historian and the editor of the “Journal of 
Slavic Military Studies.”  Glantz received degrees in history from the Virginia Mili­
tary Institute and the University of North Carolina.  He entered active service with the 
United States Army in 1963 and retired at the rank of Colonel.
In August 1945 the Soviets conducted their geographically most challenging and exten­
sive strategic operation of the Second World War. In response to the Allied request for 
Soviet assistance in the war against Japan, first made in 1944 and repeated in 1945, the 
Soviets at the Potsdam Conference (May 1945) committed themselves to operations 
against Japanese forces in Manchuria and on the Northern island possessions of Japan 
(the Kuriles and Sakhalin). There were about 700,000 Japanese troops in Manchuria 
facing an almost equal number of Soviet troops. An additional 300,000 to 400,000 
Japanese in Korea might be expected to figure in the operation, with another 100,000 on 
Kurile Islands and Sakhalin. A well-orchestrated Soviet attack would probably negate 
the requirement to engage those Japanese forces in Korea. On the basis of comparative 
strength, the Manchurian operation would be somewhat larger than that in Belorus­
sia. Using Belorussia as a guide, Soviet forces in the Far East would have to be at least 
doubled in strength to more than 1.5 million. The Soviets did realize that Japanese ar­
mored weakness would permit Soviet armor superiority, making up for part of the lack 
in manpower. Thus, initial Soviet planning assessed the need for about 1.5 million men 
and at least one tank army and one to two tanks or mechanized corps to defeat Japanese 
forces in the requisite time frame.
Several conditions delayed Soviet preparations for the operation, increased the im­
portance of the Manchurian operation, and placed major significance on the factor of 
surprise and the role of maskirovka. The first reality was the size of the projected the­
ater of operations (roughly 600 by 1,000 kilometers) and more important, the distance 
of the theater from European Russia. To raise Soviet force strength to over 1.5 million 
men would require moving almost 700,000 men over 9,000 kilometers along the um­
bilical cord of the Trans-Siberian Railroad from the European theater to the Far East. 
Even more significant was the necessity of moving large armored forces (one tank army 
and one tank corps) and the massive quantity of necessary equipment and supplies. To 
1.	
David M. Glantz, “The Red Mask: The Nature and Legacy of Soviet Military Deception,” in Strategic and Opera­
tional Deception in World War Two, Michael Handel, editor, London: Frank Cass & Co., 1987, pp. 231, 234–239. 
Reprinted by permission of Frank Cass & Co. (Taylor and Francis Group).

The Red Mask: The Nature and Legacy of Soviet Military Deception
194 
The Art and Science of Military Deception
maintain strategic surprise this movement would have to be kept as secret as possible. 
Once deployed for the offensive, those forces would have to advance through the dif­
ficult and varied terrain of Manchuria to a depth of almost 900 kilometers. Terrain 
problems also necessitated deceiving Japanese forces about actual routes of the Soviet 
advance.
The second reality was the degree of fanatical resistance the Japanese had displayed 
in earlier operations against US forces. There was no reason to assume more passive 
Japanese reception of a Soviet advance into Manchuria. This made it necessary for 
skillful operations, using the best operational and tactical techniques developed in the 
western war. Thus, the Soviets had to send experienced forces and commanders to the 
Far East. The final reality confronting the Soviets on the very eve of the offensive was 
that of time constraints. American use of the nuclear bomb, and the possible ensuing 
Japanese collapse, made it imperative that the offensive should achieve its goals in a 
matter of days, rather than weeks or months. The Soviets determined that Manchuria 
had to be secured within 30 days and the main entrances into central Manchuria within 
one week. This was as much a political as a military necessity.
From virtually every perspective, maskirovka would make the difference between 
success and failure. To a greater extent than in the west, successful strategic maskirovka 
was imperative, while operational and tactical maskirovka had to be perfect if the over­
all operational plan was to be realized.
The Soviets understood the difficulty in masking their overall offensive intentions. 
General S. M. Shtemenko noted:
Our striving for surprise in our operation was complicated very much by the fact that the 
Japanese had long and steadfastly believed in the inevitability of strategic surprise was hardly 
a practicable matter. Nevertheless, after pondering this problem, we returned more than 
once to the first days of the Great Patriotic War. Our country had also expected the war and 
prepared for it; however, the German attack proved unexpected. Consequently, it was not 
necessary to prematurely repudiate surprise in the current case.
Surprise in the Manchurian operation depended first on maintaining the secrecy of 
the operational plan and the nature and scope of Soviet offensive preparations. Also, 
to an extraordinary degree, surprise would depend on the form of the attack, which 
had to be conducted in a manner guaranteed to pre-empt Japanese defenses or paralyse 
the Japanese command and control structure. This meant the use of unorthodox op­
erational and tactical techniques, tested earlier but never before relied upon to such a 
major extent.
The first task was to secure planning for the operation. The Soviets followed proce­
dures developed in previous operations and severely restricted the number of planners 
and of planning documents. A Far East Command directive restricted full participation 
in planning to the front commander, the member of the front military council (political 
officer), the chief of staff, and the chief of the operational directorate. Front chiefs of 
troop branches and services participated in developing only their functional portions of 
the plan and were not familiar with overall front missions. The directive read:
The army commander will be assigned missions personally and verbally, without the deliv­
ery of written directives from the front. The participation in the development of the army 
operational plan will be established on the same basis as within the front. All documentation 

 
The Red Mask: The Nature and Legacy of Soviet Military Deception
The Art and Science of Military Deception	
195
concerning the plans of troop operations will be kept in the personal safes of the front and 
army commanders.
The most sensitive aspect of offensive preparations was the problem of masking the 
extensive force and materiel build-up in the Far East. This effort would take consider­
able time to complete, and would rely on a limited transport network already highly 
vulnerable to Japanese observation. This concentration, regrouping and deployment of 
forces and materiel, and the movement of commanders and staffs required to lead the 
forces were carried out under the cloak of a host of maskirovka measures. High-level 
commanders and their staffs traveled to the Far East (normally by air) under assumed 
names, wearing bogus badges of rank, branch and service. Movement by rail of ma­
teriel began as early as January 1945; and, whenever possible, the Soviets relied upon 
indigenous stocks and production to equip their forces. Movement of men and materiel 
occurred only at night under strict camouflage conditions. Hundreds of kilometers of 
artificial covers were built to physically mask the rail line from Japanese observations 
(especially along the Amur and Ussuri Rivers where the rail line was under direct obser­
vation of Japanese forces on the far bank).
During June and July the Soviets used 136,000 rail cars to move the requisite num­
ber of men and materiel to launch the offensive (22-30 trains per day). While the Japa­
nese noted the increased volume of traffic, Soviet camouflage probably concealed from 
Japanese eyes 50 per cent of the volume of men and materiel moved.
Once in the Far East, the fronts placed arriving units and materiel in widely dis­
persed camps and depots in positions distant from the front, but accessible for quick de­
ployment forward, needing only limited use of forward assembly areas and jumping-off 
positions. During these movements troops conducted exercises which made it possible 
for units to train, adapt to local conditions, and prepare for the attack while maintain­
ing their concealment. One to two days before initiation of the attack, where necessary, 
forces moved into their initial positions, in which movement of any kind, food prepara­
tion, and wood-cutting were strictly forbidden. All newly arrived units maintained strict 
radio silence. Similar measures covered the extensive redeployment of forces already 
stationed in the Far East and Trans Baikal regions.
The Far East command and the front headquarters published detailed directives and 
instructions concerning general and specific maskirovka plans to govern their forces. 
For example, the 1st Far Eastern Front (previously the Primor’ye group and 25th Army) 
issued extensive instructions calling for the creation of false troop concentrations, a 
decoy offensive sector, active defense preparations in other sectors, and activation of 
bogus reconnaissance. Troops performing these missions were not informed about the 
false nature of their activities.
Meanwhile, all activity in front sectors was kept at normal levels. The population 
carried on normal activities, military units followed usual routines, and radio traffic 
continued with no change. Newly arriving units moved only at night and rested in 
forests and villages out of the enemy’s view. Where cover was unavailable (as in the 
steppes), tanks, vehicles and personnel dug in and concealed themselves with camou­
flage materials or nets. The Soviets prepared unit command posts in advance, either 
digging them in or using existing structures which blended in with the surroundings. 
All communications nets lines were dug in as well as artillery firing positions prepared 
in advance by specially designated engineer units. Though these and other measures did 

The Red Mask: The Nature and Legacy of Soviet Military Deception
196 
The Art and Science of Military Deception
little to alter Japanese judgements about ultimate Soviet offensive intentions, they did 
conceal the timing, scope and location of the impending attack.
The extensive secrecy and maskirovka measures were but one aspect, albeit an im­
portant one, concerning preparations for the operation. Equally important were tech­
niques used by the Soviets to surprise the Japanese regarding the form of the attack. 
Most of these techniques were by no means new, having been used on various occasions 
in the German war, when the Soviets had been able to judge their effectiveness. How­
ever, in Manchuria the Soviets used a wide array of these techniques on a grander scale 
than ever before.
As in 1939, Japanese attitudes toward likely Soviet performance conditioned the 
Japanese for being surprised. The Japanese apparently stereotyped Soviet combat per­
formance on German reports of how the Soviets had operated early in the war (1941-
42). Thus, they underestimated the ability of the Soviets to employ armor skillfully and 
co-ordinate combined arms forces in poor terrain. They underestimated their logistical 
capability to effect and support large troop concentrations in terrain they (the Japanese) 
considered unsuited for large-scale military operations, particularly the areas adjacent 
to western Manchuria. The skill of Soviet combat performance far exceeded Japanese 
expectations.
The form and location of the Soviet attack at the strategic, operational and tactical 
levels also surprised the Japanese. The Soviet’s two-front strategic envelopment through 
both eastern and western Manchuria contradicted Japanese expectations and deploy­
ments. Soviet units routinely crossed terrain the Japanese considered impassable, leav­
ing it virtually undefended. Moreover the Japanese were unable to counter the Soviets’ 
conscious decision to use every possible avenue of approach in their attack. Soviet use 
of armor in first echelon at every level of command—initially, or shortly after the begin­
ning of the attack—also caught the Japanese off guard. Having discounted the threat of 
armor in such difficult terrain, they could not deal with it. The Soviet tendency to by­
pass fortified positions confounded Japanese commanders and rendered most Japanese 
defenses useless.
Tactically as well, the Japanese were unprepared to deal with Soviet combat tech­
niques. The Soviet use of small, task-organized assault groups with heavy engineer and 
firepower support clashed with the image of human waves of infantry in the assault. 
Perhaps most unexpected for the Japanese was Soviet reliance on forward detachments 
to probe Japanese defenses, bypass them, and attack deep into the Japanese opera­
tional rear. The Soviet commanders’ display of initiative at all levels did not fit Japa­
nese preconceptions of Soviet performance. In fact, the scope of Soviet use of rapid 
maneuver surprised and confused the Japanese, resulting in a general paralysis of their 
command and control. To a greater extent than at any time before, in Manchuria the 
Soviets followed the advice found in all of its earlier regulations, specifically to achieve 
maskirovka by ‘employing methods of fighting that are new for the enemy and weapons 
unknown to him’.
Soviet maskirovka measures achieved marked success. Certainly in mid-1945, the 
Japanese anticipated that the Soviet Union would ultimately join the war against Japan. 
The Soviet attack when it did occur, however, ‘caught the Japanese totally unprepared 
for an invasion they expected’. In late January 1945, the Japanese Army Vice Chief of 
Staff predicted the Soviets would abrogate the Japanese-Soviet Neutrality Pact and enter 
the war against Japan in the latter half of 1945. It happened in April. After the German 
surrender in May, the Japanese High Command (JSHQ) assessed that Soviet entry into 

 
The Red Mask: The Nature and Legacy of Soviet Military Deception
The Art and Science of Military Deception	
197
the war was unlikely until the spring of 1946, when Japan would be closer to surrender. 
They conceded, however, that Soviet attack preparations could be complete by August 
or September 1945; but thought weather conditions in that period were not conducive 
for an attack. All these assessments were based on a political judgment that Soviet war 
losses would force them to await an American invasion of Japan before they would join 
the war. Moreover, in August Manchuria was subject to heavy, often torrential mon­
soon rains which turned its few roads into morasses.
After Yalta, the Japanese estimated it would take at least three months after the Ger­
man surrender for the Soviets to move necessary forces to Manchuria for an offensive. 
By July Japanese estimates of Soviet reinforcements put Soviet strength at about 1.3 
million men. By August or September the Japanese estimated the Soviets would have 
40-50 divisions.
The Japanese did detect large-scale Soviet rail movements into the Far East. From 
February to August the Kwantung Army counted 800-1,000 trains of 40 cars each and 
deduced the movement of 20-25 Soviet divisions. Thus, Japanese intelligence ‘underesti­
mated between 30 to 50 per cent the forty Soviet divisions actually deployed eastward’, 
which caused them to believe ‘that they still had time to prepare their defenses against 
the Soviet invasion in the spring of 1946’. Interestingly enough, while undercounting 
military units and incorrectly estimating deployment regions, the Japanese kept a fairly 
accurate count of overall Soviet manpower strength in the Far East.
Based on these optimistic estimates, the Japanese were slow to implement changes 
in force disposition associated with their 1944 alteration of overall Kwantung Army 
planning from an offensive to a defensive posture. Many units had not completed their 
redeployment by the time of the Soviet invasion.
As in Belorussia, there was a dichotomy between intelligence assessments at lower 
level and high-level headquarters, with the lower-level taking a more realistic view. At a 
4 August conference at 3rd Area Army the Kwantung Army operations section said no 
invasion could be expected until September. If the attack did not begin then, the Kwan­
tung Army believed it would probably begin in the spring. High-level optimism muffled 
warnings from below, starved lower level units of meaningful intelligence information 
on the Soviets, and stifled the war preparations of low-level units. ‘In short, the Japa­
nese were unprepared strategically, operationally, or tactically for the massive Soviet 
blow which fell on 9 August 1945.’ The captured deputy chief of staff of the Kwantung 
Army, General M. Tomokatsu, declared that the specific dates of the entry of the USSR 
into the war remained unknown, despite the fact that the Kwantung Army had detected 
the Soviet build-up. Hence, he declared that the declaration of war by the Soviet Union 
on 8 August was completely unexpected. General Semizu, commander of Japanese Fifth 
Army, stated, ‘We did not expect that the Russian army would go through the taiga, 
and the offensive of Russian forces from almost inaccessible regions proved a complete 
surprise for us’. To a great extent, the combat performance of the Kwantung Army dur­
ing the Manchurian operation attested to the degree of surprise the Soviets achieved 
by using new operational and tactical techniques enabling them to achieve objectives 
in half the time. An operation optimistically judged to last at least 30 days was in fact 
completed within 15 days.
Manchuria represented a sterling effort for the Soviets regarding the wartime 
use of maskirovka. More important, it was one of their few experiences of employ­
ing maskirovka in the initial stages of war and has therefore become a major focal 

The Red Mask: The Nature and Legacy of Soviet Military Deception
198 
The Art and Science of Military Deception
point of study. Specifically, the Soviets have investigated the role of maskirovka in that 
increasingly sensitive period of the transition from peace to war.
Soviet maskirovka measures at the strategic, operational and tactical levels achieved 
greater success in Manchuria than in any previous operation. They were able to confuse 
the Japanese regarding the timing, scope, location and form of the offensive. Hence, 
Manchuria has become a textbook case for the Soviets on how to conduct strategic 
maskirovka. The time and special considerations of the offensive seemed to create con­
ditions and requirements somewhat analogous to theater offensives in a modern nuclear 
context. That fact has prompted even more intense Soviet study.

199
The Chinese Tradition of Stratagem:
circa 350 BC to the Present


201
C H A P T E R  2 7
Foreword to General Griffith’s Sun Tzu1
B.H. Liddell Hart
B. H. Liddell Hart was a British soldier and military historian.  Liddell Hart became an of­
ficer in the Kings Own Yorkshire Infantry at the outbreak of World War I.  Liddell Hart, 
after retiring from the military, became a writer and set out to explain the high casualty rates 
of the war.  
1.	
B. H. Liddell Hart, in Foreword to Sun Tzu, The Art of War, 2nd Edition, General Griffith, Sun Tzu, translated by 
General Griffith, MA: Oxford, 1963, pp. v-vii.  By permission of Oxford University Press, USA.

Foreward to General Griffith’s Sun Tzu
202 
The Art and Science of Military Deception

203
C H A P T E R  2 8
Stratagem: The Chinese View in the Sun Tzu1
Scott Boorman
Scott A. Boorman has been a junior fellow of the Harvard University Society of Fellows 
and a member of the Harvard Sociology Department. He is the author of The Protracted 
Game: A Wei-ch’I Interpretation of Maoist Revolutionary Strategy and various articles 
on Chinese military history and comparative strategic theory. 
The ancient Chinese strategist Sun Tzu is the only Chinese strategic thinker who has 
ever gained much cognizance in the West, with the latter-day exception of Mao Tse-
tung.  This recognition, though not based in most cases on deep historical evaluation, 
is well merited, since Sun Tzu is also cited among military thinkers with overwhelming 
frequency in Chinese historical and political literature, as well as being studied by most 
Chinese statesmen with pretensions toward strategic competence and by most officials 
confronted with the handling of military situations.  When one gets deeper into the 
historical source material, to be sure, one wonders whether statesmen and soldiers have 
paid much more than superficial respect to the writings of Sun Tzu (or any other theoret­
ical exponent of strategic matters); but there is no doubt that this brief book (in present 
form, it is only a few thousand characters) has had a far more controlling influence on 
Chinese strategic behavior than any comparable work, including that of Clausewitz, has 
had in the West.  The main point, in any case, is the guiding picture of strategy through 
stratagem.  A remark by a Western Sinologist on a classic of Chinese rhetoric was not 
directly intended for this context, but bears verbatim quotation: “It would not matter 
whether [that book] were one-fifth or four-fifths fictional, this would remain the central 
political fact of the age.”
Although, as previously indicated, the Sun Tzu text is at least tolerably well known 
in contemporary Western strategic circles, in the Western literature there is no inter­
pretation of its significance that is very helpful to understanding its central themes.  To 
evaluate the picture of the world presented in the Sun Tzu, several concrete aspects of 
the organization and style of the text should be discussed at the outset.  As in most 
Chinese social-theoretical and philosophical works of the period, the style is terse and 
epigrammatic and consists of a sequence of maxims strung together, roughly organized 
by topic, but offering no consistent sequential argument.  Metaphors and analogies 
are frequent; historical examples are lacking, though the standard commentaries fill in 
many examples from later epics.  The commentary interpretations are of great impor­
1.	
Scott Boorman, “Stratagem: The Chinese View in the Sun Tzu”, William W. Whitson, editor, The Military and 
Political Power in China in the 1970s, New York: Praeger Publishers, 1972, pp. 318–323. Reproduced with per­
mission of Praeger Publishers via Copyright Clearance Center.

Stratagem: The Chinese View in the Sun Tzu
204 
The Art and Science of Military Deception
tance, since for the most part they have heavily influenced the interpretations of the text 
for at least the last millennium.
Following is an excerpt from a standard translation [by Giles] of the first chapter of 
the text, which follows some introductory remarks stressing the importance of the study 
of war and the basic aspects of the military art.  The relevance to the topic of stratagem 
needs no comment:
All warfare is based on deception.  Hence, when able to attack, we must seem unable; when 
using our forces, we must seem inactive; when we are near, we must make the enemy believe 
we are far away; when far away, we must make him believe we are near.   Hold out baits to 
entice the enemy.   Feign disorder, and crush him.   If he is secure at all points, be prepared for 
him.   If he is in superior strength, evade him.  If your opponent is of choleric temper, seek to 
irritate him.   Pretend to be weak, that he may grow arrogant.   If he is taking his ease, give 
him no rest.  If his forces are united, separate them.   Attack him where he is unprepared, 
appear where you are not expected.
These military devices, leading to victory, must not be divulged beforehand. 
It is clear that Sun Tzu is here stressing primarily that level of stratagem that con­
sists of attempting to induce the enemy to make a wrong decision because he is misled 
as to one’s own situation and strategy.  The possible devices for implementation of this 
aim are numerous, and it is to the credit of the text that it does not bog down in an at­
tempted catalog of the mechanisms (by contrast to certain much later Chinese strategic 
works, which, as Herbert Franke has pointed out, fairly reek of armchair stratagems).  
In a later chapter (Chapter 9), however, there is a very interesting and quite concrete 
discussion of counterstratagems: the problem of filtering one’s intelligence with the aim 
of disclosing the enemy’s true situation when he is trying to present it deceptively.  For 
example, “Humble words and increased preparations are signs that the enemy is about 
to advance.  Violent language and driving forward as if to the attack are signs that he 
will retreat.”
For a modern Chinese, perhaps the most familiar collection of stratagems and coun­
terstratagems of this nature is that contained in the fictionalized San-kuo chih yen-i 
(Chronicle of the Three Kingdoms).  This is a rather romanticized, and hence very 
popular, narrative account in the colloquial style of a famous period of factionalism and 
dynastic decay in the third century A.D., known to have made a deep impression on 
the young Mao Tse-tung.   Carried to its romantic limit, this aspect of Chinese warfare 
leads to the near-paranoid view of Chinese conflict behavior advocated many years ago 
[1900] by a former French military attaché [G. de Cotenson] stationed in Peking. He 
argues,
Leur diplomatie consiste ordinairement à faire croire à l’ennemi qu’on veut s’entendre avec 
lui, ou aux rebelles que grâce leur sera faite, à leur promettre des honneurs pour les attirer 
dans son camp et les massacrer à loisir.
Ruses of this kind are deeply bound up with Western perceptions of Asian stra­
tegic subtlety.  From a less culturally chauvinistic viewpoint, stratagem of this nature 
is scarcely profound; in fact, to quote Balzac, “II n’y a pas de théorie, il n’y a que de 
partique dans ce métier.”

 
Stratagem: The Chinese View in the Sun Tzu
The Art and Science of Military Deception	
205
It should be noted, however, that a certain element of the last, and highest, form of 
strategem—that which seeks to manipulate the opponent’s utility function itself—ap­
pears in Sun Tzu’s prescriptive list, where he speaks of angering the enemy and encour­
aging his arrogance.  This subtle, but significant, distinction is supported by various 
standard commentaries on this particular passage.  Li Ch’uan (himself an author of 
a well-known military text of the eight century A.D., the so-called T’ai-po yin-ching 
(Secret Classic of Venus) remarks, for example, that the purpose of angering the enemy 
commander is to cause his spirit to vacillate—i.e., to lose his head.  Another commenta­
tor, Chang Yu, makes the point even more strongly.  By irritating the enemy, he remarks, 
the commanding general can cause the former to “advance lightly, without stratagem.”  
Even more extensive commentary has been generated by the remark on encouraging the 
arrogance of the enemy, with many historical examples being cited on instances where 
wars were lost because a commander was induced by the enemy to be overconfident of 
his own capabilities and thus to have a distorted view of the over-all situation.
A few isolated quotations, to be sure, prove nothing.  But the image of manipulating 
the enemy’s view of the world is pervasive.  To quote the much later (eleventh century 
A.D.) Tzu-chih t’ung-chien (Comprehensive Mirror for Aid in Government):
Now, the Way of War is this: attacking the heart is the best, attacking walls is the worst: 
battle launched at the heart is the best, battle launched at soldiers is the worst.  I would wish 
that Your Excellency subdue their minds only. 
Carried to its logical conclusion, manipulation of the mind of the enemy implies 
perturbation of his utility function to the point where he does not fight at all.  The 
real development of our highest level of stratagem occurs only in the third chapter of 
the Sun Tzu, entitled “Attack by Stratagem”.  In this section, the emphasis shifts from 
merely outwitting the enemy (deception in the limited sense) to attempting to break his 
will without fighting.  This is not a humanitarian concept, any more than is the indirect 
approach of Liddell Hart, though one can indeed trace a continuum between the type of 
bloodless victory imagined by the Sun Tzu and (for example) the almost totally ethical 
and nonstrategic remarks in such texts as the Huai-nan tzu.  The objective is to hold 
one’s own intent invariant, while simultaneously maneuvering the enemy into a position 
where he is willing to grant it.
Hence to fight and conquer in all your battles is not supreme excellence; supreme 
excellence consists in breaking the enemy’s resistance without fighting. . . .   The general, 
unable to control his irritation, will launch his men to the assault like swarming ants, 
with the result that one-third of his men are slain, while the town still remains untaken.  
Such are the disastrous effects of a siege.  Therefore the skilful leader subdues the en­
emy’s troops without any fighting; he captures their cities without laying siege to them; 
he overthrows their kingdom without lengthy operations in the field.  With his forces 
intact he will dispute the mastery of the Empire, and thus, without losing a man, his 
triumph will be complete.  This is the method of attacking by stratagem.  
The picture that emerges from this passage is very different from that suggested by 
a contemporary Western treatise [by Whaley]:  “The ultimate goal of stratagem is to 
make the enemy quite certain, very decisive, and wrong.”  The example of the town 
and countryside [given by Shakespeare, “If we lose the field we cannot keep the town”] 
provides a modern paradigm case of the kind of stratagem Sun Tzu is talking about in 
the above passage.  In point of fact, large numbers of KMT military units scattered in 

Stratagem: The Chinese View in the Sun Tzu
206 
The Art and Science of Military Deception
cities and Schwerpunkte across the North China plain eventually surrendered quite pas­
sively without a fight to encircling Chinese Communist forces based in the countryside.  
Chinese Communist guerrilla warfare effectively played upon the rigidities of thinking 
always present in the Nationalist command to maneuver the Nationalists into an inflex­
ible strategic policy inimical to their own best interests.  This kind of stratagem does 
not fit naturally into the disjunctive framework provided by Liddell Hart’s concept of 
“alternative objectives.”
Having once introduced the Chinese Communist revolutionary movement, it is rel­
evant to suggest a view of the interrelations among the triad formed by the concept of 
stratagem in the abstract, Sun Tzu, and Maoist strategy.  In another work, the present 
author has argued for a structural analogy between Maoist revolutionary strategy and 
the game of wei-ch’i (Japanese go).  Essentially, the role of wei-ch’i was to provide for 
Chinese Communist doctrine a concrete, representational model of what have been 
well-labeled as the geometrical and physical aspects of warfare.  There remains, how­
ever, a considerable realm of strategic action in revolutionary warfare with which no 
analogy to a complete-information game can cope.   Broadly speaking, this is the realm 
of incomplete information and imprecise objectives.  Although various analogies have 
been drawn between Sun Tzu and Maoist strategy as a whole, it is this latter, highly 
psychological, realm of strategic behavior that furnishes most of the common ground 
between Sun Tzu and Mao Tse-tung.
In other words, the main influence of Sun Tzu on Mao has been in the area of strat­
egy centering around deception and stratagem.  Analogies between Maoist insurgency 
and the thought of Sun Tzu are much weaker in the sphere of warfare more geomet­
ric—the realm of strategy customarily associated in the West with the name of Antoine 
Jomini.  In no sense does Sun Tzu recommend protracted guerrilla warfare with widely 
dispersed base areas of the type essential to Maoist thinking and—under suitable struc­
tural transformations—to the game of wei-ch’i.  Eventually, with more historical and 
theoretical work, one may hope (in a felicitous phase of Benjamin Schwartz) to analyze 
the organic chemistry of the Chinese strategic tradition in much greater detail: but some 
of the distinctions here suggested may provide a crude beginning.

207
C H A P T E R  2 9
Chinese Deception Doctrine: A View from Open 
Sources1
Michael Pillsbury
Michael Pillsbury is a defense policy adviser, former government official and author of 
books and reports on China. In 1975–76, while an analyst at the RAND Corporation, 
Pillsbury published articles in Foreign Policy and International Security recommending 
that the United States establish intelligence and military ties with China.  He served on 
the staff of four U.S. Senate Committees from 1978–1984 and 1986–1991.
Preface
The Introduction and Overview of this report provides a number of preliminary insights 
about how Chinese open sources deal with the issue of military deception. It is based on 
a survey of 300 Chinese books and journals published since 1992. Drawing from several 
Chinese journal articles about deception, Part One suggests several tentative proposi­
tions about what Chinese deception doctrine may be, including the proposition that 
China’s approach to deception may be quite different from other nations.   
Book One is a 60 page translation of excerpts from a book entitled Military Decep­
tion published in 1992 and written by a senior colonel who currently serves at China’s 
National Defense University. The style of this book resembles a textbook or comprehen­
sive survey. It provides a theoretical schema for using three main types of deception at 
three levels of national strategy, military campaign, tactical and single soldier deception. 
To illustrate these theoretical concepts of deception, the book describes in detail about 
150 examples of deception in practice, 100 of which are from Chinese history, fifty 
are from deceptions practiced by Western nations, and only about 15 are deceptions 
practiced by contemporary Chinese, of which only 6 are from the post 1949 period. In 
my view, the book’s theoretical concepts are highly valuable, but it is unfortunate that 
the author could provide so few illustrations since 1949. He does, however, stress the 
importance of multi-channel deception using SIGINT, imagery, and HUMINT, as well 
as the need for several techniques of counter deception analysis and collection. 
Book Two is a 40 page translation of excerpts from a set of books entitled Decep­
tive Strategy published in 1996 by a senior colonel who serves in the PLA General Staff 
Department as Director of Military Research. This book also provides a set of theoreti­
cal concepts about how to use deceptive strategy, as well as more than 200 examples. 
To a greater degree than the first book, most of the examples are drawn from Chinese 
history. This book’s preface contains calligraphy congratulating the author on the book 
from many of China’s highest ranking general officers and the defense minister. It also 
1.	
Michael Pillsbury, “Chinese Deception Doctrine: A View from Open Sources,” Washington, DC: FDDC, c.2003, 
pp. 1–4.

Chinese Deception Doctrine: A View from Open Sources
208 
The Art and Science of Military Deception
reveals the existence of a national commission for research on deceptive strategy on 
which many of these Chinese generals serve.  In my view, this book’s importance stems 
in part from its effort to examine “deceptive strategy” in a comprehensive manner, be­
ginning in China 3,000 years ago, and its assertions that Chairman Mao developed a 
unique deception style for China during the Chinese civil war that remains relevant for 
the future. 
These books were acquired in China for the Pentagon’s Office of Net Assessment 
project on Chinese military open sources.
Introduction and Overview
This report fulfills a request for a condensed translation of two Chinese books on decep­
tion theory. The military authors of the two books seem to suggest that China’s military 
possesses its own unique theory of deception. They believe that China can compensate 
for military inferiority in wartime by employing this deception doctrine. These two 
books are not unusual. They fit into a larger context of Chinese military writings of the 
past decade. Two important Chinese military themes have been the revival of ancient 
Chinese history as a guide to current military issues, and a search for strategies and 
military technologies suited for use by inferior forces [China] against superior forces 
[the United States.] Chinese writings by more than 200 authors about these themes have 
been translated in Chinese Views of Future Warfare and China Debates the Future Secu­
rity Environment [National Defense University Press]. It will be difficult for any reader 
who is unfamiliar with these Chinese strategic debates to plunge into these two Chinese 
books about deception. At least two assumptions are understood by the Chinese senior 
officers who are the intended audience of these two books on deception. The authors 
appear to assume, contrary to common US attitudes:
** Deception by an inferior power of a superior can be decisive, and is not a mere 
force multiplier.
** Extremely useful models for future military deception may be found in ancient 
Chinese history.
Implications for the U.S. 
If Chinese views are so unfamiliar, why should American readers make any effort to un­
derstand them? There are several implications for the US contained in these two books 
about the future potential role of military deception:
** The potential of successful deception against the United States appears to include:
••
Increasing US forces’ vulnerability to surprise,
••
Inducing US forces to make mistakes,
••
Minimizing warning time from the US intelligence community to US policymakers,
••
Reducing any the role the US could play, either diplomatically or militarily, 
••
Affecting domestic US policy debates, 

 
Chinese Deception Doctrine: A View from Open Sources
The Art and Science of Military Deception	
209
••
Inducing US policy paralysis or at least causing extended delays in crisis 
decisionmaking,
••
Shaping the battlefield through directed information without its source becoming 
known,
••
Exporting Chinese deception techniques to other nations hostile to the US, 
••
Countering the effects of US weapons systems and US operational concepts.
The scope of these two books is broad, and the authors appear to define “decep­
tion” to include measures to deceive with respect to:
1.	 China’s intentions, 
2.	 China’s programs, and 
3.	 China’s existing capabilities.
Both books draw upon American and Soviet writings about deception, but both 
authors state that China understands deception theory better. The US is credited with 
excellent deception techniques, as is the former USSR. An article recently credited 
the Soviet Union with aiding China in 1957 by providing a useful manual of military 
deception.
Limits of Open Sources
The two authors provide no concrete examples of any contemporary Chinese decep­
tion practices. Instead, they carefully restrict their books to over one hundred historical 
examples of deception. It is well known in China that military authors cannot obtain 
security approval for open publication if they discuss sensitive matters about Chinese 
armed forces. Thus, it cannot be expected that open sources will reveal specific and 
concrete applications of deception. There appears to be no similar taboo, however, on 
discussing deception theory and doctrine in the abstract, as long as the materials used 
are purely historical. However, both authors make clear that they are advocates of the 
use of deception. They claim the mantle of authority of both Chairman Mao’s writings 
and the classic Art of War by Sun Tzu. To underline that they are addressing the future 
employment of the deception doctrine, one of the books does go so far as to offer the 
full text of a sample deception operation order that a military region commander could 
issue. Both books seem to be supplemental reading for a classified training course that 
PLA officers have stated is conducted in various staff schools in China. Presumably, the 
classified courses use more specific manuals and real world examples, rather than the 
hundreds of historical case studies used in these two open source books. It is possible 
that the classified military training courses use the same approach to deception theory 
and doctrine as these two books. After all, one of the books is endorsed by a dozen se­
nior generals, and its author serves on the General Staff. The other book has been cited 
approvingly by additional authors.    
 The condensed, translated version of these two books amounts to 100 pages. A full, 
verbatim translation would exceed 1500 pages. A full translation would also have to ex­
plain literally hundreds of Chinese historical references that would be obscure without 

Chinese Deception Doctrine: A View from Open Sources
210 
The Art and Science of Military Deception
detailed annotations. Yet even a condensed version of Chinese deception doctrine and 
theory as discussed in these two books may be of interest for three reasons:
**First, as a great civilization with thousands of years of its own political and 
military history, contemporary Chinese military authors may have important ideas to 
contribute to those in the West with an interest in the general history and theory of 
deception. 
**Second, and more narrowly, China may have developed its own unique deception 
doctrine that merits study as part of any effort to understand Chinese national security 
strategy. 
**Third, the use of open source Chinese materials can often usefully supplement 
other US government research and analysis. Obviously, in the modern world, planning 
for military deception would be a sensitive and secret matter for any nation. It could 
not be addressed in detail in open source books. Indeed, open sources could even be a 
channel to practice deception on the unwary foreign reader. So, readers should be alert 
to such issues in making any interpretation of Chinese [or any other nation’s] writings 
on deception theory. 
Background of the Two Authors
Before turning to the description of the main features of Chinese deception theory put 
forward in these two books, some background to put them into context may be useful. 
The authors of both books occupy important positions, but apparently do not meet with 
foreign military delegations and are not known outside China. Only a few dozen Chi­
nese officers visit the US annually, out of a universe of many hundreds of Chinese pub­
lished military authors, so the fact that they are not known may be insignificant. Some 
believe all important Chinese military authors are known in the US. However, others 
fear that this is not so yet. It is important to try to understand whether these two authors 
have any authoritative status, or whether they are representative of mainstream views.  
Several Chinese sources have helped to provide background about the author of 
the more important of the two books, Colonel Ma Jinsheng. Colonel Ma is not further 
identified in his book Military Deception. However, several PLA generals have told me 
this year that Colonel Ma is not a pen name, and that he is a real person working in 
Beijing. A second confirmation about Colonel Ma was found in the comments of a PLA 
author of another book entitled Battlefield Deception published in 1999, who expressed 
his appreciation to Colonel Ma and identified him as the Director of the National De­
fense University Press. A third confirmation of Colonel Ma’s background has come 
from the quotation of one of Colonel Ma’s basic concepts about deception theory by 
yet another PLA author from the nuclear rocket forces in 1999 in a collection of articles 
about information warfare. 
Unlike Colonel Ma, the author of the second book Colonel Chai Yuchiu is identi­
fied briefly on the book jacket as a member of the General Staff Department of the 
PLA. Other PLA officers have acknowledged to me that they know him. His position 
title is stated to be Director of Military Studies of the General Staff. Unfortunately, no 
PLA officer I have interviewed has been willing to offer details of what this vague job 
title entails. Requests by several Americans to meet him have been declined, with the 
explanation that Colonel Chai does not ever meet with foreigners. However, Colonel 
Chai, like Colonel Ma,  has also been quoted in books by other PLA authors. One of 

 
Chinese Deception Doctrine: A View from Open Sources
The Art and Science of Military Deception	
211
a series of six books published by military authors in 1999 and 2000 about Chinese 
defense strategy referred to Colonel Chai’s study. Thus, both Colonel Ma and Colonel 
Chai appear to be respected, serving Army officers who are senior members of what 
might be called the defense intellectual community in Beijing, with Colonel Ma at the 
National Defense University [which trains future Chinese general officers] and Colonel 
Chai at the General Staff headquarters. Their Chinese military rank of “senior” colonel 
means that they are roughly equivalent to a brigadier general in other national systems. 
If promoted, they would become major generals.
A Unique Chinese Deception Theory?
These two books are not the sole important works on Chinese deception doctrine. At 
least five other books have been acquired as well as a dozen articles. Some of these ma­
terials [not translated here] focus on narrow problems. Two example are ways to use 
deception to neutralize US aircraft carriers and ways to use deception to attack Taiwan. 
All these books and articles, however, imply as a theoretical point that  deception opera­
tions are not the responsibility of a special unit. Rather, the most senior commanders 
are responsible for deception plans and operations. This approach differs from other 
nations. The US-UK deceptions for the Normandy landing in 1944, the Soviets in the 
1980s , and the Iraqis in the 1990s all had special organizations for deception. Iraq, for 
example, had  extensive organizational arrangements for concealment. According to 
Scott Ritter’s Endgame [p. 126]: “A “Concealment Operations Room” of the Special 
Security Organization “coordinates with the SSO to implement concealment measures 
for past programs, covert procurement, and covert manufacturing. . . . The concealment 
mechanism was the most difficult issue facing UNSCOM in its work in Iraq.” 
This difference between Chinese deception theory and that of other nations raises 
the question:
** Are there different “styles” of national deception doctrine or practice? If so, 
what does Chinese deception theory suggest would be the “signatures” of attempted 
Chinese deception?
** Logically, countering Chinese deception would have to begin with a search for 
such “signatures.”
Examples of Chinese Deception Aspirations
** Colonel Ma presents a categorization of deception into 4 levels, 3 types of goals 
and by duration. He emphasizes that successful deception can endure months or years. 
“Chains” of deception operations can be attempted, each of which is examined or 
tested through a kind of feedback loop. Then the deceiver may adjust both his “mes­
sage” and the multi channels in use. SIGINT, HUMINT, and other channels must all 
be coordinated, then whatever channel the opponent trusts the most must be used the 
most, whatever “message” is most credible to achieve the goal must be repeated and 
reinforced. Less credible messages or distrusted channels need to be downgraded. 
** Both Colonel Ma and Colonel Chai appear to believe that successful military 
deception can be “decisive”—not just a force multiplier, but a show-stopping, war-

Chinese Deception Doctrine: A View from Open Sources
212 
The Art and Science of Military Deception
winning weapon that requires appropriate attention and investment by the commander. 
Failed deceptions may be discovered.
** Deception includes not just “moving” the enemies’ forces but pre-war develop­
ment of secret weapons that are called “assassin’s clubs.” These deception weapons 
create a kind of technological surprise that is revealed only at decisive movements to 
win a war. 
** Both Colonel Ma and Colonel Chai appear to consider deception more im­
portant than Information Warfare, and even define IW as a part of a larger deception 
doctrine.
** Colonel Ma and Colonel Chai state that the best models for deception can be 
found in Chinese ancient history, especially the founders of the six greatest Chinese 
dynasties. Both use two or three time more Chinese examples than Western ones to il­
lustrate their deception theory.  
** Colonel Ma defines the most successful deception as one that makes the enemy 
actually “move” his forces and commit decisive, fatal errors. Lesser deceptions just con­
fuse or deny information to the opponent. He labels this “seduction” deception because 
it lures the enemy commander to do something. Colonel Chai argues that Chairman 
Mao created this concept of luring or seducing the enemy to make fatal errors during 
the Civil War in the 1940s, and that Mao borrowed it from ancient history.
** Colonel Ma defines deception as an integral part of strategy planning. It is not a 
separate and specialized activity. He states, 
Any deception process is the organic combination of strategy planning and preparation, and 
the application of skills. Any effective military deception does not deviate from the guidance 
of military strategy. Only under the guidance of military strategy can military deception be 
correctly carried out, otherwise it will act in a way that defeats one’s purpose [to try to go 
south by driving the chariot north], and things will go contrary to one’s wishes. 
Before formulating deception plans, commanders must first consider and assess the 
following six issues: 
1.	 What is the “shi” configuration or propensity of our side and the possible enemy 
trends? 
2.	 How can we use our power (plans one, two and three)? 
3.	 Is it possible to create a “shi” [propensity] that can cause a doubling effect to oc­
cur in one’s own capabilities? 
4.	 If this “shi” can be created, what kind of changes must the enemy make in 
deployment? 
5.	 Will the enemy be willing to make this kind of change? 
If the enemy is not willing to do so, should coercion methods or deception methods 
be used to cause the enemy to make changes beneficial to our side? 
After the above questions have been resolved one by one, the deception issue can be 
put on the agenda. The process of resolving the above issues is the process of planning 
and preparing strategy. The planning and preparation of strategy is the core issue of 
military deception.”
** To implement deception, Ma and Chai both state requires extensive use of spe­
cial operations forces [qi bing] coordinated with regular troops, both to deceive the 

 
Chinese Deception Doctrine: A View from Open Sources
The Art and Science of Military Deception	
213
enemy and to collect intelligence for the feedback loop to determine how well the decep­
tion’s message and channels are working, and what adjustments are needed.
** Low tech deception appears to be favored. So called tu ban fa, or “the country 
bumpkin style” deception can defeat high technology weapons, as a part of deception 
doctrine. A PLA author wrote in the May 2000 issue of Military Digest that the Yugo­
slav Army brilliantly used eight simple and backward means of deception:
••
Last minute anti‑air defense system changes to deny the US time to input missile 
targeting;
••
Deploying old planes to attract NATO bombers, while concealing newer fighters 
in bunkers;
••
Changing radio frequencies so that the enemy could not locate positions; 
••
Using smoke screens and radar reflectors against lasers and infrared to “trap” laser 
bombs;
••
Burning tires near airports to confuse the enemy’s cruise missiles; 
••
Covering targets with special materials to confuse reconnaissance; 
••
False SIGINT to seduce missiles to explode prematurely;
••
Delays in attacking stealth aircraft until the moment bomb bay doors opening. 
** Both Colonel Ma and Colonel Chai emphasize that intensive intelligence collec­
tion and analysis about the enemy leader’s perceptions and character and his advisory 
system must be conducted. In this way, his perceptions can be fostered to seduce him to 
commit fatal errors. Colonel Ma offers a detailed checklist for how to do this. Ma states 
that deception requires intelligence collection as follows:
1.	 Find out the main interests and characteristics of the target of deception, for fre­
quently this is more important than a general study of his life.
2.	 Find out what wars the target of deception fought in his military career, as well as 
the reasons and process of his successes and failures. Often this is more significant 
than understanding the enemy’s combat principles and military theory.
3.	 Find out what people are always around the target of deception, who is most in 
charge when speaking to him, who most easily arouses his dislike when speak­
ing to him. Frequently this is more critical than understanding the general officer 
roster and chain of command relations.
4.	 Find out what the target of deception needs the most and is most concerned with 
(including personal, family, work, and combat), for often this is more vital than 
understanding the enemy ’s general situation and terrain.
5.	 Find out what major setbacks and good fortune the target of deception has en­
countered throughout his career, and what person or thing created these setbacks 
and good fortune. Frequently, this is more important than understanding his gen­
eral resume.
** Military exercises and military equipment can be observed by satellites. There­
fore, military technological surprises [“assassin’s clubs”] and military training must be 
subordinate to deception doctrine. Colonel Ma praises Egypt for deceiving US satellites 
in its 1973 war against Israel. The doctrine appears to be that China must not reveal all 

Chinese Deception Doctrine: A View from Open Sources
214 
The Art and Science of Military Deception
its capabilities in military exercises. On the other hand, both Colonel Ma and Colonel 
Chai discuss the need for military “displays” to intimidate or to coerce. Colonel Ma 
provides a sample “deception directive” from a theater commander at the Military 
Region level:
Three days before the attack is launched, serious deception action must be taken to show the 
enemy our military will attack “A” area: 
1.	 Unload tanks at rail stations toward “A” area and set up decoy artillery.
2.	 Organize engineer troops to clear roads to “A” area.
3.	 Organize part of forces around the clock to move to “A” area and to construct field com­
mand centers and fortifications, then have them move back and forth many times. 
4.	 Extensively use mobile artillery or “floating” artillery companies and battalions to show 
“A” area has re-enforcements.
5.	 Set up mobile radios to pretend forces are being mobilized in the Corps group army 
headquarters.
6.	 Deliberately have recon teams in enemy areas lose some maps with important markings 
about “A” area. 
7.	 12 hours before the attack is launched, implement combat recon in enemy forward lines 
around “A” area. 
This sample deception instruction clearly tells us the general purpose, the tasks, and 
the timing so that the Group Army can then make their own deception planning. 
It is very important that Headquarters must have non-stop inspections of deception 
preparations.
Chinese History as a Source of Future Deception Models 
This introduction and overview does not provide a complete summary of the many 
points these two books explore. Chinese deception theory is little known in the West, 
perhaps because none of the major academic books on deception discuss China. Indeed, 
a common theme in Western books on deception is that it was invented in the West. Yet 
perhaps a unique view of the Chinese military is that China’s own rich history contains 
all the main types of deception, and therefore the most valuable lessons for the future. 
In this translation, a circle has been inserted before all Western examples used by the 
authors, and a square before all Chinese examples. The page numbers to the original 
Chinese books are shown in brackets on each page for the convenience of readers who 
wish to refer to the Chinese text.

215
Section VI:
Tactical Camouflage: Now You See It,
Now You Don’t
Introduction
Visual camouflage has been practiced in war and hunting throughout history. The term 
itself first came into use during World War I, and is derived from the French verb cam­
oufler, “to make up for the stage.”1 Camouflage in war involves the use of materials and 
techniques to hide, blend, disguise, decoy, or disrupt the appearance of military targets 
and their backgrounds. The use of these techniques helps prevent an enemy from detect­
ing or identifying friendly troops, equipment, activities, or locations. Properly designed, 
these techniques take advantage of the immediate environment and natural and artificial 
materials.2
Camouflage varies based on the surroundings in which the object will be viewed 
(air, land, sea), the climate, and the terrain. Camouflage on the ground is relatively 
simple and has involved no more than the use of local vegetation and nets. Camouflag­
ing large industrial targets or large sensitive military sites may require the expertise 
of engineers and chemists because of their knowledge of structures and materials. At 
sea, scientists with knowledge of optics and how light and color affect visibility have 
to inform the camoufler, along with experts who can minimize the knowledge gained 
from satellites, thermal cameras, and radar. Making aircraft less visible presents perhaps 
the greatest challenge. How do you effectively camouflage an aircraft when it is on the 
ground or in the air, under varying lighting conditions, and based on the surroundings 
at both the departure airfield and the at the target location? New theories of camouflage 
were invented to deal with the challenges of aircraft camouflage.3
Finally, the use of decoys is integral to camouflage. While camouflage aims to hide 
what is real, decoys attempt to show what is false. Decoys can give the enemy an in­
flated estimate of strength or can draw the enemy’s attention away from a real attack. 
The use of decoys complements camouflage. 
1.	
Guy Hartcup, Camouflage: A History of Concealment and Deception in War, New York: Charles Scribner’s Sons, 
1980, p. 7.
2.	
HQ, Department of the Army. FM 20-3, Camouflage, Concealment and Decoys, Washington, DC, 1999.
3.	
Hartcup, 8, 9, 14.


217
C H A P T E R  3 0
Now You See It, Now You Don’t: Camoufleurs, 
Conjurers and Pickpockets1
Roy Behrens
Simply the best all-round introductory book on camouflage.  A brilliant fulfillment of 
the promise of the author’s previous 1981 book on the subject. This book not only gives 
us the theory that ties deception to art, design, and war, but extends its reach to encom­
pass con games, magic, and perceptual illusions in general.  Consequently, it is perfect 
for beginners and a finishing school for veteran camoufleurs.
Mr. Behrens (1972 MA from the Rhode Island School of Design), a Vietnam War 
veteran, was an Associate Professor of Art at the University of Wisconsin (Milwaukee).
1.	
Roy Behrens, False Colors: Art, Design and Modern Camouflage, Iowa: Bobolink Books, 2002, pp. 151-171.

Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
218 
The Art and Science of Military Deception

 
Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
The Art and Science of Military Deception	
219

Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
220 
The Art and Science of Military Deception

 
Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
The Art and Science of Military Deception	
221

Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
222 
The Art and Science of Military Deception

 
Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
The Art and Science of Military Deception	
223

Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
224 
The Art and Science of Military Deception

 
Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
The Art and Science of Military Deception	
225

Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
226 
The Art and Science of Military Deception

 
Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
The Art and Science of Military Deception	
227

Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
228 
The Art and Science of Military Deception

 
Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
The Art and Science of Military Deception	
229

Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
230 
The Art and Science of Military Deception

 
Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
The Art and Science of Military Deception	
231

Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
232 
The Art and Science of Military Deception

 
Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
The Art and Science of Military Deception	
233

Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
234 
The Art and Science of Military Deception

 
Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
The Art and Science of Military Deception	
235

Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
236 
The Art and Science of Military Deception

 
Now You See It, Now You Don’t: Camoufleurs, Conjurers and Pickpockets
The Art and Science of Military Deception	
237


239
Section VII:
Strategic Deception
Introduction
Strategic Deception
Strtegic deception focuses on the big picture. At its center are the policies or even ide­
ology of a state or significant nonstate actor. Accordingly, the target of the deception 
effort must be the people and offices that can change and influence policy. These targets 
have traditionally been heads of state, ministers or cabinet members, and senior military 
commanders.1 Today, this target list should be expanded to include others who are in 
a position to sway the actions and decisions of state and nonstate actors. To be sure, 
identifying the players on this expanded list presents a challenge.
The risky and expensive nature of strategic deception inevitably confronts what 
Clausewitz called the friction of the whole machine. Strategic surprise is very difficult 
to achieve because of the possibilities of disclosure associated with a protracted, slow-
moving operation and the bungling that inevitably ensues when a full bureaucracy is in­
volved. Despite his reservations, Clausewitz ultimately tells us that high level deception, 
designed to achieve surprise, is “never wholly unproductive” and is always worth the ef­
fort because even small effects at the strategic realm can have significant ramifications.2
This section looks at the heady domain of military deception on a grand scale. This, 
as we’ll see in the next three cases, is the stuff of Pearl Harbors and D-Days. Note, how­
ever, that exactly the same set of psychological principles apply here as throughout the 
spectrum from grand strategy to minor tactics.
1.	
Roy Godson and James J. Wirtz, eds., Strategic Denial and Deception, London: Transaction Publishers, 2002), 
p. 2.
2.	
Bart Whaley, Stratagem: Deception and Surprise in War, Norwood, MA: Artech House, 2007, p. 71.


241
C H A P T E R  31
Biggest Hoax of the War: Operation FORTITUDE: 
The Allied Deception Plan that Fooled the 
Germans about Normandy1
Wentworth Eldredge
At the start of World War II, Wentworth Eldredge joined the United States Army Air 
Force.  Assigned to intelligence work, Eldredge helped distract German agents from the 
Allies’ plans for an invasion of France through Normandy.  
The following article is a brief but accurate summary covering the essential elements 
of the British and American FORTITUDE deception. 
1.	
H. Wentworth Eldredge, “Biggest Hoax of the War: Operation FORTITUDE: The Allied Deception Plan that Fooled the 
Germans about Normandy,” Air Power History, Vol. 37, No.3, Fall 1990, pp. 15–22.

Biggest Hoax of the War: Operation FORTITUDE: The Allied Deception Plan that Fooled the Germans about Normandy
242 
The Art and Science of Military Deception

 Biggest Hoax of the War: Operation FORTITUDE: The Allied Deception Plan that Fooled the Germans about Normandy
The Art and Science of Military Deception	
243

Biggest Hoax of the War: Operation FORTITUDE: The Allied Deception Plan that Fooled the Germans about Normandy
244 
The Art and Science of Military Deception

 Biggest Hoax of the War: Operation FORTITUDE: The Allied Deception Plan that Fooled the Germans about Normandy
The Art and Science of Military Deception	
245

Biggest Hoax of the War: Operation FORTITUDE: The Allied Deception Plan that Fooled the Germans about Normandy
246 
The Art and Science of Military Deception

 Biggest Hoax of the War: Operation FORTITUDE: The Allied Deception Plan that Fooled the Germans about Normandy
The Art and Science of Military Deception	
247

Biggest Hoax of the War: Operation FORTITUDE: The Allied Deception Plan that Fooled the Germans about Normandy
248 
The Art and Science of Military Deception

 Biggest Hoax of the War: Operation FORTITUDE: The Allied Deception Plan that Fooled the Germans about Normandy
The Art and Science of Military Deception	
249


251
C H A P T E R  3 2
Soviet Deception in the Cuban Missile Crisis—
Learning from the Past1
James H. Hansen
Hansen was a 30-year veteran of DIA, serving as a senior intelligence analyst until 1990. 
He then joined the CIA as an analyst and operations officer.
Moscow’s surreptitious dispatch of nuclear-capable SS-4 and SS-5 surface-to-surface 
missiles to Cuba in 1962 upset the strategic balance in an alarming way.¼1 The resulting 
showdown—which the Russians call the “Caribbean Crisis” and the Cubans call the 
“October Crisis”— brought the world to the brink of nuclear war. From its inception, 
the Soviet missile operation entailed elaborate denial and deception (D&D) efforts. The 
craft of denying the United States information on the deployment of the missiles and 
deceiving US policymakers about the Soviet Union’s intent was the foundation of Nikita 
Khrushchev’s audacious Cuban venture. Piecing together the deception activities from 
1.	
James H. Hansen, “Soviet Deception in the Cuban Missle Crisis,” Studies in Intelligence, Vol. 46, No.1, 2002, pp. 
49–58. Retrieved at: https://www.cia.gov/library/center-for-the-study-of-intelligence/csi-publications/csi-studies/
studies/vol46no1/article06.html. 
Figure 1  Range of Soviet SS-4 medium-range ballistic missiles and SS-5 intermediate-range ballistic missiles, 
if launched from Cuba.   

Soviet Deception in the Cuban Missile Crisis—Learning from the Past
252 
The Art and Science of Military Deception
declassified US, Russian, and Cuban accounts yields insights that can help us anticipate 
and overcome the D&D efforts of a growing number of foreign adversaries today.  
Maskirovka
Moscow has always had a flair for D&D, known in Russian as maskirovka. Its central 
tenet is to prevent an adversary from discovering Russian intentions by deceiving him 
about the nature, scope, and timing of an operation. Maskirovka covers a broad range 
of concepts, from deception at the strategic planning level to camouflage at the troop 
level.2 Russian military texts indicate that maskirovka is treated as an operational art 
to be polished by professors of military science and officers who specialize in this area.
DIA analysis preceding the missile crisis noted that the Soviet Army had probably 
employed large-scale battlefield deception “more frequently and with more consistent 
success than any other army.”3 The Soviets practiced extensive maskirovka before their 
move into Czechoslovakia in 1968. Moscow also trained foreign forces to apply decep­
tion, including North Vietnamese units before the Tet offensive in 1968 and Egyptian 
forces before crossing the Suez Canal in 1973.
Close-hold Planning
Gen. Anatoli Gribkov—then a senior member of the Soviet General Staff—provides 
revealing insights into the early planning of the operation. He says that, after Nikita 
Khrushchev decided to emplace the missiles in Cuba in the spring of 1962, the General 
Staff detailed only five officers—four generals and a colonel—to serve as the center of 
the military planning apparatus. Col. Gen. Semyon Ivanov, chief of the General Staff’s 
Chief Operations Directorate, was in overall charge.¼4  During that summer, the circle of 
collaborators and contacts expanded to include members of each of the relevant service 
branches, but secrecy and need-to-know prevailed. The most senior officers brought into 
the plan were at least told that Cuba was involved in the operation, but only a few were 
informed of the exact nature of the mission.¼5
The top civilian and military officials conceptualizing the operation did not see eye-
to-eye about the likelihood of pulling off a successful deception. At the very center of 
those making the decisions stood First Deputy Prime Minister Anastas Mikoyan, Pre­
sidium member Frol Kozlov, Defense Minister Marshal Rodion Malinovsky, and Mar­
shal Sergei Biryuzov, commander of the Strategic Rocket Forces.¼6  Alternate Presidium 
member Sharaf Rashidov was brought in as well, possibly for the cover that he later 
provided for traveling delegations.7  Biryuzov and his experts believed that the deploy­
ment could be made expeditiously and secretly, without the US discovering the missiles. 
Mikoyan was surprised at this judgment and believed the marshal to be a fool.¼8  Rashi­
dov was confident that the missiles could be hidden, claiming that they could be placed 
so as to blend in with the palm trees. Gribkov held that only somebody inexperienced in 
military matters could reach such a conclusion, given the extensive preparations needed 
for each missile site.
Throughout the early planning stage, no secretaries were used to prepare final typed 
texts. A colonel with good penmanship wrote the proposal that the Defense Council 
adopted. It grew into a full-fledged plan, still handwritten, which was approved by 
Malinovsky on 4 July and Khrushchev on 7 July.9  From May through October, for 
reasons of security, no communications about the proposed, planned, and actual Soviet 

 
Soviet Deception in the Cuban Missile Crisis—Learning from the Past
The Art and Science of Military Deception	
253
deployments in Cuba were sent, even by coded messages. Everything was hand-carried 
by members of the small coterie of senior officials who were directly involved.10
Developing a Cover Story
The General Staff’s code name for the operation—ANADYR—was designed to mislead 
Soviets as well as foreigners about the destination of the equipment. Anadyr is the name 
of a river flowing into the Bering Sea, the capital of the Chukotsky Autonomous District, 
and a bomber base in that desolate region. Operation ANADYR was designed to suggest 
to lower-level Soviet commanders—and Western spies—that the action was a strategic 
exercise in the far north of the USSR. Promoting the illusion, the troops that were called 
up for the Cuban expedition were told only that they were going to a cold region. Those 
needing more precise instructions, such as missile engineers, were informed that they 
would be taking ICBMs to a site on Novaya Zemlya, a large island in the Arctic where 
nuclear weapons had long been tested.11
To strengthen the concealment, many units were outfitted with skis, felt boots, 
fleece-lined parkas, and other winter equipment.12  Moreover, perhaps to further back­
stop the cover plan, Moscow tapped four ground forces regiments from the Leningrad 
Military District in the north for dispatch to Cuba. The deception was so thorough that 
it fooled even senior Soviet officers sent to Cuba. One general there asked Gribkov why 
winter equipment and clothing had been provided. The general admonished him to 
“think like an adult,” and explained, “It’s called ANADYR for a reason. We could have 
given away the game if we had put any tropical clothing in your kits.”13
Getting the Cubans on Board
Secrecy surrounded the first Soviet delegation that went to propose the audacious plan 
to Fidel Castro and other Cuban leaders. The officials arrived in Havana with little 
fanfare on 29 May, amidst a delegation of agricultural experts headed by Rashidov. The 
group included Col. Gen. Ivanov and several missile construction specialists and other 
military experts, whose job it was to determine whether the missiles could be deployed 
in secrecy.14 Ambassador Aleksandr Alekseev took Cuban Defense Minister Raul Castro 
aside to explain that “Engineer Petrov” in the group actually was Marshal Biryuzov, and 
that he needed to meet with el lider maximo without delay. Only three hours later “Engi­
neer Petrov” was shown into Fidel Castro’s office.15  The Cuban leadership unanimously 
and enthusiastically gave its approval in principle.16
Soviet maritime policy began to shift in accordance with these first trips. In June 
and July, the USSR began to charter Western ships to carry general cargo from the So­
viet Union to Cuba, reserving its own freighters for carrying military cargo.17
During 2-17 July, a Cuban delegation led by Raul Castro traveled to Moscow to 
discuss Soviet military shipments, including nuclear missiles. Khrushchev met with the 
Defense Minister on 3 and 8 July. Raul Castro initialed a draft treaty with the Soviet 
Defense Minister that governed the deployment of Soviet forces to Cuba. This pact was 
not to be publicly revealed until a visit that Khrushchev planned to make to Cuba in 
November.18
The Russians began to dispatch officers and specialists covertly to Cuba by air. 
On 10 July, Gen. Issa Pliyev, traveling under the name “Pavlov,” arrived in Cuba to 
command the Soviet contingent.19  Two days later, 67 specialists touched down. They 

Soviet Deception in the Cuban Missile Crisis—Learning from the Past
254 
The Art and Science of Military Deception
journeyed as “machine operators,” “irrigation specialists,” and “agricultural special­
ists.” Their covers, however, could not have withstood probing—they had been as­
signed to occupations about which they knew nothing. They were urged to consult the 
few genuine specialists traveling with them to gain some rudimentary knowledge of 
their ostensible jobs.20  On 17 July, Havana announced that Cuba and the USSR had 
signed an agreement establishing a regular Moscow-Havana civil air route. US intel­
ligence analysis at the time speculated that the new Tu-114 flights were bringing Soviet 
military officers and sensitive electronic and signal-monitoring equipment to Cuba.21
Then-Minister for Industry Ernesto “Che” Guevara and the head of the Cuban 
militia led another delegation to Moscow during 27 August-2 September. The purpose 
was to introduce Fidel Castro’s revisions into the draft treaty. The Cubans proposed 
that the deployment be made public in order to head off any American overreaction; 
Khrushchev, however, successfully argued for continued secrecy.
Keeping the Secret at Home
In the Soviet Union, the men and equipment destined for Cuba were assembled, loaded, 
and moved by rail at night under reinforced guard. The train routes and final destina­
tions were kept secret. Mail and telegrams along the way were strictly prohibited.22
To mask the immensity of the overall effort, the shipments to Cuba left from eight 
ports—four in the north (Kronstadt, Liepaya, Baltiysk, and Murmansk) and four on the 
Black Sea (Sevastopol, Feodosiya, Nikolayev, and Poti).23  Western access to these ports 
was closed off. It was normal for the Soviets to close ports when munitions were being 
loaded, but this time the surface-to-surface missiles were being put on the ships under 
tight security and cover of darkness.24
The troops were housed at nearby military facilities during the two or three days 
required to load a ship. Guards were posted to prevent anyone from leaving the area. 
No letters, telegrams, or telephone calls were permitted, a rule that also applied to the 
officers.25  The ships’ crew members, some of whom made more than one run to Cuba, 
were forbidden shore leave and correspondence.26  Secrecy was so strict that couriers 
carried all messages between the ports and the Defense Ministry in Moscow.27
On board, the Soviets applied the same maskirovka measures that they had adopted 
when they first began to send weapons to Cuba. Packing crates or special shipping 
containers concealed and protected weapons carried as deck cargo. Certain telltale mili­
tary equipment was boarded up with planks to make it look like the ship’s superstruc­
ture. Even on-deck field kitchens were disguised.28  The Soviets shielded crated military 
hardware—such as missiles and launchers—with metal sheets to defeat infrared pho­
tography.29  They stored other combat and specialized equipment below, out of sight. 
Ordinary automobiles, trucks, tractors, and harvesters were placed on the top deck to 
convey the impression that only civilian and agricultural gear was being transported.
The freighter Poltava, which sailed to Cuba in September, was a good example. No 
external signs indicated that it was carrying missiles. On deck were cargo trucks, none of 
which were associated with the missiles. Nonetheless, some US experts speculated that 
the ship might be carrying ballistic missiles deep in its hold, because the Soviets tended 
to use large-hatch ships of the Poltava and Omsk classes to deliver such missiles.30
The ship captains were not told where their cargoes were to be delivered. Before 
casting off, the captain and the troop commander jointly received a large sealed enve­
lope. Unfastening it, they found a smaller envelope to be opened only at a certain set of 

 
Soviet Deception in the Cuban Missile Crisis—Learning from the Past
The Art and Science of Military Deception	
255
geographic coordinates in the Atlantic Ocean. When they reached the designated point, 
an officer from the KGB’s Special Department joined them for the opening of the en­
velope. The instructions told them to proceed to a Cuban port and authorized them to 
inform the ship’s company of the destination.31  The concern for secrecy permeated the 
process. The last sentence of the captain’s letter read: “After familiarizing yourself with 
the contents of this document, destroy it.”32
Every ship involved in Operation ANADYR carried thick folders, prepared by De­
fense Ministry staff officers, which contained background information on a number of 
countries with which the USSR had good relations. The study materials on Cuba were 
buried in these packets, so that not even the compilers would know the real focus of the 
operation.
Secrecy in Transit
The Soviet ships made false declarations when they exited the Black Sea and the Bospo­
rus. Cargo records were altered and the tonnage declared was well below what was be­
ing carried.33  The ships would declare from Odessa, although they had loaded at other 
ports. Often ships going to Cuba listed Conakry, Guinea, as their destination. When the 
volume of traffic increased, a number of ships did not give their destinations but simply 
stated that they were carrying “general cargo” and “awaiting orders.”34
Transit through the Bosporus and the Dardanelles Straits presented a special chal­
lenge. Not only were the soldiers kept below decks, but the captains were under orders 
to prevent any foreigners from boarding, even the Turkish pilots who usually guided 
civilian ships through those tricky waters. Whenever the pilots approached the Soviet 
ships, the Soviet crews would lower bulging parcels of vodka, brandy, caviar, sausages, 
and other delicacies. Gribkov noted that this transparent bribery worked well: “Every­
one likes to get presents, even pilots.”35
The captains were instructed to take all possible evasive action in the event of at­
tacks or an effort to board their ships. Should evasive action fail, they were to “destroy 
all documents with state and military secrets,” take measures to protect the personnel, 
and sink the ships.36  Should their vessels experience mechanical failure en route, the 
captains were to explain to ships offering assistance that they were exporting automo­
biles.37  Had this occurred, it might have provided clues—the USSR had few cars of any 
kind and was not recognized as an automobile exporter.
Moscow also resorted to diplomatic means to reduce US reconnaissance of the ships 
en route. In July 1962, the Soviets described US reconnaissance missions in interna­
tional waters as “harassment,” and requested through their GRU officer in Washington, 
Col. Georgi Bolshakov, that these flights be stopped for the sake of better bilateral rela­
tions.38 In retrospect, this overture clearly appears to have been an effort by Khrushchev 
to delay the discovery of weapons related to Operation ANADYR. Bolshakov met with 
Attorney General Robert Kennedy more than a dozen times.
Most of the voyages lasted from 18 to 20 days. Due to strict maskirovka measures, 
the troops were kept below decks except for a few minutes at night when small groups 
were allowed to exercise and get some fresh air.39  During the tropical days, heavy tar­
paulins covered the hatches to the lower decks where the troops were berthed. With 
little air circulation, the inside temperature climbed to 120 degrees Fahrenheit or higher. 
Rations were issued twice a day and only in darkness.40  Many of the troops on board 
swore that they would never again set foot on a ship.

Soviet Deception in the Cuban Missile Crisis—Learning from the Past
256 
The Art and Science of Military Deception
Although the restrictions made conditions on board nightmarish, the deceptions 
worked. Gen. Gribkov states that “US intelligence discovered neither the true signifi­
cance of the surge in Soviet shipping to Cuba nor the mission of our troops on the island 
until nearly all the men had come ashore and, still moving in large numbers only by 
night, had been deployed to their assigned positions.”41
Unloading in Cuba
As the Soviet troops arrived, Cuban officials took steps to support Moscow’s maskirovka 
plan. In early fall, they began to exert control over the movements of all foreigners on 
the island. News reporters and foreign embassy personnel were forbidden to travel out­
side Havana. In the city, Cuban agents surveilled and harassed foreigners, especially 
British embassy officials.42
The planners had selected 11 Cuban ports to receive the Soviet ships: Havana, 
Mariel, Cabanas, Bahia Honda, Matanzas, La Isabella, Nuevitas, Nicaro, Casilda, 
Cienfuegos, and Santiago de Cuba.43  They earmarked three of them—Bahia Honda and 
Mariel on the northwest coast and Casilda on the south coast—to receive the surface-
to-surface missiles and nuclear warheads.44
Even before the Soviet ships approached Cuban ports, a number of maskirovka 
precautions had been implemented. At Mariel, for example, the Soviets built a large 
cinder-block wall around the unloading area so that none of the port activity could be 
observed by land-based agents.45  As the ships lay in port, KGB officers kept watch on 
deck. All Cubans, even militiamen, were barred from the port areas.46  Local inhabitants 
within a mile of the waterfront in Mariel had to evacuate their homes.47
The first SS-4 missiles arrived in Mariel on board the Omsk on 8 September. The In­
digirka brought the initial shipment of nuclear warheads on 4 October.48  According to 
one source, this ship carried 99 nuclear charges—some two-thirds of all nuclear weap­
ons sent to Cuba and over 20 times the explosive power dropped by all Allied bombers 
on Germany throughout World War II.49
Most of the military technicians also came ashore at Mariel. Deception activities 
throughout the transit stage and the strict security measures at Mariel hindered the 
ability of US intelligence agencies to estimate the number of Soviet troops. The plan 
for ANADYR that was approved in early July had called for moving 50,874 men. That 
total included personnel for field hospitals, bakeries, mechanical workshops, and other 
support units, all with a three-month supply of food and fuel. During September, the 
plan was revised to eliminate submarine and surface ship squadrons, due to potential 
resupply problems and concerns that their presence might sound an alarm bell in Wash­
ington. By late October, the size of the contingent in Cuba had reached about 41,900 
personnel—quadruple the size that US intelligence agencies figured.50
Nonetheless, in the hectic initial days in Cuba, secrecy created more than a few 
glitches. The General Staff had neglected to provide passwords to facilitate communica­
tion between the arriving transport ships and the Cuban greeting parties. Accordingly, 
some ship captains and on-board troop commanders had difficulty accepting orders to 
reroute their ships from their originally assigned ports. The captain of one ship even 
turned back out to sea rather than allow a Cuban patrol boat crew to come aboard to 
guide him to his anchorage.51
Usually two or three days were required to unload a ship with military cargo, and 
maskirovka requirements invariably complicated the work. Equipment that had at least 

 
Soviet Deception in the Cuban Missile Crisis—Learning from the Past
The Art and Science of Military Deception	
257
a superficial resemblance to agricultural machinery was unloaded in broad daylight, 
but weapons and other military equipment could be unloaded only at night. From the 
docks, specialized equipment was stored in sheds or moved directly to designated bases 
along back roads at night.52
All this time, Radio Moscow was claiming that the USSR was only giving Cuba 
“machine tools, wheat, and agricultural machinery,” along with “some 7,000 tons of 
various fertilizers.”53  This description was consistent with the false identities provided 
to many of the Soviet military specialists and also with the daytime unloading activity.
Movement to Field Sites
The maskirovka measures were not air tight. In the initial stages of the operation, the 
United States received reports from friendly nations, newspaper correspondents, and 
other sources indicating that hundreds of Russian troops in fatigues had been seen in 
Havana and in seemingly endless convoys along Cuba’s main highways. Many young 
Russian men also had been observed sightseeing in the Cuban capital in checked, cotton 
shirts and cheap trousers.54  Although the Soviets and Cubans took extra precautions to 
keep gawkers away from the wharves and moved the nuclear cargoes away under black 
canvas and escorted by heavy guard, the chatty Cubans gave a steady stream of clues to 
US SIGINT collectors.55
At the same time, the Soviets and Cubans mounted a major campaign using HU­
MINT channels to bolster the overall deception effort. The planners leaked accurate 
information about the deployment so as to mask it. The information was funneled 
through counterrevolutionary organizations and their press in the United States, espe­
cially in Miami. The CIA discounted the information, because it did not consider the 
groups and people peddling it to be credible. This strategy was highly effective, accord­
ing to a former Cuban intelligence officer.56
The deception campaign that exploited the émigrés’ lack of credibility was unwit­
tingly backstopped by correspondence between Cubans and their friends and relatives 
in the United States. From June to September, Cuban intelligence intercepted some 
17,000 letters that had something to say about the deployment of Soviet troops and 
missiles in Cuba. In late September, Cuban authorities permitted those letters to arrive 
in Miami as part of the deception campaign. Just as Havana expected, the CIA paid no 
attention to these letters.57
For US intelligence analysts, the amount of “noise” from Cuba grew deafening. 
Reports flooded in from Cubans, tourists, foreign diplomats in Cuba, and newspaper 
officials reporting in a private capacity. At the CIA focal point at Opa-Locka, Florida, 
intelligence officers screened countless reports and debriefed Cubans who had fled the 
island.58  Most of the reports from Cuba were exaggerated or imaginary—some were so 
outrageous that they were laughable and made all the others suspect. There were far-
fetched tales of African troops with rings in their noses, lurking Mongolians, and even 
Chinese troops. These accounts followed earlier erroneous reports of Soviet military 
equipment secreted away in caves, underground hangers, and concrete domes. The pre­
vious reports had cast doubt on the reliability of sources, so US analysts found it easy to 
dismiss the stream of reports of Soviet missiles.59
From the port areas, the canvas-covered SS-4 missiles were moved in night convoys, 
under tight security, to sites in the interior of the island. Security was tightened so that 
the troops disembarked dressed as civilians, and their escorts—Soviet personnel who 

Soviet Deception in the Cuban Missile Crisis—Learning from the Past
258 
The Art and Science of Military Deception
had arrived earlier—were required to wear Cuban military uniforms and issue com­
mands along the convoy routes only in Spanish.60  On the march or bivouacked, Soviet 
military men remained dressed in civilian clothing and were forbidden to mention their 
military designations or the ranks of their commanders. Moreover, all communications 
between the Soviet military headquarters in Havana and units in the field had to be 
made in person, not written or sent by radio. Except for very brief hookups and equip­
ment tests, Soviet troops maintained total radio silence in order to mask their identity, 
location, and troop strength from US intelligence.61
In retrospect, some Soviet and Cuban officials found it remarkable that the opera­
tion remained secret for a full month after the missiles arrived in Cuba.62  The missile 
carriers were too big to go unnoticed on the back roads of the island for long. As they 
rumbled through the little Cuban towns, they left a trail of downed telephone poles 
and mailboxes. When a peasant’s shack had to be moved or knocked down to allow a 
missile carrier to turn a tight corner, those who witnessed the event were bound to talk. 
Soviet and Cuban efforts to discredit such anecdotal accounts paid off.
Disingenuous Diplomacy
Soviet spokesmen kept up a steady stream of denials and disinformation in September. 
On 4 September, Ambassador Anatoli Dobrynin sought out Robert Kennedy and stated 
that he had received instructions from Khrushchev to assure the President that there 
would be no surface-to-surface missiles or offensive weapons placed in Cuba. Dobrynin 
also added that the Attorney General could assure his brother that the Soviet military 
buildup was not of any significance.63  On 6 September, Theodore Sorenson, special 
counsel to President Kennedy, met with Dobrynin, who reiterated his assurances that 
Soviet military assistance to Cuba was strictly defensive in nature and did not represent a 
threat to American security. The following day, Dobrynin assured US Ambassador to the 
United Nations Adlai Stevenson that the USSR was supplying only defensive weapons to 
Cuba. On 11 September, TASS announced that the USSR neither needed nor intended to 
introduce offensive nuclear weapons into Cuba.64
In late September, Khrushchev embarked on a barnstorming tour in the Turkmen 
and Uzbek republics. This high-profile trip, which extended into the first week of Octo­
ber, emphasized agricultural themes. In none of Khrushchev’s many speeches during his 
travels was there any reference suggesting aggression or threats to the United States.65
The pattern continued. On 13 October, a high State Department official, Chester 
Bowles, questioned Dobrynin on whether Moscow intended to put offensive weap­
ons in Cuba; the Ambassador denied any such intention. On 17 October, GRU Col. 
Bolshakov brought Robert Kennedy a personal message directly from Khrushchev to 
President Kennedy that “under no circumstances would surface-to-surface missiles be 
sent to Cuba.” The next day Foreign Minister Gromyko met with President Kennedy 
for two hours. Gromyko assured him that the Soviet aid to Cuba “pursued solely the 
purpose of contributing to the defense capabilities of Cuba and to the development of 
its peaceful economy.”66
Denouement
The missile sites themselves could never have remained hidden for long. They were 
constructed in areas expropriated from Cuban landowners, had no fences or walls, and 

 
Soviet Deception in the Cuban Missile Crisis—Learning from the Past
The Art and Science of Military Deception	
259
were exposed to aerial observation.67  Standard maskirovka doctrine gave preference to 
deployment in wooded areas, yet Cuba’s forests were generally sparse, consisting of a 
few clusters of palm trees or a thick undergrowth of bushes. Such vegetation could not 
cover all of the missile equipment.68  SS-4 launchers are anchored to large concrete slabs 
and surrounded not only by the missiles, but also by multiple buildings, fuel trucks and 
tanks, and hundreds of meters of thick cable. To try to maintain secrecy, Soviet com­
manders forbade their troops from taking any leave from their deployment sites and 
ruled out using Cuban labor. Nonetheless, Soviet commanders and planners knew that 
although the tractor-trailers and associated large objects could be covered by canvas, 
their masses could not be shrunk.69  Heavy equipment might obscure part of the missile 
site signature from ground-level, but from above it stuck out markedly.70
On 14 October, a U-2 aircraft photographed the area of San Cristobal, where the 
first missile unit was being deployed. In only six minutes, US Air Force Maj. Richard 
Heyser snapped 928 photographs that yielded the first confirmation of offensive mis­
siles in Cuba.71 Washington stepped up intelligence collection of all kinds, readied mas­
sive air attack and invasion plans—including sending nuclear-armed B-52s aloft—and 
engaged in extensive policy deliberations in the Executive Committee. On 22 Octo­
ber, President Kennedy revealed the missile buildup to the world. Confronted with the 
photographic evidence, the Russians informed Raul Castro that more attention would 
have to be paid to concealing the site work and camouflaging the missiles and other 
heavy equipment.72  The Soviet units stretched tarpaulins and nets over the missiles, and 
daubed paint or mud across the canvases. This marked the first time that they tried to 
conceal their missiles from the air, probably hoping to mask the total number of missiles 
and protect against sabotage.73  By 28 October, however, the confrontation, including 
Kennedy’s imposition of a naval and air quarantine on the shipment of offensive mili­
tary equipment to Cuba, led Khrushchev to agree on a formula to end the crisis. The 
Russians began to dismantle their bases.
In Conclusion
The Soviet deception effort was comprehensive, but not free from shortcomings. The 
early, overly optimistic assessments by Marshal Biryuzov and Rashidov evidently went 
Figure 2    U2 photograph of SS-4 missile site in Cuba. 

Soviet Deception in the Cuban Missile Crisis—Learning from the Past
260 
The Art and Science of Military Deception
unchallenged. Some cover arrangements were slapdash. Many of the slips occurred not 
in the USSR but in Cuba, when Soviet units had to unload their weapons, transport them 
to the field, and set them up. The operation might have been enhanced by the presence of 
maskirovka specialists in all Soviet units in Cuba. In the 1980s, a special maskirovka di­
rectorate was created within the General Staff. Such an organization would have played 
a vital role had it existed in 1962.74
On 4 February 1963, the President’s Foreign Intelligence Advisory Board issued a 
major postmortem report over the signature of its chairman, James R. Killian, Jr. The 
Killian report described the introduction and deployment of Soviet strategic missiles in 
Cuba as a “near-total intelligence surprise.”75 It concluded that the Intelligence Commu­
nity’s analysis of intelligence indicators and its production of current intelligence reports 
“failed to get across to key government officials the most accurate possible picture of 
what the Soviets might be up to in Cuba” during the months preceding 14 October. The 
report took the Community to task for inadequate early warning of hostile intentions 
and capabilities; failure to provide senior policymakers with meaningful, cumulative 
assessments of the available intelligence indicators; and failure to produce a revision 
of the erroneous National Intelligence Estimate (NIE 8-3-62) of 19 September 1962.76
Nowhere does the 10-page Killian Report mention adversarial denial and decep­
tion. Within US intelligence organizations, the awareness and systematic study of for­
eign D&D had not been developed, and would not emerge until some 20 years later. It 
is likely that with a trained, well-staffed, and deception-aware analytic corps, the United 
States could have uncovered Khrushchev’s great gamble long before Maj. Heyser’s re­
vealing U-2 mission.
Only now, four decades later, can we uncover the extent of the use of deception 
in the events leading to the Cuban missile crisis. To paraphrase Sir Winston Churchill, 
perhaps the least-explored aspect of the crisis was the Soviet effort to cloak the truth 
of its strategic missile deployment within a body-guard of lies, on a scale that most US 
planners could not comprehend.
Footnotes
1.	
Cuba is approximately 145 kilometers from US shores. The SS-4 medium-range ballistic missiles, which were 
deployed first to Cuba, had a range of up to 2,500 kilometers. The SS-5 intermediate-range ballistic missiles 
had a range of up to 5,000 kilometers.
2.	
Jennie A. Stevens and Henry S. Marsh, “Surprise and Deception in Soviet Military Thought,” Military Review, 
July 1982, pp. 25-35.
3.	
Defense Intelligence Agency (DIA), Soviet/Warsaw Pact Ground Forces Camouflage and Concealment Tech­
niques, DDI-1100-161-78, January 1979, p. vii.
4.	
Gen. Anatoli I. Gribkov and Gen. William Y. Smith, Operation ANADYR: US and Soviet Generals Recount 
the Cuban Missile Crisis (Chicago, Berlin, Tokyo, and Moscow: edition q, inc., 1994), p. 24. This is a vital 
source, given Gen. Gribkov’s role in planning and implementing the operation.
5.	
Ibid.
6.	
Raymond L. Garthoff, Reflections on the Cuban Missile Crisis, revised edition (Washington, DC: The Brook­
ings Institution, 1989), pp. 12-13.
7.	
Dino A. Brugioni, Eyeball to Eyeball: The Inside Story of the Cuban Missile Crisis (New York: Random 
House, 1991), p. 84. The author was a key figure at the National Photographic Interpretation Center in 1962.
8. 	
Garthoff, p. 17.
9.	
Gribkov and Smith, p. 24.

 
Soviet Deception in the Cuban Missile Crisis—Learning from the Past
The Art and Science of Military Deception	
261
10.	
Garthoff, p. 17.
11.	
Aleksandr Fursenko and Timothy Naftali, “One Hell of a Gamble”: Khrushchev, Castro, and Kennedy, 1958-
1964 (New York and London: W. W. Norton & Company, 1997), p. 191. This valuable source relies on mate­
rial from Soviet/Russian archives.
12.	
Gribkov and Smith, p. 15.
13.	
Ibid.
14.	
Garthoff, p. 15; also, Gribkov and Smith, p. 14.
15.	
Fursenko and Naftali, p. 186.
16.	
James G. Blight, Bruce J. Allyn, and David A. Welch, with the assistance of Davis Lewis, Cuba on the Brink: 
Castro, the Missile Crisis, and the Soviet Collapse (New York: Pantheon Books, 1993), p. 8. This source draws 
extensively on input from key Soviet/Russian and American officials who had a hand in the crisis.
17.	
Brugioni, p. 92.
18.	
Gribkov and Smith, p. 21.
19.	
Fursenko and Naftali, p. 192.
20.	
Gribkov and Smith, pp. 37-38.
21.	
Brugioni, p. 93.
22.	
Gribkov and Smith, p. 56.
23. 	
Ibid., p. 29.
24.	
Brugioni, p. 149.
25.	
Gribkov and Smith, p. 30.
26.	
Ibid., p. 56.
27.	
Ibid., p. 29.
28.	
Ibid., p. 30.
29.	
Ibid., p. 56.
30.	
Brugioni, pp. 149-150.
31.	
Gribkov and Smith, p. 31.
32.	
Ibid.
33.	
US SIGINT revealed that Soviet vessels were making false port declarations and listing less than their known 
cargo-carrying capacity. By late August, the National Security Agency noted that 57 voyages to Cuba had 
taken place in a little over a month and that some ships were on their second voyage in that period of time. See: 
National Security Agency, NSA and the Cuban Missile Crisis (Fort Meade, MD: NSA Center for Cryptologic 
History, 1998), pp. 3-4.
34.	
Brugioni, p. 149.
35.	
Gribkov and Smith, p. 57.
36.	
Fursenko and Naftali, p. 192.
37.	
Ibid.
38.	
Ibid., p. 193.
39.	
Gribkov and Smith, p. 35.
40.	
Ibid., p. 56.
41.	
Ibid.
42.	
Brugioni, p. 148. The Cubans probably knew that the British were helping the United States, which did not 
have formal representation in Havana.
43.	
Gribkov and Smith, p. 38. Gribkov’s map puts Nicaro in the wrong location, apparently confusing it with 
Niquero on the Southeast coast.
44.	
Fursenko and Naftali, p. 216.
45.	
Brugioni, p. 150.
46.	
David Detzer, The Brink: Cuban Missile Crisis, 1962 (New York: Thomas Y. Crowell, 1979), p. 69.
47.	
Ibid., p. 57.
48.	
Gribkov and Smith, p. 52.

Soviet Deception in the Cuban Missile Crisis—Learning from the Past
262 
The Art and Science of Military Deception
49.	
Fursenko and Naftali, p. 217. There is conflicting source information on the number of warheads specifically 
for the SS-4 missiles. Gribkov states that 36 such warheads were introduced. This issue cannot be resolved 
based on current evidence, but 36 appears to be a likely figure as that tracks with Soviet doctrinal require­
ments for refire missiles.
50.	
Gribkov and Smith, p. 28.
51.	
Ibid., pp. 38-39.
52.	
Ibid.
53.	
Detzer, p. 57.
54. 	
Brugioni, p. 101.
55.	
NSA, op. cit., pp. 2-3. The US SIGINT ship Oxford was hugging the Cuban coastline at that time.
56.	
Domingo Amuchastegui, “Cuban Intelligence and the October Crisis,” Intelligence and National Security, 
Volume 13, Number 3, Autumn 1998, p. 101. This is a special issue on intelligence and the missile crisis, ed­
ited by James G. Blight and David A. Welch. It is a unique collection of articles on the roles played by different 
intelligence services.
57.	
Ibid.
58.	
Detzer, p. 59.
59.	
Ibid., p. 60.
60.	
Gribkov and Smith, p. 39. This maskirovka requirement is comparable to that used during the Korean con­
flict, when Soviet pilots were instructed to speak in Chinese while flying missions to try to fool US SIGINT 
units.
61.	
Ibid.
62.	
Ibid., p. 52, and Amuchastegui, p. 101. A cautionary note here is that this article is the only published account 
by a former Cuban intelligence officer thus far.
63.	
Brugioni, p. 115.
64.	
Blight, Allyn, and Welch, pp. 463-464.
65.	
Brugioni, pp. 157-158.
66.	
Blight, Allyn, and Welch, pp. 465-466.
67.	
Brugioni, p. 150.
68.	
Gribkov and Smith, p. 40.
69.	
Ibid., p. 55.
70.	
Ibid., p. 40.
71.	
The details of the U-2 mission are found in Volume XI: Foreign Relations of the United States, 1961-1963, Cu­
ban Missile Crisis and Aftermath, edited by Edward C. Keefer, Charles S. Sampson, Louis J. Smith, and David 
S. Patterson (Washington, DC: US Government Printing Office, 1996), p. 29. Although uncertain about the 
status of the weapons in Cuba at the time of discovery, we now know that only some of the nuclear-capable 
delivery systems were ready for action in late October. Of the 36 SS-4s deployed, for example, only about half 
were ready to be fueled—an 18-hour process—and not one had been programmed for flight. See Gribkov and 
Smith, p. 63.
72.	
Gribkov and Smith, p. 53.
73.	
Detzer, p. 194.
74.	
This revelation comes from a former GRU officer who wrote under the pen name of “Viktor Suvorov” and 
produced books and articles on the Soviet military and intelligence forces in the 1980s.
75.	
Central Intelligence Agency, CIA Documents on the Cuban Missile Crisis (Washington, DC: CIA, 1992), 
p. 367.
76.	
Ibid., pp. 367-368.

263
C H A P T E R  3 3
The Barry and Thomas Critique of the Pentagon 
Report: In the Lessons and Non-Lessons of the 
Air and Missile Campaign in Kosovo1
Anthony Cordesman
Anthony Cordesman was a member of the strategic assessment group that assisted Gen­
eral Stanley McChrystal in developing a new strategy for Afghanistan. Before joining 
CSIS, Cordesman served as director of intelligence assessment in the Office of the Secre­
tary of Defense and as a civilian assistant to the deputy secretary of defense.
The Kosovo air campaign shows that the most sophisticated weapons of war are 
easily fooled by relatively primitive decoys.  So, as weapons systems become more so­
phisticated, the opportunities for deception remain the same, or perhaps greater. 
1.	
Anthony Cordesman, The Lessons and Non-Lessons of the Air and Missile Campaign in Kosovo, Westport, CT: 
Greenwood Press, 2001, pp. 159–162.

The Barry and Thomas Critique of the Pentagon Report
264 
The Art and Science of Military Deception

 
The Barry and Thomas Critique of the Pentagon Report
The Art and Science of Military Deception	
265


267
C H A P T E R  3 4
Denial and Deception Practices of WMD 
Proliferators: Iraq and Beyond1
David A. Kay
David A. Kay is best known for heading the Iraq Survey Group and acting as a Weapons 
Inspector in Iraq after the 2003 U.S. invasion.  Dr. Kay served as the UN Chief Weapons 
Inspector from 1991–1992.  Following that, he was Vice President of Science Applica­
tions International Corporation (SAIC) from 1993–2002.
1.	
David A. Kay, “Denial and Deception Practices of WMD Proliferators: Iraq and Beyond,” The Washington Quar­
terly, Vol. 18, No. 1, Winter 1995, pp. 85-105.

Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
268 
The Art and Science of Military Deception

 
Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
The Art and Science of Military Deception	
269

Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
270 
The Art and Science of Military Deception

 
Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
The Art and Science of Military Deception	
271

Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
272 
The Art and Science of Military Deception

 
Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
The Art and Science of Military Deception	
273

Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
274 
The Art and Science of Military Deception

 
Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
The Art and Science of Military Deception	
275

Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
276 
The Art and Science of Military Deception

 
Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
The Art and Science of Military Deception	
277

Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
278 
The Art and Science of Military Deception

 
Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
The Art and Science of Military Deception	
279

Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
280 
The Art and Science of Military Deception

 
Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
The Art and Science of Military Deception	
281

Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
282 
The Art and Science of Military Deception

 
Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
The Art and Science of Military Deception	
283

Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
284 
The Art and Science of Military Deception

 
Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
The Art and Science of Military Deception	
285

Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
286 
The Art and Science of Military Deception

 
Denial and Deception Practices of WMD Proliferators: Iraq and Beyond
The Art and Science of Military Deception	
287


289
Section VIII: 
Irregular Warfare and Non-State Actors 
Introduction
Terrorists and Other Non-State Actors—Constraints and Opportunities
Warfare has often been described as symmetric, where belligerents have similar power 
and available resources and generally use similar strategies and tactics. World Wars I 
and II were mostly fought symmetrically. Asymmetric warfare describes conflicts where 
absolute power and resources are significantly different among warring factions. Ac­
cordingly, for the weaker belligerents, strategies and tactics must be sufficiently different 
to offset their quantitative and qualitative disadvantages. To be sure, the stronger actor 
must also make adjustments to prevail. The American Revolution was mostly fought 
asymmetrically, especially in the south. The symmetries of warfare have generally fo­
cused on power and tactical differences but have included disparities in the interests of 
the belligerents as well.1 
Contemporary terrorist and insurgent threats have forced the academic and military 
communities to breathe new life into the study and practice of asymmetric warfare in 
general and warfare against nonstate and illicit actors in particular. Previous research 
attempted to explain how weaker actors prevail over stronger opponents, the nature of 
the strategies used by successful weak and strong actors, and occasionally, but not suf­
ficiently, the nature of the weaker actor. There has been little research conducted on the 
relationship between stratagem and asymmetric warfare. 
Weaker actors, whether they are insurgents, terrorists, state proxies or sympathetic 
groups, are forced to operate in the shadows, even covertly, to survive. This point is 
non-trivial and has important ramifications for denial, deception and ultimately for the 
scope of political-military strategy and operations. For nonstate and illicit actors, an ad­
ditional geometric element, an imbalance, exists between the requirement for deniabil­
ity and the need to conduct operations. The revelation of any substantive information 
about a nonstate or illicit actor can be lethal to their very existence.
Accordingly, illicit groups and nonstate actors must practice denial as a strategic ne­
cessity, not as a choice. If these actors trifle with this requirement they risk being rolled 
up and destroyed by the state.  J. Bowyer Bell clearly points out that the greater the 
need for denial, the greater the cost in operational efficiency.  The practical implication 
of devoting extensive resources towards concealing one’s existence and activities is that 
there are minimal residual resources for strategic deception or the strategic offense. In 
other words, the greater the need for denial, the less the likelihood of deception.  The 
1.	
 Andrew Mack, “Why Big Nations Lose Small Wars,” World Politics, Vol 27, No. 2, January 1975, p. 181.

Section VIII: Irregular Warfare and Non-State Actors  
290 
The Art and Science of Military Deception
occurrence of tactical surprise is much more likely and is necessary to advance, or at 
least sustain, an illicit actor’s cause.2
Correcting this imbalance between the requirement for deniability and the need to 
conduct operations is fundamental to success for illicit groups. This correction must 
involve increasing the legitimacy or justice of the cause within the geographic bounds 
of the conflict as well as internationally. As the perception of legitimacy increases, the 
struggle can slowly move out of the shadows and operate more overtly while maintain­
ing sufficient security for organizational survival.3
For illicit groups, the future of strategic deception may be directly linked to the 
perception of legitimacy or justice of the cause. In fact, deception can have a significant 
role in defining the nature of the struggle itself.4 Illicit organizations often have affiliated 
legitimate or semi-legitimate groups operating to inform target audiences and frame the 
struggle in terms of justice. Affiliated radical groups can easily operate in open societ­
ies outside the geographic area of the fight. In other words, strategic deception in the 
modern information environment can disguise the true nature of a political-military 
struggle. Strategic deception can, therefore, help correct the imbalance between the re­
quirement for deniability and the need to conduct operations for illicit groups. The 
greater the perceived legitimacy, the less the need for strategic denial.
In conclusion, strategic deception by illicit groups who do not have significant per­
ceived legitimacy is highly unlikely; the requirement for strategic denial is simply too 
great. Establishing legitimacy by deceptive means can offer illicit groups the freedom 
of maneuver necessary to redirect resources for the offense, shored up by strategic de­
ception. For the state, delegitimizing the illicit actor by every means available, includ­
ing deception, can ultimately render the illicit actor irrelevant, or even better, result 
in his destruction. However, one should never forget that self-deception is also a sig­
nificant threat if one unequivocally believes that illicit groups are incapable of strategic 
deception.
2.	
 J. Bowyer Bell, “Conditions Making for Success and Failure of Denial and Deception: Nonstate and Illicit Actors,” 
in Strategic Denial and Deception, Roy Godson and James Wirtz, editors, London: Transaction Publishers, 2002, 
p. 129.
3.	
 Ibid., 134.
4.	
 Ibid., 141.

291
C H A P T E R  3 5
Conditions Making for Success and Failure 
of Denial and Deception: Nonstate and Illicit 
Actors1
J. Bowyer Bell
J. Bowyer Bell received his doctorate from Duke University and went on to teach at 
M.I.T., Harvard and Trinity Universities.  While studying the Middle East, Bell became 
interested in the tactics and techniques of the IRA, and subsequently published his book, 
“The Secret Army: The IRA 1916–1970.”  Continuing his work in war and peace stud­
ies, Bell founded the International Analysis Center, whose clients included the United 
States Department of Justice and the Central Intelligence Agency.  Also an artist, the 
author painted scenes from the conflicts he witnessed.  Since his death in 2003, his paint­
ings continue to be shown around the world.
1.	
J. Bowyer Bell, “Non State and Illicit Actors,” in Strategic Denial and Deception: The Twenty-First Century Chal­
lenge, Roy Godson and James J. Wirtz, editors, NJ: Transaction Publishers, 2002, pp. 129-131, 159-161.

Conditions Making for Success and Failure of Denial and Deception: Nonstate and Illicit Actors
292 
The Art and Science of Military Deception

 
Conditions Making for Success and Failure of Denial and Deception: Nonstate and Illicit Actors
The Art and Science of Military Deception	
293

Conditions Making for Success and Failure of Denial and Deception: Nonstate and Illicit Actors
294 
The Art and Science of Military Deception

 
Conditions Making for Success and Failure of Denial and Deception: Nonstate and Illicit Actors
The Art and Science of Military Deception	
295


297
C H A P T E R  3 6
The Evolution of a Revolt1
Lieutenant-Colonel T.E. Lawrence
In this too often overlooked landmark paper, Lawrence of Arabia presents the first 
theory of what he calls “irregular war,” namely asymmetrical combat between regular 
military units and “irregulars.” It is based on his closely involved experience with the 
Arab Revolt against the Turkish Army occupiers in the Arabian Peninsula, from its in­
ception in June 1916 until victory in Palestine and Syria in 1918. Although Lawrence 
exaggerated the effectiveness of his guerrilla operations in diverting substantial Turkish 
strength from the Palestinian front, his theory stands on its own. 
Lawrence had been invited by his former colleague, Col. Guy Dawnay, to con­
tribute an article to the inaugural edition of editor Dawnay’s “Military Quarterly.” 
Accordingly, Lawrence drew from the sections on military strategy in the second and 
later destroyed draft of his monumental “Seven Pillars of Wisdom,” which wouldn’t be 
published in its world-famous third draft until 1926. There he would recycle his “The 
Evolution of A Revolt” article into Chapters 33 and 59. Still later, with Lawrence’s per­
mission, Capt. Liddell Hart lightly edited this piece for his article, “Science of Guerrilla 
Warfare,” which he published above Lawrence’s initials in the Encyclopedia Britannica, 
14th Edition (1929). Liddell Hart sent the 15 guinea fee along to Lawrence, who in de­
light wrote back, “The cheque delights me. I fancy Guy Dawnay only paid £10 for the 
original article.”
Lawrence, a most unusual Englishman, had graduated Oxford in 1910 with a de­
gree in history and a deep interest in archaeology. He served in Military Intelligence 
during World War I, during which he rose to the rank of lieutenant colonel. Afterwards 
he championed Arab rule in the Near East.
A major part of Lawrence’s operations was ambushing the Turkish trains moving 
on the Hejaz Railway. However, he had deliberately left out the one detail that explains 
how he could know when and where to hit these trains, or even how he knew which 
kinds of supplies or troop reinforcements each train carried. How could he hit them 
with minimal chance of being outgunned, much less counter-ambushed? He was as­
sured of this crucial intelligence through a cunning deception operation that he either 
devised himself or, more likely, inherited. Lawrence, not a modest man, kept this secret 
during his lifetime only because it involved one of the deepest secrets of British Military 
Intelligence—namely, the British were freely reading all Turkish codes except two, the 
Ildirim Radio Code and the Telegraph Code. By constantly cutting the railway tele­
graph lines, Lawrence forced the Turks to switch all railway communications to radio, 
thereby unintentionally but automatically sharing this private information with Brit­
ish Intelligence. Although Lawrence’s exploitation of this closely-held British SIGINT 
1.	
Lieutenant-Colonel T.E. Lawrence, “The Evolution of a Revolt,” Army Quarterly, Vol.1, No.1, London: October, 
1920, pp. 55-69.

The Evolution of a Revolt
298 
The Art and Science of Military Deception
secret was published by Liddell Hart in 1938,2 its significance wasn’t noticed until 
recently through the research of Yigal Sheffy (1998), an Israeli military historian and 
former IDF intelligence officer.
The Arab Revolt began in June, 1916, with an Arab offensive, a surprise attack 
by the half-armed and inexperienced tribesmen upon the Turkish garrisons in Medina 
and about Mecca. They had no success, and after a few days’ effort they withdrew out 
of range of the fort artillery, and began a blockade. This method forced the early sur­
render of Mecca, whose road communications were too long and rough to be held by 
the Turks. Medina, however, was linked by railway to the Turkish main Army in Syria, 
and, thanks to their superior numbers and equipment, the Turks were able in a week’s 
fighting to restore the line and reinforce the temporarily-besieged garrison there. The 
Arab forces which had attacked it fell back gradually as the Turks became more offen­
sive, and at last moved fifty miles south-west into the hills, and there took up a position 
across the main road to Mecca. At this point the campaign stood still for many weeks, 
while both sides breathed, and the Turks prepared to take the initiative, by sending an 
expeditionary force to Mecca, to crush the revolt where it had started. They moved an 
army corps to Medina by rail, and strengthened it beyond establishment with guns, 
cars, aeroplanes, machine guns, and quantities of horse, mule and camel transport. 
Then they began to advance down the main western road from Medina to Mecca. The 
total distance was about two hundred and fifty miles. The first fifty miles were easy: 
then came a belt of hills twenty miles wide, in which were Feisal’s tribesmen standing on 
the defensive: after the hills was a level stretch, for seventy miles along the coastal plain 
to Rabegh, rather more than half-way. Rabegh is a little port on the Red Sea, with good 
anchorage for ships. In it was Sherif Ali, Feisals eldest brother, with more tribal forces, 
and the beginnings of an Arab Regular Army, recruited from officers and men of Arab 
Blood, who had served in the Turkish Army, and were now willing to fight against their 
old masters for their national freedom.
Our military advisers had told us that Rabegh was the key of Mecca, since no hos­
tile force could pass along the main road without occupying it and watering at its wells 
under the palm trees. Its defence was therefore of the main importance. The Navy could 
cooperate effectively from the harbour, and the circle of the palm-groves must be laid 
out as an entrenched position, and held by regular troops. They thought that Beduin 
tribesmen would never be of any value in a fixed position, and that therefore an Arab 
regular force must be formed and trained as soon as possible to undertake this duty. If 
the Turks advanced before the new force was ready, the British would have to lend a 
brigade, of British or Allied troops, to save the Sherif in his extremity, by maintaining 
this stop-block.
A personal reconnaissance of the Arab positions, here and in the hills where Feisal 
was, caused me to modify the views of the experts slightly. Feisal had some thousands of 
men, all armed with rifles, rather casual, distrustful fellows, but very active and cheerful. 
2. T. E. Lawrence to His Biographer, Liddell Hart (New York: Doubleday, Doran & Co., 1938), 115, reprinting Liddell 
Hart, T. E. Lawrence in Arabia and After (London: Cape, 1935), 313. Lawrence’s note reads: “[P]art of the trouble 
was that we did not use W/T for ‘operation’ messages. Allenby every morning for breakfast had the log of Turkish 
signals over the preceding 24 hours: we read their every message —and I presume they read all of ours. To keep 
our moves secret we used air-mail or word of mouth. To keep the Turks public, one of my cares was to distribute 
wirecutters over their rear, and cut their telegraph at least daily.”

 
The Evolution of a Revolt
The Art and Science of Military Deception	
299
They were posted in hills and defiles of such natural strength that it seemed to me very 
improbable that the Turks could force them, just by their superior numbers: for in some 
ways it is easier to defend a range of hills against nine or ten thousand men than against 
nine or ten. Accordingly, I reported that the tribesmen (if strengthened by light machine 
guns, and regular officers as advisers) should be able to hold up the Turks indefinitely, 
while the Arab regular force was being created. As was almost inevitable in view of the 
general course of military thinking since Napoleon, we all looked only to the regulars to 
win the war. We were obsessed by the dictum of Foch that the ethic of modern war is to 
seek for the enemy’s army, his centre of power, and destroy it in battle. Irregulars would 
not attack positions and so they seemed to us incapable of forcing a decision.
While we were training the regulars (of course not sending officer or light machine 
guns to Feisal in the hills meanwhile), the Turks suddenly put my appreciation to the 
test by beginning their advance on Mecca. They broke through my “impregnable” hills 
in twenty-four hours, and came forward from them towards Rabegh slowly. So they 
proved to us the second theorem of irregular war—namely, that irregular troops are as 
unable to defend a point or line as they are to attack it.
This lesson was received by us quite without gratitude, for the Turkish success put 
us in a critical position. The Rabegh force was not capable of repelling the attack of 
a single battalion, much less of a corps. It was nearly impossible to send down British 
troops from Egypt at the moment: nor do I think that a single British brigade would 
have been capable of holding all the Rabegh position: nor was the Rabegh position 
indispensable to the Turks: nor would a single Arab have remained with the Sherif if he 
introduced British troops into the Hejaz.
 In the emergency it occurred to me that perhaps the virtue of irregulars lay in depth, 
not in face, and that it had been the threat of attack by them upon the Turkish northern 
flank which had made the enemy hesitate for so long. The actual Turkish flank ran from 
their front line to Medina, a distance of some fifty miles; but, if we moved towards the 
Hejaz j railway behind Medina, we might stretch our threat (and, accordingly, their 
flank) as far, potentially, as Damascus, eight hundred miles away to the north. Such a 
move would force the Turks to the defensive, and we might regain the initiative. Any­
how, it seemed our only chance, and so, in January, 1917, we took all Feisal’s tribes­
men, turned our backs on Mecca, Rabegh and the Turks, and marched away north two 
hundred miles to Wejh, thanks to the help of the British Red Sea Fleet, which fed and 
watered us along the coast, and gave us gun-power and a landing party at our objective.
This eccentric movement acted like a charm. Clausewitz had said that rearguards 
modulate the enemy’s action like a pendulum, not by what they do, but by their mere 
existence. We did nothing concrete, but our march recalled the Turks (who were almost 
into Rabegh) all the way back to Medina, and there they halved their force. One half 
took up the entrenched position about the city, which they held until after the Armistice. 
The other half was distributed along the railway to defend it against our threat. For the 
rest of the war the Turks stood on the defensive against us, and we won advantage over 
advantage till, when peace came, we had taken thirty-five thousand prisoners, killed 
and wounded and worn out about as many, and occupied a hundred thousand square 
miles of the enemy’s territory, at little loss to ourselves.
However, we were not then aware that Wejh was our turning point. We thought 
we had come to it to cut the railway, and I was at once sent up country to do this, as a 
means to take Medina, the Turkish headquarters and main garrison. On the way up I 

The Evolution of a Revolt
300 
The Art and Science of Military Deception
fell ill, and spent ten days on my back in a tent, without anything to do except to think 
about war and analyse our hitherto empirical practice for its real import.
I was unfortunately as much in charge of the campaign as I pleased, and had had 
no training in command to fit me for such a work. In military theory I was tolerably 
read, for curiosity in Oxford years before had taken me past Napoleon to Clausewitz 
and his school, to Caemmerer and Moltke, Goltz and the recent Frenchmen. These had 
seemed very partial books, and after a look at Jomini and Willisen I had found broader 
principles in the eighteenth century, in Saxe, Guibert and their followers. However, 
Clausewitz was intellectually so much the master of them all that unwillingly I had 
come to believe in him. Tactically the only campaigns I had studied step by step were 
the ancient affairs of Hannibal and Belisarius, Mohammed and the Crusades! My in­
terests were only in pure theory and I looked everywhere for the metaphysical side, the 
philosophy of war, about which I thought a little for some years. Now I was compelled 
suddenly to action, to find an immediate equation between my book-reading and our 
present movements.
However, the books gave me the aim in war quite pat, “the destruction of the orga­
nized forces of the enemy” by “the one process battle.” Victory could only be purchased 
by blood. This was a hard saying for us, as the Arabs had no organized forces, and so a 
Turkish Foch would have no aim: and the Arabs would not endure casualties, so that an 
Arab Clausewitz could not buy his victory. These wise men must be talking metaphors, 
for we were indubitably winning our war . . . and as I thought about it, it dawned on 
me that we had won the Hejaz war. We were in occupation of 99 percent of the Hejaz. 
The Turks were welcome to the other fraction till peace or doomsday showed them the 
futility of clinging to our window pane. This part of the war was over, so why bother 
about Medina? It was no base for us, like Rabegh, no threat to the Turks, like Wejh: just 
a blind alley for both. The Turks sat in it on the defensive, immobile, eating for food 
the transport animals which were to have moved them to Mecca, but for which there 
was no pasture in their now restricted lines. They were harmless sitting there; if we took 
them prisoner, they would cost us food and guards in Egypt: if we drove them out north­
ward into Syria, they would join the main Army blocking us in Sinai. On all counts they 
were best where they were, and they valued Medina and wanted to keep it. Let them!
This seemed unlike the ritual of war of which Foch had been priest, and so I began 
to hope that there was a difference of kind between us and him. He called his modern 
war “absolute.” In it two nations professing incompatible philosophies set out to try 
them in the light of force. A struggle of two immaterial principles could only end when 
the supporters of one had no more means of resistance. An opinion can be argued with: 
a conviction is best shot. The logical end of a war of creeds is the final destruction of 
one, and Salammbo the classical textbook-instance. These were the lines of the struggle 
between France and Germany, but not, I thought, between Germany and England, for 
all efforts to make our men hate the enemy just made them hate war, and later on by 
the Armistice we made the Great War fall short of the Foch ideal. To me it seemed only 
a variety of war: and I could then see other sorts, as Clausewitz had numbered them, 
personal wars for dynastic reasons, expulsive wars for party reasons, commercial wars 
for trading reasons.
Then I thought of the Arab aim, and saw that it was geographical, to occupy all 
Arabic-speaking lands in Asia. In the doing of it we might kill Turks: we disliked them 
very much. Yet “killing Turks” would never be an excuse or aim. If they would go qui­
etly, our war would end. If not, we would try to drive them out: in the last resort we 

 
The Evolution of a Revolt
The Art and Science of Military Deception	
301
would be compelled to the desperate course of blood, on the maxim of “murder” war, 
but as cheaply as possible for ourselves, since the Arabs were fighting for freedom, a 
pleasure only to be tasted by a man alive.
My own personal duty was command, and I began to unravel command and anal­
yse it, both from the point of view of strategy, the aim in war, the synoptic regard which 
sees everything by the standard of the whole, and from the point of view called tactics, 
the means towards the strategic end, the steps of its staircase. In each I found the same 
elements, one algebraical, one biological, a third psychological. The first seemed a pure 
science, subject to the laws of mathematics, without humanity. It dealt with known in­
variables, fixed conditions, space and time, inorganic things like hills and climates and 
railways, with mankind in type-masses too great for individual variety, with all artificial 
aids, and the extensions given our faculties by mechanical invention. It was essentially 
formulable.
In the Arab case the algebraic factor would take first account of the area we wished 
to conquer, and I began idly to calculate how many square miles . . . perhaps a hun­
dred and forty thousand . . . and how would the Turks defend all that . . . no doubt by 
a trench line across the bottom, if we were an army attacking with banners displayed 
. . . but suppose we were an influence (as we might be), an idea, a thing invulnerable, 
intangible, without front or back, drifting about like a gas? Armies were like plants, 
immobile as a whole, firm-rooted, nourished through long stems to the head. We might 
be a vapour, blowing where we listed. Our kingdoms lay in each man’s mind, and as we 
wanted nothing material to live on, so perhaps we offered nothing material to the kill­
ing. It seemed a regular soldier might be helpless without a target. He would own the 
ground he sat on, and what he could poke his rifle at.
Then I estimated how many posts they would need to contain this attack in depth, 
sedition putting up her head in every unoccupied one of these hundred thousand square 
miles. I knew the Turkish Army inside and out, and allowing for its recent extension of 
faculty by guns and aeroplanes and armoured trains, still it seemed it would have need 
of a fortified post every four square miles, and a post could not be less than twenty 
men. The Turks would need six hundred thousand men to meet the combined ill wills 
of all the local Arab people. They had one hundred thousand men available. It seemed 
the assets in this part of command were ours, and climate, railways, deserts, technical 
weapons could also be attached to our interests, if we realized our raw materials and 
were apt with them. The Turk was stupid and would believe that rebellion was absolute, 
like war, and deal with it on the analogy of absolute warfare. Analogy is fudge, anyhow, 
and to make war upon rebellion is messy and slow, like eating soup with a knife.
So much for the mathematical element, which I annoyed the others by calling hec­
astics. The second factor was biological, the breaking-point, life and death, or better, 
wear and tear. Bionomics seemed a good name for it. The war-philosophers had prop­
erly made it an art, and had elevated one item in it, “effusion of blood,” to the height 
of a principle. It became humanity in battle, an art touching every side of our corporal 
being, and very war. There was a line of variability (man) running through all its esti­
mates. Its components were sensitive and illogical, and generals guarded themselves by 
the device of a reserve, the significant medium of their art. Goltz had said that when you 
know the enemy’s strength, and he is fully deployed, then you know enough to dispense 
with a reserve. But this is never. There is always the possibility of accident, of some 
flaw in materials, present in the general’s mind: and the reserve is unconsciously held 
to meet it. There is a “felt” element in troops, not expressible in figures, guessed at by 

The Evolution of a Revolt
302 
The Art and Science of Military Deception
the equivalent of ssεa in Plato, and the greatest commander is he whose intuitions most 
nearly happen. Nine-tenths of tactics are certain, and taught in books: but the irrational 
tenth is like the kingfisher flashing across the pool, and that is the test of generals. It can 
only be ensured by instinct, sharpened by thought practising the stroke so often that at 
the crisis it is as natural as a reflex.
Yet to limit the art to humanity seemed to me an undue narrowing down. It must 
apply to materials as much as to organisms. In the Turkish Army materials were scarce 
and precious, men more plentiful than equipment. Consequently our cue should be to 
destroy not the Army but the materials. The death of a Turkish bridge or rail, machine 
or gun, or high explosive was more profitable to us than the death of a Turk. The Arab 
Army just now was equally chary of men and materials: of men because they being 
irregulars were not units, but individuals, and an individual casualty is like a pebble 
dropped in water: each may make only a brief hole, but rings of sorrow widen out 
from them. We could not afford casualties. Materials were easier to deal with and put 
straight. It was our obvious duty to make ourselves superior in some one branch, gun-
cotton or machine guns, or whatever could be made most decisive. Foch had laid down 
the maxim, applying it to men, of being superior at the critical point and moment of 
attack. We might apply it to materials, and be superior in equipment in one dominant 
moment or respect. 
For both men and things we might try to give Foch’s doctrine a negative twisted 
side, for cheapness’ sake, and be weaker than the enemy everywhere except in one point 
of matter. Most wars are wars of contact, both forces striving to keep in touch to avoid 
tactical surprise. Our war should be a war of detachment: we were to contain the enemy 
by the silent threat of a vast unknown desert, not disclosing ourselves till the moment 
of attack. This attack need be only nominal, directed not against his men, but against 
his materials: so it should not seek for his main strength or his weaknesses, but for his 
most accessible material. In railway cutting this would be usually an empty stretch of 
rail. That was a tactical success. We might turn the average into a rule (not a law—war 
is antinomian, said Colin), and at length we developed an unconscious habit of never 
engaging the enemy at all. This chimed with the numerical plea of never giving the en­
emy’s soldier a target. Many Turks on our front had no chance all the war to fire a shot 
at us, and correspondingly we were never on the defensive, except by rare accident. The 
corollary of such a rule was perfect “intelligence,” so that we could plan in complete 
certainty. The chief agent had to be the general’s head (de Feuquiere said this first), and 
his knowledge had to be faultless, leaving no room for chance. We took more pains in 
this service than any other staff I saw.
The third factor in command seemed to be the psychological, that science (Xeno­
phon called it diathetic) of which our propaganda is a stained and ignoble part. Some 
of it concerns the crowd, the adjustment of spirit to the point where it becomes fit to 
exploit in action, the prearrangement of a changing opinion to a certain end. Some of 
it deals with individuals, and then it becomes a rare art of human kindness, transcend­
ing, by purposeful emotion, the gradual logical sequence of our minds. It considers the 
capacity for mood of our men, their complexities and mutability, and the cultivation of 
what in them profits the intention. We had to arrange their minds in order of battle, just 
as carefully and as formally as other officers arranged their bodies: and not only our 
own men’s minds, though them first: the minds of the enemy, so far as we could reach 
them: and thirdly, the mind of the nation supporting us behind the firing-line, and the 
mind of the hostile nation waiting the verdict, and the neutrals looking on. 

 
The Evolution of a Revolt
The Art and Science of Military Deception	
303
It was the ethical in war, and the process on which we mainly depended for victory 
on the Arab front. The printing press is the greatest weapon in the armoury of the mod­
ern commander, and we, being amateurs in the art of command, began our war in the 
atmosphere of the twentieth century, and thought of our weapons without prejudice, 
not distinguishing one from another socially. The regular officer has the tradition of for­
ty generations of serving soldiers behind him, and to him the old weapons are the most 
honoured. We had seldom to concern ourselves with what our men did, but much with 
what they thought, and to us the diathetic was more than half command. In Europe it 
was set a little aside and entrusted to men outside the General Staff. In Asia we were 
so weak physically that we could not let the metaphysical weapon rust unused. We had 
won a province when we had taught the civilians in it to die for our ideal of freedom: 
the presence or absence of the enemy was a secondary matter.
These reasonings showed me that the idea of assaulting Medina, or even of starving 
it quickly into surrender was not in accord with our best strategy. We wanted the enemy 
to stay in Medina, and in every other harmless place, in the largest numbers. The factor 
of food would eventually confine him to the railways, but he was welcome to the Hejaz 
railway, and the Trans-Jordan railway, and the Palestine and Damascus and Aleppo 
railways for the duration of the war, so long as he gave us the other nine hundred and 
ninety-nine thousandths of the Arab world. If he showed a disposition to evacuate too 
soon, as a step to concentrating in the small area which his numbers could dominate 
effectively, then we would have to try and restore his confidence, not harshly, but by 
reducing our enterprises against him. Our ideal was to keep his railway just working, 
but only just, with the maximum of loss and discomfort to him. 
 Accordingly, I put in a few damages to the line, enough to annoy the enemy with­
out making him fear its final destruction, and then rode back to Wejh, to explain to 
my chiefs that the Arab war was geographical, and the Turkish Army for us an ac­
cident, not a target. Our aim was to seek its weakest link, and bear only on that till 
time made the mass of it fall. Our largest available resources were the tribesmen, men 
quite unused to formal warfare, whose assets were movement, endurance, individual 
intelligence, knowledge of the country, courage. We must impose the longest possible 
passive defence on the Turks (this being the most materially expensive form of war) by 
extending our own front to its maximum. Tactically we must develop a highly mobile, 
highly equipped type of army, of the smallest size, and use it successively at distributed 
points of the Turkish line, to make the Turks reinforce their occupying posts beyond the 
economic minimum of twenty men. The power of this striking force of ours would not 
be reckoned merely by its strength. The ratio between number and area determined the 
character of the war, and by having five times the mobility of the Turks we could be on 
terms with them with one-fifth their number.
 Our success was certain, to be proved by paper and pencil as soon as the propor­
tion of space and number had been learned. The contest was not physical, but mineral, 
and so battles were a mistake. All we won in a battle was the ammunition the enemy 
fired off. Our victory lay not in battles, but in occupying square miles of country. Napo­
leon had said it was rare to find generals willing to fight battles. The curse of this war 
was that so few could do anything else. Napoleon had spoken in angry reaction against 
the excessive finesse of the eighteenth century, when men almost forgot that war gave 
license to murder. We had been swinging out on his dictum for a hundred years, and 
it was time to go back a bit again. Battles are impositions on the side which believes 
itself weaker, made unavoidable either by lack of land-room, or by the need to defend 

The Evolution of a Revolt
304 
The Art and Science of Military Deception
a material property dearer than the lives of soldiers. We had nothing material to lose, 
so we were to defend nothing and to shoot nothing. The precious element of our forces 
were the Beduin irregulars, and not the regulars whose role would only be to occupy 
places to which the irregulars had already given access. Our cards were speed and time, 
not hitting power, and these gave us strategical rather than tactical strength. Range is 
more to strategy than force. The invention of bully-beef has modified land-war more 
profoundly than the invention of gunpowder.
My chiefs did not follow all these arguments, but gave me leave to try my hand after 
my own fashion. We went off first to Akaba, and took it easily. Then we took Tafileh 
and the Dead Sea: then Azrak and Deraa, and finally Damascus, all in successive stages 
worked out consciously on these sick-bed theories. The process was to set up ladders 
of tribes, giving us a safe and comfortable route from our sea-bases (Yenbo, Wejh or 
Akaba) to our advanced bases of operation. These were sometimes three hundred miles 
away, a long distance in lands without railways or roads, but made short for us by an 
assiduous cultivation of desert-power, control by camel parties of the desolate and un­
mapped wilderness which fills up all the centre of Arabia, from Mecca to Aleppo and 
Bagdad.
In character these operations were more like naval warfare than ordinary land op­
erations, in their mobility, their ubiquity, their independence of bases and communi­
cations, their lack of ground features, of strategic areas, of fixed directions, of fixed 
points. “He who commands the sea is at great liberty, and may take as much or as 
little of the war as he will”: he who commands the desert is equally fortunate. Camel 
raiding-parties, as self-contained as ships, could cruise without danger along any part 
of the enemy’s land-frontier, just out of sight of his posts along the edge of cultivation, 
and tap or raid into his lines where it seemed fittest or easiest or most profitable, with 
a sure retreat always behind them into an element which the Turks could not enter. We 
were fortified in our freedom of movement by an intimate knowledge of the desert-front 
of Syria, a country peculiarly and historically indefensible against attack from the east. I 
had traversed most of it on foot before the war many times, working out the movements 
of Saladin or Ibrahim Pasha, and, as our war-experience deepened, we became adepts 
at that form of geographical intuition, described by Bourcet as wedding unknown land 
to known in a mental map. 
Our tactics were always tip and run, not pushes, but strokes. We never tried to 
maintain or improve an advantage, but to move off and strike again somewhere else. 
We used the smallest force, in the quickest time, at the farthest place. If the action had 
continued till the enemy had changed his dispositions to resist it, we would have been 
breaking the spirit of our fundamental rule of denying him targets.
The necessary speed and range were attained by the extreme frugality of the desert 
men, and their high efficiency when mounted on their she-riding-camels. The camel is 
an intricate animal, and calls for skilled labour in the handling: but she yields a remark­
able return. We had no system of supply: each man was self-contained and carried on 
the saddle from the sea base at which the raid started, six weeks’ food for himself. 
The six-weeks’ ration for ordinary men was a half-bag of flour, forty-five pounds in 
weight. Luxurious feeders carried some rice also for variety. Each man baked for him­
self, kneading his own flour into unleavened cakes, and warming it in the ashes of a fire. 
We carried about a pint of drinking water each, since the camels required to come to 
water on average every three days, and there was no advantage in our being richer than 
our mounts. Some of us never drank between wells, but those were hardy men: most of 

 
The Evolution of a Revolt
The Art and Science of Military Deception	
305
us drank a lot at each well, and had a drink during the intermediate dry day. In the heat 
of summer Arabian camels will do about two hundred and fifty miles comfortably be­
tween drinks: and this represented three days’ vigorous marching. The country is not so 
dry as it is painted, and this radius was always more than we needed. Wells are seldom 
more than one hundred miles apart. An easy day’s march was fifty miles: an emergency 
march might be up to one hundred and ten miles in the day.
The six weeks’ food gave us a range of over a thousand miles out and home, and 
that (like the pint of water) was more than ever we needed, even in so large a country 
as Arabia. It was possible (for me, the camel-novice in the Army, “painful” was a better 
word) to ride fifteen hundred miles in the month without re-victualing, and there was 
never a fear of starvation, for each of us was riding on two hundred pounds of potential 
meat, and when food lacked we would stop and eat the weakest of our camels. Ex­
hausted camel is poor food, but cheaper killing than a fat one, and we had to remember 
that our future efficiency depended on the number of good camels at our disposal. 
They lived on grazing as we marched (we never gave them grain or fodder), and after 
their six weeks on the road they would be worn thin, and have to be sent to pasture 
for some months’ rest, while we called out another tribe in replacement, or found fresh 
riding-beasts.
We did not hamper ourselves with led-camels. The men carried with them a hun­
dred rounds of ammunition and a rifle, or else two men would be an “automatic” team, 
dividing the gun and its drums between them. They slept as they were, in their riding 
cloaks, and fared well enough till the winter of 1917–1918, which caught us on the five-
thousand foot hills of Edom behind the Dead Sea. Then we lost many men and camels 
frozen to death, or trapped in the snow, which lay over all the highlands in deep drifts 
for weeks, while we vainly appealed to Egypt for tents and boots and blankets. In reply 
we were advised that Arabia was a tropical country!
The equipment of the raiding parties aimed at simplicity, with nevertheless a techni­
cal superiority over the Turks in the most critical department. We had great quantities 
of light machine guns, used not as machine guns, but as automatic rifles, snipers’ tools, 
by men kept deliberately in ignorance of their mechanism, so that the speed of action 
would not be hampered by attempts at repair. If a gun jammed, the gunner had to throw 
it away, and go on with his rifle. We made another special feature of high explosives, 
and nearly everyone in the revolt was qualified by rule of thumb experience in demoli­
tion work. We invented special methods of our own, for rapid work under fire, in the 
course of our months of practice, and before the end were dealing with any quantity of 
track and bridges economically and safely.
On some occasions we strengthened tribal raids by armoured cars, manned by Eng­
lishmen. Armoured cars, once they have found a possible track can keep up with a 
camel party. They are, however, cumbrous and shorter-ranged, because of the difficulty 
of carrying petrol. Therefore we seldom used them more than a hundred miles from 
home. On the march to Damascus, when we were nearly four hundred miles off our 
base, we first maintained them by a baggage train of petrol-laden camels, and after­
wards by the help of the Air Force were able to give them further supplies by Handley-
Page. Cars are magnificent fighting machines, and decisive whenever they can come into 
action on their own conditions. But though each has for main principle that of “fire in 
movement,” yet the tactical employments of cars and camel-corps are so different that 
I do not recommend their being used in joint operations, except in very special circum­

The Evolution of a Revolt
306 
The Art and Science of Military Deception
stances. We found it demoralizing to both, to use armoured and unarmoured cavalry 
together.
The distribution of the raiding parties was unorthodox. It was impossible to mix or 
combine tribes, since they disliked or distrusted one another. Likewise we could not use 
the men of one tribe in the territory of another. In consequence, we aimed at the widest 
distribution of forces, in order to have the greatest number of raids on hand at once, 
and we added fluidity to their ordinary speed, by using one district on Monday, another 
on Tuesday, a third on Wednesday. This much reinforced their natural mobility. It gave 
us priceless advantages in pursuit, for the force renewed itself with fresh men in every 
new tribal area, and gave us always our pristine energy. Maximum disorder was in a 
real sense our equilibrium.
The internal economy of the raiding parties was equally curious. We aimed at maxi­
mum articulation. We were serving a common ideal, without tribal emulation, and so 
we could not hope for any esprit de corps to reinforce our motives. Soldiers are made a 
caste either by being given great pay and rewards in money, uniform, or political privi­
leges; or, as in England, by being made outcasts, cut off from their fellows by contempt. 
We could not knit man to man, for our tribesmen were in arms willingly, by conviction. 
There have been many armies enlisted voluntarily: there have been few armies serving 
voluntarily under such trying conditions, for so long a war as ours. Any of the Arabs 
could go home whenever the conviction failed him. Our only contract was honour.
Consequently we had no discipline, in the sense in which it is restrictive, submergent 
of individuality, the lowest common denominator of men. In regular armies in peace it 
means the limit of energy attainable by everybody present: it is the hunt not of an aver­
age, but of an absolute, a 100-percent, standard, in which the ninety-nine stronger men 
are played down to the level of the worst. The aim is to render the unit a unit, and the 
man a type, in order that their effort shall be calculable, their collective output even in 
grain and in bulk. The deeper the discipline, the lower the individual efficiency, and the 
more sure the performance. It is a deliberate sacrifice of capacity in order to reduce the 
uncertain element, the bionomic factor, in enlisted humanity, and its accompaniment is 
compound or social war, that form in which the man in the fighting line has to be the 
product of the multiplied exertions of the long hierarchy, from workshop to supply unit, 
which maintains him in the field.
The Arab war was simple and individual. Every enrolled man served in the line of 
battle, and was self-contained. We had no lines of communication or labour troops. The 
efficiency of each man was his personal efficiency. We thought that in our condition 
of warfare the sum yielded by single men would be at least equal to the product of a 
compound system, and it was certainly easier to adjust to tribal life and manners, given 
elasticity and understanding on the part of the commanding officers. Fortunately for 
our chances nearly every young Englishman has the roots of eccentricity in him, and so 
we got on well enough. Of course we used very few Englishmen in the field, not more 
than one per thousand of the Arab troops. A larger proportion would have created fric­
tion, just because they were foreign bodies (pearls if you please) in the oyster: and those 
who were present controlled by influence and advice, by their superior knowledge, not 
by an extraneous authority.
In practice we did not employ in the firing line the greater numbers which the adop­
tion of a “simple” system put theoretically at our disposal. We preferred to use them in 
relay: otherwise our attack would have become too extended. Each man had to have 
liberal work-room. In irregular war if two men are together one is being wasted. The 

 
The Evolution of a Revolt
The Art and Science of Military Deception	
307
moral strain of isolated action makes this simple form of war very exacting on the indi­
vidual soldier, and demands from him special initiative, endurance and enthusiasm. Our 
ideal was to make action a series of single combats. Napoleon, in his pregnant valuation 
of the Mamelukes in terms of French soldiers, first gave me the idea: Ardant du Picq 
widened its application: the prejudices of historians are generally the richest part of 
their histories. Our value depended entirely on our quality, not on our quantity. We had 
to keep always cool, for the excitement of a blood-lust would impair the science of our 
combatants, and our victory depended on our just use of speed, concealment, accuracy 
of fire. Irregular war is far more intellectual than a bayonet charge.
The illiteracy of our forces was not harmful, since we worked intentionally in these 
small numbers and explained our plan verbally to everyone. Their very illiteracy has 
trained them to a longer memory and a closer hearing of the news. Nor were our tactics 
too subtle, for they had to be translated into independent action through the heads of 
our followers, and success was impossible unless most of them used their intelligence 
to forward our conception against the moral and material accidents of the path. This 
dilution of tactical ability to the level of the lowest interpreter was regrettable, but not 
all loss. The only alternative would be independent enterprise, and a mediocre design, 
persisted in, is grander than a series of brilliant expedients and will overcome them in 
the end.
By careful persistence, kept strictly within our strength and following the spirit of 
our theories, we were able eventually to reduce the Turks to helplessness, and complete 
victory seemed to be almost within our sight when General Allenby by his immense 
stroke in Palestine threw the enemy’s main forces into hopeless confusion and put an 
immediate end to the Turkish war. We were very happy to have done with all our pains, 
but sometimes since I have felt a private regret that his too-greatness deprived me of the 
opportunity of following to the end the dictum of Saxe that a war might be won without 
fighting battles. It was an irony of fate to entrust this side-show of a side-show, with its 
opportunity of proving or disproving the theory, to an outsider like myself, not quali­
fied technically to make the best of it. I would have given so much to show that Saxe 
was the greatest master of his kind of war, but now all I can say is that we worked by 
his light for two years, and the work stood. This is a pragmatic argument that cannot 
be wholly derided.
Unfortunately our campaigns lacked a historian as much as an executant. Now that 
I try to write down what we did, and why, some of our principles look truisms (man­
kind would so rather believe a sophism) and some look contradictory. The fault must be 
either in my exposition or in my observation. Savage warfare seems never to have been 
thought out in English from the savage point of view, and the Arab revolt would have 
been a great opportunity for a thinker to test its possibilities on a grand scale. Our war 
was so odd and so far away that coy Authority left us to ourselves. We had no base ma­
chinery, no formal staff, no clerks, no government, no telegraphs, no public opinion, no 
troops of British nationality, no honour, no conventions. The experiment was a thrilling 
one, which took all our wits. We believed we would prove irregular war or rebellion 
to be an exact science, and an inevitable success, granted certain factors and if pursued 
along certain lines. We did not prove it, because the war stopped: but here the thesis is: 
It seemed that rebellion must have an unassailable base, something guarded not 
merely from attack, but from the fear of it: such a base as we had in the Red Sea Ports, 
the desert, or in the minds of the men we converted to our creed. It must have a sophisti­
cated alien enemy, in the form of a disciplined army of occupation too small to fulfill the 

The Evolution of a Revolt
308 
The Art and Science of Military Deception
doctrine of acreage: too few to adjust number to space, in order to dominate the whole 
area effectively from fortified posts. It must have a friendly population, not actively 
friendly, but sympathetic to the point of not betraying rebel movements to the enemy. 
Rebellions can be made by 2 percent, active in a striking force, and 98 percent, passively 
sympathetic. The few active rebels must have the qualities of speed and endurance, 
ubiquity and independence of arteries of supply. They must have the technical equip­
ment to destroy or paralyse the enemy’s organized communications, for irregular war 
is fairly Willisen’s definition of strategy, “the study of communication” in its extreme 
degree, of attack where the enemy is not. In fifty words: Granted mobility, security (in 
the form of denying targets to the enemy), time, and doctrine (the idea to convert every 
subject to friendliness), victory will rest with the insurgents, for the algebraical factors 
are in the end decisive, and against them perfections of means and spirit struggle quite 
in vain.

309
C H A P T E R  3 7
The Inherent Vulnerabilities of Technology: 
Insights from the National Training Center’s 
Opposing Force1
Colonel John D. Rosenberger
Colonel Rosenberger was the Chief of Staff of the First Cavalry Division at Ft.Hood 
and the Commander of the 11th Armored Cavalry Regiment (ACR). At the U.S. Army’s 
National Training Center, Rosenberger found that the Red team (OPFOR) could consis­
tently overcome the Blue teams (BLUFOR) high tech systems with low tech camouflage 
and deception measures.  This finding validated what the Serbs did against NATO dur­
ing the Kosovo War in 1999.
1.	
Colonel John D. Rosenberger, “The Inherent Vulnerabilities of Technology: Insights from the National Training 
Center’s Opposing Force,” Speech at the annual USMC Command and Control Symposium, Quantico, Virginia, 
May 2000.

The Inherent Vulnerabilities of Technology: Insights from the National Training Center’s Opposing Force
310 
The Art and Science of Military Deception

 
The Inherent Vulnerabilities of Technology: Insights from the National Training Center’s Opposing Force
The Art and Science of Military Deception	
311

The Inherent Vulnerabilities of Technology: Insights from the National Training Center’s Opposing Force
312 
The Art and Science of Military Deception

 
The Inherent Vulnerabilities of Technology: Insights from the National Training Center’s Opposing Force
The Art and Science of Military Deception	
313


315
C H A P T E R  3 8
Tactical Deception and Strategic Surprise in 
al-Qai’da’s Operations1
Richard H. Shultz, Jr. and Ruth Margolies Beitler
Richard H. Shultz, Jr. is the director of the International Security Studied Program and 
professor of International Politics at the Fletcher School of Law and Diplomacy. Ruth 
Margolies Beitler is a Professor of Comparative Politics in the Department of Social Sci­
ences at the United States Military Academy.
This article accurately portrays al-Qai’da as a nonstate equivalent of a counter­
intelligence (CI) state. It also highlights the time, preparation and foresight necessary 
for strategic surprise.  Finally, it shows how denial and cover protect and ultimately 
enhance military capability. 
1.	
Richard H. Shultz, Jr. and Ruth Margolies Beitler, “Tactical Deception and Strategic Surprise in al-Qai’da’s Opera­
tions,” Middle East Review of International Affairs (MERIA), Vol. 8, No. 2, June 2004, pp. 56–81.

Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
316 
The Art and Science of Military Deception

 
Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
The Art and Science of Military Deception	
317

Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
318 
The Art and Science of Military Deception

 
Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
The Art and Science of Military Deception	
319

Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
320 
The Art and Science of Military Deception

 
Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
The Art and Science of Military Deception	
321

Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
322 
The Art and Science of Military Deception

 
Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
The Art and Science of Military Deception	
323

Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
324 
The Art and Science of Military Deception

 
Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
The Art and Science of Military Deception	
325

Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
326 
The Art and Science of Military Deception

 
Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
The Art and Science of Military Deception	
327

Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
328 
The Art and Science of Military Deception

 
Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
The Art and Science of Military Deception	
329

Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
330 
The Art and Science of Military Deception

 
Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
The Art and Science of Military Deception	
331

Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
332 
The Art and Science of Military Deception

 
Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
The Art and Science of Military Deception	
333

Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
334 
The Art and Science of Military Deception

 
Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
The Art and Science of Military Deception	
335

Tactical Deception and Strategic Surprise in al-Qai’da’s Operations
336 
The Art and Science of Military Deception

337
C H A P T E R  3 9
How Can Weak Powers Win?1
Yang Shaohua
This paper by Yang Shaohua argues that an assymetrical strategy is essential for the 
weak. After a survey of the various Western theory of asymmetric war, the author fo­
cuses on Ivan Arreguín-Toft “How the Weak Win Wars,” (2005), which he rejects as 
having some contradictions.  Then, drawing on other studies (including Arreguín-Toft) 
he constructed a database of 36 cases from the period 1945–2007.  This secondary anal­
ysis showed strong support for Arreguín-Toft’s model of asymmetrically direct-indirect 
strategies.  Indeed, Yang found an even stronger effect in the recent 1945–2007 period 
than Arreguín-Toft found for his long-range 1809–2003 period. Implied for both strong 
and weak actors is that strategies that involve deception can mitigate the asymmetric 
advantages of an opponent. 
Mr. Yang was in Jinggangshan, China, as an assistant professor at the China Execu­
tive Leadership Academy, an official institution of the Chinese Communist Party.
1.	
Yang Shaohua, “How Can Weak Powers Win?” Chinese Journal of International Politics, Vol. 2, No. 3, Summer 
2009, pp. 335-371.

How Can Weak Powers Win?
338 
The Art and Science of Military Deception

 
How Can Weak Powers Win?
The Art and Science of Military Deception	
339

How Can Weak Powers Win?
340 
The Art and Science of Military Deception

 
How Can Weak Powers Win?
The Art and Science of Military Deception	
341

How Can Weak Powers Win?
342 
The Art and Science of Military Deception

 
How Can Weak Powers Win?
The Art and Science of Military Deception	
343

How Can Weak Powers Win?
344 
The Art and Science of Military Deception

 
How Can Weak Powers Win?
The Art and Science of Military Deception	
345

How Can Weak Powers Win?
346 
The Art and Science of Military Deception

 
How Can Weak Powers Win?
The Art and Science of Military Deception	
347

How Can Weak Powers Win?
348 
The Art and Science of Military Deception

 
How Can Weak Powers Win?
The Art and Science of Military Deception	
349

How Can Weak Powers Win?
350 
The Art and Science of Military Deception

 
How Can Weak Powers Win?
The Art and Science of Military Deception	
351

How Can Weak Powers Win?
352 
The Art and Science of Military Deception

 
How Can Weak Powers Win?
The Art and Science of Military Deception	
353

How Can Weak Powers Win?
354 
The Art and Science of Military Deception

 
How Can Weak Powers Win?
The Art and Science of Military Deception	
355

How Can Weak Powers Win?
356 
The Art and Science of Military Deception

 
How Can Weak Powers Win?
The Art and Science of Military Deception	
357

How Can Weak Powers Win?
358 
The Art and Science of Military Deception

 
How Can Weak Powers Win?
The Art and Science of Military Deception	
359

How Can Weak Powers Win?
360 
The Art and Science of Military Deception

 
How Can Weak Powers Win?
The Art and Science of Military Deception	
361

How Can Weak Powers Win?
362 
The Art and Science of Military Deception

 
How Can Weak Powers Win?
The Art and Science of Military Deception	
363

How Can Weak Powers Win?
364 
The Art and Science of Military Deception

 
How Can Weak Powers Win?
The Art and Science of Military Deception	
365

How Can Weak Powers Win?
366 
The Art and Science of Military Deception

 
How Can Weak Powers Win?
The Art and Science of Military Deception	
367

How Can Weak Powers Win?
368 
The Art and Science of Military Deception

 
How Can Weak Powers Win?
The Art and Science of Military Deception	
369

How Can Weak Powers Win?
370 
The Art and Science of Military Deception

 
How Can Weak Powers Win?
The Art and Science of Military Deception	
371

How Can Weak Powers Win?
372 
The Art and Science of Military Deception

373
Section IX: 
Ambush and Counterambush
Introduction
Ambush
Except for sniping and counter-sniping, the ambush would generally be the smallest-
scale, organizationally and logistically simplest, and least complex type of military 
deception operation.  Still, as we’ll see in the following cases, the same sophisticated 
psychological principles that we find in all deception operations are at work from the 
most organizationally complex to the simplest.  The lesson is that deception is truly a 
mind game. 


375
C H A P T E R  4 0
How to Ambush a NATO Fortress1
Commander Jan Berglund, Norwegian Navy
Commander Jan Berglund is a commanding officer in the Norwegian Special Forces.  He 
graduated with his Masters of Science in Defense Analysis from the Naval Postgraduate 
School in Monterey, California.
This case highlights the point that the greater the sense of security, the greater the 
opportunity for surprise. 
Main Circumstances
In 1996, as the commanding officer of the Norwegian Naval Special Forces, I got the as­
signment to test the security and the close defense of one of our National Defense Head­
quarters.  The headquarters (HQ) was a hard target where all the operational functions 
and communications were built deep inside of a mountain.  The facility was designed 
to resist a nuclear attack and was self-sufficient, with water, electricity and food for a 
certain number of weeks.
The close defense was organized in depth, with the outer perimeter’s first gate ap­
proximately one mile from the mountain entrance.  At this checkpoint, cars and buses 
were searched and individuals were checked for identification.  The second gate was 
200 meters inside the tunnel entrance to the facility itself.  Here, an electronic identifi­
cation card would be inserted and matched with a personal pin code.  Some hundred 
more meters inside and behind the massive doors protecting the facilities from a poten­
tial nuclear, biological, and chemical (NBC) attack was an additional post.  This post 
functioned as a surveillance center and a rallying point for military police and sentries 
on duty.  
The defending force during the exercise was a reinforced company-sized security 
force.  That force could be further reinforced by the home guard in case of a crisis or by 
mobilized regulars in case of high tension or war.  The target seemed quite impenetrable, 
and therefore, would require a well-developed deception plan to infiltrate even a single 
commando, much less a whole team.  Forced entry was not considered a viable option.  
However, even if a clandestine infiltration succeeded, another problem remained: how 
could they smuggle in enough equipment, weapons, and explosives to inflict substantial 
material damage?  
After a considerable planning period, we developed three courses of actions (COAs) 
that seemed feasible.  In order of priority, they were: 
1.	
Commander Jan Berglund, Norwegian Navy, “How to Ambush a NATO Fortress,” research paper, Department of 
Defense Analysis, Naval Postgraduate School, 1996.

How to Ambush a NATO Fortress
376 
The Art and Science of Military Deception
••
Blow up one or more of the four shuttle buses that brought people to work every 
morning (classical ambush).  
••
Get one or more men inside and inflict critical damage to either the computer/
communication section or assassinate the Commander and the command group 
(deception entry). 
••
Attack the power supply, antennas, and water supply cables leading into the moun­
tain (classical commando raid).   
To give the opposing force the most training value, all three COAs were executed.  
However, I would have realistically preferred the first or second alternative.  In the fol­
lowing account I will focus on the first COA, the ambush. 
Prior to the ambush, a team of four men conducted close reconnaissance for several 
days.  The reconnaissance was done both clandestinely and overtly.  Clandestinely by 
patrolling the terrain in order to find the best spot to attack the buses along a 20 km 
route from the city.  A 24 hour observation post (OP) was also established from a secure 
distance to monitor the bus and car arrivals, including their regularity and punctuality.  
Overtly, the reconnaissance team dressed like civilians and drove or jogged by the facil­
ity to get detailed information about the first checkpoint. 
The ambush was to take place 300 meters in front of the checkpoint.  At this par­
ticular point, the buses had to slow down to 5–10 mph because of a narrow bridge 
followed by a 90-degree curve.  In addition, our reconnaissance observed that the buses 
often queued at this point since they tended to arrive almost at the same time.  Our main 
objective was to take out at least one of the buses.  Normally, about half of the employ­
ees, officers and civilians, would arrive at the HQ by bus.  The other half arrived in their 
own cars.  The assumption was that if we took out 50 to 100 people in one blow, some 
key persons would be included, which in turn would hamper ongoing operations inside 
the HQ.  Many of these individuals were high-ranking officers or highly specialized 
technicians.  Consequently, the loss would be considerable and not easily replaceable.  
We also identified four flag officer vehicles that arrived predictably every morning with 
the Commander and his deputies from the Army, Navy, and Air Force.  Although they 
all seemed like tempting and easy targets, we decided to prioritize the buses and take 
the flag officers with snipers if we had the opportunity.  Of the four buses, two were 
more important than the others because they arrived from downtown where we knew 
that most of the key personnel would embark.  These buses were also more crowded.  
In addition to the deception supporting the reconnaissance, we had to place three 
dummy 12-kilogram claymore mines and hide them until the ambush.  It was consid­
ered a risky operation in itself because it was only 300 meters from the checkpoint, and 
security forces frequently patrolled the area.  The team, dressed in camouflage uniforms 
placed the mines the night before. 
The mines were effectively camouflaged close to the road.  Close passing security 
patrols never detected them during the morning hours.  Attached to the dummies were 
a small pyrotechnic devices that would simulate detonation and provide some smoke.  
The detonation device was remotely controlled by radio and set off from the main OP, 
which had a perfect view overlooking the target.  The remote control device provided 
for perfect timing, flexibility, and security for the ambushers. 
In the morning, the ambushers (now in the main OP) got the word by radio from 
a forward OP of the sequence in which the buses would arrive.  When the target bus 

 
How to Ambush a NATO Fortress
The Art and Science of Military Deception	
377
passed the claymores at low speed, the first and second claymore went off as planned.  
The third was detonated immediately after, probably inflicting damage to the trailering 
bus.  The four flag officers were not targeted because they had already entered the facil­
ity and an attempt on them would have compromised the main attack.  
In my view the ambush was successful because: 
The security forces never anticipated the chosen COA.  Hence, they were taken by sur­
prise.  They had limited their responsibility to the immediate fence perimeter and physi­
cal facilities.  Consequently, they forgot that their “humanware” can be just as valuable 
as their hardware as demonstrated by the loss of 50–100 people in one single, simple 
blow.  Tactical deception worked.  The group successfully masked their reconnaissance 
by traditional means of camouflage and stealthy movement under the cover of darkness.
Additionally, the reconnaissance force mimicked passing civilians without drawing 
attention.  The mine emplacement was also masked successfully, blending the three 12 
kg claymore mines into the terrain.  The security forces had the illusion of control.  The 
mines were placed within their security perimeters, right in front of their noses, just a 
few meters from the checkpoint.  To them, the situation seemed normal until the blast.  
What could the ambushers have done better? 
They could have synchronized the operations better and taken out multiple targets, such 
as the flag officer vehicles and more buses. Other simulation techniques like decoying 
could have been tried to create a traffic jam for the arriving buses and cars.  
What could the ambushed victims have done better?
••
They could have planned better by wargaming against clandestine attacks.
••
They could have avoided falling prey to routines and driving patterns  
••
They could have expanded their security responsibility to the time the buses leave 
their garages  
••
Time bombs could easily have been planted on the buses even before any passengers 
embarked. They could have checked for the buses daily prior to use.
••
They could have looked for the unnatural—civilians could have been randomly 
stopped for a closer check.  
••
The terrain could have been examined more closely. 
••
They could have familiarized themselves with their own environmental conditions.  
Security forces often restrict themselves to roads and paths, especially in the dark.
••
They could have added more sensors (IR, thermic ray cameras, movement sensors, 
etc.) to supplement the human sensors.  
••
They could have established barriers (such as obstacles, minefields, or booby traps) 
to canalize any assaulting enemy force.  
What lessons were learned? 
The important lesson is that there often is an alternate indirect approach to a problem 
if one spends enough time looking for one.  In this case, a direct attack or a single small 
group penetration into the HQ would have been very risky, maybe suicidal.  In addition, 

How to Ambush a NATO Fortress
378 
The Art and Science of Military Deception
the result or effect of this COA is difficult to estimate because it is likely the attack 
would be uncovered before completion. 
Another important lesson is the importance of stealth in order to achieve surprise.  
Camouflage, environment blending, and slow movements are crucial.  Leaving the im­
pression that everything is normal until the last crucial moment is one of the key factors 
for success.  However, once surprise is lost it must be compensated for by speed. 

379
C H A P T E R  4 1
High Desert Ambush: Hard Lessons Learned the 
Hard Way1
LTC (Ret) Lester W. Grau
“Les” Grau, a specialist in Russian military strategy and tactics, retired from the U.S. 
Army with the rank of lieutenant colonel sometime shortly after 1992 while assigned 
to the staff of the Foreign Military Studies Office at Ft. Leavenworth, Kansas. There he 
remained through the publication of this article.
For the perspective of the Mujahideen & Taliban as ambusherers of Soviet forces see 
Ali Ahmed Jalali & Lester W. Grau, “The Other Side of the Mountain: Mujahideen Tac­
tics in the Soviet-Afghan War,” Quantico, VA: U.S. Marine Corps, Studies and Analysis 
Division, 1999.
Afghanistan is not Europe, yet the Soviet Army that occupied Afghanistan in late De­
cember 1979 was trained to fight NATO on the northern European plain. Consequently, 
the Soviet Army had to reequip, reform and retrain on-site to fight the insurgent mu­
jahideen [holy warrior] guerrillas. The Soviets were forced to revise their tactics and 
tactical methodologies in order to meet the demands of this very different war. One of 
the tactical areas which the Soviets thoroughly revised was the conduct of ambushes. 
The Soviets planned to use ambushes in the European theater, but they were primarily 
ambushes against attacking or withdrawing NATO armored columns. The Soviets con­
structed most of their ambushes around tanks and tank units. They planned to employ 
concealed individual tanks, tank platoons and tank companies along high-speed avenues 
of approach or withdrawal to engage the enemy from the flank and then to depart. Such 
ambushes were part of security zone defensive planning as well as planning for the deep 
battle and pursuit. The Soviets also trained their squad and platoon-sized reconnais­
sance elements to conduct dismounted ambushes to capture prisoners and documents. 
They employed a command element, a snatch group and a fire support group in these 
small-scale ambushes.
In Afghanistan, the Mujahideen seldom used armored vehicles and seldom ad­
vanced along high-speed avenues of approach. Instead, they infiltrated light-infantry 
forces through some of the most inhospitable terrain on the planet to mass for an attack 
or ambush. The Soviets soon discovered that they had difficulty maintaining control 
of the limited road network which constituted the Soviet lines of communication. The 
guerrillas constantly cut the roads and ambushed convoys carrying material from the 
Soviet Union to the base camps and cities in Afghanistan. The Soviet ability to maintain 
1.	
Lieutenant Colonel (Ret) Lester W. Grau, “High Desert Ambush: Hard Lessons Learned the Hard Way,” Red 
Thrust Star, 3 Parts: July, 1995; October, 1995; and October, 1996.  [Excerpts of introduction and conclusion].

High Desert Ambush: Hard Lessons Learned the Hard Way
380 
The Art and Science of Military Deception
its presence in the country depended on its ability to keep the roads open and much 
of the Soviet combat was a fight for control of the road network. During the war, 
the guerrillas destroyed over 11,000 Soviet trucks (and reportedly even more Afghan 
trucks) through ambush. The Soviets learned from Mujahideen ambushes and used the 
ambush to interdict the guerrilla supplies coming from Pakistan and Iran. The Soviets 
conducted ambushes mainly with reconnaissance and other special troops (airborne, 
air assault, spetsnaz and elements from the two separate motorized rifle brigades which 
were designed as counter-guerrilla forces). The composition and employment of am­
bush forces differed with the units involved and the part of Afghanistan in which they 
were employed.
Contemporary Issues
Since the war, the Russian army has studied their ambush experience in Afghanistan.
As Russian forces continue to serve on the Tadjikistan/Afghanistan border, in 
Chechnya and other mountainous areas, the high-desert ground ambush remains a valid 
tactic for Russian ground forces. Recently, the Russian military press began debating the 
proper size and composition of an ambush force. The debate questions the exclusive use 
of reconnaissance and special troops to conduct dismounted ambushes. According to 
some Russian professionals, ambush forces should be constituted not only from recon­
naissance troops, but also from motorized rifle, tank, antitank, artillery, flamethrower, 
helicopter aviation, fixed-wing aviation, antiaircraft, chemical, electronic, engineer and, 
in the future, combat robot troops. Ambushes can be antitank, anti-personnel, anti-air, 
anti-landing, reconnaissance, phoney and special (electronic, chemical, engineer and 
combat robots).
The Russians have taken the following lessons from their Afghanistan experience:
First, the ambushing force sometimes encounters a much larger force than antici­
pated. To avoid disaster, the ambushing force must be able to disengage quickly and 
withdraw. All ambush sites require local security to prevent the ambushing force from 
being surprised.
Second, weapons systems present in platoon and company ambushes are usually re­
stricted to the organic equipment of that unit. Supplemental tanks, IFVs, self-propelled 
artillery and self-propelled air-defense guns can usually be incorporated into these am­
bush sites and hidden from enemy reconnaissance. The effect of the surprise fires of 
these weapons systems at close range can be devastating on an enemy force in the am­
bush kill zone.
Third, aviation and artillery planning and close coordination are essential for suc­
cessful ambush execution. Artillery forward observers and forward air controllers 
should be included in ambush sites where they can bring increased destruction on the 
enemy and provide necessary cover during the disengagement and withdrawal of the 
ambush force. High-precision munitions should be used in support of an ambush.
Fourth, ambush forces need to be able to extricate themselves from encounters with 
larger enemy forces and to avoid counter-ambush while they withdraw. Bronegruppa 
(armored groups) can be incorporated on the flanks of the ambush where their weapons 
systems can contribute to the deadliness of the ambush. Further, bronegruppa can be 
located forward of the ambush in a security zone. From these forward positions, bro­
negruppa can engage the enemy and then withdraw, pulling the enemy force into the 

 
High Desert Ambush: Hard Lessons Learned the Hard Way
The Art and Science of Military Deception	
381
ambush kill zone. The principal function of the bronegruppa in the ambush, however, is 
to provide for the quick, safe withdrawal of the ambush force.
Fifth, the Russians studied the mujahideen ambushes (Figure 1). They characterized 
mujahideen ambushes as having three components in addition to the command group 
— a diversionary group, a combat group and a snatch group. The diversionary group 
sealed the exit of the ambush with barricades, rockslides and minefields. The diversion­
ary group would open fire when the Soviet force attempted to clear the obstacle. The 
Soviet attention would be focused on this diversionary group and the traffic would 
stack up in the kill zone behind the obstacle. Then, the combat group would open up 
on the stationary force in the kill zone. The snatch group would move forward to grab 
prisoners, documents, weapons and munitions. The ambush force would then withdraw 
over secured paths and roads.
Soviet soldiers caught in an ambush zone would try to drive out of the kill zone. If 
they could not move, soldiers would usually dismount the personnel carriers and shelter 
behind the carriers. A favorite mujahideen technique was to plant directional mines 
(claymore-type) on the opposite side of the road facing into the ambush. When the sol­
diers would shelter behind the carriers, the mujahideen would detonate the directional 
mines and kill the sheltering soldiers.
The Russians see a place for new technology in the ambush. Infrared sights and 
viewer, combat robots, remote-controlled weapons and sensors can be used. Scatterable 
mines, helicopter mobile obstacle construction detachments and controlled minefields 
Figure 1  The Mujahideen ambushes

High Desert Ambush: Hard Lessons Learned the Hard Way
382 
The Art and Science of Military Deception
can fix the enemy in place while artillery, close air support and remotely piloted vehicles 
destroy the enemy.
For the more immediate future, the Russians have been studying the United States 
Army experience in Vietnam and, based on their studies, have proposed the creation 
and training of combat strike groups [udarno-boevaya gruppa-UBG]. These are three or 
four man teams armed with automatic weapons with silencers, portable anti-tank gre­
nade launchers, mines and radios. Up to 18 UBGs could be trained in a company and up 
to 54 UBGs could be trained in a motorized rifle battalion. UBGs would operate at night 
on enemy-occupied territory—such as the security zone—once the enemy has crossed 
it. UBGs would set up and change ambush sites two or three times a night and destroy 
enemy personnel and equipment. In order to increase their survivability, a network 
of bunkers with stores of ammunition, explosives, food, communications equipment, 
medicine could be set up in advance. The UBGs could also use these bunkers to rest in 
during the day. This is a significant departure from Afghanistan where the Soviets only 
deployed large ambush forces and only against hard intelligence.
In conclusion, the Russians are reviewing their Afghanistan ambush experience and 
trying to adapt it to their present situation and future wars. Many of their ideas seem 
relevant to other modern armies who may fight in high desert or in a counter-guerrilla 
role.

383
C H A P T E R  4 2
A Modern Day “Trojan Horse”—Operation 
JAQUE and the Use of Stratagem in a Hostage 
Rescue Operation1
Colonel Greg Wilson, US Army
The U.S. Military has been training, advising, and equipping the Colombian Armed 
Forces for decades. Interestingly, while the fruits of these long-term investments were 
clearly on display during operations designed to pressure the FARC hostage-holding 
network, nothing about these efforts helped to prepare the Colombians to develop the 
type of stratagem used in Operation JAQUE. This is a case where the student clearly 
became the teacher. 
Colonel Greg R. Wilson graduated from the United States Military Academy in 
1985. He completed Special Forces qualification and training in 1989 and since then 
has served in variety of Special Operations assignments from the tactical to strategic 
levels. COL Wilson served as the SOC Forward, Colombia, Commander and senior 
U.S. military advisor to the U.S. Ambassador and Colombian Special Operations forces 
during the planning and execution Operation JAQUE.
On 2 July 2008 Colombian Commandos surprised the world by executing one of 
the most complex and audacious hostage rescue missions in thirty years—Operation 
JAQUE, or “Check.” Without firing a shot, twelve unarmed Colombian Commandos 
rescued three Americans along with Ingrid Betancourt2 and eleven Colombian hostages, 
held prisoner by the FARC for over five and a half years. However, this was not a stereo-
typical hostage rescue operation built around the surgical application of force. Instead, it 
relied on a cunning deception plan that tricked the FARC into handing over the hostages 
to the Colombian government by creating a modern-day Trojan Horse. The operation 
delivered a devastating blow to the FARC by removing its high-value political prisoners, 
or “crown jewels,” representing one of its few political bargaining chips remaining in 
their 40-year struggle against the Colombian Government. It also represents a successful 
model for US security assistance as well as a tangible return on long-term U.S. invest­
ment in Colombia and its defense forces. AMB William Brownfield made this point 
when he said, “Colombia represents the most successful U.S. nation building effort in 
the past 40 years.”
1.	
Colonel Gregory Wilson, US Army, Special Forces, “Operation JAQUE and the Use of Stratagem in a Hostage 
Rescue Operation,” (Naval Postgraduate School, 2013). 
2.	
Ingrid Betancourt Pulecio is a Colombian politician, former senator and anti-corruption activist. Betancourt was 
kidnapped by the Revolutionary Armed Forces of Colombia on 23 February 2002.

A Modern Day “Trojan Horse”—Operation JAQUE and the Use of Stratagem in a Hostage Rescue Operation
384 
The Art and Science of Military Deception
This chapter provides an insider’s view into the campaign planning and execution 
of Operation Willing Spirit (OWS). It includes both U.S. advisory efforts and planning 
efforts designed to pressure the FARC hostage holding network and the Colombian 
rescue operation named Operation JAQUE. However, before we examine the details 
leading up to the events of 2 July 2008, it is important to note that this successful mili­
tary deception and rescue operation cannot be viewed as a discrete event. Countless 
individuals and organizations in Colombia and the U.S. devoted time and resources to 
what became both a labor of love and a source of frustration for many—the safe return 
of Tom Howe, Marc Gonzales, and Keith Stansell.
The U.S. hostage crisis began on 13 Feb 2003 when three U.S. government contrac­
tors were captured while flying a counternarcotic spray mission over the remote jungles 
of Colombia, and disappeared into the FARC hostage holding network. Their light, 
single engine aircraft experienced a mechanical problem and crash landed in the remote 
jungles of Southern Colombia. Initial efforts to locate the hostages proved unsuccessful 
as the dense and isolated Colombia jungle seemed to swallow the plane and its crew. The 
survivors of the crash had entered the sophisticated FARC hostage-holding network3. 
From its inception, hostage taking has been part of the FARC’s strategy. Most have 
been low-level kidnap-for-ransom operations designed to generate money for its activi­
ties. However, taking political hostages seemed to offer additional leverage as demon­
strated by the kidnapping of Ingrid Betancourt in 2002 and the U.S. hostages in 2003. 
To protect these valuable assets, the FARC developed a sophisticated hostage-holding 
network. This network consists of a series of camps geographically dispersed through­
out the remote jungles of Southern Colombia, hidden beneath triple canopy foliage 
making it very difficult to identify. The network is quite vast and once Colombian de­
fense forces apply pressure near a hostage holding camp, the FARC simply picks up 
the hostages and moves them to another remote camp. Security at camps is extensive 
3.	
 Colombians aboard the aircraft were executed at the crash site.
Figure 1  U.S. Hostages after rescue by Colombian Commandos.

 
A Modern Day “Trojan Horse”—Operation JAQUE and the Use of Stratagem in a Hostage Rescue Operation
The Art and Science of Military Deception	
385
and often consists of multiple rings of security around the site. Hostages are typically 
chained together and held in the center of the camp, housed in pens, with armed guards 
instructed to execute the hostages if there is a rescue attempt. The inability to locate the 
U.S. hostages and disrupt the FARC hostage holding network resulted in this being one 
of the longest hostage crises in U.S. history. 
Operation Willing Spirit
The U.S. government was initially slow to react to the unfolding hostage crisis with the 
military lacking proper authorities to act until the inception of Operation Willing Spirit 
in May of 2005. Operation Willing Spirit (OWS) represented the U.S. Government’s 
effort to safely recover the hostages. Department of Defense (DoD) efforts in support 
of OWS fell under the responsibility of U.S. Southern Command (SOUTHCOM) who 
designated Special Operation Command South (SOCSOUTH), a sub-unified command, 
to lead all DoD planning and hostage recovery efforts. Operation Willing Spirit played 
a key role in building the foundation for the rescue mission, called operation JAQUE. 
The mission centered around three lines of effort: building Colombian military capacity, 
campaign planning, and Colombian and U.S. Special Operation Forces (USSOF) efforts 
designed to stress the FARC hostage holding network. Operation Willing Spirit also re­
sulted in the deepening of relationships between U.S. and Colombian Special Operations 
Forces. These relationships intensified overtime and resulted in a level of transparency, 
integration and partnership seldom achieved between foreign military forces4.
Partnership—U.S. and Colombian Special Operational Forces 
Colombia and the United States share a strategic partnership that is very strong and 
dates back to the Korean War. Colombian forces served alongside the U.S. forces in 
Korea and won a Presidential Unit Citation as part of the UN effort to repel the com­
munist Chinese.5 USSOF military capacity building efforts in Colombia go back more 
than 30 years. General Yarborough, then Commander of the Special Warfare Center and 
School, led an assessment team to Bogota in 1959 to advise and assist the Colombians 
in developing a counterinsurgency strategy and a military training plan.6 Early efforts 
included building Colombian conventional capabilities to thwart an ongoing insurgency. 
USSOF played an important role in helping to professionalize the Colombian defense 
forces by establishing the Lancero Course, a small unit leader’s course modeled after 
the U.S. Army Ranger School.7 Additional USSOF efforts included assistance in training 
Colombian Mobile Brigades and Counter-guerrilla units that have proven to be highly 
effective in operations against the FARC.  
“Plan Colombia”, implemented in 1999, authorized additional funding and re­
sources for Colombia. Mobility was a critical shortfall and this new plan provided U.S. 
helicopters to the Colombian air force. These assets allow Colombian forces to reach 
the FARC in the remote jungle areas. SOF advisory teams helped these forces plan 
operations and perfect helicopter insertion, extraction and resupply techniques. These 
4.	
 Author’s first-hand account.
5.	
 Barbula and Old Baldy, March 1953, Charles H. Briscoe Veritas, ARSOF in Colombia, pg 15.
6.	
 Plan Lazo, Evaluation and Execution, Charles H. Briscoe Veritas, ARSOF in Colombia, pg 38–39.
7.	
 Colombian Lancero School Roots, Charles H. Briscoe Veritas, ARSOF in Colombia, pg 30.

A Modern Day “Trojan Horse”—Operation JAQUE and the Use of Stratagem in a Hostage Rescue Operation
386 
The Art and Science of Military Deception
techniques coupled with President Uribe’s counterinsurgency policy allowed Colombian 
forces to regain control of much of the countryside previously controlled by the FARC.
In 2001, USSOF capacity building efforts shifted focus to the development of Co­
lombian Special Operations Forces (COLSOF). With USSOF assistance, the Colombian 
defense forces developed their own special operations forces with expertise in jungle 
warfare and direct action missions. During 2002, the CCOPE8 was established as the 
Colombian national mission force and quickly became their premier unit for going after 
the FARC leadership and conducting hostage rescue operations. These long-term invest­
ments were crucial to the success of this rescue operation.
Operation Willing Spirit Campaign Planning 
In February 2003, U.S. priority began shifting to the recovery of the hostages. Efforts 
include establishing an aggressive psychological warfare program designed to pressure 
the FARC by encouraging defections through the rewards for justice program and accu­
mulating actionable intelligence on the hostage-holding network. In May 2005, USSOF 
were finally given the official go-ahead to support hostage recovery efforts in support of 
Operation Willing Spirit. 
Gaining knowledge about the FARC hostage-holding network was deemed critical 
to the planning and execution of a hostage rescue operation. FARC hostage holding 
camps are typically located in remote jungle areas under triple canopy foliage, so gain­
ing detailed information is very difficult. Site reconnaissance and exploitation assisted 
in acquiring the needed intelligence by allowing specially trained USSOF teams to visit 
abandoned FARC hostage holding camps to gather evidence that the hostages were 
alive and to develop a better understanding of the FARC’s hostage holding network. 
Additionally, developing the ability to conduct combined U.S. and Colombian spe­
cial operations greatly expanded military options available to the planners. Training, 
equipping and advisory efforts, under OWS authorities, greatly enhanced the CCOPE’s 
ability to conduct long-range reconnaissance and sustained operations designed to 
stress the FARC hostage holding network. Combined rehearsals during training events 
allowed SOCSOUTH and CCOPE staffs to develop integrated staff procedures in the 
event a combined operation was deemed appropriate. At the tactical level a combined 
reconnaissance capability was developed to facilitate U.S. and Colombian reconnais­
sance on suspected hostage holding camps. 
Combined planning and operations required detailed coordination by U.S. and Co­
lombian SOF as well as the interagency within the respective governments.  The OWS 
Campaign Plan and Playbook were developed to codify procedures and provide a menu 
of U.S. capabilities to support a variety of hostage rescue option. These options in­
cluded a unilateral U.S. military operation, a combined US/Colombian operation and a 
unilateral Colombian option. The OWS Playbook allowed SOCSOUTH to synchronize 
efforts and make possible the quick and efficient flow of U.S. support assets into Co­
lombia. It also provided key decision makers in the Interagency, U.S. and GOC a com­
mon framework which served to facilitate decision making as new intelligence altered 
the operational picture.
8.	
 COMANDO COJUNTO DE OPERACIONES ESPECIALES or Joint Special Operations Command.

 
A Modern Day “Trojan Horse”—Operation JAQUE and the Use of Stratagem in a Hostage Rescue Operation
The Art and Science of Military Deception	
387
As Operation Willing Spirit planning and operational capacity was improving, 
Colombian Defense Force’s were achieving unprecedented success against the FARC. 
President’s Uribe’s democratic security strategy was starting to take hold through suc­
cessful targeting of FARC leadership and counterinsurgency operations to reclaim large 
portions of the countryside. In late 2007, the Colombian military was finally ready to 
mount a campaign to pressure the hostage holding network. As a result of this cam­
paign, it became clear that the FARC 1st Front was holding the high value hostages. By 
January 2008, the sustained pressure against the 1st Front forced the need to transfer the 
hostages to the Yari Front for safe keeping. 
The Reconnaissance Plan and Operation Ellipse
All told, the hostages would move 276 miles from January to July 2008 on remote riv­
ers and through dense jungle trails before arriving at the location where they would 
ultimately be rescued. The movement of the hostages opened the door to increased 
surveillance and reconnaissance and created a significant vulnerability for the FARC. 
The hostages were being moved on foot and along a series of rivers in small indigenous 
boats. They remained chained and under tarps to minimize detection. But slowly, infor­
mation about the hostages began to emerge and Colombian SOF planners and U.S. ad­
visors developed a reconnaissance plan focused on the Apaporis River Valley. This plan 
included the emplacement of motion detection sensors along a series of rapids. Planners 
determined the hostages would have to disembark their small boats to negotiate the 
rapids at one particular location, one of the only places on the river where observing the 
hostages could be possible. 
With reconnaissance efforts underway, planners shifted focus to developing rescue 
options. Minimizing the risk to hostages was key. Accordingly, a jungle rescue opera­
tion against a mobile target was deemed too dangerous. This forced planners to develop 
a different approach which came to be known as the Cordon Strategy and was named 
Figure 2   Map of Hostage Movement Corridor.

A Modern Day “Trojan Horse”—Operation JAQUE and the Use of Stratagem in a Hostage Rescue Operation
388 
The Art and Science of Military Deception
Operation Ellipse. Once the location of the hostages was identified, Operation Ellipse 
called for establishing a security zone around the site to facilitate negotiations with the 
FARC for the safe release of the hostages. This concept was preferable to mounting a 
high-risk, direct action rescue attempt. 
The cordon strategy called for a careful combination of both physical and psycho­
logical isolation. The plan relied heavy on an influence component that included psy­
chological profiling of the FARC leadership. Psychological profiles were developed and 
used to predict how the FARC would react to the cordon. These profiles revealed that 
the top FARC leadership was hardcore and would never negotiate. However, if isolated 
from their higher command, the mid-level FARC leaders holding the hostages were 
deemed to be vulnerable and likely to negotiate. 
Once isolated and completely cut-off from the FARC leadership, the Colombians 
would establish communications and offer the hostage holders an incentive in exchange 
for the hostages. Interagency and intergovernmental coordination was critical to this 
aspect of the plan. An FBI hostage negotiation team travelled to Bogota to train the 
Colombian negotiators. Planners also coordinated with the Colombian High Commis­
sioner of Peace who was in charge of the negotiation team. Additionally, a communica­
tions system was put in place to facilitate decision making for Colombia’s leadership. 
While planning continued, the reconnaissance teams were patrolling the Apaporis 
river valley positioning themselves at key locations along the riverbanks. They had lim­
ited fields of view and while observing boat traffic was easy, identifying the hostages 
chained and under tarp in a moving boat would be difficult. Fortunately, persistence 
paid off when a Colombian reconnaissance team found the “needle in the haystack” 
when in mid-February they actually spotted the hostages bathing on the Apaporis River. 
This was the first time they had been observed since their capture. 
Now Operation Ellipse swung into full motion with Colombian SOF accompanied 
by U.S. advisors moving rapidly by helicopter to positions on the northern and south­
ern sides of the hostage site. The forces landed 15 kilometers from the hostage site to 
minimize the risk of detection. The cordon force’s movement was very slow due to the 
difficult jungle terrain. Unfortunately, the FARC and their precious cargo slipped out of 
the noose just hours prior to the final positioning of the cordon forces. 
Operation Ellipse transitioned into a pursuit operation with cordon forces moving 
great distances on foot up the Apaporis River valley attempting to encircle the hos­
tages at two other locations. As they approached Dos Rios, it became apparent that 
the hostages could slip undetected into the Yari Front and it would be very difficult to 
re-acquire them. To counter this, the decision was made to conduct a series of overt 
Colombian troop insertions in and around the Dos Rios area to discourage further 
movement west. The idea was to flood the zone with helicopters and troops to turn the 
FARC back. 
With Colombian forces losing the element of surprise, the FARC altered their stan­
dard procedures by dividing the hostages into three separate groups and melted into 
the jungle. The trail went cold in March but the Colombian Special Forces continued 
operations to pressure the FARC and attempt to reacquire the hostage trail. 
Problems From Within
With the hostage trail going cold, pressure on the FARC leadership network was in­
creasing. On 1 March, the Colombian’s killed Raul Reyes in a cross border raid into 

 
A Modern Day “Trojan Horse”—Operation JAQUE and the Use of Stratagem in a Hostage Rescue Operation
The Art and Science of Military Deception	
389
Ecuador. Raul Reyes was a member of the FARC Secretariat and in charge of the FARC’s 
International front. Mono JoyJoy, the FARC’s top military commander, was also under 
intense military pressure and out of communications with the FARC’s leadership. In fact, 
Colombian intelligence had been able to establish that the guerrilla leader guarding the 
hostages, Cesar, had not been in direct contact with the high command of Mono Jojoy 
for over three years. There also was a power struggle within the ranks of the FARC since 
the death of Manuel tirofijo Marulanda, the FARC top leader. It had been said that the 
military leader, Mono Jojoy, was unhappy when political strategist Alfonso Cano was 
chosen to succeed Marulanda. 
Cracking the FARC Communication Codes 
As pressure on the FARC leadership network intensifed, Colombian intelligence efforts 
to infiltrate the FARC communication network moved into high gear. Collecting in­
telligence for this operation began long before it was actually carried out. Defectors 
and former guerrillas provided pieces of the puzzle. These defectors came out of the 
jungle periodically from 2003-08. Former FARC hostage (1998-2007), Policeman Frank 
Pinchao, escaped in May 2007, 14 months prior to the July 2008 mission. Pinchao 
provided excellent information on the FARC routine. Frank had lived with Ingrid Be­
tancourt and the three U.S. captives.9 A critical development were laptops, seized in the 
cross border raid into Ecuador to kill Raul Reyes, that revealed some of the FARC’s 
darkest secrets and information vitial to understanding their operations and communi­
cations networks. Armed with this intelligence, some innovative Colombian intelligence 
professionals hatched a scheme to insert themselves into the FARC communication net­
work. This was the key to JAQUE and was only possible after 20 years of studying 
FARC communications procedures and vulnerabilities.  
During a scheduled change of frequencies and encryption codes, the Colombians 
successfully inserted themselves as the radio operators for two senior FARC leaders, 
Mono Jojoy and Cesar. This required identifying individuals with the same voice tones 
and accents to impersonate the FARC radio operators. Remotes jungle sites were also 
constructed to replicate the conditions under which the messages would be transmitted 
to duplicate background ambient noise. The imposter operators entered the FARC com­
munications network and slowly tested their ability to deceive the FARC leadership. 
Up to this point, the government of Colombia had to rely on traditional intelligence 
sources like communications intercepts and jungle reconnaissance to glean information 
on the hostages. This new capability allowed the GOC to manipulate the FARC chain 
of command and actually issue orders about what to do with the hostages. This was a 
total game changer. 
Operation JAQUE—“Check”
On June 26, the Colombians presented the deception and rescue concept to the U.S. 
Government. During the meeting, a bold and decisive deception operation was outlined 
that would essentially trick the FARC into unwittingly handing over the hostages to the 
Colombian government. In it simplest form, the Colombians were preparing a force to 
9.	
 Interview with Kevin Higgins, U.S. advisor to the GOC from 1999-2011.

A Modern Day “Trojan Horse”—Operation JAQUE and the Use of Stratagem in a Hostage Rescue Operation
390 
The Art and Science of Military Deception
act as a fictitious International Organization, that would go deep into FARC controlled 
territory, unarmed and pick up the hostages using civilian helicopters, and transport 
them to freedom. But the devil was in the details. 
The plan called for the Colombians to leverage their capability to infiltrate the 
FARC’s communications network and send radio messages directing Cesar, the FARC 
1st Front Commander, to prepare the hostages for transport to another FARC-controlled 
area that was currently not under Colombian military pressure. The Colombians would 
assume full responsibility for the operation and the President of Colombia had ap­
proved the plan the day prior. They also acknowledged the risk—worst case the Colom­
bians would lose a helicopter and 13 additional hostages to the FARC. The Colombian’s 
emphasized the need to act quickly as delay would increase the chance that the FARC 
would discover the deception plan. 
The initial U.S. reaction to this plan was skeptical at best. But as time passed and 
the details on the plan became known, it was clear that it had tremendous potential. 
The rescue team was carefully selected from volunteers who knew this was potentially 
a one-way trip. Team members included various ethnicities to replicate an international 
organization and everyone received acting classes in preparation for their roles. The de­
ception included the construction of a web site to backstop the international organiza­
tion and detailed preparation of the government MI-17 helicopters to look authentically 
civilian.  
Deception operations rely heavily on the enemy’s perception of the current envi­
ronment and for this operation anything out of the ordinary would risk compromise. 
To reduce the possibility of compromising the operation, the U.S. support signature in 
Colombia had to be minimized. Surprise was deemed critical and any spike in U.S. pres­
ence could tip off the FARC and spoil the rescue attempt. Accordingly, the decision was 
made to primarily leverage the existing USSOF advisory effort in country to support the 
mission. 
The stratagem called for the FARC rebels to hand over the hostages to Colombian 
soldiers posing as members of a fictitious nongovernment organization that supposedly 
would fly the captives to another FARC camp to meet rebel leader Alfonso Cano. Sol­
diers would impersonate cameramen, a journalist from a Latin American TV station, 
two would pose as guerilla fighters and four troops would dress as aid workers. Several 
aspects of the mission were designed to mimic a previous Venezuelan hostage transfer, 
including the actual composition of the group, type of helicopters used and a location 
near the previous transfer spot. In case of mission compromise or failure, Colombian 
and U.S. planners had prepared an armada of over 20 helicopters to ferry approxi­
mately 400 troops and U.S. advisors, in less than 15 minutes, to cordon off the rescue 
location and force the FARC to negotiate a hostage release or suffer the consequences. 
The GOC selected July 2, 2008 for the rescue. Despite all the careful preparation, 
the operation did not begin well. Throughout the morning a thunderstorm between Bo­
gota and the pick-up location prevented transmission of the final instructions to Cesar 
to assemble the hostages and move them to the pick-up location. Finally, around noon, 
the message went thru, and the rescue operation sprung into full motion with the heli­
copters taking off to the selected pick-up location. 
Around 1 PM, one Mi-17 helicopter landed at the FARC pick-up location in the 
Guaviare district of Colombia. Once on scene, Colombian agents wearing Che Guevara 
T-shirts linked up with FARC security and arranged to transfer the hostages. The hos­
tages were flex cuffed and loaded aboard. Cesar, previously invited to come, escorted 

 
A Modern Day “Trojan Horse”—Operation JAQUE and the Use of Stratagem in a Hostage Rescue Operation
The Art and Science of Military Deception	
391
the hostages in anticipation of meeting with the new FARC Leader, Alfonso Cano, at 
the transfer destination. Cesar along with an additional rebel were persuaded to hand 
over their pistols and were quickly subdued after the helicopters took off by Colombian 
forces. The hostagess were told: “Somos el Ejército Nacional. ¡Ustedes están en liber­
tad!” We are the national army. You are free!
After 22 minutes the radio transmission verified that helicopters had taken off 
and the hostages were secure.  Twenty minutes later the MI-17 touched down in a se­
cure landing zone. The unbelievable had just happen—the hostages were free and the 
FARC 1st Front Leadership was captured, all without firing a shot. The Colombians 
had planned and executed one of the most complex and audacious special operations 
mission in recent time. 
Conclusions
Deception is often enabled by a technical component or capability. The Colombian’s 
carefully developed this capability through studying FARC communications for over 20 
years and exploiting its vulnerabilities through breaking codes and identifying commu­
nications schedules and routinely used frequencies. With the know how to infiltrate the 
FARC communications network, the Colombians identified people with the right voices 
and tones to impersonate select FARC radio operators. This included constructing radio 
transmission sites in the jungle to establish the proper background ambient noise. 
With the capability to imitate FARC leaders’ communications, the Colombians 
proceeded to craft a strategy to recover the hostages. Instead of relying on ground re­
connaissance in the dense jungle to locate the hostages, the Colombians replicated the 
FARC chain of command and manipulated subordinate FARC commanders into unwit­
tingly handing over the hostages to the Colombian Government.
Sustained Colombian military pressure against the FARC hostage holding network 
and against the FARC military leadership ultimately set the conditions for the rescue 
and significantly contributed to both the friction and fog of war experienced by the 
FARC. It was military pressure that set in motion the hostage transfer between FARC 
fronts by increasing the network’s vulnerability to detection and interdiction during 
movement. These vulnerabilities allowed Colombian SOF to increase pressure on the 
hostage holding network and place the FARC 1st Front leadership under sustained du­
ress during Operation Ellipse from January to June 2008. Mono JoyJoy was also under 
sustained military pressure, constantly on the move and often out of communications 
with the hostage holders. This pressure prevented the FARC from successfully transfer­
ring the hostages to the Yari Front increasing the FARC’s vulnerability to the deception 
by allowing for the introduction of an alternative solution to the problem of moving the 
hostages out of the FARC 1st Front area. 
Furthermore, creating the alternate reality exploited a signature familiar to the 
FARC—Venezuelan President Hugo Chavez’s periodic interventions to arrange Red 
Cross helicopters to pick up hostages from the FARC and using a location near a site 
previously used for the hostage pick-up made the ruse even more believable.
A “Trojan Horse” has come to mean any trick or stratagem that causes a target to 
invite a foe into a securely protected bastion. This was clearly the case when Cesar, the 
FARC 1st Front Commander, essentially invited the Colombian commandos, disguised 
as an international organization, to fly in and pick up the hostages for transfer to what 
they thought was another FARC controlled area. The FARC actually picked the transfer 

A Modern Day “Trojan Horse”—Operation JAQUE and the Use of Stratagem in a Hostage Rescue Operation
392 
The Art and Science of Military Deception
site, readied the hostages for pick-up and unwittingly assisted in loading them on the 
rescue helicopter. The Colombian’s went a step further and cleverly invited Cesar to 
escort the hostages, which he readily accepted as an honor.
Operation JAQUE represents one of the finest examples of military deception in 
modern history. Deception is the deliberate misrepresentation of reality to gain a com­
petitive advantage. The Colombian government cleverly concealed their capability to 
infiltrate the FARC’s communications network and carefully tested their ability to ma­
nipulate the FARC hostage-holding network ultimately choosing to exploit their capa­
bility at precisely the right time to rescue high-value political hostages and thus achiev­
ing a strategic effect.

393
Section X: 
Deception Planners and Planning
Introduction
Deception Planners and Planning
Successful deception necessitates overcoming numerous challenges—some obvious and 
expected, others not so obvious and frustrating. The first challenge of successful decep­
tion is the enemy. An enemy who knows more about his would-be deceiver than the 
deceiver knows about his target is apt to mitigate the effects of stratagem. In theory, 
the competence of the enemy should be the single greatest challenge for the deception 
planner. Unfortunately and most frustrating, policy and strategic culture, inexperienced 
planners and a military force that is less skillful than required undermine deception, 
perhaps more than the enemy.1 Deception challenges can be divided into two catego­
ries—preconditions and process.
Preconditions
Preconditions include—but are not limited to—knowing the enemy; possessing a stra­
tegic, ulture that prizes deception; having policies that cultivate, reward, and institu­
tionalize deception as an instrument of statecraft; and developing skilled practitioners. 
To reiterate, a deceiver must know more about the adversary than the adversary knows 
about the deceiver. This requires somewhat of an outward focus designed to understand 
the culture and institutions of the enemy sufficient to identify and exploit vulnerabilities. 
All successful deception requires a knowledge advantage. 
This knowledge advantage needs to be supported by an institutional structure that 
systematically recognizes deception as a legitimate tool. Policies should provide direc­
tion, establish goals and constraints, and consider risk. An institutional structure and 
sound policy are a clear reflection of commitment.2 
Another precondition for deception success is the practitioners. Deception is more 
of a military art than a science. It can and should be taught in military schools but teach­
ing art is not a foolproof way to nurture the artist. While it is possible that classroom 
instruction or self-study can produce competent deception practitioners, Bart Whaley 
suggests that stratagem, being an art, is best passed on from teacher to student. Implicit 
in Whaley’s suggestion is that the teacher can identify the promising student.3 
1.	
Colin Gray makes a similar claim referring to strategists.
2.	
Walter Jajko, “Deception: Appeal for Acceptance; Discourse on Doctrine; Preface to Planning,” Comparative Strat­
egy, Vol. 21, 2002, p. 355.
3.	
Bart Whaley, Stratagem: Deception and Surprise in War, Norwood, MA: Artech House, 2007, pp. 3–6.

Section X: Deception Planners and Planning 
394 
The Art and Science of Military Deception
Process
The process of deception involves planning, evaluating, coordinating, deconflicting, inte­
grating, gaining approval, executing, measuring effectiveness, adjusting, terminating, and 
recording results.4 This process, with minor variations, reflects standard military plan­
ning practice and is derived from numerous conceptual models and theories about decep­
tion.5 All of these models and theories have similar objectives. These objectives include:
1.	 To provide a commander with freedom of action to carry out his mission, by de­
luding the enemy as to his intentions and by diverting the enemy’s attention away 
from the action being taken.
2.	 To mislead the enemy and persuade him to adopt a course of action that is to his 
disadvantage and that can be exploited. 
3.	 To gain surprise.
4.	 To save the lives of one’s own troops.6 
The process is simple and logical and involves the following:
1.	 The purpose of the deception—along with specific objectives—must be established.
2.	 An appraisal must be made to determine whether or not deception is the preferred 
tool. Valuable assets needed for deception should not be put at risk if sufficient 
knowledge of the enemy is lacking or if achieving the objectives listed above do 
not require stratagem. 
3.	 A thorough assessment of the enemy is required to determine his strengths, weak­
nesses, vulnerabilities, intelligence capabilities, and the decision making process 
used by the decision maker. This assessment calls for the deceiver to view himself 
through his enemy’s eyes. Mirror imaging will likely lead to a faulty assessment. 
4. 	 The deception story or mental picture that will be revealed to the enemy must 
be put together. This story must be integrated with the real plan so that they are 
mutually supporting. 
5.	 Develop the details of the plan. The details include, as a minimum: identifying or 
developing channels for transmitting information, physical displays, troop move­
ments, staged compromises of information, diplomatic exchanges and establish­
ing clear indicators, and a feedback mechanism. These are needed in order to 
verify whether or not the stratagem is working. 
Finally, every deception operation, whether it succeeds or fails, should be formally 
terminated. Termination may require a separate micro-operation designed to protect 
agents, sources, and communication channels for future use.
The comments above are not intended to address every element necessary for the 
successful use of stratagem. Still, the two categories discussed—preconditions and pro­
cess—must be taken into account. Properly used, deception is an effective and eco­
nomical tool for both the offense and the defense. However, it is not a substitute for an 
integrated strategy that applies all instruments of statecraft towards achieving a realistic 
political outcome. Stratagem can enable good strategy but it cannot rescue bad strategy.
4.	
Jajko, 351–353.
5.	
For a concise summary, see Michael Bennett and Edward Waltz, Counterdeception: Principles and Applications for 
National Defense, Norwood, MA: Artech House, 2007, pp. 20–31. Also see Bart Whaley’s article in this section.
6.	
Jon Latimer, Deception in War, New York: Overlook Press, 2001, p. 62.

395
C H A P T E R  4 3
A Commander Improvises His Own Deception 
Planning Team
Fleet Admiral William F. Halsey
Admiral William F. Halsey was a U.S. Naval officer who commanded the South Pacific 
Area during the early stages of the Pacific War against Japan.  After Pearl Harbor, 
Halsey led a series of raids against the Japanese, and then carried out the Doolittle Raid 
on April 18, 1942.   Halsey’s phrase, “Hit hard, hit fast, hit often” soon became a slogan 
for the Navy.
Admiral William F. “Bull” Halsey, Commander of the Third Fleet and (until 15 June 
1944) the South Pacific Area, was involved in strategic deception at least as early as 
October–November 1943 in the Bougainville campaign.1 But, as that operation was 
conducted jointly with General MacArthur, it is difficult to separate Halsey’s contribu­
tion, if any, to the deception plans.
In reminiscing about a later period (November 1944), Halsey passed the following 
intriguing remark:2
After the movie, I sat in on the nightly meeting of my Dirty Trick Department — Mick Car­
ney, Ham Dow, Doug Moulton, Harold Stassen, and Johnny Lawrence — and listened to 
them concoct new methods of bedeviling our gullible enemy. (The Navy prefers me to drop 
this topic right here.)
When Halsey published this tantalizing vignette in 1947, it is surprising that the 
Navy censor passed even that brief but provocative mention of deception. At any event, 
this five-man “Dirty Trick Department” consisted of:
••
Rear Adm. Robert B. “Mick” Carney, Chief of Staff, SOPAC and Third Fleet.
••
Lt. Cdr. Leonard J. “Ham” Dow, Halsey’s Communications Officer.
••
Capt. H. Douglas “Doug” Moulton, Halsey’s Air Operations Officer.
••
Lt. Cdr. Harold E. Stassen, Halsey’s Flag Secretary.
••
Lt. Cdr. John E. “Johnny” Lawrence, an Air Combat Information Officer.
Here we glimpse a Commander working intimately (and apparently effectively) 
with his deception planners. If naval deception was new to Halsey, intrigue was not. In 
setting the scene for the victory at Midway on 2–3 June 1942, Halsey had connived with 
Nimitz to circumvent the direct orders of Admiral King in Washington.
1.	
For deception in the Bougainville operation see Whaley (1969/2007), Case A39.
2.	
Fleet Admiral William F. Halsey and Lieutenant Commander J. Bryan Ill, Admiral Halsey’s Story, New York: Whit­
tlesey House, 1947, p. 235.


397
C H A P T E R  4 4
Deception Planning in 145 Different Disciplines: 
Lessons from Behind Other Hills1
Barton Whaley
How They Deceive
The prime task of the military commander and intelligence analyst was defined in the 
Duke of Wellington’s famous remark about always seeking to estimate what the op­
ponent is up to by peering at “the other side of the hill.”  This is the task of all other 
types of “detectives,” other analysts.  To fulfill this task, all of these analysts rely on 
several theories and methods.  This chapter sets forth seven of these approaches that 
have proven highly effective for various nonmilitary planners and analysts, particularly 
when deception is suspected.  While some political-military planners and intelligencers 
use some of these ideas and procedures, few have used them as systematically or even 
thought them through as much as in those disciplines where they are routinely practiced.
This chapter draws on my continuing research during the past four decades on 
145 different types of detectives.  They ranged from political and military intelligence 
analysts to arms control inspectors, cryptanalysts, police detectives, forensic scientists, 
psychologists, con artists, practical jokers, and joke writers; to such spies of nature as 
biologists and physicists.  Let’s now look at some theories and methods used to deceive 
that are usually overlooked by most military deception planners and are seldom spelled 
out in official doctrine. Eight of these deserve special notice here.
The Essence of Deception: Hiding the Real and Showing the False
••
Philosopher of science: Sir Francis Bacon (1597);
••
Forensic document examiner: Albert Osborn (1910);
••
Artist: Solomon J. Solomon (1920);
••
Physicist: Dr. R. V. Jones (1942 and 1957).
The notion of hiding-and-showing as a linked pair or dichotomy was already old 
in 1597, when English philosopher, Francis Bacon, raised this everyman’s notion to the 
level of philosophy in his essay, “Of Simulation and Dissimulation.” The reader will 
appreciate that this seemingly simple concept of simultaneously hiding one thing and 
1.	
Barton Whaley, “Lessons from Behind Other Hills: Planning Deceptions in 145 Different Disciplines,” Original 
version submitted under contract to Dr. Jack Dziak on January 15, 2007. 

Deception Planning in 145 Different Disciplines: Lessons from Behind Other Hills
398 
The Art and Science of Military Deception
showing something else in its place is the basis for both the theory of deception and all 
attempts to analyze deceptions.
It’s no accident that we owe the refinement of this concept to Bacon rather than 
some other Elizabethan humanist. Francis Bacon was, after all, a great admirer of Ma­
chiavelli. Moreover, like his Italian model, Bacon was an historian, writer, diplomat, 
and an ambitious politician whose career ups and greater downs came at the whims of 
tyrants. Additionally, Bacon had personal experience since age 16 as a secret agent in 
the cut-throat politics of the English royal court.
Albert Osborn, that pioneer American questioned-document examiner, understood 
the simulation-dissimulation linkage as found in the forgery of signatures. He stressed 
that even any half-successful forgery must be a double process, one where the forger 
tries simultaneously to simulate the characteristics of the hand being imitated while 
disguising his own. Even then, neither the simulation nor the dissimulation is apt to be 
perfect.2  Obviously, Osborn’s injunction can be extended to all types of forgery and, I 
insist, all types of deception.
Solomon J. Solomon was a London-born, British-Jewish portrait painter whose 
book Strategic Camouflage (1920) was a study of Allied and German camouflage on the 
Western Front in the Great War.3  His landmark book offered the first primitive theory 
of camouflage and introduced to military theory the old, two-part simulation-versus-
dissimulation notion using those two words.  It also first made explicit the concept of 
strategic-versus-tactical camouflage. Unfortunately, instead of building on the wisdom 
of Solomon, most of the later camouflage field manuals have degraded theory while 
concentrating on updating specific methods.
Indeed, this concept of deception as a two-fold hiding-plus-showing process is not 
as clearly understood in any other part of military, particularly Western military doc­
trine or practice as it is in such other professional doctrines as conjuring, con artistry, 
psychic fraud, counterfeiting, and forgery. Even the leading theorist and practitioner of 
military deception, Dr. R. V. Jones, was uncertain on this point. On the one hand, he of­
ten seemingly considered deception as combining dissimulation and simulation. On the 
other hand, he sometimes clearly defined a two-part typology of The Principles of Secu­
rity which are “in a sense negative” in contrast to The Principles of Deception which are 
“positive”.4 And other British and American writings on the subject similarly introduce, 
but inconsistently use, the mutually exclusive dichotomies “camouflage and deception” 
(C&D), “cover and deception” (C&D), and “denial and deception” (D&D). However, 
I prefer the prior definition of deception not merely because it is elegant, (Occam-el­
egant), but because it emphasizes the psychological fact that its two components, dis­
simulation and simulation, always occur simultaneously.4  To give a military example: If 
an insurgent team camouflages (hides or dissimulates) an RPG nest overlooking a road 
junction, they simultaneously imply (show or simulate) that there is no ambush there. 
Indeed, to enhance the notion that they pose no threat, they might even set up a visible 
dummy (simulated) ambush nest somewhere out of range of the junction.
A conclusion in deception is fundamentally simple in theory. Even in practice, 
this simplicity can be maintained. Tangled webs and other such complexities are sure 
2.	
Albert S. Osborn, Questioned Documents, Rochester: The Lawyers’ Co-operative Publishing Co., 1910, p. 12.
3.	
Solomon J. Solomon, Strategic Camouflage, London: Murray, 1920.
4.	
R.V. Jones, “Intelligence and Deception,” in Robert Pfaltzgraff, Uri Ra-anan, and Warren Milberg, eds. Intelligence 
Policy and National Security, London: Macmillan, 1981, pp. 17–18.

 
Deception Planning in 145 Different Disciplines: Lessons from Behind Other Hills
The Art and Science of Military Deception	
399
symptoms of incompetent deception planning because they unnecessarily multiply the 
blatant clues for the deception analyst to work with. Conversely, a sure sign of a com­
petent deception analyst is one who systematically applies incongruity analysis.
What They Hide and Show: The 5 Ws
••
Journalists: Rudyard Kipling (1902), etc.
Because news reporters are a numerous and important type of detective, it is natu­
ral that they developed, or at least adopted, a few standard investigative procedures of 
their own, such as the data bank that they call their in-house library or, more colloqui­
ally, morgue. However, the most important of their adaptations has become a popular 
memory aid, as seen in the following poem:
I keep six honest serving men 
They taught me all I knew;
Their names are What & Why & When 
And How & Where & Who.
Just so, rhymed English ex-newspaperman, Rudyard Kipling, back in 1902. I agree 
with Prof. Stuart Kind, an outstandingly successful English forensic scientist, that this 
bit of journalistic doggerel also “encapsulated much of the equipment of the good crime 
investigator.” Kipling’s is the earliest citation I find to the mnemonic traditionally used 
by media journalists in reporting any and every news story. Usually they call it “The 
Five Ws”—Who, What, Where, When, Why. Sometimes they call it “The Five Ws Plus 
H” (for the “How”) or just “The 5 Ws and the 1 H”. These formulations were com­
monplace in the journalism trade as early as 1932.
The Five Ws is every journalist’s checklist of the essential elements that make up 
a news story—any news story, every news story. Once he’s collected these five (or six) 
tidbits of information the story is technically complete, ready to report—ideally sum­
marized in the lead paragraph. Sociologists and political scientists—and a few military 
intelligence analysts who analyze human communications interactions adopted this 
model—call it the Lasswellian Paradigm. They were copied by a few military intel­
ligence analysts beginning with myself in 1969 when I first proposed adapting Harold 
Lasswell’s five-category model to the analysis of military deception operations. Eventu­
ally (by 1982) I expanded this checklist to nine categories.5  The otherwise admirable 
Alexander George, a Stanford professor of political science who surely knew of the 
Lasswellian Paradigm, didn’t credit anyone in 1979 with his retrograde proposal that 
the major “dimensions” of surprise were “whether, what, where, when, why.” A decade 
later, Israeli political scientist Ariel Levite would explicitly copy George’s “five dimen­
sions” and Israeli strategist Ephraim Kam would compile (without credit) an inferior 
4-point list of “aspects” he called “whether, when, where, how.”
However, the 5-Ws analytical model and its variants precedes even Kipling—indeed 
all journalists, all social scientists. It goes back to an anonymous Roman jurist who gave 
us the maxim:
5.	
Barton Whaley, Stratagem, Cambridge, MA.: CIS, MIT, 1969, pp. 210–215; Whaley & Bell, 1982, pp. 428–431. 

Deception Planning in 145 Different Disciplines: Lessons from Behind Other Hills
400 
The Art and Science of Military Deception
“Quis, quid, ubi, quibus auxiliis, cur, quomodo, quando?” [Who, what, where, with what, 
why, how, when?]
Various similar 7-, 6-, and 5-mode versions were also adopted by pioneering Ameri­
can criminologists like Edward Heinrich, British forensic scientists like Professor John 
Glaister, and that fine Hungarian-American mathematician, George Polya, who advised:
Your five best friends are What, Why, Where, When, and How. You ask What, you ask 
Why, you ask Where, When and How—and ask nobody else when you need advice.
—G. Polya, How to Solve It (1945), 197
Polya didn’t need “Who” because math problems don’t normally involve a second 
human actor.
The Five Ws and all their prior and derivative models are extraordinarily powerful 
tools. If they seem obvious or simplistic, they aren’t. Research psychiatrist, Professor 
Daniel X. Freedman, notes the ease with which medical and social science fraud enters 
undetected into the scholarly journals. He believes that this is because most researchers 
and editors conventionally omit information about when, where, or who collected the 
raw data and which of several researchers authored what parts of the conclusions. Dr. 
Freedman urges that, in order to make detection easier, “The who, what, when, where, 
how, and why of an enquiry must be reported.”6  Particularly serious, even potentially 
deadly, examples occured when political-military analysts like Cruickshank (1979), 
George (1979), Levite (1987), or Kam (1988) omitted any of these dimensions.
More generally, many media reporters, social scientists, and detectives regularly 
overlook one or more of these crucial elements, thereby missing one or more parts of the 
whole story. Witness the accounts in almost every morning newspaper and most evening 
TV news shows. The media journalists, having early on adopted this powerful but sim­
ple aid to memory, have almost forgotten it in their zealous dumbing-down preoccupa­
tion with maximizing entertainment at the expense of information. I was not surprised 
to notice on the morning of the capture of Saddam Hussein that only one American TV 
news anchor cleaved to the spirit of the Five Ws. He even named them. This was CBS’s 
Dan Rather, the oldest and arguably the only thoroughly professional journalist left on 
American TV until 2004 when even he self-destructed over his inexcusable gullibility 
when handed a clumsy forgery.
I’ll leave this model by just noting in passing that there are several derivative, al­
though unacknowledged, versions posing under various acronyms. Those nameless 
committees in the U.S. military who edit field manuals and books on joint doctrine are 
among the main offenders. The earliest example I can find is STASM, which originated 
in World War II with the Propaganda Branch of the U.S. War Department General Staff.  
This acronym stands for the five elements that are involved in the conduct of psycho­
logical warfare: Source (including media), Time, Audience, Subject, and Mission. The 
most recent (by 1987) example is SALUTE, which stands for Size, Activity, Location, 
Unit, Time, and Equipment.
My personal list, which gradually expanded from Lasswell’s list, has nine categories. 
I see perception and misperception in general and deception in particular applying to only 
6.	
Daniel X. Freedman in Michael Hersen, Richard M. Eisler, Progress in Behavior Modification, ed. Peter M. Miller 
(NY: Sycamore Publishing, 1994), 194. 

 
Deception Planning in 145 Different Disciplines: Lessons from Behind Other Hills
The Art and Science of Military Deception	
401
nine types of things. These are the categories that a deceiver tries to dissimulate or simulate, 
hide or show. They are the things about which we can be deceived or surprised. Let me count 
the ways:7
The nine categories of perception and misperception
1.	 Pattern: What is the structure and process of the event?
2.	 Players: Who are the actors?
3.	 Intention: What does the main actor hope to accomplish?
4.	 Payoff: With what potential costs and benefits?
5.	 Place: Where will the event occur?
6.	 Time: When is it scheduled for?
7.	 Strength: How much effort can or will the main actor bring to bear?
8.	 Style: What, if any, new methods or technologies might appear?
9.	 Channel: Through which media will the main actor communicate?
While this is the most comprehensive list, I use it only when doing systematic paper-
and-pencil analyses. The shorter 5 Ws or 5Ws+H lists are usually sufficient, quick-and-
dirty tools, particularly when pressed for time.
In conclusion, a few basic check-lists, such as The 5 Ws, simplify the work of both 
deception planners and deception analysts by efficiently organizing their planning and 
analyses.
Bluff and Double Bluff
••
Magicians: Thayer (1914), etc.;
••
Card sharps: Scarne (1945);
••
Mathematician: Von Neumann (1947);
••
Economists: Morgenstern (1947) and Schelling (1960);
••
Counterintelligence officers: Pinto (1952), etc.;
••
Sociologist: Goffman (1969).
The first theory of Poker was proposed in The Theory of Games and Economic 
Behavior, published in 1944 by two immigrant Americans, Hungarian mathematician 
John von Neumann and German economist Oskar Morgenstern.8  Their ground-break­
ing book included a mathematical analysis of poker that proved the rightness of expert 
players’ intuitive belief that successful poker depends not merely on randomly inter­
mixing bluffs with straight play, but that it is essential to try to bluff weak hands, even 
though these are likely to be called, in order to make the high hands pay. Indeed, during 
7.	
Based on Bart Whaley, “A Typology of Misperception; or The Ways We Can Be Wrong,” draft March 1980, p. 
111. Some of this material was summarized in Whaley & Bell (1982), p. 428–431, where I added the category of 
“pattern.”
8.	
John von Neumann and Oskar Morgenstern, The Theory of Games and Economic Behavior, Princeton: Princeton 
University Press, 2nd edition, 1947, pp. 186–189.  The Theory of Poker and specifically the Theory of Bluffing 
were primarily the work of Von Neumann, during the period 1926–1928.   See also Lawrence Friedman, “Optimal 
Bluffing Strategies in Poker,” Management Science, Vol. 17, No. 12, August 1971, pp. B764–B771. 

Deception Planning in 145 Different Disciplines: Lessons from Behind Other Hills
402 
The Art and Science of Military Deception
the mid-1800s poker was also called “Bluff.” The best situations for bluffing in Poker 
occur in the following circumstances:
1.	 Any time the ratio of the price of being called is high compared to the value of the 
pot.
2.	 Whenever all the loose, that is, reckless players (particularly novices), have folded 
and all but one or two tight, that is conservative, players remain in the game.
3.	 In high stake games, because these are more likely a) to yield situation number 1 
above and b) to discourage loose players from calling just to keep the other player 
honest.
4.	 Whenever you have evidence that the other players still in the pot perceive you as 
playing tight.
5.	 If, holding a strong hand early in the game, you check and then re-raise.
6.	 When you are sitting last.
This theory of bluffing and this list, although applied specifically to one particular 
type of card game, is generally true of all forms of bluffing. Harvard Professor Thomas 
C. Schelling, a political scientist and Nobel Prize winner, applied it to military deterrence.9 
How often do we hear someone described as good at war strategy, diplomatic negotiation, 
or everyday business dealings because he is a good poker player. Of course there are excep­
tions. Thus, von Neumann himself was usually a loser in those many poker games with his 
fellow A-Bomb scientists at Los Alamos. This was attested to by his fellow player, Polish 
mathematician Stanislaw Ulam, who offered the old losers’ excuse that they (Ulam, von 
Neumann, and Edward Teller) would “think about completely unrelated subjects during the 
bidding or betting.”
The double bluff is a trick of the kind so prettily described by conjurors as a “Sucker.”
—Charles Waller, Magic from Below (1929), 163
Magicians call it a sucker effect or sucker gag. This refers to their method of leading 
the audience to believe they’ve detected a trick’s method and then pulling a double bluff 
to surprise them even more. It is the magicians’ equivalent of the gambling sharps’ the 
cross from the popular expression double cross. Magicians use it as insurance to cover 
the secret of all their tricks, from the smallest tricks to the largest stage illusions. They 
are one of the two most nearly detection-proof effects in magic, the other being the One-
Ahead Gag, which is discussed later (“Time Out of Joint”).
Of course, the old double bluff does exist outside magic and con games. However, 
seldom on a routine basis and then only in the spy versus counterspy games where 
spies are conventionally given a legend (a cover story) and often even a reserve story (a 
second-level story-within-a-story) as backup in case the initial phony story was blown. 
Political-military deception planners should at least be alert to opportunities for incor­
porating sucker gags into their plans.
In conclusion, bluff and double bluff can profitably be employed by military (or 
political) planners in substantially more situations than at present. This seems to be 
currently routine only in the Chinese Communist military doctrine. At the very least, it 
increases uncertainty in the minds of opposing analysts.
9.	
Thomas C. Schelling, The Strategy of Conflict, Cambridge, MA: Harvard University, 1960, pp. 3–20.

 
Deception Planning in 145 Different Disciplines: Lessons from Behind Other Hills
The Art and Science of Military Deception	
403
The Theory of Outs
••
Magicians: Outs;
••
Con artists: The Blowoff;
••
Military: Plan B.
If the performer knows enough outs, he will never fail to bring a trick to successful 
conclusion.
—Jerry Mentzer, Magician Nitely (1974), 23
There are only four circumstances in which deception will fail. It fails if the target:
1.	 Takes no notice of the intended effect;
2.	 Notices but judges it irrelevant;
3.	 Misunderstands its intended meaning;
4.	 Detects its method. In most cases, the deception game ends at that point. 
However, both the successful detective and the persistent deceiver can—if they have 
prepared—continue the game one stage further. The successful detective of deception 
can switch from passive to active counterdeception. However, this will fail if the de­
ceiver takes certain steps to rescue success from impending failure by using outs.
Interestingly, among all types of deceivers, only confidence tricksters and magicians 
have developed any standard operating procedures for recovering from the unfortunate 
effects of the discovery of their deception. All others leave themselves only the option 
of hasty flight, if even that.
In Con Games
Never give a sucker an even break or smarten up a chump.
—W. C. Fields, Poppy (1923, serio-comic musical play), an improvised line, probably copy­
ing gambler Milton Mizner.
Confidence tricksters and other hustlers have developed a standard technique to 
buy enough time for a safe escape just before the victim sees the operation for the scam 
it is. This technique is called cooling out or the blow-off. It is built into the final stage of 
the operation and is itself a deception. Professional liars, like con artists, don’t have to 
improvise when questioned about discrepancies in their story. They always prepare in 
advance by, as lie expert Paul Ekman explained, “memorizing a credible reply for each 
and every question they think their quarry might raise.”10
Cooling the mark out is usually only a matter of convincing the disappointed and/
or irate sucker that his loss involves neither loss-of-face nor was the responsibility of his 
10.	 Paul Ekman, Telling Lies: Clues to Deceit in the Market Place, Politics and Marriage, New York: Norton, 1985, 
pp. 14–15.

Deception Planning in 145 Different Disciplines: Lessons from Behind Other Hills
404 
The Art and Science of Military Deception
friend, the hustler. If played carefully, the hustler may even appear so blameless that he 
can hit the mark again later.11
In Magic
Magicians share with con artists the concept of the blow-off. In fact, they borrowed this 
bit of jargon from the confidence tricksters. The blow-off in magic is simply any climax 
of a trick that sends the spectators away puzzled because of a final twist in logic. Where 
the con artist seeks only to buy time for his or her own safe get-away, the magician is 
concerned to ensure that the trick’s method remains secret.
Magicians have gone the con artist one better. In addition to the blow-off they also 
have their own concept of the out. It applies to all magic tricks. It could be system­
atically applied equally to all military deception operations but, so far, has not. First 
conceived in 1785, the magicians’ Theory of Outs is simply a much earlier statement of 
the military deception planners’ Theory of Alternative Objectives. The out is any pre-
planned alternative deceptive method in case the original plan fails.
French magician Henri Decremps foreshadowed The Theory of Outs in 1785 as 
Rule 2 in his list of principles of magic, where he wrote: “Whenever possible have sev­
eral ways of doing the same trick.”12 This rule first appeared in English translation in 
an anonymous book, plagiarized also as Rule 2 but elaborated with a reason as:13 “En­
deavour, as much as possible, to acquire various methods of performing the same feat, 
in order that if you should be likely to fail in one, or have reason to believe that your 
operations are suspected, you may be prepared with another.”13 Magicians to this day 
observe Decremps’ Second Rule, quoting or elaborating on it, although—having little 
regard for their own history—never crediting its originator.13 
Robert-Houdin expanded on Decremps in 1868 when he wrote: “However skilful 
the performer may be, and however complete his preparations for a given trick, it is still 
possible that some unforseen accident may cause a failure. The only way to get out of 
such a difficulty is to finish the trick in some other manner. But to be able to do this, 
the performer must have strictly complied with this important rule: never announce be­
forehand the nature of the effect which you intend to produce.” He went on to explain: 
“However awkward the position in which you may be placed by a breakdown, never 
for one moment dream of admitting yourself beaten; on the contrary, make up for the 
failure by coolness, animation, and ‘dash.’ Invent expedients, display redoubled dexter­
ity, and the spectators, misled by your self-possession, will probably imagine that the 
trick was intended to end as it has done.”16 Robert-Houdin need only have added that 
the invention of expedients should be done in advance in anticipation of the more likely 
types of failure.
11.	 David W. Maurer, The Big Con, Bobbs-Merrill, 1940, pp. 48, 289; Erving Goffman, “On Cooling the Mark Out,” 
Psychiatry, Vol. 15, 1952, pp. 451–463; Robert C. Prus and C.R.D. Sharper, Road Hustler: The Career Contingen­
cies of Professional Card and Dice Hustlers.
12.	 Robert-Houdin, Les secrets de la prestidigitation (1868) as translated into English as The Secrets of Conjuring and Magic, 
London: Routledge, 1878, pp. 32–33.
13.	 See, for example, John Henry Anderson, The Fashionable Science of Parlour Magic, 6th edition, Self-published in London, 
1844; The Magician’s Own Book, New York: Dick & Fitzgerald, 1857, 79, taken verbatim from Anderson; Ellis Stanyon, 
Conjuring with Cards, London: Gill, 1898, p. 3. 

 
Deception Planning in 145 Different Disciplines: Lessons from Behind Other Hills
The Art and Science of Military Deception	
405
In General
The Essence of Deception mentions the two modes of deception—dissimulation (hiding) 
and simulation (showing). This simple two-part model can be elaborated to give decep­
tion’s basic structure:
The Structure of Deception
Dissimulation
Simulation
Masking
Mimicking
Repackaging
Inventing
Dazzling
Decoying
Earlier, we saw that in practice, as in theory, all three ways of hiding the real can 
accompany the three ways of showing the false in any of their possible combinations. 
Here, the three ways to dissimulate and the three to simulate, have been arranged in 
descending order of assumed effectiveness. J. Bowyer Bell’s hypothesis was that the 
most effective way to dissimulate would be by masking. Therefore, if masking fails to 
confer enough invisibility to the real object or event and it is detected, the deceiver can 
then resort to repackaging to disguise it. If repackaging fails and the thing is recognized 
for what it is, then dazzling can be used as a last-ditch measure to at least confuse the 
target about some characteristics. Similarly, Bell assumed that the most effective way 
to simulate would be by mimicking. Therefore, should mimicking fail to show the false 
by a convincing imitation, the deceiver can resort to inventing to create an alternative 
reality. If inventing also fails, decoying can still be used at least to attract the otherwise 
undivided attention of the target away from it. Bell suggested that deception planners 
not only also have the possibility of an out but indeed, a series of priorities for them—
the poor, better, best in each of the two columns of the above chart.
Consequently, I thought it likely that the most effective deceptions will dissimulate 
by masking and simultaneously simulate by mimicking, while the least effective de­
ceptions would be those that combine dazzling with decoying to achieve only a mere 
razzle-dazzle effect. Therefore, while dazzling-decoying deceptions might get invented, 
few—if any—would survive frequent operational experience and be soon dropped from 
the repertory.
To test Bell’s hypothesis and my subsidiary one, I chose to use the tricks of magi­
cians, because among all professional deceivers, they have by far the most frequent ex­
perience of both failed and successful deceptions. Accordingly, 60 magic tricks that had 
been collected to illustrate a previous paper were fitted into a 3×3 matrix as follows:
Simulating
Dissimulating
Mimicking
Inventing
Decoying
Masking
19
10
10
Repackaging
4
3
1
Dazzling
10
2
1
Source: Whaley (1981, table, based on an opportunity sample of 60 tricks).
As can be seen in practice, or at least in magicians’ practice, both hypotheses are 
substantially verified. Masking and mimicking are not only overwhelmingly the most 
common methods used for dissimulation and simulation respectively; they also are the 

Deception Planning in 145 Different Disciplines: Lessons from Behind Other Hills
406 
The Art and Science of Military Deception
two used most often in combination. Conversely, only one example of dazzling-decoy­
ing was discovered, despite an even wider search among magic tricks. Thus, this is an 
apparently useful procedural guide for designing the potentially most effective types of 
deception and avoiding the lesser and least effective ones.
Ruses of the dazzle-decoy type are also quite rare outside of conjuring. For ex­
ample, of the dozens of carnival flat store (cheating) games of pretended chance or skill, 
only one is of this type. Carnies call it, appropriately, Razzle-Dazzle—but only among 
themselves; the suckers know it by such disguised names as Bolero, Double Up, or Ten 
Points. This “game” uses a method of scoring too complicated for the sucker to follow 
in the short time permitted so that the “flat-joint” operator need only false-count to 
make the sucker lose.14
This model of hiding and showing can also be turned around to serve as a guide for 
the analyst in assigning priorities in his search for and analysis of deceptions.
In War
Some academic military deception specialists take the sterile view that the risk of a failed 
deception is so great that it’s better to have no deception at all. Even one Cold War U.S. 
Army manual on camouflage directed that no subordinate army units initiate any cam­
ouflage operation without prior approval by senior command. This is overly pessimistic 
advice. Fortunately for their careers, few military commanders listen to this advice from 
the so-called experts. In researching Stratagem (1969), I found no cases of backfire15 
and that even unsuccessful deception operations often served to at least confuse enemy 
intelligence.
Neither soldiers’ manuals nor generals’ war plans tell them what to do when their 
deception operations fail. The usual attitude is “Well, we tried.” Because deception 
seldom costs much, most commanders just write it off as a small loss and either abort 
the real operation or, more likely, charge on in without the advantage of surprise. In 
either case, the logic is that a failed deception is no worse than not having tried at all. 
I agree with the logic but would hope for a more creative solution. I know of only two 
cases where military officers overcame their self-crippling sense of helplessness and re­
designed their deception plans to take positive advantage of the new situation.
The first example takes place around mid-1942.  Major Oliver Thynne was a nov­
ice planner with Colonel Dudley Clarke’s “A” Force, the Cairo-based British deception 
team. Thynne had just been told by Intel that the Germans had learned to distinguish 
the dummy British aircraft from the real ones because the flimsy dummies were support­
ed by struts under their wings. When Major Thynne reported this to his boss, Brigadier 
Clarke, the “master of deception”, fired back:
“Well, what have you done about it?”
“Done about it, Dudley? What could I do about it?”
“Tell them to put struts under the wings of all the real ones, of course!”16
Of course? Hardly. A commander with a straightforward mind, having recognized a 
telltale flaw in the dummies, would have ordered the camouflage department to correct 
14.	 John Scarne, Scarne’s Complete Guide to Gambling, New York: Simon and Schuster, 1961, pp. 478–489.
15.	 Since then, I have found a single example, a 1944 U.S. example.
16.	 David Mure, Master of Deception: Tangled Webs in London and the Middle East, London: Kimber, 1980, 
p. 98.

 
Deception Planning in 145 Different Disciplines: Lessons from Behind Other Hills
The Art and Science of Military Deception	
407
it. However, Clarke’s wonderfully devious mind immediately saw a way to capitalize 
on the flaw. By putting dummy struts on the real planes while grounded, enemy pilots 
would avoid them as targets for strafing and bombing. Moreover, it would cause the 
German photo-interpreters to underestimate the number of real RAF planes based lo­
cally and falsely conclude that many of the real ones must be based elsewhere.
Clarke had the wit to see the out as a general principle. One of his favorite maxims 
that he taught his staff was: “When you put over a deception, always leave yourself an 
escape route.”17
The second example of a necessary military out that worked was an audacious and 
risky one, a last minute improvisation forced upon the deception planners by sheer ur­
gency.18  Operation OLIVE was General Alexander’s decisive offensive to break the Ger­
man line across central Italy in the summer of 1944. In early June, Alexander planned 
his main attack with his American and French divisions to go through the mountain­
ous center, with a feint by his British divisions along the eastern flank on the Adriatic. 
On July 5, Alexander learned that London and Washington had decided to strip him 
of many of his American and all his French divisions, sending them away for the am­
phibious invasion of South France. Consequently, on August 4, he reluctantly decided to 
make the real attack up the Adriatic coast with his British troops, leaving the denuded 
American force to conduct the feint at the center—in other words—the very strategy 
that the current deception operations were communicating successfully to the Germans.
This reversal of strategy now required a plausibly readjusted deception. Moreover, 
with OLIVE D-day set for August 25, Alexander’s deception planners had only three 
weeks to reverse the enemy’s perceptions—a feat that military history shows to be very 
rare indeed.
The essence of the new deception plan was to work a double bluff by having the 
Germans now believe that the old evidence fed to them had been and still was the Al­
lied deception operation. This was carried out by a new and elaborate program of radio 
deception. As far as I am aware, this is the only case where a military deception plan 
was turned back on itself—a stratagem to attempt to discredit earlier disinformation by 
exposing it for the deception it had been. In the event, the new deception was successful 
enough to gain surprise of place and strength and of timing as well—two German divi­
sions were uselessly tied up in reserve for a possible attack at the center, one division at 
the point of real attack was caught being relieved, and both the field commander and a 
key divisional commander were still off on leave.
The out works in military deception because of the “principle of security of 
options.”19  Deception, by its very nature, provides its own best security. Although the 
term security of options was my original coinage, the concept was only a generalized 
extension of Liddell Hart’s principle of alternative objectives, first formulated by him in 
1929.20  Alternative objectives means simply that every football play, most military of­
fensives, and so forth, can have two (or more) goals. In most cases, commanders should 
17.	 Mure, Master of Deception, 1980, p. 221.
18.	 Whaley, Stratagem (1969), A414-A418; and Sir David Hunt, A Don at War, London: Kimber, 1966, pp. 267–270.
19.	 First stated in Whaley, Stratagem, (1969), pp, 225–226. 
20.	 The concept of “alternative goals” or “alternative objectives” was first stated by B.H. Liddell Hart in his The 
Decisive Wars of History: A Study in Strategy, London: Bell, 1929, pp. 141–158.  See also his The British Way in 
Warfare, London: Faber & Faber, 1932, p. 302; Strategy: The Indirect Approach, New York: Praeger, 1954, pp. 
161–164, 333–372; and Memoirs, Vol. I, London: Cassell, 1965, pp. 166–168.  See discussion of the evolution of 
this concept in Whaley, Stratagem (1969), pp. 128–139. 

Deception Planning in 145 Different Disciplines: Lessons from Behind Other Hills
408 
The Art and Science of Military Deception
be prepared to accept a second-best goal rather than battering away at their primary 
target.
If the deception operation succeeds in anticipating the preconceptions of the victim 
and playing upon them, deception security is absolute. In that case the victim becomes 
the unwitting agent of his own surprise, and no amount of warning (such as security 
leaks) will suffice to reverse his fatally false expectations. Even if the deception plan 
runs counter to or fails to play upon the victim’s preconceptions, the very fact that it 
threatens alternative objectives will usually assure enough uncertainty to delay, defuse, 
or otherwise blunt the victim’s response.
The worst possible case would occur if the deception plan itself were prematurely 
disclosed to the victim. However, such potentially disastrous disclosure is rare in general 
and so far unknown in war.21  The closest to this was during the Battle of Midway in 
1942 when faulty Japanese security permitted the U.S. Navy to see around the primitive 
Japanese deception operation and set an ambush.
Even if the deception plan was compromised, all would not necessarily be lost. First, 
the disclosure itself would have to be believed. Second, if the deceiver knows or even 
suspects disclosure, he can actually capitalize on this by switching to one of the alterna­
tive courses of action or simply adopting a new deception plan to reverse appearances, 
as General Alexander did in breaching the German Gothic Line in Italy in 1944 by suc­
cessfully reversing an already successful deception operation by deliberately disclosing 
the first one. Even if the direction or objective of the attack has been compromised, the 
planner can still manipulate the victim’s perception of the timing or strength or even the 
intent or style of the attack.
In conclusion, The Theory of Outs is sadly neglected by political and military op­
erations planners. Most military manuals mention the need for anticipating alternatives 
when old plans crash; but commanders and their planners tend to place that activity 
last—usually when time has run out. Magicians and con artists teach us that these Outs 
(alternatives) should be considered at every planning stage.
Time Out of Joint
••
Magicians: The One-Ahead Gag (1693), The One-Behind Gag;
••
Psychic frauds: Billet Reading (1862), It’s Later Than You Think;
••
Practical jokers: It’s Earlier Than You Think;
••
Con artists: Past Posting; or, It’s Later Than You Think;
••
Military: The Not Yet Ruse (1944).
Time itself is fair game for four types of deceivers, namely magicians, pseudo-psy­
chics, practical jokers, and confidence artists. Although most military planners and in­
telligence analysts are aware of some of the possibilities for playing deception games 
21.	 See Whaley, Stratagem (1969), A286-287.  A recent example from strategic international politics was the disclo­
sure in 1986 of the CIA’s disinformation campaign against Libyan leader Gadhafi.  At less exalted levels we see 
this in “tip-offs” of con games and other scams and commonly in “poison-pen” letters that reveal marital or other 
infidelities.  

 
Deception Planning in 145 Different Disciplines: Lessons from Behind Other Hills
The Art and Science of Military Deception	
409
with time, few of them make it routine practice. Consequently all planners and analysts 
can profitably learn from magicians, practical jokers, con artists, and soldiers.
Magicians—The One-Ahead Method
The old ‘one ahead’ I contend is the strongest move in magic.
—Larry Jennings, lecturing, 1985
The One-Ahead Principle underlies the magicians’ method of keeping a step ahead of 
the spectators while the trick or series of tricks unfolds. American magician Bruce Elliott 
has given a concise explanation of the one-ahead:
“In a series of seemingly repetitious movements or visible actions, one action unseen 
by the audience precedes the visible one. This unseen action, in advance of the audi­
ence’s knowledge, is what allows the trick to work.”
A one-ahead mentalist card trick (involving sighting the next card while naming 
and showing the previous one) was used and exposed by magicians as early as 1693 
(by Ozanam; then in 1716 by Neve; in 1740 by Guyot; in 1763 by Dean; in 1859 by 
Secret Out). It was later also applied to Billet Reading by spiritualist mediums, first by 
Charles H. Foster by 1862. Thus, while some clever spiritualist may have independently 
re-invented this method, they didn’t invent it, as is widely assumed.
The one-ahead method is surprisingly rare inside magic and even rarer outside. 
Among the few real-world examples are a few mentioned next.
Practical Jokers: It’s Earlier Than You Think
The clock gag is the type of practical joke where clocks are set forward, as when the col­
lege roommate, having studied long into the night for a 9 AM exam, awakens to find his 
alarm clock and wristwatch both showing nine and rushes madly off to a class that does 
not start for another two hours. The clock gag was a common practical joke in old-time 
live radio. There the dupe, sabotaged by the other performers and staff, would enter the 
broadcast studio to find a clock set ten or fifteen minutes ahead and thinking he was 
(already) on the air, be sabotaged by the other performers and staff.
Con Artists: It’s Later Than You Think
The Sting became the highest-grossing movie of 1974 and won seven Oscars. It was 
also one of the best movies ever done on con artistry. Out for vengeance, young Robert 
Redford recruits retired con artist Paul Newman to mastermind a big con to bilk a crime 
boss out of a fortune. Although filmed from an original screenplay by David S. Ward, 
the scam that formed the film’s gimmick was based accurately on a particularly clever 
con game called a Wire Store. Invented in 1898 by American con artist Joseph “Paper 
Collar Joe” Kratalsky, it had been continued with distinction by the Gondorf brothers 
from 1906 to 1915. The Wire Store is a large office fitted out to look like a real illegal 
horse betting parlor, filled with hired actors dressed to look like well-heeled gamblers. 
The operators tell their rich but greedy sucker that they have a confederate at the track 
who telegraphs or telephones the key race results to them a minute or so before the of­
ficial results are posted and then transmitted to the betting parlors. They then tip the 
sucker to enough real winners that he bets big—at which point they tip him to a loser. 

Deception Planning in 145 Different Disciplines: Lessons from Behind Other Hills
410 
The Art and Science of Military Deception
Ward moved that sting forward to the 1930s and then added, now anachronistically, 
Scott Joplin’s ragtime music that had been composed in the 1910-1915 period.22
A fresh wrinkle was introduced in this grand old scam in 1949 when the Whitey 
Mob neatly fleeced a Chicago bookie by interrupting the bookie’s phone-line, tape-
recording the incoming horse-race results, betting the winners, and releasing the delayed 
information a few minutes later to the unsuspecting bookie.23
By creating an unperceived time delay, The Wire con notionally put time out of joint 
to produce an it’s-later-than-you-think effect or, what I call, the Time Distortion Effect.
Soldiers
The weather was still very stormy that week, unfavorably so for the enemy to mount its 
expected amphibious assault. So Red Force was greatly surprised that morning when 
Blue had begun launching its main diversionary attack across one of Red’s Left Flank 
Beaches. Although Blue’s diversion appeared strong enough to secure the beachhead 
and move slowly beyond, Red decided that this threat could be contained by the local 
garrison without further reinforcement. Consequently, Red’s main force—including all 
its heavy armor—stayed in place behind the Center Beach, where Blue’s main invasion 
force was expected. Red maintained this policy for more than two weeks before they 
realized that the diversion was, in fact, Blue’s main and only assault. It was later than 
they’d thought. By then it was too late. That earlier morning’s landing had indeed been 
Blue’s true D-Day. That beachhead expanded steadily after June 6, 1944 until Hitler’s 
Fortress Europe was reconquered.24 This two-stage time-place deception had been ini­
tially suggested by Field-Marshal Montgomery’s wiley Intelligence Officer-turned Chief 
of Staff, Maj. Gen. Francis de Guingand and perfected by Lt.-Col. Roger Hesketh at 
Eisenhower’s deception-planning unit. It proved spectacularly successful, possibly even 
decisive, and has been widely studied. Nevertheless, this type of play upon an opponent’s 
sense of timing is seldom exploited, far less often than it could be.
Imagine some general of the future, directing battle from his immaculate H-bomb-
proof command center deep within the Earth—computers and remote sensors his only 
link to the terrible reality of the “electronic battlefield” above.25  He must believe that 
his instruments are giving him the truth, the whole truth, and nothing but the truth. But 
how can he know they are not Shakespeare’s treacherous “instruments of darkness”?
In conclusion, the ruses that can be employed to play games with a victim’s percep­
tion of time and timing range from the ridiculously simple to the sublimely clever and 
difficult. Try it as a brainstorming exercise.
The Theory of Indirect Approach
••
Military: Sun Tzu (ca. 350 BC);
22.	 Jay Robert Nash, Hustlers and Con Men, New York: Evans, 1976, pp. 20, 256–265; David W. Maurer, The Big 
Con, Bobbs-Merrill, 1940.
23.	 John Scarne, Scarne’s Complete Guide to Gambling, New York: Simon and Schuster, 1961, p. 72. 
24.	 John P. Campbell, “Roger Hesketh and the de Guingand Letter,” Intelligence and National Security, Vol.15, No.4, 
Winter 2000, pp. 131–142.
25.	 For the recent and still influential military concept of the electronic battlefield see, for example, Colonel William V. 
Kennedy, editor, Intelligence Warfare, New York: Crescent Books, 1983, pp. 76–95. 

 
Deception Planning in 145 Different Disciplines: Lessons from Behind Other Hills
The Art and Science of Military Deception	
411
••
Military: Liddell Hart (1929).
This theory is the only one given in this paper that originated with soldiers. It is 
the only one that is widely known to soldiers, particularly in present-day China and, I 
presume, North Korea. However it deserves to be closely reexamined by all deception 
planners and deception analysts because it is a key part of deception theory and prac­
tice. Lip service is not enough.
Direction, Misdirection, and Indirection
Perhaps the most elementary principle of all deception is to attract the enemy’s attention to 
what you wish him to see and distract his attention from what you do not wish him to see. 
It is by these methods that the skilful conjurer obtains his results.
—Field-Marshal Sir Archibald Wavell, Ruses and Stratagems of War (1942)
The magician’s key concept of misdirection works hand-in-glove with direction. For any 
trick to succeed, the spectator’s attention must be directed toward the intended effect 
and misdirected away from the secret method. The magician directs and misdirects by 
both words (patter) and body language.
The magician may, for example, patter about the hand being quicker than the eye to 
induce his audience to look for sudden movement while, with slow stealth, he makes his 
move right under their eyes. Friar Roger Bacon, the 13th Century English philosopher, 
stands first in a long line of uninformed observers to perpetuate this most common of all 
the false magical theories when he wrote of “persons who create illusions by the rapid­
ity of the movements of their hands.”
The magician may also use body language to both direct and misdirect. This is 
neatly illustrated by the oft-quoted maxim of the Scottish master of sleight-of-hand, 
John Ramsay:
	
If you want somebody to look at something, look at it yourself.
	
If you want somebody to look at you, look at them.
Ramsay’s first sentence is a non-verbal technique for direction, one also used by 
the practical joker who stands and stares up at nothing until a crowd gathers, peering 
to spot the mysterious thing while the trickster vanishes. His second sentence is a non-
verbal method for misdirection, one that even few magicians can resist. As Ramsay 
joked, “I work alone, but I have an invisible assistant—Miss Direction.”
Misdirection sets the scene for deception. If the misdirection is detected, the decep­
tion will fail. As applied to military theory I believe this key concept should be credited 
to English military theorist Captain Sir B. H. Liddell Hart.26  Admittedly inspired by 
Sun Tzu, he first proposed his notion of an indirect approach strategy in 1929 in his 
The Decisive Wars of History and repeatedly enlarged on it until 1954 in his Strategy: 
The Indirect Approach. Unfortunately, Liddell Hart’s critics seized on his somewhat 
ambiguous word indirection to grossly over-simplify his original insight and dismiss his 
theory as mere circular reasoning by twisting his argument to mean that only successful 
26.	 As I first argued in Whaley, Stratagem (1969), 116-121.

Deception Planning in 145 Different Disciplines: Lessons from Behind Other Hills
412 
The Art and Science of Military Deception
military operations get labeled indirect. Even his two greatest champions, Col. T. E. 
Lawrence and Gen. Archibald Wavell complained privately to him about this circulari­
ty—a remarkable fact given their own strong stratagemic bent.27  Liddell Hart’s theory 
might have fared better had he stressed the words direction and misdirection and decep­
tion and surprise and spelled out the logical and causative connections within each pair.
In his more or less systematic survey of 280 campaigns in 30 European wars during 
the period from 490 B.C. to 1913 A.D., Liddell Hart found that the strategically “direct 
approach” was the usual one, while a purposefully indirect approach involving decep­
tion was the rare exception. Moreover, he discovered a direct relationship between the 
degree of military success and the degree of strategic indirectness. Thus of the 32 cam­
paigns that produced decisive victories, only 6 succeeded by a direct approach while the 
26 others (81 percent) were credited by him to use of an indirect strategy.28
My own close study of 216 major battles in 21 wars from 1914 through 1973 con­
firmed and extends Liddell Hart. I found 33 victories that greatly exceeded their plan­
ners’ expectations. Of these, only 5 involved a direct approach while the 28 others (85 
percent) involved at least some calculated effort to deceive. Furthermore, success cor­
relates with surprise through deception. That is, the more sophisticated the stratagems, 
the better the chance for major surprise (as perceived by the victim) and, consequently, 
the greater the degree of success (as measured by the deceiver’s expectations).29
In conclusion, The Theory of Indirect Approach applies to both deception and 
counterdeception in all disciplines studied.
27.	 Wavell and Lawrence to Liddell Hart, 15 March 1934, Liddell Hart Papers, States House, Medmenham, England.
28.	 B.H. Liddell Hart, Strategy: The Indirect Approach, London: Faber and Faber, 1954, pp. 161–162.  Originally B.H. 
Liddell Hart, The Decisive Wars of History: A Study in Strategy, London: Bell, 1929, pp. 141–143, studied only 
240 campaigns in 27 wars during that same period, crediting 26 as decisive.  
29.	 Whaley, Stratagem (1969), pp. 133–139, 179–192, plus additional cases.  My analytical categories, while not en­
tirely matched to those of Liddell Hart, are on inspection of the specific cases generally comparable.  

413
Section XI:
Naval Warfare


415
C H A P T E R  4 5
How to Cheat on Naval Tonnage Treaty Limits 
1919–19391
Donald McLachlan
Donald McLachlan was born in Islington, Scotland, in 1898. He was a journalist, au­
thor and the founding editor of “The Sunday Telegraph.” McLachlan was educated at 
Magdalen College in Oxford.  During the Second World War, he initially served in the 
British Army’s Intelligence Corps, but was transferred to the Naval Intelligence Division 
by Admiral John Henry Godfrey. In 1941, he became head of the Naval Propaganda 
sub-section NID 17Z, which focused on propaganda efforts against the Kriegsmarine.  
He served in this capacity for the remainder of the war and reached the rank of com­
mander. Among his colleagues was Ian Fleming, who would go on to create James Bond.
Many men conspired, if not always deliberately, and many events linked up to induce 
the Admiralty to be content with the 14-in. gun King George V in face of the 15-in. gun 
Bismarck with its greater size, endurance and protection. The error, as it turned out, was 
not fatal—but it might have been, as the official account of the chase of the Bismarck in 
1941 shows. Wishful thinking, that ever lurking temptation for politicians dealing with 
military affairs - and for serving officers involved in politics—is even more conspicuous 
in this episode than in that of the U-boat sinkings.
The story begins with the Anglo-German Naval Treaty of June 1936 which released 
the Germans from the limits set to their navy by the Treaty of Versailles. As this had 
been repudiated by Hitler in March 1935, it was thought wise in London to start afresh 
with the new regime in the hope that the German Navy could be kept to an agreed fixed 
percentage of the British. So the Admiralty argued. Considering the atti­tude towards 
Britain then uppermost in Hitler’s mind, the calculation was not unreasonable; for it is 
now known that he was not planning an early or direct challenge to our naval predomi­
nance in Europe and hoped to avoid war with Britain.
The weakness of the arrangement was that Britain had already been restricted in 
its naval construction by an agree­ment to which the Germans were not parties when 
the Bismarck was laid down—the Washington Naval Agreement and the later London 
conference which had limited battleships to 35,000 tons. If the Germans were to build 
bigger ships, so that two or three or more British major units would be needed to pur­
sue and destroy one of theirs, then the principle of the treaty—which was that German 
strength should never exceed thirty-five per cent of the British—would lose its value. It 
was doubtless on that calculation that Admiral Raeder ordered that the Bismarck and 
Tirpitz should both be of 45,000 tons and deliberately cheated on his Government’s 
undertakings.
1.	
Donald McLachlan, “How to Cheat on Naval Tonnage Treaty Limits, 1919–1939,” Room 39, Atheneum: New 
York, 1968, pp. 134–142.

How to Cheat on Naval Tonnage Treaty Limits 1919–1939
416 
The Art and Science of Military Deception
How precisely was the game played and at what points were the British outwitted? 
On 1 July 1936 the German Embassy informed the Foreign Office in confidence that 
the particulars of battleship F would be 35,000 tons, beam 36 metres (118 ft), calibre 
of largest gun 38 cm. (14.8 in.), mean draft 7.9 metres (26 ft). The Director of Naval 
Construction is on record as commenting (5 September) some weeks later that the large 
beam (15 in. more than that planned for the King George V) was presumably dictated 
by the comparatively shallow draft of the ship, which in turn was made necessary by the 
shallow water in the Kiel Canal and the Baltic. The same month Plans Division in Lon­
don, which had been closely involved in negotiating—and therefore believed in—the 
various treaties limiting naval armaments, made their comment. Captain Tom Phillips, 
later to be Churchill’s first Vice-Chief of Naval Staff, remarked: ‘The present design of 
German capital ships appears to show that Germany is looking towards the Baltic with 
its shallow approaches more than in the past.’ In other words, they felt, these battleships 
might be regarded as aimed more at the Russians than at ourselves. Yet Phillips was by 
nature a sceptical, aggressive man. 
In the German section of NID, however, there were sus­picions of the German fig­
ures, partly inspired by secret reports that they were inaccurate, partly by a reasonable 
assumption that Nazis might lie. But at a meeting to discuss the Bismarck in early 1937 
a split in opinion was revealed between on the one side the technicians, represented by 
the Director of Naval Construction and the NID technical section, and on the other side 
the non-technical officers. The Director of Naval Intelli­gence, with his advisers divided, 
was in no position to be tenacious for scepticism against optimisim; and later that year 
on 5 August DNC wrote:
The figures given are not in themselves sufficient to warrant the conclusion that the standard 
displacement of 35,000 tons is being purposely exceeded . . . From our experience with 
Gorizia it is probable that in these countries the designers are not pressed to be meticulously 
accurate. To put this into more precise terms, taking into account displacement variations 
of completed British ships before displacement by treaty was laid down, the designers of the 
35,000-ton ship would not be blamed if the displacement on com­pletion was 36,000 tons, 
and such a figure would be more in conformity with the length and beam reported than 
35,000 tons.
This reference to the Gorizia should have alerted the Board to the risks of optimism 
about Bismarck. For physical examina­tion of the Italian cruiser while in dock at Gi­
braltar had shown that she had an armoured belt and exceeded the permissible treaty 
10,000 tons by between two and four thousand tons. There was no reason to believe 
that Hitler’s capital ship policy would be notably more honest than Mussolini’s. Yet the 
Director of Plans allowed himself to write: ‘Our principal safeguard against such an 
infraction of treaty obligations lies in the good faith of the signatories’.
Who is to blame Phillips for this attitude when the Whitehall line, set by the politi­
cians and by what they believed to be the mood of the voters, was to hope for the best 
and give the dictators a little more rope to hang themselves? Plans Division’s job was not 
to argue against the treaties, but to make the best plans they could within their limits.
Is the Director of Naval Construction’s department entitled to that particular de­
fence? It appears that the mystery of the Bismarck’s shallow draft was not investigated 
as thoroughly as it should have been by those who were designing and building the 
equivalent British battleships. On the other hand they were hard pressed with the new 

 
How to Cheat on Naval Tonnage Treaty Limits 1919–1939
The Art and Science of Military Deception	
417
programme and deeper probing of the German design would almost certainly not have 
led them to a change in our own designs which would mean breaking treaty limita­
tions. When, in 1941, information from the sur­vivors of the sunk battleship and from 
the Russian Admiralty confirmed NID’s suspicions that Bismarck’s tonnage was nearer 
45,000 than 35,000 tons, it became clear, even to DNC, that the ‘mystery’ of her shal­
low draught was a mystery no more. The Bismarck’s draught was in fact not very dif­
ferent from that of the British capital ships and its shallowness was simply a device to 
give colour to the gross understatement of her dis­placement.
What irked Godfrey at the time was the readiness of his colleague at Bath to believe 
immediately from the Russians something that he would not accept from NID.
From the German naval documents we know what was going on behind the scenes 
in Berlin while the Admiralty hoped and guessed. On 11 February 1937 the Plans Divi­
sion of the German Admiralty wrote to Admiral Raeder:
In view of the difficult conditions in our harbours, a displacement of 42,000 tons should be 
the limit of ships to be built, unless we widen the harbours and channels and also the curves 
of the Kiel Canal. . . . Politically it must be decided if the displacement should be still further 
increased above the treaty limits.
  The Constructional Office considers that no further increase should take place as long as 
we are tied to the 35,000-ton limit which we have already exceeded by 7,000 tons, so that a 
further increase could hardly be concealed . . . The Constructional Office would like to build 
an extra ship rather than exceed the 35,000-ton limit.
  Even if other Navies renounce the limits of the London Agreement or go in for calibres 
above 38 cm . . . we should be reluctant to increase them owing to the state of our channels 
and our Treaty obligations . . . a decision cannot be reached till the various aspects including 
the military factors and the clauses of the Treaty have been considered.
Here, clearly, someone was trying to be honest; but the argument which counted in 
his mind was the technical rather than the moral one. Indeed, the morals of the matter 
were not his business.
For German Plans Division it was a different matter. They stated in a memorandum 
to the Chief of Staff dated 18 February 1938 that the Bismarck’s true displacement 
was twenty per cent greater than that announced to the British; but they argued that 
it would be wrong to indicate a greater tonnage than had already been announced to 
Britain, Russia and Japan because ‘we shall be accused of starting an armament race’.
What, then, was the British Naval Attache doing? Was he too misled and if so, by 
what methods? Were the suspicions of NID due to anything reported by him? On 23 
December 1936 the yearly report of Captain Troubridge, Naval Attache in Berlin, to the 
Foreign Office (copies to DNI and C-in-C Home Fleet) said:
The Anglo-German naval agreement was one of the master strokes of policy which have 
characterized Germany’s dealings with her ex-enemies since the war. When the time is ripe, 
as history shows, it will unquestionably go the same way as other agreements: but the time 
is not yet.
The italic passage was omitted from the printed version of the Ambassador’s annual 
report (Sir E. Phipps to Mr. Eden dated 12 January 1937 C357/357/18) and the Direc­
tor of Plans already mentioned in this chapter, Captain Phillips, wrote a minute on 1 
January 1937 on the NID docket sent to him with Troubridge’s unexpurgated report:   

How to Cheat on Naval Tonnage Treaty Limits 1919–1939
418 
The Art and Science of Military Deception
‘It would be of particular interest to know the basis for the very definite statement on 
page 2 of the memorandum.’
This general expression of scepticism seems to be as far as Troubridge got and there 
is no doubt that the intelligence coming to the Admiralty from Germany was thin and 
poor. Why that should have been so is not clear; the Nazis after 1934 never tried to 
conceal their successful rearmament and were always anxious to show what they could 
do. For example, the French Air Attache, Stehlin, was given the fullest opportunity to 
see what the Luftwaffe would be able to do to France (see Chapter 15). It seems likely 
that the Secret Service was not specially pressed to find out the state of German naval 
building just because of the official optimism about the working of the treaty.
Ten years later, Troubridge was asked by Godfrey if he could explain how we had 
been so misled and he wrote as follows:
••
I fancy that generally speaking the reason that we were ‘fooled’ by the Germans, 
both as regards submarines and the battleship tonnage, was that we were inclined 
at the time (after the Anglo- German agreement) to trust them in these matters.
••
I confess that Raeder’s earnestness and apparent sincerity, assuring me that Ger­
many meant to adhere strictly to the agree­ment, may well have influenced DNI 
when my reports of these interviews came through. I started my time pretty well 
open-minded, though having studied Great Britain and the German Navy by Wood­
ward, I was pretty well on my guard.
••
As evidence of my state of mind in 1936 I mentioned in the NA’s annual report, 
which is annexed to the annual report of the Ambas­sador, something to the effect 
that the Anglo-German naval agreement remains the cornerstone of German naval 
policy. It will unquestionably be torn up when the moment seems propitious, but 
the time is not yet.
The boys in the Chancery refused to put this paragraph in, but it will remain on 
the record none the less in the copy sent to DNI and Commander in Chief Home Fleet.
Doubt about the tonnage of the Bismarck came shortly after the launching, when 
information from Williams, the vice-consul in Hamburg, indicated that she was draw­
ing a good deal more than she should.
That Raeder lied to me and also to my predecessor is undeniable. Muirhead-Gould 
[Naval Attache Berlin before Troubridge] always said he had, but I fear I was lulled to 
a certain extent by his apparent sincerity. Moreover I found it hard to understand why 
he found it necessary. But then to understand is to understand the tortuous workings of 
the Teutonic mind. Sometimes they lie just for the sake of lying. 
It will be interesting to see, when the records are opened, whether historians can 
find out the reason for this significant excision by Sir Eric Phipps from his Naval Atta­
che’s despatch. The fairest presumption is that he thought his subordinate should stick 
to naval facts and abstain from political generaliza­tion.
The lies, the realities and the contrast between them are most easily grasped in 
tabular form on p. 141.  
The mistakes and omissions here recorded were made for the most part in the pre-
war NID which faced difficulties of getting information and staff which have been 
described elsewhere. But there is this to be said in their defence. The Naval Staff in 
peacetime were strongly disinclined to accept from their intelli­gence advisers any views 

 
How to Cheat on Naval Tonnage Treaty Limits 1919–1939
The Art and Science of Military Deception	
419
or facts that might be ‘awkward’, that is to say, in sharp conflict with current strategic 
doctrine or political appreciation.  They probably felt that if Germany was in fact cheat­
ing and could be proved treacherous, no one in the Foreign Office or Downing Street 
would handle the accusation effectively; why then make it? 
But there seems too to have been reluctance among our own technical experts to 
believe that the Bismarck could combine the high speed, long endurance and good 
protection with the mounting of 15-inch guns; just as there was reluctance to believe 
that U-boats could dive as deep as they did dive, or that under­water speed could be 
increased to the degree that it was by 1944. Perhaps the British underrated the tremen­
dous advan­tages of starting again, as the Germans did, from scratch and were inhibited 
by too many decisions already taken and too many economies rigidly enforced. Be that 
as it may, they were disinclined to listen to uncomfortable truths of intelligence. Godfrey 
himself looks back on this episode as illustrating three lessons for the craft:
1.	 The unwillingness of authority to believe information that has awkward political 
implications.
2.	 The tendency of naval officers and others who have taken part in negotiations to 
become advocates of the integrity of the persons with whom they secured agree­
ment, and to lose the scepticism which is part of vigilance.
3.	 Our technicians may not be the best judges of enemy intentions and achievement. They find 
it hard sometimes to believe that what they cannot do or have not thought of doing has 
been done by the other side.
Facts about the Bismarck
Authority
German Embassy 
Official Statement
Bismarck survivors 
and notebook
Russian Admiralty
German Records
King George V
Apr.  39
Oct.  41
Oct. 42
Oct. 44
Displacement
Length
Beam
Draft
H.P.
Armament
Thickest armour
Full speed
Endurance
Fuel stowage
35,000*
792
118
26
80,000
8-15"
9"
27
?
?
41,150*
792
118
33 ¾
150,000
8-15"
13"
30¼
?
?
45,000
792
118
34
150,000
8-15"
13"
30¼
17,500 miles
   at 18kn
8,500 tons
53,000†
45,000*
792
118
34
150,000
8-15"
12½
30¼
17,500 miles
    at 18kn
8,500 tons
35,000
745
103
34
111,000
10-14"
15"
28¼
14,500 miles
   at 10kn
3,860 tons
*Standard displacement.
† Full load.
Definitions:
Full load displacement with all oil stores, ammunitions, etc., on board vessel fully equipped and ready for sea.  
Standard displacement—as for full load, but excluding all fuel and reserve feed water. 
Normal displacement—figures may differ in different countries but generally cover the condition of vessel fully equipped and ready for sea but with a portion 
only of stores, fuel and reserve feed water. 


421
C H A P T E R  4 6
Harwood and the First Deception of WWII, 19391
A Book Review by Frank Stech
Eric Grove’s superbly researched and written “The Price of Disobedience” recounts the 
first major naval battle of World War Two. This British victory hinged on the first major 
deception of the war.
The German Panzerschiff (pocket battleships) Deutschland and Graf Spee were at 
sea when war broke out in September 1939. Deutschland sank two ships in the North 
Atlantic, then was ordered to return to German waters. Graf Spee headed to Cape Horn 
and began sinking British shipping in both the South Pacific and South Atlantic. By 
December 1939, Graf Spee had sunk nine British ships.
Captain Harry Harwood, commanding the British cruisers Exeter, Ajax, and Achil­
les, used some remarkable deduction and found Graf Spee off Uruguay. His ships en­
gaged on 13 December 1939. Exeter, severely damaged, was sent back to the Falklands, 
two of Ajax’s four turrets were disabled, and the magazines of Harwood’s squadron 
were down to a seventh of their ammunition.
Graf Spee, hit over twenty times, was seriously damaged and her captain, Hans 
Langsdorff, ran her up the neutral River Plate to Montevideo, where Langsdorff hoped 
to make repairs. Harwood summoned the cruiser Cumberland to join the squadron at 
the mouth of the Plate, while the Admiralty ordered the battleship Renown, the carrier 
Ark Royal, and an escort of cruisers and destroyers to sortie from Cape Town to rein­
force Harwood.
Churchill, as First Lord, orchestrated the British and neutral press coverage of the 
engagement to deceive Lansdorff and the Kriegsmarine into believing Graf Spee was 
bottled up, by not just Harwood’s hors de combat squadron, but the Renown battle 
group, soon to be joined by the French battleship, Dunkerque. The New York Times’ 
front-page headlines claimed a “reinforced allied fleet” awaited the Graf Spee. Rumors 
were circulated and printed that Renown and Ark Royal had refueled in Rio de Janeiro 
(when the British ships were 2,500 miles away). In German-leaning Argentina, the two 
largest newspapers quoted “reliable sources” that “more than five cruisers were wait­
ing” for Graf Spee.
Uruguay (“England’s butcher”) heavily favored British interests and, refusing 
Langsdorff’s pleas for repair and resupply, Uruguay ordered the Graf Spee to sail under 
the neutrality rules, i.e., in forty-eight hours. The British, however, wished Graf Spee 
to remain in Montevideo until the Renown battle group had reinforced Harwood. The 
British naval attaché ordered a British merchantman to depart Montevideo. Under in­
ternational law, Graf Spee could not follow an adversary’s departure for 24 hours. The 
British attaché stretched out British sailings over several days (until the Uruguayans 
1.	
Frank Stech, “Harwood and the First Deception of WWII, 1939,” Amazon review March 18, 2004. http://www.
amazon.com/review/R35UPIBTP5430Q. Review of Eric Grove, The Price of Disobedience, Annapolis: US Naval 
Institute Press, 2001.

Harwood and the First Deception of WWII, 1939
422 
The Art and Science of Military Deception
caught onto his ruse) and used clever diplomacy to trap Langsdorff and the Graf Spee 
in Montevideo.
Meanwhile, Harwood skillfully maneuvered in the approaches to the Plate and sig­
naled to Cumberland as if she were the Renown battle group, while the BBC broadcast 
an ongoing account of the mythical fleet waiting the trapped German Panzerschiff. 
Masthead spotters on Graf Spee reported the Cumberland’s rigging as Renown, which 
the German attaché in Buenos Aires “confirmed,” having fallen for the deceptive refuel­
ing story. The BBC vividly reported Ark Royal (still far distant) joining Harwood, and 
the German spotters on Graf Spee, expecting to see the British carrier, did. The BBC 
reported Dunkerque and a second British battleship would soon join Ark Royal and 
Renown.
Langsdorff believed the Graf Spee was doomed. Hitler ordered Langsdorff not to 
allow the ship to be interned, and to breakout or scuttle. Langsdorff scuttled her. When 
he and the German crew arrived in Buenos Aires, Langsdorff learned the Ark Royal 
and Renown had just reached Rio, over 1,000 miles from where Graf Spee lay scut­
tled. Knowing Hitler’s likely reactions to his obedience, Langsdorff wrapped himself in 
the Kriegsmarine’s ensign and shot himself. Pictures of the burning scuttled Graf Spee 
circled the world. So did news of Langsdorff’s suicide. The Battle of the River Plate, 
the first great naval victory for the Allies, resulted from highly skilled and coordinated 
naval deception.

423
Section XII: 
Air War


425
C H A P T E R  4 7
MiG Sweep—Operation BOLO1
Colonel Walter J. Boyne
Colonel Walter J. Boyne received his wings as a Second Lieutenant in the United States 
Air Force in 1952.  Boyne flew the B-50 Superfortress as a member of the 330th Bomb 
Squadron of the 93rd Bomb Wing and was then trained to fly B-47 Stratojet.  In 1957, 
Boyne returned to school earning a Master’s degree from the University of Pittsburgh.   
Boyne then returned to flying as a test pilot with the 4925th Nuclear Test Group.  Upon 
his retirement in 1974, he had a prolific writing career, publishing over 50 books and 
1,000 magazine articles.
1.	
Colonel Walter J. Boyne, “MiG Sweep – Operation BOLO,” Air Force Magazine, Vol. 81, No. 11, November 
1998, pp. 46–51. Reprinted by permission of the Air Force Association. 

MiG Sweep—Operation BOLO
426 
The Art and Science of Military Deception

 
MiG Sweep—Operation BOLO
The Art and Science of Military Deception	
427

MiG Sweep—Operation BOLO
428 
The Art and Science of Military Deception

 
MiG Sweep—Operation BOLO
The Art and Science of Military Deception	
429

MiG Sweep—Operation BOLO
430 
The Art and Science of Military Deception

 
MiG Sweep—Operation BOLO
The Art and Science of Military Deception	
431


433
C H A P T E R  4 8
Aerial Deception since the Second World War1
Jon Latimer
Jon Latimer served for sixteen years with the Royal Monmouthshire Royal Engineers, 
the Royal Welch Fusiliers, and the Royal Regiment of Wales, as platoon commander, 
assault troop leader, and battalion intelligence officer. He has been published widely in 
military journals, and is also the author of “Operation Compass 1940” and, with Jim 
Laurier, “Tobruk 1941”. He lives in Wales.
Tactical deception and developments in electronic warfare made a considerable con­
tribution to Allied success in the Second World War and saved countless aircrew lives.  
Perhaps more significantly, air units were formed for the first time and equipped specifi­
cally to carry out this role.  As is so often the case, these lessons were quickly forgotten in 
the immediate aftermath of the war, but were then revived and developed, and since the 
war there have been phenomenal developments in both aircraft and sophisticated avion­
ics systems.  Aircraft themselves are faster and more powerful, ranging from fast agile 
fighters through versatile multi-role fighter-bombers to the colossal B-52 bomber, which 
dwarfs the Lancaster and Super Fortress of the Second World War.  More significantly, 
aerial warfare no longer involves getting as close as possible to one’s target in order to 
shoot directly at it with cannon or machine-guns, or to lob free-fall bombs.  Instead, it 
relies on sophisticated missile technology, based on radar or infra-red systems.  Similar 
systems now equip ground-based air defense units and tactics have been transformed, 
leading in turn to defensive flares and chaff (bundles of WINDOW) to act as decoys 
and draw off attacking missiles.  Flying at low altitude and high speeds may put aircraft 
under effective radar cover, but also makes them vulnerable to ground fire. 
The development of ‘Wild Weasel’ electronic counter-measure aircraft led to spe­
cially equipped fighter-bomber units, designed to seek out and destroy enemy radar-
controlled gun and missile systems in a role called Suppression of Enemy Air Defense 
(SEAD).  If an enemy radar is activated, it can be located and attacked with anti-radia­
tion missiles that home in on radar emissions.  Since the Vietnam War such units have 
formed a crucial element in securing control of the air.  More recently, so-called ‘stealth’ 
technology has been designed to make aircraft radar ‘invisible’, using radar-absorbent 
materials, carefully designed shapes and ‘cancellation’ technology (avionics that predict 
an aircraft’s reflective signal at a given frequency and angle in order to transmit a signal 
which will cancel the signature).  ‘Stealth’ technology also includes techniques to mask 
1.	
Jon Latimer, Deception in War: The Art of the Bluff, The Value of Deceit, and the Most Thrilling Episodes of Cun­
ning in Military History, from the Trojan Horse to the Gulf War, UK: Overlook, 2003, pp. 202–204.  Reprinted by 
permission of Overlook Press. 

Aerial Deception since the Second World War
434 
The Art and Science of Military Deception
sound and infra-red sources such as engine exhausts.  Although the primary threat was 
seen for a long time as being from radar-guided weapons, a US Department of Defense 
study showed that in the ten years to 1985 ninety per cent of tactical aircraft destroyed 
were victims of infra-red systems.  Such technology is increasingly being applied to 
land and naval units while towed decoys, in use at sea since the 1940s as a method of 
countering acoustic torpedoes, have been adopted since the 1980s in the form of a small 
radar jammer towed behind an aircraft.  However, counter-‘stealth’ techniques were 
soon identified, since it seems likely to continue for many years to come.  

435
C H A P T E R  4 9
Detection of the B-2 Bomber and a Brief History 
on ‘Stealth’1
Tao Yue
This article is a handy unclassified introduction to stealth and its real and potential anti-
stealth countermeasures, including bi-static radar which was undergoing development 
since 1997 by the British firm of Roke Manor Research.
Tao Yue, then a staff writer for the MIT student weekly periodical, took degrees 
in both Electrical Engineering and Computer Science and Mathematics in 2004 and 
Masters degrees from the University of Washington and Princeton University.  He has 
done work in various fields of computing, including multi-tier applications, graphics, 
and computational biology.  In 2001, he investigated the feasibility of counter-stealth 
technologies for The Tech, the MIT student newspaper. 
Scouting for Surveillance
Detection of the B-2 Stealth Bomber and a Brief History on “Stealth”
“Cell phones uncover stealth bombers.” 
In early June, the news was filled with such headlines. Newspapers put them at the 
top of the front page, magazines printed colorful diagrams, and television networks ran 
the story as the lead on their evening news broadcasts. 
And why not? The story was irresistible. Stealth technology is the most potent sym­
bol of America’s military supremacy in the post-Cold War world. Though other nations 
have worked on similar technology, thus far none have been as successful as the United 
States. That something as commonplace as cellular telephones could bring down this 
symbol of America’s military-industrial complex was simply too ironic for the media 
to resist. In news stories, the technology was described as new and revolutionary, with 
numerous analogies to David and Goliath. 
Within a week, though, the story had practically disappeared from the media. The 
U.S. military did not launch a crash program to counter this threat. No cellphone-based 
stealth detection systems were sold.
We are left wondering: “What happened?” 
Overview of stealth technology 
Stealth technology was originally developed at Lockheed Martin’s legendary Skunk 
Works research facility. The group had designed a number of pioneering military aircraft: 
1.	
Tao Yue, “Scouting for Surveillance: Detection of the B-2 Bomber and a Brief History on “Stealth”, The Tech, 
November 30, 2001.

Detection of the B-2 Bomber and a Brief History on ‘Stealth’
436 
The Art and Science of Military Deception
the P-80, America’s first jet fighter; the U-2, a high-altitude reconnaissance aircraft that 
photographed Soviet nuclear missile installations in Cuba in 1962; the SR-71, which re­
mains the fastest operational jet aircraft ever built; and of course, the F-117 Nighthawk, 
the Stealth Fighter.
Long before the Stealth Fighter’s existence was acknowledged publicly, rumors 
about its capabilities had been circulating in the aerospace and defense community. 
Tom Clancy featured the Stealth Fighter prominently in his novel Red Storm Rising, a 
political-military thriller describing a conventional war between the Warsaw Pact and 
NATO. Testors, maker of accurate scale models of cars, ships, and aircraft, felt confi­
dent enough of the Stealth Fighter’s existence to sell a model, based upon alleged sight­
ings. Experts agreed that the fighter would be known as the F-19, the next available 
number in the aircraft designation system.
When the F-117 was finally revealed, observers were surprised by more than just its 
unexpected designation. The plane simply didn’t look like a modern jet fighter. Instead 
of a sleek, aerodynamic profile optimized for supersonic performance, the F-117 was 
blocky and featured many flat surfaces. Its wing was swept back so sharply that the 
plane had difficulty developing enough lift to take off. 
There was a reason for this strange shape. Stealth technology had begun with coat­
ings that reflect less radar than the aluminum commonly used on airplanes. Indeed, the 
now thirty-year-old SR-71 reconnaissance aircraft had already made use of radar-absor­
bent coatings to reduce the risk of detection. But there is no material that would absorb 
radar perfectly. Skunk Works took the concept of stealth one step further, designing a 
shape for the F-117 that would reflect a radar beam in a different direction rather than 
back towards the transmitter.
Due to the limited computing power available in the 1970s, the plane was designed 
with flat surfaces to reduce the number of calculations required. Since each additional 
surface would add an extra direction in which radar could be reflected, the number of 
surfaces used was also kept to a minimum. The strange shape made the plane aerody­
namically unstable about all three axes, so fly-by-wire capability was required to allow 
the pilot to control the airplane. Stealth had to be built into all aspects of the airplane’s 
design: enclosed bomb bays, special pilot canopies, special seals at all joints, and special 
cooling vents for the engines.
The F-117 had a radar signature about 1/100 that of conventional airplanes, mak­
ing it appear little larger than a bird on radar scopes. The B-2 Stealth Bomber, the 
next stealth airplane in America’s arsenal, benefited from the greater computing power 
available by using a complex curved shape that further reduced its radar signature. The 
newest stealth fighter on the drawing board, the F-22, uses a still more advanced shape. 
Potential vulnerabilities
Stealth required years of research and massive computing power to develop. Defeating 
stealth was a correspondingly daunting task. F-117 Stealth Fighters flew over 1300 sor­
ties in the Gulf War without a single one being shot down. No stealth aircraft was lost 
in combat until 1999, when Yugoslav forces shot one down in Kosovo. This feat was, 
however, not repeated. 
From the beginning, though, it has been recognized that stealth does not make 
an airplane invulnerable to detection. An airplane may be detected not only by radar, 
but also by other means. Stealth aircraft typically do not use radar or send any radio 

 
Detection of the B-2 Bomber and a Brief History on ‘Stealth’
The Art and Science of Military Deception	
437
communications while in combat, in order to avoid detection by passive radio receiv­
ers. Stealth aircraft can be picked up visually in the daytime, making them usable only 
at night. Engine exhaust, though cooled to minimize the aircraft’s infrared signature, 
is nevertheless hotter than the ambient air.  It was this vulnerability that permitted 
Russian-made SA-3 infrared air-to-air missiles to lock onto the F-117 shot down over 
Yugoslavia.
Those problems can be solved operationally, though, by limiting the use of stealth 
warplanes to favorable military situations. A more serious problem is the inherent im­
perfection of the airplane’s surfaces. No matter how precisely they are manufactured, 
they will degrade naturally during flight as a consequence of atmospheric friction. Dust 
will collect on the aircraft and begin to reflect radar.  Rain will damage the radar-absor­
bent material.  Care must be taken to repair nicks and scratches, and to seal joints where 
one manufactured part is attached to another. However, these tasks must be performed 
by maintenance crews working under a great deal of time pressure to get each plane out 
for another attack run. All of these factors contribute to the fact that a stealth plane will 
always reflect some amount of radar. 
The Roke Manor system 
The stealth-detection system announced over the summer was developed at Roke Manor 
Research, a British defense firm based in Romsey, Hampshire in the United Kingdom. It 
does not try to detect emissions from careless stealth aircraft, which would be an easily-
countered move. Instead, the Roke Manor system attacks the foundations of stealth 
technology by detecting the radar waves that inevitably will reflect off it.
John Hansman, a professor of Aeronautics and Astronautics at MIT, explains, 
“Some stealth aircraft, like the F-117, are specifically designed to have a low radar cross 
section to monostatic, or conventional, radars. They are not stealthy to some bi-static 
configurations.” 
Conventional monostatic radar places the transmitter and receiver in the same loca­
tion. This makes it a trivial problem to calculate an aircraft’s position from the time and 
angle of the return signal. Bi-static or multi-static radar would position the receiver at a 
different position from the transmitter. Since stealth aircraft do reflect some radar signal 
and intentionally direct it away from the transmitter, bi-static radar could conceivably 
receive the reflection and detect the stealth aircraft.
The problem then becomes one of scale and coordination. The stealth aircraft will 
be visible only if an ideal alignment exists so that the transmitter bounces a signal off the 
stealth aircraft to the receiver. Stealth aircraft, however, are vulnerable from a very small 
subset of angles. It would be prohibitively expensive to build an enormous number of 
radar sites to obtain adequate angular coverage of stealth aircraft.
The Roke Manor system solves this problem with computing power and some cre­
ative thinking. Radar is simply a specialized application of radio, and we now live in a 
wireless age in which radio waves are ever-present. Notably, industrialized nations now 
have cell phone towers every few miles, sometimes every hundred feet in particularly 
populous areas. Telephone companies know where the towers are located and also have 
telephone lines hooked up to them.
In effect, the Roke Manor researchers have envisioned the use of cell phone towers 
as an extremely dense network of radar transmitters and receivers, interconnected via 

Detection of the B-2 Bomber and a Brief History on ‘Stealth’
438 
The Art and Science of Military Deception
communications links. The sheer quantity of cell phone towers makes detection much 
more likely than with dedicated but less-numerous radar sites. 
“A lot of stealth technology deals with redirecting radar waves,” said Greg Duck­
worth, a Principal Scientist at BBN working on underwater acoustics in an area very 
much analogous to radar.” It’s very effective against monostatic radars. However, if you 
have bistatic radars, in particular a very large number of sources, so that you excite the 
target from a wide range of angles, and you have a multiplicity of receivers in many 
locations, you essentially will get around the stealth target’s redirection capabilities. It 
is highly likely that an incident wave from a cell tower will be redirected towards one 
or more receivers.” 
Having invalidated the assumptions behind the stealth aircraft’s shape, the multi-
static radar system then pieces together all the data from the cell phone towers. Until 
recently, this problem would have been insurmountable. However, increased computa­
tional power and advanced signal processing techniques have made it possible to sort 
through all the signals and form a coherent radar picture. Ironically, the further devel­
opment of the same computing technology that originally made stealth possible has 
now made it possible to detect stealth aircraft. 
A natural technological progression
Given a dense cell phone network, massively parallel computers, and the Roke Manor 
software, how much can one determine about a plane? Quite a bit, as it turns out. 
“If you can get a radar return, you can get all kinds of information from the return 
signal if you can process it sufficiently,” Hansman said. “For example, if you look at 
the Doppler shift of the returned signal, you can get aircraft velocity. If you are sensitive 
enough, you can see frequency effects, such as engine rotation or structural vibration. If 
you have several receivers or different imaging angles, you can begin to reconstruct an 
image of the target.” 
These data further reduce the effectiveness of stealth technology. While stealth has 
always returned a small signal, even to monostatic radars, that signal is so small that 
it is usually filtered out either by the radar scope or by the operator. The intermittent 
nature of the monostatic radar contact also makes it difficult to calculate velocity. How­
ever, ubiquitous radio coverage makes it likely that stealth airplanes can be tracked, 
complete with velocity and shape information. This makes it considerably easier to 
distinguish stealth aircraft from birds in the sky. 
Ernie Rockwood, a researcher for Sensis Corporation, a company that specializes in 
air traffic and air defense, said that he was “not surprised” by this development. “Some 
of my co-workers and I worked on novel bistatic battlefield radar techniques to improve 
survivability. We also submitted a proposal to Rome Labs for an operational concept 
using multistatic techniques.” 
Defense researchers generally agree that the technology is sound. Some believe this 
to be a natural development in radar technology. 
“Underwater, they’ve already gone to multistatic systems because the reflectivity of 
targets is such that they don’t naturally bounce stuff back,” said Greg Duckworth. “Not 
because they tried to, as was the case with stealth technology, but because the physics 
makes them do that naturally.” 
Duckworth also drew an analogy between cell phone towers and television 
transmissions. 

 
Detection of the B-2 Bomber and a Brief History on ‘Stealth’
The Art and Science of Military Deception	
439
“Televisions have improved quite a bit, and comb filters have gotten better,” said 
Duckworth. “On older TV sets, though, when an airplane goes over your house, a re­
flective wave from the aircraft ends up interfering at your antenna, and you see lines and 
artifacts on your screen. To the extent that a stealth aircraft does not absorb the wave, 
the remnants of it still interact with the airplane and result in detectable interference 
patterns.” 
The television analogy is particularly apt, as Lockheed has been working on a proj­
ect that operates on the same principles as Roke Manor’s anti-stealth system. In this 
project, called Silent Sentry, FM radio stations and VHF television broadcasts are used 
to provide the dense network of radio waves that interacts with stealth aircraft. While 
there are fewer FM and VHF transmission towers than cell phone towers, each indi­
vidual station transmits with greater power. The smaller number of stations would also 
reduce the computational requirements of the system. 
Military consequences
How far-reaching are the implication of this anti-stealth technology? As with all military 
technologies, it depends on the particular application. 
Owen Cote, Associate Director and Principal Research Scientist of MIT’s Security 
Studies Program, explained, “Even if this system works, it wouldn’t be useful if you 
couldn’t shoot the aircraft down. You’d have to find some way of guiding a missile very 
close to the target before an infrared or illuminating radar could achieve a lock on the 
aircraft.” 
“This is not very mobile technology,” he continued. “Your cell phone towers are 
in fixed locations. While it would be close to impossible to destroy them all, they are 
susceptible to jamming just like conventional radar. Stealth might very well be a tech­
nology with a very short half-life. However, against foes such as Serbia or Iraq whose 
technology is not yet competitive with ours, I see stealth as having a much longer life. 
As a proof of concept, this bistatic technology sounds right. The actual implementation, 
though, is another matter.” 
Still, Dr. Cote saw some long-term effects of a successful system. “No offensive 
advantage lasts,” he said. “Often there is a relatively cheap defense counter to match 
new offensive technology. We may find ourselves moving further away from manned 
delivery platforms and focusing more on cruise missiles, tactical ballistic missiles, and 
short-range missiles with incredible accuracy.” 
The technology is widely acknowledged to be feasible, and Roke Manor claims to 
have working prototypes. However, bistatic radar is neither a miracle nor a disaster that 
renders worthless decades of stealth research. It is yet another battle in the ongoing war 
between armaments and armor.


441
Section XIII: 
Ground War: Theory and Practice


443
C H A P T E R  5 0
Night Action by Gideon at Moreh—Perhaps 
1249 B.C.1
Colonel A.P. Wavell
General Archibald Wavell was born in Colchester in 1883, and gained his commission 
in 1901.  He fought at the Battle of Ypres, where he lost his left eye.  After the injury he 
remained active, and went on to create the Middle East Command, charged with pro­
tecting the Suez Canal and the nearby oil reserves.  Wavell also served as Commander-
in-Chief of British troops in India.  After Pearl Harbor, the primary task was to protect 
British territories against Japanese attack.   In July of 1943, Wavell was made the 1st 
Earl of Cyrenaica and retired in 1947.
Except that I had to substitute science for divine inspiration, I worked somewhat along the 
same lines as Gideon.
—General Duncan in The Cavalry Went Through
All that we know of Gideon, son of Joash, warrior and statesman, is contained in three 
chapters of the Bible—Judges vi to viii. But the record of his character and actions 
given in those chapters is sufficient to rank him very high: with the possible exception 
of Joshua, he was the best general and shrewdest head of State that Israel ever brought 
forth.2 And he was no mere rough soldier. His reply to the men of Ephraim (Judges viii. 
2) could not have been bettered by the sleekest and readiest diplomat that ever purred 
French; while his dealings with the “non-cooperators” of Succoth and Penuel show 
that his diplomacy masked no weakness when he had to do with insolence and disaf­
fection amongst his own people or tributaries. Wiser than Saul, he refused the crown 
of a hereditary Kingdom which the Israelites offered him. Of his talents as a soldier we 
can judge from the account of how he carried out two of the most testing operations of 
war—a night attack and a sustained pursuit. His brilliant execution of these prove that 
his skill and determination were those of a really great captain.
And now to paint the picture of the opening situation (as umpires and directors 
of tactical exercises say) for his night attack. Gideon’s enemies, the Midianites, nomad 
Arabs of the desert, probably differed very slightly indeed from their descendants of 
today. Sheik Faisal ed Dowlish, whose activities on the Iraq border our Air Force has 
lately been engaged in curbing, is direct in tradition from Gideon’s opponents, Zebah 
and Zalmunna, gallant caterans who met their end unflinching. And the story of Israel’s 
1.	
This is the date given by the learned Dr. Angus, who is just as likely to be wrong as any of the many others who 
have tried their hand at Old Testament chronology; Colonel A.P. Wavell, “Night Action of Moreh—circa 1249 
BC.”  Wavell retells the story of Gideon’s deception of the Midianites.
2.	
After which judgment, it is a little disconcerting to turn to St. Paul’s catalogue of famous and faithful worthies of 
old (see Hebrews, chapter xi). He gives that frivolous but resourceful lady, Rahab, a verse to herself, while Gideon 
comes only in the “amongst-others-present-we-noticed” class. Paul’s catalogue need not be taken too seriously, 
however. It omits Joshua altogether. Paul was probably writing in haste to catch the last post to the Hebrews.]

Night Action by Gideon at Moreh—Perhaps 1249 B.C.
444 
The Art and Science of Military Deception
subjection to the Midianites has been common form round the borders of the Arabian 
desert for centuries. A raid or two by the nomads into the cultivated lands finds the 
settled peoples weak and divided, the gendarmerie and frontier guards inefficient and 
timidly handled. The raiders grow bolder and more numerous (some failure of pasture 
in the desert may urge them on) until at last the various tribes sink their differences, 
unite for once, and come up in the springtime “like grass-hoppers for multitude,” with 
their tents and their cattle and their camels (just as described in Judges vi. 5) to eat up 
the pasture and the crops in the settled land.
The camp of the Midianites was pitched in the eastern part of the great plain of 
Esdraelon (not far from the modern El Afule, where Allenby’s horsemen cut the Turkish 
communications). We must conceive of it as a laager rather than as a fortified camp, of 
the Midianites as armed guards to their cattle and camels rather than as an organized 
force, of their object as to pasture themselves and their beasts on the unaccustomed 
plenty rather than as to fight. It was, in fact, more of a gigantic annual picnic, than an 
invasion. But it was a serious matter to the Israelites. Gideon’s men occupied the west­
ern end of Mount Gilboa on the hills to the south. The battlefield is almost the same as 
that on which Saul was routed and slain by the Philistines some two hundred years later. 
In all fighting in Palestine, water plays a chief part.
And it was so here. The only water available for the Israelites lay at the foot of the 
hills on which they had taken up their position, and thus close to their enemy. This 
explains the fitness of the test by which Gideon chose his three hundred (the same 
number, it may be noted, as made history under Leonidas at Thermopylae). The major­
ity of his men, parched by the heat on the bare, rocky hills, flung themselves down full 
length by the stream when their opportunity came, and drank heedless and careless. 
Only the seasoned warrior, with experience of snipers and ambushes, kept his weapon 
in one hand and his eyes towards his foes, while he dipped the other hand in the water 
and lapped from it, ready for action at the slightest sign of danger. Gideon must have 
sorely felt the need of these trained warriors. The motley levy that had flocked to his 
standard3 can hardly have inspired him with much confidence. Remember that for seven 
years the Israelites had hidden in the hills when the Midianites invaded the lowlands 
they had sown; that more than two-thirds of his original gathering had already shown 
that they had no stomach for the fight (Judges vii. 3); and that Gideon was an unproved 
commander and a man of no particular weight or influence (see Judges vi. 15). He had 
soon realized that his Army was no fit instrument for a pitched battle, and that he must 
depend on stratagem and guile for success rather than on numbers. It was comforting 
to find even three hundred seasoned men whose discipline and steadiness he could trust.
But the mortar that bound together the various clans of his enemy was also loose 
and weak. The Arab of the desert is a guerilla, an irregular, accustomed to fight in small 
bodies with plenty of manoeuvre room. The cramped conditions of battle within the 
great Midianitish host must have given him a feeling of unease akin to claustrophobia. 
Close-order was not his style of fighting at all. Nor did religious fanaticism impel him to 
rush fiercely on his foes; he had still to wait some two thousand years for his revelation 
and his prophet, for his Paradise and his dark­eyed houris. So that when tales began to 
float down to the Midianite camp (as Gideon took good care that they should) of the 
3.	
Any one now remember the speech of a well-known member of the Government some years before the War, who 
asked “what need there could be of compulsory service for Home Defence? On the day that a German Army sets 
foot in England, said he, the people of this country will “flock to arms” without any compulsion.

 
Night Action by Gideon at Moreh—Perhaps 1249 B.C.
The Art and Science of Military Deception	
445
marvellous signs and portents that had marked the rise of the Israelites’ new national 
leader, they fell on nervously receptive minds. Manured by rumour, panic once sown 
would spring like mushrooms from such soil.
To return to Gideon. His whole plan was based on the possibility of creating such 
panic in his enemy’s ranks. He prepared his attack, as all night attacks must be pre­
pared, with the greatest care and attention to detail. First he organized his force. He 
divided the three hundred into three companies, which were doubtless subdivided into 
platoons. The remainder he sent off—the Book says “Every man to his tent”—but, as 
subsequent events showed, he must at least have arranged for a part to hold the fords 
of Jordan and to complete the discomfiture of the enemy, once the three hundred had 
got him on the run. Gideon’s next care was the issue of equipment—to every man a 
trumpet, a pitcher and a torch, strange weapons to cause so complete a rout. Then he 
made his personal reconnaissance, taking with him his batman Phurar (who probably 
acted also as battalion runner). This reconnaissance showed him that the hostile pa­
trols were inactive, while the nervous talk he overheard amongst the outposts proved 
that the Midianites were ripe for panic. He now returned, issued his final orders, and 
gave out the famous password, “The sword of the Lord and Gideon.” Each man lit his 
torch and carefully concealed it within the pitcher, so that no light could give away the 
movement until the critical moment; slung his trumpet ready to hand, and grasped his 
sword or spear. So the companies moved off, on an accurately worked out time-table, to 
their appointed stations round the enemy’s camp. Gideon’s signal was to be given about 
midnight, at which time, it had been ascertained, the Midianites were in the habit of 
changing sentries (“they had but newly set the watch”—Judges vii. 19).
The success of the stratagem was complete. The startled Arabs suddenly found 
themselves, as they imagined, beset by a host on every side. Panic spread; the loose co­
hesion of the undisciplined horde broke up; and tribe fought tribe in the darkness, with 
those shattering trumpets, those waving torches and that exultant battle-cry all around 
them. There was no need for the three hundred to strike a blow; they stood where they 
were while their enemies fought each other and fled.4
Slaughter overtook the demoralized Arabs in their flight, for Israel had seven long 
years of oppression to avenge, and the whole countryside rose now that their enemies 
were on the run. And when the remnant with their leaders had, as they thought, outdis­
tanced the pursuit and were secure, Gideon, relentless and untiring, fell on them again 
and completed their disaster. So that “the day of Midian” became a proverb in Israel 
for completeness of victory.5 
The principles on which Gideon acted—the value of training and discipline in work 
at night, the need for attention to detail, the importance of personal reconnaissance, the 
moral effect of a night surprise—are all still valid to-day.
A close parallel to Gideon’s plan can be traced from our own naval history — 
in Drake’s scattering of the Armada with fireships at Calais, or in Cochrane’s similar 
though less-known exploit against the French Fleet in the Basque roads, 11th of April, 
1809.
4.	
One wonders whether memories of Joshua’s trumpets at Jericho had any part in suggesting to Gideon the ruse he 
employed.
5.	
See Isaiah IX 4.


447
C H A P T E R  5 1
BCTP: Be Unpredictable, Take Risks—Or Lose1
Major R. Powl Smith, Jr.
This article is an account of training exercise PRAIRIE WARRIOR 96, an annual train­
ing exercise at Ft. Leavenworth, Kansas, that confronted student officers of the Com­
mand and General Staff College (CGSC) playing BLUFOR against the Battle Command 
Training Program (BCTP)’s famous world-class opposing force (WCOPFOR). These 
computerized exercises generally—and in this case specifically—simulate corps-level 
combat.
PRAIRIE WARRIOR 96, played in May 1996, was the first time [since BCTPs 
had begun in the early 1980s] that a student BLUFOR class not only won, but defini­
tively defeated the WCOPFOR. They did so by abandoning the conventional conserva­
tive low-risk U.S. strategy of “two up, one back” that the opposing WCOPFOR had 
been conditioned by previous exercises to expect, substituting a high-risk unorthodox 
strategy that paid off, contrary to the urging of many mentors, senior observers, and 
instructors. 
Smith, a 1982 West Point graduate and 1996 graduate of the Command and Gen­
eral Staff College (CGSC), then a major, simulated BLUFOR’s II Corps Chief of Staff 
for PRAIRIE WARRIOR 96 as co-author of its operations and deception plans. Leav­
ing the Army with the rank of lieutenant colonel after 26 years of service, he became a 
vice president of Sabot 6, an American management consulting firm.
1.	
Major R. Powl Smith, Jr., “BCTP: Be Unpredictable, Take Risks—or Lose,” Field Artillery, March–April, 1997, pp. 
16-21. Reprinted by permission of the Fires Bulletin.

BCTP: Be Unpredictable, Take Risks—Or Lose
448 
The Art and Science of Military Deception

 
BCTP: Be Unpredictable, Take Risks—Or Lose
The Art and Science of Military Deception	
449

BCTP: Be Unpredictable, Take Risks—Or Lose
450 
The Art and Science of Military Deception

 
BCTP: Be Unpredictable, Take Risks—Or Lose
The Art and Science of Military Deception	
451

BCTP: Be Unpredictable, Take Risks—Or Lose
452 
The Art and Science of Military Deception

 
BCTP: Be Unpredictable, Take Risks—Or Lose
The Art and Science of Military Deception	
453


455
C H A P T E R  5 2
The Monkey’s Paw1
Major James R. Koch
This article represents the most concise recognition of the highest levels of Soviet de­
ception plans and operations against Japan (Manchuria) in 1945 and compares with 
British-American sophisticated deceptions for D-Day 1944.  It also describes the Soviet 
plans as too tightly held and too centralized when compared with the looser and more 
diffused Allied system.
Koch, a 1974 graduate of St. Lawrence University, had retired by 1997 at the rank 
of Lieutenant Colonel.
1.	
Major James R. Koch, “The Monkey’s Paw,” Military Intelligence, Vol. 14, No. 4, October 1988, pp. 26–28.

The Monkey’s Paw
456 
The Art and Science of Military Deception

 
The Monkey’s Paw
The Art and Science of Military Deception	
457

The Monkey’s Paw
458 
The Art and Science of Military Deception

459
C H A P T E R  5 3
1st Cav in Desert Storm—Deception, Firepower 
and Movement1
Brig Gen Tommy R. Franks and Patrecia S. Hollis
Brigadier General Tommy L. Franks served as Assistant Division Commander (Maneu­
ver), 1st Cavalry Division, during the 1991 attack into southern Iraq.  A graduate of the 
Armed Forces Staff College and Army War College, Franks was the U.S. general leading 
the 2001 invasion of Afghanistan. Patrecia S. Hollis was the managing editor of “Field 
Artillery” magazine at the time of the interview. In the interview, Franks quotes from 
Sun Tzu, citing him as having inspired the successful opening deception plan.  
1.	
BrigGen Tommy R. Franks and Patrecia S. Hollis “1st Cav in Desert Storm—Deception, Firepower and Move­
ment,” Field Artillery, June 1991, pp. 31–34. 

1st Cav in Desert Storm—Deception, Firepower and Movement
460 
The Art and Science of Military Deception

 
1st Cav in Desert Storm—Deception, Firepower and Movement
The Art and Science of Military Deception	
461

1st Cav in Desert Storm—Deception, Firepower and Movement
462 
The Art and Science of Military Deception

 
1st Cav in Desert Storm—Deception, Firepower and Movement
The Art and Science of Military Deception	
463


465
Ground War: U.S. Training 
for Conventional Field Combat
Introduction
Conventional military forces have experienced the most unconstrained, realistic combat 
training at the National Training Center (NTC) in California. The NTC is a dynamic 
field environment where commanders through privates receive immediate feedback 
from a competent OPFOR as a result of the decisions they make. Accordingly, the op­
portunities and penalties associated with the practice of deception are easily assessed. An 
unpublished Rand Corporation study on deception at the NTC is revealing.1 The study 
sought to determine the occurrence of deception, the deception techniques used, and the 
impact attributed to deception efforts. An analysis of 104 individual battles fought by 
units undergoing training provided the necessary data. 
Roughly 38 of the 104 battles in the Rand Corporation study exhibited decep­
tion designed to purposefully elicit behavior from the OPFOR for exploitation by the 
unit undergoing training. Deception techniques were observed in 21 additional battles, 
but were so sufficiently uncoordinated and disconnected from purposeful behavior that 
they could hardly be classified as deception operations. The remaining 45 battles pro­
vided little evidence of deception.2
Several deception techniques emerged from the 59 battles where some form of 
stratagem was evident. The table below lists the deceptive techniques observed and the 
frequency of occurrence.3
Technique
Occurrence
Smoke
30
Night maneuver
19
False battle position
12
Indirect approach
11
Deceptive counter-reconnaissance
7
Feint or diversion
5
Camouflage & concealment
1
Demonstration
1
OPSEC
1
Deceptive reconnaissance
1
False retreat
1
Controlled movement
1
False intelligence
1
Multiple simultaneous attacks
1
1.	
 F. Feer, “Tactical Deception at the National Training Center,” The Rand Corporation, working draft, 1989. 
2.	
 Ibid., 5.
3.	
 Ibid., 6.

Ground War: U.S. Training for Conventional Field Combat 
466 
The Art and Science of Military Deception
The impact of deception operations on battle outcomes is astonishing. To begin, suc­
cessful deception operations resulted in significantly lower losses for the training unit and 
higher losses for the OPFOR. Attempted deception resulted in comparable losses on both 
sides. However, training unit losses greatly exceeded OPFOR losses in battles where decep­
tion was not attempted. More importantly, when deception was not attempted, success in 
battle occurred only 14% of the time. However, successful deception operations resulted in 
battlefield success 75% of the time.4 Commanders have an obligation to consider deception 
when they conduct operations. Ignoring deception will almost certainly increase the cost of 
victory and may result in defeat.
4.	
 Ibid., 8.

467
C H A P T E R  5 4
Deception Operations in REFORGER 881
Captain Paul A. Haveles
Captain Paul A. Haveles was a battlefield deception plans officer who served with 2nd 
Battalion, 47th Infantry Division.  
This article offers a description, analysis, and criticism of Operation Hero, the de­
ception plan employed in the corps-versus-corp training exercise REFORGER 88 held 
in West Germany in September 1988. Although this was “the largest peacetime decep­
tion operation conducted by the U.S. Army” [and by NATO] since WWII, it was only 
a “limited success.” The author attributes the immediate cause to inadequate coordina­
tion between the written deception plan and the actual unit simulations and the under­
lying cause to the fact that the deception planners were “new to deception.”
Significantly, this was the last large U.S. and NATO field exercise in Europe. Be­
cause of the high costs ($12 billion in 1990) and environmental and property damage, 
the REFORGER exercises—which had been an annual event since 1969—were abol­
ished, being replaced with far less realistic command and control simulations.
Given the poor state of deception awareness and training in the U.S. Army in 1988 
at corps level as revealed by this article, and that at battalion levels at the National 
Training Center (NTC) [as revealed by Fred Feer’s RAND study] it is fortunate that the 
Soviet Union collapsed when it did.
1.	
Captain Paul A. Haveles, “Deception Operations in REFORGER 88,” Military Review, Vol. 70, No. 8, August 
1990, pp. 35–41.  

Deception Operations in REFORGER 88
468 
The Art and Science of Military Deception

 
Deception Operations in REFORGER 88
The Art and Science of Military Deception	
469

Deception Operations in REFORGER 88
470 
The Art and Science of Military Deception

 
Deception Operations in REFORGER 88
The Art and Science of Military Deception	
471

Deception Operations in REFORGER 88
472 
The Art and Science of Military Deception

 
Deception Operations in REFORGER 88
The Art and Science of Military Deception	
473

Deception Operations in REFORGER 88
474 
The Art and Science of Military Deception

475
C H A P T E R  5 5
Voices in the Sand: Deception Operations at the 
NTC1
Captain George L. Reed
This article summarizes the extensive but highly cost-effective use of deception by the 
OPFOR (then the 63rd Regiment of 1st Infantry Division) at the Fort Irwin (California) 
National Training Center (NTC). With its smooth blend of theory and practice, this 
article is far more practical than any of the relevant US doctrinal manuals. It is combat 
deception in a six-page nutshell. 
1.	
Captain George L. Reed, “Voices in the Sand: Deception Operations at the NTC,” Armor, Vol. 97. No. 5, Septem­
ber–October 1988, pp. 26–31.

Voices in the Sand: Deception Operations at the NTC
476 
The Art and Science of Military Deception

 
Voices in the Sand: Deception Operations at the NTC
The Art and Science of Military Deception	
477

Voices in the Sand: Deception Operations at the NTC
478 
The Art and Science of Military Deception

 
Voices in the Sand: Deception Operations at the NTC
The Art and Science of Military Deception	
479

Voices in the Sand: Deception Operations at the NTC
480 
The Art and Science of Military Deception

 
Voices in the Sand: Deception Operations at the NTC
The Art and Science of Military Deception	
481


483
C H A P T E R  5 6
OPFOR Counterreconnaissance at the National 
Training Center
Captain Richard Randazzo
This article reports the highly cost-effective counter-reconnaissance efforts of the Red 
Team (“OPFOR”) regiment at Ft. Irwin and the generally poor showing of the Blue 
Team (“BLUFOR”) brigades. Incidentally, these Blues performed no better than the 
Blues of a decade earlier, as reported by Colonel John Rosenberger.
Richard A. “Rick” Randazzo (1993 West Point graduate), a U.S. Army (Armor) of­
ficer, served 34 rotations with the OPFOR at the NTC and subsequently as an Assistant 
Professor of Military Science at Southern Illinois University where he took an MBA in 
1999. 

OPFOR Counterreconnaissance at the National Training Center
484 
The Art and Science of Military Deception

 
OPFOR Counterreconnaissance at the National Training Center
The Art and Science of Military Deception	
485


487
Section XIV: 
Economic Warfare


489
C H A P T E R  5 7
The Farewell Dossier: Duping the Soviets1
Gus W. Weiss
The large-scale and largely successful Soviet industrial espionage efforts against the West 
since 1970 are well-documented and widely known. Less known is a cunning American 
countermeasure. Dr. Waldo Weiss (1966 NYU Ph.D. in Business Administration) served 
as a senior advisor to U.S. Presidents Nixon, Ford, Carter, and Reagan and the NSC. 
Here, he reveals fascinating details of his starring role as a planner in the planting of 
false technology, including software rigged with a “Trojan Horse,” on the KGB begin­
ning in 1982. The French and Americans had been alerted to Soviet espionage efforts by 
French agent KGB Col. Vladimir I. Vetrov from 1981 until his discovery and execution 
in 1983.
The Farewell Dossier
We communists have to string along with the capitalists for a while. We need their cred­
its, their agriculture, and their technology. But we are going to continue massive military 
programs and by the middle 1980s we will be in a position to return to a much more ag­
gressive foreign policy designed to gain the upper hand in our relationship with the West.
—Leonid Brezhnev, remarks in 1971 to the Politburo at the beginning of détente.
During the Cold War, and especially in the 1970s, Soviet intelligence carried out a sub­
stantial and successful clandestine effort to obtain technical and scientific knowledge 
from the West. This effort was suspected by a few U.S. Government officials but not 
documented until 1981, when French intelligence obtained the services of Col. Vladimir 
I. Vetrov, “Farewell,” who photographed and supplied 4,000 KGB documents on the 
program. In the summer of 1981, President Mitterrand told President Reagan of the 
source, and, when the material was supplied, it led to a potent counterintelligence re­
sponse by CIA and the NATO intelligence services.
President Nixon and Secretary of State Kissinger conceived of détente as the search 
for ways of easing chronic strains in US-Soviet relations. They sought to engage the 
USSR in arrangements that would move the superpowers from confrontation to ne­
gotiation. Arms control, trade, and investment were the main substantive topics. The 
Soviets viewed détente as “peaceful coexistence” and as an avenue to improve their inef­
ficient, if not beleaguered economy using improved political relations to obtain grain, 
foreign credits, and technology.1 In pure science, the Soviets deserved their impressive 
reputation, and their space program demonstrated originality and accomplishment in 
rocket engineering—but they lacked production know-how necessary for long-term 
1.	
Gus W. Weiss, “Duping the Soviets: The Farewell Dossier,” Studies in Intelligence, Vol. 39, No. 5, 1996, pp. 
121–126.

The Farewell Dossier: Duping the Soviets
490 
The Art and Science of Military Deception
competition with the United States. Soviet managers had difficulty in translating labo­
ratory results to products, quality control was poor, and plants were badly organized. 
Cost accounting, even in the defense sector, was hopelessly inadequate. In computers 
and microelectronics, the Soviets trailed Western standards by more than a decade.
Soviet S&T Espionage
The leadership recognized these shortcomings. To address the lag in technology, Soviet 
authorities in 1970 reconstituted and invigorated the USSR’s intelligence collection for 
science and technology. The Council of Ministers and the Central Committee established 
a new unit, Directorate T of the KGB’s First Chief Directorate, to plumb the R&D 
programs of Western economies. The State Committee on Science and Technology and 
the Military-Industrial Commission were to provide Directorate T and its operating 
arm, called Line X, with collection requirements. Military Intelligence (GRU), the Soviet 
Academy of Sciences, and the State Committee for External Relations completed the list 
of participants. The bulk of collection was to be done by the KGB and the GRU, with 
extensive support from the East European intelligence services. A formidable apparatus 
was set up for scientific espionage; the scale of this structure testified to its importance. 
The coming of détente provided access for Line X and opened new avenues for exploita­
tion. Soviet intelligence took full advantage.
In the early 1970s, the Nixon administration had no comprehensive policy for eco­
nomic relations with the USSR. The sale of strategic goods to Communist countries was 
governed by the Coordinating Committee of NATO (COCOM), which administered 
an Alliance-agreed list of products and data embargoed for sale. Nixon’s policy worked 
within this system, and, for the export of products exceeding the approved list, special 
exceptions were necessary. And, in a new set of commercial and scientific arrangements, 
the United States and the USSR set up joint technical commissions to assess prospects 
for cooperation. Topics included agriculture, nuclear energy, computers, and the envi­
ronment. As Kissinger noted: 
Over time, trade and investment may leaven the autarkic tendencies of the Soviet system, in­
vite gradual association of the Soviet economy with the world economy, and foster a degree 
of interdependence that adds an element of stability to the political relationship.2
Beginning in 1972, delegations of Soviet specialists came to the United States to visit 
firms and laboratories associated with their commissions. Line X, ever alert, populated 
these delegations with its own people: in an agricultural delegation of 100 about one-
third were known or suspected intelligence officers. On a visit to Boeing, a Soviet guest 
applied adhesive to his shoes to obtain metal samples. In another episode, the ranking 
scientists and managers of the Soviet computer and electronics industry obtained a visa 
for the specific purpose of visiting the Uranus Liquid Crystal Watch Company of Mine­
ola, Long Island (a firm not among the Fortune 500). Three days before the delegation’s 
arrival, they requested an expansion of the itinerary to include nearly all U.S. computer 
and semiconductor firms. This maneuver was done to observe (that is, collect) the lat­
est technology and it was executed at the last minute so that the Defense Department 
would not have time to object. It was legal—Line X had studied our regulations and 
turned them to its advantage.

 
The Farewell Dossier: Duping the Soviets
The Art and Science of Military Deception	
491
To acquire the latest aircraft technology, the Soviets in 1973 proposed purchasing 
50 Lockheed transports if the firm, then in financial difficulty, would build and equip a 
modern “aircraft city” in the USSR. A similar proposition was put to Boeing (it besieges 
the imagination to ponder Brezhnev appearing from the cabin of an Aeroflot 747). Line 
X practiced the venerable capitalist technique of playing off competitors, and, from this 
bidding, the Soviets sought to gain technical data for use at home. On a less lofty techni­
cal plane, in 1972 the Soviets surreptitiously bought 25 percent of the US grain harvest, 
using phone intercepts of the grain dealers’ network to listen to both sides of the mar­
ket. The purchase led to higher grain prices for consumers, and taxpayers provided for 
a 25 percent a bushel export subsidy. Those of us observing these arabesques began to 
question the USSR’s total commitment to the spirit of détente.
US Computer Export Policy
In late 1973, President Nixon asked his Council on International Economic Policy to 
determine which computers and associated production technology might be prudently 
sold to Communist countries. This study was necessary because détente implied the 
expansion of commercial opportunities with Eastern Europe and the USSR; a new and 
more liberal set of COCOM rules was required to fit these prospects, however illusory 
they may have been. Data processing was the most important product requiring review. 
I was put in charge of the project, and I was also made responsible for the broader prob­
lem of technology transfer. The computer study was the first review of technology policy 
within détente; it sought to assess the economic gain to the United States from computer 
sales set against the national security risk from those sales.
Not surprisingly, the study concluded that the USSR was short of computers and the 
means to pay for substantial computer imports. Our analysis presumed that the Soviets 
intended to use their foreign exchange to best advantage by purchasing the most power­
ful computers, those that also held the most national security risk (large computers were 
used for nuclear weapons calculations and cryptography). The report concluded that 
the export potential for American data processing to the USSR was small and the risk 
great if the more powerful computers were allowed for sale. The study recommended 
raising moderately the power of machines allowed for COCOM release, while at the 
same time restricting the sale of technology. Export of the largest computers was to be 
prohibited. In National Security Decision Memorandum (NSDM) 247, 14 March 1974, 
U.S. Policy on the Export of Computers to Communist Countries, President Nixon approved 
these recommendations, and they became the new export guidelines. As a result, the So­
viets were excluded from importing significantly powerful Western computers, détente 
notwithstanding.
If the Soviets were to reach comparability with the United States in computers, their 
engineers would on their own now have to create designs and produce equipment. Line 
X would have to use its espionage resources to supplement what could be developed at 
home. NSDM 247 eliminated the West as an open source available to the Soviets, but 
Western intelligence was unaware of the collection apparatus the Soviets had deployed 
to obtain the technology.

The Farewell Dossier: Duping the Soviets
492 
The Art and Science of Military Deception
Strong Suspicions and Skepticism
In the early 1970s, there were no U.S. intelligence collection requirements for technology 
transfer and scientific espionage, and few, if any, reporting sources. But, by observing 
the behavior of Soviet delegations visiting U.S. plants and by keeping in mind the clever 
1972 grain purchase, a few government officials began to suspect that a master plan 
was in place to obtain our know-how. Direct evidence was nonexistent—only anecdotal 
clues were at hand. In their intelligence history, the Soviets could point to the success 
of the atom bomb spies, and they also had to their credit collection against industrial 
technology in Germany during the 1920s. After World War II, the Soviets copied the 
American B-29 and the Rolls-Royce Nene jet engine (the copy powered the MiG-15). 
Two former members of the Rosenberg network had set up the modern Soviet microelec­
tronics industry. Soviet intelligence was professional at ferreting out science and technol­
ogy and had the results to prove it. The Soviets were adept at copying foreign designs. 
In the style of Sherlock Holmes, the clues could almost speak for themselves: the USSR 
was behind in important technologies, their intelligence was accomplished at collection, 
and détente had opened a path.
Those suspicious of a Great Game in technology espionage found that the U.S. 
Government was not 221 B Baker Street—we could make little headway in persuading 
officials in charge of intelligence requirements that the United States was facing a sig­
nificant threat. We received discouraging responses to our pleas for help: “No evidence” 
of a grand design; “not usual Soviet practice;” “no requirements and no interest;” “no 
sources.” It seemed to have escaped these authorities that having no evidence does not 
mean it is not true. The system defied movement.
A few alert colleagues were dispersed among the executive departments. In one 
episode, the Department of Commerce discovered a Line X effort to obtain an embar­
goed computer through a dummy corporation set up for this one transaction; officials 
intercepted the shipping container and substituted sandbags. (A note was enclosed, but 
it would not be politically correct to quote it.) In 1975, the Apollo-Soyuz spacecraft 
docking was used to gain intelligence access to the U.S. space program. This project 
was conceived by the Nixon administration as part of détente, and President Ford had 
no choice but to continue the effort. To the consternation of NASA, a few weeks before 
the launch counterintelligence suspected that one of the Cosmonauts was a KGB officer 
who had been collecting away over the course of the project.
Presidential Interest
President Carter was the first chief executive to take an interest in technology loss. Dur­
ing his administration, CIA had begun to report the diversion of computers from the 
West into the Soviet defense complex, and he wanted details. In response, the Agency 
assigned staff to this endeavor and produced a more complete picture of technology loss 
than had been available since the start of Directorate T. Carter also ordered the first 
comprehensive study of technology transfer, Presidential Review Memorandum 31, a 
document that only distantly addressed the threat from clandestine collection. It was 
largely a missed opportunity, but Carter responded to the Soviet invasion of Afghani­
stan by instituting sanctions, canceling several computer sales, and stopping equipment 
destined for the Kama River truck plant.

 
The Farewell Dossier: Duping the Soviets
The Art and Science of Military Deception	
493
President Reagan came to office intent on reversing what he saw as the “window 
of vulnerability” favoring the Soviets in strategic weapons. He also believed that the 
USSR’s economy did not work and that the Soviet system was on the way to collapse. 
His intuition led him to believe the Cold War could be won. Joining Reagan’s NSC staff 
were those of us who thought similarly and entertained the idea that economic pressure 
would have some effect. The NSC staff sought to fashion policies to take advantage of 
the USSR’s low productivity, its lag in technology, oppressive defense burden, and inef­
ficient economic structure. Reagan was the first president for whom this line of thought 
would have been even remotely acceptable.
A Defector in Place
Into the receptive climate of the Reagan administration came President Mitterrand, 
bearing news of Farewell—that is, Colonel Vetrov. In a private meeting associated with 
the July 1981 Ottawa economic summit, he told Reagan of the source and offered the 
intelligence to the United States. It was passed through Vice President Bush and then to 
CIA. The door had opened into Line X.
Vetrov was a 53-year-old engineer assigned to evaluate the intelligence collected by 
Directorate T, an ideal position for a defector in place. He had volunteered his services 
for ideological reasons. He supplied a list of Soviet organizations in scientific collection 
and summary reports from Directorate T on the goals, achievements, and unfilled ob­
jectives of the program. Farewell revealed the names of more than 200 Line X officers 
stationed in 10 KGB rezidents in the West, along with more than 100 leads to Line X 
recruitments.3 
Upon receipt of the documents (the Farewell Dossier, as labeled by French Intel­
ligence) CIA arranged for my access. Reading the material caused my worst nightmares 
to come true. Since 1970, Line X had obtained thousands of documents and sample 
products, in such quantity that it appeared that the Soviet military and civil sectors 
were in large measure running their research on that of the West, particularly the United 
States. Our science was supporting their national defense. Losses were in radar, comput­
ers, machine tools, and semiconductors. Line X had fulfilled two-thirds to three-fourths 
of its collection requirements—an impressive performance.
Interest in Technology Transfer
Overnight, technology transfer became a top priority, rising from the basement of In­
telligence Community interest. CIA set up a Technology Transfer Intelligence Center, 
and the Pentagon created groups to assess damage and find ways to tighten technology 
controls. But careful study of Farewell’s material suggested that more than just a few 
committees could come out of this wealth of intelligence. With the Farewell reporting, 
CIA had the Line X shopping list for still-needed technology, and with the list American 
intelligence might be able to control for its purposes at least part of Line X’s collection, 
that is, turn the tables on the KGB and conduct economic warfare of our own.
I met with Director of Central Intelligence William Casey on an afternoon in Janu­
ary 1982. I proposed using the Farewell material to feed or play back the products 
sought by Line X, but these would come from our own sources and would have been 
“improved,” that is, designed so that on arrival in the Soviet Union they would ap­
pear genuine but would later fail. U.S. intelligence would match Line X requirements 

The Farewell Dossier: Duping the Soviets
494 
The Art and Science of Military Deception
supplied through Vetrov with our version of those items, ones that would hardly meet 
the expectations of that vast Soviet apparatus deployed to collect them.
If some double agent told the KGB the Americans were alert to Line X and were 
interfering with their collection by subverting, if not sabotaging, the effort, I believed 
the United States still could not lose. The Soviets, being a suspicious lot, would be likely 
to question and reject everything Line X collected. If so, this would be a rarity in the 
world of espionage, an operation that would succeed even if compromised. Casey liked 
the proposal.
A Deception Operation
As was later reported in Aviation Week and Space Technology, CIA and the Defense De­
partment, in partnership with the FBI, set up a program to do just what we had dis­
cussed: modified products were devised and “made available” to Line X collection 
channels. The CIA project leader and his associates studied the Farewell material, ex­
amined export license applications and other intelligence, and contrived to introduce 
altered products into KGB collection. American industry helped in the preparation of 
items to be “marketed” to Line X. Contrived computer chips found their way into Soviet 
military equipment, flawed turbines were installed on a gas pipeline, and defective plans 
disrupted the output of chemical plants and a tractor factory. The Pentagon introduced 
misleading information pertinent to stealth aircraft, space defense, and tactical aircraft.4 
The Soviet Space Shuttle was a rejected NASA design.5 When Casey told President Rea­
gan of the undertaking, the latter was enthusiastic. In time, the project proved to be a 
model of interagency cooperation, with the FBI handling domestic requirements and 
CIA responsible for overseas operations. The program had great success, and it was 
never detected.
In a further use of the Farewell product, Casey sent the Deputy Director of Central 
Intelligence to Europe to tell NATO governments and intelligence services of the Line 
X threat. These meetings led to the expulsion or compromise of about 200 Soviet intel­
ligence officers and their sources, causing the collapse of Line X operations in Europe. 
Although some military intelligence officers avoided compromise, the heart of Soviet 
technology collection crumbled and would not recover. This mortal blow came just at 
the beginning of Reagan’s defense buildup, his Strategic Defense Initiative (SDI), and the 
introduction of stealth aircraft into U.S. forces.
National Security Directive
On 17 January 1983, to define his policy for political, military, and economic relations 
with the USSR, Reagan approved National Security Decision Directive (NSDD) 75, 
U.S. Relations with the USSR, a document spelling out purposes, themes, and strategy for 
competing in the Cold War. It specified three policy elements: containment and reversal 
of Soviet expansionism, promotion of change in the internal system to reduce the power 
of the ruling elite, and engagement in negotiations and agreements that would enhance 
US interests. In economic policy, NSDD 75 highlighted the need to control technology; 
Farewell’s reports had moved those writing the Directive to put emphasis on preventing 
technology loss, and the President had agreed (so a KGB defector working for a foreign 
intelligence service put his stamp on a part of presidential policy). Later in 1983, Rea­
gan proposed the SDI, which Gorbachev and the Soviet military took far more seriously 

 
The Farewell Dossier: Duping the Soviets
The Art and Science of Military Deception	
495
than American commentators. SDI would, if deployed, place unacceptable economic 
and technical demands on the Soviet system. Even Reagan’s 1983 “evil empire” speech 
had its economic effect, for immediately thereafter the Soviet military asked for a budget 
increase, this on top of already-bloated defense expenditures.
Two events beyond presidential control dovetailed with NSDD 75. The Federal 
Reserve’s restrictive monetary policy of the early 1980s led to a fall in gold and primary 
product prices, sources of Soviet foreign exchange. And the discovery of Alaskan North 
Shore oil contributed to the 1986 fall in petroleum prices, cutting the revenues not only 
of OPEC but also of the USSR. Coincident events and deliberate government policy 
had the twin effects of adding to the burden on the Soviet system and of shifting the 
superpower competition to advanced technology, where the United States held a clear 
advantage.
Good-by to Farewell
About the time I met with Casey, Vetrov fell into a tragic episode with a woman and a 
fellow KGB officer in a Moscow park. In circumstances that are not clear, he stabbed 
and killed the officer and then stabbed but did not kill the woman. He was arrested, and, 
in the ensuing investigation, his espionage activities were discovered; he was executed in 
1983. CIA had enough intelligence to institute protective countermeasures.
In 1985, the case took a bizarre turn when information on the Farewell Dossier sur­
faced in France. Mitterrand came to suspect that Vetrov had all along been a CIA plant 
set up to test him to see if the material would be handed over to the Americans or kept 
by the French. Acting on this mistaken belief, Mitterrand fired the chief of the French 
service, Yves Bonnet.6
An Important Contribution
In 1994, Gorbachev’s science adviser, Roald Sagdeev, wrote that in computers and mi­
croelectronics—the keys to modern civil and military technology—the Soviets trailed 
Western standards by 15 years and that the most striking indication of their backward­
ness was the absence of a domestically made supercomputer.7 The Soviets considered a 
supercomputer a “strategic attribute,” the lack of which was inexcusable for a super­
power.  Line X did not acquire designs for such a machine, nor could Soviet computer 
scientists build one on their own—and NSDM 247 had stopped Western help. As for 
Farewell, his contribution led to the collapse of a crucial collection program at just the 
time the Soviet military needed it, and it resulted in a forceful and effective NATO effort 
to protect its technology. Along with the U.S. defense buildup and an already flounder­
ing Soviet economy, the USSR could no longer compete, a conclusion reached by the 
Politburo in 1987.
When historians sort out the reasons for the end of the Cold War, perhaps Farewell 
will receive a footnote. It would be deserved.
Notes
1.	
Kissinger, Henry A., White House Years. Boston: Little, Brown and Company, 1979, pp. 1, 142.

The Farewell Dossier: Duping the Soviets
496 
The Art and Science of Military Deception
2.	
Kissinger on détente. Thomas G. Paterson and Dennis Merrill (Ed.), Major Problems in American Foreign Rela­
tions, Volume II, 1995, p. 600.
3.	
For a primary source from a former KGB officer, see Oleg Gordievsky and Christopher Andrew, KGB: The 
Inside Story. New York, Harper Collins, 1991.
4.	
Schweizer, Peter. Victory: The Reagan Administration’s Secret Strategy that Hastened the Collapse of the Soviet 
Union. New York: The Atlantic Monthly Press, 1995, pp. 187–90.
5.	
Conversation with James Fletcher, Administrator, NASA.
6.	
Porch, Douglas. The French Secret Services. New York: Farrar, Straus and Giroux, 1995, p. 448.
7.	
Sagdeev, Roald Z. The Making of a Soviet Scientist. New York: Jolui Wiley & Sons, 1994, pp. 298–301.

497
Section XV:
Cost Effectiveness


499
C H A P T E R  5 8
The One Percent Solution: Costs and Benefits of 
Military Deception1
Barton Whaley
1.	
Bart Whaley, “The 1% Solution: Costs & Benefits of Military Deception,” Information Strategy and Warfare, John 
Arquilla and Douglas Borer, editors, New York: Routledge, 2007, pp. 127–159.

The One Percent Solution: Costs and Benefits of Military Deception
500 
The Art and Science of Military Deception

 
The One Percent Solution: Costs and Benefits of Military Deception
The Art and Science of Military Deception	
501

The One Percent Solution: Costs and Benefits of Military Deception
502 
The Art and Science of Military Deception

 
The One Percent Solution: Costs and Benefits of Military Deception
The Art and Science of Military Deception	
503

The One Percent Solution: Costs and Benefits of Military Deception
504 
The Art and Science of Military Deception

 
The One Percent Solution: Costs and Benefits of Military Deception
The Art and Science of Military Deception	
505

The One Percent Solution: Costs and Benefits of Military Deception
506 
The Art and Science of Military Deception

 
The One Percent Solution: Costs and Benefits of Military Deception
The Art and Science of Military Deception	
507

The One Percent Solution: Costs and Benefits of Military Deception
508 
The Art and Science of Military Deception

 
The One Percent Solution: Costs and Benefits of Military Deception
The Art and Science of Military Deception	
509

The One Percent Solution: Costs and Benefits of Military Deception
510 
The Art and Science of Military Deception

 
The One Percent Solution: Costs and Benefits of Military Deception
The Art and Science of Military Deception	
511

The One Percent Solution: Costs and Benefits of Military Deception
512 
The Art and Science of Military Deception

 
The One Percent Solution: Costs and Benefits of Military Deception
The Art and Science of Military Deception	
513

The One Percent Solution: Costs and Benefits of Military Deception
514 
The Art and Science of Military Deception

 
The One Percent Solution: Costs and Benefits of Military Deception
The Art and Science of Military Deception	
515

The One Percent Solution: Costs and Benefits of Military Deception
516 
The Art and Science of Military Deception

 
The One Percent Solution: Costs and Benefits of Military Deception
The Art and Science of Military Deception	
517

The One Percent Solution: Costs and Benefits of Military Deception
518 
The Art and Science of Military Deception

 
The One Percent Solution: Costs and Benefits of Military Deception
The Art and Science of Military Deception	
519

The One Percent Solution: Costs and Benefits of Military Deception
520 
The Art and Science of Military Deception

 
The One Percent Solution: Costs and Benefits of Military Deception
The Art and Science of Military Deception	
521

The One Percent Solution: Costs and Benefits of Military Deception
522 
The Art and Science of Military Deception

 
The One Percent Solution: Costs and Benefits of Military Deception
The Art and Science of Military Deception	
523

The One Percent Solution: Costs and Benefits of Military Deception
524 
The Art and Science of Military Deception

 
The One Percent Solution: Costs and Benefits of Military Deception
The Art and Science of Military Deception	
525

The One Percent Solution: Costs and Benefits of Military Deception
526 
The Art and Science of Military Deception

 
The One Percent Solution: Costs and Benefits of Military Deception
The Art and Science of Military Deception	
527

The One Percent Solution: Costs and Benefits of Military Deception
528 
The Art and Science of Military Deception

 
The One Percent Solution: Costs and Benefits of Military Deception
The Art and Science of Military Deception	
529

The One Percent Solution: Costs and Benefits of Military Deception
530 
The Art and Science of Military Deception

531
Section XVI: 
When Your Deception Plan is Compromised: 
Plan B


533
C H A P T E R  5 9
Battle of the Gothic Line, 25 Aug 1944: 
Operation OLIVE1
Barton Whaley
You know the opponent has bought your deception plan. Then circumstances change 
180-degrees so that the obsolete deception plan has become the real plan. The opponent 
now expects your next move. But you can’t abort or even postpone. What do you do?
Fortunately, this is rare; but here is a real situation and its largely successful solu­
tion.  Note that this is also one way to counter if you discover that an opponent has 
detected your deception plan.
1.	
Barton Whaley, Stratagem: Deception and Surprise in War, Norwood, MA: Artech House, 2007, pp. 406–408.

Battle of the Gothic Line, 25 Aug 1944: Operation OLIVE
534 
The Art and Science of Military Deception

 
Battle of the Gothic Line, 25 Aug 1944: Operation OLIVE
The Art and Science of Military Deception	
535

Battle of the Gothic Line, 25 Aug 1944: Operation OLIVE
536 
The Art and Science of Military Deception

537
Section XVII:
When Deception Backfires


539
C H A P T E R  6 0
Polyakov’s Run1
Raymond L. Garthoff
This article reveals two rare cases of a deception gone wrong. Specifically, the FBI’s ef­
forts through double agents (first U.S. Army Sgt. Joseph Cassidy in 1959, then Soviet 
Col. Dmitri Polyakov in 1967) to make the Soviets believe the U.S. had much greater 
capabilities in chemical and biological weapons (CBW). In his Cassidy’s Run (2000) 
David Wise had speculated from weak evidence that Cassidy’s efforts backfired when 
the Russian response was to expand and expedite its own chemical warfare (CW) pro­
gram. Garthoff cites Wise and adds with better evidence that Polyakov’s effort similarly 
backfired by provoking the Russians in 1969 to enlarge their biological warfare (BW) 
program.
When U.S. intelligence deceived the Soviets, were they being a little too clever? 
To his Soviet handlers, SGT. Joseph Cassidy seemed like any other of the dozen or 
so well placed noncommissioned officers of the U.S. Army and Navy who had been re­
cruited to be agents by Soviet Military Intelligence (the “GRU”). The U.S. Navy’s Chief 
Warrant Officer John A. Walker, Jr. may have had the distinction of being paid more 
(well over $1 million) for the navy codes and other valuable tactical and operational 
secrets he passed to the Soviets—and Walker enjoyed a long “run” before his arrest in 
1985. 
But Cassidy had his own distinctions. First, he had the longest run of all—one that 
lasted more than 20 years, starting in 1959. The second was something the GRU did not 
learn about until much later: From the start, Sergeant Cassidy was a U.S. double agent. 
His story was only recently revealed in Cassidy’s Run, a fascinating account by 
veteran espionage observer David Wise, who evidently got a major assist from the FBI. 
Cassidy, who was recruited and run by the FBI and Army Intelligence, played the most 
important of his roles in a major deception operation in the 1960s, in the course of 
which he passed selected and real secret information—along with carefully prepared 
misinformation—about the U.S. Army chemical warfare program at the laboratory and 
test center at Edgewood Arsenal. It was a highly successful deception and disinforma­
tion operation. 
1.	
Raymond L. Garthoff, “Polyakov’s Run,” Bulletin of the Atomic Scientists, Vol. 56, No. 5, September–October 
2000, pp. 37–40.

Polyakov’s Run
540 
The Art and Science of Military Deception
Act One 
Both the United States and the Soviet Union launched substantial chemical and biologi­
cal weapons (CBW) development programs after World War II, largely building on Ger­
man and Japanese wartime research. Both countries’ programs were shrouded in secrecy. 
The purpose of the U.S. deception operation was to mislead the Soviet intelligence and 
military establishments into believing that the United States had a much more extensive 
and successful chemical weapons program than was known—and especially to convince 
Soviet leaders that the United States was developing a super nerve gas called GJ. 
There had in fact been long and serious research on GJ, but it was finally decided 
that it would never be a practicable weapon. The objective of the disinformation pro­
gram was to entice the Soviets into spending great efforts and resources on something 
American experts had concluded was a superficially promising prospect, but ultimately 
a dead end. The Soviets bought it. 
Cassidy was used in the chemical weapons deception operation from 1966 through 
mid-1969, when the American managers of the game decided to shift him to other 
operations. Author Wise was apparently unaware that the United States had also been 
transmitting disinformation on chemical weapons through other channels, and that it 
continued the disinformation operation after Cassidy was transferred. 
To all appearances at the time, the deception was a great success. The Soviet mili­
tary did, indeed, expand and intensify its efforts to develop a super nerve gas like GJ. 
However, as time went on, there was increasing evidence that Soviet scientists had suc­
ceeded where their American counterparts had given up, and that the Soviets had suc­
cessfully developed a usable, much more toxic, and highly effective nerve gas called 
Novichok. Whether Novichok is directly descended from GJ is not entirely clear, but the 
unexpected outcome raises an intriguing and important question. 
Wise implies the answer: As a result of miscalculation by U.S. scientific and intel­
ligence experts, the Soviets were encouraged to pursue a program that ultimately greatly 
increased their chemical warfare capabilities. 
Because deception and disinformation operations like the nerve gas deception in­
volve sensitive sources and methods, they are necessarily among the most tightly guard­
ed secrets—even after many years have passed. Moreover, so long as these operations 
remain secret, they may continue to have effect. On the other hand, if they are blown, 
neither their unsuccessful originators nor the duped party have much incentive to dis­
close what has happened. 
The possibility that such an operation, while successful in its own terms, might 
have wholly unexpected and undesired consequences is obviously one of the reasons for 
great care when authorizing such a measure. The need to keep the number of “witting” 
persons as limited as possible is understandable. But when the number of those apprised 
of a plan is kept to a minimum, the broader ramifications of the operation may not be 
adequately explored. 
Intriguing, exciting, and perhaps as alarming as Wise’s tale of Cassidy’s Run is, it 
was in fact only the first act of a much more dramatic play. There was a second act, 
which might be called “Polyakov’s Run.” 

 
Polyakov’s Run
The Art and Science of Military Deception	
541
“Top Hat” 
On August 17, 1967, a top secret joint decree issued by the Central Committee-Council 
of Ministers of the Soviet Union reviewed the evidence for what was seen as an extensive 
and successful U.S. program in the field of chemical and biological warfare. The decree 
called for corresponding Soviet CBW preparations. Although my attempts to obtain this 
decree in the Russian archives have so far been unsuccessful, I was able to track down a 
reference to it in the index to the still-closed files of the Central Committee. This Soviet 
decision to continue to pursue CBW programs was heavily influenced by the U.S. decep­
tion operation—if not entirely prompted by it. 
Because of the heightened Soviet concern about the U.S. CBW program, in 1967 Col. 
Dmitri Polyakov, one of the key Soviet military intelligence agents in the United States, 
was tasked with finding out all he could about the U.S. chemical weapons program. 
Soviet intelligence, however, was unaware that since late 1961 Polyakov had been 
an FBI-run double agent code-named “Top Hat.” (His CIA code name was “Bourbon.”) 
The report Polyakov sent back to Moscow was based on a continuation of the mis­
information provided through Cassidy. In 1969 he told his American handlers that his 
report had “shocked” Soviet leaders and led to a decision to undertake a crash program 
to meet the U.S. CBW threat, especially in the area of nerve gas development. “Cas­
sidy’s run” on chemical weapons was coming to an end, but “Polyakov’s run” was in 
full force. 
The Soviet decision in 1969 to undertake the crash program was confirmed by other 
sources, notably by a second Soviet agent, a KGB officer, FBI code name “Fedora,” who 
had also been recruited in the early 1960s. (His CIA code name was “Scotch.”) 
Red Herring? 
Meanwhile, the United States conducted its last biological weapons test at Johnston 
Island in 1968, and was reassessing both its chemical and biological programs. On May 
28, 1969, a national security study, Chemical and Biological Agents (NSSM-59), ques­
tioned the utility of those weapons—although the Defense Department did not want to 
rule out chemical weapons research. 
Further studies and deliberations followed, and on November 25, 1969, President 
Richard Nixon renounced completely the use of biological weapons. He also announced 
that the United States would never be the first to use chemical weapons. He called for 
international agreements to ban both types of weapons, but declared that the restric­
tions he announced were not conditioned on reaching those agreements. 
It was not until nearly a decade later that the first—and distorted—accounts of the 
role of Top Hat and Fedora were leaked to the press. In 1978, New York Times jour­
nalist David Binder reported that former FBI Deputy Director William Sullivan, along 
with several other FBI and CIA officials, had begun to suspect that both agents had been 
“turned” by Soviet counterintelligence, or perhaps had always been “triple agents.” Sul­
livan claimed that Soviet double agents had provided falsely reassuring information on 
Soviet CBW programs in order to lead the United States to cut back its own programs. 
Incredibly, Sullivan attributed Nixon’s renunciation of biological weapons and curbs on 
the use of chemical weapons to Soviet disinformation. 
Somehow, Sullivan’s leak did not result in the Soviet discovery of the identity of 
the two agents, nor did it compromise the U.S. deception operation. And, as Edward J. 

Polyakov’s Run
542 
The Art and Science of Military Deception
Epstein made clear in his 1989 book Deception, Top Hat—and almost certainly Fedora 
as well-were working for the United States and not the Soviet Union. Top Hat, a.k.a. 
Dmitri Polyakov, by then a retired major general, paid with his life for his espionage 
activities when he was betrayed by CIA turncoat Aldrich Ames in 1985. (Fedora, who 
had earlier died a natural death, had never been revealed as an American agent.) 
Nixon’s renunciation of biological weapons was based on the judgment by Ameri­
can scientists that bioweapons would not be militarily useful, not on any presumptions 
about Soviet programs, much less on Soviet disinformation. Nixon’s decision on bio­
logical weapons paralleled the earlier decision with respect to GJ and work on super 
nerve gas. 
Act Two 
The military intelligence chiefs and the FBI wanted to repeat their success, this time with 
a deception program on biological weapons. Polyakov’s run was a direct sequel to Cas­
sidy’s run on nerve gas. 
Accounts suggest that multiple channels, including Polyakov, were used to convey 
the misleading message that the United States was undertaking a clandestine biological 
weapons program, despite President Nixon’s public announcement in November 1969 
and the U.S. signature at the Biological Weapons Convention in April 1972. Soviet sus­
picions of U.S. perfidy in negotiating the biological weapons convention were seemingly 
confirmed by these clandestine disinformation channels. 
In the late 1980s and early 1990s several high-ranking Russian scientists defected 
to the West. Because of their testimony, we now know that in January 1973—at the 
same time that agents were feeding misinformation about U.S. chemical and biologi­
cal programs to the Soviets—the Central Committee-Council of Ministers decreed the 
establishment of a new, intensified Soviet program for research and development of 
biological weapons. A new cover organization known as Biopreparat, with both mili­
tary and civilian research institutes and other facilities, including standby production 
capabilities, was created. 
Throughout the 1970s and 1980s this extensive secret program continued—as did 
Soviet suspicions and concerns about the supposed clandestine U.S. biological weapons 
program. For example, I located in the archive of the Central Committee in Moscow a 
major study that the General Staff made in 1983 on foreign—and above all U.S.—bio­
logical and chemical weapons, with projections to the year 2000. No doubt there were 
other studies as well. 
It is not clear when the U.S. disinformation operations on CBW ended—probably in 
the mid-1970s—but the operations appear not to have been compromised until 1985. 
In any case, it is evident that their effects continued long after. 
Detailed information on the Soviet Biopreparat programs became available to West­
ern intelligence only in the period 1989 to 1992, when three key scientists active in the 
biological weapons program defected to the United States and Britain. (Also, in 1991 
a fourth scientist, still in the Soviet Union, publicly disclosed the secret super nerve gas 
program.) The most complete open account of the Soviet biological weapons program 
has appeared in a recent book by one of the three defectors, Kanatjan Alibekov, a Ka­
zakh who rose to become deputy director of Biopreparat from 1988 to 1992, when he 
defected. Under his new name, Ken Alibek, he published Biohazard in 1999. 

 
Polyakov’s Run
The Art and Science of Military Deception	
543
In addition to detailing the Soviet biological weapons program in the 1970s and 
1980s, Alibek bears witness that Soviet scientists were constantly spurred on by being 
told that the United States had a huge biological weapons program. He writes that the 
precipitating factor in his own decision to defect was his shock on learning from a per­
sonal visit in late 1991 to Fort Detrick and Pine Bluff, the former U.S. biological weap­
ons centers, that they had long before been closed down as active centers of research. 
This former Soviet scientist—defector and other Russian scientists have made clear 
that leaders of the Soviet military-industrial complex were all too ready to use reports 
that the United States was working hard in the CBW field to support their efforts to get 
more resources for their own programs. U.S. disinformation not only influenced Soviet 
beliefs, it was also readily used by Soviet officials to serve their own purposes. 
Act Three
The third act of this drama has been the legacy of the American CBW disinformation op­
eration in the post-Cold War era. As Alibek and the other Soviet scientists have revealed, 
Biopreparat and the overall CBW program survived the end of the Cold War. These pro­
grams were curtailed by Mikhail Gorbachev in the late 1980s, and supposedly ended in 
1990. Yet they continued on an attenuated clandestine basis, either because Gorbachev 
was persuaded that the United States also continued to carry out CBW research, or be­
cause the operation was so well covered even from him that he failed to cut it off. 
Boris Yeltsin, in turn, by a decree on April 11, 1992, again officially terminated 
the program. But there remain strong suspicions that it continues covertly on a smaller 
scale. 
An exchange of official inspection visits by American and British scientists to four 
key former Biopreparat laboratories was arranged under Gorbachev in early 1991. In 
turn, Soviet scientists—including Alibek—inspected former biological weapons facili­
ties in the United States. Yet some Russian facilities and activities may remain con­
cealed. It is very difficult to distinguish between research on epidemiology and defensive 
measures, which are permitted under the treaties, and research on actual chemical and 
biological weapons, which is banned. 
In any case, the U.S. disinformation and deception operations of the 1960s and 
1970s, designed to stimulate Soviet interest and investment in CBW, were only too suc­
cessful, leading to the development of effective chemical and biological munitions and 
to a program that may still exist on a reduced scale a decade after the end of the Cold 
War. 
This is a disastrous outcome. Although there is little danger of Russia (or the United 
States) using CBW, there is the new danger that remnants of the vast U.S.-encouraged 
Soviet programs may end up in rogue states or even in the hands of freelance terrorists. 
There have been charges that senior Russian officials in the program (including its for­
mer director, Lt. Gen. Anatoly Kuntsevich) supplied, or conspired to supply, advanced 
chemical weapons technology to Syria in the early 1990s. 
Fortunately, the only known “brain drain” of top scientists from the Soviet program 
has been to the United States, Britain, and Israel. Nonetheless, in addition to advanced 
chemical and biological agents and technology another legacy of the U.S. deception 
operation is the existence of a large number of former Soviet CBW scientists who have 
had great difficulty finding new and acceptable roles in a shrunken Russian economy. In 

Polyakov’s Run
544 
The Art and Science of Military Deception
addition, Russia’s remaining chemical munitions and CBW equipment and technology 
are inadequately protected, and the Russian government needs to institute a massive 
and costly program to dispose of its large stocks of chemical munitions. 
There were, and to some extent remain, other less tangible but nonetheless real 
adverse consequences of the “successful” CBW deception operation. Not only did the 
U.S. disinformation program lead to unexpected and undesired Soviet achievements in 
developing chemical and biological weapons, it also contributed to mutual fear, suspi­
cion, and tension. 
The program undercut Soviet belief in the efficacy of arms control and in the in­
tegrity of American policy by misleading Soviet officials into believing that the United 
States was deliberately violating the Biological Weapons Convention, justifying their 
doing so as well. But were the potential benefits of the deception worth besmirching 
America’s reputation? 
These are some of the broader ramifications of strategic deception operations that 
were not in this instance—and generally are not assessed or even considered before deci­
sions are made to forge ahead. 

545
Section XVIII:
Detecting Deception: When Detective Meets 
Deceiver


547
C H A P T E R  6 1
Counterintelligence (CI) vs. Counterespionage 
(CE)1
Robin Winks
Robin Winks was a historian, diplomat, and author.  A Fulbright scholar in New Zea­
land, Winks earned his Master’s degree in Maori studies and went on to earn his Ph.D. 
from Johns Hopkins University.  Between 1969 and 1971, he served as the U.S. Cultural 
Attaché to the American Embassy in London, and was a regular advisor to various 
government agencies.  In addition to his diplomatic work, Winks wrote about detective 
fiction, publishing “Detective Fiction” (1980), “Modus Operandi” (1983), and “Col­
loquium on Crime” (1986), among others. 
Intelligence is, of course, evaluated information, and there are hundreds of ways to assist 
a foreign evaluator to arrive at the wrong conclusions. While strategic deception was 
central in time of war, since it had immediate relevance to action, it is also important 
in time of peace, since it involves controlled, purposeful, and intimate contact with po­
tential enemies. Counterintelligence and counterespionage work is, therefore, always in 
potential conflict with those in any intelligence organization whose primary concern is 
security. If security is the most important goal, the next logical step after the discovery 
of an opposition network is to make certain one has found all members of the network 
and then obliterate it. CE, on the other hand, would wish to exploit the network, to play 
it back to the enemy. This is highly dangerous if all members have not been uncovered, 
or if some only pretend to a willingness to be exploited and then pass information in 
such a way as to reveal that they have been doubled. Those who are security-minded 
will avoid foreign agents; CE will move in on them. Angleton knew which response he 
thought most effective, and he recognized that CE was not likely to be fully understood, 
could not even be fully explained since it depended upon obscuring intentions as well as 
operations. Security, operational branches, CI, and CE would often be at cross-purposes, 
and so there would always be suspicion and competition within any centralized intel­
ligence agency.2
1.	
Robin Winks, “Counterintelligence (CI) vs Counterespionage (CE),” in Cloak and Gown, New Haven: Yale Uni­
versity Press, 1987, pp. 421–424.
2.	
Counterintelligence and counterespionage are two terms much abused, and the distinction between the two is 
discussed in several books. Buffs like to argue about whether hyphens are required or not and enjoy pointing out 
differences that arise when the words are seen as nouns, verbs, or adjectives. Norman Holmes Pearson’s papers con­
tain a document, stamped Secret, which sets out the definitions as used by the OSS. CI is “all efforts to neutralize, 
repress or eliminate the activity of enemy inimical or other persons or groups or governments or their representa­
tives to secure intelligence the obtaining of which adversely affects the national security.” CE is a subdivision of CI 
and involves human agents. It is “all efforts to neutralize, repress, or eliminate the practice of spying or employment 

Counterintelligence (CI) vs. Counterespionage (CE)
548 
The Art and Science of Military Deception
When counterintelligence actually works, it becomes a form of political action. As 
Lenin observed, every intelligence operation has a political object; CI helps to find what 
that objective is. Since no intelligence body in any democracy is supposed to engage in 
political activity, the success of any counterintelligence operation has to be hidden. Only 
failures generally become known. There can be no expectation of public praise, for any­
thing deserving of praise must be kept secret. Counterintelligence functions are positive 
intelligence. Operations might be closed down, and yet, if penetration of the enemy has 
occurred, the operation can still run. CE is like putting a virus into the bloodstream 
of the enemy. Such an approach involves the longest-range views possible; intelligence 
can never be static, since the definition of the enemy may change, as postwar shifts had 
shown. One might never know who one’s enemies will be, for revolution and subver­
sion may turn even the staunchest allies into the bitterest of enemies decades down the 
road; one must hide long-range activities from friends as well. Inevitably this will seem, 
indeed for all practical purposes will be, paranoia. This is not to be helped. There are 
a few lines from Stephen Crane that elliptically sum up the delicate balance: “A man 
feared that he might find an assassin; another that he might find a victim. One was more 
wise than the other.”
Counterintelligence, then, was not meant to apprehend enemy agents, or to operate 
against the enemy in a defensive way, despite the misleading implications of “counter.” 
Rather, as an offensive operation, CE was meant to use the opposition’s human initia­
tives against itself. This could scale the heights of the absurd if not in the hands of the 
most clever of men. In 1963, using the pseudonym Christopher Felix, James McCargar 
had written what is widely regarded as the best general book on the methods used in 
“the secret war,” The Spy and His Masters. There he describes a scene from Romanoff 
and Juliet, as played by the actor Peter Ustinov. Ustinov is prime minister of a tiny, un­
aligned nation caught between the Russians and the Americans. He meets the American 
ambassador and learns that the Americans know of a secret operation which will give 
the Soviet Union dominance over Ustinov’s country:
After a bit of reflection, the Prime Minister . . . calls on the Soviet Ambassador. After some 
preliminaries, he says to the Soviet Ambassador, “They know.” The Soviet Ambassador re­
plies calmly, “We know they know.” Back to the American Ambassador goes Ustinov. “They 
know you know,” he says conspiratorially. The American Ambassador smiles confidently. 
“We know they know we know,” he answers. Ustinov returns to the Soviet Ambassador. 
“They know you know they know,” he says. To this the Soviet Ambassador replies, trium­
phantly, “We know they know we know they know.” Once again the Prime Minister calls 
on the American Ambassador. “They know you know they know you know,” he says, weary 
and curious at the same time. The American Ambassador repeats it after him, counting on 
his fingers. “What?” he suddenly cries in horror.
of secret agents by enemy inimical or other persons or groups or governments or their representatives to secure 
intelligence the obtaining of which adversely affects the interests of the United States.” X-2 began as CI but in 
time was referred to as CE in much of the documentation. These definitions are found in typed documents on the 
theory of the running of Controlled Enemy Agents, on CI double agents in neutral countries, and similar subjects, 
in Pearson’s wooden files, box 2, as noted in the previous chapter, and they appear to be lectures Pearson prepared 
for briefing newly arrived agents. One may surmise that Angleton was introduced to the terminology by Pearson.

 
Counterintelligence (CI) vs. Counterespionage (CE)
The Art and Science of Military Deception	
549
The point was simply—not so simply—to “raise the tension one step higher”: never 
to allow your ambassador to be the one who must count on his fingers. To some this 
was of the essence of successful spy craft; to others, it was madness, the essence of 
an escalating cold war which made no sense. The existentialists would tell us that to 
know what someone else knows is impossible in any case. Knowing what they know, 
one still would not know what action they might take on what you know, even with a 
deep understanding of national character. The whole thing was simply too dangerous, 
a game with such destructive potential it ought not to be played at all. Or so some felt; 
to others, CI and CE provided superior intelligence, were the very essence of the game, 
the ideal. Until Angleton ran into a director of central intelligence who simply could not 
or would not accept the value and methodology of counterintelligence (or, to be more 
charitable, took the first view, that the risks outweighed the possible gains of sending a 
Ustinov back and forth across the floor of the stage), he was able to pursue CE, and its 
most important technique, penetration, almost without hindrance.
Angleton was an ideal man for this game. He could keep track of the agents, dou­
bled, tripled, turn and turn again. Christopher Felix describes the problem well: “The 
decisive question is precisely which turns are genuine and which are false. This is but 
one of the problems which makes CE an extraordinarily complex affair; the determina­
tion of which turns are genuine and which false is a painstaking exercise in the control 
of information, of who knows what when, that requires constant alertness and a simul­
taneous grasp of both large perspective and detail. It is obviously an intellectual exercise 
of almost mathematical complexity.” Angleton saw everything in relation to everything 
else. 
He saw questions in the round, immediately ticking off relationships, ramifications, 
subquestions which others did not think of. If a double agent were suspected, might one 
not learn about that duplicity by an examination of the precise time sequence and con­
tent of information, that is, by developing a “chron”? If there were a change in Israeli 
intelligence, how would this influence South Africa? If Communist China appeared to 
be breaking from the Soviet Union, might this not be merely a very long-range strategic 
deception?


551
C H A P T E R  6 2
Counter-Deception Planning
William R. Harris
Harris’s methodology most importantly identifies and analyzes three techniques for de­
tecting deception and hedging against failures to detect deception:
1.	 Reconstructive 
Inference: 
Attempts 
to 
reconstruct 
patterns 
of 
the 
“sprignals”(spurious signals).
2.	 Incongruity Testing: This is “the traditional form of intelligence analysis, which 
tests alternative hypotheses.”
3.	 Vulnerability Assessment: Involves predicting “future vulnerabilities on the ba­
sis of Bayesian estimates of conditional probabilities derived from past cases of 
deception.”
Dr. Harris, a Harvard JD, had been a senior staff member in The RAND Corpora­
tion’s Social Science Department, 1972–1991. He then became a freelance consultant 
whose efforts shifted away from the study of deception and counterdeception to matters 
of international law and, regrettably, vanished over the horizon.
Counter-Deception Planning: Methodologies
There is hardly an adequate theory of deception, much less a theory of counter-decep­
tion. In addition to Barton Whaley’s Stratagem, which organizes conclusions from the 
empirical data in his appendixes, and which draws upon strategic concepts, of the late 
B. H. Liddell-Hart,1 there are two stimulating pieces by R. V. Jones of the University of 
Aberdeen: “The Theory of Practical Joking—Its Relevance to Physics,” Bulletin of the 
Institute of Physics (June 1957), pp. 193-201, and a lecture on “Irony as a phenomenon 
in natural science and human affairs,” Chemistry & Industry (1968), pp. 470-477. I 
provide these references in the text because they are seminal pieces, printed in journals 
to which not everyone subscribes.
The Nature of a Counter-Deception System
Counter-deception planning, as I see it, involves three related concepts: (1) detection of 
adversary deceptions; (2) the adoption of countermeasures that reduce the likelihood 
and adverse consequences of these deceptions, and that may involve counter-deception 
deception operations, which for simplicity we will call counter-stratagems; and (3) the 
coordination of detection and countermeasure programs in a counter­deception system.

Counter-Deception Planning
552 
The Art and Science of Military Deception
This section focuses upon the interrelated problems of detection and countermea­
sures; those who read between the lines may identify organizational implications for a 
counter-deception system.
It is worthwhile to distinguish between a counter-deception system and seat-of-the-
pants counter-deception efforts. The latter generally consist of uncoordinated, perhaps 
sporadic efforts to detect and outwit foreign deception operations. The seat-of-the-pants 
method may involve overconfident intelligence analysts who know something about 
deception methods and who serve as self-appointed detection specialists. It may also 
involve the production of uncoordinated2 analyses of particular components of a decep­
tion package—for example, a report on the design and apparent objective of various 
camouflage or “dummy” configurations; a content analysis of a channel of cryptologic 
intelligence, when one suspects one’s adversary has identified the cipher insecurity; or a 
content analysis of data transmitted by enemy-controlled double agents for a particular 
circuit or period of time. The analysis of possible components in deception packages 
does not constitute a counter-deception system; such efforts are, however, ripe for orga­
nization into such a system.
Seat-of-the-Pants Counter-Deception Methods
Section II [“The Efficacy of Deception,” above] is intended as an argument against 
the seat-of-the-pants approach to counter-deception planning, in which every analyst 
serves as his own counter-deception expert.3 This method simply does not work. Those 
who are still unconvinced should read Barton Whaley’s Stratagem. Even those who are 
already convinced could profit from Stratagem, for they would see that the very intel­
ligence services and operations planners who excelled at strategic deception were also 
suckers at their own game without a counter-deception system.
The British were probably the outstanding experts at deception in World War II, yet 
they fell for the “threat” of a cross-channel German invasion (SEA LION) months after 
Hitler had terminated the program, leaving only enough traces to deceive the Soviets be­
fore Operation BARBAR0SSA.4 Similarly, although a frightfully clever British deception 
program consistently misled Abwehr intelligence in North Africa (1942–1943), the Ger­
mans controlled a British sabotage-intelligence network in Europe (Operation NORTH 
POLE).  And when the British realized, after more than a year of being duped, that the 
entire NORTH POLE system was operating under German control, they in turn misled 
the Germans into believing that this was the only British sabotage network in Holland.5
As previously calculated (in Section II), patient development of deception capabili­
ties can lead to the near-certainty of obtaining misestimates of intentions, given suffi­
cient planning time and expenditure of substantial deception assets—without a counter-
deception system. Those who still cling to the hope that the “well-rounded” intelligence 
professional can, by the seat-of-the-pants method, reverse the tide of deceptively in­
duced misestimates should digest the following data from Stratagem:
Among 114 cases of deception or surprise, Whaley found 10 cases in which the 
victim of attack received detailed documentation respecting supposed enemy plans well 
before the attack itself. Of the 10 sets of enemy “plans,” five were carefully designed 
disinformation packages and five were genuine breaches in security. All five of the false 
sets of enemy plans were accepted as genuine by the intended victim, and four of the five 
genuine plans were dismissed as unreliable.6

 
Counter-Deception Planning
The Art and Science of Military Deception	
553
Is there no justice in intelligence estimating? It would appear that amateur counter-deception 
efforts are counter­productive. Had these analysts chosen to flip coins instead of trusting to 
their judgment, in 99 percent of the cases they would have correctly identified more than one 
of 10 sets of documents.7
Detection of Deception: Three Theories
There are at least three techniques for the detection of deception operations and the 
identification of underlying verities. The three methods are interactive—one method 
may assist in the exploitation of another method, and vice versa. For convenience I 
label these methods with three shorthand designations: (1) reconstructive inference; (2) 
Incongruity testing; and (3) vulnerability assessment.
Reconstructive Inference
The reconstructive inference method involves attention to the sprignal [spurious signal] 
patterns transmitted by one’s deception adversaries. Mrs. Wohlstetter’s Pearl Harbor 
study demonstrates how difficult it is, without hindsight, to differentiate the signals 
from the noise. It is with some trepidation that one would venture to separate signals, 
sprignals, and noise, all at the same time. It is probably best first to concentrate upon the 
separation of sprignals from signals, recognizing that a bit of random noise or just plain 
junk will find its way into both categories.
To identify sprignals, one must guard against intelligence collectors who value their 
cleverness as analysts and who consequently throw out or block transmission of iden­
tified sprignals. It would be helpful to have a community-wide review of data collec­
tion—both intelligence and counter-intelligence. It may be that most of the agencies 
make at least a minor effort to collect what appear to be sprignals. Do all of the col­
lectors and interim analysts know how important it is to collect sprignals as well as 
signals or to indicate all of the danger signs that may be a tip-off [that] a seeming sig­
nal is really a sprignal?  Do the important personnel have much idea of the past track 
record of predictions? Have they read Whaley’s Stratagem or a fuller equivalent based 
upon still-classified records? Do they know of an agency center for the transmission of 
sprignals, suspected sprignals, or danger signs, or do they just send along their suspect 
information with all of the rest, risking its loss in the massive flow of data?
When a cipher is broken too easily (perhaps with the assistance of a too-easily placed 
clandestine agent), when sophisticated camouflage is discovered, or when a double 
agent is found to be under the “control” of the opposition, are the proper steps taken to 
identify the spurious signals and to segregate those perhaps designed for our “witting” 
collection as opposed to those designed for our unwitting collection?8 In short, is there 
a collecting and coordinating program to distinguish the sprignals from the signals, and 
the intentionally obvious sprignals from the others? One must be prepared to throw 
out obvious “cover plans” so as to concentrate upon more sensitive deceits, which may 
yield inferential clues.
To distinguish the patterns of deceit aimed at policy elites from those aimed at more 
diffused targets is not an easy task. The problem of differentiating strategic deception 

Counter-Deception Planning
554 
The Art and Science of Military Deception
from propaganda comes immediately to mind. We can begin with F. M. Cornford’s 
definition of propaganda: “that branch of the art of lying which consists in very nearly 
deceiving your friends without quite deceiving your enemies.9
If the usual run of propaganda operations is somewhat dissociated from strategic deception 
programs, those who reconstruct foreign deception patterns may be led astray, particularly as 
to “black” propaganda, which is as likely as not to come through clandestine agent sources.
One [American] deception planner [H. Wentworth Eldredge] of World War II sheds 
light on this problem in a backhanded way, revealing the possibility that inconsistencies 
in propaganda and deception patterns might unveil genuine intentions, at the same time 
implying that “black” propaganda may be a poor index to the purposes of deception 
planners themselves:
The biggest damn nuisance in our experience was the truly silly black and grey propaganda 
people on one’s own side. They had a low security classification (so they never knew any­
thing), they had high intelligence, enormous energy, quite a lot of resources, a great desire to 
win the war single-handed (thus they shot off in all sorts of private directions) which seemed 
to us to compromise what we were doing. They confused a target of the general enemy pub­
lic (or his troops) with our target, the enemy commander through the intelligence system.10
The above confirms what we already expect: that there is noise in the collection of 
sprignals just as there is noise in the collection of signals. One should not neglect the 
noise from the intelligence of various profiteers, who foist their imagined data upon any 
willing buyer. Reconstructive inference can yield no helpful clues here, except perhaps 
as to the mental state of the involved entrepreneur. Another form of noise may involve 
low-level cover and deception plans, which scarcely lead to useful inferences. Again 
from [Eldredge’s] World War II experience:
Actually a lot of fairly obvious things [in a deception program] were really a cover for one’s 
own “unwitting” people who were not to know that other more complex and more “clas­
sified” operations were going on to really get to the enemy command decisions. This is not 
to gainsay that routine cover and deception operations of this sort were not done to connect 
with all enemy intelligence systems.11
The foregoing suggests that it may be considerably easier to collect sprignals than to 
separate them from associated signals and noise.
Testing for Signals and Sprignals
Some sprignals may be self-identifying; if so, we may search for confirming data or 
channels that may yield already anticipated sprignals at some later date. A group that 
is sufficiently lucky—or successful in penetrating foreign deception systems—will learn 
of deception efforts from “agents in place,” or from modes of collection “by technical 
means.” A somewhat less well-established group will work out their incomplete jigsaw 
puzzles until some of the pieces fall into place inferentially. They will debrief defecting 
stratagematists with unusual care, reconstruct the sources of “bum” intelligence in past 
encounters, and seek to eliminate the circumstantial noise while labeling and watching 

 
Counter-Deception Planning
The Art and Science of Military Deception	
555
the suspicious channels. They will emphasize the sprignal identification missions of the 
counterintelligence community. They will prod security experts for more pessimistic 
evaluations that identify those sources of insecurity that may have been turned against 
them. And they will watch those sources carefully.
The incidence of signals and sprignals may be gauged, in part, from analysis of past 
patterns of deception. A politician who deceives his compatriots (even in pursuit of “na­
tional” objectives abroad) may not enhance his esteem. It should not be surprising that 
most of the literal statements of leading statesmen are at least technically truthful, or 
at least so intended. The implications of tendentious remarks may be far less reliable—
as with the implications of Khrushchev’s boasts of growing Soviet missile production 
in 1957–1959.12 And the literal or implied meaning of “background” statements not 
linked to a source whose credibility is highly valued may be of lessened reliability. So too 
with official press statements, as with the indirect TASS denial of September 11, 1962 
that nuclear missiles would” be sited in Cuba.13
The careful analyst may wish to distinguish the past reliability of literal statements, 
of inferences from tendentious remarks ripe for the plucking, of “background” interpre­
tations, and official but anonymous press releases. One analysis of perceived mendac­
ity in and around Washington, D.C. is consistent with observations of foreign states­
men. Although infrequently finding “the flat lies ... and petty mistruths,” Anthony Lake 
reports:
There have been still more misleading statements—not quite lies, but partial revelations of 
the truth deliberately designed to fool the public into believing what the government wants 
it to believe.  These must be considered the functional equivalent of lies.  The public does not 
read the fine print in government statements, and when it is fooled the result is the same loss 
of confidence which follows a flat lie.14
The counter-deception analyst will learn to differentiate the literal from the implicit, 
the flat from the ambivalent lie, the deceived from the deceiving spokesman.15 Further, 
by cross-checking deep penetrating technological sensors (by the “incongruity testing” 
method to be discussed shortly) it may be possible to establish with high confidence that 
a source or channel of data is indeed a stratagemic producer and not a source of signals 
or noise. If the exotic sources of the past have been the favorites of deception planners 
precisely because they were the ones that received top-level attention, these “special” 
sources will not be adopted as arbitrary standards against which potential sprignals will 
be tested.
It is equally important to guard against the temptation of resorting to a test standard 
derived from “traditionally reliable sources.” Over extended contests between intelli­
gence and counter­intelligence adversaries, both sides tend to develop an understanding 
of what an adversary views as reliable, and deception planners target those channels. 
Data that appear “reliable” are likely to conform to preconceptions or shared expecta­
tions, and deception planners like to reinforce these vulnerabilities. Thus, traditionally 
reliable sources and data cannot be segregated as an automatic standard against which 
to test new sources or new data.
Separating truth from deception and noise involves more than a comparison of the 
unknown with a subset of the “traditionally reliable.” It is more prudent to assume that 
all channels of information are unreliable in varying degrees and to concede the role of 
chance in strategic forecasting. By conceding the hazards of the intelligence business, 

Counter-Deception Planning
556 
The Art and Science of Military Deception
one is more likely to embark upon an ongoing sifting and resifting effort: identifying 
tentative subsets of signals and sprignals, or inconsistent clusters of data, that demand 
critical and recurrent appraisal.
If the processes of stratagemic analysis are coordinated with the aid of computers, it 
may be possible to generate data banks and analytic specialists familiar with the styles 
of unseen adversaries. Having collected and identified a mass of sprignals but not all 
of those available, and having recognized that this collection is cluttered with residual 
noise, we will want to obtain a set of sprignal patterns or relationships, and by inference 
from this universe of data to fathom the ulterior purposes and strategic links that may 
unite; the strands.16
Reconstructive inference testing has more limitations than those resulting from the 
ambivalence associated with residual noise. It is important to recognize that the infer­
ences drawn from perceived deception plans are sensitive to both time and context. If a 
pattern of sprignals is stale, it may provide clues to the last encounter, not the next one. 
One World War II operator, H. Wentworth Eldredge, reflects that “some of the best C. 
& D. operations (after an initial plan) were played by sensitive and daring men acting 
pragmatically.” Detection of an initial stratagematic plan may not prepare sprignal ana­
lysts for the fluidity that follows. Similarly, as with women’s fashions of recent years, 
one may be expected to see through more than what immediately meets the eye, and if 
one enjoys the phenomenon one may not worry about its design.
Stratagematists are at least as bright as lingerie designers. For example, in the Italian 
campaign of World War II General Alexander once changed his mind about the optimal 
place of attack only to discover that his deception staff had already encouraged the Ger­
man command to concentrate resources at this newly chosen sector of the Front. A so­
lution was found: intelligence was “leaked” to the Germans that the original deception 
target was just that, and information on the preliminary build-up at the now abandoned 
assault area convinced the Germans of the “real” target. A new deception plan rein­
forced the German smugness at their “discovery” of the prior stratagem, and General 
Alexander’s forces attacked with surprise in the area of the initial deception target.17
Despite its limitations, reconstructive inference testing on the basis of sprignal con­
figurations deserves a more systematic effort and higher priority than the public litera­
ture suggests it has received.
Upon occasion we may surprise ourselves with the success of our inferences. After 
all, most deception plans are conceived on the basis of fairly full knowledge of actual 
plans. What oversight or subconscious slip finds its way into the final stratagemic prod­
uct may not be apparent until it is detected by the adversary. Such irony, which R. V. 
Jones defines, as “a contradictory outcome of events as if in mockery of the promise and 
fitness of things,”18 is a faithful companion of history, and it should not be surprising if 
stratagems are uncovered that reveal far more than they need have done.
From the stratagematist’s perspective, “We were simply scared to death always that 
the cover plan would be blown indicating the true plan with great loss of many real 
human beings; it was a soul-shattering experience to be the mirror image of a ‘great 
captain.’”l9
Once the importance of analyzing sprignals is more generally understood, a coun­
ter-deception group may be willing to pay a higher price to receive a good selection 
of such data, provided of course that it has high confidence in the tentative channel 
identifications. It may be willing to suffer the inconvenience and possible sense of in­
justice in retaining on its payrolls an unseemly collection of identified double agents. It 

 
Counter-Deception Planning
The Art and Science of Military Deception	
557
may continue to digest cryptologic or electronic sources at substantial cost, although 
particular channels are likely to be carrying “chicken feed.” I am not suggesting that re­
sponsible officials do not recognize that in sprignals there is some utility. I would expect 
that monitoring of the types mentioned already takes place. But are the relevant officials 
aware of the usefulness of collecting enough sprignals, sufficiently well coordinated and 
analyzed, to enhance predictive performance in the critical cases? Obviously there are 
limits as to what should be spent on the collection of misleading information.
As with any intelligence system, a sprignal collection and analysis network must be 
safeguarded against system “overload.” According to the former Deputy Chief of the 
Czech “Disinformation Department,” Ladislav Bittman, the Czech secret service alone 
mounts over 100 disinformation campaigns per year against Western targets. Of these, 
a good number are coordinated by the Soviet counterpart in Moscow (Department “D” 
of the First Chief Directorate, KGB) and orchestrated with supporting operations on the 
part of other East European services. It would be a mistake to add the number of annual 
operations of each of the East European secret services, since we would be recounting 
aspects of the same Moscow-coordinated operations in many cases—especially in the 
years since 1963–­64 when most of the East European services established counterpart 
Department “D”s for liaison with the Soviet mother department. Nonetheless, we can 
assume that there are at least several hundred disinformation programs per year tar­
geted against Western audiences.
This number of operations could completely occupy the efforts of a counter-decep­
tion system. Bittman’s book, The Deception Game, indicates that most of these East 
European “special operations” are propaganda operations, mainly “black” operations 
and often involving exploitation of clandestinely obtained documents. Although in­
fluential Western audiences are the main targets, these operations are mainly disinfor­
mation programs rather than strategic deception operations seeking to have a direct 
influence on decisions of governments. A counter-deception system would do well to 
leave the analysis, detection, and mounting of counter­ operations to those segments of 
psychological warfare agencies specializing in these subjects.
Those who man the counter-deception system that guards governmental decision­
makers and their intelligence services from the strategic deceptions of their adversaries 
should protect their system from the deluge of relatively trivial problems associated 
with these disinformation programs. It would be more helpful, for example, to identify 
the channels than the contents of these disinformation programs. The same wire ser­
vices’ reporters, clandestinely influenced or owned newspapers, magazines, publishing 
houses, and the like that peddle disinformation packages are likely to be available for 
strategic deception in critical encounters. Detailed content analysis, refutation, and de­
sign of counter-operations should be left to psychological warriors. If for no other rea­
son, counter-deception specialists should avoid detailed involvement so as to preserve 
their attention span and peace of mind for more critical contests.
There are three basic filtration barriers that can protect a counter-deception system 
from sprignal overload. The first is a feedback system that encourages the entire intel­
ligence community (and its foreign liaison agencies) to restrict its collection of sprignals. 
Some reduction in the volume of incoming data and more rigorous quality control 
would ameliorate the problem at the outset. Even so, the collectors’ judgment should 
not be trusted as to which sprignals are likely to provide the most helpful inferences; 
further, those agencies or segments of agencies that specialize in psychological opera­
tions will demand the collection of many sprignals that are of trivial consequence from 

Counter-Deception Planning
558 
The Art and Science of Military Deception
the perspective of the counter-stratagematist. The counter-deception system must be 
equipped with a feedback and filtration system of its own, within the broader intelli­
gence and counter-intelligence communities. This set of barriers should be complement­
ed by the allocation of effort among the myriad clusters of sprignal packages available 
within the counter-deception system’s data pool.
One of the reassuring aspects of Whaley’s Stratagem is the disclosure that the same 
old bag of tricks that worked in World War I was tried with a few new wrinkles in 
World War II and afterward. Once counter-deception systems enter the picture, decep­
tion planners will adapt, but they too have their problems. If deception planners mount 
only small stratagems so as to avoid detection by the analysts of sprignals, they run the 
risk that their adversaries’ penetrating intelligence will lead to accurate forewarning. If 
they mount moderate level stratagems along only a few channels, they run the risk that 
their adversaries’ “incongruity testing” will unravel inconsistencies and unmask the un­
derlying plans. If they mount “grand” stratagems they may reduce the risk of detection 
by “incongruity testing,” but they enlarge the risks from reconstructive inference while 
jeopardizing many of their deception assets. If nothing else, a system for the detection 
of stratagems can increase the rate of depreciation of deception assets.  One may still 
deceive, but less often, and with fewer undetected sprignal channels for play in later 
encounters.
Incongruity Testing
Incongruity testing involves alternative pattern matching and testing for internal and 
inter-pattern consistency.20 It is no accident that many deception planners are great prac­
tical jokers as well, for both specialties thrive upon the same fertilizer, incongruity. Since 
incongruity testing is the guts of intelligence analysis, the Achilles’ heel of deception, and 
the essence of joking, I cannot recommend too highly Jones’ previously cited paper, “The 
Theory of Practical Joking.”
Simple incongruities, direct or inverted, can be humorous enough, but the more 
advanced jokes usually involve a period of preparation and induction, sometimes elabo­
rate, before the incongruity becomes apparent. They are then called hoaxes.21
The induction of incongruity in the perceptions of an adversary constitutes a strata­
gem or deception. At least theoretically, this induced incongruity could be discovered, 
given sufficient data and hypothesis testing. The contradictions inherent in the simul­
taneous presence of “reality” and a false image of that reality are amenable to both in­
ductive and deductive testing. But as Klaus Knorr notes of “the inductive fallacy,”22 one 
cannot assume, as some historians and intelligence analysts would like to believe, that 
“the facts speak for themselves.” In his survey of predictive failures Benno Wasserman 
observed a tendency to postpone induction until “all the facts are in”—that is, until it is 
too late to provide useful warning.23
If an adversary provides the facts and perhaps a set of inferences sustaining one pat­
tern of inductive reasoning, an analyst must overcome the natural inertia that prevents 
him from generating alternative hypotheses.24 The human mind is not especially well 
suited to the task of generating alternative hypotheses and of juggling them all at the 
same time. This judgment leads me to a small difference with R. V. Jones with respect 
to the ideal intelligence organization. In a classic lecture on “Scientific Intelligence” in 
February 1947 Jones remarked:

 
Counter-Deception Planning
The Art and Science of Military Deception	
559
An Intelligence organization, despite the Encyclopedia Britannica dig about there being three 
kinds of Intelligence—human, animal and military, resembles in fact a human head very 
closely. The sources of Intelligence correspond to the sense organs of the head; the detailed 
resemblance here is in some cases remarkable, with photographic reconnaissance as the eyes 
and the radio listening service as the ears. The senses pass observations to the brain, where 
they are correlated, and a particular sound is associated with a particular visual object. In 
Intelligence, information from the sources is likewise fed to a collating centre, corresponding 
to the brain; and while the brain, to be successful, must have a good memory, an Intelligence 
organization must also have a good memory built up of the individual memories of its staff 
and its filed records. So far no machine has been found to perform these functions nearly so 
well as a good human mind, and the design of an Intelligence organization must be such as to 
make it resemble a single perfect human mind as closely as possible. It follows from this that 
the most successful Intelligence organization is likely to be that which employs the smallest 
number of individual minds each of the greatest possible, ability.25
In seeking to separate signals and sprignals by incongruity testing, a counter-
deception system should compensate for the vulnerability of conservatism in human 
data evaluation. Carl Kaysen has run into the problem of cognitive rejection, when fresh 
data do not mesh with existing perceptual patterns:
Many individual items of intelligence information must be rejected as unreliable, false, ir­
relevant, useless, and so on. The judgment on which rejection is based is often a consistency 
judgment. Rejection depends on whether a particular piece of information seems reason­
able in the light of a large number of other pieces of information, or whether it contributes 
anything which is useful in the light of such other information. If the officers responsible for 
analysis were deprived of the opportunity of making such consistency judgments, extending, 
over the whole range of intelligence materials, then their judgments would necessarily be less 
good than they might be.26
This natural rejection cycle, the removal of the “odd” bits before cooking up a pu­
ree of consistent data, is pernicious. Analysts should not assume that non-access to “the 
whole range” of intelligence materials will “necessarily” impair intelligence judgments. 
On the contrary, computers that suppress segments of the data base from consideration 
may be beneficial. By using techniques of sequential analysis, analysts may be able to 
compensate for the weaknesses in human cognitive rigidity, screening out initial percep­
tual patterns and preconceptions.
Machines have one advantage over the human mind: the capability to forget on a 
temporary basis. In this respect, a computer-assisted intelligence system has a distinct 
advantage over the organization Professor Jones has commended, one using “the small­
est number of individual minds each of the greatest possible ability.”
Instead of “rejecting” data, a counter-deception system may seek to place such data 
in alternative perceptual patterns. It may turn out that in the last analysis (by which the 
humble mean not the best but the last analysis before events overtake them), analysts 
will reject the first consistent patterns in favor of another one. Since stratagematists of­
ten reinforce pre-existing or early patterns, they [the analysts] should resist the tempta­
tion to think that they were “right all along,” unless the retesting of hypotheses provides 
frequent reassurance.
The human mind may repress valuable stored data, or dwell upon obsolete im­
ages. Fusing recalled experience and wishful thinking, the human mind assigns a priori 

Counter-Deception Planning
560 
The Art and Science of Military Deception
probabilities and only reluctantly shifts these judgments. Small group experimentation 
suggests a tendency to underestimate low probability events and a tendency to overes­
timate high probability events, hence susceptibility to deceptive reinforcement of the 
“conventional wisdom,” and undue disregard of rare events.27 Vulnerability to preju­
dice, preconception, and disregard of low probability events is reinforced by the con­
servative memory system of man. Given new information, the conservative system of 
human cognition tends not to change a priori probability assessments as much as the 
new evidence should encourage. Having recognized his own weaknesses, man can del­
egate some analytic functions to nonconservative probabilistic information systems.28
By testing alternative hypotheses—both inductive and deductive—sometimes with 
the “assistance” of memory and sometimes without this burden, one can identify a set 
of plausible alternatives, eliminating enough of the hypotheses to provide sufficiently 
unequivocal warning of most critical events. There is a beneficial interaction between 
analytic method (1), reconstructive inference, and analytic method (2), incongruity test­
ing. The set of possible sprignal patterns derived by method (1) can be tested against the 
broader mass of data analyzed by method (2). If the data are still ambiguous, “crash” 
intelligence collection (counter-deception intelligence) could resolve the doubts or at 
least lead to helpful probability refinements.
Moreover, conclusions from incongruity testing would help in discerning patterns 
and purposes of deception. Patterns of data may be identified as inconsistent with either 
a high-confidence expectation or a high-confidence post mortem. These patterns may 
be disaggregated and the component data and channels of data “tagged” with a con­
ditional probability of being sprignal resources. Over time, various potential sprignal 
resources can be tested and the conditional probabilities adjusted upward or downward 
as necessary.29 Clusters of high or low-probability sprignal data should assist in evaluat­
ing alternative theories.
Computer-aided incongruity testing offers substantial hope of predictive enhance­
ment, but, like other analytic techniques, incongruity testing has its limitations. The two 
central limits of incongruity testing involve what might be called disjointed incongrui­
ties and false incongruities. Disjointed incongruities involve inconsistencies that have 
become, in the perceptions of the viewer if not in fact, separated or mis-matched. In 
simplest terms, a disjointed incongruity is one that is not recognized because the sets of 
inconsistent patterns are never paired. In contrast, a false incongruity involves the pair­
ing of two or more apparently inconsistent patterns that represent a consistent underly­
ing reality. Incongruity testing involves risks of both sorts of errors. False incongruities 
clutter our task of identifying and choosing among genuine incongruities in two ways: 
Some of these apparent but unreal incongruities are a matter of different perspectives 
and some are a consequence of the random distribution of noise in perceptual systems. 
The design of disjointed incongruities is, in fact, the design of stratagems. Induction of 
such incongruities is labeled in Jones’ paper on “The Theory of Practical Joking” as 
the “Theory of Spoof.” Since disjointed incongruities represent the primary headache 
in counter­deception planning, we should explore the two main varieties, clandestinely 
disjointed incongruities and mutually disjointed incongruities.
Clandestinely disjointed incongruities are discussed, but not labeled, by Amrom H. 
Katz:
It is perhaps tautological to suggest that we have never found anything that the Soviets have 
successfully concealed. This is a self-contained proposition. But because we have indeed 

 
Counter-Deception Planning
The Art and Science of Military Deception	
561
found many things that the Soviets have built and deployed, it is possible that a certain kind 
of self-congratulatory smugness has crept into our intelligence system.30
Some of the most dangerous stratagems in peacetime, and in arms control environ­
ments in particular, may involve such clandestinely disjointed incongruities. Until ana­
lysts are able to pair and test the inconsistent patterns, they are unlikely to identify even 
that an incongruity exists.
Incongruities whose preliminary foundations are being laid by stratagematists are 
a special case of clandestinely disjointed incongruities. Here the problem is more dif­
ficult than that of penetrating the security of clandestine behavior, assuming that there 
is no special access to the future intentions of foreign stratagematists. Where foreign 
stratagematists have been cultivating access to our intelligence systems and where they 
have been “chicken feeding” these systems with generally truthful data of a consistency 
similar to what we would obtain by our own efforts alone, there is only one slender 
present incongruity to detect—that the channels of reception are either controlled or 
known and targeted by our stratagemic opponents.
Since analysts are unlikely to detect such slender incongruities, they can at least 
take steps to accelerate the detection process once their adversaries begin to feed these 
channels with more broadly incongruous data. They may find that the background 
collection of “chicken feed” will drown out the substitution of sprignals designed to 
mislead them at critical junctures. Masterman insists upon “the prime necessity for 
truth whenever truth is possible. A lie when it is needed will only be believed if it rests 
on a firm foundation of previous truth.”31 Masterman also believes that “the force of 
this [misinformation] depends upon the reputation of the sender and that a long period 
of truthful reporting is usually a necessary preliminary for the passing over of the lie.”32
If counter-deception analysts have some conception of the behavioral changes they 
should expect to encounter, through the use of sequential statistical analysis they may be 
able to reduce the detection time for a set of incongruities.33 Thus, they may be able to 
identify sets of sprignals and noise in combination, which with sequential analysis will 
allow them to disaggregate the two over time. Then, more refined sets of sprignals may 
be subjected to incongruity testing until, it is hoped, a set of meaningful signals emerges.
Adversary deception planners are not attempting to allow the easy matching of 
these incongruities. Masterman notes “the obvious fact that cover schemes ought to 
be as near the ‘real thing’ as was safely possible.”34 This places the deception planner 
in a bind. On one hand, he wishes to establish a deception program sufficiently close 
to reality that detection of incongruities will be retarded. On the other hand, he wishes 
to establish a deception program in accord with the preconceptions of the intended 
victims. As an Abwehr officer explained, “On the German side we only attached im­
portance to the reports of agents insofar as they fitted in with our own conceptions of 
the situation.”35
The deception picture that is compatible with an adversary’s preconceptions may be 
highly incompatible with what one intends to do. Consequently, the deception planner 
must choose between a deception plan that will be readily swallowed and one that is 
minimally incongruous with the planned operations. 
So, the incongruity of two or more patterns may emerge sufficiently early that in­
consistent patterns can be identified and matched.
The second form of unidentified incongruities involves a set of mutually disjointed 
incongruities (which R. V. Jones terms just “mutual incongruities”).36 Instead of seeing 

Counter-Deception Planning
562 
The Art and Science of Military Deception
situation A as perception A, one observer, B, holds perception B and another, C, percep­
tion C. It may be that perceptions B and C are, from different perspectives, representa­
tions of the same situation, but this situation is not situation A. Both B and C share 
misleading conceptions of the true situation, A.
Jones describes a situation in which neither B nor C is likely to learn of his percep­
tual error:
Induced incongruities mutual to two victims are possible. Each victim is led to believe in 
a false world-picture which is nevertheless consistent with and complementary to the false 
world-picture of the other victim. A simple example is the device of privately telling each of 
two people whom one is about to introduce that the other is a good fellow who has, howev­
er, been going through a severe nervous strain, and who is therefore apt to get both irritable 
and rude if contradicted. It is therefore advisable to humor him by agreeing with all that he 
says. The two victims then go to great lengths to agree with one another, and separate in the 
conviction that each has handled the other extremely well.37
Another set of mutually disjointed incongruities occurred during a “real” civil de­
fense attack warning in the western United States, which lasted for some seven minutes 
on May 5, 1955. An Air Force warning through civil defense channels, a warning yellow 
(“enemy attack is probable”), resulted in 67 of 77 sampled California civil defense dis­
tricts failing to start public sirens after verifying the validity of the warning. The failure 
of operators to follow instructions was in part the result of the mutual reinforcement of 
cognitive templates: civil defense operators did not start the sirens in part because radio 
stations had not adopted CONELRAD broadcasting on specified frequencies; radio 
broadcasters didn’t hear the sirens. One siren operator explained that he does not want 
to be the first person to set off the siren switches—that if he heard sirens in other areas 
blowing then he wouldn’t mind following them; and that even if he had received no alert 
signals he would set his sirens off if he heard others blowing.38
In this case, those who did not alert the public were right; there was no attack; but 
most were wrong in assuming they had not received a “real” Air Force warning and 
were affected by the mutual consistency of their perceptions and those of other warning 
system personnel. Mutual inaction bred reassurance. But the same result in an actual 
attack would result in the loss of many more lives.
In this same “attack,” a microcosmic example of shared disjointed incongruity oc­
curred when one civil defense operator heard the warning bell, saw the “yellow alert” 
light, and assumed that the telephone company had fouled up again. He called the 
repair service of the telephone company, and “reportedly was told by the repair service 
that a repairman would be sent to correct the [warning] device.”39 The warning de­
vice was working properly, but the imagined telephone system error provided mutual 
reassurance.
Sherman Kent, retired chairman of the Board of National Estimates, has often not­
ed the disconcerting fact that many future intentions are not knowable. Indeed, even 
from within the mind of the decisionmaker it will be impossible to identify incongruities 
before an intention is formed, and it will be impossible to decide which of the incongru­
ous patterns is correct so long as that intention may be switched.
The Whaley study demonstrates that all the major intelligence services have the 
utmost difficulty with such intentions estimates, and analysts should not expect their 
incongruity testing to reverse the abysmal predictive record. However, in conjunction 

 
Counter-Deception Planning
The Art and Science of Military Deception	
563
with the other methods, they can expect incongruity testing to improve performance 
insofar as it deals with capabilities or partially executed intentions, which leave at least 
preliminary “trails” of data behind them. Such testing can at least identify ranges of un­
certainty in the place of falsely held confidence in one’s knowledge of future intentions.
These theoretical problems are exacerbated by the ecology of bureaucratic politics, 
some of whose characteristics do not escape the attention of sophisticated deception 
planners. Many intelligence services reflect the interests of their associated departments, 
however much they try to remain objective. Deception generally aims at the misdirec­
tion of policy decisions, not intelligence services. If intelligence services are “had” in 
the process, this is only incidental, a joke of passing pleasure to the deception planner. 
Deception planners not only feed information that confirms preconceptions, but where 
possible they feed sprignals that appear to reinforce self-interest.
Thus, the inertial bond between the sprignal and the bureaucrat is doubly strong: A 
preconception is reinforced at a time when the denial of this preconception would ap­
pear to be adverse to bureaucratic interests.
Part of the skill in deception work is to coax one’s enemy into an assessment of 
intentions (perhaps by dangling information that confirms preconceptions) rather than 
an assessment of capabilities, in a situation where the adversary should know better 
than to expect much luck with an intentions estimate. In the words of a former decep­
tion planner [Eldredge], “all intelligence services seem seducible into an assessment of 
intentions rather than capabilities—which makes them such fall guys for C&D [cover 
and deception].”40
When cryptanalytic success is at the disposition of the deception planner, he has the 
kind of access to his adversary’s decisionmaking system that enables him to spot the ap­
parent self-interest and preconceptions that are most ripe for exploitation:
No deception operation works against enemy intelligence but against the enemy command. 
It does little good to louse up X intelligence system, if the command believes Y system. Thus 
a basic assumption is that coordinated intelligence is a seldom thing and that commands (po­
litical and military) tend to listen to the intelligence operation that fits their preconceptions 
and even their personality set and natural cultural pattern... Hitler could be reached through 
the nitwit RSHA and tended to neglect his hard Army intelligence.41
Obviously there are organizational implications, if one wishes to do more than 
identify deceptive and underlying realities, if one wishes to be sure that decisionmakers 
accept patterns that are most sensible, not those that are most appealing. That topic will 
be discussed in Section IV. As for the substantive dangers of consensus formation, we 
should bear in mind the stratagemic vulnerability of all preconceptions and especially of 
those preconceptions that are generally shared. At this juncture we might consider the 
promising forecasting technique known as the DELPHI method and its vulnerability to 
stratagem.42
Through the exploration of expert opinion, obtained in anonymous responses and 
iterated with controlled feedback, group judgments can be elicited and refined. Al­
though some of the later DELPHI techniques minimize centrist tendencies, there is the 
danger of generating too firm a consensus, or at least the risk that others will focus on 
group forecasting indicators that will enlarge vulnerabilities to deception. After all, for­
eign deception specialists are searching for the optimal preconceptions to reinforce, and 
they may be seeking their own tele-DELPHI estimates of others’ expert consensus. On 

Counter-Deception Planning
564 
The Art and Science of Military Deception
one hand, DELPHI forecasting indicators may provide above-average hypotheses to be 
tested for signal confirmation; on the other hand, DELPHI forecasting indicators may 
provide above-average targets for foreign stratagems. So DELPHI techniques may serve 
simultaneously to identify patterns of expectation and hypotheses for sprignal testing.
Guarding Against Expectation, Self-Deception, and Commitment
Thoughtful intelligence analysts may seek to challenge those stable and dominating as­
sumptions they recognize as preconceptions, either theirs or those of other analysts or 
politicians. But in picking assumptions that deserve to be challenged by contrast with 
alternative data patterns, it is important to recognize that yesterday’s preconception may 
lead to tomorrow’s expectation. Deception planners work in a world of ongoing data 
flow. They cannot always reinforce a widely shared preconception but may be able to 
modulate the wave of subsequent expectations, preconceptions that have germinated, 
grown, and blossomed. The initial “recognition” of a pattern derived from a fresh set of 
data is “an act of imagination based on observation.43 Thus, guarding against precon­
ceptions also involves guarding against the failure to retest: the first apparently coherent 
pattern of newly received data.
We tend to find what we expect to find, whether or not it exists.44 Deception plan­
ners who cannot reinforce our memories reinforce our expectations. A pseudohistory 
about World War II Soviet intelligence, Shchit i Mech [Shield and Sword], describes the 
phenomenon:
The Soviet counterespionage had organized a tremendous catch on a wholesale scale and 
was draining out of the ‘Vali Staff’ [Abwehr, Eastern Front intelligence HQ] more and more 
people and funds.... Some of the Abwehr intelligence groups sent into the Soviet rear, from 
the time of their landing, had to engage in battle with the Soviet agents. The most sensible 
members of such groups began working under the control of the Soviet Chekists, [burden­
ing the Abwehr staff departments with a variety of information which here was considered 
as absolutely reliable since it was likely. It is precisely because of its likelihood that it had a 
particularly destructive effect upon the work of the Wehrmacht staffs,] more even than the 
daring attacks of Soviet parachute units on such staffs.45
Conformist tendencies encourage minorities to yield in the deliberations of juries 
or in the small group demonstrations of the “Asch effect,” where all but one unwitting 
person claim knowingly that the shorter of two rods is the longer one, and the unwitting 
subject agrees with the crowd. Conformity aside, human data processing may involve 
centrist tendencies, with overestimations of small magnitudes and underestimations of 
large magnitudes.46 If analysts will recognize the human tendency to seek coherence and 
plausibility in data that may be incoherent,47 to confirm expectations, and to dissolve 
minority resistance, then they should structure the incongruity testing process so as to 
protect against such weaknesses. Facilities for forgetting, for segregating and aggregat­
ing data sets, for identifying outmoded assumptions of past estimates, and for challeng­
ing the fashionable notions of the day will contribute to testing of inconsistent data 
against alternative assumptions.
Guarding against expectations is not enough. The tendency of the human psyche to 
deceive itself demands that we also guard against our fantasies, our unrealistic hopes, 

 
Counter-Deception Planning
The Art and Science of Military Deception	
565
our fears that the future will repeat the particular historical disasters we have experi­
enced. The Freudian conception of self-deception is found in the analysis of repression 
and “defense mechanisms.”48 This conception is reflected in Hannah Arendt’s contro­
versial essay on “Lying in Politics,”49 in which the prevalence of deception in politics 
is ascribed primarily to the narcosis of self-deception, the deception of bystanders and 
adversaries being almost incidental to the freeing of imagination from the impediments 
to action.50 As one confidence man puts it, “You’ve got to realize that the victim wants 
to believe you.”51
Was the nonexistent “missile gap” of 1957–1961 the product of independent Soviet 
initiative or the product of anxieties within American society that Moscow harnessed 
for mutual satisfaction? Was the Suez invasion in 1956 or the 1968 invasion of Czecho­
slovakia a question of deception and surprise, or a combination of these, and a prefer­
ence by many to be surprised in the event that an invasion was under way? Without 
quibbling over terminology, we may recognize that cognition involves a symbiotic rela­
tionship between transmitters and receivers of information.
Whatever the causes of self-deception, the result is vulnerability to foreign stratage­
matists. Since deception planners seek to influence decisions, not the track record of 
intelligence bureaucracies, they may not concentrate upon deception through the intel­
ligence channels of an adversary. Confidants of the adversary leader, or known fantasies 
of key individuals, may be exploited through more direct channels.
One problem of the intelligence service guarding against the expectations and fan­
tasies of decisionmakers is to identify cognitive vulnerabilities that are being indepen­
dently reinforced. And those in power value the privacy of their thoughts, their hopes, 
and their fears. If they are to be protected against the blunders of estimation that have 
been so plentiful in the past, those in positions of power must recognize the abundant 
opportunities for their victimization. Only then will they share information on top-level 
negotiations. Only then will they encourage critical, heretical intelligence. Without such 
encouragement, established intelligence agencies may draw comfort from Goethe, who 
wrote, “Who destroys illusion in himself and in others, nature punishes tyrannically.”52
Commitment, on the part of intelligence estimators or decisionmakers, is likely to 
increase resistance to attitude change.  Prior agreement of a group may prolong con­
formity to erroneous judgments.53 If significant actions have been taken, on the basis 
of this prior belief, resistance to attitude change may be more severe.54 If past policies 
have appeared to be successful, there may be the further delusion that the quality of 
information has been improving, even when it has not.55 Thus, attitude change is fur­
ther discouraged. So, where action has been taken, decisionmakers may fail to request 
supplemental intelligence review. Those concerned with forecasts for better decisions 
should be mindful of the need for corrective reappraisal of forecasts that are the under­
pinnings of current policy and past decisions.
To assure that the horizons of decisionmakers are not unduly restricted, there is 
a role for structured “multiple advocacy” in the decision process, as suggested by Al­
exander George,56 supported by the kind of management information systems that 
encourage use of intelligence hypotheses other than those conforming to fashionable 
expectations.57 Incongruity testing is the primary method of overcoming preconcep­
tions, expectations, self-deception, and prior commitment. When the relevant data are 
contradictory, even in small but important respects, alternative hypotheses to the most 
“plausible” deserve recurring scrutiny.

Counter-Deception Planning
566 
The Art and Science of Military Deception
Before passing from the subject of incongruity testing, we should note two aspects 
of the bureaucratic milieu, pertaining to intelligence services and degrading their ability 
to detect their adversaries’ stratagems by this method. First, there is the well-known ten­
dency of the collecting agency to overvalue its own sources.58 This is not a vast problem, 
except insofar as more-or-less untested intelligence is fed to the highest level decision­
makers. In the case of communications intelligence intercepts, electronic transcripts, or 
deep penetration agent reports that arrive just before a necessary decision, there is a 
danger that clever sprignals will be funneled to just the people who should be sheltered 
from them. As Robert Amory puts it, policymakers like “the succulent taste of the hot 
poop,” which often means the very latest in current intelligence, especially that from 
exotic sources at the expense of the more pedestrian formal estimates, which involve a 
greater effort to eliminate sprignals.59 Those channels not subjected to rigorous predis­
tribution testing are those most tempting to the peddlers of sprignals.
Second, there is the less well-known tendency of intelligence agencies to overcollect 
data, at the expense of quality control.60 This can have seriously adverse effects upon in­
telligence performance. Over the last two million years, the size of the human brain has 
been expanding at a relatively steady but slow rate.61 If only the appetites of intelligence 
collectors grew at such a leisurely pace indigestion would be less troublesome. The 
sheer bulk of incoming data encourages only cursory examination of an overwhelm­
ing volume with a higher percent of both noise and sprignals than would be found in 
a more select collection program. If one had a small core of carefully scrutinized and 
cross-checked data that could serve as a basis for incongruity testing, one would have 
a head start in the predictive contest over those who are flooded by reconnaissance 
photos or signal intercepts but have neither the manpower nor the understanding of the 
importance of incongruity testing and retesting.
If we are puzzled as to why a modest collection of deceptively induced sprignals 
can overwhelm genuine signals arriving in larger volume, and from a wider array of 
sources, we may derive some understanding from studies of signal detection. J. A. Swets 
observes: “The accuracy of knowledge about signal characteristics is less critical for 
strong signals, since strong signals carry more information about these characteristics 
with themselves.”62
If deception planners work to supplant an array of weak but genuine signals with 
strong sprignals, the seeming significance of perceived sprignals is likely to obscure the 
relative ignorance respecting their sources, characteristics, and channels of transmittal. 
The inundation of intelligence systems with increasing masses of data encourages only 
minimal attention to signal (and sprignal) characteristics. If an overloaded intelligence 
system contains sprignals with stronger impulses than those in background signals and 
noise, we should not be shocked if the sprignals dominate resulting perceptual patterns.
Those who think that the budgeting of another squadron of recce aircraft or the 
launching of another set of satellites will solve our intelligence problems should contem­
plate the possibility that more massive but indiscriminate data collection will have the 
following result: to inundate the signals with the high volume of noise, while adversary 
deception planners work feverishly and successfully to bombard the system at critical 
junctures with enough of the sprignal data to control the final pattern. If deception 
planners fear that their critical sprignals will be buried in the backlog of unprocessed 
data, they can arrange to “leak” some last-minute gem, assuring the hurdling of filtra­
tion barriers. There are too many bureaucratic and budgetary pressures encouraging 
overinvestment in intelligence collection systems. With fewer data and more care, with 

 
Counter-Deception Planning
The Art and Science of Military Deception	
567
computer assistance and a counter­deception system, we can obtain better estimative 
results.
Vulnerability Assessment
Various statistical approaches may be adopted to predict future vulnerabilities through 
knowledge of those in the past. With Bayes’ theorem and multivariate statistical analysis 
we can arrive at conditional probabilities of deception in various modes under various 
conditions. Game theory, simulation methods, and historical studies may yield conclu­
sions about the likelihood and usefulness of deception in various modes, and about the 
payoffs through inducing wrongful rejection of accurate warnings (by labeling them 
sprignals). With estimates of the risks and costs of making either a Type I (lack of warn­
ing), or Type II (false positive warning) error, a reconstructive inference system and an 
incongruity testing system can be designed so as to optimize system outputs.63 Studies 
such as Barton Whaley’s Stratagem provide at least a tentative set of a priori probabili­
ties. A set of classified studies could further refine some of these probabilities.
Aside from historical studies, war gaming, and simulation exercises, a set of field 
exercises could generate close-to-real-life probability ranges that would help assess the 
risks of various arms control postures. Although suggested from time to time since 
1961, Amrom Katz’s “Hiders and Finders” proposal has never been tested in the field.64 
The Arms Control and Disarmament Agency’s efforts in Project CLOUD GAP (renamed 
FIRST LOOK) did not constitute a full-fledged field test of stratagematic vulnerabilities. 
Even more disconcerting are the results of one of the few off-site verification experi­
ments as yet conducted: “Aerial and ground observations in a study by independent 
research teams failed to distinguish from the exterior which of three American manu­
facturing plants was producing the deadly VX nerve gas.”65 Although it was known that 
one of three plants was engaged in clandestine manufacture, off-site verification efforts 
failed without any complications introduced by deception specialists. With the “assis­
tance” of “tips” as to yet other sites said to be clandestine producers, a team with even 
a small quota of on-site inspections might well expend that quota inspecting perfectly 
innocent plants.
If the United States wishes to enter into arms control arrangements that are not safe 
unless protected by accurate intelligence, planners should run field tests in which the 
“hiders’” resources include not only passive security but strategic deception as well. If 
they are wary of deceptions mounted by particular states or clusters of states (as, for 
example, the Warsaw Pact) they should seek to understand past stratagemic styles and 
practices.
Past national styles and practices may assist in assessing vulnerabilities to prospec­
tive stratagems and in the detection of these practices by the reconstruction of sprignal 
patterns. No rigorous studies of national styles of stratagem have been identified, thus 
the research base does not support firm conclusions. Impressionistic writings do exist 
and are the basis of the following tentative observations of national styles of deception.
NOTE: Here follows several informative pages on Soviet and Chinese styles of 
stratagem. Harris called in 1973 for a “research base” that would “support firm conclu­
sions.” Thirty-four years later and I still don’t know of one. A starting point might be 
the thin preliminary effort in Whaley, The Prevalence of Guile: Deception through Time 

Counter-Deception Planning
568 
The Art and Science of Military Deception
and across Cultures and Disciplines (Washington, DC: FD&DC, Office of the Director 
of National Intelligence, 2007), 11-57, 60-64.]
Countermeasures
Even if deception analysts have only partially succeeded in detecting those stratagems 
of which they are the target, they can undertake three sets of countermeasures. The 
first is a program to make their intelligence systems less vulnerable to stratagem; some 
of the systems and techniques have been previously discussed. As preventive medicine 
they should try to ensure that their intelligence system is designed to provide secure, 
variable, corroborative data. In general the U.S. intelligence system provides such data. 
Perhaps the greatest weakness in the system is with variability. The United States tends 
to collect data in accustomed ways; further, we have bought expensive hardware and 
associated analytic equipment, and it is costly to vary collecting patterns. It is important 
to collect intelligence “sources and methods” with whatever security we can provide 
since the greater the uncertainty about our collection parameters, the more difficult for 
our adversary to custom tailor sprignal packages. It is important to corroborate data in 
“all available lights,” and where necessary to undertake “crash” collection programs 
(counter-deception intelligence), that authenticate or contradict sets of suspected signals 
and sprignals.
The second set of counter-measures involves the allocation of resources, the design 
of weapon systems and of arms control postures that reduce the costs of intelligence 
misjudgments, taking account of stratagemic vulnerabilities. When we make intentions 
estimates about matters that have not left a trail of evidence, we should take into ac­
count the high a priori probabilities of vulnerability to adversary deception. We may 
attempt to prolong our options or to withhold a more-substantial component of our re­
serves until we have greater confidence in our judgments. The withholding of resources 
may, in some cases, be more costly than a choice in the face of uncertainty. Where we 
have detected or anticipated a threat accompanied by stratagemic feints or decoys that 
we cannot expect to segregate, we might prefer to hold our reserves for specific parries, 
but we will find it irrational to do so if the “harder” indicators we seek are unlikely to 
materialize.
In the extreme case we may face the threat of a randomly generated choice. No 
matter how clever an intelligence system, it will be unable to identify the genuine threat 
before the choice is made. Further, if the random choice among N possible options is 
accompanied by N stratagems, one associated with each option, and if after the choice 
is made the probability of timely detection actions of a stratagem that does not accom­
pany the actual choice is pD, then the probability of identifying the actual choice before 
the choice is made = 1/N, and the probability of the timely elimination of all of the mis­
leading stratagems (of which there are N#M1) = the combination of detecting (N#Ml) 
events when taken (N#Ml) events at a time (#n#m1 #n#m#1) with the probability of 
detection = pD, or (pD) #n#m#l. This net probability will be quite low when pD is low 
or N is large. Further, if the probability of incorrectly eliminating (as a stratagem) the 
chosen option is much above zero, the expectation of reaching a correct and timely 
identification will be further degraded.
Where a random choice has been made and where post-choice detection of strata­
gems would not allow timely countermeasures (pD = 0), if one mounts P parries against 

 
Counter-Deception Planning
The Art and Science of Military Deception	
569
P of the N options, the probability of actually mounting a parry against the correct tar­
get is P/N. There is the risk of both spreading countermeasures too thinly to be effective 
and of concentrating them against the wrong targets. Depending upon the utilities and 
costs of various levels of counteraction, the rational game theorist will seek to minimize 
his maximum vulnerabilities (a minimax strategy) or to maximize his expected payoffs 
in counter-attack (a mixed strategy). In either case, dispositions are made that do not 
depend upon the detection of adversary stratagems.
For example, in designing an active defense and retaliatory system in the nuclear 
missile age, one may calculate that among other penetration aids one’s adversary is 
likely to mount decoys that cannot be distinguished from incoming ICBMs until after 
the decision must be made to launch ABM interceptors. A more discriminating detec­
tion system would be preferable; perhaps the system can discriminate among most of 
the incoming decoys, but one cannot count upon this event. At the least, dummy ABM 
interceptors would increase uncertainty levels on the part of the would-be attacker. One 
can raise the “entry cost” to any particular target by forcing the adversary to assign a 
greater range of uncertainty to his estimate of the distribution of “real” interceptors 
(even if the adversary knows that a certain percentage of the total apparent interceptors 
is only a set of dummies). Similarly, if one fears a counterforce attack one can increase 
the misdirection of the adversary’s initial attack by building ICBM launcher dummies 
and by camouflaging actual sites. In such cases, the value of intelligence that uncovers 
these deceits may be quite high; thus the designer of such “positive” and “negative” 
camouflage should assume that the adversary will mount expensive and sophisticated 
detection systems against these intelligence targets.
The point is not to deny the value of sprignal intelligence but to recognize that in 
some circumstances optimal allocations must be made without waiting for such intel­
ligence. Where threats are randomly generated or where sprignal packages cannot be 
pierced, waiting for counter-deception indicators may be like waiting for Godot.
The third set of counter-measures involves the “playing back” of deception op­
erations against their sponsors: counter-deception deceptions, or what I have termed 
“counter-stratagems.” Where a set of deception patterns are identified and their strate­
gic nexus uncovered, it is sometimes advisable to “feed” falsely confirming indicators 
back to the deception planners so as to lull them into the belief that they achieved the 
misallocations they were seeking.
An example of a partly successful counter-stratagem from World War II experience 
involved limited German perceptions that the Pas de Calais sector was too obviously 
only a deception target for the OVERLORD landings:
I [H. W. Eldredge] talked briefly to von Blumentritt (Rundstedt’s Chief of Staff) after V-E 
Day and he said that they had the Pas de Calais only lightly guarded (he used the word 
“crust”) and that if we broke through and went on to Paris and cut off their main forces 
they would have been in a hell of a mess. He implied that they had been misleading us on 
the Pas de Calais’ real strength (no reserves too). Thus, both he and Rundstedt had a Pas de 
Calais sensitivity. Despite this, as I recall, ... OKW and the mad Fuehrer, who saw the “big 
picture,” i.e. the deception operation, bit and hung on. (Possibly, again, it’s hard to admit 
you’ve been had.)

Counter-Deception Planning
570 
The Art and Science of Military Deception
An effective counter-deception system should support the mounting of more than 
partly successful tactical counter-stratagems. These can be effected in combination, too, 
so as to provide strategic misallocations on the part of the stratagemic initiator.
A somewhat more mischievous variation involves a set of counter­stratagems that 
do more than falsely confirm the stratagemic success of opposing deception planners. 
Instead of returning sprignal packages indicating total acceptance of the original de­
ceits, one can send back counter-stratagems suggesting modified acceptance of sprignal 
inferences with such modifications designed to cause opposing planners to modify their 
own commitments. If done skillfully, these induced modifications may uncover new 
vulnerabilities that further counter-stratagems can perpetuate.
Chess players—of whom the Russians are among the best—will appreciate the end­
less layers that can be added: counter-counter­measures, and beyond. But the sheer com­
plexity and bureaucratic inefficiency should cause most of these additional layers to 
collapse of their own weight.
Those who view stratagem as preposterous in the first instance will wonder what 
inanities I really recommend. Once more, I cite the abysmal predictive records of the 
past and note that I am deadly serious.
But we are not above making fun of ourselves; and I close the discussion of counter-
deception strategy with a quotation from Peter Ustinov’s Romanoff and Juliet:
GENERAL: Incidentally, they know your code.
AMERICAN AMBASSADOR (beaming): We know they know our code .... We only give 
them things we want them to know.
GENERAL: Incidentally, they know you know their code.
SOVIET AMBASSADOR (smiling): We have known for some time that they knew we 
knew their code. We have acted accordingly—by pretending to be duped.
GENERAL: Incidentally, you know-—they know you know they know you know 
AMERICAN AMBASSADOR (genuinely alarmed): What? Are you sure?
Notes
1.	
B. H. Liddell-Hart, Strategy: The Indirect Approach. (New York: Praeger, 1954). Liddell-Hart discusses Brit­
ish utilization of deception in the Mareth Line campaign of February-March 1943 and in Tunisia, 6 May 
1943, at pp. 282, 286-286, 289-290, in addition to his general discussion of a multiple option strategy.
2.	
By “uncoordinated” I mean that the analytic inferences as to the underlying intentions were not the product 
of all-channels intelligence analysis. One assumes that such “uncoordinated” analyses would be widely dis­
tributed among various Intelligence consumers, but this constitutes distribution, not “coordination.” On the 
evils of disjointed, compartmented analysis, see Carl Kaysen, Notes on Strategic Air Intelligence in World War 
II (ETO) R-165 (Santa Monica, Calif.: The Rand Corporation, October 1949), pp. 24-26.
3.	
Professor HI. Wentworth Eldredge conceived of some of the more spontaneous stratagems as “seat-of-the-
pants” deceptions. I have converted his usage in the cause of counter-deception analysts, who seem to rest 
more firmly on their seats.
4.	
See Barton Whaley, Codeword BARBAROSSA (Cambridge, Mass.: M.I.T. Press, 1973). See also Stratagem 
(1969 ed.), p. 146.
5.	
See sources cited in-Section II, Note 6. These examples are somewhat complicated by the remarkable success 
of the British counter-espionage services (both the Security Service, MI-5, and Section V of the Intelligence Ser­
vice, MI-6) in penetrating their German counterparts. Consequently, British deceptions operated on the Ger­
man services from the outside, admittedly with cryptologic insights, and through their contacts on the inside. 

 
Counter-Deception Planning
The Art and Science of Military Deception	
571
It is thus not surprising that Admiral Canaris, often pictured as a “hero” of the German resistance, should be 
portrayed by Hugh Trevor-Roper, who ran the German section of MI-6’s Section V, as rather incompetent. See 
Trevor-Roper’s portrait of the Abwehr chief in The Philby Affair.
6.	
Whaley, Stratagem (1969 ed.), p. 230. The five sets of fake plans swallowed whole involved Whaley’s cases 
A6 (Gaza), A8 (St.-Mihiel), A38 (North Africa, TORCH), A53 (Bavarian Redoubt), and B27 (Alam Haifa). 
The four sets of genuine plans that were disregarded involved Whaley’s cases A10 (Warsaw), A20 (Belgium), 
A21 (France), and A28 (USSR, BARBAROSSA). The only genuine plan accepted as such involved Whaley’s 
case A34 (German summer offensive, Russia, 1942, BLAU). One Soviet account of an NKGB penetration 
of German intelligence in World War II, Vadim Kozhevnikov’ s Shchit i Mech [Shield and Sword] (Moskva: 
Sovetskiy Pisatel, 1965), translated in JPRS 56046 (19 May 1972), V. II, p. 14, claims that the German war 
plan captured at Hechelen-sur-Meuse in January 1940 was a deception plan, not the genuine plan that Whaley 
claims it was. The German attack was postponed after compromise of this document and temporary military 
alerts in the West, but the attack on May 10, 1940, achieved substantial surprise.
	
NOTE: Whaley’s 1969 data was slightly corrected and added to in Barton Whaley, Meinertzhagen’s Haver­
sack Exposed: The Consequences for Counterdeception Analysis (Washington, DC: FD&DC, Office of the 
Director of National Intelligence, 2007), 25-30.
7.	
Calculating the binomial distribution of 10 choices at a time, with the probability of success, p=0.5, yields the 
following random distribution:
R, Number of 
Correct  (p=0.5) 
Predictions
pR
Successful Predictions
0
of
10
1/1,
024
=
.001
1
of
10
10/1,
024
=
.010
2
of
10
45/1,
024
=
.044
3
of
10
120/1,
024
=
.117
4
of
10
210/1,
024
=
.205
5
of
10
252/1,
024
=
.246
6
of
10
210/1,
024
=
.205
7
of
10
120/1,
024
=
.117
8
of
10
45/1,
024
=
.044
9
of
10
10/1,
024
=
.010
10
of
10
1/1,
024
=
.001
1000
	
Probability of correctly predicting 0 or 1 of 10 = 0.011 Probability of correctly predicting 2 or more of .10 = 
0.989 [Source:] Hubert M. Blalock, Jr., Social Statistics (New York: McGraw- Hill, I960), pp. 17-118.
8.	
Carl Kaysen has noted “the vital importance of not attributing to an intelligence source credibility in respect to 
information which the source cannot reasonably be expected to possess. This is, of course, an obvious remark, 
but its importance was not often appreciated in World War II.” Notes on Strategic Air Intelligence in World 
War II (ET0), p. 20.
9.	
F. M. Cornford, in Microcosmographia Academica (London: Bowes & Bowes, 1953).
10.	
Personal Communication from H. Wentworth Eldre[d]ge.
11.	
Ibid.
12.	
Arnold L. Horelick and Myron Rush, Strategic Power and Soviet Foreign Policy (Chicago: University of Chi­
cago Press, 1966), Pt. 2m, “The Politics of Soviet Missile Deception, 1957-1961,” pp. 5­-102.
13.	
“The Government of the Soviet Union authorized TASS to state that there is no need for the Soviet Union to 
shift its weapons ... to any other country, for instance Cuba. Our nuclear weapons are so powerful in their 
explosive force and the Soviet Union has such powerful rockets to carry these nuclear warheads, that there is 
no need to search for sites for them beyond the boundaries of the Soviet Union.” TASS, September 11, 1962, 
in Graham T. Allison, Essence of Decision: Explaining the Cuban Missile Crisis (Boston: Little, Brown, 1971), 
p. 40.

Counter-Deception Planning
572 
The Art and Science of Military Deception
14.	
Anthony Lake, “Lying Around Washington: The Foreign Policy Bureaucracy (2),” Foreign Policy, n. 2 (Spring 
1971), pp. 92-93. See also David Wise, The Politics of Lying (New York: Random House, 1973).
15.	
Allison, The Essence of Decision, pp. 40-41, 135, discusses the apparent ignorance of ambassadors whose 
protestations of innocence further deception plans. In the Cuban missile crisis, assurances of Foreign Minister 
Gromyko were not interpreted as acts of an ignorant official. Those of Ambassador Dobrynin were. However, 
in the “standstill ceasefire” understanding of 1970, it was reported that “U.S. officials ... [branded Ambassa­
dor Dobrynin’s] assurances to [Department of] State Secretary Rogers that the Russians would not move their 
missiles in the Suez as a ‘deliberate lie.’”  Newsweek (September 28, 1970), p. 17.
16.	
Whaley, Stratagem (1969), pp. 147-149, advocates the collection and analysis’ of the “signals of stratagem.” 
See also Harris, Intelligence and National Security.  
17.	
The best general account of Allied deception operations in the Italian campaign is W.G.F. Jackson, [The Battle 
for Italy] (London and New York: Harper & Row, 1967), esp. pp. 25-26, 44, 46-48, 51 (Sicily); 110-111 
(Salerno); 133 (Volturno); 146-147 (Sangro); 155 (Monte Camino); 173, 182-183 (Anzio); 177, 181 (Gari­
gliano); 204­207, 222, 225-229, 230, 236-237 (DIADEM); 266, 268 (Gothic Line); 299-3C0, 304-305 (Po 
Valley).  See also Whaley’s Stratagem, Cases A38, A41,A44, B31, B33, B38, and B41, for a fuller account of 
the stratagems but less detail of their context.
18.	
R. V. Jones, “Irony as a Phenomenon in Natural Science and Human Affairs,” Chemistry & Industry (1968), 
p.470. See also pp. 472-474 for unanticipated revelations.
19.	
Personal Communication of H. Wentworth Eldredge.
20.	
See 0. T. Campbell, “Pattern Matching as an Essential in Distal Knowing,”’ in K. R. Hammond, ed. , The 
Psychology of Egon Brunswick (New York: Holt, 1966), pp. 81-106.
21.	
R. V. Jones, “The Theory of Practical Joking—Its Relevance to Physics,” p. 95.
22.	
Klaus Knorr, Foreign Intelligence and the Social Sciences, Research Monograph No. 17 (Princeton, N.J.: Cen­
ter for International Studies, June 1, 1964), p. 23.
23.	
Benno Wasserman, “The Failure of Intelligence Prediction,”Political Studies, Vol. 8 (June 1960), 156-169. 
This study is marred by its failure to probe for details of the cases cited and glibly analyzed in footnotes. Was­
serman misses the presence of stratagem in most of his cases, many of which are better handled in Whaley’s 
[Stratagem].
24.	
See the sources on cognitive dissonance and attitude change cited in Section II, Note 55.
25.	
R. V. Jones, “Scientific Intelligence,” Journal of the Royal United Services Institution, Vol. 92 (1947), p. 354.
26.	
Kaysen, Notes on Strategic Air Intelligence in World War II (ETO), p. 25.
27.	
M. Al[l]port and H. Raiffa, “A Progress Report on the Training of Probability Assessors,” unpublished note, 
August 28, 1969; N. C. Dalkey and B. Brown, Comparison of Group Judgment Techniques with Short-Range 
Predictions and Almanac Questions, R-67 8-ARPA, The Rand Corporation, May 1971; Thomas A. Brown, 
An Experiment in Probabilistic Forecasting, R-944-ARPA, The Rand Corporation, forthcoming.
28.	
Ward Edwards, Nonconservative Probabilistic Information Processing Systems, Report ESD-Tk-66-404 (Ann 
Arbor, Mich.: Institute of Science and Technology, University of Michigan, December 1966). Andrew W. Mar­
shall brought this and related studies to my attention.
29.	
The shifting conditional probability evaluation, (or “tagging”) of intelligence sources and intelligence contents 
would probably require computer facilities, if only to keep track of both source and contents evaluations and 
to adjust confidence levels in the light of post mortems or special intelligence considered highly reliable. This 
approach should be contrasted with three other static evaluation systems: the traditional Al to E6 source-
content rating system, the abandonment of quantitative evaluation in favor of a fixed verbal judgment, and 
the weighted “magnitude estimation scaling” approach. On the last-mentioned method see T. Meeland and 
R. F. Rhyne, A Confidence Scale for Intelligence Reports: An Application of Magnitude Estimation Scaling, 
SRI Technical Note RSSC-TN 4923-31 (Menlo Park, Calif.: Stanford Research Institute, June 1967). The 
computer-aided Bayesian approach has the advantage of freeing the analytic data base from the vulnerabilities 
of earlier preconceptions.
30.	
Amrom H. Katz, personal communication.
31.	
Masterman, The Double-Cross System, p. 46.
32.	
Ibid., p. 34.
33.	
This technique is suggested by Andrew W. Marshall. Sequential analysis can both identify shifting channel exploi­
tation and flag perceptual patterns that might not otherwise appear suspicious if analyzed in small pieces over an 

 
Counter-Deception Planning
The Art and Science of Military Deception	
573
extended period. In this connection, note Robert Jervis’ conclusions derived from the literature on attitudinal change:
	
“Actors can more easily assimilate into their established image of another actor information contradicting 
that image if the information is transmitted and considered bit by bit than if it all comes at once…When the 
information arrives in a block, the contradiction between it and the prevailing view is apt to be much clearer.” 
Robert Jervis, “Hypotheses on Misperception,” World Politics, v. 20 (April 1968), pp. 4 65-4 66.
34.	
Masterman, The Double-Cross System, p. 164.
35.	
Delmer, The Counterfeit Spy, p. 25.
36.	
Jones, “The Theory of Practical Joking,” p. 195.
37.	
Ibid., pp. 195-196.
38.	
Richard A. Blum, Emergency Operations Procedures in a Civil Defense Situation (Menlo Park, California: 
Stanford Research Institute, December 1955), p. 23.
39.	
Ibid., p. 40.
40.	
Personal Communication of H. Wentworth Eldredge. See also Amrom H. Katz’s warning to “count on noth­
ing, and especially count not on intentions which can change faster than capabilities can be developed.” Letter 
to the Editor, Air Force/Space Digest (September 1963).
41.	
Personal Communication of H. Wentworth Eldredge. On the vulnerability of intelligence to emotion when 
fused with political interest, see Irving, The Mare’s Nest; and R. V. Jones, “Emotion, Science, and the Bomber 
Offensive,” The Listener (November 30, 1961).
42.	
On DELPHI technique and its development, see The Rand-Corporation, A Bibliography of Selected RAND 
Publications: Long-Range Forecasting and Future Computer Technology, SB-1019 (Santa Monica, Calif.: The 
Rand Corporation, February 1972), and especially Norman C. Dalkey, The DELPHI Method: An Experimen­
tal Study of Group Opinion, RM-5 888-PR (Santa Monica, Calif.: The Rand Corporation, June 1969).
43.	
Lee J. Cronbach, [Essentials of Psychological Testing]. (New York: Harper, 2d. ed., 1960), quoted in Eugene J. 
Webb, “Individual and Organizational Forces Influencing the Interpretation of Indicators,” MS, April 1969, 
p. 12.
44.	
Donald T. Campbell,. “Systematic Error on the Part of Human Links in Communication Systems,” Infor­
mation and Control, I (195-S), pp. 349-350; J. B. Juhasz and T. R. Sarbin, “On the false alarm metaphor 
in psychophysics,” Psychological Record, Vol.16 (1966), pp. 322-327; M. D. Vernon, ed., Experiments in 
Visual Perception (Harmondsworth, Penguin, 1966), ch. 5. Early “cues” may trigger a series of seemingly 
independent expectations; when 22 witnesses identified the wrong individual in an English criminal case, the 
real criminal being discovered years later, or where in a U.S. case involving forgeries attributed to one person, 
30 witnesses attributed the forgeries to a person who was acquitted upon proof that he was in prison at the 
time of at least one forgery. See Patrick Wall, Eye-Witness Identification (Springfield, Illinois: Thomas, 1965), 
p. 12. In another case, the police replicated a hunting accident in which a hunter was mistaken for a deer. The 
police, at the same distance, could tell that the figure was that of a man, not a deer. But “the hunters, expect­
ing to see a deer, ‘saw’ a deer; the police expected to see a man and therefore ‘saw’ a man.” D. S. Greer, “Any­
thing but the Truth? The Reliability of Testimony in Criminal Trials, British Journal of Criminology, Vol. 11 
(April 1971), p. 43. Expectation of an unidentified “sane” applicant, at a mental hospital led to substantial 
reductions in abnormal admission diagnoses, and unidentified “normal” admittees were treated as if they 
were abnormal. D. L. Rosenhan, “On Being Sane in Insane Places,” Science, Vol. 179 (January 19, 1973), pp. 
250-257.
45.	
Vadim Kozhevnikov, Shchit i Mech [Shield and Sword], Moskva: Sovetskiy Pisatel, 1965, translated as JPRS 
56046, 19 May 1972, pp. 102-103 (emphasis added).
46.	
HI. L. Hlollingsworth, “The inaccuracy of movement with special reference to constant errors,” Arch. Psy­
chology, n.13 (1909), and citations in Campbell, “Systematic Error on the Part of Human Links in Commu­
nications Systems,” pp. 345-346.
47.	
“The output of the human transmission and memory unit, no matter what degree of information loss, is apt 
to appear to a later, human unit, as intelligible and usable, as a base of action. This appearance of plausibil­
ity and comprehensibility in the output can accompany a total loss of the input message. Human beings as 
transmission units have this characteristic of rationalizing, of filling gaps, of providing outputs that lead to 
action rather than paralysis.” Campbell, “Systematic Error on the Part of Human Links in Communications 
Systems;” p. 341.
48.	
Anna Freud, The Ego and the Mechanisms of Defence (1936), translated by Cecil Baines (New York: Interna­
tional Universities Press, 1946).

Counter-Deception Planning
574 
The Art and Science of Military Deception
49.	
Hannah Arendt, “Lying in Politics: Reflections on the Pentagon Papers,” New York Review of Books, Vol. 17, 
No. 8, November 18, 1971, pp. 30-39; in Hannah Arendt, Lying in Politics, Civil Disobedience, on Violence, 
Thoughts on Politics and Revolution (New York: Harcourt Brace, Jovanovich, 1972).
50.	
Also see Campbell, note 47 above.
51.	
Richard H. Blum, [Deceivers and Deceived] (Springfield, Illinois: Thomas, 1972), p. 42.
52.	
J. W. von Goethe, “Die Nature,” (1782), in Schriften uber die Natur (Leipzig, A. Kroner Verlag, n.d.).
53.	
James W. Julian, C. Robert Regula, and Edwin P. Hollander, “Effects of Prior Agreement by Others on Task 
Confidence and Conformity,” Journal of Personality & Social Psychology 9 (1968), pp. 171-178.
54.	
Charles A. Kiesler et al., The Psychology of Commitment:Experiments Linking Behavior to Belief (New York 
& London: Academic Press, 1971), chs. 4 and 5.
55.	
Siegfried Streufert and Carl H. Castore, “Effects of Increasing Success and Failure on Perceived Information 
Quality,” Psychonomic Science 11 (1968), pp. 63-64.
56.	
Alexander L. George, “The Case for” Multiple Advocacy in Making Foreign Policy,” The American Political 
Science Review, Vol. 66, No. 3 (September 1972), pp. 751-785.
57.	
See Seyom Brown, Paul Y. Hammond, William M. Jones, and Robert L. Patrick, An Information System for 
the National Security Community, RM-6054 (The Rand Corporation, Santa Monica), August 1969; and 
Bruce. F. Goeller, Paul Y. Hammond, John E. Koehler, and William B. Quandt, Information System Applica­
tions for a High Level Staff, R-S40 (The Rand Corporation, Santa Monica), August 1972.
58.	
This tendency is especially noteworthy with established espionage agents, whose case officers defend their reli­
ability. Masterman remarks on the difficulty of “blowing” a well-established agent: “The fact that we have so 
many facts and details under review makes it obvious to [us] [deception controllers] that a certain message if 
sent ought to ‘blow’ an agent. But in truth it probably or almost certainly will not.” The Double-Cross System, 
p. 57. “In short, it was extremely, almost fantastically difficult to ‘blow’ a well-established agent.” Ibid., p. 58.
On departmental perspectives, see Dearborn and Simon, “Selective Perception: A Note on the Departmental 
Identification of Executives,” Sociometry, Vol.21 (June 1958), pp. 140-144.
59.	
In this connection, note Carl Kaysen’s judgment, derived from his World War II experience: “If intelligence 
from certain sources or intelligence derived by certain methods is considered supersecret and superior to the 
general run of intelligence, it tends to penetrate upward to command levels immediately without passing 
through the machinery of shirt-sleeve intelligence analysis. Intelligence items of this character can be falsely 
interpreted and wrongly evaluated by commanders and high-ranking staff officers who do not themselves pos­
sess the necessary background possessed by the whole intelligence staff as a unit.” Notes on Strategic Air Intel­
ligence in World War II (ETO), R-165 (The Rand Corporation, Santa Monica, California), October 1949, p. 
22.
60.	
Any information processing system involves selectivity choices, whether recognized or not. See “The ‘Gate 
Keeper’: A Case Study in the Selection of News,” Journalism Quarterly, Vol. 27 (Fall 1950), pp. 383-390. On 
overcollection see Amrom H. Katz, Some Ramblings and Musings on Tactical Reconnaissance, P-2722, The 
Rand Corporation, March 1963, in Air Force/Space Digest (August 1963) ; and Patrick J. McGarvey, CIA: 
The Myth and the Madness (New York: Saturday Review Press, 1972), pp. 4, 14, 20, 23-24, 27, 115, 213-­214, 
and 225-227. McGarvey quotes Gilbert Fitzhugh, Chairman of a Blue Ribbon panel on the Department of 
Defense in July 1970: “I believe that the Pentagon suffers from too much intelligence. They can’t use what they 
get because there is so much collected” (p. 24). The availability of digital computers postpones the necessity of 
remedying excess collection by providing increased processing capabilities. Edwin W. Paxson observes, “Like 
scientific journals, command and control requirements are exponentiating. And neither scholars nor gener­
als can encompass the plethora of information.  We shouldn’t forget that a plethora is a morbid condition.” 
Computers and National Security, P-4728, The Rand Corporation, January 1972, p. 14. The data processing 
requirements of intelligence are second only to those of logistics, according to Paxson. Special surveillance 
systems may generate exponential increases in data processing requirements. Major General G. T. Gould, Jr., 
referred to annual USAF data traffic increases of about percent, noting, “This figure ... [does] not include the 
data­like requirements related to imagery or special sensor-generated systems. Systems of these types require 
separate analysis. ...On a fulltime basis, one of these systems, for example, could generate ten times more data 
than all data systems are generating today.” “Computers and Communications in the Information Age,” Air 
University Review, Vol. 21 (May-June 1970), p. 1.  Ambassador John W. Tuthill writes that recruitment of 
intelligence agents “can become a kind of infection in the intelligence services, “Operation TOPSY,” Foreign 
Policy, n. 8 (Fall 1972), p. 74.

 
Counter-Deception Planning
The Art and Science of Military Deception	
575
61.	
Phillip V. Tobias, The Brain in Hominid Evolution (New York: Columbia. University Press, 1971).
62.	
J. A. Swets, “Detection Theory and Psychophysics: A Review.” Psychornetrika, Vol. 26 (1961), pp. 49-63.
63.	
A Bayesian model for the assessment of pattern verification capabilities on the basis of a priori probabilities is 
presented by R. C. Dixon and P. E. Boudreau, in “Mathematical Model for Pattern Verification,” IBM Journal 
of Research and Development, Vol. 13 (November 1969), pp. 717-721.
64.	
Amrom H. Katz, Hiders and Finders: An Approach to Evasion and Inspection Technology, P-2432 (Santa 
Monica, Calif.: The Rand Corporation), April 26, 1961.
65.	
“Verification Task Cited at Arms Talk,” The New York Times (July 1970), p. 3. Midwest Research Insti­
tute’s summary report, Verification Aspects of a Chemical and Biological Weapons Arms Control Agree­
ment, ACDA/ST-150 (Kansas City, Mo.: Midwest Research Institute, May 29, 1969), Vol. 1, p. 20, observes: 
“Regardless of the type of evasive tactics which may be practiced in either CW or BW activity, the estimated 
inspection effectiveness is high for on­site access, medium for plant-perimeter access, and low to negligible for 
extra-territorial access levels. This indicates that inspections conducted solely at locations, outside the border 
of a treaty nation will not provide the necessary assurance of compliance with a CW arms-control agreement.” 
But if deceptive measures degrade the supposedly “high” effectiveness of on-site inspections, physical access 
may not be a panacea.


577
Conclusion
The art of deception reached a high point during the Second World War. Still, there was 
reluctance among Americans to accept deception as a part of modern warfare, despite 
the fact that the Japanese attack on Pearl Harbor was a successful deception operation 
of great magnitude. The slow evolution from reluctance to acceptance was encouraged 
and assisted by the British. But, the evolution was not an easy one, and most U.S. mili­
tary leaders remained skeptical about the benefits of high-level deception operations. 
The success of the Fortitude plans changed American attitudes.1 The obvious benefits 
of successful deception operations could not be ignored. However, American deception 
staffs were never as organized as the British, and the descent from the high point reached 
in World War II was rapid. The pendulum has swung almost completely.2 Why is decep­
tion so difficult for the U.S. military?
A Cultural Handicap?
Officially sanctioned deception does not come easy to Americans. The remarkable French­
man Alexis de Tocqueville observed in the 1840s that Americans are an open, honest lot. 
Americans have a general respect for honesty mostly based on the practical notion that 
honesty is necessary for efficient, normal transactions among people. Another Frenchman, 
lesser known, but equally remarkable, Marquis de Custine, chronicled his journey to Russia 
about the same time that Tocqueville was visiting America. Custine observed that Russians 
are secretive, deceptive, and careless with the truth both individually and as representatives 
of the state. Concealment, deception and lying are deep-seated in Russian official and inter­
personal relations.3 
Tocqueville and Custine were not saying that all Americans are honest and all Russians 
are liars. However, the premium placed on the truth by Americans is contrary to the style of 
relations standard among Russians. Perhaps the authoritarian nature of the Russian govern­
ment, then and now, which demands loyalty to the state and enforces this norm through a 
system of secret police who report any deviant behavior, explains Russian dishonesty. After 
all, no reasonable person can truly be loyal to such a cruel state. Deception and lying become 
necessary for survival.4
Characteristics of the Russian counterintelligence state are present in many of the 
other state and nonstate actors who now threaten or challenge the interests of the United 
States. These new actors use deception and lying for the same reasons as the Russians. 
1.	
 Charles Cruickshank, Deception in World War II, New York: Oxford University Press, 1979, pp. 213–216.
2.	
 Many will argue that effective deception operations would remain secret and therefore unknown to scholars. 
However, more than four decades of very close association with the U.S. military directly supporting operations 
leads me to believe that deception is a lost art in the U.S. military.
3.	
 Brian D. Dailey and Patrick J. Parker, editors, Soviet Strategic Deception, Hoover Institution Press, 1987, 
p. 511
4.	
 Ibid., 512.

Conclusion
578 
The Art and Science of Military Deception
As a result, Americans are apt to suffer in war and in international politics from a lack 
of cunning and a vulnerability to fall too easily into the enemy’s traps. General Sir Ar­
chibald Wavell, British field marshal and a commander of British Army forces in the 
Middle East during the Second World War, was a master of deception. During a lecture, 
he referred to a time-honored definition of an ideal infantryman as an “athlete, stalker 
and marksman.” Wavell went on to say that his ideal infantryman was a “cat burglar, 
poacher and gunman.” Wavell’s point was that his ideal infantryman risked his life and 
liberty in the exercise of his profession and success was directly related to wits, while 
the “athlete, stalker and marksman” was not. In fact, the former is a peacetime defini­
tion of a good infantryman, and the latter a wartime definition. Wavell’s objective was 
to stimulate interest to consider methods of deceiving the enemy based on the historical 
record.5
Not unlike Wavell’s observation of Englishmen and reflecting on his wartime expe­
rience, President Eisenhower recognized the fragile place deception holds in American 
military thinking as he felt compelled to advise the War Department to “take those steps 
that are necessary to keep alive the arts of … cover and deception.”6 What Eisenhower 
couldn’t foresee was the expansion of impediments that undermine developing and im­
plementing stratagem as a tool to further U.S. interests. Regrettably, these impediments 
are mostly internally generated. 
The Erosion of Strategy and Stratagem
The terms strategy and stratagem are derived from the Greek word strategos, which 
means: military leader, general, he who would decide strategy. This distinct origin for 
both terms is nontrivial. Strategy and stratagem must be connected, and strategy almost 
always precedes stratagem. Shallow strategic thinking can only deliver inept stratagems. 
The complexities of the modern world have been surpassed by the complexities of 
the organizations whose leaders are charged with developing strategy. Overly complex 
organizations induce an internal focus at the expense of an external one that is neces­
sary to more fully understand the threat and to develop strategies to defeat it. 
The great labyrinth of joint, interagency, and combined or international headquar­
ters, centers, and task forces require a style of military planning, coordination, and 
control that brutally subordinates the need for strategic thinking to the convenience of 
bureaucratic harmony. Commanders are compelled to focus more on their own inter­
nal administration and operations. As a result, they are less responsive to the external 
structural elements of strategy consisting of the enemy, the terrain, and other specific 
phenomena particular to the conflict. In other words, these organizations are so com­
plex on the inside that they cannot possibly be responsive to the varied and often exotic 
phenomena on the outside.7 Consequently, strategy and stratagem suffer.
An example of the triumph of bureaucratic harmony over strategic thought is evi­
dent in the recent awakening in the Department of Defense to revitalize military de­
ception (MILDEC). Several years ago, a well-resourced program to educate selected 
5.	
 Archibald Wavell, Speaking Generally—Broadcasts, Orders and Addresses in Time of War (1939–43), London: 
MacMillan & Co. LTD, 1946, p. 80.
6.	
 Dwight D. Eisenhower, The Papers of Dwight David Eisenhower: The Chief of Staff, Louis Galambos, editor, Vol. 
VIII, Baltimore: Johns Hopkins Press, 1978, p. 1763.
7.	
 Edward N. Luttwak, “Notes on Low Intensity Conflict,” Parameters, December 1983, pp. 335–338.

 
Conclusion
The Art and Science of Military Deception	
579
personnel from high-level military commands on the art and science of MILDEC was 
established. A knowledgeable and experienced cadre of mostly contractors was assem­
bled to travel to the various commands and conduct multiday, on-site MILDEC semi­
nars. Unfortunately, the seminars focused exclusively on the formidable administra­
tive hurdles required to secure approval to conduct deception and never addressed the 
fundamentals of how to deceive an opponent in war or peace. The seminar may have 
had the chilling effect of deterring units from planning deception because of the heavy 
burden associated with getting a deception plan approved.8
Competent Commanders are Good Deceivers
The National Training Center (NTC) is a relatively straightforward, realistic, and uncon­
strained simulation of war for brigade and battalion commanders. It is perhaps the only 
dynamic field environment that provides opportunities and penalties tied to the practice 
of deception. An unpublished RAND Corporation study on deception concluded that 
well-planned and executed operations contain within themselves the potential for decep­
tion. In fact, successful commanders at the NTC usually attempted deception in battle. 
In contrast, commanders who demonstrated low competence in battle used deception 
much less often. However, the link between the use of deception and success seems less 
clear than the link between competently executing plans and success.9
The point is that, given the opportunity and incentives, competent commanders will 
choose to deceive. Defeating the experienced, proficient NTC opposing force (OPFOR) 
requires using every trick in the book. Good strategy and execution are necessary for 
defeating the OPFOR, but usually insufficient without a supporting stratagem. It is im­
portant to note that the simplicity of the NTC environment does not replicate today’s 
jumble of joint, interagency, and combined or international headquarters, centers, and 
task forces that unfortunately subordinates strategic thinking to the convenience of 
bureaucratic harmony. We should avoid making war more complex than it naturally is.
More Deception is Coming
The stated purpose of this book is to set in motion a renaissance for using deception as 
an instrument of statecraft. Deception is likely to be used more in war and in political 
and diplomatic interactions in the future. It is fair to assume that the chances of small 
wars will increase as the likelihood of major war diminishes. In fact, small and irregular 
wars have dominated history. Political and diplomatic stratagems can be important tools 
for those best prepared to use them. Current and future political and military leaders 
will need to be at least as clever, if not more so, than those of the past. The incentives to 
use deception by weaker actors are great. With the world being a trickier place, detect­
ing deception is very important and carrying out a few of our own will almost certainly 
be prudent. 
8.	
 I attended one of these seminars in the summer of 2012 as this book was being put together. I was shocked to find 
that not once during the seminar was anything about the art and science of deception discussed. I reported this to 
the appropriate office in the Pentagon. HSR
9.	
 F. Feer, “Tactical Deception at the National Training Center,” The Rand Corporation, working draft, 1989, p. vii.


581
Glossary of Terms Relating to Deception
“A” Type Deception  “Ambiguity Deception” geared toward creating general confusion.
“M” Type Deception  “Misleading Deception” designed to mislead an adversary into a specific 
and preconceived direction.
Active Camouflage   The artificial creation of the image or impression that you have a force or 
capability that does not actually exist.
Active Deception   Any attempt to create the impression of intentions and capabilities which you 
do not, in fact, possess.
Conditioning   The repetition of what could be preparations for a hostile action without conduct­
ing hostilities thereby lulling the victim into a false sense of security. This is a variation of the “fa­
miliarity breeds contempt” theme.  
Cover   The use of an apparently nonthreatening activity to disguise preparation for or initiation 
of a hostile act. A common example is the use of a training exercise to hide preparations for an 
attack.Note: Conditioning and cover may occur in combination with one another and they can be 
mutually supportive. A common example is a military training exercise.
Deception (as used in the manipulation of information and perceptions combination “Denial and 
to induce the target of that deception to take or not Deception”)   to take an action, thereby 
benefiting the deceiver. Note: “Denial and deception are interrelated. Denial is the basis for a suc­
cessful deception. One cannot manipulate or blur the truth or lie convincingly unless the truth is 
first concealed.” John Yurechko, Defense Intelligence Agency, “DoD Briefing on Iraqi Denial and 
Deception,” Tuesday, October 8, 2002, 12:58 p.m. EDT.
Demonstration  The deployment of forces to distract an enemy, but such a deployment does not 
usually include actual contact or combat. The purpose of a diversion is simply to mislead an enemy 
away from your real operations and objectives.
Denial  Methods used to conceal state and military secrets, particularly from foreign intelligence 
collection.
Dezinformatsia  The dissemination of false or misleading information intended to confuse, dis­
credit, or embarrass the enemy. (Marshals of the Soviet Union A. A. Grechko and N. V. Ogarkov 
[successive Chairmen of the Main Editorial Commission], The Soviet Military Encyclopedia; Eng­
lish Language Edition, Vol. 1, William C. Green and W. Robert Reeves, ed. and trans., Boulder, CO  
Westview Press, 1993, pp. 345–346.)

Glossary of Terms Relating to Deception
582 
The Art and Science of Military Deception
Diversion   The intentional distraction of an enemy’s attention away from the area of interest or 
attack. Two basic types: feint and demonstration.
Fabrication  The creation of false information or images to mislead an adversary as to your inten­
tions and/or capabilities. This is deception via manufactured data (e.g., forgeries).
Feint  An attack by friendly forces to distract enemy attention from your main area of interest or 
attack.
Manipulation  The use of true or factual data in such a way as to create a false impression. The 
information is not false, but through using it out of context, leaving out some of the details, or 
providing a false balance of emphasis, the impression is skewed (e.g., being quoted out of context).
Maskirovka  “A means of securing the combat operations and daily activity of forces; a complex 
of measures designed to mislead the enemy as to the presence and disposition of forces and various 
military objects, their condition, combat readiness and operations and also the plans of the com­
mander . . . Maskirovka contributes to the achievement of surprise for the actions of forces, the 
preservation of combat readiness and the increased survivability of objects” (Grechko and Ogarkov, 
pp. 277–280).
Operational Deception  Deception that confuses or diverts an adversary in regard to a specific 
operation or action you are preparing to conduct.
Passive Camouflage  The disguise or cloaking of forces and/or facilities to prevent their detection 
by an enemy.
Passive Deception  Efforts designed to prevent detection of your actual capabilities and intentions.
Strategic Deception  Deception that disguises your basic objectives, intentions, strategies, and 
capabilities.
Tactical Deception  Deception that misleads others while they are actively involved in competition 
with you, your interests, or your forces.

583
About the Editors
Hy Rothstein teaches in the Defense Analysis Department at the Naval Postgraduate 
School in Monterey, CA. He served in the U.S. Army as a Special Forces officer for 
more than 26 years prior to embarking on a teaching career. He is a graduate of the 
United States Military Academy at West Point and has a Ph.D. in international relations 
from the Fletcher School at Tufts University. Dr. Rothstein has written and edited books 
about Afghanistan (Afghanistan and the Troubled Future of Unconventional Warfare 
(2006) and Afghan Endgames Strategy and Policy Choices for America’s Longest War 
(Feb 2012)), Iraq (The Three Circles of War (2010)), and an anthology that explores 
the similarities between insurgency and gang violence (Gangs & Guerrillas (2011)). He 
teaches courses and conducts research on the strategic utility of special operations, mili­
tary deception, and psychological warfare. 
Barton Whaley, a specialist in deception analysis, earned a Ph.D. in political science 
from M.I.T. in 1969.  His dissertation, later published as Codeword Barbarossa, was 
the first application of the analysis of competing hypotheses (ACH) method to unmask 
the secret deception operation underlying a major surprise attack.  He has been called 
one of the world’s preeminent military-political deception theorists since 1969.  Dr. 
Whaley is also a student of magic as deception and has published an award-winning 
reference book and biographies on that subject.  Dr. Whaley has been a visiting profes­
sor in the Defense Analysis Department at the Naval Postgraduate School in Monterey, 
CA, teaching deception, the detection of deception, and intelligence analysis.  His book, 
Stratagem: Deception and Surprise in War (reprinted recently by Artech House), is ar­
guably the most cited work on the subject of military deception. 


